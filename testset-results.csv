Input masked function,Exact Match?,Expected if condition,Predicted if condition,CodeBLEU score,BLEU-4 score
"def __init__(self, scale, factor, mode): <TAB> self.index = 0 <TAB> self.scale = scale <TAB> if factor is None: <TAB>  <TAB> self._log_factor = None <TAB> else: <MASK> raise ValueError(""'factor' must be >= 1.0"") <TAB>  <TAB> self._log_factor = np.log(factor) <TAB> if mode not in self.allowed_modes: <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> (""'{0}' is not a recognized mode. "" ""Please select from: {1}"").format( <TAB>  <TAB>  <TAB>  <TAB> mode, self.allowed_modes <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB> self.mode = mode,if factor < 1.0 :,160",TRUE,"if', ' factor', ' <', ' 1', '.', '0', ' :',","if', ' factor', ' <', ' 1', '.', '0', ' :',",0,0
"def get_grab_keys(self): <TAB> keystr = None <TAB> try: <TAB>  <TAB> keys = self.display.get_grab_keys() <TAB>  <TAB> for k in keys: <MASK> keystr = gtk.gdk.keyval_name(k) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> keystr = keystr + ""+"" + gtk.gdk.keyval_name(k) <TAB> except: <TAB>  <TAB> pass <TAB> return keystr,if keystr is None :,115",FALSE,"if', ' key', 'str', ' is', ' None', ' :',","if', ' k', 'str', ' is', ' None', ' :',",0,0
"def _checkAllExamples(self, num_type): <TAB> for region_code in phonenumberutil.SUPPORTED_REGIONS: <TAB>  <TAB> numobj_py = phonenumberutil.example_number_for_type(region_code, num_type) <MASK> numobj_pb = PyToPB(numobj_py) <TAB>  <TAB>  <TAB> alt_py = PBToPy(numobj_pb) <TAB>  <TAB>  <TAB> self.assertEqual(numobj_py, alt_py),if numobj_py is not None :,127",TRUE,"if', ' num', 'obj', '_', 'py', ' is', ' not', ' None', ' :',","if', ' num', 'obj', '_', 'py', ' is', ' not', ' None', ' :',",0,0
"def _gaf10iterator(handle): <TAB> for inline in handle: <TAB>  <TAB> if inline[0] == ""!"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> inrec = inline.rstrip(""\n"").split(""\t"") <MASK> continue <TAB>  <TAB> inrec[3] = inrec[3].split(""|"")  # Qualifier <TAB>  <TAB> inrec[5] = inrec[5].split(""|"")  # DB:reference(s) <TAB>  <TAB> inrec[7] = inrec[7].split(""|"")  # With || From <TAB>  <TAB> inrec[10] = inrec[10].split(""|"")  # Synonym <TAB>  <TAB> inrec[12] = inrec[12].split(""|"")  # Taxon <TAB>  <TAB> yield dict(zip(GAF10FIELDS, inrec)),if len ( inrec ) == 1 :,188",FALSE,"if', ' len', ' (', ' in', 'rec', ' )', ' ==', ' 1', ' :',","if', ' in', ' (', ' in', 'rec', ' )', ' ==', ' 0', ' :',",0,0
"def __xor__(self, other): <TAB> inc, exc = _norm_args_notimplemented(other) <TAB> if inc is NotImplemented: <TAB>  <TAB> return NotImplemented <TAB> if inc is NotImplemented: <TAB>  <TAB> return NotImplemented <TAB> if self._included is None: <MASK> # - + <TAB>  <TAB>  <TAB> return _ComplementSet(excluded=self._excluded - inc) <TAB>  <TAB> else:  # - - <TAB>  <TAB>  <TAB> return _ComplementSet(included=self._excluded.symmetric_difference(exc)) <TAB> else: <TAB>  <TAB> if inc is None:  # + - <TAB>  <TAB>  <TAB> return _ComplementSet(excluded=exc - self._included) <TAB>  <TAB> else:  # + + <TAB>  <TAB>  <TAB> return _ComplementSet(included=self._included.symmetric_difference(inc)),if exc is None :,183",FALSE,"if', ' exc', ' is', ' None', ' :',","if', ' exc', ' is', ' not', ' :',",0,0
"def connection(self, commit_on_success=False): <TAB> with self._lock: <TAB>  <TAB> if self._bulk_commit: <TAB>  <TAB>  <TAB> if self._pending_connection is None: <TAB>  <TAB>  <TAB>  <TAB> self._pending_connection = sqlite.connect(self.filename) <TAB>  <TAB>  <TAB> con = self._pending_connection <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> con = sqlite.connect(self.filename) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if self.fast_save: <TAB>  <TAB>  <TAB>  <TAB> con.execute(""PRAGMA synchronous = 0;"") <TAB>  <TAB>  <TAB> yield con <TAB>  <TAB>  <TAB> if commit_on_success and self.can_commit: <TAB>  <TAB>  <TAB>  <TAB> con.commit() <TAB>  <TAB> finally: <MASK> con.close(),if not self . _bulk_commit :,182",FALSE,"if', ' not', ' self', ' .', ' _', 'bulk', '_', 'commit', ' :',","if', ' self', ' commit', ' .', ' fast', 'bulk', '_', 'commit', ' :',",0,0
"def renderable_events(self, date, hour): <TAB> """"Returns the number of renderable events"""" <TAB> renderable_events = [] <TAB> for event in self.events: <TAB>  <TAB> if event.covers(date, hour): <TAB>  <TAB>  <TAB> renderable_events.append(event) <TAB> if hour: <TAB>  <TAB> for current in renderable_events: <TAB>  <TAB>  <TAB> for event in self.events: <MASK> for hour in range(self.start_hour, self.end_hour): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if current.covers(date, hour) and event.covers(date, hour): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> renderable_events.append(event) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return renderable_events"",if event not in renderable_events :,191",FALSE,"if', ' event', ' not', ' in', ' renderable', '_', 'events', ' :',","if', ' current', ' .', ' in', ' renderable', '_', 'events', ' :',",0,0
"""def _prepare_cooldowns(self, ctx): <TAB> if self._buckets.valid: <TAB>  <TAB> dt = ctx.message.edited_at or ctx.message.created_at <TAB>  <TAB> current = dt.replace(tzinfo=datetime.timezone.utc).timestamp() <TAB>  <TAB> bucket = self._buckets.get_bucket(ctx.message, current) <TAB>  <TAB> retry_after = bucket.update_rate_limit(current) <MASK> raise CommandOnCooldown(bucket, retry_after)"",if retry_after :,122",FALSE,"if', ' retry', '_', 'after', ' :',","if', ' retry', '_', 'after', ' :', 'if', ' tt', ' ==', ' 16', ' :',",0,0
"def n_import_from(self, node): <TAB> relative_path_index = 0 <TAB> if self.version >= 2.5: <TAB>  <TAB> if node[relative_path_index].pattr > 0: <TAB>  <TAB>  <TAB> node[2].pattr = (""."" * node[relative_path_index].pattr) + node[2].pattr <MASK> if isinstance(node[1].pattr, tuple): <TAB>  <TAB>  <TAB>  <TAB> imports = node[1].pattr <TAB>  <TAB>  <TAB>  <TAB> for pattr in imports: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> node[1].pattr = pattr <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.default(node) <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> pass <TAB> self.default(node),if self . version > 2.7 :,170",FALSE,"if', ' self', ' .', ' version', ' >', ' 2', '.', '7', ' :',","if', ' isinstance', ' .', ' version', ' >=', ' 2', '.', '5', ' :',",0,0
"def logic(): <TAB> while 1: <TAB>  <TAB> yield a <TAB>  <TAB> var = 0 <TAB>  <TAB> for i in downrange(len(a)): <MASK> var += 1 <TAB>  <TAB> out.next = var,if a [ i ] == 1 :,61",FALSE,"if', ' a', ' [', ' i', ' ]', ' ==', ' 1', ' :',","if', ' a', ' [', ' i', ' ]', ' ==', ' out', ' :',",0,0
"def _extract_networks(self, server_node): <TAB> """"""Marshal the networks attribute of a parsed request"""""" <TAB> node = self.find_first_child_named(server_node, ""networks"") <TAB> if node is not None: <TAB>  <TAB> networks = [] <TAB>  <TAB> for network_node in self.find_children_named(node, ""network""): <TAB>  <TAB>  <TAB> item = {} <MASK> item[""uuid""] = network_node.getAttribute(""uuid"") <TAB>  <TAB>  <TAB> if network_node.hasAttribute(""fixed_ip""): <TAB>  <TAB>  <TAB>  <TAB> item[""fixed_ip""] = network_node.getAttribute(""fixed_ip"") <TAB>  <TAB>  <TAB> networks.append(item) <TAB>  <TAB> return networks <TAB> else: <TAB>  <TAB> return None,""if network_node . hasAttribute ( """"uuid"""" ) :"",186",FALSE,"if', ' network', '_', 'node', ' .', ' hasAttribute', ' (', ' ""', 'uuid', '""', ' )', ' :', 'el',","if', ' network', '_', 'node', ' .', ' has', ' (', ' ""', 'uuid', '""', ' )', ' :',",0,0
"def _model_shorthand(self, args): <TAB> accum = [] <TAB> for arg in args: <TAB>  <TAB> if isinstance(arg, Node): <TAB>  <TAB>  <TAB> accum.append(arg) <MASK> accum.append(arg) <TAB>  <TAB> elif isinstance(arg, ModelAlias): <TAB>  <TAB>  <TAB> accum.extend(arg.get_proxy_fields()) <TAB>  <TAB> elif isclass(arg) and issubclass(arg, Model): <TAB>  <TAB>  <TAB> accum.extend(arg._meta.declared_fields) <TAB> return accum,""elif isinstance ( arg , Query ) :"",125",FALSE,"if', ' isinstance', ' (', ' arg', ' ,', ' Query', ' )', ' :',","if', 'if', ' isinstance', ' (', ' arg', ' ,', ' Model', ' )', ' :',",0,0
"def on_show_comment(self, widget, another): <TAB> if widget.get_active(): <MASK> self.treeview.update_items(all=True, comment=True) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.treeview.update_items(comment=True) <TAB> else: <TAB>  <TAB> if another.get_active(): <TAB>  <TAB>  <TAB> self.treeview.update_items(all=True) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.treeview.update_items(),if another . get_active ( ) :,121",TRUE,"if', ' another', ' .', ' get', '_', 'active', ' (', ' )', ' :',","if', ' another', ' .', ' get', '_', 'active', ' (', ' )', ' :',",0,0
"def test_select_figure_formats_set(): <TAB> ip = get_ipython() <TAB> for fmts in [ <TAB>  <TAB> {""png"", ""svg""}, <TAB>  <TAB> [""png""], <TAB>  <TAB> (""jpeg"", ""pdf"", ""retina""), <TAB>  <TAB> {""svg""}, <TAB> ]: <TAB>  <TAB> active_mimes = {_fmt_mime_map[fmt] for fmt in fmts} <TAB>  <TAB> pt.select_figure_formats(ip, fmts) <TAB>  <TAB> for mime, f in ip.display_formatter.formatters.items(): <MASK> nt.assert_in(Figure, f) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> nt.assert_not_in(Figure, f),if mime in active_mimes :,170",TRUE,"if', ' mime', ' in', ' active', '_', 'm', 'imes', ' :',","if', ' mime', ' in', ' active', '_', 'm', 'imes', ' :',",0,0
"def update_from_data(self, data): <TAB> super(HelpParameter, self).update_from_data(data) <TAB> # original help.py value_sources are strings, update command strings to value-source dict <TAB> if self.value_sources: <TAB>  <TAB> self.value_sources = [ <TAB>  <TAB>  <TAB> str_or_dict <MASK> else {""link"": {""command"": str_or_dict}} <TAB>  <TAB>  <TAB> for str_or_dict in self.value_sources <TAB>  <TAB> ],""if isinstance ( str_or_dict , dict )"",130",FALSE,"if', ' isinstance', ' (', ' str', '_', 'or', '_', 'dict', ' ,', ' dict', ' )',","if', ' isinstance', ' (', ' str', '_', 'or', '_', 'dict', ' ,', ' list', ' )',",0,0
"def _reset_library_root_logger() -> None: <TAB> global _default_handler <TAB> with _lock: <MASK> return <TAB>  <TAB> library_root_logger = _get_library_root_logger() <TAB>  <TAB> library_root_logger.removeHandler(_default_handler) <TAB>  <TAB> library_root_logger.setLevel(logging.NOTSET) <TAB>  <TAB> _default_handler = None,if not _default_handler :,99",FALSE,"if', ' not', ' _', 'default', '_', 'handler', ' :',","if', ' _', ' _', 'default', '_', 'handler', ' :',",0,0
"def extract_headers(headers): <TAB> """"""This function extracts valid headers from interactive input."""""" <TAB> sorted_headers = {} <TAB> matches = re.findall(r""(.*):\s(.*)"", headers) <TAB> for match in matches: <TAB>  <TAB> header = match[0] <TAB>  <TAB> value = match[1] <TAB>  <TAB> try: <MASK> value = value[:-1] <TAB>  <TAB>  <TAB> sorted_headers[header] = value <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB> pass <TAB> return sorted_headers,""if value [ - 1 ] == """","""" :"",125",FALSE,"if', ' value', ' [', ' -', ' 1', ' ]', ' ==', ' "",""', ' :',","if', ' len', ' .', ' :', ' 1', ' ]', ' ==', ' ""-""', ' :',",0,0
"def _call_user_data_handler(self, operation, src, dst): <TAB> if hasattr(self, ""_user_data""): <TAB>  <TAB> for key, (data, handler) in self._user_data.items(): <MASK> handler.handle(operation, key, data, src, dst),if handler is not None :,80",FALSE,"if', ' handler', ' is', ' not', ' None', ' :',","if', ' hasattr', ' :', ' not', ' None', ' :',",0,0
"def update(self, other=None, **kwargs): <TAB> if other is not None: <MASK> other = other.items() <TAB>  <TAB> for key, value in other: <TAB>  <TAB>  <TAB> if key in kwargs: <TAB>  <TAB>  <TAB>  <TAB> raise TensorforceError.value( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> name=""NestedDict.update"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> argument=""key"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value=key, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> condition=""specified twice"", <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self[key] = value <TAB> for key, value in kwargs.items(): <TAB>  <TAB> self[key] = value,""if hasattr ( other , """"items"""" ) :"",153",FALSE,"if', ' hasattr', ' (', ' other', ' ,', ' ""', 'items', '""', ' )', ' :',","if', ' isinstance', ' (', ' other', ' ,', ' ""__', 'items', '""', ' )', ' :',",0,0
"def _restore_context(context): <TAB> # Check for changes in contextvars, and set them to the current <TAB> # context for downstream consumers <TAB> for cvar in context: <TAB>  <TAB> try: <MASK> cvar.set(context.get(cvar)) <TAB>  <TAB> except LookupError: <TAB>  <TAB>  <TAB> cvar.set(context.get(cvar)),if cvar . get ( ) != context . get ( cvar ) :,103",FALSE,"if', ' c', 'var', ' .', ' get', ' (', ' )', ' !=', ' context', ' .', ' get', ' (', ' c', 'var', ' )', ' :', 'if', ' type', ' (', ' k', ' )', ' ==', ' str', ' :',","if', ' c', 'var', ' .', ' get', ' (', ' ""', ' is', ' c', ' :', ' get', ' (', ' c', 'var', ' )', ' :',",0,0
"def read_file_or_url(self, fname): <TAB> # TODO: not working on localhost <TAB> if isinstance(fname, file): <TAB>  <TAB> result = open(fname, ""r"") <TAB> else: <TAB>  <TAB> match = self.urlre.match(fname) <MASK> result = urllib.urlopen(match.group(1)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> fname = os.path.expanduser(fname) <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> result = open(os.path.expanduser(fname), ""r"") <TAB>  <TAB>  <TAB> except IOError: <TAB>  <TAB>  <TAB>  <TAB> result = open( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""%s.%s"" % (os.path.expanduser(fname), self.defaultExtension), ""r"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return result,if match :,184",TRUE,"if', ' match', ' :',","if', ' match', ' :',",0,0
"def subclass_managers(self, recursive): <TAB> for cls in self.class_.__subclasses__(): <TAB>  <TAB> mgr = manager_of_class(cls) <MASK> yield mgr <TAB>  <TAB>  <TAB> if recursive: <TAB>  <TAB>  <TAB>  <TAB> for m in mgr.subclass_managers(True): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield m,if mgr is not None and mgr is not self :,89",FALSE,"if', ' mgr', ' is', ' not', ' None', ' and', ' mgr', ' is', ' not', ' self', ' :',","if', ' recursive', ' .', ' not', ' None', ' :', ' not', ' .', ' not', ' None', ' .',",0,0
"def star_path(path): <TAB> """"""Replace integers and integer-strings in a path with *"""""" <TAB> path = list(path) <TAB> for i, p in enumerate(path): <TAB>  <TAB> if isinstance(p, int): <TAB>  <TAB>  <TAB> path[i] = ""*"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if not isinstance(p, text_type): <TAB>  <TAB>  <TAB>  <TAB> p = p.decode() <MASK> path[i] = ""*"" <TAB> return join_path(path),if r_is_int . match ( p ) :,127",FALSE,"if', ' r', '_', 'is', '_', 'int', ' .', ' match', ' (', ' p', ' )', ' :',","if', ' p', '""', 'is', '_', 'integer', ' (', ' search', ' (', ' p', ' )', ' :',",0,0
"def cookie_decode(data, key): <TAB> """"""Verify and decode an encoded string. Return an object or None"""""" <TAB> if isinstance(data, unicode): <TAB>  <TAB> data = data.encode(""ascii"")  # 2to3 hack <TAB> if cookie_is_encoded(data): <TAB>  <TAB> sig, msg = data.split(u""?"".encode(""ascii""), 1)  # 2to3 hack <MASK> return pickle.loads(base64.b64decode(msg)) <TAB> return None,""if sig [ 1 : ] == base64 . b64encode ( hmac . new ( key , msg ) . digest ( ) ) :"",137",FALSE,"if', ' sig', ' [', ' 1', ' :', ' ]', ' ==', ' base', '64', ' .', ' b', '64', 'encode', ' (', ' hmac', ' .', ' new', ' (', ' key', ' ,', ' msg', ' )', ' .', ' digest', ' (', ' )', ' )', ' :',","if', ' sig', ' ==', ' 0', ' ]', ' ]', ' ==', ' ""', '64', ' .', ' b', '64', 'decode', ' (', ' msg', ' .', ' sha', ' (', ' msg', ' )', ' sig', ' )', ' )', ' hexdigest', ' (', ' )', ' )', ' :',",0,0
"def parse_row(cls, doc_row): <TAB> row = {} <TAB> for field_name, field in FIELD_MAP.items(): <TAB>  <TAB> if len(doc_row) > field[1]: <TAB>  <TAB>  <TAB> field_value = doc_row[field[1]] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> field_value = """" <MASK> field_value = field[2](field_value) <TAB>  <TAB> row[field_name] = field_value <TAB> return row,if len ( field ) >= 3 and callable ( field [ 2 ] ) :,127",FALSE,"if', ' len', ' (', ' field', ' )', ' >=', ' 3', ' and', ' callable', ' (', ' field', ' [', ' 2', ' ]', ' )', ' :',","if', ' len', ' (', ' field', ' )', ' >', ' 2', ' :', ' field', ' (', ' field', ' [', ' 2', ' ]', ' )', ' :',",0,0
"def semantic_masks(self): <TAB> for sid in self._seg_ids: <TAB>  <TAB> sinfo = self._sinfo.get(sid) <MASK> # Some pixels (e.g. id 0 in PanopticFPN) have no instance or semantic predictions. <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> yield (self._seg == sid).numpy().astype(np.bool), sinfo,""if sinfo is None or sinfo [ """"isthing"""" ] :"",104",FALSE,"if', ' s', 'info', ' is', ' None', ' or', ' s', 'info', ' [', ' ""', 'ist', 'hing', '""', ' ]', ' :',","if', ' s', 'info', ' is', ' None', ' :', ' s', 'info', ' is', ' 0', 'instance', 'an', '""', ' ]', ' is', 'if', ' self', ' (', ' self', ' .', ' subjects', '_', 'accept', 'able', ' )', ' ==', ' 0', ' :',",0,0
"def resolve(obj): <TAB> if isinstance(obj, list): <TAB>  <TAB> for item in obj: <TAB>  <TAB>  <TAB> resolve(item) <TAB>  <TAB> return <TAB> if isinstance(obj, dict): <MASK> with resolver.resolving(obj[u""$ref""]) as resolved: <TAB>  <TAB>  <TAB>  <TAB> resolve(resolved) <TAB>  <TAB>  <TAB>  <TAB> obj.clear() <TAB>  <TAB>  <TAB>  <TAB> obj.update(resolved) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for value in obj.values(): <TAB>  <TAB>  <TAB>  <TAB> resolve(value),""if """"$ref"""" in obj :"",127",FALSE,"if', ' ""$', 'ref', '""', ' in', ' obj', ' :',","if', ' u', 'ref', '""', ' in', ' obj', ' :',",0,0
"def read_ansible_config(project_path, variables_of_interest): <TAB> fnames = [""/etc/ansible/ansible.cfg""] <TAB> if project_path: <TAB>  <TAB> fnames.append(os.path.join(project_path, ""ansible.cfg"")) <TAB> values = {} <TAB> try: <TAB>  <TAB> parser = ConfigParser() <TAB>  <TAB> parser.read(fnames) <TAB>  <TAB> if ""defaults"" in parser: <TAB>  <TAB>  <TAB> for var in variables_of_interest: <MASK> values[var] = parser[""defaults""][var] <TAB> except Exception: <TAB>  <TAB> logger.exception(""Failed to read ansible configuration(s) {}"".format(fnames)) <TAB> return values,""if var in parser [ """"defaults"""" ] :"",166",TRUE,"if', ' var', ' in', ' parser', ' [', ' ""', 'defaults', '""', ' ]', ' :',","if', ' var', ' in', ' parser', ' [', ' ""', 'defaults', '""', ' ]', ' :',",0,0
"def test_globalphase(): <TAB> rule_set = DecompositionRuleSet(modules=[globalphase, r2rzandph]) <TAB> dummy = DummyEngine(save_commands=True) <TAB> eng = MainEngine( <TAB>  <TAB> dummy, <TAB>  <TAB> [AutoReplacer(rule_set), InstructionFilter(low_level_gates_noglobalphase)], <TAB> ) <TAB> qubit = eng.allocate_qubit() <TAB> R(1.2) | qubit <TAB> rz_count = 0 <TAB> for cmd in dummy.received_commands: <TAB>  <TAB> assert not isinstance(cmd.gate, R) <MASK> rz_count += 1 <TAB>  <TAB>  <TAB> assert cmd.gate == Rz(1.2) <TAB> assert rz_count == 1,""if isinstance ( cmd . gate , Rz ) :"",188",FALSE,"if', ' isinstance', ' (', ' cmd', ' .', ' gate', ' ,', ' R', 'z', ' )', ' :',","if', ' cmd', ' (', ' cmd', ' .', ' gate', ' ,', ' R', 'z', ' )', ' :',",0,0
"def _kill_current_player(self): <TAB> if self._current_player: <MASK> self.voice_client.resume() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.voice_client.stop() <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> self._current_player = None <TAB>  <TAB> return True <TAB> return False,if self . voice_client . is_paused ( ) :,93",FALSE,"if', ' self', ' .', ' voice', '_', 'client', ' .', ' is', '_', 'pa', 'used', ' (', ' )', ' :',","if', ' self', ' .', ' voice', '_', 'client', ' :', ' is', '_', 'active', 'used', ' (', ' )', ' :',",0,0
"def hasAmbiguousLanguage(self, p): <TAB> """"""Return True if p.b contains different @language directives."""""" <TAB> # c = self <TAB> languages, tag = set(), ""@language"" <TAB> for s in g.splitLines(p.b): <MASK> i = g.skip_ws(s, len(tag)) <TAB>  <TAB>  <TAB> j = g.skip_id(s, i) <TAB>  <TAB>  <TAB> word = s[i:j] <TAB>  <TAB>  <TAB> languages.add(word) <TAB> return len(list(languages)) > 1,""if g . match_word ( s , 0 , tag ) :"",140",FALSE,"if', ' g', ' .', ' match', '_', 'word', ' (', ' s', ' ,', ' 0', ' ,', ' tag', ' )', ' :',","if', ' s', ' .', ' skip', '_', 'tag', ' (', ' s', ' ,', ' ""@', ' )', ' len', ' )', ' :',",0,0
"def terminate(self): <TAB> n_retries = 10 <TAB> for i in range(n_retries): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> super(MemmappingPool, self).terminate() <TAB>  <TAB>  <TAB> break <TAB>  <TAB> except OSError as e: <TAB>  <TAB>  <TAB> if isinstance(e, WindowsError): <TAB>  <TAB>  <TAB>  <TAB> # Workaround  occasional ""[Error 5] Access is denied"" issue <TAB>  <TAB>  <TAB>  <TAB> # when trying to terminate a process under windows. <TAB>  <TAB>  <TAB>  <TAB> sleep(0.1) <MASK> warnings.warn( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Failed to terminate worker processes in"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> "" multiprocessing pool: %r"" % e <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> self._temp_folder_manager._unlink_temporary_resources(),if i + 1 == n_retries :,192",FALSE,"if', ' i', ' +', ' 1', ' ==', ' n', '_', 'retries', ' :',","if', ' e', ' %', ' 1', ' >=', ' n', '_', 'retries', ' :',",0,0
"def test_downsampling(self, method, maybe_range, fraction, expected_n_reads): <TAB> reader = sam.SamReader( <TAB>  <TAB> test_utils.genomics_core_testdata(""test.bam""), <TAB>  <TAB> downsample_fraction=fraction, <TAB>  <TAB> random_seed=12345, <TAB> ) <TAB> with reader: <MASK> reads_iter = reader.iterate() <TAB>  <TAB> elif method == ""query"": <TAB>  <TAB>  <TAB> reads_iter = reader.query(ranges.parse_literal(maybe_range)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.fail(""Unexpected method "" + str(method)) <TAB>  <TAB> self.assertEqual(test_utils.iterable_len(reads_iter), expected_n_reads),""if method == """"iterate"""" :"",177",TRUE,"if', ' method', ' ==', ' ""', 'iterate', '""', ' :',","if', ' method', ' ==', ' ""', 'iterate', '""', ' :',",0,0
"def verify_acceptable(self): <TAB> start = time.time() <TAB> while True: <MASK> return <TAB>  <TAB> elif (time.time() - start) > READ_TIMEOUT: <TAB>  <TAB>  <TAB> raise Exception(""Server socket did not accept in time"") <TAB>  <TAB> time.sleep(0.1),if self . select_acceptable ( ) :,79",FALSE,"if', ' self', ' .', ' select', '_', 'accept', 'able', ' (', ' )', ' :',","if', ' self', ' .', ' _', '_', 'accept', ' (', ' (', ' )', ' :',",0,0
"def replica_local_creator(next_creator, **kwargs) -> tf.Variable: <TAB> """"""Variable creator that by default creates replica local variables."""""" <TAB> if kwargs[""synchronization""] == tf.VariableSynchronization.AUTO: <TAB>  <TAB> kwargs[""synchronization""] = tf.VariableSynchronization.ON_READ <MASK> kwargs[""aggregation""] = tf.VariableAggregation.ONLY_FIRST_REPLICA <TAB>  <TAB> if kwargs[""trainable""] is None: <TAB>  <TAB>  <TAB> kwargs[""trainable""] = True <TAB> return next_creator(**kwargs),""if kwargs [ """"aggregation"""" ] == tf . VariableAggregation . NONE :"",144",FALSE,"if', ' kwargs', ' [', ' ""', 'aggregation', '""', ' ]', ' ==', ' tf', ' .', ' Variable', 'Aggregation', ' .', ' NONE', ' :',","if', ' kwargs', ' [', ' ""', 'aggregation', '""', ' ]', ' is', ' tf', ' .', ' Variable', 'Aggregation', ' .', ' ALL', ' :',",0,0
"def get_optional_nargs(self, name): <TAB> for n, kwargs in self.conf[""optional_args""]: <TAB>  <TAB> if name == n: <MASK> action = kwargs[""action""] <TAB>  <TAB>  <TAB>  <TAB> if action in (""store_true"", ""store_false""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return 0 <TAB>  <TAB>  <TAB> break <TAB> return 1,""if """"action"""" in kwargs :"",92",FALSE,"if', ' ""', 'action', '""', ' in', ' kwargs', ' :', 'el',","if', ' ""', 'action', '""', ' in', ' kwargs', ' :',",0,0
"def ageToDays(self, age_str): <TAB> age = 0 <TAB> age_str = age_str.replace(""&nbsp;"", "" "") <TAB> regex = ""(\d*.?\d+).(sec|hour|day|week|month|year)+"" <TAB> matches = re.findall(regex, age_str) <TAB> for match in matches: <TAB>  <TAB> nr, size = match <TAB>  <TAB> mult = 1 <TAB>  <TAB> if size == ""week"": <TAB>  <TAB>  <TAB> mult = 7 <TAB>  <TAB> elif size == ""month"": <TAB>  <TAB>  <TAB> mult = 30.5 <MASK> mult = 365 <TAB>  <TAB> age += tryInt(nr) * mult <TAB> return tryInt(age),""elif size == """"year"""" :"",163",FALSE,"if', ' size', ' ==', ' ""', 'year', '""', ' :',","if', ' size', ' ==', ' ""', 'day', '""', ' :',",0,0
"def put(self, userId, bucket, key, data): <TAB> if not self.initialized: <TAB>  <TAB> raise Exception(""archive not initialized"") <TAB> try: <TAB>  <TAB> uri = self.uri_for(userId, bucket, key) <MASK> raise Exception(""Failed writing file content to disk: {}"".format(uri)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return uri <TAB> except Exception as err: <TAB>  <TAB> logger.debug(""cannot put data: exception - "" + str(err)) <TAB>  <TAB> raise err,""if not self . _save_content ( uri , data ) :"",131",FALSE,"if', ' not', ' self', ' .', ' _', 'save', '_', 'content', ' (', ' uri', ' ,', ' data', ' )', ' :', 'el', 'if', ' min', ' >', ' 0', ' :',","if', ' not', ' uri', ' .', ' _', 'put', ' (', 'file', ' (', ' uri', ' ,', ' data', ' )', ' :',",0,0
"def update_job_weights(): <TAB> """"""Update job weights."""""" <TAB> for job in data_types.Job.query(): <TAB>  <TAB> multiplier = DEFAULT_MULTIPLIER <TAB>  <TAB> if environment.is_engine_fuzzer_job(job.name): <TAB>  <TAB>  <TAB> targets_count = ndb.Key(data_types.FuzzTargetsCount, job.name).get() <TAB>  <TAB>  <TAB> # If the count is 0, it may be due to a bad build or some other issue. Use <TAB>  <TAB>  <TAB> # the default weight in that case to allow for recovery. <TAB>  <TAB>  <TAB> if targets_count and targets_count.count: <TAB>  <TAB>  <TAB>  <TAB> multiplier = targets_count.count <MASK> multiplier = TARGET_COUNT_WEIGHT_CAP <TAB>  <TAB> update_job_weight(job.name, multiplier),if multiplier > TARGET_COUNT_WEIGHT_CAP :,199",FALSE,"if', ' multiplier', ' >', ' TARGET', '_', 'COUNT', '_', 'WEIGHT', '_', 'CAP', ' :', 'if', ' should', '_', 'throw', ' :',","if', ' max', ' >', ' max', ' :',",0,0
"def nested_update(org_dict, upd_dict): <TAB> for key, value in upd_dict.items(): <TAB>  <TAB> if isinstance(value, dict): <MASK> if not isinstance(org_dict[key], dict): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Mismatch between org_dict and upd_dict at node {}"".format(key) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> nested_update(org_dict[key], value) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> org_dict[key] = value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> org_dict[key] = value,if key in org_dict :,161",TRUE,"if', ' key', ' in', ' org', '_', 'dict', ' :',","if', ' key', ' in', ' org', '_', 'dict', ' :',",0,0
"def eintr_retry_call(func, *args, **kwargs): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return func(*args, **kwargs) <TAB>  <TAB> except EnvironmentError as e: <MASK> continue <TAB>  <TAB>  <TAB> raise,""if getattr ( e , """"errno"""" , None ) == errno . EINTR :"",79",FALSE,"if', ' getattr', ' (', ' e', ' ,', ' ""', 'errno', '""', ' ,', ' None', ' )', ' ==', ' errno', ' .', ' E', 'INT', 'R', ' :',","if', ' e', ' (', ' e', ' ,', ' ""', 'errno', '""', ' ,', ' errno', ' )', ' ==', ' errno', ' .', ' E', 'INT', 'R', ' :',",0,0
"def __init__(self, entity): <TAB> self._entity = weakref.proxy(entity) <TAB> self._observables = collections.OrderedDict() <TAB> self._keys_helper = _ObservableKeys(self._entity, self._observables) <TAB> # Ensure consistent ordering. <TAB> for attr_name in sorted(dir(type(self))): <TAB>  <TAB> type_attr = getattr(type(self), attr_name) <MASK> self._observables[attr_name] = getattr(self, attr_name),""if isinstance ( type_attr , define . observable ) :"",131",FALSE,"if', ' isinstance', ' (', ' type', '_', 'attr', ' ,', ' define', ' .', ' observable', ' )', ' :', 'if', ' start', ' ==', ' last', ' :',","if', ' type', ' (', ' type', '_', 'attr', ' ,', ' (', ' .', ' Attribute', '_', ' :',",0,0
"def elfheader(): <TAB> local_path = pwndbg.file.get_file(pwndbg.proc.exe) <TAB> with open(local_path, ""rb"") as f: <TAB>  <TAB> elffile = ELFFile(f) <TAB>  <TAB> sections = [] <TAB>  <TAB> for section in elffile.iter_sections(): <TAB>  <TAB>  <TAB> start = section[""sh_addr""] <TAB>  <TAB>  <TAB> # Don't print sections that aren't mapped into memory <MASK> continue <TAB>  <TAB>  <TAB> size = section[""sh_size""] <TAB>  <TAB>  <TAB> sections.append((start, start + size, section.name)) <TAB>  <TAB> sections.sort() <TAB>  <TAB> for start, end, name in sections: <TAB>  <TAB>  <TAB> print(""%#x - %#x "" % (start, end), name),if start == 0 :,189",TRUE,"if', ' start', ' ==', ' 0', ' :',","if', ' start', ' ==', ' 0', ' :',",0,0
"def orbit(): <TAB> """"""Define the internal thread for running the orbit."""""" <TAB> for point in points: <TAB>  <TAB> self.set_position(point) <TAB>  <TAB> self.set_focus(focus) <TAB>  <TAB> self.set_viewup(viewup) <TAB>  <TAB> self.renderer.ResetCameraClippingRange() <TAB>  <TAB> self.render() <TAB>  <TAB> time.sleep(step) <MASK> self.write_frame(),if write_frames :,107",FALSE,"if', ' write', '_', 'frames', ' :', 'el',","if', ' self', '_', 'frame', ' :',",0,0
"def json_format(self): <TAB> """"""Returns the integer value formatted as a JSON literal"""""" <TAB> fmt = self._jsonfmt <TAB> if fmt == NUMBER_FORMAT_HEX: <TAB>  <TAB> return format(self, ""#x"") <TAB> elif fmt == NUMBER_FORMAT_OCTAL: <TAB>  <TAB> return format(self, ""#o"") <TAB> elif fmt == NUMBER_FORMAT_BINARY: <TAB>  <TAB> return format(self, ""#b"") <TAB> elif fmt == NUMBER_FORMAT_LEGACYOCTAL: <TAB>  <TAB> if self == 0: <TAB>  <TAB>  <TAB> return ""0""  # For some reason Python's int doesn't do '00' <MASK> return ""-0%o"" % (-self) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""0%o"" % self <TAB> else: <TAB>  <TAB> return str(self),elif self < 0 :,189",FALSE,"if', ' self', ' <', ' 0', ' :',","if', ' self', ' ==', ' 0', ' :',",0,0
"def parseTime(timeStr): <TAB> regex = re.compile(constants.PARSE_TIME_REGEX) <TAB> parts = regex.match(timeStr) <TAB> if not parts: <TAB>  <TAB> return <TAB> parts = parts.groupdict() <TAB> time_params = {} <TAB> for (name, param) in parts.items(): <MASK> if name == ""miliseconds"": <TAB>  <TAB>  <TAB>  <TAB> time_params[""microseconds""] = int(param) * 1000 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> time_params[name] = int(param) <TAB> return datetime.timedelta(**time_params).total_seconds(),if param :,146",FALSE,"if', ' param', ' :',","if', ' param', ' ==',",0,0
"def build_extension(self, ext): <TAB> ext._convert_pyx_sources_to_lang() <TAB> _compiler = self.compiler <TAB> try: <TAB>  <TAB> if isinstance(ext, Library): <TAB>  <TAB>  <TAB> self.compiler = self.shlib_compiler <TAB>  <TAB> _build_ext.build_extension(self, ext) <MASK> cmd = self.get_finalized_command(""build_py"").build_lib <TAB>  <TAB>  <TAB> self.write_stub(cmd, ext) <TAB> finally: <TAB>  <TAB> self.compiler = _compiler,if ext . _needs_stub :,134",FALSE,"if', ' ext', ' .', ' _', 'needs', '_', 'stub', ' :',","if', ' self', ' .', ' is', 'is', '_', 'compile', ' (',",0,0
"def __init__(self, type, data, name=None): <TAB> Constant.__init__(self, type, data, name) <TAB> self.tag.unique_value = None <TAB> if isinstance(data, np.ndarray) and data.ndim > 0: <TAB>  <TAB> flat_data = data.ravel() <MASK> if (flat_data == flat_data[0]).all(): <TAB>  <TAB>  <TAB>  <TAB> self.tag.unique_value = flat_data[0],if flat_data . shape [ 0 ] :,118",FALSE,"if', ' flat', '_', 'data', ' .', ' shape', ' [', ' 0', ' ]', ' :', 'el',","if', ' len', '_', 'data', ' .', ' ndim', ' ==', ' 0', ' ]', ' .',",0,0
"def _find_machine(deb_arch): <TAB> for machine in _ARCH_TRANSLATIONS: <TAB>  <TAB> if _ARCH_TRANSLATIONS[machine].get(""deb"", """") == deb_arch: <TAB>  <TAB>  <TAB> return machine <MASK> return machine <TAB> raise errors.SnapcraftEnvironmentError( <TAB>  <TAB> ""Cannot set machine from deb_arch {!r}"".format(deb_arch) <TAB> ),""elif _ARCH_TRANSLATIONS [ machine ] . get ( """"uts_machine"""" , """""""" ) == deb_arch :"",124",FALSE,"if', ' _', 'ARCH', '_', 'TRANSL', 'ATIONS', ' [', ' machine', ' ]', ' .', ' get', ' (', ' ""', 'uts', '_', 'machine', '""', ' ,', ' """"', ' )', ' ==', ' deb', '_', 'arch', ' :',","if', ' _', 'ARCH', '_', 'TRANSL', 'ATIONS', ' [', ' machine', ' ]', ' .', ' get', ' (', ' ""', 'deb', '""', 'in', '""', ' ,', ' """"', ' )', ' ==', ' deb', '_', 'arch', ' :',",0,0
"def fields_for_form(form, only_fields, exclude_fields): <TAB> fields = OrderedDict() <TAB> for name, field in form.fields.items(): <TAB>  <TAB> is_not_in_only = only_fields and name not in only_fields <TAB>  <TAB> is_excluded = ( <TAB>  <TAB>  <TAB> name <TAB>  <TAB>  <TAB> in exclude_fields  # or <TAB>  <TAB>  <TAB> # name in already_created_fields <TAB>  <TAB> ) <MASK> continue <TAB>  <TAB> fields[name] = convert_form_field(field) <TAB> return fields,if is_not_in_only or is_excluded :,139",TRUE,"if', ' is', '_', 'not', '_', 'in', '_', 'only', ' or', ' is', '_', 'excluded', ' :',","if', ' is', '_', 'not', '_', 'in', '_', 'only', ' or', ' is', '_', 'excluded', ' :',",0,0
"def wait_services_ready(selectors, min_counts, count_fun, timeout=None): <TAB> readies = [0] * len(selectors) <TAB> start_time = time.time() <TAB> while True: <TAB>  <TAB> all_satisfy = True <TAB>  <TAB> for idx, selector in enumerate(selectors): <TAB>  <TAB>  <TAB> if readies[idx] < min_counts[idx]: <TAB>  <TAB>  <TAB>  <TAB> all_satisfy = False <TAB>  <TAB>  <TAB>  <TAB> readies[idx] = count_fun(selector) <TAB>  <TAB>  <TAB>  <TAB> break <MASK> break <TAB>  <TAB> if timeout and timeout + start_time < time.time(): <TAB>  <TAB>  <TAB> raise TimeoutError(""Wait cluster start timeout"") <TAB>  <TAB> time.sleep(1),if all_satisfy :,167",TRUE,"if', ' all', '_', 'sat', 'isf', 'y', ' :',","if', ' all', '_', 'sat', 'isf', 'y', ' :',",0,0
"def count_brokers(self): <TAB> self.nb_brokers = 0 <TAB> for broker in self.brokers: <MASK> self.nb_brokers += 1 <TAB> for realm in self.higher_realms: <TAB>  <TAB> for broker in realm.brokers: <TAB>  <TAB>  <TAB> if not broker.spare and broker.manage_sub_realms: <TAB>  <TAB>  <TAB>  <TAB> self.nb_brokers += 1,if not broker . spare :,118",FALSE,"if', ' not', ' broker', ' .', ' sp', 'are', ' :',","if', ' not', ' broker', ' .', ' sp', 'are', ' and',",0,0
"def _adapt_polymorphic_element(self, element): <TAB> if ""parententity"" in element._annotations: <TAB>  <TAB> search = element._annotations[""parententity""] <TAB>  <TAB> alias = self._polymorphic_adapters.get(search, None) <MASK> return alias.adapt_clause(element) <TAB> if isinstance(element, expression.FromClause): <TAB>  <TAB> search = element <TAB> elif hasattr(element, ""table""): <TAB>  <TAB> search = element.table <TAB> else: <TAB>  <TAB> return None <TAB> alias = self._polymorphic_adapters.get(search, None) <TAB> if alias: <TAB>  <TAB> return alias.adapt_clause(element),if alias :,157",TRUE,"if', ' alias', ' :',","if', ' alias', ' :',",0,0
"def get_all_methods(): <TAB> estimators = all_estimators() <TAB> for name, Estimator in estimators: <TAB>  <TAB> if name.startswith(""_""): <TAB>  <TAB>  <TAB> # skip private classes <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> methods = [] <TAB>  <TAB> for name in dir(Estimator): <TAB>  <TAB>  <TAB> if name.startswith(""_""): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> method_obj = getattr(Estimator, name) <MASK> methods.append(name) <TAB>  <TAB> methods.append(None) <TAB>  <TAB> for method in sorted(methods, key=lambda x: str(x)): <TAB>  <TAB>  <TAB> yield Estimator, method,""if hasattr ( method_obj , """"__call__"""" ) or isinstance ( method_obj , property ) :"",161",FALSE,"if', ' hasattr', ' (', ' method', '_', 'obj', ' ,', ' ""__', 'call', '__""', ' )', ' or', ' isinstance', ' (', ' method', '_', 'obj', ' ,', ' property', ' )', ' :', 'el',","if', ' method', ' (', ' method', '_', 'obj', ' ,', ' ""', 'getitem', '__""', ' )', ' :', ' method', ' (', ' method', '_', 'obj', ' ,', ' method', ' )', ' :',",0,0
"def __call__(self, es, params): <TAB> ops = 0 <TAB> indices = mandatory(params, ""indices"", self) <TAB> only_if_exists = params.get(""only-if-exists"", False) <TAB> request_params = params.get(""request-params"", {}) <TAB> for index_name in indices: <TAB>  <TAB> if not only_if_exists: <TAB>  <TAB>  <TAB> es.indices.delete(index=index_name, params=request_params) <TAB>  <TAB>  <TAB> ops += 1 <MASK> self.logger.info(""Index [%s] already exists. Deleting it."", index_name) <TAB>  <TAB>  <TAB> es.indices.delete(index=index_name, params=request_params) <TAB>  <TAB>  <TAB> ops += 1 <TAB> return ops, ""ops"",elif only_if_exists and es . indices . exists ( index = index_name ) :,198",FALSE,"if', ' only', '_',","if', ' index', '_',",0,0
"def get(): <TAB> result = [] <TAB> for b in self.key_bindings: <MASK> match = True <TAB>  <TAB>  <TAB> for i, j in zip(b.keys, keys): <TAB>  <TAB>  <TAB>  <TAB> if i != j and i != Keys.Any: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> match = False <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> if match: <TAB>  <TAB>  <TAB>  <TAB> result.append(b) <TAB> return result,if len ( keys ) < len ( b . keys ) :,113",FALSE,"if', '_', 'exists', ' and', ' es', ' .', ' indices', ' .', ' exists', ' (', ' index', ' =', ' index', '_', 'name', ' )', ' :',","if', '_', 'exists', ' :', ' index', ' .', ' indices', ' .', ' exists', ' (', ' index', ' =', ' index', '_', 'name', ' )', ' :',",0,0
"def autocommitter(): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if not self._running: <TAB>  <TAB>  <TAB>  <TAB> break <MASK> self._auto_commit() <TAB>  <TAB>  <TAB> self._cluster.handler.sleep(self._auto_commit_interval_ms / 1000) <TAB>  <TAB> except ReferenceError: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> # surface all exceptions to the main thread <TAB>  <TAB>  <TAB> self._worker_exception = sys.exc_info() <TAB>  <TAB>  <TAB> break <TAB> log.debug(""Autocommitter thread exiting""),if self . _auto_commit_enable :,141",FALSE,"if', ' len', ' (', ' keys', ' )', ' <', ' len', ' (', ' b', ' .', ' keys', ' )', ' :',","if', ' b', ' (', ' b', ' )', ' ==', ' len', ' (', ' b', ' .', ' keys', ' )', ' :',",0,0
"def on_conflict(self, *target_fields: Union[str, Term]) -> ""PostgreSQLQueryBuilder"": <TAB> if not self._insert_table: <TAB>  <TAB> raise QueryException(""On conflict only applies to insert query"") <TAB> self._on_conflict = True <TAB> for target_field in target_fields: <MASK> self._on_conflict_fields.append(self._conflict_field_str(target_field)) <TAB>  <TAB> elif isinstance(target_field, Term): <TAB>  <TAB>  <TAB> self._on_conflict_fields.append(target_field),""if isinstance ( target_field , str ) :"",141",TRUE,"if', ' isinstance', ' (', ' arg', '_', 'type', ' ,', ' Scalar', 'Arg', ' )', ' :',","if', ' isinstance', ' (', ' arg', '_', 'type', ' ,', ' Scalar', 'Arg', ' )', ' :',",0,0
"""def autocommitter(): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if not self._running: <TAB>  <TAB>  <TAB>  <TAB> break <MASK> self._auto_commit() <TAB>  <TAB>  <TAB> self._cluster.handler.sleep(self._auto_commit_interval_ms / 1000) <TAB>  <TAB> except ReferenceError: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> # surface all exceptions to the main thread <TAB>  <TAB>  <TAB> self._worker_exception = sys.exc_info() <TAB>  <TAB>  <TAB> break <TAB> log.debug(""""Autocommitter thread exiting"""")"",if self . _auto_commit_enable :,141",FALSE,"if', ' self', ' .', ' _', 'auto', '_', 'commit', '_', 'enable', ' :',","if', ' self', ' .', ' _', 'auto', '_', 'commit', '_', 'interval', ' :',",0,0
"""def on_conflict(self, *target_fields: Union[str, Term]) -> """"PostgreSQLQueryBuilder"""": <TAB> if not self._insert_table: <TAB>  <TAB> raise QueryException(""""On conflict only applies to insert query"""") <TAB> self._on_conflict = True <TAB> for target_field in target_fields: <MASK> self._on_conflict_fields.append(self._conflict_field_str(target_field)) <TAB>  <TAB> elif isinstance(target_field, Term): <TAB>  <TAB>  <TAB> self._on_conflict_fields.append(target_field)"",""if isinstance ( target_field , str ) :"",141",TRUE,"if', ' isinstance', ' (', ' target', '_', 'field', ' ,', ' str', ' )', ' :',","if', ' isinstance', ' (', ' target', '_', 'field', ' ,', ' str', ' )', ' :',",0,0
"def change_TV_DOWNLOAD_DIR(tv_download_dir): <TAB> if tv_download_dir == """": <TAB>  <TAB> sickbeard.TV_DOWNLOAD_DIR = """" <TAB>  <TAB> return True <TAB> if os.path.normpath(sickbeard.TV_DOWNLOAD_DIR) != os.path.normpath(tv_download_dir): <MASK> sickbeard.TV_DOWNLOAD_DIR = os.path.normpath(tv_download_dir) <TAB>  <TAB>  <TAB> logger.log(u""Changed TV download folder to "" + tv_download_dir) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> return True,if helpers . makeDir ( tv_download_dir ) :,157",FALSE,"if', ' helpers', ' .', ' make', 'Dir', ' (', ' tv', '_', 'download', '_', 'dir', ' )', ' :',","if', ' os', ' .', ' is', '_', ' (', ' s', '_', 'download', '_', 'dir', ' )', ' :',",0,0
"def save_config(self, cmd=""save config"", confirm=True, confirm_response=""y""): <TAB> """"""Saves Config."""""" <TAB> self.enable() <TAB> if confirm: <TAB>  <TAB> output = self.send_command_timing(command_string=cmd) <MASK> output += self.send_command_timing(confirm_response) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Send enter by default <TAB>  <TAB>  <TAB> output += self.send_command_timing(self.RETURN) <TAB> else: <TAB>  <TAB> # Some devices are slow so match on trailing-prompt if you can <TAB>  <TAB> output = self.send_command(command_string=cmd) <TAB> return output,if confirm_response :,159",TRUE,"if', ' confirm', '_', 'response', ' :',","if', ' confirm', '_', 'response', ' :',",0,0
"def apply_gradient_for_batch(inputs, labels, weights, loss): <TAB> with tf.GradientTape() as tape: <TAB>  <TAB> outputs = self.model(inputs, training=True) <MASK> outputs = [outputs] <TAB>  <TAB> if self._loss_outputs is not None: <TAB>  <TAB>  <TAB> outputs = [outputs[i] for i in self._loss_outputs] <TAB>  <TAB> batch_loss = loss(outputs, labels, weights) <TAB> if variables is None: <TAB>  <TAB> vars = self.model.trainable_variables <TAB> else: <TAB>  <TAB> vars = variables <TAB> grads = tape.gradient(batch_loss, vars) <TAB> self._tf_optimizer.apply_gradients(zip(grads, vars)) <TAB> self._global_step.assign_add(1) <TAB> return batch_loss,""if isinstance ( outputs , tf . Tensor ) :"",193",FALSE,"if', ' isinstance', ' (', ' outputs', ' ,', ' tf', ' .', ' Tensor', ' )', ' :',","if', ' isinstance', ' (', ' outputs', ' ,', ' list', ' .', ' Tensor', ' )', ' :',",0,0
"def sort(self, items): <TAB> slow_sorts = [] <TAB> switch_slow = False <TAB> for sort in reversed(self.sorts): <MASK> slow_sorts.append(sort) <TAB>  <TAB> elif sort.order_clause() is None: <TAB>  <TAB>  <TAB> switch_slow = True <TAB>  <TAB>  <TAB> slow_sorts.append(sort) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pass <TAB> for sort in slow_sorts: <TAB>  <TAB> items = sort.sort(items) <TAB> return items,if switch_slow :,121",TRUE,"if', ' switch', '_', 's', 'low', ' :',","if', ' switch', '_', 's', 'low', ' :',",0,0
"def getmod(self, nm): <TAB> mod = None <TAB> for thing in self.path: <TAB>  <TAB> if isinstance(thing, basestring): <TAB>  <TAB>  <TAB> owner = self.shadowpath.get(thing, -1) <TAB>  <TAB>  <TAB> if owner == -1: <TAB>  <TAB>  <TAB>  <TAB> owner = self.shadowpath[thing] = self.__makeOwner(thing) <MASK> mod = owner.getmod(nm) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> mod = thing.getmod(nm) <TAB>  <TAB> if mod: <TAB>  <TAB>  <TAB> break <TAB> return mod,if owner :,137",TRUE,"if', ' owner', ' :',","if', ' owner', ' :',",0,0
"def has(self, key): <TAB> filename = self._get_filename(key) <TAB> try: <TAB>  <TAB> with open(filename, ""rb"") as f: <TAB>  <TAB>  <TAB> pickle_time = pickle.load(f) <MASK> return True <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> os.remove(filename) <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> except (IOError, OSError, pickle.PickleError): <TAB>  <TAB> return False,if pickle_time == 0 or pickle_time >= time ( ) :,117",FALSE,"if', ' pickle', '_', 'time', ' ==', ' 0', ' or', ' pickle', '_', 'time', ' >=', ' time', ' (', ' )', ' :',","if', ' pickle', '_', 'time', ' .', ' time', ' :', ' pickle', '_', 'time', ' <', ' 0', ' .', ' )', ' :', 'if', ' i', ' %', ' 8', ' :',",0,0
"def forward(self, hs): <TAB> h = self.c0(hs[-1]) <TAB> for i in range(1, 8): <TAB>  <TAB> h = F.concat([h, hs[-i - 1]]) <MASK> h = self[""c%d"" % i](h) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> h = self.c7(h) <TAB> return h,if i < 7 :,96",FALSE,"if', ' arg', ' in', ' self', ' .', ' __', 'dict', '__', ' :',","if', ' arg', ' in', ' self', ' .', ' defaults', 'dict', '__', ' :',",0,0
"def _apply_operation(self, values): <TAB> """"""Method that defines the less-than-or-equal operation"""""" <TAB> arg1 = next(values) <TAB> for strict in self._strict: <TAB>  <TAB> arg2 = next(values) <TAB>  <TAB> if strict: <TAB>  <TAB>  <TAB> if not (arg1 < arg2): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <MASK> return False <TAB>  <TAB> arg1 = arg2 <TAB> return True,if not ( arg1 <= arg2 ) :,118",FALSE,"if', ' not', ' (', ' arg', '1', ' <=', ' arg', '2', ' )', ' :',","if', ' not', ' (', ' arg', '1', ' >', ' arg', '2', ' )', ' :',",0,0
"def i_pshufb(self, op, off=0): <TAB> dst = self.getOperValue(op, off) <TAB> src = self.getOperValue(op, off) <TAB> res = 0 <TAB> if op.opers[0].tsize == 8: <TAB>  <TAB> mask = 0x07 <TAB> else: <TAB>  <TAB> mask = 0x0F <TAB> for i in range(op.opers[0].tsize): <TAB>  <TAB> shfl = src & (1 << ((i * 8) + 7)) <MASK> s = 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> indx = (src >> (i * 8)) & mask <TAB>  <TAB>  <TAB> s = (src >> (indx * 8)) & 0xFF <TAB>  <TAB> res |= s << (i * 8) <TAB> self.setOperValue(op, 0, res),if shfl :,199",FALSE,"if', ' sh', 'fl', ' :',","if', ' sh', 'fl', ' ==',",0,0
"def report_out_of_quota(self, appid): <TAB> self.logger.warn(""report_out_of_quota:%s"", appid) <TAB> with self.lock: <MASK> self.out_of_quota_appids.append(appid) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.working_appid_list.remove(appid) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> pass,if appid not in self . out_of_quota_appids :,115",TRUE,"if', ' appid', ' not', ' in', ' self', ' .', ' out', '_', 'of', '_', 'quota', '_', 'app', 'ids', ' :',","if', ' appid', ' not', ' in', ' self', ' .', ' out', '_', 'of', '_', 'quota', '_', 'app', 'ids', ' :',",0,0
"def to_py(self, value: _StrUnset) -> _StrUnsetNone: <TAB> self._basic_py_validation(value, str) <TAB> if isinstance(value, usertypes.Unset): <TAB>  <TAB> return value <TAB> elif not value: <TAB>  <TAB> return None <TAB> value = os.path.expandvars(value) <TAB> value = os.path.expanduser(value) <TAB> try: <MASK> raise configexc.ValidationError(value, ""must be a valid directory!"") <TAB>  <TAB> if not os.path.isabs(value): <TAB>  <TAB>  <TAB> raise configexc.ValidationError(value, ""must be an absolute path!"") <TAB> except UnicodeEncodeError as e: <TAB>  <TAB> raise configexc.ValidationError(value, e) <TAB> return value,if not os . path . isdir ( value ) :,181",TRUE,"if', ' not', ' os', ' .', ' path', ' .', ' isdir', ' (', ' value', ' )', ' :',","if', ' not', ' os', ' .', ' path', ' .', ' isdir', ' (', ' value', ' )', ' :',",0,0
"def findinDoc(self, tagpath, pos, end): <TAB> result = None <TAB> if end == -1: <TAB>  <TAB> end = self.docSize <TAB> else: <TAB>  <TAB> end = min(self.docSize, end) <TAB> foundat = -1 <TAB> for j in range(pos, end): <TAB>  <TAB> item = self.docList[j] <TAB>  <TAB> if item.find(b""="") >= 0: <TAB>  <TAB>  <TAB> (name, argres) = item.split(b""="", 1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = item <TAB>  <TAB>  <TAB> argres = """" <MASK> tagpath = tagpath.encode(""utf-8"") <TAB>  <TAB> if name.endswith(tagpath): <TAB>  <TAB>  <TAB> result = argres <TAB>  <TAB>  <TAB> foundat = j <TAB>  <TAB>  <TAB> break <TAB> return foundat, result,""if isinstance ( tagpath , str ) :"",189",FALSE,"if', ' isinstance', ' (', ' tag', 'path', ' ,', ' str', ' )', ' :',","if', ' tag', ' (', ' tag', 'path', ' ,', ' bytes', ' )', ' :',",0,0
"def has_safe_repr(value): <TAB> """"""Does the node have a safe representation?"""""" <TAB> if value is None or value is NotImplemented or value is Ellipsis: <TAB>  <TAB> return True <TAB> if isinstance(value, (bool, int, long, float, complex, basestring, xrange, Markup)): <TAB>  <TAB> return True <TAB> if isinstance(value, (tuple, list, set, frozenset)): <TAB>  <TAB> for item in value: <TAB>  <TAB>  <TAB> if not has_safe_repr(item): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True <TAB> elif isinstance(value, dict): <TAB>  <TAB> for key, value in value.iteritems(): <TAB>  <TAB>  <TAB> if not has_safe_repr(key): <TAB>  <TAB>  <TAB>  <TAB> return False <MASK> return False <TAB>  <TAB> return True <TAB> return False,if not has_safe_repr ( value ) :,192",TRUE,"if', ' not', ' has', '_', 'safe', '_', 'repr', ' (', ' value', ' )', ' :',","if', ' not', ' has', '_', 'safe', '_', 'repr', ' (', ' value', ' )', ' :',",0,0
"def run(self): <TAB> # Make some objects emit lights <TAB> for obj in bpy.context.scene.objects: <MASK> obj_id = obj[""modelId""] <TAB>  <TAB>  <TAB> # In the case of the lamp <TAB>  <TAB>  <TAB> if obj_id in self.lights: <TAB>  <TAB>  <TAB>  <TAB> self._make_lamp_emissive(obj, self.lights[obj_id]) <TAB>  <TAB>  <TAB> # Make the windows emit light <TAB>  <TAB>  <TAB> if obj_id in self.windows: <TAB>  <TAB>  <TAB>  <TAB> self._make_window_emissive(obj) <TAB>  <TAB>  <TAB> # Also make ceilings slightly emit light <TAB>  <TAB>  <TAB> if obj.name.startswith(""Ceiling#""): <TAB>  <TAB>  <TAB>  <TAB> self._make_ceiling_emissive(obj),""if """"modelId"""" in obj :"",190",FALSE,"if', ' ""', 'model', 'Id', '""', ' in', ' obj', ' :',","if', ' obj', 'model', 'Id', '""', ' in', ' obj', ' :',",0,0
"def bitvector_case_fn( <TAB> rng: Random, mode: RandomizationMode, size: int, invalid_making_pos: int = None): <TAB> bits = get_random_ssz_object( <TAB>  <TAB> rng, <TAB>  <TAB> Bitvector[size], <TAB>  <TAB> max_bytes_length=(size + 7) // 8, <TAB>  <TAB> max_list_length=size, <TAB>  <TAB> mode=mode, <TAB>  <TAB> chaos=False, <TAB> ) <TAB> if invalid_making_pos is not None and invalid_making_pos <= size: <TAB>  <TAB> already_invalid = False <TAB>  <TAB> for i in range(invalid_making_pos, size): <MASK> already_invalid = True <TAB>  <TAB> if not already_invalid: <TAB>  <TAB>  <TAB> bits[invalid_making_pos] = True <TAB> return bits,if bits [ i ] :,196",TRUE,"if', ' bits', ' [', ' i', ' ]', ' :',","if', ' bits', ' [', ' i', ' ]', ' :',",0,0
"def get_transaction_execution_results(self, batch_signature): <TAB> with self._condition: <TAB>  <TAB> batch_status = self._batch_statuses.get(batch_signature) <TAB>  <TAB> if batch_status is None: <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> annotated_batch = self._batch_by_id.get(batch_signature) <TAB>  <TAB> if annotated_batch is None: <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> results = [] <TAB>  <TAB> for txn in annotated_batch.batch.transactions: <TAB>  <TAB>  <TAB> result = self._txn_results.get(txn.header_signature) <MASK> results.append(result) <TAB>  <TAB> return results,if result is not None :,161",FALSE,"if', ' result', ' is', ' not', ' None', ' :', 'el',","if', ' result', ' is', ' not', ' None', ' :',",0,0
"def one_xmm_reg_imm8(ii):  # also allows SSE4 2-imm8 instr <TAB> i, j, n = 0, 0, 0 <TAB> for op in _gen_opnds(ii): <TAB>  <TAB> if op_reg(op) and op_xmm(op): <TAB>  <TAB>  <TAB> n += 1 <TAB>  <TAB> elif op_imm8(op): <TAB>  <TAB>  <TAB> i += 1 <MASK> j += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> return n == 1 and i == 1 and j <= 1,elif op_imm8_2 ( op ) :,141",FALSE,"if', ' op', '_', 'im', 'm', '8', '_', '2', ' (', ' op', ' )', ' :',","if', ' op', '_', 'im', 'm', '4', ' (', 'op', ' (', ' op', ' )', ' :',",0,0
"def whichmodule(obj, name): <TAB> """"""Find the module an object belong to."""""" <TAB> module_name = getattr(obj, ""__module__"", None) <TAB> if module_name is not None: <TAB>  <TAB> return module_name <TAB> # Protect the iteration by using a list copy of sys.modules against dynamic <TAB> # modules that trigger imports of other modules upon calls to getattr. <TAB> for module_name, module in sys.modules.copy().items(): <TAB>  <TAB> if module_name == ""__main__"" or module is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> try: <MASK> return module_name <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB> pass <TAB> return ""__main__"",""if _getattribute ( module , name ) [ 0 ] is obj :"",171",FALSE,"if', ' _', 'get', 'attribute', ' (', ' module', ' ,', ' name', ' )', ' [', ' 0', ' ]', ' is', ' obj', ' :',","if', ' module', 'module', 'attr', ' (', ' module', ' ,', ' name', ' )', ' ==', ' 0', ' ]', ' ==', ' not', ' :',",0,0
"def get_ld_header_info(p): <TAB> # ""nested-function, but placed at module level <TAB> # as an ld_header was found, return known paths, archives and members <TAB> # these lines start with a digit <TAB> info = [] <TAB> for line in p.stdout: <MASK> info.append(line) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # blank line (separator), consume line and end for loop <TAB>  <TAB>  <TAB> break <TAB> return info,""if re . match ( """"[0-9]"""" , line ) :"",120",FALSE,"if', ' re', ' .', ' match', ' (', ' ""[', '0', '-', '9', ']""', ' ,', ' line', ' )', ' :',","if', ' line', ' .', ' search', ' (', ' r', '^', '-', '9', 'a', ' ,', ' line', ' )', ' :',",0,0
"def write(self, s): <TAB> if self.closed: <TAB>  <TAB> raise ValueError(""write to closed file"") <TAB> if type(s) not in (unicode, str, bytearray): <TAB>  <TAB> # See issue #19481 <MASK> s = unicode.__getitem__(s, slice(None)) <TAB>  <TAB> elif isinstance(s, str): <TAB>  <TAB>  <TAB> s = str.__str__(s) <TAB>  <TAB> elif isinstance(s, bytearray): <TAB>  <TAB>  <TAB> s = bytearray.__str__(s) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError(""must be string, not "" + type(s).__name__) <TAB> return self.shell.write(s, self.tags),""if isinstance ( s , unicode ) :"",161",FALSE,"if', ' isinstance', ' (', ' s', ' ,', ' unicode', ' )', ' :',","if', ' isinstance', ' (', ' s', ' ,', ' slice', ' )', ' :',",0,0
"def generate_forwards(cls, attrs): <TAB> # forward functions of _forwards <TAB> for attr_name, attr in cls._forwards.__dict__.items(): <MASK> continue <TAB>  <TAB> if isinstance(attr, property): <TAB>  <TAB>  <TAB> cls._forward.append(attr_name) <TAB>  <TAB> elif isinstance(attr, types.FunctionType): <TAB>  <TAB>  <TAB> wrapper = _forward_factory(cls, attr_name, attr) <TAB>  <TAB>  <TAB> setattr(cls, attr_name, wrapper) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError(attr_name, type(attr)),""if attr_name . startswith ( """"_"""" ) or attr_name in attrs :"",146",FALSE,"if', ' attr', '_', 'name', ' .', ' startswith', ' (', ' ""_""', ' )', ' or', ' attr', '_', 'name', ' in', ' attrs', ' :',","if', ' attr', '_', 'name', ' in', ' startswith', ' (', ' ""_""', ' )', ' or', ' attr', '_', 'name', ' .', ' attrs', ' :',",0,0
"def _user_has_dnd(bot, user_id): <TAB> try: <TAB>  <TAB> return bot.call_shared(""dnd.user_check"", user_id)  # shared dnd check <TAB> except KeyError: <TAB>  <TAB> logger.warning(""mentions: falling back to legacy _user_has_dnd()"") <TAB>  <TAB> initiator_has_dnd = False <MASK> donotdisturb = bot.memory.get(""donotdisturb"") <TAB>  <TAB>  <TAB> if user_id in donotdisturb: <TAB>  <TAB>  <TAB>  <TAB> initiator_has_dnd = True <TAB>  <TAB> return initiator_has_dnd,""if bot . memory . exists ( [ """"donotdisturb"""" ] ) :"",162",FALSE,"if', ' bot', ' .', ' memory', ' .', ' exists', ' (', ' [', ' ""', 'don', 'ot', 'dist', 'urb', '""', ' ]', ' )', ' :',","if', ' bot', ' .', ' memory', ' :', ' get', ' (', ' ""', ' user', 'don', 'ot', 'dist', 'urb', '""', ' ]', ' )', ' :',",0,0
"def init(self): <TAB> """"""Initialize a fighter from the database and validate"""""" <TAB> self.__item = None <TAB> if self.itemID: <TAB>  <TAB> self.__item = eos.db.getItem(self.itemID) <MASK> pyfalog.error(""Item (id: {0}) does not exist"", self.itemID) <TAB>  <TAB>  <TAB> return <TAB> if self.isInvalid: <TAB>  <TAB> pyfalog.error(""Item (id: {0}) is not a Fighter"", self.itemID) <TAB>  <TAB> return <TAB> self.build(),if self . __item is None :,141",FALSE,"if', ' self', ' .', ' __', 'item', ' is', ' None', ' :',","if', ' self', ' .', ' is', 'item', ' is', ' None', ' :',",0,0
"def _pg_sku_name_validator(sku_name, sku_info, tier): <TAB> if sku_name: <TAB>  <TAB> skus = get_postgres_skus(sku_info, tier) <MASK> error_msg = ( <TAB>  <TAB>  <TAB>  <TAB> ""Incorrect value for --sku-name. "" <TAB>  <TAB>  <TAB>  <TAB> + ""The SKU name does not match {} tier. Specify --tier if you did not. "".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> tier <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> raise CLIError(error_msg + ""Allowed values : {}"".format(skus)),if sku_name not in skus :,156",FALSE,"if', ' sku', '_', 'name', ' not', ' in', ' sk', 'us', ' :',","if', ' not', '_', 'name', ' !=', ' in', ' sk', 'us', ' :',",0,0
"def _parse_paternity_log(writer, file): <TAB> parent_map = {} <TAB> parent_map[0] = 0 <TAB> for line in file.read().decode(""utf-8"").split(""\n""): <MASK> continue <TAB>  <TAB> elems = line.split("" "")  # <Child> <Parent> <TAB>  <TAB> if len(elems) >= 2: <TAB>  <TAB>  <TAB> # <TAB>  <TAB>  <TAB>  <TAB>  <TAB>    print ""paternity of %d is %d"" % (int(elems[0]), int(elems[1])) <TAB>  <TAB>  <TAB> parent_map[int(elems[0])] = int(elems[1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""Odd paternity line '%s'"" % (line)) <TAB> return parent_map,if not line :,196",TRUE,"if', ' not', ' line', ' :',","if', ' not', ' line', ' :',",0,0
"def _get_next_cap(self): <TAB> # type: () -> bool <TAB> self._curr_cap = None <TAB> if self._curr_cap_idx is None: <TAB>  <TAB> self._curr_cap_idx = 0 <TAB>  <TAB> self._curr_cap = self._cap_list[0] <TAB>  <TAB> return True <TAB> else: <MASK> self._end_of_video = True <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> self._curr_cap_idx += 1 <TAB>  <TAB> self._curr_cap = self._cap_list[self._curr_cap_idx] <TAB>  <TAB> return True,if not ( self . _curr_cap_idx + 1 ) < len ( self . _cap_list ) :,163",FALSE,"if', ' not', ' (', ' self', ' .', ' _', 'curr', '_', 'cap', '_', 'idx', ' +', ' 1', ' )', ' <', ' len', ' (', ' self', ' .', ' _', 'cap', '_', 'list', ' )', ' :',","if', ' self', ' self', ' self', ' .', ' _', 'curr', '_', 'cap', ' ==', 'idx', ' ==', ' 1', ' )', ' in', ' self', ' (', ' self', ' .', ' _', 'cap', '_', 'list', ' )', ' :',",0,0
"def decode_payload(args): <TAB> try: <TAB>  <TAB> if args.token: <TAB>  <TAB>  <TAB> token = args.token <TAB>  <TAB> else: <MASK> token = sys.stdin.readline().strip() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise IOError(""Cannot read from stdin: terminal not a TTY"") <TAB>  <TAB> token = token.encode(""utf-8"") <TAB>  <TAB> data = decode(token, key=args.key, verify=args.verify) <TAB>  <TAB> return json.dumps(data) <TAB> except DecodeError as e: <TAB>  <TAB> raise DecodeError(""There was an error decoding the token: %s"" % e),if sys . stdin . isatty ( ) :,156",FALSE,"if', ' sys', ' .', ' stdin', ' .', ' is', 'at', 'ty', ' (', ' )', ' :',","if', ' args', ' .', ' stdin', ' .', ' is', 'at', 'ty', ' (', ' )', ' :',",0,0
"def cell_double_clicked(self, row, column): <TAB> if column == 3: <TAB>  <TAB> archive_name = self.selected_archive_name() <MASK> return <TAB>  <TAB> mount_point = self.mount_points.get(archive_name) <TAB>  <TAB> if mount_point is not None: <TAB>  <TAB>  <TAB> QDesktopServices.openUrl(QtCore.QUrl(f""file:///{mount_point}"")),if not archive_name :,107",FALSE,"if', ' not', ' archive', '_', 'name', ' :',","if', ' archive', ' archive', '_', 'name', ' :',",0,0
"def tiles_around(self, pos, radius=1, predicate=None): <TAB> ps = [] <TAB> x, y = pos <TAB> for dx in range(-radius, radius + 1): <TAB>  <TAB> nx = x + dx <MASK> for dy in range(-radius, radius + 1): <TAB>  <TAB>  <TAB>  <TAB> ny = y + dy <TAB>  <TAB>  <TAB>  <TAB> if ny >= 0 and ny < self.height and (dx != 0 or dy != 0): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if predicate is None or predicate((nx, ny)): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ps.append((nx, ny)) <TAB> return ps,if nx >= 0 and nx < self . width :,151",FALSE,"if', ' nx', ' >=', ' 0', ' and', ' nx', ' <', ' self', ' .', ' width', ' :',","if', ' nx', ' <', ' self', ' and', ' nx', ' <', ' self', ' .', ' width', ' :',",0,0
"def __init__(self, type, data, name=None): <TAB> Constant.__init__(self, type, data, name) <TAB> self.tag.unique_value = None <TAB> if isinstance(data, np.ndarray) and data.ndim > 0: <TAB>  <TAB> flat_data = data.ravel() <TAB>  <TAB> if flat_data.shape[0]: <MASK> self.tag.unique_value = flat_data[0],if ( flat_data == flat_data [ 0 ] ) . all ( ) :,118",FALSE,"if', ' (', ' flat', '_', 'data', ' ==', ' flat', '_', 'data', ' [', ' 0', ' ]', ' )', ' .', ' all', ' (', ' )', ' :',","if', ' len', ' len', '_', 'data', ' [', ' np', '_', 'data', ' .', ' 0', ' ]', ' )', ' .', ' ndim', ' (', ' )', ' :',",0,0
"def git_convert_standalone_clone(repodir): <TAB> """"""If specified directory is a git repository, ensure it's a standalone clone"""""" <TAB> import bb.process <TAB> if os.path.exists(os.path.join(repodir, "".git"")): <TAB>  <TAB> alternatesfile = os.path.join(repodir, "".git"", ""objects"", ""info"", ""alternates"") <MASK> # This will have been cloned with -s, so we need to convert it so none <TAB>  <TAB>  <TAB> # of the contents is shared <TAB>  <TAB>  <TAB> bb.process.run(""git repack -a"", cwd=repodir) <TAB>  <TAB>  <TAB> os.remove(alternatesfile),if os . path . exists ( alternatesfile ) :,166",TRUE,"if', ' os', ' .', ' path', ' .', ' exists', ' (', ' altern', 'ates', 'file', ' )', ' :',","if', ' os', ' .', ' path', ' .', ' exists', ' (', ' altern', 'ates', 'file', ' )', ' :',",0,0
"def _rename_recipe_file(oldrecipe, bpn, oldpv, newpv, path): <TAB> oldrecipe = os.path.basename(oldrecipe) <TAB> if oldrecipe.endswith(""_%s.bb"" % oldpv): <TAB>  <TAB> newrecipe = ""%s_%s.bb"" % (bpn, newpv) <MASK> shutil.move(os.path.join(path, oldrecipe), os.path.join(path, newrecipe)) <TAB> else: <TAB>  <TAB> newrecipe = oldrecipe <TAB> return os.path.join(path, newrecipe),if oldrecipe != newrecipe :,154",FALSE,"if', ' old', 'rec', 'ipe', ' !=', ' new', 'rec', 'ipe', ' :',","if', ' os', 'rec', 'ipe', ' .', ' new', 'rec', 'ipe', ' :',",0,0
"def profiling_startup(): <TAB> if ""--profile-sverchok-startup"" in sys.argv: <TAB>  <TAB> global _profile_nesting <TAB>  <TAB> profile = None <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> profile = get_global_profile() <TAB>  <TAB>  <TAB> _profile_nesting += 1 <MASK> profile.enable() <TAB>  <TAB>  <TAB> yield profile <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> _profile_nesting -= 1 <TAB>  <TAB>  <TAB> if _profile_nesting == 0 and profile is not None: <TAB>  <TAB>  <TAB>  <TAB> profile.disable() <TAB>  <TAB>  <TAB> dump_stats(file_path=""sverchok_profile.txt"") <TAB>  <TAB>  <TAB> save_stats(""sverchok_profile.prof"") <TAB> else: <TAB>  <TAB> yield None,if _profile_nesting == 1 :,180",FALSE,"if', ' _', 'profile', '_', 'n', 'esting', ' ==', ' 1', ' :']","if', ' _', 'profile', '_', 'n', 'esting', ' ==', ' 0', ' and']",0,0