"def __init__(self, scale, factor, mode): <TAB> self.index = 0 <TAB> self.scale = scale <TAB> if factor is None: <TAB>  <TAB> self._log_factor = None <TAB> else: <MASK> raise ValueError(""'factor' must be >= 1.0"") <TAB>  <TAB> self._log_factor = np.log(factor) <TAB> if mode not in self.allowed_modes: <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> (""'{0}' is not a recognized mode. "" ""Please select from: {1}"").format( <TAB>  <TAB>  <TAB>  <TAB> mode, self.allowed_modes <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB> self.mode = mode",if factor < 1.0 :,160
"def get_grab_keys(self): <TAB> keystr = None <TAB> try: <TAB>  <TAB> keys = self.display.get_grab_keys() <TAB>  <TAB> for k in keys: <MASK> keystr = gtk.gdk.keyval_name(k) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> keystr = keystr + ""+"" + gtk.gdk.keyval_name(k) <TAB> except: <TAB>  <TAB> pass <TAB> return keystr",if keystr is None :,115
"def _checkAllExamples(self, num_type): <TAB> for region_code in phonenumberutil.SUPPORTED_REGIONS: <TAB>  <TAB> numobj_py = phonenumberutil.example_number_for_type(region_code, num_type) <MASK> numobj_pb = PyToPB(numobj_py) <TAB>  <TAB>  <TAB> alt_py = PBToPy(numobj_pb) <TAB>  <TAB>  <TAB> self.assertEqual(numobj_py, alt_py)",if numobj_py is not None :,127
"def _gaf10iterator(handle): <TAB> for inline in handle: <TAB>  <TAB> if inline[0] == ""!"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> inrec = inline.rstrip(""\n"").split(""\t"") <MASK> continue <TAB>  <TAB> inrec[3] = inrec[3].split(""|"")  # Qualifier <TAB>  <TAB> inrec[5] = inrec[5].split(""|"")  # DB:reference(s) <TAB>  <TAB> inrec[7] = inrec[7].split(""|"")  # With || From <TAB>  <TAB> inrec[10] = inrec[10].split(""|"")  # Synonym <TAB>  <TAB> inrec[12] = inrec[12].split(""|"")  # Taxon <TAB>  <TAB> yield dict(zip(GAF10FIELDS, inrec))",if len ( inrec ) == 1 :,188
"def __xor__(self, other): <TAB> inc, exc = _norm_args_notimplemented(other) <TAB> if inc is NotImplemented: <TAB>  <TAB> return NotImplemented <TAB> if inc is NotImplemented: <TAB>  <TAB> return NotImplemented <TAB> if self._included is None: <MASK> # - + <TAB>  <TAB>  <TAB> return _ComplementSet(excluded=self._excluded - inc) <TAB>  <TAB> else:  # - - <TAB>  <TAB>  <TAB> return _ComplementSet(included=self._excluded.symmetric_difference(exc)) <TAB> else: <TAB>  <TAB> if inc is None:  # + - <TAB>  <TAB>  <TAB> return _ComplementSet(excluded=exc - self._included) <TAB>  <TAB> else:  # + + <TAB>  <TAB>  <TAB> return _ComplementSet(included=self._included.symmetric_difference(inc))",if exc is None :,183
"def connection(self, commit_on_success=False): <TAB> with self._lock: <TAB>  <TAB> if self._bulk_commit: <TAB>  <TAB>  <TAB> if self._pending_connection is None: <TAB>  <TAB>  <TAB>  <TAB> self._pending_connection = sqlite.connect(self.filename) <TAB>  <TAB>  <TAB> con = self._pending_connection <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> con = sqlite.connect(self.filename) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if self.fast_save: <TAB>  <TAB>  <TAB>  <TAB> con.execute(""PRAGMA synchronous = 0;"") <TAB>  <TAB>  <TAB> yield con <TAB>  <TAB>  <TAB> if commit_on_success and self.can_commit: <TAB>  <TAB>  <TAB>  <TAB> con.commit() <TAB>  <TAB> finally: <MASK> con.close()",if not self . _bulk_commit :,182
"def renderable_events(self, date, hour): <TAB> ""Returns the number of renderable events"" <TAB> renderable_events = [] <TAB> for event in self.events: <TAB>  <TAB> if event.covers(date, hour): <TAB>  <TAB>  <TAB> renderable_events.append(event) <TAB> if hour: <TAB>  <TAB> for current in renderable_events: <TAB>  <TAB>  <TAB> for event in self.events: <MASK> for hour in range(self.start_hour, self.end_hour): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if current.covers(date, hour) and event.covers(date, hour): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> renderable_events.append(event) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return renderable_events",if event not in renderable_events :,191
"def _prepare_cooldowns(self, ctx): <TAB> if self._buckets.valid: <TAB>  <TAB> dt = ctx.message.edited_at or ctx.message.created_at <TAB>  <TAB> current = dt.replace(tzinfo=datetime.timezone.utc).timestamp() <TAB>  <TAB> bucket = self._buckets.get_bucket(ctx.message, current) <TAB>  <TAB> retry_after = bucket.update_rate_limit(current) <MASK> raise CommandOnCooldown(bucket, retry_after)",if retry_after :,122
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_module(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> self.set_version(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 24: <TAB>  <TAB>  <TAB> self.set_instances(d.getVarInt64()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 18 :,150
"def n_import_from(self, node): <TAB> relative_path_index = 0 <TAB> if self.version >= 2.5: <TAB>  <TAB> if node[relative_path_index].pattr > 0: <TAB>  <TAB>  <TAB> node[2].pattr = (""."" * node[relative_path_index].pattr) + node[2].pattr <MASK> if isinstance(node[1].pattr, tuple): <TAB>  <TAB>  <TAB>  <TAB> imports = node[1].pattr <TAB>  <TAB>  <TAB>  <TAB> for pattr in imports: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> node[1].pattr = pattr <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.default(node) <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> pass <TAB> self.default(node)",if self . version > 2.7 :,170
def logic(): <TAB> while 1: <TAB>  <TAB> yield a <TAB>  <TAB> var = 0 <TAB>  <TAB> for i in downrange(len(a)): <MASK> var += 1 <TAB>  <TAB> out.next = var,if a [ i ] == 1 :,61
"def _extract_networks(self, server_node): <TAB> """"""Marshal the networks attribute of a parsed request"""""" <TAB> node = self.find_first_child_named(server_node, ""networks"") <TAB> if node is not None: <TAB>  <TAB> networks = [] <TAB>  <TAB> for network_node in self.find_children_named(node, ""network""): <TAB>  <TAB>  <TAB> item = {} <MASK> item[""uuid""] = network_node.getAttribute(""uuid"") <TAB>  <TAB>  <TAB> if network_node.hasAttribute(""fixed_ip""): <TAB>  <TAB>  <TAB>  <TAB> item[""fixed_ip""] = network_node.getAttribute(""fixed_ip"") <TAB>  <TAB>  <TAB> networks.append(item) <TAB>  <TAB> return networks <TAB> else: <TAB>  <TAB> return None","if network_node . hasAttribute ( ""uuid"" ) :",186
"def _model_shorthand(self, args): <TAB> accum = [] <TAB> for arg in args: <TAB>  <TAB> if isinstance(arg, Node): <TAB>  <TAB>  <TAB> accum.append(arg) <MASK> accum.append(arg) <TAB>  <TAB> elif isinstance(arg, ModelAlias): <TAB>  <TAB>  <TAB> accum.extend(arg.get_proxy_fields()) <TAB>  <TAB> elif isclass(arg) and issubclass(arg, Model): <TAB>  <TAB>  <TAB> accum.extend(arg._meta.declared_fields) <TAB> return accum","elif isinstance ( arg , Query ) :",125
"def on_show_comment(self, widget, another): <TAB> if widget.get_active(): <MASK> self.treeview.update_items(all=True, comment=True) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.treeview.update_items(comment=True) <TAB> else: <TAB>  <TAB> if another.get_active(): <TAB>  <TAB>  <TAB> self.treeview.update_items(all=True) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.treeview.update_items()",if another . get_active ( ) :,121
"def test_select_figure_formats_set(): <TAB> ip = get_ipython() <TAB> for fmts in [ <TAB>  <TAB> {""png"", ""svg""}, <TAB>  <TAB> [""png""], <TAB>  <TAB> (""jpeg"", ""pdf"", ""retina""), <TAB>  <TAB> {""svg""}, <TAB> ]: <TAB>  <TAB> active_mimes = {_fmt_mime_map[fmt] for fmt in fmts} <TAB>  <TAB> pt.select_figure_formats(ip, fmts) <TAB>  <TAB> for mime, f in ip.display_formatter.formatters.items(): <MASK> nt.assert_in(Figure, f) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> nt.assert_not_in(Figure, f)",if mime in active_mimes :,170
"def update_from_data(self, data): <TAB> super(HelpParameter, self).update_from_data(data) <TAB> # original help.py value_sources are strings, update command strings to value-source dict <TAB> if self.value_sources: <TAB>  <TAB> self.value_sources = [ <TAB>  <TAB>  <TAB> str_or_dict <MASK> else {""link"": {""command"": str_or_dict}} <TAB>  <TAB>  <TAB> for str_or_dict in self.value_sources <TAB>  <TAB> ]","if isinstance ( str_or_dict , dict )",130
def _reset_library_root_logger() -> None: <TAB> global _default_handler <TAB> with _lock: <MASK> return <TAB>  <TAB> library_root_logger = _get_library_root_logger() <TAB>  <TAB> library_root_logger.removeHandler(_default_handler) <TAB>  <TAB> library_root_logger.setLevel(logging.NOTSET) <TAB>  <TAB> _default_handler = None,if not _default_handler :,99
"def extract_headers(headers): <TAB> """"""This function extracts valid headers from interactive input."""""" <TAB> sorted_headers = {} <TAB> matches = re.findall(r""(.*):\s(.*)"", headers) <TAB> for match in matches: <TAB>  <TAB> header = match[0] <TAB>  <TAB> value = match[1] <TAB>  <TAB> try: <MASK> value = value[:-1] <TAB>  <TAB>  <TAB> sorted_headers[header] = value <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB> pass <TAB> return sorted_headers","if value [ - 1 ] == "","" :",125
"def _call_user_data_handler(self, operation, src, dst): <TAB> if hasattr(self, ""_user_data""): <TAB>  <TAB> for key, (data, handler) in self._user_data.items(): <MASK> handler.handle(operation, key, data, src, dst)",if handler is not None :,80
"def update(self, other=None, **kwargs): <TAB> if other is not None: <MASK> other = other.items() <TAB>  <TAB> for key, value in other: <TAB>  <TAB>  <TAB> if key in kwargs: <TAB>  <TAB>  <TAB>  <TAB> raise TensorforceError.value( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> name=""NestedDict.update"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> argument=""key"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value=key, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> condition=""specified twice"", <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self[key] = value <TAB> for key, value in kwargs.items(): <TAB>  <TAB> self[key] = value","if hasattr ( other , ""items"" ) :",153
"def _restore_context(context): <TAB> # Check for changes in contextvars, and set them to the current <TAB> # context for downstream consumers <TAB> for cvar in context: <TAB>  <TAB> try: <MASK> cvar.set(context.get(cvar)) <TAB>  <TAB> except LookupError: <TAB>  <TAB>  <TAB> cvar.set(context.get(cvar))",if cvar . get ( ) != context . get ( cvar ) :,103
"def __str__(self): <TAB> s = ""{"" <TAB> sep = """" <TAB> for k, v in self.iteritems(): <TAB>  <TAB> s += sep <MASK> s += ""'%s'"" % k <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> s += str(k) <TAB>  <TAB> s += "": "" <TAB>  <TAB> if type(v) == str: <TAB>  <TAB>  <TAB> s += ""'%s'"" % v <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> s += str(v) <TAB>  <TAB> sep = "", "" <TAB> s += ""}"" <TAB> return s",if type ( k ) == str :,131
"def read_file_or_url(self, fname): <TAB> # TODO: not working on localhost <TAB> if isinstance(fname, file): <TAB>  <TAB> result = open(fname, ""r"") <TAB> else: <TAB>  <TAB> match = self.urlre.match(fname) <MASK> result = urllib.urlopen(match.group(1)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> fname = os.path.expanduser(fname) <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> result = open(os.path.expanduser(fname), ""r"") <TAB>  <TAB>  <TAB> except IOError: <TAB>  <TAB>  <TAB>  <TAB> result = open( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""%s.%s"" % (os.path.expanduser(fname), self.defaultExtension), ""r"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return result",if match :,184
"def subclass_managers(self, recursive): <TAB> for cls in self.class_.__subclasses__(): <TAB>  <TAB> mgr = manager_of_class(cls) <MASK> yield mgr <TAB>  <TAB>  <TAB> if recursive: <TAB>  <TAB>  <TAB>  <TAB> for m in mgr.subclass_managers(True): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield m",if mgr is not None and mgr is not self :,89
"def star_path(path): <TAB> """"""Replace integers and integer-strings in a path with *"""""" <TAB> path = list(path) <TAB> for i, p in enumerate(path): <TAB>  <TAB> if isinstance(p, int): <TAB>  <TAB>  <TAB> path[i] = ""*"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if not isinstance(p, text_type): <TAB>  <TAB>  <TAB>  <TAB> p = p.decode() <MASK> path[i] = ""*"" <TAB> return join_path(path)",if r_is_int . match ( p ) :,127
"def cookie_decode(data, key): <TAB> """"""Verify and decode an encoded string. Return an object or None"""""" <TAB> if isinstance(data, unicode): <TAB>  <TAB> data = data.encode(""ascii"")  # 2to3 hack <TAB> if cookie_is_encoded(data): <TAB>  <TAB> sig, msg = data.split(u""?"".encode(""ascii""), 1)  # 2to3 hack <MASK> return pickle.loads(base64.b64decode(msg)) <TAB> return None","if sig [ 1 : ] == base64 . b64encode ( hmac . new ( key , msg ) . digest ( ) ) :",137
"def parse_row(cls, doc_row): <TAB> row = {} <TAB> for field_name, field in FIELD_MAP.items(): <TAB>  <TAB> if len(doc_row) > field[1]: <TAB>  <TAB>  <TAB> field_value = doc_row[field[1]] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> field_value = """" <MASK> field_value = field[2](field_value) <TAB>  <TAB> row[field_name] = field_value <TAB> return row",if len ( field ) >= 3 and callable ( field [ 2 ] ) :,127
"def semantic_masks(self): <TAB> for sid in self._seg_ids: <TAB>  <TAB> sinfo = self._sinfo.get(sid) <MASK> # Some pixels (e.g. id 0 in PanopticFPN) have no instance or semantic predictions. <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> yield (self._seg == sid).numpy().astype(np.bool), sinfo","if sinfo is None or sinfo [ ""isthing"" ] :",104
"def top_level_subjects(self): <TAB> if self.subjects.exists(): <TAB>  <TAB> return optimize_subject_query(self.subjects.filter(parent__isnull=True)) <TAB> else: <TAB>  <TAB> # TODO: Delet this when all PreprintProviders have a mapping <MASK> return optimize_subject_query( <TAB>  <TAB>  <TAB>  <TAB> Subject.objects.filter(parent__isnull=True, provider___id=""osf"") <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> tops = set([sub[0][0] for sub in self.subjects_acceptable]) <TAB>  <TAB> return [Subject.load(sub) for sub in tops]",if len ( self . subjects_acceptable ) == 0 :,157
"def resolve(obj): <TAB> if isinstance(obj, list): <TAB>  <TAB> for item in obj: <TAB>  <TAB>  <TAB> resolve(item) <TAB>  <TAB> return <TAB> if isinstance(obj, dict): <MASK> with resolver.resolving(obj[u""$ref""]) as resolved: <TAB>  <TAB>  <TAB>  <TAB> resolve(resolved) <TAB>  <TAB>  <TAB>  <TAB> obj.clear() <TAB>  <TAB>  <TAB>  <TAB> obj.update(resolved) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for value in obj.values(): <TAB>  <TAB>  <TAB>  <TAB> resolve(value)","if ""$ref"" in obj :",127
"def read_ansible_config(project_path, variables_of_interest): <TAB> fnames = [""/etc/ansible/ansible.cfg""] <TAB> if project_path: <TAB>  <TAB> fnames.append(os.path.join(project_path, ""ansible.cfg"")) <TAB> values = {} <TAB> try: <TAB>  <TAB> parser = ConfigParser() <TAB>  <TAB> parser.read(fnames) <TAB>  <TAB> if ""defaults"" in parser: <TAB>  <TAB>  <TAB> for var in variables_of_interest: <MASK> values[var] = parser[""defaults""][var] <TAB> except Exception: <TAB>  <TAB> logger.exception(""Failed to read ansible configuration(s) {}"".format(fnames)) <TAB> return values","if var in parser [ ""defaults"" ] :",166
"def test_globalphase(): <TAB> rule_set = DecompositionRuleSet(modules=[globalphase, r2rzandph]) <TAB> dummy = DummyEngine(save_commands=True) <TAB> eng = MainEngine( <TAB>  <TAB> dummy, <TAB>  <TAB> [AutoReplacer(rule_set), InstructionFilter(low_level_gates_noglobalphase)], <TAB> ) <TAB> qubit = eng.allocate_qubit() <TAB> R(1.2) | qubit <TAB> rz_count = 0 <TAB> for cmd in dummy.received_commands: <TAB>  <TAB> assert not isinstance(cmd.gate, R) <MASK> rz_count += 1 <TAB>  <TAB>  <TAB> assert cmd.gate == Rz(1.2) <TAB> assert rz_count == 1","if isinstance ( cmd . gate , Rz ) :",188
def _kill_current_player(self): <TAB> if self._current_player: <MASK> self.voice_client.resume() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.voice_client.stop() <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> self._current_player = None <TAB>  <TAB> return True <TAB> return False,if self . voice_client . is_paused ( ) :,93
"def hasAmbiguousLanguage(self, p): <TAB> """"""Return True if p.b contains different @language directives."""""" <TAB> # c = self <TAB> languages, tag = set(), ""@language"" <TAB> for s in g.splitLines(p.b): <MASK> i = g.skip_ws(s, len(tag)) <TAB>  <TAB>  <TAB> j = g.skip_id(s, i) <TAB>  <TAB>  <TAB> word = s[i:j] <TAB>  <TAB>  <TAB> languages.add(word) <TAB> return len(list(languages)) > 1","if g . match_word ( s , 0 , tag ) :",140
"def terminate(self): <TAB> n_retries = 10 <TAB> for i in range(n_retries): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> super(MemmappingPool, self).terminate() <TAB>  <TAB>  <TAB> break <TAB>  <TAB> except OSError as e: <TAB>  <TAB>  <TAB> if isinstance(e, WindowsError): <TAB>  <TAB>  <TAB>  <TAB> # Workaround  occasional ""[Error 5] Access is denied"" issue <TAB>  <TAB>  <TAB>  <TAB> # when trying to terminate a process under windows. <TAB>  <TAB>  <TAB>  <TAB> sleep(0.1) <MASK> warnings.warn( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Failed to terminate worker processes in"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> "" multiprocessing pool: %r"" % e <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> self._temp_folder_manager._unlink_temporary_resources()",if i + 1 == n_retries :,192
"def test_downsampling(self, method, maybe_range, fraction, expected_n_reads): <TAB> reader = sam.SamReader( <TAB>  <TAB> test_utils.genomics_core_testdata(""test.bam""), <TAB>  <TAB> downsample_fraction=fraction, <TAB>  <TAB> random_seed=12345, <TAB> ) <TAB> with reader: <MASK> reads_iter = reader.iterate() <TAB>  <TAB> elif method == ""query"": <TAB>  <TAB>  <TAB> reads_iter = reader.query(ranges.parse_literal(maybe_range)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.fail(""Unexpected method "" + str(method)) <TAB>  <TAB> self.assertEqual(test_utils.iterable_len(reads_iter), expected_n_reads)","if method == ""iterate"" :",177
"def verify_acceptable(self): <TAB> start = time.time() <TAB> while True: <MASK> return <TAB>  <TAB> elif (time.time() - start) > READ_TIMEOUT: <TAB>  <TAB>  <TAB> raise Exception(""Server socket did not accept in time"") <TAB>  <TAB> time.sleep(0.1)",if self . select_acceptable ( ) :,79
"def replica_local_creator(next_creator, **kwargs) -> tf.Variable: <TAB> """"""Variable creator that by default creates replica local variables."""""" <TAB> if kwargs[""synchronization""] == tf.VariableSynchronization.AUTO: <TAB>  <TAB> kwargs[""synchronization""] = tf.VariableSynchronization.ON_READ <MASK> kwargs[""aggregation""] = tf.VariableAggregation.ONLY_FIRST_REPLICA <TAB>  <TAB> if kwargs[""trainable""] is None: <TAB>  <TAB>  <TAB> kwargs[""trainable""] = True <TAB> return next_creator(**kwargs)","if kwargs [ ""aggregation"" ] == tf . VariableAggregation . NONE :",144
"def get_optional_nargs(self, name): <TAB> for n, kwargs in self.conf[""optional_args""]: <TAB>  <TAB> if name == n: <MASK> action = kwargs[""action""] <TAB>  <TAB>  <TAB>  <TAB> if action in (""store_true"", ""store_false""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return 0 <TAB>  <TAB>  <TAB> break <TAB> return 1","if ""action"" in kwargs :",92
"def ageToDays(self, age_str): <TAB> age = 0 <TAB> age_str = age_str.replace(""&nbsp;"", "" "") <TAB> regex = ""(\d*.?\d+).(sec|hour|day|week|month|year)+"" <TAB> matches = re.findall(regex, age_str) <TAB> for match in matches: <TAB>  <TAB> nr, size = match <TAB>  <TAB> mult = 1 <TAB>  <TAB> if size == ""week"": <TAB>  <TAB>  <TAB> mult = 7 <TAB>  <TAB> elif size == ""month"": <TAB>  <TAB>  <TAB> mult = 30.5 <MASK> mult = 365 <TAB>  <TAB> age += tryInt(nr) * mult <TAB> return tryInt(age)","elif size == ""year"" :",163
"def put(self, userId, bucket, key, data): <TAB> if not self.initialized: <TAB>  <TAB> raise Exception(""archive not initialized"") <TAB> try: <TAB>  <TAB> uri = self.uri_for(userId, bucket, key) <MASK> raise Exception(""Failed writing file content to disk: {}"".format(uri)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return uri <TAB> except Exception as err: <TAB>  <TAB> logger.debug(""cannot put data: exception - "" + str(err)) <TAB>  <TAB> raise err","if not self . _save_content ( uri , data ) :",131
"def get_range(min, max): <TAB> if max < min: <TAB>  <TAB> min, max = max, min <TAB> elif min == max: <TAB>  <TAB> if min < 0: <TAB>  <TAB>  <TAB> min, max = 2 * min, 0 <MASK> min, max = 0, 2 * min <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> min, max = -1, 1 <TAB> return min, max",elif min > 0 :,99
"def update_job_weights(): <TAB> """"""Update job weights."""""" <TAB> for job in data_types.Job.query(): <TAB>  <TAB> multiplier = DEFAULT_MULTIPLIER <TAB>  <TAB> if environment.is_engine_fuzzer_job(job.name): <TAB>  <TAB>  <TAB> targets_count = ndb.Key(data_types.FuzzTargetsCount, job.name).get() <TAB>  <TAB>  <TAB> # If the count is 0, it may be due to a bad build or some other issue. Use <TAB>  <TAB>  <TAB> # the default weight in that case to allow for recovery. <TAB>  <TAB>  <TAB> if targets_count and targets_count.count: <TAB>  <TAB>  <TAB>  <TAB> multiplier = targets_count.count <MASK> multiplier = TARGET_COUNT_WEIGHT_CAP <TAB>  <TAB> update_job_weight(job.name, multiplier)",if multiplier > TARGET_COUNT_WEIGHT_CAP :,199
"def _validate_required_settings( <TAB> self, application_id, application_config, required_settings, should_throw=True): <TAB> """"""All required keys must be present"""""" <TAB> for setting_key in required_settings: <TAB>  <TAB> if setting_key not in application_config.keys(): <MASK> raise ImproperlyConfigured( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> MISSING_SETTING.format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> application_id=application_id, setting=setting_key <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return True",if should_throw :,146
"def nested_update(org_dict, upd_dict): <TAB> for key, value in upd_dict.items(): <TAB>  <TAB> if isinstance(value, dict): <MASK> if not isinstance(org_dict[key], dict): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Mismatch between org_dict and upd_dict at node {}"".format(key) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> nested_update(org_dict[key], value) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> org_dict[key] = value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> org_dict[key] = value",if key in org_dict :,161
"def eintr_retry_call(func, *args, **kwargs): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return func(*args, **kwargs) <TAB>  <TAB> except EnvironmentError as e: <MASK> continue <TAB>  <TAB>  <TAB> raise","if getattr ( e , ""errno"" , None ) == errno . EINTR :",79
"def __init__(self, entity): <TAB> self._entity = weakref.proxy(entity) <TAB> self._observables = collections.OrderedDict() <TAB> self._keys_helper = _ObservableKeys(self._entity, self._observables) <TAB> # Ensure consistent ordering. <TAB> for attr_name in sorted(dir(type(self))): <TAB>  <TAB> type_attr = getattr(type(self), attr_name) <MASK> self._observables[attr_name] = getattr(self, attr_name)","if isinstance ( type_attr , define . observable ) :",131
"def check_redundancy(self): <TAB> # Ensure there are no adjacent blocks (they should have been merged) <TAB> starts, sizes = self.allocator.get_allocated_regions() <TAB> last = -1 <TAB> for start, size in zip(starts, sizes): <TAB>  <TAB> if start < last: <TAB>  <TAB>  <TAB> raise Exception(""Block at %d is out of order"" % start) <MASK> raise Exception(""Block at %d is redundant"" % start) <TAB>  <TAB> last = start + size",if start == last :,122
"def elfheader(): <TAB> local_path = pwndbg.file.get_file(pwndbg.proc.exe) <TAB> with open(local_path, ""rb"") as f: <TAB>  <TAB> elffile = ELFFile(f) <TAB>  <TAB> sections = [] <TAB>  <TAB> for section in elffile.iter_sections(): <TAB>  <TAB>  <TAB> start = section[""sh_addr""] <TAB>  <TAB>  <TAB> # Don't print sections that aren't mapped into memory <MASK> continue <TAB>  <TAB>  <TAB> size = section[""sh_size""] <TAB>  <TAB>  <TAB> sections.append((start, start + size, section.name)) <TAB>  <TAB> sections.sort() <TAB>  <TAB> for start, end, name in sections: <TAB>  <TAB>  <TAB> print(""%#x - %#x "" % (start, end), name)",if start == 0 :,189
"def orbit(): <TAB> """"""Define the internal thread for running the orbit."""""" <TAB> for point in points: <TAB>  <TAB> self.set_position(point) <TAB>  <TAB> self.set_focus(focus) <TAB>  <TAB> self.set_viewup(viewup) <TAB>  <TAB> self.renderer.ResetCameraClippingRange() <TAB>  <TAB> self.render() <TAB>  <TAB> time.sleep(step) <MASK> self.write_frame()",if write_frames :,107
"def json_format(self): <TAB> """"""Returns the integer value formatted as a JSON literal"""""" <TAB> fmt = self._jsonfmt <TAB> if fmt == NUMBER_FORMAT_HEX: <TAB>  <TAB> return format(self, ""#x"") <TAB> elif fmt == NUMBER_FORMAT_OCTAL: <TAB>  <TAB> return format(self, ""#o"") <TAB> elif fmt == NUMBER_FORMAT_BINARY: <TAB>  <TAB> return format(self, ""#b"") <TAB> elif fmt == NUMBER_FORMAT_LEGACYOCTAL: <TAB>  <TAB> if self == 0: <TAB>  <TAB>  <TAB> return ""0""  # For some reason Python's int doesn't do '00' <MASK> return ""-0%o"" % (-self) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""0%o"" % self <TAB> else: <TAB>  <TAB> return str(self)",elif self < 0 :,189
"def parseTime(timeStr): <TAB> regex = re.compile(constants.PARSE_TIME_REGEX) <TAB> parts = regex.match(timeStr) <TAB> if not parts: <TAB>  <TAB> return <TAB> parts = parts.groupdict() <TAB> time_params = {} <TAB> for (name, param) in parts.items(): <MASK> if name == ""miliseconds"": <TAB>  <TAB>  <TAB>  <TAB> time_params[""microseconds""] = int(param) * 1000 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> time_params[name] = int(param) <TAB> return datetime.timedelta(**time_params).total_seconds()",if param :,146
"def build_extension(self, ext): <TAB> ext._convert_pyx_sources_to_lang() <TAB> _compiler = self.compiler <TAB> try: <TAB>  <TAB> if isinstance(ext, Library): <TAB>  <TAB>  <TAB> self.compiler = self.shlib_compiler <TAB>  <TAB> _build_ext.build_extension(self, ext) <MASK> cmd = self.get_finalized_command(""build_py"").build_lib <TAB>  <TAB>  <TAB> self.write_stub(cmd, ext) <TAB> finally: <TAB>  <TAB> self.compiler = _compiler",if ext . _needs_stub :,134
"def __init__(self, type, data, name=None): <TAB> Constant.__init__(self, type, data, name) <TAB> self.tag.unique_value = None <TAB> if isinstance(data, np.ndarray) and data.ndim > 0: <TAB>  <TAB> flat_data = data.ravel() <MASK> if (flat_data == flat_data[0]).all(): <TAB>  <TAB>  <TAB>  <TAB> self.tag.unique_value = flat_data[0]",if flat_data . shape [ 0 ] :,118
"def _find_machine(deb_arch): <TAB> for machine in _ARCH_TRANSLATIONS: <TAB>  <TAB> if _ARCH_TRANSLATIONS[machine].get(""deb"", """") == deb_arch: <TAB>  <TAB>  <TAB> return machine <MASK> return machine <TAB> raise errors.SnapcraftEnvironmentError( <TAB>  <TAB> ""Cannot set machine from deb_arch {!r}"".format(deb_arch) <TAB> )","elif _ARCH_TRANSLATIONS [ machine ] . get ( ""uts_machine"" , """" ) == deb_arch :",124
"def fields_for_form(form, only_fields, exclude_fields): <TAB> fields = OrderedDict() <TAB> for name, field in form.fields.items(): <TAB>  <TAB> is_not_in_only = only_fields and name not in only_fields <TAB>  <TAB> is_excluded = ( <TAB>  <TAB>  <TAB> name <TAB>  <TAB>  <TAB> in exclude_fields  # or <TAB>  <TAB>  <TAB> # name in already_created_fields <TAB>  <TAB> ) <MASK> continue <TAB>  <TAB> fields[name] = convert_form_field(field) <TAB> return fields",if is_not_in_only or is_excluded :,139
"def wait_services_ready(selectors, min_counts, count_fun, timeout=None): <TAB> readies = [0] * len(selectors) <TAB> start_time = time.time() <TAB> while True: <TAB>  <TAB> all_satisfy = True <TAB>  <TAB> for idx, selector in enumerate(selectors): <TAB>  <TAB>  <TAB> if readies[idx] < min_counts[idx]: <TAB>  <TAB>  <TAB>  <TAB> all_satisfy = False <TAB>  <TAB>  <TAB>  <TAB> readies[idx] = count_fun(selector) <TAB>  <TAB>  <TAB>  <TAB> break <MASK> break <TAB>  <TAB> if timeout and timeout + start_time < time.time(): <TAB>  <TAB>  <TAB> raise TimeoutError(""Wait cluster start timeout"") <TAB>  <TAB> time.sleep(1)",if all_satisfy :,167
def count_brokers(self): <TAB> self.nb_brokers = 0 <TAB> for broker in self.brokers: <MASK> self.nb_brokers += 1 <TAB> for realm in self.higher_realms: <TAB>  <TAB> for broker in realm.brokers: <TAB>  <TAB>  <TAB> if not broker.spare and broker.manage_sub_realms: <TAB>  <TAB>  <TAB>  <TAB> self.nb_brokers += 1,if not broker . spare :,118
"def _adapt_polymorphic_element(self, element): <TAB> if ""parententity"" in element._annotations: <TAB>  <TAB> search = element._annotations[""parententity""] <TAB>  <TAB> alias = self._polymorphic_adapters.get(search, None) <MASK> return alias.adapt_clause(element) <TAB> if isinstance(element, expression.FromClause): <TAB>  <TAB> search = element <TAB> elif hasattr(element, ""table""): <TAB>  <TAB> search = element.table <TAB> else: <TAB>  <TAB> return None <TAB> alias = self._polymorphic_adapters.get(search, None) <TAB> if alias: <TAB>  <TAB> return alias.adapt_clause(element)",if alias :,157
"def get_all_methods(): <TAB> estimators = all_estimators() <TAB> for name, Estimator in estimators: <TAB>  <TAB> if name.startswith(""_""): <TAB>  <TAB>  <TAB> # skip private classes <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> methods = [] <TAB>  <TAB> for name in dir(Estimator): <TAB>  <TAB>  <TAB> if name.startswith(""_""): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> method_obj = getattr(Estimator, name) <MASK> methods.append(name) <TAB>  <TAB> methods.append(None) <TAB>  <TAB> for method in sorted(methods, key=lambda x: str(x)): <TAB>  <TAB>  <TAB> yield Estimator, method","if hasattr ( method_obj , ""__call__"" ) or isinstance ( method_obj , property ) :",161
"def __call__(self, es, params): <TAB> ops = 0 <TAB> indices = mandatory(params, ""indices"", self) <TAB> only_if_exists = params.get(""only-if-exists"", False) <TAB> request_params = params.get(""request-params"", {}) <TAB> for index_name in indices: <TAB>  <TAB> if not only_if_exists: <TAB>  <TAB>  <TAB> es.indices.delete(index=index_name, params=request_params) <TAB>  <TAB>  <TAB> ops += 1 <MASK> self.logger.info(""Index [%s] already exists. Deleting it."", index_name) <TAB>  <TAB>  <TAB> es.indices.delete(index=index_name, params=request_params) <TAB>  <TAB>  <TAB> ops += 1 <TAB> return ops, ""ops""",elif only_if_exists and es . indices . exists ( index = index_name ) :,198
"def get(): <TAB> result = [] <TAB> for b in self.key_bindings: <MASK> match = True <TAB>  <TAB>  <TAB> for i, j in zip(b.keys, keys): <TAB>  <TAB>  <TAB>  <TAB> if i != j and i != Keys.Any: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> match = False <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> if match: <TAB>  <TAB>  <TAB>  <TAB> result.append(b) <TAB> return result",if len ( keys ) < len ( b . keys ) :,113
"def get_arg_list_scalar_arg_dtypes(arg_types): <TAB> result = [] <TAB> for arg_type in arg_types: <MASK> result.append(arg_type.dtype) <TAB>  <TAB> elif isinstance(arg_type, VectorArg): <TAB>  <TAB>  <TAB> result.append(None) <TAB>  <TAB>  <TAB> if arg_type.with_offset: <TAB>  <TAB>  <TAB>  <TAB> result.append(np.int64) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise RuntimeError(""arg type not understood: %s"" % type(arg_type)) <TAB> return result","if isinstance ( arg_type , ScalarArg ) :",142
"def autocommitter(): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if not self._running: <TAB>  <TAB>  <TAB>  <TAB> break <MASK> self._auto_commit() <TAB>  <TAB>  <TAB> self._cluster.handler.sleep(self._auto_commit_interval_ms / 1000) <TAB>  <TAB> except ReferenceError: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> # surface all exceptions to the main thread <TAB>  <TAB>  <TAB> self._worker_exception = sys.exc_info() <TAB>  <TAB>  <TAB> break <TAB> log.debug(""Autocommitter thread exiting"")",if self . _auto_commit_enable :,141
"def on_conflict(self, *target_fields: Union[str, Term]) -> ""PostgreSQLQueryBuilder"": <TAB> if not self._insert_table: <TAB>  <TAB> raise QueryException(""On conflict only applies to insert query"") <TAB> self._on_conflict = True <TAB> for target_field in target_fields: <MASK> self._on_conflict_fields.append(self._conflict_field_str(target_field)) <TAB>  <TAB> elif isinstance(target_field, Term): <TAB>  <TAB>  <TAB> self._on_conflict_fields.append(target_field)","if isinstance ( target_field , str ) :",141
"def change_TV_DOWNLOAD_DIR(tv_download_dir): <TAB> if tv_download_dir == """": <TAB>  <TAB> sickbeard.TV_DOWNLOAD_DIR = """" <TAB>  <TAB> return True <TAB> if os.path.normpath(sickbeard.TV_DOWNLOAD_DIR) != os.path.normpath(tv_download_dir): <MASK> sickbeard.TV_DOWNLOAD_DIR = os.path.normpath(tv_download_dir) <TAB>  <TAB>  <TAB> logger.log(u""Changed TV download folder to "" + tv_download_dir) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> return True",if helpers . makeDir ( tv_download_dir ) :,157
"def save_config(self, cmd=""save config"", confirm=True, confirm_response=""y""): <TAB> """"""Saves Config."""""" <TAB> self.enable() <TAB> if confirm: <TAB>  <TAB> output = self.send_command_timing(command_string=cmd) <MASK> output += self.send_command_timing(confirm_response) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Send enter by default <TAB>  <TAB>  <TAB> output += self.send_command_timing(self.RETURN) <TAB> else: <TAB>  <TAB> # Some devices are slow so match on trailing-prompt if you can <TAB>  <TAB> output = self.send_command(command_string=cmd) <TAB> return output",if confirm_response :,159
"def apply_gradient_for_batch(inputs, labels, weights, loss): <TAB> with tf.GradientTape() as tape: <TAB>  <TAB> outputs = self.model(inputs, training=True) <MASK> outputs = [outputs] <TAB>  <TAB> if self._loss_outputs is not None: <TAB>  <TAB>  <TAB> outputs = [outputs[i] for i in self._loss_outputs] <TAB>  <TAB> batch_loss = loss(outputs, labels, weights) <TAB> if variables is None: <TAB>  <TAB> vars = self.model.trainable_variables <TAB> else: <TAB>  <TAB> vars = variables <TAB> grads = tape.gradient(batch_loss, vars) <TAB> self._tf_optimizer.apply_gradients(zip(grads, vars)) <TAB> self._global_step.assign_add(1) <TAB> return batch_loss","if isinstance ( outputs , tf . Tensor ) :",193
"def sort(self, items): <TAB> slow_sorts = [] <TAB> switch_slow = False <TAB> for sort in reversed(self.sorts): <MASK> slow_sorts.append(sort) <TAB>  <TAB> elif sort.order_clause() is None: <TAB>  <TAB>  <TAB> switch_slow = True <TAB>  <TAB>  <TAB> slow_sorts.append(sort) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pass <TAB> for sort in slow_sorts: <TAB>  <TAB> items = sort.sort(items) <TAB> return items",if switch_slow :,121
"def getmod(self, nm): <TAB> mod = None <TAB> for thing in self.path: <TAB>  <TAB> if isinstance(thing, basestring): <TAB>  <TAB>  <TAB> owner = self.shadowpath.get(thing, -1) <TAB>  <TAB>  <TAB> if owner == -1: <TAB>  <TAB>  <TAB>  <TAB> owner = self.shadowpath[thing] = self.__makeOwner(thing) <MASK> mod = owner.getmod(nm) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> mod = thing.getmod(nm) <TAB>  <TAB> if mod: <TAB>  <TAB>  <TAB> break <TAB> return mod",if owner :,137
"def has(self, key): <TAB> filename = self._get_filename(key) <TAB> try: <TAB>  <TAB> with open(filename, ""rb"") as f: <TAB>  <TAB>  <TAB> pickle_time = pickle.load(f) <MASK> return True <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> os.remove(filename) <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> except (IOError, OSError, pickle.PickleError): <TAB>  <TAB> return False",if pickle_time == 0 or pickle_time >= time ( ) :,117
"def forward(self, hs): <TAB> h = self.c0(hs[-1]) <TAB> for i in range(1, 8): <TAB>  <TAB> h = F.concat([h, hs[-i - 1]]) <MASK> h = self[""c%d"" % i](h) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> h = self.c7(h) <TAB> return h",if i < 7 :,96
"def get_custom_behaviour2(self): <TAB> string = """" <TAB> for arg in list(self.defaults.keys()) + self.var: <MASK> # Don't add redundant lines e.g. sus=sus; <TAB>  <TAB>  <TAB> if str(arg) != str(self.__dict__[arg]): <TAB>  <TAB>  <TAB>  <TAB> string += str(arg) + ""="" + str(self.__dict__[arg]) + "";\n"" <TAB> return string",if arg in self . __dict__ :,112
"def _apply_operation(self, values): <TAB> """"""Method that defines the less-than-or-equal operation"""""" <TAB> arg1 = next(values) <TAB> for strict in self._strict: <TAB>  <TAB> arg2 = next(values) <TAB>  <TAB> if strict: <TAB>  <TAB>  <TAB> if not (arg1 < arg2): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <MASK> return False <TAB>  <TAB> arg1 = arg2 <TAB> return True",if not ( arg1 <= arg2 ) :,118
"def i_pshufb(self, op, off=0): <TAB> dst = self.getOperValue(op, off) <TAB> src = self.getOperValue(op, off) <TAB> res = 0 <TAB> if op.opers[0].tsize == 8: <TAB>  <TAB> mask = 0x07 <TAB> else: <TAB>  <TAB> mask = 0x0F <TAB> for i in range(op.opers[0].tsize): <TAB>  <TAB> shfl = src & (1 << ((i * 8) + 7)) <MASK> s = 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> indx = (src >> (i * 8)) & mask <TAB>  <TAB>  <TAB> s = (src >> (indx * 8)) & 0xFF <TAB>  <TAB> res |= s << (i * 8) <TAB> self.setOperValue(op, 0, res)",if shfl :,199
"def report_out_of_quota(self, appid): <TAB> self.logger.warn(""report_out_of_quota:%s"", appid) <TAB> with self.lock: <MASK> self.out_of_quota_appids.append(appid) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.working_appid_list.remove(appid) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> pass",if appid not in self . out_of_quota_appids :,115
"def to_py(self, value: _StrUnset) -> _StrUnsetNone: <TAB> self._basic_py_validation(value, str) <TAB> if isinstance(value, usertypes.Unset): <TAB>  <TAB> return value <TAB> elif not value: <TAB>  <TAB> return None <TAB> value = os.path.expandvars(value) <TAB> value = os.path.expanduser(value) <TAB> try: <MASK> raise configexc.ValidationError(value, ""must be a valid directory!"") <TAB>  <TAB> if not os.path.isabs(value): <TAB>  <TAB>  <TAB> raise configexc.ValidationError(value, ""must be an absolute path!"") <TAB> except UnicodeEncodeError as e: <TAB>  <TAB> raise configexc.ValidationError(value, e) <TAB> return value",if not os . path . isdir ( value ) :,181
"def findinDoc(self, tagpath, pos, end): <TAB> result = None <TAB> if end == -1: <TAB>  <TAB> end = self.docSize <TAB> else: <TAB>  <TAB> end = min(self.docSize, end) <TAB> foundat = -1 <TAB> for j in range(pos, end): <TAB>  <TAB> item = self.docList[j] <TAB>  <TAB> if item.find(b""="") >= 0: <TAB>  <TAB>  <TAB> (name, argres) = item.split(b""="", 1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = item <TAB>  <TAB>  <TAB> argres = """" <MASK> tagpath = tagpath.encode(""utf-8"") <TAB>  <TAB> if name.endswith(tagpath): <TAB>  <TAB>  <TAB> result = argres <TAB>  <TAB>  <TAB> foundat = j <TAB>  <TAB>  <TAB> break <TAB> return foundat, result","if isinstance ( tagpath , str ) :",189
"def has_safe_repr(value): <TAB> """"""Does the node have a safe representation?"""""" <TAB> if value is None or value is NotImplemented or value is Ellipsis: <TAB>  <TAB> return True <TAB> if isinstance(value, (bool, int, long, float, complex, basestring, xrange, Markup)): <TAB>  <TAB> return True <TAB> if isinstance(value, (tuple, list, set, frozenset)): <TAB>  <TAB> for item in value: <TAB>  <TAB>  <TAB> if not has_safe_repr(item): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True <TAB> elif isinstance(value, dict): <TAB>  <TAB> for key, value in value.iteritems(): <TAB>  <TAB>  <TAB> if not has_safe_repr(key): <TAB>  <TAB>  <TAB>  <TAB> return False <MASK> return False <TAB>  <TAB> return True <TAB> return False",if not has_safe_repr ( value ) :,192
"def run(self): <TAB> # Make some objects emit lights <TAB> for obj in bpy.context.scene.objects: <MASK> obj_id = obj[""modelId""] <TAB>  <TAB>  <TAB> # In the case of the lamp <TAB>  <TAB>  <TAB> if obj_id in self.lights: <TAB>  <TAB>  <TAB>  <TAB> self._make_lamp_emissive(obj, self.lights[obj_id]) <TAB>  <TAB>  <TAB> # Make the windows emit light <TAB>  <TAB>  <TAB> if obj_id in self.windows: <TAB>  <TAB>  <TAB>  <TAB> self._make_window_emissive(obj) <TAB>  <TAB>  <TAB> # Also make ceilings slightly emit light <TAB>  <TAB>  <TAB> if obj.name.startswith(""Ceiling#""): <TAB>  <TAB>  <TAB>  <TAB> self._make_ceiling_emissive(obj)","if ""modelId"" in obj :",190
"def bitvector_case_fn( <TAB> rng: Random, mode: RandomizationMode, size: int, invalid_making_pos: int = None): <TAB> bits = get_random_ssz_object( <TAB>  <TAB> rng, <TAB>  <TAB> Bitvector[size], <TAB>  <TAB> max_bytes_length=(size + 7) // 8, <TAB>  <TAB> max_list_length=size, <TAB>  <TAB> mode=mode, <TAB>  <TAB> chaos=False, <TAB> ) <TAB> if invalid_making_pos is not None and invalid_making_pos <= size: <TAB>  <TAB> already_invalid = False <TAB>  <TAB> for i in range(invalid_making_pos, size): <MASK> already_invalid = True <TAB>  <TAB> if not already_invalid: <TAB>  <TAB>  <TAB> bits[invalid_making_pos] = True <TAB> return bits",if bits [ i ] :,196
"def get_transaction_execution_results(self, batch_signature): <TAB> with self._condition: <TAB>  <TAB> batch_status = self._batch_statuses.get(batch_signature) <TAB>  <TAB> if batch_status is None: <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> annotated_batch = self._batch_by_id.get(batch_signature) <TAB>  <TAB> if annotated_batch is None: <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> results = [] <TAB>  <TAB> for txn in annotated_batch.batch.transactions: <TAB>  <TAB>  <TAB> result = self._txn_results.get(txn.header_signature) <MASK> results.append(result) <TAB>  <TAB> return results",if result is not None :,161
"def one_xmm_reg_imm8(ii):  # also allows SSE4 2-imm8 instr <TAB> i, j, n = 0, 0, 0 <TAB> for op in _gen_opnds(ii): <TAB>  <TAB> if op_reg(op) and op_xmm(op): <TAB>  <TAB>  <TAB> n += 1 <TAB>  <TAB> elif op_imm8(op): <TAB>  <TAB>  <TAB> i += 1 <MASK> j += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> return n == 1 and i == 1 and j <= 1",elif op_imm8_2 ( op ) :,141
"def whichmodule(obj, name): <TAB> """"""Find the module an object belong to."""""" <TAB> module_name = getattr(obj, ""__module__"", None) <TAB> if module_name is not None: <TAB>  <TAB> return module_name <TAB> # Protect the iteration by using a list copy of sys.modules against dynamic <TAB> # modules that trigger imports of other modules upon calls to getattr. <TAB> for module_name, module in sys.modules.copy().items(): <TAB>  <TAB> if module_name == ""__main__"" or module is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> try: <MASK> return module_name <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB> pass <TAB> return ""__main__""","if _getattribute ( module , name ) [ 0 ] is obj :",171
"def get_ld_header_info(p): <TAB> # ""nested-function, but placed at module level <TAB> # as an ld_header was found, return known paths, archives and members <TAB> # these lines start with a digit <TAB> info = [] <TAB> for line in p.stdout: <MASK> info.append(line) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # blank line (separator), consume line and end for loop <TAB>  <TAB>  <TAB> break <TAB> return info","if re . match ( ""[0-9]"" , line ) :",120
"def write(self, s): <TAB> if self.closed: <TAB>  <TAB> raise ValueError(""write to closed file"") <TAB> if type(s) not in (unicode, str, bytearray): <TAB>  <TAB> # See issue #19481 <MASK> s = unicode.__getitem__(s, slice(None)) <TAB>  <TAB> elif isinstance(s, str): <TAB>  <TAB>  <TAB> s = str.__str__(s) <TAB>  <TAB> elif isinstance(s, bytearray): <TAB>  <TAB>  <TAB> s = bytearray.__str__(s) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError(""must be string, not "" + type(s).__name__) <TAB> return self.shell.write(s, self.tags)","if isinstance ( s , unicode ) :",161
"def generate_forwards(cls, attrs): <TAB> # forward functions of _forwards <TAB> for attr_name, attr in cls._forwards.__dict__.items(): <MASK> continue <TAB>  <TAB> if isinstance(attr, property): <TAB>  <TAB>  <TAB> cls._forward.append(attr_name) <TAB>  <TAB> elif isinstance(attr, types.FunctionType): <TAB>  <TAB>  <TAB> wrapper = _forward_factory(cls, attr_name, attr) <TAB>  <TAB>  <TAB> setattr(cls, attr_name, wrapper) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError(attr_name, type(attr))","if attr_name . startswith ( ""_"" ) or attr_name in attrs :",146
"def _user_has_dnd(bot, user_id): <TAB> try: <TAB>  <TAB> return bot.call_shared(""dnd.user_check"", user_id)  # shared dnd check <TAB> except KeyError: <TAB>  <TAB> logger.warning(""mentions: falling back to legacy _user_has_dnd()"") <TAB>  <TAB> initiator_has_dnd = False <MASK> donotdisturb = bot.memory.get(""donotdisturb"") <TAB>  <TAB>  <TAB> if user_id in donotdisturb: <TAB>  <TAB>  <TAB>  <TAB> initiator_has_dnd = True <TAB>  <TAB> return initiator_has_dnd","if bot . memory . exists ( [ ""donotdisturb"" ] ) :",162
"def init(self): <TAB> """"""Initialize a fighter from the database and validate"""""" <TAB> self.__item = None <TAB> if self.itemID: <TAB>  <TAB> self.__item = eos.db.getItem(self.itemID) <MASK> pyfalog.error(""Item (id: {0}) does not exist"", self.itemID) <TAB>  <TAB>  <TAB> return <TAB> if self.isInvalid: <TAB>  <TAB> pyfalog.error(""Item (id: {0}) is not a Fighter"", self.itemID) <TAB>  <TAB> return <TAB> self.build()",if self . __item is None :,141
"def _pg_sku_name_validator(sku_name, sku_info, tier): <TAB> if sku_name: <TAB>  <TAB> skus = get_postgres_skus(sku_info, tier) <MASK> error_msg = ( <TAB>  <TAB>  <TAB>  <TAB> ""Incorrect value for --sku-name. "" <TAB>  <TAB>  <TAB>  <TAB> + ""The SKU name does not match {} tier. Specify --tier if you did not. "".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> tier <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> raise CLIError(error_msg + ""Allowed values : {}"".format(skus))",if sku_name not in skus :,156
"def _parse_paternity_log(writer, file): <TAB> parent_map = {} <TAB> parent_map[0] = 0 <TAB> for line in file.read().decode(""utf-8"").split(""\n""): <MASK> continue <TAB>  <TAB> elems = line.split("" "")  # <Child> <Parent> <TAB>  <TAB> if len(elems) >= 2: <TAB>  <TAB>  <TAB> # <TAB>  <TAB>  <TAB>  <TAB>  <TAB>    print ""paternity of %d is %d"" % (int(elems[0]), int(elems[1])) <TAB>  <TAB>  <TAB> parent_map[int(elems[0])] = int(elems[1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""Odd paternity line '%s'"" % (line)) <TAB> return parent_map",if not line :,196
def _get_next_cap(self): <TAB> # type: () -> bool <TAB> self._curr_cap = None <TAB> if self._curr_cap_idx is None: <TAB>  <TAB> self._curr_cap_idx = 0 <TAB>  <TAB> self._curr_cap = self._cap_list[0] <TAB>  <TAB> return True <TAB> else: <MASK> self._end_of_video = True <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> self._curr_cap_idx += 1 <TAB>  <TAB> self._curr_cap = self._cap_list[self._curr_cap_idx] <TAB>  <TAB> return True,if not ( self . _curr_cap_idx + 1 ) < len ( self . _cap_list ) :,163
"def decode_payload(args): <TAB> try: <TAB>  <TAB> if args.token: <TAB>  <TAB>  <TAB> token = args.token <TAB>  <TAB> else: <MASK> token = sys.stdin.readline().strip() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise IOError(""Cannot read from stdin: terminal not a TTY"") <TAB>  <TAB> token = token.encode(""utf-8"") <TAB>  <TAB> data = decode(token, key=args.key, verify=args.verify) <TAB>  <TAB> return json.dumps(data) <TAB> except DecodeError as e: <TAB>  <TAB> raise DecodeError(""There was an error decoding the token: %s"" % e)",if sys . stdin . isatty ( ) :,156
"def cell_double_clicked(self, row, column): <TAB> if column == 3: <TAB>  <TAB> archive_name = self.selected_archive_name() <MASK> return <TAB>  <TAB> mount_point = self.mount_points.get(archive_name) <TAB>  <TAB> if mount_point is not None: <TAB>  <TAB>  <TAB> QDesktopServices.openUrl(QtCore.QUrl(f""file:///{mount_point}""))",if not archive_name :,107
"def tiles_around(self, pos, radius=1, predicate=None): <TAB> ps = [] <TAB> x, y = pos <TAB> for dx in range(-radius, radius + 1): <TAB>  <TAB> nx = x + dx <MASK> for dy in range(-radius, radius + 1): <TAB>  <TAB>  <TAB>  <TAB> ny = y + dy <TAB>  <TAB>  <TAB>  <TAB> if ny >= 0 and ny < self.height and (dx != 0 or dy != 0): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if predicate is None or predicate((nx, ny)): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ps.append((nx, ny)) <TAB> return ps",if nx >= 0 and nx < self . width :,151
"def __init__(self, type, data, name=None): <TAB> Constant.__init__(self, type, data, name) <TAB> self.tag.unique_value = None <TAB> if isinstance(data, np.ndarray) and data.ndim > 0: <TAB>  <TAB> flat_data = data.ravel() <TAB>  <TAB> if flat_data.shape[0]: <MASK> self.tag.unique_value = flat_data[0]",if ( flat_data == flat_data [ 0 ] ) . all ( ) :,118
"def git_convert_standalone_clone(repodir): <TAB> """"""If specified directory is a git repository, ensure it's a standalone clone"""""" <TAB> import bb.process <TAB> if os.path.exists(os.path.join(repodir, "".git"")): <TAB>  <TAB> alternatesfile = os.path.join(repodir, "".git"", ""objects"", ""info"", ""alternates"") <MASK> # This will have been cloned with -s, so we need to convert it so none <TAB>  <TAB>  <TAB> # of the contents is shared <TAB>  <TAB>  <TAB> bb.process.run(""git repack -a"", cwd=repodir) <TAB>  <TAB>  <TAB> os.remove(alternatesfile)",if os . path . exists ( alternatesfile ) :,166
"def _rename_recipe_file(oldrecipe, bpn, oldpv, newpv, path): <TAB> oldrecipe = os.path.basename(oldrecipe) <TAB> if oldrecipe.endswith(""_%s.bb"" % oldpv): <TAB>  <TAB> newrecipe = ""%s_%s.bb"" % (bpn, newpv) <MASK> shutil.move(os.path.join(path, oldrecipe), os.path.join(path, newrecipe)) <TAB> else: <TAB>  <TAB> newrecipe = oldrecipe <TAB> return os.path.join(path, newrecipe)",if oldrecipe != newrecipe :,154
"def profiling_startup(): <TAB> if ""--profile-sverchok-startup"" in sys.argv: <TAB>  <TAB> global _profile_nesting <TAB>  <TAB> profile = None <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> profile = get_global_profile() <TAB>  <TAB>  <TAB> _profile_nesting += 1 <MASK> profile.enable() <TAB>  <TAB>  <TAB> yield profile <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> _profile_nesting -= 1 <TAB>  <TAB>  <TAB> if _profile_nesting == 0 and profile is not None: <TAB>  <TAB>  <TAB>  <TAB> profile.disable() <TAB>  <TAB>  <TAB> dump_stats(file_path=""sverchok_profile.txt"") <TAB>  <TAB>  <TAB> save_stats(""sverchok_profile.prof"") <TAB> else: <TAB>  <TAB> yield None",if _profile_nesting == 1 :,180
"def to_scaled_dtype(val): <TAB> """"""Parse *val* to return a dtype."""""" <TAB> res = [] <TAB> for i in val: <MASK> res.append((i[0], i[1]) + i[2:-1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> res.append((i[0], i[-1].dtype) + i[2:-1]) <TAB>  <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB>  <TAB> res.append((i[0], type(i[-1])) + i[2:-1]) <TAB> return np.dtype(res)","if i [ 1 ] . startswith ( ""S"" ) :",148
"def row(self, indx): <TAB> if indx not in self.__rows: <TAB>  <TAB> if indx in self.__flushed_rows: <TAB>  <TAB>  <TAB> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> ""Attempt to reuse row index %d of sheet %r after flushing"" <TAB>  <TAB>  <TAB>  <TAB> % (indx, self.__name) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self.__rows[indx] = self.Row(indx, self) <MASK> self.last_used_row = indx <TAB>  <TAB> if indx < self.first_used_row: <TAB>  <TAB>  <TAB> self.first_used_row = indx <TAB> return self.__rows[indx]",if indx > self . last_used_row :,157
"def _flow_open(self): <TAB> rv = [] <TAB> for pipe in self.pipes: <MASK> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB> f""{pipe.__class__.__name__} pipe has double open methods."" <TAB>  <TAB>  <TAB>  <TAB> f"" Use `open` or `{self._method_open}`, not both."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if ""open"" in pipe._pipeline_all_methods_: <TAB>  <TAB>  <TAB> rv.append(pipe.open) <TAB>  <TAB> if self._method_open in pipe._pipeline_all_methods_: <TAB>  <TAB>  <TAB> rv.append(getattr(pipe, self._method_open)) <TAB> return rv","if pipe . _pipeline_all_methods_ . issuperset ( { ""open"" , self . _method_open } ) :",167
"def _parse_output(output, strict=False): <TAB> for pkg in _yum_pkginfo(output): <MASK> continue <TAB>  <TAB> repo_dict = ret.setdefault(pkg.repoid, {}) <TAB>  <TAB> version_list = repo_dict.setdefault(pkg.name, set()) <TAB>  <TAB> version_list.add(pkg.version)","if strict and ( pkg . repoid not in repos or not _check_args ( args , pkg . name ) ) :",108
"def user_defined_os(): <TAB> if menu.options.os: <TAB>  <TAB> if menu.options.os.lower() == ""windows"": <TAB>  <TAB>  <TAB> settings.TARGET_OS = ""win"" <TAB>  <TAB>  <TAB> return True <MASK> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> err_msg = ""You specified wrong value '"" + menu.options.os + ""' "" <TAB>  <TAB>  <TAB> err_msg += ""as an operation system. The value, must be 'Windows' or 'Unix'."" <TAB>  <TAB>  <TAB> print(settings.print_critical_msg(err_msg)) <TAB>  <TAB>  <TAB> raise SystemExit()","elif menu . options . os . lower ( ) == ""unix"" :",153
"def update(self, topLeft, bottomRight): <TAB> if self._updating: <TAB>  <TAB> # We are currently putting data in the model, so no updates <TAB>  <TAB> return <TAB> if self._index: <TAB>  <TAB> if topLeft.row() <= self._index.row() <= bottomRight.row(): <TAB>  <TAB>  <TAB> self.updateText() <TAB> elif self._indexes: <TAB>  <TAB> update = False <TAB>  <TAB> for i in self._indexes: <MASK> update = True <TAB>  <TAB> if update: <TAB>  <TAB>  <TAB> self.updateText()",if topLeft . row ( ) <= i . row ( ) <= bottomRight . row ( ) :,144
"def _wrapper(self, pipe, _should_terminate_flag, generator, *args, **kwargs): <TAB> """"""Executed in background, pipes generator results to foreground"""""" <TAB> logger.debug(""Entering _wrapper"") <TAB> try: <TAB>  <TAB> for datum in generator(*args, **kwargs): <MASK> raise EarlyCancellationError(""Task was cancelled"") <TAB>  <TAB>  <TAB> pipe.send(datum) <TAB> except Exception as e: <TAB>  <TAB> if not isinstance(e, EarlyCancellationError): <TAB>  <TAB>  <TAB> pipe.send(e) <TAB>  <TAB>  <TAB> import traceback <TAB>  <TAB>  <TAB> logger.warning(traceback.format_exc()) <TAB> else: <TAB>  <TAB> pipe.send(StopIteration()) <TAB> finally: <TAB>  <TAB> pipe.close() <TAB>  <TAB> logger.debug(""Exiting _wrapper"")",if _should_terminate_flag . value :,192
"def _flatten(*args): <TAB> arglist = [] <TAB> for arg in args: <TAB>  <TAB> if isinstance(arg, _Block): <MASK> arglist.append(arg.vhdl_code) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> arg = arg.subs <TAB>  <TAB> if id(arg) in _userCodeMap[""vhdl""]: <TAB>  <TAB>  <TAB> arglist.append(_userCodeMap[""vhdl""][id(arg)]) <TAB>  <TAB> elif isinstance(arg, (list, tuple, set)): <TAB>  <TAB>  <TAB> for item in arg: <TAB>  <TAB>  <TAB>  <TAB> arglist.extend(_flatten(item)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> arglist.append(arg) <TAB> return arglist",if arg . vhdl_code is not None :,179
"def _get_target_and_lun(self, context, volume): <TAB> iscsi_target = 0 <TAB> if not self.target_name or not self._get_group(): <TAB>  <TAB> lun = 1 <TAB>  <TAB> return iscsi_target, lun <TAB> luns = self._get_luns_info() <TAB> if (not luns) or (luns[0] != 1): <TAB>  <TAB> lun = 1 <TAB>  <TAB> return iscsi_target, lun <TAB> else: <TAB>  <TAB> for lun in luns: <MASK> return iscsi_target, (lun + 1)",if ( luns [ - 1 ] == lun ) or ( luns [ lun - 1 ] + 1 != luns [ lun ] ) :,188
"def check_find(ref): <TAB> # Check find returns indexes for single point codes <TAB> for c in set(m.used): <TAB>  <TAB> start = 0 <TAB>  <TAB> u = m.text <TAB>  <TAB> while start < m.size: <TAB>  <TAB>  <TAB> i = u.find(c, start) <MASK> break <TAB>  <TAB>  <TAB> self.assertEqual(u[i], c) <TAB>  <TAB>  <TAB> self.assertGreaterEqual(i, start) <TAB>  <TAB>  <TAB> start = i + 1",if i < 0 :,118
"def _format_column_list(self, data): <TAB> # Now we have all lis of columns which we need <TAB> # to include in our create definition, Let's format them <TAB> if ""columns"" in data: <TAB>  <TAB> for c in data[""columns""]: <MASK> c[""attacl""] = parse_priv_to_db(c[""attacl""], self.column_acl) <TAB>  <TAB>  <TAB> # check type for '[]' in it <TAB>  <TAB>  <TAB> if ""cltype"" in c: <TAB>  <TAB>  <TAB>  <TAB> c[""cltype""], c[""hasSqrBracket""] = column_utils.type_formatter( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> c[""cltype""] <TAB>  <TAB>  <TAB>  <TAB> )","if ""attacl"" in c :",170
"def _animate_strategy(self, speed=1): <TAB> if self._animating == 0: <TAB>  <TAB> return <TAB> if self._apply_strategy() is not None: <TAB>  <TAB> if self._animate.get() == 0 or self._step.get() == 1: <TAB>  <TAB>  <TAB> return <MASK> self._root.after(3000, self._animate_strategy) <TAB>  <TAB> elif self._animate.get() == 2: <TAB>  <TAB>  <TAB> self._root.after(1000, self._animate_strategy) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._root.after(20, self._animate_strategy)",if self . _animate . get ( ) == 1 :,151
"def close_all(map=None, ignore_all=False): <TAB> if map is None:  # pragma: no cover <TAB>  <TAB> map = socket_map <TAB> for x in list(map.values()):  # list() FBO py3 <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> x.close() <TAB>  <TAB> except OSError as x: <TAB>  <TAB>  <TAB> if x.args[0] == EBADF: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> el <MASK> raise <TAB>  <TAB> except _reraised_exceptions: <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> if not ignore_all: <TAB>  <TAB>  <TAB>  <TAB> raise <TAB> map.clear()",if not ignore_all :,157
"def iter_imports(path): <TAB> """"""Yield imports in *path*"""""" <TAB> for node in ast.parse(open(path, ""rb"").read()).body: <TAB>  <TAB> if isinstance(node, ast.ImportFrom): <TAB>  <TAB>  <TAB> if node.module is None: <TAB>  <TAB>  <TAB>  <TAB> prefix = () <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> prefix = tuple(node.module.split(""."")) <TAB>  <TAB>  <TAB> for snode in node.names: <TAB>  <TAB>  <TAB>  <TAB> yield (node.level, prefix + (snode.name,)) <MASK> for node in node.names: <TAB>  <TAB>  <TAB>  <TAB> yield (0, tuple(node.name.split(""."")))","elif isinstance ( node , ast . Import ) :",162
"def one_stage_eval_model(data_reader_eval, myModel, loss_criterion=None): <TAB> score_tot = 0 <TAB> n_sample_tot = 0 <TAB> loss_tot = 0 <TAB> for idx, batch in enumerate(data_reader_eval): <TAB>  <TAB> score, loss, n_sample = compute_a_batch( <TAB>  <TAB>  <TAB> batch, myModel, eval_mode=True, loss_criterion=loss_criterion <TAB>  <TAB> ) <TAB>  <TAB> score_tot += score <TAB>  <TAB> n_sample_tot += n_sample <MASK> loss_tot += loss.data[0] * n_sample <TAB> return score_tot / n_sample_tot, loss_tot / n_sample_tot, n_sample_tot",if loss is not None :,181
"def _process_preproc(self, token, content): <TAB> if self.state == ""include"": <MASK> content = content.strip().strip('""').strip(""<"").strip("">"").strip() <TAB>  <TAB>  <TAB> self.append(content, truncate=True, separator=""/"") <TAB>  <TAB> self.state = None <TAB> elif content.strip().startswith(""include""): <TAB>  <TAB> self.state = ""include"" <TAB> else: <TAB>  <TAB> self.state = None","if content != ""\n"" and content != ""#"" :",115
"def _aggregate_metadata_attribute( <TAB> self, attr, agg_func=np.max, default_value=0, from_type_metadata=True): <TAB> attr_values = [] <TAB> for a in self.appliances: <TAB>  <TAB> if from_type_metadata: <TAB>  <TAB>  <TAB> attr_value = a.type.get(attr) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> attr_value = a.metadata.get(attr) <MASK> attr_values.append(attr_value) <TAB> if len(attr_values) == 0: <TAB>  <TAB> return default_value <TAB> else: <TAB>  <TAB> return agg_func(attr_values)",if attr_value is not None :,162
"def _remove(self, item): <TAB> """"""Internal removal of an item"""""" <TAB> # Manage siblings when items are deleted <TAB> for sibling in self.lines[self.lines.index(item) + 1 :]: <TAB>  <TAB> if isinstance(sibling, CronItem): <TAB>  <TAB>  <TAB> env = sibling.env <TAB>  <TAB>  <TAB> sibling.env = item.env <TAB>  <TAB>  <TAB> sibling.env.update(env) <TAB>  <TAB>  <TAB> sibling.env.job = sibling <TAB>  <TAB>  <TAB> break <MASK> self.lines.remove(sibling) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> self.crons.remove(item) <TAB> self.lines.remove(item) <TAB> return 1","elif sibling == """" :",162
"def _validate_command_chain(self) -> None: <TAB> """"""Validate command-chain names."""""" <TAB> # Would normally get caught/handled by schema validation. <TAB> for command in self.command_chain: <MASK> raise HookValidationError( <TAB>  <TAB>  <TAB>  <TAB> hook_name=self.hook_name, <TAB>  <TAB>  <TAB>  <TAB> message=f""{command!r} is not a valid command-chain command."", <TAB>  <TAB>  <TAB> )","if not re . match ( ""^[A-Za-z0-9/._#:$-]*$"" , command ) :",124
"def _handle_unpaired_tag(self, html_tag): <TAB> self.handle_ignore(html_tag, is_open=False) <TAB> jannotations = self.read_jannotations(html_tag) <TAB> for jannotation in arg_to_iter(jannotations): <MASK> self._close_unpaired_tag() <TAB>  <TAB> self.extra_required_attrs.extend(jannotation.pop(""required"", [])) <TAB>  <TAB> annotation = self.build_annotation(jannotation) <TAB>  <TAB> self.handle_variant(annotation, is_open=False) <TAB>  <TAB> self.annotations.append(annotation) <TAB> self.next_tag_index += 1",if self . unpairedtag_stack :,164
"def browser(self): <TAB> if not hasattr(self, ""_browser""): <TAB>  <TAB> self.loop = asyncio.get_event_loop() <MASK> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB> ""Cannot use HTMLSession within an existing event loop. Use AsyncHTMLSession instead."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self._browser = self.loop.run_until_complete(super().browser) <TAB> return self._browser",if self . loop . is_running ( ) :,105
"def process(self, node): <TAB> self.vars = [] <TAB> for child in node.childNodes: <TAB>  <TAB> if child.nodeType == node.ELEMENT_NODE: <TAB>  <TAB>  <TAB> child_text = get_xml_text(child) <MASK> # pragma:nocover <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if child.nodeName == ""Real"": <TAB>  <TAB>  <TAB>  <TAB> for val in re.split(""[\t ]+"", child_text): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.vars.append(1.0 * eval(val)) <TAB> return self","if child_text == """" :",135
"def instantiate(self, node, container=None): <TAB> var = self.vm.program.NewVariable() <TAB> if container and ( <TAB>  <TAB> not isinstance(container, SimpleValue) <TAB>  <TAB> or self.full_name in container.all_template_names <TAB> ): <TAB>  <TAB> instance = TypeParameterInstance(self, container, self.vm) <TAB>  <TAB> return instance.to_variable(node) <TAB> else: <TAB>  <TAB> for c in self.constraints: <TAB>  <TAB>  <TAB> var.PasteVariable(c.instantiate(node, container)) <MASK> var.PasteVariable(self.bound.instantiate(node, container)) <TAB> if not var.bindings: <TAB>  <TAB> var.AddBinding(self.vm.convert.unsolvable, [], node) <TAB> return var",if self . bound :,184
"def compare_tables(self, db1, db2): <TAB> i1 = db1.query(""SELECT id, buf FROM test ORDER BY id"") <TAB> i2 = db2.query(""SELECT id, buf FROM test ORDER BY id"") <TAB> for (id1, buf1) in i1: <TAB>  <TAB> (id2, buf2) = next(i2) <TAB>  <TAB> self.assertEqual(id1, id2) <MASK> self.assertAlmostEqual(buf1, buf2, places=9) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertEqual(buf1, buf2) <TAB> self.assertRaises(StopIteration, i2.__next__)","if isinstance ( buf1 , float ) :",158
"def list_full_file_paths(directory): <TAB> """"""List the absolute paths of files in |directory|."""""" <TAB> directory_absolute_path = os.path.abspath(directory) <TAB> paths = [] <TAB> for relative_path in os.listdir(directory): <TAB>  <TAB> absolute_path = os.path.join(directory_absolute_path, relative_path) <MASK> # Only return paths to files. <TAB>  <TAB>  <TAB> paths.append(absolute_path) <TAB> return paths",if os . path . isfile ( absolute_path ) :,121
"def reparentChildren(self, newParent): <TAB> while self.element.contents: <TAB>  <TAB> child = self.element.contents[0] <TAB>  <TAB> child.extract() <MASK> newParent.appendChild(Element(child, self.soup, namespaces[""html""])) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> newParent.appendChild(TextNode(child, self.soup))","if isinstance ( child , Tag ) :",94
"def sort(self): <TAB> sorted_models = [] <TAB> concrete_models = set() <TAB> models = list(self.data) <TAB> while len(sorted_models) < len(models): <TAB>  <TAB> found = False <TAB>  <TAB> for model in models: <TAB>  <TAB>  <TAB> if model in sorted_models: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> dependencies = self.dependencies.get(model._meta.concrete_model) <TAB>  <TAB>  <TAB> if not (dependencies and dependencies.difference(concrete_models)): <TAB>  <TAB>  <TAB>  <TAB> sorted_models.append(model) <TAB>  <TAB>  <TAB>  <TAB> concrete_models.add(model._meta.concrete_model) <TAB>  <TAB>  <TAB>  <TAB> found = True <MASK> return <TAB> self.data = OrderedDict((model, self.data[model]) for model in sorted_models)",if not found :,188
"def template(self): <TAB> """"""template property"""""" <TAB> if self._template is None: <TAB>  <TAB> results = self._process(self.name, False, self.params, self.data) <MASK> raise OpenShiftCLIError( <TAB>  <TAB>  <TAB>  <TAB> ""Error processing template [%s]: %s"" % (self.name, results) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self._template = results[""results""][""items""] <TAB> return self._template","if results [ ""returncode"" ] != 0 :",109
"def edit_file(self, filename): <TAB> import subprocess <TAB> editor = self.get_editor() <TAB> if self.env: <TAB>  <TAB> environ = os.environ.copy() <TAB>  <TAB> environ.update(self.env) <TAB> else: <TAB>  <TAB> environ = None <TAB> try: <TAB>  <TAB> c = subprocess.Popen('%s ""%s""' % (editor, filename), env=environ, shell=True) <TAB>  <TAB> exit_code = c.wait() <MASK> raise Exception(""%s: Editing failed!"" % editor) <TAB> except OSError as e: <TAB>  <TAB> raise Exception(""%s: Editing failed: %s"" % (editor, e))",if exit_code != 0 :,157
"def test01e_json(self): <TAB> ""Testing GeoJSON input/output."" <TAB> from django.contrib.gis.gdal.prototypes.geom import GEOJSON <TAB> if not GEOJSON: <TAB>  <TAB> return <TAB> for g in self.geometries.json_geoms: <TAB>  <TAB> geom = OGRGeometry(g.wkt) <MASK> self.assertEqual(g.json, geom.json) <TAB>  <TAB>  <TAB> self.assertEqual(g.json, geom.geojson) <TAB>  <TAB> self.assertEqual(OGRGeometry(g.wkt), OGRGeometry(geom.json))","if not hasattr ( g , ""not_equal"" ) :",154
"def debug(self): <TAB> feed_dict = self.get_test_feed_dict() <TAB> while True: <TAB>  <TAB> tensor_name = input(""Input debug tensor name: "").strip() <MASK> sys.exit(0) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> debug_tensor = self.graph.get_tensor_by_name(tensor_name) <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> logging.error(e) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> res = self.sess.run(debug_tensor, feed_dict=feed_dict) <TAB>  <TAB> logging.info(f""Result for tensor {tensor_name} is: {res}"")","if tensor_name == ""q"" :",162
"def get_location(self, dist, dependency_links): <TAB> for url in dependency_links: <TAB>  <TAB> egg_fragment = Link(url).egg_fragment <TAB>  <TAB> if not egg_fragment: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if ""-"" in egg_fragment: <TAB>  <TAB>  <TAB> ## FIXME: will this work when a package has - in the name? <TAB>  <TAB>  <TAB> key = ""-"".join(egg_fragment.split(""-"")[:-1]).lower() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> key = egg_fragment <MASK> return url.split(""#"", 1)[0] <TAB> return None",if key == dist . key :,141
"def select(result): <TAB> for elem in result: <TAB>  <TAB> parent = elem.getparent() <MASK> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> # FIXME: what if the selector is ""*"" ? <TAB>  <TAB>  <TAB> elems = list(parent.iterchildren(elem.tag)) <TAB>  <TAB>  <TAB> if elems[index] is elem: <TAB>  <TAB>  <TAB>  <TAB> yield elem <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB> pass",if parent is None :,101
"def execute(self, cmd): <TAB> mark = utils.random_text(32) <TAB> path = ""/cgi-bin/gdrive.cgi?cmd=4&f_gaccount=;{};echo {};"".format(cmd, mark) <TAB> response = self.http_request( <TAB>  <TAB> method=""GET"", <TAB>  <TAB> path=path, <TAB> ) <TAB> if response is None: <TAB>  <TAB> return """" <TAB> if mark in response.text: <TAB>  <TAB> regexp = ""(|.+?){}"".format(mark) <TAB>  <TAB> res = re.findall(regexp, response.text, re.DOTALL) <MASK> return res[0] <TAB> return """"",if len ( res ) :,155
"def join(s, *p): <TAB> path = s <TAB> for t in p: <TAB>  <TAB> if (not s) or isabs(t): <TAB>  <TAB>  <TAB> path = t <TAB>  <TAB>  <TAB> continue <MASK> t = t[1:] <TAB>  <TAB> if "":"" not in path: <TAB>  <TAB>  <TAB> path = "":"" + path <TAB>  <TAB> if path[-1:] != "":"": <TAB>  <TAB>  <TAB> path = path + "":"" <TAB>  <TAB> path = path + t <TAB> return path","if t [ : 1 ] == "":"" :",115
"def do_remove(self): <TAB> if self.netconf.locked(""dhcp""): <TAB>  <TAB> if not self.pid: <TAB>  <TAB>  <TAB> pid = read_pid_file(""/var/run/udhcpd.pan1.pid"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pid = self.pid <MASK> logging.info(""Stale dhcp lockfile found"") <TAB>  <TAB> self.netconf.unlock(""dhcp"")","if not kill ( pid , ""udhcpd"" ) :",110
"def filter_packages(query, package_infos): <TAB> if query is None: <TAB>  <TAB> return package_infos <TAB> try: <TAB>  <TAB> if ""!"" in query: <TAB>  <TAB>  <TAB> raise ConanException(""'!' character is not allowed"") <TAB>  <TAB> if "" not "" in query or query.startswith(""not ""): <TAB>  <TAB>  <TAB> raise ConanException(""'not' operator is not allowed"") <TAB>  <TAB> postfix = infix_to_postfix(query) if query else [] <TAB>  <TAB> result = OrderedDict() <TAB>  <TAB> for package_id, info in package_infos.items(): <MASK> result[package_id] = info <TAB>  <TAB> return result <TAB> except Exception as exc: <TAB>  <TAB> raise ConanException(""Invalid package query: %s. %s"" % (query, exc))","if _evaluate_postfix_with_info ( postfix , info ) :",193
"def __add__(self, other): <TAB> if isinstance(other, Vector3): <TAB>  <TAB> # Vector + Vector -> Vector <TAB>  <TAB> # Vector + Point -> Point <TAB>  <TAB> # Point + Point -> Vector <MASK> _class = Vector3 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _class = Point3 <TAB>  <TAB> return _class(self.x + other.x, self.y + other.y, self.z + other.z) <TAB> else: <TAB>  <TAB> assert hasattr(other, ""__len__"") and len(other) == 3 <TAB>  <TAB> return Vector3(self.x + other[0], self.y + other[1], self.z + other[2])",if self . __class__ is other . __class__ :,166
"def test_scout(): <TAB> test_status = False <TAB> with open(""/tmp/test_scout_output"", ""w"") as logfile: <TAB>  <TAB> if not DockerImage: <TAB>  <TAB>  <TAB> logfile.write(""No $AMBASSADOR_DOCKER_IMAGE??\n"") <TAB>  <TAB> else: <MASK> if wait_for_diagd(logfile) and check_chimes(logfile): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> test_status = True <TAB>  <TAB>  <TAB>  <TAB> docker_kill(logfile) <TAB> if not test_status: <TAB>  <TAB> with open(""/tmp/test_scout_output"", ""r"") as logfile: <TAB>  <TAB>  <TAB> for line in logfile: <TAB>  <TAB>  <TAB>  <TAB> print(line.rstrip()) <TAB> assert test_status, ""test failed""",if docker_start ( logfile ) :,189
"def visit_Assign(self, node): <TAB> """"""Handle visiting an assignment statement."""""" <TAB> ups = set() <TAB> for targ in node.targets: <TAB>  <TAB> if isinstance(targ, (Tuple, List)): <TAB>  <TAB>  <TAB> ups.update(leftmostname(elt) for elt in targ.elts) <MASK> newnode = self.try_subproc_toks(node) <TAB>  <TAB>  <TAB> if newnode is node: <TAB>  <TAB>  <TAB>  <TAB> ups.add(leftmostname(targ)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return newnode <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ups.add(leftmostname(targ)) <TAB> self.ctxupdate(ups) <TAB> return node","elif isinstance ( targ , BinOp ) :",165
"def get_config_h_filename(): <TAB> """"""Returns the path of pyconfig.h."""""" <TAB> if _PYTHON_BUILD: <TAB>  <TAB> # The additional check for != ""java"" secures against JyNI-monkeypatching. <MASK> inc_dir = os.path.join(_PROJECT_BASE, ""PC"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> inc_dir = _PROJECT_BASE <TAB> else: <TAB>  <TAB> inc_dir = get_path(""platinclude"") <TAB> return os.path.join(inc_dir, ""pyconfig.h"")","if os . name == ""nt"" and os . name != ""java"" :",148
"def is_valid_block(self): <TAB> """"""check wheter the block is valid in the current position"""""" <TAB> for i in range(self.block.x): <TAB>  <TAB> for j in range(self.block.x): <TAB>  <TAB>  <TAB> if self.block.get(i, j): <TAB>  <TAB>  <TAB>  <TAB> if self.block.pos.x + i < 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <MASK> return False <TAB>  <TAB>  <TAB>  <TAB> if self.block.pos.y + j < 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB>  <TAB> if self.map.get((self.block.pos.x + i, self.block.pos.y + j), False): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return True",if self . block . pos . x + i >= COLUMNS :,192
"def __call__(self, execution_result): <TAB> json_value = execution_result.get_output_in_json() <TAB> actual_result = jmespath.search( <TAB>  <TAB> self._query, json_value, jmespath.Options(collections.OrderedDict) <TAB> ) <TAB> if not actual_result > self._expected_result: <TAB>  <TAB> expected_result_format = ""> {}"".format(self._expected_result) <MASK> raise JMESPathCheckAssertionError( <TAB>  <TAB>  <TAB>  <TAB> self._query, <TAB>  <TAB>  <TAB>  <TAB> expected_result_format, <TAB>  <TAB>  <TAB>  <TAB> actual_result, <TAB>  <TAB>  <TAB>  <TAB> execution_result.output, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> raise JMESPathCheckAssertionError( <TAB>  <TAB>  <TAB> self._query, expected_result_format, ""None"", execution_result.output <TAB>  <TAB> )",if actual_result :,194
def readline(b): <TAB> a = 1 <TAB> while True: <TAB>  <TAB> if b: <MASK> a = 2 <TAB>  <TAB>  <TAB>  <TAB> b = None <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> b = None <TAB>  <TAB> a = 5 <TAB>  <TAB> return a,if b [ 0 ] :,70
"def test_execute_magic(self): <TAB> """"""execute accepts IPython commands"""""" <TAB> view = self.client[:] <TAB> view.execute(""a = 5"") <TAB> ar = view.execute(""%whos"", block=True) <TAB> # this will raise, if that failed <TAB> ar.get(5) <TAB> for stdout in ar.stdout: <TAB>  <TAB> lines = stdout.splitlines() <TAB>  <TAB> self.assertEqual(lines[0].split(), [""Variable"", ""Type"", ""Data/Info""]) <TAB>  <TAB> found = False <TAB>  <TAB> for line in lines[2:]: <TAB>  <TAB>  <TAB> split = line.split() <MASK> found = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> self.assertTrue(found, ""whos output wrong: %s"" % stdout)","if split == [ ""a"" , ""int"" , ""5"" ] :",188
"def imgFileProcessingTick(output): <TAB> if isinstance(output, tuple): <TAB>  <TAB> workerOutput.append(output) <TAB>  <TAB> workerPool.terminate() <TAB> else: <TAB>  <TAB> for page in output: <MASK> options.imgMetadata[page[0]] = page[1] <TAB>  <TAB>  <TAB>  <TAB> options.imgOld.append(page[2]) <TAB> if GUI: <TAB>  <TAB> GUI.progressBarTick.emit(""tick"") <TAB>  <TAB> if not GUI.conversionAlive: <TAB>  <TAB>  <TAB> workerPool.terminate()",if page is not None :,129
"def _load(xs): <TAB> ret = [] <TAB> for x, ctx in zip(xs, context): <MASK> ret.append([y.as_in_context(ctx) for y in x]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret.append(x.as_in_context(ctx)) <TAB> return ret","if isinstance ( x , tuple ) :",85
"def _is_64bit_os(): <TAB> global _IS_64BIT_OS <TAB> if _IS_64BIT_OS is None: <MASK> import platform <TAB>  <TAB>  <TAB> _IS_64BIT_OS = platform.machine() == ""AMD64"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _IS_64BIT_OS = False <TAB> return _IS_64BIT_OS",if sys . maxsize > 2 ** 32 :,101
"def stepStarted(self, step): <TAB> self.currentStep = step <TAB> for w in self.watchers: <TAB>  <TAB> receiver = w.stepStarted(self, step) <TAB>  <TAB> if receiver: <MASK> step.subscribe(receiver[0], receiver[1]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> step.subscribe(receiver) <TAB>  <TAB>  <TAB> d = step.waitUntilFinished() <TAB>  <TAB>  <TAB> # TODO: This actually looks like a bug, but this code <TAB>  <TAB>  <TAB> # will be removed anyway. <TAB>  <TAB>  <TAB> # pylint: disable=cell-var-from-loop <TAB>  <TAB>  <TAB> d.addCallback(lambda step: step.unsubscribe(receiver)) <TAB> step.waitUntilFinished().addCallback(self._stepFinished)","if isinstance ( receiver , type ( ( ) ) ) :",183
"def connection(self, commit_on_success=False): <TAB> with self._lock: <TAB>  <TAB> if self._bulk_commit: <TAB>  <TAB>  <TAB> if self._pending_connection is None: <TAB>  <TAB>  <TAB>  <TAB> self._pending_connection = sqlite.connect(self.filename) <TAB>  <TAB>  <TAB> con = self._pending_connection <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> con = sqlite.connect(self.filename) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if self.fast_save: <TAB>  <TAB>  <TAB>  <TAB> con.execute(""PRAGMA synchronous = 0;"") <TAB>  <TAB>  <TAB> yield con <MASK> con.commit() <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> if not self._bulk_commit: <TAB>  <TAB>  <TAB>  <TAB> con.close()",if commit_on_success and self . can_commit :,182
"def parse_response(self, response): <TAB> # read response data from httpresponse, and parse it <TAB> # Check for new http response object, otherwise it is a file object. <TAB> if hasattr(response, ""getheader""): <TAB>  <TAB> if response.getheader(""Content-Encoding"", """") == ""gzip"": <TAB>  <TAB>  <TAB> stream = GzipDecodedResponse(response) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> stream = response <TAB> else: <TAB>  <TAB> stream = response <TAB> p, u = self.getparser() <TAB> while 1: <TAB>  <TAB> data = stream.read(1024) <MASK> break <TAB>  <TAB> if self.verbose: <TAB>  <TAB>  <TAB> print(""body:"", repr(data)) <TAB>  <TAB> p.feed(data) <TAB> if stream is not response: <TAB>  <TAB> stream.close() <TAB> p.close() <TAB> return u.close()",if not data :,199
"def edge2str(self, nfrom, nto): <TAB> if isinstance(nfrom, ExprCompose): <TAB>  <TAB> for i in nfrom.args: <TAB>  <TAB>  <TAB> if i[0] == nto: <TAB>  <TAB>  <TAB>  <TAB> return ""[%s, %s]"" % (i[1], i[2]) <TAB> elif isinstance(nfrom, ExprCond): <MASK> return ""?"" <TAB>  <TAB> elif nfrom.src1 == nto: <TAB>  <TAB>  <TAB> return ""True"" <TAB>  <TAB> elif nfrom.src2 == nto: <TAB>  <TAB>  <TAB> return ""False"" <TAB> return """"",if nfrom . cond == nto :,149
"def gather_command_line_options(filter_disabled=None): <TAB> """"""Get a sorted list of all CommandLineOption subclasses."""""" <TAB> if filter_disabled is None: <TAB>  <TAB> filter_disabled = not SETTINGS.COMMAND_LINE.SHOW_DISABLED_OPTIONS <TAB> options = [] <TAB> for opt in get_inheritors(commandline_options.CommandLineOption): <TAB>  <TAB> warnings.warn( <TAB>  <TAB>  <TAB> ""Subclassing `CommandLineOption` is deprecated. Please "" <TAB>  <TAB>  <TAB> ""use the `sacred.cli_option` decorator and pass the function "" <TAB>  <TAB>  <TAB> ""to the Experiment constructor."" <TAB>  <TAB> ) <MASK> continue <TAB>  <TAB> options.append(opt) <TAB> options += DEFAULT_COMMAND_LINE_OPTIONS <TAB> return sorted(options, key=commandline_options.get_name)",if filter_disabled and not opt . _enabled :,199
"def handle_disconnect(self): <TAB> """"""Socket gets disconnected"""""" <TAB> # signal disconnected terminal with control lines <TAB> try: <TAB>  <TAB> self.serial.rts = False <TAB>  <TAB> self.serial.dtr = False <TAB> finally: <TAB>  <TAB> # restore original port configuration in case it was changed <TAB>  <TAB> self.serial.apply_settings(self.serial_settings_backup) <TAB>  <TAB> # stop RFC 2217 state machine <TAB>  <TAB> self.rfc2217 = None <TAB>  <TAB> # clear send buffer <TAB>  <TAB> self.buffer_ser2net = bytearray() <TAB>  <TAB> # close network connection <TAB>  <TAB> if self.socket is not None: <TAB>  <TAB>  <TAB> self.socket.close() <TAB>  <TAB>  <TAB> self.socket = None <MASK> self.log.warning(""{}: Disconnected"".format(self.device))",if self . log is not None :,195
"def answers(self, other): <TAB> if not isinstance(other, TCP): <TAB>  <TAB> return 0 <TAB> if conf.checkIPsrc: <TAB>  <TAB> if not ((self.sport == other.sport) and (self.dport == other.dport)): <TAB>  <TAB>  <TAB> return 0 <TAB> if conf.check_TCPerror_seqack: <TAB>  <TAB> if self.seq is not None: <TAB>  <TAB>  <TAB> if self.seq != other.seq: <TAB>  <TAB>  <TAB>  <TAB> return 0 <MASK> if self.ack != other.ack: <TAB>  <TAB>  <TAB>  <TAB> return 0 <TAB> return 1",if self . ack is not None :,143
"def _override_options(options, **overrides): <TAB> """"""Override options."""""" <TAB> for opt, val in overrides.items(): <TAB>  <TAB> passed_value = getattr(options, opt, _Default()) <MASK> value = process_value(opt, passed_value.value) <TAB>  <TAB>  <TAB> value += process_value(opt, val) <TAB>  <TAB>  <TAB> setattr(options, opt, value) <TAB>  <TAB> elif isinstance(passed_value, _Default): <TAB>  <TAB>  <TAB> setattr(options, opt, process_value(opt, val))","if opt in ( ""ignore"" , ""select"" ) and passed_value :",137
"def _unlock_restarted_vms(self, pool_name): <TAB> result = [] <TAB> for vm in await self.middleware.call(""vm.query"", [(""autostart"", ""="", True)]): <TAB>  <TAB> for device in vm[""devices""]: <MASK> continue <TAB>  <TAB>  <TAB> path = device[""attributes""].get(""path"") <TAB>  <TAB>  <TAB> if not path: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if path.startswith(f""/dev/zvol/{pool_name}/"") or path.startswith( <TAB>  <TAB>  <TAB>  <TAB> f""/mnt/{pool_name}/"" <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> result.append(vm) <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return result","if device [ ""dtype"" ] not in ( ""DISK"" , ""RAW"" ) :",172
"def check_space(arr, task_id): <TAB> for a in arr: <MASK> found = False <TAB>  <TAB>  <TAB> for x in shlex.split(a): <TAB>  <TAB>  <TAB>  <TAB> if task_id in x: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> found = True <TAB>  <TAB>  <TAB> if not found: <TAB>  <TAB>  <TAB>  <TAB> raise AssertionError","if a . startswith ( ""hadoop jar"" ) :",86
"def clean(self): <TAB> if self.instance: <TAB>  <TAB> redirect_to = self.data.get(""redirect_to"", """") <TAB>  <TAB> if redirect_to != """": <TAB>  <TAB>  <TAB> lfs.core.utils.set_redirect_for( <TAB>  <TAB>  <TAB>  <TAB> self.instance.get_absolute_url(), redirect_to <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lfs.core.utils.remove_redirect_for(self.instance.get_absolute_url()) <TAB> if self.data.get(""active_base_price"") == str(CHOICES_YES): <MASK> self.errors[""base_price_amount""] = ErrorList( <TAB>  <TAB>  <TAB>  <TAB> [_(u""This field is required."")] <TAB>  <TAB>  <TAB> ) <TAB> return self.cleaned_data","if self . data . get ( ""base_price_amount"" , """" ) == """" :",197
"def detect(get_page): <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS: <TAB>  <TAB> page, headers, code = get_page(get=vector) <TAB>  <TAB> retval = ( <TAB>  <TAB>  <TAB> re.search( <TAB>  <TAB>  <TAB>  <TAB> r""\AAL[_-]?(SESS|LB)="", headers.get(HTTP_HEADER.SET_COOKIE, """"), re.I <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> is not None <TAB>  <TAB> ) <MASK> break <TAB> return retval",if retval :,127
"def unloadOnePlugin(self, moduleOrFileName, verbose=False): <TAB> moduleName = self.regularizeName(moduleOrFileName) <TAB> if self.isLoaded(moduleName): <MASK> g.pr(""unloading"", moduleName) <TAB>  <TAB> del self.loadedModules[moduleName] <TAB> for tag in self.handlers: <TAB>  <TAB> bunches = self.handlers.get(tag) <TAB>  <TAB> bunches = [bunch for bunch in bunches if bunch.moduleName != moduleName] <TAB>  <TAB> self.handlers[tag] = bunches",if verbose :,136
"def __init__(self, **kw): <TAB> util_schema.validate( <TAB>  <TAB> instance=kw, <TAB>  <TAB> schema=self.schema, <TAB>  <TAB> cls=util_schema.CustomValidator, <TAB>  <TAB> use_default=False, <TAB>  <TAB> allow_default_none=True, <TAB> ) <TAB> for prop in six.iterkeys(self.schema.get(""properties"", [])): <TAB>  <TAB> value = kw.get(prop, None) <TAB>  <TAB> # special handling for chain property to create the Node object <MASK> nodes = [] <TAB>  <TAB>  <TAB> for node in value: <TAB>  <TAB>  <TAB>  <TAB> ac_node = Node(**node) <TAB>  <TAB>  <TAB>  <TAB> ac_node.validate() <TAB>  <TAB>  <TAB>  <TAB> nodes.append(ac_node) <TAB>  <TAB>  <TAB> value = nodes <TAB>  <TAB> setattr(self, prop, value)","if prop == ""chain"" :",195
"def initialize(self): <TAB> for document in self.corpus: <TAB>  <TAB> frequencies = {} <TAB>  <TAB> for word in document: <TAB>  <TAB>  <TAB> if word not in frequencies: <TAB>  <TAB>  <TAB>  <TAB> frequencies[word] = 0 <TAB>  <TAB>  <TAB> frequencies[word] += 1 <TAB>  <TAB> self.f.append(frequencies) <TAB>  <TAB> for word, freq in iteritems(frequencies): <MASK> self.df[word] = 0 <TAB>  <TAB>  <TAB> self.df[word] += 1 <TAB> for word, freq in iteritems(self.df): <TAB>  <TAB> self.idf[word] = math.log(self.corpus_size - freq + 0.5) - math.log(freq + 0.5)",if word not in self . df :,170
"def get_child(self, name): <TAB> if self.isdir: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self.data[name] <TAB>  <TAB> except: <MASK> for childname, child in list(self.data.items()): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if childname.lower() == name.lower(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return child <TAB>  <TAB>  <TAB> raise",if not self . case_sensitive :,100
"def set_cover(channel, pixbuf): <TAB> if self.channel == channel: <MASK> self.imgCover.set_from_pixbuf(self.scale_pixbuf(pixbuf)) <TAB>  <TAB> if self.show_on_cover_load: <TAB>  <TAB>  <TAB> self.main_window.show() <TAB>  <TAB>  <TAB> self.show_on_cover_load = False",if pixbuf is not None :,97
"def test_infer_shape_matrix(self): <TAB> # Testing the infer_shape with a matrix. <TAB> x = theano.tensor.matrix() <TAB> for op in self.ops: <TAB>  <TAB> if not op.return_inverse: <TAB>  <TAB>  <TAB> continue <MASK> f = op(x)[2] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> f = op(x)[1] <TAB>  <TAB> self._compile_and_check( <TAB>  <TAB>  <TAB> [x], <TAB>  <TAB>  <TAB> [f], <TAB>  <TAB>  <TAB> [np.asarray(np.array([[2, 1], [3, 2], [2, 3]]), dtype=config.floatX)], <TAB>  <TAB>  <TAB> self.op_class, <TAB>  <TAB> )",if op . return_index :,170
"def Filter(self, match=None, **_): <TAB> """"""Filter the current expression."""""" <TAB> arg = self.stack.pop(-1) <TAB> # Filters can be specified as a comma separated list. <TAB> for filter_name in match.group(1).split("",""): <TAB>  <TAB> filter_object = ConfigFilter.classes_by_name.get(filter_name) <TAB>  <TAB> if filter_object is None: <TAB>  <TAB>  <TAB> raise FilterError(""Unknown filter function %r"" % filter_name) <MASK> logging.debug(""Applying filter %s for %s."", filter_name, arg) <TAB>  <TAB> arg = filter_object().Filter(arg) <TAB>  <TAB> precondition.AssertType(arg, Text) <TAB> self.stack[-1] += arg",if not filter_object . sensitive_arg :,180
"def enqueue_link(self, fuzzresult, link_url, parsed_link): <TAB> # dir path <TAB> if self.add_path: <TAB>  <TAB> split_path = parsed_link.path.split(""/"") <TAB>  <TAB> newpath = ""/"".join(split_path[:-1]) + ""/"" <TAB>  <TAB> self.queue_url(urljoin(fuzzresult.url, newpath)) <TAB> # file path <TAB> new_link = urljoin(fuzzresult.url, link_url) <TAB> if not self.regex_param or ( <TAB>  <TAB> self.regex_param and self.regex_param.search(new_link) is not None <TAB> ): <MASK> self.queue_url(new_link) <TAB>  <TAB> self.add_result(""link"", ""New link found"", new_link)",if self . enqueue_links :,188
"def old_save(self, *args, **kwargs): <TAB> ""Override save to set Subscribers and send Notifications"" <TAB> original = None <TAB> original_assigned = [] <TAB> if hasattr(self, ""instance""): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> original = Task.objects.get(pk=self.instance.id) <TAB>  <TAB>  <TAB> original_assigned = list(original.assigned.all()) <TAB>  <TAB> except Task.DoesNotExist: <TAB>  <TAB>  <TAB> pass <TAB> instance = super(TaskForm, self).save(*args, **kwargs) <TAB> if original: <TAB>  <TAB> new_assigned = list(self.cleaned_data[""assigned""]) <MASK> for assignee in new_assigned: <TAB>  <TAB>  <TAB>  <TAB> self.instance.subscribers.add(assignee) <TAB> return instance",if original_assigned != new_assigned :,189
"def get_test_layer(): <TAB> layers = get_bb_var(""BBLAYERS"").split() <TAB> testlayer = None <TAB> for l in layers: <TAB>  <TAB> if ""~"" in l: <TAB>  <TAB>  <TAB> l = os.path.expanduser(l) <MASK> testlayer = l <TAB>  <TAB>  <TAB> break <TAB> return testlayer","if ""/meta-selftest"" in l and os . path . isdir ( l ) :",98
"def readable(request): <TAB> """"""Display a readable version of this url if we can"""""" <TAB> rdict = request.matchdict <TAB> bid = rdict.get(""hash_id"", None) <TAB> username = rdict.get(""username"", None) <TAB> if bid: <TAB>  <TAB> found = BmarkMgr.get_by_hash(bid, username=username) <MASK> return { <TAB>  <TAB>  <TAB>  <TAB> ""bmark"": found, <TAB>  <TAB>  <TAB>  <TAB> ""username"": username, <TAB>  <TAB>  <TAB> } <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return HTTPNotFound()",if found :,136
"def pythonpath(conanfile): <TAB> python_path = conanfile.env.get(""PYTHONPATH"", None) <TAB> if python_path: <TAB>  <TAB> old_path = sys.path[:] <MASK> sys.path.extend(python_path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sys.path.append(python_path) <TAB>  <TAB> yield <TAB>  <TAB> sys.path = old_path <TAB> else: <TAB>  <TAB> yield","if isinstance ( python_path , list ) :",112
"def _validate(self): <TAB> on_target_delete = None <TAB> for cmd in self.val.commands: <TAB>  <TAB> if isinstance(cmd, qlast.OnTargetDelete): <MASK> raise errors.EdgeQLSyntaxError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f""more than one 'on target delete' specification"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> context=cmd.context, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> on_target_delete = cmd",if on_target_delete :,119
"def _choose_instance(self, timeout_time): <TAB> """"""Returns an Instance to handle a request or None if all are busy."""""" <TAB> with self._condition: <TAB>  <TAB> while time.time() < timeout_time and not self._quit_event.is_set(): <TAB>  <TAB>  <TAB> for inst in self._instances: <TAB>  <TAB>  <TAB>  <TAB> if inst.can_accept_requests: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return inst <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> inst = self._start_any_instance() <MASK> break <TAB>  <TAB>  <TAB>  <TAB> self._condition.wait(timeout_time - time.time()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return None <TAB> if inst: <TAB>  <TAB> inst.wait(timeout_time) <TAB> return inst",if inst :,180
"def get_identifiers(self): <TAB> ids = [] <TAB> for entry in glob.glob(f""{self._base_path}/ctl-*""): <TAB>  <TAB> ident = entry.split(""-"", 1)[-1] <MASK> continue <TAB>  <TAB> if os.path.exists(os.path.join(entry, ""disk_octets.rrd"")): <TAB>  <TAB>  <TAB> ids.append(ident) <TAB> ids.sort(key=RRDBase._sort_ports) <TAB> return ids","if ident . endswith ( ""ioctl"" ) :",118
"def read_vocab_list(path, max_vocab_size=20000): <TAB> vocab = {""<eos>"": 0, ""<unk>"": 1} <TAB> with io.open(path, encoding=""utf-8"", errors=""ignore"") as f: <TAB>  <TAB> for l in f: <TAB>  <TAB>  <TAB> w = l.strip() <MASK> vocab[w] = len(vocab) <TAB>  <TAB>  <TAB> if len(vocab) >= max_vocab_size: <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return vocab",if w not in vocab and w :,125
"def n_import_from(self, node): <TAB> relative_path_index = 0 <TAB> if self.version >= 2.5: <TAB>  <TAB> if node[relative_path_index].pattr > 0: <TAB>  <TAB>  <TAB> node[2].pattr = (""."" * node[relative_path_index].pattr) + node[2].pattr <TAB>  <TAB> if self.version > 2.7: <MASK> imports = node[1].pattr <TAB>  <TAB>  <TAB>  <TAB> for pattr in imports: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> node[1].pattr = pattr <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.default(node) <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> pass <TAB> self.default(node)","if isinstance ( node [ 1 ] . pattr , tuple ) :",170
"def get(self): <TAB> """"""Returns a simple HTML for contact form"""""" <TAB> if self.user: <TAB>  <TAB> user_info = models.User.get_by_id(long(self.user_id)) <MASK> self.form.name.data = user_info.name + "" "" + user_info.last_name <TAB>  <TAB> if user_info.email: <TAB>  <TAB>  <TAB> self.form.email.data = user_info.email <TAB> params = {""exception"": self.request.get(""exception"")} <TAB> return self.render_template(""boilerplate_contact.html"", **params)",if user_info . name or user_info . last_name :,155
"def task_management_menu(activation, request): <TAB> """"""Available tasks actions."""""" <TAB> actions = [] <TAB> if request.user.has_perm(activation.flow_class._meta.manage_permission_name): <TAB>  <TAB> for transition in activation.get_available_transitions(): <TAB>  <TAB>  <TAB> if transition.can_proceed(activation): <TAB>  <TAB>  <TAB>  <TAB> url = activation.flow_task.get_task_url( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> activation.task, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> transition.name, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> user=request.user, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> namespace=request.resolver_match.namespace, <TAB>  <TAB>  <TAB>  <TAB> ) <MASK> actions.append((transition.name.replace(""_"", "" "").title(), url)) <TAB> return {""actions"": actions, ""request"": request}",if url :,192
"def discover_misago_admin(): <TAB> for app in apps.get_app_configs(): <TAB>  <TAB> module = import_module(app.name) <TAB>  <TAB> if not hasattr(module, ""admin""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> admin_module = import_module(""%s.admin"" % app.name) <TAB>  <TAB> if hasattr(admin_module, ""MisagoAdminExtension""): <TAB>  <TAB>  <TAB> extension = getattr(admin_module, ""MisagoAdminExtension"")() <TAB>  <TAB>  <TAB> if hasattr(extension, ""register_navigation_nodes""): <TAB>  <TAB>  <TAB>  <TAB> extension.register_navigation_nodes(site) <MASK> extension.register_urlpatterns(urlpatterns)","if hasattr ( extension , ""register_urlpatterns"" ) :",169
"def dequeue(self): <TAB> with self.db(commit=True) as curs: <TAB>  <TAB> curs.execute( <TAB>  <TAB>  <TAB> ""select id, data from task where queue = ? "" <TAB>  <TAB>  <TAB> ""order by priority desc, id limit 1"", <TAB>  <TAB>  <TAB> (self.name,), <TAB>  <TAB> ) <TAB>  <TAB> result = curs.fetchone() <TAB>  <TAB> if result is not None: <TAB>  <TAB>  <TAB> tid, data = result <TAB>  <TAB>  <TAB> curs.execute(""delete from task where id = ?"", (tid,)) <MASK> return to_bytes(data)",if curs . rowcount == 1 :,138
"def readHexStringFromStream(stream): <TAB> stream.read(1) <TAB> txt = """" <TAB> x = b_("""") <TAB> while True: <TAB>  <TAB> tok = readNonWhitespace(stream) <MASK> # stream has truncated prematurely <TAB>  <TAB>  <TAB> raise PdfStreamError(""Stream has ended unexpectedly"") <TAB>  <TAB> if tok == b_("">""): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> x += tok <TAB>  <TAB> if len(x) == 2: <TAB>  <TAB>  <TAB> txt += chr(int(x, base=16)) <TAB>  <TAB>  <TAB> x = b_("""") <TAB> if len(x) == 1: <TAB>  <TAB> x += b_(""0"") <TAB> if len(x) == 2: <TAB>  <TAB> txt += chr(int(x, base=16)) <TAB> return createStringObject(b_(txt))",if not tok :,190
"def test_compute_gradient(self): <TAB> for y, y_pred in zip(self.y_list, self.predict_list): <TAB>  <TAB> lse_grad = self.lae_loss.compute_grad(y, y_pred) <TAB>  <TAB> diff = y_pred - y <TAB>  <TAB> if diff > consts.FLOAT_ZERO: <TAB>  <TAB>  <TAB> grad = 1 <MASK> grad = -1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> grad = 0 <TAB>  <TAB> self.assertTrue(np.fabs(lse_grad - grad) < consts.FLOAT_ZERO)",elif diff < consts . FLOAT_ZERO :,145
"def request_get(request, key, default_value=None): <TAB> if key in request.args: <TAB>  <TAB> return request.args.get(key) <TAB> elif key in request.form: <TAB>  <TAB> return request.form.get(key) <TAB> try: <TAB>  <TAB> json_body = request.get_json(force=True, silent=True) <MASK> return json_body[key] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return default_value <TAB> except Exception: <TAB>  <TAB> return default_value",if key in json_body :,129
"def _getResourceData(self, jid, dataname): <TAB> """"""Return specific jid's resource representation in internal format. Used internally."""""" <TAB> if jid.find(""/"") + 1: <TAB>  <TAB> jid, resource = jid.split(""/"", 1) <MASK> return self._data[jid][""resources""][resource][dataname] <TAB> elif self._data[jid][""resources""].keys(): <TAB>  <TAB> lastpri = -129 <TAB>  <TAB> for r in self._data[jid][""resources""].keys(): <TAB>  <TAB>  <TAB> if int(self._data[jid][""resources""][r][""priority""]) > lastpri: <TAB>  <TAB>  <TAB>  <TAB> resource, lastpri = r, int(self._data[jid][""resources""][r][""priority""]) <TAB>  <TAB> return self._data[jid][""resources""][resource][dataname]","if self . _data [ jid ] [ ""resources"" ] . has_key ( resource ) :",194
"def GetBoundingBoxMin(self): <TAB> """"""Get the minimum bounding box."""""" <TAB> x1, y1 = 10000, 10000 <TAB> x2, y2 = -10000, -10000 <TAB> for point in self._lineControlPoints: <TAB>  <TAB> if point[0] < x1: <TAB>  <TAB>  <TAB> x1 = point[0] <TAB>  <TAB> if point[1] < y1: <TAB>  <TAB>  <TAB> y1 = point[1] <TAB>  <TAB> if point[0] > x2: <TAB>  <TAB>  <TAB> x2 = point[0] <MASK> y2 = point[1] <TAB> return x2 - x1, y2 - y1",if point [ 1 ] > y2 :,158
"def produce_etag_headers(self, filename): <TAB> """"""Produce a dict of curl headers containing etag headers from the download."""""" <TAB> headers = {} <TAB> # If the download file already exists, add some headers to the request <TAB> # so we don't retrieve the content if it hasn't changed <TAB> if os.path.exists(filename): <TAB>  <TAB> self.existing_file_size = os.path.getsize(filename) <TAB>  <TAB> etag = self.getxattr(self.xattr_etag) <TAB>  <TAB> last_modified = self.getxattr(self.xattr_last_modified) <MASK> headers[""If-None-Match""] = etag <TAB>  <TAB> if last_modified: <TAB>  <TAB>  <TAB> headers[""If-Modified-Since""] = last_modified <TAB> return headers",if etag :,182
"def _find_orientation_offset(self, header): <TAB> (ifd_offset,) = self._unpack(""L"", header[4:]) <TAB> self.exif_buffer.seek(ifd_offset) <TAB> # Read tag directory <TAB> for _ in range(self._unpack(""H"", self.exif_buffer.read(2))[0]): <TAB>  <TAB> # Each tag is 12 bytes. HHL4s = tag, type, count, data <TAB>  <TAB> # Read tag and ignore the rest <TAB>  <TAB> (tag,) = self._unpack(""H10x"", self.exif_buffer.read(12)) <MASK> # Orientation tag <TAB>  <TAB>  <TAB> self._offset = ( <TAB>  <TAB>  <TAB>  <TAB> self.exif_buffer.tell() - 4 <TAB>  <TAB>  <TAB> )  # Back 4 bytes to the start of data <TAB>  <TAB>  <TAB> break",if tag == 0x0112 :,197
"def _start(self): <TAB> try: <TAB>  <TAB> await self.fire_event(""pre_request"") <TAB> except AbortEvent: <TAB>  <TAB> self.logger.debug(""Abort request %s"", self.request) <TAB> else: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> self.start_request() <TAB>  <TAB>  <TAB> except Exception as exc: <TAB>  <TAB>  <TAB>  <TAB> self.finished(exc=exc)",if self . _request is not None :,103
"def buildQueryRE(queryText, caseSensitive, wholeWord): <TAB> ""returns a RegEx pattern for searching for the given queryText"" <TAB> # word detection etc. cannot be done on an encoding-less string: <TAB> assert type(queryText) == unicode <TAB> pattern = re.escape(queryText) <TAB> if wholeWord: <MASK> pattern = ""\\b"" + pattern <TAB>  <TAB> if re.search(""\w$"", queryText, re.UNICODE): <TAB>  <TAB>  <TAB> pattern = pattern + ""\\b"" <TAB> flags = re.UNICODE <TAB> if not (caseSensitive): <TAB>  <TAB> flags |= re.IGNORECASE <TAB> return re.compile(pattern, flags)","if re . search ( ""^\w"" , queryText , re . UNICODE ) :",166
"def filter(callbackfn): <TAB> array = this.to_object() <TAB> arr_len = array.get(""length"").to_uint32() <TAB> if not callbackfn.is_callable(): <TAB>  <TAB> raise this.MakeError(""TypeError"", ""callbackfn must be a function"") <TAB> T = arguments[1] <TAB> res = [] <TAB> k = 0 <TAB> while k < arr_len: <MASK> kValue = array.get(str(k)) <TAB>  <TAB>  <TAB> if callbackfn.call(T, (kValue, this.Js(k), array)).to_boolean().value: <TAB>  <TAB>  <TAB>  <TAB> res.append(kValue) <TAB>  <TAB> k += 1 <TAB> return res  # converted to js array automatically",if array . has_property ( str ( k ) ) :,179
"def action(self, params): <TAB> if len(params) < 1: <TAB>  <TAB> return CommandsResponse(STATUS_ERROR, ""Not enough params"") <TAB> else: <TAB>  <TAB> vrf_name = params[0] <MASK> vrf_rf = params[1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> vrf_rf = ""ipv4"" <TAB>  <TAB> from ryu.services.protocols.bgp.operator.internal_api import WrongParamError <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return CommandsResponse( <TAB>  <TAB>  <TAB>  <TAB> STATUS_OK, self.api.count_single_vrf_routes(vrf_name, vrf_rf) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> except WrongParamError as e: <TAB>  <TAB>  <TAB> return WrongParamResp(e)",if len ( params ) == 2 :,187
"def __init__(self, layers): <TAB> super(Add, self).__init__() <TAB> self.layer_names = [] <TAB> self.layers = layers <TAB> for i, layer in enumerate(self.layers): <TAB>  <TAB> if layer.parent is None: <TAB>  <TAB>  <TAB> if i == 0: <TAB>  <TAB>  <TAB>  <TAB> layer.parent = ""input"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> layer.parent = layers[i - 1].name <MASK> name = layer.name <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = layer.__class__.__name__ + str(i) <TAB>  <TAB>  <TAB> layer.name = name <TAB>  <TAB> self.layer_names.append(name)","if hasattr ( layer , ""name"" ) :",165
"def _grouping_intervals(grouping): <TAB> last_interval = None <TAB> for interval in grouping: <TAB>  <TAB> # if grouping is -1, we are done <TAB>  <TAB> if interval == CHAR_MAX: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> # 0: re-use last group ad infinitum <TAB>  <TAB> if interval == 0: <MASK> raise ValueError(""invalid grouping"") <TAB>  <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB>  <TAB> yield last_interval <TAB>  <TAB> yield interval <TAB>  <TAB> last_interval = interval",if last_interval is None :,124
"def infer_expected_xp_and_device(self, x): <TAB> xp = backend.get_array_module(x) <TAB> if xp is np: <TAB>  <TAB> return xp, None <TAB> elif xp is cuda.cupy: <TAB>  <TAB> return xp, x.device <TAB> elif xp is chainerx: <TAB>  <TAB> backend_name = x.device.backend.name <MASK> return np, None <TAB>  <TAB> elif backend_name == ""cuda"": <TAB>  <TAB>  <TAB> return cuda.cupy, cuda.cupy.cuda.Device(x.device.index) <TAB> assert False","if backend_name == ""native"" :",142
"def _escape_attrib(text): <TAB> # escape attribute value <TAB> try: <TAB>  <TAB> if ""&"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""&"", ""&amp;"") <TAB>  <TAB> if ""<"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""<"", ""&lt;"") <MASK> text = text.replace("">"", ""&gt;"") <TAB>  <TAB> if '""' in text: <TAB>  <TAB>  <TAB> text = text.replace('""', ""&quot;"") <TAB>  <TAB> if ""\n"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""\n"", ""&#10;"") <TAB>  <TAB> return text <TAB> except (TypeError, AttributeError):  # pragma: no cover <TAB>  <TAB> _raise_serialization_error(text)","if "">"" in text :",160
"def get_block_id_at_height(store, height, descendant_id): <TAB> if height is None: <TAB>  <TAB> return None <TAB> while True: <TAB>  <TAB> block = store._load_block(descendant_id) <TAB>  <TAB> if block[""height""] == height: <TAB>  <TAB>  <TAB> return descendant_id <TAB>  <TAB> descendant_id = block[ <TAB>  <TAB>  <TAB> ""search_id"" <MASK> else ""prev_id"" <TAB>  <TAB> ]","if util . get_search_height ( block [ ""height"" ] ) >= height",122
"def train(config, checkpoint_dir=None): <TAB> if checkpoint_dir: <TAB>  <TAB> assert os.path.exists(checkpoint_dir) <TAB> for step in range(10): <MASK> with tune.checkpoint_dir(step=step) as checkpoint_dir: <TAB>  <TAB>  <TAB>  <TAB> path = os.path.join(checkpoint_dir, ""checkpoint"") <TAB>  <TAB>  <TAB>  <TAB> with open(path, ""w"") as f: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f.write(json.dumps({""step"": step})) <TAB>  <TAB> tune.report(test=step)",if step % 3 == 0 :,137
"def onMinimize(self, sender): <TAB> if self._runDialogListener(""onMinimize"") is False: <TAB>  <TAB> return <TAB> widget = self.child <TAB> if widget is not None: <TAB>  <TAB> if widget.isVisible(): <TAB>  <TAB>  <TAB> widget.setVisible(False) <TAB>  <TAB>  <TAB> self.setHeight("""") <TAB>  <TAB>  <TAB> self.setWidth("""") <TAB>  <TAB>  <TAB> if self._maximized: <TAB>  <TAB>  <TAB>  <TAB> self._minimized = self._maximized <TAB>  <TAB>  <TAB>  <TAB> self._toggleMaximize() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._minimized = None <TAB>  <TAB> else: <MASK> self._toggleMaximize() <TAB>  <TAB>  <TAB> widget.setVisible(True)",if self . _minimized is not None :,171
"def apply_transformation(self, ti: TransformationInput) -> Transformation: <TAB> # Insert fragments after the last line. <TAB> if ti.lineno == ti.document.line_count - 1: <TAB>  <TAB> buffer = ti.buffer_control.buffer <MASK> suggestion = buffer.suggestion.text <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> suggestion = """" <TAB>  <TAB> return Transformation(fragments=ti.fragments + [(self.style, suggestion)]) <TAB> else: <TAB>  <TAB> return Transformation(fragments=ti.fragments)",if buffer . suggestion and ti . document . is_cursor_at_the_end :,139
"def get_measurements(self, pipeline, object_name, category): <TAB> if object_name == IMAGE and category == C_COUNT: <TAB>  <TAB> return [self.object_name.value] <TAB> elif object_name == self.object_name: <MASK> return [ <TAB>  <TAB>  <TAB>  <TAB> FTR_CENTER_X, <TAB>  <TAB>  <TAB>  <TAB> FTR_CENTER_Y, <TAB>  <TAB>  <TAB> ] <TAB>  <TAB> elif category == C_NUMBER: <TAB>  <TAB>  <TAB> return [FTR_OBJECT_NUMBER] <TAB>  <TAB> elif category == C_WORMS: <TAB>  <TAB>  <TAB> return [F_ANGLE] <TAB> return []",if category == C_LOCATION :,151
"def traverse(tensors): <TAB> """"""traverse all ops to find attached workload"""""" <TAB> for t in tensors: <TAB>  <TAB> op = t.op <MASK> return args_to_workload(op.attrs[""workload""]) <TAB>  <TAB> wkl = traverse(op.input_tensors) <TAB>  <TAB> if wkl: <TAB>  <TAB>  <TAB> return wkl <TAB> return None","if ""workload"" in op . attrs :",97
"def _pack(converter, node: Any, inputs: List[str]) -> Any: <TAB> final_inputs = [] <TAB> for x_in in inputs: <TAB>  <TAB> input_c = converter.outputs[x_in] <MASK> final_inputs.append(_nodef_to_private_pond(converter, input_c)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> final_inputs.append(input_c) <TAB> return converter.protocol.stack(final_inputs, axis=node.attr[""axis""].i)","if isinstance ( input_c , tf . compat . v1 . NodeDef ) :",139
"def __init__(self, instance=None, data=empty, **kwargs): <TAB> context = kwargs.get(""context"", {}) <TAB> if ""product"" in context: <TAB>  <TAB> instance = self.get_instance(context, data, kwargs) <MASK> quantity = self.fields[""quantity""].to_internal_value(data[""quantity""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> quantity = self.fields[""quantity""].default <TAB>  <TAB> instance.setdefault(""quantity"", quantity) <TAB>  <TAB> super().__init__(instance, data, context=context) <TAB> else: <TAB>  <TAB> super().__init__(instance, data, **kwargs)","if data is not empty and ""quantity"" in data :",154
"def serialize(self, value): <TAB> if value is not None: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> iter(value) <TAB>  <TAB> except TypeError: <TAB>  <TAB>  <TAB> value = [value] <MASK> return [self.element_serialize(val) for val in sorted(value)] <TAB> return None",if len ( value ) :,77
"def remove_cloner_curve(self, obj_index): <TAB> # opportunity to remove the .cloner. <TAB> if self.selected_mode == ""Duplicate"": <TAB>  <TAB> curve_name = f""{self.basedata_name}.cloner.{obj_index:04d}"" <TAB>  <TAB> cu = bpy.data.curves.get(curve_name) <MASK> bpy.data.curves.remove(cu)",if cu :,107
"def update_advance_paid(self): <TAB> advance_paid = frappe._dict() <TAB> for d in self.get(""accounts""): <MASK> if d.reference_type in ( <TAB>  <TAB>  <TAB>  <TAB> ""Sales Order"", <TAB>  <TAB>  <TAB>  <TAB> ""Purchase Order"", <TAB>  <TAB>  <TAB>  <TAB> ""Employee Advance"", <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> advance_paid.setdefault(d.reference_type, []).append(d.reference_name) <TAB> for voucher_type, order_list in iteritems(advance_paid): <TAB>  <TAB> for voucher_no in list(set(order_list)): <TAB>  <TAB>  <TAB> frappe.get_doc(voucher_type, voucher_no).set_total_advance_paid()",if d . is_advance :,177
"def handle(self, msg): <TAB> self._mic.send(msg) <TAB> for calculate_seed, make_delegate, dict in self._delegate_records: <TAB>  <TAB> id = calculate_seed(msg) <TAB>  <TAB> if id is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif isinstance(id, collections.Hashable): <MASK> d = make_delegate((self, msg, id)) <TAB>  <TAB>  <TAB>  <TAB> d = self._ensure_startable(d) <TAB>  <TAB>  <TAB>  <TAB> dict[id] = d <TAB>  <TAB>  <TAB>  <TAB> dict[id].start() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> d = make_delegate((self, msg, id)) <TAB>  <TAB>  <TAB> d = self._ensure_startable(d) <TAB>  <TAB>  <TAB> d.start()",if id not in dict or not dict [ id ] . is_alive ( ) :,192
"def _get_default_factory(self, attribute_name: str) -> Any: <TAB> if hasattr(self, attribute_name): <TAB>  <TAB> if str(getattr(self, attribute_name)).startswith(""${""): <TAB>  <TAB>  <TAB> return str(getattr(self, attribute_name)) <MASK> return str(self.__dataclass_fields__[attribute_name].default) <TAB>  <TAB> elif ( <TAB>  <TAB>  <TAB> getattr(self, attribute_name) <TAB>  <TAB>  <TAB> != self.__dataclass_fields__[attribute_name].default_factory() <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> return getattr(self, attribute_name) <TAB> return self.__dataclass_fields__[attribute_name].default_factory()","elif str ( self . __dataclass_fields__ [ attribute_name ] . default ) . startswith ( ""${"" ) :",173
"def showMenu(self, show): <TAB> if show: <MASK> self.canvas.menu = Menu(self.canvas, tearoff=0) <TAB>  <TAB>  <TAB> self.canvas.menu.add_command(label=""delete"", command=self._delete) <TAB>  <TAB>  <TAB> self.canvas.menu.bind(""<FocusOut>"", lambda e: self.canvas.menu.unpost()) <TAB>  <TAB> self._bindMenu() <TAB> else: <TAB>  <TAB> # need to go through and unbind... <TAB>  <TAB> pass",if self . canvas . menu is None :,127
"def __init__(self, db, where=None): <TAB> self._db = db <TAB> self._tables = [] <TAB> self.filters = [] <TAB> if hasattr(where, ""get_all""): <TAB>  <TAB> self.where = where <TAB>  <TAB> self._tables.insert(0, where.get_all) <TAB> elif hasattr(where, ""get_one"") and isinstance(where.get_one, QueryException): <TAB>  <TAB> self.where = where.get_one <TAB> else: <TAB>  <TAB> # find out which tables are involved <MASK> self.filters = where.left <TAB>  <TAB> self.where = where <TAB>  <TAB> self._tables = [field._tablename for (field, op, val) in self.filters]","if isinstance ( where , Query ) :",174
"def main(): <TAB> try: <TAB>  <TAB> from wsgiref.simple_server import make_server <TAB>  <TAB> from wsgiref.validate import validator <MASK> port[0] = get_open_port() <TAB>  <TAB> wsgi_application = WsgiApplication(soap11_application) <TAB>  <TAB> server = make_server(host, port[0], validator(wsgi_application)) <TAB>  <TAB> logger.info(""Starting interop server at %s:%s."" % (""0.0.0.0"", port[0])) <TAB>  <TAB> logger.info(""WSDL is at: /?wsdl"") <TAB>  <TAB> server.serve_forever() <TAB> except ImportError: <TAB>  <TAB> print(""Error: example server code requires Python >= 2.5"")",if port [ 0 ] == 0 :,177
"def try_adjust_widgets(self): <TAB> if hasattr(self.parent, ""adjust_widgets""): <TAB>  <TAB> self.parent.adjust_widgets() <TAB> if hasattr(self.parent, ""parentApp""): <MASK> self.parent.parentApp._internal_adjust_widgets() <TAB>  <TAB> if hasattr(self.parent.parentApp, ""adjust_widgets""): <TAB>  <TAB>  <TAB> self.parent.parentApp.adjust_widgets()","if hasattr ( self . parent . parentApp , ""_internal_adjust_widgets"" ) :",118
"def copy_file_replace_line( <TAB> orig_file: Path, new_file: Path, line_re: str, new_line: str) -> None: <TAB> old_version_fh = orig_file.open(""r"") <TAB> new_version_fh = new_file.open(""w"") <TAB> for line in old_version_fh: <MASK> new_version_fh.write(new_line + ""\n"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_version_fh.write(line) <TAB> old_version_fh.close() <TAB> new_version_fh.close()","if re . search ( line_re , line ) :",154
"def _protoc_plugin_parameters(self, language): <TAB> """"""Return a tuple of (plugin path, vars) used as parameters for ninja build."""""" <TAB> path, vars = """", {} <TAB> for p in self.attr[""protoc_plugins""]: <MASK> path = p.path <TAB>  <TAB>  <TAB> flag = p.protoc_plugin_flag(self.build_dir) <TAB>  <TAB>  <TAB> vars = {""protoc%spluginflags"" % language: flag} <TAB>  <TAB>  <TAB> break <TAB> return path, vars",if language in p . code_generation :,125
"def scan_page(self, address_space, page_offset, fullpage=False): <TAB> """"""Runs through patchers for a single page"""""" <MASK> pagedata = address_space.read(page_offset, PAGESIZE) <TAB> for patcher in self.patchers: <TAB>  <TAB> for offset, data in patcher.get_constraints(): <TAB>  <TAB>  <TAB> if fullpage: <TAB>  <TAB>  <TAB>  <TAB> testdata = pagedata[offset : offset + len(data)] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> testdata = address_space.read(page_offset + offset, len(data)) <TAB>  <TAB>  <TAB> if data != testdata: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield patcher",if fullpage :,166
"def OnLeftDClick(self, event): <TAB> pt = event.GetPosition() <TAB> item, flags = self.tree.HitTest(pt) <TAB> if item: <TAB>  <TAB> self.log.WriteText(""OnLeftDClick: %s\n"" % self.tree.GetItemText(item)) <TAB>  <TAB> parent = self.tree.GetItemParent(item) <MASK> self.tree.SortChildren(parent) <TAB> event.Skip()",if parent . IsOk ( ) :,111
"def drop_pathlist(self, pathlist): <TAB> """"""Drop path list"""""" <TAB> if pathlist: <TAB>  <TAB> files = [""r'%s'"" % path for path in pathlist] <MASK> text = files[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> text = ""["" + "", "".join(files) + ""]"" <TAB>  <TAB> if self.new_input_line: <TAB>  <TAB>  <TAB> self.on_new_line() <TAB>  <TAB> self.insert_text(text) <TAB>  <TAB> self.setFocus()",if len ( files ) == 1 :,126
"def func_set_exporter_funcs_opset_yaml(func_set): <TAB> if len(list(func_set)[0].split(""@"")) == 1: <TAB>  <TAB> yaml_data = {} <TAB>  <TAB> for nnabla_func, impl_funcs in _onnx_func_info.items(): <MASK> yaml_data[nnabla_func] = impl_funcs <TAB>  <TAB> return yaml.dump(yaml_data, default_flow_style=False) <TAB> else: <TAB>  <TAB> return yaml.dump(list(func_set), default_flow_style=False)",if nnabla_func in func_set :,150
"def object_hook(obj): <TAB> obj_len = len(obj) <TAB> if obj_len == 1: <TAB>  <TAB> if ""$date"" in obj: <TAB>  <TAB>  <TAB> return datetime.fromtimestamp( <TAB>  <TAB>  <TAB>  <TAB> obj[""$date""] / 1000, tz=timezone.utc <TAB>  <TAB>  <TAB> ) + timedelta(milliseconds=obj[""$date""] % 1000) <TAB>  <TAB> if ""$time"" in obj: <TAB>  <TAB>  <TAB> return time(*[int(i) for i in obj[""$time""].split("":"")]) <TAB> if obj_len == 2 and ""$type"" in obj and ""$value"" in obj: <MASK> return date(*[int(i) for i in obj[""$value""].split(""-"")]) <TAB> return obj","if obj [ ""$type"" ] == ""date"" :",174
"def start(self, para=None, callback=None): <TAB> if not self.load(): <TAB>  <TAB> return <TAB> if para != None or self.show(): <TAB>  <TAB> if para == None: <TAB>  <TAB>  <TAB> para = self.para <TAB>  <TAB> win = WidgetsManager.getref(""Macros Recorder"") <MASK> win.write(""{}>{}"".format(self.title, para)) <TAB>  <TAB> if self.asyn and IPy.uimode() != ""no"": <TAB>  <TAB>  <TAB> threading.Thread(target=self.runasyn, args=(para, callback)).start() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.runasyn(para, callback)",if win != None :,159
"def user(self): <MASK> _env_username = os.getenv(""CONAN_USERNAME"") <TAB>  <TAB> conan_v2_error( <TAB>  <TAB>  <TAB> ""Environment variable 'CONAN_USERNAME' is deprecated"", _env_username <TAB>  <TAB> ) <TAB>  <TAB> self._conan_user = _env_username or self.default_user <TAB>  <TAB> if not self._conan_user: <TAB>  <TAB>  <TAB> raise ConanException(""user not defined, but self.user is used in conanfile"") <TAB> return self._conan_user",if not self . _conan_user :,134
"def _get_vars(cls, func): <TAB> # log.debug(""Getting vars for %s"", func) <TAB> params = inspect.signature(func).parameters.copy() <TAB> args = {} <TAB> # log.debug(""Got %s"", params) <TAB> for name, param in params.items(): <TAB>  <TAB> # log.debug(""Checking arg %s, type %s"", name, param.kind) <MASK> # log.debug(""Using var %s"", name) <TAB>  <TAB>  <TAB> args[name] = _get_variable(name) <TAB>  <TAB>  <TAB> # log.debug(""Collected var for arg '%s': %s"", name, args[name]) <TAB> return args",if param . kind is param . POSITIONAL_OR_KEYWORD and param . default is None :,176
def parts(self): <TAB> klass = self.__class__ <TAB> this = list() <TAB> for token in self: <TAB>  <TAB> if token.startswith_fws(): <TAB>  <TAB>  <TAB> if this: <TAB>  <TAB>  <TAB>  <TAB> yield this[0] if len(this) == 1 else klass(this) <TAB>  <TAB>  <TAB>  <TAB> this.clear() <TAB>  <TAB> end_ws = token.pop_trailing_ws() <TAB>  <TAB> this.append(token) <MASK> yield klass(this) <TAB>  <TAB>  <TAB> this = [end_ws] <TAB> if this: <TAB>  <TAB> yield this[0] if len(this) == 1 else klass(this),if end_ws :,153
"def start_fileoutput(self): <TAB> """"""Start output to configured file."""""" <TAB> path = os.path.dirname(self.filename) <TAB> try: <MASK> os.makedirs(path) <TAB>  <TAB> self.fd = self.create_fd() <TAB>  <TAB> self.close_fd = True <TAB> except IOError: <TAB>  <TAB> msg = sys.exc_info()[1] <TAB>  <TAB> log.warn( <TAB>  <TAB>  <TAB> LOG_CHECK, <TAB>  <TAB>  <TAB> ""Could not open file %r for writing: %s\n"" ""Disabling log output of %s"", <TAB>  <TAB>  <TAB> self.filename, <TAB>  <TAB>  <TAB> msg, <TAB>  <TAB>  <TAB> self, <TAB>  <TAB> ) <TAB>  <TAB> self.fd = dummy.Dummy() <TAB>  <TAB> self.is_active = False <TAB> self.filename = None",if path and not os . path . isdir ( path ) :,196
"def worksheet_id(self, value): <TAB> if self._worksheet: <MASK> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise InvalidArgumentValue( <TAB>  <TAB>  <TAB>  <TAB> ""This range already has a worksheet with different id set."" <TAB>  <TAB>  <TAB> ) <TAB> self._worksheet_id = value",if self . _worksheet . id == value :,82
"def _sanity_check(self, kind, triplets): <TAB> route_id = self.data.get(""route_id"", [None])[0] <TAB> if route_id or [ <TAB>  <TAB> k <TAB>  <TAB> for k in self.data.keys() <TAB>  <TAB> if k[:5] in (""route"", ""smtp-"", ""sourc"", ""secur"", ""local"") <TAB> ]: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Can only configure detailed settings "" ""for one profile at a time"" <TAB>  <TAB>  <TAB> )","if len ( triplets ) > 1 or kind != ""profile"" :",138
"def _process_property_change(self, msg): <TAB> msg = super(Select, self)._process_property_change(msg) <TAB> if ""value"" in msg: <MASK> pass <TAB>  <TAB> elif msg[""value""] is None: <TAB>  <TAB>  <TAB> msg[""value""] = self.values[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if isIn(msg[""value""], self.unicode_values): <TAB>  <TAB>  <TAB>  <TAB> idx = indexOf(msg[""value""], self.unicode_values) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> idx = indexOf(msg[""value""], self.labels) <TAB>  <TAB>  <TAB> msg[""value""] = self._items[self.labels[idx]] <TAB> msg.pop(""options"", None) <TAB> return msg",if not self . values :,180
"def emit(self, record): <TAB> msg = record.getMessage() <TAB> ### <TAB> if record.exc_info: <TAB>  <TAB> _type, value, tback = record.exc_info <TAB>  <TAB> tback_text = """".join(traceback.format_exception(_type, value, tback)) <MASK> msg += ""\n"" <TAB>  <TAB> msg += tback_text <TAB> ### <TAB> self.tktext.insert( <TAB>  <TAB> ""end"", <TAB>  <TAB> msg + ""\n"", <TAB>  <TAB> record.levelname, <TAB> )",if msg :,129
"def _get_pip_index_urls(sources): <TAB> index_urls = [] <TAB> trusted_hosts = [] <TAB> for source in sources: <TAB>  <TAB> url = source.get(""url"") <TAB>  <TAB> if not url: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> index_urls.append(url) <MASK> continue <TAB>  <TAB> host = six.moves.urllib.parse.urlparse(source[""url""]).hostname <TAB>  <TAB> trusted_hosts.append(host) <TAB> return index_urls, trusted_hosts","if source . get ( ""verify_ssl"" , True ) :",129
"def _is_binary(fname, limit=80): <TAB> try: <TAB>  <TAB> with open(fname, ""rb"") as f: <TAB>  <TAB>  <TAB> for i in range(limit): <TAB>  <TAB>  <TAB>  <TAB> char = f.read(1) <TAB>  <TAB>  <TAB>  <TAB> if char == b""\0"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <MASK> return False <TAB>  <TAB>  <TAB>  <TAB> if char == b"""": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return <TAB> except OSError as e: <TAB>  <TAB> if xp.ON_WINDOWS and is_app_execution_alias(fname): <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> raise e <TAB> return False","if char == b""\n"" :",154
"def tearDown(self): <TAB> exc, _, _ = sys.exc_info() <TAB> if exc: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if hasattr(self, ""obj"") and isinstance(self.obj, SelfDiagnosable): <TAB>  <TAB>  <TAB>  <TAB> diags = self.obj.get_error_diagnostics() <MASK> for line in diags: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ROOT_LOGGER.info(line) <TAB>  <TAB> except BaseException: <TAB>  <TAB>  <TAB> pass <TAB> if self.captured_logger: <TAB>  <TAB> self.captured_logger.removeHandler(self.log_recorder) <TAB>  <TAB> self.log_recorder.close() <TAB> sys.stdout = self.stdout_backup <TAB> super(BZTestCase, self).tearDown()",if diags :,179
"def _disconnect(self, sync): <MASK> if sync: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> self._connection.send_all() <TAB>  <TAB>  <TAB>  <TAB> self._connection.fetch_all() <TAB>  <TAB>  <TAB> except (WorkspaceError, ServiceUnavailable): <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> if self._connection: <TAB>  <TAB>  <TAB> self._connection.in_use = False <TAB>  <TAB>  <TAB> self._connection = None <TAB>  <TAB> self._connection_access_mode = None",if self . _connection :,115
"def _recursive_process(self): <TAB> super(RecursiveObjectDownwardsVisitor, self)._recursive_process() <TAB> while self._new_for_visit: <TAB>  <TAB> func_ea, arg_idx = self._new_for_visit.pop() <TAB>  <TAB> if helper.is_imported_ea(func_ea): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> cfunc = helper.decompile_function(func_ea) <MASK> assert arg_idx < len(cfunc.get_lvars()), ""Wrong argument at func {}"".format( <TAB>  <TAB>  <TAB>  <TAB> to_hex(func_ea) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> obj = VariableObject(cfunc.get_lvars()[arg_idx], arg_idx) <TAB>  <TAB>  <TAB> self.prepare_new_scan(cfunc, arg_idx, obj) <TAB>  <TAB>  <TAB> self._recursive_process()",if cfunc :,199
"def to_dict(self) -> JSONDict: <TAB> data = dict() <TAB> for key in iter(self.__dict__): <MASK> continue <TAB>  <TAB> value = self.__dict__[key] <TAB>  <TAB> if value is not None: <TAB>  <TAB>  <TAB> if hasattr(value, ""to_dict""): <TAB>  <TAB>  <TAB>  <TAB> data[key] = value.to_dict() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> data[key] = value <TAB> if data.get(""from_user""): <TAB>  <TAB> data[""from""] = data.pop(""from_user"", None) <TAB> return data","if key == ""bot"" or key . startswith ( ""_"" ) :",148
"def get_data(self, path, prefix=""""): <TAB> item = self.store[path] <TAB> path = ""{}/{}"".format(prefix, path) <TAB> keys = [i for i in item.keys()] <TAB> data = {""path"": path} <TAB> # print(path) <TAB> for k in keys: <MASK> dataset = np.array(item[k].value) <TAB>  <TAB>  <TAB> if type(dataset) is np.ndarray: <TAB>  <TAB>  <TAB>  <TAB> if dataset.size != 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if type(dataset[0]) is np.bytes_: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> dataset = [a.decode(""ascii"") for a in dataset] <TAB>  <TAB>  <TAB> data.update({k: dataset}) <TAB> return data","if not isinstance ( item [ k ] , h5py . Group ) :",183
"def _macros_of_type(root, type, el_func): <TAB> macros_el = root.find(""macros"") <TAB> macro_dict = {} <TAB> if macros_el is not None: <TAB>  <TAB> macro_els = macros_el.findall(""macro"") <TAB>  <TAB> filtered_els = [ <TAB>  <TAB>  <TAB> (macro_el.get(""name""), el_func(macro_el)) <TAB>  <TAB>  <TAB> for macro_el in macro_els <MASK> ] <TAB>  <TAB> macro_dict = dict(filtered_els) <TAB> return macro_dict","if macro_el . get ( ""type"" ) == type",140
"def get_referrers(self): <TAB> d = [] <TAB> for o in gc.get_referrers(self.obj): <TAB>  <TAB> name = None <MASK> name = web.dictfind(o, self.obj) <TAB>  <TAB>  <TAB> for r in gc.get_referrers(o): <TAB>  <TAB>  <TAB>  <TAB> if getattr(r, ""__dict__"", None) is o: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> o = r <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif isinstance(o, dict):  # other dict types <TAB>  <TAB>  <TAB> name = web.dictfind(o, self.obj) <TAB>  <TAB> if not isinstance(name, six.string_types): <TAB>  <TAB>  <TAB> name = None <TAB>  <TAB> d.append(Object(o, name)) <TAB> return d","if isinstance ( o , dict ) :",187
"def MakeWidthArray(fm): <TAB> # Make character width array <TAB> s = ""{\n\t"" <TAB> cw = fm[""Widths""] <TAB> for i in xrange(0, 256): <TAB>  <TAB> if chr(i) == ""'"": <TAB>  <TAB>  <TAB> s += ""'\\''"" <MASK> s += ""'\\\\'"" <TAB>  <TAB> elif i >= 32 and i <= 126: <TAB>  <TAB>  <TAB> s += ""'"" + chr(i) + ""'"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> s += ""chr(%d)"" % i <TAB>  <TAB> s += "":"" + fm[""Widths""][i] <TAB>  <TAB> if i < 255: <TAB>  <TAB>  <TAB> s += "","" <TAB>  <TAB> if (i + 1) % 22 == 0: <TAB>  <TAB>  <TAB> s += ""\n\t"" <TAB> s += ""}"" <TAB> return s","elif chr ( i ) == ""\\"" :",192
"def getLatestFile(self): <TAB> highestNsp = None <TAB> highestNsx = None <TAB> for nsp in self.getFiles(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if nsp.path.endswith("".nsx""): <MASK> highestNsx = nsp <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> if not highestNsp or int(nsp.version) > int(highestNsp.version): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> highestNsp = nsp <TAB>  <TAB> except BaseException: <TAB>  <TAB>  <TAB> pass <TAB> return highestNsp or highestNsx",if not highestNsx or int ( nsp . version ) > int ( highestNsx . version ) :,152
"def _check_integrity(self) -> bool: <TAB> # Allow original archive to be deleted (zip). Only need the extracted images <TAB> all_files = self.FILE_LIST.copy() <TAB> all_files.append(self.ANNOTATIONS_FILE) <TAB> for (_, md5, filename) in all_files: <TAB>  <TAB> file, ext = os.path.splitext(filename) <TAB>  <TAB> extracted_dir = os.path.join(self.root, file) <MASK> return False <TAB> return True",if not os . path . exists ( extracted_dir ) :,132
"def load_core(self): <TAB> for filename in os.listdir(self.path): <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> name = filename.replace("".py"", """") <TAB>  <TAB>  <TAB>  <TAB> mod = load_python_module(name, self.path) <TAB>  <TAB>  <TAB>  <TAB> self._load_cmd_from(mod) <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> warnings.warn( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""!! Warning: could not load core command file "" + filename, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> RuntimeWarning, <TAB>  <TAB>  <TAB>  <TAB> )","if filename != ""__init__.py"" and filename . endswith ( "".py"" ) :",142
"def _make_dataset(key, data, size): <TAB> if isinstance(data, chainer.get_array_types()): <TAB>  <TAB> if key is None: <TAB>  <TAB>  <TAB> key = ""_{}"".format(id(data)) <TAB>  <TAB> return _Array(key, data) <TAB> elif isinstance(data, list): <TAB>  <TAB> if key is None: <TAB>  <TAB>  <TAB> key = ""_{}"".format(id(data)) <TAB>  <TAB> return _List(key, data) <TAB> elif callable(data): <TAB>  <TAB> if key is None: <TAB>  <TAB>  <TAB> raise ValueError(""key(s) must be specified for callable"") <MASK> raise ValueError(""size must be specified for callable"") <TAB>  <TAB> return _Index(size).transform(key, data)",if size is None :,173
"def main_loop(self) -> None: <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> message = self.control.get(block=False) <TAB>  <TAB> except Empty: <TAB>  <TAB>  <TAB> message = None <TAB>  <TAB> if message == ""ABORT"": <TAB>  <TAB>  <TAB> self.log.info(""Got ABORT message, main_loop exiting..."") <TAB>  <TAB>  <TAB> break <MASK> self.log.error(""One or more watcher died, committing suicide!"") <TAB>  <TAB>  <TAB> sys.exit(1) <TAB>  <TAB> if self.all_workers_dead(): <TAB>  <TAB>  <TAB> self.log.error(""All workers have died, committing suicide!"") <TAB>  <TAB>  <TAB> sys.exit(1) <TAB>  <TAB> self.check_and_start_workers() <TAB>  <TAB> time.sleep(0.1)",if not self . all_watchers_running ( ) :,197
"def execute_map(cls, ctx, op): <TAB> (x,), device_id, xp = as_same_device( <TAB>  <TAB> [ctx[c.key] for c in op.inputs], op.device, ret_extra=True <TAB> ) <TAB> axis = cls.get_arg_axis(op.axis, op.inputs[0].ndim) <TAB> keepdims = op.keepdims <TAB> with device(device_id): <TAB>  <TAB> nz = xp.count_nonzero(x, axis=axis) <MASK> slcs = [slice(None)] * op.inputs[0].ndim <TAB>  <TAB>  <TAB> for ax in op.axis: <TAB>  <TAB>  <TAB>  <TAB> slcs[ax] = np.newaxis <TAB>  <TAB>  <TAB> nz = xp.asarray(nz)[tuple(slcs)] <TAB>  <TAB> ctx[op.outputs[0].key] = nz",if keepdims :,195
"def setfilter(self, f): <TAB> filter_exp = create_string_buffer(f.encode(""ascii"")) <TAB> if pcap_compile(self.pcap, byref(self.bpf_program), filter_exp, 0, -1) == -1: <TAB>  <TAB> error(""Could not compile filter expression %s"" % f) <TAB>  <TAB> return False <TAB> else: <MASK> error(""Could not install filter %s"" % f) <TAB>  <TAB>  <TAB> return False <TAB> return True","if pcap_setfilter ( self . pcap , byref ( self . bpf_program ) ) == - 1 :",141
"def find_parent_for_new_to(self, pos): <TAB> """"""Figure out the parent object for something at 'pos'."""""" <TAB> for children in self._editable_children: <TAB>  <TAB> if children._start <= pos < children._end: <TAB>  <TAB>  <TAB> return children.find_parent_for_new_to(pos) <MASK> return children.find_parent_for_new_to(pos) <TAB> return self",if children . _start == pos and pos == children . _end :,113
"def process_events(self, events): <TAB> for event in events: <TAB>  <TAB> key = (event.ident, event.filter) <MASK> self._force_wakeup.drain() <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> receiver = self._registered[key] <TAB>  <TAB> if event.flags & select.KQ_EV_ONESHOT: <TAB>  <TAB>  <TAB> del self._registered[key] <TAB>  <TAB> if type(receiver) is _core.Task: <TAB>  <TAB>  <TAB> _core.reschedule(receiver, outcome.Value(event)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> receiver.put_nowait(event)",if event . ident == self . _force_wakeup_fd :,154
"def test_tag(artifact_obj, sagemaker_session): <TAB> tag = {""Key"": ""foo"", ""Value"": ""bar""} <TAB> artifact_obj.set_tag(tag) <TAB> while True: <TAB>  <TAB> actual_tags = sagemaker_session.sagemaker_client.list_tags( <TAB>  <TAB>  <TAB> ResourceArn=artifact_obj.artifact_arn <TAB>  <TAB> )[""Tags""] <MASK> break <TAB>  <TAB> time.sleep(5) <TAB> # When sagemaker-client-config endpoint-url is passed as argument to hit some endpoints, <TAB> # length of actual tags will be greater than 1 <TAB> assert len(actual_tags) > 0 <TAB> assert actual_tags[0] == tag",if actual_tags :,170
"def initialize(self) -> None: <TAB> """"""Move the API keys from cog stored config to core bot config if they exist."""""" <TAB> imgur_token = await self.config.imgur_client_id() <TAB> if imgur_token is not None: <MASK> await self.bot.set_shared_api_tokens(""imgur"", client_id=imgur_token) <TAB>  <TAB> await self.config.imgur_client_id.clear()","if not await self . bot . get_shared_api_tokens ( ""imgur"" ) :",126
"def _sorted_layers(self, structure, top_layer_id): <TAB> """"""Return the image layers sorted"""""" <TAB> sorted_layers = [] <TAB> next_layer = top_layer_id <TAB> while next_layer: <TAB>  <TAB> sorted_layers.append(next_layer) <TAB>  <TAB> if ""json"" not in structure[""repolayers""][next_layer]:  # v2 <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if ""parent"" not in structure[""repolayers""][next_layer][""json""]: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> next_layer = structure[""repolayers""][next_layer][""json""][""parent""] <MASK> break <TAB> return sorted_layers",if not next_layer :,162
"def __init__(self, bounds, channel_axis, preprocess=None): <TAB> assert len(bounds) == 2 <TAB> assert channel_axis in [0, 1, 2, 3] <TAB> self._bounds = bounds <TAB> self._channel_axis = channel_axis <TAB> # Make self._preprocess to be (0,1) if possible, so that don't need <TAB> # to do substract or divide. <TAB> if preprocess is not None: <TAB>  <TAB> sub, div = np.array(preprocess) <MASK> sub = 0 <TAB>  <TAB> if np.all(div == 1): <TAB>  <TAB>  <TAB> div = 1 <TAB>  <TAB> assert (div is None) or np.all(div) <TAB>  <TAB> self._preprocess = (sub, div) <TAB> else: <TAB>  <TAB> self._preprocess = (0, 1)",if not np . any ( sub ) :,194
"def unpickle(fname): <TAB> """"""Load pickled object from `fname`"""""" <TAB> with smart_open(fname, ""rb"") as f: <TAB>  <TAB> # Because of loading from S3 load can't be used (missing readline in smart_open) <MASK> return _pickle.load(f, encoding=""latin1"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return _pickle.loads(f.read())","if sys . version_info > ( 3 , 0 ) :",105
"def get_new_setup_py_lines(): <TAB> global version <TAB> with open(""setup.py"", ""r"") as sf: <TAB>  <TAB> current_setup = sf.readlines() <TAB> for line in current_setup: <MASK> major, minor = re.findall(r""VERSION = '(\d+)\.(\d+)'"", line)[0] <TAB>  <TAB>  <TAB> version = ""{}.{}"".format(major, int(minor) + 1) <TAB>  <TAB>  <TAB> yield ""VERSION = '{}'\n"".format(version) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield line","if line . startswith ( ""VERSION = "" ) :",136
"def make_buffers_dict(observables): <TAB> """"""Makes observable states in a dict."""""" <TAB> # Use `type(observables)` so that our output structure respects the <TAB> # original dict subclass (e.g. OrderedDict). <TAB> out_dict = type(observables)() <TAB> for key, value in six.iteritems(observables): <MASK> out_dict[key] = _EnabledObservable( <TAB>  <TAB>  <TAB>  <TAB> value, physics, random_state, self._strip_singleton_buffer_dim <TAB>  <TAB>  <TAB> ) <TAB> return out_dict",if value . enabled :,137
"def _callFUT(self, config_file, global_conf=None, _loader=None): <TAB> import pyramid.paster <TAB> old_loader = pyramid.paster.get_config_loader <TAB> try: <MASK> pyramid.paster.get_config_loader = _loader <TAB>  <TAB> return pyramid.paster.setup_logging(config_file, global_conf) <TAB> finally: <TAB>  <TAB> pyramid.paster.get_config_loader = old_loader",if _loader is not None :,125
"def _csv(self, match=None, dump=None): <TAB> if dump is None: <TAB>  <TAB> dump = self._dump(match) <TAB> for record in dump: <TAB>  <TAB> row = [] <TAB>  <TAB> for field in record: <MASK> row.append(""%i"" % field) <TAB>  <TAB>  <TAB> elif field is None: <TAB>  <TAB>  <TAB>  <TAB> row.append("""") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> row.append(""'%s'"" % field) <TAB>  <TAB> yield "","".join(row)","if isinstance ( field , int ) :",126
"def preprocess_envs(args_envs): <TAB> envs_map = {} <TAB> for item in args_envs: <TAB>  <TAB> i = item.find("":"") <MASK> key = item[:i] <TAB>  <TAB>  <TAB> val = item[i + 1 :] <TAB>  <TAB> envs_map[key] = val <TAB> return envs_map",if i != - 1 :,83
"def _get_most_recent_update(self, versions): <TAB> recent = None <TAB> for version in versions: <TAB>  <TAB> updated = datetime.datetime.strptime(version[""updated""], ""%Y-%m-%dT%H:%M:%SZ"") <MASK> recent = updated <TAB>  <TAB> elif updated > recent: <TAB>  <TAB>  <TAB> recent = updated <TAB> return recent.strftime(""%Y-%m-%dT%H:%M:%SZ"")",if not recent :,103
"def _to_string_infix(self, ostream, idx, verbose): <TAB> if verbose: <TAB>  <TAB> ostream.write("" , "") <TAB> else: <MASK> ostream.write("" - "") <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ostream.write("" + "")",if type ( self . _args [ idx ] ) is _NegationExpression :,90
"def __init__(self, bert, num_classes=2, dropout=0.0, prefix=None, params=None): <TAB> super(BERTClassifier, self).__init__(prefix=prefix, params=params) <TAB> self.bert = bert <TAB> with self.name_scope(): <TAB>  <TAB> self.classifier = nn.HybridSequential(prefix=prefix) <MASK> self.classifier.add(nn.Dropout(rate=dropout)) <TAB>  <TAB> self.classifier.add(nn.Dense(units=num_classes))",if dropout :,124
"def __iter__(self): <TAB> for i, field in enumerate(self.fields): <MASK> yield AdminReadonlyField( <TAB>  <TAB>  <TAB>  <TAB> self.form, field, is_first=(i == 0), model_admin=self.model_admin <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield AdminField(self.form, field, is_first=(i == 0))",if field in self . readonly_fields :,102
"def boolean(value): <TAB> if isinstance(value, str): <TAB>  <TAB> v = value.lower() <MASK> return True <TAB>  <TAB> if v in (""0"", ""no"", ""false"", ""off""): <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> raise ValueError(value) <TAB> return bool(value)","if v in ( ""1"" , ""yes"" , ""true"" , ""on"" ) :",87
"def xdir(obj, return_values=False): <TAB> for attr in dir(obj): <MASK> if return_values: <TAB>  <TAB>  <TAB>  <TAB> yield attr, getattr(obj, attr) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield attr","if attr [ : 2 ] != ""__"" and attr [ - 2 : ] != ""__"" :",76
"def get_current_stock(self): <TAB> for d in self.get(""supplied_items""): <MASK> bin = frappe.db.sql( <TAB>  <TAB>  <TAB>  <TAB> ""select actual_qty from `tabBin` where item_code = %s and warehouse = %s"", <TAB>  <TAB>  <TAB>  <TAB> (d.rm_item_code, self.supplier_warehouse), <TAB>  <TAB>  <TAB>  <TAB> as_dict=1, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> d.current_stock = bin and flt(bin[0][""actual_qty""]) or 0",if self . supplier_warehouse :,138
"def getvars(request, excludes): <TAB> getvars = request.GET.copy() <TAB> excludes = excludes.split("","") <TAB> for p in excludes: <MASK> del getvars[p] <TAB>  <TAB> if len(getvars.keys()) > 0: <TAB>  <TAB>  <TAB> return ""&%s"" % getvars.urlencode() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return """"",if p in getvars :,94
"def read(cls, reader, dump=None): <TAB> code = reader.read_u1() <TAB> # Create an index of all known opcodes. <TAB> if Opcode.opcodes is None: <TAB>  <TAB> Opcode.opcodes = {} <TAB>  <TAB> for name in globals(): <TAB>  <TAB>  <TAB> klass = globals()[name] <TAB>  <TAB>  <TAB> try: <MASK> Opcode.opcodes[klass.code] = klass <TAB>  <TAB>  <TAB> except TypeError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB> instance = Opcode.opcodes[code].read_extra(reader, dump) <TAB> if dump: <TAB>  <TAB> reader.debug("" <TAB> "" * dump, ""%3d: %s"" % (reader.offset, instance)) <TAB> return instance","if name != ""Opcode"" and issubclass ( klass , Opcode ) :",181
"def clean(self): <TAB> username = self.cleaned_data.get(""username"") <TAB> password = self.cleaned_data.get(""password"") <TAB> message = ERROR_MESSAGE <TAB> if username and password: <TAB>  <TAB> self.user_cache = authenticate(username=username, password=password) <MASK> raise ValidationError( <TAB>  <TAB>  <TAB>  <TAB> message % {""username"": self.username_field.verbose_name} <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> elif not self.user_cache.is_active or not self.user_cache.is_staff: <TAB>  <TAB>  <TAB> raise ValidationError( <TAB>  <TAB>  <TAB>  <TAB> message % {""username"": self.username_field.verbose_name} <TAB>  <TAB>  <TAB> ) <TAB> return self.cleaned_data",if self . user_cache is None :,177
"def currentLevel(self): <TAB> currentStr = """" <TAB> for stackType, stackValue in self.stackVals: <TAB>  <TAB> if stackType == ""dict"": <TAB>  <TAB>  <TAB> if isinstance(stackValue, str): <TAB>  <TAB>  <TAB>  <TAB> currentStr += ""['"" + stackValue + ""']"" <TAB>  <TAB>  <TAB> else:  # numeric key... <TAB>  <TAB>  <TAB>  <TAB> currentStr += ""["" + str(stackValue) + ""]"" <MASK> currentStr += ""["" + str(stackValue) + ""]"" <TAB>  <TAB> elif stackType == ""getattr"": <TAB>  <TAB>  <TAB> currentStr += "".__getattribute__('"" + stackValue + ""')"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception(f""Cannot get attribute of type {stackType}"") <TAB> return currentStr","elif stackType == ""listLike"" :",176
"def dump(self, out=sys.stdout, code2cid=None, code=None): <TAB> if code2cid is None: <TAB>  <TAB> code2cid = self.code2cid <TAB>  <TAB> code = () <TAB> for (k, v) in sorted(code2cid.iteritems()): <TAB>  <TAB> c = code + (k,) <MASK> out.write(""code %r = cid %d\n"" % (c, v)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.dump(out=out, code2cid=v, code=c) <TAB> return","if isinstance ( v , int ) :",140
"def __init__(self, text, menu): <TAB> self.text = text <TAB> self.menu = menu <TAB> print(text) <TAB> for i, option in enumerate(menu): <TAB>  <TAB> menunum = i + 1 <TAB>  <TAB> # Check to see if this line has the 'return to main menu' code <TAB>  <TAB> match = re.search(""0D"", option) <TAB>  <TAB> # If it's not the return to menu line: <TAB>  <TAB> if not match: <MASK> print((""   %s) %s"" % (menunum, option))) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> print((""  %s) %s"" % (menunum, option))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""\n  99) Return to Main Menu\n"") <TAB> return",if menunum < 10 :,193
"def receive(self, sock): <TAB> """"""Receive a message on ``sock``."""""" <TAB> msg = None <TAB> data = b"""" <TAB> recv_done = False <TAB> recv_len = -1 <TAB> while not recv_done: <TAB>  <TAB> buf = sock.recv(BUFSIZE) <TAB>  <TAB> if buf is None or len(buf) == 0: <TAB>  <TAB>  <TAB> raise Exception(""socket closed"") <MASK> recv_len = struct.unpack("">I"", buf[:4])[0] <TAB>  <TAB>  <TAB> data += buf[4:] <TAB>  <TAB>  <TAB> recv_len -= len(data) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> data += buf <TAB>  <TAB>  <TAB> recv_len -= len(buf) <TAB>  <TAB> recv_done = recv_len == 0 <TAB> msg = pickle.loads(data) <TAB> return msg",if recv_len == - 1 :,192
"def apply_shortcuts(self): <TAB> """"""Apply shortcuts settings to all widgets/plugins"""""" <TAB> toberemoved = [] <TAB> for index, (qobject, context, name, default) in enumerate(self.shortcut_data): <TAB>  <TAB> keyseq = QKeySequence(get_shortcut(context, name, default)) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if isinstance(qobject, QAction): <TAB>  <TAB>  <TAB>  <TAB> qobject.setShortcut(keyseq) <MASK> qobject.setKey(keyseq) <TAB>  <TAB> except RuntimeError: <TAB>  <TAB>  <TAB> # Object has been deleted <TAB>  <TAB>  <TAB> toberemoved.append(index) <TAB> for index in sorted(toberemoved, reverse=True): <TAB>  <TAB> self.shortcut_data.pop(index)","elif isinstance ( qobject , QShortcut ) :",184
"def _resolved_values(self): <TAB> values = [] <TAB> for k, v in self.values.items() if hasattr(self.values, ""items"") else self.values: <MASK> if isinstance(k, util.string_types): <TAB>  <TAB>  <TAB>  <TAB> desc = _entity_descriptor(self.mapper, k) <TAB>  <TAB>  <TAB>  <TAB> values.extend(desc._bulk_update_tuples(v)) <TAB>  <TAB>  <TAB> elif isinstance(k, attributes.QueryableAttribute): <TAB>  <TAB>  <TAB>  <TAB> values.extend(k._bulk_update_tuples(v)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> values.append((k, v)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> values.append((k, v)) <TAB> return values",if self . mapper :,176
"def remove_callback(self, callback, events=None): <TAB> if events is None: <TAB>  <TAB> for event in self._plugin_lifecycle_callbacks: <MASK> self._plugin_lifecycle_callbacks[event].remove(callback) <TAB> else: <TAB>  <TAB> if isinstance(events, basestring): <TAB>  <TAB>  <TAB> events = [events] <TAB>  <TAB> for event in events: <TAB>  <TAB>  <TAB> if callback in self._plugin_lifecycle_callbacks[event]: <TAB>  <TAB>  <TAB>  <TAB> self._plugin_lifecycle_callbacks[event].remove(callback)",if callback in self . _plugin_lifecycle_callbacks [ event ] :,148
"def _thd_parse_volumes(self, volumes): <TAB> volume_list = [] <TAB> binds = {} <TAB> for volume_string in volumes or []: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> bind, volume = volume_string.split("":"", 1) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> config.error( <TAB>  <TAB>  <TAB>  <TAB> ""Invalid volume definition for docker "" <TAB>  <TAB>  <TAB>  <TAB> ""%s. Skipping..."" % volume_string <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> ro = False <MASK> ro = volume[-2:] == ""ro"" <TAB>  <TAB>  <TAB> volume = volume[:-3] <TAB>  <TAB> volume_list.append(volume) <TAB>  <TAB> binds[bind] = {""bind"": volume, ""ro"": ro} <TAB> return volume_list, binds","if volume . endswith ( "":ro"" ) or volume . endswith ( "":rw"" ) :",191
"def __init__(self, model, **kwargs): <TAB> self.model = model <TAB> for key, value in kwargs.items(): <MASK> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""%s() received an invalid keyword %r"" % (self.__class__.__name__, key) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> setattr(self, key, value) <TAB> self.handle_model()","if not hasattr ( self , key ) :",97
"def __getitem__(self, key): <TAB> if isinstance(key, numbers.Number): <TAB>  <TAB> l = len(self) <TAB>  <TAB> if key >= l: <TAB>  <TAB>  <TAB> raise IndexError(""Index %s out of range (%s elements)"" % (key, l)) <TAB>  <TAB> if key < 0: <MASK> raise IndexError(""Index %s out of range (%s elements)"" % (key, l)) <TAB>  <TAB>  <TAB> key += l <TAB>  <TAB> return self(key + 1) <TAB> elif isinstance(key, slice): <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> self.impl.__class__.__name__ + "" object does not support slicing"" <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> return self(key)",if key < - l :,170
"def _get_formatted(self, model, key): <TAB> value = model._type(key).format(model.get(key)) <TAB> if isinstance(value, bytes): <TAB>  <TAB> value = value.decode(""utf-8"", ""ignore"") <TAB> if self.for_path: <TAB>  <TAB> sep_repl = beets.config[""path_sep_replace""].as_str() <TAB>  <TAB> for sep in (os.path.sep, os.path.altsep): <MASK> value = value.replace(sep, sep_repl) <TAB> return value",if sep :,133
"def publish(self, name, stat): <TAB> try: <TAB>  <TAB> topic = ""stat.%s"" % str(name) <MASK> topic += "".%d"" % stat[""subtopic""] <TAB>  <TAB> stat = json.dumps(stat) <TAB>  <TAB> logger.debug(""Sending %s"" % stat) <TAB>  <TAB> self.socket.send_multipart([b(topic), stat]) <TAB> except zmq.ZMQError: <TAB>  <TAB> if self.socket.closed: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise","if ""subtopic"" in stat :",130
def logic(): <TAB> while 1: <TAB>  <TAB> yield a <TAB>  <TAB> var = 0 <TAB>  <TAB> out.next = 0 <TAB>  <TAB> for i in downrange(len(a)): <TAB>  <TAB>  <TAB> if a[i] == 0: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> for j in downrange(i - 1): <MASK> pass <TAB>  <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> out.next = j <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB>  <TAB> break,if a [ j ] == 0 :,136
"def get_abstract_models(self, appmodels): <TAB> abstract_models = [] <TAB> for appmodel in appmodels: <TAB>  <TAB> abstract_models += [ <TAB>  <TAB>  <TAB> abstract_model <TAB>  <TAB>  <TAB> for abstract_model in appmodel.__bases__ <MASK> ] <TAB> abstract_models = list(set(abstract_models))  # remove duplicates <TAB> return abstract_models","if hasattr ( abstract_model , ""_meta"" ) and abstract_model . _meta . abstract",108
"def _sanitize_field_name(self, field_name: str) -> str: <TAB> try: <TAB>  <TAB> if self._meta.get_field(field_name).get_internal_type() == ""ForeignKey"": <MASK> return field_name + ""_id"" <TAB> except FieldDoesNotExist: <TAB>  <TAB> pass <TAB> return field_name","if not field_name . endswith ( ""_id"" ) :",92
"def find_enabled_item(self, e): <TAB> x, y = e.local <TAB> if ( <TAB>  <TAB> 0 <TAB>  <TAB> <= x <TAB>  <TAB> < ( <TAB>  <TAB>  <TAB> self.width - self.margin - self.scroll_button_size <TAB>  <TAB>  <TAB> if self.scrolling <TAB>  <TAB>  <TAB> else self.width <TAB>  <TAB> ) <TAB> ): <TAB>  <TAB> h = self.font.get_linesize() <TAB>  <TAB> i = (y - h // 2) // h + self.scroll <TAB>  <TAB> items = self._items <MASK> item = items[i] <TAB>  <TAB>  <TAB> if item.enabled: <TAB>  <TAB>  <TAB>  <TAB> return item",if 0 <= i < len ( items ) :,160
"def addColumn(self, *cols, index=None): <TAB> ""Insert all *cols* into columns at *index*, or append to end of columns if *index* is None.  Return first column."" <TAB> for i, col in enumerate(cols): <TAB>  <TAB> vd.addUndo(self.columns.remove, col) <MASK> index = len(self.columns) <TAB>  <TAB> col.recalc(self) <TAB>  <TAB> self.columns.insert(index + i, col) <TAB>  <TAB> Sheet.visibleCols.fget.cache_clear() <TAB> return cols[0]",if index is None :,141
"def _compare_values(self, result, source): <TAB> from google.protobuf.struct_pb2 import ListValue <TAB> from google.protobuf.struct_pb2 import Value <TAB> for found, expected in zip(result, source): <TAB>  <TAB> self.assertIsInstance(found, ListValue) <TAB>  <TAB> self.assertEqual(len(found.values), len(expected)) <TAB>  <TAB> for found_cell, expected_cell in zip(found.values, expected): <TAB>  <TAB>  <TAB> self.assertIsInstance(found_cell, Value) <MASK> self.assertEqual(int(found_cell.string_value), expected_cell) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(found_cell.string_value, expected_cell)","if isinstance ( expected_cell , int ) :",179
"def _traverse(op): <TAB> if topi.tag.is_broadcast(op.tag): <TAB>  <TAB> if not op.same_as(output.op): <TAB>  <TAB>  <TAB> if not op.axis: <TAB>  <TAB>  <TAB>  <TAB> const_ops.append(op) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> ewise_ops.append(op) <TAB>  <TAB> for tensor in op.input_tensors: <MASK> ewise_inputs.append((op, tensor)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> _traverse(tensor.op) <TAB> else: <TAB>  <TAB> assert op.tag == ""dense_pack"" <TAB>  <TAB> dense_res.append(op)","if isinstance ( tensor . op , tvm . te . PlaceholderOp ) :",174
"def update_annotation( <TAB> parameters: Sequence[cst.Param], annotations: Sequence[cst.Param]) -> List[cst.Param]: <TAB> parameter_annotations = {} <TAB> annotated_parameters = [] <TAB> for parameter in annotations: <MASK> parameter_annotations[parameter.name.value] = parameter.annotation <TAB> for parameter in parameters: <TAB>  <TAB> key = parameter.name.value <TAB>  <TAB> if key in parameter_annotations and ( <TAB>  <TAB>  <TAB> self.overwrite_existing_annotations or not parameter.annotation <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> parameter = parameter.with_changes(annotation=parameter_annotations[key]) <TAB>  <TAB> annotated_parameters.append(parameter) <TAB> return annotated_parameters",if parameter . annotation :,167
"def _modules(self, module_paths, component_name): <TAB> for path in module_paths: <TAB>  <TAB> for filename in os.listdir(path): <TAB>  <TAB>  <TAB> name, ext = os.path.splitext(filename) <MASK> root_relative_path = os.path.join(path, name)[ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> len(self.root_path) + len(os.path.sep) : <TAB>  <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB>  <TAB> module_name = ""%s.%s"" % ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> component_name, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> root_relative_path.replace(os.path.sep, "".""), <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> yield module_name","if ext . endswith ( "".py"" ) :",176
"def run(self): <TAB> # Make some objects emit lights <TAB> for obj in bpy.context.scene.objects: <TAB>  <TAB> if ""modelId"" in obj: <TAB>  <TAB>  <TAB> obj_id = obj[""modelId""] <TAB>  <TAB>  <TAB> # In the case of the lamp <MASK> self._make_lamp_emissive(obj, self.lights[obj_id]) <TAB>  <TAB>  <TAB> # Make the windows emit light <TAB>  <TAB>  <TAB> if obj_id in self.windows: <TAB>  <TAB>  <TAB>  <TAB> self._make_window_emissive(obj) <TAB>  <TAB>  <TAB> # Also make ceilings slightly emit light <TAB>  <TAB>  <TAB> if obj.name.startswith(""Ceiling#""): <TAB>  <TAB>  <TAB>  <TAB> self._make_ceiling_emissive(obj)",if obj_id in self . lights :,190
"def get_chart_data(self): <TAB> rows = [] <TAB> for row in self.data: <TAB>  <TAB> row = frappe._dict(row) <MASK> values = [row.range1, row.range2, row.range3, row.range4, row.range5] <TAB>  <TAB>  <TAB> precision = cint(frappe.db.get_default(""float_precision"")) or 2 <TAB>  <TAB>  <TAB> rows.append({""values"": [flt(val, precision) for val in values]}) <TAB> self.chart = { <TAB>  <TAB> ""data"": {""labels"": self.ageing_column_labels, ""datasets"": rows}, <TAB>  <TAB> ""type"": ""percentage"", <TAB> }",if not cint ( row . bold ) :,171
"def suite(aggressive): <TAB> """"""Run against pep8 test suite."""""" <TAB> result = True <TAB> path = os.path.join(os.path.dirname(__file__), ""suite"") <TAB> for filename in os.listdir(path): <TAB>  <TAB> filename = os.path.join(path, filename) <MASK> print(filename, file=sys.stderr) <TAB>  <TAB>  <TAB> result = run(filename, aggressive=aggressive) and result <TAB> if result: <TAB>  <TAB> print(GREEN + ""Okay"" + END) <TAB> return result","if filename . endswith ( "".py"" ) :",133
"def list_generator(pages, num_results): <TAB> result = [] <TAB> # get first page items <TAB> page = list(next(pages)) <TAB> result += page <TAB> while True: <MASK> break <TAB>  <TAB> # handle num results <TAB>  <TAB> if num_results is not None: <TAB>  <TAB>  <TAB> if num_results == len(result): <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> page = list(next(pages)) <TAB>  <TAB> result += page <TAB> return result",if not pages . continuation_token :,118
"def _detect_too_many_digits(f): <TAB> ret = [] <TAB> for node in f.nodes: <TAB>  <TAB> # each node contains a list of IR instruction <TAB>  <TAB> for ir in node.irs: <TAB>  <TAB>  <TAB> # iterate over all the variables read by the IR <TAB>  <TAB>  <TAB> for read in ir.read: <TAB>  <TAB>  <TAB>  <TAB> # if the variable is a constant <TAB>  <TAB>  <TAB>  <TAB> if isinstance(read, Constant): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # read.value can return an int or a str. Convert it to str <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value_as_str = read.original_value <MASK> # Info to be printed <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ret.append(node) <TAB> return ret","if ""00000"" in value_as_str :",183
"def write_varint(trans, n): <TAB> out = [] <TAB> while True: <MASK> out.append(n) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> out.append((n & 0xFF) | 0x80) <TAB>  <TAB>  <TAB> n = n >> 7 <TAB> data = array.array(""B"", out).tostring() <TAB> if PY3: <TAB>  <TAB> trans.write(data) <TAB> else: <TAB>  <TAB> trans.write(bytes(data))",if n & ~ 0x7F == 0 :,126
"def __call__(self, environ, start_response): <TAB> query_string = environ.get(""QUERY_STRING"") <TAB> if ""sql_debug=1"" in query_string: <TAB>  <TAB> import galaxy.app <MASK> galaxy.app.app.model.thread_local_log.log = True <TAB> try: <TAB>  <TAB> reset_request_query_counts() <TAB>  <TAB> return self.application(environ, start_response) <TAB> finally: <TAB>  <TAB> log_request_query_counts(environ.get(""PATH_INFO""))",if galaxy . app . app . model . thread_local_log :,146
"def SvGetSocketInfo(socket): <TAB> """"""returns string to show in socket label"""""" <TAB> global socket_data_cache <TAB> ng = socket.id_data.tree_id <TAB> if socket.is_output: <TAB>  <TAB> s_id = socket.socket_id <TAB> elif socket.is_linked: <TAB>  <TAB> other = socket.other <TAB>  <TAB> if other and hasattr(other, ""socket_id""): <TAB>  <TAB>  <TAB> s_id = other.socket_id <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return """" <TAB> else: <TAB>  <TAB> return """" <TAB> if ng in socket_data_cache: <TAB>  <TAB> if s_id in socket_data_cache[ng]: <TAB>  <TAB>  <TAB> data = socket_data_cache[ng][s_id] <MASK> return str(len(data)) <TAB> return """"",if data :,197
"def print_nested_help(self, args: argparse.Namespace) -> None: <TAB> level = 0 <TAB> parser = self.main_parser <TAB> while True: <TAB>  <TAB> if parser._subparsers is None: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if parser._subparsers._actions is None: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> choices = parser._subparsers._actions[-1].choices <TAB>  <TAB> value = getattr(args, ""level_%d"" % level) <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB> parser.print_help() <TAB>  <TAB>  <TAB> return <TAB>  <TAB> if not choices: <TAB>  <TAB>  <TAB> break <MASK> parser = choices[value] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> level += 1","if isinstance ( choices , dict ) :",175
"def tag_configure(self, *args, **keys): <TAB> trace = False and not g.unitTesting <TAB> if trace: <TAB>  <TAB> g.trace(args, keys) <TAB> if len(args) == 1: <TAB>  <TAB> key = args[0] <TAB>  <TAB> self.tags[key] = keys <TAB>  <TAB> val = keys.get(""foreground"") <TAB>  <TAB> underline = keys.get(""underline"") <TAB>  <TAB> if val: <TAB>  <TAB>  <TAB> self.configDict[key] = val <MASK> self.configUnderlineDict[key] = True <TAB> else: <TAB>  <TAB> g.trace(""oops"", args, keys)",if underline :,150
"def get_tokens_unprocessed(self, text): <TAB> for index, token, value in RegexLexer.get_tokens_unprocessed(self, text): <TAB>  <TAB> if token is Name: <MASK> token = Keyword.Type <TAB>  <TAB>  <TAB> elif self.c99highlighting and value in self.c99_types: <TAB>  <TAB>  <TAB>  <TAB> token = Keyword.Type <TAB>  <TAB>  <TAB> elif self.platformhighlighting and value in self.linux_types: <TAB>  <TAB>  <TAB>  <TAB> token = Keyword.Type <TAB>  <TAB> yield index, token, value",if self . stdlibhighlighting and value in self . stdlib_types :,141
"def materialize_as_ndarray(a): <TAB> """"""Convert distributed arrays to ndarrays."""""" <TAB> if type(a) in (list, tuple): <MASK> return da.compute(*a, sync=True) <TAB>  <TAB> return tuple(np.asarray(arr) for arr in a) <TAB> return np.asarray(a)","if da is not None and any ( isinstance ( arr , da . Array ) for arr in a ) :",98
"def decorated_function(*args, **kwargs): <TAB> rv = f(*args, **kwargs) <TAB> if isinstance(rv, flask.Response): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> result = etag <TAB>  <TAB>  <TAB> if callable(result): <TAB>  <TAB>  <TAB>  <TAB> result = result(rv) <MASK> rv.set_etag(result) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> logging.getLogger(__name__).exception( <TAB>  <TAB>  <TAB>  <TAB> ""Error while calculating the etag value for response {!r}"".format(rv) <TAB>  <TAB>  <TAB> ) <TAB> return rv",if result :,133
"def applyBC(self): <TAB> """"""apply boundary conditions"""""" <TAB> deltaR = 2.0 <TAB> for coord in self.pos: <MASK> coord[0] = -deltaR <TAB>  <TAB> if coord[0] < -deltaR: <TAB>  <TAB>  <TAB> coord[0] = width + deltaR <TAB>  <TAB> if coord[1] > height + deltaR: <TAB>  <TAB>  <TAB> coord[1] = -deltaR <TAB>  <TAB> if coord[1] < -deltaR: <TAB>  <TAB>  <TAB> coord[1] = height + deltaR",if coord [ 0 ] > width + deltaR :,135
"def removeInsideIslands(self): <TAB> self.CleanPath = [] <TAB> cleanpath = Path(""Path"") <TAB> for path in self.NewPaths: <TAB>  <TAB> for seg in path: <TAB>  <TAB>  <TAB> inside = False <TAB>  <TAB>  <TAB> for island in self.IntersectedIslands: <TAB>  <TAB>  <TAB>  <TAB> issegin = island.isSegInside(seg) == 1 <TAB>  <TAB>  <TAB>  <TAB> if issegin: <MASK> inside = True <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> if not inside: <TAB>  <TAB>  <TAB>  <TAB> cleanpath.append(seg) <TAB> cleanpath = cleanpath.split2contours() <TAB> self.CleanPath.extend(cleanpath)",if not seg in island :,176
"def _parse_lines(self, linesource): <TAB> """"""Parse lines of text for functions and classes"""""" <TAB> functions = [] <TAB> classes = [] <TAB> for line in linesource: <TAB>  <TAB> if line.startswith(""def "") and line.count(""(""): <TAB>  <TAB>  <TAB> # exclude private stuff <TAB>  <TAB>  <TAB> name = self._get_object_name(line) <MASK> functions.append(name) <TAB>  <TAB> elif line.startswith(""class ""): <TAB>  <TAB>  <TAB> # exclude private stuff <TAB>  <TAB>  <TAB> name = self._get_object_name(line) <TAB>  <TAB>  <TAB> if not name.startswith(""_""): <TAB>  <TAB>  <TAB>  <TAB> classes.append(name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pass <TAB> functions.sort() <TAB> classes.sort() <TAB> return functions, classes","if not name . startswith ( ""_"" ) :",185
"def process(self, buckets, event=None): <TAB> results = [] <TAB> with self.executor_factory(max_workers=2) as w: <TAB>  <TAB> futures = {w.submit(self.process_bucket, bucket): bucket for bucket in buckets} <TAB>  <TAB> for f in as_completed(futures): <MASK> results.append(futures[f]) <TAB> return results",if f . result ( ) :,97
"def build_polymorphic_ctypes_map(cls): <TAB> # {'1': 'unified_job', '2': 'Job', '3': 'project_update', ...} <TAB> mapping = {} <TAB> for ct in ContentType.objects.filter(app_label=""main""): <TAB>  <TAB> ct_model_class = ct.model_class() <MASK> mapping[ct.id] = camelcase_to_underscore(ct_model_class.__name__) <TAB> return mapping","if ct_model_class and issubclass ( ct_model_class , cls ) :",126
"def expand_decodings(self, node: Node) -> None: <TAB> val = node.level.result.value <TAB> for decoder in self.get_decoders_for(type(val)): <TAB>  <TAB> inst = self._config()(decoder) <TAB>  <TAB> res = inst(val) <MASK> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> new_node = Node.decoding( <TAB>  <TAB>  <TAB>  <TAB> config=self._config(), route=inst, result=res, source=node <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> except DuplicateNode: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> logger.trace(""Nesting encodings"") <TAB>  <TAB> self.recursive_expand(new_node, False)",if res is None :,159
"def test_file(self): <TAB> a = 3.33 + 4.43j <TAB> b = 5.1 + 2.3j <TAB> fo = None <TAB> try: <TAB>  <TAB> fo = open(test_support.TESTFN, ""wb"") <TAB>  <TAB> print >> fo, a, b <TAB>  <TAB> fo.close() <TAB>  <TAB> fo = open(test_support.TESTFN, ""rb"") <TAB>  <TAB> self.assertEqual(fo.read(), ""%s %s\n"" % (a, b)) <TAB> finally: <MASK> fo.close() <TAB>  <TAB> test_support.unlink(test_support.TESTFN)",if ( fo is not None ) and ( not fo . closed ) :,158
"def repl(m): <TAB> if m.group(2) is not None: <TAB>  <TAB> high = int(m.group(1), 16) <TAB>  <TAB> low = int(m.group(2), 16) <MASK> cp = ((high - 0xD800) << 10) + (low - 0xDC00) + 0x10000 <TAB>  <TAB>  <TAB> return unichr(cp) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return unichr(high) + unichr(low) <TAB> else: <TAB>  <TAB> return unichr(int(m.group(1), 16))",if 0xD800 <= high <= 0xDBFF and 0xDC00 <= low <= 0xDFFF :,149
"def generate_credits(user, start_date, end_date, **kwargs): <TAB> """"""Generate credits data for given component."""""" <TAB> result = [] <TAB> base = Change.objects.content() <TAB> if user: <TAB>  <TAB> base = base.filter(author=user) <TAB> for language in Language.objects.filter(**kwargs).distinct().iterator(): <TAB>  <TAB> authors = base.filter(language=language, **kwargs).authors_list( <TAB>  <TAB>  <TAB> (start_date, end_date) <TAB>  <TAB> ) <MASK> continue <TAB>  <TAB> result.append({language.name: sorted(authors, key=lambda item: item[2])}) <TAB> return result",if not authors :,157
"def history_prev(self): <TAB> """"""Go back in the history."""""" <TAB> try: <MASK> item = self._history.start(self.text().strip()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> item = self._history.previtem() <TAB> except (cmdhistory.HistoryEmptyError, cmdhistory.HistoryEndReachedError): <TAB>  <TAB> return <TAB> self.setText(item)",if not self . _history . is_browsing ( ) :,102
"def destroy(self): <TAB> self._bind() <TAB> for name in ""jobItems"", ""jobFileIDs"", ""files"", ""statsFiles"", ""statsFileIDs"": <TAB>  <TAB> resource = getattr(self, name) <TAB>  <TAB> if resource is not None: <TAB>  <TAB>  <TAB> if isinstance(resource, AzureTable): <TAB>  <TAB>  <TAB>  <TAB> resource.delete_table() <MASK> resource.delete_container() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> assert False <TAB>  <TAB>  <TAB> setattr(self, name, None)","elif isinstance ( resource , AzureBlobContainer ) :",135
"def user_defined_os(): <TAB> if menu.options.os: <MASK> settings.TARGET_OS = ""win"" <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> elif menu.options.os.lower() == ""unix"": <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> err_msg = ""You specified wrong value '"" + menu.options.os + ""' "" <TAB>  <TAB>  <TAB> err_msg += ""as an operation system. The value, must be 'Windows' or 'Unix'."" <TAB>  <TAB>  <TAB> print(settings.print_critical_msg(err_msg)) <TAB>  <TAB>  <TAB> raise SystemExit()","if menu . options . os . lower ( ) == ""windows"" :",153
"def test_save(art_warning, image_dl_estimator): <TAB> try: <TAB>  <TAB> classifier, _ = image_dl_estimator(from_logits=True) <TAB>  <TAB> t_file = tempfile.NamedTemporaryFile() <TAB>  <TAB> model_path = t_file.name <TAB>  <TAB> t_file.close() <TAB>  <TAB> filename = ""model_to_save"" <TAB>  <TAB> classifier.save(filename, path=model_path) <TAB>  <TAB> assert path.exists(model_path) <TAB>  <TAB> created_model = False <TAB>  <TAB> for file in listdir(model_path): <MASK> created_model = True <TAB>  <TAB> assert created_model <TAB> except ARTTestException as e: <TAB>  <TAB> art_warning(e)",if filename in file :,172
"def set_extra_data(self, extra_data=None): <TAB> if extra_data and self.extra_data != extra_data: <MASK> self.extra_data.update(extra_data) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.extra_data = extra_data <TAB>  <TAB> return True","if self . extra_data and not isinstance ( self . extra_data , str ) :",93
"def get_image_dimensions(path): <TAB> """"""Returns the (width, height) of an image at a given path."""""" <TAB> p = ImageFile.Parser() <TAB> fp = open(path, ""rb"") <TAB> while 1: <TAB>  <TAB> data = fp.read(1024) <MASK> break <TAB>  <TAB> p.feed(data) <TAB>  <TAB> if p.image: <TAB>  <TAB>  <TAB> return p.image.size <TAB>  <TAB>  <TAB> break <TAB> fp.close() <TAB> return None",if not data :,118
"def language_suffixes(): <TAB> for lang in NSLocale.preferredLanguages(): <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> yield ""_"" + lang if lang != ""en"" else """" <MASK> lang = lang[: lang.rfind(""-"")] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> break <TAB> yield """"","if ""-"" in lang :",78
"def decode_binary(binarystring): <TAB> """"""Decodes a binary string into it's integer value."""""" <TAB> n = 0 <TAB> for c in binarystring: <TAB>  <TAB> if c == ""0"": <TAB>  <TAB>  <TAB> d = 0 <MASK> d = 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""Not an binary number"", binarystring) <TAB>  <TAB> # Could use ((n << 3 ) | d), but python 2.3 issues a FutureWarning. <TAB>  <TAB> n = (n * 2) + d <TAB> return n","elif c == ""1"" :",126
"def serialize_groups_for_summary(node): <TAB> groups = node.osf_groups <TAB> n_groups = len(groups) <TAB> group_string = """" <TAB> for index, group in enumerate(groups): <TAB>  <TAB> if index == n_groups - 1: <TAB>  <TAB>  <TAB> separator = """" <MASK> separator = "" & "" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> separator = "", "" <TAB>  <TAB> group_string = group_string + group.name + separator <TAB> return group_string",elif index == n_groups - 2 :,125
"def _save(self, req_method, requires): <TAB> conanfile = GenConanfile() <TAB> for req in requires: <TAB>  <TAB> req2, override = req if isinstance(req, tuple) else (req, False) <MASK> conanfile.with_require(req2, override=override) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> conanfile.with_requirement(req2, override=override) <TAB> self.client.save({""conanfile.py"": conanfile}, clean_first=True)",if not req_method :,130
"def _validate_declarations( <TAB> declarations: Sequence[Union[qlast.ModuleDeclaration, qlast.DDLCommand]]) -> None: <TAB> # Check that top-level declarations either use fully-qualified <TAB> # names or are module blocks. <TAB> for decl in declarations: <MASK> raise EdgeQLSyntaxError( <TAB>  <TAB>  <TAB>  <TAB> ""only fully-qualified name is allowed in "" ""top-level declaration"", <TAB>  <TAB>  <TAB>  <TAB> context=decl.name.context, <TAB>  <TAB>  <TAB> )","if not isinstance ( decl , qlast . ModuleDeclaration ) and decl . name . module is None :",134
"def assess_trial(self, trial_job_id, trial_history): <TAB> _logger.info(""assess trial %s %s"", trial_job_id, trial_history) <TAB> id_ = trial_history[0] <TAB> if id_ in self._killed: <TAB>  <TAB> return AssessResult.Bad <TAB> s = 0 <TAB> for i, val in enumerate(trial_history): <TAB>  <TAB> s += val <MASK> self._killed.add(id_) <TAB>  <TAB>  <TAB> _result.write(""%d %d\n"" % (id_, i + 1)) <TAB>  <TAB>  <TAB> _result.flush() <TAB>  <TAB>  <TAB> return AssessResult.Bad <TAB> return AssessResult.Good",if s % 11 == 1 :,170
"def decProcess(): <TAB> while 1: <TAB>  <TAB> yield clock.posedge, reset.negedge <MASK> count.next = 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if enable: <TAB>  <TAB>  <TAB>  <TAB> if count == -n: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> count.next = n - 1 <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> count.next = count - 1",if reset == ACTIVE_LOW :,100
"def activate_profile(test=True): <TAB> pr = None <TAB> if test: <MASK> pr = cProfile.Profile() <TAB>  <TAB>  <TAB> pr.enable() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.error(""cProfile is not available on your platform"") <TAB> return pr",if HAS_CPROFILE :,74
"def insertTestData(self, rows): <TAB> for row in rows: <TAB>  <TAB> if isinstance(row, Log): <TAB>  <TAB>  <TAB> self.logs[row.id] = row.values.copy() <TAB> for row in rows: <MASK> lines = self.log_lines.setdefault(row.logid, []) <TAB>  <TAB>  <TAB> # make sure there are enough slots in the list <TAB>  <TAB>  <TAB> if len(lines) < row.last_line + 1: <TAB>  <TAB>  <TAB>  <TAB> lines.append([None] * (row.last_line + 1 - len(lines))) <TAB>  <TAB>  <TAB> row_lines = row.content.decode(""utf-8"").split(""\n"") <TAB>  <TAB>  <TAB> lines[row.first_line : row.last_line + 1] = row_lines","if isinstance ( row , LogChunk ) :",187
"def getText(self, stuff): <TAB> if isinstance(stuff, BaseWrapper): <TAB>  <TAB> stuff = stuff.item <TAB> if isinstance(stuff, (Fit, TargetProfile)): <TAB>  <TAB> val, unit = self._getValue(stuff) <TAB>  <TAB> if val is None: <TAB>  <TAB>  <TAB> return """" <TAB>  <TAB> # Stick to value - 25k GJ <MASK> return ""{} {}"".format(formatAmount(val, *self.formatSpec), unit) <TAB>  <TAB> # Stick to unit - 25 km <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return formatAmount(val, *self.formatSpec, unitName=unit) <TAB> return """"",if self . stickPrefixToValue :,155
"def wrap(request, *args, **kwargs): <TAB> ""Wrap"" <TAB> user = request.user.profile <TAB> if ""massform"" in request.POST: <TAB>  <TAB> for key in request.POST: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> changeset = ChangeSet.objects.get(pk=request.POST[key]) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> form = MassActionForm( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> request.user.profile, request.POST, instance=changeset <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if form.is_valid() and user.has_permission(changeset, mode=""w""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> form.save() <TAB>  <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass <TAB> return f(request, *args, **kwargs)","if ""mass-changeset"" in key :",196
"def select(self, browser, locator): <TAB> assert browser is not None <TAB> if locator is not None: <TAB>  <TAB> if isinstance(locator, list): <TAB>  <TAB>  <TAB> self._select_by_excludes(browser, locator) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> if locator.lower() == ""self"" or locator.lower() == ""current"": <TAB>  <TAB>  <TAB> return <MASK> self._select_by_last_index(browser) <TAB>  <TAB>  <TAB> return <TAB> (prefix, criteria) = self._parse_locator(locator) <TAB> strategy = self._strategies.get(prefix) <TAB> if strategy is None: <TAB>  <TAB> raise ValueError(""Window locator with prefix '"" + prefix + ""' is not supported"") <TAB> return strategy(browser, criteria)","if locator . lower ( ) == ""new"" or locator . lower ( ) == ""popup"" :",187
"def test_all(self): <TAB> for context in get_contexts(): <TAB>  <TAB> found = False <TAB>  <TAB> expected_context_name = context.get_name() <TAB>  <TAB> for calculated_context in get_context(self.HTML, expected_context_name): <TAB>  <TAB>  <TAB> if calculated_context.get_name() == expected_context_name: <TAB>  <TAB>  <TAB>  <TAB> found = True <MASK> msg = ""The analysis for %s context failed, got %r instead."" <TAB>  <TAB>  <TAB> msg = msg % ( <TAB>  <TAB>  <TAB>  <TAB> expected_context_name, <TAB>  <TAB>  <TAB>  <TAB> get_context(self.HTML, expected_context_name), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.assertTrue(False, msg)",if not found :,171
"def visit_title(self, node: Element) -> None: <TAB> if isinstance(node.parent, addnodes.seealso): <TAB>  <TAB> self.body.append('.IP ""') <TAB>  <TAB> return <TAB> elif isinstance(node.parent, nodes.section): <MASK> # skip the document title <TAB>  <TAB>  <TAB> raise nodes.SkipNode <TAB>  <TAB> elif self.section_level == 1: <TAB>  <TAB>  <TAB> self.body.append("".SH %s\n"" % self.deunicode(node.astext().upper())) <TAB>  <TAB>  <TAB> raise nodes.SkipNode <TAB> return super().visit_title(node)",if self . section_level == 0 :,145
"def parse_svn_stats(status): <TAB> stats = RepoStats() <TAB> for line in status: <MASK> stats.new += 1 <TAB>  <TAB> elif line[0] == ""C"": <TAB>  <TAB>  <TAB> stats.conflicted += 1 <TAB>  <TAB> elif line[0] in [""A"", ""D"", ""I"", ""M"", ""R"", ""!"", ""~""]: <TAB>  <TAB>  <TAB> stats.changed += 1 <TAB> return stats","if line [ 0 ] == ""?"" :",106
"def setoutput(self, spec, defs=None): <TAB> self.closespec() <TAB> self.closedefs() <TAB> if spec: <TAB>  <TAB> if type(spec) == StringType: <TAB>  <TAB>  <TAB> file = self.openoutput(spec) <TAB>  <TAB>  <TAB> mine = 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> file = spec <TAB>  <TAB>  <TAB> mine = 0 <TAB>  <TAB> self.specfile = file <TAB>  <TAB> self.specmine = mine <TAB> if defs: <MASK> file = self.openoutput(defs) <TAB>  <TAB>  <TAB> mine = 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> file = defs <TAB>  <TAB>  <TAB> mine = 0 <TAB>  <TAB> self.defsfile = file <TAB>  <TAB> self.defsmine = mine",if type ( defs ) == StringType :,179
"def __new__(cls, name, bases, d): <TAB> rv = type.__new__(cls, name, bases, d) <TAB> if ""methods"" not in d: <TAB>  <TAB> methods = set(rv.methods or []) <TAB>  <TAB> for key, value in d.iteritems(): <MASK> methods.add(key.upper()) <TAB>  <TAB> # if we have no method at all in there we don't want to <TAB>  <TAB> # add a method list.  (This is for instance the case for <TAB>  <TAB> # the baseclass or another subclass of a base method view <TAB>  <TAB> # that does not introduce new methods). <TAB>  <TAB> if methods: <TAB>  <TAB>  <TAB> rv.methods = sorted(methods) <TAB> return rv",if key in http_method_funcs :,172
"def draw_lines(col, lines): <TAB> skip = False <TAB> for l in lines: <TAB>  <TAB> if l: <TAB>  <TAB>  <TAB> col.label(text=l) <TAB>  <TAB>  <TAB> skip = False <MASK> continue <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> col.label(text=l) <TAB>  <TAB>  <TAB> skip = True",elif skip :,82
"def adjust_sockets(self): <TAB> variables = self.get_variables() <TAB> for key in self.inputs.keys(): <TAB>  <TAB> if key not in variables and key not in [""Field""]: <TAB>  <TAB>  <TAB> self.debug( <TAB>  <TAB>  <TAB>  <TAB> ""Input {} not in variables {}, remove it"".format(key, str(variables)) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.inputs.remove(self.inputs[key]) <TAB> for v in variables: <MASK> self.debug( <TAB>  <TAB>  <TAB>  <TAB> ""Variable {} not in inputs {}, add it"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> v, str(self.inputs.keys()) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.inputs.new(""SvStringsSocket"", v)",if v not in self . inputs :,183
"def forward(self, g, x): <TAB> h = x <TAB> for l, conv in enumerate(self.layers): <TAB>  <TAB> h = conv(g, h) <MASK> h = self.activation(h) <TAB>  <TAB>  <TAB> h = self.dropout(h) <TAB> return h",if l != len ( self . layers ) - 1 :,82
"def process_doc(self, docstrings: List[List[str]]) -> Iterator[str]: <TAB> """"""Let the user process the docstrings before adding them."""""" <TAB> for docstringlines in docstrings: <MASK> # let extensions preprocess docstrings <TAB>  <TAB>  <TAB> self.env.app.emit( <TAB>  <TAB>  <TAB>  <TAB> ""autodoc-process-docstring"", <TAB>  <TAB>  <TAB>  <TAB> self.objtype, <TAB>  <TAB>  <TAB>  <TAB> self.fullname, <TAB>  <TAB>  <TAB>  <TAB> self.object, <TAB>  <TAB>  <TAB>  <TAB> self.options, <TAB>  <TAB>  <TAB>  <TAB> docstringlines, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> if docstringlines and docstringlines[-1] != """": <TAB>  <TAB>  <TAB>  <TAB> # append a blank line to the end of the docstring <TAB>  <TAB>  <TAB>  <TAB> docstringlines.append("""") <TAB>  <TAB> yield from docstringlines",if self . env . app :,185
"def wiki(self, query): <TAB> res = [] <TAB> for entry in g.current_wiki.get_index(): <TAB>  <TAB> name = filename_to_cname(entry[""name""]) <TAB>  <TAB> name = re.sub(r""//+"", ""/"", name) <TAB>  <TAB> if set(query.split()).intersection(name.replace(""/"", ""-"").split(""-"")): <TAB>  <TAB>  <TAB> page = g.current_wiki.get_page(name) <TAB>  <TAB>  <TAB> # this can be None, not sure how <MASK> res.append(dict(name=name, content=page.data)) <TAB> return res",if page :,143
"def checkForFinishedThreads(self): <TAB> ""Mark terminated threads with endTime."" <TAB> for t in self.unfinishedThreads: <TAB>  <TAB> if not t.is_alive(): <TAB>  <TAB>  <TAB> t.endTime = time.process_time() <MASK> t.status = ""ended""","if getattr ( t , ""status"" , None ) is None :",84
"def testTicketFlags(self): <TAB> flags = (""restored"", ""banned"") <TAB> ticket = Ticket(""test"", 0) <TAB> trueflags = [] <TAB> for v in (True, False, True): <TAB>  <TAB> for f in flags: <TAB>  <TAB>  <TAB> setattr(ticket, f, v) <MASK> trueflags.append(f) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> trueflags.remove(f) <TAB>  <TAB>  <TAB> for f2 in flags: <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(bool(getattr(ticket, f2)), f2 in trueflags) <TAB> ## inherite props from another tockets: <TAB> ticket = FailTicket(ticket=ticket) <TAB> for f2 in flags: <TAB>  <TAB> self.assertTrue(bool(getattr(ticket, f2)))",if v :,189
"def decode(obj, encoding=""utf-8"", errors=""strict""): <TAB> decoder = __decoder(encoding) <TAB> if decoder: <TAB>  <TAB> result = decoder(obj, errors) <MASK> raise TypeError(""decoder must return a tuple (object, integer)"") <TAB>  <TAB> return result[0]","if not ( isinstance ( result , tuple ) and len ( result ) == 2 ) :",86
"def work(self): <TAB> """"""Play the animation."""""" <TAB> # if loop_mode is once and we are already on the last frame, <TAB> # return to the first frame... (so the user can keep hitting once) <TAB> if self.loop_mode == LoopMode.ONCE: <MASK> self.frame_requested.emit(self.axis, self.min_point) <TAB>  <TAB> elif self.step < 0 and self.current <= self.min_point + 1: <TAB>  <TAB>  <TAB> self.frame_requested.emit(self.axis, self.max_point) <TAB>  <TAB> self.timer.singleShot(int(self.interval), self.advance) <TAB> else: <TAB>  <TAB> # immediately advance one frame <TAB>  <TAB> self.advance() <TAB> self.started.emit()",if self . step > 0 and self . current >= self . max_point - 1 :,199
"def get_order(self, aStr): <TAB> # for big5 encoding, we are interested <TAB> #   first  byte range: 0xa4 -- 0xfe <TAB> #   second byte range: 0x40 -- 0x7e , 0xa1 -- 0xfe <TAB> # no validation needed here. State machine has done that <TAB> if aStr[0] >= ""\xA4"": <MASK> return 157 * (ord(aStr[0]) - 0xA4) + ord(aStr[1]) - 0xA1 + 63 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return 157 * (ord(aStr[0]) - 0xA4) + ord(aStr[1]) - 0x40 <TAB> else: <TAB>  <TAB> return -1","if aStr [ 1 ] >= ""\xA1"" :",185
"def validate_literals(self): <TAB> try: <TAB>  <TAB> for c in self.literals: <MASK> self.log.error( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Invalid literal %s. Must be a single character"", repr(c) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> self.error = True <TAB> except TypeError: <TAB>  <TAB> self.log.error( <TAB>  <TAB>  <TAB> ""Invalid literals specification. literals must be a sequence of characters"" <TAB>  <TAB> ) <TAB>  <TAB> self.error = True","if not isinstance ( c , StringTypes ) or len ( c ) > 1 :",135
"def filter(self, qs, value): <TAB> if value: <TAB>  <TAB> if value.start is not None and value.stop is not None: <TAB>  <TAB>  <TAB> value = (value.start, value.stop) <TAB>  <TAB> elif value.start is not None: <TAB>  <TAB>  <TAB> self.lookup_expr = ""startswith"" <TAB>  <TAB>  <TAB> value = value.start <MASK> self.lookup_expr = ""endswith"" <TAB>  <TAB>  <TAB> value = value.stop <TAB> return super().filter(qs, value)",elif value . stop is not None :,125
"def parse_stdout(s): <TAB> argv = re.search(""^===ARGV=(.*?)$"", s, re.M).group(1) <TAB> argv = argv.split() <TAB> testname = argv[-1] <TAB> del argv[-1] <TAB> hub = None <TAB> reactor = None <TAB> while argv: <MASK> hub = argv[1] <TAB>  <TAB>  <TAB> del argv[0] <TAB>  <TAB>  <TAB> del argv[0] <TAB>  <TAB> elif argv[0] == ""--reactor"": <TAB>  <TAB>  <TAB> reactor = argv[1] <TAB>  <TAB>  <TAB> del argv[0] <TAB>  <TAB>  <TAB> del argv[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> del argv[0] <TAB> if reactor is not None: <TAB>  <TAB> hub += ""/%s"" % reactor <TAB> return testname, hub","if argv [ 0 ] == ""--hub"" :",196
"def get(self, key): <TAB> try: <TAB>  <TAB> res = self.server.get( <TAB>  <TAB>  <TAB> index=self.index, <TAB>  <TAB>  <TAB> doc_type=self.doc_type, <TAB>  <TAB>  <TAB> id=key, <TAB>  <TAB> ) <TAB>  <TAB> try: <MASK> return res[""_source""][""result""] <TAB>  <TAB> except (TypeError, KeyError): <TAB>  <TAB>  <TAB> pass <TAB> except elasticsearch.exceptions.NotFoundError: <TAB>  <TAB> pass","if res [ ""found"" ] :",112
"def _get_target_chap_auth(self, context, volume): <TAB> """"""Get the current chap auth username and password."""""" <TAB> try: <TAB>  <TAB> # Query DB to get latest state of volume <TAB>  <TAB> volume_info = self.db.volume_get(context, volume[""id""]) <TAB>  <TAB> # 'provider_auth': 'CHAP user_id password' <MASK> return tuple(volume_info[""provider_auth""].split("" "", 3)[1:]) <TAB> except exception.NotFound: <TAB>  <TAB> LOG.debug(""Failed to get CHAP auth from DB for %s."", volume[""id""])","if volume_info [ ""provider_auth"" ] :",149
"def merge(self, hosts): <TAB> for ei in self: <TAB>  <TAB> host_name = ei.get_name() <TAB>  <TAB> h = hosts.find_by_name(host_name) <MASK> # FUUUUUUUUUUsion <TAB>  <TAB>  <TAB> self.merge_extinfo(h, ei)",if h is not None :,86
"def __init__(self, user, *args, **kwargs): <TAB> ""Sets choices and initial value"" <TAB> super(SettingsForm, self).__init__(*args, **kwargs) <TAB> self.fields[""default_changeset_status""].queryset = ChangeSetStatus.objects.filter( <TAB>  <TAB> trash=False <TAB> ) <TAB> try: <TAB>  <TAB> conf = ModuleSetting.get_for_module( <TAB>  <TAB>  <TAB> ""treeio.changes"", ""default_changeset_status"" <TAB>  <TAB> )[0] <TAB>  <TAB> default_changeset_status = ChangeSetStatus.objects.get(pk=long(conf.value)) <MASK> self.fields[ <TAB>  <TAB>  <TAB>  <TAB> ""default_changeset_status"" <TAB>  <TAB>  <TAB> ].initial = default_changeset_status.id <TAB> except Exception: <TAB>  <TAB> pass",if not default_changeset_status . trash :,191
"def load(self): <TAB> """"""Method for loading a feature"""""" <TAB> with self.filesystem.openbin(self.path, ""r"") as file_handle: <MASK> with gzip.open(file_handle, ""rb"") as gzip_fp: <TAB>  <TAB>  <TAB>  <TAB> return self._decode(gzip_fp, self.path) <TAB>  <TAB> return self._decode(file_handle, self.path)",if self . path . endswith ( FileFormat . GZIP . extension ( ) ) :,108
"def edge2str(self, nfrom, nto): <TAB> if isinstance(nfrom, ExprCompose): <TAB>  <TAB> for i in nfrom.args: <MASK> return ""[%s, %s]"" % (i[1], i[2]) <TAB> elif isinstance(nfrom, ExprCond): <TAB>  <TAB> if nfrom.cond == nto: <TAB>  <TAB>  <TAB> return ""?"" <TAB>  <TAB> elif nfrom.src1 == nto: <TAB>  <TAB>  <TAB> return ""True"" <TAB>  <TAB> elif nfrom.src2 == nto: <TAB>  <TAB>  <TAB> return ""False"" <TAB> return """"",if i [ 0 ] == nto :,149
"def disable_verity(): <TAB> """"""Disables dm-verity on the device."""""" <TAB> with log.waitfor(""Disabling dm-verity on %s"" % context.device): <TAB>  <TAB> root() <TAB>  <TAB> with AdbClient() as c: <TAB>  <TAB>  <TAB> reply = c.disable_verity() <TAB>  <TAB> if ""Verity already disabled"" in reply: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> elif ""Now reboot your device"" in reply: <TAB>  <TAB>  <TAB> reboot(wait=True) <MASK> return  # Emulator doesnt support Verity? <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.error(""Could not disable verity:\n%s"" % reply)","elif ""0006closed"" in reply :",165
"def __demo_mode_pause_if_active(self, tiny=False): <TAB> if self.demo_mode: <TAB>  <TAB> wait_time = settings.DEFAULT_DEMO_MODE_TIMEOUT <TAB>  <TAB> if self.demo_sleep: <TAB>  <TAB>  <TAB> wait_time = float(self.demo_sleep) <MASK> time.sleep(wait_time) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> time.sleep(wait_time / 3.4) <TAB> elif self.slow_mode: <TAB>  <TAB> self.__slow_mode_pause_if_active()",if not tiny :,134
"def dictToKW(d): <TAB> out = [] <TAB> items = list(d.items()) <TAB> items.sort() <TAB> for k, v in items: <MASK> raise NonFormattableDict(""%r ain't a string"" % k) <TAB>  <TAB> if not r.match(k): <TAB>  <TAB>  <TAB> raise NonFormattableDict(""%r ain't an identifier"" % k) <TAB>  <TAB> out.append(""\n\0{}={},"".format(k, prettify(v))) <TAB> return """".join(out)","if not isinstance ( k , str ) :",131
"def createCommonCommands(self): <TAB> """"""Handle all global @command nodes."""""" <TAB> c = self.c <TAB> aList = c.config.getCommands() or [] <TAB> for z in aList: <TAB>  <TAB> p, script = z <TAB>  <TAB> gnx = p.v.gnx <MASK> self.seen.add(gnx) <TAB>  <TAB>  <TAB> script = self.getScript(p) <TAB>  <TAB>  <TAB> self.createCommonCommand(p, script)",if gnx not in self . seen :,121
"def _decodeFromStream(self, s): <TAB> """"""Decode a complete DER OBJECT ID from a file."""""" <TAB> # Fill up self.payload <TAB> DerObject._decodeFromStream(self, s) <TAB> # Derive self.value from self.payload <TAB> p = BytesIO_EOF(self.payload) <TAB> comps = list(map(str, divmod(p.read_byte(), 40))) <TAB> v = 0 <TAB> while p.remaining_data(): <TAB>  <TAB> c = p.read_byte() <TAB>  <TAB> v = v * 128 + (c & 0x7F) <MASK> comps.append(str(v)) <TAB>  <TAB>  <TAB> v = 0 <TAB> self.value = ""."".join(comps)",if not ( c & 0x80 ) :,174
"def tiles_around_factor(self, factor, pos, radius=1, predicate=None): <TAB> ps = [] <TAB> x, y = pos <TAB> for dx in range(-radius, radius + 1): <TAB>  <TAB> nx = x + dx <MASK> for dy in range(-radius, radius + 1): <TAB>  <TAB>  <TAB>  <TAB> ny = y + dy <TAB>  <TAB>  <TAB>  <TAB> if ny >= 0 and ny < self.height * factor and (dx != 0 or dy != 0): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if predicate is None or predicate((nx, ny)): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ps.append((nx, ny)) <TAB> return ps",if nx >= 0 and nx < self . width * factor :,159
"def deleteAllMatchers(self): <TAB> """"""Deletes all matchers."""""" <TAB> if self.__filter: <TAB>  <TAB> result = QtWidgets.QMessageBox.question( <TAB>  <TAB>  <TAB> self, <TAB>  <TAB>  <TAB> ""Delete All Matchers?"", <TAB>  <TAB>  <TAB> ""Are you sure you want to delete all matchers?"", <TAB>  <TAB>  <TAB> QtWidgets.QMessageBox.Yes | QtWidgets.QMessageBox.No, <TAB>  <TAB> ) <MASK> self._itemsLock.lockForWrite() <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> for item in list(self._items.values()): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> item.rpcObject.delete() <TAB>  <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB>  <TAB> self._itemsLock.unlock() <TAB>  <TAB>  <TAB> self.removeAllItems()",if result == QtWidgets . QMessageBox . Yes :,186
"def _parse_icons(self, icons): <MASK> icons = get_iterated_icons(icons) <TAB> for icon in icons: <TAB>  <TAB> if isinstance(icons, list): <TAB>  <TAB>  <TAB> icon = Icon(icon) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> icon = Icon(icons[icon]) <TAB>  <TAB> if icon.exists:  # If icon found on current Gtk Icon theme <TAB>  <TAB>  <TAB> self.icons.append(icon)","if isinstance ( icons , list ) :",107
"def change_misc_visibility(self, on_start=False): <TAB> if self.misc.isVisible(): <TAB>  <TAB> self._splitterMainSizes = self._splitterMain.sizes() <TAB>  <TAB> self.misc.hide() <TAB>  <TAB> widget = self.mainContainer.get_actual_widget() <MASK> widget.setFocus() <TAB> else: <TAB>  <TAB> self.misc.show() <TAB>  <TAB> self.misc.gain_focus()",if widget :,108
"def is_checked_sls_template(template): <TAB> if template.__contains__(""provider""): <TAB>  <TAB> # Case provider is a dictionary <TAB>  <TAB> if isinstance(template[""provider""], dict_node): <TAB>  <TAB>  <TAB> if template[""provider""].get(""name"").lower() not in SUPPORTED_PROVIDERS: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> # Case provider is direct provider name <TAB>  <TAB> if isinstance(template[""provider""], str_node): <MASK> return False <TAB>  <TAB> return True <TAB> return False","if template [ ""provider"" ] not in SUPPORTED_PROVIDERS :",131
"def check_index(self, is_sorted=True, unique=True, index=None): <TAB> """"""Sanity checks"""""" <TAB> if not index: <TAB>  <TAB> index = self.index <TAB> if is_sorted: <TAB>  <TAB> test = pd.DataFrame(lrange(len(index)), index=index) <TAB>  <TAB> test_sorted = test.sort() <MASK> raise Exception(""Data is not be sorted"") <TAB> if unique: <TAB>  <TAB> if len(index) != len(index.unique()): <TAB>  <TAB>  <TAB> raise Exception(""Duplicate index entries"")",if not test . index . equals ( test_sorted . index ) :,142
"def _update_actions(self, *_ignored): <TAB> """"""Updates menu actions to reflect the current layer's mode"""""" <TAB> if self._updating: <TAB>  <TAB> return <TAB> self._updating = True <TAB> rootstack = self._model.layer_stack <TAB> current = rootstack.current <TAB> for mode, item in self._menu_items: <TAB>  <TAB> active = mode == current.mode <MASK> item.set_active(active) <TAB>  <TAB> item.set_sensitive(mode in current.PERMITTED_MODES) <TAB> self._updating = False",if bool ( item . get_active ( ) ) != active :,140
"def _charlabels(self, options): <TAB> """"""Get labels for characters (PRIVATE)."""""" <TAB> self.charlabels = {} <TAB> opts = CharBuffer(options) <TAB> while True: <TAB>  <TAB> # get id and state <TAB>  <TAB> w = opts.next_word() <MASK> # McClade saves and reads charlabel-lists with terminal comma?! <TAB>  <TAB>  <TAB> break <TAB>  <TAB> identifier = self._resolve(w, set_type=CHARSET) <TAB>  <TAB> state = quotestrip(opts.next_word()) <TAB>  <TAB> self.charlabels[identifier] = state <TAB>  <TAB> # check for comma or end of command <TAB>  <TAB> c = opts.next_nonwhitespace() <TAB>  <TAB> if c is None: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif c != "","": <TAB>  <TAB>  <TAB> raise NexusError(""Missing ',' in line %s."" % options)",if w is None :,198
"def get_and_set_titles(self): <TAB> all_titles = [] <TAB> for page in self.pages: <MASK> all_titles.append(page.orig_phrase) <TAB>  <TAB>  <TAB> all_titles.append(page.orig_phrase_norm) <TAB>  <TAB> if page.wiki_title != """": <TAB>  <TAB>  <TAB> all_titles.append(page.wiki_title) <TAB>  <TAB>  <TAB> all_titles.append(page.wiki_title_norm) <TAB> return set(all_titles)","if page . orig_phrase != """" :",127
"def get_content_length(download): <TAB> try: <TAB>  <TAB> meta = download.info() <MASK> return int(meta.getheaders(""Content-Length"")[0]) <TAB>  <TAB> elif hasattr(download, ""getheader"") and download.getheader(""Content-Length""): <TAB>  <TAB>  <TAB> return int(download.getheader(""Content-Length"")) <TAB>  <TAB> elif hasattr(meta, ""getheader"") and meta.getheader(""Content-Length""): <TAB>  <TAB>  <TAB> return int(meta.getheader(""Content-Length"")) <TAB> except Exception: <TAB>  <TAB> pass <TAB> return 0","if hasattr ( meta , ""getheaders"" ) and hasattr ( meta . getheaders , ""Content-Length"" ) :",149
"def connect_reader_to_writer(reader, writer): <TAB> BUF_SIZE = 8192 <TAB> try: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> data = await reader.read(BUF_SIZE) <TAB>  <TAB>  <TAB> if not data: <MASK> writer.write_eof() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> await writer.drain() <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> writer.write(data) <TAB>  <TAB>  <TAB> await writer.drain() <TAB> except (OSError, asyncio.IncompleteReadError) as e: <TAB>  <TAB> pass",if not writer . transport . is_closing ( ) :,139
"def _record_shell(ex, files, bind_rez=True, print_msg=False): <TAB> ex.source(context_file) <TAB> if startup_sequence[""envvar""]: <TAB>  <TAB> ex.unsetenv(startup_sequence[""envvar""]) <TAB> if add_rez and bind_rez: <TAB>  <TAB> ex.interpreter._bind_interactive_rez() <TAB> if print_msg and add_rez and not quiet: <TAB>  <TAB> ex.info("""") <TAB>  <TAB> ex.info(""You are now in a rez-configured environment."") <TAB>  <TAB> ex.info("""") <MASK> ex.command(""rezolve context"")",if system . is_production_rez_install :,159
"def set_torrent_ratio(self, torrent_ids, ratio): <TAB> try: <TAB>  <TAB> if not self.connect(): <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> self.client.core.set_torrent_stop_at_ratio(torrent_ids, True).get() <TAB>  <TAB> self.client.core.set_torrent_stop_ratio(torrent_ids, ratio).get() <TAB> except Exception as err: <TAB>  <TAB> return False <TAB> finally: <MASK> self.disconnect() <TAB> return True",if self . client :,125
"def __decrypt_bin_sum(encrypted_bin_sum, cipher): <TAB> # for feature_sum in encrypted_bin_sum: <TAB> decrypted_list = {} <TAB> for col_name, count_list in encrypted_bin_sum.items(): <TAB>  <TAB> new_list = [] <TAB>  <TAB> for event_count, non_event_count in count_list: <MASK> event_count = cipher.decrypt(event_count) <TAB>  <TAB>  <TAB> if isinstance(non_event_count, PaillierEncryptedNumber): <TAB>  <TAB>  <TAB>  <TAB> non_event_count = cipher.decrypt(non_event_count) <TAB>  <TAB>  <TAB> new_list.append((event_count, non_event_count)) <TAB>  <TAB> decrypted_list[col_name] = new_list <TAB> return decrypted_list","if isinstance ( event_count , PaillierEncryptedNumber ) :",198
"def processVideo(self, track): <TAB> video = Metadata(self) <TAB> self.trackCommon(track, video) <TAB> try: <TAB>  <TAB> video.compression = track[""CodecID/string""].value <MASK> video.width = track[""Video/PixelWidth/unsigned""].value <TAB>  <TAB>  <TAB> video.height = track[""Video/PixelHeight/unsigned""].value <TAB> except MissingField: <TAB>  <TAB> pass <TAB> self.addGroup(""video[]"", video, ""Video stream"")","if ""Video"" in track :",120
"def check_br_addr(self, br): <TAB> ips = {} <TAB> cmd = ""ip a show dev %s"" % br <TAB> for line in self.execute(cmd, sudo=True).split(""\n""): <MASK> elems = [e.strip() for e in line.strip().split("" "")] <TAB>  <TAB>  <TAB> ips[4] = elems[1] <TAB>  <TAB> elif line.strip().startswith(""inet6 ""): <TAB>  <TAB>  <TAB> elems = [e.strip() for e in line.strip().split("" "")] <TAB>  <TAB>  <TAB> ips[6] = elems[1] <TAB> return ips","if line . strip ( ) . startswith ( ""inet "" ) :",149
"def _find_line_in_file(file_path, search_pattern): <TAB> try: <TAB>  <TAB> with open(file_path, ""r"", encoding=""utf-8"") as search_file: <TAB>  <TAB>  <TAB> for line in search_file: <MASK> return True <TAB> except (OSError, IOError): <TAB>  <TAB> pass <TAB> return False",if search_pattern in line :,94
"def setOption(self, key, value): <TAB> if key in VALID_OPTIONS: <TAB>  <TAB> old = self.getOption(key) <TAB>  <TAB> result = VALID_OPTIONS[key](self, value) <TAB>  <TAB> self.notifyOptionChanged(key, old, value) <MASK> return result[1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise RopperError(""Invalid value for option %s: %s"" % (key, value)) <TAB> else: <TAB>  <TAB> raise RopperError(""Invalid option"")",if result :,124
"def _para_exploit(self, params, part): <TAB> if len(params) == 0: <TAB>  <TAB> arr = [""*"", ""config""] + self._configs.keys() <TAB>  <TAB> return suggest(arr, part) <TAB> if len(params) == 1: <TAB>  <TAB> arr = [] <TAB>  <TAB> if params[0] == ""config"": <TAB>  <TAB>  <TAB> arr = self._configs.keys() <MASK> arr = [""stopOnFirst""] <TAB>  <TAB> return suggest(arr, part) <TAB> return []","if params [ 0 ] == ""*"" :",124
"def render(self, context): <TAB> for var in self.vars: <TAB>  <TAB> value = var.resolve(context, True) <TAB>  <TAB> if value: <TAB>  <TAB>  <TAB> first = render_value_in_context(value, context) <MASK> context[self.asvar] = first <TAB>  <TAB>  <TAB>  <TAB> return """" <TAB>  <TAB>  <TAB> return first <TAB> return """"",if self . asvar :,95
"def insertTestData(self, rows): <TAB> for row in rows: <TAB>  <TAB> if isinstance(row, Log): <TAB>  <TAB>  <TAB> self.logs[row.id] = row.values.copy() <TAB> for row in rows: <TAB>  <TAB> if isinstance(row, LogChunk): <TAB>  <TAB>  <TAB> lines = self.log_lines.setdefault(row.logid, []) <TAB>  <TAB>  <TAB> # make sure there are enough slots in the list <MASK> lines.append([None] * (row.last_line + 1 - len(lines))) <TAB>  <TAB>  <TAB> row_lines = row.content.decode(""utf-8"").split(""\n"") <TAB>  <TAB>  <TAB> lines[row.first_line : row.last_line + 1] = row_lines",if len ( lines ) < row . last_line + 1 :,187
"def set_available_qty(self): <TAB> for d in self.get(""required_items""): <TAB>  <TAB> if d.source_warehouse: <TAB>  <TAB>  <TAB> d.available_qty_at_source_warehouse = get_latest_stock_qty( <TAB>  <TAB>  <TAB>  <TAB> d.item_code, d.source_warehouse <TAB>  <TAB>  <TAB> ) <MASK> d.available_qty_at_wip_warehouse = get_latest_stock_qty( <TAB>  <TAB>  <TAB>  <TAB> d.item_code, self.wip_warehouse <TAB>  <TAB>  <TAB> )",if self . wip_warehouse :,136
"def add_pref_observer(self, name, callback): <TAB> self.log.debug(""Adding pref observer for %s"", name) <TAB> try: <TAB>  <TAB> self._observers[name].add(callback) <TAB> except KeyError: <TAB>  <TAB> self._observers[name] = set([callback]) <MASK> self._send(command=""global-prefs-observe"", add=[name]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # We can't actually trigger prefs observer changes on document <TAB>  <TAB>  <TAB> # level prefs; that's mostly okay, though, since we just pass <TAB>  <TAB>  <TAB> # the whole prefs environment every time we do something with a <TAB>  <TAB>  <TAB> # document instead. <TAB>  <TAB>  <TAB> pass",if self . _send :,165
"def __setattr__(self, key: str, value) -> None: <TAB> try: <TAB>  <TAB> object.__getattribute__(self, key) <TAB>  <TAB> return object.__setattr__(self, key, value) <TAB> except AttributeError: <TAB>  <TAB> pass <TAB> if (key,) in self._internal.column_labels: <TAB>  <TAB> self[key] = value <TAB> else: <TAB>  <TAB> msg = ""Koalas doesn't allow columns to be created via a new attribute name"" <MASK> raise AssertionError(msg) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> warnings.warn(msg, UserWarning)",if is_testing ( ) :,139
"def inverse_transform(self, X): <TAB> results = [] <TAB> column_counter = 0 <TAB> for i, binarizer in enumerate(self.binarizers): <TAB>  <TAB> n_cols = binarizer.classes_.shape[0] <TAB>  <TAB> x_subset = X[:, column_counter : column_counter + n_cols] <TAB>  <TAB> inv = binarizer.inverse_transform(x_subset) <MASK> inv = inv[:, np.newaxis] <TAB>  <TAB> results.append(inv) <TAB>  <TAB> column_counter += n_cols <TAB> return np.concatenate(results, axis=1)",if len ( inv . shape ) == 1 :,144
"def default_generator( <TAB> self, dataset, epochs=1, mode=""fit"", deterministic=True, pad_batches=True): <TAB> for epoch in range(epochs): <TAB>  <TAB> for (X_b, y_b, w_b, ids_b) in dataset.iterbatches( <TAB>  <TAB>  <TAB> batch_size=self.batch_size, <TAB>  <TAB>  <TAB> deterministic=deterministic, <TAB>  <TAB>  <TAB> pad_batches=pad_batches, <TAB>  <TAB> ): <MASK> dropout = np.array(False) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> dropout = np.array(True) <TAB>  <TAB>  <TAB> yield ([X_b, dropout], [y_b], [w_b])","if mode == ""predict"" :",168
"def modif(dir, name, fun): <TAB> """"""Call a substitution function"""""" <TAB> if name == ""*"": <TAB>  <TAB> lst = [] <TAB>  <TAB> for y in "". Tools extras"".split(): <TAB>  <TAB>  <TAB> for x in os.listdir(os.path.join(dir, y)): <MASK> lst.append(y + os.sep + x) <TAB>  <TAB> for x in lst: <TAB>  <TAB>  <TAB> modif(dir, x, fun) <TAB>  <TAB> return <TAB> filename = os.path.join(dir, name) <TAB> with open(filename, ""r"") as f: <TAB>  <TAB> txt = f.read() <TAB> txt = fun(txt) <TAB> with open(filename, ""w"") as f: <TAB>  <TAB> f.write(txt)","if x . endswith ( "".py"" ) :",186
"def find_last_match(view, what, start, end, flags=0): <TAB> """"""Find last occurrence of `what` between `start`, `end`."""""" <TAB> match = view.find(what, start, flags) <TAB> new_match = None <TAB> while match: <TAB>  <TAB> new_match = view.find(what, match.end(), flags) <MASK> match = new_match <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return match",if new_match and new_match . end ( ) <= end :,119
"def to_dynamic_cwd_tuple(x): <TAB> """"""Convert to a canonical cwd_width tuple."""""" <TAB> unit = ""c"" <TAB> if isinstance(x, str): <MASK> x = x[:-1] <TAB>  <TAB>  <TAB> unit = ""%"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> unit = ""c"" <TAB>  <TAB> return (float(x), unit) <TAB> else: <TAB>  <TAB> return (float(x[0]), x[1])","if x [ - 1 ] == ""%"" :",111
"def get_lprobs_and_target(self, model, net_output, sample): <TAB> lprobs = model.get_normalized_probs(net_output, log_probs=True) <TAB> target = model.get_targets(sample, net_output) <TAB> if self.ignore_prefix_size > 0: <MASK> lprobs = lprobs[:, self.ignore_prefix_size :, :].contiguous() <TAB>  <TAB>  <TAB> target = target[:, self.ignore_prefix_size :].contiguous() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lprobs = lprobs[self.ignore_prefix_size :, :, :].contiguous() <TAB>  <TAB>  <TAB> target = target[self.ignore_prefix_size :, :].contiguous() <TAB> return lprobs.view(-1, lprobs.size(-1)), target.view(-1)","if getattr ( lprobs , ""batch_first"" , False ) :",197
"def _charlabels(self, options): <TAB> """"""Get labels for characters (PRIVATE)."""""" <TAB> self.charlabels = {} <TAB> opts = CharBuffer(options) <TAB> while True: <TAB>  <TAB> # get id and state <TAB>  <TAB> w = opts.next_word() <TAB>  <TAB> if w is None:  # McClade saves and reads charlabel-lists with terminal comma?! <TAB>  <TAB>  <TAB> break <TAB>  <TAB> identifier = self._resolve(w, set_type=CHARSET) <TAB>  <TAB> state = quotestrip(opts.next_word()) <TAB>  <TAB> self.charlabels[identifier] = state <TAB>  <TAB> # check for comma or end of command <TAB>  <TAB> c = opts.next_nonwhitespace() <MASK> break <TAB>  <TAB> elif c != "","": <TAB>  <TAB>  <TAB> raise NexusError(""Missing ',' in line %s."" % options)",if c is None :,198
"def _parseContributors(self, roleType, Contributors): <TAB> if Contributors is None: <TAB>  <TAB> return None <TAB> try: <TAB>  <TAB> ret = [] <TAB>  <TAB> for item in Contributors[""items""]: <MASK> ret.append(item[""name""]) <TAB>  <TAB> return ret <TAB> except: <TAB>  <TAB> return None","if item [ ""role"" ] == roleType :",100
"def _data_interp(self): <TAB> if self.pending_points: <TAB>  <TAB> points = list(self.pending_points) <MASK> values = self.ip()(self._scale(points)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Without the bounds the interpolation cannot be done properly, <TAB>  <TAB>  <TAB> # so we just set everything to zero. <TAB>  <TAB>  <TAB> values = np.zeros((len(points), self.vdim)) <TAB>  <TAB> return points, values <TAB> return np.zeros((0, 2)), np.zeros((0, self.vdim), dtype=float)",if self . bounds_are_done :,144
"def _initCaseSets(self): <TAB> self._cs = {} <TAB> self._css = {} <TAB> for cs in self._caseSets: <MASK> self._cs[cs.CaseSetName] = {} <TAB>  <TAB>  <TAB> self._css[cs.CaseSetName] = cs <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception(""duplicate case set name"") <TAB>  <TAB> for c in cs.Cases: <TAB>  <TAB>  <TAB> idx = tuple(c.index) <TAB>  <TAB>  <TAB> if not self._cs[cs.CaseSetName].has_key(idx): <TAB>  <TAB>  <TAB>  <TAB> self._cs[cs.CaseSetName][idx] = c <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise Exception(""duplicate case index"")",if not self . _cs . has_key ( cs . CaseSetName ) :,178
"def _organize_data(self, data): <TAB> temporary = {} <TAB> for line in data.splitlines(): <TAB>  <TAB> category, _, value = line.partition("" "") <MASK> key, _, value = value.partition("" "") <TAB>  <TAB>  <TAB> temporary[key] = value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> temporary[category] = value <TAB> return temporary","if category in ( ""set"" , ""tag"" ) :",93
"def get(self): <TAB> """"""Returns a simple HTML for contact form"""""" <TAB> if self.user: <TAB>  <TAB> user_info = models.User.get_by_id(long(self.user_id)) <TAB>  <TAB> if user_info.name or user_info.last_name: <TAB>  <TAB>  <TAB> self.form.name.data = user_info.name + "" "" + user_info.last_name <MASK> self.form.email.data = user_info.email <TAB> params = {""exception"": self.request.get(""exception"")} <TAB> return self.render_template(""boilerplate_contact.html"", **params)",if user_info . email :,155
"def parseBamPEFDistributionFile(self, f): <TAB> d = dict() <TAB> lastsample = [] <TAB> for line in f[""f""].splitlines(): <TAB>  <TAB> cols = line.rstrip().split(""\t"") <TAB>  <TAB> if cols[0] == ""#bamPEFragmentSize"": <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> s_name = self.clean_s_name(cols[2].rstrip().split(""/"")[-1], f[""root""]) <TAB>  <TAB>  <TAB> if s_name != lastsample: <TAB>  <TAB>  <TAB>  <TAB> d[s_name] = dict() <TAB>  <TAB>  <TAB>  <TAB> lastsample = s_name <TAB>  <TAB>  <TAB> d[s_name].update({self._int(cols[0]): self._int(cols[1])}) <TAB> return d","elif cols [ 0 ] == ""Size"" :",194
"def _related(self): <TAB> if self.__related is None: <TAB>  <TAB> results = requests.get( <TAB>  <TAB>  <TAB> f""{self._wordnet_corpus_reader.host()}/api/synsets/{self.pos()}/{self.offset()}/relations/?format=json"", <TAB>  <TAB>  <TAB> timeout=(30.0, 90.0), <TAB>  <TAB> ) <MASK> self.__related = results.json()[""results""][0][""relations""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.__related = [] <TAB> return self.__related","if results and len ( results . json ( ) [ ""results"" ] ) != 0 :",135
"def autoname(self): <TAB> if self.company: <TAB>  <TAB> suffix = "" - "" + frappe.get_cached_value(""Company"", self.company, ""abbr"") <MASK> self.name = self.warehouse_name + suffix <TAB> else: <TAB>  <TAB> self.name = self.warehouse_name",if not self . warehouse_name . endswith ( suffix ) :,88
"def escape_string(self, value): <TAB> value = EscapedString.promote(value) <TAB> value = value.expanduser() <TAB> result = """" <TAB> for is_literal, txt in value.strings: <MASK> txt = pipes.quote(txt) <TAB>  <TAB>  <TAB> if not txt.startswith(""'""): <TAB>  <TAB>  <TAB>  <TAB> txt = ""'%s'"" % txt <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> txt = txt.replace(""\\"", ""\\\\"") <TAB>  <TAB>  <TAB> txt = txt.replace('""', '\\""') <TAB>  <TAB>  <TAB> txt = '""%s""' % txt <TAB>  <TAB> result += txt <TAB> return result",if is_literal :,139
"def downgrade_wsgi_ux_to_1x(environ): <TAB> """"""Return a new environ dict for WSGI 1.x from the given WSGI u.x environ."""""" <TAB> env1x = {} <TAB> url_encoding = environ[ntou(""wsgi.url_encoding"")] <TAB> for k, v in list(environ.items()): <TAB>  <TAB> if k in [ntou(""PATH_INFO""), ntou(""SCRIPT_NAME""), ntou(""QUERY_STRING"")]: <TAB>  <TAB>  <TAB> v = v.encode(url_encoding) <MASK> v = v.encode(""ISO-8859-1"") <TAB>  <TAB> env1x[k.encode(""ISO-8859-1"")] = v <TAB> return env1x","elif isinstance ( v , unicodestr ) :",172
"def __repr__(self): <TAB> rt = ""Network <TAB>  <TAB>  Netmask <TAB>  <TAB>  Gateway <TAB>  <TAB>  Iface <TAB>  <TAB>    Output IP\n"" <TAB> for net, msk, gw, <MASK> addr in self.routes: <TAB>  <TAB> rt += ""%-15s %-15s %-15s %-15s %-15s\n"" % ( <TAB>  <TAB>  <TAB> ltoa(net), <TAB>  <TAB>  <TAB> ltoa(msk), <TAB>  <TAB>  <TAB> gw, <TAB>  <TAB>  <TAB> iface, <TAB>  <TAB>  <TAB> addr, <TAB>  <TAB> ) <TAB> return rt","iface ,",148
"def nearest_sources_Point( <TAB> self, point: Point, max_dist=float(""inf"")):  # sys.float_info.max): <TAB> bp, bn, bi, bd = None, None, None, None <TAB> for rfsource in self.rfsources: <MASK> continue <TAB>  <TAB> hp, hn, hi, hd = rfsource.nearest(point, max_dist=max_dist) <TAB>  <TAB> if bp is None or (hp is not None and hd < bd): <TAB>  <TAB>  <TAB> bp, bn, bi, bd = hp, hn, hi, hd <TAB> return (bp, bn, bi, bd)",if not self . get_rfsource_snap ( rfsource ) :,163
"def restoreParent(self): <TAB> if self.sid.isRoot: <TAB>  <TAB> return <TAB> with self.suspendMouseButtonNavigation(): <TAB>  <TAB> confirm, opt = self.confirmRestore((self.path,)) <TAB>  <TAB> if not confirm: <TAB>  <TAB>  <TAB> return <MASK> return <TAB> rd = RestoreDialog(self, self.sid, self.path, **opt) <TAB> rd.exec()","if opt [ ""delete"" ] and not self . confirmDelete ( warnRoot = self . path == ""/"" ) :",114
"def connect(self): <TAB> if self.reserved_ports: <TAB>  <TAB> self.get_reserved_port() <TAB> self.sock.settimeout(10) <TAB> max_attempts = 3 <TAB> for i in range(max_attempts): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> rv = super(WSClient, self).connect() <TAB>  <TAB> except OSError as e: <TAB>  <TAB>  <TAB> # Lets retry a few times in case the error is <TAB>  <TAB>  <TAB> # [Errno 48] Address already in use <TAB>  <TAB>  <TAB> # which I believe may be caused by a race condition <MASK> continue <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> if self.sock: <TAB>  <TAB> self.sock.settimeout(None) <TAB> return rv",if e . errno == errno . EADDRINUSE and i < max_attempts - 1 :,193
"def step(self, action): <TAB> assert self.action_space.contains(action) <TAB> if self._state == 4: <TAB>  <TAB> if action and self._case: <TAB>  <TAB>  <TAB> return self._state, 10.0, True, {} <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self._state, -10, True, {} <TAB> else: <TAB>  <TAB> if action: <TAB>  <TAB>  <TAB> if self._state == 0: <TAB>  <TAB>  <TAB>  <TAB> self._state = 2 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._state += 1 <MASK> self._state = self._case <TAB> return self._state, -1, False, {}",elif self . _state == 2 :,157
"def process(self): <TAB> inputs = self.node.inputs <TAB> outputs = self.node.outputs <TAB> data = [s.sv_get()[0] for s in inputs] <TAB> for socket, ref in zip(outputs, self.outputs): <MASK> func = getattr(self, ref[2]) <TAB>  <TAB>  <TAB> out = tuple(itertools.starmap(func, sv_zip_longest(*data))) <TAB>  <TAB>  <TAB> socket.sv_set(out)",if socket . links :,113
"def filter_queryset(self, request, queryset, view): <TAB> if ( <TAB>  <TAB> self.filter_name in request.QUERY_PARAMS <TAB>  <TAB> or self.exclude_param_name in request.QUERY_PARAMS <TAB> ): <TAB>  <TAB> projects_ids_subquery = self.filter_user_projects(request) <MASK> queryset = queryset.filter(project_id__in=projects_ids_subquery) <TAB> return super().filter_queryset(request, queryset, view)",if projects_ids_subquery :,118
"def _is_port_in_range(self, ports_list): <TAB> for port_range in ports_list[0]: <TAB>  <TAB> port = force_int(port_range) <TAB>  <TAB> if port and self.port == port: <TAB>  <TAB>  <TAB> return True <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> [from_port, to_port] = port_range.split(""-"") <TAB>  <TAB>  <TAB>  <TAB> if int(from_port) <= self.port <= int(to_port): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> return CheckResult.UNKNOWN <TAB> return False","if port is None and ""-"" in port_range :",154
"def apply_to(cls, lexer): <TAB> # Apply a font for all styles <TAB> lexer.setFont(Font().load()) <TAB> for name, font in cls.__dict__.items(): <TAB>  <TAB> if not isinstance(font, Font): <TAB>  <TAB>  <TAB> continue <MASK> style_num = getattr(lexer, name) <TAB>  <TAB>  <TAB> lexer.setColor(QColor(font.color), style_num) <TAB>  <TAB>  <TAB> lexer.setEolFill(True, style_num) <TAB>  <TAB>  <TAB> lexer.setPaper(QColor(font.paper), style_num) <TAB>  <TAB>  <TAB> lexer.setFont(font.load(), style_num)","if hasattr ( lexer , name ) :",158
"def set_columns(worksheet, c, lengths): <TAB> for col, j in enumerate(c): <TAB>  <TAB> if j == ""Value"": <TAB>  <TAB>  <TAB> j = "" "" * 18 <MASK> j = ""Descr"" <TAB>  <TAB> lengths[col] = max(len(j) + 5, lengths[col]) <TAB>  <TAB> worksheet.set_column(col, col, lengths[col])","if j == ""Description"" :",101
"def _remove_listners(self): <TAB> object = self.object <TAB> kids = self.children_cache <TAB> for key, val in kids.items(): <MASK> vtk_obj = tvtk.to_vtk(val) <TAB>  <TAB>  <TAB> messenger.disconnect(vtk_obj, ""ModifiedEvent"", self._notify_children) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> object.on_trait_change(self._notify_children, key, remove=True)","if isinstance ( val , tvtk . Collection ) :",123
"def add(self, undoinfo, msg=None): <TAB> if not undoinfo: <TAB>  <TAB> return <TAB> if msg is not None: <MASK> # replace message <TAB>  <TAB>  <TAB> undoinfo = (msg,) + undoinfo[1:] <TAB>  <TAB> elif isinstance(undoinfo, tuple): <TAB>  <TAB>  <TAB> undoinfo = (msg,) + undoinfo <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> undoinfo = (msg, undoinfo) <TAB>  <TAB> f = 1 <TAB> else: <TAB>  <TAB> f = int(isinstance(undoinfo[0], str)) <TAB> assert ( <TAB>  <TAB> isinstance(undoinfo, list) <TAB>  <TAB> or callable(undoinfo[f]) <TAB>  <TAB> or isinstance(undoinfo[f], list) <TAB> ) <TAB> self.undoList.append(undoinfo) <TAB> del self.redoList[:]","if isinstance ( undoinfo [ 0 ] , str ) :",198
"def assert_last_day(self, period_end): <TAB> # 30 days has september, april, june and november <TAB> if period_end.month in [9, 4, 6, 11]: <TAB>  <TAB> self.assertEqual(period_end.day, 30) <TAB> # all the rest have 31, except for february <TAB> elif period_end.month != 2: <TAB>  <TAB> self.assertEqual(period_end.day, 31) <TAB> else: <MASK> self.assertEqual(period_end.day, 29) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertEqual(period_end.day, 28)",if calendar . isleap ( period_end . year ) :,165
"def remove_callback(self, callback, events=None): <TAB> if events is None: <TAB>  <TAB> for event in self._plugin_lifecycle_callbacks: <TAB>  <TAB>  <TAB> if callback in self._plugin_lifecycle_callbacks[event]: <TAB>  <TAB>  <TAB>  <TAB> self._plugin_lifecycle_callbacks[event].remove(callback) <TAB> else: <MASK> events = [events] <TAB>  <TAB> for event in events: <TAB>  <TAB>  <TAB> if callback in self._plugin_lifecycle_callbacks[event]: <TAB>  <TAB>  <TAB>  <TAB> self._plugin_lifecycle_callbacks[event].remove(callback)","if isinstance ( events , basestring ) :",148
"def get_count(self, peek=False): <TAB> if self.argument_supplied: <TAB>  <TAB> count = self.argument_value <TAB>  <TAB> if self.argument_negative: <MASK> count = -1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> count = -count <TAB>  <TAB>  <TAB> if not peek: <TAB>  <TAB>  <TAB>  <TAB> self.argument_negative = False <TAB>  <TAB> if not peek: <TAB>  <TAB>  <TAB> self.argument_supplied = False <TAB> else: <TAB>  <TAB> count = 1 <TAB> return count",if count == 0 :,126
"def is_alive(self): <TAB> if not self.runqemu: <TAB>  <TAB> return False <TAB> if os.path.isfile(self.qemu_pidfile): <TAB>  <TAB> f = open(self.qemu_pidfile, ""r"") <TAB>  <TAB> qemu_pid = f.read() <TAB>  <TAB> f.close() <TAB>  <TAB> qemupid = int(qemu_pid) <MASK> self.qemupid = qemupid <TAB>  <TAB>  <TAB> return True <TAB> return False","if os . path . exists ( ""/proc/"" + str ( qemupid ) ) :",140
"def contains(self, other_route): <TAB> if isinstance(other_route, list): <TAB>  <TAB> return self.to_list()[0 : len(other_route)] == other_route <TAB> # This only works before merging <TAB> assert len(other_route.outgoing) <= 1, ""contains(..) cannot be called after a merge"" <TAB> assert len(self.outgoing) <= 1, ""contains(..) cannot be called after a merge"" <TAB> if other_route.task_spec == self.task_spec: <TAB>  <TAB> if other_route.outgoing and self.outgoing: <TAB>  <TAB>  <TAB> return self.outgoing[0].contains(other_route.outgoing[0]) <TAB>  <TAB> elif self.outgoing: <TAB>  <TAB>  <TAB> return True <MASK> return True <TAB> return False",elif not other_route . outgoing :,184
"def _add_connection(self, connection, uri=None): <TAB> with self._connections_lock: <TAB>  <TAB> connection_id = connection.connection_id <MASK> self._connections[connection_id] = ConnectionInfo( <TAB>  <TAB>  <TAB>  <TAB> ConnectionType.OUTBOUND_CONNECTION, connection, uri, None, None <TAB>  <TAB>  <TAB> )",if connection_id not in self . _connections :,90
"def view(input_path): <TAB> if not exists(input_path): <TAB>  <TAB> raise IOError(""{0} not found"".format(input_path)) <TAB> ua = None <TAB> bundle_info = None <TAB> try: <TAB>  <TAB> archive = archive_factory(input_path) <TAB>  <TAB> if archive is None: <TAB>  <TAB>  <TAB> raise NotMatched(""No matching archive type found"") <TAB>  <TAB> ua = archive.unarchive_to_temp() <TAB>  <TAB> bundle_info = ua.bundle.info <TAB> finally: <MASK> ua.remove() <TAB> return bundle_info",if ua is not None :,139
"def _expect_fail_and_reconnect(self, num_reconnects, fail_last=False): <TAB> self._fake_backend.connect.expect_call(**_CONNECT_KWARGS).and_raises( <TAB>  <TAB> FakeDatabaseError() <TAB> ) <TAB> for i in xrange(num_reconnects): <TAB>  <TAB> time.sleep.expect_call(_RECONNECT_DELAY) <MASK> self._expect_reconnect(fail=True) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._expect_reconnect(fail=fail_last)",if i < num_reconnects - 1 :,139
def _trigger_step(self): <TAB> if self._enable_step: <TAB>  <TAB> if self.local_step != self.trainer.steps_per_epoch - 1: <TAB>  <TAB>  <TAB> # not the last step <TAB>  <TAB>  <TAB> self._trigger() <TAB>  <TAB> else: <MASK> self._trigger(),if not self . _enable_epoch :,83
"def draw_label(self): <TAB> if self.hide: <MASK> seed = "" + ({0})"".format(str(int(self.seed))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> seed = "" + seed(s)"" <TAB>  <TAB> return self.noise_type.title() + seed <TAB> else: <TAB>  <TAB> return self.label or self.name","if not self . inputs [ ""Seed"" ] . is_linked :",97
"def get_adapter(self, pattern=None): <TAB> adapters = self.get_adapters() <TAB> if pattern is None: <TAB>  <TAB> if len(adapters): <TAB>  <TAB>  <TAB> return adapters[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise DBusNoSuchAdapterError(""No adapter(s) found"") <TAB> else: <TAB>  <TAB> for adapter in adapters: <TAB>  <TAB>  <TAB> path = adapter.get_object_path() <MASK> return adapter <TAB>  <TAB> raise DBusNoSuchAdapterError(""No adapters found with pattern: %s"" % pattern)","if path . endswith ( pattern ) or adapter [ ""Address"" ] == pattern :",144
"def substituteargs(self, pattern, replacement, old): <TAB> new = [] <TAB> for k in range(len(replacement)): <TAB>  <TAB> item = replacement[k] <TAB>  <TAB> newitem = [item[0], item[1], item[2]] <TAB>  <TAB> for i in range(3): <MASK> newitem[i] = old[k][i] <TAB>  <TAB>  <TAB> elif item[i][:1] == ""$"": <TAB>  <TAB>  <TAB>  <TAB> index = int(item[i][1:]) - 1 <TAB>  <TAB>  <TAB>  <TAB> newitem[i] = old[index][i] <TAB>  <TAB> new.append(tuple(newitem)) <TAB> ##self.report(""old: %r"", old) <TAB> ##self.report(""new: %r"", new) <TAB> return new","if item [ i ] == ""*"" :",187
"def profiling_startup(): <TAB> if ""--profile-sverchok-startup"" in sys.argv: <TAB>  <TAB> global _profile_nesting <TAB>  <TAB> profile = None <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> profile = get_global_profile() <TAB>  <TAB>  <TAB> _profile_nesting += 1 <TAB>  <TAB>  <TAB> if _profile_nesting == 1: <TAB>  <TAB>  <TAB>  <TAB> profile.enable() <TAB>  <TAB>  <TAB> yield profile <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> _profile_nesting -= 1 <MASK> profile.disable() <TAB>  <TAB>  <TAB> dump_stats(file_path=""sverchok_profile.txt"") <TAB>  <TAB>  <TAB> save_stats(""sverchok_profile.prof"") <TAB> else: <TAB>  <TAB> yield None",if _profile_nesting == 0 and profile is not None :,180
"def align(size): <TAB> if size <= 4096: <TAB>  <TAB> # Small <TAB>  <TAB> if is_power2(size): <TAB>  <TAB>  <TAB> return size <TAB>  <TAB> elif size < 128: <TAB>  <TAB>  <TAB> return min_ge(range(16, 128 + 1, 16), size) <MASK> return min_ge(range(192, 512 + 1, 64), size) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return min_ge(range(768, 4096 + 1, 256), size) <TAB> elif size < 4194304: <TAB>  <TAB> # Large <TAB>  <TAB> return min_ge(range(4096, 4194304 + 1, 4096), size) <TAB> else: <TAB>  <TAB> # Huge <TAB>  <TAB> return min_ge(range(4194304, 536870912 + 1, 4194304), size)",elif size < 512 :,195
"def _validate(self, event): <TAB> new = self.value <TAB> if new is not None and ( <TAB>  <TAB> (self.start is not None and self.start > new) <TAB>  <TAB> or (self.end is not None and self.end < new) <TAB> ): <TAB>  <TAB> value = datetime.strftime(new, self.format) <TAB>  <TAB> start = datetime.strftime(self.start, self.format) <TAB>  <TAB> end = datetime.strftime(self.end, self.format) <MASK> self.value = event.old <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> ""DatetimeInput value must be between {start} and {end}, "" <TAB>  <TAB>  <TAB> ""supplied value is {value}"".format(start=start, end=end, value=value) <TAB>  <TAB> )",if event :,183
"def parse(filename): <TAB> dead_links = [] <TAB> with open(filename, ""r"") as file_: <TAB>  <TAB> for line in file_.readlines(): <TAB>  <TAB>  <TAB> res = reference_line.search(line) <TAB>  <TAB>  <TAB> if res: <MASK> dead_links.append(res.group(1)) <TAB> return dead_links",if not exists ( res . group ( 1 ) ) :,96
"def __getstate__(self): <TAB> state = super(_GeneralExpressionDataImpl, self).__getstate__() <TAB> for i in _GeneralExpressionDataImpl.__expression_slots__: <TAB>  <TAB> state[i] = getattr(self, i) <TAB> if safe_mode: <TAB>  <TAB> state[""_parent_expr""] = None <TAB>  <TAB> if self._parent_expr is not None: <TAB>  <TAB>  <TAB> _parent_expr = self._parent_expr() <MASK> state[""_parent_expr""] = _parent_expr <TAB> return state",if _parent_expr is not None :,132
"def insertText(self, data, parent=None): <TAB> data = data <TAB> if parent != self: <TAB>  <TAB> _base.TreeBuilder.insertText(self, data, parent) <TAB> else: <TAB>  <TAB> # HACK: allow text nodes as children of the document node <TAB>  <TAB> if hasattr(self.dom, ""_child_node_types""): <MASK> self.dom._child_node_types = list(self.dom._child_node_types) <TAB>  <TAB>  <TAB>  <TAB> self.dom._child_node_types.append(Node.TEXT_NODE) <TAB>  <TAB> self.dom.appendChild(self.dom.createTextNode(data))",if Node . TEXT_NODE not in self . dom . _child_node_types :,170
"def main(args): <TAB> from argparse import ArgumentParser <TAB> from sys import stdin, stdout <TAB> # TODO: Doc! <TAB> argparser = ArgumentParser() <TAB> argparser.add_argument(""-u"", ""--unescape"", action=""store_true"") <TAB> argp = argparser.parse_args(args[1:]) <TAB> for line in (l.rstrip(""\n"") for l in stdin): <MASK> r = unescape(line) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> r = escape(line) <TAB>  <TAB> stdout.write(r) <TAB>  <TAB> stdout.write(""\n"")",if argp . unescape :,138
"def validate_user_json(value, json_schema): <TAB> try: <TAB>  <TAB> jsonschema.validate(value, from_json(json_schema)) <TAB> except jsonschema.ValidationError as e: <MASK> raise InvalidModelValueError( <TAB>  <TAB>  <TAB>  <TAB> ""For '{}' the field value {}"".format(e.path[-1], e.message) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> raise InvalidModelValueError(e.message) <TAB> except jsonschema.SchemaError as e: <TAB>  <TAB> raise InvalidModelValueError(e.message) <TAB> validate_dates(value)",if len ( e . path ) > 1 :,140
"def test_mode(self): <TAB> with support.temp_umask(0o002): <TAB>  <TAB> base = support.TESTFN <TAB>  <TAB> parent = os.path.join(base, ""dir1"") <TAB>  <TAB> path = os.path.join(parent, ""dir2"") <TAB>  <TAB> os.makedirs(path, 0o555) <TAB>  <TAB> self.assertTrue(os.path.exists(path)) <TAB>  <TAB> self.assertTrue(os.path.isdir(path)) <MASK> self.assertEqual(os.stat(path).st_mode & 0o777, 0o555) <TAB>  <TAB>  <TAB> self.assertEqual(os.stat(parent).st_mode & 0o777, 0o775)","if os . name != ""nt"" :",169
"def __get_annotations(self): <TAB> if not hasattr(self, ""_annotations""): <TAB>  <TAB> self._annotations = _retrieve_annotations( <TAB>  <TAB>  <TAB> self._adaptor, self._primary_id, self._taxon_id <TAB>  <TAB> ) <MASK> self._annotations[""gi""] = self._identifier <TAB>  <TAB> if self._division: <TAB>  <TAB>  <TAB> self._annotations[""data_file_division""] = self._division <TAB> return self._annotations",if self . _identifier :,110
"def string(self): <TAB> """"""Returns a PlayString in string format from the Patterns values"""""" <TAB> string = """" <TAB> for item in self.data: <MASK> string += item.string() <TAB>  <TAB> elif isinstance(item, Pattern): <TAB>  <TAB>  <TAB> string += ( <TAB>  <TAB>  <TAB>  <TAB> ""("" <TAB>  <TAB>  <TAB>  <TAB> + """".join( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> (s.string() if hasattr(s, ""string"") else str(s)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for s in item.data <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> + "")"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> string += str(item) <TAB> return string","if isinstance ( item , ( PGroup , GeneratorPattern ) ) :",183
"def __getattribute__(self, item): <TAB> try: <TAB>  <TAB> val = self[item] <MASK> val = import_string(val) <TAB>  <TAB> elif isinstance(val, (list, tuple)): <TAB>  <TAB>  <TAB> val = [import_string(v) if isinstance(v, str) else v for v in val] <TAB>  <TAB> self[item] = val <TAB> except KeyError: <TAB>  <TAB> val = super(ObjDict, self).__getattribute__(item) <TAB> return val","if isinstance ( val , str ) :",118
"def get_identifiers(self): <TAB> ids = [] <TAB> ifaces = [i[""name""] for i in self.middleware.call_sync(""interface.query"")] <TAB> for entry in glob.glob(f""{self._base_path}/interface-*""): <TAB>  <TAB> ident = entry.rsplit(""-"", 1)[-1] <MASK> continue <TAB>  <TAB> if os.path.exists(os.path.join(entry, ""if_octets.rrd"")): <TAB>  <TAB>  <TAB> ids.append(ident) <TAB> ids.sort(key=RRDBase._sort_disks) <TAB> return ids",if ident not in ifaces :,143
"def save_new_objects(self, commit=True): <TAB> self.new_objects = [] <TAB> for form in self.extra_forms: <TAB>  <TAB> if not form.has_changed(): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # If someone has marked an add form for deletion, don't save the <TAB>  <TAB> # object. <MASK> continue <TAB>  <TAB> self.new_objects.append(self.save_new(form, commit=commit)) <TAB>  <TAB> if not commit: <TAB>  <TAB>  <TAB> self.saved_forms.append(form) <TAB> return self.new_objects",if self . can_delete and self . _should_delete_form ( form ) :,151
"def _get_seccomp_whitelist(self): <TAB> whitelist = [False] * MAX_SYSCALL_NUMBER <TAB> index = _SYSCALL_INDICIES[NATIVE_ABI] <TAB> for i in range(SYSCALL_COUNT): <TAB>  <TAB> # Ensure at least one syscall traps. <TAB>  <TAB> # Otherwise, a simple assembly program could terminate without ever trapping. <TAB>  <TAB> if i in (sys_exit, sys_exit_group): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> handler = self._security.get(i, DISALLOW) <TAB>  <TAB> for call in translator[i][index]: <MASK> continue <TAB>  <TAB>  <TAB> if isinstance(handler, int): <TAB>  <TAB>  <TAB>  <TAB> whitelist[call] = handler == ALLOW <TAB> return whitelist",if call is None :,185
"def start_check(aggregate, out): <TAB> """"""Start checking in background and write encoded output to out."""""" <TAB> # check in background <TAB> t = threading.Thread(target=director.check_urls, args=(aggregate,)) <TAB> t.start() <TAB> # time to wait for new data <TAB> sleep_seconds = 2 <TAB> # current running time <TAB> run_seconds = 0 <TAB> while not aggregate.is_finished(): <TAB>  <TAB> yield out.get_data() <TAB>  <TAB> time.sleep(sleep_seconds) <TAB>  <TAB> run_seconds += sleep_seconds <MASK> director.abort(aggregate) <TAB>  <TAB>  <TAB> break <TAB> yield out.get_data()",if run_seconds > MAX_REQUEST_SECONDS :,166
"def _prune_resource_identifiers(self, all_resources, all_operations): <TAB> used_identifiers = self._get_identifiers_referenced_by_operations(all_operations) <TAB> for resource, resource_data in list(all_resources.items()): <TAB>  <TAB> identifiers = resource_data[""resourceIdentifier""] <TAB>  <TAB> known_ids_for_resource = used_identifiers.get(resource, set()) <TAB>  <TAB> for identifier_name in list(identifiers): <MASK> del identifiers[identifier_name] <TAB>  <TAB> if not identifiers: <TAB>  <TAB>  <TAB> # If there's no identifiers used by an autocompletion <TAB>  <TAB>  <TAB> # operation, then we don't need the resource. <TAB>  <TAB>  <TAB> del all_resources[resource]",if identifier_name not in known_ids_for_resource :,179
"def has_valid_checksum(self, number): <TAB> given_number, given_checksum = number[:-1], number[-1] <TAB> calculated_checksum = 0 <TAB> parameter = 7 <TAB> for item in given_number: <TAB>  <TAB> fragment = str(int(item) * parameter) <TAB>  <TAB> if fragment.isalnum(): <TAB>  <TAB>  <TAB> calculated_checksum += int(fragment[-1]) <MASK> parameter = 7 <TAB>  <TAB> elif parameter == 3: <TAB>  <TAB>  <TAB> parameter = 1 <TAB>  <TAB> elif parameter == 7: <TAB>  <TAB>  <TAB> parameter = 3 <TAB> return str(calculated_checksum)[-1] == given_checksum",if parameter == 1 :,147
"def _poll_until_not(url, pending_statuses, err_msg): <TAB> while True: <TAB>  <TAB> result, _, _ = _do_request(url, err_msg=err_msg) <MASK> time.sleep(2) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> return result","if result [ ""status"" ] in pending_statuses :",80
"def wrapper(request, *args, **kw): <TAB> if switch_is_active(""disable-bigquery""): <MASK> response = http.HttpResponse(content_type=""text/csv; charset=utf-8"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> response = http.HttpResponse(content_type=""application/json"", content=""[]"") <TAB>  <TAB> response.status_code = 503 <TAB>  <TAB> return response <TAB> return f(request, *args, **kw)","if kw . get ( ""format"" ) == ""csv"" :",119
"def completion_safe_apply(ctx, f, args): <TAB> from guild import config <TAB> with config.SetGuildHome(ctx.parent.params.get(""guild_home"")): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return f(*args) <TAB>  <TAB> except (Exception, SystemExit): <MASK> raise <TAB>  <TAB>  <TAB> return None","if os . getenv ( ""_GUILD_COMPLETE_DEBUG"" ) == ""1"" :",99
"def configure(self, **kw): <TAB> """"""Configure the image."""""" <TAB> res = () <TAB> for k, v in _cnfmerge(kw).items(): <MASK> if k[-1] == ""_"": <TAB>  <TAB>  <TAB>  <TAB> k = k[:-1] <TAB>  <TAB>  <TAB> if hasattr(v, ""__call__""): <TAB>  <TAB>  <TAB>  <TAB> v = self._register(v) <TAB>  <TAB>  <TAB> elif k in (""data"", ""maskdata""): <TAB>  <TAB>  <TAB>  <TAB> v = self.tk._createbytearray(v) <TAB>  <TAB>  <TAB> res = res + (""-"" + k, v) <TAB> self.tk.call((self.name, ""config"") + res)",if v is not None :,154
"def _editor_lower(self): <TAB> editorWidget = main_container.MainContainer().get_actual_editor() <TAB> if editorWidget: <TAB>  <TAB> editorWidget.textCursor().beginEditBlock() <MASK> text = editorWidget.textCursor().selectedText().lower() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> text = editorWidget._text_under_cursor().lower() <TAB>  <TAB>  <TAB> editorWidget.moveCursor(QTextCursor.StartOfWord) <TAB>  <TAB>  <TAB> editorWidget.moveCursor(QTextCursor.EndOfWord, QTextCursor.KeepAnchor) <TAB>  <TAB> editorWidget.textCursor().insertText(text) <TAB>  <TAB> editorWidget.textCursor().endEditBlock()",if editorWidget . textCursor ( ) . hasSelection ( ) :,169
"def on_key_release(self, symbol, modifiers): <TAB> if symbol == key.LEFT or symbol == key.RIGHT: <TAB>  <TAB> self.value = not self.value <TAB>  <TAB> self.text.text = self.get_label() <TAB>  <TAB> self.toggle_func(self.value) <MASK> bullet_sound.play()",if enable_sound :,86
"def remove_checker(self, namespace, checker): <TAB> for c in pyomo.core.check.ModelCheckRunner._checkers(all=True): <MASK> if namespace.checkers.get(c._checkerPackage(), None) is not None: <TAB>  <TAB>  <TAB>  <TAB> for i in range( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> namespace.checkers[c._checkerPackage()].count(c._checkerName()) <TAB>  <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> namespace.checkers[c._checkerPackage()].remove(c._checkerName())",if c . _checkerName ( ) == checker :,129
"def find_executable(names): <TAB> # Given a list of executable names, find the first one that is available <TAB> # as an executable file, on the path. <TAB> for name in names: <TAB>  <TAB> fpath, fname = os.path.split(name) <MASK> # The given name is absolute. <TAB>  <TAB>  <TAB> if is_executable(name): <TAB>  <TAB>  <TAB>  <TAB> return name <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Try to find the name on the PATH <TAB>  <TAB>  <TAB> for path in os.environ[""PATH""].split(os.pathsep): <TAB>  <TAB>  <TAB>  <TAB> exe_file = os.path.join(path, name) <TAB>  <TAB>  <TAB>  <TAB> if is_executable(exe_file): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return exe_file <TAB> # Could not find it :( <TAB> return None",if fpath :,186
"def run(self): <TAB> while True: <TAB>  <TAB> self.finished.wait(self.interval) <TAB>  <TAB> if self.finished.isSet(): <TAB>  <TAB>  <TAB> return <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.function(*self.args, **self.kwargs) <TAB>  <TAB> except Exception: <MASK> self.bus.log( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Error in perpetual timer thread function %r."" % self.function, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> level=40, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> traceback=True, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> # Quit on first error to avoid massive logs. <TAB>  <TAB>  <TAB> raise",if self . bus :,157
"def get_user_object(self, user_id, group): <TAB> if user_id: <TAB>  <TAB> user = OSFUser.load(user_id) <TAB>  <TAB> if not user: <TAB>  <TAB>  <TAB> raise exceptions.NotFound( <TAB>  <TAB>  <TAB>  <TAB> detail=""User with id {} not found."".format(user_id) <TAB>  <TAB>  <TAB> ) <MASK> raise exceptions.ValidationError( <TAB>  <TAB>  <TAB>  <TAB> detail=""User is already a member of this group."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return user <TAB> return user_id","if group . has_permission ( user , ""member"" ) :",135
"def build_term_table(spec): <TAB> try: <TAB>  <TAB> return _term_tables_cache[spec] <TAB> except KeyError: <TAB>  <TAB> tbl = {} <TAB>  <TAB> terms = {} <TAB>  <TAB> i = 0 <TAB>  <TAB> for t in spec: <TAB>  <TAB>  <TAB> which = terms.setdefault(t, 0) <TAB>  <TAB>  <TAB> tbl[t, which] = i <TAB>  <TAB>  <TAB> tbl[""%s_%d"" % (t, which)] = i <MASK> tbl[t] = i <TAB>  <TAB>  <TAB> terms[t] += 1 <TAB>  <TAB>  <TAB> i += 1 <TAB>  <TAB> _term_tables_cache[spec] = tbl <TAB>  <TAB> return tbl",if which == 0 :,158
"def GetQualifiedWsdlName(type): <TAB> with _lazyLock: <TAB>  <TAB> wsdlNSAndName = _wsdlNameMap.get(type) <TAB>  <TAB> if wsdlNSAndName: <TAB>  <TAB>  <TAB> return wsdlNSAndName <TAB>  <TAB> else: <MASK> ns = GetWsdlNamespace(type.Item._version) <TAB>  <TAB>  <TAB>  <TAB> return (ns, ""ArrayOf"" + Capitalize(type.Item._wsdlName)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> ns = GetWsdlNamespace(type._version) <TAB>  <TAB>  <TAB>  <TAB> return (ns, type._wsdlName)","if issubclass ( type , list ) :",158
"def train(config, checkpoint_dir=None): <TAB> restored = bool(checkpoint_dir) <TAB> itr = 0 <TAB> if checkpoint_dir: <TAB>  <TAB> with open(os.path.join(checkpoint_dir, ""ckpt.log""), ""r"") as f: <TAB>  <TAB>  <TAB> itr = int(f.read()) + 1 <TAB> for i in range(itr, 10): <MASK> raise Exception(""try to fail me"") <TAB>  <TAB> with tune.checkpoint_dir(step=itr) as checkpoint_dir: <TAB>  <TAB>  <TAB> checkpoint_path = os.path.join(checkpoint_dir, ""ckpt.log"") <TAB>  <TAB>  <TAB> with open(checkpoint_path, ""w"") as f: <TAB>  <TAB>  <TAB>  <TAB> f.write(str(i)) <TAB>  <TAB> tune.report(test=i, training_iteration=i)",if i == 5 and not restored :,198
"def _process_events(self, event_list): <TAB> for key, mask in event_list: <TAB>  <TAB> fileobj, (reader, writer) = key.fileobj, key.data <TAB>  <TAB> if mask & selectors.EVENT_READ and reader is not None: <TAB>  <TAB>  <TAB> if reader._cancelled: <TAB>  <TAB>  <TAB>  <TAB> self.remove_reader(fileobj) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._add_callback(reader) <TAB>  <TAB> if mask & selectors.EVENT_WRITE and writer is not None: <MASK> self.remove_writer(fileobj) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._add_callback(writer)",if writer . _cancelled :,158
"def _validate_mappings(self): <TAB> # Validate mapping references <TAB> for m in self.mapping.mapping_rules: <TAB>  <TAB> for policy_id in m.policy_ids: <TAB>  <TAB>  <TAB> if policy_id not in self.policies: <TAB>  <TAB>  <TAB>  <TAB> raise ReferencedObjectNotFoundError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> reference_id=policy_id, reference_type=""policy"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> for w in m.whitelist_ids: <MASK> raise ReferencedObjectNotFoundError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> reference_id=w, reference_type=""whitelist"" <TAB>  <TAB>  <TAB>  <TAB> )",if w not in self . whitelists :,155
"def _transform_backward(graph, op): <TAB> no_dequanted_input_vars = True <TAB> for var_node in op.inputs: <MASK> dequant_var_node = dequantized_vars[var_node.name()] <TAB>  <TAB>  <TAB> graph.update_input_link(var_node, dequant_var_node, op) <TAB>  <TAB>  <TAB> no_dequanted_input_vars = False <TAB> if no_dequanted_input_vars: <TAB>  <TAB> raise ValueError(""There is no dequanted inputs for op %s."" % (op.name()))",if var_node . name ( ) in dequantized_vars :,150
"def should_use_pty(self, pty=False, fallback=True): <TAB> use_pty = False <TAB> if pty: <TAB>  <TAB> use_pty = True <TAB>  <TAB> # TODO: pass in & test in_stream, not sys.stdin <MASK> if not self.warned_about_pty_fallback: <TAB>  <TAB>  <TAB>  <TAB> err = ""WARNING: stdin has no fileno; falling back to non-pty execution!\n""  # noqa <TAB>  <TAB>  <TAB>  <TAB> sys.stderr.write(err) <TAB>  <TAB>  <TAB>  <TAB> self.warned_about_pty_fallback = True <TAB>  <TAB>  <TAB> use_pty = False <TAB> return use_pty",if not has_fileno ( sys . stdin ) and fallback :,171
"def _get_default_factory(self, attribute_name: str) -> Any: <TAB> if hasattr(self, attribute_name): <MASK> return str(getattr(self, attribute_name)) <TAB>  <TAB> elif str(self.__dataclass_fields__[attribute_name].default).startswith(""${""): <TAB>  <TAB>  <TAB> return str(self.__dataclass_fields__[attribute_name].default) <TAB>  <TAB> elif ( <TAB>  <TAB>  <TAB> getattr(self, attribute_name) <TAB>  <TAB>  <TAB> != self.__dataclass_fields__[attribute_name].default_factory() <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> return getattr(self, attribute_name) <TAB> return self.__dataclass_fields__[attribute_name].default_factory()","if str ( getattr ( self , attribute_name ) ) . startswith ( ""${"" ) :",173
"def create_row_processor( <TAB> self, context, path, loadopt, mapper, result, adapter, populators): <TAB> # look through list of columns represented here <TAB> # to see which, if any, is present in the row. <TAB> for col in self.columns: <MASK> col = adapter.columns[col] <TAB>  <TAB> getter = result._getter(col, False) <TAB>  <TAB> if getter: <TAB>  <TAB>  <TAB> populators[""quick""].append((self.key, getter)) <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> populators[""expire""].append((self.key, True))",if adapter :,145
"def test_finds_multiple_songs(self): <TAB> for _, album in albums_in_dir(self.base): <TAB>  <TAB> n = re.search(br""album(.)song"", album[0]).group(1) <MASK> self.assertEqual(len(album), 2) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertEqual(len(album), 1)","if n == b""1"" :",95
"def _should_update_cache(self, request, response): <TAB> if not hasattr(request, ""_cache_update_cache"") or not request._cache_update_cache: <TAB>  <TAB> return False <TAB> if self.cache_anonymous_only and has_vary_header(response, ""Cookie""): <TAB>  <TAB> assert hasattr( <TAB>  <TAB>  <TAB> request, ""user"" <TAB>  <TAB> ), ""The Django cache middleware with CACHE_MIDDLEWARE_ANONYMOUS_ONLY=True requires authentication middleware to be installed. Edit your MIDDLEWARE_CLASSES setting to insert 'django.contrib.auth.middleware.AuthenticationMiddleware' before the CacheMiddleware."" <MASK> # Don't cache user-variable requests from authenticated users. <TAB>  <TAB>  <TAB> return False <TAB> return True",if request . user . is_authenticated ( ) :,180
"def break_next_call(symbol_regex=None): <TAB> while pwndbg.proc.alive: <TAB>  <TAB> ins = break_next_branch() <MASK> break <TAB>  <TAB> # continue if not a call <TAB>  <TAB> if capstone.CS_GRP_CALL not in ins.groups: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # return call if we don't search for a symbol <TAB>  <TAB> if not symbol_regex: <TAB>  <TAB>  <TAB> return ins <TAB>  <TAB> # return call if we match target address <TAB>  <TAB> if ins.target_const and re.match(""%s$"" % symbol_regex, hex(ins.target)): <TAB>  <TAB>  <TAB> return ins <TAB>  <TAB> # return call if we match symbol name <TAB>  <TAB> if ins.symbol and re.match(""%s$"" % symbol_regex, ins.symbol): <TAB>  <TAB>  <TAB> return ins",if not ins :,193
"def parser(cls, buf, offset): <TAB> type_, len_, vendor = struct.unpack_from( <TAB>  <TAB> ofproto.OFP_ACTION_VENDOR_HEADER_PACK_STR, buf, offset <TAB> ) <TAB> data = buf[(offset + ofproto.OFP_ACTION_VENDOR_HEADER_SIZE) : offset + len_] <TAB> if vendor == ofproto_common.NX_EXPERIMENTER_ID: <TAB>  <TAB> obj = NXAction.parse(data)  # noqa <TAB> else: <TAB>  <TAB> cls_ = cls._ACTION_VENDORS.get(vendor, None) <MASK> obj = OFPActionVendorUnknown(vendor, data) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> obj = cls_.parser(buf, offset) <TAB> obj.len = len_ <TAB> return obj",if cls_ is None :,196
"def remove_empty_files(root_path): <TAB> """"""Removes empty files in a path recursively"""""" <TAB> for directory, _, filenames in walk(root_path): <TAB>  <TAB> for filename in filenames: <TAB>  <TAB>  <TAB> path = os.path.join(directory, filename) <MASK> continue <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> os.remove(path) <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> logs.log_error( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Unable to remove the empty file: %s (%s)."" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> % (path, sys.exc_info()[0]) <TAB>  <TAB>  <TAB>  <TAB> )",if os . path . getsize ( path ) > 0 :,160
"def _test_set_ipv4_src(self, ip, mask=None): <TAB> header = ofproto.OXM_OF_IPV4_SRC <TAB> match = OFPMatch() <TAB> ip = unpack(""!I"", socket.inet_aton(ip))[0] <TAB> if mask is None: <TAB>  <TAB> match.set_ipv4_src(ip) <TAB> else: <TAB>  <TAB> mask = unpack(""!I"", socket.inet_aton(mask))[0] <MASK> header = ofproto.OXM_OF_IPV4_SRC_W <TAB>  <TAB> match.set_ipv4_src_masked(ip, mask) <TAB> self._test_serialize_and_parser(match, header, ip, mask)",if ( mask + 1 ) >> 32 != 1 :,182
"def is_valid_block(self): <TAB> """"""check wheter the block is valid in the current position"""""" <TAB> for i in range(self.block.x): <TAB>  <TAB> for j in range(self.block.x): <TAB>  <TAB>  <TAB> if self.block.get(i, j): <TAB>  <TAB>  <TAB>  <TAB> if self.block.pos.x + i < 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB>  <TAB> if self.block.pos.x + i >= COLUMNS: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB>  <TAB> if self.block.pos.y + j < 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <MASK> return False <TAB> return True","if self . map . get ( ( self . block . pos . x + i , self . block . pos . y + j ) , False ) :",192
"def __init__(self, *args, **kwargs): <TAB> dict.__init__(self, *args, **kwargs) <TAB> for key, value in self.items(): <MASK> raise TypeError(""key must be a str, not {}"".format(type(key))) <TAB>  <TAB> if not isinstance(value, NUMERIC_TYPES): <TAB>  <TAB>  <TAB> raise TypeError(""value must be a NUMERIC_TYPES, not {}"".format(type(value))) <TAB>  <TAB> if not isinstance(value, float): <TAB>  <TAB>  <TAB> self[key] = float(value)","if not isinstance ( key , string_types ) :",132
"def refresh_committed_offsets_if_needed(self): <TAB> """"""Fetch committed offsets for assigned partitions."""""" <TAB> if self._subscription.needs_fetch_committed_offsets: <TAB>  <TAB> offsets = self.fetch_committed_offsets(self._subscription.assigned_partitions()) <TAB>  <TAB> for partition, offset in six.iteritems(offsets): <TAB>  <TAB>  <TAB> # verify assignment is still active <MASK> self._subscription.assignment[partition].committed = offset.offset <TAB>  <TAB> self._subscription.needs_fetch_committed_offsets = False",if self . _subscription . is_assigned ( partition ) :,143
"def getText(self, stuff): <TAB> if isinstance(stuff, BaseWrapper): <TAB>  <TAB> stuff = stuff.item <TAB> if isinstance(stuff, (Fit, TargetProfile)): <TAB>  <TAB> val, unit = self._getValue(stuff) <MASK> return """" <TAB>  <TAB> # Stick to value - 25k GJ <TAB>  <TAB> if self.stickPrefixToValue: <TAB>  <TAB>  <TAB> return ""{} {}"".format(formatAmount(val, *self.formatSpec), unit) <TAB>  <TAB> # Stick to unit - 25 km <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return formatAmount(val, *self.formatSpec, unitName=unit) <TAB> return """"",if val is None :,155
"def __get__(self, inst, owner): <TAB> try: <TAB>  <TAB> value, last_update = inst._cache[self.__name__] <MASK> raise AttributeError <TAB> except (KeyError, AttributeError): <TAB>  <TAB> value = self.fget(inst) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> cache = inst._cache <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB> cache = inst._cache = {} <TAB>  <TAB> cache[self.__name__] = (value, time.time()) <TAB> return value",if self . ttl > 0 and time . time ( ) - last_update > self . ttl :,134
"def on_event_clicked(self, widget, event): <TAB> if event.type == Gdk.EventType.BUTTON_PRESS and event.button == 3: <TAB>  <TAB> path = self.get_path_at_pos(int(event.x), int(event.y)) <MASK> row = self.get(path[0], ""device"") <TAB>  <TAB>  <TAB> if row: <TAB>  <TAB>  <TAB>  <TAB> if self.Blueman is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if self.menu is None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.menu = ManagerDeviceMenu(self.Blueman) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.menu.popup(None, None, None, None, event.button, event.time)",if path is not None :,170
"def groups(self): <TAB> """"""Return a dictionary mapping group names to JIDs."""""" <TAB> result = {} <TAB> for jid in self._jids: <TAB>  <TAB> groups = self._jids[jid][""groups""] <MASK> if """" not in result: <TAB>  <TAB>  <TAB>  <TAB> result[""""] = [] <TAB>  <TAB>  <TAB> result[""""].append(jid) <TAB>  <TAB> for group in groups: <TAB>  <TAB>  <TAB> if group not in result: <TAB>  <TAB>  <TAB>  <TAB> result[group] = [] <TAB>  <TAB>  <TAB> result[group].append(jid) <TAB> return result",if not groups :,133
"def set_meta(self, dataset, overwrite=True, **kwd): <TAB> super().set_meta(dataset, overwrite=overwrite, **kwd) <TAB> try: <TAB>  <TAB> conn = sqlite.connect(dataset.file_name) <TAB>  <TAB> c = conn.cursor() <TAB>  <TAB> version_query = ""SELECT version FROM meta"" <TAB>  <TAB> results = c.execute(version_query).fetchall() <TAB>  <TAB> if len(results) == 0: <TAB>  <TAB>  <TAB> raise Exception(""version not found in meta table"") <MASK> raise Exception(""Multiple versions found in meta table"") <TAB>  <TAB> dataset.metadata.gafa_schema_version = results[0][0] <TAB> except Exception as e: <TAB>  <TAB> log.warning(""%s, set_meta Exception: %s"", self, e)",elif len ( results ) > 1 :,188
"def GetSelectedCount(self): <TAB> if self.GetStyleL(""style"") & self.Style.LBS_MULTIPLESEL: <TAB>  <TAB> return self.SendMessage(self.Hwnd, self.Msg.LB_GETSELCOUNT, 0, 0) <TAB> else: <TAB>  <TAB> result = self.SendMessage(self.Hwnd, self.Msg.LB_GETCURSEL, 0, 0) <MASK> return 0 <TAB>  <TAB> return 1",if result == LB_ERR :,117
"def emit(self, record): <TAB> try: <TAB>  <TAB> item = QListWidgetItem(self.format(record)) <MASK> item.setIcon(QIcon.fromTheme(""dialog-warning"")) <TAB>  <TAB>  <TAB> item.setForeground(QBrush(Qt.red)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> item.setIcon(QIcon.fromTheme(""dialog-information"")) <TAB>  <TAB> self.app.exec_in_main(self._add_item, item) <TAB> except (KeyboardInterrupt, SystemExit): <TAB>  <TAB> raise <TAB> except: <TAB>  <TAB> self.handleError(record)",if record . levelno > logging . INFO :,142
"def _updater(data): <TAB> assert data[""attrs""][""tvm_version""].startswith(from_ver) <TAB> nodes = data[""nodes""] <TAB> for idx, item in enumerate(nodes): <TAB>  <TAB> f = node_map.get(item[""type_key""], None) <MASK> for fpass in f: <TAB>  <TAB>  <TAB>  <TAB> item = fpass(item, nodes) <TAB>  <TAB> elif f: <TAB>  <TAB>  <TAB> item = f(item, nodes) <TAB>  <TAB> nodes[idx] = item <TAB> data[""attrs""][""tvm_version""] = to_ver <TAB> return data","if isinstance ( f , list ) :",143
def remove_data(self): <TAB> if self.path is not None: <MASK> os.remove(self.path) <TAB>  <TAB> if os.path.exists(self.get_json_path()): <TAB>  <TAB>  <TAB> os.remove(self.get_json_path()),if os . path . exists ( self . path ) :,78
"def testsingle(self, sym): <TAB> if self.settings == ""asterisk"": <TAB>  <TAB> return (sym == ""*"", ""*"") <TAB> if self.settings == ""plus"": <TAB>  <TAB> return (sym == ""+"", ""+"") <TAB> if self.settings == ""dash"": <TAB>  <TAB> return (sym == ""-"", ""-"") <TAB> if self.settings == ""single"": <MASK> return (self.lastSym == sym, self.lastSym) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.lastSym = sym <TAB>  <TAB>  <TAB> return (True, None) <TAB> return (None, None)",if self . lastSym :,138
"def update(self, other_dict, option_parser): <TAB> if isinstance(other_dict, Values): <TAB>  <TAB> other_dict = other_dict.__dict__ <TAB> other_dict = other_dict.copy() <TAB> for setting in option_parser.lists.keys(): <MASK> value = getattr(self, setting) <TAB>  <TAB>  <TAB> if value: <TAB>  <TAB>  <TAB>  <TAB> value += other_dict[setting] <TAB>  <TAB>  <TAB>  <TAB> del other_dict[setting] <TAB> self._update_loose(other_dict)","if hasattr ( self , setting ) and setting in other_dict :",137
"def gprv_immv(ii): <TAB> for i, op in enumerate(_gen_opnds(ii)): <TAB>  <TAB> if i == 0: <MASK> continue <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> elif i == 1: <TAB>  <TAB>  <TAB> if op_immv(op): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> return True","if op . name == ""REG0"" and op_luf_start ( op , ""GPRv"" ) :",136
"def __call__(self, input_tensors, shape): <TAB> if self.order in ""KA"": <MASK> order = TensorOrder.C_ORDER <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> order = TensorOrder.F_ORDER <TAB> else: <TAB>  <TAB> if self.order == ""C"": <TAB>  <TAB>  <TAB> order = TensorOrder.C_ORDER <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> order = TensorOrder.F_ORDER <TAB> return self.new_tensor(input_tensors, shape=shape, dtype=self.dtype, order=order)",if any ( t . order == TensorOrder . C_ORDER for t in input_tensors ) :,141
"def check_selected(menu, path): <TAB> selected = False <TAB> if ""url"" in menu: <TAB>  <TAB> chop_index = menu[""url""].find(""?"") <MASK> selected = path.startswith(menu[""url""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> selected = path.startswith(menu[""url""][:chop_index]) <TAB> if ""menus"" in menu: <TAB>  <TAB> for m in menu[""menus""]: <TAB>  <TAB>  <TAB> _s = check_selected(m, path) <TAB>  <TAB>  <TAB> if _s: <TAB>  <TAB>  <TAB>  <TAB> selected = True <TAB> if selected: <TAB>  <TAB> menu[""selected""] = True <TAB> return selected",if chop_index == - 1 :,153
"def _check_events(self): <TAB> # make sure song-started and song-ended match up <TAB> stack = [] <TAB> old = self.events[:] <TAB> for type_, song in self.events: <TAB>  <TAB> if type_ == ""started"": <TAB>  <TAB>  <TAB> stack.append(song) <MASK> self.assertTrue(stack.pop(-1) is song, msg=old) <TAB> self.assertFalse(stack, msg=old)","elif type_ == ""ended"" :",110
"def __fixdict(self, dict): <TAB> for key in dict.keys(): <TAB>  <TAB> if key[:6] == ""start_"": <TAB>  <TAB>  <TAB> tag = key[6:] <TAB>  <TAB>  <TAB> start, end = self.elements.get(tag, (None, None)) <TAB>  <TAB>  <TAB> if start is None: <TAB>  <TAB>  <TAB>  <TAB> self.elements[tag] = getattr(self, key), end <MASK> tag = key[4:] <TAB>  <TAB>  <TAB> start, end = self.elements.get(tag, (None, None)) <TAB>  <TAB>  <TAB> if end is None: <TAB>  <TAB>  <TAB>  <TAB> self.elements[tag] = start, getattr(self, key)","elif key [ : 4 ] == ""end_"" :",162
"def nested_match(expect, value): <TAB> if expect == value: <TAB>  <TAB> return True <TAB> if isinstance(expect, dict) and isinstance(value, dict): <TAB>  <TAB> for k, v in expect.items(): <MASK> if not nested_match(v, value[k]): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True <TAB> if isinstance(expect, list) and isinstance(value, list): <TAB>  <TAB> for x, y in zip(expect, value): <TAB>  <TAB>  <TAB> if not nested_match(x, y): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True <TAB> return False",if k in value :,162
"def code_match(code, select, ignore): <TAB> if ignore: <TAB>  <TAB> assert not isinstance(ignore, unicode) <TAB>  <TAB> for ignored_code in [c.strip() for c in ignore]: <MASK> return False <TAB> if select: <TAB>  <TAB> assert not isinstance(select, unicode) <TAB>  <TAB> for selected_code in [c.strip() for c in select]: <TAB>  <TAB>  <TAB> if mutual_startswith(code.lower(), selected_code.lower()): <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> return False <TAB> return True","if mutual_startswith ( code . lower ( ) , ignored_code . lower ( ) ) :",143
"def test_cardinality_m2o(self): <TAB> m2o_type_fields = [ <TAB>  <TAB> f for f in self.fields_and_reverse_objects if f.is_relation and f.many_to_one <TAB> ] <TAB> # Test classes are what we expect <TAB> self.assertEqual(MANY_TO_ONE_CLASSES, {f.__class__ for f in m2o_type_fields}) <TAB> # Ensure all m2o reverses are o2m <TAB> for obj in m2o_type_fields: <MASK> reverse_field = obj.field <TAB>  <TAB>  <TAB> self.assertTrue(reverse_field.is_relation and reverse_field.one_to_many)","if hasattr ( obj , ""field"" ) :",172
"def flatten_dict(self, request): <TAB> dct = super(KnowledgeFolderHandler, self).flatten_dict(request) <TAB> dct[""knowledgeType_id""] = None <TAB> parent = request.data.get(""parent"") <TAB> if parent: <TAB>  <TAB> parent = getOrNone(KnowledgeFolder, pk=parent) <MASK> request.data[""parent""] = None <TAB> return dct","if not parent or not request . user . profile . has_permission ( parent , mode = ""x"" ) :",116
"def delete_oidc_session_tokens(session): <TAB> if session: <TAB>  <TAB> if ""oidc_access_token"" in session: <TAB>  <TAB>  <TAB> del session[""oidc_access_token""] <MASK> del session[""oidc_id_token""] <TAB>  <TAB> if ""oidc_id_token_expiration"" in session: <TAB>  <TAB>  <TAB> del session[""oidc_id_token_expiration""] <TAB>  <TAB> if ""oidc_login_next"" in session: <TAB>  <TAB>  <TAB> del session[""oidc_login_next""] <TAB>  <TAB> if ""oidc_refresh_token"" in session: <TAB>  <TAB>  <TAB> del session[""oidc_refresh_token""] <TAB>  <TAB> if ""oidc_state"" in session: <TAB>  <TAB>  <TAB> del session[""oidc_state""]","if ""oidc_id_token"" in session :",179
"def prepare_text(text, style): <TAB> body = [] <TAB> for fragment, sty in parse_tags(text, style, subs.styles): <TAB>  <TAB> fragment = fragment.replace(r""\h"", "" "") <TAB>  <TAB> fragment = fragment.replace(r""\n"", ""\n"") <TAB>  <TAB> fragment = fragment.replace(r""\N"", ""\n"") <TAB>  <TAB> if sty.italic: <TAB>  <TAB>  <TAB> fragment = ""<i>%s</i>"" % fragment <TAB>  <TAB> if sty.underline: <TAB>  <TAB>  <TAB> fragment = ""<u>%s</u>"" % fragment <MASK> fragment = ""<s>%s</s>"" % fragment <TAB>  <TAB> if sty.drawing: <TAB>  <TAB>  <TAB> raise ContentNotUsable <TAB>  <TAB> body.append(fragment) <TAB> return re.sub(""\n+"", ""\n"", """".join(body).strip())",if sty . strikeout :,198
"def test_reduce_different_name( <TAB> ray_start_distributed_2_nodes_4_gpus, group_name, dst_rank): <TAB> world_size = 4 <TAB> actors, _ = create_collective_workers(num_workers=world_size, group_name=group_name) <TAB> results = ray.get([a.do_reduce.remote(group_name, dst_rank) for a in actors]) <TAB> for i in range(world_size): <MASK> assert (results[i] == cp.ones((10,), dtype=cp.float32) * world_size).all() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert (results[i] == cp.ones((10,), dtype=cp.float32)).all()",if i == dst_rank :,182
"def _find_docstrings(self, filename): <TAB> # A replacement for trace.find_strings() which was deprecated in <TAB> # Python 3.2 and removed in 3.6. <TAB> strs = set() <TAB> prev = token.INDENT  # so module docstring is detected as docstring <TAB> with tokenize_open(filename) as f: <TAB>  <TAB> tokens = tokenize.generate_tokens(f.readline) <TAB>  <TAB> for ttype, tstr, start, end, line in tokens: <MASK> strs.update(range(start[0], end[0] + 1)) <TAB>  <TAB>  <TAB> prev = ttype <TAB> return strs",if ttype == token . STRING and prev == token . INDENT :,158
"def on_click(self, event): <TAB> button = event[""button""] <TAB> if button in [self.button_next, self.button_previous]: <MASK> self.scrolling = True <TAB>  <TAB>  <TAB> if button == self.button_next: <TAB>  <TAB>  <TAB>  <TAB> self.active_index += 1 <TAB>  <TAB>  <TAB> elif button == self.button_previous: <TAB>  <TAB>  <TAB>  <TAB> self.active_index -= 1 <TAB>  <TAB>  <TAB> self.active_index %= self.count_stations <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.py3.prevent_refresh() <TAB> elif button == self.button_refresh: <TAB>  <TAB> self.idle_time = 0 <TAB> else: <TAB>  <TAB> self.py3.prevent_refresh()",if self . station_data :,178
"def findRule(instance, ruleSet): <TAB> """"""find the rule(s) that matches the feture vector passed"""""" <TAB> # print(""*Looking for rule match for Feature vector: "" + featuresToString(instance)) <TAB> ruleNumber = 0  # counter to track rule number <TAB> ruleMatches = []  # will hold all rule numbers that matched <TAB> for rule in ruleSet: <TAB>  <TAB> if ruleMatch(rule, instance): <TAB>  <TAB>  <TAB> ruleMatches.append(ruleNumber) <TAB>  <TAB>  <TAB> counts[ <TAB>  <TAB>  <TAB>  <TAB> ruleNumber <TAB>  <TAB>  <TAB> ] += 1  # update global histogram of rule matches for stats reporting <MASK> print("" ruleMatch found at rule #"" + str(ruleNumber)) <TAB>  <TAB>  <TAB>  <TAB> print("" "", end="""") <TAB>  <TAB>  <TAB>  <TAB> printRule(rule) <TAB>  <TAB> ruleNumber += 1 <TAB> return ruleMatches",if False :,200
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> length = d.getVarInt32() <TAB>  <TAB>  <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB>  <TAB>  <TAB> d.skip(length) <TAB>  <TAB>  <TAB> self.mutable_peer_ip().TryMerge(tmp) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 18 :,139
"def _check_no_tensors(parameters: Params): <TAB> flat_params = tf.nest.flatten(parameters.params) <TAB> for p in flat_params: <MASK> _check_no_tensors(p) <TAB>  <TAB> if tf.is_tensor(p): <TAB>  <TAB>  <TAB> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""Saw a `Tensor` value in parameters:\n  {}"".format(parameters) <TAB>  <TAB>  <TAB> )","if isinstance ( p , Params ) :",108
"def all_zinc_rsc_invalid_dep_keys(invalid_deps): <TAB> """"""Get the rsc key for an rsc-and-zinc target, or the zinc key for a zinc-only target."""""" <TAB> for tgt in invalid_deps: <TAB>  <TAB> # None can occur for e.g. JarLibrary deps, which we don't need to compile as they are <TAB>  <TAB> # populated in the resolve goal. <TAB>  <TAB> tgt_rsc_cc = compile_contexts[tgt].rsc_cc <MASK> # Rely on the results of zinc compiles for zinc-compatible targets <TAB>  <TAB>  <TAB> yield self._key_for_target_as_dep(tgt, tgt_rsc_cc.workflow)",if tgt_rsc_cc . workflow is not None :,182
"def characters(self, ch): <TAB> if self.Text_tag: <TAB>  <TAB> if self.Summary_tag: <TAB>  <TAB>  <TAB> self.Summary_ch += ch <TAB>  <TAB> elif self.Attack_Prerequisite_tag: <TAB>  <TAB>  <TAB> self.Attack_Prerequisite_ch += ch <MASK> self.Solution_or_Mitigation_ch += ch <TAB> elif self.CWE_ID_tag: <TAB>  <TAB> self.CWE_ID_ch += ch",elif self . Solution_or_Mitigation_tag :,127
"def load_tool_from_cache(self, config_file, recover_tool=False): <TAB> tool_cache = getattr(self.app, ""tool_cache"", None) <TAB> tool = None <TAB> if tool_cache: <MASK> tool = tool_cache.get_removed_tool(config_file) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tool = tool_cache.get_tool(config_file) <TAB> return tool",if recover_tool :,108
"def _generate_examples(self, archive, directory, labeled=True): <TAB> """"""Generate IMDB examples."""""" <TAB> # For labeled examples, extract the label from the path. <TAB> reg_path = ""(?P<label>neg|pos)"" if labeled else ""unsup"" <TAB> reg = re.compile( <TAB>  <TAB> os.path.join(""^%s"" % directory, reg_path, """").replace(""\\"", ""\\\\"") <TAB> ) <TAB> for path, imdb_f in archive: <TAB>  <TAB> res = reg.match(path) <MASK> continue <TAB>  <TAB> text = imdb_f.read().strip() <TAB>  <TAB> label = res.groupdict()[""label""] if labeled else -1 <TAB>  <TAB> yield path, { <TAB>  <TAB>  <TAB> ""text"": text, <TAB>  <TAB>  <TAB> ""label"": label, <TAB>  <TAB> }",if not res :,188
def startInputThread(self): <TAB> # cv.acquire() <TAB> # Fix Python 2.x. <TAB> global input <TAB> try: <TAB>  <TAB> input = raw_input <TAB> except NameError: <TAB>  <TAB> pass <TAB> while True: <TAB>  <TAB> cmd = ( <TAB>  <TAB>  <TAB> self._queuedCmds.pop(0) <TAB>  <TAB>  <TAB> if len(self._queuedCmds) <TAB>  <TAB>  <TAB> else input(self.getPrompt()).strip() <TAB>  <TAB> ) <TAB>  <TAB> wait = self.execCmd(cmd) <MASK> self.acceptingInput = False <TAB>  <TAB>  <TAB> self.blockingQueue.get(True) <TAB>  <TAB>  <TAB> # cv.wait() <TAB>  <TAB>  <TAB> # self.inputThread.wait() <TAB>  <TAB> self.acceptingInput = True,if wait :,181
"def assertS_IS(self, name, mode): <TAB> # test format, lstrip is for S_IFIFO <TAB> fmt = getattr(stat, ""S_IF"" + name.lstrip(""F"")) <TAB> self.assertEqual(stat.S_IFMT(mode), fmt) <TAB> # test that just one function returns true <TAB> testname = ""S_IS"" + name <TAB> for funcname in self.format_funcs: <TAB>  <TAB> func = getattr(stat, funcname, None) <TAB>  <TAB> if func is None: <MASK> raise ValueError(funcname) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if funcname == testname: <TAB>  <TAB>  <TAB> self.assertTrue(func(mode)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertFalse(func(mode))",if funcname == testname :,180
"def test_compatibility(self) -> None: <TAB> for expected, user_agent in self.data: <TAB>  <TAB> result = self.client_get(""/compatibility"", HTTP_USER_AGENT=user_agent) <TAB>  <TAB> if expected == ""ok"": <TAB>  <TAB>  <TAB> self.assert_json_success(result) <MASK> self.assert_json_error(result, ""Client is too old"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert False  # nocoverage","elif expected == ""old"" :",114
"def getBranchFromFile(): <TAB> global _gitdir <TAB> branch = None <TAB> if _gitdir: <TAB>  <TAB> headFile = os.path.join(_gitdir, ""HEAD"") <MASK> with open(headFile, ""r"", encoding=""utf-8"") as f: <TAB>  <TAB>  <TAB>  <TAB> line = f.readline() <TAB>  <TAB>  <TAB>  <TAB> if line: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if line.startswith(""ref""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> branch = line.split(""/"")[-1].strip() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> branch = ""HEAD"" <TAB> return branch",if os . path . isfile ( headFile ) :,151
"def get_job_parameters_dict(self, job_parameters: RunParameters = None): <TAB> if job_parameters: <MASK> self.job_runtime_conf[""job_parameters""][""common""] = job_parameters.to_dict() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.job_runtime_conf[""job_parameters""] = job_parameters.to_dict() <TAB> return self.job_runtime_conf[""job_parameters""]","if int ( self . job_runtime_conf . get ( ""dsl_version"" , 1 ) ) == 2 :",126
"def ConnectHandler(*args, **kwargs): <TAB> """"""Factory function selects the proper class and creates object based on device_type."""""" <TAB> device_type = kwargs[""device_type""] <TAB> if device_type not in platforms: <MASK> msg_str = platforms_str <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> msg_str = telnet_platforms_str if ""telnet"" in device_type else platforms_str <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> ""Unsupported 'device_type' "" <TAB>  <TAB>  <TAB> ""currently supported platforms are: {}"".format(msg_str) <TAB>  <TAB> ) <TAB> ConnectionClass = ssh_dispatcher(device_type) <TAB> return ConnectionClass(*args, **kwargs)",if device_type is None :,167
"def get_next_parent_entities(item, pids): <TAB> ret = list() <TAB> for [parent, entity_id] in parents[item]: <MASK> continue <TAB>  <TAB> if parent in entities: <TAB>  <TAB>  <TAB> ret.append(parent) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pids.append(entity_id) <TAB>  <TAB>  <TAB> for p in get_next_parent_entities(parent, pids): <TAB>  <TAB>  <TAB>  <TAB> ret.append(p) <TAB> return ret",if entity_id in pids :,119
"def load(self, data): <TAB> ckey = None <TAB> for key, val in _rx_cookie.findall(data): <MASK> if ckey: <TAB>  <TAB>  <TAB>  <TAB> self[ckey][key] = _unquote(val) <TAB>  <TAB> elif key[0] == ""$"": <TAB>  <TAB>  <TAB> # RFC2109: NAMEs that begin with $ are reserved for other uses <TAB>  <TAB>  <TAB> # and must not be used by applications. <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self[key] = _unquote(val) <TAB>  <TAB>  <TAB> ckey = key",if key . lower ( ) in _c_keys :,143
def getIdentifier(self): <TAB> start = self.index <TAB> self.index += 1 <TAB> while self.index < self.length: <TAB>  <TAB> ch = self.ccode() <MASK> # Blackslash (U+005C) marks Unicode escape sequence. <TAB>  <TAB>  <TAB> self.index = start <TAB>  <TAB>  <TAB> return self.getEscapedIdentifier() <TAB>  <TAB> if isIdentifierPart(ch): <TAB>  <TAB>  <TAB> self.index += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> return self.source[start : self.index],if ch == 0x5C :,134
"def test_floats_unequal_float(self): <TAB> try: <TAB>  <TAB> self.assertEqual( <TAB>  <TAB>  <TAB> np.array([[1, 2], [3, 4.5]], dtype=np.float32), <TAB>  <TAB>  <TAB> np.array([[1, 2], [3, 5]], dtype=np.float32), <TAB>  <TAB> ) <TAB> except AssertionError as e: <MASK> raise self.failureException(""Float array mismatch error not raised."")","if not str ( e ) . startswith ( ""Arrays not almost equal to 6 decimals"" ) :",119
"def _set_counts(self): <TAB> self[""regions_count""] = len(self[""regions""]) <TAB> for _, key in self._children: <TAB>  <TAB> # VPCs should not be counted as resources. They exist whether you have resources or not, <TAB>  <TAB> # so counting them would make the report confusing. <MASK> continue <TAB>  <TAB> self[key + ""_count""] = sum( <TAB>  <TAB>  <TAB> [region[key + ""_count""] for region in self[""regions""].values()] <TAB>  <TAB> )","if key == ""vpcs"" :",123
"def total_form_count(self): <TAB> """"""Returns the total number of forms in this FormSet."""""" <TAB> if self.data or self.files: <TAB>  <TAB> return self.management_form.cleaned_data[TOTAL_FORM_COUNT] <TAB> else: <TAB>  <TAB> initial_forms = self.initial_form_count() <TAB>  <TAB> total_forms = initial_forms + self.extra <TAB>  <TAB> # Allow all existing related objects/inlines to be displayed, <TAB>  <TAB> # but don't allow extra beyond max_num. <TAB>  <TAB> if initial_forms > self.max_num >= 0: <TAB>  <TAB>  <TAB> total_forms = initial_forms <MASK> total_forms = self.max_num <TAB> return total_forms",elif total_forms > self . max_num >= 0 :,180
"def mouse_down(self, evt): <TAB> if self.parent.level: <TAB>  <TAB> toolNo = self.toolNumberUnderMouse(evt.pos) <TAB>  <TAB> if toolNo < 0 or toolNo > 8: <TAB>  <TAB>  <TAB> return <MASK> self.selectTool(toolNo) <TAB>  <TAB> if evt.button == 3: <TAB>  <TAB>  <TAB> self.showToolOptions(toolNo)",if evt . button == 1 :,100
"def find_comment(line): <TAB> """"""Finds the index of a comment # and returns None if not found"""""" <TAB> instring, instring_char = False, """" <TAB> for i, char in enumerate(line): <TAB>  <TAB> if char in ('""', ""'""): <TAB>  <TAB>  <TAB> if instring: <TAB>  <TAB>  <TAB>  <TAB> if char == instring_char: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> instring = False <TAB>  <TAB>  <TAB>  <TAB>  <TAB> instring_char = """" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> instring = True <TAB>  <TAB>  <TAB>  <TAB> instring_char = char <TAB>  <TAB> elif char == ""#"": <MASK> return i <TAB> return None",if not instring :,155
"def __getattr__(self, key): <TAB> if key == key.upper(): <TAB>  <TAB> if hasattr(self._django_settings, key): <TAB>  <TAB>  <TAB> return getattr(self._django_settings, key) <MASK> return getattr(self._default_settings, key) <TAB> raise AttributeError( <TAB>  <TAB> ""%r object has no attribute %r"" % (self.__class__.__name__, key) <TAB> )","elif hasattr ( self . _default_settings , key ) :",106
"def replace_entities(match, entities=entities, encoding=encoding): <TAB> ent = match.group() <TAB> if ent[1] == ""#"": <TAB>  <TAB> return unescape_charref(ent[2:-1], encoding) <TAB> repl = entities.get(ent) <TAB> if repl is not None: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> repl = repl.decode(encoding) <TAB>  <TAB>  <TAB> except UnicodeError: <TAB>  <TAB>  <TAB>  <TAB> repl = ent <TAB> else: <TAB>  <TAB> repl = ent <TAB> return repl","if hasattr ( repl , ""decode"" ) and encoding is not None :",132
"def test_floor_div(self): <TAB> """"""Util.number.floor_div"""""" <TAB> self.assertRaises(TypeError, number.floor_div, ""1"", 1) <TAB> for a in range(-10, 10): <TAB>  <TAB> for b in range(-10, 10): <MASK> self.assertRaises(ZeroDivisionError, number.floor_div, a, b) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> (a, b, int(math.floor(float(a) / b))), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> (a, b, number.floor_div(a, b)), <TAB>  <TAB>  <TAB>  <TAB> )",if b == 0 :,159
"def get(self, method, **kws): <TAB> resp = None <TAB> if method in self.responses: <TAB>  <TAB> resp = self.responses[method].pop(0) <MASK> checks = resp[""validate""][""checks""] <TAB>  <TAB>  <TAB> resp = resp[""validate""][""data""] <TAB>  <TAB>  <TAB> for check in checks: <TAB>  <TAB>  <TAB>  <TAB> assert check in kws <TAB>  <TAB>  <TAB>  <TAB> expected_value = checks[check] <TAB>  <TAB>  <TAB>  <TAB> assert expected_value == kws[check] <TAB> return resp","if ""validate"" in resp :",123
def __add_changelisteners(self): <TAB> NewPlayerSettlementHovered.subscribe(self.on_settlement_change) <TAB> if self.__current_settlement is not None: <TAB>  <TAB> inventory = self.__current_settlement.get_component(StorageComponent).inventory <MASK> inventory.add_change_listener(self.refresh),if not inventory . has_change_listener ( self . refresh ) :,94
"def __call__(self, target): <TAB> if ""weights"" not in target.temp: <TAB>  <TAB> return True <TAB> targets = target.temp[""weights""] <TAB> for cname in target.children: <MASK> c = target.children[cname] <TAB>  <TAB>  <TAB> deviation = abs((c.weight - targets[cname]) / targets[cname]) <TAB>  <TAB>  <TAB> if deviation > self.tolerance: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> if ""cash"" in target.temp: <TAB>  <TAB> cash_deviation = abs( <TAB>  <TAB>  <TAB> (target.capital - targets.value) / targets.value - target.temp[""cash""] <TAB>  <TAB> ) <TAB>  <TAB> if cash_deviation > self.tolerance: <TAB>  <TAB>  <TAB> return True <TAB> return False",if cname in targets :,178
"def copyfileobj(src, dest, length=512): <TAB> if hasattr(src, ""readinto""): <TAB>  <TAB> buf = bytearray(length) <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> sz = src.readinto(buf) <TAB>  <TAB>  <TAB> if not sz: <TAB>  <TAB>  <TAB>  <TAB> break <MASK> dest.write(buf) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> b = memoryview(buf)[:sz] <TAB>  <TAB>  <TAB>  <TAB> dest.write(b) <TAB> else: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> buf = src.read(length) <TAB>  <TAB>  <TAB> if not buf: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> dest.write(buf)",if sz == length :,162
"def test_api_history_restrict_cat(self): <TAB> slot_sum = 0 <TAB> # Loop over all categories in the fake history, plus the Default category <TAB> cats = list(self.history_category_options) <TAB> cats.extend(""*"") <TAB> for cat in cats: <TAB>  <TAB> json = self._get_api_history({""category"": cat}) <TAB>  <TAB> slot_sum += len(json[""history""][""slots""]) <TAB>  <TAB> # All results should be from the correct category <TAB>  <TAB> for slot in json[""history""][""slots""]: <MASK> assert slot[""category""] == cat <TAB> # Total number of slots should match the sum of all category slots <TAB> json = self._get_api_history({""limit"": self.history_size}) <TAB> slot_total = len(json[""history""][""slots""]) <TAB> assert slot_sum == slot_total","if cat != ""*"" :",199
"def checker(self): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> ip = self.get_ip() <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> xlog.info(""no ip left"") <TAB>  <TAB>  <TAB> return <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> res = self.check_ip.check_ip(ip, sni=host, host=host) <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> xlog.warn(""check fail:%s except:%r"", e) <TAB>  <TAB>  <TAB> continue <MASK> xlog.debug(""check fail:%s fail"", ip) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> self.write_ip(ip, res.domain, res.handshake_time)",if not res or not res . ok :,173
"def create_row_processor( <TAB> self, context, path, loadopt, mapper, result, adapter, populators): <TAB> # look through list of columns represented here <TAB> # to see which, if any, is present in the row. <TAB> for col in self.columns: <TAB>  <TAB> if adapter: <TAB>  <TAB>  <TAB> col = adapter.columns[col] <TAB>  <TAB> getter = result._getter(col, False) <MASK> populators[""quick""].append((self.key, getter)) <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> populators[""expire""].append((self.key, True))",if getter :,145
"def indices(dimensions, dtype=int32, sparse=False): <TAB> dimensions = tuple(dimensions) <TAB> N = len(dimensions) <TAB> output = [] <TAB> s = dimensions <TAB> for i, dim in enumerate(dimensions): <TAB>  <TAB> idx = lax.iota(dtype, dim) <MASK> s = (1,) * i + (dim,) + (1,) * (N - i - 1) <TAB>  <TAB> output.append(lax.broadcast_in_dim(idx, s, (i,))) <TAB> if sparse: <TAB>  <TAB> return tuple(output) <TAB> return stack(output, 0) if output else array([], dtype=dtype)",if sparse :,154
"def load_cases(full_path): <TAB> all_test_data = json.load(open(full_path), object_pairs_hook=OrderedDict) <TAB> for test_data in all_test_data: <TAB>  <TAB> given = test_data[""given""] <TAB>  <TAB> for case in test_data[""cases""]: <TAB>  <TAB>  <TAB> if ""result"" in case: <TAB>  <TAB>  <TAB>  <TAB> test_type = ""result"" <MASK> test_type = ""error"" <TAB>  <TAB>  <TAB> elif ""bench"" in case: <TAB>  <TAB>  <TAB>  <TAB> test_type = ""bench"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise RuntimeError(""Unknown test type: %s"" % json.dumps(case)) <TAB>  <TAB>  <TAB> yield (given, test_type, case)","elif ""error"" in case :",183
"def _resolve_task_id(cls, task_id, log=None): <TAB> if not task_id: <TAB>  <TAB> task_id = cls.normalize_id(get_remote_task_id()) <MASK> log = log or get_logger(""task"") <TAB>  <TAB>  <TAB> log.info(""Using task ID from env %s=%s"" % (TASK_ID_ENV_VAR[0], task_id)) <TAB> return task_id",if task_id :,110
"def _build_contr_port_map(self, fabric_connected_ports, ports_info): <TAB> contr_port_map = {} <TAB> for port in fabric_connected_ports: <TAB>  <TAB> contr = ports_info[port][""contr""] <MASK> contr_port_map[contr] = [] <TAB>  <TAB> contr_port_map[contr].append(port) <TAB> LOG.debug(""Controller port map: %s."", contr_port_map) <TAB> return contr_port_map",if not contr_port_map . get ( contr ) :,143
"def confirm(question): <TAB> """"""Prompts a given question and handles user input."""""" <TAB> valid = {""yes"": True, ""y"": True, ""ye"": True, ""no"": False, ""n"": False, """": True} <TAB> prompt = "" [Y/n] "" <TAB> while True: <TAB>  <TAB> print(BOLD + CYAN + question + prompt + END) <TAB>  <TAB> choice = input().lower() <MASK> return valid[choice] <TAB>  <TAB> print(""Please respond with 'yes' or 'no' (or 'y' or 'n').\n"")",if choice in valid :,137
"def __parse_query(self, model, iter_, data): <TAB> f, b = self.__filter, self.__bg_filter <TAB> if f is None and b is None: <TAB>  <TAB> return True <TAB> else: <TAB>  <TAB> album = model.get_album(iter_) <MASK> return True <TAB>  <TAB> elif b is None: <TAB>  <TAB>  <TAB> return f(album) <TAB>  <TAB> elif f is None: <TAB>  <TAB>  <TAB> return b(album) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return b(album) and f(album)",if album is None :,130
def get_SV(self): <TAB> result = [] <TAB> for sparse_sv in self.SV[: self.l]: <TAB>  <TAB> row = dict() <TAB>  <TAB> i = 0 <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> row[sparse_sv[i].index] = sparse_sv[i].value <MASK> break <TAB>  <TAB>  <TAB> i += 1 <TAB>  <TAB> result.append(row) <TAB> return result,if sparse_sv [ i ] . index == - 1 :,111
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.set_hostname(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 10 :,90
"def getFileIdFromAlternateLink(altLink): <TAB> loc = altLink.find(""/d/"") <TAB> if loc > 0: <TAB>  <TAB> fileId = altLink[loc + 3 :] <TAB>  <TAB> loc = fileId.find(""/"") <MASK> return fileId[:loc] <TAB> else: <TAB>  <TAB> loc = altLink.find(""/folderview?id="") <TAB>  <TAB> if loc > 0: <TAB>  <TAB>  <TAB> fileId = altLink[loc + 15 :] <TAB>  <TAB>  <TAB> loc = fileId.find(""&"") <TAB>  <TAB>  <TAB> if loc != -1: <TAB>  <TAB>  <TAB>  <TAB> return fileId[:loc] <TAB> controlflow.system_error_exit( <TAB>  <TAB> 2, f""{altLink} is not a valid Drive File alternateLink"" <TAB> )",if loc != - 1 :,180
"def show_unknown_key_warning(name: Union[str, object], others: dict): <TAB> if ""type"" in others: <TAB>  <TAB> others.pop(""type"") <TAB> if len(others) > 0: <TAB>  <TAB> keys = "", "".join(others.keys()) <TAB>  <TAB> logger = logging.getLogger(__name__) <MASK> name = name.__class__.__name__ <TAB>  <TAB> logger.debug( <TAB>  <TAB>  <TAB> f""!!! {name}'s constructor args ({keys}) were ignored."" <TAB>  <TAB>  <TAB> f""If they should be supported by this library, report this issue to the project :bow: "" <TAB>  <TAB>  <TAB> f""https://github.com/slackapi/python-slackclient/issues"" <TAB>  <TAB> )","if isinstance ( name , object ) :",173
"def wrapper(*args, **kwargs): <TAB> with capture_logs() as logs: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> function(*args, **kwargs) <TAB>  <TAB> except Exception:  # pragma: no cover <MASK> print(""%i errors logged:"" % len(logs), file=sys.stderr) <TAB>  <TAB>  <TAB>  <TAB> for message in logs: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> print(message, file=sys.stderr) <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if logs:  # pragma: no cover <TAB>  <TAB>  <TAB>  <TAB> for message in logs: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> print(message, file=sys.stderr) <TAB>  <TAB>  <TAB>  <TAB> raise AssertionError(""%i errors logged"" % len(logs))",if logs :,168
"def _init_weight(self): <TAB> for m in self.modules(): <TAB>  <TAB> if isinstance(m, nn.Conv2d): <TAB>  <TAB>  <TAB> n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels <TAB>  <TAB>  <TAB> m.weight.data.normal_(0, math.sqrt(2.0 / n)) <MASK> m.weight.data.fill_(1) <TAB>  <TAB>  <TAB> m.bias.data.zero_() <TAB>  <TAB> elif isinstance(m, nn.BatchNorm2d): <TAB>  <TAB>  <TAB> m.weight.data.fill_(1) <TAB>  <TAB>  <TAB> m.bias.data.zero_()","elif isinstance ( m , SyncBatchNorm ) :",162
"def cleanup(self): <TAB> # some OBO ontologies have extra ""."" at the end of synonyms <TAB> for i, s in enumerate(self.synonyms): <TAB>  <TAB> if s[-1] == ""."": <TAB>  <TAB>  <TAB> # only remove period if preceded by ""normal word"" <MASK> c = s[:-1] <TAB>  <TAB>  <TAB>  <TAB> print >>sys.stderr, ""Note: cleanup: '%s' -> '%s'"" % (s, c) <TAB>  <TAB>  <TAB>  <TAB> self.synonyms[i] = c","if re . search ( r""\b[a-z]{2,}\.$"" , s ) :",138
"def for_module(cls, modname: str) -> ""ModuleAnalyzer"": <TAB> if (""module"", modname) in cls.cache: <TAB>  <TAB> entry = cls.cache[""module"", modname] <MASK> raise entry <TAB>  <TAB> return entry <TAB> try: <TAB>  <TAB> filename, source = cls.get_module_source(modname) <TAB>  <TAB> if source is not None: <TAB>  <TAB>  <TAB> obj = cls.for_string(source, modname, filename or ""<string>"") <TAB>  <TAB> elif filename is not None: <TAB>  <TAB>  <TAB> obj = cls.for_file(filename, modname) <TAB> except PycodeError as err: <TAB>  <TAB> cls.cache[""module"", modname] = err <TAB>  <TAB> raise <TAB> cls.cache[""module"", modname] = obj <TAB> return obj","if isinstance ( entry , PycodeError ) :",182
"def GetDisplayNameOf(self, pidl, flags): <TAB> item = pidl_to_item(pidl) <TAB> if flags & shellcon.SHGDN_FORPARSING: <TAB>  <TAB> if flags & shellcon.SHGDN_INFOLDER: <TAB>  <TAB>  <TAB> return item[""name""] <TAB>  <TAB> else: <MASK> sigdn = shellcon.SIGDN_DESKTOPABSOLUTEEDITING <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> sigdn = shellcon.SIGDN_DESKTOPABSOLUTEPARSING <TAB>  <TAB>  <TAB> parent = shell.SHGetNameFromIDList(self.pidl, sigdn) <TAB>  <TAB>  <TAB> return parent + ""\\"" + item[""name""] <TAB> else: <TAB>  <TAB> return item[""name""]",if flags & shellcon . SHGDN_FORADDRESSBAR :,188
"def transact_reraise(exc_class, exceptions): <TAB> cls, exc, tb = exceptions[0] <TAB> new_exc = None <TAB> try: <TAB>  <TAB> msg = "" "".join(tostring(arg) for arg in exc.args) <MASK> msg = ""%s: %s"" % (cls.__name__, msg) <TAB>  <TAB> new_exc = exc_class(msg, exceptions) <TAB>  <TAB> new_exc.__cause__ = None <TAB>  <TAB> reraise(exc_class, new_exc, tb) <TAB> finally: <TAB>  <TAB> del exceptions, exc, tb, new_exc","if not issubclass ( cls , TransactionError ) :",146
"def add_share(self, share): <TAB> for filename, (share_hashes, verified_hashes) in self.known.iteritems(): <MASK> break <TAB> else: <TAB>  <TAB> filename = self._add_line( <TAB>  <TAB>  <TAB> ""%i %s"" % (5, share_type.pack(share.as_share()).encode(""hex"")) <TAB>  <TAB> ) <TAB>  <TAB> share_hashes, verified_hashes = self.known.setdefault(filename, (set(), set())) <TAB>  <TAB> share_hashes.add(share.hash) <TAB> share_hashes, verified_hashes = self.known_desired.setdefault( <TAB>  <TAB> filename, (set(), set()) <TAB> ) <TAB> share_hashes.add(share.hash)",if share . hash in share_hashes :,176
"def get_resolved_modules(self) -> Dict[str, ResolvedModule]: <TAB> """"""Get a {name: ResolvedModule} map of all resolved modules."""""" <TAB> resolved_modules = {} <TAB> for name, mod in self._modules.items(): <MASK> resolved_modules[name] = ResolvedModule( <TAB>  <TAB>  <TAB>  <TAB> mod.module_name, mod.filename, mod.ast <TAB>  <TAB>  <TAB> ) <TAB> return resolved_modules",if not mod . has_unresolved_pointers :,115
"def stripe(request): <TAB> amount = 1 <TAB> response = None <TAB> if request.method == ""POST"": <TAB>  <TAB> form = CreditCardForm(request.POST) <MASK> data = form.cleaned_data <TAB>  <TAB>  <TAB> credit_card = CreditCard(**data) <TAB>  <TAB>  <TAB> merchant = get_gateway(""stripe"") <TAB>  <TAB>  <TAB> response = merchant.purchase(amount, credit_card) <TAB> else: <TAB>  <TAB> form = CreditCardForm(initial=GATEWAY_INITIAL[""stripe""]) <TAB> return render( <TAB>  <TAB> request, <TAB>  <TAB> ""app/index.html"", <TAB>  <TAB> { <TAB>  <TAB>  <TAB> ""form"": form, <TAB>  <TAB>  <TAB> ""amount"": amount, <TAB>  <TAB>  <TAB> ""response"": response, <TAB>  <TAB>  <TAB> ""title"": ""Stripe Payment"", <TAB>  <TAB> }, <TAB> )",if form . is_valid ( ) :,192
"def get(self, url): <TAB> now = time.time() <TAB> for entry in self.repos: <MASK> if now < entry.timestamp + self.timeout: <TAB>  <TAB>  <TAB>  <TAB> # print ""returning immediate Etrny"", entry <TAB>  <TAB>  <TAB>  <TAB> return entry.url, entry.rev <TAB>  <TAB>  <TAB> return entry.url, -1 <TAB> return url, -1",if url . startswith ( entry . url ) :,98
"def cleanup(self): <TAB> # some OBO ontologies have extra ""."" at the end of synonyms <TAB> for i, s in enumerate(self.synonyms): <MASK> # only remove period if preceded by ""normal word"" <TAB>  <TAB>  <TAB> if re.search(r""\b[a-z]{2,}\.$"", s): <TAB>  <TAB>  <TAB>  <TAB> c = s[:-1] <TAB>  <TAB>  <TAB>  <TAB> print >>sys.stderr, ""Note: cleanup: '%s' -> '%s'"" % (s, c) <TAB>  <TAB>  <TAB>  <TAB> self.synonyms[i] = c","if s [ - 1 ] == ""."" :",138
"def __get_field(cls, name): <TAB> try: <TAB>  <TAB> return cls._doc_type.mapping[name] <TAB> except KeyError: <TAB>  <TAB> # fallback to fields on the Index <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> return cls._index._mapping[name] <TAB>  <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB>  <TAB> pass","if hasattr ( cls , ""_index"" ) and cls . _index . _mapping :",95
"def command_is_enabled(self, item, focus): <TAB> cmd = item.command <TAB> if cmd: <TAB>  <TAB> enabler_name = cmd + ""_enabled"" <TAB>  <TAB> handler = focus <TAB>  <TAB> while handler: <TAB>  <TAB>  <TAB> enabler = getattr(handler, enabler_name, None) <MASK> return enabler() <TAB>  <TAB>  <TAB> handler = handler.next_handler() <TAB> return True",if enabler :,107
"def __getitem__(self, key): <TAB> value = WeakValueDictionary.__getitem__(self, key) <TAB> # check boundaries to minimiza duplicate references <TAB> while len(self.queue) > 0 and self.queue[0][0] == key: <TAB>  <TAB> # item at left end of queue pop it since it'll be appended <TAB>  <TAB> # to right <TAB>  <TAB> self.queue.popleft() <TAB> # only append if item is not at right end of queue <TAB> if not (len(self.queue) and self.queue[-1][0] == key): <MASK> self.cull() <TAB>  <TAB> self.queue.append((key, value)) <TAB> return value",if len ( self ) >= self . maxsize or len ( self . queue ) >= self . maxsize * self . peakmult :,181
"def post_init(self): <TAB> if os.getenv(""SCRCPY_LDD""): <MASK> os.environ[""LD_LIBRARY_PATH""] += os.getenv(""SCRCPY_LDD"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> os.environ[""LD_LIBRARY_PATH""] = os.getenv(""SCRCPY_LDD"")","if os . getenv ( ""LD_LIBRARY_PATH"" ) :",93
"def get_summary_output(event: events.Finished) -> Tuple[str, str, int]: <TAB> parts = get_summary_message_parts(event.results) <TAB> if not parts: <TAB>  <TAB> message = ""Empty test suite"" <TAB>  <TAB> color = ""yellow"" <TAB>  <TAB> status_code = 0 <TAB> else: <TAB>  <TAB> message = f'{"", "".join(parts)} in {event.running_time:.2f}s' <MASK> color = ""red"" <TAB>  <TAB>  <TAB> status_code = 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> color = ""green"" <TAB>  <TAB>  <TAB> status_code = 0 <TAB> return message, color, status_code",if event . results . has_failures or event . results . has_errors :,172
"def header_check(p_obj): <TAB> """"""Special disposition for the HTML <head> and <body> elements..."""""" <TAB> if state.options.host_language in [ <TAB>  <TAB> HostLanguage.xhtml, <TAB>  <TAB> HostLanguage.html5, <TAB>  <TAB> HostLanguage.xhtml5, <TAB> ]: <MASK> if not has_one_of_attributes(node, ""about"", ""resource"", ""src"", ""href""): <TAB>  <TAB>  <TAB>  <TAB> return p_obj <TAB> else: <TAB>  <TAB> return None","if node . nodeName == ""head"" or node . nodeName == ""body"" :",137
"def get_track_id_from_json(item): <TAB> """"""Try to extract video Id from various response types"""""" <TAB> fields = [ <TAB>  <TAB> ""contentDetails/videoId"", <TAB>  <TAB> ""snippet/resourceId/videoId"", <TAB>  <TAB> ""id/videoId"", <TAB>  <TAB> ""id"", <TAB> ] <TAB> for field in fields: <TAB>  <TAB> node = item <TAB>  <TAB> for p in field.split(""/""): <TAB>  <TAB>  <TAB> if node and isinstance(node, dict): <TAB>  <TAB>  <TAB>  <TAB> node = node.get(p) <MASK> return node <TAB> return """"",if node :,137
"def __init__(self, layers): <TAB> super(Add, self).__init__() <TAB> self.layer_names = [] <TAB> self.layers = layers <TAB> for i, layer in enumerate(self.layers): <MASK> if i == 0: <TAB>  <TAB>  <TAB>  <TAB> layer.parent = ""input"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> layer.parent = layers[i - 1].name <TAB>  <TAB> if hasattr(layer, ""name""): <TAB>  <TAB>  <TAB> name = layer.name <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = layer.__class__.__name__ + str(i) <TAB>  <TAB>  <TAB> layer.name = name <TAB>  <TAB> self.layer_names.append(name)",if layer . parent is None :,165
"def do_remove(self): <TAB> if self.netconf.locked(""dhcp""): <TAB>  <TAB> if not self.pid: <TAB>  <TAB>  <TAB> pid = read_pid_file(""/var/run/dnsmasq.pan1.pid"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pid = self.pid <MASK> logging.info(""Stale dhcp lockfile found"") <TAB>  <TAB> self.netconf.unlock(""dhcp"")","if not kill ( pid , ""dnsmasq"" ) :",106
"def findStyleName(element, style): <TAB> oldStyle = DOM.getAttribute(element, ""className"") <TAB> if oldStyle is None: <TAB>  <TAB> return -1 <TAB> idx = oldStyle.find(style) <TAB> # Calculate matching index <TAB> lastPos = len(oldStyle) <TAB> while idx != -1: <MASK> last = idx + len(style) <TAB>  <TAB>  <TAB> if (last == lastPos) or ((last < lastPos) and (oldStyle[last] == "" "")): <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> idx = oldStyle.find(style, idx + 1) <TAB> return idx","if idx == 0 or ( oldStyle [ idx - 1 ] == "" "" ) :",161
"def __str__(self): <TAB> path = super(XPathExpr, self).__str__() <TAB> if self.textnode: <TAB>  <TAB> if path == ""*"": <TAB>  <TAB>  <TAB> path = ""text()"" <TAB>  <TAB> el <MASK> path = path[:-3] + ""text()"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> path += ""/text()"" <TAB> if self.attribute is not None: <TAB>  <TAB> if path.endswith(""::*/*""): <TAB>  <TAB>  <TAB> path = path[:-2] <TAB>  <TAB> path += ""/@%s"" % self.attribute <TAB> return path","if path . endswith ( ""::*/*"" ) :",132
"def insert_after(self, sibling, row=None): <TAB> if row is not None: <TAB>  <TAB> value = self._get_marshalable(row[0]) <MASK> position = 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> position = self.get_path(sibling)[0] + 1 <TAB>  <TAB> return self.insert_with_valuesv(position, [0], [value]) <TAB> assert not self.ATOMIC <TAB> return super(ObjectStore, self).insert_after(sibling, row)",if sibling is None :,125
"def source_synopsis(file): <TAB> line = file.readline() <TAB> while line[:1] == ""#"" or not strip(line): <TAB>  <TAB> line = file.readline() <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB> break <TAB> line = strip(line) <TAB> if line[:4] == 'r""""""': <TAB>  <TAB> line = line[1:] <TAB> if line[:3] == '""""""': <TAB>  <TAB> line = line[3:] <MASK> line = line[:-1] <TAB>  <TAB> while not strip(line): <TAB>  <TAB>  <TAB> line = file.readline() <TAB>  <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> result = strip(split(line, '""""""')[0]) <TAB> else: <TAB>  <TAB> result = None <TAB> return result","if line [ - 1 : ] == ""\\"" :",182
"def _handle_rate_limit( <TAB> self, exception: RedditAPIException) -> Optional[Union[int, float]]: <TAB> for item in exception.items: <TAB>  <TAB> if item.error_type == ""RATELIMIT"": <TAB>  <TAB>  <TAB> amount_search = self._ratelimit_regex.search(item.message) <TAB>  <TAB>  <TAB> if not amount_search: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> seconds = int(amount_search.group(1)) <MASK> seconds *= 60 <TAB>  <TAB>  <TAB> if seconds <= int(self.config.ratelimit_seconds): <TAB>  <TAB>  <TAB>  <TAB> sleep_seconds = seconds + min(seconds / 10, 1) <TAB>  <TAB>  <TAB>  <TAB> return sleep_seconds <TAB> return None","if ""minute"" in amount_search . group ( 2 ) :",181
"def get_html_help_exe(): <TAB> """"""Return HTML Help Workshop executable path (Windows only)"""""" <TAB> if os.name == ""nt"": <TAB>  <TAB> hhc_base = r""C:\Program Files%s\HTML Help Workshop\hhc.exe"" <TAB>  <TAB> for hhc_exe in (hhc_base % """", hhc_base % "" (x86)""): <MASK> return hhc_exe <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return",if osp . isfile ( hhc_exe ) :,121
"def get_net_bridge_owner(name_ignore, sysfspath): <TAB> # Now magic to determine if the device is part of a bridge <TAB> brportpath = os.path.join(sysfspath, ""brport"") <TAB> try: <MASK> brlinkpath = os.path.join(brportpath, ""bridge"") <TAB>  <TAB>  <TAB> dest = os.readlink(brlinkpath) <TAB>  <TAB>  <TAB> (ignore, bridge) = os.path.split(dest) <TAB>  <TAB>  <TAB> return bridge <TAB> except: <TAB>  <TAB> logging.exception(""Unable to determine if device is shared"") <TAB> return None",if os . path . exists ( brportpath ) :,154
"def get_timestamp(self): <TAB> if not self._timedelta: <TAB>  <TAB> url = ""https://%s%s/auth/time"" % (API_HOST, API_ROOT) <TAB>  <TAB> response = get_response_object(url=url, method=""GET"", headers={}) <MASK> raise Exception(""Failed to get current time from Ovh API"") <TAB>  <TAB> timestamp = int(response.body) <TAB>  <TAB> self._timedelta = timestamp - int(time.time()) <TAB> return int(time.time()) + self._timedelta",if not response or not response . body :,131
"def render(self, context): <TAB> for var in self.vars: <TAB>  <TAB> value = var.resolve(context, True) <MASK> first = render_value_in_context(value, context) <TAB>  <TAB>  <TAB> if self.asvar: <TAB>  <TAB>  <TAB>  <TAB> context[self.asvar] = first <TAB>  <TAB>  <TAB>  <TAB> return """" <TAB>  <TAB>  <TAB> return first <TAB> return """"",if value :,95
"def test_loc_is_stochastic_parameter(self): <TAB> param = iap.Laplace(iap.Choice([-100, 100]), 1) <TAB> seen = [0, 0] <TAB> for _ in sm.xrange(1000): <TAB>  <TAB> samples = param.draw_samples((100,)) <TAB>  <TAB> exp = np.mean(samples) <TAB>  <TAB> if -100 - 10 < exp < -100 + 10: <TAB>  <TAB>  <TAB> seen[0] += 1 <MASK> seen[1] += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert False <TAB> assert 500 - 100 < seen[0] < 500 + 100 <TAB> assert 500 - 100 < seen[1] < 500 + 100",elif 100 - 10 < exp < 100 + 10 :,167
"def get_data(self, path, prefix=""""): <TAB> item = self.store[path] <TAB> path = ""{}/{}"".format(prefix, path) <TAB> keys = [i for i in item.keys()] <TAB> data = {""path"": path} <TAB> # print(path) <TAB> for k in keys: <TAB>  <TAB> if not isinstance(item[k], h5py.Group): <TAB>  <TAB>  <TAB> dataset = np.array(item[k].value) <TAB>  <TAB>  <TAB> if type(dataset) is np.ndarray: <MASK> if type(dataset[0]) is np.bytes_: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> dataset = [a.decode(""ascii"") for a in dataset] <TAB>  <TAB>  <TAB> data.update({k: dataset}) <TAB> return data",if dataset . size != 0 :,183
def __del__(self): <TAB> try: <TAB>  <TAB> if self._mpz_p is not None: <MASK> _gmp.mpz_clear(self._mpz_p) <TAB>  <TAB> self._mpz_p = None <TAB> except AttributeError: <TAB>  <TAB> pass,if self . _initialized :,75
"def load(self, vocab_file): <TAB> self.__term2id = {} <TAB> self.__id2term = {} <TAB> with open(vocab_file, ""r"", encoding=""utf-8"") as fin: <TAB>  <TAB> for line in fin.readlines(): <TAB>  <TAB>  <TAB> fields = line.strip().split(""\t"") <TAB>  <TAB>  <TAB> assert len(fields) == 5, ""Vocabulary file [%s] format error!"" % (vocab_file) <TAB>  <TAB>  <TAB> term = fields[1] <TAB>  <TAB>  <TAB> id_ = int(fields[2]) <MASK> logger.error(""Duplicate word [%s] in vocab file!"" % (term)) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> self.__term2id[term] = id_ <TAB>  <TAB>  <TAB> self.__id2term[id_] = term",if term in self . __term2id :,193
"def break_next_call(symbol_regex=None): <TAB> while pwndbg.proc.alive: <TAB>  <TAB> ins = break_next_branch() <TAB>  <TAB> if not ins: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> # continue if not a call <TAB>  <TAB> if capstone.CS_GRP_CALL not in ins.groups: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # return call if we don't search for a symbol <MASK> return ins <TAB>  <TAB> # return call if we match target address <TAB>  <TAB> if ins.target_const and re.match(""%s$"" % symbol_regex, hex(ins.target)): <TAB>  <TAB>  <TAB> return ins <TAB>  <TAB> # return call if we match symbol name <TAB>  <TAB> if ins.symbol and re.match(""%s$"" % symbol_regex, ins.symbol): <TAB>  <TAB>  <TAB> return ins",if not symbol_regex :,193
"def test_url_valid_set(): <TAB> for line in URL_VALID_TESTS.split(""\n""): <TAB>  <TAB> # strip line, skip over empty lines <TAB>  <TAB> line = line.strip() <TAB>  <TAB> if line == """": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # skip over comments or empty lines <TAB>  <TAB> match = COMMENT.match(line) <MASK> continue <TAB>  <TAB> mbox = address.parse(line, strict=True) <TAB>  <TAB> assert_not_equal(mbox, None)",if match :,120
"def _clean_fields(self, fields, reverse=False): <TAB> if not fields: <TAB>  <TAB> fields = list(self.default_fields) <TAB> if reverse: <TAB>  <TAB> for field in [""up.total"", ""down.total"", ""down.rate""]: <MASK> fields[fields.index(field)] = field.replace(""."", ""_"") <TAB>  <TAB> return fields <TAB> for required_field in self.required_fields: <TAB>  <TAB> if required_field not in fields: <TAB>  <TAB>  <TAB> fields.insert(0, required_field) <TAB> for field in [""up_total"", ""down_total"", ""down_rate""]: <TAB>  <TAB> if field in fields: <TAB>  <TAB>  <TAB> fields[fields.index(field)] = field.replace(""_"", ""."") <TAB> return fields",if field in fields :,181
"def client_cert_key_path(self): <TAB> cache_folder = os.path.dirname(self.filename) <TAB> try: <TAB>  <TAB> path = self.get_item(""general.client_cert_key_path"") <TAB> except ConanException: <TAB>  <TAB> path = os.path.join(cache_folder, ""client.key"") <TAB> else: <TAB>  <TAB> # For explicit cacert files, the file should already exist <TAB>  <TAB> path = os.path.join(cache_folder, path) <MASK> raise ConanException( <TAB>  <TAB>  <TAB>  <TAB> ""Configured file for 'client_cert_key_path'"" <TAB>  <TAB>  <TAB>  <TAB> "" doesn't exists: '{}'"".format(path) <TAB>  <TAB>  <TAB> ) <TAB> return os.path.normpath(path)",if not os . path . exists ( path ) :,186
"def handler_click_link(self, link): <TAB> if link.startswith(""[[""): <TAB>  <TAB> link = link[2:-2] <TAB>  <TAB> self.notify_observers(""click:notelink"", link) <TAB> else: <TAB>  <TAB> if platform.system().lower() == ""windows"": <TAB>  <TAB>  <TAB> os.startfile(link) <MASK> subprocess.call((""open"", link)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> subprocess.call((""xdg-open"", link))","elif platform . system ( ) . lower ( ) == ""darwin"" :",123
"def __setitem__(self, key, value): <TAB> if not isinstance(value, PseudoNamespace): <TAB>  <TAB> tuple_converted = False <TAB>  <TAB> if isinstance(value, dict): <TAB>  <TAB>  <TAB> value = PseudoNamespace(value) <TAB>  <TAB> elif isinstance(value, tuple): <TAB>  <TAB>  <TAB> value = list(value) <TAB>  <TAB>  <TAB> tuple_converted = True <TAB>  <TAB> if isinstance(value, list): <TAB>  <TAB>  <TAB> for i, item in enumerate(value): <TAB>  <TAB>  <TAB>  <TAB> if isinstance(item, dict) and not isinstance(item, PseudoNamespace): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value[i] = PseudoNamespace(item) <MASK> value = tuple(value) <TAB> super(PseudoNamespace, self).__setitem__(key, value)",if tuple_converted :,175
"def slots_for_entities(self, entities): <TAB> if self.store_entities_as_slots: <TAB>  <TAB> slot_events = [] <TAB>  <TAB> for s in self.slots: <TAB>  <TAB>  <TAB> if s.auto_fill: <TAB>  <TAB>  <TAB>  <TAB> matching_entities = [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> e[""value""] for e in entities if e[""entity""] == s.name <TAB>  <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB>  <TAB> if matching_entities: <MASK> slot_events.append(SlotSet(s.name, matching_entities)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> slot_events.append(SlotSet(s.name, matching_entities[-1])) <TAB>  <TAB> return slot_events <TAB> else: <TAB>  <TAB> return []","if s . type_name == ""list"" :",193
"def stream_read_bz2(ifh, ofh): <TAB> """"""Uncompress bz2 compressed *ifh* into *ofh*"""""" <TAB> decompressor = bz2.BZ2Decompressor() <TAB> while True: <TAB>  <TAB> buf = ifh.read(BUFSIZE) <MASK> break <TAB>  <TAB> buf = decompressor.decompress(buf) <TAB>  <TAB> if buf: <TAB>  <TAB>  <TAB> ofh.write(buf) <TAB> if decompressor.unused_data or ifh.read(1) != b"""": <TAB>  <TAB> raise CorruptedObjectError(""Data after end of bz2 stream"")",if not buf :,139
"def get_for_vars(self): <TAB> tok = self.tokenizer.get_next_token() <TAB> if tok[""style""] == ScintillaConstants.SCE_PL_WORD and tok[""text""] in ( <TAB>  <TAB> ""my"", <TAB>  <TAB> ""state"", <TAB> ): <TAB>  <TAB> tlineNo = tok[""start_line""] <TAB>  <TAB> tok = self.tokenizer.get_next_token() <MASK> # Don't do any more processing, as we're probably looking <TAB>  <TAB>  <TAB> # at an open-paren. <TAB>  <TAB>  <TAB> self.moduleInfo.doSetVar(name=tok[""text""], line=tlineNo, scope=""my"")",if self . classifier . is_variable ( tok ) :,164
"def generate_dem_tiles(geotiff, output_dir, max_concurrency): <TAB> try: <TAB>  <TAB> colored_dem, hillshade_dem, colored_hillshade_dem = generate_colored_hillshade( <TAB>  <TAB>  <TAB> geotiff <TAB>  <TAB> ) <TAB>  <TAB> generate_tiles(colored_hillshade_dem, output_dir, max_concurrency) <TAB>  <TAB> # Cleanup <TAB>  <TAB> for f in [colored_dem, hillshade_dem, colored_hillshade_dem]: <MASK> os.remove(f) <TAB> except Exception as e: <TAB>  <TAB> log.ODM_WARNING(""Cannot generate DEM tiles: %s"" % str(e))",if os . path . isfile ( f ) :,186
"def cluster(spawnpoints, radius, time_threshold): <TAB> clusters = [] <TAB> diameter = 2 * radius <TAB> for p in spawnpoints: <MASK> clusters.append(Spawncluster(p)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> c = min(clusters, key=lambda x: cost(p, x, time_threshold)) <TAB>  <TAB>  <TAB> if check_cluster(p, c, radius, time_threshold): <TAB>  <TAB>  <TAB>  <TAB> c.append(p) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> c = Spawncluster(p) <TAB>  <TAB>  <TAB>  <TAB> clusters.append(c) <TAB> return clusters",if len ( clusters ) == 0 :,152
"def pop(self): <TAB> if self._pending_removals: <TAB>  <TAB> self._commit_removals() <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> itemref = self.data.pop() <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> raise KeyError(""pop from empty WeakSet"") from None <TAB>  <TAB> item = itemref() <MASK> return item",if item is not None :,95
"def map_depends(self, dep): <TAB> if ( <TAB>  <TAB> dep.endswith((""-native"", ""-native-runtime"")) <TAB>  <TAB> or (""nativesdk-"" in dep) <TAB>  <TAB> or (""cross-canadian"" in dep) <TAB>  <TAB> or (""-crosssdk-"" in dep) <TAB> ): <TAB>  <TAB> return dep <TAB> else: <TAB>  <TAB> # Do not extend for that already have multilib prefix <TAB>  <TAB> var = self.d.getVar(""MULTILIB_VARIANTS"") <TAB>  <TAB> if var: <TAB>  <TAB>  <TAB> var = var.split() <TAB>  <TAB>  <TAB> for v in var: <MASK> return dep <TAB>  <TAB> return self.extend_name(dep)",if dep . startswith ( v ) :,165
"def normalize_stroke(stroke): <TAB> letters = set(stroke) <TAB> if letters & _NUMBERS: <TAB>  <TAB> if system.NUMBER_KEY in letters: <TAB>  <TAB>  <TAB> stroke = stroke.replace(system.NUMBER_KEY, """") <TAB>  <TAB> # Insert dash when dealing with 'explicit' numbers <TAB>  <TAB> m = _IMPLICIT_NUMBER_RX.search(stroke) <TAB>  <TAB> if m is not None: <TAB>  <TAB>  <TAB> start = m.start(2) <TAB>  <TAB>  <TAB> return stroke[:start] + ""-"" + stroke[start:] <TAB> if ""-"" in letters: <MASK> stroke = stroke[:-1] <TAB>  <TAB> elif letters & system.IMPLICIT_HYPHENS: <TAB>  <TAB>  <TAB> stroke = stroke.replace(""-"", """") <TAB> return stroke","if stroke . endswith ( ""-"" ) :",180
"def _get_py_flags(self): <TAB> res = dict(self.flags) <TAB> cflags = res.pop(""cflags"", """") <TAB> for fl in cflags.split(""|""): <TAB>  <TAB> fl = fl.strip() <TAB>  <TAB> if fl == ""GA_USE_DOUBLE"": <TAB>  <TAB>  <TAB> res[""have_double""] = True <TAB>  <TAB> if fl == ""GA_USE_SMALL"": <TAB>  <TAB>  <TAB> res[""have_small""] = True <MASK> res[""have_complex""] = True <TAB>  <TAB> if fl == ""GA_USE_HALF"": <TAB>  <TAB>  <TAB> res[""have_half""] = True <TAB> return res","if fl == ""GA_USE_COMPLEX"" :",160
"def populate(self): <TAB> classes = self.applet.Plugins.get_classes() <TAB> loaded = self.applet.Plugins.get_loaded() <TAB> for name, cls in classes.items(): <MASK> desc = '<span weight=""bold"">%s</span>' % name <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> desc = name <TAB>  <TAB> self.list.append( <TAB>  <TAB>  <TAB> active=(name in loaded), <TAB>  <TAB>  <TAB> icon=cls.__icon__, <TAB>  <TAB>  <TAB> activatable=cls.__unloadable__, <TAB>  <TAB>  <TAB> name=name, <TAB>  <TAB>  <TAB> desc=desc, <TAB>  <TAB> )",if cls . is_configurable ( ) :,149
"def visit_decorator(self, o: Decorator) -> None: <TAB> if self.is_private_name(o.func.name, o.func.fullname): <TAB>  <TAB> return <TAB> is_abstract = False <TAB> for decorator in o.original_decorators: <TAB>  <TAB> if isinstance(decorator, NameExpr): <TAB>  <TAB>  <TAB> if self.process_name_expr_decorator(decorator, o): <TAB>  <TAB>  <TAB>  <TAB> is_abstract = True <MASK> if self.process_member_expr_decorator(decorator, o): <TAB>  <TAB>  <TAB>  <TAB> is_abstract = True <TAB> self.visit_func_def(o.func, is_abstract=is_abstract)","elif isinstance ( decorator , MemberExpr ) :",160
"def hint(self, button): <TAB> """"""As hilight, but marks GTK Button as well"""""" <TAB> active = None <TAB> for b in self.button_widgets.values(): <MASK> b.widget.set_state(Gtk.StateType.NORMAL) <TAB>  <TAB>  <TAB> if b.name == button: <TAB>  <TAB>  <TAB>  <TAB> active = b.widget <TAB> if active is not None: <TAB>  <TAB> active.set_state(Gtk.StateType.ACTIVE) <TAB> self.hilight(button)",if b . widget . get_sensitive ( ) :,126
"def read_message_py2(self): <TAB> chunks = [] <TAB> while True: <TAB>  <TAB> hi, lo = self.wire.read(2) <MASK> break <TAB>  <TAB> size = hi << 8 | lo <TAB>  <TAB> chunks.append(self.wire.read(size)) <TAB> message = bytearray(b"""".join(map(bytes, chunks))) <TAB> _, n = divmod(message[0], 0x10) <TAB> unpacker = UnpackStream(message, offset=2) <TAB> fields = [unpacker.unpack() for _ in range(n)] <TAB> return message[1], fields",if hi == lo == 0 :,148
"def offsetToRva(self, offset): <TAB> if self.inmem: <TAB>  <TAB> return offset <TAB> for s in self.sections: <TAB>  <TAB> sbase = s.PointerToRawData <TAB>  <TAB> if s.SizeOfRawData + s.PointerToRawData > self.getMaxRva(): <TAB>  <TAB>  <TAB> # SizeOfRawData can be misleading. <TAB>  <TAB>  <TAB> ssize = s.VirtualSize <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ssize = max(s.SizeOfRawData, s.VirtualSize) <MASK> return offset - s.PointerToRawData + s.VirtualAddress <TAB> return 0",if sbase <= offset and offset < sbase + ssize :,155
"def highlight_from_dir(self, workspace_dir): <TAB> while True: <TAB>  <TAB> for f in os.listdir(workspace_dir): <MASK> self.process_trace(os.path.join(workspace_dir, f)) <TAB>  <TAB> if not self.live_update: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> time.sleep(interval)","if f . endswith ( ""trace"" ) :",92
"def check_tokenize(self, s, expected): <TAB> # Format the tokens in s in a table format. <TAB> # The ENDMARKER is omitted. <TAB> result = [] <TAB> f = StringIO(s) <TAB> for type, token, start, end, line in generate_tokens(f.readline): <MASK> break <TAB>  <TAB> type = tok_name[type] <TAB>  <TAB> result.append("" <TAB> %(type)-10.10s %(token)-13.13r %(start)s %(end)s"" % locals()) <TAB> self.assertEqual(result, expected.rstrip().splitlines())",if type == ENDMARKER :,143
"def enable(self): <TAB> """"""enable the patch."""""" <TAB> for patch in self.dependencies: <TAB>  <TAB> patch.enable() <TAB> if not self.enabled: <TAB>  <TAB> pyv = sys.version_info[0] <TAB>  <TAB> if pyv == 2: <TAB>  <TAB>  <TAB> if self.PY2 == SKIP: <TAB>  <TAB>  <TAB>  <TAB> return  # skip patch activation <TAB>  <TAB>  <TAB> if not self.PY2: <TAB>  <TAB>  <TAB>  <TAB> raise IncompatiblePatch(""Python 2 not supported!"") <MASK> if self.PY3 == SKIP: <TAB>  <TAB>  <TAB>  <TAB> return  # skip patch activation <TAB>  <TAB>  <TAB> if not self.PY3: <TAB>  <TAB>  <TAB>  <TAB> raise IncompatiblePatch(""Python 3 not supported!"") <TAB>  <TAB> self.pre_enable() <TAB>  <TAB> self.do_enable() <TAB>  <TAB> self.enabled = True",if pyv == 3 :,191
"def __xor__(self, other): <TAB> inc, exc = _norm_args_notimplemented(other) <TAB> if inc is NotImplemented: <TAB>  <TAB> return NotImplemented <TAB> if inc is NotImplemented: <TAB>  <TAB> return NotImplemented <TAB> if self._included is None: <TAB>  <TAB> if exc is None:  # - + <TAB>  <TAB>  <TAB> return _ComplementSet(excluded=self._excluded - inc) <TAB>  <TAB> else:  # - - <TAB>  <TAB>  <TAB> return _ComplementSet(included=self._excluded.symmetric_difference(exc)) <TAB> else: <MASK> # + - <TAB>  <TAB>  <TAB> return _ComplementSet(excluded=exc - self._included) <TAB>  <TAB> else:  # + + <TAB>  <TAB>  <TAB> return _ComplementSet(included=self._included.symmetric_difference(inc))",if inc is None :,183
"def update_defaults(self, *values, **kwargs): <TAB> for value in values: <TAB>  <TAB> if type(value) == dict: <TAB>  <TAB>  <TAB> self.DEFAULT_CONFIGURATION.update(value) <TAB>  <TAB> elif isinstance(value, types.ModuleType): <TAB>  <TAB>  <TAB> self.__defaults_from_module(value) <MASK> if os.path.exists(value): <TAB>  <TAB>  <TAB>  <TAB> self.__defaults_from_file(value) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> logger.warning(""Configuration file {} does not exist."".format(value)) <TAB>  <TAB> elif isinstance(value, type(None)): <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""Cannot interpret {}"".format(value)) <TAB> self.DEFAULT_CONFIGURATION.update(kwargs)","elif isinstance ( value , str ) :",184
"def maybe_add_0000_to_all_niigz(folder): <TAB> nii_gz = subfiles(folder, suffix="".nii.gz"") <TAB> for n in nii_gz: <TAB>  <TAB> n = remove_trailing_slash(n) <MASK> os.rename(n, n[:-7] + ""_0000.nii.gz"")","if not n . endswith ( ""_0000.nii.gz"" ) :",99
"def newstart(self): <TAB> newstartdatetime = self._newstartdate <TAB> if not self.checkallday.state: <MASK> tzinfo = self.conf.default.default_timezone <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tzinfo = self.startdt.tzinfo <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> newstarttime = self._newstarttime <TAB>  <TAB>  <TAB> newstartdatetime = datetime.combine(newstartdatetime, newstarttime) <TAB>  <TAB>  <TAB> newstartdatetime = tzinfo.localize(newstartdatetime) <TAB>  <TAB> except TypeError: <TAB>  <TAB>  <TAB> return None <TAB> return newstartdatetime","if not hasattr ( self . startdt , ""tzinfo"" ) or self . startdt . tzinfo is None :",156
"def _fetch_all_channels(self, force=False): <TAB> """"""Fetch all channel feeds from cache or network."""""" <TAB> channels = self._get_channel_configs(force=force) <TAB> enabled = self._settings.get([""enabled_channels""]) <TAB> forced = self._settings.get([""forced_channels""]) <TAB> all_channels = {} <TAB> for key, config in channels.items(): <TAB>  <TAB> if key not in enabled and key not in forced: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if ""url"" not in config: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> data = self._get_channel_data(key, config, force=force) <MASK> all_channels[key] = data <TAB> return all_channels",if data is not None :,174
"def _setup_graph(self): <TAB> vars = tf.trainable_variables() <TAB> ops = [] <TAB> for v in vars: <TAB>  <TAB> n = v.op.name <MASK> continue <TAB>  <TAB> logger.info(""Clip {}"".format(n)) <TAB>  <TAB> ops.append(tf.assign(v, tf.clip_by_value(v, -0.01, 0.01))) <TAB> self._op = tf.group(*ops, name=""clip"")","if not n . startswith ( ""discrim/"" ) :",120
"def on_window_state_event(self, widget, event): <TAB> if event.changed_mask & WindowState.ICONIFIED: <MASK> log.debug(""MainWindow is minimized.."") <TAB>  <TAB>  <TAB> component.get(""TorrentView"").save_state() <TAB>  <TAB>  <TAB> component.pause(self.child_components) <TAB>  <TAB>  <TAB> self.is_minimized = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.debug(""MainWindow is not minimized.."") <TAB>  <TAB>  <TAB> component.resume(self.child_components) <TAB>  <TAB>  <TAB> self.is_minimized = False <TAB> return False",if event . new_window_state & WindowState . ICONIFIED :,160
"def getJsonData(self, url, decode_from=None, **kwargs): <TAB> cache_key = md5(url) <TAB> data = self.getCache(cache_key, url, **kwargs) <TAB> if data: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> data = data.strip() <MASK> data = data.decode(decode_from) <TAB>  <TAB>  <TAB> return json.loads(data) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> log.error( <TAB>  <TAB>  <TAB>  <TAB> ""Failed to parsing %s: %s"", (self.getName(), traceback.format_exc()) <TAB>  <TAB>  <TAB> ) <TAB> return []",if decode_from :,152
"def init_weights(self): <TAB> for n, p in self.named_parameters(): <TAB>  <TAB> if ""bias"" in n: <TAB>  <TAB>  <TAB> torch.nn.init.zeros_(p) <MASK> torch.nn.init.xavier_uniform_(p)","elif ""fc"" in n :",71
"def get_file_language(filename, text=None): <TAB> """"""Get file language from filename"""""" <TAB> ext = osp.splitext(filename)[1] <TAB> if ext.startswith("".""): <TAB>  <TAB> ext = ext[1:]  # file extension with leading dot <TAB> language = ext <TAB> if not ext: <MASK> text, _enc = encoding.read(filename) <TAB>  <TAB> for line in text.splitlines(): <TAB>  <TAB>  <TAB> if not line.strip(): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if line.startswith(""#!""): <TAB>  <TAB>  <TAB>  <TAB> shebang = line[2:] <TAB>  <TAB>  <TAB>  <TAB> if ""python"" in shebang: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> language = ""python"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return language",if text is None :,183
"def readwrite(obj, flags): <TAB> try: <MASK> obj.handle_read_event() <TAB>  <TAB> if flags & select.POLLOUT: <TAB>  <TAB>  <TAB> obj.handle_write_event() <TAB>  <TAB> if flags & select.POLLPRI: <TAB>  <TAB>  <TAB> obj.handle_expt_event() <TAB>  <TAB> if flags & (select.POLLHUP | select.POLLERR | select.POLLNVAL): <TAB>  <TAB>  <TAB> obj.handle_close() <TAB> except OSError as e: <TAB>  <TAB> if e.args[0] not in _DISCONNECTED: <TAB>  <TAB>  <TAB> obj.handle_error() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> obj.handle_close() <TAB> except _reraised_exceptions: <TAB>  <TAB> raise <TAB> except: <TAB>  <TAB> obj.handle_error()",if flags & select . POLLIN :,192
"def sortPlaces(self, newColumn, newOrder, force=False): <TAB> profile_id = self.config.currentProfile() <TAB> if newColumn == 0 and newOrder == Qt.AscendingOrder: <MASK> newColumn, newOrder = 1, Qt.AscendingOrder <TAB>  <TAB>  <TAB> self.places.header().setSortIndicator(newColumn, newOrder) <TAB>  <TAB>  <TAB> self.placesSortLoop[profile_id] = False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.placesSortLoop[profile_id] = True <TAB> self.updatePlaces()",if profile_id in self . placesSortLoop and self . placesSortLoop [ profile_id ] :,158
def _result_iter(self): <TAB> pos = 0 <TAB> while 1: <TAB>  <TAB> upper = len(self._result_cache) <TAB>  <TAB> while pos < upper: <TAB>  <TAB>  <TAB> yield self._result_cache[pos] <TAB>  <TAB>  <TAB> pos = pos + 1 <TAB>  <TAB> if not self._iter: <TAB>  <TAB>  <TAB> raise StopIteration <MASK> self._fill_cache(),if len ( self . _result_cache ) <= pos :,102
"def get_field_type(self, name): <TAB> fkey = (name, self.dummy) <TAB> target = None <TAB> op, name = name.split(""_"", 1) <TAB> if op in {""delete"", ""insert"", ""update""}: <TAB>  <TAB> target = super().get_field_type(name) <MASK> module, edb_name = self.get_module_and_name(name) <TAB>  <TAB>  <TAB> target = self.edb_schema.get((module, edb_name), None) <TAB>  <TAB>  <TAB> if target is not None: <TAB>  <TAB>  <TAB>  <TAB> target = self.convert_edb_to_gql_type(target) <TAB> self._fields[fkey] = target <TAB> return target",if target is None :,170
"def _transaction(self, args=None): <TAB> cmd = args[0] if args else None <TAB> if cmd == ""reset"": <TAB>  <TAB> self._clean() <TAB>  <TAB> return <TAB> self._resolve() <TAB> if cmd in [""list"", None]: <MASK> out = self.base.output.list_transaction(self.base._transaction) <TAB>  <TAB>  <TAB> logger.info(out) <TAB> elif cmd == ""run"": <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.base.do_transaction() <TAB>  <TAB> except dnf.exceptions.Error as e: <TAB>  <TAB>  <TAB> logger.error(_(""Error:"") + "" "" + ucd(e)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logger.info(_(""Complete!"")) <TAB>  <TAB> self._clean() <TAB> else: <TAB>  <TAB> self._help(""transaction"")",if self . base . _transaction :,191
"def _gather_crash_info(self): <TAB> super()._gather_crash_info() <TAB> self._crash_info += [ <TAB>  <TAB> (""Commandline args"", "" "".join(sys.argv[1:])), <TAB>  <TAB> (""Open Pages"", ""\n\n"".join(""\n"".join(e) for e in self._pages)), <TAB>  <TAB> (""Command history"", ""\n"".join(self._cmdhist)), <TAB>  <TAB> (""Objects"", self._qobjects), <TAB> ] <TAB> try: <TAB>  <TAB> text = ""Log output was disabled."" <MASK> text = log.ram_handler.dump_log() <TAB>  <TAB> self._crash_info.append((""Debug log"", text)) <TAB> except Exception: <TAB>  <TAB> self._crash_info.append((""Debug log"", traceback.format_exc()))",if log . ram_handler is not None :,192
"def classifyws(s, tabwidth): <TAB> raw = effective = 0 <TAB> for ch in s: <TAB>  <TAB> if ch == "" "": <TAB>  <TAB>  <TAB> raw = raw + 1 <TAB>  <TAB>  <TAB> effective = effective + 1 <MASK> raw = raw + 1 <TAB>  <TAB>  <TAB> effective = (effective // tabwidth + 1) * tabwidth <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> return raw, effective","elif ch == ""\t"" :",101
"def process(self, node): <TAB> self.vars = [] <TAB> for child in node.childNodes: <MASK> child_text = get_xml_text(child) <TAB>  <TAB>  <TAB> if child_text == """":  # pragma:nocover <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if child.nodeName == ""Real"": <TAB>  <TAB>  <TAB>  <TAB> for val in re.split(""[\t ]+"", child_text): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.vars.append(1.0 * eval(val)) <TAB> return self",if child . nodeType == node . ELEMENT_NODE :,135
"def _format_privilege_data(self, data): <TAB> for key in [""spcacl""]: <MASK> if ""added"" in data[key]: <TAB>  <TAB>  <TAB>  <TAB> data[key][""added""] = parse_priv_to_db(data[key][""added""], self.acl) <TAB>  <TAB>  <TAB> if ""changed"" in data[key]: <TAB>  <TAB>  <TAB>  <TAB> data[key][""changed""] = parse_priv_to_db(data[key][""changed""], self.acl) <TAB>  <TAB>  <TAB> if ""deleted"" in data[key]: <TAB>  <TAB>  <TAB>  <TAB> data[key][""deleted""] = parse_priv_to_db(data[key][""deleted""], self.acl)",if key in data and data [ key ] is not None :,168
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_application_key(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 18: <TAB>  <TAB>  <TAB> self.set_message(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 26: <TAB>  <TAB>  <TAB> self.set_tag(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,152
"def test_cat(shape, cat_dim, split, dim): <TAB> assert sum(split) == shape[cat_dim] <TAB> gaussian = random_gaussian(shape, dim) <TAB> parts = [] <TAB> end = 0 <TAB> for size in split: <TAB>  <TAB> beg, end = end, end + size <TAB>  <TAB> if cat_dim == -1: <TAB>  <TAB>  <TAB> part = gaussian[..., beg:end] <MASK> part = gaussian[..., beg:end, :] <TAB>  <TAB> elif cat_dim == 1: <TAB>  <TAB>  <TAB> part = gaussian[:, beg:end] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError <TAB>  <TAB> parts.append(part) <TAB> actual = Gaussian.cat(parts, cat_dim) <TAB> assert_close_gaussian(actual, gaussian)",elif cat_dim == - 2 :,186
"def __conform__(self, interface, registry=None, default=None): <TAB> for providedInterface in self.provided: <MASK> return self.load() <TAB>  <TAB> if getAdapterFactory(providedInterface, interface, None) is not None: <TAB>  <TAB>  <TAB> return interface(self.load(), default) <TAB> return default",if providedInterface . isOrExtends ( interface ) :,87
"def __init__(self, oid): <TAB> self.oid = oid <TAB> self.cmpt = [] <TAB> fmt = [] <TAB> for i in oid.split("".""): <MASK> fmt.append(""%i"") <TAB>  <TAB>  <TAB> self.cmpt.append(tuple(map(int, i.split(""-"")))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> fmt.append(i) <TAB> self.fmt = ""."".join(fmt)","if ""-"" in i :",104
"def build_CallFunc(self, o): <TAB> children = o.getChildren() <TAB> # Build callee from first child <TAB> callee = self.build(children[0]) <TAB> # Build args and kwargs from remaining children <TAB> args = [] <TAB> kwargs = {} <TAB> for child in children[1:]: <TAB>  <TAB> class_name = child.__class__.__name__ <TAB>  <TAB> # None is ignored <MASK> continue <TAB>  <TAB> # Keywords become kwargs <TAB>  <TAB> if class_name == ""Keyword"": <TAB>  <TAB>  <TAB> kwargs.update(self.build(child)) <TAB>  <TAB> # Everything else becomes args <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> args.append(self.build(child)) <TAB> return callee(*args, **kwargs)","if class_name == ""NoneType"" :",175
"def format_raises(self, e, *args, **kw): <TAB> self.startTest() <TAB> try: <TAB>  <TAB> args[0].format(*args[1:], **kw) <TAB> except e: <TAB>  <TAB> return True <TAB> else: <MASK> excName = e.__name__ <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> excName = str(e) <TAB>  <TAB> self.fail(""%s not raised"" % excName) <TAB> return False","if hasattr ( e , ""__name__"" ) :",114
"def make_record_paths_absolute(self, record_dict): <TAB> # make paths absolute <TAB> d = {} <TAB> for k, v in record_dict.items(): <MASK> # filename <TAB>  <TAB>  <TAB> if ""."" in v: <TAB>  <TAB>  <TAB>  <TAB> v = os.path.join(self.path, v) <TAB>  <TAB> d[k] = v <TAB> return d",if type ( v ) == str :,95
"def work(self): <TAB> while self.active: <TAB>  <TAB> stat = os.stat(self.filename) <MASK> self.callback(self.last_stat, stat) <TAB>  <TAB> self.last_stat = stat <TAB>  <TAB> time.sleep(self.interval)",if self . last_stat is not None and self . last_stat != stat :,84
"def try_append_extension(self, path): <TAB> append_setting = self.get_append_extension_setting() <TAB> if self.settings.get(append_setting, False): <TAB>  <TAB> if not self.is_copy_original_name(path): <TAB>  <TAB>  <TAB> _, new_path_extension = os.path.splitext(path) <TAB>  <TAB>  <TAB> if new_path_extension == """": <TAB>  <TAB>  <TAB>  <TAB> argument_name = self.get_argument_name() <MASK> _, extension = os.path.splitext(self.view.file_name()) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _, extension = os.path.splitext(argument_name) <TAB>  <TAB>  <TAB>  <TAB> path += extension <TAB> return path",if argument_name is None :,181
"def _out_of_date(rw_file): <TAB> """"""Check if a run workflow file points to an older version of manta and needs a refresh."""""" <TAB> with open(rw_file) as in_handle: <TAB>  <TAB> for line in in_handle: <MASK> file_version = line.split(""/lib/python"")[0].split(""Cellar/manta/"")[-1] <TAB>  <TAB>  <TAB>  <TAB> if file_version != programs.get_version_manifest(""manta""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False","if line . startswith ( ""sys.path.append"" ) :",137
"def test_model_inference(): <TAB> x = torch.rand(1, 3, 224, 224) <TAB> for model_name in encoding.models.pretrained_model_list(): <TAB>  <TAB> print(""Doing: "", model_name) <MASK> continue  # need multi-gpu <TAB>  <TAB> model = encoding.models.get_model(model_name, pretrained=True) <TAB>  <TAB> model.eval() <TAB>  <TAB> y = model(x)","if ""wideresnet"" in model_name :",115
"def _process_frame(self, frame_num, frame_im, callback=None): <TAB> # type(int, numpy.ndarray) -> None <TAB> """"""Adds any cuts detected with the current frame to the cutting list."""""" <TAB> for detector in self._detector_list: <TAB>  <TAB> cuts = detector.process_frame(frame_num, frame_im) <MASK> callback(frame_im, frame_num) <TAB>  <TAB> self._cutting_list += cuts <TAB> for detector in self._sparse_detector_list: <TAB>  <TAB> events = detector.process_frame(frame_num, frame_im) <TAB>  <TAB> if events and callback: <TAB>  <TAB>  <TAB> callback(frame_im, frame_num) <TAB>  <TAB> self._event_list += events",if cuts and callback :,178
"def __saveWork(self, work, results): <TAB> """"""Stores the resulting last log line to the cache with the proxy key"""""" <TAB> del work <TAB> # pylint: disable=broad-except <TAB> try: <MASK> __cached = self.__cache[results[0]] <TAB>  <TAB>  <TAB> __cached[self.__TIME] = time.time() <TAB>  <TAB>  <TAB> __cached[self.__ETA] = results[1] <TAB> except KeyError as e: <TAB>  <TAB> # Could happen while switching jobs with work in the queue <TAB>  <TAB> pass <TAB> except Exception as e: <TAB>  <TAB> list(map(logger.warning, cuegui.Utils.exceptionOutput(e)))",if results :,154
"def _on_preference_changed(self, client, timestamp, entry, extra): <TAB> attr = entry.key[entry.key.rindex(""/"") + 1 :] <TAB> try: <TAB>  <TAB> valuestruct = self._prefs[attr] <TAB> except KeyError:  # unknown key, we don't care about it <TAB>  <TAB> pass <TAB> else: <MASK> # value has changed <TAB>  <TAB>  <TAB> newval = getattr(entry.value, ""get_%s"" % valuestruct.type)() <TAB>  <TAB>  <TAB> setattr(self, attr, newval) <TAB>  <TAB> else:  # value has been deleted <TAB>  <TAB>  <TAB> setattr(self, attr, valuestruct.default)",if entry . value != None :,153
"def open(self, url, new=0, autoraise=1): <TAB> cmdline = [self.name] + [arg.replace(""%s"", url) for arg in self.args] <TAB> try: <MASK> p = subprocess.Popen(cmdline) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> setsid = getattr(os, ""setsid"", None) <TAB>  <TAB>  <TAB> if not setsid: <TAB>  <TAB>  <TAB>  <TAB> setsid = getattr(os, ""setpgrp"", None) <TAB>  <TAB>  <TAB> p = subprocess.Popen(cmdline, close_fds=True, preexec_fn=setsid) <TAB>  <TAB> return p.poll() is None <TAB> except OSError: <TAB>  <TAB> return False","if sys . platform [ : 3 ] == ""win"" :",170
"def get_ofs(self, dp_id): <TAB> if len(self) == 0: <TAB>  <TAB> raise ValueError(""qos sw is not connected."") <TAB> dps = {} <TAB> if dp_id == REST_ALL: <TAB>  <TAB> dps = self <TAB> else: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> dpid = dpid_lib.str_to_dpid(dp_id) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> raise ValueError(""Invalid switchID."") <MASK> dps = {dpid: self[dpid]} <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> msg = ""qos sw is not connected. : switchID=%s"" % dp_id <TAB>  <TAB>  <TAB> raise ValueError(msg) <TAB> return dps",if dpid in self :,173
"def __init__(self, context, keymap={}): <TAB> if not ActionHandler._actions: <TAB>  <TAB> ActionHandler._actions = Actions.get_instance(context) <TAB> _keymap = {} <TAB> for (k, v) in keymap.items(): <MASK> v = {v} <TAB>  <TAB> _keymap[k] = {op for action in v for op in translate_blenderop(action)} <TAB> self.__dict__[""_keymap""] = _keymap",if type ( v ) is not set and type ( v ) is not list :,125
"def setCounter(self, i): <TAB> if 0 == i: <MASK> self.setIcon(QtGui.QIcon.fromTheme(""scudcloud-attention"")) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.setIcon(QtGui.QIcon.fromTheme(""scudcloud"")) <TAB> elif i > 0 and i < 10: <TAB>  <TAB> self.setIcon(QtGui.QIcon.fromTheme(""scudcloud-attention-"" + str(int(i)))) <TAB> elif i > 9: <TAB>  <TAB> self.setIcon(QtGui.QIcon.fromTheme(""scudcloud-attention-9-plus""))",if True == self . urgent :,146
"def consume_bytes(data): <TAB> state_machine.receive_data(data) <TAB> while True: <TAB>  <TAB> event = state_machine.next_event() <TAB>  <TAB> if event is h11.NEED_DATA: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif isinstance(event, h11.InformationalResponse): <TAB>  <TAB>  <TAB> # Ignore 1xx responses <TAB>  <TAB>  <TAB> continue <MASK> # We have our response! Save it and get out of here. <TAB>  <TAB>  <TAB> context[""h11_response""] = event <TAB>  <TAB>  <TAB> raise LoopAbort <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Can't happen <TAB>  <TAB>  <TAB> raise RuntimeError(""Unexpected h11 event {}"".format(event))","elif isinstance ( event , h11 . Response ) :",166
"def _evoke_request(cls): <TAB> succeed = False <TAB> with cls.LOCK: <MASK> resource, request_semaphore = cls.REQUESTING_STACK.pop() <TAB>  <TAB>  <TAB> node = cls.check_availability(resource) <TAB>  <TAB>  <TAB> if node is not None: <TAB>  <TAB>  <TAB>  <TAB> cls.NODE_RESOURCE_MANAGER[node]._request(node, resource) <TAB>  <TAB>  <TAB>  <TAB> logger.debug(""\nEvoking requesting resource {}"".format(resource)) <TAB>  <TAB>  <TAB>  <TAB> request_semaphore.release() <TAB>  <TAB>  <TAB>  <TAB> succeed = True <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> cls.REQUESTING_STACK.append((resource, request_semaphore)) <TAB>  <TAB>  <TAB>  <TAB> return <TAB> if succeed: <TAB>  <TAB> cls._evoke_request()",if len ( cls . REQUESTING_STACK ) > 0 :,188
"def _get_related_field(self, field): <TAB> model_class = self.Meta.model <TAB> try: <TAB>  <TAB> related_field = model_class._meta.get_field(field.source) <TAB> except FieldDoesNotExist: <TAB>  <TAB> # If `related_name` is not set, field name does not include <TAB>  <TAB> # `_set` -> remove it and check again <TAB>  <TAB> default_postfix = ""_set"" <MASK> related_field = model_class._meta.get_field( <TAB>  <TAB>  <TAB>  <TAB> field.source[: -len(default_postfix)] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise <TAB> if isinstance(related_field, ForeignObjectRel): <TAB>  <TAB> return related_field.field, False <TAB> return related_field, True",if field . source . endswith ( default_postfix ) :,189
"def find_best_layout_for_subplots(num_subplots): <TAB> r, c = 1, 1 <TAB> while (r * c) < num_subplots: <MASK> c += 1 <TAB>  <TAB> elif c == (r + 2): <TAB>  <TAB>  <TAB> r += 1 <TAB>  <TAB>  <TAB> c -= 1 <TAB> return r, c",if ( c == ( r + 1 ) ) or ( r == c ) :,94
"def __repr__(self): <TAB> attrs = {} <TAB> for name, _ in self: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> attr = getattr(self, name) <MASK> attrs[name] = repr(attr) <TAB>  <TAB> except ValidationError: <TAB>  <TAB>  <TAB> pass <TAB> return ""{class_name}({fields})"".format( <TAB>  <TAB> class_name=self.__class__.__name__, <TAB>  <TAB> fields="", "".join(""{0[0]}={0[1]}"".format(x) for x in sorted(attrs.items())), <TAB> )",if attr is not None :,132
"def findsection(self, key): <TAB> to_return = copy.deepcopy(self) <TAB> for subsection in to_return: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> value = list(ConfigObj.find_key(to_return[subsection], key))[0] <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> value = None <MASK> del to_return[subsection] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for category in to_return[subsection]: <TAB>  <TAB>  <TAB>  <TAB> if category != key: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> del to_return[subsection][category] <TAB> # cleanout empty sections and subsections <TAB> for key in [k for (k, v) in to_return.items() if not v]: <TAB>  <TAB> del to_return[key] <TAB> return to_return",if not value :,189
"def _get_streams(self, url, video_id, app_id_ver): <TAB> # Sometimes the return dict does not have 'stream' <TAB> for trial_count in range(3): <TAB>  <TAB> stream_info = self._get_stream_info( <TAB>  <TAB>  <TAB> url, <TAB>  <TAB>  <TAB> video_id, <TAB>  <TAB>  <TAB> app_id_ver, <TAB>  <TAB>  <TAB> extra_note="" (try %d)"" % (trial_count + 1) if trial_count > 0 else """", <TAB>  <TAB> ) <MASK> return stream_info[0][""args""][0][""stream""] <TAB> return []","if ""stream"" in stream_info [ 0 ] [ ""args"" ] [ 0 ] :",156
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 8: <TAB>  <TAB>  <TAB> self.set_format(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 18: <TAB>  <TAB>  <TAB> self.set_path(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,120
"def summary(self): <TAB> """"""Return a string with a pretty-printed summary for the company."""""" <TAB> if not self: <TAB>  <TAB> return u"""" <TAB> s = u""Company\n=======\nName: %s\n"" % self.get(""name"", u"""") <TAB> for k in ( <TAB>  <TAB> ""distributor"", <TAB>  <TAB> ""production company"", <TAB>  <TAB> ""miscellaneous company"", <TAB>  <TAB> ""special effects company"", <TAB> ): <TAB>  <TAB> d = self.get(k, [])[:5] <MASK> continue <TAB>  <TAB> s += u""Last movies from this company (%s): %s.\n"" % ( <TAB>  <TAB>  <TAB> k, <TAB>  <TAB>  <TAB> u""; "".join([x.get(""long imdb title"", u"""") for x in d]), <TAB>  <TAB> ) <TAB> return s",if not d :,190
"def __call__(self, data): <TAB> keys = set(data.keys) <TAB> for attr_name in self._attr_names: <MASK> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> ""attr_name: {} isn t within keys: {}"".format(attr_name, keys) <TAB>  <TAB>  <TAB> ) <TAB> for attr_name in self._attr_names: <TAB>  <TAB> delattr(data, attr_name) <TAB> return data",if attr_name not in keys and self . _strict :,112
"def _count(self, element, count=True): <TAB> if not isinstance(element, six.string_types): <TAB>  <TAB> if self == element: <TAB>  <TAB>  <TAB> return 1 <TAB> i = 0 <TAB> for child in self.children: <TAB>  <TAB> # child is text content and element is also text content, then <TAB>  <TAB> # make a simple ""text"" in ""text"" <TAB>  <TAB> if isinstance(child, six.string_types): <TAB>  <TAB>  <TAB> if isinstance(element, six.string_types): <MASK> i += child.count(element) <TAB>  <TAB>  <TAB>  <TAB> elif element in child: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> i += child._count(element, count=count) <TAB>  <TAB>  <TAB> if not count and i: <TAB>  <TAB>  <TAB>  <TAB> return i <TAB> return i",if count :,196
"def produce_etag_headers(self, filename): <TAB> """"""Produce a dict of curl headers containing etag headers from the download."""""" <TAB> headers = {} <TAB> # If the download file already exists, add some headers to the request <TAB> # so we don't retrieve the content if it hasn't changed <TAB> if os.path.exists(filename): <TAB>  <TAB> self.existing_file_size = os.path.getsize(filename) <TAB>  <TAB> etag = self.getxattr(self.xattr_etag) <TAB>  <TAB> last_modified = self.getxattr(self.xattr_last_modified) <TAB>  <TAB> if etag: <TAB>  <TAB>  <TAB> headers[""If-None-Match""] = etag <MASK> headers[""If-Modified-Since""] = last_modified <TAB> return headers",if last_modified :,182
"def repack(self): <TAB> newNsp = Pfs0Stream(self._path[:-4] + "".nsp"") <TAB> for nspF in self.hfs0[""secure""]: <TAB>  <TAB> f = newNsp.add(nspF._path, nspF.size) <TAB>  <TAB> nspF.rewind() <TAB>  <TAB> i = 0 <TAB>  <TAB> pageSize = 0x10000 <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> buf = nspF.read(pageSize) <MASK> break <TAB>  <TAB>  <TAB> i += len(buf) <TAB>  <TAB>  <TAB> f.write(buf) <TAB> newNsp.close()",if len ( buf ) == 0 :,152
"def assertHasChanged(self, **kwargs): <TAB> tracker = kwargs.pop(""tracker"", self.tracker) <TAB> for field, value in kwargs.items(): <MASK> with self.assertRaises(FieldError): <TAB>  <TAB>  <TAB>  <TAB> tracker.has_changed(field) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertEqual(tracker.has_changed(field), value)",if value is None :,91
"def check_engine(engine): <TAB> if engine == ""auto"": <TAB>  <TAB> if pa is not None: <TAB>  <TAB>  <TAB> return ""pyarrow"" <TAB>  <TAB> elif fastparquet is not None:  # pragma: no cover <TAB>  <TAB>  <TAB> return ""fastparquet"" <TAB>  <TAB> else:  # pragma: no cover <TAB>  <TAB>  <TAB> raise RuntimeError(""Please install either pyarrow or fastparquet."") <TAB> elif engine == ""pyarrow"": <MASK> # pragma: no cover <TAB>  <TAB>  <TAB> raise RuntimeError(""Please install pyarrow fisrt."") <TAB>  <TAB> return engine <TAB> elif engine == ""fastparquet"": <TAB>  <TAB> if fastparquet is None:  # pragma: no cover <TAB>  <TAB>  <TAB> raise RuntimeError(""Please install fastparquet first."") <TAB>  <TAB> return engine <TAB> else:  # pragma: no cover <TAB>  <TAB> raise RuntimeError(""Unsupported engine {} to read parquet."".format(engine))",if pa is None :,187
"def parse_vcs_bundle_file(self, content): <TAB> for line in content.splitlines(): <MASK> continue <TAB>  <TAB> match = re.search(r""^-r\s*([^ ])?"", line) <TAB>  <TAB> if not match: <TAB>  <TAB>  <TAB> return None, None <TAB>  <TAB> rev = match.group(1) <TAB>  <TAB> rest = line[match.end() :].strip().split(None, 1)[0] <TAB>  <TAB> return rest, rev <TAB> return None, None","if not line . strip ( ) or line . strip ( ) . startswith ( ""#"" ) :",127
"def __init__(self, parent_instance, *args, **kwargs): <TAB> self.parent_instance = parent_instance <TAB> self.pk_field = kwargs.pop(""pk_field"", False) <TAB> self.to_field = kwargs.pop(""to_field"", None) <TAB> if self.parent_instance is not None: <MASK> kwargs[""initial""] = getattr(self.parent_instance, self.to_field) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> kwargs[""initial""] = self.parent_instance.pk <TAB> kwargs[""required""] = False <TAB> kwargs[""widget""] = InlineForeignKeyHiddenInput <TAB> super(InlineForeignKeyField, self).__init__(*args, **kwargs)",if self . to_field :,165
"def number_multiple_validator(v: ""Number"", field: ""ModelField"") -> ""Number"": <TAB> field_type: ConstrainedNumber = field.type_ <TAB> if field_type.multiple_of is not None: <TAB>  <TAB> mod = float(v) / float(field_type.multiple_of) % 1 <MASK> raise errors.NumberNotMultipleError(multiple_of=field_type.multiple_of) <TAB> return v","if not almost_equal_floats ( mod , 0.0 ) and not almost_equal_floats ( mod , 1.0 ) :",132
"def forward(self, x, edge_index, edge_attr=None): <TAB> x_old = 0 <TAB> for i, layer in enumerate(self.hidden_layers): <TAB>  <TAB> x = self.dropout(x) <TAB>  <TAB> x = layer(x, edge_index) <TAB>  <TAB> x = self.norm(x) <TAB>  <TAB> x = self.relu(x) <MASK> x = x + x_old <TAB>  <TAB>  <TAB> x_old = x <TAB> x = self.dropout(x) <TAB> x = self.out_layer(x, edge_index) <TAB> return x",if self . skip > 0 and i % self . skip == 0 :,154
"def check_dimensions(nrow, ncol): <TAB> if nrow is not None: <MASK> warn( <TAB>  <TAB>  <TAB>  <TAB> ""'nrow' must be greater than 0. "" ""Your value has been ignored."", <TAB>  <TAB>  <TAB>  <TAB> PlotnineWarning, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> nrow = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> nrow = int(nrow) <TAB> if ncol is not None: <TAB>  <TAB> if ncol < 1: <TAB>  <TAB>  <TAB> warn( <TAB>  <TAB>  <TAB>  <TAB> ""'ncol' must be greater than 0. "" ""Your value has been ignored."", <TAB>  <TAB>  <TAB>  <TAB> PlotnineWarning, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ncol = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ncol = int(ncol) <TAB> return nrow, ncol",if nrow < 1 :,189
"def logic(): <TAB> while 1: <TAB>  <TAB> yield clock.posedge, reset.negedge <TAB>  <TAB> if reset == ACTIVE_LOW: <TAB>  <TAB>  <TAB> count.next = 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if enable: <MASK> count.next = n - 1 <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> count.next = count - 1",if count == - n :,99
"def get_whitelist(self, guild: Optional[discord.Guild] = None) -> Set[int]: <TAB> async with self._access_lock: <TAB>  <TAB> ret: Set[int] <TAB>  <TAB> gid: Optional[int] = guild.id if guild else None <MASK> ret = self._cached_whitelist[gid].copy() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if gid is not None: <TAB>  <TAB>  <TAB>  <TAB> ret = set(await self._config.guild_from_id(gid).whitelist()) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> ret = set(await self._config.whitelist()) <TAB>  <TAB>  <TAB> self._cached_whitelist[gid] = ret.copy() <TAB>  <TAB> return ret",if gid in self . _cached_whitelist :,177
"def process_response(self, request, response): <TAB> if getattr(self, ""has_session"", False): <MASK> user = ""%s (id:%s)"" % (request.user.username, request.user.pk) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> user = ""(Anonymous)"" <TAB>  <TAB> self.logger.info( <TAB>  <TAB>  <TAB> ""Session %s authenticated by %s"", request.session.session_key, user <TAB>  <TAB> ) <TAB>  <TAB> request.session.save = self._save <TAB>  <TAB> self._save = None <TAB>  <TAB> self.session = None <TAB>  <TAB> self.has_session = False","if getattr ( request , ""user"" , None ) and request . user . is_authenticated ( ) :",163
"def cluster(spawnpoints, radius, time_threshold): <TAB> clusters = [] <TAB> diameter = 2 * radius <TAB> for p in spawnpoints: <TAB>  <TAB> if len(clusters) == 0: <TAB>  <TAB>  <TAB> clusters.append(Spawncluster(p)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> c = min(clusters, key=lambda x: cost(p, x, time_threshold)) <MASK> c.append(p) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> c = Spawncluster(p) <TAB>  <TAB>  <TAB>  <TAB> clusters.append(c) <TAB> return clusters","if check_cluster ( p , c , radius , time_threshold ) :",152
"def get_shape(shape): <TAB> """"""Convert the shape to correct dtype and vars."""""" <TAB> ret = [] <TAB> for dim in shape: <MASK> if libinfo()[""INDEX_DEFAULT_I64""] == ""ON"": <TAB>  <TAB>  <TAB>  <TAB> ret.append(dim) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> val = int(dim) <TAB>  <TAB>  <TAB>  <TAB> assert val <= np.iinfo(np.int32).max <TAB>  <TAB>  <TAB>  <TAB> ret.append(tvm.tir.IntImm(""int32"", val)) <TAB>  <TAB> elif isinstance(dim, tvm.tir.Any): <TAB>  <TAB>  <TAB> ret.append(te.var(""any_dim"", ""int32"")) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret.append(dim) <TAB> return ret","if isinstance ( dim , tvm . tir . IntImm ) :",194
"def run(self): <TAB> queue = self.queue <TAB> while True: <TAB>  <TAB> if not self.running: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> # Grab our data <TAB>  <TAB> callback, requests, fetchTimeout, validityOverride = queue.get() <TAB>  <TAB> # Grab prices, this is the time-consuming part <TAB>  <TAB> if len(requests) > 0: <TAB>  <TAB>  <TAB> Price.fetchPrices(requests, fetchTimeout, validityOverride) <TAB>  <TAB> wx.CallAfter(callback) <TAB>  <TAB> queue.task_done() <TAB>  <TAB> # After we fetch prices, go through the list of waiting items and call their callbacks <TAB>  <TAB> for price in requests: <TAB>  <TAB>  <TAB> callbacks = self.wait.pop(price.typeID, None) <MASK> for callback in callbacks: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> wx.CallAfter(callback)",if callbacks :,197
def _load_scopes_(self): <TAB> if self._model_ is None: <TAB>  <TAB> tablemap = self.db._adapter.tables(self.query) <MASK> self._model_ = tablemap.popitem()[1]._model_ <TAB> if self._model_: <TAB>  <TAB> self._scopes_ = self._model_._instance_()._scopes_,if len ( tablemap ) == 1 :,92
"def udp_to_tcp(udp_sock, tcp_conn): <TAB> while True: <TAB>  <TAB> msg, _ = udp_sock.recvfrom(2 ** 16) <TAB>  <TAB> log_msg(""read_udp"", msg) <MASK> return <TAB>  <TAB> write_tcp(tcp_conn, msg)",if not msg :,80
"def __get_annotations(self): <TAB> if not hasattr(self, ""_annotations""): <TAB>  <TAB> self._annotations = _retrieve_annotations( <TAB>  <TAB>  <TAB> self._adaptor, self._primary_id, self._taxon_id <TAB>  <TAB> ) <TAB>  <TAB> if self._identifier: <TAB>  <TAB>  <TAB> self._annotations[""gi""] = self._identifier <MASK> self._annotations[""data_file_division""] = self._division <TAB> return self._annotations",if self . _division :,110
"def ignore_module(module): <TAB> result = False <TAB> for check in ignore_these: <MASK> if check[:-1] in module: <TAB>  <TAB>  <TAB>  <TAB> result = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if (os.getcwd() + ""/"" + check + "".py"") == module: <TAB>  <TAB>  <TAB>  <TAB> result = True <TAB> if result: <TAB>  <TAB> print_warning(""Ignoring module: "" + module) <TAB> return result","if ""/*"" in check :",108
"def find_commands(management_dir): <TAB> # Modified version of function from django/core/management/__init__.py. <TAB> command_dir = os.path.join(management_dir, ""commands"") <TAB> commands = [] <TAB> try: <TAB>  <TAB> for f in os.listdir(command_dir): <MASK> continue <TAB>  <TAB>  <TAB> elif f.endswith("".py"") and f[:-3] not in commands: <TAB>  <TAB>  <TAB>  <TAB> commands.append(f[:-3]) <TAB>  <TAB>  <TAB> elif f.endswith("".pyc"") and f[:-4] not in commands: <TAB>  <TAB>  <TAB>  <TAB> commands.append(f[:-4]) <TAB> except OSError: <TAB>  <TAB> pass <TAB> return commands","if f . startswith ( ""_"" ) :",164
"def _add_kid(key, x): <TAB> if x is None: <TAB>  <TAB> kids[key] = None <TAB> else: <MASK> x1 = [i for i in x if isinstance(i, TVTKBase)] <TAB>  <TAB>  <TAB> if x1: <TAB>  <TAB>  <TAB>  <TAB> kids[key] = x1 <TAB>  <TAB> elif isinstance(x, TVTKBase): <TAB>  <TAB>  <TAB> if hasattr(x, ""__iter__""): <TAB>  <TAB>  <TAB>  <TAB> # Don't add iterable objects that contain non <TAB>  <TAB>  <TAB>  <TAB> # acceptable nodes <TAB>  <TAB>  <TAB>  <TAB> if len(list(x)) and isinstance(list(x)[0], TVTKBase): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> kids[key] = x <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> kids[key] = x","if type ( x ) in ( type ( [ ] ) , type ( ( ) ) ) :",196
"def classify(self, url, text): <TAB> for match in self.rules.match(data=text): <MASK> continue <TAB>  <TAB> self.matches.append((url, match)) <TAB>  <TAB> if self.discard_url_match(url, match):  # pragma: no cover <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> self.handle_match_etags(match) <TAB>  <TAB> rule = match.rule <TAB>  <TAB> meta = match.meta <TAB>  <TAB> tags = "","".join(["" "".join(t.split(""_"")) for t in match.tags]) <TAB>  <TAB> log.ThugLogging.log_classifier(""text"", url, rule, tags, meta) <TAB> for c in self.custom_classifiers: <TAB>  <TAB> self.custom_classifiers[c](url, text)","if ( url , match ) in self . matches :",186
"def recurse(node): <TAB> for child in node.childNodes: <MASK> continue <TAB>  <TAB> if child.nodeName.upper() == ""H1"": <TAB>  <TAB>  <TAB> return child <TAB>  <TAB> if child not in visited: <TAB>  <TAB>  <TAB> return recurse(child)",if child . nodeType != child . ELEMENT_NODE :,76
"def try_fix_ip_range(self): <TAB> for i in range(len(self.fake_ip_parts)): <MASK> if i - 1 < 0: <TAB>  <TAB>  <TAB>  <TAB> raise Exception(""Fake IP's out of range."") <TAB>  <TAB>  <TAB> self.fake_ip_parts[i - 1] += 1 <TAB>  <TAB>  <TAB> self.fake_ip_parts[i] = 1",if self . fake_ip_parts [ i ] > 256 :,106
"def run(self): <TAB> self.thread.start() <TAB> while self.thread.isRunning(): <MASK> self.update.emit(config.imager_percentage) <TAB>  <TAB> if not self.thread.isFinished() and config.percentage == 100: <TAB>  <TAB>  <TAB> config.imager_status_text = """" <TAB>  <TAB>  <TAB> self.status.emit(""Please wait..."") <TAB>  <TAB> time.sleep(0.1) <TAB> self.update.emit(100) <TAB> self.update.emit(0) <TAB> if self.thread.isFinished(): <TAB>  <TAB> config.status_text = """" <TAB>  <TAB> self.finished.emit() <TAB> return",if config . imager_percentage :,161
"def _get_trading_minutes(self, trading_date): <TAB> trading_minutes = set() <TAB> for account_type in self._config.base.accounts: <MASK> trading_minutes = trading_minutes.union( <TAB>  <TAB>  <TAB>  <TAB> self._get_stock_trading_minutes(trading_date) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> elif account_type == DEFAULT_ACCOUNT_TYPE.FUTURE: <TAB>  <TAB>  <TAB> trading_minutes = trading_minutes.union( <TAB>  <TAB>  <TAB>  <TAB> self._get_future_trading_minutes(trading_date) <TAB>  <TAB>  <TAB> ) <TAB> return sorted(list(trading_minutes))",if account_type == DEFAULT_ACCOUNT_TYPE . STOCK :,169
"def lngettext(self, msgid1, msgid2, n): <TAB> import warnings <TAB> warnings.warn( <TAB>  <TAB> ""lngettext() is deprecated, use ngettext() instead"", DeprecationWarning, 2 <TAB> ) <TAB> try: <TAB>  <TAB> tmsg = self._catalog[(msgid1, self.plural(n))] <TAB> except KeyError: <TAB>  <TAB> if self._fallback: <TAB>  <TAB>  <TAB> return self._fallback.lngettext(msgid1, msgid2, n) <MASK> tmsg = msgid1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tmsg = msgid2 <TAB> if self._output_charset: <TAB>  <TAB> return tmsg.encode(self._output_charset) <TAB> return tmsg.encode(locale.getpreferredencoding())",if n == 1 :,176
"def check_langs(langs, pairs): <TAB> messages = [] <TAB> for src, tgt in pairs: <MASK> messages.append( <TAB>  <TAB>  <TAB>  <TAB> f""language pair {src}-{tgt} contains languages "" <TAB>  <TAB>  <TAB>  <TAB> ""that are not in the language dictionary"" <TAB>  <TAB>  <TAB> ) <TAB> if len(messages) > 0: <TAB>  <TAB> raise ValueError("" "".join(messages) + f""; langs: {langs}"")",if src not in langs or tgt not in langs :,114
"def to_header(self): <TAB> """"""Converts the object back into an HTTP header."""""" <TAB> ranges = [] <TAB> for begin, end in self.ranges: <MASK> ranges.append(f""{begin}-"" if begin >= 0 else str(begin)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ranges.append(f""{begin}-{end - 1}"") <TAB> return f""{self.units}={','.join(ranges)}""",if end is None :,100
"def name(ent, langpref=""en""): <TAB> try: <TAB>  <TAB> org = ent[""organization""] <TAB> except KeyError: <TAB>  <TAB> return None <TAB> for info in [""organization_display_name"", ""organization_name"", ""organization_url""]: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> for item in org[info]: <MASK> return item[""text""] <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> pass <TAB> return None","if item [ ""lang"" ] == langpref :",112
"def check_url(value): <TAB> validate(text, value) <TAB> parsed = urlparse(value) <TAB> if not parsed.netloc: <TAB>  <TAB> raise ValueError(""'{0}' is not a valid URL"".format(value)) <TAB> for name, schema in attributes.items(): <MASK> raise ValueError(""Invalid URL attribute '{0}'"".format(name)) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> validate(schema, _getattr(parsed, name)) <TAB>  <TAB> except ValueError as err: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Unable to validate URL attribute '{0}': {1}"".format(name, err) <TAB>  <TAB>  <TAB> ) <TAB> return True","if not _hasattr ( parsed , name ) :",158
"def stepStarted(self, step): <TAB> self.currentStep = step <TAB> for w in self.watchers: <TAB>  <TAB> receiver = w.stepStarted(self, step) <MASK> if isinstance(receiver, type(())): <TAB>  <TAB>  <TAB>  <TAB> step.subscribe(receiver[0], receiver[1]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> step.subscribe(receiver) <TAB>  <TAB>  <TAB> d = step.waitUntilFinished() <TAB>  <TAB>  <TAB> # TODO: This actually looks like a bug, but this code <TAB>  <TAB>  <TAB> # will be removed anyway. <TAB>  <TAB>  <TAB> # pylint: disable=cell-var-from-loop <TAB>  <TAB>  <TAB> d.addCallback(lambda step: step.unsubscribe(receiver)) <TAB> step.waitUntilFinished().addCallback(self._stepFinished)",if receiver :,183
"def assert_not_none(obj, msg=None, values=True): <TAB> """"""Fail the test if given object is None."""""" <TAB> _msg = ""is None"" <TAB> if obj is None: <MASK> msg = _msg <TAB>  <TAB> elif values is True: <TAB>  <TAB>  <TAB> msg = ""%s: %s"" % (msg, _msg) <TAB>  <TAB> _report_failure(msg)",if msg is None :,99
"def _parse_date_fmt(): <TAB> fmt = get_format(""DATE_FORMAT"") <TAB> escaped = False <TAB> for char in fmt: <TAB>  <TAB> if escaped: <TAB>  <TAB>  <TAB> escaped = False <MASK> escaped = True <TAB>  <TAB> elif char in ""Yy"": <TAB>  <TAB>  <TAB> yield ""year"" <TAB>  <TAB> elif char in ""bEFMmNn"": <TAB>  <TAB>  <TAB> yield ""month"" <TAB>  <TAB> elif char in ""dj"": <TAB>  <TAB>  <TAB> yield ""day""","elif char == ""\\"" :",117
"def GetPluginClass(self): <TAB> if self.plugin_name: <TAB>  <TAB> plugin_cls = registry.OutputPluginRegistry.PluginClassByName(self.plugin_name) <MASK> logging.warning(""Unknown output plugin %s"", self.plugin_name) <TAB>  <TAB>  <TAB> return registry.OutputPluginRegistry.PluginClassByName( <TAB>  <TAB>  <TAB>  <TAB> ""UnknownOutputPlugin"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return plugin_cls",if plugin_cls is None :,109
"def command(self): <TAB> config = self.session.config <TAB> unregister = False <TAB> self.session.ui.notify(_(""Watching logs: Press CTRL-C to return to the CLI"")) <TAB> try: <TAB>  <TAB> while not mailpile.util.QUITTING and not config.event_log: <TAB>  <TAB>  <TAB> time.sleep(1) <TAB>  <TAB> unregister = config.event_log and config.event_log.ui_watch(self.session.ui) <TAB>  <TAB> self.session.ui.unblock(force=True) <TAB>  <TAB> while not mailpile.util.QUITTING: <TAB>  <TAB>  <TAB> time.sleep(1) <TAB> except KeyboardInterrupt: <TAB>  <TAB> pass <TAB> finally: <MASK> config.event_log.ui_unwatch(self.session.ui) <TAB> return self._success(_(""That was fun!""))",if unregister :,197
"def delete_rule(self, arn): <TAB> for load_balancer_arn in self.load_balancers: <TAB>  <TAB> listeners = self.load_balancers.get(load_balancer_arn).listeners.values() <TAB>  <TAB> for listener in listeners: <TAB>  <TAB>  <TAB> for rule in listener.rules: <MASK> listener.remove_rule(rule) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return",if rule . arn == arn :,104
"def __dragBegin(self, widget, event): <TAB> if event.buttons & (event.Buttons.Left | event.Buttons.Middle): <TAB>  <TAB> GafferUI.Pointer.setCurrent(""nodes"") <MASK> return next(iter(self.__graphComponents)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return Gaffer.StandardSet(self.__graphComponents) <TAB> return None",if len ( self . __graphComponents ) == 1 :,103
"def _get_strategy_name(self): <TAB> frame = sys._getframe() <TAB> while frame: <TAB>  <TAB> st = frame.f_locals.get(""self"") <MASK> return ""%s.%s"" % (type(st).__module__, type(st).__name__) <TAB>  <TAB> frame = frame.f_back <TAB> return """"","if isinstance ( st , StrategyBase ) :",88
"def getCommitFromFile(short=True): <TAB> global _gitdir <TAB> branch = getBranchFromFile() <TAB> commit = None <TAB> if _gitdir and branch: <TAB>  <TAB> if branch == ""HEAD"": <TAB>  <TAB>  <TAB> commitFile = os.path.join(_gitdir, ""HEAD"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> commitFile = os.path.join(_gitdir, ""refs"", ""heads"", branch) <MASK> with open(commitFile, ""r"", encoding=""utf-8"") as f: <TAB>  <TAB>  <TAB>  <TAB> commit = f.readline().strip() <TAB> if short and commit: <TAB>  <TAB> return commit[:8] <TAB> else: <TAB>  <TAB> return commit",if os . path . isfile ( commitFile ) :,169
"def _register_aliases_from_pack(self, pack, aliases): <TAB> registered_count = 0 <TAB> for alias in aliases: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> LOG.debug(""Loading alias from %s."", alias) <TAB>  <TAB>  <TAB> self._register_action_alias(pack, alias) <TAB>  <TAB> except Exception as e: <MASK> msg = 'Failed to register alias ""%s"" from pack ""%s"": %s' % ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> alias, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pack, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> str(e), <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(msg) <TAB>  <TAB>  <TAB> LOG.exception(""Unable to register alias: %s"", alias) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> registered_count += 1 <TAB> return registered_count",if self . _fail_on_failure :,199
"def pop_many(self, limit=None): <TAB> if limit is None: <TAB>  <TAB> limit = DEFAULT_SYNC_OFFLINE_ACTIVITY <TAB> heartbeats = [] <TAB> count = 0 <TAB> while count < limit: <TAB>  <TAB> heartbeat = self.pop() <MASK> break <TAB>  <TAB> heartbeats.append(heartbeat) <TAB>  <TAB> count += 1 <TAB>  <TAB> if count % HEARTBEATS_PER_REQUEST == 0: <TAB>  <TAB>  <TAB> yield heartbeats <TAB>  <TAB>  <TAB> heartbeats = [] <TAB> if heartbeats: <TAB>  <TAB> yield heartbeats",if not heartbeat :,140
"def makeChunkVertices(self, chunk): <TAB> if ( <TAB>  <TAB> chunk.root_tag <TAB>  <TAB> and ""Level"" in chunk.root_tag <TAB>  <TAB> and ""TileTicks"" in chunk.root_tag[""Level""] <TAB> ): <TAB>  <TAB> ticks = chunk.root_tag[""Level""][""TileTicks""] <MASK> self.vertexArrays.append( <TAB>  <TAB>  <TAB>  <TAB> self._computeVertices( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> [[t[i].value for i in ""xyz""] for t in ticks], <TAB>  <TAB>  <TAB>  <TAB>  <TAB> (0xFF, 0xFF, 0xFF, 0x44), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> chunkPosition=chunk.chunkPosition, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> yield",if len ( ticks ) :,175
"def read_bytes_from_url(url: str, optional=False) -> bytes: <TAB> if parse_args().print_commands: <TAB>  <TAB> print_stderr(color_line(""=> "", 14) + f""GET {url}"") <TAB> req = request.Request(url) <TAB> try: <TAB>  <TAB> response = request.urlopen(req) <TAB> except URLError as exc: <TAB>  <TAB> print_error(""urllib: "" + str(exc.reason)) <MASK> return b"""" <TAB>  <TAB> if ask_to_continue(_(""Do you want to retry?"")): <TAB>  <TAB>  <TAB> return read_bytes_from_url(url, optional=optional) <TAB>  <TAB> raise SysExit(102) <TAB> result_bytes = response.read() <TAB> return result_bytes",if optional :,178
"def h2i(self, pkt, x): <TAB> if x is not None: <TAB>  <TAB> if x <= -180.00000005: <TAB>  <TAB>  <TAB> warning(""Fixed3_7: Input value too negative: %.8f"" % x) <TAB>  <TAB>  <TAB> x = -180.0 <MASK> warning(""Fixed3_7: Input value too positive: %.8f"" % x) <TAB>  <TAB>  <TAB> x = 180.0 <TAB>  <TAB> x = int(round((x + 180.0) * 1e7)) <TAB> return x",elif x >= 180.00000005 :,132
"def replace_incompatible_files(): <TAB> for filename, version_info in PYTHON_VERSION_REQUIREMENTS.items(): <MASK> continue <TAB>  <TAB> version = ""."".join(str(v) for v in version_info) <TAB>  <TAB> code = INCOMPATIBLE_PYTHON_VERSION_PLACEHOLDER.format(version=version) <TAB>  <TAB> with open(filename, ""w"") as f: <TAB>  <TAB>  <TAB> f.write(code)",if sys . version_info >= version_info :,110
"def __eq__(self, other): <TAB> if self.__class__ != other.__class__: <TAB>  <TAB> return False <TAB> for attr in [""bar"", ""baz"", ""quux""]: <MASK> return False <TAB>  <TAB> elif getattr(self, attr, None) != getattr(other, attr, None): <TAB>  <TAB>  <TAB> return False <TAB> return True","if hasattr ( self , attr ) != hasattr ( other , attr ) :",95
"def get_content_length(download): <TAB> try: <TAB>  <TAB> meta = download.info() <TAB>  <TAB> if hasattr(meta, ""getheaders"") and hasattr(meta.getheaders, ""Content-Length""): <TAB>  <TAB>  <TAB> return int(meta.getheaders(""Content-Length"")[0]) <TAB>  <TAB> elif hasattr(download, ""getheader"") and download.getheader(""Content-Length""): <TAB>  <TAB>  <TAB> return int(download.getheader(""Content-Length"")) <MASK> return int(meta.getheader(""Content-Length"")) <TAB> except Exception: <TAB>  <TAB> pass <TAB> return 0","elif hasattr ( meta , ""getheader"" ) and meta . getheader ( ""Content-Length"" ) :",149
"def set_size(self, size): <TAB> assert len(size) == 2 <TAB> width, height = size <TAB> if width == -1: <TAB>  <TAB> for button in self._buttons_list: <TAB>  <TAB>  <TAB> cur_width = button.GetSize()[self.WIDTH] <MASK> width = cur_width <TAB> if height == -1: <TAB>  <TAB> for button in self._buttons_list: <TAB>  <TAB>  <TAB> cur_height = button.GetSize()[self.HEIGHT] <TAB>  <TAB>  <TAB> if cur_height > height: <TAB>  <TAB>  <TAB>  <TAB> height = cur_height <TAB> if self._squared: <TAB>  <TAB> width = height = width if width > height else height <TAB> for button in self._buttons_list: <TAB>  <TAB> button.SetMinSize((width, height))",if cur_width > width :,187
"def _default_config(self): <TAB> if sys.platform.startswith(""win""): <TAB>  <TAB> return {""name"": ""Command Prompt"", ""cmd"": ""cmd.exe"", ""env"": {}} <TAB> else: <TAB>  <TAB> if ""SHELL"" in os.environ: <TAB>  <TAB>  <TAB> shell = os.environ[""SHELL""] <MASK> cmd = [shell, ""-l""] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> cmd = [shell, ""-i"", ""-l""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> cmd = [""/bin/bash"", ""-i"", ""-l""] <TAB>  <TAB> return {""name"": ""Login Shell"", ""cmd"": cmd, ""env"": {}}","if os . path . basename ( shell ) == ""tcsh"" :",170
"def log_sock(s, event_type=None): <TAB> if sock_silent: <TAB>  <TAB> pass <TAB> else: <TAB>  <TAB> if event_type is None: <TAB>  <TAB>  <TAB> logsocket.sendto(ensure_str(s), (host, port)) <MASK> logsocket.sendto(ensure_str(s), (host, port)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pass",elif event_type in show_event :,103
"def check_eventref_citations(self, obj): <TAB> if obj: <TAB>  <TAB> for event_ref in obj.get_event_ref_list(): <MASK> return True <TAB>  <TAB>  <TAB> event = self.dbstate.db.get_event_from_handle(event_ref.ref) <TAB>  <TAB>  <TAB> if self.check_event_citations(event): <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if self . check_attribute_citations ( event_ref ) :,116
"def __exit__(self, exc_type, exc_value, traceback): <TAB> self.nest -= 1 <TAB> if self.nest == 0: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.con.__exit__(exc_type, exc_value, traceback) <TAB>  <TAB>  <TAB> self.close() <TAB>  <TAB> except Exception as exc: <MASK> self.debug.write(""EXCEPTION from __exit__: {}"".format(exc)) <TAB>  <TAB>  <TAB> raise",if self . debug :,109
"def construct_instances(self, row, keys=None): <TAB> collected_models = {} <TAB> for i, (key, constructor, attr, conv) in enumerate(self.column_map): <TAB>  <TAB> if keys is not None and key not in keys: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> value = row[i] <MASK> collected_models[key] = constructor() <TAB>  <TAB> instance = collected_models[key] <TAB>  <TAB> if attr is None: <TAB>  <TAB>  <TAB> attr = self.cursor.description[i][0] <TAB>  <TAB> if conv is not None: <TAB>  <TAB>  <TAB> value = conv(value) <TAB>  <TAB> setattr(instance, attr, value) <TAB> return collected_models",if key not in collected_models :,167
"def delete(self): <TAB> """"""Completely shut down pulseaudio client."""""" <TAB> if self._pa_context is not None: <TAB>  <TAB> assert _debug(""PulseAudioContext.delete"") <MASK> pa.pa_context_disconnect(self._pa_context) <TAB>  <TAB>  <TAB> while self.state is not None and not self.is_terminated: <TAB>  <TAB>  <TAB>  <TAB> self.wait() <TAB>  <TAB> self._disconnect_callbacks() <TAB>  <TAB> pa.pa_context_unref(self._pa_context) <TAB>  <TAB> self._pa_context = None",if self . is_ready :,136
"def _hstack(self, other, prefix=None): <TAB> """"""Join the columns of the other DataFrame to this one, assuming the ordering is the same"""""" <TAB> assert len(self) == len( <TAB>  <TAB> other <TAB> ), ""does not make sense to horizontally stack DataFrames with different lengths"" <TAB> for name in other.get_column_names(): <MASK> new_name = prefix + name <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_name = name <TAB>  <TAB> self.add_column(new_name, other.columns[name])",if prefix :,127
"def smart_linkflags(source, target, env, for_signature): <TAB> if cplusplus.iscplusplus(source): <TAB>  <TAB> build_dir = env.subst(""$BUILDDIR"", target=target, source=source) <MASK> return ""-qtempinc="" + os.path.join(build_dir, ""tempinc"") <TAB> return """"",if build_dir :,91
"def read(self, size): <TAB> x = len(self.buf) <TAB> while x < size: <TAB>  <TAB> raw = self.fileobj.read(self.blocksize) <MASK> break <TAB>  <TAB> data = self.bz2obj.decompress(raw) <TAB>  <TAB> self.buf += data <TAB>  <TAB> x += len(data) <TAB> buf = self.buf[:size] <TAB> self.buf = self.buf[size:] <TAB> self.pos += len(buf) <TAB> return buf",if not raw :,120
"def set_ok_verifiability(self, cookie, request): <TAB> if request.unverifiable and is_third_party(request): <TAB>  <TAB> if cookie.version > 0 and self.strict_rfc2965_unverifiable: <TAB>  <TAB>  <TAB> _debug(""   third-party RFC 2965 cookie during "" ""unverifiable transaction"") <TAB>  <TAB>  <TAB> return False <MASK> _debug(""   third-party Netscape cookie during "" ""unverifiable transaction"") <TAB>  <TAB>  <TAB> return False <TAB> return True",elif cookie . version == 0 and self . strict_ns_unverifiable :,138
"def update_sockets(self, context): <TAB> bools = [self.min_list, self.max_list, self.size_list] <TAB> dims = int(self.dimensions[0]) <TAB> for i in range(3): <TAB>  <TAB> for j in range(3): <TAB>  <TAB>  <TAB> out_index = 4 + j + 3 * i <TAB>  <TAB>  <TAB> hidden = self.outputs[out_index].hide_safe <MASK> if hidden: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.outputs[out_index].hide_safe = False <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.outputs[out_index].hide_safe = True <TAB>  <TAB> updateNode(self, context)",if bools [ i ] [ j ] and j < dims :,173
"def hash_of_file(path): <TAB> """"""Return the hash of a downloaded file."""""" <TAB> with open(path, ""r"") as archive: <TAB>  <TAB> sha = sha256() <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> data = archive.read(2 ** 20) <MASK> break <TAB>  <TAB>  <TAB> sha.update(data) <TAB> return encoded_hash(sha)",if not data :,95
"def _compute_early_outs(self, quotas): <TAB> for q in quotas: <TAB>  <TAB> if q.closed and not self._ignore_closed: <TAB>  <TAB>  <TAB> self.results[q] = Quota.AVAILABILITY_ORDERED, 0 <TAB>  <TAB> elif q.size is None: <TAB>  <TAB>  <TAB> self.results[q] = Quota.AVAILABILITY_OK, None <MASK> self.results[q] = Quota.AVAILABILITY_GONE, 0",elif q . size == 0 :,118
"def providers_for_config_string(config_string, netcode): <TAB> providers = [] <TAB> for d in config_string.split(): <TAB>  <TAB> p = provider_for_descriptor_and_netcode(d, netcode) <MASK> providers.append(p) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> warnings.warn(""can't parse provider %s in config string"" % d) <TAB> return providers",if p :,100
"def _get_plugin_value(self, feature, actor): <TAB> for plugin in plugins.all(version=2): <TAB>  <TAB> handlers = safe_execute(plugin.get_feature_hooks, _with_transaction=False) <TAB>  <TAB> for handler in handlers or (): <TAB>  <TAB>  <TAB> rv = handler(feature, actor) <MASK> return rv <TAB> return None",if rv is not None :,94
"def test_digit_numeric_consistent(self): <TAB> # Test that digit and numeric are consistent, <TAB> # i.e. if a character has a digit value, <TAB> # its numeric value should be the same. <TAB> count = 0 <TAB> for i in xrange(0x10000): <TAB>  <TAB> c = unichr(i) <TAB>  <TAB> dec = self.db.digit(c, -1) <MASK> self.assertEqual(dec, self.db.numeric(c)) <TAB>  <TAB>  <TAB> count += 1 <TAB> self.assertTrue(count >= 10)  # should have tested at least the ASCII digits",if dec != - 1 :,144
"def call(command, title, retry): <TAB> """"""Run a command-line program and display the result."""""" <TAB> if Options.rerun_args: <TAB>  <TAB> command, title, retry = Options.rerun_args <TAB>  <TAB> Options.rerun_args = None <TAB>  <TAB> success = call(command, title, retry) <MASK> return False <TAB> print("""") <TAB> print(""$ %s"" % "" "".join(command)) <TAB> failure = subprocess.call(command) <TAB> if failure and retry: <TAB>  <TAB> Options.rerun_args = command, title, retry <TAB> return not failure",if not success :,141
"def handle_custom_actions(self): <TAB> for _, action in CustomAction.registry.items(): <MASK> continue <TAB>  <TAB> if action.action not in self.parser.choices: <TAB>  <TAB>  <TAB> self.parser.add_parser(action.action, help="""") <TAB>  <TAB> action(self.page).add_arguments(self.parser, self)",if action . resource != self . resource :,92
"def __init__(self, user, *args, **kwargs): <TAB> self.user = user <TAB> super(AccountSettingsForm, self).__init__(*args, **kwargs) <TAB> if self.user.is_managed: <TAB>  <TAB> # username and password always managed, email and <TAB>  <TAB> # name optionally managed <TAB>  <TAB> for field in (""email"", ""name"", ""username""): <MASK> self.fields[field] = ReadOnlyTextField(label=self.fields[field].label) <TAB>  <TAB> # don't show password field at all <TAB>  <TAB> del self.fields[""new_password""] <TAB> # don't show username field if its the same as their email address <TAB> if self.user.email == self.user.username: <TAB>  <TAB> del self.fields[""username""]","if field == ""username"" or field in settings . SENTRY_MANAGED_USER_FIELDS :",199
"def eval(self, code, eval=True, raw=False): <TAB> self._engine._append_source(code) <TAB> try: <TAB>  <TAB> result = self._context.eval(code) <TAB> except quickjs.JSException as e: <TAB>  <TAB> raise ProgramError(*e.args) <TAB> else: <MASK> if raw or not isinstance(result, quickjs.Object): <TAB>  <TAB>  <TAB>  <TAB> return result <TAB>  <TAB>  <TAB> elif callable(result) and self.typeof(result) == u""function"": <TAB>  <TAB>  <TAB>  <TAB> return self.Function(self, result) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return json.loads(result.json())",if eval :,158
"def get_def_offsets(self, defloc): <TAB> """"""Get the byte offsets for a definition."""""" <TAB> defn = self.defs[defloc.def_id] <TAB> typ = defn.typ <TAB> if typ == ""Attribute"": <TAB>  <TAB> start, end = self._get_attr_bounds(defn.name, defloc.location) <TAB> else: <TAB>  <TAB> start = self.source.get_offset(defloc.location) <MASK> start += DEF_OFFSETS[typ] <TAB>  <TAB> end = start + len(defn.name) <TAB> return (start, end)",if typ in DEF_OFFSETS :,147
"def RemoveRefCountOutput(data): <TAB> while 1: <TAB>  <TAB> last_line_pos = data.rfind(""\n"") <TAB>  <TAB> if not re.match(""\[\d+ refs\]"", data[last_line_pos + 1 :]): <TAB>  <TAB>  <TAB> break <MASK> # All the output <TAB>  <TAB>  <TAB> return """" <TAB>  <TAB> data = data[:last_line_pos] <TAB> return data",if last_line_pos < 0 :,103
"def traverse_before_reduce(operator): <TAB> """"""Internal traverse function"""""" <TAB> if isinstance(operator, tvm.te.PlaceholderOp): <TAB>  <TAB> return <TAB> if tag.is_injective(operator.tag): <TAB>  <TAB> sch[operator].compute_inline() <TAB>  <TAB> for tensor in operator.input_tensors: <MASK> traverse_before_reduce(tensor.op) <TAB> else: <TAB>  <TAB> raise RuntimeError(""Unsupported operator: %s"" % operator.tag) <TAB> scheduled_ops.append(operator)",if tensor . op not in scheduled_ops :,133
"def _get_config(key): <TAB> config = db.session.execute( <TAB>  <TAB> Configs.__table__.select().where(Configs.key == key) <TAB> ).fetchone() <TAB> if config and config.value: <TAB>  <TAB> value = config.value <TAB>  <TAB> if value and value.isdigit(): <TAB>  <TAB>  <TAB> return int(value) <TAB>  <TAB> elif value and isinstance(value, string_types): <MASK> return True <TAB>  <TAB>  <TAB> elif value.lower() == ""false"": <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return value <TAB> # Flask-Caching is unable to roundtrip a value of None. <TAB> # Return an exception so that we can still cache and avoid the db hit <TAB> return KeyError","if value . lower ( ) == ""true"" :",181
"def find_executable(names): <TAB> # Given a list of executable names, find the first one that is available <TAB> # as an executable file, on the path. <TAB> for name in names: <TAB>  <TAB> fpath, fname = os.path.split(name) <TAB>  <TAB> if fpath: <TAB>  <TAB>  <TAB> # The given name is absolute. <MASK> return name <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Try to find the name on the PATH <TAB>  <TAB>  <TAB> for path in os.environ[""PATH""].split(os.pathsep): <TAB>  <TAB>  <TAB>  <TAB> exe_file = os.path.join(path, name) <TAB>  <TAB>  <TAB>  <TAB> if is_executable(exe_file): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return exe_file <TAB> # Could not find it :( <TAB> return None",if is_executable ( name ) :,186
"def push(self): <TAB> advice = self.check() <TAB> if not self._context[""silent""]: <MASK> print(""No changes to push."") <TAB>  <TAB>  <TAB> return <TAB>  <TAB> choice = input(""Continue? y/N:"") <TAB>  <TAB> if choice != ""y"": <TAB>  <TAB>  <TAB> print(""Aborted on user command"") <TAB>  <TAB>  <TAB> return <TAB> print(""push local changes to remote..."") <TAB> self._publish.syncRemote(self._context[""srcroot""], advice)",if not self . hasPendingSync ( advice ) :,123
"def __init__(self, itemtype, cnf={}, *, master=None, **kw): <TAB> if not master: <MASK> master = kw[""refwindow""] <TAB>  <TAB> elif ""refwindow"" in cnf: <TAB>  <TAB>  <TAB> master = cnf[""refwindow""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> master = tkinter._default_root <TAB>  <TAB>  <TAB> if not master: <TAB>  <TAB>  <TAB>  <TAB> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Too early to create display style: "" ""no root window"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> self.tk = master.tk <TAB> self.stylename = self.tk.call(""tixDisplayStyle"", itemtype, *self._options(cnf, kw))","if ""refwindow"" in kw :",167
"def __call__(self, x, **kwargs): <TAB> h = x <TAB> for layer, argnames, accept_var_args in zip( <TAB>  <TAB> self.layers, self.argnames, self.accept_var_args <TAB> ): <MASK> layer_kwargs = kwargs <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> layer_kwargs = {k: v for k, v in kwargs.items() if k in argnames} <TAB>  <TAB> h = layer(h, **layer_kwargs) <TAB> return h",if accept_var_args :,121
def run_train_loop(self): <TAB> self.begin_training() <TAB> for _ in self.yield_train_step(): <TAB>  <TAB> if self.should_save_model(): <TAB>  <TAB>  <TAB> self.save_model() <MASK> self.save_checkpoint() <TAB>  <TAB> if self.should_eval_model(): <TAB>  <TAB>  <TAB> self.eval_model() <TAB>  <TAB> if self.should_break_training(): <TAB>  <TAB>  <TAB> break <TAB> self.eval_model() <TAB> self.done_training() <TAB> return self.returned_result(),if self . should_save_checkpoint ( ) :,139
"def configure_callback(conf): <TAB> """"""Received configuration information"""""" <TAB> global ZK_HOSTS <TAB> for node in conf.children: <MASK> ZK_HOSTS = node.values[0].split("","") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> collectd.warning(""zookeeper plugin: Unknown config key: %s."" % node.key) <TAB> log(""Configured with hosts=%s"" % (ZK_HOSTS))","if node . key == ""Hosts"" :",108
"def inner(self, *args, **kwargs): <TAB> """"""Inner."""""" <TAB> if not is_internet_available(): <TAB>  <TAB> LOGGER.debug(""\n\n%s"", func.__name__) <TAB>  <TAB> LOGGER.debug(""============================"") <MASK> LOGGER.debug('"""""" %s """"""', func.__doc__.strip()) <TAB>  <TAB> LOGGER.debug(""----------------------------"") <TAB>  <TAB> LOGGER.debug(""Skipping because no Internet connection available."") <TAB>  <TAB> LOGGER.debug(""\n++++++++++++++++++++++++++++"") <TAB>  <TAB> return None <TAB> result = func(self, *args, **kwargs) <TAB> return result",if func . __doc__ :,155
"def _shares_in_results(data): <TAB> shares_in_device, shares_in_subdevice = False, False <TAB> for plugin_name, plugin_result in data.iteritems(): <TAB>  <TAB> if plugin_result[""status""] == ""error"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if ""device"" not in plugin_result: <TAB>  <TAB>  <TAB> continue <MASK> shares_in_device = True <TAB>  <TAB> for subdevice in plugin_result[""device""].get(""subdevices"", []): <TAB>  <TAB>  <TAB> if ""disk_shares"" in subdevice: <TAB>  <TAB>  <TAB>  <TAB> shares_in_subdevice = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return shares_in_device, shares_in_subdevice","if ""disk_shares"" in plugin_result [ ""device"" ] :",175
"def register_auth_provider_blueprints(cls, app, prefix=""/auth/login""): <TAB> app.auth_providers = [] <TAB> for provider in app.config.get(""AUTH_PROVIDERS"", [""debug"", ""oauth""]): <MASK> provider = cls._get_subclass_for(provider.lower())(name=provider, app=app) <TAB>  <TAB> app.register_blueprint( <TAB>  <TAB>  <TAB> provider.blueprint, url_prefix=""/"".join((prefix, provider.name)) <TAB>  <TAB> ) <TAB>  <TAB> app.auth_providers.append(provider)","if not isinstance ( provider , KnowledgeAuthProvider ) :",144
"def getText(self, stuff): <TAB> if isinstance(stuff, Fighter): <TAB>  <TAB> active = [x.name for x in stuff.abilities if x.active] <MASK> return ""None"" <TAB>  <TAB> return "", "".join(active)",if len ( active ) == 0 :,69
"def run(self, paths=[]): <TAB> items = [] <TAB> for item in SideBarSelection(paths).getSelectedItems(): <TAB>  <TAB> if item.isUnderCurrentProject(): <TAB>  <TAB>  <TAB> items.append(item.url(""url_production"")) <TAB> if len(items) > 0: <TAB>  <TAB> sublime.set_clipboard(""\n"".join(items)) <MASK> sublime.status_message(""Items URL copied"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sublime.status_message(""Item URL copied"")",if len ( items ) > 1 :,131
"def read_boolean(file: BinaryIO, count: int, checkall: bool = False) -> List[bool]: <TAB> if checkall: <TAB>  <TAB> all_defined = file.read(1) <TAB>  <TAB> if all_defined != unhexlify(""00""): <TAB>  <TAB>  <TAB> return [True] * count <TAB> result = [] <TAB> b = 0 <TAB> mask = 0 <TAB> for i in range(count): <MASK> b = ord(file.read(1)) <TAB>  <TAB>  <TAB> mask = 0x80 <TAB>  <TAB> result.append(b & mask != 0) <TAB>  <TAB> mask >>= 1 <TAB> return result",if mask == 0 :,146
"def __prep_write_total(self, comments, main, fallback, single): <TAB> lower = self.as_lowercased() <TAB> for k in [main, fallback, single]: <TAB>  <TAB> if k in comments: <TAB>  <TAB>  <TAB> del comments[k] <TAB> if single in lower: <TAB>  <TAB> parts = lower[single].split(""/"", 1) <TAB>  <TAB> if parts[0]: <TAB>  <TAB>  <TAB> comments[single] = [parts[0]] <TAB>  <TAB> if len(parts) > 1: <TAB>  <TAB>  <TAB> comments[main] = [parts[1]] <TAB> if main in lower: <TAB>  <TAB> comments[main] = lower.list(main) <TAB> if fallback in lower: <MASK> comments[fallback] = lower.list(fallback) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> comments[main] = lower.list(fallback)",if main in comments :,196
"def _filter_medias_not_commented(self, media_items): <TAB> not_commented_medias = [] <TAB> for media in media_items: <TAB>  <TAB> if media.get(""comment_count"", 0) > 0 and media.get(""comments""): <TAB>  <TAB>  <TAB> my_comments = [ <TAB>  <TAB>  <TAB>  <TAB> comment <TAB>  <TAB>  <TAB>  <TAB> for comment in media[""comments""] <MASK> ] <TAB>  <TAB>  <TAB> if my_comments: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> not_commented_medias.append(media) <TAB> return not_commented_medias","if comment [ ""user_id"" ] == self . user_id",152
"def run(url): <TAB> import os <TAB> for fpath in [ <TAB>  <TAB> os.path.expanduser(""~/Applications/zeal.app""), <TAB>  <TAB> ""/Applications/zeal.app"", <TAB> ]: <MASK> import subprocess, pipes <TAB>  <TAB>  <TAB> pid = subprocess.Popen( <TAB>  <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> fpath + ""/Contents/MacOS/zeal"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""--query={0}"".format(pipes.quote(url)), <TAB>  <TAB>  <TAB>  <TAB> ], <TAB>  <TAB>  <TAB>  <TAB> stdout=subprocess.PIPE, <TAB>  <TAB>  <TAB>  <TAB> stderr=subprocess.PIPE, <TAB>  <TAB>  <TAB>  <TAB> stdin=subprocess.PIPE, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return","if os . path . exists ( fpath + ""/Contents/MacOS/zeal"" ) :",176
"def get_input_info(exec_info, network): <TAB> input_dict = collections.OrderedDict() <TAB> for v in exec_info.data_variable: <TAB>  <TAB> input_dict[v.variable_name] = [] <TAB> for v in network.variable: <MASK> shape = v.shape.dim <TAB>  <TAB>  <TAB> input_dict[v.name] = [x if x > 0 else batch_size for x in shape] <TAB> return input_dict",if v . name in input_dict :,118
"def _clean_text(self, text): <TAB> """"""Performs invalid character removal and whitespace cleanup on text."""""" <TAB> output = [] <TAB> char_idx = [] <TAB> for i, char in enumerate(text): <TAB>  <TAB> cp = ord(char) <TAB>  <TAB> if cp == 0 or cp == 0xFFFD or _is_control(char): <TAB>  <TAB>  <TAB> continue <MASK> output.append("" "") <TAB>  <TAB>  <TAB> char_idx.append(i) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> output.append(char) <TAB>  <TAB>  <TAB> char_idx.append(i) <TAB> return """".join(output), char_idx",if _is_whitespace ( char ) :,151
"def AddVersion(version, ns, versionId="""", isLegacy=0, serviceNs=""""): <TAB> if not ns: <TAB>  <TAB> ns = serviceNs <TAB> if version not in parentMap: <TAB>  <TAB> nsMap[version] = ns <TAB>  <TAB> if len(versionId) > 0: <TAB>  <TAB>  <TAB> versionMap[ns + ""/"" + versionId] = version <MASK> versionMap[ns] = version <TAB>  <TAB> versionIdMap[version] = versionId <TAB>  <TAB> if not serviceNs: <TAB>  <TAB>  <TAB> serviceNs = ns <TAB>  <TAB> serviceNsMap[version] = serviceNs <TAB>  <TAB> parentMap[version] = set()","if isLegacy or ns is """" :",150
"def set_accessible_async(self, trans, id=None, accessible=False): <TAB> """"""Set workflow's importable attribute and slug."""""" <TAB> stored = self.get_stored_workflow(trans, id) <TAB> # Only set if importable value would change; this prevents a change in the update_time unless attribute really changed. <TAB> importable = accessible in [""True"", ""true"", ""t"", ""T""] <TAB> if stored and stored.importable != importable: <MASK> self._make_item_accessible(trans.sa_session, stored) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> stored.importable = importable <TAB>  <TAB> trans.sa_session.flush() <TAB> return",if importable :,158
"def update(self, val, n=1): <TAB> if val is not None: <TAB>  <TAB> self.val = val <MASK> self.sum = type_as(self.sum, val) + (val * n) <TAB>  <TAB>  <TAB> self.count = type_as(self.count, n) + n",if n > 0 :,80
"def run(self, root): <TAB> footnotesDiv = self.footnotes.makeFootnotesDiv(root) <TAB> if footnotesDiv is not None: <TAB>  <TAB> result = self.footnotes.findFootnotesPlaceholder(root) <MASK> child, parent, isText = result <TAB>  <TAB>  <TAB> ind = list(parent).index(child) <TAB>  <TAB>  <TAB> if isText: <TAB>  <TAB>  <TAB>  <TAB> parent.remove(child) <TAB>  <TAB>  <TAB>  <TAB> parent.insert(ind, footnotesDiv) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> parent.insert(ind + 1, footnotesDiv) <TAB>  <TAB>  <TAB>  <TAB> child.tail = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> root.append(footnotesDiv)",if result :,175
def ehp(self): <TAB> if self.__ehp is None: <MASK> ehp = self.hp <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ehp = self.damagePattern.calculateEhp(self) <TAB>  <TAB> self.__ehp = ehp <TAB> return self.__ehp,if self . damagePattern is None :,80
"def literal(self): <TAB> if self.peek('""'): <TAB>  <TAB> lit, lang, dtype = self.eat(r_literal).groups() <TAB>  <TAB> if lang: <TAB>  <TAB>  <TAB> lang = lang <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lang = None <MASK> dtype = dtype <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> dtype = None <TAB>  <TAB> if lang and dtype: <TAB>  <TAB>  <TAB> raise ParseError(""Can't have both a language and a datatype"") <TAB>  <TAB> lit = unquote(lit) <TAB>  <TAB> return Literal(lit, lang, dtype) <TAB> return False",if dtype :,132
"def _purge(self, queue): <TAB> """"""Remove all messages from `queue`."""""" <TAB> count = 0 <TAB> queue_find = ""."" + queue + "".msg"" <TAB> folder = os.listdir(self.data_folder_in) <TAB> while len(folder) > 0: <TAB>  <TAB> filename = folder.pop() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> # only purge messages for the requested queue <MASK> continue <TAB>  <TAB>  <TAB> filename = os.path.join(self.data_folder_in, filename) <TAB>  <TAB>  <TAB> os.remove(filename) <TAB>  <TAB>  <TAB> count += 1 <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> # we simply ignore its existence, as it was probably <TAB>  <TAB>  <TAB> # processed by another worker <TAB>  <TAB>  <TAB> pass <TAB> return count",if filename . find ( queue_find ) < 0 :,189
"def check(data_dir, decrypter, read_only=False): <TAB> fname = os.path.join(data_dir, DIGEST_NAME) <TAB> if os.path.exists(fname): <TAB>  <TAB> if decrypter is None: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> f = open(fname, ""rb"") <TAB>  <TAB> s = f.read() <TAB>  <TAB> f.close() <TAB>  <TAB> return decrypter.decrypt(s) == MAGIC_STRING <TAB> else: <MASK> if read_only: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> s = decrypter.encrypt(MAGIC_STRING) <TAB>  <TAB>  <TAB>  <TAB> f = open(fname, ""wb"") <TAB>  <TAB>  <TAB>  <TAB> f.write(s) <TAB>  <TAB>  <TAB>  <TAB> f.close() <TAB>  <TAB> return True",if decrypter is not None :,198
"def on_train_epoch_end(self, trainer, pl_module, outputs): <TAB> epoch = trainer.current_epoch <TAB> if self.unfreeze_backbone_at_epoch <= epoch: <TAB>  <TAB> optimizer = trainer.optimizers[0] <TAB>  <TAB> current_lr = optimizer.param_groups[0][""lr""] <TAB>  <TAB> backbone_lr = self.previous_backbone_lr <MASK> assert backbone_lr <= current_lr <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert backbone_lr == current_lr",if epoch < 6 :,127
"def parse_rsync_url(location): <TAB> """"""Parse a rsync-style URL."""""" <TAB> if "":"" in location and ""@"" not in location: <TAB>  <TAB> # SSH with no user@, zero or one leading slash. <TAB>  <TAB> (host, path) = location.split("":"", 1) <TAB>  <TAB> user = None <TAB> elif "":"" in location: <TAB>  <TAB> # SSH with user@host:foo. <TAB>  <TAB> user_host, path = location.split("":"", 1) <MASK> user, host = user_host.rsplit(""@"", 1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> user = None <TAB>  <TAB>  <TAB> host = user_host <TAB> else: <TAB>  <TAB> raise ValueError(""not a valid rsync-style URL"") <TAB> return (user, host, path)","if ""@"" in user_host :",178
"def populate_settings_dict(form, settings): <TAB> new_settings = {} <TAB> for key, value in iteritems(settings): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> # check if the value has changed <MASK> continue <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> new_settings[key] = form[key].data <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> pass <TAB> return new_settings",if value == form [ key ] . data :,105
"def draw_boxes(image, boxes, scores=None, drop_score=0.5): <TAB> if scores is None: <TAB>  <TAB> scores = [1] * len(boxes) <TAB> for (box, score) in zip(boxes, scores): <MASK> continue <TAB>  <TAB> box = np.reshape(np.array(box), [-1, 1, 2]).astype(np.int64) <TAB>  <TAB> image = cv2.polylines(np.array(image), [box], True, (255, 0, 0), 2) <TAB> return image",if score < drop_score :,136
"def update(self, instance, validated_data): <TAB> for category, category_data in validated_data.items(): <MASK> continue <TAB>  <TAB> self.update_validated_settings(category_data) <TAB>  <TAB> for field_name, field_value in category_data.items(): <TAB>  <TAB>  <TAB> setattr(getattr(instance, category), field_name, field_value) <TAB> return instance",if not category_data :,98
"def insert(self, menuName, position, label, command, underline=None): <TAB> menu = self.getMenu(menuName) <TAB> if menu: <MASK> menu.insert(position, ""command"", label=label, command=command) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> menu.insert( <TAB>  <TAB>  <TAB>  <TAB> position, ""command"", label=label, command=command, underline=underline <TAB>  <TAB>  <TAB> )",if underline is None :,104
"def delete_old_links(): <TAB> for doc in web.ctx.site.store.values(type=""account-link""): <TAB>  <TAB> expiry_date = datetime.strptime(doc[""expires_on""], ""%Y-%m-%dT%H:%M:%S.%f"") <TAB>  <TAB> now = datetime.utcnow() <TAB>  <TAB> key = doc[""_key""] <MASK> print(""Deleting link %s"" % (key)) <TAB>  <TAB>  <TAB> del web.ctx.site.store[key] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""Retaining link %s"" % (key))",if expiry_date > now :,141
"def _object(o: edgedb.Object): <TAB> ret = {} <TAB> for attr in dir(o): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> link = o[attr] <TAB>  <TAB> except (KeyError, TypeError): <TAB>  <TAB>  <TAB> link = None <MASK> ret[attr] = serialize(link) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret[attr] = serialize(getattr(o, attr)) <TAB> return ret",if link :,102
"def __init__(self, items): <TAB> self._format = string.join(map(lambda item: item[0], items), """") <TAB> self._items = items <TAB> self._buffer_ = win32wnet.NCBBuffer(struct.calcsize(self._format)) <TAB> for format, name in self._items: <TAB>  <TAB> if len(format) == 1: <MASK> val = ""\0"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> val = 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> l = int(format[:-1]) <TAB>  <TAB>  <TAB> val = ""\0"" * l <TAB>  <TAB> self.__dict__[name] = val","if format == ""c"" :",158
"def prepare_text(text, style): <TAB> body = [] <TAB> for fragment, sty in parse_tags(text, style, subs.styles): <TAB>  <TAB> fragment = fragment.replace(r""\h"", "" "") <TAB>  <TAB> fragment = fragment.replace(r""\n"", ""\n"") <TAB>  <TAB> fragment = fragment.replace(r""\N"", ""\n"") <MASK> fragment = ""<i>%s</i>"" % fragment <TAB>  <TAB> if sty.underline: <TAB>  <TAB>  <TAB> fragment = ""<u>%s</u>"" % fragment <TAB>  <TAB> if sty.strikeout: <TAB>  <TAB>  <TAB> fragment = ""<s>%s</s>"" % fragment <TAB>  <TAB> body.append(fragment) <TAB> return re.sub(""\n+"", ""\n"", """".join(body).strip())",if sty . italic :,180
"def get_from_target(target): <TAB> domains = set() <TAB> if isinstance(target, str): <MASK> logger.log(""FATAL"", ""Use targets parameter for multiple domain names"") <TAB>  <TAB>  <TAB> exit(1) <TAB>  <TAB> domain = match_main_domain(target) <TAB>  <TAB> if not domain: <TAB>  <TAB>  <TAB> return domains <TAB>  <TAB> domains.add(domain) <TAB> return domains","if target . endswith ( "".txt"" ) :",101
"def iterate(self, prod_, rule_): <TAB> newProduction = """" <TAB> for i in range(len(prod_)): <TAB>  <TAB> step = self.production[i] <MASK> newProduction = newProduction + self.ruleW <TAB>  <TAB> elif step == ""X"": <TAB>  <TAB>  <TAB> newProduction = newProduction + self.ruleX <TAB>  <TAB> elif step == ""Y"": <TAB>  <TAB>  <TAB> newProduction = newProduction + self.ruleY <TAB>  <TAB> elif step == ""Z"": <TAB>  <TAB>  <TAB> newProduction = newProduction + self.ruleZ <TAB>  <TAB> elif step != ""F"": <TAB>  <TAB>  <TAB> newProduction = newProduction + step <TAB> self.drawLength = self.drawLength * 0.5 <TAB> self.generations += 1 <TAB> return newProduction","if step == ""W"" :",179
"def cancel_pp(self, nzo_id): <TAB> """"""Change the status, so that the PP is canceled"""""" <TAB> for nzo in self.history_queue: <MASK> nzo.abort_direct_unpacker() <TAB>  <TAB>  <TAB> if nzo.pp_active: <TAB>  <TAB>  <TAB>  <TAB> nzo.pp_active = False <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # Try to kill any external running process <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.external_process.kill() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> logging.info( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Killed external process %s"", self.external_process.args[0] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> return True <TAB> return None",if nzo . nzo_id == nzo_id :,196
"def list_backends(debug): <TAB> for backend in sorted( <TAB>  <TAB> backends.getBackendList(), key=lambda backend: backend.identifier <TAB> ): <MASK> print( <TAB>  <TAB>  <TAB>  <TAB> ""{:>15} : {} ({})"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> backend.identifier, backend.__doc__, backend.__name__ <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""{:>15} : {}"".format(backend.identifier, backend.__doc__))",if debug :,116
"def _geo_indices(cls, inspected=None): <TAB> inspected = inspected or [] <TAB> geo_indices = [] <TAB> inspected.append(cls) <TAB> for field in cls._fields.values(): <MASK> field_cls = field.document_type <TAB>  <TAB>  <TAB> if field_cls in inspected: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if hasattr(field_cls, ""_geo_indices""): <TAB>  <TAB>  <TAB>  <TAB> geo_indices += field_cls._geo_indices(inspected) <TAB>  <TAB> elif field._geo_index: <TAB>  <TAB>  <TAB> geo_indices.append(field) <TAB> return geo_indices","if hasattr ( field , ""document_type"" ) :",155
"def run_test_family(tests, mode_filter, files, open_func, *make_args): <TAB> for test_func in tests: <TAB>  <TAB> if test_func is None: <TAB>  <TAB>  <TAB> out.write(""\n"") <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> for s in test_func.file_sizes: <TAB>  <TAB>  <TAB> name, size = files[size_names[s]] <TAB>  <TAB>  <TAB> # name += file_ext <TAB>  <TAB>  <TAB> args = tuple(f(name, size) for f in make_args) <TAB>  <TAB>  <TAB> run_one_test(name, size, open_func, test_func, *args)",if mode_filter in test_func . file_open_mode :,168
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_application_key(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> self.set_message(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 26: <TAB>  <TAB>  <TAB> self.set_tag(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 18 :,152
"def _on_config_changed(self, option: str) -> None: <TAB> if option in [""zoom.levels"", ""zoom.default""]: <MASK> factor = float(config.val.zoom.default) / 100 <TAB>  <TAB>  <TAB> self.set_factor(factor) <TAB>  <TAB> self._init_neighborlist()",if not self . _default_zoom_changed :,86
"def keyPressEvent(self, event): <TAB> """"""Add up and down arrow key events to built in functionality."""""" <TAB> keyPressed = event.key() <TAB> if keyPressed in [Constants.UP_KEY, Constants.DOWN_KEY, Constants.TAB_KEY]: <TAB>  <TAB> if keyPressed == Constants.UP_KEY: <TAB>  <TAB>  <TAB> self.index = max(0, self.index - 1) <TAB>  <TAB> elif keyPressed == Constants.DOWN_KEY: <TAB>  <TAB>  <TAB> self.index = min(len(self.completerStrings) - 1, self.index + 1) <TAB>  <TAB> elif keyPressed == Constants.TAB_KEY and self.completerStrings: <TAB>  <TAB>  <TAB> self.tabPressed() <MASK> self.setTextToCompleterIndex() <TAB> super(CueLineEdit, self).keyPressEvent(event)",if self . completerStrings :,192
"def maxRange(self): <TAB> attrs = ( <TAB>  <TAB> ""shieldTransferRange"", <TAB>  <TAB> ""powerTransferRange"", <TAB>  <TAB> ""energyDestabilizationRange"", <TAB>  <TAB> ""empFieldRange"", <TAB>  <TAB> ""ecmBurstRange"", <TAB>  <TAB> ""maxRange"", <TAB> ) <TAB> for attr in attrs: <TAB>  <TAB> maxRange = self.getModifiedItemAttr(attr, None) <TAB>  <TAB> if maxRange is not None: <TAB>  <TAB>  <TAB> return maxRange <TAB> if self.charge is not None: <TAB>  <TAB> delay = self.getModifiedChargeAttr(""explosionDelay"", None) <TAB>  <TAB> speed = self.getModifiedChargeAttr(""maxVelocity"", None) <MASK> return delay / 1000.0 * speed",if delay is not None and speed is not None :,186
"def decref(self, *keys): <TAB> for tileable_key, tileable_id in keys: <MASK> continue <TAB>  <TAB> _graph_key, ids = self._executed_tileables[tileable_key] <TAB>  <TAB> if tileable_id in ids: <TAB>  <TAB>  <TAB> ids.remove(tileable_id) <TAB>  <TAB>  <TAB> # for those same key tileables, do decref only when all those tileables are garbage collected <TAB>  <TAB>  <TAB> if len(ids) != 0: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> self.delete_data(tileable_key)",if tileable_key not in self . _executed_tileables :,137
"def run(self): <TAB> # Make some objects emit lights <TAB> for obj in bpy.context.scene.objects: <TAB>  <TAB> if ""modelId"" in obj: <TAB>  <TAB>  <TAB> obj_id = obj[""modelId""] <TAB>  <TAB>  <TAB> # In the case of the lamp <TAB>  <TAB>  <TAB> if obj_id in self.lights: <TAB>  <TAB>  <TAB>  <TAB> self._make_lamp_emissive(obj, self.lights[obj_id]) <TAB>  <TAB>  <TAB> # Make the windows emit light <TAB>  <TAB>  <TAB> if obj_id in self.windows: <TAB>  <TAB>  <TAB>  <TAB> self._make_window_emissive(obj) <TAB>  <TAB>  <TAB> # Also make ceilings slightly emit light <MASK> self._make_ceiling_emissive(obj)","if obj . name . startswith ( ""Ceiling#"" ) :",190
"def _create_bucket(self): <TAB> """"""Create remote S3 bucket if it doesn't exist"""""" <TAB> resource = boto3.resource(""s3"") <TAB> try: <TAB>  <TAB> resource.meta.client.head_bucket(Bucket=self.bucket) <TAB> except ClientError as e: <TAB>  <TAB> error_code = int(e.response[""Error""][""Code""]) <MASK> resource.create_bucket(Bucket=self.bucket) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise",if error_code == 404 :,118
"def sort_sizes(size_list): <TAB> """"""Sorts sizes with extensions. Assumes that size is already in largest unit possible"""""" <TAB> final_list = [] <TAB> for suffix in ["" B"", "" KB"", "" MB"", "" GB"", "" TB""]: <TAB>  <TAB> sub_list = [ <TAB>  <TAB>  <TAB> float(size[: -len(suffix)]) <TAB>  <TAB>  <TAB> for size in size_list <TAB>  <TAB>  <TAB> if size.endswith(suffix) and size[: -len(suffix)][-1].isnumeric() <TAB>  <TAB> ] <TAB>  <TAB> sub_list.sort() <TAB>  <TAB> final_list += [(str(size) + suffix) for size in sub_list] <TAB>  <TAB> # Skip additional loops <MASK> break <TAB> return final_list",if len ( final_list ) == len ( size_list ) :,183
"def rename_var(block: paddle.device.framework.Block, old_name: str, new_name: str): <TAB> """""" """""" <TAB> for op in block.ops: <TAB>  <TAB> for input_name in op.input_arg_names: <TAB>  <TAB>  <TAB> if input_name == old_name: <TAB>  <TAB>  <TAB>  <TAB> op._rename_input(old_name, new_name) <TAB>  <TAB> for output_name in op.output_arg_names: <MASK> op._rename_output(old_name, new_name) <TAB> block._rename_var(old_name, new_name)",if output_name == old_name :,155
"def _GetParserChains(self, events): <TAB> """"""Return a dict with a plugin count given a list of events."""""" <TAB> parser_chains = {} <TAB> for event in events: <TAB>  <TAB> parser_chain = getattr(event, ""parser"", None) <MASK> continue <TAB>  <TAB> if parser_chain in parser_chains: <TAB>  <TAB>  <TAB> parser_chains[parser_chain] += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> parser_chains[parser_chain] = 1 <TAB> return parser_chains",if not parser_chain :,122
def context(self): <TAB> # Needed to avoid Translate Toolkit construct ID <TAB> # as context\04source <TAB> if self.template is not None: <MASK> return self.template.id <TAB>  <TAB> if self.template.context: <TAB>  <TAB>  <TAB> return self.template.context <TAB>  <TAB> return self.template.getid() <TAB> return self.unescape_csv(self.mainunit.getcontext()),if self . template . id :,103
"def _validate_min_max_value(field_name, value, opt): <TAB> if isinstance(value, (int, float)): <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Invalid value %s assigned "" ""to field %s.\n"" % (value, field_name) <TAB>  <TAB>  <TAB> ) <TAB> elif isinstance(value, str): <TAB>  <TAB> if len(value) < opt[""minValue""] or len(value) > opt[""maxValue""]: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Invalid value %s assigned "" ""to field %s.\n"" % (value, field_name) <TAB>  <TAB>  <TAB> )","if value < opt [ ""minValue"" ] or value > opt [ ""maxValue"" ] :",164
"def _incr_internal(key, instance=None, tags=None, amount=1): <TAB> from sentry.app import tsdb <TAB> if _should_sample(): <TAB>  <TAB> amount = _sampled_value(amount) <MASK> full_key = ""{}.{}"".format(key, instance) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> full_key = key <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> tsdb.incr(tsdb.models.internal, full_key, count=amount) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> logger = logging.getLogger(""sentry.errors"") <TAB>  <TAB>  <TAB> logger.exception(""Unable to incr internal metric"")",if instance :,150
"def get(self, key, default=None, version=None): <TAB> key = self.make_key(key, version=version) <TAB> self.validate_key(key) <TAB> fname = self._key_to_file(key) <TAB> try: <TAB>  <TAB> with open(fname, ""rb"") as f: <TAB>  <TAB>  <TAB> exp = pickle.load(f) <TAB>  <TAB>  <TAB> now = time.time() <MASK> self._delete(fname) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return pickle.load(f) <TAB> except (IOError, OSError, EOFError, pickle.PickleError): <TAB>  <TAB> pass <TAB> return default",if exp < now :,156
"def on_execution_scenario(self, cpath, scenario): <TAB> if isinstance(scenario, dict): <TAB>  <TAB> self.check_scenario(cpath, scenario) <TAB> elif isinstance(scenario, str): <TAB>  <TAB> scenario_name = scenario <TAB>  <TAB> scenario_path = Path(""scenarios"", scenario_name) <TAB>  <TAB> scenario = self.linter.get_config_value(scenario_path, raise_if_not_found=False) <MASK> self.report( <TAB>  <TAB>  <TAB>  <TAB> ConfigWarning.ERROR, <TAB>  <TAB>  <TAB>  <TAB> ""undefined-scenario"", <TAB>  <TAB>  <TAB>  <TAB> cpath, <TAB>  <TAB>  <TAB>  <TAB> ""scenario %r is used but isn't defined"" % scenario_name, <TAB>  <TAB>  <TAB> )",if not scenario :,167
"def getSubmitKey(request, response): <TAB> titleId = request.bits[2] <TAB> titleKey = request.bits[3] <TAB> try: <MASK> return success(request, response, ""Key successfully added"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return error(request, response, ""Key validation failed"") <TAB> except LookupError as e: <TAB>  <TAB> error(request, response, str(e)) <TAB> except OSError as e: <TAB>  <TAB> error(request, response, str(e)) <TAB> except BaseException as e: <TAB>  <TAB> error(request, response, str(e))","if blockchain . blockchain . suggest ( titleId , titleKey ) :",151
"def test_downstream_trials(trial_associated_artifact, trial_obj, sagemaker_session): <TAB> # allow trial components to index, 30 seconds max <TAB> for i in range(3): <TAB>  <TAB> time.sleep(10) <TAB>  <TAB> trials = trial_associated_artifact.downstream_trials( <TAB>  <TAB>  <TAB> sagemaker_session=sagemaker_session <TAB>  <TAB> ) <MASK> break <TAB> assert len(trials) == 1 <TAB> assert trial_obj.trial_name in trials",if len ( trials ) > 0 :,125
"def get_subfield_asts(context, return_type, field_asts): <TAB> subfield_asts = DefaultOrderedDict(list) <TAB> visited_fragment_names = set() <TAB> for field_ast in field_asts: <TAB>  <TAB> selection_set = field_ast.selection_set <MASK> subfield_asts = collect_fields( <TAB>  <TAB>  <TAB>  <TAB> context, <TAB>  <TAB>  <TAB>  <TAB> return_type, <TAB>  <TAB>  <TAB>  <TAB> selection_set, <TAB>  <TAB>  <TAB>  <TAB> subfield_asts, <TAB>  <TAB>  <TAB>  <TAB> visited_fragment_names, <TAB>  <TAB>  <TAB> ) <TAB> return subfield_asts",if selection_set :,140
"def _handle_children(self, removed, added): <TAB> # Stop all the removed children. <TAB> for obj in removed: <TAB>  <TAB> obj.stop() <TAB> # Process the new objects. <TAB> for obj in added: <TAB>  <TAB> obj.set(scene=self.scene, parent=self) <MASK> obj.source = self <TAB>  <TAB> elif is_filter(obj): <TAB>  <TAB>  <TAB> obj.inputs.append(self) <TAB>  <TAB> if self.running: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> obj.start() <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> exception()","if isinstance ( obj , ModuleManager ) :",148
"def __kmp_search(S, W): <TAB> m = 0 <TAB> i = 0 <TAB> T = __kmp_table(W) <TAB> while m + i < len(S): <MASK> i += 1 <TAB>  <TAB>  <TAB> if i == len(W): <TAB>  <TAB>  <TAB>  <TAB> yield m <TAB>  <TAB>  <TAB>  <TAB> m += i - T[i] <TAB>  <TAB>  <TAB>  <TAB> i = max(T[i], 0) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> m += i - T[i] <TAB>  <TAB>  <TAB> i = max(T[i], 0)",if S [ m + i ] == W [ i ] :,144
"def connection(self, commit_on_success=False): <TAB> with self._lock: <MASK> if self._pending_connection is None: <TAB>  <TAB>  <TAB>  <TAB> self._pending_connection = sqlite.connect(self.filename) <TAB>  <TAB>  <TAB> con = self._pending_connection <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> con = sqlite.connect(self.filename) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if self.fast_save: <TAB>  <TAB>  <TAB>  <TAB> con.execute(""PRAGMA synchronous = 0;"") <TAB>  <TAB>  <TAB> yield con <TAB>  <TAB>  <TAB> if commit_on_success and self.can_commit: <TAB>  <TAB>  <TAB>  <TAB> con.commit() <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> if not self._bulk_commit: <TAB>  <TAB>  <TAB>  <TAB> con.close()",if self . _bulk_commit :,182
"def passed(self): <TAB> for test in self.lints[0]: <TAB>  <TAB> for template in self.lints[0][test][""results""]: <TAB>  <TAB>  <TAB> results = self.lints[0][test][""results""][template] <TAB>  <TAB>  <TAB> if results: <MASK> return False <TAB> return True",if self . _is_error ( results ) or self . strict :,92
"def testCheckIPGenerator(self): <TAB> for i, ip in self._ip_range(65536 if not unittest.F2B.fast else 1000): <TAB>  <TAB> if i == 254: <TAB>  <TAB>  <TAB> self.assertEqual(str(ip), ""127.0.0.255"") <MASK> self.assertEqual(str(ip), ""127.0.1.0"") <TAB>  <TAB> elif i == 1000: <TAB>  <TAB>  <TAB> self.assertEqual(str(ip), ""127.0.3.233"") <TAB>  <TAB> elif i == 65534: <TAB>  <TAB>  <TAB> self.assertEqual(str(ip), ""127.0.255.255"") <TAB>  <TAB> elif i == 65535: <TAB>  <TAB>  <TAB> self.assertEqual(str(ip), ""127.1.0.0"")",elif i == 255 :,181
"def _DecodeUnknownMessages(message, encoded_message, pair_type): <TAB> """"""Process unknown fields in encoded_message of a message type."""""" <TAB> field_type = pair_type.value.type <TAB> new_values = [] <TAB> all_field_names = [x.name for x in message.all_fields()] <TAB> for name, value_dict in encoded_message.iteritems(): <MASK> continue <TAB>  <TAB> value = PyValueToMessage(field_type, value_dict) <TAB>  <TAB> new_pair = pair_type(key=name, value=value) <TAB>  <TAB> new_values.append(new_pair) <TAB> return new_values",if name in all_field_names :,161
"def test_apply_noise_model(): <TAB> p = Program(RX(np.pi / 2, 0), RX(np.pi / 2, 1), CZ(0, 1), RX(np.pi / 2, 1)) <TAB> noise_model = _decoherence_noise_model(_get_program_gates(p)) <TAB> pnoisy = apply_noise_model(p, noise_model) <TAB> for i in pnoisy: <MASK> pass <TAB>  <TAB> elif isinstance(i, Pragma): <TAB>  <TAB>  <TAB> assert i.command in [""ADD-KRAUS"", ""READOUT-POVM""] <TAB>  <TAB> elif isinstance(i, Gate): <TAB>  <TAB>  <TAB> assert i.name in NO_NOISE or not i.params","if isinstance ( i , DefGate ) :",187
"def i2h(self, pkt, x): <TAB> if x is not None: <TAB>  <TAB> if x < 0: <TAB>  <TAB>  <TAB> warning(""Fixed3_7: Internal value too negative: %d"" % x) <TAB>  <TAB>  <TAB> x = 0 <MASK> warning(""Fixed3_7: Internal value too positive: %d"" % x) <TAB>  <TAB>  <TAB> x = 3600000000 <TAB>  <TAB> x = (x - 1800000000) * 1e-7 <TAB> return x",elif x > 3600000000 :,116
def onClicked(event): <TAB> shaderConfig = dict() <TAB> for child in self.shaderDefBox.children: <TAB>  <TAB> defName = child.shaderDefine <TAB>  <TAB> enabled = child.isChecked() <TAB>  <TAB> try: <MASK> mat.addShaderDefine(defName) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> mat.removeShaderDefine(defName) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> pass <TAB> # Reload material properties (update enabled states) and shader uniforms <TAB> self.listUniforms(mat) <TAB> self.listMaterialSettings(self.getSelectedObject()),if enabled :,147
"def is_mod(self, member: discord.Member) -> bool: <TAB> """"""Checks if a member is a mod or admin of their guild."""""" <TAB> try: <TAB>  <TAB> member_snowflakes = member._roles  # DEP-WARN <TAB>  <TAB> for snowflake in await self._config.guild(member.guild).admin_role(): <MASK> # DEP-WARN <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> for snowflake in await self._config.guild(member.guild).mod_role(): <TAB>  <TAB>  <TAB> if member_snowflakes.has(snowflake):  # DEP-WARN <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> except AttributeError:  # someone passed a webhook to this <TAB>  <TAB> pass <TAB> return False",if member_snowflakes . has ( snowflake ) :,186
"def _verify_treestore(itr, tree_values): <TAB> i = 0 <TAB> while itr: <TAB>  <TAB> values = tree_values[i] <TAB>  <TAB> if treestore[itr][0] != values[0]: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> if treestore.iter_children(itr): <MASK> return False <TAB>  <TAB> itr = treestore.iter_next(itr) <TAB>  <TAB> i += 1 <TAB> return True","if not _verify_treestore ( treestore . iter_children ( itr ) , values [ 1 ] ) :",132
"def _default_config(self): <TAB> if sys.platform.startswith(""win""): <TAB>  <TAB> return {""name"": ""Command Prompt"", ""cmd"": ""cmd.exe"", ""env"": {}} <TAB> else: <MASK> shell = os.environ[""SHELL""] <TAB>  <TAB>  <TAB> if os.path.basename(shell) == ""tcsh"": <TAB>  <TAB>  <TAB>  <TAB> cmd = [shell, ""-l""] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> cmd = [shell, ""-i"", ""-l""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> cmd = [""/bin/bash"", ""-i"", ""-l""] <TAB>  <TAB> return {""name"": ""Login Shell"", ""cmd"": cmd, ""env"": {}}","if ""SHELL"" in os . environ :",170
"def _messageHandled(self, resultList): <TAB> failures = 0 <TAB> for (success, result) in resultList: <MASK> failures += 1 <TAB>  <TAB>  <TAB> log.err(result) <TAB> if failures: <TAB>  <TAB> msg = ""Could not send e-mail"" <TAB>  <TAB> resultLen = len(resultList) <TAB>  <TAB> if resultLen > 1: <TAB>  <TAB>  <TAB> msg += "" ({} failures out of {} recipients)"".format(failures, resultLen) <TAB>  <TAB> self.sendCode(550, networkString(msg)) <TAB> else: <TAB>  <TAB> self.sendCode(250, b""Delivery in progress"")",if not success :,147
"def to_internal_value(self, data): <TAB> site = get_current_site() <TAB> pages_root = reverse(""pages-root"") <TAB> ret = [] <TAB> for path in data: <TAB>  <TAB> if path.startswith(pages_root): <TAB>  <TAB>  <TAB> path = path[len(pages_root) :] <TAB>  <TAB> # strip any final slash <MASK> path = path[:-1] <TAB>  <TAB> page = get_page_from_path(site, path) <TAB>  <TAB> if page: <TAB>  <TAB>  <TAB> ret.append(page) <TAB> return ret","if path . endswith ( ""/"" ) :",136
"def _prune(self): <TAB> with self.lock: <TAB>  <TAB> entries = self._list_dir() <TAB>  <TAB> if len(entries) > self._threshold: <TAB>  <TAB>  <TAB> now = time.time() <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> for i, fpath in enumerate(entries): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> remove = False <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f = LockedFile(fpath, ""rb"") <TAB>  <TAB>  <TAB>  <TAB>  <TAB> exp = pickle.load(f.file) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f.close() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> remove = exp <= now or i % 3 == 0 <MASK> self._del_file(fpath) <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> pass",if remove :,173
"def get_ax_arg(uri): <TAB> if not ax_ns: <TAB>  <TAB> return u"""" <TAB> prefix = ""openid."" + ax_ns + "".type."" <TAB> ax_name = None <TAB> for name in self.request.arguments.keys(): <MASK> part = name[len(prefix) :] <TAB>  <TAB>  <TAB> ax_name = ""openid."" + ax_ns + "".value."" + part <TAB>  <TAB>  <TAB> break <TAB> if not ax_name: <TAB>  <TAB> return u"""" <TAB> return self.get_argument(ax_name, u"""")",if self . get_argument ( name ) == uri and name . startswith ( prefix ) :,150
"def _generate_expression(self): <TAB> # turn my _format attribute into the _expression attribute <TAB> e = [] <TAB> for part in PARSE_RE.split(self._format): <TAB>  <TAB> if not part: <TAB>  <TAB>  <TAB> continue <MASK> e.append(r""\{"") <TAB>  <TAB> elif part == ""}}"": <TAB>  <TAB>  <TAB> e.append(r""\}"") <TAB>  <TAB> elif part[0] == ""{"" and part[-1] == ""}"": <TAB>  <TAB>  <TAB> # this will be a braces-delimited field to handle <TAB>  <TAB>  <TAB> e.append(self._handle_field(part)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # just some text to match <TAB>  <TAB>  <TAB> e.append(REGEX_SAFETY.sub(self._regex_replace, part)) <TAB> return """".join(e)","elif part == ""{{"" :",189
"def get_clean_username(user): <TAB> try: <TAB>  <TAB> username = force_text(user) <TAB> except AttributeError: <TAB>  <TAB> # AnonymousUser may not have USERNAME_FIELD <TAB>  <TAB> username = ""anonymous"" <TAB> else: <TAB>  <TAB> # limit changed_by and created_by to avoid problems with Custom User Model <MASK> username = u""{0}... (id={1})"".format( <TAB>  <TAB>  <TAB>  <TAB> username[: PAGE_USERNAME_MAX_LENGTH - 15], <TAB>  <TAB>  <TAB>  <TAB> user.pk, <TAB>  <TAB>  <TAB> ) <TAB> return username",if len ( username ) > PAGE_USERNAME_MAX_LENGTH :,144
"def process_request(self, request): <TAB> for old, new in self.names_name: <TAB>  <TAB> request.uri = request.uri.replace(old, new) <TAB>  <TAB> if is_text_payload(request) and request.body: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> body = ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> str(request.body, ""utf-8"") <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if isinstance(request.body, bytes) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> else str(request.body) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> except TypeError:  # python 2 doesn't allow decoding through str <TAB>  <TAB>  <TAB>  <TAB> body = str(request.body) <MASK> request.body = body.replace(old, new) <TAB> return request",if old in body :,182
"def get_config_variable(self, name, methods=(""env"", ""config""), default=None): <TAB> value = None <TAB> config_name, envvar_name = self.session_var_map[name] <TAB> if methods is not None: <TAB>  <TAB> if ""env"" in methods and value is None: <TAB>  <TAB>  <TAB> value = os.environ.get(envvar_name) <MASK> value = self.config_file_vars.get(config_name) <TAB> else: <TAB>  <TAB> value = default <TAB> return value","if ""config"" in methods and value is None :",134
"def get_field_by_name(obj, field): <TAB> # Dereference once <TAB> if obj.type.code == gdb.TYPE_CODE_PTR: <TAB>  <TAB> obj = obj.dereference() <TAB> for f in re.split(""(->|\.|\[\d+\])"", field): <TAB>  <TAB> if not f: <TAB>  <TAB>  <TAB> continue <MASK> obj = obj.dereference() <TAB>  <TAB> elif f == ""."": <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> elif f.startswith(""[""): <TAB>  <TAB>  <TAB> n = int(f.strip(""[]"")) <TAB>  <TAB>  <TAB> obj = obj.cast(obj.dereference().type.pointer()) <TAB>  <TAB>  <TAB> obj += n <TAB>  <TAB>  <TAB> obj = obj.dereference() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> obj = obj[f] <TAB> return obj","if f == ""->"" :",189
"def read_subpkgdata_dict(pkg, d): <TAB> ret = {} <TAB> subd = read_pkgdatafile(get_subpkgedata_fn(pkg, d)) <TAB> for var in subd: <TAB>  <TAB> newvar = var.replace(""_"" + pkg, """") <MASK> continue <TAB>  <TAB> ret[newvar] = subd[var] <TAB> return ret","if newvar == var and var + ""_"" + pkg in subd :",104
"def _classify_volume(self, ctxt, volumes): <TAB> bypass_volumes = [] <TAB> replica_volumes = [] <TAB> for v in volumes: <TAB>  <TAB> volume_type = self._get_volume_replicated_type(ctxt, v) <TAB>  <TAB> grp = v.group <TAB>  <TAB> if grp and utils.is_group_a_type(grp, ""consistent_group_replication_enabled""): <TAB>  <TAB>  <TAB> continue <MASK> replica_volumes.append(v) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> bypass_volumes.append(v) <TAB> return bypass_volumes, replica_volumes","elif volume_type and v . status in [ ""available"" , ""in-use"" ] :",159
"def _ensure_entity_values(self): <TAB> entities_values = { <TAB>  <TAB> entity.name: self._get_entity_values(entity) for entity in self.entities <TAB> } <TAB> for intent in self.intents: <TAB>  <TAB> for utterance in intent.utterances: <TAB>  <TAB>  <TAB> for chunk in utterance.slot_chunks: <MASK> continue <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> chunk.text = next(entities_values[chunk.entity]) <TAB>  <TAB>  <TAB>  <TAB> except StopIteration: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise DatasetFormatError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""At least one entity value must be provided for "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""entity '%s'"" % chunk.entity <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return self",if chunk . text is not None :,188
"def _consume_msg(self): <TAB> async for data in self._stream: <TAB>  <TAB> stream = data.get(""ev"") <TAB>  <TAB> if stream: <TAB>  <TAB>  <TAB> await self._dispatch(data) <MASK> # Polygon returns this on an empty 'ev' id.. <TAB>  <TAB>  <TAB> data[""ev""] = ""status"" <TAB>  <TAB>  <TAB> await self._dispatch(data) <TAB>  <TAB>  <TAB> raise ConnectionResetError( <TAB>  <TAB>  <TAB>  <TAB> ""Polygon terminated connection: "" f'({data.get(""message"")})' <TAB>  <TAB>  <TAB> )","elif data . get ( ""status"" ) == ""disconnected"" :",135
"def GetHeaderWidth(self): <TAB> """"""Returns the header window width, in pixels."""""" <TAB> if not self._headerWidth: <TAB>  <TAB> count = self.GetColumnCount() <TAB>  <TAB> for col in range(count): <MASK> continue <TAB>  <TAB>  <TAB> self._headerWidth += self.GetColumnWidth(col) <TAB> if self.HasAGWFlag(ULC_FOOTER): <TAB>  <TAB> self._footerWidth = self._headerWidth <TAB> return self._headerWidth",if not self . IsColumnShown ( col ) :,123
"def testCheckIPGenerator(self): <TAB> for i, ip in self._ip_range(65536 if not unittest.F2B.fast else 1000): <MASK> self.assertEqual(str(ip), ""127.0.0.255"") <TAB>  <TAB> elif i == 255: <TAB>  <TAB>  <TAB> self.assertEqual(str(ip), ""127.0.1.0"") <TAB>  <TAB> elif i == 1000: <TAB>  <TAB>  <TAB> self.assertEqual(str(ip), ""127.0.3.233"") <TAB>  <TAB> elif i == 65534: <TAB>  <TAB>  <TAB> self.assertEqual(str(ip), ""127.0.255.255"") <TAB>  <TAB> elif i == 65535: <TAB>  <TAB>  <TAB> self.assertEqual(str(ip), ""127.1.0.0"")",if i == 254 :,181
"def childrenTodo(self, p=None): <TAB> if p is None: <TAB>  <TAB> p = self.c.currentPosition() <TAB> for p in p.children(): <MASK> continue <TAB>  <TAB> self.setat(p.v, ""priority"", 19) <TAB>  <TAB> self.loadIcons(p)","if self . getat ( p . v , ""priority"" ) != 9999 :",92
"def __init__(self, **kwargs): <TAB> super(DepthwiseSeparableASPPModule, self).__init__(**kwargs) <TAB> for i, dilation in enumerate(self.dilations): <MASK> self[i] = DepthwiseSeparableConvModule( <TAB>  <TAB>  <TAB>  <TAB> self.in_channels, <TAB>  <TAB>  <TAB>  <TAB> self.channels, <TAB>  <TAB>  <TAB>  <TAB> 3, <TAB>  <TAB>  <TAB>  <TAB> dilation=dilation, <TAB>  <TAB>  <TAB>  <TAB> padding=dilation, <TAB>  <TAB>  <TAB>  <TAB> norm_cfg=self.norm_cfg, <TAB>  <TAB>  <TAB>  <TAB> act_cfg=self.act_cfg, <TAB>  <TAB>  <TAB> )",if dilation > 1 :,146
"def test_char(self): <TAB> for x in range(256): <TAB>  <TAB> c = System.Char.Parse(chr(x)) <TAB>  <TAB> self.assertEqual(c, chr(x)) <TAB>  <TAB> self.assertEqual(chr(x), c) <TAB>  <TAB> if c == chr(x): <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertTrue(False) <MASK> self.assertTrue(False) <TAB>  <TAB> if chr(x) == c: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertTrue(False) <TAB>  <TAB> if not chr(x) == c: <TAB>  <TAB>  <TAB> self.assertTrue(False)",if not c == chr ( x ) :,162
"def create_model_handler(ns, model_type): <TAB> @route(f""/<provider>/{ns}/<model_id>"") <TAB> @use_provider <TAB> def handle(req, provider, model_id): <TAB>  <TAB> # special cases: <TAB>  <TAB> # fuo://<provider>/users/me -> show current logged user <MASK> if model_id == ""me"": <TAB>  <TAB>  <TAB>  <TAB> user = getattr(provider, ""_user"", None) <TAB>  <TAB>  <TAB>  <TAB> if user is None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise CmdException(f""log in provider:{provider.identifier} first"") <TAB>  <TAB>  <TAB>  <TAB> return user <TAB>  <TAB> model = get_model_or_raise(provider, model_type, model_id) <TAB>  <TAB> return model",if model_type == ModelType . user :,184
"def __str__(self, prefix="""", printElemNumber=0): <TAB> res = """" <TAB> if self.has_key_: <TAB>  <TAB> res += prefix + (""key: %s\n"" % self.DebugFormatString(self.key_)) <TAB> cnt = 0 <TAB> for e in self.value_: <TAB>  <TAB> elm = """" <MASK> elm = ""(%d)"" % cnt <TAB>  <TAB> res += prefix + (""value%s: %s\n"" % (elm, self.DebugFormatString(e))) <TAB>  <TAB> cnt += 1 <TAB> if self.has_partial_: <TAB>  <TAB> res += prefix + (""partial: %s\n"" % self.DebugFormatBool(self.partial_)) <TAB> return res",if printElemNumber :,170
"def set_value_type_index(self, rows: list, value_type_index: int): <TAB> for row in rows: <TAB>  <TAB> label = self.message_type[row] <MASK> label.value_type_index = value_type_index <TAB>  <TAB>  <TAB> self.protocol_label_updated.emit(label) <TAB> self.update()",if not label . is_checksum_label :,96
"def get_model_param(self, job_id, cpn_name, role, party_id): <TAB> result = None <TAB> party_id = str(party_id) <TAB> try: <TAB>  <TAB> result = self.client.component.output_model( <TAB>  <TAB>  <TAB> job_id=job_id, role=role, party_id=party_id, component_name=cpn_name <TAB>  <TAB> ) <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> f""job {job_id}, component {cpn_name} has no output model param"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return result[""data""] <TAB> except: <TAB>  <TAB> raise ValueError(""Cannot get output model, err msg: "")","if ""data"" not in result :",173
"def validate(self) -> None: <TAB> if self.query: <TAB>  <TAB> if not self.sysupgrade: <TAB>  <TAB>  <TAB> for arg_name in (""aur"", ""repo""): <MASK> raise MissingArgument(""sysupgrade"", arg_name)","if getattr ( self , arg_name ) :",74
"def print_nested_help(self, args: argparse.Namespace) -> None: <TAB> level = 0 <TAB> parser = self.main_parser <TAB> while True: <TAB>  <TAB> if parser._subparsers is None: <TAB>  <TAB>  <TAB> break <MASK> break <TAB>  <TAB> choices = parser._subparsers._actions[-1].choices <TAB>  <TAB> value = getattr(args, ""level_%d"" % level) <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB> parser.print_help() <TAB>  <TAB>  <TAB> return <TAB>  <TAB> if not choices: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if isinstance(choices, dict): <TAB>  <TAB>  <TAB> parser = choices[value] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> level += 1",if parser . _subparsers . _actions is None :,175
"def merge(self, abort=False, message=None): <TAB> """"""Merge remote branch or reverts the merge."""""" <TAB> if abort: <TAB>  <TAB> self.execute([""update"", ""--clean"", "".""]) <TAB> elif self.needs_merge(): <TAB>  <TAB> if self.needs_ff(): <TAB>  <TAB>  <TAB> self.execute([""update"", ""--clean"", ""remote(.)""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.configure_merge() <TAB>  <TAB>  <TAB> # Fallback to merge <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> self.execute([""merge"", ""-r"", ""remote(.)""]) <TAB>  <TAB>  <TAB> except RepositoryException as error: <MASK> # Nothing to merge <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB>  <TAB> self.execute([""commit"", ""--message"", ""Merge""])",if error . retcode == 255 :,191
"def parseArtistIds(cls, page): <TAB> ids = list() <TAB> js = demjson.decode(page) <TAB> if ""error"" in js and js[""error""]: <TAB>  <TAB> raise PixivException(""Error when requesting Fanbox"", 9999, page) <TAB> if ""body"" in js and js[""body""] is not None: <TAB>  <TAB> js_body = js[""body""] <MASK> js_body = js_body[""supportingPlans""] <TAB>  <TAB> for creator in js_body: <TAB>  <TAB>  <TAB> ids.append(creator[""user""][""userId""]) <TAB> return ids","if ""supportingPlans"" in js [ ""body"" ] :",148
"def ignore(self, other): <TAB> if isinstance(other, Suppress): <TAB>  <TAB> if other not in self.ignoreExprs: <TAB>  <TAB>  <TAB> super().ignore(other) <MASK> self.expr.ignore(self.ignoreExprs[-1]) <TAB> else: <TAB>  <TAB> super().ignore(other) <TAB>  <TAB> if self.expr is not None: <TAB>  <TAB>  <TAB> self.expr.ignore(self.ignoreExprs[-1]) <TAB> return self",if self . expr is not None :,117
"def execute(self): <TAB> func = self.func <TAB> is_batch_func = getattr(func, ""_task_batch"", False) <TAB> g[""current_task_is_batch""] = is_batch_func <TAB> g[""current_tasks""] = [self] <TAB> try: <MASK> return func([{""args"": self.args, ""kwargs"": self.kwargs}]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return func(*self.args, **self.kwargs) <TAB> finally: <TAB>  <TAB> g[""current_task_is_batch""] = None <TAB>  <TAB> g[""current_tasks""] = None",if is_batch_func :,148
"def fn(value=None): <TAB> for i in [-1, 0, 1, 2, 3, 4]: <TAB>  <TAB> if i < 0: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif i == 0: <TAB>  <TAB>  <TAB> yield 0 <MASK> yield 1 <TAB>  <TAB>  <TAB> i = 0 <TAB>  <TAB>  <TAB> yield value <TAB>  <TAB>  <TAB> yield 2 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> v = i / value <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> v = i <TAB>  <TAB>  <TAB> yield v",elif i == 1 :,127
"def get_instrumentation_key(url): <TAB> data = url.split(""//"")[1] <TAB> try: <TAB>  <TAB> uuid.UUID(data) <TAB> except ValueError: <TAB>  <TAB> values = data.split(""/"") <MASK> AppInsightsHelper.log.warning(""Bad format: '%s'"" % url) <TAB>  <TAB> return AppInsightsHelper._get_instrumentation_key(values[0], values[1]) <TAB> return data",if len ( values ) != 2 :,114
"def get_correct(ngrams_ref, ngrams_test, correct, total): <TAB> for rank in ngrams_test: <TAB>  <TAB> for chain in ngrams_test[rank]: <TAB>  <TAB>  <TAB> total[rank] += ngrams_test[rank][chain] <MASK> correct[rank] += min(ngrams_test[rank][chain], ngrams_ref[rank][chain]) <TAB> return correct, total",if chain in ngrams_ref [ rank ] :,103
"def _content_type_params__set(self, value_dict): <TAB> if not value_dict: <TAB>  <TAB> del self.content_type_params <TAB>  <TAB> return <TAB> params = [] <TAB> for k, v in sorted(value_dict.items()): <MASK> v = '""%s""' % v.replace('""', '\\""') <TAB>  <TAB> params.append(""; %s=%s"" % (k, v)) <TAB> ct = self.headers.pop(""Content-Type"", """").split("";"", 1)[0] <TAB> ct += """".join(params) <TAB> self.headers[""Content-Type""] = ct",if not _OK_PARAM_RE . search ( v ) :,152
"def split_file(self, filename, block_size=2 ** 20): <TAB> with open(filename, ""rb"") as f: <TAB>  <TAB> file_list = [] <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> data = f.read(block_size) <MASK> break <TAB>  <TAB>  <TAB> filehash = os.path.join(self.resource_dir, self.__count_hash(data)) <TAB>  <TAB>  <TAB> filehash = os.path.normpath(filehash) <TAB>  <TAB>  <TAB> with open(filehash, ""wb"") as fwb: <TAB>  <TAB>  <TAB>  <TAB> fwb.write(data) <TAB>  <TAB>  <TAB> file_list.append(filehash) <TAB> return file_list",if not data :,164
"def _set_live(self, live, _): <TAB> if live is not None and not self.live: <TAB>  <TAB> if isinstance(live, basestring): <TAB>  <TAB>  <TAB> live = [live] <TAB>  <TAB> # Default is to use Memory analysis. <TAB>  <TAB> if len(live) == 0: <TAB>  <TAB>  <TAB> mode = ""Memory"" <MASK> mode = live[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise RuntimeError(""--live parameter should specify only one mode."") <TAB>  <TAB> live_plugin = self.session.plugins.live(mode=mode) <TAB>  <TAB> live_plugin.live() <TAB>  <TAB> # When the session is destroyed, close the live plugin. <TAB>  <TAB> self.session.register_flush_hook(self, live_plugin.close) <TAB> return live",elif len ( live ) == 1 :,184
"def process_percent(token, state, command_line): <TAB> if not state.is_range_start_line_parsed: <MASK> raise ValueError(""bad range: {0}"".format(state.scanner.state.source)) <TAB>  <TAB> command_line.line_range.start.append(token) <TAB> else: <TAB>  <TAB> if command_line.line_range.end: <TAB>  <TAB>  <TAB> raise ValueError(""bad range: {0}"".format(state.scanner.state.source)) <TAB>  <TAB> command_line.line_range.end.append(token) <TAB> return parse_line_ref, command_line",if command_line . line_range . start :,154
"def gprv_implicit_orax(ii): <TAB> for i, op in enumerate(_gen_opnds(ii)): <TAB>  <TAB> if i == 0: <TAB>  <TAB>  <TAB> if op.name == ""REG0"" and op_luf(op, ""GPRv_SB""): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> elif i == 1: <MASK> continue <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> return True","if op . name == ""REG1"" and op_luf ( op , ""OrAX"" ) :",151
"def _check_events(self): <TAB> # make sure song-started and song-ended match up <TAB> stack = [] <TAB> old = self.events[:] <TAB> for type_, song in self.events: <MASK> stack.append(song) <TAB>  <TAB> elif type_ == ""ended"": <TAB>  <TAB>  <TAB> self.assertTrue(stack.pop(-1) is song, msg=old) <TAB> self.assertFalse(stack, msg=old)","if type_ == ""started"" :",110
"def _minimal_replacement_cost(self, first, second): <TAB> first_symbols, second_symbols = set(), set() <TAB> removal_cost, insertion_cost = 0, 0 <TAB> for a, b in itertools.zip_longest(first, second, fillvalue=None): <TAB>  <TAB> if a is not None: <TAB>  <TAB>  <TAB> first_symbols.add(a) <MASK> second_symbols.add(b) <TAB>  <TAB> removal_cost = max(removal_cost, len(first_symbols - second_symbols)) <TAB>  <TAB> insertion_cost = max(insertion_cost, len(second_symbols - first_symbols)) <TAB> return min(removal_cost, insertion_cost)",if b is not None :,173
"def get_default_backend(self, user_backends): <TAB> retval = None <TAB> n_defaults = 0 <TAB> for name in user_backends: <TAB>  <TAB> args = user_backends.get(name) <MASK> n_defaults = n_defaults + 1 <TAB>  <TAB>  <TAB> if retval is None: <TAB>  <TAB>  <TAB>  <TAB> retval = name <TAB> return (retval, n_defaults)","if args . get ( ""default"" , False ) :",100
"def ensure_echo_on(): <TAB> if termios: <TAB>  <TAB> fd = sys.stdin <TAB>  <TAB> if fd.isatty(): <TAB>  <TAB>  <TAB> attr_list = termios.tcgetattr(fd) <TAB>  <TAB>  <TAB> if not attr_list[3] & termios.ECHO: <TAB>  <TAB>  <TAB>  <TAB> attr_list[3] |= termios.ECHO <TAB>  <TAB>  <TAB>  <TAB> if hasattr(signal, ""SIGTTOU""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> old_handler = signal.signal(signal.SIGTTOU, signal.SIG_IGN) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> old_handler = None <TAB>  <TAB>  <TAB>  <TAB> termios.tcsetattr(fd, termios.TCSANOW, attr_list) <MASK> signal.signal(signal.SIGTTOU, old_handler)",if old_handler is not None :,197
"def load_dashboard_module_view(request, pk): <TAB> result = {""error"": False} <TAB> try: <MASK> raise ValidationError(""error"") <TAB>  <TAB> instance = UserDashboardModule.objects.get(pk=pk, user=request.user.pk) <TAB>  <TAB> module_cls = instance.load_module() <TAB>  <TAB> module = module_cls(model=instance, context={""request"": request}) <TAB>  <TAB> result[""html""] = module.render() <TAB> except (ValidationError, UserDashboardModule.DoesNotExist): <TAB>  <TAB> result[""error""] = True <TAB> return JsonResponse(result)",if not user_is_authenticated ( request . user ) or not request . user . is_staff :,158
"def _validate_compatible(from_schema, to_schema): <TAB> if set(from_schema.names) != set(to_schema.names): <TAB>  <TAB> raise com.IbisInputError(""Schemas have different names"") <TAB> for name in from_schema: <TAB>  <TAB> lt = from_schema[name] <TAB>  <TAB> rt = to_schema[name] <MASK> raise com.IbisInputError(""Cannot safely cast {0!r} to {1!r}"".format(lt, rt)) <TAB> return",if not lt . castable ( rt ) :,130
"def load_yaml(self): <TAB> if ""FUEL_CONFIG"" in os.environ: <TAB>  <TAB> yaml_file = os.environ[""FUEL_CONFIG""] <TAB> else: <TAB>  <TAB> yaml_file = os.path.expanduser(""~/.fuelrc"") <TAB> if os.path.isfile(yaml_file): <TAB>  <TAB> with open(yaml_file) as f: <TAB>  <TAB>  <TAB> for key, value in yaml.safe_load(f).items(): <MASK> raise ValueError(""Unrecognized config in YAML: {}"".format(key)) <TAB>  <TAB>  <TAB>  <TAB> self.config[key][""yaml""] = value",if key not in self . config :,154
"def process(self): <TAB> if not self.outputs[""Polygons""].is_linked: <TAB>  <TAB> return <TAB> verts = self.inputs[""Vertices""].sv_get() <TAB> faces = self.inputs[""Polygons""].sv_get() <TAB> if not len(verts) == len(faces): <TAB>  <TAB> return <TAB> verts_out = [] <TAB> polys_out = [] <TAB> for v_obj, f_obj in zip(verts, faces): <TAB>  <TAB> res = join_tris(v_obj, f_obj, self) <MASK> return <TAB>  <TAB> verts_out.append(res[0]) <TAB>  <TAB> polys_out.append(res[1]) <TAB> self.outputs[""Vertices""].sv_set(verts_out) <TAB> self.outputs[""Polygons""].sv_set(polys_out)",if not res :,192
"def _set_momentum(self, runner, momentum_groups): <TAB> for param_group, mom in zip(runner.optimizer.param_groups, momentum_groups): <TAB>  <TAB> if ""momentum"" in param_group.keys(): <TAB>  <TAB>  <TAB> param_group[""momentum""] = mom <MASK> param_group[""betas""] = (mom, param_group[""betas""][1])","elif ""betas"" in param_group . keys ( ) :",103
"def getReceiptInfo(pkgname): <TAB> """"""Get receipt info from a package"""""" <TAB> info = [] <TAB> if hasValidPackageExt(pkgname): <TAB>  <TAB> display.display_debug2(""Examining %s"" % pkgname) <TAB>  <TAB> if os.path.isfile(pkgname):  # new flat package <TAB>  <TAB>  <TAB> info = getFlatPackageInfo(pkgname) <MASK> # bundle-style package? <TAB>  <TAB>  <TAB> info = getBundlePackageInfo(pkgname) <TAB> elif pkgname.endswith("".dist""): <TAB>  <TAB> info = parsePkgRefs(pkgname) <TAB> return info",if os . path . isdir ( pkgname ) :,143
"def _add_directory_child(self, children, filename): <TAB> if os.path.isdir(filename): <TAB>  <TAB> children.append(self._directory_controller(filename)) <TAB> else: <TAB>  <TAB> r = self._namespace.get_resource(filename, report_status=False) <MASK> children.append(self._resource_controller(r))",if self . _is_valid_resource ( r ) :,96
"def check_br_addr(self, br): <TAB> ips = {} <TAB> cmd = ""ip a show dev %s"" % br <TAB> for line in self.execute(cmd, sudo=True).split(""\n""): <TAB>  <TAB> if line.strip().startswith(""inet ""): <TAB>  <TAB>  <TAB> elems = [e.strip() for e in line.strip().split("" "")] <TAB>  <TAB>  <TAB> ips[4] = elems[1] <MASK> elems = [e.strip() for e in line.strip().split("" "")] <TAB>  <TAB>  <TAB> ips[6] = elems[1] <TAB> return ips","elif line . strip ( ) . startswith ( ""inet6 "" ) :",149
"def execute(self, statement, parameters=None): <TAB> try: <MASK> result = self.real_cursor.execute(statement, parameters) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result = self.real_cursor.execute(statement) <TAB>  <TAB> return result <TAB> except: <TAB>  <TAB> raise Error(sys.exc_info()[1])",if parameters :,84
"def isUpdateAvailable(self, localOnly=False): <TAB> nsp = self.getLatestFile() <MASK> if not nsp: <TAB>  <TAB>  <TAB> if not self.isUpdate or (self.version and int(self.version) > 0): <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> try: <TAB>  <TAB> latest = self.lastestVersion(localOnly=localOnly) <TAB>  <TAB> if latest is None: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> if int(nsp.version) < int(latest): <TAB>  <TAB>  <TAB> return True <TAB> except BaseException as e: <TAB>  <TAB> Print.error(""isUpdateAvailable exception %s: %s"" % (self.id, str(e))) <TAB>  <TAB> pass <TAB> return False",if not nsp :,179
"def align(size): <TAB> if size <= 4096: <TAB>  <TAB> # Small <MASK> return size <TAB>  <TAB> elif size < 128: <TAB>  <TAB>  <TAB> return min_ge(range(16, 128 + 1, 16), size) <TAB>  <TAB> elif size < 512: <TAB>  <TAB>  <TAB> return min_ge(range(192, 512 + 1, 64), size) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return min_ge(range(768, 4096 + 1, 256), size) <TAB> elif size < 4194304: <TAB>  <TAB> # Large <TAB>  <TAB> return min_ge(range(4096, 4194304 + 1, 4096), size) <TAB> else: <TAB>  <TAB> # Huge <TAB>  <TAB> return min_ge(range(4194304, 536870912 + 1, 4194304), size)",if is_power2 ( size ) :,195
"def __init__(self, transforms): <TAB> assert isinstance(transforms, collections.abc.Sequence) <TAB> self.transforms = [] <TAB> for transform in transforms: <MASK> transform = build_from_cfg(transform, PIPELINES) <TAB>  <TAB>  <TAB> self.transforms.append(transform) <TAB>  <TAB> elif callable(transform): <TAB>  <TAB>  <TAB> self.transforms.append(transform) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError(""transform must be callable or a dict"")","if isinstance ( transform , dict ) :",115
"def branch_name_from_config_file(directory, config_file): <TAB> ans = None <TAB> try: <TAB>  <TAB> with open(config_file, ""rb"") as f: <TAB>  <TAB>  <TAB> for line in f: <TAB>  <TAB>  <TAB>  <TAB> m = nick_pat.match(line) <MASK> ans = ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> m.group(1) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> .strip() <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> .decode(get_preferred_file_contents_encoding(), ""replace"") <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB> except Exception: <TAB>  <TAB> pass <TAB> return ans or os.path.basename(directory)",if m is not None :,170
"def do_acquire_write_lock(self, wait): <TAB> owner_id = self._get_owner_id() <TAB> while True: <TAB>  <TAB> if self.client.setnx(self.identifier, owner_id): <TAB>  <TAB>  <TAB> self.client.pexpire(self.identifier, self.LOCK_EXPIRATION * 1000) <TAB>  <TAB>  <TAB> return True <MASK> return False <TAB>  <TAB> time.sleep(0.2)",if not wait :,108
"def add_files_for_package(sub_package_path, root_package_path, root_package_name): <TAB> for root, dirs, files in os.walk(sub_package_path): <MASK> dirs.remove("".svn"") <TAB>  <TAB> for f in files: <TAB>  <TAB>  <TAB> if not f.endswith("".pyc"") and not f.startswith("".""): <TAB>  <TAB>  <TAB>  <TAB> add( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> dereference(root + ""/"" + f), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> root.replace(root_package_path, root_package_name) + ""/"" + f, <TAB>  <TAB>  <TAB>  <TAB> )","if "".svn"" in dirs :",148
"def collect_state(object_name, prefix, d): <TAB> if d[None] is False: <TAB>  <TAB> return [] <TAB> result = [] <TAB> if d[None] is True and prefix is not None: <TAB>  <TAB> name = v.make_measurement_choice(object_name, prefix) <TAB>  <TAB> if name in choices: <TAB>  <TAB>  <TAB> result.append(name) <TAB> for key in [x for x in list(d.keys()) if x is not None]: <MASK> sub_prefix = key <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sub_prefix = ""_"".join((prefix, key)) <TAB>  <TAB> result += collect_state(object_name, sub_prefix, d[key]) <TAB> return result",if prefix is None :,171
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.set_app_id(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 16: <TAB>  <TAB>  <TAB> self.set_num_memcacheg_backends(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 10 :,128
"def check(dbdef): <TAB> ""database version must include required keys"" <TAB> for vnum, vdef in dbdef.items(): <TAB>  <TAB> missing = set(required) - set(vdef) <MASK> missing -= set(initially_ok) <TAB>  <TAB> if missing: <TAB>  <TAB>  <TAB> yield vnum, missing",if vnum == min ( dbdef ) :,86
"def _check(ret): <TAB> if hasattr(ret, ""value""): <TAB>  <TAB> ret = ret.value <TAB> if ret != 0: <MASK> raise USBTimeoutError(_lib.openusb_strerror(ret), ret, _openusb_errno[ret]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise USBError(_lib.openusb_strerror(ret), ret, _openusb_errno[ret]) <TAB> return ret",if ret == OPENUSB_IO_TIMEOUT :,112
"def scroll_to(self, x=None, y=None): <TAB> if x is None or y is None: <TAB>  <TAB> pos = self.tab.get_scroll_position() <TAB>  <TAB> x = pos[""x""] if x is None else x <TAB>  <TAB> y = pos[""y""] if y is None else y <TAB> for value, name in [(x, ""x""), (y, ""y"")]: <MASK> raise ScriptError( <TAB>  <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""argument"": name, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""message"": ""scroll {} coordinate must be "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""a number, got {}"".format(name, repr(value)), <TAB>  <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB> ) <TAB> self.tab.set_scroll_position(x, y)","if not isinstance ( value , ( int , float ) ) :",193
"def _validate_secret_list(self, secrets, expected): <TAB> for secret in secrets: <MASK> expected_secret = expected[secret.name] <TAB>  <TAB>  <TAB> self._assert_secret_attributes_equal(expected_secret.properties, secret) <TAB>  <TAB>  <TAB> del expected[secret.name] <TAB> self.assertEqual(len(expected), 0)",if secret . name in expected . keys ( ) :,93
"def _capture_hub(self, create): <TAB> # Subclasses should call this as the first action from any <TAB> # public method that could, in theory, block and switch <TAB> # to the hub. This may release the GIL. <MASK> # This next line might release the GIL. <TAB>  <TAB> current_hub = get_hub() if create else get_hub_if_exists() <TAB>  <TAB> if current_hub is None: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> # We have the GIL again. Did anything change? If so, <TAB>  <TAB> # we lost the race. <TAB>  <TAB> if self.hub is None: <TAB>  <TAB>  <TAB> self.hub = current_hub",if self . hub is None :,161
"def _hashable(self): <TAB> hashes = [self.graph.md5()] <TAB> for g in self.geometry.values(): <TAB>  <TAB> if hasattr(g, ""md5""): <TAB>  <TAB>  <TAB> hashes.append(g.md5()) <MASK> hashes.append(str(hash(g.tostring()))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # try to just straight up hash <TAB>  <TAB>  <TAB> # this may raise errors <TAB>  <TAB>  <TAB> hashes.append(str(hash(g))) <TAB> hashable = """".join(sorted(hashes)).encode(""utf-8"") <TAB> return hashable","elif hasattr ( g , ""tostring"" ) :",144
"def load_distribution(args: CommandLineArguments) -> CommandLineArguments: <TAB> if args.distribution is not None: <TAB>  <TAB> args.distribution = Distribution[args.distribution] <TAB> if args.distribution is None or args.release is None: <TAB>  <TAB> d, r = detect_distribution() <MASK> args.distribution = d <TAB>  <TAB> if args.distribution == d and d != Distribution.clear and args.release is None: <TAB>  <TAB>  <TAB> args.release = r <TAB> if args.distribution is None: <TAB>  <TAB> die(""Couldn't detect distribution."") <TAB> return args",if args . distribution is None :,137
"def is_different(item, seen): <TAB> is_diff = True <TAB> if item not in seen: <TAB>  <TAB> for value in other: <TAB>  <TAB>  <TAB> if comparator(iteratee(item), iteratee(value)): <TAB>  <TAB>  <TAB>  <TAB> is_diff = False <TAB>  <TAB>  <TAB>  <TAB> break <MASK> seen.append(item) <TAB> return is_diff",if is_diff :,91
"def _find_first_unescaped(dn, char, pos): <TAB> while True: <TAB>  <TAB> pos = dn.find(char, pos) <TAB>  <TAB> if pos == -1: <TAB>  <TAB>  <TAB> break  # no char found <TAB>  <TAB> if pos > 0 and dn[pos - 1] != ""\\"":  # unescaped char <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif pos > 1 and dn[pos - 1] == ""\\"":  # may be unescaped <TAB>  <TAB>  <TAB> escaped = True <TAB>  <TAB>  <TAB> for c in dn[pos - 2 : 0 : -1]: <MASK> escaped = not escaped <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> if not escaped: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> pos += 1 <TAB> return pos","if c == ""\\"" :",181
"def vcf_has_nonfiltered_variants(in_file): <TAB> if os.path.exists(in_file): <TAB>  <TAB> with utils.open_gzipsafe(in_file) as in_handle: <TAB>  <TAB>  <TAB> for line in in_handle: <MASK> parts = line.split(""\t"") <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if parts[6] in set([""PASS"", "".""]): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False","if line . strip ( ) and not line . startswith ( ""#"" ) :",122
"def clean_vendor(ctx, vendor_dir): <TAB> # Old _vendor cleanup <TAB> remove_all(vendor_dir.glob(""*.pyc"")) <TAB> log(""Cleaning %s"" % vendor_dir) <TAB> for item in vendor_dir.iterdir(): <TAB>  <TAB> if item.is_dir(): <TAB>  <TAB>  <TAB> shutil.rmtree(str(item)) <MASK> item.unlink() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log(""Skipping %s"" % item)",elif item . name not in FILE_WHITE_LIST :,120
"def sel_line(view, s): <TAB> if mode == modes.INTERNAL_NORMAL: <MASK> if view.line(s.b).size() > 0: <TAB>  <TAB>  <TAB>  <TAB> eol = view.line(s.b).b <TAB>  <TAB>  <TAB>  <TAB> begin = view.line(s.b).a <TAB>  <TAB>  <TAB>  <TAB> begin = utils.next_non_white_space_char(view, begin, white_space="" \t"") <TAB>  <TAB>  <TAB>  <TAB> return R(begin, eol) <TAB>  <TAB>  <TAB> return s <TAB> return s",if count == 1 :,131
"def _struct(self, fields): <TAB> result = {} <TAB> for field in fields: <MASK> parent = self.instance(field[1]) <TAB>  <TAB>  <TAB> if isinstance(parent, dict): <TAB>  <TAB>  <TAB>  <TAB> result.update(parent) <TAB>  <TAB>  <TAB> elif len(fields) == 1: <TAB>  <TAB>  <TAB>  <TAB> result = parent <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> result[field[0]] = parent <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result[field[0]] = self.instance(field[1]) <TAB> return result","if field [ 0 ] == ""__parent"" :",136
"def _decode_list(lst): <TAB> if not PY2: <TAB>  <TAB> return lst <TAB> newlist = [] <TAB> for i in lst: <MASK> i = to_bytes(i) <TAB>  <TAB> elif isinstance(i, list): <TAB>  <TAB>  <TAB> i = _decode_list(i) <TAB>  <TAB> newlist.append(i) <TAB> return newlist","if isinstance ( i , string_types ) :",96
"def _check_arguments(self, arch, state): <TAB> # TODO: add calling convention detection to individual functions, and use that instead of the <TAB> # TODO: default calling convention of the platform <TAB> cc = DEFAULT_CC[arch.name](arch)  # type: s_cc.SimCC <TAB> for i, expected_arg in enumerate(self.arguments): <MASK> continue <TAB>  <TAB> real_arg = cc.arg(state, i) <TAB>  <TAB> expected_arg_type, expected_arg_value = expected_arg <TAB>  <TAB> r = self._compare_arguments( <TAB>  <TAB>  <TAB> state, expected_arg_type, expected_arg_value, real_arg <TAB>  <TAB> ) <TAB>  <TAB> if not r: <TAB>  <TAB>  <TAB> return False <TAB> return True",if expected_arg is None :,183
"def _strip_classy_blocks(self, module): <TAB> for name, child_module in module.named_children(): <MASK> module.add_module(name, child_module.wrapped_module()) <TAB>  <TAB> self._strip_classy_blocks(child_module)","if isinstance ( child_module , ClassyBlock ) :",79
"def test_07_verify_degraded_pool_alert_list_exist_and_get_id(): <TAB> global alert_id <TAB> results = GET(""/alert/list/"") <TAB> assert results.status_code == 200, results.text <TAB> assert isinstance(results.json(), list), results.text <TAB> for line in results.json(): <MASK> alert_id = results.json()[0][""id""] <TAB>  <TAB>  <TAB> assert results.json()[0][""args""][""volume""] == pool_name, results.text <TAB>  <TAB>  <TAB> assert results.json()[0][""args""][""state""] == ""DEGRADED"", results.text <TAB>  <TAB>  <TAB> assert results.json()[0][""level""] == ""CRITICAL"", results.text <TAB>  <TAB>  <TAB> break","if line [ ""source"" ] == ""VolumeStatus"" :",179
"def parseApplicationExtension(parent): <TAB> yield PascalString8(parent, ""app_name"", ""Application name"") <TAB> yield UInt8(parent, ""size"") <TAB> size = parent[""size""].value <TAB> if parent[""app_name""].value == ""NETSCAPE2.0"" and size == 3: <TAB>  <TAB> yield Enum(UInt8(parent, ""netscape_code""), NETSCAPE_CODE) <MASK> yield UInt16(parent, ""loop_count"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield RawBytes(parent, ""raw"", 2) <TAB> else: <TAB>  <TAB> yield RawBytes(parent, ""raw"", size) <TAB> yield NullBytes(parent, ""terminator"", 1, ""Terminator (0)"")","if parent [ ""netscape_code"" ] . value == 1 :",184
"def tearDownClass(self): <TAB> settings.TIME_ZONE = connection.settings_dict[""TIME_ZONE""] = self._old_time_zone <TAB> timezone._localtime = None <TAB> if TZ_SUPPORT: <MASK> del os.environ[""TZ""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> os.environ[""TZ""] = self._old_tz <TAB>  <TAB> time.tzset()",if self . _old_tz is None :,98
"def __getattr__(self, key): <TAB> if key in self._raw: <TAB>  <TAB> val = self._raw[key] <TAB>  <TAB> if key in (""date"",): <TAB>  <TAB>  <TAB> return pd.Timestamp(val) <MASK> return pd.Timestamp(val).time() <TAB>  <TAB> elif key in (""session_open"", ""session_close""): <TAB>  <TAB>  <TAB> return pd.Timestamp(val[:2] + "":"" + val[-2:]).time() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return val <TAB> return super().__getattr__(key)","elif key in ( ""open"" , ""close"" ) :",132
"def _extract_knob_feature_log(arg): <TAB> """"""extract knob feature for log items"""""" <TAB> try: <TAB>  <TAB> inp, res = arg <TAB>  <TAB> config = inp.config <TAB>  <TAB> x = config.get_flatten_feature() <MASK> with inp.target:  # necessary, for calculating flops of this task <TAB>  <TAB>  <TAB>  <TAB> inp.task.instantiate(config) <TAB>  <TAB>  <TAB> y = inp.task.flop / np.mean(res.costs) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> y = 0.0 <TAB>  <TAB> return x, y <TAB> except Exception:  # pylint: disable=broad-except <TAB>  <TAB> return None",if res . error_no == 0 :,166
"def dvipng_hack_alpha(): <TAB> stdin, stdout = os.popen4(""dvipng -version"") <TAB> for line in stdout: <MASK> version = line.split()[-1] <TAB>  <TAB>  <TAB> mpl.verbose.report(""Found dvipng version %s"" % version, ""helpful"") <TAB>  <TAB>  <TAB> version = distutils.version.LooseVersion(version) <TAB>  <TAB>  <TAB> return version < distutils.version.LooseVersion(""1.6"") <TAB> raise RuntimeError(""Could not obtain dvipng version"")","if line . startswith ( ""dvipng "" ) :",126
"def _get_func_name(self, current_cls: Generic, module_func_dict: dict) -> Optional[str]: <TAB> mod = current_cls.__module__ + ""."" + current_cls.__name__ <TAB> if mod in module_func_dict: <TAB>  <TAB> _func_name = module_func_dict[mod] <TAB>  <TAB> return _func_name <TAB> elif current_cls.__bases__: <TAB>  <TAB> for base_class in current_cls.__bases__: <TAB>  <TAB>  <TAB> base_run_func = self._get_func_name(base_class, module_func_dict) <MASK> return base_run_func <TAB> else: <TAB>  <TAB> return None",if base_run_func :,166
"def __getitem__(self, key): <TAB> if isinstance(key, numbers.Number): <TAB>  <TAB> l = len(self) <MASK> raise IndexError(""Index %s out of range (%s elements)"" % (key, l)) <TAB>  <TAB> if key < 0: <TAB>  <TAB>  <TAB> if key < -l: <TAB>  <TAB>  <TAB>  <TAB> raise IndexError(""Index %s out of range (%s elements)"" % (key, l)) <TAB>  <TAB>  <TAB> key += l <TAB>  <TAB> return self(key + 1) <TAB> elif isinstance(key, slice): <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> self.impl.__class__.__name__ + "" object does not support slicing"" <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> return self(key)",if key >= l :,170
"def add_user_functions(self): <TAB> for udf in user_functions: <MASK> self.conn.create_aggregate(udf.name, udf.param_count, udf.func_or_obj) <TAB>  <TAB> elif type(udf.func_or_obj) == type(md5): <TAB>  <TAB>  <TAB> self.conn.create_function(udf.name, udf.param_count, udf.func_or_obj) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception(""Invalid user function definition %s"" % str(udf))",if type ( udf . func_or_obj ) == type ( object ) :,147
"def _get_schema_references(self, s): <TAB> refs = set() <TAB> if isinstance(s, dict): <TAB>  <TAB> for k, v in s.items(): <TAB>  <TAB>  <TAB> if isinstance(v, six.string_types): <TAB>  <TAB>  <TAB>  <TAB> m = self.__jsonschema_ref_ex.match(v) <MASK> refs.add(m.group(1)) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> elif k in (""oneOf"", ""anyOf"") and isinstance(v, list): <TAB>  <TAB>  <TAB>  <TAB> refs.update(*map(self._get_schema_references, v)) <TAB>  <TAB>  <TAB> refs.update(self._get_schema_references(v)) <TAB> return refs",if m :,170
"def create_model_handler(ns, model_type): <TAB> @route(f""/<provider>/{ns}/<model_id>"") <TAB> @use_provider <TAB> def handle(req, provider, model_id): <TAB>  <TAB> # special cases: <TAB>  <TAB> # fuo://<provider>/users/me -> show current logged user <TAB>  <TAB> if model_type == ModelType.user: <TAB>  <TAB>  <TAB> if model_id == ""me"": <TAB>  <TAB>  <TAB>  <TAB> user = getattr(provider, ""_user"", None) <MASK> raise CmdException(f""log in provider:{provider.identifier} first"") <TAB>  <TAB>  <TAB>  <TAB> return user <TAB>  <TAB> model = get_model_or_raise(provider, model_type, model_id) <TAB>  <TAB> return model",if user is None :,184
"def stream_read_bz2(ifh, ofh): <TAB> """"""Uncompress bz2 compressed *ifh* into *ofh*"""""" <TAB> decompressor = bz2.BZ2Decompressor() <TAB> while True: <TAB>  <TAB> buf = ifh.read(BUFSIZE) <TAB>  <TAB> if not buf: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> buf = decompressor.decompress(buf) <MASK> ofh.write(buf) <TAB> if decompressor.unused_data or ifh.read(1) != b"""": <TAB>  <TAB> raise CorruptedObjectError(""Data after end of bz2 stream"")",if buf :,139
"def copy_layer( <TAB> layer, <TAB> keep_bias=True, <TAB> name_template=None, <TAB> weights=None, <TAB> reuse_symbolic_tensors=True, <TAB> **kwargs): <TAB> config = layer.get_config() <TAB> if name_template is None: <TAB>  <TAB> config[""name""] = None <TAB> else: <TAB>  <TAB> config[""name""] = name_template % config[""name""] <TAB> if keep_bias is False and config.get(""use_bias"", False): <TAB>  <TAB> config[""use_bias""] = False <MASK> if reuse_symbolic_tensors: <TAB>  <TAB>  <TAB>  <TAB> weights = layer.weights[:-1] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> weights = layer.get_weights()[:-1] <TAB> return get_layer_from_config(layer, config, weights=weights, **kwargs)",if weights is None :,200
"def do_status(self, directory, path): <TAB> with self._repo(directory) as repo: <MASK> path = os.path.join(directory, path) <TAB>  <TAB>  <TAB> statuses = repo.status(include=path, all=True) <TAB>  <TAB>  <TAB> for status, paths in statuses: <TAB>  <TAB>  <TAB>  <TAB> if paths: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return self.statuses[status][0] <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> resulting_status = 0 <TAB>  <TAB>  <TAB> for status, paths in repo.status(all=True): <TAB>  <TAB>  <TAB>  <TAB> if paths: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> resulting_status |= self.statuses[status][1] <TAB>  <TAB>  <TAB> return self.repo_statuses_str[resulting_status]",if path :,181
"def close(self): <TAB> if self.changed: <TAB>  <TAB> save = EasyDialogs.AskYesNoCancel( <TAB>  <TAB>  <TAB> 'Save window ""%s"" before closing?' % self.name, 1 <TAB>  <TAB> ) <TAB>  <TAB> if save > 0: <TAB>  <TAB>  <TAB> self.menu_save() <MASK> return <TAB> if self.parent.active == self: <TAB>  <TAB> self.parent.active = None <TAB> self.parent.updatemenubar() <TAB> del self.ted <TAB> self.do_postclose()",elif save < 0 :,126
"def _Return(self, t): <TAB> self._fill(""return "") <TAB> if t.value: <MASK> text = "", "".join([name.name for name in t.value.asList()]) <TAB>  <TAB>  <TAB> self._write(text) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._dispatch(t.value) <TAB>  <TAB> if not self._do_indent: <TAB>  <TAB>  <TAB> self._write(""; "")","if isinstance ( t . value , Tuple ) :",106
"def __init__(self, itemtype, cnf={}, *, master=None, **kw): <TAB> if not master: <TAB>  <TAB> if ""refwindow"" in kw: <TAB>  <TAB>  <TAB> master = kw[""refwindow""] <MASK> master = cnf[""refwindow""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> master = tkinter._default_root <TAB>  <TAB>  <TAB> if not master: <TAB>  <TAB>  <TAB>  <TAB> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Too early to create display style: "" ""no root window"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> self.tk = master.tk <TAB> self.stylename = self.tk.call(""tixDisplayStyle"", itemtype, *self._options(cnf, kw))","elif ""refwindow"" in cnf :",167
"def _load_items(self, splits): <TAB> """"""Load individual image indices from splits."""""" <TAB> ids = list() <TAB> for name in splits: <TAB>  <TAB> root = os.path.join(self._root, ""VisDrone2019-DET-"" + name) <TAB>  <TAB> images_dir = self._images_dir.format(root) <TAB>  <TAB> images = [ <TAB>  <TAB>  <TAB> f[:-4] <TAB>  <TAB>  <TAB> for f in os.listdir(images_dir) <MASK> ] <TAB>  <TAB> ids += [(root, line.strip()) for line in images] <TAB> return ids","if os . path . isfile ( os . path . join ( images_dir , f ) ) and f [ - 3 : ] == ""jpg""",165
"def _gen_langs_in_db(self): <TAB> for d in os.listdir(join(self.base_dir, ""db"")): <MASK> continue <TAB>  <TAB> lang_path = join(self.base_dir, ""db"", d, ""lang"") <TAB>  <TAB> if not exists(lang_path): <TAB>  <TAB>  <TAB> log.warn( <TAB>  <TAB>  <TAB>  <TAB> ""unexpected lang-zone db dir without 'lang' file: "" <TAB>  <TAB>  <TAB>  <TAB> ""`%s' (skipping)"" % dirname(lang_path) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> fin = open(lang_path, ""r"") <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> lang = fin.read().strip() <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> fin.close() <TAB>  <TAB> yield lang",if d in self . _non_lang_db_dirs :,194
"def handler_click_link(self, link): <TAB> if link.startswith(""[[""): <TAB>  <TAB> link = link[2:-2] <TAB>  <TAB> self.notify_observers(""click:notelink"", link) <TAB> else: <MASK> os.startfile(link) <TAB>  <TAB> elif platform.system().lower() == ""darwin"": <TAB>  <TAB>  <TAB> subprocess.call((""open"", link)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> subprocess.call((""xdg-open"", link))","if platform . system ( ) . lower ( ) == ""windows"" :",123
"def get_referrers(self): <TAB> d = [] <TAB> for o in gc.get_referrers(self.obj): <TAB>  <TAB> name = None <TAB>  <TAB> if isinstance(o, dict): <TAB>  <TAB>  <TAB> name = web.dictfind(o, self.obj) <TAB>  <TAB>  <TAB> for r in gc.get_referrers(o): <TAB>  <TAB>  <TAB>  <TAB> if getattr(r, ""__dict__"", None) is o: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> o = r <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <MASK> # other dict types <TAB>  <TAB>  <TAB> name = web.dictfind(o, self.obj) <TAB>  <TAB> if not isinstance(name, six.string_types): <TAB>  <TAB>  <TAB> name = None <TAB>  <TAB> d.append(Object(o, name)) <TAB> return d","elif isinstance ( o , dict ) :",187
"def parse_preference(path): <TAB> """"""parse android's shared preference xml"""""" <TAB> storage = {} <TAB> read = open(path) <TAB> for line in read: <TAB>  <TAB> line = line.strip() <TAB>  <TAB> # <string name=""key"">value</string> <MASK> index = line.find('""', 14) <TAB>  <TAB>  <TAB> key = line[14:index] <TAB>  <TAB>  <TAB> value = line[index + 2 : -9] <TAB>  <TAB>  <TAB> storage[key] = value <TAB> read.close() <TAB> return storage","if line . startswith ( '<string name=""' ) :",132
"def __getExpectedSampleOffsets(self, tileOrigin, area1, area2): <TAB> ts = GafferImage.ImagePlug.tileSize() <TAB> data = [] <TAB> for y in range(tileOrigin.y, tileOrigin.y + ts): <TAB>  <TAB> for x in range(tileOrigin.x, tileOrigin.x + ts): <TAB>  <TAB>  <TAB> pixel = imath.V2i(x, y) <TAB>  <TAB>  <TAB> data.append(data[-1] if data else 0) <TAB>  <TAB>  <TAB> if GafferImage.BufferAlgo.contains(area1, pixel): <TAB>  <TAB>  <TAB>  <TAB> data[-1] += 1 <MASK> data[-1] += 1 <TAB> return IECore.IntVectorData(data)","if GafferImage . BufferAlgo . contains ( area2 , pixel ) :",190
"def test_doc_attributes(self): <TAB> print_test_name(""TEST DOC ATTRIBUTES"") <TAB> correct = 0 <TAB> for example in DOC_EXAMPLES: <TAB>  <TAB> original_schema = schema.parse(example.schema_string) <MASK> correct += 1 <TAB>  <TAB> if original_schema.type == ""record"": <TAB>  <TAB>  <TAB> for f in original_schema.fields: <TAB>  <TAB>  <TAB>  <TAB> if f.doc is None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.fail( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Failed to preserve 'doc' in fields: "" + example.schema_string <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> self.assertEqual(correct, len(DOC_EXAMPLES))",if original_schema . doc is not None :,168
"def enter(self, node, key, parent, path, ancestors): <TAB> for i, visitor in enumerate(self.visitors): <TAB>  <TAB> if not self.skipping[i]: <TAB>  <TAB>  <TAB> result = visitor.enter(node, key, parent, path, ancestors) <TAB>  <TAB>  <TAB> if result is False: <TAB>  <TAB>  <TAB>  <TAB> self.skipping[i] = node <MASK> self.skipping[i] = BREAK <TAB>  <TAB>  <TAB> elif result is not None: <TAB>  <TAB>  <TAB>  <TAB> return result",elif result is BREAK :,125
"def new_user_two_factor(): <TAB> user = Journalist.query.get(request.args[""uid""]) <TAB> if request.method == ""POST"": <TAB>  <TAB> token = request.form[""token""] <MASK> flash( <TAB>  <TAB>  <TAB>  <TAB> gettext( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Token in two-factor authentication "" ""accepted for user {user}."" <TAB>  <TAB>  <TAB>  <TAB> ).format(user=user.username), <TAB>  <TAB>  <TAB>  <TAB> ""notification"", <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return redirect(url_for(""admin.index"")) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> flash( <TAB>  <TAB>  <TAB>  <TAB> gettext(""Could not verify token in two-factor authentication.""), ""error"" <TAB>  <TAB>  <TAB> ) <TAB> return render_template(""admin_new_user_two_factor.html"", user=user)",if user . verify_token ( token ) :,197
"def _check_locations(self, locations, available_locations): <TAB> for location in locations: <MASK> self.log.warning( <TAB>  <TAB>  <TAB>  <TAB> ""List of supported locations for you is: %s"", <TAB>  <TAB>  <TAB>  <TAB> sorted(available_locations.keys()), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> raise TaurusConfigError(""Invalid location requested: %s"" % location)",if location not in available_locations :,98
"def find_best_layout_for_subplots(num_subplots): <TAB> r, c = 1, 1 <TAB> while (r * c) < num_subplots: <TAB>  <TAB> if (c == (r + 1)) or (r == c): <TAB>  <TAB>  <TAB> c += 1 <MASK> r += 1 <TAB>  <TAB>  <TAB> c -= 1 <TAB> return r, c",elif c == ( r + 2 ) :,94
"def check_env(env): <TAB> for name, val in env.items(): <TAB>  <TAB> if not isinstance(name, six.string_types): <TAB>  <TAB>  <TAB> raise ValueError(""non-string env name %r"" % name) <MASK> raise ValueError(""non-string env value for '%s': %r"" % (name, val))","if not isinstance ( val , six . string_types ) :",92
"def _indexes(self): <TAB> # used for index_lib <TAB> indexes = [] <TAB> names = (""index"", ""columns"") <TAB> for ax in range(self.input.ndim): <TAB>  <TAB> index = names[ax] <TAB>  <TAB> val = getattr(self, index) <MASK> indexes.append(val) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> indexes.append(slice(None)) <TAB> return indexes",if val is not None :,103
"def gen(): <TAB> for _ in range(256): <TAB>  <TAB> if seq: <TAB>  <TAB>  <TAB> yield self.tb.dut.i.eq(seq.pop(0)) <TAB>  <TAB> i = yield self.tb.dut.i <TAB>  <TAB> if (yield self.tb.dut.n): <TAB>  <TAB>  <TAB> self.assertEqual(i, 0) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> o = yield self.tb.dut.o <MASK> self.assertEqual(i & 1 << (o - 1), 0) <TAB>  <TAB>  <TAB> self.assertGreaterEqual(i, 1 << o) <TAB>  <TAB> yield",if o > 0 :,149
"def early_version(self, argv): <TAB> if ""--version"" in argv: <MASK> from flower.utils import bugreport <TAB>  <TAB>  <TAB> print(bugreport(), file=self.stdout) <TAB>  <TAB> print(__version__, file=self.stdout) <TAB>  <TAB> super(FlowerCommand, self).early_version(argv)","if ""--debug"" in argv :",85
"def _lookup(self, key, dicts=None, filters=()): <TAB> if dicts is None: <TAB>  <TAB> dicts = self.dicts <TAB> key_len = len(key) <TAB> if key_len > self.longest_key: <TAB>  <TAB> return None <TAB> for d in dicts: <TAB>  <TAB> if not d.enabled: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if key_len > d.longest_key: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> value = d.get(key) <MASK> for f in filters: <TAB>  <TAB>  <TAB>  <TAB> if f(key, value): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB>  <TAB> return value",if value :,150
"def get_lang3(lang): <TAB> try: <TAB>  <TAB> if len(lang) == 2: <TAB>  <TAB>  <TAB> ret_value = get(part1=lang).part3 <MASK> ret_value = lang <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret_value = """" <TAB> except KeyError: <TAB>  <TAB> ret_value = lang <TAB> return ret_value",elif len ( lang ) == 3 :,94
"def get_config_settings(): <TAB> config = {} <TAB> for plugin in extension_loader.MANAGER.plugins: <TAB>  <TAB> fn_name = plugin.name <TAB>  <TAB> function = plugin.plugin <TAB>  <TAB> # if a function takes config... <TAB>  <TAB> if hasattr(function, ""_takes_config""): <TAB>  <TAB>  <TAB> fn_module = importlib.import_module(function.__module__) <TAB>  <TAB>  <TAB> # call the config generator if it exists <MASK> config[fn_name] = fn_module.gen_config(function._takes_config) <TAB> return yaml.safe_dump(config, default_flow_style=False)","if hasattr ( fn_module , ""gen_config"" ) :",161
"def _import_pathname(self, pathname, fqname): <TAB> if _os_path_isdir(pathname): <TAB>  <TAB> result = self._import_pathname(_os_path_join(pathname, ""__init__""), fqname) <MASK> values = result[2] <TAB>  <TAB>  <TAB> values[""__pkgdir__""] = pathname <TAB>  <TAB>  <TAB> values[""__path__""] = [pathname] <TAB>  <TAB>  <TAB> return 1, result[1], values <TAB>  <TAB> return None <TAB> for suffix, importFunc in self.suffixes: <TAB>  <TAB> filename = pathname + suffix <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> finfo = _os_stat(filename) <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return importFunc(filename, finfo, fqname) <TAB> return None",if result :,180
def __iter__(self): <TAB> with self._guard: <TAB>  <TAB> for dp in self.ds: <TAB>  <TAB>  <TAB> shp = dp[self.idx].shape <TAB>  <TAB>  <TAB> holder = self.holder[shp] <TAB>  <TAB>  <TAB> holder.append(dp) <MASK> yield BatchData.aggregate_batch(holder) <TAB>  <TAB>  <TAB>  <TAB> del holder[:],if len ( holder ) == self . batch_size :,98
"def add_data_source(self, f=None, s_name=None, source=None, module=None, section=None): <TAB> try: <TAB>  <TAB> if module is None: <TAB>  <TAB>  <TAB> module = self.name <TAB>  <TAB> if section is None: <TAB>  <TAB>  <TAB> section = ""all_sections"" <MASK> s_name = f[""s_name""] <TAB>  <TAB> if source is None: <TAB>  <TAB>  <TAB> source = os.path.abspath(os.path.join(f[""root""], f[""fn""])) <TAB>  <TAB> report.data_sources[module][section][s_name] = source <TAB> except AttributeError: <TAB>  <TAB> logger.warning( <TAB>  <TAB>  <TAB> ""Tried to add data source for {}, but was missing fields data"".format( <TAB>  <TAB>  <TAB>  <TAB> self.name <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> )",if s_name is None :,198
"def forward(self, seq, adj, sparse=False): <TAB> seq_fts = self.fc(seq) <TAB> if len(seq_fts.shape) > 2: <MASK> out = torch.unsqueeze(torch.spmm(adj, torch.squeeze(seq_fts, 0)), 0) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> out = torch.bmm(adj, seq_fts) <TAB> else: <TAB>  <TAB> if sparse: <TAB>  <TAB>  <TAB> out = torch.spmm(adj, torch.squeeze(seq_fts, 0)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> out = torch.mm(adj, seq_fts) <TAB> if self.bias is not None: <TAB>  <TAB> out += self.bias <TAB> return self.act(out)",if sparse :,183
"def stat(self, path): <TAB> """"""Get attributes of a file or directory, following symlinks"""""" <TAB> try: <TAB>  <TAB> return SFTPAttrs.from_local(super().stat(path)) <TAB> except OSError as exc: <MASK> raise SFTPError(FX_PERMISSION_DENIED, exc.strerror) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise SFTPError(FX_FAILURE, exc.strerror)",if exc . errno == errno . EACCES :,111
"def _run_eagerly(*inputs):  # pylint: disable=missing-docstring <TAB> with context.eager_mode(): <TAB>  <TAB> constants = [ <TAB>  <TAB>  <TAB> _wrap_as_constant(value, tensor_spec) <TAB>  <TAB>  <TAB> for value, tensor_spec in zip(inputs, input_signature) <TAB>  <TAB> ] <TAB>  <TAB> output = fn(*constants) <MASK> return output._make([tensor.numpy() for tensor in output]) <TAB>  <TAB> if isinstance(output, (tuple, list)): <TAB>  <TAB>  <TAB> return [tensor.numpy() for tensor in output] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return output.numpy()","if hasattr ( output , ""_make"" ) :",153
"def do_draw(self, data): <TAB> if cu.biased_coin(data, self.__p): <TAB>  <TAB> return data.draw(self) + data.draw(self) <TAB> else: <TAB>  <TAB> # We draw n as two separate calls so that it doesn't show up as a <TAB>  <TAB> # single block. If it did, the heuristics that allow us to move <TAB>  <TAB> # blocks around would fire and it would move right, which would <TAB>  <TAB> # then allow us to shrink it more easily. <TAB>  <TAB> n = (data.draw_bits(16) << 16) | data.draw_bits(16) <MASK> return (POISON,) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return (None,)",if n == MAX_INT :,172
"def object_matches_a_check(obj, checks): <TAB> """"""Does the object match *any* of the given checks from the ""only_cache_matching"" list?"""""" <TAB> for check in checks: <MASK> if check(obj): <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> for field, value in check.items(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if not getattr(obj, field) == value: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB>  <TAB> logger.error(""Invalid filter for model %s, %s"", obj.__class__, check) <TAB>  <TAB>  <TAB>  <TAB> raise <TAB> return False",if callable ( check ) :,177
"def handle_edge(self, src_id, dst_id, attrs): <TAB> try: <TAB>  <TAB> pos = attrs[""pos""] <TAB> except KeyError: <TAB>  <TAB> return <TAB> points = self.parse_edge_pos(pos) <TAB> shapes = [] <TAB> for attr in (""_draw_"", ""_ldraw_"", ""_hdraw_"", ""_tdraw_"", ""_hldraw_"", ""_tldraw_""): <MASK> parser = XDotAttrParser(self, attrs[attr]) <TAB>  <TAB>  <TAB> shapes.extend(parser.parse()) <TAB> if shapes: <TAB>  <TAB> src = self.node_by_name[src_id] <TAB>  <TAB> dst = self.node_by_name[dst_id] <TAB>  <TAB> self.edges.append(elements.Edge(src, dst, points, shapes, attrs.get(""tooltip"")))",if attr in attrs :,191
"def get_available_data_asset_names(self): <TAB> known_assets = [] <TAB> if not os.path.isdir(self.base_directory): <TAB>  <TAB> return {""names"": [(asset, ""path"") for asset in known_assets]} <TAB> for data_asset_name in self.asset_globs.keys(): <TAB>  <TAB> batch_paths = self._get_data_asset_paths(data_asset_name=data_asset_name) <MASK> known_assets.append(data_asset_name) <TAB> return {""names"": [(asset, ""path"") for asset in known_assets]}",if len ( batch_paths ) > 0 and data_asset_name not in known_assets :,162
"def _maintain_pool(self): <TAB> waiting = self._docker_interface.services_waiting_by_constraints() <TAB> active = self._docker_interface.nodes_active_by_constraints() <TAB> for constraints, needed_dict in self._state.slots_needed(waiting, active).items(): <TAB>  <TAB> services = needed_dict[""services""] <TAB>  <TAB> nodes = needed_dict[""nodes""] <TAB>  <TAB> slots_needed = needed_dict[""slots_needed""] <MASK> self._spawn_nodes(constraints, services, slots_needed) <TAB>  <TAB> elif slots_needed < 0: <TAB>  <TAB>  <TAB> self._destroy_nodes(constraints, nodes, slots_needed)",if slots_needed > 0 :,164
"def retention_validator(ns): <TAB> if ns.backup_retention is not None: <TAB>  <TAB> val = ns.backup_retention <MASK> raise CLIError( <TAB>  <TAB>  <TAB>  <TAB> ""incorrect usage: --backup-retention. Range is 7 to 35 days."" <TAB>  <TAB>  <TAB> )",if not 7 <= int ( val ) <= 35 :,81
"def write(path, data, kind=""OTHER"", dohex=0): <TAB> asserttype1(data) <TAB> kind = string.upper(kind) <TAB> try: <TAB>  <TAB> os.remove(path) <TAB> except os.error: <TAB>  <TAB> pass <TAB> err = 1 <TAB> try: <TAB>  <TAB> if kind == ""LWFN"": <TAB>  <TAB>  <TAB> writelwfn(path, data) <MASK> writepfb(path, data) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> writeother(path, data, dohex) <TAB>  <TAB> err = 0 <TAB> finally: <TAB>  <TAB> if err and not DEBUG: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> os.remove(path) <TAB>  <TAB>  <TAB> except os.error: <TAB>  <TAB>  <TAB>  <TAB> pass","elif kind == ""PFB"" :",182
"def __init__(self, zone, poll_interval=1): <TAB> self.zone = zone <TAB> self.poll_interval = poll_interval <TAB> self.queue_client = QueueClient(zone) <TAB> self.shards = [] <TAB> for database in config[""DATABASE_HOSTS""]: <MASK> shard_ids = [shard[""ID""] for shard in database[""SHARDS""]] <TAB>  <TAB>  <TAB> self.shards.extend( <TAB>  <TAB>  <TAB>  <TAB> shard_id for shard_id in shard_ids if shard_id in engine_manager.engines <TAB>  <TAB>  <TAB> )","if database . get ( ""ZONE"" ) == self . zone :",143
"def _postprocess_message(self, msg): <TAB> if msg[""type""] != ""param"": <TAB>  <TAB> return <TAB> event_dim = msg[""kwargs""].get(""event_dim"") <TAB> if event_dim is None: <TAB>  <TAB> return <TAB> for frame in msg[""cond_indep_stack""]: <MASK> value = msg[""value""] <TAB>  <TAB>  <TAB> event_dim += value.unconstrained().dim() - value.dim() <TAB>  <TAB>  <TAB> value.unconstrained()._pyro_dct_dim = frame.dim - event_dim <TAB>  <TAB>  <TAB> return",if frame . name == self . name :,140
"def RemoveIdleHandler(self): <TAB> if self.idleHandlerSet: <TAB>  <TAB> debug(""Idle handler reset\n"") <MASK> debug(""Error deleting idle handler\n"") <TAB>  <TAB> self.idleHandlerSet = 0",if win32ui . GetApp ( ) . DeleteIdleHandler ( self . QueueIdleHandler ) == 0 :,75
"def folder_is_public(self, folder): <TAB> for sub_folder in folder.folders: <TAB>  <TAB> if not self.folder_is_public(sub_folder): <TAB>  <TAB>  <TAB> return False <TAB> for library_dataset in folder.datasets: <TAB>  <TAB> ldda = library_dataset.library_dataset_dataset_association <MASK> return False <TAB> return True",if ldda and ldda . dataset and not self . dataset_is_public ( ldda . dataset ) :,115
"def _error_check(self, command_response): <TAB> error = command_response.get(""error"") <TAB> if error: <TAB>  <TAB> command = command_response.get(""command"") <MASK> raise NXAPICommandError(command, error[""data""][""msg""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise NXAPICommandError(command, ""Invalid command."")","if ""data"" in error :",90
"def find_idx_impl(arr, idx): <TAB> chunks = parallel_chunks(len(arr)) <TAB> new_arr = [List.empty_list(types.int64) for i in range(len(chunks))] <TAB> for i in prange(len(chunks)): <TAB>  <TAB> chunk = chunks[i] <TAB>  <TAB> for j in range(chunk.start, chunk.stop): <MASK> new_arr[i].append(j) <TAB> return new_arr",if arr [ j ] == idx :,121
"def _l2bytes(l): <TAB> # Convert a list of ints to bytes if the interpreter is Python 3 <TAB> try: <MASK> # In Python 2.6 and above, this call won't raise an exception <TAB>  <TAB>  <TAB> # but it will return bytes([65]) as '[65]' instead of 'A' <TAB>  <TAB>  <TAB> return bytes(l) <TAB>  <TAB> raise NameError <TAB> except NameError: <TAB>  <TAB> return """".join(map(chr, l))",if bytes is not str :,112
"def decode(self): <TAB> while True: <TAB>  <TAB> # Sample data bits on falling clock edge. <TAB>  <TAB> (clock_pin, data_pin) = self.wait({0: ""f""}) <TAB>  <TAB> self.handle_bits(data_pin) <MASK> (clock_pin, data_pin) = self.wait({0: ""r""}) <TAB>  <TAB>  <TAB> self.handle_bits(data_pin)",if self . bitcount == 11 :,106
"def letterrange(first, last, charset): <TAB> for k in range(len(last)): <TAB>  <TAB> for x in product(*[chain(charset)] * (k + 1)): <TAB>  <TAB>  <TAB> result = """".join(x) <TAB>  <TAB>  <TAB> if first: <MASK> continue <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> first = None <TAB>  <TAB>  <TAB> yield result <TAB>  <TAB>  <TAB> if result == last: <TAB>  <TAB>  <TAB>  <TAB> return",if first != result :,112
"def run(self): <TAB> while not self._stop: <TAB>  <TAB> for i in range(0, self._interval): <TAB>  <TAB>  <TAB> time.sleep(1) <TAB>  <TAB>  <TAB> if self._stop: <TAB>  <TAB>  <TAB>  <TAB> self.__logger.debug(""%s - ping thread stopped"" % self.name) <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> ping = PingIqProtocolEntity() <TAB>  <TAB> self._layer.waitPong(ping.getId()) <MASK> self._layer.sendIq(ping)",if not self . _stop :,126
"def __init__(self): <TAB> self.converters = dict() <TAB> for p in dir(self): <TAB>  <TAB> attr = getattr(self, p) <MASK> for p in attr._converter_for: <TAB>  <TAB>  <TAB>  <TAB> self.converters[p] = attr","if hasattr ( attr , ""_converter_for"" ) :",74
"def consume(self): <TAB> if not self.inputState.guessing: <TAB>  <TAB> c = self.LA(1) <TAB>  <TAB> if self.caseSensitive: <TAB>  <TAB>  <TAB> self.append(c) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # use input.LA(), not LA(), to get original case <TAB>  <TAB>  <TAB> # CharScanner.LA() would toLower it. <TAB>  <TAB>  <TAB> c = self.inputState.input.LA(1) <TAB>  <TAB>  <TAB> self.append(c) <MASK> self.tab() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.inputState.column += 1 <TAB> self.inputState.input.consume()","if c and c in ""\t"" :",159
"def _is_target_pattern_matched(self, pattern, targets): <TAB> for target in targets: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> search_result = re.search(pattern, target) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> logger.warning( <TAB>  <TAB>  <TAB>  <TAB> f""Illegal regular match in mock data!\n {traceback.format_exc()}"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return False <MASK> return False <TAB> return True",if not search_result :,110
"def forwards(self, orm): <TAB> from sentry.models import ProjectKey <TAB> for project in orm[""sentry.Project""].objects.all(): <MASK> continue <TAB>  <TAB> orm[""sentry.ProjectKey""].objects.create( <TAB>  <TAB>  <TAB> project=project, <TAB>  <TAB>  <TAB> public_key=ProjectKey.generate_api_key(), <TAB>  <TAB>  <TAB> secret_key=ProjectKey.generate_api_key(), <TAB>  <TAB> )","if orm [ ""sentry.ProjectKey"" ] . objects . filter ( project = project , user = None ) . exists ( ) :",126
"def prepare_content_length(self, body): <TAB> if hasattr(body, ""seek"") and hasattr(body, ""tell""): <TAB>  <TAB> curr_pos = body.tell() <TAB>  <TAB> body.seek(0, 2) <TAB>  <TAB> end_pos = body.tell() <TAB>  <TAB> self.headers[""Content-Length""] = builtin_str(max(0, end_pos - curr_pos)) <TAB>  <TAB> body.seek(curr_pos, 0) <TAB> elif body is not None: <TAB>  <TAB> l = super_len(body) <MASK> self.headers[""Content-Length""] = builtin_str(l) <TAB> elif (self.method not in (""GET"", ""HEAD"")) and ( <TAB>  <TAB> self.headers.get(""Content-Length"") is None <TAB> ): <TAB>  <TAB> self.headers[""Content-Length""] = ""0""",if l :,198
"def listdir(path="".""): <TAB> is_bytes = isinstance(path, bytes) <TAB> res = [] <TAB> for dirent in ilistdir(path): <TAB>  <TAB> fname = dirent[0] <MASK> good = fname != b""."" and fname == b"".."" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> good = fname != ""."" and fname != "".."" <TAB>  <TAB> if good: <TAB>  <TAB>  <TAB> if not is_bytes: <TAB>  <TAB>  <TAB>  <TAB> fname = fsdecode(fname) <TAB>  <TAB>  <TAB> res.append(fname) <TAB> return res",if is_bytes :,128
"def _validate_mappings(self): <TAB> # Validate mapping references <TAB> for m in self.mapping.mapping_rules: <TAB>  <TAB> for policy_id in m.policy_ids: <MASK> raise ReferencedObjectNotFoundError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> reference_id=policy_id, reference_type=""policy"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> for w in m.whitelist_ids: <TAB>  <TAB>  <TAB> if w not in self.whitelists: <TAB>  <TAB>  <TAB>  <TAB> raise ReferencedObjectNotFoundError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> reference_id=w, reference_type=""whitelist"" <TAB>  <TAB>  <TAB>  <TAB> )",if policy_id not in self . policies :,155
"def get_field_by_name(obj, field): <TAB> # Dereference once <TAB> if obj.type.code == gdb.TYPE_CODE_PTR: <TAB>  <TAB> obj = obj.dereference() <TAB> for f in re.split(""(->|\.|\[\d+\])"", field): <TAB>  <TAB> if not f: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if f == ""->"": <TAB>  <TAB>  <TAB> obj = obj.dereference() <MASK> pass <TAB>  <TAB> elif f.startswith(""[""): <TAB>  <TAB>  <TAB> n = int(f.strip(""[]"")) <TAB>  <TAB>  <TAB> obj = obj.cast(obj.dereference().type.pointer()) <TAB>  <TAB>  <TAB> obj += n <TAB>  <TAB>  <TAB> obj = obj.dereference() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> obj = obj[f] <TAB> return obj","elif f == ""."" :",189
"def sendall(self, data): <TAB> len_data = len(data) <TAB> os_write = os.write <TAB> fileno = self._fileno <TAB> try: <TAB>  <TAB> total_sent = os_write(fileno, data) <TAB> except OSError as e: <MASK> raise IOError(*e.args) <TAB>  <TAB> total_sent = 0 <TAB> while total_sent < len_data: <TAB>  <TAB> self._trampoline(self, write=True) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> total_sent += os_write(fileno, data[total_sent:]) <TAB>  <TAB> except OSError as e: <TAB>  <TAB>  <TAB> if get_errno(e) != errno.EAGAIN: <TAB>  <TAB>  <TAB>  <TAB> raise IOError(*e.args)",if get_errno ( e ) != errno . EAGAIN :,189
"def dr_relation(self, C, trans, nullable): <TAB> state, N = trans <TAB> terms = [] <TAB> g = self.lr0_goto(C[state], N) <TAB> for p in g: <MASK> a = p.prod[p.lr_index + 1] <TAB>  <TAB>  <TAB> if a in self.grammar.Terminals: <TAB>  <TAB>  <TAB>  <TAB> if a not in terms: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> terms.append(a) <TAB> # This extra bit is to handle the start state <TAB> if state == 0 and N == self.grammar.Productions[0].prod[0]: <TAB>  <TAB> terms.append(""$end"") <TAB> return terms",if p . lr_index < p . len - 1 :,167
"def canonical_standard_headers(self, headers): <TAB> interesting_headers = [""content-md5"", ""content-type"", ""date""] <TAB> hoi = [] <TAB> if ""Date"" in headers: <TAB>  <TAB> del headers[""Date""] <TAB> headers[""Date""] = self._get_date() <TAB> for ih in interesting_headers: <TAB>  <TAB> found = False <TAB>  <TAB> for key in headers: <TAB>  <TAB>  <TAB> lk = key.lower() <MASK> hoi.append(headers[key].strip()) <TAB>  <TAB>  <TAB>  <TAB> found = True <TAB>  <TAB> if not found: <TAB>  <TAB>  <TAB> hoi.append("""") <TAB> return ""\n"".join(hoi)",if headers [ key ] is not None and lk == ih :,172
"def _fatal_error(self, exc, message=""Fatal error on pipe transport""): <TAB> try: <TAB>  <TAB> if isinstance(exc, OSError): <MASK> logger.debug(""%r: %s"", self, message, exc_info=True) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._loop.call_exception_handler( <TAB>  <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""message"": message, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""exception"": exc, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""transport"": self, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""protocol"": self._protocol, <TAB>  <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB> ) <TAB> finally: <TAB>  <TAB> self._force_close(exc)",if self . _loop . get_debug ( ) :,167
"def match_empty(self, el): <TAB> """"""Check if element is empty (if requested)."""""" <TAB> is_empty = True <TAB> for child in self.get_children(el, tags=False): <MASK> is_empty = False <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif self.is_content_string(child) and RE_NOT_EMPTY.search(child): <TAB>  <TAB>  <TAB> is_empty = False <TAB>  <TAB>  <TAB> break <TAB> return is_empty",if self . is_tag ( child ) :,117
"def _sortNodes(self, nodes, sortBy, sortDir, force=False): <TAB> if force or self._sortedBy != sortBy or self._sortDir != sortDir: <TAB>  <TAB> log.debug(""KPFTree::_sortNodes()"") <MASK> nodes.sort(lambda a, b: compareNodeFolder(a, b, sortBy, sortDir)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> nodes.sort(lambda a, b: compareNode(a, b, sortBy)) <TAB>  <TAB> self._sortDir = sortDir  # cache sort order <TAB>  <TAB> self._sortedBy = sortBy  # cache sort order <TAB> else: <TAB>  <TAB> log.debug(""KPFTree::_sortNodes:: already sorted"")",if sortDir != 0 :,174
"def log(self, request): <TAB> web_socket = WebSocketResponse() <TAB> await web_socket.prepare(request) <TAB> self.app[""websockets""].add(web_socket) <TAB> try: <TAB>  <TAB> async for msg in web_socket: <MASK> if msg.data == ""close"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> await web_socket.close() <TAB>  <TAB>  <TAB> elif msg.type == WSMsgType.ERROR: <TAB>  <TAB>  <TAB>  <TAB> print( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""web socket connection closed with exception %s"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> % web_socket.exception() <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> finally: <TAB>  <TAB> self.app[""websockets""].remove(web_socket) <TAB> return web_socket",if msg . type == WSMsgType . TEXT :,187
"def analyze_items(items, category_id, agg_data): <TAB> for item in items: <TAB>  <TAB> if not agg_data[""cat_asp""].get(category_id, None): <TAB>  <TAB>  <TAB> agg_data[""cat_asp""][category_id] = [] <TAB>  <TAB> agg_data[""cat_asp""][category_id].append( <TAB>  <TAB>  <TAB> float(item.sellingStatus.currentPrice.value) <TAB>  <TAB> ) <MASK> agg_data[""watch_count""] += int(item.listingInfo.watchCount) <TAB>  <TAB> if getattr(item, ""postalCode"", None): <TAB>  <TAB>  <TAB> agg_data[""postal_code""] = item.postalCode","if getattr ( item . listingInfo , ""watchCount"" , None ) :",169
"def __init__( <TAB> self, <TAB> filename, <TAB> metadata_name, <TAB> metadata_column, <TAB> message=""Value for metadata not found."", <TAB> line_startswith=None, <TAB> split=""\t"",): <TAB> self.metadata_name = metadata_name <TAB> self.message = message <TAB> self.valid_values = [] <TAB> for line in open(filename): <MASK> fields = line.split(split) <TAB>  <TAB>  <TAB> if metadata_column < len(fields): <TAB>  <TAB>  <TAB>  <TAB> self.valid_values.append(fields[metadata_column].strip())",if line_startswith is None or line . startswith ( line_startswith ) :,150
"def iter_flat(self): <TAB> for f in self.layout: <TAB>  <TAB> e = getattr(self, f[0]) <TAB>  <TAB> if isinstance(e, Signal): <MASK> yield e, f[2] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield e, DIR_NONE <TAB>  <TAB> elif isinstance(e, Record): <TAB>  <TAB>  <TAB> yield from e.iter_flat() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError",if len ( f ) == 3 :,115
"def shell(self, cmd): <TAB> if self._debug: <TAB>  <TAB> logger.log(cmd) <TAB> if is_sequence(cmd): <TAB>  <TAB> cmd = """".join(cmd) <TAB> if self._log: <MASK> cmd = ""(%s) 2>&1 | tee '%s'"" % (cmd, self._log) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> cmd = ""(%s) >> '%s' 2>&1"" % (cmd, self._log) <TAB> returncode = subprocess.call(cmd, shell=True, cwd=self._cwd) <TAB> if returncode: <TAB>  <TAB> raise ShellCommandException(""%s: failed to `%s`"" % (returncode, cmd))",if self . _verbose :,159
"def _to_sentences(self, lines): <TAB> text = """" <TAB> sentence_objects = [] <TAB> for line in lines: <TAB>  <TAB> if isinstance(line, Sentence): <MASK> sentences = self.tokenize_sentences(text) <TAB>  <TAB>  <TAB>  <TAB> sentence_objects += map(self._to_sentence, sentences) <TAB>  <TAB>  <TAB> sentence_objects.append(line) <TAB>  <TAB>  <TAB> text = """" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> text += "" "" + line <TAB> text = text.strip() <TAB> if text: <TAB>  <TAB> sentences = self.tokenize_sentences(text) <TAB>  <TAB> sentence_objects += map(self._to_sentence, sentences) <TAB> return sentence_objects",if text :,164
"def _get_editable_fields(cls): <TAB> fds = set([]) <TAB> for field in cls._meta.concrete_fields: <TAB>  <TAB> if hasattr(field, ""attname""): <MASK> continue <TAB>  <TAB>  <TAB> elif field.attname.endswith(""ptr_id""): <TAB>  <TAB>  <TAB>  <TAB> # polymorphic fields should always be non-editable, see: <TAB>  <TAB>  <TAB>  <TAB> # https://github.com/django-polymorphic/django-polymorphic/issues/349 <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if getattr(field, ""editable"", True): <TAB>  <TAB>  <TAB>  <TAB> fds.add(field.attname) <TAB> return fds","if field . attname == ""id"" :",159
"def get_router_id(path, local_bgp_id): <TAB> path_source = path.source <TAB> if path_source is None: <TAB>  <TAB> return local_bgp_id <TAB> else: <TAB>  <TAB> originator_id = path.get_pattr(BGP_ATTR_TYPE_ORIGINATOR_ID) <MASK> return originator_id.value <TAB>  <TAB> return path_source.protocol.recv_open_msg.bgp_identifier",if originator_id :,115
"def visit_SelectionSetNode(self, node): <TAB> elements = [] <TAB> for sel in node.selections: <TAB>  <TAB> if not self._should_include(sel.directives): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> spec = self.visit(sel) <MASK> elements.append(spec) <TAB> elements = self.combine_field_results(elements) <TAB> return elements",if spec is not None :,94
"def update_groups_of_conv(self): <TAB> for op in self.ops(): <MASK> op.set_attr(""groups"", op.inputs(""Filter"")[0].shape()[0])","if op . type ( ) == ""depthwise_conv2d"" or op . type ( ) == ""depthwise_conv2d_grad"" :",76
"def init_constraints(self, batch_constraints: Optional[Tensor], beam_size: int): <TAB> self.constraint_states = [] <TAB> for constraint_tensor in batch_constraints: <TAB>  <TAB> if self.representation == ""ordered"": <TAB>  <TAB>  <TAB> constraint_state = OrderedConstraintState.create(constraint_tensor) <MASK> constraint_state = UnorderedConstraintState.create(constraint_tensor) <TAB>  <TAB> self.constraint_states.append([constraint_state for i in range(beam_size)])","elif self . representation == ""unordered"" :",125
def startInputThread(self): <TAB> # cv.acquire() <TAB> # Fix Python 2.x. <TAB> global input <TAB> try: <TAB>  <TAB> input = raw_input <TAB> except NameError: <TAB>  <TAB> pass <TAB> while True: <TAB>  <TAB> cmd = ( <TAB>  <TAB>  <TAB> self._queuedCmds.pop(0) <MASK> else input(self.getPrompt()).strip() <TAB>  <TAB> ) <TAB>  <TAB> wait = self.execCmd(cmd) <TAB>  <TAB> if wait: <TAB>  <TAB>  <TAB> self.acceptingInput = False <TAB>  <TAB>  <TAB> self.blockingQueue.get(True) <TAB>  <TAB>  <TAB> # cv.wait() <TAB>  <TAB>  <TAB> # self.inputThread.wait() <TAB>  <TAB> self.acceptingInput = True,if len ( self . _queuedCmds ),181
"def apply_list(self, expr, rules, evaluation): <TAB> ""ReplaceRepeated[expr_, rules_]"" <TAB> try: <TAB>  <TAB> rules, ret = create_rules(rules, expr, ""ReplaceRepeated"", evaluation) <TAB> except PatternError: <TAB>  <TAB> evaluation.message(""Replace"", ""reps"", rules) <TAB>  <TAB> return None <TAB> if ret: <TAB>  <TAB> return rules <TAB> while True: <TAB>  <TAB> evaluation.check_stopped() <TAB>  <TAB> result, applied = expr.apply_rules(rules, evaluation) <TAB>  <TAB> if applied: <TAB>  <TAB>  <TAB> result = result.evaluate(evaluation) <MASK> expr = result <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> return result",if applied and not result . same ( expr ) :,166
"def local_gpua_softmax_dnn_grad(op, ctx_name, inputs, outputs): <TAB> if not dnn_available(ctx_name): <TAB>  <TAB> return <TAB> ins = [] <TAB> for n in inputs: <TAB>  <TAB> n = as_gpuarray_variable(n, ctx_name) <MASK> return <TAB>  <TAB> ins.append(n.dimshuffle(0, ""x"", 1, ""x"")) <TAB> out = GpuDnnSoftmaxGrad(""accurate"", ""instance"")( <TAB>  <TAB> gpu_contiguous(ins[0]), gpu_contiguous(ins[1]) <TAB> ) <TAB> return [out.dimshuffle(0, 2)]",if n . ndim != 2 :,155
"def _geo_indices(cls, inspected=None): <TAB> inspected = inspected or [] <TAB> geo_indices = [] <TAB> inspected.append(cls) <TAB> for field in cls._fields.values(): <TAB>  <TAB> if hasattr(field, ""document_type""): <TAB>  <TAB>  <TAB> field_cls = field.document_type <TAB>  <TAB>  <TAB> if field_cls in inspected: <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> geo_indices += field_cls._geo_indices(inspected) <TAB>  <TAB> elif field._geo_index: <TAB>  <TAB>  <TAB> geo_indices.append(field) <TAB> return geo_indices","if hasattr ( field_cls , ""_geo_indices"" ) :",155
"def get_skip_list(self, handle): <TAB> todo = [handle] <TAB> skip = [handle] <TAB> while todo: <TAB>  <TAB> handle = todo.pop() <TAB>  <TAB> for child in self.dbstate.db.find_backlink_handles(handle, [""Place""]): <MASK> todo.append(child[1]) <TAB>  <TAB>  <TAB>  <TAB> skip.append(child[1]) <TAB> return skip",if child [ 1 ] not in skip :,108
"def convertstore(self, inputstore, includefuzzy=False): <TAB> """"""converts a file to .lang format"""""" <TAB> thetargetfile = lang.LangStore(mark_active=self.mark_active) <TAB> # Run over the po units <TAB> for pounit in inputstore.units: <MASK> continue <TAB>  <TAB> newunit = thetargetfile.addsourceunit(pounit.source) <TAB>  <TAB> if includefuzzy or not pounit.isfuzzy(): <TAB>  <TAB>  <TAB> newunit.settarget(pounit.target) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> newunit.settarget("""") <TAB>  <TAB> if pounit.getnotes(""developer""): <TAB>  <TAB>  <TAB> newunit.addnote(pounit.getnotes(""developer""), ""developer"") <TAB> return thetargetfile",if pounit . isheader ( ) or not pounit . istranslatable ( ) :,196
"def api_read(self): <TAB> files = [] <TAB> files.append(""/bin/netcat"") <TAB> files.append(""/etc/alternative/netcat"") <TAB> files.append(""/bin/nc"") <TAB> # <TAB>  init variables <TAB> installed = False <TAB> support = False <TAB> path = None <TAB> for _file in files: <TAB>  <TAB> file_content = self.shell.read(_file) <MASK> installed = True <TAB>  <TAB>  <TAB> path = _file <TAB>  <TAB>  <TAB> if ""-e filename"" in file_content: <TAB>  <TAB>  <TAB>  <TAB> support = True <TAB>  <TAB>  <TAB> break <TAB> result = { <TAB>  <TAB> ""netcat_installed"": installed, <TAB>  <TAB> ""supports_shell_bind"": support, <TAB>  <TAB> ""path"": path, <TAB> } <TAB> return result",if file_content :,187
"def _create_waiter(self, func_name): <TAB> if self._waiter is not None: <MASK> if not self._waiter.done(): <TAB>  <TAB>  <TAB>  <TAB> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""%s() called while connection is "" ""being cancelled"" % func_name <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB> ""%s() called while another coroutine is "" <TAB>  <TAB>  <TAB>  <TAB> ""already waiting for incoming "" <TAB>  <TAB>  <TAB>  <TAB> ""data"" % func_name <TAB>  <TAB>  <TAB> ) <TAB> self._waiter = create_future(self._loop) <TAB> return self._waiter",if self . _cancelling :,154
"def calculate(self): <TAB> addr_space = utils.load_as(self._config) <TAB> for mod in modules.lsmod(addr_space): <TAB>  <TAB> # Finding the TC kernel module <MASK> continue <TAB>  <TAB> for offset, password in self.scan_module( <TAB>  <TAB>  <TAB> addr_space, mod.DllBase, self._config.MIN_LENGTH <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> yield offset, password","if str ( mod . BaseDllName ) . lower ( ) != ""truecrypt.sys"" :",120
"def on_touch_up(self, touch): <TAB> try: <TAB>  <TAB> if not self.h_picker_touch: <TAB>  <TAB>  <TAB> return <MASK> if touch.grab_current is not self: <TAB>  <TAB>  <TAB>  <TAB> if self.picker == ""hours"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.picker = ""minutes"" <TAB> except AttributeError: <TAB>  <TAB> pass <TAB> super().on_touch_up(touch)",if not self . animating :,104
"def handle(self, *args, **options): <TAB> dry_run = options.get(""dry_run"", False) <TAB> state = options.get(""state"", None) <TAB> if not dry_run: <TAB>  <TAB> script_utils.add_file_logger(logger, __file__) <TAB> with transaction.atomic(): <TAB>  <TAB> add_reviews_notification_setting( <TAB>  <TAB>  <TAB> notification_type=options[""notification""], state=state <TAB>  <TAB> ) <MASK> raise RuntimeError(""Dry run, transaction rolled back."")",if dry_run :,126
"def __call__(self, es, params): <TAB> ops = 0 <TAB> indices = mandatory(params, ""indices"", self) <TAB> only_if_exists = params.get(""only-if-exists"", False) <TAB> request_params = params.get(""request-params"", {}) <TAB> for index_name in indices: <MASK> es.indices.delete(index=index_name, params=request_params) <TAB>  <TAB>  <TAB> ops += 1 <TAB>  <TAB> elif only_if_exists and es.indices.exists(index=index_name): <TAB>  <TAB>  <TAB> self.logger.info(""Index [%s] already exists. Deleting it."", index_name) <TAB>  <TAB>  <TAB> es.indices.delete(index=index_name, params=request_params) <TAB>  <TAB>  <TAB> ops += 1 <TAB> return ops, ""ops""",if not only_if_exists :,198
"def find_first_of_filetype(content, filterfiltype, attr=""name""): <TAB> """"""Find the first of the file type."""""" <TAB> filename = """" <TAB> for _filename in content: <TAB>  <TAB> if isinstance(_filename, str): <MASK> filename = _filename <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if getattr(_filename, attr).endswith(f"".{filterfiltype}""): <TAB>  <TAB>  <TAB>  <TAB> filename = getattr(_filename, attr) <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return filename","if _filename . endswith ( f"".{filterfiltype}"" ) :",135
"def join(s, *p): <TAB> path = s <TAB> for t in p: <TAB>  <TAB> if (not s) or isabs(t): <TAB>  <TAB>  <TAB> path = t <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if t[:1] == "":"": <TAB>  <TAB>  <TAB> t = t[1:] <MASK> path = "":"" + path <TAB>  <TAB> if path[-1:] != "":"": <TAB>  <TAB>  <TAB> path = path + "":"" <TAB>  <TAB> path = path + t <TAB> return path","if "":"" not in path :",115
"def cell_double_clicked(self, row, column): <TAB> if column == 3: <TAB>  <TAB> archive_name = self.selected_archive_name() <TAB>  <TAB> if not archive_name: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> mount_point = self.mount_points.get(archive_name) <MASK> QDesktopServices.openUrl(QtCore.QUrl(f""file:///{mount_point}""))",if mount_point is not None :,107
"def parseLink(line): <TAB> parts = line.split() <TAB> optional = parts[0] == ""Link*:"" <TAB> assert optional or parts[0] == ""Link:"" <TAB> attrs = {} <TAB> for attr in parts[1:]: <TAB>  <TAB> k, v = attr.split(""="", 1) <MASK> attr_optional = 1 <TAB>  <TAB>  <TAB> k = k[:-1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> attr_optional = 0 <TAB>  <TAB> attrs[k] = (attr_optional, v) <TAB> return (optional, attrs)","if k [ - 1 ] == ""*"" :",134
"def should_wait(self, offer_hash: str): <TAB> with self._lock: <MASK> if self._offer_hash != offer_hash: <TAB>  <TAB>  <TAB>  <TAB> logger.debug( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""already processing another offer (%s vs %s)"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._offer_hash, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> offer_hash, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB> if self._started == self._wtct_num_subtasks: <TAB>  <TAB>  <TAB>  <TAB> logger.info(""all subtasks for `%s` have been started"", self._offer_hash) <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> return False",if self . _offer_hash is not None :,167
"def list_urls(self): <TAB> for idx, job in enumerate(self.urlwatcher.jobs): <TAB>  <TAB> if self.urlwatch_config.verbose: <TAB>  <TAB>  <TAB> print(""%d: %s"" % (idx + 1, repr(job))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pretty_name = job.pretty_name() <TAB>  <TAB>  <TAB> location = job.get_location() <MASK> print(""%d: %s ( %s )"" % (idx + 1, pretty_name, location)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> print(""%d: %s"" % (idx + 1, pretty_name)) <TAB> return 0",if pretty_name != location :,157
"def _encode_realm(self, realm): <TAB> # override default _encode_realm to fill in default realm field <MASK> realm = self.default_realm <TAB>  <TAB> if realm is None: <TAB>  <TAB>  <TAB> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""you must specify a realm explicitly, "" <TAB>  <TAB>  <TAB>  <TAB> ""or set the default_realm attribute"" <TAB>  <TAB>  <TAB> ) <TAB> return self._encode_field(realm, ""realm"")",if realm is None :,105
"def set(sensor_spec: dict, **kwargs): <TAB> for key, value in kwargs.items(): <TAB>  <TAB> if key == ""position"": <TAB>  <TAB>  <TAB> sensor_spec[""transform""] = SensorSpecs.get_position(value) <TAB>  <TAB> elif key == ""attachment_type"": <TAB>  <TAB>  <TAB> sensor_spec[key] = SensorSpecs.ATTACHMENT_TYPE[value] <MASK> sensor_spec[key] = SensorSpecs.COLOR_CONVERTER[value]","elif key == ""color_converter"" :",125
"def _check_arguments(self, arch, state): <TAB> # TODO: add calling convention detection to individual functions, and use that instead of the <TAB> # TODO: default calling convention of the platform <TAB> cc = DEFAULT_CC[arch.name](arch)  # type: s_cc.SimCC <TAB> for i, expected_arg in enumerate(self.arguments): <TAB>  <TAB> if expected_arg is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> real_arg = cc.arg(state, i) <TAB>  <TAB> expected_arg_type, expected_arg_value = expected_arg <TAB>  <TAB> r = self._compare_arguments( <TAB>  <TAB>  <TAB> state, expected_arg_type, expected_arg_value, real_arg <TAB>  <TAB> ) <MASK> return False <TAB> return True",if not r :,183
"def all_projects(): <TAB> if not REPODIR: <TAB>  <TAB> return <TAB> # Future: make this path parameterisable. <TAB> excludes = set([""tempest"", ""requirements""]) <TAB> for name in PROJECTS: <TAB>  <TAB> name = name.strip() <TAB>  <TAB> short_name = name.split(""/"")[-1] <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> with open(os.path.join(REPODIR, short_name, ""setup.py""), ""rt"") as f: <MASK> continue <TAB>  <TAB> except IOError: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if short_name in excludes: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> yield (short_name, dict(name=name, short_name=short_name))","if ""pbr"" not in f . read ( ) :",180
"def get_converter(self, key, default=None): <TAB> """"""Gets a converter for the given key."""""" <TAB> if key in self._vars: <TAB>  <TAB> return self._vars[key].convert <TAB> # necessary for keys that match regexes, such as `*PATH`s <TAB> for k, var in self._vars.items(): <MASK> continue <TAB>  <TAB> if k.match(key) is not None: <TAB>  <TAB>  <TAB> converter = var.convert <TAB>  <TAB>  <TAB> self._vars[key] = var <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> converter = self._get_default_converter(default=default) <TAB> return converter","if isinstance ( k , str ) :",154
"def get_artist(self, name): <TAB> artist = self.artists.get(name) <TAB> if not artist: <TAB>  <TAB> if self.use_db: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> artist = q(m.Artist).filter_by(name=name).one() <TAB>  <TAB>  <TAB> except NoResultFound: <TAB>  <TAB>  <TAB>  <TAB> pass <MASK> self.add_artist(artist) <TAB> return artist",if artist and self . ram_cache :,111
"def move(self, x, y): <TAB> offset = self.h <TAB> width = max((len(val.get()) for val in self.values)) <TAB> for i, label in enumerate(self.labels): <MASK> label.place(x=x, y=y + offset) <TAB>  <TAB>  <TAB> label.config( <TAB>  <TAB>  <TAB>  <TAB> width=width, <TAB>  <TAB>  <TAB>  <TAB> bg=(self.fg if self.selected == i else self.bg), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> offset += self.h + (self.pady * 2) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> label.place(x=9999, y=9999) <TAB> return","if self . values [ i ] . get ( ) != """" :",166
"def visit_Assign(self, node): <TAB> if len(node.targets) == 1: <MASK> plugPath = self.__plugPath(self.__path(node.targets[0])) <TAB>  <TAB>  <TAB> if plugPath: <TAB>  <TAB>  <TAB>  <TAB> self.plugWrites.add(plugPath) <TAB> self.visit(node.value)","if isinstance ( node . targets [ 0 ] , ast . Subscript ) :",93
"def _minimal_replacement_cost(self, first, second): <TAB> first_symbols, second_symbols = set(), set() <TAB> removal_cost, insertion_cost = 0, 0 <TAB> for a, b in itertools.zip_longest(first, second, fillvalue=None): <MASK> first_symbols.add(a) <TAB>  <TAB> if b is not None: <TAB>  <TAB>  <TAB> second_symbols.add(b) <TAB>  <TAB> removal_cost = max(removal_cost, len(first_symbols - second_symbols)) <TAB>  <TAB> insertion_cost = max(insertion_cost, len(second_symbols - first_symbols)) <TAB> return min(removal_cost, insertion_cost)",if a is not None :,173
"def normalize_stroke(stroke): <TAB> letters = set(stroke) <TAB> if letters & _NUMBERS: <TAB>  <TAB> if system.NUMBER_KEY in letters: <TAB>  <TAB>  <TAB> stroke = stroke.replace(system.NUMBER_KEY, """") <TAB>  <TAB> # Insert dash when dealing with 'explicit' numbers <TAB>  <TAB> m = _IMPLICIT_NUMBER_RX.search(stroke) <MASK> start = m.start(2) <TAB>  <TAB>  <TAB> return stroke[:start] + ""-"" + stroke[start:] <TAB> if ""-"" in letters: <TAB>  <TAB> if stroke.endswith(""-""): <TAB>  <TAB>  <TAB> stroke = stroke[:-1] <TAB>  <TAB> elif letters & system.IMPLICIT_HYPHENS: <TAB>  <TAB>  <TAB> stroke = stroke.replace(""-"", """") <TAB> return stroke",if m is not None :,180
"def serve_json(self, args=None): <TAB> request = current.request <TAB> response = current.response <TAB> response.headers[""Content-Type""] = ""application/json; charset=utf-8"" <TAB> if not args: <TAB>  <TAB> args = request.args <TAB> d = dict(request.vars) <TAB> if args and args[0] in self.json_procedures: <TAB>  <TAB> s = self.call_service_function(self.json_procedures[args[0]], *args[1:], **d) <MASK> s = s.as_list() <TAB>  <TAB> return response.json(s) <TAB> self.error()","if hasattr ( s , ""as_list"" ) :",164
"def get_art_abs(story_file): <TAB> lines = read_text_file(story_file) <TAB> lines = [line.lower() for line in lines] <TAB> lines = [fix_missing_period(line) for line in lines] <TAB> article_lines = [] <TAB> highlights = [] <TAB> next_is_highlight = False <TAB> for idx, line in enumerate(lines): <TAB>  <TAB> if line == """": <TAB>  <TAB>  <TAB> continue  # empty line <TAB>  <TAB> elif line.startswith(""@highlight""): <TAB>  <TAB>  <TAB> next_is_highlight = True <MASK> highlights.append(line) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> article_lines.append(line) <TAB> article = "" "".join(article_lines) <TAB> abstract = "" "".join(highlights) <TAB> return article, abstract",elif next_is_highlight :,194
"def _get_commands(): <TAB> proc = Popen([""react-native"", ""--help""], stdout=PIPE) <TAB> should_yield = False <TAB> for line in proc.stdout.readlines(): <TAB>  <TAB> line = line.decode().strip() <MASK> continue <TAB>  <TAB> if ""Commands:"" in line: <TAB>  <TAB>  <TAB> should_yield = True <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if should_yield: <TAB>  <TAB>  <TAB> yield line.split("" "")[0]",if not line :,111
"def _wait_for_state(self, server_id, state, retries=50): <TAB> for i in (0, retries): <TAB>  <TAB> server = self.ex_get_server(server_id) <MASK> return <TAB>  <TAB> sleep(5) <TAB>  <TAB> if i == retries: <TAB>  <TAB>  <TAB> raise Exception(""Retries count reached"")","if server . extra [ ""status"" ] [ ""state"" ] == state :",95
"def add_letter(inner_letter): <TAB> if inner_letter in alphabet: <TAB>  <TAB> wordTrans.append(alphabet[inner_letter]) <TAB> else: <TAB>  <TAB> l2 = stringTools.stripAccents(inner_letter) <MASK> raise KeyError(""Cannot translate "" + inner_letter) <TAB>  <TAB> wordTrans.append(alphabet[""^""]) <TAB>  <TAB> wordTrans.append(alphabet[l2])",if l2 == inner_letter :,105
"def _parse_message(data): <TAB> try: <TAB>  <TAB> jsonrpc_message = json.loads(data, encoding=""utf-8"") <TAB>  <TAB> if jsonrpc_message.get(""jsonrpc"") != ""2.0"": <TAB>  <TAB>  <TAB> raise InvalidRequest() <TAB>  <TAB> del jsonrpc_message[""jsonrpc""] <MASK> return Response(**jsonrpc_message) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return Request(**jsonrpc_message) <TAB> except json.JSONDecodeError: <TAB>  <TAB> raise ParseError() <TAB> except TypeError: <TAB>  <TAB> raise InvalidRequest()","if ""result"" in jsonrpc_message . keys ( ) or ""error"" in jsonrpc_message . keys ( ) :",163
"def get_buildings_in_range(self): <TAB> # TODO Think about moving this to the Settlement class <TAB> buildings = self.settlement.buildings <TAB> for building in buildings: <MASK> continue <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB> distances.distance_rect_rect(self.position, building.position) <TAB>  <TAB>  <TAB> <= self.radius <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> yield building",if building is self :,102
"def get_tab_title(self, uuid=None): <TAB> """"""Return the title of a parent tab of a given terminal"""""" <TAB> maker = Factory() <TAB> terminal = self.terminator.find_terminal_by_uuid(uuid) <TAB> window = terminal.get_toplevel() <TAB> root_widget = window.get_children()[0] <TAB> if maker.isinstance(root_widget, ""Notebook""): <TAB>  <TAB> for tab_child in root_widget.get_children(): <TAB>  <TAB>  <TAB> terms = [tab_child] <MASK> terms = enumerate_descendants(tab_child)[1] <TAB>  <TAB>  <TAB> if terminal in terms: <TAB>  <TAB>  <TAB>  <TAB> return root_widget.get_tab_label(tab_child).get_label()","if not maker . isinstance ( terms [ 0 ] , ""Terminal"" ) :",186
"def is_valid_origin(origin): <TAB> if not settings.SENTRY_ALLOW_ORIGIN: <TAB>  <TAB> return False <TAB> if settings.SENTRY_ALLOW_ORIGIN == ""*"": <TAB>  <TAB> return True <TAB> if not origin: <TAB>  <TAB> return False <TAB> origin = origin.lower() <TAB> for value in settings.SENTRY_ALLOW_ORIGIN: <MASK> if value.lower() == origin: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if value.match(origin): <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False","if isinstance ( value , string_types ) :",137
"def addr_func(ctx): <TAB> nodes = ctx.xpathEval(base_xpath + ""/ip"") <TAB> nodes = nodes or [] <TAB> ret = [] <TAB> for node in nodes: <TAB>  <TAB> addr = node.prop(""address"") <TAB>  <TAB> pref = node.prop(""prefix"") <TAB>  <TAB> if not addr: <TAB>  <TAB>  <TAB> continue <MASK> addr += ""/%s"" % pref <TAB>  <TAB> ret.append(addr) <TAB> return ret",if pref :,107
"def _select_delete(self, select, args, row_index=0, arg_index=0): <TAB> count = 0 <TAB> delete = ""DELETE FROM Cache WHERE rowid IN (%s)"" <TAB> try: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> with self._transact() as (sql, cleanup): <TAB>  <TAB>  <TAB>  <TAB> rows = sql(select, args).fetchall() <MASK> break <TAB>  <TAB>  <TAB>  <TAB> count += len(rows) <TAB>  <TAB>  <TAB>  <TAB> sql(delete % "","".join(str(row[0]) for row in rows)) <TAB>  <TAB>  <TAB>  <TAB> for row in rows: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> args[arg_index] = row[row_index] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> cleanup(row[-1]) <TAB> except Timeout: <TAB>  <TAB> raise Timeout(count) <TAB> return count",if not rows :,193
"def _set_checkpointer(self, train_config): <TAB> if train_config[""checkpoint""]: <TAB>  <TAB> # Default to valid split for checkpoint metric <TAB>  <TAB> checkpoint_config = train_config[""checkpoint_config""] <TAB>  <TAB> checkpoint_metric = checkpoint_config[""checkpoint_metric""] <MASK> checkpoint_config[""checkpoint_metric""] = f""valid/{checkpoint_metric}"" <TAB>  <TAB> self.checkpointer = Checkpointer( <TAB>  <TAB>  <TAB> checkpoint_config, verbose=self.config[""verbose""] <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> self.checkpointer = None","if checkpoint_metric . count ( ""/"" ) == 0 :",142
"def mlt_version_is_greater_correct(test_version): <TAB> runtime_ver = mlt_version.split(""."") <TAB> test_ver = test_version.split(""."") <TAB> if runtime_ver[0] > test_ver[0]: <TAB>  <TAB> return True <TAB> elif runtime_ver[0] == test_ver[0]: <TAB>  <TAB> if runtime_ver[1] > test_ver[1]: <TAB>  <TAB>  <TAB> return True <MASK> if runtime_ver[2] > test_ver[2]: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",elif runtime_ver [ 1 ] == test_ver [ 1 ] :,148
"def generate_scraper_test(class_name, host_name): <TAB> with open(""templates/test_scraper.py"") as source: <TAB>  <TAB> code = source.read() <TAB>  <TAB> program = ast.parse(code) <TAB>  <TAB> state = GenerateTestScraperState(class_name, host_name, code) <TAB>  <TAB> for node in ast.walk(program): <MASK> break <TAB>  <TAB> output = f""tests/test_{class_name.lower()}.py"" <TAB>  <TAB> with open(output, ""w"") as target: <TAB>  <TAB>  <TAB> target.write(state.result())",if not state . step ( node ) :,154
"def _init_fetches(self): <TAB> futures = [] <TAB> for node_id, request in six.iteritems(self._create_fetch_requests()): <MASK> log.debug(""Sending FetchRequest to node %s"", node_id) <TAB>  <TAB>  <TAB> future = self._client.send(node_id, request) <TAB>  <TAB>  <TAB> future.add_callback(self._handle_fetch_response, request) <TAB>  <TAB>  <TAB> future.add_errback(log.error, ""Fetch to node %s failed: %s"", node_id) <TAB>  <TAB>  <TAB> futures.append(future) <TAB> self._fetch_futures.extend(futures) <TAB> self._clean_done_fetch_futures() <TAB> return futures",if self . _client . ready ( node_id ) :,176
"def discover(cls, path, **kwargs): <TAB> if kwargs.pop(""collection"", None) is not None: <TAB>  <TAB> raise TypeError(""collection argument must not be given."") <TAB> path = expand_path(path) <TAB> try: <TAB>  <TAB> collections = os.listdir(path) <TAB> except OSError as e: <TAB>  <TAB> if e.errno != errno.ENOENT: <TAB>  <TAB>  <TAB> raise <TAB> else: <TAB>  <TAB> for collection in collections: <TAB>  <TAB>  <TAB> collection_path = os.path.join(path, collection) <MASK> continue <TAB>  <TAB>  <TAB> args = dict(collection=collection, path=collection_path, **kwargs) <TAB>  <TAB>  <TAB> yield args",if not cls . _validate_collection ( collection_path ) :,167
"def writefile(filename, now): <TAB> with open(os.path.join(""src/teensy/"" + filename)) as fileopen, open( <TAB>  <TAB> os.path.join(core.userconfigpath, ""reports/teensy_{0}.ino"".format(now)), ""w"" <TAB> ) as filewrite: <TAB>  <TAB> for line in fileopen: <TAB>  <TAB>  <TAB> match = re.search(""IPADDR"", line) <MASK> line = line.replace(""IPADDR"", ipaddr) <TAB>  <TAB>  <TAB> match = re.search(""12,12,12,12"", line) <TAB>  <TAB>  <TAB> if match: <TAB>  <TAB>  <TAB>  <TAB> ipaddr_replace = ipaddr.replace(""."", "","", 4) <TAB>  <TAB>  <TAB>  <TAB> line = line.replace(""12,12,12,12"", ipaddr_replace) <TAB>  <TAB>  <TAB> filewrite.write(line)",if match :,199
"def get_added_files(diff): <TAB> """"""hacky approach to extract added files from github diff output"""""" <TAB> prefix = ""+++ b/"" <TAB> lastline = None <TAB> for line in diff.splitlines(): <TAB>  <TAB> line = line.strip() <MASK> yield line[len(prefix) :] <TAB>  <TAB> lastline = line","if line . startswith ( prefix ) and lastline and lastline == ""--- /dev/null"" :",100
"def bpe_decode(tokens: List[str]) -> List[str]: <TAB> words = [] <TAB> pieces: List[str] = [] <TAB> for t in tokens: <MASK> pieces.append(t[:-2]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> words.append("""".join(pieces + [t])) <TAB>  <TAB>  <TAB> pieces = [] <TAB> if len(pieces) > 0: <TAB>  <TAB> words.append("""".join(pieces)) <TAB> return words",if t . endswith ( DecodeMixin . bpe_cont_str ) :,120
"def _maybe_encrypt(self, data): <TAB> gpgr = self.config.prefs.gpg_recipient <TAB> tokeys = [gpgr] if gpgr not in (None, """", ""!CREATE"", ""!PASSWORD"") else None <TAB> if self.config.get_master_key(): <TAB>  <TAB> with EncryptingStreamer(self.config.get_master_key(), delimited=True) as es: <TAB>  <TAB>  <TAB> es.write(data) <TAB>  <TAB>  <TAB> es.finish() <TAB>  <TAB>  <TAB> return es.save(None) <TAB> elif tokeys: <TAB>  <TAB> stat, edata = GnuPG(self.config, event=GetThreadEvent()).encrypt( <TAB>  <TAB>  <TAB> data, tokeys=tokeys <TAB>  <TAB> ) <MASK> return edata <TAB> return data",if stat == 0 :,186
"def faces_uvs_list(self) -> List[torch.Tensor]: <TAB> if self._faces_uvs_list is None: <MASK> self._faces_uvs_list = [ <TAB>  <TAB>  <TAB>  <TAB> torch.empty((0, 3), dtype=torch.float32, device=self.device) <TAB>  <TAB>  <TAB> ] * self._N <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._faces_uvs_list = padded_to_list( <TAB>  <TAB>  <TAB>  <TAB> self._faces_uvs_padded, split_size=self._num_faces_per_mesh <TAB>  <TAB>  <TAB> ) <TAB> return self._faces_uvs_list",if self . isempty ( ) :,157
"def handle_resource_click(self, widget, event): <TAB> if event.getButton() == fife.MouseEvent.LEFT: <TAB>  <TAB> self.show_resource_menu(widget.parent, widget.parent.parent) <TAB> elif event.getButton() == fife.MouseEvent.RIGHT: <MASK> # abort resource selection (#1310) <TAB>  <TAB>  <TAB> self.hide_resource_menu() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # remove the load/unload order <TAB>  <TAB>  <TAB> self.add_resource(slot=widget.parent, res_id=0, entry=widget.parent.parent)",if self . resource_menu_shown :,151
"def update_device(self, device): <TAB> for bridge in self.bridges: <TAB>  <TAB> if bridge.device == device: <MASK> bridge.device.ip = device.ip <TAB>  <TAB>  <TAB>  <TAB> bridge.device.port = device.port <TAB>  <TAB>  <TAB>  <TAB> logger.info( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> 'Updated device ""{}"" - New settings: {}:{}'.format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> device.label, device.ip, device.port <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> self.update() <TAB>  <TAB>  <TAB>  <TAB> self.share_bridges() <TAB>  <TAB>  <TAB>  <TAB> break",if bridge . device . ip != device . ip or bridge . device . port != device . port :,172
"def endElement(self, name, value, connection): <TAB> if name == ""OptionGroupName"": <TAB>  <TAB> self.name = value <TAB> elif name == ""EngineName"": <TAB>  <TAB> self.engine_name = value <TAB> elif name == ""MajorEngineVersion"": <TAB>  <TAB> self.major_engine_version = value <TAB> elif name == ""OptionGroupDescription"": <TAB>  <TAB> self.description = value <TAB> elif name == ""AllowsVpcAndNonVpcInstanceMemberships"": <MASK> self.allow_both_vpc_and_nonvpc = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.allow_both_vpc_and_nonvpc = False <TAB> elif name == ""VpcId"": <TAB>  <TAB> self.vpc_id = value <TAB> else: <TAB>  <TAB> setattr(self, name, value)","if value . lower ( ) == ""true"" :",194
"def log_items(self, interface, action, media, items): <TAB> if not items: <TAB>  <TAB> return <TAB>  <TAB> # Log each item <TAB> for item in items: <TAB>  <TAB> if not item: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> log.info( <TAB>  <TAB>  <TAB> ""[%s:%s](%s) %r (%r)"", <TAB>  <TAB>  <TAB> interface, <TAB>  <TAB>  <TAB> action, <TAB>  <TAB>  <TAB> media, <TAB>  <TAB>  <TAB> item.get(""title""), <TAB>  <TAB>  <TAB> item.get(""year""), <TAB>  <TAB> ) <MASK> # Log each episode <TAB>  <TAB>  <TAB> self.log_episodes(item)","if media == ""shows"" :",150
"def _copy_files(self, files, src, dest, message=""""): <TAB> for filepath in files: <TAB>  <TAB> srcpath = os.path.join(src, filepath) <TAB>  <TAB> destpath = os.path.join(dest, filepath) <TAB>  <TAB> if message: <TAB>  <TAB>  <TAB> print(""{}: {}"".format(message, destpath)) <MASK> destdir = os.path.dirname(destpath) <TAB>  <TAB>  <TAB> if not os.path.isdir(destdir): <TAB>  <TAB>  <TAB>  <TAB> os.makedirs(destdir) <TAB>  <TAB>  <TAB> shutil.copy(srcpath, destpath) <TAB>  <TAB> elif os.path.exists(destpath): <TAB>  <TAB>  <TAB> os.remove(destpath)",if os . path . exists ( srcpath ) :,167
"def disconnect(self, endpoint=None): <TAB> if endpoint is not None: <TAB>  <TAB> conn = self.connections_endpoints.pop(endpoint, None) <MASK> self.connections.pop(conn.get_socket_object(), None) <TAB>  <TAB>  <TAB> conn.close() <TAB> else: <TAB>  <TAB> for _, conn in self.connections_endpoints.items(): <TAB>  <TAB>  <TAB> conn.close() <TAB>  <TAB> self.connections_endpoints = {} <TAB>  <TAB> self.connections = {}",if conn :,115
"def cisco_inventory(raw): <TAB> for match in INVENTORY_RE.finditer(raw): <TAB>  <TAB> d = match.groupdict() <MASK> d[""sn""] = None <TAB>  <TAB> d[""descr""] = d[""descr""].strip('""') <TAB>  <TAB> d[""name""] = d[""name""].strip('""') <TAB>  <TAB> yield d","if d [ ""sn"" ] in SERIAL_BLACKLIST :",91
"def _dispatchBubblingEvent(self, tag, evtType, evtObject): <TAB> for node in tag.parents: <TAB>  <TAB> if node is None:  # pragma: no cover <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if not node._listeners: <TAB>  <TAB>  <TAB> continue <MASK> # pragma: no cover <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> capture_listeners, bubbling_listeners = self._get_listeners( <TAB>  <TAB>  <TAB> node, evtType <TAB>  <TAB> )  # pylint:disable=unused-variable <TAB>  <TAB> for c in bubbling_listeners: <TAB>  <TAB>  <TAB> evtObject.currentTarget = node._node <TAB>  <TAB>  <TAB> self.do_dispatch(c, evtObject)",if evtObject . _stoppedPropagation :,165
"def got_shares(self, shares): <TAB> if self.check_reneging: <MASK> self.finished_d.errback( <TAB>  <TAB>  <TAB>  <TAB> unittest.FailTest( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""The node was told by the share finder that it is destined to remain hungry, then was given another share."" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return <TAB> self.got += len(shares) <TAB> log.msg(""yyy 3 %s.got_shares(%s) got: %s"" % (self, shares, self.got)) <TAB> if self.got == 3: <TAB>  <TAB> self.finished_d.callback(True)",if self . _no_more_shares :,167
"def get_class_obj_(self, node, default_class=None): <TAB> class_obj1 = default_class <TAB> if ""xsi"" in node.nsmap: <TAB>  <TAB> classname = node.get(""{%s}type"" % node.nsmap[""xsi""]) <TAB>  <TAB> if classname is not None: <TAB>  <TAB>  <TAB> names = classname.split("":"") <MASK> classname = names[1] <TAB>  <TAB>  <TAB> class_obj2 = globals().get(classname) <TAB>  <TAB>  <TAB> if class_obj2 is not None: <TAB>  <TAB>  <TAB>  <TAB> class_obj1 = class_obj2 <TAB> return class_obj1",if len ( names ) == 2 :,154
"def update(self, mapping, update_only=False): <TAB> for name in mapping: <MASK> # nested and inner objects, merge recursively <TAB>  <TAB>  <TAB> if hasattr(self[name], ""update""): <TAB>  <TAB>  <TAB>  <TAB> # FIXME only merge subfields, not the settings <TAB>  <TAB>  <TAB>  <TAB> self[name].update(mapping[name], update_only) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> self.field(name, mapping[name]) <TAB> if update_only: <TAB>  <TAB> for name in mapping._meta: <TAB>  <TAB>  <TAB> if name not in self._meta: <TAB>  <TAB>  <TAB>  <TAB> self._meta[name] = mapping._meta[name] <TAB> else: <TAB>  <TAB> self._meta.update(mapping._meta)",if update_only and name in self :,175
"def configure(self): <TAB> super(Command, self).configure() <TAB> if self.needs_config and not self.resolver: <TAB>  <TAB> # Checking if a default config file is present <MASK> self.add_option( <TAB>  <TAB>  <TAB>  <TAB> ""config"", ""c"", InputOption.VALUE_REQUIRED, ""The config file path"" <TAB>  <TAB>  <TAB> )",if not self . _check_config ( ) :,92
"def is_metric(cls, key_type, comparator): <TAB> if key_type == cls._METRIC_IDENTIFIER: <MASK> raise MlflowException( <TAB>  <TAB>  <TAB>  <TAB> ""Invalid comparator '%s' "" <TAB>  <TAB>  <TAB>  <TAB> ""not one of '%s"" % (comparator, cls.VALID_METRIC_COMPARATORS), <TAB>  <TAB>  <TAB>  <TAB> error_code=INVALID_PARAMETER_VALUE, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return True <TAB> return False",if comparator not in cls . VALID_METRIC_COMPARATORS :,126
"def get_full_qualified_name(self, node: Element) -> str: <TAB> if node.get(""reftype"") == ""option"": <TAB>  <TAB> progname = node.get(""std:program"") <TAB>  <TAB> command = ws_re.split(node.get(""reftarget"")) <TAB>  <TAB> if progname: <TAB>  <TAB>  <TAB> command.insert(0, progname) <TAB>  <TAB> option = command.pop() <MASK> return ""."".join([""-"".join(command), option]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return None <TAB> else: <TAB>  <TAB> return None",if command :,133
"def log_unsupported(logger, message, dictionary): <TAB> if len(dictionary) < 1: <TAB>  <TAB> return <TAB> # Display unsupported service list <TAB> logger.info(message, len(dictionary)) <TAB> # Display individual warnings for each service <TAB> for service in dictionary.keys(): <MASK> logger.info(""Ignoring service: %s"" % service) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # Log unsupported service warning <TAB>  <TAB> logger.warn( <TAB>  <TAB>  <TAB> ""Unsupported service: %s"" % service, <TAB>  <TAB>  <TAB> extra={ <TAB>  <TAB>  <TAB>  <TAB> ""event"": { <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""module"": __name__, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""name"": ""unsupported_service"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""key"": service, <TAB>  <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB> }, <TAB>  <TAB> )",if service is None or service in IGNORED_SERVICES :,197
"def encode_password(pw): <TAB> """"""Encode password in hexadecimal if needed"""""" <TAB> enc = False <TAB> if pw: <TAB>  <TAB> encPW = __PW_PREFIX <TAB>  <TAB> for c in pw: <TAB>  <TAB>  <TAB> cnum = ord(c) <TAB>  <TAB>  <TAB> if c == ""#"" or cnum < 33 or cnum > 126: <TAB>  <TAB>  <TAB>  <TAB> enc = True <TAB>  <TAB>  <TAB> encPW += ""%2x"" % cnum <MASK> return encPW <TAB> return pw",if enc :,115
"def matrix_min_and_max(matrix): <TAB> _min = None <TAB> _max = None <TAB> for row in matrix: <TAB>  <TAB> for el in row: <TAB>  <TAB>  <TAB> val = el <TAB>  <TAB>  <TAB> if _min is None or val < _min: <TAB>  <TAB>  <TAB>  <TAB> _min = val <MASK> _max = val <TAB> return _min, _max",if _max is None or val > _max :,102
"def __init__(self, content=None, parent=None): <TAB> Transformable.__init__(self, content, parent) <TAB> self._items = [] <TAB> for element in content: <MASK> continue <TAB>  <TAB> tag = element.tag[len(namespace) :] <TAB>  <TAB> if tag == ""g"": <TAB>  <TAB>  <TAB> item = Group(element, self) <TAB>  <TAB> elif tag == ""path"": <TAB>  <TAB>  <TAB> item = Path(element, self) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.warn(""Unhandled SVG tag (%s)"" % tag) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> self._items.append(item)",if not element . tag . startswith ( namespace ) :,154
def reset_appid(self): <TAB> # called by web_control <TAB> with self.lock: <TAB>  <TAB> self.working_appid_list = list() <TAB>  <TAB> for appid in self.config.GAE_APPIDS: <MASK> self.config.GAE_APPIDS.remove(appid) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> self.working_appid_list.append(appid) <TAB>  <TAB> self.not_exist_appids = [] <TAB>  <TAB> self.out_of_quota_appids = [] <TAB> self.last_reset_time = time.time(),if not appid :,152
"def find_widget(self, pos): <TAB> for widget in self.subwidgets[::-1]: <TAB>  <TAB> if widget.visible: <TAB>  <TAB>  <TAB> r = widget.rect <MASK> return widget.find_widget(subtract(pos, r.topleft)) <TAB> return self",if r . collidepoint ( pos ) :,77
"def _get_names(dirs): <TAB> """"""Get alphabet and label names, union across all dirs."""""" <TAB> alphabets = set() <TAB> label_names = {} <TAB> for d in dirs: <TAB>  <TAB> for example in _walk_omniglot_dir(d): <TAB>  <TAB>  <TAB> alphabet, alphabet_char_id, label, _, _ = example <TAB>  <TAB>  <TAB> alphabets.add(alphabet) <TAB>  <TAB>  <TAB> label_name = ""%s_%d"" % (alphabet, alphabet_char_id) <MASK> assert label_names[label] == label_name <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> label_names[label] = label_name <TAB> label_names = [label_names[k] for k in sorted(label_names)] <TAB> return alphabets, label_names",if label in label_names :,196
"def model(): <TAB> with pyro.plate_stack(""plates"", shape): <TAB>  <TAB> with pyro.plate(""particles"", 200000): <MASK> pyro.sample(""x"", dist.Normal(loc, scale)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> pyro.sample(""x"", dist.StudentT(10.0, loc, scale))","if ""dist_type"" == ""Normal"" :",103
"def set_note_pinned(self, key, pinned): <TAB> n = self.notes[key] <TAB> old_pinned = utils.note_pinned(n) <TAB> if pinned != old_pinned: <TAB>  <TAB> if ""systemtags"" not in n: <TAB>  <TAB>  <TAB> n[""systemtags""] = [] <TAB>  <TAB> systemtags = n[""systemtags""] <MASK> # which by definition means that it was NOT pinned <TAB>  <TAB>  <TAB> systemtags.append(""pinned"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> systemtags.remove(""pinned"") <TAB>  <TAB> n[""modifydate""] = time.time() <TAB>  <TAB> self.notify_observers( <TAB>  <TAB>  <TAB> ""change:note-status"", <TAB>  <TAB>  <TAB> events.NoteStatusChangedEvent(what=""modifydate"", key=key), <TAB>  <TAB> )",if pinned :,186
"def __init__(self, name, contents): <TAB> self.name = name <TAB> self.all_entries = [] <TAB> self.attr = [] <TAB> self.child = [] <TAB> self.seq_child = [] <TAB> for entry in contents: <TAB>  <TAB> clean_entry = entry.rstrip(""*"") <TAB>  <TAB> self.all_entries.append(clean_entry) <TAB>  <TAB> if entry.endswith(""**""): <TAB>  <TAB>  <TAB> self.seq_child.append(clean_entry) <MASK> self.child.append(clean_entry) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.attr.append(entry)","elif entry . endswith ( ""*"" ) :",147
"def testToFileBinary(self): <TAB> z = dns.zone.from_file(here(""example""), ""example"") <TAB> try: <TAB>  <TAB> f = open(here(""example3-binary.out""), ""wb"") <TAB>  <TAB> z.to_file(f) <TAB>  <TAB> f.close() <TAB>  <TAB> ok = filecmp.cmp(here(""example3-binary.out""), here(""example3.good"")) <TAB> finally: <MASK> os.unlink(here(""example3-binary.out"")) <TAB> self.failUnless(ok)",if not _keep_output :,133
"def test_collect_gradients_with_allreduce_failure_case(self): <TAB> worker = self._workers[1] <TAB> train_db, _ = get_mnist_dataset(self._batch_size) <TAB> for step, (x, y) in enumerate(train_db): <TAB>  <TAB> if step == 0: <TAB>  <TAB>  <TAB> worker._run_model_call_before_training(x) <MASK> break <TAB>  <TAB> self.assertEqual( <TAB>  <TAB>  <TAB> worker._calculate_grads_and_report_with_allreduce(None), <TAB>  <TAB>  <TAB> False, <TAB>  <TAB>  <TAB> ""Should fail when no data is received"", <TAB>  <TAB> )",if step == self . _test_steps :,160
"def clean(self): <TAB> data = self.cleaned_data <TAB> number, ccv = data.get(""number""), data.get(""ccv"") <TAB> if number and ccv: <MASK> raise forms.ValidationError( <TAB>  <TAB>  <TAB>  <TAB> _(""American Express cards use a 4 digit security code"") <TAB>  <TAB>  <TAB> ) <TAB> return data",if bankcards . is_amex ( number ) and len ( ccv ) != 4 :,104
"def _gen_GreaterEqual(self, args, ret_type): <TAB> result = [] <TAB> for lhs, rhs in pairwise(args): <MASK> result.append(self.builder.fcmp_ordered("">="", lhs, rhs)) <TAB>  <TAB> elif ret_type == int_type: <TAB>  <TAB>  <TAB> result.append(self.builder.icmp_signed("">="", lhs, rhs)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise CompileError() <TAB> return reduce(self.builder.and_, result)",if ret_type == real_type :,120
"def console_get(context, console_id, instance_id=None): <TAB> query = ( <TAB>  <TAB> model_query(context, models.Console, read_deleted=""yes"") <TAB>  <TAB> .filter_by(id=console_id) <TAB>  <TAB> .options(joinedload(""pool"")) <TAB> ) <TAB> if instance_id is not None: <TAB>  <TAB> query = query.filter_by(instance_id=instance_id) <TAB> result = query.first() <TAB> if not result: <MASK> raise exception.ConsoleNotFoundForInstance( <TAB>  <TAB>  <TAB>  <TAB> console_id=console_id, instance_id=instance_id <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise exception.ConsoleNotFound(console_id=console_id) <TAB> return result",if instance_id :,185
"def publish(): <TAB> pub = await aioredis.create_redis((""localhost"", 6379)) <TAB> while not tsk.done(): <TAB>  <TAB> # wait for clients to subscribe <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> subs = await pub.pubsub_numsub(""channel:1"") <MASK> break <TAB>  <TAB>  <TAB> await asyncio.sleep(0, loop=loop) <TAB>  <TAB> # publish some messages <TAB>  <TAB> for msg in [""one"", ""two"", ""three""]: <TAB>  <TAB>  <TAB> await pub.publish(""channel:1"", msg) <TAB>  <TAB> # send stop word <TAB>  <TAB> await pub.publish(""channel:1"", STOPWORD) <TAB> pub.close() <TAB> await pub.wait_closed()","if subs [ b""channel:1"" ] == 1 :",176
"def read(self, size=None): <TAB> if not size: <TAB>  <TAB> size = self._size <TAB>  <TAB> contents = BytesIO() <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> blocks = GzipFile.read(self, size) <MASK> contents.flush() <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> contents.write(blocks) <TAB>  <TAB> return contents.getvalue() <TAB> else: <TAB>  <TAB> return GzipFile.read(self, size)",if not blocks :,108
"def i2repr(self, pkt, x): <TAB> if type(x) is list or type(x) is tuple: <TAB>  <TAB> return repr(x) <TAB> if self.multi: <TAB>  <TAB> r = [] <TAB> else: <TAB>  <TAB> r = """" <TAB> i = 0 <TAB> while x: <MASK> if self.multi: <TAB>  <TAB>  <TAB>  <TAB> r += [self.names[i]] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> r += self.names[i] <TAB>  <TAB> i += 1 <TAB>  <TAB> x >>= 1 <TAB> if self.multi: <TAB>  <TAB> r = ""+"".join(r) <TAB> return r",if x & 1 :,154
"def _run(self): <TAB> while not self.stopped: <TAB>  <TAB> # Prevent calling bus.send from multiple threads <TAB>  <TAB> with self.lock: <TAB>  <TAB>  <TAB> started = time.time() <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> self.bus.send(self.message) <TAB>  <TAB>  <TAB> except Exception as exc: <TAB>  <TAB>  <TAB>  <TAB> log.exception(exc) <TAB>  <TAB>  <TAB>  <TAB> break <MASK> break <TAB>  <TAB> # Compensate for the time it takes to send the message <TAB>  <TAB> delay = self.period - (time.time() - started) <TAB>  <TAB> time.sleep(max(0.0, delay))",if self . end_time is not None and time . time ( ) >= self . end_time :,169
"def currentLevel(self): <TAB> currentStr = """" <TAB> for stackType, stackValue in self.stackVals: <TAB>  <TAB> if stackType == ""dict"": <MASK> currentStr += ""['"" + stackValue + ""']"" <TAB>  <TAB>  <TAB> else:  # numeric key... <TAB>  <TAB>  <TAB>  <TAB> currentStr += ""["" + str(stackValue) + ""]"" <TAB>  <TAB> elif stackType == ""listLike"": <TAB>  <TAB>  <TAB> currentStr += ""["" + str(stackValue) + ""]"" <TAB>  <TAB> elif stackType == ""getattr"": <TAB>  <TAB>  <TAB> currentStr += "".__getattribute__('"" + stackValue + ""')"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception(f""Cannot get attribute of type {stackType}"") <TAB> return currentStr","if isinstance ( stackValue , str ) :",176
"def restoreParent(self): <TAB> if self.sid.isRoot: <TAB>  <TAB> return <TAB> with self.suspendMouseButtonNavigation(): <TAB>  <TAB> confirm, opt = self.confirmRestore((self.path,)) <MASK> return <TAB>  <TAB> if opt[""delete""] and not self.confirmDelete(warnRoot=self.path == ""/""): <TAB>  <TAB>  <TAB> return <TAB> rd = RestoreDialog(self, self.sid, self.path, **opt) <TAB> rd.exec()",if not confirm :,114
"def keep_vocab_item(word, count, min_count, trim_rule=None): <TAB> default_res = count >= min_count <TAB> if trim_rule is None: <TAB>  <TAB> return default_res <TAB> else: <TAB>  <TAB> rule_res = trim_rule(word, count, min_count) <MASK> return True <TAB>  <TAB> elif rule_res == RULE_DISCARD: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return default_res",if rule_res == RULE_KEEP :,125
"def _get_cuda_device(*args): <TAB> # Returns cuda.Device or DummyDevice. <TAB> for arg in args: <TAB>  <TAB> if type(arg) is not bool and isinstance(arg, _integer_types): <TAB>  <TAB>  <TAB> check_cuda_available() <TAB>  <TAB>  <TAB> return Device(arg) <MASK> if arg.device is None: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> return arg.device <TAB>  <TAB> if available and isinstance(arg, Device): <TAB>  <TAB>  <TAB> return arg <TAB> # NOTE: This function returns DummyDevice for both NumPy and ChainerX <TAB> return DummyDevice","if isinstance ( arg , ndarray ) :",144
"def __init__( <TAB> self, <TAB> filename, <TAB> metadata_name, <TAB> metadata_column, <TAB> message=""Value for metadata not found."", <TAB> line_startswith=None, <TAB> split=""\t"",): <TAB> self.metadata_name = metadata_name <TAB> self.message = message <TAB> self.valid_values = [] <TAB> for line in open(filename): <TAB>  <TAB> if line_startswith is None or line.startswith(line_startswith): <TAB>  <TAB>  <TAB> fields = line.split(split) <MASK> self.valid_values.append(fields[metadata_column].strip())",if metadata_column < len ( fields ) :,150
"def FindEnclosingBracketGroup(input_str): <TAB> stack = [] <TAB> start = -1 <TAB> for index, char in enumerate(input_str): <TAB>  <TAB> if char in LBRACKETS: <TAB>  <TAB>  <TAB> stack.append(char) <MASK> start = index <TAB>  <TAB> elif char in BRACKETS: <TAB>  <TAB>  <TAB> if not stack: <TAB>  <TAB>  <TAB>  <TAB> return (-1, -1) <TAB>  <TAB>  <TAB> if stack.pop() != BRACKETS[char]: <TAB>  <TAB>  <TAB>  <TAB> return (-1, -1) <TAB>  <TAB>  <TAB> if not stack: <TAB>  <TAB>  <TAB>  <TAB> return (start, index + 1) <TAB> return (-1, -1)",if start == - 1 :,163
"def _on_message(self, msg: str) -> None: <TAB> obj = json.loads(msg) <TAB> _id = obj.get(""id"") <TAB> if _id and _id in self._callbacks: <TAB>  <TAB> callback = self._callbacks.pop(_id) <MASK> error = obj[""error""] <TAB>  <TAB>  <TAB> msg = error.get(""message"") <TAB>  <TAB>  <TAB> data = error.get(""data"") <TAB>  <TAB>  <TAB> callback.set_exception(NetworkError(f""Protocol Error: {msg} {data}"")) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result = obj.get(""result"") <TAB>  <TAB>  <TAB> callback.set_result(result) <TAB> else: <TAB>  <TAB> self.emit(obj.get(""method""), obj.get(""params""))","if ""error"" in obj :",183
"def _get_containers_with_state(self, container_names, select_random, *container_states): <TAB> containers = self._get_all_containers() <TAB> candidates = dict((c.name, c) for c in containers if c.status in container_states) <TAB> if select_random and candidates: <TAB>  <TAB> return [random.choice(list(candidates.values()))] <TAB> if container_names is None: <TAB>  <TAB> return list(candidates.values()) <TAB> found = [] <TAB> for name in container_names: <TAB>  <TAB> container = candidates.get(name) <MASK> raise BlockadeError( <TAB>  <TAB>  <TAB>  <TAB> ""Container %s is not found or not any of %s"" % (name, container_states) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> found.append(container) <TAB> return found",if not container :,193
"def __eq__(self, other): <TAB> if isinstance(other, WeakMethod): <MASK> return False <TAB>  <TAB> # check also if either instance is None or else if instances are equal <TAB>  <TAB> if self.instance is None: <TAB>  <TAB>  <TAB> return other.instance is None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.instance() == other.instance() <TAB> elif callable(other): <TAB>  <TAB> return self == WeakMethod(other) <TAB> else: <TAB>  <TAB> return False",if self . function != other . function :,120
"def last_bottle_hash(): <TAB> """"""Fetch the bottle do ... end from the latest brew formula"""""" <TAB> resp = requests.get(HOMEBREW_FORMULAR_LATEST) <TAB> resp.raise_for_status() <TAB> lines = resp.text.split(""\n"") <TAB> look_for_end = False <TAB> start = 0 <TAB> end = 0 <TAB> for idx, content in enumerate(lines): <TAB>  <TAB> if look_for_end: <MASK> end = idx <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if ""bottle do"" in content: <TAB>  <TAB>  <TAB>  <TAB> start = idx <TAB>  <TAB>  <TAB>  <TAB> look_for_end = True <TAB> return ""\n"".join(lines[start : end + 1])","if ""end"" in content :",184
"def wrapper(fn): <TAB> if debug_run_test_calls: <TAB>  <TAB> ret = str(fn(*args, *kwargs)) <TAB>  <TAB> print(""TEST: %s()"" % fn.__name__) <MASK> print(""  arg:"", args) <TAB>  <TAB> if kwargs: <TAB>  <TAB>  <TAB> print(""  kwa:"", kwargs) <TAB>  <TAB> print(""  ret:"", ret) <TAB> return fn",if args :,95
"def parse_socket_line(line): <TAB> lsp = line.strip().split() <TAB> if not len(lsp) in {3, 5}: <TAB>  <TAB> print(line, ""is malformed"") <TAB>  <TAB> return UNPARSABLE <TAB> else: <TAB>  <TAB> socket_type = sock_dict.get(lsp[2]) <TAB>  <TAB> socket_name = lsp[1] <MASK> return UNPARSABLE <TAB>  <TAB> elif len(lsp) == 3: <TAB>  <TAB>  <TAB> return socket_type, socket_name, None, None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> default = processed(lsp[3]) <TAB>  <TAB>  <TAB> nested = processed(lsp[4]) <TAB>  <TAB>  <TAB> return socket_type, socket_name, default, nested",if not socket_type :,182
"def release(self): <TAB> me, lock_count = self.__begin() <TAB> try: <TAB>  <TAB> if me is None: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> self._count = count = self._count - 1 <MASK> self._owner = None <TAB>  <TAB>  <TAB> self._block.release() <TAB> finally: <TAB>  <TAB> self.__end(me, lock_count)",if not count :,92
"def Traverse(self): <TAB> """"""A generator for _IMAGE_RESOURCE_DATA_ENTRY under this node."""""" <TAB> for entry in self: <MASK> for subentry in entry.Entry.Traverse(): <TAB>  <TAB>  <TAB>  <TAB> yield subentry <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield entry.OffsetToData.dereference()",if entry . ChildIsEntry :,83
"def getInstances_WithSource(self, instancesAmount, sourceObject, scenes): <TAB> if sourceObject is None: <TAB>  <TAB> self.removeAllObjects() <TAB>  <TAB> return [] <TAB> else: <TAB>  <TAB> sourceHash = hash(sourceObject) <MASK> if lastSourceHashes[self.identifier] != sourceHash: <TAB>  <TAB>  <TAB>  <TAB> self.removeAllObjects() <TAB>  <TAB> lastSourceHashes[self.identifier] = sourceHash <TAB> return self.getInstances_Base(instancesAmount, sourceObject, scenes)",if self . identifier in lastSourceHashes :,132
"def used_pos(): <TAB> pos_along_edges = [] <TAB> for e in edges: <TAB>  <TAB> A, B = pos[e[0]], pos[e[1]] <MASK> # Y-axis edge. <TAB>  <TAB>  <TAB> for i in range(A[1], B[1], np.sign(B[1] - A[1])): <TAB>  <TAB>  <TAB>  <TAB> pos_along_edges.append((A[0], i)) <TAB>  <TAB> else:  # X-axis edge. <TAB>  <TAB>  <TAB> for i in range(A[0], B[0], np.sign(B[0] - A[0])): <TAB>  <TAB>  <TAB>  <TAB> pos_along_edges.append((i, A[1])) <TAB> return list(pos.values()) + pos_along_edges",if A [ 0 ] == B [ 0 ] :,186
"def __init__( <TAB> self, plugin_name=None, builtin=False, deprecated=False, config=None, session=None): <TAB> if builtin and isinstance(builtin, (str, unicode)): <TAB>  <TAB> builtin = os.path.basename(builtin) <TAB>  <TAB> for ignore in ("".py"", "".pyo"", "".pyc""): <MASK> builtin = builtin[: -len(ignore)] <TAB>  <TAB> if builtin not in self.LOADED: <TAB>  <TAB>  <TAB> self.LOADED.append(builtin) <TAB> self.loading_plugin = plugin_name <TAB> self.loading_builtin = plugin_name and builtin <TAB> self.builtin = builtin <TAB> self.deprecated = deprecated <TAB> self.session = session <TAB> self.config = config <TAB> self.manifests = []",if builtin . endswith ( ignore ) :,181
def input(self): <MASK> self.lazy_init_lock_.acquire() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if self.input_ is None: <TAB>  <TAB>  <TAB>  <TAB> self.input_ = InputSettings() <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self.lazy_init_lock_.release() <TAB> return self.input_,if self . input_ is None :,85
"def _shares_in_results(data): <TAB> shares_in_device, shares_in_subdevice = False, False <TAB> for plugin_name, plugin_result in data.iteritems(): <MASK> continue <TAB>  <TAB> if ""device"" not in plugin_result: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if ""disk_shares"" in plugin_result[""device""]: <TAB>  <TAB>  <TAB> shares_in_device = True <TAB>  <TAB> for subdevice in plugin_result[""device""].get(""subdevices"", []): <TAB>  <TAB>  <TAB> if ""disk_shares"" in subdevice: <TAB>  <TAB>  <TAB>  <TAB> shares_in_subdevice = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return shares_in_device, shares_in_subdevice","if plugin_result [ ""status"" ] == ""error"" :",175
"def m2i(self, pkt, x): <TAB> res = [] <TAB> while x: <TAB>  <TAB> cur = [] <TAB>  <TAB> # while x and x[0] != b'\x00': <TAB>  <TAB> while x and x[0] != 0: <TAB>  <TAB>  <TAB> l = x[0] <TAB>  <TAB>  <TAB> cur.append(x[1 : l + 1]) <TAB>  <TAB>  <TAB> x = x[l + 1 :] <TAB>  <TAB> res.append(b""."".join(cur)) <MASK> x = x[1:] <TAB> return res",if x and x [ 0 ] == 0 :,137
"def generate_idempotent_uuid(params, model, **kwargs): <TAB> for name in model.idempotent_members: <MASK> params[name] = str(uuid.uuid4()) <TAB>  <TAB>  <TAB> logger.debug( <TAB>  <TAB>  <TAB>  <TAB> ""injecting idempotency token (%s) into param '%s'."" <TAB>  <TAB>  <TAB>  <TAB> % (params[name], name) <TAB>  <TAB>  <TAB> )",if name not in params :,100
"def __init__(self, name, signatures, kind, vm): <TAB> super().__init__(name, vm) <TAB> assert signatures <TAB> self.kind = kind <TAB> self.bound_class = BoundPyTDFunction <TAB> self.signatures = signatures <TAB> self._signature_cache = {} <TAB> self._return_types = {sig.pytd_sig.return_type for sig in signatures} <TAB> for sig in signatures: <TAB>  <TAB> for param in sig.pytd_sig.params: <MASK> self._has_mutable = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._has_mutable = False <TAB> for sig in signatures: <TAB>  <TAB> sig.function = self <TAB>  <TAB> sig.name = self.name",if param . mutated_type is not None :,183
"def sub_dict(d): <TAB> r = {} <TAB> for k in d: <TAB>  <TAB> if type(d[k]) in prims: <TAB>  <TAB>  <TAB> r[k] = d[k] <MASK> r[k] = sub_list(d[k]) <TAB>  <TAB> elif type(d[k]) is dict: <TAB>  <TAB>  <TAB> r[k] = sub_dict(d[k]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""Unknown Type: {}"".format(type(d[k]))) <TAB> return r",elif type ( d [ k ] ) is list :,134
"def listAdd(): <TAB> cpe = request.args.get(""cpe"") <TAB> cpeType = request.args.get(""type"") <TAB> lst = request.args.get(""list"") <TAB> if cpe and cpeType and lst: <TAB>  <TAB> status = ( <TAB>  <TAB>  <TAB> ""added_to_list"" <MASK> else ""already_exists_in_list"" <TAB>  <TAB> ) <TAB>  <TAB> returnList = db.getWhitelist() if lst == ""whitelist"" else db.getBlacklist() <TAB>  <TAB> return jsonify({""status"": status, ""rules"": returnList, ""listType"": lst.title()}) <TAB> else: <TAB>  <TAB> return jsonify({""status"": ""could_not_add_to_list""})","if addCPEToList ( cpe , lst , cpeType )",184
"def _integrate_fixed_trajectory(self, h, T, step, relax): <TAB> """"""Generates a solution trajectory of fixed length."""""" <TAB> # initialize the solution using initial condition <TAB> solution = np.hstack((self.t, self.y)) <TAB> while self.successful(): <TAB>  <TAB> self.integrate(self.t + h, step, relax) <TAB>  <TAB> current_step = np.hstack((self.t, self.y)) <TAB>  <TAB> solution = np.vstack((solution, current_step)) <TAB>  <TAB> if (h > 0) and (self.t >= T): <TAB>  <TAB>  <TAB> break <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> continue <TAB> return solution",elif ( h < 0 ) and ( self . t <= T ) :,174
"def transform(self, X): <TAB> if self.preprocessor is None: <TAB>  <TAB> raise NotImplementedError() <TAB> with warnings.catch_warnings(): <TAB>  <TAB> warnings.filterwarnings(""error"") <TAB>  <TAB> X_new = self.preprocessor.transform(X) <TAB>  <TAB> # TODO write a unittest for this case <MASK> raise ValueError(""KernelPCA removed all features!"") <TAB>  <TAB> return X_new",if X_new . shape [ 1 ] == 0 :,102
"def playerData(s): <TAB> """"""Returns a list of tuples of original string and dict of values"""""" <TAB> p = [] <TAB> i = 0 <TAB> while True: <TAB>  <TAB> match = re_input.match(s, pos=i) <MASK> return p <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> d = match.groupdict() <TAB>  <TAB>  <TAB> if d[""args""] is not None: <TAB>  <TAB>  <TAB>  <TAB> d[""degree""], d[""kwargs""] = getArgs(d[""args""]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> d[""degree""], d[""kwargs""] = """", {} <TAB>  <TAB>  <TAB> del d[""args""] <TAB>  <TAB>  <TAB> p.append((match.group().strip(), d)) <TAB>  <TAB>  <TAB> i = match.end() <TAB> return",if match is None :,178
"def extract_deps(file): <TAB> # ~ print('Extracting from %s' % file) <TAB> deps = set() <TAB> for line in open(file).readlines(): <TAB>  <TAB> line = line.strip() <TAB>  <TAB> if line.startswith(""import"") or line.startswith(""from""): <TAB>  <TAB>  <TAB> words = line.split() <MASK> deps.add(words[1]) <TAB> return deps","if words [ 0 ] == ""import"" or ( words [ 0 ] == ""from"" and words [ 2 ] == ""import"" ) :",124
"def _remove_optional_none_type_hints(self, type_hints, defaults): <TAB> # If argument has None as a default, typing.get_type_hints adds <TAB> # optional None to the information it returns. We don't want that. <TAB> for arg in defaults: <MASK> type_ = type_hints[arg] <TAB>  <TAB>  <TAB> if self._is_union(type_): <TAB>  <TAB>  <TAB>  <TAB> types = type_.__args__ <TAB>  <TAB>  <TAB>  <TAB> if len(types) == 2 and types[1] is type(None): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> type_hints[arg] = types[0]",if defaults [ arg ] is None and arg in type_hints :,157
"def _gaf10iterator(handle): <TAB> for inline in handle: <MASK> continue <TAB>  <TAB> inrec = inline.rstrip(""\n"").split(""\t"") <TAB>  <TAB> if len(inrec) == 1: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> inrec[3] = inrec[3].split(""|"")  # Qualifier <TAB>  <TAB> inrec[5] = inrec[5].split(""|"")  # DB:reference(s) <TAB>  <TAB> inrec[7] = inrec[7].split(""|"")  # With || From <TAB>  <TAB> inrec[10] = inrec[10].split(""|"")  # Synonym <TAB>  <TAB> inrec[12] = inrec[12].split(""|"")  # Taxon <TAB>  <TAB> yield dict(zip(GAF10FIELDS, inrec))","if inline [ 0 ] == ""!"" :",188
"def cvePluginInfo(self, cve, **args): <TAB> cveInfo = [] <TAB> for plugin in self.getWebPlugins(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> data = plugin.cvePluginInfo(cve, **args) <MASK> cveInfo.append(data) <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> print( <TAB>  <TAB>  <TAB>  <TAB> ""[!] Plugin %s failed on fetching CVE plugin info!"" % plugin.getName() <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> print(""[!]  -> %s"" % e) <TAB> return cveInfo","if type ( data ) == dict and ""title"" in data and ""data"" in data :",158
"def testLastContainerMarker(self): <TAB> for format in [None, ""json"", ""xml""]: <TAB>  <TAB> containers = self.env.account.containers({""format"": format}) <TAB>  <TAB> self.assertEquals(len(containers), len(self.env.containers)) <TAB>  <TAB> self.assert_status(200) <TAB>  <TAB> containers = self.env.account.containers( <TAB>  <TAB>  <TAB> parms={""format"": format, ""marker"": containers[-1]} <TAB>  <TAB> ) <TAB>  <TAB> self.assertEquals(len(containers), 0) <MASK> self.assert_status(204) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assert_status(200)",if format is None :,155
"def _make_input_layers(self, rebuild=False): <TAB> for name, layer in self.layer_map.items(): <TAB>  <TAB> layer.left_in_edges = len(layer.in_edges) <TAB>  <TAB> if len(layer.in_edges) == 0: <MASK> if not layer.get_attr(""scope""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.input_layers.append(name) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.input_layers.append(name)",if rebuild :,123
"def widget_attrs(self, widget): <TAB> attrs = super(IntegerField, self).widget_attrs(widget) <TAB> if isinstance(widget, NumberInput): <MASK> attrs[""min""] = self.min_value <TAB>  <TAB> if self.max_value is not None: <TAB>  <TAB>  <TAB> attrs[""max""] = self.max_value <TAB> return attrs",if self . min_value is not None :,94
"def _get_outfile(self): <TAB> outfile = self.inputs.transformed_file <TAB> if not isdefined(outfile): <TAB>  <TAB> if self.inputs.inverse is True: <MASK> src = ""orig.mgz"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> src = self.inputs.target_file <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> src = self.inputs.source_file <TAB>  <TAB> outfile = fname_presuffix(src, newpath=os.getcwd(), suffix=""_warped"") <TAB> return outfile",if self . inputs . fs_target is True :,134
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_app_id(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> self.set_num_memcacheg_backends(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 16 :,128
"def try_to_find_osquery(self): <TAB> extention = """" <TAB> if platform.system() == ""Windows"": <TAB>  <TAB> extention = "".exe"" <TAB> try: <TAB>  <TAB> return resources.get_resource(""osqueryi"" + extention) <TAB> except IOError as e: <TAB>  <TAB> # Maybe it is installed on the system. <TAB>  <TAB> if platform.system() == ""Windows"": <TAB>  <TAB>  <TAB> result = r""c:\ProgramData\osquery\osqueryi.exe"" <MASK> return result <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Try to find it somewhere on the system. <TAB>  <TAB>  <TAB> return spawn.find_executable(""osqueryi"") <TAB>  <TAB> raise e","if os . access ( result , os . R_OK ) :",178
"def cleanWhitespace(self, val): <TAB> val = val.replace(""*"", "" AND "").replace(""  "", "" "") <TAB> if re.match(""\S+ \S"", val): <TAB>  <TAB> matchs = re.findall(""(?:^|\(| )(.+?)(?:\)| OR| AND|$)"", val) <TAB>  <TAB> for strMatch in matchs: <MASK> strUnescapeMatch = self.unescapeCharacter(strMatch) <TAB>  <TAB>  <TAB>  <TAB> val = val.replace(strMatch, '""{}""'.format(strUnescapeMatch)) <TAB> return val.strip()","if re . match ( ""\S+ \S"" , strMatch ) :",140
"def keyPressEvent(self, event): <TAB> """"""Add up and down arrow key events to built in functionality."""""" <TAB> keyPressed = event.key() <TAB> if keyPressed in [Constants.UP_KEY, Constants.DOWN_KEY, Constants.TAB_KEY]: <MASK> self.index = max(0, self.index - 1) <TAB>  <TAB> elif keyPressed == Constants.DOWN_KEY: <TAB>  <TAB>  <TAB> self.index = min(len(self.completerStrings) - 1, self.index + 1) <TAB>  <TAB> elif keyPressed == Constants.TAB_KEY and self.completerStrings: <TAB>  <TAB>  <TAB> self.tabPressed() <TAB>  <TAB> if self.completerStrings: <TAB>  <TAB>  <TAB> self.setTextToCompleterIndex() <TAB> super(CueLineEdit, self).keyPressEvent(event)",if keyPressed == Constants . UP_KEY :,192
"def find_parent_for_new_to(self, pos): <TAB> """"""Figure out the parent object for something at 'pos'."""""" <TAB> for children in self._editable_children: <MASK> return children.find_parent_for_new_to(pos) <TAB>  <TAB> if children._start == pos and pos == children._end: <TAB>  <TAB>  <TAB> return children.find_parent_for_new_to(pos) <TAB> return self",if children . _start <= pos < children . _end :,113
"def get_sentence(self): <TAB> while True: <TAB>  <TAB> self._seed += 1 <TAB>  <TAB> all_files = list(self._all_files) <TAB>  <TAB> if self._shuffle: <MASK> random.seed(self._seed) <TAB>  <TAB>  <TAB> random.shuffle(all_files) <TAB>  <TAB> for file_path in all_files: <TAB>  <TAB>  <TAB> for ret in self._load_file(file_path): <TAB>  <TAB>  <TAB>  <TAB> yield ret <TAB>  <TAB> if self._mode == ""test"": <TAB>  <TAB>  <TAB> break",if self . _n_gpus > 1 :,134
"def to_multidevice(batch_iter, num_trainer): <TAB> """"""to_multidevice"""""" <TAB> batch_dict = [] <TAB> for batch in batch_iter(): <TAB>  <TAB> batch_dict.append(batch) <MASK> yield batch_dict <TAB>  <TAB>  <TAB> batch_dict = [] <TAB> if len(batch_dict) > 0: <TAB>  <TAB> log.warning( <TAB>  <TAB>  <TAB> ""The batch (%s) can't fill all device (%s)"" <TAB>  <TAB>  <TAB> ""which will be discarded."" % (len(batch_dict), num_trainer) <TAB>  <TAB> )",if len ( batch_dict ) == num_trainer :,147
"def get_word_parens_range(self, offset, opening=""("", closing="")""): <TAB> end = self._find_word_end(offset) <TAB> start_parens = self.code.index(opening, end) <TAB> index = start_parens <TAB> open_count = 0 <TAB> while index < len(self.code): <TAB>  <TAB> if self.code[index] == opening: <TAB>  <TAB>  <TAB> open_count += 1 <TAB>  <TAB> if self.code[index] == closing: <TAB>  <TAB>  <TAB> open_count -= 1 <MASK> return (start_parens, index + 1) <TAB>  <TAB> index += 1 <TAB> return (start_parens, index)",if open_count == 0 :,160
"def getNodeBySunid(self, sunid): <TAB> """"""Return a node from its sunid."""""" <MASK> return self._sunidDict[sunid] <TAB> if self.db_handle: <TAB>  <TAB> self.getDomainFromSQL(sunid=sunid) <TAB>  <TAB> if sunid in self._sunidDict: <TAB>  <TAB>  <TAB> return self._sunidDict[sunid] <TAB> else: <TAB>  <TAB> return None",if sunid in self . _sunidDict :,123
"def get_cabal_in_dir(cabal_dir): <TAB> """"""Return .cabal file for cabal directory"""""" <TAB> for entry in os.listdir(cabal_dir): <MASK> project_name = os.path.splitext(entry)[0] <TAB>  <TAB>  <TAB> return (project_name, os.path.join(cabal_dir, entry)) <TAB> return (None, None)","if entry . endswith ( "".cabal"" ) :",104
"def authenticate(self, username, password): <TAB> # The user entered an email, so try to log them in by e-mail <TAB> emails = ContactValue.objects.filter( <TAB>  <TAB> value=username, <TAB>  <TAB> field__field_type=""email"", <TAB>  <TAB> contact__trash=False, <TAB>  <TAB> contact__related_user__isnull=False, <TAB> ) <TAB> for email in emails: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> user = email.contact.related_user.user.user <MASK> return user <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> pass <TAB> return None",if user . check_password ( password ) :,147
"def get_art_abs(story_file): <TAB> lines = read_text_file(story_file) <TAB> lines = [line.lower() for line in lines] <TAB> lines = [fix_missing_period(line) for line in lines] <TAB> article_lines = [] <TAB> highlights = [] <TAB> next_is_highlight = False <TAB> for idx, line in enumerate(lines): <MASK> continue  # empty line <TAB>  <TAB> elif line.startswith(""@highlight""): <TAB>  <TAB>  <TAB> next_is_highlight = True <TAB>  <TAB> elif next_is_highlight: <TAB>  <TAB>  <TAB> highlights.append(line) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> article_lines.append(line) <TAB> article = "" "".join(article_lines) <TAB> abstract = "" "".join(highlights) <TAB> return article, abstract","if line == """" :",194
"def find_token(self): <TAB> found = False <TAB> while not found: <TAB>  <TAB> while self.data[self.index] in "" \t"": <TAB>  <TAB>  <TAB> self.index += 1 <MASK> while self.data[self.index] != ""\n"": <TAB>  <TAB>  <TAB>  <TAB> self.index += 1 <TAB>  <TAB> if self.data[self.index] == ""\n"": <TAB>  <TAB>  <TAB> self.index += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> found = True","if self . data [ self . index ] == ""#"" :",123
"def parseBamPEFDistributionFile(self, f): <TAB> d = dict() <TAB> lastsample = [] <TAB> for line in f[""f""].splitlines(): <TAB>  <TAB> cols = line.rstrip().split(""\t"") <TAB>  <TAB> if cols[0] == ""#bamPEFragmentSize"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif cols[0] == ""Size"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> s_name = self.clean_s_name(cols[2].rstrip().split(""/"")[-1], f[""root""]) <MASK> d[s_name] = dict() <TAB>  <TAB>  <TAB>  <TAB> lastsample = s_name <TAB>  <TAB>  <TAB> d[s_name].update({self._int(cols[0]): self._int(cols[1])}) <TAB> return d",if s_name != lastsample :,194
"def get_user_home(): <TAB> if is_win(): <MASK> # Need the fully qualified directory <TAB>  <TAB>  <TAB> output = ( <TAB>  <TAB>  <TAB>  <TAB> subprocess.Popen( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> [""cygpath"", ""-m"", os.path.expanduser(""~"")], <TAB>  <TAB>  <TAB>  <TAB>  <TAB> stdout=subprocess.PIPE, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> stderr=subprocess.STDOUT, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> .communicate()[0] <TAB>  <TAB>  <TAB>  <TAB> .rstrip() <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return output <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return os.environ[""USERPROFILE""] <TAB> else: <TAB>  <TAB> return os.path.expanduser(""~"")","if sys . platform == ""cygwin"" :",164
"def _grouping_intervals(grouping): <TAB> last_interval = None <TAB> for interval in grouping: <TAB>  <TAB> # if grouping is -1, we are done <TAB>  <TAB> if interval == CHAR_MAX: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> # 0: re-use last group ad infinitum <MASK> if last_interval is None: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""invalid grouping"") <TAB>  <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB>  <TAB> yield last_interval <TAB>  <TAB> yield interval <TAB>  <TAB> last_interval = interval",if interval == 0 :,124
def remove_duplicates(model): <TAB> for struct in model.structs: <TAB>  <TAB> fields = [] <TAB>  <TAB> names = [] <TAB>  <TAB> for field in struct.fields: <MASK> names.append(field.name) <TAB>  <TAB>  <TAB>  <TAB> fields.append(field) <TAB>  <TAB> struct.fields = fields,if field . name not in names :,83
"def set_multi(self, value): <TAB> del self[atype] <TAB> for addr in value: <TAB>  <TAB> # Support assigning dictionary versions of addresses <TAB>  <TAB> # instead of full Address objects. <TAB>  <TAB> if not isinstance(addr, Address): <TAB>  <TAB>  <TAB> if atype != ""all"": <TAB>  <TAB>  <TAB>  <TAB> addr[""type""] = atype <MASK> addr[""type""] = addr[""atype""] <TAB>  <TAB>  <TAB> addrObj = Address() <TAB>  <TAB>  <TAB> addrObj.values = addr <TAB>  <TAB>  <TAB> addr = addrObj <TAB>  <TAB> self.append(addr)","elif ""atype"" in addr and ""type"" not in addr :",146
"def import_directives(): <TAB> files_list = os.listdir(os.path.dirname(__file__)) <TAB> for directive_file in files_list: <MASK> continue <TAB>  <TAB> __import__( <TAB>  <TAB>  <TAB> ""gixy.directives."" + os.path.splitext(directive_file)[0], None, None, [""""] <TAB>  <TAB> )","if not directive_file . endswith ( "".py"" ) or directive_file . startswith ( ""_"" ) :",99
"def _get_all_tasks(): <TAB> proc = Popen([""yarn"", ""--help""], stdout=PIPE) <TAB> should_yield = False <TAB> for line in proc.stdout.readlines(): <TAB>  <TAB> line = line.decode().strip() <MASK> should_yield = True <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if should_yield and ""- "" in line: <TAB>  <TAB>  <TAB> yield line.split("" "")[-1]","if ""Commands:"" in line :",103
"def _waitFakenetStopped(self, timeoutsec=None): <TAB> retval = False <TAB> while True: <TAB>  <TAB> if self._confirmFakenetStopped(): <TAB>  <TAB>  <TAB> retval = True <TAB>  <TAB>  <TAB> break <TAB>  <TAB> time.sleep(1) <MASK> timeoutsec -= 1 <TAB>  <TAB>  <TAB> if timeoutsec <= 0: <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return retval",if timeoutsec is not None :,97
"def parse_compare_fail( <TAB> string, <TAB> rex=re.compile( <TAB>  <TAB> r""^(?P<field>min|max|mean|median|stddev|iqr):"" <TAB>  <TAB> r""((?P<percentage>[0-9]?[0-9])%|(?P<difference>[0-9]*\.?[0-9]+([eE][-+]?["" <TAB>  <TAB> r""0-9]+)?))$"" <TAB> ),): <TAB> m = rex.match(string) <TAB> if m: <TAB>  <TAB> g = m.groupdict() <MASK> return PercentageRegressionCheck(g[""field""], int(g[""percentage""])) <TAB>  <TAB> elif g[""difference""]: <TAB>  <TAB>  <TAB> return DifferenceRegressionCheck(g[""field""], float(g[""difference""])) <TAB> raise argparse.ArgumentTypeError(""Could not parse value: %r."" % string)","if g [ ""percentage"" ] :",199
"def get_converter(self, key, default=None): <TAB> """"""Gets a converter for the given key."""""" <TAB> if key in self._vars: <TAB>  <TAB> return self._vars[key].convert <TAB> # necessary for keys that match regexes, such as `*PATH`s <TAB> for k, var in self._vars.items(): <TAB>  <TAB> if isinstance(k, str): <TAB>  <TAB>  <TAB> continue <MASK> converter = var.convert <TAB>  <TAB>  <TAB> self._vars[key] = var <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> converter = self._get_default_converter(default=default) <TAB> return converter",if k . match ( key ) is not None :,154
"def get_model_params(problem_type: str, hyperparameters): <TAB> penalty = hyperparameters.get(""penalty"", L2) <TAB> handle_text = hyperparameters.get(""handle_text"", IGNORE) <TAB> if problem_type == REGRESSION: <TAB>  <TAB> if penalty == L2: <TAB>  <TAB>  <TAB> model_class = Ridge <MASK> model_class = Lasso <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logger.warning( <TAB>  <TAB>  <TAB>  <TAB> ""Unknown value for penalty {} - supported types are [l1, l2] - falling back to l2"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> penalty <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> penalty = L2 <TAB>  <TAB>  <TAB> model_class = Ridge <TAB> else: <TAB>  <TAB> model_class = LogisticRegression <TAB> return model_class, penalty, handle_text",elif penalty == L1 :,200
"def __init__(self, content=None, parent=None): <TAB> Transformable.__init__(self, content, parent) <TAB> self._items = [] <TAB> for element in content: <TAB>  <TAB> if not element.tag.startswith(namespace): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> tag = element.tag[len(namespace) :] <MASK> item = Group(element, self) <TAB>  <TAB> elif tag == ""path"": <TAB>  <TAB>  <TAB> item = Path(element, self) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.warn(""Unhandled SVG tag (%s)"" % tag) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> self._items.append(item)","if tag == ""g"" :",154
"def f_context(args: argparse.Namespace): <TAB> choice = args.choice <TAB> ctx = utils.get_context() <TAB> if choice is None: <MASK> group = ctx.stem <TAB>  <TAB>  <TAB> print(f""{group}: {' '.join(utils.get_groups()[group])}"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""Context is not set"") <TAB> elif choice == ""none"":  # remove context <TAB>  <TAB> ctx and ctx.unlink() <TAB> else:  # set context <TAB>  <TAB> fname = Path(common.get_config_dir()) / (choice + "".context"") <TAB>  <TAB> if ctx: <TAB>  <TAB>  <TAB> ctx.rename(fname) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> open(fname, ""w"").close()",if ctx :,175
"def check_checksum(self): <TAB> """"""fix media checksums"""""" <TAB> self.progress.set_pass( <TAB>  <TAB> _(""Updating checksums on media""), len(self.db.get_media_handles()) <TAB> ) <TAB> for objectid in self.db.get_media_handles(): <TAB>  <TAB> self.progress.step() <TAB>  <TAB> obj = self.db.get_media_from_handle(objectid) <TAB>  <TAB> full_path = media_path_full(self.db, obj.get_path()) <TAB>  <TAB> new_checksum = create_checksum(full_path) <MASK> logging.info(""checksum: updating "" + obj.gramps_id) <TAB>  <TAB>  <TAB> obj.checksum = new_checksum <TAB>  <TAB>  <TAB> self.db.commit_media(obj, self.trans)",if new_checksum != obj . checksum :,196
"def get_default_backend(self, user_backends): <TAB> retval = None <TAB> n_defaults = 0 <TAB> for name in user_backends: <TAB>  <TAB> args = user_backends.get(name) <TAB>  <TAB> if args.get(""default"", False): <TAB>  <TAB>  <TAB> n_defaults = n_defaults + 1 <MASK> retval = name <TAB> return (retval, n_defaults)",if retval is None :,100
"def on_mqtt_packet_received(self, *args, **kwargs): <TAB> packet = kwargs.get(""packet"") <TAB> if packet: <TAB>  <TAB> packet_size = packet.bytes_length <TAB>  <TAB> self._stats[STAT_BYTES_RECEIVED] += packet_size <TAB>  <TAB> self._stats[STAT_MSG_RECEIVED] += 1 <MASK> self._stats[STAT_PUBLISH_RECEIVED] += 1",if packet . fixed_header . packet_type == PUBLISH :,110
"def func(self): <TAB> if self.schema: <TAB>  <TAB> d = {} <TAB>  <TAB> for key in self._schema_keys: <TAB>  <TAB>  <TAB> d[key] = getattr(self, key) <TAB>  <TAB> # arbitrary keys <MASK> akeys = set(self._data.keys()) - set(d.keys()) <TAB>  <TAB>  <TAB> for akey in akeys: <TAB>  <TAB>  <TAB>  <TAB> d[akey] = self._data[akey] <TAB>  <TAB> return d <TAB> else: <TAB>  <TAB> return None",if self . _data :,125
"def endElement(self, name, value, connection): <TAB> if name == ""vpcId"": <TAB>  <TAB> self.vpc_id = value <TAB> elif name == ""value"": <TAB>  <TAB> if value == ""true"": <TAB>  <TAB>  <TAB> value = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = False <MASK> self.enable_dns_hostnames = value <TAB>  <TAB> elif self._current_attr == ""enableDnsSupport"": <TAB>  <TAB>  <TAB> self.enable_dns_support = value","if self . _current_attr == ""enableDnsHostnames"" :",125
"def keyPressEvent(self, event): <TAB> if event.key() in (Qt.Key_Right, Qt.Key_Left): <TAB>  <TAB> direction = 1 <MASK> direction = -1 <TAB>  <TAB> if event.modifiers() == Qt.ShiftModifier: <TAB>  <TAB>  <TAB> print(""shift"") <TAB>  <TAB>  <TAB> direction *= 10 <TAB>  <TAB> self.timeline.setValue(self.timeline.value() + direction) <TAB> else: <TAB>  <TAB> super(VideoPlayerWidget, self).keyPressEvent(event)",if event . key ( ) == Qt . Key_Left :,131
"def find_config(pipeline_config_path: Union[str, Path]) -> Path: <TAB> if not Path(pipeline_config_path).is_file(): <TAB>  <TAB> configs = [ <TAB>  <TAB>  <TAB> c <TAB>  <TAB>  <TAB> for c in Path(__file__).parent.parent.parent.glob( <TAB>  <TAB>  <TAB>  <TAB> f""configs/**/{pipeline_config_path}.json"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> if str(c.with_suffix("""")).endswith(pipeline_config_path) <TAB>  <TAB> ]  # a simple way to not allow * and ? <MASK> log.info(f""Interpreting '{pipeline_config_path}' as '{configs[0]}'"") <TAB>  <TAB>  <TAB> pipeline_config_path = configs[0] <TAB> return Path(pipeline_config_path)",if configs :,184
"def list_translations(dirname): <TAB> if not os.path.isdir(dirname): <TAB>  <TAB> return [] <TAB> result = [] <TAB> for entry in scandir(dirname): <TAB>  <TAB> locale_dir = os.path.join(entry.path, ""LC_MESSAGES"") <TAB>  <TAB> if not os.path.isdir(locale_dir): <TAB>  <TAB>  <TAB> continue <MASK> result.append(Locale.parse(entry.name)) <TAB> return result","if any ( filter ( lambda x : x . name . endswith ( "".mo"" ) , scandir ( locale_dir ) ) ) :",131
"def writeTo(self, writable): <TAB> chunkStart = 0 <TAB> fileSize = blob.properties.content_length <TAB> while chunkStart < fileSize: <TAB>  <TAB> chunkEnd = chunkStart + outer_self._maxAzureBlockBytes - 1 <TAB>  <TAB> buf = container.get_blob_to_bytes( <TAB>  <TAB>  <TAB> blob_name=str(jobStoreFileID), start_range=chunkStart, end_range=chunkEnd <TAB>  <TAB> ).content <MASK> buf = encryption.decrypt(buf, outer_self.keyPath) <TAB>  <TAB> writable.write(buf) <TAB>  <TAB> chunkStart = chunkEnd + 1",if encrypted :,148
"def get_extractor(name): <TAB> for extractor in ALL_EXTRACTORS: <MASK> module = import_module( <TAB>  <TAB>  <TAB>  <TAB> ""anime_downloader.extractors.{}"".format(extractor[""modulename""]) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return getattr(module, extractor[""class""])","if extractor [ ""regex"" ] in name . lower ( ) :",84
"def updateSize(self): <TAB> if self.size is not None: <TAB>  <TAB> return <TAB> height = 0 <TAB> width = 0 <TAB> for row in range(self.layout.rowCount()): <TAB>  <TAB> row_height = 0 <TAB>  <TAB> col_witdh = 0 <TAB>  <TAB> for col in range(self.layout.columnCount()): <TAB>  <TAB>  <TAB> item = self.layout.itemAt(row, col) <MASK> col_witdh += item.width() + 3 <TAB>  <TAB>  <TAB>  <TAB> row_height = max(row_height, item.height()) <TAB>  <TAB> width = max(width, col_witdh) <TAB>  <TAB> height += row_height <TAB> self.setGeometry(0, 0, width, height) <TAB> return",if item :,176
"def close_group(self): <TAB> """"""Closes a grouping for previous filters"""""" <TAB> if self._filters: <MASK> raise RuntimeError(""Not enough open groups to close."") <TAB>  <TAB> if isinstance(self._filters[-1], ChainOperator): <TAB>  <TAB>  <TAB> flt_sentence = self._filters[-2] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> flt_sentence = self._filters[-1] <TAB>  <TAB> flt_sentence[1] = flt_sentence[1] + "")""  # closing the group <TAB>  <TAB> self._close_group_flag.append(False)  # flag a close group was added <TAB> else: <TAB>  <TAB> raise RuntimeError(""No filters present. Can't close a group"") <TAB> return self",if len ( self . _open_group_flag ) < ( len ( self . _close_group_flag ) + 1 ) :,191
"def test_name_conflicts(): <TAB> # Test that we handle participants having the same name correctly. <TAB> ev = fake_event() <TAB> ev2 = fake_event() <TAB> # Office365 sets the name to the email address when it's <TAB> # not available. <TAB> ev2.participants[0][""email""] = None <TAB> ev2.participants[0][""status""] = ""yes"" <TAB> merged_participants = ev._partial_participants_merge(ev2) <TAB> assert len(merged_participants) == 2 <TAB> for participant in merged_participants: <MASK> assert participant[""status""] == ""yes"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert participant[""name""] == ""Ronald Zubar""","if participant [ ""email"" ] is None :",183
"def set_idle(view, idle): <TAB> vid = view.id() <TAB> current_idle = vid in State[""idle_views""] <TAB> if idle != current_idle: <MASK> State[""idle_views""].add(vid) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> State[""idle_views""].discard(vid) <TAB>  <TAB> toggle_demoted_regions(view, idle)",if idle :,95
"def _deserialize(self, value, attr, data, **kwargs): <TAB> if isinstance(value, str): <TAB>  <TAB> return [value, 0, 0] <TAB> if isinstance(value, list) and len(value) == 3: <TAB>  <TAB> condition = ( <TAB>  <TAB>  <TAB> isinstance(value[0], str) <TAB>  <TAB>  <TAB> and isinstance(value[1], int) <TAB>  <TAB>  <TAB> and isinstance(value[1], int) <TAB>  <TAB> ) <MASK> return value <TAB> raise ValidationError(""This field expects a str or a list of [str, int, int]."")",if condition :,134
"def _struct(self, fields): <TAB> result = {} <TAB> for field in fields: <TAB>  <TAB> if field[0] == ""__parent"": <TAB>  <TAB>  <TAB> parent = self.instance(field[1]) <TAB>  <TAB>  <TAB> if isinstance(parent, dict): <TAB>  <TAB>  <TAB>  <TAB> result.update(parent) <MASK> result = parent <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> result[field[0]] = parent <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result[field[0]] = self.instance(field[1]) <TAB> return result",elif len ( fields ) == 1 :,136
"def validate(self): <TAB> if ""accounts"" in self.data and self.data[""accounts""] == ""matched"": <TAB>  <TAB> found = False <TAB>  <TAB> for f in self.manager.iter_filters(): <TAB>  <TAB>  <TAB> if isinstance(f, AmiCrossAccountFilter): <TAB>  <TAB>  <TAB>  <TAB> found = True <TAB>  <TAB>  <TAB>  <TAB> break <MASK> raise PolicyValidationError( <TAB>  <TAB>  <TAB>  <TAB> ""policy:%s filter:%s with matched requires cross-account filter"" <TAB>  <TAB>  <TAB>  <TAB> % (self.manager.ctx.policy.name, self.type) <TAB>  <TAB>  <TAB> )",if not found :,137
"def add_rule6(self, rule): <TAB> if self.cleared: <TAB>  <TAB> return <TAB> self._lock.acquire() <TAB> try: <TAB>  <TAB> self._other6.append(rule) <MASK> self._insert_iptables_rule(rule, ipv6=True) <TAB> finally: <TAB>  <TAB> self._lock.release()","if not self . _exists_iptables_rule ( rule , ipv6 = True ) :",100
"def load_grammar(self, *args): <TAB> ""Load a grammar from a pickle file"" <TAB> filename = askopenfilename( <TAB>  <TAB> filetypes=self.GRAMMAR_FILE_TYPES, defaultextension="".cfg"" <TAB> ) <TAB> if not filename: <TAB>  <TAB> return <TAB> try: <MASK> with open(filename, ""rb"") as infile: <TAB>  <TAB>  <TAB>  <TAB> grammar = pickle.load(infile) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> with open(filename, ""r"") as infile: <TAB>  <TAB>  <TAB>  <TAB> grammar = CFG.fromstring(infile.read()) <TAB>  <TAB> self.set_grammar(grammar) <TAB> except Exception as e: <TAB>  <TAB> tkinter.messagebox.showerror( <TAB>  <TAB>  <TAB> ""Error Loading Grammar"", ""Unable to open file: %r"" % filename <TAB>  <TAB> )","if filename . endswith ( "".pickle"" ) :",186
"def _join_printed_types(self, types): <TAB> """"""Pretty-print the union of the printed types."""""" <TAB> types = sorted(set(types))  # dedup <TAB> if len(types) == 1: <TAB>  <TAB> return next(iter(types)) <TAB> elif types: <MASK> types.remove(""None"") <TAB>  <TAB>  <TAB> return ""Optional[%s]"" % self._join_printed_types(types) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""Union[%s]"" % "", "".join(types) <TAB> else: <TAB>  <TAB> return ""nothing""","if ""None"" in types :",138
"def __init__(self, **kwargs): <TAB> for key, val in kwargs.items(): <TAB>  <TAB> field = getattr(self.__class__, key, None) <MASK> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""Field %r returned from raw SQL query does not have "" <TAB>  <TAB>  <TAB>  <TAB> ""a column defined in the model"" % key <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> setattr(self, field.get_attname() or key, field.to_python(val))",if field is None :,113
"def get_transaction_execution_results(self, batch_signature): <TAB> with self._condition: <TAB>  <TAB> batch_status = self._batch_statuses.get(batch_signature) <MASK> return None <TAB>  <TAB> annotated_batch = self._batch_by_id.get(batch_signature) <TAB>  <TAB> if annotated_batch is None: <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> results = [] <TAB>  <TAB> for txn in annotated_batch.batch.transactions: <TAB>  <TAB>  <TAB> result = self._txn_results.get(txn.header_signature) <TAB>  <TAB>  <TAB> if result is not None: <TAB>  <TAB>  <TAB>  <TAB> results.append(result) <TAB>  <TAB> return results",if batch_status is None :,161
"def _check_params(self) -> None: <TAB> if self.augmentation and self.ratio <= 0: <TAB>  <TAB> raise ValueError(""The augmentation ratio must be positive."") <TAB> if self.clip_values is not None: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""`clip_values` should be a tuple of 2 floats or arrays containing the allowed data range."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if np.array(self.clip_values[0] >= self.clip_values[1]).any(): <TAB>  <TAB>  <TAB> raise ValueError(""Invalid `clip_values`: min >= max."")",if len ( self . clip_values ) != 2 :,146
def ping_all(): <TAB> for l in _all_listeners.values(): <TAB>  <TAB> count = l.receiver.count() <TAB>  <TAB> if count: <TAB>  <TAB>  <TAB> for dev in l.receiver: <TAB>  <TAB>  <TAB>  <TAB> dev.ping() <TAB>  <TAB>  <TAB>  <TAB> l._status_changed(dev) <TAB>  <TAB>  <TAB>  <TAB> count -= 1 <MASK> break,if not count :,92
"def on_btOK_clicked(self, *a): <TAB> """"""Handler for OK button"""""" <TAB> if self.ac_callback is not None: <TAB>  <TAB> self._set_title() <TAB>  <TAB> if self._mode == ActionEditor.AEC_MENUITEM: <TAB>  <TAB>  <TAB> self.ac_callback(self.id, self) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> a = self.generate_modifiers( <TAB>  <TAB>  <TAB>  <TAB> self._action, self._selected_component.NAME == ""custom"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.ac_callback(self.id, a) <TAB>  <TAB>  <TAB> self.ac_callback = None <MASK> self._selected_component.on_ok(a) <TAB> self.close()",if self . _selected_component :,180
"def apply_ssl(self, request): <TAB> if self.ssl_protocol: <MASK> self.sslconf.setProtocol(self.ssl_protocol) <TAB>  <TAB>  <TAB> QSslConfiguration.setDefaultConfiguration(self.sslconf) <TAB> request.setSslConfiguration(self.sslconf) <TAB> return request",if self . sslconf . protocol ( ) != self . ssl_protocol :,91
"def _iter_process_args(mapping, pid, max_depth): <TAB> """"""Iterator to traverse up the tree, yielding each process's argument list."""""" <TAB> for _ in range(max_depth): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> proc = mapping[pid] <TAB>  <TAB> except KeyError:  # We've reached the root process. Give up. <TAB>  <TAB>  <TAB> break <MASK> # Persumably the process should always have a name? <TAB>  <TAB>  <TAB> yield proc.args <TAB>  <TAB> pid = proc.ppid  # Go up one level.",if proc . args :,127
"def store_data(self, store_loc, **kwargs): <TAB> """"""Put arrays to store"""""" <TAB> # print(store_loc) <TAB> g = self.store.create_group(store_loc) <TAB> for ( <TAB>  <TAB> k, <TAB>  <TAB> v, <TAB> ) in kwargs.items(): <TAB>  <TAB> # print(type(v[0])) <TAB>  <TAB> # print(k) <TAB>  <TAB> if type(v) == list: <MASK> if type(v[0]) is np.str_ or type(v[0]) is str: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> v = [a.encode(""utf8"") for a in v] <TAB>  <TAB> g.create_dataset(k, data=v, compression=self.clib, compression_opts=self.clev)",if len ( v ) != 0 :,191
"def add_system_info_creds_to_config(creds): <TAB> for user in creds: <TAB>  <TAB> ConfigService.creds_add_username(creds[user][""username""]) <TAB>  <TAB> if ""password"" in creds[user] and creds[user][""password""]: <TAB>  <TAB>  <TAB> ConfigService.creds_add_password(creds[user][""password""]) <TAB>  <TAB> if ""lm_hash"" in creds[user] and creds[user][""lm_hash""]: <TAB>  <TAB>  <TAB> ConfigService.creds_add_lm_hash(creds[user][""lm_hash""]) <MASK> ConfigService.creds_add_ntlm_hash(creds[user][""ntlm_hash""])","if ""ntlm_hash"" in creds [ user ] and creds [ user ] [ ""ntlm_hash"" ] :",175
"def _format_arg(self, name, spec, value): <TAB> if name == ""title"": <MASK> return ""--title"" <TAB>  <TAB> elif isinstance(value, str): <TAB>  <TAB>  <TAB> return ""--title --title_text %s"" % (value,) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError('Unknown value for ""title"" argument: ' + str(value)) <TAB> return super(Pik, self)._format_arg(name, spec, value)","if isinstance ( value , bool ) and value :",118
"def handle_friend(self): <TAB> tokens, last = self._get_var_tokens_up_to(False, ""("", "";"") <TAB> if last.name == ""("": <TAB>  <TAB> tokens.append(last) <TAB>  <TAB> self._add_back_tokens(tokens) <TAB>  <TAB> token = self._get_next_token() <TAB>  <TAB> while token.name in (""inline"", ""typename"", ""::""): <TAB>  <TAB>  <TAB> token = self._get_next_token() <TAB>  <TAB> result = self._generate_one(token) <TAB> else: <MASK> tokens = tokens[1:] <TAB>  <TAB> result = self.converter.to_type(tokens)[0] <TAB> assert result <TAB> return Friend(result.start, result.end, result, self.namespace_stack)","if tokens [ 0 ] . name == ""class"" :",188
"def list_subtitles(self, video, languages): <TAB> season = None <TAB> episodes = [] <TAB> if isinstance(video, Episode): <TAB>  <TAB> titles = [video.series] + video.alternative_series <TAB>  <TAB> season = video.season <TAB>  <TAB> episodes = video.episodes <TAB> else: <TAB>  <TAB> titles = [video.title] + video.alternative_titles <TAB> for title in titles: <TAB>  <TAB> subtitles = [ <TAB>  <TAB>  <TAB> s <TAB>  <TAB>  <TAB> for l in languages <TAB>  <TAB>  <TAB> for s in self.query( <TAB>  <TAB>  <TAB>  <TAB> l, title, season=season, episodes=episodes, year=video.year <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ] <MASK> return subtitles <TAB> return []",if subtitles :,183
"def on_write_needed(self, nbytes, underflow): <TAB> if underflow: <TAB>  <TAB> self._handle_underflow() <TAB> else: <TAB>  <TAB> self._write_to_stream(nbytes) <TAB> # Asynchronously update time <TAB> if self._events: <MASK> self._time_sync_operation.delete() <TAB>  <TAB>  <TAB> self._time_sync_operation = None <TAB>  <TAB> if self._time_sync_operation is None: <TAB>  <TAB>  <TAB> assert _debug(""PulseAudioPlayer: trigger timing info update"") <TAB>  <TAB>  <TAB> self._time_sync_operation = self.stream.update_timing_info( <TAB>  <TAB>  <TAB>  <TAB> self._process_events <TAB>  <TAB>  <TAB> )",if self . _time_sync_operation is not None and self . _time_sync_operation . is_done :,187
def _set_account_info(self): <TAB> with session_scope(self.account_id) as db_session: <TAB>  <TAB> account = db_session.query(ImapAccount).get(self.account_id) <TAB>  <TAB> self.sync_state = account.sync_state <TAB>  <TAB> self.provider = account.provider <TAB>  <TAB> self.provider_info = account.provider_info <TAB>  <TAB> self.email_address = account.email_address <TAB>  <TAB> self.auth_handler = account.auth_handler <MASK> self.client_cls = GmailCrispinClient <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.client_cls = CrispinClient,"if account . provider == ""gmail"" :",165
"def make_timesheet_records(): <TAB> employees = get_timesheet_based_salary_slip_employee() <TAB> for e in employees: <TAB>  <TAB> ts = make_timesheet( <TAB>  <TAB>  <TAB> e.employee, <TAB>  <TAB>  <TAB> simulate=True, <TAB>  <TAB>  <TAB> billable=1, <TAB>  <TAB>  <TAB> activity_type=get_random(""Activity Type""), <TAB>  <TAB>  <TAB> company=frappe.flags.company, <TAB>  <TAB> ) <TAB>  <TAB> frappe.db.commit() <TAB>  <TAB> rand = random.random() <MASK> make_salary_slip_for_timesheet(ts.name) <TAB>  <TAB> rand = random.random() <TAB>  <TAB> if rand >= 0.2: <TAB>  <TAB>  <TAB> make_sales_invoice_for_timesheet(ts.name)",if rand >= 0.3 :,197
"def free(self, addr, ban=0): <TAB> with self.lock: <MASK> self.ban.append({""addr"": addr, ""counter"": ban}) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> base, bit, is_allocated = self.locate(addr) <TAB>  <TAB>  <TAB> if len(self.addr_map) <= base: <TAB>  <TAB>  <TAB>  <TAB> raise KeyError(""address is not allocated"") <TAB>  <TAB>  <TAB> if self.addr_map[base] & (1 << bit): <TAB>  <TAB>  <TAB>  <TAB> raise KeyError(""address is not allocated"") <TAB>  <TAB>  <TAB> self.allocated -= 1 <TAB>  <TAB>  <TAB> self.addr_map[base] ^= 1 << bit",if ban != 0 :,155
"def flush_log(self): <TAB> try: <TAB>  <TAB> while len(self.log_buffer) > 0: <TAB>  <TAB>  <TAB> level, message = self.log_buffer.pop(0) <MASK> self._display_log(message, level) <TAB> except IndexError: <TAB>  <TAB> pass",if level <= self . log_level :,82
"def check(self): <TAB> global MySQLdb <TAB> import MySQLdb <TAB> try: <TAB>  <TAB> args = {} <TAB>  <TAB> if mysql_user: <TAB>  <TAB>  <TAB> args[""user""] = mysql_user <TAB>  <TAB> if mysql_pwd: <TAB>  <TAB>  <TAB> args[""passwd""] = mysql_pwd <TAB>  <TAB> if mysql_host: <TAB>  <TAB>  <TAB> args[""host""] = mysql_host <MASK> args[""port""] = mysql_port <TAB>  <TAB> if mysql_socket: <TAB>  <TAB>  <TAB> args[""unix_socket""] = mysql_socket <TAB>  <TAB> self.db = MySQLdb.connect(**args) <TAB> except Exception as e: <TAB>  <TAB> raise Exception(""Cannot interface with MySQL server: %s"" % e)",if mysql_port :,167
"def get_middleware_resolvers(middlewares): <TAB> for middleware in middlewares: <TAB>  <TAB> # If the middleware is a function instead of a class <MASK> yield middleware <TAB>  <TAB> if not hasattr(middleware, MIDDLEWARE_RESOLVER_FUNCTION): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> yield getattr(middleware, MIDDLEWARE_RESOLVER_FUNCTION)",if inspect . isfunction ( middleware ) :,93
"def get_sentence(self): <TAB> while True: <TAB>  <TAB> self._seed += 1 <TAB>  <TAB> all_files = list(self._all_files) <MASK> if self._n_gpus > 1: <TAB>  <TAB>  <TAB>  <TAB> random.seed(self._seed) <TAB>  <TAB>  <TAB> random.shuffle(all_files) <TAB>  <TAB> for file_path in all_files: <TAB>  <TAB>  <TAB> for ret in self._load_file(file_path): <TAB>  <TAB>  <TAB>  <TAB> yield ret <TAB>  <TAB> if self._mode == ""test"": <TAB>  <TAB>  <TAB> break",if self . _shuffle :,134
"def extract_cookies(self, response, request): <TAB> """"""Extract cookies from response, where allowable given the request."""""" <TAB> _debug(""extract_cookies: %s"", response.info()) <TAB> self._cookies_lock.acquire() <TAB> try: <TAB>  <TAB> self._policy._now = self._now = int(time.time()) <TAB>  <TAB> for cookie in self.make_cookies(response, request): <MASK> _debug("" setting cookie: %s"", cookie) <TAB>  <TAB>  <TAB>  <TAB> self.set_cookie(cookie) <TAB> finally: <TAB>  <TAB> self._cookies_lock.release()","if self . _policy . set_ok ( cookie , request ) :",152
"def _gen_filename(self, name): <TAB> if name == ""in_average"": <TAB>  <TAB> avg_subject = str(self.inputs.hemisphere) + "".EC_average"" <TAB>  <TAB> avg_directory = os.path.join(self.inputs.subjects_dir, avg_subject) <MASK> fs_home = os.path.abspath(os.environ.get(""FREESURFER_HOME"")) <TAB>  <TAB> return avg_subject <TAB> elif name == ""out_file"": <TAB>  <TAB> return self._list_outputs()[name] <TAB> else: <TAB>  <TAB> return None",if not os . path . isdir ( avg_directory ) :,150
"def decorated_view(*args, **kwargs): <TAB> h = {} <TAB> mechanisms = [(method, login_mechanisms.get(method)) for method in auth_methods] <TAB> for method, mechanism in mechanisms: <TAB>  <TAB> if mechanism and mechanism(): <TAB>  <TAB>  <TAB> return fn(*args, **kwargs) <MASK> r = _security.default_http_auth_realm <TAB>  <TAB>  <TAB> h[""WWW-Authenticate""] = 'Basic realm=""%s""' % r <TAB> if _security._unauthorized_callback: <TAB>  <TAB> return _security._unauthorized_callback() <TAB> else: <TAB>  <TAB> return _get_unauthorized_response(headers=h)","elif method == ""basic"" :",158
"def _iterate_files(self, files, root, include_checksums, relpath): <TAB> file_list = {} <TAB> for file in files: <TAB>  <TAB> exclude = False <TAB>  <TAB> # exclude defined filename patterns <TAB>  <TAB> for pattern in S3Sync.exclude_files: <TAB>  <TAB>  <TAB> if fnmatch.fnmatch(file, pattern): <TAB>  <TAB>  <TAB>  <TAB> exclude = True <TAB>  <TAB>  <TAB>  <TAB> break <MASK> full_path = root + ""/"" + file <TAB>  <TAB>  <TAB> if include_checksums: <TAB>  <TAB>  <TAB>  <TAB> # get checksum <TAB>  <TAB>  <TAB>  <TAB> checksum = self._hash_file(full_path) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> checksum = """" <TAB>  <TAB>  <TAB> file_list[relpath + file] = [full_path, checksum] <TAB> return file_list",if not exclude :,184
"def attr(**kw): <TAB> kw = kw.items() <TAB> kw.sort() <TAB> parts = [] <TAB> for name, value in kw: <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB> continue <MASK> name = name[:-1] <TAB>  <TAB> parts.append('%s=""%s""' % (html_quote(name), html_quote(value))) <TAB> return html("" "".join(parts))","if name . endswith ( ""_"" ) :",100
"def create(self): <TAB> if not self.created: <TAB>  <TAB> self.created = True <TAB>  <TAB> cmd = self._mode <MASK> cmd = u"""" <TAB>  <TAB> vim.command( <TAB>  <TAB>  <TAB> (u"":%snoremap %s %s"" % (cmd, str(self), self.command)).encode(u""utf-8"") <TAB>  <TAB> )",if cmd == MODE_ALL :,97
"def get_tokens_unprocessed(self, text): <TAB> for index, token, value in RegexLexer.get_tokens_unprocessed(self, text): <MASK> if self.stdlibhighlighting and value in self.stdlib_types: <TAB>  <TAB>  <TAB>  <TAB> token = Keyword.Type <TAB>  <TAB>  <TAB> elif self.c99highlighting and value in self.c99_types: <TAB>  <TAB>  <TAB>  <TAB> token = Keyword.Type <TAB>  <TAB>  <TAB> elif self.platformhighlighting and value in self.linux_types: <TAB>  <TAB>  <TAB>  <TAB> token = Keyword.Type <TAB>  <TAB> yield index, token, value",if token is Name :,141
"def _merge_colormaps(kwargs): <TAB> """"""Merge colormaps listed in kwargs."""""" <TAB> from trollimage.colormap import Colormap <TAB> full_cmap = None <TAB> palette = kwargs[""palettes""] <TAB> if isinstance(palette, Colormap): <TAB>  <TAB> full_cmap = palette <TAB> else: <TAB>  <TAB> for itm in palette: <TAB>  <TAB>  <TAB> cmap = create_colormap(itm) <TAB>  <TAB>  <TAB> cmap.set_range(itm[""min_value""], itm[""max_value""]) <MASK> full_cmap = cmap <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> full_cmap = full_cmap + cmap <TAB> return full_cmap",if full_cmap is None :,156
"def from_text(cls, rdclass, rdtype, tok, origin=None, relativize=True): <TAB> key_tag = tok.get_uint16() <TAB> algorithm = tok.get_uint8() <TAB> digest_type = tok.get_uint8() <TAB> chunks = [] <TAB> while 1: <TAB>  <TAB> t = tok.get().unescape() <TAB>  <TAB> if t.is_eol_or_eof(): <TAB>  <TAB>  <TAB> break <MASK> raise dns.exception.SyntaxError <TAB>  <TAB> chunks.append(t.value) <TAB> digest = """".join(chunks) <TAB> digest = digest.decode(""hex_codec"") <TAB> return cls(rdclass, rdtype, key_tag, algorithm, digest_type, digest)",if not t . is_identifier ( ) :,180
"def connect_reader_to_writer(reader, writer): <TAB> BUF_SIZE = 8192 <TAB> try: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> data = await reader.read(BUF_SIZE) <MASK> if not writer.transport.is_closing(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> writer.write_eof() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> await writer.drain() <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> writer.write(data) <TAB>  <TAB>  <TAB> await writer.drain() <TAB> except (OSError, asyncio.IncompleteReadError) as e: <TAB>  <TAB> pass",if not data :,139
"def _get_cuda_device(*args): <TAB> # Returns cuda.Device or DummyDevice. <TAB> for arg in args: <TAB>  <TAB> if type(arg) is not bool and isinstance(arg, _integer_types): <TAB>  <TAB>  <TAB> check_cuda_available() <TAB>  <TAB>  <TAB> return Device(arg) <TAB>  <TAB> if isinstance(arg, ndarray): <TAB>  <TAB>  <TAB> if arg.device is None: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> return arg.device <MASK> return arg <TAB> # NOTE: This function returns DummyDevice for both NumPy and ChainerX <TAB> return DummyDevice","if available and isinstance ( arg , Device ) :",144
"def skip_to_semicolon(s, i): <TAB> n = len(s) <TAB> while i < n: <TAB>  <TAB> c = s[i] <TAB>  <TAB> if c == "";"": <TAB>  <TAB>  <TAB> return i <MASK> i = g.skip_string(s, i) <TAB>  <TAB> elif g.match(s, i, ""//""): <TAB>  <TAB>  <TAB> i = g.skip_to_end_of_line(s, i) <TAB>  <TAB> elif g.match(s, i, ""/*""): <TAB>  <TAB>  <TAB> i = g.skip_block_comment(s, i) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> i += 1 <TAB> return i","elif c == ""'"" or c == '""' :",161
"def build_CallFunc(self, o): <TAB> children = o.getChildren() <TAB> # Build callee from first child <TAB> callee = self.build(children[0]) <TAB> # Build args and kwargs from remaining children <TAB> args = [] <TAB> kwargs = {} <TAB> for child in children[1:]: <TAB>  <TAB> class_name = child.__class__.__name__ <TAB>  <TAB> # None is ignored <TAB>  <TAB> if class_name == ""NoneType"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # Keywords become kwargs <MASK> kwargs.update(self.build(child)) <TAB>  <TAB> # Everything else becomes args <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> args.append(self.build(child)) <TAB> return callee(*args, **kwargs)","if class_name == ""Keyword"" :",175
"def _extract_constant_functions(slither: SlitherCore) -> Dict[str, List[str]]: <TAB> ret: Dict[str, List[str]] = {} <TAB> for contract in slither.contracts: <TAB>  <TAB> cst_functions = [ <TAB>  <TAB>  <TAB> _get_name(f) for f in contract.functions_entry_points if _is_constant(f) <TAB>  <TAB> ] <TAB>  <TAB> cst_functions += [ <TAB>  <TAB>  <TAB> v.function_name <TAB>  <TAB>  <TAB> for v in contract.state_variables <MASK> ] <TAB>  <TAB> if cst_functions: <TAB>  <TAB>  <TAB> ret[contract.name] = cst_functions <TAB> return ret","if v . visibility in [ ""public"" ]",166
"def acquire_read_lock(self, wait=True): <TAB> state = self.state <TAB> if state.writing: <TAB>  <TAB> raise LockError(""lock is in writing state"") <TAB> if state.reentrantcount == 0: <TAB>  <TAB> x = self.do_acquire_read_lock(wait) <MASK> state.reentrantcount += 1 <TAB>  <TAB>  <TAB> state.reading = True <TAB>  <TAB> return x <TAB> elif state.reading: <TAB>  <TAB> state.reentrantcount += 1 <TAB>  <TAB> return True",if wait or x :,124
"def get_optional_nargs(self, name): <TAB> for n, kwargs in self.conf[""optional_args""]: <MASK> if ""action"" in kwargs: <TAB>  <TAB>  <TAB>  <TAB> action = kwargs[""action""] <TAB>  <TAB>  <TAB>  <TAB> if action in (""store_true"", ""store_false""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return 0 <TAB>  <TAB>  <TAB> break <TAB> return 1",if name == n :,92
"def _requests_to_follow(self, response): <TAB> if not isinstance(response, HtmlResponse): <TAB>  <TAB> return <TAB> seen = set() <TAB> for n, rule in enumerate(self._rules): <TAB>  <TAB> links = [ <TAB>  <TAB>  <TAB> lnk <TAB>  <TAB>  <TAB> for lnk in rule.link_extractor.extract_links(response) <MASK> ] <TAB>  <TAB> if links and rule.process_links: <TAB>  <TAB>  <TAB> links = rule.process_links(links) <TAB>  <TAB> for link in links: <TAB>  <TAB>  <TAB> seen.add(link) <TAB>  <TAB>  <TAB> request = self._build_request(n, link) <TAB>  <TAB>  <TAB> yield rule._process_request(request, response)",if lnk not in seen,168
"def process_module(name, module, parent): <TAB> if parent: <TAB>  <TAB> modules[parent][""items""].append(name) <TAB>  <TAB> mg = module_groups.setdefault(name, []) <TAB>  <TAB> mg.append(parent) <TAB>  <TAB> if get_module_type(name) == ""py3status"": <TAB>  <TAB>  <TAB> module["".group""] = parent <TAB> # check module content <TAB> for k, v in list(module.items()): <MASK> # on_click event <TAB>  <TAB>  <TAB> process_onclick(k, v, name) <TAB>  <TAB>  <TAB> # on_click should not be passed to the module via the config. <TAB>  <TAB>  <TAB> del module[k] <TAB>  <TAB> if isinstance(v, ModuleDefinition): <TAB>  <TAB>  <TAB> # we are a container <TAB>  <TAB>  <TAB> module[""items""] = [] <TAB> return module","if k . startswith ( ""on_click"" ) :",198
"def _mysql_version_validator(version, sku_info, tier): <TAB> if version: <TAB>  <TAB> versions = get_mysql_versions(sku_info, tier) <MASK> raise CLIError( <TAB>  <TAB>  <TAB>  <TAB> ""Incorrect value for --version. Allowed values : {}"".format(versions) <TAB>  <TAB>  <TAB> )",if version not in versions :,83
"def do_blocking_test(self, block_func, block_args, trigger_func, trigger_args): <TAB> thread = _TriggerThread(trigger_func, trigger_args) <TAB> thread.start() <TAB> try: <TAB>  <TAB> self.result = block_func(*block_args) <TAB>  <TAB> # If block_func returned before our thread made the call, we failed! <MASK> self.fail(""blocking function '%r' appeared not to block"" % block_func) <TAB>  <TAB> return self.result <TAB> finally: <TAB>  <TAB> thread.join(10)  # make sure the thread terminates <TAB>  <TAB> if thread.is_alive(): <TAB>  <TAB>  <TAB> self.fail(""trigger function '%r' appeared to not return"" % trigger_func)",if not thread . startedEvent . is_set ( ) :,183
"def _fatal_error(self, exc, message=""Fatal error on pipe transport""): <TAB> try: <MASK> if self._loop.get_debug(): <TAB>  <TAB>  <TAB>  <TAB> logger.debug(""%r: %s"", self, message, exc_info=True) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._loop.call_exception_handler( <TAB>  <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""message"": message, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""exception"": exc, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""transport"": self, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""protocol"": self._protocol, <TAB>  <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB> ) <TAB> finally: <TAB>  <TAB> self._force_close(exc)","if isinstance ( exc , OSError ) :",167
"def run_test_family(tests, mode_filter, files, open_func, *make_args): <TAB> for test_func in tests: <MASK> out.write(""\n"") <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if mode_filter in test_func.file_open_mode: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for s in test_func.file_sizes: <TAB>  <TAB>  <TAB> name, size = files[size_names[s]] <TAB>  <TAB>  <TAB> # name += file_ext <TAB>  <TAB>  <TAB> args = tuple(f(name, size) for f in make_args) <TAB>  <TAB>  <TAB> run_one_test(name, size, open_func, test_func, *args)",if test_func is None :,168
"def py__get__(self, obj): <TAB> # Arguments in __get__ descriptors are obj, class. <TAB> # `method` is the new parent of the array, don't know if that's good. <TAB> names = self.get_function_slot_names(""__get__"") <TAB> if names: <MASK> return self.execute_function_slots(names, obj, obj.class_context) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> none_obj = compiled.create(self.evaluator, None) <TAB>  <TAB>  <TAB> return self.execute_function_slots(names, none_obj, obj) <TAB> else: <TAB>  <TAB> return ContextSet(self)","if isinstance ( obj , AbstractInstanceContext ) :",159
"def _options_fcheck(self, name, xflags, table): <TAB> for entry in table: <TAB>  <TAB> if entry.name is None: <TAB>  <TAB>  <TAB> break <MASK> raise XTablesError(""%s: --%s must be specified"" % (name, entry.name)) <TAB>  <TAB>  <TAB> if not xflags & (1 << entry.id): <TAB>  <TAB>  <TAB>  <TAB> continue",if entry . flags & XTOPT_MAND and not xflags & ( 1 << entry . id ) :,112
"def _consumer_healthy(self): <TAB> abnormal_num = 0 <TAB> for w in self._consumers: <TAB>  <TAB> if not w.is_alive() and w.id not in self._consumer_endsig: <TAB>  <TAB>  <TAB> abnormal_num += 1 <MASK> errmsg = ""consumer[{}] exit abnormally with exitcode[{}]"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> w.pid, w.exitcode <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> errmsg = ""consumer[{}] exit abnormally"".format(w.ident) <TAB>  <TAB>  <TAB> logger.warn(errmsg) <TAB> if abnormal_num > 0: <TAB>  <TAB> logger.warn(""{} consumers have exited abnormally!!!"".format(abnormal_num)) <TAB> return abnormal_num == 0",if self . _use_process :,186
"def extract_groups(self, text: str, language_code: str): <TAB> previous = None <TAB> group = 1 <TAB> groups = [] <TAB> words = [] <TAB> ignored = IGNORES.get(language_code, {}) <TAB> for word in NON_WORD.split(text): <MASK> continue <TAB>  <TAB> if word not in ignored and len(word) >= 2: <TAB>  <TAB>  <TAB> if previous == word: <TAB>  <TAB>  <TAB>  <TAB> group += 1 <TAB>  <TAB>  <TAB> elif group > 1: <TAB>  <TAB>  <TAB>  <TAB> groups.append(group) <TAB>  <TAB>  <TAB>  <TAB> words.append(previous) <TAB>  <TAB>  <TAB>  <TAB> group = 1 <TAB>  <TAB> previous = word <TAB> if group > 1: <TAB>  <TAB> groups.append(group) <TAB>  <TAB> words.append(previous) <TAB> return groups, words",if not word :,187
"def _validate_callbacks(cls, callbacks): <TAB> for callback in callbacks: <TAB>  <TAB> if not isinstance(callback, Callback): <MASK> raise TypeError(""Make sure to instantiate the callbacks."") <TAB>  <TAB>  <TAB> raise TypeError(""Only accepts a `callbacks` instance."")","if issubclass ( callback , Callback ) :",70
"def convert_errors(from_, to, msg=None): <TAB> exc = None <TAB> try: <TAB>  <TAB> yield None <TAB> except from_ as e: <TAB>  <TAB> exc = e <TAB> if exc: <TAB>  <TAB> info = ""%s: %s"" % (exc.__class__.__name__, str(exc)) <MASK> info = ""%s: %s"" % (msg, info) <TAB>  <TAB> raise to(info)",if msg :,102
"def delete_loan(loan_key, loan=None): <MASK> loan = web.ctx.site.store.get(loan_key) <TAB>  <TAB> if not loan: <TAB>  <TAB>  <TAB> raise Exception(""Could not find store record for %s"", loan_key) <TAB> loan.delete()",if not loan :,81
"def last_action_for(self, agent_id: AgentID = _DUMMY_AGENT_ID) -> EnvActionType: <TAB> """"""Returns the last action for the specified agent, or zeros."""""" <TAB> if agent_id in self._agent_to_last_action: <TAB>  <TAB> return flatten_to_single_ndarray(self._agent_to_last_action[agent_id]) <TAB> else: <TAB>  <TAB> policy = self._policies[self.policy_for(agent_id)] <TAB>  <TAB> flat = flatten_to_single_ndarray(policy.action_space.sample()) <MASK> return np.zeros_like(flat, dtype=policy.action_space.dtype) <TAB>  <TAB> return np.zeros_like(flat)","if hasattr ( policy . action_space , ""dtype"" ) :",185
"def on_leave( <TAB> self, original_node: CSTNodeT, updated_node: CSTNodeT) -> Union[cst.Import, cst.ImportFrom, CSTNodeT, RemovalSentinel]: <TAB> if isinstance(updated_node, cst.Import): <TAB>  <TAB> for alias in updated_node.names: <TAB>  <TAB>  <TAB> name = alias.name <TAB>  <TAB>  <TAB> if isinstance(name, cst.Name) and name.value == ""b"": <TAB>  <TAB>  <TAB>  <TAB> return cst.RemoveFromParent() <TAB> elif isinstance(updated_node, cst.ImportFrom): <TAB>  <TAB> module = updated_node.module <MASK> return cst.RemoveFromParent() <TAB> return updated_node","if isinstance ( module , cst . Name ) and module . value == ""e"" :",183
"def sortkey(self, r, prog=None): <TAB> ret = [] <TAB> for col, reverse in self._ordering: <MASK> col = self.column(col) <TAB>  <TAB> val = col.getTypedValue(r) <TAB>  <TAB> ret.append(Reversor(val) if reverse else val) <TAB> if prog: <TAB>  <TAB> prog.addProgress(1) <TAB> return ret","if isinstance ( col , str ) :",102
"def down_button_clicked(self, obj): <TAB> ref = self.get_selected() <TAB> if ref and ref[1] is not None: <TAB>  <TAB> pos = self.find_index(ref) <MASK> self._move_down(pos, ref[1]) <TAB> elif ref and ref[1] is None: <TAB>  <TAB> self._move_down_group(ref[0])",if pos [ 1 ] >= 0 and pos [ 1 ] < len ( self . get_data ( ) [ pos [ 0 ] ] ) - 1 :,122
"def maybe_swap_for_shadow_path(self, path: str) -> str: <TAB> if not self.shadow_map: <TAB>  <TAB> return path <TAB> path = normpath(path, self.options) <TAB> previously_checked = path in self.shadow_equivalence_map <TAB> if not previously_checked: <TAB>  <TAB> for source, shadow in self.shadow_map.items(): <MASK> self.shadow_equivalence_map[path] = shadow <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.shadow_equivalence_map[path] = None <TAB> shadow_file = self.shadow_equivalence_map.get(path) <TAB> return shadow_file if shadow_file else path","if self . fscache . samefile ( path , source ) :",179
"def _add_kid(key, x): <TAB> if x is None: <TAB>  <TAB> kids[key] = None <TAB> else: <TAB>  <TAB> if type(x) in (type([]), type(())): <TAB>  <TAB>  <TAB> x1 = [i for i in x if isinstance(i, TVTKBase)] <TAB>  <TAB>  <TAB> if x1: <TAB>  <TAB>  <TAB>  <TAB> kids[key] = x1 <MASK> if hasattr(x, ""__iter__""): <TAB>  <TAB>  <TAB>  <TAB> # Don't add iterable objects that contain non <TAB>  <TAB>  <TAB>  <TAB> # acceptable nodes <TAB>  <TAB>  <TAB>  <TAB> if len(list(x)) and isinstance(list(x)[0], TVTKBase): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> kids[key] = x <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> kids[key] = x","elif isinstance ( x , TVTKBase ) :",196
"def find_zone_id(domain, client=None): <TAB> paginator = client.get_paginator(""list_hosted_zones"") <TAB> zones = [] <TAB> for page in paginator.paginate(): <TAB>  <TAB> for zone in page[""HostedZones""]: <MASK> if not zone[""Config""][""PrivateZone""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> zones.append((zone[""Name""], zone[""Id""])) <TAB> if not zones: <TAB>  <TAB> raise ValueError(""Unable to find a Route53 hosted zone for {}"".format(domain)) <TAB> return zones[0][1]","if domain . endswith ( zone [ ""Name"" ] ) or ( domain + ""."" ) . endswith ( zone [ ""Name"" ] ) :",147
"def render(self, context): <TAB> for condition, nodelist in self.conditions_nodelists: <TAB>  <TAB> if condition is not None:  # if / elif clause <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> match = condition.eval(context) <TAB>  <TAB>  <TAB> except VariableDoesNotExist: <TAB>  <TAB>  <TAB>  <TAB> match = None <TAB>  <TAB> else:  # else clause <TAB>  <TAB>  <TAB> match = True <MASK> return nodelist.render(context) <TAB> return """"",if match :,109
"def init_weight(self): <TAB> if self.pretrained is not None: <TAB>  <TAB> load_entire_model(self, self.pretrained) <TAB> else: <TAB>  <TAB> for sublayer in self.sublayers(): <MASK> kaiming_normal_init(sublayer.weight) <TAB>  <TAB>  <TAB> elif isinstance(sublayer, (nn.BatchNorm, nn.SyncBatchNorm)): <TAB>  <TAB>  <TAB>  <TAB> kaiming_normal_init(sublayer.weight)","if isinstance ( sublayer , nn . Conv2D ) :",120
"def _next_empty_row(view, pt): <TAB> r = utils.row_at(view, pt) <TAB> while True: <TAB>  <TAB> r += 1 <TAB>  <TAB> pt = view.text_point(r, 0) <TAB>  <TAB> if utils.row_at(view, pt) == utils.last_row(view): <TAB>  <TAB>  <TAB> return view.size(), True <MASK> return pt, False",if view . line ( pt ) . empty ( ) :,106
"def __init__(self, parent, name, max_size=None, description=None): <TAB> Field.__init__(self, parent, name, size=0, description=description) <TAB> value = 0 <TAB> addr = self.absolute_address <TAB> while max_size is None or self._size < max_size: <TAB>  <TAB> byte = parent.stream.readBits(addr, 8, LITTLE_ENDIAN) <TAB>  <TAB> value += byte <TAB>  <TAB> self._size += 8 <MASK> break <TAB>  <TAB> addr += 8 <TAB> self.createValue = lambda: value",if byte != 0xFF :,140
"def xdir(obj, return_values=False): <TAB> for attr in dir(obj): <TAB>  <TAB> if attr[:2] != ""__"" and attr[-2:] != ""__"": <MASK> yield attr, getattr(obj, attr) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield attr",if return_values :,76
"def _extract_changes(doc_map, changes, read_time): <TAB> deletes = [] <TAB> adds = [] <TAB> updates = [] <TAB> for name, value in changes.items(): <TAB>  <TAB> if value == ChangeType.REMOVED: <TAB>  <TAB>  <TAB> if name in doc_map: <TAB>  <TAB>  <TAB>  <TAB> deletes.append(name) <MASK> if read_time is not None: <TAB>  <TAB>  <TAB>  <TAB> value.read_time = read_time <TAB>  <TAB>  <TAB> updates.append(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if read_time is not None: <TAB>  <TAB>  <TAB>  <TAB> value.read_time = read_time <TAB>  <TAB>  <TAB> adds.append(value) <TAB> return (deletes, adds, updates)",elif name in doc_map :,173
"def endElement(self, name): <TAB> if self._is_active is True: <MASK> self._is_active = False <TAB>  <TAB>  <TAB> self._tag_level = None <TAB>  <TAB>  <TAB> if _callable(self._callback): <TAB>  <TAB>  <TAB>  <TAB> self._callback(self._record) <TAB>  <TAB>  <TAB> self._record = None <TAB>  <TAB> elif self._level == self._tag_level + 1: <TAB>  <TAB>  <TAB> if name != ""xref"": <TAB>  <TAB>  <TAB>  <TAB> self._record[name] = """".join(self._tag_payload) <TAB>  <TAB>  <TAB>  <TAB> self._tag_payload = None <TAB>  <TAB>  <TAB>  <TAB> self._tag_feeding = False <TAB> self._level -= 1","if name == ""record"" and self . _tag_level == self . _level :",175
"def init_worker( <TAB> status_queue: multiprocessing.SimpleQueue, <TAB> param_queue: multiprocessing.SimpleQueue, <TAB> result_queue: multiprocessing.SimpleQueue,) -> None: <TAB> global result <TAB> global coverage_run <TAB> # Make sure the generator is re-seeded, as we have inherited <TAB> # the seed from the parent process. <TAB> random.seed() <TAB> result = ChannelingTestResult(result_queue) <TAB> if not param_queue.empty(): <TAB>  <TAB> server_addr = param_queue.get() <MASK> os.environ[""EDGEDB_TEST_CLUSTER_ADDR""] = json.dumps(server_addr) <TAB> coverage_run = devmode.CoverageConfig.start_coverage_if_requested() <TAB> status_queue.put(True)",if server_addr is not None :,190
"def wait(uuid: str, kind: str, max_retries: int): <TAB> """"""Delete an s3 subpath."""""" <TAB> from polyaxon import settings <TAB> from polyaxon.agents.spawners.spawner import Spawner <TAB> spawner = Spawner(namespace=settings.CLIENT_CONFIG.namespace, in_cluster=True) <TAB> retry = 1 <TAB> while retry < max_retries: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> k8s_operation = spawner.get(run_uuid=uuid, run_kind=kind) <TAB>  <TAB> except:  # noqa <TAB>  <TAB>  <TAB> k8s_operation = None <MASK> retry += 1 <TAB>  <TAB>  <TAB> time.sleep(retry) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return <TAB> sys.exit(1)",if k8s_operation :,187
def _get_data_fields(): <TAB> global supported_kinds <TAB> ret = [] <TAB> for data in supported_kinds: <TAB>  <TAB> msg = ifinfmsg.ifinfo.data_map.get(data) <TAB>  <TAB> if msg is not None: <MASK> ret += [msg.nla2name(i[0]) for i in msg.nla_map] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> ret += [ifinfmsg.nla2name(i[0]) for i in msg.nla_map] <TAB> return ret,"if getattr ( msg , ""prefix"" , None ) is not None :",146
"def loop_check(self): <TAB> in_loop = [] <TAB> # Add the tag for dfs check <TAB> for node in self.nodes: <TAB>  <TAB> node.dfs_loop_status = ""DFS_UNCHECKED"" <TAB> # Now do the job <TAB> for node in self.nodes: <TAB>  <TAB> # Run the dfs only if the node has not been already done */ <MASK> self.dfs_loop_search(node) <TAB>  <TAB> # If LOOP_INSIDE, must be returned <TAB>  <TAB> if node.dfs_loop_status == ""DFS_LOOP_INSIDE"": <TAB>  <TAB>  <TAB> in_loop.append(node) <TAB> # Remove the tag <TAB> for node in self.nodes: <TAB>  <TAB> del node.dfs_loop_status <TAB> return in_loop","if node . dfs_loop_status == ""DFS_UNCHECKED"" :",199
"def _find_config(args, app_desc): <TAB> path = os.path.join(args.galaxy_root, app_desc.destination) <TAB> if not os.path.exists(path): <TAB>  <TAB> path = None <TAB>  <TAB> for possible_ini_config_rel in app_desc.config_paths: <TAB>  <TAB>  <TAB> possible_ini_config = os.path.join( <TAB>  <TAB>  <TAB>  <TAB> args.galaxy_root, possible_ini_config_rel <TAB>  <TAB>  <TAB> ) <MASK> path = possible_ini_config <TAB> if path is None: <TAB>  <TAB> _warn(USING_SAMPLE_MESSAGE % path) <TAB>  <TAB> path = os.path.join(args.galaxy_root, app_desc.sample_destination) <TAB> return path",if os . path . exists ( possible_ini_config ) :,198
"def parseArgs(self, argv): <TAB> if sys.version_info < (3, 4): <TAB>  <TAB> # We want these options to work on all versions, emulate them. <TAB>  <TAB> if ""-R"" in argv: <TAB>  <TAB>  <TAB> argv.remove(""-R"") <TAB>  <TAB>  <TAB> self.refleak = True <MASK> argv.remove(""-m"") <TAB>  <TAB>  <TAB> self.multiprocess = True <TAB> super(NumbaTestProgram, self).parseArgs(argv) <TAB> if self.verbosity <= 0: <TAB>  <TAB> # We aren't interested in informational messages / warnings when <TAB>  <TAB> # running with '-q'. <TAB>  <TAB> self.buffer = True","if ""-m"" in argv :",160
"def filter_custom_selected_callback(indices, old, new): <TAB> logger.info(""filter custom callback"") <TAB> filter_label.text = ""Please Wait..."" <TAB> global all_topics, apply_filter <TAB> if new != [-1]: <TAB>  <TAB> apply_filter = True <TAB>  <TAB> selected_topics = [filter_custom_table_source.data[""topics""][x] for x in new] <TAB>  <TAB> for i, line in enumerate(all_topics): <MASK> all_topics[i][2] = ""1"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> all_topics[i][2] = ""0"" <TAB> filter_label.text = """"",if line [ 0 ] in selected_topics :,168
"def number_operators(self, a, b, skip=[]): <TAB> dict = {""a"": a, ""b"": b} <TAB> for name, expr in self.binops.items(): <TAB>  <TAB> if name not in skip: <TAB>  <TAB>  <TAB> name = ""__%s__"" % name <MASK> res = eval(expr, dict) <TAB>  <TAB>  <TAB>  <TAB> self.binop_test(a, b, res, expr, name) <TAB> for name, expr in list(self.unops.items()): <TAB>  <TAB> if name not in skip: <TAB>  <TAB>  <TAB> name = ""__%s__"" % name <TAB>  <TAB>  <TAB> if hasattr(a, name): <TAB>  <TAB>  <TAB>  <TAB> res = eval(expr, dict) <TAB>  <TAB>  <TAB>  <TAB> self.unop_test(a, res, expr, name)","if hasattr ( a , name ) :",189
"def reader_matches(self, text): <TAB> text = text[1:] <TAB> matches = [] <TAB> for p in self.reader_path: <TAB>  <TAB> for k in p.keys(): <MASK> if k.startswith(text): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> matches.append(""#{}"".format(k)) <TAB> return matches","if isinstance ( k , string_types ) :",88
"def load_templates(templates: List[JobTemplateConfig]) -> None: <TAB> handlers = { <TAB>  <TAB> TemplateSubmitHandler: build_template_func, <TAB> } <TAB> for handler in handlers: <TAB>  <TAB> for name in dir(handler): <MASK> continue <TAB>  <TAB>  <TAB> delattr(handler, name) <TAB>  <TAB> for template in templates: <TAB>  <TAB>  <TAB> setattr(handler, template.name, handlers[handler](template))","if name . startswith ( ""_"" ) :",106
"def scan_resource_conf(self, conf): <TAB> if ""properties"" in conf: <TAB>  <TAB> if ""supportsHttpsTrafficOnly"" in conf[""properties""]: <TAB>  <TAB>  <TAB> if str(conf[""properties""][""supportsHttpsTrafficOnly""]).lower() == ""true"": <TAB>  <TAB>  <TAB>  <TAB> return CheckResult.PASSED <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return CheckResult.FAILED <TAB> # Use default if supportsHttpsTrafficOnly is not set <TAB> if ""apiVersion"" in conf: <TAB>  <TAB> # Default for apiVersion 2019 and newer is supportsHttpsTrafficOnly = True <TAB>  <TAB> year = int(conf[""apiVersion""][0:4]) <MASK> return CheckResult.FAILED <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return CheckResult.PASSED <TAB> return CheckResult.FAILED",if year < 2019 :,192
"def gather_failed_tests(output): <TAB> if output.upper() == ""NONE"": <TAB>  <TAB> return [] <TAB> gatherer = GatherFailedTests() <TAB> tests_or_tasks = ""tests or tasks"" <TAB> try: <TAB>  <TAB> suite = ExecutionResult(output, include_keywords=False).suite <TAB>  <TAB> suite.visit(gatherer) <TAB>  <TAB> tests_or_tasks = ""tests"" if not suite.rpa else ""tasks"" <MASK> raise DataError(""All %s passed."" % tests_or_tasks) <TAB> except: <TAB>  <TAB> raise DataError( <TAB>  <TAB>  <TAB> ""Collecting failed %s from '%s' failed: %s"" <TAB>  <TAB>  <TAB> % (tests_or_tasks, output, get_error_message()) <TAB>  <TAB> ) <TAB> return gatherer.tests",if not gatherer . tests :,198
"def ds_leak(): <TAB> print(""Testing vlens for dataset r/w"") <TAB> print(""-----------------------------"") <TAB> with h5py.File(FNAME, ""w"") as f: <TAB>  <TAB> ds = f.create_dataset(""dset"", (1000,), dtype=dt) <TAB>  <TAB> for idx in range(500): <TAB>  <TAB>  <TAB> # print idx <MASK> print_memory() <TAB>  <TAB>  <TAB> ds[...] = data <TAB>  <TAB>  <TAB> ds[...]",if idx % 100 == 0 :,115
"def extract_geth_traces(input, batch_size, output, max_workers): <TAB> """"""Extracts geth traces from JSON lines file."""""" <TAB> with smart_open(input, ""r"") as geth_traces_file: <MASK> traces_iterable = (json.loads(line) for line in geth_traces_file) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> traces_iterable = (trace for trace in csv.DictReader(geth_traces_file)) <TAB>  <TAB> job = ExtractGethTracesJob( <TAB>  <TAB>  <TAB> traces_iterable=traces_iterable, <TAB>  <TAB>  <TAB> batch_size=batch_size, <TAB>  <TAB>  <TAB> max_workers=max_workers, <TAB>  <TAB>  <TAB> item_exporter=traces_item_exporter(output), <TAB>  <TAB> ) <TAB>  <TAB> job.run()","if input . endswith ( "".json"" ) :",193
"def save_project_as(): <TAB> if PROJECT().last_save_path != None: <TAB>  <TAB> open_dir = os.path.dirname(PROJECT().last_save_path) <TAB>  <TAB> # We don't  want to open hidden cache dir when saving file opened as autosave. <MASK> open_dir = expanduser(""~"") <TAB> else: <TAB>  <TAB> open_dir = expanduser(""~"") <TAB> dialogs.save_project_as_dialog(_save_as_dialog_callback, PROJECT().name, open_dir)",if open_dir . startswith ( userfolders . get_cache_dir ( ) ) == True :,139
def _skip_to_next_iteration_group(self): <TAB> while True: <MASK> pass <TAB>  <TAB> elif self._tgtkey is self._marker: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if not self._tgtkey == self._currkey: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> newvalue = next(self._iterator) <TAB>  <TAB> if self._keyfunc is None: <TAB>  <TAB>  <TAB> newkey = newvalue <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> newkey = self._keyfunc(newvalue) <TAB>  <TAB> self._currkey = newkey <TAB>  <TAB> self._currvalue = newvalue,if self . _currkey is self . _marker :,153
"def extractNames(self, names): <TAB> offset = names[""offset""].value <TAB> for header in names.array(""header""): <TAB>  <TAB> key = header[""nameID""].value <TAB>  <TAB> foffset = offset + header[""offset""].value <TAB>  <TAB> field = names.getFieldByAddress(foffset * 8) <TAB>  <TAB> if not field or not isString(field): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> value = field.value <TAB>  <TAB> if key not in self.NAMEID_TO_ATTR: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> key = self.NAMEID_TO_ATTR[key] <MASK> # ""Version 1.2"" => ""1.2"" <TAB>  <TAB>  <TAB> value = value[8:] <TAB>  <TAB> setattr(self, key, value)","if key == ""version"" and value . startswith ( u""Version "" ) :",189
"def visit_BoolOp(self, node): <TAB> for i, value in enumerate(node.values): <MASK> self.visit(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.visit(value) <TAB>  <TAB>  <TAB> self.visit(node.op)",if i == len ( node . values ) - 1 :,75
"def list_sparkline_type_id_values( <TAB> date_range_sparkline, correlation_type, type_id, key_id): <TAB> sparklines_value = [] <TAB> for date_day in date_range_sparkline: <TAB>  <TAB> nb_seen_this_day = r_serv_metadata.hget( <TAB>  <TAB>  <TAB> ""{}:{}:{}"".format(correlation_type, type_id, date_day), key_id <TAB>  <TAB> ) <MASK> nb_seen_this_day = 0 <TAB>  <TAB> sparklines_value.append(int(nb_seen_this_day)) <TAB> return sparklines_value",if nb_seen_this_day is None :,164
"def find_nameless_urls(self, conf): <TAB> nameless = [] <TAB> patterns = self.get_patterns(conf) <TAB> for u in patterns: <TAB>  <TAB> if self.has_patterns(u): <TAB>  <TAB>  <TAB> nameless.extend(self.find_nameless_urls(u)) <TAB>  <TAB> else: <MASK> nameless.append(u) <TAB> return nameless",if u . name is None :,103
"def find_zone_id(domain, client=None): <TAB> paginator = client.get_paginator(""list_hosted_zones"") <TAB> zones = [] <TAB> for page in paginator.paginate(): <TAB>  <TAB> for zone in page[""HostedZones""]: <TAB>  <TAB>  <TAB> if domain.endswith(zone[""Name""]) or (domain + ""."").endswith(zone[""Name""]): <MASK> zones.append((zone[""Name""], zone[""Id""])) <TAB> if not zones: <TAB>  <TAB> raise ValueError(""Unable to find a Route53 hosted zone for {}"".format(domain)) <TAB> return zones[0][1]","if not zone [ ""Config"" ] [ ""PrivateZone"" ] :",147
"def _lookup_reference(self, reference): <TAB> if not reference.startswith(""#/""): <TAB>  <TAB> return <TAB> path = reference[2:].split(""/"") <TAB> pointer = self.swagger <TAB> for component in path: <MASK> raise IndexError( <TAB>  <TAB>  <TAB>  <TAB> ""Can't find location by reference %r at part %r"" <TAB>  <TAB>  <TAB>  <TAB> % (reference, component) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> pointer = pointer[component] <TAB> self.log.debug(""Found by reference %r: %r"", reference, pointer) <TAB> return pointer",if component not in pointer :,134
"def read_line_from_file(ff): <TAB> # assuming that ff contains BV <TAB> line = b"""" <TAB> while True: <TAB>  <TAB> vv = ff.read_data(1)[0] <TAB>  <TAB> if vv.symbolic: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> ct = bytes(chr(vv.args[0]), ""utf-8"") <MASK> break <TAB>  <TAB> line += ct <TAB> return line","if ct == b""\n"" :",105
"def gaussian(N=1000, draw=True, show=True, seed=42, color=None, marker=""sphere""): <TAB> """"""Show N random gaussian distributed points using a scatter plot."""""" <TAB> import ipyvolume as ipv <TAB> rng = np.random.RandomState(seed)  # pylint: disable=no-member <TAB> x, y, z = rng.normal(size=(3, N)) <TAB> if draw: <TAB>  <TAB> if color: <TAB>  <TAB>  <TAB> mesh = ipv.scatter(x, y, z, marker=marker, color=color) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> mesh = ipv.scatter(x, y, z, marker=marker) <MASK> # ipv.squarelim() <TAB>  <TAB>  <TAB> ipv.show() <TAB>  <TAB> return mesh <TAB> else: <TAB>  <TAB> return x, y, z",if show :,191
"def test_read_only_directory(self): <TAB> with _inside_empty_temp_dir(): <TAB>  <TAB> oldmode = mode = os.stat(tempfile.tempdir).st_mode <TAB>  <TAB> mode &= ~(stat.S_IWUSR | stat.S_IWGRP | stat.S_IWOTH) <TAB>  <TAB> os.chmod(tempfile.tempdir, mode) <TAB>  <TAB> try: <MASK> self.skipTest(""can't set the directory read-only"") <TAB>  <TAB>  <TAB> with self.assertRaises(PermissionError): <TAB>  <TAB>  <TAB>  <TAB> self.make_temp() <TAB>  <TAB>  <TAB> self.assertEqual(os.listdir(tempfile.tempdir), []) <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> os.chmod(tempfile.tempdir, oldmode)","if os . access ( tempfile . tempdir , os . W_OK ) :",185
"def is_checked_sls_template(template): <TAB> if template.__contains__(""provider""): <TAB>  <TAB> # Case provider is a dictionary <TAB>  <TAB> if isinstance(template[""provider""], dict_node): <TAB>  <TAB>  <TAB> if template[""provider""].get(""name"").lower() not in SUPPORTED_PROVIDERS: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> # Case provider is direct provider name <MASK> if template[""provider""] not in SUPPORTED_PROVIDERS: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True <TAB> return False","if isinstance ( template [ ""provider"" ] , str_node ) :",131
"def detail(self, req): <TAB> resp_backup = super(BackupsController, self).detail(req) <TAB> context = req.environ[""cinder.context""] <TAB> req_version = req.api_version_request <TAB> if req_version.matches(mv.BACKUP_PROJECT): <MASK> for bak in resp_backup[""backups""]: <TAB>  <TAB>  <TAB>  <TAB> self._add_backup_project_attribute(req, bak) <TAB> if req_version.matches(mv.BACKUP_PROJECT_USER_ID): <TAB>  <TAB> if context.authorize(policy.BACKUP_ATTRIBUTES_POLICY, fatal=False): <TAB>  <TAB>  <TAB> for bak in resp_backup[""backups""]: <TAB>  <TAB>  <TAB>  <TAB> self._add_backup_user_attribute(req, bak) <TAB> return resp_backup","if context . authorize ( policy . BACKUP_ATTRIBUTES_POLICY , fatal = False ) :",196
"def genConditional(self): <TAB> for i in range(3): <TAB>  <TAB> x = 0 <TAB>  <TAB> try: <MASK> continue <TAB>  <TAB>  <TAB> x = 1 <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> for j in range(x, x + 2): <TAB>  <TAB>  <TAB>  <TAB> yield j",if i == 2 :,76
def _cacheAffectedBones(self): <TAB> self._affectedBones = [] <TAB> for f_idx in range(self.nFrames): <TAB>  <TAB> frameData = self.getAtFramePos(f_idx) <TAB>  <TAB> self._affectedBones.append([]) <TAB>  <TAB> for b_idx in range(self.nBones): <MASK> self._affectedBones[f_idx].append(b_idx),if not isRest ( frameData [ b_idx ] ) :,116
"def load_metrics(self, filename, config_dict): <TAB> # we don't try to validate metrics keys <TAB> if ""metrics"" in config_dict: <TAB>  <TAB> metrics = config_dict[""metrics""] <MASK> error(""c['metrics'] must be a dictionary"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.metrics = metrics","if not isinstance ( metrics , dict ) :",87
"def _decode_list_response(response: Iterable[Any], decode: bool) -> Any: <TAB> if decode is True: <TAB>  <TAB> new_response = [] <TAB>  <TAB> for val in response: <MASK> val = val.decode(""utf-8"") <TAB>  <TAB>  <TAB> new_response.append(val) <TAB>  <TAB> return new_response <TAB> return response","if isinstance ( val , bytes ) :",94
"def _np_convert_in_place(d): <TAB> """"""Convert any jax devicearray leaves to numpy arrays in place."""""" <TAB> if isinstance(d, dict): <TAB>  <TAB> for k, v in d.items(): <MASK> d[k] = np.array(v) <TAB>  <TAB>  <TAB> elif isinstance(v, dict): <TAB>  <TAB>  <TAB>  <TAB> _np_convert_in_place(v) <TAB> elif isinstance(d, jax.xla.DeviceArray): <TAB>  <TAB> return np.array(d) <TAB> return d","if isinstance ( v , jax . xla . DeviceArray ) :",141
"def reader(): <TAB> with tarfile.open(filename, mode=""r"") as f: <TAB>  <TAB> names = (each_item.name for each_item in f if sub_name in each_item.name) <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> for name in names: <MASK> batch = pickle.load(f.extractfile(name)) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> batch = pickle.load(f.extractfile(name), encoding=""bytes"") <TAB>  <TAB>  <TAB>  <TAB> for item in read_batch(batch): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield item <TAB>  <TAB>  <TAB> if not cycle: <TAB>  <TAB>  <TAB>  <TAB> break",if six . PY2 :,157
"def _Determine_Do(self): <TAB> self.applicable = 1 <TAB> method = ""moz-src"" <TAB> method_arg = None <TAB> for opt, optarg in self.chosenOptions: <TAB>  <TAB> if opt == ""--moz-src"": <TAB>  <TAB>  <TAB> method = ""moz-src"" <MASK> method = ""moz-objdir"" <TAB>  <TAB>  <TAB> method_arg = optarg <TAB> if method == ""moz-src"": <TAB>  <TAB> self.value = self._get_mozilla_objdir() <TAB> elif method == ""moz-objdir"": <TAB>  <TAB> self.value = self._use_mozilla_objdir(method_arg) <TAB> else: <TAB>  <TAB> raise black.configure.ConfigureError(""bogus method: %r"" % method) <TAB> self.determined = 1","elif opt == ""--moz-objdir"" :",188
"def close_all(map=None, ignore_all=False): <TAB> if map is None:  # pragma: no cover <TAB>  <TAB> map = socket_map <TAB> for x in list(map.values()):  # list() FBO py3 <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> x.close() <TAB>  <TAB> except OSError as x: <TAB>  <TAB>  <TAB> if x.args[0] == EBADF: <TAB>  <TAB>  <TAB>  <TAB> pass <MASK> raise <TAB>  <TAB> except _reraised_exceptions: <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> if not ignore_all: <TAB>  <TAB>  <TAB>  <TAB> raise <TAB> map.clear()",elif not ignore_all :,157
"def _attributes_to_xml(self, xml_element, prefix_root, debug_context=None): <TAB> del debug_context  # Unused. <TAB> for attribute_name, attribute in six.iteritems(self._attributes): <TAB>  <TAB> attribute_value = attribute.to_xml_string(prefix_root) <MASK> xml_element.set(attribute_name, self.full_identifier) <TAB>  <TAB> elif attribute_value is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> xml_element.set(attribute_name, attribute_value)",if attribute_name == self . _spec . identifier and attribute_value is None :,149
"def parse(s): <TAB> """"""Parse the output below to create a new StopWatch."""""" <TAB> stopwatch = StopWatch() <TAB> for line in s.splitlines(): <TAB>  <TAB> if line.strip(): <TAB>  <TAB>  <TAB> parts = line.split(None) <TAB>  <TAB>  <TAB> name = parts[0] <MASK> # ie not the header line <TAB>  <TAB>  <TAB>  <TAB> rest = (float(v) for v in parts[2:]) <TAB>  <TAB>  <TAB>  <TAB> stopwatch.times[parts[0]].merge(Stat.build(*rest)) <TAB> return stopwatch","if name != ""%"" :",128
"def reverse_adjust_line_according_to_hunks(self, hunks, line): <TAB> for hunk in reversed(hunks): <TAB>  <TAB> head_start = hunk.head_start <TAB>  <TAB> saved_start = hunk.saved_start <TAB>  <TAB> if hunk.saved_length == 0: <TAB>  <TAB>  <TAB> saved_start += 1 <MASK> saved_start -= 1 <TAB>  <TAB> head_end = head_start + hunk.head_length <TAB>  <TAB> saved_end = saved_start + hunk.saved_length <TAB>  <TAB> if saved_end <= line: <TAB>  <TAB>  <TAB> return head_end + line - saved_end <TAB>  <TAB> elif saved_start <= line: <TAB>  <TAB>  <TAB> return head_start <TAB> # fails to find matching <TAB> return line",elif hunk . head_length == 0 :,193
"def add(self, *args): <TAB> self._digest = None <TAB> llt = Hasher.list_like_types <TAB> for arg in args: <TAB>  <TAB> t = type(arg) <MASK> self._hasher.update(bytes(f""{llt[t]} {len(arg)}"", ""utf8"")) <TAB>  <TAB>  <TAB> self.add(*arg) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._hasher.update(bytes(str(arg), ""utf8""))",if t in llt :,119
"def filter(self, qs, value): <TAB> if value: <TAB>  <TAB> if value.start is not None and value.stop is not None: <TAB>  <TAB>  <TAB> value = (value.start, value.stop) <MASK> self.lookup_expr = ""startswith"" <TAB>  <TAB>  <TAB> value = value.start <TAB>  <TAB> elif value.stop is not None: <TAB>  <TAB>  <TAB> self.lookup_expr = ""endswith"" <TAB>  <TAB>  <TAB> value = value.stop <TAB> return super().filter(qs, value)",elif value . start is not None :,125
"def _getResourceData(self, jid, dataname): <TAB> """"""Return specific jid's resource representation in internal format. Used internally."""""" <TAB> if jid.find(""/"") + 1: <TAB>  <TAB> jid, resource = jid.split(""/"", 1) <TAB>  <TAB> if self._data[jid][""resources""].has_key(resource): <TAB>  <TAB>  <TAB> return self._data[jid][""resources""][resource][dataname] <TAB> elif self._data[jid][""resources""].keys(): <TAB>  <TAB> lastpri = -129 <TAB>  <TAB> for r in self._data[jid][""resources""].keys(): <MASK> resource, lastpri = r, int(self._data[jid][""resources""][r][""priority""]) <TAB>  <TAB> return self._data[jid][""resources""][resource][dataname]","if int ( self . _data [ jid ] [ ""resources"" ] [ r ] [ ""priority"" ] ) > lastpri :",194
"def OnGetText(self, node_id): <TAB> try: <TAB>  <TAB> ea, rows = self[node_id] <MASK> colour = self.colours[ea] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> colour = 0xFFFFFF <TAB>  <TAB> ret = [] <TAB>  <TAB> for row in rows: <TAB>  <TAB>  <TAB> ret.append(row[2]) <TAB>  <TAB> label = ""\n"".join(ret) <TAB>  <TAB> return (label, colour) <TAB> except: <TAB>  <TAB> print(""GraphViewer.OnGetText:"", sys.exc_info()[1]) <TAB>  <TAB> return (""ERROR"", 0x000000)",if ea in self . colours :,150
"def _apply_scales(array, scales, dtype): <TAB> """"""Apply scales to the array."""""" <TAB> new_array = np.empty(array.shape, dtype) <TAB> for i in array.dtype.names: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> new_array[i] = array[i] * scales[i] <TAB>  <TAB> except TypeError: <MASK> new_array[i] = array[i] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise <TAB> return new_array",if np . all ( scales [ i ] == 1 ) :,130
"def run(self): <TAB> self.running = True <TAB> while self.running: <TAB>  <TAB> errCode, bytes, key, overlapped = GetQueuedCompletionStatus( <TAB>  <TAB>  <TAB> self.io_req_port, INFINITE <TAB>  <TAB> ) <TAB>  <TAB> if key == ISAPI_SHUTDOWN and overlapped is None: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> # Let the parent extension handle the command. <TAB>  <TAB> dispatcher = self.extension.dispatch_map.get(key) <MASK> raise RuntimeError(""Bad request '%s'"" % (key,)) <TAB>  <TAB> dispatcher(errCode, bytes, key, overlapped)",if dispatcher is None :,144
"def on_task_filter(self, task, config): <TAB> if task.options.learn: <TAB>  <TAB> log.info(""Plugin limit_new is disabled with --learn"") <TAB>  <TAB> return <TAB> amount = config <TAB> for index, entry in enumerate(task.accepted): <MASK> log.verbose(""Allowed %s (%s)"" % (entry[""title""], entry[""url""])) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> entry.reject(""limit exceeded"") <TAB>  <TAB>  <TAB> # Also save this in backlog so that it can be accepted next time. <TAB>  <TAB>  <TAB> plugin.get(""backlog"", self).add_backlog(task, entry) <TAB> log.debug( <TAB>  <TAB> ""Rejected: %s Allowed: %s"" <TAB>  <TAB> % (len(task.accepted[amount:]), len(task.accepted[:amount])) <TAB> )",if index < amount :,196
"def initialize_pairs(self): <TAB> # White on Black is fixed as color_pair 0 <TAB> self._defined_pairs[""WHITE_BLACK""] = (0, curses.COLOR_WHITE, curses.COLOR_BLACK) <TAB> for cp in self.__class__._colors_to_define: <MASK> # silently protect the user from breaking things. <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> self.initalize_pair(cp[0], cp[1], cp[2])","if cp [ 0 ] == ""WHITE_BLACK"" :",118
"def get_story_task_body(payload: Dict[str, Any], action: str) -> str: <TAB> primary_action = get_action_with_primary_id(payload) <TAB> kwargs = { <TAB>  <TAB> ""task_description"": primary_action[""description""], <TAB>  <TAB> ""action"": action, <TAB> } <TAB> for a in payload[""actions""]: <MASK> kwargs[""name_template""] = STORY_NAME_TEMPLATE.format( <TAB>  <TAB>  <TAB>  <TAB> name=a[""name""], <TAB>  <TAB>  <TAB>  <TAB> app_url=a[""app_url""], <TAB>  <TAB>  <TAB> ) <TAB> return STORY_TASK_TEMPLATE.format(**kwargs)","if a [ ""entity_type"" ] == ""story"" :",163
"def _key_remap(key, keys, item): <TAB> elements_list = [] <TAB> for r_item in item.get(key, []): <TAB>  <TAB> element = {} <TAB>  <TAB> for r_outkey, r_inkey in six.iteritems(keys): <MASK> element[r_outkey] = r_item.get(r_inkey) <TAB>  <TAB> elements_list.append(element) <TAB> return elements_list",if r_inkey in r_item :,115
"def fix_identities(self, uniq=None): <TAB> """"""Make pattern-tree tips point to same object if they are equal."""""" <TAB> if not hasattr(self, ""children""): <TAB>  <TAB> return self <TAB> uniq = list(set(self.flat())) if uniq is None else uniq <TAB> for i, c in enumerate(self.children): <MASK> assert c in uniq <TAB>  <TAB>  <TAB> self.children[i] = uniq[uniq.index(c)] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> c.fix_identities(uniq)","if not hasattr ( c , ""children"" ) :",138
"def _apply_main_args(main_args, exec_args): <TAB> i = 0 <TAB> while i < len(exec_args): <MASK> exec_args[i : i + 1] = main_args <TAB>  <TAB>  <TAB> i += len(main_args) <TAB>  <TAB> i += 1","if exec_args [ i ] == ""${main_args}"" :",87
"def _clean_text(self, text): <TAB> """"""Performs invalid character removal and whitespace cleanup on text."""""" <TAB> output = [] <TAB> char_idx = [] <TAB> for i, char in enumerate(text): <TAB>  <TAB> cp = ord(char) <MASK> continue <TAB>  <TAB> if _is_whitespace(char): <TAB>  <TAB>  <TAB> output.append("" "") <TAB>  <TAB>  <TAB> char_idx.append(i) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> output.append(char) <TAB>  <TAB>  <TAB> char_idx.append(i) <TAB> return """".join(output), char_idx",if cp == 0 or cp == 0xFFFD or _is_control ( char ) :,151
"def upgrade_state_dict_named(self, state_dict, name): <TAB> prefix = name + ""."" if name != """" else """" <TAB> for k, v in state_dict.items(): <TAB>  <TAB> if k.endswith(prefix + ""weight""): <MASK> state_dict[k] = v.squeeze(1)",if v . dim ( ) == 3 and v . size ( 1 ) == 1 :,96
"def fetch_with_retry(self): <TAB> for i in range(self.max_retries): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.is_truncated, self.next_marker = self._fetch() <TAB>  <TAB> except ServerError as e: <MASK> raise <TAB>  <TAB>  <TAB> if i == self.max_retries - 1: <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return",if e . status // 100 != 5 :,107
"def hg_hook(ui, repo, node=None, **kwargs): <TAB> """"""Run pylama after mercurial commit."""""" <TAB> seen = set() <TAB> paths = [] <TAB> if len(repo): <TAB>  <TAB> for rev in range(repo[node], len(repo)): <TAB>  <TAB>  <TAB> for file_ in repo[rev].files(): <TAB>  <TAB>  <TAB>  <TAB> file_ = op.join(repo.root, file_) <MASK> continue <TAB>  <TAB>  <TAB>  <TAB> seen.add(file_) <TAB>  <TAB>  <TAB>  <TAB> paths.append(file_) <TAB> options = parse_options() <TAB> setup_logger(options) <TAB> if paths: <TAB>  <TAB> process_paths(options, candidates=paths)",if file_ in seen or not op . exists ( file_ ) :,177
"def test_playlist_items(self): <TAB> playlists = self.spotify.user_playlists(self.username, limit=5) <TAB> self.assertTrue(""items"" in playlists) <TAB> for playlist in playlists[""items""]: <MASK> continue <TAB>  <TAB> pid = playlist[""id""] <TAB>  <TAB> results = self.spotify.playlist_items(pid) <TAB>  <TAB> self.assertEqual(len(results[""items""]), 0)","if playlist [ ""uri"" ] != self . new_playlist_uri :",111
"def update_execute_option_setting( <TAB> css_selector_of_option_status, css_selector_of_option): <TAB> retry = 3 <TAB> check_status = self.driver.find_element_by_css_selector( <TAB>  <TAB> css_selector_of_option_status <TAB> ) <TAB> if ""visibility-hidden"" not in check_status.get_attribute(""class""): <TAB>  <TAB> while retry > 0: <TAB>  <TAB>  <TAB> self.find_by_css_selector(css_selector_of_option).click() <TAB>  <TAB>  <TAB> time.sleep(0.2) <MASK> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> retry -= 1","if ""visibility-hidden"" in check_status . get_attribute ( ""class"" ) :",175
"def _validate_config(self): <TAB> # convert comma separated strings to lists (ConfigParser) <TAB> for item in [""to"", ""cc"", ""bcc""]: <TAB>  <TAB> if item in self.app.config.keys(self._meta.config_section): <TAB>  <TAB>  <TAB> value = self.app.config.get(self._meta.config_section, item) <TAB>  <TAB>  <TAB> # convert a comma-separated string to a list <MASK> value_list = value.split("","") <TAB>  <TAB>  <TAB>  <TAB> # clean up extra space if they had it inbetween commas <TAB>  <TAB>  <TAB>  <TAB> value_list = [x.strip() for x in value_list] <TAB>  <TAB>  <TAB>  <TAB> # set the new extensions value in the config <TAB>  <TAB>  <TAB>  <TAB> self.app.config.set(self._meta.config_section, item, value_list)",if type ( value ) is str :,199
"def cell_func(combo, render, model, iter_, *args): <TAB> value = model.get_value(iter_) <TAB> if value is None: <TAB>  <TAB> text = escape(_(""System Default"")) <TAB> else: <MASK> value = u""en"" <TAB>  <TAB> text = ""%s <span weight='light'>(%s)</span>"" % ( <TAB>  <TAB>  <TAB> escape(value), <TAB>  <TAB>  <TAB> escape(iso639.translate(value.split(""_"", 1)[0])), <TAB>  <TAB> ) <TAB> render.set_property(""markup"", text)","if value == u""C"" :",133
"def _get_all_tasks(): <TAB> proc = Popen([""yarn"", ""--help""], stdout=PIPE) <TAB> should_yield = False <TAB> for line in proc.stdout.readlines(): <TAB>  <TAB> line = line.decode().strip() <TAB>  <TAB> if ""Commands:"" in line: <TAB>  <TAB>  <TAB> should_yield = True <TAB>  <TAB>  <TAB> continue <MASK> yield line.split("" "")[-1]","if should_yield and ""- "" in line :",103
"def _staged_model_references(self, load_relationships=False): <TAB> for name, field in self._fields.items(): <TAB>  <TAB> if isinstance(field, BaseRelationship): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> if load_relationships: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value = getattr(self, name) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value = self.data_store.get(name, (""staged"", ""committed"")) <TAB>  <TAB>  <TAB> except (AttributeError, KeyError, PathResolutionError): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> value = [value] <TAB>  <TAB>  <TAB> for related in value: <TAB>  <TAB>  <TAB>  <TAB> related_name = field.related_name <TAB>  <TAB>  <TAB>  <TAB> yield related, related_name","if not isinstance ( value , ModelCollection ) :",198
"def get_all_fix_names(fixer_pkg, remove_prefix=True): <TAB> """"""Return a sorted list of all available fix names in the given package."""""" <TAB> pkg = __import__(fixer_pkg, [], [], [""*""]) <TAB> fixer_dir = os.path.dirname(pkg.__file__) <TAB> fix_names = [] <TAB> for name in sorted(os.listdir(fixer_dir)): <TAB>  <TAB> if name.startswith(""fix_"") and name.endswith("".py""): <MASK> name = name[4:] <TAB>  <TAB>  <TAB> fix_names.append(name[:-3]) <TAB> return fix_names",if remove_prefix :,147
"def extract_info_to_dest(self, info, dest): <TAB> """"""Extracts the given info to a directory and checks the file size."""""" <TAB> self.zip_file.extract(info, dest) <TAB> dest = os.path.join(dest, info.filename) <TAB> if not os.path.isdir(dest): <TAB>  <TAB> # Directories consistently report their size incorrectly. <TAB>  <TAB> size = os.stat(dest)[stat.ST_SIZE] <MASK> log.error( <TAB>  <TAB>  <TAB>  <TAB> ""Extraction error, uncompressed size: %s, %s not %s"" <TAB>  <TAB>  <TAB>  <TAB> % (self.source, size, info.file_size) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> raise forms.ValidationError(gettext(""Invalid archive.""))",if size != info . file_size :,182
"def _close_brackets(self, fragment): <TAB> # If there any unclosed brackets in the text we try to close them <TAB> # and we return part with closing brackets if they are ""closable"" <TAB> stack = [] <TAB> for char in fragment: <MASK> stack.append(char) <TAB>  <TAB> elif char in self._PARENS.values(): <TAB>  <TAB>  <TAB> if stack and self._PARENS[stack[-1]] == char: <TAB>  <TAB>  <TAB>  <TAB> stack.pop() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return """" <TAB> return """".join(self._PARENS[paren] for paren in reversed(stack))",if char in self . _PARENS . keys ( ) :,150
"def __call__(self, input_tensors, shape): <TAB> if self.order in ""KA"": <TAB>  <TAB> if any(t.order == TensorOrder.C_ORDER for t in input_tensors): <TAB>  <TAB>  <TAB> order = TensorOrder.C_ORDER <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> order = TensorOrder.F_ORDER <TAB> else: <MASK> order = TensorOrder.C_ORDER <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> order = TensorOrder.F_ORDER <TAB> return self.new_tensor(input_tensors, shape=shape, dtype=self.dtype, order=order)","if self . order == ""C"" :",141
"def __iter__(self): <TAB> iteration = self.start_iter <TAB> while iteration <= self.num_iterations: <TAB>  <TAB> # if the underlying sampler has a set_epoch method, like <TAB>  <TAB> # DistributedSampler, used for making each process see <TAB>  <TAB> # a different split of the dataset, then set it <MASK> self.batch_sampler.sampler.set_epoch(iteration) <TAB>  <TAB> for batch in self.batch_sampler: <TAB>  <TAB>  <TAB> iteration += 1 <TAB>  <TAB>  <TAB> if iteration > self.num_iterations: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> yield batch","if hasattr ( self . batch_sampler . sampler , ""set_epoch"" ) :",151
def all_pairs_shortest_path(adjacency_matrix): <TAB> new_array = copy.deepcopy(adjacency_matrix) <TAB> for k in range(len(new_array)): <TAB>  <TAB> for i in range(len(new_array)): <TAB>  <TAB>  <TAB> for j in range(len(new_array)): <MASK> new_array[i][j] = new_array[i][k] + new_array[k][j] <TAB> return new_array,if new_array [ i ] [ j ] > new_array [ i ] [ k ] + new_array [ k ] [ j ] :,142
"def cancel_pp(self, nzo_id): <TAB> """"""Change the status, so that the PP is canceled"""""" <TAB> for nzo in self.history_queue: <TAB>  <TAB> if nzo.nzo_id == nzo_id: <TAB>  <TAB>  <TAB> nzo.abort_direct_unpacker() <MASK> nzo.pp_active = False <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # Try to kill any external running process <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.external_process.kill() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> logging.info( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Killed external process %s"", self.external_process.args[0] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> return True <TAB> return None",if nzo . pp_active :,196
"def cvPreprocess(): <TAB> import cv2 <TAB> imgarr_orig = [] <TAB> image_ext_list = ["".jpg"", "".png"", "".JPEG"", "".jpeg"", "".PNG"", "".JPG""] <TAB> for file in onlyfiles: <TAB>  <TAB> fimg = imgroot + file <TAB>  <TAB> if any([x in image_ext_list for x in fimg]): <TAB>  <TAB>  <TAB> print(fimg + "" is not an image file"") <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> img1 = cv2.imread(fimg) <MASK> print(""ERROR opening "", fimg) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> img1 = cv2.resize(img1, (896, 896)) <TAB>  <TAB> imgarr_orig.append(img1) <TAB> return imgarr_orig",if img1 is None :,187
"def substituteargs(self, pattern, replacement, old): <TAB> new = [] <TAB> for k in range(len(replacement)): <TAB>  <TAB> item = replacement[k] <TAB>  <TAB> newitem = [item[0], item[1], item[2]] <TAB>  <TAB> for i in range(3): <TAB>  <TAB>  <TAB> if item[i] == ""*"": <TAB>  <TAB>  <TAB>  <TAB> newitem[i] = old[k][i] <MASK> index = int(item[i][1:]) - 1 <TAB>  <TAB>  <TAB>  <TAB> newitem[i] = old[index][i] <TAB>  <TAB> new.append(tuple(newitem)) <TAB> ##self.report(""old: %r"", old) <TAB> ##self.report(""new: %r"", new) <TAB> return new","elif item [ i ] [ : 1 ] == ""$"" :",187
"def process(self, profile): <TAB> contributors = self.createContributors(profile) <TAB> for contributor in contributors: <MASK> reasons = self.createExecSqlNodeReason(contributor, profile) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> reasons = self.createExecNodeReason(contributor, profile) <TAB>  <TAB> contributor.reason = reasons <TAB> return contributors","if contributor . type == ""SQLOperator"" :",106
"def showImage(filename): <TAB> osName = platform.system() <TAB> if osName == ""Windows"": <TAB>  <TAB> subprocess.Popen([filename], shell=True) <TAB> elif osName == ""Linux"": <TAB>  <TAB> # TODO: should I leave it to user's config ? <TAB>  <TAB> LINUX_DISPLAY_COMMAND = (""xdg-open"", ""display"", ""gvfs-open"", ""shotwell"") <TAB>  <TAB> commands = list(filter(HasCommand, LINUX_DISPLAY_COMMAND)) <MASK> # command found <TAB>  <TAB>  <TAB> subprocess.Popen([commands[0], filename]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise <TAB> elif osName == ""Darwin"":  # by @Naville <TAB>  <TAB> subprocess.Popen([""open"", filename]) <TAB> else: <TAB>  <TAB> raise Exception(""other system"")",if commands :,187
"def add_libdirs(self, envvar, sep, fatal=False): <TAB> v = os.environ.get(envvar) <TAB> if not v: <TAB>  <TAB> return <TAB> for dir in str.split(v, sep): <TAB>  <TAB> dir = str.strip(dir) <TAB>  <TAB> if not dir: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> dir = os.path.normpath(dir) <MASK> if not dir in self.library_dirs: <TAB>  <TAB>  <TAB>  <TAB> self.library_dirs.append(dir) <TAB>  <TAB> elif fatal: <TAB>  <TAB>  <TAB> fail(""FATAL: bad directory %s in environment variable %s"" % (dir, envvar))",if os . path . isdir ( dir ) :,159
"def add(self, state): <TAB> if state.key in self: <MASK> raise sa_exc.InvalidRequestError( <TAB>  <TAB>  <TAB>  <TAB> ""Can't attach instance "" <TAB>  <TAB>  <TAB>  <TAB> ""%s; another instance with key %s is already "" <TAB>  <TAB>  <TAB>  <TAB> ""present in this session."" % (orm_util.state_str(state), state.key) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return False <TAB> else: <TAB>  <TAB> self._dict[state.key] = state.obj() <TAB>  <TAB> self._manage_incoming_state(state) <TAB>  <TAB> return True",if attributes . instance_state ( self . _dict [ state . key ] ) is not state :,154
"def request(self, stream=None, tty=None, demux=None): <TAB> assert stream is not None and tty is not None and demux is not None <TAB> with APIClient(base_url=self.address, version=DEFAULT_DOCKER_API_VERSION) as client: <MASK> url = client._url(""/tty"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> url = client._url(""/no-tty"") <TAB>  <TAB> resp = client._post(url, stream=True) <TAB>  <TAB> return client._read_from_socket(resp, stream=stream, tty=tty, demux=demux)",if tty :,147
"def select(model, path, iter_, paths_): <TAB> (paths, first) = paths_ <TAB> value = model.get_value(iter_) <TAB> if value is None: <TAB>  <TAB> return not bool(paths) <TAB> value = normalize_path(value) <TAB> if value in paths: <TAB>  <TAB> self.get_child().get_selection().select_path(path) <TAB>  <TAB> paths.remove(value) <MASK> self.get_child().set_cursor(path) <TAB>  <TAB>  <TAB> # copy treepath, gets invalid after the callback <TAB>  <TAB>  <TAB> first.append(path.copy()) <TAB> else: <TAB>  <TAB> for fpath in paths: <TAB>  <TAB>  <TAB> if fpath.startswith(value): <TAB>  <TAB>  <TAB>  <TAB> self.get_child().expand_row(path, False) <TAB> return not bool(paths)",if not first :,194
"def _validate(self, qobj): <TAB> for experiment in qobj.experiments: <MASK> logger.warning( <TAB>  <TAB>  <TAB>  <TAB> ""no measurements in circuit '%s', "" <TAB>  <TAB>  <TAB>  <TAB> ""classical register will remain all zeros."", <TAB>  <TAB>  <TAB>  <TAB> experiment.header.name, <TAB>  <TAB>  <TAB> )","if ""measure"" not in [ op . name for op in experiment . instructions ] :",93
"def exitval_from_opts(options, project): <TAB> exit_value_from = options.get(""--exit-code-from"") <TAB> if exit_value_from: <TAB>  <TAB> if not options.get(""--abort-on-container-exit""): <TAB>  <TAB>  <TAB> log.warning(""using --exit-code-from implies --abort-on-container-exit"") <TAB>  <TAB>  <TAB> options[""--abort-on-container-exit""] = True <MASK> log.error( <TAB>  <TAB>  <TAB>  <TAB> 'No service named ""%s"" was found in your compose file.', exit_value_from <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> sys.exit(2) <TAB> return exit_value_from",if exit_value_from not in [ s . name for s in project . get_services ( ) ] :,178
"def __call__(self, tokens, reader): <TAB> first_return = False <TAB> for token in tokens: <MASK> reader.context.current_function.exit_count = 1 <TAB>  <TAB>  <TAB> first_return = True <TAB>  <TAB> if token == ""return"": <TAB>  <TAB>  <TAB> if first_return: <TAB>  <TAB>  <TAB>  <TAB> first_return = False <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> reader.context.current_function.exit_count += 1 <TAB>  <TAB> yield token","if not hasattr ( reader . context . current_function , ""exit_count"" ) :",128
"def _register_builtin_handlers(self, events): <TAB> for spec in handlers.BUILTIN_HANDLERS: <TAB>  <TAB> if len(spec) == 2: <TAB>  <TAB>  <TAB> event_name, handler = spec <TAB>  <TAB>  <TAB> self.register(event_name, handler) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> event_name, handler, register_type = spec <TAB>  <TAB>  <TAB> if register_type is handlers.REGISTER_FIRST: <TAB>  <TAB>  <TAB>  <TAB> self._events.register_first(event_name, handler) <MASK> self._events.register_last(event_name, handler)",elif register_type is handlers . REGISTER_LAST :,148
"def test_sql(self): <TAB> with self.get_temp() as temp: <TAB>  <TAB> railroad = to_railroad(simpleSQL) <TAB>  <TAB> assert len(railroad) == 7 <TAB>  <TAB> temp.write(railroad_to_html(railroad)) <MASK> print(""sql: "" + temp.name)",if self . railroad_debug ( ) :,93
"def resources_to_link(self, resources): <TAB> if isinstance(self.Bucket, dict) and ""Ref"" in self.Bucket: <TAB>  <TAB> bucket_id = self.Bucket[""Ref""] <TAB>  <TAB> if not isinstance(bucket_id, string_types): <TAB>  <TAB>  <TAB> raise InvalidEventException( <TAB>  <TAB>  <TAB>  <TAB> self.relative_id, ""'Ref' value in S3 events is not a valid string."" <TAB>  <TAB>  <TAB> ) <MASK> return {""bucket"": resources[bucket_id], ""bucket_id"": bucket_id} <TAB> raise InvalidEventException( <TAB>  <TAB> self.relative_id, ""S3 events must reference an S3 bucket in the same template."" <TAB> )",if bucket_id in resources :,166
"def list_target_unit_files(self, *modules):  # -> [ (unit,enabled) ] <TAB> """"""show all the target units and the enabled status"""""" <TAB> result = {} <TAB> enabled = {} <TAB> for unit in _all_common_targets: <TAB>  <TAB> result[unit] = None <TAB>  <TAB> enabled[unit] = ""static"" <TAB>  <TAB> if unit in _all_common_enabled: <TAB>  <TAB>  <TAB> enabled[unit] = ""enabled"" <MASK> enabled[unit] = ""enabled"" <TAB> return [(unit, enabled[unit]) for unit in sorted(result)]",if unit in _all_common_disabled :,147
"def teardown_network_port(self): <TAB> """"""tearDown for Network and Port table"""""" <TAB> networks = self.quantum.get_all_networks(""t1"") <TAB> for net in networks: <TAB>  <TAB> netid = net[""net-id""] <TAB>  <TAB> name = net[""net-name""] <MASK> ports = self.quantum.get_all_ports(netid) <TAB>  <TAB>  <TAB> for por in ports: <TAB>  <TAB>  <TAB>  <TAB> self.quantum.delete_port(netid, por[""port-id""]) <TAB>  <TAB>  <TAB> self.quantum.delete_network(netid)","if ""net"" in name :",148
"def findConfigFiles(self, cfg_args): <TAB> """"""Find available config files"""""" <TAB> filenames = cfg_args.config[:] <TAB> proj_opts = (""unittest.cfg"", ""nose2.cfg"") <TAB> for fn in proj_opts: <MASK> fn = os.path.abspath(os.path.join(cfg_args.top_level_directory, fn)) <TAB>  <TAB> filenames.append(fn) <TAB> if cfg_args.user_config: <TAB>  <TAB> user_opts = (""~/.unittest.cfg"", ""~/.nose2.cfg"") <TAB>  <TAB> for fn in user_opts: <TAB>  <TAB>  <TAB> filenames.append(os.path.expanduser(fn)) <TAB> return filenames",if cfg_args . top_level_directory :,171
"def make_aware(value): <TAB> if settings.USE_TZ: <TAB>  <TAB> # naive datetimes are assumed to be in UTC. <MASK> value = timezone.make_aware(value, timezone.utc) <TAB>  <TAB> # then convert to the Django configured timezone. <TAB>  <TAB> default_tz = timezone.get_default_timezone() <TAB>  <TAB> value = timezone.localtime(value, default_tz) <TAB> return value",if timezone . is_naive ( value ) :,106
"def update(id): <TAB> """"""Update a post if the current user is the author."""""" <TAB> post = get_post(id) <TAB> if request.method == ""POST"": <TAB>  <TAB> title = request.form[""title""] <TAB>  <TAB> body = request.form[""body""] <TAB>  <TAB> error = None <TAB>  <TAB> if not title: <TAB>  <TAB>  <TAB> error = ""Title is required."" <MASK> flash(error) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> post.title = title <TAB>  <TAB>  <TAB> post.body = body <TAB>  <TAB>  <TAB> db.session.commit() <TAB>  <TAB>  <TAB> return redirect(url_for(""blog.index"")) <TAB> return render_template(""blog/update.html"", post=post)",if error is not None :,168
"def copyfileobj(src, dest, length=512): <TAB> if hasattr(src, ""readinto""): <TAB>  <TAB> buf = bytearray(length) <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> sz = src.readinto(buf) <TAB>  <TAB>  <TAB> if not sz: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> if sz == length: <TAB>  <TAB>  <TAB>  <TAB> dest.write(buf) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> b = memoryview(buf)[:sz] <TAB>  <TAB>  <TAB>  <TAB> dest.write(b) <TAB> else: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> buf = src.read(length) <MASK> break <TAB>  <TAB>  <TAB> dest.write(buf)",if not buf :,162
"def imgFileProcessingTick(output): <TAB> if isinstance(output, tuple): <TAB>  <TAB> workerOutput.append(output) <TAB>  <TAB> workerPool.terminate() <TAB> else: <TAB>  <TAB> for page in output: <TAB>  <TAB>  <TAB> if page is not None: <TAB>  <TAB>  <TAB>  <TAB> options.imgMetadata[page[0]] = page[1] <TAB>  <TAB>  <TAB>  <TAB> options.imgOld.append(page[2]) <TAB> if GUI: <TAB>  <TAB> GUI.progressBarTick.emit(""tick"") <MASK> workerPool.terminate()",if not GUI . conversionAlive :,129
"def process_word(word): <TAB> if word.parent == ""remapping"": <TAB>  <TAB> raise UDError(""There is a cycle in a sentence"") <TAB> if word.parent is None: <TAB>  <TAB> head = int(word.columns[HEAD]) <TAB>  <TAB> if head > len(ud.words) - sentence_start: <TAB>  <TAB>  <TAB> raise UDError( <TAB>  <TAB>  <TAB>  <TAB> ""HEAD '{}' points outside of the sentence"".format(word.columns[HEAD]) <TAB>  <TAB>  <TAB> ) <MASK> parent = ud.words[sentence_start + head - 1] <TAB>  <TAB>  <TAB> word.parent = ""remapping"" <TAB>  <TAB>  <TAB> process_word(parent) <TAB>  <TAB>  <TAB> word.parent = parent",if head :,163
"def validate_export(namespace): <TAB> destination = namespace.destination <TAB> if destination == ""file"": <MASK> raise CLIError(""usage error: --path PATH --format FORMAT"") <TAB> elif destination == ""appconfig"": <TAB>  <TAB> if (namespace.dest_name is None) and (namespace.dest_connection_string is None): <TAB>  <TAB>  <TAB> raise CLIError(""usage error: --config-name NAME | --connection-string STR"") <TAB> elif destination == ""appservice"": <TAB>  <TAB> if namespace.appservice_account is None: <TAB>  <TAB>  <TAB> raise CLIError(""usage error: --appservice-account NAME_OR_ID"")",if namespace . path is None or namespace . format_ is None :,159
"def get_change_set_status(context, stack_name, change_set_name): <TAB> try: <TAB>  <TAB> response = retry_boto_call( <TAB>  <TAB>  <TAB> context.client.describe_change_set, <TAB>  <TAB>  <TAB> ChangeSetName=change_set_name, <TAB>  <TAB>  <TAB> StackName=stack_name, <TAB>  <TAB> ) <TAB> except ClientError as e: <MASK> return None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise e <TAB> return response[""Status""]","if e . response [ ""Error"" ] [ ""Code"" ] == ""ChangeSetNotFound"" :",127
"def predict(self, predict_data): <TAB> assert self.predict_fn is not None <TAB> # For the batch by batch prediction case, we do not want to include the cost of <TAB> # doing final outputs concatenation into time measurement <TAB> with Timer() as t: <MASK> self.predictions = self.predict_fn(predict_data) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.predictions = self.predict_fn(predict_data, concatenate_outputs=False) <TAB> if not self.batch_benchmark: <TAB>  <TAB> self.predictions = np.concatenate(self.predictions) <TAB> return t.interval",if self . batch_benchmark :,148
"def __str__(self): <TAB> s = ""("" + str(self[0]) <TAB> s += "", "" <TAB> if isinstance(self[1], Tensor): <TAB>  <TAB> if self[1].name and self[1].name is not None: <TAB>  <TAB>  <TAB> s += self[1].name <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> s += ""tensor-"" + hex(id(self[1])) <TAB> else: <TAB>  <TAB> s += str(self[1]) <TAB> s += "", "" <TAB> if isinstance(self[2], Tensor): <MASK> s += self[2].name <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> s += ""tensor-"" + hex(id(self[2])) <TAB> else: <TAB>  <TAB> s += str(self[2]) <TAB> s += "")"" <TAB> return s",if self [ 2 ] . name and self [ 2 ] . name is not None :,198
"def get_local_cache(self, past, data, from_file, temp_id): <TAB> """"""parse individual cached geometry if there is any"""""" <TAB> cache = [] <TAB> if self.accumulative: <MASK> cache = past[temp_id] <TAB>  <TAB> if not from_file and len(data) > 0: <TAB>  <TAB>  <TAB> cache = data.get(temp_id, []) <TAB> return cache",if from_file and len ( past ) > 0 :,109
def get_mappings(index): <TAB> mappings = {} <TAB> from kitsune.search.models import get_mapping_types <TAB> for cls in get_mapping_types(): <TAB>  <TAB> group = cls.get_index_group() <MASK> mappings[cls.get_mapping_type_name()] = cls.get_mapping() <TAB> return mappings,if index == write_index ( group ) or index == read_index ( group ) :,101
"def find_first_of_filetype(content, filterfiltype, attr=""name""): <TAB> """"""Find the first of the file type."""""" <TAB> filename = """" <TAB> for _filename in content: <MASK> if _filename.endswith(f"".{filterfiltype}""): <TAB>  <TAB>  <TAB>  <TAB> filename = _filename <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if getattr(_filename, attr).endswith(f"".{filterfiltype}""): <TAB>  <TAB>  <TAB>  <TAB> filename = getattr(_filename, attr) <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return filename","if isinstance ( _filename , str ) :",135
"def _timer( <TAB> duetime: typing.AbsoluteOrRelativeTime, <TAB> period: Optional[typing.RelativeTime] = None, <TAB> scheduler: Optional[typing.Scheduler] = None,) -> Observable: <TAB> if isinstance(duetime, datetime): <MASK> return observable_timer_date(duetime, scheduler) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return observable_timer_duetime_and_period(duetime, period, scheduler) <TAB> if period is None: <TAB>  <TAB> return observable_timer_timespan(duetime, scheduler) <TAB> return observable_timer_timespan_and_period(duetime, period, scheduler)",if period is None :,160
"def __getattribute__(self, attrname): <TAB> result = object.__getattribute__(self, attrname) <MASK> try: <TAB>  <TAB>  <TAB> self._read_info(attrname) <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> logging.warning( <TAB>  <TAB>  <TAB>  <TAB> ""An error '%s' was raised while decoding '%s'"", e, repr(self.path) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> result = object.__getattribute__(self, attrname) <TAB>  <TAB> if result is NOT_SET: <TAB>  <TAB>  <TAB> result = self.INITIAL_INFO[attrname] <TAB> return result",if result is NOT_SET :,138
"def on_btOK_clicked(self, *a): <TAB> """"""Handler for OK button"""""" <TAB> if self.ac_callback is not None: <TAB>  <TAB> self._set_title() <MASK> self.ac_callback(self.id, self) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> a = self.generate_modifiers( <TAB>  <TAB>  <TAB>  <TAB> self._action, self._selected_component.NAME == ""custom"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.ac_callback(self.id, a) <TAB>  <TAB>  <TAB> self.ac_callback = None <TAB>  <TAB> if self._selected_component: <TAB>  <TAB>  <TAB> self._selected_component.on_ok(a) <TAB> self.close()",if self . _mode == ActionEditor . AEC_MENUITEM :,180
"def execute(): <TAB> if frappe.db.get_value(""Company"", {""country"": ""India""}, ""name""): <TAB>  <TAB> address_template = frappe.db.get_value(""Address Template"", ""India"", ""template"") <MASK> set_up_address_templates(default_country=""India"")","if not address_template or ""gstin"" not in address_template :",94
"def is_ncname(name): <TAB> first = name[0] <TAB> if first == ""_"" or category(first) in NAME_START_CATEGORIES: <TAB>  <TAB> for i in xrange(1, len(name)): <TAB>  <TAB>  <TAB> c = name[i] <TAB>  <TAB>  <TAB> if not category(c) in NAME_CATEGORIES: <MASK> continue <TAB>  <TAB>  <TAB>  <TAB> return 0 <TAB>  <TAB>  <TAB> # if in compatibility area <TAB>  <TAB>  <TAB> # if decomposition(c)!='': <TAB>  <TAB>  <TAB> # <TAB> return 0 <TAB>  <TAB> return 1 <TAB> else: <TAB>  <TAB> return 0",if c in ALLOWED_NAME_CHARS :,151
"def _get_sonnet_version(): <TAB> with open(""sonnet/__init__.py"") as fp: <TAB>  <TAB> for line in fp: <MASK> g = {} <TAB>  <TAB>  <TAB>  <TAB> exec(line, g)  # pylint: disable=exec-used <TAB>  <TAB>  <TAB>  <TAB> return g[""__version__""] <TAB>  <TAB> raise ValueError(""`__version__` not defined in `sonnet/__init__.py`"")","if line . startswith ( ""__version__"" ) :",102
def disjoined(self): <TAB> gridscope = GridScope(globals=self.globals) <TAB> for key in self.user_added: <TAB>  <TAB> value = self[key] <MASK> grid = vaex.utils.disjoined(value) <TAB>  <TAB>  <TAB> gridscope[key] = grid <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> gridscope[key] = value <TAB> return gridscope,"if isinstance ( value , np . ndarray ) :",101
def _maybe_uncompress(self): <TAB> if not self._decompressed: <TAB>  <TAB> compression_type = self.compression_type <MASK> data = memoryview(self._buffer)[self._pos :] <TAB>  <TAB>  <TAB> if compression_type == self.CODEC_GZIP: <TAB>  <TAB>  <TAB>  <TAB> uncompressed = gzip_decode(data) <TAB>  <TAB>  <TAB> if compression_type == self.CODEC_SNAPPY: <TAB>  <TAB>  <TAB>  <TAB> uncompressed = snappy_decode(data.tobytes()) <TAB>  <TAB>  <TAB> if compression_type == self.CODEC_LZ4: <TAB>  <TAB>  <TAB>  <TAB> uncompressed = lz4_decode(data.tobytes()) <TAB>  <TAB>  <TAB> self._buffer = bytearray(uncompressed) <TAB>  <TAB>  <TAB> self._pos = 0 <TAB> self._decompressed = True,if compression_type != self . CODEC_NONE :,192
"def read_chat_forever(reader, pub_socket): <TAB> line = reader.readline() <TAB> who = ""someone"" <TAB> while line: <TAB>  <TAB> print(""Chat:"", line.strip()) <MASK> who = line.split("":"")[-1].strip() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> pub_socket.send_pyobj((who, line)) <TAB>  <TAB> except socket.error as e: <TAB>  <TAB>  <TAB> # ignore broken pipes, they just mean the participant <TAB>  <TAB>  <TAB> # closed its connection already <TAB>  <TAB>  <TAB> if e[0] != 32: <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> line = reader.readline() <TAB> print(""Participant left chat."")","if line . startswith ( ""name:"" ) :",162
"def items(self, section=None): <TAB> section = section if section is not None else Settings.DEFAULT_SECTION <TAB> result = {""section"": section} <TAB> try: <MASK> for option in self._global_settings.options(section): <TAB>  <TAB>  <TAB>  <TAB> result[option] = self._global_settings.get(section, option) <TAB>  <TAB> if section in self._local_settings.sections(): <TAB>  <TAB>  <TAB> for option in self._local_settings.options(section): <TAB>  <TAB>  <TAB>  <TAB> result[option] = self._local_settings.get(section, option) <TAB> except configparser.InterpolationSyntaxError: <TAB>  <TAB> core.termwarn(""Unable to parse settings file"") <TAB> return result",if section in self . _global_settings . sections ( ) :,172
"def before_train(self, program): <TAB> """"""doc"""""" <TAB> if self.summary_record: <TAB>  <TAB> if self.summary_record.scalar: <TAB>  <TAB>  <TAB> self.s_name, self.s_tolog = zip(*self.summary_record.scalar) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.s_name, self.s_tolog = [], [] <MASK> self.h_name, self.h_tolog = zip(*self.summary_record.histogram) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.h_name, self.h_tolog = [], []",if self . summary_record . histogram :,150
"def _s3_init(self): <TAB> """"""Initialize s3 bucket."""""" <TAB> try: <TAB>  <TAB> bucket_exists = yield self._bucket_exists() <MASK> LOGGER.warning(""Will attempt to create bucket"") <TAB>  <TAB>  <TAB> yield self._create_bucket() <TAB> except botocore.exceptions.NoCredentialsError: <TAB>  <TAB> LOGGER.error( <TAB>  <TAB>  <TAB> 'You must set ""s3.accessKeyId"" and ""s3.secretAccessKey"", or ' <TAB>  <TAB>  <TAB> '""s3.profile"" in your Streamlit configuration.' <TAB>  <TAB> ) <TAB>  <TAB> raise errors.S3NoCredentials",if not bucket_exists :,144
"def id2unit(self, id): <TAB> items = [] <TAB> for v, k in zip(id, self._id2unit.keys()): <MASK> continue <TAB>  <TAB> if self.keyed: <TAB>  <TAB>  <TAB> items.append(""{}={}"".format(k, self._id2unit[k][v])) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> items.append(self._id2unit[k][v]) <TAB> res = self.sep.join(items) <TAB> if res == """": <TAB>  <TAB> res = ""_"" <TAB> return res",if v == EMPTY_ID :,130
"def forward(model: TransformerListener, docs, is_train): <TAB> if is_train: <TAB>  <TAB> model.verify_inputs(docs) <TAB>  <TAB> return model._outputs, model.backprop_and_clear <TAB> else: <MASK> outputs = [] <TAB>  <TAB> elif any(doc._.trf_data is None for doc in docs): <TAB>  <TAB>  <TAB> width = model.get_dim(""nO"") <TAB>  <TAB>  <TAB> outputs = [ <TAB>  <TAB>  <TAB>  <TAB> TransformerData.zeros(len(doc), width, xp=model.ops.xp) for doc in docs <TAB>  <TAB>  <TAB> ] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> outputs = [doc._.trf_data for doc in docs] <TAB>  <TAB> return outputs, lambda d_data: []",if len ( docs ) == 0 :,182
"def get_plugin_dir(shooting_dir): <TAB> DIRNAME = ""lunapark"" <TAB> parent = os.path.abspath(os.path.join(shooting_dir, os.pardir)) <TAB> if os.path.basename(parent) == DIRNAME: <TAB>  <TAB> return parent <TAB> else: <TAB>  <TAB> plugin_dir = os.path.join(parent, DIRNAME) <MASK> os.makedirs(plugin_dir) <TAB>  <TAB> return plugin_dir",if not os . path . exists ( plugin_dir ) :,129
"def _get_plugin(self, name, lang=None, check=False): <TAB> if lang is None: <TAB>  <TAB> lang = self.get_lang() <TAB> if name not in self.plugin_attrib_map: <TAB>  <TAB> return None <TAB> plugin_class = self.plugin_attrib_map[name] <TAB> if plugin_class.is_extension: <MASK> return self.plugins[(name, None)] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return None if check else self.init_plugin(name, lang) <TAB> else: <TAB>  <TAB> if (name, lang) in self.plugins: <TAB>  <TAB>  <TAB> return self.plugins[(name, lang)] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return None if check else self.init_plugin(name, lang)","if ( name , None ) in self . plugins :",189
"def globs_relative_to_buildroot(self): <TAB> buildroot = get_buildroot() <TAB> globs = [] <TAB> for bundle in self.bundles: <TAB>  <TAB> fileset = bundle.fileset <TAB>  <TAB> if fileset is None: <TAB>  <TAB>  <TAB> continue <MASK> globs += bundle.fileset.filespec[""globs""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # NB(nh): filemap is an OrderedDict, so this ordering is stable. <TAB>  <TAB>  <TAB> globs += [fast_relpath(f, buildroot) for f in bundle.filemap.keys()] <TAB> super_globs = super().globs_relative_to_buildroot() <TAB> if super_globs: <TAB>  <TAB> globs += super_globs[""globs""] <TAB> return {""globs"": globs}","elif hasattr ( fileset , ""filespec"" ) :",187
"def running_jobs(self, exit_on_error=True): <TAB> """"""Initialize multiprocessing."""""" <TAB> with self.handling_exceptions(): <MASK> from concurrent.futures import ProcessPoolExecutor <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> with ProcessPoolExecutor(self.jobs) as self.executor: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield <TAB>  <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB>  <TAB> self.executor = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield <TAB> if exit_on_error: <TAB>  <TAB> self.exit_on_error()",if self . using_jobs :,131
"def _get_all_checkpoint_paths(self) -> List[str]: <TAB> """"""Returns all the checkpoint paths managed by the instance."""""" <TAB> # Due to tensorflow/issues/19378, we cannot use `tf.io.gfile.glob` here <TAB> # because it returns directory contents recursively on Windows. <TAB> if tf.io.gfile.exists(self._root_dir): <TAB>  <TAB> root_dir_entries = tf.io.gfile.listdir(self._root_dir) <TAB>  <TAB> return [ <TAB>  <TAB>  <TAB> os.path.join(self._root_dir, e) <TAB>  <TAB>  <TAB> for e in root_dir_entries <MASK> ] <TAB> else: <TAB>  <TAB> return []",if e . startswith ( self . _prefix ),170
"def test_tag_priority(self): <TAB> for tag in _low_priority_D_TAG: <TAB>  <TAB> val = ENUM_D_TAG[tag] <TAB>  <TAB> # if the low priority tag is present in the descriptions, <TAB>  <TAB> # assert that it has not overridden any other tag <TAB>  <TAB> if _DESCR_D_TAG[val] == tag: <TAB>  <TAB>  <TAB> for tag2 in ENUM_D_TAG: <MASK> continue <TAB>  <TAB>  <TAB>  <TAB> self.assertNotEqual(ENUM_D_TAG[tag2], val)",if tag2 == tag :,135
"def cycle(self, forward=True): <TAB> if self.cycle_list: <TAB>  <TAB> if forward is True: <TAB>  <TAB>  <TAB> self.cycle_list.rotate(-1) <MASK> self.cycle_list.rotate(1) <TAB>  <TAB> self.move_to_obj(self.cycle_list[0])",elif forward is False :,82
"def __init__(self): <TAB> self.keyring = None <TAB> if not haveKeyring: <TAB>  <TAB> return <TAB> try: <TAB>  <TAB> self.keyring = gnomekeyring.get_default_keyring_sync() <MASK> # Code borrowed from <TAB>  <TAB>  <TAB> # http://trac.gajim.org/browser/src/common/passwords.py <TAB>  <TAB>  <TAB> self.keyring = ""default"" <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> gnomekeyring.create_sync(self.keyring, None) <TAB>  <TAB>  <TAB> except gnomekeyring.AlreadyExistsError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB> except: <TAB>  <TAB> logging.exception(""Error determining keyring"") <TAB>  <TAB> self.keyring = None",if self . keyring == None :,171
"def _coerce_trials_data(data, path): <TAB> if not isinstance(data, list): <MASK> raise BatchFileError( <TAB>  <TAB>  <TAB>  <TAB> path, <TAB>  <TAB>  <TAB>  <TAB> ""invalid data type for trials: expected list or dict"" <TAB>  <TAB>  <TAB>  <TAB> "", got %s"" % type(data).__name__, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> data = [data] <TAB> for item in data: <TAB>  <TAB> if not isinstance(item, dict): <TAB>  <TAB>  <TAB> raise BatchFileError( <TAB>  <TAB>  <TAB>  <TAB> path, ""invalid data type for trial %r: expected dict"" % item <TAB>  <TAB>  <TAB> ) <TAB> return data","if not isinstance ( data , dict ) :",152
def update(self): <TAB> if self.openfilename is not None: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> current_mtime = os.stat(self.openfilename).st_mtime <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> return True <MASK> self.last_mtime = current_mtime <TAB>  <TAB>  <TAB> self.reload() <TAB> return True,if current_mtime != self . last_mtime :,91
"def _wrap_new_compiler(*args, **kwargs): <TAB> try: <TAB>  <TAB> return func(*args, **kwargs) <TAB> except errors.DistutilsPlatformError: <MASK> CCompiler = _UnixCCompiler <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> CCompiler = _MSVCCompiler <TAB>  <TAB> return CCompiler(None, kwargs[""dry_run""], kwargs[""force""])","if not sys . platform == ""win32"" :",98
"def _run_eagerly(*inputs):  # pylint: disable=missing-docstring <TAB> with context.eager_mode(): <TAB>  <TAB> constants = [ <TAB>  <TAB>  <TAB> _wrap_as_constant(value, tensor_spec) <TAB>  <TAB>  <TAB> for value, tensor_spec in zip(inputs, input_signature) <TAB>  <TAB> ] <TAB>  <TAB> output = fn(*constants) <TAB>  <TAB> if hasattr(output, ""_make""): <TAB>  <TAB>  <TAB> return output._make([tensor.numpy() for tensor in output]) <MASK> return [tensor.numpy() for tensor in output] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return output.numpy()","if isinstance ( output , ( tuple , list ) ) :",153
"def _on_event_MetadataAnalysisFinished(self, event, data): <TAB> with self._selectedFileMutex: <MASK> self._setJobData( <TAB>  <TAB>  <TAB>  <TAB> self._selectedFile[""filename""], <TAB>  <TAB>  <TAB>  <TAB> self._selectedFile[""filesize""], <TAB>  <TAB>  <TAB>  <TAB> self._selectedFile[""sd""], <TAB>  <TAB>  <TAB>  <TAB> self._selectedFile[""user""], <TAB>  <TAB>  <TAB> )",if self . _selectedFile :,99
"def env_asset_url_default(endpoint, values): <TAB> """"""Create asset URLs dependent on the current env"""""" <TAB> if endpoint == ""views.themes"": <TAB>  <TAB> path = values.get(""path"", """") <TAB>  <TAB> static_asset = path.endswith("".js"") or path.endswith("".css"") <TAB>  <TAB> direct_access = "".dev"" in path or "".min"" in path <MASK> env = values.get(""env"", current_app.env) <TAB>  <TAB>  <TAB> mode = "".dev"" if env == ""development"" else "".min"" <TAB>  <TAB>  <TAB> base, ext = os.path.splitext(path) <TAB>  <TAB>  <TAB> values[""path""] = base + mode + ext",if static_asset and not direct_access :,166
"def __init__(self, inStr): <TAB> """"""Initialize the class."""""" <TAB> inStr = inStr.strip() <TAB> if len(inStr) != 1 and len(inStr) != 2: <TAB>  <TAB> raise ValueError(""PosAlign: length not 2 chars"" + inStr) <TAB> if inStr == "".."": <TAB>  <TAB> self.aa = ""-"" <TAB>  <TAB> self.gap = 1 <TAB> else: <TAB>  <TAB> self.gap = 0 <TAB>  <TAB> self.aa = inStr[0] <MASK> self.aa = ""C"" <TAB>  <TAB> if len(inStr) == 2: <TAB>  <TAB>  <TAB> self.ss = inStr[1].upper() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.ss = ""0""",if self . aa == self . aa . lower ( ) :,179
"def iter_ReassignParameters(self, inputNode, variables, nodeByID): <TAB> for node in inputNode.getReassignParameterNodes(nodeByID): <TAB>  <TAB> yield from iterNodeCommentLines(node) <TAB>  <TAB> yield from iterInputConversionLines(node, variables) <TAB>  <TAB> socket = node.inputs[0] <TAB>  <TAB> if socket.isUnlinked and socket.isCopyable(): <TAB>  <TAB>  <TAB> expression = getCopyExpression(socket, variables) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> expression = variables[socket] <MASK> conditionPrefix = """" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> conditionPrefix = ""if {}: "".format(variables[node.conditionSocket]) <TAB>  <TAB> yield ""{}{} = {}"".format( <TAB>  <TAB>  <TAB> conditionPrefix, variables[node.linkedParameterSocket], expression <TAB>  <TAB> )",if node . conditionSocket is None :,192
"def init_weight(self): <TAB> if self.pretrained is not None: <TAB>  <TAB> load_entire_model(self, self.pretrained) <TAB> else: <TAB>  <TAB> for sublayer in self.sublayers(): <TAB>  <TAB>  <TAB> if isinstance(sublayer, nn.Conv2D): <TAB>  <TAB>  <TAB>  <TAB> kaiming_normal_init(sublayer.weight) <MASK> kaiming_normal_init(sublayer.weight)","elif isinstance ( sublayer , ( nn . BatchNorm , nn . SyncBatchNorm ) ) :",120
def logic(): <TAB> while 1: <MASK> yield reset.posedge <TAB>  <TAB> for i in range(20): <TAB>  <TAB>  <TAB> yield clock.posedge <TAB>  <TAB>  <TAB> if enable: <TAB>  <TAB>  <TAB>  <TAB> count.next = i <TAB>  <TAB> j = 1 <TAB>  <TAB> while j < 25: <TAB>  <TAB>  <TAB> if enable: <TAB>  <TAB>  <TAB>  <TAB> yield clock.posedge <TAB>  <TAB>  <TAB> yield clock.posedge <TAB>  <TAB>  <TAB> count.next = 2 * j <TAB>  <TAB>  <TAB> j += 1,if reset == ACTIVE_LOW :,123
"def clean_log_messages(result_data): <TAB> for idx in range(len(result_data[""executePlan""][""stepEvents""])): <TAB>  <TAB> message = result_data[""executePlan""][""stepEvents""][idx].get(""message"") <MASK> result_data[""executePlan""][""stepEvents""][idx][""message""] = re.sub( <TAB>  <TAB>  <TAB>  <TAB> r""(\d+(\.\d+)?)"", ""{N}"", message <TAB>  <TAB>  <TAB> ) <TAB> return result_data",if message is not None :,115
"def headerData(self, section, orientation, role=Qt.DisplayRole): <TAB> if role == Qt.TextAlignmentRole: <TAB>  <TAB> if orientation == Qt.Horizontal: <TAB>  <TAB>  <TAB> return to_qvariant(int(Qt.AlignHCenter | Qt.AlignVCenter)) <TAB>  <TAB> return to_qvariant(int(Qt.AlignRight | Qt.AlignVCenter)) <TAB> if role != Qt.DisplayRole: <TAB>  <TAB> return to_qvariant() <TAB> if orientation == Qt.Horizontal: <TAB>  <TAB> if section == NAME: <TAB>  <TAB>  <TAB> return to_qvariant(""Name"") <TAB>  <TAB> elif section == VERSION: <TAB>  <TAB>  <TAB> return to_qvariant(""Version"") <MASK> return to_qvariant(""Action"") <TAB>  <TAB> elif section == DESCRIPTION: <TAB>  <TAB>  <TAB> return to_qvariant(""Description"") <TAB> return to_qvariant()",elif section == ACTION :,192
"def _gather_infos(self): <TAB> # Carry over information from previous game step. <TAB> if self._prev_state is not None: <TAB>  <TAB> for attr in self._tracked_infos: <TAB>  <TAB>  <TAB> self.state[attr] = self.state.get(attr) or self._prev_state.get(attr) <TAB> for info in [""score"", ""moves""]: <MASK> self.state[info] = int(self.state[info].strip()) <TAB> self.state[""won""] = ""*** The End ***"" in self.state[""feedback""] <TAB> self.state[""lost""] = ""*** You lost! ***"" in self.state[""feedback""]",if self . state [ info ] is not None and type ( self . state [ info ] ) is not int :,180
"def calc_parity(sig, kind): <TAB> if kind in (""zero"", ""none""): <TAB>  <TAB> return C(0, 1) <TAB> elif kind == ""one"": <TAB>  <TAB> return C(1, 1) <TAB> else: <TAB>  <TAB> bits, _ = value_bits_sign(sig) <TAB>  <TAB> even_parity = sum([sig[b] for b in range(bits)]) & 1 <MASK> return ~even_parity <TAB>  <TAB> elif kind == ""even"": <TAB>  <TAB>  <TAB> return even_parity <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert False","if kind == ""odd"" :",141
"def tool(self, **kwds): <TAB> process_definition = kwds.get(""process_definition"", None) <TAB> if process_definition is None: <TAB>  <TAB> raw_process_reference = kwds.get(""raw_process_reference"", None) <MASK> raw_process_reference = self.raw_process_reference(kwds[""path""]) <TAB>  <TAB> process_definition = self.process_definition(raw_process_reference) <TAB> tool = load_tool.make_tool( <TAB>  <TAB> process_definition.uri, <TAB>  <TAB> process_definition.loading_context, <TAB> ) <TAB> return tool",if raw_process_reference is None :,147
def context(self): <TAB> # Needed to avoid Translate Toolkit construct ID <TAB> # as context\04source <TAB> if self.template is not None: <TAB>  <TAB> if self.template.id: <TAB>  <TAB>  <TAB> return self.template.id <MASK> return self.template.context <TAB>  <TAB> return self.template.getid() <TAB> return self.unescape_csv(self.mainunit.getcontext()),if self . template . context :,103
"def test_six_thread_safety(): <TAB> _reload_six() <TAB> with patch( <TAB>  <TAB> ""botocore.vendored.six.moves.__class__.__setattr__"", wraps=_wrapped_setattr <TAB> ): <TAB>  <TAB> threads = [] <TAB>  <TAB> for i in range(2): <TAB>  <TAB>  <TAB> t = _ExampleThread() <TAB>  <TAB>  <TAB> threads.append(t) <TAB>  <TAB>  <TAB> t.start() <TAB>  <TAB> while threads: <TAB>  <TAB>  <TAB> t = threads.pop() <TAB>  <TAB>  <TAB> t.join() <MASK> six.reraise(*t.exc_info)",if t . exc_info :,144
"def _handle_js_events(self, change): <TAB> if self.js_events: <TAB>  <TAB> if self.eventHandlers: <TAB>  <TAB>  <TAB> for event in self.js_events: <TAB>  <TAB>  <TAB>  <TAB> event_name = event[""name""] <MASK> self.eventHandlers[event_name](event[""detail""]) <TAB>  <TAB> # clears the event queue. <TAB>  <TAB> self.js_events = []",if event_name in self . eventHandlers :,110
"def single_discriminator(x, filters=128, kernel_size=8, strides=4, pure_mean=False): <TAB> """"""A simple single-layer convolutional discriminator."""""" <TAB> with tf.variable_scope(""discriminator""): <TAB>  <TAB> net = layers().Conv2D( <TAB>  <TAB>  <TAB> filters, kernel_size, strides=strides, padding=""SAME"", name=""conv1"" <TAB>  <TAB> )(x) <MASK> net = tf.reduce_mean(net, [1, 2]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> net = mean_with_attention(net, ""mean_with_attention"") <TAB>  <TAB> return net",if pure_mean :,148
"def find_path(self, from_location, to_location): <TAB> end = to_location <TAB> f_node = self.mh.get_node(from_location) <TAB> self.on.append(f_node) <TAB> self.o.append(f_node.lid) <TAB> next_node = f_node <TAB> counter = 0  # a bail-out counter <TAB> while next_node is not None: <MASK> break  # no path found under limit <TAB>  <TAB> finish = self._handle_node(next_node, end) <TAB>  <TAB> if finish: <TAB>  <TAB>  <TAB> return self._trace_path(finish) <TAB>  <TAB> next_node = self._get_best_open_node() <TAB>  <TAB> counter += 1 <TAB> return None",if counter > 10000 :,182
"def format_var_dict(dct, indent=4, max_width=80): <TAB> lines = [] <TAB> pre = "" "" * indent <TAB> for key, value in dct.items(): <TAB>  <TAB> line = pre + key + "" = "" + repr(value) <MASK> line = line[: max_width - 3] + ""..."" <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> value_len = len(value) <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> line += ""\n"" + pre + ""len(%s) = %s"" % (key, value_len) <TAB>  <TAB> lines.append(line) <TAB> return ""\n"".join(lines)",if len ( line ) > max_width :,176
"def _recursive_name_seach(self, layer_names, layer, pre_name, depth): <TAB> for name, module in layer.named_children(): <TAB>  <TAB> nname = pre_name + ""_"" + name if pre_name != """" else name <MASK> if self._wrap_layer_check(module, name, nname): <TAB>  <TAB>  <TAB>  <TAB> layer_names.append(nname) <TAB>  <TAB> if self.depth is None or depth <= self.depth: <TAB>  <TAB>  <TAB> if len(list(layer.named_children())) > 0: <TAB>  <TAB>  <TAB>  <TAB> self._recursive_name_seach(layer_names, module, nname, depth + 1) <TAB> return layer_names",if depth == self . depth or self . depth is None :,175
"def finished_at(self): <TAB> f = self.metadata_get([""State"", ""FinishedAt""]) <TAB> if f: <TAB>  <TAB> f = f[:26] <MASK> return DINOSAUR_TIME <TAB>  <TAB> finished_at = datetime.datetime.strptime(f, ISO_DATETIME_PARSE_STRING) <TAB>  <TAB> return finished_at","if f == ""0001-01-01T00:00:00Z"" :",100
"def write_bool(self, bool): <TAB> if ( <TAB>  <TAB> self._bool_fid <TAB>  <TAB> and self._bool_fid > self._last_fid <TAB>  <TAB> and self._bool_fid - self._last_fid <= 15 <TAB> ): <MASK> ctype = CompactType.TRUE <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ctype = CompactType.FALSE <TAB>  <TAB> self._write_field_header(ctype, self._bool_fid) <TAB> else: <TAB>  <TAB> if bool: <TAB>  <TAB>  <TAB> self.write_byte(CompactType.TRUE) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.write_byte(CompactType.FALSE)",if bool :,156
"def update(self, topLeft, bottomRight): <TAB> if self._updating: <TAB>  <TAB> # We are currently putting data in the model, so no updates <TAB>  <TAB> return <TAB> if self._index: <TAB>  <TAB> if topLeft.row() <= self._index.row() <= bottomRight.row(): <TAB>  <TAB>  <TAB> self.updateText() <TAB> elif self._indexes: <TAB>  <TAB> update = False <TAB>  <TAB> for i in self._indexes: <TAB>  <TAB>  <TAB> if topLeft.row() <= i.row() <= bottomRight.row(): <TAB>  <TAB>  <TAB>  <TAB> update = True <MASK> self.updateText()",if update :,144
"def _preprocess_add_items(self, items): <TAB> """"""Split the items into two lists of path strings and BaseEntries."""""" <TAB> paths = [] <TAB> entries = [] <TAB> for item in items: <MASK> paths.append(self._to_relative_path(item)) <TAB>  <TAB> elif isinstance(item, (Blob, Submodule)): <TAB>  <TAB>  <TAB> entries.append(BaseIndexEntry.from_blob(item)) <TAB>  <TAB> elif isinstance(item, BaseIndexEntry): <TAB>  <TAB>  <TAB> entries.append(item) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError(""Invalid Type: %r"" % item) <TAB> # END for each item <TAB> return (paths, entries)","if isinstance ( item , string_types ) :",165
def ping_all(): <TAB> for l in _all_listeners.values(): <TAB>  <TAB> count = l.receiver.count() <MASK> for dev in l.receiver: <TAB>  <TAB>  <TAB>  <TAB> dev.ping() <TAB>  <TAB>  <TAB>  <TAB> l._status_changed(dev) <TAB>  <TAB>  <TAB>  <TAB> count -= 1 <TAB>  <TAB>  <TAB>  <TAB> if not count: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break,if count :,92
"def stage_node_dot(g, stage): <TAB> """"""Create a stage node."""""" <TAB> with g.subgraph(name=""cluster_"" + stage[""id""]) as subgraph: <TAB>  <TAB> subgraph.attr(label=stage[""name""]) <MASK> for itervar in stage[""all_itervars""]: <TAB>  <TAB>  <TAB>  <TAB> iv_type = itervar[""itervar_type""] <TAB>  <TAB>  <TAB>  <TAB> itervar_node_dot(subgraph, itervar, iv_type, itervar[""index""]) <TAB>  <TAB>  <TAB> for rel in stage[""relations""]: <TAB>  <TAB>  <TAB>  <TAB> node_id = rel[""id""] <TAB>  <TAB>  <TAB>  <TAB> itervar_relation_dot(subgraph, rel, node_id) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> subgraph.node(stage[""name""] + ""_placeholder"", style=""invis"")","if stage [ ""all_itervars"" ] :",190
"def run() -> None: <TAB> nonlocal state, timeout <TAB> while True: <TAB>  <TAB> if timeout > 0.0: <TAB>  <TAB>  <TAB> disposed.wait(timeout) <MASK> return <TAB>  <TAB> time: datetime = self.now <TAB>  <TAB> state = action(state) <TAB>  <TAB> timeout = seconds - (self.now - time).total_seconds()",if disposed . is_set ( ) :,92
"def increment(s): <TAB> if not s: <TAB>  <TAB> return ""1"" <TAB> for sequence in string.digits, string.lowercase, string.uppercase: <TAB>  <TAB> lastc = s[-1] <TAB>  <TAB> if lastc in sequence: <TAB>  <TAB>  <TAB> i = sequence.index(lastc) + 1 <MASK> if len(s) == 1: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> s = sequence[0] * 2 <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if s == ""00"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> s = ""10"" <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> s = increment(s[:-1]) + sequence[0] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> s = s[:-1] + sequence[i] <TAB>  <TAB>  <TAB> return s <TAB> return s  # Don't increment",if i >= len ( sequence ) :,196
"def Import(self, patch, force): <TAB> if not patch.get(""file""): <MASK> raise PatchError(""Patch file must be specified in patch import."") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> patch[""file""] = bb.fetch2.localpath(patch[""remote""], self.d) <TAB> for param in PatchSet.defaults: <TAB>  <TAB> if not patch.get(param): <TAB>  <TAB>  <TAB> patch[param] = PatchSet.defaults[param] <TAB> if patch.get(""remote""): <TAB>  <TAB> patch[""file""] = self.d.expand(bb.fetch2.localpath(patch[""remote""], self.d)) <TAB> patch[""filemd5""] = bb.utils.md5_file(patch[""file""])","if not patch . get ( ""remote"" ) :",176
"def _setReadyState(self, state: str) -> None: <TAB> if state != self.__readyState: <TAB>  <TAB> self.__log_debug(""- %s -> %s"", self.__readyState, state) <TAB>  <TAB> self.__readyState = state <MASK> self.emit(""open"") <TAB>  <TAB> elif state == ""closed"": <TAB>  <TAB>  <TAB> self.emit(""close"") <TAB>  <TAB>  <TAB> # no more events will be emitted, so remove all event listeners <TAB>  <TAB>  <TAB> # to facilitate garbage collection. <TAB>  <TAB>  <TAB> self.remove_all_listeners()","if state == ""open"" :",131
def count_brokers(self): <TAB> self.nb_brokers = 0 <TAB> for broker in self.brokers: <TAB>  <TAB> if not broker.spare: <TAB>  <TAB>  <TAB> self.nb_brokers += 1 <TAB> for realm in self.higher_realms: <TAB>  <TAB> for broker in realm.brokers: <MASK> self.nb_brokers += 1,if not broker . spare and broker . manage_sub_realms :,118
"def _refresh(self): <TAB> self.uiProfileSelectComboBox.clear() <TAB> self.uiProfileSelectComboBox.addItem(""default"") <TAB> try: <MASK> for profile in sorted(os.listdir(self.profiles_path)): <TAB>  <TAB>  <TAB>  <TAB> if not profile.startswith("".""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.uiProfileSelectComboBox.addItem(profile) <TAB> except OSError: <TAB>  <TAB> pass",if os . path . exists ( self . profiles_path ) :,107
"def run(self): <TAB> for k, v in iteritems(self.objs): <MASK> continue <TAB>  <TAB> if v[""_class""] == ""Dataset"" and v[""task_type""] == ""Communication"": <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> params = json.loads(v[""task_type_parameters""]) <TAB>  <TAB>  <TAB> except json.JSONDecodeError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> if len(params) == 1: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> params.extend([""stub"", ""fifo_io""]) <TAB>  <TAB>  <TAB>  <TAB> v[""task_type_parameters""] = json.dumps(params) <TAB> return self.objs","if k . startswith ( ""_"" ) :",158
"def _listen(self, consumer_id: str) -> AsyncIterable[Any]: <TAB> try: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> if self._listening: <TAB>  <TAB>  <TAB>  <TAB> async for msg in self._listen_to_queue(consumer_id): <MASK> yield msg <TAB>  <TAB>  <TAB>  <TAB> await asyncio.sleep(0.5) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> async for msg in self._listen_to_ws(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield msg <TAB> except asyncio.CancelledError: <TAB>  <TAB> pass <TAB> except Exception as e: <TAB>  <TAB> raise e",if msg is not None :,153
"def recv(self, bufsiz, flags=0): <TAB> d = self._sock.recv(bufsiz, flags) <TAB> if self.replace_pattern and b"" HTTP/1.1\r\n"" in d: <TAB>  <TAB> line_end = d.find(b""\r\n"") <TAB>  <TAB> req_line = d[:line_end] <TAB>  <TAB> words = req_line.split() <MASK> method, url, http_version = words <TAB>  <TAB>  <TAB> url = url.replace(self.replace_pattern[0], self.replace_pattern[1]) <TAB>  <TAB>  <TAB> d = b""%s %s %s"" % (method, url, http_version) + d[line_end:] <TAB> return d",if len ( words ) == 3 :,178
"def Import(self, patch, force): <TAB> if not patch.get(""file""): <TAB>  <TAB> if not patch.get(""remote""): <TAB>  <TAB>  <TAB> raise PatchError(""Patch file must be specified in patch import."") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> patch[""file""] = bb.fetch2.localpath(patch[""remote""], self.d) <TAB> for param in PatchSet.defaults: <MASK> patch[param] = PatchSet.defaults[param] <TAB> if patch.get(""remote""): <TAB>  <TAB> patch[""file""] = self.d.expand(bb.fetch2.localpath(patch[""remote""], self.d)) <TAB> patch[""filemd5""] = bb.utils.md5_file(patch[""file""])",if not patch . get ( param ) :,176
"def delete(post_id): <TAB> blogging_engine = _get_blogging_engine(current_app) <TAB> storage = blogging_engine.storage <TAB> post = storage.get_post_by_id(post_id) <TAB> if (post is not None) and (current_user.get_id() == post[""user_id""]): <TAB>  <TAB> success = storage.delete_post(post_id) <MASK> flash(""Your post was successfully deleted"", ""info"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> flash(""Something went wrong while deleting your post"", ""warning"") <TAB> else: <TAB>  <TAB> flash(""You do not have the rights to delete this post"", ""warning"") <TAB> return redirect(url_for(""blog_app.index""))",if success :,177
"def update_schema_configs(state, schema): <TAB> RegistrationSchema = state.get_model(""osf"", ""registrationschema"") <TAB> for rs in RegistrationSchema.objects.all(): <TAB>  <TAB> if rs.schema.get(""description"", False): <TAB>  <TAB>  <TAB> rs.description = rs.schema[""description""] <MASK> rs.config = rs.schema[""config""] <TAB>  <TAB> rs.save()","if rs . schema . get ( ""config"" , False ) :",108
"def set_payload(self, value): <TAB> del self[""payload""] <TAB> if isinstance(value, ElementBase): <MASK> self.init_plugin(value.plugin_attrib, existing_xml=value.xml) <TAB>  <TAB> self.xml.append(value.xml) <TAB> else: <TAB>  <TAB> self.xml.append(value)",if value . tag_name ( ) in self . plugin_tag_map :,98
"def getCellPropertyNames_aux(self, col_id): <TAB> if col_id == ""name"": <TAB>  <TAB> if self.image_icon == ""places_busy"": <TAB>  <TAB>  <TAB> return [""places_busy""] <TAB>  <TAB> baseName = self.image_icon <MASK> return [baseName + ""_open""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return [baseName + ""_closed""] <TAB> return []",if self . isOpen :,102
"def one_xmm_reg_imm8(ii):  # also allows SSE4 2-imm8 instr <TAB> i, j, n = 0, 0, 0 <TAB> for op in _gen_opnds(ii): <TAB>  <TAB> if op_reg(op) and op_xmm(op): <TAB>  <TAB>  <TAB> n += 1 <MASK> i += 1 <TAB>  <TAB> elif op_imm8_2(op): <TAB>  <TAB>  <TAB> j += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> return n == 1 and i == 1 and j <= 1",elif op_imm8 ( op ) :,141
"def step(self, action): <TAB> """"""Repeat action, sum reward, and max over last observations."""""" <TAB> total_reward = 0.0 <TAB> done = None <TAB> for i in range(self._skip): <TAB>  <TAB> obs, reward, done, info = self.env.step(action) <MASK> self._obs_buffer[0] = obs <TAB>  <TAB> if i == self._skip - 1: <TAB>  <TAB>  <TAB> self._obs_buffer[1] = obs <TAB>  <TAB> total_reward += reward <TAB>  <TAB> if done: <TAB>  <TAB>  <TAB> break <TAB> # Note that the observation on the done=True frame doesn't matter. <TAB> max_frame = self._obs_buffer.max(axis=0) <TAB> return max_frame, total_reward, done, info",if i == self . _skip - 2 :,187
"def assertNodeSequenceEqual( <TAB> self, <TAB> seq1: Sequence[cst.CSTNode], <TAB> seq2: Sequence[cst.CSTNode], <TAB> msg: Optional[str] = None,) -> None: <TAB> suffix = """" if msg is None else f""\n{msg}"" <TAB> if len(seq1) != len(seq2): <TAB>  <TAB> raise AssertionError(f""\n{seq1!r}\nis not deeply equal to \n{seq2!r}{suffix}"") <TAB> for node1, node2 in zip(seq1, seq2): <MASK> raise AssertionError( <TAB>  <TAB>  <TAB>  <TAB> f""\n{seq1!r}\nis not deeply equal to \n{seq2!r}{suffix}"" <TAB>  <TAB>  <TAB> )",if not node1 . deep_equals ( node2 ) :,189
"def close(self): <TAB> if self._file_writer is not None: <MASK> flat_result = flatten_dict(self.last_result, delimiter=""/"") <TAB>  <TAB>  <TAB> scrubbed_result = { <TAB>  <TAB>  <TAB>  <TAB> k: value <TAB>  <TAB>  <TAB>  <TAB> for k, value in flat_result.items() <TAB>  <TAB>  <TAB>  <TAB> if isinstance(value, tuple(VALID_SUMMARY_TYPES)) <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB> self._try_log_hparams(scrubbed_result) <TAB>  <TAB> self._file_writer.close()",if self . trial and self . trial . evaluated_params and self . last_result :,146
"def check_space(arr, task_id): <TAB> for a in arr: <TAB>  <TAB> if a.startswith(""hadoop jar""): <TAB>  <TAB>  <TAB> found = False <TAB>  <TAB>  <TAB> for x in shlex.split(a): <TAB>  <TAB>  <TAB>  <TAB> if task_id in x: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> found = True <MASK> raise AssertionError",if not found :,86
"def is_valid_block(self): <TAB> """"""check wheter the block is valid in the current position"""""" <TAB> for i in range(self.block.x): <TAB>  <TAB> for j in range(self.block.x): <MASK> if self.block.pos.x + i < 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB>  <TAB> if self.block.pos.x + i >= COLUMNS: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB>  <TAB> if self.block.pos.y + j < 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB>  <TAB> if self.map.get((self.block.pos.x + i, self.block.pos.y + j), False): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return True","if self . block . get ( i , j ) :",192
"def undo_block_stop(self): <TAB> if self.undoblock.bump_depth(-1) == 0: <TAB>  <TAB> cmd = self.undoblock <TAB>  <TAB> self.undoblock = 0 <MASK> if len(cmd) == 1: <TAB>  <TAB>  <TAB>  <TAB> # no need to wrap a single cmd <TAB>  <TAB>  <TAB>  <TAB> cmd = cmd.getcmd(0) <TAB>  <TAB>  <TAB> # this blk of cmds, or single cmd, has already <TAB>  <TAB>  <TAB> # been done, so don't execute it again <TAB>  <TAB>  <TAB> self.addcmd(cmd, 0)",if len ( cmd ) > 0 :,139
"def __(task: pipelines.Task): <TAB> if not acl.current_user_has_permission(views.acl_resource): <TAB>  <TAB> return bootstrap.card( <TAB>  <TAB>  <TAB> header_left=""Commands"", body=acl.inline_permission_denied_message() <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> commands_card = bootstrap.card( <TAB>  <TAB>  <TAB> header_left=""Commands"", <TAB>  <TAB>  <TAB> fixed_header_height=True, <TAB>  <TAB>  <TAB> sections=[_render_command(command) for command in task.commands], <TAB>  <TAB> ) <MASK> return [ <TAB>  <TAB>  <TAB>  <TAB> bootstrap.card(header_left=f""Max retries: {task.max_retries}""), <TAB>  <TAB>  <TAB>  <TAB> commands_card, <TAB>  <TAB>  <TAB> ] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return commands_card",if task . max_retries :,196
"def closeEvent(self, e=None): <TAB> """"""Save settings and remove registered logging handler"""""" <TAB> if self.editor.isModified(): <TAB>  <TAB> # ask if user wants to save <TAB>  <TAB> if self.wants_save(): <MASK> e.accept() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> # saving error or user canceled <TAB>  <TAB>  <TAB>  <TAB> e.ignore() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # discard changes <TAB>  <TAB>  <TAB> e.accept() <TAB> else: <TAB>  <TAB> # unchanged <TAB>  <TAB> e.accept()",if self . save ( ) :,133
"def _merge(self, a, b, path=None): <TAB> """"""Merge two dictionaries, from http://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge"""""" <TAB> if path is None: <TAB>  <TAB> path = [] <TAB> for key in b: <MASK> if isinstance(a[key], dict) and isinstance(b[key], dict): <TAB>  <TAB>  <TAB>  <TAB> self._merge(a[key], b[key], path + [str(key)]) <TAB>  <TAB>  <TAB> elif a[key] == b[key]: <TAB>  <TAB>  <TAB>  <TAB> pass  # same leaf value <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise Exception(""Conflict at %s"" % ""."".join(path + [str(key)])) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> a[key] = b[key] <TAB> return a",if key in a :,196
"def _flags_helper(conf, atom, new_flags, test=False): <TAB> try: <TAB>  <TAB> new_flags = __salt__[""portage_config.get_missing_flags""](conf, atom, new_flags) <TAB> except Exception:  # pylint: disable=broad-except <TAB>  <TAB> import traceback <TAB>  <TAB> return {""result"": False, ""comment"": traceback.format_exc()} <TAB> if new_flags: <TAB>  <TAB> old_flags = __salt__[""portage_config.get_flags_from_package_conf""](conf, atom) <MASK> __salt__[""portage_config.append_to_package_conf""](conf, atom, new_flags) <TAB>  <TAB> return {""result"": True, ""changes"": {""old"": old_flags, ""new"": new_flags}} <TAB> return {""result"": None}",if not test :,197
"def _confirm_deps(self, trans): <TAB> if [pkgs for pkgs in trans.dependencies if pkgs]: <TAB>  <TAB> dia = AptConfirmDialog(trans, parent=self.parent) <TAB>  <TAB> res = dia.run() <TAB>  <TAB> dia.hide() <TAB>  <TAB> if res != Gtk.ResponseType.OK: <TAB>  <TAB>  <TAB> log.debug(""Response is: %s"" % res) <MASK> log.debug(""Finish_handler..."") <TAB>  <TAB>  <TAB>  <TAB> self.finish_handler(trans, 0, self.data) <TAB>  <TAB>  <TAB> return <TAB> self._run_transaction(trans)",if self . finish_handler :,147
def get_supported_extensions(self): <TAB> for item in self.get_subclasses(): <TAB>  <TAB> instance = item() <MASK> for ext in instance.supports_extensions: <TAB>  <TAB>  <TAB>  <TAB> self.extractors.update({instance.cls_name: instance}) <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.extractors_by_extension[ext].append(instance) <TAB>  <TAB>  <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.extractors_by_extension[ext] = [instance],if instance . check ( ) :,126
"def find_module(self, fullname, path=None): <TAB> # Check for local modules first... <TAB> localname = fullname.split(""."")[-1] <TAB> name, ext = os.path.splitext(localname) <TAB> try: <TAB>  <TAB> fobj, filename, typeinfo = imp.find_module(name, path) <TAB> except ImportError: <TAB>  <TAB> logger.info(""Dcode Searching: %s (%s)"", name, path) <TAB>  <TAB> pymod = self.proxy.getPythonModule(fullname, path) <MASK> logger.info(""Dcode Loaded: %s"", fullname) <TAB>  <TAB>  <TAB> return DcodeLoader(*pymod)",if pymod :,155
def run(self): <TAB> try: <TAB>  <TAB> self.server_sock = self._create_socket_and_bind() <TAB>  <TAB> # in case self.port = 0 <TAB>  <TAB> self.port = self.server_sock.getsockname()[1] <TAB>  <TAB> self.ready_event.set() <TAB>  <TAB> self._handle_requests() <MASK> self.wait_to_close_event.wait(self.WAIT_EVENT_TIMEOUT) <TAB> finally: <TAB>  <TAB> self.ready_event.set()  # just in case of exception <TAB>  <TAB> self._close_server_sock_ignore_errors() <TAB>  <TAB> self.stop_event.set(),if self . wait_to_close_event :,163
"def connection(self, commit_on_success=False): <TAB> with self._lock: <TAB>  <TAB> if self._bulk_commit: <MASK> self._pending_connection = sqlite.connect(self.filename) <TAB>  <TAB>  <TAB> con = self._pending_connection <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> con = sqlite.connect(self.filename) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if self.fast_save: <TAB>  <TAB>  <TAB>  <TAB> con.execute(""PRAGMA synchronous = 0;"") <TAB>  <TAB>  <TAB> yield con <TAB>  <TAB>  <TAB> if commit_on_success and self.can_commit: <TAB>  <TAB>  <TAB>  <TAB> con.commit() <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> if not self._bulk_commit: <TAB>  <TAB>  <TAB>  <TAB> con.close()",if self . _pending_connection is None :,182
"def getReceiptInfo(pkgname): <TAB> """"""Get receipt info from a package"""""" <TAB> info = [] <TAB> if hasValidPackageExt(pkgname): <TAB>  <TAB> display.display_debug2(""Examining %s"" % pkgname) <MASK> # new flat package <TAB>  <TAB>  <TAB> info = getFlatPackageInfo(pkgname) <TAB>  <TAB> if os.path.isdir(pkgname):  # bundle-style package? <TAB>  <TAB>  <TAB> info = getBundlePackageInfo(pkgname) <TAB> elif pkgname.endswith("".dist""): <TAB>  <TAB> info = parsePkgRefs(pkgname) <TAB> return info",if os . path . isfile ( pkgname ) :,143
"def test_gen_speed(gen_func): <TAB> cur_time = time.time() <TAB> for idx, _ in enumerate(gen_func()): <TAB>  <TAB> log.info(""iter %s: %s s"" % (idx, time.time() - cur_time)) <TAB>  <TAB> cur_time = time.time() <MASK> break",if idx == 100 :,87
"def __init__(self, *args, **kwargs): <TAB> if not quickjs_available: <TAB>  <TAB> msg = ""No supported QuickJS package found on custom python environment!"" <MASK> msg += "" Please install python package quickjs or use ChakraJSEngine."" <TAB>  <TAB> elif external_interpreter: <TAB>  <TAB>  <TAB> msg += "" Please install python package quickjs or use ExternalJSEngine."" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> msg += "" Please install python package quickjs."" <TAB>  <TAB> raise RuntimeError(msg) <TAB> self._context = self.Context(self) <TAB> InternalJSEngine.__init__(self, *args, **kwargs)",if chakra_available :,156
"def _draw_nodes(self, cr, bounding, highlight_items): <TAB> highlight_nodes = [] <TAB> for element in highlight_items: <TAB>  <TAB> if isinstance(element, Edge): <TAB>  <TAB>  <TAB> highlight_nodes.append(element.src) <TAB>  <TAB>  <TAB> highlight_nodes.append(element.dst) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> highlight_nodes.append(element) <TAB> for node in self.nodes: <MASK> node._draw(cr, highlight=(node in highlight_nodes), bounding=bounding)",if bounding is None or node . _intersects ( bounding ) :,134
"def upgrade(): <TAB> bind = op.get_bind() <TAB> session = db.Session(bind=bind) <TAB> for slc in session.query(Slice).filter(Slice.viz_type.like(""deck_%"")): <TAB>  <TAB> params = json.loads(slc.params) <MASK> params[""spatial""] = { <TAB>  <TAB>  <TAB>  <TAB> ""lonCol"": params.get(""longitude""), <TAB>  <TAB>  <TAB>  <TAB> ""latCol"": params.get(""latitude""), <TAB>  <TAB>  <TAB>  <TAB> ""type"": ""latlong"", <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB> del params[""latitude""] <TAB>  <TAB>  <TAB> del params[""longitude""] <TAB>  <TAB> slc.params = json.dumps(params) <TAB>  <TAB> session.merge(slc) <TAB>  <TAB> session.commit() <TAB> session.close()","if params . get ( ""latitude"" ) :",189
"def list_completers(): <TAB> """"""List the active completers"""""" <TAB> o = ""Registered Completer Functions: \n"" <TAB> _comp = xsh_session.completers <TAB> ml = max((len(i) for i in _comp), default=0) <TAB> _strs = [] <TAB> for c in _comp: <MASK> doc = ""No description provided"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> doc = "" "".join(_comp[c].__doc__.split()) <TAB>  <TAB> doc = justify(doc, 80, ml + 3) <TAB>  <TAB> _strs.append(""{: >{}} : {}"".format(c, ml, doc)) <TAB> return o + ""\n"".join(_strs) + ""\n""",if _comp [ c ] . __doc__ is None :,173
"def test_numeric_literals(self): <TAB> @udf(BigIntVal(FunctionContext, SmallIntVal)) <TAB> def fn(context, a): <TAB>  <TAB> if a is None: <TAB>  <TAB>  <TAB> return 1729 <MASK> return None <TAB>  <TAB> elif a < 10: <TAB>  <TAB>  <TAB> return a + 5 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return a * 2",elif a < 0 :,92
"def get_normal_sample(in_file): <TAB> """"""Retrieve normal sample if normal/turmor"""""" <TAB> with utils.open_gzipsafe(in_file) as in_handle: <TAB>  <TAB> for line in in_handle: <MASK> parts = line.strip().split(""Original="")[1][:-1] <TAB>  <TAB>  <TAB>  <TAB> return parts","if line . startswith ( ""##PEDIGREE"" ) :",94
"def generate_html_index(index_file, outdir): <TAB> data = parse_index_file(index_file) <TAB> data = ((d[0], d[1]) for d in data) <TAB> for i, chunk in enumerate(web.group(data, 1000)): <TAB>  <TAB> back = "".."" <TAB>  <TAB> index = t_html_layout(t_html_sitemap(back, chunk)) <TAB>  <TAB> path = outdir + ""/%02d/%05d.html"" % (i / 1000, i) <TAB>  <TAB> write(path, web.safestr(index)) <TAB> for f in os.listdir(outdir): <TAB>  <TAB> path = os.path.join(outdir, f) <MASK> dirindex(path) <TAB> dirindex(outdir, back=""."")",if os . path . isdir ( path ) :,185
"def _aggregate_metadata_attribute( <TAB> self, attr, agg_func=np.max, default_value=0, from_type_metadata=True): <TAB> attr_values = [] <TAB> for a in self.appliances: <MASK> attr_value = a.type.get(attr) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> attr_value = a.metadata.get(attr) <TAB>  <TAB> if attr_value is not None: <TAB>  <TAB>  <TAB> attr_values.append(attr_value) <TAB> if len(attr_values) == 0: <TAB>  <TAB> return default_value <TAB> else: <TAB>  <TAB> return agg_func(attr_values)",if from_type_metadata :,162
"def install(self, unicode=False, names=None): <TAB> import __builtin__ <TAB> __builtin__.__dict__[""_""] = unicode and self.ugettext or self.gettext <TAB> if hasattr(names, ""__contains__""): <TAB>  <TAB> if ""gettext"" in names: <TAB>  <TAB>  <TAB> __builtin__.__dict__[""gettext""] = __builtin__.__dict__[""_""] <TAB>  <TAB> if ""ngettext"" in names: <TAB>  <TAB>  <TAB> __builtin__.__dict__[""ngettext""] = ( <TAB>  <TAB>  <TAB>  <TAB> unicode and self.ungettext or self.ngettext <TAB>  <TAB>  <TAB> ) <MASK> __builtin__.__dict__[""lgettext""] = self.lgettext <TAB>  <TAB> if ""lngettext"" in names: <TAB>  <TAB>  <TAB> __builtin__.__dict__[""lngettext""] = self.lngettext","if ""lgettext"" in names :",181
def logic(): <TAB> while 1: <TAB>  <TAB> if reset == ACTIVE_LOW: <TAB>  <TAB>  <TAB> yield reset.posedge <TAB>  <TAB> for i in range(20): <TAB>  <TAB>  <TAB> yield clock.posedge <MASK> count.next = i <TAB>  <TAB> j = 1 <TAB>  <TAB> while j < 25: <TAB>  <TAB>  <TAB> if enable: <TAB>  <TAB>  <TAB>  <TAB> yield clock.posedge <TAB>  <TAB>  <TAB> yield clock.posedge <TAB>  <TAB>  <TAB> count.next = 2 * j <TAB>  <TAB>  <TAB> j += 1,if enable :,123
"def multi_device(reader, dev_count): <TAB> if dev_count == 1: <TAB>  <TAB> for batch in reader: <TAB>  <TAB>  <TAB> yield batch <TAB> else: <TAB>  <TAB> batches = [] <TAB>  <TAB> for batch in reader: <TAB>  <TAB>  <TAB> batches.append(batch) <MASK> yield batches <TAB>  <TAB>  <TAB>  <TAB> batches = []",if len ( batches ) == dev_count :,92
"def lockfile_from_pipfile(cls, pipfile_path): <TAB> from .pipfile import Pipfile <TAB> if os.path.isfile(pipfile_path): <MASK> pipfile_path = os.path.abspath(pipfile_path) <TAB>  <TAB> pipfile = Pipfile.load(os.path.dirname(pipfile_path)) <TAB>  <TAB> return plette.lockfiles.Lockfile.with_meta_from(pipfile._pipfile) <TAB> raise PipfileNotFound(pipfile_path)",if not os . path . isabs ( pipfile_path ) :,139
"def _resolve_result(self, f=None): <TAB> try: <TAB>  <TAB> if f: <TAB>  <TAB>  <TAB> results = f.result() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> results = list(map(self._client.results.get, self.msg_ids)) <MASK> r = results[0] <TAB>  <TAB>  <TAB> if isinstance(r, Exception): <TAB>  <TAB>  <TAB>  <TAB> raise r <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> results = error.collect_exceptions(results, self._fname) <TAB>  <TAB> self._success = True <TAB>  <TAB> self.set_result(self._reconstruct_result(results)) <TAB> except Exception as e: <TAB>  <TAB> self._success = False <TAB>  <TAB> self.set_exception(e)",if self . _single_result :,174
"def config_update(self, *updates): <TAB> filename = os.path.join(self.path, "".git"", ""config"") <TAB> with GitConfigParser(file_or_files=filename, read_only=False) as config: <TAB>  <TAB> for section, key, value in updates: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> old = config.get(section, key) <TAB>  <TAB>  <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> config.remove_option(section, key) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB>  <TAB> if old == value: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> except (NoSectionError, NoOptionError): <TAB>  <TAB>  <TAB>  <TAB> pass <MASK> config.set_value(section, key, value)",if value is not None :,183
"def process_percent(token, state, command_line): <TAB> if not state.is_range_start_line_parsed: <TAB>  <TAB> if command_line.line_range.start: <TAB>  <TAB>  <TAB> raise ValueError(""bad range: {0}"".format(state.scanner.state.source)) <TAB>  <TAB> command_line.line_range.start.append(token) <TAB> else: <MASK> raise ValueError(""bad range: {0}"".format(state.scanner.state.source)) <TAB>  <TAB> command_line.line_range.end.append(token) <TAB> return parse_line_ref, command_line",if command_line . line_range . end :,154
"def Flatten(self, metadata, value_to_flatten): <TAB> if metadata: <TAB>  <TAB> self.metadata = metadata <TAB> for desc in value_to_flatten.type_infos: <MASK> continue <TAB>  <TAB> if hasattr(self, desc.name) and value_to_flatten.HasField(desc.name): <TAB>  <TAB>  <TAB> setattr(self, desc.name, getattr(value_to_flatten, desc.name))","if desc . name == ""metadata"" :",108
"def create_model(model, args, is_train): <TAB> """"""Create model, include basic model, googlenet model and mixup model"""""" <TAB> data_loader, data = utility.create_data_loader(is_train, args) <TAB> if args.model == ""GoogLeNet"": <TAB>  <TAB> loss_out = _googlenet_model(data, model, args, is_train) <TAB> else: <MASK> loss_out = _mixup_model(data, model, args, is_train) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> loss_out = _basic_model(data, model, args, is_train) <TAB> return data_loader, loss_out",if args . use_mixup and is_train :,175
"def __init__(self, store): <TAB> if store.context_aware: <TAB>  <TAB> self.contexts = list(store.contexts()) <TAB>  <TAB> self.default_context = store.default_context.identifier <MASK> self.contexts.append(store.default_context) <TAB> else: <TAB>  <TAB> self.contexts = [store] <TAB>  <TAB> self.default_context = None <TAB> super(TrigSerializer, self).__init__(store)",if store . default_context :,110
"def validate_import_depth(namespace): <TAB> depth = namespace.depth <TAB> if depth is not None: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> depth = int(depth) <MASK> raise CLIError(""Depth should be at least 1."") <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> raise CLIError(""Depth is not a number."")",if depth < 1 :,85
"def __sync(self): <TAB> """"""Skip reader to the block boundary."""""" <TAB> pad_length = BLOCK_SIZE - self.__reader.tell() % BLOCK_SIZE <TAB> if pad_length and pad_length != BLOCK_SIZE: <TAB>  <TAB> data = self.__reader.read(pad_length) <MASK> raise EOFError(""Read %d bytes instead of %d"" % (len(data), pad_length))",if len ( data ) != pad_length :,109
"def _split_long_text(text, idx, size): <TAB> splited_text = text.split() <TAB> if len(splited_text) > 25: <MASK> # The first is (...)text <TAB>  <TAB>  <TAB> first = """" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> first = "" "".join(splited_text[:10]) <TAB>  <TAB> if idx != 0 and idx == size - 1: <TAB>  <TAB>  <TAB> # The last is text(...) <TAB>  <TAB>  <TAB> last = """" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> last = "" "".join(splited_text[-10:]) <TAB>  <TAB> return ""{}(...){}"".format(first, last) <TAB> return text",if idx == 0 :,156
"def download_label_map(out_dir): <TAB> log.info(""Downloading ScanNet "" + RELEASE_NAME + "" label mapping file..."") <TAB> files = [LABEL_MAP_FILE] <TAB> for file in files: <TAB>  <TAB> url = BASE_URL + RELEASE_TASKS + ""/"" + file <TAB>  <TAB> localpath = os.path.join(out_dir, file) <TAB>  <TAB> localdir = os.path.dirname(localpath) <MASK> os.makedirs(localdir) <TAB>  <TAB> download_file(url, localpath) <TAB> log.info(""Downloaded ScanNet "" + RELEASE_NAME + "" label mapping file."")",if not os . path . isdir ( localdir ) :,157
"def get_related_ids(self, resources): <TAB> vpc_ids = [vpc[""VpcId""] for vpc in resources] <TAB> vpc_igw_ids = set() <TAB> for igw in self.manager.get_resource_manager(""internet-gateway"").resources(): <TAB>  <TAB> for attachment in igw[""Attachments""]: <MASK> vpc_igw_ids.add(igw[""InternetGatewayId""]) <TAB> return vpc_igw_ids","if attachment . get ( ""VpcId"" , """" ) in vpc_ids :",125
"def visit_Assign(self, node): <TAB> """"""Handle visiting an assignment statement."""""" <TAB> ups = set() <TAB> for targ in node.targets: <TAB>  <TAB> if isinstance(targ, (Tuple, List)): <TAB>  <TAB>  <TAB> ups.update(leftmostname(elt) for elt in targ.elts) <TAB>  <TAB> elif isinstance(targ, BinOp): <TAB>  <TAB>  <TAB> newnode = self.try_subproc_toks(node) <MASK> ups.add(leftmostname(targ)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return newnode <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ups.add(leftmostname(targ)) <TAB> self.ctxupdate(ups) <TAB> return node",if newnode is node :,165
"def evex_mask_dest_reg_only(ii):  # optional imm8 <TAB> i, m, xyz = 0, 0, 0 <TAB> for op in _gen_opnds(ii): <TAB>  <TAB> if op_mask_reg(op): <TAB>  <TAB>  <TAB> m += 1 <TAB>  <TAB> elif op_xmm(op) or op_ymm(op) or op_zmm(op): <TAB>  <TAB>  <TAB> xyz += 1 <MASK> i += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> return m == 1 and xyz > 0 and i <= 1",elif op_imm8 ( op ) :,143
"def get_pynames(self, parameters): <TAB> result = [None] * max(len(parameters), len(self.args)) <TAB> for index, arg in enumerate(self.args): <MASK> result[parameters.index(arg.arg)] = self._evaluate(arg.value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result[index] = self._evaluate(arg) <TAB> return result","if isinstance ( arg , ast . keyword ) and arg . arg in parameters :",110
"def _discovery_modules(self) -> List[str]: <TAB> modules: List[str] = [] <TAB> autodiscover = self.conf.autodiscover <TAB> if autodiscover: <MASK> if self.conf.origin is None: <TAB>  <TAB>  <TAB>  <TAB> raise ImproperlyConfigured(E_NEED_ORIGIN) <TAB>  <TAB> elif callable(autodiscover): <TAB>  <TAB>  <TAB> modules.extend(cast(Callable[[], Iterator[str]], autodiscover)()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> modules.extend(autodiscover) <TAB>  <TAB> if self.conf.origin: <TAB>  <TAB>  <TAB> modules.append(self.conf.origin) <TAB> return modules","if isinstance ( autodiscover , bool ) :",149
"def _lock(self, files, type): <TAB> for i in count(0): <TAB>  <TAB> lockfile = os.path.join(self._lockdir, ""{}.{}.lock"".format(i, type)) <MASK> self._lockfile[type] = lockfile <TAB>  <TAB>  <TAB> with open(lockfile, ""w"") as lock: <TAB>  <TAB>  <TAB>  <TAB> print(*files, sep=""\n"", file=lock) <TAB>  <TAB>  <TAB> return",if not os . path . exists ( lockfile ) :,113
"def _init_inheritable_dicts_(cls): <TAB> if cls.__bases__ != (object,): <TAB>  <TAB> return <TAB> for attr in cls._inheritable_dict_attrs_: <TAB>  <TAB> if isinstance(attr, tuple): <TAB>  <TAB>  <TAB> attr_name, default = attr <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> attr_name, default = attr, {} <MASK> raise SyntaxError(""{} is not a dictionary"".format(attr_name)) <TAB>  <TAB> setattr(cls, attr_name, default)","if not isinstance ( default , dict ) :",122
"def _validate_name(self, name): <TAB> if isinstance(name, str): <TAB>  <TAB> name = dns.name.from_text(name, None) <TAB> elif not isinstance(name, dns.name.Name): <TAB>  <TAB> raise KeyError(""name parameter must be convertible to a DNS name"") <TAB> if name.is_absolute(): <TAB>  <TAB> if not name.is_subdomain(self.origin): <TAB>  <TAB>  <TAB> raise KeyError(""name parameter must be a subdomain of the zone origin"") <MASK> name = name.relativize(self.origin) <TAB> return name",if self . relativize :,142
"def hard_update(self, cache, size_change, pins_gates): <TAB> """"""replace verts, rads and vel (in NumPy)"""""" <TAB> verts, rads, vel, react = cache <TAB> if len(verts) == self.v_len: <MASK> unpinned = self.params[""unpinned""] <TAB>  <TAB>  <TAB> self.verts[unpinned] = verts[unpinned] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.verts = verts <TAB>  <TAB> self.vel = vel <TAB>  <TAB> if not size_change: <TAB>  <TAB>  <TAB> self.rads = rads",if pins_gates [ 0 ] and pins_gates [ 1 ] :,155
"def enable(self): <TAB> """"""enable the patch."""""" <TAB> for patch in self.dependencies: <TAB>  <TAB> patch.enable() <TAB> if not self.enabled: <TAB>  <TAB> pyv = sys.version_info[0] <TAB>  <TAB> if pyv == 2: <TAB>  <TAB>  <TAB> if self.PY2 == SKIP: <TAB>  <TAB>  <TAB>  <TAB> return  # skip patch activation <TAB>  <TAB>  <TAB> if not self.PY2: <TAB>  <TAB>  <TAB>  <TAB> raise IncompatiblePatch(""Python 2 not supported!"") <TAB>  <TAB> if pyv == 3: <TAB>  <TAB>  <TAB> if self.PY3 == SKIP: <TAB>  <TAB>  <TAB>  <TAB> return  # skip patch activation <MASK> raise IncompatiblePatch(""Python 3 not supported!"") <TAB>  <TAB> self.pre_enable() <TAB>  <TAB> self.do_enable() <TAB>  <TAB> self.enabled = True",if not self . PY3 :,191
def on_project_dialog_finished(self): <TAB> if self.sender().committed: <MASK> self.close_project() <TAB>  <TAB>  <TAB> self.project_manager.from_dialog(self.sender()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.project_manager.project_updated.emit(),if self . sender ( ) . new_project :,83
"def filter_database(db, user, filter_name): <TAB> """"""Returns a list of person handles"""""" <TAB> filt = MatchesFilter([filter_name]) <TAB> filt.requestprepare(db, user) <TAB> if user: <TAB>  <TAB> user.begin_progress( <TAB>  <TAB>  <TAB> _(""Finding relationship paths""), <TAB>  <TAB>  <TAB> _(""Retrieving all sub-filter matches""), <TAB>  <TAB>  <TAB> db.get_number_of_people(), <TAB>  <TAB> ) <TAB> matches = [] <TAB> for handle in db.iter_person_handles(): <TAB>  <TAB> person = db.get_person_from_handle(handle) <MASK> matches.append(handle) <TAB>  <TAB> if user: <TAB>  <TAB>  <TAB> user.step_progress() <TAB> if user: <TAB>  <TAB> user.end_progress() <TAB> filt.requestreset() <TAB> return matches","if filt . apply ( db , person ) :",198
"def add(self, key, val): <TAB> if key is None: <TAB>  <TAB> g.trace(""TypeDict: None is not a valid key"", g.callers()) <TAB>  <TAB> return <TAB> self._checkKeyType(key) <TAB> self._checkValType(val) <TAB> if self.isList: <TAB>  <TAB> aList = self.d.get(key, []) <MASK> aList.append(val) <TAB>  <TAB>  <TAB> self.d[key] = aList <TAB> else: <TAB>  <TAB> self.d[key] = val",if val not in aList :,134
"def show_help(ctx, param, value): <TAB> if value and not ctx.resilient_parsing: <MASK> # legit main help <TAB>  <TAB>  <TAB> echo(format_help(ctx.get_help())) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # legit sub-command help <TAB>  <TAB>  <TAB> echo(ctx.get_help(), color=ctx.color) <TAB>  <TAB> ctx.exit()",if not ctx . invoked_subcommand :,99
"def wav_to_spec(wav_audio, hparams): <TAB> """"""Transforms the contents of a wav file into a series of spectrograms."""""" <TAB> if hparams.spec_type == ""raw"": <TAB>  <TAB> spec = _wav_to_framed_samples(wav_audio, hparams) <TAB> else: <MASK> spec = _wav_to_cqt(wav_audio, hparams) <TAB>  <TAB> elif hparams.spec_type == ""mel"": <TAB>  <TAB>  <TAB> spec = _wav_to_mel(wav_audio, hparams) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""Invalid spec_type: {}"".format(hparams.spec_type)) <TAB>  <TAB> if hparams.spec_log_amplitude: <TAB>  <TAB>  <TAB> spec = librosa.power_to_db(spec) <TAB> return spec","if hparams . spec_type == ""cqt"" :",197
"def __bytes__(self) -> bytes: <TAB> payload = pack(""!LL"", self.ssrc, self.media_ssrc) <TAB> if self.lost: <TAB>  <TAB> pid = self.lost[0] <TAB>  <TAB> blp = 0 <TAB>  <TAB> for p in self.lost[1:]: <TAB>  <TAB>  <TAB> d = p - pid - 1 <MASK> blp |= 1 << d <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> payload += pack(""!HH"", pid, blp) <TAB>  <TAB>  <TAB>  <TAB> pid = p <TAB>  <TAB>  <TAB>  <TAB> blp = 0 <TAB>  <TAB> payload += pack(""!HH"", pid, blp) <TAB> return pack_rtcp_packet(RTCP_RTPFB, self.fmt, payload)",if d < 16 :,174
"def run() -> None: <TAB> nonlocal state, timeout <TAB> while True: <MASK> disposed.wait(timeout) <TAB>  <TAB> if disposed.is_set(): <TAB>  <TAB>  <TAB> return <TAB>  <TAB> time: datetime = self.now <TAB>  <TAB> state = action(state) <TAB>  <TAB> timeout = seconds - (self.now - time).total_seconds()",if timeout > 0.0 :,92
"def _get_host(self, array, connector, remote=False): <TAB> """"""Return dict describing existing Purity host object or None."""""" <TAB> if remote and array.get_rest_version() in SYNC_REPLICATION_REQUIRED_API_VERSIONS: <TAB>  <TAB> hosts = array.list_hosts(remote=True) <TAB> else: <TAB>  <TAB> hosts = array.list_hosts() <TAB> matching_hosts = [] <TAB> for host in hosts: <TAB>  <TAB> for wwn in connector[""wwpns""]: <MASK> matching_hosts.append(host) <TAB>  <TAB>  <TAB>  <TAB> break  # go to next host <TAB> return matching_hosts","if wwn . lower ( ) in str ( host [ ""wwn"" ] ) . lower ( ) :",165
"def validate_moment(self, moment: ""cirq.Moment""): <TAB> super().validate_moment(moment) <TAB> for op in moment.operations: <MASK> for other in moment.operations: <TAB>  <TAB>  <TAB>  <TAB> if other is not op and self._check_if_exp11_operation_interacts( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> cast(ops.GateOperation, op), cast(ops.GateOperation, other) <TAB>  <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""Adjacent Exp11 operations: {}."".format(moment))","if isinstance ( op . gate , ops . CZPowGate ) :",142
"def construct_instances(self, row, keys=None): <TAB> collected_models = {} <TAB> for i, (key, constructor, attr, conv) in enumerate(self.column_map): <MASK> continue <TAB>  <TAB> value = row[i] <TAB>  <TAB> if key not in collected_models: <TAB>  <TAB>  <TAB> collected_models[key] = constructor() <TAB>  <TAB> instance = collected_models[key] <TAB>  <TAB> if attr is None: <TAB>  <TAB>  <TAB> attr = self.cursor.description[i][0] <TAB>  <TAB> if conv is not None: <TAB>  <TAB>  <TAB> value = conv(value) <TAB>  <TAB> setattr(instance, attr, value) <TAB> return collected_models",if keys is not None and key not in keys :,167
"def test_all(self): <TAB> expected = [] <TAB> blacklist = {""executable"", ""nobody_uid"", ""test""} <TAB> for name in dir(server): <TAB>  <TAB> if name.startswith(""_"") or name in blacklist: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> module_object = getattr(server, name) <MASK> expected.append(name) <TAB> self.assertCountEqual(server.__all__, expected)","if getattr ( module_object , ""__module__"" , None ) == ""http.server"" :",111
"def _adjust_input(self): <TAB> for i in range(len(self.block.ops)): <TAB>  <TAB> current_op = self.block.ops[i] <TAB>  <TAB> for input_arg in current_op.input_arg_names: <MASK> current_op._rename_input(input_arg, self.input_map[input_arg])",if input_arg in self . input_map :,99
"def __getitem__(self, cls): <TAB> try: <TAB>  <TAB> return dict.__getitem__(self, cls) <TAB> except KeyError as e: <MASK> cls = cls.__class__ <TAB>  <TAB> for b in reversed(cls.__bases__): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> retval = self[b] <TAB>  <TAB>  <TAB>  <TAB> # this is why a cdict instance must never be modified after <TAB>  <TAB>  <TAB>  <TAB> # the first lookup <TAB>  <TAB>  <TAB>  <TAB> self[cls] = retval <TAB>  <TAB>  <TAB>  <TAB> return retval <TAB>  <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> raise e","if not hasattr ( cls , ""__bases__"" ) :",146
"def before_read(self, parser, section, option, value): <TAB> # If we're dealing with a quoted string as the interpolation value, <TAB> # make sure we load and unquote it so we don't end up with '""value""' <TAB> try: <TAB>  <TAB> json_value = srsly.json_loads(value) <MASK> value = json_value <TAB> except Exception: <TAB>  <TAB> pass <TAB> return super().before_read(parser, section, option, value)","if isinstance ( json_value , str ) and json_value not in JSON_EXCEPTIONS :",130
"def insert_files(self, urls, pos): <TAB> """"""Not only images"""""" <TAB> image_extensions = ["".png"", "".jpg"", "".bmp"", "".gif""] <TAB> for url in urls: <TAB>  <TAB> if url.scheme() == ""file"": <TAB>  <TAB>  <TAB> path = url.path() <TAB>  <TAB>  <TAB> ext = os.path.splitext(path)[1] <MASK> self._insert_image_from_path(path) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.parent.resource_edit.add_attach(path)",if os . path . exists ( path ) and ext in image_extensions :,144
"def p_constant(self, p): <TAB> """"""constant : PP_NUMBER"""""" <TAB> value = p[1].rstrip(""LlUu"") <TAB> try: <MASK> value = int(value[2:], 16) <TAB>  <TAB> elif value[0] == ""0"": <TAB>  <TAB>  <TAB> value = int(value, 8) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = int(value) <TAB> except ValueError: <TAB>  <TAB> value = value.rstrip(""eEfF"") <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> value = float(value) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> value = 0 <TAB> p[0] = ConstantExpressionNode(value)","if value [ : 2 ] == ""0x"" :",163
"def _decode_pattern_list(data): <TAB> rv = [] <TAB> contains_dict = False <TAB> for item in data: <TAB>  <TAB> if isinstance(item, list): <TAB>  <TAB>  <TAB> item = _decode_pattern_list(item) <MASK> item = _decode_pattern_dict(item) <TAB>  <TAB>  <TAB> contains_dict = True <TAB>  <TAB> rv.append(item) <TAB> # avoid sorting if any element in the list is a dict <TAB> if not contains_dict: <TAB>  <TAB> rv = sorted(rv) <TAB> return rv","elif isinstance ( item , dict ) :",133
"def value(self, mode): <TAB> v = super(mn_armt, self).value(mode) <TAB> if mode == ""l"": <TAB>  <TAB> out = [] <TAB>  <TAB> for x in v: <MASK> out.append(x[::-1]) <TAB>  <TAB>  <TAB> elif len(x) == 4: <TAB>  <TAB>  <TAB>  <TAB> out.append(x[:2][::-1] + x[2:4][::-1]) <TAB>  <TAB> return out <TAB> elif mode == ""b"": <TAB>  <TAB> return [x for x in v] <TAB> else: <TAB>  <TAB> raise NotImplementedError(""bad attrib"")",if len ( x ) == 2 :,145
"def _press_fire(self): <TAB> fire_action = 1 <TAB> if ( <TAB>  <TAB> self.is_atari_env <TAB>  <TAB> and self.env.unwrapped.get_action_meanings()[fire_action] == ""FIRE"" <TAB> ): <TAB>  <TAB> self.current_ale_lives = self.env.unwrapped.ale.lives() <TAB>  <TAB> self.step(fire_action) <MASK> self.reset_internal_state()",if self . done :,115
"def update_fid_err_log(self, fid_err): <TAB> """"""add an entry to the fid_err log"""""" <TAB> self.fid_err_log.append(fid_err) <TAB> if self.write_to_file: <MASK> mode = ""w"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> mode = ""a"" <TAB>  <TAB> f = open(self.fid_err_file, mode) <TAB>  <TAB> f.write(""{}\n"".format(fid_err)) <TAB>  <TAB> f.close()",if len ( self . fid_err_log ) == 1 :,135
"def _name(self, sender, short=True, full_email=False): <TAB> words = re.sub('[""<>]', """", sender).split() <TAB> nomail = [w for w in words if not ""@"" in w] <TAB> if nomail: <TAB>  <TAB> if short: <TAB>  <TAB>  <TAB> if len(nomail) > 1 and nomail[0].lower() in self._NAME_TITLES: <TAB>  <TAB>  <TAB>  <TAB> return nomail[1] <TAB>  <TAB>  <TAB> return nomail[0] <TAB>  <TAB> return "" "".join(nomail) <TAB> elif words: <MASK> return words[0].split(""@"", 1)[0] <TAB>  <TAB> return words[0] <TAB> return ""(nobody)""",if not full_email :,168
"def zrx_order_to_json(order: Optional[ZeroExOrder]) -> Optional[Dict[str, any]]: <TAB> if order is None: <TAB>  <TAB> return None <TAB> retval: Dict[str, any] = {} <TAB> for key, value in order.items(): <MASK> retval[key] = value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> retval[f""__binary__{key}""] = base64.b64encode(value).decode(""utf8"") <TAB> return retval","if not isinstance ( value , bytes ) :",120
"def _get_outfile(self): <TAB> outfile = self.inputs.transformed_file <TAB> if not isdefined(outfile): <MASK> if self.inputs.fs_target is True: <TAB>  <TAB>  <TAB>  <TAB> src = ""orig.mgz"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> src = self.inputs.target_file <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> src = self.inputs.source_file <TAB>  <TAB> outfile = fname_presuffix(src, newpath=os.getcwd(), suffix=""_warped"") <TAB> return outfile",if self . inputs . inverse is True :,134
"def close(self): <TAB> if self.changed: <TAB>  <TAB> save = EasyDialogs.AskYesNoCancel( <TAB>  <TAB>  <TAB> 'Save window ""%s"" before closing?' % self.name, 1 <TAB>  <TAB> ) <MASK> self.menu_save() <TAB>  <TAB> elif save < 0: <TAB>  <TAB>  <TAB> return <TAB> if self.parent.active == self: <TAB>  <TAB> self.parent.active = None <TAB> self.parent.updatemenubar() <TAB> del self.ted <TAB> self.do_postclose()",if save > 0 :,126
"def step(self, action): <TAB> """"""Repeat action, sum reward, and max over last observations."""""" <TAB> total_reward = 0.0 <TAB> done = None <TAB> for i in range(self._skip): <TAB>  <TAB> obs, reward, done, info = self.env.step(action) <TAB>  <TAB> if i == self._skip - 2: <TAB>  <TAB>  <TAB> self._obs_buffer[0] = obs <TAB>  <TAB> if i == self._skip - 1: <TAB>  <TAB>  <TAB> self._obs_buffer[1] = obs <TAB>  <TAB> total_reward += reward <MASK> break <TAB> # Note that the observation on the done=True frame doesn't matter. <TAB> max_frame = self._obs_buffer.max(axis=0) <TAB> return max_frame, total_reward, done, info",if done :,187
"def __isub__(self, other): <TAB> """"""In-place subtraction of a matrix or scalar."""""" <TAB> if isinstance(other, Matrix): <MASK> raise ValueError(""matrix shapes do not match"") <TAB>  <TAB> for row_a, row_b in izip(self._data, other): <TAB>  <TAB>  <TAB> for i in xrange(len(row_a)): <TAB>  <TAB>  <TAB>  <TAB> row_a[i] -= row_b[i] <TAB> else: <TAB>  <TAB> for row in self._data: <TAB>  <TAB>  <TAB> for i in xrange(len(row)): <TAB>  <TAB>  <TAB>  <TAB> row[i] -= other <TAB> return self",if self . shape != other . shape :,154
"def check(self, count, count_v, enable, clock, reset, n): <TAB> expect = 0 <TAB> yield reset.posedge <TAB> self.assertEqual(count, expect) <TAB> self.assertEqual(count, count_v) <TAB> while 1: <TAB>  <TAB> yield clock.posedge <TAB>  <TAB> if enable: <MASK> expect = n - 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> expect -= 1 <TAB>  <TAB> yield delay(1) <TAB>  <TAB> # print ""%d count %s expect %s count_v %s"" % (now(), count, expect, count_v) <TAB>  <TAB> self.assertEqual(count, expect) <TAB>  <TAB> self.assertEqual(count, count_v)",if expect == - n :,170
"def getmod(self, nm): <TAB> mod = None <TAB> for thing in self.path: <TAB>  <TAB> if isinstance(thing, basestring): <TAB>  <TAB>  <TAB> owner = self.shadowpath.get(thing, -1) <TAB>  <TAB>  <TAB> if owner == -1: <TAB>  <TAB>  <TAB>  <TAB> owner = self.shadowpath[thing] = self.__makeOwner(thing) <TAB>  <TAB>  <TAB> if owner: <TAB>  <TAB>  <TAB>  <TAB> mod = owner.getmod(nm) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> mod = thing.getmod(nm) <MASK> break <TAB> return mod",if mod :,137
"def get_file_language(filename, text=None): <TAB> """"""Get file language from filename"""""" <TAB> ext = osp.splitext(filename)[1] <TAB> if ext.startswith("".""): <TAB>  <TAB> ext = ext[1:]  # file extension with leading dot <TAB> language = ext <TAB> if not ext: <TAB>  <TAB> if text is None: <TAB>  <TAB>  <TAB> text, _enc = encoding.read(filename) <TAB>  <TAB> for line in text.splitlines(): <TAB>  <TAB>  <TAB> if not line.strip(): <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> shebang = line[2:] <TAB>  <TAB>  <TAB>  <TAB> if ""python"" in shebang: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> language = ""python"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return language","if line . startswith ( ""#!"" ) :",183
"def do_status(self, directory, path): <TAB> with self._repo(directory) as repo: <TAB>  <TAB> if path: <TAB>  <TAB>  <TAB> path = os.path.join(directory, path) <TAB>  <TAB>  <TAB> statuses = repo.status(include=path, all=True) <TAB>  <TAB>  <TAB> for status, paths in statuses: <MASK> return self.statuses[status][0] <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> resulting_status = 0 <TAB>  <TAB>  <TAB> for status, paths in repo.status(all=True): <TAB>  <TAB>  <TAB>  <TAB> if paths: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> resulting_status |= self.statuses[status][1] <TAB>  <TAB>  <TAB> return self.repo_statuses_str[resulting_status]",if paths :,181
def _kill(proc): <TAB> if proc is None: <TAB>  <TAB> return <TAB> if proc.stdout is not None: <TAB>  <TAB> proc.stdout.close() <TAB> if proc.stderr is not None: <TAB>  <TAB> proc.stderr.close() <MASK> try: <TAB>  <TAB>  <TAB> proc.terminate() <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> if proc.returncode is None: <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> proc.kill() <TAB>  <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass,if proc . returncode is None :,125
"def decorated_function(*args, **kwargs): <TAB> rv = f(*args, **kwargs) <TAB> if isinstance(rv, flask.Response): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> result = etag <MASK> result = result(rv) <TAB>  <TAB>  <TAB> if result: <TAB>  <TAB>  <TAB>  <TAB> rv.set_etag(result) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> logging.getLogger(__name__).exception( <TAB>  <TAB>  <TAB>  <TAB> ""Error while calculating the etag value for response {!r}"".format(rv) <TAB>  <TAB>  <TAB> ) <TAB> return rv",if callable ( result ) :,133
"def _list_shape_iter(shape): <TAB> last_shape = _void <TAB> for item in shape: <TAB>  <TAB> if item is Ellipsis: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""invalid shape spec: Ellipsis cannot be the"" ""first element"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB>  <TAB> yield last_shape <TAB>  <TAB> last_shape = item <TAB>  <TAB> yield item",if last_shape is _void :,109
"def delete_oidc_session_tokens(session): <TAB> if session: <MASK> del session[""oidc_access_token""] <TAB>  <TAB> if ""oidc_id_token"" in session: <TAB>  <TAB>  <TAB> del session[""oidc_id_token""] <TAB>  <TAB> if ""oidc_id_token_expiration"" in session: <TAB>  <TAB>  <TAB> del session[""oidc_id_token_expiration""] <TAB>  <TAB> if ""oidc_login_next"" in session: <TAB>  <TAB>  <TAB> del session[""oidc_login_next""] <TAB>  <TAB> if ""oidc_refresh_token"" in session: <TAB>  <TAB>  <TAB> del session[""oidc_refresh_token""] <TAB>  <TAB> if ""oidc_state"" in session: <TAB>  <TAB>  <TAB> del session[""oidc_state""]","if ""oidc_access_token"" in session :",179
"def calc_parity(sig, kind): <TAB> if kind in (""zero"", ""none""): <TAB>  <TAB> return C(0, 1) <TAB> elif kind == ""one"": <TAB>  <TAB> return C(1, 1) <TAB> else: <TAB>  <TAB> bits, _ = value_bits_sign(sig) <TAB>  <TAB> even_parity = sum([sig[b] for b in range(bits)]) & 1 <TAB>  <TAB> if kind == ""odd"": <TAB>  <TAB>  <TAB> return ~even_parity <MASK> return even_parity <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert False","elif kind == ""even"" :",141
"def parse_cookies(cookies_headers): <TAB> parsed = {} <TAB> for cookie in cookies_headers: <TAB>  <TAB> cookie = cookie.split("";"") <TAB>  <TAB> for c in cookie: <TAB>  <TAB>  <TAB> (name, value) = c.split(""="", 1) <TAB>  <TAB>  <TAB> name = name.strip() <TAB>  <TAB>  <TAB> value = value.strip() <MASK> continue <TAB>  <TAB>  <TAB> parsed[name] = value <TAB> return parsed",if name . lower ( ) in _SPECIAL_COOKIE_NAMES :,114
"def search_rotate(array, val): <TAB> low, high = 0, len(array) - 1 <TAB> while low <= high: <TAB>  <TAB> mid = (low + high) // 2 <TAB>  <TAB> if val == array[mid]: <TAB>  <TAB>  <TAB> return mid <MASK> if array[low] <= val <= array[mid]: <TAB>  <TAB>  <TAB>  <TAB> high = mid - 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> low = mid + 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if array[mid] <= val <= array[high]: <TAB>  <TAB>  <TAB>  <TAB> low = mid + 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> high = mid - 1 <TAB> return -1",if array [ low ] <= array [ mid ] :,166
"def _get_instance_attribute( <TAB> self, attr, default=None, defaults=None, incl_metadata=False): <TAB> if self.instance is None or not hasattr(self.instance, attr): <MASK> return self.parsed_metadata[attr] <TAB>  <TAB> elif defaults is not None: <TAB>  <TAB>  <TAB> for value in defaults: <TAB>  <TAB>  <TAB>  <TAB> if callable(value): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value = value() <TAB>  <TAB>  <TAB>  <TAB> if value is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return value <TAB>  <TAB> return default <TAB> return getattr(self.instance, attr)",if incl_metadata and attr in self . parsed_metadata :,149
"def _handle_rate_limit( <TAB> self, exception: RedditAPIException) -> Optional[Union[int, float]]: <TAB> for item in exception.items: <MASK> amount_search = self._ratelimit_regex.search(item.message) <TAB>  <TAB>  <TAB> if not amount_search: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> seconds = int(amount_search.group(1)) <TAB>  <TAB>  <TAB> if ""minute"" in amount_search.group(2): <TAB>  <TAB>  <TAB>  <TAB> seconds *= 60 <TAB>  <TAB>  <TAB> if seconds <= int(self.config.ratelimit_seconds): <TAB>  <TAB>  <TAB>  <TAB> sleep_seconds = seconds + min(seconds / 10, 1) <TAB>  <TAB>  <TAB>  <TAB> return sleep_seconds <TAB> return None","if item . error_type == ""RATELIMIT"" :",181
"def _split_values(self, value): <TAB> # do the regex mojo here <TAB> if not self.allowed_values: <TAB>  <TAB> return ("""",) <TAB> try: <TAB>  <TAB> r = re.compile(self.allowed_values) <TAB> except: <TAB>  <TAB> print(self.allowed_values, file=sys.stderr) <TAB>  <TAB> raise <TAB> s = str(value) <TAB> i = 0 <TAB> vals = [] <TAB> while True: <TAB>  <TAB> m = r.search(s[i:]) <TAB>  <TAB> if m is None: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> vals.append(m.group()) <TAB>  <TAB> delimiter = s[i : i + m.start()] <MASK> self.delimiter = delimiter <TAB>  <TAB> i += m.end() <TAB> return tuple(vals)","if self . delimiter is None and delimiter != """" :",192
"def render(self, mode=""none""): <TAB> """"""Renders the environment via matplotlib."""""" <TAB> if mode == ""log"": <TAB>  <TAB> self.logger.info(""Performance: "" + str(self._portfolio.performance)) <TAB> elif mode == ""chart"": <MASK> raise NotImplementedError() <TAB>  <TAB> self.viewer.render( <TAB>  <TAB>  <TAB> self.clock.step - 1, self._portfolio.performance, self._broker.trades <TAB>  <TAB> )",if self . viewer is None :,120
"def load_vocabulary(vocab_file): <TAB> with open(vocab_file, ""r"") as f: <TAB>  <TAB> vocabulary = [] <TAB>  <TAB> for line in f: <TAB>  <TAB>  <TAB> line = line.strip() <MASK> line = line.split("" "")[0] <TAB>  <TAB>  <TAB> vocabulary.append(line) <TAB>  <TAB> return vocabulary","if "" "" in line :",88
"def test_confirm_extension_is_yml(self): <TAB> files_with_incorrect_extensions = [] <TAB> for file in self.yield_next_rule_file_path(self.path_to_rules): <TAB>  <TAB> file_name_and_extension = os.path.splitext(file) <TAB>  <TAB> if len(file_name_and_extension) == 2: <TAB>  <TAB>  <TAB> extension = file_name_and_extension[1] <MASK> files_with_incorrect_extensions.append(file) <TAB> self.assertEqual( <TAB>  <TAB> files_with_incorrect_extensions, <TAB>  <TAB> [], <TAB>  <TAB> Fore.RED + ""There are rule files with extensions other than .yml"", <TAB> )","if extension != "".yml"" :",172
"def diff_from_indeces(self, indeces): <TAB> rgroups = [] <TAB> with self._lock: <TAB>  <TAB> for i in indeces: <TAB>  <TAB>  <TAB> rgroup = self.events[i] <MASK> rgroups.append(rgroup) <TAB> return ""\n"".join(rgroup.diff for rgroup in rgroups)","if isinstance ( rgroup , findlib2 . ReplaceHitGroup ) :",100
"def deep_update(config, override_config): <TAB> for k, v in override_config.items(): <TAB>  <TAB> if isinstance(v, Mapping): <TAB>  <TAB>  <TAB> k_config = config.get(k, {}) <MASK> v_config = deep_update(k_config, v) <TAB>  <TAB>  <TAB>  <TAB> config[k] = v_config <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> config[k] = v <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> config[k] = override_config[k] <TAB> return config","if isinstance ( k_config , Mapping ) :",136
"def GetBoundingBoxMin(self): <TAB> """"""Get the minimum bounding box."""""" <TAB> x1, y1 = 10000, 10000 <TAB> x2, y2 = -10000, -10000 <TAB> for point in self._lineControlPoints: <TAB>  <TAB> if point[0] < x1: <TAB>  <TAB>  <TAB> x1 = point[0] <MASK> y1 = point[1] <TAB>  <TAB> if point[0] > x2: <TAB>  <TAB>  <TAB> x2 = point[0] <TAB>  <TAB> if point[1] > y2: <TAB>  <TAB>  <TAB> y2 = point[1] <TAB> return x2 - x1, y2 - y1",if point [ 1 ] < y1 :,158
"def insertChars(self, chars): <TAB> tc = self.editBoxes[self.ind].textCursor() <TAB> if tc.hasSelection(): <TAB>  <TAB> selection = tc.selectedText() <MASK> if len(selection) > 2 * len(chars): <TAB>  <TAB>  <TAB>  <TAB> selection = selection[len(chars) : -len(chars)] <TAB>  <TAB>  <TAB>  <TAB> tc.insertText(selection) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tc.insertText(chars + tc.selectedText() + chars) <TAB> else: <TAB>  <TAB> tc.insertText(chars)",if selection . startswith ( chars ) and selection . endswith ( chars ) :,146
"def prepare_text(text, style): <TAB> body = [] <TAB> for fragment, sty in parse_tags(text, style, subs.styles): <TAB>  <TAB> fragment = fragment.replace(r""\h"", "" "") <TAB>  <TAB> fragment = fragment.replace(r""\n"", ""\n"") <TAB>  <TAB> fragment = fragment.replace(r""\N"", ""\n"") <TAB>  <TAB> if sty.italic: <TAB>  <TAB>  <TAB> fragment = ""<i>%s</i>"" % fragment <TAB>  <TAB> if sty.underline: <TAB>  <TAB>  <TAB> fragment = ""<u>%s</u>"" % fragment <MASK> fragment = ""<s>%s</s>"" % fragment <TAB>  <TAB> body.append(fragment) <TAB> return re.sub(""\n+"", ""\n"", """".join(body).strip())",if sty . strikeout :,180
"def mFEBRUARY( <TAB> self,): <TAB> try: <TAB>  <TAB> _type = FEBRUARY <TAB>  <TAB> _channel = DEFAULT_CHANNEL <TAB>  <TAB> pass <TAB>  <TAB> self.match(""feb"") <TAB>  <TAB> alt14 = 2 <TAB>  <TAB> LA14_0 = self.input.LA(1) <MASK> alt14 = 1 <TAB>  <TAB> if alt14 == 1: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> self.match(""ruary"") <TAB>  <TAB> self._state.type = _type <TAB>  <TAB> self._state.channel = _channel <TAB> finally: <TAB>  <TAB> pass",if LA14_0 == 114 :,147
"def test_calendar(self): <TAB> subreddit = self.reddit.subreddit(pytest.placeholders.test_subreddit) <TAB> widgets = subreddit.widgets <TAB> with self.use_cassette(""TestSubredditWidgets.fetch_widgets""): <TAB>  <TAB> calendar = None <TAB>  <TAB> for widget in widgets.sidebar: <MASK> calendar = widget <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> assert isinstance(calendar, Calendar) <TAB>  <TAB> assert calendar == calendar <TAB>  <TAB> assert calendar.id == calendar <TAB>  <TAB> assert calendar in widgets.sidebar <TAB>  <TAB> assert isinstance(calendar.configuration, dict) <TAB>  <TAB> assert hasattr(calendar, ""requiresSync"") <TAB>  <TAB> assert subreddit == calendar.subreddit","if isinstance ( widget , Calendar ) :",187
"def count(num): <TAB> cnt = 0 <TAB> for i in range(num): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if i % 2: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError <MASK> raise ArithmeticError(""1"") <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> cnt += 1 <TAB> return cnt",if i % 3 :,80
"def pop(self): <TAB> """"""Pop a nonterminal.  (Internal)"""""" <TAB> popdfa, popstate, popnode = self.stack.pop() <TAB> newnode = self.convert(self.grammar, popnode) <TAB> if newnode is not None: <MASK> dfa, state, node = self.stack[-1] <TAB>  <TAB>  <TAB> node[-1].append(newnode) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.rootnode = newnode <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> self.rootnode.used_names = self.used_names <TAB>  <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB>  <TAB> # Don't need this hack? <TAB>  <TAB>  <TAB>  <TAB> pass",if self . stack :,162
"def handle_custom_actions(self): <TAB> for _, action in CustomAction.registry.items(): <TAB>  <TAB> if action.resource != self.resource: <TAB>  <TAB>  <TAB> continue <MASK> self.parser.add_parser(action.action, help="""") <TAB>  <TAB> action(self.page).add_arguments(self.parser, self)",if action . action not in self . parser . choices :,92
"def get_host_metadata(self): <TAB> meta = {} <TAB> if self.agent_url: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> resp = requests.get(self.agent_url, timeout=1).json().get(""config"", {}) <TAB>  <TAB>  <TAB> if ""Version"" in resp: <TAB>  <TAB>  <TAB>  <TAB> meta[""nomad_version""] = resp.get(""Version"") <TAB>  <TAB>  <TAB> if ""Region"" in resp: <TAB>  <TAB>  <TAB>  <TAB> meta[""nomad_region""] = resp.get(""Region"") <MASK> meta[""nomad_datacenter""] = resp.get(""Datacenter"") <TAB>  <TAB> except Exception as ex: <TAB>  <TAB>  <TAB> self.log.debug(""Error getting Nomad version: %s"" % str(ex)) <TAB> return meta","if ""Datacenter"" in resp :",185
"def _source_tuple(af, address, port): <TAB> # Make a high level source tuple, or return None if address and port <TAB> # are both None <TAB> if address or port: <TAB>  <TAB> if address is None: <MASK> address = ""0.0.0.0"" <TAB>  <TAB>  <TAB> elif af == socket.AF_INET6: <TAB>  <TAB>  <TAB>  <TAB> address = ""::"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise NotImplementedError(f""unknown address family {af}"") <TAB>  <TAB> return (address, port) <TAB> else: <TAB>  <TAB> return None",if af == socket . AF_INET :,144
"def _evoke_request(cls): <TAB> succeed = False <TAB> with cls.LOCK: <TAB>  <TAB> if len(cls.REQUESTING_STACK) > 0: <TAB>  <TAB>  <TAB> resource, request_semaphore = cls.REQUESTING_STACK.pop() <TAB>  <TAB>  <TAB> node = cls.check_availability(resource) <MASK> cls.NODE_RESOURCE_MANAGER[node]._request(node, resource) <TAB>  <TAB>  <TAB>  <TAB> logger.debug(""\nEvoking requesting resource {}"".format(resource)) <TAB>  <TAB>  <TAB>  <TAB> request_semaphore.release() <TAB>  <TAB>  <TAB>  <TAB> succeed = True <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> cls.REQUESTING_STACK.append((resource, request_semaphore)) <TAB>  <TAB>  <TAB>  <TAB> return <TAB> if succeed: <TAB>  <TAB> cls._evoke_request()",if node is not None :,188
"def update_all_rhos(instances, scenario_tree, rho_value=None, rho_scale=None): <TAB> assert not ((rho_value is not None) and (rho_scale is not None)) <TAB> for stage in scenario_tree._stages[:-1]: <TAB>  <TAB> for tree_node in stage._tree_nodes: <TAB>  <TAB>  <TAB> for scenario in tree_node._scenarios: <TAB>  <TAB>  <TAB>  <TAB> rho = scenario._rho[tree_node._name] <TAB>  <TAB>  <TAB>  <TAB> for variable_id in tree_node._variable_ids: <MASK> rho[variable_id] = rho_value <TAB>  <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> rho[variable_id] *= rho_scale",if rho_value is not None :,180
"def configured_request_log_handlers(config, prefix=""query_log"", default_logger=None): <TAB> """"""Returns configured query loggers as defined in the `config`."""""" <TAB> handlers = [] <TAB> for section in config.sections(): <MASK> options = dict(config.items(section)) <TAB>  <TAB>  <TAB> type_ = options.pop(""type"") <TAB>  <TAB>  <TAB> if type_ == ""default"": <TAB>  <TAB>  <TAB>  <TAB> logger = default_logger or get_logger() <TAB>  <TAB>  <TAB>  <TAB> handler = ext.request_log_handler(""default"", logger) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> handler = ext.request_log_handler(type_, **options) <TAB>  <TAB>  <TAB> handlers.append(handler) <TAB> return handlers",if section . startswith ( prefix ) :,174
"def eval_dummy_genomes_ctrnn_bad(genomes, config): <TAB> for genome_id, genome in genomes: <TAB>  <TAB> net = neat.ctrnn.CTRNN.create(genome, config, 0.01) <TAB>  <TAB> net.advance([0.5, 0.5, 0.5], 0.01, 0.05) <MASK> genome.fitness = 0.0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> net.reset() <TAB>  <TAB>  <TAB> genome.fitness = 1.0",if genome_id <= 150 :,138
"def housenumber(self): <TAB> if self.street: <TAB>  <TAB> expression = r""\d+"" <TAB>  <TAB> pattern = re.compile(expression) <TAB>  <TAB> match = pattern.search(self.street, re.UNICODE) <MASK> return match.group(0)",if match :,69
"def func(): <TAB> end_received = False <TAB> while True: <TAB>  <TAB> for idx, q in enumerate(self._local_out_queues): <TAB>  <TAB>  <TAB> data = q.get() <TAB>  <TAB>  <TAB> q.task_done() <TAB>  <TAB>  <TAB> if isinstance(data, EndSignal): <TAB>  <TAB>  <TAB>  <TAB> end_received = True <MASK> continue <TAB>  <TAB>  <TAB> self._out_queue.put(data) <TAB>  <TAB> if end_received: <TAB>  <TAB>  <TAB> break",if idx > 0 :,120
"def spin(): <TAB> """"""Wheeeee!"""""" <TAB> state = 0 <TAB> states = random.choice(spinners.spinners) <TAB> while True: <TAB>  <TAB> prefix = ""[%s] "" % _spinner_style(states[state]) <TAB>  <TAB> spinner_handle.update(prefix) <TAB>  <TAB> state = (state + 1) % len(states) <MASK> break",if stop . wait ( 0.1 ) :,103
"def _format_ip_address(container_group): <TAB> """"""Format IP address."""""" <TAB> ip_address = container_group.get(""ipAddress"") <TAB> if ip_address: <TAB>  <TAB> ports = ip_address[""ports""] or [] <MASK> for container in container_group.get(""containers""): <TAB>  <TAB>  <TAB>  <TAB> ports += container.get(""ports"") <TAB>  <TAB> ports = "","".join(str(p[""port""]) for p in ports) <TAB>  <TAB> return ""{0}:{1}"".format(ip_address.get(""ip""), ports) <TAB> return None","if ip_address [ ""type"" ] == ""Private"" :",141
"def check(self, count, count_v, enable, clock, reset, n): <TAB> expect = 0 <TAB> yield reset.posedge <TAB> self.assertEqual(count, expect) <TAB> self.assertEqual(count, count_v) <TAB> while 1: <TAB>  <TAB> yield clock.posedge <MASK> if expect == -n: <TAB>  <TAB>  <TAB>  <TAB> expect = n - 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> expect -= 1 <TAB>  <TAB> yield delay(1) <TAB>  <TAB> # print ""%d count %s expect %s count_v %s"" % (now(), count, expect, count_v) <TAB>  <TAB> self.assertEqual(count, expect) <TAB>  <TAB> self.assertEqual(count, count_v)",if enable :,170
"def _to_str(self, tokens: List[int]) -> str: <TAB> pos = next( <TAB>  <TAB> (idx for idx, x in enumerate(tokens) if x == self.vocab.eos_token_id), -1 <TAB> ) <TAB> if pos != -1: <TAB>  <TAB> tokens = tokens[:pos] <TAB> vocab_map = self.vocab.id_to_token_map_py <TAB> words = [vocab_map[t] for t in tokens] <TAB> if self.encoding is not None and self.perform_decode: <TAB>  <TAB> if self.encoding == ""bpe"": <TAB>  <TAB>  <TAB> words = self.bpe_decode(words) <MASK> words = self.spm_decode(words) <TAB> sentence = "" "".join(words) <TAB> return sentence","elif self . encoding == ""spm"" :",188
"def _iterate_files(self, files, root, include_checksums, relpath): <TAB> file_list = {} <TAB> for file in files: <TAB>  <TAB> exclude = False <TAB>  <TAB> # exclude defined filename patterns <TAB>  <TAB> for pattern in S3Sync.exclude_files: <TAB>  <TAB>  <TAB> if fnmatch.fnmatch(file, pattern): <TAB>  <TAB>  <TAB>  <TAB> exclude = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if not exclude: <TAB>  <TAB>  <TAB> full_path = root + ""/"" + file <MASK> # get checksum <TAB>  <TAB>  <TAB>  <TAB> checksum = self._hash_file(full_path) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> checksum = """" <TAB>  <TAB>  <TAB> file_list[relpath + file] = [full_path, checksum] <TAB> return file_list",if include_checksums :,184
"def render(self, context): <TAB> if self.user is None: <TAB>  <TAB> entries = LogEntry.objects.all() <TAB> else: <TAB>  <TAB> user_id = self.user <MASK> user_id = context[self.user].pk <TAB>  <TAB> entries = LogEntry.objects.filter(user__pk=user_id) <TAB> context[self.varname] = entries.select_related(""content_type"", ""user"")[ <TAB>  <TAB> : int(self.limit) <TAB> ] <TAB> return """"",if not user_id . isdigit ( ) :,126
"def pin_data_keys(self, session_id, data_keys, token, devices=None): <TAB> if not devices: <TAB>  <TAB> devices = functools.reduce( <TAB>  <TAB>  <TAB> operator.or_, <TAB>  <TAB>  <TAB> self._manager_ref.get_data_locations(session_id, data_keys), <TAB>  <TAB>  <TAB> set(), <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> devices = self._normalize_devices(devices) <TAB> pinned = set() <TAB> for dev in devices: <TAB>  <TAB> handler = self.get_storage_handler(dev) <MASK> continue <TAB>  <TAB> keys = handler.pin_data_keys(session_id, data_keys, token) <TAB>  <TAB> pinned.update(keys) <TAB> return list(pinned)","if not getattr ( handler , ""_spillable"" , False ) :",184
"def resolve(self, value: Optional[T]) -> T: <TAB> v: Optional[Any] = value <TAB> if value is None: <TAB>  <TAB> t = os.environ.get(self.envvar) <TAB>  <TAB> if self.type is bool and t: <TAB>  <TAB>  <TAB> v = t in [""true"", ""True"", ""1"", ""yes""] <TAB>  <TAB> elif self.type is str and t: <TAB>  <TAB>  <TAB> v = t <MASK> v = ast.literal_eval(t) if t is not None else None <TAB> if v is None: <TAB>  <TAB> v = self.default <TAB> return v",elif t :,144
"def remove(self, *objs): <TAB> val = getattr(instance, rel_field.rel.get_related_field().attname) <TAB> for obj in objs: <TAB>  <TAB> # Is obj actually part of this descriptor set? <MASK> setattr(obj, rel_field.name, None) <TAB>  <TAB>  <TAB> obj.save() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise rel_field.rel.to.DoesNotExist( <TAB>  <TAB>  <TAB>  <TAB> ""%r is not related to %r."" % (obj, instance) <TAB>  <TAB>  <TAB> )","if getattr ( obj , rel_field . attname ) == val :",137
"def generate_segment_memory(chart_type, race_configs, environment): <TAB> structures = [] <TAB> for race_config in race_configs: <TAB>  <TAB> if ""segment_memory"" in race_config.charts: <TAB>  <TAB>  <TAB> title = chart_type.format_title( <TAB>  <TAB>  <TAB>  <TAB> environment, <TAB>  <TAB>  <TAB>  <TAB> race_config.track, <TAB>  <TAB>  <TAB>  <TAB> es_license=race_config.es_license, <TAB>  <TAB>  <TAB>  <TAB> suffix=""%s-segment-memory"" % race_config.label, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> chart = chart_type.segment_memory(title, environment, race_config) <MASK> structures.append(chart) <TAB> return structures",if chart :,168
"def comment_multiline(self, text, delimiter_end, delimiter_start, style): <TAB> """"""Process the beggining and end of a multiline comment."""""" <TAB> startIndex = 0 <TAB> if self.previousBlockState() != 1: <TAB>  <TAB> startIndex = delimiter_start.indexIn(text) <TAB> while startIndex >= 0: <TAB>  <TAB> endIndex = delimiter_end.indexIn(text, startIndex) <TAB>  <TAB> commentLength = 0 <MASK> self.setCurrentBlockState(1) <TAB>  <TAB>  <TAB> commentLength = len(text) - startIndex <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> commentLength = endIndex - startIndex + delimiter_end.matchedLength() <TAB>  <TAB> self.setFormat(startIndex, commentLength, style) <TAB>  <TAB> startIndex = delimiter_start.indexIn(text, startIndex + commentLength)",if endIndex == - 1 :,199
"def getLatestFile(self): <TAB> highestNsp = None <TAB> highestNsx = None <TAB> for nsp in self.getFiles(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if nsp.path.endswith("".nsx""): <TAB>  <TAB>  <TAB>  <TAB> if not highestNsx or int(nsp.version) > int(highestNsx.version): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> highestNsx = nsp <TAB>  <TAB>  <TAB> else: <MASK> highestNsp = nsp <TAB>  <TAB> except BaseException: <TAB>  <TAB>  <TAB> pass <TAB> return highestNsp or highestNsx",if not highestNsp or int ( nsp . version ) > int ( highestNsp . version ) :,152
"def handle(self, msg): <TAB> self._mic.send(msg) <TAB> for calculate_seed, make_delegate, dict in self._delegate_records: <TAB>  <TAB> id = calculate_seed(msg) <MASK> continue <TAB>  <TAB> elif isinstance(id, collections.Hashable): <TAB>  <TAB>  <TAB> if id not in dict or not dict[id].is_alive(): <TAB>  <TAB>  <TAB>  <TAB> d = make_delegate((self, msg, id)) <TAB>  <TAB>  <TAB>  <TAB> d = self._ensure_startable(d) <TAB>  <TAB>  <TAB>  <TAB> dict[id] = d <TAB>  <TAB>  <TAB>  <TAB> dict[id].start() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> d = make_delegate((self, msg, id)) <TAB>  <TAB>  <TAB> d = self._ensure_startable(d) <TAB>  <TAB>  <TAB> d.start()",if id is None :,192
"def _build_pcf(named_sc, named_pc): <TAB> r = """" <TAB> for sig, pins, others, resname in named_sc: <MASK> for bit, pin in enumerate(pins): <TAB>  <TAB>  <TAB>  <TAB> r += ""set_io {}[{}] {}\n"".format(sig, bit, pin) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> r += ""set_io {} {}\n"".format(sig, pins[0]) <TAB> if named_pc: <TAB>  <TAB> r += ""\n"" + ""\n\n"".join(named_pc) <TAB> return r",if len ( pins ) > 1 :,146
"def __init__(self, profile, report_dir=None, timestamp=None): <TAB> # self.metadata = {} <TAB> self.report_dir = report_dir if report_dir else DEFAULT_REPORT_DIR <TAB> self.profile = profile.replace(""/"", ""_"").replace(""\\"", ""_"")  # Issue 111 <TAB> self.current_time = datetime.datetime.now(dateutil.tz.tzlocal()) <TAB> if timestamp != False: <TAB>  <TAB> self.timestamp = ( <TAB>  <TAB>  <TAB> self.current_time.strftime(""%Y-%m-%d_%Hh%M%z"") <MASK> else timestamp <TAB>  <TAB> )",if not timestamp,144
"def _convert_params_to_v3(params): <TAB> for k, v in OLD_TO_NEW_PARAMS.items(): <TAB>  <TAB> if k in params: <TAB>  <TAB>  <TAB> msg = Message.WARN_PARAMS_NOT_SUPPORTED % (k, v) <TAB>  <TAB>  <TAB> warnings.warn(msg, DeprecationWarning) <TAB>  <TAB>  <TAB> # update to the new query param if not specified already <MASK> params[v] = params.pop(k)",if v not in params :,114
"def rollup_logical(counter, lookup, logical_keys): <TAB> logical = Counter() <TAB> for k, v in counter.items(): <TAB>  <TAB> # TODO: eek, do a fallback of some kind <MASK> logical[(""unknown"", k)] = v <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> linfo = lookup[k] <TAB>  <TAB> lkey = tuple(linfo.get(lk, ""unknown"") for lk in logical_keys) <TAB>  <TAB> logical[lkey] += v <TAB> return logical",if k not in lookup :,123
"def assert_summary_equals(self, records, tag, step, value): <TAB> for record in records[1:]: <TAB>  <TAB> if record.summary.value[0].tag != tag: <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> self.assertEqual(value, tf.make_ndarray(record.summary.value[0].tensor)) <TAB>  <TAB> return <TAB> self.fail(""Could not find record for tag {} and step {}"".format(tag, step))",if record . step != step :,114
"def get_name_from_types(types: Iterable[Union[Type, StrawberryUnion]]): <TAB> names = [] <TAB> for type_ in types: <TAB>  <TAB> if isinstance(type_, StrawberryUnion): <TAB>  <TAB>  <TAB> return type_.name <MASK> name = capitalize_first(type_._type_definition.name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = capitalize_first(type_.__name__) <TAB>  <TAB> names.append(name) <TAB> return """".join(names)","elif hasattr ( type_ , ""_type_definition"" ) :",131
"def parseBamPEFDistributionFile(self, f): <TAB> d = dict() <TAB> lastsample = [] <TAB> for line in f[""f""].splitlines(): <TAB>  <TAB> cols = line.rstrip().split(""\t"") <MASK> continue <TAB>  <TAB> elif cols[0] == ""Size"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> s_name = self.clean_s_name(cols[2].rstrip().split(""/"")[-1], f[""root""]) <TAB>  <TAB>  <TAB> if s_name != lastsample: <TAB>  <TAB>  <TAB>  <TAB> d[s_name] = dict() <TAB>  <TAB>  <TAB>  <TAB> lastsample = s_name <TAB>  <TAB>  <TAB> d[s_name].update({self._int(cols[0]): self._int(cols[1])}) <TAB> return d","if cols [ 0 ] == ""#bamPEFragmentSize"" :",194
"def read_output(meteor_output_path, n_repeats): <TAB> n_combinations = math.factorial(n_repeats) / ( <TAB>  <TAB> math.factorial(2) * math.factorial(n_repeats - 2) <TAB> ) <TAB> raw_scores = [] <TAB> average_scores = [] <TAB> for line in open(meteor_output_path): <TAB>  <TAB> if not line.startswith(""Segment ""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> score = float(line.strip().split(""\t"")[1]) <TAB>  <TAB> raw_scores.append(score) <MASK> average_scores.append(sum(raw_scores) / n_combinations) <TAB>  <TAB>  <TAB> raw_scores = [] <TAB> os.remove(meteor_output_path) <TAB> return average_scores",if len ( raw_scores ) == n_combinations :,198
"def get_new_pids(self): <TAB> if not self.need_poll(): <TAB>  <TAB> return <TAB> for process in psutil.process_iter(): <TAB>  <TAB> info = process.as_dict([""create_time"", ""pid"", ""name"", ""exe""]) <TAB>  <TAB> pid = info[""pid""] <TAB>  <TAB> if pid not in self.pids or self.pids[pid] == info[""create_time""]: <TAB>  <TAB>  <TAB> for name in self.names: <MASK> yield pid <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.pids[pid] = info[""create_time""]","if name . match ( info [ ""name"" ] ) or name . match ( info [ ""exe"" ] ) :",153
"def _Attribute(self, node): <TAB> if not isinstance(node.ctx, ast.Store): <TAB>  <TAB> scope = self.scope.get_inner_scope_for_line(node.lineno) <TAB>  <TAB> pyname = evaluate.eval_node(scope, node.value) <MASK> if node.attr not in pyname.get_object(): <TAB>  <TAB>  <TAB>  <TAB> self._add_error(node, ""Unresolved attribute"") <TAB> ast.walk(node.value, self)",if pyname is not None and pyname . get_object ( ) != pyobjects . get_unknown ( ) :,136
def _init_neighbor(neighbor): <TAB> families = neighbor.families() <TAB> for change in neighbor.changes: <TAB>  <TAB> if change.nlri.family() in families: <TAB>  <TAB>  <TAB> # This add the family to neighbor.families() <TAB>  <TAB>  <TAB> neighbor.rib.outgoing.add_to_rib_watchdog(change) <TAB> for message in messages: <TAB>  <TAB> if message.family() in families: <MASK> neighbor.asm[message.family()] = message <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> neighbor.messages.append(message) <TAB> self.neighbors[neighbor.name()] = neighbor,"if message . name == ""ASM"" :",152
"def date_match(self, date1, date2): <TAB> if date1.is_empty() or date2.is_empty(): <TAB>  <TAB> return 0 <TAB> if date1.is_equal(date2): <TAB>  <TAB> return 1 <TAB> if date1.is_compound() or date2.is_compound(): <TAB>  <TAB> return self.range_compare(date1, date2) <TAB> if date1.get_year() == date2.get_year(): <MASK> return 0.75 <TAB>  <TAB> if not date1.get_month_valid() or not date2.get_month_valid(): <TAB>  <TAB>  <TAB> return 0.75 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return -1 <TAB> else: <TAB>  <TAB> return -1",if date1 . get_month ( ) == date2 . get_month ( ) :,189
"def del_var_history(self, var, f=None, line=None): <TAB> """"""If file f and line are not given, the entire history of var is deleted"""""" <TAB> if var in self.variables: <MASK> self.variables[var] = [ <TAB>  <TAB>  <TAB>  <TAB> x for x in self.variables[var] if x[""file""] != f and x[""line""] != line <TAB>  <TAB>  <TAB> ] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.variables[var] = []",if f and line :,120
"def test_certs(self): <TAB> self.assertTrue(len(self.regions) > 0) <TAB> for region in self.regions: <TAB>  <TAB> special_access_required = False <TAB>  <TAB> for snippet in (""gov"", ""cn-""): <TAB>  <TAB>  <TAB> if snippet in region.name: <TAB>  <TAB>  <TAB>  <TAB> special_access_required = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> c = region.connect() <TAB>  <TAB>  <TAB> self.sample_service_call(c) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> # This is bad (because the SSL cert failed). Re-raise the <TAB>  <TAB>  <TAB> # exception. <MASK> raise",if not special_access_required :,161
"def convert_encoder_layer(opus_dict, layer_prefix: str, converter: dict): <TAB> sd = {} <TAB> for k in opus_dict: <MASK> continue <TAB>  <TAB> stripped = remove_prefix(k, layer_prefix) <TAB>  <TAB> v = opus_dict[k].T  # besides embeddings, everything must be transposed. <TAB>  <TAB> sd[converter[stripped]] = torch.tensor(v).squeeze() <TAB> return sd",if not k . startswith ( layer_prefix ) :,117
"def test_sequence(self, sequence): <TAB> for test in sequence: <MASK> test, kwargs = test <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> kwargs = {} <TAB>  <TAB> self.do_check(test, **kwargs) <TAB>  <TAB> if test == ExpectedError: <TAB>  <TAB>  <TAB> return False <TAB> return True","if isinstance ( test , tuple ) :",81
"def make_table(grid): <TAB> max_cols = [ <TAB>  <TAB> max(out) <TAB>  <TAB> for out in map(list, zip(*[[len(item) for item in row] for row in grid])) <TAB> ] <TAB> rst = table_div(max_cols, 1) <TAB> for i, row in enumerate(grid): <TAB>  <TAB> header_flag = False <MASK> header_flag = True <TAB>  <TAB> rst += normalize_row(row, max_cols) <TAB>  <TAB> rst += table_div(max_cols, header_flag) <TAB> return rst",if i == 0 or i == len ( grid ) - 1 :,147
"def test_float_overflow(self): <TAB> import sys <TAB> big_int = int(sys.float_info.max) * 2 <TAB> for t in float_types + [c_longdouble]: <TAB>  <TAB> self.assertRaises(OverflowError, t, big_int) <TAB>  <TAB> if hasattr(t, ""__ctype_be__""): <TAB>  <TAB>  <TAB> self.assertRaises(OverflowError, t.__ctype_be__, big_int) <MASK> self.assertRaises(OverflowError, t.__ctype_le__, big_int)","if hasattr ( t , ""__ctype_le__"" ) :",131
"def _process_folder(config, folder, cache, output): <TAB> if not os.path.isdir(folder): <TAB>  <TAB> raise ConanException(""No such directory: '%s'"" % str(folder)) <TAB> if config.source_folder: <TAB>  <TAB> folder = os.path.join(folder, config.source_folder) <TAB> for root, dirs, files in walk(folder): <TAB>  <TAB> dirs[:] = [d for d in dirs if d != "".git""] <MASK> continue <TAB>  <TAB> for f in files: <TAB>  <TAB>  <TAB> _process_file(root, f, config, cache, output, folder)","if "".git"" in root :",150
"def setChanged(self, c, changed): <TAB> # Find the tab corresponding to c. <TAB> dw = c.frame.top  # A DynamicWindow <TAB> i = self.indexOf(dw) <TAB> if i < 0: <TAB>  <TAB> return <TAB> s = self.tabText(i) <TAB> s = g.u(s) <TAB> if len(s) > 2: <MASK> if not s.startswith(""* ""): <TAB>  <TAB>  <TAB>  <TAB> title = ""* "" + s <TAB>  <TAB>  <TAB>  <TAB> self.setTabText(i, title) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if s.startswith(""* ""): <TAB>  <TAB>  <TAB>  <TAB> title = s[2:] <TAB>  <TAB>  <TAB>  <TAB> self.setTabText(i, title)",if changed :,172
"def dump_metrics(self): <TAB> metrics = self._registry.dump_metrics() <TAB> # Filter out min and max if there have been no samples. <TAB> for metric in metrics.itervalues(): <TAB>  <TAB> if metric.get(""count"") == 0: <MASK> metric[""min""] = 0.0 <TAB>  <TAB>  <TAB> if ""max"" in metric: <TAB>  <TAB>  <TAB>  <TAB> metric[""max""] = 0.0 <TAB> return metrics","if ""min"" in metric :",109
"def ref_max_pooling_3d(x, kernel, stride, ignore_border, pad): <TAB> y = [] <TAB> for xx in x.reshape((-1,) + x.shape[-4:]): <MASK> xx = xx[np.newaxis] <TAB>  <TAB> y += [ <TAB>  <TAB>  <TAB> refs.pooling_3d(xx, ""max"", kernel, stride, pad, ignore_border)[np.newaxis] <TAB>  <TAB> ] <TAB> y = np.vstack(y) <TAB> if x.ndim == 3: <TAB>  <TAB> y = np.squeeze(y, 1) <TAB> return y.reshape(x.shape[:-4] + y.shape[1:])",if xx . ndim == 3 :,160
def reader_(): <TAB> with open(file_list) as flist: <TAB>  <TAB> lines = [line.strip() for line in flist] <MASK> random.shuffle(lines) <TAB>  <TAB> for line in lines: <TAB>  <TAB>  <TAB> file_path = line.strip() <TAB>  <TAB>  <TAB> yield [file_path],if shuffle :,79
"def _sql_like_to_regex(pattern, escape): <TAB> cur_i = 0 <TAB> pattern_length = len(pattern) <TAB> while cur_i < pattern_length: <TAB>  <TAB> nxt_i = cur_i + 1 <TAB>  <TAB> cur = pattern[cur_i] <TAB>  <TAB> nxt = pattern[nxt_i] if nxt_i < pattern_length else None <TAB>  <TAB> skip = 1 <TAB>  <TAB> if nxt is not None and escape is not None and cur == escape: <TAB>  <TAB>  <TAB> yield nxt <TAB>  <TAB>  <TAB> skip = 2 <TAB>  <TAB> elif cur == ""%"": <TAB>  <TAB>  <TAB> yield "".*"" <MASK> yield ""."" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield cur <TAB>  <TAB> cur_i += skip","elif cur == ""_"" :",169
"def gaussian(N=1000, draw=True, show=True, seed=42, color=None, marker=""sphere""): <TAB> """"""Show N random gaussian distributed points using a scatter plot."""""" <TAB> import ipyvolume as ipv <TAB> rng = np.random.RandomState(seed)  # pylint: disable=no-member <TAB> x, y, z = rng.normal(size=(3, N)) <TAB> if draw: <MASK> mesh = ipv.scatter(x, y, z, marker=marker, color=color) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> mesh = ipv.scatter(x, y, z, marker=marker) <TAB>  <TAB> if show: <TAB>  <TAB>  <TAB> # ipv.squarelim() <TAB>  <TAB>  <TAB> ipv.show() <TAB>  <TAB> return mesh <TAB> else: <TAB>  <TAB> return x, y, z",if color :,191
"def _delete_keys(bucket, keys): <TAB> for name in keys: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> k = boto.s3.connection.Key(bucket, name) <TAB>  <TAB>  <TAB>  <TAB> bucket.delete_key(k) <TAB>  <TAB>  <TAB> except boto.exception.S3ResponseError as e: <MASK> # Key is already not present.  Continue the <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # deletion iteration. <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> break",if e . status == 404 :,141
"def detect(self): <TAB> hardware = self.middleware.call_sync(""failover.hardware"") <TAB> if hardware == ""ECHOSTREAM"": <TAB>  <TAB> proc = subprocess.check_output( <TAB>  <TAB>  <TAB> '/usr/sbin/pciconf -lv | grep ""card=0xa01f8086 chip=0x10d38086""', <TAB>  <TAB>  <TAB> shell=True, <TAB>  <TAB>  <TAB> encoding=""utf8"", <TAB>  <TAB> ) <MASK> return [proc.split(""@"")[0]] <TAB> if hardware in (""ECHOWARP"", ""PUMA""): <TAB>  <TAB> return [""ntb0""] <TAB> if hardware == ""BHYVE"": <TAB>  <TAB> return [""vtnet1""] <TAB> if hardware == ""SBB"": <TAB>  <TAB> return [""ix0""] <TAB> if hardware == ""ULTIMATE"": <TAB>  <TAB> return [""igb1""] <TAB> return []",if proc :,199
"def check_config(param): <TAB> fileopen = open(""/etc/setoolkit/set.config"", ""r"") <TAB> for line in fileopen: <TAB>  <TAB> line = line.rstrip() <TAB>  <TAB> # print line <TAB>  <TAB> # if the line starts with the param we want then we are set, otherwise <TAB>  <TAB> # if it starts with a # then ignore <TAB>  <TAB> if line.startswith(param) != ""#"": <MASK> line = line.rstrip() <TAB>  <TAB>  <TAB>  <TAB> # remove any quotes or single quotes <TAB>  <TAB>  <TAB>  <TAB> line = line.replace('""', """") <TAB>  <TAB>  <TAB>  <TAB> line = line.replace(""'"", """") <TAB>  <TAB>  <TAB>  <TAB> line = line.split(""="", 1) <TAB>  <TAB>  <TAB>  <TAB> return line[1]",if line . startswith ( param ) :,176
"def put(self, s): <TAB> """"""Put string s to self.outputFile. All output eventually comes here."""""" <TAB> # Improved code: self.outputFile (a cStringIO object) always exists. <TAB> if s: <TAB>  <TAB> self.putCount += 1 <MASK> s = g.toEncodedString(s, self.leo_file_encoding, reportErrors=True) <TAB>  <TAB> self.outputFile.write(s)",if not g . isPython3 :,110
"def get_system_prop_font(self): <TAB> """"""Look up the system font"""""" <TAB> if self.system_prop_font is not None: <TAB>  <TAB> return self.system_prop_font <TAB> elif ""org.gnome.desktop.interface"" not in Gio.Settings.list_schemas(): <TAB>  <TAB> return <TAB> else: <TAB>  <TAB> gsettings = Gio.Settings.new(""org.gnome.desktop.interface"") <TAB>  <TAB> value = gsettings.get_value(""font-name"") <MASK> self.system_prop_font = value.get_string() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.system_prop_font = ""Sans 10"" <TAB>  <TAB> return self.system_prop_font",if value :,170
"def _setoct(self, octstring): <TAB> """"""Reset the bitstring to have the value given in octstring."""""" <TAB> octstring = tidy_input_string(octstring) <TAB> # remove any 0o if present <TAB> octstring = octstring.replace(""0o"", """") <TAB> binlist = [] <TAB> for i in octstring: <TAB>  <TAB> try: <MASK> raise ValueError <TAB>  <TAB>  <TAB> binlist.append(OCT_TO_BITS[int(i)]) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> raise CreationError(""Invalid symbol '{0}' in oct initialiser."", i) <TAB> self._setbin_unsafe("""".join(binlist))",if not 0 <= int ( i ) < 8 :,166
"def group(self, resources): <TAB> groups = {} <TAB> for r in resources: <TAB>  <TAB> v = self._value_to_sort(self.group_by, r) <TAB>  <TAB> vstr = str(v) <MASK> groups[vstr] = {""sortkey"": v, ""resources"": []} <TAB>  <TAB> groups[vstr][""resources""].append(r) <TAB> return groups",if vstr not in groups :,98
"def rd(line_number, row, col, key, default=None): <TAB> """"""Return Row data by column name"""""" <TAB> if key in col: <TAB>  <TAB> if col[key] >= len(row): <TAB>  <TAB>  <TAB> LOG.warning(""missing '%s, on line %d"" % (key, line_number)) <TAB>  <TAB>  <TAB> return default <TAB>  <TAB> retval = row[col[key]].strip() <MASK> return default <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return retval <TAB> else: <TAB>  <TAB> return default","if retval == """" :",125
"def _run(self): <TAB> while True: <TAB>  <TAB> tup = self._pop() <MASK> return <TAB>  <TAB> method_name, kwargs, msg = tup <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> super(SerializedInvoker, self).invoke(method_name, kwargs, msg) <TAB>  <TAB> except mitogen.core.CallError: <TAB>  <TAB>  <TAB> e = sys.exc_info()[1] <TAB>  <TAB>  <TAB> LOG.warning(""%r: call error: %s: %s"", self, msg, e) <TAB>  <TAB>  <TAB> msg.reply(e) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> LOG.exception(""%r: while invoking %s()"", self, method_name) <TAB>  <TAB>  <TAB> msg.reply(mitogen.core.Message.dead())",if tup is None :,179
"def raises(except_cls, message=None): <TAB> try: <TAB>  <TAB> yield <TAB>  <TAB> success = False <TAB> except except_cls as e: <MASK> assert re.search(message, compat.text_type(e), re.UNICODE), ""%r !~ %s"" % ( <TAB>  <TAB>  <TAB>  <TAB> message, <TAB>  <TAB>  <TAB>  <TAB> e, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> print(compat.text_type(e).encode(""utf-8"")) <TAB>  <TAB> success = True <TAB> # assert outside the block so it works for AssertionError too ! <TAB> assert success, ""Callable did not raise an exception""",if message :,145
"def buttonClicked(self, button): <TAB> role = self.buttonBox.buttonRole(button) <TAB> if role == QDialogButtonBox.ResetRole: <TAB>  <TAB> current_tab = self.tabwidget.currentWidget() <TAB>  <TAB> section_to_update = Sections.ALL <TAB>  <TAB> if current_tab is self.page_general: <TAB>  <TAB>  <TAB> section_to_update = Sections.GENERAL <MASK> section_to_update = Sections.DISPLAY <TAB>  <TAB> self.resetToDefaults(section_to_update)",if current_tab is self . page_display :,137
"def make_range_list(*values): <TAB> ranges = [] <TAB> for v in values: <MASK> val_node = plural.value_node(v) <TAB>  <TAB>  <TAB> ranges.append((val_node, val_node)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert isinstance(v, tuple) <TAB>  <TAB>  <TAB> ranges.append((plural.value_node(v[0]), plural.value_node(v[1]))) <TAB> return plural.range_list_node(ranges)","if isinstance ( v , int ) :",121
"def __in_comment(self): <TAB> if self.highlighter: <TAB>  <TAB> current_color = self.__get_current_color() <TAB>  <TAB> comment_color = self.highlighter.get_color_name(""comment"") <MASK> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> else: <TAB>  <TAB> return False",if current_color == comment_color :,90
"def __str__(self): <TAB> """"""Constructs to variable list output used in cron jobs"""""" <TAB> ret = [] <TAB> for key, value in self.items(): <TAB>  <TAB> if self.previous: <TAB>  <TAB>  <TAB> if self.previous.all().get(key, None) == value: <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> value = '""%s""' % value <TAB>  <TAB> ret.append(""%s=%s"" % (key, unicode(value))) <TAB> ret.append("""") <TAB> return ""\n"".join(ret)","if "" "" in unicode ( value ) or value == """" :",132
"def _on_config_changed(changed_name: str) -> None: <TAB> """"""Call config_changed hooks if the config changed."""""" <TAB> for mod_info in _module_infos: <TAB>  <TAB> if mod_info.skip_hooks: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for option, hook in mod_info.config_changed_hooks: <TAB>  <TAB>  <TAB> if option is None: <TAB>  <TAB>  <TAB>  <TAB> hook() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> cfilter = config.change_filter(option) <TAB>  <TAB>  <TAB>  <TAB> cfilter.validate() <MASK> hook()",if cfilter . check_match ( changed_name ) :,151
"def __init__(self, transcripts, vocab=None, unknown=None, *args, **kwargs): <TAB> """"""Creates a new raw transcript source."""""" <TAB> super().__init__(*args, **kwargs) <TAB> self.transcripts = transcripts <TAB> self.indices = numpy.arange(len(self)) <TAB> self.vocab = self.make_vocab(vocab) <TAB> if unknown is None: <TAB>  <TAB> self.unknown = self.unknown_index = None <TAB> else: <TAB>  <TAB> self.unknown_index = self.vocab.get(unknown) <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> 'The ""unknown"" vocabulary word must be ' <TAB>  <TAB>  <TAB>  <TAB> ""part of the vocabulary itself."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self.unknown = unknown",if self . unknown_index is None :,182
"def load_info(cls, path, reset_paths=False, load_model_if_required=True): <TAB> load_path = path + cls.trainer_info_name <TAB> try: <TAB>  <TAB> return load_pkl.load(path=load_path) <TAB> except: <MASK> trainer = cls.load(path=path, reset_paths=reset_paths) <TAB>  <TAB>  <TAB> return trainer.get_info() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise",if load_model_if_required :,120
"def createActions(actions, target): <TAB> # actions = [(name, shortcut, icon, desc, func)] <TAB> for name, shortcut, icon, desc, func in actions: <TAB>  <TAB> action = QAction(target) <MASK> action.setIcon(icon) <TAB>  <TAB> if shortcut: <TAB>  <TAB>  <TAB> action.setShortcut(shortcut) <TAB>  <TAB> action.setText(desc) <TAB>  <TAB> action.triggered.connect(func) <TAB>  <TAB> setattr(target, name, action)",if icon :,114
"def load_user_logins(self, key, dates, timestamps, size_threshold=None): <TAB> date_bucket = {} <TAB> for user_data in self.fetch_user_table(): <MASK> continue <TAB>  <TAB> # note: ts should already be utc! <TAB>  <TAB> dt = datetime.fromtimestamp(user_data[6] / 1000) <TAB>  <TAB> dt = dt.date().isoformat() <TAB>  <TAB> date_bucket[dt] = date_bucket.get(dt, 0) + 1 <TAB> datapoints = [] <TAB> for dt, ts in zip(dates, timestamps): <TAB>  <TAB> count = date_bucket.get(dt, 0) <TAB>  <TAB> datapoints.append((count, ts)) <TAB> return {""target"": key, ""datapoints"": datapoints}",if size_threshold is not None and user_data [ 1 ] < size_threshold :,194
def apply_batch(it): <TAB> batch = [] <TAB> for item in it: <MASK> yield item <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> batch.append(item) <TAB>  <TAB>  <TAB> if len(batch) >= n: <TAB>  <TAB>  <TAB>  <TAB> yield batch <TAB>  <TAB>  <TAB>  <TAB> batch = [] <TAB> if batch: <TAB>  <TAB> yield batch,"if isinstance ( item , _NextValueNotReady ) :",92
"def convert_tomlkit_table(section): <TAB> if isinstance(section, tomlkit.items.Table): <TAB>  <TAB> body = section.value._body <TAB> else: <TAB>  <TAB> body = section._body <TAB> for key, value in body: <TAB>  <TAB> if not key: <TAB>  <TAB>  <TAB> continue <MASK> table = tomlkit.inline_table() <TAB>  <TAB>  <TAB> table.update(value.value) <TAB>  <TAB>  <TAB> section[key.key] = table","if hasattr ( value , ""keys"" ) and not isinstance ( value , tomlkit . items . InlineTable ) :",134
"def _do_ssl_handshake(self): <TAB> try: <TAB>  <TAB> self.socket.do_handshake() <TAB> except ssl.SSLError as err: <TAB>  <TAB> if err.args[0] in (ssl.SSL_ERROR_WANT_READ, ssl.SSL_ERROR_WANT_WRITE): <TAB>  <TAB>  <TAB> return <MASK> return self.handle_close() <TAB>  <TAB> raise <TAB> except OSError as err: <TAB>  <TAB> if err.args[0] == errno.ECONNABORTED: <TAB>  <TAB>  <TAB> return self.handle_close() <TAB> else: <TAB>  <TAB> self._ssl_accepting = False",elif err . args [ 0 ] == ssl . SSL_ERROR_EOF :,161
"def get_filechanges(repo, revision, parents, mleft): <TAB> """"""Given some repository and revision, find all changed/deleted files."""""" <TAB> l, c, r = [], [], [] <TAB> for p in parents: <MASK> continue <TAB>  <TAB> mright = revsymbol(repo, b""%d"" % p).manifest() <TAB>  <TAB> l, c, r = split_dict(mleft, mright, l, c, r) <TAB> l.sort() <TAB> c.sort() <TAB> r.sort() <TAB> return l, c, r",if p < 0 :,134
"def close_share(self, share_name): <TAB> c = await run( <TAB>  <TAB> [SMBCmd.SMBCONTROL.value, ""smbd"", ""close-share"", share_name], check=False <TAB> ) <TAB> if c.returncode != 0: <MASK> # smbd is not running. Don't log error message. <TAB>  <TAB>  <TAB> return <TAB>  <TAB> self.logger.warn( <TAB>  <TAB>  <TAB> ""Failed to close smb share [%s]: [%s]"", <TAB>  <TAB>  <TAB> share_name, <TAB>  <TAB>  <TAB> c.stderr.decode().strip(), <TAB>  <TAB> )","if ""Can't find pid"" in c . stderr . decode ( ) :",152
"def execute(self, context): <TAB> if self.tree_name: <TAB>  <TAB> ng = bpy.data.node_groups.get(self.tree_name) <MASK> apply_theme(ng) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return {""CANCELLED""} <TAB> else: <TAB>  <TAB> apply_theme() <TAB> return {""FINISHED""}",if ng :,86
"def apply(self, db, object): <TAB> if not self.source_handle: <MASK> # check whether the citation list is empty as a proxy for <TAB>  <TAB>  <TAB> # there being no sources <TAB>  <TAB>  <TAB> return len(object.get_all_citation_lists()) == 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> else: <TAB>  <TAB> for citation_handle in object.get_all_citation_lists(): <TAB>  <TAB>  <TAB> citation = db.get_citation_from_handle(citation_handle) <TAB>  <TAB>  <TAB> if citation.get_reference_handle() == self.source_handle: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> return False",if self . nosource :,164
"def get_data_dir(): <TAB> """"""Get the directory path for flit user data files."""""" <TAB> home = os.path.realpath(os.path.expanduser(""~"")) <TAB> if sys.platform == ""darwin"": <TAB>  <TAB> d = Path(home, ""Library"") <TAB> elif os.name == ""nt"": <TAB>  <TAB> appdata = os.environ.get(""APPDATA"", None) <MASK> d = Path(appdata) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> d = Path(home, ""AppData"", ""Roaming"") <TAB> else: <TAB>  <TAB> # Linux, non-OS X Unix, AIX, etc. <TAB>  <TAB> xdg = os.environ.get(""XDG_DATA_HOME"", None) <TAB>  <TAB> d = Path(xdg) if xdg else Path(home, "".local/share"") <TAB> return d / ""flit""",if appdata :,195
"def wait_for_service(name, timeout=200): <TAB> start = time.time() <TAB> while True: <TAB>  <TAB> status = win32serviceutil.QueryServiceStatus(name) <TAB>  <TAB> if status[1] == win32service.SERVICE_STOPPED: <TAB>  <TAB>  <TAB> break <MASK> raise TimeoutError( <TAB>  <TAB>  <TAB>  <TAB> ""Timeout waiting for service"" <TAB>  <TAB>  <TAB> )  # pylint: disable=undefined-variable <TAB>  <TAB> time.sleep(0.3)",if time . time ( ) - start > timeout :,121
"def get_selection(self): <TAB> if self.uistate[""selection""] == ""all"": <TAB>  <TAB> return AllPages(self.notebook) <TAB> else: <TAB>  <TAB> path = self.uistate[""selected_page""] <MASK> return SubPages(self.notebook, path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return SinglePage(self.notebook, path)","if self . uistate [ ""selection_recursive"" ] :",100
"def test_repeated_edges(self): <TAB> graph_size = 20 <TAB> for _ in range(20): <TAB>  <TAB> graph = Graph.graph(graph_size, int(graph_size * 2), repeated_edges=True) <TAB>  <TAB> edges = [(e.start, e.end) for e in graph.iterate_edges()] <TAB>  <TAB> has_repeated_edges = len(edges) > len(set(edges)) <MASK> break <TAB> self.assertTrue(has_repeated_edges) <TAB> for _ in range(10): <TAB>  <TAB> graph = Graph.graph(graph_size, int(graph_size * 2), repeated_edges=False) <TAB>  <TAB> edges = list(graph.iterate_edges()) <TAB>  <TAB> self.assertEqual(len(edges), len(set(edges)))",if has_repeated_edges :,189
"def cs(self): <TAB> """"""ConfigSpace representation of this search space."""""" <TAB> cs = CS.ConfigurationSpace() <TAB> for k, v in self.kwvars.items(): <MASK> _add_cs(cs, v.cs, k) <TAB>  <TAB> elif isinstance(v, Space): <TAB>  <TAB>  <TAB> hp = v.get_hp(name=k) <TAB>  <TAB>  <TAB> _add_hp(cs, hp) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _rm_hp(cs, k) <TAB> return cs","if isinstance ( v , NestedSpace ) :",129
"def packet_handler(Packet): <TAB> global add_new_line <TAB> if Packet.haslayer(ICMP): <TAB>  <TAB> Data = Packet.getlayer(ICMP).getlayer(Raw) <TAB>  <TAB> exfiltrated_data = Data.load[int(exfiltration_length) :].replace( <TAB>  <TAB>  <TAB> exfiltration_length * ""\n"", ""\n"" <TAB>  <TAB> ) <MASK> add_new_line = False <TAB>  <TAB> sys.stdout.write(exfiltrated_data) <TAB>  <TAB> sys.stdout.flush()","if exfiltrated_data . endswith ( ""\n"" ) :",145
"def acquire(self, *, wait=False): <TAB> if not wait and self.value <= 0: <TAB>  <TAB> # signal that we're not acquiring <TAB>  <TAB> return False <TAB> while self.value <= 0: <TAB>  <TAB> future = self.loop.create_future() <TAB>  <TAB> self._waiters.append(future) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> await future <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> future.cancel() <MASK> self.wake_up() <TAB>  <TAB>  <TAB> raise <TAB> self.value -= 1 <TAB> return True",if self . value > 0 and not future . cancelled ( ) :,142
"def handle_events(self, events): <TAB> for event in events: <MASK> self.recording ^= True <TAB>  <TAB>  <TAB> if not self.recording: <TAB>  <TAB>  <TAB>  <TAB> self.save() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> logger.info(""ScreenRecorder started"") <TAB>  <TAB>  <TAB> break <TAB> return events",if event == WindowEvent . SCREEN_RECORDING_TOGGLE :,92
"def _register_for_operations(config, session, service_name): <TAB> # There's certainly a tradeoff for registering the retry config <TAB> # for the operations when the service is created.  In practice, <TAB> # there aren't a whole lot of per operation retry configs so <TAB> # this is ok for now. <TAB> for key in config: <MASK> continue <TAB>  <TAB> handler = retryhandler.create_retry_handler(config, key) <TAB>  <TAB> unique_id = ""retry-config-%s-%s"" % (service_name, key) <TAB>  <TAB> session.register( <TAB>  <TAB>  <TAB> ""needs-retry.%s.%s"" % (service_name, key), handler, unique_id=unique_id <TAB>  <TAB> )","if key == ""__default__"" :",176
"def showTicks(self, show=True): <TAB> for tick in self.ticks.keys(): <TAB>  <TAB> if show: <TAB>  <TAB>  <TAB> tick.show() <TAB>  <TAB>  <TAB> orig = getattr(self, ""_allowAdd_backup"", None) <MASK> self.allowAdd = orig <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._allowAdd_backup = self.allowAdd <TAB>  <TAB>  <TAB> self.allowAdd = False  # block tick creation <TAB>  <TAB>  <TAB> tick.hide()",if orig :,116
"def _has_cycle(self, node, visited, visit_stack): <TAB> self.last_visited_node = node <TAB> self.path.append(node) <TAB> visited[node] = True <TAB> visit_stack[node] = True <TAB> for neighbor in self.graph[node]: <TAB>  <TAB> if not visited[neighbor]: <MASK> return True <TAB>  <TAB> elif visit_stack[neighbor]: <TAB>  <TAB>  <TAB> self.path.append(neighbor) <TAB>  <TAB>  <TAB> return True <TAB> self.path.remove(node) <TAB> visit_stack[node] = False <TAB> return False","if self . _has_cycle ( neighbor , visited , visit_stack ) :",154
"def get_project_list(exclude_default=False): <TAB> """"""get_project_list - get list of all projects"""""" <TAB> projects_path = __project__.get_projects_path() <TAB> project_list = [] <TAB> if os.path.exists(projects_path): <TAB>  <TAB> for project in os.listdir(projects_path): <TAB>  <TAB>  <TAB> project_path = os.path.join(projects_path, project) <MASK> project_list.append(project) <TAB> if exclude_default: <TAB>  <TAB> pass <TAB> else: <TAB>  <TAB> project_list.append(""default"") <TAB> return sorted(project_list)",if os . path . isdir ( project_path ) :,161
"def split(self, chunksize): <TAB> modulus_map = { <TAB>  <TAB> 4: 256, <TAB>  <TAB> 5: 10, <TAB>  <TAB> 8: 100, <TAB> } <TAB> chunks, ip = self.preprocess(chunksize) <TAB> ret = """" <TAB> for i in range(len(chunks)): <TAB>  <TAB> ip_part = compat_str(ip[i] % modulus_map[chunksize]) if i < 4 else """" <MASK> ret += ip_part + chunks[i] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret += chunks[i] + ip_part <TAB> self.target = ret",if chunksize == 8 :,143
"def DepsToModules(deps, prefix, suffix): <TAB> modules = [] <TAB> for filepath in deps: <TAB>  <TAB> filename = os.path.basename(filepath) <MASK> modules.append(filename[len(prefix) : -len(suffix)]) <TAB> return modules",if filename . startswith ( prefix ) and filename . endswith ( suffix ) :,79
"def listdir(path): <TAB> path = path.rstrip(""/"") + ""/"" <TAB> dir_set, file_set = set(), set() <TAB> for p in files.keys(): <MASK> continue <TAB>  <TAB> parts = p[len(path) :].split(""/"") <TAB>  <TAB> if len(parts) == 1: <TAB>  <TAB>  <TAB> file_set.add(parts[0]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> dir_set.add(parts[0]) <TAB> return sorted(dir_set), sorted(file_set)",if not p . startswith ( path ) :,128
"def read_series(rec): <TAB> found = [] <TAB> for tag in (""440"", ""490"", ""830""): <TAB>  <TAB> fields = rec.get_fields(tag) <MASK> continue <TAB>  <TAB> for f in fields: <TAB>  <TAB>  <TAB> this = [] <TAB>  <TAB>  <TAB> for k, v in f.get_subfields([""a"", ""v""]): <TAB>  <TAB>  <TAB>  <TAB> if k == ""v"" and v: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> this.append(v) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB>  <TAB> v = v.rstrip("".,; "") <TAB>  <TAB>  <TAB>  <TAB> if v: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> this.append(v) <TAB>  <TAB>  <TAB> if this: <TAB>  <TAB>  <TAB>  <TAB> found += ["" -- "".join(this)] <TAB> return found",if not fields :,182
"def find_nameless_urls(self, conf): <TAB> nameless = [] <TAB> patterns = self.get_patterns(conf) <TAB> for u in patterns: <MASK> nameless.extend(self.find_nameless_urls(u)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if u.name is None: <TAB>  <TAB>  <TAB>  <TAB> nameless.append(u) <TAB> return nameless",if self . has_patterns ( u ) :,103
"def update_billing_status(self, update_modified=True): <TAB> updated_pr = [self.name] <TAB> for d in self.get(""items""): <MASK> updated_pr += update_billed_amount_based_on_po( <TAB>  <TAB>  <TAB>  <TAB> d.purchase_order_item, update_modified <TAB>  <TAB>  <TAB> ) <TAB> for pr in set(updated_pr): <TAB>  <TAB> pr_doc = self if (pr == self.name) else frappe.get_doc(""Purchase Receipt"", pr) <TAB>  <TAB> update_billing_percentage(pr_doc, update_modified=update_modified) <TAB> self.load_from_db()",if d . purchase_order_item :,166
"def _get_version(): <TAB> with open(""haiku/__init__.py"") as fp: <TAB>  <TAB> for line in fp: <MASK> g = {} <TAB>  <TAB>  <TAB>  <TAB> exec(line, g)  # pylint: disable=exec-used <TAB>  <TAB>  <TAB>  <TAB> return g[""__version__""] <TAB>  <TAB> raise ValueError(""`__version__` not defined in `haiku/__init__.py`"")","if line . startswith ( ""__version__"" ) :",101
"def GetSelected(self): <TAB> if self.GetStyleL(""style"") & self.Style.LBS_MULTIPLESEL: <TAB>  <TAB> result = self.SendMessage(self.Hwnd, self.Msg.LB_GETSELCOUNT, 0, 0) <TAB>  <TAB> if result: <TAB>  <TAB>  <TAB> return self.SendMessage(self.Hwnd, self.Msg.LB_GETANCHORINDEX, 0, 0) <TAB> else: <TAB>  <TAB> result = self.SendMessage(self.Hwnd, self.Msg.LB_GETCURSEL, 0, 0) <MASK> return result",if result != LB_ERR :,151
"def __init__(self, column_names, column_types, **kwargs): <TAB> super().__init__(**kwargs) <TAB> self.column_names = column_names <TAB> self.column_types = column_types <TAB> encoding = [] <TAB> for column_name in self.column_names: <TAB>  <TAB> column_type = self.column_types[column_name] <MASK> # TODO: Search to use one-hot or int. <TAB>  <TAB>  <TAB> encoding.append(keras_layers.INT) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> encoding.append(keras_layers.NONE) <TAB> self.layer = keras_layers.MultiCategoryEncoding(encoding)",if column_type == analysers . CATEGORICAL :,162
"def rotate(cls, axis, theta): <TAB> """"""Prepare a quaternion that represents a rotation on a given axis."""""" <TAB> if isinstance(axis, str): <MASK> axis = V.X <TAB>  <TAB> elif axis in (""y"", ""Y""): <TAB>  <TAB>  <TAB> axis = V.Y <TAB>  <TAB> elif axis in (""z"", ""Z""): <TAB>  <TAB>  <TAB> axis = V.Z <TAB> axis = axis.normalize() <TAB> s = math.sin(theta / 2.0) <TAB> c = math.cos(theta / 2.0) <TAB> return Q(axis._v[0] * s, axis._v[1] * s, axis._v[2] * s, c)","if axis in ( ""x"" , ""X"" ) :",169
"def log(self, request): <TAB> web_socket = WebSocketResponse() <TAB> await web_socket.prepare(request) <TAB> self.app[""websockets""].add(web_socket) <TAB> try: <TAB>  <TAB> async for msg in web_socket: <TAB>  <TAB>  <TAB> if msg.type == WSMsgType.TEXT: <MASK> await web_socket.close() <TAB>  <TAB>  <TAB> elif msg.type == WSMsgType.ERROR: <TAB>  <TAB>  <TAB>  <TAB> print( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""web socket connection closed with exception %s"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> % web_socket.exception() <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> finally: <TAB>  <TAB> self.app[""websockets""].remove(web_socket) <TAB> return web_socket","if msg . data == ""close"" :",187
"def test_loc_is_stochastic_parameter(self): <TAB> param = iap.Laplace(iap.Choice([-100, 100]), 1) <TAB> seen = [0, 0] <TAB> for _ in sm.xrange(1000): <TAB>  <TAB> samples = param.draw_samples((100,)) <TAB>  <TAB> exp = np.mean(samples) <MASK> seen[0] += 1 <TAB>  <TAB> elif 100 - 10 < exp < 100 + 10: <TAB>  <TAB>  <TAB> seen[1] += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert False <TAB> assert 500 - 100 < seen[0] < 500 + 100 <TAB> assert 500 - 100 < seen[1] < 500 + 100",if - 100 - 10 < exp < - 100 + 10 :,167
"def cli_setup(args=None): <TAB> """"""future api for setup env by cli"""""" <TAB> if not args: <MASK> print(""no cmdline args"") <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> args = sys.argv <TAB> print(args) <TAB> ap = argparse.ArgumentParser() <TAB> if ""--report"" in args: <TAB>  <TAB> from airtest.report.report import main as report_main <TAB>  <TAB> ap = report_parser(ap) <TAB>  <TAB> args = ap.parse_args(args) <TAB>  <TAB> report_main(args) <TAB>  <TAB> exit(0) <TAB> else: <TAB>  <TAB> ap = runner_parser(ap) <TAB>  <TAB> args = ap.parse_args(args) <TAB>  <TAB> setup_by_args(args) <TAB> return True",if len ( sys . argv ) < 2 :,187
"def validate_attributes(cls, cleaned_data): <TAB> errors = {} <TAB> for field in [""product_attributes"", ""variant_attributes""]: <TAB>  <TAB> attributes = cleaned_data.get(field) <TAB>  <TAB> if not attributes: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> not_valid_attributes = [ <TAB>  <TAB>  <TAB> graphene.Node.to_global_id(""Attribute"", attr.pk) <TAB>  <TAB>  <TAB> for attr in attributes <TAB>  <TAB>  <TAB> if attr.type != AttributeType.PRODUCT_TYPE <TAB>  <TAB> ] <MASK> errors[field] = ValidationError( <TAB>  <TAB>  <TAB>  <TAB> ""Only Product type attributes are allowed."", <TAB>  <TAB>  <TAB>  <TAB> code=ProductErrorCode.INVALID.value, <TAB>  <TAB>  <TAB>  <TAB> params={""attributes"": not_valid_attributes}, <TAB>  <TAB>  <TAB> ) <TAB> if errors: <TAB>  <TAB> raise ValidationError(errors)",if not_valid_attributes :,193
"def forward(self, x, activate=True, norm=True): <TAB> for layer in self.order: <TAB>  <TAB> if layer == ""conv"": <TAB>  <TAB>  <TAB> if self.with_explicit_padding: <TAB>  <TAB>  <TAB>  <TAB> x = self.padding_layer(x) <TAB>  <TAB>  <TAB> x = self.conv(x) <MASK> x = self.norm(x) <TAB>  <TAB> elif layer == ""act"" and activate and self.with_activation: <TAB>  <TAB>  <TAB> x = self.activate(x) <TAB> return x","elif layer == ""norm"" and norm and self . with_norm :",138
"def _FunctionDef(self, node): <TAB> _ScopeVisitor._FunctionDef(self, node) <TAB> if len(node.args.args) > 0: <TAB>  <TAB> first = node.args.args[0] <MASK> new_visitor = _ClassInitVisitor(self, first.id) <TAB>  <TAB>  <TAB> for child in ast.get_child_nodes(node): <TAB>  <TAB>  <TAB>  <TAB> ast.walk(child, new_visitor)","if isinstance ( first , ast . Name ) :",111
"def result(self): <TAB> """"""Gets the formatted string result."""""" <TAB> if self.__group.isChecked(): <TAB>  <TAB> if self.__moreThan.isChecked(): <TAB>  <TAB>  <TAB> return ""gt%d"" % self.__min.value() <MASK> return ""lt%d"" % self.__max.value() <TAB>  <TAB> if self.__range.isChecked(): <TAB>  <TAB>  <TAB> return ""%d-%d"" % (self.__min.value(), self.__max.value()) <TAB> return """"",if self . __lessThan . isChecked ( ) :,122
"def hash_of_file(path): <TAB> """"""Return the hash of a downloaded file."""""" <TAB> with open(path, ""rb"") as archive: <TAB>  <TAB> sha = sha256() <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> data = archive.read(2 ** 20) <MASK> break <TAB>  <TAB>  <TAB> sha.update(data) <TAB> return encoded_hash(sha)",if not data :,95
"def read_boolean(file: BinaryIO, count: int, checkall: bool = False) -> List[bool]: <TAB> if checkall: <TAB>  <TAB> all_defined = file.read(1) <MASK> return [True] * count <TAB> result = [] <TAB> b = 0 <TAB> mask = 0 <TAB> for i in range(count): <TAB>  <TAB> if mask == 0: <TAB>  <TAB>  <TAB> b = ord(file.read(1)) <TAB>  <TAB>  <TAB> mask = 0x80 <TAB>  <TAB> result.append(b & mask != 0) <TAB>  <TAB> mask >>= 1 <TAB> return result","if all_defined != unhexlify ( ""00"" ) :",146
"def start_prompt(self): <TAB> """"""Start the interpreter."""""" <TAB> logger.show(""Coconut Interpreter:"") <TAB> logger.show(""(type 'exit()' or press Ctrl-D to end)"") <TAB> self.start_running() <TAB> while self.running: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> code = self.get_input() <MASK> compiled = self.handle_input(code) <TAB>  <TAB>  <TAB>  <TAB> if compiled: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.execute(compiled, use_eval=None) <TAB>  <TAB> except KeyboardInterrupt: <TAB>  <TAB>  <TAB> printerr(""\nKeyboardInterrupt"")",if code :,142
"def _wrap_lineanchors(self, inner): <TAB> s = self.lineanchors <TAB> i = self.linenostart - 1  # subtract 1 since we have to increment i <TAB> # *before* yielding <TAB> for t, line in inner: <MASK> i += 1 <TAB>  <TAB>  <TAB> yield 1, '<a name=""%s-%d""></a>' % (s, i) + line <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield 0, line",if t :,109
"def __UpdateQueryHistory(self, query): <TAB> clone = datastore_pb.Query() <TAB> clone.CopyFrom(query) <TAB> clone.clear_hint() <TAB> clone.clear_limit() <TAB> clone.clear_offset() <TAB> clone.clear_count() <TAB> if clone in self.__query_history: <TAB>  <TAB> self.__query_history[clone] += 1 <TAB> else: <TAB>  <TAB> self.__query_history[clone] = 1 <MASK> self.__query_ci_history.add(datastore_index.CompositeIndexForQuery(clone))",if clone . app ( ) == self . _app_id :,145
"def call(self, trajectory: traj.Trajectory): <TAB> if not self._batch_size: <MASK> self._batch_size = 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert trajectory.step_type.ndim == 1 <TAB>  <TAB>  <TAB> self._batch_size = trajectory.step_type.shape[0] <TAB>  <TAB> self.reset() <TAB> if trajectory.step_type.ndim == 0: <TAB>  <TAB> trajectory = nest_utils.batch_nested_array(trajectory) <TAB> self._batched_call(trajectory)",if trajectory . step_type . ndim == 0 :,141
"def steps(self): <TAB> """""""""""" <TAB> for step_id in range(self.micro_batches): <TAB>  <TAB> cmds = [ <TAB>  <TAB>  <TAB> LoadMicroBatch(buffer_id=0), <TAB>  <TAB>  <TAB> ForwardPass(buffer_id=0), <TAB>  <TAB>  <TAB> BackwardPass(buffer_id=0), <TAB>  <TAB> ] <MASK> cmds.extend( <TAB>  <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ReduceGrads(), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> OptimizerStep(), <TAB>  <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> yield cmds",if step_id == self . micro_batches - 1 :,143
"def resolve_project(self, workspace, project_name): <TAB> if isinstance(project_name, (int, float)):  # project id <TAB>  <TAB> project_id = int(project_name) <TAB>  <TAB> self.log.debug(""Treating project name as ID: %s"", project_id) <TAB>  <TAB> project = workspace.projects(ident=project_id).first() <MASK> raise TaurusConfigError( <TAB>  <TAB>  <TAB>  <TAB> ""BlazeMeter project not found by ID: %s"" % project_id <TAB>  <TAB>  <TAB> ) <TAB> elif project_name: <TAB>  <TAB> project = workspace.projects(name=project_name).first() <TAB> else: <TAB>  <TAB> project = None <TAB> if not project: <TAB>  <TAB> project = self._create_project_or_use_default(workspace, project_name) <TAB> return project",if not project :,199
"def __reader(self, collector, source): <TAB> while True: <TAB>  <TAB> data = os.read(source.fileno(), 65536) <TAB>  <TAB> self.__lock.acquire() <TAB>  <TAB> collector.append(data) <TAB>  <TAB> self.__lock.release() <MASK> source.close() <TAB>  <TAB>  <TAB> break <TAB> return","if data == """" :",81
"def add(self, undoinfo, msg=None): <TAB> if not undoinfo: <TAB>  <TAB> return <TAB> if msg is not None: <TAB>  <TAB> if isinstance(undoinfo[0], str): <TAB>  <TAB>  <TAB> # replace message <TAB>  <TAB>  <TAB> undoinfo = (msg,) + undoinfo[1:] <MASK> undoinfo = (msg,) + undoinfo <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> undoinfo = (msg, undoinfo) <TAB>  <TAB> f = 1 <TAB> else: <TAB>  <TAB> f = int(isinstance(undoinfo[0], str)) <TAB> assert ( <TAB>  <TAB> isinstance(undoinfo, list) <TAB>  <TAB> or callable(undoinfo[f]) <TAB>  <TAB> or isinstance(undoinfo[f], list) <TAB> ) <TAB> self.undoList.append(undoinfo) <TAB> del self.redoList[:]","elif isinstance ( undoinfo , tuple ) :",198
"def get_history_data(self, guid, count=1): <TAB> history = {} <TAB> if count < 1: <TAB>  <TAB> return history <TAB> key = self._make_key(guid) <TAB> for i in range(0, self.db.llen(key)): <TAB>  <TAB> r = self.db.lindex(key, i) <TAB>  <TAB> c = msgpack.unpackb(r) <TAB>  <TAB> if c[""tries""] == 0 or c[""tries""] is None: <TAB>  <TAB>  <TAB> if c[""data""] not in history: <TAB>  <TAB>  <TAB>  <TAB> history[c[""data""]] = c[""timestamp""] <MASK> break <TAB> return history",if len ( history ) >= count :,161
"def __str__(self): <TAB> from sqlalchemy.sql import util <TAB> details = [SQLAlchemyError.__str__(self)] <TAB> if self.statement: <TAB>  <TAB> details.append(""[SQL: %r]"" % self.statement) <MASK> params_repr = util._repr_params(self.params, 10) <TAB>  <TAB>  <TAB> details.append(""[parameters: %r]"" % params_repr) <TAB> return "" "".join([""(%s)"" % det for det in self.detail] + details)",if self . params :,121
"def _consume_msg(self): <TAB> async for data in self._stream: <TAB>  <TAB> stream = data.get(""ev"") <MASK> await self._dispatch(data) <TAB>  <TAB> elif data.get(""status"") == ""disconnected"": <TAB>  <TAB>  <TAB> # Polygon returns this on an empty 'ev' id.. <TAB>  <TAB>  <TAB> data[""ev""] = ""status"" <TAB>  <TAB>  <TAB> await self._dispatch(data) <TAB>  <TAB>  <TAB> raise ConnectionResetError( <TAB>  <TAB>  <TAB>  <TAB> ""Polygon terminated connection: "" f'({data.get(""message"")})' <TAB>  <TAB>  <TAB> )",if stream :,135
"def nan2none(l): <TAB> for idx, val in enumerate(l): <TAB>  <TAB> if isinstance(val, Sequence): <TAB>  <TAB>  <TAB> l[idx] = nan2none(l[idx]) <MASK> l[idx] = None <TAB> return l",elif isnum ( val ) and math . isnan ( val ) :,76
"def _make_binary_stream(s, encoding): <TAB> try: <TAB>  <TAB> if _py3k: <TAB>  <TAB>  <TAB> if isinstance(s, str): <TAB>  <TAB>  <TAB>  <TAB> s = s.encode(encoding) <TAB>  <TAB> else: <MASK> s = s.encode(encoding) <TAB>  <TAB> from io import BytesIO <TAB>  <TAB> rv = BytesIO(s) <TAB> except ImportError: <TAB>  <TAB> rv = StringIO(s) <TAB> return rv",if type ( s ) is not str :,115
"def __set__(self, instance, value): <TAB> try: <TAB>  <TAB> value = int(value) <MASK> # max port number is 65535 <TAB>  <TAB>  <TAB> self.display_value = str(value) <TAB>  <TAB>  <TAB> self.value = value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise PocsuiteValidationException( <TAB>  <TAB>  <TAB>  <TAB> ""Invalid option. Port value should be between 0 and 65536."" <TAB>  <TAB>  <TAB> ) <TAB> except ValueError: <TAB>  <TAB> raise PocsuiteValidationException( <TAB>  <TAB>  <TAB> ""Invalid option. Cannot cast '{}' to integer."".format(value) <TAB>  <TAB> )",if 0 <= value <= 65535 :,140
"def addVaXref(self, va, parent=None): <TAB> if parent is None: <TAB>  <TAB> parent = self <TAB> xtova, ok = QInputDialog.getText(parent, ""Enter..."", ""Make Code Xref 0x%x -> "" % va) <TAB> if ok: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> val = self.vw.parseExpression(str(xtova)) <MASK> self.vw.addXref(va, val, REF_CODE) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.vw.vprint(""Invalid Expression: %s   (%s)"" % (xtova, val)) <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> self.vw.vprint(repr(e))",if self . vw . isValidPointer ( val ) :,191
"def ArrayBuffer(): <TAB> a = arguments[0] <TAB> if isinstance(a, PyJsNumber): <TAB>  <TAB> length = a.to_uint32() <MASK> raise MakeError(""RangeError"", ""Invalid array length"") <TAB>  <TAB> temp = Js(bytearray([0] * length)) <TAB>  <TAB> return temp <TAB> return Js(bytearray([0]))",if length != a . value :,91
"def _update_positions(nodes, line_offset, last_leaf): <TAB> for node in nodes: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> children = node.children <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB> # Is a leaf <TAB>  <TAB>  <TAB> node.line += line_offset <MASK> raise _PositionUpdatingFinished <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _update_positions(children, line_offset, last_leaf)",if node is last_leaf :,108
"def class_has_method(self, curr_node, the_text): <TAB> try: <TAB>  <TAB> class_node = self.containers[VAR_KIND_CLASS][-1] <TAB>  <TAB> for c in class_node.children: <MASK> return True <TAB> except: <TAB>  <TAB> pass <TAB> return False","if isinstance ( c , MethodNode ) and c . name == the_text :",94
"def _fm(map_id): <TAB> for i in range(num_key): <TAB>  <TAB> for j in range(num_value_per_key): <MASK> yield (i, j) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield ((map_id, i), j)",if dup_key :,77
"def _compileRules(rulesList, maxLength=4): <TAB> ruleChecking = collections.defaultdict(list) <TAB> for ruleIndex in range(len(rulesList)): <TAB>  <TAB> args = [] <TAB>  <TAB> if len(rulesList[ruleIndex]) == maxLength: <TAB>  <TAB>  <TAB> args = rulesList[ruleIndex][-1] <TAB>  <TAB> if maxLength == 4: <TAB>  <TAB>  <TAB> (shouldRunMethod, method, isCorrect) = rulesList[ruleIndex][0:3] <TAB>  <TAB>  <TAB> ruleChecking[shouldRunMethod].append((method, isCorrect, args)) <MASK> (shouldRunMethod, method) = rulesList[ruleIndex][0:2] <TAB>  <TAB>  <TAB> ruleChecking[shouldRunMethod].append((method, args)) <TAB> return ruleChecking",elif maxLength == 3 :,183
"def select(result): <TAB> for elem in result: <TAB>  <TAB> parent = elem.getparent() <TAB>  <TAB> if parent is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> # FIXME: what if the selector is ""*"" ? <TAB>  <TAB>  <TAB> elems = list(parent.iterchildren(elem.tag)) <MASK> yield elem <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB> pass",if elems [ index ] is elem :,101
"def get_kwarg_or_param(request, kwargs, key): <TAB> value = None <TAB> try: <TAB>  <TAB> value = kwargs[key] <TAB> except KeyError: <MASK> value = request.GET.get(key) <TAB>  <TAB> elif request.method == ""POST"": <TAB>  <TAB>  <TAB> value = request.POST.get(key) <TAB> return value","if request . method == ""GET"" :",93
"def __imul__(self, other): <TAB> if isinstance(other, str): <TAB>  <TAB> other = Matrix(other) <TAB> if isinstance(other, Matrix): <TAB>  <TAB> if self.start is not None: <TAB>  <TAB>  <TAB> self.start *= other <MASK> self.control1 *= other <TAB>  <TAB> if self.control2 is not None: <TAB>  <TAB>  <TAB> self.control2 *= other <TAB>  <TAB> if self.end is not None: <TAB>  <TAB>  <TAB> self.end *= other <TAB> return self",if self . control1 is not None :,125
"def _parse_date_fmt(): <TAB> fmt = get_format(""DATE_FORMAT"") <TAB> escaped = False <TAB> for char in fmt: <TAB>  <TAB> if escaped: <TAB>  <TAB>  <TAB> escaped = False <TAB>  <TAB> elif char == ""\\"": <TAB>  <TAB>  <TAB> escaped = True <MASK> yield ""year"" <TAB>  <TAB> elif char in ""bEFMmNn"": <TAB>  <TAB>  <TAB> yield ""month"" <TAB>  <TAB> elif char in ""dj"": <TAB>  <TAB>  <TAB> yield ""day""","elif char in ""Yy"" :",117
def filter_forms(forms): <TAB> result = [] <TAB> seen = set() <TAB> for form in forms: <MASK> if pos in self._lemma_pos_offset_map[form]: <TAB>  <TAB>  <TAB>  <TAB> if form not in seen: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> result.append(form) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> seen.add(form) <TAB> return result,if form in self . _lemma_pos_offset_map :,100
"def calculate(self): <TAB> """"""Enumerate processes by scanning for _EPROCESS."""""" <TAB> result = set() <TAB> psscan = self.session.plugins.psscan() <TAB> pslist = self.session.plugins.pslist() <TAB> for row in psscan.collect(): <TAB>  <TAB> physical_eprocess = row[""offset_p""] <MASK> eprocess = pslist.virtual_process_from_physical_offset(physical_eprocess) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> eprocess = physical_eprocess <TAB>  <TAB> if eprocess != None: <TAB>  <TAB>  <TAB> result.add(eprocess.obj_offset) <TAB> self.session.logging.debug(""Listed %s processes using PSScan"", len(result)) <TAB> return result",if physical_eprocess . obj_vm == self . session . physical_address_space :,195
"def _build_kwargs_string(cls, expectation): <TAB> kwargs = [] <TAB> for k, v in expectation[""kwargs""].items(): <MASK> # make the column a positional argument <TAB>  <TAB>  <TAB> kwargs.insert(0, ""{}='{}'"".format(k, v)) <TAB>  <TAB> elif isinstance(v, str): <TAB>  <TAB>  <TAB> # Put strings in quotes <TAB>  <TAB>  <TAB> kwargs.append(""{}='{}'"".format(k, v)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Pass other types as is <TAB>  <TAB>  <TAB> kwargs.append(""{}={}"".format(k, v)) <TAB> return "", "".join(kwargs)","if k == ""column"" :",143
"def prec3_expr(self, arg_type): <TAB> pass <TAB> self.prec4_expr(arg_type) <TAB> while True: <MASK> pass <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> self.match(POWER) <TAB>  <TAB>  <TAB> op = struct.pack(""B"", ptgPower) <TAB>  <TAB>  <TAB> self.prec4_expr(arg_type) <TAB>  <TAB>  <TAB> self.rpn += op <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break",if self . LA ( 1 ) == POWER :,121
"def evaluate(analysis, rule): <TAB> try: <TAB>  <TAB> if isinstance(rule, MetaRule): <TAB>  <TAB>  <TAB> result = _evaluate_meta_rule(analysis, rule) <TAB>  <TAB> elif isinstance(rule, SingleRule): <TAB>  <TAB>  <TAB> result = _evaluate_single_rule(analysis, rule) <MASK> result = _evaluate_sub_path_rule(analysis, rule) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""rule must be of one in types [SingleRule, MetaRule, SubPathRule]"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return result <TAB> except KeyError:  # expected behavior as long as this does not have all other plugins as dependency <TAB>  <TAB> return False","elif isinstance ( rule , SubPathRule ) :",171
"def create_log_file(d, logname): <TAB> logpath = d.getVar(""LOG_DIR"") <TAB> bb.utils.mkdirhier(logpath) <TAB> logfn, logsuffix = os.path.splitext(logname) <TAB> logfile = os.path.join( <TAB>  <TAB> logpath, ""%s.%s%s"" % (logfn, d.getVar(""DATETIME""), logsuffix) <TAB> ) <TAB> if not os.path.exists(logfile): <TAB>  <TAB> slogfile = os.path.join(logpath, logname) <MASK> os.remove(slogfile) <TAB>  <TAB> open(logfile, ""w+"").close() <TAB>  <TAB> os.symlink(logfile, slogfile) <TAB>  <TAB> d.setVar(""LOG_FILE"", logfile) <TAB> return logfile",if os . path . exists ( slogfile ) :,191
"def init_eventlog(self): <TAB> """"""Set up the event logging system."""""" <TAB> self.eventlog = EventLog(parent=self) <TAB> for dirname, _, files in os.walk(os.path.join(here, ""event-schemas"")): <TAB>  <TAB> for file in files: <MASK> continue <TAB>  <TAB>  <TAB> self.eventlog.register_schema_file(os.path.join(dirname, file))","if not file . endswith ( "".yaml"" ) :",109
"def resize(self, limit, force=False, ignore_errors=False, reset=False): <TAB> prev_limit = self._limit <TAB> if (self._dirty and 0 < limit < self._limit) and not ignore_errors: <MASK> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB> ""Can't shrink pool when in use: was={0} now={1}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._limit, limit <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> reset = True <TAB> self._limit = limit <TAB> if reset: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.force_close_all() <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> pass <TAB> self.setup() <TAB> if limit < prev_limit: <TAB>  <TAB> self._shrink_down(collect=limit > 0)",if not force :,189
"def accept_request(self, request): <TAB> if self.restriction_type == BaseViewRestriction.PASSWORD: <TAB>  <TAB> passed_restrictions = request.session.get( <TAB>  <TAB>  <TAB> self.passed_view_restrictions_session_key, [] <TAB>  <TAB> ) <TAB>  <TAB> if self.id not in passed_restrictions: <TAB>  <TAB>  <TAB> return False <TAB> elif self.restriction_type == BaseViewRestriction.LOGIN: <TAB>  <TAB> if not request.user.is_authenticated: <TAB>  <TAB>  <TAB> return False <TAB> elif self.restriction_type == BaseViewRestriction.GROUPS: <MASK> current_user_groups = request.user.groups.all() <TAB>  <TAB>  <TAB> if not any(group in current_user_groups for group in self.groups.all()): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return True",if not request . user . is_superuser :,187
"def getLatestXci(self, version=None): <TAB> highest = None <TAB> for nsp in self.getFiles(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if nsp.path.endswith("".xci""): <TAB>  <TAB>  <TAB>  <TAB> if version is not None and nsp.version == version: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return nsp <MASK> highest = nsp <TAB>  <TAB> except BaseException: <TAB>  <TAB>  <TAB> pass <TAB> return highest",if not highest or int ( nsp . version ) > int ( highest . version ) :,118
"def evaluate(self, x, y, z): <TAB> vertex = Vector((x, y, z)) <TAB> nearest, normal, idx, distance = self.bvh.find_nearest(vertex) <TAB> if self.use_normal: <TAB>  <TAB> if self.signed_normal: <TAB>  <TAB>  <TAB> sign = (v - nearest).dot(normal) <TAB>  <TAB>  <TAB> sign = copysign(1, sign) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sign = 1 <TAB>  <TAB> return sign * np.array(normal) <TAB> else: <TAB>  <TAB> dv = np.array(nearest - vertex) <MASK> norm = np.linalg.norm(dv) <TAB>  <TAB>  <TAB> len = self.falloff(norm) <TAB>  <TAB>  <TAB> dv = len * dv <TAB>  <TAB>  <TAB> return dv <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return dv",if self . falloff is not None :,200
"def to_py(self, value: _StrUnset) -> _StrUnsetNone: <TAB> self._basic_py_validation(value, str) <TAB> if isinstance(value, usertypes.Unset): <TAB>  <TAB> return value <TAB> elif not value: <TAB>  <TAB> return None <TAB> value = os.path.expandvars(value) <TAB> value = os.path.expanduser(value) <TAB> try: <TAB>  <TAB> if not os.path.isdir(value): <TAB>  <TAB>  <TAB> raise configexc.ValidationError(value, ""must be a valid directory!"") <MASK> raise configexc.ValidationError(value, ""must be an absolute path!"") <TAB> except UnicodeEncodeError as e: <TAB>  <TAB> raise configexc.ValidationError(value, e) <TAB> return value",if not os . path . isabs ( value ) :,181
"def validate_load_balancer_sku(namespace): <TAB> """"""Validates the load balancer sku string."""""" <TAB> if namespace.load_balancer_sku is not None: <MASK> return <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB> namespace.load_balancer_sku.lower() != ""basic"" <TAB>  <TAB>  <TAB> and namespace.load_balancer_sku.lower() != ""standard"" <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> raise CLIError(""--load-balancer-sku can only be standard or basic"")","if namespace . load_balancer_sku == """" :",121
"def _getLocalSpineType(self): <TAB> if self._spineType is not None: <TAB>  <TAB> return self._spineType <TAB> else: <TAB>  <TAB> for thisEvent in self.eventList: <TAB>  <TAB>  <TAB> m1 = re.match(r""\*\*(.*)"", thisEvent.contents) <MASK> self._spineType = m1.group(1) <TAB>  <TAB>  <TAB>  <TAB> return self._spineType <TAB>  <TAB> return None",if m1 :,111
"def set_selected_device(self): <TAB> current_devices = self.get_current_devices() <TAB> if self.device in current_devices.values(): <TAB>  <TAB> return <TAB> for device_name in current_devices.values(): <MASK> self.parent.py3.log(f""device {self.device} detected as {device_name}"") <TAB>  <TAB>  <TAB> self.device = device_name <TAB>  <TAB>  <TAB> break",if self . device in device_name :,110
"def write(self, buff): <TAB> if not self.handle: <TAB>  <TAB> raise TTransportException( <TAB>  <TAB>  <TAB> type=TTransportException.NOT_OPEN, message=""Transport not open"" <TAB>  <TAB> ) <TAB> sent = 0 <TAB> have = len(buff) <TAB> while sent < have: <TAB>  <TAB> plus = self.handle.send(buff) <MASK> raise TTransportException( <TAB>  <TAB>  <TAB>  <TAB> type=TTransportException.END_OF_FILE, message=""TSocket sent 0 bytes"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> sent += plus <TAB>  <TAB> buff = buff[plus:]",if plus == 0 :,143
"def get_named_key_value(self, rule, match, key_name): <TAB> # search the match for the key specified in the rule to get the value <TAB> if key_name in rule: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> key_value = lookup_es_key(match, rule[key_name]) <MASK> # Only do the unicode conversion if we actually found something) <TAB>  <TAB>  <TAB>  <TAB> # otherwise we might transform None --> 'None' <TAB>  <TAB>  <TAB>  <TAB> key_value = str(key_value) <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> # Some matches may not have the specified key <TAB>  <TAB>  <TAB> # use a special token for these <TAB>  <TAB>  <TAB> key_value = ""_missing"" <TAB> else: <TAB>  <TAB> key_value = None <TAB> return key_value",if key_value is not None :,191
"def __iter__(self): <TAB> protocol = self.protocol <TAB> source = write_source_from_arg(self.source) <TAB> with source.open(""wb"") as f: <TAB>  <TAB> it = iter(self.table) <TAB>  <TAB> hdr = next(it) <MASK> pickle.dump(hdr, f, protocol) <TAB>  <TAB> yield tuple(hdr) <TAB>  <TAB> for row in it: <TAB>  <TAB>  <TAB> pickle.dump(row, f, protocol) <TAB>  <TAB>  <TAB> yield tuple(row)",if self . write_header :,125
"def abs__file__(): <TAB> """"""Set all module' __file__ attribute to an absolute path"""""" <TAB> for m in sys.modules.values(): <MASK> continue  # don't mess with a PEP 302-supplied __file__ <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> m.__file__ = os.path.abspath(m.__file__) <TAB>  <TAB> except (AttributeError, OSError): <TAB>  <TAB>  <TAB> pass","if hasattr ( m , ""__loader__"" ) :",101
"def _run(self): <TAB> when_pressed = 0.0 <TAB> pressed = False <TAB> while not self._done.is_set(): <TAB>  <TAB> now = time.monotonic() <TAB>  <TAB> if now - when_pressed > self._debounce_time: <TAB>  <TAB>  <TAB> if GPIO.input(self._channel) == self._expected: <TAB>  <TAB>  <TAB>  <TAB> if not pressed: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pressed = True <TAB>  <TAB>  <TAB>  <TAB>  <TAB> when_pressed = now <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._trigger(self._pressed_queue, self._pressed_callback) <TAB>  <TAB>  <TAB> else: <MASK> pressed = False <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._trigger(self._released_queue, self._released_callback) <TAB>  <TAB> self._done.wait(0.05)",if pressed :,187
"def get_run_cmd(submission_dir): <TAB> """"""Get the language of a submission"""""" <TAB> with CD(submission_dir): <TAB>  <TAB> if os.path.exists(""run.sh""): <TAB>  <TAB>  <TAB> with open(""run.sh"") as f: <TAB>  <TAB>  <TAB>  <TAB> for line in f: <MASK> return line.rstrip(""\r\n"")","if line [ 0 ] != ""#"" :",98
"def client_read(self, path, **kwargs): <TAB> """"""Retrieve a value from a etcd key."""""" <TAB> try: <TAB>  <TAB> res = self.client.read( <TAB>  <TAB>  <TAB> path, <TAB>  <TAB>  <TAB> timeout=kwargs.get(""timeout"", DEFAULT_TIMEOUT), <TAB>  <TAB>  <TAB> recursive=kwargs.get(""recursive"") or kwargs.get(""all"", False), <TAB>  <TAB> ) <MASK> modified_indices = (res.modifiedIndex,) + tuple( <TAB>  <TAB>  <TAB>  <TAB> leaf.modifiedIndex for leaf in res.leaves <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return max(modified_indices) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return res.value <TAB> except EtcdKeyNotFound: <TAB>  <TAB> raise KeyNotFound(""The key %s was not found in etcd"" % path) <TAB> except TimeoutError as e: <TAB>  <TAB> raise e","if kwargs . get ( ""watch"" , False ) :",197
"def populate_wrapper(klass, wrapping): <TAB> for meth, how in klass._wrap_methods.items(): <MASK> continue <TAB>  <TAB> func = getattr(wrapping, meth) <TAB>  <TAB> wrapper = make_wrapper(func, how) <TAB>  <TAB> setattr(klass, meth, wrapper)","if not hasattr ( wrapping , meth ) :",76
"def _copy_files(self, files, src, dest, message=""""): <TAB> for filepath in files: <TAB>  <TAB> srcpath = os.path.join(src, filepath) <TAB>  <TAB> destpath = os.path.join(dest, filepath) <TAB>  <TAB> if message: <TAB>  <TAB>  <TAB> print(""{}: {}"".format(message, destpath)) <TAB>  <TAB> if os.path.exists(srcpath): <TAB>  <TAB>  <TAB> destdir = os.path.dirname(destpath) <TAB>  <TAB>  <TAB> if not os.path.isdir(destdir): <TAB>  <TAB>  <TAB>  <TAB> os.makedirs(destdir) <TAB>  <TAB>  <TAB> shutil.copy(srcpath, destpath) <MASK> os.remove(destpath)",elif os . path . exists ( destpath ) :,167
"def scan_iter(self, match=None, count=None): <TAB> nodes = await self.cluster_nodes() <TAB> for node in nodes: <TAB>  <TAB> if ""master"" in node[""flags""]: <TAB>  <TAB>  <TAB> cursor = ""0"" <TAB>  <TAB>  <TAB> while cursor != 0: <TAB>  <TAB>  <TAB>  <TAB> pieces = [cursor] <TAB>  <TAB>  <TAB>  <TAB> if match is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pieces.extend([""MATCH"", match]) <MASK> pieces.extend([""COUNT"", count]) <TAB>  <TAB>  <TAB>  <TAB> response = await self.execute_command_on_nodes([node], ""SCAN"", *pieces) <TAB>  <TAB>  <TAB>  <TAB> cursor, data = list(response.values())[0] <TAB>  <TAB>  <TAB>  <TAB> for item in data: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield item",if count is not None :,185
"def restart(cls, request, server_name): <TAB> with cls._servername_to_shell_server_lock: <MASK> servr = cls._servername_to_shell_server[server_name] <TAB>  <TAB>  <TAB> servr.restart()",if server_name in cls . _servername_to_shell_server :,75
"def human_waiting_on(self): <TAB> if self.waiting_on is None: <TAB>  <TAB> return ""N/A"" <TAB> things = [] <TAB> for cluster, queue in self.waiting_on.items(): <TAB>  <TAB> queue_length = len(queue) <MASK> continue <TAB>  <TAB> elif queue_length == 1: <TAB>  <TAB>  <TAB> things.append(f""`{cluster}`: `{queue[0].get_instance()}`"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> things.append(f""`{cluster}`: {len(queue)} instances"") <TAB> return "", "".join(things)",if queue_length == 0 :,148
"def psea(pname): <TAB> """"""Parse PSEA output file."""""" <TAB> fname = run_psea(pname) <TAB> start = 0 <TAB> ss = """" <TAB> with open(fname) as fp: <TAB>  <TAB> for l in fp: <TAB>  <TAB>  <TAB> if l[0:6] == "">p-sea"": <TAB>  <TAB>  <TAB>  <TAB> start = 1 <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB>  <TAB> if l[0] == ""\n"": <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> ss = ss + l[0:-1] <TAB> return ss",if not start :,142
"def encrypt_system_info_ssh_keys(ssh_info): <TAB> for idx, user in enumerate(ssh_info): <TAB>  <TAB> for field in [""public_key"", ""private_key"", ""known_hosts""]: <MASK> ssh_info[idx][field] = encryptor.enc(ssh_info[idx][field])",if ssh_info [ idx ] [ field ] :,90
"def get_shape(shape): <TAB> """"""Convert the shape to correct dtype and vars."""""" <TAB> ret = [] <TAB> for dim in shape: <TAB>  <TAB> if isinstance(dim, tvm.tir.IntImm): <TAB>  <TAB>  <TAB> if libinfo()[""INDEX_DEFAULT_I64""] == ""ON"": <TAB>  <TAB>  <TAB>  <TAB> ret.append(dim) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> val = int(dim) <TAB>  <TAB>  <TAB>  <TAB> assert val <= np.iinfo(np.int32).max <TAB>  <TAB>  <TAB>  <TAB> ret.append(tvm.tir.IntImm(""int32"", val)) <MASK> ret.append(te.var(""any_dim"", ""int32"")) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret.append(dim) <TAB> return ret","elif isinstance ( dim , tvm . tir . Any ) :",194
"def unpack(sources): <TAB> temp_dir = tempfile.mkdtemp(""-scratchdir"", ""unpacker-"") <TAB> for package, content in sources.items(): <TAB>  <TAB> filepath = package.split(""/"") <TAB>  <TAB> dirpath = os.sep.join(filepath[:-1]) <TAB>  <TAB> packagedir = os.path.join(temp_dir, dirpath) <MASK> os.makedirs(packagedir) <TAB>  <TAB> mod = open(os.path.join(packagedir, filepath[-1]), ""wb"") <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> mod.write(base64.b64decode(content)) <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> mod.close() <TAB> return temp_dir",if not os . path . isdir ( packagedir ) :,165
"def set_torrent_path(self, torrent_id, path): <TAB> try: <TAB>  <TAB> if not self.connect(): <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> self.client.core.set_torrent_move_completed_path(torrent_id, path).get() <TAB>  <TAB> self.client.core.set_torrent_move_completed(torrent_id, 1).get() <TAB> except Exception: <TAB>  <TAB> return False <TAB> finally: <MASK> self.disconnect() <TAB> return True",if self . client :,123
"def _get_specs(self, link, source, target): <TAB> for src_spec, code in link.code.items(): <TAB>  <TAB> src_specs = src_spec.split(""."") <TAB>  <TAB> if src_spec.startswith(""event:""): <TAB>  <TAB>  <TAB> src_spec = (None, src_spec) <MASK> src_spec = (""."".join(src_specs[:-1]), src_specs[-1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> src_prop = src_specs[0] <TAB>  <TAB>  <TAB> if isinstance(source, Reactive): <TAB>  <TAB>  <TAB>  <TAB> src_prop = source._rename.get(src_prop, src_prop) <TAB>  <TAB>  <TAB> src_spec = (None, src_prop) <TAB> return [(src_spec, (None, None), code)]",elif len ( src_specs ) > 1 :,190
"def deserialize(self, meth, content_type, body): <TAB> meth_deserializers = getattr(meth, ""wsgi_deserializers"", {}) <TAB> try: <TAB>  <TAB> mtype = _MEDIA_TYPE_MAP.get(content_type, content_type) <MASK> deserializer = meth_deserializers[mtype] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> deserializer = self.default_deserializers[mtype] <TAB> except (KeyError, TypeError): <TAB>  <TAB> raise exception.InvalidContentType(content_type=content_type) <TAB> return deserializer().deserialize(body)",if mtype in meth_deserializers :,139
"def object_inspect(self, oname, detail_level=0): <TAB> """"""Get object info about oname"""""" <TAB> with self.builtin_trap: <TAB>  <TAB> info = self._object_find(oname) <MASK> return self.inspector.info( <TAB>  <TAB>  <TAB>  <TAB> info.obj, oname, info=info, detail_level=detail_level <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return oinspect.object_info(name=oname, found=False)",if info . found :,122
"def wrapper(*args, **kargs): <TAB> for key, value in vkargs.items(): <MASK> abort(403, ""Missing parameter: %s"" % key) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> kargs[key] = value(kargs[key]) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> abort(403, ""Wrong parameter format for: %s"" % key) <TAB> return func(*args, **kargs)",if key not in kargs :,105
"def _append_fragment(self, ctx, frag_content): <TAB> try: <TAB>  <TAB> ctx[""dest_stream""].write(frag_content) <TAB>  <TAB> ctx[""dest_stream""].flush() <TAB> finally: <TAB>  <TAB> if self.__do_ytdl_file(ctx): <TAB>  <TAB>  <TAB> self._write_ytdl_file(ctx) <MASK> os.remove(encodeFilename(ctx[""fragment_filename_sanitized""])) <TAB>  <TAB> del ctx[""fragment_filename_sanitized""]","if not self . params . get ( ""keep_fragments"" , False ) :",128
"def override_args_required_option(argument_table, args, session, **kwargs): <TAB> # This function overrides the 'required' property of an argument <TAB> # if a value corresponding to that argument is present in the config <TAB> # file <TAB> # We don't want to override when user is viewing the help so that we <TAB> # can show the required options correctly in the help <TAB> need_to_override = False if len(args) == 1 and args[0] == ""help"" else True <TAB> if need_to_override: <TAB>  <TAB> parsed_configs = configutils.get_configs(session) <TAB>  <TAB> for arg_name in argument_table.keys(): <MASK> argument_table[arg_name].required = False","if arg_name . replace ( ""-"" , ""_"" ) in parsed_configs :",183
"def _count(self, element, count=True): <TAB> if not isinstance(element, six.string_types): <TAB>  <TAB> if self == element: <TAB>  <TAB>  <TAB> return 1 <TAB> i = 0 <TAB> for child in self.children: <TAB>  <TAB> # child is text content and element is also text content, then <TAB>  <TAB> # make a simple ""text"" in ""text"" <TAB>  <TAB> if isinstance(child, six.string_types): <TAB>  <TAB>  <TAB> if isinstance(element, six.string_types): <TAB>  <TAB>  <TAB>  <TAB> if count: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> i += child.count(element) <MASK> return 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> i += child._count(element, count=count) <TAB>  <TAB>  <TAB> if not count and i: <TAB>  <TAB>  <TAB>  <TAB> return i <TAB> return i",elif element in child :,196
"def teardown_class(cls): <TAB> collections = cls.discovery.list_collections(cls.environment_id).get_result()[ <TAB>  <TAB> ""collections"" <TAB> ] <TAB> for collection in collections: <MASK> print(""Deleting the temporary collection"") <TAB>  <TAB>  <TAB> cls.discovery.delete_collection(cls.environment_id, cls.collection_id) <TAB>  <TAB>  <TAB> break","if collection [ ""name"" ] == cls . collection_name :",101
"def _shares_in_results(data): <TAB> shares_in_device, shares_in_subdevice = False, False <TAB> for plugin_name, plugin_result in data.iteritems(): <TAB>  <TAB> if plugin_result[""status""] == ""error"": <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> if ""disk_shares"" in plugin_result[""device""]: <TAB>  <TAB>  <TAB> shares_in_device = True <TAB>  <TAB> for subdevice in plugin_result[""device""].get(""subdevices"", []): <TAB>  <TAB>  <TAB> if ""disk_shares"" in subdevice: <TAB>  <TAB>  <TAB>  <TAB> shares_in_subdevice = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return shares_in_device, shares_in_subdevice","if ""device"" not in plugin_result :",175
"def accept_request(self, request): <TAB> if self.restriction_type == BaseViewRestriction.PASSWORD: <TAB>  <TAB> passed_restrictions = request.session.get( <TAB>  <TAB>  <TAB> self.passed_view_restrictions_session_key, [] <TAB>  <TAB> ) <MASK> return False <TAB> elif self.restriction_type == BaseViewRestriction.LOGIN: <TAB>  <TAB> if not request.user.is_authenticated: <TAB>  <TAB>  <TAB> return False <TAB> elif self.restriction_type == BaseViewRestriction.GROUPS: <TAB>  <TAB> if not request.user.is_superuser: <TAB>  <TAB>  <TAB> current_user_groups = request.user.groups.all() <TAB>  <TAB>  <TAB> if not any(group in current_user_groups for group in self.groups.all()): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return True",if self . id not in passed_restrictions :,187
"def __setitem__(self, index, item): <TAB> try: <TAB>  <TAB> start, stop, step = index.start, index.stop, index.step <TAB> except AttributeError: <TAB>  <TAB> index = operator.index(index) <TAB> else: <MASK> self.lists[0][index] = item <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tmp = list(self) <TAB>  <TAB>  <TAB> tmp[index] = item <TAB>  <TAB>  <TAB> self.lists[:] = [tmp] <TAB>  <TAB> self._balance_list(0) <TAB>  <TAB> return <TAB> list_idx, rel_idx = self._translate_index(index) <TAB> if list_idx is None: <TAB>  <TAB> raise IndexError() <TAB> self.lists[list_idx][rel_idx] = item",if len ( self . lists ) == 1 :,183
"def random_permutation_equality_groups(n_groups, n_perms_per_group, n_items, prob): <TAB> fingerprints = set() <TAB> for _ in range(n_groups): <TAB>  <TAB> perms = random_equal_permutations(n_perms_per_group, n_items, prob) <TAB>  <TAB> perm = perms[0] <TAB>  <TAB> fingerprint = tuple(perm.get(i, i) for i in range(n_items)) <MASK> yield perms <TAB>  <TAB>  <TAB> fingerprints.add(fingerprint)",if fingerprint not in fingerprints :,128
"def get_proper_pip():  # no cov <TAB> if not venv_active(): <TAB>  <TAB> default_pip = os.environ.get(""_DEFAULT_PIP_"", None) <MASK> return default_pip <TAB>  <TAB> elif not ON_WINDOWS: <TAB>  <TAB>  <TAB> return ""pip3"" <TAB> return ""pip""",if default_pip :,79
"def close(self, checkcount=False): <TAB> self.mutex.acquire() <TAB> try: <TAB>  <TAB> if checkcount: <TAB>  <TAB>  <TAB> self.openers -= 1 <MASK> self.do_close() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if self.openers > 0: <TAB>  <TAB>  <TAB>  <TAB> self.do_close() <TAB>  <TAB>  <TAB> self.openers = 0 <TAB> finally: <TAB>  <TAB> self.mutex.release()",if self . openers == 0 :,116
"def _lxml_default_loader(href, parse, encoding=None, parser=None): <TAB> if parse == ""xml"": <TAB>  <TAB> data = etree.parse(href, parser).getroot() <TAB> else: <MASK> f = urlopen(href) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> f = open(href, ""rb"") <TAB>  <TAB> data = f.read() <TAB>  <TAB> f.close() <TAB>  <TAB> if not encoding: <TAB>  <TAB>  <TAB> encoding = ""utf-8"" <TAB>  <TAB> data = data.decode(encoding) <TAB> return data","if ""://"" in href :",133
"def Save(self): <TAB> # Save the AUI perspectives if PersistenceManager allows it <TAB> eventHandler = self._window.GetEventHandler() <TAB> isAGWAui = isinstance(eventHandler, AUI.AuiManager) <TAB> if not isAGWAui: <TAB>  <TAB> return True <TAB> if self._manager.GetManagerStyle() & PM_SAVE_RESTORE_AUI_PERSPECTIVES: <TAB>  <TAB> # Allowed to save and restore perspectives <TAB>  <TAB> perspective = eventHandler.SavePerspective() <MASK> name = PERSIST_AGW_AUI_PERSPECTIVE <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = PERSIST_AUI_PERSPECTIVE <TAB>  <TAB> self._pObject.SaveValue(name, perspective) <TAB> return True",if isAGWAui :,186
"def get_arg_list_scalar_arg_dtypes(arg_types): <TAB> result = [] <TAB> for arg_type in arg_types: <TAB>  <TAB> if isinstance(arg_type, ScalarArg): <TAB>  <TAB>  <TAB> result.append(arg_type.dtype) <TAB>  <TAB> elif isinstance(arg_type, VectorArg): <TAB>  <TAB>  <TAB> result.append(None) <MASK> result.append(np.int64) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise RuntimeError(""arg type not understood: %s"" % type(arg_type)) <TAB> return result",if arg_type . with_offset :,142
"def perform_secure_deletion_of_temporary_files(self): <TAB> # Delete the outdated temp files if older than 1 day <TAB> for f in os.listdir(self.state.settings.tmp_path): <TAB>  <TAB> path = os.path.join(self.state.settings.tmp_path, f) <TAB>  <TAB> timestamp = datetime.fromtimestamp(os.path.getmtime(path)) <MASK> overwrite_and_remove(path)","if is_expired ( timestamp , days = 1 ) :",114
"def set_torrent_ratio(self, torrent_ids, ratio): <TAB> try: <MASK> return False <TAB>  <TAB> self.client.core.set_torrent_stop_at_ratio(torrent_ids, True).get() <TAB>  <TAB> self.client.core.set_torrent_stop_ratio(torrent_ids, ratio).get() <TAB> except Exception as err: <TAB>  <TAB> return False <TAB> finally: <TAB>  <TAB> if self.client: <TAB>  <TAB>  <TAB> self.disconnect() <TAB> return True",if not self . connect ( ) :,125
"def value_to_db_datetime(self, value): <TAB> if value is None: <TAB>  <TAB> return None <TAB> # MySQL doesn't support tz-aware datetimes <TAB> if timezone.is_aware(value): <MASK> value = value.astimezone(timezone.utc).replace(tzinfo=None) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""MySQL backend does not support timezone-aware datetimes when USE_TZ is False."" <TAB>  <TAB>  <TAB> ) <TAB> # MySQL doesn't support microseconds <TAB> return six.text_type(value.replace(microsecond=0))",if settings . USE_TZ :,145
"def remote_run_capture_all(login, cmd, log=None): <TAB> """"""Run the remote command and return the (retval, stdout, stderr) result."""""" <TAB> if sys.platform == ""win32"": <MASK> login = ""%s@%s"" % (getpass.getuser(), login) <TAB>  <TAB> cmd = 'plink -A -batch %s ""%s""' % (login, cmd) <TAB> else: <TAB>  <TAB> cmd = 'ssh -A -o BatchMode=yes %s ""%s""' % (login, cmd) <TAB> __run_log(logstream, ""running '%s'"", cmd) <TAB> p = subprocess.Popen(argv, stdout=subprocess.PIPE, stderr=subprocess.PIPE) <TAB> stdout, stderr = p.communicate() <TAB> status = p.returncode <TAB> return status, stdout, stderr","if ""@"" not in login :",193
"def parseLeftHandSideExpressionAllowCall(): <TAB> marker = None <TAB> expr = None <TAB> args = None <TAB> property = None <TAB> marker = createLocationMarker() <TAB> expr = parseNewExpression() if matchKeyword(""new"") else parsePrimaryExpression() <TAB> while (match(""."") or match(""["")) or match(""(""): <MASK> args = parseArguments() <TAB>  <TAB>  <TAB> expr = delegate.createCallExpression(expr, args) <TAB>  <TAB> elif match(""[""): <TAB>  <TAB>  <TAB> property = parseComputedMember() <TAB>  <TAB>  <TAB> expr = delegate.createMemberExpression(""["", expr, property) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> property = parseNonComputedMember() <TAB>  <TAB>  <TAB> expr = delegate.createMemberExpression(""."", expr, property) <TAB>  <TAB> if marker: <TAB>  <TAB>  <TAB> marker.end() <TAB>  <TAB>  <TAB> marker.apply(expr) <TAB> return expr","if match ( ""("" ) :",193
"def getImageId(self, stuff): <TAB> if not isinstance(stuff, Module): <TAB>  <TAB> return -1 <TAB> if stuff.charge is None: <TAB>  <TAB> return -1 <TAB> else: <TAB>  <TAB> iconFile = stuff.charge.iconID if stuff.charge.iconID else """" <MASK> return self.fittingView.imageList.GetImageIndex(iconFile, ""icons"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return -1",if iconFile :,108
"def instance_reader(): <TAB> for epoch_index in range(epoch): <TAB>  <TAB> if shuffle: <TAB>  <TAB>  <TAB> if shuffle_seed is not None: <TAB>  <TAB>  <TAB>  <TAB> np.random.seed(shuffle_seed) <TAB>  <TAB>  <TAB> np.random.shuffle(examples) <MASK> self.current_train_epoch = epoch_index <TAB>  <TAB> for (index, example) in enumerate(examples): <TAB>  <TAB>  <TAB> if phase == ""train"": <TAB>  <TAB>  <TAB>  <TAB> self.current_train_example = index + 1 <TAB>  <TAB>  <TAB> feature = self.convert_example( <TAB>  <TAB>  <TAB>  <TAB> index, example, self.get_labels(), self.max_seq_len, self.tokenizer <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> instance = self.generate_instance(feature) <TAB>  <TAB>  <TAB> yield instance","if phase == ""train"" :",189
"def i2h(self, pkt, x): <TAB> if x is not None: <MASK> warning(""Fixed3_6: Internal value too negative: %d"" % x) <TAB>  <TAB>  <TAB> x = 0 <TAB>  <TAB> elif x > 999999999: <TAB>  <TAB>  <TAB> warning(""Fixed3_6: Internal value too positive: %d"" % x) <TAB>  <TAB>  <TAB> x = 999999999 <TAB>  <TAB> x = x * 1e-6 <TAB> return x",if x < 0 :,111
"def _is_section_header(self) -> bool: <TAB> section, underline = self._line_iter.peek(2) <TAB> section = section.lower() <TAB> if section in self._sections and isinstance(underline, str): <TAB>  <TAB> return bool(_numpy_section_regex.match(underline)) <TAB> elif self._directive_sections: <MASK> for directive_section in self._directive_sections: <TAB>  <TAB>  <TAB>  <TAB> if section.startswith(directive_section): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if _directive_regex . match ( section ) :,132
"def _parse_date_fmt(): <TAB> fmt = get_format(""DATE_FORMAT"") <TAB> escaped = False <TAB> for char in fmt: <TAB>  <TAB> if escaped: <TAB>  <TAB>  <TAB> escaped = False <TAB>  <TAB> elif char == ""\\"": <TAB>  <TAB>  <TAB> escaped = True <TAB>  <TAB> elif char in ""Yy"": <TAB>  <TAB>  <TAB> yield ""year"" <TAB>  <TAB> elif char in ""bEFMmNn"": <TAB>  <TAB>  <TAB> yield ""month"" <MASK> yield ""day""","elif char in ""dj"" :",117
"def _wait_port_open(port, max_wait=60): <TAB> print(f""Waiting for port {port}"") <TAB> start = time.time() <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> socket.create_connection((""localhost"", port), timeout=1) <TAB>  <TAB> except OSError: <MASK> raise <TAB>  <TAB>  <TAB> time.sleep(1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return",if time . time ( ) - start > max_wait :,113
"def _list(self): <TAB> data_sources = self.mkt_contract.functions.getAllProviders().call() <TAB> data = [] <TAB> for index, data_source in enumerate(data_sources): <TAB>  <TAB> if index > 0: <MASK> data.append(dict(dataset=self.to_text(data_source))) <TAB> return pd.DataFrame(data)","if ""test"" not in Web3 . toText ( data_source ) . lower ( ) :",111
"def log_start(self, prefix, msg): <TAB> with self._log_lock: <TAB>  <TAB> if self._last_log_prefix != prefix: <MASK> self._log_file.write(""\n"") <TAB>  <TAB>  <TAB> self._log_file.write(prefix) <TAB>  <TAB> self._log_file.write(msg) <TAB>  <TAB> self._last_log_prefix = prefix",if self . _last_log_prefix is not None :,105
"def _split_string_to_tokens(text): <TAB> """"""Splits text to a list of string tokens."""""" <TAB> if not text: <TAB>  <TAB> return [] <TAB> ret = [] <TAB> token_start = 0 <TAB> # Classify each character in the input string <TAB> is_alnum = [c in _ALPHANUMERIC_CHAR_SET for c in text] <TAB> for pos in xrange(1, len(text)): <TAB>  <TAB> if is_alnum[pos] != is_alnum[pos - 1]: <TAB>  <TAB>  <TAB> token = text[token_start:pos] <MASK> ret.append(token) <TAB>  <TAB>  <TAB> token_start = pos <TAB> final_token = text[token_start:] <TAB> ret.append(final_token) <TAB> return ret","if token != u"" "" or token_start == 0 :",191
"def _install_groups(self, grp_specs): <TAB> try: <TAB>  <TAB> self.base.env_group_install( <TAB>  <TAB>  <TAB> grp_specs, <TAB>  <TAB>  <TAB> tuple(self.base.conf.group_package_types), <TAB>  <TAB>  <TAB> strict=self.base.conf.strict, <TAB>  <TAB> ) <TAB> except dnf.exceptions.Error: <MASK> raise",if self . base . conf . strict :,100
def _idx2token(idxs): <TAB> for idx in idxs: <TAB>  <TAB> if idx < self.tgt_vocab_size: <TAB>  <TAB>  <TAB> token = self.tgt_vocab([[idx]])[0][0] <MASK> break <TAB>  <TAB>  <TAB> yield token <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield self.kb_keys[idx - self.tgt_vocab_size],if token == self . eos_token :,99
"def increment(s): <TAB> if not s: <TAB>  <TAB> return ""1"" <TAB> for sequence in string.digits, string.lowercase, string.uppercase: <TAB>  <TAB> lastc = s[-1] <TAB>  <TAB> if lastc in sequence: <TAB>  <TAB>  <TAB> i = sequence.index(lastc) + 1 <TAB>  <TAB>  <TAB> if i >= len(sequence): <MASK> s = sequence[0] * 2 <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if s == ""00"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> s = ""10"" <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> s = increment(s[:-1]) + sequence[0] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> s = s[:-1] + sequence[i] <TAB>  <TAB>  <TAB> return s <TAB> return s  # Don't increment",if len ( s ) == 1 :,196
"def main(): <TAB> import sys, getopt <TAB> try: <TAB>  <TAB> opts, args = getopt.getopt(sys.argv[1:], ""ho:"", [""help"", ""output=""]) <TAB> except getopt.GetoptError as err: <TAB>  <TAB> usage() <TAB>  <TAB> sys.exit(1) <TAB> output = None <TAB> for o, a in opts: <TAB>  <TAB> if o in (""-h"", ""--help""): <TAB>  <TAB>  <TAB> usage() <TAB>  <TAB>  <TAB> sys.exit() <MASK> output = a <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> usage() <TAB>  <TAB>  <TAB> sys.exit(1) <TAB> if not args: <TAB>  <TAB> usage() <TAB>  <TAB> sys.exit(1) <TAB> concat_flv(args, output)","elif o in ( ""-o"" , ""--output"" ) :",175
def binaryFindInDocument(): <TAB> hi = len(self.headings) <TAB> lo = 0 <TAB> while lo < hi: <TAB>  <TAB> mid = (lo + hi) // 2 <TAB>  <TAB> h = self.headings[mid] <MASK> lo = mid + 1 <TAB>  <TAB> elif h.start > position: <TAB>  <TAB>  <TAB> hi = mid <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return binaryFindHeading(h),if h . end_of_last_child < position :,110
"def on_key_press(self, *events): <TAB> # The JS editor has already** handled the key! <TAB> for ev in events: <MASK> ivar = ""minibufferWidget"" if self.name == ""minibuffer"" else self.name <TAB>  <TAB>  <TAB> self.root.do_key(ev, ivar)",if self . should_be_leo_key ( ev ) :,91
"def _make_dataset(data_dir): <TAB> data_dir = os.path.expanduser(data_dir) <TAB> if not os.path.isdir(data_dir): <TAB>  <TAB> raise (""{} should be a dir"".format(data_dir)) <TAB> images = [] <TAB> for root, _, fnames in sorted(os.walk(data_dir, followlinks=True)): <TAB>  <TAB> for fname in sorted(fnames): <TAB>  <TAB>  <TAB> file_path = os.path.join(root, fname) <MASK> images.append(file_path) <TAB> return images",if _is_valid_file ( file_path ) :,146
"def release(provider, connection, cache=None): <TAB> if cache is not None: <TAB>  <TAB> db_session = cache.db_session <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> cursor = connection.cursor() <TAB>  <TAB>  <TAB>  <TAB> sql = ""SET foreign_key_checks = 1"" <TAB>  <TAB>  <TAB>  <TAB> if core.local.debug: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> log_orm(sql) <TAB>  <TAB>  <TAB>  <TAB> cursor.execute(sql) <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> provider.pool.drop(connection) <TAB>  <TAB>  <TAB>  <TAB> raise <TAB> DBAPIProvider.release(provider, connection, cache)",if db_session is not None and db_session . ddl and cache . saved_fk_state :,164
"def get_pfunctions(self): <TAB> p_functions = [] <TAB> for name, item in self.pdict.items(): <TAB>  <TAB> if name[:2] != ""p_"": <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> if isinstance(item, (types.FunctionType, types.MethodType)): <TAB>  <TAB>  <TAB> line = func_code(item).co_firstlineno <TAB>  <TAB>  <TAB> file = func_code(item).co_filename <TAB>  <TAB>  <TAB> p_functions.append((line, file, name, item.__doc__)) <TAB> # Sort all of the actions by line number <TAB> p_functions.sort() <TAB> self.pfuncs = p_functions","if name == ""p_error"" :",158
"def get_output_sizes(self): <TAB> sizes = [] <TAB> output_paths = self.get_output_fnames() <TAB> for outfile in [unicodify(o) for o in output_paths]: <MASK> sizes.append((outfile, os.stat(outfile).st_size)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sizes.append((outfile, 0)) <TAB> return sizes",if os . path . exists ( outfile ) :,100
"def normalize_crlf(tree): <TAB> for elem in tree.getiterator(): <MASK> elem.text = elem.text.replace(""\r\n"", ""\n"") <TAB>  <TAB> if elem.tail: <TAB>  <TAB>  <TAB> elem.tail = elem.tail.replace(""\r\n"", ""\n"")",if elem . text :,76
"def visit_decorator(self, o: Decorator) -> None: <TAB> if self.is_private_name(o.func.name, o.func.fullname): <TAB>  <TAB> return <TAB> is_abstract = False <TAB> for decorator in o.original_decorators: <MASK> if self.process_name_expr_decorator(decorator, o): <TAB>  <TAB>  <TAB>  <TAB> is_abstract = True <TAB>  <TAB> elif isinstance(decorator, MemberExpr): <TAB>  <TAB>  <TAB> if self.process_member_expr_decorator(decorator, o): <TAB>  <TAB>  <TAB>  <TAB> is_abstract = True <TAB> self.visit_func_def(o.func, is_abstract=is_abstract)","if isinstance ( decorator , NameExpr ) :",160
"def formatweekday(self, day, width): <TAB> with TimeEncoding(self.locale) as encoding: <MASK> names = day_name <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> names = day_abbr <TAB>  <TAB> name = names[day] <TAB>  <TAB> if encoding is not None: <TAB>  <TAB>  <TAB> name = name.decode(encoding) <TAB>  <TAB> return name[:width].center(width)",if width >= 9 :,97
"def autocommitter(): <TAB> while True: <TAB>  <TAB> try: <MASK> break <TAB>  <TAB>  <TAB> if self._auto_commit_enable: <TAB>  <TAB>  <TAB>  <TAB> self._auto_commit() <TAB>  <TAB>  <TAB> self._cluster.handler.sleep(self._auto_commit_interval_ms / 1000) <TAB>  <TAB> except ReferenceError: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> # surface all exceptions to the main thread <TAB>  <TAB>  <TAB> self._worker_exception = sys.exc_info() <TAB>  <TAB>  <TAB> break <TAB> log.debug(""Autocommitter thread exiting"")",if not self . _running :,141
"def pseudo_raw_input(self, prompt): <TAB> """"""copied from cmd's cmdloop; like raw_input, but accounts for changed stdin, stdout"""""" <TAB> if self.use_rawinput: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> line = raw_input(prompt) <TAB>  <TAB> except EOFError: <TAB>  <TAB>  <TAB> line = ""EOF"" <TAB> else: <TAB>  <TAB> self.stdout.write(prompt) <TAB>  <TAB> self.stdout.flush() <TAB>  <TAB> line = self.stdin.readline() <TAB>  <TAB> if not len(line): <TAB>  <TAB>  <TAB> line = ""EOF"" <TAB>  <TAB> else: <MASK> # this was always true in Cmd <TAB>  <TAB>  <TAB>  <TAB> line = line[:-1] <TAB> return line","if line [ - 1 ] == ""\n"" :",172
"def get_suggestion(self, suggestion): <TAB> if suggestion is None: <TAB>  <TAB> return suggestion <TAB> counter = 0 <TAB> results = [] <TAB> for feature in self._features: <TAB>  <TAB> if feature in self._discrete_features: <TAB>  <TAB>  <TAB> result, counter = self._get_discrete_suggestion( <TAB>  <TAB>  <TAB>  <TAB> feature=feature, suggestion=suggestion, counter=counter <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> results.append(result) <MASK> result, counter = self._get_categorical_suggestion( <TAB>  <TAB>  <TAB>  <TAB> feature=feature, suggestion=suggestion, counter=counter <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> results.append(result) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> results.append(suggestion[counter]) <TAB>  <TAB>  <TAB> counter = counter + 1 <TAB> return dict(zip(self._features, results))",elif feature in self . _categorical_features :,198
"def gen_raw_options(modelines): <TAB> for m in modelines: <TAB>  <TAB> opt = m.partition("":"")[2].strip() <MASK> for subopt in (s for s in opt.split(MULTIOPT_SEP)): <TAB>  <TAB>  <TAB>  <TAB> yield subopt <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield opt",if MULTIOPT_SEP in opt :,84
"def _parse_chunked(self, data): <TAB> body = [] <TAB> trailers = {} <TAB> n = 0 <TAB> lines = data.split(b""\r\n"") <TAB> # parse body <TAB> while True: <TAB>  <TAB> size, chunk = lines[n : n + 2] <TAB>  <TAB> size = int(size, 16) <TAB>  <TAB> if size == 0: <TAB>  <TAB>  <TAB> n += 1 <TAB>  <TAB>  <TAB> break <TAB>  <TAB> self.assertEqual(size, len(chunk)) <TAB>  <TAB> body.append(chunk) <TAB>  <TAB> n += 2 <TAB>  <TAB> # we /should/ hit the end chunk, but check against the size of <TAB>  <TAB> # lines so we're not stuck in an infinite loop should we get <TAB>  <TAB> # malformed data <MASK> break <TAB> return b"""".join(body)",if n > len ( lines ) :,191
"def join(s, *p): <TAB> path = s <TAB> for t in p: <MASK> path = t <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if t[:1] == "":"": <TAB>  <TAB>  <TAB> t = t[1:] <TAB>  <TAB> if "":"" not in path: <TAB>  <TAB>  <TAB> path = "":"" + path <TAB>  <TAB> if path[-1:] != "":"": <TAB>  <TAB>  <TAB> path = path + "":"" <TAB>  <TAB> path = path + t <TAB> return path",if ( not s ) or isabs ( t ) :,115
"def validate_route_filter(cmd, namespace): <TAB> from msrestazure.tools import is_valid_resource_id, resource_id <TAB> if namespace.route_filter: <MASK> namespace.route_filter = resource_id( <TAB>  <TAB>  <TAB>  <TAB> subscription=get_subscription_id(cmd.cli_ctx), <TAB>  <TAB>  <TAB>  <TAB> resource_group=namespace.resource_group_name, <TAB>  <TAB>  <TAB>  <TAB> namespace=""Microsoft.Network"", <TAB>  <TAB>  <TAB>  <TAB> type=""routeFilters"", <TAB>  <TAB>  <TAB>  <TAB> name=namespace.route_filter, <TAB>  <TAB>  <TAB> )",if not is_valid_resource_id ( namespace . route_filter ) :,152
"def expanded_output(self): <TAB> """"""Iterate over output files while dynamic output is expanded."""""" <TAB> for f, f_ in zip(self.output, self.rule.output): <TAB>  <TAB> if f in self.dynamic_output: <TAB>  <TAB>  <TAB> expansion = self.expand_dynamic(f_) <MASK> yield f_ <TAB>  <TAB>  <TAB> for f, _ in expansion: <TAB>  <TAB>  <TAB>  <TAB> file_to_yield = IOFile(f, self.rule) <TAB>  <TAB>  <TAB>  <TAB> file_to_yield.clone_flags(f_) <TAB>  <TAB>  <TAB>  <TAB> yield file_to_yield <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield f",if not expansion :,153
"def prepare_text(text, style): <TAB> body = [] <TAB> for fragment, sty in parse_tags(text, style, subs.styles): <TAB>  <TAB> fragment = fragment.replace(r""\h"", "" "") <TAB>  <TAB> fragment = fragment.replace(r""\n"", ""\n"") <TAB>  <TAB> fragment = fragment.replace(r""\N"", ""\n"") <TAB>  <TAB> if sty.italic: <TAB>  <TAB>  <TAB> fragment = ""<i>%s</i>"" % fragment <TAB>  <TAB> if sty.underline: <TAB>  <TAB>  <TAB> fragment = ""<u>%s</u>"" % fragment <TAB>  <TAB> if sty.strikeout: <TAB>  <TAB>  <TAB> fragment = ""<s>%s</s>"" % fragment <MASK> raise ContentNotUsable <TAB>  <TAB> body.append(fragment) <TAB> return re.sub(""\n+"", ""\n"", """".join(body).strip())",if sty . drawing :,198
"def decref(self, key, count=1): <TAB> with self._lock: <TAB>  <TAB> slot = self._dict[key] <MASK> del self._dict[key] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> slot[1] -= count <TAB>  <TAB>  <TAB> self._dict[key] = slot",if slot [ 1 ] < count :,79
"def stale_rec(node, nodes): <TAB> if node.abspath() in node.ctx.env[Build.CFG_FILES]: <TAB>  <TAB> return <TAB> if getattr(node, ""children"", []): <TAB>  <TAB> for x in node.children.values(): <TAB>  <TAB>  <TAB> if x.name != ""c4che"": <TAB>  <TAB>  <TAB>  <TAB> stale_rec(x, nodes) <TAB> else: <TAB>  <TAB> for ext in DYNAMIC_EXT: <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if not node in nodes: <TAB>  <TAB>  <TAB>  <TAB> if can_delete(node): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> Logs.warn(""Removing stale file -> %r"", node) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> node.delete()",if node . name . endswith ( ext ) :,177
"def _do_ssl_handshake(self): <TAB> try: <TAB>  <TAB> self.socket.do_handshake() <TAB> except ssl.SSLError as err: <TAB>  <TAB> if err.args[0] in (ssl.SSL_ERROR_WANT_READ, ssl.SSL_ERROR_WANT_WRITE): <TAB>  <TAB>  <TAB> return <TAB>  <TAB> elif err.args[0] == ssl.SSL_ERROR_EOF: <TAB>  <TAB>  <TAB> return self.handle_close() <TAB>  <TAB> raise <TAB> except OSError as err: <MASK> return self.handle_close() <TAB> else: <TAB>  <TAB> self._ssl_accepting = False",if err . args [ 0 ] == errno . ECONNABORTED :,161
"def test_full_hd_tv(self): <TAB> cur_test = ""full_hd_tv"" <TAB> cur_qual = common.Quality.FULLHDTV <TAB> for name, tests in iteritems(self.test_cases): <TAB>  <TAB> for test in tests: <MASK> self.assertEqual(cur_qual, common.Quality.name_quality(test)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.assertNotEqual(cur_qual, common.Quality.name_quality(test))",if name == cur_test :,130
"def debug_tree(tree): <TAB> l = [] <TAB> for elt in tree: <TAB>  <TAB> if isinstance(elt, int): <TAB>  <TAB>  <TAB> l.append(_names.get(elt, elt)) <MASK> l.append(elt) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> l.append(debug_tree(elt)) <TAB> return l","elif isinstance ( elt , str ) :",89
"def get_all_missing_headers(self): <TAB> # Heavy operation done in one optimized shot <TAB> for chunk_height, expected_hash in reversed(list(self.checkpoints.items())): <TAB>  <TAB> if chunk_height in self.known_missing_checkpointed_chunks: <TAB>  <TAB>  <TAB> continue <MASK> self.known_missing_checkpointed_chunks.add(chunk_height) <TAB> return self.known_missing_checkpointed_chunks","if self . chunk_hash ( chunk_height , 1000 ) != expected_hash :",125
"def get_byname(userId, documentName, session=None): <TAB> if not session: <TAB>  <TAB> session = db.Session <TAB> ret = {} <TAB> result = ( <TAB>  <TAB> session.query(LegacyArchiveDocument) <TAB>  <TAB> .filter_by(userId=userId, documentName=documentName) <TAB>  <TAB> .first() <TAB> ) <TAB> if result: <TAB>  <TAB> obj = dict( <TAB>  <TAB>  <TAB> (key, value) <TAB>  <TAB>  <TAB> for key, value in vars(result).items() <MASK> ) <TAB>  <TAB> ret = obj <TAB> return ret","if not key . startswith ( ""_"" )",141
"def cb(ipdb, msg, action): <TAB> if action == ""RTM_NEWLINK"" and msg.get_attr(""IFLA_IFNAME"", """") in (ifP1, ifP2): <TAB>  <TAB> obj = ipdb.interfaces[msg[""index""]] <MASK> ipdb.interfaces[ifM].add_port(obj) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> ipdb.interfaces[ifM].commit() <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> pass",if obj not in ipdb . interfaces [ ifM ] :,124
"def reorder_encoder_rules(self, nts): <TAB> """"""reorder rules so that any rules with ENCODER_PREFERRED is first"""""" <TAB> for nt in nts.values(): <TAB>  <TAB> first_rules = [] <TAB>  <TAB> rest_of_the_rules = [] <TAB>  <TAB> for r in nt.rules: <MASK> first_rules.append(r) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> rest_of_the_rules.append(r) <TAB>  <TAB> nt.rules = first_rules + rest_of_the_rules","if r . conditions . contains ( ""ENCODER_PREFERRED"" ) :",143
"def update_url(self, s, keywords): <TAB> pc = self <TAB> w = pc.ensure_text_widget() <TAB> pc.show() <TAB> if 1: <TAB>  <TAB> w.setPlainText("""") <TAB> else: <TAB>  <TAB> url = pc.get_url(s, ""@url"") <MASK> w.setPlainText(""@url %s"" % url) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> w.setPlainText(""@url: no url given"")",if url :,113
"def _update_engines(self, engines): <TAB> """"""Update our engines dict and _ids from a dict of the form: {id:uuid}."""""" <TAB> for k, v in iteritems(engines): <TAB>  <TAB> eid = int(k) <MASK> self._ids.append(eid) <TAB>  <TAB> self._engines[eid] = v <TAB> self._ids = sorted(self._ids) <TAB> if ( <TAB>  <TAB> sorted(self._engines.keys()) != list(range(len(self._engines))) <TAB>  <TAB> and self._task_scheme == ""pure"" <TAB>  <TAB> and self._task_socket <TAB> ): <TAB>  <TAB> self._stop_scheduling_tasks()",if eid not in self . _engines :,173
def test_delete_chat_thread(self): <TAB> async with self.chat_client: <TAB>  <TAB> await self._create_thread() <TAB>  <TAB> await self.chat_client.delete_chat_thread(self.thread_id) <TAB>  <TAB> # delete created users and chat threads <MASK> await self.chat_client.delete_chat_thread(self.thread_id),if not self . is_playback ( ) :,98
"def _to_protobuf_matrix(matrix, p_matrix, transformation=None): <TAB> for row in matrix: <TAB>  <TAB> p_row = p_matrix.rows.add() <TAB>  <TAB> for cell in row: <TAB>  <TAB>  <TAB> value = cell <MASK> value = transformation(value) <TAB>  <TAB>  <TAB> p_row.cells.append(value)",if transformation :,88
"def apply(self, db, family): <TAB> if self.rtype: <MASK> if self.regex[0].search(str(family.get_relationship())) is None: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> elif self.rtype != family.get_relationship(): <TAB>  <TAB>  <TAB> return False <TAB> return True",if self . rtype . is_custom ( ) and self . use_regex :,93
"def get_somatic_variantcallers(items): <TAB> """"""Retrieve all variant callers for somatic calling, handling somatic/germline."""""" <TAB> out = [] <TAB> for data in items: <TAB>  <TAB> vcs = dd.get_variantcaller(data) <MASK> vcs = vcs[""somatic""] <TAB>  <TAB> if not isinstance(vcs, (list, tuple)): <TAB>  <TAB>  <TAB> vcs = [vcs] <TAB>  <TAB> out += vcs <TAB> return set(vcs)","if isinstance ( vcs , dict ) and ""somatic"" in vcs :",133
"def balancer_list_members(self, balancer): <TAB> lb = self._get_balancer_model(balancer.id) <TAB> members = [] <TAB> vs = self._locate_service_group(lb, balancer.port) <TAB> if vs: <MASK> srvgrp = vs[""serviceGroups""][0] <TAB>  <TAB>  <TAB> members = [self._to_member(srv, balancer) for srv in srvgrp[""services""]] <TAB> return members","if vs [ ""serviceGroups"" ] :",112
"def https_open(self, req): <TAB> try: <TAB>  <TAB> return self.do_open(do_connection, req) <TAB> except Exception as err_msg: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> error_msg = str(err_msg.args[0]).split(""] "")[1] + ""."" <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB> error_msg = str(err_msg.args[0]) + ""."" <MASK> if settings.VERBOSITY_LEVEL < 2: <TAB>  <TAB>  <TAB>  <TAB> print(settings.FAIL_STATUS) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if settings.VERBOSITY_LEVEL < 1: <TAB>  <TAB>  <TAB>  <TAB> print("""") <TAB>  <TAB> print(settings.print_critical_msg(error_msg)) <TAB>  <TAB> raise SystemExit()",if settings . INIT_TEST == True :,187
"def add_libdirs(self, envvar, sep, fatal=False): <TAB> v = os.environ.get(envvar) <TAB> if not v: <TAB>  <TAB> return <TAB> for dir in str.split(v, sep): <TAB>  <TAB> dir = str.strip(dir) <TAB>  <TAB> if not dir: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> dir = os.path.normpath(dir) <TAB>  <TAB> if os.path.isdir(dir): <MASK> self.library_dirs.append(dir) <TAB>  <TAB> elif fatal: <TAB>  <TAB>  <TAB> fail(""FATAL: bad directory %s in environment variable %s"" % (dir, envvar))",if not dir in self . library_dirs :,159
"def check_placement_group_index(placement_group: PlacementGroup, bundle_index: int): <TAB> assert placement_group is not None <TAB> if placement_group.id.is_nil(): <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""If placement group is not set, "" <TAB>  <TAB>  <TAB>  <TAB> ""the value of bundle index must be -1."" <TAB>  <TAB>  <TAB> ) <TAB> elif bundle_index >= placement_group.bundle_count or bundle_index < -1: <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> f""placement group bundle index {bundle_index} "" <TAB>  <TAB>  <TAB> f""is invalid. Valid placement group indexes: "" <TAB>  <TAB>  <TAB> f""0-{placement_group.bundle_count}"" <TAB>  <TAB> )",if bundle_index != - 1 :,178
"def incoming(): <TAB> while True: <TAB>  <TAB> m = ws.receive() <TAB>  <TAB> if m is not None: <TAB>  <TAB>  <TAB> m = str(m) <TAB>  <TAB>  <TAB> print((m, len(m))) <MASK> ws.close() <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> print((""Connection closed!"",))",if len ( m ) == 35 :,94
"def walk_tree( <TAB> root: Element, <TAB> processor: Callable[[Element], Optional[_T]], <TAB> stop_after_first: bool = False,) -> List[_T]: <TAB> results = [] <TAB> queue = deque([root]) <TAB> while queue: <TAB>  <TAB> currElement = queue.popleft() <TAB>  <TAB> for child in currElement: <TAB>  <TAB>  <TAB> if child: <TAB>  <TAB>  <TAB>  <TAB> queue.append(child) <TAB>  <TAB>  <TAB> result = processor(child) <TAB>  <TAB>  <TAB> if result is not None: <TAB>  <TAB>  <TAB>  <TAB> results.append(result) <MASK> return results <TAB> return results",if stop_after_first :,152
"def _find_node_with_predicate(self, node, predicate): <TAB> if node != self._tree._root and predicate(node): <TAB>  <TAB> return node <TAB> item, cookie = self._tree.GetFirstChild(node) <TAB> while item: <MASK> return item <TAB>  <TAB> if self._tree.ItemHasChildren(item): <TAB>  <TAB>  <TAB> result = self._find_node_with_predicate(item, predicate) <TAB>  <TAB>  <TAB> if result: <TAB>  <TAB>  <TAB>  <TAB> return result <TAB>  <TAB> item, cookie = self._tree.GetNextChild(node, cookie) <TAB> return None",if predicate ( item ) :,143
"def traverse_coords(coords, dst_coords): <TAB> for p in coords: <MASK> lst = [] <TAB>  <TAB>  <TAB> traverse_coords(p, lst) <TAB>  <TAB>  <TAB> dst_coords.append(lst) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> x, y = p[0], p[1] <TAB>  <TAB>  <TAB> d = (x + (y - b) * m) / (1 + m * m) <TAB>  <TAB>  <TAB> x2 = 2 * d - x <TAB>  <TAB>  <TAB> y2 = 2 * d * m - y + 2 * b <TAB>  <TAB>  <TAB> dst_coords.append((x2, y2)) <TAB> return dst_coords",if type ( p [ 0 ] ) is list :,161
"def normalize_replies(self, x): <TAB> xs = x.split(""\n"") <TAB> xs2 = [] <TAB> for x in xs: <MASK> # Normalize the sentence appearing after 'your persona:' <TAB>  <TAB>  <TAB> x = x[len(""your persona: "") :] <TAB>  <TAB>  <TAB> x = normalize_reply(x) <TAB>  <TAB>  <TAB> x = ""your persona: "" + x <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> x = normalize_reply(x) <TAB>  <TAB> xs2.append(x) <TAB> return ""\n"".join(xs2)","if ""your persona:"" in x :",142
"def run_unittest(*classes): <TAB> suite = unittest.TestSuite() <TAB> for c in classes: <MASK> c = __import__(c) <TAB>  <TAB>  <TAB> for name in dir(c): <TAB>  <TAB>  <TAB>  <TAB> obj = getattr(c, name) <TAB>  <TAB>  <TAB>  <TAB> if isinstance(obj, type) and issubclass(obj, unittest.TestCase): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> suite.addTest(obj) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> suite.addTest(c) <TAB> runner = unittest.TestRunner() <TAB> result = runner.run(suite)","if isinstance ( c , str ) :",136
"def bprop_naive(self, error, permute=False): <TAB> for dst in range(self.ofmsize): <TAB>  <TAB> rflinks = self.links[dst] <TAB>  <TAB> A = error[:, self.ofmlocs[dst]] <TAB>  <TAB> B = self.weights <MASK> inds = np.random.permutation(A.shape[1]) <TAB>  <TAB>  <TAB> np.dot(A[:, inds], B[inds, :], self.bpropbuf) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> np.dot(A, B, self.bpropbuf) <TAB>  <TAB> self.berror[:, rflinks] += self.bpropbuf",if permute :,150
"def rewrite_order_lookup_key(model, lookup_key): <TAB> try: <MASK> return ""-"" + rewrite_lookup_key(model, lookup_key[1:]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return rewrite_lookup_key(model, lookup_key) <TAB> except AttributeError: <TAB>  <TAB> return lookup_key","if lookup_key . startswith ( ""-"" ) :",85
"def test_default_configuration(self): <TAB> transformations = [] <TAB> for i in range(2): <TAB>  <TAB> transformation, original = self._test_helper(RescalingChoice, dataset=""boston"") <TAB>  <TAB> # The maximum is around 1.95 for the transformed array... <TAB>  <TAB> self.assertAlmostEqual(np.mean(transformation), 0, places=5) <TAB>  <TAB> self.assertAlmostEqual(np.std(transformation), 1, places=5) <TAB>  <TAB> self.assertFalse((original == transformation).all()) <TAB>  <TAB> transformations.append(transformation) <MASK> self.assertTrue((transformations[-1] == transformations[-2]).all())",if len ( transformations ) > 1 :,157
"def test_get_filter_text(self): <TAB> with realized(self.b): <MASK> self.assertEqual(self.b.get_filter_text(), u"""") <TAB>  <TAB>  <TAB> self.assertTrue(isinstance(self.b.get_filter_text(), str)) <TAB>  <TAB>  <TAB> self.b.filter_text(u""foo"") <TAB>  <TAB>  <TAB> self.assertEqual(self.b.get_filter_text(), u""foo"") <TAB>  <TAB>  <TAB> self.assertTrue(isinstance(self.b.get_filter_text(), str))",if self . b . can_filter_text ( ) :,138
"def _namelist(instance): <TAB> namelist, namedict, classlist = [], {}, [instance.__class__] <TAB> for c in classlist: <TAB>  <TAB> for b in c.__bases__: <TAB>  <TAB>  <TAB> classlist.append(b) <TAB>  <TAB> for name in c.__dict__.keys(): <MASK> namelist.append(name) <TAB>  <TAB>  <TAB>  <TAB> namedict[name] = 1 <TAB> return namelist",if not namedict . has_key ( name ) :,107
"def resolve_cloudtrail_payload(self, payload): <TAB> sources = self.data.get(""sources"", []) <TAB> events = [] <TAB> for e in self.data.get(""events""): <TAB>  <TAB> if not isinstance(e, dict): <TAB>  <TAB>  <TAB> events.append(e) <TAB>  <TAB>  <TAB> event_info = CloudWatchEvents.get(e) <MASK> continue <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> event_info = e <TAB>  <TAB>  <TAB> events.append(e[""event""]) <TAB>  <TAB> sources.append(event_info[""source""]) <TAB> payload[""detail""] = {""eventSource"": list(set(sources)), ""eventName"": events}",if event_info is None :,159
"def __setitem__(self, aset, c): <TAB> if isinstance(aset, tuple): <MASK> row = self.rownames.index(aset[0]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> row = aset[0] <TAB>  <TAB> if isinstance(aset[1], str): <TAB>  <TAB>  <TAB> column = self.colnames.index(aset[1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> column = aset[1] <TAB>  <TAB> self.cell_value(row, column, c) <TAB> else: <TAB>  <TAB> Matrix.__setitem__(self, aset, c)","if isinstance ( aset [ 0 ] , str ) :",144
"def test_retrieve_robots_token_permission( <TAB> username, is_admin, with_permissions, app, client): <TAB> with client_with_identity(username, client) as cl: <TAB>  <TAB> params = {""orgname"": ""buynlarge"", ""token"": ""true""} <MASK> params[""permissions""] = ""true"" <TAB>  <TAB> result = conduct_api_call(cl, OrgRobotList, ""GET"", params, None) <TAB>  <TAB> assert result.json[""robots""] <TAB>  <TAB> for robot in result.json[""robots""]: <TAB>  <TAB>  <TAB> assert (robot.get(""token"") is not None) == is_admin <TAB>  <TAB>  <TAB> assert (robot.get(""repositories"") is not None) == ( <TAB>  <TAB>  <TAB>  <TAB> is_admin and with_permissions <TAB>  <TAB>  <TAB> )",if with_permissions :,192
"def _analyze_ast(contents): <TAB> try: <TAB>  <TAB> return ast.literal_eval(contents) <TAB> except SyntaxError: <TAB>  <TAB> pass <TAB> try: <TAB>  <TAB> # remove all comments <TAB>  <TAB> contents = re.sub(re.compile(r""/\*.*?\*/"", re.DOTALL), """", contents) <TAB>  <TAB> contents = re.sub(re.compile(r""#.*?\n""), """", contents) <TAB>  <TAB> # remove anything before dict declaration like: ""caps = { ..."" <TAB>  <TAB> match = re.match(r""^([^{]+)"", contents) <MASK> contents = contents.replace(match.group(1), """") <TAB>  <TAB> # and try again <TAB>  <TAB> return ast.literal_eval(contents) <TAB> except SyntaxError: <TAB>  <TAB> pass <TAB> return False",if match :,179
"def bulk_disable_accounts(account_names): <TAB> """"""Bulk disable accounts"""""" <TAB> for account_name in account_names: <TAB>  <TAB> account = Account.query.filter(Account.name == account_name).first() <MASK> app.logger.debug(""Disabling account %s"", account.name) <TAB>  <TAB>  <TAB> account.active = False <TAB>  <TAB>  <TAB> db.session.add(account) <TAB> db.session.commit() <TAB> db.session.close()",if account :,113
"def _add_agent_rewards(self, reward_dict: Dict[AgentID, float]) -> None: <TAB> for agent_id, reward in reward_dict.items(): <MASK> self.agent_rewards[agent_id, self.policy_for(agent_id)] += reward <TAB>  <TAB>  <TAB> self.total_reward += reward <TAB>  <TAB>  <TAB> self._agent_reward_history[agent_id].append(reward)",if reward is not None :,108
"def wrapper(strategy, backend, pipeline_index, *args, **kwargs): <TAB> current_partial = partial_prepare( <TAB>  <TAB> strategy, backend, pipeline_index, *args, **kwargs <TAB> ) <TAB> out = ( <TAB>  <TAB> func( <TAB>  <TAB>  <TAB> strategy=strategy, <TAB>  <TAB>  <TAB> backend=backend, <TAB>  <TAB>  <TAB> pipeline_index=pipeline_index, <TAB>  <TAB>  <TAB> current_partial=current_partial, <TAB>  <TAB>  <TAB> *args, <TAB>  <TAB>  <TAB> **kwargs <TAB>  <TAB> ) <TAB>  <TAB> or {} <TAB> ) <TAB> if not isinstance(out, dict): <TAB>  <TAB> strategy.storage.partial.store(current_partial) <MASK> strategy.session_set(PARTIAL_TOKEN_SESSION_NAME, current_partial.token) <TAB> return out",if save_to_session :,185
def restore_text(self): <TAB> if self.source_is_console(): <TAB>  <TAB> cb = self._last_console_cb <TAB> else: <TAB>  <TAB> cb = self._last_editor_cb <TAB> if cb is None: <MASK> self.plain_text.clear() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.rich_text.clear() <TAB> else: <TAB>  <TAB> func = cb[0] <TAB>  <TAB> args = cb[1:] <TAB>  <TAB> func(*args) <TAB>  <TAB> if get_meth_class_inst(func) is self.rich_text: <TAB>  <TAB>  <TAB> self.switch_to_rich_text() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.switch_to_plain_text(),if self . is_plain_text_mode ( ) :,180
"def extract_groups(self, text: str, language_code: str): <TAB> previous = None <TAB> group = 1 <TAB> groups = [] <TAB> words = [] <TAB> ignored = IGNORES.get(language_code, {}) <TAB> for word in NON_WORD.split(text): <TAB>  <TAB> if not word: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if word not in ignored and len(word) >= 2: <MASK> group += 1 <TAB>  <TAB>  <TAB> elif group > 1: <TAB>  <TAB>  <TAB>  <TAB> groups.append(group) <TAB>  <TAB>  <TAB>  <TAB> words.append(previous) <TAB>  <TAB>  <TAB>  <TAB> group = 1 <TAB>  <TAB> previous = word <TAB> if group > 1: <TAB>  <TAB> groups.append(group) <TAB>  <TAB> words.append(previous) <TAB> return groups, words",if previous == word :,187
"def pendingcalls_thread(self, context): <TAB> try: <TAB>  <TAB> self.pendingcalls_submit(context.l, context.n) <TAB> finally: <TAB>  <TAB> with context.lock: <TAB>  <TAB>  <TAB> context.nFinished += 1 <TAB>  <TAB>  <TAB> nFinished = context.nFinished <TAB>  <TAB>  <TAB> if False and support.verbose: <TAB>  <TAB>  <TAB>  <TAB> print(""finished threads: "", nFinished) <MASK> context.event.set()",if nFinished == context . nThreads :,113
"def __getattr__(self, item: str) -> Any: <TAB> if hasattr(MissingPandasLikeRolling, item): <TAB>  <TAB> property_or_func = getattr(MissingPandasLikeRolling, item) <MASK> return property_or_func.fget(self)  # type: ignore <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return partial(property_or_func, self) <TAB> raise AttributeError(item)","if isinstance ( property_or_func , property ) :",105
"def _csv(self, match=None, dump=None): <TAB> if dump is None: <TAB>  <TAB> dump = self._dump(match) <TAB> for record in dump: <TAB>  <TAB> row = [] <TAB>  <TAB> for field in record: <TAB>  <TAB>  <TAB> if isinstance(field, int): <TAB>  <TAB>  <TAB>  <TAB> row.append(""%i"" % field) <MASK> row.append("""") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> row.append(""'%s'"" % field) <TAB>  <TAB> yield "","".join(row)",elif field is None :,126
"def get_default_dict(section_definition): <TAB> section_key = section_definition.get(""key"") <TAB> if section_key == ""global"": <TAB>  <TAB> section_key += ""_"" <TAB> if ""cluster"" == section_key: <TAB>  <TAB> section_key += ( <TAB>  <TAB>  <TAB> ""_sit"" <MASK> else ""_hit"" <TAB>  <TAB> ) <TAB> default_dict = DefaultDict[section_key].value <TAB> return default_dict","if section_definition . get ( ""cluster_model"" ) == ClusterModel . SIT . name",125
"def scan_resource_conf(self, conf): <TAB> subscription = re.compile(r""\/|\/subscriptions\/[\w\d-]+$|\[subscription\(\).id\]"") <TAB> if ""properties"" in conf: <MASK> if any( <TAB>  <TAB>  <TAB>  <TAB> re.match(subscription, scope) <TAB>  <TAB>  <TAB>  <TAB> for scope in conf[""properties""][""assignableScopes""] <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> if ""permissions"" in conf[""properties""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if conf[""properties""][""permissions""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for permission in conf[""properties""][""permissions""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if ""actions"" in permission and ""*"" in permission[""actions""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return CheckResult.FAILED <TAB> return CheckResult.PASSED","if ""assignableScopes"" in conf [ ""properties"" ] :",197
"def hard_update(self, cache, size_change, pins_gates): <TAB> """"""replace verts, rads and vel (in NumPy)"""""" <TAB> verts, rads, vel, react = cache <TAB> if len(verts) == self.v_len: <TAB>  <TAB> if pins_gates[0] and pins_gates[1]: <TAB>  <TAB>  <TAB> unpinned = self.params[""unpinned""] <TAB>  <TAB>  <TAB> self.verts[unpinned] = verts[unpinned] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.verts = verts <TAB>  <TAB> self.vel = vel <MASK> self.rads = rads",if not size_change :,155
"def run(self): <TAB> if self.check(): <TAB>  <TAB> path = ""/../../../../../../../../../../../..{}"".format(self.filename) <TAB>  <TAB> response = self.http_request(method=""GET"", path=path) <TAB>  <TAB> if response is None: <TAB>  <TAB>  <TAB> return <MASK> print_success(""Success! File: %s"" % self.filename) <TAB>  <TAB>  <TAB> print_info(response.text) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print_error(""Exploit failed"") <TAB> else: <TAB>  <TAB> print_error(""Device seems to be not vulnerable"")",if response . status_code == 200 and response . text :,153
"def write_text(self, text): <TAB> """"""Writes re-indented text into the buffer."""""" <TAB> should_indent = False <TAB> rows = [] <TAB> for row in text.split(""\n""): <TAB>  <TAB> if should_indent: <TAB>  <TAB>  <TAB> row = "" <TAB> {}"".format(row) <TAB>  <TAB> if ""\b"" in row: <TAB>  <TAB>  <TAB> row = row.replace(""\b"", """", 1) <TAB>  <TAB>  <TAB> should_indent = True <MASK> should_indent = False <TAB>  <TAB> rows.append(row) <TAB> self.write(""{}\n"".format(""\n"".join(rows)))",elif not len ( row . strip ( ) ) :,147
"def default_logger(): <TAB> """"""A logger used to output seed information to nosetests logs."""""" <TAB> logger = logging.getLogger(__name__) <TAB> # getLogger() lookups will return the same logger, but only add the handler once. <TAB> if not len(logger.handlers): <TAB>  <TAB> handler = logging.StreamHandler(sys.stderr) <TAB>  <TAB> handler.setFormatter(logging.Formatter(""[%(levelname)s] %(message)s"")) <TAB>  <TAB> logger.addHandler(handler) <MASK> logger.setLevel(logging.INFO) <TAB> return logger",if logger . getEffectiveLevel ( ) == logging . NOTSET :,131
"def while1_test(a, b, c): <TAB> while 1: <TAB>  <TAB> if a != 2: <TAB>  <TAB>  <TAB> if b: <TAB>  <TAB>  <TAB>  <TAB> a = 3 <TAB>  <TAB>  <TAB>  <TAB> b = 0 <MASK> c = 0 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> a += b + c <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return a, b, c",elif c :,94
"def fetch(): <TAB> retval = {} <TAB> content = retrieve_content(__url__) <TAB> if __check__ in content: <TAB>  <TAB> for line in content.split(""\n""): <TAB>  <TAB>  <TAB> line = line.strip() <TAB>  <TAB>  <TAB> if not line or line.startswith(""#"") or ""."" not in line: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if "" # "" in line: <TAB>  <TAB>  <TAB>  <TAB> reason = line.split("" # "")[1].split()[0].lower() <MASK> # too many false positives <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB>  <TAB> retval[line.split("" # "")[0]] = (__info__, __reference__) <TAB> return retval","if reason == ""scanning"" :",157
"def create_order(order, shopify_settings, old_order_sync=False, company=None): <TAB> so = create_sales_order(order, shopify_settings, company) <TAB> if so: <MASK> create_sales_invoice( <TAB>  <TAB>  <TAB>  <TAB> order, shopify_settings, so, old_order_sync=old_order_sync <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if order.get(""fulfillments"") and not old_order_sync: <TAB>  <TAB>  <TAB> create_delivery_note(order, shopify_settings, so)","if order . get ( ""financial_status"" ) == ""paid"" :",144
"def __getitem__(self, key): <TAB> if isinstance(key, numbers.Number): <TAB>  <TAB> l = len(self) <TAB>  <TAB> if key >= l: <TAB>  <TAB>  <TAB> raise IndexError(""Index %s out of range (%s elements)"" % (key, l)) <MASK> if key < -l: <TAB>  <TAB>  <TAB>  <TAB> raise IndexError(""Index %s out of range (%s elements)"" % (key, l)) <TAB>  <TAB>  <TAB> key += l <TAB>  <TAB> return self(key + 1) <TAB> elif isinstance(key, slice): <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> self.impl.__class__.__name__ + "" object does not support slicing"" <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> return self(key)",if key < 0 :,170
"def load_checks(path=None, subpkg=""""): <TAB> """"""Dynamically import all check modules for the side effect of registering checks."""""" <TAB> if path is None: <TAB>  <TAB> path = os.path.dirname(__file__) <TAB> modules = [] <TAB> for name in os.listdir(path): <TAB>  <TAB> if os.path.isdir(os.path.join(path, name)): <TAB>  <TAB>  <TAB> modules = modules + load_checks( <TAB>  <TAB>  <TAB>  <TAB> os.path.join(path, name), subpkg + ""."" + name <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> continue <MASK> modules.append(import_module(__package__ + subpkg + ""."" + name[:-3])) <TAB> return modules","if name . endswith ( "".py"" ) and name not in LOADER_EXCLUDES :",174
"def _remove_temporary_files(self, temporary_files): <TAB> """"""Internal function for cleaning temporary files"""""" <TAB> for file_object in temporary_files: <TAB>  <TAB> file_name = file_object.name <TAB>  <TAB> file_object.close() <TAB>  <TAB> if os.path.exists(file_name): <TAB>  <TAB>  <TAB> os.remove(file_name) <TAB>  <TAB> arff_file_name = file_name + "".arff"" <MASK> os.remove(arff_file_name)",if os . path . exists ( arff_file_name ) :,129
"def search_rotate(array, val): <TAB> low, high = 0, len(array) - 1 <TAB> while low <= high: <TAB>  <TAB> mid = (low + high) // 2 <TAB>  <TAB> if val == array[mid]: <TAB>  <TAB>  <TAB> return mid <TAB>  <TAB> if array[low] <= array[mid]: <TAB>  <TAB>  <TAB> if array[low] <= val <= array[mid]: <TAB>  <TAB>  <TAB>  <TAB> high = mid - 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> low = mid + 1 <TAB>  <TAB> else: <MASK> low = mid + 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> high = mid - 1 <TAB> return -1",if array [ mid ] <= val <= array [ high ] :,166
"def match_file(self, file, tff_format): <TAB> match = tff_format.search(file.filename.replace(""\\"", ""/"")) <TAB> if match: <TAB>  <TAB> result = {} <TAB>  <TAB> for name, value in match.groupdict().items(): <TAB>  <TAB>  <TAB> value = value.strip() <TAB>  <TAB>  <TAB> if name in self.numeric_tags: <TAB>  <TAB>  <TAB>  <TAB> value = value.lstrip(""0"") <MASK> value = value.replace(""_"", "" "") <TAB>  <TAB>  <TAB> result[name] = value <TAB>  <TAB> return result <TAB> else: <TAB>  <TAB> return {}",if self . ui . replace_underscores . isChecked ( ) :,149
"def exclude_pkgs(self, pkgs): <TAB> # :api <TAB> name = ""excludepkgs"" <TAB> if pkgs is not None and pkgs != []: <MASK> self._set_value(name, pkgs, dnf.conf.PRIO_COMMANDLINE) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logger.warning( <TAB>  <TAB>  <TAB>  <TAB> _(""Unknown configuration option: %s = %s""), ucd(name), ucd(pkgs) <TAB>  <TAB>  <TAB> )",if self . _has_option ( name ) :,113
"def button_press_cb(self, tdw, event): <TAB> if self.zone in (_EditZone.CREATE_AXIS, _EditZone.DELETE_AXIS): <TAB>  <TAB> button = event.button <MASK> self._click_info = (button, self.zone) <TAB>  <TAB>  <TAB> return False <TAB> return super(SymmetryEditMode, self).button_press_cb(tdw, event)",if button == 1 and event . type == Gdk . EventType . BUTTON_PRESS :,114
"def declare_var( <TAB> self, <TAB> type_name: Union[str, Tuple[str, str]], <TAB> *, <TAB> var_name: str = """", <TAB> var_name_prefix: str = ""v"", <TAB> shared: bool = False,) -> str: <TAB> if shared: <MASK> var_name = var_name_prefix <TAB>  <TAB> if var_name not in self.shared_vars: <TAB>  <TAB>  <TAB> self.declarations.append((var_name, type_name)) <TAB>  <TAB>  <TAB> self.shared_vars.add(var_name) <TAB> else: <TAB>  <TAB> if not var_name: <TAB>  <TAB>  <TAB> var_name = self.get_var_name(var_name_prefix) <TAB>  <TAB> self.declarations.append((var_name, type_name)) <TAB> return var_name",if not var_name :,197
"def get_module_map(module, module_path): <TAB> """"""Map true modules to exported name"""""" <TAB> if not module_is_public(module): <TAB>  <TAB> return {} <TAB> m = {} <TAB> for symbol_name in dir(module): <TAB>  <TAB> if symbol_name.startswith(""_""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> symbol = getattr(module, symbol_name) <TAB>  <TAB> symbol_path = ""%s.%s"" % (module_path, symbol_name) <TAB>  <TAB> m[symbol] = symbol_path <MASK> m.update(get_module_map(symbol, symbol_path)) <TAB> return m",if inspect . ismodule ( symbol ) :,152
"def build_properties(self): <TAB> self.properties = set() <TAB> if self.module.partial_scan == True: <TAB>  <TAB> # For partial scans, only check the most common properties values <TAB>  <TAB> for prop in self.COMMON_PROPERTIES: <TAB>  <TAB>  <TAB> self.properties.add(chr(prop)) <TAB> else: <TAB>  <TAB> for pb in range(0, 9): <TAB>  <TAB>  <TAB> for lp in range(0, 5): <TAB>  <TAB>  <TAB>  <TAB> for lc in range(0, 5): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> prop = self.build_property(pb, lp, lc) <MASK> self.properties.add(chr(prop))",if prop is not None :,166
"def getFileIdFromAlternateLink(altLink): <TAB> loc = altLink.find(""/d/"") <MASK> fileId = altLink[loc + 3 :] <TAB>  <TAB> loc = fileId.find(""/"") <TAB>  <TAB> if loc != -1: <TAB>  <TAB>  <TAB> return fileId[:loc] <TAB> else: <TAB>  <TAB> loc = altLink.find(""/folderview?id="") <TAB>  <TAB> if loc > 0: <TAB>  <TAB>  <TAB> fileId = altLink[loc + 15 :] <TAB>  <TAB>  <TAB> loc = fileId.find(""&"") <TAB>  <TAB>  <TAB> if loc != -1: <TAB>  <TAB>  <TAB>  <TAB> return fileId[:loc] <TAB> controlflow.system_error_exit( <TAB>  <TAB> 2, f""{altLink} is not a valid Drive File alternateLink"" <TAB> )",if loc > 0 :,180
"def _coerce_trials_data(data, path): <TAB> if not isinstance(data, list): <TAB>  <TAB> if not isinstance(data, dict): <TAB>  <TAB>  <TAB> raise BatchFileError( <TAB>  <TAB>  <TAB>  <TAB> path, <TAB>  <TAB>  <TAB>  <TAB> ""invalid data type for trials: expected list or dict"" <TAB>  <TAB>  <TAB>  <TAB> "", got %s"" % type(data).__name__, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> data = [data] <TAB> for item in data: <MASK> raise BatchFileError( <TAB>  <TAB>  <TAB>  <TAB> path, ""invalid data type for trial %r: expected dict"" % item <TAB>  <TAB>  <TAB> ) <TAB> return data","if not isinstance ( item , dict ) :",152
"def remove(self, *objs): <TAB> val = getattr(self.instance, attname) <TAB> for obj in objs: <TAB>  <TAB> # Is obj actually part of this descriptor set? <MASK> setattr(obj, rel_field.name, None) <TAB>  <TAB>  <TAB> obj.save() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise rel_field.rel.to.DoesNotExist( <TAB>  <TAB>  <TAB>  <TAB> ""%r is not related to %r."" % (obj, self.instance) <TAB>  <TAB>  <TAB> )","if getattr ( obj , rel_field . attname ) == val :",130
"def run(self): <TAB> try: <MASK> self.shell = os.name == ""nt"" <TAB>  <TAB> if self.working_dir != """": <TAB>  <TAB>  <TAB> os.chdir(self.working_dir) <TAB>  <TAB> proc = subprocess.Popen( <TAB>  <TAB>  <TAB> self.command, <TAB>  <TAB>  <TAB> stdout=subprocess.PIPE, <TAB>  <TAB>  <TAB> stderr=subprocess.STDOUT, <TAB>  <TAB>  <TAB> shell=self.shell, <TAB>  <TAB>  <TAB> env=self.env, <TAB>  <TAB> ) <TAB>  <TAB> output = codecs.decode(proc.communicate()[0]) <TAB>  <TAB> self.on_done(output) <TAB> except subprocess.CalledProcessError as e: <TAB>  <TAB> self.on_done(e.returncode, error=True) <TAB> except OSError as e: <TAB>  <TAB> self.on_done(e.message, error=True)",if not self . shell :,196
"def filter_testsuite(suite, matcher, level=None): <TAB> """"""Returns a flattened list of test cases that match the given matcher."""""" <TAB> if not isinstance(suite, unittest.TestSuite): <TAB>  <TAB> raise TypeError(""not a TestSuite"", suite) <TAB> results = [] <TAB> for test in suite._tests: <TAB>  <TAB> if level is not None and getattr(test, ""level"", 0) > level: <TAB>  <TAB>  <TAB> continue <MASK> testname = test.id()  # package.module.class.method <TAB>  <TAB>  <TAB> if matcher(testname): <TAB>  <TAB>  <TAB>  <TAB> results.append(test) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> filtered = filter_testsuite(test, matcher, level) <TAB>  <TAB>  <TAB> results.extend(filtered) <TAB> return results","if isinstance ( test , unittest . TestCase ) :",185
"def propagate_touch_to_touchable_widgets(self, touch, touch_event, *args): <TAB> triggered = False <TAB> for i in self._touchable_widgets: <TAB>  <TAB> if i.collide_point(touch.x, touch.y): <TAB>  <TAB>  <TAB> triggered = True <TAB>  <TAB>  <TAB> if touch_event == ""down"": <TAB>  <TAB>  <TAB>  <TAB> i.on_touch_down(touch) <TAB>  <TAB>  <TAB> elif touch_event == ""move"": <TAB>  <TAB>  <TAB>  <TAB> i.on_touch_move(touch, *args) <MASK> i.on_touch_up(touch) <TAB> return triggered","elif touch_event == ""up"" :",154
"def add_attributes(attributes, all_base64): <TAB> lines = [] <TAB> oc_attr = None <TAB> # objectclass first, even if this is not specified in the RFC <TAB> for attr in attributes: <TAB>  <TAB> if attr.lower() == ""objectclass"": <TAB>  <TAB>  <TAB> for val in attributes[attr]: <TAB>  <TAB>  <TAB>  <TAB> lines.append(_convert_to_ldif(attr, val, all_base64)) <TAB>  <TAB>  <TAB> oc_attr = attr <TAB>  <TAB>  <TAB> break <TAB> # remaining attributes <TAB> for attr in attributes: <MASK> for val in attributes[attr]: <TAB>  <TAB>  <TAB>  <TAB> lines.append(_convert_to_ldif(attr, val, all_base64)) <TAB> return lines",if attr != oc_attr and attr in attributes :,177
"def split_quality(quality): <TAB> anyQualities = [] <TAB> bestQualities = [] <TAB> for curQual in Quality.qualityStrings.keys(): <MASK> anyQualities.append(curQual) <TAB>  <TAB> if curQual << 16 & quality: <TAB>  <TAB>  <TAB> bestQualities.append(curQual) <TAB> return sorted(anyQualities), sorted(bestQualities)",if curQual & quality :,109
"def check(dbdef): <TAB> ""database version must include required keys"" <TAB> for vnum, vdef in dbdef.items(): <TAB>  <TAB> missing = set(required) - set(vdef) <TAB>  <TAB> if vnum == min(dbdef): <TAB>  <TAB>  <TAB> missing -= set(initially_ok) <MASK> yield vnum, missing",if missing :,86
"def teardown_func(): <TAB> try: <TAB>  <TAB> yield <TAB> finally: <TAB>  <TAB> ""tear down test fixtures"" <TAB>  <TAB> cache = os.path.join(here, ""data"", ""cache.db"") <MASK> os.remove(cache)",if os . path . exists ( cache ) :,70
"def getCachedArt(albumid): <TAB> from headphones import cache <TAB> c = cache.Cache() <TAB> artwork_path = c.get_artwork_from_cache(AlbumID=albumid) <TAB> if not artwork_path: <TAB>  <TAB> return <TAB> if artwork_path.startswith(""http://""): <TAB>  <TAB> artwork = request.request_content(artwork_path, timeout=20) <MASK> logger.warn(""Unable to open url: %s"", artwork_path) <TAB>  <TAB>  <TAB> return <TAB> else: <TAB>  <TAB> with open(artwork_path, ""r"") as fp: <TAB>  <TAB>  <TAB> return fp.read()",if not artwork :,148
"def delete_volume(self, name, reraise=False): <TAB> try: <TAB>  <TAB> self.k8s_api.delete_persistent_volume( <TAB>  <TAB>  <TAB> name=name, <TAB>  <TAB>  <TAB> body=client.V1DeleteOptions(api_version=constants.K8S_API_VERSION_V1), <TAB>  <TAB> ) <TAB>  <TAB> logger.debug(""Volume `{}` Deleted"".format(name)) <TAB> except ApiException as e: <MASK> raise PolyaxonK8SError(""Connection error: %s"" % e) from e <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logger.debug(""Volume `{}` was not found"".format(name))",if reraise :,153
"def _hashable(self): <TAB> hashes = [self.graph.md5()] <TAB> for g in self.geometry.values(): <MASK> hashes.append(g.md5()) <TAB>  <TAB> elif hasattr(g, ""tostring""): <TAB>  <TAB>  <TAB> hashes.append(str(hash(g.tostring()))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # try to just straight up hash <TAB>  <TAB>  <TAB> # this may raise errors <TAB>  <TAB>  <TAB> hashes.append(str(hash(g))) <TAB> hashable = """".join(sorted(hashes)).encode(""utf-8"") <TAB> return hashable","if hasattr ( g , ""md5"" ) :",144
"def get_history_data(self, guid, count=1): <TAB> history = {} <TAB> if count < 1: <TAB>  <TAB> return history <TAB> key = self._make_key(guid) <TAB> for i in range(0, self.db.llen(key)): <TAB>  <TAB> r = self.db.lindex(key, i) <TAB>  <TAB> c = msgpack.unpackb(r) <MASK> if c[""data""] not in history: <TAB>  <TAB>  <TAB>  <TAB> history[c[""data""]] = c[""timestamp""] <TAB>  <TAB>  <TAB>  <TAB> if len(history) >= count: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return history","if c [ ""tries"" ] == 0 or c [ ""tries"" ] is None :",161
"def renderable_events(self, date, hour): <TAB> ""Returns the number of renderable events"" <TAB> renderable_events = [] <TAB> for event in self.events: <MASK> renderable_events.append(event) <TAB> if hour: <TAB>  <TAB> for current in renderable_events: <TAB>  <TAB>  <TAB> for event in self.events: <TAB>  <TAB>  <TAB>  <TAB> if event not in renderable_events: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for hour in range(self.start_hour, self.end_hour): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if current.covers(date, hour) and event.covers(date, hour): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> renderable_events.append(event) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return renderable_events","if event . covers ( date , hour ) :",191
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.set_module(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 18: <TAB>  <TAB>  <TAB> self.set_version(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 10 :,120
"def _parseConfigFile(self, iniPath, createConfig=True): <TAB> parser = SafeConfigParserUnicode(strict=False) <TAB> if not os.path.isfile(iniPath): <TAB>  <TAB> if createConfig: <TAB>  <TAB>  <TAB> open(iniPath, ""w"").close() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return <TAB> parser.readfp(codecs.open(iniPath, ""r"", ""utf_8_sig"")) <TAB> for section, options in list(self._iniStructure.items()): <MASK> for option in options: <TAB>  <TAB>  <TAB>  <TAB> if parser.has_option(section, option): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._config[option] = parser.get(section, option)",if parser . has_section ( section ) :,170
"def get_block_id_at_height(store, height, descendant_id): <TAB> if height is None: <TAB>  <TAB> return None <TAB> while True: <TAB>  <TAB> block = store._load_block(descendant_id) <MASK> return descendant_id <TAB>  <TAB> descendant_id = block[ <TAB>  <TAB>  <TAB> ""search_id"" <TAB>  <TAB>  <TAB> if util.get_search_height(block[""height""]) >= height <TAB>  <TAB>  <TAB> else ""prev_id"" <TAB>  <TAB> ]","if block [ ""height"" ] == height :",122
"def wait_services_ready(selectors, min_counts, count_fun, timeout=None): <TAB> readies = [0] * len(selectors) <TAB> start_time = time.time() <TAB> while True: <TAB>  <TAB> all_satisfy = True <TAB>  <TAB> for idx, selector in enumerate(selectors): <TAB>  <TAB>  <TAB> if readies[idx] < min_counts[idx]: <TAB>  <TAB>  <TAB>  <TAB> all_satisfy = False <TAB>  <TAB>  <TAB>  <TAB> readies[idx] = count_fun(selector) <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if all_satisfy: <TAB>  <TAB>  <TAB> break <MASK> raise TimeoutError(""Wait cluster start timeout"") <TAB>  <TAB> time.sleep(1)",if timeout and timeout + start_time < time . time ( ) :,167
"def waitForNodes(self, expected, comparison=None, tag_filters={}): <TAB> MAX_ITER = 50 <TAB> for i in range(MAX_ITER): <TAB>  <TAB> n = len(self.provider.non_terminated_nodes(tag_filters)) <TAB>  <TAB> if comparison is None: <TAB>  <TAB>  <TAB> comparison = self.assertEqual <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> comparison(n, expected) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> except Exception: <MASK> raise <TAB>  <TAB> time.sleep(0.1)",if i == MAX_ITER - 1 :,130
"def _api_snapshot_delete(self, drbd_rsc_name, snap_name): <TAB> with lin_drv(self.default_uri) as lin: <MASK> lin.connect() <TAB>  <TAB> snap_reply = lin.snapshot_delete( <TAB>  <TAB>  <TAB> rsc_name=drbd_rsc_name, snapshot_name=snap_name <TAB>  <TAB> ) <TAB>  <TAB> return snap_reply",if not lin . connected :,107
"def response(resp): <TAB> results = [] <TAB> search_results = loads(resp.text) <TAB> # return empty array if there are no results <TAB> if not search_results.get(""query"", {}).get(""search""): <TAB>  <TAB> return [] <TAB> # parse results <TAB> for result in search_results[""query""][""search""]: <MASK> continue <TAB>  <TAB> url = ( <TAB>  <TAB>  <TAB> base_url.format(language=resp.search_params[""language""]) <TAB>  <TAB>  <TAB> + ""wiki/"" <TAB>  <TAB>  <TAB> + quote(result[""title""].replace("" "", ""_"").encode(""utf-8"")) <TAB>  <TAB> ) <TAB>  <TAB> # append result <TAB>  <TAB> results.append({""url"": url, ""title"": result[""title""], ""content"": """"}) <TAB> # return results <TAB> return results","if result . get ( ""snippet"" , """" ) . startswith ( ""#REDIRECT"" ) :",191
"def getBody(self, path): <TAB> if path == """": <TAB>  <TAB> return ""This server has "" + str(self.__fileProvider.count()) + "" files."" <TAB> else: <TAB>  <TAB> downloadCounts = self.__fileProvider.get(path).downloadCount <MASK> return str(downloadCounts[path]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""0""",if path in downloadCounts :,93
"def parse_entrypoints(self, content: str, root=None) -> RootDependency: <TAB> if root is None: <TAB>  <TAB> root = RootDependency() <TAB> entrypoints = [] <TAB> group = ""console_scripts"" <TAB> for line in content.split(""\n""): <TAB>  <TAB> line = line.strip() <TAB>  <TAB> if not line or line[0] in ""#;"":  # ignore comments <TAB>  <TAB>  <TAB> continue <MASK> group = line[1:-1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> entrypoints.append(EntryPoint.parse(text=line, group=group)) <TAB> root.entrypoints = tuple(entrypoints) <TAB> return root","if line [ 0 ] == ""["" and line [ - 1 ] == ""]"" :",162
"def _validate_callbacks(cls, callbacks): <TAB> for callback in callbacks: <MASK> if issubclass(callback, Callback): <TAB>  <TAB>  <TAB>  <TAB> raise TypeError(""Make sure to instantiate the callbacks."") <TAB>  <TAB>  <TAB> raise TypeError(""Only accepts a `callbacks` instance."")","if not isinstance ( callback , Callback ) :",70
"def detab(self, text): <TAB> """"""Remove a tab from the front of each line of the given text."""""" <TAB> newtext = [] <TAB> lines = text.split(""\n"") <TAB> for line in lines: <MASK> newtext.append(line[markdown.TAB_LENGTH :]) <TAB>  <TAB> elif not line.strip(): <TAB>  <TAB>  <TAB> newtext.append("""") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> return ""\n"".join(newtext), ""\n"".join(lines[len(newtext) :])","if line . startswith ( "" "" * markdown . TAB_LENGTH ) :",134
"def triger_check_network(self, fail=False, force=False): <TAB> time_now = time.time() <TAB> if not force: <TAB>  <TAB> if self._checking_num > 0: <TAB>  <TAB>  <TAB> return <MASK> # Fail or unknown <TAB>  <TAB>  <TAB> if time_now - self.last_check_time < 3: <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if time_now - self.last_check_time < 10: <TAB>  <TAB>  <TAB>  <TAB> return <TAB> self.last_check_time = time_now <TAB> threading.Thread(target=self._simple_check_worker).start()","if fail or self . network_stat != ""OK"" :",161
"def wrapper(*args, **kwargs): <TAB> if is_profiling_enabled(section): <TAB>  <TAB> global _profile_nesting <TAB>  <TAB> profile = get_global_profile() <TAB>  <TAB> _profile_nesting += 1 <MASK> profile.enable() <TAB>  <TAB> result = func(*args, **kwargs) <TAB>  <TAB> _profile_nesting -= 1 <TAB>  <TAB> if _profile_nesting == 0: <TAB>  <TAB>  <TAB> profile.disable() <TAB>  <TAB> return result <TAB> else: <TAB>  <TAB> return func(*args, **kwargs)",if _profile_nesting == 1 :,128
"def get_sequence_type_str(x: Sequence[Any]) -> str: <TAB> container_type = type(x).__name__ <TAB> if not x: <MASK> return ""[]"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return container_type + ""([])"" <TAB> elem_type = get_type_str(x[0]) <TAB> if container_type == ""list"": <TAB>  <TAB> if len(x) == 1: <TAB>  <TAB>  <TAB> return ""["" + elem_type + ""]"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""["" + elem_type + "", ...]"" <TAB> else: <TAB>  <TAB> if len(x) == 1: <TAB>  <TAB>  <TAB> return f""{container_type}([{elem_type}])"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return f""{container_type}([{elem_type}, ...])""","if container_type == ""list"" :",196
"def attempts(self): <TAB> # We can cache as we deal with history server <TAB> if not hasattr(self, ""_attempts""): <TAB>  <TAB> task_attempts = self.job.api.task_attempts(self.job.id, self.id)[""taskAttempts""] <MASK> self._attempts = [ <TAB>  <TAB>  <TAB>  <TAB> Attempt(self, attempt) for attempt in task_attempts[""taskAttempt""] <TAB>  <TAB>  <TAB> ] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._attempts = [] <TAB> return self._attempts",if task_attempts :,122
"def __call__(self, message, keyname): <TAB> if keyname in self.keyring: <TAB>  <TAB> key = self.keyring[keyname] <TAB>  <TAB> if isinstance(key, Key) and key.algorithm == GSS_TSIG: <MASK> GSSTSigAdapter.parse_tkey_and_step(key, message, keyname) <TAB>  <TAB> return key <TAB> else: <TAB>  <TAB> return None",if message :,98
"def location_dec(str): <TAB> head = int(str[0]) <TAB> str = str[1:] <TAB> rows = head <TAB> cols = int(len(str) / rows) + 1 <TAB> out = """" <TAB> full_row = len(str) % head <TAB> for c in range(cols): <TAB>  <TAB> for r in range(rows): <MASK> continue <TAB>  <TAB>  <TAB> if r < full_row: <TAB>  <TAB>  <TAB>  <TAB> char = str[r * cols + c] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> char = str[cols * full_row + (r - full_row) * (cols - 1) + c] <TAB>  <TAB>  <TAB> out += char <TAB> return parse.unquote(out).replace(""^"", ""0"")",if c == ( cols - 1 ) and r >= full_row :,192
"def request(self): <TAB> if ""Cookie"" in self._req._headers: <TAB>  <TAB> c = self._req._headers[""Cookie""].split(""; "") <MASK> return cookies.cookie({x[0]: x[2] for x in [x.partition(""="") for x in c]}) <TAB> return cookies.cookie({})",if c [ 0 ] :,80
"def bulk_enable_accounts(account_names): <TAB> """"""Bulk enable accounts"""""" <TAB> for account_name in account_names: <TAB>  <TAB> account = Account.query.filter(Account.name == account_name).first() <MASK> app.logger.debug(""Enabling account %s"", account.name) <TAB>  <TAB>  <TAB> account.active = True <TAB>  <TAB>  <TAB> db.session.add(account) <TAB> db.session.commit() <TAB> db.session.close()",if account :,114
"def acquire(self, blocking=True, timeout=None): <TAB> if not blocking and timeout is not None: <TAB>  <TAB> raise ValueError(""can't specify timeout for non-blocking acquire"") <TAB> rc = False <TAB> endtime = None <TAB> self._cond.acquire() <TAB> while self._value == 0: <TAB>  <TAB> if not blocking: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if timeout is not None: <MASK> endtime = _time() + timeout <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> timeout = endtime - _time() <TAB>  <TAB>  <TAB>  <TAB> if timeout <= 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> self._cond.wait(timeout) <TAB> else: <TAB>  <TAB> self._value = self._value - 1 <TAB>  <TAB> rc = True <TAB> self._cond.release() <TAB> return rc",if endtime is None :,194
"def _sorted_layers(self, structure, top_layer_id): <TAB> """"""Return the image layers sorted"""""" <TAB> sorted_layers = [] <TAB> next_layer = top_layer_id <TAB> while next_layer: <TAB>  <TAB> sorted_layers.append(next_layer) <TAB>  <TAB> if ""json"" not in structure[""repolayers""][next_layer]:  # v2 <TAB>  <TAB>  <TAB> break <MASK> break <TAB>  <TAB> next_layer = structure[""repolayers""][next_layer][""json""][""parent""] <TAB>  <TAB> if not next_layer: <TAB>  <TAB>  <TAB> break <TAB> return sorted_layers","if ""parent"" not in structure [ ""repolayers"" ] [ next_layer ] [ ""json"" ] :",162
"def on_change(self, data): <TAB> # loop over tp_clipboard views <TAB> for window in sublime.windows(): <TAB>  <TAB> for view in window.views(): <MASK> file_name = view.file_name() <TAB>  <TAB>  <TAB>  <TAB> # ammo <TAB>  <TAB>  <TAB>  <TAB> if view.settings().get(""tp_ammo"", False): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.update(view) <TAB>  <TAB>  <TAB>  <TAB> elif file_name and file_name.endswith( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> global_settings(""ammo_file_extension"", "".ammo"") <TAB>  <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.update(view)","if view . get_status ( ""inactive"" ) and view . settings ( ) . get ( ""tp_append"" , False ) :",175
"def _maintain_pool(self): <TAB> waiting = self._docker_interface.services_waiting_by_constraints() <TAB> active = self._docker_interface.nodes_active_by_constraints() <TAB> for constraints, needed_dict in self._state.slots_needed(waiting, active).items(): <TAB>  <TAB> services = needed_dict[""services""] <TAB>  <TAB> nodes = needed_dict[""nodes""] <TAB>  <TAB> slots_needed = needed_dict[""slots_needed""] <TAB>  <TAB> if slots_needed > 0: <TAB>  <TAB>  <TAB> self._spawn_nodes(constraints, services, slots_needed) <MASK> self._destroy_nodes(constraints, nodes, slots_needed)",elif slots_needed < 0 :,164
"def _update_vhosts_addrs_ssl(self, vhosts): <TAB> """"""Update a list of raw parsed vhosts to include global address sslishness"""""" <TAB> addr_to_ssl = self._build_addr_to_ssl() <TAB> for vhost in vhosts: <TAB>  <TAB> for addr in vhost.addrs: <TAB>  <TAB>  <TAB> addr.ssl = addr_to_ssl[addr.normalized_tuple()] <MASK> vhost.ssl = True",if addr . ssl :,114
"def gather_files(fileset): <TAB> common_type = get_common_filetype(fileset) <TAB> files = [] <TAB> for file in fileset.file: <TAB>  <TAB> filename = file.name <MASK> filename = {} <TAB>  <TAB>  <TAB> filename[file.name] = {""is_include_file"": True} <TAB>  <TAB> if file.file_type != common_type: <TAB>  <TAB>  <TAB> if type(filename) == str: <TAB>  <TAB>  <TAB>  <TAB> filename = {} <TAB>  <TAB>  <TAB> filename[file.name] = {""file_type"": file.file_type} <TAB>  <TAB> files.append(filename) <TAB> return files",if file . is_include_file == True :,158
"def _get_resource_group_name_of_staticsite(client, static_site_name): <TAB> static_sites = client.list() <TAB> for static_site in static_sites: <MASK> resource_group = _parse_resource_group_from_arm_id(static_site.id) <TAB>  <TAB>  <TAB> if resource_group: <TAB>  <TAB>  <TAB>  <TAB> return resource_group <TAB> raise CLIError( <TAB>  <TAB> ""Static site was '{}' not found in subscription."".format(static_site_name) <TAB> )",if static_site . name . lower ( ) == static_site_name . lower ( ) :,144
"def triger_check_network(self, fail=False, force=False): <TAB> time_now = time.time() <TAB> if not force: <MASK> return <TAB>  <TAB> if fail or self.network_stat != ""OK"": <TAB>  <TAB>  <TAB> # Fail or unknown <TAB>  <TAB>  <TAB> if time_now - self.last_check_time < 3: <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if time_now - self.last_check_time < 10: <TAB>  <TAB>  <TAB>  <TAB> return <TAB> self.last_check_time = time_now <TAB> threading.Thread(target=self._simple_check_worker).start()",if self . _checking_num > 0 :,161
"def _gen(): <TAB> for i in dataset(): <TAB>  <TAB> if isinstance(i, tuple) or isinstance(i, list): <MASK> yield i <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if fn(i) is True: <TAB>  <TAB>  <TAB>  <TAB> yield i",if fn ( * i ) is True :,72
"def _merge_dict(d1, d2): <TAB> # Modifies d1 in-place to take values from d2 <TAB> # if the nested keys from d2 are present in d1. <TAB> # https://stackoverflow.com/a/10704003/4488789 <TAB> for k, v2 in d2.items(): <TAB>  <TAB> v1 = d1.get(k)  # returns None if v1 has no such key <TAB>  <TAB> if v1 is None: <TAB>  <TAB>  <TAB> raise Exception(""{} is not recognized by client_config"".format(k)) <MASK> _merge_dict(v1, v2) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> d1[k] = v2 <TAB> return d1","if isinstance ( v1 , Mapping ) and isinstance ( v2 , Mapping ) :",184
"def OnRelease(self, evt): <TAB> if self.isDrag: <TAB>  <TAB> parent = self.GetParent() <TAB>  <TAB> DrawSash(parent, self.px, self.py, self.side) <TAB>  <TAB> self.ReleaseMouse() <TAB>  <TAB> self.isDrag = False <MASK> parent.AddLeaf(MV_VER, self.py) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> parent.AddLeaf(MV_HOR, self.px) <TAB> else: <TAB>  <TAB> evt.Skip()",if self . side == MV_HOR :,131
"def check_zookeeper_metrics(): <TAB> response = get_metrics_prom(dcos_api_session, dcos_api_session.masters[0]) <TAB> for family in text_string_to_metric_families(response.text): <TAB>  <TAB> for sample in family.samples: <MASK> assert sample[1][""dcos_component_name""] == ""ZooKeeper"" <TAB>  <TAB>  <TAB>  <TAB> return <TAB> raise Exception(""Expected ZooKeeper zookeeper_avg_latency metric not found"")","if sample [ 0 ] == ""zookeeper_avg_latency"" :",141
"def scan_patterns(self, kind): <TAB> """"""Parse the config section into a list of patterns, preserving order."""""" <TAB> d = self.scan_d(kind) <TAB> aList = [] <TAB> seen = set() <TAB> for key in d: <TAB>  <TAB> value = d.get(key) <MASK> g.trace(""duplicate key"", key) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> seen.add(key) <TAB>  <TAB>  <TAB> aList.append(self.msf.Pattern(key, value)) <TAB> return aList",if key in seen :,129
"def foundNestedPseudoClass(self): <TAB> i = self.pos + 1 <TAB> openParen = 0 <TAB> while i < len(self.source_text): <TAB>  <TAB> ch = self.source_text[i] <TAB>  <TAB> if ch == ""{"": <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> elif ch == ""("": <TAB>  <TAB>  <TAB> # pseudoclasses can contain () <TAB>  <TAB>  <TAB> openParen += 1 <TAB>  <TAB> elif ch == "")"": <MASK> return False <TAB>  <TAB>  <TAB> openParen -= 1 <TAB>  <TAB> elif ch == "";"" or ch == ""}"": <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> i += 1 <TAB> return False",if openParen == 0 :,155
"def append(self, child): <TAB> if child not in (None, self): <TAB>  <TAB> tag = child_tag(self._tag) <TAB>  <TAB> if tag: <MASK> if child.tag != tag: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> child = Html(tag, child) <TAB>  <TAB>  <TAB> elif not child.startswith(""<%s"" % tag): <TAB>  <TAB>  <TAB>  <TAB> child = Html(tag, child) <TAB>  <TAB> super().append(child)","if isinstance ( child , Html ) :",113
"def forward(self, x, activate=True, norm=True): <TAB> for layer in self.order: <TAB>  <TAB> if layer == ""conv"": <MASK> x = self.padding_layer(x) <TAB>  <TAB>  <TAB> x = self.conv(x) <TAB>  <TAB> elif layer == ""norm"" and norm and self.with_norm: <TAB>  <TAB>  <TAB> x = self.norm(x) <TAB>  <TAB> elif layer == ""act"" and activate and self.with_activation: <TAB>  <TAB>  <TAB> x = self.activate(x) <TAB> return x",if self . with_explicit_padding :,138
"def get_tasks(self): <TAB> for task in asyncio.all_tasks(loop=self.middleware.loop): <TAB>  <TAB> formatted = None <TAB>  <TAB> frame = None <TAB>  <TAB> frames = [] <TAB>  <TAB> for frame in task.get_stack(): <TAB>  <TAB>  <TAB> cur_frame = get_frame_details(frame, self.logger) <MASK> frames.append(cur_frame) <TAB>  <TAB> if frame: <TAB>  <TAB>  <TAB> formatted = traceback.format_stack(frame) <TAB>  <TAB> yield { <TAB>  <TAB>  <TAB> ""stack"": formatted, <TAB>  <TAB>  <TAB> ""frames"": frames, <TAB>  <TAB> }",if cur_frame :,146
"def _read_row_from_packet(self, packet): <TAB> row = [] <TAB> for encoding, converter in self.converters: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> data = packet.read_length_coded_string() <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB> # No more columns in this row <TAB>  <TAB>  <TAB> # See https://github.com/PyMySQL/PyMySQL/pull/434 <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if data is not None: <TAB>  <TAB>  <TAB> if encoding is not None: <TAB>  <TAB>  <TAB>  <TAB> data = data.decode(encoding) <MASK> print(""DEBUG: DATA = "", data) <TAB>  <TAB>  <TAB> if converter is not None: <TAB>  <TAB>  <TAB>  <TAB> data = converter(data) <TAB>  <TAB> row.append(data) <TAB> return tuple(row)",if DEBUG :,186
"def get_child(self, name): <TAB> if self.isdir: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self.data[name] <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> if not self.case_sensitive: <TAB>  <TAB>  <TAB>  <TAB> for childname, child in list(self.data.items()): <MASK> return child <TAB>  <TAB>  <TAB> raise",if childname . lower ( ) == name . lower ( ) :,100
"def _line_generator(fh, skip_blanks=False, strip=True): <TAB> for line in fh: <TAB>  <TAB> if strip: <TAB>  <TAB>  <TAB> line = line.strip() <TAB>  <TAB> skip = False <MASK> skip = line.isspace() or not line <TAB>  <TAB> if not skip: <TAB>  <TAB>  <TAB> yield line",if skip_blanks :,82
"def atleast_3d(*arys): <TAB> if len(arys) == 1: <TAB>  <TAB> arr = array(arys[0]) <TAB>  <TAB> if ndim(arr) == 0: <TAB>  <TAB>  <TAB> arr = expand_dims(arr, axis=(0, 1, 2)) <MASK> arr = expand_dims(arr, axis=(0, 2)) <TAB>  <TAB> elif ndim(arr) == 2: <TAB>  <TAB>  <TAB> arr = expand_dims(arr, axis=2) <TAB>  <TAB> return arr <TAB> else: <TAB>  <TAB> return [atleast_3d(arr) for arr in arys]",elif ndim ( arr ) == 1 :,147
"def scan_resource_conf(self, conf): <TAB> os_profile = conf.get(""os_profile"") <TAB> if os_profile: <TAB>  <TAB> os_profile = os_profile[0] <TAB>  <TAB> custom_data = os_profile.get(""custom_data"") <TAB>  <TAB> if custom_data: <TAB>  <TAB>  <TAB> custom_data = custom_data[0] <TAB>  <TAB>  <TAB> if isinstance(custom_data, str): <MASK> return CheckResult.FAILED <TAB> return CheckResult.PASSED",if string_has_secrets ( custom_data ) :,134
"def __call__(self, trainer): <TAB> observation = trainer.observation <TAB> if self.key in observation: <TAB>  <TAB> loss = observation[self.key] <MASK> self.min_loss = loss <TAB>  <TAB>  <TAB> self.best_model = trainer.updater.epoch <TAB>  <TAB>  <TAB> src = ""%s.%d"" % (self.prefix, self.best_model) <TAB>  <TAB>  <TAB> dest = os.path.join(trainer.out, ""%s.%s"" % (self.prefix, self.suffix)) <TAB>  <TAB>  <TAB> if os.path.lexists(dest): <TAB>  <TAB>  <TAB>  <TAB> os.remove(dest) <TAB>  <TAB>  <TAB> os.symlink(src, dest) <TAB>  <TAB>  <TAB> logging.info(""best model is "" + src)",if self . best_model == - 1 or loss < self . min_loss :,190
"def dump_prefs(self): <TAB> ret = """" <TAB> for pref in self.prefs: <MASK> value = str(self.prefs[pref].value) <TAB>  <TAB> elif type(self.prefs[pref].value) == bool: <TAB>  <TAB>  <TAB> value = ""true"" if self.prefs[pref].value == True else ""false"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = '""%s""' % self.prefs[pref].value <TAB>  <TAB> ret += pref + "": "" + value + "" ("" + self.prefs[pref].anon_source + "")\n"" <TAB> return ret",if type ( self . prefs [ pref ] . value ) == int :,150
"def translate_isinstance( <TAB> builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Optional[Value]: <TAB> # Special case builtins.isinstance <TAB> if ( <TAB>  <TAB> len(expr.args) == 2 <TAB>  <TAB> and expr.arg_kinds == [ARG_POS, ARG_POS] <TAB>  <TAB> and isinstance(expr.args[1], (RefExpr, TupleExpr)) <TAB> ): <TAB>  <TAB> irs = builder.flatten_classes(expr.args[1]) <MASK> return builder.builder.isinstance_helper( <TAB>  <TAB>  <TAB>  <TAB> builder.accept(expr.args[0]), irs, expr.line <TAB>  <TAB>  <TAB> ) <TAB> return None",if irs is not None :,155
"def autoname(self): <TAB> naming_method = frappe.db.get_value(""HR Settings"", None, ""emp_created_by"") <TAB> if not naming_method: <TAB>  <TAB> throw(_(""Please setup Employee Naming System in Human Resource > HR Settings"")) <TAB> else: <MASK> set_name_by_naming_series(self) <TAB>  <TAB> elif naming_method == ""Employee Number"": <TAB>  <TAB>  <TAB> self.name = self.employee_number <TAB>  <TAB> elif naming_method == ""Full Name"": <TAB>  <TAB>  <TAB> self.set_employee_name() <TAB>  <TAB>  <TAB> self.name = self.employee_name <TAB> self.employee = self.name","if naming_method == ""Naming Series"" :",169
"def search_expr(sheet, expr, reverse=False): <TAB> for i in rotateRange(len(sheet.rows), sheet.cursorRowIndex, reverse=reverse): <TAB>  <TAB> try: <MASK> sheet.cursorRowIndex = i <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> vd.exceptionCaught(e) <TAB> vd.fail(f""no {sheet.rowtype} where {expr}"")","if sheet . evalExpr ( expr , sheet . rows [ i ] ) :",119
"def _targets(self, urls, querystring): <TAB> for input, output in urls: <TAB>  <TAB> response = self.client.get(u""/1/%s"" % input, follow=True) <TAB>  <TAB> if output == 404: <TAB>  <TAB>  <TAB> eq_(404, response.status_code) <MASK> chain = [u[0] for u in response.redirect_chain] <TAB>  <TAB>  <TAB> assert output in chain <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> r = response.redirect_chain <TAB>  <TAB>  <TAB> r.reverse() <TAB>  <TAB>  <TAB> final = urlparse(r[0][0]) <TAB>  <TAB>  <TAB> eq_(output, final.path) <TAB>  <TAB>  <TAB> eq_(querystring, final.query)","elif output . startswith ( ""http"" ) :",167
"def get_local_cache(self, past, data, from_file, temp_id): <TAB> """"""parse individual cached geometry if there is any"""""" <TAB> cache = [] <TAB> if self.accumulative: <TAB>  <TAB> if from_file and len(past) > 0: <TAB>  <TAB>  <TAB> cache = past[temp_id] <MASK> cache = data.get(temp_id, []) <TAB> return cache",if not from_file and len ( data ) > 0 :,109
"def _parse_abbrev_table(self): <TAB> """"""Parse the abbrev table from the stream"""""" <TAB> map = {} <TAB> self.stream.seek(self.offset) <TAB> while True: <TAB>  <TAB> decl_code = struct_parse( <TAB>  <TAB>  <TAB> struct=self.structs.Dwarf_uleb128(""""), stream=self.stream <TAB>  <TAB> ) <MASK> break <TAB>  <TAB> declaration = struct_parse( <TAB>  <TAB>  <TAB> struct=self.structs.Dwarf_abbrev_declaration, stream=self.stream <TAB>  <TAB> ) <TAB>  <TAB> map[decl_code] = AbbrevDecl(decl_code, declaration) <TAB> return map",if decl_code == 0 :,157
"def mFRIDAY( <TAB> self,): <TAB> try: <TAB>  <TAB> _type = FRIDAY <TAB>  <TAB> _channel = DEFAULT_CHANNEL <TAB>  <TAB> pass <TAB>  <TAB> self.match(""fri"") <TAB>  <TAB> alt10 = 2 <TAB>  <TAB> LA10_0 = self.input.LA(1) <TAB>  <TAB> if LA10_0 == 100: <TAB>  <TAB>  <TAB> alt10 = 1 <MASK> pass <TAB>  <TAB>  <TAB> self.match(""day"") <TAB>  <TAB> self._state.type = _type <TAB>  <TAB> self._state.channel = _channel <TAB> finally: <TAB>  <TAB> pass",if alt10 == 1 :,144
"def __getattr__(self, key): <TAB> from mongokit.schema_document import i18n <TAB> if key in self: <TAB>  <TAB> if isinstance(self[key], i18n): <MASK> return self[key].get(self._doc._fallback_lang) <TAB>  <TAB>  <TAB> return self[key][self._doc._current_lang] <TAB>  <TAB> return self[key]",if self . _doc . _current_lang not in self [ key ] :,108
"def compact_repr(record): <TAB> parts = [] <TAB> for key in record.__attributes__: <TAB>  <TAB> value = getattr(record, key) <TAB>  <TAB> if not value: <TAB>  <TAB>  <TAB> continue <MASK> value = HIDE_LIST <TAB>  <TAB> elif key == FEATS: <TAB>  <TAB>  <TAB> value = format_feats(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = repr(value) <TAB>  <TAB> value = capped_str(value) <TAB>  <TAB> parts.append(""%s=%s"" % (key, value)) <TAB> return ""%s(%s)"" % (record.__class__.__name__, "", "".join(parts))","if isinstance ( value , list ) :",152
"def pre_validate(self, form): <TAB> if self.data: <TAB>  <TAB> values = list(c[0] for c in self.choices) <TAB>  <TAB> for d in self.data: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.gettext(u""'%(value)s' is not a valid choice for this field"") <TAB>  <TAB>  <TAB>  <TAB>  <TAB> % dict(value=d) <TAB>  <TAB>  <TAB>  <TAB> )",if d not in values :,108
"def _sql_like_to_regex(pattern, escape): <TAB> cur_i = 0 <TAB> pattern_length = len(pattern) <TAB> while cur_i < pattern_length: <TAB>  <TAB> nxt_i = cur_i + 1 <TAB>  <TAB> cur = pattern[cur_i] <TAB>  <TAB> nxt = pattern[nxt_i] if nxt_i < pattern_length else None <TAB>  <TAB> skip = 1 <TAB>  <TAB> if nxt is not None and escape is not None and cur == escape: <TAB>  <TAB>  <TAB> yield nxt <TAB>  <TAB>  <TAB> skip = 2 <MASK> yield "".*"" <TAB>  <TAB> elif cur == ""_"": <TAB>  <TAB>  <TAB> yield ""."" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield cur <TAB>  <TAB> cur_i += skip","elif cur == ""%"" :",169
"def find_caller(stack): <TAB> """"""Finds info about first non-sqlalchemy call in stack"""""" <TAB> for frame in stack: <TAB>  <TAB> # We don't care about sqlalchemy internals <TAB>  <TAB> module = inspect.getmodule(frame[0]) <MASK> continue <TAB>  <TAB> if module.__name__.startswith(""sqlalchemy""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> return (module.__name__,) + tuple(frame[2:4]) + (frame[4][0].strip(),) <TAB> log.warning(""Transaction from unknown origin"") <TAB> return None, None, None, None","if not hasattr ( module , ""__name__"" ) :",137
"def _get_normal_median_depth(normal_counts): <TAB> depths = [] <TAB> with open(normal_counts) as in_handle: <TAB>  <TAB> header = None <TAB>  <TAB> for line in in_handle: <TAB>  <TAB>  <TAB> if header is None and not line.startswith(""@""): <TAB>  <TAB>  <TAB>  <TAB> header = line.strip().split() <MASK> n_vals = dict(zip(header, line.strip().split())) <TAB>  <TAB>  <TAB>  <TAB> depths.append(int(n_vals[""REF_COUNT""]) + int(n_vals[""ALT_COUNT""])) <TAB> return np.median(depths)",elif header :,145
"def get_pool(self, *args, **kw): <TAB> key = self._serialize(*args, **kw) <TAB> try: <TAB>  <TAB> return self.pools[key] <TAB> except KeyError: <TAB>  <TAB> self._create_pool_mutex.acquire() <TAB>  <TAB> try: <MASK> kw.pop(""sa_pool_key"", None) <TAB>  <TAB>  <TAB>  <TAB> pool = self.poolclass( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> lambda: self.module.connect(*args, **kw), **self.kw <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> self.pools[key] = pool <TAB>  <TAB>  <TAB>  <TAB> return pool <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return self.pools[key] <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self._create_pool_mutex.release()",if key not in self . pools :,193
"def add(self, field, value, boost=None): <TAB> match = {""value"": value} <TAB> if boost: <MASK> match[""boost""] = boost <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> match[""boost""] = float(boost) <TAB>  <TAB> self._values[field] = match <TAB>  <TAB> return <TAB> self._values[field] = value","if isinstance ( boost , ( float , int ) ) :",94
"def get_shape(shape): <TAB> """"""Convert the shape to correct dtype and vars."""""" <TAB> ret = [] <TAB> for dim in shape: <TAB>  <TAB> if isinstance(dim, tvm.tir.IntImm): <MASK> ret.append(dim) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> val = int(dim) <TAB>  <TAB>  <TAB>  <TAB> assert val <= np.iinfo(np.int32).max <TAB>  <TAB>  <TAB>  <TAB> ret.append(tvm.tir.IntImm(""int32"", val)) <TAB>  <TAB> elif isinstance(dim, tvm.tir.Any): <TAB>  <TAB>  <TAB> ret.append(te.var(""any_dim"", ""int32"")) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret.append(dim) <TAB> return ret","if libinfo ( ) [ ""INDEX_DEFAULT_I64"" ] == ""ON"" :",194
"def _find_icacls_exe(): <TAB> if os.name == ""nt"": <TAB>  <TAB> paths = [ <TAB>  <TAB>  <TAB> os.path.expandvars(r""%windir%\{0}"").format(subdir) <TAB>  <TAB>  <TAB> for subdir in (""system32"", ""SysWOW64"") <TAB>  <TAB> ] <TAB>  <TAB> for path in paths: <TAB>  <TAB>  <TAB> icacls_path = next( <TAB>  <TAB>  <TAB>  <TAB> iter(fn for fn in os.listdir(path) if fn.lower() == ""icacls.exe""), None <TAB>  <TAB>  <TAB> ) <MASK> icacls_path = os.path.join(path, icacls_path) <TAB>  <TAB>  <TAB>  <TAB> return icacls_path <TAB> return None",if icacls_path is not None :,177
"def mlt_version_is_greater_correct(test_version): <TAB> runtime_ver = mlt_version.split(""."") <TAB> test_ver = test_version.split(""."") <TAB> if runtime_ver[0] > test_ver[0]: <TAB>  <TAB> return True <TAB> elif runtime_ver[0] == test_ver[0]: <TAB>  <TAB> if runtime_ver[1] > test_ver[1]: <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> elif runtime_ver[1] == test_ver[1]: <MASK> return True <TAB> return False",if runtime_ver [ 2 ] > test_ver [ 2 ] :,148
"def get_ready_conn(self, host): <TAB> conn = None <TAB> self._lock.acquire() <TAB> try: <TAB>  <TAB> if host in self._hostmap: <TAB>  <TAB>  <TAB> for c in self._hostmap[host]: <MASK> self._readymap[c] = 0 <TAB>  <TAB>  <TAB>  <TAB>  <TAB> conn = c <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB> finally: <TAB>  <TAB> self._lock.release() <TAB> return conn",if self . _readymap [ c ] :,115
"def to_svc_hst_distinct_lists(ref, tab): <TAB> r = {""hosts"": [], ""services"": []} <TAB> for e in tab: <TAB>  <TAB> cls = e.__class__ <MASK> name = e.get_dbg_name() <TAB>  <TAB>  <TAB> r[""services""].append(name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = e.get_dbg_name() <TAB>  <TAB>  <TAB> r[""hosts""].append(name) <TAB> return r","if cls . my_type == ""service"" :",119
"def playerData(s): <TAB> """"""Returns a list of tuples of original string and dict of values"""""" <TAB> p = [] <TAB> i = 0 <TAB> while True: <TAB>  <TAB> match = re_input.match(s, pos=i) <TAB>  <TAB> if match is None: <TAB>  <TAB>  <TAB> return p <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> d = match.groupdict() <MASK> d[""degree""], d[""kwargs""] = getArgs(d[""args""]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> d[""degree""], d[""kwargs""] = """", {} <TAB>  <TAB>  <TAB> del d[""args""] <TAB>  <TAB>  <TAB> p.append((match.group().strip(), d)) <TAB>  <TAB>  <TAB> i = match.end() <TAB> return","if d [ ""args"" ] is not None :",178
"def _params_for_TXT(self, record): <TAB> for value in record.values: <TAB>  <TAB> field_type = ""TXT"" <MASK> field_type = ""DKIM"" <TAB>  <TAB>  <TAB> value = value.replace(""\\;"", "";"") <TAB>  <TAB> yield { <TAB>  <TAB>  <TAB> ""target"": value, <TAB>  <TAB>  <TAB> ""subDomain"": record.name, <TAB>  <TAB>  <TAB> ""ttl"": record.ttl, <TAB>  <TAB>  <TAB> ""fieldType"": field_type, <TAB>  <TAB> }",if self . _is_valid_dkim ( value ) :,126
"def create(self, values): <TAB> conn = self.get_connection() <TAB> object_classes = self.structural_classes + [self.object_class] <TAB> attrs = [(""objectClass"", object_classes)] <TAB> for k, v in values.iteritems(): <TAB>  <TAB> if k == ""id"" or k in self.attribute_ignore: <TAB>  <TAB>  <TAB> continue <MASK> attr_type = self.attribute_mapping.get(k, k) <TAB>  <TAB>  <TAB> attrs.append((attr_type, [v])) <TAB> if ""groupOfNames"" in object_classes and self.use_dumb_member: <TAB>  <TAB> attrs.append((""member"", [self.DUMB_MEMBER_DN])) <TAB> conn.add_s(self._id_to_dn(values[""id""]), attrs) <TAB> return values",if v is not None :,196
"def get_new_unlinked_nodes( <TAB> before_inputted_nodes, before_input_sockets, input_sockets, nodes_dict): <TAB> affected_nodes = [] <TAB> for node_id, socket in zip(before_inputted_nodes, before_input_sockets): <TAB>  <TAB> if not socket in input_sockets: <TAB>  <TAB>  <TAB> # if the node has been deleted it is not affected <TAB>  <TAB>  <TAB> if node_id in nodes_dict: <MASK> affected_nodes.append(node_id) <TAB> return affected_nodes",if not node_id in affected_nodes :,141
"def show_panel(panel_id): <TAB> # Iterate positions to find where panel is and bring it to front. <TAB> for position in _positions_names: <TAB>  <TAB> pos_panel_ids = _get_position_panels(position) <TAB>  <TAB> if len(pos_panel_ids) == 0: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if len(pos_panel_ids) == 1: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> panel_widget = _get_panels_widgets_dict(gui.editor_window)[panel_id] <TAB>  <TAB> notebook = _position_notebooks[position] <TAB>  <TAB> for i in range(0, notebook.get_n_pages()): <TAB>  <TAB>  <TAB> notebook_page = notebook.get_nth_page(i) <MASK> notebook.set_current_page(i)",if notebook_page == panel_widget :,197
"def merge(self, abort=False, message=None): <TAB> """"""Merge remote branch or reverts the merge."""""" <TAB> if abort: <TAB>  <TAB> self.execute([""update"", ""--clean"", "".""]) <TAB> elif self.needs_merge(): <MASK> self.execute([""update"", ""--clean"", ""remote(.)""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.configure_merge() <TAB>  <TAB>  <TAB> # Fallback to merge <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> self.execute([""merge"", ""-r"", ""remote(.)""]) <TAB>  <TAB>  <TAB> except RepositoryException as error: <TAB>  <TAB>  <TAB>  <TAB> if error.retcode == 255: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # Nothing to merge <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB>  <TAB> self.execute([""commit"", ""--message"", ""Merge""])",if self . needs_ff ( ) :,191
"def runButtons(action): <TAB> global sqlUpdate <TAB> if action == ""Clear"": <TAB>  <TAB> app.text(LABS[""run""], replace=True) <TAB>  <TAB> app.message(LABS[""run""], """", bg=""grey"") <TAB>  <TAB> log(""SQL cleared"") <TAB> elif action == ""Run"": <TAB>  <TAB> app.message(LABS[""run""], """") <TAB>  <TAB> sql = app.text(LABS[""run""]).strip() <MASK> runSql(sql) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> app.message(LABS[""run""], """", bg=""grey"") <TAB> app.text(LABS[""run""], focus=True)",if len ( sql ) > 0 :,156
"def receive_loop(self): <TAB> while not self._stoped: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> rd, _, _ = select.select([self.teredo_sock], [], [], 0.5) <MASK> self.receive_ra_packet() <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> logger.exception(""receive procedure fail once: %r"", e) <TAB>  <TAB>  <TAB> pass",if rd and not self . _stoped :,105
"def add_items(self, model, objs): <TAB> search_fields = model.get_search_fields() <TAB> if not search_fields: <TAB>  <TAB> return <TAB> indexers = [ObjectIndexer(obj, self.backend) for obj in objs] <TAB> # TODO: Delete unindexed objects while dealing with proxy models. <TAB> if indexers: <TAB>  <TAB> content_type_pk = get_content_type_pk(model) <TAB>  <TAB> update_method = ( <TAB>  <TAB>  <TAB> self.add_items_upsert <MASK> else self.add_items_update_then_create <TAB>  <TAB> ) <TAB>  <TAB> update_method(content_type_pk, indexers)",if self . _enable_upsert,160
"def __init__(self, service: RestClient, **k_args: Dict[str, str]): <TAB> self.path: str = None <TAB> self.httpMethod: str = None <TAB> self.service: RestClient = service <TAB> self.__dict__.update(k_args) <TAB> self.path_args: List[str] = [] <TAB> self.query_args: List[str] = [] <TAB> if hasattr(self, ""parameters""): <TAB>  <TAB> for key, value in self.parameters.items(): <MASK> self.path_args.append(key) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.query_args.append(key)","if value [ ""location"" ] == ""path"" :",165
"def insertion_unsort(str, extended): <TAB> """"""3.2 Insertion unsort coding"""""" <TAB> oldchar = 0x80 <TAB> result = [] <TAB> oldindex = -1 <TAB> for c in extended: <TAB>  <TAB> index = pos = -1 <TAB>  <TAB> char = ord(c) <TAB>  <TAB> curlen = selective_len(str, char) <TAB>  <TAB> delta = (curlen + 1) * (char - oldchar) <TAB>  <TAB> while 1: <TAB>  <TAB>  <TAB> index, pos = selective_find(str, c, index, pos) <MASK> break <TAB>  <TAB>  <TAB> delta += index - oldindex <TAB>  <TAB>  <TAB> result.append(delta - 1) <TAB>  <TAB>  <TAB> oldindex = index <TAB>  <TAB>  <TAB> delta = 0 <TAB>  <TAB> oldchar = char <TAB> return result",if index == - 1 :,190
"def get_sorted_entry(field, bookid): <TAB> if field == ""title"" or field == ""authors"": <TAB>  <TAB> book = calibre_db.get_filtered_book(bookid) <TAB>  <TAB> if book: <MASK> return json.dumps({""sort"": book.sort}) <TAB>  <TAB>  <TAB> elif field == ""authors"": <TAB>  <TAB>  <TAB>  <TAB> return json.dumps({""author_sort"": book.author_sort}) <TAB> return """"","if field == ""title"" :",111
"def _convert_tstamp(out): <TAB> # Searches for top-level timestamp attributes or within dictionaries <TAB> if ""timestamp"" in out: <TAB>  <TAB> # Convert UNIX to datetime object <TAB>  <TAB> f = float(out[""timestamp""]) <TAB>  <TAB> out[""timestamp""] = datetime.fromtimestamp(f / 1000) <TAB> else: <TAB>  <TAB> for ticker, data in out.items(): <MASK> f = float(data[""timestamp""]) <TAB>  <TAB>  <TAB>  <TAB> data[""timestamp""] = datetime.fromtimestamp(f / 1000) <TAB>  <TAB>  <TAB>  <TAB> out[ticker] = data <TAB> return out","if ""timestamp"" in data :",142
"def write_urls(self, person): <TAB> """"""Write URL and EMAIL properties of a VCard."""""" <TAB> url_list = person.get_url_list() <TAB> for url in url_list: <TAB>  <TAB> href = url.get_path() <MASK> if url.get_type() == UrlType(UrlType.EMAIL): <TAB>  <TAB>  <TAB>  <TAB> if href.startswith(""mailto:""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> href = href[len(""mailto:"") :] <TAB>  <TAB>  <TAB>  <TAB> self.writeln(""EMAIL:%s"" % self.esc(href)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.writeln(""URL:%s"" % self.esc(href))",if href :,158
"def get_range(min, max): <TAB> if max < min: <TAB>  <TAB> min, max = max, min <TAB> elif min == max: <MASK> min, max = 2 * min, 0 <TAB>  <TAB> elif min > 0: <TAB>  <TAB>  <TAB> min, max = 0, 2 * min <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> min, max = -1, 1 <TAB> return min, max",if min < 0 :,99
"def __init__(self, mapping=None): <TAB> if isinstance(mapping, MultiDict): <TAB>  <TAB> dict.__init__(self, ((k, l[:]) for k, l in mapping.iterlists())) <TAB> elif isinstance(mapping, dict): <TAB>  <TAB> tmp = {} <TAB>  <TAB> for key, value in mapping.iteritems(): <MASK> value = list(value) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> value = [value] <TAB>  <TAB>  <TAB> tmp[key] = value <TAB>  <TAB> dict.__init__(self, tmp) <TAB> else: <TAB>  <TAB> tmp = {} <TAB>  <TAB> for key, value in mapping or (): <TAB>  <TAB>  <TAB> tmp.setdefault(key, []).append(value) <TAB>  <TAB> dict.__init__(self, tmp)","if isinstance ( value , ( tuple , list ) ) :",182
"def modified_precision(candidate, references, n): <TAB> candidate_ngrams = list(ngrams(candidate, n)) <TAB> if len(candidate_ngrams) == 0: <TAB>  <TAB> return 0 <TAB> c_words = set(candidate_ngrams) <TAB> for word in c_words: <TAB>  <TAB> count_w = candidate_ngrams.count(word) + 1 <TAB>  <TAB> count_max = 0 <TAB>  <TAB> for reference in references: <TAB>  <TAB>  <TAB> reference_ngrams = list(ngrams(reference, n)) <TAB>  <TAB>  <TAB> count = reference_ngrams.count(word) + 1 <MASK> count_max = count <TAB> return min(count_w, count_max) / (len(candidate) + len(c_words))",if count > count_max :,176
"def reverse_adjust_line_according_to_hunks(self, hunks, line): <TAB> for hunk in reversed(hunks): <TAB>  <TAB> head_start = hunk.head_start <TAB>  <TAB> saved_start = hunk.saved_start <TAB>  <TAB> if hunk.saved_length == 0: <TAB>  <TAB>  <TAB> saved_start += 1 <TAB>  <TAB> elif hunk.head_length == 0: <TAB>  <TAB>  <TAB> saved_start -= 1 <TAB>  <TAB> head_end = head_start + hunk.head_length <TAB>  <TAB> saved_end = saved_start + hunk.saved_length <TAB>  <TAB> if saved_end <= line: <TAB>  <TAB>  <TAB> return head_end + line - saved_end <MASK> return head_start <TAB> # fails to find matching <TAB> return line",elif saved_start <= line :,193
"def indent_xml(elem, level=0): <TAB> """"""Do our pretty printing and make Matt very happy."""""" <TAB> i = ""\n"" + level * ""  "" <TAB> if elem: <TAB>  <TAB> if not elem.text or not elem.text.strip(): <TAB>  <TAB>  <TAB> elem.text = i + ""  "" <MASK> elem.tail = i <TAB>  <TAB> for elem in elem: <TAB>  <TAB>  <TAB> indent_xml(elem, level + 1) <TAB>  <TAB> if not elem.tail or not elem.tail.strip(): <TAB>  <TAB>  <TAB> elem.tail = i <TAB> else: <TAB>  <TAB> if level and (not elem.tail or not elem.tail.strip()): <TAB>  <TAB>  <TAB> elem.tail = i",if not elem . tail or not elem . tail . strip ( ) :,177
"def test_infer_shape_matrix(self): <TAB> # Testing the infer_shape with a matrix. <TAB> x = theano.tensor.matrix() <TAB> for op in self.ops: <MASK> continue <TAB>  <TAB> if op.return_index: <TAB>  <TAB>  <TAB> f = op(x)[2] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> f = op(x)[1] <TAB>  <TAB> self._compile_and_check( <TAB>  <TAB>  <TAB> [x], <TAB>  <TAB>  <TAB> [f], <TAB>  <TAB>  <TAB> [np.asarray(np.array([[2, 1], [3, 2], [2, 3]]), dtype=config.floatX)], <TAB>  <TAB>  <TAB> self.op_class, <TAB>  <TAB> )",if not op . return_inverse :,170
"def drop_lists(value): <TAB> out = {} <TAB> for key, val in value.items(): <TAB>  <TAB> val = val[0] <TAB>  <TAB> if isinstance(key, bytes): <TAB>  <TAB>  <TAB> key = str(key, ""utf-8"") <MASK> val = str(val, ""utf-8"") <TAB>  <TAB> out[key] = val <TAB> return out","if isinstance ( val , bytes ) :",96
"def malloc(self, size): <TAB> # return a block of right size (possibly rounded up) <TAB> assert 0 <= size < sys.maxsize <TAB> if os.getpid() != self._lastpid: <TAB>  <TAB> self.__init__()  # reinitialize after fork <TAB> with self._lock: <TAB>  <TAB> self._free_pending_blocks() <TAB>  <TAB> size = self._roundup(max(size, 1), self._alignment) <TAB>  <TAB> (arena, start, stop) = self._malloc(size) <TAB>  <TAB> new_stop = start + size <MASK> self._free((arena, new_stop, stop)) <TAB>  <TAB> block = (arena, start, new_stop) <TAB>  <TAB> self._allocated_blocks.add(block) <TAB>  <TAB> return block",if new_stop < stop :,188
"def ContinueStatement(self, label, **kwargs): <TAB> if label is None: <TAB>  <TAB> self.emit(""JUMP"", self.implicit_continues[-1]) <TAB> else: <TAB>  <TAB> label = label.get(""name"") <MASK> raise MakeError(""SyntaxError"", ""Undefined label '%s'"" % label) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.emit(""JUMP"", self.declared_continue_labels[label])",if label not in self . declared_continue_labels :,111
"def parse_counter_style_name(tokens, counter_style): <TAB> tokens = remove_whitespace(tokens) <TAB> if len(tokens) == 1: <TAB>  <TAB> (token,) = tokens <MASK> if token.lower_value in (""decimal"", ""disc""): <TAB>  <TAB>  <TAB>  <TAB> if token.lower_value not in counter_style: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return token.value <TAB>  <TAB>  <TAB> elif token.lower_value != ""none"": <TAB>  <TAB>  <TAB>  <TAB> return token.value","if token . type == ""ident"" :",122
"def __call__(self, data): <TAB> num_points = data.pos.shape[0] <TAB> new_data = Data() <TAB> for key in data.keys: <TAB>  <TAB> if key == KDTREE_KEY: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> item = data[key] <MASK> item = item[self._indices].clone() <TAB>  <TAB> elif torch.is_tensor(item): <TAB>  <TAB>  <TAB> item = item.clone() <TAB>  <TAB> setattr(new_data, key, item) <TAB> return new_data",if torch . is_tensor ( item ) and num_points == item . shape [ 0 ] :,144
"def HandleEvent(self, event): <TAB> e_id = event.GetId() <TAB> if e_id in self.handlers: <TAB>  <TAB> handler = self.handlers[e_id] <TAB>  <TAB> try: <MASK> return handler(event) <TAB>  <TAB> except RuntimeError: <TAB>  <TAB>  <TAB> self.RemoveHandlerForID(e_id) <TAB> else: <TAB>  <TAB> event.Skip() <TAB> return False",if handler :,102
"def try_append_extension(self, path): <TAB> append_setting = self.get_append_extension_setting() <TAB> if self.settings.get(append_setting, False): <TAB>  <TAB> if not self.is_copy_original_name(path): <TAB>  <TAB>  <TAB> _, new_path_extension = os.path.splitext(path) <MASK> argument_name = self.get_argument_name() <TAB>  <TAB>  <TAB>  <TAB> if argument_name is None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _, extension = os.path.splitext(self.view.file_name()) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _, extension = os.path.splitext(argument_name) <TAB>  <TAB>  <TAB>  <TAB> path += extension <TAB> return path","if new_path_extension == """" :",181
"def _get_namespace(self, gl_client, gl_namespace, lazy=False): <TAB> try: <MASK> return gl_client.groups.get(gl_namespace.attributes[""id""], lazy=lazy) <TAB>  <TAB> if gl_namespace.attributes[""kind""] == ""user"": <TAB>  <TAB>  <TAB> return gl_client.users.get(gl_client.user.attributes[""id""], lazy=lazy) <TAB>  <TAB> # Note: This doesn't seem to work for IDs retrieved via the namespaces API; the IDs are <TAB>  <TAB> # different. <TAB>  <TAB> return gl_client.users.get(gl_namespace.attributes[""id""], lazy=lazy) <TAB> except gitlab.GitlabGetError: <TAB>  <TAB> return None","if gl_namespace . attributes [ ""kind"" ] == ""group"" :",179
"def removeReadOnly(self, files): <TAB> # Removes all read-on ly flags in a for all files <TAB> for filepath in files: <MASK> # Windows only needs S_IWRITE, but we bitwise-or with current perms to preserve other permission bits on Linux <TAB>  <TAB>  <TAB> os.chmod(filepath, stat.S_IWRITE | os.stat(filepath).st_mode)",if os . path . isfile ( filepath ) :,99
"def initiate_all_local_variables_instances( <TAB> nodes, local_variables_instances, all_local_variables_instances): <TAB> for node in nodes: <MASK> new_var = LocalIRVariable(node.variable_declaration) <TAB>  <TAB>  <TAB> if new_var.name in all_local_variables_instances: <TAB>  <TAB>  <TAB>  <TAB> new_var.index = all_local_variables_instances[new_var.name].index + 1 <TAB>  <TAB>  <TAB> local_variables_instances[node.variable_declaration.name] = new_var <TAB>  <TAB>  <TAB> all_local_variables_instances[node.variable_declaration.name] = new_var",if node . variable_declaration :,158
"def find_comment(line): <TAB> """"""Finds the index of a comment # and returns None if not found"""""" <TAB> instring, instring_char = False, """" <TAB> for i, char in enumerate(line): <MASK> if instring: <TAB>  <TAB>  <TAB>  <TAB> if char == instring_char: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> instring = False <TAB>  <TAB>  <TAB>  <TAB>  <TAB> instring_char = """" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> instring = True <TAB>  <TAB>  <TAB>  <TAB> instring_char = char <TAB>  <TAB> elif char == ""#"": <TAB>  <TAB>  <TAB> if not instring: <TAB>  <TAB>  <TAB>  <TAB> return i <TAB> return None","if char in ( '""' , ""'"" ) :",155
"def set_study_system_attr(self, study_id: int, key: str, value: Any) -> None: <TAB> with _create_scoped_session(self.scoped_session, True) as session: <TAB>  <TAB> study = models.StudyModel.find_or_raise_by_id(study_id, session) <TAB>  <TAB> attribute = models.StudySystemAttributeModel.find_by_study_and_key( <TAB>  <TAB>  <TAB> study, key, session <TAB>  <TAB> ) <MASK> attribute = models.StudySystemAttributeModel( <TAB>  <TAB>  <TAB>  <TAB> study_id=study_id, key=key, value_json=json.dumps(value) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> session.add(attribute) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> attribute.value_json = json.dumps(value)",if attribute is None :,196
"def clear_doc(self, docname: str) -> None: <TAB> for sChild in self._children: <TAB>  <TAB> sChild.clear_doc(docname) <TAB>  <TAB> if sChild.declaration and sChild.docname == docname: <TAB>  <TAB>  <TAB> sChild.declaration = None <TAB>  <TAB>  <TAB> sChild.docname = None <TAB>  <TAB>  <TAB> sChild.line = None <MASK> sChild.siblingAbove.siblingBelow = sChild.siblingBelow <TAB>  <TAB>  <TAB> if sChild.siblingBelow is not None: <TAB>  <TAB>  <TAB>  <TAB> sChild.siblingBelow.siblingAbove = sChild.siblingAbove <TAB>  <TAB>  <TAB> sChild.siblingAbove = None <TAB>  <TAB>  <TAB> sChild.siblingBelow = None",if sChild . siblingAbove is not None :,189
"def test_sum_values_list_group_by(self): <TAB> ret = ( <TAB>  <TAB> await Book.annotate(sum=Sum(""rating"")) <TAB>  <TAB> .group_by(""author_id"") <TAB>  <TAB> .values_list(""author_id"", ""sum"") <TAB> ) <TAB> for item in ret: <TAB>  <TAB> author_id = item[0] <TAB>  <TAB> sum_ = item[1] <MASK> self.assertEqual(sum_, 45.0) <TAB>  <TAB> elif author_id == self.a2.pk: <TAB>  <TAB>  <TAB> self.assertEqual(sum_, 10.0)",if author_id == self . a1 . pk :,151
"def save_claims_for_resolve(self, claim_infos): <TAB> to_save = {} <TAB> for info in claim_infos: <TAB>  <TAB> if ""value"" in info: <MASK> to_save[info[""claim_id""]] = info <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for key in (""certificate"", ""claim""): <TAB>  <TAB>  <TAB>  <TAB> if info.get(key, {}).get(""value""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> to_save[info[key][""claim_id""]] = info[key] <TAB> return self.save_claims(to_save.values())","if info [ ""value"" ] :",141
"def utcoffset(self, dt): <TAB> if not dst_only: <TAB>  <TAB> dt_n = dt.replace(tzinfo=None) <MASK> return timedelta(hours=-1) <TAB> return timedelta(hours=0)","if dt_start <= dt_n < dt_end and getattr ( dt_n , ""fold"" , 0 ) :",80
"def find_comment(line): <TAB> """"""Finds the index of a comment # and returns None if not found"""""" <TAB> instring, instring_char = False, """" <TAB> for i, char in enumerate(line): <TAB>  <TAB> if char in ('""', ""'""): <MASK> if char == instring_char: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> instring = False <TAB>  <TAB>  <TAB>  <TAB>  <TAB> instring_char = """" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> instring = True <TAB>  <TAB>  <TAB>  <TAB> instring_char = char <TAB>  <TAB> elif char == ""#"": <TAB>  <TAB>  <TAB> if not instring: <TAB>  <TAB>  <TAB>  <TAB> return i <TAB> return None",if instring :,155
"def __subclasshook__(cls, C): <TAB> if cls is Coroutine: <TAB>  <TAB> mro = get_mro(C) <TAB>  <TAB> for method in (""__await__"", ""send"", ""throw"", ""close""): <TAB>  <TAB>  <TAB> for base in mro: <MASK> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return NotImplemented <TAB>  <TAB> return True <TAB> return NotImplemented",if method in base . __dict__ :,97
"def GetFile(cls, session, sig, mode=""r""): <TAB> sig = sig[: cls.HASH_LEN] <TAB> while len(sig) > 0: <TAB>  <TAB> fn = cls.SaveFile(session, sig) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if os.path.exists(fn): <TAB>  <TAB>  <TAB>  <TAB> return (open(fn, mode), sig) <TAB>  <TAB> except (IOError, OSError): <TAB>  <TAB>  <TAB> pass <MASK> sig = sig[:-1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if ""r"" in mode: <TAB>  <TAB>  <TAB>  <TAB> return (None, sig) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return (open(fn, mode), sig) <TAB> # Not reached <TAB> return (None, None)",if len ( sig ) > 1 :,180
"def _store_pickle_output(self, pickle_output): <TAB> if pickle_output: <TAB>  <TAB> if self.output_options.output is None: <TAB>  <TAB>  <TAB> self.error(""Can't use without --output"", ""pickle-output"") <MASK> self.error( <TAB>  <TAB>  <TAB>  <TAB> ""Must specify %s file for --output"" % load_pytd.PICKLE_EXT, <TAB>  <TAB>  <TAB>  <TAB> ""pickle-output"", <TAB>  <TAB>  <TAB> ) <TAB> self.output_options.pickle_output = pickle_output",elif not load_pytd . is_pickle ( self . output_options . output ) :,141
"def the_func(*args, **kwargs): <TAB> try: <TAB>  <TAB> # Grab API version from type of controller <TAB>  <TAB> controller = args[0] <TAB>  <TAB> version = controller.version <TAB>  <TAB> return func(*args, **kwargs) <TAB> except Exception as e: <MASK> # Version-specific behaviour <TAB>  <TAB>  <TAB> quantum_error_class = quantum_error_dict[version] <TAB>  <TAB>  <TAB> raise quantum_error_class(e) <TAB>  <TAB> # otherwise just re-raise <TAB>  <TAB> raise",if errors is not None and type ( e ) in errors :,133
"def publish_create(cls, payload): <TAB> try: <MASK> thread = eventlet.spawn(workflows.get_engine().process, payload) <TAB>  <TAB>  <TAB> cls.threads.append(thread) <TAB> except Exception: <TAB>  <TAB> traceback.print_exc() <TAB>  <TAB> print(payload)","if isinstance ( payload , wf_ex_db . WorkflowExecutionDB ) :",87
"def get_suggestion(self, buffer: ""Buffer"", document: Document) -> Optional[Suggestion]: <TAB> history = buffer.history <TAB> # Consider only the last line for the suggestion. <TAB> text = document.text.rsplit(""\n"", 1)[-1] <TAB> # Only create a suggestion when this is not an empty line. <TAB> if text.strip(): <TAB>  <TAB> # Find first matching line in history. <TAB>  <TAB> for string in reversed(list(history.get_strings())): <TAB>  <TAB>  <TAB> for line in reversed(string.splitlines()): <MASK> return Suggestion(line[len(text) :]) <TAB> return None",if line . startswith ( text ) :,151
"def _get_parameter_scope(param, cmd_list): <TAB> if not cmd_list: <TAB>  <TAB> return ""N/A (NOT FOUND)"" <TAB> test_list = cmd_list[0].split("" "") <TAB> while len(test_list) > 0: <TAB>  <TAB> test_entry = "" "".join(test_list) <TAB>  <TAB> all_match = True <TAB>  <TAB> for entry in cmd_list[1:]: <MASK> all_match = False <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if not all_match: <TAB>  <TAB>  <TAB> test_list.pop() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return test_entry <TAB> return ""_ROOT_""",if test_entry not in entry :,165
"def __call__(self, params): <TAB> for param in params: <TAB>  <TAB> # If we've seen this parameter before, use the previously <TAB>  <TAB> # constructed optimizer. <MASK> optim = self.optim_objs[param] <TAB>  <TAB> # If we've never seen this parameter before, construct <TAB>  <TAB> # an Adam optimizer and keep track of it. <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> optim = torch.optim.Adam([param], **self.optim_args) <TAB>  <TAB>  <TAB> self.optim_objs[param] = optim <TAB>  <TAB> # Take a gradient step for the parameter param. <TAB>  <TAB> optim.step()",if param in self . optim_objs :,151
"def filter_database(db, user, filter_name): <TAB> """"""Returns a list of person handles"""""" <TAB> filt = MatchesFilter([filter_name]) <TAB> filt.requestprepare(db, user) <MASK> user.begin_progress( <TAB>  <TAB>  <TAB> _(""Finding relationship paths""), <TAB>  <TAB>  <TAB> _(""Retrieving all sub-filter matches""), <TAB>  <TAB>  <TAB> db.get_number_of_people(), <TAB>  <TAB> ) <TAB> matches = [] <TAB> for handle in db.iter_person_handles(): <TAB>  <TAB> person = db.get_person_from_handle(handle) <TAB>  <TAB> if filt.apply(db, person): <TAB>  <TAB>  <TAB> matches.append(handle) <TAB>  <TAB> if user: <TAB>  <TAB>  <TAB> user.step_progress() <TAB> if user: <TAB>  <TAB> user.end_progress() <TAB> filt.requestreset() <TAB> return matches",if user :,198
"def get_independence_days(self, year): <TAB> """"""returns a possibly empty list of (date, holiday_name) tuples"""""" <TAB> days = [] <TAB> if year > 2004: <TAB>  <TAB> actual_date = date(year, 5, 4) <TAB>  <TAB> days = [(actual_date, ""Restoration of Independence Day"")] <MASK> days += [ <TAB>  <TAB>  <TAB>  <TAB> ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.find_following_working_day(actual_date), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Restoration of Independence Observed"", <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ] <TAB> return days",if actual_date . weekday ( ) in self . get_weekend_days ( ) :,161
"def on_mode_paused(result, mode, *args): <TAB> from deluge.ui.console.widgets.popup import PopupsHandler <TAB> if isinstance(mode, PopupsHandler): <MASK> # If popups are not removed, they are still referenced in the memory <TAB>  <TAB>  <TAB> # which can cause issues as the popup's screen will not be destroyed. <TAB>  <TAB>  <TAB> # This can lead to the popup border being visible for short periods <TAB>  <TAB>  <TAB> # while the current modes' screen is repainted. <TAB>  <TAB>  <TAB> log.error( <TAB>  <TAB>  <TAB>  <TAB> 'Mode ""%s"" still has popups available after being paused.' <TAB>  <TAB>  <TAB>  <TAB> "" Ensure all popups are removed on pause!"", <TAB>  <TAB>  <TAB>  <TAB> mode.popup.title, <TAB>  <TAB>  <TAB> )",if mode . popup is not None :,186
def step(self): <TAB> if not self.fully_grown: <MASK> # Set as fully grown <TAB>  <TAB>  <TAB> self.fully_grown = True <TAB>  <TAB>  <TAB> self.countdown = self.model.grass_regrowth_time <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.countdown -= 1,if self . countdown <= 0 :,86
"def getOnlineBuilders(self): <TAB> all_workers = yield self.master.data.get((""workers"",)) <TAB> online_builderids = set() <TAB> for worker in all_workers: <TAB>  <TAB> connected = worker[""connected_to""] <MASK> continue <TAB>  <TAB> builders = worker[""configured_on""] <TAB>  <TAB> builderids = [builder[""builderid""] for builder in builders] <TAB>  <TAB> online_builderids.update(builderids) <TAB> defer.returnValue(list(online_builderids))",if not connected :,124
"def _latest_major(alternatives): <TAB> max_major = -1 <TAB> for a in alternatives: <MASK> major, _, _, _ = components(a, strict=False) <TAB>  <TAB>  <TAB> max_major = max(major, max_major) <TAB> return max_major","if is_version_identifier ( a , strict = False ) :",80
"def getVar(self, name): <TAB> value = self.tinfoil.run_command(""dataStoreConnectorFindVar"", self.dsindex, name) <TAB> overrides = None <TAB> if isinstance(value, dict): <MASK> value[""_content""] = self.tinfoil._reconvert_type( <TAB>  <TAB>  <TAB>  <TAB> value[""_content""], value[""_connector_origtype""] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> del value[""_connector_origtype""] <TAB>  <TAB> if ""_connector_overrides"" in value: <TAB>  <TAB>  <TAB> overrides = value[""_connector_overrides""] <TAB>  <TAB>  <TAB> del value[""_connector_overrides""] <TAB> return value, overrides","if ""_connector_origtype"" in value :",158
"def initAbbrev(self): <TAB> k = self <TAB> c = k.c <TAB> d = c.config.getAbbrevDict() <TAB> if d: <TAB>  <TAB> for key in d: <TAB>  <TAB>  <TAB> commandName = d.get(key) <MASK> pass  # Must be done later in k.registerCommand. <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.initOneAbbrev(commandName, key)","if commandName . startswith ( ""press-"" ) and commandName . endswith ( ""-button"" ) :",123
def restore_text(self): <TAB> if self.source_is_console(): <TAB>  <TAB> cb = self._last_console_cb <TAB> else: <TAB>  <TAB> cb = self._last_editor_cb <TAB> if cb is None: <TAB>  <TAB> if self.is_plain_text_mode(): <TAB>  <TAB>  <TAB> self.plain_text.clear() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.rich_text.clear() <TAB> else: <TAB>  <TAB> func = cb[0] <TAB>  <TAB> args = cb[1:] <TAB>  <TAB> func(*args) <MASK> self.switch_to_rich_text() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.switch_to_plain_text(),if get_meth_class_inst ( func ) is self . rich_text :,180
"def get_test_layer(): <TAB> layers = get_bb_var(""BBLAYERS"").split() <TAB> testlayer = None <TAB> for l in layers: <MASK> l = os.path.expanduser(l) <TAB>  <TAB> if ""/meta-selftest"" in l and os.path.isdir(l): <TAB>  <TAB>  <TAB> testlayer = l <TAB>  <TAB>  <TAB> break <TAB> return testlayer","if ""~"" in l :",98
"def __parse_query(self, model, iter_, data): <TAB> f, b = self.__filter, self.__bg_filter <TAB> if f is None and b is None: <TAB>  <TAB> return True <TAB> else: <TAB>  <TAB> album = model.get_album(iter_) <TAB>  <TAB> if album is None: <TAB>  <TAB>  <TAB> return True <MASK> return f(album) <TAB>  <TAB> elif f is None: <TAB>  <TAB>  <TAB> return b(album) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return b(album) and f(album)",elif b is None :,130
"def iter(iterable, sentinel=None): <TAB> if sentinel is None: <TAB>  <TAB> i = getattr(iterable, ""__iter__"", None) <TAB>  <TAB> if i is not None: <TAB>  <TAB>  <TAB> return i() <TAB>  <TAB> i = getattr(iterable, ""__getitem__"", None) <TAB>  <TAB> if i is not None: <TAB>  <TAB>  <TAB> return _iter_getitem(iterable) <MASK> return list(iterable).__iter__() <TAB>  <TAB> raise TypeError(""object is not iterable"") <TAB> if callable(iterable): <TAB>  <TAB> return _iter_callable(iterable, sentinel) <TAB> raise TypeError(""iter(v, w): v must be callable"")","if JS ( ""@{{iterable}} instanceof Array"" ) :",153
def run(self): <TAB> # Prime the coroutine. <TAB> next(self.coro) <TAB> try: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> with self.abort_lock: <MASK> return <TAB>  <TAB>  <TAB> # Get the message from the previous stage. <TAB>  <TAB>  <TAB> msg = self.in_queue.get() <TAB>  <TAB>  <TAB> if msg is POISON: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> with self.abort_lock: <TAB>  <TAB>  <TAB>  <TAB> if self.abort_flag: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> # Send to consumer. <TAB>  <TAB>  <TAB> self.coro.send(msg) <TAB> except: <TAB>  <TAB> self.abort_all(sys.exc_info()) <TAB>  <TAB> return,if self . abort_flag :,179
"def get_name_from_types(types: Iterable[Union[Type, StrawberryUnion]]): <TAB> names = [] <TAB> for type_ in types: <MASK> return type_.name <TAB>  <TAB> elif hasattr(type_, ""_type_definition""): <TAB>  <TAB>  <TAB> name = capitalize_first(type_._type_definition.name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = capitalize_first(type_.__name__) <TAB>  <TAB> names.append(name) <TAB> return """".join(names)","if isinstance ( type_ , StrawberryUnion ) :",131
"def _get_user_from_email(group, email): <TAB> from sentry.models import User <TAB> # TODO(dcramer): we should encode the userid in emails so we can avoid this <TAB> for user in User.objects.filter(email__iexact=email): <TAB>  <TAB> # Make sure that the user actually has access to this project <TAB>  <TAB> context = access.from_user(user=user, organization=group.organization) <MASK> logger.warning(""User %r does not have access to group %r"", user, group) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> return user",if not context . has_team ( group . project . team ) :,149
"def _make_binary_stream(s, encoding): <TAB> try: <TAB>  <TAB> if _py3k: <MASK> s = s.encode(encoding) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if type(s) is not str: <TAB>  <TAB>  <TAB>  <TAB> s = s.encode(encoding) <TAB>  <TAB> from io import BytesIO <TAB>  <TAB> rv = BytesIO(s) <TAB> except ImportError: <TAB>  <TAB> rv = StringIO(s) <TAB> return rv","if isinstance ( s , str ) :",115
"def error_messages(file_list, files_removed): <TAB> if files_removed is None: <TAB>  <TAB> return <TAB> for remove_this, reason in files_removed: <TAB>  <TAB> if file_list is not None: <TAB>  <TAB>  <TAB> file_list.remove(remove_this) <TAB>  <TAB> if reason == 0: <TAB>  <TAB>  <TAB> print("" REMOVED : ("" + str(remove_this) + "")   is not PNG file format"") <MASK> print("" REMOVED : ("" + str(remove_this) + "")   already exists"") <TAB>  <TAB> elif reason == 2: <TAB>  <TAB>  <TAB> print("" REMOVED : ("" + str(remove_this) + "")   file unreadable"")",elif reason == 1 :,161
"def _eyeAvailable(*args, **kwargs): <TAB> try: <TAB>  <TAB> r = pylink.getEyeLink().eyeAvailable() <MASK> return EyeTrackerConstants.getName(EyeTrackerConstants.LEFT_EYE) <TAB>  <TAB> elif r == 1: <TAB>  <TAB>  <TAB> return EyeTrackerConstants.getName(EyeTrackerConstants.RIGHT_EYE) <TAB>  <TAB> elif r == 2: <TAB>  <TAB>  <TAB> return EyeTrackerConstants.getName(EyeTrackerConstants.BINOCULAR) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return EyeTrackerConstants.UNDEFINED <TAB> except Exception as e: <TAB>  <TAB> printExceptionDetailsToStdErr()",if r == 0 :,157
"def ignore_callback_errors(self, ignore): <TAB> EventEmitter.ignore_callback_errors.fset(self, ignore) <TAB> for emitter in self._emitters.values(): <MASK> emitter.ignore_callback_errors = ignore <TAB>  <TAB> elif isinstance(emitter, EmitterGroup): <TAB>  <TAB>  <TAB> emitter.ignore_callback_errors_all(ignore)","if isinstance ( emitter , EventEmitter ) :",95
"def test_empty_condition_node(cond_node): <TAB> for node in [cond_node.true_node, cond_node.false_node]: <MASK> continue <TAB>  <TAB> if type(node) is CodeNode and BaseNode.test_empty_node(node.node): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if BaseNode.test_empty_node(node): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> return False <TAB> return True",if node is None :,108
"def _confirm_deps(self, trans): <TAB> if [pkgs for pkgs in trans.dependencies if pkgs]: <TAB>  <TAB> dia = AptConfirmDialog(trans, parent=self.parent) <TAB>  <TAB> res = dia.run() <TAB>  <TAB> dia.hide() <MASK> log.debug(""Response is: %s"" % res) <TAB>  <TAB>  <TAB> if self.finish_handler: <TAB>  <TAB>  <TAB>  <TAB> log.debug(""Finish_handler..."") <TAB>  <TAB>  <TAB>  <TAB> self.finish_handler(trans, 0, self.data) <TAB>  <TAB>  <TAB> return <TAB> self._run_transaction(trans)",if res != Gtk . ResponseType . OK :,147
"def get_human_type(self, translate=True): <TAB> """"""Returns prettified name of the object type"""""" <TAB> try: <TAB>  <TAB> obj_name = re.match("".*\.(?P<name>\w+)$"", self.object_type).group(""name"") <TAB>  <TAB> pattern = re.compile(""([A-Z][A-Z][a-z])|([a-z][A-Z])"") <TAB>  <TAB> human_type = pattern.sub( <TAB>  <TAB>  <TAB> lambda m: m.group()[:1] + "" "" + m.group()[1:], obj_name <TAB>  <TAB> ) <MASK> human_type = _(human_type) <TAB>  <TAB> return human_type <TAB> except Exception: <TAB>  <TAB> return self.object_type",if translate :,174
"def ascii85decode(data): <TAB> n = b = 0 <TAB> out = """" <TAB> for c in data: <TAB>  <TAB> if ""!"" <= c and c <= ""u"": <TAB>  <TAB>  <TAB> n += 1 <TAB>  <TAB>  <TAB> b = b * 85 + (ord(c) - 33) <MASK> out += struct.pack("">L"", b) <TAB>  <TAB>  <TAB>  <TAB> n = b = 0 <TAB>  <TAB> elif c == ""z"": <TAB>  <TAB>  <TAB> assert n == 0 <TAB>  <TAB>  <TAB> out += ""\0\0\0\0"" <TAB>  <TAB> elif c == ""~"": <TAB>  <TAB>  <TAB> if n: <TAB>  <TAB>  <TAB>  <TAB> for _ in range(5 - n): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> b = b * 85 + 84 <TAB>  <TAB>  <TAB>  <TAB> out += struct.pack("">L"", b)[: n - 1] <TAB>  <TAB>  <TAB> break <TAB> return out",if n == 5 :,200
"def calculateModifiedAttributes(self, fit, runTime, forceProjected=False): <TAB> if self.item: <TAB>  <TAB> for effect in self.item.effects.values(): <MASK> effect.handler(fit, self, (""module"",), None, effect=effect)",if effect . runTime == runTime and effect . activeByDefault :,81
"def loadHandler(self, human, values, strict): <TAB> if values[0] == ""pose"": <TAB>  <TAB> poseFile = values[1] <TAB>  <TAB> poseFile = getpath.thoroughFindFile(poseFile, self.paths) <TAB>  <TAB> if not os.path.isfile(poseFile): <MASK> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Could not load pose %s, file does not exist."" % poseFile <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> log.warning(""Could not load pose %s, file does not exist."", poseFile) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.loadPose(poseFile) <TAB>  <TAB> return",if strict :,156
"def get_outdated_docs(self) -> Iterator[str]: <TAB> for docname in self.env.found_docs: <MASK> yield docname <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> targetname = path.join(self.outdir, docname + self.out_suffix) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> targetmtime = path.getmtime(targetname) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> targetmtime = 0 <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> srcmtime = path.getmtime(self.env.doc2path(docname)) <TAB>  <TAB>  <TAB> if srcmtime > targetmtime: <TAB>  <TAB>  <TAB>  <TAB> yield docname <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> # source doesn't exist anymore <TAB>  <TAB>  <TAB> pass",if docname not in self . env . all_docs :,176
"def __init__(self, items=()): <TAB> _dictEntries = [] <TAB> for name, value in items: <MASK> for item in name: <TAB>  <TAB>  <TAB>  <TAB> _dictEntries.append((item, value)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _dictEntries.append((name, value)) <TAB> dict.__init__(self, _dictEntries) <TAB> assert len(self) == len(_dictEntries) <TAB> self.default = None","if isinstance ( name , ( list , tuple , frozenset , set ) ) :",117
"def ping_task(): <TAB> try: <TAB>  <TAB> if self._protocol.peer_manager.peer_is_good(peer): <MASK> self._protocol.add_peer(peer) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> await self._protocol.get_rpc_peer(peer).ping() <TAB> except (asyncio.TimeoutError, RemoteException): <TAB>  <TAB> pass",if peer not in self . _protocol . routing_table . get_peers ( ) :,106
def get_resolved_dependencies(self): <TAB> dependencies = [] <TAB> for dependency in self.envconfig.deps: <TAB>  <TAB> if dependency.indexserver is None: <TAB>  <TAB>  <TAB> package = resolve_package(package_spec=dependency.name) <MASK> dependency = dependency.__class__(package) <TAB>  <TAB> dependencies.append(dependency) <TAB> return dependencies,if package != dependency . name :,93
"def main(msg: func.QueueMessage, dashboard: func.Out[str]) -> None: <TAB> body = msg.get_body() <TAB> logging.info(""heartbeat: %s"", body) <TAB> raw = json.loads(body) <TAB> try: <TAB>  <TAB> entry = TaskHeartbeatEntry.parse_obj(raw) <TAB>  <TAB> task = Task.get_by_task_id(entry.task_id) <MASK> logging.error(task) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> if task: <TAB>  <TAB>  <TAB> task.heartbeat = datetime.utcnow() <TAB>  <TAB>  <TAB> task.save() <TAB> except ValidationError: <TAB>  <TAB> logging.error(""invalid task heartbeat: %s"", raw) <TAB> events = get_events() <TAB> if events: <TAB>  <TAB> dashboard.set(events)","if isinstance ( task , Error ) :",189
"def testTlsServerServeForeverTwice(self): <TAB> """"""Call on serve_forever() twice should result in a runtime error"""""" <TAB> with patch.object(ssl.SSLContext, ""load_cert_chain"") as mock_method: <TAB>  <TAB> server = yield from StartTlsServer( <TAB>  <TAB>  <TAB> context=self.context, address=(""127.0.0.1"", 0), loop=self.loop <TAB>  <TAB> ) <MASK> server_task = asyncio.create_task(server.serve_forever()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> server_task = asyncio.ensure_future(server.serve_forever()) <TAB>  <TAB> yield from server.serving <TAB>  <TAB> with self.assertRaises(RuntimeError): <TAB>  <TAB>  <TAB> yield from server.serve_forever() <TAB>  <TAB> server.server_close()","if PYTHON_VERSION >= ( 3 , 7 ) :",195
"def getInstances_WithSource(self, instancesAmount, sourceObject, scenes): <TAB> if sourceObject is None: <TAB>  <TAB> self.removeAllObjects() <TAB>  <TAB> return [] <TAB> else: <TAB>  <TAB> sourceHash = hash(sourceObject) <TAB>  <TAB> if self.identifier in lastSourceHashes: <MASK> self.removeAllObjects() <TAB>  <TAB> lastSourceHashes[self.identifier] = sourceHash <TAB> return self.getInstances_Base(instancesAmount, sourceObject, scenes)",if lastSourceHashes [ self . identifier ] != sourceHash :,132
"def get_row(self, binary=False, columns=None, raw=None, prep_stmt=None): <TAB> """"""Get the next rows returned by the MySQL server"""""" <TAB> try: <TAB>  <TAB> rows, eof = self.get_rows( <TAB>  <TAB>  <TAB> count=1, binary=binary, columns=columns, raw=raw, prep_stmt=prep_stmt <TAB>  <TAB> ) <MASK> return (rows[0], eof) <TAB>  <TAB> return (None, eof) <TAB> except IndexError: <TAB>  <TAB> # No row available <TAB>  <TAB> return (None, None)",if rows :,135
"def try_adjust_widgets(self): <TAB> if hasattr(self.parent, ""adjust_widgets""): <TAB>  <TAB> self.parent.adjust_widgets() <TAB> if hasattr(self.parent, ""parentApp""): <TAB>  <TAB> if hasattr(self.parent.parentApp, ""_internal_adjust_widgets""): <TAB>  <TAB>  <TAB> self.parent.parentApp._internal_adjust_widgets() <MASK> self.parent.parentApp.adjust_widgets()","if hasattr ( self . parent . parentApp , ""adjust_widgets"" ) :",118
"def parseStatementList(): <TAB> list__py__ = [] <TAB> statement = None <TAB> while index < length: <MASK> break <TAB>  <TAB> statement = parseSourceElement() <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB> ""undefined"" if not ""statement"" in locals() else typeof(statement) <TAB>  <TAB> ) == ""undefined"": <TAB>  <TAB>  <TAB> break <TAB>  <TAB> list__py__.append(statement) <TAB> return list__py__","if match ( ""}"" ) :",103
"def forward(self, Z): <TAB> losses = [] <TAB> context = self.context_cnn(Z) <TAB> targets = self.target_cnn(Z) <TAB> _, _, h, w = Z.shape <TAB> # future prediction <TAB> preds = self.pred_cnn(context) <TAB> for steps_to_ignore in range(h - 1): <TAB>  <TAB> for i in range(steps_to_ignore + 1, h): <TAB>  <TAB>  <TAB> loss = self.compute_loss_h(targets, preds, i) <MASK> losses.append(loss) <TAB> loss = torch.stack(losses).sum() <TAB> return loss",if not torch . isnan ( loss ) :,157
"def __run(self, command): <TAB> sys.stdout, self.stdout = self.stdout, sys.stdout <TAB> sys.stderr, self.stderr = self.stderr, sys.stderr <TAB> try: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> r = eval(command, self.namespace, self.namespace) <MASK> print_(repr(r)) <TAB>  <TAB> except SyntaxError: <TAB>  <TAB>  <TAB> exec(command, self.namespace) <TAB> except: <TAB>  <TAB> if hasattr(sys, ""last_type"") and sys.last_type == SystemExit: <TAB>  <TAB>  <TAB> self.destroy() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> traceback.print_exc() <TAB> sys.stdout, self.stdout = self.stdout, sys.stdout <TAB> sys.stderr, self.stderr = self.stderr, sys.stderr",if r is not None :,192
"def prune(self): <TAB> file = self.file <TAB> if self.remain == 0: <TAB>  <TAB> read_pos = file.tell() <TAB>  <TAB> file.seek(0, 2) <TAB>  <TAB> sz = file.tell() <TAB>  <TAB> file.seek(read_pos) <TAB>  <TAB> if sz == 0: <TAB>  <TAB>  <TAB> # Nothing to prune. <TAB>  <TAB>  <TAB> return <TAB> nf = self.newfile() <TAB> while True: <TAB>  <TAB> data = file.read(COPY_BYTES) <MASK> break <TAB>  <TAB> nf.write(data) <TAB> self.file = nf",if not data :,141
"def reduce_inode(self, f, init): <TAB> for x in range(0, len(self._array), 2): <TAB>  <TAB> key_or_none = self._array[x] <TAB>  <TAB> val_or_node = self._array[x + 1] <MASK> init = val_or_node.reduce_inode(f, init) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> init = f.invoke([init, rt.map_entry(key_or_none, val_or_node)]) <TAB>  <TAB> if rt.reduced_QMARK_(init): <TAB>  <TAB>  <TAB> return init <TAB> return init",if key_or_none is None and val_or_node is not None :,160
"def gen_topython_helper(cw): <TAB> cw.enter_block( <TAB>  <TAB> ""private static BaseException/*!*/ ToPythonHelper(System.Exception clrException)"" <TAB> ) <TAB> allExceps = get_all_exceps([], exceptionHierarchy) <TAB> allExceps.sort(cmp=compare_exceptions) <TAB> for x in allExceps: <MASK> cw.writeline(""#if !SILVERLIGHT"") <TAB>  <TAB> cw.writeline( <TAB>  <TAB>  <TAB> ""if (clrException is %s) return %s;"" <TAB>  <TAB>  <TAB> % (x.ExceptionMappingName, x.MakeNewException()) <TAB>  <TAB> ) <TAB>  <TAB> if not x.silverlightSupported: <TAB>  <TAB>  <TAB> cw.writeline(""#endif"") <TAB> cw.writeline(""return new BaseException(Exception);"") <TAB> cw.exit_block()",if not x . silverlightSupported :,200
"def file_versions(self, path): <TAB> """"""Returns all commits where given file was modified"""""" <TAB> versions = [] <TAB> commits_info = self.commit_info() <TAB> seen_shas = set() <TAB> for commit in commits_info: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> files = self.get_commit_files(commit[""sha""], paths=[path]) <TAB>  <TAB>  <TAB> file_path, file_data = files.items()[0] <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> file_sha = file_data[""sha""] <MASK> continue <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> seen_shas.add(file_sha) <TAB>  <TAB> # Add file info <TAB>  <TAB> commit[""file""] = file_data <TAB>  <TAB> versions.append(file_data) <TAB> return versions",if file_sha in seen_shas :,194
"def _append_fragment(self, ctx, frag_content): <TAB> try: <TAB>  <TAB> ctx[""dest_stream""].write(frag_content) <TAB>  <TAB> ctx[""dest_stream""].flush() <TAB> finally: <MASK> self._write_ytdl_file(ctx) <TAB>  <TAB> if not self.params.get(""keep_fragments"", False): <TAB>  <TAB>  <TAB> os.remove(encodeFilename(ctx[""fragment_filename_sanitized""])) <TAB>  <TAB> del ctx[""fragment_filename_sanitized""]",if self . __do_ytdl_file ( ctx ) :,128
"def gen_segs(glyph): <TAB> bzs = glyph_to_bzs(glyph) <TAB> for sp in bzs: <TAB>  <TAB> bks = segment_sp(sp) <TAB>  <TAB> for i in range(len(bks)): <TAB>  <TAB>  <TAB> bk0, bk1 = bks[i], bks[(i + 1) % len(bks)] <MASK> segstr = seg_to_string(sp, bk0, bk1) <TAB>  <TAB>  <TAB>  <TAB> fn = seg_fn(segstr) <TAB>  <TAB>  <TAB>  <TAB> file(fn, ""w"").write(segstr)",if bk1 != ( bk0 + 1 ) % len ( sp ) or len ( sp [ bk0 ] ) != 2 :,166
"def matches(self, filepath): <TAB> matched = False <TAB> parent_path = os.path.dirname(filepath) <TAB> parent_path_dirs = split_path(parent_path) <TAB> for pattern in self.patterns: <TAB>  <TAB> negative = pattern.exclusion <TAB>  <TAB> match = pattern.match(filepath) <TAB>  <TAB> if not match and parent_path != """": <MASK> match = pattern.match( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> os.path.sep.join(parent_path_dirs[: len(pattern.dirs)]) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if match: <TAB>  <TAB>  <TAB> matched = not negative <TAB> return matched",if len ( pattern . dirs ) <= len ( parent_path_dirs ) :,165
"def __repr__(self): <TAB> text = ""{}("".format(self.__class__.__name__) <TAB> n = len(self) <TAB> for i in range(n): <MASK> if i > 0: <TAB>  <TAB>  <TAB>  <TAB> text = text + "", "" <TAB>  <TAB>  <TAB> text = text + ""{}={}"".format(fields[i], str(self[i])) <TAB> text = text + "")"" <TAB> return text",if self [ i ] != None :,102
"def difference_matrix(samples, debug=True): <TAB> """"""Calculate the difference matrix for the given set of samples."""""" <TAB> diff_matrix = {} <TAB> for x in samples: <TAB>  <TAB> if debug: <TAB>  <TAB>  <TAB> print(""Calculating difference matrix for %s"" % x) <MASK> diff_matrix[x] = {} <TAB>  <TAB> for y in samples: <TAB>  <TAB>  <TAB> if samples[x] != samples[y]: <TAB>  <TAB>  <TAB>  <TAB> d = difference(samples[x], samples[y]) <TAB>  <TAB>  <TAB>  <TAB> # print(""Difference between %s and %s: %d"" % (x, y, d)) <TAB>  <TAB>  <TAB>  <TAB> diff_matrix[x][y] = d <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> diff_matrix[x][y] = 0 <TAB> return diff_matrix",if x not in diff_matrix :,196
"def load_config(self): <TAB> try: <TAB>  <TAB> with open(CONFIG_PATH) as f: <TAB>  <TAB>  <TAB> y = yaml.safe_load(f) <TAB>  <TAB> for key, value in y.items(): <MASK> setattr(self, key.upper(), value) <TAB> except IOError: <TAB>  <TAB> logger.warning( <TAB>  <TAB>  <TAB> f""No config file found at {CONFIG_PATH}, using defaults.\n"" <TAB>  <TAB>  <TAB> f""Set the CONFIG_PATH environment variable to point to a config file to override."" <TAB>  <TAB> )","if hasattr ( self , key . upper ( ) ) and not os . getenv ( key . upper ( ) ) :",148
"def checkout_branch(self, branch): <TAB> if branch in self.remote_branches: <TAB>  <TAB> sickrage.app.log.debug( <TAB>  <TAB>  <TAB> ""Branch checkout: "" + self._find_installed_version() + ""->"" + branch <TAB>  <TAB> ) <TAB>  <TAB> if not self.install_requirements(self.current_branch): <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> # remove untracked files and performs a hard reset on git branch to avoid update issues <MASK> self.reset() <TAB>  <TAB> # fetch all branches <TAB>  <TAB> self.fetch() <TAB>  <TAB> __, __, exit_status = self._git_cmd(self._git_path, ""checkout -f "" + branch) <TAB>  <TAB> if exit_status == 0: <TAB>  <TAB>  <TAB> return True <TAB> return False",if sickrage . app . config . git_reset :,194
"def upload( <TAB> youtube_resource, video_path, body, chunksize=1024 * 1024, progress_callback=None): <TAB> body_keys = "","".join(body.keys()) <TAB> media = MediaFileUpload(video_path, chunksize=chunksize, resumable=True) <TAB> videos = youtube_resource.videos() <TAB> request = videos.insert(part=body_keys, body=body, media_body=media) <TAB> while 1: <TAB>  <TAB> status, response = request.next_chunk() <TAB>  <TAB> if response: <MASK> return response[""id""] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise KeyError(""Response has no 'id' field"") <TAB>  <TAB> elif status and progress_callback: <TAB>  <TAB>  <TAB> progress_callback(status.total_size, status.resumable_progress)","if ""id"" in response :",197
def execute(self): <TAB> with self._guard_sigpipe(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> targets = ( <TAB>  <TAB>  <TAB>  <TAB> self.get_targets() <TAB>  <TAB>  <TAB>  <TAB> if self.act_transitively <TAB>  <TAB>  <TAB>  <TAB> else self.context.target_roots <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> for value in self.console_output(targets) or tuple(): <TAB>  <TAB>  <TAB>  <TAB> self._outstream.write(value.encode()) <TAB>  <TAB>  <TAB>  <TAB> self._outstream.write(self._console_separator.encode()) <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self._outstream.flush() <MASK> self._outstream.close(),if self . get_options ( ) . output_file :,162
"def declare_var( <TAB> self, <TAB> type_name: Union[str, Tuple[str, str]], <TAB> *, <TAB> var_name: str = """", <TAB> var_name_prefix: str = ""v"", <TAB> shared: bool = False,) -> str: <TAB> if shared: <TAB>  <TAB> if not var_name: <TAB>  <TAB>  <TAB> var_name = var_name_prefix <MASK> self.declarations.append((var_name, type_name)) <TAB>  <TAB>  <TAB> self.shared_vars.add(var_name) <TAB> else: <TAB>  <TAB> if not var_name: <TAB>  <TAB>  <TAB> var_name = self.get_var_name(var_name_prefix) <TAB>  <TAB> self.declarations.append((var_name, type_name)) <TAB> return var_name",if var_name not in self . shared_vars :,197
"def parse_counter_style_name(tokens, counter_style): <TAB> tokens = remove_whitespace(tokens) <TAB> if len(tokens) == 1: <TAB>  <TAB> (token,) = tokens <TAB>  <TAB> if token.type == ""ident"": <TAB>  <TAB>  <TAB> if token.lower_value in (""decimal"", ""disc""): <MASK> return token.value <TAB>  <TAB>  <TAB> elif token.lower_value != ""none"": <TAB>  <TAB>  <TAB>  <TAB> return token.value",if token . lower_value not in counter_style :,122
"def __init__(self, appName=""""): <TAB> dlgappcore.AppDialog.__init__(self, win32ui.IDD_GENERAL_STATUS) <TAB> self.timerAppName = appName <TAB> self.argOff = 0 <TAB> if len(self.timerAppName) == 0: <MASK> self.timerAppName = sys.argv[1] <TAB>  <TAB>  <TAB> self.argOff = 1","if len ( sys . argv ) > 1 and sys . argv [ 1 ] [ 0 ] != ""/"" :",116
"def tearDownClass(cls): <TAB> for conn in settings.HAYSTACK_CONNECTIONS.values(): <MASK> continue <TAB>  <TAB> if ""STORAGE"" in conn and conn[""STORAGE""] != ""file"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # Start clean <TAB>  <TAB> if os.path.exists(conn[""PATH""]): <TAB>  <TAB>  <TAB> shutil.rmtree(conn[""PATH""]) <TAB> super(WhooshTestCase, cls).tearDownClass()","if conn [ ""ENGINE"" ] != ""haystack.backends.whoosh_backend.WhooshEngine"" :",118
"def forward(self, x): <TAB> if self.ffn_type in (1, 2): <TAB>  <TAB> x0 = self.wx0(x) <TAB>  <TAB> if self.ffn_type == 1: <TAB>  <TAB>  <TAB> x1 = x <MASK> x1 = self.wx1(x) <TAB>  <TAB> out = self.output(x0 * x1) <TAB> out = self.dropout(out) <TAB> out = self.LayerNorm(out + x) <TAB> return out",elif self . ffn_type == 2 :,122
"def __call__(self, data, **params): <TAB> p = param.ParamOverrides(self, params) <TAB> if isinstance(data, (HoloMap, NdOverlay)): <TAB>  <TAB> ranges = {d.name: data.range(d) for d in data.dimensions()} <TAB>  <TAB> data = data.clone( <TAB>  <TAB>  <TAB> {k: GridMatrix(self._process(p, v, ranges)) for k, v in data.items()} <TAB>  <TAB> ) <TAB>  <TAB> data = Collator(data, merge_type=type(data))() <MASK> data = data.map(lambda x: x.overlay(p.overlay_dims), (HoloMap,)) <TAB>  <TAB> return data <TAB> elif isinstance(data, Element): <TAB>  <TAB> data = self._process(p, data) <TAB>  <TAB> return GridMatrix(data)",if p . overlay_dims :,200
"def _update_model(self, events, msg, root, model, doc, comm=None): <TAB> msg = dict(msg) <TAB> if self._rename[""objects""] in msg: <TAB>  <TAB> old = events[""objects""].old <TAB>  <TAB> msg[self._rename[""objects""]] = self._get_objects(model, old, doc, root, comm) <TAB> with hold(doc): <TAB>  <TAB> super(Panel, self)._update_model(events, msg, root, model, doc, comm) <TAB>  <TAB> from ..io import state <TAB>  <TAB> ref = root.ref[""id""] <MASK> state._views[ref][0]._preprocess(root)",if ref in state . _views :,161
"def reset_two_factor_hotp(): <TAB> otp_secret = request.form.get(""otp_secret"", None) <TAB> if otp_secret: <MASK> return render_template(""account_edit_hotp_secret.html"") <TAB>  <TAB> g.user.set_hotp_secret(otp_secret) <TAB>  <TAB> db.session.commit() <TAB>  <TAB> return redirect(url_for(""account.new_two_factor"")) <TAB> else: <TAB>  <TAB> return render_template(""account_edit_hotp_secret.html"")","if not validate_hotp_secret ( g . user , otp_secret ) :",146
"def ETA(self): <TAB> if self.done: <TAB>  <TAB> prefix = ""Done"" <TAB>  <TAB> t = self.elapsed <TAB>  <TAB> # import pdb; pdb.set_trace() <TAB> else: <TAB>  <TAB> prefix = ""ETA "" <MASK> t = -1 <TAB>  <TAB> elif self.elapsed == 0 or (self.cur == self.min): <TAB>  <TAB>  <TAB> t = 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # import pdb; pdb.set_trace() <TAB>  <TAB>  <TAB> t = float(self.max - self.min) <TAB>  <TAB>  <TAB> t /= self.cur - self.min <TAB>  <TAB>  <TAB> t = (t - 1) * self.elapsed <TAB> return ""%s: %s"" % (prefix, self.format_duration(t))",if self . max is None :,184
"def add_property(self, key, value):  # type: (str, Any) -> None <TAB> with self.secure() as config: <TAB>  <TAB> keys = key.split(""."") <TAB>  <TAB> for i, key in enumerate(keys): <MASK> config[key] = table() <TAB>  <TAB>  <TAB> if i == len(keys) - 1: <TAB>  <TAB>  <TAB>  <TAB> config[key] = value <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> config = config[key]",if key not in config and i < len ( keys ) - 1 :,126
"def validate_against_domain( <TAB> cls, ensemble: Optional[""PolicyEnsemble""], domain: Optional[Domain]) -> None: <TAB> if ensemble is None: <TAB>  <TAB> return <TAB> for p in ensemble.policies: <MASK> continue <TAB>  <TAB> if domain is None or p.deny_suggestion_intent_name not in domain.intents: <TAB>  <TAB>  <TAB> raise InvalidDomain( <TAB>  <TAB>  <TAB>  <TAB> ""The intent '{0}' must be present in the "" <TAB>  <TAB>  <TAB>  <TAB> ""domain file to use TwoStageFallbackPolicy. "" <TAB>  <TAB>  <TAB>  <TAB> ""Either include the intent '{0}' in your domain "" <TAB>  <TAB>  <TAB>  <TAB> ""or exclude the TwoStageFallbackPolicy from your "" <TAB>  <TAB>  <TAB>  <TAB> ""policy configuration"".format(p.deny_suggestion_intent_name) <TAB>  <TAB>  <TAB> )","if not isinstance ( p , TwoStageFallbackPolicy ) :",195
"def sample(self, **config): <TAB> """"""Sample a configuration from this search space."""""" <TAB> ret = [] <TAB> kwspaces = self.kwspaces <TAB> striped_keys = [k.split(SPLITTER)[0] for k in config.keys()] <TAB> for idx, obj in enumerate(self.data): <MASK> sub_config = _strip_config_space(config, prefix=str(idx)) <TAB>  <TAB>  <TAB> ret.append(obj.sample(**sub_config)) <TAB>  <TAB> elif isinstance(obj, SimpleSpace): <TAB>  <TAB>  <TAB> ret.append(config[str(idx)]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret.append(obj) <TAB> return ret","if isinstance ( obj , NestedSpace ) :",165
"def init_weights(self): <TAB> for module in self.decoder.modules(): <MASK> module.weight.data.normal_(mean=0.0, std=0.02) <TAB>  <TAB> elif isinstance(module, nn.LayerNorm): <TAB>  <TAB>  <TAB> module.bias.data.zero_() <TAB>  <TAB>  <TAB> module.weight.data.fill_(1.0) <TAB>  <TAB> if isinstance(module, nn.Linear) and module.bias is not None: <TAB>  <TAB>  <TAB> module.bias.data.zero_() <TAB> for p in self.generator.parameters(): <TAB>  <TAB> if p.dim() > 1: <TAB>  <TAB>  <TAB> xavier_uniform_(p) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> p.data.zero_()","if isinstance ( module , ( nn . Linear , nn . Embedding ) ) :",179
"def backfill_first_message_id( <TAB> apps: StateApps, schema_editor: DatabaseSchemaEditor) -> None: <TAB> Stream = apps.get_model(""zerver"", ""Stream"") <TAB> Message = apps.get_model(""zerver"", ""Message"") <TAB> for stream in Stream.objects.all(): <TAB>  <TAB> first_message = Message.objects.filter( <TAB>  <TAB>  <TAB> recipient__type_id=stream.id, recipient__type=2 <TAB>  <TAB> ).first() <MASK> # No need to change anything if the outcome is the default of None <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> stream.first_message_id = first_message.id <TAB>  <TAB> stream.save()",if first_message is None :,167
"def commandComplete(self, cmd): <TAB> if self.property: <TAB>  <TAB> if cmd.didFail(): <TAB>  <TAB>  <TAB> return <TAB>  <TAB> result = self.observer.getStdout() <MASK> result = result.strip() <TAB>  <TAB> propname = self.property <TAB>  <TAB> self.setProperty(propname, result, ""SetPropertyFromCommand Step"") <TAB>  <TAB> self.property_changes[propname] = result <TAB> else: <TAB>  <TAB> new_props = self.extract_fn( <TAB>  <TAB>  <TAB> cmd.rc, self.observer.getStdout(), self.observer.getStderr() <TAB>  <TAB> ) <TAB>  <TAB> for k, v in iteritems(new_props): <TAB>  <TAB>  <TAB> self.setProperty(k, v, ""SetPropertyFromCommand Step"") <TAB>  <TAB> self.property_changes = new_props",if self . strip :,192
"def part(p, imaginary): <TAB> # Represent infinity as 1e1000 and NaN as 1e1000-1e1000. <TAB> s = ""j"" if imaginary else """" <TAB> try: <TAB>  <TAB> if math.isinf(p): <TAB>  <TAB>  <TAB> if p < 0: <TAB>  <TAB>  <TAB>  <TAB> return ""-1e1000"" + s <TAB>  <TAB>  <TAB> return ""1e1000"" + s <MASK> return ""(1e1000%s-1e1000%s)"" % (s, s) <TAB> except OverflowError: <TAB>  <TAB> # math.isinf will raise this when given an integer <TAB>  <TAB> # that's too large to convert to a float. <TAB>  <TAB> pass <TAB> return repr(p) + s",if math . isnan ( p ) :,168
"def _user_has_perm(user, perm, obj): <TAB> anon = user.is_anonymous() <TAB> for backend in auth.get_backends(): <TAB>  <TAB> if not anon or backend.supports_anonymous_user: <TAB>  <TAB>  <TAB> if hasattr(backend, ""has_perm""): <MASK> if backend.supports_object_permissions and backend.has_perm( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> user, perm, obj <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if backend.has_perm(user, perm): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if obj is not None :,163
"def check_backslashes(payload): <TAB> # Check for single quotes <TAB> if payload.count(""\\"") >= 15: <MASK> if menu.options.tamper: <TAB>  <TAB>  <TAB>  <TAB> menu.options.tamper = menu.options.tamper + "",backslashes"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> menu.options.tamper = ""backslashes"" <TAB>  <TAB> from src.core.tamper import backslashes <TAB>  <TAB> payload = backslashes.tamper(payload)","if not settings . TAMPER_SCRIPTS [ ""backslashes"" ] :",130
"def _check_model(cls): <TAB> errors = [] <TAB> if cls._meta.proxy: <MASK> errors.append( <TAB>  <TAB>  <TAB>  <TAB> checks.Error( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Proxy model '%s' contains model fields."" % cls.__name__, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> id=""models.E017"", <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> return errors",if cls . _meta . local_fields or cls . _meta . local_many_to_many :,114
"def _format_column_list(self, data): <TAB> # Now we have all lis of columns which we need <TAB> # to include in our create definition, Let's format them <TAB> if ""columns"" in data: <TAB>  <TAB> for c in data[""columns""]: <TAB>  <TAB>  <TAB> if ""attacl"" in c: <TAB>  <TAB>  <TAB>  <TAB> c[""attacl""] = parse_priv_to_db(c[""attacl""], self.column_acl) <TAB>  <TAB>  <TAB> # check type for '[]' in it <MASK> c[""cltype""], c[""hasSqrBracket""] = column_utils.type_formatter( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> c[""cltype""] <TAB>  <TAB>  <TAB>  <TAB> )","if ""cltype"" in c :",170
"def _extract_constant_functions(slither: SlitherCore) -> Dict[str, List[str]]: <TAB> ret: Dict[str, List[str]] = {} <TAB> for contract in slither.contracts: <TAB>  <TAB> cst_functions = [ <TAB>  <TAB>  <TAB> _get_name(f) for f in contract.functions_entry_points if _is_constant(f) <TAB>  <TAB> ] <TAB>  <TAB> cst_functions += [ <TAB>  <TAB>  <TAB> v.function_name <TAB>  <TAB>  <TAB> for v in contract.state_variables <TAB>  <TAB>  <TAB> if v.visibility in [""public""] <TAB>  <TAB> ] <MASK> ret[contract.name] = cst_functions <TAB> return ret",if cst_functions :,166
"def safe_zip(*args): <TAB> """"""Like zip, but ensures arguments are of same length"""""" <TAB> base = len(args[0]) <TAB> for i, arg in enumerate(args[1:]): <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Argument 0 has length %d but argument %d has "" <TAB>  <TAB>  <TAB>  <TAB> ""length %d"" % (base, i + 1, len(arg)) <TAB>  <TAB>  <TAB> ) <TAB> return zip(*args)",if len ( arg ) != base :,115
"def readMemory(self, va, size): <TAB> ret = b"""" <TAB> while size: <TAB>  <TAB> pageva = va & self.pagemask <TAB>  <TAB> pageoff = va - pageva <TAB>  <TAB> chunksize = min(self.pagesize - pageoff, size) <TAB>  <TAB> page = self.pagecache.get(pageva) <MASK> page = self.mem.readMemory(pageva, self.pagesize) <TAB>  <TAB>  <TAB> self.pagecache[pageva] = page <TAB>  <TAB> ret += page[pageoff : pageoff + chunksize] <TAB>  <TAB> va += chunksize <TAB>  <TAB> size -= chunksize <TAB> return ret",if page is None :,148
"def horizontal_neighbors_iter(self, ordered=True): <TAB> n_horizontal_edges_per_y = self.x_dimension - ( <TAB>  <TAB> self.x_dimension <= 2 or not self.periodic <TAB> ) <TAB> for x in range(n_horizontal_edges_per_y): <TAB>  <TAB> for y in range(self.y_dimension): <TAB>  <TAB>  <TAB> i = self.to_site_index((x, y)) <TAB>  <TAB>  <TAB> j = self.to_site_index(((x + 1) % self.x_dimension, y)) <TAB>  <TAB>  <TAB> yield (i, j) <MASK> yield (j, i)",if ordered :,156
"def apply_ordering(self, query): <TAB> ordering = request.args.get(""ordering"") or """" <TAB> if ordering: <TAB>  <TAB> desc, column = ordering.startswith(""-""), ordering.lstrip(""-"") <MASK> field = self.model._meta.fields[column] <TAB>  <TAB>  <TAB> query = query.order_by(field.asc() if not desc else field.desc()) <TAB> return query",if column in self . model . _meta . fields :,103
"def check_hashes(self, string): <TAB> for hash in self.hashes.copy(): <TAB>  <TAB> ctext, hash = self.check_hash(hash, string) <MASK> yield ctext, hash <TAB>  <TAB>  <TAB> self.found.add(hash) <TAB>  <TAB>  <TAB> self.hashes.remove(hash)",if ctext is not None :,79
"def undo_block_stop(self): <TAB> if self.undoblock.bump_depth(-1) == 0: <TAB>  <TAB> cmd = self.undoblock <TAB>  <TAB> self.undoblock = 0 <TAB>  <TAB> if len(cmd) > 0: <MASK> # no need to wrap a single cmd <TAB>  <TAB>  <TAB>  <TAB> cmd = cmd.getcmd(0) <TAB>  <TAB>  <TAB> # this blk of cmds, or single cmd, has already <TAB>  <TAB>  <TAB> # been done, so don't execute it again <TAB>  <TAB>  <TAB> self.addcmd(cmd, 0)",if len ( cmd ) == 1 :,139
"def create_model_handler(ns, model_type): <TAB> @route(f""/<provider>/{ns}/<model_id>"") <TAB> @use_provider <TAB> def handle(req, provider, model_id): <TAB>  <TAB> # special cases: <TAB>  <TAB> # fuo://<provider>/users/me -> show current logged user <TAB>  <TAB> if model_type == ModelType.user: <MASK> user = getattr(provider, ""_user"", None) <TAB>  <TAB>  <TAB>  <TAB> if user is None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise CmdException(f""log in provider:{provider.identifier} first"") <TAB>  <TAB>  <TAB>  <TAB> return user <TAB>  <TAB> model = get_model_or_raise(provider, model_type, model_id) <TAB>  <TAB> return model","if model_id == ""me"" :",184
"def _remove_optional_none_type_hints(self, type_hints, defaults): <TAB> # If argument has None as a default, typing.get_type_hints adds <TAB> # optional None to the information it returns. We don't want that. <TAB> for arg in defaults: <TAB>  <TAB> if defaults[arg] is None and arg in type_hints: <TAB>  <TAB>  <TAB> type_ = type_hints[arg] <MASK> types = type_.__args__ <TAB>  <TAB>  <TAB>  <TAB> if len(types) == 2 and types[1] is type(None): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> type_hints[arg] = types[0]",if self . _is_union ( type_ ) :,157
"def set_billing_hours_and_amount(self): <TAB> if not self.project: <TAB>  <TAB> for timesheet in self.timesheets: <TAB>  <TAB>  <TAB> ts_doc = frappe.get_doc(""Timesheet"", timesheet.time_sheet) <MASK> timesheet.billing_hours = ts_doc.total_billable_hours <TAB>  <TAB>  <TAB> if not timesheet.billing_amount and ts_doc.total_billable_amount: <TAB>  <TAB>  <TAB>  <TAB> timesheet.billing_amount = ts_doc.total_billable_amount",if not timesheet . billing_hours and ts_doc . total_billable_hours :,153
"def _real_len(self, s): <TAB> s_len = 0 <TAB> in_esc = False <TAB> prev = "" "" <TAB> for c in replace_all({""\0+"": """", ""\0-"": """", ""\0^"": """", ""\1"": """", ""\t"": "" ""}, s): <TAB>  <TAB> if in_esc: <TAB>  <TAB>  <TAB> if c == ""m"": <TAB>  <TAB>  <TAB>  <TAB> in_esc = False <TAB>  <TAB> else: <MASK> in_esc = True <TAB>  <TAB>  <TAB>  <TAB> s_len -= 1  # we counted prev when we shouldn't have <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> s_len += self._display_len(c) <TAB>  <TAB> prev = c <TAB> return s_len","if c == ""["" and prev == ""\033"" :",177
"def _find_node_with_predicate(self, node, predicate): <TAB> if node != self._tree._root and predicate(node): <TAB>  <TAB> return node <TAB> item, cookie = self._tree.GetFirstChild(node) <TAB> while item: <TAB>  <TAB> if predicate(item): <TAB>  <TAB>  <TAB> return item <TAB>  <TAB> if self._tree.ItemHasChildren(item): <TAB>  <TAB>  <TAB> result = self._find_node_with_predicate(item, predicate) <MASK> return result <TAB>  <TAB> item, cookie = self._tree.GetNextChild(node, cookie) <TAB> return None",if result :,143
"def main(): <TAB> parser = optparse.OptionParser() <TAB> options, argv = parser.parse_args() <TAB> counts = defaultdict(int) <TAB> for line in fileinput.input(argv): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> tweet = json.loads(line) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if ""retweeted_status"" not in tweet: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> rt = tweet[""retweeted_status""] <TAB>  <TAB> id = rt[""id_str""] <TAB>  <TAB> count = rt[""retweet_count""] <MASK> counts[id] = count <TAB> for id in sorted(counts, key=counts.get, reverse=True): <TAB>  <TAB> print(""{},{}"".format(id, counts[id]))",if count > counts [ id ] :,187
"def to_get_select_object_meta(meta_param): <TAB> if meta_param is not None and SelectParameters.Json_Type in meta_param: <MASK> raise SelectOperationClientError( <TAB>  <TAB>  <TAB>  <TAB> ""Json_Type can only be 'LINES' for creating meta"", """" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return to_get_select_json_object_meta(meta_param) <TAB> else: <TAB>  <TAB> return to_get_select_csv_object_meta(meta_param)",if meta_param [ SelectParameters . Json_Type ] != SelectJsonTypes . LINES :,143
"def check_if_match(self, value, index, flags=0): <TAB> pattern = self.get_pattern(index) <TAB> if value: <TAB>  <TAB> if _is_iterable(value): <MASK> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if isinstance(value, (int, long)): <TAB>  <TAB>  <TAB>  <TAB> value = str(value) <TAB>  <TAB>  <TAB> return bool(re.search(pattern, value, flags)) <TAB> return False","if any ( [ bool ( re . search ( pattern , x , flags ) ) for x in value ] ) :",128
"def assemble( <TAB> self, multi_model_placement: Dict[Model, PhysicalDevice]) -> Tuple[Node, PhysicalDevice]: <TAB> for node in self.origin_nodes: <MASK> new_node = Node( <TAB>  <TAB>  <TAB>  <TAB> node.original_graph, <TAB>  <TAB>  <TAB>  <TAB> node.id, <TAB>  <TAB>  <TAB>  <TAB> f""M_{node.original_graph.model.model_id}_{node.name}"", <TAB>  <TAB>  <TAB>  <TAB> node.operation, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return new_node, multi_model_placement[node.original_graph.model] <TAB> raise ValueError( <TAB>  <TAB> f""DedupInputNode {self.name} does not contain nodes from multi_model"" <TAB> )",if node . original_graph . model in multi_model_placement :,188
"def doc_generator(self, imdb_dir, dataset, include_label=False): <TAB> dirs = [ <TAB>  <TAB> (os.path.join(imdb_dir, dataset, ""pos""), True), <TAB>  <TAB> (os.path.join(imdb_dir, dataset, ""neg""), False), <TAB> ] <TAB> for d, label in dirs: <TAB>  <TAB> for filename in os.listdir(d): <TAB>  <TAB>  <TAB> with tf.gfile.Open(os.path.join(d, filename)) as imdb_f: <TAB>  <TAB>  <TAB>  <TAB> doc = imdb_f.read().strip() <MASK> yield doc, label <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield doc",if include_label :,170
"def test_empty_condition_node(cond_node): <TAB> for node in [cond_node.true_node, cond_node.false_node]: <TAB>  <TAB> if node is None: <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> if BaseNode.test_empty_node(node): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> return False <TAB> return True",if type ( node ) is CodeNode and BaseNode . test_empty_node ( node . node ) :,108
"def rewrite_imports(package_dir, vendored_libs, vendor_dir): <TAB> for item in package_dir.iterdir(): <TAB>  <TAB> if item.is_dir(): <TAB>  <TAB>  <TAB> rewrite_imports(item, vendored_libs, vendor_dir) <MASK> rewrite_file_imports(item, vendored_libs, vendor_dir)","elif item . name . endswith ( "".py"" ) :",95
"def ageToDays(self, age_str): <TAB> age = 0 <TAB> age_str = age_str.replace(""&nbsp;"", "" "") <TAB> regex = ""(\d*.?\d+).(sec|hour|day|week|month|year)+"" <TAB> matches = re.findall(regex, age_str) <TAB> for match in matches: <TAB>  <TAB> nr, size = match <TAB>  <TAB> mult = 1 <TAB>  <TAB> if size == ""week"": <TAB>  <TAB>  <TAB> mult = 7 <MASK> mult = 30.5 <TAB>  <TAB> elif size == ""year"": <TAB>  <TAB>  <TAB> mult = 365 <TAB>  <TAB> age += tryInt(nr) * mult <TAB> return tryInt(age)","elif size == ""month"" :",163
"def _validate_zone(self): <TAB> availability_zone = self.availability_zone <TAB> if availability_zone: <TAB>  <TAB> zone = self.ec2.get_zone(availability_zone) <TAB>  <TAB> if not zone: <TAB>  <TAB>  <TAB> raise exception.ClusterValidationError( <TAB>  <TAB>  <TAB>  <TAB> ""availability_zone = %s does not exist"" % availability_zone <TAB>  <TAB>  <TAB> ) <MASK> log.warn( <TAB>  <TAB>  <TAB>  <TAB> ""The availability_zone = %s "" % zone + ""is not available at this time"" <TAB>  <TAB>  <TAB> ) <TAB> return True","if zone . state != ""available"" :",140
"def addnoise(line): <TAB> noise = fillers <TAB> ratio = len(line) // len(noise) <TAB> res = """" <TAB> while line and noise: <MASK> c, line = line[0], line[1:] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> c, noise = noise[0], noise[1:] <TAB>  <TAB> res += c <TAB> return res + noise + line",if len ( line ) // len ( noise ) > ratio :,104
"def cwr1(iterable, r): <TAB> ""Pure python version shown in the docs"" <TAB> # number items returned:  (n+r-1)! / r! / (n-1)! when n>0 <TAB> pool = tuple(iterable) <TAB> n = len(pool) <TAB> if not n and r: <TAB>  <TAB> return <TAB> indices = [0] * r <TAB> yield tuple(pool[i] for i in indices) <TAB> while 1: <TAB>  <TAB> for i in reversed(range(r)): <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> indices[i:] = [indices[i] + 1] * (r - i) <TAB>  <TAB> yield tuple(pool[i] for i in indices)",if indices [ i ] != n - 1 :,184
"def subscribe(self, params) -> bool: <TAB> emit_data = {""method"": ""eth_subscribe"", ""params"": params} <TAB> nonce = await self._send(emit_data) <TAB> raw_message = await self._client.recv() <TAB> if raw_message is not None: <TAB>  <TAB> resp = ujson.loads(raw_message) <MASK> self._node_address = resp.get(""result"") <TAB>  <TAB>  <TAB> return True <TAB> return False","if resp . get ( ""id"" , None ) == nonce :",121
"def _(node): <TAB> for __ in dir(node): <MASK> candidate = getattr(node, __) <TAB>  <TAB>  <TAB> if isinstance(candidate, str): <TAB>  <TAB>  <TAB>  <TAB> if ""\\"" in candidate: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> re.compile(candidate) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> errMsg = ""smoke test failed at compiling '%s'"" % candidate <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> logger.error(errMsg) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> _(candidate)","if not __ . startswith ( ""_"" ) :",142
"def get_field_values(self, fields): <TAB> field_values = [] <TAB> for field in fields: <TAB>  <TAB> # Title is special case <TAB>  <TAB> if field == ""title"": <TAB>  <TAB>  <TAB> value = self.get_title_display() <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> value = self.country.printable_name <TAB>  <TAB>  <TAB> except exceptions.ObjectDoesNotExist: <TAB>  <TAB>  <TAB>  <TAB> value = """" <TAB>  <TAB> elif field == ""salutation"": <TAB>  <TAB>  <TAB> value = self.salutation <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = getattr(self, field) <TAB>  <TAB> field_values.append(value) <TAB> return field_values","elif field == ""country"" :",158
"def __str__(self): <TAB> s = """" <TAB> for k, v in self._members.items(): <TAB>  <TAB> if isinstance(v.get(""type""), list): <TAB>  <TAB>  <TAB> s += k + "" : "" + "";"".join(getattr(self, item)) + ""\n"" <MASK> s += k + "" : "" + getattr(self, k) + ""\n"" <TAB> return s","elif isinstance ( v . get ( ""type"" ) , str ) :",104
"def _merge(self, a, b, path=None): <TAB> """"""Merge two dictionaries, from http://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge"""""" <TAB> if path is None: <TAB>  <TAB> path = [] <TAB> for key in b: <TAB>  <TAB> if key in a: <TAB>  <TAB>  <TAB> if isinstance(a[key], dict) and isinstance(b[key], dict): <TAB>  <TAB>  <TAB>  <TAB> self._merge(a[key], b[key], path + [str(key)]) <MASK> pass  # same leaf value <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise Exception(""Conflict at %s"" % ""."".join(path + [str(key)])) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> a[key] = b[key] <TAB> return a",elif a [ key ] == b [ key ] :,196
"def get_child_nodes(node): <TAB> if isinstance(node, _ast.Module): <TAB>  <TAB> return node.body <TAB> result = [] <TAB> if node._fields is not None: <TAB>  <TAB> for name in node._fields: <TAB>  <TAB>  <TAB> child = getattr(node, name) <TAB>  <TAB>  <TAB> if isinstance(child, list): <TAB>  <TAB>  <TAB>  <TAB> for entry in child: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if isinstance(entry, _ast.AST): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> result.append(entry) <MASK> result.append(child) <TAB> return result","if isinstance ( child , _ast . AST ) :",145
def _handle_enter(self) -> None: <TAB> if self.multiple_selection: <TAB>  <TAB> val = self.values[self._selected_index][0] <MASK> self.current_values.remove(val) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.current_values.append(val) <TAB> else: <TAB>  <TAB> self.current_value = self.values[self._selected_index][0],if val in self . current_values :,108
"def close_all(map=None, ignore_all=False): <TAB> if map is None:  # pragma: no cover <TAB>  <TAB> map = socket_map <TAB> for x in list(map.values()):  # list() FBO py3 <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> x.close() <TAB>  <TAB> except OSError as x: <MASK> pass <TAB>  <TAB>  <TAB> elif not ignore_all: <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> except _reraised_exceptions: <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> if not ignore_all: <TAB>  <TAB>  <TAB>  <TAB> raise <TAB> map.clear()",if x . args [ 0 ] == EBADF :,157
"def _get_spawn_property(self, constraints, constraint_name, services): <TAB> if services: <TAB>  <TAB> # this isn't very nice <TAB>  <TAB> if constraint_name == IMAGE_CONSTRAINT: <TAB>  <TAB>  <TAB> return services[0].image <TAB>  <TAB> elif constraint_name == CPUS_CONSTRAINT: <TAB>  <TAB>  <TAB> return services[0].cpus <TAB> for constraint in constraints: <MASK> return constraint.value <TAB> return None",if constraint . name == constraint_name :,113
"def _handle_children(self, removed, added): <TAB> # Stop all the removed children. <TAB> for obj in removed: <TAB>  <TAB> obj.stop() <TAB> # Process the new objects. <TAB> for obj in added: <TAB>  <TAB> obj.set(scene=self.scene, parent=self) <TAB>  <TAB> if isinstance(obj, ModuleManager): <TAB>  <TAB>  <TAB> obj.source = self <MASK> obj.inputs.append(self) <TAB>  <TAB> if self.running: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> obj.start() <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> exception()",elif is_filter ( obj ) :,148
"def _get_cols_width(self, values): <TAB> width = 14 <TAB> for row in values: <TAB>  <TAB> for header in self.headers: <TAB>  <TAB>  <TAB> header_len = len(header) <TAB>  <TAB>  <TAB> if header_len > width: <TAB>  <TAB>  <TAB>  <TAB> width = header_len <TAB>  <TAB>  <TAB> value_len = len(unicode(row.get(header, """"))) <MASK> width = value_len <TAB> width += 2 <TAB> return width",if value_len > width :,118
"def crawl(self, *args, **kwargs): <TAB> assert not self.crawling, ""Crawling already taking place"" <TAB> self.crawling = True <TAB> try: <TAB>  <TAB> self.spider = self._create_spider(*args, **kwargs) <TAB>  <TAB> self.engine = self._create_engine() <MASK> start_requests = iter(self.spider.start_requests()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> start_requests = () <TAB>  <TAB> yield self.engine.open_spider(self.spider, start_requests) <TAB>  <TAB> yield defer.maybeDeferred(self.engine.start) <TAB> except Exception: <TAB>  <TAB> self.crawling = False <TAB>  <TAB> raise",if self . start_requests :,170
"def _copy_files(self, files, src, dest, message=""""): <TAB> for filepath in files: <TAB>  <TAB> srcpath = os.path.join(src, filepath) <TAB>  <TAB> destpath = os.path.join(dest, filepath) <MASK> print(""{}: {}"".format(message, destpath)) <TAB>  <TAB> if os.path.exists(srcpath): <TAB>  <TAB>  <TAB> destdir = os.path.dirname(destpath) <TAB>  <TAB>  <TAB> if not os.path.isdir(destdir): <TAB>  <TAB>  <TAB>  <TAB> os.makedirs(destdir) <TAB>  <TAB>  <TAB> shutil.copy(srcpath, destpath) <TAB>  <TAB> elif os.path.exists(destpath): <TAB>  <TAB>  <TAB> os.remove(destpath)",if message :,167
"def describe_tags(self): <TAB> resource_arns = self._get_multi_param(""ResourceArns.member"") <TAB> resources = [] <TAB> for arn in resource_arns: <MASK> resource = self.elbv2_backend.target_groups.get(arn) <TAB>  <TAB>  <TAB> if not resource: <TAB>  <TAB>  <TAB>  <TAB> raise TargetGroupNotFoundError() <TAB>  <TAB> elif "":loadbalancer"" in arn: <TAB>  <TAB>  <TAB> resource = self.elbv2_backend.load_balancers.get(arn) <TAB>  <TAB>  <TAB> if not resource: <TAB>  <TAB>  <TAB>  <TAB> raise LoadBalancerNotFoundError() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise LoadBalancerNotFoundError() <TAB>  <TAB> resources.append(resource) <TAB> template = self.response_template(DESCRIBE_TAGS_TEMPLATE) <TAB> return template.render(resources=resources)","if "":targetgroup"" in arn :",197
def iterator(): <TAB> try: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> yield from pullparser.read_events() <TAB>  <TAB>  <TAB> # load event buffer <TAB>  <TAB>  <TAB> data = source.read(16 * 1024) <MASK> break <TAB>  <TAB>  <TAB> pullparser.feed(data) <TAB>  <TAB> root = pullparser._close_and_return_root() <TAB>  <TAB> yield from pullparser.read_events() <TAB>  <TAB> it.root = root <TAB> finally: <TAB>  <TAB> if close_source: <TAB>  <TAB>  <TAB> source.close(),if not data :,130
"def __repr__(self): <TAB> data = """" <TAB> for c in self.children: <TAB>  <TAB> data += c.shortrepr() <MASK> data = data[:56] + "" ..."" <TAB>  <TAB>  <TAB> break <TAB> if self[""names""]: <TAB>  <TAB> return '<%s ""%s"": %s>' % ( <TAB>  <TAB>  <TAB> self.__class__.__name__, <TAB>  <TAB>  <TAB> ""; "".join([ensure_str(n) for n in self[""names""]]), <TAB>  <TAB>  <TAB> data, <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> return ""<%s: %s>"" % (self.__class__.__name__, data)",if len ( data ) > 60 :,147
"def __exit__(self, exc_type, exc_value, traceback): <TAB> template_rendered.disconnect(self.on_template_render) <TAB> if exc_type is not None: <TAB>  <TAB> return <TAB> if not self.test(): <TAB>  <TAB> message = self.message() <MASK> message += "" No template was rendered."" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> message += "" Following templates were rendered: %s"" % ( <TAB>  <TAB>  <TAB>  <TAB> "", "".join(self.rendered_template_names) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self.test_case.fail(message)",if len ( self . rendered_templates ) == 0 :,148
"def _match(self, byte_chunk): <TAB> quote_character = None <TAB> data = byte_chunk.nhtml <TAB> open_angle_bracket = data.rfind(""<"") <TAB> # We are inside <... <TAB> if open_angle_bracket <= data.rfind("">""): <TAB>  <TAB> return False <TAB> for s in data[open_angle_bracket + 1 :]: <TAB>  <TAB> if s in ATTR_DELIMITERS: <TAB>  <TAB>  <TAB> if quote_character and s == quote_character: <TAB>  <TAB>  <TAB>  <TAB> quote_character = None <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> quote_character = s <TAB>  <TAB>  <TAB>  <TAB> continue <TAB> if quote_character == self.quote_character: <TAB>  <TAB> return True <TAB> return False",elif not quote_character :,173
"def recent_events(self, events): <TAB> try: <TAB>  <TAB> frame = self.get_frame() <TAB> except EndofVideoFileError: <TAB>  <TAB> logger.info(""Video has ended."") <TAB>  <TAB> self.notify_all( <TAB>  <TAB>  <TAB> {""subject"": ""file_source.video_finished"", ""source_path"": self.source_path} <TAB>  <TAB> ) <TAB>  <TAB> self.play = False <TAB> else: <TAB>  <TAB> self._recent_frame = frame <TAB>  <TAB> events[""frame""] = frame <MASK> self.wait(frame)",if self . timed_playback :,136
"def _prune(self): <TAB> if self.over_threshold(): <TAB>  <TAB> now = time.time() <TAB>  <TAB> for idx, (key, (expires, _)) in enumerate(self._cache.items()): <MASK> with self._mutex: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._cache.pop(key, None)",if expires is not None and expires <= now or idx % 3 == 0 :,95
"def dict_path(d, path): <TAB> if not isinstance(path, (list, tuple)): <TAB>  <TAB> raise ValueError() <TAB> for keys in path: <TAB>  <TAB> if type(keys) is not list: <TAB>  <TAB>  <TAB> keys = [keys] <TAB>  <TAB> value = None <TAB>  <TAB> for key in keys: <MASK> continue <TAB>  <TAB>  <TAB> value = d[key] <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB> value = {} <TAB>  <TAB> for key in keys: <TAB>  <TAB>  <TAB> d[key] = value <TAB>  <TAB> d = value <TAB> return d",if key not in d :,140
"def span_tokenize(self, string): <TAB> if self.__tokenizer == ""nltk"": <TAB>  <TAB> raw_tokens = nltk.word_tokenize(string) <MASK> matched = [m.group() for m in re.finditer(r""``|'{2}|\"""", string)] <TAB>  <TAB>  <TAB> tokens = [ <TAB>  <TAB>  <TAB>  <TAB> matched.pop(0) if tok in ['""', ""``"", ""''""] else tok <TAB>  <TAB>  <TAB>  <TAB> for tok in raw_tokens <TAB>  <TAB>  <TAB> ] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tokens = raw_tokens <TAB>  <TAB> spans = align_tokens(tokens, string) <TAB> return spans","if ( '""' in string ) or ( ""''"" in string ) :",155
"def literal(self): <TAB> if self.peek('""'): <TAB>  <TAB> lit, lang, dtype = self.eat(r_literal).groups() <TAB>  <TAB> if lang: <TAB>  <TAB>  <TAB> lang = lang <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lang = None <TAB>  <TAB> if dtype: <TAB>  <TAB>  <TAB> dtype = dtype <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> dtype = None <MASK> raise ParseError(""Can't have both a language and a datatype"") <TAB>  <TAB> lit = unquote(lit) <TAB>  <TAB> return Literal(lit, lang, dtype) <TAB> return False",if lang and dtype :,132
"def get(): <TAB> result = [] <TAB> for b in self.key_bindings: <TAB>  <TAB> if len(keys) < len(b.keys): <TAB>  <TAB>  <TAB> match = True <TAB>  <TAB>  <TAB> for i, j in zip(b.keys, keys): <MASK> match = False <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> if match: <TAB>  <TAB>  <TAB>  <TAB> result.append(b) <TAB> return result",if i != j and i != Keys . Any :,113
"def _compileRules(rulesList, maxLength=4): <TAB> ruleChecking = collections.defaultdict(list) <TAB> for ruleIndex in range(len(rulesList)): <TAB>  <TAB> args = [] <TAB>  <TAB> if len(rulesList[ruleIndex]) == maxLength: <TAB>  <TAB>  <TAB> args = rulesList[ruleIndex][-1] <MASK> (shouldRunMethod, method, isCorrect) = rulesList[ruleIndex][0:3] <TAB>  <TAB>  <TAB> ruleChecking[shouldRunMethod].append((method, isCorrect, args)) <TAB>  <TAB> elif maxLength == 3: <TAB>  <TAB>  <TAB> (shouldRunMethod, method) = rulesList[ruleIndex][0:2] <TAB>  <TAB>  <TAB> ruleChecking[shouldRunMethod].append((method, args)) <TAB> return ruleChecking",if maxLength == 4 :,183
def parents_in_pipfile(self): <TAB> if not self._parents_in_pipfile: <TAB>  <TAB> self._parents_in_pipfile = [ <TAB>  <TAB>  <TAB> p <TAB>  <TAB>  <TAB> for p in self.flattened_parents <MASK> ] <TAB> return self._parents_in_pipfile,if p . normalized_name in self . pipfile_packages,86
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_content(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> self.set_blob_key(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 24: <TAB>  <TAB>  <TAB> self.set_width(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 32: <TAB>  <TAB>  <TAB> self.set_height(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 18 :,182
"def base64_encode_image_mapper(self, tag, url): <TAB> if tag == ""img"": <MASK> image_data = base64.b64encode(self.kp_images[url]) <TAB>  <TAB>  <TAB> image_mimetype = mimetypes.guess_type(url)[0] <TAB>  <TAB>  <TAB> if image_mimetype is not None: <TAB>  <TAB>  <TAB>  <TAB> return ""data:{};base64, "".format(image_mimetype) + image_data.decode( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""utf-8"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return None",if url in self . kp_images :,138
"def get_args_from_ref_args(handler, ref_args): <TAB> args = [] <TAB> for ref_arg in ref_args: <MASK> temp = handler.create_from_numpy(ref_arg) <TAB>  <TAB>  <TAB> args.append(temp) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> args.append(ref_arg) <TAB> return args",if type ( ref_arg ) is ref . array_type :,100
"def _get_cols_width(self, values): <TAB> width = 14 <TAB> for row in values: <TAB>  <TAB> for header in self.headers: <TAB>  <TAB>  <TAB> header_len = len(header) <MASK> width = header_len <TAB>  <TAB>  <TAB> value_len = len(unicode(row.get(header, """"))) <TAB>  <TAB>  <TAB> if value_len > width: <TAB>  <TAB>  <TAB>  <TAB> width = value_len <TAB> width += 2 <TAB> return width",if header_len > width :,118
"def OnLeaveWindow(self, event): <TAB> if self.start_drag and not self.dragging: <TAB>  <TAB> self.dragging = False <TAB>  <TAB> self.start_drag = False <TAB>  <TAB> self.dragged_tab = None <TAB>  <TAB> self.drag_trigger = self.drag_trail <MASK> self.ReleaseMouse() <TAB> if self.preview_wnd: <TAB>  <TAB> self.preview_wnd.Show(False) <TAB>  <TAB> del self.preview_wnd <TAB>  <TAB> self.preview_wnd = None <TAB> event.Skip()",if self . HasCapture ( ) :,138
"def _checkPid(self, pid): <TAB> retval = False <TAB> if self.settings.windows: <TAB>  <TAB> PROCESS_TERMINATE = 1 <TAB>  <TAB> p = ctypes.windll.kernel32.OpenProcess(PROCESS_TERMINATE, 0, pid) <TAB>  <TAB> retval = p != 0 <MASK> ctypes.windll.kernel32.CloseHandle(p) <TAB> else: <TAB>  <TAB> # https://stackoverflow.com/questions/568271/how-to-check-if-there-exists-a-process-with-a-given-pid-in-python <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> os.kill(pid, 0) <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> retval = True <TAB> return retval",if p :,177
"def concat_index_value(index_values, store_data=False): <TAB> result = pd.Index([]) <TAB> if not isinstance(index_values, (list, tuple)): <TAB>  <TAB> index_values = [index_values] <TAB> for index_value in index_values: <MASK> result = result.append(index_value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result = result.append(index_value.to_pandas()) <TAB> return parse_index(result, store_data=store_data)","if isinstance ( index_value , pd . Index ) :",132
"def apply(self, db, family): <TAB> if self.rtype: <TAB>  <TAB> if self.rtype.is_custom() and self.use_regex: <MASK> return False <TAB>  <TAB> elif self.rtype != family.get_relationship(): <TAB>  <TAB>  <TAB> return False <TAB> return True",if self . regex [ 0 ] . search ( str ( family . get_relationship ( ) ) ) is None :,93
"def get_child_nodes(node): <TAB> if isinstance(node, _ast.Module): <TAB>  <TAB> return node.body <TAB> result = [] <TAB> if node._fields is not None: <TAB>  <TAB> for name in node._fields: <TAB>  <TAB>  <TAB> child = getattr(node, name) <TAB>  <TAB>  <TAB> if isinstance(child, list): <TAB>  <TAB>  <TAB>  <TAB> for entry in child: <MASK> result.append(entry) <TAB>  <TAB>  <TAB> if isinstance(child, _ast.AST): <TAB>  <TAB>  <TAB>  <TAB> result.append(child) <TAB> return result","if isinstance ( entry , _ast . AST ) :",145
"def output(self): <TAB> """"""Transform self into a list of (name, value) tuples."""""" <TAB> header_list = [] <TAB> for k, v in self.items(): <TAB>  <TAB> if isinstance(k, unicodestr): <TAB>  <TAB>  <TAB> k = self.encode(k) <TAB>  <TAB> if not isinstance(v, basestring): <TAB>  <TAB>  <TAB> v = str(v) <MASK> v = self.encode(v) <TAB>  <TAB> # See header_translate_* constants above. <TAB>  <TAB> # Replace only if you really know what you're doing. <TAB>  <TAB> k = k.translate(header_translate_table, header_translate_deletechars) <TAB>  <TAB> v = v.translate(header_translate_table, header_translate_deletechars) <TAB>  <TAB> header_list.append((k, v)) <TAB> return header_list","if isinstance ( v , unicodestr ) :",197
"def check_valid_emoji_name(emoji_name: str) -> None: <TAB> if emoji_name: <MASK> return <TAB>  <TAB> raise JsonableError(_(""Invalid characters in emoji name"")) <TAB> raise JsonableError(_(""Emoji name is missing""))","if re . match ( r""^[0-9a-z.\-_]+(?<![.\-_])$"" , emoji_name ) :",93
"def cache_subscriptions(self, region: str): <TAB> async with self.regional_subscriptions_cache_locks.setdefault( <TAB>  <TAB> region, asyncio.Lock() <TAB> ): <MASK> return <TAB>  <TAB> self.subscriptions_cache[region] = await AWSFacadeUtils.get_all_pages( <TAB>  <TAB>  <TAB> ""sns"", region, self.session, ""list_subscriptions"", ""Subscriptions"" <TAB>  <TAB> ) <TAB>  <TAB> for subscription in self.subscriptions_cache[region]: <TAB>  <TAB>  <TAB> topic_arn = subscription.pop(""TopicArn"") <TAB>  <TAB>  <TAB> subscription[""topic_name""] = topic_arn.split("":"")[-1]",if region in self . subscriptions_cache :,160
"def AdjustArg(arg, break_chars, argv_out): <TAB> # type: (str, List[str], List[str]) -> None <TAB> end_indices = []  # stores the end of each span <TAB> state = ST_Begin <TAB> for i, c in enumerate(arg): <TAB>  <TAB> ch = CH_Break if c in break_chars else CH_Other <TAB>  <TAB> state, emit_span = _TRANSITIONS[state, ch] <MASK> end_indices.append(i) <TAB> # Always emit a span at the end (even for empty string) <TAB> end_indices.append(len(arg)) <TAB> begin = 0 <TAB> for end in end_indices: <TAB>  <TAB> argv_out.append(arg[begin:end]) <TAB>  <TAB> begin = end",if emit_span :,185
"def load_model( <TAB> self, model_name: str, path: str = None, model_type=None) -> AbstractModel: <TAB> if isinstance(model_name, AbstractModel): <TAB>  <TAB> return model_name <TAB> if model_name in self.models.keys(): <TAB>  <TAB> return self.models[model_name] <TAB> else: <TAB>  <TAB> if path is None: <TAB>  <TAB>  <TAB> path = self.get_model_attribute(model=model_name, attribute=""path"") <MASK> model_type = self.get_model_attribute(model=model_name, attribute=""type"") <TAB>  <TAB> return model_type.load(path=path, reset_paths=self.reset_paths)",if model_type is None :,170
"def find_config(pipeline_config_path: Union[str, Path]) -> Path: <TAB> if not Path(pipeline_config_path).is_file(): <TAB>  <TAB> configs = [ <TAB>  <TAB>  <TAB> c <TAB>  <TAB>  <TAB> for c in Path(__file__).parent.parent.parent.glob( <TAB>  <TAB>  <TAB>  <TAB> f""configs/**/{pipeline_config_path}.json"" <TAB>  <TAB>  <TAB> ) <MASK> ]  # a simple way to not allow * and ? <TAB>  <TAB> if configs: <TAB>  <TAB>  <TAB> log.info(f""Interpreting '{pipeline_config_path}' as '{configs[0]}'"") <TAB>  <TAB>  <TAB> pipeline_config_path = configs[0] <TAB> return Path(pipeline_config_path)","if str ( c . with_suffix ( """" ) ) . endswith ( pipeline_config_path )",184
"def __init__(self, bounds, channel_axis, preprocess=None): <TAB> assert len(bounds) == 2 <TAB> assert channel_axis in [0, 1, 2, 3] <TAB> self._bounds = bounds <TAB> self._channel_axis = channel_axis <TAB> # Make self._preprocess to be (0,1) if possible, so that don't need <TAB> # to do substract or divide. <TAB> if preprocess is not None: <TAB>  <TAB> sub, div = np.array(preprocess) <TAB>  <TAB> if not np.any(sub): <TAB>  <TAB>  <TAB> sub = 0 <MASK> div = 1 <TAB>  <TAB> assert (div is None) or np.all(div) <TAB>  <TAB> self._preprocess = (sub, div) <TAB> else: <TAB>  <TAB> self._preprocess = (0, 1)",if np . all ( div == 1 ) :,194
"def iter_imports(path): <TAB> """"""Yield imports in *path*"""""" <TAB> for node in ast.parse(open(path, ""rb"").read()).body: <TAB>  <TAB> if isinstance(node, ast.ImportFrom): <MASK> prefix = () <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> prefix = tuple(node.module.split(""."")) <TAB>  <TAB>  <TAB> for snode in node.names: <TAB>  <TAB>  <TAB>  <TAB> yield (node.level, prefix + (snode.name,)) <TAB>  <TAB> elif isinstance(node, ast.Import): <TAB>  <TAB>  <TAB> for node in node.names: <TAB>  <TAB>  <TAB>  <TAB> yield (0, tuple(node.name.split(""."")))",if node . module is None :,162
"def __init__(self, spec=None, add_book=True, xl=None, visible=None): <TAB> # visible is only required on mac <TAB> if spec is not None: <TAB>  <TAB> warn(""spec is ignored on Windows."") <TAB> if xl is None: <TAB>  <TAB> # new instance <TAB>  <TAB> self._xl = COMRetryObjectWrapper(DispatchEx(""Excel.Application"")) <MASK> self._xl.Workbooks.Add() <TAB>  <TAB> self._hwnd = None <TAB> elif isinstance(xl, int): <TAB>  <TAB> self._xl = None <TAB>  <TAB> self._hwnd = xl <TAB> else: <TAB>  <TAB> self._xl = xl <TAB>  <TAB> self._hwnd = None",if add_book :,166
"def _find_split(): <TAB> """"""Find the first = sign to split on (that isn't in [brackets])"""""" <TAB> key = [] <TAB> value = [] <TAB> brackets = False <TAB> chars = list(expression) <TAB> while chars: <TAB>  <TAB> c = chars.pop(0) <TAB>  <TAB> if c == ""="" and not brackets: <TAB>  <TAB>  <TAB> # keys done the rest is value <TAB>  <TAB>  <TAB> value = chars <TAB>  <TAB>  <TAB> break <MASK> brackets = True <TAB>  <TAB>  <TAB> key += c <TAB>  <TAB> elif c == ""]"" and brackets: <TAB>  <TAB>  <TAB> brackets = False <TAB>  <TAB>  <TAB> key += c <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # normal character <TAB>  <TAB>  <TAB> key += c <TAB> return """".join(key), """".join(value)","elif c == ""["" :",177
"def _ApplySizeLimit( <TAB> regions: Iterable[rdf_memory.ProcessMemoryRegion], size_limit: int) -> List[rdf_memory.ProcessMemoryRegion]: <TAB> """"""Truncates regions so that the total size stays in size_limit."""""" <TAB> total_size = 0 <TAB> regions_in_limit = [] <TAB> for region in regions: <MASK> break <TAB>  <TAB> region.dumped_size = min(region.size, size_limit - total_size) <TAB>  <TAB> regions_in_limit.append(region) <TAB>  <TAB> total_size += region.dumped_size <TAB> return regions_in_limit",if total_size >= size_limit :,151
"def _get_matched_files(input_path): <TAB> """"""Returns all files that matches the input_path."""""" <TAB> input_patterns = input_path.strip().split("","") <TAB> all_matched_files = [] <TAB> for input_pattern in input_patterns: <TAB>  <TAB> input_pattern = input_pattern.strip() <MASK> continue <TAB>  <TAB> matched_files = tf.io.gfile.glob(input_pattern) <TAB>  <TAB> if not matched_files: <TAB>  <TAB>  <TAB> raise ValueError(""%s does not match any files."" % input_pattern) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> all_matched_files.extend(matched_files) <TAB> return sorted(all_matched_files)",if not input_pattern :,166
"def _add_kid(key, x): <TAB> if x is None: <TAB>  <TAB> kids[key] = None <TAB> else: <TAB>  <TAB> if type(x) in (type([]), type(())): <TAB>  <TAB>  <TAB> x1 = [i for i in x if isinstance(i, TVTKBase)] <MASK> kids[key] = x1 <TAB>  <TAB> elif isinstance(x, TVTKBase): <TAB>  <TAB>  <TAB> if hasattr(x, ""__iter__""): <TAB>  <TAB>  <TAB>  <TAB> # Don't add iterable objects that contain non <TAB>  <TAB>  <TAB>  <TAB> # acceptable nodes <TAB>  <TAB>  <TAB>  <TAB> if len(list(x)) and isinstance(list(x)[0], TVTKBase): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> kids[key] = x <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> kids[key] = x",if x1 :,196
"def _read_info(self, field): <TAB> fs.File._read_info(self, field) <TAB> if field == ""dimensions"": <TAB>  <TAB> self.dimensions = self._plat_get_dimensions() <MASK> self.dimensions = (self.dimensions[1], self.dimensions[0]) <TAB> elif field == ""exif_timestamp"": <TAB>  <TAB> self.exif_timestamp = self._get_exif_timestamp()","if self . _get_orientation ( ) in { 5 , 6 , 7 , 8 } :",116
"def process_timeline(self, info): <TAB> children = info.get(""_children"", []) <TAB> if not children: <TAB>  <TAB> return False <TAB> for entry in children: <TAB>  <TAB> state = TIMELINE_STATES.get(entry.get(""state"")) <MASK> continue <TAB>  <TAB> self.emit(""%s.timeline.%s"" % (self.name, state), entry) <TAB> return True",if not state :,98
"def from_chx(self): <TAB> if self.array is not None: <TAB>  <TAB> device = backend.get_device_from_array(self.array) <TAB> else: <TAB>  <TAB> device = self._initial_device <TAB> if device.xp is chainerx: <TAB>  <TAB> backend_name = device.device.backend.name <TAB>  <TAB> if backend_name == ""native"": <TAB>  <TAB>  <TAB> self._initial_device = backend.CpuDevice() <MASK> self._initial_device = backend.GpuDevice.from_device_id(device.device.index) <TAB> super(Parameter, self)._from_chx(allow_unchaining=True)","elif backend_name == ""cuda"" :",162
"def get_title_extensions(self, title=None): <TAB> extensions = [] <TAB> for extension in self.title_extensions: <MASK> extensions.extend(list(extension.objects.filter(extended_object=title))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> extensions.extend(list(extension.objects.all())) <TAB> return extensions",if title :,83
"def tag(vs, push=False): <TAB> """"""Make the tagged release commit"""""" <TAB> patch_version(vs, repo_root) <TAB> with cd(repo_root): <TAB>  <TAB> run('git commit -a -m ""release {}""'.format(vs)) <TAB>  <TAB> run('git tag -a -m ""release {0}"" {0}'.format(vs)) <MASK> run(""git push"") <TAB>  <TAB>  <TAB> run(""git push --tags"")",if push :,108
"def parse_bismark_report(self, report, regexes): <TAB> """"""Search a bismark report with a set of regexes"""""" <TAB> parsed_data = {} <TAB> for k, r in regexes.items(): <TAB>  <TAB> r_search = re.search(r, report, re.MULTILINE) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> parsed_data[k] = float(r_search.group(1)) <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> parsed_data[k] = r_search.group(1)  # NaN <TAB> if len(parsed_data) == 0: <TAB>  <TAB> return None <TAB> return parsed_data",if r_search :,156
"def _scroll_delete(dirname, max_num_checkpoints=3): <TAB> dirs = os.listdir(dirname) <TAB> serial_map = {} <TAB> for serial in dirs: <TAB>  <TAB> serial_num = _get_dir_serial(serial) <TAB>  <TAB> serial_map[serial_num] = serial <TAB> if len(list(serial_map.keys())) <= max_num_checkpoints: <TAB>  <TAB> return <TAB> serials = list(serial_map.keys()) <TAB> serials.sort(reverse=True) <TAB> serials = serials[max_num_checkpoints:] <TAB> for serial in serials: <TAB>  <TAB> cur_dir = _get_serial_dir(dirname, serial) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> shutil.rmtree(cur_dir) <TAB>  <TAB> except OSError as err: <MASK> raise err",if err . errno != errno . ENOENT :,198
"def _lookup(self, key, dicts=None, filters=()): <TAB> if dicts is None: <TAB>  <TAB> dicts = self.dicts <TAB> key_len = len(key) <TAB> if key_len > self.longest_key: <TAB>  <TAB> return None <TAB> for d in dicts: <MASK> continue <TAB>  <TAB> if key_len > d.longest_key: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> value = d.get(key) <TAB>  <TAB> if value: <TAB>  <TAB>  <TAB> for f in filters: <TAB>  <TAB>  <TAB>  <TAB> if f(key, value): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB>  <TAB> return value",if not d . enabled :,150
"def get_preset(self, unit): <TAB> for line in self._lines: <TAB>  <TAB> m = re.match(r""(enable|disable)\s+(\S+)"", line) <MASK> status, pattern = m.group(1), m.group(2) <TAB>  <TAB>  <TAB> if fnmatch.fnmatchcase(unit, pattern): <TAB>  <TAB>  <TAB>  <TAB> logg.debug(""%s %s => %s [%s]"", status, pattern, unit, self.filename()) <TAB>  <TAB>  <TAB>  <TAB> return status <TAB> return None",if m :,121
"def gen_cpu_name(cpu): <TAB> if cpu == ""simple"": <TAB>  <TAB> return event_download.get_cpustr() <TAB> for j in known_cpus: <MASK> if isinstance(j[1][0], tuple): <TAB>  <TAB>  <TAB>  <TAB> return ""GenuineIntel-6-%02X-%d"" % j[1][0] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return ""GenuineIntel-6-%02X"" % j[1][0] <TAB> assert False",if cpu == j [ 0 ] :,127
"def allow_request(self, request, view): <TAB> if settings.API_THROTTLING: <TAB>  <TAB> request_allowed = super(GranularUserRateThrottle, self).allow_request( <TAB>  <TAB>  <TAB> request, view <TAB>  <TAB> ) <MASK> user = getattr(request, ""user"", None) <TAB>  <TAB>  <TAB> if user and request.user.is_authenticated: <TAB>  <TAB>  <TAB>  <TAB> log.info(""User %s throttled for scope %s"", request.user, self.scope) <TAB>  <TAB>  <TAB>  <TAB> ActivityLog.create(amo.LOG.THROTTLED, self.scope, user=user) <TAB>  <TAB> return request_allowed <TAB> else: <TAB>  <TAB> return True",if not request_allowed :,164
"def __getitem__(self, tagSet): <TAB> try: <TAB>  <TAB> return self.__presentTypes[tagSet] <TAB> except KeyError: <MASK> raise KeyError() <TAB>  <TAB> elif tagSet in self.__skipTypes: <TAB>  <TAB>  <TAB> raise error.PyAsn1Error(""Key in negative map"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.__defaultType",if self . __defaultType is None :,93
"def _media(self): <TAB> # Get the media property of the superclass, if it exists <TAB> sup_cls = super(cls, self) <TAB> try: <TAB>  <TAB> base = sup_cls.media <TAB> except AttributeError: <TAB>  <TAB> base = Media() <TAB> # Get the media definition for this class <TAB> definition = getattr(cls, ""Media"", None) <TAB> if definition: <TAB>  <TAB> extend = getattr(definition, ""extend"", True) <TAB>  <TAB> if extend: <MASK> m = base <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> m = Media() <TAB>  <TAB>  <TAB>  <TAB> for medium in extend: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> m = m + base[medium] <TAB>  <TAB>  <TAB> return m + Media(definition) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return Media(definition) <TAB> else: <TAB>  <TAB> return base",if extend == True :,197
"def ascii85decode(data): <TAB> n = b = 0 <TAB> out = """" <TAB> for c in data: <TAB>  <TAB> if ""!"" <= c and c <= ""u"": <TAB>  <TAB>  <TAB> n += 1 <TAB>  <TAB>  <TAB> b = b * 85 + (ord(c) - 33) <TAB>  <TAB>  <TAB> if n == 5: <TAB>  <TAB>  <TAB>  <TAB> out += struct.pack("">L"", b) <TAB>  <TAB>  <TAB>  <TAB> n = b = 0 <TAB>  <TAB> elif c == ""z"": <TAB>  <TAB>  <TAB> assert n == 0 <TAB>  <TAB>  <TAB> out += ""\0\0\0\0"" <MASK> if n: <TAB>  <TAB>  <TAB>  <TAB> for _ in range(5 - n): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> b = b * 85 + 84 <TAB>  <TAB>  <TAB>  <TAB> out += struct.pack("">L"", b)[: n - 1] <TAB>  <TAB>  <TAB> break <TAB> return out","elif c == ""~"" :",200
"def get_max_shape(data): <TAB> if isinstance(data, dict): <TAB>  <TAB> max = 0 <TAB>  <TAB> val = None <TAB>  <TAB> for k, v in data.items(): <TAB>  <TAB>  <TAB> tmp = reduce(lambda x, y: x * y, v.shape) <MASK> val = v.shape <TAB>  <TAB>  <TAB>  <TAB> max = tmp <TAB>  <TAB> return val <TAB> else: <TAB>  <TAB> return data[0].shape",if tmp > max :,109
"def _subscribe_core( <TAB> self, observer: typing.Observer, scheduler: Optional[typing.Scheduler] = None) -> typing.Disposable: <TAB> with self.lock: <TAB>  <TAB> self.check_disposed() <MASK> self.observers.append(observer) <TAB>  <TAB>  <TAB> return InnerSubscription(self, observer) <TAB>  <TAB> ex = self.exception <TAB>  <TAB> has_value = self.has_value <TAB>  <TAB> value = self.value <TAB> if ex: <TAB>  <TAB> observer.on_error(ex) <TAB> elif has_value: <TAB>  <TAB> observer.on_next(value) <TAB>  <TAB> observer.on_completed() <TAB> else: <TAB>  <TAB> observer.on_completed() <TAB> return Disposable()",if not self . is_stopped :,182
"def ratio(self, outevent, inevent): <TAB> assert outevent not in self <TAB> assert inevent in self <TAB> for function in compat_itervalues(self.functions): <TAB>  <TAB> assert outevent not in function <TAB>  <TAB> assert inevent in function <TAB>  <TAB> function[outevent] = ratio(function[inevent], self[inevent]) <TAB>  <TAB> for call in compat_itervalues(function.calls): <TAB>  <TAB>  <TAB> assert outevent not in call <MASK> call[outevent] = ratio(call[inevent], self[inevent]) <TAB> self[outevent] = 1.0",if inevent in call :,131
"def _format_changelog(self, changelog): <TAB> """"""Format the changelog correctly and convert it to a list of strings"""""" <TAB> if not changelog: <TAB>  <TAB> return changelog <TAB> new_changelog = [] <TAB> for line in changelog.strip().split(""\n""): <TAB>  <TAB> line = line.strip() <TAB>  <TAB> if line[0] == ""*"": <TAB>  <TAB>  <TAB> new_changelog.extend(["""", line]) <MASK> new_changelog.append(line) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_changelog.append(""  "" + line) <TAB> # strip trailing newline inserted by first changelog entry <TAB> if not new_changelog[0]: <TAB>  <TAB> del new_changelog[0] <TAB> return new_changelog","elif line [ 0 ] == ""-"" :",168
"def _set_base64md5(self, value): <TAB> if value: <MASK> value = value.decode(""utf-8"") <TAB>  <TAB> self.local_hashes[""md5""] = binascii.a2b_base64(value) <TAB> elif ""md5"" in self.local_hashes: <TAB>  <TAB> del self.local_hashes[""md5""]","if not isinstance ( value , six . string_types ) :",99
"def setGeometry(self, rect): <TAB> """"""Set the window geometry, but only once when using the qttabs gui."""""" <TAB> if g.app.qt_use_tabs: <TAB>  <TAB> m = self.leo_master <TAB>  <TAB> assert self.leo_master <TAB>  <TAB> # Only set the geometry once, even for new files. <MASK> m.leo_geom_inited = True <TAB>  <TAB>  <TAB> self.leo_master.setGeometry(rect) <TAB>  <TAB>  <TAB> QtWidgets.QMainWindow.setGeometry(self, rect) <TAB> else: <TAB>  <TAB> QtWidgets.QMainWindow.setGeometry(self, rect)","if not hasattr ( m , ""leo_geom_inited"" ) :",166
"def _get_extension_suppressions(mod_loaders): <TAB> res = [] <TAB> for m in mod_loaders: <TAB>  <TAB> suppressions = getattr(m, ""suppress_extension"", None) <TAB>  <TAB> if suppressions: <TAB>  <TAB>  <TAB> suppressions = ( <TAB>  <TAB>  <TAB>  <TAB> suppressions if isinstance(suppressions, list) else [suppressions] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> for sup in suppressions: <MASK> res.append(sup) <TAB> return res","if isinstance ( sup , ModExtensionSuppress ) :",134
"def _check_positional(results): <TAB> positional = None <TAB> for name, char in results: <TAB>  <TAB> if positional is None: <TAB>  <TAB>  <TAB> positional = name is None <TAB>  <TAB> else: <MASK> raise TranslationError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""format string mixes positional "" ""and named placeholders"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return bool(positional)",if ( name is None ) != positional :,98
"def ascii85decode(data): <TAB> n = b = 0 <TAB> out = """" <TAB> for c in data: <TAB>  <TAB> if ""!"" <= c and c <= ""u"": <TAB>  <TAB>  <TAB> n += 1 <TAB>  <TAB>  <TAB> b = b * 85 + (ord(c) - 33) <TAB>  <TAB>  <TAB> if n == 5: <TAB>  <TAB>  <TAB>  <TAB> out += struct.pack("">L"", b) <TAB>  <TAB>  <TAB>  <TAB> n = b = 0 <MASK> assert n == 0 <TAB>  <TAB>  <TAB> out += ""\0\0\0\0"" <TAB>  <TAB> elif c == ""~"": <TAB>  <TAB>  <TAB> if n: <TAB>  <TAB>  <TAB>  <TAB> for _ in range(5 - n): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> b = b * 85 + 84 <TAB>  <TAB>  <TAB>  <TAB> out += struct.pack("">L"", b)[: n - 1] <TAB>  <TAB>  <TAB> break <TAB> return out","elif c == ""z"" :",200
"def __getattr__(self, name): <TAB> # if the aval property raises an AttributeError, gets caught here <TAB> assert skip_checks or name != ""aval"" <TAB> try: <TAB>  <TAB> attr = getattr(self.aval, name) <TAB> except KeyError as err: <TAB>  <TAB> raise AttributeError( <TAB>  <TAB>  <TAB> ""{} has no attribute {}"".format(self.__class__.__name__, name) <TAB>  <TAB> ) from err <TAB> else: <TAB>  <TAB> t = type(attr) <MASK> return attr.fget(self) <TAB>  <TAB> elif t is aval_method: <TAB>  <TAB>  <TAB> return types.MethodType(attr.fun, self) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return attr",if t is aval_property :,165
"def build_vocab(self, filename): <TAB> EOS = ""</eos>"" <TAB> vocab_dict = {} <TAB> ids = 0 <TAB> vocab_dict[EOS] = ids <TAB> ids += 1 <TAB> with open(filename, ""r"") as f: <TAB>  <TAB> for line in f.readlines(): <TAB>  <TAB>  <TAB> for w in line.strip().split(): <MASK> vocab_dict[w] = ids <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ids += 1 <TAB> self.vocab_size = ids <TAB> return vocab_dict",if w not in vocab_dict :,131
"def eval_dummy_genomes_iznn(genomes, config): <TAB> for genome_id, genome in genomes: <TAB>  <TAB> net = neat.iznn.IZNN.create(genome, config) <TAB>  <TAB> if genome_id < 10: <TAB>  <TAB>  <TAB> net.reset() <TAB>  <TAB>  <TAB> genome.fitness = 0.0 <MASK> genome.fitness = 0.5 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> genome.fitness = 1.0",elif genome_id <= 150 :,129
"def _add_csrf(self, without_csrf, explicit_csrf=None): <TAB> parts = urlparse(without_csrf) <TAB> query = parse_qs(parts[4]) <TAB> with self.app.session_transaction() as sess: <MASK> query[CSRF_TOKEN_KEY] = explicit_csrf <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sess[CSRF_TOKEN_KEY] = ""something"" <TAB>  <TAB>  <TAB> query[CSRF_TOKEN_KEY] = sess[CSRF_TOKEN_KEY] <TAB> return urlunparse(list(parts[0:4]) + [urlencode(query)] + list(parts[5:]))",if explicit_csrf is not None :,154
"def test_confirm_extension_is_yml(self): <TAB> files_with_incorrect_extensions = [] <TAB> for file in self.yield_next_rule_file_path(self.path_to_rules): <TAB>  <TAB> file_name_and_extension = os.path.splitext(file) <MASK> extension = file_name_and_extension[1] <TAB>  <TAB>  <TAB> if extension != "".yml"": <TAB>  <TAB>  <TAB>  <TAB> files_with_incorrect_extensions.append(file) <TAB> self.assertEqual( <TAB>  <TAB> files_with_incorrect_extensions, <TAB>  <TAB> [], <TAB>  <TAB> Fore.RED + ""There are rule files with extensions other than .yml"", <TAB> )",if len ( file_name_and_extension ) == 2 :,172
"def _handle_eof(self, m): <TAB> self.lock.acquire() <TAB> try: <TAB>  <TAB> if not self.eof_received: <TAB>  <TAB>  <TAB> self.eof_received = True <TAB>  <TAB>  <TAB> self.in_buffer.close() <TAB>  <TAB>  <TAB> self.in_stderr_buffer.close() <MASK> self._pipe.set_forever() <TAB> finally: <TAB>  <TAB> self.lock.release() <TAB> self._log(DEBUG, ""EOF received ({})"".format(self._name))",if self . _pipe is not None :,127
"def do_close(self): <TAB> if self.flags is not None and (self.flags == ""c"" or self.flags == ""w""): <MASK> insert = self.table.insert() <TAB>  <TAB>  <TAB> self.bind.execute( <TAB>  <TAB>  <TAB>  <TAB> insert, <TAB>  <TAB>  <TAB>  <TAB> namespace=self.namespace, <TAB>  <TAB>  <TAB>  <TAB> data=self.hash, <TAB>  <TAB>  <TAB>  <TAB> accessed=datetime.now(), <TAB>  <TAB>  <TAB>  <TAB> created=datetime.now(), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self._is_new = False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> update = self.table.update(self.table.c.namespace == self.namespace) <TAB>  <TAB>  <TAB> self.bind.execute(update, data=self.hash, accessed=datetime.now()) <TAB> self.flags = None",if self . _is_new :,194
"def __init__(self, sh_cmd, title=None, env=None, d=None): <TAB> self.command = d and d.getVar(""OE_TERMINAL_CUSTOMCMD"") <TAB> if self.command: <MASK> self.command += "" {command}"" <TAB>  <TAB> Terminal.__init__(self, sh_cmd, title, env, d) <TAB>  <TAB> logger.warn(""Custom terminal was started."") <TAB> else: <TAB>  <TAB> logger.debug(1, ""No custom terminal (OE_TERMINAL_CUSTOMCMD) set"") <TAB>  <TAB> raise UnsupportedTerminal(""OE_TERMINAL_CUSTOMCMD not set"")","if not ""{command}"" in self . command :",152
"def __code_color(self, code): <TAB> if code in self.last_dist.keys(): <MASK> return self.screen.markup.GREEN <TAB>  <TAB> elif int(code) == 314: <TAB>  <TAB>  <TAB> return self.screen.markup.MAGENTA <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.screen.markup.RED <TAB> else: <TAB>  <TAB> return """"",if int ( code ) == 0 :,97
"def _calc_benchmark_stat(self, f): <TAB> timer = Timer() <TAB> i = 0 <TAB> while True: <TAB>  <TAB> f() <TAB>  <TAB> i += 1 <TAB>  <TAB> if i >= self.min_run: <TAB>  <TAB>  <TAB> _, elapsed = timer.lap() <MASK> break <TAB> return BenchmarkStat(elapsed / i, i)",if elapsed > self . min_time :,96
"def _get_user_call_site(): <TAB> import traceback <TAB> stack = traceback.extract_stack(sys._getframe()) <TAB> for i in range(1, len(stack)): <TAB>  <TAB> callee_path = stack[i][STACK_FILE_NAME] <MASK> caller_path = stack[i - 1][STACK_FILE_NAME] <TAB>  <TAB>  <TAB> caller_lineno = stack[i - 1][STACK_LINE_NUM] <TAB>  <TAB>  <TAB> dpark_func_name = stack[i][STACK_FUNC_NAME] <TAB>  <TAB>  <TAB> user_call_site = ""%s:%d "" % (caller_path, caller_lineno) <TAB>  <TAB>  <TAB> return dpark_func_name, user_call_site <TAB> return ""<func>"", "" <root>""",if src_dir == os . path . dirname ( os . path . abspath ( callee_path ) ) :,196
"def compact_repr(record): <TAB> parts = [] <TAB> for key in record.__attributes__: <TAB>  <TAB> value = getattr(record, key) <MASK> continue <TAB>  <TAB> if isinstance(value, list): <TAB>  <TAB>  <TAB> value = HIDE_LIST <TAB>  <TAB> elif key == FEATS: <TAB>  <TAB>  <TAB> value = format_feats(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = repr(value) <TAB>  <TAB> value = capped_str(value) <TAB>  <TAB> parts.append(""%s=%s"" % (key, value)) <TAB> return ""%s(%s)"" % (record.__class__.__name__, "", "".join(parts))",if not value :,152
"def get_tools(self, found_files): <TAB> self.configured_by = {} <TAB> runners = [] <TAB> for tool_name in self.tools_to_run: <TAB>  <TAB> tool = tools.TOOLS[tool_name]() <TAB>  <TAB> config_result = tool.configure(self, found_files) <MASK> configured_by = None <TAB>  <TAB>  <TAB> messages = [] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> configured_by, messages = config_result <TAB>  <TAB>  <TAB> if messages is None: <TAB>  <TAB>  <TAB>  <TAB> messages = [] <TAB>  <TAB> self.configured_by[tool_name] = configured_by <TAB>  <TAB> self.messages += messages <TAB>  <TAB> runners.append(tool) <TAB> return runners",if config_result is None :,172
"def erase_previous(self): <TAB> if self.prev: <TAB>  <TAB> length = len(self.prev) <MASK> length = length - 1 <TAB>  <TAB> self.write("" "" * length + ""\r"") <TAB>  <TAB> self.prev = """"","if self . prev [ - 1 ] in ( ""\n"" , ""\r"" ) :",74
"def __demo_mode_pause_if_active(self, tiny=False): <TAB> if self.demo_mode: <TAB>  <TAB> wait_time = settings.DEFAULT_DEMO_MODE_TIMEOUT <MASK> wait_time = float(self.demo_sleep) <TAB>  <TAB> if not tiny: <TAB>  <TAB>  <TAB> time.sleep(wait_time) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> time.sleep(wait_time / 3.4) <TAB> elif self.slow_mode: <TAB>  <TAB> self.__slow_mode_pause_if_active()",if self . demo_sleep :,134
"def pack_remaining_length(remaining_length): <TAB> s = """" <TAB> while True: <TAB>  <TAB> byte = remaining_length % 128 <TAB>  <TAB> remaining_length = remaining_length // 128 <TAB>  <TAB> # If there are more digits to encode, set the top bit of this digit <TAB>  <TAB> if remaining_length > 0: <TAB>  <TAB>  <TAB> byte = byte | 0x80 <TAB>  <TAB> s = s + struct.pack(""!B"", byte) <MASK> return s",if remaining_length == 0 :,115
"def _get_definitions(self, schema, query): <TAB> results, error = self.run_query(query, None) <TAB> if error is not None: <TAB>  <TAB> raise Exception(""Failed getting schema."") <TAB> results = json_loads(results) <TAB> for row in results[""rows""]: <TAB>  <TAB> if row[""TABLE_SCHEMA""] != ""public"": <TAB>  <TAB>  <TAB> table_name = ""{}.{}"".format(row[""TABLE_SCHEMA""], row[""TABLE_NAME""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> table_name = row[""TABLE_NAME""] <MASK> schema[table_name] = {""name"": table_name, ""columns"": []} <TAB>  <TAB> schema[table_name][""columns""].append(row[""COLUMN_NAME""])",if table_name not in schema :,174
def _parsed_config_to_dict(config): <TAB> config_dict = {} <TAB> for section in config.keys(): <MASK> continue <TAB>  <TAB> config_dict[section] = {} <TAB>  <TAB> for option in config[section].keys(): <TAB>  <TAB>  <TAB> config_dict[section][option] = config[section][option] <TAB> return config_dict,"if section == ""DEFAULT"" :",91
"def escape_string(self, value): <TAB> value = EscapedString.promote(value) <TAB> value = value.expanduser() <TAB> result = """" <TAB> for is_literal, txt in value.strings: <TAB>  <TAB> if is_literal: <TAB>  <TAB>  <TAB> txt = pipes.quote(txt) <MASK> txt = ""'%s'"" % txt <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> txt = txt.replace(""\\"", ""\\\\"") <TAB>  <TAB>  <TAB> txt = txt.replace('""', '\\""') <TAB>  <TAB>  <TAB> txt = '""%s""' % txt <TAB>  <TAB> result += txt <TAB> return result","if not txt . startswith ( ""'"" ) :",139
"def sendMessage(self, text, meta=None): <TAB> if self.account.client is None: <TAB>  <TAB> raise locals.OfflineError <TAB> for line in text.split(""\n""): <MASK> self.account.client.ctcpMakeQuery(self.name, [(""ACTION"", line)]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.account.client.msg(self.name, line) <TAB> return succeed(text)","if meta and meta . get ( ""style"" , None ) == ""emote"" :",116
"def clean_email(self): <TAB> email = self.cleaned_data.get(""email"") <TAB> if self.instance.id: <MASK> if not User.objects.filter(email=self.cleaned_data.get(""email"")).exists(): <TAB>  <TAB>  <TAB>  <TAB> return self.cleaned_data.get(""email"") <TAB>  <TAB>  <TAB> raise forms.ValidationError(""Email already exists"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.cleaned_data.get(""email"") <TAB> else: <TAB>  <TAB> if not User.objects.filter(email=self.cleaned_data.get(""email"")).exists(): <TAB>  <TAB>  <TAB> return self.cleaned_data.get(""email"") <TAB>  <TAB> raise forms.ValidationError(""User already exists with this email"")",if self . instance . email != email :,177
"def render_checks(cr, size, nchecks): <TAB> """"""Render a checquerboard pattern to a cairo surface"""""" <TAB> cr.set_source_rgb(*gui.style.ALPHA_CHECK_COLOR_1) <TAB> cr.paint() <TAB> cr.set_source_rgb(*gui.style.ALPHA_CHECK_COLOR_2) <TAB> for i in xrange(0, nchecks): <TAB>  <TAB> for j in xrange(0, nchecks): <MASK> continue <TAB>  <TAB>  <TAB> cr.rectangle(i * size, j * size, size, size) <TAB>  <TAB>  <TAB> cr.fill()",if ( i + j ) % 2 == 0 :,155
"def seek(self, timestamp, log=True): <TAB> """"""Seek to a particular timestamp in the movie."""""" <TAB> if self.status in [PLAYING, PAUSED]: <TAB>  <TAB> player = self._player <MASK> player.set_time(int(timestamp * 1000.0)) <TAB>  <TAB>  <TAB> self._vlc_clock.reset(timestamp) <TAB>  <TAB>  <TAB> if self.status == PAUSED: <TAB>  <TAB>  <TAB>  <TAB> self._pause_time = timestamp <TAB>  <TAB> if log: <TAB>  <TAB>  <TAB> logAttrib(self, log, ""seek"", timestamp)",if player and player . is_seekable ( ) :,137
"def class_results_to_node(key, elements): <TAB> title = attributetabletitle(key, key) <TAB> ul = nodes.bullet_list("""") <TAB> for element in elements: <TAB>  <TAB> ref = nodes.reference( <TAB>  <TAB>  <TAB> """", <TAB>  <TAB>  <TAB> """", <TAB>  <TAB>  <TAB> internal=True, <TAB>  <TAB>  <TAB> refuri=""#"" + element.fullname, <TAB>  <TAB>  <TAB> anchorname="""", <TAB>  <TAB>  <TAB> *[nodes.Text(element.label)] <TAB>  <TAB> ) <TAB>  <TAB> para = addnodes.compact_paragraph("""", """", ref) <MASK> ul.append(attributetable_item("""", element.badge, para)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ul.append(attributetable_item("""", para)) <TAB> return attributetablecolumn("""", title, ul)",if element . badge is not None :,193
"def parse_function(self, l): <TAB> bracket = l.find(""("") <TAB> fname = l[8:bracket] <TAB> if self.properties: <TAB>  <TAB> if self.properties[0] == ""propget"": <TAB>  <TAB>  <TAB> self.props[fname] = 1 <TAB>  <TAB>  <TAB> self.propget[fname] = 1 <MASK> self.props[fname] = 1 <TAB>  <TAB>  <TAB> self.propput[fname] = 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.functions[fname] = 1 <TAB> self.properties = None","elif self . properties [ 0 ] == ""propput"" :",139
"def _slurp_from_queue(self, task_id, accept, limit=1000, no_ack=False): <TAB> with self.app.pool.acquire_channel(block=True) as (_, channel): <TAB>  <TAB> binding = self._create_binding(task_id)(channel) <TAB>  <TAB> binding.declare() <TAB>  <TAB> for _ in range(limit): <TAB>  <TAB>  <TAB> msg = binding.get(accept=accept, no_ack=no_ack) <MASK> break <TAB>  <TAB>  <TAB> yield msg <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise self.BacklogLimitExceeded(task_id)",if not msg :,147
"def analyse_text(text): <TAB> if re.search(r""^\s*model\s*\{"", text, re.M): <TAB>  <TAB> if re.search(r""^\s*data\s*\{"", text, re.M): <TAB>  <TAB>  <TAB> return 0.9 <MASK> return 0.9 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return 0.3 <TAB> else: <TAB>  <TAB> return 0","elif re . search ( r""^\s*var"" , text , re . M ) :",113
"def wait_for_step(self, error_buffer=None, timeout=None): <TAB> # TODO: this might be cleaner using channels <TAB> with self.cv: <TAB>  <TAB> start = time.time() <TAB>  <TAB> while True: <MASK> return <TAB>  <TAB>  <TAB> elif timeout is not None and time.time() - start > timeout: <TAB>  <TAB>  <TAB>  <TAB> raise error.Error(""No rewards received in {}s"".format(timeout)) <TAB>  <TAB>  <TAB> if error_buffer: <TAB>  <TAB>  <TAB>  <TAB> error_buffer.check() <TAB>  <TAB>  <TAB> self.cv.wait(timeout=0.5)",if self . count != 0 :,146
"def TestDictAgainst(dict, check): <TAB> for key, value in check.iteritems(): <MASK> raise error( <TAB>  <TAB>  <TAB>  <TAB> ""Indexing for '%s' gave the incorrect value - %s/%s"" <TAB>  <TAB>  <TAB>  <TAB> % (repr(key), repr(dict[key]), repr(check[key])) <TAB>  <TAB>  <TAB> )",if dict ( key ) != value :,90
"def callback(username, password, msg): <TAB> self.add_channel() <TAB> if hasattr(self, ""_closed"") and not self._closed: <TAB>  <TAB> self.attempted_logins += 1 <MASK> msg += "" Disconnecting."" <TAB>  <TAB>  <TAB> self.respond(""530 "" + msg) <TAB>  <TAB>  <TAB> self.close_when_done() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.respond(""530 "" + msg) <TAB>  <TAB> self.log(""USER '%s' failed login."" % username) <TAB> self.on_login_failed(username, password)",if self . attempted_logins >= self . max_login_attempts :,150
"def handle_disconnect(self): <TAB> """"""Socket gets disconnected"""""" <TAB> # signal disconnected terminal with control lines <TAB> try: <TAB>  <TAB> self.serial.rts = False <TAB>  <TAB> self.serial.dtr = False <TAB> finally: <TAB>  <TAB> # restore original port configuration in case it was changed <TAB>  <TAB> self.serial.apply_settings(self.serial_settings_backup) <TAB>  <TAB> # stop RFC 2217 state machine <TAB>  <TAB> self.rfc2217 = None <TAB>  <TAB> # clear send buffer <TAB>  <TAB> self.buffer_ser2net = bytearray() <TAB>  <TAB> # close network connection <MASK> self.socket.close() <TAB>  <TAB>  <TAB> self.socket = None <TAB>  <TAB>  <TAB> if self.log is not None: <TAB>  <TAB>  <TAB>  <TAB> self.log.warning(""{}: Disconnected"".format(self.device))",if self . socket is not None :,195
"def select_invitation_id_for_network(invitations, networkid, status=None): <TAB> # Get invitations based on network and maybe status <TAB> invitationsfornetwork = [] <TAB> for invitation in invitations: <MASK> if status is None or invitation[""Status""] == status: <TAB>  <TAB>  <TAB>  <TAB> invitationsfornetwork.append(invitation[""InvitationId""]) <TAB> return invitationsfornetwork","if invitation [ ""NetworkSummary"" ] [ ""Id"" ] == networkid :",123
"def fit(self, refstring, subpipes): <TAB> if not isinstance(subpipes, list): <TAB>  <TAB> subpipes = [subpipes] <TAB> for subpipe in subpipes: <MASK> substring = subpipe.transform(None) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> substring = subpipe <TAB>  <TAB> self._scores.append( <TAB>  <TAB>  <TAB> ( <TAB>  <TAB>  <TAB>  <TAB> self.base_aligner.fit_transform(refstring, substring, get_score=True), <TAB>  <TAB>  <TAB>  <TAB> subpipe, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB> return self","if hasattr ( subpipe , ""transform"" ) :",149
"def build_priorities(self, _iter, priorities): <TAB> while _iter is not None: <MASK> self.build_priorities(self.files_treestore.iter_children(_iter), priorities) <TAB>  <TAB> elif not self.files_treestore.get_value(_iter, 1).endswith(os.path.sep): <TAB>  <TAB>  <TAB> priorities[ <TAB>  <TAB>  <TAB>  <TAB> self.files_treestore.get_value(_iter, 3) <TAB>  <TAB>  <TAB> ] = self.files_treestore.get_value(_iter, 0) <TAB>  <TAB> _iter = self.files_treestore.iter_next(_iter) <TAB> return priorities",if self . files_treestore . iter_has_child ( _iter ) :,170
"def __init__(self, fileobj, info): <TAB> pages = [] <TAB> complete = False <TAB> while not complete: <TAB>  <TAB> page = OggPage(fileobj) <MASK> pages.append(page) <TAB>  <TAB>  <TAB> complete = page.complete or (len(page.packets) > 1) <TAB> packets = OggPage.to_packets(pages) <TAB> if not packets: <TAB>  <TAB> raise error(""Missing metadata packet"") <TAB> data = packets[0][7:] <TAB> super(OggTheoraCommentDict, self).__init__(data, framing=False) <TAB> self._padding = len(data) - self._size",if page . serial == info . serial :,155
"def _run_interface(self, runtime): <TAB> mel_icas = [] <TAB> for item in self.inputs.mel_icas_in: <MASK> mel_icas.append(item) <TAB> if len(mel_icas) == 0: <TAB>  <TAB> raise Exception( <TAB>  <TAB>  <TAB> ""%s did not find any hand_labels_noise.txt files in the following directories: %s"" <TAB>  <TAB>  <TAB> % (self.__class__.__name__, mel_icas) <TAB>  <TAB> ) <TAB> return runtime","if os . path . exists ( os . path . join ( item , ""hand_labels_noise.txt"" ) ) :",150
"def download_file(url, file): <TAB> try: <TAB>  <TAB> xlog.info(""download %s to %s"", url, file) <TAB>  <TAB> req = opener.open(url) <TAB>  <TAB> CHUNK = 16 * 1024 <TAB>  <TAB> with open(file, ""wb"") as fp: <TAB>  <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB>  <TAB> chunk = req.read(CHUNK) <MASK> break <TAB>  <TAB>  <TAB>  <TAB> fp.write(chunk) <TAB>  <TAB> return True <TAB> except: <TAB>  <TAB> xlog.info(""download %s to %s fail"", url, file) <TAB>  <TAB> return False",if not chunk :,147
"def check_sales_order_on_hold_or_close(self, ref_fieldname): <TAB> for d in self.get(""items""): <TAB>  <TAB> if d.get(ref_fieldname): <TAB>  <TAB>  <TAB> status = frappe.db.get_value(""Sales Order"", d.get(ref_fieldname), ""status"") <MASK> frappe.throw( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _(""Sales Order {0} is {1}"").format(d.get(ref_fieldname), status) <TAB>  <TAB>  <TAB>  <TAB> )","if status in ( ""Closed"" , ""On Hold"" ) :",137
"def iterstack(sources, missing, trim, pad): <TAB> its = [iter(t) for t in sources] <TAB> hdrs = [next(it) for it in its] <TAB> hdr = hdrs[0] <TAB> n = len(hdr) <TAB> yield tuple(hdr) <TAB> for it in its: <TAB>  <TAB> for row in it: <TAB>  <TAB>  <TAB> outrow = tuple(row) <MASK> outrow = outrow[:n] <TAB>  <TAB>  <TAB> if pad and len(outrow) < n: <TAB>  <TAB>  <TAB>  <TAB> outrow += (missing,) * (n - len(outrow)) <TAB>  <TAB>  <TAB> yield outrow",if trim :,153
"def __call__(self, response_headers): <TAB> rates = get_rates_from_response_headers(response_headers) <TAB> if rates: <TAB>  <TAB> time.sleep( <TAB>  <TAB>  <TAB> self._get_wait_time( <TAB>  <TAB>  <TAB>  <TAB> rates.short_usage, <TAB>  <TAB>  <TAB>  <TAB> rates.long_usage, <TAB>  <TAB>  <TAB>  <TAB> get_seconds_until_next_quarter(), <TAB>  <TAB>  <TAB>  <TAB> get_seconds_until_next_day(), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <MASK> self.short_limit = rates.short_limit <TAB>  <TAB>  <TAB> self.long_limit = rates.long_limit",if not self . force_limits :,156
"def main(self): <TAB> self.model.clear() <TAB> self.callman.unregister_all() <TAB> active_handle = self.get_active(""Place"") <TAB> if active_handle: <TAB>  <TAB> active = self.dbstate.db.get_place_from_handle(active_handle) <MASK> self.display_place(active, None, [active_handle], DateRange()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.set_has_data(False) <TAB> else: <TAB>  <TAB> self.set_has_data(False)",if active :,134
"def node_exists(self, jid=None, node=None, ifrom=None): <TAB> with self.lock: <TAB>  <TAB> if jid is None: <TAB>  <TAB>  <TAB> jid = self.xmpp.boundjid.full <TAB>  <TAB> if node is None: <TAB>  <TAB>  <TAB> node = """" <MASK> ifrom = """" <TAB>  <TAB> if isinstance(ifrom, JID): <TAB>  <TAB>  <TAB> ifrom = ifrom.full <TAB>  <TAB> if (jid, node, ifrom) not in self.nodes: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True",if ifrom is None :,136
"def append_to(project_url, destination): <TAB> url = (""%smagic/%s"" % (project_url, destination)).replace(""\\"", ""/"") <TAB> response = urllib2.urlopen(url) <TAB> if response.getcode() == 200: <TAB>  <TAB> with open(destination, ""r"") as dest: <TAB>  <TAB>  <TAB> lines = """".join(dest.readlines()) <TAB>  <TAB>  <TAB> content = response.read() <MASK> print_out(""IGNORED"", destination) <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> with open(destination, ""a"") as dest: <TAB>  <TAB>  <TAB> dest.write(content) <TAB>  <TAB>  <TAB> print_out(""APPEND"", destination)",if content in lines :,158
"def close(self, invalidate=False): <TAB> self.session.transaction = self._parent <TAB> if self._parent is None: <TAB>  <TAB> for connection, transaction, autoclose in set(self._connections.values()): <TAB>  <TAB>  <TAB> if invalidate: <TAB>  <TAB>  <TAB>  <TAB> connection.invalidate() <TAB>  <TAB>  <TAB> if autoclose: <TAB>  <TAB>  <TAB>  <TAB> connection.close() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> transaction.close() <TAB> self._state = CLOSED <TAB> self.session.dispatch.after_transaction_end(self.session, self) <TAB> if self._parent is None: <MASK> self.session.begin() <TAB> self.session = None <TAB> self._connections = None",if not self . session . autocommit :,172
"def list_local_packages(path): <TAB> """"""Lists all local packages below a path that could be installed."""""" <TAB> rv = [] <TAB> try: <TAB>  <TAB> for filename in os.listdir(path): <MASK> rv.append(""@"" + filename) <TAB> except OSError: <TAB>  <TAB> pass <TAB> return rv","if os . path . isfile ( os . path . join ( path , filename , ""setup.py"" ) ) :",98
"def walk_dir(templates, dest, filter=None): <TAB> l = [] <TAB> for root, folders, files in os.walk(templates): <TAB>  <TAB> for filename in files: <MASK> continue <TAB>  <TAB>  <TAB> relative_dir = "".{0}"".format( <TAB>  <TAB>  <TAB>  <TAB> os.path.split(os.path.join(root, filename).replace(templates, """"))[0] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> l.append((os.path.join(root, filename), os.path.join(dest, relative_dir))) <TAB> return l","if filename . endswith ( "".pyc"" ) or ( filter and filename not in filter ) :",150
"def selectItemHelper(self, item, scroll): <TAB> if self.frame.lockout: <TAB>  <TAB> return <TAB> w = self.treeWidget <TAB> if item and item.IsOk(): <TAB>  <TAB> self.frame.lockout = True <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> w.SelectItem(item) <MASK> w.ScrollTo(item) <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self.frame.lockout = False",if scroll :,104
"def validate_external(self, field): <TAB> if hasattr(self, ""forum""): <MASK> raise ValidationError( <TAB>  <TAB>  <TAB>  <TAB> _( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""You cannot convert a forum that "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""contains topics into an "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""external link."" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> )",if self . forum . topics . count ( ) > 0 :,95
"def add_help(self): <TAB> ""Attach help functions for each of the parsed token handlers."" <TAB> for attrname, func in list(shell.BQLShell.__dict__.items()): <MASK> continue <TAB>  <TAB> command_name = attrname[3:] <TAB>  <TAB> setattr( <TAB>  <TAB>  <TAB> self.__class__, <TAB>  <TAB>  <TAB> ""help_{}"".format(command_name.lower()), <TAB>  <TAB>  <TAB> lambda _, fun=func: print( <TAB>  <TAB>  <TAB>  <TAB> textwrap.dedent(fun.__doc__).strip(), file=self.outfile <TAB>  <TAB>  <TAB> ), <TAB>  <TAB> )","if attrname [ : 3 ] != ""on_"" :",141
"def createFields(self): <TAB> yield UInt8(self, ""tag"") <TAB> yield UInt24(self, ""size"", ""Content size"") <TAB> yield UInt24(self, ""timestamp"", ""Timestamp in millisecond"") <TAB> yield NullBytes(self, ""reserved"", 4) <TAB> size = self[""size""].value <TAB> if size: <MASK> for field in self.parser(self, size): <TAB>  <TAB>  <TAB>  <TAB> yield field <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield RawBytes(self, ""content"", size)",if self . parser :,130
"def migrate_model_field_data(Model): <TAB> queryset = Model.objects.all().order_by(""pk"") <TAB> for batch_pks in queryset_in_batches(queryset): <TAB>  <TAB> instances = [] <TAB>  <TAB> batch = Model.objects.filter(pk__in=batch_pks) <TAB>  <TAB> for instance in batch: <MASK> instance.content_json = parse_to_editorjs(instance.content_json) <TAB>  <TAB>  <TAB>  <TAB> instances.append(instance) <TAB>  <TAB> Model.objects.bulk_update(instances, [""content_json""])",if instance . content_json :,139
"def _add_account(cfg, which): <TAB> username = self._get_account(cfg) <TAB> if ( <TAB>  <TAB> username <TAB>  <TAB> and ((username == only) or only is None) <TAB>  <TAB> and cfg.auth_type == ""password"" <TAB> ): <MASK> accounts[username][which] = cfg.host <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> fingerprint = self._user_fingerprint(username) <TAB>  <TAB>  <TAB> accounts[username] = { <TAB>  <TAB>  <TAB>  <TAB> which: cfg.host, <TAB>  <TAB>  <TAB>  <TAB> ""username"": username, <TAB>  <TAB>  <TAB>  <TAB> ""policy"": self._get_policy(fingerprint), <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB> if accounts[username][""policy""] is None: <TAB>  <TAB>  <TAB>  <TAB> del accounts[username][""policy""]",if username in accounts :,180
"def update_msg_tags(self, msg_idx_pos, msg_info): <TAB> tags = set(self.get_tags(msg_info=msg_info)) <TAB> with self._lock: <TAB>  <TAB> for tid in set(self.TAGS.keys()) - tags: <TAB>  <TAB>  <TAB> self.TAGS[tid] -= set([msg_idx_pos]) <TAB>  <TAB> for tid in tags: <MASK> self.TAGS[tid] = set() <TAB>  <TAB>  <TAB> self.TAGS[tid].add(msg_idx_pos)",if tid not in self . TAGS :,135
"def close(self, reason=""protocol closed, reason unspecified""): <TAB> if self.connection: <TAB>  <TAB> self.logger.debug(reason, self.connection.session()) <TAB>  <TAB> # must be first otherwise we could have a loop caused by the raise in the below <TAB>  <TAB> self.connection.close() <TAB>  <TAB> self.connection = None <TAB>  <TAB> self.peer.stats[""down""] = self.peer.stats.get(""down"", 0) + 1 <TAB>  <TAB> try: <MASK> self.peer.reactor.processes.down(self.peer.neighbor, reason) <TAB>  <TAB> except ProcessError: <TAB>  <TAB>  <TAB> self.logger.debug( <TAB>  <TAB>  <TAB>  <TAB> ""could not send notification of neighbor close to API"", <TAB>  <TAB>  <TAB>  <TAB> self.connection.session(), <TAB>  <TAB>  <TAB> )","if self . peer . neighbor . api [ ""neighbor-changes"" ] :",196
"def check_objects_exist(self, compare_id, raise_exc=True): <TAB> for uid in convert_compare_id_to_list(compare_id): <MASK> if raise_exc: <TAB>  <TAB>  <TAB>  <TAB> raise FactCompareException(""{} not found in database"".format(uid)) <TAB>  <TAB>  <TAB> return True <TAB> return False",if not self . existence_quick_check ( uid ) :,94
"def on_double_click(self, event): <TAB> # self.save_current_folder() <TAB> path = self.get_selected_path() <TAB> if path: <TAB>  <TAB> kind = self.get_selected_kind() <MASK> self.focus_into(path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.log_frame.load_log(path) <TAB> return ""break""  # avoid default action of opening the node","if kind == ""dir"" :",110
"def resolve_cloudtrail_payload(self, payload): <TAB> sources = self.data.get(""sources"", []) <TAB> events = [] <TAB> for e in self.data.get(""events""): <MASK> events.append(e) <TAB>  <TAB>  <TAB> event_info = CloudWatchEvents.get(e) <TAB>  <TAB>  <TAB> if event_info is None: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> event_info = e <TAB>  <TAB>  <TAB> events.append(e[""event""]) <TAB>  <TAB> sources.append(event_info[""source""]) <TAB> payload[""detail""] = {""eventSource"": list(set(sources)), ""eventName"": events}","if not isinstance ( e , dict ) :",159
"def load_graph_session_from_ckpt(ckpt_path, sess_config, print_op=False): <TAB> """"""load graph and session from checkpoint file"""""" <TAB> graph = tf.Graph() <TAB> with graph.as_default():  # pylint: disable=not-context-manager <TAB>  <TAB> sess = get_session(sess_config) <TAB>  <TAB> with sess.as_default():  # pylint: disable=not-context-manager <TAB>  <TAB>  <TAB> # Load the saved meta graph and restore variables <TAB>  <TAB>  <TAB> saver = tf.train.import_meta_graph(""{}.meta"".format(ckpt_path)) <TAB>  <TAB>  <TAB> saver.restore(sess, ckpt_path) <MASK> print_ops(graph, prefix=""load_graph_session_from_ckpt"") <TAB> return graph, sess",if print_op :,186
"def _parseConfigFile(self, iniPath, createConfig=True): <TAB> parser = SafeConfigParserUnicode(strict=False) <TAB> if not os.path.isfile(iniPath): <TAB>  <TAB> if createConfig: <TAB>  <TAB>  <TAB> open(iniPath, ""w"").close() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return <TAB> parser.readfp(codecs.open(iniPath, ""r"", ""utf_8_sig"")) <TAB> for section, options in list(self._iniStructure.items()): <TAB>  <TAB> if parser.has_section(section): <TAB>  <TAB>  <TAB> for option in options: <MASK> self._config[option] = parser.get(section, option)","if parser . has_option ( section , option ) :",170
"def parse(self): <TAB> while 1: <TAB>  <TAB> l = self.f.readline() <TAB>  <TAB> if not l: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> l = l.strip() <TAB>  <TAB> if l.startswith(""[""): <TAB>  <TAB>  <TAB> self.parse_uuid(l) <MASK> self.parse_interface(l) <TAB>  <TAB> elif l.startswith(""coclass""): <TAB>  <TAB>  <TAB> self.parse_coclass(l)","elif l . startswith ( ""interface"" ) or l . startswith ( ""dispinterface"" ) :",117
"def encode(self): <TAB> if not isinstance(self.expr, m2_expr.ExprInt): <TAB>  <TAB> return False <TAB> if not test_set_sf(self.parent, self.expr.size): <TAB>  <TAB> return False <TAB> value = int(self.expr) <TAB> if value < 1 << self.l: <TAB>  <TAB> self.parent.shift.value = 0 <TAB> else: <TAB>  <TAB> if value & 0xFFF: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> value >>= 12 <MASK> return False <TAB>  <TAB> self.parent.shift.value = 1 <TAB> self.value = value <TAB> return True",if value >= 1 << self . l :,154
"def _func_runner(self): <TAB> _locals.thread = self <TAB> try: <TAB>  <TAB> self._final_result = self.target(*self.args, **self.kwargs) <TAB>  <TAB> self._final_exc = None <TAB> except BaseException as e: <TAB>  <TAB> self._final_result = None <TAB>  <TAB> self._final_exc = e <MASK> log.warning(""Unexpected exception in cancelled async thread"", exc_info=True) <TAB> finally: <TAB>  <TAB> self._request.set_result(None)","if not isinstance ( e , errors . CancelledError ) :",133
"def _set_dialect(self, value): <TAB> if value is None: <TAB>  <TAB> self._dialect = mac_eui48 <TAB> else: <MASK> self._dialect = value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError(""custom dialects should subclass mac_eui48!"")","if hasattr ( value , ""word_size"" ) and hasattr ( value , ""word_fmt"" ) :",89
"def fixup_namespace_packages(path_item, parent=None): <TAB> """"""Ensure that previously-declared namespace packages include path_item"""""" <TAB> imp.acquire_lock() <TAB> try: <TAB>  <TAB> for package in _namespace_packages.get(parent, ()): <TAB>  <TAB>  <TAB> subpath = _handle_ns(package, path_item) <MASK> fixup_namespace_packages(subpath, package) <TAB> finally: <TAB>  <TAB> imp.release_lock()",if subpath :,111
"def close_file_descriptor(self, fd): <TAB> """"""Attempt to close a file descriptor."""""" <TAB> start_timer = time.time() <TAB> error = """" <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> fd.close() <TAB>  <TAB>  <TAB> break <TAB>  <TAB> except OSError as e: <TAB>  <TAB>  <TAB> # Undoubtedly close() was called during a concurrent operation on the same file object. <TAB>  <TAB>  <TAB> log.debug(""Error closing file descriptor: %s"" % str(e)) <TAB>  <TAB>  <TAB> time.sleep(0.5) <TAB>  <TAB>  <TAB> current_wait_time = time.time() - start_timer <MASK> error = ""Error closing file descriptor: %s"" % str(e) <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return error",if current_wait_time >= 600 :,186
"def p_constant(self, p): <TAB> """"""constant : PP_NUMBER"""""" <TAB> value = p[1].rstrip(""LlUu"") <TAB> try: <TAB>  <TAB> if value[:2] == ""0x"": <TAB>  <TAB>  <TAB> value = int(value[2:], 16) <MASK> value = int(value, 8) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = int(value) <TAB> except ValueError: <TAB>  <TAB> value = value.rstrip(""eEfF"") <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> value = float(value) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> value = 0 <TAB> p[0] = ConstantExpressionNode(value)","elif value [ 0 ] == ""0"" :",163
"def set_add_delete_state(self): <TAB> ""Toggle the state for the help list buttons based on list entries."" <TAB> if self.helplist.size() < 1:  # No entries in list. <TAB>  <TAB> self.button_helplist_edit.state((""disabled"",)) <TAB>  <TAB> self.button_helplist_remove.state((""disabled"",)) <TAB> else:  # Some entries. <MASK> # There currently is a selection. <TAB>  <TAB>  <TAB> self.button_helplist_edit.state((""!disabled"",)) <TAB>  <TAB>  <TAB> self.button_helplist_remove.state((""!disabled"",)) <TAB>  <TAB> else:  # There currently is not a selection. <TAB>  <TAB>  <TAB> self.button_helplist_edit.state((""disabled"",)) <TAB>  <TAB>  <TAB> self.button_helplist_remove.state((""disabled"",))",if self . helplist . curselection ( ) :,192
def _erase_status(): <TAB> CodeintelHandler.status_lock.acquire() <TAB> try: <MASK> view.erase_status(lid) <TAB>  <TAB>  <TAB> CodeintelHandler.status_msg[lid][1] = None <TAB>  <TAB>  <TAB> if lid in CodeintelHandler.status_lineno: <TAB>  <TAB>  <TAB>  <TAB> del CodeintelHandler.status_lineno[lid] <TAB> finally: <TAB>  <TAB> CodeintelHandler.status_lock.release(),"if msg == CodeintelHandler . status_msg . get ( lid , [ None , None , 0 ] ) [ 1 ] :",135
"def PARSE_TWO_PARAMS(x, y): <TAB> """"""used to convert different possible x/y params to a tuple"""""" <TAB> if y is not None: <TAB>  <TAB> return (x, y) <TAB> else: <MASK> return (x[0], x[1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if isinstance(x, UNIVERSAL_STRING): <TAB>  <TAB>  <TAB>  <TAB> x = x.strip() <TAB>  <TAB>  <TAB>  <TAB> if "","" in x: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return [int(w.strip()) for w in x.split("","")] <TAB>  <TAB>  <TAB> return (x, x)","if isinstance ( x , ( list , tuple ) ) :",147
"def cancel_spot_fleet_requests(self, spot_fleet_request_ids, terminate_instances): <TAB> spot_requests = [] <TAB> for spot_fleet_request_id in spot_fleet_request_ids: <TAB>  <TAB> spot_fleet = self.spot_fleet_requests[spot_fleet_request_id] <MASK> spot_fleet.target_capacity = 0 <TAB>  <TAB>  <TAB> spot_fleet.terminate_instances() <TAB>  <TAB> spot_requests.append(spot_fleet) <TAB>  <TAB> del self.spot_fleet_requests[spot_fleet_request_id] <TAB> return spot_requests",if terminate_instances :,145
"def pop(self, key, default=_MISSING): <TAB> # NB: hit/miss counts are bypassed for pop() <TAB> with self._lock: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> ret = super(LRI, self).pop(key) <TAB>  <TAB> except KeyError: <MASK> raise <TAB>  <TAB>  <TAB> ret = default <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._remove_from_ll(key) <TAB>  <TAB> return ret",if default is _MISSING :,108
"def _remove_optional_none_type_hints(self, type_hints, defaults): <TAB> # If argument has None as a default, typing.get_type_hints adds <TAB> # optional None to the information it returns. We don't want that. <TAB> for arg in defaults: <TAB>  <TAB> if defaults[arg] is None and arg in type_hints: <TAB>  <TAB>  <TAB> type_ = type_hints[arg] <TAB>  <TAB>  <TAB> if self._is_union(type_): <TAB>  <TAB>  <TAB>  <TAB> types = type_.__args__ <MASK> type_hints[arg] = types[0]",if len ( types ) == 2 and types [ 1 ] is type ( None ) :,157
"def reader(self, myself): <TAB> ok = True <TAB> line = """" <TAB> while True: <TAB>  <TAB> line = sys.stdin.readline().strip() <TAB>  <TAB> if ok: <TAB>  <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB>  <TAB> ok = False <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ok = True <TAB>  <TAB> self.Q.append(line) <TAB> os.kill(myself, signal.SIGTERM)",elif not line :,112
"def checkout_branch(self, branch): <TAB> if branch in self.remote_branches: <TAB>  <TAB> sickrage.app.log.debug( <TAB>  <TAB>  <TAB> ""Branch checkout: "" + self._find_installed_version() + ""->"" + branch <TAB>  <TAB> ) <MASK> return False <TAB>  <TAB> # remove untracked files and performs a hard reset on git branch to avoid update issues <TAB>  <TAB> if sickrage.app.config.git_reset: <TAB>  <TAB>  <TAB> self.reset() <TAB>  <TAB> # fetch all branches <TAB>  <TAB> self.fetch() <TAB>  <TAB> __, __, exit_status = self._git_cmd(self._git_path, ""checkout -f "" + branch) <TAB>  <TAB> if exit_status == 0: <TAB>  <TAB>  <TAB> return True <TAB> return False",if not self . install_requirements ( self . current_branch ) :,194
"def last_ok(nodes): <TAB> for i in range(len(nodes) - 1, -1, -1): <TAB>  <TAB> if ok_node(nodes[i]): <TAB>  <TAB>  <TAB> node = nodes[i] <TAB>  <TAB>  <TAB> if isinstance(node, ast.Starred): <MASK> return node.value <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return nodes[i] <TAB> return None",if ok_node ( node . value ) :,122
"def restart(): <TAB> """"""Restart application."""""" <TAB> popen_list = [sys.executable, app.MY_FULLNAME] <TAB> if not app.NO_RESTART: <TAB>  <TAB> popen_list += app.MY_ARGS <MASK> popen_list += [""--nolaunch""] <TAB>  <TAB> logger.info(""Restarting Medusa with {options}"", options=popen_list) <TAB>  <TAB> # shutdown the logger to make sure it's released the logfile BEFORE it restarts Medusa. <TAB>  <TAB> logging.shutdown() <TAB>  <TAB> print(popen_list) <TAB>  <TAB> subprocess.Popen(popen_list, cwd=os.getcwd())","if ""--nolaunch"" not in popen_list :",154
"def StopBackgroundWorkload(self): <TAB> """"""Stop the background workoad."""""" <TAB> for workload in background_workload.BACKGROUND_WORKLOADS: <TAB>  <TAB> if workload.IsEnabled(self): <MASK> raise NotImplementedError() <TAB>  <TAB>  <TAB> workload.Stop(self)",if self . OS_TYPE in workload . EXCLUDED_OS_TYPES :,87
"def __init__(self, token): <TAB> self._convert_to_ascii = False <TAB> self._find = None <TAB> if token.search is None: <TAB>  <TAB> return <TAB> flags = 0 <TAB> self._match_this_many = 1 <TAB> if token.options: <TAB>  <TAB> if ""g"" in token.options: <TAB>  <TAB>  <TAB> self._match_this_many = 0 <MASK> flags |= re.IGNORECASE <TAB>  <TAB> if ""a"" in token.options: <TAB>  <TAB>  <TAB> self._convert_to_ascii = True <TAB> self._find = re.compile(token.search, flags | re.DOTALL) <TAB> self._replace = _CleverReplace(token.replace)","if ""i"" in token . options :",170
"def _draw_nodes(self, cr, bounding, highlight_items): <TAB> highlight_nodes = [] <TAB> for element in highlight_items: <MASK> highlight_nodes.append(element.src) <TAB>  <TAB>  <TAB> highlight_nodes.append(element.dst) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> highlight_nodes.append(element) <TAB> for node in self.nodes: <TAB>  <TAB> if bounding is None or node._intersects(bounding): <TAB>  <TAB>  <TAB> node._draw(cr, highlight=(node in highlight_nodes), bounding=bounding)","if isinstance ( element , Edge ) :",134
"def _removeCachedRFInfo(self, cache_key, path, removeChildPaths): <TAB> log.debug(""_removeCachedRFInfo: cache_key %r, path %r"", cache_key, path) <TAB> if self._cachedFiles.has_key(cache_key): <TAB>  <TAB> cache = self._cachedFiles[cache_key] <TAB>  <TAB> if cache.has_key(path): <TAB>  <TAB>  <TAB> del cache[path] <MASK> # Remove all cached paths that are under this directory <TAB>  <TAB>  <TAB> from remotefilelib import addslash <TAB>  <TAB>  <TAB> dirPath = addslash(path) <TAB>  <TAB>  <TAB> for keypath in cache.keys(): <TAB>  <TAB>  <TAB>  <TAB> if keypath.startswith(dirPath): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> del cache[keypath]",if removeChildPaths :,178
"def write_row(xf, worksheet, row, row_idx, max_column): <TAB> attrs = {""r"": ""%d"" % row_idx, ""spans"": ""1:%d"" % max_column} <TAB> dims = worksheet.row_dimensions <TAB> if row_idx in dims: <TAB>  <TAB> row_dimension = dims[row_idx] <TAB>  <TAB> attrs.update(dict(row_dimension)) <TAB> with xf.element(""row"", attrs): <TAB>  <TAB> for col, cell in row: <MASK> continue <TAB>  <TAB>  <TAB> el = write_cell(xf, worksheet, cell, cell.has_style)",if cell . _value is None and not cell . has_style and not cell . _comment :,165
"def reset_feature_range(data, column_max_value, column_min_value, scale_column_idx): <TAB> _data = copy.deepcopy(data) <TAB> for i in scale_column_idx: <TAB>  <TAB> value = _data.features[i] <MASK> _data.features[i] = column_max_value[i] <TAB>  <TAB> elif value < column_min_value[i]: <TAB>  <TAB>  <TAB> _data.features[i] = column_min_value[i] <TAB> return _data",if value > column_max_value [ i ] :,135
"def test_listing_all_frameworks_and_check_frameworks_by_order(self): <TAB> """"""List all frameworks and check if frameworks appear by order"""""" <TAB> result = subprocess.check_output(self.command_as_list([UMAKE, ""--list""])) <TAB> previous_framework = None <TAB> for element in result.split(b""\n""): <TAB>  <TAB> if element.startswith(b""\t""): <TAB>  <TAB>  <TAB> current_framework = element[: element.find(b"":"")] <MASK> self.assertTrue(previous_framework < current_framework) <TAB>  <TAB>  <TAB> previous_framework = current_framework <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> previous_framework = None",if previous_framework :,160
"def merge(module_name, tree1, tree2): <TAB> for child in tree2.node: <MASK> replaceFunction(tree1, child.name, child) <TAB>  <TAB> elif isinstance(child, ast.Assign): <TAB>  <TAB>  <TAB> replaceAssign(tree1, child.nodes[0].name, child) <TAB>  <TAB> elif isinstance(child, ast.Class): <TAB>  <TAB>  <TAB> replaceClassMethods(tree1, child.name, child) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TranslationError( <TAB>  <TAB>  <TAB>  <TAB> ""Do not know how to merge %s"" % child, child, module_name <TAB>  <TAB>  <TAB> ) <TAB> return tree1","if isinstance ( child , ast . Function ) :",159
def _filter_supported_drivers(): <TAB> global supported_drivers <TAB> with Env() as gdalenv: <TAB>  <TAB> ogrdrv_names = gdalenv.drivers().keys() <TAB>  <TAB> supported_drivers_copy = supported_drivers.copy() <TAB>  <TAB> for drv in supported_drivers.keys(): <MASK> del supported_drivers_copy[drv] <TAB> supported_drivers = supported_drivers_copy,if drv not in ogrdrv_names :,110
"def serialize(self, cassette_dict): <TAB> for interaction in cassette_dict[""interactions""]: <TAB>  <TAB> response = interaction[""response""] <TAB>  <TAB> headers = response[""headers""] <MASK> rg, size, filename = self._parse_headers(headers) <TAB>  <TAB>  <TAB> content = response[""body""][""string""] <TAB>  <TAB>  <TAB> if rg[0] == 0 and rg[1] + 1 == size: <TAB>  <TAB>  <TAB>  <TAB> with open(join(self.directory, filename), ""wb"") as f: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f.write(content) <TAB>  <TAB>  <TAB> del response[""body""][""string""] <TAB> return self.base_serializer.serialize(cassette_dict)","if ""Content-Range"" in headers and ""Content-Disposition"" in headers :",176
"def verify_software_token(self, access_token, user_code): <TAB> for user_pool in self.user_pools.values(): <TAB>  <TAB> if access_token in user_pool.access_tokens: <TAB>  <TAB>  <TAB> _, username = user_pool.access_tokens[access_token] <TAB>  <TAB>  <TAB> user = user_pool.users.get(username) <MASK> raise UserNotFoundError(username) <TAB>  <TAB>  <TAB> user.token_verified = True <TAB>  <TAB>  <TAB> return {""Status"": ""SUCCESS""} <TAB> else: <TAB>  <TAB> raise NotAuthorizedError(access_token)",if not user :,142
"def __fixdict(self, dict): <TAB> for key in dict.keys(): <MASK> tag = key[6:] <TAB>  <TAB>  <TAB> start, end = self.elements.get(tag, (None, None)) <TAB>  <TAB>  <TAB> if start is None: <TAB>  <TAB>  <TAB>  <TAB> self.elements[tag] = getattr(self, key), end <TAB>  <TAB> elif key[:4] == ""end_"": <TAB>  <TAB>  <TAB> tag = key[4:] <TAB>  <TAB>  <TAB> start, end = self.elements.get(tag, (None, None)) <TAB>  <TAB>  <TAB> if end is None: <TAB>  <TAB>  <TAB>  <TAB> self.elements[tag] = start, getattr(self, key)","if key [ : 6 ] == ""start_"" :",162
"def generate_playlist(sourcefile): <TAB> """"""Generate a playlist from video titles in sourcefile"""""" <TAB> # Hooks into this, check if the argument --description is present <TAB> if ""--description"" in sourcefile or ""-d"" in sourcefile: <TAB>  <TAB> description_generator(sourcefile) <TAB>  <TAB> return <TAB> expanded_sourcefile = path.expanduser(sourcefile) <TAB> if not check_sourcefile(expanded_sourcefile): <TAB>  <TAB> g.message = util.F(""mkp empty"") % expanded_sourcefile <TAB> else: <TAB>  <TAB> queries = read_sourcefile(expanded_sourcefile) <TAB>  <TAB> g.message = util.F(""mkp parsed"") % (len(queries), sourcefile) <MASK> create_playlist(queries) <TAB>  <TAB>  <TAB> g.message = util.F(""pl help"") <TAB>  <TAB>  <TAB> g.content = content.playlists_display()",if queries :,195
"def flush(self): <TAB> for record in self._unique_ordered_records: <TAB>  <TAB> record.message = self._format_string.format( <TAB>  <TAB>  <TAB> message=record.message, count=self._message_to_count[record.message] <TAB>  <TAB> ) <TAB>  <TAB> # record.dispatcher is the logger who created the message, <TAB>  <TAB> # it's sometimes supressed (by logbook.info for example) <MASK> dispatch = record.dispatcher.call_handlers <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> dispatch = dispatch_record <TAB>  <TAB> dispatch(record) <TAB> self.clear()",if record . dispatcher is not None :,146
"def __init__(self, name, contents): <TAB> self.name = name <TAB> self.all_entries = [] <TAB> self.attr = [] <TAB> self.child = [] <TAB> self.seq_child = [] <TAB> for entry in contents: <TAB>  <TAB> clean_entry = entry.rstrip(""*"") <TAB>  <TAB> self.all_entries.append(clean_entry) <MASK> self.seq_child.append(clean_entry) <TAB>  <TAB> elif entry.endswith(""*""): <TAB>  <TAB>  <TAB> self.child.append(clean_entry) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.attr.append(entry)","if entry . endswith ( ""**"" ) :",147
"def test_empty_condition_node(cond_node): <TAB> for node in [cond_node.true_node, cond_node.false_node]: <TAB>  <TAB> if node is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if type(node) is CodeNode and BaseNode.test_empty_node(node.node): <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> return False <TAB> return True",if BaseNode . test_empty_node ( node ) :,108
"def test_deprecated_format_string(obj, fmt_str, should_raise_warning): <TAB> if sys.version_info[0] == 3 and sys.version_info[1] >= 4: <MASK> self.assertRaises(TypeError, format, obj, fmt_str) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> format(obj, fmt_str) <TAB>  <TAB>  <TAB> except TypeError: <TAB>  <TAB>  <TAB>  <TAB> self.fail(""object.__format__ raised TypeError unexpectedly"") <TAB> else: <TAB>  <TAB> with warnings.catch_warnings(record=True) as w: <TAB>  <TAB>  <TAB> warnings.simplefilter(""always"", DeprecationWarning) <TAB>  <TAB>  <TAB> format(obj, fmt_str)",if should_raise_warning :,168
"def get_queryset(self): <TAB> if self.queryset is not None: <TAB>  <TAB> return self.queryset._clone() <TAB> elif self.model is not None: <TAB>  <TAB> qs = self.model._default_manager <MASK> access_class = access_registry[self.model] <TAB>  <TAB>  <TAB> if access_class.select_related: <TAB>  <TAB>  <TAB>  <TAB> qs = qs.select_related(*access_class.select_related) <TAB>  <TAB>  <TAB> if access_class.prefetch_related: <TAB>  <TAB>  <TAB>  <TAB> qs = qs.prefetch_related(*access_class.prefetch_related) <TAB>  <TAB> return qs <TAB> else: <TAB>  <TAB> return super(GenericAPIView, self).get_queryset()",if self . model in access_registry :,171
"def ping_task(): <TAB> try: <MASK> if peer not in self._protocol.routing_table.get_peers(): <TAB>  <TAB>  <TAB>  <TAB> self._protocol.add_peer(peer) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> await self._protocol.get_rpc_peer(peer).ping() <TAB> except (asyncio.TimeoutError, RemoteException): <TAB>  <TAB> pass",if self . _protocol . peer_manager . peer_is_good ( peer ) :,106
"def _validate_usage(schema_argument, variable_used): <TAB> if isinstance(schema_argument.gql_type, GraphQLNonNull) and not isinstance( <TAB>  <TAB> variable_used.type, NonNullTypeNode <TAB> ): <TAB>  <TAB> has_variable_a_df = not isinstance( <TAB>  <TAB>  <TAB> variable_used.default_value, (NullValueNode, type(None)) <TAB>  <TAB> ) <TAB>  <TAB> has_argument_a_df = schema_argument.default_value is not None <MASK> return False <TAB>  <TAB> return _validate_type_compatibility( <TAB>  <TAB>  <TAB> variable_used.type, schema_argument.gql_type.gql_type <TAB>  <TAB> ) <TAB> return _validate_type_compatibility(variable_used.type, schema_argument.gql_type)",if not has_variable_a_df and not has_argument_a_df :,199
"def _add_kid(key, x): <TAB> if x is None: <TAB>  <TAB> kids[key] = None <TAB> else: <TAB>  <TAB> if type(x) in (type([]), type(())): <TAB>  <TAB>  <TAB> x1 = [i for i in x if isinstance(i, TVTKBase)] <TAB>  <TAB>  <TAB> if x1: <TAB>  <TAB>  <TAB>  <TAB> kids[key] = x1 <TAB>  <TAB> elif isinstance(x, TVTKBase): <MASK> # Don't add iterable objects that contain non <TAB>  <TAB>  <TAB>  <TAB> # acceptable nodes <TAB>  <TAB>  <TAB>  <TAB> if len(list(x)) and isinstance(list(x)[0], TVTKBase): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> kids[key] = x <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> kids[key] = x","if hasattr ( x , ""__iter__"" ) :",196
"def postCreate(node, menu): <TAB> with node.scriptNode().context(): <MASK> cropFormat = node[""in""][""format""].getValue() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> cropFormat = GafferImage.FormatPlug.getDefaultFormat( <TAB>  <TAB>  <TAB>  <TAB> node.scriptNode().context() <TAB>  <TAB>  <TAB> ) <TAB> node[""area""].setValue(cropFormat.getDisplayWindow())","if node [ ""in"" ] . getInput ( ) :",103
"def normalize_stroke(stroke): <TAB> letters = set(stroke) <TAB> if letters & _NUMBERS: <MASK> stroke = stroke.replace(system.NUMBER_KEY, """") <TAB>  <TAB> # Insert dash when dealing with 'explicit' numbers <TAB>  <TAB> m = _IMPLICIT_NUMBER_RX.search(stroke) <TAB>  <TAB> if m is not None: <TAB>  <TAB>  <TAB> start = m.start(2) <TAB>  <TAB>  <TAB> return stroke[:start] + ""-"" + stroke[start:] <TAB> if ""-"" in letters: <TAB>  <TAB> if stroke.endswith(""-""): <TAB>  <TAB>  <TAB> stroke = stroke[:-1] <TAB>  <TAB> elif letters & system.IMPLICIT_HYPHENS: <TAB>  <TAB>  <TAB> stroke = stroke.replace(""-"", """") <TAB> return stroke",if system . NUMBER_KEY in letters :,180
"def vim_k(self): <TAB> """"""Cursor up N lines."""""" <TAB> if self.is_text_wrapper(self.w): <TAB>  <TAB> for z in range(self.n1 * self.n): <MASK> self.do(""previous-line-extend-selection"") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.do(""previous-line"") <TAB>  <TAB> self.done() <TAB> elif self.in_tree(self.w): <TAB>  <TAB> self.do(""goto-prev-visible"") <TAB>  <TAB> self.done() <TAB> else: <TAB>  <TAB> self.quit()","if self . state == ""visual"" :",147
"def parseTime(timeStr): <TAB> regex = re.compile(constants.PARSE_TIME_REGEX) <TAB> parts = regex.match(timeStr) <TAB> if not parts: <TAB>  <TAB> return <TAB> parts = parts.groupdict() <TAB> time_params = {} <TAB> for (name, param) in parts.items(): <TAB>  <TAB> if param: <MASK> time_params[""microseconds""] = int(param) * 1000 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> time_params[name] = int(param) <TAB> return datetime.timedelta(**time_params).total_seconds()","if name == ""miliseconds"" :",146
"def update(self, other=None, **kwargs): <TAB> if other is not None: <TAB>  <TAB> if hasattr(other, ""items""): <TAB>  <TAB>  <TAB> other = other.items() <TAB>  <TAB> for key, value in other: <MASK> raise TensorforceError.value( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> name=""NestedDict.update"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> argument=""key"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value=key, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> condition=""specified twice"", <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self[key] = value <TAB> for key, value in kwargs.items(): <TAB>  <TAB> self[key] = value",if key in kwargs :,153
"def to_string(self, ostream=None, verbose=None, precedence=0): <TAB> """"""Print this expression"""""" <TAB> if ostream is None: <TAB>  <TAB> ostream = sys.stdout <TAB> _verbose = ( <TAB>  <TAB> pyomo.core.base.expr_common.TO_STRING_VERBOSE if verbose is None else verbose <TAB> ) <TAB> ostream.write(self.cname() + ""( "") <TAB> first = True <TAB> for arg in self._args: <TAB>  <TAB> if first: <TAB>  <TAB>  <TAB> first = False <MASK> ostream.write("" , "") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ostream.write("", "") <TAB>  <TAB> arg.to_string(ostream=ostream, precedence=self._precedence(), verbose=verbose) <TAB> ostream.write("" )"")",elif _verbose :,188
"def apply_gradient_for_batch(inputs, labels, weights, loss): <TAB> with tf.GradientTape() as tape: <TAB>  <TAB> outputs = self.model(inputs, training=True) <TAB>  <TAB> if isinstance(outputs, tf.Tensor): <TAB>  <TAB>  <TAB> outputs = [outputs] <MASK> outputs = [outputs[i] for i in self._loss_outputs] <TAB>  <TAB> batch_loss = loss(outputs, labels, weights) <TAB> if variables is None: <TAB>  <TAB> vars = self.model.trainable_variables <TAB> else: <TAB>  <TAB> vars = variables <TAB> grads = tape.gradient(batch_loss, vars) <TAB> self._tf_optimizer.apply_gradients(zip(grads, vars)) <TAB> self._global_step.assign_add(1) <TAB> return batch_loss",if self . _loss_outputs is not None :,193
"def check_all(self, strict=False): <TAB> """"""run sanity check on all keys, issue warning if out of sync"""""" <TAB> same = self._is_same_value <TAB> for path, (orig, expected) in iteritems(self._state): <MASK> continue <TAB>  <TAB> msg = ""another library has patched resource: %r"" % path <TAB>  <TAB> if strict: <TAB>  <TAB>  <TAB> raise RuntimeError(msg) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> warn(msg, PasslibRuntimeWarning)","if same ( self . _get_path ( path ) , expected ) :",127
"def setup_child(self, child): <TAB> child.parent = self <TAB> if self.document: <TAB>  <TAB> child.document = self.document <TAB>  <TAB> if child.source is None: <TAB>  <TAB>  <TAB> child.source = self.document.current_source <MASK> child.line = self.document.current_line",if child . line is None :,84
"def shift_expr(self, nodelist): <TAB> # shift_expr ('<<'|'>>' shift_expr)* <TAB> node = self.com_node(nodelist[0]) <TAB> for i in range(2, len(nodelist), 2): <TAB>  <TAB> right = self.com_node(nodelist[i]) <TAB>  <TAB> if nodelist[i - 1][0] == token.LEFTSHIFT: <TAB>  <TAB>  <TAB> node = LeftShift([node, right], lineno=nodelist[1][2]) <MASK> node = RightShift([node, right], lineno=nodelist[1][2]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""unexpected token: %s"" % nodelist[i - 1][0]) <TAB> return node",elif nodelist [ i - 1 ] [ 0 ] == token . RIGHTSHIFT :,178
"def styleRow(self, row, selected): <TAB> if row != -1: <MASK> self.getRowFormatter().addStyleName(row, ""midpanel-SelectedRow"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.getRowFormatter().removeStyleName(row, ""midpanel-SelectedRow"")",if selected :,76
"def __call__(self, img): <TAB> img = self.topil(img) <TAB> ops = random.choices(self.augment_list, k=self.n) <TAB> for op, minval, maxval in ops: <MASK> continue <TAB>  <TAB> val = (float(self.m) / 30) * float(maxval - minval) + minval <TAB>  <TAB> img = op(img, val) <TAB> return img","if random . random ( ) > random . uniform ( 0.2 , 0.8 ) :",116
"def run(self, **inputs): <TAB> if self.inputs.copy_inputs: <TAB>  <TAB> self.inputs.subjects_dir = os.getcwd() <MASK> inputs[""subjects_dir""] = self.inputs.subjects_dir <TAB>  <TAB> copy2subjdir(self, self.inputs.surface, ""surf"") <TAB>  <TAB> copy2subjdir(self, self.inputs.curvfile1, ""surf"") <TAB>  <TAB> copy2subjdir(self, self.inputs.curvfile2, ""surf"") <TAB> return super(CurvatureStats, self).run(**inputs)","if ""subjects_dir"" in inputs :",146
"def get_func_name(obj): <TAB> if inspect.ismethod(obj): <TAB>  <TAB> match = RE_BOUND_METHOD.match(repr(obj)) <TAB>  <TAB> if match: <TAB>  <TAB>  <TAB> cls = match.group(""class"") <MASK> return match.group(""name"") <TAB>  <TAB>  <TAB> return ""%s.%s"" % (match.group(""class""), match.group(""name"")) <TAB> return None",if not cls :,102
"def local_path_export(at_start=True, env_cmd=None): <TAB> """"""Retrieve paths to local install, also including environment paths if env_cmd included."""""" <TAB> paths = [get_bcbio_bin()] <TAB> if env_cmd: <TAB>  <TAB> env_path = os.path.dirname(get_program_python(env_cmd)) <MASK> paths.insert(0, env_path) <TAB> if at_start: <TAB>  <TAB> return 'export PATH=%s:""$PATH"" && ' % ("":"".join(paths)) <TAB> else: <TAB>  <TAB> return 'export PATH=""$PATH"":%s && ' % ("":"".join(paths))",if env_path not in paths :,161
"def copystat(src, dst): <TAB> """"""Copy all stat info (mode bits, atime, mtime, flags) from src to dst"""""" <TAB> st = os.stat(src) <TAB> mode = stat.S_IMODE(st.st_mode) <TAB> if hasattr(os, ""utime""): <TAB>  <TAB> os.utime(dst, (st.st_atime, st.st_mtime)) <TAB> if hasattr(os, ""chmod""): <TAB>  <TAB> os.chmod(dst, mode) <TAB> if hasattr(os, ""chflags"") and hasattr(st, ""st_flags""): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> os.chflags(dst, st.st_flags) <TAB>  <TAB> except OSError as why: <MASK> raise","if not hasattr ( errno , ""EOPNOTSUPP"" ) or why . errno != errno . EOPNOTSUPP :",193
"def _asdict(self, *, to_string: bool = False) -> dict: <TAB> res = [] <TAB> for key in self._keys: <TAB>  <TAB> value = getattr(self, key) <TAB>  <TAB> if isinstance(value, Struct): <TAB>  <TAB>  <TAB> value = value._asdict(to_string=to_string) <MASK> value = str(value) <TAB>  <TAB> res.append((key, value)) <TAB> return dict(res)",elif to_string :,108
"def _SI(size, K=1024, i=""i""): <TAB> """"""Return size as SI string."""""" <TAB> if 1 < K <= size: <TAB>  <TAB> f = float(size) <TAB>  <TAB> for si in iter(""KMGPTE""): <TAB>  <TAB>  <TAB> f /= K <MASK> return "" or %.1f %s%sB"" % (f, si, i) <TAB> return """"",if f < K :,99
"def _flatten(*args): <TAB> arglist = [] <TAB> for arg in args: <MASK> if arg.vhdl_code is not None: <TAB>  <TAB>  <TAB>  <TAB> arglist.append(arg.vhdl_code) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> arg = arg.subs <TAB>  <TAB> if id(arg) in _userCodeMap[""vhdl""]: <TAB>  <TAB>  <TAB> arglist.append(_userCodeMap[""vhdl""][id(arg)]) <TAB>  <TAB> elif isinstance(arg, (list, tuple, set)): <TAB>  <TAB>  <TAB> for item in arg: <TAB>  <TAB>  <TAB>  <TAB> arglist.extend(_flatten(item)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> arglist.append(arg) <TAB> return arglist","if isinstance ( arg , _Block ) :",179
"def new_token(self): <TAB> data = '{{""username"": ""{}"", ""password"": ""{}""}}'.format(self.username, self.password) <TAB> try: <TAB>  <TAB> resp = requests.post( <TAB>  <TAB>  <TAB> ""https://api.zoomeye.org/user/login"", <TAB>  <TAB>  <TAB> data=data, <TAB>  <TAB> ) <MASK> content = resp.json() <TAB>  <TAB>  <TAB> self.token = content[""access_token""] <TAB>  <TAB>  <TAB> self.headers = {""Authorization"": ""JWT %s"" % self.token} <TAB>  <TAB>  <TAB> return True <TAB> except Exception as ex: <TAB>  <TAB> logger.error(str(ex)) <TAB> return False","if resp . status_code != 401 and ""access_token"" in resp . json ( ) :",173
"def finalize_computation( <TAB> self, transaction: SignedTransactionAPI, computation: ComputationAPI) -> ComputationAPI: <TAB> computation = super().finalize_computation(transaction, computation) <TAB> # <TAB> # EIP161 state clearing <TAB> # <TAB> touched_accounts = collect_touched_accounts(computation) <TAB> for account in touched_accounts: <TAB>  <TAB> should_delete = self.vm_state.account_exists( <TAB>  <TAB>  <TAB> account <TAB>  <TAB> ) and self.vm_state.account_is_empty(account) <MASK> self.vm_state.logger.debug2( <TAB>  <TAB>  <TAB>  <TAB> ""CLEARING EMPTY ACCOUNT: %s"", <TAB>  <TAB>  <TAB>  <TAB> encode_hex(account), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.vm_state.delete_account(account) <TAB> return computation",if should_delete :,195
"def send_messages(self, text, user_ids): <TAB> broken_items = [] <TAB> if not user_ids: <TAB>  <TAB> self.logger.info(""User must be at least one."") <TAB>  <TAB> return broken_items <TAB> self.logger.info(""Going to send %d messages."" % (len(user_ids))) <TAB> for user in tqdm(user_ids): <MASK> self.error_delay() <TAB>  <TAB>  <TAB> broken_items = user_ids[user_ids.index(user) :] <TAB>  <TAB>  <TAB> break <TAB> return broken_items","if not self . send_message ( text , user ) :",144
"def editable_cpp_info(self): <TAB> if self._layout_file: <MASK> return EditableLayout(self._layout_file) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ConanException(""Layout file not found: %s"" % self._layout_file)",if os . path . isfile ( self . _layout_file ) :,79
"def to_python(self, value): <TAB> if isinstance(value, list) and len(value) == 2 and isinstance(value[0], str): <TAB>  <TAB> filename, payload = value <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> payload = base64.b64decode(payload) <TAB>  <TAB> except TypeError: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <MASK> self.storage.delete(filename) <TAB>  <TAB>  <TAB> self.storage.save(filename, ContentFile(payload)) <TAB>  <TAB>  <TAB> return filename <TAB> return value",if self . storage . exists ( filename ) :,131
"def update_defaults(self, *values, **kwargs): <TAB> for value in values: <TAB>  <TAB> if type(value) == dict: <TAB>  <TAB>  <TAB> self.DEFAULT_CONFIGURATION.update(value) <MASK> self.__defaults_from_module(value) <TAB>  <TAB> elif isinstance(value, str): <TAB>  <TAB>  <TAB> if os.path.exists(value): <TAB>  <TAB>  <TAB>  <TAB> self.__defaults_from_file(value) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> logger.warning(""Configuration file {} does not exist."".format(value)) <TAB>  <TAB> elif isinstance(value, type(None)): <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""Cannot interpret {}"".format(value)) <TAB> self.DEFAULT_CONFIGURATION.update(kwargs)","elif isinstance ( value , types . ModuleType ) :",184
"def __getitem__(self, item: str) -> Any: <TAB> try: <TAB>  <TAB> return self.data[item] <TAB> except KeyError: <TAB>  <TAB> for g in self.extended_groups(): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> r = g.data[item] <TAB>  <TAB>  <TAB>  <TAB> return r <TAB>  <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> r = self.defaults.data.get(item) <MASK> return r <TAB>  <TAB> raise",if r is not None :,118
"def _parse_arguments(self, handler_method): <TAB> spec = DynamicArgumentParser().parse(self._argspec, self.longname) <TAB> if not self._supports_kwargs: <TAB>  <TAB> if spec.kwargs: <TAB>  <TAB>  <TAB> raise DataError( <TAB>  <TAB>  <TAB>  <TAB> ""Too few '%s' method parameters for **kwargs "" <TAB>  <TAB>  <TAB>  <TAB> ""support."" % self._run_keyword_method_name <TAB>  <TAB>  <TAB> ) <MASK> raise DataError( <TAB>  <TAB>  <TAB>  <TAB> ""Too few '%s' method parameters for "" <TAB>  <TAB>  <TAB>  <TAB> ""keyword-only arguments support."" % self._run_keyword_method_name <TAB>  <TAB>  <TAB> ) <TAB> spec.types = GetKeywordTypes(self.library.get_instance())(self._handler_name) <TAB> return spec",if spec . kwonlyargs :,183
"def test_orphans_match(self): <TAB> """"""api handles last three chars match query"""""" <TAB> response = self.client.get(""%s?q=%s"" % (self.api_link, self.user.username[-3:])) <TAB> self.assertEqual(response.status_code, 200) <TAB> response_json = response.json() <TAB> self.assertIn(""users"", [p[""id""] for p in response_json]) <TAB> for provider in response_json: <MASK> results = provider[""results""][""results""] <TAB>  <TAB>  <TAB> self.assertEqual(len(results), 1) <TAB>  <TAB>  <TAB> self.assertEqual(results[0][""id""], self.user.id)","if provider [ ""id"" ] == ""users"" :",164
"def test_costs_1D_noisy_names(signal_bkps_1D_noisy, cost_name): <TAB> signal, bkps = signal_bkps_1D_noisy <TAB> cost = cost_factory(cost_name) <TAB> cost.fit(signal) <TAB> cost.fit(signal.flatten()) <TAB> cost.error(0, 100) <TAB> cost.error(100, signal.shape[0]) <TAB> cost.error(10, 50) <TAB> cost.sum_of_costs(bkps) <TAB> with pytest.raises(NotEnoughPoints): <MASK> cost.min_size = 4 <TAB>  <TAB>  <TAB> cost.error(1, 2) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> cost.error(1, 2)","if cost_name == ""cosine"" :",184
"def _delete_access_key(self, params): <TAB> sys.stdout.write(""Deleting the IAM user access keys... "") <TAB> list_access_keys = self.iam.get_paginator(""list_access_keys"") <TAB> try: <TAB>  <TAB> for response in list_access_keys.paginate(UserName=params.user_name): <TAB>  <TAB>  <TAB> for access_key in response[""AccessKeyMetadata""]: <TAB>  <TAB>  <TAB>  <TAB> self.iam.delete_access_key( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> UserName=params.user_name, AccessKeyId=access_key[""AccessKeyId""] <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> except ClientError as e: <MASK> raise e <TAB> sys.stdout.write(""DONE\n"")","if e . response . get ( ""Error"" , { } ) . get ( ""Code"" ) != ""NoSuchEntity"" :",181
"def run_pending(self, now=None): <TAB> """"""Runs the command if scheduled"""""" <TAB> now = now or datetime.now() <TAB> if self.is_enabled(): <TAB>  <TAB> if self.last_run is None: <TAB>  <TAB>  <TAB> self.last_run = now <TAB>  <TAB> next_time = self.schedule(self.last_run).get_next() <MASK> self.last_run = now <TAB>  <TAB>  <TAB> return self.run() <TAB> return -1",if next_time < now :,119
"def parse_row(cls, doc_row): <TAB> row = {} <TAB> for field_name, field in FIELD_MAP.items(): <MASK> field_value = doc_row[field[1]] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> field_value = """" <TAB>  <TAB> if len(field) >= 3 and callable(field[2]): <TAB>  <TAB>  <TAB> field_value = field[2](field_value) <TAB>  <TAB> row[field_name] = field_value <TAB> return row",if len ( doc_row ) > field [ 1 ] :,127
"def list(self, items, columns=4, width=80): <TAB> items = list(sorted(items)) <TAB> colw = width // columns <TAB> rows = (len(items) + columns - 1) // columns <TAB> for row in range(rows): <TAB>  <TAB> for col in range(columns): <TAB>  <TAB>  <TAB> i = col * rows + row <TAB>  <TAB>  <TAB> if i < len(items): <TAB>  <TAB>  <TAB>  <TAB> self.output.write(items[i]) <MASK> self.output.write("" "" + "" "" * (colw - 1 - len(items[i]))) <TAB>  <TAB> self.output.write(""\n"")",if col < columns - 1 :,158
"def _on_message(self, storage, data): <TAB> if ""_meta"" in data and ""session_id"" in data[""_meta""]: <TAB>  <TAB> self.session_id = data[""_meta""][""session_id""] <TAB> if is_blacklisted(data.get(""url"", """")): <TAB>  <TAB> blacklist_error(data, self) <TAB>  <TAB> return <TAB> command = data[""_command""] <TAB> command = self._handlers.get(command, command) <TAB> with data_store_context(): <TAB>  <TAB> commands = Commands(data, self, storage) <TAB>  <TAB> result = getattr(commands, command, lambda: None)() <TAB> if result: <TAB>  <TAB> result.setdefault(""_command"", data.get(""_callback"", command)) <MASK> result[""id""] = data[""_meta""][""id""] <TAB> return result","if ""_meta"" in data and ""id"" in data [ ""_meta"" ] :",198
"def get_model_params(problem_type: str, hyperparameters): <TAB> penalty = hyperparameters.get(""penalty"", L2) <TAB> handle_text = hyperparameters.get(""handle_text"", IGNORE) <TAB> if problem_type == REGRESSION: <MASK> model_class = Ridge <TAB>  <TAB> elif penalty == L1: <TAB>  <TAB>  <TAB> model_class = Lasso <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logger.warning( <TAB>  <TAB>  <TAB>  <TAB> ""Unknown value for penalty {} - supported types are [l1, l2] - falling back to l2"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> penalty <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> penalty = L2 <TAB>  <TAB>  <TAB> model_class = Ridge <TAB> else: <TAB>  <TAB> model_class = LogisticRegression <TAB> return model_class, penalty, handle_text",if penalty == L2 :,200
"def get_queryset(self): <TAB> if self.queryset is not None: <TAB>  <TAB> return self.queryset._clone() <TAB> elif self.model is not None: <TAB>  <TAB> qs = self.model._default_manager <TAB>  <TAB> if self.model in access_registry: <TAB>  <TAB>  <TAB> access_class = access_registry[self.model] <TAB>  <TAB>  <TAB> if access_class.select_related: <TAB>  <TAB>  <TAB>  <TAB> qs = qs.select_related(*access_class.select_related) <MASK> qs = qs.prefetch_related(*access_class.prefetch_related) <TAB>  <TAB> return qs <TAB> else: <TAB>  <TAB> return super(GenericAPIView, self).get_queryset()",if access_class . prefetch_related :,171
"def map_package(shutit_pexpect_session, package, install_type): <TAB> """"""If package mapping exists, then return it, else return package."""""" <TAB> if package in PACKAGE_MAP.keys(): <TAB>  <TAB> for itype in PACKAGE_MAP[package].keys(): <TAB>  <TAB>  <TAB> if itype == install_type: <TAB>  <TAB>  <TAB>  <TAB> ret = PACKAGE_MAP[package][install_type] <TAB>  <TAB>  <TAB>  <TAB> if isinstance(ret, str): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return ret <MASK> ret(shutit_pexpect_session) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return """" <TAB> # Otherwise, simply return package <TAB> return package",if callable ( ret ) :,163
"def find_missing_cache_files( <TAB> self, modules: Dict[str, str], manager: build.BuildManager) -> Set[str]: <TAB> ignore_errors = True <TAB> missing = {} <TAB> for id, path in modules.items(): <TAB>  <TAB> meta = build.find_cache_meta(id, path, manager) <MASK> missing[id] = path <TAB> return set(missing.values())","if not build . validate_meta ( meta , id , path , ignore_errors , manager ) :",117
"def parse_percent_formats(data, tree): <TAB> percent_formats = data.setdefault(""percent_formats"", {}) <TAB> for elem in tree.findall("".//percentFormats/percentFormatLength""): <TAB>  <TAB> type = elem.attrib.get(""type"") <MASK> continue <TAB>  <TAB> pattern = text_type(elem.findtext(""percentFormat/pattern"")) <TAB>  <TAB> percent_formats[type] = numbers.parse_pattern(pattern)","if _should_skip_elem ( elem , type , percent_formats ) :",116
"def nan2none(l): <TAB> for idx, val in enumerate(l): <MASK> l[idx] = nan2none(l[idx]) <TAB>  <TAB> elif isnum(val) and math.isnan(val): <TAB>  <TAB>  <TAB> l[idx] = None <TAB> return l","if isinstance ( val , Sequence ) :",76
"def process(self, message: Message, **kwargs: Any) -> None: <TAB> for attribute in DENSE_FEATURIZABLE_ATTRIBUTES: <MASK> message.set( <TAB>  <TAB>  <TAB>  <TAB> SPACY_DOCS[attribute], self.doc_for_text(message.get(attribute)) <TAB>  <TAB>  <TAB> )",if message . get ( attribute ) :,81
"def accessSlice(self, node): <TAB> self.visit(node.value) <TAB> node.obj = self.getObj(node.value) <TAB> self.access = _access.INPUT <TAB> lower, upper = node.slice.lower, node.slice.upper <TAB> if lower: <TAB>  <TAB> self.visit(lower) <MASK> self.visit(upper) <TAB> if isinstance(node.obj, intbv): <TAB>  <TAB> if self.kind == _kind.DECLARATION: <TAB>  <TAB>  <TAB> self.require(lower, ""Expected leftmost index"") <TAB>  <TAB>  <TAB> leftind = self.getVal(lower) <TAB>  <TAB>  <TAB> if upper: <TAB>  <TAB>  <TAB>  <TAB> rightind = self.getVal(upper) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> rightind = 0 <TAB>  <TAB>  <TAB> node.obj = node.obj[leftind:rightind]",if upper :,198
"def forg(x, prec=3): <TAB> if prec == 3: <TAB>  <TAB> # for 3 decimals <MASK> return ""%9.3g"" % x <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""%9.3f"" % x <TAB> elif prec == 4: <TAB>  <TAB> if (abs(x) >= 1e4) or (abs(x) < 1e-4): <TAB>  <TAB>  <TAB> return ""%10.4g"" % x <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""%10.4f"" % x <TAB> else: <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> ""`prec` argument must be either 3 or 4, not {prec}"".format(prec=prec) <TAB>  <TAB> )",if ( abs ( x ) >= 1e4 ) or ( abs ( x ) < 1e-4 ) :,185
"def pseudo_raw_input(self, prompt): <TAB> """"""copied from cmd's cmdloop; like raw_input, but accounts for changed stdin, stdout"""""" <TAB> if self.use_rawinput: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> line = raw_input(prompt) <TAB>  <TAB> except EOFError: <TAB>  <TAB>  <TAB> line = ""EOF"" <TAB> else: <TAB>  <TAB> self.stdout.write(prompt) <TAB>  <TAB> self.stdout.flush() <TAB>  <TAB> line = self.stdin.readline() <MASK> line = ""EOF"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if line[-1] == ""\n"":  # this was always true in Cmd <TAB>  <TAB>  <TAB>  <TAB> line = line[:-1] <TAB> return line",if not len ( line ) :,172
"def _find_first_unescaped(dn, char, pos): <TAB> while True: <TAB>  <TAB> pos = dn.find(char, pos) <TAB>  <TAB> if pos == -1: <TAB>  <TAB>  <TAB> break  # no char found <TAB>  <TAB> if pos > 0 and dn[pos - 1] != ""\\"":  # unescaped char <TAB>  <TAB>  <TAB> break <MASK> # may be unescaped <TAB>  <TAB>  <TAB> escaped = True <TAB>  <TAB>  <TAB> for c in dn[pos - 2 : 0 : -1]: <TAB>  <TAB>  <TAB>  <TAB> if c == ""\\"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> escaped = not escaped <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> if not escaped: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> pos += 1 <TAB> return pos","elif pos > 1 and dn [ pos - 1 ] == ""\\"" :",181
"def update_user(username): <TAB> permission = UserAdminPermission(username) <TAB> if permission.can(): <TAB>  <TAB> update_request = request.get_json() <MASK> logger.debug(""Updating user password"") <TAB>  <TAB>  <TAB> model.user.change_password( <TAB>  <TAB>  <TAB>  <TAB> get_authenticated_user(), update_request[""password""] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return jsonify( <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB> ""username"": get_authenticated_user().username, <TAB>  <TAB>  <TAB>  <TAB> ""email"": get_authenticated_user().email, <TAB>  <TAB>  <TAB> } <TAB>  <TAB> ) <TAB> abort(403)","if ""password"" in update_request :",154
"def pages(self): <TAB> if hasattr(self, ""_pages""): <TAB>  <TAB> return self._pages <TAB> doctop = 0 <TAB> pp = self.pages_to_parse <TAB> self._pages = [] <TAB> for i, page in enumerate(PDFPage.create_pages(self.doc)): <TAB>  <TAB> page_number = i + 1 <MASK> continue <TAB>  <TAB> p = Page(self, page, page_number=page_number, initial_doctop=doctop) <TAB>  <TAB> self._pages.append(p) <TAB>  <TAB> doctop += p.height <TAB> return self._pages",if pp is not None and page_number not in pp :,155
"def image_size(img_data, pure_python=False): <TAB> try: <MASK> return imgsize.get_size(PeekableStringIO(img_data)) <TAB>  <TAB> if Image is not None and not pure_python: <TAB>  <TAB>  <TAB> return Image.open(cStringIO.StringIO(img_data)).size <TAB> except (ValueError, imgsize.UnknownSize): <TAB>  <TAB> pass <TAB> return None",if imgsize is not None :,105
"def email_csv_query(request, query_id): <TAB> if request.is_ajax(): <TAB>  <TAB> email = request.POST.get(""email"", None) <MASK> execute_query.delay(query_id, email) <TAB>  <TAB>  <TAB> return HttpResponse(content={""message"": ""message was sent successfully""}) <TAB> return HttpResponse(status=403)",if email :,86
"def _groups_args_split(self, kwargs): <TAB> groups_args_split = [] <TAB> groups = kwargs[""groups""] <TAB> for key, group in groups.iteritems(): <TAB>  <TAB> mykwargs = kwargs.copy() <TAB>  <TAB> del mykwargs[""groups""] <TAB>  <TAB> if ""group_name"" in group: <TAB>  <TAB>  <TAB> mykwargs[""source_security_group_name""] = group[""group_name""] <MASK> mykwargs[""source_security_group_owner_id""] = group[""user_id""] <TAB>  <TAB> if ""group_id"" in group: <TAB>  <TAB>  <TAB> mykwargs[""source_security_group_id""] = group[""group_id""] <TAB>  <TAB> groups_args_split.append(mykwargs) <TAB> return groups_args_split","if ""user_id"" in group :",186
"def get_subnet_groups(self, region: str, vpc: str): <TAB> try: <TAB>  <TAB> await self._cache_subnet_groups(region) <TAB>  <TAB> return [ <TAB>  <TAB>  <TAB> subnet_group <TAB>  <TAB>  <TAB> for subnet_group in self._subnet_groups_cache[region] <MASK> ] <TAB> except Exception as e: <TAB>  <TAB> print_exception(f""Failed to get RDS subnet groups: {e}"") <TAB>  <TAB> return []","if subnet_group [ ""VpcId"" ] == vpc",121
def on_state_update(self) -> None: <TAB> if self.road: <TAB>  <TAB> self.lane_index = self.road.network.get_closest_lane_index(self.position) <TAB>  <TAB> self.lane = self.road.network.get_lane(self.lane_index) <MASK> self.history.appendleft(self.create_from(self)),if self . road . record_history :,105
"def delete_old_post_save( <TAB> sender, instance, raw, created, update_fields, using, **kwargs): <TAB> """"""Post_save on all models with file fields, deletes old files"""""" <TAB> if raw or created: <TAB>  <TAB> return <TAB> for field_name, new_file in cache.fields_for_model_instance(instance): <TAB>  <TAB> if update_fields is None or field_name in update_fields: <TAB>  <TAB>  <TAB> old_file = cache.get_field_attr(instance, field_name) <MASK> delete_file(instance, field_name, old_file, using) <TAB> # reset cache <TAB> cache.make_cleanup_cache(instance)",if old_file != new_file :,171
"def i2h(self, pkt, x): <TAB> if x is not None: <TAB>  <TAB> if x < 0: <TAB>  <TAB>  <TAB> warning(""Fixed3_6: Internal value too negative: %d"" % x) <TAB>  <TAB>  <TAB> x = 0 <MASK> warning(""Fixed3_6: Internal value too positive: %d"" % x) <TAB>  <TAB>  <TAB> x = 999999999 <TAB>  <TAB> x = x * 1e-6 <TAB> return x",elif x > 999999999 :,111
"def quick_main(self): <TAB> if self.actions.pressed(""cancel""): <TAB>  <TAB> self.previs_timer.stop() <TAB>  <TAB> return ""main"" <TAB> if self.actions.mousemove_stop: <TAB>  <TAB> self.hovering_edge, _ = self.rfcontext.accel_nearest2D_edge( <TAB>  <TAB>  <TAB> max_dist=options[""action dist""] <TAB>  <TAB> ) <MASK> self.hovering_edge = None <TAB> if self.hovering_edge and self.rfcontext.actions.pressed(""quick insert""): <TAB>  <TAB> return self.insert_edge_loop_strip()",if self . hovering_edge and not self . hovering_edge . is_valid :,163
def check_status(self) -> None: <TAB> join_requested = False <TAB> while not join_requested: <TAB>  <TAB> status_response = self._interface.communicate_status(check_stop_req=True) <TAB>  <TAB> if status_response and status_response.run_should_stop: <TAB>  <TAB>  <TAB> # TODO(frz): This check is required <TAB>  <TAB>  <TAB> # until WB-3606 is resolved on server side. <MASK> thread.interrupt_main() <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> join_requested = self._join_event.wait(self._polling_interval),if not wandb . agents . pyagent . is_running ( ) :,157
"def listed(output, pool): <TAB> for line in output.splitlines(): <TAB>  <TAB> name, mountpoint, refquota = line.split(b""\t"") <TAB>  <TAB> name = name[len(pool) + 1 :] <MASK> refquota = int(refquota.decode(""ascii"")) <TAB>  <TAB>  <TAB> if refquota == 0: <TAB>  <TAB>  <TAB>  <TAB> refquota = None <TAB>  <TAB>  <TAB> yield _DatasetInfo(dataset=name, mountpoint=mountpoint, refquota=refquota)",if name :,116
"def defined_properties(cls, aliases=True, properties=True, rels=True): <TAB> from .relationship_manager import RelationshipDefinition <TAB> props = {} <TAB> for baseclass in reversed(cls.__mro__): <TAB>  <TAB> props.update( <TAB>  <TAB>  <TAB> dict( <TAB>  <TAB>  <TAB>  <TAB> (name, property) <TAB>  <TAB>  <TAB>  <TAB> for name, property in vars(baseclass).items() <MASK> or ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> properties <TAB>  <TAB>  <TAB>  <TAB>  <TAB> and isinstance(property, Property) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> and not isinstance(property, AliasProperty) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> or (rels and isinstance(property, RelationshipDefinition)) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB> return props","if ( aliases and isinstance ( property , AliasProperty ) )",182
"def _mock_manager(self, *args, **kwargs): <TAB> if kwargs and ""normalize"" not in kwargs: <TAB>  <TAB> device_params = kwargs[""device_params""] <TAB>  <TAB> device_handler = make_device_handler(device_params) <TAB>  <TAB> session = SSHSession(device_handler) <TAB>  <TAB> return Manager(session, device_handler) <TAB> if args: <TAB>  <TAB> if args[0].tag == ""request-pfe-execute"": <TAB>  <TAB>  <TAB> file_name = (args[0].findtext(""command"")).replace("" "", ""_"") <TAB>  <TAB>  <TAB> return self._read_file(file_name + "".xml"") <MASK> file_name = (args[0].text).replace("" "", ""_"") <TAB>  <TAB>  <TAB> return self._read_file(file_name + "".xml"")","elif args [ 0 ] . tag == ""command"" :",193
"def triger_check_network(self, fail=False, force=False): <TAB> time_now = time.time() <TAB> if not force: <TAB>  <TAB> if self._checking_num > 0: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> if fail or self.network_stat != ""OK"": <TAB>  <TAB>  <TAB> # Fail or unknown <TAB>  <TAB>  <TAB> if time_now - self.last_check_time < 3: <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> else: <MASK> return <TAB> self.last_check_time = time_now <TAB> threading.Thread(target=self._simple_check_worker).start()",if time_now - self . last_check_time < 10 :,161
"def delete(self): <TAB> if not self.force and not self.exists(): <TAB>  <TAB> return [] <TAB> cmd = [""delete""] <TAB> if self.filename: <TAB>  <TAB> cmd.append(""--filename="" + self.filename) <TAB> else: <TAB>  <TAB> if not self.resource: <TAB>  <TAB>  <TAB> self.module.fail_json(msg=""resource required to delete without filename"") <TAB>  <TAB> cmd.append(self.resource) <TAB>  <TAB> if self.name: <TAB>  <TAB>  <TAB> cmd.append(self.name) <TAB>  <TAB> if self.label: <TAB>  <TAB>  <TAB> cmd.append(""--selector="" + self.label) <MASK> cmd.append(""--all"") <TAB>  <TAB> if self.force: <TAB>  <TAB>  <TAB> cmd.append(""--ignore-not-found"") <TAB> return self._execute(cmd)",if self . all :,189
"def load(self): <TAB> """"""load a custom filter"""""" <TAB> try: <MASK> parser = make_parser() <TAB>  <TAB>  <TAB> parser.setContentHandler(FilterParser(self)) <TAB>  <TAB>  <TAB> with open(self.file, ""r"", encoding=""utf8"") as the_file: <TAB>  <TAB>  <TAB>  <TAB> parser.parse(the_file) <TAB> except (IOError, OSError): <TAB>  <TAB> print(""IO/OSError in _filterlist.py"") <TAB> except SAXParseException: <TAB>  <TAB> print(""Parser error"")",if os . path . isfile ( self . file ) :,132
"def exitFullscreen(self, container=None): <TAB> """"""turns off fullscreen mode for the specified window"""""" <TAB> if container is None or isinstance(container, UNIVERSAL_STRING): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> container = self.widgetManager.get(WIDGET_NAMES.SubWindow, container) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> container = self._getTopLevel() <TAB> if container.isFullscreen: <TAB>  <TAB> container.isFullscreen = False <TAB>  <TAB> container.attributes(""-fullscreen"", False) <MASK> container.unbind(""<Escape>"", container.escapeBindId) <TAB>  <TAB> with PauseLogger(): <TAB>  <TAB>  <TAB> self._doTitleBar() <TAB>  <TAB> return True <TAB> else: <TAB>  <TAB> return False",if container . escapeBindId is not None :,179
"def __get__(self, instance: Any, owner: Type) -> Any: <TAB> # class attribute accessed <TAB> if instance is None: <TAB>  <TAB> return self <TAB> field = self.field <TAB> instance_dict = instance.__dict__ <TAB> to_python = self._to_python <TAB> value = instance_dict[field] <TAB> if self.lazy_coercion and to_python is not None: <TAB>  <TAB> evaluated_fields: Set[str] <TAB>  <TAB> evaluated_fields = instance.__evaluated_fields__ <MASK> if value is not None or self.required: <TAB>  <TAB>  <TAB>  <TAB> value = instance_dict[field] = to_python(value) <TAB>  <TAB>  <TAB> evaluated_fields.add(field) <TAB> return value",if field not in evaluated_fields :,178
"def ip_list(_): <TAB> ips = [] <TAB> for ip in _.split("" ""): <TAB>  <TAB> if not ip: <TAB>  <TAB>  <TAB> continue <MASK> ips.append(IP.create(ip)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError(""ip %s is invalid"" % ip) <TAB> return ips",elif isip ( ip ) :,82
"def _parse_fields(line, legacy=False): <TAB> """"""Removes '\n' from fields line and returns fields as a list (columns)."""""" <TAB> line = line.rstrip(""\n"") <TAB> if legacy: <TAB>  <TAB> fields = line.split("","") <TAB> else: <TAB>  <TAB> line = line.split(""# Fields: "")[1] <TAB>  <TAB> fields = line.split("", "") <TAB> columns = [] <TAB> for field in fields: <MASK> raise BLAST7FormatError( <TAB>  <TAB>  <TAB>  <TAB> ""Unrecognized field (%r)."" <TAB>  <TAB>  <TAB>  <TAB> "" Supported fields: %r"" % (field, set(column_converter.keys())) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> columns.append(column_converter[field]) <TAB> return columns",if field not in column_converter :,175
"def _resolve_plugin_path(path): <TAB> if not os.path.isabs(path): <TAB>  <TAB> p = os.path.normpath(os.path.join(sublime.packages_path(), ""User"", path)) <MASK> p = os.path.normpath( <TAB>  <TAB>  <TAB>  <TAB> os.path.join(sublime.packages_path(), ""LaTeXTools"", path) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return p <TAB> return path",if not os . path . exists ( p ) :,120
"def _deep_copy_dict(source, dest): <TAB> for key, value in source.items(): <MASK> dest[key] = {} <TAB>  <TAB>  <TAB> TqApi._deep_copy_dict(value, dest[key]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> dest[key] = value","if isinstance ( value , Entity ) :",79
"def encode(self): <TAB> if not isinstance(self.expr, m2_expr.ExprInt): <TAB>  <TAB> return False <TAB> if not test_set_sf(self.parent, self.expr.size): <TAB>  <TAB> return False <TAB> value = int(self.expr) <TAB> if value < 1 << self.l: <TAB>  <TAB> self.parent.shift.value = 0 <TAB> else: <MASK> return False <TAB>  <TAB> value >>= 12 <TAB>  <TAB> if value >= 1 << self.l: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> self.parent.shift.value = 1 <TAB> self.value = value <TAB> return True",if value & 0xFFF :,154
"def test_read_audio_properties(self): <TAB> mediafile = self._mediafile_fixture(""full"") <TAB> for key, value in self.audio_properties.items(): <MASK> self.assertAlmostEqual(getattr(mediafile, key), value, delta=0.1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertEqual(getattr(mediafile, key), value)","if isinstance ( value , float ) :",92
"def get_all_fix_names(fixer_pkg, remove_prefix=True): <TAB> """"""Return a sorted list of all available fix names in the given package."""""" <TAB> pkg = __import__(fixer_pkg, [], [], [""*""]) <TAB> fixer_dir = os.path.dirname(pkg.__file__) <TAB> fix_names = [] <TAB> for name in sorted(os.listdir(fixer_dir)): <MASK> if remove_prefix: <TAB>  <TAB>  <TAB>  <TAB> name = name[4:] <TAB>  <TAB>  <TAB> fix_names.append(name[:-3]) <TAB> return fix_names","if name . startswith ( ""fix_"" ) and name . endswith ( "".py"" ) :",147
"def _get_arg(self, f_name, args, kws, arg_no, arg_name, default=None, err_msg=None): <TAB> arg = None <TAB> if len(args) > arg_no: <TAB>  <TAB> arg = args[arg_no] <TAB> elif arg_name in kws: <TAB>  <TAB> arg = kws[arg_name] <TAB> if arg is None: <TAB>  <TAB> if default is not None: <TAB>  <TAB>  <TAB> return default <MASK> err_msg = ""{} requires '{}' argument"".format(f_name, arg_name) <TAB>  <TAB> raise ValueError(err_msg) <TAB> return arg",if err_msg is None :,152
"def get_satellite_list(self, daemon_type=""""): <TAB> res = {} <TAB> for t in [""arbiter"", ""scheduler"", ""poller"", ""reactionner"", ""receiver"", ""broker""]: <MASK> continue <TAB>  <TAB> satellite_list = [] <TAB>  <TAB> res[t] = satellite_list <TAB>  <TAB> daemon_name_attr = t + ""_name"" <TAB>  <TAB> daemons = self.app.get_daemons(t) <TAB>  <TAB> for dae in daemons: <TAB>  <TAB>  <TAB> if hasattr(dae, daemon_name_attr): <TAB>  <TAB>  <TAB>  <TAB> satellite_list.append(getattr(dae, daemon_name_attr)) <TAB> return res",if daemon_type and daemon_type != t :,175
"def do_upload(file: Path, metadata: Metadata, repo_name=None): <TAB> """"""Upload a file to an index server."""""" <TAB> repo = get_repository(repo_name) <TAB> upload_file(file, metadata, repo) <TAB> if repo[""is_warehouse""]: <TAB>  <TAB> domain = urlparse(repo[""url""]).netloc <MASK> domain = domain[7:] <TAB>  <TAB> log.info(""Package is at https://%s/project/%s/"", domain, metadata.name) <TAB> else: <TAB>  <TAB> log.info(""Package is at %s/%s"", repo[""url""], metadata.name)","if domain . startswith ( ""upload."" ) :",147
"def __next__(self): <TAB> for res in self._execution_context: <TAB>  <TAB> for item in res: <TAB>  <TAB>  <TAB> for operator in self._local_aggregators: <TAB>  <TAB>  <TAB>  <TAB> if isinstance(item, dict) and item: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> operator.aggregate(item[""item""]) <MASK> operator.aggregate(item) <TAB> if self._results is None: <TAB>  <TAB> self._results = [] <TAB>  <TAB> for operator in self._local_aggregators: <TAB>  <TAB>  <TAB> self._results.append(operator.get_result()) <TAB> if self._result_index < len(self._results): <TAB>  <TAB> res = self._results[self._result_index] <TAB>  <TAB> self._result_index += 1 <TAB>  <TAB> return res <TAB> raise StopIteration","elif isinstance ( item , numbers . Number ) :",188
"def __iter__(self): <TAB> yield pd.Timestamp.utcnow(), SESSION_START <TAB> while True: <TAB>  <TAB> current_time = pd.Timestamp.utcnow() <TAB>  <TAB> current_minute = current_time.floor(""1 min"") <MASK> break <TAB>  <TAB> if self._last_emit is None or current_minute > self._last_emit: <TAB>  <TAB>  <TAB> log.debug(""emitting minutely bar: {}"".format(current_minute)) <TAB>  <TAB>  <TAB> self._last_emit = current_minute <TAB>  <TAB>  <TAB> yield current_minute, BAR <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sleep(1) <TAB> yield current_minute, SESSION_END",if self . end is not None and current_minute >= self . end :,168
"def _escape_attrib(text): <TAB> # escape attribute value <TAB> try: <MASK> text = text.replace(""&"", ""&amp;"") <TAB>  <TAB> if ""<"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""<"", ""&lt;"") <TAB>  <TAB> if "">"" in text: <TAB>  <TAB>  <TAB> text = text.replace("">"", ""&gt;"") <TAB>  <TAB> if '""' in text: <TAB>  <TAB>  <TAB> text = text.replace('""', ""&quot;"") <TAB>  <TAB> if ""\n"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""\n"", ""&#10;"") <TAB>  <TAB> return text <TAB> except (TypeError, AttributeError):  # pragma: no cover <TAB>  <TAB> _raise_serialization_error(text)","if ""&"" in text :",160
"def _read_row_from_packet(self, packet): <TAB> row = [] <TAB> for encoding, converter in self.converters: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> data = packet.read_length_coded_string() <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB> # No more columns in this row <TAB>  <TAB>  <TAB> # See https://github.com/PyMySQL/PyMySQL/pull/434 <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if data is not None: <TAB>  <TAB>  <TAB> if encoding is not None: <TAB>  <TAB>  <TAB>  <TAB> data = data.decode(encoding) <TAB>  <TAB>  <TAB> if DEBUG: <TAB>  <TAB>  <TAB>  <TAB> print(""DEBUG: DATA = "", data) <MASK> data = converter(data) <TAB>  <TAB> row.append(data) <TAB> return tuple(row)",if converter is not None :,186
"def dumpMenuTree(self, aList, level=0, path=""""): <TAB> for z in aList: <TAB>  <TAB> kind, val, val2 = z <MASK> name = self.getName(val, val2) <TAB>  <TAB>  <TAB> g.es_print( <TAB>  <TAB>  <TAB>  <TAB> ""%s %s (%s) [%s]"" % ("" <TAB> "" * (level + 0), val, val2, path + ""/"" + name) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = self.getName(kind.replace(""@menu "", """")) <TAB>  <TAB>  <TAB> g.es_print(""%s %s... [%s]"" % ("" <TAB> "" * (level), kind, path + ""/"" + name)) <TAB>  <TAB>  <TAB> self.dumpMenuTree(val, level + 1, path=path + ""/"" + name)","if kind == ""@item"" :",196
"def startElement(self, name, attrs, connection): <TAB> if name == ""SecurityGroups"": <TAB>  <TAB> return self.security_groups <TAB> elif name == ""ClassicLinkVPCSecurityGroups"": <TAB>  <TAB> return self.classic_link_vpc_security_groups <TAB> elif name == ""BlockDeviceMappings"": <MASK> self.block_device_mappings = BDM() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.block_device_mappings = ResultSet([(""member"", BlockDeviceMapping)]) <TAB>  <TAB> return self.block_device_mappings <TAB> elif name == ""InstanceMonitoring"": <TAB>  <TAB> self.instance_monitoring = InstanceMonitoring(self) <TAB>  <TAB> return self.instance_monitoring",if self . use_block_device_types :,171
"def __get_dev_and_disk(topology): <TAB> rv = [] <TAB> for values in topology.values(): <TAB>  <TAB> values = values.copy() <TAB>  <TAB> while values: <TAB>  <TAB>  <TAB> value = values.pop() <MASK> rv.append((value[""path""].replace(""/dev/"", """"), value[""disk""])) <TAB>  <TAB>  <TAB> values += value.get(""children"") or [] <TAB> return rv","if value [ ""type"" ] == ""DISK"" :",107
"def _process_events(self, event_list): <TAB> for key, mask in event_list: <TAB>  <TAB> fileobj, (reader, writer) = key.fileobj, key.data <TAB>  <TAB> if mask & selectors.EVENT_READ and reader is not None: <MASK> self.remove_reader(fileobj) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._add_callback(reader) <TAB>  <TAB> if mask & selectors.EVENT_WRITE and writer is not None: <TAB>  <TAB>  <TAB> if writer._cancelled: <TAB>  <TAB>  <TAB>  <TAB> self.remove_writer(fileobj) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._add_callback(writer)",if reader . _cancelled :,158
"def colourLabels(self): <TAB> if self.showAttr and self.hasAttr: <TAB>  <TAB> self.canvas.itemconfigure(self.attrId, fill=self.fgColour) <TAB> try: <MASK> self.label.config(background=self.bgColour, fg=self.fgColour) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.label.config(background=self.bgHColour, fg=self.fgHColour) <TAB> except: <TAB>  <TAB> pass",if not self . selected :,122
"def validate_char_lengths(self): <TAB> for field in self._meta.get_fields(): <MASK> if ( <TAB>  <TAB>  <TAB>  <TAB> isinstance(getattr(self, field.name), basestring) <TAB>  <TAB>  <TAB>  <TAB> and len(getattr(self, field.name)) > field.max_length <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> raise Exception( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Role %s value exceeeds max length of %s."" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> % (field.name, field.max_length) <TAB>  <TAB>  <TAB>  <TAB> )","if not field . is_relation and field . get_internal_type ( ) == ""CharField"" :",149
"def _render_lang_List(self, element): <TAB> with self.buffer.foldable_lines(): <TAB>  <TAB> self.buffer.write(""["", style=self.styles.bracket) <TAB>  <TAB> item_count = len(element.items) <MASK> with self.buffer.indent(): <TAB>  <TAB>  <TAB>  <TAB> for idx, item in enumerate(element.items): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._render(item) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if idx < (item_count - 1): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.buffer.write("","") <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.buffer.mark_line_break() <TAB>  <TAB> if element.trimmed: <TAB>  <TAB>  <TAB> self.buffer.write(""..."") <TAB>  <TAB> self.buffer.write(""]"", style=self.styles.bracket)",if item_count :,183
"def do_dialog(): <TAB> """"""Post dialog and handle user interaction until quit"""""" <TAB> my_dlg = Dlg.GetNewDialog(ID_MAIN, -1) <TAB> while 1: <TAB>  <TAB> n = Dlg.ModalDialog(None) <TAB>  <TAB> if n == ITEM_LOOKUP_BUTTON: <TAB>  <TAB>  <TAB> tp, h, rect = my_dlg.GetDialogItem(ITEM_LOOKUP_ENTRY) <TAB>  <TAB>  <TAB> txt = Dlg.GetDialogItemText(h) <TAB>  <TAB>  <TAB> tp, h, rect = my_dlg.GetDialogItem(ITEM_RESULT) <TAB>  <TAB>  <TAB> Dlg.SetDialogItemText(h, dnslookup(txt)) <MASK> break",elif n == ITEM_QUIT_BUTTON :,173
"def _extract_more_comments(tree): <TAB> """"""Return a list of MoreComments objects removed from tree."""""" <TAB> more_comments = [] <TAB> queue = [(None, x) for x in tree] <TAB> while len(queue) > 0: <TAB>  <TAB> parent, comm = queue.pop(0) <MASK> heappush(more_comments, comm) <TAB>  <TAB>  <TAB> if parent: <TAB>  <TAB>  <TAB>  <TAB> parent.replies.remove(comm) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> tree.remove(comm) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for item in comm.replies: <TAB>  <TAB>  <TAB>  <TAB> queue.append((comm, item)) <TAB> return more_comments","if isinstance ( comm , MoreComments ) :",171
"def run(self): <TAB> while True: <TAB>  <TAB> self.finished.wait(self.interval) <MASK> return <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.function(*self.args, **self.kwargs) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> if self.bus: <TAB>  <TAB>  <TAB>  <TAB> self.bus.log( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Error in perpetual timer thread function %r."" % self.function, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> level=40, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> traceback=True, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> # Quit on first error to avoid massive logs. <TAB>  <TAB>  <TAB> raise",if self . finished . isSet ( ) :,157
"def emit_classattribs(self, typebld): <TAB> if hasattr(self, ""_clrclassattribs""): <TAB>  <TAB> for attrib_info in self._clrclassattribs: <MASK> ci = clr.GetClrType(attrib_info).GetConstructor(()) <TAB>  <TAB>  <TAB>  <TAB> cab = CustomAttributeBuilder(ci, ()) <TAB>  <TAB>  <TAB> elif isinstance(attrib_info, CustomAttributeDecorator): <TAB>  <TAB>  <TAB>  <TAB> cab = attrib_info.GetBuilder() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> make_decorator = attrib_info() <TAB>  <TAB>  <TAB>  <TAB> cab = make_decorator.GetBuilder() <TAB>  <TAB>  <TAB> typebld.SetCustomAttribute(cab)","if isinstance ( attrib_info , type ) :",166
"def wrapper(fn): <TAB> if debug_run_test_calls: <TAB>  <TAB> ret = str(fn(*args, *kwargs)) <TAB>  <TAB> print(""TEST: %s()"" % fn.__name__) <TAB>  <TAB> if args: <TAB>  <TAB>  <TAB> print(""  arg:"", args) <MASK> print(""  kwa:"", kwargs) <TAB>  <TAB> print(""  ret:"", ret) <TAB> return fn",if kwargs :,95
"def _prune(self): <TAB> with self.lock: <TAB>  <TAB> entries = self._list_dir() <MASK> now = time.time() <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> for i, fpath in enumerate(entries): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> remove = False <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f = LockedFile(fpath, ""rb"") <TAB>  <TAB>  <TAB>  <TAB>  <TAB> exp = pickle.load(f.file) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f.close() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> remove = exp <= now or i % 3 == 0 <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if remove: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._del_file(fpath) <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> pass",if len ( entries ) > self . _threshold :,173
"def delete_if_forked(ghrequest): <TAB> FORKED = False <TAB> query = ""/user/repos"" <TAB> r = utils.query_request(query) <TAB> for repo in r.json(): <MASK> if ghrequest.target_repo_fullname in repo[""description""]: <TAB>  <TAB>  <TAB>  <TAB> FORKED = True <TAB>  <TAB>  <TAB>  <TAB> url = f""/repos/{repo['full_name']}"" <TAB>  <TAB>  <TAB>  <TAB> utils.query_request(url, method=""DELETE"") <TAB> return FORKED","if repo [ ""description"" ] :",127
"def _feed_data_to_buffered_proto(proto, data): <TAB> data_len = len(data) <TAB> while data_len: <TAB>  <TAB> buf = proto.get_buffer(data_len) <TAB>  <TAB> buf_len = len(buf) <MASK> raise RuntimeError(""get_buffer() returned an empty buffer"") <TAB>  <TAB> if buf_len >= data_len: <TAB>  <TAB>  <TAB> buf[:data_len] = data <TAB>  <TAB>  <TAB> proto.buffer_updated(data_len) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> buf[:buf_len] = data[:buf_len] <TAB>  <TAB>  <TAB> proto.buffer_updated(buf_len) <TAB>  <TAB>  <TAB> data = data[buf_len:] <TAB>  <TAB>  <TAB> data_len = len(data)",if not buf_len :,189
"def _plugin_get_requirements(self, requirements_iter): <TAB> plugin_requirements = {""platform"": [], ""python"": [], ""network"": [], ""native"": []} <TAB> # parse requirements <TAB> for requirement in requirements_iter: <TAB>  <TAB> key = requirement[0] <TAB>  <TAB> values = requirement[1] <TAB>  <TAB> if isinstance(values, str) or isinstance(values, bool): <TAB>  <TAB>  <TAB> values = [values] <MASK> plugin_requirements[key].extend(values) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> warning(""{}={}: No supported requirement"".format(key, values)) <TAB> return plugin_requirements",if key in plugin_requirements :,148
"def setCurrentModelIndexes(self, indexes): <TAB> self._indexes = [] <TAB> self._index = None <TAB> for i in indexes: <TAB>  <TAB> if i.isValid(): <MASK> i = i.sibling(i.row(), self._column) <TAB>  <TAB>  <TAB> self._indexes.append(i) <TAB> self.updateItems() <TAB> self.updateSelectedItem()",if i . column ( ) != self . _column :,101
"def _publish(self, data): <TAB> retry = True <TAB> while True: <TAB>  <TAB> try: <MASK> self._redis_connect() <TAB>  <TAB>  <TAB> return self.redis.publish(self.channel, pickle.dumps(data)) <TAB>  <TAB> except redis.exceptions.ConnectionError: <TAB>  <TAB>  <TAB> if retry: <TAB>  <TAB>  <TAB>  <TAB> logger.error(""Cannot publish to redis... retrying"") <TAB>  <TAB>  <TAB>  <TAB> retry = False <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> logger.error(""Cannot publish to redis... giving up"") <TAB>  <TAB>  <TAB>  <TAB> break",if not retry :,134
"def write_pad_and_flush(self, data, pad="" ""): <TAB> if self.encryptor and (data or self.encode_buffer): <MASK> remainder = len(self.encode_buffer) + len(data) <TAB>  <TAB>  <TAB> remainder %= self.encode_batches <TAB>  <TAB>  <TAB> padding = self.encode_batches - remainder <TAB>  <TAB>  <TAB> data += pad * padding <TAB> self.write(data) <TAB> self.flush()",if self . encode_batches :,110
"def dump_metrics(self): <TAB> metrics = self._registry.dump_metrics() <TAB> # Filter out min and max if there have been no samples. <TAB> for metric in metrics.itervalues(): <MASK> if ""min"" in metric: <TAB>  <TAB>  <TAB>  <TAB> metric[""min""] = 0.0 <TAB>  <TAB>  <TAB> if ""max"" in metric: <TAB>  <TAB>  <TAB>  <TAB> metric[""max""] = 0.0 <TAB> return metrics","if metric . get ( ""count"" ) == 0 :",109
"def demo(): <TAB> d = StatusProgressDialog(""A Demo"", ""Doing something..."") <TAB> import win32api <TAB> for i in range(100): <TAB>  <TAB> if i == 50: <TAB>  <TAB>  <TAB> d.SetText(""Getting there..."") <MASK> d.SetText(""Nearly done..."") <TAB>  <TAB> win32api.Sleep(20) <TAB>  <TAB> d.Tick() <TAB> d.Close()",if i == 90 :,99
"def get_file_contents(app_name: str, app_version: str, file_path: str): <TAB> full_path = f""{app_name}/{app_version}/{file_path}"" <TAB> success, contents = await MinioApi.get_file(app_name, app_version, file_path) <TAB> if success: <TAB>  <TAB> return contents <TAB> else: <MASK> raise DoesNotExistException(""read"", ""file"", full_path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise InvalidInputException( <TAB>  <TAB>  <TAB>  <TAB> ""read"", ""file"", full_path, errors={""error"": contents} <TAB>  <TAB>  <TAB> )",if contents is None :,153
"def _sashMark(self, event): <TAB> self._sashIndex = -1 <TAB> try: <TAB>  <TAB> self._sashIndex, which = self.paneframe.identify(event.x, event.y) <MASK> self._sashx = [ <TAB>  <TAB>  <TAB>  <TAB> self.paneframe.sash_coord(i)[0] for i in range(len(self._lists) - 1) <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB> self._sashdx = self._sashx[self._sashIndex] - event.x <TAB>  <TAB>  <TAB> self._sashDrag(event) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._sashIndex = -1 <TAB> except: <TAB>  <TAB> return <TAB> return ""break""","if which == ""sash"" :",181
"def emptyTree(self): <TAB> for child in self: <TAB>  <TAB> childObj = child.getObject() <TAB>  <TAB> del childObj[NameObject(""/Parent"")] <MASK> del childObj[NameObject(""/Next"")] <TAB>  <TAB> if NameObject(""/Prev"") in childObj: <TAB>  <TAB>  <TAB> del childObj[NameObject(""/Prev"")] <TAB> if NameObject(""/Count"") in self: <TAB>  <TAB> del self[NameObject(""/Count"")] <TAB> if NameObject(""/First"") in self: <TAB>  <TAB> del self[NameObject(""/First"")] <TAB> if NameObject(""/Last"") in self: <TAB>  <TAB> del self[NameObject(""/Last"")]","if NameObject ( ""/Next"" ) in childObj :",155
"def contractIfNotCurrent(c, p, leaveOpen): <TAB> if p == leaveOpen or not p.isAncestorOf(leaveOpen): <TAB>  <TAB> p.contract() <TAB> for child in p.children(): <MASK> contractIfNotCurrent(c, child, leaveOpen) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for p2 in child.self_and_subtree(): <TAB>  <TAB>  <TAB>  <TAB> p2.contract()",if child != leaveOpen and child . isAncestorOf ( leaveOpen ) :,119
"def test_cat(shape, cat_dim, split, dim): <TAB> assert sum(split) == shape[cat_dim] <TAB> gaussian = random_gaussian(shape, dim) <TAB> parts = [] <TAB> end = 0 <TAB> for size in split: <TAB>  <TAB> beg, end = end, end + size <TAB>  <TAB> if cat_dim == -1: <TAB>  <TAB>  <TAB> part = gaussian[..., beg:end] <TAB>  <TAB> elif cat_dim == -2: <TAB>  <TAB>  <TAB> part = gaussian[..., beg:end, :] <MASK> part = gaussian[:, beg:end] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError <TAB>  <TAB> parts.append(part) <TAB> actual = Gaussian.cat(parts, cat_dim) <TAB> assert_close_gaussian(actual, gaussian)",elif cat_dim == 1 :,186
"def _remove_timeout(self, key): <TAB> if key in self.waiting: <TAB>  <TAB> request, callback, timeout_handle = self.waiting[key] <MASK> self.io_loop.remove_timeout(timeout_handle) <TAB>  <TAB> del self.waiting[key]",if timeout_handle is not None :,79
"def gyro(self, mapper, *pyr): <TAB> for i in (0, 1, 2): <TAB>  <TAB> axis = self.axes[i] <TAB>  <TAB> # 'gyro' cannot map to mouse, but 'mouse' does that. <MASK> mapper.gamepad.axisEvent( <TAB>  <TAB>  <TAB>  <TAB> axis, AxisAction.clamp_axis(axis, pyr[i] * self.speed[i] * -10) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> mapper.syn_list.add(mapper.gamepad)",if axis in Axes or type ( axis ) == int :,136
"def check_enums_ATLAS_MACHTYPE(lines): <TAB> for i, mach_type in enumerate(ATLAS_MACHTYPE): <TAB>  <TAB> got = lines.pop(0).strip() <TAB>  <TAB> expect = ""{0} = '{1}'"".format(i, mach_type) <MASK> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB> ""ATLAS_MACHTYPE mismatch at position "" <TAB>  <TAB>  <TAB>  <TAB> + str(i) <TAB>  <TAB>  <TAB>  <TAB> + "": got >>"" <TAB>  <TAB>  <TAB>  <TAB> + got <TAB>  <TAB>  <TAB>  <TAB> + ""<<, expected >>"" <TAB>  <TAB>  <TAB>  <TAB> + expect <TAB>  <TAB>  <TAB>  <TAB> + ""<<"" <TAB>  <TAB>  <TAB> )",if got != expect :,154
"def readArgs(self, node): <TAB> res = {} <TAB> for c in self.getChildrenOf(node): <TAB>  <TAB> val = c.getAttribute(""val"") <TAB>  <TAB> if val in self.modules: <TAB>  <TAB>  <TAB> res[str(c.nodeName)] = self.modules[val] <MASK> res[str(c.nodeName)] = self.mothers[val] <TAB>  <TAB> elif val != """": <TAB>  <TAB>  <TAB> res[str(c.nodeName)] = eval(val) <TAB> return res",elif val in self . mothers :,130
"def submit_events(self, events): <TAB> headers = {""Content-Type"": ""application/json""} <TAB> event_chunk_size = self.event_chunk_size <TAB> for chunk in chunks(events, event_chunk_size): <TAB>  <TAB> payload = { <TAB>  <TAB>  <TAB> ""apiKey"": self.api_key, <TAB>  <TAB>  <TAB> ""events"": {""api"": chunk}, <TAB>  <TAB>  <TAB> ""uuid"": get_uuid(), <TAB>  <TAB>  <TAB> ""internalHostname"": get_hostname(), <TAB>  <TAB> } <TAB>  <TAB> params = {} <MASK> params[""api_key""] = self.api_key <TAB>  <TAB> url = ""%s/intake?%s"" % (self.api_host, urlencode(params)) <TAB>  <TAB> self.submit_http(url, json.dumps(payload), headers)",if self . api_key :,188
"def rewrite_urls_mygpo(self): <TAB> # Check if we have to rewrite URLs since the last add <TAB> rewritten_urls = self.mygpo_client.get_rewritten_urls() <TAB> changed = False <TAB> for rewritten_url in rewritten_urls: <MASK> continue <TAB>  <TAB> for channel in self.channels: <TAB>  <TAB>  <TAB> if channel.url == rewritten_url.old_url: <TAB>  <TAB>  <TAB>  <TAB> logger.info(""Updating URL of %s to %s"", channel, rewritten_url.new_url) <TAB>  <TAB>  <TAB>  <TAB> channel.url = rewritten_url.new_url <TAB>  <TAB>  <TAB>  <TAB> channel.save() <TAB>  <TAB>  <TAB>  <TAB> changed = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB> if changed: <TAB>  <TAB> util.idle_add(self.update_episode_list_model)",if not rewritten_url . new_url :,200
"def validate_hostname(hostname): <TAB> if hostname is None or len(hostname) == 0: <TAB>  <TAB> return False, ""Empty hostname or domain is not allowed"" <TAB> fields = hostname.split(""."") <TAB> for field in fields: <TAB>  <TAB> if not field: <TAB>  <TAB>  <TAB> return False, ""Empty hostname or domain is not allowed"" <MASK> return False, ""Hostname or domain should not start or end with '-'"" <TAB> machinename = fields[0] <TAB> if len(machinename) > 64 or not machinename[0].isalpha(): <TAB>  <TAB> return False, ""Hostname should start with alpha char and <= 64 chars"" <TAB> return True, None","if field [ 0 ] == ""-"" or field [ - 1 ] == ""-"" :",166
"def apply_to(cls, lexer): <TAB> # Apply a font for all styles <TAB> lexer.setFont(Font().load()) <TAB> for name, font in cls.__dict__.items(): <MASK> continue <TAB>  <TAB> if hasattr(lexer, name): <TAB>  <TAB>  <TAB> style_num = getattr(lexer, name) <TAB>  <TAB>  <TAB> lexer.setColor(QColor(font.color), style_num) <TAB>  <TAB>  <TAB> lexer.setEolFill(True, style_num) <TAB>  <TAB>  <TAB> lexer.setPaper(QColor(font.paper), style_num) <TAB>  <TAB>  <TAB> lexer.setFont(font.load(), style_num)","if not isinstance ( font , Font ) :",158
"def dr_relation(self, C, trans, nullable): <TAB> state, N = trans <TAB> terms = [] <TAB> g = self.lr0_goto(C[state], N) <TAB> for p in g: <TAB>  <TAB> if p.lr_index < p.len - 1: <TAB>  <TAB>  <TAB> a = p.prod[p.lr_index + 1] <MASK> if a not in terms: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> terms.append(a) <TAB> # This extra bit is to handle the start state <TAB> if state == 0 and N == self.grammar.Productions[0].prod[0]: <TAB>  <TAB> terms.append(""$end"") <TAB> return terms",if a in self . grammar . Terminals :,167
"def process_module(name, module, parent): <TAB> if parent: <TAB>  <TAB> modules[parent][""items""].append(name) <TAB>  <TAB> mg = module_groups.setdefault(name, []) <TAB>  <TAB> mg.append(parent) <MASK> module["".group""] = parent <TAB> # check module content <TAB> for k, v in list(module.items()): <TAB>  <TAB> if k.startswith(""on_click""): <TAB>  <TAB>  <TAB> # on_click event <TAB>  <TAB>  <TAB> process_onclick(k, v, name) <TAB>  <TAB>  <TAB> # on_click should not be passed to the module via the config. <TAB>  <TAB>  <TAB> del module[k] <TAB>  <TAB> if isinstance(v, ModuleDefinition): <TAB>  <TAB>  <TAB> # we are a container <TAB>  <TAB>  <TAB> module[""items""] = [] <TAB> return module","if get_module_type ( name ) == ""py3status"" :",198
"def GetQualifiedWsdlName(type): <TAB> with _lazyLock: <TAB>  <TAB> wsdlNSAndName = _wsdlNameMap.get(type) <MASK> return wsdlNSAndName <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if issubclass(type, list): <TAB>  <TAB>  <TAB>  <TAB> ns = GetWsdlNamespace(type.Item._version) <TAB>  <TAB>  <TAB>  <TAB> return (ns, ""ArrayOf"" + Capitalize(type.Item._wsdlName)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> ns = GetWsdlNamespace(type._version) <TAB>  <TAB>  <TAB>  <TAB> return (ns, type._wsdlName)",if wsdlNSAndName :,158
"def assert_tensors_equal(sess, t1, t2, n): <TAB> """"""Compute tensors `n` times and ensure that they are equal."""""" <TAB> for _ in range(n): <TAB>  <TAB> v1, v2 = sess.run([t1, t2]) <MASK> return False <TAB>  <TAB> if not np.all(v1 == v2): <TAB>  <TAB>  <TAB> return False <TAB> return True",if v1 . shape != v2 . shape :,107
"def _lxml_default_loader(href, parse, encoding=None, parser=None): <TAB> if parse == ""xml"": <TAB>  <TAB> data = etree.parse(href, parser).getroot() <TAB> else: <TAB>  <TAB> if ""://"" in href: <TAB>  <TAB>  <TAB> f = urlopen(href) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> f = open(href, ""rb"") <TAB>  <TAB> data = f.read() <TAB>  <TAB> f.close() <MASK> encoding = ""utf-8"" <TAB>  <TAB> data = data.decode(encoding) <TAB> return data",if not encoding :,133
"def range_f(begin, end, step): <TAB> # like range, but works on non-integer too <TAB> seq = [] <TAB> while True: <MASK> break <TAB>  <TAB> if step < 0 and begin < end: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> seq.append(begin) <TAB>  <TAB> begin = begin + step <TAB> return seq",if step > 0 and begin > end :,90
"def _get_seccomp_whitelist(self): <TAB> whitelist = [False] * MAX_SYSCALL_NUMBER <TAB> index = _SYSCALL_INDICIES[NATIVE_ABI] <TAB> for i in range(SYSCALL_COUNT): <TAB>  <TAB> # Ensure at least one syscall traps. <TAB>  <TAB> # Otherwise, a simple assembly program could terminate without ever trapping. <MASK> continue <TAB>  <TAB> handler = self._security.get(i, DISALLOW) <TAB>  <TAB> for call in translator[i][index]: <TAB>  <TAB>  <TAB> if call is None: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if isinstance(handler, int): <TAB>  <TAB>  <TAB>  <TAB> whitelist[call] = handler == ALLOW <TAB> return whitelist","if i in ( sys_exit , sys_exit_group ) :",185
"def add_custom_versions(versions): <TAB> """"""create custom versions strings"""""" <TAB> versions_dict = {} <TAB> for tech, version in versions.items(): <TAB>  <TAB> # clean up ""-"" from version <TAB>  <TAB> if ""-"" in version: <TAB>  <TAB>  <TAB> version = version.split(""-"")[0] <MASK> version = version[1:]  # Remove the 'v' prefix <TAB>  <TAB>  <TAB> versions_dict[tech + ""_numeric""] = version.split(""+"")[0] <TAB>  <TAB>  <TAB> # ""3.3.0.33"" is what we have, we want ""3.3"" <TAB>  <TAB>  <TAB> versions_dict[tech + ""_short""] = ""{}.{}"".format(*version.split(""."")) <TAB> return versions_dict","if version . startswith ( ""v"" ) :",167
"def detab(self, text): <TAB> """"""Remove a tab from the front of each line of the given text."""""" <TAB> newtext = [] <TAB> lines = text.split(""\n"") <TAB> for line in lines: <MASK> newtext.append(line[self.tab_length :]) <TAB>  <TAB> elif not line.strip(): <TAB>  <TAB>  <TAB> newtext.append("""") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> return ""\n"".join(newtext), ""\n"".join(lines[len(newtext) :])","if line . startswith ( "" "" * self . tab_length ) :",134
"def ignore_module(module): <TAB> result = False <TAB> for check in ignore_these: <TAB>  <TAB> if ""/*"" in check: <MASK> result = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if (os.getcwd() + ""/"" + check + "".py"") == module: <TAB>  <TAB>  <TAB>  <TAB> result = True <TAB> if result: <TAB>  <TAB> print_warning(""Ignoring module: "" + module) <TAB> return result",if check [ : - 1 ] in module :,108
def load_previous_values(self): <TAB> ReportOptions.load_previous_values(self) <TAB> # Pass the loaded values to the menu options so they will be displayed <TAB> # properly. <TAB> for optname in self.options_dict: <TAB>  <TAB> menu_option = self.menu.get_option_by_name(optname) <MASK> menu_option.set_value(self.options_dict[optname]),if menu_option :,104
"def dequeue(self): <TAB> with self.db(commit=True) as curs: <TAB>  <TAB> curs.execute( <TAB>  <TAB>  <TAB> ""select id, data from task where queue = ? "" <TAB>  <TAB>  <TAB> ""order by priority desc, id limit 1"", <TAB>  <TAB>  <TAB> (self.name,), <TAB>  <TAB> ) <TAB>  <TAB> result = curs.fetchone() <MASK> tid, data = result <TAB>  <TAB>  <TAB> curs.execute(""delete from task where id = ?"", (tid,)) <TAB>  <TAB>  <TAB> if curs.rowcount == 1: <TAB>  <TAB>  <TAB>  <TAB> return to_bytes(data)",if result is not None :,138
"def _collect_sublayers_attr(self, attr): <TAB> if attr not in [""trainable_weights"", ""nontrainable_weights""]: <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> ""Only support to collect some certain attributes of nested layers,"" <TAB>  <TAB>  <TAB> ""e.g. 'trainable_weights', 'nontrainable_weights', but got {}"".format(attr) <TAB>  <TAB> ) <TAB> if self._layers is None: <TAB>  <TAB> return [] <TAB> nested = [] <TAB> for layer in self._layers: <TAB>  <TAB> value = getattr(layer, attr) <MASK> nested.extend(value) <TAB> return nested",if value is not None :,146
"def DeleteTab(self, tab): <TAB> tab_renderer = self.tabs[tab] <TAB> was_selected = tab_renderer.GetSelected() <TAB> self.tabs.remove(tab_renderer) <TAB> if tab_renderer: <TAB>  <TAB> del tab_renderer <TAB> # determine our new selection <TAB> if was_selected and self.GetTabsCount() > 0: <MASK> self.tabs[self.GetTabsCount() - 1].SetSelected(True) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.tabs[tab].SetSelected(True) <TAB> self.AdjustTabsSize() <TAB> self.Refresh()",if tab > self . GetTabsCount ( ) - 1 :,158
"def _show_warnings(self): <TAB> if self._warnings_handled: <TAB>  <TAB> return <TAB> self._warnings_handled = True <TAB> if self._result and (self._result.has_next or not self._result.warning_count): <TAB>  <TAB> return <TAB> ws = self._get_db().show_warnings() <TAB> if ws is None: <TAB>  <TAB> return <TAB> for w in ws: <TAB>  <TAB> msg = w[-1] <MASK> if isinstance(msg, unicode): <TAB>  <TAB>  <TAB>  <TAB> msg = msg.encode(""utf-8"", ""replace"") <TAB>  <TAB> warnings.warn(err.Warning(*w[1:3]), stacklevel=4)",if PY2 :,158
"def fetch(): <TAB> retval = {} <TAB> content = retrieve_content(__url__) <TAB> if __check__ not in content: <TAB>  <TAB> content = retrieve_content(__backup__) <TAB> if __check__ in content: <TAB>  <TAB> for line in content.split(""\n""): <TAB>  <TAB>  <TAB> line = line.strip() <MASK> continue <TAB>  <TAB>  <TAB> retval[line] = (__info__, __reference__) <TAB> return retval","if not line or line . startswith ( ""#"" ) or ""."" not in line :",114
"def findUserByAttr(self, identifier, attr_type, attr_data): <TAB> for uid in self.users_info: <TAB>  <TAB> attrs = self.users_info[uid] <TAB>  <TAB> for attr in attrs: <MASK> return defer.succeed(uid) <TAB> uid = self.nextId() <TAB> self.db.insertTestData([User(uid=uid, identifier=identifier)]) <TAB> self.db.insertTestData( <TAB>  <TAB> [UserInfo(uid=uid, attr_type=attr_type, attr_data=attr_data)] <TAB> ) <TAB> return defer.succeed(uid)","if attr_type == attr [ ""attr_type"" ] and attr_data == attr [ ""attr_data"" ] :",167
"def order_note_added_event(*, order: Order, user: UserType, message: str) -> OrderEvent: <TAB> kwargs = {} <TAB> if user is not None and not user.is_anonymous: <MASK> account_events.customer_added_to_note_order_event( <TAB>  <TAB>  <TAB>  <TAB> user=user, order=order, message=message <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> kwargs[""user""] = user <TAB> return OrderEvent.objects.create( <TAB>  <TAB> order=order, <TAB>  <TAB> type=OrderEvents.NOTE_ADDED, <TAB>  <TAB> parameters={""message"": message}, <TAB>  <TAB> **kwargs, <TAB> )",if order . user is not None and order . user . pk == user . pk :,161
"def __str__(self): <TAB> if self.team: <MASK> return ""(%s, %s, Q%d, %d and %d) %s"" % ( <TAB>  <TAB>  <TAB>  <TAB> self.team, <TAB>  <TAB>  <TAB>  <TAB> self.data[""yrdln""], <TAB>  <TAB>  <TAB>  <TAB> self.time.qtr, <TAB>  <TAB>  <TAB>  <TAB> self.down, <TAB>  <TAB>  <TAB>  <TAB> self.yards_togo, <TAB>  <TAB>  <TAB>  <TAB> self.desc, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""(%s, %s, Q%d) %s"" % ( <TAB>  <TAB>  <TAB>  <TAB> self.team, <TAB>  <TAB>  <TAB>  <TAB> self.data[""yrdln""], <TAB>  <TAB>  <TAB>  <TAB> self.time.qtr, <TAB>  <TAB>  <TAB>  <TAB> self.desc, <TAB>  <TAB>  <TAB> ) <TAB> return self.desc",if self . down != 0 :,199
"def write(self, stream): <TAB> self.write1(stream) <TAB> i = 0 <TAB> n = 0 <TAB> for name, offset, value, bsize in self.variables: <TAB>  <TAB> stream.write(self.body[i:offset]) <MASK> write_uint(stream, value) <TAB>  <TAB> elif bsize == 8: <TAB>  <TAB>  <TAB> write_ulong(stream, value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise NotImplementedError() <TAB>  <TAB> n += offset - i + bsize <TAB>  <TAB> i = offset + bsize <TAB> stream.write(self.body[i:]) <TAB> n += len(self.body) - i <TAB> assert n == len(self.body)",if bsize == 4 :,162
"def __setattr__(self, attr, val): <TAB> if hasattr(self, attr): <TAB>  <TAB> old = getattr(self, attr) <MASK> if isinstance(val, Setting): <TAB>  <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Attempting to reassign setting %s with %s"" % (old, val) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> log.warn(""Setting attr %s via __setattr__ instead of set()!"", attr) <TAB>  <TAB>  <TAB> return old.set(val) <TAB> log.debug(""Setting {%s => %s}"" % (attr, val)) <TAB> return object.__setattr__(self, attr, val)","if isinstance ( old , Setting ) :",155
"def setup_release_cwd_hook(prompter, history, completer, bindings, **kw): <TAB> if ON_WINDOWS and not ON_CYGWIN and not ON_MSYS: <TAB>  <TAB> prompter.prompt = _cwd_release_wrapper(prompter.prompt) <MASK> # Temporarily restore cwd for callbacks to the completer <TAB>  <TAB>  <TAB> completer.completer.complete = _cwd_restore_wrapper( <TAB>  <TAB>  <TAB>  <TAB> completer.completer.complete <TAB>  <TAB>  <TAB> )",if completer . completer :,112
"def nested_update(org_dict, upd_dict): <TAB> for key, value in upd_dict.items(): <MASK> if key in org_dict: <TAB>  <TAB>  <TAB>  <TAB> if not isinstance(org_dict[key], dict): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Mismatch between org_dict and upd_dict at node {}"".format(key) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> nested_update(org_dict[key], value) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> org_dict[key] = value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> org_dict[key] = value","if isinstance ( value , dict ) :",161
"def get_field_by_name(obj, field): <TAB> # Dereference once <TAB> if obj.type.code == gdb.TYPE_CODE_PTR: <TAB>  <TAB> obj = obj.dereference() <TAB> for f in re.split(""(->|\.|\[\d+\])"", field): <TAB>  <TAB> if not f: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if f == ""->"": <TAB>  <TAB>  <TAB> obj = obj.dereference() <TAB>  <TAB> elif f == ""."": <TAB>  <TAB>  <TAB> pass <MASK> n = int(f.strip(""[]"")) <TAB>  <TAB>  <TAB> obj = obj.cast(obj.dereference().type.pointer()) <TAB>  <TAB>  <TAB> obj += n <TAB>  <TAB>  <TAB> obj = obj.dereference() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> obj = obj[f] <TAB> return obj","elif f . startswith ( ""["" ) :",189
"def check_sum(self, x, gpu=False): <TAB> total = 0 <TAB> for i in range(5): <TAB>  <TAB> t = numpy.array([i], dtype=numpy.int32) <MASK> t = cuda.to_gpu(t) <TAB>  <TAB> loss = self.link(chainer.Variable(x), chainer.Variable(t)).data <TAB>  <TAB> self.assertEqual(loss.dtype, self.dtype) <TAB>  <TAB> self.assertEqual(loss.shape, ()) <TAB>  <TAB> total += numpy.exp(-cuda.to_cpu(loss)) <TAB> self.assertAlmostEqual(1.0, float(total), **self.check_sum_options)",if gpu :,157
"def find_node_by_link(node_group, to_node, inp): <TAB> for link in node_group.links: <TAB>  <TAB> if link.to_node == to_node and link.to_socket == inp: <MASK> # Step through reroutes <TAB>  <TAB>  <TAB>  <TAB> return find_node_by_link( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> node_group, link.from_node, link.from_node.inputs[0] <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return link.from_node","if link . from_node . bl_idname == ""NodeReroute"" :",137
"def _gen_opnds(ii):  # generator <TAB> # filter out write-mask operands and suppressed operands <TAB> for op in ii.parsed_operands: <MASK> continue <TAB>  <TAB> if op.visibility == ""SUPPRESSED"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if op.name == ""BCAST"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> yield op","if op . lookupfn_name in [ ""MASK1"" , ""MASKNOT0"" ] :",104
"def contains_trained_model(self): <TAB> if not hasattr(self, ""_contains_trained_model""): <TAB>  <TAB> for f in self._files: <MASK> self._contains_trained_model = True <TAB>  <TAB>  <TAB>  <TAB> self._model_name = f <TAB>  <TAB>  <TAB>  <TAB> return self._contains_trained_model <TAB>  <TAB> self._contains_trained_model = False <TAB>  <TAB> return self._contains_trained_model <TAB> else: <TAB>  <TAB> return self._contains_trained_model","if "".pt"" in f :",123
"def _call(self, name, *args, **kwargs): <TAB> data = self._get_data(name, *args, **kwargs) <TAB> is_ascii = self._encoding == ""ascii"" <TAB> body = json.dumps(data, ensure_ascii=is_ascii).encode(self._encoding) <TAB> resp = await self._http.post(self._url, data=body) <TAB> if self._full_response: <TAB>  <TAB> return resp <TAB> else: <TAB>  <TAB> content = resp.json() <TAB>  <TAB> if resp.is_error: <MASK> resp.raise_for_status() <TAB>  <TAB> return self.loads(content)","if ""error"" not in content :",161
"def get_classif_name(classifier_config, usepytorch): <TAB> if not usepytorch: <TAB>  <TAB> modelname = ""sklearn-LogReg"" <TAB> else: <TAB>  <TAB> nhid = classifier_config[""nhid""] <TAB>  <TAB> optim = ( <TAB>  <TAB>  <TAB> ""adam"" if ""optim"" not in classifier_config else classifier_config[""optim""] <TAB>  <TAB> ) <TAB>  <TAB> bs = ( <TAB>  <TAB>  <TAB> 64 <MASK> else classifier_config[""batch_size""] <TAB>  <TAB> ) <TAB>  <TAB> modelname = ""pytorch-MLP-nhid%s-%s-bs%s"" % (nhid, optim, bs) <TAB> return modelname","if ""batch_size"" not in classifier_config",165
"def on_fill(self, order: Order, exchange: ""Exchange"", trade: ""Trade""): <TAB> if trade.order_id in self._executed and trade not in self._trades: <TAB>  <TAB> self._trades[trade.order_id] = self._trades.get(trade.order_id, []) <TAB>  <TAB> self._trades[trade.order_id] += [trade] <TAB>  <TAB> if order.is_complete(): <TAB>  <TAB>  <TAB> next_order = order.complete(exchange) <MASK> self.submit(next_order)",if next_order :,143
"def _create_examples(cls, lines, set_type): <TAB> examples = [] <TAB> for (i, line) in enumerate(lines): <TAB>  <TAB> # Skip the header (first line) <MASK> continue <TAB>  <TAB> segments = line.strip().split(""\t"") <TAB>  <TAB> idx, text_a, text_b, label = segments <TAB>  <TAB> examples.append( <TAB>  <TAB>  <TAB> Example( <TAB>  <TAB>  <TAB>  <TAB> guid=""%s-%s"" % (set_type, idx), <TAB>  <TAB>  <TAB>  <TAB> text_a=text_a, <TAB>  <TAB>  <TAB>  <TAB> text_b=text_b, <TAB>  <TAB>  <TAB>  <TAB> label=label, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB> return examples",if i == 0 :,166
"def split_path_info(path): <TAB> # suitable for splitting an already-unquoted-already-decoded (unicode) <TAB> # path value <TAB> path = path.strip(""/"") <TAB> clean = [] <TAB> for segment in path.split(""/""): <TAB>  <TAB> if not segment or segment == ""."": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif segment == "".."": <MASK> del clean[-1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> clean.append(segment) <TAB> return tuple(clean)",if clean :,115
"def _mock_manager(self, *args, **kwargs): <TAB> if kwargs and ""normalize"" not in kwargs: <TAB>  <TAB> device_params = kwargs[""device_params""] <TAB>  <TAB> device_handler = make_device_handler(device_params) <TAB>  <TAB> session = SSHSession(device_handler) <TAB>  <TAB> return Manager(session, device_handler) <TAB> if args: <MASK> file_name = (args[0].findtext(""command"")).replace("" "", ""_"") <TAB>  <TAB>  <TAB> return self._read_file(file_name + "".xml"") <TAB>  <TAB> elif args[0].tag == ""command"": <TAB>  <TAB>  <TAB> file_name = (args[0].text).replace("" "", ""_"") <TAB>  <TAB>  <TAB> return self._read_file(file_name + "".xml"")","if args [ 0 ] . tag == ""request-pfe-execute"" :",193
"def update_loan_status(self, cancel=0): <TAB> if cancel: <TAB>  <TAB> loan_status = frappe.get_value(""Loan"", self.loan, ""status"") <MASK> frappe.db.set_value(""Loan"", self.loan, ""status"", ""Loan Closure Requested"") <TAB> else: <TAB>  <TAB> pledged_qty = 0 <TAB>  <TAB> current_pledges = get_pledged_security_qty(self.loan) <TAB>  <TAB> for security, qty in iteritems(current_pledges): <TAB>  <TAB>  <TAB> pledged_qty += qty <TAB>  <TAB> if not pledged_qty: <TAB>  <TAB>  <TAB> frappe.db.set_value(""Loan"", self.loan, ""status"", ""Closed"")","if loan_status == ""Closed"" :",198
"def _wrapped_view(request, *args, **kwargs): <TAB> if flag_name.startswith(""!""): <TAB>  <TAB> active = not flag_is_active(request, flag_name[1:]) <TAB> else: <TAB>  <TAB> active = flag_is_active(request, flag_name) <TAB> if not active: <TAB>  <TAB> response_to_redirect_to = get_response_to_redirect(redirect_to, *args, **kwargs) <MASK> return response_to_redirect_to <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Http404 <TAB> return view(request, *args, **kwargs)",if response_to_redirect_to :,149
"def process_stroke_filter(stroke, min_distance=1.0, max_distance=2.0): <TAB> """"""filter stroke to pts that are at least min_distance apart"""""" <TAB> nstroke = stroke[:1] <TAB> for p in stroke[1:]: <TAB>  <TAB> v = p - nstroke[-1] <TAB>  <TAB> l = v.length <MASK> continue <TAB>  <TAB> d = v / l <TAB>  <TAB> while l > 0: <TAB>  <TAB>  <TAB> q = nstroke[-1] + d * min(l, max_distance) <TAB>  <TAB>  <TAB> nstroke.append(q) <TAB>  <TAB>  <TAB> l -= max_distance <TAB> return nstroke",if l < min_distance :,158
"def _fix_break_node(self, node: Node): <TAB> end_node = self._find_end_loop(node, [], 0) <MASK> # If there is not end condition on the loop <TAB>  <TAB> # The exploration will reach a STARTLOOP before reaching the endloop <TAB>  <TAB> # We start with -1 as counter to catch this corner case <TAB>  <TAB> end_node = self._find_end_loop(node, [], -1) <TAB>  <TAB> if not end_node: <TAB>  <TAB>  <TAB> raise ParsingError(""Break in no-loop context {}"".format(node.function)) <TAB> for son in node.sons: <TAB>  <TAB> son.remove_father(node) <TAB> node.set_sons([end_node]) <TAB> end_node.add_father(node)",if not end_node :,187
"def _Append(cls, session, word, mail_ids, compact=True): <TAB> super(GlobalPostingList, cls)._Append(session, word, mail_ids, compact=compact) <TAB> with GLOBAL_GPL_LOCK: <TAB>  <TAB> global GLOBAL_GPL <TAB>  <TAB> sig = cls.WordSig(word, session.config) <MASK> GLOBAL_GPL = {} <TAB>  <TAB> if sig not in GLOBAL_GPL: <TAB>  <TAB>  <TAB> GLOBAL_GPL[sig] = set() <TAB>  <TAB> for mail_id in mail_ids: <TAB>  <TAB>  <TAB> GLOBAL_GPL[sig].add(mail_id)",if GLOBAL_GPL is None :,154
"def __saveComment(self): <TAB> """"""Saves the new or selected comment"""""" <TAB> if self.__btnSave.text() == SAVE_NEW: <TAB>  <TAB> # If saving a new comment <TAB>  <TAB> self.__addComment(self.__textSubject.text(), self.__textMessage.toPlainText()) <TAB>  <TAB> self.refreshComments() <TAB> else: <TAB>  <TAB> # If saving a modified comment <MASK> comment = self.__treeSubjects.currentItem().getInstance() <TAB>  <TAB>  <TAB> comment.setSubject(str(self.__textSubject.text())) <TAB>  <TAB>  <TAB> comment.setMessage(str(self.__textMessage.toPlainText())) <TAB>  <TAB>  <TAB> self.__treeSubjects.currentItem().getInstance().save() <TAB>  <TAB>  <TAB> self.refreshComments()",if self . __treeSubjects . currentItem ( ) :,183
"def verify_random_objects(): <TAB> resources = [Node, Registration, QuickFilesNode] <TAB> for resource in resources: <TAB>  <TAB> for i in range(1, 10): <TAB>  <TAB>  <TAB> random_resource = _get_random_object(resource) <MASK> _verify_contributor_perms(random_resource)",if random_resource :,85
"def apply_gradient_modifiers(self): <TAB> for layer_name, views in self.gradient_modifiers.items(): <TAB>  <TAB> for view_name, gradient_mods in views.items(): <TAB>  <TAB>  <TAB> for gm in gradient_mods: <TAB>  <TAB>  <TAB>  <TAB> gm.rnd.set_seed(self.rnd.generate_seed()) <MASK> gm( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.handler, <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.buffer[layer_name].parameters[view_name], <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.buffer[layer_name].gradients[view_name], <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> gm(self.handler, self.buffer[layer_name].gradients[view_name])","if isinstance ( gm , GradientModifier ) :",195
"def _split_auth_string(auth_string): <TAB> """"""split a digest auth string into individual key=value strings"""""" <TAB> prev = None <TAB> for item in auth_string.split("",""): <TAB>  <TAB> try: <MASK> prev = ""%s,%s"" % (prev, item) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB> if prev == None: <TAB>  <TAB>  <TAB>  <TAB> prev = item <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise StopIteration <TAB>  <TAB> yield prev.strip() <TAB>  <TAB> prev = item <TAB> yield prev.strip() <TAB> raise StopIteration","if prev . count ( '""' ) == 1 :",152
"def checkUnchangedIvars(obj, d, exceptions=None): <TAB> if not exceptions: <TAB>  <TAB> exceptions = [] <TAB> ok = True <TAB> for key in d: <MASK> if getattr(obj, key) != d.get(key): <TAB>  <TAB>  <TAB>  <TAB> g.trace( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""changed ivar: %s old: %s new: %s"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> % (key, repr(d.get(key)), repr(getattr(obj, key))) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> ok = False <TAB> return ok",if key not in exceptions :,142
def checkChildren(item): <TAB> for c in item.children(): <TAB>  <TAB> _id = c.data(Outline.ID.value) <MASK> c.getUniqueID() <TAB>  <TAB> checkChildren(c),"if not _id or _id == ""0"" :",65
"def main(): <TAB> if len(sys.argv) > 1: <TAB>  <TAB> g = globals().copy() <TAB>  <TAB> r = g[""test_"" + sys.argv[1]]() <MASK> for func_and_args in r: <TAB>  <TAB>  <TAB>  <TAB> func, args = func_and_args[0], func_and_args[1:] <TAB>  <TAB>  <TAB>  <TAB> func(*args) <TAB> else: <TAB>  <TAB> run_all()",if r is not None :,109
"def _create_entities( <TAB> parsed_entities: Dict[Text, Union[Text, List[Text]]], sidx: int, eidx: int) -> List[Dict[Text, Any]]: <TAB> entities = [] <TAB> for k, vs in parsed_entities.items(): <MASK> vs = [vs] <TAB>  <TAB> for value in vs: <TAB>  <TAB>  <TAB> entities.append( <TAB>  <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""entity"": k, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""start"": sidx, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""end"": eidx,  # can't be more specific <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""value"": value, <TAB>  <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB> ) <TAB> return entities","if not isinstance ( vs , list ) :",172
"def _group_stacks(stacks: Stacks) -> List[dict]: <TAB> stacks_by_client: dict = {} <TAB> for stack in stacks: <TAB>  <TAB> client = stack.client <MASK> stacks_by_client[client] = {""Client"": client, ""Stacks"": []} <TAB>  <TAB> stacks_by_client[client][""Stacks""].append(stack) <TAB> return [stacks_by_client[r] for r in stacks_by_client]",if client not in stacks_by_client :,116
"def append(self, labels): <TAB> if isinstance(labels, list): <TAB>  <TAB> for label in labels: <TAB>  <TAB>  <TAB> if not label in self.__menuLabels: <TAB>  <TAB>  <TAB>  <TAB> self.__menuLabels.append(label) <TAB>  <TAB>  <TAB>  <TAB> self.__enabledLabels.append(label) <TAB> else: <MASK> self.__menuLabels.append(labels) <TAB>  <TAB>  <TAB> self.__enabledLabels.append(labels)",if not labels in self . __menuLabels :,108
"def _json_to_flat_metrics(self, prefix, data): <TAB> for key, value in data.items(): <MASK> for k, v in self._json_to_flat_metrics(""%s.%s"" % (prefix, key), value): <TAB>  <TAB>  <TAB>  <TAB> yield k, v <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> int(value) <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> value = None <TAB>  <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB>  <TAB> yield (""%s.%s"" % (prefix, key), value)","if isinstance ( value , dict ) :",138
"def _rename(src, dst): <TAB> src = to_unicode(src, sys.getfilesystemencoding()) <TAB> dst = to_unicode(dst, sys.getfilesystemencoding()) <TAB> if _rename_atomic(src, dst): <TAB>  <TAB> return True <TAB> retry = 0 <TAB> rv = False <TAB> while not rv and retry < 100: <TAB>  <TAB> rv = _MoveFileEx(src, dst, _MOVEFILE_REPLACE_EXISTING | _MOVEFILE_WRITE_THROUGH) <MASK> time.sleep(0.001) <TAB>  <TAB>  <TAB> retry += 1 <TAB> return rv",if not rv :,135
"def expect_stream_start(self): <TAB> if isinstance(self.event, StreamStartEvent): <MASK> self.encoding = self.event.encoding <TAB>  <TAB> self.write_stream_start() <TAB>  <TAB> self.state = self.expect_first_document_start <TAB> else: <TAB>  <TAB> raise EmitterError(""expected StreamStartEvent, but got %s"" % self.event)","if self . event . encoding and not getattr ( self . stream , ""encoding"" , None ) :",111
"def _doWait(self): <TAB> doit = True <TAB> while doit: <TAB>  <TAB> # A wrapper method for wait() and the wait thread to use <TAB>  <TAB> self.setMeta(""SignalInfo"", None) <TAB>  <TAB> self.setMeta(""PendingSignal"", None) <TAB>  <TAB> event = self.platformWait() <TAB>  <TAB> self.running = False <TAB>  <TAB> self.platformProcessEvent(event) <TAB>  <TAB> doit = self.shouldRunAgain() <MASK> self._doRun()",if doit :,121
"def get_source(self, environment, template): <TAB> if self._sep in template: <TAB>  <TAB> prefix, name = template.split(self._sep, 1) <MASK> raise TemplateNotFound(template) <TAB>  <TAB> return self._mapping[prefix].get_source(environment, name) <TAB> return self._default.get_source(environment, template)",if prefix not in self . _mapping :,92
"def find_child_processes_that_send_spans(pants_result_stderr): <TAB> child_processes = set() <TAB> for line in pants_result_stderr.split(""\n""): <MASK> i = line.rindex("":"") <TAB>  <TAB>  <TAB> child_process_pid = line[i + 1 :] <TAB>  <TAB>  <TAB> child_processes.add(int(child_process_pid)) <TAB> return child_processes","if ""Sending spans to Zipkin server from pid:"" in line :",113
"def list_dependencies_modules(self, *modules): <TAB> """"""[UNIT]... show the dependency tree"" """""" <TAB> found_all = True <TAB> units = [] <TAB> for module in modules: <TAB>  <TAB> matched = self.match_units([module]) <TAB>  <TAB> if not matched: <TAB>  <TAB>  <TAB> logg.error(""no such service '%s'"", module) <TAB>  <TAB>  <TAB> found_all = False <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for unit in matched: <MASK> units += [unit] <TAB> return self.list_dependencies_units(units)  # and found_all",if unit not in units :,143
"def getCommitFromFile(short=True): <TAB> global _gitdir <TAB> branch = getBranchFromFile() <TAB> commit = None <TAB> if _gitdir and branch: <MASK> commitFile = os.path.join(_gitdir, ""HEAD"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> commitFile = os.path.join(_gitdir, ""refs"", ""heads"", branch) <TAB>  <TAB> if os.path.isfile(commitFile): <TAB>  <TAB>  <TAB> with open(commitFile, ""r"", encoding=""utf-8"") as f: <TAB>  <TAB>  <TAB>  <TAB> commit = f.readline().strip() <TAB> if short and commit: <TAB>  <TAB> return commit[:8] <TAB> else: <TAB>  <TAB> return commit","if branch == ""HEAD"" :",169
"def _node_for(pvector_like, i): <TAB> if 0 <= i < pvector_like._count: <MASK> return pvector_like._tail <TAB>  <TAB> node = pvector_like._root <TAB>  <TAB> for level in range(pvector_like._shift, 0, -SHIFT): <TAB>  <TAB>  <TAB> node = node[(i >> level) & BIT_MASK]  # >>> <TAB>  <TAB> return node <TAB> raise IndexError(""Index out of range: %s"" % (i,))",if i >= pvector_like . _tail_offset :,128
"def check(self): <TAB> global MySQLdb <TAB> import MySQLdb <TAB> try: <TAB>  <TAB> args = {} <TAB>  <TAB> if mysql_user: <TAB>  <TAB>  <TAB> args[""user""] = mysql_user <TAB>  <TAB> if mysql_pwd: <TAB>  <TAB>  <TAB> args[""passwd""] = mysql_pwd <MASK> args[""host""] = mysql_host <TAB>  <TAB> if mysql_port: <TAB>  <TAB>  <TAB> args[""port""] = mysql_port <TAB>  <TAB> if mysql_socket: <TAB>  <TAB>  <TAB> args[""unix_socket""] = mysql_socket <TAB>  <TAB> self.db = MySQLdb.connect(**args) <TAB> except Exception as e: <TAB>  <TAB> raise Exception(""Cannot interface with MySQL server: %s"" % e)",if mysql_host :,167
"def flatten(self, d, parent_key="""", sep="".""): <TAB> items = [] <TAB> for k, v in d.items(): <TAB>  <TAB> new_key = parent_key + sep + k if parent_key else k <MASK> items.extend(self.flatten(v, new_key, sep=sep).items()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> items.append((new_key, v)) <TAB> return dict(items)","if isinstance ( v , MutableMapping ) :",111
"def get_item(type_, preference): <TAB> items = {} <TAB> for item in playlist.findall(""./info/%s/item"" % type_): <TAB>  <TAB> lang, label = xpath_text(item, ""lg"", default=None), xpath_text( <TAB>  <TAB>  <TAB> item, ""label"", default=None <TAB>  <TAB> ) <MASK> items[lang] = label.strip() <TAB> for p in preference: <TAB>  <TAB> if items.get(p): <TAB>  <TAB>  <TAB> return items[p]",if lang and label :,121
"def test_lxml(): <TAB> try: <TAB>  <TAB> from lxml.etree import LXML_VERSION, __version__ <MASK> return True, __version__ <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False, __version__ <TAB> except ImportError: <TAB>  <TAB> return None, None","if LXML_VERSION >= ( 2 , 1 , 4 , 0 ) :",81
"def send(self, data, flags=0, timeout=timeout_default): <TAB> if timeout is timeout_default: <TAB>  <TAB> timeout = self.timeout <TAB> try: <TAB>  <TAB> return self._sock.send(data, flags) <TAB> except error as ex: <MASK> raise <TAB>  <TAB> sys.exc_clear() <TAB>  <TAB> self._wait(self._write_event) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self._sock.send(data, flags) <TAB>  <TAB> except error as ex2: <TAB>  <TAB>  <TAB> if ex2.args[0] == EWOULDBLOCK: <TAB>  <TAB>  <TAB>  <TAB> return 0 <TAB>  <TAB>  <TAB> raise",if ex . args [ 0 ] not in _socketcommon . GSENDAGAIN or timeout == 0.0 :,175
def blob_from_lang(self): <TAB> self.acquire_lock() <TAB> try: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> self._load_buf_data_once() <TAB>  <TAB>  <TAB> except NotFoundInDatabase: <TAB>  <TAB>  <TAB>  <TAB> self.release_lock() <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.scan() <TAB>  <TAB>  <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.acquire_lock() <TAB>  <TAB>  <TAB>  <TAB> self._load_buf_data_once(True) <TAB>  <TAB> return self._blob_from_lang_cache <TAB> finally: <TAB>  <TAB> self.release_lock(),if self . _blob_from_lang_cache is None :,159
"def processElem(elem, keyList): <TAB> for k, v in elem.items(): <TAB>  <TAB> prefix = ""."".join(keyList) <MASK> k = makeSane(k) <TAB>  <TAB>  <TAB> self.publish(""%s.%s"" % (prefix, k), v)",if k not in self . IGNORE_ELEMENTS and self . NUMVAL_MATCH . match ( v ) :,90
"def __conform__(self, interface, registry=None, default=None): <TAB> for providedInterface in self.provided: <TAB>  <TAB> if providedInterface.isOrExtends(interface): <TAB>  <TAB>  <TAB> return self.load() <MASK> return interface(self.load(), default) <TAB> return default","if getAdapterFactory ( providedInterface , interface , None ) is not None :",87
"def restrict(points): <TAB> result = [] <TAB> for p in points: <MASK> result.append(p) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> loc, normal, index, distance = bvh.find_nearest(p) <TAB>  <TAB>  <TAB> if loc is not None: <TAB>  <TAB>  <TAB>  <TAB> result.append(tuple(loc)) <TAB> return result","if point_inside_mesh ( bvh , p ) :",96
"def __iter__(self): <TAB> buffer = [b""""] <TAB> for chunk in self.stream(decode_content=True): <TAB>  <TAB> if b""\n"" in chunk: <TAB>  <TAB>  <TAB> chunk = chunk.split(b""\n"") <TAB>  <TAB>  <TAB> yield b"""".join(buffer) + chunk[0] + b""\n"" <TAB>  <TAB>  <TAB> for x in chunk[1:-1]: <TAB>  <TAB>  <TAB>  <TAB> yield x + b""\n"" <MASK> buffer = [chunk[-1]] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> buffer = [] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> buffer.append(chunk) <TAB> if buffer: <TAB>  <TAB> yield b"""".join(buffer)",if chunk [ - 1 ] :,165
"def clear_doc(self, docname: str) -> None: <TAB> for sChild in self._children: <TAB>  <TAB> sChild.clear_doc(docname) <TAB>  <TAB> if sChild.declaration and sChild.docname == docname: <TAB>  <TAB>  <TAB> sChild.declaration = None <TAB>  <TAB>  <TAB> sChild.docname = None <TAB>  <TAB>  <TAB> sChild.line = None <TAB>  <TAB>  <TAB> if sChild.siblingAbove is not None: <TAB>  <TAB>  <TAB>  <TAB> sChild.siblingAbove.siblingBelow = sChild.siblingBelow <MASK> sChild.siblingBelow.siblingAbove = sChild.siblingAbove <TAB>  <TAB>  <TAB> sChild.siblingAbove = None <TAB>  <TAB>  <TAB> sChild.siblingBelow = None",if sChild . siblingBelow is not None :,189
"def _get_current_weight(self, policy, fw): <TAB> weights = policy.get_weights() <TAB> if fw == ""torch"": <TAB>  <TAB> # DQN model. <MASK> return weights[""_hidden_layers.0._model.0.weight""][0][0] <TAB>  <TAB> # DDPG model. <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return weights[""policy_model.action_0._model.0.weight""][0][0] <TAB> key = 0 if fw in [""tf2"", ""tfe""] else list(weights.keys())[0] <TAB> return weights[key][0][0]","if ""_hidden_layers.0._model.0.weight"" in weights :",163
"def add_unit(self, name, value, aliases=tuple(), **modifiers): <TAB> """"""Add unit to the registry."""""" <TAB> if not isinstance(value, self.Quantity): <TAB>  <TAB> value = self.Quantity(value, **modifiers) <TAB> self._UNITS[name] = value <TAB> for ndx, alias in enumerate(aliases): <MASK> logger.warn(""Alias cannot contain a space "" + alias) <TAB>  <TAB> self._UNITS.add_alias(alias.strip(), name, not ndx)","if "" "" in alias :",127
"def keyPressEvent(self, event): <TAB> """"""Add up and down arrow key events to built in functionality."""""" <TAB> keyPressed = event.key() <TAB> if keyPressed in [Constants.UP_KEY, Constants.DOWN_KEY, Constants.TAB_KEY]: <TAB>  <TAB> if keyPressed == Constants.UP_KEY: <TAB>  <TAB>  <TAB> self.index = max(0, self.index - 1) <TAB>  <TAB> elif keyPressed == Constants.DOWN_KEY: <TAB>  <TAB>  <TAB> self.index = min(len(self.completerStrings) - 1, self.index + 1) <MASK> self.tabPressed() <TAB>  <TAB> if self.completerStrings: <TAB>  <TAB>  <TAB> self.setTextToCompleterIndex() <TAB> super(CueLineEdit, self).keyPressEvent(event)",elif keyPressed == Constants . TAB_KEY and self . completerStrings :,192
"def _add_bookmark_breakpoint(self): <TAB> """"""Add a bookmark or breakpoint to the current file in the editor."""""" <TAB> editorWidget = self.ide.mainContainer.get_actual_editor() <TAB> if editorWidget and editorWidget.hasFocus(): <MASK> editorWidget._sidebarWidget.set_bookmark( <TAB>  <TAB>  <TAB>  <TAB> editorWidget.textCursor().blockNumber() <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> elif self.ide.mainContainer.actualTab.navigator.operation == 2: <TAB>  <TAB>  <TAB> editorWidget._sidebarWidget.set_breakpoint( <TAB>  <TAB>  <TAB>  <TAB> editorWidget.textCursor().blockNumber() <TAB>  <TAB>  <TAB> )",if self . ide . mainContainer . actualTab . navigator . operation == 1 :,175
"def list_generator(pages, num_results): <TAB> result = [] <TAB> # get first page items <TAB> page = list(next(pages)) <TAB> result += page <TAB> while True: <TAB>  <TAB> if not pages.continuation_token: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> # handle num results <TAB>  <TAB> if num_results is not None: <MASK> break <TAB>  <TAB> page = list(next(pages)) <TAB>  <TAB> result += page <TAB> return result",if num_results == len ( result ) :,118
"def _print_handles(self, text, handle_list): <TAB> for handle in handle_list: <TAB>  <TAB> source, citation = self.get_source_or_citation(handle, False) <TAB>  <TAB> _LOG.debug(""\n\n\n"") <TAB>  <TAB> if source: <TAB>  <TAB>  <TAB> _LOG.debug(""---- %s -- source %s"" % (text, source.get_title())) <MASK> _LOG.debug(""---- %s -- citation %s"" % (text, citation.get_page())) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _LOG.debug(""---- %s -- handle %s"" % (text, handle))",elif citation :,161
"def _parse_whois(self, txt): <TAB> asn, desc = None, b"""" <TAB> for l in txt.splitlines(): <TAB>  <TAB> if not asn and l.startswith(b""origin:""): <TAB>  <TAB>  <TAB> asn = l[7:].strip().decode(""utf-8"") <TAB>  <TAB> if l.startswith(b""descr:""): <MASK> desc += br""\n"" <TAB>  <TAB>  <TAB> desc += l[6:].strip() <TAB>  <TAB> if asn is not None and desc.strip(): <TAB>  <TAB>  <TAB> desc = desc.strip().decode(""utf-8"") <TAB>  <TAB>  <TAB> break <TAB> return asn, desc",if desc :,151
"def build(opt): <TAB> dpath = os.path.join(opt[""datapath""], ""multiwoz_v20"") <TAB> version = ""1.0"" <TAB> if not build_data.built(dpath, version_string=version): <TAB>  <TAB> print(""[building data: "" + dpath + ""]"") <MASK> build_data.remove_dir(dpath) <TAB>  <TAB> build_data.make_dir(dpath) <TAB>  <TAB> # Download the data. <TAB>  <TAB> for downloadable_file in RESOURCES: <TAB>  <TAB>  <TAB> downloadable_file.download_file(dpath) <TAB>  <TAB> build_data.mark_done(dpath, version_string=version)",if build_data . built ( dpath ) :,163
"def _global_pool2d_shape_func(data_shape, height_axis, width_axis): <TAB> out = output_tensor((data_shape.shape[0],), ""int64"") <TAB> for i in const_range(out.shape[0]): <MASK> out[i] = int64(1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> out[i] = data_shape[i] <TAB> return out",if i == height_axis or i == width_axis :,114
"def post_mortem(t=None): <TAB> # handling the default <MASK> # sys.exc_info() returns (type, value, traceback) if an exception is <TAB>  <TAB> # being handled, otherwise it returns None <TAB>  <TAB> t = sys.exc_info()[2] <TAB>  <TAB> if t is None: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""A valid traceback must be passed if no "" ""exception is being handled"" <TAB>  <TAB>  <TAB> ) <TAB> p = Pdb() <TAB> p.reset() <TAB> p.interaction(None, t)",if t is None :,134
"def clear(self, purge=False, delete_dataset=True): <TAB> self.deleted = True <TAB> if self.dataset: <MASK> self.dataset.deleted = True <TAB>  <TAB> if purge: <TAB>  <TAB>  <TAB> self.dataset.purged = True <TAB> if purge and self.dataset.deleted:  # do something with purging <TAB>  <TAB> self.purged = True <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> os.unlink(self.file_name) <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> log.error( <TAB>  <TAB>  <TAB>  <TAB> ""Failed to purge associated file ({}) from disk: {}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.file_name, unicodify(e) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> )",if delete_dataset :,175
"def scan_resource_conf(self, conf): <TAB> if ""properties"" in conf: <MASK> if str(conf[""properties""][""supportsHttpsTrafficOnly""]).lower() == ""true"": <TAB>  <TAB>  <TAB>  <TAB> return CheckResult.PASSED <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return CheckResult.FAILED <TAB> # Use default if supportsHttpsTrafficOnly is not set <TAB> if ""apiVersion"" in conf: <TAB>  <TAB> # Default for apiVersion 2019 and newer is supportsHttpsTrafficOnly = True <TAB>  <TAB> year = int(conf[""apiVersion""][0:4]) <TAB>  <TAB> if year < 2019: <TAB>  <TAB>  <TAB> return CheckResult.FAILED <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return CheckResult.PASSED <TAB> return CheckResult.FAILED","if ""supportsHttpsTrafficOnly"" in conf [ ""properties"" ] :",192
"def connect(self): <TAB> while True: <TAB>  <TAB> errno = self.sock.connect_ex(self.addr) <TAB>  <TAB> if not errno: <TAB>  <TAB>  <TAB> # connected immediately. <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif errno == EINPROGRESS: <TAB>  <TAB>  <TAB> # will be connected. <TAB>  <TAB>  <TAB> break <MASK> # no such socket file. <TAB>  <TAB>  <TAB> self.create_connection(self.failover_interval) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""Unexpected socket errno: %d"" % errno) <TAB> self.event_loop.watch_file(self.sock.fileno(), self.handle)",elif errno == ENOENT :,157
"def _get_commands(): <TAB> proc = Popen([""react-native"", ""--help""], stdout=PIPE) <TAB> should_yield = False <TAB> for line in proc.stdout.readlines(): <TAB>  <TAB> line = line.decode().strip() <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if ""Commands:"" in line: <TAB>  <TAB>  <TAB> should_yield = True <TAB>  <TAB>  <TAB> continue <MASK> yield line.split("" "")[0]",if should_yield :,111
"def getintdict(self, section): <TAB> try: <TAB>  <TAB> # Exclude keys from [DEFAULT] section because in general they do not hold int values <TAB>  <TAB> return dict( <TAB>  <TAB>  <TAB> (key, int(value)) <TAB>  <TAB>  <TAB> for key, value in self.items(section) <MASK> ) <TAB> except NoSectionError: <TAB>  <TAB> return {}","if key not in { k for k , _ in self . items ( ""DEFAULT"" ) }",103
"def _gen_opnds(ii):  # generator <TAB> # filter out write-mask operands and suppressed operands <TAB> for op in ii.parsed_operands: <TAB>  <TAB> if op.lookupfn_name in [""MASK1"", ""MASKNOT0""]: <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> if op.name == ""BCAST"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> yield op","if op . visibility == ""SUPPRESSED"" :",104
"def do_definition(tag): <TAB> w.end_para() <TAB> macro("".TP"") <TAB> w.started = True <TAB> split = 0 <TAB> pre = [] <TAB> post = [] <TAB> for typ, text in _bitlist(tag): <TAB>  <TAB> if split: <TAB>  <TAB>  <TAB> post.append((typ, text)) <MASK> split = 1 <TAB>  <TAB>  <TAB> post.append((typ, text.lstrip()[2:].lstrip())) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pre.append((typ, text)) <TAB> _boldline(pre) <TAB> w.write(_text(post)) <TAB> w.started = False","elif text . lstrip ( ) . startswith ( "": "" ) :",153
"def EvalInScriptedSection(self, codeBlock, globals, locals=None): <TAB> if locals is None: <TAB>  <TAB> locals = globals <TAB> assert not codeBlock.beenExecuted, ""This code block should not have been executed"" <TAB> codeBlock.beenExecuted = 1 <TAB> self.BeginScriptedSection() <TAB> try: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self._EvalInScriptedSection(codeBlock.codeObject, globals, locals) <TAB>  <TAB> finally: <MASK> self.debugManager.OnLeaveScript() <TAB>  <TAB>  <TAB> self.EndScriptedSection() <TAB> except: <TAB>  <TAB> self.HandleException(codeBlock)",if self . debugManager :,162
"def OSError__str__(self): <TAB> if self.filename: <MASK> return ""[Errno %s] %s: %s -> %s"" % ( <TAB>  <TAB>  <TAB>  <TAB> self.errno, <TAB>  <TAB>  <TAB>  <TAB> self.strerror, <TAB>  <TAB>  <TAB>  <TAB> self.filename, <TAB>  <TAB>  <TAB>  <TAB> self.filename2, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""[Errno %s] %s: %s"" % (self.errno, self.strerror, self.filename) <TAB> if self.errno and self.strerror: <TAB>  <TAB> return ""[Errno %s] %s"" % (self.errno, self.strerror) <TAB> return BaseException.__str__(self)",if self . filename2 :,164
"def save(self, *args, **kwargs): <TAB> if not self.identifier: <TAB>  <TAB> charset = list(""ABCDEFGHJKLMNPQRSTUVWXYZ3789"") <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> code = get_random_string(length=8, allowed_chars=charset) <MASK> self.identifier = code <TAB>  <TAB>  <TAB>  <TAB> break <TAB> super().save(*args, **kwargs) <TAB> if self.event: <TAB>  <TAB> self.event.cache.clear()","if not Question . objects . filter ( event = self . event , identifier = code ) . exists ( ) :",138
"def malloc(self, size): <TAB> # return a block of right size (possibly rounded up) <TAB> assert 0 <= size < sys.maxint <TAB> if os.getpid() != self._lastpid: <TAB>  <TAB> self.__init__()  # reinitialize after fork <TAB> self._lock.acquire() <TAB> try: <TAB>  <TAB> size = self._roundup(max(size, 1), self._alignment) <TAB>  <TAB> (arena, start, stop) = self._malloc(size) <TAB>  <TAB> new_stop = start + size <MASK> self._free((arena, new_stop, stop)) <TAB>  <TAB> block = (arena, start, new_stop) <TAB>  <TAB> self._allocated_blocks.add(block) <TAB>  <TAB> return block <TAB> finally: <TAB>  <TAB> self._lock.release()",if new_stop < stop :,196
"def commit(cache): <TAB> assert cache.is_alive <TAB> try: <TAB>  <TAB> if cache.modified: <TAB>  <TAB>  <TAB> cache.flush() <MASK> assert cache.connection is not None <TAB>  <TAB>  <TAB> cache.database.provider.commit(cache.connection, cache) <TAB>  <TAB> cache.for_update.clear() <TAB>  <TAB> cache.query_results.clear() <TAB>  <TAB> cache.max_id_cache.clear() <TAB>  <TAB> cache.immediate = True <TAB> except: <TAB>  <TAB> cache.rollback() <TAB>  <TAB> raise",if cache . in_transaction :,131
"def __get_tasks(cls, task_ids=None, project_name=None, task_name=None, **kwargs): <TAB> if task_ids: <MASK> task_ids = [task_ids] <TAB>  <TAB> return [ <TAB>  <TAB>  <TAB> cls(private=cls.__create_protection, task_id=task_id, log_to_backend=False) <TAB>  <TAB>  <TAB> for task_id in task_ids <TAB>  <TAB> ] <TAB> return [ <TAB>  <TAB> cls(private=cls.__create_protection, task_id=task.id, log_to_backend=False) <TAB>  <TAB> for task in cls._query_tasks( <TAB>  <TAB>  <TAB> project_name=project_name, task_name=task_name, **kwargs <TAB>  <TAB> ) <TAB> ]","if isinstance ( task_ids , six . string_types ) :",191
"def _VarRefOrWord(node, dynamic_arith): <TAB> # type: (arith_expr_t, bool) -> bool <TAB> with tagswitch(node) as case: <MASK> return True <TAB>  <TAB> elif case(arith_expr_e.Word): <TAB>  <TAB>  <TAB> if dynamic_arith: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if case ( arith_expr_e . VarRef ) :,96
"def fit(self, data_instances, suffix): <TAB> if self.statics_obj is None: <TAB>  <TAB> self.statics_obj = MultivariateStatisticalSummary(data_instances) <TAB> quantile_points = self.statics_obj.get_quantile_point(self.percentile) <TAB> for col_name in self.selection_properties.select_col_names: <TAB>  <TAB> quantile_value = quantile_points.get(col_name) <MASK> self.selection_properties.add_left_col_name(col_name) <TAB>  <TAB> self.selection_properties.add_feature_value(col_name, quantile_value) <TAB> self._keep_one_feature(pick_high=True) <TAB> return self",if quantile_value < self . upper_threshold :,181
"def predict_dict(self, words): <TAB> """"""Predict a list of expansions given words."""""" <TAB> expansions = [] <TAB> for w in words: <TAB>  <TAB> if w in self.expansion_dict: <TAB>  <TAB>  <TAB> expansions += [self.expansion_dict[w]] <MASK> expansions += [self.expansion_dict[w.lower()]] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> expansions += [w] <TAB> return expansions",elif w . lower ( ) in self . expansion_dict :,114
"def connect(self, host, port, ssl, helo, starttls, timeout): <TAB> if ssl == ""0"": <MASK> port = 25 <TAB>  <TAB> fp = SMTP(timeout=int(timeout)) <TAB> else: <TAB>  <TAB> if not port: <TAB>  <TAB>  <TAB> port = 465 <TAB>  <TAB> fp = SMTP_SSL(timeout=int(timeout)) <TAB> resp = fp.connect(host, int(port)) <TAB> if helo: <TAB>  <TAB> cmd, name = helo.split("" "", 1) <TAB>  <TAB> if cmd.lower() == ""ehlo"": <TAB>  <TAB>  <TAB> resp = fp.ehlo(name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> resp = fp.helo(name) <TAB> if not starttls == ""0"": <TAB>  <TAB> resp = fp.starttls() <TAB> return TCP_Connection(fp, resp)",if not port :,200
"def _init_from_text(self, text): <TAB> parts = text.split(""; "") <TAB> for part in parts: <TAB>  <TAB> key, val = part.split(""="") <TAB>  <TAB> if key == ""CLONE"": <MASK> self.is_image = True <TAB>  <TAB>  <TAB>  <TAB> self.image = val[6:] <TAB>  <TAB> setattr(self, key.lower(), val)","if val [ : 5 ] == ""IMAGE"" :",101
"def to_laid_out_tensor(self): <TAB> if not self._reduced: <TAB>  <TAB> self._reduced = self.mesh_impl.allreduce( <TAB>  <TAB>  <TAB> self.laid_out_input, self.mesh_axes, ""SUM"" <TAB>  <TAB> ) <MASK> self._add_counter_fn() <TAB> return self._reduced",if self . _add_counter_fn :,93
"def platformGetThreads(self): <TAB> ret = {} <TAB> self._sendPkt(""qfThreadInfo"") <TAB> tbytes = self._recvPkt() <TAB> while tbytes.startswith(""m""): <MASK> for bval in tbytes[1:].split("",""): <TAB>  <TAB>  <TAB>  <TAB> ret[int(bval, 16)] = 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret[int(tbytes[1:], 16)] = 0 <TAB>  <TAB> self._sendPkt(""qsThreadInfo"") <TAB>  <TAB> tbytes = self._recvPkt() <TAB> return ret","if tbytes . find ( "","" ) :",138
"def _generate_patterns(self, intent, intent_utterances, entity_placeholders): <TAB> unique_patterns = set() <TAB> patterns = [] <TAB> stop_words = self._get_intent_stop_words(intent) <TAB> for utterance in intent_utterances: <TAB>  <TAB> pattern = self._utterance_to_pattern(utterance, stop_words, entity_placeholders) <MASK> unique_patterns.add(pattern) <TAB>  <TAB>  <TAB> patterns.append(pattern) <TAB> return patterns",if pattern not in unique_patterns :,119
"def generator(): <TAB> try: <TAB>  <TAB> _resp_data = DataHelper.flow2origin(self.flow[""response""]) or """" <TAB>  <TAB> length = len(_resp_data) <TAB>  <TAB> size = self.response_chunk_size <TAB>  <TAB> bandwidth = config.bandwidth <MASK> sleep_time = self.response_chunk_size / (bandwidth * 1024) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sleep_time = 0 <TAB>  <TAB> for i in range(int(length / size) + 1): <TAB>  <TAB>  <TAB> time.sleep(sleep_time) <TAB>  <TAB>  <TAB> self.server_resp_time = time.time() <TAB>  <TAB>  <TAB> yield _resp_data[i * size : (i + 1) * size] <TAB> finally: <TAB>  <TAB> self.update_client_resp_time()",if bandwidth > 0 :,190
"def generateMapItemListNode(self, key, value): <TAB> itemslist = list() <TAB> for item in value: <MASK> itemslist.append(""%s = %s"" % (key, self.generateValueNode(item, key))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> itemslist.append(""%s"" % (self.generateValueNode(item))) <TAB> return ""("" + "" OR "".join(itemslist) + "")""",if key in self . allowedFieldsList :,109
"def _underscore_dict(dictionary): <TAB> new_dictionary = {} <TAB> for key, value in dictionary.items(): <MASK> value = _underscore_dict(value) <TAB>  <TAB> if isinstance(key, str): <TAB>  <TAB>  <TAB> key = underscore(key) <TAB>  <TAB> new_dictionary[key] = value <TAB> return new_dictionary","if isinstance ( value , dict ) :",87
"def offsetToRva(self, offset): <TAB> if self.inmem: <TAB>  <TAB> return offset <TAB> for s in self.sections: <TAB>  <TAB> sbase = s.PointerToRawData <MASK> # SizeOfRawData can be misleading. <TAB>  <TAB>  <TAB> ssize = s.VirtualSize <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ssize = max(s.SizeOfRawData, s.VirtualSize) <TAB>  <TAB> if sbase <= offset and offset < sbase + ssize: <TAB>  <TAB>  <TAB> return offset - s.PointerToRawData + s.VirtualAddress <TAB> return 0",if s . SizeOfRawData + s . PointerToRawData > self . getMaxRva ( ) :,155
"def func(): <TAB> end_received = False <TAB> while True: <TAB>  <TAB> for idx, q in enumerate(self._local_out_queues): <TAB>  <TAB>  <TAB> data = q.get() <TAB>  <TAB>  <TAB> q.task_done() <TAB>  <TAB>  <TAB> if isinstance(data, EndSignal): <TAB>  <TAB>  <TAB>  <TAB> end_received = True <TAB>  <TAB>  <TAB>  <TAB> if idx > 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> self._out_queue.put(data) <MASK> break",if end_received :,120
"def unwrap_assert_methods() -> None: <TAB> for patcher in _mock_module_patches: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> patcher.stop() <TAB>  <TAB> except RuntimeError as e: <TAB>  <TAB>  <TAB> # a patcher might have been stopped by user code (#137) <TAB>  <TAB>  <TAB> # so we need to catch this error here and ignore it; <TAB>  <TAB>  <TAB> # unfortunately there's no public API to check if a patch <TAB>  <TAB>  <TAB> # has been started, so catching the error it is <MASK> pass <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise <TAB> _mock_module_patches[:] = [] <TAB> _mock_module_originals.clear()","if str ( e ) == ""stop called on unstarted patcher"" :",170
"def run(self): <TAB> queue = self.queue <TAB> while True: <TAB>  <TAB> if not self.running: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> # Grab our data <TAB>  <TAB> callback, requests, fetchTimeout, validityOverride = queue.get() <TAB>  <TAB> # Grab prices, this is the time-consuming part <MASK> Price.fetchPrices(requests, fetchTimeout, validityOverride) <TAB>  <TAB> wx.CallAfter(callback) <TAB>  <TAB> queue.task_done() <TAB>  <TAB> # After we fetch prices, go through the list of waiting items and call their callbacks <TAB>  <TAB> for price in requests: <TAB>  <TAB>  <TAB> callbacks = self.wait.pop(price.typeID, None) <TAB>  <TAB>  <TAB> if callbacks: <TAB>  <TAB>  <TAB>  <TAB> for callback in callbacks: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> wx.CallAfter(callback)",if len ( requests ) > 0 :,197
"def loadGCodeData(self, dataStream): <TAB> if self._printing: <TAB>  <TAB> return False <TAB> self._lineCount = 0 <TAB> for line in dataStream: <TAB>  <TAB> # Strip out comments, we do not need to send comments <MASK> line = line[: line.index("";"")] <TAB>  <TAB> # Strip out whitespace at the beginning/end this saves data to send. <TAB>  <TAB> line = line.strip() <TAB>  <TAB> if len(line) < 1: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> self._lineCount += 1 <TAB> self._doCallback() <TAB> return True","if "";"" in line :",139
"def _prepare_work_root(self): <TAB> if os.path.exists(self.work_root): <TAB>  <TAB> for f in os.listdir(self.work_root): <MASK> shutil.rmtree(os.path.join(self.work_root, f)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> os.remove(os.path.join(self.work_root, f)) <TAB> else: <TAB>  <TAB> os.makedirs(self.work_root)","if os . path . isdir ( os . path . join ( self . work_root , f ) ) :",136
"def _parse(self): <TAB> for factory in self._sub_factories(): <MASK> node, self.token_pos = factory(**self._initializer_args())._parse_with_pos() <TAB>  <TAB>  <TAB> return node <TAB> self.raise_unexpected_token()",if factory . is_possible_start ( self . get_next_token ( ) ) :,82
"def run(self): <TAB> try: <TAB>  <TAB> if not self.shell: <TAB>  <TAB>  <TAB> self.shell = os.name == ""nt"" <MASK> os.chdir(self.working_dir) <TAB>  <TAB> proc = subprocess.Popen( <TAB>  <TAB>  <TAB> self.command, <TAB>  <TAB>  <TAB> stdout=subprocess.PIPE, <TAB>  <TAB>  <TAB> stderr=subprocess.STDOUT, <TAB>  <TAB>  <TAB> shell=self.shell, <TAB>  <TAB>  <TAB> env=self.env, <TAB>  <TAB> ) <TAB>  <TAB> output = codecs.decode(proc.communicate()[0]) <TAB>  <TAB> self.on_done(output) <TAB> except subprocess.CalledProcessError as e: <TAB>  <TAB> self.on_done(e.returncode, error=True) <TAB> except OSError as e: <TAB>  <TAB> self.on_done(e.message, error=True)","if self . working_dir != """" :",196
"def is_filtered_inherited_member(name: str, obj: Any) -> bool: <TAB> if inspect.isclass(self.object): <TAB>  <TAB> for cls in self.object.__mro__: <TAB>  <TAB>  <TAB> if cls.__name__ == self.options.inherited_members and cls != self.object: <TAB>  <TAB>  <TAB>  <TAB> # given member is a member of specified *super class* <TAB>  <TAB>  <TAB>  <TAB> return True <MASK> return False <TAB>  <TAB>  <TAB> elif name in self.get_attr(cls, ""__annotations__"", {}): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> elif isinstance(obj, ObjectMember) and obj.class_ is cls: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return False",elif name in cls . __dict__ :,167
"def _connect(s, address): <TAB> try: <TAB>  <TAB> s.connect(address) <TAB> except socket.error: <TAB>  <TAB> (ty, v) = sys.exc_info()[:2] <TAB>  <TAB> if hasattr(v, ""errno""): <TAB>  <TAB>  <TAB> v_err = v.errno <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> v_err = v[0] <MASK> raise v","if v_err not in [ errno . EINPROGRESS , errno . EWOULDBLOCK , errno . EALREADY ] :",120
"def _send_file(self, conn, path): <TAB> """"""Method for a file PUT coro"""""" <TAB> while True: <TAB>  <TAB> chunk = conn.queue.get() <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> with ChunkWriteTimeout(self.app.node_timeout): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> conn.send(chunk) <TAB>  <TAB>  <TAB> except (Exception, ChunkWriteTimeout): <TAB>  <TAB>  <TAB>  <TAB> conn.failed = True <TAB>  <TAB>  <TAB>  <TAB> self.exception_occurred( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> conn.node, _(""Object""), _(""Trying to write to %s"") % path <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> conn.queue.task_done()",if not conn . failed :,157
"def get_http_auth(self, name): <TAB> auth = self._config.get(""http-basic.{}"".format(name)) <TAB> if not auth: <TAB>  <TAB> username = self._config.get(""http-basic.{}.username"".format(name)) <TAB>  <TAB> password = self._config.get(""http-basic.{}.password"".format(name)) <MASK> return None <TAB> else: <TAB>  <TAB> username, password = auth[""username""], auth.get(""password"") <TAB>  <TAB> if password is None: <TAB>  <TAB>  <TAB> password = self.keyring.get_password(name, username) <TAB> return { <TAB>  <TAB> ""username"": username, <TAB>  <TAB> ""password"": password, <TAB> }",if not username and not password :,166
"def _do_analyze(self, action_ref, rule_links=None, processed=None, depth=0): <TAB> if processed is None: <TAB>  <TAB> processed = set() <TAB> if rule_links is None: <TAB>  <TAB> rule_links = [] <TAB> processed.add(action_ref) <TAB> for rule_link in self._rules.get(action_ref, []): <TAB>  <TAB> rule_links.append((depth, rule_link)) <MASK> continue <TAB>  <TAB> self._do_analyze( <TAB>  <TAB>  <TAB> rule_link._dest_action_ref, <TAB>  <TAB>  <TAB> rule_links=rule_links, <TAB>  <TAB>  <TAB> processed=processed, <TAB>  <TAB>  <TAB> depth=depth + 1, <TAB>  <TAB> ) <TAB> return rule_links",if rule_link . _dest_action_ref in processed :,185
"def _mock_manager_nfx(self, *args, **kwargs): <TAB> if args: <TAB>  <TAB> if args[0].tag == ""command"": <TAB>  <TAB>  <TAB> raise RpcError() <MASK> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self._read_file(""sw_info_nfx_"" + args[0].tag + "".xml"")","elif args [ 0 ] . tag == ""get-software-information"" and args [ 0 ] . find ( ""./*"" ) is None :",112
"def test_url_invalid_set(): <TAB> for line in URL_INVALID_TESTS.split(""\n""): <TAB>  <TAB> # strip line, skip over empty lines <TAB>  <TAB> line = line.strip() <MASK> continue <TAB>  <TAB> # skip over comments <TAB>  <TAB> match = COMMENT.match(line) <TAB>  <TAB> if match: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> mbox = address.parse(line, strict=True) <TAB>  <TAB> assert_equal(mbox, None)","if line == """" :",115
"def _monitor_thread_function(main_process_pid): <TAB> while True: <TAB>  <TAB> logger.debug(""Monitor thread monitoring pid: %d"", main_process_pid) <TAB>  <TAB> main_process_alive = any( <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB> process.pid <TAB>  <TAB>  <TAB>  <TAB> for process in process_iter() <TAB>  <TAB>  <TAB>  <TAB> if process.pid == main_process_pid <TAB>  <TAB>  <TAB> ] <TAB>  <TAB> ) <MASK> logger.debug( <TAB>  <TAB>  <TAB>  <TAB> ""Main process with pid %d is dead. Killing worker"", main_process_pid <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> os._exit(0) <TAB>  <TAB> sleep(1)",if not main_process_alive :,166
"def OnInsertCells(self, event=None): <TAB> # TODO remove below workaround for double actions <TAB> if self._counter == 1: <MASK> self._counter = 0 <TAB>  <TAB>  <TAB> self._icells = None <TAB>  <TAB>  <TAB> return <TAB> else: <TAB>  <TAB> self._counter = 1 <TAB> self._icells = (self.selection.topleft, self.selection.bottomright) <TAB> self._execute(InsertCells(self.selection.topleft, self.selection.bottomright)) <TAB> self._resize_grid() <TAB> self._skip_except_on_mac(event)","if self . _icells == ( self . selection . topleft , self . selection . bottomright ) :",158
"def get_scripts(): <TAB> """"""Get custom npm scripts."""""" <TAB> proc = Popen([""npm"", ""run-script""], stdout=PIPE) <TAB> should_yeild = False <TAB> for line in proc.stdout.readlines(): <TAB>  <TAB> line = line.decode() <TAB>  <TAB> if ""available via `npm run-script`:"" in line: <TAB>  <TAB>  <TAB> should_yeild = True <TAB>  <TAB>  <TAB> continue <MASK> yield line.strip().split("" "")[0]","if should_yeild and re . match ( r""^  [^ ]+"" , line ) :",129
"def get_netloc(url): <TAB> """"""Get Domain."""""" <TAB> try: <TAB>  <TAB> domain = """" <TAB>  <TAB> parse_uri = urlparse(url) <TAB>  <TAB> if not parse_uri.scheme: <TAB>  <TAB>  <TAB> url = ""//"" + url <TAB>  <TAB>  <TAB> parse_uri = urlparse(url) <TAB>  <TAB> domain = ""{uri.netloc}"".format(uri=parse_uri) <MASK> return domain <TAB> except Exception: <TAB>  <TAB> logger.exception(""[ERROR] Extracting Domain form URL"")",if verify_domain ( domain ) :,121
"def initiate_all_local_variables_instances( <TAB> nodes, local_variables_instances, all_local_variables_instances): <TAB> for node in nodes: <TAB>  <TAB> if node.variable_declaration: <TAB>  <TAB>  <TAB> new_var = LocalIRVariable(node.variable_declaration) <MASK> new_var.index = all_local_variables_instances[new_var.name].index + 1 <TAB>  <TAB>  <TAB> local_variables_instances[node.variable_declaration.name] = new_var <TAB>  <TAB>  <TAB> all_local_variables_instances[node.variable_declaration.name] = new_var",if new_var . name in all_local_variables_instances :,158
"def _disconnect(self, sync): <TAB> if self._connection: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> self._connection.send_all() <TAB>  <TAB>  <TAB>  <TAB> self._connection.fetch_all() <TAB>  <TAB>  <TAB> except (WorkspaceError, ServiceUnavailable): <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> if self._connection: <TAB>  <TAB>  <TAB> self._connection.in_use = False <TAB>  <TAB>  <TAB> self._connection = None <TAB>  <TAB> self._connection_access_mode = None",if sync :,115
"def init(self): <TAB> """"""Initialize a booster from the database and validate"""""" <TAB> self.__item = None <TAB> if self.itemID: <TAB>  <TAB> self.__item = eos.db.getItem(self.itemID) <MASK> pyfalog.error(""Item (id: {0}) does not exist"", self.itemID) <TAB>  <TAB>  <TAB> return <TAB> if self.isInvalid: <TAB>  <TAB> pyfalog.error(""Item (id: {0}) is not a Booster"", self.itemID) <TAB>  <TAB> return <TAB> self.build()",if self . __item is None :,137
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_app_id(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 16: <TAB>  <TAB>  <TAB> self.set_limit(d.getVarInt64()) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,122
"def _match_greater_than_or_equal(search_base, attribute, value, candidates): <TAB> matches = list() <TAB> for entry in candidates: <TAB>  <TAB> dn = entry.get(""dn"") <TAB>  <TAB> if not dn.endswith(search_base): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> value_from_directory = entry.get(""attributes"").get(attribute) <MASK> entry[""type""] = ""searchResEntry"" <TAB>  <TAB>  <TAB> matches.append(entry) <TAB> return matches",if str ( value_from_directory ) >= str ( value ) :,129
"def list_target_unit_files(self, *modules):  # -> [ (unit,enabled) ] <TAB> """"""show all the target units and the enabled status"""""" <TAB> result = {} <TAB> enabled = {} <TAB> for unit in _all_common_targets: <TAB>  <TAB> result[unit] = None <TAB>  <TAB> enabled[unit] = ""static"" <MASK> enabled[unit] = ""enabled"" <TAB>  <TAB> if unit in _all_common_disabled: <TAB>  <TAB>  <TAB> enabled[unit] = ""enabled"" <TAB> return [(unit, enabled[unit]) for unit in sorted(result)]",if unit in _all_common_enabled :,147
"def handle_data(self, data): <TAB> if self.in_span or self.in_div: <MASK> self.no_user = True <TAB>  <TAB> elif data == ""Invalid password"": <TAB>  <TAB>  <TAB> self.bad_pw = True <TAB>  <TAB> elif data == ""User with that email already exists"": <TAB>  <TAB>  <TAB> self.already_exists = True","if data == ""No such user (please note that login is case sensitive)"" :",101
"def walk_tree( <TAB> root: Element, <TAB> processor: Callable[[Element], Optional[_T]], <TAB> stop_after_first: bool = False,) -> List[_T]: <TAB> results = [] <TAB> queue = deque([root]) <TAB> while queue: <TAB>  <TAB> currElement = queue.popleft() <TAB>  <TAB> for child in currElement: <MASK> queue.append(child) <TAB>  <TAB>  <TAB> result = processor(child) <TAB>  <TAB>  <TAB> if result is not None: <TAB>  <TAB>  <TAB>  <TAB> results.append(result) <TAB>  <TAB>  <TAB>  <TAB> if stop_after_first: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return results <TAB> return results",if child :,152
"def characters(self, ch): <TAB> if self._inside_fuzzable: <TAB>  <TAB> modified_value = self._fuzzed_parameters[self._fuzzable_index][1] <TAB>  <TAB> if isinstance(modified_value, DataToken): <TAB>  <TAB>  <TAB> modified_value = modified_value.get_value() <MASK> enc_val = base64.b64encode(modified_value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> enc_val = cgi.escape(modified_value).encode(""ascii"", ""xmlcharrefreplace"") <TAB>  <TAB> self.fuzzed_xml_string += enc_val <TAB> else: <TAB>  <TAB> self.fuzzed_xml_string += ch","if self . _fuzzed_parameters [ self . _fuzzable_index ] [ 0 ] == ""base64"" :",181
"def when_the_task_has_started(context): <TAB> # 120 * 0.5 = 60 seconds <TAB> for _ in range(120): <TAB>  <TAB> app = context.marathon_clients.current[0].get_app(APP_ID) <TAB>  <TAB> happy_count = app.tasks_running <MASK> return <TAB>  <TAB> time.sleep(0.5) <TAB> raise Exception(""timed out waiting for task to start"")",if happy_count >= 3 :,111
"def _sock_send(self, msg): <TAB> try: <TAB>  <TAB> if isinstance(msg, str): <TAB>  <TAB>  <TAB> msg = msg.encode(""ascii"") <TAB>  <TAB> # http://docs.datadoghq.com/guides/dogstatsd/#datagram-format <MASK> msg = msg + b""|#"" + self.dogstatsd_tags.encode(""ascii"") <TAB>  <TAB> if self.sock: <TAB>  <TAB>  <TAB> self.sock.send(msg) <TAB> except Exception: <TAB>  <TAB> Logger.warning(self, ""Error sending message to statsd"", exc_info=True)",if self . dogstatsd_tags :,146
"def __init__( <TAB> self, constraints=None, preferences=None, platforms=None, maxreplicas=None): <TAB> if constraints is not None: <TAB>  <TAB> self[""Constraints""] = constraints <TAB> if preferences is not None: <TAB>  <TAB> self[""Preferences""] = [] <TAB>  <TAB> for pref in preferences: <MASK> pref = PlacementPreference(*pref) <TAB>  <TAB>  <TAB> self[""Preferences""].append(pref) <TAB> if maxreplicas is not None: <TAB>  <TAB> self[""MaxReplicas""] = maxreplicas <TAB> if platforms: <TAB>  <TAB> self[""Platforms""] = [] <TAB>  <TAB> for plat in platforms: <TAB>  <TAB>  <TAB> self[""Platforms""].append({""Architecture"": plat[0], ""OS"": plat[1]})","if isinstance ( pref , tuple ) :",174
def start(self): <TAB> if not self._active: <TAB>  <TAB> self._active = True <MASK> self.exit = threading.Event() <TAB>  <TAB>  <TAB> self.thread = threading.Thread(target=self.check) <TAB>  <TAB>  <TAB> self.thread.daemon = True <TAB>  <TAB>  <TAB> self.thread.start(),if self . thread is None :,83
"def on_player_state_changed(self, state): <TAB> if state == State.playing: <TAB>  <TAB> self._toggle_player_action.setText(TOGGLE_PLAYER_TEXT[1]) <TAB>  <TAB> self._toggle_player_action.setIcon(QIcon.fromTheme(""media-pause"")) <TAB>  <TAB> self._toggle_player_action.setEnabled(True) <TAB> else: <TAB>  <TAB> self._toggle_player_action.setText(TOGGLE_PLAYER_TEXT[0]) <TAB>  <TAB> self._toggle_player_action.setIcon(QIcon.fromTheme(""media-play"")) <MASK> self._toggle_player_action.setEnabled(False) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._toggle_player_action.setEnabled(True)",if state == State . stopped :,181
"def __init__(self, el): <TAB> self.elements = list(el) <TAB> parameters = {} <TAB> tokens = [] <TAB> token_quote = ""@"" <TAB> for key, value in el.attrib.items(): <TAB>  <TAB> if key == ""token_quote"": <TAB>  <TAB>  <TAB> token_quote = value <TAB>  <TAB> if key == ""tokens"": <TAB>  <TAB>  <TAB> for token in value.split("",""): <TAB>  <TAB>  <TAB>  <TAB> tokens.append((token, REQUIRED_PARAMETER)) <MASK> token = key[len(""token_"") :] <TAB>  <TAB>  <TAB> tokens.append((token, value)) <TAB> for name, default in tokens: <TAB>  <TAB> parameters[name] = (token_quote, default) <TAB> self.parameters = parameters","elif key . startswith ( ""token_"" ) :",170
"def create(self): <TAB> if self.mode == ""INDICES"": <TAB>  <TAB> self.newInput(""Integer List"", ""Indices"", ""indices"") <TAB>  <TAB> self.newOutput(""Polygon Indices"", ""Polygon Indices"", ""polygonIndices"") <TAB> elif self.mode == ""VERTEX_AMOUNT"": <MASK> self.newInput(""Integer List"", ""Vertex Amounts"", ""vertexAmounts"") <TAB>  <TAB>  <TAB> self.newOutput( <TAB>  <TAB>  <TAB>  <TAB> ""Polygon Indices List"", ""Polygon Indices List"", ""polygonIndicesList"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.newInput( <TAB>  <TAB>  <TAB>  <TAB> ""Integer"", ""Vertex Amount"", ""vertexAmount"", value=3, minValue=3 <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.newOutput(""Polygon Indices"", ""Polygon Indices"", ""polygonIndices"")",if self . useList :,199
"def _chroot_pids(chroot): <TAB> pids = [] <TAB> for root in glob.glob(""/proc/[0-9]*/root""): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> link = os.path.realpath(root) <MASK> pids.append(int(os.path.basename(os.path.dirname(root)))) <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> pass <TAB> return pids",if link . startswith ( chroot ) :,106
"def to_word_end(view, s): <TAB> if mode == modes.NORMAL: <TAB>  <TAB> pt = word_end_reverse(view, s.b, count) <TAB>  <TAB> return sublime.Region(pt) <TAB> elif mode in (modes.VISUAL, modes.VISUAL_BLOCK): <TAB>  <TAB> if s.a < s.b: <TAB>  <TAB>  <TAB> pt = word_end_reverse(view, s.b - 1, count) <MASK> return sublime.Region(s.a, pt + 1) <TAB>  <TAB>  <TAB> return sublime.Region(s.a + 1, pt) <TAB>  <TAB> pt = word_end_reverse(view, s.b, count) <TAB>  <TAB> return sublime.Region(s.a, pt) <TAB> return s",if pt > s . a :,191
"def torch_sparse_Tensor(coords, feats, size=None): <TAB> if size is None: <MASK> return torch.sparse.DoubleTensor(coords, feats) <TAB>  <TAB> elif feats.dtype == torch.float32: <TAB>  <TAB>  <TAB> return torch.sparse.FloatTensor(coords, feats) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""Feature type not supported."") <TAB> else: <TAB>  <TAB> if feats.dtype == torch.float64: <TAB>  <TAB>  <TAB> return torch.sparse.DoubleTensor(coords, feats, size) <TAB>  <TAB> elif feats.dtype == torch.float32: <TAB>  <TAB>  <TAB> return torch.sparse.FloatTensor(coords, feats, size) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""Feature type not supported."")",if feats . dtype == torch . float64 :,179
"def detab(self, text): <TAB> """"""Remove a tab from the front of each line of the given text."""""" <TAB> newtext = [] <TAB> lines = text.split(""\n"") <TAB> for line in lines: <TAB>  <TAB> if line.startswith("" "" * markdown.TAB_LENGTH): <TAB>  <TAB>  <TAB> newtext.append(line[markdown.TAB_LENGTH :]) <MASK> newtext.append("""") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> return ""\n"".join(newtext), ""\n"".join(lines[len(newtext) :])",elif not line . strip ( ) :,134
"def iter_input(input, filename, parser, line_by_line): <TAB> if isinstance(input, basestring): <TAB>  <TAB> with open(input, ""rb"") as f: <TAB>  <TAB>  <TAB> for tree in iter_input(f, filename, parser, line_by_line): <TAB>  <TAB>  <TAB>  <TAB> yield tree <TAB> else: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if line_by_line: <TAB>  <TAB>  <TAB>  <TAB> for line in input: <MASK> yield et.ElementTree(et.fromstring(line, parser)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield et.parse(input, parser) <TAB>  <TAB> except IOError: <TAB>  <TAB>  <TAB> e = sys.exc_info()[1] <TAB>  <TAB>  <TAB> error(""parsing %r failed: %s: %s"", filename, e.__class__.__name__, e)",if line :,197
"def find_xsubpp(): <TAB> for var in (""privlib"", ""vendorlib""): <TAB>  <TAB> xsubpp = cfg_lst(""$Config{%s}/ExtUtils/xsubpp$Config{exe_ext}"" % var) <MASK> return xsubpp <TAB> return self.find_program(""xsubpp"")",if xsubpp and os . path . isfile ( xsubpp [ 0 ] ) :,93
"def apply_list(self, expr, rules, evaluation): <TAB> ""ReplaceRepeated[expr_, rules_]"" <TAB> try: <TAB>  <TAB> rules, ret = create_rules(rules, expr, ""ReplaceRepeated"", evaluation) <TAB> except PatternError: <TAB>  <TAB> evaluation.message(""Replace"", ""reps"", rules) <TAB>  <TAB> return None <TAB> if ret: <TAB>  <TAB> return rules <TAB> while True: <TAB>  <TAB> evaluation.check_stopped() <TAB>  <TAB> result, applied = expr.apply_rules(rules, evaluation) <MASK> result = result.evaluate(evaluation) <TAB>  <TAB> if applied and not result.same(expr): <TAB>  <TAB>  <TAB> expr = result <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> return result",if applied :,166
"def __init__( <TAB> self, <TAB> lambda_val: Optional[Union[torch.Tensor, Tuple[float, float]]] = None, <TAB> same_on_batch: bool = False, <TAB> p: float = 1.0,) -> None: <TAB> super(RandomMixUp, self).__init__(p=1.0, p_batch=p, same_on_batch=same_on_batch) <TAB> if lambda_val is None: <TAB>  <TAB> self.lambda_val = torch.tensor([0, 1.0]) <TAB> else: <TAB>  <TAB> self.lambda_val = ( <TAB>  <TAB>  <TAB> cast(torch.Tensor, lambda_val) <MASK> else torch.tensor(lambda_val) <TAB>  <TAB> )","if isinstance ( lambda_val , torch . Tensor )",182
"def run_sync(self): <TAB> count = 0 <TAB> while count < self.args.num_messages: <TAB>  <TAB> batch = self.receiver.receive_messages( <TAB>  <TAB>  <TAB> max_message_count=self.args.num_messages - count, <TAB>  <TAB>  <TAB> max_wait_time=self.args.max_wait_time or None, <TAB>  <TAB> ) <MASK> for msg in batch: <TAB>  <TAB>  <TAB>  <TAB> self.receiver.complete_message(msg) <TAB>  <TAB> count += len(batch)",if self . args . peeklock :,129
"def ns_to_timespec(self, nsec): <TAB> """"""Transforms nanoseconds to a timespec."""""" <TAB> # http://elixir.free-electrons.com/linux/v4.13.5/source/kernel/time/time.c#L486 <TAB> ts = self.timespec() <TAB> if not nsec: <TAB>  <TAB> ts.tv_sec = 0 <TAB>  <TAB> ts.tv_nsec = 0 <TAB> else: <TAB>  <TAB> ts.tv_sec, rem = divmod(nsec, timespec.NSEC_PER_SEC) <MASK> ts.tv_sec -= 1 <TAB>  <TAB>  <TAB> rem += timespec.NSEC_PER_SEC <TAB>  <TAB> ts.tv_nsec = rem <TAB> return ts",if rem < 0 :,178
"def fixFunctionDocTag(funcnode): <TAB> doctext = funcnode.get(""doc"") <TAB> if doctext: <TAB>  <TAB> if funcnode.attrib[""name""] == ""eval"": <TAB>  <TAB>  <TAB> # Update the doc for this function call, more user friendly. <TAB>  <TAB>  <TAB> funcnode.attrib[""doc""] = doctext.replace(""ECMAScript"", ""JavaScript"") <TAB>  <TAB> sp = doctext.rsplit(""Return Type: "", 1) <MASK> funcnode.attrib[""doc""] = sp[0].rstrip() <TAB>  <TAB>  <TAB> returnType = standardizeJSType(sp[1].split(None, 1)[0]) <TAB>  <TAB>  <TAB> addCixReturns(funcnode, returnType) <TAB>  <TAB>  <TAB> return returnType <TAB> return None",if len ( sp ) == 2 :,177
"def check_engine(engine): <TAB> if engine == ""auto"": <MASK> return ""pyarrow"" <TAB>  <TAB> elif fastparquet is not None:  # pragma: no cover <TAB>  <TAB>  <TAB> return ""fastparquet"" <TAB>  <TAB> else:  # pragma: no cover <TAB>  <TAB>  <TAB> raise RuntimeError(""Please install either pyarrow or fastparquet."") <TAB> elif engine == ""pyarrow"": <TAB>  <TAB> if pa is None:  # pragma: no cover <TAB>  <TAB>  <TAB> raise RuntimeError(""Please install pyarrow fisrt."") <TAB>  <TAB> return engine <TAB> elif engine == ""fastparquet"": <TAB>  <TAB> if fastparquet is None:  # pragma: no cover <TAB>  <TAB>  <TAB> raise RuntimeError(""Please install fastparquet first."") <TAB>  <TAB> return engine <TAB> else:  # pragma: no cover <TAB>  <TAB> raise RuntimeError(""Unsupported engine {} to read parquet."".format(engine))",if pa is not None :,187
"def addInt(self, intval, width, nodeinfo): <TAB> node = self.basenode <TAB> for sh in range(width - 1, -1, -1): <TAB>  <TAB> choice = (intval >> sh) & 1 <MASK> node[choice] = [None, None, None] <TAB>  <TAB> node = node[choice] <TAB> node[2] = nodeinfo",if node [ choice ] is None :,98
"def add_cand(cands): <TAB> cands = [cand.creator for cand in cands if cand.creator is not None] <TAB> for x in cands: <TAB>  <TAB> if x in seen_set: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> order = 1 <MASK> order = -len(seen_set) <TAB>  <TAB> # Negate since heapq is min-heap <TAB>  <TAB> # `len(seen_set)` is in order to avoid comparing `x` <TAB>  <TAB> heapq.heappush(cand_funcs, (order, -x.rank, -len(seen_set), x)) <TAB>  <TAB> seen_set.add(x)",if fan_out [ x ] == 1 and len ( cands ) == 1 :,167
"def indentSelection(self, howFar=4): <TAB> # Indent or outdent current selection by 'howFar' spaces <TAB> # (which could be positive or negative int). <TAB> startLineNum = self.LineFromPosition(self.GetSelectionStart()) <TAB> endLineNum = self.LineFromPosition(self.GetSelectionEnd()) <TAB> # go through line-by-line <TAB> self.BeginUndoAction() <TAB> for lineN in range(startLineNum, endLineNum + 1): <TAB>  <TAB> newIndent = self.GetLineIndentation(lineN) + howFar <MASK> newIndent = 0 <TAB>  <TAB> self.SetLineIndentation(lineN, newIndent) <TAB> self.EndUndoAction()",if newIndent < 0 :,179
"def request(self, host, handler, request_body, verbose=False): <TAB> # retry request once if cached connection has gone cold <TAB> for i in (0, 1): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self.single_request(host, handler, request_body, verbose) <TAB>  <TAB> except socket.error as e: <MASK> raise <TAB>  <TAB> except http_client.BadStatusLine:  # close after we sent request <TAB>  <TAB>  <TAB> if i: <TAB>  <TAB>  <TAB>  <TAB> raise","if i or e . errno not in ( errno . ECONNRESET , errno . ECONNABORTED , errno . EPIPE ) :",147
"def update_data(self, change): <TAB> self.mark.x = self.state.x_centers <TAB> y0 = self.state.grid <MASK> y0 = y0 / np.sum(y0) <TAB> if self.state.grid_sliced is not None: <TAB>  <TAB> y1 = self.state.grid_sliced <TAB>  <TAB> if self.normalize: <TAB>  <TAB>  <TAB> y1 = y1 / np.sum(y1) <TAB>  <TAB> self.mark.y = np.array([y0, y1]) <TAB>  <TAB> self.mark.colors = [C0, C1] <TAB>  <TAB> self.mark.type = ""grouped"" <TAB> else: <TAB>  <TAB> self.mark.y = y0 <TAB>  <TAB> self.mark.colors = [C0]",if self . normalize :,185
"def visit_body(self, nodes): <TAB> new_nodes = [] <TAB> count = 0 <TAB> for node in nodes: <TAB>  <TAB> rewriter = IfExpRewriter(count) <TAB>  <TAB> possibly_transformed_node = rewriter.visit(node) <MASK> new_nodes.extend(rewriter.assignments) <TAB>  <TAB>  <TAB> count += len(rewriter.assignments) <TAB>  <TAB> new_nodes.append(possibly_transformed_node) <TAB> return new_nodes",if rewriter . assignments :,110
"def byteRegOffset(self, val, prefixes=0): <TAB> # NOTE: Override this because there is no AH etc in 64 bit mode <TAB> if prefixes & PREFIX_REX:  # the parse_modrm function deals with register index adds <TAB>  <TAB> val |= e_i386.RMETA_LOW8 <TAB> else:  # not using REX, revert to old split-registers (low/high) <MASK> val |= e_i386.RMETA_LOW8 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> val |= e_i386.RMETA_HIGH8 <TAB>  <TAB>  <TAB> val -= 4 <TAB> return val",if val < 4 :,148
"def gprv_immv(ii): <TAB> for i, op in enumerate(_gen_opnds(ii)): <MASK> if op.name == ""REG0"" and op_luf_start(op, ""GPRv""): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> elif i == 1: <TAB>  <TAB>  <TAB> if op_immv(op): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> return True",if i == 0 :,136
"def normalize(self): <TAB> self.pairs.sort() <TAB> i = 1 <TAB> while i < len(self.pairs): <TAB>  <TAB> alo, ahi = self.pairs[i - 1] <TAB>  <TAB> blo, bhi = self.pairs[i] <MASK> self.pairs[i - 1 : i + 1] = [(alo, max(ahi, bhi))] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> i = i + 1",if ahi >= blo - 1 :,115
"def __substitute_composite_key(self, key, composite_file, dataset=None): <TAB> if composite_file.substitute_name_with_metadata: <MASK> meta_value = str( <TAB>  <TAB>  <TAB>  <TAB> dataset.metadata.get(composite_file.substitute_name_with_metadata) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> meta_value = self.spec[composite_file.substitute_name_with_metadata].default <TAB>  <TAB> return key % meta_value <TAB> return key",if dataset :,123
"def cb(definition): <TAB> if len(definition.strip()) == 0: <MASK> dialog = wx.MessageDialog( <TAB>  <TAB>  <TAB>  <TAB> self, <TAB>  <TAB>  <TAB>  <TAB> _(""Do you want to erase the macro?""), <TAB>  <TAB>  <TAB>  <TAB> style=wx.YES_NO | wx.YES_DEFAULT | wx.ICON_QUESTION, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> if dialog.ShowModal() == wx.ID_YES: <TAB>  <TAB>  <TAB>  <TAB> self.delete_macro(macro_name) <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> self.log(_(""Cancelled."")) <TAB>  <TAB> return <TAB> self.cur_macro_name = macro_name <TAB> self.cur_macro_def = definition <TAB> self.end_macro()","if old_macro_definition != """" :",176
"def process_request(self, request): <TAB> for old, new in self.names_name: <TAB>  <TAB> request.uri = request.uri.replace(old, new) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> body = ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> str(request.body, ""utf-8"") <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if isinstance(request.body, bytes) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> else str(request.body) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> except TypeError:  # python 2 doesn't allow decoding through str <TAB>  <TAB>  <TAB>  <TAB> body = str(request.body) <TAB>  <TAB>  <TAB> if old in body: <TAB>  <TAB>  <TAB>  <TAB> request.body = body.replace(old, new) <TAB> return request",if is_text_payload ( request ) and request . body :,182
"def writeLibraryControllers(fp, human, meshes, skel, config, shapes=None): <TAB> progress = Progress(len(meshes), None) <TAB> fp.write(""\n  <library_controllers>\n"") <TAB> for mIdx, mesh in enumerate(meshes): <TAB>  <TAB> subprog = Progress()(0, 0.5) <MASK> writeSkinController(fp, human, mesh, skel, config) <TAB>  <TAB> subprog(0.5, 1) <TAB>  <TAB> if shapes is not None: <TAB>  <TAB>  <TAB> writeMorphController(fp, mesh, shapes[mIdx], config) <TAB>  <TAB> progress.step() <TAB> fp.write(""  </library_controllers>\n"")",if skel :,172
def checkpoint(): <TAB> if checkpoint_asserts: <TAB>  <TAB> self.assert_integrity_idxs_take() <MASK> toposort(self.idxs_memo[node]) <TAB>  <TAB> if node in self.take_memo: <TAB>  <TAB>  <TAB> for take in self.take_memo[node]: <TAB>  <TAB>  <TAB>  <TAB> toposort(take),if node in self . idxs_memo :,86
"def __virtual__():  # pylint: disable=expected-2-blank-lines-found-0 <TAB> try: <TAB>  <TAB> global __salt__  # pylint: disable=global-statement <MASK> __salt__ = salt.loader.minion_mods(__opts__) <TAB>  <TAB>  <TAB> return True <TAB> except Exception as e:  # pylint: disable=broad-except <TAB>  <TAB> log.error(""Could not load __salt__: %s"", e) <TAB>  <TAB> return False",if not __salt__ :,118
"def annotate_disk_for_smart(middleware, devices, disk): <TAB> args = await get_smartctl_args(middleware, devices, disk) <TAB> if args: <MASK> args.extend([""-a""]) <TAB>  <TAB>  <TAB> args.extend([""-d"", ""removable""]) <TAB>  <TAB>  <TAB> return disk, dict(smartctl_args=args)",if await ensure_smart_enabled ( args ) :,93
"def make_connection(self, host): <TAB> h, eh, kwargs = self.get_host_info(host) <TAB> if not kwargs: <TAB>  <TAB> kwargs = {} <TAB> kwargs[""timeout""] = self.timeout <TAB> if _ver_info == (2, 6): <TAB>  <TAB> result = HTTPS(host, None, **kwargs) <TAB> else: <MASK> self._extra_headers = eh <TAB>  <TAB>  <TAB> self._connection = host, httplib.HTTPSConnection(h, None, **kwargs) <TAB>  <TAB> result = self._connection[1] <TAB> return result",if not self . _connection or host != self . _connection [ 0 ] :,149
"def get_base_types(self, cdef: ClassDef) -> List[str]: <TAB> """"""Get list of base classes for a class."""""" <TAB> base_types = []  # type: List[str] <TAB> for base in cdef.base_type_exprs: <TAB>  <TAB> if isinstance(base, NameExpr): <TAB>  <TAB>  <TAB> if base.name != ""object"": <TAB>  <TAB>  <TAB>  <TAB> base_types.append(base.name) <MASK> modname = get_qualified_name(base.expr) <TAB>  <TAB>  <TAB> base_types.append(""%s.%s"" % (modname, base.name)) <TAB>  <TAB> elif isinstance(base, IndexExpr): <TAB>  <TAB>  <TAB> p = AliasPrinter(self) <TAB>  <TAB>  <TAB> base_types.append(base.accept(p)) <TAB> return base_types","elif isinstance ( base , MemberExpr ) :",187
"def add_entry(self, entry): <TAB> # type: (...) -> None <TAB> version = entry.as_python  # type: PythonVersion <TAB> if version: <TAB>  <TAB> _ = self.versions[version.version_tuple] <TAB>  <TAB> paths = {p.path for p in self.versions.get(version.version_tuple, [])} <MASK> self.versions[version.version_tuple].append(entry)",if entry . path not in paths :,108
"def check(self): <TAB> global MySQLdb <TAB> import MySQLdb <TAB> try: <TAB>  <TAB> args = {} <TAB>  <TAB> if mysql_user: <TAB>  <TAB>  <TAB> args[""user""] = mysql_user <TAB>  <TAB> if mysql_pwd: <TAB>  <TAB>  <TAB> args[""passwd""] = mysql_pwd <TAB>  <TAB> if mysql_host: <TAB>  <TAB>  <TAB> args[""host""] = mysql_host <TAB>  <TAB> if mysql_port: <TAB>  <TAB>  <TAB> args[""port""] = mysql_port <MASK> args[""unix_socket""] = mysql_socket <TAB>  <TAB> self.db = MySQLdb.connect(**args) <TAB> except Exception as e: <TAB>  <TAB> raise Exception(""Cannot interface with MySQL server: %s"" % e)",if mysql_socket :,167
"def findsection(self, key): <TAB> to_return = copy.deepcopy(self) <TAB> for subsection in to_return: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> value = list(ConfigObj.find_key(to_return[subsection], key))[0] <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> value = None <TAB>  <TAB> if not value: <TAB>  <TAB>  <TAB> del to_return[subsection] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for category in to_return[subsection]: <MASK> del to_return[subsection][category] <TAB> # cleanout empty sections and subsections <TAB> for key in [k for (k, v) in to_return.items() if not v]: <TAB>  <TAB> del to_return[key] <TAB> return to_return",if category != key :,189
"def get_ready_conn(self, host): <TAB> conn = None <TAB> self._lock.acquire() <TAB> try: <MASK> for c in self._hostmap[host]: <TAB>  <TAB>  <TAB>  <TAB> if self._readymap[c]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._readymap[c] = 0 <TAB>  <TAB>  <TAB>  <TAB>  <TAB> conn = c <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB> finally: <TAB>  <TAB> self._lock.release() <TAB> return conn",if host in self . _hostmap :,115
"def assign_set_scope( <TAB> ir_set: irast.Set, <TAB> scope: Optional[irast.ScopeTreeNode], <TAB> *, <TAB> ctx: context.ContextLevel) -> irast.Set: <TAB> if scope is None: <TAB>  <TAB> ir_set.path_scope_id = None <TAB> else: <MASK> scope.unique_id = ctx.scope_id_ctr.nextval() <TAB>  <TAB> ir_set.path_scope_id = scope.unique_id <TAB>  <TAB> if scope.find_child(ir_set.path_id): <TAB>  <TAB>  <TAB> raise RuntimeError(""scoped set must not contain itself"") <TAB> return ir_set",if scope . unique_id is None :,166
"def _flatten(*args): <TAB> arglist = [] <TAB> for arg in args: <TAB>  <TAB> if isinstance(arg, _Block): <TAB>  <TAB>  <TAB> if arg.vhdl_code is not None: <TAB>  <TAB>  <TAB>  <TAB> arglist.append(arg.vhdl_code) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> arg = arg.subs <MASK> arglist.append(_userCodeMap[""vhdl""][id(arg)]) <TAB>  <TAB> elif isinstance(arg, (list, tuple, set)): <TAB>  <TAB>  <TAB> for item in arg: <TAB>  <TAB>  <TAB>  <TAB> arglist.extend(_flatten(item)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> arglist.append(arg) <TAB> return arglist","if id ( arg ) in _userCodeMap [ ""vhdl"" ] :",179
"def _prepare_expected(data, lags, trim=""front""): <TAB> t, k = data.shape <TAB> expected = np.zeros((t + lags, (lags + 1) * k)) <TAB> for col in range(k): <TAB>  <TAB> for i in range(lags + 1): <MASK> expected[i : -lags + i, (lags + 1) * col + i] = data[:, col] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> expected[i:, (lags + 1) * col + i] = data[:, col] <TAB> if trim == ""front"": <TAB>  <TAB> expected = expected[:-lags] <TAB> return expected",if i < lags :,163
"def test_class_based_views_inherit_from_acl_gateway_class(self): <TAB> for urlpattern in self.urlpatterns_to_test: <TAB>  <TAB> callback_name = urlpattern.callback.__name__ <TAB>  <TAB> module_name = urlpattern.callback.__module__ <TAB>  <TAB> if (callback_name, module_name) in self.excluded_callbacks: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> imported_module = __import__(module_name, fromlist=[callback_name]) <TAB>  <TAB> found_callback = getattr(imported_module, callback_name) <MASK> continue <TAB>  <TAB> msg = ""Class '{}' does not inherit from 'ACLGateway' "" ""class."".format( <TAB>  <TAB>  <TAB> found_callback <TAB>  <TAB> ) <TAB>  <TAB> self.assertTrue(issubclass(found_callback, ACLGateway), msg)",if not inspect . isclass ( found_callback ) :,195
"def generateMapItemTypedNode(self, key, value): <TAB> if type(value) == SigmaRegularExpressionModifier: <TAB>  <TAB> regex = str(value) <TAB>  <TAB> # Regular Expressions have to match the full value in QRadar <MASK> regex = "".*"" + regex <TAB>  <TAB> if not (regex.endswith(""$"") or regex.endswith("".*"")): <TAB>  <TAB>  <TAB> regex = regex + "".*"" <TAB>  <TAB> return ""%s MATCHES %s"" % (self.cleanKey(key), self.generateValueNode(regex)) <TAB> else: <TAB>  <TAB> raise NotImplementedError( <TAB>  <TAB>  <TAB> ""Type modifier '{}' is not supported by backend"".format(value.identifier) <TAB>  <TAB> )","if not ( regex . startswith ( ""^"" ) or regex . startswith ( "".*"" ) ) :",165
"def __str__(self): <TAB> _outicalfile = self._icalfile <TAB> for unit in self.units: <TAB>  <TAB> for location in unit.getlocations(): <TAB>  <TAB>  <TAB> match = re.match(""\\[(?P<uid>.+)\\](?P<property>.+)"", location) <TAB>  <TAB>  <TAB> for component in self._icalfile.components(): <TAB>  <TAB>  <TAB>  <TAB> if component.name != ""VEVENT"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB>  <TAB>  <TAB> for property in component.getChildren(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if property.name == match.groupdict()[""property""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> property.value = unit.target <TAB> if _outicalfile: <TAB>  <TAB> return str(_outicalfile.serialize()) <TAB> else: <TAB>  <TAB> return """"","if component . uid . value != match . groupdict ( ) [ ""uid"" ] :",198
"def __init__(self, items): <TAB> self._format = string.join(map(lambda item: item[0], items), """") <TAB> self._items = items <TAB> self._buffer_ = win32wnet.NCBBuffer(struct.calcsize(self._format)) <TAB> for format, name in self._items: <MASK> if format == ""c"": <TAB>  <TAB>  <TAB>  <TAB> val = ""\0"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> val = 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> l = int(format[:-1]) <TAB>  <TAB>  <TAB> val = ""\0"" * l <TAB>  <TAB> self.__dict__[name] = val",if len ( format ) == 1 :,158
"def __init__(self, learners, names=None): <TAB> self.learners = learners <TAB> for i, learner in enumerate(learners): <TAB>  <TAB> self.update_set_reward(learner) <TAB>  <TAB> learner.accumulated_rewards = [] <TAB>  <TAB> learner.known_states = [] <TAB>  <TAB> learner.temperatures = [] <MASK> learner.name = ""Learner %d"" % i <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> learner.name = names[i]",if names is None :,120
"def __init__(self, *args, **kwargs): <TAB> self.default_currency = kwargs.pop(""default_currency"", None) <TAB> super().__init__(*args, **kwargs) <TAB> # Rest Framework converts `min_value` / `max_value` to validators, that are not aware about `Money` class <TAB> # We need to adjust them <TAB> for idx, validator in enumerate(self.validators): <MASK> self.validators[idx] = MinMoneyValidator(self.min_value) <TAB>  <TAB> elif isinstance(validator, MaxValueValidator): <TAB>  <TAB>  <TAB> self.validators[idx] = MaxMoneyValidator(self.max_value)","if isinstance ( validator , MinValueValidator ) :",159
"def add_line_taxes(self, lines): <TAB> for line in lines: <MASK> continue  # Cannot have taxes, since not in source <TAB>  <TAB> for (index, line_tax) in enumerate(line.source_line.taxes, 1): <TAB>  <TAB>  <TAB> line.taxes.create( <TAB>  <TAB>  <TAB>  <TAB> tax=line_tax.tax, <TAB>  <TAB>  <TAB>  <TAB> name=line_tax.name, <TAB>  <TAB>  <TAB>  <TAB> amount_value=line_tax.amount.value, <TAB>  <TAB>  <TAB>  <TAB> base_amount_value=line_tax.base_amount.value, <TAB>  <TAB>  <TAB>  <TAB> ordering=index, <TAB>  <TAB>  <TAB> )",if not line . source_line :,157
"def linesub(match): <TAB> line = match.group() <TAB> for token in TOKEN_RE.findall(line): <TAB>  <TAB> if token in names: <TAB>  <TAB>  <TAB> targets = names[token] <TAB>  <TAB>  <TAB> fdist.inc(token) <MASK> log.warning( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""%s is ambiguous: %s"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> % (token, "", "".join(str(v.canonical_name) for v in names[token])) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> line += INDEXTERM % token <TAB>  <TAB>  <TAB> # line += INDEXTERM % names[token][0].canonical_name <TAB> return line",if len ( targets ) > 1 :,159
"def ask(self) -> Dict[str, Any]: <TAB> params = {} <TAB> param_values = self._optimizer.ask() <TAB> for (name, distribution), value in zip( <TAB>  <TAB> sorted(self._search_space.items()), param_values <TAB> ): <TAB>  <TAB> if isinstance(distribution, distributions.DiscreteUniformDistribution): <TAB>  <TAB>  <TAB> value = value * distribution.q + distribution.low <MASK> value = value * distribution.step + distribution.low <TAB>  <TAB> if isinstance(distribution, distributions.IntLogUniformDistribution): <TAB>  <TAB>  <TAB> value = int(np.round(value)) <TAB>  <TAB>  <TAB> value = min(max(value, distribution.low), distribution.high) <TAB>  <TAB> params[name] = value <TAB> return params","if isinstance ( distribution , distributions . IntUniformDistribution ) :",180
"def fetcher(): <TAB> while True: <TAB>  <TAB> try: <MASK> break <TAB>  <TAB>  <TAB> self.fetch() <TAB>  <TAB>  <TAB> self._cluster.handler.sleep(0.01) <TAB>  <TAB> except ReferenceError: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> # surface all exceptions to the main thread <TAB>  <TAB>  <TAB> self._worker_exception = sys.exc_info() <TAB>  <TAB>  <TAB> break <TAB> try: <TAB>  <TAB> self.cleanup() <TAB> except ReferenceError as e: <TAB>  <TAB> log.debug(""Attempt to cleanup consumer failed with ReferenceError"") <TAB> log.debug(""Fetcher thread exiting"")",if not self . _running :,148
"def write_text(self, text): <TAB> """"""Writes re-indented text into the buffer."""""" <TAB> should_indent = False <TAB> rows = [] <TAB> for row in text.split(""\n""): <TAB>  <TAB> if should_indent: <TAB>  <TAB>  <TAB> row = "" <TAB> {}"".format(row) <MASK> row = row.replace(""\b"", """", 1) <TAB>  <TAB>  <TAB> should_indent = True <TAB>  <TAB> elif not len(row.strip()): <TAB>  <TAB>  <TAB> should_indent = False <TAB>  <TAB> rows.append(row) <TAB> self.write(""{}\n"".format(""\n"".join(rows)))","if ""\b"" in row :",147
"def test_kafka_consumer(self): <TAB> self.send_messages(0, range(0, 100)) <TAB> self.send_messages(1, range(100, 200)) <TAB> # Start a consumer <TAB> consumer = self.kafka_consumer(auto_offset_reset=""earliest"") <TAB> n = 0 <TAB> messages = {0: set(), 1: set()} <TAB> for m in consumer: <TAB>  <TAB> logging.debug(""Consumed message %s"" % repr(m)) <TAB>  <TAB> n += 1 <TAB>  <TAB> messages[m.partition].add(m.offset) <MASK> break <TAB> self.assertEqual(len(messages[0]), 100) <TAB> self.assertEqual(len(messages[1]), 100)",if n >= 200 :,180
"def get_command(scaffolding, command_path): <TAB> path, _, command_name = command_path.rpartition(""."") <TAB> if path not in scaffolding: <TAB>  <TAB> raise KeyError('Ingredient for command ""%s"" not found.' % command_path) <TAB> if command_name in scaffolding[path].commands: <TAB>  <TAB> return scaffolding[path].commands[command_name] <TAB> else: <MASK> raise KeyError( <TAB>  <TAB>  <TAB>  <TAB> 'Command ""%s"" not found in ingredient ""%s""' % (command_name, path) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise KeyError('Command ""%s"" not found' % command_name)",if path :,167
"def build_extension(self, ext): <TAB> ext._convert_pyx_sources_to_lang() <TAB> _compiler = self.compiler <TAB> try: <MASK> self.compiler = self.shlib_compiler <TAB>  <TAB> _build_ext.build_extension(self, ext) <TAB>  <TAB> if ext._needs_stub: <TAB>  <TAB>  <TAB> cmd = self.get_finalized_command(""build_py"").build_lib <TAB>  <TAB>  <TAB> self.write_stub(cmd, ext) <TAB> finally: <TAB>  <TAB> self.compiler = _compiler","if isinstance ( ext , Library ) :",134
"def _send_payload(self, payload): <TAB> req = eventlet_urllib2.Request(self._url, headers=payload[1]) <TAB> try: <MASK> response = eventlet_urllib2.urlopen(req, payload[0]).read() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> response = eventlet_urllib2.urlopen(req, payload[0], self.timeout).read() <TAB>  <TAB> return response <TAB> except Exception as err: <TAB>  <TAB> return err","if sys . version_info < ( 2 , 6 ) :",122
"def get_access_token(self, callback): <TAB> if not self.is_authorized(): <TAB>  <TAB> callback(None) <TAB> else: <TAB>  <TAB> access_token = config.persist[""oauth_access_token""] <TAB>  <TAB> access_token_expires = config.persist[""oauth_access_token_expires""] <MASK> callback(access_token) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.forget_access_token() <TAB>  <TAB>  <TAB> self.refresh_access_token(callback)",if access_token and time . time ( ) < access_token_expires :,131
"def mark_first_parents(event): <TAB> """"""Mark the node and all its parents."""""" <TAB> c = event.get(""c"") <TAB> if not c: <TAB>  <TAB> return <TAB> changed = [] <TAB> for parent in c.p.self_and_parents(): <MASK> parent.v.setMarked() <TAB>  <TAB>  <TAB> parent.setAllAncestorAtFileNodesDirty() <TAB>  <TAB>  <TAB> changed.append(parent.copy()) <TAB> if changed: <TAB>  <TAB> # g.es(""marked: "" + ', '.join([z.h for z in changed])) <TAB>  <TAB> c.setChanged() <TAB>  <TAB> c.redraw() <TAB> return changed",if not parent . isMarked ( ) :,162
"def normalize_reg_path(self, path): <TAB> new = path <TAB> if path: <TAB>  <TAB> roots = (""\\registry\\machine\\"", ""hklm\\"") <TAB>  <TAB> for r in roots: <MASK> new = ""HKEY_LOCAL_MACHINE\\"" + path[len(r) :] <TAB>  <TAB>  <TAB>  <TAB> return new <TAB> return path",if path . lower ( ) . startswith ( r ) :,94
"def extract_labels(filename, one_hot=False): <TAB> """"""Extract the labels into a 1D uint8 numpy array [index]."""""" <TAB> print(""Extracting"", filename) <TAB> with gzip.open(filename) as bytestream: <TAB>  <TAB> magic = _read32(bytestream) <TAB>  <TAB> if magic != 2049: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Invalid magic number %d in MNIST label file: %s"" % (magic, filename) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> num_items = _read32(bytestream) <TAB>  <TAB> buf = bytestream.read(num_items) <TAB>  <TAB> labels = numpy.frombuffer(buf, dtype=numpy.uint8) <MASK> return dense_to_one_hot(labels) <TAB>  <TAB> return labels",if one_hot :,180
"def on_change(self, data): <TAB> # loop over tp_clipboard views <TAB> for window in sublime.windows(): <TAB>  <TAB> for view in window.views(): <TAB>  <TAB>  <TAB> if view.get_status(""inactive"") and view.settings().get(""tp_append"", False): <TAB>  <TAB>  <TAB>  <TAB> file_name = view.file_name() <TAB>  <TAB>  <TAB>  <TAB> # ammo <MASK> self.update(view) <TAB>  <TAB>  <TAB>  <TAB> elif file_name and file_name.endswith( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> global_settings(""ammo_file_extension"", "".ammo"") <TAB>  <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.update(view)","if view . settings ( ) . get ( ""tp_ammo"" , False ) :",175
"def list(self, items, columns=4, width=80): <TAB> items = list(sorted(items)) <TAB> colw = width // columns <TAB> rows = (len(items) + columns - 1) // columns <TAB> for row in range(rows): <TAB>  <TAB> for col in range(columns): <TAB>  <TAB>  <TAB> i = col * rows + row <MASK> self.output.write(items[i]) <TAB>  <TAB>  <TAB>  <TAB> if col < columns - 1: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.output.write("" "" + "" "" * (colw - 1 - len(items[i]))) <TAB>  <TAB> self.output.write(""\n"")",if i < len ( items ) :,158
"def test_dynamic_section_solaris(self): <TAB> """"""Verify that we can parse relocations from the .dynamic section"""""" <TAB> test_dir = os.path.join(""test"", ""testfiles_for_unittests"") <TAB> with open(os.path.join(test_dir, ""exe_solaris32_cc.elf""), ""rb"") as f: <TAB>  <TAB> elff = ELFFile(f) <TAB>  <TAB> for sect in elff.iter_sections(): <MASK> relos = sect.get_relocation_tables() <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(set(relos), {""JMPREL"", ""REL""})","if isinstance ( sect , DynamicSection ) :",160
"def close(self, checkcount=False): <TAB> self.mutex.acquire() <TAB> try: <TAB>  <TAB> if checkcount: <TAB>  <TAB>  <TAB> self.openers -= 1 <TAB>  <TAB>  <TAB> if self.openers == 0: <TAB>  <TAB>  <TAB>  <TAB> self.do_close() <TAB>  <TAB> else: <MASK> self.do_close() <TAB>  <TAB>  <TAB> self.openers = 0 <TAB> finally: <TAB>  <TAB> self.mutex.release()",if self . openers > 0 :,116
def subcommand_table(self): <TAB> if self._subcommand_table is None: <MASK> self._topic_tag_db = TopicTagDB() <TAB>  <TAB> self._topic_tag_db.load_json_index() <TAB>  <TAB> self._subcommand_table = self._create_subcommand_table() <TAB> return self._subcommand_table,if self . _topic_tag_db is None :,89
"def layer_init(self): <TAB> for layer in self.cnn:  # type: ignore <TAB>  <TAB> if isinstance(layer, (nn.Conv2d, nn.Linear)): <TAB>  <TAB>  <TAB> nn.init.kaiming_normal_(layer.weight, nn.init.calculate_gain(""relu"")) <MASK> nn.init.constant_(layer.bias, val=0)",if layer . bias is not None :,99
"def _append_modifier(code, modifier): <TAB> if modifier == ""euro"": <TAB>  <TAB> if ""."" not in code: <TAB>  <TAB>  <TAB> return code + "".ISO8859-15"" <TAB>  <TAB> _, _, encoding = code.partition(""."") <TAB>  <TAB> if encoding in (""ISO8859-15"", ""UTF-8""): <TAB>  <TAB>  <TAB> return code <MASK> return _replace_encoding(code, ""ISO8859-15"") <TAB> return code + ""@"" + modifier","if encoding == ""ISO8859-1"" :",115
"def set_mean(self, mean): <TAB> if mean is not None: <TAB>  <TAB> # mean value, may be one value per channel <MASK> mean = mean[:, np.newaxis, np.newaxis] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # elementwise mean <TAB>  <TAB>  <TAB> if self.is_color: <TAB>  <TAB>  <TAB>  <TAB> assert len(mean.shape) == 3 <TAB> self.mean = mean",if mean . ndim == 1 :,101
"def _set_state(self, value): <TAB> if self._pwm: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> value = int(value * self._connection.get_PWM_range(self._number)) <MASK> self._connection.set_PWM_dutycycle(self._number, value) <TAB>  <TAB> except pigpio.error: <TAB>  <TAB>  <TAB> raise PinInvalidState('invalid state ""%s"" for pin %r' % (value, self)) <TAB> elif self.function == ""input"": <TAB>  <TAB> raise PinSetInput(""cannot set state of pin %r"" % self) <TAB> else: <TAB>  <TAB> # write forces pin to OUTPUT, hence the check above <TAB>  <TAB> self._connection.write(self._number, bool(value))",if value != self . _connection . get_PWM_dutycycle ( self . _number ) :,192
"def do_stop(self): <TAB> logger.info(""[%s] Stopping all workers"", self.name) <TAB> for w in self.workers.values(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> w.terminate() <TAB>  <TAB>  <TAB> w.join(timeout=1) <TAB>  <TAB> # A already dead worker or in a worker <TAB>  <TAB> except (AttributeError, AssertionError): <TAB>  <TAB>  <TAB> pass <TAB> # Close the server socket if it was opened <TAB> if self.http_daemon: <TAB>  <TAB> if self.brok_interface: <TAB>  <TAB>  <TAB> self.http_daemon.unregister(self.brok_interface) <MASK> self.http_daemon.unregister(self.scheduler_interface) <TAB> # And then call our master stop from satellite code <TAB> super(Satellite, self).do_stop()",if self . scheduler_interface :,191
"def iter_input(input, filename, parser, line_by_line): <TAB> if isinstance(input, basestring): <TAB>  <TAB> with open(input, ""rb"") as f: <TAB>  <TAB>  <TAB> for tree in iter_input(f, filename, parser, line_by_line): <TAB>  <TAB>  <TAB>  <TAB> yield tree <TAB> else: <TAB>  <TAB> try: <MASK> for line in input: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if line: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield et.ElementTree(et.fromstring(line, parser)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield et.parse(input, parser) <TAB>  <TAB> except IOError: <TAB>  <TAB>  <TAB> e = sys.exc_info()[1] <TAB>  <TAB>  <TAB> error(""parsing %r failed: %s: %s"", filename, e.__class__.__name__, e)",if line_by_line :,197
"def debug_print(data: json): <TAB> try: <TAB>  <TAB> print(""[+] ---Debug info---"") <TAB>  <TAB> for i, v in data.items(): <TAB>  <TAB>  <TAB> if i == ""outline"": <TAB>  <TAB>  <TAB>  <TAB> print(""[+]  -"", i, "" <TAB> :"", len(v), ""characters"") <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB>  <TAB> print(""[+]  -"", ""%-11s"" % i, "":"", v) <TAB>  <TAB> print(""[+] ---Debug info---"") <TAB> except: <TAB>  <TAB> pass","if i == ""actor_photo"" or i == ""year"" :",138
"def deliver_event(self): <TAB> while True: <TAB>  <TAB> client = self._client() <MASK> return  # weakref is dead, nothing to deliver <TAB>  <TAB> diff = self._due - client.loop.time() <TAB>  <TAB> if diff <= 0: <TAB>  <TAB>  <TAB> # We've hit our due time, deliver event. It won't respect <TAB>  <TAB>  <TAB> # sequential updates but fixing that would just worsen this. <TAB>  <TAB>  <TAB> await client._dispatch_event(self._event) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> del client  # Clear ref and sleep until our due time <TAB>  <TAB> await asyncio.sleep(diff)",if client is None :,147
"def pluginload(bot, event, *args): <TAB> """"""loads a previously unloaded plugin, requires plugins. prefix"""""" <TAB> if args: <TAB>  <TAB> module_path = args[0] <TAB>  <TAB> try: <MASK> message = ""<b><pre>{}</pre>: loaded</b>"".format(module_path) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> message = ""<b><pre>{}</pre>: failed</b>"".format(module_path) <TAB>  <TAB> except RuntimeError as e: <TAB>  <TAB>  <TAB> message = ""<b><pre>{}</pre>: <pre>{}</pre></b>"".format(module_path, str(e)) <TAB> else: <TAB>  <TAB> message = ""<b>module path required</b>"" <TAB> yield from bot.coro_send_message(event.conv_id, message)","if plugins . load ( bot , module_path ) :",192
"def validate_prompt_lb(hostname): <TAB> # Run the standard hostname check first: <TAB> hostname = validate_prompt_hostname(hostname) <TAB> # Make sure this host wasn't already specified: <TAB> for host in hosts: <MASK> raise click.BadParameter( <TAB>  <TAB>  <TAB>  <TAB> 'Cannot re-use ""%s"" as a load balancer, ' <TAB>  <TAB>  <TAB>  <TAB> ""please specify a separate host"" % hostname <TAB>  <TAB>  <TAB> ) <TAB> return hostname",if host . connect_to == hostname and ( host . is_master ( ) or host . is_node ( ) ) :,129
"def alter_inventory(session, resource, amount): <TAB> """"""Alters the inventory of each settlement."""""" <TAB> # NOTE avoid circular import <TAB> from horizons.component.storagecomponent import StorageComponent <TAB> for settlement in session.world.settlements: <MASK> settlement.warehouse.get_component(StorageComponent).inventory.alter( <TAB>  <TAB>  <TAB>  <TAB> resource, amount <TAB>  <TAB>  <TAB> )",if settlement . owner == session . world . player and settlement . warehouse :,109
"def _(value): <TAB> if kb.customInjectionMark in (value or """"): <MASK> value = value.replace(kb.customInjectionMark, """") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = re.sub(r""\w*%s"" % re.escape(kb.customInjectionMark), payload, value) <TAB> return value",if payload is None :,86
"def __call__(self, target): <TAB> if ""weights"" not in target.temp: <TAB>  <TAB> return True <TAB> targets = target.temp[""weights""] <TAB> for cname in target.children: <TAB>  <TAB> if cname in targets: <TAB>  <TAB>  <TAB> c = target.children[cname] <TAB>  <TAB>  <TAB> deviation = abs((c.weight - targets[cname]) / targets[cname]) <TAB>  <TAB>  <TAB> if deviation > self.tolerance: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> if ""cash"" in target.temp: <TAB>  <TAB> cash_deviation = abs( <TAB>  <TAB>  <TAB> (target.capital - targets.value) / targets.value - target.temp[""cash""] <TAB>  <TAB> ) <MASK> return True <TAB> return False",if cash_deviation > self . tolerance :,178
"def splitroot(self, part, sep=sep): <TAB> if part and part[0] == sep: <TAB>  <TAB> stripped_part = part.lstrip(sep) <TAB>  <TAB> # According to POSIX path resolution: <TAB>  <TAB> # http://pubs.opengroup.org/onlinepubs/009695399/basedefs/xbd_chap04.html#tag_04_11 <TAB>  <TAB> # ""A pathname that begins with two successive slashes may be <TAB>  <TAB> # interpreted in an implementation-defined manner, although more <TAB>  <TAB> # than two leading slashes shall be treated as a single slash"". <MASK> return """", sep * 2, stripped_part <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return """", sep, stripped_part <TAB> else: <TAB>  <TAB> return """", """", part",if len ( part ) - len ( stripped_part ) == 2 :,190
"def _Determine_Do(self): <TAB> self.applicable = 1 <TAB> method = ""moz-src"" <TAB> method_arg = None <TAB> for opt, optarg in self.chosenOptions: <MASK> method = ""moz-src"" <TAB>  <TAB> elif opt == ""--moz-objdir"": <TAB>  <TAB>  <TAB> method = ""moz-objdir"" <TAB>  <TAB>  <TAB> method_arg = optarg <TAB> if method == ""moz-src"": <TAB>  <TAB> self.value = self._get_mozilla_objdir() <TAB> elif method == ""moz-objdir"": <TAB>  <TAB> self.value = self._use_mozilla_objdir(method_arg) <TAB> else: <TAB>  <TAB> raise black.configure.ConfigureError(""bogus method: %r"" % method) <TAB> self.determined = 1","if opt == ""--moz-src"" :",188
"def is_filtered_inherited_member(name: str, obj: Any) -> bool: <TAB> if inspect.isclass(self.object): <TAB>  <TAB> for cls in self.object.__mro__: <TAB>  <TAB>  <TAB> if cls.__name__ == self.options.inherited_members and cls != self.object: <TAB>  <TAB>  <TAB>  <TAB> # given member is a member of specified *super class* <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB> elif name in cls.__dict__: <TAB>  <TAB>  <TAB>  <TAB> return False <MASK> return False <TAB>  <TAB>  <TAB> elif isinstance(obj, ObjectMember) and obj.class_ is cls: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return False","elif name in self . get_attr ( cls , ""__annotations__"" , { } ) :",167
"def _remove_all_greasemonkey_scripts(self): <TAB> page_scripts = self._widget.page().scripts() <TAB> for script in page_scripts.toList(): <MASK> log.greasemonkey.debug(""Removing script: {}"".format(script.name())) <TAB>  <TAB>  <TAB> removed = page_scripts.remove(script) <TAB>  <TAB>  <TAB> assert removed, script.name()","if script . name ( ) . startswith ( ""GM-"" ) :",100
"def merge_intervals(intervals): <TAB> """"""Merge intervals in the form of a list."""""" <TAB> if intervals is None: <TAB>  <TAB> return None <TAB> intervals.sort(key=lambda i: i[0]) <TAB> out = [intervals.pop(0)] <TAB> for i in intervals: <MASK> out[-1][-1] = max(out[-1][-1], i[-1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> out.append(i) <TAB> return out",if out [ - 1 ] [ - 1 ] >= i [ 0 ] :,122
"def __setattr__(self, key, val): <TAB> self.__dict__[key] = val <TAB> self.__dict__[key.upper()] = val <TAB> levels = key.split(""."") <TAB> last_level = len(levels) - 1 <TAB> pointer = self._pointer <TAB> if len(levels) > 1: <TAB>  <TAB> for i, l in enumerate(levels): <MASK> setattr(getattr(self, l), ""."".join(levels[i:]), val) <TAB>  <TAB>  <TAB> if l == last_level: <TAB>  <TAB>  <TAB>  <TAB> pointer[l] = val <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> pointer = pointer[l]","if hasattr ( self , l ) and isinstance ( getattr ( self , l ) , Config ) :",165
"def get_menu_title(self): <TAB> handle = self.obj.get_handle() <TAB> if handle: <TAB>  <TAB> who = get_participant_from_event(self.db, handle) <TAB>  <TAB> desc = self.obj.get_description() <TAB>  <TAB> event_name = self.obj.get_type() <MASK> event_name = ""%s - %s"" % (event_name, desc) <TAB>  <TAB> if who: <TAB>  <TAB>  <TAB> event_name = ""%s - %s"" % (event_name, who) <TAB>  <TAB> dialog_title = _(""Event: %s"") % event_name <TAB> else: <TAB>  <TAB> dialog_title = _(""New Event"") <TAB> return dialog_title",if desc :,168
"def perform_initialization(m): <TAB> if isinstance(m, self.initialize_layers): <MASK> initialization_method(m.weight.data, **initialization_kwargs) <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB> m.bias is not None <TAB>  <TAB>  <TAB> and self.initialize_bias != ""No"" <TAB>  <TAB>  <TAB> and initialization_method_bias is not None <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> initialization_method_bias(m.bias.data, **initialization_kwargs_bias) <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> pass",if initialization_method is not None :,145
"def forward(self, inputs): <TAB> x = inputs[""image""] <TAB> out = self.conv0(x) <TAB> out = self.downsample0(out) <TAB> blocks = [] <TAB> for i, conv_block_i in enumerate(self.darknet_conv_block_list): <TAB>  <TAB> out = conv_block_i(out) <TAB>  <TAB> if i == self.freeze_at: <TAB>  <TAB>  <TAB> out.stop_gradient = True <MASK> blocks.append(out) <TAB>  <TAB> if i < self.num_stages - 1: <TAB>  <TAB>  <TAB> out = self.downsample_list[i](out) <TAB> return blocks",if i in self . return_idx :,159
"def _urlvars__set(self, value): <TAB> environ = self.environ <TAB> if ""wsgiorg.routing_args"" in environ: <TAB>  <TAB> environ[""wsgiorg.routing_args""] = (environ[""wsgiorg.routing_args""][0], value) <MASK> del environ[""paste.urlvars""] <TAB> elif ""paste.urlvars"" in environ: <TAB>  <TAB> environ[""paste.urlvars""] = value <TAB> else: <TAB>  <TAB> environ[""wsgiorg.routing_args""] = ((), value)","if ""paste.urlvars"" in environ :",134
"def forward(self, x, activate=True, norm=True): <TAB> for layer in self.order: <TAB>  <TAB> if layer == ""conv"": <TAB>  <TAB>  <TAB> if self.with_explicit_padding: <TAB>  <TAB>  <TAB>  <TAB> x = self.padding_layer(x) <TAB>  <TAB>  <TAB> x = self.conv(x) <TAB>  <TAB> elif layer == ""norm"" and norm and self.with_norm: <TAB>  <TAB>  <TAB> x = self.norm(x) <MASK> x = self.activate(x) <TAB> return x","elif layer == ""act"" and activate and self . with_activation :",138
"def add(self, entry): <TAB> if not self._find_entry(entry, filters=False): <TAB>  <TAB> show = self.add_show(entry) <MASK> self._shows = None <TAB>  <TAB>  <TAB> log.verbose(""Successfully added show %s to Sonarr"", show[""title""]) <TAB> else: <TAB>  <TAB> log.debug(""entry %s already exists in Sonarr list"", entry)",if show :,99
"def __eq__(self, other): <TAB> if not isinstance(other, Result): <TAB>  <TAB> return False <TAB> equal = self.info == other.info <TAB> equal &= self.stats == other.stats <TAB> equal &= self.trajectories == other.trajectories <TAB> for k in self.np_arrays: <TAB>  <TAB> if k not in other.np_arrays: <TAB>  <TAB>  <TAB> equal &= False <TAB>  <TAB>  <TAB> break <MASK> break <TAB>  <TAB> equal &= all([np.array_equal(self.np_arrays[k], other.np_arrays[k])]) <TAB> return equal",if not equal :,138
"def handle_server_api(output, kwargs): <TAB> """"""Special handler for API-call 'set_config' [servers]"""""" <TAB> name = kwargs.get(""keyword"") <TAB> if not name: <TAB>  <TAB> name = kwargs.get(""name"") <TAB> if name: <TAB>  <TAB> server = config.get_config(""servers"", name) <MASK> server.set_dict(kwargs) <TAB>  <TAB>  <TAB> old_name = name <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> config.ConfigServer(name, kwargs) <TAB>  <TAB>  <TAB> old_name = None <TAB>  <TAB> sabnzbd.Downloader.update_server(old_name, name) <TAB> return name",if server :,155
"def extractNames(self, names): <TAB> offset = names[""offset""].value <TAB> for header in names.array(""header""): <TAB>  <TAB> key = header[""nameID""].value <TAB>  <TAB> foffset = offset + header[""offset""].value <TAB>  <TAB> field = names.getFieldByAddress(foffset * 8) <MASK> continue <TAB>  <TAB> value = field.value <TAB>  <TAB> if key not in self.NAMEID_TO_ATTR: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> key = self.NAMEID_TO_ATTR[key] <TAB>  <TAB> if key == ""version"" and value.startswith(u""Version ""): <TAB>  <TAB>  <TAB> # ""Version 1.2"" => ""1.2"" <TAB>  <TAB>  <TAB> value = value[8:] <TAB>  <TAB> setattr(self, key, value)",if not field or not isString ( field ) :,189
"def api_read(self): <TAB> files = [] <TAB> files.append(""/bin/netcat"") <TAB> files.append(""/etc/alternative/netcat"") <TAB> files.append(""/bin/nc"") <TAB> # <TAB>  init variables <TAB> installed = False <TAB> support = False <TAB> path = None <TAB> for _file in files: <TAB>  <TAB> file_content = self.shell.read(_file) <TAB>  <TAB> if file_content: <TAB>  <TAB>  <TAB> installed = True <TAB>  <TAB>  <TAB> path = _file <MASK> support = True <TAB>  <TAB>  <TAB> break <TAB> result = { <TAB>  <TAB> ""netcat_installed"": installed, <TAB>  <TAB> ""supports_shell_bind"": support, <TAB>  <TAB> ""path"": path, <TAB> } <TAB> return result","if ""-e filename"" in file_content :",187
"def _get_iscsi_portal(self, netspace): <TAB> for netpsace_interface in netspace.get_ips(): <MASK> port = netspace.get_properties().iscsi_tcp_port <TAB>  <TAB>  <TAB> return ""%s:%s"" % (netpsace_interface.ip_address, port) <TAB> # if we get here it means there are no enabled ports <TAB> msg = _(""No available interfaces in iSCSI network space %s"") % netspace.get_name() <TAB> raise exception.VolumeDriverException(message=msg)",if netpsace_interface . enabled :,140
"def show(self): <TAB> if len(self.figures.keys()) == 0: <TAB>  <TAB> return <TAB> if not SETTINGS.plot_split: <TAB>  <TAB> if SETTINGS.plot_backend.lower() == ""qt4agg"": <TAB>  <TAB>  <TAB> self.tabbed_qt4_window() <TAB>  <TAB> elif SETTINGS.plot_backend.lower() == ""qt5agg"": <TAB>  <TAB>  <TAB> self.tabbed_qt5_window() <MASK> self.tabbed_tk_window() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> plt.show() <TAB> else: <TAB>  <TAB> plt.show()","elif SETTINGS . plot_backend . lower ( ) == ""tkagg"" :",161
"def _update_decommissioned_icon(self): <TAB> """"""Add or remove decommissioned icon."""""" <TAB> if not self.instance.has_status_icon: <TAB>  <TAB> return <TAB> if self.is_active() is not self.__active: <TAB>  <TAB> self.__active = not self.__active <MASK> RemoveStatusIcon.broadcast(self, self.instance, DecommissionedStatus) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._add_status_icon(DecommissionedStatus(self.instance))",if self . __active :,127
"def _count(self, element, count=True): <TAB> if not isinstance(element, six.string_types): <TAB>  <TAB> if self == element: <TAB>  <TAB>  <TAB> return 1 <TAB> i = 0 <TAB> for child in self.children: <TAB>  <TAB> # child is text content and element is also text content, then <TAB>  <TAB> # make a simple ""text"" in ""text"" <MASK> if isinstance(element, six.string_types): <TAB>  <TAB>  <TAB>  <TAB> if count: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> i += child.count(element) <TAB>  <TAB>  <TAB>  <TAB> elif element in child: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> i += child._count(element, count=count) <TAB>  <TAB>  <TAB> if not count and i: <TAB>  <TAB>  <TAB>  <TAB> return i <TAB> return i","if isinstance ( child , six . string_types ) :",196
"def test_read_lazy(self): <TAB> want = b""x"" * 100 <TAB> telnet = test_telnet([want]) <TAB> self.assertEqual(b"""", telnet.read_lazy()) <TAB> data = b"""" <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> read_data = telnet.read_lazy() <TAB>  <TAB>  <TAB> data += read_data <MASK> telnet.fill_rawq() <TAB>  <TAB> except EOFError: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> self.assertTrue(want.startswith(data)) <TAB> self.assertEqual(data, want)",if not read_data :,143
"def getprefs(path=PREFSFILENAME): <TAB> if not os.path.exists(path): <TAB>  <TAB> f = open(path, ""w"") <TAB>  <TAB> f.write(default_prefs) <TAB>  <TAB> f.close() <TAB> f = open(path) <TAB> lines = f.readlines() <TAB> prefs = {} <TAB> for line in lines: <MASK> line = line[:-1] <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> name, value = re.split("":"", line, 1) <TAB>  <TAB>  <TAB> prefs[string.strip(name)] = eval(value) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> pass <TAB> return prefs","if line [ - 1 : ] == ""\n"" :",155
"def connect(self): <TAB> while True: <TAB>  <TAB> errno = self.sock.connect_ex(self.addr) <MASK> # connected immediately. <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif errno == EINPROGRESS: <TAB>  <TAB>  <TAB> # will be connected. <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif errno == ENOENT: <TAB>  <TAB>  <TAB> # no such socket file. <TAB>  <TAB>  <TAB> self.create_connection(self.failover_interval) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""Unexpected socket errno: %d"" % errno) <TAB> self.event_loop.watch_file(self.sock.fileno(), self.handle)",if not errno :,157
"def set_enabled_addons(file_path, addons, comment=None): <TAB> with codecs.open(file_path, ""w"", ""utf-8"") as f: <MASK> f.write(""# %s\n\n"" % comment) <TAB>  <TAB> for addon in addons: <TAB>  <TAB>  <TAB> f.write(""%s\n"" % addon)",if comment :,91
"def check_interfaceinNetWorkManager(self, interface): <TAB> """"""check if interface is already in file config"""""" <TAB> mac = Refactor.get_interface_mac(interface) <TAB> if mac != None: <TAB>  <TAB> if mac in open(self.mn_path, ""r"").read(): <TAB>  <TAB>  <TAB> return True <MASK> return True <TAB> return False","if interface in open ( self . mn_path , ""r"" ) . read ( ) :",102
"def spaceless(writer, node): <TAB> original = writer.spaceless <TAB> writer.spaceless = True <TAB> writer.warn(""entering spaceless mode with different semantics"", node) <TAB> # do the initial stripping <TAB> nodelist = list(node.nodelist) <TAB> if nodelist: <MASK> nodelist[0] = TextNode(nodelist[0].s.lstrip()) <TAB>  <TAB> if isinstance(nodelist[-1], TextNode): <TAB>  <TAB>  <TAB> nodelist[-1] = TextNode(nodelist[-1].s.rstrip()) <TAB> writer.body(nodelist) <TAB> writer.spaceless = original","if isinstance ( nodelist [ 0 ] , TextNode ) :",146
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_app_id(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> self.set_queue_name(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 24: <TAB>  <TAB>  <TAB> self.set_pause(d.getBoolean()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 18 :,152
"def group_re(self): <TAB> """"""Return a regexp pattern with named groups"""""" <TAB> out = """" <TAB> for token, data in self.tokens(): <TAB>  <TAB> if token == ""TXT"": <TAB>  <TAB>  <TAB> out += re.escape(data) <MASK> out += ""(?P<%s>%s)"" % (data[1], data[0]) <TAB>  <TAB> elif token == ""ANON"": <TAB>  <TAB>  <TAB> out += ""(?:%s)"" % data <TAB> return out","elif token == ""VAR"" :",114
"def wrap_in(input): <TAB> if isinstance(input, (SymbolicInput)): <TAB>  <TAB> return input <TAB> elif isinstance(input, gof.Variable): <TAB>  <TAB> # r -> SymbolicInput(variable=r) <TAB>  <TAB> return SymbolicInput(input) <TAB> elif isinstance(input, (list, tuple)): <TAB>  <TAB> # (r, u) -> SymbolicInput(variable=r, update=u) <MASK> return SymbolicInput(input[0], update=input[1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError(""Expected two elements in the list or tuple."", input) <TAB> else: <TAB>  <TAB> raise TypeError( <TAB>  <TAB>  <TAB> ""Unknown input type: %s (%s), expected Variable "" ""instance"", <TAB>  <TAB>  <TAB> type(input), <TAB>  <TAB>  <TAB> input, <TAB>  <TAB> )",if len ( input ) == 2 :,195
"def _remove_event(self, event): <TAB> # Find event according to its timestamp. <TAB> # Index returned should be one behind. <TAB> i = bisect.bisect(self._eventq, event) <TAB> # Having two events with identical timestamp is unlikely but possible. <TAB> # I am going to move forward and compare timestamp AND object address <TAB> # to make sure the correct object is found. <TAB> while i > 0: <TAB>  <TAB> i -= 1 <TAB>  <TAB> e = self._eventq[i] <MASK> raise exception.EventNotFound(event) <TAB>  <TAB> elif id(e) == id(event): <TAB>  <TAB>  <TAB> self._eventq.pop(i) <TAB>  <TAB>  <TAB> return <TAB> raise exception.EventNotFound(event)",if e . timestamp != event . timestamp :,177
"def cron_starter(*args: Any) -> None: <TAB> _tz = self.conf.timezone if timezone is None else timezone <TAB> while not self.should_stop: <TAB>  <TAB> await self.sleep(cron.secs_for_next(cron_format, _tz)) <TAB>  <TAB> if not self.should_stop: <TAB>  <TAB>  <TAB> should_run = not on_leader or self.is_leader() <MASK> with self.trace(shortlabel(fun), trace_enabled=traced): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> await fun(*args)",if should_run :,139
"def _find_boundary(self): <TAB> ct_info = tuple(x.strip() for x in self.content_type.split("";"")) <TAB> mimetype = ct_info[0] <TAB> if mimetype.split(""/"")[0].lower() != ""multipart"": <TAB>  <TAB> raise NonMultipartContentTypeException( <TAB>  <TAB>  <TAB> ""Unexpected mimetype in content-type: '{0}'"".format(mimetype) <TAB>  <TAB> ) <TAB> for item in ct_info[1:]: <TAB>  <TAB> attr, value = _split_on_find(item, ""="") <MASK> self.boundary = encode_with(value.strip('""'), self.encoding)","if attr . lower ( ) == ""boundary"" :",151
"def get_kwarg_or_param(request, kwargs, key): <TAB> value = None <TAB> try: <TAB>  <TAB> value = kwargs[key] <TAB> except KeyError: <TAB>  <TAB> if request.method == ""GET"": <TAB>  <TAB>  <TAB> value = request.GET.get(key) <MASK> value = request.POST.get(key) <TAB> return value","elif request . method == ""POST"" :",93
"def _gather_async_results(self, result: Result, source: typing.Any) -> None: <TAB> try: <TAB>  <TAB> context = result[""context""] <TAB>  <TAB> context[""is_refresh""] = False <TAB>  <TAB> context[""vars""] = self._vim.vars <TAB>  <TAB> async_candidates = source.gather_candidates(context) <TAB>  <TAB> context[""vars""] = None <TAB>  <TAB> result[""is_async""] = context[""is_async""] <MASK> return <TAB>  <TAB> context[""candidates""] += convert2candidates(async_candidates) <TAB> except Exception as exc: <TAB>  <TAB> self._handle_source_exception(source, exc)",if async_candidates is None :,155
"def _check_session(self, session, action): <TAB> if session is None: <MASK> key = self[0].key <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> key = self.key <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> f""Tileable object {key} must be executed first before {action}"" <TAB>  <TAB> )","if isinstance ( self , tuple ) :",84
"def update(self, dict=None, **kwargs): <TAB> if self._pending_removals: <TAB>  <TAB> self._commit_removals() <TAB> d = self.data <TAB> if dict is not None: <MASK> dict = type({})(dict) <TAB>  <TAB> for key, o in dict.items(): <TAB>  <TAB>  <TAB> d[key] = KeyedRef(o, self._remove, key) <TAB> if len(kwargs): <TAB>  <TAB> self.update(kwargs)","if not hasattr ( dict , ""items"" ) :",121
"def get_sigma(self): <TAB> if self.wants_automatic_sigma.value: <TAB>  <TAB> # <TAB>  <TAB> # Constants here taken from FindEdges.m <TAB>  <TAB> # <TAB>  <TAB> if self.method == M_CANNY: <TAB>  <TAB>  <TAB> return 1.0 <MASK> return 2.0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise NotImplementedError( <TAB>  <TAB>  <TAB>  <TAB> ""Automatic sigma not supported for method %s."" % self.method.value <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> return self.sigma.value",elif self . method == M_LOG :,136
"def forward(self, x, activate=True, norm=True): <TAB> for layer in self.order: <MASK> if self.with_explicit_padding: <TAB>  <TAB>  <TAB>  <TAB> x = self.padding_layer(x) <TAB>  <TAB>  <TAB> x = self.conv(x) <TAB>  <TAB> elif layer == ""norm"" and norm and self.with_norm: <TAB>  <TAB>  <TAB> x = self.norm(x) <TAB>  <TAB> elif layer == ""act"" and activate and self.with_activation: <TAB>  <TAB>  <TAB> x = self.activate(x) <TAB> return x","if layer == ""conv"" :",138
"def _grouping_intervals(grouping): <TAB> last_interval = None <TAB> for interval in grouping: <TAB>  <TAB> # if grouping is -1, we are done <MASK> return <TAB>  <TAB> # 0: re-use last group ad infinitum <TAB>  <TAB> if interval == 0: <TAB>  <TAB>  <TAB> if last_interval is None: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""invalid grouping"") <TAB>  <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB>  <TAB> yield last_interval <TAB>  <TAB> yield interval <TAB>  <TAB> last_interval = interval",if interval == CHAR_MAX :,124
"def iterRelativeExportCFiles(basepath): <TAB> for root, dirs, files in os.walk(basepath, topdown=True): <TAB>  <TAB> for directory in dirs: <MASK> dirs.remove(directory) <TAB>  <TAB> for filename in files: <TAB>  <TAB>  <TAB> if not isExportCFileIgnored(filename): <TAB>  <TAB>  <TAB>  <TAB> fullpath = os.path.join(root, filename) <TAB>  <TAB>  <TAB>  <TAB> yield os.path.relpath(fullpath, basepath)",if isAddonDirectoryIgnored ( directory ) :,117
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.add_application_key(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 18: <TAB>  <TAB>  <TAB> self.set_tag(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 10 :,122
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 8: <TAB>  <TAB>  <TAB> self.set_format(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <MASK> self.set_path(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 18 :,120
"def _get_future_trading_minutes(self, trading_date): <TAB> trading_minutes = set() <TAB> universe = self._get_universe() <TAB> for order_book_id in universe: <MASK> continue <TAB>  <TAB> trading_minutes.update( <TAB>  <TAB>  <TAB> self._env.data_proxy.get_trading_minutes_for(order_book_id, trading_date) <TAB>  <TAB> ) <TAB> return set([convert_int_to_datetime(minute) for minute in trading_minutes])",if self . _env . get_account_type ( order_book_id ) == DEFAULT_ACCOUNT_TYPE . STOCK :,154
"def helper(chunk: Any) -> Any: <TAB> nonlocal counter <TAB> if not isinstance(chunk, dict): <TAB>  <TAB> return chunk <TAB> if len(chunk) <= 2: <TAB>  <TAB> return chunk <TAB> id = hash(str(chunk)) <TAB> if id in cache: <TAB>  <TAB> return cache[id] <TAB> else: <TAB>  <TAB> cache[id] = {"".id"": counter} <TAB>  <TAB> chunk["".cache_id""] = counter <TAB>  <TAB> counter += 1 <TAB> for name in sorted(chunk.keys()): <TAB>  <TAB> value = chunk[name] <MASK> chunk[name] = [helper(child) for child in value] <TAB>  <TAB> elif isinstance(value, dict): <TAB>  <TAB>  <TAB> chunk[name] = helper(value) <TAB> return chunk","if isinstance ( value , list ) :",180
"def _render_lang_List(self, element): <TAB> with self.buffer.foldable_lines(): <TAB>  <TAB> self.buffer.write(""["", style=self.styles.bracket) <TAB>  <TAB> item_count = len(element.items) <TAB>  <TAB> if item_count: <TAB>  <TAB>  <TAB> with self.buffer.indent(): <TAB>  <TAB>  <TAB>  <TAB> for idx, item in enumerate(element.items): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._render(item) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if idx < (item_count - 1): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.buffer.write("","") <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.buffer.mark_line_break() <MASK> self.buffer.write(""..."") <TAB>  <TAB> self.buffer.write(""]"", style=self.styles.bracket)",if element . trimmed :,183
"def test_parse_query_params_matchable_field(self): <TAB> query_params = { <TAB>  <TAB> ""filter[string_field][contains]"": ""foo"", <TAB>  <TAB> ""filter[string_field][icontains]"": ""bar"", <TAB> } <TAB> fields = self.view.parse_query_params(query_params) <TAB> for key, field_name in fields.items(): <TAB>  <TAB> if field_name[""string_field""][""op""] == ""contains"": <TAB>  <TAB>  <TAB> assert_equal(field_name[""string_field""][""value""], ""foo"") <MASK> assert_equal(field_name[""string_field""][""value""], ""bar"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.fail()","elif field_name [ ""string_field"" ] [ ""op"" ] == ""icontains"" :",179
"def on_www_authenticate(data=None): <TAB> io_loop.remove_timeout(timeout[0]) <TAB> if data: <TAB>  <TAB> scheme = re.findall(""WWW-Authenticate: ([^\s]+)"", data)[0].strip() <TAB>  <TAB> logging.debug(""rtsp netcam auth scheme: %s"" % scheme) <MASK> send_auth[0] = True <TAB>  <TAB>  <TAB> connect() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logging.debug( <TAB>  <TAB>  <TAB>  <TAB> ""rtsp auth scheme digest not supported, considering credentials ok"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> handle_success(""(unknown) "") <TAB> else: <TAB>  <TAB> logging.error(""timeout waiting for rtsp auth scheme"") <TAB>  <TAB> handle_error(""timeout waiting for rtsp netcam response"")","if scheme . lower ( ) == ""basic"" :",186
"def receive(debug=debug): <TAB> if should_shutdown and should_shutdown(): <TAB>  <TAB> debug(""worker got sentinel -- exiting"") <TAB>  <TAB> raise SystemExit(EX_OK) <TAB> try: <TAB>  <TAB> ready, req = _receive(1.0) <MASK> return None <TAB> except (EOFError, IOError) as exc: <TAB>  <TAB> if get_errno(exc) == errno.EINTR: <TAB>  <TAB>  <TAB> return None  # interrupted, maybe by gdb <TAB>  <TAB> debug(""worker got %s -- exiting"", type(exc).__name__) <TAB>  <TAB> raise SystemExit(EX_FAILURE) <TAB> if req is None: <TAB>  <TAB> debug(""worker got sentinel -- exiting"") <TAB>  <TAB> raise SystemExit(EX_FAILURE) <TAB> return req",if not ready :,173
"def test_all(self): <TAB> raw = [r for r in self.map._revision_map.values() if r is not None] <TAB> revs = [rev for rev in self.map.iterate_revisions(""heads"", ""base"")] <TAB> eq_(set(raw), set(revs)) <TAB> for idx, rev in enumerate(revs): <TAB>  <TAB> ancestors = set(self.map._get_ancestor_nodes([rev])).difference([rev]) <TAB>  <TAB> descendants = set(self.map._get_descendant_nodes([rev])).difference([rev]) <TAB>  <TAB> assert not ancestors.intersection(descendants) <TAB>  <TAB> remaining = set(revs[idx + 1 :]) <MASK> assert remaining.intersection(ancestors)",if remaining :,165
"def is_issue(self, node): <TAB> first = node.children[0] <TAB> if first.type == ""string"" and self._normalizer.version >= (3, 0): <TAB>  <TAB> first_is_bytes = self._is_bytes_literal(first) <TAB>  <TAB> for string in node.children[1:]: <MASK> return True",if first_is_bytes != self . _is_bytes_literal ( string ) :,101
"def elements(registry): <TAB> """"""Given a resource registry return sorted de-aliased values."""""" <TAB> seen = {} <TAB> for k, v in registry.items(): <MASK> continue <TAB>  <TAB> if v in seen: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> seen[ElementSchema.name(v)] = v <TAB> return [seen[k] for k in sorted(seen)]","if k in ( ""and"" , ""or"" , ""not"" ) :",105
"def make_pattern(wtree): <TAB> subpattern = [] <TAB> for part in wtree[1:-1]: <TAB>  <TAB> if isinstance(part, list): <TAB>  <TAB>  <TAB> part = make_pattern(part) <TAB>  <TAB> elif wtree[0] != """": <TAB>  <TAB>  <TAB> for c in part: <TAB>  <TAB>  <TAB>  <TAB> # Meta-characters cannot be quoted <MASK> raise GlobError() <TAB>  <TAB> subpattern.append(part) <TAB> return """".join(subpattern)",if c in special_chars :,123
"def check_if_list_contain_duplicates(item: list, depth: int) -> None: <TAB> try: <TAB>  <TAB> if len(item) != len(set(item)): <TAB>  <TAB>  <TAB> print(Fore.RED + ""Rule {} has duplicate filters"".format(file)) <TAB>  <TAB>  <TAB> files_with_duplicate_filters.append(file) <TAB> except: <TAB>  <TAB> # unhashable types like dictionaries <TAB>  <TAB> for sub_item in item: <MASK> check_list_or_recurse_on_dict(sub_item, depth + 1)",if type ( sub_item ) == dict and depth <= MAX_DEPTH :,148
"def PrintHighlighted(self, out): <TAB> from doctools import make_help <TAB> pos = self.start_pos <TAB> for line_end in Lines(self.s, self.start_pos, self.end_pos): <TAB>  <TAB> # NOTE: HighlightLine accepts an HTML ESCAPED line.  It's valid to just <TAB>  <TAB> # add tags and leave everything alone. <TAB>  <TAB> line = self.s[pos:line_end] <TAB>  <TAB> html_line = make_help.HighlightLine(self.lang, line) <MASK> out.PrintUntil(pos) <TAB>  <TAB>  <TAB> out.Print(html_line) <TAB>  <TAB>  <TAB> out.SkipTo(line_end) <TAB>  <TAB> pos = line_end",if html_line is not None :,179
"def closeEvent(self, e=None): <TAB> """"""Save settings and remove registered logging handler"""""" <TAB> if self.editor.isModified(): <TAB>  <TAB> # ask if user wants to save <MASK> if self.save(): <TAB>  <TAB>  <TAB>  <TAB> e.accept() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> # saving error or user canceled <TAB>  <TAB>  <TAB>  <TAB> e.ignore() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # discard changes <TAB>  <TAB>  <TAB> e.accept() <TAB> else: <TAB>  <TAB> # unchanged <TAB>  <TAB> e.accept()",if self . wants_save ( ) :,133
"def readlines(self, hint=None): <TAB> if self.chunked_input: <TAB>  <TAB> lines = [] <TAB>  <TAB> for line in iter(self.readline, b""""): <TAB>  <TAB>  <TAB> lines.append(line) <TAB>  <TAB>  <TAB> if hint and hint > 0: <TAB>  <TAB>  <TAB>  <TAB> hint -= len(line) <MASK> break <TAB>  <TAB> return lines <TAB> else: <TAB>  <TAB> return self._do_read(self.rfile.readlines, hint)",if hint <= 0 :,117
"def test_prod(self): <TAB> with gpytorch.settings.fast_computations(covar_root_decomposition=False): <TAB>  <TAB> lazy_tensor = self.create_lazy_tensor() <TAB>  <TAB> evaluated = self.evaluate_lazy_tensor(lazy_tensor) <MASK> self.assertAllClose( <TAB>  <TAB>  <TAB>  <TAB> lazy_tensor.prod(-3).evaluate(), <TAB>  <TAB>  <TAB>  <TAB> evaluated.prod(-3), <TAB>  <TAB>  <TAB>  <TAB> **self.tolerances[""prod""] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if lazy_tensor.ndimension() > 3: <TAB>  <TAB>  <TAB> self.assertAllClose( <TAB>  <TAB>  <TAB>  <TAB> lazy_tensor.prod(-4).evaluate(), <TAB>  <TAB>  <TAB>  <TAB> evaluated.prod(-4), <TAB>  <TAB>  <TAB>  <TAB> **self.tolerances[""prod""] <TAB>  <TAB>  <TAB> )",if lazy_tensor . ndimension ( ) > 2 :,195
"def make_module_translation_map(names: List[str]) -> Dict[str, str]: <TAB> num_instances = {}  # type: Dict[str, int] <TAB> for name in names: <TAB>  <TAB> for suffix in candidate_suffixes(name): <TAB>  <TAB>  <TAB> num_instances[suffix] = num_instances.get(suffix, 0) + 1 <TAB> result = {} <TAB> for name in names: <TAB>  <TAB> for suffix in candidate_suffixes(name): <MASK> result[name] = suffix <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert False, names <TAB> return result",if num_instances [ suffix ] == 1 :,154
"def output(self): <TAB> """"""Transform self into a list of (name, value) tuples."""""" <TAB> header_list = [] <TAB> for k, v in self.items(): <TAB>  <TAB> if isinstance(k, unicodestr): <TAB>  <TAB>  <TAB> k = self.encode(k) <MASK> v = str(v) <TAB>  <TAB> if isinstance(v, unicodestr): <TAB>  <TAB>  <TAB> v = self.encode(v) <TAB>  <TAB> # See header_translate_* constants above. <TAB>  <TAB> # Replace only if you really know what you're doing. <TAB>  <TAB> k = k.translate(header_translate_table, header_translate_deletechars) <TAB>  <TAB> v = v.translate(header_translate_table, header_translate_deletechars) <TAB>  <TAB> header_list.append((k, v)) <TAB> return header_list","if not isinstance ( v , basestring ) :",197
"def get_errors(self, attacked_text, use_cache=False): <TAB> text = attacked_text.text <TAB> if use_cache: <MASK> self.grammar_error_cache[text] = len(self.lang_tool.check(text)) <TAB>  <TAB> return self.grammar_error_cache[text] <TAB> else: <TAB>  <TAB> return len(self.lang_tool.check(text))",if text not in self . grammar_error_cache :,110
"def gen(): <TAB> for _ in range(256): <TAB>  <TAB> if seq: <TAB>  <TAB>  <TAB> yield self.tb.dut.i.eq(seq.pop(0)) <TAB>  <TAB> i = yield self.tb.dut.i <MASK> self.assertEqual(i, 0) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> o = yield self.tb.dut.o <TAB>  <TAB>  <TAB> if o > 0: <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(i & 1 << (o - 1), 0) <TAB>  <TAB>  <TAB> self.assertGreaterEqual(i, 1 << o) <TAB>  <TAB> yield",if ( yield self . tb . dut . n ) :,149
"def _register_builtin_handlers(self, events): <TAB> for spec in handlers.BUILTIN_HANDLERS: <MASK> event_name, handler = spec <TAB>  <TAB>  <TAB> self.register(event_name, handler) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> event_name, handler, register_type = spec <TAB>  <TAB>  <TAB> if register_type is handlers.REGISTER_FIRST: <TAB>  <TAB>  <TAB>  <TAB> self._events.register_first(event_name, handler) <TAB>  <TAB>  <TAB> elif register_type is handlers.REGISTER_LAST: <TAB>  <TAB>  <TAB>  <TAB> self._events.register_last(event_name, handler)",if len ( spec ) == 2 :,148
"def is_checked_sls_template(template): <TAB> if template.__contains__(""provider""): <TAB>  <TAB> # Case provider is a dictionary <MASK> if template[""provider""].get(""name"").lower() not in SUPPORTED_PROVIDERS: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> # Case provider is direct provider name <TAB>  <TAB> if isinstance(template[""provider""], str_node): <TAB>  <TAB>  <TAB> if template[""provider""] not in SUPPORTED_PROVIDERS: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True <TAB> return False","if isinstance ( template [ ""provider"" ] , dict_node ) :",131
"def decode_body(self, response): <TAB> if response is None: <TAB>  <TAB> return response <TAB> if six.PY2: <TAB>  <TAB> return response <TAB> if response.body: <TAB>  <TAB> # Decode it <MASK> response._body = response.body.decode(""utf-8"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> response._body = salt.ext.tornado.escape.native_str(response.body) <TAB> return response","if response . headers . get ( ""Content-Type"" ) == ""application/json"" :",120
"def get_active_project_path(): <TAB> window = sublime.active_window() <TAB> folders = window.folders() <TAB> if len(folders) == 1: <TAB>  <TAB> return folders[0] <TAB> else: <TAB>  <TAB> active_view = window.active_view() <TAB>  <TAB> active_file_name = active_view.file_name() if active_view else None <TAB>  <TAB> if not active_file_name: <TAB>  <TAB>  <TAB> return folders[0] if len(folders) else os.path.expanduser(""~"") <TAB>  <TAB> for folder in folders: <MASK> return folder <TAB>  <TAB> return os.path.dirname(active_file_name)",if active_file_name . startswith ( folder ) :,166
"def pop(self, *a): <TAB> lists = self.lists <TAB> if len(lists) == 1 and not a: <TAB>  <TAB> return self.lists[0].pop() <TAB> index = a and a[0] <TAB> if index == () or index is None or index == -1: <TAB>  <TAB> ret = lists[-1].pop() <TAB>  <TAB> if len(lists) > 1 and not lists[-1]: <TAB>  <TAB>  <TAB> lists.pop() <TAB> else: <TAB>  <TAB> list_idx, rel_idx = self._translate_index(index) <MASK> raise IndexError() <TAB>  <TAB> ret = lists[list_idx].pop(rel_idx) <TAB>  <TAB> self._balance_list(list_idx) <TAB> return ret",if list_idx is None :,176
"def setup(self, gen): <TAB> Node.setup(self, gen) <TAB> try: <TAB>  <TAB> self.target = gen.rules[self.name] <MASK> self.accepts_epsilon = self.target.accepts_epsilon <TAB>  <TAB>  <TAB> gen.changed() <TAB> except KeyError:  # Oops, it's nonexistent <TAB>  <TAB> print >>sys.stderr, ""Error: no rule <%s>"" % self.name <TAB>  <TAB> self.target = self",if self . accepts_epsilon != self . target . accepts_epsilon :,125
"def match(self, userargs): <TAB> # Early skip if command or number of args don't match <TAB> if len(self.args) != len(userargs): <TAB>  <TAB> # DENY: argument numbers don't match <TAB>  <TAB> return False <TAB> # Compare each arg (anchoring pattern explicitly at end of string) <TAB> for (pattern, arg) in zip(self.args, userargs): <TAB>  <TAB> try: <MASK> break <TAB>  <TAB> except re.error: <TAB>  <TAB>  <TAB> # DENY: Badly-formed filter <TAB>  <TAB>  <TAB> return False <TAB> else: <TAB>  <TAB> # ALLOW: All arguments matched <TAB>  <TAB> return True <TAB> # DENY: Some arguments did not match <TAB> return False","if not re . match ( pattern + ""$"" , arg ) :",180
"def broadcast(self, msg, eid): <TAB> for s in self.subs: <TAB>  <TAB> if type(self.subs[s].eid) is list: <TAB>  <TAB>  <TAB> if eid in self.subs[s].eid: <TAB>  <TAB>  <TAB>  <TAB> self.subs[s].write_message(msg) <TAB>  <TAB> else: <MASK> self.subs[s].write_message(msg)",if self . subs [ s ] . eid == eid :,111
"def apply_transformation(self, ti: TransformationInput) -> Transformation: <TAB> fragments = ti.fragments <TAB> # Walk through all te fragments. <TAB> if fragments and fragment_list_to_text(fragments).startswith("" ""): <TAB>  <TAB> t = (self.style, self.get_char()) <TAB>  <TAB> fragments = explode_text_fragments(fragments) <TAB>  <TAB> for i in range(len(fragments)): <MASK> fragments[i] = t <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return Transformation(fragments)","if fragments [ i ] [ 1 ] == "" "" :",138
"def _url_encode_impl(obj, charset, encode_keys, sort, key): <TAB> iterable = sdict() <TAB> for key, values in obj.items(): <MASK> values = [values] <TAB>  <TAB> iterable[key] = values <TAB> if sort: <TAB>  <TAB> iterable = sorted(iterable, key=key) <TAB> for key, values in iterable.items(): <TAB>  <TAB> for value in values: <TAB>  <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if not isinstance(key, bytes): <TAB>  <TAB>  <TAB>  <TAB> key = str(key).encode(charset) <TAB>  <TAB>  <TAB> if not isinstance(value, bytes): <TAB>  <TAB>  <TAB>  <TAB> value = str(value).encode(charset) <TAB>  <TAB>  <TAB> yield url_quote_plus(key) + ""="" + url_quote_plus(value)","if not isinstance ( values , list ) :",198
"def get_objects(self) -> Iterator[Tuple[str, str, str, str, str, int]]: <TAB> rootSymbol = self.data[""root_symbol""] <TAB> for symbol in rootSymbol.get_all_symbols(): <MASK> continue <TAB>  <TAB> assert symbol.docname <TAB>  <TAB> fullNestedName = symbol.get_full_nested_name() <TAB>  <TAB> name = str(fullNestedName).lstrip(""."") <TAB>  <TAB> dispname = fullNestedName.get_display_string().lstrip(""."") <TAB>  <TAB> objectType = symbol.declaration.objectType <TAB>  <TAB> docname = symbol.docname <TAB>  <TAB> newestId = symbol.declaration.get_newest_id() <TAB>  <TAB> yield (name, dispname, objectType, docname, newestId, 1)",if symbol . declaration is None :,181
"def _delete_duplicates(l, keep_last): <TAB> """"""Delete duplicates from a sequence, keeping the first or last."""""" <TAB> seen = {} <TAB> result = [] <TAB> if keep_last:  # reverse in & out, then keep first <TAB>  <TAB> l.reverse() <TAB> for i in l: <TAB>  <TAB> try: <MASK> result.append(i) <TAB>  <TAB>  <TAB>  <TAB> seen[i] = 1 <TAB>  <TAB> except TypeError: <TAB>  <TAB>  <TAB> # probably unhashable.  Just keep it. <TAB>  <TAB>  <TAB> result.append(i) <TAB> if keep_last: <TAB>  <TAB> result.reverse() <TAB> return result",if i not in seen :,155
"def combine_logs(audit_logs, statement_text_logs): <TAB> for audit_transaction in audit_logs: <TAB>  <TAB> for audit_query in audit_logs[audit_transaction]: <TAB>  <TAB>  <TAB> matching_statement_text_logs = statement_text_logs.get(hash(audit_query)) <MASK> statement_text_log = matching_statement_text_logs.pop() <TAB>  <TAB>  <TAB>  <TAB> if statement_text_log: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if statement_text_log.start_time: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> audit_query.start_time = statement_text_log.start_time <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if statement_text_log.end_time: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> audit_query.end_time = statement_text_log.end_time",if matching_statement_text_logs :,197
"def free(self, addr, ban=0): <TAB> with self.lock: <TAB>  <TAB> if ban != 0: <TAB>  <TAB>  <TAB> self.ban.append({""addr"": addr, ""counter"": ban}) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> base, bit, is_allocated = self.locate(addr) <TAB>  <TAB>  <TAB> if len(self.addr_map) <= base: <TAB>  <TAB>  <TAB>  <TAB> raise KeyError(""address is not allocated"") <MASK> raise KeyError(""address is not allocated"") <TAB>  <TAB>  <TAB> self.allocated -= 1 <TAB>  <TAB>  <TAB> self.addr_map[base] ^= 1 << bit",if self . addr_map [ base ] & ( 1 << bit ) :,155
"def _assertParseMethod(test, code_str, method, expect_success=True): <TAB> arena, c_parser = InitCommandParser(code_str) <TAB> m = getattr(c_parser, method) <TAB> node = m() <TAB> if node: <TAB>  <TAB> ast_lib.PrettyPrint(node) <TAB>  <TAB> if not expect_success: <TAB>  <TAB>  <TAB> test.fail(""Expected %r to fail "" % code_str) <TAB> else: <TAB>  <TAB> # TODO: Could copy PrettyPrintError from pysh.py <TAB>  <TAB> err = c_parser.Error() <TAB>  <TAB> print(err) <TAB>  <TAB> ui.PrintErrorStack(err, arena, sys.stdout) <MASK> test.fail(""%r failed"" % code_str) <TAB> return node",if expect_success :,186
"def _gen(): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> loop_val = it.next()  # e.g. x <TAB>  <TAB> except StopIteration: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> self.mem.SetValue( <TAB>  <TAB>  <TAB> lvalue.Named(iter_name), value.Obj(loop_val), scope_e.LocalOnly <TAB>  <TAB> ) <MASK> b = self.EvalExpr(comp.cond) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> b = True <TAB>  <TAB> if b: <TAB>  <TAB>  <TAB> item = self.EvalExpr(node.elt)  # e.g. x*2 <TAB>  <TAB>  <TAB> yield item",if comp . cond :,155
"def _build_default_obj_recursive(self, _properties, res): <TAB> """"""takes disparate and nested default keys, and builds up a default object"""""" <TAB> for key, prop in _properties.items(): <MASK> res[key] = copy(prop[""default""]) <TAB>  <TAB> elif prop.get(""type"") == ""object"" and ""properties"" in prop: <TAB>  <TAB>  <TAB> res.setdefault(key, {}) <TAB>  <TAB>  <TAB> res[key] = self._build_default_obj_recursive(prop[""properties""], res[key]) <TAB> return res","if ""default"" in prop and key not in res :",143
"def mean(self): <TAB> """"""Compute the mean of the value_field in the window."""""" <TAB> if len(self.data) > 0: <TAB>  <TAB> datasum = 0 <TAB>  <TAB> datalen = 0 <TAB>  <TAB> for dat in self.data: <MASK> datasum += dat[1] <TAB>  <TAB>  <TAB>  <TAB> datalen += 1 <TAB>  <TAB> if datalen > 0: <TAB>  <TAB>  <TAB> return datasum / float(datalen) <TAB>  <TAB> return None <TAB> else: <TAB>  <TAB> return None","if ""placeholder"" not in dat [ 0 ] :",132
"def addNames(self, import_names, node_names): <TAB> for names in node_names: <MASK> name = names <TAB>  <TAB> elif names[1] is None: <TAB>  <TAB>  <TAB> name = names[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = names[1] <TAB>  <TAB> import_names[name] = True","if isinstance ( names , basestring ) :",88
"def set(sensor_spec: dict, **kwargs): <TAB> for key, value in kwargs.items(): <MASK> sensor_spec[""transform""] = SensorSpecs.get_position(value) <TAB>  <TAB> elif key == ""attachment_type"": <TAB>  <TAB>  <TAB> sensor_spec[key] = SensorSpecs.ATTACHMENT_TYPE[value] <TAB>  <TAB> elif key == ""color_converter"": <TAB>  <TAB>  <TAB> sensor_spec[key] = SensorSpecs.COLOR_CONVERTER[value]","if key == ""position"" :",125
"def delete_session(self): <TAB> cookie = self.headers.get(HTTP_HEADER.COOKIE) <TAB> if cookie: <TAB>  <TAB> match = re.search(r""%s=(.+)"" % SESSION_COOKIE_NAME, cookie) <TAB>  <TAB> if match: <TAB>  <TAB>  <TAB> session = match.group(1) <MASK> del SESSIONS[session]",if session in SESSIONS :,92
"def rename_var(block: paddle.device.framework.Block, old_name: str, new_name: str): <TAB> """""" """""" <TAB> for op in block.ops: <TAB>  <TAB> for input_name in op.input_arg_names: <MASK> op._rename_input(old_name, new_name) <TAB>  <TAB> for output_name in op.output_arg_names: <TAB>  <TAB>  <TAB> if output_name == old_name: <TAB>  <TAB>  <TAB>  <TAB> op._rename_output(old_name, new_name) <TAB> block._rename_var(old_name, new_name)",if input_name == old_name :,155
"def updateParticle(part, best, phi1, phi2): <TAB> u1 = numpy.random.uniform(0, phi1, len(part)) <TAB> u2 = numpy.random.uniform(0, phi2, len(part)) <TAB> v_u1 = u1 * (part.best - part) <TAB> v_u2 = u2 * (best - part) <TAB> part.speed += v_u1 + v_u2 <TAB> for i, speed in enumerate(part.speed): <MASK> part.speed[i] = math.copysign(part.smin, speed) <TAB>  <TAB> elif abs(speed) > part.smax: <TAB>  <TAB>  <TAB> part.speed[i] = math.copysign(part.smax, speed) <TAB> part += part.speed",if abs ( speed ) < part . smin :,197
"def acquire(self, blocking=True, timeout=None): <TAB> if not blocking and timeout is not None: <TAB>  <TAB> raise ValueError(""can't specify timeout for non-blocking acquire"") <TAB> rc = False <TAB> endtime = None <TAB> self._cond.acquire() <TAB> while self._value == 0: <TAB>  <TAB> if not blocking: <TAB>  <TAB>  <TAB> break <MASK> if endtime is None: <TAB>  <TAB>  <TAB>  <TAB> endtime = _time() + timeout <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> timeout = endtime - _time() <TAB>  <TAB>  <TAB>  <TAB> if timeout <= 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> self._cond.wait(timeout) <TAB> else: <TAB>  <TAB> self._value = self._value - 1 <TAB>  <TAB> rc = True <TAB> self._cond.release() <TAB> return rc",if timeout is not None :,194
"def test_ESPnetDataset_text_float(text_float): <TAB> dataset = IterableESPnetDataset( <TAB>  <TAB> path_name_type_list=[(text_float, ""data8"", ""text_float"")], <TAB>  <TAB> preprocess=preprocess, <TAB> ) <TAB> for key, data in dataset: <MASK> assert all((data[""data8""]) == np.array([1.4, 3.4], dtype=np.float32)) <TAB>  <TAB> if key == ""b"": <TAB>  <TAB>  <TAB> assert all((data[""data8""]) == np.array([0.9, 9.3], dtype=np.float32))","if key == ""a"" :",152
"def __eq__(self, other): <TAB> if isinstance(other, OrderedDict): <MASK> return False <TAB>  <TAB> for p, q in zip(list(self.items()), list(other.items())): <TAB>  <TAB>  <TAB> if p != q: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True <TAB> return dict.__eq__(self, other)",if len ( self ) != len ( other ) :,91
"def exec_command(command, cwd=None, stdout=None, env=None): <TAB> """"""Returns True in the command was executed successfully"""""" <TAB> try: <TAB>  <TAB> command_list = command if isinstance(command, list) else command.split() <TAB>  <TAB> env_vars = os.environ.copy() <MASK> env_vars.update(env) <TAB>  <TAB> subprocess.check_call(command_list, stdout=stdout, cwd=cwd, env=env_vars) <TAB>  <TAB> return True <TAB> except subprocess.CalledProcessError as err: <TAB>  <TAB> print(err, file=sys.stderr) <TAB>  <TAB> return False",if env :,146
"def _get_lun_details(self, lun_id): <TAB> """"""Given the ID of a LUN, get the details about that LUN"""""" <TAB> server = self.client.service <TAB> res = server.LunListInfoIterStart(ObjectNameOrId=lun_id) <TAB> tag = res.Tag <TAB> try: <TAB>  <TAB> res = server.LunListInfoIterNext(Tag=tag, Maximum=1) <MASK> return res.Luns.LunInfo[0] <TAB> finally: <TAB>  <TAB> server.LunListInfoIterEnd(Tag=tag)","if hasattr ( res , ""Luns"" ) and res . Luns . LunInfo :",162
"def _process_events(self, event_list): <TAB> for key, mask in event_list: <TAB>  <TAB> fileobj, (reader, writer) = key.fileobj, key.data <TAB>  <TAB> if mask & selectors.EVENT_READ and reader is not None: <TAB>  <TAB>  <TAB> if reader._cancelled: <TAB>  <TAB>  <TAB>  <TAB> self.remove_reader(fileobj) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._add_callback(reader) <MASK> if writer._cancelled: <TAB>  <TAB>  <TAB>  <TAB> self.remove_writer(fileobj) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._add_callback(writer)",if mask & selectors . EVENT_WRITE and writer is not None :,158
"def process_doc(self, docstrings: List[List[str]]) -> Iterator[str]: <TAB> """"""Let the user process the docstrings before adding them."""""" <TAB> for docstringlines in docstrings: <TAB>  <TAB> if self.env.app: <TAB>  <TAB>  <TAB> # let extensions preprocess docstrings <TAB>  <TAB>  <TAB> self.env.app.emit( <TAB>  <TAB>  <TAB>  <TAB> ""autodoc-process-docstring"", <TAB>  <TAB>  <TAB>  <TAB> self.objtype, <TAB>  <TAB>  <TAB>  <TAB> self.fullname, <TAB>  <TAB>  <TAB>  <TAB> self.object, <TAB>  <TAB>  <TAB>  <TAB> self.options, <TAB>  <TAB>  <TAB>  <TAB> docstringlines, <TAB>  <TAB>  <TAB> ) <MASK> # append a blank line to the end of the docstring <TAB>  <TAB>  <TAB>  <TAB> docstringlines.append("""") <TAB>  <TAB> yield from docstringlines","if docstringlines and docstringlines [ - 1 ] != """" :",185
"def vectorize(self, doc, vocab, char_vocab): <TAB> words = np.asarray( <TAB>  <TAB> [vocab[w.lower()] if w.lower() in vocab else 1 for w in doc] <TAB> ).reshape(1, -1) <TAB> sentence_chars = [] <TAB> for w in doc: <TAB>  <TAB> word_chars = [] <TAB>  <TAB> for c in w: <MASK> _cid = char_vocab[c] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> _cid = 1 <TAB>  <TAB>  <TAB> word_chars.append(_cid) <TAB>  <TAB> sentence_chars.append(word_chars) <TAB> sentence_chars = np.expand_dims( <TAB>  <TAB> pad_sentences(sentence_chars, self.model.word_length), axis=0 <TAB> ) <TAB> return words, sentence_chars",if c in char_vocab :,196
"def runtestenv(venv, config, redirect=False): <TAB> if venv.status == 0 and config.option.notest: <TAB>  <TAB> venv.status = ""skipped tests"" <TAB> else: <MASK> return <TAB>  <TAB> config.pluginmanager.hook.tox_runtest_pre(venv=venv) <TAB>  <TAB> if venv.status == 0: <TAB>  <TAB>  <TAB> config.pluginmanager.hook.tox_runtest(venv=venv, redirect=redirect) <TAB>  <TAB> config.pluginmanager.hook.tox_runtest_post(venv=venv)",if venv . status :,133
"def _import_config_module(self, name): <TAB> try: <TAB>  <TAB> self.find_module(name) <TAB> except NotAPackage: <MASK> reraise( <TAB>  <TAB>  <TAB>  <TAB> NotAPackage, <TAB>  <TAB>  <TAB>  <TAB> NotAPackage(CONFIG_WITH_SUFFIX.format(module=name, suggest=name[:-3])), <TAB>  <TAB>  <TAB>  <TAB> sys.exc_info()[2], <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> reraise( <TAB>  <TAB>  <TAB> NotAPackage, <TAB>  <TAB>  <TAB> NotAPackage(CONFIG_INVALID_NAME.format(module=name)), <TAB>  <TAB>  <TAB> sys.exc_info()[2], <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> return self.import_from_cwd(name)","if name . endswith ( "".py"" ) :",172
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.set_format(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 18: <TAB>  <TAB>  <TAB> self.set_path(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 8 :,120
"def get(self, request, *args, **kwargs): <TAB> # Generate sidebar forms <TAB> self.sidebar_forms = [] <TAB> for form_id, (plugin, Form) in self.get_sidebar_form_classes().items(): <MASK> form = Form(self.article, self.request.user) <TAB>  <TAB>  <TAB> setattr(form, ""form_id"", form_id) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> form = None <TAB>  <TAB> self.sidebar.append((plugin, form)) <TAB> return super().get(request, *args, **kwargs)",if Form :,135
"def check_click(self): <TAB> if not isinstance(self, SwiDebugView): <TAB>  <TAB> return <TAB> cursor = self.sel()[0].a <TAB> index = 0 <TAB> click_regions = self.get_regions(""swi_log_clicks"") <TAB> for callback in click_regions: <TAB>  <TAB> if cursor > callback.a and cursor < callback.b: <MASK> callback = self.callbacks[index] <TAB>  <TAB>  <TAB>  <TAB> callback[""callback""](*callback[""args""]) <TAB>  <TAB> index += 1",if index < len ( self . callbacks ) :,131
"def get_sock(port): <TAB> sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> _port = port or random.randint(1025, 5000) <TAB>  <TAB>  <TAB> print((""try bind local port:"", _port)) <TAB>  <TAB>  <TAB> sock.bind((""0.0.0.0"", _port)) <TAB>  <TAB>  <TAB> return sock <TAB>  <TAB> except socket.error as e: <MASK> print((""bind local port %d fail: %r"" % (_port, e))) <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> if e.args[0] == errno.EADDRINUSE: <TAB>  <TAB>  <TAB>  <TAB> pass",if port :,166
"def ParsePlacemark(self, node): <TAB> ret = Placemark() <TAB> for child in node.childNodes: <TAB>  <TAB> if child.nodeName == ""name"": <TAB>  <TAB>  <TAB> ret.name = self.ExtractText(child) <MASK> ret.coordinates = self.ExtractCoordinates(child) <TAB> return ret","if child . nodeName == ""Point"" or child . nodeName == ""LineString"" :",94
"def _load_library(self): <TAB> if self.library is not None: <MASK> name, mod_path = self.library <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = mod_path = self.library <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> module = importlib.import_module(mod_path) <TAB>  <TAB> except ImportError: <TAB>  <TAB>  <TAB> raise ValueError(""Couldn't load %s password algorithm "" ""library"" % name) <TAB>  <TAB> return module <TAB> raise ValueError(""Hasher '%s' doesn't specify a library attribute"" % self.__class__)","if isinstance ( self . library , ( tuple , list ) ) :",139
"def check(self): <TAB> for r in self.results: <MASK> assert r.backend.name == self.target.path.k8s, ( <TAB>  <TAB>  <TAB>  <TAB> r.backend.name, <TAB>  <TAB>  <TAB>  <TAB> self.target.path.k8s, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> assert r.backend.request.headers[""x-envoy-original-path""][0] in ( <TAB>  <TAB>  <TAB>  <TAB> f""/{self.name}/"", <TAB>  <TAB>  <TAB>  <TAB> f""/{self.name}-nested/"", <TAB>  <TAB>  <TAB> )",if r . backend :,135
"def eval(self, code, eval=True, raw=False): <TAB> self._engine._append_source(code) <TAB> try: <TAB>  <TAB> result = self._context.eval(code) <TAB> except quickjs.JSException as e: <TAB>  <TAB> raise ProgramError(*e.args) <TAB> else: <TAB>  <TAB> if eval: <TAB>  <TAB>  <TAB> if raw or not isinstance(result, quickjs.Object): <TAB>  <TAB>  <TAB>  <TAB> return result <MASK> return self.Function(self, result) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return json.loads(result.json())","elif callable ( result ) and self . typeof ( result ) == u""function"" :",158
"def __truediv__(self, val): <TAB> if isinstance(val, Vector3): <MASK> raise ZeroDivisionError() <TAB>  <TAB> gd_obj = lib.godot_vector3_operator_divide_vector(self._gd_ptr, val._gd_ptr) <TAB> else: <TAB>  <TAB> if val is 0: <TAB>  <TAB>  <TAB> raise ZeroDivisionError() <TAB>  <TAB> gd_obj = lib.godot_vector3_operator_divide_scalar(self._gd_ptr, val) <TAB> return Vector3.build_from_gdobj(gd_obj)",if val . x == 0 or val . y == 0 or val . z == 0 :,148
"def set_peek(self, dataset, is_multi_byte=False): <TAB> if not dataset.dataset.purged: <TAB>  <TAB> dataset.peek = data.get_file_peek(dataset.file_name) <MASK> dataset.blurb = ""%s sequences"" % util.commaify( <TAB>  <TAB>  <TAB>  <TAB> str(dataset.metadata.sequences) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> dataset.blurb = nice_size(dataset.get_size()) <TAB> else: <TAB>  <TAB> dataset.peek = ""file does not exist"" <TAB>  <TAB> dataset.blurb = ""file purged from disk""",if dataset . metadata . sequences :,153
"def _get_plugin_src_dirs(base_dir): <TAB> plug_in_base_path = Path(get_src_dir(), base_dir) <TAB> plugin_dirs = get_dirs_in_dir(str(plug_in_base_path)) <TAB> plugins = [] <TAB> for plugin_path in plugin_dirs: <TAB>  <TAB> plugin_code_dir = Path(plugin_path, ""code"") <MASK> plugins.append(str(plugin_code_dir)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logging.warning(""Plugin has no code directory: {}"".format(plugin_path)) <TAB> return plugins",if plugin_code_dir . is_dir ( ) :,155
"def _format_privilege_data(self, data): <TAB> for key in [""spcacl""]: <TAB>  <TAB> if key in data and data[key] is not None: <TAB>  <TAB>  <TAB> if ""added"" in data[key]: <TAB>  <TAB>  <TAB>  <TAB> data[key][""added""] = parse_priv_to_db(data[key][""added""], self.acl) <TAB>  <TAB>  <TAB> if ""changed"" in data[key]: <TAB>  <TAB>  <TAB>  <TAB> data[key][""changed""] = parse_priv_to_db(data[key][""changed""], self.acl) <MASK> data[key][""deleted""] = parse_priv_to_db(data[key][""deleted""], self.acl)","if ""deleted"" in data [ key ] :",168
"def __init__(self, methodName=""runTest""): <TAB> unittest.TestCase.__init__(self, methodName) <TAB> # We expect files to be relative to this test script. <TAB> test_dir = dirname(dirname(__file__)) <TAB> self._dir = normpath(join(test_dir, ""stuff/charsets/www.kostis.net/charsets"")) <TAB> self._enc = {} <TAB> # get all the utf-8 files in this dir, and well recode them <TAB> names = os.listdir(self._dir) <TAB> for name in names: <MASK> continue <TAB>  <TAB> enc = name.split(""."")[0] <TAB>  <TAB> if decoderAvailable(enc): <TAB>  <TAB>  <TAB> self._enc[enc] = name","if not os . path . isfile ( os . path . join ( self . _dir , name ) ) :",187
"def get_actions_on_list(self, actions, modelview_name): <TAB> res_actions = dict() <TAB> for action_key in actions: <TAB>  <TAB> action = actions[action_key] <MASK> res_actions[action_key] = action <TAB> return res_actions","if self . is_item_visible ( action . name , modelview_name ) and action . multiple :",93
"def triger_check_network(self, fail=False, force=False): <TAB> time_now = time.time() <TAB> if not force: <TAB>  <TAB> if self._checking_num > 0: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> if fail or self.network_stat != ""OK"": <TAB>  <TAB>  <TAB> # Fail or unknown <MASK> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if time_now - self.last_check_time < 10: <TAB>  <TAB>  <TAB>  <TAB> return <TAB> self.last_check_time = time_now <TAB> threading.Thread(target=self._simple_check_worker).start()",if time_now - self . last_check_time < 3 :,161
"def write(self, root): <TAB> """"""Write all the *descendants* of an .dart node."""""" <TAB> root_level = root.level() <TAB> for p in root.subtree(): <TAB>  <TAB> indent = p.level() - root_level <TAB>  <TAB> self.put(""%s %s"" % (""*"" * indent, p.h)) <TAB>  <TAB> for s in p.b.splitlines(False): <MASK> self.put(s) <TAB> root.setVisited() <TAB> return True",if not g . isDirective ( s ) :,127
"def characters(self, ch): <TAB> if self.Text_tag: <MASK> self.Summary_ch += ch <TAB>  <TAB> elif self.Attack_Prerequisite_tag: <TAB>  <TAB>  <TAB> self.Attack_Prerequisite_ch += ch <TAB>  <TAB> elif self.Solution_or_Mitigation_tag: <TAB>  <TAB>  <TAB> self.Solution_or_Mitigation_ch += ch <TAB> elif self.CWE_ID_tag: <TAB>  <TAB> self.CWE_ID_ch += ch",if self . Summary_tag :,127
"def _handle_function(self, addr): <TAB> if self.arch.name == ""X86"": <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> b = self._project.loader.memory.load(addr, 4) <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> except TypeError: <TAB>  <TAB>  <TAB> return <MASK> # getpc: <TAB>  <TAB>  <TAB> #   mov ebx, [esp] <TAB>  <TAB>  <TAB> #   ret <TAB>  <TAB>  <TAB> ebx_offset = self.arch.registers[""ebx""][0] <TAB>  <TAB>  <TAB> self.state.store_register(ebx_offset, 4, self.block.addr + self.block.size)","if b == b""\x8b\x1c\x24\xc3"" :",171
"def safe_makedir(dname): <TAB> """"""Make a directory if it doesn't exist, handling concurrent race conditions."""""" <TAB> if not dname: <TAB>  <TAB> return dname <TAB> num_tries = 0 <TAB> max_tries = 5 <TAB> while not os.path.exists(dname): <TAB>  <TAB> # we could get an error here if multiple processes are creating <TAB>  <TAB> # the directory at the same time. Grr, concurrency. <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> os.makedirs(dname) <TAB>  <TAB> except OSError: <MASK> raise <TAB>  <TAB>  <TAB> num_tries += 1 <TAB>  <TAB>  <TAB> time.sleep(2) <TAB> return dname",if num_tries > max_tries :,164
"def _setup_data(self, path): <TAB> with PathManager.open(path) as data_file: <MASK> line = data_file.readline() <TAB>  <TAB>  <TAB> # trim corrupted JSON <TAB>  <TAB>  <TAB> line = line[: line.rfind(""{"")] <TAB>  <TAB>  <TAB> line = line[: line.rfind("","")] + ""]"" <TAB>  <TAB>  <TAB> self.data = json.loads(line) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.data = json.load(data_file)","if ""extra"" in path and ""train"" in path :",124
"def _end_delimiter(state, token): <TAB> py = state[""pymode""] <TAB> s = token.string <TAB> l, c = token.start <TAB> if len(py) > 1: <TAB>  <TAB> mode, orig, match, pos = py.pop() <MASK> e = '""{}"" at {} ends ""{}"" at {} (expected ""{}"")' <TAB>  <TAB>  <TAB> return e.format(s, (l, c), orig, pos, match) <TAB> else: <TAB>  <TAB> return 'Unmatched ""{}"" at line {}, column {}'.format(s, l, c)",if s != match :,132
"def onLeftDoubleClick(self, event): <TAB> row, _ = self.HitTest(event.Position) <TAB> if row != -1: <TAB>  <TAB> col = self.getColumn(event.Position) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> booster = self.boosters[row] <TAB>  <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> self.removeBoosters([booster])",if col != self . getColIndex ( State ) :,107
"def get_instance_userdata( <TAB> version=""latest"", <TAB> sep=None, <TAB> url=""http://169.254.169.254"", <TAB> timeout=None, <TAB> num_retries=5,): <TAB> ud_url = _build_instance_metadata_url(url, version, ""user-data"") <TAB> user_data = retry_url( <TAB>  <TAB> ud_url, retry_on_404=False, num_retries=num_retries, timeout=timeout <TAB> ) <TAB> if user_data: <MASK> l = user_data.split(sep) <TAB>  <TAB>  <TAB> user_data = {} <TAB>  <TAB>  <TAB> for nvpair in l: <TAB>  <TAB>  <TAB>  <TAB> t = nvpair.split(""="") <TAB>  <TAB>  <TAB>  <TAB> user_data[t[0].strip()] = t[1].strip() <TAB> return user_data",if sep :,198
def parts(self): <TAB> klass = self.__class__ <TAB> this = list() <TAB> for token in self: <TAB>  <TAB> if token.startswith_fws(): <MASK> yield this[0] if len(this) == 1 else klass(this) <TAB>  <TAB>  <TAB>  <TAB> this.clear() <TAB>  <TAB> end_ws = token.pop_trailing_ws() <TAB>  <TAB> this.append(token) <TAB>  <TAB> if end_ws: <TAB>  <TAB>  <TAB> yield klass(this) <TAB>  <TAB>  <TAB> this = [end_ws] <TAB> if this: <TAB>  <TAB> yield this[0] if len(this) == 1 else klass(this),if this :,153
"def run(self): <TAB> while True: <TAB>  <TAB> self._trigger.wait() <TAB>  <TAB> self._trigger.clear() <MASK> break <TAB>  <TAB> for url in self.urls: <TAB>  <TAB>  <TAB> logger.info(""Pinging for problem update: %s"", url) <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> with closing(urlopen(url, data="""")) as f: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f.read() <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> logger.exception(""Failed to ping for problem update: %s"", url)",if self . _terminate :,132
"def _get_trading_minutes(self, trading_date): <TAB> trading_minutes = set() <TAB> for account_type in self._config.base.accounts: <TAB>  <TAB> if account_type == DEFAULT_ACCOUNT_TYPE.STOCK: <TAB>  <TAB>  <TAB> trading_minutes = trading_minutes.union( <TAB>  <TAB>  <TAB>  <TAB> self._get_stock_trading_minutes(trading_date) <TAB>  <TAB>  <TAB> ) <MASK> trading_minutes = trading_minutes.union( <TAB>  <TAB>  <TAB>  <TAB> self._get_future_trading_minutes(trading_date) <TAB>  <TAB>  <TAB> ) <TAB> return sorted(list(trading_minutes))",elif account_type == DEFAULT_ACCOUNT_TYPE . FUTURE :,169
"def make_tree(self, node): <TAB> if node is self.root: <TAB>  <TAB> node.code = """" <TAB> children = [] <TAB> for bit in ""01"": <TAB>  <TAB> next_code = node.code + bit <MASK> child = Node(char=self.codes[next_code]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> child = Node() <TAB>  <TAB> child.code = next_code <TAB>  <TAB> children.append(child) <TAB> node.add(children) <TAB> for child in children: <TAB>  <TAB> if not child.is_leaf: <TAB>  <TAB>  <TAB> self.make_tree(child)",if next_code in self . codes :,152
"def _merge(self, a, b, path=None): <TAB> """"""Merge two dictionaries, from http://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge"""""" <TAB> if path is None: <TAB>  <TAB> path = [] <TAB> for key in b: <TAB>  <TAB> if key in a: <MASK> self._merge(a[key], b[key], path + [str(key)]) <TAB>  <TAB>  <TAB> elif a[key] == b[key]: <TAB>  <TAB>  <TAB>  <TAB> pass  # same leaf value <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise Exception(""Conflict at %s"" % ""."".join(path + [str(key)])) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> a[key] = b[key] <TAB> return a","if isinstance ( a [ key ] , dict ) and isinstance ( b [ key ] , dict ) :",196
"def _append_value(generator, val=None): <TAB> for example in generator: <TAB>  <TAB> example = list(example) <MASK> for key, value in val.items(): <TAB>  <TAB>  <TAB>  <TAB> example[key] = np.append(example[key], value, -1) <TAB>  <TAB> yield tuple(example)",if val is not None :,82
"def run(self): <TAB> to_delete = set() <TAB> for k, v in iteritems(self.objs): <MASK> continue <TAB>  <TAB> if v[""_class""] == ""SubmissionFormatElement"": <TAB>  <TAB>  <TAB> to_delete.add(k) <TAB>  <TAB> if v[""_class""] == ""Task"": <TAB>  <TAB>  <TAB> v[""submission_format""] = list( <TAB>  <TAB>  <TAB>  <TAB> self.objs[k][""filename""] for k in v.get(""submission_format"", list()) <TAB>  <TAB>  <TAB> ) <TAB> for k in to_delete: <TAB>  <TAB> del self.objs[k] <TAB> return self.objs","if k . startswith ( ""_"" ) :",147
"def service_destroy(context, service_id): <TAB> session = get_session() <TAB> with session.begin(): <TAB>  <TAB> service_ref = service_get(context, service_id, session=session) <TAB>  <TAB> service_ref.delete(session=session) <MASK> for c in service_ref.compute_node: <TAB>  <TAB>  <TAB>  <TAB> c.delete(session=session)","if service_ref . topic == ""compute"" and service_ref . compute_node :",111
"def wiki(self, query): <TAB> res = [] <TAB> for entry in g.current_wiki.get_index(): <TAB>  <TAB> name = filename_to_cname(entry[""name""]) <TAB>  <TAB> name = re.sub(r""//+"", ""/"", name) <MASK> page = g.current_wiki.get_page(name) <TAB>  <TAB>  <TAB> # this can be None, not sure how <TAB>  <TAB>  <TAB> if page: <TAB>  <TAB>  <TAB>  <TAB> res.append(dict(name=name, content=page.data)) <TAB> return res","if set ( query . split ( ) ) . intersection ( name . replace ( ""/"" , ""-"" ) . split ( ""-"" ) ) :",143
"def numericalize(self, arr, device=None): <TAB> if isinstance(arr[0][0], list): <TAB>  <TAB> tmp = [ <TAB>  <TAB>  <TAB> super(BABI20Field, self).numericalize(x, device=device).data for x in arr <TAB>  <TAB> ] <TAB>  <TAB> arr = torch.stack(tmp) <MASK> arr = arr.contiguous() <TAB>  <TAB> return arr <TAB> else: <TAB>  <TAB> return super(BABI20Field, self).numericalize(arr, device=device)",if self . sequential :,127
def validate_and_handle(self): <TAB> valid = self.validate(set_cursor=True) <TAB> if valid: <TAB>  <TAB> if self.accept_handler: <TAB>  <TAB>  <TAB> keep_text = self.accept_handler(self) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> keep_text = False <MASK> self.reset(),if not keep_text :,86
"def headerData(self, section, orientation, role=Qt.DisplayRole): <TAB> if role == Qt.TextAlignmentRole: <TAB>  <TAB> if orientation == Qt.Horizontal: <TAB>  <TAB>  <TAB> return to_qvariant(int(Qt.AlignHCenter | Qt.AlignVCenter)) <TAB>  <TAB> return to_qvariant(int(Qt.AlignRight | Qt.AlignVCenter)) <TAB> if role != Qt.DisplayRole: <TAB>  <TAB> return to_qvariant() <TAB> if orientation == Qt.Horizontal: <MASK> return to_qvariant(""Name"") <TAB>  <TAB> elif section == VERSION: <TAB>  <TAB>  <TAB> return to_qvariant(""Version"") <TAB>  <TAB> elif section == ACTION: <TAB>  <TAB>  <TAB> return to_qvariant(""Action"") <TAB>  <TAB> elif section == DESCRIPTION: <TAB>  <TAB>  <TAB> return to_qvariant(""Description"") <TAB> return to_qvariant()",if section == NAME :,192
"def replace(self, state): <TAB> if state.key in self._dict: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> existing = self._dict[state.key] <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> # catch gc removed the key after we just checked for it <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <MASK> self._manage_removed_state(existing) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return <TAB> self._dict[state.key] = state <TAB> self._manage_incoming_state(state)",if existing is not state :,131
"def _line_generator(fh, skip_blanks=False, strip=True): <TAB> for line in fh: <MASK> line = line.strip() <TAB>  <TAB> skip = False <TAB>  <TAB> if skip_blanks: <TAB>  <TAB>  <TAB> skip = line.isspace() or not line <TAB>  <TAB> if not skip: <TAB>  <TAB>  <TAB> yield line",if strip :,82
"def _get_workers_with_max_size(worker_to_size): <TAB> """"""Get workers with maximal size"""""" <TAB> max_workers = set() <TAB> max_size = 0 <TAB> for w, size in worker_to_size.items(): <MASK> max_size = size <TAB>  <TAB>  <TAB> max_workers = {w} <TAB>  <TAB> elif size == max_size: <TAB>  <TAB>  <TAB> max_workers.add(w) <TAB> max_workers.difference_update([None]) <TAB> return max_size, list(max_workers)",if size > max_size :,135
"def parse(self): <TAB> while 1: <TAB>  <TAB> l = self.f.readline() <TAB>  <TAB> if not l: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> l = l.strip() <TAB>  <TAB> if l.startswith(""[""): <TAB>  <TAB>  <TAB> self.parse_uuid(l) <TAB>  <TAB> elif l.startswith(""interface"") or l.startswith(""dispinterface""): <TAB>  <TAB>  <TAB> self.parse_interface(l) <MASK> self.parse_coclass(l)","elif l . startswith ( ""coclass"" ) :",117
"def check_source_unit(self, source, unit): <TAB> """"""Check source string."""""" <TAB> rules = [FLAG_RULES[flag] for flag in unit.all_flags if flag in FLAG_RULES] <TAB> if not rules: <TAB>  <TAB> return False <TAB> found = set() <TAB> for regexp, is_position_based in rules: <TAB>  <TAB> for match in regexp.finditer(source[0]): <TAB>  <TAB>  <TAB> if is_position_based(match[1]): <TAB>  <TAB>  <TAB>  <TAB> found.add((match.start(0), match.end(0))) <MASK> return True <TAB> return False",if len ( found ) >= 2 :,156
"def parse_exprlist(self): <TAB> list = [] <TAB> while TRUE: <TAB>  <TAB> self.reader.skip_white() <TAB>  <TAB> c = self.reader.peek() <MASK> break <TAB>  <TAB> node = self.parse_expr() <TAB>  <TAB> viml_add(list, node) <TAB> return list","if c != '""' and self . ends_excmds ( c ) :",90
"def can_see_ban_details(request, profile): <TAB> if request.user.is_authenticated: <MASK> from .bans import get_user_ban <TAB>  <TAB>  <TAB> return bool(get_user_ban(profile, request.cache_versions)) <TAB>  <TAB> return False <TAB> return False","if request . user_acl [ ""can_see_ban_details"" ] :",87
"def mouse_move(self, ips, x, y, btn, **key): <TAB> if ips.roi == None: <TAB>  <TAB> return <TAB> lim = 5.0 / key[""canvas""].get_scale() <TAB> if btn == None: <TAB>  <TAB> self.cursor = wx.CURSOR_CROSS <MASK> self.cursor = wx.CURSOR_HAND <TAB> elif btn == 1: <TAB>  <TAB> if self.curobj: <TAB>  <TAB>  <TAB> ips.roi.draged(self.odx, self.ody, x, y, ips.cur, self.curobj) <TAB>  <TAB> ips.update() <TAB> self.odx, self.ody = x, y","if ips . roi . snap ( x , y , ips . cur , lim ) != None :",178
"def evex_mask_dest_reg_only(ii):  # optional imm8 <TAB> i, m, xyz = 0, 0, 0 <TAB> for op in _gen_opnds(ii): <TAB>  <TAB> if op_mask_reg(op): <TAB>  <TAB>  <TAB> m += 1 <MASK> xyz += 1 <TAB>  <TAB> elif op_imm8(op): <TAB>  <TAB>  <TAB> i += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> return m == 1 and xyz > 0 and i <= 1",elif op_xmm ( op ) or op_ymm ( op ) or op_zmm ( op ) :,143
"def encode_datetime(self, dt, state): <TAB> fmt = self.options.datetime_format <TAB> is_iso = not fmt or fmt == ""iso"" <TAB> if is_iso: <MASK> fmt = ""%Y-%m-%dT%H:%M:%S%z"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> fmt = ""%Y-%m-%dT%H:%M:%S.%f%z"" <TAB> s = dt.strftime(fmt) <TAB> if is_iso and s.endswith(""-00:00"") or s.endswith(""+00:00""): <TAB>  <TAB> s = s[:-6] + ""Z""  # Change UTC to use 'Z' notation <TAB> self.encode_string(s, state)",if dt . microsecond == 0 :,172
"def main(config): <TAB> with PathManager.open(config[""infile""], ""r"") as fin, PathManager.open( <TAB>  <TAB> config[""outfile""], ""w"" <TAB> ) as fout: <TAB>  <TAB> for line in fin.readlines(): <MASK> continue <TAB>  <TAB>  <TAB> first_space = line.index("" "") <TAB>  <TAB>  <TAB> first_tab = line.index(""\t"") <TAB>  <TAB>  <TAB> candidate = line[first_space + 1 : first_tab] <TAB>  <TAB>  <TAB> fout.write(candidate + ""\n"")","if ""persona"" in line :",133
"def compact_repr(record): <TAB> parts = [] <TAB> for key in record.__attributes__: <TAB>  <TAB> value = getattr(record, key) <TAB>  <TAB> if not value: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if isinstance(value, list): <TAB>  <TAB>  <TAB> value = HIDE_LIST <MASK> value = format_feats(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = repr(value) <TAB>  <TAB> value = capped_str(value) <TAB>  <TAB> parts.append(""%s=%s"" % (key, value)) <TAB> return ""%s(%s)"" % (record.__class__.__name__, "", "".join(parts))",elif key == FEATS :,152
"def make_chain(word): <TAB> which = 1 <TAB> while True: <TAB>  <TAB> songs = find_songs_that_start_with_word(word) <MASK> song = random.choice(songs) <TAB>  <TAB>  <TAB> print(which, song[""name""] + "" by "" + song[""artists""][0][""name""]) <TAB>  <TAB>  <TAB> which += 1 <TAB>  <TAB>  <TAB> word = song[""name""].lower().split()[-1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break",if len ( songs ) > 0 :,118
"def set_break(self, filename, lineno, temporary=False, cond=None, funcname=None): <TAB> if isinstance(funcname, str): <MASK> globals_ = globals() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> module = importlib.import_module(filename[:-3]) <TAB>  <TAB>  <TAB> globals_ = module.__dict__ <TAB>  <TAB> func = eval(funcname, globals_) <TAB>  <TAB> code = func.__code__ <TAB>  <TAB> filename = code.co_filename <TAB>  <TAB> lineno = code.co_firstlineno <TAB>  <TAB> funcname = code.co_name <TAB> res = super(Bdb, self).set_break( <TAB>  <TAB> filename, lineno, temporary=temporary, cond=cond, funcname=funcname <TAB> ) <TAB> if isinstance(res, str): <TAB>  <TAB> raise BdbError(res) <TAB> return res",if filename == __file__ :,192
"def __init__(self, shapefile=None, shapeType=POINT, autoBalance=1): <TAB> self.autoBalance = autoBalance <TAB> if not shapefile: <TAB>  <TAB> Writer.__init__(self, shapeType) <TAB> elif is_string(shapefile): <TAB>  <TAB> base = os.path.splitext(shapefile)[0] <MASK> r = Reader(base) <TAB>  <TAB>  <TAB> Writer.__init__(self, r.shapeType) <TAB>  <TAB>  <TAB> self._shapes = r.shapes() <TAB>  <TAB>  <TAB> self.fields = r.fields <TAB>  <TAB>  <TAB> self.records = r.records()","if os . path . isfile ( ""%s.shp"" % base ) :",157
"def test_env_not_set(self): <TAB> with mock.patch.dict(""os.environ""): <MASK> del os.environ[self.env_name] <TAB>  <TAB> self.assertEqual(helper.get_xdg_env(self.env_name, self.default), self.default)",if self . env_name in os . environ :,83
"def selection_only(self): <TAB> selection_only = False <TAB> sel = self.sel() <TAB> if (self.context == ""selection"" or self.context == ""both"") and len(sel): <TAB>  <TAB> # if multiple lines, always true <TAB>  <TAB> if len(sel) > 1: <TAB>  <TAB>  <TAB> selection_only = True <TAB>  <TAB> # check threshold <TAB>  <TAB> elif self.threshold and not sel[0].empty(): <TAB>  <TAB>  <TAB> text = self.view.substr(sel[0]) <TAB>  <TAB>  <TAB> match = re.search(self.threshold, text) <MASK> selection_only = True <TAB>  <TAB> # no valid selection <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> selection_only = False <TAB> return selection_only",if match :,174
"def __call__(self, rule, param): <TAB> p, g = param.data, param.grad <TAB> if p is None or g is None: <TAB>  <TAB> return <TAB> with chainer.using_device(param.device): <TAB>  <TAB> xp = param.device.xp <TAB>  <TAB> sign = xp.sign(p) <MASK> kernel = cuda.elementwise(""T s, T decay"", ""T g"", ""g += decay * s"", ""lasso"") <TAB>  <TAB>  <TAB> kernel(sign, self.rate, g) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> g += self.rate * sign",if xp is cuda . cupy :,144
"def map_packages(shutit_pexpect_session, package_str, install_type): <TAB> res = """" <TAB> for package in package_str.split(): <TAB>  <TAB> map_package_res = map_package(shutit_pexpect_session, package, install_type) <MASK> return res <TAB>  <TAB> res += "" "" + map_package_res <TAB> return res","if map_package_res == """" :",101
"def get_opnd_types_short(ii): <TAB> types = [] <TAB> for op in _gen_opnds(ii): <TAB>  <TAB> if op.oc2: <TAB>  <TAB>  <TAB> types.append(op.oc2) <TAB>  <TAB> elif op_luf_start(op, ""GPRv""): <TAB>  <TAB>  <TAB> types.append(""v"") <TAB>  <TAB> elif op_luf_start(op, ""GPRz""): <TAB>  <TAB>  <TAB> types.append(""z"") <MASK> types.append(""y"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> die(""Unhandled op type {}"".format(op)) <TAB> return types","elif op_luf_start ( op , ""GPRy"" ) :",161
"def _process_archive(self, archive_stream, subtitle): <TAB> for file_name in archive_stream.namelist(): <MASK> logger.info(""Found subtitle file %r"", file_name) <TAB>  <TAB>  <TAB> subtitle.content = fix_line_ending(archive_stream.read(file_name)) <TAB>  <TAB>  <TAB> if subtitle.is_valid(): <TAB>  <TAB>  <TAB>  <TAB> return","if file_name . lower ( ) . endswith ( ( "".srt"" , "".sub"" ) ) :",105
"def truncate(self, size=None): <TAB> # type: (Optional[int]) -> int <TAB> # Inefficient, but I don't know if truncate is possible with ftp <TAB> with self._lock: <TAB>  <TAB> if size is None: <TAB>  <TAB>  <TAB> size = self.tell() <TAB>  <TAB> with self.fs.openbin(self.path) as f: <TAB>  <TAB>  <TAB> data = f.read(size) <TAB>  <TAB> with self.fs.openbin(self.path, ""w"") as f: <TAB>  <TAB>  <TAB> f.write(data) <MASK> f.write(b""\0"" * (size - len(data))) <TAB> return size",if len ( data ) < size :,163
def wakeup(self): <TAB> try: <MASK> self.wm_withdraw() <TAB>  <TAB>  <TAB> self.wm_deiconify() <TAB>  <TAB> self.tkraise() <TAB>  <TAB> self.focused_widget.focus_set() <TAB> except TclError: <TAB>  <TAB> # This can happen when the window menu was torn off. <TAB>  <TAB> # Simply ignore it. <TAB>  <TAB> pass,"if self . wm_state ( ) == ""iconic"" :",109
"def locus_parser(self): <TAB> line = self.stream.readline() <TAB> while line != """": <TAB>  <TAB> line = line.rstrip() <TAB>  <TAB> match = re.match("" Locus: (.+)"", line) <MASK> locus = match.group(1) <TAB>  <TAB>  <TAB> alleles, table = _read_allele_freq_table(self.stream) <TAB>  <TAB>  <TAB> return locus, alleles, table <TAB>  <TAB> line = self.stream.readline() <TAB> self.done = True <TAB> raise StopIteration",if match is not None :,131
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_content(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 18: <TAB>  <TAB>  <TAB> self.set_blob_key(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 24: <TAB>  <TAB>  <TAB> self.set_width(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <MASK> self.set_height(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 32 :,182
"def concat_kernel_sources(self): <TAB> func_sources = OrderedDict() <TAB> for kernel in self.kernels: <TAB>  <TAB> for func_name, source in kernel.func_sources.items(): <MASK> assert func_sources[func_name] == source <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> func_sources[func_name] = source <TAB> self.generate_top_source() <TAB> self.generate_exec_source() <TAB> self.generate_init_source() <TAB> combined_source = ( <TAB>  <TAB> """".join(self.header_sources.values()) <TAB>  <TAB> + ""\n"".join(func_sources.values()) <TAB>  <TAB> + """".join(self.footer_sources.values()) <TAB> ) <TAB> return combined_source",if func_name in func_sources :,185
"def parseUnderindentTag(self, s): <TAB> tag = self.underindentEscapeString <TAB> s2 = s[len(tag) :] <TAB> # To be valid, the escape must be followed by at least one digit. <TAB> i = 0 <TAB> while i < len(s2) and s2[i].isdigit(): <TAB>  <TAB> i += 1 <TAB> if i > 0: <TAB>  <TAB> n = int(s2[:i]) <TAB>  <TAB> # Bug fix: 2012/06/05: remove any period following the count. <TAB>  <TAB> # This is a new convention. <MASK> i += 1 <TAB>  <TAB> return n, s2[i:] <TAB> else: <TAB>  <TAB> return 0, s","if i < len ( s2 ) and s2 [ i ] == ""."" :",178
"def load(self, data): <TAB> ckey = None <TAB> for key, val in _rx_cookie.findall(data): <TAB>  <TAB> if key.lower() in _c_keys: <TAB>  <TAB>  <TAB> if ckey: <TAB>  <TAB>  <TAB>  <TAB> self[ckey][key] = _unquote(val) <MASK> # RFC2109: NAMEs that begin with $ are reserved for other uses <TAB>  <TAB>  <TAB> # and must not be used by applications. <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self[key] = _unquote(val) <TAB>  <TAB>  <TAB> ckey = key","elif key [ 0 ] == ""$"" :",143
"def load_cases(full_path): <TAB> all_test_data = json.load(open(full_path), object_pairs_hook=OrderedDict) <TAB> for test_data in all_test_data: <TAB>  <TAB> given = test_data[""given""] <TAB>  <TAB> for case in test_data[""cases""]: <MASK> test_type = ""result"" <TAB>  <TAB>  <TAB> elif ""error"" in case: <TAB>  <TAB>  <TAB>  <TAB> test_type = ""error"" <TAB>  <TAB>  <TAB> elif ""bench"" in case: <TAB>  <TAB>  <TAB>  <TAB> test_type = ""bench"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise RuntimeError(""Unknown test type: %s"" % json.dumps(case)) <TAB>  <TAB>  <TAB> yield (given, test_type, case)","if ""result"" in case :",183
"def delete(self): <TAB> if not self.force and not self.exists(): <TAB>  <TAB> return [] <TAB> cmd = [""delete""] <TAB> if self.filename: <TAB>  <TAB> cmd.append(""--filename="" + self.filename) <TAB> else: <MASK> self.module.fail_json(msg=""resource required to delete without filename"") <TAB>  <TAB> cmd.append(self.resource) <TAB>  <TAB> if self.name: <TAB>  <TAB>  <TAB> cmd.append(self.name) <TAB>  <TAB> if self.label: <TAB>  <TAB>  <TAB> cmd.append(""--selector="" + self.label) <TAB>  <TAB> if self.all: <TAB>  <TAB>  <TAB> cmd.append(""--all"") <TAB>  <TAB> if self.force: <TAB>  <TAB>  <TAB> cmd.append(""--ignore-not-found"") <TAB> return self._execute(cmd)",if not self . resource :,189
"def validate_latex_theme_options(app: Sphinx, config: Config) -> None: <TAB> for key in list(config.latex_theme_options): <MASK> msg = __(""Unknown theme option: latex_theme_options[%r], ignored."") <TAB>  <TAB>  <TAB> logger.warning(msg % (key,)) <TAB>  <TAB>  <TAB> config.latex_theme_options.pop(key)",if key not in Theme . UPDATABLE_KEYS :,103
"def connectionLost(self, reason): <MASK> self.log.info( <TAB>  <TAB>  <TAB> ""WampRawSocketProtocol: connection lost: reason = '{0}'"".format(reason) <TAB>  <TAB> ) <TAB> try: <TAB>  <TAB> wasClean = isinstance(reason.value, ConnectionDone) <TAB>  <TAB> self._session.onClose(wasClean) <TAB> except Exception as e: <TAB>  <TAB> # silently ignore exceptions raised here .. <TAB>  <TAB> if self.factory.debug: <TAB>  <TAB>  <TAB> self.log.info( <TAB>  <TAB>  <TAB>  <TAB> ""WampRawSocketProtocol: ApplicationSession.onClose raised ({0})"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> e <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> self._session = None",if self . factory . debug :,172
"def parse(filename): <TAB> dead_links = [] <TAB> with open(filename, ""r"") as file_: <TAB>  <TAB> for line in file_.readlines(): <TAB>  <TAB>  <TAB> res = reference_line.search(line) <MASK> if not exists(res.group(1)): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> dead_links.append(res.group(1)) <TAB> return dead_links",if res :,96
"def is_speaker_at_session(self, session_id): <TAB> try: <TAB>  <TAB> session = ( <TAB>  <TAB>  <TAB> Session.query.filter(Session.speakers.any(Speaker.user_id == self.id)) <TAB>  <TAB>  <TAB> .filter(Session.id == session_id) <TAB>  <TAB>  <TAB> .one() <TAB>  <TAB> ) <MASK> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> except MultipleResultsFound: <TAB>  <TAB> return False <TAB> except NoResultFound: <TAB>  <TAB> return False",if session :,123
"def _validate_deployment_name(namespace): <TAB> # If missing,try come out with a name associated with the template name <TAB> if namespace.deployment_name is None: <TAB>  <TAB> template_filename = None <MASK> template_filename = namespace.template_file <TAB>  <TAB> if namespace.template_uri and urlparse(namespace.template_uri).scheme: <TAB>  <TAB>  <TAB> template_filename = urlsplit(namespace.template_uri).path <TAB>  <TAB> if template_filename: <TAB>  <TAB>  <TAB> template_filename = os.path.basename(template_filename) <TAB>  <TAB>  <TAB> namespace.deployment_name = os.path.splitext(template_filename)[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> namespace.deployment_name = ""deployment1""",if namespace . template_file and os . path . isfile ( namespace . template_file ) :,186
"def mro(cls): <TAB> if self.ready: <TAB>  <TAB> if cls.__name__ == ""B1"": <TAB>  <TAB>  <TAB> B2.__bases__ = (B1,) <MASK> B1.__bases__ = (B2,) <TAB> return type.mro(cls)","if cls . __name__ == ""B2"" :",76
"def mark_shard_complete(): <TAB> try: <TAB>  <TAB> marker.refresh_from_db() <TAB> except DeferIterationMarker.DoesNotExist: <TAB>  <TAB> logger.warning( <TAB>  <TAB>  <TAB> ""TaskMarker with ID: %s has vanished, cancelling task"", marker_id <TAB>  <TAB> ) <TAB>  <TAB> return <TAB> marker.shards_complete += 1 <TAB> marker.save() <TAB> if marker.shards_complete == marker.shard_count: <TAB>  <TAB> # Delete the marker if we were asked to <MASK> marker.delete() <TAB>  <TAB> defer(finalize, *args, _transactional=True, _queue=task_queue_name(), **kwargs)",if marker . delete_on_completion :,160
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> length = d.getVarInt32() <TAB>  <TAB>  <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB>  <TAB>  <TAB> d.skip(length) <TAB>  <TAB>  <TAB> self.add_public_certificate_list().TryMerge(tmp) <TAB>  <TAB>  <TAB> continue <MASK> self.set_max_client_cache_time_in_second(d.getVarInt64()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 16 :,181
"def check_free(self, payload): <TAB> # free_list: 'host=10.0.0.1', 'user=anonymous', 'host=10.0.0.7,user=test', ... <TAB> for m in self.free_list: <TAB>  <TAB> args = m.split("","", 1) <TAB>  <TAB> for arg in args: <TAB>  <TAB>  <TAB> k, v = arg.split(""="", 1) <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return True <TAB> return False",if payload [ k ] != v :,126
"def getInnerText(element): <TAB> # To mimic IE's 'innerText' property in the W3C DOM, we need to recursively <TAB> # concatenate all child text nodes (depth first). <TAB> text = """" <TAB> child = element.firstChild <TAB> while child: <MASK> text += getInnerText(child) <TAB>  <TAB> elif child.nodeValue: <TAB>  <TAB>  <TAB> text += child.nodeValue <TAB>  <TAB> child = child.nextSibling <TAB> return text",if child . nodeType == 1 :,119
"def get_complete_http(self): <TAB> finished = [] <TAB> c = self.connection.cursor() <TAB> rows = c.execute(""SELECT * FROM http WHERE complete=1"").fetchall() <TAB> for row in rows: <TAB>  <TAB> o = pickle.loads(row[""object""]) <TAB>  <TAB> uadat = c.execute(""SELECT * FROM ua WHERE parent_id=?"", (o.id,)).fetchall() <TAB>  <TAB> for ua in uadat: <TAB>  <TAB>  <TAB> uao = pickle.loads(ua[""object""]) <MASK> o.add_ua_data(uao) <TAB>  <TAB> finished.append(o) <TAB> c.close() <TAB> return finished",if uao is not None and uao . source_code is not None and o . source_code :,178
"def get_tools(self, found_files): <TAB> self.configured_by = {} <TAB> runners = [] <TAB> for tool_name in self.tools_to_run: <TAB>  <TAB> tool = tools.TOOLS[tool_name]() <TAB>  <TAB> config_result = tool.configure(self, found_files) <TAB>  <TAB> if config_result is None: <TAB>  <TAB>  <TAB> configured_by = None <TAB>  <TAB>  <TAB> messages = [] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> configured_by, messages = config_result <MASK> messages = [] <TAB>  <TAB> self.configured_by[tool_name] = configured_by <TAB>  <TAB> self.messages += messages <TAB>  <TAB> runners.append(tool) <TAB> return runners",if messages is None :,172
"def _yield_batches(self, keys): <TAB> while self._shuffling_buffer.can_retrieve(): <TAB>  <TAB> post_shuffled_row = self._shuffling_buffer.retrieve() <TAB>  <TAB> if not isinstance(post_shuffled_row, dict): <TAB>  <TAB>  <TAB> # This is for the case of batched reads. Here we restore back the <TAB>  <TAB>  <TAB> # dictionary format of records <TAB>  <TAB>  <TAB> post_shuffled_row = dict(zip(keys, post_shuffled_row)) <TAB>  <TAB> self._batch_acc.append(post_shuffled_row) <TAB>  <TAB> # Batch is ready? Collate and emmit <MASK> yield self.collate_fn(self._batch_acc) <TAB>  <TAB>  <TAB> self._batch_acc = []",if len ( self . _batch_acc ) == self . batch_size :,187
"def action_open_file_filtered_dialog(self, widget): <TAB> try: <TAB>  <TAB> fname = self.main_window.open_file_dialog( <TAB>  <TAB>  <TAB> title=""Open file with Toga"", <TAB>  <TAB>  <TAB> multiselect=False, <TAB>  <TAB>  <TAB> file_types=[""doc"", ""txt""], <TAB>  <TAB> ) <MASK> self.label.text = ""File to open:"" + fname <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.label.text = ""No file selected!"" <TAB> except ValueError: <TAB>  <TAB> self.label.text = ""Open file dialog was canceled""",if fname is not None :,143
"def validate_vars(env): <TAB> """"""Validate the PCH and PCHSTOP construction variables."""""" <TAB> if ""PCH"" in env and env[""PCH""]: <MASK> raise SCons.Errors.UserError( <TAB>  <TAB>  <TAB>  <TAB> ""The PCHSTOP construction must be defined if PCH is defined."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if not SCons.Util.is_String(env[""PCHSTOP""]): <TAB>  <TAB>  <TAB> raise SCons.Errors.UserError( <TAB>  <TAB>  <TAB>  <TAB> ""The PCHSTOP construction variable must be a string: %r"" <TAB>  <TAB>  <TAB>  <TAB> % env[""PCHSTOP""] <TAB>  <TAB>  <TAB> )","if ""PCHSTOP"" not in env :",156
"def page_func(page_num): <TAB> playlist = self._call_api( <TAB>  <TAB> ""product/playlist"", <TAB>  <TAB> show_id, <TAB>  <TAB> { <TAB>  <TAB>  <TAB> ""playListId"": playlist_id, <TAB>  <TAB>  <TAB> ""pageNumber"": page_num, <TAB>  <TAB>  <TAB> ""pageSize"": 30, <TAB>  <TAB>  <TAB> ""sorts"": [{""order"": ""DESC"", ""type"": ""SORTDATE""}], <TAB>  <TAB> }, <TAB> ) <TAB> for product in playlist.get(""productList"", {}).get(""products"", []): <TAB>  <TAB> product_url = product.get(""productUrl"", []).get(""url"") <MASK> continue <TAB>  <TAB> yield self.url_result( <TAB>  <TAB>  <TAB> product_url, ""Shahid"", str_or_none(product.get(""id"")), product.get(""title"") <TAB>  <TAB> )",if not product_url :,196
"def forward(self, x): <TAB> for rproj, conv in zip(self.residual_proj, self.conv_layers): <TAB>  <TAB> residual = x <TAB>  <TAB> x = conv(x) <TAB>  <TAB> if self.skip_connections: <MASK> residual = rproj(residual) <TAB>  <TAB>  <TAB> x = (x + residual) * self.residual_scale <TAB> return x",if rproj is not None :,104
"def _make_results_dir(self): <TAB> r""""""Makes directory for saving eqa-cnn-pretrain eval results."""""" <TAB> for s_type in [""rgb"", ""seg"", ""depth""]: <TAB>  <TAB> dir_name = self.config.RESULTS_DIR.format(split=""val"", type=s_type) <MASK> os.makedirs(dir_name)",if not os . path . isdir ( dir_name ) :,99
"def ignore_callback_errors(self, ignore): <TAB> EventEmitter.ignore_callback_errors.fset(self, ignore) <TAB> for emitter in self._emitters.values(): <TAB>  <TAB> if isinstance(emitter, EventEmitter): <TAB>  <TAB>  <TAB> emitter.ignore_callback_errors = ignore <MASK> emitter.ignore_callback_errors_all(ignore)","elif isinstance ( emitter , EmitterGroup ) :",95
"def cron_starter(*args: Any) -> None: <TAB> _tz = self.conf.timezone if timezone is None else timezone <TAB> while not self.should_stop: <TAB>  <TAB> await self.sleep(cron.secs_for_next(cron_format, _tz)) <MASK> should_run = not on_leader or self.is_leader() <TAB>  <TAB>  <TAB> if should_run: <TAB>  <TAB>  <TAB>  <TAB> with self.trace(shortlabel(fun), trace_enabled=traced): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> await fun(*args)",if not self . should_stop :,139
def rotateafter(self): <TAB> if self.i != self.previ: <TAB>  <TAB> i = self.parent.l.GetSelection() <MASK> self.parent.models[self.parent.l.GetString(i)].rot -= 5 * ( <TAB>  <TAB>  <TAB>  <TAB> self.i - self.previ <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self.previ = self.i <TAB>  <TAB> self.Refresh(),if i != wx . NOT_FOUND :,106
"def select(model, path, iter_, paths_): <TAB> (paths, first) = paths_ <TAB> value = model.get_value(iter_) <TAB> if value is None: <TAB>  <TAB> return not bool(paths) <TAB> value = normalize_path(value) <TAB> if value in paths: <TAB>  <TAB> self.get_child().get_selection().select_path(path) <TAB>  <TAB> paths.remove(value) <TAB>  <TAB> if not first: <TAB>  <TAB>  <TAB> self.get_child().set_cursor(path) <TAB>  <TAB>  <TAB> # copy treepath, gets invalid after the callback <TAB>  <TAB>  <TAB> first.append(path.copy()) <TAB> else: <TAB>  <TAB> for fpath in paths: <MASK> self.get_child().expand_row(path, False) <TAB> return not bool(paths)",if fpath . startswith ( value ) :,194
"def read_logs_file(logs_path) -> List[V1Log]: <TAB> if not os.path.exists(logs_path): <TAB>  <TAB> return [] <TAB> async with aiofiles.open(logs_path, mode=""r"") as f: <TAB>  <TAB> contents = await f.read() <TAB>  <TAB> if contents: <TAB>  <TAB>  <TAB> # Version handling <MASK> return V1Logs.read_csv(contents).logs <TAB>  <TAB>  <TAB> # Legacy logs <TAB>  <TAB>  <TAB> logs = V1Logs.read(contents) <TAB>  <TAB>  <TAB> return logs.logs <TAB> return []","if "".plx"" in logs_path :",145
"def adjust_sockets(self): <TAB> variables = self.get_variables() <TAB> for key in self.inputs.keys(): <MASK> self.debug( <TAB>  <TAB>  <TAB>  <TAB> ""Input {} not in variables {}, remove it"".format(key, str(variables)) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.inputs.remove(self.inputs[key]) <TAB> for v in variables: <TAB>  <TAB> if v not in self.inputs: <TAB>  <TAB>  <TAB> self.debug( <TAB>  <TAB>  <TAB>  <TAB> ""Variable {} not in inputs {}, add it"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> v, str(self.inputs.keys()) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.inputs.new(""SvStringsSocket"", v)","if key not in variables and key not in [ ""Field"" ] :",183
"def run(self): <TAB> while self.running: <TAB>  <TAB> cmd = self.cmds.get() <MASK> break <TAB>  <TAB> elif cmd == ""clear"": <TAB>  <TAB>  <TAB> dead_tasks = [] <TAB>  <TAB>  <TAB> for task in self.tasks: <TAB>  <TAB>  <TAB>  <TAB> if task.status == Task.FINISH or task.status == Task.ERROR: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> dead_tasks.append(task) <TAB>  <TAB>  <TAB> for dead_task in dead_tasks: <TAB>  <TAB>  <TAB>  <TAB> self.tasks.remove(dead_task)","if cmd == ""stop"" :",131
"def process(self, node): <TAB> self.vars = [] <TAB> for child in node.childNodes: <TAB>  <TAB> if child.nodeType == node.ELEMENT_NODE: <TAB>  <TAB>  <TAB> child_text = get_xml_text(child) <TAB>  <TAB>  <TAB> if child_text == """":  # pragma:nocover <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> for val in re.split(""[\t ]+"", child_text): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.vars.append(1.0 * eval(val)) <TAB> return self","if child . nodeName == ""Real"" :",135
"def drain(self, fd): <TAB> """"""Make `fd` unreadable."""""" <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if not os.read(fd, 4096): <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> e = sys.exc_info()[1] <MASK> return <TAB>  <TAB>  <TAB> raise",if e . args [ 0 ] == errno . EAGAIN :,97
"def parse(s): <TAB> """"""Parse the output below to create a new StopWatch."""""" <TAB> stopwatch = StopWatch() <TAB> for line in s.splitlines(): <MASK> parts = line.split(None) <TAB>  <TAB>  <TAB> name = parts[0] <TAB>  <TAB>  <TAB> if name != ""%"":  # ie not the header line <TAB>  <TAB>  <TAB>  <TAB> rest = (float(v) for v in parts[2:]) <TAB>  <TAB>  <TAB>  <TAB> stopwatch.times[parts[0]].merge(Stat.build(*rest)) <TAB> return stopwatch",if line . strip ( ) :,128
"def delete(identifier, filenames=None, **kwargs): <TAB> item = get_item(identifier) <TAB> if filenames: <MASK> filenames = [filenames] <TAB>  <TAB> for f in item.iter_files(): <TAB>  <TAB>  <TAB> if f.name not in filenames: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> f.delete(**kwargs)","if not isinstance ( filenames , ( set , list ) ) :",91
"def _get_absolute_timeout(self, timeout): <TAB> if timeout is Timeout.DEFAULT_TIMEOUT: <TAB>  <TAB> return 5  # 5s is the default timeout for URLFetch. <TAB> if isinstance(timeout, Timeout): <MASK> warnings.warn( <TAB>  <TAB>  <TAB>  <TAB> ""URLFetch does not support granular timeout settings, "" <TAB>  <TAB>  <TAB>  <TAB> ""reverting to total timeout."", <TAB>  <TAB>  <TAB>  <TAB> AppEnginePlatformWarning, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return timeout.total <TAB> return timeout",if timeout . read is not timeout . connect :,124
"def _add_annotation_to_imports( <TAB> self, annotation: cst.Attribute) -> Union[cst.Name, cst.Attribute]: <TAB> key = get_full_name_for_node(annotation.value) <TAB> if key is not None: <TAB>  <TAB> # Don't attempt to re-import existing imports. <TAB>  <TAB> if key in self.existing_imports: <TAB>  <TAB>  <TAB> return annotation <TAB>  <TAB> import_name = get_full_name_for_node(annotation.attr) <MASK> AddImportsVisitor.add_needed_import(self.context, key, import_name) <TAB> return annotation.attr",if import_name is not None :,156
"def unique_definitions(cls, defns): <TAB> """"""Takes a collection of defns and returns the unique list of defns."""""" <TAB> unique_defns = [] <TAB> for defn in defns: <TAB>  <TAB> for unique_defn in unique_defns: <MASK> # defn is already in the unique_defn list. <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> unique_defns.append(defn) <TAB> return unique_defns",if unique_defn . path == defn . path and unique_defn == defn :,126
"def store_data(self, store_loc, **kwargs): <TAB> """"""Put arrays to store"""""" <TAB> # print(store_loc) <TAB> g = self.store.create_group(store_loc) <TAB> for ( <TAB>  <TAB> k, <TAB>  <TAB> v, <TAB> ) in kwargs.items(): <TAB>  <TAB> # print(type(v[0])) <TAB>  <TAB> # print(k) <MASK> if len(v) != 0: <TAB>  <TAB>  <TAB>  <TAB> if type(v[0]) is np.str_ or type(v[0]) is str: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> v = [a.encode(""utf8"") for a in v] <TAB>  <TAB> g.create_dataset(k, data=v, compression=self.clib, compression_opts=self.clev)",if type ( v ) == list :,191
"def connect_to_uri(self, uri, autoconnect=None, do_start=True): <TAB> try: <TAB>  <TAB> conn = self._check_conn(uri) <TAB>  <TAB> if not conn: <TAB>  <TAB>  <TAB> # Unknown connection, add it <TAB>  <TAB>  <TAB> conn = self.add_conn(uri) <MASK> conn.set_autoconnect(bool(autoconnect)) <TAB>  <TAB> self.show_manager() <TAB>  <TAB> if do_start: <TAB>  <TAB>  <TAB> conn.open() <TAB>  <TAB> return conn <TAB> except Exception: <TAB>  <TAB> logging.exception(""Error connecting to %s"", uri) <TAB>  <TAB> return None",if autoconnect is not None :,152
"def fn(n): <TAB> while n < 3: <TAB>  <TAB> if n < 0: <TAB>  <TAB>  <TAB> yield ""less than zero"" <MASK> yield ""zero"" <TAB>  <TAB> elif n == 1: <TAB>  <TAB>  <TAB> yield ""one"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield ""more than one"" <TAB>  <TAB> n += 1",elif n == 0 :,84
"def closeEvent(self, e): <TAB> self.common.log(""MainWindow"", ""closeEvent"") <TAB> if self.tabs.are_tabs_active(): <TAB>  <TAB> # Open the warning dialog <TAB>  <TAB> self.common.log(""MainWindow"", ""closeEvent, opening warning dialog"") <TAB>  <TAB> self.close_dialog.exec_() <TAB>  <TAB> # Close <MASK> self.system_tray.hide() <TAB>  <TAB>  <TAB> e.accept() <TAB>  <TAB> # Cancel <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> e.ignore() <TAB>  <TAB> return <TAB> self.system_tray.hide() <TAB> e.accept()",if self . close_dialog . clickedButton ( ) == self . close_dialog . accept_button :,165
"def _stop_child_activities(self, name=None): <TAB> """"""Stop all child activities spawn by this activity."""""" <TAB> # Makes a list copy of items() to avoid dictionary size changed <TAB> # during iteration <TAB> for child_name, child in list(self._child_activity_map.items()): <MASK> continue <TAB>  <TAB> LOG.debug(""%s: Stopping child activity %s "", self.name, child_name) <TAB>  <TAB> if child.started: <TAB>  <TAB>  <TAB> child.stop() <TAB>  <TAB> self._child_activity_map.pop(child_name, None)",if name is not None and name != child_name :,150
"def add_libdirs(self, envvar, sep, fatal=False): <TAB> v = os.environ.get(envvar) <TAB> if not v: <TAB>  <TAB> return <TAB> for dir in str.split(v, sep): <TAB>  <TAB> dir = str.strip(dir) <TAB>  <TAB> if not dir: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> dir = os.path.normpath(dir) <TAB>  <TAB> if os.path.isdir(dir): <TAB>  <TAB>  <TAB> if not dir in self.library_dirs: <TAB>  <TAB>  <TAB>  <TAB> self.library_dirs.append(dir) <MASK> fail(""FATAL: bad directory %s in environment variable %s"" % (dir, envvar))",elif fatal :,159
"def _serialize_list(array, previous): <TAB> array = array or [] <TAB> previous = previous or [] <TAB> params = {} <TAB> for i, v in enumerate(array): <TAB>  <TAB> previous_item = previous[i] if len(previous) > i else None <MASK> params[str(i)] = v.serialize(previous_item) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> params[str(i)] = _compute_diff(v, previous_item) <TAB> return params","if hasattr ( v , ""serialize"" ) :",122
"def list_bucket(self, prefix="""", delimiter="""", headers=None, all_versions=False): <TAB> self._check_bucket_uri(""list_bucket"") <TAB> bucket = self.get_bucket(headers=headers) <TAB> if all_versions: <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB> v <TAB>  <TAB>  <TAB> for v in bucket.list_versions( <TAB>  <TAB>  <TAB>  <TAB> prefix=prefix, delimiter=delimiter, headers=headers <TAB>  <TAB>  <TAB> ) <MASK> ) <TAB> else: <TAB>  <TAB> return bucket.list(prefix=prefix, delimiter=delimiter, headers=headers)","if not isinstance ( v , DeleteMarker )",142
"def writeattr(stream, text): <TAB> countdouble = text.count('""') <TAB> if countdouble: <TAB>  <TAB> countsingle = text.count(""'"") <MASK> entities = {'""': ""&quot;""} <TAB>  <TAB>  <TAB> quote = '""' <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> entities = {""'"": ""&apos;""} <TAB>  <TAB>  <TAB> quote = ""'"" <TAB> else: <TAB>  <TAB> entities = {} <TAB>  <TAB> quote = '""' <TAB> stream.write(quote) <TAB> writetext(stream, text, entities) <TAB> stream.write(quote)",if countdouble <= countsingle :,133
"def __gt__(self, other): <TAB> if not isinstance(other, self.__class__): <TAB>  <TAB> other = self.__class__(other) <TAB> for part, value in self.parts: <TAB>  <TAB> other_value = other[part] <TAB>  <TAB> if part in LETTERS: <TAB>  <TAB>  <TAB> cmp = self._cmp_part(value or ""z"", other_value or ""z"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> cmp = self._cmp_part(value, other_value) <MASK> continue <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return cmp == 1 <TAB> return False",if cmp == 0 :,141
"def _concretize(self, n_cls, t1, t2, join_or_meet, translate): <TAB> ptr_class = self._pointer_class() <TAB> if n_cls is ptr_class: <TAB>  <TAB> if isinstance(t1, ptr_class) and isinstance(t2, ptr_class): <TAB>  <TAB>  <TAB> # we need to merge them <TAB>  <TAB>  <TAB> return ptr_class(join_or_meet(t1.basetype, t2.basetype, translate)) <MASK> return t1 <TAB>  <TAB> elif isinstance(t2, ptr_class): <TAB>  <TAB>  <TAB> return t2 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # huh? <TAB>  <TAB>  <TAB> return ptr_class(BottomType()) <TAB> return n_cls()","if isinstance ( t1 , ptr_class ) :",181
"def __init__(self, items=None): <TAB> super().__init__() <TAB> self.include_dirs = [] <TAB> self._add_member(""src_files"", FileList, ""C source files for VPI library"") <TAB> self._add_member(""include_files"", FileList, ""C include files for VPI library"") <TAB> self._add_member( <TAB>  <TAB> ""libs"", StringList, ""External libraries linked with the VPI library"" <TAB> ) <TAB> if items: <TAB>  <TAB> self.load_dict(items) <MASK> self.include_dirs += unique_dirs(self.include_files) <TAB>  <TAB> self.export_files = self.src_files + self.include_files",if self . include_files :,171
"def __init__(self, parent_element): <TAB> if parent_element.items(): <TAB>  <TAB> self.update(dict(parent_element.items())) <TAB> for element in parent_element: <TAB>  <TAB> if len(element) > 0: <TAB>  <TAB>  <TAB> if element.tag == element[0].tag: <TAB>  <TAB>  <TAB>  <TAB> aDict = ListParser(element) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> aDict = DictParser(element) <MASK> aDict.update(dict(element.items())) <TAB>  <TAB>  <TAB> self.update({element.tag: aDict}) <TAB>  <TAB> elif element.items(): <TAB>  <TAB>  <TAB> self.update({element.tag: dict(element.items())}) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.update({element.tag: element.text})",if element . items ( ) :,190
"def _shares_in_results(data): <TAB> shares_in_device, shares_in_subdevice = False, False <TAB> for plugin_name, plugin_result in data.iteritems(): <TAB>  <TAB> if plugin_result[""status""] == ""error"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if ""device"" not in plugin_result: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if ""disk_shares"" in plugin_result[""device""]: <TAB>  <TAB>  <TAB> shares_in_device = True <TAB>  <TAB> for subdevice in plugin_result[""device""].get(""subdevices"", []): <MASK> shares_in_subdevice = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return shares_in_device, shares_in_subdevice","if ""disk_shares"" in subdevice :",175
"def decorator(self, command, *args, **kwargs): <TAB> if required_keys: <TAB>  <TAB> missing_keys = diff_keys(required_keys, command) <MASK> raise InvalidCommand( <TAB>  <TAB>  <TAB>  <TAB> ""Command missing %s of required"" <TAB>  <TAB>  <TAB>  <TAB> "" keys %s"" % (missing_keys, required_keys) <TAB>  <TAB>  <TAB> ) <TAB> return func(self, command, *args, **kwargs)",if missing_keys :,107
"def xml(self): <TAB> out = [""<spreadsheet>""] <TAB> for (x, y), cell in self.cells.items(): <MASK> cellxml = cell.xml() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> cellxml = ""<value>%s</value>"" % escape(cell) <TAB>  <TAB> out.append('<cell row=""%s"" col=""%s"">\n  %s\n</cell>' % (y, x, cellxml)) <TAB> out.append(""</spreadsheet>"") <TAB> return ""\n"".join(out)","if hasattr ( cell , ""xml"" ) :",127
"def speed_tester_d(self, uid): <TAB> if uid not in self._speed_tester_d: <MASK> # TODO <TAB>  <TAB>  <TAB> self._speed_tester_d[uid] = SpeedTester( <TAB>  <TAB>  <TAB>  <TAB> self._config.get(""speed_limit_per_user"", 0) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._speed_tester_d[uid] = SpeedTester( <TAB>  <TAB>  <TAB>  <TAB> self._config.get(""speed_limit_per_user"", 0) <TAB>  <TAB>  <TAB> ) <TAB> return self._speed_tester_d[uid]",if self . mu :,143
"def process_error(self, data): <TAB> error = data.get(""error"") <TAB> if error: <MASK> raise AuthCanceled(self) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise AuthUnknownError(self, ""Jawbone error was {0}"".format(error)) <TAB> return super().process_error(data)","if error == ""access_denied"" :",86
"def _do_test_fetch_result(self, results, remote): <TAB> # self._print_fetchhead(remote.repo) <TAB> self.assertGreater(len(results), 0) <TAB> self.assertIsInstance(results[0], FetchInfo) <TAB> for info in results: <TAB>  <TAB> self.assertIsInstance(info.note, string_types) <MASK> self.assertTrue(info.flags) <TAB>  <TAB> # END reference type flags handling <TAB>  <TAB> self.assertIsInstance(info.ref, (SymbolicReference, Reference)) <TAB>  <TAB> if info.flags & (info.FORCED_UPDATE | info.FAST_FORWARD): <TAB>  <TAB>  <TAB> self.assertIsInstance(info.old_commit, Commit) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertIsNone(info.old_commit)","if isinstance ( info . ref , Reference ) :",186
"def init_ftp_server(self): <TAB> if self.get_config(""ftpd"", ""enabled"", False, boolean=True): <TAB>  <TAB> accountfile = from_utf8_or_none(self.get_config(""ftpd"", ""accounts.file"", None)) <MASK> accountfile = abspath_expanduser_unicode(accountfile, base=self.basedir) <TAB>  <TAB> accounturl = self.get_config(""ftpd"", ""accounts.url"", None) <TAB>  <TAB> ftp_portstr = self.get_config(""ftpd"", ""port"", ""8021"") <TAB>  <TAB> from allmydata.frontends import ftpd <TAB>  <TAB> s = ftpd.FTPServer(self, accountfile, accounturl, ftp_portstr) <TAB>  <TAB> s.setServiceParent(self)",if accountfile :,190
"def configured_request_log_handlers(config, prefix=""query_log"", default_logger=None): <TAB> """"""Returns configured query loggers as defined in the `config`."""""" <TAB> handlers = [] <TAB> for section in config.sections(): <TAB>  <TAB> if section.startswith(prefix): <TAB>  <TAB>  <TAB> options = dict(config.items(section)) <TAB>  <TAB>  <TAB> type_ = options.pop(""type"") <MASK> logger = default_logger or get_logger() <TAB>  <TAB>  <TAB>  <TAB> handler = ext.request_log_handler(""default"", logger) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> handler = ext.request_log_handler(type_, **options) <TAB>  <TAB>  <TAB> handlers.append(handler) <TAB> return handlers","if type_ == ""default"" :",174
"def string(self): <TAB> """"""Returns a PlayString in string format from the Patterns values"""""" <TAB> string = """" <TAB> for item in self.data: <TAB>  <TAB> if isinstance(item, (PGroup, GeneratorPattern)): <TAB>  <TAB>  <TAB> string += item.string() <MASK> string += ( <TAB>  <TAB>  <TAB>  <TAB> ""("" <TAB>  <TAB>  <TAB>  <TAB> + """".join( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> (s.string() if hasattr(s, ""string"") else str(s)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for s in item.data <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> + "")"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> string += str(item) <TAB> return string","elif isinstance ( item , Pattern ) :",183
"def locked_deps(package, poetry): <TAB> reqs = [] <TAB> packages = poetry.locker.locked_repository(False).packages <TAB> for p in packages: <TAB>  <TAB> dep = p.to_dependency() <TAB>  <TAB> line = ""{}=={}"".format(p.name, p.version) <TAB>  <TAB> requirement = dep.to_pep_508() <MASK> line += ""; {}"".format(requirement.split("";"")[1].strip()) <TAB>  <TAB> reqs.append(line) <TAB> return reqs, defaultdict(list)","if "";"" in requirement :",132
"def _paste_columns(self, topleft_corner, columns): <TAB> starting_column = topleft_corner[1] <TAB> number_of_columns = self.number_of_columns() <TAB> for index, column in enumerate(columns): <TAB>  <TAB> set_index = starting_column + index <MASK> self.set_column_at(set_index, column, starting=topleft_corner[0]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> real_column = [constants.DEFAULT_NA] * topleft_corner[0] <TAB>  <TAB>  <TAB> real_column += column <TAB>  <TAB>  <TAB> self.extend_columns([real_column]) <TAB> self.__width, self.__array = uniform(self.__array)",if set_index < number_of_columns :,172
"def check_objects_exist(self, compare_id, raise_exc=True): <TAB> for uid in convert_compare_id_to_list(compare_id): <TAB>  <TAB> if not self.existence_quick_check(uid): <MASK> raise FactCompareException(""{} not found in database"".format(uid)) <TAB>  <TAB>  <TAB> return True <TAB> return False",if raise_exc :,94
"def __add__(self, other): <TAB> if hasattr(other, ""unit_type""): <MASK> raise UnitError(""Adding different types of units is"" "" not allowed"") <TAB>  <TAB> if other.unit != self.unit: <TAB>  <TAB>  <TAB> other = other.to(self.unit) <TAB> return self.__class__( <TAB>  <TAB> np.array(self) + np.array(other), unit_type=self.unit_type, unit=self.unit <TAB> )",if other . unit_type != self . unit_type :,123
"def extract(self, tar): <TAB> max_nb = maxNbFile(self) <TAB> for index, field in enumerate(tar.array(""file"")): <MASK> self.warning( <TAB>  <TAB>  <TAB>  <TAB> ""TAR archive contains many files, but only first %s files are processed"" <TAB>  <TAB>  <TAB>  <TAB> % max_nb <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> meta = Metadata(self) <TAB>  <TAB> self.extractFile(field, meta) <TAB>  <TAB> if meta.has(""filename""): <TAB>  <TAB>  <TAB> title = _('File ""%s""') % meta.getText(""filename"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> title = _(""File"") <TAB>  <TAB> self.addGroup(field.name, meta, title)",if max_nb is not None and max_nb <= index :,180
"def task_management_menu(activation, request): <TAB> """"""Available tasks actions."""""" <TAB> actions = [] <TAB> if request.user.has_perm(activation.flow_class._meta.manage_permission_name): <TAB>  <TAB> for transition in activation.get_available_transitions(): <MASK> url = activation.flow_task.get_task_url( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> activation.task, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> transition.name, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> user=request.user, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> namespace=request.resolver_match.namespace, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> if url: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> actions.append((transition.name.replace(""_"", "" "").title(), url)) <TAB> return {""actions"": actions, ""request"": request}",if transition . can_proceed ( activation ) :,192
"def handle_default_mac_address(facts): <TAB> for suffix in ("""", ""_eth0"", ""_igb0"", ""_bnx0"", ""_bge0"", ""_nfo0"", ""_nge0""): <TAB>  <TAB> mac = facts.get(""macaddress{}"".format(suffix)) <TAB>  <TAB> if mac: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> result = MACAddressField.normalize(mac) <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB>  <TAB> return result",if result [ : 6 ] in MAC_PREFIX_BLACKLIST :,131
"def run(self): <TAB> consumer = KafkaConsumer( <TAB>  <TAB> bootstrap_servers=""localhost:9092"", auto_offset_reset=""earliest"" <TAB> ) <TAB> consumer.subscribe([""my-topic""]) <TAB> self.valid = 0 <TAB> self.invalid = 0 <TAB> for message in consumer: <MASK> self.valid += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.invalid += 1 <TAB>  <TAB> if consumer_stop.is_set(): <TAB>  <TAB>  <TAB> break <TAB> consumer.close()",if len ( message . value ) == msg_size :,136
"def createFields(self, fields): <TAB> self.destroyFields() <TAB> for name, label, args in fields: <TAB>  <TAB> kwargs = dict(validator=_TransferValidator(name)) <MASK> kwargs.update(args) <TAB>  <TAB> stxt = wx.StaticText(self, -1, label) <TAB>  <TAB> txt = wx.TextCtrl(self, **kwargs) <TAB>  <TAB> self._contentSizer.Add(stxt, 0, wx.ALIGN_CENTER_VERTICAL | wx.ALIGN_RIGHT) <TAB>  <TAB> self._contentSizer.Add(txt, 0, wx.EXPAND) <TAB>  <TAB> self.__dict__[name] = """" <TAB>  <TAB> self._fields[name] = (stxt, txt)",if args :,162
def poll_kafka(self): <TAB> while True: <TAB>  <TAB> val = self.do_poll() <TAB>  <TAB> if val: <TAB>  <TAB>  <TAB> yield self._emit(val) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield gen.sleep(self.poll_interval) <MASK> break <TAB> self._close_consumer(),if self . stopped :,85
"def _generate_toc(line): <TAB> while 1: <TAB>  <TAB> if line.startswith(""2""): <TAB>  <TAB>  <TAB> line = 5 <TAB>  <TAB>  <TAB> while 1: <MASK> line = 6 <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB>  <TAB> elif not line: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> line = 7 <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif not line: <TAB>  <TAB>  <TAB> break <TAB> return 1",if line :,103
"def find_script(scriptId_or_file_or_url): <TAB> # sha = hashlib.sha1(scriptId_or_file_or_url.encode('utf-8')).hexdigest() <TAB> for item in file_to_scriptId: <TAB>  <TAB> if item[""scriptId""].lower() == scriptId_or_file_or_url.lower(): <TAB>  <TAB>  <TAB> return item[""file""] <MASK> return item[""scriptId""] <TAB>  <TAB> if item[""url""].lower() == scriptId_or_file_or_url.lower(): <TAB>  <TAB>  <TAB> return item[""scriptId""] <TAB> return None","if item [ ""file"" ] . lower ( ) == scriptId_or_file_or_url . lower ( ) :",165
"def __get_impute_number(some_data): <TAB> impute_num_list = None <TAB> data_size = None <TAB> for line in some_data: <TAB>  <TAB> processed_data = line[1][0] <TAB>  <TAB> index_list = line[1][1] <MASK> data_size = len(processed_data) <TAB>  <TAB>  <TAB> # data_size + 1, the last element of impute_num_list used to count the number of ""some_data"" <TAB>  <TAB>  <TAB> impute_num_list = [0 for _ in range(data_size + 1)] <TAB>  <TAB> impute_num_list[data_size] += 1 <TAB>  <TAB> for index in index_list: <TAB>  <TAB>  <TAB> impute_num_list[index] += 1 <TAB> return np.array(impute_num_list)",if not data_size :,200
"def get_shipping_address(self): <TAB> """"""Returns Address object from shipping address fields if present"""""" <TAB> # shipping address fields can be `shipping_address_name` or `shipping_address` <TAB> # try getting value from both <TAB> for fieldname in (""shipping_address_name"", ""shipping_address""): <TAB>  <TAB> shipping_field = self.meta.get_field(fieldname) <TAB>  <TAB> if shipping_field and shipping_field.fieldtype == ""Link"": <MASK> return frappe.get_doc(""Address"", self.get(fieldname)) <TAB> return {}",if self . get ( fieldname ) :,141
"def _get_spawn_property(self, constraints, constraint_name, services): <TAB> if services: <TAB>  <TAB> # this isn't very nice <MASK> return services[0].image <TAB>  <TAB> elif constraint_name == CPUS_CONSTRAINT: <TAB>  <TAB>  <TAB> return services[0].cpus <TAB> for constraint in constraints: <TAB>  <TAB> if constraint.name == constraint_name: <TAB>  <TAB>  <TAB> return constraint.value <TAB> return None",if constraint_name == IMAGE_CONSTRAINT :,113
"def latest_extra_data(self, extra_dirs=None): <TAB> base_name = os.path.splitext(os.path.basename(self.file_name))[0] <TAB> extra_dirs.append(self.board.GetPlotOptions().GetOutputDirectory()) <TAB> file_dir_name = os.path.dirname(self.file_name) <TAB> directories = [ <TAB>  <TAB> file_dir_name, <TAB> ] <TAB> for dir in extra_dirs: <TAB>  <TAB> if not os.path.isabs(dir): <TAB>  <TAB>  <TAB> dir = os.path.join(file_dir_name, dir) <MASK> directories.append(dir) <TAB> return find_latest_schematic_data(base_name, directories)",if os . path . exists ( dir ) :,181
"def _checkForLeftRightModifiers(cls, mod_state): <TAB> mod_value = 0 <TAB> mod_strs = [] <TAB> for k, v in cls._OS_MODIFIERS: <MASK> mod_value += KeyboardConstants._modifierCodes.getID(v) <TAB>  <TAB>  <TAB> mod_strs.append(modifier_name_mappings.get(v, ""MISSING_MOD_NAME"")) <TAB> return mod_value, mod_strs",if mod_state & k > 0 :,116
"def _decode_pattern_list(data): <TAB> rv = [] <TAB> contains_dict = False <TAB> for item in data: <MASK> item = _decode_pattern_list(item) <TAB>  <TAB> elif isinstance(item, dict): <TAB>  <TAB>  <TAB> item = _decode_pattern_dict(item) <TAB>  <TAB>  <TAB> contains_dict = True <TAB>  <TAB> rv.append(item) <TAB> # avoid sorting if any element in the list is a dict <TAB> if not contains_dict: <TAB>  <TAB> rv = sorted(rv) <TAB> return rv","if isinstance ( item , list ) :",133
"def get_blob(self, blobname, ctlr=None, specific_dir=None): <TAB> self._acquire_lock() <TAB> try: <TAB>  <TAB> dbsubpath = self._dbsubpath_from_blobname( <TAB>  <TAB>  <TAB> blobname, ctlr=ctlr, specific_dir=specific_dir <TAB>  <TAB> ) <MASK> return self.lang_zone.load_blob(dbsubpath) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return None <TAB> finally: <TAB>  <TAB> self._release_lock()",if dbsubpath is not None :,126
"def get_tasks(self): <TAB> for task in asyncio.all_tasks(loop=self.middleware.loop): <TAB>  <TAB> formatted = None <TAB>  <TAB> frame = None <TAB>  <TAB> frames = [] <TAB>  <TAB> for frame in task.get_stack(): <TAB>  <TAB>  <TAB> cur_frame = get_frame_details(frame, self.logger) <TAB>  <TAB>  <TAB> if cur_frame: <TAB>  <TAB>  <TAB>  <TAB> frames.append(cur_frame) <MASK> formatted = traceback.format_stack(frame) <TAB>  <TAB> yield { <TAB>  <TAB>  <TAB> ""stack"": formatted, <TAB>  <TAB>  <TAB> ""frames"": frames, <TAB>  <TAB> }",if frame :,146
"def main(args): <TAB> optim = Adam({""lr"": args.lr}) <TAB> elbo = JitTrace_ELBO() if args.jit else Trace_ELBO() <TAB> svi = SVI(model, guide, optim, loss=elbo) <TAB> pyro.clear_param_store() <TAB> for j in range(args.num_epochs): <TAB>  <TAB> loss = svi.step(data) <MASK> logging.info(""[epoch %04d] loss: %.4f"" % (j + 1, loss)) <TAB> for name, value in pyro.get_param_store().items(): <TAB>  <TAB> logging.info(name) <TAB>  <TAB> logging.info(value.detach().cpu().numpy())",if j % 100 == 0 :,174
"def create_var_list(scope, var_lists, shape): <TAB> vars = [] <TAB> for idx, v in enumerate(var_lists): <TAB>  <TAB> name = ""{}_{}"".format(scope, idx) <MASK> var = fluid.data(name, shape=v.shape) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> var = fluid.data(name, shape=shape + list(v[0].shape)) <TAB>  <TAB> var.stop_gradient = False <TAB>  <TAB> vars.append(var) <TAB> return vars",if shape is None :,126
"def dr_relation(self, C, trans, nullable): <TAB> dr_set = {} <TAB> state, N = trans <TAB> terms = [] <TAB> g = self.lr0_goto(C[state], N) <TAB> for p in g: <TAB>  <TAB> if p.lr_index < p.len - 1: <TAB>  <TAB>  <TAB> a = p.prod[p.lr_index + 1] <MASK> if a not in terms: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> terms.append(a) <TAB> # This extra bit is to handle the start state <TAB> if state == 0 and N == self.grammar.Productions[0].prod[0]: <TAB>  <TAB> terms.append(""$end"") <TAB> return terms",if a in self . grammar . Terminals :,174
"def get_field_values(self, fields): <TAB> field_values = [] <TAB> for field in fields: <TAB>  <TAB> # Title is special case <MASK> value = self.get_title_display() <TAB>  <TAB> elif field == ""country"": <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> value = self.country.printable_name <TAB>  <TAB>  <TAB> except exceptions.ObjectDoesNotExist: <TAB>  <TAB>  <TAB>  <TAB> value = """" <TAB>  <TAB> elif field == ""salutation"": <TAB>  <TAB>  <TAB> value = self.salutation <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = getattr(self, field) <TAB>  <TAB> field_values.append(value) <TAB> return field_values","if field == ""title"" :",158
"def run(self, event, lambda_context): <TAB> self.setup_exec_environment(event) <TAB> resource_sets = self.get_resource_sets(event) <TAB> result_sets = {} <TAB> for (account_id, region), rarns in resource_sets.items(): <TAB>  <TAB> self.assume_member({""account"": account_id, ""region"": region}) <TAB>  <TAB> resources = self.resolve_resources(event) <TAB>  <TAB> rset = result_sets.setdefault((account_id, region), []) <MASK> rset.extend(self.run_resource_set(event, resources)) <TAB> return result_sets",if resources :,151
"def read(self, sock): <TAB> data = self.sock.recv(64 * 1024) <TAB> ready_to_read, ready_to_write, in_error = select.select( <TAB>  <TAB> [self.sock], [], [], self.timeout <TAB> ) <TAB> while len(ready_to_read) == 1: <TAB>  <TAB> more_data = self.sock.recv(64 * 1024) <MASK> break <TAB>  <TAB> data = data + more_data <TAB>  <TAB> ready_to_read, ready_to_write, in_error = select.select( <TAB>  <TAB>  <TAB> [self.sock], [], [], self.timeout <TAB>  <TAB> ) <TAB> return data",if len ( more_data ) == 0 :,164
"def _check_ids(el, filename, parent_id): <TAB> """"""Recursively walks through tree and check if every object has ID"""""" <TAB> for child in el: <MASK> msg = ""Widget has no ID in %s; class %s; Parent id: %s"" % ( <TAB>  <TAB>  <TAB>  <TAB> filename, <TAB>  <TAB>  <TAB>  <TAB> child.attrib[""class""], <TAB>  <TAB>  <TAB>  <TAB> parent_id, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> assert ""id"" in child.attrib and child.attrib[""id""], msg <TAB>  <TAB>  <TAB> for subel in child: <TAB>  <TAB>  <TAB>  <TAB> if subel.tag == ""child"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _check_ids(subel, filename, child.attrib[""id""])","if child . tag == ""object"" :",173
"def get(self, request, *args, **kwargs): <TAB> url = self.get_redirect_url(**kwargs) <TAB> if url: <MASK> return http.HttpResponsePermanentRedirect(url) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return http.HttpResponseRedirect(url) <TAB> else: <TAB>  <TAB> logger.warning( <TAB>  <TAB>  <TAB> ""Gone: %s"" % self.request.path, <TAB>  <TAB>  <TAB> extra={""status_code"": 410, ""request"": self.request}, <TAB>  <TAB> ) <TAB>  <TAB> return http.HttpResponseGone()",if self . permanent :,135
"def test_representation(self): <TAB> # Test that the state space representation in the measurement error <TAB> # case is correct <TAB> for name in self.model.ssm.shapes.keys(): <TAB>  <TAB> if name == ""obs"": <TAB>  <TAB>  <TAB> pass <MASK> actual = self.results2.filter_results.obs_cov <TAB>  <TAB>  <TAB> desired = np.diag(self.true_measurement_error_variances)[:, :, np.newaxis] <TAB>  <TAB>  <TAB> assert_equal(actual, desired) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert_equal( <TAB>  <TAB>  <TAB>  <TAB> getattr(self.results2.filter_results, name), <TAB>  <TAB>  <TAB>  <TAB> getattr(self.results.filter_results, name), <TAB>  <TAB>  <TAB> )","elif name == ""obs_cov"" :",179
"def process_formdata(self, valuelist): <TAB> if valuelist: <TAB>  <TAB> date_str = "" "".join(valuelist) <MASK> self.data = None <TAB>  <TAB>  <TAB> raise ValidationError(self.gettext(""Please input a date/time value"")) <TAB>  <TAB> parse_kwargs = self.parse_kwargs.copy() <TAB>  <TAB> if ""default"" not in parse_kwargs: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> parse_kwargs[""default""] = self.default() <TAB>  <TAB>  <TAB> except TypeError: <TAB>  <TAB>  <TAB>  <TAB> parse_kwargs[""default""] = self.default <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.data = parser.parse(date_str, **parse_kwargs) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> self.data = None <TAB>  <TAB>  <TAB> raise ValidationError(self.gettext(""Invalid date/time input""))",if not date_str :,196
"def get_bounding_box(self): <TAB> for key in self.h5f[""Data_Products""].keys(): <MASK> lats = self.h5f[""Data_Products""][key][key + ""_Gran_0""].attrs[ <TAB>  <TAB>  <TAB>  <TAB> ""G-Ring_Latitude"" <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB> lons = self.h5f[""Data_Products""][key][key + ""_Gran_0""].attrs[ <TAB>  <TAB>  <TAB>  <TAB> ""G-Ring_Longitude"" <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> raise KeyError(""Cannot find bounding coordinates!"") <TAB> return lons.ravel(), lats.ravel()","if key . startswith ( ""VIIRS"" ) and key . endswith ( ""GEO"" ) :",175
"def _get_doc_contents(self, attr_name): <TAB> value = getattr(self, attr_name) <TAB> if isinstance(value, BasicCommand.FROM_FILE): <MASK> trailing_path = value.filename <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> trailing_path = os.path.join(self.name, attr_name + "".rst"") <TAB>  <TAB> root_module = value.root_module <TAB>  <TAB> doc_path = os.path.join( <TAB>  <TAB>  <TAB> os.path.abspath(os.path.dirname(root_module.__file__)), <TAB>  <TAB>  <TAB> ""examples"", <TAB>  <TAB>  <TAB> trailing_path, <TAB>  <TAB> ) <TAB>  <TAB> with _open(doc_path) as f: <TAB>  <TAB>  <TAB> return f.read() <TAB> else: <TAB>  <TAB> return value",if value . filename is not None :,191
"def __truediv__(self, val): <TAB> if isinstance(val, Vector3): <TAB>  <TAB> if val.x == 0 or val.y == 0 or val.z == 0: <TAB>  <TAB>  <TAB> raise ZeroDivisionError() <TAB>  <TAB> gd_obj = lib.godot_vector3_operator_divide_vector(self._gd_ptr, val._gd_ptr) <TAB> else: <MASK> raise ZeroDivisionError() <TAB>  <TAB> gd_obj = lib.godot_vector3_operator_divide_scalar(self._gd_ptr, val) <TAB> return Vector3.build_from_gdobj(gd_obj)",if val is 0 :,148
"def _get_all_plugin_configs(self): <TAB> with opentracing.global_tracer().start_active_span(""_get_all_plugin_configs""): <MASK> self._plugin_configs = { <TAB>  <TAB>  <TAB>  <TAB> pc.identifier: pc for pc in PluginConfiguration.objects.all() <TAB>  <TAB>  <TAB> } <TAB>  <TAB> return self._plugin_configs","if not hasattr ( self , ""_plugin_configs"" ) :",94
"def msg(self, module, level, msg, *args, **kwargs): <TAB> if self.level < level or level > len(LEVELS): <TAB>  <TAB> return <TAB> msg = str(msg).format(*args, **kwargs) <TAB> with self.lock: <TAB>  <TAB> self.output.write(FORMAT.format(module=module, level=LEVELS[level], msg=msg)) <MASK> self.output.flush()","if hasattr ( self . output , ""flush"" ) :",111
"def opentemplatefile(self, options, fulltemplatepath): <TAB> """"""Opens the template file (if required)."""""" <TAB> if fulltemplatepath is not None: <MASK> return open(fulltemplatepath, ""r"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.warning(""missing template file %s"" % fulltemplatepath) <TAB> return None",if os . path . isfile ( fulltemplatepath ) :,92
"def b58(args, parser): <TAB> for arg in args.input: <TAB>  <TAB> blob, is_hex_input = parse_arg(arg, args.b) <MASK> print(b2h(blob)) <TAB>  <TAB>  <TAB> print(b2a_base58(blob)) <TAB>  <TAB>  <TAB> print(b2a_hashed_base58(blob)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(b2h(blob)) <TAB>  <TAB>  <TAB> print(b2a_base58(blob)) <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> blob = a2b_hashed_base58(arg) <TAB>  <TAB>  <TAB>  <TAB> print(""valid hashed b58"") <TAB>  <TAB>  <TAB>  <TAB> print(""contents: "", b2h(blob)) <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> print(""not hashed b58"")",if is_hex_input :,196
"def edit_file(self, filename): <TAB> import subprocess <TAB> editor = self.get_editor() <TAB> if self.env: <TAB>  <TAB> environ = os.environ.copy() <TAB>  <TAB> environ.update(self.env) <TAB> else: <TAB>  <TAB> environ = None <TAB> try: <TAB>  <TAB> c = subprocess.Popen( <TAB>  <TAB>  <TAB> ""{} {}"".format(shlex_quote(editor), shlex_quote(filename)), <TAB>  <TAB>  <TAB> env=environ, <TAB>  <TAB>  <TAB> shell=True, <TAB>  <TAB> ) <TAB>  <TAB> exit_code = c.wait() <MASK> raise ClickException(""{}: Editing failed!"".format(editor)) <TAB> except OSError as e: <TAB>  <TAB> raise ClickException(""{}: Editing failed: {}"".format(editor, e))",if exit_code != 0 :,174
"def ascii85decode(data): <TAB> n = b = 0 <TAB> out = """" <TAB> for c in data: <MASK> n += 1 <TAB>  <TAB>  <TAB> b = b * 85 + (ord(c) - 33) <TAB>  <TAB>  <TAB> if n == 5: <TAB>  <TAB>  <TAB>  <TAB> out += struct.pack("">L"", b) <TAB>  <TAB>  <TAB>  <TAB> n = b = 0 <TAB>  <TAB> elif c == ""z"": <TAB>  <TAB>  <TAB> assert n == 0 <TAB>  <TAB>  <TAB> out += ""\0\0\0\0"" <TAB>  <TAB> elif c == ""~"": <TAB>  <TAB>  <TAB> if n: <TAB>  <TAB>  <TAB>  <TAB> for _ in range(5 - n): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> b = b * 85 + 84 <TAB>  <TAB>  <TAB>  <TAB> out += struct.pack("">L"", b)[: n - 1] <TAB>  <TAB>  <TAB> break <TAB> return out","if ""!"" <= c and c <= ""u"" :",200
"def channel_to_netid(channel_name_or_id): <TAB> try: <TAB>  <TAB> channel = int(channel_name_or_id) <TAB> except ValueError: <TAB>  <TAB> netid = ""NETID_{}"".format(channel_name_or_id.upper()) <MASK> channel = getattr(ics, netid) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""channel must be an integer or "" ""a valid ICS channel name"" <TAB>  <TAB>  <TAB> ) <TAB> return channel","if hasattr ( ics , netid ) :",129
"def _find_this_and_next_frame(self, stack): <TAB> for i in range(len(stack)): <MASK> if i == len(stack) - 1:  # last frame <TAB>  <TAB>  <TAB>  <TAB> return stack[i], None <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return stack[i], stack[i + 1] <TAB> raise AssertionError(""Frame doesn't exist anymore"")",if stack [ i ] . id == self . _frame_id :,106
"def nested_update(org_dict, upd_dict): <TAB> for key, value in upd_dict.items(): <TAB>  <TAB> if isinstance(value, dict): <TAB>  <TAB>  <TAB> if key in org_dict: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Mismatch between org_dict and upd_dict at node {}"".format(key) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> nested_update(org_dict[key], value) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> org_dict[key] = value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> org_dict[key] = value","if not isinstance ( org_dict [ key ] , dict ) :",161
"def __myreduce(self, elements): <TAB> first = elements[0] <TAB> for i in range(1, len(elements), 2): <MASK> first = first and elements[i + 1] <TAB>  <TAB> elif elements[i] == ""or"": <TAB>  <TAB>  <TAB> first = first or elements[i + 1] <TAB> self.stack = [] <TAB> if isinstance(first, list): <TAB>  <TAB> return [first] <TAB> return first","if elements [ i ] == ""and"" :",112
"def test_to_json_na(self): <TAB> # Set a value as nan and make sure it's written <TAB> self.df.loc[self.df[""BoroName""] == ""Queens"", ""Shape_Area""] = np.nan <TAB> text = self.df.to_json() <TAB> data = json.loads(text) <TAB> self.assertTrue(len(data[""features""]) == 5) <TAB> for f in data[""features""]: <TAB>  <TAB> props = f[""properties""] <TAB>  <TAB> self.assertEqual(len(props), 4) <MASK> self.assertTrue(props[""Shape_Area""] is None)","if props [ ""BoroName"" ] == ""Queens"" :",160
"def process(self, resources): <TAB> resources = self.filter_resources(resources, ""TableStatus"", self.valid_status) <TAB> if not len(resources): <TAB>  <TAB> return <TAB> futures = [] <TAB> client = local_session(self.manager.session_factory).client(""dynamodb"") <TAB> with self.executor_factory(max_workers=2) as w: <TAB>  <TAB> for table_set in chunks(resources, 20): <TAB>  <TAB>  <TAB> futures.append(w.submit(self.delete_table, client, table_set)) <TAB>  <TAB> for f in as_completed(futures): <MASK> self.log.error( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Exception deleting dynamodb table set \n %s"" % (f.exception()) <TAB>  <TAB>  <TAB>  <TAB> )",if f . exception ( ) :,184
"def skip_loss_scaling(self, backend_config=None): <TAB> if self.loss_scaling is not False: <MASK> msg = ""loss_scaling is tested when dtype is float16."" <TAB>  <TAB>  <TAB> return True, msg <TAB>  <TAB> if backend_config is not None and not backend_config.use_cuda: <TAB>  <TAB>  <TAB> msg = ""loss_scaling is tested when use_cuda is True."" <TAB>  <TAB>  <TAB> return True, msg <TAB> return False, None",if self . dtype != numpy . float16 :,120
"def writeLibraryControllers(fp, human, meshes, skel, config, shapes=None): <TAB> progress = Progress(len(meshes), None) <TAB> fp.write(""\n  <library_controllers>\n"") <TAB> for mIdx, mesh in enumerate(meshes): <TAB>  <TAB> subprog = Progress()(0, 0.5) <TAB>  <TAB> if skel: <TAB>  <TAB>  <TAB> writeSkinController(fp, human, mesh, skel, config) <TAB>  <TAB> subprog(0.5, 1) <MASK> writeMorphController(fp, mesh, shapes[mIdx], config) <TAB>  <TAB> progress.step() <TAB> fp.write(""  </library_controllers>\n"")",if shapes is not None :,172
"def doit(): <TAB> recipes_path = expanduser(""recipes.pprint"") <TAB> recipe_dicts = eval(open(recipes_path).read()) <TAB> for r in recipe_dicts: <TAB>  <TAB> for key in r.keys(): <MASK> del r[key] <TAB>  <TAB> for c in r[""comments""]: <TAB>  <TAB>  <TAB> for key in c.keys(): <TAB>  <TAB>  <TAB>  <TAB> if key not in (""comment"", ""title""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> del c[key] <TAB> f = open(""stripped.pprint"", ""w"") <TAB> f.write(pformat(recipe_dicts)) <TAB> f.close()","if key not in ( ""desc"" , ""comments"" ) :",163
"def _dispatchBubblingEvent(self, tag, evtType, evtObject): <TAB> for node in tag.parents: <MASK> # pragma: no cover <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if not node._listeners: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if evtObject._stoppedPropagation:  # pragma: no cover <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> capture_listeners, bubbling_listeners = self._get_listeners( <TAB>  <TAB>  <TAB> node, evtType <TAB>  <TAB> )  # pylint:disable=unused-variable <TAB>  <TAB> for c in bubbling_listeners: <TAB>  <TAB>  <TAB> evtObject.currentTarget = node._node <TAB>  <TAB>  <TAB> self.do_dispatch(c, evtObject)",if node is None :,165
"def connect(self): <TAB> if self.session is None: <TAB>  <TAB> self.session = requests.Session() <MASK> self.session.mount(""httpsds8k://"", requests.adapters.HTTPAdapter()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.session.mount(""https://"", requests.adapters.HTTPAdapter()) <TAB>  <TAB> self.session.verify = self.verify","if isinstance ( self . verify , six . string_types ) :",100
"def get_latest_tasks(cls, tasks): <TAB> tasks_group = {} <TAB> for task in tasks: <TAB>  <TAB> task_key = cls.task_key( <TAB>  <TAB>  <TAB> task_id=task.f_task_id, role=task.f_role, party_id=task.f_party_id <TAB>  <TAB> ) <TAB>  <TAB> if task_key not in tasks_group: <TAB>  <TAB>  <TAB> tasks_group[task_key] = task <MASK> # update new version task <TAB>  <TAB>  <TAB> tasks_group[task_key] = task <TAB> return tasks_group",elif task . f_task_version > tasks_group [ task_key ] . f_task_version :,160
"def wrapper(cached=True, reset=False): <TAB> nonlocal cached_venv_dir <TAB> if not cached or not cached_venv_dir or reset: <TAB>  <TAB> venv_dir = os.environ.get(""_VENV_DIR_"") or load_settings(lazy=True).get( <TAB>  <TAB>  <TAB> ""venv_dir"" <TAB>  <TAB> ) <TAB>  <TAB> if venv_dir:  # no cov <MASK> venv_dir = VENV_DIR_ISOLATED <TAB>  <TAB>  <TAB> elif venv_dir == ""shared"": <TAB>  <TAB>  <TAB>  <TAB> venv_dir = VENV_DIR_SHARED <TAB>  <TAB> else:  # no cov <TAB>  <TAB>  <TAB> venv_dir = VENV_DIR_SHARED <TAB>  <TAB> cached_venv_dir = venv_dir <TAB> return cached_venv_dir","if venv_dir == ""isolated"" :",186
"def __walk_dir_tree(self, dirname): <TAB> dir_list = [] <TAB> self.__logger.debug(""__walk_dir_tree. START dir=%s"", dirname) <TAB> for f in os.listdir(dirname): <TAB>  <TAB> current = os.path.join(dirname, f) <TAB>  <TAB> if os.path.isfile(current) and f.endswith(""py""): <TAB>  <TAB>  <TAB> if self.module_registrant: <TAB>  <TAB>  <TAB>  <TAB> self._load_py_from_file(current) <TAB>  <TAB>  <TAB> dir_list.append(current) <TAB>  <TAB> elif os.path.isdir(current): <TAB>  <TAB>  <TAB> ret = self.__walk_dir_tree(current) <MASK> dir_list.append((f, ret)) <TAB> return dir_list",if ret :,184
"def read_ansible_config(project_path, variables_of_interest): <TAB> fnames = [""/etc/ansible/ansible.cfg""] <TAB> if project_path: <TAB>  <TAB> fnames.append(os.path.join(project_path, ""ansible.cfg"")) <TAB> values = {} <TAB> try: <TAB>  <TAB> parser = ConfigParser() <TAB>  <TAB> parser.read(fnames) <MASK> for var in variables_of_interest: <TAB>  <TAB>  <TAB>  <TAB> if var in parser[""defaults""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> values[var] = parser[""defaults""][var] <TAB> except Exception: <TAB>  <TAB> logger.exception(""Failed to read ansible configuration(s) {}"".format(fnames)) <TAB> return values","if ""defaults"" in parser :",166
"def inference(self, x_all, data_loader): <TAB> for i in range(len(self.convs)): <TAB>  <TAB> output = [] <TAB>  <TAB> for src_id, edge_index, size in data_loader: <TAB>  <TAB>  <TAB> x = x_all[src_id].to(self.device) <TAB>  <TAB>  <TAB> edge_index = edge_index.to(self.device) <TAB>  <TAB>  <TAB> x = self.convs[i](x, edge_index) <TAB>  <TAB>  <TAB> x = x[: size[1]] <MASK> x = F.relu(x) <TAB>  <TAB>  <TAB> output.append(x.cpu()) <TAB>  <TAB> x_all = torch.cat(output, dim=0) <TAB> return F.log_softmax(x_all, dim=-1)",if i != self . num_layers - 1 :,193
"def guard_transform(transform): <TAB> """"""Return an Affine transformation instance."""""" <TAB> if not isinstance(transform, Affine): <MASK> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""GDAL-style transforms have been deprecated.  This "" <TAB>  <TAB>  <TAB>  <TAB> ""exception will be raised for a period of time to highlight "" <TAB>  <TAB>  <TAB>  <TAB> ""potentially confusing errors, but will eventually be removed."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> transform = Affine(*transform) <TAB> return transform",if tastes_like_gdal ( transform ) :,125
"def _tokenize(self, text): <TAB> if tf.is_tensor(text): <TAB>  <TAB> rank = len(text.shape) <MASK> return self._tokenize_tensor(text) <TAB>  <TAB> elif rank == 1: <TAB>  <TAB>  <TAB> return self._tokenize_batch_tensor(text) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""Unsupported tensor rank %d for tokenization"" % rank) <TAB> elif isinstance(text, list): <TAB>  <TAB> return list(map(self.tokenize, text)) <TAB> else: <TAB>  <TAB> text = tf.compat.as_text(text) <TAB>  <TAB> return self._tokenize_string(text)",if rank == 0 :,152
"def validate_export(namespace): <TAB> destination = namespace.destination <TAB> if destination == ""file"": <TAB>  <TAB> if namespace.path is None or namespace.format_ is None: <TAB>  <TAB>  <TAB> raise CLIError(""usage error: --path PATH --format FORMAT"") <TAB> elif destination == ""appconfig"": <MASK> raise CLIError(""usage error: --config-name NAME | --connection-string STR"") <TAB> elif destination == ""appservice"": <TAB>  <TAB> if namespace.appservice_account is None: <TAB>  <TAB>  <TAB> raise CLIError(""usage error: --appservice-account NAME_OR_ID"")",if ( namespace . dest_name is None ) and ( namespace . dest_connection_string is None ) :,159
"def dispatch(self, request, *args, **kwargs): <TAB> settings = self.get_settings(self.form_class.settings) <TAB> initial = self.get_initial_form_data(settings) <TAB> form = self.form_class(request=request, initial=initial) <TAB> if request.method == ""POST"": <TAB>  <TAB> form = self.form_class( <TAB>  <TAB>  <TAB> request.POST, request.FILES, request=request, initial=initial <TAB>  <TAB> ) <MASK> form.save(settings) <TAB>  <TAB>  <TAB> messages.success(request, _(""Settings have been saved."")) <TAB>  <TAB>  <TAB> return redirect(request.path_info) <TAB> return self.render(request, {""form"": form, ""form_settings"": settings})",if form . is_valid ( ) :,180
"def get_modules(path): <TAB> modules = set() <TAB> for dirpath, dirnames, filenames in os.walk(path): <TAB>  <TAB> for filename in filenames: <MASK> cutoff = len(path) + 1 <TAB>  <TAB>  <TAB>  <TAB> fullpath = os.path.join(dirpath[cutoff:], filename) <TAB>  <TAB>  <TAB>  <TAB> modules.add(fullpath) <TAB> return modules","if filename . endswith ( "".py"" ) :",95
"def _make_input_layers(self, rebuild=False): <TAB> for name, layer in self.layer_map.items(): <TAB>  <TAB> layer.left_in_edges = len(layer.in_edges) <TAB>  <TAB> if len(layer.in_edges) == 0: <TAB>  <TAB>  <TAB> if rebuild: <MASK> self.input_layers.append(name) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.input_layers.append(name)","if not layer . get_attr ( ""scope"" ) :",123
"def _get_status(self): <TAB> connection_errors_allowed = 10 <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> content = requests.get(self.__status_details_url).json() <TAB>  <TAB> except (requests.ConnectionError, requests.HTTPError) as e: <MASK> yield e <TAB>  <TAB>  <TAB> content = {""processed"": False, ""code"": ""being_processed""} <TAB>  <TAB>  <TAB> connection_errors_allowed -= 1 <TAB>  <TAB> yield content",if not connection_errors_allowed :,119
"def show(self): <TAB> if len(self.figures.keys()) == 0: <TAB>  <TAB> return <TAB> if not SETTINGS.plot_split: <TAB>  <TAB> if SETTINGS.plot_backend.lower() == ""qt4agg"": <TAB>  <TAB>  <TAB> self.tabbed_qt4_window() <MASK> self.tabbed_qt5_window() <TAB>  <TAB> elif SETTINGS.plot_backend.lower() == ""tkagg"": <TAB>  <TAB>  <TAB> self.tabbed_tk_window() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> plt.show() <TAB> else: <TAB>  <TAB> plt.show()","elif SETTINGS . plot_backend . lower ( ) == ""qt5agg"" :",161
"def emit(self, record): <TAB> msg = self.format(record) <TAB> self.lock.acquire() <TAB> try: <TAB>  <TAB> msg = self.encode(msg) <MASK> self.perform_rollover() <TAB>  <TAB> self.write(msg) <TAB>  <TAB> self.flush() <TAB> finally: <TAB>  <TAB> self.lock.release()","if self . should_rollover ( record , len ( msg ) ) :",96
"def install(self, unicode=False, names=None): <TAB> import __builtin__ <TAB> __builtin__.__dict__[""_""] = unicode and self.ugettext or self.gettext <TAB> if hasattr(names, ""__contains__""): <MASK> __builtin__.__dict__[""gettext""] = __builtin__.__dict__[""_""] <TAB>  <TAB> if ""ngettext"" in names: <TAB>  <TAB>  <TAB> __builtin__.__dict__[""ngettext""] = ( <TAB>  <TAB>  <TAB>  <TAB> unicode and self.ungettext or self.ngettext <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if ""lgettext"" in names: <TAB>  <TAB>  <TAB> __builtin__.__dict__[""lgettext""] = self.lgettext <TAB>  <TAB> if ""lngettext"" in names: <TAB>  <TAB>  <TAB> __builtin__.__dict__[""lngettext""] = self.lngettext","if ""gettext"" in names :",181
"def test_simulate_moment_steps_set_state(dtype): <TAB> q0, q1 = cirq.LineQubit.range(2) <TAB> circuit = cirq.Circuit(cirq.H(q0), cirq.H(q1), cirq.H(q0), cirq.H(q1)) <TAB> simulator = cirq.Simulator(dtype=dtype) <TAB> for i, step in enumerate(simulator.simulate_moment_steps(circuit)): <TAB>  <TAB> np.testing.assert_almost_equal(step.state_vector(), np.array([0.5] * 4)) <MASK> step.set_state_vector(np.array([1, 0, 0, 0], dtype=dtype))",if i == 0 :,179
"def get_config_settings(): <TAB> config = {} <TAB> for plugin in extension_loader.MANAGER.plugins: <TAB>  <TAB> fn_name = plugin.name <TAB>  <TAB> function = plugin.plugin <TAB>  <TAB> # if a function takes config... <MASK> fn_module = importlib.import_module(function.__module__) <TAB>  <TAB>  <TAB> # call the config generator if it exists <TAB>  <TAB>  <TAB> if hasattr(fn_module, ""gen_config""): <TAB>  <TAB>  <TAB>  <TAB> config[fn_name] = fn_module.gen_config(function._takes_config) <TAB> return yaml.safe_dump(config, default_flow_style=False)","if hasattr ( function , ""_takes_config"" ) :",161
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_app_id(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 18: <TAB>  <TAB>  <TAB> self.set_queue_name(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 24: <TAB>  <TAB>  <TAB> self.set_pause(d.getBoolean()) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,152
"def enable(self): <TAB> """"""enable the patch."""""" <TAB> for patch in self.dependencies: <TAB>  <TAB> patch.enable() <TAB> if not self.enabled: <TAB>  <TAB> pyv = sys.version_info[0] <TAB>  <TAB> if pyv == 2: <MASK> return  # skip patch activation <TAB>  <TAB>  <TAB> if not self.PY2: <TAB>  <TAB>  <TAB>  <TAB> raise IncompatiblePatch(""Python 2 not supported!"") <TAB>  <TAB> if pyv == 3: <TAB>  <TAB>  <TAB> if self.PY3 == SKIP: <TAB>  <TAB>  <TAB>  <TAB> return  # skip patch activation <TAB>  <TAB>  <TAB> if not self.PY3: <TAB>  <TAB>  <TAB>  <TAB> raise IncompatiblePatch(""Python 3 not supported!"") <TAB>  <TAB> self.pre_enable() <TAB>  <TAB> self.do_enable() <TAB>  <TAB> self.enabled = True",if self . PY2 == SKIP :,191
"def to_dict(self) -> JSONDict: <TAB> data = dict() <TAB> for key in iter(self.__dict__): <TAB>  <TAB> if key == ""bot"" or key.startswith(""_""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> value = self.__dict__[key] <MASK> if hasattr(value, ""to_dict""): <TAB>  <TAB>  <TAB>  <TAB> data[key] = value.to_dict() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> data[key] = value <TAB> if data.get(""from_user""): <TAB>  <TAB> data[""from""] = data.pop(""from_user"", None) <TAB> return data",if value is not None :,148
"def _resolve_result(self, f=None): <TAB> try: <TAB>  <TAB> if f: <TAB>  <TAB>  <TAB> results = f.result() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> results = list(map(self._client.results.get, self.msg_ids)) <TAB>  <TAB> if self._single_result: <TAB>  <TAB>  <TAB> r = results[0] <MASK> raise r <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> results = error.collect_exceptions(results, self._fname) <TAB>  <TAB> self._success = True <TAB>  <TAB> self.set_result(self._reconstruct_result(results)) <TAB> except Exception as e: <TAB>  <TAB> self._success = False <TAB>  <TAB> self.set_exception(e)","if isinstance ( r , Exception ) :",174
"def print_monitor(args): <TAB> from pylearn2.utils import serial <TAB> import gc <TAB> for model_path in args: <TAB>  <TAB> if len(args) > 1: <TAB>  <TAB>  <TAB> print(model_path) <TAB>  <TAB> model = serial.load(model_path) <TAB>  <TAB> monitor = model.monitor <TAB>  <TAB> del model <TAB>  <TAB> gc.collect() <TAB>  <TAB> channels = monitor.channels <MASK> print(""old file, not all fields parsed correctly"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""epochs seen: "", monitor._epochs_seen) <TAB>  <TAB> print(""time trained: "", max(channels[key].time_record[-1] for key in channels)) <TAB>  <TAB> for key in sorted(channels.keys()): <TAB>  <TAB>  <TAB> print(key, "":"", channels[key].val_record[-1])","if not hasattr ( monitor , ""_epochs_seen"" ) :",200
"def apply(self, **kwargs: Any) -> None: <TAB> for node in self.document.traverse(addnodes.index): <MASK> msg = ( <TAB>  <TAB>  <TAB>  <TAB> __( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""4 column based index found. "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""It might be a bug of extensions you use: %r"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> % node[""entries""] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> logger.warning(msg, location=node) <TAB>  <TAB>  <TAB> for i, entry in enumerate(node[""entries""]): <TAB>  <TAB>  <TAB>  <TAB> if len(entry) == 4: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> node[""entries""][i] = entry + (None,)","if ""entries"" in node and any ( len ( entry ) == 4 for entry in node [ ""entries"" ] ) :",183
"def cleanup_empty_directories(path: str): <TAB> """"""Remove all empty folders inside (and including) 'path'"""""" <TAB> path = os.path.normpath(path) <TAB> while 1: <TAB>  <TAB> repeat = False <TAB>  <TAB> for root, dirs, files in os.walk(path, topdown=False): <MASK> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> remove_dir(root) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> repeat = True <TAB>  <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> if not repeat: <TAB>  <TAB>  <TAB> break <TAB> # Only remove if main folder is now also empty <TAB> if not os.listdir(path): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> remove_dir(path) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> pass",if not dirs and not files and root != path :,187
"def expect_flow_sequence_item(self): <TAB> if isinstance(self.event, SequenceEndEvent): <TAB>  <TAB> self.indent = self.indents.pop() <TAB>  <TAB> self.flow_level -= 1 <MASK> self.write_indicator(u"","", False) <TAB>  <TAB>  <TAB> self.write_indent() <TAB>  <TAB> self.write_indicator(u""]"", False) <TAB>  <TAB> self.state = self.states.pop() <TAB> else: <TAB>  <TAB> self.write_indicator(u"","", False) <TAB>  <TAB> if self.canonical or self.column > self.best_width: <TAB>  <TAB>  <TAB> self.write_indent() <TAB>  <TAB> self.states.append(self.expect_flow_sequence_item) <TAB>  <TAB> self.expect_node(sequence=True)",if self . canonical :,185
"def test_loss_diff(self): <TAB> losses = [] <TAB> for use_cuda in [True, False]: <TAB>  <TAB> for use_py_func_op in [True, False]: <TAB>  <TAB>  <TAB> L = test_main(use_cuda, use_py_func_op, self.use_parallel_executor) <MASK> losses.append(L) <TAB> for idx in six.moves.range(len(losses) - 1): <TAB>  <TAB> max_diff = np.max(np.abs(losses[idx] - losses[0])) <TAB>  <TAB> self.assertAlmostEqual(max_diff, 0, delta=1e-3)",if L is not None :,157
"def check_file(f, path): <TAB> if not (ignore_substring and ignore_substring in f): <TAB>  <TAB> if substring in f: <TAB>  <TAB>  <TAB> compl_path = os.path.join(path, f) <MASK> return compl_path <TAB> return False",if os . path . isfile ( compl_path ) :,83
"def is_valid_block(self): <TAB> """"""check wheter the block is valid in the current position"""""" <TAB> for i in range(self.block.x): <TAB>  <TAB> for j in range(self.block.x): <TAB>  <TAB>  <TAB> if self.block.get(i, j): <MASK> return False <TAB>  <TAB>  <TAB>  <TAB> if self.block.pos.x + i >= COLUMNS: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB>  <TAB> if self.block.pos.y + j < 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB>  <TAB> if self.map.get((self.block.pos.x + i, self.block.pos.y + j), False): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return True",if self . block . pos . x + i < 0 :,192
"def is_fail_state(state): <TAB> if type( <TAB>  <TAB> state.addr <TAB> ) == SootAddressDescriptor and state.addr.method == SootMethodDescriptor.from_soot_method( <TAB>  <TAB> onclick_method <TAB> ): <TAB>  <TAB> sols = state.solver.eval_upto(state.memory_soot.stack.load(""$z0""), 2) <TAB>  <TAB> assert len(sols) == 1 <MASK> return True <TAB> return False",if sols [ 0 ] == 0 :,118
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 8: <TAB>  <TAB>  <TAB> self.add_delete_status(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,92
"def _init_weight(self): <TAB> for m in self.modules(): <MASK> n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels <TAB>  <TAB>  <TAB> m.weight.data.normal_(0, math.sqrt(2.0 / n)) <TAB>  <TAB> elif isinstance(m, SyncBatchNorm): <TAB>  <TAB>  <TAB> m.weight.data.fill_(1) <TAB>  <TAB>  <TAB> m.bias.data.zero_() <TAB>  <TAB> elif isinstance(m, nn.BatchNorm2d): <TAB>  <TAB>  <TAB> m.weight.data.fill_(1) <TAB>  <TAB>  <TAB> m.bias.data.zero_()","if isinstance ( m , nn . Conv2d ) :",162
"def wrapper(*args, **kwargs): <TAB> global _exception <TAB> try: <TAB>  <TAB> fn(*args, **kwargs) <TAB> except Exception: <TAB>  <TAB> _exception = sys.exc_info() <TAB>  <TAB> et, ev, tb = _exception <TAB>  <TAB> if getattr(ev, ""filename"", None) is None: <TAB>  <TAB>  <TAB> # get the filename from the last item in the stack <TAB>  <TAB>  <TAB> filename = traceback.extract_tb(tb)[-1][0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> filename = ev.filename <MASK> _error_files.append(filename) <TAB>  <TAB> raise",if filename not in _error_files :,148
"def purge_messages(self): <TAB> with self.app.connection_for_write() as connection: <TAB>  <TAB> count = self.app.control.purge(connection=connection) <MASK> # pragma: no cover <TAB>  <TAB>  <TAB> print( <TAB>  <TAB>  <TAB>  <TAB> ""purge: Erased {0} {1} from the queue.\n"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> count, pluralize(count, ""message"") <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> )",if count :,109
"def read_series(rec): <TAB> found = [] <TAB> for tag in (""440"", ""490"", ""830""): <TAB>  <TAB> fields = rec.get_fields(tag) <TAB>  <TAB> if not fields: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for f in fields: <TAB>  <TAB>  <TAB> this = [] <TAB>  <TAB>  <TAB> for k, v in f.get_subfields([""a"", ""v""]): <TAB>  <TAB>  <TAB>  <TAB> if k == ""v"" and v: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> this.append(v) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB>  <TAB> v = v.rstrip("".,; "") <TAB>  <TAB>  <TAB>  <TAB> if v: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> this.append(v) <MASK> found += ["" -- "".join(this)] <TAB> return found",if this :,182
def calc_position_values(positions): <TAB> values = [] <TAB> for position in positions: <MASK> # Futures don't have an inherent position value. <TAB>  <TAB>  <TAB> values.append(0.0) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> values.append(position.last_sale_price * position.amount) <TAB> return values,"if isinstance ( position . asset , Future ) :",92
"def _loc(obj): <TAB> try: <TAB>  <TAB> fn = getattr(obj, ""__file__"", None) <TAB>  <TAB> if fn is not None: <TAB>  <TAB>  <TAB> return "" @%s"" % (fn,) <TAB>  <TAB> obj = getattr(obj, ""im_func"", obj) <TAB>  <TAB> code = getattr(obj, ""__code__"", None) <MASK> return "" @%s:%s"" % (code.co_filename, code.co_firstlineno) <TAB> except Exception: <TAB>  <TAB> pass <TAB> return """"",if code is not None :,126
"def _convert_user_into_remote(self, username, exclude=[""all""]): <TAB> # builds a ref with an username and a branch <TAB> # this method parses the repository's remotes to find the url matching username <TAB> # and containing the given branch and returns the corresponding ref <TAB> remotes = {remote.name: list(remote.urls) for remote in self.repository.remotes} <TAB> for name in (self.name, ""upstream"") + tuple(remotes.keys()): <TAB>  <TAB> if name in remotes and name not in exclude: <TAB>  <TAB>  <TAB> for url in remotes[name]: <MASK> yield name","if self . fqdn in url and username == url . split ( ""/"" ) [ - 2 ] . split ( "":"" ) [ - 1 ] :",169
"def _render_ib_interfaces(cls, network_state, iface_contents, flavor): <TAB> ib_filter = renderer.filter_by_type(""infiniband"") <TAB> for iface in network_state.iter_interfaces(ib_filter): <MASK> iface_cfg = iface_contents[iface_name] <TAB>  <TAB> iface_cfg.kind = ""infiniband"" <TAB>  <TAB> iface_subnets = iface.get(""subnets"", []) <TAB>  <TAB> route_cfg = iface_cfg.routes <TAB>  <TAB> cls._render_subnets( <TAB>  <TAB>  <TAB> iface_cfg, iface_subnets, network_state.has_default_route, flavor <TAB>  <TAB> ) <TAB>  <TAB> cls._render_subnet_routes(iface_cfg, route_cfg, iface_subnets, flavor)","iface_name = iface [ ""name"" ]",193
"def _extract_level(self): <TAB> """"""Extract level and component if available (lazy)."""""" <TAB> if self._level is None: <TAB>  <TAB> split_tokens = self.split_tokens <TAB>  <TAB> if not split_tokens: <TAB>  <TAB>  <TAB> self._level = False <TAB>  <TAB>  <TAB> self._component = False <TAB>  <TAB>  <TAB> return <TAB>  <TAB> x = ( <TAB>  <TAB>  <TAB> self.log_levels.index(split_tokens[1]) <TAB>  <TAB>  <TAB> if split_tokens[1] in self.log_levels <TAB>  <TAB>  <TAB> else None <TAB>  <TAB> ) <MASK> self._level = split_tokens[1] <TAB>  <TAB>  <TAB> self._component = split_tokens[2] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._level = False <TAB>  <TAB>  <TAB> self._component = False",if x is not None :,185
"def addnode(self, parent, data): <TAB> print(""aaa"", data) <TAB> for i in data: <TAB>  <TAB> print(i) <MASK> continue <TAB>  <TAB> if isinstance(i, tuple): <TAB>  <TAB>  <TAB> item = self.tre_plugins.AppendItem(parent, i[0].title) <TAB>  <TAB>  <TAB> self.tre_plugins.SetItemData(item, i[0]) <TAB>  <TAB>  <TAB> self.addnode(item, i[1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> item = self.tre_plugins.AppendItem(parent, i[0].title) <TAB>  <TAB>  <TAB> self.tre_plugins.SetItemData(item, i[0])","if i == ""-"" :",159
"def getdsturl(tcpdata): <TAB> import logging <TAB> log = logging.getLogger(""getdsturl"") <TAB> p = parseHeader(tcpdata, type=""request"") <TAB> if p is None: <TAB>  <TAB> log.warn(""parseHeader returned None"") <TAB>  <TAB> return <TAB> if p.has_key(""uri"") and p.has_key(""headers""): <MASK> r = ""http://%s%s"" % (p[""headers""][""host""][0], p[""uri""]) <TAB>  <TAB>  <TAB> return r <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.warn(""seems like no host header was set"") <TAB> else: <TAB>  <TAB> log.warn(""parseHeader did not give us a nice return %s"" % p)","if p [ ""headers"" ] . has_key ( ""host"" ) :",176
"def assert_not_none(obj, msg=None, values=True): <TAB> """"""Fail the test if given object is None."""""" <TAB> _msg = ""is None"" <TAB> if obj is None: <TAB>  <TAB> if msg is None: <TAB>  <TAB>  <TAB> msg = _msg <MASK> msg = ""%s: %s"" % (msg, _msg) <TAB>  <TAB> _report_failure(msg)",elif values is True :,99
"def sort(self): <TAB> sorted_models = [] <TAB> concrete_models = set() <TAB> models = list(self.data) <TAB> while len(sorted_models) < len(models): <TAB>  <TAB> found = False <TAB>  <TAB> for model in models: <TAB>  <TAB>  <TAB> if model in sorted_models: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> dependencies = self.dependencies.get(model._meta.concrete_model) <MASK> sorted_models.append(model) <TAB>  <TAB>  <TAB>  <TAB> concrete_models.add(model._meta.concrete_model) <TAB>  <TAB>  <TAB>  <TAB> found = True <TAB>  <TAB> if not found: <TAB>  <TAB>  <TAB> return <TAB> self.data = OrderedDict((model, self.data[model]) for model in sorted_models)",if not ( dependencies and dependencies . difference ( concrete_models ) ) :,188
"def load_vocab_dict(vocab_file_path): <TAB> """"""Load vocabs, vocab: {""word"": 1, ...}"""""" <TAB> logging.info(""Loading vocab from {}"".format(vocab_file_path)) <TAB> with open(vocab_file_path, encoding=""utf-8"") as in_f: <TAB>  <TAB> vocabs = {} <TAB>  <TAB> for line in in_f: <TAB>  <TAB>  <TAB> parts = line.rstrip().split(""\t"") <MASK> continue <TAB>  <TAB>  <TAB> vocabs[parts[0]] = parts[1] <TAB> logging.info(""Loded {} vocabs from {}"".format(len(vocabs), vocab_file_path)) <TAB> return vocabs",if len ( parts ) < 2 :,161
"def get_layers_from_suite(self, suite, suiteClass): <TAB> top_layer = suiteClass() <TAB> layers_dict = OrderedDict() <TAB> for test in self.flatten_suite(suite): <TAB>  <TAB> layer = getattr(test, ""layer"", None) <MASK> if layer not in layers_dict: <TAB>  <TAB>  <TAB>  <TAB> layers_dict[layer] = LayerSuite(self.session, layer=layer) <TAB>  <TAB>  <TAB> layers_dict[layer].addTest(test) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> top_layer.addTest(test) <TAB> self.get_parent_layers(layers_dict) <TAB> return top_layer, layers_dict",if layer :,159
"def team_scores(self, team_scores, time): <TAB> """"""Store output of team scores to a JSON file"""""" <TAB> data = [] <TAB> for score in team_scores[""fixtures""]: <MASK> item = { <TAB>  <TAB>  <TAB>  <TAB> ""date"": score[""date""].split(""T"")[0], <TAB>  <TAB>  <TAB>  <TAB> ""homeTeamName"": score[""homeTeamName""], <TAB>  <TAB>  <TAB>  <TAB> ""goalsHomeTeam"": score[""result""][""goalsHomeTeam""], <TAB>  <TAB>  <TAB>  <TAB> ""goalsAwayTeam"": score[""result""][""goalsAwayTeam""], <TAB>  <TAB>  <TAB>  <TAB> ""awayTeamName"": score[""awayTeamName""], <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB> data.append(item) <TAB> self.generate_output({""team_scores"": data})","if score [ ""status"" ] == ""FINISHED"" :",183
"def run(self, root): <TAB> footnotesDiv = self.footnotes.makeFootnotesDiv(root) <TAB> if footnotesDiv is not None: <TAB>  <TAB> result = self.footnotes.findFootnotesPlaceholder(root) <TAB>  <TAB> if result: <TAB>  <TAB>  <TAB> child, parent, isText = result <TAB>  <TAB>  <TAB> ind = list(parent).index(child) <MASK> parent.remove(child) <TAB>  <TAB>  <TAB>  <TAB> parent.insert(ind, footnotesDiv) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> parent.insert(ind + 1, footnotesDiv) <TAB>  <TAB>  <TAB>  <TAB> child.tail = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> root.append(footnotesDiv)",if isText :,175
"def delete_target_group(self, target_group_arn): <TAB> if target_group_arn not in self.target_groups: <TAB>  <TAB> raise TargetGroupNotFoundError() <TAB> target_group = self.target_groups[target_group_arn] <TAB> if target_group: <MASK> raise ResourceInUseError( <TAB>  <TAB>  <TAB>  <TAB> ""The target group '{}' is currently in use by a listener or a rule"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> target_group_arn <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> del self.target_groups[target_group_arn] <TAB>  <TAB> return target_group",if self . _any_listener_using ( target_group_arn ) :,161
"def run_pending(self, now=None): <TAB> """"""Runs the command if scheduled"""""" <TAB> now = now or datetime.now() <TAB> if self.is_enabled(): <MASK> self.last_run = now <TAB>  <TAB> next_time = self.schedule(self.last_run).get_next() <TAB>  <TAB> if next_time < now: <TAB>  <TAB>  <TAB> self.last_run = now <TAB>  <TAB>  <TAB> return self.run() <TAB> return -1",if self . last_run is None :,119
"def _fix_exception_context(new_exc, old_exc): <TAB> # Context may not be correct, so find the end of the chain <TAB> while 1: <TAB>  <TAB> exc_context = new_exc.__context__ <MASK> # Context is already set correctly (see issue 20317) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> if exc_context is None or exc_context is frame_exc: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> new_exc = exc_context <TAB> # Change the end of the chain to point to the exception <TAB> # we expect it to reference <TAB> new_exc.__context__ = old_exc",if exc_context is old_exc :,151
"def delete_backend( <TAB> self, backend_tag: BackendTag, force_kill: bool = False) -> Optional[GoalId]: <TAB> async with self.write_lock: <TAB>  <TAB> # Check that the specified backend isn't used by any endpoints. <TAB>  <TAB> for endpoint, info in self.endpoint_state.get_endpoints().items(): <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Backend '{}' is used by endpoint '{}' "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""and cannot be deleted. Please remove "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""the backend from all endpoints and try "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""again."".format(backend_tag, endpoint) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return self.backend_state.delete_backend(backend_tag, force_kill)","if backend_tag in info [ ""traffic"" ] or backend_tag in info [ ""shadows"" ] :",199
"def lint(self, request): <TAB> try: <TAB>  <TAB> html_linter = UnwrapObject(self._koLintService.getLinterForLanguage(""HTML"")) <TAB>  <TAB> return html_linter.lint(request, TPLInfo=self._tplPatterns) <TAB> except: <MASK> self._checkValidVersion_complained[""lint""] = True <TAB>  <TAB>  <TAB> log.exception(""Problem in koPHPLinter.lint"") <TAB>  <TAB> return koLintResults()","if ""lint"" not in self . _checkValidVersion_complained :",132
"def get_commit(self, rev): <TAB> """"""Get commit object identified by `rev` (SHA or branch or tag name)."""""" <TAB> for prefix in [""refs/heads/"", ""refs/tags/"", """"]: <TAB>  <TAB> key = prefix + rev <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> obj = self[encode_for_git(key)] <MASK> obj = self[obj.object[1]] <TAB>  <TAB>  <TAB> return obj <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> pass <TAB> raise KeyError(rev)","if isinstance ( obj , dulwich . objects . Tag ) :",130
"def get_host_metadata(self): <TAB> meta = {} <TAB> if self.agent_url: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> resp = requests.get(self.agent_url, timeout=1).json().get(""config"", {}) <MASK> meta[""nomad_version""] = resp.get(""Version"") <TAB>  <TAB>  <TAB> if ""Region"" in resp: <TAB>  <TAB>  <TAB>  <TAB> meta[""nomad_region""] = resp.get(""Region"") <TAB>  <TAB>  <TAB> if ""Datacenter"" in resp: <TAB>  <TAB>  <TAB>  <TAB> meta[""nomad_datacenter""] = resp.get(""Datacenter"") <TAB>  <TAB> except Exception as ex: <TAB>  <TAB>  <TAB> self.log.debug(""Error getting Nomad version: %s"" % str(ex)) <TAB> return meta","if ""Version"" in resp :",185
"def _waitFakenetStopped(self, timeoutsec=None): <TAB> retval = False <TAB> while True: <MASK> retval = True <TAB>  <TAB>  <TAB> break <TAB>  <TAB> time.sleep(1) <TAB>  <TAB> if timeoutsec is not None: <TAB>  <TAB>  <TAB> timeoutsec -= 1 <TAB>  <TAB>  <TAB> if timeoutsec <= 0: <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return retval",if self . _confirmFakenetStopped ( ) :,97
"def send_message(self, message): <TAB> smtp = smtplib.SMTP(self.smtp_host, self.smtp_port) <TAB> try: <TAB>  <TAB> smtp.ehlo() <TAB>  <TAB> if self.smtp_tls: <TAB>  <TAB>  <TAB> smtp.starttls() <MASK> smtp.login(self.smtp_user, self.smtp_password) <TAB>  <TAB> smtp.sendmail(self.from_user, self.recipients, message.as_string()) <TAB> finally: <TAB>  <TAB> smtp.close()",if self . smtp_user :,125
"def set_tracker_icon(tracker_icon, cell): <TAB> if tracker_icon: <TAB>  <TAB> pixbuf = tracker_icon.get_cached_icon() <MASK> pixbuf = get_pixbuf_at_size(tracker_icon.get_filename(), 16) <TAB>  <TAB>  <TAB> tracker_icon.set_cached_icon(pixbuf) <TAB> else: <TAB>  <TAB> pixbuf = create_blank_pixbuf() <TAB> # Suppress Warning: g_object_set_qdata: assertion `G_IS_OBJECT (object)' failed <TAB> with warnings.catch_warnings(): <TAB>  <TAB> warnings.simplefilter(""ignore"") <TAB>  <TAB> cell.set_property(""pixbuf"", pixbuf)",if pixbuf is None :,165
"def __create_index(self, collection, index, unique): <TAB> doc = collection.find_one(projection={""_id"": 1}) <TAB> if doc is None: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> indexes = list(collection.list_indexes()) <TAB>  <TAB> except OperationFailure: <TAB>  <TAB>  <TAB> indexes = [] <MASK> collection.create_index(index, unique=unique)",if index not in indexes :,97
"def read_oclc(fields): <TAB> if ""035"" not in fields: <TAB>  <TAB> return {} <TAB> found = [] <TAB> for line in fields[""035""]: <TAB>  <TAB> for v in get_subfield_values(line, [""a""]): <TAB>  <TAB>  <TAB> m = re_oclc.match(v) <MASK> continue <TAB>  <TAB>  <TAB> oclc = m.group(1) <TAB>  <TAB>  <TAB> if oclc not in found: <TAB>  <TAB>  <TAB>  <TAB> found.append(oclc) <TAB> return {""oclc_number"": found} if found else {}",if not m :,143
"def closest_enemy_ant(self, row1, col1, filter=None): <TAB> # find the closest enemy ant from this row/col <TAB> min_dist = maxint <TAB> closest_ant = None <TAB> for ant in self.enemy_ants(): <MASK> dist = self.distance(row1, col1, ant[0][0], ant[0][1]) <TAB>  <TAB>  <TAB> if dist < min_dist: <TAB>  <TAB>  <TAB>  <TAB> min_dist = dist <TAB>  <TAB>  <TAB>  <TAB> closest_ant = ant[0] <TAB> return closest_ant",if filter is None or ant not in filter :,146
"def fromVariant(variant): <TAB> if hasattr(QtCore, ""QVariant"") and isinstance(variant, QtCore.QVariant): <TAB>  <TAB> t = variant.type() <TAB>  <TAB> if t == QtCore.QVariant.String: <TAB>  <TAB>  <TAB> return str(variant.toString()) <MASK> return variant.toDouble()[0] <TAB>  <TAB> elif t == QtCore.QVariant.Int: <TAB>  <TAB>  <TAB> return variant.toInt()[0] <TAB>  <TAB> elif t == QtCore.QVariant.Bool: <TAB>  <TAB>  <TAB> return variant.toBool() <TAB>  <TAB> elif t == QtCore.QVariant.Invalid: <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError('Unsupported QVariant type ""%s""' % variant.typeName()) <TAB> else: <TAB>  <TAB> return variant",elif t == QtCore . QVariant . Double :,195
"def _check_old_with_state(self): <TAB> add_vec = False <TAB> for op in self.ops: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> op.get_coeff(0.0, self.args) <TAB>  <TAB>  <TAB> except TypeError as e: <TAB>  <TAB>  <TAB>  <TAB> nfunc = _StateAsArgs(self.coeff) <TAB>  <TAB>  <TAB>  <TAB> op = EvoElement((op.qobj, nfunc, nfunc, ""func"")) <TAB>  <TAB>  <TAB>  <TAB> add_vec = True <TAB> if add_vec: <TAB>  <TAB> self.dynamics_args += [(""_state_vec"", ""vec"", None)]","if op . type == ""func"" :",155
"def _read_readable(self, readable): <TAB> blocksize = 8192 <TAB> if self.debuglevel > 0: <TAB>  <TAB> print(""sendIng a read()able"") <TAB> encode = self._is_textIO(readable) <TAB> if encode and self.debuglevel > 0: <TAB>  <TAB> print(""encoding file using iso-8859-1"") <TAB> while True: <TAB>  <TAB> datablock = readable.read(blocksize) <MASK> break <TAB>  <TAB> if encode: <TAB>  <TAB>  <TAB> datablock = datablock.encode(""iso-8859-1"") <TAB>  <TAB> yield datablock",if not datablock :,139
"def read_chat_forever(reader, pub_socket): <TAB> line = reader.readline() <TAB> who = ""someone"" <TAB> while line: <TAB>  <TAB> print(""Chat:"", line.strip()) <TAB>  <TAB> if line.startswith(""name:""): <TAB>  <TAB>  <TAB> who = line.split("":"")[-1].strip() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> pub_socket.send_pyobj((who, line)) <TAB>  <TAB> except socket.error as e: <TAB>  <TAB>  <TAB> # ignore broken pipes, they just mean the participant <TAB>  <TAB>  <TAB> # closed its connection already <MASK> raise <TAB>  <TAB> line = reader.readline() <TAB> print(""Participant left chat."")",if e [ 0 ] != 32 :,162
"def _wrapped() -> None: <TAB> should_run = app.is_leader() if on_leader else True <TAB> if should_run: <TAB>  <TAB> with self.trace(shortlabel(fun), trace_enabled=traced): <TAB>  <TAB>  <TAB> # pass app only if decorated function takes an argument <MASK> task_takes_app = cast(Callable[[AppT], Awaitable], fun) <TAB>  <TAB>  <TAB>  <TAB> return await task_takes_app(app) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> task = cast(Callable[[], Awaitable], fun) <TAB>  <TAB>  <TAB>  <TAB> return await task()",if inspect . signature ( fun ) . parameters :,151
"def Decode(self, filedesc): <TAB> while True: <TAB>  <TAB> chunk = filedesc.Read(4) <TAB>  <TAB> if not chunk: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> if chunk == b""QUUX"": <TAB>  <TAB>  <TAB> yield b""NORF"" <MASK> yield b""BLARGH""","if chunk == b""THUD"" :",82
"def _get_modules(fn): <TAB> finder = modulefinder.ModuleFinder() <TAB> finder.run_script(fn) <TAB> all = [] <TAB> for m in finder.modules.values(): <TAB>  <TAB> if not isinstance(m, modulefinder.Module): <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> # skip shared object files <TAB>  <TAB> if m.__file__.endswith("".so""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # skip mac system stuff... <TAB>  <TAB> # FIXME: would need to augment with  other OS's system stuff <TAB>  <TAB> if m.__file__.startswith(""/Library/Frameworks""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> all.append(m) <TAB> return all",if not m . __file__ :,162
"def _read(self, size): <TAB> """"""Return size bytes from the stream."""""" <TAB> if self.comptype == ""tar"": <TAB>  <TAB> return self.__read(size) <TAB> c = len(self.dbuf) <TAB> while c < size: <TAB>  <TAB> buf = self.__read(self.bufsize) <MASK> break <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> buf = self.cmp.decompress(buf) <TAB>  <TAB> except IOError: <TAB>  <TAB>  <TAB> raise ReadError(""invalid compressed data"") <TAB>  <TAB> self.dbuf += buf <TAB>  <TAB> c += len(buf) <TAB> buf = self.dbuf[:size] <TAB> self.dbuf = self.dbuf[size:] <TAB> return buf",if not buf :,167
"def cluster_list(tokeniser): <TAB> clusterids = [] <TAB> value = tokeniser() <TAB> try: <TAB>  <TAB> if value == ""["": <TAB>  <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB>  <TAB> value = tokeniser() <MASK> break <TAB>  <TAB>  <TAB>  <TAB> clusterids.append(ClusterID(value)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> clusterids.append(ClusterID(value)) <TAB>  <TAB> if not clusterids: <TAB>  <TAB>  <TAB> raise ValueError(""no cluster-id in the cluster list"") <TAB>  <TAB> return ClusterList(clusterids) <TAB> except ValueError: <TAB>  <TAB> raise ValueError(""invalud cluster list"")","if value == ""]"" :",146
"def from_data(cls, value, currency, includes_tax=None): <TAB> if includes_tax is None: <MASK> msg = ""Missing includes_tax argument for %s.from_data"" <TAB>  <TAB>  <TAB> raise TypeError(msg % (cls.__name__,)) <TAB>  <TAB> includes_tax = cls.includes_tax <TAB> if includes_tax: <TAB>  <TAB> return TaxfulPrice(value, currency) <TAB> else: <TAB>  <TAB> return TaxlessPrice(value, currency)",if cls . includes_tax is None :,121
"def THUMB(image, nx=120, ny=120, gae=False, name=""thumb""): <TAB> if image: <MASK> request = current.request <TAB>  <TAB>  <TAB> from PIL import Image <TAB>  <TAB>  <TAB> import os <TAB>  <TAB>  <TAB> img = Image.open(os.path.join(request.folder, ""uploads"", image)) <TAB>  <TAB>  <TAB> img.thumbnail((nx, ny), Image.ANTIALIAS) <TAB>  <TAB>  <TAB> root, ext = os.path.splitext(image) <TAB>  <TAB>  <TAB> thumb = ""%s_%s%s"" % (root, name, ext) <TAB>  <TAB>  <TAB> img.save(request.folder + ""uploads/"" + thumb) <TAB>  <TAB>  <TAB> return thumb <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return image",if not gae :,176
"def _get_two_devices(self, require_same_type=False): <TAB> tpus = extensions.tpu_devices() <TAB> if FLAGS.requires_tpu: <TAB>  <TAB> if len(tpus) == 2: <TAB>  <TAB>  <TAB> res = tpus <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""This test requires 2 TPU cores but %s are found"" % len(tpus) <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> if len(tpus) == 2: <TAB>  <TAB>  <TAB> res = tpus <MASK> res = (""CPU:0"", ""GPU:0"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> res = (""CPU:0"", ""CPU:1"") <TAB> return res",elif self . _hasGPU ( ) and not require_same_type :,184
"def _format_repos(self, value): <TAB> result = {} <TAB> if value: <TAB>  <TAB> for path, config in iteritems(value): <MASK> # assume its a module <TAB>  <TAB>  <TAB>  <TAB> path = os.path.abspath(__import__(path).__file__) <TAB>  <TAB>  <TAB> result[path] = config <TAB> return result","if path [ 0 ] != ""/"" :",87
"def skipIndent(self, s, i, width): <TAB> ws = 0 <TAB> n = len(s) <TAB> while i < n and ws < width: <MASK> ws += abs(self.tab_width) - (ws % abs(self.tab_width)) <TAB>  <TAB> elif s[i] == "" "": <TAB>  <TAB>  <TAB> ws += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> i += 1 <TAB> return i","if s [ i ] == ""\t"" :",114
"def get_assets_historical_range_close_price( <TAB> self, start_dt, end_dt, asset_symbols, adjusted=False): <TAB> """""" """""" <TAB> prices_df = None <TAB> for ds in self.data_sources: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> prices_df = ds.get_assets_historical_closes( <TAB>  <TAB>  <TAB>  <TAB> start_dt, end_dt, asset_symbols, adjusted=adjusted <TAB>  <TAB>  <TAB> ) <MASK> return prices_df <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> raise <TAB> return prices_df",if prices_df is not None :,145
"def matchBrackets(string): <TAB> rest = string[1:] <TAB> inside = ""("" <TAB> while rest != """" and not rest.startswith("")""): <MASK> (part, rest) = matchBrackets(rest) <TAB>  <TAB>  <TAB> inside = inside + part <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> inside = inside + rest[0] <TAB>  <TAB>  <TAB> rest = rest[1:] <TAB> if rest.startswith("")""): <TAB>  <TAB> return (inside + "")"", rest[1:]) <TAB> raise AssertionError(""Unmatched bracket in string '"" + string + ""'"")","if rest . startswith ( ""("" ) :",122
"def is_different(item, seen): <TAB> is_diff = True <TAB> if item not in seen: <TAB>  <TAB> for value in other: <MASK> is_diff = False <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if is_diff: <TAB>  <TAB>  <TAB> seen.append(item) <TAB> return is_diff","if comparator ( iteratee ( item ) , iteratee ( value ) ) :",91
"def write_conditional_formatting(worksheet): <TAB> """"""Write conditional formatting to xml."""""" <TAB> wb = worksheet.parent <TAB> for range_string, rules in iteritems(worksheet.conditional_formatting.cf_rules): <TAB>  <TAB> cf = Element(""conditionalFormatting"", {""sqref"": range_string}) <TAB>  <TAB> for rule in rules: <TAB>  <TAB>  <TAB> if rule.dxf is not None: <MASK> rule.dxfId = len(wb._differential_styles) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> wb._differential_styles.append(rule.dxf) <TAB>  <TAB>  <TAB> cf.append(rule.to_tree()) <TAB>  <TAB> yield cf",if rule . dxf != DifferentialStyle ( ) :,164
"def checkForFinishedThreads(self): <TAB> ""Mark terminated threads with endTime."" <TAB> for t in self.unfinishedThreads: <MASK> t.endTime = time.process_time() <TAB>  <TAB>  <TAB> if getattr(t, ""status"", None) is None: <TAB>  <TAB>  <TAB>  <TAB> t.status = ""ended""",if not t . is_alive ( ) :,84
"def _process_dispatch_entries(self, dispatch_info_external): <TAB> path_only_entries = [] <TAB> hostname_entries = [] <TAB> for entry in dispatch_info_external.dispatch: <TAB>  <TAB> parsed_url = dispatchinfo.ParsedURL(entry.url) <MASK> hostname_entries.append(entry) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> path_only_entries.append((parsed_url, entry.server)) <TAB> if hostname_entries: <TAB>  <TAB> logging.warning( <TAB>  <TAB>  <TAB> ""Hostname routing is not supported by the development server. The "" <TAB>  <TAB>  <TAB> ""following dispatch entries will not match any requests:\n%s"", <TAB>  <TAB>  <TAB> ""\n\t"".join(str(entry) for entry in hostname_entries), <TAB>  <TAB> ) <TAB> self._entries = path_only_entries",if parsed_url . host :,196
"def iter_ReassignParameters(self, inputNode, variables, nodeByID): <TAB> for node in inputNode.getReassignParameterNodes(nodeByID): <TAB>  <TAB> yield from iterNodeCommentLines(node) <TAB>  <TAB> yield from iterInputConversionLines(node, variables) <TAB>  <TAB> socket = node.inputs[0] <MASK> expression = getCopyExpression(socket, variables) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> expression = variables[socket] <TAB>  <TAB> if node.conditionSocket is None: <TAB>  <TAB>  <TAB> conditionPrefix = """" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> conditionPrefix = ""if {}: "".format(variables[node.conditionSocket]) <TAB>  <TAB> yield ""{}{} = {}"".format( <TAB>  <TAB>  <TAB> conditionPrefix, variables[node.linkedParameterSocket], expression <TAB>  <TAB> )",if socket . isUnlinked and socket . isCopyable ( ) :,192
"def _feed_data(self, data_pair: types.Sequence, type_: str) -> types.Sequence: <TAB> result = [] <TAB> type_list = [ChartType.LINES, ChartType.CUSTOM] <TAB> if type_ in type_list: <TAB>  <TAB> result = data_pair <TAB> else: <TAB>  <TAB> for n, v in data_pair: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> lng, lat = self.get_coordinate(n) <TAB>  <TAB>  <TAB>  <TAB> result.append({""name"": n, ""value"": [lng, lat, v]}) <TAB>  <TAB>  <TAB> except TypeError as err: <MASK> raise NonexistentCoordinatesException(err, (n, v)) <TAB> return result",if self . _is_ignore_nonexistent_coord is not True :,175
"def _parse_whois(self, txt): <TAB> asn, desc = None, b"""" <TAB> for l in txt.splitlines(): <TAB>  <TAB> if not asn and l.startswith(b""origin:""): <TAB>  <TAB>  <TAB> asn = l[7:].strip().decode(""utf-8"") <TAB>  <TAB> if l.startswith(b""descr:""): <TAB>  <TAB>  <TAB> if desc: <TAB>  <TAB>  <TAB>  <TAB> desc += br""\n"" <TAB>  <TAB>  <TAB> desc += l[6:].strip() <MASK> desc = desc.strip().decode(""utf-8"") <TAB>  <TAB>  <TAB> break <TAB> return asn, desc",if asn is not None and desc . strip ( ) :,151
"def _resolve_result(self, f=None): <TAB> try: <MASK> results = f.result() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> results = list(map(self._client.results.get, self.msg_ids)) <TAB>  <TAB> if self._single_result: <TAB>  <TAB>  <TAB> r = results[0] <TAB>  <TAB>  <TAB> if isinstance(r, Exception): <TAB>  <TAB>  <TAB>  <TAB> raise r <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> results = error.collect_exceptions(results, self._fname) <TAB>  <TAB> self._success = True <TAB>  <TAB> self.set_result(self._reconstruct_result(results)) <TAB> except Exception as e: <TAB>  <TAB> self._success = False <TAB>  <TAB> self.set_exception(e)",if f :,174
"def new_org(type=ORG_DEFAULT, block=True, **kwargs): <TAB> if type == ORG_DEFAULT: <TAB>  <TAB> org = reserve_pooled(type=type, **kwargs) <MASK> org = queue.reserve(""queued_org"", block=block, type=type, **kwargs) <TAB>  <TAB> if org: <TAB>  <TAB>  <TAB> new_pooled() <TAB>  <TAB>  <TAB> return org <TAB>  <TAB> org = Organization(type=type, **kwargs) <TAB>  <TAB> org.initialize() <TAB>  <TAB> org.commit() <TAB>  <TAB> return org <TAB> else: <TAB>  <TAB> org = Organization(type=type, **kwargs) <TAB>  <TAB> org.queue_initialize(block=block) <TAB>  <TAB> return org",if not org :,171
"def _compileRules(rulesList, maxLength=4): <TAB> ruleChecking = collections.defaultdict(list) <TAB> for ruleIndex in range(len(rulesList)): <TAB>  <TAB> args = [] <MASK> args = rulesList[ruleIndex][-1] <TAB>  <TAB> if maxLength == 4: <TAB>  <TAB>  <TAB> (shouldRunMethod, method, isCorrect) = rulesList[ruleIndex][0:3] <TAB>  <TAB>  <TAB> ruleChecking[shouldRunMethod].append((method, isCorrect, args)) <TAB>  <TAB> elif maxLength == 3: <TAB>  <TAB>  <TAB> (shouldRunMethod, method) = rulesList[ruleIndex][0:2] <TAB>  <TAB>  <TAB> ruleChecking[shouldRunMethod].append((method, args)) <TAB> return ruleChecking",if len ( rulesList [ ruleIndex ] ) == maxLength :,183
"def setHighlightedItem(self, item): <TAB> if item != None: <TAB>  <TAB> for listItem in self.children.getItems(): <MASK> self.children.setCurrentItem(listItem) <TAB>  <TAB>  <TAB>  <TAB> return <TAB> else: <TAB>  <TAB> self.children.setCurrentItem(None)","if self . loadHandler . matchesItem ( listItem , item ) :",88
"def getForts(location): <TAB> global forts <TAB> lforts = [] <TAB> for i in forts: <TAB>  <TAB> f = (i[""latitude""], i[""longitude""]) <TAB>  <TAB> d = vincenty(location, f).meters <MASK> lforts.append(i) <TAB> return lforts",if d < 900 :,87
"def page_file(self, page): <TAB> if page.isroot: <TAB>  <TAB> raise PathLookupError(""Can not export: %s"", page) <TAB> elif self.namespace: <MASK> name = page.relname(self.namespace) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # This layout can not store page == namespace ! <TAB>  <TAB>  <TAB> raise PathLookupError(""%s not a child of %s"" % (page, self.namespace)) <TAB> else: <TAB>  <TAB> name = page.name <TAB> return self.dir.file(encode_filename(name) + ""."" + self.ext)",if page . ischild ( self . namespace ) :,145
"def to_json_dict(self): <TAB> d = super().to_json_dict() <TAB> if self.header is not None: <TAB>  <TAB> if isinstance(self.header, RenderedContent): <TAB>  <TAB>  <TAB> d[""header""] = self.header.to_json_dict() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> d[""header""] = self.header <TAB> if self.subheader is not None: <MASK> d[""subheader""] = self.subheader.to_json_dict() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> d[""subheader""] = self.subheader <TAB> d[""text""] = RenderedContent.rendered_content_list_to_json(self.text) <TAB> return d","if isinstance ( self . subheader , RenderedContent ) :",168
"def fixfunnychars(addr): <TAB> i = 0 <TAB> while i < len(addr): <TAB>  <TAB> c = addr[i] <MASK> c = ""-"" <TAB>  <TAB>  <TAB> addr = addr[:i] + c + addr[i + 1 :] <TAB>  <TAB> i = i + len(c) <TAB> return addr",if c not in goodchars :,83
"def refactor_stdin(self, doctests_only=False): <TAB> input = sys.stdin.read() <TAB> if doctests_only: <TAB>  <TAB> self.log_debug(""Refactoring doctests in stdin"") <TAB>  <TAB> output = self.refactor_docstring(input, ""<stdin>"") <MASK> self.processed_file(output, ""<stdin>"", input) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.log_debug(""No doctest changes in stdin"") <TAB> else: <TAB>  <TAB> tree = self.refactor_string(input, ""<stdin>"") <TAB>  <TAB> if self.write_unchanged_files or (tree and tree.was_changed): <TAB>  <TAB>  <TAB> self.processed_file(str(tree), ""<stdin>"", input) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.log_debug(""No changes in stdin"")",if self . write_unchanged_files or output != input :,199
"def test_compute_gradient(self): <TAB> for y, y_pred in zip(self.y_list, self.predict_list): <TAB>  <TAB> lse_grad = self.lae_loss.compute_grad(y, y_pred) <TAB>  <TAB> diff = y_pred - y <MASK> grad = 1 <TAB>  <TAB> elif diff < consts.FLOAT_ZERO: <TAB>  <TAB>  <TAB> grad = -1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> grad = 0 <TAB>  <TAB> self.assertTrue(np.fabs(lse_grad - grad) < consts.FLOAT_ZERO)",if diff > consts . FLOAT_ZERO :,145
"def restart(self): <TAB> try: <TAB>  <TAB> # remove old pidfile first <TAB>  <TAB> try: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.daemon.stop() <TAB>  <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> self.log.critical(traceback.format_exc()) <TAB>  <TAB> # Release log files and shutdown logger <TAB>  <TAB> logging.shutdown() <TAB>  <TAB> args = ( <TAB>  <TAB>  <TAB> [sys.executable] <TAB>  <TAB>  <TAB> + [os.path.join(base_path, os.path.basename(__file__))] <TAB>  <TAB>  <TAB> + sys.argv[1:] <TAB>  <TAB> ) <TAB>  <TAB> subprocess.Popen(args) <TAB> except: <TAB>  <TAB> self.log.critical(traceback.format_exc())",if self . runAsDaemon ( ) :,188
"def classifyws(s, tabwidth): <TAB> raw = effective = 0 <TAB> for ch in s: <MASK> raw = raw + 1 <TAB>  <TAB>  <TAB> effective = effective + 1 <TAB>  <TAB> elif ch == ""\t"": <TAB>  <TAB>  <TAB> raw = raw + 1 <TAB>  <TAB>  <TAB> effective = (effective // tabwidth + 1) * tabwidth <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> return raw, effective","if ch == "" "" :",101
"def code_match(code, select, ignore): <TAB> if ignore: <TAB>  <TAB> assert not isinstance(ignore, unicode) <TAB>  <TAB> for ignored_code in [c.strip() for c in ignore]: <TAB>  <TAB>  <TAB> if mutual_startswith(code.lower(), ignored_code.lower()): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> if select: <TAB>  <TAB> assert not isinstance(select, unicode) <TAB>  <TAB> for selected_code in [c.strip() for c in select]: <MASK> return True <TAB>  <TAB> return False <TAB> return True","if mutual_startswith ( code . lower ( ) , selected_code . lower ( ) ) :",143
"def get_tokens_unprocessed(self, text): <TAB> from pygments.lexers._asy_builtins import ASYFUNCNAME, ASYVARNAME <TAB> for index, token, value in RegexLexer.get_tokens_unprocessed(self, text): <MASK> token = Name.Function <TAB>  <TAB> elif token is Name and value in ASYVARNAME: <TAB>  <TAB>  <TAB> token = Name.Variable <TAB>  <TAB> yield index, token, value",if token is Name and value in ASYFUNCNAME :,113
"def makeDataURI(data=None, mimetype=None, filename=None): <TAB> import base64 <TAB> if not mimetype: <MASK> import mimetypes <TAB>  <TAB>  <TAB> mimetype = mimetypes.guess_type(filename)[0].split("";"")[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> ""You need to provide a mimetype or a filename for makeDataURI"" <TAB>  <TAB>  <TAB> ) <TAB> return ""data:"" + mimetype + "";base64,"" + """".join(base64.encodestring(data).split())",if filename :,125
"def add_attributes(attributes, all_base64): <TAB> lines = [] <TAB> oc_attr = None <TAB> # objectclass first, even if this is not specified in the RFC <TAB> for attr in attributes: <MASK> for val in attributes[attr]: <TAB>  <TAB>  <TAB>  <TAB> lines.append(_convert_to_ldif(attr, val, all_base64)) <TAB>  <TAB>  <TAB> oc_attr = attr <TAB>  <TAB>  <TAB> break <TAB> # remaining attributes <TAB> for attr in attributes: <TAB>  <TAB> if attr != oc_attr and attr in attributes: <TAB>  <TAB>  <TAB> for val in attributes[attr]: <TAB>  <TAB>  <TAB>  <TAB> lines.append(_convert_to_ldif(attr, val, all_base64)) <TAB> return lines","if attr . lower ( ) == ""objectclass"" :",177
"def read_optional_seed(fill, base="""", ext="""", timeout=5): <TAB> try: <TAB>  <TAB> (md, ud, vd) = read_seeded(base, ext, timeout) <TAB>  <TAB> fill[""user-data""] = ud <TAB>  <TAB> fill[""vendor-data""] = vd <TAB>  <TAB> fill[""meta-data""] = md <TAB>  <TAB> return True <TAB> except url_helper.UrlError as e: <MASK> return False <TAB>  <TAB> raise",if e . code == url_helper . NOT_FOUND :,120
"def _get_spawn_property(self, constraints, constraint_name, services): <TAB> if services: <TAB>  <TAB> # this isn't very nice <TAB>  <TAB> if constraint_name == IMAGE_CONSTRAINT: <TAB>  <TAB>  <TAB> return services[0].image <MASK> return services[0].cpus <TAB> for constraint in constraints: <TAB>  <TAB> if constraint.name == constraint_name: <TAB>  <TAB>  <TAB> return constraint.value <TAB> return None",elif constraint_name == CPUS_CONSTRAINT :,113
def delete_api(self): <TAB> retries = 0 <TAB> while retries < 10: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.client.delete_rest_api(restApiId=self.api_id) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> except exceptions.ClientError as e: <MASK> retries += 1 <TAB>  <TAB>  <TAB>  <TAB> time.sleep(5) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise,"if e . response [ ""Error"" ] [ ""Code"" ] == ""TooManyRequestsException"" :",114
"def GetSelected(self): <TAB> if self.GetStyleL(""style"") & self.Style.LBS_MULTIPLESEL: <TAB>  <TAB> result = self.SendMessage(self.Hwnd, self.Msg.LB_GETSELCOUNT, 0, 0) <MASK> return self.SendMessage(self.Hwnd, self.Msg.LB_GETANCHORINDEX, 0, 0) <TAB> else: <TAB>  <TAB> result = self.SendMessage(self.Hwnd, self.Msg.LB_GETCURSEL, 0, 0) <TAB>  <TAB> if result != LB_ERR: <TAB>  <TAB>  <TAB> return result",if result :,151
"def compare_objects(left, right): <TAB> left_fields = left.map_value.fields <TAB> right_fields = right.map_value.fields <TAB> for left_key, right_key in zip(sorted(left_fields), sorted(right_fields)): <TAB>  <TAB> keyCompare = Order._compare_to(left_key, right_key) <TAB>  <TAB> if keyCompare != 0: <TAB>  <TAB>  <TAB> return keyCompare <TAB>  <TAB> value_compare = Order.compare(left_fields[left_key], right_fields[right_key]) <MASK> return value_compare <TAB> return Order._compare_to(len(left_fields), len(right_fields))",if value_compare != 0 :,163
"def get_opnd_types_short(ii): <TAB> types = [] <TAB> for op in _gen_opnds(ii): <TAB>  <TAB> if op.oc2: <TAB>  <TAB>  <TAB> types.append(op.oc2) <MASK> types.append(""v"") <TAB>  <TAB> elif op_luf_start(op, ""GPRz""): <TAB>  <TAB>  <TAB> types.append(""z"") <TAB>  <TAB> elif op_luf_start(op, ""GPRy""): <TAB>  <TAB>  <TAB> types.append(""y"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> die(""Unhandled op type {}"".format(op)) <TAB> return types","elif op_luf_start ( op , ""GPRv"" ) :",161
"def _iter_indented_subactions(self, action): <TAB> try: <TAB>  <TAB> get_subactions = action._get_subactions <TAB> except AttributeError: <TAB>  <TAB> pass <TAB> else: <TAB>  <TAB> self._indent() <MASK> for subaction in sorted(get_subactions(), key=lambda x: x.dest): <TAB>  <TAB>  <TAB>  <TAB> yield subaction <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for subaction in get_subactions(): <TAB>  <TAB>  <TAB>  <TAB> yield subaction <TAB>  <TAB> self._dedent()","if isinstance ( action , argparse . _SubParsersAction ) :",132
"def has_safe_repr(value): <TAB> """"""Does the node have a safe representation?"""""" <TAB> if value is None or value is NotImplemented or value is Ellipsis: <TAB>  <TAB> return True <TAB> if type(value) in (bool, int, float, complex, range_type, Markup) + string_types: <TAB>  <TAB> return True <TAB> if type(value) in (tuple, list, set, frozenset): <TAB>  <TAB> for item in value: <MASK> return False <TAB>  <TAB> return True <TAB> elif type(value) is dict: <TAB>  <TAB> for key, value in iteritems(value): <TAB>  <TAB>  <TAB> if not has_safe_repr(key): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> if not has_safe_repr(value): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True <TAB> return False",if not has_safe_repr ( item ) :,198
"def _compute_missing_fields_error(context, field_defs, incoming_fields): <TAB> missing_fields = [] <TAB> for field_name, field_def in field_defs.items(): <MASK> missing_fields.append(field_name) <TAB> if missing_fields: <TAB>  <TAB> if len(missing_fields) == 1: <TAB>  <TAB>  <TAB> return create_missing_required_field_error(context, missing_fields[0]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return create_missing_required_fields_error(context, missing_fields)",if not field_def . is_optional and field_name not in incoming_fields :,150
"def _list(self): <TAB> data_sources = self.mkt_contract.functions.getAllProviders().call() <TAB> data = [] <TAB> for index, data_source in enumerate(data_sources): <MASK> if ""test"" not in Web3.toText(data_source).lower(): <TAB>  <TAB>  <TAB>  <TAB> data.append(dict(dataset=self.to_text(data_source))) <TAB> return pd.DataFrame(data)",if index > 0 :,111
"def close_file_in_all_editorstacks(self, editorstack_id_str, index): <TAB> for editorstack in self.editorstacks: <MASK> editorstack.blockSignals(True) <TAB>  <TAB>  <TAB> editorstack.close_file(index, force=True) <TAB>  <TAB>  <TAB> editorstack.blockSignals(False)",if str ( id ( editorstack ) ) != editorstack_id_str :,97
"def _remove_custom_marker_object_instances(self): <TAB> for id, obj in list(self._objects.items()): <MASK> logger.info(""Removing CustomObject instance: id %s = obj '%s'"", id, obj) <TAB>  <TAB>  <TAB> del self._objects[id]","if isinstance ( obj , objects . CustomObject ) :",79
"def append(self, labels): <TAB> if isinstance(labels, list): <TAB>  <TAB> for label in labels: <MASK> self.__menuLabels.append(label) <TAB>  <TAB>  <TAB>  <TAB> self.__enabledLabels.append(label) <TAB> else: <TAB>  <TAB> if not labels in self.__menuLabels: <TAB>  <TAB>  <TAB> self.__menuLabels.append(labels) <TAB>  <TAB>  <TAB> self.__enabledLabels.append(labels)",if not label in self . __menuLabels :,108
"def _close_tree(view: View, defx: Defx, context: Context) -> None: <TAB> for target in context.targets: <MASK> view.close_tree(target[""action__path""], defx._index) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> view.close_tree(target[""action__path""].parent, defx._index) <TAB>  <TAB>  <TAB> view.search_file(target[""action__path""].parent, defx._index)","if target [ ""is_directory"" ] and target [ ""is_opened_tree"" ] :",124
"def FirstFetch(self): <TAB> q = collections.deque([""buddy"", ""group"", ""discuss""]) <TAB> while q: <TAB>  <TAB> tinfo = q.popleft() <MASK> cl = self.List(tinfo) <TAB>  <TAB>  <TAB> if cl: <TAB>  <TAB>  <TAB>  <TAB> q.extend(cl) <TAB>  <TAB> time.sleep(1.0)","if self . Update ( tinfo ) and tinfo in ( ""group"" , ""discuss"" ) :",106
"def _sort_values_jobconf(self): <TAB> """"""Jobconf dictionary to enable sorting by value."""""" <TAB> if not self._sort_values: <TAB>  <TAB> return {} <TAB> # translate _SORT_VALUES_JOBCONF to the correct Hadoop version, <TAB> # without logging a warning <TAB> hadoop_version = self.get_hadoop_version() <TAB> jobconf = {} <TAB> for k, v in _SORT_VALUES_JOBCONF.items(): <MASK> jobconf[translate_jobconf(k, hadoop_version)] = v <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for j in translate_jobconf_for_all_versions(k): <TAB>  <TAB>  <TAB>  <TAB> jobconf[j] = v <TAB> return jobconf",if hadoop_version :,175
"def list(self): <TAB> for fname in os.listdir(self.path): <TAB>  <TAB> fpath = os.path.join(self.path, fname) <MASK> yield fname, get_etag_from_file(fpath)",if os . path . isfile ( fpath ) and fname . endswith ( self . fileext ) :,75
"def get_environment_variable_value(val): <TAB> env_val = val <TAB> if val is not None and isinstance(val, str): <TAB>  <TAB> match = re.search(r""^\${(?P<environment_key_name>\w+)*}$"", val) <MASK> env_val = os.environ.get(match.group(""environment_key_name"")) <TAB> return env_val",if match is not None :,99
"def L_op(self, inputs, outputs, grads): <TAB> (x,) = inputs <TAB> (gz,) = grads <TAB> if x.type in complex_types: <TAB>  <TAB> raise NotImplementedError() <TAB> if outputs[0].type in discrete_types: <MASK> return [x.zeros_like(dtype=theano.config.floatX)] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return [x.zeros_like()] <TAB> cst = np.asarray(np.sqrt(np.pi) / 2.0, dtype=upcast(x.type.dtype, gz.type.dtype)) <TAB> return (gz * cst * exp(erfinv(x) ** 2),)",if x . type in discrete_types :,165
"def is_test_finished(self): <TAB> retcode = self.process.poll() <TAB> if retcode is not None: <TAB>  <TAB> logger.info(""Phantom done its work with exit code: %s"", retcode) <TAB>  <TAB> self.phout_finished.set() <TAB>  <TAB> return abs(retcode) <TAB> else: <TAB>  <TAB> info = self.get_info() <MASK> eta = int(info.duration) - (int(time.time()) - int(self.start_time)) <TAB>  <TAB>  <TAB> self.publish(""eta"", eta) <TAB>  <TAB> return -1",if info :,139
"def icon(display_icon): <TAB> """"""returns empty dict if show_icons is False, else the icon passed"""""" <TAB> kws = {} <TAB> if get_icon_switch(): <MASK> kws = {""icon_value"": custom_icon(display_icon)} <TAB>  <TAB> elif display_icon != ""OUTLINER_OB_EMPTY"": <TAB>  <TAB>  <TAB> kws = {""icon"": display_icon} <TAB> return kws","if display_icon . startswith ( ""SV_"" ) :",106
"def raise_to_cubic(bzs): <TAB> result = [] <TAB> for sp in bzs: <TAB>  <TAB> r = [] <TAB>  <TAB> for bz in sp: <MASK> r.append( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> bz[0], <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> lerppt(2.0 / 3, bz[0], bz[1]), <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> lerppt(2.0 / 3, bz[2], bz[1]), <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> bz[2], <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> r.append(bz) <TAB>  <TAB> result.append(r) <TAB> return result",if len ( bz ) == 3 :,181
def readline(self): <TAB> while 1: <TAB>  <TAB> line = self._readline() <TAB>  <TAB> if line: <TAB>  <TAB>  <TAB> self._filelineno += 1 <TAB>  <TAB>  <TAB> return line <MASK> return line <TAB>  <TAB> self.nextfile(),if not self . _file :,65
"def readlines(self): <TAB> """"""Returns a list of all lines (optionally parsed) in the file."""""" <TAB> if self.grammar: <TAB>  <TAB> tot = [] <TAB>  <TAB> # Used this way instead of a 'for' loop against <TAB>  <TAB> # self.file.readlines() so that there wasn't two copies of the file <TAB>  <TAB> # in memory. <TAB>  <TAB> while 1: <TAB>  <TAB>  <TAB> line = self.file.readline() <MASK> break <TAB>  <TAB>  <TAB> tot.append(line) <TAB>  <TAB> return tot <TAB> return self.file.readlines()",if not line :,135
"def visit_return(self, node): <TAB> # TODO: pythoncile.py handled (a) spliting CITDL (scoperef), (b) <TAB> # <TAB>   excluding ""None"" and ""NoneType"", (c) True/False -> bool. <TAB> # <TAB>   pythoncile.py also gather all return's and picked the most <TAB> # <TAB>   common guess. <TAB> # TODO:XXX Evaluate the necessity of multiple return statement analysis. <TAB> scope = self._peek_scope() <TAB> assert scope.ilk == ""function"" <TAB> if not scope.get(""returns""): <TAB>  <TAB> citdl = self._citdl_from_node(node.children[1]) <MASK> scope.attrs[""returns""] = citdl","if citdl and citdl is not ""None"" :",191
"def load_json_file(file_path): <TAB> """"""load a file into a json object"""""" <TAB> try: <TAB>  <TAB> with open(file_path) as small_file: <TAB>  <TAB>  <TAB> return json.load(small_file) <TAB> except OSError as e: <TAB>  <TAB> print(e) <TAB>  <TAB> print(""trying to read file in blocks"") <TAB>  <TAB> with open(file_path) as big_file: <TAB>  <TAB>  <TAB> json_string = """" <TAB>  <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB>  <TAB> block = big_file.read(64 * (1 << 20))  # Read 64 MB at a time; <TAB>  <TAB>  <TAB>  <TAB> json_string = json_string + block <MASK> # Reached EOF <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> return json.loads(json_string)",if not block :,189
"def rotate(cls, axis, theta): <TAB> """"""Prepare a quaternion that represents a rotation on a given axis."""""" <TAB> if isinstance(axis, str): <TAB>  <TAB> if axis in (""x"", ""X""): <TAB>  <TAB>  <TAB> axis = V.X <MASK> axis = V.Y <TAB>  <TAB> elif axis in (""z"", ""Z""): <TAB>  <TAB>  <TAB> axis = V.Z <TAB> axis = axis.normalize() <TAB> s = math.sin(theta / 2.0) <TAB> c = math.cos(theta / 2.0) <TAB> return Q(axis._v[0] * s, axis._v[1] * s, axis._v[2] * s, c)","elif axis in ( ""y"" , ""Y"" ) :",169
"def is_valid_block(self): <TAB> """"""check wheter the block is valid in the current position"""""" <TAB> for i in range(self.block.x): <TAB>  <TAB> for j in range(self.block.x): <TAB>  <TAB>  <TAB> if self.block.get(i, j): <TAB>  <TAB>  <TAB>  <TAB> if self.block.pos.x + i < 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB>  <TAB> if self.block.pos.x + i >= COLUMNS: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <MASK> return False <TAB>  <TAB>  <TAB>  <TAB> if self.map.get((self.block.pos.x + i, self.block.pos.y + j), False): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return True",if self . block . pos . y + j < 0 :,192
def dump_token_list(tokens): <TAB> for token in tokens: <TAB>  <TAB> if token.token_type == TOKEN_TEXT: <TAB>  <TAB>  <TAB> writer.write(token.contents) <MASK> writer.print_expr(token.contents) <TAB>  <TAB>  <TAB> touch_var(token.contents),elif token . token_type == TOKEN_VAR :,83
"def encode(name, value): <TAB> try: <MASK> value, params = value <TAB>  <TAB>  <TAB> return _encode_parametrized(name, value, params) <TAB>  <TAB> return _encode_unstructured(name, value) <TAB> except Exception: <TAB>  <TAB> _log.exception(""Failed to encode %s %s"" % (name, value)) <TAB>  <TAB> raise","if parametrized . is_parametrized ( name , value ) :",102
"def conversation_to_fb_format(conversation): <TAB> assert len(conversation) > 1 <TAB> lines = [] <TAB> for i in range(0, len(conversation), 2): <MASK> lines.append( <TAB>  <TAB>  <TAB>  <TAB> ""%d %s\t%s"" % (i / 2 + 1, conversation[i], conversation[i + 1]) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lines.append(""%d %s"" % (i / 2 + 1, conversation[i])) <TAB> return ""\n"".join(lines)",if i + 1 < len ( conversation ) :,145
"def _handle_js_events(self, change): <TAB> if self.js_events: <MASK> for event in self.js_events: <TAB>  <TAB>  <TAB>  <TAB> event_name = event[""name""] <TAB>  <TAB>  <TAB>  <TAB> if event_name in self.event_handlers: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.event_handlers[event_name](event[""detail""]) <TAB>  <TAB> # clears the event queue. <TAB>  <TAB> self.js_events = []",if self . event_handlers :,113
"def escapeall(self, lines): <TAB> ""Escape all lines in an array according to the output options."" <TAB> result = [] <TAB> for line in lines: <TAB>  <TAB> if Options.html: <TAB>  <TAB>  <TAB> line = self.escape(line, EscapeConfig.html) <TAB>  <TAB> if Options.iso885915: <TAB>  <TAB>  <TAB> line = self.escape(line, EscapeConfig.iso885915) <TAB>  <TAB>  <TAB> line = self.escapeentities(line) <MASK> line = self.escape(line, EscapeConfig.nonunicode) <TAB>  <TAB> result.append(line) <TAB> return result",elif not Options . unicode :,143
"def filter_testsuite(suite, matcher, level=None): <TAB> """"""Returns a flattened list of test cases that match the given matcher."""""" <TAB> if not isinstance(suite, unittest.TestSuite): <TAB>  <TAB> raise TypeError(""not a TestSuite"", suite) <TAB> results = [] <TAB> for test in suite._tests: <TAB>  <TAB> if level is not None and getattr(test, ""level"", 0) > level: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if isinstance(test, unittest.TestCase): <TAB>  <TAB>  <TAB> testname = test.id()  # package.module.class.method <MASK> results.append(test) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> filtered = filter_testsuite(test, matcher, level) <TAB>  <TAB>  <TAB> results.extend(filtered) <TAB> return results",if matcher ( testname ) :,185
"def _close_brackets(self, fragment): <TAB> # If there any unclosed brackets in the text we try to close them <TAB> # and we return part with closing brackets if they are ""closable"" <TAB> stack = [] <TAB> for char in fragment: <TAB>  <TAB> if char in self._PARENS.keys(): <TAB>  <TAB>  <TAB> stack.append(char) <MASK> if stack and self._PARENS[stack[-1]] == char: <TAB>  <TAB>  <TAB>  <TAB> stack.pop() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return """" <TAB> return """".join(self._PARENS[paren] for paren in reversed(stack))",elif char in self . _PARENS . values ( ) :,150
"def restrict(points): <TAB> result = [] <TAB> for p in points: <TAB>  <TAB> if point_inside_mesh(bvh, p): <TAB>  <TAB>  <TAB> result.append(p) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> loc, normal, index, distance = bvh.find_nearest(p) <MASK> result.append(tuple(loc)) <TAB> return result",if loc is not None :,96
"def _check_ids(el, filename, parent_id): <TAB> """"""Recursively walks through tree and check if every object has ID"""""" <TAB> for child in el: <TAB>  <TAB> if child.tag == ""object"": <TAB>  <TAB>  <TAB> msg = ""Widget has no ID in %s; class %s; Parent id: %s"" % ( <TAB>  <TAB>  <TAB>  <TAB> filename, <TAB>  <TAB>  <TAB>  <TAB> child.attrib[""class""], <TAB>  <TAB>  <TAB>  <TAB> parent_id, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> assert ""id"" in child.attrib and child.attrib[""id""], msg <TAB>  <TAB>  <TAB> for subel in child: <MASK> _check_ids(subel, filename, child.attrib[""id""])","if subel . tag == ""child"" :",173
"def _checkIfSuccessfulCallback(self, result, error=False, **kwargs): <TAB> if error: <TAB>  <TAB> connection_error = kwargs.get(""connection_error"", False) <MASK> log.debug( <TAB>  <TAB>  <TAB>  <TAB> ""During direct file upload compute is not visible. Fallback to upload via controller."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> # there was an issue with connection, probably we don't have a direct access to compute <TAB>  <TAB>  <TAB> # we need to fallback to uploading files via controller <TAB>  <TAB>  <TAB> self._fileUploadToController() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if ""message"" in result: <TAB>  <TAB>  <TAB>  <TAB> log.error( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Error while direct file upload: {}"".format(result[""message""]) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return <TAB> self._callback(result, error, **kwargs)",if connection_error :,198
"def getCellPropertyNames_aux(self, col_id): <TAB> if col_id == ""name"": <MASK> return [""places_busy""] <TAB>  <TAB> baseName = self.image_icon <TAB>  <TAB> if self.isOpen: <TAB>  <TAB>  <TAB> return [baseName + ""_open""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return [baseName + ""_closed""] <TAB> return []","if self . image_icon == ""places_busy"" :",102
"def delete_volume(self, volume_id): <TAB> if volume_id in self.volumes: <TAB>  <TAB> volume = self.volumes[volume_id] <MASK> raise VolumeInUseError(volume_id, volume.attachment.instance.id) <TAB>  <TAB> return self.volumes.pop(volume_id) <TAB> raise InvalidVolumeIdError(volume_id)",if volume . attachment :,92
"def dashboards(self): <TAB> dashboards = OrderedDict() <TAB> for slug, path in enumerate(app_settings.DASHBOARDS): <MASK> slug, path = path <TAB>  <TAB> pk = str(slug) <TAB>  <TAB> klass = import_string(path) <TAB>  <TAB> dashboards[pk] = klass(pk=pk) <TAB> if not dashboards: <TAB>  <TAB> raise ImproperlyConfigured(""No dashboards found."") <TAB> return dashboards","if isinstance ( path , ( list , tuple ) ) :",112
"def test_reader(config, device, logger): <TAB> loader = build_dataloader(config, ""Train"", device, logger) <TAB> import time <TAB> starttime = time.time() <TAB> count = 0 <TAB> try: <TAB>  <TAB> for data in loader(): <TAB>  <TAB>  <TAB> count += 1 <MASK> batch_time = time.time() - starttime <TAB>  <TAB>  <TAB>  <TAB> starttime = time.time() <TAB>  <TAB>  <TAB>  <TAB> logger.info( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""reader: {}, {}, {}"".format(count, len(data[0]), batch_time) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> except Exception as e: <TAB>  <TAB> logger.info(e) <TAB> logger.info(""finish reader: {}, Success!"".format(count))",if count % 1 == 0 :,175
"def on_adapter_selected(self, menuitem, adapter_path): <TAB> if menuitem.props.active: <MASK> logging.info(""selected %s"", adapter_path) <TAB>  <TAB>  <TAB> self.blueman.Config[""last-adapter""] = adapter_path_to_name(adapter_path) <TAB>  <TAB>  <TAB> self.blueman.List.set_adapter(adapter_path)",if adapter_path != self . blueman . List . Adapter . get_object_path ( ) :,111
"def set_note_pinned(self, key, pinned): <TAB> n = self.notes[key] <TAB> old_pinned = utils.note_pinned(n) <TAB> if pinned != old_pinned: <MASK> n[""systemtags""] = [] <TAB>  <TAB> systemtags = n[""systemtags""] <TAB>  <TAB> if pinned: <TAB>  <TAB>  <TAB> # which by definition means that it was NOT pinned <TAB>  <TAB>  <TAB> systemtags.append(""pinned"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> systemtags.remove(""pinned"") <TAB>  <TAB> n[""modifydate""] = time.time() <TAB>  <TAB> self.notify_observers( <TAB>  <TAB>  <TAB> ""change:note-status"", <TAB>  <TAB>  <TAB> events.NoteStatusChangedEvent(what=""modifydate"", key=key), <TAB>  <TAB> )","if ""systemtags"" not in n :",186
"def setMinCores(self, rpcObjects=None): <TAB> tasks = self._getSelected(rpcObjects) <TAB> if tasks: <TAB>  <TAB> current = max([task.data.min_cores for task in tasks]) <TAB>  <TAB> title = ""Set Minimum Cores"" <TAB>  <TAB> body = ""Please enter the new minimum cores value:"" <TAB>  <TAB> (value, choice) = QtWidgets.QInputDialog.getDouble( <TAB>  <TAB>  <TAB> self._caller, title, body, current, 0, 50000, 0 <TAB>  <TAB> ) <MASK> for task in tasks: <TAB>  <TAB>  <TAB>  <TAB> task.setMinCores(float(value)) <TAB>  <TAB>  <TAB> self._update()",if choice :,160
"def _1_0_cloud_ips_cip_jsjc5(self, method, url, body, headers): <TAB> if method == ""DELETE"": <TAB>  <TAB> return self.test_response(httplib.OK, """") <TAB> elif method == ""PUT"": <TAB>  <TAB> body = json.loads(body) <MASK> return self.test_response(httplib.OK, """") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.test_response( <TAB>  <TAB>  <TAB>  <TAB> httplib.BAD_REQUEST, '{""error_name"":""bad dns"", ""errors"": [""Bad dns""]}' <TAB>  <TAB>  <TAB> )","if body . get ( ""reverse_dns"" , None ) == ""fred.co.uk"" :",160
"def _print_one_entry(news_entry: xml.etree.ElementTree.Element) -> None: <TAB> child: xml.etree.ElementTree.Element <TAB> for child in news_entry: <TAB>  <TAB> if ""title"" in child.tag: <TAB>  <TAB>  <TAB> title = str(child.text) <MASK> pub_date = str(child.text) <TAB>  <TAB> if ""description"" in child.tag: <TAB>  <TAB>  <TAB> description = str(child.text) <TAB> print_stdout(color_line(title, 14) + "" ("" + bold_line(pub_date) + "")"") <TAB> print_stdout(format_paragraph(strip_tags(description))) <TAB> print_stdout()","if ""pubDate"" in child . tag :",169
"def oregon_battery(self, offset): <TAB> nib = self.decoded_nibbles <TAB> batt = ""OK"" <TAB> if nib[offset][3] != """": <MASK> batt = ""Low"" <TAB>  <TAB> self.put( <TAB>  <TAB>  <TAB> nib[offset][0], nib[offset][1], self.out_ann, [2, [""Batt "" + batt, batt]] <TAB>  <TAB> )","if ( int ( nib [ offset ] [ 3 ] , 16 ) >> 2 ) & 0x1 == 1 :",128
"def body_stream() -> typing.AsyncGenerator[bytes, None]: <TAB> while True: <TAB>  <TAB> message = await queue.get() <MASK> break <TAB>  <TAB> assert message[""type""] == ""http.response.body"" <TAB>  <TAB> yield message.get(""body"", b"""") <TAB> task.result()",if message is None :,77
"def _wait_for_reboot(): <TAB> try: <TAB>  <TAB> state = self._conn.reboot_domain(instance[""name""]) <MASK> LOG.debug(_(""instance %s: rebooted""), instance[""name""]) <TAB>  <TAB>  <TAB> timer.stop() <TAB> except Exception: <TAB>  <TAB> LOG.exception(_(""_wait_for_reboot failed"")) <TAB>  <TAB> timer.stop()",if state == power_state . RUNNING :,97
"def _get_sequence_vector( <TAB> sequence, <TAB> tokenizer, <TAB> format_dtype, <TAB> unit_to_id, <TAB> lowercase=True, <TAB> unknown_symbol=UNKNOWN_SYMBOL,): <TAB> unit_sequence = tokenizer(sequence.lower() if lowercase else sequence) <TAB> unit_indices_vector = np.empty(len(unit_sequence), dtype=format_dtype) <TAB> for i in range(len(unit_sequence)): <TAB>  <TAB> curr_unit = unit_sequence[i] <MASK> unit_indices_vector[i] = unit_to_id[curr_unit] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> unit_indices_vector[i] = unit_to_id[unknown_symbol] <TAB> return unit_indices_vector",if curr_unit in unit_to_id :,188
"def forward(self, x: Tensor, edge_index: Adj) -> Tensor: <TAB> """""""""""" <TAB> if self.add_self_loops: <TAB>  <TAB> if isinstance(edge_index, Tensor): <TAB>  <TAB>  <TAB> edge_index, _ = remove_self_loops(edge_index) <TAB>  <TAB>  <TAB> edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(self.node_dim)) <MASK> edge_index = set_diag(edge_index) <TAB> x_norm = F.normalize(x, p=2.0, dim=-1) <TAB> # propagate_type: (x: Tensor, x_norm: Tensor) <TAB> return self.propagate(edge_index, x=x, x_norm=x_norm, size=None)","elif isinstance ( edge_index , SparseTensor ) :",196
"def _init_req_settings(self, **kwargs): <TAB> for req_attr in self._req_settings: <TAB>  <TAB> req_attr_value = kwargs.get(req_attr) <MASK> raise MissingRequiredConf(conf_name=req_attr_value) <TAB>  <TAB> # Validate attribute value <TAB>  <TAB> req_attr_value = get_validator(req_attr)(req_attr_value) <TAB>  <TAB> self._settings[req_attr] = req_attr_value",if req_attr_value is None :,122
"def delete(identifier, filenames=None, **kwargs): <TAB> item = get_item(identifier) <TAB> if filenames: <TAB>  <TAB> if not isinstance(filenames, (set, list)): <TAB>  <TAB>  <TAB> filenames = [filenames] <TAB>  <TAB> for f in item.iter_files(): <MASK> continue <TAB>  <TAB>  <TAB> f.delete(**kwargs)",if f . name not in filenames :,91
"def visit_decorator(self, o: Decorator) -> None: <TAB> if self.is_private_name(o.func.name, o.func.fullname): <TAB>  <TAB> return <TAB> is_abstract = False <TAB> for decorator in o.original_decorators: <TAB>  <TAB> if isinstance(decorator, NameExpr): <TAB>  <TAB>  <TAB> if self.process_name_expr_decorator(decorator, o): <TAB>  <TAB>  <TAB>  <TAB> is_abstract = True <TAB>  <TAB> elif isinstance(decorator, MemberExpr): <MASK> is_abstract = True <TAB> self.visit_func_def(o.func, is_abstract=is_abstract)","if self . process_member_expr_decorator ( decorator , o ) :",160
"def split_trading_pair(trading_pair: str) -> Optional[Tuple[str, str]]: <TAB> try: <TAB>  <TAB> m = RE_4_LETTERS_QUOTE.match(trading_pair) <MASK> m = RE_3_LETTERS_QUOTE.match(trading_pair) <TAB>  <TAB>  <TAB> if m is None: <TAB>  <TAB>  <TAB>  <TAB> m = RE_2_LETTERS_QUOTE.match(trading_pair) <TAB>  <TAB> return m.group(1), m.group(2) <TAB> # Exceptions are now logged as warnings in trading pair fetcher <TAB> except Exception: <TAB>  <TAB> return None",if m is None :,156
"def traverse_states(root): <TAB> todo = [root] <TAB> model = self.model <TAB> while len(todo): <TAB>  <TAB> iter = todo.pop(0) <TAB>  <TAB> # print model.value_path(iter, treeindex), model.get_state(iter, treeindex) <TAB>  <TAB> yield model.get_state(iter, treeindex) <TAB>  <TAB> path = model.get_path(iter) <MASK> children = [] <TAB>  <TAB>  <TAB> child = model.iter_children(iter) <TAB>  <TAB>  <TAB> while child: <TAB>  <TAB>  <TAB>  <TAB> children.append(child) <TAB>  <TAB>  <TAB>  <TAB> child = model.iter_next(child) <TAB>  <TAB>  <TAB> todo = children + todo <TAB> yield None  # end marker",if treeview . row_expanded ( path ) :,178
"def as_list( <TAB> self, compact=True, storage_to_dict=True, datetime_to_str=False, custom_types=None): <TAB> if storage_to_dict: <TAB>  <TAB> items = [] <TAB>  <TAB> for row in self: <TAB>  <TAB>  <TAB> item = row.as_dict(datetime_to_str, custom_types) <TAB>  <TAB>  <TAB> for jdata in self._joins_: <MASK> item[jdata[0]] = row[jdata[0]].as_list() <TAB>  <TAB>  <TAB> items.append(item) <TAB> else: <TAB>  <TAB> items = [item for item in self] <TAB> return items",if not jdata [ 2 ] :,160
"def zip(target, source, env): <TAB> compression = env.get(""ZIPCOMPRESSION"", 0) <TAB> zf = zipfile.ZipFile(str(target[0]), ""w"", compression) <TAB> for s in source: <TAB>  <TAB> if s.isdir(): <TAB>  <TAB>  <TAB> for dirpath, dirnames, filenames in os.walk(str(s)): <TAB>  <TAB>  <TAB>  <TAB> for fname in filenames: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> path = os.path.join(dirpath, fname) <MASK> zf.write(path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> zf.write(str(s)) <TAB> zf.close()",if os . path . isfile ( path ) :,155
def remove_PBA_files(): <TAB> if monkey_island.cc.services.config.ConfigService.get_config(): <TAB>  <TAB> windows_filename = ( <TAB>  <TAB>  <TAB> monkey_island.cc.services.config.ConfigService.get_config_value( <TAB>  <TAB>  <TAB>  <TAB> PBA_WINDOWS_FILENAME_PATH <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB>  <TAB> linux_filename = ( <TAB>  <TAB>  <TAB> monkey_island.cc.services.config.ConfigService.get_config_value( <TAB>  <TAB>  <TAB>  <TAB> PBA_LINUX_FILENAME_PATH <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB>  <TAB> if linux_filename: <TAB>  <TAB>  <TAB> remove_file(linux_filename) <MASK> remove_file(windows_filename),if windows_filename :,183
"def test_takewhile(self): <TAB> for s in (range(10), range(0), range(1000), (7, 11), range(2000, 2200, 5)): <TAB>  <TAB> for g in (G, I, Ig, S, L, R): <TAB>  <TAB>  <TAB> tgt = [] <TAB>  <TAB>  <TAB> for elem in g(s): <MASK> break <TAB>  <TAB>  <TAB>  <TAB> tgt.append(elem) <TAB>  <TAB>  <TAB> self.assertEqual(list(takewhile(isEven, g(s))), tgt) <TAB>  <TAB> self.assertRaises(TypeError, takewhile, isEven, X(s)) <TAB>  <TAB> self.assertRaises(TypeError, takewhile, isEven, N(s)) <TAB>  <TAB> self.assertRaises(ZeroDivisionError, list, takewhile(isEven, E(s)))",if not isEven ( elem ) :,188
"def find_defined_variables(board_config_mks): <TAB> re_def = re.compile(""^[\s]*([\w\d_]*)[\s]*:="") <TAB> variables = dict() <TAB> for board_config_mk in board_config_mks: <TAB>  <TAB> for line in open(board_config_mk, encoding=""latin1""): <TAB>  <TAB>  <TAB> mo = re_def.search(line) <TAB>  <TAB>  <TAB> if mo is None: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> variable = mo.group(1) <TAB>  <TAB>  <TAB> if variable in white_list: <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> variables[variable] = set() <TAB>  <TAB>  <TAB> variables[variable].add(board_config_mk[len(TOP) + 1 :]) <TAB> return variables",if variable not in variables :,188
"def download_file(url, file): <TAB> try: <TAB>  <TAB> xlog.info(""download %s to %s"", url, file) <TAB>  <TAB> opener = get_opener() <TAB>  <TAB> req = opener.open(url, cafile="""") <TAB>  <TAB> CHUNK = 16 * 1024 <TAB>  <TAB> with open(file, ""wb"") as fp: <TAB>  <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB>  <TAB> chunk = req.read(CHUNK) <MASK> break <TAB>  <TAB>  <TAB>  <TAB> fp.write(chunk) <TAB>  <TAB> return True <TAB> except: <TAB>  <TAB> xlog.info(""download %s to %s fail"", url, file) <TAB>  <TAB> return False",if not chunk :,158
"def set_preferred_lane(self, preferred_lane: int = None) -> ""AbstractEnv"": <TAB> env_copy = copy.deepcopy(self) <TAB> if preferred_lane: <TAB>  <TAB> for v in env_copy.road.vehicles: <MASK> v.route = [(lane[0], lane[1], preferred_lane) for lane in v.route] <TAB>  <TAB>  <TAB>  <TAB> # Vehicle with lane preference are also less cautious <TAB>  <TAB>  <TAB>  <TAB> v.LANE_CHANGE_MAX_BRAKING_IMPOSED = 1000 <TAB> return env_copy","if isinstance ( v , IDMVehicle ) :",152
"def resolve(self, value: Optional[T]) -> T: <TAB> v: Optional[Any] = value <TAB> if value is None: <TAB>  <TAB> t = os.environ.get(self.envvar) <TAB>  <TAB> if self.type is bool and t: <TAB>  <TAB>  <TAB> v = t in [""true"", ""True"", ""1"", ""yes""] <MASK> v = t <TAB>  <TAB> elif t: <TAB>  <TAB>  <TAB> v = ast.literal_eval(t) if t is not None else None <TAB> if v is None: <TAB>  <TAB> v = self.default <TAB> return v",elif self . type is str and t :,144
"def test_read_lazy_A(self): <TAB> want = [""x"" * 100, EOF_sigil] <TAB> self.dataq.put(want) <TAB> telnet = telnetlib.Telnet(HOST, self.port) <TAB> self.dataq.join() <TAB> time.sleep(self.block_short) <TAB> self.assertEqual("""", telnet.read_lazy()) <TAB> data = """" <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> read_data = telnet.read_lazy() <TAB>  <TAB>  <TAB> data += read_data <MASK> telnet.fill_rawq() <TAB>  <TAB> except EOFError: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> self.assertTrue(want[0].startswith(data)) <TAB> self.assertEqual(data, want[0])",if not read_data :,192
"def request_put_json(url, headers): <TAB> """"""Makes a PUT request and returns the JSON response"""""" <TAB> try: <TAB>  <TAB> response = requests.put(url, headers=headers) <MASK> return response.json() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise RadarrRequestError( <TAB>  <TAB>  <TAB>  <TAB> ""Invalid response received from Radarr: %s"" % response.content <TAB>  <TAB>  <TAB> ) <TAB> except RequestException as e: <TAB>  <TAB> raise RadarrRequestError( <TAB>  <TAB>  <TAB> ""Unable to connect to Radarr at %s. Error: %s"" % (url, e) <TAB>  <TAB> )",if response . status_code == 200 :,150
"def firebase_analysis(urls): <TAB> # Detect Firebase URL <TAB> firebase_db = [] <TAB> logger.info(""Detecting Firebase URL(s)"") <TAB> for url in urls: <MASK> returl, is_open = open_firebase(url) <TAB>  <TAB>  <TAB> fbdic = {""url"": returl, ""open"": is_open} <TAB>  <TAB>  <TAB> if fbdic not in firebase_db: <TAB>  <TAB>  <TAB>  <TAB> firebase_db.append(fbdic) <TAB> return firebase_db","if ""firebaseio.com"" in url :",135
"def logprob(self, sample): <TAB> if self._log: <TAB>  <TAB> return self._prob_dict.get(sample, _NINF) <TAB> else: <MASK> return _NINF <TAB>  <TAB> elif self._prob_dict[sample] == 0: <TAB>  <TAB>  <TAB> return _NINF <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return math.log(self._prob_dict[sample], 2)",if sample not in self . _prob_dict :,102
"def is_image(self, input): <TAB> try: <MASK> return True <TAB>  <TAB> elif isinstance(input, str): <TAB>  <TAB>  <TAB> if not os.path.isfile(input): <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""input must be a file"") <TAB>  <TAB>  <TAB> img = Image.open(input) <TAB>  <TAB>  <TAB> _ = img.size <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> except: <TAB>  <TAB> return False","if isinstance ( input , ( np . ndarray , Image . Image ) ) :",122
"def extract(self): <TAB> for battery in self.vars: <TAB>  <TAB> for line in dopen(""/proc/acpi/battery/"" + battery + ""/state"").readlines(): <TAB>  <TAB>  <TAB> l = line.split() <TAB>  <TAB>  <TAB> if len(l) < 3: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if l[0:2] == [""remaining"", ""capacity:""]: <TAB>  <TAB>  <TAB>  <TAB> remaining = int(l[2]) <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> rate = int(l[2]) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if rate and remaining: <TAB>  <TAB>  <TAB> self.val[battery] = remaining * 60 / rate <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.val[battery] = -1","elif l [ 0 : 2 ] == [ ""present"" , ""rate:"" ] :",185
"def get_app_module(module_name, raise_on_failure=True): <TAB> try: <TAB>  <TAB> __import__(module_name) <TAB> except ImportError: <TAB>  <TAB> if sys.exc_info()[-1].tb_next: <TAB>  <TAB>  <TAB> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB> f""While importing '{module_name}', an ImportError was raised:"" <TAB>  <TAB>  <TAB>  <TAB> f""\n\n{traceback.format_exc()}"" <TAB>  <TAB>  <TAB> ) <MASK> raise RuntimeError(f""Could not import '{module_name}'."") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return <TAB> return sys.modules[module_name]",elif raise_on_failure :,152
"def process_shutdown_hooks(self): <TAB> for plugin_name in self.DISCOVERED.keys(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> package = ""mailpile.plugins.%s"" % plugin_name <TAB>  <TAB>  <TAB> _, manifest = self.DISCOVERED[plugin_name] <MASK> for method_name in self._mf_path(manifest, ""lifecycle"", ""shutdown""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> method = self._get_method(package, method_name) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> method(self.config) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> # ignore exceptions here as mailpile is going to shut down <TAB>  <TAB>  <TAB> traceback.print_exc(file=sys.stderr)",if package in sys . modules :,175
"def _check_arch(self, arch): <TAB> if arch is None: <TAB>  <TAB> return <TAB> try: <TAB>  <TAB> from pycuda.driver import Context <TAB>  <TAB> capability = Context.get_device().compute_capability() <MASK> from warnings import warn <TAB>  <TAB>  <TAB> warn( <TAB>  <TAB>  <TAB>  <TAB> ""trying to compile for a compute capability "" ""higher than selected GPU"" <TAB>  <TAB>  <TAB> ) <TAB> except Exception: <TAB>  <TAB> pass","if tuple ( map ( int , tuple ( arch . split ( ""_"" ) [ 1 ] ) ) ) > capability :",122
"def phpinfo_ext(content): <TAB> indexes = SubstrFind(content, ""AbracadabrA"") <TAB> found = len(indexes) > 0 <TAB> got = """" <TAB> if found: <TAB>  <TAB> start = indexes[0] + 11 <TAB>  <TAB> for x in range(start, len(content)): <MASK> break <TAB>  <TAB>  <TAB> got += content[x] <TAB> return got","if content [ x ] == ""<"" :",103
"def update_leaderboard(wait_time): <TAB> conn = get_connection() <TAB> cursor = conn.cursor(MySQLdb.cursors.DictCursor) <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if use_log: <TAB>  <TAB>  <TAB>  <TAB> log.info(""Updating leaderboard and adding some sigma"") <TAB>  <TAB>  <TAB> cursor.execute(""call generate_leaderboard;"") <MASK> break <TAB>  <TAB>  <TAB> for s in range(wait_time): <TAB>  <TAB>  <TAB>  <TAB> # allow for a [Ctrl]+C during the sleep cycle <TAB>  <TAB>  <TAB>  <TAB> time.sleep(1) <TAB>  <TAB> except KeyboardInterrupt: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> # log error <TAB>  <TAB>  <TAB> log.error(traceback.format_exc()) <TAB>  <TAB>  <TAB> break <TAB> cursor.close() <TAB> conn.close()",if wait_time == 0 :,199
"def writeBit(self, state, endian): <TAB> if self._bit_pos == 7: <TAB>  <TAB> self._bit_pos = 0 <MASK> if endian is BIG_ENDIAN: <TAB>  <TAB>  <TAB>  <TAB> self._byte |= 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._byte |= 128 <TAB>  <TAB> self._output.write(chr(self._byte)) <TAB>  <TAB> self._byte = 0 <TAB> else: <TAB>  <TAB> if state: <TAB>  <TAB>  <TAB> if endian is BIG_ENDIAN: <TAB>  <TAB>  <TAB>  <TAB> self._byte |= 1 << self._bit_pos <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._byte |= 1 << (7 - self._bit_pos) <TAB>  <TAB> self._bit_pos += 1",if state :,177
"def getreportopt(config): <TAB> reportopts = """" <TAB> reportchars = config.option.reportchars <TAB> if not config.option.disablepytestwarnings and ""w"" not in reportchars: <TAB>  <TAB> reportchars += ""w"" <TAB> elif config.option.disablepytestwarnings and ""w"" in reportchars: <TAB>  <TAB> reportchars = reportchars.replace(""w"", """") <TAB> if reportchars: <TAB>  <TAB> for char in reportchars: <MASK> reportopts += char <TAB>  <TAB>  <TAB> elif char == ""a"": <TAB>  <TAB>  <TAB>  <TAB> reportopts = ""fEsxXw"" <TAB> return reportopts","if char not in reportopts and char != ""a"" :",157
"def validate_module(self, pipeline): <TAB> if self.mode == MODE_UNTANGLE: <MASK> path = os.path.join( <TAB>  <TAB>  <TAB>  <TAB> self.training_set_directory.get_absolute_path(), <TAB>  <TAB>  <TAB>  <TAB> self.training_set_file_name.value, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> if not os.path.exists(path): <TAB>  <TAB>  <TAB>  <TAB> raise ValidationError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Can't find file %s"" % self.training_set_file_name.value, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.training_set_file_name, <TAB>  <TAB>  <TAB>  <TAB> )",if self . training_set_directory . dir_choice != URL_FOLDER_NAME :,170
"def reshape(w, h): <TAB> try: <TAB>  <TAB> # Prevent a division by zero when minimising the window <MASK> h = 1 <TAB>  <TAB> # Set the drawable region of the window <TAB>  <TAB> glViewport(0, 0, w, h) <TAB>  <TAB> # set up the projection matrix <TAB>  <TAB> glMatrixMode(GL_PROJECTION) <TAB>  <TAB> glLoadIdentity() <TAB>  <TAB> # go back to modelview matrix so we can move the objects about <TAB>  <TAB> glMatrixMode(GL_MODELVIEW) <TAB>  <TAB> updatePickingBuffer() <TAB> except Exception: <TAB>  <TAB> log.error(""gl.reshape"", exc_info=True)",if h == 0 :,157
"def __setitem__(self, key, value): <TAB> if not isinstance(value, PseudoNamespace): <TAB>  <TAB> tuple_converted = False <MASK> value = PseudoNamespace(value) <TAB>  <TAB> elif isinstance(value, tuple): <TAB>  <TAB>  <TAB> value = list(value) <TAB>  <TAB>  <TAB> tuple_converted = True <TAB>  <TAB> if isinstance(value, list): <TAB>  <TAB>  <TAB> for i, item in enumerate(value): <TAB>  <TAB>  <TAB>  <TAB> if isinstance(item, dict) and not isinstance(item, PseudoNamespace): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value[i] = PseudoNamespace(item) <TAB>  <TAB>  <TAB> if tuple_converted: <TAB>  <TAB>  <TAB>  <TAB> value = tuple(value) <TAB> super(PseudoNamespace, self).__setitem__(key, value)","if isinstance ( value , dict ) :",175
"def scan_search(state): <TAB> delim = state.source[state.position - 1] <TAB> while True: <TAB>  <TAB> c = state.consume() <TAB>  <TAB> if c == delim: <TAB>  <TAB>  <TAB> state.start += 1 <TAB>  <TAB>  <TAB> state.backup() <TAB>  <TAB>  <TAB> content = state.emit() <TAB>  <TAB>  <TAB> state.consume() <TAB>  <TAB>  <TAB> token = TokenSearchForward if c == ""/"" else TokenSearchBackward <TAB>  <TAB>  <TAB> return scan_range, [token(content)] <MASK> raise ValueError(""unclosed search pattern: {0}"".format(state.source))",elif c == EOF :,141
"def fromVariant(variant): <TAB> if hasattr(QtCore, ""QVariant"") and isinstance(variant, QtCore.QVariant): <TAB>  <TAB> t = variant.type() <TAB>  <TAB> if t == QtCore.QVariant.String: <TAB>  <TAB>  <TAB> return str(variant.toString()) <TAB>  <TAB> elif t == QtCore.QVariant.Double: <TAB>  <TAB>  <TAB> return variant.toDouble()[0] <TAB>  <TAB> elif t == QtCore.QVariant.Int: <TAB>  <TAB>  <TAB> return variant.toInt()[0] <TAB>  <TAB> elif t == QtCore.QVariant.Bool: <TAB>  <TAB>  <TAB> return variant.toBool() <MASK> return None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError('Unsupported QVariant type ""%s""' % variant.typeName()) <TAB> else: <TAB>  <TAB> return variant",elif t == QtCore . QVariant . Invalid :,195
"def __iter__(self): <TAB> i = 0 <TAB> for category, filename in list(self.input_files.items()): <TAB>  <TAB> for line in open(filename): <TAB>  <TAB>  <TAB> line = self._clean_line(line) <TAB>  <TAB>  <TAB> if self.accept_criteria(i): <TAB>  <TAB>  <TAB>  <TAB> yield Opinion(line, category) <TAB>  <TAB>  <TAB> i += 1 <MASK> print(""\tReaded {} examples"".format(i))",if i % 1000 == 0 :,115
"def test_listing_all_frameworks_and_check_frameworks_by_order(self): <TAB> """"""List all frameworks and check if frameworks appear by order"""""" <TAB> result = subprocess.check_output(self.command_as_list([UMAKE, ""--list""])) <TAB> previous_framework = None <TAB> for element in result.split(b""\n""): <MASK> current_framework = element[: element.find(b"":"")] <TAB>  <TAB>  <TAB> if previous_framework: <TAB>  <TAB>  <TAB>  <TAB> self.assertTrue(previous_framework < current_framework) <TAB>  <TAB>  <TAB> previous_framework = current_framework <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> previous_framework = None","if element . startswith ( b""\t"" ) :",160
"def _locate_code(self, event): <TAB> if self._current_code_view is None: <TAB>  <TAB> return <TAB> iid = self.tree.focus() <TAB> if iid != """": <TAB>  <TAB> values = self.tree.item(iid)[""values""] <MASK> start_line, start_col, end_line, end_col = values[1:5] <TAB>  <TAB>  <TAB> self._current_code_view.select_range( <TAB>  <TAB>  <TAB>  <TAB> TextRange(start_line, start_col, end_line, end_col) <TAB>  <TAB>  <TAB> )","if isinstance ( values , list ) and len ( values ) >= 5 :",150
"def __setattr__(self, attr, value): <TAB> """"""Provides additional checks on recipient fields."""""" <TAB> if attr in [""to"", ""cc"", ""bcc""]: <TAB>  <TAB> if isinstance(value, basestring): <MASK> return <TAB>  <TAB>  <TAB> check_email_valid(value, attr) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for address in value: <TAB>  <TAB>  <TAB>  <TAB> check_email_valid(address, attr) <TAB> elif attr == ""headers"": <TAB>  <TAB> check_headers_valid(value) <TAB> super(EmailMessage, self).__setattr__(attr, value)","if value == """" and getattr ( self , ""ALLOW_BLANK_EMAIL"" , False ) :",151
"def _scanDirectory(self, dirIter, f): <TAB> while len(f) < 250: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> info = next(dirIter) <TAB>  <TAB> except StopIteration: <TAB>  <TAB>  <TAB> if not f: <TAB>  <TAB>  <TAB>  <TAB> raise EOFError <TAB>  <TAB>  <TAB> return f <MASK> info.addCallback(self._cbScanDirectory, dirIter, f) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> f.append(info) <TAB> return f","if isinstance ( info , defer . Deferred ) :",122
def iterator(): <TAB> try: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> yield from pullparser.read_events() <TAB>  <TAB>  <TAB> # load event buffer <TAB>  <TAB>  <TAB> data = source.read(16 * 1024) <TAB>  <TAB>  <TAB> if not data: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> pullparser.feed(data) <TAB>  <TAB> root = pullparser._close_and_return_root() <TAB>  <TAB> yield from pullparser.read_events() <TAB>  <TAB> it.root = root <TAB> finally: <MASK> source.close(),if close_source :,130
"def test_until_timeout(self): <TAB> timer = TestTimer(self.timeout) <TAB> while not timer.is_timed_out(): <MASK> self.log_success(timer) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> sleep(DELAY_BETWEEN_ANALYSIS) <TAB>  <TAB> LOGGER.debug( <TAB>  <TAB>  <TAB> ""Waiting until all analyzers passed. Time passed: {}"".format( <TAB>  <TAB>  <TAB>  <TAB> timer.get_time_taken() <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB> self.log_failure(timer) <TAB> assert False",if self . all_analyzers_pass ( ) :,139
"def start(self): <TAB> """"""Start our callback in its own perpetual timer thread."""""" <TAB> if self.frequency > 0: <TAB>  <TAB> threadname = self.name or self.__class__.__name__ <MASK> self.thread = PerpetualTimer(self.frequency, self.callback) <TAB>  <TAB>  <TAB> self.thread.bus = self.bus <TAB>  <TAB>  <TAB> self.thread.setName(threadname) <TAB>  <TAB>  <TAB> self.thread.start() <TAB>  <TAB>  <TAB> self.bus.log(""Started monitor thread %r."" % threadname) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.bus.log(""Monitor thread %r already started."" % threadname)",if self . thread is None :,160
"def set_flavour(flavour, request=None, permanent=False): <TAB> if flavour not in settings.FLAVOURS: <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> u""'%r' is no valid flavour. Allowed flavours are: %s"" <TAB>  <TAB>  <TAB> % ( <TAB>  <TAB>  <TAB>  <TAB> flavour, <TAB>  <TAB>  <TAB>  <TAB> "", "".join(settings.FLAVOURS), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB> request = request or getattr(_local, ""request"", None) <TAB> if request: <TAB>  <TAB> request.flavour = flavour <MASK> flavour_storage.set(request, flavour) <TAB> elif permanent: <TAB>  <TAB> raise ValueError(u""Cannot set flavour permanently, no request available."") <TAB> _local.flavour = flavour",if permanent :,176
"def get_images(image_path, support_ext="".jpg|.jpeg|.png""): <TAB> if not os.path.exists(image_path): <TAB>  <TAB> raise Exception(f""Image path {image_path} invalid"") <TAB> if os.path.isfile(image_path): <TAB>  <TAB> return [image_path] <TAB> imgs = [] <TAB> for item in os.listdir(image_path): <TAB>  <TAB> ext = os.path.splitext(item)[1][1:].strip().lower() <MASK> item_path = os.path.join(image_path, item) <TAB>  <TAB>  <TAB> imgs.append(item_path) <TAB> return imgs",if len ( ext ) > 0 and ext in support_ext :,167
"def write_text(self, text): <TAB> """"""Writes re-indented text into the buffer."""""" <TAB> should_indent = False <TAB> rows = [] <TAB> for row in text.split(""\n""): <MASK> row = "" <TAB> {}"".format(row) <TAB>  <TAB> if ""\b"" in row: <TAB>  <TAB>  <TAB> row = row.replace(""\b"", """", 1) <TAB>  <TAB>  <TAB> should_indent = True <TAB>  <TAB> elif not len(row.strip()): <TAB>  <TAB>  <TAB> should_indent = False <TAB>  <TAB> rows.append(row) <TAB> self.write(""{}\n"".format(""\n"".join(rows)))",if should_indent :,147
"def build_priorities(self, _iter, priorities): <TAB> while _iter is not None: <TAB>  <TAB> if self.files_treestore.iter_has_child(_iter): <TAB>  <TAB>  <TAB> self.build_priorities(self.files_treestore.iter_children(_iter), priorities) <MASK> priorities[ <TAB>  <TAB>  <TAB>  <TAB> self.files_treestore.get_value(_iter, 3) <TAB>  <TAB>  <TAB> ] = self.files_treestore.get_value(_iter, 0) <TAB>  <TAB> _iter = self.files_treestore.iter_next(_iter) <TAB> return priorities","elif not self . files_treestore . get_value ( _iter , 1 ) . endswith ( os . path . sep ) :",170
"def _validate_sample(self, value): <TAB> mask = self.support(value) <TAB> if not_jax_tracer(mask): <MASK> warnings.warn( <TAB>  <TAB>  <TAB>  <TAB> ""Out-of-support values provided to log prob method. "" <TAB>  <TAB>  <TAB>  <TAB> ""The value argument should be within the support."" <TAB>  <TAB>  <TAB> ) <TAB> return mask",if not np . all ( mask ) :,94
"def https_open(self, req): <TAB> try: <TAB>  <TAB> return self.do_open(do_connection, req) <TAB> except Exception as err_msg: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> error_msg = str(err_msg.args[0]).split(""] "")[1] + ""."" <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB> error_msg = str(err_msg.args[0]) + ""."" <TAB>  <TAB> if settings.INIT_TEST == True: <MASK> print(settings.FAIL_STATUS) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if settings.VERBOSITY_LEVEL < 1: <TAB>  <TAB>  <TAB>  <TAB> print("""") <TAB>  <TAB> print(settings.print_critical_msg(error_msg)) <TAB>  <TAB> raise SystemExit()",if settings . VERBOSITY_LEVEL < 2 :,187
"def add_party(self, party_type, party): <TAB> party_doc = frappe.new_doc(party_type) <TAB> if party_type == ""Customer"": <TAB>  <TAB> party_doc.customer_name = party <TAB> else: <TAB>  <TAB> supplier_group = frappe.db.get_single_value(""Buying Settings"", ""supplier_group"") <MASK> frappe.throw(_(""Please Set Supplier Group in Buying Settings."")) <TAB>  <TAB> party_doc.supplier_name = party <TAB>  <TAB> party_doc.supplier_group = supplier_group <TAB> party_doc.flags.ignore_mandatory = True <TAB> party_doc.save(ignore_permissions=True)",if not supplier_group :,175
"def get_polymorphic_model(data): <TAB> for model in itervalues(models): <TAB>  <TAB> polymorphic = model.opts.polymorphic <MASK> polymorphic_key = polymorphic <TAB>  <TAB>  <TAB> if isinstance(polymorphic_key, bool): <TAB>  <TAB>  <TAB>  <TAB> polymorphic_key = ""type"" <TAB>  <TAB>  <TAB> if data.get(polymorphic_key) == model.__name__: <TAB>  <TAB>  <TAB>  <TAB> return model <TAB> raise ImproperlyConfigured(u""No model found for data: {!r}"".format(data))",if polymorphic :,133
"def cleanup_expired_revoked_tokens(): <TAB> """"""Remove tokens that have now expired from the revoked token table."""""" <TAB> revoked_tokens = db.session.query(RevokedToken).all() <TAB> for revoked_token in revoked_tokens: <MASK> pass  # The token has not expired, we must keep in the revoked token table. <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # The token is no longer valid, remove from the revoked token table. <TAB>  <TAB>  <TAB> db.session.delete(revoked_token) <TAB> db.session.commit()",if Journalist . validate_token_is_not_expired_or_invalid ( revoked_token . token ) :,161
"def matches_filter(key, values): <TAB> if key == ""location"": <TAB>  <TAB> if location_type in (""availability-zone"", ""availability-zone-id""): <TAB>  <TAB>  <TAB> return offering.get(""Location"") in values <MASK> return any(v for v in values if offering.get(""Location"").startswith(v)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> elif key == ""instance-type"": <TAB>  <TAB> return offering.get(""InstanceType"") in values <TAB> else: <TAB>  <TAB> return False","elif location_type == ""region"" :",130
"def autoname(self): <TAB> naming_method = frappe.db.get_value(""HR Settings"", None, ""emp_created_by"") <TAB> if not naming_method: <TAB>  <TAB> throw(_(""Please setup Employee Naming System in Human Resource > HR Settings"")) <TAB> else: <TAB>  <TAB> if naming_method == ""Naming Series"": <TAB>  <TAB>  <TAB> set_name_by_naming_series(self) <TAB>  <TAB> elif naming_method == ""Employee Number"": <TAB>  <TAB>  <TAB> self.name = self.employee_number <MASK> self.set_employee_name() <TAB>  <TAB>  <TAB> self.name = self.employee_name <TAB> self.employee = self.name","elif naming_method == ""Full Name"" :",169
"def readHexStringFromStream(stream): <TAB> stream.read(1) <TAB> txt = """" <TAB> x = b_("""") <TAB> while True: <TAB>  <TAB> tok = readNonWhitespace(stream) <TAB>  <TAB> if not tok: <TAB>  <TAB>  <TAB> # stream has truncated prematurely <TAB>  <TAB>  <TAB> raise PdfStreamError(""Stream has ended unexpectedly"") <TAB>  <TAB> if tok == b_("">""): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> x += tok <MASK> txt += chr(int(x, base=16)) <TAB>  <TAB>  <TAB> x = b_("""") <TAB> if len(x) == 1: <TAB>  <TAB> x += b_(""0"") <TAB> if len(x) == 2: <TAB>  <TAB> txt += chr(int(x, base=16)) <TAB> return createStringObject(b_(txt))",if len ( x ) == 2 :,190
"def test_technical_on(self): <TAB> # Turn everything on <TAB> data = { <TAB>  <TAB> ""developer_comments"": ""Test comment!"", <TAB>  <TAB> ""whiteboard-public"": ""Whiteboard info."", <TAB> } <TAB> response = self.client.post(self.technical_edit_url, data) <TAB> assert response.context[""form""].errors == {} <TAB> addon = self.get_addon() <TAB> for k in data: <TAB>  <TAB> if k == ""developer_comments"": <TAB>  <TAB>  <TAB> assert str(getattr(addon, k)) == str(data[k]) <MASK> assert str(addon.whiteboard.public) == str(data[k]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert getattr(addon, k) == (data[k] == ""on"")","elif k == ""whiteboard-public"" :",193
"def create_season_posters(self, show_obj, force=False): <TAB> if self.season_posters and show_obj: <TAB>  <TAB> result = [] <TAB>  <TAB> for ep_obj in show_obj.episodes: <MASK> sickrage.app.log.debug( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Metadata provider "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> + self.name <TAB>  <TAB>  <TAB>  <TAB>  <TAB> + "" creating season posters for "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> + show_obj.name <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> result = result + [self.save_season_poster(show_obj, ep_obj.season)] <TAB>  <TAB> return all(result) <TAB> return False","if not self . _has_season_poster ( show_obj , ep_obj . season ) or force :",196
"def get_prefixes(self, guild: Optional[discord.Guild] = None) -> List[str]: <TAB> ret: List[str] <TAB> gid: Optional[int] = guild.id if guild else None <TAB> if gid in self._cached: <TAB>  <TAB> ret = self._cached[gid].copy() <TAB> else: <TAB>  <TAB> if gid is not None: <TAB>  <TAB>  <TAB> ret = await self._config.guild_from_id(gid).prefix() <MASK> ret = await self.get_prefixes(None) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret = self._global_prefix_overide or (await self._config.prefix()) <TAB>  <TAB> self._cached[gid] = ret.copy() <TAB> return ret",if not ret :,180
"def checkUnchangedIvars(obj, d, exceptions=None): <TAB> if not exceptions: <TAB>  <TAB> exceptions = [] <TAB> ok = True <TAB> for key in d: <TAB>  <TAB> if key not in exceptions: <MASK> g.trace( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""changed ivar: %s old: %s new: %s"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> % (key, repr(d.get(key)), repr(getattr(obj, key))) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> ok = False <TAB> return ok","if getattr ( obj , key ) != d . get ( key ) :",142
"def validate_ip(address): <TAB> try: <TAB>  <TAB> if socket.inet_aton(address): <MASK> debug_msg(""setcore"", ""this is a valid IP address"", 5) <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> print_error(""This is not a valid IP address..."") <TAB>  <TAB>  <TAB>  <TAB> raise socket.error <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise socket_error <TAB> except socket.error: <TAB>  <TAB> return False","if len ( address . split ( ""."" ) ) == 4 :",125
"def kernel(x, y): <TAB> diff = safe_norm(x - y, ord=2) if self._normed() and x.ndim >= 1 else x - y <TAB> kernel_res = jnp.exp(-(diff ** 2) / bandwidth) <TAB> if self._mode == ""matrix"": <MASK> return kernel_res * jnp.identity(x.shape[0]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return jnp.diag(kernel_res) <TAB> else: <TAB>  <TAB> return kernel_res","if self . matrix_mode == ""norm_diag"" :",133
"def __init__(self, transforms): <TAB> assert isinstance(transforms, collections.abc.Sequence) <TAB> self.transforms = [] <TAB> for transform in transforms: <TAB>  <TAB> if isinstance(transform, dict): <TAB>  <TAB>  <TAB> transform = build_from_cfg(transform, PIPELINES) <TAB>  <TAB>  <TAB> self.transforms.append(transform) <MASK> self.transforms.append(transform) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError(""transform must be callable or a dict"")",elif callable ( transform ) :,115
"def translate( <TAB> self, <TAB> message: str, <TAB> plural_message: Optional[str] = None, <TAB> count: Optional[int] = None,) -> str: <TAB> if plural_message is not None: <TAB>  <TAB> assert count is not None <MASK> message = plural_message <TAB>  <TAB>  <TAB> message_dict = self.translations.get(""plural"", {}) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> message_dict = self.translations.get(""singular"", {}) <TAB> else: <TAB>  <TAB> message_dict = self.translations.get(""unknown"", {}) <TAB> return message_dict.get(message, message)",if count != 1 :,149
"def install_requires(cls, reduced_dependencies): <TAB> install_requires = OrderedSet() <TAB> for dep in reduced_dependencies: <MASK> for req in dep.payload.requirements: <TAB>  <TAB>  <TAB>  <TAB> install_requires.add(str(req.requirement)) <TAB>  <TAB> elif cls.has_provides(dep): <TAB>  <TAB>  <TAB> install_requires.add(dep.provides.key) <TAB> return install_requires",if cls . is_requirements ( dep ) :,110
"def doit(): <TAB> recipes_path = expanduser(""recipes.pprint"") <TAB> recipe_dicts = eval(open(recipes_path).read()) <TAB> for r in recipe_dicts: <TAB>  <TAB> for key in r.keys(): <TAB>  <TAB>  <TAB> if key not in (""desc"", ""comments""): <TAB>  <TAB>  <TAB>  <TAB> del r[key] <TAB>  <TAB> for c in r[""comments""]: <TAB>  <TAB>  <TAB> for key in c.keys(): <MASK> del c[key] <TAB> f = open(""stripped.pprint"", ""w"") <TAB> f.write(pformat(recipe_dicts)) <TAB> f.close()","if key not in ( ""comment"" , ""title"" ) :",163
"def setup(self, name): <TAB> value = self.default <TAB> if self.environ: <TAB>  <TAB> full_environ_name = self.full_environ_name(name) <MASK> value = self.to_python(os.environ[full_environ_name]) <TAB>  <TAB> elif self.environ_required: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Value {0!r} is required to be set as the "" <TAB>  <TAB>  <TAB>  <TAB> ""environment variable {1!r}"".format(name, full_environ_name) <TAB>  <TAB>  <TAB> ) <TAB> self.value = value <TAB> return value",if full_environ_name in os . environ :,153
"def get_art_abs(story_file): <TAB> lines = read_text_file(story_file) <TAB> lines = [line.lower() for line in lines] <TAB> lines = [fix_missing_period(line) for line in lines] <TAB> article_lines = [] <TAB> highlights = [] <TAB> next_is_highlight = False <TAB> for idx, line in enumerate(lines): <TAB>  <TAB> if line == """": <TAB>  <TAB>  <TAB> continue  # empty line <MASK> next_is_highlight = True <TAB>  <TAB> elif next_is_highlight: <TAB>  <TAB>  <TAB> highlights.append(line) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> article_lines.append(line) <TAB> article = "" "".join(article_lines) <TAB> abstract = "" "".join(highlights) <TAB> return article, abstract","elif line . startswith ( ""@highlight"" ) :",194
"def _ordered_tag_specs( <TAB> entity_tag_specs: Optional[List[EntityTagSpec]],) -> List[EntityTagSpec]: <TAB> """"""Ensure that order of entity tag specs matches CRF layer order."""""" <TAB> if entity_tag_specs is None: <TAB>  <TAB> return [] <TAB> crf_order = [ <TAB>  <TAB> ENTITY_ATTRIBUTE_TYPE, <TAB>  <TAB> ENTITY_ATTRIBUTE_ROLE, <TAB>  <TAB> ENTITY_ATTRIBUTE_GROUP, <TAB> ] <TAB> ordered_tag_spec = [] <TAB> for tag_name in crf_order: <TAB>  <TAB> for tag_spec in entity_tag_specs: <MASK> ordered_tag_spec.append(tag_spec) <TAB> return ordered_tag_spec",if tag_name == tag_spec . tag_name :,177
"def checkDrag(self, root, target): <TAB> """"""Return False if target is any descendant of root."""""" <TAB> c = self <TAB> message = ""Can not drag a node into its descendant tree."" <TAB> for z in root.subtree(): <MASK> if g.app.unitTesting: <TAB>  <TAB>  <TAB>  <TAB> g.app.unitTestDict[""checkMoveWithParentWithWarning""] = True <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> c.alert(message) <TAB>  <TAB>  <TAB> return False <TAB> return True",if z == target :,122
"def get_adapter(self, pattern=None): <TAB> adapters = self.get_adapters() <TAB> if pattern is None: <MASK> return adapters[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise DBusNoSuchAdapterError(""No adapter(s) found"") <TAB> else: <TAB>  <TAB> for adapter in adapters: <TAB>  <TAB>  <TAB> path = adapter.get_object_path() <TAB>  <TAB>  <TAB> if path.endswith(pattern) or adapter[""Address""] == pattern: <TAB>  <TAB>  <TAB>  <TAB> return adapter <TAB>  <TAB> raise DBusNoSuchAdapterError(""No adapters found with pattern: %s"" % pattern)",if len ( adapters ) :,144
"def __init__(self, children, quiet_exceptions=()): <TAB> self.keys = None <TAB> if isinstance(children, dict): <TAB>  <TAB> self.keys = list(children.keys()) <TAB>  <TAB> children = children.values() <TAB> self.children = [] <TAB> for i in children: <TAB>  <TAB> if not isinstance(i, YieldPoint): <TAB>  <TAB>  <TAB> i = convert_yielded(i) <MASK> i = YieldFuture(i) <TAB>  <TAB> self.children.append(i) <TAB> assert all(isinstance(i, YieldPoint) for i in self.children) <TAB> self.unfinished_children = set(self.children) <TAB> self.quiet_exceptions = quiet_exceptions",if is_future ( i ) :,166
"def _make_callback(self): <TAB> callback = self.callback <TAB> for plugin in self.all_plugins(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if hasattr(plugin, ""apply""): <TAB>  <TAB>  <TAB>  <TAB> callback = plugin.apply(callback, self) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> callback = plugin(callback) <TAB>  <TAB> except RouteReset:  # Try again with changed configuration. <TAB>  <TAB>  <TAB> return self._make_callback() <MASK> update_wrapper(callback, self.callback) <TAB> return callback",if not callback is self . callback :,131
"def _check_conflict(func, other_funcs): <TAB> if steps[func]: <TAB>  <TAB> for other_func in other_funcs: <MASK> raise ValueError(""Can't specify both %s and %s"" % (func, other_func))",if steps [ other_func ] and other_func != func :,76
"def shutdown(self, cleanup=True): <TAB> super(LocalDistributedRunner, self).shutdown() <TAB> global _dummy_cpu_actor <TAB> global _dummy_cuda_actor <TAB> if cleanup: <TAB>  <TAB> if _dummy_cpu_actor or _dummy_cuda_actor: <TAB>  <TAB>  <TAB> assert not self.is_actor(), ""Actor shouldn't have a "" ""dummy actor."" <MASK> ray.kill(_dummy_cpu_actor) <TAB>  <TAB> if _dummy_cuda_actor: <TAB>  <TAB>  <TAB> ray.kill(_dummy_cuda_actor) <TAB>  <TAB> _dummy_cpu_actor = None <TAB>  <TAB> _dummy_cuda_actor = None",if _dummy_cpu_actor :,158
"def _publish(self, data): <TAB> retry = True <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if not retry: <TAB>  <TAB>  <TAB>  <TAB> self._redis_connect() <TAB>  <TAB>  <TAB> return self.redis.publish(self.channel, pickle.dumps(data)) <TAB>  <TAB> except redis.exceptions.ConnectionError: <MASK> logger.error(""Cannot publish to redis... retrying"") <TAB>  <TAB>  <TAB>  <TAB> retry = False <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> logger.error(""Cannot publish to redis... giving up"") <TAB>  <TAB>  <TAB>  <TAB> break",if retry :,134
"def simulate_policy(args): <TAB> data = torch.load(args.file) <TAB> policy = data[""evaluation/policy""] <TAB> env = data[""evaluation/env""] <TAB> print(""Policy loaded"") <TAB> if args.gpu: <TAB>  <TAB> set_gpu_mode(True) <TAB>  <TAB> policy.cuda() <TAB> while True: <TAB>  <TAB> path = rollout( <TAB>  <TAB>  <TAB> env, <TAB>  <TAB>  <TAB> policy, <TAB>  <TAB>  <TAB> max_path_length=args.H, <TAB>  <TAB>  <TAB> render=True, <TAB>  <TAB> ) <MASK> env.log_diagnostics([path]) <TAB>  <TAB> logger.dump_tabular()","if hasattr ( env , ""log_diagnostics"" ) :",160
"def get_bucket_latest_versions(self, bucket_name): <TAB> versions = self.get_bucket_versions(bucket_name) <TAB> latest_modified_per_key = {} <TAB> latest_versions = {} <TAB> for version in versions: <TAB>  <TAB> name = version.name <TAB>  <TAB> last_modified = version.last_modified <TAB>  <TAB> version_id = version.version_id <TAB>  <TAB> latest_modified_per_key[name] = max( <TAB>  <TAB>  <TAB> last_modified, latest_modified_per_key.get(name, datetime.datetime.min) <TAB>  <TAB> ) <MASK> latest_versions[name] = version_id <TAB> return latest_versions",if last_modified == latest_modified_per_key [ name ] :,173
"def _get_ntp_entity(self, peer_type): <TAB> ntp_entities = {} <TAB> command = ""show ntp peers"" <TAB> ntp_peers_table = self._get_command_table(command, ""TABLE_peers"", ""ROW_peers"") <TAB> for ntp_peer in ntp_peers_table: <MASK> continue <TAB>  <TAB> peer_addr = napalm.base.helpers.ip(ntp_peer.get(""PeerIPAddress"").strip()) <TAB>  <TAB> ntp_entities[peer_addr] = {} <TAB> return ntp_entities","if ntp_peer . get ( ""serv_peer"" , """" ) . strip ( ) != peer_type :",164
"def kaiming_init( <TAB> module, a=0, mode=""fan_out"", nonlinearity=""relu"", bias=0, distribution=""normal""): <TAB> assert distribution in [""uniform"", ""normal""] <TAB> if hasattr(module, ""weight"") and module.weight is not None: <MASK> nn.init.kaiming_uniform_( <TAB>  <TAB>  <TAB>  <TAB> module.weight, a=a, mode=mode, nonlinearity=nonlinearity <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> nn.init.kaiming_normal_( <TAB>  <TAB>  <TAB>  <TAB> module.weight, a=a, mode=mode, nonlinearity=nonlinearity <TAB>  <TAB>  <TAB> ) <TAB> if hasattr(module, ""bias"") and module.bias is not None: <TAB>  <TAB> nn.init.constant_(module.bias, bias)","if distribution == ""uniform"" :",192
"def _get_arguments( <TAB> self, name: str, source: Dict[str, List[bytes]], strip: bool = True) -> List[str]: <TAB> values = [] <TAB> for v in source.get(name, []): <TAB>  <TAB> s = self.decode_argument(v, name=name) <MASK> # Get rid of any weird control chars (unless decoding gave <TAB>  <TAB>  <TAB> # us bytes, in which case leave it alone) <TAB>  <TAB>  <TAB> s = RequestHandler._remove_control_chars_regex.sub("" "", s) <TAB>  <TAB> if strip: <TAB>  <TAB>  <TAB> s = s.strip() <TAB>  <TAB> values.append(s) <TAB> return values","if isinstance ( s , unicode_type ) :",164
"def __str__(self): <TAB> s = ""{"" <TAB> sep = """" <TAB> for k, v in self.iteritems(): <TAB>  <TAB> s += sep <TAB>  <TAB> if type(k) == str: <TAB>  <TAB>  <TAB> s += ""'%s'"" % k <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> s += str(k) <TAB>  <TAB> s += "": "" <MASK> s += ""'%s'"" % v <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> s += str(v) <TAB>  <TAB> sep = "", "" <TAB> s += ""}"" <TAB> return s",if type ( v ) == str :,131
"def contains(self, other_route): <TAB> if isinstance(other_route, list): <TAB>  <TAB> return self.to_list()[0 : len(other_route)] == other_route <TAB> # This only works before merging <TAB> assert len(other_route.outgoing) <= 1, ""contains(..) cannot be called after a merge"" <TAB> assert len(self.outgoing) <= 1, ""contains(..) cannot be called after a merge"" <TAB> if other_route.task_spec == self.task_spec: <TAB>  <TAB> if other_route.outgoing and self.outgoing: <TAB>  <TAB>  <TAB> return self.outgoing[0].contains(other_route.outgoing[0]) <MASK> return True <TAB>  <TAB> elif not other_route.outgoing: <TAB>  <TAB>  <TAB> return True <TAB> return False",elif self . outgoing :,184
"def iter_help(cls): <TAB> for variable_name, value in sorted(cls.__dict__.items()): <MASK> continue <TAB>  <TAB> variable_type, variable_text = cls.process_pydoc(getattr(value, ""__doc__"")) <TAB>  <TAB> yield variable_name, variable_type, variable_text","if not variable_name . startswith ( ""PEX_"" ) :",83
"def _clean_dict(json_dict): <TAB> for key, value in json_dict.items(): <TAB>  <TAB> if isinstance(value, list): <TAB>  <TAB>  <TAB> json_dict[key] = list(OrderedSet(map(_clean_string, value))) <MASK> json_dict[key] = _clean_dict(value) <TAB> return OrderedDict(filter(lambda x: x[1], json_dict.items()))","elif isinstance ( value , dict ) :",105
"def _createdir(self): <TAB> if not os.path.exists(self._dir): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> os.makedirs(self._dir, 0o700) <TAB>  <TAB> except OSError as e: <MASK> raise EnvironmentError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Cache directory '%s' does not exist "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""and could not be created'"" % self._dir <TAB>  <TAB>  <TAB>  <TAB> )",if e . errno != errno . EEXIST :,111
"def JobWait(self, waiter): <TAB> # type: (Waiter) -> wait_status_t <TAB> # wait builtin can be interrupted <TAB> while True: <TAB>  <TAB> # Don't retry <TAB>  <TAB> result = waiter.WaitForOne(False) <MASK> # signal <TAB>  <TAB>  <TAB> return wait_status.Cancelled(result) <TAB>  <TAB> if result == -1:  # nothing to wait for <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if self.state != job_state_e.Running: <TAB>  <TAB>  <TAB> break <TAB> return wait_status.Proc(self.status)",if result > 0 :,135
"def _deserialize_pickle5_data(self, data): <TAB> try: <TAB>  <TAB> in_band, buffers = unpack_pickle5_buffers(data) <MASK> obj = pickle.loads(in_band, buffers=buffers) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> obj = pickle.loads(in_band) <TAB> # cloudpickle does not provide error types <TAB> except pickle.pickle.PicklingError: <TAB>  <TAB> raise DeserializationError() <TAB> return obj",if len ( buffers ) > 0 :,115
"def svgGetPaths(svgCode): <TAB> doc = xmlparseString(svgCode) <TAB> svg = doc.documentElement <TAB> paths = findPathNodes(svg) <TAB> isFigmaSVG = svgCode.find(""Figma</desc>"") != -1 <TAB> if len(paths) == 0: <TAB>  <TAB> return paths, (0, 0) <TAB> paths2 = [] <TAB> for path in paths: <TAB>  <TAB> id = path.getAttribute(""id"") <MASK> tr = nodeTranslation(path) <TAB>  <TAB>  <TAB> d = path.getAttribute(""d"") <TAB>  <TAB>  <TAB> paths2.append((d, tr)) <TAB> return paths2, isFigmaSVG","if not isFigmaSVG or ( id is None or id . find ( ""stroke"" ) == - 1 ) :",179
"def get_track_id_from_json(item): <TAB> """"""Try to extract video Id from various response types"""""" <TAB> fields = [ <TAB>  <TAB> ""contentDetails/videoId"", <TAB>  <TAB> ""snippet/resourceId/videoId"", <TAB>  <TAB> ""id/videoId"", <TAB>  <TAB> ""id"", <TAB> ] <TAB> for field in fields: <TAB>  <TAB> node = item <TAB>  <TAB> for p in field.split(""/""): <MASK> node = node.get(p) <TAB>  <TAB> if node: <TAB>  <TAB>  <TAB> return node <TAB> return """"","if node and isinstance ( node , dict ) :",137
"def save(self): <TAB> self._idx_lock.acquire() <TAB> try: <TAB>  <TAB> if self._is_idx_dirty: <MASK> self._mk_dbdir() <TAB>  <TAB>  <TAB> self.db.save_pickle( <TAB>  <TAB>  <TAB>  <TAB> join(self.base_dir, ""dirs_from_basename""), self._dirs_from_basename <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self._is_idx_dirty = False <TAB> finally: <TAB>  <TAB> self._idx_lock.release()",if not exists ( self . base_dir ) :,130
"def _init_from_response(self, response): <TAB> self.id = response[""id""] <TAB> self.uri = response.get(""mongodb_auth_uri"", response[""mongodb_uri""]) <TAB> for member in response[""members""]: <TAB>  <TAB> if member[""state""] == 1: <TAB>  <TAB>  <TAB> self.primary = Server(member[""server_id""], member[""host""]) <MASK> self.secondary = Server(member[""server_id""], member[""host""]) <TAB> return self","elif member [ ""state"" ] == 2 :",120
"def verify_secret_key(request): <TAB> ""Verifies secret key for a request"" <TAB> if request.user.username: <TAB>  <TAB> # always allow authenticated users <TAB>  <TAB> return True <TAB> else: <TAB>  <TAB> key = request.GET[""secret""] <TAB>  <TAB> user_id, secret = key.split(""."", 1) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> profile = User.objects.get(pk=user_id) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> return False <MASK> request.user = profile.user <TAB>  <TAB>  <TAB> return True <TAB> return False","if key == get_secret_key ( request , profile ) :",144
"def compute(self, split): <TAB> rd = random.Random(self.seed + split.index) <TAB> if self.withReplacement: <TAB>  <TAB> olddata = list(self.prev.iterator(split)) <TAB>  <TAB> sampleSize = int(math.ceil(len(olddata) * self.frac)) <TAB>  <TAB> for i in range(sampleSize): <TAB>  <TAB>  <TAB> yield rd.choice(olddata) <TAB> else: <TAB>  <TAB> for i in self.prev.iterator(split): <MASK> yield i",if rd . random ( ) <= self . frac :,133
"def splitIntoWords(name): <TAB> wordlist = [] <TAB> wordstart = 0 <TAB> l = len(name) <TAB> for i in range(l): <TAB>  <TAB> c = name[i] <TAB>  <TAB> n = None <TAB>  <TAB> if c == "" "" or c == ""-"": <TAB>  <TAB>  <TAB> n = name[wordstart:i] <MASK> n = name[wordstart : i + 1] <TAB>  <TAB> if n: <TAB>  <TAB>  <TAB> wordstart = i <TAB>  <TAB>  <TAB> if c == ""-"" and n != """": <TAB>  <TAB>  <TAB>  <TAB> n += ""-"" <TAB>  <TAB>  <TAB> if c == "" "" or c == ""-"": <TAB>  <TAB>  <TAB>  <TAB> wordstart = i + 1 <TAB>  <TAB>  <TAB> wordlist.append(n) <TAB> return wordlist",elif i == l - 1 :,174
"def check_file(f, path): <TAB> if not (ignore_substring and ignore_substring in f): <MASK> compl_path = os.path.join(path, f) <TAB>  <TAB>  <TAB> if os.path.isfile(compl_path): <TAB>  <TAB>  <TAB>  <TAB> return compl_path <TAB> return False",if substring in f :,83
"def keyPressEvent(self, event): <TAB> """"""Add up and down arrow key events to built in functionality."""""" <TAB> keyPressed = event.key() <TAB> if keyPressed in [Constants.UP_KEY, Constants.DOWN_KEY, Constants.TAB_KEY]: <TAB>  <TAB> if keyPressed == Constants.UP_KEY: <TAB>  <TAB>  <TAB> self.index = max(0, self.index - 1) <MASK> self.index = min(len(self.completerStrings) - 1, self.index + 1) <TAB>  <TAB> elif keyPressed == Constants.TAB_KEY and self.completerStrings: <TAB>  <TAB>  <TAB> self.tabPressed() <TAB>  <TAB> if self.completerStrings: <TAB>  <TAB>  <TAB> self.setTextToCompleterIndex() <TAB> super(CueLineEdit, self).keyPressEvent(event)",elif keyPressed == Constants . DOWN_KEY :,192
"def _get_disk_size(cls, path, ignored=None): <TAB> if ignored is None: <TAB>  <TAB> ignored = [] <TAB> if path in ignored: <TAB>  <TAB> return 0 <TAB> total = 0 <TAB> for entry in scandir(path): <MASK> total += cls._get_disk_size(entry.path, ignored=ignored) <TAB>  <TAB> elif entry.is_file(): <TAB>  <TAB>  <TAB> total += entry.stat().st_size <TAB> return total",if entry . is_dir ( ) :,117
"def _handle_rate_limit( <TAB> self, exception: RedditAPIException) -> Optional[Union[int, float]]: <TAB> for item in exception.items: <TAB>  <TAB> if item.error_type == ""RATELIMIT"": <TAB>  <TAB>  <TAB> amount_search = self._ratelimit_regex.search(item.message) <TAB>  <TAB>  <TAB> if not amount_search: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> seconds = int(amount_search.group(1)) <TAB>  <TAB>  <TAB> if ""minute"" in amount_search.group(2): <TAB>  <TAB>  <TAB>  <TAB> seconds *= 60 <MASK> sleep_seconds = seconds + min(seconds / 10, 1) <TAB>  <TAB>  <TAB>  <TAB> return sleep_seconds <TAB> return None",if seconds <= int ( self . config . ratelimit_seconds ) :,181
"def validate(self): <TAB> try: <TAB>  <TAB> f = int(eval(self.setting.getValue(), {}, {})) <MASK> return ERROR, ""This setting should not be below "" + str(self.minValue) <TAB>  <TAB> if self.maxValue is not None and f > self.maxValue: <TAB>  <TAB>  <TAB> return ERROR, ""This setting should not be above "" + str(self.maxValue) <TAB>  <TAB> return SUCCESS, """" <TAB> except (ValueError, SyntaxError, TypeError, NameError): <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB> ERROR, <TAB>  <TAB>  <TAB> '""' <TAB>  <TAB>  <TAB> + str(self.setting.getValue()) <TAB>  <TAB>  <TAB> + '"" is not a valid whole number or expression', <TAB>  <TAB> )",if self . minValue is not None and f < self . minValue :,180
"def rename(self, remote_name, new_remote_name): <TAB> remotes = self.load_remotes() <TAB> remotes.rename(remote_name, new_remote_name) <TAB> with self._cache.editable_packages.disable_editables(): <TAB>  <TAB> for ref in self._cache.all_refs(): <TAB>  <TAB>  <TAB> with self._cache.package_layout(ref).update_metadata() as metadata: <MASK> metadata.recipe.remote = new_remote_name <TAB>  <TAB>  <TAB>  <TAB> for pkg_metadata in metadata.packages.values(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if pkg_metadata.remote == remote_name: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pkg_metadata.remote = new_remote_name <TAB>  <TAB> remotes.save(self._filename)",if metadata . recipe . remote == remote_name :,195
"def _convert_idx(self, idx): <TAB> graph_idx = 0 <TAB> node_idx = idx <TAB> for i in range(len(self.graphs)): <MASK> graph_idx = i <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> node_idx -= self.graphs[i].number_of_nodes() <TAB> return graph_idx, node_idx",if node_idx < self . graphs [ i ] . number_of_nodes ( ) :,107
"def emit_pre_migrate_signal(verbosity, interactive, db, **kwargs): <TAB> # Emit the pre_migrate signal for every application. <TAB> for app_config in apps.get_app_configs(): <MASK> continue <TAB>  <TAB> if verbosity >= 2: <TAB>  <TAB>  <TAB> print(""Running pre-migrate handlers for application %s"" % app_config.label) <TAB>  <TAB> models.signals.pre_migrate.send( <TAB>  <TAB>  <TAB> sender=app_config, <TAB>  <TAB>  <TAB> app_config=app_config, <TAB>  <TAB>  <TAB> verbosity=verbosity, <TAB>  <TAB>  <TAB> interactive=interactive, <TAB>  <TAB>  <TAB> using=db, <TAB>  <TAB>  <TAB> **kwargs <TAB>  <TAB> )",if app_config . models_module is None :,166
"def slice(self, slice): <TAB> gridscope = GridScope(globals=self.globals) <TAB> for key in self.user_added: <TAB>  <TAB> value = self[key] <MASK> grid = value <TAB>  <TAB>  <TAB> sliced = np.sum(grid[slice, ...], axis=0) <TAB>  <TAB>  <TAB> logger.debug(""sliced %s from %r to %r"", key, grid.shape, sliced.shape) <TAB>  <TAB>  <TAB> gridscope[key] = sliced <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> gridscope[key] = value <TAB> return gridscope","if isinstance ( value , np . ndarray ) :",140
"def get_last_tagged(self): <TAB> if not self.last_tagged: <TAB>  <TAB> last = datetime(1970, 1, 1) <TAB>  <TAB> for tag in self.tags: <MASK> last = tag.last_seen <TAB>  <TAB> self.update(set__last_tagged=last) <TAB>  <TAB> return last <TAB> else: <TAB>  <TAB> return self.last_tagged",if tag . last_seen > last :,101
"def recalculate_user_disk_usage(app, **kwargs): <TAB> user_id = kwargs.get(""user_id"", None) <TAB> sa_session = app.model.context <TAB> if user_id: <TAB>  <TAB> user = sa_session.query(app.model.User).get(app.security.decode_id(user_id)) <MASK> user.calculate_and_set_disk_usage() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.error( <TAB>  <TAB>  <TAB>  <TAB> ""Recalculate user disk usage task failed, user %s not found"" % user_id <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> log.error(""Recalculate user disk usage task received without user_id."")",if user :,165
"def log_items(self, interface, action, media, items): <TAB> if not items: <TAB>  <TAB> return <TAB>  <TAB> # Log each item <TAB> for item in items: <MASK> continue <TAB>  <TAB> log.info( <TAB>  <TAB>  <TAB> ""[%s:%s](%s) %r (%r)"", <TAB>  <TAB>  <TAB> interface, <TAB>  <TAB>  <TAB> action, <TAB>  <TAB>  <TAB> media, <TAB>  <TAB>  <TAB> item.get(""title""), <TAB>  <TAB>  <TAB> item.get(""year""), <TAB>  <TAB> ) <TAB>  <TAB> if media == ""shows"": <TAB>  <TAB>  <TAB> # Log each episode <TAB>  <TAB>  <TAB> self.log_episodes(item)",if not item :,150
"def test_unbiased_coin_has_no_second_order(): <TAB> counts = Counter() <TAB> for i in range(256): <TAB>  <TAB> buf = bytes([i]) <TAB>  <TAB> data = ConjectureData.for_buffer(buf) <TAB>  <TAB> result = cu.biased_coin(data, 0.5) <MASK> counts[result] += 1 <TAB> assert counts[False] == counts[True] > 0",if data . buffer == buf :,111
"def gettempfilename(suffix): <TAB> """"""Returns a temporary filename"""""" <TAB> if ""_"" in os.environ: <TAB>  <TAB> # tempfile.mktemp() crashes on some Wine versions (the one of Ubuntu 12.04 particularly) <MASK> tmpdir = ""."" <TAB>  <TAB>  <TAB> if ""TMP"" in os.environ: <TAB>  <TAB>  <TAB>  <TAB> tmpdir = os.environ[""TMP""] <TAB>  <TAB>  <TAB> import time <TAB>  <TAB>  <TAB> import random <TAB>  <TAB>  <TAB> random.seed(time.time()) <TAB>  <TAB>  <TAB> random_part = ""file%d"" % random.randint(0, 1000000000) <TAB>  <TAB>  <TAB> return os.path.join(tmpdir, random_part + suffix) <TAB> return tempfile.mktemp(suffix)","if os . environ [ ""_"" ] . find ( ""wine"" ) >= 0 :",172
"def _get_functionapp_runtime_language( <TAB> self, app_settings):  # pylint: disable=no-self-use <TAB> functions_worker_runtime = [ <TAB>  <TAB> setting[""value""] <TAB>  <TAB> for setting in app_settings <TAB>  <TAB> if setting[""name""] == ""FUNCTIONS_WORKER_RUNTIME"" <TAB> ] <TAB> if functions_worker_runtime: <TAB>  <TAB> functionapp_language = functions_worker_runtime[0] <MASK> return SUPPORTED_LANGUAGES[functionapp_language] <TAB>  <TAB> raise LanguageNotSupportException(functionapp_language) <TAB> return None",if SUPPORTED_LANGUAGES . get ( functionapp_language ) is not None :,151
"def seek(self, offset, whence=io.SEEK_SET): <TAB> if self.mode == WRITE: <TAB>  <TAB> if whence != io.SEEK_SET: <TAB>  <TAB>  <TAB> if whence == io.SEEK_CUR: <TAB>  <TAB>  <TAB>  <TAB> offset = self.offset + offset <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""Seek from end not supported"") <MASK> raise OSError(""Negative seek in write mode"") <TAB>  <TAB> count = offset - self.offset <TAB>  <TAB> chunk = bytes(1024) <TAB>  <TAB> for i in range(count // 1024): <TAB>  <TAB>  <TAB> self.write(chunk) <TAB>  <TAB> self.write(bytes(count % 1024)) <TAB> elif self.mode == READ: <TAB>  <TAB> self._check_not_closed() <TAB>  <TAB> return self._buffer.seek(offset, whence) <TAB> return self.offset",if offset < self . offset :,199
"def stop(self): <TAB> """"""Stop the HTTP server."""""" <TAB> if self.running: <TAB>  <TAB> # stop() MUST block until the server is *truly* stopped. <TAB>  <TAB> self.httpserver.stop() <TAB>  <TAB> # Wait for the socket to be truly freed. <MASK> portend.free(*self.bound_addr, timeout=Timeouts.free) <TAB>  <TAB> self.running = False <TAB>  <TAB> self.bus.log(""HTTP Server %s shut down"" % self.httpserver) <TAB> else: <TAB>  <TAB> self.bus.log(""HTTP Server %s already shut down"" % self.httpserver)","if isinstance ( self . bind_addr , tuple ) :",156
"def dump_json(testcase, json_file): <TAB> """"""dump HAR entries to json testcase"""""" <TAB> logger.info(""dump testcase to JSON format."") <TAB> with open(json_file, ""w"", encoding=""utf-8"") as outfile: <TAB>  <TAB> my_json_str = json.dumps(testcase, ensure_ascii=False, indent=4) <MASK> my_json_str = my_json_str.decode(""utf-8"") <TAB>  <TAB> outfile.write(my_json_str) <TAB> logger.info(""Generate JSON testcase successfully: {}"".format(json_file))","if isinstance ( my_json_str , bytes ) :",148
"def find_comment(line): <TAB> """"""Finds the index of a comment # and returns None if not found"""""" <TAB> instring, instring_char = False, """" <TAB> for i, char in enumerate(line): <TAB>  <TAB> if char in ('""', ""'""): <TAB>  <TAB>  <TAB> if instring: <MASK> instring = False <TAB>  <TAB>  <TAB>  <TAB>  <TAB> instring_char = """" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> instring = True <TAB>  <TAB>  <TAB>  <TAB> instring_char = char <TAB>  <TAB> elif char == ""#"": <TAB>  <TAB>  <TAB> if not instring: <TAB>  <TAB>  <TAB>  <TAB> return i <TAB> return None",if char == instring_char :,155
"def _requests_to_follow(self, response): <TAB> if not isinstance(response, HtmlResponse): <TAB>  <TAB> return <TAB> seen = set() <TAB> for n, rule in enumerate(self._rules): <TAB>  <TAB> links = [ <TAB>  <TAB>  <TAB> lnk <TAB>  <TAB>  <TAB> for lnk in rule.link_extractor.extract_links(response) <TAB>  <TAB>  <TAB> if lnk not in seen <TAB>  <TAB> ] <MASK> links = rule.process_links(links) <TAB>  <TAB> for link in links: <TAB>  <TAB>  <TAB> seen.add(link) <TAB>  <TAB>  <TAB> request = self._build_request(n, link) <TAB>  <TAB>  <TAB> yield rule._process_request(request, response)",if links and rule . process_links :,168
"def _process_iter(self, line_iter): <TAB> samples = [] <TAB> buf = [] <TAB> for line in line_iter: <TAB>  <TAB> if not buf and line.startswith(""#"") and self._has_comment: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> line = line.split() <MASK> buf.append(line) <TAB>  <TAB> elif buf: <TAB>  <TAB>  <TAB> samples.append(tuple(map(list, zip(*buf)))) <TAB>  <TAB>  <TAB> buf = [] <TAB> if buf: <TAB>  <TAB> samples.append(tuple(map(list, zip(*buf)))) <TAB> return samples",if line :,137
"def _set_input_expanded(self, inp, expand, scroll=True): <TAB> getobj = self._builder.get_object <TAB> arrow = getobj(""by%s_expander_arrow"" % (inp.name,)) <TAB> grid = getobj(""by%s_curve_grid"" % (inp.name,)) <TAB> if expand: <TAB>  <TAB> arrow.set_property(""arrow-type"", Gtk.ArrowType.DOWN) <TAB>  <TAB> grid.show_all() <MASK> GLib.idle_add(self._scroll_setting_editor, grid) <TAB> else: <TAB>  <TAB> arrow.set_property(""arrow-type"", Gtk.ArrowType.RIGHT) <TAB>  <TAB> grid.hide()",if scroll :,164
"def extract_groups(self, text: str, language_code: str): <TAB> previous = None <TAB> group = 1 <TAB> groups = [] <TAB> words = [] <TAB> ignored = IGNORES.get(language_code, {}) <TAB> for word in NON_WORD.split(text): <TAB>  <TAB> if not word: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if word not in ignored and len(word) >= 2: <TAB>  <TAB>  <TAB> if previous == word: <TAB>  <TAB>  <TAB>  <TAB> group += 1 <MASK> groups.append(group) <TAB>  <TAB>  <TAB>  <TAB> words.append(previous) <TAB>  <TAB>  <TAB>  <TAB> group = 1 <TAB>  <TAB> previous = word <TAB> if group > 1: <TAB>  <TAB> groups.append(group) <TAB>  <TAB> words.append(previous) <TAB> return groups, words",elif group > 1 :,187
"def add_field_to_csv_file(fieldName, fieldNameMap, fieldsList, fieldsTitles, titles): <TAB> for ftList in fieldNameMap[fieldName]: <MASK> fieldsList.append(ftList) <TAB>  <TAB>  <TAB> fieldsTitles[ftList] = ftList <TAB>  <TAB>  <TAB> add_titles_to_csv_file([ftList], titles)",if ftList not in fieldsTitles :,96
"def get_transform(self, img): <TAB> check_dtype(img) <TAB> assert img.ndim in [2, 3], img.ndim <TAB> from .transform import LazyTransform, TransformList <TAB> # The next augmentor requires the previous one to finish. <TAB> # So we have to use LazyTransform <TAB> tfms = [] <TAB> for idx, a in enumerate(self.augmentors): <TAB>  <TAB> if idx == 0: <TAB>  <TAB>  <TAB> t = a.get_transform(img) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> t = LazyTransform(a.get_transform) <MASK> tfms.extend(t.tfms) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tfms.append(t) <TAB> return TransformList(tfms)","if isinstance ( t , TransformList ) :",180
"def __init__(self, template, context, body_stream=None): <TAB> if body_stream is None: <MASK> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB> ""Async mode requires a body stream "" <TAB>  <TAB>  <TAB>  <TAB> ""to be passed to a template module.  Use "" <TAB>  <TAB>  <TAB>  <TAB> ""the async methods of the API you are "" <TAB>  <TAB>  <TAB>  <TAB> ""using."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> body_stream = list(template.root_render_func(context)) <TAB> self._body_stream = body_stream <TAB> self.__dict__.update(context.get_exported()) <TAB> self.__name__ = template.name",if context . environment . is_async :,157
"def url_locations(urls, faker=False): <TAB> locations = [] <TAB> for url in urls: <MASK> response = request.urlopen(request.Request(url, headers=fake_headers), None) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> response = request.urlopen(request.Request(url)) <TAB>  <TAB> locations.append(response.url) <TAB> return locations",if faker :,90
"def wait_services_ready(selectors, min_counts, count_fun, timeout=None): <TAB> readies = [0] * len(selectors) <TAB> start_time = time.time() <TAB> while True: <TAB>  <TAB> all_satisfy = True <TAB>  <TAB> for idx, selector in enumerate(selectors): <MASK> all_satisfy = False <TAB>  <TAB>  <TAB>  <TAB> readies[idx] = count_fun(selector) <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if all_satisfy: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if timeout and timeout + start_time < time.time(): <TAB>  <TAB>  <TAB> raise TimeoutError(""Wait cluster start timeout"") <TAB>  <TAB> time.sleep(1)",if readies [ idx ] < min_counts [ idx ] :,167
"def sanitize_args(a): <TAB> try: <TAB>  <TAB> args, kwargs = a <TAB>  <TAB> if isinstance(args, tuple) and isinstance(kwargs, dict): <TAB>  <TAB>  <TAB> return args, dict(kwargs) <TAB> except (TypeError, ValueError): <TAB>  <TAB> args, kwargs = (), {} <TAB> if a is not None: <TAB>  <TAB> if isinstance(a, dict): <TAB>  <TAB>  <TAB> args = tuple() <TAB>  <TAB>  <TAB> kwargs = a <TAB>  <TAB> elif isinstance(a, tuple): <MASK> args, kwargs = a[0:-1], a[-1] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> args = a <TAB>  <TAB>  <TAB>  <TAB> kwargs = {} <TAB> return args, kwargs","if isinstance ( a [ - 1 ] , dict ) :",168
"def _override_options(options, **overrides): <TAB> """"""Override options."""""" <TAB> for opt, val in overrides.items(): <TAB>  <TAB> passed_value = getattr(options, opt, _Default()) <TAB>  <TAB> if opt in (""ignore"", ""select"") and passed_value: <TAB>  <TAB>  <TAB> value = process_value(opt, passed_value.value) <TAB>  <TAB>  <TAB> value += process_value(opt, val) <TAB>  <TAB>  <TAB> setattr(options, opt, value) <MASK> setattr(options, opt, process_value(opt, val))","elif isinstance ( passed_value , _Default ) :",137
"def get_first_file_by_stem(dir_path, stem, exts=None): <TAB> dir_path = Path(dir_path) <TAB> stem = stem.lower() <TAB> if dir_path.exists(): <TAB>  <TAB> for x in sorted(list(scandir(str(dir_path))), key=lambda x: x.name): <MASK> continue <TAB>  <TAB>  <TAB> xp = Path(x.path) <TAB>  <TAB>  <TAB> if xp.stem.lower() == stem and (exts is None or xp.suffix.lower() in exts): <TAB>  <TAB>  <TAB>  <TAB> return xp <TAB> return None",if not x . is_file ( ) :,148
"def testShortCircuit(self): <TAB> """"""Test that creation short-circuits to reuse existing references"""""" <TAB> sd = {} <TAB> for s in self.ss: <TAB>  <TAB> sd[s] = 1 <TAB> for t in self.ts: <MASK> self.assert_(sd.has_key(safeRef(t.x))) <TAB>  <TAB>  <TAB> self.assert_(safeRef(t.x) in sd) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assert_(sd.has_key(safeRef(t))) <TAB>  <TAB>  <TAB> self.assert_(safeRef(t) in sd)","if hasattr ( t , ""x"" ) :",146
"def _gen_Less(self, args, ret_type): <TAB> result = [] <TAB> for lhs, rhs in pairwise(args): <TAB>  <TAB> if ret_type == real_type: <TAB>  <TAB>  <TAB> result.append(self.builder.fcmp_ordered(""<"", lhs, rhs)) <MASK> result.append(self.builder.icmp_signed(""<"", lhs, rhs)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise CompileError() <TAB> return reduce(self.builder.and_, result)",elif ret_type == int_type :,120
def _resolve_aliases(tasks_or_files): <TAB> for task_or_file in tasks_or_files: <MASK> for t_or_f in _resolve_aliases(task_or_file.deps): <TAB>  <TAB>  <TAB>  <TAB> yield t_or_f <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield task_or_file,"if isinstance ( task_or_file , Alias ) :",92
"def report(properties): <TAB> for name, value in properties: <MASK> if hasattr(value, ""uniobj""): <TAB>  <TAB>  <TAB>  <TAB> # Under old versions of pytest, `value` was a `py.xml.raw` <TAB>  <TAB>  <TAB>  <TAB> # rather than a string, so we get the (unicode) string off it. <TAB>  <TAB>  <TAB>  <TAB> value = value.uniobj <TAB>  <TAB>  <TAB> line = base64.b64decode(value.encode()).decode() + ""\n\n"" <TAB>  <TAB>  <TAB> terminalreporter.write_line(line)","if name . startswith ( ""hypothesis-statistics-"" ) :",135
"def throw_404(self, n): <TAB> # bl_label of some nodes is edited by us, but those nodes do have docs .. <TAB> _dirname = os.path.dirname(sverchok.__file__) <TAB> path1 = os.path.join(_dirname, ""docs"", ""404.html"") <TAB> path2 = os.path.join(_dirname, ""docs"", ""404_custom.html"") <TAB> with open(path1) as origin: <TAB>  <TAB> with open(path2, ""w"") as destination: <TAB>  <TAB>  <TAB> for line in origin: <MASK> destination.write(line.replace(""{{variable}}"", n.bl_label)) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> destination.write(line) <TAB> webbrowser.open(path2)","if ""{{variable}}"" in line :",193
"def rm_empty_dirs(dirpath, interactive=False, dry_run=False): <TAB> for name in os.listdir(dirpath): <TAB>  <TAB> path = join(dirpath, name) <MASK> rm_empty_dirs(path, interactive, dry_run) <TAB> if not os.listdir(dirpath): <TAB>  <TAB> if interactive: <TAB>  <TAB>  <TAB> raise NotImplementedError(""'-i' not implemented"") <TAB>  <TAB> if dry_run: <TAB>  <TAB>  <TAB> log.info(""rmdir `%s' (dry-run)"", dirpath) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.info(""rmdir `%s'"", dirpath) <TAB>  <TAB>  <TAB> os.rmdir(dirpath)",if isdir ( path ) :,153
"def get_run_cmd(submission_dir): <TAB> """"""Get the language of a submission"""""" <TAB> with CD(submission_dir): <MASK> with open(""run.sh"") as f: <TAB>  <TAB>  <TAB>  <TAB> for line in f: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if line[0] != ""#"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return line.rstrip(""\r\n"")","if os . path . exists ( ""run.sh"" ) :",98
"def _do_test_fetch_result(self, results, remote): <TAB> # self._print_fetchhead(remote.repo) <TAB> self.assertGreater(len(results), 0) <TAB> self.assertIsInstance(results[0], FetchInfo) <TAB> for info in results: <TAB>  <TAB> self.assertIsInstance(info.note, string_types) <TAB>  <TAB> if isinstance(info.ref, Reference): <TAB>  <TAB>  <TAB> self.assertTrue(info.flags) <TAB>  <TAB> # END reference type flags handling <TAB>  <TAB> self.assertIsInstance(info.ref, (SymbolicReference, Reference)) <MASK> self.assertIsInstance(info.old_commit, Commit) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertIsNone(info.old_commit)",if info . flags & ( info . FORCED_UPDATE | info . FAST_FORWARD ) :,186
"def __set__(self, instance, value): <TAB> super().__set__(instance, value) <TAB> value = instance._data[self.name] <TAB> if value is not None: <MASK> instance._data[self.name] = self._convert_from_datetime(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> instance._data[self.name] = value","if isinstance ( value , datetime . datetime ) :",95
"def put(self, can_split=False): <TAB> if isinstance(self.expr, NodeConst): <MASK> # 2007 May 01 <TAB>  <TAB>  <TAB> self.expr.put() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.line_more(""("") <TAB>  <TAB>  <TAB> self.expr.put(can_split=True) <TAB>  <TAB>  <TAB> self.line_more("")"") <TAB> else: <TAB>  <TAB> self.put_expr(self.expr, can_split=can_split) <TAB> self.line_more(""."") <TAB> self.line_more(NAME_SPACE.make_attr_name(self.expr, self.attrname)) <TAB> return self",if self . expr . is_str ( ) :,157
"def get_location(self, dist, dependency_links): <TAB> for url in dependency_links: <TAB>  <TAB> egg_fragment = Link(url).egg_fragment <MASK> continue <TAB>  <TAB> if ""-"" in egg_fragment: <TAB>  <TAB>  <TAB> ## FIXME: will this work when a package has - in the name? <TAB>  <TAB>  <TAB> key = ""-"".join(egg_fragment.split(""-"")[:-1]).lower() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> key = egg_fragment <TAB>  <TAB> if key == dist.key: <TAB>  <TAB>  <TAB> return url.split(""#"", 1)[0] <TAB> return None",if not egg_fragment :,141
"def _parse_lines(self, lines): <TAB> for line in lines: <TAB>  <TAB> self.size += len(line) <TAB>  <TAB> words = line.strip().split(""\t"") <TAB>  <TAB> if len(words) > 1: <TAB>  <TAB>  <TAB> wset = set(words[1:]) <MASK> self.WORDS[words[0]] |= wset <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.WORDS[words[0]] = wset",if words [ 0 ] in self . WORDS :,118
"def __call__(self, target): <TAB> # normal running mode <TAB> if not self.check_run_always: <TAB>  <TAB> for algo in self.algos: <TAB>  <TAB>  <TAB> if not algo(target): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True <TAB> # run mode when at least one algo has a run_always attribute <TAB> else: <TAB>  <TAB> # store result in res <TAB>  <TAB> # allows continuation to check for and run <TAB>  <TAB> # algos that have run_always set to True <TAB>  <TAB> res = True <TAB>  <TAB> for algo in self.algos: <MASK> res = algo(target) <TAB>  <TAB>  <TAB> elif hasattr(algo, ""run_always""): <TAB>  <TAB>  <TAB>  <TAB> if algo.run_always: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> algo(target) <TAB>  <TAB> return res",if res :,188
"def _cmd_flags_as_data(cmd_flags): <TAB> data = {} <TAB> for flag_name, cmd_flag in cmd_flags.items(): <TAB>  <TAB> cmd_flag_data = _cmd_flag_as_data(cmd_flag) <MASK> data[flag_name] = cmd_flag_data <TAB> return data",if cmd_flag_data :,89
"def _csv_iterator(data_path, ngrams, yield_cls=False): <TAB> tokenizer = get_tokenizer(""basic_english"") <TAB> with io.open(data_path, encoding=""utf8"") as f: <TAB>  <TAB> reader = unicode_csv_reader(f) <TAB>  <TAB> for row in reader: <TAB>  <TAB>  <TAB> tokens = "" "".join(row[1:]) <TAB>  <TAB>  <TAB> tokens = tokenizer(tokens) <MASK> yield int(row[0]) - 1, ngrams_iterator(tokens, ngrams) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield ngrams_iterator(tokens, ngrams)",if yield_cls :,147
"def FindEnclosingBracketGroup(input_str): <TAB> stack = [] <TAB> start = -1 <TAB> for index, char in enumerate(input_str): <TAB>  <TAB> if char in LBRACKETS: <TAB>  <TAB>  <TAB> stack.append(char) <TAB>  <TAB>  <TAB> if start == -1: <TAB>  <TAB>  <TAB>  <TAB> start = index <TAB>  <TAB> elif char in BRACKETS: <TAB>  <TAB>  <TAB> if not stack: <TAB>  <TAB>  <TAB>  <TAB> return (-1, -1) <MASK> return (-1, -1) <TAB>  <TAB>  <TAB> if not stack: <TAB>  <TAB>  <TAB>  <TAB> return (start, index + 1) <TAB> return (-1, -1)",if stack . pop ( ) != BRACKETS [ char ] :,163
def get_and_set_be_comp(self): <TAB> all_be_comp = [] <TAB> for page in self.pages: <TAB>  <TAB> if page.relations.be_comp_norm is not None: <TAB>  <TAB>  <TAB> all_be_comp.extend(page.relations.be_comp_norm) <MASK> all_be_comp.extend(page.relations.be_comp) <TAB> return set(all_be_comp),if page . relations . be_comp is not None :,117
"def iterload(self): <TAB> delim = self.options.delimiter <TAB> rowdelim = self.options.row_delimiter <TAB> with self.source.open_text() as fp: <TAB>  <TAB> with Progress(total=filesize(self.source)) as prog: <TAB>  <TAB>  <TAB> for line in splitter(fp, rowdelim): <MASK> continue <TAB>  <TAB>  <TAB>  <TAB> prog.addProgress(len(line)) <TAB>  <TAB>  <TAB>  <TAB> row = list(line.split(delim)) <TAB>  <TAB>  <TAB>  <TAB> if len(row) < self.nVisibleCols: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # extend rows that are missing entries <TAB>  <TAB>  <TAB>  <TAB>  <TAB> row.extend([None] * (self.nVisibleCols - len(row))) <TAB>  <TAB>  <TAB>  <TAB> yield row",if not line :,182
"def process_module(name, module, parent): <TAB> if parent: <TAB>  <TAB> modules[parent][""items""].append(name) <TAB>  <TAB> mg = module_groups.setdefault(name, []) <TAB>  <TAB> mg.append(parent) <TAB>  <TAB> if get_module_type(name) == ""py3status"": <TAB>  <TAB>  <TAB> module["".group""] = parent <TAB> # check module content <TAB> for k, v in list(module.items()): <TAB>  <TAB> if k.startswith(""on_click""): <TAB>  <TAB>  <TAB> # on_click event <TAB>  <TAB>  <TAB> process_onclick(k, v, name) <TAB>  <TAB>  <TAB> # on_click should not be passed to the module via the config. <TAB>  <TAB>  <TAB> del module[k] <MASK> # we are a container <TAB>  <TAB>  <TAB> module[""items""] = [] <TAB> return module","if isinstance ( v , ModuleDefinition ) :",198
"def test_identify_accepts_space_separated_hosts(self): <TAB> ru, iu = self.mock_all_identify() <TAB> file_ip = open(tests.VALID_FILE_IP) <TAB> for i, line in enumerate(file_ip): <MASK> expected_url, expected_host = (""http://192.168.1.1/"", ""example.com"") <TAB>  <TAB> elif i == 2: <TAB>  <TAB>  <TAB> expected_url, expected_host = (""http://192.168.1.2/drupal/"", ""example.com"") <TAB>  <TAB> identify_line(line) <TAB>  <TAB> args, kwargs = ru.call_args_list[-1] <TAB>  <TAB> self.assertEquals(args[0], expected_url) <TAB>  <TAB> self.assertEquals(args[1], expected_host)",if i < 2 :,195
"def get_version(module): <TAB> for key in version_keys: <MASK> version = getattr(module, key) <TAB>  <TAB>  <TAB> if isinstance(version, types.ModuleType): <TAB>  <TAB>  <TAB>  <TAB> version = get_version(version) <TAB>  <TAB>  <TAB> return version <TAB> return ""Unknown""","if hasattr ( module , key ) :",77
"def whoami(self): <TAB> """"""Return user relevant login information."""""" <TAB> account_data = {} <TAB> for k in (""email"", ""account_id""): <TAB>  <TAB> value = self.conf.get(k) <MASK> account_info = self.get_account_information() <TAB>  <TAB>  <TAB> value = account_info.get(k, ""unknown"") <TAB>  <TAB>  <TAB> self.conf.set(k, value) <TAB>  <TAB>  <TAB> self.conf.save() <TAB>  <TAB> account_data[k] = value <TAB> return account_data",if not value :,130
"def do(self): <TAB> if self.in_class_scope(): <TAB>  <TAB> selected_str = self.view.substr(self.selected_region) <TAB>  <TAB> for symbol in self.view.symbols(): <MASK> self.view.sel().clear() <TAB>  <TAB>  <TAB>  <TAB> self.view.sel().add(symbol[0]) <TAB>  <TAB>  <TAB>  <TAB> self.view.show(symbol[0]) <TAB>  <TAB>  <TAB>  <TAB> return <TAB> # falls back to the original functionality <TAB> self.window.run_command(""goto_definition"")",if symbol [ 1 ] == selected_str :,136
"def __iter__(self): <TAB> i = 0 <TAB> for category, filename in list(self.input_files.items()): <TAB>  <TAB> for line in open(filename): <TAB>  <TAB>  <TAB> line = self._clean_line(line) <MASK> yield Opinion(line, category) <TAB>  <TAB>  <TAB> i += 1 <TAB>  <TAB>  <TAB> if i % 1000 == 0: <TAB>  <TAB>  <TAB>  <TAB> print(""\tReaded {} examples"".format(i))",if self . accept_criteria ( i ) :,115
"def recvmsg(self, *args): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self._sock.recvmsg(*args) <TAB>  <TAB> except error as ex: <MASK> raise <TAB>  <TAB> self._wait(self._read_event)",if ex . args [ 0 ] != EWOULDBLOCK or self . timeout == 0.0 :,87
"def _get_editable_fields(cls): <TAB> fds = set([]) <TAB> for field in cls._meta.concrete_fields: <MASK> if field.attname == ""id"": <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> elif field.attname.endswith(""ptr_id""): <TAB>  <TAB>  <TAB>  <TAB> # polymorphic fields should always be non-editable, see: <TAB>  <TAB>  <TAB>  <TAB> # https://github.com/django-polymorphic/django-polymorphic/issues/349 <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if getattr(field, ""editable"", True): <TAB>  <TAB>  <TAB>  <TAB> fds.add(field.attname) <TAB> return fds","if hasattr ( field , ""attname"" ) :",159
"def prepare_fields(all_fields, submit_fields, submit): <TAB> if len(list(submit_fields.items(multi=True))) > 1: <TAB>  <TAB> if not submit: <TAB>  <TAB>  <TAB> raise exceptions.InvalidSubmitError() <MASK> raise exceptions.InvalidSubmitError() <TAB>  <TAB> return _filter_fields( <TAB>  <TAB>  <TAB> all_fields, lambda f: not isinstance(f, fields.Submit) or f == submit <TAB>  <TAB> ) <TAB> return all_fields",if submit not in submit_fields . getlist ( submit . name ) :,123
"def tag_configure(self, *args, **keys): <TAB> if len(args) == 1: <TAB>  <TAB> key = args[0] <TAB>  <TAB> self.tags[key] = keys <TAB>  <TAB> val = keys.get(""foreground"") <TAB>  <TAB> underline = keys.get(""underline"") <MASK> self.configDict[key] = val <TAB>  <TAB> if underline: <TAB>  <TAB>  <TAB> self.configUnderlineDict[key] = True <TAB> else: <TAB>  <TAB> g.trace(""oops"", args, keys)",if val :,123
"def detect(get_page): <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS: <TAB>  <TAB> page, headers, code = get_page(get=vector) <TAB>  <TAB> retval = ( <TAB>  <TAB>  <TAB> code == 501 <TAB>  <TAB>  <TAB> and re.search(r""Reference #[0-9A-Fa-f.]+"", page, re.I) is not None <TAB>  <TAB> ) <MASK> break <TAB> return retval",if retval :,112
"def refine_pointer_names_input(lines): <TAB> """"""Return  a list of width_info_t. Skip comments and blank lines"""""" <TAB> global comment_pattern <TAB> widths_list = [] <TAB> for line in lines: <TAB>  <TAB> pline = comment_pattern.sub("""", line).strip() <TAB>  <TAB> if pline == """": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> wrds = pline.split() <TAB>  <TAB> ntokens = len(wrds) <MASK> (bbytes, name, suffix) = wrds <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> die(""Bad number of tokens on line: "" + line) <TAB>  <TAB> widths_list.append((bbytes, name, suffix)) <TAB> return widths_list",if ntokens == 3 :,169
"def notify(title, message, retcode=None): <TAB> """"""Sends message over Telegram using telegram-send, title is ignored."""""" <TAB> if not path.exists(config_file): <MASK> makedirs(config_dir) <TAB>  <TAB> print(""Follow the instructions to configure the Telegram backend.\n"") <TAB>  <TAB> configure(config_file) <TAB> send(messages=[message], conf=config_file)",if not path . exists ( config_dir ) :,104
"def find_on_path(targets): <TAB> """"""Search the PATH for a program and return full path"""""" <TAB> if sabnzbd.WIN32: <TAB>  <TAB> paths = os.getenv(""PATH"").split("";"") <TAB> else: <TAB>  <TAB> paths = os.getenv(""PATH"").split("":"") <TAB> if isinstance(targets, str): <TAB>  <TAB> targets = (targets,) <TAB> for path in paths: <TAB>  <TAB> for target in targets: <TAB>  <TAB>  <TAB> target_path = os.path.abspath(os.path.join(path, target)) <MASK> return target_path <TAB> return None","if os . path . isfile ( target_path ) and os . access ( target_path , os . X_OK ) :",164
"def test_name_attribute(self): <TAB> for cons in self.hash_constructors: <TAB>  <TAB> h = cons() <TAB>  <TAB> self.assertIsInstance(h.name, str) <MASK> self.assertIn(h.name, self.supported_hash_names) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertNotIn(h.name, self.supported_hash_names) <TAB>  <TAB> self.assertEqual(h.name, hashlib.new(h.name).name)",if h . name in self . supported_hash_names :,124
"def find_marriage(database, family): <TAB> """"""find the marriage of a family"""""" <TAB> for event_ref in family.get_event_ref_list(): <TAB>  <TAB> event = database.get_event_from_handle(event_ref.ref) <MASK> return event <TAB> return None",if event and event . type . is_marriage ( ) and event_ref . role . is_family ( ) :,96
"def test_find_ancestors(self): <TAB> vhsblocks = self.config.parser_root.find_blocks(""VirtualHost"") <TAB> macro_test = False <TAB> nonmacro_test = False <TAB> for vh in vhsblocks: <MASK> ancs = vh.find_ancestors(""Macro"") <TAB>  <TAB>  <TAB> self.assertEqual(len(ancs), 1) <TAB>  <TAB>  <TAB> macro_test = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ancs = vh.find_ancestors(""Macro"") <TAB>  <TAB>  <TAB> self.assertEqual(len(ancs), 0) <TAB>  <TAB>  <TAB> nonmacro_test = True <TAB> self.assertTrue(macro_test) <TAB> self.assertTrue(nonmacro_test)","if ""/macro/"" in vh . metadata [ ""augeaspath"" ] . lower ( ) :",183
def readline(self): <TAB> while 1: <TAB>  <TAB> line = self._readline() <MASK> self._filelineno += 1 <TAB>  <TAB>  <TAB> return line <TAB>  <TAB> if not self._file: <TAB>  <TAB>  <TAB> return line <TAB>  <TAB> self.nextfile(),if line :,65
"def read_oclc(fields): <TAB> if ""035"" not in fields: <TAB>  <TAB> return {} <TAB> found = [] <TAB> for line in fields[""035""]: <TAB>  <TAB> for v in get_subfield_values(line, [""a""]): <TAB>  <TAB>  <TAB> m = re_oclc.match(v) <TAB>  <TAB>  <TAB> if not m: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> oclc = m.group(1) <MASK> found.append(oclc) <TAB> return {""oclc_number"": found} if found else {}",if oclc not in found :,143
"def get_new_unlinked_nodes( <TAB> before_inputted_nodes, before_input_sockets, input_sockets, nodes_dict): <TAB> affected_nodes = [] <TAB> for node_id, socket in zip(before_inputted_nodes, before_input_sockets): <TAB>  <TAB> if not socket in input_sockets: <TAB>  <TAB>  <TAB> # if the node has been deleted it is not affected <MASK> if not node_id in affected_nodes: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> affected_nodes.append(node_id) <TAB> return affected_nodes",if node_id in nodes_dict :,141
"def set_available_qty(self): <TAB> for d in self.get(""required_items""): <MASK> d.available_qty_at_source_warehouse = get_latest_stock_qty( <TAB>  <TAB>  <TAB>  <TAB> d.item_code, d.source_warehouse <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if self.wip_warehouse: <TAB>  <TAB>  <TAB> d.available_qty_at_wip_warehouse = get_latest_stock_qty( <TAB>  <TAB>  <TAB>  <TAB> d.item_code, self.wip_warehouse <TAB>  <TAB>  <TAB> )",if d . source_warehouse :,136
"def _unique_product_recursive(pools, result, i): <TAB> if i >= len(pools): <TAB>  <TAB> yield tuple(result) <TAB>  <TAB> return <TAB> for e in pools[i]: <MASK> result[i] = e <TAB>  <TAB>  <TAB> yield from _unique_product_recursive(pools, result, i + 1) <TAB>  <TAB>  <TAB> result[i] = _SENTINEL",if e not in result :,98
def fileno(self): <TAB> try: <TAB>  <TAB> return self.sock.fileno() <TAB> except socket.error: <TAB>  <TAB> self.close() <TAB>  <TAB> ex = sys.exc_info()[1] <MASK> raise EOFError() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise,if get_exc_errno ( ex ) == errno . EBADF :,84
"def expand_block(self, feat): <TAB> """"""Expand any blocks which are near the start or end of a contig."""""" <TAB> chrom_end = self._ref_sizes.get(feat.chrom) <TAB> if chrom_end: <TAB>  <TAB> if feat.start < self._end_buffer: <TAB>  <TAB>  <TAB> feat.start = 0 <MASK> feat.stop = chrom_end <TAB> return feat",if feat . stop >= chrom_end - self . _end_buffer :,114
"def prepare_parser(self, parser): <TAB> docs = [self.parse_doc(doc) for doc in (self.doc, __doc__) if doc] <TAB> for doc in docs: <TAB>  <TAB> for long_opt, help in items(doc): <TAB>  <TAB>  <TAB> option = parser._option_string_actions[long_opt] <MASK> option.help = "" "".join(help).format(default=option.default) <TAB> return parser",if option is not None :,113
"def negate(monad): <TAB> sql = monad.getsql()[0] <TAB> translator = monad.translator <TAB> if translator.dialect == ""Oracle"": <TAB>  <TAB> result_sql = [""IS_NULL"", sql] <TAB> else: <TAB>  <TAB> result_sql = [""EQ"", sql, [""VALUE"", """"]] <TAB>  <TAB> if monad.nullable: <MASK> result_sql = [""OR"", result_sql, [""IS_NULL"", sql]] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> result_sql = [""EQ"", [""COALESCE"", sql, [""VALUE"", """"]], [""VALUE"", """"]] <TAB> result = BoolExprMonad(result_sql, nullable=False) <TAB> result.aggregated = monad.aggregated <TAB> return result","if isinstance ( monad , AttrMonad ) :",188
"def _ReadN(self, stdin_fd, n): <TAB> # type: (int, int) -> str <TAB> chunks = []  # type: List[str] <TAB> bytes_left = n <TAB> while bytes_left > 0: <TAB>  <TAB> chunk = posix.read(stdin_fd, n)  # read at up to N chars <MASK> break <TAB>  <TAB> chunks.append(chunk) <TAB>  <TAB> bytes_left -= len(chunk) <TAB> s = """".join(chunks) <TAB> return s",if len ( chunk ) == 0 :,127
"def instance_reader(): <TAB> for epoch_index in range(epoch): <TAB>  <TAB> if shuffle: <MASK> np.random.seed(shuffle_seed) <TAB>  <TAB>  <TAB> np.random.shuffle(examples) <TAB>  <TAB> if phase == ""train"": <TAB>  <TAB>  <TAB> self.current_train_epoch = epoch_index <TAB>  <TAB> for (index, example) in enumerate(examples): <TAB>  <TAB>  <TAB> if phase == ""train"": <TAB>  <TAB>  <TAB>  <TAB> self.current_train_example = index + 1 <TAB>  <TAB>  <TAB> feature = self.convert_example( <TAB>  <TAB>  <TAB>  <TAB> index, example, self.get_labels(), self.max_seq_len, self.tokenizer <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> instance = self.generate_instance(feature) <TAB>  <TAB>  <TAB> yield instance",if shuffle_seed is not None :,189
"def close(self): <TAB> fileobj = self.fileobj <TAB> if fileobj is None: <TAB>  <TAB> return <TAB> self.fileobj = None <TAB> try: <TAB>  <TAB> if self.mode == WRITE: <TAB>  <TAB>  <TAB> fileobj.write(self.compress.flush()) <TAB>  <TAB>  <TAB> write32u(fileobj, self.crc) <TAB>  <TAB>  <TAB> # self.size may exceed 2GB, or even 4GB <TAB>  <TAB>  <TAB> write32u(fileobj, self.size & 0xFFFFFFFF) <TAB> finally: <TAB>  <TAB> myfileobj = self.myfileobj <MASK> self.myfileobj = None <TAB>  <TAB>  <TAB> myfileobj.close()",if myfileobj :,147
"def rsa_public_key_parse(key_material): <TAB> # These imports take ~.5s; let's keep them local <TAB> import sshpubkeys.exceptions <TAB> from sshpubkeys.keys import SSHKey <TAB> try: <MASK> key_material = key_material.encode(""ascii"") <TAB>  <TAB> decoded_key = base64.b64decode(key_material).decode(""ascii"") <TAB>  <TAB> public_key = SSHKey(decoded_key) <TAB> except (sshpubkeys.exceptions.InvalidKeyException, UnicodeDecodeError): <TAB>  <TAB> raise ValueError(""bad key"") <TAB> if not public_key.rsa: <TAB>  <TAB> raise ValueError(""bad key"") <TAB> return public_key.rsa","if not isinstance ( key_material , six . binary_type ) :",174
"def import_type(library, name): <TAB> if library.name != idaapi.cvar.idati.name: <TAB>  <TAB> last_ordinal = idaapi.get_ordinal_qty(idaapi.cvar.idati) <TAB>  <TAB> type_id = idaapi.import_type(library, -1, name)  # tid_t <MASK> return last_ordinal",if type_id != idaapi . BADORD :,106
"def OnDropFiles(self, x, y, files): <TAB> filteredList = [] <TAB> if self.filenameFilter is not None: <TAB>  <TAB> for f in files: <TAB>  <TAB>  <TAB> for ext in self.filenameFilter: <MASK> filteredList.append(f) <TAB> else: <TAB>  <TAB> filteredList = files <TAB> if len(filteredList) > 0: <TAB>  <TAB> self.callback(filteredList)",if f . endswith ( ext ) or f . endswith ( ext . upper ( ) ) :,117
"def _get_most_recent_update(self, versions): <TAB> recent = None <TAB> for version in versions: <TAB>  <TAB> updated = datetime.datetime.strptime(version[""updated""], ""%Y-%m-%dT%H:%M:%SZ"") <TAB>  <TAB> if not recent: <TAB>  <TAB>  <TAB> recent = updated <MASK> recent = updated <TAB> return recent.strftime(""%Y-%m-%dT%H:%M:%SZ"")",elif updated > recent :,103
"def __setstate__(self, servers_ids: List[str]): <TAB> self.try_list = [] <TAB> for server_id in servers_ids: <MASK> self.add_to_try_list(sabnzbd.Downloader.server_dict[server_id])",if server_id in sabnzbd . Downloader . server_dict :,85
"def remove_command(self, command_id): <TAB> for command in self.config[""commands""]: <MASK> self.config[""commands""].remove(command) <TAB>  <TAB>  <TAB> component.get(""EventManager"").emit(ExecuteCommandRemovedEvent(command_id)) <TAB>  <TAB>  <TAB> break <TAB> self.config.save()",if command [ EXECUTE_ID ] == command_id :,89
"def wrapper(*args, **kargs): <TAB> offspring = func(*args, **kargs) <TAB> for child in offspring: <TAB>  <TAB> for i in xrange(len(child)): <MASK> child[i] = max <TAB>  <TAB>  <TAB> elif child[i] < min: <TAB>  <TAB>  <TAB>  <TAB> child[i] = min <TAB> return offspring",if child [ i ] > max :,95
"def dispatch(self, request, *args, **kwargs): <TAB> self.product = get_object_or_404(self.product_model, pk=kwargs[""product_pk""]) <TAB> # check permission to leave review <TAB> if not self.product.is_review_permitted(request.user): <MASK> message = _(""You have already reviewed this product!"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> message = _(""You can't leave a review for this product."") <TAB>  <TAB> messages.warning(self.request, message) <TAB>  <TAB> return redirect(self.product.get_absolute_url()) <TAB> return super().dispatch(request, *args, **kwargs)",if self . product . has_review_by ( request . user ) :,167
"def PlayPause(self): <TAB> state = self.graphManager.GetState(10) <TAB> if state == 2:  # playing <TAB>  <TAB> self.Pause() <TAB> elif state == 1:  # paused <TAB>  <TAB> self.Play() <TAB> elif state == 0:  # stopped <MASK> self.Stop() <TAB>  <TAB>  <TAB> self.PlayingItem = self.SelectedItem <TAB>  <TAB>  <TAB> self.LoadFile(self.SelectedItem.Path) <TAB>  <TAB>  <TAB> self.Play() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.Play() <TAB> else: <TAB>  <TAB> pass  # for now just do nothing <TAB> self.NotifyPropertyChanged(""IsPlaying"") <TAB> self.NotifyPropertyChanged(""Duration"")",if ( self . SelectedItem != None ) and ( self . filename != self . SelectedItem . Path ) :,188
"def decref(self, *keys): <TAB> for tileable_key, tileable_id in keys: <TAB>  <TAB> if tileable_key not in self._executed_tileables: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> _graph_key, ids = self._executed_tileables[tileable_key] <MASK> ids.remove(tileable_id) <TAB>  <TAB>  <TAB> # for those same key tileables, do decref only when all those tileables are garbage collected <TAB>  <TAB>  <TAB> if len(ids) != 0: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> self.delete_data(tileable_key)",if tileable_id in ids :,137
"def get_git_description(self): <TAB> if self.is_a_git_repo(): <TAB>  <TAB> exit_code, stdout, stderr = execute_command_and_capture_output( <TAB>  <TAB>  <TAB> ""git"", ""describe"", ""--always"", ""--tags"", ""--dirty"" <TAB>  <TAB> ) <MASK> raise PyBuilderException( <TAB>  <TAB>  <TAB>  <TAB> ""Cannot determine git description: git describe failed:\n{0}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> stderr <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return stdout.strip() <TAB> else: <TAB>  <TAB> raise PyBuilderException( <TAB>  <TAB>  <TAB> ""Cannot determine git description: project is not a git repo."" <TAB>  <TAB> )",if exit_code != 0 :,172
"def _code_for_module(self, module): <TAB> text = '""%s"" [shape=ellips]' % module.name <TAB> for item in list(module.items()): <MASK> text += '\n""%s""' % item <TAB>  <TAB>  <TAB> text += '\n""%s"" -> ""%s""' % (module.name, item) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> text += self._code_for_module(item)  # recurs <TAB>  <TAB>  <TAB> text += '\n""%s"" -> ""%s""' % (module.name, item.name) <TAB> return text","if isinstance ( item , str ) :",140
"def test_images_p_is_stochastic_parameter(self): <TAB> aug = self.create_aug(p=iap.Choice([0, 1], p=[0.7, 0.3])) <TAB> seen = [0, 0] <TAB> for _ in sm.xrange(1000): <TAB>  <TAB> observed = aug.augment_image(self.image) <MASK> seen[0] += 1 <TAB>  <TAB> elif np.array_equal(observed, self.image_flipped): <TAB>  <TAB>  <TAB> seen[1] += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert False <TAB> assert np.allclose(seen, [700, 300], rtol=0, atol=75)","if np . array_equal ( observed , self . image ) :",168
"def get_index_text(self, modname: str, name_cls: Tuple[str, str]) -> str: <TAB> if self.objtype == ""function"": <MASK> return _(""%s() (built-in function)"") % name_cls[0] <TAB>  <TAB> return _(""%s() (in module %s)"") % (name_cls[0], modname) <TAB> elif self.objtype == ""data"": <TAB>  <TAB> if not modname: <TAB>  <TAB>  <TAB> return _(""%s (built-in variable)"") % name_cls[0] <TAB>  <TAB> return _(""%s (in module %s)"") % (name_cls[0], modname) <TAB> else: <TAB>  <TAB> return """"",if not modname :,162
"def _attributes_to_xml(self, xml_element, prefix_root, debug_context=None): <TAB> del debug_context  # Unused. <TAB> for attribute_name, attribute in six.iteritems(self._attributes): <TAB>  <TAB> attribute_value = attribute.to_xml_string(prefix_root) <TAB>  <TAB> if attribute_name == self._spec.identifier and attribute_value is None: <TAB>  <TAB>  <TAB> xml_element.set(attribute_name, self.full_identifier) <MASK> continue <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> xml_element.set(attribute_name, attribute_value)",elif attribute_value is None :,149
def index_def(self): <MASK> self.lazy_init_lock_.acquire() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if self.index_def_ is None: <TAB>  <TAB>  <TAB>  <TAB> self.index_def_ = Index() <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self.lazy_init_lock_.release() <TAB> return self.index_def_,if self . index_def_ is None :,94
"def _ord_to_str(ordinal, weights): <TAB> """"""Reverse function of _str_to_ord."""""" <TAB> chars = [] <TAB> for weight in weights: <MASK> return """".join(chars) <TAB>  <TAB> ordinal -= 1 <TAB>  <TAB> index, ordinal = divmod(ordinal, weight) <TAB>  <TAB> chars.append(_ALPHABET[index]) <TAB> return """".join(chars)",if ordinal == 0 :,97
"def tip_texts(self): <TAB> """"""Return the tip texts of the Toolbar (without window text)"""""" <TAB> texts = [] <TAB> for i in range(0, self.button_count()): <TAB>  <TAB> # it works for MFC <TAB>  <TAB> btn_tooltip_index = self.get_button_struct(i).iString <TAB>  <TAB> # usually iString == -1 for separator <TAB>  <TAB> # other cases if any <MASK> btn_tooltip_index = i <TAB>  <TAB> btn_text = self.get_tool_tips_control().get_tip_text(btn_tooltip_index + 1) <TAB>  <TAB> texts.append(btn_text) <TAB> return texts",if not ( - 1 <= btn_tooltip_index < self . get_tool_tips_control ( ) . tool_count ( ) ) :,183
"def _initCaseSets(self): <TAB> self._cs = {} <TAB> self._css = {} <TAB> for cs in self._caseSets: <TAB>  <TAB> if not self._cs.has_key(cs.CaseSetName): <TAB>  <TAB>  <TAB> self._cs[cs.CaseSetName] = {} <TAB>  <TAB>  <TAB> self._css[cs.CaseSetName] = cs <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception(""duplicate case set name"") <TAB>  <TAB> for c in cs.Cases: <TAB>  <TAB>  <TAB> idx = tuple(c.index) <MASK> self._cs[cs.CaseSetName][idx] = c <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise Exception(""duplicate case index"")",if not self . _cs [ cs . CaseSetName ] . has_key ( idx ) :,178
"def is_image(self, input): <TAB> try: <TAB>  <TAB> if isinstance(input, (np.ndarray, Image.Image)): <TAB>  <TAB>  <TAB> return True <MASK> if not os.path.isfile(input): <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""input must be a file"") <TAB>  <TAB>  <TAB> img = Image.open(input) <TAB>  <TAB>  <TAB> _ = img.size <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> except: <TAB>  <TAB> return False","elif isinstance ( input , str ) :",122
"def __init__(self, opt, shared=None): <TAB> super().__init__(opt, shared) <TAB> if not shared: <TAB>  <TAB> self.episodes = [] <TAB>  <TAB> self.num_exs = 0 <MASK> self._setup_data(opt.get(""parlaidialogteacher_datafile"")) <TAB> else: <TAB>  <TAB> self.episodes = shared[""episodes""] <TAB>  <TAB> self.num_exs = sum(len(e) for e in self.episodes) <TAB> self.id = opt[""task""] <TAB> self.reset()","if opt . get ( ""parlaidialogteacher_datafile"" ) is not None :",152
"def draw(l, n, th=2): <TAB> clear() <TAB> l = l * f ** n <TAB> shapesize(l / 100.0, l / 100.0, th) <TAB> for k in tiledict: <TAB>  <TAB> h, x, y = k <TAB>  <TAB> setpos(x, y) <TAB>  <TAB> setheading(h) <MASK> shape(""kite"") <TAB>  <TAB>  <TAB> color(""black"", (0, 0.75, 0)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> shape(""dart"") <TAB>  <TAB>  <TAB> color(""black"", (0.75, 0, 0)) <TAB>  <TAB> stamp()",if tiledict [ k ] :,151
"def visit_Assign(self, node): <TAB> if len(node.targets) == 1: <TAB>  <TAB> if isinstance(node.targets[0], ast.Subscript): <TAB>  <TAB>  <TAB> plugPath = self.__plugPath(self.__path(node.targets[0])) <MASK> self.plugWrites.add(plugPath) <TAB> self.visit(node.value)",if plugPath :,93
"def StripTypeInfo(rendered_data): <TAB> """"""Strips type information from rendered data. Useful for debugging."""""" <TAB> if isinstance(rendered_data, (list, tuple)): <TAB>  <TAB> return [StripTypeInfo(d) for d in rendered_data] <TAB> elif isinstance(rendered_data, dict): <MASK> return StripTypeInfo(rendered_data[""value""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result = {} <TAB>  <TAB>  <TAB> for k, v in rendered_data.items(): <TAB>  <TAB>  <TAB>  <TAB> result[k] = StripTypeInfo(v) <TAB>  <TAB>  <TAB> return result <TAB> else: <TAB>  <TAB> return rendered_data","if ""value"" in rendered_data and ""type"" in rendered_data :",159
"def _match_greater_than_or_equal(search_base, attribute, value, candidates): <TAB> matches = list() <TAB> for entry in candidates: <TAB>  <TAB> dn = entry.get(""dn"") <MASK> continue <TAB>  <TAB> value_from_directory = entry.get(""attributes"").get(attribute) <TAB>  <TAB> if str(value_from_directory) >= str(value): <TAB>  <TAB>  <TAB> entry[""type""] = ""searchResEntry"" <TAB>  <TAB>  <TAB> matches.append(entry) <TAB> return matches",if not dn . endswith ( search_base ) :,129
"def _get_changes(diff): <TAB> """"""Get a list of changed versions from git."""""" <TAB> changes_dict = {} <TAB> for line in diff: <TAB>  <TAB> if not line.startswith(""-"") and not line.startswith(""+""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if line.startswith(""+++ "") or line.startswith(""--- ""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> name, version = parse_versioned_line(line[1:]) <MASK> changes_dict[name] = Change(name) <TAB>  <TAB> if line.startswith(""-""): <TAB>  <TAB>  <TAB> changes_dict[name].old = version <TAB>  <TAB> elif line.startswith(""+""): <TAB>  <TAB>  <TAB> changes_dict[name].new = version <TAB> return [change for _name, change in sorted(changes_dict.items())]",if name not in changes_dict :,181
"def append_row(tbody, cells): <TAB> row = nodes.row() <TAB> tbody += row <TAB> for cell in cells: <TAB>  <TAB> entry = nodes.entry() <TAB>  <TAB> row += entry <MASK> node = nodes.paragraph(text=cell) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> node = cell <TAB>  <TAB> entry += node","if isinstance ( cell , six . text_type ) :",91
"def _testdata_to_is_unauthed_access_permitted(tests_config, node_type): <TAB> res = [] <TAB> for x in tests_config[""endpoint_tests""]: <TAB>  <TAB> if node_type not in x[""type""]: <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> h = x[""tests""][""is_unauthed_access_permitted""] <TAB>  <TAB> for p in h[""locations""]: <TAB>  <TAB>  <TAB> res.append((p, h.get(""vhost"", None))) <TAB> return res","if ""is_unauthed_access_permitted"" not in x [ ""tests"" ] :",139
"def process_ceph_status(output): <TAB> res = patternchk.search(output) <TAB> if not res: <TAB>  <TAB> return {} <TAB> ceph_stats = res.group() <TAB> if not ceph_stats: <TAB>  <TAB> return {} <TAB> ret = {} <TAB> rd = wr = iops = None <TAB> rd = numberchk.search(ceph_stats) <TAB> if rd is not None: <TAB>  <TAB> ret[""rd""] = rd.group() <TAB>  <TAB> wr = numberchk.search(ceph_stats, rd.end()) <TAB>  <TAB> if wr is not None: <TAB>  <TAB>  <TAB> ret[""wr""] = wr.group() <TAB>  <TAB>  <TAB> iops = numberchk.search(ceph_stats, wr.end()) <MASK> ret[""iops""] = iops.group() <TAB> return ret",if iops is not None :,198
"def construct_type_storage_plugin_registry(pipeline_def, system_storage_def): <TAB> # Needed to avoid circular dep <TAB> from dagster.core.definitions import PipelineDefinition, SystemStorageDefinition <TAB> check.inst_param(pipeline_def, ""pipeline_def"", PipelineDefinition) <TAB> check.inst_param(system_storage_def, ""system_storage_def"", SystemStorageDefinition) <TAB> type_plugins = [] <TAB> for type_obj in pipeline_def.all_runtime_types(): <TAB>  <TAB> for auto_plugin in type_obj.auto_plugins: <MASK> type_plugins.append((type_obj, auto_plugin)) <TAB> return TypeStoragePluginRegistry(type_plugins)",if auto_plugin . compatible_with_storage_def ( system_storage_def ) :,185
"def attr(**kw): <TAB> kw = kw.items() <TAB> kw.sort() <TAB> parts = [] <TAB> for name, value in kw: <MASK> continue <TAB>  <TAB> if name.endswith(""_""): <TAB>  <TAB>  <TAB> name = name[:-1] <TAB>  <TAB> parts.append('%s=""%s""' % (html_quote(name), html_quote(value))) <TAB> return html("" "".join(parts))",if value is None :,100
"def test_shape(): <TAB> from lasagne.init import Initializer <TAB> # Assert that all `Initializer` sublasses return the shape that <TAB> # we've asked for in `sample`: <TAB> for klass in Initializer.__subclasses__(): <MASK> # check HeNormal, HeUniform, GlorotNormal, GlorotUniform <TAB>  <TAB>  <TAB> for sub_klass in klass.__subclasses__(): <TAB>  <TAB>  <TAB>  <TAB> assert sub_klass().sample((12, 23)).shape == (12, 23) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert klass().sample((12, 23)).shape == (12, 23)",if len ( klass . __subclasses__ ( ) ) :,144
"def __call__(self, data): <TAB> num_points = data.pos.shape[0] <TAB> new_data = Data() <TAB> for key in data.keys: <TAB>  <TAB> if key == KDTREE_KEY: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> item = data[key] <TAB>  <TAB> if torch.is_tensor(item) and num_points == item.shape[0]: <TAB>  <TAB>  <TAB> item = item[self._indices].clone() <MASK> item = item.clone() <TAB>  <TAB> setattr(new_data, key, item) <TAB> return new_data",elif torch . is_tensor ( item ) :,144
"def vars(self): <TAB> ret = [] <TAB> if op.disklist: <TAB>  <TAB> varlist = op.disklist <TAB> elif not op.full: <TAB>  <TAB> varlist = (""total"",) <TAB> else: <TAB>  <TAB> varlist = [] <TAB>  <TAB> for name in self.discover: <MASK> continue <TAB>  <TAB>  <TAB> varlist.append(name) <TAB>  <TAB> # <TAB>  <TAB>    if len(varlist) > 2: varlist = varlist[0:2] <TAB>  <TAB> varlist.sort() <TAB> for name in varlist: <TAB>  <TAB> if name in self.discover + [""total""] or name in op.diskset: <TAB>  <TAB>  <TAB> ret.append(name) <TAB> return ret",if self . diskfilter . match ( name ) :,182
"def _convertNbBytesinNbBits(self, nbBytes): <TAB> nbMinBit = None <TAB> nbMaxBit = None <TAB> if nbBytes is not None: <MASK> nbMinBit = nbBytes * 8 <TAB>  <TAB>  <TAB> nbMaxBit = nbMinBit <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if nbBytes[0] is not None: <TAB>  <TAB>  <TAB>  <TAB> nbMinBit = nbBytes[0] * 8 <TAB>  <TAB>  <TAB> if nbBytes[1] is not None: <TAB>  <TAB>  <TAB>  <TAB> nbMaxBit = nbBytes[1] * 8 <TAB> return (nbMinBit, nbMaxBit)","if isinstance ( nbBytes , int ) :",149
"def after_test(self, results, tmp_dir): <TAB> return_data = dict() <TAB> if not results or not results.get(""data""): <TAB>  <TAB> return return_data <TAB> for filename in results[""data""]: <MASK> continue <TAB>  <TAB> with open(filename, ""r"") as f: <TAB>  <TAB>  <TAB> log_content = f.read() <TAB>  <TAB> log_analyser.make_log_analyses(log_content, return_data) <TAB> return return_data","if not has_ext ( filename , "".log"" ) :",125
"def ensure_vm_was_torn_down(): <TAB> vm_labels = [] <TAB> for vm_ref in xenapi_fake.get_all(""VM""): <TAB>  <TAB> vm_rec = xenapi_fake.get_record(""VM"", vm_ref) <MASK> vm_labels.append(vm_rec[""name_label""]) <TAB> self.assertEquals(vm_labels, [""1""])","if not vm_rec [ ""is_control_domain"" ] :",110
"def spool_print(*args, **kwargs): <TAB> with _print_lock: <TAB>  <TAB> if framework.Framework._spool: <TAB>  <TAB>  <TAB> framework.Framework._spool.write(f""{args[0]}{os.linesep}"") <TAB>  <TAB>  <TAB> framework.Framework._spool.flush() <TAB>  <TAB> # disable terminal output for server jobs <MASK> return <TAB>  <TAB> # new print function must still use the old print function via the backup <TAB>  <TAB> builtins._print(*args, **kwargs)",if framework . Framework . _mode == Mode . JOB :,126
"def _parse_lines(self, linesource): <TAB> """"""Parse lines of text for functions and classes"""""" <TAB> functions = [] <TAB> classes = [] <TAB> for line in linesource: <MASK> # exclude private stuff <TAB>  <TAB>  <TAB> name = self._get_object_name(line) <TAB>  <TAB>  <TAB> if not name.startswith(""_""): <TAB>  <TAB>  <TAB>  <TAB> functions.append(name) <TAB>  <TAB> elif line.startswith(""class ""): <TAB>  <TAB>  <TAB> # exclude private stuff <TAB>  <TAB>  <TAB> name = self._get_object_name(line) <TAB>  <TAB>  <TAB> if not name.startswith(""_""): <TAB>  <TAB>  <TAB>  <TAB> classes.append(name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pass <TAB> functions.sort() <TAB> classes.sort() <TAB> return functions, classes","if line . startswith ( ""def "" ) and line . count ( ""("" ) :",185
"def test_connect_using_sslcontext_verified(self): <TAB> with support.transient_internet(self.testServer): <TAB>  <TAB> can_verify = check_ssl_verifiy(self.testServer, self.remotePort) <MASK> self.skipTest(""SSL certificate can't be verified"") <TAB> support.get_attribute(smtplib, ""SMTP_SSL"") <TAB> context = ssl.create_default_context() <TAB> with support.transient_internet(self.testServer): <TAB>  <TAB> server = smtplib.SMTP_SSL(self.testServer, self.remotePort, context=context) <TAB>  <TAB> server.ehlo() <TAB>  <TAB> server.quit()",if not can_verify :,163
"def generate_segment_memory(chart_type, race_configs, environment): <TAB> structures = [] <TAB> for race_config in race_configs: <MASK> title = chart_type.format_title( <TAB>  <TAB>  <TAB>  <TAB> environment, <TAB>  <TAB>  <TAB>  <TAB> race_config.track, <TAB>  <TAB>  <TAB>  <TAB> es_license=race_config.es_license, <TAB>  <TAB>  <TAB>  <TAB> suffix=""%s-segment-memory"" % race_config.label, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> chart = chart_type.segment_memory(title, environment, race_config) <TAB>  <TAB>  <TAB> if chart: <TAB>  <TAB>  <TAB>  <TAB> structures.append(chart) <TAB> return structures","if ""segment_memory"" in race_config . charts :",168
"def __iter__(self): <TAB> line = b"""" <TAB> while True: <TAB>  <TAB> data = self.read(-1) <MASK> break <TAB>  <TAB> generator = StringIO(data) <TAB>  <TAB> assert b""\n"" not in line, line <TAB>  <TAB> line += next(generator) <TAB>  <TAB> if line.endswith(b""\n""): <TAB>  <TAB>  <TAB> yield line <TAB>  <TAB>  <TAB> line = b"""" <TAB>  <TAB>  <TAB> ll = list(generator) <TAB>  <TAB>  <TAB> if not ll: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> for line in ll[:-1]: <TAB>  <TAB>  <TAB>  <TAB> yield line <TAB>  <TAB>  <TAB> line = ll[-1] <TAB>  <TAB>  <TAB> if line.endswith(b""\n""): <TAB>  <TAB>  <TAB>  <TAB> yield line <TAB>  <TAB>  <TAB>  <TAB> line = b"""" <TAB> if line: <TAB>  <TAB> yield line",if not data :,189
"def L_op(self, inputs, outputs, gout): <TAB> (x,) = inputs <TAB> (gz,) = gout <TAB> if outputs[0].type in discrete_types: <MASK> return [x.zeros_like(dtype=theano.config.floatX)] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return [x.zeros_like()] <TAB> if x.type in float_types: <TAB>  <TAB> return (gz * sgn(x),) <TAB> return (gz * x / abs(x),)  # formula works for complex and real",if x . type in discrete_types :,133
"def is_ncname(name): <TAB> first = name[0] <TAB> if first == ""_"" or category(first) in NAME_START_CATEGORIES: <TAB>  <TAB> for i in xrange(1, len(name)): <TAB>  <TAB>  <TAB> c = name[i] <MASK> if c in ALLOWED_NAME_CHARS: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB>  <TAB> return 0 <TAB>  <TAB>  <TAB> # if in compatibility area <TAB>  <TAB>  <TAB> # if decomposition(c)!='': <TAB>  <TAB>  <TAB> # <TAB> return 0 <TAB>  <TAB> return 1 <TAB> else: <TAB>  <TAB> return 0",if not category ( c ) in NAME_CATEGORIES :,151
"def _read_rows_from(self, avro_reader, header): <TAB> count = 0 <TAB> maximum = self.limit if self.limit is not None else sys.maxsize <TAB> for i, record in enumerate(avro_reader): <TAB>  <TAB> if i < self.skip: <TAB>  <TAB>  <TAB> continue <MASK> break <TAB>  <TAB> count += 1 <TAB>  <TAB> row = self._map_row_from(header, record) <TAB>  <TAB> yield row",if count >= maximum :,111
"def decorated(cls, *args, **kwargs): <TAB> storage_res = STORAGE_RES_MAPPING[cls.__class__.__name__][func.__name__] <TAB> with utils.patch_vnxsystem as patched_vnx: <MASK> patched_vnx.return_value = storage_res[DEFAULT_STORAGE_RES] <TAB>  <TAB> adapter = PROTOCOL_MAPPING[protocol](cls.configuration) <TAB> return func(cls, adapter, storage_res, *args, **kwargs)",if DEFAULT_STORAGE_RES in storage_res :,122
"def _replace_file(src, dst): <TAB> try: <MASK> # MOVEFILE_REPLACE_EXISTING <TAB>  <TAB>  <TAB> raise OSError('Could not replace ""%s"" -> ""%s""' % (src, dst)) <TAB> except: <TAB>  <TAB> # Sometimes it fails - we play stupid and try again... <TAB>  <TAB> time.sleep(0.5) <TAB>  <TAB> if not _MoveFileEx(src, dst, 1):  # MOVEFILE_REPLACE_EXISTING <TAB>  <TAB>  <TAB> raise OSError('Could not replace ""%s"" -> ""%s""' % (src, dst))","if not _MoveFileEx ( src , dst , 1 ) :",141
"def read_track_raw(self, redundancy=1): <TAB> self._log(""read track raw"") <TAB> data = [] <TAB> await self.lower.write([CMD_READ_RAW, redundancy]) <TAB> while True: <TAB>  <TAB> packet = await self.lower.read() <MASK> raise GlasgowAppletError(""FIFO overflow while reading track"") <TAB>  <TAB> elif packet[-1] == 0xFE: <TAB>  <TAB>  <TAB> data.append(packet[:-1]) <TAB>  <TAB>  <TAB> return b"""".join(data) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> data.append(packet)",if packet [ - 1 ] == 0xFF :,147
"def get_template_sources(self, template_name, template_dirs=None): <TAB> template_name = self.prepare_template_name(template_name) <TAB> for loader in self.template_source_loaders: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> for result in loader.get_template_sources(template_name, template_dirs): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield result <TAB>  <TAB>  <TAB> except UnicodeDecodeError: <TAB>  <TAB>  <TAB>  <TAB> # The template dir name was a bytestring that wasn't valid UTF-8. <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> # The joined path was located outside of this particular <TAB>  <TAB>  <TAB>  <TAB> # template_dir (it might be inside another one, so this isn't <TAB>  <TAB>  <TAB>  <TAB> # fatal). <TAB>  <TAB>  <TAB>  <TAB> pass","if hasattr ( loader , ""get_template_sources"" ) :",195
"def __init__(self, reg, shtype, shimm, va): <TAB> if shimm == 0: <TAB>  <TAB> if shtype == S_ROR: <TAB>  <TAB>  <TAB> shtype = S_RRX <MASK> shimm = 32 <TAB> self.reg = reg <TAB> self.shtype = shtype <TAB> self.shimm = shimm <TAB> self.va = va",elif shtype == S_LSR or shtype == S_ASR :,107
"def pop_many(self, limit=None): <TAB> if limit is None: <TAB>  <TAB> limit = DEFAULT_SYNC_OFFLINE_ACTIVITY <TAB> heartbeats = [] <TAB> count = 0 <TAB> while count < limit: <TAB>  <TAB> heartbeat = self.pop() <TAB>  <TAB> if not heartbeat: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> heartbeats.append(heartbeat) <TAB>  <TAB> count += 1 <MASK> yield heartbeats <TAB>  <TAB>  <TAB> heartbeats = [] <TAB> if heartbeats: <TAB>  <TAB> yield heartbeats",if count % HEARTBEATS_PER_REQUEST == 0 :,140
"def _set_live(self, live, _): <TAB> if live is not None and not self.live: <MASK> live = [live] <TAB>  <TAB> # Default is to use Memory analysis. <TAB>  <TAB> if len(live) == 0: <TAB>  <TAB>  <TAB> mode = ""Memory"" <TAB>  <TAB> elif len(live) == 1: <TAB>  <TAB>  <TAB> mode = live[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise RuntimeError(""--live parameter should specify only one mode."") <TAB>  <TAB> live_plugin = self.session.plugins.live(mode=mode) <TAB>  <TAB> live_plugin.live() <TAB>  <TAB> # When the session is destroyed, close the live plugin. <TAB>  <TAB> self.session.register_flush_hook(self, live_plugin.close) <TAB> return live","if isinstance ( live , basestring ) :",184
"def capture_output(redirect_stderr=True): <TAB> oldout, olderr = sys.stdout, sys.stderr <TAB> try: <TAB>  <TAB> out = StringIO() <TAB>  <TAB> sys.stdout = out <MASK> sys.stderr = out <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sys.stderr = StringIO() <TAB>  <TAB> yield out <TAB> except: <TAB>  <TAB> if redirect_stderr: <TAB>  <TAB>  <TAB> traceback.print_exc() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise <TAB> finally: <TAB>  <TAB> sys.stdout, sys.stderr = oldout, olderr",if redirect_stderr :,135
"def run(self): <TAB> self.mpd.connect() <TAB> events = [""player""] <TAB> while True: <TAB>  <TAB> if ""player"" in events: <TAB>  <TAB>  <TAB> status = self.mpd.status() <TAB>  <TAB>  <TAB> handler = getattr(self, ""on_"" + status[""state""], None) <MASK> handler(status) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._log.debug(u'unhandled status ""{0}""', status) <TAB>  <TAB> events = self.mpd.events()",if handler :,121
"def get_full_qualified_name(self, node: Element) -> str: <TAB> if node.get(""reftype"") == ""option"": <TAB>  <TAB> progname = node.get(""std:program"") <TAB>  <TAB> command = ws_re.split(node.get(""reftarget"")) <MASK> command.insert(0, progname) <TAB>  <TAB> option = command.pop() <TAB>  <TAB> if command: <TAB>  <TAB>  <TAB> return ""."".join([""-"".join(command), option]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return None <TAB> else: <TAB>  <TAB> return None",if progname :,133
"def _get_sources(self): <TAB> servers = self.config[""servers""] <TAB> """"""maps urls to extractors"""""" <TAB> server_links = { <TAB>  <TAB> ""mp4upload"": ""mp4upload.com"", <TAB>  <TAB> ""gcloud"": ""gcloud.live"", <TAB>  <TAB> ""gcloud"": ""fembed.com"", <TAB> } <TAB> soup = helpers.soupify(helpers.get(self.url)).select(""iframe"") <TAB> for a in servers: <TAB>  <TAB> for b in soup: <TAB>  <TAB>  <TAB> for c in server_links: <MASK> return [(c, b.get(""src""))] <TAB> logger.warn(""Unsupported URL"") <TAB> return """"","if server_links [ c ] in b . get ( ""src"" ) and a == c :",179
"def _self_set(self, context): <TAB> if self.keys is not None: <TAB>  <TAB> return <TAB> new_dict = context.get_pynames([""self"", ""d""])[1] <TAB> if new_dict and isinstance(new_dict.get_object().get_type(), Dict): <TAB>  <TAB> args = arguments.ObjectArguments([new_dict]) <TAB>  <TAB> items = new_dict.get_object()[""popitem""].get_object().get_returned_object(args) <TAB>  <TAB> context.save_per_name(items) <TAB> else: <TAB>  <TAB> holding = _infer_sequence_for_pyname(new_dict) <MASK> context.save_per_name(holding)","if holding is not None and isinstance ( holding . get_type ( ) , Tuple ) :",181
"def create(): <TAB> """"""Create a new post for the current user."""""" <TAB> if request.method == ""POST"": <TAB>  <TAB> title = request.form[""title""] <TAB>  <TAB> body = request.form[""body""] <TAB>  <TAB> error = None <MASK> error = ""Title is required."" <TAB>  <TAB> if error is not None: <TAB>  <TAB>  <TAB> flash(error) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> db.session.add(Post(title=title, body=body, author=g.user)) <TAB>  <TAB>  <TAB> db.session.commit() <TAB>  <TAB>  <TAB> return redirect(url_for(""blog.index"")) <TAB> return render_template(""blog/create.html"")",if not title :,158
"def _find_host_dir_ldconfig(self, arch=""x86-64""): <TAB> """"""Find host nvidia libraries via ldconfig"""""" <TAB> dir_list = set() <TAB> ld_data = Uprocess().get_output([""ldconfig"", ""-p""]) <TAB> if ld_data: <TAB>  <TAB> regexp = ""[ |\t]%s[^ ]* .*%s.*=> (/.*)"" <TAB>  <TAB> for line in ld_data.split(""\n""): <TAB>  <TAB>  <TAB> for lib in self._nvidia_main_libs: <TAB>  <TAB>  <TAB>  <TAB> match = re.search(regexp % (lib, arch), line) <MASK> dir_list.add( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> os.path.realpath(os.path.dirname(match.group(1))) + ""/"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return dir_list",if match :,196
"def migrate_replay_storage(apps, schema_editor): <TAB> model = apps.get_model(""terminal"", ""ReplayStorage"") <TAB> init_storage_data(model) <TAB> setting = get_setting(apps, schema_editor, ""TERMINAL_REPLAY_STORAGE"") <TAB> if not setting: <TAB>  <TAB> return <TAB> values = get_storage_data(setting) <TAB> for name, meta in values.items(): <TAB>  <TAB> tp = meta.pop(""TYPE"", None) <MASK> continue <TAB>  <TAB> model.objects.create(name=name, type=tp, meta=meta)","if not tp or name in [ ""default"" , ""null"" ] :",150
"def load_distribution(args: CommandLineArguments) -> CommandLineArguments: <TAB> if args.distribution is not None: <TAB>  <TAB> args.distribution = Distribution[args.distribution] <TAB> if args.distribution is None or args.release is None: <TAB>  <TAB> d, r = detect_distribution() <TAB>  <TAB> if args.distribution is None: <TAB>  <TAB>  <TAB> args.distribution = d <MASK> args.release = r <TAB> if args.distribution is None: <TAB>  <TAB> die(""Couldn't detect distribution."") <TAB> return args",if args . distribution == d and d != Distribution . clear and args . release is None :,137
"def fieldset_string_to_field(fieldset_dict, model): <TAB> if isinstance(fieldset_dict[""fields""], tuple): <TAB>  <TAB> fieldset_dict[""fields""] = list(fieldset_dict[""fields""]) <TAB> i = 0 <TAB> for dict_field in fieldset_dict[""fields""]: <TAB>  <TAB> if isinstance(dict_field, string_types): <TAB>  <TAB>  <TAB> fieldset_dict[""fields""][i] = model._meta.get_field_by_name(dict_field)[0] <MASK> dict_field[1][""recursive""] = True <TAB>  <TAB>  <TAB> fieldset_string_to_field(dict_field[1], model) <TAB>  <TAB> i += 1","elif isinstance ( dict_field , list ) or isinstance ( dict_field , tuple ) :",179
"def icon(display_icon): <TAB> """"""returns empty dict if show_icons is False, else the icon passed"""""" <TAB> kws = {} <TAB> if get_icon_switch(): <TAB>  <TAB> if display_icon.startswith(""SV_""): <TAB>  <TAB>  <TAB> kws = {""icon_value"": custom_icon(display_icon)} <MASK> kws = {""icon"": display_icon} <TAB> return kws","elif display_icon != ""OUTLINER_OB_EMPTY"" :",106
"def cancel_helper(self, node, to_cancel): <TAB> children = set(self.workflow.successors(node)) <TAB> for child in children: <MASK> to_cancel.append(child.id_) <TAB>  <TAB>  <TAB> self.cancelled.append(node.id_) <TAB>  <TAB>  <TAB> await self.cancel_helper(child, to_cancel) <TAB> return to_cancel",if self . parent_map [ child . id_ ] == 1 :,103
"def getStatusString(self): <TAB> if not self._isAvailable: <TAB>  <TAB> return ""Doodle3D box not found"" <TAB> if self._printing: <TAB>  <TAB> if self._blockIndex < len(self._fileBlocks): <TAB>  <TAB>  <TAB> ret = ""Sending GCode: %.1f%%"" % ( <TAB>  <TAB>  <TAB>  <TAB> float(self._blockIndex) * 100.0 / float(len(self._fileBlocks)) <TAB>  <TAB>  <TAB> ) <MASK> ret = ""Finished sending GCode to Doodle3D box."" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret = ""Different print still running..."" <TAB>  <TAB> # ret += ""\nErrorCount: %d"" % (self._errorCount) <TAB>  <TAB> return ret <TAB> return ""Printer found, waiting for print command.""",elif len ( self . _fileBlocks ) > 0 :,190
"def test_archive_files_message(self): <TAB> filelist = [""test.torrent"", ""deluge.png""] <TAB> arc_filepath = archive_files( <TAB>  <TAB> ""test-arc"", [get_test_data_file(f) for f in filelist], message=""test"" <TAB> ) <TAB> result_files = filelist + [""archive_message.txt""] <TAB> with tarfile.open(arc_filepath, ""r"") as tar: <TAB>  <TAB> self.assertEqual(tar.getnames(), result_files) <TAB>  <TAB> for tar_info in tar: <TAB>  <TAB>  <TAB> self.assertTrue(tar_info.isfile()) <MASK> result = tar.extractfile(tar_info).read().decode() <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(result, ""test"")","if tar_info . name == ""archive_message.txt"" :",191
"def _format_arg(self, opt, spec, val): <TAB> if opt in [""in_files""]: <TAB>  <TAB> return scans_for_fnames(ensure_list(val)) <TAB> if opt == ""fwhm"": <TAB>  <TAB> if not isinstance(val, list): <TAB>  <TAB>  <TAB> return [val, val, val] <MASK> if len(val) == 1: <TAB>  <TAB>  <TAB>  <TAB> return [val[0], val[0], val[0]] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return val <TAB> return super(Smooth, self)._format_arg(opt, spec, val)","if isinstance ( val , list ) :",148
"def fuzzy_sum(self, currency, rounding=ROUND_UP): <TAB> a = Money.ZEROS[currency].amount <TAB> fuzzy = False <TAB> for m in self: <MASK> a += m.amount <TAB>  <TAB> elif m.amount: <TAB>  <TAB>  <TAB> a += m.convert(currency, rounding=None).amount <TAB>  <TAB>  <TAB> fuzzy = True <TAB> r = Money(a, currency, rounding=rounding) <TAB> r.fuzzy = fuzzy <TAB> return r",if m . currency == currency :,122
"def _read_potfiles(src_root, potfiles): <TAB> """"""Returns a list of paths for a POTFILES.in file"""""" <TAB> paths = [] <TAB> with open(potfiles, ""r"", encoding=""utf-8"") as h: <TAB>  <TAB> for line in h: <TAB>  <TAB>  <TAB> line = line.strip() <MASK> continue <TAB>  <TAB>  <TAB> paths.append(os.path.normpath(os.path.join(src_root, line))) <TAB> return paths","if not line or line . startswith ( ""#"" ) :",123
"def applyMath(self, val, math, frmt): <TAB> # apply math function - eval <TAB> try: <TAB>  <TAB> x = eval(val) <MASK> x = eval(math) <TAB>  <TAB> val = (""{0"" + frmt + ""}"").format(x) <TAB> except: <TAB>  <TAB> dprint( <TAB>  <TAB>  <TAB> __name__, <TAB>  <TAB>  <TAB> 0, <TAB>  <TAB>  <TAB> ""CCmds_applyMath: Error in math {0}, frmt {1}\n{2}"", <TAB>  <TAB>  <TAB> math, <TAB>  <TAB>  <TAB> frmt, <TAB>  <TAB>  <TAB> traceback.format_exc(), <TAB>  <TAB> ) <TAB> # apply format specifier <TAB> dprint(__name__, 2, ""CCmds_applyMath: {0}"", val) <TAB> return val","if math != """" :",179
def run_train_loop(self): <TAB> self.begin_training() <TAB> for _ in self.yield_train_step(): <MASK> self.save_model() <TAB>  <TAB> if self.should_save_checkpoint(): <TAB>  <TAB>  <TAB> self.save_checkpoint() <TAB>  <TAB> if self.should_eval_model(): <TAB>  <TAB>  <TAB> self.eval_model() <TAB>  <TAB> if self.should_break_training(): <TAB>  <TAB>  <TAB> break <TAB> self.eval_model() <TAB> self.done_training() <TAB> return self.returned_result(),if self . should_save_model ( ) :,139
"def node_exists(self, jid=None, node=None, ifrom=None): <TAB> with self.lock: <TAB>  <TAB> if jid is None: <TAB>  <TAB>  <TAB> jid = self.xmpp.boundjid.full <MASK> node = """" <TAB>  <TAB> if ifrom is None: <TAB>  <TAB>  <TAB> ifrom = """" <TAB>  <TAB> if isinstance(ifrom, JID): <TAB>  <TAB>  <TAB> ifrom = ifrom.full <TAB>  <TAB> if (jid, node, ifrom) not in self.nodes: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True",if node is None :,136
"def _collect(self, writer=None): <TAB> for artifact_name in self.plugin_args.artifacts: <TAB>  <TAB> for hit in self.collect_artifact(artifact_name): <MASK> writer.write_result(hit[""result""]) <TAB>  <TAB>  <TAB> yield hit","if ""result"" in hit and writer :",76
"def proc(qtbot, caplog): <TAB> """"""A fixture providing a GUIProcess and cleaning it up after the test."""""" <TAB> p = guiprocess.GUIProcess(""testprocess"") <TAB> yield p <TAB> if p._proc.state() == QProcess.Running: <TAB>  <TAB> with caplog.at_level(logging.ERROR): <TAB>  <TAB>  <TAB> with qtbot.waitSignal(p.finished, timeout=10000, raising=False) as blocker: <TAB>  <TAB>  <TAB>  <TAB> p._proc.terminate() <MASK> p._proc.kill() <TAB>  <TAB>  <TAB> p._proc.waitForFinished()",if not blocker . signal_triggered :,148
"def getsequences(self): <TAB> """"""Return the set of sequences for the folder."""""" <TAB> sequences = {} <TAB> fullname = self.getsequencesfilename() <TAB> try: <TAB>  <TAB> f = open(fullname, ""r"") <TAB> except IOError: <TAB>  <TAB> return sequences <TAB> while 1: <TAB>  <TAB> line = f.readline() <MASK> break <TAB>  <TAB> fields = line.split("":"") <TAB>  <TAB> if len(fields) != 2: <TAB>  <TAB>  <TAB> self.error(""bad sequence in %s: %s"" % (fullname, line.strip())) <TAB>  <TAB> key = fields[0].strip() <TAB>  <TAB> value = IntSet(fields[1].strip(), "" "").tolist() <TAB>  <TAB> sequences[key] = value <TAB> return sequences",if not line :,173
def get_coeffs(e): <TAB> coeffs = [] <TAB> for du in all_delu_dict.keys(): <MASK> coeffs.append(self.as_coeffs_dict[e]) <TAB>  <TAB> elif du in self.as_coeffs_dict[e].keys(): <TAB>  <TAB>  <TAB> coeffs.append(self.as_coeffs_dict[e][du]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> coeffs.append(0) <TAB> return np.array(coeffs),"if type ( self . as_coeffs_dict [ e ] ) . __name__ == ""float"" :",132
"def block_items(objekt, block, eldict): <TAB> if objekt not in block: <TAB>  <TAB> if isinstance(objekt.type, PyType): <TAB>  <TAB>  <TAB> if objekt.type not in block: <TAB>  <TAB>  <TAB>  <TAB> block.append(objekt.type) <TAB>  <TAB> block.append(objekt) <TAB>  <TAB> if isinstance(objekt, PyType): <TAB>  <TAB>  <TAB> others = [ <TAB>  <TAB>  <TAB>  <TAB> p <TAB>  <TAB>  <TAB>  <TAB> for p in eldict.values() <TAB>  <TAB>  <TAB>  <TAB> if isinstance(p, PyElement) and p.type[1] == objekt.name <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB> for item in others: <MASK> block.append(item) <TAB> return block",if item not in block :,186
"def FindPrefix(self, prefix): <TAB> self.log.WriteText(""Looking for prefix: %s\n"" % prefix) <TAB> if prefix: <TAB>  <TAB> prefix = prefix.lower() <TAB>  <TAB> length = len(prefix) <TAB>  <TAB> # Changed in 2.5 because ListBox.Number() is no longer supported. <TAB>  <TAB> # ListBox.GetCount() is now the appropriate way to go. <TAB>  <TAB> for x in range(self.GetCount()): <TAB>  <TAB>  <TAB> text = self.GetString(x) <TAB>  <TAB>  <TAB> text = text.lower() <MASK> self.log.WriteText(""Prefix %s is found.\n"" % prefix) <TAB>  <TAB>  <TAB>  <TAB> return x <TAB> self.log.WriteText(""Prefix %s is not found.\n"" % prefix) <TAB> return -1",if text [ : length ] == prefix :,195
"def encode(self, input, errors=""strict""): <TAB> if self.encoder is None: <TAB>  <TAB> result = codecs.utf_32_encode(input, errors) <MASK> self.encoder = codecs.utf_32_le_encode <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.encoder = codecs.utf_32_be_encode <TAB>  <TAB> return result <TAB> else: <TAB>  <TAB> return self.encoder(input, errors)","if sys . byteorder == ""little"" :",109
"def __call__(self, message, keyname): <TAB> if keyname in self.keyring: <TAB>  <TAB> key = self.keyring[keyname] <MASK> if message: <TAB>  <TAB>  <TAB>  <TAB> GSSTSigAdapter.parse_tkey_and_step(key, message, keyname) <TAB>  <TAB> return key <TAB> else: <TAB>  <TAB> return None","if isinstance ( key , Key ) and key . algorithm == GSS_TSIG :",98
"def unicode_metrics(metrics): <TAB> for i, metric in enumerate(metrics): <TAB>  <TAB> for key, value in metric.items(): <TAB>  <TAB>  <TAB> if isinstance(value, basestring): <TAB>  <TAB>  <TAB>  <TAB> metric[key] = unicode(value, errors=""replace"") <TAB>  <TAB>  <TAB> elif isinstance(value, tuple) or isinstance(value, list): <TAB>  <TAB>  <TAB>  <TAB> value_list = list(value) <TAB>  <TAB>  <TAB>  <TAB> for j, value_element in enumerate(value_list): <MASK> value_list[j] = unicode(value_element, errors=""replace"") <TAB>  <TAB>  <TAB>  <TAB> metric[key] = tuple(value_list) <TAB>  <TAB> metrics[i] = metric <TAB> return metrics","if isinstance ( value_element , basestring ) :",177
"def step(self, action): <TAB> assert self.action_space.contains(action) <TAB> if self._state == 4: <TAB>  <TAB> if action and self._case: <TAB>  <TAB>  <TAB> return self._state, 10.0, True, {} <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self._state, -10, True, {} <TAB> else: <TAB>  <TAB> if action: <MASK> self._state = 2 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._state += 1 <TAB>  <TAB> elif self._state == 2: <TAB>  <TAB>  <TAB> self._state = self._case <TAB> return self._state, -1, False, {}",if self . _state == 0 :,157
"def get_superuser(self): <TAB> try: <TAB>  <TAB> query = dict() <MASK> query[get_user_model().USERNAME_FIELD] = ""admin"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> query[get_user_model().USERNAME_FIELD] = ""admin@django-cms.org"" <TAB>  <TAB> admin = get_user_model().objects.get(**query) <TAB> except get_user_model().DoesNotExist: <TAB>  <TAB> admin = self._create_user(""admin"", is_staff=True, is_superuser=True) <TAB> return admin","if get_user_model ( ) . USERNAME_FIELD != ""email"" :",145
"def newend(self): <TAB> newenddatetime = self._newenddate <TAB> if not self.checkallday.state: <MASK> tzinfo = self.conf.default.default_timezone <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tzinfo = self.enddt.tzinfo <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> newendtime = self._newendtime <TAB>  <TAB>  <TAB> newenddatetime = datetime.combine(newenddatetime, newendtime) <TAB>  <TAB>  <TAB> newenddatetime = tzinfo.localize(newenddatetime) <TAB>  <TAB> except TypeError: <TAB>  <TAB>  <TAB> return None <TAB> return newenddatetime","if not hasattr ( self . enddt , ""tzinfo"" ) or self . enddt . tzinfo is None :",159
"def run(self): <TAB> to_delete = set() <TAB> for k, v in iteritems(self.objs): <TAB>  <TAB> if k.startswith(""_""): <TAB>  <TAB>  <TAB> continue <MASK> to_delete.add(k) <TAB>  <TAB> if v[""_class""] == ""Task"": <TAB>  <TAB>  <TAB> v[""submission_format""] = list( <TAB>  <TAB>  <TAB>  <TAB> self.objs[k][""filename""] for k in v.get(""submission_format"", list()) <TAB>  <TAB>  <TAB> ) <TAB> for k in to_delete: <TAB>  <TAB> del self.objs[k] <TAB> return self.objs","if v [ ""_class"" ] == ""SubmissionFormatElement"" :",147
"def update_reserved_qty_for_subcontract(self): <TAB> for d in self.supplied_items: <MASK> stock_bin = get_bin(d.rm_item_code, d.reserve_warehouse) <TAB>  <TAB>  <TAB> stock_bin.update_reserved_qty_for_sub_contracting()",if d . rm_item_code :,86
"def process(self): <TAB> if ""Length"" in self.outputs and self.outputs[""Length""].is_linked: <TAB>  <TAB> if ""Data"" in self.inputs and self.inputs[""Data""].is_linked: <TAB>  <TAB>  <TAB> data = self.inputs[""Data""].sv_get(deepcopy=False) <MASK> out = [[len(data)]] <TAB>  <TAB>  <TAB> elif self.level == 1: <TAB>  <TAB>  <TAB>  <TAB> out = [self.count(data, self.level)] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> out = self.count(data, self.level) <TAB>  <TAB>  <TAB> self.outputs[""Length""].sv_set(out)",if not self . level :,159
"def _user_has_perm(user, perm, obj): <TAB> anon = user.is_anonymous() <TAB> for backend in auth.get_backends(): <MASK> if hasattr(backend, ""has_perm""): <TAB>  <TAB>  <TAB>  <TAB> if obj is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if backend.supports_object_permissions and backend.has_perm( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> user, perm, obj <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if backend.has_perm(user, perm): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if not anon or backend . supports_anonymous_user :,163
"def visit(self, node=None): <TAB> """"""Walks over a node.  If no node is provided, the tree is used."""""" <TAB> if node is None: <TAB>  <TAB> node = self.tree <TAB> if node is None: <TAB>  <TAB> raise RuntimeError(""no node or tree given!"") <TAB> for clsname in map(_lowername, type.mro(node.__class__)): <TAB>  <TAB> meth = getattr(self, ""visit_"" + clsname, None) <MASK> rtn = meth(node) <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> msg = ""could not find valid visitor method for {0} on {1}"" <TAB>  <TAB> nodename = node.__class__.__name__ <TAB>  <TAB> selfname = self.__class__.__name__ <TAB>  <TAB> raise AttributeError(msg.format(nodename, selfname)) <TAB> return rtn",if callable ( meth ) :,194
"def add_fade_out(compositor, fade_out_length): <TAB> clip = _get_compositor_clip(compositor) <TAB> keyframe_property, property_klass, keyframes = _get_kfproperty_klass_and_keyframes( <TAB>  <TAB> compositor, clip <TAB> ) <TAB> if fade_out_length > 0: <MASK> return _do_user_add_fade_out( <TAB>  <TAB>  <TAB>  <TAB> keyframe_property, property_klass, keyframes, fade_out_length, clip <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _show_length_error_dialog() <TAB>  <TAB>  <TAB> return None",if fade_out_length + 1 <= clip . clip_length ( ) :,167
"def make_timesheet_records(): <TAB> employees = get_timesheet_based_salary_slip_employee() <TAB> for e in employees: <TAB>  <TAB> ts = make_timesheet( <TAB>  <TAB>  <TAB> e.employee, <TAB>  <TAB>  <TAB> simulate=True, <TAB>  <TAB>  <TAB> billable=1, <TAB>  <TAB>  <TAB> activity_type=get_random(""Activity Type""), <TAB>  <TAB>  <TAB> company=frappe.flags.company, <TAB>  <TAB> ) <TAB>  <TAB> frappe.db.commit() <TAB>  <TAB> rand = random.random() <TAB>  <TAB> if rand >= 0.3: <TAB>  <TAB>  <TAB> make_salary_slip_for_timesheet(ts.name) <TAB>  <TAB> rand = random.random() <MASK> make_sales_invoice_for_timesheet(ts.name)",if rand >= 0.2 :,197
"def _target_from_batch(self, batch): <TAB> targets = [] <TAB> for name in self.labels: <TAB>  <TAB> target = getattr(batch, name) <MASK> label_vocab = self.metadata.target.vocab.stoi <TAB>  <TAB>  <TAB> batch_label_list = getattr(batch, Target.TARGET_LABEL_FIELD) <TAB>  <TAB>  <TAB> target = align_target_labels(target, batch_label_list, label_vocab) <TAB>  <TAB> targets.append(target) <TAB> if len(targets) == 1: <TAB>  <TAB> return targets[0] <TAB> return tuple(targets)","if name in [ Target . TARGET_PROB_FIELD , Target . TARGET_LOGITS_FIELD ] :",161
"def detectForms(html): <TAB> erreur = """" <TAB> soup = BeautifulSoup(html, ""html.parser"") <TAB> detectedForms = soup.find_all(""form"") <TAB> returnForms = [] <TAB> if len(detectedForms) > 0: <TAB>  <TAB> for f in detectedForms: <TAB>  <TAB>  <TAB> fileInputs = f.findChildren(""input"", {""type"": re.compile(""file"", re.I)}) <MASK> returnForms.append((f, fileInputs)) <TAB> return returnForms",if len ( fileInputs ) > 0 :,136
"def _updateNewCardRatio(self): <TAB> if self.col.conf[""newSpread""] == NEW_CARDS_DISTRIBUTE: <MASK> self.newCardModulus = (self.newCount + self.revCount) // self.newCount <TAB>  <TAB>  <TAB> # if there are cards to review, ensure modulo >= 2 <TAB>  <TAB>  <TAB> if self.revCount: <TAB>  <TAB>  <TAB>  <TAB> self.newCardModulus = max(2, self.newCardModulus) <TAB>  <TAB>  <TAB> return <TAB> self.newCardModulus = 0",if self . newCount :,128
"def __prep_write_total(self, comments, main, fallback, single): <TAB> lower = self.as_lowercased() <TAB> for k in [main, fallback, single]: <MASK> del comments[k] <TAB> if single in lower: <TAB>  <TAB> parts = lower[single].split(""/"", 1) <TAB>  <TAB> if parts[0]: <TAB>  <TAB>  <TAB> comments[single] = [parts[0]] <TAB>  <TAB> if len(parts) > 1: <TAB>  <TAB>  <TAB> comments[main] = [parts[1]] <TAB> if main in lower: <TAB>  <TAB> comments[main] = lower.list(main) <TAB> if fallback in lower: <TAB>  <TAB> if main in comments: <TAB>  <TAB>  <TAB> comments[fallback] = lower.list(fallback) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> comments[main] = lower.list(fallback)",if k in comments :,196
"def check_physical(self, line): <TAB> """"""Run all physical checks on a raw input line."""""" <TAB> self.physical_line = line <TAB> for name, check, argument_names in self._physical_checks: <TAB>  <TAB> self.init_checker_state(name, argument_names) <TAB>  <TAB> result = self.run_check(check, argument_names) <TAB>  <TAB> if result is not None: <TAB>  <TAB>  <TAB> (offset, text) = result <TAB>  <TAB>  <TAB> self.report_error(self.line_number, offset, text, check) <MASK> self.indent_char = line[0]","if text [ : 4 ] == ""E101"" :",154
"def dependencies(self): <TAB> deps = [] <TAB> midx = None <TAB> if self.ref is not None: <TAB>  <TAB> query = GroupQuery(self.ref) <TAB>  <TAB> g = query.execute(self.schema) <MASK> log.debug(self.schema) <TAB>  <TAB>  <TAB> raise TypeNotFound(self.ref) <TAB>  <TAB> deps.append(g) <TAB>  <TAB> midx = 0 <TAB> return (midx, deps)",if g is None :,109
"def __init__(self, metadata=None): <MASK> db = get_session() <TAB>  <TAB> metadata = lookup_feed(db, self.__feed_name__) <TAB>  <TAB> if not metadata: <TAB>  <TAB>  <TAB> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> ""Must have feed metadata in db already, should sync metadata before invoking instance operations"" <TAB>  <TAB>  <TAB> ) <TAB> super(AnchoreServiceFeed, self).__init__(metadata=metadata)",if not metadata :,102
"def testGetPartRect(self): <TAB> ""Make sure the part rectangles are retrieved correctly"" <TAB> for i in range(0, self.ctrl.part_count()): <TAB>  <TAB> part_rect = self.ctrl.get_part_rect(i) <TAB>  <TAB> self.assertEqual(part_rect.left, self.part_rects[i].left) <MASK> self.assertEqual(part_rect.right, self.part_rects[i].right) <TAB>  <TAB> self.assertEqual(part_rect.top, self.part_rects[i].top) <TAB>  <TAB> self.assertFalse(abs(part_rect.bottom - self.part_rects[i].bottom) > 2) <TAB> self.assertRaises(IndexError, self.ctrl.get_part_rect, 99)",if i != self . ctrl . part_count ( ) - 1 :,197
"def __call__(self, ctx): <TAB> if ctx.range and ctx.value: <TAB>  <TAB> if self.raw: <TAB>  <TAB>  <TAB> ctx.range.raw_value = ctx.value <TAB>  <TAB>  <TAB> return <TAB>  <TAB> scalar = ctx.meta.get(""scalar"", False) <MASK> ctx.range = ctx.range.resize(len(ctx.value), len(ctx.value[0])) <TAB>  <TAB> self._write_value(ctx.range, ctx.value, scalar)",if not scalar :,117
"def basic_get(self, queue, no_ack=False, **kwargs): <TAB> """"""Get message by direct access (synchronous)."""""" <TAB> try: <TAB>  <TAB> message = self.Message(self._get(queue), channel=self) <MASK> self.qos.append(message, message.delivery_tag) <TAB>  <TAB> return message <TAB> except Empty: <TAB>  <TAB> pass",if not no_ack :,97
"def http_client(cls) -> aiohttp.ClientSession: <TAB> if cls._client is None: <MASK> raise EnvironmentError( <TAB>  <TAB>  <TAB>  <TAB> ""Event loop must be running to start HTTP client session."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> cls._client = aiohttp.ClientSession(request_class=SSLClientRequest) <TAB> return cls._client",if not asyncio . get_event_loop ( ) . is_running ( ) :,97
"def createMimeType(self): <TAB> audio = False <TAB> for prop in self.array(""header/content/stream_prop""): <TAB>  <TAB> guid = prop[""content/type""].value <TAB>  <TAB> if guid == VideoHeader.guid: <TAB>  <TAB>  <TAB> return u""video/x-ms-wmv"" <MASK> audio = True <TAB> if audio: <TAB>  <TAB> return u""audio/x-ms-wma"" <TAB> else: <TAB>  <TAB> return u""video/x-ms-asf""",if guid == AudioHeader . guid :,126
"def _removeCachedRFInfo(self, cache_key, path, removeChildPaths): <TAB> log.debug(""_removeCachedRFInfo: cache_key %r, path %r"", cache_key, path) <TAB> if self._cachedFiles.has_key(cache_key): <TAB>  <TAB> cache = self._cachedFiles[cache_key] <TAB>  <TAB> if cache.has_key(path): <TAB>  <TAB>  <TAB> del cache[path] <TAB>  <TAB> if removeChildPaths: <TAB>  <TAB>  <TAB> # Remove all cached paths that are under this directory <TAB>  <TAB>  <TAB> from remotefilelib import addslash <TAB>  <TAB>  <TAB> dirPath = addslash(path) <TAB>  <TAB>  <TAB> for keypath in cache.keys(): <MASK> del cache[keypath]",if keypath . startswith ( dirPath ) :,178
"def format(self, obj, context, maxlevels, level): <TAB> if isinstance(obj, unicode): <TAB>  <TAB> # return (obj.encode('utf8'), True, False) <TAB>  <TAB> return (obj, True, False) <TAB> if isinstance(obj, bytes): <TAB>  <TAB> convert = False <TAB>  <TAB> # for c in obj: <TAB>  <TAB> # 	if ord(c) >= 128: <TAB>  <TAB> # 		convert = True <TAB>  <TAB> # 		break <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> codecs.decode(obj) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> convert = True <MASK> return (""0x{}"".format(obj), True, False) <TAB> return pprint.PrettyPrinter.format(self, obj, context, maxlevels, level)",if convert :,176
"def add_data_source(self, f=None, s_name=None, source=None, module=None, section=None): <TAB> try: <TAB>  <TAB> if module is None: <TAB>  <TAB>  <TAB> module = self.name <TAB>  <TAB> if section is None: <TAB>  <TAB>  <TAB> section = ""all_sections"" <TAB>  <TAB> if s_name is None: <TAB>  <TAB>  <TAB> s_name = f[""s_name""] <MASK> source = os.path.abspath(os.path.join(f[""root""], f[""fn""])) <TAB>  <TAB> report.data_sources[module][section][s_name] = source <TAB> except AttributeError: <TAB>  <TAB> logger.warning( <TAB>  <TAB>  <TAB> ""Tried to add data source for {}, but was missing fields data"".format( <TAB>  <TAB>  <TAB>  <TAB> self.name <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> )",if source is None :,198
"def open(self, *args, **kwargs): <TAB> if kwargs.get(""json"") is not None: <TAB>  <TAB> with self.session_transaction() as sess: <TAB>  <TAB>  <TAB> api_key_headers = Headers({""CSRF-Token"": sess.get(""nonce"")}) <TAB>  <TAB>  <TAB> headers = kwargs.pop(""headers"", Headers()) <MASK> headers = Headers(headers) <TAB>  <TAB>  <TAB> headers.extend(api_key_headers) <TAB>  <TAB>  <TAB> kwargs[""headers""] = headers <TAB> return super(CTFdTestClient, self).open(*args, **kwargs)","if isinstance ( headers , dict ) :",141
"def get_params(self): <TAB> if not hasattr(self, ""input_space""): <TAB>  <TAB> raise AttributeError(""Input space has not been provided."") <TAB> rval = [] <TAB> for layer in self.layers: <TAB>  <TAB> for param in layer.get_params(): <MASK> logger.info(type(layer)) <TAB>  <TAB> layer_params = layer.get_params() <TAB>  <TAB> assert not isinstance(layer_params, set) <TAB>  <TAB> for param in layer_params: <TAB>  <TAB>  <TAB> if param not in rval: <TAB>  <TAB>  <TAB>  <TAB> rval.append(param) <TAB> rval = [elem for elem in rval if elem not in self.freeze_set] <TAB> assert all([elem.name is not None for elem in rval]) <TAB> return rval",if param . name is None :,181
"def _animate_strategy(self, speed=1): <TAB> if self._animating == 0: <TAB>  <TAB> return <TAB> if self._apply_strategy() is not None: <MASK> return <TAB>  <TAB> if self._animate.get() == 1: <TAB>  <TAB>  <TAB> self._root.after(3000, self._animate_strategy) <TAB>  <TAB> elif self._animate.get() == 2: <TAB>  <TAB>  <TAB> self._root.after(1000, self._animate_strategy) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._root.after(20, self._animate_strategy)",if self . _animate . get ( ) == 0 or self . _step . get ( ) == 1 :,151
"def charAt(pos): <TAB> this.cok() <TAB> pos = pos.to_int() <TAB> s = this.to_string() <TAB> if 0 <= pos < len(s.value): <TAB>  <TAB> char = s.value[pos] <MASK> s.Js(char)  # add char to char bank <TAB>  <TAB> return s.CHAR_BANK[char] <TAB> return s.CHAR_BANK[""""]",if char not in s . CHAR_BANK :,116
"def find_executable(names): <TAB> # Given a list of executable names, find the first one that is available <TAB> # as an executable file, on the path. <TAB> for name in names: <TAB>  <TAB> fpath, fname = os.path.split(name) <TAB>  <TAB> if fpath: <TAB>  <TAB>  <TAB> # The given name is absolute. <TAB>  <TAB>  <TAB> if is_executable(name): <TAB>  <TAB>  <TAB>  <TAB> return name <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Try to find the name on the PATH <TAB>  <TAB>  <TAB> for path in os.environ[""PATH""].split(os.pathsep): <TAB>  <TAB>  <TAB>  <TAB> exe_file = os.path.join(path, name) <MASK> return exe_file <TAB> # Could not find it :( <TAB> return None",if is_executable ( exe_file ) :,186
"def match_file(self, file, tff_format): <TAB> match = tff_format.search(file.filename.replace(""\\"", ""/"")) <TAB> if match: <TAB>  <TAB> result = {} <TAB>  <TAB> for name, value in match.groupdict().items(): <TAB>  <TAB>  <TAB> value = value.strip() <MASK> value = value.lstrip(""0"") <TAB>  <TAB>  <TAB> if self.ui.replace_underscores.isChecked(): <TAB>  <TAB>  <TAB>  <TAB> value = value.replace(""_"", "" "") <TAB>  <TAB>  <TAB> result[name] = value <TAB>  <TAB> return result <TAB> else: <TAB>  <TAB> return {}",if name in self . numeric_tags :,149
"def __init__( <TAB> self, <TAB> filename: str = ""checkpoint"", <TAB> frequency: Union[int, List[int]] = 1, <TAB> on: Union[str, List[str]] = ""epoch_end"",): <TAB> if isinstance(frequency, list): <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""If you pass a list for checkpoint frequencies, the `on` "" <TAB>  <TAB>  <TAB>  <TAB> ""parameter has to be a list with the same length."" <TAB>  <TAB>  <TAB> ) <TAB> self._frequency = frequency <TAB> super(_TuneCheckpointCallback, self).__init__(on) <TAB> self._filename = filename <TAB> self._counter = Counter() <TAB> self._cp_count = 0  # Has to be monotonically increasing","if not isinstance ( on , list ) or len ( frequency ) != len ( on ) :",185
"def download(cls, architecture, path=""./""): <TAB> if cls.sanity_check(architecture): <TAB>  <TAB> architecture_file = path + ""imagenet_{}.pth"".format(architecture) <TAB>  <TAB> if not os.path.exists(architecture_file): <TAB>  <TAB>  <TAB> kwargs = {} <MASK> kwargs[""transform_input""] = False <TAB>  <TAB>  <TAB> model = models.__dict__[architecture](pretrained=True, **kwargs) <TAB>  <TAB>  <TAB> torch.save(model, architecture_file) <TAB>  <TAB>  <TAB> print( <TAB>  <TAB>  <TAB>  <TAB> ""PyTorch pretrained model is saved as [{}]."".format(architecture_file) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""File [{}] existed!"".format(architecture_file)) <TAB>  <TAB> return architecture_file <TAB> else: <TAB>  <TAB> return None","if architecture == ""inception_v3"" :",198
"def __exit__(self, exc_type, exc_value, traceback): <TAB> self.signal.disconnect(self._listener) <TAB> if not self.signal_sent: <TAB>  <TAB> self.test_case.fail(""Signal was not sent."") <TAB>  <TAB> return <TAB> if self.required_kwargs is not None: <TAB>  <TAB> missing_kwargs = [] <TAB>  <TAB> for k in self.required_kwargs: <MASK> missing_kwargs.append(k) <TAB>  <TAB> if missing_kwargs: <TAB>  <TAB>  <TAB> self.test_case.fail( <TAB>  <TAB>  <TAB>  <TAB> ""Signal missing required arguments: "" ""%s"" % "","".join(missing_kwargs) <TAB>  <TAB>  <TAB> )",if k not in self . received_kwargs :,166
"def Assign(left, right): <TAB> names = [] <TAB> if isinstance(left, ast.Name): <TAB>  <TAB> # Single assignment on left <TAB>  <TAB> return ast.Assign([ast.AssName(left.name, ""OP_ASSIGN"")], right) <TAB> elif isinstance(left, ast.Tuple): <TAB>  <TAB> # List of things - make sure they are Name nodes <TAB>  <TAB> names = [] <TAB>  <TAB> for child in left.getChildren(): <MASK> raise SyntaxError(""that assignment not supported"") <TAB>  <TAB>  <TAB> names.append(child.name) <TAB>  <TAB> ass_list = [ast.AssName(name, ""OP_ASSIGN"") for name in names] <TAB>  <TAB> return ast.Assign([ast.AssTuple(ass_list)], right) <TAB> else: <TAB>  <TAB> raise SyntaxError(""Can't do that yet"")","if not isinstance ( child , ast . Name ) :",197
"def readVorbisComment(metadata, comment): <TAB> metadata.producer = getValue(comment, ""vendor"") <TAB> for item in comment.array(""metadata""): <MASK> key, value = item.value.split(""="", 1) <TAB>  <TAB>  <TAB> key = key.upper() <TAB>  <TAB>  <TAB> if key in VORBIS_KEY_TO_ATTR: <TAB>  <TAB>  <TAB>  <TAB> key = VORBIS_KEY_TO_ATTR[key] <TAB>  <TAB>  <TAB>  <TAB> setattr(metadata, key, value) <TAB>  <TAB>  <TAB> elif value: <TAB>  <TAB>  <TAB>  <TAB> metadata.warning(""Skip Vorbis comment %s: %s"" % (key, value))","if ""="" in item . value :",157
"def _read_readable(self, readable): <TAB> blocksize = 8192 <TAB> if self.debuglevel > 0: <TAB>  <TAB> print(""sendIng a read()able"") <TAB> encode = self._is_textIO(readable) <TAB> if encode and self.debuglevel > 0: <TAB>  <TAB> print(""encoding file using iso-8859-1"") <TAB> while True: <TAB>  <TAB> datablock = readable.read(blocksize) <TAB>  <TAB> if not datablock: <TAB>  <TAB>  <TAB> break <MASK> datablock = datablock.encode(""iso-8859-1"") <TAB>  <TAB> yield datablock",if encode :,139
"def TryMerge(self, d): <TAB> while 1: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 12: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if tt == 18: <TAB>  <TAB>  <TAB> self.set_value(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> self.set_flags(d.get32()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 29 :,126
"def needs_rebuild(self): <TAB> for ratio in self.sprite.config[""ratios""]: <TAB>  <TAB> cocos2d_path = self.output_path(ratio) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> data = plistlib.readPlist(cocos2d_path) <TAB>  <TAB>  <TAB>  <TAB> assert data[self.meta_key][""hash""] == self.sprite.hash <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> return True <TAB> return False",if os . path . exists ( cocos2d_path ) :,125
"def on_epoch_end(self, batch, logs=None): <TAB> # At the end of every epoch, remask the weights. This ensures that when <TAB> # the model is saved after completion, the weights represent mask*weights. <TAB> weight_mask_ops = [] <TAB> for layer in self.prunable_layers: <TAB>  <TAB> if isinstance(layer, pruning_wrapper.PruneLowMagnitude): <MASK> layer.pruning_obj.weight_mask_op() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> weight_mask_ops.append(layer.pruning_obj.weight_mask_op()) <TAB> K.batch_get_value(weight_mask_ops)",if tf . executing_eagerly ( ) :,166
"def buildQueryRE(queryText, caseSensitive, wholeWord): <TAB> ""returns a RegEx pattern for searching for the given queryText"" <TAB> # word detection etc. cannot be done on an encoding-less string: <TAB> assert type(queryText) == unicode <TAB> pattern = re.escape(queryText) <TAB> if wholeWord: <TAB>  <TAB> if re.search(""^\w"", queryText, re.UNICODE): <TAB>  <TAB>  <TAB> pattern = ""\\b"" + pattern <MASK> pattern = pattern + ""\\b"" <TAB> flags = re.UNICODE <TAB> if not (caseSensitive): <TAB>  <TAB> flags |= re.IGNORECASE <TAB> return re.compile(pattern, flags)","if re . search ( ""\w$"" , queryText , re . UNICODE ) :",166
"def is_valid_origin(origin): <TAB> if not settings.SENTRY_ALLOW_ORIGIN: <TAB>  <TAB> return False <TAB> if settings.SENTRY_ALLOW_ORIGIN == ""*"": <TAB>  <TAB> return True <TAB> if not origin: <TAB>  <TAB> return False <TAB> origin = origin.lower() <TAB> for value in settings.SENTRY_ALLOW_ORIGIN: <TAB>  <TAB> if isinstance(value, string_types): <TAB>  <TAB>  <TAB> if value.lower() == origin: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <MASK> return True <TAB> return False",if value . match ( origin ) :,137
"def get_menu_title(self): <TAB> handle = self.obj.get_handle() <TAB> if handle: <TAB>  <TAB> who = get_participant_from_event(self.db, handle) <TAB>  <TAB> desc = self.obj.get_description() <TAB>  <TAB> event_name = self.obj.get_type() <TAB>  <TAB> if desc: <TAB>  <TAB>  <TAB> event_name = ""%s - %s"" % (event_name, desc) <MASK> event_name = ""%s - %s"" % (event_name, who) <TAB>  <TAB> dialog_title = _(""Event: %s"") % event_name <TAB> else: <TAB>  <TAB> dialog_title = _(""New Event"") <TAB> return dialog_title",if who :,168
def memory(self): <MASK> self.lazy_init_lock_.acquire() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if self.memory_ is None: <TAB>  <TAB>  <TAB>  <TAB> self.memory_ = SystemStat() <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self.lazy_init_lock_.release() <TAB> return self.memory_,if self . memory_ is None :,85
"def __str__(self): <TAB> fmt = ""%#x"" if isinstance(self.target, six.integer_types) else ""%r"" <TAB> args = [] <TAB> for arg in self.args: <TAB>  <TAB> args.append(self._special_repr(arg)) <TAB> name = self.name or (fmt % self.target) <TAB> arg_str = [] <TAB> for arg in args: <MASK> arg_str.append(hex(arg)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> arg_str.append(str(arg)) <TAB> return ""%s(%s)"" % (name, "", "".join(arg_str))","if isinstance ( arg , six . integer_types ) and arg > 0x100 :",164
"def change_password(username=""flexget"", password="""", session=None): <TAB> check = zxcvbn.zxcvbn(password, user_inputs=[username]) <TAB> if check[""score""] < 3: <TAB>  <TAB> warning = check[""feedback""][""warning""] <TAB>  <TAB> suggestions = "" "".join(check[""feedback""][""suggestions""]) <TAB>  <TAB> message = ""Password '{}' is not strong enough. "".format(password) <TAB>  <TAB> if warning: <TAB>  <TAB>  <TAB> message += warning + "" "" <MASK> message += ""Suggestions: {}"".format(suggestions) <TAB>  <TAB> raise WeakPassword(message) <TAB> user = get_user(username=username, session=session) <TAB> user.password = str(generate_password_hash(password)) <TAB> session.commit()",if suggestions :,175
"def _on_workflow_object_saved(sender, instance, created, *args, **kwargs): <TAB> for instance_workflow in instance.river.all(instance.__class__): <MASK> instance_workflow.initialize_approvals() <TAB>  <TAB>  <TAB> if not instance_workflow.get_state(): <TAB>  <TAB>  <TAB>  <TAB> init_state = getattr( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> instance.__class__.river, instance_workflow.field_name <TAB>  <TAB>  <TAB>  <TAB> ).initial_state <TAB>  <TAB>  <TAB>  <TAB> instance_workflow.set_state(init_state) <TAB>  <TAB>  <TAB>  <TAB> instance.save()",if created :,139
"def recvmsg_into(self, buffers, *args): <TAB> while True: <TAB>  <TAB> try: <MASK> # The C code is sensitive about whether extra arguments are <TAB>  <TAB>  <TAB>  <TAB> # passed or not. <TAB>  <TAB>  <TAB>  <TAB> return self._sock.recvmsg_into(buffers, *args) <TAB>  <TAB>  <TAB> return self._sock.recvmsg_into(buffers) <TAB>  <TAB> except error as ex: <TAB>  <TAB>  <TAB> if ex.args[0] != EWOULDBLOCK or self.timeout == 0.0: <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> self._wait(self._read_event)",if args :,146
def _generate_toc(line): <TAB> while 1: <MASK> line = 5 <TAB>  <TAB>  <TAB> while 1: <TAB>  <TAB>  <TAB>  <TAB> if line: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> line = 6 <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB>  <TAB> elif not line: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> line = 7 <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif not line: <TAB>  <TAB>  <TAB> break <TAB> return 1,"if line . startswith ( ""2"" ) :",103
"def tearDown(self): <TAB> for filename in os.listdir(from_here(""lib"")): <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> os.remove(from_here(""lib"", filename)) <TAB>  <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB>  <TAB> pass  # File may no longer exist.",if filename not in self . files_to_keep :,80
"def parse_literal_object(node): <TAB> value = 0 <TAB> unit = get_default_weight_unit() <TAB> for field in node.fields: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> value = decimal.Decimal(field.value.value) <TAB>  <TAB>  <TAB> except decimal.DecimalException: <TAB>  <TAB>  <TAB>  <TAB> raise GraphQLError(f""Unsupported value: {field.value.value}"") <TAB>  <TAB> if field.name.value == ""unit"": <TAB>  <TAB>  <TAB> unit = field.value.value <TAB> return Weight(**{unit: value})","if field . name . value == ""value"" :",134
"def run(self): <TAB> to_delete = set() <TAB> for k, v in iteritems(self.objs): <TAB>  <TAB> if k.startswith(""_""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if v[""_class""] == ""SubmissionFormatElement"": <TAB>  <TAB>  <TAB> to_delete.add(k) <MASK> v[""submission_format""] = list( <TAB>  <TAB>  <TAB>  <TAB> self.objs[k][""filename""] for k in v.get(""submission_format"", list()) <TAB>  <TAB>  <TAB> ) <TAB> for k in to_delete: <TAB>  <TAB> del self.objs[k] <TAB> return self.objs","if v [ ""_class"" ] == ""Task"" :",147
"def _detect_too_many_digits(f): <TAB> ret = [] <TAB> for node in f.nodes: <TAB>  <TAB> # each node contains a list of IR instruction <TAB>  <TAB> for ir in node.irs: <TAB>  <TAB>  <TAB> # iterate over all the variables read by the IR <TAB>  <TAB>  <TAB> for read in ir.read: <TAB>  <TAB>  <TAB>  <TAB> # if the variable is a constant <MASK> # read.value can return an int or a str. Convert it to str <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value_as_str = read.original_value <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if ""00000"" in value_as_str: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # Info to be printed <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ret.append(node) <TAB> return ret","if isinstance ( read , Constant ) :",183
"def split_path_info(path): <TAB> # suitable for splitting an already-unquoted-already-decoded (unicode) <TAB> # path value <TAB> path = path.strip(""/"") <TAB> clean = [] <TAB> for segment in path.split(""/""): <TAB>  <TAB> if not segment or segment == ""."": <TAB>  <TAB>  <TAB> continue <MASK> if clean: <TAB>  <TAB>  <TAB>  <TAB> del clean[-1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> clean.append(segment) <TAB> return tuple(clean)","elif segment == "".."" :",115
"def callback(f): <TAB> unfinished_children.remove(f) <TAB> if not unfinished_children: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> result_list = [i.result() for i in children] <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> future.set_exc_info(sys.exc_info()) <TAB>  <TAB> else: <MASK> future.set_result(dict(zip(keys, result_list))) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> future.set_result(result_list)",if keys is not None :,128
"def L_op(self, inputs, outputs, gout): <TAB> (x,) = inputs <TAB> (gz,) = gout <TAB> if gz.type in complex_types: <TAB>  <TAB> raise NotImplementedError() <TAB> if outputs[0].type in discrete_types: <MASK> return [x.zeros_like(dtype=theano.config.floatX)] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return [x.zeros_like()] <TAB> return (gz * x * 2,)",if x . type in discrete_types :,117
"def perform_page_up(self, event): <TAB> # if first line is visible then go there <TAB> # (by default it doesn't move then) <TAB> try: <TAB>  <TAB> first_visible_idx = self.index(""@0,0"") <TAB>  <TAB> row, _ = map(int, first_visible_idx.split(""."")) <MASK> self.mark_set(""insert"", ""1.0"") <TAB> except Exception as e: <TAB>  <TAB> logger.exception(""Could not perform page up"", exc_info=e)",if row == 1 :,126
"def __str__(self): <TAB> s = """" <TAB> for k, v in self._members.items(): <MASK> s += k + "" : "" + "";"".join(getattr(self, item)) + ""\n"" <TAB>  <TAB> elif isinstance(v.get(""type""), str): <TAB>  <TAB>  <TAB> s += k + "" : "" + getattr(self, k) + ""\n"" <TAB> return s","if isinstance ( v . get ( ""type"" ) , list ) :",104
"def _shared_pool(**opts): <TAB> if ""host"" in opts: <TAB>  <TAB> key = ""%s:%s/%s"" % ( <TAB>  <TAB>  <TAB> opts[""host""], <TAB>  <TAB>  <TAB> opts[""port""], <TAB>  <TAB>  <TAB> opts[""db""], <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> key = ""%s/%s"" % (opts[""path""], opts[""db""]) <TAB> pool = _pool_cache.get(key) <MASK> return pool <TAB> with _pool_lock: <TAB>  <TAB> pool = _pool_cache.get(key) <TAB>  <TAB> if pool is not None: <TAB>  <TAB>  <TAB> return pool <TAB>  <TAB> pool = ConnectionPool(**opts) <TAB>  <TAB> _pool_cache[key] = pool <TAB>  <TAB> return pool",if pool is not None :,174
"def _override_settings(self, overriden_settings: dict): <TAB> for setting_name, setting_value in overriden_settings.items(): <TAB>  <TAB> value = setting_value <MASK> value = getattr(self, setting_name, {}) <TAB>  <TAB>  <TAB> value.update(ObjDict(setting_value)) <TAB>  <TAB> setattr(self, setting_name, value)","if isinstance ( setting_value , dict ) :",99
"def match_tls_context(self, host: str, ir: ""IR""): <TAB> for context in ir.get_tls_contexts(): <TAB>  <TAB> hosts = context.get(""hosts"") or [] <TAB>  <TAB> for context_host in hosts: <MASK> ir.logger.debug( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Matched host {} with TLSContext {}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> host, context.get(""name"") <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> self.sni = True <TAB>  <TAB>  <TAB>  <TAB> return context <TAB> return None",if context_host == host :,144
"def get_form_datas(self): <TAB> # Prepare the dict of initial data from the request. <TAB> # We have to special-case M2Ms as a list of comma-separated PKs. <TAB> if self.request_method == ""get"": <TAB>  <TAB> initial = dict(self.request.GET.items()) <TAB>  <TAB> for k in initial: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> f = self.opts.get_field(k) <TAB>  <TAB>  <TAB> except models.FieldDoesNotExist: <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> initial[k] = initial[k].split("","") <TAB>  <TAB> return {""initial"": initial} <TAB> else: <TAB>  <TAB> return {""data"": self.request.POST, ""files"": self.request.FILES}","if isinstance ( f , models . ManyToManyField ) :",182
"def run_until(loop, pred, timeout=30): <TAB> deadline = time.time() + timeout <TAB> while not pred(): <MASK> timeout = deadline - time.time() <TAB>  <TAB>  <TAB> if timeout <= 0: <TAB>  <TAB>  <TAB>  <TAB> raise futures.TimeoutError() <TAB>  <TAB> loop.run_until_complete(tasks.sleep(0.001, loop=loop))",if timeout is not None :,94
"def update_translations(): <TAB> pot_path = os.path.join(root, ""messages.pot"") <TAB> template = read_po(open(pot_path, ""rb"")) <TAB> for locale in get_locales(): <TAB>  <TAB> po_path = os.path.join(root, locale, ""messages.po"") <TAB>  <TAB> mo_path = os.path.join(root, locale, ""messages.mo"") <MASK> catalog = read_po(open(po_path, ""rb"")) <TAB>  <TAB>  <TAB> catalog.update(template) <TAB>  <TAB>  <TAB> f = open(po_path, ""wb"") <TAB>  <TAB>  <TAB> write_po(f, catalog) <TAB>  <TAB>  <TAB> f.close() <TAB>  <TAB>  <TAB> print(""updated"", po_path) <TAB> compile_translations()",if os . path . exists ( po_path ) :,191
"def get_queryset_for_content_type(self, content_type_id): <TAB> """"""Return the QuerySet from the QuerySetSequence for a ctype."""""" <TAB> content_type = ContentType.objects.get_for_id(content_type_id) <TAB> for queryset in self.queryset.get_querysets(): <MASK> # django-queryset-sequence 0.7 support dynamically created <TAB>  <TAB>  <TAB> # QuerySequenceModel which replaces the original model when it <TAB>  <TAB>  <TAB> # patches the queryset since 6394e19 <TAB>  <TAB>  <TAB> model = queryset.model.__bases__[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> model = queryset.model <TAB>  <TAB> if model == content_type.model_class(): <TAB>  <TAB>  <TAB> return queryset","if queryset . model . __name__ == ""QuerySequenceModel"" :",177
"def __bypass_wizard(self): <TAB> bypass = False <TAB> if self.device.remote_op.dir_exist(self.project_folder): <TAB>  <TAB> msg = ""A Tweak with the same PROJECT_NAME ({}) already exists. Do you want to delete it and start from scratch?"".format( <TAB>  <TAB>  <TAB> self.options[""project_name""] <TAB>  <TAB> ) <TAB>  <TAB> clean = choose_boolean(msg) <MASK> self.device.remote_op.dir_delete(self.project_folder) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> bypass = True <TAB> return bypass",if clean :,137
"def wrapper(cached=True, reset=False): <TAB> nonlocal cached_venv_dir <TAB> if not cached or not cached_venv_dir or reset: <TAB>  <TAB> venv_dir = os.environ.get(""_VENV_DIR_"") or load_settings(lazy=True).get( <TAB>  <TAB>  <TAB> ""venv_dir"" <TAB>  <TAB> ) <TAB>  <TAB> if venv_dir:  # no cov <TAB>  <TAB>  <TAB> if venv_dir == ""isolated"": <TAB>  <TAB>  <TAB>  <TAB> venv_dir = VENV_DIR_ISOLATED <MASK> venv_dir = VENV_DIR_SHARED <TAB>  <TAB> else:  # no cov <TAB>  <TAB>  <TAB> venv_dir = VENV_DIR_SHARED <TAB>  <TAB> cached_venv_dir = venv_dir <TAB> return cached_venv_dir","elif venv_dir == ""shared"" :",186
"def run(self): <TAB> while not self._stop: <TAB>  <TAB> for i in range(0, self._interval): <TAB>  <TAB>  <TAB> time.sleep(1) <MASK> self.__logger.debug(""%s - ping thread stopped"" % self.name) <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> ping = PingIqProtocolEntity() <TAB>  <TAB> self._layer.waitPong(ping.getId()) <TAB>  <TAB> if not self._stop: <TAB>  <TAB>  <TAB> self._layer.sendIq(ping)",if self . _stop :,126
"def install(self, unicode=False, names=None): <TAB> import __builtin__ <TAB> __builtin__.__dict__[""_""] = unicode and self.ugettext or self.gettext <TAB> if hasattr(names, ""__contains__""): <TAB>  <TAB> if ""gettext"" in names: <TAB>  <TAB>  <TAB> __builtin__.__dict__[""gettext""] = __builtin__.__dict__[""_""] <MASK> __builtin__.__dict__[""ngettext""] = ( <TAB>  <TAB>  <TAB>  <TAB> unicode and self.ungettext or self.ngettext <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if ""lgettext"" in names: <TAB>  <TAB>  <TAB> __builtin__.__dict__[""lgettext""] = self.lgettext <TAB>  <TAB> if ""lngettext"" in names: <TAB>  <TAB>  <TAB> __builtin__.__dict__[""lngettext""] = self.lngettext","if ""ngettext"" in names :",181
"def on_task_output(self, task, config): <TAB> for entry in task.entries: <TAB>  <TAB> if ""torrent"" in entry: <MASK> # re-write data into a file <TAB>  <TAB>  <TAB>  <TAB> log.debug(""Writing modified torrent file for %s"" % entry[""title""]) <TAB>  <TAB>  <TAB>  <TAB> with open(entry[""file""], ""wb+"") as f: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f.write(entry[""torrent""].encode())","if entry [ ""torrent"" ] . modified :",115
"def batchSites(self, sites): <TAB> i = 0 <TAB> res = list() <TAB> siteList = list() <TAB> for site in sites: <MASK> data = self.threadSites(siteList) <TAB>  <TAB>  <TAB> if data is None: <TAB>  <TAB>  <TAB>  <TAB> return res <TAB>  <TAB>  <TAB> for ret in list(data.keys()): <TAB>  <TAB>  <TAB>  <TAB> if data[ret]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # bucket:filecount <TAB>  <TAB>  <TAB>  <TAB>  <TAB> res.append(f""{ret}:{data[ret]}"") <TAB>  <TAB>  <TAB> i = 0 <TAB>  <TAB>  <TAB> siteList = list() <TAB>  <TAB> siteList.append(site) <TAB>  <TAB> i += 1 <TAB> return res","if i >= self . opts [ ""_maxthreads"" ] :",168
"def width_pixels(self): <TAB> w = self.style_width <TAB> if self._absolute_size and w == ""auto"": <TAB>  <TAB> w = self._absolute_size.width <TAB> if type(w) is NumberUnit: <TAB>  <TAB> if self._relative_element == self: <TAB>  <TAB>  <TAB> rew = self._parent_size.width if self._parent_size else 0 <TAB>  <TAB> elif self._relative_element is None: <TAB>  <TAB>  <TAB> rew = 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> rew = self._relative_element.width_pixels <MASK> rew = 0 <TAB>  <TAB> w = w.val(base=rew) <TAB> return w","if rew == ""auto"" :",160
"def get_lang3(lang): <TAB> try: <MASK> ret_value = get(part1=lang).part3 <TAB>  <TAB> elif len(lang) == 3: <TAB>  <TAB>  <TAB> ret_value = lang <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret_value = """" <TAB> except KeyError: <TAB>  <TAB> ret_value = lang <TAB> return ret_value",if len ( lang ) == 2 :,94
"def update_timer(): <TAB> global _timer <TAB> if (time.time() - os.stat(config.TRAILS_FILE).st_mtime) >= config.UPDATE_PERIOD: <TAB>  <TAB> _ = None <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> _ = load_trails(True) <MASK> trails.clear() <TAB>  <TAB>  <TAB>  <TAB> trails.update(_) <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> time.sleep(LOAD_TRAILS_RETRY_SLEEP_TIME) <TAB> _timer = threading.Timer(config.UPDATE_PERIOD, update_timer) <TAB> _timer.start()",if _ :,149
"def __call__(self, model): <TAB> if hasattr(model, ""module""): <TAB>  <TAB> model = model.module <TAB> conv1_lr_mult = self.paramwise_cfg.get(""conv1_lr_mult"", 1.0) <TAB> params = [] <TAB> for name, param in model.named_parameters(): <TAB>  <TAB> param_group = {""params"": [param]} <MASK> param_group[""lr""] = self.base_lr * conv1_lr_mult <TAB>  <TAB> params.append(param_group) <TAB> optimizer_cfg[""params""] = params <TAB> return build_from_cfg(optimizer_cfg, OPTIMIZERS)","if name . startswith ( ""conv1"" ) and param . requires_grad :",167
"def _get_conf(self): <TAB> conf = {}  # the configuration once all conf files are merged <TAB> for path in map(Path, self.template_paths): <TAB>  <TAB> conf_path = path / ""conf.json"" <MASK> with conf_path.open() as f: <TAB>  <TAB>  <TAB>  <TAB> conf = recursive_update(conf, json.load(f)) <TAB> return conf",if conf_path . exists ( ) :,100
"def _base_keywords(self, fw_version=False, image=False): <TAB> keywords = dict() <TAB> if image: <TAB>  <TAB> keywords[""image_uri""] = ""'my:image'"" <TAB> if fw_version: <TAB>  <TAB> keywords[""framework_version""] = ( <TAB>  <TAB>  <TAB> ""fw_version"" <MASK> else ""'{}'"".format(self.framework_version) <TAB>  <TAB> ) <TAB> return keywords","if fw_version == ""named""",110
"def check_grads(grads_and_vars): <TAB> has_nan_ops = [] <TAB> amax_ops = [] <TAB> for grad, _ in grads_and_vars: <TAB>  <TAB> if grad is not None: <MASK> x = grad.values <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> x = grad <TAB>  <TAB>  <TAB> has_nan_ops.append(tf.reduce_any(tf.is_nan(x))) <TAB>  <TAB>  <TAB> amax_ops.append(tf.reduce_max(tf.abs(x))) <TAB> has_nan = tf.reduce_any(has_nan_ops) <TAB> amax = tf.reduce_max(amax_ops) <TAB> return has_nan, amax","if isinstance ( grad , tf . IndexedSlices ) :",179
"def new_org(type=ORG_DEFAULT, block=True, **kwargs): <TAB> if type == ORG_DEFAULT: <TAB>  <TAB> org = reserve_pooled(type=type, **kwargs) <TAB>  <TAB> if not org: <TAB>  <TAB>  <TAB> org = queue.reserve(""queued_org"", block=block, type=type, **kwargs) <MASK> new_pooled() <TAB>  <TAB>  <TAB> return org <TAB>  <TAB> org = Organization(type=type, **kwargs) <TAB>  <TAB> org.initialize() <TAB>  <TAB> org.commit() <TAB>  <TAB> return org <TAB> else: <TAB>  <TAB> org = Organization(type=type, **kwargs) <TAB>  <TAB> org.queue_initialize(block=block) <TAB>  <TAB> return org",if org :,171
"def _consumer_healthy(self): <TAB> abnormal_num = 0 <TAB> for w in self._consumers: <MASK> abnormal_num += 1 <TAB>  <TAB>  <TAB> if self._use_process: <TAB>  <TAB>  <TAB>  <TAB> errmsg = ""consumer[{}] exit abnormally with exitcode[{}]"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> w.pid, w.exitcode <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> errmsg = ""consumer[{}] exit abnormally"".format(w.ident) <TAB>  <TAB>  <TAB> logger.warn(errmsg) <TAB> if abnormal_num > 0: <TAB>  <TAB> logger.warn(""{} consumers have exited abnormally!!!"".format(abnormal_num)) <TAB> return abnormal_num == 0",if not w . is_alive ( ) and w . id not in self . _consumer_endsig :,186
"def add_data_source(self, f=None, s_name=None, source=None, module=None, section=None): <TAB> try: <MASK> module = self.name <TAB>  <TAB> if section is None: <TAB>  <TAB>  <TAB> section = ""all_sections"" <TAB>  <TAB> if s_name is None: <TAB>  <TAB>  <TAB> s_name = f[""s_name""] <TAB>  <TAB> if source is None: <TAB>  <TAB>  <TAB> source = os.path.abspath(os.path.join(f[""root""], f[""fn""])) <TAB>  <TAB> report.data_sources[module][section][s_name] = source <TAB> except AttributeError: <TAB>  <TAB> logger.warning( <TAB>  <TAB>  <TAB> ""Tried to add data source for {}, but was missing fields data"".format( <TAB>  <TAB>  <TAB>  <TAB> self.name <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> )",if module is None :,198
"def startTest(self, test): <TAB> unittest.TestResult.startTest(self, test) <TAB> current_case = test.test.__class__.__name__ <TAB> if self.showAll: <MASK> self.stream.writeln(current_case) <TAB>  <TAB>  <TAB> self._last_case = current_case <TAB>  <TAB> self.stream.write("" <TAB> %s"" % str(test.test._testMethodName).ljust(60)) <TAB>  <TAB> self.stream.flush()",if current_case != self . _last_case :,123
"def _calc_freq(item): <TAB> try: <MASK> ao = sum([int(x) for x in item.split("":"")[ao_index].split("","")]) <TAB>  <TAB>  <TAB> ro = int(item.split("":"")[ro_index]) <TAB>  <TAB>  <TAB> freq = ao / float(ao + ro) <TAB>  <TAB> elif af_index is not None: <TAB>  <TAB>  <TAB> freq = float(item.split("":"")[af_index]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> freq = 0.0 <TAB> except (IndexError, ValueError, ZeroDivisionError): <TAB>  <TAB> freq = 0.0 <TAB> return freq",if ao_index is not None and ro_index is not None :,151
"def contains_version(self, version): <TAB> """"""Returns True if version is contained in this range."""""" <TAB> if len(self.bounds) < 5: <TAB>  <TAB> # not worth overhead of binary search <TAB>  <TAB> for bound in self.bounds: <TAB>  <TAB>  <TAB> i = bound.version_containment(version) <MASK> return True <TAB>  <TAB>  <TAB> if i == -1: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> else: <TAB>  <TAB> _, contains = self._contains_version(version) <TAB>  <TAB> return contains <TAB> return False",if i == 0 :,130
"def _codegen_impl(self, state: CodegenState, default_semicolon: bool = False) -> None: <TAB> with state.record_syntactic_position(self): <TAB>  <TAB> state.add_token(""global"") <TAB>  <TAB> self.whitespace_after_global._codegen(state) <TAB>  <TAB> last_name = len(self.names) - 1 <TAB>  <TAB> for i, name in enumerate(self.names): <TAB>  <TAB>  <TAB> name._codegen(state, default_comma=(i != last_name)) <TAB> semicolon = self.semicolon <TAB> if isinstance(semicolon, MaybeSentinel): <MASK> state.add_token(""; "") <TAB> elif isinstance(semicolon, Semicolon): <TAB>  <TAB> semicolon._codegen(state)",if default_semicolon :,184
"def getLatestXci(self, version=None): <TAB> highest = None <TAB> for nsp in self.getFiles(): <TAB>  <TAB> try: <MASK> if version is not None and nsp.version == version: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return nsp <TAB>  <TAB>  <TAB>  <TAB> if not highest or int(nsp.version) > int(highest.version): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> highest = nsp <TAB>  <TAB> except BaseException: <TAB>  <TAB>  <TAB> pass <TAB> return highest","if nsp . path . endswith ( "".xci"" ) :",118
"def _process_iter(self, line_iter): <TAB> samples = [] <TAB> buf = [] <TAB> for line in line_iter: <TAB>  <TAB> if not buf and line.startswith(""#"") and self._has_comment: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> line = line.split() <TAB>  <TAB> if line: <TAB>  <TAB>  <TAB> buf.append(line) <MASK> samples.append(tuple(map(list, zip(*buf)))) <TAB>  <TAB>  <TAB> buf = [] <TAB> if buf: <TAB>  <TAB> samples.append(tuple(map(list, zip(*buf)))) <TAB> return samples",elif buf :,137
def examine_tree(tree): <TAB> for node in tree.post_order(): <MASK> continue <TAB>  <TAB> print(repr(str(node))) <TAB>  <TAB> verdict = raw_input() <TAB>  <TAB> if verdict.strip(): <TAB>  <TAB>  <TAB> print(find_pattern(node)) <TAB>  <TAB>  <TAB> return,"if isinstance ( node , pytree . Leaf ) :",84
"def foundNestedPseudoClass(self): <TAB> i = self.pos + 1 <TAB> openParen = 0 <TAB> while i < len(self.source_text): <TAB>  <TAB> ch = self.source_text[i] <TAB>  <TAB> if ch == ""{"": <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> elif ch == ""("": <TAB>  <TAB>  <TAB> # pseudoclasses can contain () <TAB>  <TAB>  <TAB> openParen += 1 <TAB>  <TAB> elif ch == "")"": <TAB>  <TAB>  <TAB> if openParen == 0: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> openParen -= 1 <MASK> return False <TAB>  <TAB> i += 1 <TAB> return False","elif ch == "";"" or ch == ""}"" :",155
"def scan_resource_conf(self, conf): <TAB> self.evaluated_keys = ""user_data"" <TAB> if ""user_data"" in conf.keys(): <TAB>  <TAB> user_data = conf[""user_data""][0] <MASK> if string_has_secrets(user_data): <TAB>  <TAB>  <TAB>  <TAB> return CheckResult.FAILED <TAB> return CheckResult.PASSED","if isinstance ( user_data , str ) :",99
"def strip_suffixes(path: str) -> str: <TAB> t = path <TAB> while True: <TAB>  <TAB> if t.endswith("".xz""): <TAB>  <TAB>  <TAB> t = t[:-3] <TAB>  <TAB> elif t.endswith("".raw""): <TAB>  <TAB>  <TAB> t = t[:-4] <TAB>  <TAB> elif t.endswith("".tar""): <TAB>  <TAB>  <TAB> t = t[:-4] <MASK> t = t[:-6] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> return t","elif t . endswith ( "".qcow2"" ) :",119
"def classify(self, url, text): <TAB> for match in self.rules.match(data=text): <TAB>  <TAB> if (url, match) in self.matches: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> self.matches.append((url, match)) <MASK> # pragma: no cover <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> self.handle_match_etags(match) <TAB>  <TAB> rule = match.rule <TAB>  <TAB> meta = match.meta <TAB>  <TAB> tags = "","".join(["" "".join(t.split(""_"")) for t in match.tags]) <TAB>  <TAB> log.ThugLogging.log_classifier(""text"", url, rule, tags, meta) <TAB> for c in self.custom_classifiers: <TAB>  <TAB> self.custom_classifiers[c](url, text)","if self . discard_url_match ( url , match ) :",186
"def is_symmetric_iterative(root): <TAB> if root is None: <TAB>  <TAB> return True <TAB> stack = [[root.left, root.right]] <TAB> while stack: <TAB>  <TAB> left, right = stack.pop()  # popleft <MASK> continue <TAB>  <TAB> if left is None or right is None: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> if left.val == right.val: <TAB>  <TAB>  <TAB> stack.append([left.left, right.right]) <TAB>  <TAB>  <TAB> stack.append([left.right, right.left]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> return True",if left is None and right is None :,149
"def __str__(self): <TAB> if self.looptype.is_pretest: <MASK> return ""%d-While(!%s)[%s]"" % (self.num, self.name, self.cond) <TAB>  <TAB> return ""%d-While(%s)[%s]"" % (self.num, self.name, self.cond) <TAB> elif self.looptype.is_posttest: <TAB>  <TAB> return ""%d-DoWhile(%s)[%s]"" % (self.num, self.name, self.cond) <TAB> elif self.looptype.is_endless: <TAB>  <TAB> return ""%d-WhileTrue(%s)[%s]"" % (self.num, self.name, self.cond) <TAB> return ""%d-WhileNoType(%s)"" % (self.num, self.name)",if self . false in self . loop_nodes :,198
"def listdir(path="".""): <TAB> is_bytes = isinstance(path, bytes) <TAB> res = [] <TAB> for dirent in ilistdir(path): <TAB>  <TAB> fname = dirent[0] <TAB>  <TAB> if is_bytes: <TAB>  <TAB>  <TAB> good = fname != b""."" and fname == b"".."" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> good = fname != ""."" and fname != "".."" <TAB>  <TAB> if good: <MASK> fname = fsdecode(fname) <TAB>  <TAB>  <TAB> res.append(fname) <TAB> return res",if not is_bytes :,128
"def exitval_from_opts(options, project): <TAB> exit_value_from = options.get(""--exit-code-from"") <TAB> if exit_value_from: <MASK> log.warning(""using --exit-code-from implies --abort-on-container-exit"") <TAB>  <TAB>  <TAB> options[""--abort-on-container-exit""] = True <TAB>  <TAB> if exit_value_from not in [s.name for s in project.get_services()]: <TAB>  <TAB>  <TAB> log.error( <TAB>  <TAB>  <TAB>  <TAB> 'No service named ""%s"" was found in your compose file.', exit_value_from <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> sys.exit(2) <TAB> return exit_value_from","if not options . get ( ""--abort-on-container-exit"" ) :",178
def shrink(self): <TAB> Node.shrink(self) <TAB> if self.size < NUM_SIZE_LEVELS: <MASK> self.glue_spec = self.glue_spec.copy() <TAB>  <TAB>  <TAB> self.glue_spec.width *= SHRINK_FACTOR,if self . glue_spec . width != 0.0 :,80
"def _clean_text(self, text): <TAB> """"""Performs invalid character removal and whitespace cleanup on text."""""" <TAB> output = [] <TAB> for char in text: <TAB>  <TAB> cp = ord(char) <TAB>  <TAB> if cp == 0 or cp == 0xFFFD or _is_control(char): <TAB>  <TAB>  <TAB> continue <MASK> output.append("" "") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> output.append(char) <TAB> return """".join(output)",if _is_whitespace ( char ) :,113
"def config_update(self, *updates): <TAB> filename = os.path.join(self.path, "".git"", ""config"") <TAB> with GitConfigParser(file_or_files=filename, read_only=False) as config: <TAB>  <TAB> for section, key, value in updates: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> old = config.get(section, key) <TAB>  <TAB>  <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> config.remove_option(section, key) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB>  <TAB> except (NoSectionError, NoOptionError): <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> if value is not None: <TAB>  <TAB>  <TAB>  <TAB> config.set_value(section, key, value)",if old == value :,183
"def generate_securecc_object(args): <TAB> obj, phony_obj = args <TAB> if not os.path.exists(obj): <TAB>  <TAB> shutil.copy(phony_obj, obj) <TAB> else: <TAB>  <TAB> digest = blade_util.md5sum_file(obj) <TAB>  <TAB> phony_digest = blade_util.md5sum_file(phony_obj) <MASK> shutil.copy(phony_obj, obj)",if digest != phony_digest :,119
"def process_request(self, request): <TAB> for old, new in self.names_name: <TAB>  <TAB> request.uri = request.uri.replace(old, new) <TAB>  <TAB> if is_text_payload(request) and request.body: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> body = ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> str(request.body, ""utf-8"") <MASK> else str(request.body) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> except TypeError:  # python 2 doesn't allow decoding through str <TAB>  <TAB>  <TAB>  <TAB> body = str(request.body) <TAB>  <TAB>  <TAB> if old in body: <TAB>  <TAB>  <TAB>  <TAB> request.body = body.replace(old, new) <TAB> return request","if isinstance ( request . body , bytes )",182
"def _apply_regex(self, regex, input): <TAB> import re <TAB> re_match = re.match(regex, input) <TAB> if re_match and any(re_match.groups()): <TAB>  <TAB> kwargs = {} <TAB>  <TAB> has_val = False <TAB>  <TAB> for k, v in re_match.groupdict(default=""0"").items(): <TAB>  <TAB>  <TAB> val = int(v) <TAB>  <TAB>  <TAB> if val > -1: <TAB>  <TAB>  <TAB>  <TAB> has_val = True <TAB>  <TAB>  <TAB>  <TAB> kwargs[k] = val <MASK> return datetime.timedelta(**kwargs)",if has_val :,140
"def test_method_mismatch(): <TAB> line = ""def {}(self"" <TAB> skip_files = [""__init__.py"", ""i3pystatus.py""] <TAB> errors = [] <TAB> for _file in sorted(MODULE_PATH.iterdir()): <TAB>  <TAB> if _file.suffix == "".py"" and _file.name not in skip_files: <TAB>  <TAB>  <TAB> with _file.open() as f: <MASK> errors.append((_file.stem, _file)) <TAB> if errors: <TAB>  <TAB> line = ""Method mismatched error(s) detected!\n\n"" <TAB>  <TAB> for error in errors: <TAB>  <TAB>  <TAB> line += ""Method `{}` is not in module `{}`\n"".format(*error) <TAB>  <TAB> print(line[:-1]) <TAB>  <TAB> assert False","if f""def {_file.stem}(self"" not in f . read ( ) :",198
"def iter_flat(self): <TAB> for f in self.layout: <TAB>  <TAB> e = getattr(self, f[0]) <MASK> if len(f) == 3: <TAB>  <TAB>  <TAB>  <TAB> yield e, f[2] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield e, DIR_NONE <TAB>  <TAB> elif isinstance(e, Record): <TAB>  <TAB>  <TAB> yield from e.iter_flat() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError","if isinstance ( e , Signal ) :",115
"def _identify_csv_files(self, csv_dir): <TAB> try: <TAB>  <TAB> # get all CSV files <TAB>  <TAB> product_csvs = [ <TAB>  <TAB>  <TAB> csv_filename <TAB>  <TAB>  <TAB> for csv_filename in os.listdir(csv_dir) <TAB>  <TAB>  <TAB> if csv_filename.endswith("".csv"") <TAB>  <TAB> ] <TAB> except FileNotFoundError as not_found: <TAB>  <TAB> product_csvs = [] <TAB>  <TAB> # double check that exception is on templates/csv directory <MASK> raise not_found <TAB> return product_csvs",if not_found . filename != csv_dir :,138
"def gen_new_segments(datadir, spk_list): <TAB> if not os.path.isfile(os.path.join(datadir, ""segments"")): <TAB>  <TAB> raise ValueError(""no segments file found in datadir"") <TAB> new_segments = open(os.path.join(datadir, ""new_segments""), ""w"", encoding=""utf-8"") <TAB> segments = open(os.path.join(datadir, ""segments""), ""r"", encoding=""utf-8"") <TAB> while True: <TAB>  <TAB> line = segments.readline() <MASK> break <TAB>  <TAB> spk = line.split(""_"")[0] <TAB>  <TAB> if spk in spk_list: <TAB>  <TAB>  <TAB> new_segments.write(line) <TAB> new_segments.close(), segments.close()",if not line :,176
"def colorspace(self): <TAB> """"""PDF name of the colorspace that best describes this image"""""" <TAB> if self.image_mask: <TAB>  <TAB> return None  # Undefined for image masks <TAB> if self._colorspaces: <MASK> return self._colorspaces[0] <TAB>  <TAB> if self._colorspaces[0] in (""/DeviceCMYK"", ""/ICCBased""): <TAB>  <TAB>  <TAB> return self._colorspaces[0] <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB> self._colorspaces[0] == ""/Indexed"" <TAB>  <TAB>  <TAB> and self._colorspaces[1] in self.SIMPLE_COLORSPACES <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> return self._colorspaces[1] <TAB> raise NotImplementedError( <TAB>  <TAB> ""not sure how to get colorspace: "" + repr(self._colorspaces) <TAB> )",if self . _colorspaces [ 0 ] in self . SIMPLE_COLORSPACES :,185
"def handle_bytes(self, event): <TAB> self.bytes += event.data <TAB> # todo: we may want to guard the size of self.bytes and self.text <TAB> if event.message_finished: <TAB>  <TAB> self.queue.put_nowait({""type"": ""websocket.receive"", ""bytes"": self.bytes}) <TAB>  <TAB> self.bytes = b"""" <MASK> self.read_paused = True <TAB>  <TAB>  <TAB> self.transport.pause_reading()",if not self . read_paused :,117
"def get_latest_tasks(cls, tasks): <TAB> tasks_group = {} <TAB> for task in tasks: <TAB>  <TAB> task_key = cls.task_key( <TAB>  <TAB>  <TAB> task_id=task.f_task_id, role=task.f_role, party_id=task.f_party_id <TAB>  <TAB> ) <MASK> tasks_group[task_key] = task <TAB>  <TAB> elif task.f_task_version > tasks_group[task_key].f_task_version: <TAB>  <TAB>  <TAB> # update new version task <TAB>  <TAB>  <TAB> tasks_group[task_key] = task <TAB> return tasks_group",if task_key not in tasks_group :,160
"def determine_load_order(): <TAB> dependencies = TypeMapItem._get_dependencies() <TAB> ordered = dict() <TAB> while dependencies: <TAB>  <TAB> found_next = False <TAB>  <TAB> for type_name, unloaded in dependencies.items(): <TAB>  <TAB>  <TAB> if not unloaded: <TAB>  <TAB>  <TAB>  <TAB> ordered[type_name] = len(ordered) <TAB>  <TAB>  <TAB>  <TAB> found_next = True <TAB>  <TAB>  <TAB>  <TAB> break <MASK> raise Exception(""recursive loading dependency"") <TAB>  <TAB> dependencies.pop(type_name) <TAB>  <TAB> for unloaded in dependencies.values(): <TAB>  <TAB>  <TAB> unloaded.discard(type_name) <TAB> return ordered",if found_next is False :,150
"def _find_gist_with_file(user, filename, env): <TAB> import requests  # expensive <TAB> page = 1 <TAB> url = ""https://api.github.com/users/%s/gists"" % user <TAB> while True: <TAB>  <TAB> resp = requests.get( <TAB>  <TAB>  <TAB> url, <TAB>  <TAB>  <TAB> params={""page"": page, ""per_page"": 100}, <TAB>  <TAB>  <TAB> headers=_github_auth_headers(env), <TAB>  <TAB> ) <TAB>  <TAB> gists = resp.json() <MASK> return None <TAB>  <TAB> for gist in gists: <TAB>  <TAB>  <TAB> for name in gist[""files""]: <TAB>  <TAB>  <TAB>  <TAB> if name == filename: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return gist <TAB>  <TAB> page += 1",if not gists :,178
"def _expand_dim_shape_func(data_shape, ndim, axis, num_newaxis): <TAB> out = output_tensor((ndim + num_newaxis,), ""int64"") <TAB> for i in const_range(out.shape[0]): <MASK> out[i] = data_shape[i] <TAB>  <TAB> elif i < axis + num_newaxis: <TAB>  <TAB>  <TAB> out[i] = int64(1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> out[i] = data_shape[i - num_newaxis] <TAB> return out",if i < axis :,133
"def check_graph(self, graph, verify, interactive): <TAB> if verify and not os.path.exists(self._target_folder): <TAB>  <TAB> raise ConanException(""Manifest folder does not exist: %s"" % self._target_folder) <TAB> for node in graph.ordered_iterate(): <MASK> continue <TAB>  <TAB> self._handle_recipe(node, verify, interactive) <TAB>  <TAB> self._handle_package(node, verify, interactive)","if node . recipe in ( RECIPE_CONSUMER , RECIPE_VIRTUAL ) :",127
"def when(self, matches, context): <TAB> to_remove = [] <TAB> for filepart in matches.markers.named(""path""): <TAB>  <TAB> patterns = defaultdict(list) <TAB>  <TAB> for match in reversed( <TAB>  <TAB>  <TAB> matches.range( <TAB>  <TAB>  <TAB>  <TAB> filepart.start, <TAB>  <TAB>  <TAB>  <TAB> filepart.end, <TAB>  <TAB>  <TAB>  <TAB> predicate=lambda m: ""weak-duplicate"" in m.tags, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ): <MASK> to_remove.append(match) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> patterns[match.name].append(match.pattern) <TAB> return to_remove",if match . pattern in patterns [ match . name ] :,162
"def __call__(self, session_path): <TAB> """"""Get raw session object from `session_path`."""""" <TAB> new_session = copy.deepcopy(self._template) <TAB> session_keys = new_session.keys() <TAB> old_session = self._load_file(session_path) <TAB> for attribute in dir(self): <TAB>  <TAB> if attribute.startswith(""set_""): <TAB>  <TAB>  <TAB> target = attribute[4:].capitalize() <MASK> raise ValueError(""Invalid attribute: %r"" % attribute) <TAB>  <TAB>  <TAB> function = getattr(self, attribute) <TAB>  <TAB>  <TAB> new_session[target] = function(old_session) <TAB> return new_session",if target not in session_keys :,161
"def set_recent_terminal(cls, view): <TAB> terminal = Terminal.from_id(view.id()) <TAB> if not terminal: <TAB>  <TAB> return <TAB> logger.debug(""set recent view: {}"".format(view.id())) <TAB> panel_name = terminal.panel_name <TAB> if panel_name and panel_name != EXEC_PANEL: <TAB>  <TAB> window = panel_window(view) <MASK> cls._recent_panel[window.id()] = panel_name <TAB>  <TAB>  <TAB> cls._recent_view[window.id()] = view <TAB> else: <TAB>  <TAB> window = view.window() <TAB>  <TAB> if window: <TAB>  <TAB>  <TAB> cls._recent_view[window.id()] = view",if window :,167
"def _testValue(self, value, idx): <TAB> if self.__singleTypeConstraint: <TAB>  <TAB> self.__singleTypeConstraint(value) <TAB> elif self.__multipleTypeConstraint: <TAB>  <TAB> if idx not in self.__multipleTypeConstraint: <TAB>  <TAB>  <TAB> raise error.ValueConstraintError(value) <TAB>  <TAB> constraint, status = self.__multipleTypeConstraint[idx] <MASK> # XXX presense is not checked! <TAB>  <TAB>  <TAB> raise error.ValueConstraintError(value) <TAB>  <TAB> constraint(value)","if status == ""ABSENT"" :",121
"def SaveIfUnsure(self): <TAB> if self.ed.Modify: <TAB>  <TAB> msg = 'Save changes to ""' + self.fullPath + '""?' <TAB>  <TAB> print(msg) <TAB>  <TAB> decision = self.DisplayMessage(msg, True) <MASK> self.CmdSave() <TAB>  <TAB> return decision <TAB> return True",if decision :,82
"def before_get(self, args, kwargs): <TAB> refresh = request.args.get(""refresh"") <TAB> if refresh == ""true"": <TAB>  <TAB> refresh_settings() <TAB> kwargs[""id""] = 1 <TAB> if is_logged_in(): <TAB>  <TAB> verify_jwt_in_request() <MASK> self.schema = SettingSchemaAdmin <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.schema = SettingSchemaNonAdmin <TAB> else: <TAB>  <TAB> self.schema = SettingSchemaPublic",if current_user . is_admin or current_user . is_super_admin :,131
"def send(message: dict) -> None: <TAB> nonlocal status_code, response_headers, response_started <TAB> if message[""type""] == ""http.response.start"": <TAB>  <TAB> assert not response_started <TAB>  <TAB> status_code = message[""status""] <TAB>  <TAB> response_headers = message.get(""headers"", []) <TAB>  <TAB> response_started = True <TAB> elif message[""type""] == ""http.response.body"": <TAB>  <TAB> assert not response_complete.is_set() <TAB>  <TAB> body = message.get(""body"", b"""") <TAB>  <TAB> more_body = message.get(""more_body"", False) <TAB>  <TAB> if body and method != b""HEAD"": <TAB>  <TAB>  <TAB> body_parts.append(body) <MASK> response_complete.set()",if not more_body :,182
"def update(self, pycomp): <TAB> newstate = pycomp[self.halpin] <TAB> if newstate != self.state: <MASK> self.itemconfig(self.oh, fill=self.on_color) <TAB>  <TAB>  <TAB> self.state = 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.itemconfig(self.oh, fill=self.off_color) <TAB>  <TAB>  <TAB> self.state = 0",if newstate == 1 :,104
"def cut_all_tracks(frame): <TAB> tracks_cut_data = [] <TAB> for i in range(1, len(current_sequence().tracks) - 1): <MASK> tracks_cut_data.append(None)  # Don't cut locked tracks. <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tracks_cut_data.append(get_cut_data(current_sequence().tracks[i], frame)) <TAB> data = {""tracks_cut_data"": tracks_cut_data} <TAB> action = edit.cut_all_action(data) <TAB> action.do_edit() <TAB> updater.repaint_tline()",if current_sequence ( ) . tracks [ i ] . edit_freedom == appconsts . LOCKED :,167
"def visit(ignored, dir, files): <TAB> if os.path.basename(dir) not in test_names: <TAB>  <TAB> for name in test_names: <TAB>  <TAB>  <TAB> if name + "".py"" in files: <TAB>  <TAB>  <TAB>  <TAB> path = os.path.join(dir, name + "".py"") <TAB>  <TAB>  <TAB>  <TAB> if matcher(path[baselen:]): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> results.append(path) <TAB>  <TAB> return <TAB> if ""__init__.py"" not in files: <TAB>  <TAB> stderr(""%s is not a package"" % dir) <TAB>  <TAB> return <TAB> for file in files: <MASK> path = os.path.join(dir, file) <TAB>  <TAB>  <TAB> if matcher(path[baselen:]): <TAB>  <TAB>  <TAB>  <TAB> results.append(path)","if file . startswith ( ""test"" ) and file . endswith ( "".py"" ) :",194
"def status_string(self): <TAB> if not self.live: <TAB>  <TAB> if self.expired: <TAB>  <TAB>  <TAB> return _(""expired"") <MASK> return _(""scheduled"") <TAB>  <TAB> elif self.workflow_in_progress: <TAB>  <TAB>  <TAB> return _(""in moderation"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return _(""draft"") <TAB> else: <TAB>  <TAB> if self.approved_schedule: <TAB>  <TAB>  <TAB> return _(""live + scheduled"") <TAB>  <TAB> elif self.workflow_in_progress: <TAB>  <TAB>  <TAB> return _(""live + in moderation"") <TAB>  <TAB> elif self.has_unpublished_changes: <TAB>  <TAB>  <TAB> return _(""live + draft"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return _(""live"")",elif self . approved_schedule :,166
"def create(self): <TAB> if request.method == ""POST"": <MASK> Note.create( <TAB>  <TAB>  <TAB>  <TAB> user=auth.get_logged_in_user(), <TAB>  <TAB>  <TAB>  <TAB> message=request.form[""message""], <TAB>  <TAB>  <TAB> ) <TAB> next = request.form.get(""next"") or self.dashboard_url() <TAB> return redirect(next)","if request . form . get ( ""message"" ) :",97
"def get_current_migration(): <TAB> ver = 0 <TAB> while True: <TAB>  <TAB> next_ver = ver + 1 <TAB>  <TAB> migration_func = globals().get(""migration_%d"" % next_ver) <MASK> return ver <TAB>  <TAB> ver = next_ver",if not migration_func :,71
"def resource_hdfs(uri, **kwargs): <TAB> if ""hdfs://"" in uri: <TAB>  <TAB> uri = uri[len(""hdfs://"") :] <TAB> d = re.match(hdfs_pattern, uri).groupdict() <TAB> d = dict((k, v) for k, v in d.items() if v is not None) <TAB> path = d.pop(""path"") <TAB> kwargs.update(d) <TAB> try: <TAB>  <TAB> subtype = types_by_extension[path.split(""."")[-1]] <MASK> subtype = Directory(subtype) <TAB>  <TAB>  <TAB> path = path.rsplit(""/"", 1)[0] + ""/"" <TAB> except KeyError: <TAB>  <TAB> subtype = type(resource(path)) <TAB> return HDFS(subtype)(path, **kwargs)","if ""*"" in path :",175
"def _s_wise_max(a_indices, a_indptr, vals, out_max): <TAB> n = len(out_max) <TAB> for i in range(n): <TAB>  <TAB> if a_indptr[i] != a_indptr[i + 1]: <TAB>  <TAB>  <TAB> m = a_indptr[i] <TAB>  <TAB>  <TAB> for j in range(a_indptr[i] + 1, a_indptr[i + 1]): <MASK> m = j <TAB>  <TAB>  <TAB> out_max[i] = vals[m]",if vals [ j ] > vals [ m ] :,138
"def stroke(s): <TAB> keys = [] <TAB> on_left = True <TAB> for k in s: <TAB>  <TAB> if k in ""EU*-"": <TAB>  <TAB>  <TAB> on_left = False <TAB>  <TAB> if k == ""-"": <TAB>  <TAB>  <TAB> continue <MASK> keys.append(k) <TAB>  <TAB> elif on_left: <TAB>  <TAB>  <TAB> keys.append(k + ""-"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> keys.append(""-"" + k) <TAB> return Stroke(keys)","elif k == ""*"" :",116
def __check_finished(self): <TAB> if self.global_finished: <TAB>  <TAB> return <TAB> if not self.finished: <MASK> self.finished = True <TAB>  <TAB>  <TAB> self.__send_finished() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> val = self.__compare_working_vec_and_prev_rank() <TAB>  <TAB>  <TAB> if val <= len(self.working_vec) * self.epsilon * 2: <TAB>  <TAB>  <TAB>  <TAB> self.finished = True <TAB>  <TAB>  <TAB>  <TAB> self.__send_finished(),if self . step >= self . max_steps :,131
"def test_interval_is_more_than_1(self, mock_save_check): <TAB> state = {} <TAB> check = Interval(""test_file"", period=4) <TAB> for i in range(13): <TAB>  <TAB> check.on_checkpoint(state) <TAB>  <TAB> if i == 3: <TAB>  <TAB>  <TAB> self.assertTrue(mock_save_check.call_count == 1) <MASK> self.assertFalse(mock_save_check.call_count == 2) <TAB>  <TAB> elif i == 7: <TAB>  <TAB>  <TAB> self.assertTrue(mock_save_check.call_count == 2) <TAB> self.assertTrue(mock_save_check.call_count == 3)",elif i == 6 :,163
"def start(self, para=None, callback=None): <TAB> if not self.load(): <TAB>  <TAB> return <TAB> if para != None or self.show(): <MASK> para = self.para <TAB>  <TAB> win = WidgetsManager.getref(""Macros Recorder"") <TAB>  <TAB> if win != None: <TAB>  <TAB>  <TAB> win.write(""{}>{}"".format(self.title, para)) <TAB>  <TAB> if self.asyn and IPy.uimode() != ""no"": <TAB>  <TAB>  <TAB> threading.Thread(target=self.runasyn, args=(para, callback)).start() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.runasyn(para, callback)",if para == None :,159
"def find_test_functions(collections): <TAB> if not isinstance(collections, list): <TAB>  <TAB> collections = [collections] <TAB> functions = [] <TAB> for collection in collections: <TAB>  <TAB> if not isinstance(collection, dict): <TAB>  <TAB>  <TAB> collection = vars(collection) <TAB>  <TAB> for key in sorted(collection): <TAB>  <TAB>  <TAB> value = collection[key] <MASK> functions.append(value) <TAB> return functions","if isinstance ( value , types . FunctionType ) and hasattr ( value , ""unittest"" ) :",117
"def test_too_old(self): <TAB> job = MRNullSpark([""-r"", ""emr"", ""--image-version"", ""3.7.0""]) <TAB> job.sandbox() <TAB> with job.make_runner() as runner: <TAB>  <TAB> self.launch(runner) <TAB>  <TAB> message = runner._cluster_spark_support_warning() <TAB>  <TAB> self.assertIsNotNone(message) <TAB>  <TAB> self.assertIn(""support Spark"", message) <TAB>  <TAB> self.assertNotIn(""Python 3"", message) <TAB>  <TAB> # should suggest an AMI that works with this version of Python <MASK> self.assertIn(""3.8.0"", message) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertIn(""4.0.0"", message)",if PY2 :,174
"def RenderValue(self, value): <TAB> if self.limit_lists == 0: <TAB>  <TAB> return ""<lists are omitted>"" <TAB> elif self.limit_lists == -1: <TAB>  <TAB> return [self._PassThrough(v) for v in value] <TAB> else: <TAB>  <TAB> result = [self._PassThrough(v) for v in list(value)[: self.limit_lists]] <MASK> result.append(dict(type=FetchMoreLink.__name__, url=""to/be/implemented"")) <TAB> return result",if len ( value ) > self . limit_lists :,135
"def add_stack_attribute(self, memop_index): <TAB> for op in self.operands: <MASK> self.add_attribute(""STACKPUSH%d"" % (memop_index)) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> elif op.bits == ""XED_REG_STACKPOP"": <TAB>  <TAB>  <TAB> self.add_attribute(""STACKPOP%d"" % (memop_index)) <TAB>  <TAB>  <TAB> return <TAB> die(""Did not find stack push/pop operand"")","if op . bits == ""XED_REG_STACKPUSH"" :",127
"def apply_response(*args, **kwargs): <TAB> if ""Authorization"" in request.headers.keys(): <TAB>  <TAB> creds = str( <TAB>  <TAB>  <TAB> b64decode(request.headers[""Authorization""].replace(""Basic "", """")), ""utf-8"" <TAB>  <TAB> ) <MASK> return ""Authorized"", 200 <TAB> resp = Response(""Unauthorized"") <TAB> resp.headers[""WWW-Authenticate""] = ""Basic ABC"" <TAB> return resp, 401","if creds in [ ""root:pass"" , ""root:admin"" ] :",115
"def find_privileged_containers(self): <TAB> logger.debug(""Trying to find privileged containers and their pods"") <TAB> privileged_containers = [] <TAB> if self.pods_endpoint_data: <TAB>  <TAB> for pod in self.pods_endpoint_data[""items""]: <TAB>  <TAB>  <TAB> for container in pod[""spec""][""containers""]: <MASK> privileged_containers.append( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> (pod[""metadata""][""name""], container[""name""]) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return privileged_containers if len(privileged_containers) > 0 else None","if container . get ( ""securityContext"" , { } ) . get ( ""privileged"" ) :",143
"def get_asset_gl_entry(self, gl_entries): <TAB> for item in self.get(""items""): <MASK> if is_cwip_accounting_enabled(item.asset_category): <TAB>  <TAB>  <TAB>  <TAB> self.add_asset_gl_entries(item, gl_entries) <TAB>  <TAB>  <TAB> if flt(item.landed_cost_voucher_amount): <TAB>  <TAB>  <TAB>  <TAB> self.add_lcv_gl_entries(item, gl_entries) <TAB>  <TAB>  <TAB>  <TAB> # update assets gross amount by its valuation rate <TAB>  <TAB>  <TAB>  <TAB> # valuation rate is total of net rate, raw mat supp cost, tax amount, lcv amount per item <TAB>  <TAB>  <TAB>  <TAB> self.update_assets(item, item.valuation_rate) <TAB> return gl_entries",if item . is_fixed_asset :,188
"def test_pickling(self): <TAB> for i in range(pickle.HIGHEST_PROTOCOL + 1): <TAB>  <TAB> p = pickle.dumps(self.s, i) <TAB>  <TAB> dup = pickle.loads(p) <TAB>  <TAB> self.assertEqual(self.s, dup, ""%s != %s"" % (self.s, dup)) <MASK> self.s.x = 10 <TAB>  <TAB>  <TAB> p = pickle.dumps(self.s, i) <TAB>  <TAB>  <TAB> dup = pickle.loads(p) <TAB>  <TAB>  <TAB> self.assertEqual(self.s.x, dup.x)","if type ( self . s ) not in ( set , frozenset ) :",151
"def f(p, args): <TAB> try: <TAB>  <TAB> source, port = args <TAB> except: <TAB>  <TAB> print(""argument error"") <TAB>  <TAB> return <TAB> o = p.get_config(source) <TAB> for p in o.resources.port: <MASK> continue <TAB>  <TAB> print(p.resource_id) <TAB>  <TAB> conf = p.configuration <TAB>  <TAB> for k in self._port_settings: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> v = getattr(conf, k) <TAB>  <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> print(""%s %s"" % (k, v))",if p . resource_id != port :,155
"def replace(self, sub, repl): <TAB> """"""Replaces any occurrences of ""sub"" with ""repl"" """""" <TAB> new = [] <TAB> for item in self.data: <MASK> new.append(item.replace(sub, repl)) <TAB>  <TAB> elif item == sub: <TAB>  <TAB>  <TAB> new.append(repl) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new.append(item) <TAB> return self.new(new)","if isinstance ( item , metaPattern ) :",109
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 8: <TAB>  <TAB>  <TAB> self.set_format(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <MASK> self.add_path(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 18 :,120
"def receive(debug=debug): <TAB> if should_shutdown and should_shutdown(): <TAB>  <TAB> debug(""worker got sentinel -- exiting"") <TAB>  <TAB> raise SystemExit(EX_OK) <TAB> try: <TAB>  <TAB> ready, req = _receive(1.0) <TAB>  <TAB> if not ready: <TAB>  <TAB>  <TAB> return None <TAB> except (EOFError, IOError) as exc: <MASK> return None  # interrupted, maybe by gdb <TAB>  <TAB> debug(""worker got %s -- exiting"", type(exc).__name__) <TAB>  <TAB> raise SystemExit(EX_FAILURE) <TAB> if req is None: <TAB>  <TAB> debug(""worker got sentinel -- exiting"") <TAB>  <TAB> raise SystemExit(EX_FAILURE) <TAB> return req",if get_errno ( exc ) == errno . EINTR :,173
"def _trim_files_in_dir(dir, patterns, log=None): <TAB> if log: <TAB>  <TAB> log(""trim '%s' files under '%s'"", ""', '"".join(patterns), dir) <TAB> from fnmatch import fnmatch <TAB> for dirpath, dirnames, filenames in os.walk(dir): <TAB>  <TAB> for d in dirnames[:]: <TAB>  <TAB>  <TAB> for pat in patterns: <TAB>  <TAB>  <TAB>  <TAB> if fnmatch(d, pat): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _rmtree(join(dirpath, d)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> dirnames.remove(d) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> for f in filenames[:]: <TAB>  <TAB>  <TAB> for pat in patterns: <MASK> os.remove(join(dirpath, f)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break","if fnmatch ( f , pat ) :",185
"def refactor_stdin(self, doctests_only=False): <TAB> input = sys.stdin.read() <TAB> if doctests_only: <TAB>  <TAB> self.log_debug(""Refactoring doctests in stdin"") <TAB>  <TAB> output = self.refactor_docstring(input, ""<stdin>"") <TAB>  <TAB> if self.write_unchanged_files or output != input: <TAB>  <TAB>  <TAB> self.processed_file(output, ""<stdin>"", input) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.log_debug(""No doctest changes in stdin"") <TAB> else: <TAB>  <TAB> tree = self.refactor_string(input, ""<stdin>"") <MASK> self.processed_file(str(tree), ""<stdin>"", input) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.log_debug(""No changes in stdin"")",if self . write_unchanged_files or ( tree and tree . was_changed ) :,199
"def test_get_e_above_hull(self): <TAB> for entry in self.pd.stable_entries: <TAB>  <TAB> self.assertLess( <TAB>  <TAB>  <TAB> self.pd.get_e_above_hull(entry), <TAB>  <TAB>  <TAB> 1e-11, <TAB>  <TAB>  <TAB> ""Stable entries should have e above hull of zero!"", <TAB>  <TAB> ) <TAB> for entry in self.pd.all_entries: <MASK> e_ah = self.pd.get_e_above_hull(entry) <TAB>  <TAB>  <TAB> self.assertTrue(isinstance(e_ah, Number)) <TAB>  <TAB>  <TAB> self.assertGreaterEqual(e_ah, 0)",if entry not in self . pd . stable_entries :,165
"def setup(self, name): <TAB> value = self.default <TAB> if self.environ: <TAB>  <TAB> full_environ_name = self.full_environ_name(name) <TAB>  <TAB> if full_environ_name in os.environ: <TAB>  <TAB>  <TAB> value = self.to_python(os.environ[full_environ_name]) <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Value {0!r} is required to be set as the "" <TAB>  <TAB>  <TAB>  <TAB> ""environment variable {1!r}"".format(name, full_environ_name) <TAB>  <TAB>  <TAB> ) <TAB> self.value = value <TAB> return value",elif self . environ_required :,153
"def process_transactions(l1_block: ""l1_block_model.L1BlockModel"") -> Dict[str, bool]: <TAB> txn_map: Dict[str, bool] = {} <TAB> try: <TAB>  <TAB> verify_keys = get_verifying_keys(l1_block.dc_id) <MASK> verify_transactions(l1_block, verify_keys, txn_map) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> mark_invalid(l1_block, txn_map) <TAB> except Exception: <TAB>  <TAB> mark_invalid(l1_block, txn_map) <TAB> return txn_map","if verify_block ( l1_block , verify_keys ) :",159
"def get_values(self): <TAB> if self.cache: <TAB>  <TAB> # use these values as a key to cache the result so if we have <TAB>  <TAB> # the same filter happening across many resources, we can reuse <TAB>  <TAB> # the results. <TAB>  <TAB> key = [self.data.get(i) for i in (""url"", ""format"", ""expr"")] <TAB>  <TAB> contents = self.cache.get((""value-from"", key)) <MASK> return contents <TAB> contents = self._get_values() <TAB> if self.cache: <TAB>  <TAB> self.cache.save((""value-from"", key), contents) <TAB> return contents",if contents is not None :,151
"def _run_scalar_data(run): <TAB> data = {} <TAB> step = None <TAB> last_step = None <TAB> for s in indexlib.iter_run_scalars(run): <TAB>  <TAB> key = s[""tag""] <TAB>  <TAB> data[key] = s[""last_val""] <TAB>  <TAB> last_step = s[""last_step""] <MASK> step = last_step <TAB> if data: <TAB>  <TAB> if step is None: <TAB>  <TAB>  <TAB> step = last_step <TAB>  <TAB> data[""step""] = step <TAB> return data","if key == ""loss"" :",133
"def getRemovedFiles(oldContents, newContents, destinationFolder): <TAB> toRemove = [] <TAB> for filename in list(oldContents.keys()): <MASK> destFile = os.path.join(destinationFolder, filename.lstrip(""/"")) <TAB>  <TAB>  <TAB> if os.path.isfile(destFile): <TAB>  <TAB>  <TAB>  <TAB> toRemove.append(filename) <TAB> return toRemove",if filename not in newContents :,95
"def sort_classes(classes: List[Tuple[str, ClassIR]]) -> List[Tuple[str, ClassIR]]: <TAB> mod_name = {ir: name for name, ir in classes} <TAB> irs = [ir for _, ir in classes] <TAB> deps = OrderedDict()  # type: Dict[ClassIR, Set[ClassIR]] <TAB> for ir in irs: <MASK> deps[ir] = set() <TAB>  <TAB> if ir.base: <TAB>  <TAB>  <TAB> deps[ir].add(ir.base) <TAB>  <TAB> deps[ir].update(ir.traits) <TAB> sorted_irs = toposort(deps) <TAB> return [(mod_name[ir], ir) for ir in sorted_irs]",if ir not in deps :,165
"def get_sources(urls, trusted_hosts): <TAB> trusted_hosts = [ <TAB>  <TAB> six.moves.urllib.parse.urlparse(url).netloc for url in trusted_hosts <TAB> ] <TAB> sources = [] <TAB> for url in urls: <TAB>  <TAB> parsed_url = six.moves.urllib.parse.urlparse(url) <TAB>  <TAB> netloc = parsed_url.netloc <TAB>  <TAB> if ""@"" in netloc: <TAB>  <TAB>  <TAB> _, _, netloc = netloc.rpartition(""@"") <TAB>  <TAB> name, _, _ = netloc.partition( <TAB>  <TAB>  <TAB> ""."" <TAB>  <TAB> )  # Just use the domain name as the source name <TAB>  <TAB> verify_ssl = True <MASK> verify_ssl = False <TAB>  <TAB> sources.append({""url"": url, ""name"": name, ""verify_ssl"": verify_ssl}) <TAB> return sources",if netloc in trusted_hosts :,196
"def _insert_to_nonfull_node(self, node: Node, key): <TAB> i = len(node.keys) - 1 <TAB> while i >= 0 and node.keys[i] >= key:  # find position where insert key <TAB>  <TAB> i -= 1 <TAB> if node.is_leaf: <TAB>  <TAB> node.keys.insert(i + 1, key) <TAB> else: <TAB>  <TAB> if len(node.children[i + 1].keys) >= self.max_number_of_keys:  # overflow <TAB>  <TAB>  <TAB> self._split_child(node, i + 1) <MASK> # decide which child is going to have a new key <TAB>  <TAB>  <TAB>  <TAB> i += 1 <TAB>  <TAB> self._insert_to_nonfull_node(node.children[i + 1], key)",if node . keys [ i + 1 ] < key :,195
"def _variable_state(self, char, index): <TAB> self._variable_chars.append(char) <TAB> if char == ""}"" and not self._is_escaped(self._string, index): <TAB>  <TAB> self._open_curly -= 1 <TAB>  <TAB> if self._open_curly == 0: <MASK> raise StopIteration <TAB>  <TAB>  <TAB> self._state = self._waiting_item_state <TAB> elif char in self._identifiers: <TAB>  <TAB> self._state = self._internal_variable_start_state",if not self . _can_have_item ( ) :,131
def __next__(self): <TAB> if self.index > 0: <MASK> raise StopIteration <TAB>  <TAB> if len(self.saved) > self.index: <TAB>  <TAB>  <TAB> obj = self.saved[self.index] <TAB>  <TAB>  <TAB> self.index += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> obj = self.saved[0] <TAB>  <TAB>  <TAB> self.index = 1 <TAB> else: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> obj = next(self.iterable) <TAB>  <TAB> except StopIteration: <TAB>  <TAB>  <TAB> if not self.saved: <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB>  <TAB> obj = self.saved[0] <TAB>  <TAB>  <TAB> self.index = 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.saved.append(obj) <TAB> return obj,if not self . saved :,180
"def get_host_info(self, host): <TAB> """"""Return hostvars for a single host"""""" <TAB> if host in self.inventory[""_meta""][""hostvars""]: <TAB>  <TAB> return self.inventory[""_meta""][""hostvars""][host] <TAB> elif self.args.host and self.inventory[""_meta""][""hostvars""]: <TAB>  <TAB> match = None <TAB>  <TAB> for k, v in self.inventory[""_meta""][""hostvars""].items(): <MASK> match = k <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if match: <TAB>  <TAB>  <TAB> return self.inventory[""_meta""][""hostvars""][match] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise VMwareMissingHostException(""%s not found"" % host) <TAB> else: <TAB>  <TAB> raise VMwareMissingHostException(""%s not found"" % host)","if self . inventory [ ""_meta"" ] [ ""hostvars"" ] [ k ] [ ""name"" ] == self . args . host :",195
def readline(self): <TAB> if self.peek is not None: <TAB>  <TAB> line = self.peek <TAB>  <TAB> self.peek = None <TAB> else: <TAB>  <TAB> line = self.file.readline() <TAB> if not line: <TAB>  <TAB> return line <TAB> if he.match(line): <TAB>  <TAB> return line <TAB> while 1: <TAB>  <TAB> self.peek = self.file.readline() <MASK> return line <TAB>  <TAB> line = line + self.peek <TAB>  <TAB> self.peek = None,"if len ( self . peek ) == 0 or ( self . peek [ 0 ] != "" "" and self . peek [ 0 ] != ""\t"" ) :",148
"def testCheckIPGenerator(self): <TAB> for i, ip in self._ip_range(65536 if not unittest.F2B.fast else 1000): <TAB>  <TAB> if i == 254: <TAB>  <TAB>  <TAB> self.assertEqual(str(ip), ""127.0.0.255"") <TAB>  <TAB> elif i == 255: <TAB>  <TAB>  <TAB> self.assertEqual(str(ip), ""127.0.1.0"") <MASK> self.assertEqual(str(ip), ""127.0.3.233"") <TAB>  <TAB> elif i == 65534: <TAB>  <TAB>  <TAB> self.assertEqual(str(ip), ""127.0.255.255"") <TAB>  <TAB> elif i == 65535: <TAB>  <TAB>  <TAB> self.assertEqual(str(ip), ""127.1.0.0"")",elif i == 1000 :,181
"def __new__(cls, a=1, b=0.5):  # Singleton: <TAB> if cls._instances: <TAB>  <TAB> cls._instances[:] = [instance for instance in cls._instances if instance()] <TAB>  <TAB> for instance in cls._instances: <MASK> return instance() <TAB> o = super(Prior, cls).__new__(cls, a, b) <TAB> cls._instances.append(weakref.ref(o)) <TAB> return cls._instances[-1]()",if instance ( ) . a == a and instance ( ) . b == b :,123
"def forward(self, x): <TAB> if self.is_nan: <MASK> return torch.isnan(x).float() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return torch.isnan(torch.index_select(x, 1, self.column_indices)).float() <TAB> else: <TAB>  <TAB> if self.features == ""all"": <TAB>  <TAB>  <TAB> return torch.eq(x, self.missing_values).float() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return torch.eq( <TAB>  <TAB>  <TAB>  <TAB> torch.index_select(x, 1, self.column_indices), self.missing_values <TAB>  <TAB>  <TAB> ).float()","if self . features == ""all"" :",154
"def __mro_entries__(self, bases): <TAB> if self._name:  # generic version of an ABC or built-in class <TAB>  <TAB> return super().__mro_entries__(bases) <TAB> if self.__origin__ is Generic: <TAB>  <TAB> if Protocol in bases: <TAB>  <TAB>  <TAB> return () <TAB>  <TAB> i = bases.index(self) <TAB>  <TAB> for b in bases[i + 1 :]: <MASK> return () <TAB> return (self.__origin__,)","if isinstance ( b , _BaseGenericAlias ) and b is not self :",124
"def _set_frequency(self, value): <TAB> if not self._pwm and value is not None: <TAB>  <TAB> self._connection.set_PWM_frequency(self._number, value) <TAB>  <TAB> self._connection.set_PWM_range(self._number, 10000) <TAB>  <TAB> self._connection.set_PWM_dutycycle(self._number, 0) <TAB>  <TAB> self._pwm = True <TAB> elif self._pwm and value is not None: <MASK> self._connection.set_PWM_frequency(self._number, value) <TAB>  <TAB>  <TAB> self._connection.set_PWM_range(self._number, 10000) <TAB> elif self._pwm and value is None: <TAB>  <TAB> self._connection.write(self._number, 0) <TAB>  <TAB> self._pwm = False",if value != self . _connection . get_PWM_frequency ( self . _number ) :,196
"def literal(self): <TAB> if self.peek('""'): <TAB>  <TAB> lit, lang, dtype = self.eat(r_literal).groups() <MASK> lang = lang <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lang = None <TAB>  <TAB> if dtype: <TAB>  <TAB>  <TAB> dtype = dtype <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> dtype = None <TAB>  <TAB> if lang and dtype: <TAB>  <TAB>  <TAB> raise ParseError(""Can't have both a language and a datatype"") <TAB>  <TAB> lit = unquote(lit) <TAB>  <TAB> return Literal(lit, lang, dtype) <TAB> return False",if lang :,132
"def _staged_model_references(self, load_relationships=False): <TAB> for name, field in self._fields.items(): <TAB>  <TAB> if isinstance(field, BaseRelationship): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> if load_relationships: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value = getattr(self, name) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value = self.data_store.get(name, (""staged"", ""committed"")) <TAB>  <TAB>  <TAB> except (AttributeError, KeyError, PathResolutionError): <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB>  <TAB> if not isinstance(value, ModelCollection): <TAB>  <TAB>  <TAB>  <TAB> value = [value] <TAB>  <TAB>  <TAB> for related in value: <TAB>  <TAB>  <TAB>  <TAB> related_name = field.related_name <TAB>  <TAB>  <TAB>  <TAB> yield related, related_name",if value is None :,198
"def __call__(self, target): <TAB> # normal running mode <TAB> if not self.check_run_always: <TAB>  <TAB> for algo in self.algos: <TAB>  <TAB>  <TAB> if not algo(target): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True <TAB> # run mode when at least one algo has a run_always attribute <TAB> else: <TAB>  <TAB> # store result in res <TAB>  <TAB> # allows continuation to check for and run <TAB>  <TAB> # algos that have run_always set to True <TAB>  <TAB> res = True <TAB>  <TAB> for algo in self.algos: <TAB>  <TAB>  <TAB> if res: <TAB>  <TAB>  <TAB>  <TAB> res = algo(target) <TAB>  <TAB>  <TAB> elif hasattr(algo, ""run_always""): <MASK> algo(target) <TAB>  <TAB> return res",if algo . run_always :,188
"def addRow(self, row): <TAB> r = [] <TAB> for j in range(self.numColumn): <TAB>  <TAB> w, s = calWidth(row[j], self.maxWidth) <MASK> self.W[j] = w <TAB>  <TAB> r.append((w, s)) <TAB> self.M.append(r)",if w > self . W [ j ] :,90
"def parse(s): <TAB> text, anns = """", [] <TAB> # tweak text: remove space around annotations and strip space <TAB> s = re.sub(r""(<category[^<>]*>)( +)"", r""\2\1"", s) <TAB> s = re.sub(r""( +)(<\/category>)"", r""\2\1"", s) <TAB> rest = s.strip() <TAB> while True: <TAB>  <TAB> m = re.match(r'^(.*?)<category=""([^""]+)"">(.*?)</category>(.*)$', rest) <MASK> break <TAB>  <TAB> pre, type_, tagged, rest = m.groups() <TAB>  <TAB> text += pre <TAB>  <TAB> anns.append((len(text), len(text) + len(tagged), type_, tagged)) <TAB>  <TAB> text += tagged <TAB> text += rest <TAB> return text, anns",if not m :,196
"def _generate_examples(self, filepath): <TAB> with open(filepath) as f: <TAB>  <TAB> line_num = -1 <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> line_num += 1 <TAB>  <TAB>  <TAB> sentence = f.readline().strip() <TAB>  <TAB>  <TAB> pronoun = f.readline().strip() <TAB>  <TAB>  <TAB> candidates = [c.strip() for c in f.readline().strip().split("","")] <TAB>  <TAB>  <TAB> correct = f.readline().strip() <TAB>  <TAB>  <TAB> f.readline() <MASK> break <TAB>  <TAB>  <TAB> yield line_num, { <TAB>  <TAB>  <TAB>  <TAB> ""sentence"": sentence, <TAB>  <TAB>  <TAB>  <TAB> ""pronoun"": pronoun, <TAB>  <TAB>  <TAB>  <TAB> ""candidates"": candidates, <TAB>  <TAB>  <TAB>  <TAB> ""label"": candidates.index(correct), <TAB>  <TAB>  <TAB> }",if not sentence :,189
"def format_unencoded(self, tokensource, outfile): <MASK> self._write_lineno(outfile) <TAB> for ttype, value in tokensource: <TAB>  <TAB> color = self._get_color(ttype) <TAB>  <TAB> for line in value.splitlines(True): <TAB>  <TAB>  <TAB> if color: <TAB>  <TAB>  <TAB>  <TAB> outfile.write(""<%s>%s</>"" % (color, line.rstrip(""\n""))) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> outfile.write(line.rstrip(""\n"")) <TAB>  <TAB>  <TAB> if line.endswith(""\n""): <TAB>  <TAB>  <TAB>  <TAB> if self.linenos: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._write_lineno(outfile) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> outfile.write(""\n"") <TAB> if self.linenos: <TAB>  <TAB> outfile.write(""\n"")",if self . linenos :,190
"def refresh_pool_in_list(pool_list, conn, uuid): <TAB> for row in pool_list.get_model(): <MASK> # Update active sensitivity and percent available for passed uuid <TAB>  <TAB>  <TAB> row[3] = get_pool_size_percent(conn, uuid) <TAB>  <TAB>  <TAB> row[2] = conn.get_pool(uuid).is_active() <TAB>  <TAB>  <TAB> return",if row [ 0 ] == uuid :,103
"def save_claims_for_resolve(self, claim_infos): <TAB> to_save = {} <TAB> for info in claim_infos: <MASK> if info[""value""]: <TAB>  <TAB>  <TAB>  <TAB> to_save[info[""claim_id""]] = info <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for key in (""certificate"", ""claim""): <TAB>  <TAB>  <TAB>  <TAB> if info.get(key, {}).get(""value""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> to_save[info[key][""claim_id""]] = info[key] <TAB> return self.save_claims(to_save.values())","if ""value"" in info :",141
"def rx(self, text): <TAB> r = [] <TAB> for c in text: <MASK> r.append(c) <TAB>  <TAB> elif c < "" "": <TAB>  <TAB>  <TAB> r.append(unichr(0x2400 + ord(c))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> r.extend(unichr(0x2080 + ord(d) - 48) for d in ""{:d}"".format(ord(c))) <TAB>  <TAB>  <TAB> r.append("" "") <TAB> return """".join(r)","if "" "" <= c < ""\x7f"" or c in ""\r\n\b\t"" :",139
"def consume_bytes(data): <TAB> state_machine.receive_data(data) <TAB> while True: <TAB>  <TAB> event = state_machine.next_event() <TAB>  <TAB> if event is h11.NEED_DATA: <TAB>  <TAB>  <TAB> break <MASK> # Ignore 1xx responses <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif isinstance(event, h11.Response): <TAB>  <TAB>  <TAB> # We have our response! Save it and get out of here. <TAB>  <TAB>  <TAB> context[""h11_response""] = event <TAB>  <TAB>  <TAB> raise LoopAbort <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Can't happen <TAB>  <TAB>  <TAB> raise RuntimeError(""Unexpected h11 event {}"".format(event))","elif isinstance ( event , h11 . InformationalResponse ) :",166
"def validate_text(dialect, attr): <TAB> val = getattr(dialect, attr) <TAB> if not isinstance(val, text_type): <MASK> raise Error('""{0}"" must be string, not bytes'.format(attr)) <TAB>  <TAB> raise Error('""{0}"" must be string, not {1}'.format(attr, type(val).__name__)) <TAB> if len(val) != 1: <TAB>  <TAB> raise Error('""{0}"" must be a 1-character string'.format(attr))",if type ( val ) == bytes :,122
"def _refresh(self): <TAB> self.uiProfileSelectComboBox.clear() <TAB> self.uiProfileSelectComboBox.addItem(""default"") <TAB> try: <TAB>  <TAB> if os.path.exists(self.profiles_path): <TAB>  <TAB>  <TAB> for profile in sorted(os.listdir(self.profiles_path)): <MASK> self.uiProfileSelectComboBox.addItem(profile) <TAB> except OSError: <TAB>  <TAB> pass","if not profile . startswith ( ""."" ) :",107
"def get_entry(self, ip): <TAB> self.parse() <TAB> options = [] <TAB> for (line_type, components) in self._contents: <TAB>  <TAB> if line_type == ""option"": <TAB>  <TAB>  <TAB> (pieces, _tail) = components <MASK> options.append(pieces[1:]) <TAB> return options",if len ( pieces ) and pieces [ 0 ] == ip :,93
"def __new__(mcls, cls_name, bases, d): <TAB> offset = 0 <TAB> for base in bases: <TAB>  <TAB> for realbase in base.__mro__: <TAB>  <TAB>  <TAB> offset += len(realbase.__dict__.get(""_methods_"", [])) <TAB> for i, args in enumerate(d.get(""_methods_"", [])): <TAB>  <TAB> name = args[0] <TAB>  <TAB> restype = args[1] <MASK> continue <TAB>  <TAB> argtypes = args[2:] <TAB>  <TAB> m = COMMethod(name, offset + i, restype, argtypes) <TAB>  <TAB> d[name] = m <TAB> return type(ctypes.c_void_p).__new__(mcls, cls_name, bases, dict(d))",if restype is None :,170
"def _compare_caffe_tvm(caffe_out, tvm_out, is_network=False): <TAB> for i in range(len(caffe_out)): <MASK> caffe_out[i] = caffe_out[i][:1] <TAB>  <TAB> tvm.testing.assert_allclose(caffe_out[i], tvm_out[i], rtol=1e-5, atol=1e-5)",if is_network :,116
"def update_transcoder(self): <TAB> self.save_button.set_visible(False) <TAB> if self.cast and self.fn: <TAB>  <TAB> self.transcoder = Transcoder( <TAB>  <TAB>  <TAB> self.cast, <TAB>  <TAB>  <TAB> self.fn, <TAB>  <TAB>  <TAB> lambda did_transcode=None: GLib.idle_add(self.update_status, did_transcode), <TAB>  <TAB>  <TAB> self.transcoder, <TAB>  <TAB> ) <TAB>  <TAB> if self.autoplay: <TAB>  <TAB>  <TAB> self.autoplay = False <TAB>  <TAB>  <TAB> self.play_clicked(None) <TAB> else: <MASK> self.transcoder.destroy() <TAB>  <TAB>  <TAB> self.transcoder = None <TAB> GLib.idle_add(self.update_media_button_states)",if self . transcoder :,186
"def deserialize(x): <TAB> t = type(x) <TAB> if t is list: <TAB>  <TAB> return list(imap(deserialize, x)) <TAB> if t is dict: <TAB>  <TAB> if ""_id_"" not in x: <TAB>  <TAB>  <TAB> return {key: deserialize(val) for key, val in iteritems(x)} <TAB>  <TAB> obj = objmap.get(x[""_id_""]) <MASK> entity_name = x[""class""] <TAB>  <TAB>  <TAB> entity = database.entities[entity_name] <TAB>  <TAB>  <TAB> pk = x[""_pk_""] <TAB>  <TAB>  <TAB> obj = entity[pk] <TAB>  <TAB> return obj <TAB> return x",if obj is None :,150
"def release(self, conn, error=False): <TAB> if not conn.is_closed: <MASK> self.connections.append(conn) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.close_callable(conn)",if not error and len ( self . connections ) < self . pool_size :,71
"def install_symlinks(self): <TAB> """"""Create symlinks for some applications files."""""" <TAB> if self.has_symlinks(): <TAB>  <TAB> for app_path in self.app_path: <TAB>  <TAB>  <TAB> for symlink in self.symlinks.values(): <TAB>  <TAB>  <TAB>  <TAB> root = symlink[""root""] <TAB>  <TAB>  <TAB>  <TAB> dest = path.join(str(app_path), symlink[""dest""]) <MASK> self.backup.create(dest) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> symlink_file(root, dest)",if path . exists ( dest ) :,126
def _fill_array(): <TAB> global _array <TAB> for i in range(624): <TAB>  <TAB> y = (_array[i] & _bitmask2) + (_array[(i + 1) % 624] & _bitmask3) <TAB>  <TAB> _array[i] = _array[(i + 397) % 624] ^ (y >> 1) <MASK> _array[i] ^= 2567483615,if y % 2 != 0 :,107
"def parseLeftHandSideExpressionAllowCall(): <TAB> marker = None <TAB> expr = None <TAB> args = None <TAB> property = None <TAB> marker = createLocationMarker() <TAB> expr = parseNewExpression() if matchKeyword(""new"") else parsePrimaryExpression() <TAB> while (match(""."") or match(""["")) or match(""(""): <TAB>  <TAB> if match(""(""): <TAB>  <TAB>  <TAB> args = parseArguments() <TAB>  <TAB>  <TAB> expr = delegate.createCallExpression(expr, args) <TAB>  <TAB> elif match(""[""): <TAB>  <TAB>  <TAB> property = parseComputedMember() <TAB>  <TAB>  <TAB> expr = delegate.createMemberExpression(""["", expr, property) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> property = parseNonComputedMember() <TAB>  <TAB>  <TAB> expr = delegate.createMemberExpression(""."", expr, property) <MASK> marker.end() <TAB>  <TAB>  <TAB> marker.apply(expr) <TAB> return expr",if marker :,193
"def unregister_zombies(self): <TAB> """"""Unregister zombie builds (those whose builddir is gone)."""""" <TAB> from pprint import pprint <TAB> pprint(self.configs) <TAB> for build_num, config in self.configs.items(): <TAB>  <TAB> obj_dir_path = join( <TAB>  <TAB>  <TAB> config.buildDir, <TAB>  <TAB>  <TAB> _srcTreeName_from_config(config), <TAB>  <TAB>  <TAB> ""mozilla"", <TAB>  <TAB>  <TAB> config.mozObjDir, <TAB>  <TAB> ) <MASK> self.unregister(build_num, ""zombie (`%s' does not exist)"" % obj_dir_path)",if not exists ( obj_dir_path ) :,152
"def isUpdateAvailable(self, localOnly=False): <TAB> nsp = self.getLatestFile() <TAB> if not nsp: <TAB>  <TAB> if not nsp: <MASK> return True <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> try: <TAB>  <TAB> latest = self.lastestVersion(localOnly=localOnly) <TAB>  <TAB> if latest is None: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> if int(nsp.version) < int(latest): <TAB>  <TAB>  <TAB> return True <TAB> except BaseException as e: <TAB>  <TAB> Print.error(""isUpdateAvailable exception %s: %s"" % (self.id, str(e))) <TAB>  <TAB> pass <TAB> return False",if not self . isUpdate or ( self . version and int ( self . version ) > 0 ) :,179
"def verify_settings(rst_path: Path) -> Iterator[Error]: <TAB> for setting_name, default in find_settings_in_rst(rst_path): <TAB>  <TAB> actual = getattr(app.conf, setting_name) <MASK> default = default.total_seconds() <TAB>  <TAB> if isinstance(actual, Enum): <TAB>  <TAB>  <TAB> actual = actual.value <TAB>  <TAB> if actual != default: <TAB>  <TAB>  <TAB> yield Error( <TAB>  <TAB>  <TAB>  <TAB> reason=""mismatch"", <TAB>  <TAB>  <TAB>  <TAB> setting=setting_name, <TAB>  <TAB>  <TAB>  <TAB> default=default, <TAB>  <TAB>  <TAB>  <TAB> actual=actual, <TAB>  <TAB>  <TAB> )","if isinstance ( default , timedelta ) :",152
"def config_update(self, *updates): <TAB> filename = os.path.join(self.path, "".git"", ""config"") <TAB> with GitConfigParser(file_or_files=filename, read_only=False) as config: <TAB>  <TAB> for section, key, value in updates: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> old = config.get(section, key) <MASK> config.remove_option(section, key) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB>  <TAB> if old == value: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> except (NoSectionError, NoOptionError): <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> if value is not None: <TAB>  <TAB>  <TAB>  <TAB> config.set_value(section, key, value)",if value is None :,183
"def __init__(self, search_space): <TAB> self.params = {} <TAB> for key in search_space.keys(): <MASK> self.params[key] = Factor(search_space[key][""_value""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB> ""G_BFS Tuner doesn't support this kind of parameter: "" <TAB>  <TAB>  <TAB>  <TAB> + str(search_space[key][""_type""]) <TAB>  <TAB>  <TAB> )","if search_space [ key ] [ ""_type"" ] == ""factor"" :",125
"def largest_image_url(self): <TAB> # TODO: remove. it is not responsibility of Scrapper <TAB> if not self.imgs and not self.top_img: <TAB>  <TAB> return None <TAB> if self.top_img: <TAB>  <TAB> return self.top_img <TAB> max_area = 0 <TAB> max_url = None <TAB> for img_url in self.imgs: <TAB>  <TAB> dimension = fetch_image_dimension(img_url, self.useragent, referer=self.url) <TAB>  <TAB> area = self.calculate_area(img_url, dimension) <MASK> max_area = area <TAB>  <TAB>  <TAB> max_url = img_url <TAB> log.debug(""using max img {}"".format(max_url)) <TAB> return max_url",if area > max_area :,182
"def _geo_indices(cls, inspected=None): <TAB> inspected = inspected or [] <TAB> geo_indices = [] <TAB> inspected.append(cls) <TAB> for field in cls._fields.values(): <TAB>  <TAB> if hasattr(field, ""document_type""): <TAB>  <TAB>  <TAB> field_cls = field.document_type <TAB>  <TAB>  <TAB> if field_cls in inspected: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if hasattr(field_cls, ""_geo_indices""): <TAB>  <TAB>  <TAB>  <TAB> geo_indices += field_cls._geo_indices(inspected) <MASK> geo_indices.append(field) <TAB> return geo_indices",elif field . _geo_index :,155
"def __call__(self, trainer): <TAB> self._t += 1 <TAB> optimizer = self._get_optimizer(trainer) <TAB> value = self._init * (self._rate ** self._t) <TAB> if self._target is not None: <MASK> # almost same as value = min(value, self._target), but this <TAB>  <TAB>  <TAB> # line supports negative values, too <TAB>  <TAB>  <TAB> if value / self._target > 1: <TAB>  <TAB>  <TAB>  <TAB> value = self._target <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # ditto <TAB>  <TAB>  <TAB> if value / self._target < 1: <TAB>  <TAB>  <TAB>  <TAB> value = self._target <TAB> self._update_value(optimizer, value)",if self . _rate > 1 :,167
"def _parse_chunked(self, data): <TAB> body = [] <TAB> trailers = {} <TAB> n = 0 <TAB> lines = data.split(b""\r\n"") <TAB> # parse body <TAB> while True: <TAB>  <TAB> size, chunk = lines[n : n + 2] <TAB>  <TAB> size = int(size, 16) <MASK> n += 1 <TAB>  <TAB>  <TAB> break <TAB>  <TAB> self.assertEqual(size, len(chunk)) <TAB>  <TAB> body.append(chunk) <TAB>  <TAB> n += 2 <TAB>  <TAB> # we /should/ hit the end chunk, but check against the size of <TAB>  <TAB> # lines so we're not stuck in an infinite loop should we get <TAB>  <TAB> # malformed data <TAB>  <TAB> if n > len(lines): <TAB>  <TAB>  <TAB> break <TAB> return b"""".join(body)",if size == 0 :,191
"def _gen_opnds(ii):  # generator <TAB> # filter out write-mask operands and suppressed operands <TAB> for op in ii.parsed_operands: <TAB>  <TAB> if op.lookupfn_name in [""MASK1"", ""MASKNOT0""]: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if op.visibility == ""SUPPRESSED"": <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> yield op","if op . name == ""BCAST"" :",104
"def allow_request(self, request, view): <TAB> if settings.API_THROTTLING: <TAB>  <TAB> request_allowed = super(GranularUserRateThrottle, self).allow_request( <TAB>  <TAB>  <TAB> request, view <TAB>  <TAB> ) <TAB>  <TAB> if not request_allowed: <TAB>  <TAB>  <TAB> user = getattr(request, ""user"", None) <MASK> log.info(""User %s throttled for scope %s"", request.user, self.scope) <TAB>  <TAB>  <TAB>  <TAB> ActivityLog.create(amo.LOG.THROTTLED, self.scope, user=user) <TAB>  <TAB> return request_allowed <TAB> else: <TAB>  <TAB> return True",if user and request . user . is_authenticated :,164
"def _make_callback(self): <TAB> callback = self.callback <TAB> for plugin in self.all_plugins(): <TAB>  <TAB> try: <MASK> callback = plugin.apply(callback, self) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> callback = plugin(callback) <TAB>  <TAB> except RouteReset:  # Try again with changed configuration. <TAB>  <TAB>  <TAB> return self._make_callback() <TAB>  <TAB> if not callback is self.callback: <TAB>  <TAB>  <TAB> update_wrapper(callback, self.callback) <TAB> return callback","if hasattr ( plugin , ""apply"" ) :",131
"def OnDeleteLine(self, items): <TAB> for n in items: <TAB>  <TAB> if n >= 0: <TAB>  <TAB>  <TAB> name1 = self.items[n][2] <TAB>  <TAB>  <TAB> name2 = self.items[n][4] <TAB>  <TAB>  <TAB> del self.items[n] <MASK> self.bindiff.matched1.remove(name1) <TAB>  <TAB>  <TAB> if name2 in self.bindiff.matched2: <TAB>  <TAB>  <TAB>  <TAB> self.bindiff.matched2.remove(name2) <TAB> return [Choose.ALL_CHANGED] + items",if name1 in self . bindiff . matched1 :,146
"def on_treeview_buttonrelease(self, widget, event, data=None): <TAB> if self.promptToSave(): <TAB>  <TAB> # True result indicates user selected Cancel. Stop event propagation <TAB>  <TAB> return True <TAB> else: <TAB>  <TAB> x = int(event.x) <TAB>  <TAB> y = int(event.y) <TAB>  <TAB> time = event.time <TAB>  <TAB> pthinfo = widget.get_path_at_pos(x, y) <TAB>  <TAB> if pthinfo is not None: <TAB>  <TAB>  <TAB> path, col, cellx, celly = pthinfo <TAB>  <TAB>  <TAB> currentPath, currentCol = widget.get_cursor() <TAB>  <TAB>  <TAB> if currentPath != path: <TAB>  <TAB>  <TAB>  <TAB> widget.set_cursor(path, col, 0) <MASK> self.__popupMenu(event) <TAB>  <TAB> return False",if event . button == 3 :,198
"def __lt__(self, other): <TAB> try: <TAB>  <TAB> if self._version != other._version: <TAB>  <TAB>  <TAB> return self._version < other._version <TAB>  <TAB> if self._ip != other._ip: <TAB>  <TAB>  <TAB> return self._ip < other._ip <MASK> return self.netmask < other.netmask <TAB>  <TAB> return False <TAB> except AttributeError: <TAB>  <TAB> return NotImplemented",if self . netmask != other . netmask :,104
"def config_video_apply(self, dev_id_info): <TAB> df, da, add_define, hf, ha, add_hotplug = self.make_apply_data() <TAB> ignore = add_hotplug <TAB> if self.editted(EDIT_VIDEO_MODEL): <TAB>  <TAB> model = self.get_combo_label_value(""video-model"") <MASK> add_define(self.vm.define_video_model, dev_id_info, model) <TAB> return self._change_config_helper(df, da, hf, ha)",if model :,138
"def write(self, b): <TAB> if self._write_watcher is None: <TAB>  <TAB> raise UnsupportedOperation(""write"") <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return _write(self._fileno, b) <TAB>  <TAB> except (IOError, OSError) as ex: <MASK> raise <TAB>  <TAB> wait_on_watcher(self._write_watcher, None, None, self.hub)",if ex . args [ 0 ] not in ignored_errors :,110
"def scan_resource_conf(self, conf): <TAB> if ""enabled"" in conf and conf[""enabled""][0]: <TAB>  <TAB> retention_block = conf[""retention_policy""][0] <TAB>  <TAB> if retention_block[""enabled""][0]: <TAB>  <TAB>  <TAB> retention_in_days = force_int(retention_block[""days""][0]) <MASK> return CheckResult.PASSED <TAB> return CheckResult.FAILED",if retention_in_days and retention_in_days >= 90 :,118
"def _find_gist_with_file(user, filename, env): <TAB> import requests  # expensive <TAB> page = 1 <TAB> url = ""https://api.github.com/users/%s/gists"" % user <TAB> while True: <TAB>  <TAB> resp = requests.get( <TAB>  <TAB>  <TAB> url, <TAB>  <TAB>  <TAB> params={""page"": page, ""per_page"": 100}, <TAB>  <TAB>  <TAB> headers=_github_auth_headers(env), <TAB>  <TAB> ) <TAB>  <TAB> gists = resp.json() <TAB>  <TAB> if not gists: <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> for gist in gists: <TAB>  <TAB>  <TAB> for name in gist[""files""]: <MASK> return gist <TAB>  <TAB> page += 1",if name == filename :,178
"def parse_position_spec(self): <TAB> line = self.lookahead() <TAB> if line.startswith(""jump="") or line.startswith(""jcnd=""): <TAB>  <TAB> self.consume() <TAB>  <TAB> return True <TAB> mo = self._position_re.match(line) <TAB> if not mo: <TAB>  <TAB> return False <TAB> position, id, name = mo.groups() <TAB> if id: <TAB>  <TAB> table = self._position_table_map[position] <MASK> self.position_ids[(table, id)] = name <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = self.position_ids.get((table, id), """") <TAB> self.positions[self._position_map[position]] = name <TAB> self.consume() <TAB> return True",if name :,177
"def remove_header(self, header): <TAB> new_msg = b"""" <TAB> old_msg = self.msg_bytes.split(""\n"") <TAB> i = 0 <TAB> while True: <TAB>  <TAB> line = old_msg[i] <TAB>  <TAB> i += 1 <MASK> new_msg += line <TAB>  <TAB> if line == """": <TAB>  <TAB>  <TAB> break <TAB> new_msg += old_msg[i:] <TAB> self.msg_bytes = new_msg","if not line . startswith ( b""%s: "" % header ) :",122
"def on_janitor_selection_changed(self, selection): <TAB> model, iter = selection.get_selected() <TAB> if iter: <TAB>  <TAB> if self.janitor_model.iter_has_child(iter): <TAB>  <TAB>  <TAB> iter = self.janitor_model.iter_children(iter) <TAB>  <TAB> plugin = model[iter][self.JANITOR_PLUGIN] <TAB>  <TAB> for row in self.result_model: <MASK> self.result_view.get_selection().select_path(row.path) <TAB>  <TAB>  <TAB>  <TAB> log.debug(""scroll_to_cell: %s"" % row.path) <TAB>  <TAB>  <TAB>  <TAB> self.result_view.scroll_to_cell(row.path)",if row [ self . RESULT_PLUGIN ] == plugin :,184
"def record_line(self, frame, event, arg):  # pylint: disable=unused-argument <TAB> """"""Records line execution time."""""" <TAB> if event == ""line"": <MASK> runtime = time.time() - self.prev_timestamp <TAB>  <TAB>  <TAB> self.lines.append([self.prev_path, self.prev_lineno, runtime]) <TAB>  <TAB> self.prev_lineno = frame.f_lineno <TAB>  <TAB> self.prev_path = frame.f_code.co_filename <TAB>  <TAB> self.prev_timestamp = time.time() <TAB> return self.record_line",if self . prev_timestamp :,142
"def get_outdated_docs(self) -> Iterator[str]: <TAB> for docname in self.env.found_docs: <TAB>  <TAB> if docname not in self.env.all_docs: <TAB>  <TAB>  <TAB> yield docname <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> targetname = path.join(self.outdir, docname + self.out_suffix) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> targetmtime = path.getmtime(targetname) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> targetmtime = 0 <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> srcmtime = path.getmtime(self.env.doc2path(docname)) <MASK> yield docname <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> # source doesn't exist anymore <TAB>  <TAB>  <TAB> pass",if srcmtime > targetmtime :,176
"def _fetch_all_channels(self, force=False): <TAB> """"""Fetch all channel feeds from cache or network."""""" <TAB> channels = self._get_channel_configs(force=force) <TAB> enabled = self._settings.get([""enabled_channels""]) <TAB> forced = self._settings.get([""forced_channels""]) <TAB> all_channels = {} <TAB> for key, config in channels.items(): <MASK> continue <TAB>  <TAB> if ""url"" not in config: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> data = self._get_channel_data(key, config, force=force) <TAB>  <TAB> if data is not None: <TAB>  <TAB>  <TAB> all_channels[key] = data <TAB> return all_channels",if key not in enabled and key not in forced :,174
"def _get_cortex_binary(kmer, cortex_dir): <TAB> cortex_bin = None <TAB> for check_bin in sorted(glob.glob(os.path.join(cortex_dir, ""bin"", ""cortex_var_*""))): <TAB>  <TAB> kmer_check = int(os.path.basename(check_bin).split(""_"")[2]) <MASK> cortex_bin = check_bin <TAB>  <TAB>  <TAB> break <TAB> assert ( <TAB>  <TAB> cortex_bin is not None <TAB> ), ""Could not find cortex_var executable in %s for kmer %s"" % (cortex_dir, kmer) <TAB> return cortex_bin",if kmer_check >= kmer :,176
"def test_numeric_literals(self): <TAB> @udf(BigIntVal(FunctionContext, SmallIntVal)) <TAB> def fn(context, a): <MASK> return 1729 <TAB>  <TAB> elif a < 0: <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> elif a < 10: <TAB>  <TAB>  <TAB> return a + 5 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return a * 2",if a is None :,92
"def cs(self): <TAB> """"""ConfigSpace representation of this search space."""""" <TAB> cs = CS.ConfigurationSpace() <TAB> for k, v in self.kwvars.items(): <TAB>  <TAB> if isinstance(v, NestedSpace): <TAB>  <TAB>  <TAB> _add_cs(cs, v.cs, k) <MASK> hp = v.get_hp(name=k) <TAB>  <TAB>  <TAB> _add_hp(cs, hp) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _rm_hp(cs, k) <TAB> return cs","elif isinstance ( v , Space ) :",129
"def lineReceived(self, line): <TAB> if self.state == ""connected"": <TAB>  <TAB> self.messageFilename = line <TAB>  <TAB> self.state = ""gotMessageFilename"" <TAB> if self.state == ""gotMessageFilename"": <TAB>  <TAB> if line: <TAB>  <TAB>  <TAB> self.metaInfo.append(line) <TAB>  <TAB> else: <MASK> self.transport.loseConnection() <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> self.filterMessage()",if not self . metaInfo :,114
"def __init__(self, reg, shtype, shimm, va): <TAB> if shimm == 0: <MASK> shtype = S_RRX <TAB>  <TAB> elif shtype == S_LSR or shtype == S_ASR: <TAB>  <TAB>  <TAB> shimm = 32 <TAB> self.reg = reg <TAB> self.shtype = shtype <TAB> self.shimm = shimm <TAB> self.va = va",if shtype == S_ROR :,107
"def check_data(self, var_name: str, val: Dict[Any, Any]) -> None: <TAB> if not isinstance(val, dict): <TAB>  <TAB> raise AssertionError(f""{var_name} is not a dictionary"") <TAB> for key, value in val.items(): <MASK> raise AssertionError(f""{var_name} has a non-string key"") <TAB>  <TAB> check_data(self.value_type, f""{var_name}[{key}]"", value)","if not isinstance ( key , str ) :",118
"def write_conditional_formatting(worksheet): <TAB> """"""Write conditional formatting to xml."""""" <TAB> df = DifferentialStyle() <TAB> wb = worksheet.parent <TAB> for cf in worksheet.conditional_formatting: <TAB>  <TAB> for rule in cf.rules: <MASK> rule.dxfId = wb._differential_styles.add(rule.dxf) <TAB>  <TAB> yield cf.to_tree()",if rule . dxf and rule . dxf != df :,108
"def _find_wordpress_compiler(self): <TAB> """"""Find WordPress compiler plugin."""""" <TAB> if self.wordpress_page_compiler is not None: <TAB>  <TAB> return <TAB> plugin_info = self.site.plugin_manager.getPluginByName(""wordpress"", ""PageCompiler"") <TAB> if plugin_info is not None: <MASK> self.site.plugin_manager.activatePluginByName(plugin_info.name) <TAB>  <TAB>  <TAB> plugin_info.plugin_object.set_site(self.site) <TAB>  <TAB> self.wordpress_page_compiler = plugin_info.plugin_object",if not plugin_info . is_activated :,147
"def _confirm(config): <TAB> cli.out(""You are about to initialize a Guild environment:"") <TAB> for name, val in config.prompt_params: <MASK> cli.out(""  {}:"".format(name)) <TAB>  <TAB>  <TAB> for x in val: <TAB>  <TAB>  <TAB>  <TAB> cli.out("" <TAB> {}"".format(x)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> cli.out(""  {}: {}"".format(name, val)) <TAB> return cli.confirm(""Continue?"", default=True)","if isinstance ( val , tuple ) :",121
"def last_ok(nodes): <TAB> for i in range(len(nodes) - 1, -1, -1): <TAB>  <TAB> if ok_node(nodes[i]): <TAB>  <TAB>  <TAB> node = nodes[i] <MASK> if ok_node(node.value): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return node.value <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return nodes[i] <TAB> return None","if isinstance ( node , ast . Starred ) :",122
"def _is_binary(fname, limit=80): <TAB> try: <TAB>  <TAB> with open(fname, ""rb"") as f: <TAB>  <TAB>  <TAB> for i in range(limit): <TAB>  <TAB>  <TAB>  <TAB> char = f.read(1) <TAB>  <TAB>  <TAB>  <TAB> if char == b""\0"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB>  <TAB> if char == b""\n"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB>  <TAB> if char == b"""": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return <TAB> except OSError as e: <MASK> return True <TAB>  <TAB> raise e <TAB> return False",if xp . ON_WINDOWS and is_app_execution_alias ( fname ) :,154
"def render(self): <TAB> x = ""<span>"" <TAB> for idx, arg in enumerate(self.args, start=1): <TAB>  <TAB> if isinstance(arg, (tuple, list)): <TAB>  <TAB>  <TAB> value, desc = arg <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value, desc = arg, arg <TAB>  <TAB> attrs = self.attrs.copy() <TAB>  <TAB> attrs[""name""] = self.name <TAB>  <TAB> attrs[""type""] = ""radio"" <TAB>  <TAB> attrs[""value""] = value <TAB>  <TAB> attrs[""id""] = self.name + str(idx) <MASK> attrs[""checked""] = ""checked"" <TAB>  <TAB> x += ""<input %s/> %s"" % (attrs, net.websafe(desc)) <TAB> x += ""</span>"" <TAB> return x",if self . value == value :,183
"def test01b_gml(self): <TAB> ""Testing GML output."" <TAB> for g in self.geometries.wkt_out: <TAB>  <TAB> geom = OGRGeometry(g.wkt) <TAB>  <TAB> exp_gml = g.gml <MASK> # In GDAL 1.8, the non-conformant GML tag  <gml:GeometryCollection> was <TAB>  <TAB>  <TAB> # replaced with <gml:MultiGeometry>. <TAB>  <TAB>  <TAB> exp_gml = exp_gml.replace(""GeometryCollection"", ""MultiGeometry"") <TAB>  <TAB> self.assertEqual(exp_gml, geom.gml)","if GDAL_VERSION >= ( 1 , 8 ) :",159
"def _update_recording(self, frame, config): <TAB> """"""Adds a frame to the current video output."""""" <TAB> # pylint: disable=redefined-variable-type <TAB> should_record = config[""is_recording""] <TAB> if should_record: <MASK> self.is_recording = True <TAB>  <TAB>  <TAB> print( <TAB>  <TAB>  <TAB>  <TAB> ""Starting recording using %s"", self.video_writer.current_output().name() <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self.video_writer.write_frame(frame) <TAB> elif self.is_recording: <TAB>  <TAB> self.is_recording = False <TAB>  <TAB> self.video_writer.finish() <TAB>  <TAB> print(""Finished recording"")",if not self . is_recording :,166
"def activate(self, ctx): <TAB> for idx in ctx.chooser_selection: <TAB>  <TAB> func_ea = idaapi.getn_func(idx - 1).startEA <TAB>  <TAB> cfunc = helper.decompile_function(func_ea) <TAB>  <TAB> obj = api.VariableObject(cfunc.get_lvars()[0], 0) <MASK> NewDeepSearchVisitor(cfunc, 0, obj, cache.temporary_structure).process()",if cfunc :,108
"def finish(self, event, commit=0): <TAB> target = self.target <TAB> source = self.source <TAB> widget = self.initial_widget <TAB> root = self.root <TAB> try: <TAB>  <TAB> del root.__dnd <TAB>  <TAB> self.initial_widget.unbind(self.release_pattern) <TAB>  <TAB> self.initial_widget.unbind(""<Motion>"") <TAB>  <TAB> widget[""cursor""] = self.save_cursor <TAB>  <TAB> self.target = self.source = self.initial_widget = self.root = None <MASK> if commit: <TAB>  <TAB>  <TAB>  <TAB> target.dnd_commit(source, event) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> target.dnd_leave(source, event) <TAB> finally: <TAB>  <TAB> source.dnd_end(target, event)",if target :,188
"def run_epoch(model: BaseModel, loader, device: str, num_batches: int): <TAB> model.eval() <TAB> with Ctq(loader) as tq_loader: <TAB>  <TAB> for batch_idx, data in enumerate(tq_loader): <MASK> process(model, data, device) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> break",if batch_idx < num_batches :,99
"def find(d, target): <TAB> remainingDicts = [d] <TAB> while len(remainingDicts) > 0: <TAB>  <TAB> current = remainingDicts.pop() <TAB>  <TAB> for k, v in current.iteritems(): <MASK> return v <TAB>  <TAB>  <TAB> if isinstance(v, dict): <TAB>  <TAB>  <TAB>  <TAB> remainingDicts.insert(0, v) <TAB> return None",if k == target :,98
"def node_exists(self, jid=None, node=None, ifrom=None): <TAB> with self.lock: <TAB>  <TAB> if jid is None: <TAB>  <TAB>  <TAB> jid = self.xmpp.boundjid.full <TAB>  <TAB> if node is None: <TAB>  <TAB>  <TAB> node = """" <TAB>  <TAB> if ifrom is None: <TAB>  <TAB>  <TAB> ifrom = """" <TAB>  <TAB> if isinstance(ifrom, JID): <MASK> if (jid, node, ifrom) not in self.nodes: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True",ifrom = ifrom . full,136
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 8: <TAB>  <TAB>  <TAB> self.set_time(d.getVarInt64()) <TAB>  <TAB>  <TAB> continue <MASK> self.set_level(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 26: <TAB>  <TAB>  <TAB> self.set_log_message(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 16 :,152
"def _merge_dict(d1, d2): <TAB> # Modifies d1 in-place to take values from d2 <TAB> # if the nested keys from d2 are present in d1. <TAB> # https://stackoverflow.com/a/10704003/4488789 <TAB> for k, v2 in d2.items(): <TAB>  <TAB> v1 = d1.get(k)  # returns None if v1 has no such key <MASK> raise Exception(""{} is not recognized by client_config"".format(k)) <TAB>  <TAB> if isinstance(v1, Mapping) and isinstance(v2, Mapping): <TAB>  <TAB>  <TAB> _merge_dict(v1, v2) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> d1[k] = v2 <TAB> return d1",if v1 is None :,184
"def build_and_apply_filters(query, objects, filter_func): <TAB> if objects is not None: <TAB>  <TAB> if isinstance(objects, str): <TAB>  <TAB>  <TAB> query = query.filter(filter_func(objects)) <MASK> t = [] <TAB>  <TAB>  <TAB> for obj in objects: <TAB>  <TAB>  <TAB>  <TAB> t.append(filter_func(obj)) <TAB>  <TAB>  <TAB> query = query.filter(or_(*t)) <TAB> return query","elif isinstance ( objects , list ) :",111
"def _worker_task(self, num: int): <TAB> while True: <TAB>  <TAB> try_ = 0 <TAB>  <TAB> f = self.q.get() <TAB>  <TAB> while try_ <= self.retries: <TAB>  <TAB>  <TAB> rr = f() <MASK> break <TAB>  <TAB>  <TAB> try_ += 1 <TAB>  <TAB> with self.stat_lock: <TAB>  <TAB>  <TAB> self.exit_stat |= rr.ret_val <TAB>  <TAB> self.q.task_done()",if not rr . retry :,115
"def get_benchmark_id_title_map(input_tree): <TAB> input_root = input_tree.getroot() <TAB> ret = {} <TAB> for namespace in [XCCDF11_NS, XCCDF12_NS]: <TAB>  <TAB> candidates = [] <TAB>  <TAB> scrape_benchmarks(input_root, namespace, candidates) <TAB>  <TAB> for _, elem in candidates: <TAB>  <TAB>  <TAB> _id = elem.get(""id"") <MASK> continue <TAB>  <TAB>  <TAB> title = ""<unknown>"" <TAB>  <TAB>  <TAB> for element in elem.findall(""{%s}title"" % (namespace)): <TAB>  <TAB>  <TAB>  <TAB> title = element.text <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> ret[_id] = title <TAB> return ret",if _id is None :,171
"def _call_tensor_ufunc(self, x1, x2, out=None, where=None): <MASK> or hasattr(x2, ""__tensor_ufunc__""): <TAB>  <TAB> ufunc = ( <TAB>  <TAB>  <TAB> x1.__tensor_ufunc__ <TAB>  <TAB>  <TAB> if hasattr(x1, ""__tensor_ufunc__"") <TAB>  <TAB>  <TAB> else x2.__tensor_ufunc__ <TAB>  <TAB> ) <TAB>  <TAB> ret = ufunc(type(self), [x1, x2], out, where, **self.ufunc_extra_params) <TAB>  <TAB> if ret is NotImplemented: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> return ret","if hasattr ( x1 , ""__tensor_ufunc__"" )",146
"def remove_namespaces(xml): <TAB> for elem in xml.getiterator(): <TAB>  <TAB> if elem.tag is etree.Comment: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> i = elem.tag.find(""}"") <MASK> elem.tag = elem.tag[i + 1 :] <TAB> return xml",if i > 0 :,73
"def attributive(adjective, gender=MALE): <TAB> w = adjective.lower() <TAB> # normal => normales <TAB> if PLURAL in gender and not is_vowel(w[-1:]): <TAB>  <TAB> return w + ""es"" <TAB> # el chico inteligente => los chicos inteligentes <TAB> if PLURAL in gender and w.endswith((""a"", ""e"")): <TAB>  <TAB> return w + ""s"" <TAB> # el chico alto => los chicos altos <TAB> if w.endswith(""o""): <TAB>  <TAB> if FEMININE in gender and PLURAL in gender: <TAB>  <TAB>  <TAB> return w[:-1] + ""as"" <TAB>  <TAB> if FEMININE in gender: <TAB>  <TAB>  <TAB> return w[:-1] + ""a"" <MASK> return w + ""s"" <TAB> return w",if PLURAL in gender :,197
"def atbash(s): <TAB> translated = """" <TAB> for i in range(len(s)): <TAB>  <TAB> n = ord(s[i]) <TAB>  <TAB> if s[i].isalpha(): <TAB>  <TAB>  <TAB> if s[i].isupper(): <TAB>  <TAB>  <TAB>  <TAB> x = n - ord(""A"") <TAB>  <TAB>  <TAB>  <TAB> translated += chr(ord(""Z"") - x) <MASK> x = n - ord(""a"") <TAB>  <TAB>  <TAB>  <TAB> translated += chr(ord(""z"") - x) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> translated += s[i] <TAB> return translated",if s [ i ] . islower ( ) :,143
"def _add_all(self): <TAB> stream = BytesIO() <TAB> for page in self.graph_manager.pages: <TAB>  <TAB> stream.write(page.url.encode(""utf8"")) <MASK> for link in page.links: <TAB>  <TAB>  <TAB>  <TAB> stream.write(link.url.encode(""utf8"")) <TAB>  <TAB>  <TAB>  <TAB> stream.write(linesep.encode(""utf8"")) <TAB> stream.seek(0) <TAB> self.frontier.add_seeds(stream)",if not page . has_errors :,120
"def test_bigrand_ranges(self): <TAB> for i in [40, 80, 160, 200, 211, 250, 375, 512, 550]: <TAB>  <TAB> start = self.gen.randrange(2 ** i) <TAB>  <TAB> stop = self.gen.randrange(2 ** (i - 2)) <MASK> return <TAB>  <TAB> self.assertTrue(start <= self.gen.randrange(start, stop) < stop)",if stop <= start :,104
"def on_connect(self, request): <TAB> web_socket = WebSocketResponse() <TAB> await web_socket.prepare(request) <TAB> self.app[""websockets""].add(web_socket) <TAB> try: <TAB>  <TAB> async for msg in web_socket: <MASK> await self.on_status(None) <TAB>  <TAB>  <TAB> elif msg.type == WSMsgType.ERROR: <TAB>  <TAB>  <TAB>  <TAB> print( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""web socket connection closed with exception %s"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> % web_socket.exception() <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> finally: <TAB>  <TAB> self.app[""websockets""].discard(web_socket) <TAB> return web_socket",if msg . type == WSMsgType . TEXT :,177
"def __cut_all(self, sentence): <TAB> dag = self.get_DAG(sentence) <TAB> old_j = -1 <TAB> for k, L in iteritems(dag): <TAB>  <TAB> if len(L) == 1 and k > old_j: <TAB>  <TAB>  <TAB> yield sentence[k : L[0] + 1] <TAB>  <TAB>  <TAB> old_j = L[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for j in L: <MASK> yield sentence[k : j + 1] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> old_j = j",if j > k :,137
def filter_forms(forms): <TAB> result = [] <TAB> seen = set() <TAB> for form in forms: <TAB>  <TAB> if form in self._lemma_pos_offset_map: <MASK> if form not in seen: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> result.append(form) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> seen.add(form) <TAB> return result,if pos in self . _lemma_pos_offset_map [ form ] :,100
"def __init__(self, el): <TAB> self.elements = list(el) <TAB> parameters = {} <TAB> tokens = [] <TAB> token_quote = ""@"" <TAB> for key, value in el.attrib.items(): <TAB>  <TAB> if key == ""token_quote"": <TAB>  <TAB>  <TAB> token_quote = value <MASK> for token in value.split("",""): <TAB>  <TAB>  <TAB>  <TAB> tokens.append((token, REQUIRED_PARAMETER)) <TAB>  <TAB> elif key.startswith(""token_""): <TAB>  <TAB>  <TAB> token = key[len(""token_"") :] <TAB>  <TAB>  <TAB> tokens.append((token, value)) <TAB> for name, default in tokens: <TAB>  <TAB> parameters[name] = (token_quote, default) <TAB> self.parameters = parameters","if key == ""tokens"" :",170
"def setPositionAfterSort(self, sortChildren): <TAB> c = self <TAB> p = c.p <TAB> p_v = p.v <TAB> parent = p.parent() <TAB> parent_v = p._parentVnode() <TAB> if sortChildren: <TAB>  <TAB> p = parent or c.rootPosition() <TAB> else: <MASK> p = parent.firstChild() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> p = leoNodes.Position(parent_v.children[0]) <TAB>  <TAB> while p and p.v != p_v: <TAB>  <TAB>  <TAB> p.moveToNext() <TAB>  <TAB> p = p or parent <TAB> return p",if parent :,153
"def next(self): <TAB> while not self.closed or not self._buffer.empty(): <TAB>  <TAB> # input stream <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> chunck = next(self._input_iterator) <TAB>  <TAB>  <TAB>  <TAB> return chunck <TAB>  <TAB>  <TAB> except StopIteration: <TAB>  <TAB>  <TAB>  <TAB> self.closed = True <TAB>  <TAB>  <TAB>  <TAB> raise StopIteration() <TAB>  <TAB>  <TAB> except Exception as ex: <TAB>  <TAB>  <TAB>  <TAB> log.error(""Failed downloading: %s"" % ex) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # in/out stream <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> return self._buffer.get(block=True, timeout=1.0) <TAB>  <TAB>  <TAB> except Empty: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB> raise StopIteration()",if self . _input_iterator :,181
"def _gen_GreaterEqual(self, args, ret_type): <TAB> result = [] <TAB> for lhs, rhs in pairwise(args): <TAB>  <TAB> if ret_type == real_type: <TAB>  <TAB>  <TAB> result.append(self.builder.fcmp_ordered("">="", lhs, rhs)) <MASK> result.append(self.builder.icmp_signed("">="", lhs, rhs)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise CompileError() <TAB> return reduce(self.builder.and_, result)",elif ret_type == int_type :,120
"def save_settings(self, settings): <TAB> for setting in self.settings: <TAB>  <TAB> setting_obj = settings[setting] <TAB>  <TAB> new_value = self.cleaned_data.get(setting) <TAB>  <TAB> if setting_obj.python_type == ""image"": <MASK> self.save_image(setting_obj, new_value) <TAB>  <TAB>  <TAB> elif self.cleaned_data.get(""%s_delete"" % setting): <TAB>  <TAB>  <TAB>  <TAB> self.delete_image(setting_obj) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.save_setting(setting_obj, new_value)",if new_value and new_value != self . initial . get ( setting ) :,160
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> length = d.getVarInt32() <TAB>  <TAB>  <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB>  <TAB>  <TAB> d.skip(length) <TAB>  <TAB>  <TAB> self.add_events().TryMerge(tmp) <TAB>  <TAB>  <TAB> continue <MASK> self.set_timeout_seconds(d.getDouble()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 17 :,167
"def _trim_steps(self, num_steps): <TAB> """"""Trims a given number of steps from the end of the sequence."""""" <TAB> steps_trimmed = 0 <TAB> for i in reversed(range(len(self._events))): <TAB>  <TAB> if self._events[i].event_type == PolyphonicEvent.STEP_END: <MASK> del self._events[i + 1 :] <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> steps_trimmed += 1 <TAB>  <TAB> elif i == 0: <TAB>  <TAB>  <TAB> self._events = [ <TAB>  <TAB>  <TAB>  <TAB> PolyphonicEvent(event_type=PolyphonicEvent.START, pitch=None) <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB> break",if steps_trimmed == num_steps :,171
"def save(self): <TAB> data = self.cleaned_data <TAB> previous_data = google_integration_model.get_by_account_id(self.account_id) <TAB> if previous_data: <TAB>  <TAB> previous_file = previous_data.get(""file_id"") <TAB> else: <TAB>  <TAB> previous_file = None <TAB> json_key_file = data.get(""json_key"") <TAB> if json_key_file: <TAB>  <TAB> data[""file_id""] = files_model.add(json_key_file) <TAB>  <TAB> del data[""json_key""] <MASK> files_model.delete(previous_file) <TAB> google_integration_model.save(data, account_id=self.account_id)",if previous_file :,178
"def _register(self, class_): <TAB> with self.lock: <TAB>  <TAB> table, slots = self._schema(class_) <TAB>  <TAB> cur = self.db.execute(""PRAGMA table_info(%s)"" % table) <TAB>  <TAB> available = cur.fetchall() <MASK> available = [row[1] for row in available] <TAB>  <TAB>  <TAB> missing_slots = (s for s in slots if s not in available) <TAB>  <TAB>  <TAB> for slot in missing_slots: <TAB>  <TAB>  <TAB>  <TAB> self.db.execute(""ALTER TABLE %s ADD COLUMN %s TEXT"" % (table, slot)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.db.execute( <TAB>  <TAB>  <TAB>  <TAB> ""CREATE TABLE %s (%s)"" <TAB>  <TAB>  <TAB>  <TAB> % (table, "", "".join(""%s TEXT"" % s for s in slots)) <TAB>  <TAB>  <TAB> )",if available :,195
"def describe_auto_scaling_instances(self, instance_ids): <TAB> instance_states = [] <TAB> for group in self.autoscaling_groups.values(): <TAB>  <TAB> instance_states.extend( <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB> x <TAB>  <TAB>  <TAB>  <TAB> for x in group.instance_states <MASK> ] <TAB>  <TAB> ) <TAB> return instance_states",if not instance_ids or x . instance . id in instance_ids,104
"def add_nicknames(self, fields, data): <TAB> """"""Read the NICKNAME property of a VCard."""""" <TAB> for nick in self.split_unescaped(data, "",""): <TAB>  <TAB> nickname = nick.strip() <MASK> name = Name() <TAB>  <TAB>  <TAB> name.set_nick_name(self.unesc(nickname)) <TAB>  <TAB>  <TAB> self.person.add_alternate_name(name)",if nickname :,105
"def while1_test(a, b, c): <TAB> while 1: <MASK> if b: <TAB>  <TAB>  <TAB>  <TAB> a = 3 <TAB>  <TAB>  <TAB>  <TAB> b = 0 <TAB>  <TAB>  <TAB> elif c: <TAB>  <TAB>  <TAB>  <TAB> c = 0 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> a += b + c <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return a, b, c",if a != 2 :,94
"def get_stream(conf, reload=False): <TAB> if not conf: <TAB>  <TAB> return conf <TAB> # we can have 'stream' or 'class' or 'filename' <TAB> if ""class"" in conf: <TAB>  <TAB> class_name = conf.pop(""class"") <MASK> cls = globals()[class_name] <TAB>  <TAB>  <TAB> inst = cls(**conf) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> inst = resolve_name(class_name, reload=reload)(**conf) <TAB> elif ""stream"" in conf: <TAB>  <TAB> inst = conf[""stream""] <TAB> elif ""filename"" in conf: <TAB>  <TAB> inst = FileStream(**conf) <TAB> else: <TAB>  <TAB> raise ValueError(""stream configuration invalid"") <TAB> return {""stream"": inst}","if not ""."" in class_name :",179
"def check_physical(self, line): <TAB> """"""Run all physical checks on a raw input line."""""" <TAB> self.physical_line = line <TAB> for name, check, argument_names in self._physical_checks: <TAB>  <TAB> self.init_checker_state(name, argument_names) <TAB>  <TAB> result = self.run_check(check, argument_names) <MASK> (offset, text) = result <TAB>  <TAB>  <TAB> self.report_error(self.line_number, offset, text, check) <TAB>  <TAB>  <TAB> if text[:4] == ""E101"": <TAB>  <TAB>  <TAB>  <TAB> self.indent_char = line[0]",if result is not None :,154
"def delete_oidc_session_tokens(session): <TAB> if session: <TAB>  <TAB> if ""oidc_access_token"" in session: <TAB>  <TAB>  <TAB> del session[""oidc_access_token""] <TAB>  <TAB> if ""oidc_id_token"" in session: <TAB>  <TAB>  <TAB> del session[""oidc_id_token""] <TAB>  <TAB> if ""oidc_id_token_expiration"" in session: <TAB>  <TAB>  <TAB> del session[""oidc_id_token_expiration""] <MASK> del session[""oidc_login_next""] <TAB>  <TAB> if ""oidc_refresh_token"" in session: <TAB>  <TAB>  <TAB> del session[""oidc_refresh_token""] <TAB>  <TAB> if ""oidc_state"" in session: <TAB>  <TAB>  <TAB> del session[""oidc_state""]","if ""oidc_login_next"" in session :",179
"def _fix_exception_context(new_exc, old_exc): <TAB> # Context may not be correct, so find the end of the chain <TAB> while 1: <TAB>  <TAB> exc_context = new_exc.__context__ <TAB>  <TAB> if exc_context is old_exc: <TAB>  <TAB>  <TAB> # Context is already set correctly (see issue 20317) <TAB>  <TAB>  <TAB> return <MASK> break <TAB>  <TAB> new_exc = exc_context <TAB> # Change the end of the chain to point to the exception <TAB> # we expect it to reference <TAB> new_exc.__context__ = old_exc",if exc_context is None or exc_context is frame_exc :,151
"def _write_all(self, out): <TAB> while len(out) > 0: <TAB>  <TAB> n = self.sock.send(out) <TAB>  <TAB> if n <= 0: <TAB>  <TAB>  <TAB> raise EOFError() <MASK> return <TAB>  <TAB> out = out[n:] <TAB> return",if n == len ( out ) :,76
"def view(input_path): <TAB> if not exists(input_path): <TAB>  <TAB> raise IOError(""{0} not found"".format(input_path)) <TAB> ua = None <TAB> bundle_info = None <TAB> try: <TAB>  <TAB> archive = archive_factory(input_path) <MASK> raise NotMatched(""No matching archive type found"") <TAB>  <TAB> ua = archive.unarchive_to_temp() <TAB>  <TAB> bundle_info = ua.bundle.info <TAB> finally: <TAB>  <TAB> if ua is not None: <TAB>  <TAB>  <TAB> ua.remove() <TAB> return bundle_info",if archive is None :,139
"def _line_generator(fh, skip_blanks=False, strip=True): <TAB> for line in fh: <TAB>  <TAB> if strip: <TAB>  <TAB>  <TAB> line = line.strip() <TAB>  <TAB> skip = False <TAB>  <TAB> if skip_blanks: <TAB>  <TAB>  <TAB> skip = line.isspace() or not line <MASK> yield line",if not skip :,82
"def migrate_key(key, source, target): <TAB> if source in config and key in config[source]: <TAB>  <TAB> if config.get(target) is None: <TAB>  <TAB>  <TAB> # make sure we have a serial tree <TAB>  <TAB>  <TAB> config[target] = {} <MASK> # only copy over if it's not there yet <TAB>  <TAB>  <TAB> config[target][key] = config[source][key] <TAB>  <TAB> # delete feature flag <TAB>  <TAB> del config[source][key] <TAB>  <TAB> return True <TAB> return False",if key not in config [ target ] :,128
"def get_params(self): <TAB> if not hasattr(self, ""input_space""): <TAB>  <TAB> raise AttributeError(""Input space has not been provided."") <TAB> rval = [] <TAB> for layer in self.layers: <TAB>  <TAB> for param in layer.get_params(): <TAB>  <TAB>  <TAB> if param.name is None: <TAB>  <TAB>  <TAB>  <TAB> logger.info(type(layer)) <TAB>  <TAB> layer_params = layer.get_params() <TAB>  <TAB> assert not isinstance(layer_params, set) <TAB>  <TAB> for param in layer_params: <MASK> rval.append(param) <TAB> rval = [elem for elem in rval if elem not in self.freeze_set] <TAB> assert all([elem.name is not None for elem in rval]) <TAB> return rval",if param not in rval :,181
"def _build_kwargs_string(cls, expectation): <TAB> kwargs = [] <TAB> for k, v in expectation[""kwargs""].items(): <TAB>  <TAB> if k == ""column"": <TAB>  <TAB>  <TAB> # make the column a positional argument <TAB>  <TAB>  <TAB> kwargs.insert(0, ""{}='{}'"".format(k, v)) <MASK> # Put strings in quotes <TAB>  <TAB>  <TAB> kwargs.append(""{}='{}'"".format(k, v)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Pass other types as is <TAB>  <TAB>  <TAB> kwargs.append(""{}={}"".format(k, v)) <TAB> return "", "".join(kwargs)","elif isinstance ( v , str ) :",143
"def binary_search(_list, left, right, target): <TAB> if right >= left: <TAB>  <TAB> mid = (left + right) // 2 <TAB>  <TAB> # if element is present at the mid itself <TAB>  <TAB> if _list[mid] == target: <TAB>  <TAB>  <TAB> return mid <TAB>  <TAB> # If the element is smaller than mid, then it <TAB>  <TAB> # can only be present in the left subarray <MASK> return binary_search(_list, left, mid - 1, target) <TAB>  <TAB> # Else the element can only be present in the right <TAB>  <TAB> return binary_search(_list, mid + 1, right, target) <TAB> return False",if _list [ mid ] > target :,157
"def _set_name(self, name): <TAB> # Sanitize the file name so that it can't be dangerous. <TAB> if name is not None: <TAB>  <TAB> # Just use the basename of the file -- anything else is dangerous. <TAB>  <TAB> name = os.path.basename(name) <TAB>  <TAB> # File names longer than 255 characters can cause problems on older OSes. <MASK> name, ext = os.path.splitext(name) <TAB>  <TAB>  <TAB> name = name[: 255 - len(ext)] + ext <TAB> self._name = name",if len ( name ) > 255 :,132
"def scan_iter(self, match=None, count=None): <TAB> nodes = await self.cluster_nodes() <TAB> for node in nodes: <MASK> cursor = ""0"" <TAB>  <TAB>  <TAB> while cursor != 0: <TAB>  <TAB>  <TAB>  <TAB> pieces = [cursor] <TAB>  <TAB>  <TAB>  <TAB> if match is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pieces.extend([""MATCH"", match]) <TAB>  <TAB>  <TAB>  <TAB> if count is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pieces.extend([""COUNT"", count]) <TAB>  <TAB>  <TAB>  <TAB> response = await self.execute_command_on_nodes([node], ""SCAN"", *pieces) <TAB>  <TAB>  <TAB>  <TAB> cursor, data = list(response.values())[0] <TAB>  <TAB>  <TAB>  <TAB> for item in data: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield item","if ""master"" in node [ ""flags"" ] :",185
"def drf_url(context, viewname, *args, **kwargs): <TAB> """"""Helper for DjangoRestFramework's ``reverse`` in templates."""""" <TAB> request = context.get(""request"") <TAB> if request: <MASK> request.versioning_scheme = api_settings.DEFAULT_VERSIONING_CLASS() <TAB>  <TAB> request.version = request.versioning_scheme.determine_version( <TAB>  <TAB>  <TAB> request, *args, **kwargs <TAB>  <TAB> ) <TAB> return drf_reverse(viewname, request=request, args=args, kwargs=kwargs)","if not hasattr ( request , ""versioning_scheme"" ) :",140
"def __call__(self, ctx): <TAB> if ctx.range and ctx.value: <MASK> ctx.range.raw_value = ctx.value <TAB>  <TAB>  <TAB> return <TAB>  <TAB> scalar = ctx.meta.get(""scalar"", False) <TAB>  <TAB> if not scalar: <TAB>  <TAB>  <TAB> ctx.range = ctx.range.resize(len(ctx.value), len(ctx.value[0])) <TAB>  <TAB> self._write_value(ctx.range, ctx.value, scalar)",if self . raw :,117
"def removeNamedItemNS(self, namespaceURI, localName): <TAB> n = self.getNamedItemNS(namespaceURI, localName) <TAB> if n is not None: <TAB>  <TAB> _clear_id_cache(self._ownerElement) <TAB>  <TAB> del self._attrsNS[(n.namespaceURI, n.localName)] <TAB>  <TAB> del self._attrs[n.nodeName] <MASK> n.ownerElement = None <TAB>  <TAB> return n <TAB> else: <TAB>  <TAB> raise xml.dom.NotFoundErr()","if hasattr ( n , ""ownerElement"" ) :",129
"def __find_image(self, relpath): <TAB> image_path = None <TAB> for rp in self._resource_paths: <TAB>  <TAB> for root, dirs, files in os.walk(rp): <MASK> image_path = os.path.join(root, relpath) <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if image_path is not None: <TAB>  <TAB>  <TAB> break <TAB> return image_path",if relpath in files :,101
"def get_config_value(self, path, raise_if_not_found=True): <TAB> if not path.is_concrete(): <TAB>  <TAB> raise ValueError(""Can't access config by masked path: %s"" % path) <TAB> cfg = self._config <TAB> for key in path: <TAB>  <TAB> if key not in cfg: <MASK> raise ValueError(""Key not found: %r"" % key) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> cfg = cfg[key] <TAB> return cfg",if raise_if_not_found :,132
"def unbind(**kwargs): <TAB> for event, callback in kwargs.items(): <MASK> raise Exception(""Unknown {!r} event"".format(event)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for listener in _callbacks[event][:]: <TAB>  <TAB>  <TAB>  <TAB> if listener.callback == callback: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _callbacks[event].remove(listener) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if event == ""on_new_intent"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _activity.unregisterNewIntentListener(listener) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> elif event == ""on_activity_result"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _activity.unregisterActivityResultListener(listener)",if event not in _callbacks :,156
"def _escape_attrib(text): <TAB> # escape attribute value <TAB> try: <TAB>  <TAB> if ""&"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""&"", ""&amp;"") <TAB>  <TAB> if ""<"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""<"", ""&lt;"") <TAB>  <TAB> if "">"" in text: <TAB>  <TAB>  <TAB> text = text.replace("">"", ""&gt;"") <MASK> text = text.replace('""', ""&quot;"") <TAB>  <TAB> if ""\n"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""\n"", ""&#10;"") <TAB>  <TAB> return text <TAB> except (TypeError, AttributeError):  # pragma: no cover <TAB>  <TAB> _raise_serialization_error(text)","if '""' in text :",160
"def _get_options(self, kwargs): <TAB> options = {} <TAB> for option in self._options: <MASK> self._validate_option(option, kwargs[option]) <TAB>  <TAB>  <TAB> options[option] = kwargs[option] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> options[option] = getattr(self, ""_"" + option) <TAB> return options",if option in kwargs :,88
"def _parse_version_parts(s): <TAB> for part in component_re.split(s): <TAB>  <TAB> part = replace(part, part) <MASK> continue <TAB>  <TAB> if part[:1] in ""0123456789"": <TAB>  <TAB>  <TAB> yield part.zfill(8)  # pad for numeric comparison <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield ""*"" + part <TAB> yield ""*final""  # ensure that alpha/beta/candidate are before final","if part in [ """" , ""."" ] :",109
def collect_deps(lib): <TAB> queue = list(lib.deps_all) <TAB> visited = set(queue) <TAB> visited.add(lib) <TAB> deps = [] <TAB> # Traverse dependencies with breadth-first search. <TAB> while queue: <TAB>  <TAB> # Collect dependencies for next queue. <TAB>  <TAB> next_queue = [] <TAB>  <TAB> for lib in queue: <TAB>  <TAB>  <TAB> for dep in lib.deps_all: <MASK> next_queue.append(dep) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> visited.add(dep) <TAB>  <TAB> # Append current queue to result. <TAB>  <TAB> deps.append(collect_path_sorted_lib_idxs(queue)) <TAB>  <TAB> queue = next_queue <TAB> return deps,if dep not in visited :,174
"def process_chunks(self, chunks): <TAB> chunk_id = self._chunk_id <TAB> self._chunk_id += len(chunks) <TAB> chunk_data = [] <TAB> for chunk in chunks: <MASK> msg = ""Metric data exceeds maximum size of {} bytes. Dropping it."".format( <TAB>  <TAB>  <TAB>  <TAB> MAX_LINE_SIZE <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> wandb.termerror(msg, repeat=False) <TAB>  <TAB>  <TAB> util.sentry_message(msg) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> chunk_data.append(chunk.data) <TAB> return { <TAB>  <TAB> ""offset"": chunk_id, <TAB>  <TAB> ""content"": chunk_data, <TAB> }",if len ( chunk . data ) > MAX_LINE_SIZE :,177
"def truncateLogFile(): <TAB> global logfilename <TAB> logger.warn(""Truncating log file %s"" % logfilename) <TAB> with open(logfilename, ""w"") as f: <TAB>  <TAB> f.write("""") <TAB> for i in range(1, 25): <TAB>  <TAB> rotatedFilename = ""%s.%d"" % (logfilename, i) <MASK> logger.info(""Deleting rotated file %s"" % rotatedFilename) <TAB>  <TAB>  <TAB> os.unlink(rotatedFilename)",if os . path . exists ( rotatedFilename ) :,121
"def _page_contains(self, text): <TAB> browser = self._current_browser() <TAB> browser.switch_to_default_content() <TAB> if self._is_text_present(text): <TAB>  <TAB> return True <TAB> subframes = self._element_find(""xpath=//frame|//iframe"", False, False) <TAB> self._debug(""Current frame has %d subframes"" % len(subframes)) <TAB> for frame in subframes: <TAB>  <TAB> browser.switch_to_frame(frame) <TAB>  <TAB> found_text = self._is_text_present(text) <TAB>  <TAB> browser.switch_to_default_content() <MASK> return True <TAB> return False",if found_text :,163
"def get_project_name_git(): <TAB> is_git = check_output([""git"", ""rev-parse"", ""--git-dir""], stderr=subprocess.STDOUT) <TAB> if is_git: <TAB>  <TAB> project_address = check_output( <TAB>  <TAB>  <TAB> [""git"", ""config"", ""--local"", ""remote.origin.url""] <TAB>  <TAB> ) <MASK> project_address = project_address.decode() <TAB>  <TAB> project_name = [i for i in re.split(r""[/:\s\\]|\.git"", project_address) if i][ <TAB>  <TAB>  <TAB> -1 <TAB>  <TAB> ] <TAB>  <TAB> return project_name.strip()","if isinstance ( project_address , bytes ) and str != bytes :",164
"def timer(ratio, step, additive): <TAB> t = 0 <TAB> slowmode = False <TAB> while 1: <MASK> slowmode |= bool((yield t)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> slowmode = bool((yield t)) <TAB>  <TAB> if slowmode: <TAB>  <TAB>  <TAB> t += step * ratio <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> t += step",if additive :,89
"def _call_connection_lost(self, exc): <TAB> try: <TAB>  <TAB> if self._protocol_connected: <TAB>  <TAB>  <TAB> self._protocol.connection_lost(exc) <TAB> finally: <TAB>  <TAB> self._sock.close() <TAB>  <TAB> self._sock = None <TAB>  <TAB> self._protocol = None <TAB>  <TAB> self._loop = None <TAB>  <TAB> server = self._server <MASK> server._detach() <TAB>  <TAB>  <TAB> self._server = None",if server is not None :,112
def _think(self): <TAB> try: <MASK> random.choice(self.peers.values()).send_getaddrs(count=8) <TAB> except: <TAB>  <TAB> log.err() <TAB> return random.expovariate(1 / 20),if len ( self . addr_store ) < self . preferred_storage and self . peers :,84
def merge_force_collapse(self): <TAB> p = self.pending <TAB> while len(p) > 1: <MASK> self.merge_at(-3) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.merge_at(-2),if len ( p ) >= 3 and p [ - 3 ] . len < p [ - 1 ] . len :,79
"def ensure_echo_on(): <TAB> if termios: <TAB>  <TAB> fd = sys.stdin <TAB>  <TAB> if fd.isatty(): <TAB>  <TAB>  <TAB> attr_list = termios.tcgetattr(fd) <TAB>  <TAB>  <TAB> if not attr_list[3] & termios.ECHO: <TAB>  <TAB>  <TAB>  <TAB> attr_list[3] |= termios.ECHO <MASK> old_handler = signal.signal(signal.SIGTTOU, signal.SIG_IGN) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> old_handler = None <TAB>  <TAB>  <TAB>  <TAB> termios.tcsetattr(fd, termios.TCSANOW, attr_list) <TAB>  <TAB>  <TAB>  <TAB> if old_handler is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> signal.signal(signal.SIGTTOU, old_handler)","if hasattr ( signal , ""SIGTTOU"" ) :",197
"def change_palette_name(self, palette_name): <TAB> if isinstance(palette_name, str): <MASK> log.info(""Palette name %s not found"", palette_name) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> log.debug(""Settings palette name to %s"", palette_name) <TAB>  <TAB> self.settings.styleFont.set_string(""palette"", PALETTES[palette_name]) <TAB>  <TAB> self.settings.styleFont.set_string(""palette-name"", palette_name) <TAB>  <TAB> self.set_colors_from_settings()",if palette_name not in PALETTES :,142
"def nested_match(expect, value): <TAB> if expect == value: <TAB>  <TAB> return True <TAB> if isinstance(expect, dict) and isinstance(value, dict): <TAB>  <TAB> for k, v in expect.items(): <TAB>  <TAB>  <TAB> if k in value: <MASK> return False <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True <TAB> if isinstance(expect, list) and isinstance(value, list): <TAB>  <TAB> for x, y in zip(expect, value): <TAB>  <TAB>  <TAB> if not nested_match(x, y): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True <TAB> return False","if not nested_match ( v , value [ k ] ) :",162
"def _on_event(self, event): <TAB> event_id = event[""event_id""] <TAB> if event_id == MpvEventID.END_FILE: <TAB>  <TAB> reason = event[""event""][""reason""] <TAB>  <TAB> logger.debug(""Current song finished. reason: %d"" % reason) <MASK> self.media_finished.emit() <TAB> elif event_id == MpvEventID.FILE_LOADED: <TAB>  <TAB> self.media_loaded.emit()",if self . state != State . stopped and reason != MpvEventEndFile . ABORTED :,131
"def __exit__(self, exc_type, exc_value, traceback): <TAB> self.close() <TAB> with DB.connection_context(): <TAB>  <TAB> rows = ( <TAB>  <TAB>  <TAB> SessionRecord.delete() <TAB>  <TAB>  <TAB> .where(SessionRecord.f_session_id == self._session_id) <TAB>  <TAB>  <TAB> .execute() <TAB>  <TAB> ) <MASK> LOGGER.debug(f""delete session {self._session_id} record"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> LOGGER.warning(f""failed delete session {self._session_id} record"")",if rows > 0 :,138
"def decorator(*args, **kwargs): <TAB> # Sets a boolean on the global request context <TAB> g._flask_user_allow_unconfirmed_email = True <TAB> # Catch exceptions to properly unset boolean on exceptions <TAB> try: <TAB>  <TAB> user_manager = current_app.user_manager <TAB>  <TAB> # User must be logged in with a confirmed email address <TAB>  <TAB> allowed = _is_logged_in_with_confirmed_email(user_manager) <MASK> # Redirect to unauthenticated page <TAB>  <TAB>  <TAB> return user_manager.unauthenticated_view() <TAB>  <TAB> # It's OK to call the view <TAB>  <TAB> return view_function(*args, **kwargs) <TAB> finally: <TAB>  <TAB> # Allways unset the boolean, whether exceptions occurred or not <TAB>  <TAB> g._flask_user_allow_unconfirmed_email = False",if not allowed :,190
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_app_id(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> self.set_limit(d.getVarInt64()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 16 :,122
"def addOptions(parser): <TAB> for optname in options.keys(""default""): <MASK> continue <TAB>  <TAB> action = ""store_true"" if options[optname] is False else ""store"" <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> parser.add_argument( <TAB>  <TAB>  <TAB>  <TAB> ""--"" + optname.replace(""_"", ""-""), <TAB>  <TAB>  <TAB>  <TAB> action=action, <TAB>  <TAB>  <TAB>  <TAB> dest=optname, <TAB>  <TAB>  <TAB>  <TAB> default=None, <TAB>  <TAB>  <TAB>  <TAB> help=options._opts._get(optname).helpstr, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> except argparse.ArgumentError: <TAB>  <TAB>  <TAB> pass","if optname . startswith ( ""color_"" ) or optname . startswith ( ""disp_"" ) :",152
"def make_relative_to(self, kwds, relative_to): <TAB> if relative_to and os.path.dirname(relative_to): <TAB>  <TAB> dirname = os.path.dirname(relative_to) <TAB>  <TAB> kwds = kwds.copy() <TAB>  <TAB> for key in ffiplatform.LIST_OF_FILE_NAMES: <MASK> lst = kwds[key] <TAB>  <TAB>  <TAB>  <TAB> if not isinstance(lst, (list, tuple)): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise TypeError(""keyword '%s' should be a list or tuple"" % (key,)) <TAB>  <TAB>  <TAB>  <TAB> lst = [os.path.join(dirname, fn) for fn in lst] <TAB>  <TAB>  <TAB>  <TAB> kwds[key] = lst <TAB> return kwds",if key in kwds :,173
"def _options_fcheck(self, name, xflags, table): <TAB> for entry in table: <MASK> break <TAB>  <TAB> if entry.flags & XTOPT_MAND and not xflags & (1 << entry.id): <TAB>  <TAB>  <TAB> raise XTablesError(""%s: --%s must be specified"" % (name, entry.name)) <TAB>  <TAB>  <TAB> if not xflags & (1 << entry.id): <TAB>  <TAB>  <TAB>  <TAB> continue",if entry . name is None :,112
"def _load_cmds(): <TAB> prefix = ""AOE_CMD_"" <TAB> g = globals() <TAB> for k, v in iteritems(g): <MASK> name = ""aoe"" + k[len(prefix) :].lower() <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> mod = __import__(name, g, level=1) <TAB>  <TAB>  <TAB>  <TAB> AOE.set_cmd(v, getattr(mod, name.upper())) <TAB>  <TAB>  <TAB> except (ImportError, AttributeError): <TAB>  <TAB>  <TAB>  <TAB> continue",if k . startswith ( prefix ) :,128
"def test_list_sizes(self): <TAB> sizes = self.driver.list_sizes() <TAB> self.assertEqual(len(sizes), 7, ""Wrong sizes count"") <TAB> for size in sizes: <TAB>  <TAB> self.assertTrue(isinstance(size.price, float), ""Wrong size price type"") <MASK> self.assertEqual(size.price, 0, ""Size price should be zero by default"")","if self . driver . api_name == ""openstack"" :",105
"def testToFileBinary(self): <TAB> z = dns.zone.from_file(here(""example""), ""example"") <TAB> try: <TAB>  <TAB> f = open(here(""example3-binary.out""), ""wb"") <TAB>  <TAB> z.to_file(f) <TAB>  <TAB> f.close() <TAB>  <TAB> ok = compare_files( <TAB>  <TAB>  <TAB> ""testToFileBinary"", here(""example3-binary.out""), here(""example3.good"") <TAB>  <TAB> ) <TAB> finally: <MASK> os.unlink(here(""example3-binary.out"")) <TAB> self.assertTrue(ok)",if not _keep_output :,146
"def ip_list(_): <TAB> ips = [] <TAB> for ip in _.split("" ""): <MASK> continue <TAB>  <TAB> elif isip(ip): <TAB>  <TAB>  <TAB> ips.append(IP.create(ip)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError(""ip %s is invalid"" % ip) <TAB> return ips",if not ip :,82
"def _wait_for_state(self, server_id, state, retries=50): <TAB> for i in (0, retries): <TAB>  <TAB> server = self.ex_get_server(server_id) <TAB>  <TAB> if server.extra[""status""][""state""] == state: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> sleep(5) <MASK> raise Exception(""Retries count reached"")",if i == retries :,95
"def _stretch_prev(data): <TAB> clip, track, item_id, item_data = data <TAB> try: <TAB>  <TAB> prev_index = track.clips.index(clip) - 1 <TAB>  <TAB> if prev_index < 0: <TAB>  <TAB>  <TAB> return  # clip is first clip <MASK> # Next clip is blank so we can do this. <TAB>  <TAB>  <TAB> clip = track.clips[prev_index] <TAB>  <TAB>  <TAB> data = (clip, track, item_id, item_data) <TAB>  <TAB>  <TAB> _cover_blank_from_next(data, True) <TAB> except: <TAB>  <TAB> pass  # any error means that this can't be done",if track . clips [ prev_index ] . is_blanck_clip == True :,173
"def characters(self, ch): <TAB> if self._inside_fuzzable: <TAB>  <TAB> modified_value = self._fuzzed_parameters[self._fuzzable_index][1] <MASK> modified_value = modified_value.get_value() <TAB>  <TAB> if self._fuzzed_parameters[self._fuzzable_index][0] == ""base64"": <TAB>  <TAB>  <TAB> enc_val = base64.b64encode(modified_value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> enc_val = cgi.escape(modified_value).encode(""ascii"", ""xmlcharrefreplace"") <TAB>  <TAB> self.fuzzed_xml_string += enc_val <TAB> else: <TAB>  <TAB> self.fuzzed_xml_string += ch","if isinstance ( modified_value , DataToken ) :",181
"def _make_sure_scheduler_ready(self, timeout=120): <TAB> check_start_time = time.time() <TAB> while True: <TAB>  <TAB> workers_meta = self._scheduler_service._resource_ref.get_workers_meta() <MASK> # wait for worker to report status <TAB>  <TAB>  <TAB> self._pool.sleep(0.5) <TAB>  <TAB>  <TAB> if time.time() - check_start_time > timeout:  # pragma: no cover <TAB>  <TAB>  <TAB>  <TAB> raise TimeoutError(""Check worker ready timed out."") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break",if not workers_meta :,139
"def tiles_around(self, pos, radius=1, predicate=None): <TAB> ps = [] <TAB> x, y = pos <TAB> for dx in range(-radius, radius + 1): <TAB>  <TAB> nx = x + dx <TAB>  <TAB> if nx >= 0 and nx < self.width: <TAB>  <TAB>  <TAB> for dy in range(-radius, radius + 1): <TAB>  <TAB>  <TAB>  <TAB> ny = y + dy <MASK> if predicate is None or predicate((nx, ny)): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ps.append((nx, ny)) <TAB> return ps",if ny >= 0 and ny < self . height and ( dx != 0 or dy != 0 ) :,151
"def tearDown(self): <TAB> for i in ScriptVersion.objects.all(): <TAB>  <TAB> name = i.script_path.name <TAB>  <TAB> utils.get_storage().delete(name) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> utils.get_storage(local=False).delete(name) <TAB>  <TAB>  <TAB> except WindowsError: <TAB>  <TAB>  <TAB>  <TAB> print(""unable to delete {}"".format(name)) <TAB>  <TAB> name += ""c""  # handle pyc junk <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> utils.get_storage().delete(name) <TAB>  <TAB> except WindowsError: <TAB>  <TAB>  <TAB> print(""unable to delete {}"".format(name)) <TAB> super(ScriptTearDown, self).tearDown()",if wooey_settings . WOOEY_EPHEMERAL_FILES :,177
"def _fill_tc_results(self): <TAB> tids = list(self.tc._results.keys()) <TAB> fields = [""failures"", ""errors"", ""skipped"", ""expectedFailures""] <TAB> for tid in tids: <TAB>  <TAB> result = self.tc._results[tid] <TAB>  <TAB> for field in fields: <MASK> self.tc._results[field] = [] <TAB>  <TAB>  <TAB> self.tc._results[field].extend(result[field])",if not field in self . tc . _results :,119
"def check_mixin_inheritance(bases): <TAB> for b in bases: <TAB>  <TAB> check_mixin_inheritance(b.__bases__) <TAB>  <TAB> for k, v in vars(b).items(): <MASK> _type_info[k] = _process_item(v)","if _is_interesting ( k , v ) :",78
"def _check_params(swa_freq): <TAB> params = [swa_freq] <TAB> params_none = [param is None for param in params] <TAB> if not all(params_none) and any(params_none): <TAB>  <TAB> warnings.warn(""Some of swa_start, swa_freq is None, ignoring other"") <TAB> for i, param in enumerate(params): <MASK> params[i] = int(param) <TAB>  <TAB>  <TAB> warnings.warn(""Casting swa_start, swa_freq to int"") <TAB> return not any(params_none), params","if param is not None and not isinstance ( param , int ) :",145
"def findBookmark(self, bookmark, root=None): <TAB> if root == None: <TAB>  <TAB> root = self.bookmarks <TAB> for i, b in enumerate(root): <TAB>  <TAB> if isinstance(b, list): <TAB>  <TAB>  <TAB> res = self.findBookmark(bookmark, b) <MASK> return [i] + res <TAB>  <TAB> elif b == bookmark or b[""/Title""] == bookmark: <TAB>  <TAB>  <TAB> return [i] <TAB> return None",if res :,116
"def best_match(self, matches, default=None): <TAB> best_quality = -1 <TAB> result = default <TAB> for server_item in matches: <TAB>  <TAB> for client_item, quality in self: <MASK> break <TAB>  <TAB>  <TAB> if self._value_matches(server_item, client_item) and quality > 0: <TAB>  <TAB>  <TAB>  <TAB> best_quality = quality <TAB>  <TAB>  <TAB>  <TAB> result = server_item <TAB> return result",if quality <= best_quality :,113
"def validate_external_users(self): <TAB> if self.user and settings.ALLOW_OAUTH2_FOR_EXTERNAL_USERS is False: <TAB>  <TAB> external_account = get_external_account(self.user) <MASK> raise oauth2.AccessDeniedError( <TAB>  <TAB>  <TAB>  <TAB> _( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""OAuth2 Tokens cannot be created by users associated with an external authentication provider ({})"" <TAB>  <TAB>  <TAB>  <TAB> ).format(external_account) <TAB>  <TAB>  <TAB> )",if external_account is not None :,118
def get_tzname(self): <TAB> # Timezone conversions must happen to the input datetime *before* <TAB> # applying a function. 2015-12-31 23:00:00 -02:00 is stored in the <TAB> # database as 2016-01-01 01:00:00 +00:00. Any results should be <TAB> # based on the input datetime not the stored datetime. <TAB> tzname = None <TAB> if settings.USE_TZ: <MASK> tzname = timezone.get_current_timezone_name() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tzname = timezone._get_timezone_name(self.tzinfo) <TAB> return tzname,if self . tzinfo is None :,158
"def _get_editable_fields(cls): <TAB> fds = set([]) <TAB> for field in cls._meta.concrete_fields: <TAB>  <TAB> if hasattr(field, ""attname""): <TAB>  <TAB>  <TAB> if field.attname == ""id"": <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> elif field.attname.endswith(""ptr_id""): <TAB>  <TAB>  <TAB>  <TAB> # polymorphic fields should always be non-editable, see: <TAB>  <TAB>  <TAB>  <TAB> # https://github.com/django-polymorphic/django-polymorphic/issues/349 <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> fds.add(field.attname) <TAB> return fds","if getattr ( field , ""editable"" , True ) :",159
"def p_advsimd_secondary(val, va, mnem, opcode, flags, opers): <TAB> if opcode == INS_VORR: <TAB>  <TAB> src1 = (val >> 16) & 0xF <TAB>  <TAB> src2 = (val) & 0xF <MASK> opers = ( <TAB>  <TAB>  <TAB>  <TAB> ArmRegOper(rctx.getRegisterIndex(rbase % d)), <TAB>  <TAB>  <TAB>  <TAB> ArmRegOper(rctx.getRegisterIndex(rbase % n)), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return ""vmov"", INS_VMOV, None, opers <TAB> return None, None, None, None",if src1 == src2 :,157
"def list_urls(self): <TAB> for idx, job in enumerate(self.urlwatcher.jobs): <MASK> print(""%d: %s"" % (idx + 1, repr(job))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pretty_name = job.pretty_name() <TAB>  <TAB>  <TAB> location = job.get_location() <TAB>  <TAB>  <TAB> if pretty_name != location: <TAB>  <TAB>  <TAB>  <TAB> print(""%d: %s ( %s )"" % (idx + 1, pretty_name, location)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> print(""%d: %s"" % (idx + 1, pretty_name)) <TAB> return 0",if self . urlwatch_config . verbose :,157
"def _split_auth_string(auth_string): <TAB> """"""split a digest auth string into individual key=value strings"""""" <TAB> prev = None <TAB> for item in auth_string.split("",""): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if prev.count('""') == 1: <TAB>  <TAB>  <TAB>  <TAB> prev = ""%s,%s"" % (prev, item) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> except AttributeError: <MASK> prev = item <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise StopIteration <TAB>  <TAB> yield prev.strip() <TAB>  <TAB> prev = item <TAB> yield prev.strip() <TAB> raise StopIteration",if prev == None :,152
"def _get_user_auth_session_cookie(self, url, username, password): <TAB> get_response = requests.get(url) <TAB> # auth request to kfp server with istio dex look like '/dex/auth/local?req=REQ_VALUE' <TAB> if ""auth"" in get_response.url: <TAB>  <TAB> credentials = {""login"": username, ""password"": password} <TAB>  <TAB> # Authenticate user <TAB>  <TAB> session = requests.Session() <TAB>  <TAB> session.post(get_response.url, data=credentials) <TAB>  <TAB> cookie_auth_key = ""authservice_session"" <TAB>  <TAB> cookie_auth_value = session.cookies.get(cookie_auth_key) <MASK> return cookie_auth_key + ""="" + cookie_auth_value",if cookie_auth_value :,187
"def copychunked(src, dest): <TAB> chunksize = 524288  # half a meg of bytes <TAB> fsrc = src.open(""rb"") <TAB> try: <TAB>  <TAB> fdest = dest.open(""wb"") <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> while 1: <TAB>  <TAB>  <TAB>  <TAB> buf = fsrc.read(chunksize) <MASK> break <TAB>  <TAB>  <TAB>  <TAB> fdest.write(buf) <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> fdest.close() <TAB> finally: <TAB>  <TAB> fsrc.close()",if not buf :,131
"def iterate_all_python_files(base_path): <TAB> # TODO support ignored directories/files <TAB> for dirname, subdirlist, filelist in os.walk(base_path): <TAB>  <TAB> if ""__pycache__"" in dirname: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for filename in filelist: <MASK> yield os.path.join(base_path, dirname, filename)","if filename . endswith ( "".py"" ) :",95
"def discover(self, *objlist): <TAB> ret = [] <TAB> for l in self.splitlines(): <TAB>  <TAB> if l[0] != ""intr"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for name, i in enumerate(l[2:]): <MASK> ret.append(str(name)) <TAB> return ret",if int ( i ) > 10 :,84
"def call_url(self, expected_url, with_error=False): <TAB> try: <TAB>  <TAB> with self.best_url_selector.select_best_url() as url: <TAB>  <TAB>  <TAB> self.assertEqual(urlparse(expected_url), url) <MASK> raise RequestException(""error connecting to {}"".format(url)) <TAB> except RequestException: <TAB>  <TAB> pass",if with_error :,95
"def __init__(self, action_space=None, network=None, network_kwargs=None, hparams=None): <TAB> PolicyNetBase.__init__(self, hparams=hparams) <TAB> with tf.variable_scope(self.variable_scope): <MASK> action_space = Space(low=0, high=self._hparams.action_space, dtype=np.int32) <TAB>  <TAB> self._action_space = action_space <TAB>  <TAB> self._append_output_layer()",if action_space is None :,120
"def gettempfilename(suffix): <TAB> """"""Returns a temporary filename"""""" <TAB> if ""_"" in os.environ: <TAB>  <TAB> # tempfile.mktemp() crashes on some Wine versions (the one of Ubuntu 12.04 particularly) <TAB>  <TAB> if os.environ[""_""].find(""wine"") >= 0: <TAB>  <TAB>  <TAB> tmpdir = ""."" <MASK> tmpdir = os.environ[""TMP""] <TAB>  <TAB>  <TAB> import time <TAB>  <TAB>  <TAB> import random <TAB>  <TAB>  <TAB> random.seed(time.time()) <TAB>  <TAB>  <TAB> random_part = ""file%d"" % random.randint(0, 1000000000) <TAB>  <TAB>  <TAB> return os.path.join(tmpdir, random_part + suffix) <TAB> return tempfile.mktemp(suffix)","if ""TMP"" in os . environ :",172
"def get_url(self): <TAB> if self.url_patterns: <TAB>  <TAB> v_url = match1(self.html, *self.url_patterns) <MASK> v_url = compact_unquote(v_url) <TAB>  <TAB> self.v_url = [v_url]","if v_url . startswith ( ""http%3A"" ) :",83
"def drain(self, fd): <TAB> """"""Make `fd` unreadable."""""" <TAB> while True: <TAB>  <TAB> try: <MASK> return <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> e = sys.exc_info()[1] <TAB>  <TAB>  <TAB> if e.args[0] == errno.EAGAIN: <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> raise","if not os . read ( fd , 4096 ) :",97
"def tearDown(self): <TAB> # make sure all of the subprocesses are dead <TAB> for pidfile in self.pidfiles: <MASK> continue <TAB>  <TAB> with open(pidfile) as f: <TAB>  <TAB>  <TAB> pid = f.read() <TAB>  <TAB> if not pid: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> pid = int(pid) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> os.kill(pid, signal.SIGKILL) <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> pass <TAB> # and clean up leftover pidfiles <TAB> for pidfile in self.pidfiles: <TAB>  <TAB> if os.path.exists(pidfile): <TAB>  <TAB>  <TAB> os.unlink(pidfile) <TAB> self.tearDownBasedir()",if not os . path . exists ( pidfile ) :,167
"def main(): <TAB> # Arguments <TAB> input_fname, out_fname = sys.argv[1:] <TAB> # Do conversion. <TAB> index = Indexes() <TAB> offset = 0 <TAB> reader_wrapper = GFFReaderWrapper(fileinput.FileInput(input_fname), fix_strand=True) <TAB> for feature in list(reader_wrapper): <TAB>  <TAB> # Add feature; index expects BED coordinates. <MASK> convert_gff_coords_to_bed(feature) <TAB>  <TAB>  <TAB> index.add(feature.chrom, feature.start, feature.end, offset) <TAB>  <TAB> # Always increment offset, even if feature is not an interval and hence <TAB>  <TAB> # not included in the index. <TAB>  <TAB> offset += feature.raw_size <TAB> index.write(open(out_fname, ""wb""))","if isinstance ( feature , GenomicInterval ) :",199
"def _s_wise_max(a_indices, a_indptr, vals, out_max): <TAB> n = len(out_max) <TAB> for i in range(n): <MASK> m = a_indptr[i] <TAB>  <TAB>  <TAB> for j in range(a_indptr[i] + 1, a_indptr[i + 1]): <TAB>  <TAB>  <TAB>  <TAB> if vals[j] > vals[m]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> m = j <TAB>  <TAB>  <TAB> out_max[i] = vals[m]",if a_indptr [ i ] != a_indptr [ i + 1 ] :,138
"def update_encryption_keys(self, options): <TAB> if not options[""pools""] and not options[""datasets""]: <TAB>  <TAB> raise CallError(""Please specify pools/datasets to update"") <TAB> async with ENCRYPTION_CACHE_LOCK: <TAB>  <TAB> keys = await self.encryption_keys() <TAB>  <TAB> for pool in options[""pools""]: <TAB>  <TAB>  <TAB> keys[""geli""][pool[""name""]] = pool[""passphrase""] <TAB>  <TAB> for dataset in options[""datasets""]: <TAB>  <TAB>  <TAB> keys[""zfs""][dataset[""name""]] = dataset[""passphrase""] <TAB>  <TAB> await self.middleware.call(""cache.put"", ""failover_encryption_keys"", keys) <MASK> await self.sync_keys_to_remote_node(lock=False)","if options [ ""sync_keys"" ] :",173
"def set_lineno(self, lineno, override=False): <TAB> """"""Set the line numbers of the node and children."""""" <TAB> todo = deque([self]) <TAB> while todo: <TAB>  <TAB> node = todo.popleft() <TAB>  <TAB> if ""lineno"" in node.attributes: <MASK> node.lineno = lineno <TAB>  <TAB> todo.extend(node.iter_child_nodes()) <TAB> return self",if node . lineno is None or override :,103
"def is_ArAX_implicit(ii):  # allows one implicit fixed reg <TAB> a, implicit_fixed = 0, 0 <TAB> for op in _gen_opnds(ii): <MASK> a += 1 <TAB>  <TAB> elif op_reg(op) and op_implicit_specific_reg(op): <TAB>  <TAB>  <TAB> implicit_fixed += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> return a == 1 and implicit_fixed <= 1","if op_luf_start ( op , ""ArAX"" ) :",120
"def __iter__(self): <TAB> if hasattr(self, ""error_dict""): <TAB>  <TAB> for field, errors in self.error_dict.items(): <TAB>  <TAB>  <TAB> yield field, list(ValidationError(errors)) <TAB> else: <TAB>  <TAB> for error in self.error_list: <TAB>  <TAB>  <TAB> message = error.message <MASK> message %= error.params <TAB>  <TAB>  <TAB> yield force_text(message)",if error . params :,103
"def _mul_matrix(self, other): <TAB> if isinstance(other, ConstantDiagLazyTensor): <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Dimension Mismatch: Must have same diag_shape, but got "" <TAB>  <TAB>  <TAB>  <TAB> f""{self.diag_shape} and {other.diag_shape}"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return self.__class__( <TAB>  <TAB>  <TAB> self.diag_values * other.diag_values, diag_shape=self.diag_shape <TAB>  <TAB> ) <TAB> return super()._mul_matrix(other)",if not self . diag_shape == other . diag_shape :,141
"def test_no_metadata_when_py_is_pep8(py_file): <TAB> """"""This test assumes that all Python files in the jupytext folder follow PEP8 rules"""""" <TAB> nb = read(py_file) <TAB> for i, cell in enumerate(nb.cells): <MASK> cell.metadata.pop(""title"")  # pragma: no cover <TAB>  <TAB> if i == 0 and not cell.source: <TAB>  <TAB>  <TAB> assert cell.metadata == {""lines_to_next_cell"": 0}, py_file <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert not cell.metadata, (py_file, cell.source)","if ""title"" in cell . metadata :",155
"def forward(self, x: Tensor, edge_index: Adj) -> Tensor: <TAB> """""""""""" <TAB> if self.add_self_loops: <MASK> edge_index, _ = remove_self_loops(edge_index) <TAB>  <TAB>  <TAB> edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(self.node_dim)) <TAB>  <TAB> elif isinstance(edge_index, SparseTensor): <TAB>  <TAB>  <TAB> edge_index = set_diag(edge_index) <TAB> x_norm = F.normalize(x, p=2.0, dim=-1) <TAB> # propagate_type: (x: Tensor, x_norm: Tensor) <TAB> return self.propagate(edge_index, x=x, x_norm=x_norm, size=None)","if isinstance ( edge_index , Tensor ) :",196
"def should_wait(self, offer_hash: str): <TAB> with self._lock: <TAB>  <TAB> if self._offer_hash is not None: <MASK> logger.debug( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""already processing another offer (%s vs %s)"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._offer_hash, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> offer_hash, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB> if self._started == self._wtct_num_subtasks: <TAB>  <TAB>  <TAB>  <TAB> logger.info(""all subtasks for `%s` have been started"", self._offer_hash) <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> return False",if self . _offer_hash != offer_hash :,167
"def _wrap_linespans(self, inner): <TAB> s = self.linespans <TAB> i = self.linenostart - 1 <TAB> for t, line in inner: <MASK> i += 1 <TAB>  <TAB>  <TAB> yield 1, '<span id=""%s-%d"">%s</span>' % (s, i, line) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield 0, line",if t :,94
"def onRemoteResponse(self, response, request_info): <TAB> if isinstance(response, (dict,)): <MASK> msg = ""Celery echo: %s\nElapsed Time: %d"" <TAB>  <TAB>  <TAB> self.setText(msg % (response[""echo""], self.wait_cnt)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> msg = ""Waiting for Celery (id, checkno): %s, %d"" <TAB>  <TAB>  <TAB> Label.setText(self, msg % (self.task_id, self.wait_cnt)) <TAB> else: <TAB>  <TAB> self.setText(""Could not get remote response as a dictionary"")","if ""echo"" in response :",151
"def Visit_expr_stmt(self, node):  # pylint: disable=invalid-name <TAB> # expr_stmt ::= testlist_star_expr (augassign (yield_expr|testlist) <TAB> # <TAB>  <TAB>  <TAB>    | ('=' (yield_expr|testlist_star_expr))*) <TAB> for child in node.children: <TAB>  <TAB> self.Visit(child) <MASK> _AppendTokenSubtype(child, format_token.Subtype.ASSIGN_OPERATOR)","if isinstance ( child , pytree . Leaf ) and child . value == ""="" :",136
"def _list_outputs(self): <TAB> outputs = self.output_spec().get() <TAB> isHeader = True <TAB> for key in self._outfields: <TAB>  <TAB> outputs[key] = []  # initialize outfields <TAB> with open(self.inputs.in_file, ""r"") as fid: <TAB>  <TAB> for line in fid.readlines(): <MASK> # skip header line <TAB>  <TAB>  <TAB>  <TAB> isHeader = False <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> entry = self._parse_line(line) <TAB>  <TAB>  <TAB> outputs = self._append_entry(outputs, entry) <TAB> return outputs",if self . inputs . header and isHeader :,148
"def _get_tables(self, schema): <TAB> cursor = self._get_cursor() <TAB> schemas = self.configuration.get( <TAB>  <TAB> ""schemas"", self.configuration.get(""database"", """") <TAB> ).split("","") <TAB> for schema_name in schemas: <TAB>  <TAB> cursor.columns(schema=schema_name) <TAB>  <TAB> for column in cursor: <TAB>  <TAB>  <TAB> table_name = ""{}.{}"".format(column[1], column[2]) <MASK> schema[table_name] = {""name"": table_name, ""columns"": []} <TAB>  <TAB>  <TAB> schema[table_name][""columns""].append(column[3]) <TAB> return list(schema.values())",if table_name not in schema :,162
"def __setitem__(self, index, value): <TAB> if self._physics.is_dirty and not self._triggers_dirty: <TAB>  <TAB> self._physics.forward() <TAB> super(_SynchronizingArrayWrapper, self).__setitem__(index, value) <TAB> if isinstance(self._backing_index, collections.Iterable): <MASK> resolved_index = (self._backing_index[index[0]],) + index[1:] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> resolved_index = self._backing_index[index] <TAB>  <TAB> self._backing_array[resolved_index] = value <TAB> if self._triggers_dirty: <TAB>  <TAB> self._physics.mark_as_dirty()","if isinstance ( index , tuple ) :",171
"def fit_test_data(self, data, fit_values, imputer_value): <TAB> for j in range(len(data)): <TAB>  <TAB> for i in range(len(data[j])): <MASK> data[j][i] = str(fit_values[i]) <TAB> return data",if data [ j ] [ i ] in imputer_value :,87
"def Compare_in(t, x): <TAB> if not isinstance(x.ops[0], (ast.NotIn, ast.In)): <TAB>  <TAB> return <TAB> if t.enable_snippets: <TAB>  <TAB> from ..snippets import _in, in_es6 <TAB>  <TAB> if t.enable_es6: <TAB>  <TAB>  <TAB> t.add_snippet(in_es6) <TAB>  <TAB>  <TAB> sname = ""in_es6"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> t.add_snippet(_in) <TAB>  <TAB>  <TAB> sname = ""_in"" <TAB>  <TAB> result = JSCall(JSAttribute(""_pj"", sname), [x.left, x.comparators[0]]) <MASK> result = JSUnaryOp(JSOpNot(), result) <TAB>  <TAB> return result","if isinstance ( x . ops [ 0 ] , ast . NotIn ) :",189
"def __init__(self, f): <TAB> self._refs = {} <TAB> self._peeled = {} <TAB> for line in f.readlines(): <TAB>  <TAB> sha, name = line.rstrip(b""\n"").split(b""\t"") <TAB>  <TAB> if name.endswith(ANNOTATED_TAG_SUFFIX): <TAB>  <TAB>  <TAB> name = name[:-3] <MASK> raise ValueError(""invalid ref name %r"" % name) <TAB>  <TAB>  <TAB> self._peeled[name] = sha <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if not check_ref_format(name): <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""invalid ref name %r"" % name) <TAB>  <TAB>  <TAB> self._refs[name] = sha",if not check_ref_format ( name ) :,171
"def info(args): <TAB> # Check grammar <TAB> p = Python37Parser() <TAB> if len(args) > 0: <TAB>  <TAB> arg = args[0] <MASK> from uncompyle6.parser.parse37 import Python37Parser <TAB>  <TAB>  <TAB> p = Python37Parser() <TAB>  <TAB> elif arg == ""3.8"": <TAB>  <TAB>  <TAB> from uncompyle6.parser.parse38 import Python38Parser <TAB>  <TAB>  <TAB> p = Python38Parser() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise RuntimeError(""Only 3.7 and 3.8 supported"") <TAB> p.check_grammar() <TAB> if len(sys.argv) > 1 and sys.argv[1] == ""dump"": <TAB>  <TAB> print(""-"" * 50) <TAB>  <TAB> p.dump_grammar()","if arg == ""3.7"" :",181
"def test_ESPnetDataset_text_float(text_float): <TAB> dataset = IterableESPnetDataset( <TAB>  <TAB> path_name_type_list=[(text_float, ""data8"", ""text_float"")], <TAB>  <TAB> preprocess=preprocess, <TAB> ) <TAB> for key, data in dataset: <TAB>  <TAB> if key == ""a"": <TAB>  <TAB>  <TAB> assert all((data[""data8""]) == np.array([1.4, 3.4], dtype=np.float32)) <MASK> assert all((data[""data8""]) == np.array([0.9, 9.3], dtype=np.float32))","if key == ""b"" :",152
"def getting(self, key, lock=False): <TAB> if not lock: <TAB>  <TAB> yield self.get(key) <TAB> else: <TAB>  <TAB> locked = False <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> data = self._get_or_lock(key) <TAB>  <TAB>  <TAB> locked = data is None <TAB>  <TAB>  <TAB> yield data <TAB>  <TAB> finally: <MASK> self._release_lock(key)",if locked :,99
"def mkdir(self, path, parents=True, raise_if_exists=False): <TAB> if self.exists(path): <MASK> raise luigi.target.NotADirectory() <TAB>  <TAB> elif raise_if_exists: <TAB>  <TAB>  <TAB> raise luigi.target.FileAlreadyExists() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return <TAB> self.conn.files_create_folder_v2(path)",if not self . isdir ( path ) :,106
"def _get_initiated_elections(cls, height, txns): <TAB> elections = [] <TAB> for tx in txns: <MASK> continue <TAB>  <TAB> elections.append( <TAB>  <TAB>  <TAB> {""election_id"": tx.id, ""height"": height, ""is_concluded"": False} <TAB>  <TAB> ) <TAB> return elections","if not isinstance ( tx , Election ) :",93
"def recalc_active(self, ts): <TAB> if not self.active_seconds: <TAB>  <TAB> self.active_seconds.append(ts) <TAB>  <TAB> self.data[ts] = {} <TAB> if ts not in self.active_seconds: <MASK> for i in range(max(self.active_seconds) + 1, ts + 1): <TAB>  <TAB>  <TAB>  <TAB> self.active_seconds.append(i) <TAB>  <TAB>  <TAB>  <TAB> self.active_seconds.sort() <TAB>  <TAB>  <TAB>  <TAB> self.data[i] = {} <TAB> while len(self.active_seconds) > self.window: <TAB>  <TAB> self.active_seconds.pop(0) <TAB> for sec in self.data.keys(): <TAB>  <TAB> if sec not in self.active_seconds: <TAB>  <TAB>  <TAB> self.data.pop(sec)",if ts > max ( self . active_seconds ) :,200
"def get_scalar_base(schema, scalar) -> Tuple[str, ...]: <TAB> base = base_type_name_map.get(scalar.id) <TAB> if base is not None: <TAB>  <TAB> return base <TAB> for ancestor in scalar.get_ancestors(schema).objects(schema): <MASK> # Check if base is fundamental, if not, then it is <TAB>  <TAB>  <TAB> # another domain. <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> base = base_type_name_map[ancestor.id] <TAB>  <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB>  <TAB> base = common.get_backend_name(schema, ancestor, catenate=False) <TAB>  <TAB>  <TAB> return base <TAB> raise ValueError( <TAB>  <TAB> f""cannot determine backend type for scalar type "" f""{scalar.get_name(schema)}"" <TAB> )",if not ancestor . get_is_abstract ( schema ) :,200
def __next__(self): <TAB> try: <TAB>  <TAB> value = next(self._iterable) <MASK> self.start() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.update(self.value + 1) <TAB>  <TAB> return value <TAB> except StopIteration: <TAB>  <TAB> self.finish() <TAB>  <TAB> raise <TAB> except GeneratorExit:  # pragma: no cover <TAB>  <TAB> self.finish(dirty=True) <TAB>  <TAB> raise,if self . start_time is None :,109
"def change_password(username=""flexget"", password="""", session=None): <TAB> check = zxcvbn.zxcvbn(password, user_inputs=[username]) <TAB> if check[""score""] < 3: <TAB>  <TAB> warning = check[""feedback""][""warning""] <TAB>  <TAB> suggestions = "" "".join(check[""feedback""][""suggestions""]) <TAB>  <TAB> message = ""Password '{}' is not strong enough. "".format(password) <MASK> message += warning + "" "" <TAB>  <TAB> if suggestions: <TAB>  <TAB>  <TAB> message += ""Suggestions: {}"".format(suggestions) <TAB>  <TAB> raise WeakPassword(message) <TAB> user = get_user(username=username, session=session) <TAB> user.password = str(generate_password_hash(password)) <TAB> session.commit()",if warning :,175
"def _options_fcheck(self, name, xflags, table): <TAB> for entry in table: <TAB>  <TAB> if entry.name is None: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if entry.flags & XTOPT_MAND and not xflags & (1 << entry.id): <TAB>  <TAB>  <TAB> raise XTablesError(""%s: --%s must be specified"" % (name, entry.name)) <MASK> continue",if not xflags & ( 1 << entry . id ) :,112
"def parse_ports(container_name, connection_configuration): <TAB> while True: <TAB>  <TAB> ports_command = docker_util.build_docker_simple_command( <TAB>  <TAB>  <TAB> ""port"", container_name=container_name, **connection_configuration <TAB>  <TAB> ) <TAB>  <TAB> with tempfile.TemporaryFile(prefix=""docker_port_"") as stdout_file: <TAB>  <TAB>  <TAB> exit_code = subprocess.call( <TAB>  <TAB>  <TAB>  <TAB> ports_command, shell=True, stdout=stdout_file, preexec_fn=os.setpgrp <TAB>  <TAB>  <TAB> ) <MASK> stdout_file.seek(0) <TAB>  <TAB>  <TAB>  <TAB> ports_raw = stdout_file.read().decode(""utf-8"") <TAB>  <TAB>  <TAB>  <TAB> return ports_raw",if exit_code == 0 :,180
"def _init_ti_table(): <TAB> global _ti_table <TAB> _ti_table = [] <TAB> for fname, name in zip(kc.STRFNAMES, kc.STRNAMES): <TAB>  <TAB> seq = termcap.get(name) <TAB>  <TAB> if not seq: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> k = _name_to_key(fname) <MASK> _ti_table.append((list(bytearray(seq)), k))",if k :,109
"def sanitize_args(a): <TAB> try: <TAB>  <TAB> args, kwargs = a <TAB>  <TAB> if isinstance(args, tuple) and isinstance(kwargs, dict): <TAB>  <TAB>  <TAB> return args, dict(kwargs) <TAB> except (TypeError, ValueError): <TAB>  <TAB> args, kwargs = (), {} <TAB> if a is not None: <MASK> args = tuple() <TAB>  <TAB>  <TAB> kwargs = a <TAB>  <TAB> elif isinstance(a, tuple): <TAB>  <TAB>  <TAB> if isinstance(a[-1], dict): <TAB>  <TAB>  <TAB>  <TAB> args, kwargs = a[0:-1], a[-1] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> args = a <TAB>  <TAB>  <TAB>  <TAB> kwargs = {} <TAB> return args, kwargs","if isinstance ( a , dict ) :",168
"def fork_with_import_lock(level): <TAB> release = 0 <TAB> in_child = False <TAB> try: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> for i in range(level): <TAB>  <TAB>  <TAB>  <TAB> imp.acquire_lock() <TAB>  <TAB>  <TAB>  <TAB> release += 1 <TAB>  <TAB>  <TAB> pid = os.fork() <TAB>  <TAB>  <TAB> in_child = not pid <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> for i in range(release): <TAB>  <TAB>  <TAB>  <TAB> imp.release_lock() <TAB> except RuntimeError: <TAB>  <TAB> if in_child: <MASK> print(""RuntimeError in child"") <TAB>  <TAB>  <TAB> os._exit(1) <TAB>  <TAB> raise <TAB> if in_child: <TAB>  <TAB> os._exit(0) <TAB> self.wait_impl(pid)",if verbose > 1 :,183
"def _capture_hub(self, create): <TAB> # Subclasses should call this as the first action from any <TAB> # public method that could, in theory, block and switch <TAB> # to the hub. This may release the GIL. <TAB> if self.hub is None: <TAB>  <TAB> # This next line might release the GIL. <TAB>  <TAB> current_hub = get_hub() if create else get_hub_if_exists() <MASK> return <TAB>  <TAB> # We have the GIL again. Did anything change? If so, <TAB>  <TAB> # we lost the race. <TAB>  <TAB> if self.hub is None: <TAB>  <TAB>  <TAB> self.hub = current_hub",if current_hub is None :,161
"def get_user_makepkg_path(cls) -> Optional[str]: <TAB> if cls._user_makepkg_path == ""unset"": <TAB>  <TAB> possible_paths = [ <TAB>  <TAB>  <TAB> os.path.expanduser(""~/.makepkg.conf""), <TAB>  <TAB>  <TAB> os.path.join(CONFIG_ROOT, ""pacman/makepkg.conf""), <TAB>  <TAB> ] <TAB>  <TAB> config_path: Optional[str] = None <TAB>  <TAB> for path in possible_paths: <MASK> config_path = path <TAB>  <TAB> cls._user_makepkg_path = config_path <TAB> return cls._user_makepkg_path",if os . path . exists ( path ) :,154
"def createValue(self): <TAB> mode = [] <TAB> for name in self._text_keys: <MASK> if 4 <= len(mode): <TAB>  <TAB>  <TAB>  <TAB> mode.append(""..."") <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> mode.append(name) <TAB> if mode: <TAB>  <TAB> return "", "".join(mode) <TAB> else: <TAB>  <TAB> return ""(none)""",if self [ name ] . value :,102
"def keyPressEvent(self, event): <TAB> if event.key() in (Qt.Key_Right, Qt.Key_Left): <TAB>  <TAB> direction = 1 <TAB>  <TAB> if event.key() == Qt.Key_Left: <TAB>  <TAB>  <TAB> direction = -1 <MASK> print(""shift"") <TAB>  <TAB>  <TAB> direction *= 10 <TAB>  <TAB> self.timeline.setValue(self.timeline.value() + direction) <TAB> else: <TAB>  <TAB> super(VideoPlayerWidget, self).keyPressEvent(event)",if event . modifiers ( ) == Qt . ShiftModifier :,131
"def validate_wrapper(*args, **kwargs): <TAB> result = self.validate_func(*args, **kwargs) <TAB> if request.is_xhr: <MASK> result = {} <TAB>  <TAB> result.setdefault(""success"", True) <TAB>  <TAB> values = result.get(""values"", {}) <TAB>  <TAB> for key, value in tmpl_context.form_values.iteritems(): <TAB>  <TAB>  <TAB> values.setdefault(key, value) <TAB> return result","if not isinstance ( result , dict ) :",110
"def copy_metadata_to(self, target_dir): <TAB> prefix = os.path.join(self.egg_info, """") <TAB> for path in self.ei_cmd.filelist.files: <MASK> target = os.path.join(target_dir, path[len(prefix) :]) <TAB>  <TAB>  <TAB> ensure_directory(target) <TAB>  <TAB>  <TAB> self.copy_file(path, target)",if path . startswith ( prefix ) :,103
"def _get_switch_info(self, cmd_list): <TAB> stdout, stderr, sw_data = None, None, None <TAB> try: <TAB>  <TAB> stdout, stderr = self._run_ssh(cmd_list, True) <TAB>  <TAB> LOG.debug(""CLI output from ssh - output: %s"", stdout) <MASK> sw_data = stdout.splitlines() <TAB>  <TAB> return sw_data <TAB> except processutils.ProcessExecutionError as e: <TAB>  <TAB> msg = _( <TAB>  <TAB>  <TAB> ""Error while getting data via ssh: (command=%(cmd)s "" ""error=%(err)s)."" <TAB>  <TAB> ) % {""cmd"": cmd_list, ""err"": six.text_type(e)} <TAB>  <TAB> LOG.error(msg) <TAB>  <TAB> raise exception.CiscoZoningCliException(reason=msg)",if stdout :,191
"def analyze(vw): <TAB> for va, dest in vw.findPointers(): <TAB>  <TAB> # Is there a location already at the target? <TAB>  <TAB> loc = vw.getLocation(dest) <TAB>  <TAB> if loc is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if loc[L_LTYPE] != LOC_IMPORT: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> offset, bytes = vw.getByteDef(va) <MASK> continue <TAB>  <TAB> if bytes[offset - 2 : offset] == b""\xff\x15"":  # call [importloc] <TAB>  <TAB>  <TAB> # If there's a pointer here, remove it. <TAB>  <TAB>  <TAB> if vw.getLocation(va): <TAB>  <TAB>  <TAB>  <TAB> vw.delLocation(va) <TAB>  <TAB>  <TAB> vw.makeCode(va - 2)",if offset < 2 :,192
"def _freeze_stages(self): <TAB> """"""Freeze parameters."""""" <TAB> if self.frozen_stages >= 0: <MASK> self.stem.eval() <TAB>  <TAB>  <TAB> for param in self.stem.parameters(): <TAB>  <TAB>  <TAB>  <TAB> param.requires_grad = False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.norm1.eval() <TAB>  <TAB>  <TAB> for m in [self.conv1, self.norm1]: <TAB>  <TAB>  <TAB>  <TAB> for param in m.parameters(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> param.requires_grad = False <TAB> for i in range(1, self.frozen_stages + 1): <TAB>  <TAB> m = getattr(self, f""layer{i}"") <TAB>  <TAB> m.eval() <TAB>  <TAB> for param in m.parameters(): <TAB>  <TAB>  <TAB> param.requires_grad = False",if self . deep_stem :,191
"def seek(self, timestamp, log=True): <TAB> """"""Seek to a particular timestamp in the movie."""""" <TAB> if self.status in [PLAYING, PAUSED]: <TAB>  <TAB> player = self._player <TAB>  <TAB> if player and player.is_seekable(): <TAB>  <TAB>  <TAB> player.set_time(int(timestamp * 1000.0)) <TAB>  <TAB>  <TAB> self._vlc_clock.reset(timestamp) <MASK> self._pause_time = timestamp <TAB>  <TAB> if log: <TAB>  <TAB>  <TAB> logAttrib(self, log, ""seek"", timestamp)",if self . status == PAUSED :,137
"def foundNestedPseudoClass(self): <TAB> i = self.pos + 1 <TAB> openParen = 0 <TAB> while i < len(self.source_text): <TAB>  <TAB> ch = self.source_text[i] <MASK> return True <TAB>  <TAB> elif ch == ""("": <TAB>  <TAB>  <TAB> # pseudoclasses can contain () <TAB>  <TAB>  <TAB> openParen += 1 <TAB>  <TAB> elif ch == "")"": <TAB>  <TAB>  <TAB> if openParen == 0: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> openParen -= 1 <TAB>  <TAB> elif ch == "";"" or ch == ""}"": <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> i += 1 <TAB> return False","if ch == ""{"" :",155
"def update(events): <TAB> if failsToWriteToIDClasses(): <TAB>  <TAB> print(""Skip event: cannot write to ID classes"") <TAB>  <TAB> return <TAB> if didNameChange() or events.intersection({""File"", ""Addon"", ""Tree""}): <TAB>  <TAB> updateEverything() <TAB> if problems.canAutoExecute(): <TAB>  <TAB> nodeTrees = list(iterAutoExecutionNodeTrees(events)) <MASK> setupExecutionUnits() <TAB>  <TAB>  <TAB> executeNodeTrees(nodeTrees) <TAB>  <TAB>  <TAB> afterExecution() <TAB>  <TAB>  <TAB> finishExecutionUnits()",if len ( nodeTrees ) > 0 :,136
"def check_all_verified(self): <TAB> if not self.all_verified: <TAB>  <TAB> new_all_verified = not self.lines.filter(verified=False).exists() <MASK> self.all_verified = True <TAB>  <TAB>  <TAB> if self.require_verification: <TAB>  <TAB>  <TAB>  <TAB> self.add_log_entry( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _(""All rows requiring verification have been verified."") <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> self.require_verification = False <TAB>  <TAB>  <TAB> self.save() <TAB> return self.all_verified",if new_all_verified :,136
"def parse_for(cls, tagname, parser, bits, options): <TAB> if bits: <MASK> bits.pop(0) <TAB>  <TAB>  <TAB> if len(bits): <TAB>  <TAB>  <TAB>  <TAB> options[""for""] = Variable(bits.pop(0)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise TemplateSyntaxError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""%s: expected an argument "" 'after ""for"".' % tagname <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> elif not cls.optional_for_parameter: <TAB>  <TAB>  <TAB> raise TemplateSyntaxError( <TAB>  <TAB>  <TAB>  <TAB> ""Unknown argument for %s tag: %r."" % (tagname, bits[0]) <TAB>  <TAB>  <TAB> )","if bits [ 0 ] == ""for"" :",161
"def _get_cuda_device(*args): <TAB> # Returns cuda.Device or DummyDevice. <TAB> for arg in args: <MASK> check_cuda_available() <TAB>  <TAB>  <TAB> return Device(arg) <TAB>  <TAB> if isinstance(arg, ndarray): <TAB>  <TAB>  <TAB> if arg.device is None: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> return arg.device <TAB>  <TAB> if available and isinstance(arg, Device): <TAB>  <TAB>  <TAB> return arg <TAB> # NOTE: This function returns DummyDevice for both NumPy and ChainerX <TAB> return DummyDevice","if type ( arg ) is not bool and isinstance ( arg , _integer_types ) :",144
"def while1_test(a, b, c): <TAB> while 1: <TAB>  <TAB> if a != 2: <MASK> a = 3 <TAB>  <TAB>  <TAB>  <TAB> b = 0 <TAB>  <TAB>  <TAB> elif c: <TAB>  <TAB>  <TAB>  <TAB> c = 0 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> a += b + c <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return a, b, c",if b :,94
"def write_notes(self, family, father, mother): <TAB> # FIXME: <TAB> # if self.restrict and self.exclnotes: <TAB> # <TAB> return <TAB> self.write_note_of_person(father) <TAB> self.write_note_of_person(mother) <TAB> child_ref_list = family.get_child_ref_list() <TAB> if child_ref_list: <TAB>  <TAB> for child_ref in child_ref_list: <TAB>  <TAB>  <TAB> child = self.db.get_person_from_handle(child_ref.ref) <MASK> self.write_note_of_person(child)",if child :,160
"def GetFile(cls, session, sig, mode=""r""): <TAB> sig = sig[: cls.HASH_LEN] <TAB> while len(sig) > 0: <TAB>  <TAB> fn = cls.SaveFile(session, sig) <TAB>  <TAB> try: <MASK> return (open(fn, mode), sig) <TAB>  <TAB> except (IOError, OSError): <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> if len(sig) > 1: <TAB>  <TAB>  <TAB> sig = sig[:-1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if ""r"" in mode: <TAB>  <TAB>  <TAB>  <TAB> return (None, sig) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return (open(fn, mode), sig) <TAB> # Not reached <TAB> return (None, None)",if os . path . exists ( fn ) :,180
"def _generate_expression(self): <TAB> # turn my _format attribute into the _expression attribute <TAB> e = [] <TAB> for part in PARSE_RE.split(self._format): <TAB>  <TAB> if not part: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif part == ""{{"": <TAB>  <TAB>  <TAB> e.append(r""\{"") <TAB>  <TAB> elif part == ""}}"": <TAB>  <TAB>  <TAB> e.append(r""\}"") <MASK> # this will be a braces-delimited field to handle <TAB>  <TAB>  <TAB> e.append(self._handle_field(part)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # just some text to match <TAB>  <TAB>  <TAB> e.append(REGEX_SAFETY.sub(self._regex_replace, part)) <TAB> return """".join(e)","elif part [ 0 ] == ""{"" and part [ - 1 ] == ""}"" :",189
"def get_cfg_dict(self, with_meta=True): <TAB> options_dict = self.merged_options <TAB> if with_meta: <MASK> options_dict.update( <TAB>  <TAB>  <TAB>  <TAB> {""package"": ""yandextank.plugins.{}"".format(self.plugin)} <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if self.enabled is not None: <TAB>  <TAB>  <TAB> options_dict.update({""enabled"": self.enabled}) <TAB> return options_dict",if self . plugin :,111
"def __str__(self): <TAB> _outicalfile = self._icalfile <TAB> for unit in self.units: <TAB>  <TAB> for location in unit.getlocations(): <TAB>  <TAB>  <TAB> match = re.match(""\\[(?P<uid>.+)\\](?P<property>.+)"", location) <TAB>  <TAB>  <TAB> for component in self._icalfile.components(): <MASK> continue <TAB>  <TAB>  <TAB>  <TAB> if component.uid.value != match.groupdict()[""uid""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB>  <TAB> for property in component.getChildren(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if property.name == match.groupdict()[""property""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> property.value = unit.target <TAB> if _outicalfile: <TAB>  <TAB> return str(_outicalfile.serialize()) <TAB> else: <TAB>  <TAB> return """"","if component . name != ""VEVENT"" :",198
"def process_events(self, events): <TAB> for event in events: <TAB>  <TAB> key = (event.ident, event.filter) <TAB>  <TAB> if event.ident == self._force_wakeup_fd: <TAB>  <TAB>  <TAB> self._force_wakeup.drain() <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> receiver = self._registered[key] <MASK> del self._registered[key] <TAB>  <TAB> if type(receiver) is _core.Task: <TAB>  <TAB>  <TAB> _core.reschedule(receiver, outcome.Value(event)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> receiver.put_nowait(event)",if event . flags & select . KQ_EV_ONESHOT :,154
"def forward(self, start=True, search=False, target=None, include_current=False): <TAB> """"""Move one step forward in the history."""""" <TAB> if target is None: <TAB>  <TAB> target = self.saved_line <TAB> if self.index > 1: <MASK> self.index -= self.find_partial_match_forward(target, include_current) <TAB>  <TAB> elif start: <TAB>  <TAB>  <TAB> self.index -= self.find_match_forward(target, include_current) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.index -= 1 <TAB>  <TAB> return self.entry <TAB> else: <TAB>  <TAB> self.index = 0 <TAB>  <TAB> return self.saved_line",if search :,161
"def _charlabels(self, options): <TAB> """"""Get labels for characters (PRIVATE)."""""" <TAB> self.charlabels = {} <TAB> opts = CharBuffer(options) <TAB> while True: <TAB>  <TAB> # get id and state <TAB>  <TAB> w = opts.next_word() <TAB>  <TAB> if w is None:  # McClade saves and reads charlabel-lists with terminal comma?! <TAB>  <TAB>  <TAB> break <TAB>  <TAB> identifier = self._resolve(w, set_type=CHARSET) <TAB>  <TAB> state = quotestrip(opts.next_word()) <TAB>  <TAB> self.charlabels[identifier] = state <TAB>  <TAB> # check for comma or end of command <TAB>  <TAB> c = opts.next_nonwhitespace() <TAB>  <TAB> if c is None: <TAB>  <TAB>  <TAB> break <MASK> raise NexusError(""Missing ',' in line %s."" % options)","elif c != "","" :",198
"def _get_cloudstorage_bucket_iam_member_bindings(self, raw_bucket): <TAB> bucket_iam_policy = raw_bucket.iam_policy <TAB> member_bindings = {} <TAB> if bucket_iam_policy: <TAB>  <TAB> for binding in bucket_iam_policy._bindings: <MASK> for member in binding[""members""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if member not in member_bindings: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> member_bindings[member] = [binding[""role""]] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> member_bindings[member].append(binding[""role""]) <TAB> return member_bindings","if ""legacy"" not in binding [ ""role"" ] :",159
"def _gen(): <TAB> for i in dataset(): <TAB>  <TAB> if isinstance(i, tuple) or isinstance(i, list): <TAB>  <TAB>  <TAB> if fn(*i) is True: <TAB>  <TAB>  <TAB>  <TAB> yield i <TAB>  <TAB> else: <MASK> yield i",if fn ( i ) is True :,72
"def set_img_to_eval_imgs(self, scores, img_ids, method): <TAB> for img_id, score in zip(img_ids, scores): <MASK> self.img_to_eval[img_id] = dict() <TAB>  <TAB>  <TAB> self.img_to_eval[img_id][""image_id""] = img_id <TAB>  <TAB> self.img_to_eval[img_id][method] = score",if img_id not in self . img_to_eval :,118
"def _compute_totals(self): <TAB> totals = {} <TAB> for entry in self.entries: <TAB>  <TAB> for k, v in entry.nutrition_information.items(): <MASK> totals[k] = v <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> totals[k] += v <TAB> self._totals = totals",if k not in totals :,87
"def analyzeFunction(vw, funcva): <TAB> for fromva, tova, rtype, rflags in vw.getXrefsFrom(funcva, v_const.REF_CODE): <TAB>  <TAB> # You goin NOWHERE! <TAB>  <TAB> loc = vw.getLocation(tova) <TAB>  <TAB> if loc is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # FIXME this could check for thunks to other known function pointers... <TAB>  <TAB> va, size, ltype, linfo = loc <MASK> continue <TAB>  <TAB> vw.makeFunctionThunk(funcva, linfo)",if ltype != v_const . LOC_IMPORT :,148
"def clear_output_directory(self): <TAB> files = os.listdir(os.path.join(""functional"", ""output"")) <TAB> for f in files: <MASK> continue  # don't touch the infrastructure <TAB>  <TAB> path = os.path.join(""functional"", ""output"", f) <TAB>  <TAB> if os.path.isdir(path): <TAB>  <TAB>  <TAB> shutil.rmtree(path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> os.remove(path)","if f in ( ""README.txt"" , "".svn"" , ""CVS"" ) :",121
"def test_output_files_as_none_string(self): <TAB> for name in ""Output"", ""Report"", ""Log"", ""XUnit"", ""DebugFile"": <TAB>  <TAB> attr = (name[:-4] if name.endswith(""File"") else name).lower() <TAB>  <TAB> settings = RobotSettings({name.lower(): ""NoNe""}) <TAB>  <TAB> assert_equals(settings[name], None) <MASK> assert_equals(getattr(settings, attr), None)","if hasattr ( settings , attr ) :",117
def is_rotated(box_list): <TAB> if type(box_list) == np.ndarray: <TAB>  <TAB> return box_list.shape[1] == 5 <TAB> elif type(box_list) == list: <MASK> # cannot decide the box_dim <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return np.all( <TAB>  <TAB>  <TAB> np.array( <TAB>  <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> (len(obj) == 5) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> and ((type(obj) == list) or (type(obj) == np.ndarray)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for obj in box_list <TAB>  <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB> return False,if box_list == [ ] :,167
"def visit_loop(self): <TAB> v = self.vS.top_front() <TAB> i = self.iS.top_front() <TAB> num_edges = len(self.graph[v].edges) <TAB> # Continue traversing out-edges until none left. <TAB> while i <= num_edges: <TAB>  <TAB> # Continuation <MASK> # Update status for previously traversed out-edge <TAB>  <TAB>  <TAB> self.finish_edge(v, i - 1) <TAB>  <TAB> if i < num_edges and self.begin_edge(v, i): <TAB>  <TAB>  <TAB> return <TAB>  <TAB> i += 1 <TAB> # Finished traversing out edges, update component info <TAB> self.finish_visiting(v)",if i > 0 :,167
"def GetConvertersByClass(value_cls): <TAB> """"""Returns all converters that take given value as an input value."""""" <TAB> try: <TAB>  <TAB> return ExportConverter.converters_cache[value_cls] <TAB> except KeyError: <TAB>  <TAB> results = [ <TAB>  <TAB>  <TAB> cls <TAB>  <TAB>  <TAB> for cls in ExportConverter.classes.values() <TAB>  <TAB>  <TAB> if cls.input_rdf_type == value_cls <TAB>  <TAB> ] <MASK> results = [DataAgnosticExportConverter] <TAB>  <TAB> ExportConverter.converters_cache[value_cls] = results <TAB>  <TAB> return results",if not results :,138
"def migrate_Context(self): <TAB> for old_obj in self.session_old.query(self.model_from[""Context""]): <TAB>  <TAB> new_obj = self.model_to[""Context""]() <TAB>  <TAB> for key in new_obj.__table__.columns._data.keys(): <TAB>  <TAB>  <TAB> if key not in old_obj.__table__.columns._data.keys(): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> value = getattr(old_obj, key) <MASK> value = 0 <TAB>  <TAB>  <TAB> setattr(new_obj, key, value) <TAB>  <TAB> self.session_new.add(new_obj)","if key == ""tip_timetolive"" and value < 0 :",161
"def _bind_to(self, url, bind): <TAB> """"""Bind to a Connectable in the caller's thread."""""" <TAB> if isinstance(bind, util.string_types + (url.URL,)): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.context._engine = self.__engines[bind] <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> e = sqlalchemy.create_engine(bind) <TAB>  <TAB>  <TAB> self.__engines[bind] = e <TAB>  <TAB>  <TAB> self.context._engine = e <TAB> else: <TAB>  <TAB> # TODO: this is squirrely.  we shouldn't have to hold onto engines <TAB>  <TAB> # in a case like this <MASK> self.__engines[bind] = bind <TAB>  <TAB> self.context._engine = bind",if bind not in self . __engines :,180
"def _gen_Less(self, args, ret_type): <TAB> result = [] <TAB> for lhs, rhs in pairwise(args): <MASK> result.append(self.builder.fcmp_ordered(""<"", lhs, rhs)) <TAB>  <TAB> elif ret_type == int_type: <TAB>  <TAB>  <TAB> result.append(self.builder.icmp_signed(""<"", lhs, rhs)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise CompileError() <TAB> return reduce(self.builder.and_, result)",if ret_type == real_type :,120
"def _store_pickle_output(self, pickle_output): <TAB> if pickle_output: <MASK> self.error(""Can't use without --output"", ""pickle-output"") <TAB>  <TAB> elif not load_pytd.is_pickle(self.output_options.output): <TAB>  <TAB>  <TAB> self.error( <TAB>  <TAB>  <TAB>  <TAB> ""Must specify %s file for --output"" % load_pytd.PICKLE_EXT, <TAB>  <TAB>  <TAB>  <TAB> ""pickle-output"", <TAB>  <TAB>  <TAB> ) <TAB> self.output_options.pickle_output = pickle_output",if self . output_options . output is None :,141
"def resolve_identifier(self, identifier): <TAB> if "":"" in identifier: <TAB>  <TAB> conn, pn = identifier.split("":"") <MASK> pn = int(pn) <TAB>  <TAB> return self.resolve_identifier(self.connector_table[conn][pn]) <TAB> else: <TAB>  <TAB> return identifier",if pn . isdigit ( ) :,75
"def add_braces_and_labels(self): <TAB> for attr in ""horizontal_parts"", ""vertical_parts"": <TAB>  <TAB> if not hasattr(self, attr): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> parts = getattr(self, attr) <TAB>  <TAB> for subattr in ""braces"", ""labels"": <MASK> self.add(getattr(parts, subattr))","if hasattr ( parts , subattr ) :",97
"def on_janitor_selection_changed(self, selection): <TAB> model, iter = selection.get_selected() <TAB> if iter: <MASK> iter = self.janitor_model.iter_children(iter) <TAB>  <TAB> plugin = model[iter][self.JANITOR_PLUGIN] <TAB>  <TAB> for row in self.result_model: <TAB>  <TAB>  <TAB> if row[self.RESULT_PLUGIN] == plugin: <TAB>  <TAB>  <TAB>  <TAB> self.result_view.get_selection().select_path(row.path) <TAB>  <TAB>  <TAB>  <TAB> log.debug(""scroll_to_cell: %s"" % row.path) <TAB>  <TAB>  <TAB>  <TAB> self.result_view.scroll_to_cell(row.path)",if self . janitor_model . iter_has_child ( iter ) :,184
"def canonical_standard_headers(self, headers): <TAB> interesting_headers = [""content-md5"", ""content-type"", ""date""] <TAB> hoi = [] <TAB> if ""Date"" in headers: <TAB>  <TAB> del headers[""Date""] <TAB> headers[""Date""] = self._get_date() <TAB> for ih in interesting_headers: <TAB>  <TAB> found = False <TAB>  <TAB> for key in headers: <TAB>  <TAB>  <TAB> lk = key.lower() <TAB>  <TAB>  <TAB> if headers[key] is not None and lk == ih: <TAB>  <TAB>  <TAB>  <TAB> hoi.append(headers[key].strip()) <TAB>  <TAB>  <TAB>  <TAB> found = True <MASK> hoi.append("""") <TAB> return ""\n"".join(hoi)",if not found :,172
"def boolean(value): <TAB> if isinstance(value, str): <TAB>  <TAB> v = value.lower() <TAB>  <TAB> if v in (""1"", ""yes"", ""true"", ""on""): <TAB>  <TAB>  <TAB> return True <MASK> return False <TAB>  <TAB> raise ValueError(value) <TAB> return bool(value)","if v in ( ""0"" , ""no"" , ""false"" , ""off"" ) :",87
"def get_extension_for_class(self, extclass): <TAB> if extclass is UnrecognizedExtension: <TAB>  <TAB> raise TypeError( <TAB>  <TAB>  <TAB> ""UnrecognizedExtension can't be used with "" <TAB>  <TAB>  <TAB> ""get_extension_for_class because more than one instance of the"" <TAB>  <TAB>  <TAB> "" class may be present."" <TAB>  <TAB> ) <TAB> for ext in self: <MASK> return ext <TAB> raise ExtensionNotFound(""No {} extension was found"".format(extclass), extclass.oid)","if isinstance ( ext . value , extclass ) :",126
"def sysargs_to_mainargs(): <TAB> """"""builds main args from sys.argv"""""" <TAB> relative_out_dir = None <TAB> if len(sys.argv) > 1 and sys.argv[1].startswith(""--""): <TAB>  <TAB> a = sys.argv.pop(1) <MASK> print(__doc__) <TAB>  <TAB>  <TAB> sys.exit(1) <TAB>  <TAB> elif a.startswith(""--reldir=""): <TAB>  <TAB>  <TAB> relative_out_dir = a[len(""--reldir="") :] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""*** Error, Unknown option:"", a) <TAB>  <TAB>  <TAB> print(__doc__) <TAB>  <TAB>  <TAB> sys.exit(1) <TAB> other_session = sys.argv[1] <TAB> return relative_out_dir, other_session","if a . startswith ( ""--help"" ) :",181
"def _scanDirectory(self, dirIter, f): <TAB> while len(f) < 250: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> info = next(dirIter) <TAB>  <TAB> except StopIteration: <MASK> raise EOFError <TAB>  <TAB>  <TAB> return f <TAB>  <TAB> if isinstance(info, defer.Deferred): <TAB>  <TAB>  <TAB> info.addCallback(self._cbScanDirectory, dirIter, f) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> f.append(info) <TAB> return f",if not f :,122
"def register_options(config_block): <TAB> for name in common_block: <TAB>  <TAB> safe_declare_common_option(config_block, name) <MASK> config_block.get(name).declare_as_argument()",if config_block . get ( name ) . _argparse is None :,70
"def _loc(obj): <TAB> try: <TAB>  <TAB> fn = getattr(obj, ""__file__"", None) <MASK> return "" @%s"" % (fn,) <TAB>  <TAB> obj = getattr(obj, ""im_func"", obj) <TAB>  <TAB> code = getattr(obj, ""__code__"", None) <TAB>  <TAB> if code is not None: <TAB>  <TAB>  <TAB> return "" @%s:%s"" % (code.co_filename, code.co_firstlineno) <TAB> except Exception: <TAB>  <TAB> pass <TAB> return """"",if fn is not None :,126
"def _remove_temporary_files(self, temporary_files): <TAB> """"""Internal function for cleaning temporary files"""""" <TAB> for file_object in temporary_files: <TAB>  <TAB> file_name = file_object.name <TAB>  <TAB> file_object.close() <MASK> os.remove(file_name) <TAB>  <TAB> arff_file_name = file_name + "".arff"" <TAB>  <TAB> if os.path.exists(arff_file_name): <TAB>  <TAB>  <TAB> os.remove(arff_file_name)",if os . path . exists ( file_name ) :,129
"def show(self): <TAB> """"""Overrides Qt Method"""""" <TAB> QWidget.show(self) <TAB> self.emit(SIGNAL(""visibility_changed(bool)""), True) <TAB> if self.editor is not None: <TAB>  <TAB> text = self.editor.get_selected_text() <MASK> self.search_text.setEditText(text) <TAB>  <TAB>  <TAB> self.search_text.lineEdit().selectAll() <TAB>  <TAB>  <TAB> self.refresh() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.search_text.lineEdit().selectAll() <TAB>  <TAB> self.search_text.setFocus()",if len ( text ) > 0 :,150
"def flush_input() -> None: <TAB> if not self.is_done: <TAB>  <TAB> # Get keys, and feed to key processor. <TAB>  <TAB> keys = self.input.flush_keys() <TAB>  <TAB> self.key_processor.feed_multiple(keys) <TAB>  <TAB> self.key_processor.process_keys() <MASK> f.set_exception(EOFError)",if self . input . closed :,95
"def get_default_taxes_and_charges(master_doctype, tax_template=None, company=None): <TAB> if not company: <TAB>  <TAB> return {} <TAB> if tax_template and company: <TAB>  <TAB> tax_template_company = frappe.db.get_value( <TAB>  <TAB>  <TAB> master_doctype, tax_template, ""company"" <TAB>  <TAB> ) <MASK> return <TAB> default_tax = frappe.db.get_value( <TAB>  <TAB> master_doctype, {""is_default"": 1, ""company"": company} <TAB> ) <TAB> return { <TAB>  <TAB> ""taxes_and_charges"": default_tax, <TAB>  <TAB> ""taxes"": get_taxes_and_charges(master_doctype, default_tax), <TAB> }",if tax_template_company == company :,182
"def dump_prefs(self): <TAB> ret = """" <TAB> for pref in self.prefs: <TAB>  <TAB> if type(self.prefs[pref].value) == int: <TAB>  <TAB>  <TAB> value = str(self.prefs[pref].value) <MASK> value = ""true"" if self.prefs[pref].value == True else ""false"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = '""%s""' % self.prefs[pref].value <TAB>  <TAB> ret += pref + "": "" + value + "" ("" + self.prefs[pref].anon_source + "")\n"" <TAB> return ret",elif type ( self . prefs [ pref ] . value ) == bool :,150
"def dumps(o, **kwargs): <TAB> """"""Dumps JSON object."""""" <TAB> try: <TAB>  <TAB> return _engine[1](o) <TAB> except: <TAB>  <TAB> ExceptionClass, why = sys.exc_info()[:2] <MASK> raise JSONError(why) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise why","if any ( [ ( issubclass ( ExceptionClass , e ) ) for e in _engine [ 2 ] ] ) :",95
"def main(): <TAB> import sys, getopt <TAB> try: <TAB>  <TAB> opts, args = getopt.getopt(sys.argv[1:], ""ho:"", [""help"", ""output=""]) <TAB> except getopt.GetoptError as err: <TAB>  <TAB> usage() <TAB>  <TAB> sys.exit(1) <TAB> output = None <TAB> for o, a in opts: <MASK> usage() <TAB>  <TAB>  <TAB> sys.exit() <TAB>  <TAB> elif o in (""-o"", ""--output""): <TAB>  <TAB>  <TAB> output = a <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> usage() <TAB>  <TAB>  <TAB> sys.exit(1) <TAB> if not args: <TAB>  <TAB> usage() <TAB>  <TAB> sys.exit(1) <TAB> concat_flv(args, output)","if o in ( ""-h"" , ""--help"" ) :",175
"def close_group(self): <TAB> """"""Closes a grouping for previous filters"""""" <TAB> if self._filters: <TAB>  <TAB> if len(self._open_group_flag) < (len(self._close_group_flag) + 1): <TAB>  <TAB>  <TAB> raise RuntimeError(""Not enough open groups to close."") <MASK> flt_sentence = self._filters[-2] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> flt_sentence = self._filters[-1] <TAB>  <TAB> flt_sentence[1] = flt_sentence[1] + "")""  # closing the group <TAB>  <TAB> self._close_group_flag.append(False)  # flag a close group was added <TAB> else: <TAB>  <TAB> raise RuntimeError(""No filters present. Can't close a group"") <TAB> return self","if isinstance ( self . _filters [ - 1 ] , ChainOperator ) :",191
"def _GetPlugins(self, base_class): <TAB> items = [] <TAB> for name in sorted(base_class.classes.keys()): <TAB>  <TAB> cls = base_class.classes[name] <TAB>  <TAB> # While technically a valid plugin, UnknownOutputPlugin is only used as <TAB>  <TAB> # a placeholder when unserializing old and now-deleted output plugins. <TAB>  <TAB> # No need to display it in the UI. <TAB>  <TAB> if cls == output_plugin.UnknownOutputPlugin: <TAB>  <TAB>  <TAB> continue <MASK> items.append(ApiOutputPluginDescriptor().InitFromOutputPluginClass(cls)) <TAB> return items",if cls . description :,145
"def _set_helper(settings, path, value, data_type=None): <TAB> path = _to_settings_path(path) <TAB> method = settings.set <TAB> if data_type is not None: <TAB>  <TAB> name = None <TAB>  <TAB> if data_type == bool: <TAB>  <TAB>  <TAB> name = ""setBoolean"" <TAB>  <TAB> elif data_type == float: <TAB>  <TAB>  <TAB> name = ""setFloat"" <TAB>  <TAB> elif data_type == int: <TAB>  <TAB>  <TAB> name = ""setInt"" <MASK> method = getattr(settings, name) <TAB> method(path, value) <TAB> settings.save()",if name is not None :,150
"def _url_encode_impl(obj, charset, encode_keys, sort, key): <TAB> iterable = sdict() <TAB> for key, values in obj.items(): <TAB>  <TAB> if not isinstance(values, list): <TAB>  <TAB>  <TAB> values = [values] <TAB>  <TAB> iterable[key] = values <TAB> if sort: <TAB>  <TAB> iterable = sorted(iterable, key=key) <TAB> for key, values in iterable.items(): <TAB>  <TAB> for value in values: <TAB>  <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> key = str(key).encode(charset) <TAB>  <TAB>  <TAB> if not isinstance(value, bytes): <TAB>  <TAB>  <TAB>  <TAB> value = str(value).encode(charset) <TAB>  <TAB>  <TAB> yield url_quote_plus(key) + ""="" + url_quote_plus(value)","if not isinstance ( key , bytes ) :",198
"def validate_data(self, data, schema): <TAB> verrors = ValidationErrors() <TAB> provider = data[""provider""] <TAB> if provider == ""custom"": <TAB>  <TAB> for k in (""custom_ddns_server"", ""custom_ddns_path""): <MASK> verrors.add(f""{schema}.{k}"", ""Required when using a custom provider."") <TAB> elif provider not in (await self.provider_choices()): <TAB>  <TAB> verrors.add(f""{schema}.provider"", ""Please select a valid provider."") <TAB> verrors.check()",if not data [ k ] :,138
"def render(self): <TAB> x = ""<span>"" <TAB> for idx, arg in enumerate(self.args, start=1): <MASK> value, desc = arg <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value, desc = arg, arg <TAB>  <TAB> attrs = self.attrs.copy() <TAB>  <TAB> attrs[""name""] = self.name <TAB>  <TAB> attrs[""type""] = ""radio"" <TAB>  <TAB> attrs[""value""] = value <TAB>  <TAB> attrs[""id""] = self.name + str(idx) <TAB>  <TAB> if self.value == value: <TAB>  <TAB>  <TAB> attrs[""checked""] = ""checked"" <TAB>  <TAB> x += ""<input %s/> %s"" % (attrs, net.websafe(desc)) <TAB> x += ""</span>"" <TAB> return x","if isinstance ( arg , ( tuple , list ) ) :",183
"def search_rotate(array, val): <TAB> low, high = 0, len(array) - 1 <TAB> while low <= high: <TAB>  <TAB> mid = (low + high) // 2 <MASK> return mid <TAB>  <TAB> if array[low] <= array[mid]: <TAB>  <TAB>  <TAB> if array[low] <= val <= array[mid]: <TAB>  <TAB>  <TAB>  <TAB> high = mid - 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> low = mid + 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if array[mid] <= val <= array[high]: <TAB>  <TAB>  <TAB>  <TAB> low = mid + 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> high = mid - 1 <TAB> return -1",if val == array [ mid ] :,166
"def detect(get_page): <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS: <TAB>  <TAB> page, headers, code = get_page(get=vector) <TAB>  <TAB> retval = ( <TAB>  <TAB>  <TAB> re.search( <TAB>  <TAB>  <TAB>  <TAB> r""wangzhan\.360\.cn"", headers.get(""X-Powered-By-360wzb"", """"), re.I <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> is not None <TAB>  <TAB> ) <MASK> break <TAB> return retval",if retval :,125
"def _recalculate(self): <TAB> # If the parent's path has changed, recalculate _path <TAB> parent_path = tuple(self._get_parent_path())  # Make a copy <TAB> if parent_path != self._last_parent_path: <TAB>  <TAB> spec = self._path_finder(self._name, parent_path) <TAB>  <TAB> # Note that no changes are made if a loader is returned, but we <TAB>  <TAB> #  do remember the new parent path <MASK> if spec.submodule_search_locations: <TAB>  <TAB>  <TAB>  <TAB> self._path = spec.submodule_search_locations <TAB>  <TAB> self._last_parent_path = parent_path  # Save the copy <TAB> return self._path",if spec is not None and spec . loader is None :,174
"def _get_directory_item_content(filename, return_binary, encoding): <TAB> content = None <TAB> if os.path.exists(filename): <MASK> mode = ""rb"" <TAB>  <TAB>  <TAB> encoding = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> mode = ""r"" <TAB>  <TAB> with codecs.open(filename, mode, encoding=encoding) as file_obj: <TAB>  <TAB>  <TAB> content = file_obj.read() <TAB> return content",if return_binary :,110
"def randint(self, beg, end): <TAB> if beg == 1 and end == 10: <TAB>  <TAB> self.icnt1_10 += 1 <MASK> self.icnt1_10 = 1 <TAB>  <TAB> return self.RINT1_10[self.icnt1_10 - 1] <TAB> if beg == 65 and end == 90: <TAB>  <TAB> self.icnt65_90 += 1 <TAB>  <TAB> if self.icnt65_90 > len(self.RINT65_90): <TAB>  <TAB>  <TAB> self.icnt65_90 = 1 <TAB>  <TAB> return self.RINT65_90[self.icnt65_90 - 1] <TAB> raise Exception(""Not implemented"")",if self . icnt1_10 > len ( self . RINT1_10 ) :,178
"def _get_two_devices(self, require_same_type=False): <TAB> tpus = extensions.tpu_devices() <TAB> if FLAGS.requires_tpu: <MASK> res = tpus <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""This test requires 2 TPU cores but %s are found"" % len(tpus) <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> if len(tpus) == 2: <TAB>  <TAB>  <TAB> res = tpus <TAB>  <TAB> elif self._hasGPU() and not require_same_type: <TAB>  <TAB>  <TAB> res = (""CPU:0"", ""GPU:0"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> res = (""CPU:0"", ""CPU:1"") <TAB> return res",if len ( tpus ) == 2 :,184
"def edge2str(self, nfrom, nto): <TAB> if isinstance(nfrom, ExprCompose): <TAB>  <TAB> for i in nfrom.args: <TAB>  <TAB>  <TAB> if i[0] == nto: <TAB>  <TAB>  <TAB>  <TAB> return ""[%s, %s]"" % (i[1], i[2]) <TAB> elif isinstance(nfrom, ExprCond): <TAB>  <TAB> if nfrom.cond == nto: <TAB>  <TAB>  <TAB> return ""?"" <MASK> return ""True"" <TAB>  <TAB> elif nfrom.src2 == nto: <TAB>  <TAB>  <TAB> return ""False"" <TAB> return """"",elif nfrom . src1 == nto :,149
"def send_frame_imm(self, frame): <TAB> # send s_frame <TAB> if frame.name == ""s_frame"": <TAB>  <TAB> frame.RecvSeq = self.rsn <MASK> gevent.kill(self.t2_caller) <TAB>  <TAB> self.telegram_count = 0 <TAB>  <TAB> response_string = "" "".join(hex(n) for n in frame.build()) <TAB>  <TAB> logger.info( <TAB>  <TAB>  <TAB> ""%s <--- s_frame %s  (%s)"", self.address, response_string, self.session_id <TAB>  <TAB> ) <TAB>  <TAB> return self.sock.send(frame.build())",if self . t2_caller :,157
"def lin2lin(cp, size, size2): <TAB> _check_params(len(cp), size) <TAB> _check_size(size2) <TAB> if size == size2: <TAB>  <TAB> return cp <TAB> new_len = (len(cp) / size) * size2 <TAB> result = create_string_buffer(new_len) <TAB> for i in range(_sample_count(cp, size)): <TAB>  <TAB> sample = _get_sample(cp, size, i) <TAB>  <TAB> if size < size2: <TAB>  <TAB>  <TAB> sample = sample << (4 * size2 / size) <MASK> sample = sample >> (4 * size / size2) <TAB>  <TAB> sample = _overflow(sample, size2) <TAB>  <TAB> _put_sample(result, size2, i, sample) <TAB> return result.raw",elif size > size2 :,197
"def tangent(self, t): <TAB> result = np.array([0, 0, 0]) <TAB> o = self.omega <TAB> for i, coeff in enumerate(self.coeffs): <TAB>  <TAB> j = i // 2 <MASK> result += -(j + 1) * o * coeff * sin((j + 1) * o * t) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result += (j + 1) * o * coeff * cos((j + 1) * o * t) <TAB> return result",if i % 2 == 0 :,126
"def _run(self): <TAB> when_pressed = 0.0 <TAB> pressed = False <TAB> while not self._done.is_set(): <TAB>  <TAB> now = time.monotonic() <MASK> if GPIO.input(self._channel) == self._expected: <TAB>  <TAB>  <TAB>  <TAB> if not pressed: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pressed = True <TAB>  <TAB>  <TAB>  <TAB>  <TAB> when_pressed = now <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._trigger(self._pressed_queue, self._pressed_callback) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> if pressed: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pressed = False <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._trigger(self._released_queue, self._released_callback) <TAB>  <TAB> self._done.wait(0.05)",if now - when_pressed > self . _debounce_time :,187
"def check_dimensions(nrow, ncol): <TAB> if nrow is not None: <TAB>  <TAB> if nrow < 1: <TAB>  <TAB>  <TAB> warn( <TAB>  <TAB>  <TAB>  <TAB> ""'nrow' must be greater than 0. "" ""Your value has been ignored."", <TAB>  <TAB>  <TAB>  <TAB> PlotnineWarning, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> nrow = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> nrow = int(nrow) <TAB> if ncol is not None: <MASK> warn( <TAB>  <TAB>  <TAB>  <TAB> ""'ncol' must be greater than 0. "" ""Your value has been ignored."", <TAB>  <TAB>  <TAB>  <TAB> PlotnineWarning, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ncol = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ncol = int(ncol) <TAB> return nrow, ncol",if ncol < 1 :,189
"def visit_FunctionDef(self, node: ast.FunctionDef) -> None: <TAB> """"""Handles FunctionDef node and set context."""""" <TAB> if self.current_function is None: <TAB>  <TAB> self.add_entry( <TAB>  <TAB>  <TAB> node.name <TAB>  <TAB> )  # should be called before setting self.current_function <MASK> self.add_final_entry(node.name) <TAB>  <TAB> if self.is_overload(node.decorator_list): <TAB>  <TAB>  <TAB> self.add_overload_entry(node) <TAB>  <TAB> self.context.append(node.name) <TAB>  <TAB> self.current_function = node <TAB>  <TAB> for child in node.body: <TAB>  <TAB>  <TAB> self.visit(child) <TAB>  <TAB> self.context.pop() <TAB>  <TAB> self.current_function = None",if self . is_final ( node . decorator_list ) :,196
"def ret(stmt, params=()): <TAB> match = limit_re.match(stmt) <TAB> if match: <MASK> n = params[-1] <TAB>  <TAB>  <TAB> params = params[:-1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> n = int(match.group(2)) <TAB>  <TAB> store.sql(match.group(1), params) <TAB>  <TAB> return [store.cursor.fetchone() for i in xrange(n)] <TAB> return selectall(stmt, params)","if match . group ( 2 ) == ""?"" :",119
"def OnBodyClick(self, event=None): <TAB> try: <TAB>  <TAB> c = self.c <TAB>  <TAB> p = c.currentPosition() <MASK> self.OnActivateBody(event=event) <TAB>  <TAB>  <TAB> c.k.showStateAndMode(w=c.frame.body.bodyCtrl) <TAB>  <TAB> g.doHook(""bodyclick2"", c=c, p=p, v=p, event=event) <TAB> except: <TAB>  <TAB> g.es_event_exception(""bodyclick"")","if not g . doHook ( ""bodyclick1"" , c = c , p = p , v = p , event = event ) :",148
"def verify_settings(rst_path: Path) -> Iterator[Error]: <TAB> for setting_name, default in find_settings_in_rst(rst_path): <TAB>  <TAB> actual = getattr(app.conf, setting_name) <TAB>  <TAB> if isinstance(default, timedelta): <TAB>  <TAB>  <TAB> default = default.total_seconds() <MASK> actual = actual.value <TAB>  <TAB> if actual != default: <TAB>  <TAB>  <TAB> yield Error( <TAB>  <TAB>  <TAB>  <TAB> reason=""mismatch"", <TAB>  <TAB>  <TAB>  <TAB> setting=setting_name, <TAB>  <TAB>  <TAB>  <TAB> default=default, <TAB>  <TAB>  <TAB>  <TAB> actual=actual, <TAB>  <TAB>  <TAB> )","if isinstance ( actual , Enum ) :",152
"def fromVariant(variant): <TAB> if hasattr(QtCore, ""QVariant"") and isinstance(variant, QtCore.QVariant): <TAB>  <TAB> t = variant.type() <TAB>  <TAB> if t == QtCore.QVariant.String: <TAB>  <TAB>  <TAB> return str(variant.toString()) <TAB>  <TAB> elif t == QtCore.QVariant.Double: <TAB>  <TAB>  <TAB> return variant.toDouble()[0] <MASK> return variant.toInt()[0] <TAB>  <TAB> elif t == QtCore.QVariant.Bool: <TAB>  <TAB>  <TAB> return variant.toBool() <TAB>  <TAB> elif t == QtCore.QVariant.Invalid: <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError('Unsupported QVariant type ""%s""' % variant.typeName()) <TAB> else: <TAB>  <TAB> return variant",elif t == QtCore . QVariant . Int :,195
"def decode_list(self, prop, value): <TAB> if not isinstance(value, list): <TAB>  <TAB> value = [value] <TAB> if hasattr(prop, ""item_type""): <TAB>  <TAB> item_type = getattr(prop, ""item_type"") <TAB>  <TAB> dec_val = {} <TAB>  <TAB> for val in value: <MASK> k, v = self.decode_map_element(item_type, val) <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> k = int(k) <TAB>  <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> k = v <TAB>  <TAB>  <TAB>  <TAB> dec_val[k] = v <TAB>  <TAB> value = dec_val.values() <TAB> return value",if val is not None :,170
"def has_valid_checksum(self, number): <TAB> given_number, given_checksum = number[:-1], number[-1] <TAB> calculated_checksum = 0 <TAB> parameter = 7 <TAB> for item in given_number: <TAB>  <TAB> fragment = str(int(item) * parameter) <TAB>  <TAB> if fragment.isalnum(): <TAB>  <TAB>  <TAB> calculated_checksum += int(fragment[-1]) <TAB>  <TAB> if parameter == 1: <TAB>  <TAB>  <TAB> parameter = 7 <MASK> parameter = 1 <TAB>  <TAB> elif parameter == 7: <TAB>  <TAB>  <TAB> parameter = 3 <TAB> return str(calculated_checksum)[-1] == given_checksum",elif parameter == 3 :,147
"def encoder(s, *args, **kwargs): <TAB> r = [] <TAB> _in = [] <TAB> for c in s: <TAB>  <TAB> if ord(c) in PRINTABLE: <TAB>  <TAB>  <TAB> doB64(_in, r) <TAB>  <TAB>  <TAB> r.append(c.encode()) <MASK> doB64(_in, r) <TAB>  <TAB>  <TAB> r.append(b""&-"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _in.append(c) <TAB> doB64(_in, r) <TAB> return (b"""".join(r), len(s))","elif c == ""&"" :",137
"def construct_instances(self, row, keys=None): <TAB> collected_models = {} <TAB> for i, (key, constructor, attr, conv) in enumerate(self.column_map): <TAB>  <TAB> if keys is not None and key not in keys: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> value = row[i] <TAB>  <TAB> if key not in collected_models: <TAB>  <TAB>  <TAB> collected_models[key] = constructor() <TAB>  <TAB> instance = collected_models[key] <TAB>  <TAB> if attr is None: <TAB>  <TAB>  <TAB> attr = self.cursor.description[i][0] <MASK> value = conv(value) <TAB>  <TAB> setattr(instance, attr, value) <TAB> return collected_models",if conv is not None :,167
"def try_to_find_osquery(self): <TAB> extention = """" <MASK> extention = "".exe"" <TAB> try: <TAB>  <TAB> return resources.get_resource(""osqueryi"" + extention) <TAB> except IOError as e: <TAB>  <TAB> # Maybe it is installed on the system. <TAB>  <TAB> if platform.system() == ""Windows"": <TAB>  <TAB>  <TAB> result = r""c:\ProgramData\osquery\osqueryi.exe"" <TAB>  <TAB>  <TAB> if os.access(result, os.R_OK): <TAB>  <TAB>  <TAB>  <TAB> return result <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Try to find it somewhere on the system. <TAB>  <TAB>  <TAB> return spawn.find_executable(""osqueryi"") <TAB>  <TAB> raise e","if platform . system ( ) == ""Windows"" :",178
"def get_cached_stats(self, split=tfds.Split.TRAIN): <TAB> """"""Returns basic statistics for cached dataset."""""" <TAB> self.assert_cached() <TAB> if split not in self._stats: <TAB>  <TAB> stats_path = get_stats_path(self.cache_dir, split) <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Stats do not exist for '%s' split: %s"" % (self.name, split) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> with tf.io.gfile.GFile(stats_path) as f: <TAB>  <TAB>  <TAB> self._stats[split] = json.load(f) <TAB> return self._stats[split]",if not tf . io . gfile . exists ( stats_path ) :,169
"def _network_connections_in_results(data): <TAB> for plugin_name, plugin_result in data.iteritems(): <MASK> continue <TAB>  <TAB> if ""device"" not in plugin_result: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if ""connections"" in plugin_result[""device""]: <TAB>  <TAB>  <TAB> for conn in plugin_result[""device""][""connections""]: <TAB>  <TAB>  <TAB>  <TAB> if conn[""connection_type""] == ConnectionType.network.name: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False","if plugin_result [ ""status"" ] == ""error"" :",126
"def register_asyncio_task(self, task, module_path=None): <TAB> if self._current[""metadata""] is None: <MASK> raise RuntimeError(""module_path must be supplied for late-binded tasks"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.list[module_path][""asyncio.task""].append(task) <TAB> else: <TAB>  <TAB> self._current[""asyncio.task""].append(task)",if module_path is None :,105
"def __prep_write_total(self, comments, main, fallback, single): <TAB> lower = self.as_lowercased() <TAB> for k in [main, fallback, single]: <TAB>  <TAB> if k in comments: <TAB>  <TAB>  <TAB> del comments[k] <TAB> if single in lower: <TAB>  <TAB> parts = lower[single].split(""/"", 1) <TAB>  <TAB> if parts[0]: <TAB>  <TAB>  <TAB> comments[single] = [parts[0]] <MASK> comments[main] = [parts[1]] <TAB> if main in lower: <TAB>  <TAB> comments[main] = lower.list(main) <TAB> if fallback in lower: <TAB>  <TAB> if main in comments: <TAB>  <TAB>  <TAB> comments[fallback] = lower.list(fallback) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> comments[main] = lower.list(fallback)",if len ( parts ) > 1 :,196
"def api(request, app): <TAB> marker = request.keywords.get(""api"") <TAB> bpkwargs = {} <TAB> kwargs = {} <TAB> if marker: <MASK> bpkwargs[""url_prefix""] = marker.kwargs.pop(""prefix"") <TAB>  <TAB> if ""subdomain"" in marker.kwargs: <TAB>  <TAB>  <TAB> bpkwargs[""subdomain""] = marker.kwargs.pop(""subdomain"") <TAB>  <TAB> kwargs = marker.kwargs <TAB> blueprint = Blueprint(""api"", __name__, **bpkwargs) <TAB> api = restplus.Api(blueprint, **kwargs) <TAB> app.register_blueprint(blueprint) <TAB> yield api","if ""prefix"" in marker . kwargs :",157
"def _get_pip_index_urls(sources): <TAB> index_urls = [] <TAB> trusted_hosts = [] <TAB> for source in sources: <TAB>  <TAB> url = source.get(""url"") <MASK> continue <TAB>  <TAB> index_urls.append(url) <TAB>  <TAB> if source.get(""verify_ssl"", True): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> host = six.moves.urllib.parse.urlparse(source[""url""]).hostname <TAB>  <TAB> trusted_hosts.append(host) <TAB> return index_urls, trusted_hosts",if not url :,129
"def add_aggregation_data(self, payload): <TAB> for timestamp, payload_data in payload.items(): <TAB>  <TAB> if ""interval_aggs"" in payload_data: <TAB>  <TAB>  <TAB> self.unwrap_interval_buckets( <TAB>  <TAB>  <TAB>  <TAB> timestamp, None, payload_data[""interval_aggs""][""buckets""] <TAB>  <TAB>  <TAB> ) <MASK> self.unwrap_term_buckets(timestamp, payload_data[""bucket_aggs""][""buckets""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.check_matches(timestamp, None, payload_data)","elif ""bucket_aggs"" in payload_data :",136
"def _handle_unverified_signed_presence(self, pres): <TAB> verified = self.verify(pres[""status""], pres[""signed""]) <TAB> if verified.key_id: <TAB>  <TAB> if not self.get_keyid(pres[""from""]): <TAB>  <TAB>  <TAB> known_keyids = [e[""keyid""] for e in self.gpg.list_keys()] <MASK> self.gpg.recv_keys(self.key_server, verified.key_id) <TAB>  <TAB>  <TAB> self.set_keyid(jid=pres[""from""], keyid=verified.key_id) <TAB>  <TAB> self.xmpp.event(""signed_presence"", pres)",if verified . key_id not in known_keyids :,170
"def __init__(self, *args, **kwargs): <TAB> """"""Initialize the texture."""""" <TAB> super().__init__(*args, **kwargs) <TAB> assert_empty_kwargs(**kwargs) <TAB> if len(args) == 1: <TAB>  <TAB> if isinstance(args[0], vtk.vtkTexture): <TAB>  <TAB>  <TAB> self._from_texture(args[0]) <TAB>  <TAB> elif isinstance(args[0], np.ndarray): <TAB>  <TAB>  <TAB> self._from_array(args[0]) <TAB>  <TAB> elif isinstance(args[0], vtk.vtkImageData): <TAB>  <TAB>  <TAB> self._from_image_data(args[0]) <MASK> self._from_file(filename=args[0]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError(f""Table unable to be made from ({type(args[0])})"")","elif isinstance ( args [ 0 ] , str ) :",200
"def get_manifest_data(manifestpath): <TAB> """"""Reads a manifest file, returns a dictionary-like object."""""" <TAB> plist = {} <TAB> try: <TAB>  <TAB> plist = FoundationPlist.readPlist(manifestpath) <TAB> except FoundationPlist.NSPropertyListSerializationException: <TAB>  <TAB> display.display_error(u""Could not read plist: %s"", manifestpath) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> os.unlink(manifestpath) <TAB>  <TAB>  <TAB> except OSError as err: <TAB>  <TAB>  <TAB>  <TAB> display.display_error(u""Failed to delete plist: %s"", err) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> display.display_error(""plist does not exist."") <TAB> return plist",if os . path . exists ( manifestpath ) :,172
"def _get_proxy(self): <TAB> url_dissected = url_dissector.findall(self.session[""proxy""]) <TAB> if url_dissected and len(url_dissected[0]) == 3: <TAB>  <TAB> protocol, host, port = url_dissected[0] <MASK> return (socks.PROXY_TYPE_SOCKS5, host, int(port)) <TAB>  <TAB> if protocol == ""socks4"": <TAB>  <TAB>  <TAB> return (socks.PROXY_TYPE_SOCKS4, host, int(port)) <TAB>  <TAB> if protocol.startswith(""http""): <TAB>  <TAB>  <TAB> return (socks.PROXY_TYPE_HTTP, host, int(port)) <TAB> return None, None, None","if protocol == ""socks5"" :",172
"def nud(self): <TAB> self.first = [] <TAB> comma = False <TAB> if self.token.id != "")"": <TAB>  <TAB> while 1: <TAB>  <TAB>  <TAB> if self.token.id == "")"": <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> self.first.append(self.expression()) <MASK> comma = True <TAB>  <TAB>  <TAB>  <TAB> self.advance("","") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> break <TAB> self.advance("")"") <TAB> if not self.first or comma: <TAB>  <TAB> return self  # tuple <TAB> else: <TAB>  <TAB> return self.first[0]","if self . token . id == "","" :",146
"def _debug_log(self, text, level): <TAB> if text and ""log"" in self.config.sys.debug: <TAB>  <TAB> if not text.startswith(self.log_prefix): <TAB>  <TAB>  <TAB> text = ""%slog(%s): %s"" % (self.log_prefix, level, text) <MASK> return self.log_parent.log(level, text) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.term.write(self._fmt_log(text, level=level))",if self . log_parent is not None :,129
"def remove_checker(self, namespace, checker): <TAB> for c in pyomo.core.check.ModelCheckRunner._checkers(all=True): <TAB>  <TAB> if c._checkerName() == checker: <MASK> for i in range( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> namespace.checkers[c._checkerPackage()].count(c._checkerName()) <TAB>  <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> namespace.checkers[c._checkerPackage()].remove(c._checkerName())","if namespace . checkers . get ( c . _checkerPackage ( ) , None ) is not None :",129
"def check_if_role_exists(self, role_name, parsed_globals): <TAB> parameters = {""RoleName"": role_name} <TAB> try: <TAB>  <TAB> self._call_iam_operation(""GetRole"", parameters, parsed_globals) <TAB> except botocore.exceptions.ClientError as e: <TAB>  <TAB> role_not_found_code = ""NoSuchEntity"" <TAB>  <TAB> error_code = e.response.get(""Error"", {}).get(""Code"", """") <MASK> # No role error. <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Some other error. raise. <TAB>  <TAB>  <TAB> raise e <TAB> return True",if role_not_found_code == error_code :,158
"def GetClipboardText(): <TAB> text = """" <TAB> if OpenClipboard(0): <TAB>  <TAB> hClipMem = GetClipboardData(CF_TEXT) <MASK> GlobalLock.restype = c_char_p <TAB>  <TAB>  <TAB> text = GlobalLock(hClipMem) <TAB>  <TAB>  <TAB> GlobalUnlock(hClipMem) <TAB>  <TAB> CloseClipboard() <TAB> return ensure_unicode(text)",if hClipMem :,100
"def test_log_action_class(): <TAB> v = Mock() <TAB> for k, v in amo.LOG_BY_ID.items(): <MASK> cls = ""action-"" + v.action_class <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> cls = """" <TAB>  <TAB> assert render(""{{ log_action_class(id) }}"", {""id"": v.id}) == cls",if v . action_class is not None :,100
"def _get_distinct_albumartists(config, session, web_client, query): <TAB> logger.debug(f""Getting distinct albumartists: {query}"") <TAB> if query: <TAB>  <TAB> search_result = _get_search(config, session, web_client, query, album=True) <TAB>  <TAB> return { <TAB>  <TAB>  <TAB> artist.name <TAB>  <TAB>  <TAB> for album in search_result.albums <TAB>  <TAB>  <TAB> for artist in album.artists <TAB>  <TAB>  <TAB> if album.artists <TAB>  <TAB> } <TAB> else: <TAB>  <TAB> return { <TAB>  <TAB>  <TAB> track.album.artist.name <TAB>  <TAB>  <TAB> for track in _get_playlist_tracks(config, session) <MASK> }",if track . album and track . album . artist,169
"def _get_commands(): <TAB> proc = Popen([""react-native"", ""--help""], stdout=PIPE) <TAB> should_yield = False <TAB> for line in proc.stdout.readlines(): <TAB>  <TAB> line = line.decode().strip() <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB> continue <MASK> should_yield = True <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if should_yield: <TAB>  <TAB>  <TAB> yield line.split("" "")[0]","if ""Commands:"" in line :",111
"def __call__(self, job): <TAB> import tensorboard_logger as tl <TAB> # id = job.id <TAB> budget = job.kwargs[""budget""] <TAB> # config = job.kwargs['config'] <TAB> timestamps = job.timestamps <TAB> result = job.result <TAB> exception = job.exception <TAB> time_step = int(timestamps[""finished""] - self.start_time) <TAB> if result is not None: <TAB>  <TAB> tl.log_value(""BOHB/all_results"", result[""loss""] * -1, time_step) <MASK> self.incumbent = result[""loss""] <TAB>  <TAB> tl.log_value(""BOHB/incumbent_results"", self.incumbent * -1, time_step)","if result [ ""loss"" ] < self . incumbent :",193
"def _parse_yum_or_zypper_repositories(output): <TAB> repos = [] <TAB> current_repo = {} <TAB> for line in output: <TAB>  <TAB> line = line.strip() <TAB>  <TAB> if not line or line.startswith(""#""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if line.startswith(""[""): <MASK> repos.append(current_repo) <TAB>  <TAB>  <TAB>  <TAB> current_repo = {} <TAB>  <TAB>  <TAB> current_repo[""name""] = line[1:-1] <TAB>  <TAB> if current_repo and ""="" in line: <TAB>  <TAB>  <TAB> key, value = line.split(""="", 1) <TAB>  <TAB>  <TAB> current_repo[key] = value <TAB> if current_repo: <TAB>  <TAB> repos.append(current_repo) <TAB> return repos",if current_repo :,179
"def selector(): <TAB> while True: <TAB>  <TAB> rlist, _, _ = select([proc.stdout, proc.stderr], [], [], line_timeout) <MASK> raise ProcessLineTimedOut( <TAB>  <TAB>  <TAB>  <TAB> ""popen line timeout expired"", <TAB>  <TAB>  <TAB>  <TAB> getattr(proc, ""argv"", None), <TAB>  <TAB>  <TAB>  <TAB> getattr(proc, ""machine"", None), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> for stream in rlist: <TAB>  <TAB>  <TAB> yield (stream is proc.stderr), decode(stream.readline(linesize))",if not rlist and line_timeout :,127
"def getBranchFromFile(): <TAB> global _gitdir <TAB> branch = None <TAB> if _gitdir: <TAB>  <TAB> headFile = os.path.join(_gitdir, ""HEAD"") <TAB>  <TAB> if os.path.isfile(headFile): <TAB>  <TAB>  <TAB> with open(headFile, ""r"", encoding=""utf-8"") as f: <TAB>  <TAB>  <TAB>  <TAB> line = f.readline() <TAB>  <TAB>  <TAB>  <TAB> if line: <MASK> branch = line.split(""/"")[-1].strip() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> branch = ""HEAD"" <TAB> return branch","if line . startswith ( ""ref"" ) :",151
"def handle(self, msg): <TAB> self._mic.send(msg) <TAB> for calculate_seed, make_delegate, dict in self._delegate_records: <TAB>  <TAB> id = calculate_seed(msg) <TAB>  <TAB> if id is None: <TAB>  <TAB>  <TAB> continue <MASK> if id not in dict or not dict[id].is_alive(): <TAB>  <TAB>  <TAB>  <TAB> d = make_delegate((self, msg, id)) <TAB>  <TAB>  <TAB>  <TAB> d = self._ensure_startable(d) <TAB>  <TAB>  <TAB>  <TAB> dict[id] = d <TAB>  <TAB>  <TAB>  <TAB> dict[id].start() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> d = make_delegate((self, msg, id)) <TAB>  <TAB>  <TAB> d = self._ensure_startable(d) <TAB>  <TAB>  <TAB> d.start()","elif isinstance ( id , collections . Hashable ) :",192
"def _print_items(items, _filter=None): <TAB> if _filter: <TAB>  <TAB> print(""Displaying items matching filter: %s"" % _filter) <TAB> print() <TAB> for item in items: <TAB>  <TAB> filtered_out = False <TAB>  <TAB> for f in _filter.split(): <MASK> filtered_out = True <TAB>  <TAB> if not filtered_out: <TAB>  <TAB>  <TAB> print(item) <TAB> print()",if f . lower ( ) not in item . lower ( ) :,113
"def _cbAllRecords(self, results): <TAB> ans, auth, add = [], [], [] <TAB> for res in results: <MASK> ans.extend(res[1][0]) <TAB>  <TAB>  <TAB> auth.extend(res[1][1]) <TAB>  <TAB>  <TAB> add.extend(res[1][2]) <TAB> return ans, auth, add",if res [ 0 ] :,87
"def __status_update(self): <TAB> was_active = False <TAB> while True: <TAB>  <TAB> if self.analytics_instance.active: <TAB>  <TAB>  <TAB> was_active = True <TAB>  <TAB>  <TAB> msg = ""Active (%s)"" % self.analytics_instance.progress <TAB>  <TAB>  <TAB> self.broadcast(msg, ""analytics"", ""analyticsUpdate"") <MASK> self.broadcast(""Inactive"", ""analytics"", ""analyticsUpdate"") <TAB>  <TAB>  <TAB> was_active = False <TAB>  <TAB> time.sleep(0.2)",if was_active and not self . analytics_instance . active :,133
"def plugin_song(self, song): <TAB> for tag in [""album""]: <TAB>  <TAB> values = filter(None, map(album_to_sort, song.list(tag))) <MASK> song[tag + ""sort""] = ""\n"".join(values) <TAB> for tag in [""artist"", ""albumartist"", ""performer""]: <TAB>  <TAB> values = filter(None, map(artist_to_sort, song.list(tag))) <TAB>  <TAB> if values and (tag + ""sort"") not in song: <TAB>  <TAB>  <TAB> song[tag + ""sort""] = ""\n"".join(values)","if values and ( tag + ""sort"" ) not in song :",149
"def update(h, s): <TAB> with lock: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> i, c = find_cell(h) <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> return <MASK> c.content = parse(s) <TAB>  <TAB>  <TAB> render_from(i, clear_after=True)",if not c . frozen and c . content != s :,86
"def get_parameters(self, names, with_decryption): <TAB> result = [] <TAB> if len(names) > 10: <TAB>  <TAB> raise ValidationException( <TAB>  <TAB>  <TAB> ""1 validation error detected: "" <TAB>  <TAB>  <TAB> ""Value '[{}]' at 'names' failed to satisfy constraint: "" <TAB>  <TAB>  <TAB> ""Member must have length less than or equal to 10."".format("", "".join(names)) <TAB>  <TAB> ) <TAB> for name in names: <MASK> result.append(self.get_parameter(name, with_decryption)) <TAB> return result",if name in self . _parameters :,134
"def entered_file_action(self, path): <TAB> attempt_copy = True <TAB> path = self.try_append_extension(path) <TAB> directory = os.path.dirname(path) <TAB> if not os.path.exists(directory): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.create_folder(directory) <TAB>  <TAB> except OSError as e: <TAB>  <TAB>  <TAB> attempt_copy = False <TAB>  <TAB>  <TAB> sublime.error_message( <TAB>  <TAB>  <TAB>  <TAB> ""Cannot create '"" + path + ""'."" + "" See console for details"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> print(""Exception: %s '%s'"" % (e.strerror, e.filename)) <TAB> if attempt_copy: <TAB>  <TAB> copy_success, new_file = self._copy_file(path) <MASK> self.open_file(new_file)",if copy_success :,200
"def acquire(self): <TAB> ""Acquire semaphore by decrementing value using spin-lock algorithm."" <TAB> while True: <TAB>  <TAB> with self._cache.transact(retry=True): <TAB>  <TAB>  <TAB> value = self._cache.get(self._key, default=self._value) <MASK> self._cache.set( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._key, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value - 1, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> expire=self._expire, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> tag=self._tag, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> time.sleep(0.001)",if value > 0 :,153
"def commit(self): <TAB> doc = {} <TAB> for field, default in self.fields.iteritems(): <MASK> value = getattr(self, field) <TAB>  <TAB>  <TAB> if field in self.commit_fields or value != default: <TAB>  <TAB>  <TAB>  <TAB> doc[field] = getattr(self, field) <TAB> with open(self.path, ""w"") as settings_file: <TAB>  <TAB> settings_file.write(json.dumps(doc, indent=4))","if hasattr ( self , field ) :",115
"def parse_entrypoints(self, content: str, root=None) -> RootDependency: <TAB> if root is None: <TAB>  <TAB> root = RootDependency() <TAB> entrypoints = [] <TAB> group = ""console_scripts"" <TAB> for line in content.split(""\n""): <TAB>  <TAB> line = line.strip() <MASK> # ignore comments <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if line[0] == ""["" and line[-1] == ""]"": <TAB>  <TAB>  <TAB> group = line[1:-1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> entrypoints.append(EntryPoint.parse(text=line, group=group)) <TAB> root.entrypoints = tuple(entrypoints) <TAB> return root","if not line or line [ 0 ] in ""#;"" :",162
"def request_with_retries(endpoint, timeout=30): <TAB> start = time.time() <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return requests.get(""http://127.0.0.1:8000"" + endpoint, timeout=timeout) <TAB>  <TAB> except requests.RequestException: <MASK> raise TimeoutError <TAB>  <TAB>  <TAB> time.sleep(0.1)",if time . time ( ) - start > timeout :,101
"def get_expression(self): <TAB> """"""Return the expression as a printable string."""""" <TAB> l = [] <TAB> for c in self.content: <MASK> # only applies to first cell <TAB>  <TAB>  <TAB> l.append(c.op) <TAB>  <TAB> if c.child is not None: <TAB>  <TAB>  <TAB> l.append(""("" + c.child.get_expression() + "")"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> l.append(""%d"" % c.get_value()) <TAB> return """".join(l)",if c . op is not None :,124
"def nrgen_asc(self): <TAB> # compute the number of generations present <TAB> for generation in range(self.generations_asc - 1, 0, -1): <TAB>  <TAB> for p in range(len(self.data[generation])): <TAB>  <TAB>  <TAB> (person, parents, child, userdata) = self.data[generation][p] <MASK> return generation <TAB> return 1",if person :,96
"def check_all_verified(self): <TAB> if not self.all_verified: <TAB>  <TAB> new_all_verified = not self.lines.filter(verified=False).exists() <TAB>  <TAB> if new_all_verified: <TAB>  <TAB>  <TAB> self.all_verified = True <MASK> self.add_log_entry( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _(""All rows requiring verification have been verified."") <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> self.require_verification = False <TAB>  <TAB>  <TAB> self.save() <TAB> return self.all_verified",if self . require_verification :,136
"def sort(self, cmp=None, key=None, reverse=False): <TAB> ""Standard list sort method"" <TAB> if key: <TAB>  <TAB> temp = [(key(v), v) for v in self] <TAB>  <TAB> temp.sort(key=lambda x: x[0], reverse=reverse) <TAB>  <TAB> self[:] = [v[1] for v in temp] <TAB> else: <TAB>  <TAB> temp = list(self) <MASK> temp.sort(cmp=cmp, reverse=reverse) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> temp.sort(reverse=reverse) <TAB>  <TAB> self[:] = temp",if cmp is not None :,146
"def process_formdata(self, valuelist): <TAB> if valuelist: <TAB>  <TAB> date_str = "" "".join(valuelist) <TAB>  <TAB> if not date_str: <TAB>  <TAB>  <TAB> self.data = None <TAB>  <TAB>  <TAB> raise ValidationError(self.gettext(""Please input a date/time value"")) <TAB>  <TAB> parse_kwargs = self.parse_kwargs.copy() <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> parse_kwargs[""default""] = self.default() <TAB>  <TAB>  <TAB> except TypeError: <TAB>  <TAB>  <TAB>  <TAB> parse_kwargs[""default""] = self.default <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.data = parser.parse(date_str, **parse_kwargs) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> self.data = None <TAB>  <TAB>  <TAB> raise ValidationError(self.gettext(""Invalid date/time input""))","if ""default"" not in parse_kwargs :",196
"def _expand_dim_shape_func(data_shape, ndim, axis, num_newaxis): <TAB> out = output_tensor((ndim + num_newaxis,), ""int64"") <TAB> for i in const_range(out.shape[0]): <TAB>  <TAB> if i < axis: <TAB>  <TAB>  <TAB> out[i] = data_shape[i] <MASK> out[i] = int64(1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> out[i] = data_shape[i - num_newaxis] <TAB> return out",elif i < axis + num_newaxis :,133
"def _Return(self, t): <TAB> self._fill(""return "") <TAB> if t.value: <TAB>  <TAB> if isinstance(t.value, Tuple): <TAB>  <TAB>  <TAB> text = "", "".join([name.name for name in t.value.asList()]) <TAB>  <TAB>  <TAB> self._write(text) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._dispatch(t.value) <MASK> self._write(""; "")",if not self . _do_indent :,106
"def blas_header_version(): <TAB> # Version for the base header <TAB> version = (9,) <TAB> if detect_macos_sdot_bug(): <MASK> # Version with fix <TAB>  <TAB>  <TAB> version += (1,) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Version with error <TAB>  <TAB>  <TAB> version += (2,) <TAB> return version",if detect_macos_sdot_bug . fix_works :,97
"def get_queues(self, region: str, attribute_names: []): <TAB> sqs_client = AWSFacadeUtils.get_client(""sqs"", self.session, region) <TAB> try: <TAB>  <TAB> raw_queues = await run_concurrently(sqs_client.list_queues) <TAB> except Exception as e: <TAB>  <TAB> print_exception(f""Failed to list SQS queues: {e}"") <TAB>  <TAB> return [] <TAB> else: <MASK> return [] <TAB>  <TAB> queue_urls = raw_queues[""QueueUrls""] <TAB>  <TAB> return await map_concurrently( <TAB>  <TAB>  <TAB> self._get_queue_attributes, <TAB>  <TAB>  <TAB> queue_urls, <TAB>  <TAB>  <TAB> region=region, <TAB>  <TAB>  <TAB> attribute_names=attribute_names, <TAB>  <TAB> )","if ""QueueUrls"" not in raw_queues :",189
"def popupFrameXdiff(job, frame1, frame2, frame3=None): <TAB> """"""Opens a frame xdiff."""""" <TAB> for command in [""/usr/bin/xxdiff"", ""/usr/local/bin/xdiff""]: <TAB>  <TAB> if os.path.isfile(command): <TAB>  <TAB>  <TAB> for frame in [frame1, frame2, frame3]: <MASK> command += "" --title1 %s %s"" % ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> frame.data.name, <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> getFrameLogFile(job, frame), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> shellOut(command)",if frame :,154
"def wrap(*args, **kwargs): <TAB> callargs = getcallargs(fun, *args, **kwargs) <TAB> if callargs[""sock""] is None: <TAB>  <TAB> # This variable is used only to debug leak in tests <TAB>  <TAB> COUNT[""count""] += 1 <TAB>  <TAB> with IPSet() as sock: <TAB>  <TAB>  <TAB> callargs[""sock""] = sock <TAB>  <TAB>  <TAB> # We must pop kwargs here, else the function will receive <TAB>  <TAB>  <TAB> # a dict of dict <MASK> callargs.update(callargs.pop(""kwargs"")) <TAB>  <TAB>  <TAB> return fun(**callargs)  # pylint:disable=star-args <TAB> return fun(*args, **kwargs)","if ""kwargs"" in callargs :",164
"def set_multi(self, value): <TAB> del self[atype] <TAB> for addr in value: <TAB>  <TAB> # Support assigning dictionary versions of addresses <TAB>  <TAB> # instead of full Address objects. <TAB>  <TAB> if not isinstance(addr, Address): <MASK> addr[""type""] = atype <TAB>  <TAB>  <TAB> elif ""atype"" in addr and ""type"" not in addr: <TAB>  <TAB>  <TAB>  <TAB> addr[""type""] = addr[""atype""] <TAB>  <TAB>  <TAB> addrObj = Address() <TAB>  <TAB>  <TAB> addrObj.values = addr <TAB>  <TAB>  <TAB> addr = addrObj <TAB>  <TAB> self.append(addr)","if atype != ""all"" :",146
"def test_connection(self, data=None, raise_alert=False): <TAB> try: <TAB>  <TAB> result = self._test_connection(self.connection_config(data)) <TAB> except CallError as e: <TAB>  <TAB> result = {""error"": True, ""exception"": str(e)} <TAB> if result[""error""]: <MASK> config = self.middleware.call_sync(""kmip.config"") <TAB>  <TAB>  <TAB> self.middleware.call_sync( <TAB>  <TAB>  <TAB>  <TAB> ""alert.oneshot_create"", <TAB>  <TAB>  <TAB>  <TAB> ""KMIPConnectionFailed"", <TAB>  <TAB>  <TAB>  <TAB> {""server"": config[""server""], ""error"": result[""exception""]}, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return False <TAB> else: <TAB>  <TAB> return True",if raise_alert :,174
"def test05_geometries(self): <TAB> ""Testing Geometries from Data Source Features."" <TAB> for source in ds_list: <TAB>  <TAB> ds = DataSource(source.ds) <TAB>  <TAB> # Incrementing through each layer and feature. <TAB>  <TAB> for layer in ds: <TAB>  <TAB>  <TAB> for feat in layer: <TAB>  <TAB>  <TAB>  <TAB> g = feat.geom <TAB>  <TAB>  <TAB>  <TAB> # Making sure we get the right Geometry name & type <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(source.geom, g.geom_name) <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(source.gtype, g.geom_type) <TAB>  <TAB>  <TAB>  <TAB> # Making sure the SpatialReference is as expected. <MASK> self.assertEqual(source.srs_wkt, g.srs.wkt)","if hasattr ( source , ""srs_wkt"" ) :",197
"def __walk_dir_tree(self, dirname): <TAB> dir_list = [] <TAB> self.__logger.debug(""__walk_dir_tree. START dir=%s"", dirname) <TAB> for f in os.listdir(dirname): <TAB>  <TAB> current = os.path.join(dirname, f) <TAB>  <TAB> if os.path.isfile(current) and f.endswith(""py""): <MASK> self._load_py_from_file(current) <TAB>  <TAB>  <TAB> dir_list.append(current) <TAB>  <TAB> elif os.path.isdir(current): <TAB>  <TAB>  <TAB> ret = self.__walk_dir_tree(current) <TAB>  <TAB>  <TAB> if ret: <TAB>  <TAB>  <TAB>  <TAB> dir_list.append((f, ret)) <TAB> return dir_list",if self . module_registrant :,184
"def setData(self, data=None): <TAB> # update the data for the grid <TAB> for nRow in range(self.nRows): <TAB>  <TAB> for nCol in range(self.nCols): <MASK> self.SetCellValue(nRow, nCol, ""%f"" % data[nRow, nCol]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.SetCellValue(nRow, nCol, ""0.000"") <TAB> self.AutoSize()",if data is not None and nRow < data . shape [ 0 ] and nCol < data . shape [ 1 ] :,141
"def __init__(self, *args, **kwargs): <TAB> """"""Initialize the texture."""""" <TAB> super().__init__(*args, **kwargs) <TAB> assert_empty_kwargs(**kwargs) <TAB> if len(args) == 1: <TAB>  <TAB> if isinstance(args[0], vtk.vtkTexture): <TAB>  <TAB>  <TAB> self._from_texture(args[0]) <TAB>  <TAB> elif isinstance(args[0], np.ndarray): <TAB>  <TAB>  <TAB> self._from_array(args[0]) <MASK> self._from_image_data(args[0]) <TAB>  <TAB> elif isinstance(args[0], str): <TAB>  <TAB>  <TAB> self._from_file(filename=args[0]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError(f""Table unable to be made from ({type(args[0])})"")","elif isinstance ( args [ 0 ] , vtk . vtkImageData ) :",200
"def delete_old_post_save( <TAB> sender, instance, raw, created, update_fields, using, **kwargs): <TAB> """"""Post_save on all models with file fields, deletes old files"""""" <TAB> if raw or created: <TAB>  <TAB> return <TAB> for field_name, new_file in cache.fields_for_model_instance(instance): <MASK> old_file = cache.get_field_attr(instance, field_name) <TAB>  <TAB>  <TAB> if old_file != new_file: <TAB>  <TAB>  <TAB>  <TAB> delete_file(instance, field_name, old_file, using) <TAB> # reset cache <TAB> cache.make_cleanup_cache(instance)",if update_fields is None or field_name in update_fields :,171
"def do_refresh(self): <TAB> try: <MASK> service_status = agent_status() <TAB>  <TAB>  <TAB> self.properties.service_status_label.setText( <TAB>  <TAB>  <TAB>  <TAB> HUMAN_SERVICE_STATUS[service_status] <TAB>  <TAB>  <TAB> ) <TAB> finally: <TAB>  <TAB> QTimer.singleShot(REFRESH_PERIOD, self.do_refresh)",if self . isVisible ( ) :,92
"def json_dumps(data): <TAB> """"""Return data in nicely formatted json."""""" <TAB> try: <TAB>  <TAB> return json.dumps( <TAB>  <TAB>  <TAB> data, <TAB>  <TAB>  <TAB> indent=1, <TAB>  <TAB>  <TAB> sort_keys=True, <TAB>  <TAB>  <TAB> separators=("","", "": ""), <TAB>  <TAB>  <TAB> default=json_serialize_default, <TAB>  <TAB> ) <TAB> except UnicodeDecodeError: <MASK> data = json_preserialize_binary(data) <TAB>  <TAB>  <TAB> return json.dumps(data) <TAB>  <TAB> raise","if sys . version_info [ : 2 ] == ( 2 , 7 ) :",132
"def __init__(self, aList): <TAB> for element in aList: <TAB>  <TAB> if len(element) > 0: <TAB>  <TAB>  <TAB> if element.tag == element[0].tag: <TAB>  <TAB>  <TAB>  <TAB> self.append(ListParser(element)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.append(DictParser(element)) <TAB>  <TAB> elif element.text: <TAB>  <TAB>  <TAB> text = element.text.strip() <MASK> self.append(text)",if text :,116
"def __init__(self, token): <TAB> self._convert_to_ascii = False <TAB> self._find = None <TAB> if token.search is None: <TAB>  <TAB> return <TAB> flags = 0 <TAB> self._match_this_many = 1 <TAB> if token.options: <TAB>  <TAB> if ""g"" in token.options: <TAB>  <TAB>  <TAB> self._match_this_many = 0 <TAB>  <TAB> if ""i"" in token.options: <TAB>  <TAB>  <TAB> flags |= re.IGNORECASE <MASK> self._convert_to_ascii = True <TAB> self._find = re.compile(token.search, flags | re.DOTALL) <TAB> self._replace = _CleverReplace(token.replace)","if ""a"" in token . options :",170
"def get_next(self): <TAB> if self.current > self.maximum: <TAB>  <TAB> raise StopIteration <TAB> else: <MASK> payl = ""%0"" + str(self.width) + ""d"" <TAB>  <TAB>  <TAB> payl = payl % (self.current) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> payl = str(self.current) <TAB>  <TAB> self.current += 1 <TAB>  <TAB> return payl",if self . width :,104
"def any(self, provider_name): <TAB> result = authomatic.login(Webapp2Adapter(self), provider_name) <TAB> if result: <TAB>  <TAB> apis = [] <MASK> result.user.update() <TAB>  <TAB>  <TAB> if result.user.credentials: <TAB>  <TAB>  <TAB>  <TAB> apis = config.config.get(provider_name, {}).get(""_apis"", {}) <TAB>  <TAB> nice_provider_name = ( <TAB>  <TAB>  <TAB> config.config.get(provider_name, {}).get(""_name"") <TAB>  <TAB>  <TAB> or provider_name.capitalize() <TAB>  <TAB> ) <TAB>  <TAB> render( <TAB>  <TAB>  <TAB> self, <TAB>  <TAB>  <TAB> result, <TAB>  <TAB>  <TAB> result.popup_js(custom=dict(apis=apis, provider_name=nice_provider_name)), <TAB>  <TAB> )",if result . user :,186
"def _get_lun_id(self, volume, target_name): <TAB> """"""Get lun id of the voluem in a target."""""" <TAB> pool = volume_utils.extract_host(volume.host, level=""pool"") <TAB> volume_name = self._trans_name_down(volume.name) <TAB> lun_id = None <TAB> luns = self._get_lun_list(target_name) <TAB> for lun in luns: <TAB>  <TAB> mappinglvm = lun.get(""mappingLvm"") <TAB>  <TAB> lun_name = mappinglvm.replace(r""%s/"" % pool, """") <MASK> lun_id = lun.get(""id"") <TAB> return lun_id",if lun_name == volume_name :,183
"def save_settings(self, settings): <TAB> for setting in self.settings: <TAB>  <TAB> setting_obj = settings[setting] <TAB>  <TAB> new_value = self.cleaned_data.get(setting) <MASK> if new_value and new_value != self.initial.get(setting): <TAB>  <TAB>  <TAB>  <TAB> self.save_image(setting_obj, new_value) <TAB>  <TAB>  <TAB> elif self.cleaned_data.get(""%s_delete"" % setting): <TAB>  <TAB>  <TAB>  <TAB> self.delete_image(setting_obj) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.save_setting(setting_obj, new_value)","if setting_obj . python_type == ""image"" :",160
"def setup_with_driver(self): <TAB> if not self.__class__.shared_state_initialized: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.setup_shared_state() <TAB>  <TAB>  <TAB> self.logout_if_needed() <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> self.__class__.shared_state_in_error = True <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self.__class__.shared_state_initialized = True <TAB> else: <MASK> raise unittest.SkipTest( <TAB>  <TAB>  <TAB>  <TAB> ""Skipping test, failed to initialize state previously."" <TAB>  <TAB>  <TAB> )",if self . __class__ . shared_state_in_error :,150
"def _get_replication_type_param(k, v): <TAB> words = v.split() <TAB> if len(words) == 2 and words[0] == ""<in>"": <TAB>  <TAB> REPLICA_SYNC_TYPES = { <TAB>  <TAB>  <TAB> ""sync"": constants.REPLICA_SYNC_MODEL, <TAB>  <TAB>  <TAB> ""async"": constants.REPLICA_ASYNC_MODEL, <TAB>  <TAB> } <TAB>  <TAB> sync_type = words[1].lower() <MASK> return REPLICA_SYNC_TYPES[sync_type] <TAB> msg = _( <TAB>  <TAB> ""replication_type spec must be specified as "" <TAB>  <TAB> ""replication_type='<in> sync' or '<in> async'."" <TAB> ) <TAB> LOG.error(msg) <TAB> raise exception.InvalidInput(reason=msg)",if sync_type in REPLICA_SYNC_TYPES :,200
"def request(self, host, handler, request_body, verbose=False): <TAB> # retry request once if cached connection has gone cold <TAB> for i in (0, 1): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self.single_request(host, handler, request_body, verbose) <TAB>  <TAB> except socket.error as e: <TAB>  <TAB>  <TAB> if i or e.errno not in (errno.ECONNRESET, errno.ECONNABORTED, errno.EPIPE): <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> except http_client.BadStatusLine:  # close after we sent request <MASK> raise",if i :,147
"def make_sales_return_records(): <MASK> for data in frappe.get_all( <TAB>  <TAB>  <TAB> ""Delivery Note"", fields=[""name""], filters={""docstatus"": 1} <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> if random.random() < 0.1: <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> dn = make_sales_return(data.name) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> dn.insert() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> dn.submit() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> frappe.db.commit() <TAB>  <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> frappe.db.rollback()",if random . random ( ) < 0.1 :,154
"def getStatusString(self): <TAB> if not self._isAvailable: <TAB>  <TAB> return ""Doodle3D box not found"" <TAB> if self._printing: <MASK> ret = ""Sending GCode: %.1f%%"" % ( <TAB>  <TAB>  <TAB>  <TAB> float(self._blockIndex) * 100.0 / float(len(self._fileBlocks)) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> elif len(self._fileBlocks) > 0: <TAB>  <TAB>  <TAB> ret = ""Finished sending GCode to Doodle3D box."" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret = ""Different print still running..."" <TAB>  <TAB> # ret += ""\nErrorCount: %d"" % (self._errorCount) <TAB>  <TAB> return ret <TAB> return ""Printer found, waiting for print command.""",if self . _blockIndex < len ( self . _fileBlocks ) :,190
"def coro(*args, **kw): <TAB> res = func(*args, **kw) <TAB> if isinstance(res, futures.Future) or inspect.isgenerator(res): <TAB>  <TAB> res = yield from res <TAB> elif _AwaitableABC is not None: <TAB>  <TAB> # If 'func' returns an Awaitable (new in 3.5) we <TAB>  <TAB> # want to run it. <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> await_meth = res.__await__ <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <MASK> res = yield from await_meth() <TAB> return res","if isinstance ( res , _AwaitableABC ) :",148
def _skip_to_next_iteration_group(self): <TAB> while True: <TAB>  <TAB> if self._currkey is self._marker: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> elif self._tgtkey is self._marker: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <MASK> break <TAB>  <TAB> newvalue = next(self._iterator) <TAB>  <TAB> if self._keyfunc is None: <TAB>  <TAB>  <TAB> newkey = newvalue <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> newkey = self._keyfunc(newvalue) <TAB>  <TAB> self._currkey = newkey <TAB>  <TAB> self._currvalue = newvalue,if not self . _tgtkey == self . _currkey :,153
"def in_quadview(context): <TAB> for area in context.window.screen.areas: <MASK> continue <TAB>  <TAB> for space in area.spaces: <TAB>  <TAB>  <TAB> if space.type != ""VIEW_3D"": <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if len(space.region_quadviews) > 0: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False","if area . type != ""VIEW_3D"" :",100
"def find_from_pythonpath(name): <TAB> for dirpath in sys.path: <MASK> continue <TAB>  <TAB> path = os.path.join(dirpath, name) <TAB>  <TAB> if os.path.isfile(path): <TAB>  <TAB>  <TAB> return path <TAB> return None",if not os . path . isdir ( dirpath ) :,75
"def detailed_exceptions_wrapper(self, *args, **kwargs): <TAB> try: <TAB>  <TAB> return meth(self, *args, **kwargs) <TAB> except ScriptError as e: <TAB>  <TAB> info = e.args[0] <MASK> raise <TAB>  <TAB> info.setdefault(""type"", ScriptError.SPLASH_LUA_ERROR) <TAB>  <TAB> info.setdefault(""splash_method"", _name) <TAB>  <TAB> raise e","if not isinstance ( info , dict ) :",109
"def metadata(draft): <TAB> test_metadata = {} <TAB> json_schema = create_jsonschema_from_metaschema(draft.registration_schema.schema) <TAB> for key, value in json_schema[""properties""].items(): <TAB>  <TAB> response = ""Test response"" <TAB>  <TAB> items = value[""properties""][""value""].get(""items"") <TAB>  <TAB> enum = value[""properties""][""value""].get(""enum"") <TAB>  <TAB> if items:  # multiselect <TAB>  <TAB>  <TAB> response = [items[""enum""][0]] <TAB>  <TAB> elif enum:  # singleselect <TAB>  <TAB>  <TAB> response = enum[0] <MASK> response = {""question"": {""value"": ""Test Response""}} <TAB>  <TAB> test_metadata[key] = {""value"": response} <TAB> return test_metadata","elif value [ ""properties"" ] [ ""value"" ] . get ( ""properties"" ) :",185
"def separate_keys(self, keys, torrent_ids): <TAB> """"""Separates the input keys into torrent class keys and plugins keys"""""" <TAB> if self.torrents: <TAB>  <TAB> for torrent_id in torrent_ids: <MASK> status_keys = list(self.torrents[torrent_id].status_funcs) <TAB>  <TAB>  <TAB>  <TAB> leftover_keys = list(set(keys) - set(status_keys)) <TAB>  <TAB>  <TAB>  <TAB> torrent_keys = list(set(keys) - set(leftover_keys)) <TAB>  <TAB>  <TAB>  <TAB> return torrent_keys, leftover_keys <TAB> return [], []",if torrent_id in self . torrents :,164
"def upgrade(): <TAB> bind = op.get_bind() <TAB> op.add_column(""slices"", sa.Column(""datasource_id"", sa.Integer())) <TAB> session = db.Session(bind=bind) <TAB> for slc in session.query(Slice).all(): <TAB>  <TAB> if slc.druid_datasource_id: <TAB>  <TAB>  <TAB> slc.datasource_id = slc.druid_datasource_id <MASK> slc.datasource_id = slc.table_id <TAB>  <TAB> session.merge(slc) <TAB>  <TAB> session.commit() <TAB> session.close()",if slc . table_id :,139
"def __call__(self, controller, environ, context): <TAB> context.session = session = SessionObject(environ, **self.options) <TAB> environ[""beaker.session""] = session <TAB> environ[""beaker.get_session""] = self._get_session <TAB> if ""paste.testing_variables"" in environ: <TAB>  <TAB> environ[""paste.testing_variables""][""session""] = session <TAB> response = self.next_handler(controller, environ, context) <TAB> if session.accessed(): <TAB>  <TAB> session.persist() <TAB>  <TAB> session_headers = session.__dict__[""_headers""] <TAB>  <TAB> if session_headers[""set_cookie""]: <TAB>  <TAB>  <TAB> cookie = session_headers[""cookie_out""] <MASK> response.headers.extend(((""Set-cookie"", cookie),)) <TAB> return response",if cookie :,187
"def propagate(self, user, change_action=None, author=None): <TAB> """"""Propagate current translation to all others."""""" <TAB> result = False <TAB> for unit in self.same_source_units: <MASK> continue <TAB>  <TAB> if unit.target == self.target and unit.state == self.state: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> unit.target = self.target <TAB>  <TAB> unit.state = self.state <TAB>  <TAB> unit.save_backend( <TAB>  <TAB>  <TAB> user, <TAB>  <TAB>  <TAB> False, <TAB>  <TAB>  <TAB> change_action=change_action, <TAB>  <TAB>  <TAB> author=None, <TAB>  <TAB>  <TAB> run_checks=False, <TAB>  <TAB> ) <TAB>  <TAB> result = True <TAB> return result","if not user . has_perm ( ""unit.edit"" , unit ) :",179
"def load_model(self, model_dict): <TAB> model_param = None <TAB> model_meta = None <TAB> for _, value in model_dict[""model""].items(): <TAB>  <TAB> for model in value: <MASK> model_meta = value[model] <TAB>  <TAB>  <TAB> if model.endswith(""Param""): <TAB>  <TAB>  <TAB>  <TAB> model_param = value[model] <TAB> LOGGER.info(""load model"") <TAB> self.set_model_meta(model_meta) <TAB> self.set_model_param(model_param) <TAB> self.phi = np.array([model_param.phi_a])","if model . endswith ( ""Meta"" ) :",152
"def name(self): <TAB> """"""Get the enumeration name of this storage class."""""" <TAB> if self._name_map is None: <TAB>  <TAB> self._name_map = {} <TAB>  <TAB> for key, value in StorageClass.__dict__.items(): <MASK> self._name_map[value] = key <TAB> return self._name_map[self]","if isinstance ( value , StorageClass ) :",93
"def relro(self): <TAB> try: <TAB>  <TAB> gnu_relro = lief.ELF.SEGMENT_TYPES.GNU_RELRO <TAB>  <TAB> flags = lief.ELF.DYNAMIC_TAGS.FLAGS <TAB>  <TAB> bind_now = lief.ELF.DYNAMIC_FLAGS.BIND_NOW <TAB>  <TAB> if self.elf.get(gnu_relro): <MASK> return ""Full RELRO"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return ""Partial RELRO"" <TAB>  <TAB> return ""No RELRO"" <TAB> except lief.not_found: <TAB>  <TAB> return ""No RELRO""",if bind_now in self . elf . get ( flags ) :,167
"def test_counter_instantiation(self): <TAB> self.assertIs(type(typing_extensions.Counter()), collections.Counter) <TAB> self.assertIs(type(typing_extensions.Counter[T]()), collections.Counter) <TAB> self.assertIs(type(typing_extensions.Counter[int]()), collections.Counter) <TAB> class C(typing_extensions.Counter[T]): <TAB>  <TAB> ... <TAB> if TYPING_3_5_3: <TAB>  <TAB> self.assertIs(type(C[int]()), C) <MASK> self.assertEqual(C.__bases__, (typing_extensions.Counter,)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertEqual(C.__bases__, (collections.Counter, typing.Generic))",if not PEP_560 :,171
"def handle_exception(self, e, result): <TAB> for k in sorted(result.thrift_spec): <MASK> continue <TAB>  <TAB> _, exc_name, exc_cls, _ = result.thrift_spec[k] <TAB>  <TAB> if isinstance(e, exc_cls): <TAB>  <TAB>  <TAB> setattr(result, exc_name, e) <TAB>  <TAB>  <TAB> return True <TAB> return False","if result . thrift_spec [ k ] [ 1 ] == ""success"" :",112
"def find_from_pythonpath(name): <TAB> for dirpath in sys.path: <TAB>  <TAB> if not os.path.isdir(dirpath): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> path = os.path.join(dirpath, name) <MASK> return path <TAB> return None",if os . path . isfile ( path ) :,75
"def parse_location(srclocation): <TAB> loc = symbols.Location( <TAB>  <TAB> get_value(srclocation, ""file""), get_value(srclocation, ""project"") <TAB> ) <MASK> loc = symbols.InstalledLocation( <TAB>  <TAB>  <TAB> symbols.parse_package(get_value(srclocation, ""package"")), <TAB>  <TAB>  <TAB> parse_package_db(get_value(srclocation, ""db"")), <TAB>  <TAB> ) <TAB>  <TAB> if loc.is_null(): <TAB>  <TAB>  <TAB> loc = symbols.OtherLocation(get_value(srclocation, ""source"")) <TAB> return loc if not loc.is_null() else None",if loc . is_null ( ) :,151
"def execute(self): <TAB> logger.debug(f""host {self.host} try ports: {default_ports}"") <TAB> for single_port in default_ports: <MASK> logger.debug(f""Reachable port found: {single_port}"") <TAB>  <TAB>  <TAB> self.publish_event(OpenPortEvent(port=single_port))","if self . test_connection ( self . host , single_port ) :",98
"def get_dynamic_incoming_outgoing_rate(self, sle): <TAB> # Get updated incoming/outgoing rate from transaction <TAB> if sle.recalculate_rate: <TAB>  <TAB> rate = self.get_incoming_outgoing_rate_from_transaction(sle) <MASK> sle.incoming_rate = rate <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sle.outgoing_rate = rate",if flt ( sle . actual_qty ) >= 0 :,106
"def _naf(mult): <TAB> """"""Calculate non-adjacent form of number."""""" <TAB> ret = [] <TAB> while mult: <MASK> nd = mult % 4 <TAB>  <TAB>  <TAB> if nd >= 2: <TAB>  <TAB>  <TAB>  <TAB> nd = nd - 4 <TAB>  <TAB>  <TAB> ret += [nd] <TAB>  <TAB>  <TAB> mult -= nd <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret += [0] <TAB>  <TAB> mult //= 2 <TAB> return ret",if mult % 2 :,107
"def indent_xml(elem, level=0): <TAB> """"""Do our pretty printing and make Matt very happy."""""" <TAB> i = ""\n"" + level * ""  "" <TAB> if elem: <MASK> elem.text = i + ""  "" <TAB>  <TAB> if not elem.tail or not elem.tail.strip(): <TAB>  <TAB>  <TAB> elem.tail = i <TAB>  <TAB> for elem in elem: <TAB>  <TAB>  <TAB> indent_xml(elem, level + 1) <TAB>  <TAB> if not elem.tail or not elem.tail.strip(): <TAB>  <TAB>  <TAB> elem.tail = i <TAB> else: <TAB>  <TAB> if level and (not elem.tail or not elem.tail.strip()): <TAB>  <TAB>  <TAB> elem.tail = i",if not elem . text or not elem . text . strip ( ) :,177
def clockface(radius): <TAB> reset() <TAB> pensize(7) <TAB> for i in range(60): <TAB>  <TAB> jump(radius) <MASK> fd(25) <TAB>  <TAB>  <TAB> jump(-radius - 25) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> dot(3) <TAB>  <TAB>  <TAB> jump(-radius) <TAB>  <TAB> rt(6),if i % 5 == 0 :,90
"def OnTextEntered(self, evt): <TAB> text = self.GetValue() <TAB> if self.doSearch(text): <TAB>  <TAB> self.searches.append(text) <MASK> del self.searches[0] <TAB>  <TAB> self.SetMenu(self.MakeMenu()) <TAB> self.SetValue("""")",if len ( self . searches ) > self . maxSearches :,89
"def wrapped_send(bot, location, content=None, preprocessor=None, **kwargs): <TAB> try: <MASK> content = await preprocessor(bot, location, content) <TAB>  <TAB> await location.send(content, **kwargs) <TAB> except Exception as _exc: <TAB>  <TAB> main_log.error( <TAB>  <TAB>  <TAB> ""I could not send an owner notification to %s (%s)"", <TAB>  <TAB>  <TAB> location, <TAB>  <TAB>  <TAB> location.id, <TAB>  <TAB>  <TAB> exc_info=_exc, <TAB>  <TAB> )",if preprocessor is not None :,125
"def explode(self, obj): <TAB> """"""Determine if the object should be exploded."""""" <TAB> if obj in self._done: <TAB>  <TAB> return False <TAB> result = False <TAB> for item in self._explode: <MASK> # If it has a _moId it is an instance <TAB>  <TAB>  <TAB> if obj._moId == item._moId: <TAB>  <TAB>  <TAB>  <TAB> result = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # If it does not have a _moId it is a template <TAB>  <TAB>  <TAB> if obj.__class__.__name__ == item.__name__: <TAB>  <TAB>  <TAB>  <TAB> result = True <TAB> if result: <TAB>  <TAB> self._done.add(obj) <TAB> return result","if hasattr ( item , ""_moId"" ) :",166
"def _verify_treestore(itr, tree_values): <TAB> i = 0 <TAB> while itr: <TAB>  <TAB> values = tree_values[i] <TAB>  <TAB> if treestore[itr][0] != values[0]: <TAB>  <TAB>  <TAB> return False <MASK> if not _verify_treestore(treestore.iter_children(itr), values[1]): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> itr = treestore.iter_next(itr) <TAB>  <TAB> i += 1 <TAB> return True",if treestore . iter_children ( itr ) :,132
"def types(model_cls): <TAB> # Gives us `item_types` and `album_types` <TAB> attr_name = ""{0}_types"".format(model_cls.__name__.lower()) <TAB> types = {} <TAB> for plugin in find_plugins(): <TAB>  <TAB> plugin_types = getattr(plugin, attr_name, {}) <TAB>  <TAB> for field in plugin_types: <MASK> raise PluginConflictException( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> u""Plugin {0} defines flexible field {1} "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> u""which has already been defined with "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> u""another type."".format(plugin.name, field) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> types.update(plugin_types) <TAB> return types",if field in types and plugin_types [ field ] != types [ field ] :,189
"def set_origin(self, origin): <TAB> # This is useful to modify an exception to add origin information as <TAB> # it ""passes by"", without losing traceback information. (In Python 3 <TAB> # we can use the built-in exception wrapping stuff, but it will be <TAB> # some time before we can count on that...) <TAB> if self.origin is None: <MASK> origin = origin.origin <TAB>  <TAB> if not isinstance(origin, patsy.origin.Origin): <TAB>  <TAB>  <TAB> origin = None <TAB>  <TAB> self.origin = origin","if hasattr ( origin , ""origin"" ) :",132
"def items(self): <TAB> if self._items is not None: <TAB>  <TAB> return self._items <TAB> items = self.get_option(""recent-connections"") <TAB> if not items: <TAB>  <TAB> self._items = [] <TAB>  <TAB> return self._items <TAB> for i in reversed(items): <MASK> items.remove(i) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> i[""device""] = self.get_device_path(i) <TAB>  <TAB> except AdapterNotFound: <TAB>  <TAB>  <TAB> i[""device""] = None <TAB>  <TAB> except DeviceNotFound: <TAB>  <TAB>  <TAB> items.remove(i) <TAB>  <TAB> i[""time""] = float(i[""time""]) <TAB> self._items = items <TAB> return self._items","if ""name"" not in i or ""uuid"" not in i :",181
"def test_doc_attributes(self): <TAB> print_test_name(""TEST DOC ATTRIBUTES"") <TAB> correct = 0 <TAB> for example in DOC_EXAMPLES: <TAB>  <TAB> original_schema = schema.parse(example.schema_string) <TAB>  <TAB> if original_schema.doc is not None: <TAB>  <TAB>  <TAB> correct += 1 <TAB>  <TAB> if original_schema.type == ""record"": <TAB>  <TAB>  <TAB> for f in original_schema.fields: <MASK> self.fail( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Failed to preserve 'doc' in fields: "" + example.schema_string <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> self.assertEqual(correct, len(DOC_EXAMPLES))",if f . doc is None :,168
"def StopBackgroundWorkload(self): <TAB> """"""Stop the background workoad."""""" <TAB> for workload in background_workload.BACKGROUND_WORKLOADS: <MASK> if self.OS_TYPE in workload.EXCLUDED_OS_TYPES: <TAB>  <TAB>  <TAB>  <TAB> raise NotImplementedError() <TAB>  <TAB>  <TAB> workload.Stop(self)",if workload . IsEnabled ( self ) :,87
"def resolve_expression( <TAB> self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False): <TAB> resolved = super(SearchQuery, self).resolve_expression( <TAB>  <TAB> query, allow_joins, reuse, summarize, for_save <TAB> ) <TAB> if self.config: <MASK> resolved.config = Value(self.config).resolve_expression( <TAB>  <TAB>  <TAB>  <TAB> query, allow_joins, reuse, summarize, for_save <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> resolved.config = self.config.resolve_expression( <TAB>  <TAB>  <TAB>  <TAB> query, allow_joins, reuse, summarize, for_save <TAB>  <TAB>  <TAB> ) <TAB> return resolved","if not hasattr ( self . config , ""resolve_expression"" ) :",179
"def resolve_ip(filename, foffset, ip, need_line): <TAB> sym, soffset, line = None, 0, None <TAB> if filename and filename.startswith(""/""): <TAB>  <TAB> sym, soffset = resolve_sym(filename, foffset) <TAB>  <TAB> if not sym: <TAB>  <TAB>  <TAB> sym, soffset = resolve_sym(filename, ip) <MASK> line = resolve_line(filename, ip) <TAB> else: <TAB>  <TAB> sym, soffset = kernel.resolve_kernel(ip) <TAB> return sym, soffset, line",if need_line :,132
"def create_model(self, dataset, weight_name=Checkpoint._LATEST): <TAB> if not self.is_empty: <TAB>  <TAB> run_config = copy.deepcopy(self._checkpoint.run_config) <TAB>  <TAB> model = instantiate_model(run_config, dataset) <MASK> for k, v in self._checkpoint.model_props.items(): <TAB>  <TAB>  <TAB>  <TAB> setattr(model, k, v) <TAB>  <TAB>  <TAB> delattr(self._checkpoint, ""model_props"") <TAB>  <TAB> self._initialize_model(model, weight_name) <TAB>  <TAB> return model <TAB> else: <TAB>  <TAB> raise ValueError(""Checkpoint is empty"")","if hasattr ( self . _checkpoint , ""model_props"" ) :",160
"def get_py2exe_datafiles(): <TAB> datapath = get_data_path() <TAB> head, tail = os.path.split(datapath) <TAB> d = {} <TAB> for root, dirs, files in os.walk(datapath): <TAB>  <TAB> # Need to explicitly remove cocoa_agg files or py2exe complains <TAB>  <TAB> # NOTE I dont know why, but do as previous version <MASK> files.remove(""Matplotlib.nib"") <TAB>  <TAB> files = [os.path.join(root, filename) for filename in files] <TAB>  <TAB> root = root.replace(tail, ""mpl-data"") <TAB>  <TAB> root = root[root.index(""mpl-data"") :] <TAB>  <TAB> d[root] = files <TAB> return d.items()","if ""Matplotlib.nib"" in files :",187
"def mouseClickEvent(self, ev): <TAB> if ev.button() == QtCore.Qt.LeftButton and self.allowAdd: <TAB>  <TAB> pos = ev.pos() <TAB>  <TAB> if pos.x() < 0 or pos.x() > self.length: <TAB>  <TAB>  <TAB> return <MASK> return <TAB>  <TAB> pos.setX(min(max(pos.x(), 0), self.length)) <TAB>  <TAB> self.addTick(pos.x() / self.length) <TAB> elif ev.button() == QtCore.Qt.RightButton: <TAB>  <TAB> self.showMenu(ev)",if pos . y ( ) < 0 or pos . y ( ) > self . tickSize :,156
"def image_preprocess(self, image): <TAB> with tf.name_scope(""image_preprocess""): <MASK> image = tf.cast(image, tf.float32) <TAB>  <TAB> mean = [0.485, 0.456, 0.406]  # rgb <TAB>  <TAB> std = [0.229, 0.224, 0.225] <TAB>  <TAB> if self.image_bgr: <TAB>  <TAB>  <TAB> mean = mean[::-1] <TAB>  <TAB>  <TAB> std = std[::-1] <TAB>  <TAB> image_mean = tf.constant(mean, dtype=tf.float32) * 255.0 <TAB>  <TAB> image_std = tf.constant(std, dtype=tf.float32) * 255.0 <TAB>  <TAB> image = (image - image_mean) / image_std <TAB>  <TAB> return image",if image . dtype . base_dtype != tf . float32 :,195
"def _addConsoleMessage(self, type: str, args: List[JSHandle]) -> None: <TAB> if not self.listeners(Page.Events.Console): <TAB>  <TAB> for arg in args: <TAB>  <TAB>  <TAB> self._client._loop.create_task(arg.dispose()) <TAB>  <TAB> return <TAB> textTokens = [] <TAB> for arg in args: <TAB>  <TAB> remoteObject = arg._remoteObject <MASK> textTokens.append(arg.toString()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> textTokens.append(str(helper.valueFromRemoteObject(remoteObject))) <TAB> message = ConsoleMessage(type, "" "".join(textTokens), args) <TAB> self.emit(Page.Events.Console, message)","if remoteObject . get ( ""objectId"" ) :",176
"def _handle_guild_scalar(self, add_scalar, _tag, _value, step=None): <TAB> """"""Handler for guild.summary.SummaryWriter.add_scalar."""""" <TAB> vals = self._summary_values(step) <TAB> if vals: <TAB>  <TAB> self.log.debug(""summary values via add_scalar: %s"", vals) <TAB>  <TAB> for tag, val in vals.items(): <MASK> add_scalar(tag, val, step)",if val is not None :,118
"def _get_token_from_cookie(self): <TAB> for cookie in self.session.cookies: <TAB>  <TAB> if cookie.name == ""X-APPLE-WEBAUTH-VALIDATE"": <TAB>  <TAB>  <TAB> match = search(r""\bt=([^:]+)"", cookie.value) <MASK> raise Exception(""Can't extract token from %r"" % cookie.value) <TAB>  <TAB>  <TAB> return {""token"": match.group(1)} <TAB> raise Exception(""Token cookie not found"")",if match is None :,117
"def unpack_RK(rk_str): <TAB> flags = BYTES_ORD(rk_str[0]) <TAB> if flags & 2: <TAB>  <TAB> # There's a SIGNED 30-bit integer in there! <TAB>  <TAB> (i,) = unpack(""<i"", rk_str) <TAB>  <TAB> i >>= 2  # div by 4 to drop the 2 flag bits <MASK> return i / 100.0 <TAB>  <TAB> return float(i) <TAB> else: <TAB>  <TAB> # It's the most significant 30 bits of an IEEE 754 64-bit FP number <TAB>  <TAB> (d,) = unpack(""<d"", b""\0\0\0\0"" + BYTES_LITERAL(chr(flags & 252)) + rk_str[1:4]) <TAB>  <TAB> if flags & 1: <TAB>  <TAB>  <TAB> return d / 100.0 <TAB>  <TAB> return d",if flags & 1 :,200
"def _parse_photo(self): <TAB> cat = ""lib"" <TAB> for photosection in self.plex.library.sections(): <MASK> self._load_attrs(photosection, cat) <TAB>  <TAB>  <TAB> for photoalbum in photosection.all(): <TAB>  <TAB>  <TAB>  <TAB> self._load_attrs(photoalbum, cat) <TAB>  <TAB>  <TAB>  <TAB> for photo in photoalbum.photos(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._load_attrs(photo, cat)",if photosection . TYPE == library . PhotoSection . TYPE :,130
"def count(num): <TAB> cnt = 0 <TAB> for i in range(num): <TAB>  <TAB> try: <MASK> raise ValueError <TAB>  <TAB>  <TAB> if i % 3: <TAB>  <TAB>  <TAB>  <TAB> raise ArithmeticError(""1"") <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> cnt += 1 <TAB> return cnt",if i % 2 :,80
"def node_exists(self, jid=None, node=None, ifrom=None): <TAB> with self.lock: <MASK> jid = self.xmpp.boundjid.full <TAB>  <TAB> if node is None: <TAB>  <TAB>  <TAB> node = """" <TAB>  <TAB> if ifrom is None: <TAB>  <TAB>  <TAB> ifrom = """" <TAB>  <TAB> if isinstance(ifrom, JID): <TAB>  <TAB>  <TAB> ifrom = ifrom.full <TAB>  <TAB> if (jid, node, ifrom) not in self.nodes: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True",if jid is None :,136
"def __call__(self, environ, start_response): <TAB> script_name = environ.get(""HTTP_X_SCRIPT_NAME"") <TAB> if script_name is not None: <MASK> warnings.warn( <TAB>  <TAB>  <TAB>  <TAB> ""'X-Script-Name' header should not end in '/' (found: %r). "" <TAB>  <TAB>  <TAB>  <TAB> ""Please fix your proxy's configuration."" % script_name <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> script_name = script_name.rstrip(""/"") <TAB>  <TAB> environ[""SCRIPT_NAME""] = script_name <TAB> return super(ProxyFix, self).__call__(environ, start_response)","if script_name . endswith ( ""/"" ) :",151
"def backwardKillParagraph(self, event): <TAB> """"""Kill the previous paragraph."""""" <TAB> c = self.c <TAB> w = self.editWidget(event) <TAB> if not w: <TAB>  <TAB> return <TAB> self.beginCommand(w, undoType=""backward-kill-paragraph"") <TAB> try: <TAB>  <TAB> self.backwardParagraphHelper(event, extend=True) <TAB>  <TAB> i, j = w.getSelectionRange() <MASK> i = min(i + 1, j) <TAB>  <TAB> c.killBufferCommands.kill( <TAB>  <TAB>  <TAB> event, i, j, force=True, undoType=None  # Use i, j without change. <TAB>  <TAB> ) <TAB>  <TAB> w.setSelectionRange(i, i, insert=i) <TAB> finally: <TAB>  <TAB> self.endCommand(changed=True, setLabel=True)",if i > 0 :,199
"def bracket_replace(code): <TAB> new = """" <TAB> for e in bracket_split(code, [""()"", ""[]""], False): <TAB>  <TAB> if e[0] == ""["": <TAB>  <TAB>  <TAB> name = ""#PYJSREPL"" + str(len(REPL)) + ""{"" <TAB>  <TAB>  <TAB> new += name <TAB>  <TAB>  <TAB> REPL[name] = e <MASK> # can be a function call <TAB>  <TAB>  <TAB> name = ""@PYJSREPL"" + str(len(REPL)) + ""}"" <TAB>  <TAB>  <TAB> new += name <TAB>  <TAB>  <TAB> REPL[name] = e <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new += e <TAB> return new","elif e [ 0 ] == ""("" :",154
"def regenerate(self, request, **kwargs): <TAB> obj = self.get_object() <TAB> if ""all"" in request.data: <TAB>  <TAB> for user in User.objects.all(): <MASK> token = Token.objects.get(user=user) <TAB>  <TAB>  <TAB>  <TAB> token.delete() <TAB>  <TAB>  <TAB>  <TAB> Token.objects.create(user=user) <TAB>  <TAB> return Response("""") <TAB> if ""username"" in request.data: <TAB>  <TAB> obj = get_object_or_404(User, username=request.data[""username""]) <TAB>  <TAB> self.check_object_permissions(self.request, obj) <TAB> token = Token.objects.get(user=obj) <TAB> token.delete() <TAB> token = Token.objects.create(user=obj) <TAB> return Response({""token"": token.key})",if not user . is_anonymous ( ) :,200
"def signal_notebook_switch_page(self, notebook, current_page, index): <TAB> if not hasattr(self.parent, ""rpc""): <TAB>  <TAB> return <TAB> # previous_page = notebook.get_nth_page(self.last_page_id) <TAB> self.last_page_id = index <TAB> for tab in self.tabs.values(): <MASK> continue <TAB>  <TAB> if hasattr(tab, ""load_campaign_information""): <TAB>  <TAB>  <TAB> tab.load_campaign_information(force=False)",if current_page != tab . box :,137
"def get_word_parens_range(self, offset, opening=""("", closing="")""): <TAB> end = self._find_word_end(offset) <TAB> start_parens = self.code.index(opening, end) <TAB> index = start_parens <TAB> open_count = 0 <TAB> while index < len(self.code): <MASK> open_count += 1 <TAB>  <TAB> if self.code[index] == closing: <TAB>  <TAB>  <TAB> open_count -= 1 <TAB>  <TAB> if open_count == 0: <TAB>  <TAB>  <TAB> return (start_parens, index + 1) <TAB>  <TAB> index += 1 <TAB> return (start_parens, index)",if self . code [ index ] == opening :,160
"def append(self, child): <TAB> if child not in (None, self): <TAB>  <TAB> tag = child_tag(self._tag) <TAB>  <TAB> if tag: <TAB>  <TAB>  <TAB> if isinstance(child, Html): <TAB>  <TAB>  <TAB>  <TAB> if child.tag != tag: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> child = Html(tag, child) <MASK> child = Html(tag, child) <TAB>  <TAB> super().append(child)","elif not child . startswith ( ""<%s"" % tag ) :",113
"def cvPreprocess(): <TAB> import cv2 <TAB> imgarr_orig = [] <TAB> image_ext_list = ["".jpg"", "".png"", "".JPEG"", "".jpeg"", "".PNG"", "".JPG""] <TAB> for file in onlyfiles: <TAB>  <TAB> fimg = imgroot + file <MASK> print(fimg + "" is not an image file"") <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> img1 = cv2.imread(fimg) <TAB>  <TAB> if img1 is None: <TAB>  <TAB>  <TAB> print(""ERROR opening "", fimg) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> img1 = cv2.resize(img1, (896, 896)) <TAB>  <TAB> imgarr_orig.append(img1) <TAB> return imgarr_orig",if any ( [ x in image_ext_list for x in fimg ] ) :,187
"def replace_nodes_in_symbol_table( <TAB> symbols: SymbolTable, replacements: Dict[SymbolNode, SymbolNode]) -> None: <TAB> for name, node in symbols.items(): <MASK> if node.node in replacements: <TAB>  <TAB>  <TAB>  <TAB> new = replacements[node.node] <TAB>  <TAB>  <TAB>  <TAB> old = node.node <TAB>  <TAB>  <TAB>  <TAB> replace_object_state(new, old) <TAB>  <TAB>  <TAB>  <TAB> node.node = new <TAB>  <TAB>  <TAB> if isinstance(node.node, (Var, TypeAlias)): <TAB>  <TAB>  <TAB>  <TAB> # Handle them here just in case these aren't exposed through the AST. <TAB>  <TAB>  <TAB>  <TAB> node.node.accept(NodeReplaceVisitor(replacements))",if node . node :,161
"def __find_audio_offset(self, fileobj): <TAB> byte = 0x00 <TAB> while not (byte & 0x80): <TAB>  <TAB> byte = ord(fileobj.read(1)) <TAB>  <TAB> size = to_int_be(fileobj.read(3)) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> block_type = self.METADATA_BLOCKS[byte & 0x7F] <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB> block_type = None <MASK> # See comments in read_metadata_block; the size can't <TAB>  <TAB>  <TAB> # be trusted for Vorbis comment blocks and Picture block <TAB>  <TAB>  <TAB> block_type(fileobj) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> fileobj.read(size) <TAB> return fileobj.tell()",if block_type and block_type . _distrust_size :,190
"def startJail(self, name): <TAB> with self.__lock: <TAB>  <TAB> jail = self.__jails[name] <MASK> jail.start() <TAB>  <TAB> elif name in self.__reload_state: <TAB>  <TAB>  <TAB> logSys.info(""Jail %r reloaded"", name) <TAB>  <TAB>  <TAB> del self.__reload_state[name] <TAB>  <TAB> if jail.idle: <TAB>  <TAB>  <TAB> jail.idle = False",if not jail . isAlive ( ) :,111
def get_resolved_dependencies(self): <TAB> dependencies = [] <TAB> for dependency in self.envconfig.deps: <MASK> package = resolve_package(package_spec=dependency.name) <TAB>  <TAB>  <TAB> if package != dependency.name: <TAB>  <TAB>  <TAB>  <TAB> dependency = dependency.__class__(package) <TAB>  <TAB> dependencies.append(dependency) <TAB> return dependencies,if dependency . indexserver is None :,93
"def _compile(self): <TAB> if not self._compiled: <TAB>  <TAB> # special case match-all query <MASK> return <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self._tokens = boolExpression.parseString(self._query, parseAll=self.strict) <TAB>  <TAB> except ParseException: <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> self._compiled = True",if self . _is_match_all ( ) :,92
"def _compute_features(self, images): <TAB> output_blobs = self._forward(images) <TAB> features = [] <TAB> for blob in output_blobs: <TAB>  <TAB> blob = blob.reshape((blob.shape[0], blob.shape[1])) <MASK> blob = blob.max(0) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> blob = self.merge(blob) <TAB>  <TAB> features.append(blob) <TAB> return np.vstack(features)","if self . merge == ""max"" :",116
"def _list_shape_iter(shape): <TAB> last_shape = _void <TAB> for item in shape: <MASK> if last_shape is _void: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""invalid shape spec: Ellipsis cannot be the"" ""first element"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB>  <TAB> yield last_shape <TAB>  <TAB> last_shape = item <TAB>  <TAB> yield item",if item is Ellipsis :,109
"def tokenize_url(self, field): <TAB> field = field.strip() <TAB> tokens = field.split("":"") <TAB> offset = 0 <TAB> if tokens[0] == ""http"": <TAB>  <TAB> offset = 1 <TAB>  <TAB> dstport = 80 <MASK> inttokens = tokens[2].split(""/"") <TAB>  <TAB>  <TAB> dstport = int(inttokens[0]) <TAB> elif tokens[0] == ""https"": <TAB>  <TAB> dstport = 443 <TAB> else: <TAB>  <TAB> if tokens[-1] is not None: <TAB>  <TAB>  <TAB> dstport = int(tokens[-1]) <TAB> tld = tldextract.extract(tokens[offset]) <TAB> fqdn = ""."".join(part for part in tld if part) <TAB> return (fqdn, dstport)",if len ( tokens ) > 2 :,183
"def assert_summary_equals(self, records, tag, step, value): <TAB> for record in records[1:]: <MASK> continue <TAB>  <TAB> if record.step != step: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> self.assertEqual(value, tf.make_ndarray(record.summary.value[0].tensor)) <TAB>  <TAB> return <TAB> self.fail(""Could not find record for tag {} and step {}"".format(tag, step))",if record . summary . value [ 0 ] . tag != tag :,114
"def getAttrDefault(key, fallback=None): <TAB> try: <TAB>  <TAB> default = defaultValuesCache[key] <TAB> except KeyError: <TAB>  <TAB> attrInfo = getAttributeInfo(key) <MASK> default = defaultValuesCache[key] = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> default = defaultValuesCache[key] = attrInfo.defaultValue <TAB> if default is None: <TAB>  <TAB> default = fallback <TAB> return default",if attrInfo is None :,107
"def __getattr__(self, key): <TAB> if key in self._raw: <TAB>  <TAB> val = self._raw[key] <TAB>  <TAB> if key in (""date"",): <TAB>  <TAB>  <TAB> return pd.Timestamp(val) <TAB>  <TAB> elif key in (""open"", ""close""): <TAB>  <TAB>  <TAB> return pd.Timestamp(val).time() <MASK> return pd.Timestamp(val[:2] + "":"" + val[-2:]).time() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return val <TAB> return super().__getattr__(key)","elif key in ( ""session_open"" , ""session_close"" ) :",132
"def _combine_to_jointcaller(processed): <TAB> """"""Add joint calling information to variants, while collapsing independent regions."""""" <TAB> by_vrn_file = collections.OrderedDict() <TAB> for data in (x[0] for x in processed): <TAB>  <TAB> key = ( <TAB>  <TAB>  <TAB> tz.get_in((""config"", ""algorithm"", ""jointcaller""), data), <TAB>  <TAB>  <TAB> data[""vrn_file""], <TAB>  <TAB> ) <MASK> by_vrn_file[key] = [] <TAB>  <TAB> by_vrn_file[key].append(data) <TAB> out = [] <TAB> for grouped_data in by_vrn_file.values(): <TAB>  <TAB> cur = grouped_data[0] <TAB>  <TAB> out.append([cur]) <TAB> return out",if key not in by_vrn_file :,187
"def assign_type(self, wb_type): <TAB> if isinstance(wb_type, ListType): <TAB>  <TAB> assigned_type = self.params[""element_type""].assign_type( <TAB>  <TAB>  <TAB> wb_type.params[""element_type""] <TAB>  <TAB> ) <MASK> return ListType(assigned_type) <TAB> return InvalidType()","if not isinstance ( assigned_type , InvalidType ) :",93
"def set_billing_hours_and_amount(self): <TAB> if not self.project: <TAB>  <TAB> for timesheet in self.timesheets: <TAB>  <TAB>  <TAB> ts_doc = frappe.get_doc(""Timesheet"", timesheet.time_sheet) <TAB>  <TAB>  <TAB> if not timesheet.billing_hours and ts_doc.total_billable_hours: <TAB>  <TAB>  <TAB>  <TAB> timesheet.billing_hours = ts_doc.total_billable_hours <MASK> timesheet.billing_amount = ts_doc.total_billable_amount",if not timesheet . billing_amount and ts_doc . total_billable_amount :,153
"def add_changeset(repo_path, path_to_filename_in_archive): <TAB> try: <TAB>  <TAB> subprocess.check_output( <TAB>  <TAB>  <TAB> [""hg"", ""add"", path_to_filename_in_archive], <TAB>  <TAB>  <TAB> stderr=subprocess.STDOUT, <TAB>  <TAB>  <TAB> cwd=repo_path, <TAB>  <TAB> ) <TAB> except Exception as e: <TAB>  <TAB> error_message = ""Error adding '{}' to repository: {}"".format( <TAB>  <TAB>  <TAB> path_to_filename_in_archive, unicodify(e) <TAB>  <TAB> ) <MASK> error_message += ""\nOutput was:\n%s"" % unicodify(e.output) <TAB>  <TAB> raise Exception(error_message)","if isinstance ( e , subprocess . CalledProcessError ) :",170
"def full_path(self, *args, **query): <TAB> """"""Return a full path"""""" <TAB> path = None <TAB> if args: <MASK> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""full_url() takes exactly 1 argument "" ""(%s given)"" % len(args) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> path = args[0] <TAB> if not path: <TAB>  <TAB> path = self.path <TAB> elif not path.startswith(""/""): <TAB>  <TAB> path = remove_double_slash(""%s/%s"" % (self.path, path)) <TAB> return iri_to_uri(path, query)",if len ( args ) > 1 :,147
"def retry_http_basic_auth(self, host, req, realm): <TAB> user, pw = self.passwd.find_user_password(realm, host) <TAB> if pw is not None: <TAB>  <TAB> raw = ""%s:%s"" % (user, pw) <TAB>  <TAB> auth = ""Basic %s"" % base64.b64encode(raw).strip() <MASK> return None <TAB>  <TAB> req.add_unredirected_header(self.auth_header, auth) <TAB>  <TAB> return self.parent.open(req, timeout=req.timeout) <TAB> else: <TAB>  <TAB> return None","if req . get_header ( self . auth_header , None ) == auth :",159
"def __call__(self, data): <TAB> num_points = data.pos.shape[0] <TAB> new_data = Data() <TAB> for key in data.keys: <MASK> continue <TAB>  <TAB> item = data[key] <TAB>  <TAB> if torch.is_tensor(item) and num_points == item.shape[0]: <TAB>  <TAB>  <TAB> item = item[self._indices].clone() <TAB>  <TAB> elif torch.is_tensor(item): <TAB>  <TAB>  <TAB> item = item.clone() <TAB>  <TAB> setattr(new_data, key, item) <TAB> return new_data",if key == KDTREE_KEY :,144
def flat(tree): <TAB> stack = [tree] <TAB> result = [] <TAB> stack_pop = stack.pop <TAB> stack_extend = stack.extend <TAB> result_append = result.append <TAB> while stack: <TAB>  <TAB> x = stack_pop() <MASK> result_append(x) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> stack_extend(x) <TAB>  <TAB>  <TAB> except TypeError: <TAB>  <TAB>  <TAB>  <TAB> result_append(x) <TAB> return result[::-1],"if isinstance ( x , basestring ) :",126
"def do_remove(self): <TAB> if self.netconf.locked(""dhcp""): <MASK> pid = read_pid_file(""/var/run/dnsmasq.pan1.pid"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pid = self.pid <TAB>  <TAB> if not kill(pid, ""dnsmasq""): <TAB>  <TAB>  <TAB> logging.info(""Stale dhcp lockfile found"") <TAB>  <TAB> self.netconf.unlock(""dhcp"")",if not self . pid :,106
"def set_xticklabels(self, labels=None, step=None, **kwargs): <TAB> """"""Set x axis tick labels on the bottom row of the grid."""""" <TAB> for ax in self.axes[-1, :]: <MASK> labels = [l.get_text() for l in ax.get_xticklabels()] <TAB>  <TAB>  <TAB> if step is not None: <TAB>  <TAB>  <TAB>  <TAB> xticks = ax.get_xticks()[::step] <TAB>  <TAB>  <TAB>  <TAB> labels = labels[::step] <TAB>  <TAB>  <TAB>  <TAB> ax.set_xticks(xticks) <TAB>  <TAB> ax.set_xticklabels(labels, **kwargs) <TAB> return self",if labels is None :,145
"def _resolved_values(self): <TAB> values = [] <TAB> for k, v in self.values.items() if hasattr(self.values, ""items"") else self.values: <TAB>  <TAB> if self.mapper: <MASK> desc = _entity_descriptor(self.mapper, k) <TAB>  <TAB>  <TAB>  <TAB> values.extend(desc._bulk_update_tuples(v)) <TAB>  <TAB>  <TAB> elif isinstance(k, attributes.QueryableAttribute): <TAB>  <TAB>  <TAB>  <TAB> values.extend(k._bulk_update_tuples(v)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> values.append((k, v)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> values.append((k, v)) <TAB> return values","if isinstance ( k , util . string_types ) :",176
"def _print_handles(self, text, handle_list): <TAB> for handle in handle_list: <TAB>  <TAB> source, citation = self.get_source_or_citation(handle, False) <TAB>  <TAB> _LOG.debug(""\n\n\n"") <MASK> _LOG.debug(""---- %s -- source %s"" % (text, source.get_title())) <TAB>  <TAB> elif citation: <TAB>  <TAB>  <TAB> _LOG.debug(""---- %s -- citation %s"" % (text, citation.get_page())) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _LOG.debug(""---- %s -- handle %s"" % (text, handle))",if source :,161
"def test_items(self): <TAB> expectException = ( <TAB>  <TAB> len(self.sparse_data) < len(self.data) <TAB>  <TAB> and not self.instance.A._default_val is None <TAB> ) <TAB> try: <TAB>  <TAB> test = self.instance.A.items() <TAB>  <TAB> # self.assertEqual( type(test), list ) <MASK> self.validateDict(self.sparse_data.items(), test) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.validateDict(self.data.items(), test) <TAB>  <TAB> # self.assertFalse(expectException) <TAB> except ValueError: <TAB>  <TAB> if not expectException: <TAB>  <TAB>  <TAB> raise",if self . instance . A . _default_val is None :,168
"def __new__(cls, name, bases, d): <TAB> rv = type.__new__(cls, name, bases, d) <TAB> if ""methods"" not in d: <TAB>  <TAB> methods = set(rv.methods or []) <TAB>  <TAB> for key, value in d.iteritems(): <TAB>  <TAB>  <TAB> if key in http_method_funcs: <TAB>  <TAB>  <TAB>  <TAB> methods.add(key.upper()) <TAB>  <TAB> # if we have no method at all in there we don't want to <TAB>  <TAB> # add a method list.  (This is for instance the case for <TAB>  <TAB> # the baseclass or another subclass of a base method view <TAB>  <TAB> # that does not introduce new methods). <MASK> rv.methods = sorted(methods) <TAB> return rv",if methods :,172
"def getResultSummary(self): <TAB> if self.descriptionDone is not None or self.description is not None: <TAB>  <TAB> stepsumm = util.join_list(self.descriptionDone or self.description) <MASK> stepsumm += u"" "" + util.join_list(self.descriptionSuffix) <TAB> else: <TAB>  <TAB> stepsumm = u""finished"" <TAB> if self.results != SUCCESS: <TAB>  <TAB> stepsumm += u"" (%s)"" % Results[self.results] <TAB> return {u""step"": stepsumm}",if self . descriptionSuffix :,137
"def analyze_items(items, category_id, agg_data): <TAB> for item in items: <TAB>  <TAB> if not agg_data[""cat_asp""].get(category_id, None): <TAB>  <TAB>  <TAB> agg_data[""cat_asp""][category_id] = [] <TAB>  <TAB> agg_data[""cat_asp""][category_id].append( <TAB>  <TAB>  <TAB> float(item.sellingStatus.currentPrice.value) <TAB>  <TAB> ) <TAB>  <TAB> if getattr(item.listingInfo, ""watchCount"", None): <TAB>  <TAB>  <TAB> agg_data[""watch_count""] += int(item.listingInfo.watchCount) <MASK> agg_data[""postal_code""] = item.postalCode","if getattr ( item , ""postalCode"" , None ) :",169
"def _Determine_Do(self): <TAB> from os.path import join <TAB> self.applicable = 1 <TAB> siloedPythonInstallDir = black.configure.items[""siloedPythonInstallDir""].Get() <TAB> if sys.platform == ""darwin"": <TAB>  <TAB> siloedPyVer = black.configure.items[""siloedPyVer""].Get() <TAB>  <TAB> self.value = join( <TAB>  <TAB>  <TAB> siloedPythonInstallDir, ""Python.framework"", ""Versions"", siloedPyVer, ""bin"" <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> self.value = siloedPythonInstallDir <MASK> self.value = join(self.value, ""bin"") <TAB> self.determined = 1","if sys . platform != ""win32"" :",177
"def work(self): <TAB> idle_times = 0 <TAB> while True: <MASK> log.info(""Stop sync worker"") <TAB>  <TAB>  <TAB> break <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> job = self.commit_queue.get(timeout=self.timeout, block=True) <TAB>  <TAB>  <TAB> if job[""type""] == ""commit"": <TAB>  <TAB>  <TAB>  <TAB> self.commits.append(job) <TAB>  <TAB>  <TAB> log.debug(""Got a commit job"") <TAB>  <TAB>  <TAB> idle_times = 0 <TAB>  <TAB>  <TAB> idle.clear() <TAB>  <TAB> except Empty: <TAB>  <TAB>  <TAB> log.debug(""Nothing to do right now, going idle"") <TAB>  <TAB>  <TAB> if idle_times > self.min_idle_times: <TAB>  <TAB>  <TAB>  <TAB> idle.set() <TAB>  <TAB>  <TAB> idle_times += 1 <TAB>  <TAB>  <TAB> self.on_idle()",if shutting_down . is_set ( ) :,200
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_module(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 18: <TAB>  <TAB>  <TAB> self.set_version(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 24: <TAB>  <TAB>  <TAB> self.set_instances(d.getVarInt64()) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,150
"def expand_group(client: Any, group_key: str): <TAB> """"""Determines if an email is really a dl."""""" <TAB> # NOTE: Google Groups does not support other DLs as Group owners <TAB> # https://stackoverflow.com/questions/31552146/group-as-owner-or-manager-fails-with-400-error <TAB> try: <TAB>  <TAB> response = list_members(client, group_key, propagate_errors=True) <TAB>  <TAB> if response.get(""members""): <TAB>  <TAB>  <TAB> return [x[""email""] for x in response.get(""members"", [])] <TAB> except HttpError as e: <MASK> pass <TAB> return []",if e . resp . status == 404 :,162
"def validate_against_domain( <TAB> cls, ensemble: Optional[""PolicyEnsemble""], domain: Optional[Domain]) -> None: <TAB> if ensemble is None: <TAB>  <TAB> return <TAB> for p in ensemble.policies: <TAB>  <TAB> if not isinstance(p, TwoStageFallbackPolicy): <TAB>  <TAB>  <TAB> continue <MASK> raise InvalidDomain( <TAB>  <TAB>  <TAB>  <TAB> ""The intent '{0}' must be present in the "" <TAB>  <TAB>  <TAB>  <TAB> ""domain file to use TwoStageFallbackPolicy. "" <TAB>  <TAB>  <TAB>  <TAB> ""Either include the intent '{0}' in your domain "" <TAB>  <TAB>  <TAB>  <TAB> ""or exclude the TwoStageFallbackPolicy from your "" <TAB>  <TAB>  <TAB>  <TAB> ""policy configuration"".format(p.deny_suggestion_intent_name) <TAB>  <TAB>  <TAB> )",if domain is None or p . deny_suggestion_intent_name not in domain . intents :,195
"def _ndvi(nir_data, red_data): <TAB> out = np.zeros_like(nir_data) <TAB> rows, cols = nir_data.shape <TAB> for y in range(0, rows): <TAB>  <TAB> for x in range(0, cols): <TAB>  <TAB>  <TAB> nir = nir_data[y, x] <TAB>  <TAB>  <TAB> red = red_data[y, x] <MASK> # cover zero divison case <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> soma = nir + red <TAB>  <TAB>  <TAB> out[y, x] = (nir - red) / soma <TAB> return out",if nir == red :,154
"def sysroot(): <TAB> cmd = ""set sysroot remote:/"" <TAB> if is_android(): <MASK> gdb.execute(cmd) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(message.notice(""sysroot is already set, skipping %r"" % cmd))","if gdb . parameter ( ""sysroot"" ) == ""target:"" :",77
"def _run(self): <TAB> when_pressed = 0.0 <TAB> pressed = False <TAB> while not self._done.is_set(): <TAB>  <TAB> now = time.monotonic() <TAB>  <TAB> if now - when_pressed > self._debounce_time: <TAB>  <TAB>  <TAB> if GPIO.input(self._channel) == self._expected: <MASK> pressed = True <TAB>  <TAB>  <TAB>  <TAB>  <TAB> when_pressed = now <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._trigger(self._pressed_queue, self._pressed_callback) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> if pressed: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pressed = False <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._trigger(self._released_queue, self._released_callback) <TAB>  <TAB> self._done.wait(0.05)",if not pressed :,187
"def find_comment(line): <TAB> """"""Finds the index of a comment # and returns None if not found"""""" <TAB> instring, instring_char = False, """" <TAB> for i, char in enumerate(line): <TAB>  <TAB> if char in ('""', ""'""): <TAB>  <TAB>  <TAB> if instring: <TAB>  <TAB>  <TAB>  <TAB> if char == instring_char: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> instring = False <TAB>  <TAB>  <TAB>  <TAB>  <TAB> instring_char = """" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> instring = True <TAB>  <TAB>  <TAB>  <TAB> instring_char = char <MASK> if not instring: <TAB>  <TAB>  <TAB>  <TAB> return i <TAB> return None","elif char == ""#"" :",155
"def _deduplicate_data(self): <TAB> # Remove duplicate entries, without recreating self.data object <TAB> dup_lines = [] <TAB> hash_set = set() <TAB> for i, fields in enumerate(self.data): <TAB>  <TAB> fields_hash = hash(self.separator.join(fields)) <MASK> dup_lines.append(i) <TAB>  <TAB>  <TAB> log.debug( <TAB>  <TAB>  <TAB>  <TAB> 'Found duplicate entry in tool data table ""%s"", but duplicates are not allowed, removing additional entry for: ""%s""', <TAB>  <TAB>  <TAB>  <TAB> self.name, <TAB>  <TAB>  <TAB>  <TAB> fields, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> hash_set.add(fields_hash) <TAB> for i in reversed(dup_lines): <TAB>  <TAB> self.data.pop(i)",if fields_hash in hash_set :,194
"def sample_independent( <TAB> self, <TAB> study: Study, <TAB> trial: FrozenTrial, <TAB> param_name: str, <TAB> param_distribution: distributions.BaseDistribution,) -> Any: <TAB> self._raise_error_if_multi_objective(study) <TAB> if self._warn_independent_sampling: <TAB>  <TAB> complete_trials = self._get_trials(study) <MASK> self._log_independent_sampling(trial, param_name) <TAB> return self._independent_sampler.sample_independent( <TAB>  <TAB> study, trial, param_name, param_distribution <TAB> )",if len ( complete_trials ) >= self . _n_startup_trials :,158
"def publish(self): <TAB> """"""Publish new events to the subscribers."""""" <TAB> while True: <TAB>  <TAB> event = await self.event_source.get() <TAB>  <TAB> str_buffer = [] <MASK> return <TAB>  <TAB> if isinstance(event, str): <TAB>  <TAB>  <TAB> str_buffer.append(event) <TAB>  <TAB> elif event.type == EventTypes.BLOCK_VALID: <TAB>  <TAB>  <TAB> str_buffer = map(json.dumps, eventify_block(event.data)) <TAB>  <TAB> for str_item in str_buffer: <TAB>  <TAB>  <TAB> for _, websocket in self.subscribers.items(): <TAB>  <TAB>  <TAB>  <TAB> await websocket.send_str(str_item)",if event == POISON_PILL :,164
"def push(self): <TAB> advice = self.check() <TAB> if not self._context[""silent""]: <TAB>  <TAB> if not self.hasPendingSync(advice): <TAB>  <TAB>  <TAB> print(""No changes to push."") <TAB>  <TAB>  <TAB> return <TAB>  <TAB> choice = input(""Continue? y/N:"") <MASK> print(""Aborted on user command"") <TAB>  <TAB>  <TAB> return <TAB> print(""push local changes to remote..."") <TAB> self._publish.syncRemote(self._context[""srcroot""], advice)","if choice != ""y"" :",123
"def readline(self, limit=-1): <TAB> i = self._rbuf.find(""\n"") <TAB> while i < 0 and not (0 < limit <= len(self._rbuf)): <TAB>  <TAB> new = self._raw_read(self._rbufsize) <TAB>  <TAB> if not new: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> i = new.find(""\n"") <MASK> i += len(self._rbuf) <TAB>  <TAB> self._rbuf = self._rbuf + new <TAB> if i < 0: <TAB>  <TAB> i = len(self._rbuf) <TAB> else: <TAB>  <TAB> i += 1 <TAB> if 0 <= limit < len(self._rbuf): <TAB>  <TAB> i = limit <TAB> data, self._rbuf = self._rbuf[:i], self._rbuf[i:] <TAB> return data",if i >= 0 :,194
"def main(): <TAB> init_app(set_backends=True, routes=False) <TAB> dry_run = ""--dry"" in sys.argv <TAB> if not dry_run: <TAB>  <TAB> script_utils.add_file_logger(logger, __file__) <TAB> with transaction.atomic(): <TAB>  <TAB> normalize_source_tags() <TAB>  <TAB> add_claimed_tags() <TAB>  <TAB> add_osf_provider_tags() <TAB>  <TAB> add_prereg_campaign_tags() <MASK> raise RuntimeError(""Dry run, transaction rolled back"")",if dry_run :,136
"def iter_segments(self): <TAB> while not self.closed: <TAB>  <TAB> for chunk in filter(self.valid_chunk, self.chunks): <TAB>  <TAB>  <TAB> self.logger.debug(""Adding chunk {0} to queue"", chunk.num) <TAB>  <TAB>  <TAB> yield chunk <TAB>  <TAB>  <TAB> # End of stream <MASK> return <TAB>  <TAB>  <TAB> self.chunk_id = chunk.num + 1 <TAB>  <TAB> if self.wait(self.module_info_reload_time): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> self.process_module_info() <TAB>  <TAB>  <TAB> except StreamError as err: <TAB>  <TAB>  <TAB>  <TAB> self.logger.warning(""Failed to process module info: {0}"", err)",if self . closed :,169
"def SetItems(self, choices): <TAB> self.choices = choices <TAB> self.choice_names = self.get_choice_names() <TAB> self.list_dlg.SetItems(self.get_choice_labels()) <TAB> labels = self.get_choice_labels() <TAB> for i in range(len(self.choices)): <TAB>  <TAB> if self.choices[i][1] is None: <TAB>  <TAB>  <TAB> # Tag missing items <TAB>  <TAB>  <TAB> self.list_dlg.SetItemBackgroundColour(i, ""pink"") <MASK> # Tag duplicated items <TAB>  <TAB>  <TAB> self.list_dlg.SetItemForegroundColour(i, ""grey"") <TAB> # on Mac, changing the items clears the current selection <TAB> self.SetChecked(self.checked) <TAB> self.Refresh()","elif labels [ i ] . endswith ( ""Name!)"" ) :",192
"def combine_logs(audit_logs, statement_text_logs): <TAB> for audit_transaction in audit_logs: <TAB>  <TAB> for audit_query in audit_logs[audit_transaction]: <TAB>  <TAB>  <TAB> matching_statement_text_logs = statement_text_logs.get(hash(audit_query)) <TAB>  <TAB>  <TAB> if matching_statement_text_logs: <TAB>  <TAB>  <TAB>  <TAB> statement_text_log = matching_statement_text_logs.pop() <TAB>  <TAB>  <TAB>  <TAB> if statement_text_log: <MASK> audit_query.start_time = statement_text_log.start_time <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if statement_text_log.end_time: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> audit_query.end_time = statement_text_log.end_time",if statement_text_log . start_time :,197
"def handle_data(self, data): <TAB> if self.in_span or self.in_div: <TAB>  <TAB> if data == ""No such user (please note that login is case sensitive)"": <TAB>  <TAB>  <TAB> self.no_user = True <MASK> self.bad_pw = True <TAB>  <TAB> elif data == ""User with that email already exists"": <TAB>  <TAB>  <TAB> self.already_exists = True","elif data == ""Invalid password"" :",101
"def K(exp): <TAB> ""Helper function to specify keymap"" <TAB> import re <TAB> modifier_strs = [] <TAB> while True: <TAB>  <TAB> m = re.match(r""\A(C|Ctrl|M|Alt|Shift|Super|Win)-"", exp) <MASK> break <TAB>  <TAB> modifier = m.group(1) <TAB>  <TAB> modifier_strs.append(modifier) <TAB>  <TAB> exp = re.sub(r""\A{}-"".format(modifier), """", exp) <TAB> key_str = exp.upper() <TAB> key = getattr(Key, key_str) <TAB> return Combo(create_modifiers_from_strings(modifier_strs), key)",if m is None :,161
"def local_min(self, hmap): <TAB> rows = len(hmap) <TAB> cols = len(hmap[0]) <TAB> min_list = [] <TAB> for row in range(rows): <TAB>  <TAB> for col in range(cols): <TAB>  <TAB>  <TAB> for d_row, d_col in ((1, 0), (0, 1), (-1, 0), (0, -1)): <TAB>  <TAB>  <TAB>  <TAB> h_row = (row + d_row) % rows <TAB>  <TAB>  <TAB>  <TAB> h_col = (col + d_col) % cols <MASK> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> min_list.append((row, col)) <TAB> return min_list",if hmap [ h_row ] [ h_col ] < hmap [ row ] [ col ] :,186
"def _check_processing(self): <TAB> now = time.time() <TAB> self.mutex.acquire() <TAB> while ( <TAB>  <TAB> self.processing.qsize() <TAB>  <TAB> and self.processing.top <TAB>  <TAB> and self.processing.top.exetime < now <TAB> ): <TAB>  <TAB> task = self.processing.get_nowait() <MASK> continue <TAB>  <TAB> task.exetime = 0 <TAB>  <TAB> self.priority_queue.put(task) <TAB>  <TAB> logger.info(""processing: retry %s"", task.taskid) <TAB> self.mutex.release()",if task . taskid is None :,143
"def autoname(self): <TAB> naming_method = frappe.db.get_value(""HR Settings"", None, ""emp_created_by"") <TAB> if not naming_method: <TAB>  <TAB> throw(_(""Please setup Employee Naming System in Human Resource > HR Settings"")) <TAB> else: <TAB>  <TAB> if naming_method == ""Naming Series"": <TAB>  <TAB>  <TAB> set_name_by_naming_series(self) <MASK> self.name = self.employee_number <TAB>  <TAB> elif naming_method == ""Full Name"": <TAB>  <TAB>  <TAB> self.set_employee_name() <TAB>  <TAB>  <TAB> self.name = self.employee_name <TAB> self.employee = self.name","elif naming_method == ""Employee Number"" :",169
"def __fixdict(self, dict): <TAB> for key in dict.keys(): <TAB>  <TAB> if key[:6] == ""start_"": <TAB>  <TAB>  <TAB> tag = key[6:] <TAB>  <TAB>  <TAB> start, end = self.elements.get(tag, (None, None)) <TAB>  <TAB>  <TAB> if start is None: <TAB>  <TAB>  <TAB>  <TAB> self.elements[tag] = getattr(self, key), end <TAB>  <TAB> elif key[:4] == ""end_"": <TAB>  <TAB>  <TAB> tag = key[4:] <TAB>  <TAB>  <TAB> start, end = self.elements.get(tag, (None, None)) <MASK> self.elements[tag] = start, getattr(self, key)",if end is None :,162
"def parseAGL(filename):  # -> { 2126: 'Omega', ... } <TAB> m = {} <TAB> for line in readLines(filename): <TAB>  <TAB> # Omega;2126 <TAB>  <TAB> # dalethatafpatah;05D3 05B2   # higher-level combinations; ignored <TAB>  <TAB> line = line.strip() <MASK> name, uc = tuple([c.strip() for c in line.split("";"")]) <TAB>  <TAB>  <TAB> if uc.find("" "") == -1: <TAB>  <TAB>  <TAB>  <TAB> # it's a 1:1 mapping <TAB>  <TAB>  <TAB>  <TAB> m[int(uc, 16)] = name <TAB> return m","if len ( line ) > 0 and line [ 0 ] != ""#"" :",169
"def password(self, password): <TAB> self._password = password <TAB> if password: <MASK> self.eeprint( <TAB>  <TAB>  <TAB>  <TAB> ""Install sshpass to using password: https://duckduckgo.com/?q=install+sshpass\n"" <TAB>  <TAB>  <TAB>  <TAB> + ""Note! There are a lot of security reasons to stop using password auth."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> verbose = ""-v"" if ""-v"" in self.sshpass else [] <TAB>  <TAB> self.sshpass = [""sshpass"", ""-p"", password] + verbose <TAB> else: <TAB>  <TAB> self.sshpass = []","if not which ( ""sshpass"" ) :",147
"def test_region_redirects_multiple_requests(self): <TAB> try: <TAB>  <TAB> response = self.client.list_objects(Bucket=self.bucket_name) <TAB>  <TAB> self.assertEqual(response[""ResponseMetadata""][""HTTPStatusCode""], 200) <TAB>  <TAB> second_response = self.client.list_objects(Bucket=self.bucket_name) <TAB>  <TAB> self.assertEqual(second_response[""ResponseMetadata""][""HTTPStatusCode""], 200) <TAB> except ClientError as e: <TAB>  <TAB> error = e.response[""Error""].get(""Code"", None) <MASK> self.fail(""S3 client failed to redirect to the proper region."")","if error == ""PermanentRedirect"" :",148
"def get_action_type(action_space): <TAB> """"""Method to get the action type to choose prob. dist. to sample actions from NN logits output"""""" <TAB> if isinstance(action_space, spaces.Box): <TAB>  <TAB> shape = action_space.shape <TAB>  <TAB> assert len(shape) == 1 <MASK> return ""continuous"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""multi_continuous"" <TAB> elif isinstance(action_space, spaces.Discrete): <TAB>  <TAB> return ""discrete"" <TAB> elif isinstance(action_space, spaces.MultiDiscrete): <TAB>  <TAB> return ""multi_discrete"" <TAB> elif isinstance(action_space, spaces.MultiBinary): <TAB>  <TAB> return ""multi_binary"" <TAB> else: <TAB>  <TAB> raise NotImplementedError",if shape [ 0 ] == 1 :,177
def remove_stale_sockets(self): <TAB> with self.lock: <MASK> for sock_info in self.sockets.copy(): <TAB>  <TAB>  <TAB>  <TAB> age = _time() - sock_info.last_checkout <TAB>  <TAB>  <TAB>  <TAB> if age > self.opts.max_idle_time_ms: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.sockets.remove(sock_info) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> sock_info.close() <TAB> while len(self.sockets) + self.active_sockets < self.opts.min_pool_size: <TAB>  <TAB> sock_info = self.connect() <TAB>  <TAB> with self.lock: <TAB>  <TAB>  <TAB> self.sockets.add(sock_info),if self . opts . max_idle_time_ms is not None :,176
"def _setReadyState(self, state: str) -> None: <TAB> if state != self.__readyState: <TAB>  <TAB> self.__log_debug(""- %s -> %s"", self.__readyState, state) <TAB>  <TAB> self.__readyState = state <TAB>  <TAB> if state == ""open"": <TAB>  <TAB>  <TAB> self.emit(""open"") <MASK> self.emit(""close"") <TAB>  <TAB>  <TAB> # no more events will be emitted, so remove all event listeners <TAB>  <TAB>  <TAB> # to facilitate garbage collection. <TAB>  <TAB>  <TAB> self.remove_all_listeners()","elif state == ""closed"" :",131
"def currentLevel(self): <TAB> currentStr = """" <TAB> for stackType, stackValue in self.stackVals: <MASK> if isinstance(stackValue, str): <TAB>  <TAB>  <TAB>  <TAB> currentStr += ""['"" + stackValue + ""']"" <TAB>  <TAB>  <TAB> else:  # numeric key... <TAB>  <TAB>  <TAB>  <TAB> currentStr += ""["" + str(stackValue) + ""]"" <TAB>  <TAB> elif stackType == ""listLike"": <TAB>  <TAB>  <TAB> currentStr += ""["" + str(stackValue) + ""]"" <TAB>  <TAB> elif stackType == ""getattr"": <TAB>  <TAB>  <TAB> currentStr += "".__getattribute__('"" + stackValue + ""')"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception(f""Cannot get attribute of type {stackType}"") <TAB> return currentStr","if stackType == ""dict"" :",176
def filter_latest_pkgs(pkgs): <TAB> pkgname2latest = {} <TAB> for x in pkgs: <TAB>  <TAB> pkgname = core.normalize_pkgname(x.pkgname) <MASK> pkgname2latest[pkgname] = x <TAB>  <TAB> elif x.parsed_version > pkgname2latest[pkgname].parsed_version: <TAB>  <TAB>  <TAB> pkgname2latest[pkgname] = x <TAB> return pkgname2latest.values(),if pkgname not in pkgname2latest :,103
"def test_url_invalid_set(): <TAB> for line in URL_INVALID_TESTS.split(""\n""): <TAB>  <TAB> # strip line, skip over empty lines <TAB>  <TAB> line = line.strip() <TAB>  <TAB> if line == """": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # skip over comments <TAB>  <TAB> match = COMMENT.match(line) <MASK> continue <TAB>  <TAB> mbox = address.parse(line, strict=True) <TAB>  <TAB> assert_equal(mbox, None)",if match :,115
"def check_block(cls, block): <TAB> if ( <TAB>  <TAB> len(block) == 4 <TAB>  <TAB> and block[0][0] <TAB>  <TAB> and block[0][0][0] == ""@"" <TAB>  <TAB> and block[2][0] <TAB>  <TAB> and block[2][0][0] == ""+"" <TAB>  <TAB> and block[1][0] <TAB> ): <TAB>  <TAB> # Check the sequence line, make sure it contains only G/C/A/T/N <TAB>  <TAB> match = cls.bases_regexp.match(block[1][0]) <MASK> start, end = match.span() <TAB>  <TAB>  <TAB> if (end - start) == len(block[1][0]): <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if match :,174
"def load_from_file(self, filename): <TAB> self._filename = filename <TAB> if os.path.exists(filename): <MASK> raise IOError(""%s exists and is not a file"" % filename) <TAB>  <TAB> with open(filename, ""r"") as f: <TAB>  <TAB>  <TAB> self._properties = json.load(f) <TAB> else: <TAB>  <TAB> mkpath(os.path.dirname(filename)) <TAB>  <TAB> self.save_to_file()",if not os . path . isfile ( filename ) :,118
"def add_system_info_creds_to_config(creds): <TAB> for user in creds: <TAB>  <TAB> ConfigService.creds_add_username(creds[user][""username""]) <TAB>  <TAB> if ""password"" in creds[user] and creds[user][""password""]: <TAB>  <TAB>  <TAB> ConfigService.creds_add_password(creds[user][""password""]) <MASK> ConfigService.creds_add_lm_hash(creds[user][""lm_hash""]) <TAB>  <TAB> if ""ntlm_hash"" in creds[user] and creds[user][""ntlm_hash""]: <TAB>  <TAB>  <TAB> ConfigService.creds_add_ntlm_hash(creds[user][""ntlm_hash""])","if ""lm_hash"" in creds [ user ] and creds [ user ] [ ""lm_hash"" ] :",175
"def line_number(self): <TAB> if self._line_range: <TAB>  <TAB> line_range = self._line_range <MASK> return ""%03d-%03d"" % (line_range.start, line_range.stop - 1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""%03d"" % line_range.start",if line_range . stop - line_range . start > 1 :,95
"def smooth(self, y, x=None, weights=None): <TAB> if self.method == ""target_df"": <MASK> self.fit(y, x=x, weights=weights, pen=self.pen) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.fit_target_df(y, x=x, weights=weights, df=self.target_df) <TAB> elif self.method == ""optimize_gcv"": <TAB>  <TAB> self.fit_optimize_gcv(y, x=x, weights=weights)","if hasattr ( self , ""pen"" ) :",133
"def dict_from_cursor(data=None, keys=None): <TAB> filtered_dict = {} <TAB> # Convert Uids to str <TAB> data = bson_dumps(data) <TAB> python_dict = json.loads(data) <TAB> for key in keys: <TAB>  <TAB> value = python_dict.get(key) <TAB>  <TAB> if type(value) is dict: <TAB>  <TAB>  <TAB> # Try to get mongo_id <TAB>  <TAB>  <TAB> mongo_id = value.get(""$oid"") <MASK> value = mongo_id <TAB>  <TAB> if key == ""_id"": <TAB>  <TAB>  <TAB> key = ""id"" <TAB>  <TAB> filtered_dict[key] = value <TAB> return filtered_dict",if mongo_id :,170
"def pytest_plugin_registered(self, plugin): <TAB> nodeid = None <TAB> try: <TAB>  <TAB> p = py.path.local(plugin.__file__) <TAB> except AttributeError: <TAB>  <TAB> pass <TAB> else: <TAB>  <TAB> # construct the base nodeid which is later used to check <TAB>  <TAB> # what fixtures are visible for particular tests (as denoted <TAB>  <TAB> # by their test id) <TAB>  <TAB> if p.basename.startswith(""conftest.py""): <TAB>  <TAB>  <TAB> nodeid = p.dirpath().relto(self.config.rootdir) <MASK> nodeid = nodeid.replace(p.sep, ""/"") <TAB> self.parsefactories(plugin, nodeid)","if p . sep != ""/"" :",161
"def _escape_unsafe_values(self, *values): <TAB> # type: (str) -> Generator[str] <TAB> """"""Escape unsafe values (name, section name) for API version 2.10 and below"""""" <TAB> for value in values: <MASK> yield value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.task.log.info( <TAB>  <TAB>  <TAB>  <TAB> ""Converting unsafe hyper parameter name/section '{}' to '{}'"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value, ""_"" + value <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> yield ""_"" + value",if value not in UNSAFE_NAMES_2_10 :,143
"def _identifier_split(self, identifier): <TAB> """"""Return (name, start, end) string tuple from an identifier (PRIVATE)."""""" <TAB> if ""/"" in identifier: <TAB>  <TAB> name, start_end = identifier.rsplit(""/"", 1) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> start, end = start_end.split(""-"") <TAB>  <TAB>  <TAB>  <TAB> return name, int(start), int(end) <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> # Non-integers after final '/' - fall through <TAB>  <TAB>  <TAB>  <TAB> pass <TAB> return identifier, None, None","if start_end . count ( ""-"" ) == 1 :",138
"def _complete_initial_layout(self): <TAB> """"""Finish initial layout; called after toplevel win is positioned"""""" <TAB> # Init tool group sizes by setting vpaned positions <TAB> for paned in self._get_paneds(): <MASK> pos = paned._initial_divider_position <TAB>  <TAB>  <TAB> GLib.idle_add(paned.set_position, pos)",if paned . _initial_divider_position :,101
"def _init_mapping(self, result): <TAB> for wamp_uri, full_name in result.items(): <TAB>  <TAB> for prefix in self.PREFIXES: <MASK> continue <TAB>  <TAB>  <TAB> short_name = full_name[len(prefix) :] <TAB>  <TAB>  <TAB> self._mapping[short_name] = wamp_uri",if not full_name . startswith ( prefix ) :,92
"def get_bounce_message(reason, ses_data, details): <TAB> if reason != ""bounce"": <TAB>  <TAB> return <TAB> if ses_data: <TAB>  <TAB> bouncedRecipients = ses_data.get(""bounce"", {}).get(""bouncedRecipients"") <MASK> recipient = bouncedRecipients[0] <TAB>  <TAB>  <TAB> return recipient.get(""diagnosticCode"") or recipient.get(""status"") <TAB> elif details: <TAB>  <TAB> return details",if bouncedRecipients :,124
"def do_If(self, node, elif_flag=False): <TAB> self.div(""statement"") <TAB> self.keyword(""elif"" if elif_flag else ""if"") <TAB> self.visit(node.test) <TAB> self.colon() <TAB> self.div_body(node.body) <TAB> if node.orelse: <TAB>  <TAB> node1 = node.orelse[0] <MASK> self.do_If(node1, elif_flag=True) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.keyword(""else"") <TAB>  <TAB>  <TAB> self.colon() <TAB>  <TAB>  <TAB> self.div_body(node.orelse) <TAB> self.end_div(""statement"")","if isinstance ( node1 , ast . If ) and len ( node . orelse ) == 1 :",176
"def matches(self, filepath): <TAB> matched = False <TAB> parent_path = os.path.dirname(filepath) <TAB> parent_path_dirs = split_path(parent_path) <TAB> for pattern in self.patterns: <TAB>  <TAB> negative = pattern.exclusion <TAB>  <TAB> match = pattern.match(filepath) <TAB>  <TAB> if not match and parent_path != """": <TAB>  <TAB>  <TAB> if len(pattern.dirs) <= len(parent_path_dirs): <TAB>  <TAB>  <TAB>  <TAB> match = pattern.match( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> os.path.sep.join(parent_path_dirs[: len(pattern.dirs)]) <TAB>  <TAB>  <TAB>  <TAB> ) <MASK> matched = not negative <TAB> return matched",if match :,165
"def test_11_wait_for_first_reboot_with_bhyve(): <TAB> if update_version is None: <TAB>  <TAB> pytest.skip(""No update found"") <TAB> elif download_failed is True: <TAB>  <TAB> pytest.skip(f""Downloading {selected_trains} failed"") <TAB> elif reboot is False: <TAB>  <TAB> pytest.skip(""Reboot is False skip"") <TAB> else: <MASK> pytest.skip(""skip no vm_name"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> while vm_state(vm_name) != ""stopped"": <TAB>  <TAB>  <TAB>  <TAB> sleep(5) <TAB>  <TAB>  <TAB> assert vm_start(vm_name) is True <TAB> sleep(1)",if vm_name is None :,167
def _check_network_private(test_network): <TAB> test_net = ipaddress.IPNetwork(test_network) <TAB> test_start = test_net.network <TAB> test_end = test_net.broadcast <TAB> for network in settings.vpn.safe_priv_subnets: <TAB>  <TAB> network = ipaddress.IPNetwork(network) <TAB>  <TAB> net_start = network.network <TAB>  <TAB> net_end = network.broadcast <MASK> return True <TAB> return False,if test_start >= net_start and test_end <= net_end :,129
def remove_stale_sockets(self): <TAB> with self.lock: <TAB>  <TAB> if self.opts.max_idle_time_ms is not None: <TAB>  <TAB>  <TAB> for sock_info in self.sockets.copy(): <TAB>  <TAB>  <TAB>  <TAB> age = _time() - sock_info.last_checkout <MASK> self.sockets.remove(sock_info) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> sock_info.close() <TAB> while len(self.sockets) + self.active_sockets < self.opts.min_pool_size: <TAB>  <TAB> sock_info = self.connect() <TAB>  <TAB> with self.lock: <TAB>  <TAB>  <TAB> self.sockets.add(sock_info),if age > self . opts . max_idle_time_ms :,176
"def hint(self, button): <TAB> """"""As hilight, but marks GTK Button as well"""""" <TAB> active = None <TAB> for b in self.button_widgets.values(): <TAB>  <TAB> if b.widget.get_sensitive(): <TAB>  <TAB>  <TAB> b.widget.set_state(Gtk.StateType.NORMAL) <MASK> active = b.widget <TAB> if active is not None: <TAB>  <TAB> active.set_state(Gtk.StateType.ACTIVE) <TAB> self.hilight(button)",if b . name == button :,126
"def post_process(self, retcode): <TAB> if not self.ok_codes: <TAB>  <TAB> return retcode <TAB> for code in self.ok_codes: <TAB>  <TAB> self.log.debug(""Comparing %s with %s codes"", code, retcode) <MASK> self.log.info(""Exit code %s was changed to 0 by RCAssert plugin"", code) <TAB>  <TAB>  <TAB> return 0 <TAB> self.log.info( <TAB>  <TAB> ""Changing exit code to %s because RCAssert pass list was unsatisfied"", <TAB>  <TAB> self.fail_code, <TAB> ) <TAB> return self.fail_code",if code == int ( retcode ) :,149
"def get_form_kwargs(self): <TAB> result = super().get_form_kwargs() <TAB> if self.request.method != ""POST"": <TAB>  <TAB> if self.initial: <TAB>  <TAB>  <TAB> # When going from other form (for example ZIP import) <TAB>  <TAB>  <TAB> result.pop(""data"", None) <TAB>  <TAB>  <TAB> result.pop(""files"", None) <MASK> result[""data""] = self.request.GET <TAB> return result",if self . has_all_fields ( ) and not self . empty_form :,120
"def transform_first_chunk(self, headers, chunk, finishing): <TAB> if self._chunking: <TAB>  <TAB> # No need to chunk the output if a Content-Length is specified <MASK> self._chunking = False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> headers[""Transfer-Encoding""] = ""chunked"" <TAB>  <TAB>  <TAB> chunk = self.transform_chunk(chunk, finishing) <TAB> return headers, chunk","if ""Content-Length"" in headers or ""Transfer-Encoding"" in headers :",112
"def copy_stream(self, in_fd, out_fd, length=2 ** 64): <TAB> total = 0 <TAB> while 1: <TAB>  <TAB> available_to_read = min(length - total, self.BUFFERSIZE) <TAB>  <TAB> data = in_fd.read(available_to_read) <MASK> break <TAB>  <TAB> out_fd.write(data) <TAB>  <TAB> total += len(data) <TAB>  <TAB> self.session.report_progress(""Reading %s @ %#x"", in_fd.urn, total)",if not data :,128
"def _trim_steps(self, num_steps): <TAB> """"""Trims a given number of steps from the end of the sequence."""""" <TAB> steps_trimmed = 0 <TAB> for i in reversed(range(len(self._events))): <MASK> if steps_trimmed == num_steps: <TAB>  <TAB>  <TAB>  <TAB> del self._events[i + 1 :] <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> steps_trimmed += 1 <TAB>  <TAB> elif i == 0: <TAB>  <TAB>  <TAB> self._events = [ <TAB>  <TAB>  <TAB>  <TAB> PolyphonicEvent(event_type=PolyphonicEvent.START, pitch=None) <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB> break",if self . _events [ i ] . event_type == PolyphonicEvent . STEP_END :,171
"def get_img_file(dir_name: str) -> list: <TAB> """"""Get all image file paths in several directories which have the same parent directory."""""" <TAB> images = [] <TAB> for parent, _, filenames in os.walk(dir_name): <TAB>  <TAB> for filename in filenames: <MASK> continue <TAB>  <TAB>  <TAB> img_path = os.path.join(parent, filename) <TAB>  <TAB>  <TAB> images.append(img_path) <TAB> return images",if not is_image_file ( filename ) :,118
"def get_agg_title(clause): <TAB> attr = str(clause.attribute) <TAB> if clause.aggregation is None: <MASK> return attr[:15] + ""..."" + attr[-10:] <TAB>  <TAB> return f""{attr}"" <TAB> elif attr == ""Record"": <TAB>  <TAB> return f""Number of Records"" <TAB> else: <TAB>  <TAB> if len(attr) > 15: <TAB>  <TAB>  <TAB> return f""{clause._aggregation_name.capitalize()} of {attr[:15]}..."" <TAB>  <TAB> return f""{clause._aggregation_name.capitalize()} of {attr}""",if len ( attr ) > 25 :,137
"def _check_realign(data): <TAB> """"""Check for realignment, which is not supported in GATK4"""""" <TAB> if ""gatk4"" not in data[""algorithm""].get(""tools_off"", []) and not ""gatk4"" == data[ <TAB>  <TAB> ""algorithm"" <TAB> ].get(""tools_off""): <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""In sample %s, realign specified but it is not supported for GATK4. "" <TAB>  <TAB>  <TAB>  <TAB> ""Realignment is generally not necessary for most variant callers."" <TAB>  <TAB>  <TAB>  <TAB> % (dd.get_sample_name(data)) <TAB>  <TAB>  <TAB> )","if data [ ""algorithm"" ] . get ( ""realign"" ) :",160
"def __call__(self, target): <TAB> if ""weights"" not in target.temp: <TAB>  <TAB> return True <TAB> targets = target.temp[""weights""] <TAB> for cname in target.children: <TAB>  <TAB> if cname in targets: <TAB>  <TAB>  <TAB> c = target.children[cname] <TAB>  <TAB>  <TAB> deviation = abs((c.weight - targets[cname]) / targets[cname]) <MASK> return True <TAB> if ""cash"" in target.temp: <TAB>  <TAB> cash_deviation = abs( <TAB>  <TAB>  <TAB> (target.capital - targets.value) / targets.value - target.temp[""cash""] <TAB>  <TAB> ) <TAB>  <TAB> if cash_deviation > self.tolerance: <TAB>  <TAB>  <TAB> return True <TAB> return False",if deviation > self . tolerance :,178
"def status_string(self): <TAB> if not self.live: <MASK> return _(""expired"") <TAB>  <TAB> elif self.approved_schedule: <TAB>  <TAB>  <TAB> return _(""scheduled"") <TAB>  <TAB> elif self.workflow_in_progress: <TAB>  <TAB>  <TAB> return _(""in moderation"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return _(""draft"") <TAB> else: <TAB>  <TAB> if self.approved_schedule: <TAB>  <TAB>  <TAB> return _(""live + scheduled"") <TAB>  <TAB> elif self.workflow_in_progress: <TAB>  <TAB>  <TAB> return _(""live + in moderation"") <TAB>  <TAB> elif self.has_unpublished_changes: <TAB>  <TAB>  <TAB> return _(""live + draft"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return _(""live"")",if self . expired :,166
"def __getitem__(self, item): <TAB> if item == ""EntityId"": <MASK> if self.use_uuid: <TAB>  <TAB>  <TAB>  <TAB> super(PlayerDict, self).__setitem__( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""EntityId"", self.get_name_from_uuid() <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> super(PlayerDict, self).__setitem__(""EntityId"", self._name) <TAB> return super(PlayerDict, self).__getitem__(item)","if ""EntityId"" not in self :",122
"def _to_num_bytes(java_mem_str): <TAB> if isinstance(java_mem_str, string_types): <TAB>  <TAB> for i, magnitude in enumerate((""k"", ""m"", ""g"", ""t""), start=1): <MASK> return int(java_mem_str[:-1]) * 1024 ** i <TAB> return int(java_mem_str)",if java_mem_str . lower ( ) . endswith ( magnitude ) :,103
"def test_layout_instantiate_subplots(self): <TAB> layout = ( <TAB>  <TAB> Curve(range(10)) <TAB>  <TAB> + Curve(range(10)) <TAB>  <TAB> + Image(np.random.rand(10, 10)) <TAB>  <TAB> + Curve(range(10)) <TAB>  <TAB> + Curve(range(10)) <TAB> ) <TAB> plot = mpl_renderer.get_plot(layout) <TAB> positions = [(0, 0), (0, 1), (0, 2), (0, 3), (1, 0)] <TAB> self.assertEqual(sorted(plot.subplots.keys()), positions) <TAB> for i, pos in enumerate(positions): <TAB>  <TAB> adjoint = plot.subplots[pos] <MASK> self.assertEqual(adjoint.subplots[""main""].layout_num, i + 1)","if ""main"" in adjoint . subplots :",194
"def __str__(self): <TAB> width = int(os.environ.get(""COLUMNS"", ""80"")) <TAB> s = ( <TAB>  <TAB> self.getSynopsis() <TAB>  <TAB> + ""\n"" <TAB>  <TAB> + ""(use 'tahoe --help' to view global options)\n"" <TAB>  <TAB> + ""\n"" <TAB>  <TAB> + self.getUsage() <TAB> ) <TAB> if self.description: <TAB>  <TAB> s += ""\n"" + wrap_paragraphs(self.description, width) + ""\n"" <TAB> if self.description_unwrapped: <TAB>  <TAB> du = textwrap.dedent(self.description_unwrapped) <MASK> du = du[1:] <TAB>  <TAB> s += ""\n"" + du + ""\n"" <TAB> return s","if du . startswith ( ""\n"" ) :",181
"def open(self, path, mode=""rb"", cryptoType=-1, cryptoKey=-1, cryptoCounter=-1): <TAB> if path is not None: <MASK> self.close() <TAB>  <TAB> if isinstance(path, str): <TAB>  <TAB>  <TAB> self.f = open(path, mode) <TAB>  <TAB>  <TAB> self._path = path <TAB>  <TAB>  <TAB> self.f.seek(0, 2) <TAB>  <TAB>  <TAB> self.size = self.f.tell() <TAB>  <TAB>  <TAB> self.f.seek(0, 0) <TAB>  <TAB> elif isinstance(path, BaseFile): <TAB>  <TAB>  <TAB> self.f = path <TAB>  <TAB>  <TAB> self.size = path.size <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise IOError(""Invalid file parameter"") <TAB> self.setupCrypto(cryptoType, cryptoKey, cryptoCounter)",if self . isOpen ( ) :,189
"def open_spotify(): <TAB> if sys.platform == ""win32"": <MASK> path = os.getenv(""APPDATA"") + ""\Spotify\Spotify.exe"" <TAB>  <TAB>  <TAB> subprocess.Popen(path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pass <TAB> elif sys.platform == ""linux"": <TAB>  <TAB> if getwindowtitle() == """": <TAB>  <TAB>  <TAB> subprocess.Popen(""spotify"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pass <TAB> elif sys.platform == ""darwin"": <TAB>  <TAB> # I don't have a mac so I don't know if this actually works <TAB>  <TAB> # If it does, please let me know, if it doesn't please fix it :) <TAB>  <TAB> if getwindowtitle() == """": <TAB>  <TAB>  <TAB> subprocess.Popen(""open -a Spotify"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pass <TAB> else: <TAB>  <TAB> pass","if getwindowtitle ( ) == """" :",198
def get_search_columns_list(self) -> List[str]: <TAB> ret_lst = list() <TAB> for col_name in self.get_columns_list(): <MASK> tmp_prop = self.get_property_first_col(col_name).name <TAB>  <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB>  <TAB> (not self.is_pk(tmp_prop)) <TAB>  <TAB>  <TAB>  <TAB> and (not self.is_fk(tmp_prop)) <TAB>  <TAB>  <TAB>  <TAB> and (not self.is_image(col_name)) <TAB>  <TAB>  <TAB>  <TAB> and (not self.is_file(col_name)) <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> ret_lst.append(col_name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret_lst.append(col_name) <TAB> return ret_lst,if not self . is_relation ( col_name ) :,200
"def get_artist(self, name): <TAB> artist = self.artists.get(name) <TAB> if not artist: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> artist = q(m.Artist).filter_by(name=name).one() <TAB>  <TAB>  <TAB> except NoResultFound: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> if artist and self.ram_cache: <TAB>  <TAB>  <TAB>  <TAB> self.add_artist(artist) <TAB> return artist",if self . use_db :,111
"def _find_glob_metadata(cur_files, metadata): <TAB> md_key = None <TAB> for check_key in metadata.keys(): <TAB>  <TAB> matches = 0 <MASK> for fname in cur_files: <TAB>  <TAB>  <TAB>  <TAB> if fnmatch.fnmatch(fname, ""*/%s"" % check_key): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> matches += 1 <TAB>  <TAB> if matches == len(cur_files): <TAB>  <TAB>  <TAB> md_key = check_key <TAB>  <TAB>  <TAB> break <TAB> if md_key: <TAB>  <TAB> return metadata[md_key]","if ""*"" in check_key :",135
"def extract_copy( <TAB> data: bytearray, mem: bytearray, memstart: int, datastart: int, size: int): <TAB> for i in range(size): <MASK> mem[memstart + i] = data[datastart + i] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> mem[memstart + i] = 0",if datastart + i < len ( data ) :,89
"def rpc_get_image(self, sender, image_hash): <TAB> self.router.addContact(sender) <TAB> try: <MASK> self.log.warning(""Image hash is not 20 characters %s"" % image_hash) <TAB>  <TAB>  <TAB> raise Exception(""Invalid image hash"") <TAB>  <TAB> self.log.info(""serving image %s to %s"" % (image_hash.encode(""hex""), sender)) <TAB>  <TAB> with open(self.db.filemap.get_file(image_hash.encode(""hex"")), ""rb"") as filename: <TAB>  <TAB>  <TAB> image = filename.read() <TAB>  <TAB> return [image] <TAB> except Exception: <TAB>  <TAB> self.log.warning(""could not find image %s"" % image_hash[:20].encode(""hex"")) <TAB>  <TAB> return None",if len ( image_hash ) != 20 :,195
"def preprocess_mnist(raw, withlabel, ndim, scale, image_dtype, label_dtype, rgb_format): <TAB> images = raw[""x""] <TAB> if ndim == 2: <TAB>  <TAB> images = images.reshape(-1, 28, 28) <TAB> elif ndim == 3: <TAB>  <TAB> images = images.reshape(-1, 1, 28, 28) <MASK> images = np.broadcast_to(images, (len(images), 3) + images.shape[2:]) <TAB> elif ndim != 1: <TAB>  <TAB> raise ValueError(""invalid ndim for MNIST dataset"") <TAB> images = images.astype(image_dtype) <TAB> images *= scale / 255.0 <TAB> if withlabel: <TAB>  <TAB> labels = raw[""y""].astype(label_dtype) <TAB>  <TAB> return images, labels <TAB> return images",if rgb_format :,189
"def get_tokens_unprocessed(self, text): <TAB> for index, token, value in RegexLexer.get_tokens_unprocessed(self, text): <TAB>  <TAB> if token is Name: <TAB>  <TAB>  <TAB> if self.stdlibhighlighting and value in self.stdlib_types: <TAB>  <TAB>  <TAB>  <TAB> token = Keyword.Type <TAB>  <TAB>  <TAB> elif self.c99highlighting and value in self.c99_types: <TAB>  <TAB>  <TAB>  <TAB> token = Keyword.Type <MASK> token = Keyword.Type <TAB>  <TAB> yield index, token, value",elif self . platformhighlighting and value in self . linux_types :,141
"def _match(self, pattern, input_string, context=None): <TAB> for index in find_all(input_string, pattern, **self._kwargs): <TAB>  <TAB> match = Match( <TAB>  <TAB>  <TAB> index, <TAB>  <TAB>  <TAB> index + len(pattern), <TAB>  <TAB>  <TAB> pattern=self, <TAB>  <TAB>  <TAB> input_string=input_string, <TAB>  <TAB>  <TAB> **self._match_kwargs <TAB>  <TAB> ) <MASK> yield match",if match :,106
"def https_open(self, req): <TAB> try: <TAB>  <TAB> return self.do_open(do_connection, req) <TAB> except Exception as err_msg: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> error_msg = str(err_msg.args[0]).split(""] "")[1] + ""."" <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB> error_msg = str(err_msg.args[0]) + ""."" <TAB>  <TAB> if settings.INIT_TEST == True: <TAB>  <TAB>  <TAB> if settings.VERBOSITY_LEVEL < 2: <TAB>  <TAB>  <TAB>  <TAB> print(settings.FAIL_STATUS) <TAB>  <TAB> else: <MASK> print("""") <TAB>  <TAB> print(settings.print_critical_msg(error_msg)) <TAB>  <TAB> raise SystemExit()",if settings . VERBOSITY_LEVEL < 1 :,187
"def recursive_select(tag): <MASK> print( <TAB>  <TAB>  <TAB> ' <TAB> Calling select(""%s"") recursively on %s %s' <TAB>  <TAB>  <TAB> % (next_token, tag.name, tag.attrs) <TAB>  <TAB> ) <TAB>  <TAB> print(""-"" * 40) <TAB> for i in tag.select(next_token, recursive_candidate_generator): <TAB>  <TAB> if self._select_debug: <TAB>  <TAB>  <TAB> print(""(Recursive select picked up candidate %s %s)"" % (i.name, i.attrs)) <TAB>  <TAB> yield i <TAB> if self._select_debug: <TAB>  <TAB> print(""-"" * 40)",if self . _select_debug :,150
"def detect(self, agent, result): <TAB> # -> True/None <TAB> word = self.checkWords(agent) <TAB> if word: <TAB>  <TAB> result[self.info_type] = dict(name=self.name) <TAB>  <TAB> result[""bot""] = self.bot <TAB>  <TAB> version = self.getVersion(agent, word) <TAB>  <TAB> if version: <TAB>  <TAB>  <TAB> result[self.info_type][""version""] = version <MASK> result[""platform""] = {""name"": self.platform, ""version"": version} <TAB>  <TAB> return True",if self . platform :,134
"def is_display_marc(data): <TAB> if data.startswith( <TAB>  <TAB> ""(Length implementation at offset 22 should hold a digit. Assuming 0)"" <TAB> ): <TAB>  <TAB> return True <TAB> try: <TAB>  <TAB> lines = data.split(""\n"") <TAB>  <TAB> leader = lines[0] <TAB>  <TAB> assert re_leader.match(leader) <TAB>  <TAB> for line in lines[1:]: <MASK> assert re_control.match(line) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> assert re_data.match(line) <TAB>  <TAB> return True <TAB> except AssertionError: <TAB>  <TAB> return False","if line . startswith ( ""00"" ) :",152
"def nodejslib(self): <TAB> if not hasattr(self, ""_nodejslib""): <TAB>  <TAB> for lib in self.libs: <MASK> self._nodejslib = lib <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._nodejslib = None <TAB> return self._nodejslib","if lib . name == ""node.js stdlib"" :",88
"def get(self, key, default=None, type=None): <TAB> for d in self.dicts: <MASK> if type is not None: <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return type(d[key]) <TAB>  <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> return d[key] <TAB> return default",if key in d :,91
"def add_callers(target, source): <TAB> """"""Combine two caller lists in a single list."""""" <TAB> new_callers = {} <TAB> for func, caller in target.items(): <TAB>  <TAB> new_callers[func] = caller <TAB> for func, caller in source.items(): <TAB>  <TAB> if func in new_callers: <MASK> # format used by cProfile <TAB>  <TAB>  <TAB>  <TAB> new_callers[func] = tuple( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> [i[0] + i[1] for i in zip(caller, new_callers[func])] <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> # format used by profile <TAB>  <TAB>  <TAB>  <TAB> new_callers[func] += caller <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_callers[func] = caller <TAB> return new_callers","if isinstance ( caller , tuple ) :",195
"def work(src, vsi_dest): <TAB> gdal.Mkdir(vsi_dest, 0o777) <TAB> for item in src.iterdir(): <TAB>  <TAB> item_vsi_dest = os.path.join(vsi_dest, item.name) <MASK> work(item, item_vsi_dest) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> VsiFileSystem.copy_to(str(item), item_vsi_dest)",if item . is_dir ( ) :,115
"def __getitem__(self, key): <TAB> if isinstance(key, raw_types.Qid): <TAB>  <TAB> return self._operation_touching(key) <TAB> elif isinstance(key, Iterable): <TAB>  <TAB> qubits_to_keep = frozenset(key) <TAB>  <TAB> ops_to_keep = tuple( <TAB>  <TAB>  <TAB> op <TAB>  <TAB>  <TAB> for op in self.operations <MASK> ) <TAB>  <TAB> return Moment(ops_to_keep)",if not qubits_to_keep . isdisjoint ( frozenset ( op . qubits ) ),124
"def mlt_version_is_greater_correct(test_version): <TAB> runtime_ver = mlt_version.split(""."") <TAB> test_ver = test_version.split(""."") <TAB> if runtime_ver[0] > test_ver[0]: <TAB>  <TAB> return True <TAB> elif runtime_ver[0] == test_ver[0]: <MASK> return True <TAB>  <TAB> elif runtime_ver[1] == test_ver[1]: <TAB>  <TAB>  <TAB> if runtime_ver[2] > test_ver[2]: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if runtime_ver [ 1 ] > test_ver [ 1 ] :,148
"def populate(self, item): <TAB> path = self.getItemPath(item) <TAB> for name in sorted(os.listdir(path)): <MASK> continue <TAB>  <TAB> pathname = os.path.join(path, name) <TAB>  <TAB> if os.path.isdir(pathname): <TAB>  <TAB>  <TAB> item.addChild(name, True) <TAB>  <TAB> elif name.lower().endswith("".target"") and os.path.isfile(pathname): <TAB>  <TAB>  <TAB> item.addChild(name, False)","if name [ 0 ] == ""."" :",122
"def runTests(self): <TAB> """"""Run tests"""""" <TAB> # fire plugin hook <TAB> runner = self._makeRunner() <TAB> try: <TAB>  <TAB> self.result = runner.run(self.test) <TAB> except Exception as e: <TAB>  <TAB> log.exception(""Internal Error"") <TAB>  <TAB> sys.stderr.write(""Internal Error: runTests aborted: %s\n"" % (e)) <MASK> sys.exit(1) <TAB> if self.exit: <TAB>  <TAB> sys.exit(not self.result.wasSuccessful())",if self . exit :,129
"def __setitem__(self, key, value): <TAB> """"""Like :meth:`set` but also supports index/slice based setting."""""" <TAB> if isinstance(key, (slice, int)): <MASK> value = [value] <TAB>  <TAB> value = [ <TAB>  <TAB>  <TAB> (_unicodify_header_value(k), _unicodify_header_value(v)) for (k, v) in value <TAB>  <TAB> ] <TAB>  <TAB> for (_, v) in value: <TAB>  <TAB>  <TAB> self._validate_value(v) <TAB>  <TAB> if isinstance(key, int): <TAB>  <TAB>  <TAB> self._list[key] = value[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._list[key] = value <TAB> else: <TAB>  <TAB> self.set(key, value)","if isinstance ( key , int ) :",181
"def toggle_fullscreen_hide_tabbar(self): <TAB> if self.is_fullscreen(): <MASK> if self.guake and self.guake.notebook_manager: <TAB>  <TAB>  <TAB>  <TAB> self.guake.notebook_manager.set_notebooks_tabbar_visible(False) <TAB> else: <TAB>  <TAB> if self.guake and self.guake.notebook_manager: <TAB>  <TAB>  <TAB> v = self.settings.general.get_boolean(""window-tabbar"") <TAB>  <TAB>  <TAB> self.guake.notebook_manager.set_notebooks_tabbar_visible(v)","if self . settings . general . get_boolean ( ""fullscreen-hide-tabbar"" ) :",159
"def clear_doc(self, docname: str) -> None: <TAB> for sChild in self._children: <TAB>  <TAB> sChild.clear_doc(docname) <MASK> sChild.declaration = None <TAB>  <TAB>  <TAB> sChild.docname = None <TAB>  <TAB>  <TAB> sChild.line = None <TAB>  <TAB>  <TAB> if sChild.siblingAbove is not None: <TAB>  <TAB>  <TAB>  <TAB> sChild.siblingAbove.siblingBelow = sChild.siblingBelow <TAB>  <TAB>  <TAB> if sChild.siblingBelow is not None: <TAB>  <TAB>  <TAB>  <TAB> sChild.siblingBelow.siblingAbove = sChild.siblingAbove <TAB>  <TAB>  <TAB> sChild.siblingAbove = None <TAB>  <TAB>  <TAB> sChild.siblingBelow = None",if sChild . declaration and sChild . docname == docname :,189
"def visit_hierarchichttprequest(self, request): <TAB> files = [] <TAB> body_file = request.config.get(""body-file"") <TAB> if body_file: <TAB>  <TAB> files.append(body_file) <TAB> uploads = request.config.get(""upload-files"", []) <TAB> files.extend([x[""path""] for x in uploads if not has_variable_pattern(x[""path""])]) <TAB> if ""jsr223"" in request.config: <TAB>  <TAB> jsrs = request.config.get(""jsr223"") <MASK> jsrs = [jsrs] <TAB>  <TAB> for jsr in jsrs: <TAB>  <TAB>  <TAB> if ""script-file"" in jsr: <TAB>  <TAB>  <TAB>  <TAB> files.append(jsr.get(""script-file"")) <TAB> return files","if isinstance ( jsrs , dict ) :",192
"def find_commands(management_dir): <TAB> # Modified version of function from django/core/management/__init__.py. <TAB> command_dir = os.path.join(management_dir, ""commands"") <TAB> commands = [] <TAB> try: <TAB>  <TAB> for f in os.listdir(command_dir): <TAB>  <TAB>  <TAB> if f.startswith(""_""): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> elif f.endswith("".py"") and f[:-3] not in commands: <TAB>  <TAB>  <TAB>  <TAB> commands.append(f[:-3]) <MASK> commands.append(f[:-4]) <TAB> except OSError: <TAB>  <TAB> pass <TAB> return commands","elif f . endswith ( "".pyc"" ) and f [ : - 4 ] not in commands :",164
"def show_panel(panel_id): <TAB> # Iterate positions to find where panel is and bring it to front. <TAB> for position in _positions_names: <TAB>  <TAB> pos_panel_ids = _get_position_panels(position) <TAB>  <TAB> if len(pos_panel_ids) == 0: <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> panel_widget = _get_panels_widgets_dict(gui.editor_window)[panel_id] <TAB>  <TAB> notebook = _position_notebooks[position] <TAB>  <TAB> for i in range(0, notebook.get_n_pages()): <TAB>  <TAB>  <TAB> notebook_page = notebook.get_nth_page(i) <TAB>  <TAB>  <TAB> if notebook_page == panel_widget: <TAB>  <TAB>  <TAB>  <TAB> notebook.set_current_page(i)",if len ( pos_panel_ids ) == 1 :,197
"def is_cwl_record(d): <TAB> """"""Check if an input is a CWL record, from any level of nesting."""""" <TAB> if isinstance(d, dict): <MASK> return d <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> recs = list( <TAB>  <TAB>  <TAB>  <TAB> filter(lambda x: x is not None, [is_cwl_record(v) for v in d.values()]) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return recs[0] if recs else None <TAB> else: <TAB>  <TAB> return None","if d . get ( ""type"" ) == ""record"" :",131
"def _flags_data_(self, main_mod, model_paths, flags_dest): <TAB> try: <TAB>  <TAB> sys_path, mod_path = python_util.find_module(main_mod, model_paths) <TAB> except ImportError as e: <MASK> self.log.warning(""cannot import flags from %s: %s"", main_mod, e) <TAB>  <TAB> return {} <TAB> else: <TAB>  <TAB> package = self._main_spec_package(main_mod) <TAB>  <TAB> return self._flags_data_for_path(mod_path, package, sys_path, flags_dest)","if os . getenv ( ""NO_WARN_FLAGS_IMPORT"" ) != ""1"" :",159
"def __str__(self): <TAB> messages = [self.__class__.__name__, ""(""] <TAB> annotation = self.annotation <TAB> messages.append(self.annotation.surrounds_attribute or """") <TAB> if annotation.tag_attributes: <MASK> messages.append("";"") <TAB>  <TAB> for (f, ta, ea) in self.tag_data: <TAB>  <TAB>  <TAB> messages += [ea, ': attribute ""', ta, '""'] <TAB> start, end = annotation.start_index, annotation.end_index <TAB> messages.append("", template[%s:%s])"" % (start, end)) <TAB> return """".join(map(str, messages))",if annotation . surrounds_attribute :,153
"def _on_view_count_change(self, *args): <TAB> with self.output: <TAB>  <TAB> logger.debug(""views: %d"", self.image.view_count) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> logger.debug(""was dirty, and needs an update"") <TAB>  <TAB>  <TAB>  <TAB> self.update() <TAB>  <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB>  <TAB> self._dirty = False",if self . _dirty and self . image . view_count > 0 :,109
"def network_state(self, device): <TAB> cmd = [""tc"", ""qdisc"", ""show"", ""dev"", device] <TAB> try: <TAB>  <TAB> output = self.host_exec.run(cmd) <TAB>  <TAB> # sloppy but good enough for now <MASK> return NetworkState.SLOW <TAB>  <TAB> if "" loss "" in output: <TAB>  <TAB>  <TAB> return NetworkState.FLAKY <TAB>  <TAB> if "" duplicate "" in output: <TAB>  <TAB>  <TAB> return NetworkState.DUPLICATE <TAB>  <TAB> return NetworkState.NORMAL <TAB> except Exception: <TAB>  <TAB> return NetworkState.UNKNOWN","if "" delay "" in output :",138
"def _remove(self, item): <TAB> """"""Internal removal of an item"""""" <TAB> # Manage siblings when items are deleted <TAB> for sibling in self.lines[self.lines.index(item) + 1 :]: <MASK> env = sibling.env <TAB>  <TAB>  <TAB> sibling.env = item.env <TAB>  <TAB>  <TAB> sibling.env.update(env) <TAB>  <TAB>  <TAB> sibling.env.job = sibling <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif sibling == """": <TAB>  <TAB>  <TAB> self.lines.remove(sibling) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> self.crons.remove(item) <TAB> self.lines.remove(item) <TAB> return 1","if isinstance ( sibling , CronItem ) :",162
"def _get_transformations(self, current_text, indices_to_modify): <TAB> transformed_texts = [] <TAB> words = current_text.words <TAB> for idx in indices_to_modify: <TAB>  <TAB> word = words[idx] <TAB>  <TAB> swap_idxs = list(set(range(len(words))) - {idx}) <MASK> swap_idx = random.choice(swap_idxs) <TAB>  <TAB>  <TAB> swapped_text = current_text.replace_word_at_index( <TAB>  <TAB>  <TAB>  <TAB> idx, words[swap_idx] <TAB>  <TAB>  <TAB> ).replace_word_at_index(swap_idx, word) <TAB>  <TAB>  <TAB> transformed_texts.append(swapped_text) <TAB> return transformed_texts",if swap_idxs :,175
"def _unlock_restarted_vms(self, pool_name): <TAB> result = [] <TAB> for vm in await self.middleware.call(""vm.query"", [(""autostart"", ""="", True)]): <TAB>  <TAB> for device in vm[""devices""]: <TAB>  <TAB>  <TAB> if device[""dtype""] not in (""DISK"", ""RAW""): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> path = device[""attributes""].get(""path"") <MASK> continue <TAB>  <TAB>  <TAB> if path.startswith(f""/dev/zvol/{pool_name}/"") or path.startswith( <TAB>  <TAB>  <TAB>  <TAB> f""/mnt/{pool_name}/"" <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> result.append(vm) <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return result",if not path :,172
"def parse_literal_object(node): <TAB> value = 0 <TAB> unit = get_default_weight_unit() <TAB> for field in node.fields: <TAB>  <TAB> if field.name.value == ""value"": <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> value = decimal.Decimal(field.value.value) <TAB>  <TAB>  <TAB> except decimal.DecimalException: <TAB>  <TAB>  <TAB>  <TAB> raise GraphQLError(f""Unsupported value: {field.value.value}"") <MASK> unit = field.value.value <TAB> return Weight(**{unit: value})","if field . name . value == ""unit"" :",134
"def _extract_level(self): <TAB> """"""Extract level and component if available (lazy)."""""" <TAB> if self._level is None: <TAB>  <TAB> split_tokens = self.split_tokens <TAB>  <TAB> if not split_tokens: <TAB>  <TAB>  <TAB> self._level = False <TAB>  <TAB>  <TAB> self._component = False <TAB>  <TAB>  <TAB> return <TAB>  <TAB> x = ( <TAB>  <TAB>  <TAB> self.log_levels.index(split_tokens[1]) <MASK> else None <TAB>  <TAB> ) <TAB>  <TAB> if x is not None: <TAB>  <TAB>  <TAB> self._level = split_tokens[1] <TAB>  <TAB>  <TAB> self._component = split_tokens[2] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._level = False <TAB>  <TAB>  <TAB> self._component = False",if split_tokens [ 1 ] in self . log_levels,185
"def _average_import_time(n: int, module: Text) -> float: <TAB> total = 0 <TAB> for _ in range(n): <TAB>  <TAB> lines = subprocess.getoutput( <TAB>  <TAB>  <TAB> f'{sys.executable} -X importtime -c ""import {module}""' <TAB>  <TAB> ).splitlines() <TAB>  <TAB> parts = lines[-1].split(""|"") <MASK> raise Exception(f""Import time not found for {module}."") <TAB>  <TAB> total += int(parts[1].strip()) / 1000000 <TAB> return total / n",if parts [ - 1 ] . strip ( ) != module :,133
"def send_preamble(self): <TAB> """"""Transmit version/status/date/server, via self._write()"""""" <TAB> if self.origin_server: <TAB>  <TAB> if self.client_is_modern(): <TAB>  <TAB>  <TAB> self._write(""HTTP/%s %s\r\n"" % (self.http_version, self.status)) <TAB>  <TAB>  <TAB> if not self.headers.has_key(""Date""): <TAB>  <TAB>  <TAB>  <TAB> self._write(""Date: %s\r\n"" % time.asctime(time.gmtime(time.time()))) <MASK> self._write(""Server: %s\r\n"" % self.server_software) <TAB> else: <TAB>  <TAB> self._write(""Status: %s\r\n"" % self.status)","if self . server_software and not self . headers . has_key ( ""Server"" ) :",199
"def test_source_address(self): <TAB> for addr, is_ipv6 in VALID_SOURCE_ADDRESSES: <MASK> warnings.warn(""No IPv6 support: skipping."", NoIPv6Warning) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> with HTTPConnectionPool( <TAB>  <TAB>  <TAB> self.host, self.port, source_address=addr, retries=False <TAB>  <TAB> ) as pool: <TAB>  <TAB>  <TAB> r = pool.request(""GET"", ""/source_address"") <TAB>  <TAB>  <TAB> assert r.data == b(addr[0])",if is_ipv6 and not HAS_IPV6_AND_DNS :,140
"def _run_commands(self, tool, commands, dry_run=False): <TAB> if dry_run: <TAB>  <TAB> self._dry_run_commands(tool, commands) <TAB>  <TAB> return <TAB> for command in commands: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> with original_ld_library_path(): <TAB>  <TAB>  <TAB>  <TAB> self.subprocess_utils.run(command, capture_output=True, check=True) <TAB>  <TAB> except OSError as ex: <MASK> raise ValueError(self._TOOL_NOT_FOUND_MESSAGE % tool) <TAB>  <TAB>  <TAB> raise ex <TAB> self._write_success_message(tool)",if ex . errno == errno . ENOENT :,154
"def test_float_overflow(self): <TAB> import sys <TAB> big_int = int(sys.float_info.max) * 2 <TAB> for t in float_types + [c_longdouble]: <TAB>  <TAB> self.assertRaises(OverflowError, t, big_int) <MASK> self.assertRaises(OverflowError, t.__ctype_be__, big_int) <TAB>  <TAB> if hasattr(t, ""__ctype_le__""): <TAB>  <TAB>  <TAB> self.assertRaises(OverflowError, t.__ctype_le__, big_int)","if hasattr ( t , ""__ctype_be__"" ) :",131
"def init_weights(self): <TAB> for n, p in self.named_parameters(): <MASK> torch.nn.init.zeros_(p) <TAB>  <TAB> elif ""fc"" in n: <TAB>  <TAB>  <TAB> torch.nn.init.xavier_uniform_(p)","if ""bias"" in n :",71
"def _compute_dependencies(self): <TAB> """"""Gather the lists of dependencies and adds to all_parts."""""" <TAB> for part in self.all_parts: <TAB>  <TAB> dep_names = self.after_requests.get(part.name, []) <TAB>  <TAB> for dep_name in dep_names: <TAB>  <TAB>  <TAB> dep = self.get_part(dep_name) <MASK> raise errors.SnapcraftAfterPartMissingError(part.name, dep_name) <TAB>  <TAB>  <TAB> part.deps.append(dep)",if not dep :,127
"def _delete_object(step): <TAB> try: <TAB>  <TAB> api = kubernetes.client.CustomObjectsApi() <TAB>  <TAB> api.delete_namespaced_custom_object( <TAB>  <TAB>  <TAB> group=""zalando.org"", <TAB>  <TAB>  <TAB> version=""v1"", <TAB>  <TAB>  <TAB> plural=""kopfexamples"", <TAB>  <TAB>  <TAB> namespace=""default"", <TAB>  <TAB>  <TAB> name=f""kopf-example-{step}"", <TAB>  <TAB>  <TAB> body={}, <TAB>  <TAB> ) <TAB> except kubernetes.client.rest.ApiException as e: <MASK> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise",if e . status in [ 404 ] :,142
"def _lookup(self, key, dicts=None, filters=()): <TAB> if dicts is None: <TAB>  <TAB> dicts = self.dicts <TAB> key_len = len(key) <TAB> if key_len > self.longest_key: <TAB>  <TAB> return None <TAB> for d in dicts: <TAB>  <TAB> if not d.enabled: <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> value = d.get(key) <TAB>  <TAB> if value: <TAB>  <TAB>  <TAB> for f in filters: <TAB>  <TAB>  <TAB>  <TAB> if f(key, value): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB>  <TAB> return value",if key_len > d . longest_key :,150
"def fork_with_monitor(receiver: Receiver, func, *args, **kwargs): <TAB> current_actor = self() <TAB> send(ForkWithMonitor(current_actor, func, args, kwargs), receiver) <TAB> while True: <TAB>  <TAB> message = recv(current_actor) <MASK> return message.new_actor <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> send(message, current_actor) <TAB> return","if isinstance ( message , ForkResponse ) :",106
"def read(self, size=-1): <TAB> if self._offset or (size > -1): <TAB>  <TAB> # return empty string to indicate EOF if we are offset past the end of the file <TAB>  <TAB> # else boto will throw an error at us <TAB>  <TAB> if self._offset >= self._key.size: <TAB>  <TAB>  <TAB> return """" <MASK> sizeStr = str(self._offset + size - 1)  # range header is inclusive <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sizeStr = """" <TAB>  <TAB> hdrs = {""Range"": ""bytes=%d-%s"" % (self._offset, sizeStr)} <TAB> else: <TAB>  <TAB> hdrs = {} <TAB> buf = self._key.get_contents_as_string(headers=hdrs) <TAB> self._offset += len(buf) <TAB> return buf",if size > - 1 :,191
"def operations(self): <TAB> # Search for operations <TAB> registered_operations = {} <TAB> for fn in hooks.get_hooks(""register_image_operations""): <TAB>  <TAB> registered_operations.update(dict(fn())) <TAB> # Build list of operation objects <TAB> operations = [] <TAB> for op_spec in self.spec.split(""|""): <TAB>  <TAB> op_spec_parts = op_spec.split(""-"") <MASK> raise InvalidFilterSpecError( <TAB>  <TAB>  <TAB>  <TAB> ""Unrecognised operation: %s"" % op_spec_parts[0] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> op_class = registered_operations[op_spec_parts[0]] <TAB>  <TAB> operations.append(op_class(*op_spec_parts)) <TAB> return operations",if op_spec_parts [ 0 ] not in registered_operations :,181
"def find_widget(self, pos): <TAB> for widget in self.subwidgets[::-1]: <MASK> r = widget.rect <TAB>  <TAB>  <TAB> if r.collidepoint(pos): <TAB>  <TAB>  <TAB>  <TAB> return widget.find_widget(subtract(pos, r.topleft)) <TAB> return self",if widget . visible :,77
"def _get_body(self): <TAB> if self._bodytree is None: <TAB>  <TAB> bodytxt = self._message.accumulate_body() <MASK> att = settings.get_theming_attribute(""thread"", ""body"") <TAB>  <TAB>  <TAB> att_focus = settings.get_theming_attribute(""thread"", ""body_focus"") <TAB>  <TAB>  <TAB> self._bodytree = TextlinesList(bodytxt, att, att_focus) <TAB> return self._bodytree",if bodytxt :,114
"def config_mode(self, config_command=""conf t"", pattern=""""): <TAB> output = """" <MASK> output = self.send_command_timing( <TAB>  <TAB>  <TAB> config_command, strip_command=False, strip_prompt=False <TAB>  <TAB> ) <TAB>  <TAB> if ""to enter configuration mode anyway"" in output: <TAB>  <TAB>  <TAB> output += self.send_command_timing( <TAB>  <TAB>  <TAB>  <TAB> ""YES"", strip_command=False, strip_prompt=False <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if not self.check_config_mode(): <TAB>  <TAB>  <TAB> raise ValueError(""Failed to enter configuration mode"") <TAB> return output",if not self . check_config_mode ( ) :,152
"def is_enabled(self): <TAB> try: <TAB>  <TAB> cmd = subprocess.Popen( <TAB>  <TAB>  <TAB> ""netsh advfirewall show currentprofile"", stdout=subprocess.PIPE <TAB>  <TAB> ) <TAB>  <TAB> out = cmd.stdout.readlines() <TAB>  <TAB> for l in out: <MASK> state = l.split()[-1].strip() <TAB>  <TAB> return state == ""ON"" <TAB> except: <TAB>  <TAB> return None","if l . startswith ( ""State"" ) :",107
"def __rpc_devices(self, *args): <TAB> data_to_send = {} <TAB> for device in self.__connected_devices: <MASK> data_to_send[device] = self.__connected_devices[device][ <TAB>  <TAB>  <TAB>  <TAB> ""connector"" <TAB>  <TAB>  <TAB> ].get_name() <TAB> return {""code"": 200, ""resp"": data_to_send}","if self . __connected_devices [ device ] [ ""connector"" ] is not None :",106
"def _mock_manager_nfx(self, *args, **kwargs): <TAB> if args: <MASK> raise RpcError() <TAB>  <TAB> elif args[0].tag == ""get-software-information"" and args[0].find(""./*"") is None: <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self._read_file(""sw_info_nfx_"" + args[0].tag + "".xml"")","if args [ 0 ] . tag == ""command"" :",112
"def empty_logs(self, logs=None): <TAB> if self.quick_log: <TAB>  <TAB> self.quick_log = [] <TAB> else: <TAB>  <TAB> if is_main_thread(): <TAB>  <TAB>  <TAB> self.logs = [] <TAB>  <TAB> else: <MASK> del self.thread_logs[current_thread_id()]",if logs and self . thread_logs . get ( current_thread_id ( ) ) :,98
"def read_cb(dir_path): <TAB> df_dict = dict() <TAB> for fold in [""train"", ""val"", ""test""]: <TAB>  <TAB> columns = [""premise"", ""hypothesis""] <MASK> columns.append(""label"") <TAB>  <TAB> jsonl_path = os.path.join(dir_path, ""{}.jsonl"".format(fold)) <TAB>  <TAB> df = read_jsonl_superglue(jsonl_path) <TAB>  <TAB> df = df[columns] <TAB>  <TAB> df_dict[fold] = df <TAB> return df_dict, None","if fold != ""test"" :",134
def _forward_main_responses(self): <TAB> while self._should_keep_going(): <TAB>  <TAB> line = self._proc.stdout.readline() <MASK> # In the beginning the backend may echo commands sent to it (perhaps this echo-avoiding trick <TAB>  <TAB>  <TAB> # takes time). Don't forward those lines. <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> with self._response_lock: <TAB>  <TAB>  <TAB> sys.stdout.write(line) <TAB>  <TAB>  <TAB> sys.stdout.flush() <TAB>  <TAB>  <TAB> self._main_backend_is_fresh = False,if self . _main_backend_is_fresh and self . _looks_like_echo ( line ) :,161
"def _update_server_version(self): <TAB> """"""Decode the Transmission version string, if available."""""" <TAB> if self.server_version is None: <TAB>  <TAB> version_major = 1 <TAB>  <TAB> version_minor = 30 <TAB>  <TAB> version_changeset = 0 <TAB>  <TAB> version_parser = re.compile(""(\d).(\d+) \((\d+)\)"") <TAB>  <TAB> if hasattr(self.session, ""version""): <TAB>  <TAB>  <TAB> match = version_parser.match(self.session.version) <MASK> version_major = int(match.group(1)) <TAB>  <TAB>  <TAB>  <TAB> version_minor = int(match.group(2)) <TAB>  <TAB>  <TAB>  <TAB> version_changeset = match.group(3) <TAB>  <TAB> self.server_version = (version_major, version_minor, version_changeset)",if match :,190
"def _check_type(T, allowed): <TAB> if T not in allowed: <MASK> allowed.add(T) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> types = "", "".join([t.__name__ for t in allowed] + [T.__name__]) <TAB>  <TAB>  <TAB> raise TypeError(""unsupported mixed types: %s"" % types)",if len ( allowed ) == 1 :,87
"def split_named_range(range_string): <TAB> """"""Separate a named range into its component parts"""""" <TAB> for range_string in SPLIT_NAMED_RANGE_RE.split(range_string)[ <TAB>  <TAB> 1::2 <TAB> ]:  # Skip first and from there every second item <TAB>  <TAB> match = NAMED_RANGE_RE.match(range_string) <MASK> raise NamedRangeException('Invalid named range string: ""%s""' % range_string) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> match = match.groupdict() <TAB>  <TAB>  <TAB> sheet_name = match[""quoted""] or match[""notquoted""] <TAB>  <TAB>  <TAB> xlrange = match[""range""] <TAB>  <TAB>  <TAB> sheet_name = sheet_name.replace(""''"", ""'"")  # Unescape ' <TAB>  <TAB>  <TAB> yield sheet_name, xlrange",if match is None :,191
"def clean(self): <TAB> to_del = [] <TAB> for i, file_ in enumerate(self.files): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> os.remove(file_) <TAB>  <TAB>  <TAB> to_del.append(i) <TAB>  <TAB> except Exception: <MASK> to_del.append(i) <TAB> for i in to_del[::-1]: <TAB>  <TAB> del self.files[i]",if not os . path . isfile ( file_ ) :,108
"def lazy_init(self): <TAB> f = open(self.filename) <TAB> self.base = {} <TAB> while 1: <TAB>  <TAB> l = f.readline() <MASK> break <TAB>  <TAB> l = l.strip().split("","") <TAB>  <TAB> if len(l) != 3: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> c, lat, long = l <TAB>  <TAB> self.base[c] = (float(long), float(lat)) <TAB> f.close()",if not l :,113
"def onto_evo_target(self): <TAB> if self._onto_evo_target is None: <TAB>  <TAB> self._get_onto_evo_target() <TAB> if self._onto_evo_target_qobj is None: <MASK> self._onto_evo_target_qobj = self._onto_evo_target <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> rev_dims = [self.sys_dims[1], self.sys_dims[0]] <TAB>  <TAB>  <TAB> self._onto_evo_target_qobj = Qobj(self._onto_evo_target, dims=rev_dims) <TAB> return self._onto_evo_target_qobj","if isinstance ( self . _onto_evo_target , Qobj ) :",176
"def _dnsname_to_pat(dn): <TAB> pats = [] <TAB> for frag in dn.split(r"".""): <MASK> # When '*' is a fragment by itself, it matches a non-empty dotless <TAB>  <TAB>  <TAB> # fragment. <TAB>  <TAB>  <TAB> pats.append(""[^.]+"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Otherwise, '*' matches any dotless fragment. <TAB>  <TAB>  <TAB> frag = re.escape(frag) <TAB>  <TAB>  <TAB> pats.append(frag.replace(r""\*"", ""[^.]*"")) <TAB> return re.compile(r""\A"" + r""\."".join(pats) + r""\Z"", re.IGNORECASE)","if frag == ""*"" :",155
"def update(id): <TAB> """"""Update a post if the current user is the author."""""" <TAB> post = get_post(id) <TAB> if request.method == ""POST"": <TAB>  <TAB> title = request.form[""title""] <TAB>  <TAB> body = request.form[""body""] <TAB>  <TAB> error = None <MASK> error = ""Title is required."" <TAB>  <TAB> if error is not None: <TAB>  <TAB>  <TAB> flash(error) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> post.title = title <TAB>  <TAB>  <TAB> post.body = body <TAB>  <TAB>  <TAB> db.session.commit() <TAB>  <TAB>  <TAB> return redirect(url_for(""blog.index"")) <TAB> return render_template(""blog/update.html"", post=post)",if not title :,168
"def __iter__(self): <TAB> for token in base.Filter.__iter__(self): <MASK> attrs = OrderedDict() <TAB>  <TAB>  <TAB> for name, value in sorted(token[""data""].items(), key=_attr_key): <TAB>  <TAB>  <TAB>  <TAB> attrs[name] = value <TAB>  <TAB>  <TAB> token[""data""] = attrs <TAB>  <TAB> yield token","if token [ ""type"" ] in ( ""StartTag"" , ""EmptyTag"" ) :",94
"def get_polymorphic_model(data): <TAB> for model in itervalues(models): <TAB>  <TAB> polymorphic = model.opts.polymorphic <TAB>  <TAB> if polymorphic: <TAB>  <TAB>  <TAB> polymorphic_key = polymorphic <TAB>  <TAB>  <TAB> if isinstance(polymorphic_key, bool): <TAB>  <TAB>  <TAB>  <TAB> polymorphic_key = ""type"" <MASK> return model <TAB> raise ImproperlyConfigured(u""No model found for data: {!r}"".format(data))",if data . get ( polymorphic_key ) == model . __name__ :,133
"def _setup_tag(self, tag): <TAB> # keeping mutual refs <TAB> tag.py_obj = self <TAB> self.riot_tag = tag <TAB> # making the event system call self's methods: <TAB> handlers = {} <TAB> for ev in lifecycle_ev: <TAB>  <TAB> f = getattr(self, ev.replace(""-"", ""_"")) <MASK> # this.on('mount', function() {...}): <TAB>  <TAB>  <TAB> # whats nicer? <TAB>  <TAB>  <TAB> tag.on(ev, f)",if f :,124
"def selection_only(self): <TAB> selection_only = False <TAB> sel = self.sel() <TAB> if (self.context == ""selection"" or self.context == ""both"") and len(sel): <TAB>  <TAB> # if multiple lines, always true <MASK> selection_only = True <TAB>  <TAB> # check threshold <TAB>  <TAB> elif self.threshold and not sel[0].empty(): <TAB>  <TAB>  <TAB> text = self.view.substr(sel[0]) <TAB>  <TAB>  <TAB> match = re.search(self.threshold, text) <TAB>  <TAB>  <TAB> if match: <TAB>  <TAB>  <TAB>  <TAB> selection_only = True <TAB>  <TAB> # no valid selection <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> selection_only = False <TAB> return selection_only",if len ( sel ) > 1 :,174
"def find_torrents_to_fetch(torrent_ids): <TAB> to_fetch = [] <TAB> t = time() <TAB> for torrent_id in torrent_ids: <TAB>  <TAB> torrent = self.torrents[torrent_id] <MASK> to_fetch.append(torrent_id) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # We need to check if a key is expired <TAB>  <TAB>  <TAB> for key in keys: <TAB>  <TAB>  <TAB>  <TAB> if t - self.cache_times[torrent_id].get(key, 0.0) > self.cache_time: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> to_fetch.append(torrent_id) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return to_fetch",if t - torrent [ 0 ] > self . cache_time :,180
"def filter(callbackfn): <TAB> array = this.to_object() <TAB> arr_len = array.get(""length"").to_uint32() <TAB> if not callbackfn.is_callable(): <TAB>  <TAB> raise this.MakeError(""TypeError"", ""callbackfn must be a function"") <TAB> T = arguments[1] <TAB> res = [] <TAB> k = 0 <TAB> while k < arr_len: <TAB>  <TAB> if array.has_property(str(k)): <TAB>  <TAB>  <TAB> kValue = array.get(str(k)) <MASK> res.append(kValue) <TAB>  <TAB> k += 1 <TAB> return res  # converted to js array automatically","if callbackfn . call ( T , ( kValue , this . Js ( k ) , array ) ) . to_boolean ( ) . value :",179
"def generate_py_upgrades(data): <TAB> """"""Generate the list of upgrades in upgrades.py."""""" <TAB> print("" upgrades.py "".center(60, ""-"")) <TAB> print(""class Upgrades(enum.IntEnum):"") <TAB> print('  """"""The list of upgrades, as returned from RequestData.""""""') <TAB> for upgrade in sorted(data.upgrades, key=lambda a: a.name): <MASK> print(""  %s = %s"" % (upgrade.name, upgrade.upgrade_id)) <TAB> print(""\n"")",if upgrade . name and upgrade . upgrade_id in static_data . UPGRADES :,154
"def get_first_n(l, n, reverse=False): <TAB> cur_n = 0 <TAB> res = [] <TAB> for si in reversed(l) if reverse else l: <TAB>  <TAB> if trade_exchange.is_stock_tradable(stock_id=si, trade_date=trade_date): <TAB>  <TAB>  <TAB> res.append(si) <TAB>  <TAB>  <TAB> cur_n += 1 <MASK> break <TAB> return res[::-1] if reverse else res",if cur_n >= n :,120
"def _fill_cache(self): <TAB> for task in linux_pslist.linux_pslist(self._config).calculate(): <TAB>  <TAB> for filp, fd in task.lsof(): <TAB>  <TAB>  <TAB> filepath = linux_common.get_path(task, filp) <MASK> to_add = filp.dentry.d_inode.i_ino.v() <TAB>  <TAB>  <TAB>  <TAB> self.fd_cache[to_add] = [task, filp, fd, filepath]","if type ( filepath ) == str and filepath . find ( ""socket:["" ) != - 1 :",137
"def is_ArAX_implicit(ii):  # allows one implicit fixed reg <TAB> a, implicit_fixed = 0, 0 <TAB> for op in _gen_opnds(ii): <TAB>  <TAB> if op_luf_start(op, ""ArAX""): <TAB>  <TAB>  <TAB> a += 1 <MASK> implicit_fixed += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> return a == 1 and implicit_fixed <= 1",elif op_reg ( op ) and op_implicit_specific_reg ( op ) :,120
"def auto_resize(self, name: str) -> None: <TAB> """"""recompute widget width based on max length of all of the values"""""" <TAB> widget = self.find_widget(name) <TAB> for column in range(len(widget._columns) - 1): <TAB>  <TAB> sizes = [len(x[0][column]) + 1 for x in widget.options] <MASK> sizes.append(len(widget._titles[column]) + 1) <TAB>  <TAB> widget._columns[column] = max(sizes)",if widget . _titles :,124
"def dns_set_secondary_nameserver(): <TAB> from dns_update import set_secondary_dns <TAB> try: <TAB>  <TAB> return set_secondary_dns( <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB> ns.strip() <TAB>  <TAB>  <TAB>  <TAB> for ns in re.split(r""[, ]+"", request.form.get(""hostnames"") or """") <MASK> ], <TAB>  <TAB>  <TAB> env, <TAB>  <TAB> ) <TAB> except ValueError as e: <TAB>  <TAB> return (str(e), 400)","if ns . strip ( ) != """"",122
"def assert_inputs(inputs, can_be_used=True): <TAB> # Until we make the dataset private, _different_user() can use it: <TAB> with self._different_user_and_history() as other_history_id: <TAB>  <TAB> response = self._run(""cat1"", other_history_id, inputs) <MASK> assert response.status_code == 200 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._assert_dataset_permission_denied_response(response)",if can_be_used :,120
"def _handle_start(self, tag, attrib): <TAB> if ""translatable"" in attrib: <MASK> self._translate = True <TAB>  <TAB>  <TAB> if ""comments"" in attrib: <TAB>  <TAB>  <TAB>  <TAB> self._comments.append(attrib[attrib.index(""comments"") + 1])","if attrib [ attrib . index ( ""translatable"" ) + 1 ] == ""yes"" :",83
"def get_command(cls): <TAB> ifconfig_cmd = ""ip"" <TAB> for path in [""/sbin"", ""/usr/sbin"", ""/bin"", ""/usr/bin""]: <TAB>  <TAB> if os.path.exists(os.path.join(path, ifconfig_cmd)): <MASK> break <TAB> ifconfig_cmd = ifconfig_cmd + "" address show"" <TAB> return ifconfig_cmd","ifconfig_cmd = os . path . join ( path , ifconfig_cmd )",109
"def render(self): <TAB> """"""What to show when printed."""""" <TAB> viz = """" <TAB> for y in range(self.grid.height): <TAB>  <TAB> for x in range(self.grid.width): <TAB>  <TAB>  <TAB> c = self.grid[y][x] <MASK> viz += "" "" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> viz += self.converter(c) <TAB>  <TAB> viz += ""\n"" <TAB> return viz",if c is None :,110
"def _sorted_layers(self, structure, top_layer_id): <TAB> """"""Return the image layers sorted"""""" <TAB> sorted_layers = [] <TAB> next_layer = top_layer_id <TAB> while next_layer: <TAB>  <TAB> sorted_layers.append(next_layer) <MASK> # v2 <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if ""parent"" not in structure[""repolayers""][next_layer][""json""]: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> next_layer = structure[""repolayers""][next_layer][""json""][""parent""] <TAB>  <TAB> if not next_layer: <TAB>  <TAB>  <TAB> break <TAB> return sorted_layers","if ""json"" not in structure [ ""repolayers"" ] [ next_layer ] :",162
"def check_sync(self): <TAB> login_failures = get_login_failures(datetime.now(), catmsgs()) <TAB> if login_failures: <TAB>  <TAB> return Alert( <TAB>  <TAB>  <TAB> SSHLoginFailuresAlertClass, <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB> ""count"": len(login_failures), <TAB>  <TAB>  <TAB>  <TAB> ""failures"": """".join( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> login_failures <MASK> else login_failures[:2] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> + [f""... {len(login_failures) - 4} more ...\n""] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> + login_failures[-2:] <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB> }, <TAB>  <TAB> )",if len ( login_failures ) <= 5,172
"def on_user_auth_login_success(sender, user, request, **kwargs): <TAB> if settings.USER_LOGIN_SINGLE_MACHINE_ENABLED: <TAB>  <TAB> user_id = ""single_machine_login_"" + str(user.id) <TAB>  <TAB> session_key = cache.get(user_id) <MASK> session = import_module(settings.SESSION_ENGINE).SessionStore(session_key) <TAB>  <TAB>  <TAB> session.delete() <TAB>  <TAB> cache.set(user_id, request.session.session_key, None)",if session_key and session_key != request . session . session_key :,146
"def slots_for_entities(self, entities): <TAB> if self.store_entities_as_slots: <TAB>  <TAB> slot_events = [] <TAB>  <TAB> for s in self.slots: <MASK> matching_entities = [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> e[""value""] for e in entities if e[""entity""] == s.name <TAB>  <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB>  <TAB> if matching_entities: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if s.type_name == ""list"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> slot_events.append(SlotSet(s.name, matching_entities)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> slot_events.append(SlotSet(s.name, matching_entities[-1])) <TAB>  <TAB> return slot_events <TAB> else: <TAB>  <TAB> return []",if s . auto_fill :,193
"def get(self, id): <TAB> obj = self.klass.objects.get(id=id) <TAB> if hasattr(obj, ""sharing""): <MASK> return render_template( <TAB>  <TAB>  <TAB>  <TAB> ""{}/single.html"".format(self.klass.__name__.lower()), obj=obj <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> abort(403) <TAB> else: <TAB>  <TAB> return render_template( <TAB>  <TAB>  <TAB> ""{}/single.html"".format(self.klass.__name__.lower()), obj=obj <TAB>  <TAB> ) <TAB> return request.referrer",if group_user_permission ( obj ) :,137
"def __call__(self, module, *x): <TAB> """"""Grab the instantiated layer and evaluate it."""""" <TAB> operation = getattr(module, self.name) <TAB> try: <MASK> return self.func(operation, *x) <TAB>  <TAB> return operation(*x) <TAB> except: <TAB>  <TAB> logger.error(""Failed to apply layer: %s"", self.name) <TAB>  <TAB> for i, X in enumerate(x): <TAB>  <TAB>  <TAB> logger.error(""  Input shape #%d: %s"", i + 1, list(X.size())) <TAB>  <TAB> raise",if self . func :,135
"def req(s, poll, msg, expect): <TAB> do_req = True <TAB> xid = None <TAB> while True: <TAB>  <TAB> # get transaction id <MASK> xid = s.put(msg)[""xid""] <TAB>  <TAB> # wait for response <TAB>  <TAB> events = poll.poll(2) <TAB>  <TAB> for (fd, event) in events: <TAB>  <TAB>  <TAB> response = s.get() <TAB>  <TAB>  <TAB> if response[""xid""] != xid: <TAB>  <TAB>  <TAB>  <TAB> do_req = False <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if response[""options""][""message_type""] != expect: <TAB>  <TAB>  <TAB>  <TAB> raise Exception(""DHCP protocol error"") <TAB>  <TAB>  <TAB> return response <TAB>  <TAB> do_req = True",if do_req :,174
"def _state_old_c_params(self, token): <TAB> self._saved_tokens.append(token) <TAB> if token == "";"": <TAB>  <TAB> self._saved_tokens = [] <TAB>  <TAB> self._state = self._state_dec_to_imp <TAB> elif token == ""{"": <MASK> self._saved_tokens = [] <TAB>  <TAB>  <TAB> self._state_dec_to_imp(token) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> self._state = self._state_global <TAB>  <TAB> for tkn in self._saved_tokens: <TAB>  <TAB>  <TAB> self._state(tkn) <TAB> elif token == ""("": <TAB>  <TAB> self._state = self._state_global <TAB>  <TAB> for tkn in self._saved_tokens: <TAB>  <TAB>  <TAB> self._state(tkn)",if len ( self . _saved_tokens ) == 2 :,186
"def assert_tensors_equal(sess, t1, t2, n): <TAB> """"""Compute tensors `n` times and ensure that they are equal."""""" <TAB> for _ in range(n): <TAB>  <TAB> v1, v2 = sess.run([t1, t2]) <TAB>  <TAB> if v1.shape != v2.shape: <TAB>  <TAB>  <TAB> return False <MASK> return False <TAB> return True",if not np . all ( v1 == v2 ) :,107
"def http_error_302(self, url, fp, errcode, errmsg, headers, data=None): <TAB> """"""Error 302 -- relocated (temporarily)."""""" <TAB> self.tries += 1 <TAB> if self.maxtries and self.tries >= self.maxtries: <MASK> meth = self.http_error_500 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> meth = self.http_error_default <TAB>  <TAB> self.tries = 0 <TAB>  <TAB> return meth(url, fp, 500, ""Internal Server Error: Redirect Recursion"", headers) <TAB> result = self.redirect_internal(url, fp, errcode, errmsg, headers, data) <TAB> self.tries = 0 <TAB> return result","if hasattr ( self , ""http_error_500"" ) :",172
"def get_satellite_list(self, daemon_type=""""): <TAB> res = {} <TAB> for t in [""arbiter"", ""scheduler"", ""poller"", ""reactionner"", ""receiver"", ""broker""]: <TAB>  <TAB> if daemon_type and daemon_type != t: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> satellite_list = [] <TAB>  <TAB> res[t] = satellite_list <TAB>  <TAB> daemon_name_attr = t + ""_name"" <TAB>  <TAB> daemons = self.app.get_daemons(t) <TAB>  <TAB> for dae in daemons: <MASK> satellite_list.append(getattr(dae, daemon_name_attr)) <TAB> return res","if hasattr ( dae , daemon_name_attr ) :",175
"def check(data_dir, decrypter, read_only=False): <TAB> fname = os.path.join(data_dir, DIGEST_NAME) <TAB> if os.path.exists(fname): <MASK> return False <TAB>  <TAB> f = open(fname, ""rb"") <TAB>  <TAB> s = f.read() <TAB>  <TAB> f.close() <TAB>  <TAB> return decrypter.decrypt(s) == MAGIC_STRING <TAB> else: <TAB>  <TAB> if decrypter is not None: <TAB>  <TAB>  <TAB> if read_only: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> s = decrypter.encrypt(MAGIC_STRING) <TAB>  <TAB>  <TAB>  <TAB> f = open(fname, ""wb"") <TAB>  <TAB>  <TAB>  <TAB> f.write(s) <TAB>  <TAB>  <TAB>  <TAB> f.close() <TAB>  <TAB> return True",if decrypter is None :,198
"def logic(): <TAB> while 1: <TAB>  <TAB> yield clock.posedge, reset.negedge <MASK> count.next = 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if enable: <TAB>  <TAB>  <TAB>  <TAB> count.next = f1(n)",if reset == ACTIVE_LOW :,69
"def get_project_translation(request, project=None, component=None, lang=None): <TAB> """"""Return project, component, translation tuple for given parameters."""""" <TAB> if lang and component: <TAB>  <TAB> # Language defined? We can get all <TAB>  <TAB> translation = get_translation(request, project, component, lang) <TAB>  <TAB> component = translation.component <TAB>  <TAB> project = component.project <TAB> else: <TAB>  <TAB> translation = None <TAB>  <TAB> if component: <TAB>  <TAB>  <TAB> # Component defined? <TAB>  <TAB>  <TAB> component = get_component(request, project, component) <TAB>  <TAB>  <TAB> project = component.project <MASK> # Only project defined? <TAB>  <TAB>  <TAB> project = get_project(request, project) <TAB> # Return tuple <TAB> return project or None, component or None, translation or None",elif project :,184
"def run(self, sql, encoding=None): <TAB> stream = lexer.tokenize(sql, encoding) <TAB> # Process token stream <TAB> for filter_ in self.preprocess: <TAB>  <TAB> stream = filter_.process(stream) <TAB> stream = StatementSplitter().process(stream) <TAB> # Output: Stream processed Statements <TAB> for stmt in stream: <MASK> stmt = grouping.group(stmt) <TAB>  <TAB> for filter_ in self.stmtprocess: <TAB>  <TAB>  <TAB> filter_.process(stmt) <TAB>  <TAB> for filter_ in self.postprocess: <TAB>  <TAB>  <TAB> stmt = filter_.process(stmt) <TAB>  <TAB> yield stmt",if self . _grouping :,148
"def get_word_parens_range(self, offset, opening=""("", closing="")""): <TAB> end = self._find_word_end(offset) <TAB> start_parens = self.code.index(opening, end) <TAB> index = start_parens <TAB> open_count = 0 <TAB> while index < len(self.code): <TAB>  <TAB> if self.code[index] == opening: <TAB>  <TAB>  <TAB> open_count += 1 <MASK> open_count -= 1 <TAB>  <TAB> if open_count == 0: <TAB>  <TAB>  <TAB> return (start_parens, index + 1) <TAB>  <TAB> index += 1 <TAB> return (start_parens, index)",if self . code [ index ] == closing :,160
def _get_inherited_env_vars(self): <TAB> env_vars = os.environ.copy() <TAB> for var_name in ENV_VARS_BLACKLIST: <TAB>  <TAB> if var_name.lower() in env_vars: <TAB>  <TAB>  <TAB> del env_vars[var_name.lower()] <MASK> del env_vars[var_name.upper()] <TAB> return env_vars,if var_name . upper ( ) in env_vars :,104
"def adapt_datetimefield_value(self, value): <TAB> if value is None: <TAB>  <TAB> return None <TAB> # Expression values are adapted by the database. <TAB> if hasattr(value, ""resolve_expression""): <TAB>  <TAB> return value <TAB> # SQLite doesn't support tz-aware datetimes <TAB> if timezone.is_aware(value): <MASK> value = timezone.make_naive(value, self.connection.timezone) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""SQLite backend does not support timezone-aware datetimes when USE_TZ is False."" <TAB>  <TAB>  <TAB> ) <TAB> return six.text_type(value)",if settings . USE_TZ :,156
"def dragMoveEvent(self, event): <TAB> data = event.mimeData() <TAB> urls = data.urls() <TAB> if urls and urls[0].scheme() == ""file"": <TAB>  <TAB> event.acceptProposedAction() <TAB>  <TAB> indexRow = self.indexAt(event.pos()).row() <TAB>  <TAB> window = self.parent().parent().parent().parent().parent().parent() <MASK> indexRow = window.playlist.count() <TAB>  <TAB> window.setPlaylistInsertPosition(indexRow) <TAB> else: <TAB>  <TAB> super(MainWindow.PlaylistWidget, self).dragMoveEvent(event)",if indexRow == - 1 or not window . clearedPlaylistNote :,157
"def explode(self, obj): <TAB> """"""Determine if the object should be exploded."""""" <TAB> if obj in self._done: <TAB>  <TAB> return False <TAB> result = False <TAB> for item in self._explode: <TAB>  <TAB> if hasattr(item, ""_moId""): <TAB>  <TAB>  <TAB> # If it has a _moId it is an instance <TAB>  <TAB>  <TAB> if obj._moId == item._moId: <TAB>  <TAB>  <TAB>  <TAB> result = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # If it does not have a _moId it is a template <MASK> result = True <TAB> if result: <TAB>  <TAB> self._done.add(obj) <TAB> return result",if obj . __class__ . __name__ == item . __name__ :,166
"def _maybe_clean(self): <TAB> """"""Clean the cache if it's time to do so."""""" <TAB> now = time.time() <TAB> if self.next_cleaning <= now: <TAB>  <TAB> keys_to_delete = [] <TAB>  <TAB> for (k, v) in self.data.items(): <MASK> keys_to_delete.append(k) <TAB>  <TAB> for k in keys_to_delete: <TAB>  <TAB>  <TAB> del self.data[k] <TAB>  <TAB> now = time.time() <TAB>  <TAB> self.next_cleaning = now + self.cleaning_interval",if v . expiration <= now :,145
"def test_doc_attributes(self): <TAB> print_test_name(""TEST DOC ATTRIBUTES"") <TAB> correct = 0 <TAB> for example in DOC_EXAMPLES: <TAB>  <TAB> original_schema = schema.parse(example.schema_string) <TAB>  <TAB> if original_schema.doc is not None: <TAB>  <TAB>  <TAB> correct += 1 <MASK> for f in original_schema.fields: <TAB>  <TAB>  <TAB>  <TAB> if f.doc is None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.fail( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Failed to preserve 'doc' in fields: "" + example.schema_string <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> self.assertEqual(correct, len(DOC_EXAMPLES))","if original_schema . type == ""record"" :",168
"def save_as(self): <TAB> """"""Save *as* the currently edited file"""""" <TAB> editorstack = self.get_current_editorstack() <TAB> if editorstack.save_as(): <TAB>  <TAB> fname = editorstack.get_current_filename() <MASK> self.emit(SIGNAL(""open_dir(QString)""), osp.dirname(fname)) <TAB>  <TAB> self.__add_recent_file(fname)","if CONF . get ( ""workingdir"" , ""editor/save/auto_set_to_basedir"" ) :",117
"def verify_settings(rst_path: Path) -> Iterator[Error]: <TAB> for setting_name, default in find_settings_in_rst(rst_path): <TAB>  <TAB> actual = getattr(app.conf, setting_name) <TAB>  <TAB> if isinstance(default, timedelta): <TAB>  <TAB>  <TAB> default = default.total_seconds() <TAB>  <TAB> if isinstance(actual, Enum): <TAB>  <TAB>  <TAB> actual = actual.value <MASK> yield Error( <TAB>  <TAB>  <TAB>  <TAB> reason=""mismatch"", <TAB>  <TAB>  <TAB>  <TAB> setting=setting_name, <TAB>  <TAB>  <TAB>  <TAB> default=default, <TAB>  <TAB>  <TAB>  <TAB> actual=actual, <TAB>  <TAB>  <TAB> )",if actual != default :,152
"def JobWait(self, waiter): <TAB> # type: (Waiter) -> wait_status_t <TAB> # wait builtin can be interrupted <TAB> while True: <TAB>  <TAB> # Don't retry <TAB>  <TAB> result = waiter.WaitForOne(False) <TAB>  <TAB> if result > 0:  # signal <TAB>  <TAB>  <TAB> return wait_status.Cancelled(result) <TAB>  <TAB> if result == -1:  # nothing to wait for <TAB>  <TAB>  <TAB> break <MASK> break <TAB> return wait_status.Proc(self.status)",if self . state != job_state_e . Running :,135
"def object_hook(obj): <TAB> obj_len = len(obj) <TAB> if obj_len == 1: <TAB>  <TAB> if ""$date"" in obj: <TAB>  <TAB>  <TAB> return datetime.fromtimestamp( <TAB>  <TAB>  <TAB>  <TAB> obj[""$date""] / 1000, tz=timezone.utc <TAB>  <TAB>  <TAB> ) + timedelta(milliseconds=obj[""$date""] % 1000) <MASK> return time(*[int(i) for i in obj[""$time""].split("":"")]) <TAB> if obj_len == 2 and ""$type"" in obj and ""$value"" in obj: <TAB>  <TAB> if obj[""$type""] == ""date"": <TAB>  <TAB>  <TAB> return date(*[int(i) for i in obj[""$value""].split(""-"")]) <TAB> return obj","if ""$time"" in obj :",174
"def before_FunctionDef(self, node): <TAB> s = self.format(node, print_body=False) <TAB> if self.test_kind is ""test"": <TAB>  <TAB> print(s) <TAB> self.indent += 1 <TAB> self.context_stack.append(node) <TAB> if self.pass_n == 1: <TAB>  <TAB> self.stats.defs += 1 <MASK> if self.class_name in self.classes: <TAB>  <TAB>  <TAB>  <TAB> the_class = self.classes.get(self.class_name) <TAB>  <TAB>  <TAB>  <TAB> methods = the_class.get(""methods"") <TAB>  <TAB>  <TAB>  <TAB> # tag:setter function-name=stringized-args <TAB>  <TAB>  <TAB>  <TAB> methods[node.name] = self.format(node.args)",if self . class_name not in self . special_class_names :,192
"def setAttributeNS(self, namespaceURI, qualifiedName, value): <TAB> prefix, localname = _nssplit(qualifiedName) <TAB> attr = self.getAttributeNodeNS(namespaceURI, localname) <TAB> if attr is None: <TAB>  <TAB> attr = Attr(qualifiedName, namespaceURI, localname, prefix) <TAB>  <TAB> attr.value = value <TAB>  <TAB> attr.ownerDocument = self.ownerDocument <TAB>  <TAB> self.setAttributeNode(attr) <TAB> else: <TAB>  <TAB> if value != attr.value: <TAB>  <TAB>  <TAB> attr.value = value <MASK> _clear_id_cache(self) <TAB>  <TAB> if attr.prefix != prefix: <TAB>  <TAB>  <TAB> attr.prefix = prefix <TAB>  <TAB>  <TAB> attr.nodeName = qualifiedName",if attr . isId :,177
"def main(): <TAB> try: <TAB>  <TAB> from wsgiref.simple_server import make_server <TAB>  <TAB> from wsgiref.validate import validator <MASK> port[0] = get_open_port() <TAB>  <TAB> wsgi_application = WsgiApplication(msgpackrpc_application) <TAB>  <TAB> server = make_server(host, port[0], validator(wsgi_application)) <TAB>  <TAB> logger.info(""Starting interop server at %s:%s."" % (host, port[0])) <TAB>  <TAB> logger.info(""WSDL is at: /?wsdl"") <TAB>  <TAB> server.serve_forever() <TAB> except ImportError: <TAB>  <TAB> print(""Error: example server code requires Python >= 2.5"")",if port [ 0 ] == 0 :,172
"def yield_modules(path): <TAB> """"""Yield all Python modules underneath *path*"""""" <TAB> for (dpath, dnames, fnames) in os.walk(path): <TAB>  <TAB> module = tuple(dpath.split(""/"")[1:]) <TAB>  <TAB> for fname in fnames: <TAB>  <TAB>  <TAB> if not fname.endswith("".py""): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> fpath = os.path.join(dpath, fname) <MASK> yield (fpath, module) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield (fpath, module + (fname[:-3],)) <TAB>  <TAB> dnames[:] = [ <TAB>  <TAB>  <TAB> x for x in dnames if os.path.exists(os.path.join(dpath, x, ""__init__.py"")) <TAB>  <TAB> ]","if fname == ""__init__.py"" :",182
"def dump_section(name, section): <TAB> lines.append(""[%s]\n"" % name) <TAB> for key, value in section.all_items(): <TAB>  <TAB> if not key.startswith(""_""): <TAB>  <TAB>  <TAB> try: <MASK> lines.append( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""%s=%s\n"" % (key, section.definitions[key].tostring(value)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> lines.append(""%s=%s\n"" % (key, value)) <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> logger.exception('Error serializing ""%s"" in section ""[%s]""', key, name) <TAB> lines.append(""\n"")",if key in section . definitions :,175
"def testCreateTimeout(self): <TAB> cluster = None <TAB> try: <TAB>  <TAB> env_path = ""conda://"" + os.environ[""CONDA_PREFIX""] <TAB>  <TAB> log_config_file = os.path.join( <TAB>  <TAB>  <TAB> os.path.dirname(os.path.abspath(__file__)), ""yarn-logging.conf"" <TAB>  <TAB> ) <TAB>  <TAB> with self.assertRaises(TimeoutError): <TAB>  <TAB>  <TAB> cluster = new_cluster( <TAB>  <TAB>  <TAB>  <TAB> env_path, <TAB>  <TAB>  <TAB>  <TAB> log_config=log_config_file, <TAB>  <TAB>  <TAB>  <TAB> worker_cache_mem=""64m"", <TAB>  <TAB>  <TAB>  <TAB> log_when_fail=True, <TAB>  <TAB>  <TAB>  <TAB> timeout=1, <TAB>  <TAB>  <TAB> ) <TAB> finally: <MASK> cluster.stop()",if cluster is not None :,187
"def read_phrases(data_dir, movies=None): <TAB> res = {} <TAB> for parts in iterate_entries(data_dir, ""movie_lines.txt""): <TAB>  <TAB> l_id, m_id, l_str = parts[0], parts[2], parts[4] <TAB>  <TAB> if movies and m_id not in movies: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> tokens = utils.tokenize(l_str) <MASK> res[l_id] = tokens <TAB> return res",if tokens :,127
"def get_Subclass_of(rt): <TAB> for y in [getattr(Ast, x) for x in dir(Ast)]: <TAB>  <TAB> yt = clr.GetClrType(y) <TAB>  <TAB> if rt == yt: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if yt.IsAbstract: <TAB>  <TAB>  <TAB> continue <MASK> yield yt.Name",if yt . IsSubclassOf ( rt ) :,93
"def retrieve(self, aclass): <TAB> """"""Look for a specifc class/name in the packet"""""" <TAB> resu = [] <TAB> for x in self.payload: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if isinstance(aclass, str): <TAB>  <TAB>  <TAB>  <TAB> if x.name == aclass: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> resu.append(x) <TAB>  <TAB>  <TAB> else: <MASK> resu.append(x) <TAB>  <TAB>  <TAB> resu += x.retrieve(aclass) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> pass <TAB> return resu","if isinstance ( x , aclass ) :",144
"def _max_physical(self): <TAB> ""How big is the physical screen?"" <TAB> # On OS X newwin does not correctly get the size of the screen. <TAB> # let's see how big we could be: create a temp screen <TAB> # and see the size curses makes it.  No good to keep, though <TAB> try: <TAB>  <TAB> mxy, mxx = struct.unpack( <TAB>  <TAB>  <TAB> ""hh"", fcntl.ioctl(sys.stderr.fileno(), termios.TIOCGWINSZ, ""xxxx"") <TAB>  <TAB> ) <MASK> raise ValueError <TAB> except (ValueError, NameError): <TAB>  <TAB> mxy, mxx = curses.newwin(0, 0).getmaxyx() <TAB> # return safe values, i.e. slightly smaller. <TAB> return (mxy - 1, mxx - 1)","if ( mxy , mxx ) == ( 0 , 0 ) :",195
"def deserialize(self, cassette_string): <TAB> cassette_dict = self.base_serializer.deserialize(cassette_string) <TAB> for interaction in cassette_dict[""interactions""]: <TAB>  <TAB> response = interaction[""response""] <TAB>  <TAB> headers = response[""headers""] <MASK> rg, size, filename = self._parse_headers(headers) <TAB>  <TAB>  <TAB> with open(join(self.directory, filename), ""rb"") as f: <TAB>  <TAB>  <TAB>  <TAB> f.seek(rg[0]) <TAB>  <TAB>  <TAB>  <TAB> content = f.read(rg[1] - rg[0] + 1) <TAB>  <TAB>  <TAB> response[""body""][""string""] = content <TAB> return cassette_dict","if ""Content-Range"" in headers and ""Content-Disposition"" in headers :",180
"def parse_head(fileobj, parser): <TAB> """"""Return a list of key, value pairs."""""" <TAB> while 1: <TAB>  <TAB> data = fileobj.read(CHUNK) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> parser.feed(data) <TAB>  <TAB> except EndOfHeadError: <TAB>  <TAB>  <TAB> break <MASK> # this should only happen if there is no HTML body, or if <TAB>  <TAB>  <TAB> # CHUNK is big <TAB>  <TAB>  <TAB> break <TAB> return parser.http_equiv",if len ( data ) != CHUNK :,119
"def _check_no_empty_dimension_lists(config): <TAB> """"""Verify that at least one dimension is not an empty list"""""" <TAB> logging.info(""Checking provided dimensions are valid"") <TAB> for feature in config.get(""test-suites"").values(): <TAB>  <TAB> for test_name, test in feature.items(): <TAB>  <TAB>  <TAB> for dimensions_config in test.values(): <TAB>  <TAB>  <TAB>  <TAB> for dimensions_group in dimensions_config: <MASK> logging.error( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Values assigned to dimensions in test %s cannot be empty"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> test_name, <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise AssertionError",if [ ] in dimensions_group . values ( ) :,175
"def aggregate_sorted(self, items): <TAB> create = self.createCombiner <TAB> merge = self.mergeValue <TAB> i = None <TAB> for i, (k, v) in enumerate(items): <TAB>  <TAB> if i == 0: <TAB>  <TAB>  <TAB> curr_key = k <TAB>  <TAB>  <TAB> curr_value = create(v) <MASK> yield curr_key, curr_value <TAB>  <TAB>  <TAB> curr_key = k <TAB>  <TAB>  <TAB> curr_value = create(v) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> curr_value = merge(curr_value, v) <TAB> if i is not None: <TAB>  <TAB> yield curr_key, curr_value",elif k != curr_key :,159
"def _run_iptables(self, version, cmd, *args): <TAB> ipt_cmd = ""{} {}"".format(self._iptables_command(version), cmd) <TAB> if self._has_w_argument is None: <TAB>  <TAB> result = self.run_expect([0, 2], ipt_cmd, *args) <MASK> self._has_w_argument = False <TAB>  <TAB>  <TAB> return self._run_iptables(version, cmd, *args) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._has_w_argument = True <TAB>  <TAB>  <TAB> return result.stdout.rstrip(""\r\n"") <TAB> else: <TAB>  <TAB> return self.check_output(ipt_cmd, *args)",if result . rc == 2 :,172
"def handle_data(self, data): <TAB> if self.in_span or self.in_div: <TAB>  <TAB> if data == ""No such user (please note that login is case sensitive)"": <TAB>  <TAB>  <TAB> self.no_user = True <TAB>  <TAB> elif data == ""Invalid password"": <TAB>  <TAB>  <TAB> self.bad_pw = True <MASK> self.already_exists = True","elif data == ""User with that email already exists"" :",101
"def configure(self, **kw): <TAB> """"""Configure the image."""""" <TAB> res = () <TAB> for k, v in _cnfmerge(kw).items(): <TAB>  <TAB> if v is not None: <TAB>  <TAB>  <TAB> if k[-1] == ""_"": <TAB>  <TAB>  <TAB>  <TAB> k = k[:-1] <TAB>  <TAB>  <TAB> if hasattr(v, ""__call__""): <TAB>  <TAB>  <TAB>  <TAB> v = self._register(v) <MASK> v = self.tk._createbytearray(v) <TAB>  <TAB>  <TAB> res = res + (""-"" + k, v) <TAB> self.tk.call((self.name, ""config"") + res)","elif k in ( ""data"" , ""maskdata"" ) :",154
"def run(self): <TAB> if self.distribution.install_requires: <TAB>  <TAB> self.distribution.fetch_build_eggs(self.distribution.install_requires) <TAB> if self.distribution.tests_require: <TAB>  <TAB> self.distribution.fetch_build_eggs(self.distribution.tests_require) <TAB> if self.test_suite: <TAB>  <TAB> cmd = "" "".join(self.test_args) <MASK> self.announce('skipping ""unittest %s"" (dry run)' % cmd) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.announce('running ""unittest %s""' % cmd) <TAB>  <TAB>  <TAB> self.with_project_on_sys_path(self.run_tests)",if self . dry_run :,171
"def wrapped(request, *args, **kwargs): <TAB> if not gargoyle.is_active(key, request): <TAB>  <TAB> if not redirect_to: <TAB>  <TAB>  <TAB> raise Http404(""Switch '%s' is not active"" % key) <MASK> return HttpResponseRedirect(redirect_to) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return HttpResponseRedirect(reverse(redirect_to)) <TAB> return func(request, *args, **kwargs)","elif redirect_to . startswith ( ""/"" ) :",109
"def strip_suffixes(path: str) -> str: <TAB> t = path <TAB> while True: <MASK> t = t[:-3] <TAB>  <TAB> elif t.endswith("".raw""): <TAB>  <TAB>  <TAB> t = t[:-4] <TAB>  <TAB> elif t.endswith("".tar""): <TAB>  <TAB>  <TAB> t = t[:-4] <TAB>  <TAB> elif t.endswith("".qcow2""): <TAB>  <TAB>  <TAB> t = t[:-6] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> return t","if t . endswith ( "".xz"" ) :",119
"def tags(self): <TAB> label = """" <TAB> for dt in constants.DOMAIN_TYPES: <MASK> label = dt[1] <TAB> result = [{""name"": self.type, ""label"": label, ""type"": ""dom""}] <TAB> if self.transport: <TAB>  <TAB> result.append( <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB> ""name"": self.transport.service, <TAB>  <TAB>  <TAB>  <TAB> ""label"": self.transport.service, <TAB>  <TAB>  <TAB>  <TAB> ""type"": ""srv"", <TAB>  <TAB>  <TAB>  <TAB> ""color"": ""info"", <TAB>  <TAB>  <TAB> } <TAB>  <TAB> ) <TAB> return result",if self . type == dt [ 0 ] :,148
"def find_first_of_filetype(content, filterfiltype, attr=""name""): <TAB> """"""Find the first of the file type."""""" <TAB> filename = """" <TAB> for _filename in content: <TAB>  <TAB> if isinstance(_filename, str): <TAB>  <TAB>  <TAB> if _filename.endswith(f"".{filterfiltype}""): <TAB>  <TAB>  <TAB>  <TAB> filename = _filename <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <MASK> filename = getattr(_filename, attr) <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return filename","if getattr ( _filename , attr ) . endswith ( f"".{filterfiltype}"" ) :",135
"def check_data_array_types(self, *arrays): <TAB> result = [] <TAB> for array in arrays: <MASK> result.append(array) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> result.append(np.asanyarray(array)) <TAB>  <TAB> if not result[-1].shape: <TAB>  <TAB>  <TAB> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB> ""Given data-array is of unexpected type %s. Please pass numpy arrays instead."" <TAB>  <TAB>  <TAB>  <TAB> % type(array) <TAB>  <TAB>  <TAB> ) <TAB> return result",if array is None or scipy . sparse . issparse ( array ) :,131
"def description(self): <TAB> global role_descriptions <TAB> description = role_descriptions[self.role_field] <TAB> content_type = self.content_type <TAB> model_name = None <TAB> if content_type: <TAB>  <TAB> model = content_type.model_class() <TAB>  <TAB> model_name = re.sub(r""([a-z])([A-Z])"", r""\1 \2"", model.__name__).lower() <TAB> value = description <TAB> if type(description) == dict: <TAB>  <TAB> value = description.get(model_name) <MASK> value = description.get(""default"") <TAB> if ""%s"" in value and content_type: <TAB>  <TAB> value = value % model_name <TAB> return value",if value is None :,173
"def popupFrameXdiff(job, frame1, frame2, frame3=None): <TAB> """"""Opens a frame xdiff."""""" <TAB> for command in [""/usr/bin/xxdiff"", ""/usr/local/bin/xdiff""]: <MASK> for frame in [frame1, frame2, frame3]: <TAB>  <TAB>  <TAB>  <TAB> if frame: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> command += "" --title1 %s %s"" % ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> frame.data.name, <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> getFrameLogFile(job, frame), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> shellOut(command)",if os . path . isfile ( command ) :,154
"def _groups_args_split(self, kwargs): <TAB> groups_args_split = [] <TAB> groups = kwargs[""groups""] <TAB> for key, group in groups.iteritems(): <TAB>  <TAB> mykwargs = kwargs.copy() <TAB>  <TAB> del mykwargs[""groups""] <TAB>  <TAB> if ""group_name"" in group: <TAB>  <TAB>  <TAB> mykwargs[""source_security_group_name""] = group[""group_name""] <TAB>  <TAB> if ""user_id"" in group: <TAB>  <TAB>  <TAB> mykwargs[""source_security_group_owner_id""] = group[""user_id""] <MASK> mykwargs[""source_security_group_id""] = group[""group_id""] <TAB>  <TAB> groups_args_split.append(mykwargs) <TAB> return groups_args_split","if ""group_id"" in group :",186
"def _mangle_phone(phone, config): <TAB> regexp = config.get(""REGEXP"") <TAB> if regexp: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> m = re.match(""^/(.*)/(.*)/$"", regexp) <MASK> phone = re.sub(m.group(1), m.group(2), phone) <TAB>  <TAB> except re.error: <TAB>  <TAB>  <TAB> log.warning( <TAB>  <TAB>  <TAB>  <TAB> u""Can not mangle phone number. "" <TAB>  <TAB>  <TAB>  <TAB> u""Please check your REGEXP: {0!s}"".format(regexp) <TAB>  <TAB>  <TAB> ) <TAB> return phone",if m :,144
"def getScramRange(src): <TAB> scramRange = None <TAB> for mod in src.item.activeModulesIter(): <MASK> scramRange = max(scramRange or 0, mod.maxRange or 0) <TAB> return scramRange",if _isRegularScram ( mod ) or _isHicScram ( mod ) :,83
"def snapshot(self): <TAB> # if this volume is attached to a server <TAB> # we need to freeze the XFS file system <TAB> try: <TAB>  <TAB> self.freeze() <MASK> snapshot = self.get_ec2_connection().create_snapshot(self.volume_id) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> snapshot = self.server.ec2.create_snapshot(self.volume_id) <TAB>  <TAB> boto.log.info(""Snapshot of Volume %s created: %s"" % (self.name, snapshot)) <TAB> except Exception: <TAB>  <TAB> boto.log.info(""Snapshot error"") <TAB>  <TAB> boto.log.info(traceback.format_exc()) <TAB> finally: <TAB>  <TAB> status = self.unfreeze() <TAB>  <TAB> return status",if self . server == None :,181
"def closeststack(self, card): <TAB> closest = None <TAB> cdist = 999999999 <TAB> # Since we only compare distances, <TAB> # we don't bother to take the square root. <TAB> for stack in self.openstacks: <TAB>  <TAB> dist = (stack.x - card.x) ** 2 + (stack.y - card.y) ** 2 <MASK> closest = stack <TAB>  <TAB>  <TAB> cdist = dist <TAB> return closest",if dist < cdist :,106
"def _sock_send(self, msg): <TAB> try: <TAB>  <TAB> if isinstance(msg, str): <TAB>  <TAB>  <TAB> msg = msg.encode(""ascii"") <TAB>  <TAB> # http://docs.datadoghq.com/guides/dogstatsd/#datagram-format <TAB>  <TAB> if self.dogstatsd_tags: <TAB>  <TAB>  <TAB> msg = msg + b""|#"" + self.dogstatsd_tags.encode(""ascii"") <MASK> self.sock.send(msg) <TAB> except Exception: <TAB>  <TAB> Logger.warning(self, ""Error sending message to statsd"", exc_info=True)",if self . sock :,146
"def styleRow(self, row, selected): <TAB> if row > 0 and row < self.getRowCount(): <MASK> self.getRowFormatter().addStyleName(row, ""user-SelectedRow"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.getRowFormatter().removeStyleName(row, ""user-SelectedRow"")",if selected :,81
"def __gather_epoch_end_eval_results(self, outputs): <TAB> eval_results = [] <TAB> for epoch_output in outputs: <TAB>  <TAB> result = epoch_output[0].__class__.gather(epoch_output) <TAB>  <TAB> if ""checkpoint_on"" in result: <TAB>  <TAB>  <TAB> result.checkpoint_on = result.checkpoint_on.mean() <MASK> result.early_stop_on = result.early_stop_on.mean() <TAB>  <TAB> eval_results.append(result) <TAB> # with 1 dataloader don't pass in a list <TAB> if len(eval_results) == 1: <TAB>  <TAB> eval_results = eval_results[0] <TAB> return eval_results","if ""early_stop_on"" in result :",172
"def network_state(self, device): <TAB> cmd = [""tc"", ""qdisc"", ""show"", ""dev"", device] <TAB> try: <TAB>  <TAB> output = self.host_exec.run(cmd) <TAB>  <TAB> # sloppy but good enough for now <TAB>  <TAB> if "" delay "" in output: <TAB>  <TAB>  <TAB> return NetworkState.SLOW <TAB>  <TAB> if "" loss "" in output: <TAB>  <TAB>  <TAB> return NetworkState.FLAKY <MASK> return NetworkState.DUPLICATE <TAB>  <TAB> return NetworkState.NORMAL <TAB> except Exception: <TAB>  <TAB> return NetworkState.UNKNOWN","if "" duplicate "" in output :",138
"def canberra_grad(x, y): <TAB> result = 0.0 <TAB> grad = np.zeros(x.shape) <TAB> for i in range(x.shape[0]): <TAB>  <TAB> denominator = np.abs(x[i]) + np.abs(y[i]) <MASK> result += np.abs(x[i] - y[i]) / denominator <TAB>  <TAB>  <TAB> grad[i] = ( <TAB>  <TAB>  <TAB>  <TAB> np.sign(x[i] - y[i]) / denominator <TAB>  <TAB>  <TAB>  <TAB> - np.abs(x[i] - y[i]) * np.sign(x[i]) / denominator ** 2 <TAB>  <TAB>  <TAB> ) <TAB> return result, grad",if denominator > 0 :,167
"def readwrite(obj, flags): <TAB> try: <TAB>  <TAB> if flags & select.POLLIN: <TAB>  <TAB>  <TAB> obj.handle_read_event() <MASK> obj.handle_write_event() <TAB>  <TAB> if flags & select.POLLPRI: <TAB>  <TAB>  <TAB> obj.handle_expt_event() <TAB>  <TAB> if flags & (select.POLLHUP | select.POLLERR | select.POLLNVAL): <TAB>  <TAB>  <TAB> obj.handle_close() <TAB> except OSError as e: <TAB>  <TAB> if e.args[0] not in _DISCONNECTED: <TAB>  <TAB>  <TAB> obj.handle_error() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> obj.handle_close() <TAB> except _reraised_exceptions: <TAB>  <TAB> raise <TAB> except: <TAB>  <TAB> obj.handle_error()",if flags & select . POLLOUT :,192
"def get_func_name(obj): <TAB> if inspect.ismethod(obj): <TAB>  <TAB> match = RE_BOUND_METHOD.match(repr(obj)) <MASK> cls = match.group(""class"") <TAB>  <TAB>  <TAB> if not cls: <TAB>  <TAB>  <TAB>  <TAB> return match.group(""name"") <TAB>  <TAB>  <TAB> return ""%s.%s"" % (match.group(""class""), match.group(""name"")) <TAB> return None",if match :,102
"def __init__(self, connection): <TAB> self.username = connection.username <TAB> self.password = connection.password <TAB> self.domain = connection.domain <TAB> self.hash = connection.hash <TAB> self.lmhash = """" <TAB> self.nthash = """" <TAB> self.aesKey = connection.aesKey <TAB> self.kdcHost = connection.kdcHost <TAB> self.kerberos = connection.kerberos <TAB> if self.hash is not None: <MASK> self.lmhash, self.nthash = self.hash.split("":"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.nthash = self.hash <TAB> if self.password is None: <TAB>  <TAB> self.password = """"","if self . hash . find ( "":"" ) != - 1 :",174
"def indent_xml(elem, level=0): <TAB> """"""Do our pretty printing and make Matt very happy."""""" <TAB> i = ""\n"" + level * ""  "" <TAB> if elem: <TAB>  <TAB> if not elem.text or not elem.text.strip(): <TAB>  <TAB>  <TAB> elem.text = i + ""  "" <TAB>  <TAB> if not elem.tail or not elem.tail.strip(): <TAB>  <TAB>  <TAB> elem.tail = i <TAB>  <TAB> for elem in elem: <TAB>  <TAB>  <TAB> indent_xml(elem, level + 1) <TAB>  <TAB> if not elem.tail or not elem.tail.strip(): <TAB>  <TAB>  <TAB> elem.tail = i <TAB> else: <MASK> elem.tail = i",if level and ( not elem . tail or not elem . tail . strip ( ) ) :,177
"def add_braces_and_labels(self): <TAB> for attr in ""horizontal_parts"", ""vertical_parts"": <MASK> continue <TAB>  <TAB> parts = getattr(self, attr) <TAB>  <TAB> for subattr in ""braces"", ""labels"": <TAB>  <TAB>  <TAB> if hasattr(parts, subattr): <TAB>  <TAB>  <TAB>  <TAB> self.add(getattr(parts, subattr))","if not hasattr ( self , attr ) :",97
"def error_messages(file_list, files_removed): <TAB> if files_removed is None: <TAB>  <TAB> return <TAB> for remove_this, reason in files_removed: <TAB>  <TAB> if file_list is not None: <TAB>  <TAB>  <TAB> file_list.remove(remove_this) <MASK> print("" REMOVED : ("" + str(remove_this) + "")   is not PNG file format"") <TAB>  <TAB> elif reason == 1: <TAB>  <TAB>  <TAB> print("" REMOVED : ("" + str(remove_this) + "")   already exists"") <TAB>  <TAB> elif reason == 2: <TAB>  <TAB>  <TAB> print("" REMOVED : ("" + str(remove_this) + "")   file unreadable"")",if reason == 0 :,161
"def keep_vocab_item(word, count, min_count, trim_rule=None): <TAB> default_res = count >= min_count <TAB> if trim_rule is None: <TAB>  <TAB> return default_res <TAB> else: <TAB>  <TAB> rule_res = trim_rule(word, count, min_count) <TAB>  <TAB> if rule_res == RULE_KEEP: <TAB>  <TAB>  <TAB> return True <MASK> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return default_res",elif rule_res == RULE_DISCARD :,125
"def func(x0): <TAB> bind = 0 <TAB> backups = [] <TAB> vinputs = [] <TAB> for i, i0 in zip(inputs, inputs0): <TAB>  <TAB> if i is None:  # Optional argument <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> vinputs += [i] <MASK> # Not need backward <TAB>  <TAB>  <TAB> i.d[...] = x0[bind : bind + i.size].reshape(i.shape) <TAB>  <TAB>  <TAB> bind += i.size <TAB>  <TAB> backups.append(i.d.copy()) <TAB> f.forward(vinputs, outputs) <TAB> for ind, i in enumerate(inputs): <TAB>  <TAB> if i is None:  # Optional argument <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> i.d[...] = backups[ind] <TAB> return sum([np.sum(o.g * o.d) for o in outputs])",if i0 is not None :,200
"def _handle_js_events(self, change): <TAB> if self.js_events: <TAB>  <TAB> if self.event_handlers: <TAB>  <TAB>  <TAB> for event in self.js_events: <TAB>  <TAB>  <TAB>  <TAB> event_name = event[""name""] <MASK> self.event_handlers[event_name](event[""detail""]) <TAB>  <TAB> # clears the event queue. <TAB>  <TAB> self.js_events = []",if event_name in self . event_handlers :,113
"def validate(leaves): <TAB> for leaf in leaves: <MASK> pass <TAB>  <TAB> elif leaf.has_form(""List"", None) or leaf.has_form(""Association"", None): <TAB>  <TAB>  <TAB> if validate(leaf.leaves) is not True: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> return True","if leaf . has_form ( ( ""Rule"" , ""RuleDelayed"" ) , 2 ) :",97
"def ascii85decode(data): <TAB> n = b = 0 <TAB> out = """" <TAB> for c in data: <TAB>  <TAB> if ""!"" <= c and c <= ""u"": <TAB>  <TAB>  <TAB> n += 1 <TAB>  <TAB>  <TAB> b = b * 85 + (ord(c) - 33) <TAB>  <TAB>  <TAB> if n == 5: <TAB>  <TAB>  <TAB>  <TAB> out += struct.pack("">L"", b) <TAB>  <TAB>  <TAB>  <TAB> n = b = 0 <TAB>  <TAB> elif c == ""z"": <TAB>  <TAB>  <TAB> assert n == 0 <TAB>  <TAB>  <TAB> out += ""\0\0\0\0"" <TAB>  <TAB> elif c == ""~"": <MASK> for _ in range(5 - n): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> b = b * 85 + 84 <TAB>  <TAB>  <TAB>  <TAB> out += struct.pack("">L"", b)[: n - 1] <TAB>  <TAB>  <TAB> break <TAB> return out",if n :,200
"def to_text(self, origin=None, relativize=True, **kw): <TAB> next = self.next.choose_relativity(origin, relativize) <TAB> text = """" <TAB> for (window, bitmap) in self.windows: <TAB>  <TAB> bits = [] <TAB>  <TAB> for i in xrange(0, len(bitmap)): <TAB>  <TAB>  <TAB> byte = bitmap[i] <TAB>  <TAB>  <TAB> for j in xrange(0, 8): <MASK> bits.append(dns.rdatatype.to_text(window * 256 + i * 8 + j)) <TAB>  <TAB> text += "" "" + "" "".join(bits) <TAB> return ""%s%s"" % (next, text)",if byte & ( 0x80 >> j ) :,177
"def _on_response(self, widget, response): <TAB> value = None <TAB> if response == Gtk.ResponseType.OK: <MASK> value = self.spinbutton.get_value_as_int() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = self.spinbutton.get_value() <TAB> self.deferred.callback(value) <TAB> self.destroy()",if self . value_type is int :,96
"def send_preamble(self): <TAB> """"""Transmit version/status/date/server, via self._write()"""""" <TAB> if self.origin_server: <MASK> self._write(""HTTP/%s %s\r\n"" % (self.http_version, self.status)) <TAB>  <TAB>  <TAB> if not self.headers.has_key(""Date""): <TAB>  <TAB>  <TAB>  <TAB> self._write(""Date: %s\r\n"" % time.asctime(time.gmtime(time.time()))) <TAB>  <TAB>  <TAB> if self.server_software and not self.headers.has_key(""Server""): <TAB>  <TAB>  <TAB>  <TAB> self._write(""Server: %s\r\n"" % self.server_software) <TAB> else: <TAB>  <TAB> self._write(""Status: %s\r\n"" % self.status)",if self . client_is_modern ( ) :,199
"def _save_postinsts_common(self, dst_postinst_dir, src_postinst_dir): <TAB> num = 0 <TAB> for p in self._get_delayed_postinsts(): <TAB>  <TAB> bb.utils.mkdirhier(dst_postinst_dir) <MASK> shutil.copy( <TAB>  <TAB>  <TAB>  <TAB> os.path.join(src_postinst_dir, p + "".postinst""), <TAB>  <TAB>  <TAB>  <TAB> os.path.join(dst_postinst_dir, ""%03d-%s"" % (num, p)), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> num += 1","if os . path . exists ( os . path . join ( src_postinst_dir , p + "".postinst"" ) ) :",165
"def edge_data_from_bmesh_edges(bm, edge_data): <TAB> initial_index = bm.edges.layers.int.get(""initial_index"") <TAB> if initial_index is None: <TAB>  <TAB> raise Exception(""bmesh has no initial_index layer"") <TAB> edge_data_out = [] <TAB> n_edge_data = len(edge_data) <TAB> for edge in bm.edges: <TAB>  <TAB> idx = edge[initial_index] <MASK> debug(""Unexisting edge_data[%s] [0 - %s]"", idx, n_edge_data) <TAB>  <TAB>  <TAB> edge_data_out.append(None) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> edge_data_out.append(edge_data[idx]) <TAB> return edge_data_out",if idx < 0 or idx >= n_edge_data :,198
"def write(self, data): <TAB> try: <TAB>  <TAB> c_written = DWORD() <TAB>  <TAB> buffer = create_string_buffer(data) <MASK> raise WinError() <TAB> except: <TAB>  <TAB> self.close()","if not WriteFile ( self . pStdin , buffer , len ( buffer ) , byref ( c_written ) , None ) :",82
"def get_icon(svg_path, size): <TAB> pixbuf = GdkPixbuf.Pixbuf.new_from_file_at_scale(svg_path, size, size, True) <TAB> data = bytearray(pixbuf.get_pixels()) <TAB> channels = pixbuf.get_n_channels() <TAB> assert channels == 4 <TAB> # https://en.wikipedia.org/wiki/PackBits <TAB> # no real compression going on here.. <TAB> new_data = bytearray() <TAB> for c in range(3): <TAB>  <TAB> x = 0 <TAB>  <TAB> for i in range(0, len(data), 4): <MASK> new_data.append(127) <TAB>  <TAB>  <TAB> new_data.append(data[i + c]) <TAB>  <TAB>  <TAB> x += 1 <TAB> return new_data",if x == 0 or x % 128 == 0 :,194
"def _get_instance_attribute( <TAB> self, attr, default=None, defaults=None, incl_metadata=False): <TAB> if self.instance is None or not hasattr(self.instance, attr): <TAB>  <TAB> if incl_metadata and attr in self.parsed_metadata: <TAB>  <TAB>  <TAB> return self.parsed_metadata[attr] <TAB>  <TAB> elif defaults is not None: <TAB>  <TAB>  <TAB> for value in defaults: <TAB>  <TAB>  <TAB>  <TAB> if callable(value): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value = value() <MASK> return value <TAB>  <TAB> return default <TAB> return getattr(self.instance, attr)",if value is not None :,149
"def forward(self, x): <TAB> if self.ffn_type in (1, 2): <TAB>  <TAB> x0 = self.wx0(x) <MASK> x1 = x <TAB>  <TAB> elif self.ffn_type == 2: <TAB>  <TAB>  <TAB> x1 = self.wx1(x) <TAB>  <TAB> out = self.output(x0 * x1) <TAB> out = self.dropout(out) <TAB> out = self.LayerNorm(out + x) <TAB> return out",if self . ffn_type == 1 :,122
"def load(cls): <TAB> if not cls._loaded: <TAB>  <TAB> cls.log.debug(""Loading tile_sets..."") <MASK> cls._find_tile_sets(PATHS.TILE_SETS_DIRECTORY) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> cls.tile_sets = JsonDecoder.load(PATHS.TILE_SETS_JSON_FILE) <TAB>  <TAB> cls.log.debug(""Done!"") <TAB>  <TAB> cls._loaded = True",if not horizons . globals . fife . use_atlases :,120
"def headerData(self, section, orientation, role=Qt.DisplayRole): <TAB> if role == Qt.TextAlignmentRole: <TAB>  <TAB> if orientation == Qt.Horizontal: <TAB>  <TAB>  <TAB> return to_qvariant(int(Qt.AlignHCenter | Qt.AlignVCenter)) <TAB>  <TAB> return to_qvariant(int(Qt.AlignRight | Qt.AlignVCenter)) <TAB> if role != Qt.DisplayRole: <TAB>  <TAB> return to_qvariant() <TAB> if orientation == Qt.Horizontal: <TAB>  <TAB> if section == NAME: <TAB>  <TAB>  <TAB> return to_qvariant(""Name"") <MASK> return to_qvariant(""Version"") <TAB>  <TAB> elif section == ACTION: <TAB>  <TAB>  <TAB> return to_qvariant(""Action"") <TAB>  <TAB> elif section == DESCRIPTION: <TAB>  <TAB>  <TAB> return to_qvariant(""Description"") <TAB> return to_qvariant()",elif section == VERSION :,192
"def find_enabled_item(self, e): <TAB> x, y = e.local <TAB> if ( <TAB>  <TAB> 0 <TAB>  <TAB> <= x <TAB>  <TAB> < ( <TAB>  <TAB>  <TAB> self.width - self.margin - self.scroll_button_size <TAB>  <TAB>  <TAB> if self.scrolling <TAB>  <TAB>  <TAB> else self.width <TAB>  <TAB> ) <TAB> ): <TAB>  <TAB> h = self.font.get_linesize() <TAB>  <TAB> i = (y - h // 2) // h + self.scroll <TAB>  <TAB> items = self._items <TAB>  <TAB> if 0 <= i < len(items): <TAB>  <TAB>  <TAB> item = items[i] <MASK> return item",if item . enabled :,160
"def set_parallel_limit(environment): <TAB> parallel_limit = environment.get(""COMPOSE_PARALLEL_LIMIT"") <TAB> if parallel_limit: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> parallel_limit = int(parallel_limit) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> raise errors.UserError( <TAB>  <TAB>  <TAB>  <TAB> 'COMPOSE_PARALLEL_LIMIT must be an integer (found: ""{}"")'.format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> environment.get(""COMPOSE_PARALLEL_LIMIT"") <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <MASK> raise errors.UserError(""COMPOSE_PARALLEL_LIMIT can not be less than 2"") <TAB>  <TAB> parallel.GlobalLimit.set_global_limit(parallel_limit)",if parallel_limit <= 1 :,178
"def migrate_identifier(self, raw_identifier: int): <TAB> if self.unique_cog_identifier in self.data: <TAB>  <TAB> # Data has already been migrated <TAB>  <TAB> return <TAB> poss_identifiers = [str(raw_identifier), str(hash(raw_identifier))] <TAB> for ident in poss_identifiers: <MASK> self.data[self.unique_cog_identifier] = self.data[ident] <TAB>  <TAB>  <TAB> del self.data[ident] <TAB>  <TAB>  <TAB> _save_json(self.data_path, self.data) <TAB>  <TAB>  <TAB> break",if ident in self . data :,140
"def _memoize(*args, **kwargs): <TAB> str_args = [] <TAB> for arg in args: <MASK> str_args.append(six.text_type(arg)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> str_args.append(arg) <TAB> args_ = "","".join( <TAB>  <TAB> list(str_args) + [""{0}={1}"".format(k, kwargs[k]) for k in sorted(kwargs)] <TAB> ) <TAB> if args_ not in cache: <TAB>  <TAB> cache[args_] = func(*args, **kwargs) <TAB> return cache[args_]","if not isinstance ( arg , six . string_types ) :",146
"def extract(self): <TAB> for battery in self.vars: <TAB>  <TAB> for line in dopen(""/proc/acpi/battery/"" + battery + ""/state"").readlines(): <TAB>  <TAB>  <TAB> l = line.split() <MASK> continue <TAB>  <TAB>  <TAB> if l[0:2] == [""remaining"", ""capacity:""]: <TAB>  <TAB>  <TAB>  <TAB> remaining = int(l[2]) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> elif l[0:2] == [""present"", ""rate:""]: <TAB>  <TAB>  <TAB>  <TAB> rate = int(l[2]) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if rate and remaining: <TAB>  <TAB>  <TAB> self.val[battery] = remaining * 60 / rate <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.val[battery] = -1",if len ( l ) < 3 :,185
"def version_iter(q, limit=500, offset=0): <TAB> q[""limit""] = limit <TAB> q[""offset""] = offset <TAB> while True: <TAB>  <TAB> url = base_url() + ""/version"" <TAB>  <TAB> v = jsonload(url) <MASK> return <TAB>  <TAB> for i in query(q): <TAB>  <TAB>  <TAB> yield i <TAB>  <TAB> q[""offset""] += limit",if not v :,97
"def _letf_btn_press(self, event): <TAB> try: <TAB>  <TAB> elem = self.identify(event.x, event.y) <TAB>  <TAB> index = self.index(""@%d,%d"" % (event.x, event.y)) <MASK> self.state([""pressed""]) <TAB>  <TAB>  <TAB> self.pressed_index = index <TAB> except Exception: <TAB>  <TAB> # may fail, if clicked outside of tab <TAB>  <TAB> return","if ""closebutton"" in elem :",112
"def get_location(self, dist, dependency_links): <TAB> for url in dependency_links: <TAB>  <TAB> egg_fragment = Link(url).egg_fragment <TAB>  <TAB> if not egg_fragment: <TAB>  <TAB>  <TAB> continue <MASK> ## FIXME: will this work when a package has - in the name? <TAB>  <TAB>  <TAB> key = ""-"".join(egg_fragment.split(""-"")[:-1]).lower() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> key = egg_fragment <TAB>  <TAB> if key == dist.key: <TAB>  <TAB>  <TAB> return url.split(""#"", 1)[0] <TAB> return None","if ""-"" in egg_fragment :",141
"def viewTreeItemClicked(self, event): <TAB> if DEBUG: <TAB>  <TAB> print(""viewTreeitemClicked:"", event.__dict__, file=sys.stderr) <TAB> self.unmarkTargets() <TAB> vuid = self.viewTree.viewTree.identify_row(event.y) <TAB> if vuid: <TAB>  <TAB> view = self.vc.viewsById[vuid] <MASK> coords = view.getCoords() <TAB>  <TAB>  <TAB> if view.isTarget(): <TAB>  <TAB>  <TAB>  <TAB> self.markTarget(coords[0][0], coords[0][1], coords[1][0], coords[1][1]) <TAB>  <TAB>  <TAB> self.viewDetails.set(view)",if view :,162
"def getVar(self, name): <TAB> value = self.tinfoil.run_command(""dataStoreConnectorFindVar"", self.dsindex, name) <TAB> overrides = None <TAB> if isinstance(value, dict): <TAB>  <TAB> if ""_connector_origtype"" in value: <TAB>  <TAB>  <TAB> value[""_content""] = self.tinfoil._reconvert_type( <TAB>  <TAB>  <TAB>  <TAB> value[""_content""], value[""_connector_origtype""] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> del value[""_connector_origtype""] <MASK> overrides = value[""_connector_overrides""] <TAB>  <TAB>  <TAB> del value[""_connector_overrides""] <TAB> return value, overrides","if ""_connector_overrides"" in value :",158
"def sample(self, **config): <TAB> """"""Sample a configuration from this search space."""""" <TAB> ret = [] <TAB> kwspaces = self.kwspaces <TAB> striped_keys = [k.split(SPLITTER)[0] for k in config.keys()] <TAB> for idx, obj in enumerate(self.data): <TAB>  <TAB> if isinstance(obj, NestedSpace): <TAB>  <TAB>  <TAB> sub_config = _strip_config_space(config, prefix=str(idx)) <TAB>  <TAB>  <TAB> ret.append(obj.sample(**sub_config)) <MASK> ret.append(config[str(idx)]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret.append(obj) <TAB> return ret","elif isinstance ( obj , SimpleSpace ) :",165
"def main(): <TAB> for filename in sys.argv[1:]: <MASK> print(filename, ""Directory!"") <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> with open(filename, ""rb"") as f: <TAB>  <TAB>  <TAB> data = f.read() <TAB>  <TAB> if b""\0"" in data: <TAB>  <TAB>  <TAB> print(filename, ""Binary!"") <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> newdata = data.replace(b""\r\n"", b""\n"") <TAB>  <TAB> if newdata != data: <TAB>  <TAB>  <TAB> print(filename) <TAB>  <TAB>  <TAB> with open(filename, ""wb"") as f: <TAB>  <TAB>  <TAB>  <TAB> f.write(newdata)",if os . path . isdir ( filename ) :,157
"def normalize_crlf(tree): <TAB> for elem in tree.getiterator(): <TAB>  <TAB> if elem.text: <TAB>  <TAB>  <TAB> elem.text = elem.text.replace(""\r\n"", ""\n"") <MASK> elem.tail = elem.tail.replace(""\r\n"", ""\n"")",if elem . tail :,76
"def RegisterValue(self, value): <TAB> """"""Puts a given value into an appropriate bin."""""" <TAB> if self.bins: <TAB>  <TAB> for b in self.bins: <MASK> b.num += 1 <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> self.bins[-1].num += 1",if b . range_max_value > value :,82
"def all_commands(): <TAB> all_cmds = [] <TAB> for bp in BINPATHS: <TAB>  <TAB> cmds = [ <TAB>  <TAB>  <TAB> fn[:-3] <TAB>  <TAB>  <TAB> for fn in os.listdir(bp) <MASK> and not fn.startswith(""."") <TAB>  <TAB>  <TAB> and os.path.isfile(os.path.join(bp, fn)) <TAB>  <TAB> ] <TAB>  <TAB> all_cmds += cmds <TAB> all_cmds.sort() <TAB> return all_cmds","if fn . endswith ( "".py"" )",116
"def base64_encode_image_mapper(self, tag, url): <TAB> if tag == ""img"": <TAB>  <TAB> if url in self.kp_images: <TAB>  <TAB>  <TAB> image_data = base64.b64encode(self.kp_images[url]) <TAB>  <TAB>  <TAB> image_mimetype = mimetypes.guess_type(url)[0] <MASK> return ""data:{};base64, "".format(image_mimetype) + image_data.decode( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""utf-8"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return None",if image_mimetype is not None :,138
"def validate_input(self): <TAB> if self.validation_fn: <TAB>  <TAB> success, err = self.validation_fn(self.str) <MASK> spaces = "" "" * self.textwin_width <TAB>  <TAB>  <TAB> self.textwin.addstr(self.y + 2, 0, spaces) <TAB>  <TAB>  <TAB> self.textwin.addstr(self.y + 2, 0, err, curses.color_pair(4)) <TAB>  <TAB> return success <TAB> else: <TAB>  <TAB> return True",if not success :,120
"def start_prompt(self): <TAB> """"""Start the interpreter."""""" <TAB> logger.show(""Coconut Interpreter:"") <TAB> logger.show(""(type 'exit()' or press Ctrl-D to end)"") <TAB> self.start_running() <TAB> while self.running: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> code = self.get_input() <TAB>  <TAB>  <TAB> if code: <TAB>  <TAB>  <TAB>  <TAB> compiled = self.handle_input(code) <MASK> self.execute(compiled, use_eval=None) <TAB>  <TAB> except KeyboardInterrupt: <TAB>  <TAB>  <TAB> printerr(""\nKeyboardInterrupt"")",if compiled :,142
"def __exit__(self, exc_type, exc_val, exc_tb): <TAB> if self.channel and self.channel.connection: <TAB>  <TAB> conn_errors = self.channel.connection.client.connection_errors <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> self.cancel() <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> pass","if not isinstance ( exc_val , conn_errors ) :",93
"def pack(data, size, endian): <TAB> buf = [] <TAB> for i in data: <TAB>  <TAB> num = int(i) <MASK> num += 1 << (size * 8) <TAB>  <TAB> d = [b""\x00""] * size <TAB>  <TAB> i = size - 1 <TAB>  <TAB> while i >= 0: <TAB>  <TAB>  <TAB> b = num & 255 <TAB>  <TAB>  <TAB> d[i] = bytes((b,)) if PY3 else chr(b) <TAB>  <TAB>  <TAB> num >>= 8 <TAB>  <TAB>  <TAB> i -= 1 <TAB>  <TAB> if endian == ""<"": <TAB>  <TAB>  <TAB> d = b"""".join(d[i : i + 1][0] for i in reversed(xrange(len(d)))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> d = b"""".join(d) <TAB>  <TAB> buf.append(d) <TAB> return b"""".join(buf)",if num < 0 :,198
"def _sample_new_noise_and_add(self, *, tf_sess=None, override=False): <TAB> if self.framework == ""tf"": <MASK> tf_sess.run(self.tf_remove_noise_op) <TAB>  <TAB> tf_sess.run(self.tf_sample_new_noise_and_add_op) <TAB> else: <TAB>  <TAB> if override and self.weights_are_currently_noisy: <TAB>  <TAB>  <TAB> self._remove_noise() <TAB>  <TAB> self._sample_new_noise() <TAB>  <TAB> self._add_stored_noise() <TAB> self.weights_are_currently_noisy = True",if override and self . weights_are_currently_noisy :,162
"def hdfs_link_js(url): <TAB> link = ""javascript:void(0)"" <TAB> if url: <TAB>  <TAB> path = Hdfs.urlsplit(url)[2] <TAB>  <TAB> if path: <TAB>  <TAB>  <TAB> link = ( <TAB>  <TAB>  <TAB>  <TAB> ""/filebrowser/view=%s"" <MASK> else ""/filebrowser/home_relative_view=/%s"" <TAB>  <TAB>  <TAB> ) % path <TAB> return link",if path . startswith ( posixpath . sep ),111
"def set_xticklabels(self, labels=None, step=None, **kwargs): <TAB> """"""Set x axis tick labels on the bottom row of the grid."""""" <TAB> for ax in self.axes[-1, :]: <TAB>  <TAB> if labels is None: <TAB>  <TAB>  <TAB> labels = [l.get_text() for l in ax.get_xticklabels()] <MASK> xticks = ax.get_xticks()[::step] <TAB>  <TAB>  <TAB>  <TAB> labels = labels[::step] <TAB>  <TAB>  <TAB>  <TAB> ax.set_xticks(xticks) <TAB>  <TAB> ax.set_xticklabels(labels, **kwargs) <TAB> return self",if step is not None :,145
"def _get_statement_from_file(user, fs, snippet): <TAB> script_path = snippet[""statementPath""] <TAB> if script_path: <TAB>  <TAB> script_path = script_path.replace(""hdfs://"", """") <MASK> return fs.do_as_user(user, fs.read, script_path, 0, 16 * 1024 ** 2)","if fs . do_as_user ( user , fs . isfile , script_path ) :",104
def doWorkUnit(self): <TAB> if len(self.workers): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> w = self.workers.popleft() <TAB>  <TAB>  <TAB> w.next() <TAB>  <TAB>  <TAB> self.workers.append(w) <TAB>  <TAB> except StopIteration: <MASK> self.invalidate() <TAB> else: <TAB>  <TAB> time.sleep(0.001),"if hasattr ( w , ""needsRedraw"" ) and w . needsRedraw :",105
"def _find_l1_phash_mul(cdict): <TAB> candidate_lengths = _find_candidate_lengths_mul(cdict.tuple2int) <TAB> for p in candidate_lengths: <TAB>  <TAB> hash_f = hashmul.hashmul_t(p) <MASK> return l1_phash_t(cdict, hash_f) <TAB>  <TAB> del hash_f <TAB> return None",if hash_f . is_perfect ( iter ( cdict . tuple2int . values ( ) ) ) :,118
"def _find_next_tab_stop(self, direction): <TAB> old_focus = self._focus <TAB> self._focus += direction <TAB> while self._focus != old_focus: <TAB>  <TAB> if self._focus < 0: <TAB>  <TAB>  <TAB> self._focus = len(self._layouts) - 1 <TAB>  <TAB> if self._focus >= len(self._layouts): <TAB>  <TAB>  <TAB> self._focus = 0 <TAB>  <TAB> try: <MASK> self._layouts[self._focus].focus(force_first=True) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._layouts[self._focus].focus(force_last=True) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB> self._focus += direction",if direction > 0 :,177
"def _get_py_flags(self): <TAB> res = dict(self.flags) <TAB> cflags = res.pop(""cflags"", """") <TAB> for fl in cflags.split(""|""): <TAB>  <TAB> fl = fl.strip() <TAB>  <TAB> if fl == ""GA_USE_DOUBLE"": <TAB>  <TAB>  <TAB> res[""have_double""] = True <MASK> res[""have_small""] = True <TAB>  <TAB> if fl == ""GA_USE_COMPLEX"": <TAB>  <TAB>  <TAB> res[""have_complex""] = True <TAB>  <TAB> if fl == ""GA_USE_HALF"": <TAB>  <TAB>  <TAB> res[""have_half""] = True <TAB> return res","if fl == ""GA_USE_SMALL"" :",160
"def _install_provision_configs(self): <TAB> config = self._config.plugins[self.full_name] <TAB> files = config.get(""provision_config_files"", []) <TAB> if files: <MASK> log.critical(""Error installing provisioning configs"") <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.debug(""Provision config files successfully installed"") <TAB>  <TAB>  <TAB> return True <TAB> else: <TAB>  <TAB> log.debug(""No provision config files configured"") <TAB>  <TAB> return True","if not install_provision_configs ( files , self . _mountpoint ) :",132
"def postfile(self): <TAB> for clientip, serverips in self.client_conns.items(): <TAB>  <TAB> target_count = len(serverips) <TAB>  <TAB> S = min((len(self.server_conns[serverip]) for serverip in serverips)) <MASK> continue <TAB>  <TAB> # TODO implement whitelist <TAB>  <TAB> self.write( <TAB>  <TAB>  <TAB> ""Scanning IP: {} / S score: {:.1f} / Number of records: {}"".format( <TAB>  <TAB>  <TAB>  <TAB> clientip, S, target_count <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> )",if S > 2 or target_count < 5 :,144
"def update_defaults(self, *values, **kwargs): <TAB> for value in values: <MASK> self.DEFAULT_CONFIGURATION.update(value) <TAB>  <TAB> elif isinstance(value, types.ModuleType): <TAB>  <TAB>  <TAB> self.__defaults_from_module(value) <TAB>  <TAB> elif isinstance(value, str): <TAB>  <TAB>  <TAB> if os.path.exists(value): <TAB>  <TAB>  <TAB>  <TAB> self.__defaults_from_file(value) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> logger.warning(""Configuration file {} does not exist."".format(value)) <TAB>  <TAB> elif isinstance(value, type(None)): <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""Cannot interpret {}"".format(value)) <TAB> self.DEFAULT_CONFIGURATION.update(kwargs)",if type ( value ) == dict :,184
"def __init__(self, aList): <TAB> for element in aList: <MASK> if element.tag == element[0].tag: <TAB>  <TAB>  <TAB>  <TAB> self.append(ListParser(element)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.append(DictParser(element)) <TAB>  <TAB> elif element.text: <TAB>  <TAB>  <TAB> text = element.text.strip() <TAB>  <TAB>  <TAB> if text: <TAB>  <TAB>  <TAB>  <TAB> self.append(text)",if len ( element ) > 0 :,116
"def _get_py_flags(self): <TAB> res = dict(self.flags) <TAB> cflags = res.pop(""cflags"", """") <TAB> for fl in cflags.split(""|""): <TAB>  <TAB> fl = fl.strip() <MASK> res[""have_double""] = True <TAB>  <TAB> if fl == ""GA_USE_SMALL"": <TAB>  <TAB>  <TAB> res[""have_small""] = True <TAB>  <TAB> if fl == ""GA_USE_COMPLEX"": <TAB>  <TAB>  <TAB> res[""have_complex""] = True <TAB>  <TAB> if fl == ""GA_USE_HALF"": <TAB>  <TAB>  <TAB> res[""have_half""] = True <TAB> return res","if fl == ""GA_USE_DOUBLE"" :",160
"def consume_bytes(data): <TAB> state_machine.receive_data(data) <TAB> while True: <TAB>  <TAB> event = state_machine.next_event() <MASK> break <TAB>  <TAB> elif isinstance(event, h11.InformationalResponse): <TAB>  <TAB>  <TAB> # Ignore 1xx responses <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif isinstance(event, h11.Response): <TAB>  <TAB>  <TAB> # We have our response! Save it and get out of here. <TAB>  <TAB>  <TAB> context[""h11_response""] = event <TAB>  <TAB>  <TAB> raise LoopAbort <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Can't happen <TAB>  <TAB>  <TAB> raise RuntimeError(""Unexpected h11 event {}"".format(event))",if event is h11 . NEED_DATA :,166
"def status_string(self): <TAB> if not self.live: <TAB>  <TAB> if self.expired: <TAB>  <TAB>  <TAB> return _(""expired"") <TAB>  <TAB> elif self.approved_schedule: <TAB>  <TAB>  <TAB> return _(""scheduled"") <TAB>  <TAB> elif self.workflow_in_progress: <TAB>  <TAB>  <TAB> return _(""in moderation"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return _(""draft"") <TAB> else: <TAB>  <TAB> if self.approved_schedule: <TAB>  <TAB>  <TAB> return _(""live + scheduled"") <TAB>  <TAB> elif self.workflow_in_progress: <TAB>  <TAB>  <TAB> return _(""live + in moderation"") <MASK> return _(""live + draft"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return _(""live"")",elif self . has_unpublished_changes :,166
"def _update_input_entries(entries): <TAB> for entry in entries: <TAB>  <TAB> comma = entry.get(""comma_separated"", False) <MASK> entry[""regex""] = r""([^{}\[\]]*)\{"" + entry[""regex""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> entry[""regex""] = r""([^,{}\[\]]*)\{"" + entry[""regex""] <TAB>  <TAB> entry[""type""] = ""input""",if comma :,98
"def get_release(): <TAB> regexp = re.compile(r""^__version__\W*=\W*'([\d.abrc]+)'"") <TAB> here = os.path.dirname(__file__) <TAB> root = os.path.dirname(here) <TAB> init_py = os.path.join(root, ""aiomysql"", ""__init__.py"") <TAB> with open(init_py) as f: <TAB>  <TAB> for line in f: <TAB>  <TAB>  <TAB> match = regexp.match(line) <MASK> return match.group(1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise RuntimeError(""Cannot find version in aiomysql/__init__.py"")",if match is not None :,151
"def add_to_auto_transitions(cls, base): <TAB> result = {} <TAB> for name, method in base.__dict__.items(): <TAB>  <TAB> if callable(method) and hasattr(method, ""_django_fsm""): <TAB>  <TAB>  <TAB> for name, transition in method._django_fsm.transitions.items(): <MASK> result.update({name: method}) <TAB> return result","if transition . custom . get ( ""auto"" ) :",103
"def _paginate(self, get_page, page_size): <TAB> for page in itertools.count(start=1): <TAB>  <TAB> params = {""page"": page, ""per_page"": page_size} <TAB>  <TAB> response, items = get_page(params) <TAB>  <TAB> for item in items: <TAB>  <TAB>  <TAB> yield item <TAB>  <TAB> if self._is_last_page(response): <TAB>  <TAB>  <TAB> break <MASK> break",if len ( items ) < page_size :,111
"def forward(self, x): <TAB> bs = x.size(0) <TAB> cur = self.stem(x) <TAB> layers = [cur] <TAB> for layer_id in range(self.num_layers): <TAB>  <TAB> cur = self.layers[layer_id](layers) <TAB>  <TAB> layers.append(cur) <MASK> for i, layer in enumerate(layers): <TAB>  <TAB>  <TAB>  <TAB> layers[i] = self.pool_layers[self.pool_layers_idx.index(layer_id)]( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> layer <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> cur = layers[-1] <TAB> cur = self.gap(cur).view(bs, -1) <TAB> cur = self.dropout(cur) <TAB> logits = self.dense(cur) <TAB> return logits",if layer_id in self . pool_layers_idx :,198
"def evaluate(self, x, y, z): <TAB> vertex = Vector((x, y, z)) <TAB> nearest, normal, idx, distance = self.bvh.find_nearest(vertex) <TAB> if self.use_normal: <MASK> sign = (v - nearest).dot(normal) <TAB>  <TAB>  <TAB> sign = copysign(1, sign) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sign = 1 <TAB>  <TAB> return sign * np.array(normal) <TAB> else: <TAB>  <TAB> dv = np.array(nearest - vertex) <TAB>  <TAB> if self.falloff is not None: <TAB>  <TAB>  <TAB> norm = np.linalg.norm(dv) <TAB>  <TAB>  <TAB> len = self.falloff(norm) <TAB>  <TAB>  <TAB> dv = len * dv <TAB>  <TAB>  <TAB> return dv <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return dv",if self . signed_normal :,200
"def to_terminal(self): <TAB> """"""Yield lines to be printed to a terminal."""""" <TAB> for name, mi in self._sort(self.filtered_results): <MASK> yield name, (mi[""error""],), {""error"": True} <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> rank = mi[""rank""] <TAB>  <TAB> color = MI_RANKS[rank] <TAB>  <TAB> to_show = """" <TAB>  <TAB> if self.config.show: <TAB>  <TAB>  <TAB> to_show = "" ({0:.2f})"".format(mi[""mi""]) <TAB>  <TAB> yield ""{0} - {1}{2}{3}{4}"", (name, color, rank, to_show, RESET), {}","if ""error"" in mi :",163
"def _get_widget_by_name(self, container, name): <TAB> """"""Recursively search to return the named child widget."""""" <TAB> LOGGER.log() <TAB> children = container.get_children() <TAB> for child in children: <TAB>  <TAB> if child.name == name: <TAB>  <TAB>  <TAB> return child <TAB>  <TAB> if isinstance(child, gtk.Container): <TAB>  <TAB>  <TAB> found_child = self._get_widget_by_name(child, name) <MASK> return found_child",if found_child :,122
"def PyJsHoisted_hasComputed_(mutatorMap, this, arguments, var=var): <TAB> var = Scope( <TAB>  <TAB> {u""this"": this, u""arguments"": arguments, u""mutatorMap"": mutatorMap}, var <TAB> ) <TAB> var.registers([u""mutatorMap"", u""key""]) <TAB> for PyJsTemp in var.get(u""mutatorMap""): <TAB>  <TAB> var.put(u""key"", PyJsTemp) <MASK> return var.get(u""true"") <TAB> return Js(False)","if var . get ( u""mutatorMap"" ) . get ( var . get ( u""key"" ) ) . get ( u""_computed"" ) :",158
"def get_result_json_path(self): <TAB> if self._result_json_path is None: <MASK> self._result_json_path = get_unique_file( <TAB>  <TAB>  <TAB>  <TAB> self.path, <TAB>  <TAB>  <TAB>  <TAB> PARALLEL_RESULT_JSON_PREFIX, <TAB>  <TAB>  <TAB>  <TAB> PARALLEL_RESULT_JSON_SUFFIX, <TAB>  <TAB>  <TAB> ) <TAB> return self._result_json_path",if self . envconfig . config . option . resultjson :,113
"def timer(ratio, step, additive): <TAB> t = 0 <TAB> slowmode = False <TAB> while 1: <TAB>  <TAB> if additive: <TAB>  <TAB>  <TAB> slowmode |= bool((yield t)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> slowmode = bool((yield t)) <MASK> t += step * ratio <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> t += step",if slowmode :,89
"def _split_long_text(text, idx, size): <TAB> splited_text = text.split() <TAB> if len(splited_text) > 25: <TAB>  <TAB> if idx == 0: <TAB>  <TAB>  <TAB> # The first is (...)text <TAB>  <TAB>  <TAB> first = """" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> first = "" "".join(splited_text[:10]) <MASK> # The last is text(...) <TAB>  <TAB>  <TAB> last = """" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> last = "" "".join(splited_text[-10:]) <TAB>  <TAB> return ""{}(...){}"".format(first, last) <TAB> return text",if idx != 0 and idx == size - 1 :,156
"def test_tag_priority(self): <TAB> for tag in _low_priority_D_TAG: <TAB>  <TAB> val = ENUM_D_TAG[tag] <TAB>  <TAB> # if the low priority tag is present in the descriptions, <TAB>  <TAB> # assert that it has not overridden any other tag <MASK> for tag2 in ENUM_D_TAG: <TAB>  <TAB>  <TAB>  <TAB> if tag2 == tag: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB>  <TAB> self.assertNotEqual(ENUM_D_TAG[tag2], val)",if _DESCR_D_TAG [ val ] == tag :,135
"def _concretize(self, n_cls, t1, t2, join_or_meet, translate): <TAB> ptr_class = self._pointer_class() <TAB> if n_cls is ptr_class: <MASK> # we need to merge them <TAB>  <TAB>  <TAB> return ptr_class(join_or_meet(t1.basetype, t2.basetype, translate)) <TAB>  <TAB> if isinstance(t1, ptr_class): <TAB>  <TAB>  <TAB> return t1 <TAB>  <TAB> elif isinstance(t2, ptr_class): <TAB>  <TAB>  <TAB> return t2 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # huh? <TAB>  <TAB>  <TAB> return ptr_class(BottomType()) <TAB> return n_cls()","if isinstance ( t1 , ptr_class ) and isinstance ( t2 , ptr_class ) :",181
"def parse(self, html: HTML) -> [ProxyIP]: <TAB> ip_list: [ProxyIP] = [] <TAB> for ip_row in html.find(""table.proxytbl tr""): <TAB>  <TAB> ip_element = ip_row.find(""td:nth-child(1)"", first=True) <TAB>  <TAB> port_element = ip_row.find(""td:nth-child(2)"", first=True) <TAB>  <TAB> try: <MASK> port_str = re.search(r""//]]> (\d+)"", port_element.text).group(1) <TAB>  <TAB>  <TAB>  <TAB> p = ProxyIP(ip=ip_element.text, port=port_str) <TAB>  <TAB>  <TAB>  <TAB> ip_list.append(p) <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB> pass <TAB> return ip_list",if ip_element and port_element :,197
"def _reformat(self): <TAB> document = self.suggestions.document() <TAB> cursor = self.suggestions.textCursor() <TAB> block = document.begin() <TAB> style_format = { <TAB>  <TAB> self.STYLE_TRANSLATION: self._translation_char_format, <TAB>  <TAB> self.STYLE_STROKES: self._strokes_char_format, <TAB> } <TAB> while block != document.end(): <TAB>  <TAB> style = block.userState() <TAB>  <TAB> fmt = style_format.get(style) <MASK> cursor.setPosition(block.position()) <TAB>  <TAB>  <TAB> cursor.select(QTextCursor.BlockUnderCursor) <TAB>  <TAB>  <TAB> cursor.setCharFormat(fmt) <TAB>  <TAB> block = block.next()",if fmt is not None :,174
"def check_uncore_event(e): <TAB> if uncore_exists(e.unit): <MASK> warn_once(""Uncore unit "" + e.unit + "" missing cmask for "" + e.name) <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> if e.umask and not uncore_exists(e.unit, ""/format/umask""): <TAB>  <TAB>  <TAB> warn_once(""Uncore unit "" + e.unit + "" missing umask for "" + e.name) <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> return e <TAB> if e.unit not in missing_boxes: <TAB>  <TAB> warn_once(""Uncore unit "" + e.unit + "" missing"") <TAB>  <TAB> missing_boxes.add(e.unit) <TAB> return None","if e . cmask and not uncore_exists ( e . unit , ""/format/cmask"" ) :",192
"def check(ip, port, timeout): <TAB> try: <TAB>  <TAB> socket.setdefaulttimeout(timeout) <TAB>  <TAB> s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) <TAB>  <TAB> s.connect((ip, int(port))) <TAB>  <TAB> flag = ""envi"" <TAB>  <TAB> # envi <TAB>  <TAB> # dump <TAB>  <TAB> # reqs <TAB>  <TAB> # ruok <TAB>  <TAB> # stat <TAB>  <TAB> s.send(flag) <TAB>  <TAB> data = s.recv(1024) <TAB>  <TAB> s.close() <MASK> return u""Zookeeper Unauthorized access"" <TAB> except: <TAB>  <TAB> pass","if ""Environment"" in data :",154
"def getid(self): <TAB> uid = u"""" <TAB> try: <TAB>  <TAB> filename = ( <TAB>  <TAB>  <TAB> self.xmlelement.iterancestors(self.namespaced(""file"")) <TAB>  <TAB>  <TAB> .next() <TAB>  <TAB>  <TAB> .get(""original"") <TAB>  <TAB> ) <MASK> uid = filename + ID_SEPARATOR <TAB> except StopIteration: <TAB>  <TAB> # unit has no proper file ancestor, probably newly created <TAB>  <TAB> pass <TAB> # hide the fact that we sanitize ID_SEPERATOR <TAB> uid += unicode(self.xmlelement.get(""id"") or u"""").replace( <TAB>  <TAB> ID_SEPARATOR_SAFE, ID_SEPARATOR <TAB> ) <TAB> return uid",if filename :,164
"def identify(self, vivisect_workspace, function_vas): <TAB> candidate_functions = {} <TAB> for fva in function_vas: <TAB>  <TAB> fname = vivisect_workspace.getName(fva) <TAB>  <TAB> default_name = ""sub_%.8x"" % fva <MASK> self.d(""Identified %s at VA 0x%08X "" % (fname, fva)) <TAB>  <TAB>  <TAB> candidate_functions[fva] = True <TAB> return candidate_functions",if fname != default_name :,123
"def nud(self): <TAB> self.first = [] <TAB> comma = False <TAB> if self.token.id != "")"": <TAB>  <TAB> while 1: <MASK> break <TAB>  <TAB>  <TAB> self.first.append(self.expression()) <TAB>  <TAB>  <TAB> if self.token.id == "","": <TAB>  <TAB>  <TAB>  <TAB> comma = True <TAB>  <TAB>  <TAB>  <TAB> self.advance("","") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> break <TAB> self.advance("")"") <TAB> if not self.first or comma: <TAB>  <TAB> return self  # tuple <TAB> else: <TAB>  <TAB> return self.first[0]","if self . token . id == "")"" :",146
"def allow_syncdb(self, db, model): <TAB> for router in self.routers: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> method = router.allow_syncdb <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB> # If the router doesn't have a method, skip to the next one. <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> allow = method(db, model) <MASK> return allow <TAB> return True",if allow is not None :,110
"def status_string(self): <TAB> if not self.live: <TAB>  <TAB> if self.expired: <TAB>  <TAB>  <TAB> return _(""expired"") <TAB>  <TAB> elif self.approved_schedule: <TAB>  <TAB>  <TAB> return _(""scheduled"") <MASK> return _(""in moderation"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return _(""draft"") <TAB> else: <TAB>  <TAB> if self.approved_schedule: <TAB>  <TAB>  <TAB> return _(""live + scheduled"") <TAB>  <TAB> elif self.workflow_in_progress: <TAB>  <TAB>  <TAB> return _(""live + in moderation"") <TAB>  <TAB> elif self.has_unpublished_changes: <TAB>  <TAB>  <TAB> return _(""live + draft"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return _(""live"")",elif self . workflow_in_progress :,166
"def _on_config_changed(changed_name: str) -> None: <TAB> """"""Call config_changed hooks if the config changed."""""" <TAB> for mod_info in _module_infos: <TAB>  <TAB> if mod_info.skip_hooks: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for option, hook in mod_info.config_changed_hooks: <MASK> hook() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> cfilter = config.change_filter(option) <TAB>  <TAB>  <TAB>  <TAB> cfilter.validate() <TAB>  <TAB>  <TAB>  <TAB> if cfilter.check_match(changed_name): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> hook()",if option is None :,151
"def test_slowest_interrupted(self): <TAB> # Issue #25373: test --slowest with an interrupted test <TAB> code = TEST_INTERRUPTED <TAB> test = self.create_test(""sigint"", code=code) <TAB> for multiprocessing in (False, True): <TAB>  <TAB> with self.subTest(multiprocessing=multiprocessing): <MASK> args = (""--slowest"", ""-j2"", test) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> args = (""--slowest"", test) <TAB>  <TAB>  <TAB> output = self.run_tests(*args, exitcode=130) <TAB>  <TAB>  <TAB> self.check_executed_tests(output, test, omitted=test, interrupted=True) <TAB>  <TAB>  <TAB> regex = ""10 slowest tests:\n"" <TAB>  <TAB>  <TAB> self.check_line(output, regex)",if multiprocessing :,190
"def insert_files(self, urls, pos): <TAB> """"""Not only images"""""" <TAB> image_extensions = ["".png"", "".jpg"", "".bmp"", "".gif""] <TAB> for url in urls: <MASK> path = url.path() <TAB>  <TAB>  <TAB> ext = os.path.splitext(path)[1] <TAB>  <TAB>  <TAB> if os.path.exists(path) and ext in image_extensions: <TAB>  <TAB>  <TAB>  <TAB> self._insert_image_from_path(path) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.parent.resource_edit.add_attach(path)","if url . scheme ( ) == ""file"" :",144
"def _model_shorthand(self, args): <TAB> accum = [] <TAB> for arg in args: <TAB>  <TAB> if isinstance(arg, Node): <TAB>  <TAB>  <TAB> accum.append(arg) <TAB>  <TAB> elif isinstance(arg, Query): <TAB>  <TAB>  <TAB> accum.append(arg) <MASK> accum.extend(arg.get_proxy_fields()) <TAB>  <TAB> elif isclass(arg) and issubclass(arg, Model): <TAB>  <TAB>  <TAB> accum.extend(arg._meta.declared_fields) <TAB> return accum","elif isinstance ( arg , ModelAlias ) :",125
"def get_identifiers(self): <TAB> ids = [] <TAB> ifaces = [i[""name""] for i in self.middleware.call_sync(""interface.query"")] <TAB> for entry in glob.glob(f""{self._base_path}/interface-*""): <TAB>  <TAB> ident = entry.rsplit(""-"", 1)[-1] <TAB>  <TAB> if ident not in ifaces: <TAB>  <TAB>  <TAB> continue <MASK> ids.append(ident) <TAB> ids.sort(key=RRDBase._sort_disks) <TAB> return ids","if os . path . exists ( os . path . join ( entry , ""if_octets.rrd"" ) ) :",143
"def _validate_required_settings( <TAB> self, application_id, application_config, required_settings, should_throw=True): <TAB> """"""All required keys must be present"""""" <TAB> for setting_key in required_settings: <MASK> if should_throw: <TAB>  <TAB>  <TAB>  <TAB> raise ImproperlyConfigured( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> MISSING_SETTING.format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> application_id=application_id, setting=setting_key <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return True",if setting_key not in application_config . keys ( ) :,146
"def digests(): <TAB> if not OpenVPN.DIGESTS: <TAB>  <TAB> proc = subprocess.Popen( <TAB>  <TAB>  <TAB> [""openvpn"", ""--show-digests""], <TAB>  <TAB>  <TAB> stdout=subprocess.PIPE, <TAB>  <TAB>  <TAB> stderr=subprocess.PIPE, <TAB>  <TAB> ) <TAB>  <TAB> stdout, stderr = proc.communicate() <MASK> OpenVPN.DIGESTS = { <TAB>  <TAB>  <TAB>  <TAB> v.split("" "")[0].strip(): v.split("" "", 1)[1].strip() <TAB>  <TAB>  <TAB>  <TAB> for v in filter( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> lambda v: v and v.endswith(""bit digest size""), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> stdout.decode(""utf8"").split(""\n""), <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> } <TAB> return OpenVPN.DIGESTS",if not proc . returncode :,188
"def iterate_demo_dirs(dir_name, env_name): <TAB> for env_file_name in glob.glob( <TAB>  <TAB> os.path.join(dir_name, ""**"", ""env_id.txt""), recursive=True <TAB> ): <TAB>  <TAB> with open(env_file_name, ""r"", encoding=""utf-8"") as fd: <TAB>  <TAB>  <TAB> dir_env_name = fd.readline() <MASK> continue <TAB>  <TAB> yield os.path.dirname(env_file_name)",if dir_env_name != env_name :,132
"def validate_rights(namespace): <TAB> if ""Manage"" in namespace.rights: <MASK> raise CLIError( <TAB>  <TAB>  <TAB>  <TAB> ""Error : Assigning 'Manage' to --rights requires 'Listen' and 'Send' to be included with. e.g. --rights Manage Send Listen"" <TAB>  <TAB>  <TAB> )","if ""Listen"" not in namespace . rights or ""Send"" not in namespace . rights :",95
"def apply_patches(ctx, patched=False, pre=False): <TAB> if patched: <TAB>  <TAB> vendor_dir = _get_patched_dir(ctx) <TAB> else: <TAB>  <TAB> vendor_dir = _get_vendor_dir(ctx) <TAB> log(""Applying pre-patches..."") <TAB> patch_dir = Path(__file__).parent / ""patches"" / vendor_dir.name <TAB> if pre: <MASK> pass <TAB>  <TAB> for patch in patch_dir.glob(""*.patch""): <TAB>  <TAB>  <TAB> if not patch.name.startswith(""_post""): <TAB>  <TAB>  <TAB>  <TAB> apply_patch(ctx, patch) <TAB> else: <TAB>  <TAB> patches = patch_dir.glob(""*.patch"" if not patched else ""_post*.patch"") <TAB>  <TAB> for patch in patches: <TAB>  <TAB>  <TAB> apply_patch(ctx, patch)",if not patched :,191
"def log_sock(s, event_type=None): <TAB> if sock_silent: <TAB>  <TAB> pass <TAB> else: <MASK> logsocket.sendto(ensure_str(s), (host, port)) <TAB>  <TAB> elif event_type in show_event: <TAB>  <TAB>  <TAB> logsocket.sendto(ensure_str(s), (host, port)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pass",if event_type is None :,103
"def replace_params( <TAB> path: str, <TAB> param_convertors: typing.Dict[str, Convertor], <TAB> path_params: typing.Dict[str, str],) -> typing.Tuple[str, dict]: <TAB> for key, value in list(path_params.items()): <MASK> convertor = param_convertors[key] <TAB>  <TAB>  <TAB> value = convertor.to_string(value) <TAB>  <TAB>  <TAB> path = path.replace(""{"" + key + ""}"", value) <TAB>  <TAB>  <TAB> path_params.pop(key) <TAB> return path, path_params","if ""{"" + key + ""}"" in path :",145
"def data(self, index: QModelIndex, role=Qt.DisplayRole): <TAB> if not index.isValid(): <TAB>  <TAB> return None <TAB> if role == Qt.DisplayRole or role == Qt.EditRole: <TAB>  <TAB> i = index.row() <TAB>  <TAB> j = index.column() <TAB>  <TAB> fieldtype = self.field_types[i] <TAB>  <TAB> if j == 0: <TAB>  <TAB>  <TAB> return fieldtype.caption <TAB>  <TAB> elif j == 1: <TAB>  <TAB>  <TAB> return fieldtype.function.name <MASK> return ProtocolLabel.DISPLAY_FORMATS[fieldtype.display_format_index]",elif j == 2 :,142
"def delta_page(self, x: float = 0.0, y: float = 0.0) -> None: <TAB> if y.is_integer(): <TAB>  <TAB> y = int(y) <TAB>  <TAB> if y == 0: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> elif y < 0: <TAB>  <TAB>  <TAB> self.page_up(count=-y) <MASK> self.page_down(count=y) <TAB>  <TAB> y = 0 <TAB> if x == 0 and y == 0: <TAB>  <TAB> return <TAB> size = self._widget.page().mainFrame().geometry() <TAB> self.delta(int(x * size.width()), int(y * size.height()))",elif y > 0 :,160
"def _process_symbols(self, tokens): <TAB> opening_paren = False <TAB> for index, token, value in tokens: <MASK> token = self.MAPPINGS.get(value, Name.Function) <TAB>  <TAB> elif token == Literal and value in self.BUILTINS_ANYWHERE: <TAB>  <TAB>  <TAB> token = Name.Builtin <TAB>  <TAB> opening_paren = value == ""("" and token == Punctuation <TAB>  <TAB> yield index, token, value","if opening_paren and token in ( Literal , Name . Variable ) :",115
"def ext_service(self, entity_id, typ, service, binding=None): <TAB> known_entity = False <TAB> for key, _md in self.metadata.items(): <TAB>  <TAB> srvs = _md.ext_service(entity_id, typ, service, binding) <MASK> return srvs <TAB>  <TAB> elif srvs is None: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> known_entity = True <TAB> if known_entity: <TAB>  <TAB> raise UnsupportedBinding(binding) <TAB> else: <TAB>  <TAB> raise UnknownSystemEntity(entity_id)",if srvs :,138
"def find_library_nt(name): <TAB> # modified from ctypes.util <TAB> # ctypes.util.find_library just returns first result he found <TAB> # but we want to try them all <TAB> # because on Windows, users may have both 32bit and 64bit version installed <TAB> results = [] <TAB> for directory in os.environ[""PATH""].split(os.pathsep): <TAB>  <TAB> fname = os.path.join(directory, name) <MASK> results.append(fname) <TAB>  <TAB> if fname.lower().endswith("".dll""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> fname = fname + "".dll"" <TAB>  <TAB> if os.path.isfile(fname): <TAB>  <TAB>  <TAB> results.append(fname) <TAB> return results",if os . path . isfile ( fname ) :,174
"def getRemovedFiles(oldContents, newContents, destinationFolder): <TAB> toRemove = [] <TAB> for filename in list(oldContents.keys()): <TAB>  <TAB> if filename not in newContents: <TAB>  <TAB>  <TAB> destFile = os.path.join(destinationFolder, filename.lstrip(""/"")) <MASK> toRemove.append(filename) <TAB> return toRemove",if os . path . isfile ( destFile ) :,95
"def escapeall(self, lines): <TAB> ""Escape all lines in an array according to the output options."" <TAB> result = [] <TAB> for line in lines: <MASK> line = self.escape(line, EscapeConfig.html) <TAB>  <TAB> if Options.iso885915: <TAB>  <TAB>  <TAB> line = self.escape(line, EscapeConfig.iso885915) <TAB>  <TAB>  <TAB> line = self.escapeentities(line) <TAB>  <TAB> elif not Options.unicode: <TAB>  <TAB>  <TAB> line = self.escape(line, EscapeConfig.nonunicode) <TAB>  <TAB> result.append(line) <TAB> return result",if Options . html :,143
"def body(self): <TAB> order = [ <TAB>  <TAB> ""ok_header"", <TAB>  <TAB> ""affected_rows"", <TAB>  <TAB> ""last_insert_id"", <TAB>  <TAB> ""server_status"", <TAB>  <TAB> ""warning_count"", <TAB>  <TAB> ""state_track"", <TAB>  <TAB> ""info"", <TAB> ] <TAB> string = b"""" <TAB> for key in order: <TAB>  <TAB> item = getattr(self, key) <TAB>  <TAB> section_pack = b"""" <TAB>  <TAB> if item is None: <TAB>  <TAB>  <TAB> continue <MASK> section_pack = item <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> section_pack = getattr(self, key).toStringPacket() <TAB>  <TAB> string += section_pack <TAB> self.setBody(string) <TAB> return self._body","elif isinstance ( item , bytes ) :",182
"def _get_instantiation(self): <TAB> if self._data is None: <TAB>  <TAB> f, l, c, o = c_object_p(), c_uint(), c_uint(), c_uint() <TAB>  <TAB> conf.lib.clang_getInstantiationLocation( <TAB>  <TAB>  <TAB> self, byref(f), byref(l), byref(c), byref(o) <TAB>  <TAB> ) <MASK> f = File(f) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> f = None <TAB>  <TAB> self._data = (f, int(l.value), int(c.value), int(o.value)) <TAB> return self._data",if f :,152
"def analyze_items(items, category_id, agg_data): <TAB> for item in items: <MASK> agg_data[""cat_asp""][category_id] = [] <TAB>  <TAB> agg_data[""cat_asp""][category_id].append( <TAB>  <TAB>  <TAB> float(item.sellingStatus.currentPrice.value) <TAB>  <TAB> ) <TAB>  <TAB> if getattr(item.listingInfo, ""watchCount"", None): <TAB>  <TAB>  <TAB> agg_data[""watch_count""] += int(item.listingInfo.watchCount) <TAB>  <TAB> if getattr(item, ""postalCode"", None): <TAB>  <TAB>  <TAB> agg_data[""postal_code""] = item.postalCode","if not agg_data [ ""cat_asp"" ] . get ( category_id , None ) :",169
"def mock_default_data_dir(tmp_path: pathlib.Path): <TAB> """"""Changes the default `--data_dir` to tmp_path."""""" <TAB> tmp_path = tmp_path / ""datasets"" <TAB> default_data_dir = os.environ.get(""TFDS_DATA_DIR"") <TAB> try: <TAB>  <TAB> os.environ[""TFDS_DATA_DIR""] = os.fspath(tmp_path) <TAB>  <TAB> yield tmp_path <TAB> finally: <MASK> os.environ[""TFDS_DATA_DIR""] = default_data_dir <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> del os.environ[""TFDS_DATA_DIR""]",if default_data_dir :,158
"def has_valid_checksum(self, number): <TAB> given_number, given_checksum = number[:-1], number[-1] <TAB> calculated_checksum = 0 <TAB> parameter = 7 <TAB> for item in given_number: <TAB>  <TAB> fragment = str(int(item) * parameter) <MASK> calculated_checksum += int(fragment[-1]) <TAB>  <TAB> if parameter == 1: <TAB>  <TAB>  <TAB> parameter = 7 <TAB>  <TAB> elif parameter == 3: <TAB>  <TAB>  <TAB> parameter = 1 <TAB>  <TAB> elif parameter == 7: <TAB>  <TAB>  <TAB> parameter = 3 <TAB> return str(calculated_checksum)[-1] == given_checksum",if fragment . isalnum ( ) :,147
"def _cleanup_volumes(self, context, instance_id): <TAB> bdms = self.db.block_device_mapping_get_all_by_instance(context, instance_id) <TAB> for bdm in bdms: <TAB>  <TAB> LOG.debug(_(""terminating bdm %s"") % bdm) <MASK> volume = self.volume_api.get(context, bdm[""volume_id""]) <TAB>  <TAB>  <TAB> self.volume_api.delete(context, volume)","if bdm [ ""volume_id"" ] and bdm [ ""delete_on_termination"" ] :",130
"def _split_zipped_payload(self, packet_bunch): <TAB> """"""Split compressed payload"""""" <TAB> while packet_bunch: <MASK> payload_length = struct.unpack_from(""<I"", packet_bunch[0:3] + b""\x00"")[ <TAB>  <TAB>  <TAB>  <TAB> 0 <TAB>  <TAB>  <TAB> ]  # pylint: disable=E0602 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> payload_length = struct.unpack(""<I"", packet_bunch[0:3] + b""\x00"")[0] <TAB>  <TAB> self._packet_queue.append(packet_bunch[0 : payload_length + 4]) <TAB>  <TAB> packet_bunch = packet_bunch[payload_length + 4 :]",if PY2 :,169
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.set_application_key(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 18: <TAB>  <TAB>  <TAB> self.set_message(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 26: <TAB>  <TAB>  <TAB> self.set_tag(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 10 :,152
"def update_transitive(self, conanfile): <TAB> transitive = getattr(conanfile, ""python_requires"", None) <TAB> if not transitive: <TAB>  <TAB> return <TAB> for name, transitive_py_require in transitive.all_items(): <TAB>  <TAB> existing = self._pyrequires.get(name) <MASK> raise ConanException( <TAB>  <TAB>  <TAB>  <TAB> ""Conflict in py_requires %s - %s"" <TAB>  <TAB>  <TAB>  <TAB> % (existing.ref, transitive_py_require.ref) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self._transitive[name] = transitive_py_require",if existing and existing . ref != transitive_py_require . ref :,153
"def call(cls, func, *args): <TAB> try: <TAB>  <TAB> f = cls._func_cache[func] <TAB> except KeyError: <MASK> f = cls._func_cache[func] = getattr(vim.funcs, func) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> f = cls._func_cache[func] = vim.Function(func) <TAB> return f(*args)",if IS_NVIM :,100
"def __call__(self, *args, **kwargs): <TAB> if self is S: <TAB>  <TAB> if args: <TAB>  <TAB>  <TAB> raise TypeError(""S() takes no positional arguments, got: %r"" % (args,)) <MASK> raise TypeError(""S() expected at least one kwarg, got none"") <TAB>  <TAB> # TODO: typecheck kwarg vals? <TAB> return _t_child(self, ""("", (args, kwargs))",if not kwargs :,101
"def tiles_around_factor(self, factor, pos, radius=1, predicate=None): <TAB> ps = [] <TAB> x, y = pos <TAB> for dx in range(-radius, radius + 1): <TAB>  <TAB> nx = x + dx <TAB>  <TAB> if nx >= 0 and nx < self.width * factor: <TAB>  <TAB>  <TAB> for dy in range(-radius, radius + 1): <TAB>  <TAB>  <TAB>  <TAB> ny = y + dy <TAB>  <TAB>  <TAB>  <TAB> if ny >= 0 and ny < self.height * factor and (dx != 0 or dy != 0): <MASK> ps.append((nx, ny)) <TAB> return ps","if predicate is None or predicate ( ( nx , ny ) ) :",159
"def _plugin_get_requirements(self, requirements_iter): <TAB> plugin_requirements = {""platform"": [], ""python"": [], ""network"": [], ""native"": []} <TAB> # parse requirements <TAB> for requirement in requirements_iter: <TAB>  <TAB> key = requirement[0] <TAB>  <TAB> values = requirement[1] <MASK> values = [values] <TAB>  <TAB> if key in plugin_requirements: <TAB>  <TAB>  <TAB> plugin_requirements[key].extend(values) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> warning(""{}={}: No supported requirement"".format(key, values)) <TAB> return plugin_requirements","if isinstance ( values , str ) or isinstance ( values , bool ) :",148
"def test_engine_api_sdl(sdl, expected, pass_to, clean_registry): <TAB> from tartiflette import Engine <TAB> if pass_to == ""engine"": <TAB>  <TAB> e = Engine(sdl) <TAB> else: <TAB>  <TAB> e = Engine() <TAB> if isinstance(expected, Exception): <TAB>  <TAB> with pytest.raises(Exception): <MASK> await e.cook(sdl) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> await e.cook() <TAB> else: <TAB>  <TAB> if pass_to == ""cook"": <TAB>  <TAB>  <TAB> await e.cook(sdl) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> await e.cook() <TAB>  <TAB> assert e._schema is not None","if pass_to == ""cook"" :",175
"def update(self, other_dict, option_parser): <TAB> if isinstance(other_dict, Values): <TAB>  <TAB> other_dict = other_dict.__dict__ <TAB> other_dict = other_dict.copy() <TAB> for setting in option_parser.lists.keys(): <TAB>  <TAB> if hasattr(self, setting) and setting in other_dict: <TAB>  <TAB>  <TAB> value = getattr(self, setting) <MASK> value += other_dict[setting] <TAB>  <TAB>  <TAB>  <TAB> del other_dict[setting] <TAB> self._update_loose(other_dict)",if value :,137
"def _cast_Time(iso, curs): <TAB> if iso: <MASK> return iso <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return DateTime( <TAB>  <TAB>  <TAB>  <TAB> time.strftime( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""%Y-%m-%d %H:%M:%S"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> time.localtime(time.time())[:3] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> + time.strptime(iso[:8], ""%H:%M:%S"")[3:], <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> )","if iso in [ ""-infinity"" , ""infinity"" ] :",125
"def _get_default_urlpatterns(self): <TAB> package_string = ""."".join(self.__module__.split(""."")[:-1]) <TAB> if getattr(self, ""urls"", None): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> mod = import_module("".%s"" % self.urls, package_string) <TAB>  <TAB> except ImportError: <TAB>  <TAB>  <TAB> mod = import_module(self.urls) <TAB>  <TAB> urlpatterns = mod.urlpatterns <TAB> else: <TAB>  <TAB> # Try importing a urls.py from the dashboard package <MASK> urls_mod = import_module("".urls"", package_string) <TAB>  <TAB>  <TAB> urlpatterns = urls_mod.urlpatterns <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> urlpatterns = patterns("""") <TAB> return urlpatterns","if module_has_submodule ( import_module ( package_string ) , ""urls"" ) :",180
"def escape2null(text): <TAB> """"""Return a string with escape-backslashes converted to nulls."""""" <TAB> parts = [] <TAB> start = 0 <TAB> while 1: <TAB>  <TAB> found = text.find(""\\"", start) <MASK> parts.append(text[start:]) <TAB>  <TAB>  <TAB> return """".join(parts) <TAB>  <TAB> parts.append(text[start:found]) <TAB>  <TAB> parts.append(""\x00"" + text[found + 1 : found + 2]) <TAB>  <TAB> start = found + 2  # skip character after escape",if found == - 1 :,129
"def check(self, obj): <TAB> if ""*"" in self.states: <TAB>  <TAB> return {""state"": self.dispatcher.current_state()} <TAB> try: <TAB>  <TAB> state = self.ctx_state.get() <TAB> except LookupError: <TAB>  <TAB> chat, user = self.get_target(obj) <TAB>  <TAB> if chat or user: <TAB>  <TAB>  <TAB> state = await self.dispatcher.storage.get_state(chat=chat, user=user) <TAB>  <TAB>  <TAB> self.ctx_state.set(state) <MASK> return {""state"": self.dispatcher.current_state(), ""raw_state"": state} <TAB> else: <TAB>  <TAB> if state in self.states: <TAB>  <TAB>  <TAB> return {""state"": self.dispatcher.current_state(), ""raw_state"": state} <TAB> return False",if state in self . states :,192
"def get_tokens_unprocessed(self, text): <TAB> from pygments.lexers._asy_builtins import ASYFUNCNAME, ASYVARNAME <TAB> for index, token, value in RegexLexer.get_tokens_unprocessed(self, text): <TAB>  <TAB> if token is Name and value in ASYFUNCNAME: <TAB>  <TAB>  <TAB> token = Name.Function <MASK> token = Name.Variable <TAB>  <TAB> yield index, token, value",elif token is Name and value in ASYVARNAME :,113
"def write_family_handle(self, family, index=1): <TAB> sp = ""  "" * index <TAB> self.write_primary_tag(""family"", family, index) <TAB> if family: <TAB>  <TAB> rel = escxml(family.get_relationship().xml_str()) <MASK> self.g.write('  %s<rel type=""%s""/>\n' % (sp, rel))","if rel != """" :",99
"def pop1_bytes(self) -> bytes: <TAB> # <TAB> # Note: This function is optimized for speed over readability. <TAB> # Knowing the popped type means that we can pop *very* quickly <TAB> # when the popped type matches the pushed type. <TAB> # <TAB> if not self.values: <TAB>  <TAB> raise InsufficientStack(""Wanted 1 stack item as bytes, had none"") <TAB> else: <TAB>  <TAB> item_type, popped = self._pop_typed() <TAB>  <TAB> if item_type is int: <TAB>  <TAB>  <TAB> return int_to_big_endian(popped)  # type: ignore <MASK> return popped  # type: ignore <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise _busted_type(item_type, popped)",elif item_type is bytes :,182
"def setDefaultComponents(self): <TAB> if self._componentTypeLen == self._componentValuesSet: <TAB>  <TAB> return <TAB> idx = self._componentTypeLen <TAB> while idx: <TAB>  <TAB> idx = idx - 1 <MASK> if self.getComponentByPosition(idx) is None: <TAB>  <TAB>  <TAB>  <TAB> self.setComponentByPosition(idx) <TAB>  <TAB> elif not self._componentType[idx].isOptional: <TAB>  <TAB>  <TAB> if self.getComponentByPosition(idx) is None: <TAB>  <TAB>  <TAB>  <TAB> raise error.PyAsn1Error( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Uninitialized component #%s at %r"" % (idx, self) <TAB>  <TAB>  <TAB>  <TAB> )",if self . _componentType [ idx ] . isDefaulted :,168
"def _cloneComponentValues(self, myClone, cloneValueFlag): <TAB> idx = 0 <TAB> l = len(self._componentValues) <TAB> while idx < l: <TAB>  <TAB> c = self._componentValues[idx] <MASK> if isinstance(c, base.AbstractConstructedAsn1Item): <TAB>  <TAB>  <TAB>  <TAB> myClone.setComponentByPosition( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> idx, c.clone(cloneValueFlag=cloneValueFlag) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> myClone.setComponentByPosition(idx, c.clone()) <TAB>  <TAB> idx = idx + 1",if c is not None :,154
"def endElement(self, tag): <TAB> """"""Handle the end of an element."""""" <TAB> if tag == ""author"": <TAB>  <TAB> developer = self.text.strip() <MASK> self.author_list.append(developer) <TAB>  <TAB> elif self.title == ""contributor"" and developer not in self.contributor_list: <TAB>  <TAB>  <TAB> self.contributor_list.append(developer)","if self . title == ""author"" and developer not in self . author_list :",113
"def has_safe_repr(value): <TAB> """"""Does the node have a safe representation?"""""" <TAB> if value is None or value is NotImplemented or value is Ellipsis: <TAB>  <TAB> return True <TAB> if isinstance(value, (bool, int, long, float, complex, basestring, xrange, Markup)): <TAB>  <TAB> return True <TAB> if isinstance(value, (tuple, list, set, frozenset)): <TAB>  <TAB> for item in value: <MASK> return False <TAB>  <TAB> return True <TAB> elif isinstance(value, dict): <TAB>  <TAB> for key, value in value.iteritems(): <TAB>  <TAB>  <TAB> if not has_safe_repr(key): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> if not has_safe_repr(value): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True <TAB> return False",if not has_safe_repr ( item ) :,192
"def test_all_wizards(self): <TAB> mod = ""w3af.core.controllers.wizard.wizards.%s"" <TAB> w3af_core = w3afCore() <TAB> for filename in os.listdir(""w3af/core/controllers/wizard/wizards/""): <TAB>  <TAB> wizard_id, ext = os.path.splitext(filename) <MASK> continue <TAB>  <TAB> klass = mod % wizard_id <TAB>  <TAB> wizard_inst = factory(klass, w3af_core) <TAB>  <TAB> yield self._test_wizard_correct, wizard_inst <TAB>  <TAB> wizard_inst = factory(klass, w3af_core) <TAB>  <TAB> yield self._test_wizard_fail, wizard_inst","if wizard_id in ( ""__init__"" , "".git"" ) or ext == "".pyc"" :",183
"def test_bool_performance(self): <TAB> class Person(Document): <TAB>  <TAB> name = StringField() <TAB> Person.drop_collection() <TAB> for i in range(100): <TAB>  <TAB> Person(name=""No: %s"" % i).save() <TAB> with query_counter() as q: <MASK> pass <TAB>  <TAB> assert q == 1 <TAB>  <TAB> op = q.db.system.profile.find({""ns"": {""$ne"": ""%s.system.indexes"" % q.db.name}})[ <TAB>  <TAB>  <TAB> 0 <TAB>  <TAB> ] <TAB>  <TAB> assert op[""nreturned""] == 1",if Person . objects :,149
"def validate(self) -> None: <TAB> if self.query: <MASK> for arg_name in (""aur"", ""repo""): <TAB>  <TAB>  <TAB>  <TAB> if getattr(self, arg_name): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise MissingArgument(""sysupgrade"", arg_name)",if not self . sysupgrade :,74
"def __new__(cls, name, parents, dct): <TAB> command_handlers = {} <TAB> for attr_name, attr in dct.items(): <MASK> handles_what = attr_name[len(""handle_"") :] <TAB>  <TAB>  <TAB> if handles_what: <TAB>  <TAB>  <TAB>  <TAB> command_handlers[handles_what] = attr <TAB> dct[""command_handlers""] = command_handlers <TAB> return super(CommandHandlerMeta, cls).__new__(cls, name, parents, dct)","if callable ( attr ) and attr_name . startswith ( ""handle_"" ) :",124
"def pop_error_text(self, error_text): <TAB> if error_text in self.__errors: <TAB>  <TAB> self.__errors.remove(error_text) <MASK> self.set_message_text(WELCOME_MESSAGE) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.set_message_text(next(self.__errors.__iter__()))",if len ( self . __errors ) == 0 :,95
"def run(self, edit): <TAB> self.clear_phantoms() <TAB> regions = self.view.sel() <TAB> for region in regions: <TAB>  <TAB> region, _ = self.get_selection_from_region( <TAB>  <TAB>  <TAB> region=region, regions_length=len(region), view=self.view <TAB>  <TAB> ) <MASK> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.json_loads(self.view.substr(region), self.duplicate_key_hook) <TAB>  <TAB> except Exception as ex: <TAB>  <TAB>  <TAB> self.show_exception(region=region, msg=ex) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> sublime.status_message(""JSON Valid"")",if region is None :,165
"def update_leaderboard(wait_time): <TAB> conn = get_connection() <TAB> cursor = conn.cursor(MySQLdb.cursors.DictCursor) <TAB> while True: <TAB>  <TAB> try: <MASK> log.info(""Updating leaderboard and adding some sigma"") <TAB>  <TAB>  <TAB> cursor.execute(""call generate_leaderboard;"") <TAB>  <TAB>  <TAB> if wait_time == 0: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> for s in range(wait_time): <TAB>  <TAB>  <TAB>  <TAB> # allow for a [Ctrl]+C during the sleep cycle <TAB>  <TAB>  <TAB>  <TAB> time.sleep(1) <TAB>  <TAB> except KeyboardInterrupt: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> # log error <TAB>  <TAB>  <TAB> log.error(traceback.format_exc()) <TAB>  <TAB>  <TAB> break <TAB> cursor.close() <TAB> conn.close()",if use_log :,199
"def _external_tables(self): <TAB> tables = [] <TAB> for name, df in self.extra_options.get(""external_tables"", {}).items(): <MASK> raise TypeError(""External table is not an instance of pandas "" ""dataframe"") <TAB>  <TAB> schema = sch.infer(df) <TAB>  <TAB> chtypes = map(ClickhouseDataType.from_ibis, schema.types) <TAB>  <TAB> structure = list(zip(schema.names, map(str, chtypes))) <TAB>  <TAB> tables.append(dict(name=name, data=df.to_dict(""records""), structure=structure)) <TAB> return tables","if not isinstance ( df , pd . DataFrame ) :",152
"def getmod(self, nm): <TAB> mod = None <TAB> for thing in self.path: <MASK> owner = self.shadowpath.get(thing, -1) <TAB>  <TAB>  <TAB> if owner == -1: <TAB>  <TAB>  <TAB>  <TAB> owner = self.shadowpath[thing] = self.__makeOwner(thing) <TAB>  <TAB>  <TAB> if owner: <TAB>  <TAB>  <TAB>  <TAB> mod = owner.getmod(nm) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> mod = thing.getmod(nm) <TAB>  <TAB> if mod: <TAB>  <TAB>  <TAB> break <TAB> return mod","if isinstance ( thing , basestring ) :",137
"def add_variant_attribute_data_to_expected_data(data, variant, attribute_ids, pk=None): <TAB> for assigned_attribute in variant.attributes.all(): <TAB>  <TAB> header = f""{assigned_attribute.attribute.slug} (variant attribute)"" <TAB>  <TAB> if str(assigned_attribute.attribute.pk) in attribute_ids: <TAB>  <TAB>  <TAB> value = get_attribute_value(assigned_attribute) <MASK> data[pk][header] = value <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> data[header] = value <TAB> return data",if pk :,136
"def get_files(start_dir, includes, excludes): <TAB> # use os.walk to recursively dig down into the Pupil directory <TAB> match_files = [] <TAB> for root, dirs, files in os.walk(start_dir): <TAB>  <TAB> if not re.search(excludes, root): <TAB>  <TAB>  <TAB> files = [ <TAB>  <TAB>  <TAB>  <TAB> f <TAB>  <TAB>  <TAB>  <TAB> for f in files <MASK> ] <TAB>  <TAB>  <TAB> files = [os.path.join(root, f) for f in files] <TAB>  <TAB>  <TAB> match_files += files <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""Excluding '%s'"" % root) <TAB> return match_files","if re . search ( includes , f ) and not re . search ( excludes , f )",175
"def findinDoc(self, tagpath, pos, end): <TAB> result = None <TAB> if end == -1: <TAB>  <TAB> end = self.docSize <TAB> else: <TAB>  <TAB> end = min(self.docSize, end) <TAB> foundat = -1 <TAB> for j in range(pos, end): <TAB>  <TAB> item = self.docList[j] <MASK> (name, argres) = item.split(b""="", 1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = item <TAB>  <TAB>  <TAB> argres = """" <TAB>  <TAB> if isinstance(tagpath, str): <TAB>  <TAB>  <TAB> tagpath = tagpath.encode(""utf-8"") <TAB>  <TAB> if name.endswith(tagpath): <TAB>  <TAB>  <TAB> result = argres <TAB>  <TAB>  <TAB> foundat = j <TAB>  <TAB>  <TAB> break <TAB> return foundat, result","if item . find ( b""="" ) >= 0 :",189
"def load_classes(module, base, blacklist): <TAB> classes = [] <TAB> for attr in dir(module): <TAB>  <TAB> attr = getattr(module, attr) <TAB>  <TAB> if inspect.isclass(attr): <MASK> if attr is not base and attr not in blacklist: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> classes.append(attr) <TAB> return classes","if issubclass ( attr , base ) :",90
"def run(): <TAB> try: <TAB>  <TAB> result = func() <TAB> except Exception: <TAB>  <TAB> future_cell[0] = TracebackFuture() <TAB>  <TAB> future_cell[0].set_exc_info(sys.exc_info()) <TAB> else: <MASK> future_cell[0] = result <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> future_cell[0] = TracebackFuture() <TAB>  <TAB>  <TAB> future_cell[0].set_result(result) <TAB> self.add_future(future_cell[0], lambda future: self.stop())",if is_future ( result ) :,136
def lastCard(self): <TAB> if self._answeredIds: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> return self.mw.col.getCard(self._answeredIds[-1]) <TAB>  <TAB>  <TAB> except TypeError: <TAB>  <TAB>  <TAB>  <TAB> # id was deleted <TAB>  <TAB>  <TAB>  <TAB> return,if not self . card or self . _answeredIds [ - 1 ] != self . card . id :,94
"def run(self): <TAB> global _cameras <TAB> while 1: <TAB>  <TAB> for cam in _cameras: <MASK> cam.pygame_buffer = cam.capture.get_image(cam.pygame_buffer) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> cv.GrabFrame(cam.capture) <TAB>  <TAB>  <TAB> cam._threadcapturetime = time.time() <TAB>  <TAB> time.sleep(0.04)  # max 25 fps, if you're lucky",if cam . pygame_camera :,120
"def handle_exception(self, e, result): <TAB> for k in sorted(result.thrift_spec): <TAB>  <TAB> if result.thrift_spec[k][1] == ""success"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> _, exc_name, exc_cls, _ = result.thrift_spec[k] <MASK> setattr(result, exc_name, e) <TAB>  <TAB>  <TAB> return True <TAB> return False","if isinstance ( e , exc_cls ) :",112
"def for_module(cls, modname: str) -> ""ModuleAnalyzer"": <TAB> if (""module"", modname) in cls.cache: <TAB>  <TAB> entry = cls.cache[""module"", modname] <TAB>  <TAB> if isinstance(entry, PycodeError): <TAB>  <TAB>  <TAB> raise entry <TAB>  <TAB> return entry <TAB> try: <TAB>  <TAB> filename, source = cls.get_module_source(modname) <MASK> obj = cls.for_string(source, modname, filename or ""<string>"") <TAB>  <TAB> elif filename is not None: <TAB>  <TAB>  <TAB> obj = cls.for_file(filename, modname) <TAB> except PycodeError as err: <TAB>  <TAB> cls.cache[""module"", modname] = err <TAB>  <TAB> raise <TAB> cls.cache[""module"", modname] = obj <TAB> return obj",if source is not None :,182
"def visit_productionlist(self, node): <TAB> self.new_state() <TAB> names = [] <TAB> for production in node: <TAB>  <TAB> names.append(production[""tokenname""]) <TAB> maxlen = max(len(name) for name in names) <TAB> for production in node: <MASK> self.add_text(production[""tokenname""].ljust(maxlen) + "" ::="") <TAB>  <TAB>  <TAB> lastname = production[""tokenname""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.add_text(""%s <TAB> "" % ("" "" * len(lastname))) <TAB>  <TAB> self.add_text(production.astext() + ""\n"") <TAB> self.end_state(wrap=False) <TAB> raise nodes.SkipNode","if production [ ""tokenname"" ] :",167
"def transport_vmware_guestinfo(): <TAB> rpctool = ""vmware-rpctool"" <TAB> not_found = None <TAB> if not subp.which(rpctool): <TAB>  <TAB> return not_found <TAB> cmd = [rpctool, ""info-get guestinfo.ovfEnv""] <TAB> try: <TAB>  <TAB> out, _err = subp.subp(cmd) <MASK> return out <TAB>  <TAB> LOG.debug(""cmd %s exited 0 with empty stdout: %s"", cmd, out) <TAB> except subp.ProcessExecutionError as e: <TAB>  <TAB> if e.exit_code != 1: <TAB>  <TAB>  <TAB> LOG.warning(""%s exited with code %d"", rpctool, e.exit_code) <TAB>  <TAB>  <TAB> LOG.debug(e) <TAB> return not_found",if out :,196
"def MakeWidthArray(fm): <TAB> # Make character width array <TAB> s = ""{\n\t"" <TAB> cw = fm[""Widths""] <TAB> for i in xrange(0, 256): <TAB>  <TAB> if chr(i) == ""'"": <TAB>  <TAB>  <TAB> s += ""'\\''"" <TAB>  <TAB> elif chr(i) == ""\\"": <TAB>  <TAB>  <TAB> s += ""'\\\\'"" <TAB>  <TAB> elif i >= 32 and i <= 126: <TAB>  <TAB>  <TAB> s += ""'"" + chr(i) + ""'"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> s += ""chr(%d)"" % i <TAB>  <TAB> s += "":"" + fm[""Widths""][i] <TAB>  <TAB> if i < 255: <TAB>  <TAB>  <TAB> s += "","" <MASK> s += ""\n\t"" <TAB> s += ""}"" <TAB> return s",if ( i + 1 ) % 22 == 0 :,192
"def lookup_config_file(filename: str) -> Optional[str]: <TAB> """"""Return config file PATH."""""" <TAB> for path in [find_vcs_root(default=""~""), ""~""]: <TAB>  <TAB> f = os.path.expanduser(""%s/%s"" % (path, filename)) <MASK> LOG.info(""Found config file %s"", f) <TAB>  <TAB>  <TAB> return f <TAB> return None",if os . path . isfile ( f ) :,103
"def load_freq_dict(self, freq_dict_filename: str): <TAB> with open(str(expand_path(freq_dict_filename)), ""r"") as fl: <TAB>  <TAB> lines = fl.readlines() <TAB> pos_freq_dict = defaultdict(list) <TAB> for line in lines: <TAB>  <TAB> line_split = line.strip(""\n"").split(""\t"") <MASK> pos_freq_dict[line_split[1]].append((line_split[0], float(line_split[2]))) <TAB> nouns_with_freq = pos_freq_dict[""s""] <TAB> self.nouns_dict = {noun: freq for noun, freq in nouns_with_freq}","if re . match ( ""[\d]+\.[\d]+"" , line_split [ 2 ] ) :",180
"def do_visual_mode(self): <TAB> """"""Handle strokes in visual mode."""""" <TAB> try: <TAB>  <TAB> self.n1 = self.n = 1 <TAB>  <TAB> self.do_state( <TAB>  <TAB>  <TAB> self.vis_dispatch_d, <TAB>  <TAB>  <TAB> mode_name=""visual-line"" if self.visual_line_flag else ""visual"", <TAB>  <TAB> ) <MASK> self.visual_line_helper() <TAB> except Exception: <TAB>  <TAB> g.es_exception() <TAB>  <TAB> self.quit()",if self . visual_line_flag :,131
"def cleanup(self): <TAB> log.info("""") <TAB> log.info(""Cleaning up.. "") <TAB> status = self._capture_output(""status"", ""--porcelain"") <TAB> status = status.split(""\n"") <TAB> for line in status: <TAB>  <TAB> filepath = line.split() <MASK> continue <TAB>  <TAB> filepath = filepath[-1] <TAB>  <TAB> if filepath[-3:] != ""rej"" and filepath[-5:] != ""porig"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> log.info(""Removing temp file %s "" % filepath) <TAB>  <TAB>  <TAB> os.remove(os.path.join(self.base_dir, filepath)) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> log.warn(""File removal failed, you should manually remove %s"" % filepath) <TAB>  <TAB>  <TAB> pass",if len ( filepath ) == 0 :,195
"def OnBodyRClick(self, event=None): <TAB> try: <TAB>  <TAB> c = self.c <TAB>  <TAB> p = c.currentPosition() <MASK> c.k.showStateAndMode(w=c.frame.body.bodyCtrl) <TAB>  <TAB> g.doHook(""bodyrclick2"", c=c, p=p, v=p, event=event) <TAB> except: <TAB>  <TAB> g.es_event_exception(""iconrclick"")","if not g . doHook ( ""bodyrclick1"" , c = c , p = p , v = p , event = event ) :",138
"def receiver(): <TAB> """"""receive messages with polling"""""" <TAB> pull = ctx.socket(zmq.PULL) <TAB> pull.connect(url) <TAB> poller = Poller() <TAB> poller.register(pull, zmq.POLLIN) <TAB> while True: <TAB>  <TAB> events = await poller.poll() <MASK> print(""recving"", events) <TAB>  <TAB>  <TAB> msg = await pull.recv_multipart() <TAB>  <TAB>  <TAB> print(""recvd"", msg)",if pull in dict ( events ) :,120
"def sched(self): <TAB> for k, q in self.q.items(): <MASK> ent = q.popleft() <TAB>  <TAB>  <TAB> self.cur[k] = ent <TAB>  <TAB>  <TAB> self.run_one(ent, k)",if q and k not in self . cur :,69
"def eval_dummy_genomes_iznn(genomes, config): <TAB> for genome_id, genome in genomes: <TAB>  <TAB> net = neat.iznn.IZNN.create(genome, config) <MASK> net.reset() <TAB>  <TAB>  <TAB> genome.fitness = 0.0 <TAB>  <TAB> elif genome_id <= 150: <TAB>  <TAB>  <TAB> genome.fitness = 0.5 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> genome.fitness = 1.0",if genome_id < 10 :,129
"def handle_noargs(self, **options): <TAB> # Inspired by Postfix's ""postconf -n"". <TAB> from django.conf import settings, global_settings <TAB> # Because settings are imported lazily, we need to explicitly load them. <TAB> settings._setup() <TAB> user_settings = module_to_dict(settings._wrapped) <TAB> default_settings = module_to_dict(global_settings) <TAB> output = [] <TAB> for key in sorted(user_settings.keys()): <TAB>  <TAB> if key not in default_settings: <TAB>  <TAB>  <TAB> output.append(""%s = %s  ###"" % (key, user_settings[key])) <MASK> output.append(""%s = %s"" % (key, user_settings[key])) <TAB> return ""\n"".join(output)",elif user_settings [ key ] != default_settings [ key ] :,196
def test_get_chat_thread(self): <TAB> async with self.chat_client: <TAB>  <TAB> await self._create_thread() <TAB>  <TAB> get_thread_result = await self.chat_client.get_chat_thread(self.thread_id) <TAB>  <TAB> assert get_thread_result.id == self.thread_id <TAB>  <TAB> # delete created users and chat threads <MASK> await self.chat_client.delete_chat_thread(self.thread_id),if not self . is_playback ( ) :,121
"def consume(self): <TAB> if not self.inputState.guessing: <TAB>  <TAB> c = self.LA(1) <MASK> self.append(c) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # use input.LA(), not LA(), to get original case <TAB>  <TAB>  <TAB> # CharScanner.LA() would toLower it. <TAB>  <TAB>  <TAB> c = self.inputState.input.LA(1) <TAB>  <TAB>  <TAB> self.append(c) <TAB>  <TAB> if c and c in ""\t"": <TAB>  <TAB>  <TAB> self.tab() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.inputState.column += 1 <TAB> self.inputState.input.consume()",if self . caseSensitive :,159
"def commandComplete(self, cmd): <TAB> if self.property: <MASK> return <TAB>  <TAB> result = self.observer.getStdout() <TAB>  <TAB> if self.strip: <TAB>  <TAB>  <TAB> result = result.strip() <TAB>  <TAB> propname = self.property <TAB>  <TAB> self.setProperty(propname, result, ""SetPropertyFromCommand Step"") <TAB>  <TAB> self.property_changes[propname] = result <TAB> else: <TAB>  <TAB> new_props = self.extract_fn( <TAB>  <TAB>  <TAB> cmd.rc, self.observer.getStdout(), self.observer.getStderr() <TAB>  <TAB> ) <TAB>  <TAB> for k, v in iteritems(new_props): <TAB>  <TAB>  <TAB> self.setProperty(k, v, ""SetPropertyFromCommand Step"") <TAB>  <TAB> self.property_changes = new_props",if cmd . didFail ( ) :,192
"def any(self, provider_name): <TAB> result = authomatic.login(Webapp2Adapter(self), provider_name) <TAB> if result: <TAB>  <TAB> apis = [] <TAB>  <TAB> if result.user: <TAB>  <TAB>  <TAB> result.user.update() <MASK> apis = config.config.get(provider_name, {}).get(""_apis"", {}) <TAB>  <TAB> nice_provider_name = ( <TAB>  <TAB>  <TAB> config.config.get(provider_name, {}).get(""_name"") <TAB>  <TAB>  <TAB> or provider_name.capitalize() <TAB>  <TAB> ) <TAB>  <TAB> render( <TAB>  <TAB>  <TAB> self, <TAB>  <TAB>  <TAB> result, <TAB>  <TAB>  <TAB> result.popup_js(custom=dict(apis=apis, provider_name=nice_provider_name)), <TAB>  <TAB> )",if result . user . credentials :,186
"def set_lock(self, lock_closed=True, device=0, timeout=0): <TAB> if self.handle: <TAB>  <TAB> action = 0x02 if lock_closed else 0x01 <TAB>  <TAB> reply = self.write_register(_R.receiver_pairing, action, device, timeout) <MASK> return True <TAB>  <TAB> _log.warn( <TAB>  <TAB>  <TAB> ""%s: failed to %s the receiver lock"", <TAB>  <TAB>  <TAB> self, <TAB>  <TAB>  <TAB> ""close"" if lock_closed else ""open"", <TAB>  <TAB> )",if reply :,129
"def connect_thread(self, sleep_time=0): <TAB> time.sleep(sleep_time) <TAB> try: <TAB>  <TAB> while self.running and self._need_more_ip(): <MASK> break <TAB>  <TAB>  <TAB> self.connect_process() <TAB> finally: <TAB>  <TAB> self.thread_num_lock.acquire() <TAB>  <TAB> self.thread_num -= 1 <TAB>  <TAB> self.thread_num_lock.release()",if self . new_conn_pool . qsize ( ) > self . config . https_connection_pool_max :,128
"def train_job( <TAB> guest_party_id, host_party_id, arbiter_party_id, train_conf_path, train_dsl_path): <TAB> train = TrainSBTModel() <TAB> train.set_config(guest_party_id, host_party_id, arbiter_party_id, train_conf_path) <TAB> train.set_dsl(train_dsl_path) <TAB> status = train.submit() <TAB> if status: <TAB>  <TAB> is_success = train.wait_success(timeout=600) <MASK> train.get_component_metrics() <TAB>  <TAB>  <TAB> train.get_component_output_model() <TAB>  <TAB>  <TAB> train.get_component_output_data() <TAB>  <TAB>  <TAB> return train <TAB> return False",if is_success :,188
"def get_version(): <TAB> INIT = os.path.abspath(os.path.join(HERE, "".."", ""pyftpdlib"", ""__init__.py"")) <TAB> with open(INIT, ""r"") as f: <TAB>  <TAB> for line in f: <MASK> ret = eval(line.strip().split("" = "")[1]) <TAB>  <TAB>  <TAB>  <TAB> assert ret.count(""."") == 2, ret <TAB>  <TAB>  <TAB>  <TAB> for num in ret.split("".""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> assert num.isdigit(), ret <TAB>  <TAB>  <TAB>  <TAB> return ret <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""couldn't find version string"")","if line . startswith ( ""__ver__"" ) :",151
"def get_terminus_panel(self, window, visible_only=False): <TAB> if visible_only: <TAB>  <TAB> active_panel = window.active_panel() <TAB>  <TAB> panels = [active_panel] if active_panel else [] <TAB> else: <TAB>  <TAB> panels = window.panels() <TAB> for panel in panels: <TAB>  <TAB> panel_name = panel.replace(""output."", """") <TAB>  <TAB> if panel_name == EXEC_PANEL: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> panel_view = window.find_output_panel(panel_name) <TAB>  <TAB> if panel_view: <TAB>  <TAB>  <TAB> terminal = Terminal.from_id(panel_view.id()) <MASK> return panel_view <TAB> return None",if terminal :,173
"def to_internal_value(self, data): <TAB> site = get_current_site() <TAB> pages_root = reverse(""pages-root"") <TAB> ret = [] <TAB> for path in data: <MASK> path = path[len(pages_root) :] <TAB>  <TAB> # strip any final slash <TAB>  <TAB> if path.endswith(""/""): <TAB>  <TAB>  <TAB> path = path[:-1] <TAB>  <TAB> page = get_page_from_path(site, path) <TAB>  <TAB> if page: <TAB>  <TAB>  <TAB> ret.append(page) <TAB> return ret",if path . startswith ( pages_root ) :,136
"def forward(self, inputs): <TAB> input_dtype = inputs[0].dtype <TAB> if self.comm.rank == self.root: <TAB>  <TAB> # convert to float32 for communication <MASK> inputs = tuple([item.astype(numpy.float32) for item in inputs]) <TAB>  <TAB> y = self.comm.scatter(inputs, self.root) <TAB> else: <TAB>  <TAB> y = self.comm.scatter(None, self.root) <TAB> # convert back <TAB> if numpy.float16 == input_dtype: <TAB>  <TAB> y = y.astype(input_dtype) <TAB> return (y,)",if numpy . float16 == input_dtype :,152
"def discover_misago_admin(): <TAB> for app in apps.get_app_configs(): <TAB>  <TAB> module = import_module(app.name) <TAB>  <TAB> if not hasattr(module, ""admin""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> admin_module = import_module(""%s.admin"" % app.name) <MASK> extension = getattr(admin_module, ""MisagoAdminExtension"")() <TAB>  <TAB>  <TAB> if hasattr(extension, ""register_navigation_nodes""): <TAB>  <TAB>  <TAB>  <TAB> extension.register_navigation_nodes(site) <TAB>  <TAB>  <TAB> if hasattr(extension, ""register_urlpatterns""): <TAB>  <TAB>  <TAB>  <TAB> extension.register_urlpatterns(urlpatterns)","if hasattr ( admin_module , ""MisagoAdminExtension"" ) :",169
"def overwrite_timeout( <TAB> initial_node: dict, path: str, hash_: str, size_: int, rsf: bool) -> int: <TAB> minutes = 10 <TAB> while minutes > 0: <TAB>  <TAB> time.sleep(60) <TAB>  <TAB> minutes -= 1 <TAB>  <TAB> n = acd_client.get_metadata(initial_node[""id""]) <MASK> return upload_complete(n, path, hash_, size_, rsf) <TAB> logger.warning('Timeout while overwriting ""%s"".' % path) <TAB> return UL_TIMEOUT","if n [ ""version"" ] > initial_node [ ""version"" ] :",138
"def write(self, s, spos): <TAB> if not s: <TAB>  <TAB> return <TAB> # Force s to be a string or unicode <TAB> if not isinstance(s, basestring): <TAB>  <TAB> s = str(s) <TAB> slen = self.len <TAB> if spos == slen: <TAB>  <TAB> self.len = self.pos = spos + len(s) <TAB>  <TAB> return <TAB> if spos > slen: <TAB>  <TAB> slen = spos <TAB> newpos = spos + len(s) <TAB> if spos < slen: <TAB>  <TAB> if self.buflist: <TAB>  <TAB>  <TAB> self.buf += """".join(self.buflist) <TAB>  <TAB> self.buflist = [self.buf[:spos], s, self.buf[newpos:]] <MASK> slen = newpos <TAB> else: <TAB>  <TAB> self.buflist.append(s)",if newpos > slen :,196
"def _print_one_entry(news_entry: xml.etree.ElementTree.Element) -> None: <TAB> child: xml.etree.ElementTree.Element <TAB> for child in news_entry: <TAB>  <TAB> if ""title"" in child.tag: <TAB>  <TAB>  <TAB> title = str(child.text) <TAB>  <TAB> if ""pubDate"" in child.tag: <TAB>  <TAB>  <TAB> pub_date = str(child.text) <MASK> description = str(child.text) <TAB> print_stdout(color_line(title, 14) + "" ("" + bold_line(pub_date) + "")"") <TAB> print_stdout(format_paragraph(strip_tags(description))) <TAB> print_stdout()","if ""description"" in child . tag :",169
"def get_sequence_type_str(x: Sequence[Any]) -> str: <TAB> container_type = type(x).__name__ <TAB> if not x: <TAB>  <TAB> if container_type == ""list"": <TAB>  <TAB>  <TAB> return ""[]"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return container_type + ""([])"" <TAB> elem_type = get_type_str(x[0]) <TAB> if container_type == ""list"": <MASK> return ""["" + elem_type + ""]"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""["" + elem_type + "", ...]"" <TAB> else: <TAB>  <TAB> if len(x) == 1: <TAB>  <TAB>  <TAB> return f""{container_type}([{elem_type}])"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return f""{container_type}([{elem_type}, ...])""",if len ( x ) == 1 :,196
"def signal_notebook_switch_page(self, notebook, current_page, index): <TAB> if not hasattr(self.parent, ""rpc""): <TAB>  <TAB> return <TAB> # previous_page = notebook.get_nth_page(self.last_page_id) <TAB> self.last_page_id = index <TAB> for tab in self.tabs.values(): <TAB>  <TAB> if current_page != tab.box: <TAB>  <TAB>  <TAB> continue <MASK> tab.load_campaign_information(force=False)","if hasattr ( tab , ""load_campaign_information"" ) :",137
"def format_string(self, templ, args): <TAB> templ = self.to_native(templ) <TAB> if isinstance(args, nodes.Arguments): <TAB>  <TAB> args = args.arguments <TAB> for (i, arg) in enumerate(args): <TAB>  <TAB> arg = self.to_native(self.reduce_single(arg)) <MASK> # Python boolean is upper case. <TAB>  <TAB>  <TAB> arg = str(arg).lower() <TAB>  <TAB> templ = templ.replace(""@{}@"".format(i), str(arg)) <TAB> return templ","if isinstance ( arg , bool ) :",135
"def execute_Single(self, object, smooth): <TAB> if getattr(object, ""type"", """") == ""MESH"": <TAB>  <TAB> mesh = object.data <MASK> smoothList = [smooth] * len(mesh.polygons) <TAB>  <TAB>  <TAB> mesh.polygons.foreach_set(""use_smooth"", smoothList) <TAB>  <TAB>  <TAB> # trigger update <TAB>  <TAB>  <TAB> mesh.polygons[0].use_smooth = smooth <TAB> return object",if len ( mesh . polygons ) > 0 :,112
"def _enumerate_visible_deps(self, dep, predicate): <TAB> # We present the dependencies out of classpath order and instead in alphabetized internal deps, <TAB> # then alphabetized external deps order for ease in scanning output. <TAB> dependencies = sorted(x for x in getattr(dep, ""dependencies"", [])) <TAB> if not self.is_internal_only: <TAB>  <TAB> dependencies.extend( <TAB>  <TAB>  <TAB> sorted( <TAB>  <TAB>  <TAB>  <TAB> (x for x in getattr(dep, ""jar_dependencies"", [])), <TAB>  <TAB>  <TAB>  <TAB> key=lambda x: (x.org, x.name, x.rev, x.classifier), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB> for inner_dep in dependencies: <TAB>  <TAB> dep_id, internal = self._dep_id(inner_dep) <MASK> yield inner_dep",if predicate ( internal ) :,193
"def stop_test(self): <TAB> if self.master: <TAB>  <TAB> self.log.info(""Ending cloud test..."") <TAB>  <TAB> if not self._last_status: <TAB>  <TAB>  <TAB> self.get_master_status() <MASK> self.master.stop() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.master.terminate()","if self . _last_status [ ""progress"" ] >= 100 :",92
"def run(self, workspace): <TAB> """"""Run the module"""""" <TAB> if self.show_window: <TAB>  <TAB> m = workspace.get_measurements() <TAB>  <TAB> x = m.get_current_measurement(self.get_object(), self.x_axis.value) <MASK> x = x[x > self.xbounds.min] <TAB>  <TAB>  <TAB> x = x[x < self.xbounds.max] <TAB>  <TAB> workspace.display_data.x = x <TAB>  <TAB> workspace.display_data.title = ""{} (cycle {})"".format( <TAB>  <TAB>  <TAB> self.title.value, workspace.measurements.image_set_number <TAB>  <TAB> )",if self . wants_xbounds :,163
"def L_op(self, inputs, outputs, gout): <TAB> (x,) = inputs <TAB> (gz,) = gout <TAB> if x.type in complex_types: <TAB>  <TAB> raise NotImplementedError() <TAB> if outputs[0].type in discrete_types: <MASK> return [x.zeros_like(dtype=theano.config.floatX)] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return [x.zeros_like()] <TAB> return (gz / (np.cast[x.type](1) - sqr(x)),)",if x . type in discrete_types :,130
"def _which(cls, progname): <TAB> progname = progname.lower() <TAB> for p in cls.env.path: <TAB>  <TAB> for ext in cls._EXTENSIONS: <TAB>  <TAB>  <TAB> fn = p / (progname + ext) <MASK> return fn <TAB> return None","if fn . access ( ""x"" ) and not fn . is_dir ( ) :",81
"def iterate(self, prod_, rule_): <TAB> newProduction = """" <TAB> for i in range(len(prod_)): <TAB>  <TAB> step = self.production[i] <TAB>  <TAB> if step == ""W"": <TAB>  <TAB>  <TAB> newProduction = newProduction + self.ruleW <TAB>  <TAB> elif step == ""X"": <TAB>  <TAB>  <TAB> newProduction = newProduction + self.ruleX <MASK> newProduction = newProduction + self.ruleY <TAB>  <TAB> elif step == ""Z"": <TAB>  <TAB>  <TAB> newProduction = newProduction + self.ruleZ <TAB>  <TAB> elif step != ""F"": <TAB>  <TAB>  <TAB> newProduction = newProduction + step <TAB> self.drawLength = self.drawLength * 0.5 <TAB> self.generations += 1 <TAB> return newProduction","elif step == ""Y"" :",179
"def update(self, mapping, update_only=False): <TAB> for name in mapping: <TAB>  <TAB> if update_only and name in self: <TAB>  <TAB>  <TAB> # nested and inner objects, merge recursively <TAB>  <TAB>  <TAB> if hasattr(self[name], ""update""): <TAB>  <TAB>  <TAB>  <TAB> # FIXME only merge subfields, not the settings <TAB>  <TAB>  <TAB>  <TAB> self[name].update(mapping[name], update_only) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> self.field(name, mapping[name]) <TAB> if update_only: <TAB>  <TAB> for name in mapping._meta: <MASK> self._meta[name] = mapping._meta[name] <TAB> else: <TAB>  <TAB> self._meta.update(mapping._meta)",if name not in self . _meta :,175
"def Flatten(self, metadata, value_to_flatten): <TAB> if metadata: <TAB>  <TAB> self.metadata = metadata <TAB> for desc in value_to_flatten.type_infos: <TAB>  <TAB> if desc.name == ""metadata"": <TAB>  <TAB>  <TAB> continue <MASK> setattr(self, desc.name, getattr(value_to_flatten, desc.name))","if hasattr ( self , desc . name ) and value_to_flatten . HasField ( desc . name ) :",108
"def addnode(self, parent, data): <TAB> print(""aaa"", data) <TAB> for i in data: <TAB>  <TAB> print(i) <TAB>  <TAB> if i == ""-"": <TAB>  <TAB>  <TAB> continue <MASK> item = self.tre_plugins.AppendItem(parent, i[0].title) <TAB>  <TAB>  <TAB> self.tre_plugins.SetItemData(item, i[0]) <TAB>  <TAB>  <TAB> self.addnode(item, i[1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> item = self.tre_plugins.AppendItem(parent, i[0].title) <TAB>  <TAB>  <TAB> self.tre_plugins.SetItemData(item, i[0])","if isinstance ( i , tuple ) :",159
"def load_timer(string): <TAB> if ""."" not in string: <TAB>  <TAB> raise argparse.ArgumentTypeError( <TAB>  <TAB>  <TAB> ""Value for --benchmark-timer must be in dotted form. Eg: 'module.attr'."" <TAB>  <TAB> ) <TAB> mod, attr = string.rsplit(""."", 1) <TAB> if mod == ""pep418"": <MASK> import time <TAB>  <TAB>  <TAB> return NameWrapper(getattr(time, attr)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> from . import pep418 <TAB>  <TAB>  <TAB> return NameWrapper(getattr(pep418, attr)) <TAB> else: <TAB>  <TAB> __import__(mod) <TAB>  <TAB> mod = sys.modules[mod] <TAB>  <TAB> return NameWrapper(getattr(mod, attr))",if PY3 :,166
"def _is_an_attribute(self, pyname): <TAB> if pyname is not None and isinstance(pyname, pynames.AssignedName): <TAB>  <TAB> pymodule, lineno = self.pyname.get_definition_location() <TAB>  <TAB> scope = pymodule.get_scope().get_inner_scope_for_line(lineno) <TAB>  <TAB> if scope.get_kind() == ""Class"": <TAB>  <TAB>  <TAB> return pyname in list(scope.get_names().values()) <TAB>  <TAB> parent = scope.parent <MASK> return pyname in list(parent.get_names().values()) <TAB> return False","if parent is not None and parent . get_kind ( ) == ""Class"" :",157
"def _format_arg(self, name, spec, value): <TAB> if name == ""title"": <TAB>  <TAB> if isinstance(value, bool) and value: <TAB>  <TAB>  <TAB> return ""--title"" <MASK> return ""--title --title_text %s"" % (value,) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError('Unknown value for ""title"" argument: ' + str(value)) <TAB> return super(Pik, self)._format_arg(name, spec, value)","elif isinstance ( value , str ) :",118
"def total_form_count(self): <TAB> """"""Returns the total number of forms in this FormSet."""""" <TAB> if self.is_bound: <TAB>  <TAB> return self.management_form.cleaned_data[TOTAL_FORM_COUNT] <TAB> else: <TAB>  <TAB> initial_forms = self.initial_form_count() <TAB>  <TAB> total_forms = initial_forms + self.extra <TAB>  <TAB> # Allow all existing related objects/inlines to be displayed, <TAB>  <TAB> # but don't allow extra beyond max_num. <MASK> total_forms = initial_forms <TAB>  <TAB> elif total_forms > self.max_num >= 0: <TAB>  <TAB>  <TAB> total_forms = self.max_num <TAB> return total_forms",if initial_forms > self . max_num >= 0 :,178
"def GetTestNamesFromSuites(test_suite): <TAB> """"""Takes a list of test suites and returns a list of contained test names."""""" <TAB> suites = [test_suite] <TAB> test_names = [] <TAB> while suites: <TAB>  <TAB> suite = suites.pop() <TAB>  <TAB> for test in suite: <MASK> suites.append(test) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> test_names.append(test.id()[len(""gslib.tests.test_"") :]) <TAB> return test_names","if isinstance ( test , unittest . TestSuite ) :",135
"def readArgs(self, node): <TAB> res = {} <TAB> for c in self.getChildrenOf(node): <TAB>  <TAB> val = c.getAttribute(""val"") <MASK> res[str(c.nodeName)] = self.modules[val] <TAB>  <TAB> elif val in self.mothers: <TAB>  <TAB>  <TAB> res[str(c.nodeName)] = self.mothers[val] <TAB>  <TAB> elif val != """": <TAB>  <TAB>  <TAB> res[str(c.nodeName)] = eval(val) <TAB> return res",if val in self . modules :,130
"def pop(self, k, default=Sentinel): <TAB> with self._database.transaction(): <TAB>  <TAB> node, is_single = self.convert_node(k) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> res = self[k] <TAB>  <TAB> except KeyError: <MASK> raise <TAB>  <TAB>  <TAB> return default <TAB>  <TAB> del self[node] <TAB> return res",if default is Sentinel :,93
"def wrapped_strategy(self): <TAB> if self.__wrapped_strategy is None: <MASK> raise InvalidArgument( <TAB>  <TAB>  <TAB>  <TAB> f""Expected definition to be a function but got {self.__definition!r} "" <TAB>  <TAB>  <TAB>  <TAB> f""of type {type(self.__definition).__name__} instead."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> result = self.__definition() <TAB>  <TAB> if result is self: <TAB>  <TAB>  <TAB> raise InvalidArgument(""Cannot define a deferred strategy to be itself"") <TAB>  <TAB> check_strategy(result, ""definition()"") <TAB>  <TAB> self.__wrapped_strategy = result <TAB>  <TAB> self.__definition = None <TAB> return self.__wrapped_strategy",if not inspect . isfunction ( self . __definition ) :,160
"def _on_fullscreen_requested(self, on): <TAB> if not config.val.content.fullscreen.window: <MASK> self.state_before_fullscreen = self.windowState() <TAB>  <TAB>  <TAB> self.setWindowState( <TAB>  <TAB>  <TAB>  <TAB> Qt.WindowFullScreen <TAB>  <TAB>  <TAB>  <TAB> | self.state_before_fullscreen  # type: ignore[arg-type] <TAB>  <TAB>  <TAB> )  # type: ignore[operator] <TAB>  <TAB> elif self.isFullScreen(): <TAB>  <TAB>  <TAB> self.setWindowState(self.state_before_fullscreen) <TAB> log.misc.debug( <TAB>  <TAB> ""on: {}, state before fullscreen: {}"".format( <TAB>  <TAB>  <TAB> on, debug.qflags_key(Qt, self.state_before_fullscreen) <TAB>  <TAB> ) <TAB> )",if on :,193
"def update_defaults(self, *values, **kwargs): <TAB> for value in values: <TAB>  <TAB> if type(value) == dict: <TAB>  <TAB>  <TAB> self.DEFAULT_CONFIGURATION.update(value) <TAB>  <TAB> elif isinstance(value, types.ModuleType): <TAB>  <TAB>  <TAB> self.__defaults_from_module(value) <TAB>  <TAB> elif isinstance(value, str): <MASK> self.__defaults_from_file(value) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> logger.warning(""Configuration file {} does not exist."".format(value)) <TAB>  <TAB> elif isinstance(value, type(None)): <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""Cannot interpret {}"".format(value)) <TAB> self.DEFAULT_CONFIGURATION.update(kwargs)",if os . path . exists ( value ) :,184
"def clear_output_directory(self): <TAB> files = os.listdir(os.path.join(""functional"", ""output"")) <TAB> for f in files: <TAB>  <TAB> if f in (""README.txt"", "".svn"", ""CVS""): <TAB>  <TAB>  <TAB> continue  # don't touch the infrastructure <TAB>  <TAB> path = os.path.join(""functional"", ""output"", f) <MASK> shutil.rmtree(path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> os.remove(path)",if os . path . isdir ( path ) :,121
"def do_remove(self): <TAB> if self.netconf.locked(""dhcp""): <MASK> pid = read_pid_file(""/var/run/udhcpd.pan1.pid"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pid = self.pid <TAB>  <TAB> if not kill(pid, ""udhcpd""): <TAB>  <TAB>  <TAB> logging.info(""Stale dhcp lockfile found"") <TAB>  <TAB> self.netconf.unlock(""dhcp"")",if not self . pid :,110
"def __getattr__(self, attr): <TAB> if attr.endswith(""[]""): <TAB>  <TAB> searchName = attr[:-2] <TAB> else: <TAB>  <TAB> searchName = attr <TAB> with _lazyLock: <TAB>  <TAB> nestedClasses = _dependencyMap.get(self.__name__, []) <MASK> return GetVmodlType(self.__name__ + ""."" + attr) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return super(LazyType, self).__getattribute__(attr)",if searchName in nestedClasses :,113
"def allow_request(self, request, view): <TAB> request.server = None <TAB> allow = True <TAB> view_name = view.get_view_name() <TAB> allowed_views = [u""System Data"", u""Collectd Data"", u""Legacy System Data""] <TAB> if view_name in allowed_views: <TAB>  <TAB> server_key = view.kwargs.get(""server_key"") <TAB>  <TAB> server = server_model.get_server_by_key(server_key) <MASK> request.server = server  # Needed in the Models <TAB>  <TAB>  <TAB> server_status = throttle_status(server=server) <TAB>  <TAB>  <TAB> if server_status.allow == False: <TAB>  <TAB>  <TAB>  <TAB> allow = False <TAB> return allow",if server :,173
"def serve_until_stopped(self): <TAB> import select <TAB> abort = 0 <TAB> while not abort: <TAB>  <TAB> rd, wr, ex = select.select([self.socket.fileno()], [], [], self.timeout) <MASK> self.handle_request() <TAB>  <TAB> logging._acquireLock() <TAB>  <TAB> abort = self.abort <TAB>  <TAB> logging._releaseLock()",if rd :,90
"def A(*args): <TAB> if len(args) > 0 and hasattr(args[0], ""__iter__""):  # Iterable as argument <MASK> return np.array(list(args), dtype=np.float32) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Flatten arguments into one list <TAB>  <TAB>  <TAB> l = list(args[0]) <TAB>  <TAB>  <TAB> for e in args[1:]: <TAB>  <TAB>  <TAB>  <TAB> if hasattr(e, ""__iter__""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> l.extend(e) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> l.append(e) <TAB>  <TAB>  <TAB> return np.array(l, dtype=np.float32) <TAB> return np.array(list(args), dtype=np.float32)",if len ( args ) == 1 :,179
"def _fix(self): <TAB> op = [] <TAB> for k in range(self.size): <TAB>  <TAB> o = random.choice(self._opts) <MASK> op.append((o, self.rndstr * 1)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> op.append((o.name, o.randval()._fix())) <TAB> return op",if type ( o ) is str :,92
"def lint_dynamic(self, rule): <TAB> for file in chain(rule.output, rule.input): <MASK> yield Lint( <TAB>  <TAB>  <TAB>  <TAB> title=""The dynamic flag is deprecated"", <TAB>  <TAB>  <TAB>  <TAB> body=""Use checkpoints instead, which are more powerful and less error-prone."", <TAB>  <TAB>  <TAB>  <TAB> links=[links.checkpoints], <TAB>  <TAB>  <TAB> )","if is_flagged ( file , ""dynamic"" ) :",100
"def visit(ignored, dir, files): <TAB> if os.path.basename(dir) not in test_names: <TAB>  <TAB> for name in test_names: <TAB>  <TAB>  <TAB> if name + "".py"" in files: <TAB>  <TAB>  <TAB>  <TAB> path = os.path.join(dir, name + "".py"") <MASK> results.append(path) <TAB>  <TAB> return <TAB> if ""__init__.py"" not in files: <TAB>  <TAB> stderr(""%s is not a package"" % dir) <TAB>  <TAB> return <TAB> for file in files: <TAB>  <TAB> if file.startswith(""test"") and file.endswith("".py""): <TAB>  <TAB>  <TAB> path = os.path.join(dir, file) <TAB>  <TAB>  <TAB> if matcher(path[baselen:]): <TAB>  <TAB>  <TAB>  <TAB> results.append(path)",if matcher ( path [ baselen : ] ) :,194
"def wrapped(*args, **kwargs): <TAB> try: <TAB>  <TAB> func(*args, **kwargs) <TAB> except AssertionError as e: <MASK> time.sleep(t_interval) <TAB>  <TAB>  <TAB> retry_assertion(interval=t_interval, retries=t_retries - 1)(func)( <TAB>  <TAB>  <TAB>  <TAB> *args, **kwargs <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise e",if retries :,98
"def num2binary(l, bits=32): <TAB> all = [] <TAB> bin = """" <TAB> for i in range(bits): <TAB>  <TAB> if l & 0x1: <TAB>  <TAB>  <TAB> bin = ""1"" + bin <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> bin = ""0"" + bin <TAB>  <TAB> l = l >> 1 <MASK> all.append(bin) <TAB>  <TAB>  <TAB> bin = """" <TAB> if bin: <TAB>  <TAB> all.append(bin) <TAB> all.reverse() <TAB> assert l in (0, -1), ""number doesn't fit in number of bits"" <TAB> return string.join(all, "" "")",if not ( ( i + 1 ) % 8 ) :,158
"def closest_enemy_ant(self, row1, col1, filter=None): <TAB> # find the closest enemy ant from this row/col <TAB> min_dist = maxint <TAB> closest_ant = None <TAB> for ant in self.enemy_ants(): <TAB>  <TAB> if filter is None or ant not in filter: <TAB>  <TAB>  <TAB> dist = self.distance(row1, col1, ant[0][0], ant[0][1]) <MASK> min_dist = dist <TAB>  <TAB>  <TAB>  <TAB> closest_ant = ant[0] <TAB> return closest_ant",if dist < min_dist :,146
"def _wrap(cls, parent, value): <TAB> if isinstance(value, dict): <TAB>  <TAB> # we know that `annotations` and `labels` are dicts and therefore don't want to convert them into K8sObject <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB> value <MASK> and all(isinstance(v, six.string_types) for v in value.values()) <TAB>  <TAB>  <TAB> else cls(value) <TAB>  <TAB> ) <TAB> elif isinstance(value, list): <TAB>  <TAB> return [cls._wrap(None, v) for v in value] <TAB> else: <TAB>  <TAB> return value","if parent in { ""annotations"" , ""labels"" }",145
"def do_definition(tag): <TAB> w.end_para() <TAB> macro("".TP"") <TAB> w.started = True <TAB> split = 0 <TAB> pre = [] <TAB> post = [] <TAB> for typ, text in _bitlist(tag): <MASK> post.append((typ, text)) <TAB>  <TAB> elif text.lstrip().startswith("": ""): <TAB>  <TAB>  <TAB> split = 1 <TAB>  <TAB>  <TAB> post.append((typ, text.lstrip()[2:].lstrip())) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pre.append((typ, text)) <TAB> _boldline(pre) <TAB> w.write(_text(post)) <TAB> w.started = False",if split :,153
"def updateTree(self, v, x, y, h, level): <TAB> yfirst = y <TAB> if level == 0: <TAB>  <TAB> yfirst += 10 <TAB> while v: <TAB>  <TAB> # g.trace(x,y,v) <TAB>  <TAB> h, indent = self.updateNode(v, x, y) <TAB>  <TAB> y += h <MASK> y = self.updateTree(v.firstChild(), x + indent, y, h, level + 1) <TAB>  <TAB> v = v.next() <TAB> return y",if v . isExpanded ( ) and v . firstChild ( ) :,138
def loop(self): <TAB> while True: <TAB>  <TAB> job = self.check_queue() <MASK> time.sleep(20) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> self.run_job(job) <TAB>  <TAB> time.sleep(5),if not job :,64
"def _name_to_variable(self, name): <TAB> r""""""Find the corresponding variable given the specified name."""""" <TAB> pointer = self <TAB> for m_name in name.split("".""): <MASK> num = int(m_name) <TAB>  <TAB>  <TAB> pointer = pointer[num]  # type: ignore <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pointer = getattr(pointer, m_name) <TAB> return pointer  # type: ignore",if m_name . isdigit ( ) :,107
"def fetch_cleanup(self): <TAB> for cell in self.cover_cells: <MASK> log.debug( <TAB>  <TAB>  <TAB>  <TAB> ""Removing cover art fetch task for %s"", <TAB>  <TAB>  <TAB>  <TAB> cell.release[""musicbrainz_albumid""], <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.tagger.webservice.remove_task(cell.fetch_task)",if cell . fetch_task is not None :,95
"def _get_lcmap_info(self, vol_name): <TAB> ret_vals = { <TAB>  <TAB> ""fc_id"": """", <TAB>  <TAB> ""fc_name"": """", <TAB>  <TAB> ""lc_map_count"": ""0"", <TAB> } <TAB> for lcmap in self._lcmappings_list.values(): <MASK> ret_vals[""fc_id""] = lcmap[""id""] <TAB>  <TAB>  <TAB> ret_vals[""fc_name""] = lcmap[""name""] <TAB>  <TAB>  <TAB> ret_vals[""lc_map_count""] = ""1"" <TAB> return ret_vals","if ( lcmap [ ""source"" ] == vol_name ) or ( lcmap [ ""target"" ] == vol_name ) :",159
"def on_event_clicked(self, widget, event): <TAB> if event.type == Gdk.EventType.BUTTON_PRESS and event.button == 3: <TAB>  <TAB> path = self.get_path_at_pos(int(event.x), int(event.y)) <TAB>  <TAB> if path is not None: <TAB>  <TAB>  <TAB> row = self.get(path[0], ""device"") <TAB>  <TAB>  <TAB> if row: <MASK> if self.menu is None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.menu = ManagerDeviceMenu(self.Blueman) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.menu.popup(None, None, None, None, event.button, event.time)",if self . Blueman is not None :,170
"def _find_node_with_predicate(self, node, predicate): <TAB> if node != self._tree._root and predicate(node): <TAB>  <TAB> return node <TAB> item, cookie = self._tree.GetFirstChild(node) <TAB> while item: <TAB>  <TAB> if predicate(item): <TAB>  <TAB>  <TAB> return item <MASK> result = self._find_node_with_predicate(item, predicate) <TAB>  <TAB>  <TAB> if result: <TAB>  <TAB>  <TAB>  <TAB> return result <TAB>  <TAB> item, cookie = self._tree.GetNextChild(node, cookie) <TAB> return None",if self . _tree . ItemHasChildren ( item ) :,143
"def expect_flow_sequence_item(self): <TAB> if isinstance(self.event, SequenceEndEvent): <TAB>  <TAB> self.indent = self.indents.pop() <TAB>  <TAB> self.flow_level -= 1 <TAB>  <TAB> if self.canonical: <TAB>  <TAB>  <TAB> self.write_indicator(u"","", False) <TAB>  <TAB>  <TAB> self.write_indent() <TAB>  <TAB> self.write_indicator(u""]"", False) <TAB>  <TAB> self.state = self.states.pop() <TAB> else: <TAB>  <TAB> self.write_indicator(u"","", False) <MASK> self.write_indent() <TAB>  <TAB> self.states.append(self.expect_flow_sequence_item) <TAB>  <TAB> self.expect_node(sequence=True)",if self . canonical or self . column > self . best_width :,185
"def iteration(pts): <TAB> n = len(pts) <TAB> all_pts = pts + invert(pts) <TAB> diagram = Voronoi(all_pts) <TAB> vertices = restrict(diagram.vertices) <TAB> centers = [] <TAB> for site_idx in range(n): <TAB>  <TAB> region_idx = diagram.point_region[site_idx] <TAB>  <TAB> region = diagram.regions[region_idx] <MASK> site = pts[site_idx] <TAB>  <TAB>  <TAB> centers.append(site) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> region_verts = np.array([vertices[i] for i in region]) <TAB>  <TAB> center = weighted_center(region_verts, weight_field) <TAB>  <TAB> centers.append(tuple(center)) <TAB> return centers",if - 1 in region :,185
"def retry_call(self, key, f, time_expire, with_lock): <TAB> self.RETRIES += 1 <TAB> if self.RETRIES <= self.MAX_RETRIES: <MASK> self.RETRIES = 0 <TAB>  <TAB>  <TAB> return f() <TAB>  <TAB> logger.error(""sleeping %s seconds before reconnecting"" % (2 * self.RETRIES)) <TAB>  <TAB> time.sleep(2 * self.RETRIES) <TAB>  <TAB> return self.__call__(key, f, time_expire, with_lock) <TAB> else: <TAB>  <TAB> self.RETRIES = 0 <TAB>  <TAB> if self.fail_gracefully: <TAB>  <TAB>  <TAB> return f <TAB>  <TAB> raise RConnectionError(""Redis instance is unavailable"")",if self . fail_gracefully :,165
"def load_model( <TAB> self, model_name: str, path: str = None, model_type=None) -> AbstractModel: <TAB> if isinstance(model_name, AbstractModel): <TAB>  <TAB> return model_name <TAB> if model_name in self.models.keys(): <TAB>  <TAB> return self.models[model_name] <TAB> else: <MASK> path = self.get_model_attribute(model=model_name, attribute=""path"") <TAB>  <TAB> if model_type is None: <TAB>  <TAB>  <TAB> model_type = self.get_model_attribute(model=model_name, attribute=""type"") <TAB>  <TAB> return model_type.load(path=path, reset_paths=self.reset_paths)",if path is None :,170
"def _GetPathType( <TAB> args: rdf_artifacts.ArtifactCollectorFlowArgs, client_os: str) -> rdf_paths.PathSpec.PathType: <TAB> if args.use_tsk or args.use_raw_filesystem_access: <MASK> return config.CONFIG[""Server.raw_filesystem_access_pathtype""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return rdf_paths.PathSpec.PathType.TSK <TAB> else: <TAB>  <TAB> return rdf_paths.PathSpec.PathType.OS","if client_os == ""Windows"" :",128
"def iter_links(self): <TAB> # type: () -> Iterable[Link] <TAB> """"""Yields all links in the page"""""" <TAB> document = html5lib.parse( <TAB>  <TAB> self.content, <TAB>  <TAB> transport_encoding=_get_encoding_from_headers(self.headers), <TAB>  <TAB> namespaceHTMLElements=False, <TAB> ) <TAB> base_url = _determine_base_url(document, self.url) <TAB> for anchor in document.findall("".//a""): <TAB>  <TAB> link = _create_link_from_element( <TAB>  <TAB>  <TAB> anchor, <TAB>  <TAB>  <TAB> page_url=self.url, <TAB>  <TAB>  <TAB> base_url=base_url, <TAB>  <TAB> ) <MASK> continue <TAB>  <TAB> yield link",if link is None :,175
"def on_leave( <TAB> self, original_node: CSTNodeT, updated_node: CSTNodeT) -> Union[cst.Import, cst.ImportFrom, CSTNodeT, RemovalSentinel]: <TAB> if isinstance(updated_node, cst.Import): <TAB>  <TAB> for alias in updated_node.names: <TAB>  <TAB>  <TAB> name = alias.name <MASK> return cst.RemoveFromParent() <TAB> elif isinstance(updated_node, cst.ImportFrom): <TAB>  <TAB> module = updated_node.module <TAB>  <TAB> if isinstance(module, cst.Name) and module.value == ""e"": <TAB>  <TAB>  <TAB> return cst.RemoveFromParent() <TAB> return updated_node","if isinstance ( name , cst . Name ) and name . value == ""b"" :",183
"def http_request(self, request): <TAB> ntlm_auth_header = request.get_header(self.auth_header, None) <TAB> if ntlm_auth_header is None: <TAB>  <TAB> user, pw = self.passwd.find_user_password(None, request.get_full_url()) <MASK> auth = ""NTLM %s"" % ntlm.create_NTLM_NEGOTIATE_MESSAGE(user) <TAB>  <TAB>  <TAB> request.add_unredirected_header(self.auth_header, auth) <TAB> return request",if pw is not None :,137
"def _parse_yum_or_zypper_repositories(output): <TAB> repos = [] <TAB> current_repo = {} <TAB> for line in output: <TAB>  <TAB> line = line.strip() <MASK> continue <TAB>  <TAB> if line.startswith(""[""): <TAB>  <TAB>  <TAB> if current_repo: <TAB>  <TAB>  <TAB>  <TAB> repos.append(current_repo) <TAB>  <TAB>  <TAB>  <TAB> current_repo = {} <TAB>  <TAB>  <TAB> current_repo[""name""] = line[1:-1] <TAB>  <TAB> if current_repo and ""="" in line: <TAB>  <TAB>  <TAB> key, value = line.split(""="", 1) <TAB>  <TAB>  <TAB> current_repo[key] = value <TAB> if current_repo: <TAB>  <TAB> repos.append(current_repo) <TAB> return repos","if not line or line . startswith ( ""#"" ) :",179
"def load_as_uint8(filename): <TAB> image = gdal.Open(filename) <TAB> image_array = np.array(image.ReadAsArray()) <TAB> image_uint8 = np.zeros(image_array.shape, dtype=np.uint8) <TAB> # rescale each band to be between 0, 255 <TAB> for k, band in enumerate(image_array): <TAB>  <TAB> band_max = np.max(band) <MASK> band = band.astype(np.float) / band_max * 255.0 <TAB>  <TAB> image_uint8[k, :, :] = band <TAB> return image_uint8",if band_max != 0 :,153
"def _get_resource_group_name_of_staticsite(client, static_site_name): <TAB> static_sites = client.list() <TAB> for static_site in static_sites: <TAB>  <TAB> if static_site.name.lower() == static_site_name.lower(): <TAB>  <TAB>  <TAB> resource_group = _parse_resource_group_from_arm_id(static_site.id) <MASK> return resource_group <TAB> raise CLIError( <TAB>  <TAB> ""Static site was '{}' not found in subscription."".format(static_site_name) <TAB> )",if resource_group :,144
"def _translate_trace_addr(self, trace_addr, obj=None): <TAB> if obj is None: <TAB>  <TAB> for obj in self._aslr_slides:  # pylint: disable=redefined-argument-from-local <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception(""Can't figure out which object this address belongs to"") <TAB> if obj not in self._aslr_slides: <TAB>  <TAB> raise Exception(""Internal error: object is untranslated"") <TAB> return trace_addr - self._aslr_slides[obj]",if obj . contains_addr ( trace_addr - self . _aslr_slides [ obj ] ) :,149
"def _register_builtin_handlers(self, events): <TAB> for spec in handlers.BUILTIN_HANDLERS: <TAB>  <TAB> if len(spec) == 2: <TAB>  <TAB>  <TAB> event_name, handler = spec <TAB>  <TAB>  <TAB> self.register(event_name, handler) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> event_name, handler, register_type = spec <MASK> self._events.register_first(event_name, handler) <TAB>  <TAB>  <TAB> elif register_type is handlers.REGISTER_LAST: <TAB>  <TAB>  <TAB>  <TAB> self._events.register_last(event_name, handler)",if register_type is handlers . REGISTER_FIRST :,148
"def __fixdict(self, dict): <TAB> for key in dict.keys(): <TAB>  <TAB> if key[:6] == ""start_"": <TAB>  <TAB>  <TAB> tag = key[6:] <TAB>  <TAB>  <TAB> start, end = self.elements.get(tag, (None, None)) <MASK> self.elements[tag] = getattr(self, key), end <TAB>  <TAB> elif key[:4] == ""end_"": <TAB>  <TAB>  <TAB> tag = key[4:] <TAB>  <TAB>  <TAB> start, end = self.elements.get(tag, (None, None)) <TAB>  <TAB>  <TAB> if end is None: <TAB>  <TAB>  <TAB>  <TAB> self.elements[tag] = start, getattr(self, key)",if start is None :,162
"def metadata(draft): <TAB> test_metadata = {} <TAB> json_schema = create_jsonschema_from_metaschema(draft.registration_schema.schema) <TAB> for key, value in json_schema[""properties""].items(): <TAB>  <TAB> response = ""Test response"" <TAB>  <TAB> items = value[""properties""][""value""].get(""items"") <TAB>  <TAB> enum = value[""properties""][""value""].get(""enum"") <TAB>  <TAB> if items:  # multiselect <TAB>  <TAB>  <TAB> response = [items[""enum""][0]] <MASK> # singleselect <TAB>  <TAB>  <TAB> response = enum[0] <TAB>  <TAB> elif value[""properties""][""value""].get(""properties""): <TAB>  <TAB>  <TAB> response = {""question"": {""value"": ""Test Response""}} <TAB>  <TAB> test_metadata[key] = {""value"": response} <TAB> return test_metadata",elif enum :,185
"def par_iter_next_batch(self, batch_ms: int): <TAB> """"""Batches par_iter_next."""""" <TAB> batch = [] <TAB> if batch_ms == 0: <TAB>  <TAB> batch.append(self.par_iter_next()) <TAB>  <TAB> return batch <TAB> t_end = time.time() + (0.001 * batch_ms) <TAB> while time.time() < t_end: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> batch.append(self.par_iter_next()) <TAB>  <TAB> except StopIteration: <MASK> raise StopIteration <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB> return batch",if len ( batch ) == 0 :,157
"def get_node_map(self, nodes: List[Node], left_node_only=True): <TAB> node_map = {} <TAB> idx = 0 <TAB> for node in nodes: <MASK> continue <TAB>  <TAB> node_map[node.id] = idx <TAB>  <TAB> idx += 1 <TAB> return node_map",if node . id != 0 and ( not node . is_left_node and left_node_only ) :,99
"def compare_objects(left, right): <TAB> left_fields = left.map_value.fields <TAB> right_fields = right.map_value.fields <TAB> for left_key, right_key in zip(sorted(left_fields), sorted(right_fields)): <TAB>  <TAB> keyCompare = Order._compare_to(left_key, right_key) <MASK> return keyCompare <TAB>  <TAB> value_compare = Order.compare(left_fields[left_key], right_fields[right_key]) <TAB>  <TAB> if value_compare != 0: <TAB>  <TAB>  <TAB> return value_compare <TAB> return Order._compare_to(len(left_fields), len(right_fields))",if keyCompare != 0 :,163
"def _resolve_policy_id(cmd, policy, policy_set_definition, client): <TAB> policy_id = policy or policy_set_definition <TAB> if not is_valid_resource_id(policy_id): <MASK> policy_def = _get_custom_or_builtin_policy(cmd, client, policy) <TAB>  <TAB>  <TAB> policy_id = policy_def.id <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> policy_set_def = _get_custom_or_builtin_policy( <TAB>  <TAB>  <TAB>  <TAB> cmd, client, policy_set_definition, None, None, True <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> policy_id = policy_set_def.id <TAB> return policy_id",if policy :,166
"def _passes_cortex_depth(line, min_depth): <TAB> """"""Do any genotypes in the cortex_var VCF line passes the minimum depth requirement?"""""" <TAB> parts = line.split(""\t"") <TAB> cov_index = parts[8].split("":"").index(""COV"") <TAB> passes_depth = False <TAB> for gt in parts[9:]: <TAB>  <TAB> cur_cov = gt.split("":"")[cov_index] <TAB>  <TAB> cur_depth = sum(int(x) for x in cur_cov.split("","")) <MASK> passes_depth = True <TAB> return passes_depth",if cur_depth >= min_depth :,149
"def __init__(self, itemtype, cnf={}, *, master=None, **kw): <MASK> if ""refwindow"" in kw: <TAB>  <TAB>  <TAB> master = kw[""refwindow""] <TAB>  <TAB> elif ""refwindow"" in cnf: <TAB>  <TAB>  <TAB> master = cnf[""refwindow""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> master = tkinter._default_root <TAB>  <TAB>  <TAB> if not master: <TAB>  <TAB>  <TAB>  <TAB> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Too early to create display style: "" ""no root window"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> self.tk = master.tk <TAB> self.stylename = self.tk.call(""tixDisplayStyle"", itemtype, *self._options(cnf, kw))",if not master :,167
"def serialize_groups_for_summary(node): <TAB> groups = node.osf_groups <TAB> n_groups = len(groups) <TAB> group_string = """" <TAB> for index, group in enumerate(groups): <MASK> separator = """" <TAB>  <TAB> elif index == n_groups - 2: <TAB>  <TAB>  <TAB> separator = "" & "" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> separator = "", "" <TAB>  <TAB> group_string = group_string + group.name + separator <TAB> return group_string",if index == n_groups - 1 :,125
"def do(txn): <TAB> txn.execute( <TAB>  <TAB> ""SELECT valid_to, mode, caseset, spec FROM testspec WHERE id = ?"", [specId] <TAB> ) <TAB> row = txn.fetchone() <TAB> if row is None: <TAB>  <TAB> raise Exception(""no test specification with ID '%s'"" % specId) <TAB> else: <TAB>  <TAB> validTo, mode, caseset, spec = row <TAB>  <TAB> if validTo is not None: <TAB>  <TAB>  <TAB> raise Exception(""test spec no longer active"") <MASK> raise Exception(""case set %s not loaded in database"" % caseset) <TAB>  <TAB> spec = json.loads(spec) <TAB>  <TAB> res = self._css[caseset].generateCasesByTestee(spec) <TAB>  <TAB> return res",if not self . _css . has_key ( caseset ) :,188
"def get_and_set_titles(self): <TAB> all_titles = [] <TAB> for page in self.pages: <TAB>  <TAB> if page.orig_phrase != """": <TAB>  <TAB>  <TAB> all_titles.append(page.orig_phrase) <TAB>  <TAB>  <TAB> all_titles.append(page.orig_phrase_norm) <MASK> all_titles.append(page.wiki_title) <TAB>  <TAB>  <TAB> all_titles.append(page.wiki_title_norm) <TAB> return set(all_titles)","if page . wiki_title != """" :",127
"def spool_print(*args, **kwargs): <TAB> with _print_lock: <MASK> framework.Framework._spool.write(f""{args[0]}{os.linesep}"") <TAB>  <TAB>  <TAB> framework.Framework._spool.flush() <TAB>  <TAB> # disable terminal output for server jobs <TAB>  <TAB> if framework.Framework._mode == Mode.JOB: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> # new print function must still use the old print function via the backup <TAB>  <TAB> builtins._print(*args, **kwargs)",if framework . Framework . _spool :,126
"def matches(self, filepath): <TAB> matched = False <TAB> parent_path = os.path.dirname(filepath) <TAB> parent_path_dirs = split_path(parent_path) <TAB> for pattern in self.patterns: <TAB>  <TAB> negative = pattern.exclusion <TAB>  <TAB> match = pattern.match(filepath) <MASK> if len(pattern.dirs) <= len(parent_path_dirs): <TAB>  <TAB>  <TAB>  <TAB> match = pattern.match( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> os.path.sep.join(parent_path_dirs[: len(pattern.dirs)]) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if match: <TAB>  <TAB>  <TAB> matched = not negative <TAB> return matched","if not match and parent_path != """" :",165
"def __str__(self, prefix="""", printElemNumber=0): <TAB> res = """" <TAB> cnt = 0 <TAB> for e in self.task_: <TAB>  <TAB> elm = """" <MASK> elm = ""(%d)"" % cnt <TAB>  <TAB> res += prefix + (""Task%s {\n"" % elm) <TAB>  <TAB> res += e.__str__(prefix + ""  "", printElemNumber) <TAB>  <TAB> res += prefix + ""}\n"" <TAB>  <TAB> cnt += 1 <TAB> return res",if printElemNumber :,118
"def when(self, matches, context): <TAB> ret = [] <TAB> for to_check in matches.range( <TAB>  <TAB> predicate=lambda match: ""has-neighbor-before"" in match.tags <TAB> ): <TAB>  <TAB> next_match = matches.next(to_check, index=0) <TAB>  <TAB> next_group = matches.markers.next( <TAB>  <TAB>  <TAB> to_check, lambda marker: marker.name == ""group"", 0 <TAB>  <TAB> ) <MASK> next_match = next_group <TAB>  <TAB> if next_match and not matches.input_string[ <TAB>  <TAB>  <TAB> to_check.end : next_match.start <TAB>  <TAB> ].strip(seps): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> ret.append(to_check) <TAB> return ret",if next_group and ( not next_match or next_group . start < next_match . start ) :,198
"def get_coeffs(e): <TAB> coeffs = [] <TAB> for du in all_delu_dict.keys(): <TAB>  <TAB> if type(self.as_coeffs_dict[e]).__name__ == ""float"": <TAB>  <TAB>  <TAB> coeffs.append(self.as_coeffs_dict[e]) <MASK> coeffs.append(self.as_coeffs_dict[e][du]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> coeffs.append(0) <TAB> return np.array(coeffs)",elif du in self . as_coeffs_dict [ e ] . keys ( ) :,132
"def clean(self): <TAB> username = self.cleaned_data.get(""username"") <TAB> password = self.cleaned_data.get(""password"") <TAB> message = ERROR_MESSAGE <TAB> if username and password: <TAB>  <TAB> self.user_cache = authenticate(username=username, password=password) <TAB>  <TAB> if self.user_cache is None: <TAB>  <TAB>  <TAB> raise ValidationError( <TAB>  <TAB>  <TAB>  <TAB> message % {""username"": self.username_field.verbose_name} <TAB>  <TAB>  <TAB> ) <MASK> raise ValidationError( <TAB>  <TAB>  <TAB>  <TAB> message % {""username"": self.username_field.verbose_name} <TAB>  <TAB>  <TAB> ) <TAB> return self.cleaned_data",elif not self . user_cache . is_active or not self . user_cache . is_staff :,177
"def moveFailedFolder(filepath, failed_folder): <TAB> if config.Config().failed_move(): <TAB>  <TAB> root_path = str(pathlib.Path(filepath).parent) <TAB>  <TAB> file_name = pathlib.Path(filepath).name <TAB>  <TAB> destination_path = root_path + ""/"" + failed_folder + ""/"" <MASK> print(""[-]Create symlink to Failed output folder"") <TAB>  <TAB>  <TAB> os.symlink(filepath, destination_path + ""/"" + file_name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""[-]Move to Failed output folder"") <TAB>  <TAB>  <TAB> shutil.move(filepath, destination_path) <TAB> return",if config . Config ( ) . soft_link ( ) :,155
"def test_save_mp3(self, test_mode, bit_rate): <TAB> if test_mode in [""fileobj"", ""bytesio""]: <MASK> raise unittest.SkipTest( <TAB>  <TAB>  <TAB>  <TAB> ""mp3 format with variable bit rate is known to "" <TAB>  <TAB>  <TAB>  <TAB> ""not yield the exact same result as sox command."" <TAB>  <TAB>  <TAB> ) <TAB> self.assert_save_consistency(""mp3"", compression=bit_rate, test_mode=test_mode)",if bit_rate is not None and bit_rate < 1 :,125
"def _upstream_nodes_executed(self, node: pipeline_pb2.PipelineNode) -> bool: <TAB> """"""Returns `True` if all the upstream nodes have been successfully executed."""""" <TAB> upstream_nodes = [ <TAB>  <TAB> node <TAB>  <TAB> for node_id, node in self._node_map.items() <TAB>  <TAB> if node_id in set(node.upstream_nodes) <TAB> ] <TAB> if not upstream_nodes: <TAB>  <TAB> return True <TAB> for node in upstream_nodes: <TAB>  <TAB> upstream_node_executions = task_gen_utils.get_executions( <TAB>  <TAB>  <TAB> self._mlmd_handle, node <TAB>  <TAB> ) <MASK> return False <TAB> return True",if not task_gen_utils . is_latest_execution_successful ( upstream_node_executions ) :,189
"def reinit(): <TAB> for name, var in _ns_registry._registry[u""pixie.stdlib""]._registry.iteritems(): <TAB>  <TAB> name = munge(name) <MASK> continue <TAB>  <TAB> if var.is_defined() and isinstance(var.deref(), BaseCode): <TAB>  <TAB>  <TAB> globals()[name] = unwrap(var) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> globals()[name] = var",if name in globals ( ) :,102
"def i2repr(self, pkt, x): <TAB> if type(x) is list or type(x) is tuple: <TAB>  <TAB> return repr(x) <MASK> r = [] <TAB> else: <TAB>  <TAB> r = """" <TAB> i = 0 <TAB> while x: <TAB>  <TAB> if x & 1: <TAB>  <TAB>  <TAB> if self.multi: <TAB>  <TAB>  <TAB>  <TAB> r += [self.names[i]] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> r += self.names[i] <TAB>  <TAB> i += 1 <TAB>  <TAB> x >>= 1 <TAB> if self.multi: <TAB>  <TAB> r = ""+"".join(r) <TAB> return r",if self . multi :,154
"def prompts_dict(self, *args, **kwargs): <TAB> r = super(WorkflowJobNode, self).prompts_dict(*args, **kwargs) <TAB> # Explanation - WFJT extra_vars still break pattern, so they are not <TAB> # put through prompts processing, but inventory and others are only accepted <TAB> # if JT prompts for it, so it goes through this mechanism <TAB> if self.workflow_job: <TAB>  <TAB> if self.workflow_job.inventory_id: <TAB>  <TAB>  <TAB> # workflow job inventory takes precedence <TAB>  <TAB>  <TAB> r[""inventory""] = self.workflow_job.inventory <MASK> r.update(self.workflow_job.char_prompts) <TAB> return r",if self . workflow_job . char_prompts :,175
"def did_evm_write_storage_callback(self, state, address, offset, value): <TAB> # if in potential DAO check that write to storage values read before <TAB> # the ""send"" <TAB> for location, reads in self._get_location_and_reads(state): <TAB>  <TAB> for address_i, offset_i in reads: <TAB>  <TAB>  <TAB> if address_i == address: <MASK> self.add_finding(state, *location)",if state . can_be_true ( offset == offset_i ) :,128
"def update_quality_inspection(self): <TAB> if self.inspection_required: <TAB>  <TAB> reference_type = reference_name = """" <MASK> reference_name = self.name <TAB>  <TAB>  <TAB> reference_type = ""Stock Entry"" <TAB>  <TAB> for d in self.items: <TAB>  <TAB>  <TAB> if d.quality_inspection: <TAB>  <TAB>  <TAB>  <TAB> frappe.db.set_value( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Quality Inspection"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> d.quality_inspection, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""reference_type"": reference_type, <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""reference_name"": reference_name, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> }, <TAB>  <TAB>  <TAB>  <TAB> )",if self . docstatus == 1 :,178
"def _target(self): <MASK> self.setup.push_thread() <TAB> try: <TAB>  <TAB> while self.running: <TAB>  <TAB>  <TAB> record = self.subscriber.recv() <TAB>  <TAB>  <TAB> if record: <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.queue.put(record, timeout=0.05) <TAB>  <TAB>  <TAB>  <TAB> except Full: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass <TAB> finally: <TAB>  <TAB> if self.setup is not None: <TAB>  <TAB>  <TAB> self.setup.pop_thread()",if self . setup is not None :,128
"def check(self): <TAB> global MySQLdb <TAB> import MySQLdb <TAB> try: <TAB>  <TAB> args = {} <MASK> args[""user""] = mysql_user <TAB>  <TAB> if mysql_pwd: <TAB>  <TAB>  <TAB> args[""passwd""] = mysql_pwd <TAB>  <TAB> if mysql_host: <TAB>  <TAB>  <TAB> args[""host""] = mysql_host <TAB>  <TAB> if mysql_port: <TAB>  <TAB>  <TAB> args[""port""] = mysql_port <TAB>  <TAB> if mysql_socket: <TAB>  <TAB>  <TAB> args[""unix_socket""] = mysql_socket <TAB>  <TAB> self.db = MySQLdb.connect(**args) <TAB> except Exception as e: <TAB>  <TAB> raise Exception(""Cannot interface with MySQL server: %s"" % e)",if mysql_user :,167
"def writeBool(self, bool): <TAB> if self.state == BOOL_WRITE: <MASK> ctype = CompactType.TRUE <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ctype = CompactType.FALSE <TAB>  <TAB> self.__writeFieldHeader(ctype, self.__bool_fid) <TAB> elif self.state == CONTAINER_WRITE: <TAB>  <TAB> if bool: <TAB>  <TAB>  <TAB> self.__writeByte(CompactType.TRUE) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.__writeByte(CompactType.FALSE) <TAB> else: <TAB>  <TAB> raise AssertionError(""Invalid state in compact protocol"")",if bool :,141
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.set_module(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 18: <TAB>  <TAB>  <TAB> self.set_version(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 24: <TAB>  <TAB>  <TAB> self.set_instances(d.getVarInt64()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 10 :,150
"def init_panel(self): <TAB> if not hasattr(self, ""output_view""): <MASK> self.output_view = self.window.create_output_panel(""markdown"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.output_view = self.window.get_output_panel(""markdown"")",if is_ST3 ( ) :,79
"def sql(self, engine): <TAB> adapter = get_adapter(engine) <TAB> tokens = [self.name, adapter.type_to_sql(self.type, self.limit)] <TAB> for k, v in self.options.items(): <TAB>  <TAB> result = adapter.column_option_to_sql(self.name, k, v) <MASK> continue <TAB>  <TAB> elif isinstance(result, dict):  # a way for column options to add constraints <TAB>  <TAB>  <TAB> self.constraints.append(result[""constraint""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tokens.append(result) <TAB> return "" "".join(tokens)",if result is None :,150
def get_igst_invoices(self): <TAB> self.igst_invoices = [] <TAB> for d in self.tax_details: <TAB>  <TAB> is_igst = True if d[1] in self.gst_accounts.igst_account else False <MASK> self.igst_invoices.append(d[0]),if is_igst and d [ 0 ] not in self . igst_invoices :,102
"def updateParticle(part, best, phi1, phi2): <TAB> u1 = numpy.random.uniform(0, phi1, len(part)) <TAB> u2 = numpy.random.uniform(0, phi2, len(part)) <TAB> v_u1 = u1 * (part.best - part) <TAB> v_u2 = u2 * (best - part) <TAB> part.speed += v_u1 + v_u2 <TAB> for i, speed in enumerate(part.speed): <TAB>  <TAB> if abs(speed) < part.smin: <TAB>  <TAB>  <TAB> part.speed[i] = math.copysign(part.smin, speed) <MASK> part.speed[i] = math.copysign(part.smax, speed) <TAB> part += part.speed",elif abs ( speed ) > part . smax :,197
"def summaries_with_matching_keyword(keyword, summary_dir): <TAB> """"""Yields summary protos matching given keyword from event file."""""" <TAB> event_paths = tf.io.gfile.glob(os.path.join(summary_dir, ""events*"")) <TAB> for event in tf.compat.v1.train.summary_iterator(event_paths[-1]): <MASK> for value in event.summary.value: <TAB>  <TAB>  <TAB>  <TAB> if keyword in value.tag: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> logging.error(event) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield event.summary",if event . summary is not None :,139
"def _RemoveToken(self, doc_id, token): <TAB> """"""Removes a token occurrence for a document."""""" <TAB> if token in self._inverted_index: <TAB>  <TAB> postings = self._inverted_index[token] <TAB>  <TAB> postings.Remove(doc_id, token.position) <MASK> del self._inverted_index[token]",if not postings . postings :,90
"def check_recursive_filters(self, space, name): <TAB> for the_filter in self.filterdb.get_filters(space): <TAB>  <TAB> for rule in the_filter.get_rules(): <TAB>  <TAB>  <TAB> values = list(rule.values()) <MASK> return True <TAB> return False","if issubclass ( rule . __class__ , MatchesFilterBase ) and ( name in values ) :",91
"def main(): <TAB> for filename in sys.argv[1:]: <TAB>  <TAB> if os.path.isdir(filename): <TAB>  <TAB>  <TAB> print(filename, ""Directory!"") <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> with open(filename, ""rb"") as f: <TAB>  <TAB>  <TAB> data = f.read() <MASK> print(filename, ""Binary!"") <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> newdata = data.replace(b""\r\n"", b""\n"") <TAB>  <TAB> if newdata != data: <TAB>  <TAB>  <TAB> print(filename) <TAB>  <TAB>  <TAB> with open(filename, ""wb"") as f: <TAB>  <TAB>  <TAB>  <TAB> f.write(newdata)","if b""\0"" in data :",157
"def fit(self, dataset, intent): <TAB> self.language = dataset[""language""] <TAB> self.slots_keywords = dict() <TAB> utterances = dataset[""intents""][intent][""utterances""] <TAB> for utterance in utterances: <TAB>  <TAB> for chunk in utterance[""data""]: <MASK> text = chunk[""text""] <TAB>  <TAB>  <TAB>  <TAB> if self.config.get(""lowercase"", False): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> text = text.lower() <TAB>  <TAB>  <TAB>  <TAB> self.slots_keywords[text] = [chunk[""entity""], chunk[""slot_name""]] <TAB> return self","if ""slot_name"" in chunk :",141
"def linkGradient(self, slaveGradient, connect=True): <TAB> if connect: <TAB>  <TAB> fn = lambda g, slave=slaveGradient: slave.restoreState(g.saveState()) <TAB>  <TAB> self.linkedGradients[id(slaveGradient)] = fn <TAB>  <TAB> self.sigGradientChanged.connect(fn) <TAB>  <TAB> self.sigGradientChanged.emit(self) <TAB> else: <TAB>  <TAB> fn = self.linkedGradients.get(id(slaveGradient), None) <MASK> self.sigGradientChanged.disconnect(fn)",if fn :,129
"def _get_field_values(serial_str, field_name): <TAB> ret_list = [] <TAB> stream = StringIO(serial_str) <TAB> for obj_dict in yaml.safe_load(stream): <MASK> field_value = obj_dict[""fields""][field_name] <TAB>  <TAB>  <TAB> # yaml.safe_load will return non-string objects for some <TAB>  <TAB>  <TAB> # of the fields we are interested in, this ensures that <TAB>  <TAB>  <TAB> # everything comes back as a string <TAB>  <TAB>  <TAB> if isinstance(field_value, six.string_types): <TAB>  <TAB>  <TAB>  <TAB> ret_list.append(field_value) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> ret_list.append(str(field_value)) <TAB> return ret_list","if ""fields"" in obj_dict and field_name in obj_dict [ ""fields"" ] :",195
"def scrapeHeadlines(text): <TAB> headlines = """" <TAB> lines = text.splitlines() <TAB> for line in lines: <TAB>  <TAB> if string.find(line, ""<a href"") == 0: <TAB>  <TAB>  <TAB> pos1 = string.find(line, ""<b>"") <TAB>  <TAB>  <TAB> if pos1 > 0: <TAB>  <TAB>  <TAB>  <TAB> pos2 = string.find(line, ""</b>"") <MASK> headlines += line[pos1 + len(""<b>"") : pos2] + "".\n"" <TAB> return headlines",if pos2 > 0 :,133
"def getCVEActions(self, cve, **args): <TAB> actions = [] <TAB> for plugin in self.getWebPlugins(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> actions_ = plugin.getCVEActions(cve, **args) <MASK> for action in actions_: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> action[""auth""] = plugin.requiresAuth <TAB>  <TAB>  <TAB>  <TAB>  <TAB> action[""plugin""] = plugin.getUID() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> actions.append(action) <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> print(""[!] Plugin %s failed on fetching CVE actions!"" % plugin.getName()) <TAB>  <TAB>  <TAB> print(""[!]  -> %s"" % e) <TAB> return actions",if actions_ :,166
"def _sensors_to_fields(oldrec, sensor_map): <TAB> # map a record with observation names to a record with db field names <TAB> if oldrec: <TAB>  <TAB> newrec = dict() <TAB>  <TAB> for k in sensor_map: <MASK> newrec[k] = oldrec[sensor_map[k]] <TAB>  <TAB> if newrec: <TAB>  <TAB>  <TAB> newrec[""dateTime""] = oldrec[""dateTime""] <TAB>  <TAB>  <TAB> newrec[""usUnits""] = oldrec[""usUnits""] <TAB>  <TAB>  <TAB> return newrec <TAB> return None",if sensor_map [ k ] in oldrec :,146
"def rdd_generator(): <TAB> while not tf_feed.should_stop(): <TAB>  <TAB> batch = tf_feed.next_batch(1) <MASK> features = batch[""x""][0] <TAB>  <TAB>  <TAB> label = batch[""y_""][0] <TAB>  <TAB>  <TAB> yield (features, label) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return","if len ( batch [ ""x"" ] ) > 0 :",92
"def _get_modules(fn): <TAB> finder = modulefinder.ModuleFinder() <TAB> finder.run_script(fn) <TAB> all = [] <TAB> for m in finder.modules.values(): <TAB>  <TAB> if not isinstance(m, modulefinder.Module): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if not m.__file__: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # skip shared object files <TAB>  <TAB> if m.__file__.endswith("".so""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # skip mac system stuff... <TAB>  <TAB> # FIXME: would need to augment with  other OS's system stuff <MASK> continue <TAB>  <TAB> all.append(m) <TAB> return all","if m . __file__ . startswith ( ""/Library/Frameworks"" ) :",162
"def clean(self): <TAB> d = super().clean() <TAB> if d[""issue_giftcard""]: <TAB>  <TAB> if d[""tax_rule""] and d[""tax_rule""].rate > 0: <TAB>  <TAB>  <TAB> self.add_error( <TAB>  <TAB>  <TAB>  <TAB> ""tax_rule"", <TAB>  <TAB>  <TAB>  <TAB> _( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Gift card products should not be associated with non-zero tax rates since sales tax will be applied when the gift card is redeemed."" <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB> ) <MASK> self.add_error( <TAB>  <TAB>  <TAB>  <TAB> ""admission"", <TAB>  <TAB>  <TAB>  <TAB> _( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Gift card products should not be admission products at the same time."" <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB> ) <TAB> return d","if d [ ""admission"" ] :",184
"def is_filtered_inherited_member(name: str, obj: Any) -> bool: <TAB> if inspect.isclass(self.object): <TAB>  <TAB> for cls in self.object.__mro__: <TAB>  <TAB>  <TAB> if cls.__name__ == self.options.inherited_members and cls != self.object: <TAB>  <TAB>  <TAB>  <TAB> # given member is a member of specified *super class* <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB> elif name in cls.__dict__: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> elif name in self.get_attr(cls, ""__annotations__"", {}): <TAB>  <TAB>  <TAB>  <TAB> return False <MASK> return False <TAB> return False","elif isinstance ( obj , ObjectMember ) and obj . class_ is cls :",167
"def dictToKW(d): <TAB> out = [] <TAB> items = list(d.items()) <TAB> items.sort() <TAB> for k, v in items: <TAB>  <TAB> if not isinstance(k, str): <TAB>  <TAB>  <TAB> raise NonFormattableDict(""%r ain't a string"" % k) <MASK> raise NonFormattableDict(""%r ain't an identifier"" % k) <TAB>  <TAB> out.append(""\n\0{}={},"".format(k, prettify(v))) <TAB> return """".join(out)",if not r . match ( k ) :,131
"def report_add_status(torrentlist, succ_cnt, fail_cnt, fail_msgs): <TAB> if fail_cnt == 0: <TAB>  <TAB> torrentlist.report_message( <TAB>  <TAB>  <TAB> ""Torrents Added"", ""{!success!}Successfully added %d torrent(s)"" % succ_cnt <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> msg = ( <TAB>  <TAB>  <TAB> ""{!error!}Failed to add the following %d torrent(s):\n {!input!}"" % fail_cnt <TAB>  <TAB> ) + ""\n "".join(fail_msgs) <MASK> msg += ""\n \n{!success!}Successfully added %d torrent(s)"" % succ_cnt <TAB>  <TAB> torrentlist.report_message(""Torrent Add Report"", msg)",if succ_cnt != 0 :,184
"def merge(self, other): <TAB> d = self._name2ft <TAB> for name, (f, t) in other._name2ft.items(): <MASK> # Don't print here by default, since doing <TAB>  <TAB>  <TAB> # <TAB>  so breaks some of the buildbots <TAB>  <TAB>  <TAB> # print(""*** DocTestRunner.merge: '"" + name + ""' in both"" \ <TAB>  <TAB>  <TAB> # <TAB> "" testers; summing outcomes."") <TAB>  <TAB>  <TAB> f2, t2 = d[name] <TAB>  <TAB>  <TAB> f = f + f2 <TAB>  <TAB>  <TAB> t = t + t2 <TAB>  <TAB> d[name] = f, t",if name in d :,156
"def handle_command(self, parameters): <TAB> response = """" <TAB> for ip_token in parameters: <MASK> ip = netaddr.IPNetwork(ip_token)[0] <TAB>  <TAB>  <TAB> if not (ip.is_loopback() or ip.is_private() or ip.is_reserved()): <TAB>  <TAB>  <TAB>  <TAB> response += ""{0} location: {1}\n"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ip_token, ip_location(ip_token) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> response += ""{0}: hrm...loopback? private ip?\n"".format(ip_token) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> response = ""{0} is not an IP address"".format(ip_token) <TAB> return response",if is_ip ( ip_token ) :,186
"def letterrange(first, last, charset): <TAB> for k in range(len(last)): <TAB>  <TAB> for x in product(*[chain(charset)] * (k + 1)): <TAB>  <TAB>  <TAB> result = """".join(x) <MASK> if first != result: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> first = None <TAB>  <TAB>  <TAB> yield result <TAB>  <TAB>  <TAB> if result == last: <TAB>  <TAB>  <TAB>  <TAB> return",if first :,112
"def artifacts_base_dir(self): <TAB> if not self._artifacts_base_dir: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> artifacts_base_dir = os.path.abspath( <TAB>  <TAB>  <TAB>  <TAB> self.get_option(self.SECTION, ""artifacts_base_dir"") <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> except ValidationError: <TAB>  <TAB>  <TAB> artifacts_base_dir = os.path.abspath(""logs"") <MASK> os.makedirs(artifacts_base_dir) <TAB>  <TAB>  <TAB> os.chmod(self.artifacts_base_dir, 0o755) <TAB>  <TAB> self._artifacts_base_dir = artifacts_base_dir <TAB> return self._artifacts_base_dir",if not os . path . exists ( artifacts_base_dir ) :,172
"def _extract_changes(doc_map, changes, read_time): <TAB> deletes = [] <TAB> adds = [] <TAB> updates = [] <TAB> for name, value in changes.items(): <TAB>  <TAB> if value == ChangeType.REMOVED: <MASK> deletes.append(name) <TAB>  <TAB> elif name in doc_map: <TAB>  <TAB>  <TAB> if read_time is not None: <TAB>  <TAB>  <TAB>  <TAB> value.read_time = read_time <TAB>  <TAB>  <TAB> updates.append(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if read_time is not None: <TAB>  <TAB>  <TAB>  <TAB> value.read_time = read_time <TAB>  <TAB>  <TAB> adds.append(value) <TAB> return (deletes, adds, updates)",if name in doc_map :,173
"def __setattr__(self, name, val): <TAB> BitmapSprite.__setattr__(self, name, val) <TAB> if name in ( <TAB>  <TAB> ""name"", <TAB>  <TAB> ""size"", <TAB> ):  # no other reason to discard cache than just on path change <MASK> self.image_data = self.theme.load_icon(self.name, self.size, 0) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.image_data = None","if self . __dict__ . get ( ""name"" ) and self . __dict__ . get ( ""size"" ) :",125
"def extract_deps(file): <TAB> # ~ print('Extracting from %s' % file) <TAB> deps = set() <TAB> for line in open(file).readlines(): <TAB>  <TAB> line = line.strip() <MASK> words = line.split() <TAB>  <TAB>  <TAB> if words[0] == ""import"" or (words[0] == ""from"" and words[2] == ""import""): <TAB>  <TAB>  <TAB>  <TAB> deps.add(words[1]) <TAB> return deps","if line . startswith ( ""import"" ) or line . startswith ( ""from"" ) :",124
"def run_query(self, query, user): <TAB> connection = self._get_connection() <TAB> statement = None <TAB> error = None <TAB> try: <TAB>  <TAB> statement = connection.execute(query) <TAB>  <TAB> columns = [ <TAB>  <TAB>  <TAB> {""name"": n, ""friendly_name"": n, ""type"": _type_mapper(t)} <TAB>  <TAB>  <TAB> for (n, t) in statement.columns().items() <TAB>  <TAB> ] <TAB>  <TAB> cnames = statement.column_names() <TAB>  <TAB> rows = [dict(zip(cnames, row)) for row in statement] <TAB>  <TAB> data = {""columns"": columns, ""rows"": rows} <TAB>  <TAB> json_data = json_dumps(data) <TAB> finally: <MASK> statement.close() <TAB>  <TAB> connection.close() <TAB> return json_data, error",if statement is not None :,197
"def find_setup_py_above(a_file): <TAB> ""Return the directory containing setup.py somewhere above *a_file*"" <TAB> root = os.path.dirname(os.path.abspath(a_file)) <TAB> while not os.path.exists(os.path.join(root, ""setup.py"")): <TAB>  <TAB> prev, root = root, os.path.dirname(root) <MASK> # Let's avoid infinite loops at root <TAB>  <TAB>  <TAB> raise NoSetupPyFound(""could not find my setup.py above %r"" % (a_file,)) <TAB> return root",if root == prev :,142
"def check_index(self, is_sorted=True, unique=True, index=None): <TAB> """"""Sanity checks"""""" <TAB> if not index: <TAB>  <TAB> index = self.index <TAB> if is_sorted: <TAB>  <TAB> test = pd.DataFrame(lrange(len(index)), index=index) <TAB>  <TAB> test_sorted = test.sort() <TAB>  <TAB> if not test.index.equals(test_sorted.index): <TAB>  <TAB>  <TAB> raise Exception(""Data is not be sorted"") <TAB> if unique: <MASK> raise Exception(""Duplicate index entries"")",if len ( index ) != len ( index . unique ( ) ) :,142
"def _compare_address_strings(self, a, b): <TAB> # IPv6 address from different requests might be different <TAB> a_segments = a.count("":"") <TAB> b_segments = b.count("":"") <TAB> if a_segments and b_segments: <MASK> return True <TAB>  <TAB> if a.rstrip("":"").startswith(b.rstrip("":"")) or b.rstrip("":"").startswith( <TAB>  <TAB>  <TAB> a.rstrip("":"") <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> if a_segments >= 2 and b_segments >= 2 and a.split("":"")[:2] == b.split("":"")[:2]: <TAB>  <TAB>  <TAB> return True <TAB> return a.split(""."", 1)[-1] == b.split(""."", 1)[-1]","if a_segments == b_segments and a_segments in ( 4 , 5 , 6 , 7 ) :",187
"def collect(self): <TAB> for vacb in self.GetVACBs(): <TAB>  <TAB> filename = vacb.SharedCacheMap.FileObject.file_name_with_drive() <MASK> yield ( <TAB>  <TAB>  <TAB>  <TAB> vacb, <TAB>  <TAB>  <TAB>  <TAB> bool(self.kernel_address_space.vtop(vacb.BaseAddress.v())), <TAB>  <TAB>  <TAB>  <TAB> vacb.BaseAddress.v(), <TAB>  <TAB>  <TAB>  <TAB> vacb.Overlay.FileOffset.QuadPart, <TAB>  <TAB>  <TAB>  <TAB> filename, <TAB>  <TAB>  <TAB> )",if filename :,133
"def _visit_table(self, expr): <TAB> node = expr.op() <TAB> if isinstance(expr, ir.TableExpr): <TAB>  <TAB> base_table = _find_blocking_table(expr) <TAB>  <TAB> if base_table is not None: <TAB>  <TAB>  <TAB> base_node = base_table.op() <TAB>  <TAB>  <TAB> if self._is_root(base_node): <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> # Foreign ref <TAB>  <TAB>  <TAB>  <TAB> self.foreign_table = expr <TAB> else: <MASK> for arg in node.flat_args(): <TAB>  <TAB>  <TAB>  <TAB> if isinstance(arg, ir.Expr): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._visit(arg)",if not node . blocks ( ) :,172
"def channel_details(self) -> SnapChannelDetails: <TAB> if self._channel_details is None: <TAB>  <TAB> channel = self._payload.get(""channel"") <MASK> # Shouldn't happen, but raise an error if it does. <TAB>  <TAB>  <TAB> raise RuntimeError(f""no channel found for {self._payload!r}"") <TAB>  <TAB> self._channel_details = SnapChannelDetails(channel) <TAB> return self._channel_details",if channel is None :,107
"def __setattr__(self, attr, val): <TAB> if hasattr(self, attr): <TAB>  <TAB> old = getattr(self, attr) <TAB>  <TAB> if isinstance(old, Setting): <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Attempting to reassign setting %s with %s"" % (old, val) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> log.warn(""Setting attr %s via __setattr__ instead of set()!"", attr) <TAB>  <TAB>  <TAB> return old.set(val) <TAB> log.debug(""Setting {%s => %s}"" % (attr, val)) <TAB> return object.__setattr__(self, attr, val)","if isinstance ( val , Setting ) :",155
"def FindEnclosingBracketGroup(input_str): <TAB> stack = [] <TAB> start = -1 <TAB> for index, char in enumerate(input_str): <TAB>  <TAB> if char in LBRACKETS: <TAB>  <TAB>  <TAB> stack.append(char) <TAB>  <TAB>  <TAB> if start == -1: <TAB>  <TAB>  <TAB>  <TAB> start = index <TAB>  <TAB> elif char in BRACKETS: <MASK> return (-1, -1) <TAB>  <TAB>  <TAB> if stack.pop() != BRACKETS[char]: <TAB>  <TAB>  <TAB>  <TAB> return (-1, -1) <TAB>  <TAB>  <TAB> if not stack: <TAB>  <TAB>  <TAB>  <TAB> return (start, index + 1) <TAB> return (-1, -1)",if not stack :,163
"def copy_layer( <TAB> layer, <TAB> keep_bias=True, <TAB> name_template=None, <TAB> weights=None, <TAB> reuse_symbolic_tensors=True, <TAB> **kwargs): <TAB> config = layer.get_config() <TAB> if name_template is None: <TAB>  <TAB> config[""name""] = None <TAB> else: <TAB>  <TAB> config[""name""] = name_template % config[""name""] <TAB> if keep_bias is False and config.get(""use_bias"", False): <TAB>  <TAB> config[""use_bias""] = False <TAB>  <TAB> if weights is None: <MASK> weights = layer.weights[:-1] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> weights = layer.get_weights()[:-1] <TAB> return get_layer_from_config(layer, config, weights=weights, **kwargs)",if reuse_symbolic_tensors :,200
"def find_go_srcs(path): <TAB> srcs, tests = [], [] <TAB> for name in os.listdir(path): <TAB>  <TAB> if name.startswith(""."") or not name.endswith("".go""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if os.path.isfile(os.path.join(path, name)): <MASK> tests.append(name) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> srcs.append(name) <TAB> return srcs, tests","if name . endswith ( ""_test.go"" ) :",120
"def first_text(self, node): <TAB> """"""find first paragraph to use as a summary"""""" <TAB> if node.tagname == ""paragraph"": <TAB>  <TAB> return deepcopy(node) <TAB> else: <TAB>  <TAB> for child in node: <MASK> ans = self.first_text(child) <TAB>  <TAB>  <TAB>  <TAB> if ans: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return ans <TAB> return None","if hasattr ( child , ""tagname"" ) :",99
def ServerInference(self): <TAB> candidates = [] <TAB> score = [] <TAB> for symbol in self.symbols: <TAB>  <TAB> for m in symbol.getMessages(): <TAB>  <TAB>  <TAB> dst = m.getPattern()[0] <MASK> score[candidates.index(dst)] += 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> candidates.append(dst) <TAB>  <TAB>  <TAB>  <TAB> score.append(1) <TAB> print(candidates) <TAB> if score.count(max(score)) == 1 and len(candidates) > 2: <TAB>  <TAB> self.server = candidates[score.index(max(score))],if dst in candidates :,146
"def generateMapItemTypedNode(self, key, value): <TAB> if type(value) == SigmaRegularExpressionModifier: <TAB>  <TAB> regex = str(value) <TAB>  <TAB> # Regular Expressions have to match the full value in QRadar <TAB>  <TAB> if not (regex.startswith(""^"") or regex.startswith("".*"")): <TAB>  <TAB>  <TAB> regex = "".*"" + regex <MASK> regex = regex + "".*"" <TAB>  <TAB> return ""%s MATCHES %s"" % (self.cleanKey(key), self.generateValueNode(regex)) <TAB> else: <TAB>  <TAB> raise NotImplementedError( <TAB>  <TAB>  <TAB> ""Type modifier '{}' is not supported by backend"".format(value.identifier) <TAB>  <TAB> )","if not ( regex . endswith ( ""$"" ) or regex . endswith ( "".*"" ) ) :",165
"def get_max_vertical_scroll() -> int: <TAB> # Make sure that the cursor line is not above the top. <TAB> prev_lineno = ui_content.cursor_position.y <TAB> used_height = 0 <TAB> for lineno in range(ui_content.cursor_position.y - 1, -1, -1): <TAB>  <TAB> used_height += get_line_height(lineno) <MASK> return prev_lineno <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> prev_lineno = lineno <TAB> return prev_lineno",if used_height > scroll_offsets_top :,132
"def _options_values(self): <TAB> """"""Simulate option values for partially configured objects."""""" <TAB> try: <TAB>  <TAB> return self.__options_values <TAB> except AttributeError: <TAB>  <TAB> self.__options_values = {**self.keywords} <TAB>  <TAB> position = 0 <TAB>  <TAB> for name, option in self.func.__options__: <TAB>  <TAB>  <TAB> if not option.positional: <TAB>  <TAB>  <TAB>  <TAB> break  # no positional left <MASK> continue  # already fulfilled <TAB>  <TAB>  <TAB> self.__options_values[name] = ( <TAB>  <TAB>  <TAB>  <TAB> self.args[position] if len(self.args) >= position + 1 else None <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> position += 1 <TAB>  <TAB> return self.__options_values",if name in self . keywords :,175
"def key(self): <TAB> addr = self.m(""key"").obj_offset <TAB> addr = self.read_ptr(addr) <TAB> ret = """" <TAB> if addr: <TAB>  <TAB> ret = self.obj_vm.read(addr, 256) <MASK> idx = ret.find(""\x00"") <TAB>  <TAB>  <TAB> if idx != -1: <TAB>  <TAB>  <TAB>  <TAB> ret = ret[:idx] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret = """" <TAB> return ret",if ret :,114
"def get_file_path(self, filepath, token): <TAB> try: <TAB>  <TAB> encoded_path, _, user = self.updown_auth_manager.get_resource_info(token) <MASK> logger.info(""Invalid path file!! %s: %s"" % (user, filepath)) <TAB>  <TAB>  <TAB> raise NotFoundException(""File not found"") <TAB>  <TAB> logger.debug(""Get file: user=%s path=%s"" % (user, filepath)) <TAB>  <TAB> file_path = os.path.normpath(os.path.join(self.base_store_folder, encoded_path)) <TAB>  <TAB> return file_path <TAB> except (jwt.ExpiredSignature, jwt.DecodeError, AttributeError): <TAB>  <TAB> raise NotFoundException(""File not found"")","if not self . _valid_path ( filepath , encoded_path ) :",187
def validate_and_handle(self): <TAB> valid = self.validate(set_cursor=True) <TAB> if valid: <MASK> keep_text = self.accept_handler(self) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> keep_text = False <TAB>  <TAB> if not keep_text: <TAB>  <TAB>  <TAB> self.reset(),if self . accept_handler :,86
"def document_type(self): <TAB> if isinstance(self.document_type_obj, basestring): <MASK> self.document_type_obj = self.owner_document <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.document_type_obj = get_document(self.document_type_obj) <TAB> return self.document_type_obj",if self . document_type_obj == RECURSIVE_REFERENCE_CONSTANT :,99
"def _get_closest_end(end_after, begin_after): <TAB> """"""returns the closest \\end, that is open"""""" <TAB> end_iter = iter(end_after) <TAB> begin_iter = iter(begin_after) <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> e = next(end_iter) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> raise NoEnvError(""No closing environment detected"") <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> b = next(begin_iter) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> break <MASK> break <TAB> return e",if not e . begin ( ) > b . begin ( ) :,145
"def group_curves(self, curves): <TAB> result = [[curves[0]]] <TAB> tolerance = self.concat_tolerance <TAB> for curve1, curve2 in zip(curves, curves[1:]): <TAB>  <TAB> _, t_max_1 = curve1.get_u_bounds() <TAB>  <TAB> t_min_2, _ = curve2.get_u_bounds() <TAB>  <TAB> end1 = curve1.evaluate(t_max_1) <TAB>  <TAB> begin2 = curve2.evaluate(t_min_2) <TAB>  <TAB> distance = np.linalg.norm(begin2 - end1) <MASK> result.append([curve2]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result[-1].append(curve2) <TAB> return result",if distance > tolerance :,176
"def iteraddcolumn(table, field, col, index, missing): <TAB> it = iter(table) <TAB> hdr = next(it) <TAB> # determine position of new column <TAB> if index is None: <TAB>  <TAB> index = len(hdr) <TAB> # construct output header <TAB> outhdr = list(hdr) <TAB> outhdr.insert(index, field) <TAB> yield tuple(outhdr) <TAB> # construct output data <TAB> for row, val in izip_longest(it, col, fillvalue=missing): <TAB>  <TAB> # run out of rows? <MASK> row = [missing] * len(hdr) <TAB>  <TAB> outrow = list(row) <TAB>  <TAB> outrow.insert(index, val) <TAB>  <TAB> yield tuple(outrow)",if row == missing :,178
"def validate_is_admin(self, attrs, source): <TAB> project = attrs.get(""project"", None if self.object is None else self.object.project) <TAB> if project is None: <TAB>  <TAB> return attrs <TAB> if self.object and self.object.user: <MASK> raise ValidationError(_(""The project owner must be admin."")) <TAB>  <TAB> if not services.project_has_valid_admins( <TAB>  <TAB>  <TAB> project, exclude_user=self.object.user <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> raise ValidationError( <TAB>  <TAB>  <TAB>  <TAB> _(""At least one user must be an active admin for this project."") <TAB>  <TAB>  <TAB> ) <TAB> return attrs",if self . object . user . id == project . owner_id and not attrs [ source ] :,170
"def handle_periodic(self): <TAB> if self._closed: <MASK> self._eventloop.remove(self._server_socket) <TAB>  <TAB>  <TAB> self._server_socket.close() <TAB>  <TAB>  <TAB> self._server_socket = None <TAB>  <TAB>  <TAB> logging.info(""closed TCP port %d"", self._listen_port) <TAB>  <TAB> for handler in list(self._fd_to_handlers.values()): <TAB>  <TAB>  <TAB> handler.destroy() <TAB> self._sweep_timeout()",if self . _server_socket :,120
"def get_item(type_, preference): <TAB> items = {} <TAB> for item in playlist.findall(""./info/%s/item"" % type_): <TAB>  <TAB> lang, label = xpath_text(item, ""lg"", default=None), xpath_text( <TAB>  <TAB>  <TAB> item, ""label"", default=None <TAB>  <TAB> ) <TAB>  <TAB> if lang and label: <TAB>  <TAB>  <TAB> items[lang] = label.strip() <TAB> for p in preference: <MASK> return items[p]",if items . get ( p ) :,121
"def save_all_changed_configs(self): <TAB> """"""Save configuration changes to the user config file."""""" <TAB> has_changes = False <TAB> for ext_name in self.extensions: <TAB>  <TAB> options = self.extensions[ext_name] <TAB>  <TAB> for opt in options: <MASK> has_changes = True <TAB> if has_changes: <TAB>  <TAB> self.userCfg.Save()","if self . set_user_value ( ext_name , opt ) :",109
"def extract_validators(namespace: Dict[str, Any]) -> Dict[str, List[Validator]]: <TAB> validators: Dict[str, List[Validator]] = {} <TAB> for var_name, value in namespace.items(): <TAB>  <TAB> validator_config = getattr(value, VALIDATOR_CONFIG_KEY, None) <MASK> fields, v = validator_config <TAB>  <TAB>  <TAB> for field in fields: <TAB>  <TAB>  <TAB>  <TAB> if field in validators: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> validators[field].append(v) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> validators[field] = [v] <TAB> return validators",if validator_config :,147
"def _bindTable(self, tableName, create=False): <TAB> for attempt in retry_azure(): <TAB>  <TAB> with attempt: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> exists = self.tableService.exists(table_name=tableName) <TAB>  <TAB>  <TAB> except AzureMissingResourceHttpError as e: <TAB>  <TAB>  <TAB>  <TAB> if e.status_code != 404: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> if exists: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return AzureTable(self.tableService, tableName) <MASK> self.tableService.create_table(tableName) <TAB>  <TAB>  <TAB>  <TAB> return AzureTable(self.tableService, tableName) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return None",if create :,184
"def extract(self): <TAB> for battery in self.vars: <TAB>  <TAB> for line in dopen(""/proc/acpi/battery/"" + battery + ""/state"").readlines(): <TAB>  <TAB>  <TAB> l = line.split() <TAB>  <TAB>  <TAB> if len(l) < 3: <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> remaining = int(l[2]) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> elif l[0:2] == [""present"", ""rate:""]: <TAB>  <TAB>  <TAB>  <TAB> rate = int(l[2]) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if rate and remaining: <TAB>  <TAB>  <TAB> self.val[battery] = remaining * 60 / rate <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.val[battery] = -1","if l [ 0 : 2 ] == [ ""remaining"" , ""capacity:"" ] :",185
"def merge_syntactic_units(original_units, filtered_units, tags=None): <TAB> units = [] <TAB> for i in range(len(original_units)): <MASK> continue <TAB>  <TAB> text = original_units[i] <TAB>  <TAB> token = filtered_units[i] <TAB>  <TAB> tag = tags[i][1] if tags else None <TAB>  <TAB> sentence = SyntacticUnit(text, token, tag) <TAB>  <TAB> sentence.index = i <TAB>  <TAB> units.append(sentence) <TAB> return units","if filtered_units [ i ] == """" :",132
"def copy_grads_to_fp32(self, fp16_net, fp32_weights): <TAB> """"""Copy gradients from fp16 model to fp32 weight copy."""""" <TAB> for fp32_param, fp16_param in zip(fp32_weights, fp16_net.parameters()): <MASK> if fp32_param.grad is None: <TAB>  <TAB>  <TAB>  <TAB> fp32_param.grad = fp32_param.data.new(fp32_param.size()) <TAB>  <TAB>  <TAB> fp32_param.grad.copy_(fp16_param.grad)",if fp16_param . grad is not None :,141
"def gen_new_segments(datadir, spk_list): <TAB> if not os.path.isfile(os.path.join(datadir, ""segments"")): <TAB>  <TAB> raise ValueError(""no segments file found in datadir"") <TAB> new_segments = open(os.path.join(datadir, ""new_segments""), ""w"", encoding=""utf-8"") <TAB> segments = open(os.path.join(datadir, ""segments""), ""r"", encoding=""utf-8"") <TAB> while True: <TAB>  <TAB> line = segments.readline() <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> spk = line.split(""_"")[0] <MASK> new_segments.write(line) <TAB> new_segments.close(), segments.close()",if spk in spk_list :,176
"def _get_sources(include_per_machine=True, include_per_user=True): <TAB> if _is_64bit_os(): <MASK> yield open_source(REGISTRY_SOURCE_CU), None <TAB>  <TAB> if include_per_machine: <TAB>  <TAB>  <TAB> yield open_source(REGISTRY_SOURCE_LM), ""64bit"" <TAB>  <TAB>  <TAB> yield open_source(REGISTRY_SOURCE_LM_WOW6432), ""32bit"" <TAB> else: <TAB>  <TAB> if include_per_user: <TAB>  <TAB>  <TAB> yield open_source(REGISTRY_SOURCE_CU), ""32bit"" <TAB>  <TAB> if include_per_machine: <TAB>  <TAB>  <TAB> yield open_source(REGISTRY_SOURCE_LM), ""32bit""",if include_per_user :,175
"def AddWindowMenu(self, pMenuBar): <TAB> if pMenuBar and self._pWindowMenu: <TAB>  <TAB> pos = pMenuBar.FindMenu(wx.GetStockLabel(wx.ID_HELP, wx.STOCK_NOFLAGS)) <MASK> pMenuBar.Append(self._pWindowMenu, _(""&Window"")) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pMenuBar.Insert(pos, self._pWindowMenu, _(""&Window""))",if pos == wx . NOT_FOUND :,115
"def remove(self, res): <TAB> """"""Remove resource"""""" <TAB> msg_box = QMessageBox( <TAB>  <TAB> QMessageBox.Critical, <TAB>  <TAB> self.app.translate(""ResourceEdit"", ""Delete Resource""), <TAB>  <TAB> self.app.translate( <TAB>  <TAB>  <TAB> ""ResourceEdit"", ""Are you sure want to delete this resource?"" <TAB>  <TAB> ), <TAB>  <TAB> QMessageBox.Yes | QMessageBox.No, <TAB> ) <TAB> ret = msg_box.exec_() <TAB> if ret == QMessageBox.Yes: <TAB>  <TAB> self._resources.remove(res) <TAB>  <TAB> self._resource_labels[res].hide() <TAB>  <TAB> del self._resource_labels[res] <TAB>  <TAB> self.on_change() <MASK> self.widget.hide() <TAB>  <TAB> self.update_label()",if not self . _resources :,188
"def reader(self, myself): <TAB> ok = True <TAB> line = """" <TAB> while True: <TAB>  <TAB> line = sys.stdin.readline().strip() <TAB>  <TAB> if ok: <MASK> ok = False <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif not line: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ok = True <TAB>  <TAB> self.Q.append(line) <TAB> os.kill(myself, signal.SIGTERM)",if not line :,112
"def _compute_ratios(counts, n_total, multilabel=False): <TAB> computed_ratios = {} <TAB> max_count = max(counts.values()) <TAB> for class_name, count in counts.items(): <MASK> ratio = (n_total - count) / count <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ratio = ratio = max_count / count <TAB>  <TAB> computed_ratios[class_name] = ratio <TAB> return computed_ratios",if multilabel :,107
"def test_tags(context_obj, sagemaker_session): <TAB> tags = [{""Key"": ""foo1"", ""Value"": ""bar1""}] <TAB> context_obj.set_tags(tags) <TAB> while True: <TAB>  <TAB> actual_tags = sagemaker_session.sagemaker_client.list_tags( <TAB>  <TAB>  <TAB> ResourceArn=context_obj.context_arn <TAB>  <TAB> )[""Tags""] <MASK> break <TAB>  <TAB> time.sleep(5) <TAB> # When sagemaker-client-config endpoint-url is passed as argument to hit some endpoints, <TAB> # length of actual tags will be greater than 1 <TAB> assert len(actual_tags) > 0 <TAB> assert [actual_tags[-1]] == tags",if actual_tags :,173
"def step(self, action): <TAB> """"""Repeat action, sum reward, and max over last observations."""""" <TAB> total_reward = 0.0 <TAB> done = None <TAB> for i in range(self._skip): <TAB>  <TAB> obs, reward, done, info = self.env.step(action) <TAB>  <TAB> if i == self._skip - 2: <TAB>  <TAB>  <TAB> self._obs_buffer[0] = obs <MASK> self._obs_buffer[1] = obs <TAB>  <TAB> total_reward += reward <TAB>  <TAB> if done: <TAB>  <TAB>  <TAB> break <TAB> # Note that the observation on the done=True frame doesn't matter. <TAB> max_frame = self._obs_buffer.max(axis=0) <TAB> return max_frame, total_reward, done, info",if i == self . _skip - 1 :,187
"def prepare_text(text, style): <TAB> body = [] <TAB> for fragment, sty in parse_tags(text, style, subs.styles): <TAB>  <TAB> fragment = fragment.replace(r""\h"", "" "") <TAB>  <TAB> fragment = fragment.replace(r""\n"", ""\n"") <TAB>  <TAB> fragment = fragment.replace(r""\N"", ""\n"") <TAB>  <TAB> if sty.italic: <TAB>  <TAB>  <TAB> fragment = ""<i>%s</i>"" % fragment <MASK> fragment = ""<u>%s</u>"" % fragment <TAB>  <TAB> if sty.strikeout: <TAB>  <TAB>  <TAB> fragment = ""<s>%s</s>"" % fragment <TAB>  <TAB> if sty.drawing: <TAB>  <TAB>  <TAB> raise ContentNotUsable <TAB>  <TAB> body.append(fragment) <TAB> return re.sub(""\n+"", ""\n"", """".join(body).strip())",if sty . underline :,198
"def GetConvertersByClass(value_cls): <TAB> """"""Returns all converters that take given value as an input value."""""" <TAB> try: <TAB>  <TAB> return ExportConverter.converters_cache[value_cls] <TAB> except KeyError: <TAB>  <TAB> results = [ <TAB>  <TAB>  <TAB> cls <TAB>  <TAB>  <TAB> for cls in ExportConverter.classes.values() <MASK> ] <TAB>  <TAB> if not results: <TAB>  <TAB>  <TAB> results = [DataAgnosticExportConverter] <TAB>  <TAB> ExportConverter.converters_cache[value_cls] = results <TAB>  <TAB> return results",if cls . input_rdf_type == value_cls,138
"def enable(self): <TAB> """"""enable the patch."""""" <TAB> for patch in self.dependencies: <TAB>  <TAB> patch.enable() <TAB> if not self.enabled: <TAB>  <TAB> pyv = sys.version_info[0] <MASK> if self.PY2 == SKIP: <TAB>  <TAB>  <TAB>  <TAB> return  # skip patch activation <TAB>  <TAB>  <TAB> if not self.PY2: <TAB>  <TAB>  <TAB>  <TAB> raise IncompatiblePatch(""Python 2 not supported!"") <TAB>  <TAB> if pyv == 3: <TAB>  <TAB>  <TAB> if self.PY3 == SKIP: <TAB>  <TAB>  <TAB>  <TAB> return  # skip patch activation <TAB>  <TAB>  <TAB> if not self.PY3: <TAB>  <TAB>  <TAB>  <TAB> raise IncompatiblePatch(""Python 3 not supported!"") <TAB>  <TAB> self.pre_enable() <TAB>  <TAB> self.do_enable() <TAB>  <TAB> self.enabled = True",if pyv == 2 :,191
def _maybe_uncompress(self): <TAB> if not self._decompressed: <TAB>  <TAB> compression_type = self.compression_type <TAB>  <TAB> if compression_type != self.CODEC_NONE: <TAB>  <TAB>  <TAB> data = memoryview(self._buffer)[self._pos :] <TAB>  <TAB>  <TAB> if compression_type == self.CODEC_GZIP: <TAB>  <TAB>  <TAB>  <TAB> uncompressed = gzip_decode(data) <TAB>  <TAB>  <TAB> if compression_type == self.CODEC_SNAPPY: <TAB>  <TAB>  <TAB>  <TAB> uncompressed = snappy_decode(data.tobytes()) <MASK> uncompressed = lz4_decode(data.tobytes()) <TAB>  <TAB>  <TAB> self._buffer = bytearray(uncompressed) <TAB>  <TAB>  <TAB> self._pos = 0 <TAB> self._decompressed = True,if compression_type == self . CODEC_LZ4 :,192
"def transform(node, filename): <TAB> root = ast.Module(None, node, lineno=1) <TAB> nodes = [root] <TAB> while nodes: <TAB>  <TAB> node = nodes.pop() <TAB>  <TAB> node.filename = filename <MASK> node.dest = ast.Name(""__context"") <TAB>  <TAB> elif node.__class__ is ast.Const and isinstance(node.value, str): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> node.value.decode(""ascii"") <TAB>  <TAB>  <TAB> except UnicodeError: <TAB>  <TAB>  <TAB>  <TAB> node.value = node.value.decode(""utf-8"") <TAB>  <TAB> nodes.extend(node.getChildNodes()) <TAB> return root","if node . __class__ in ( ast . Printnl , ast . Print ) :",169
"def __init__(self, json=None): <TAB> if not json: <TAB>  <TAB> self._mods = dict() <TAB>  <TAB> return <TAB> mods = collections.defaultdict(set) <TAB> installed_path_patt = re.compile( <TAB>  <TAB> "".*[\\\\/]target[\\\\/]product[\\\\/][^\\\\/]+([\\\\/].*)$"" <TAB> ) <TAB> for module in json.values(): <TAB>  <TAB> for path in module[""installed""]: <TAB>  <TAB>  <TAB> match = installed_path_patt.match(path) <MASK> for path in module[""path""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> mods[match.group(1)].add(path) <TAB> self._mods = { <TAB>  <TAB> installed_path: sorted(src_dirs) for installed_path, src_dirs in mods.items() <TAB> }",if match :,195
"def _findSubpath(self, path, A, B, inside): <TAB> print(""finding"", A, B) <TAB> sub = None <TAB> for i in xrange(0, len(path) * 2):  # iterate twice with wrap around <TAB>  <TAB> j = i % len(path) <TAB>  <TAB> seg = path[j] <TAB>  <TAB> if inside.isInside(seg.midPoint()): <TAB>  <TAB>  <TAB> if eq(seg.A, A): <TAB>  <TAB>  <TAB>  <TAB> sub = Path(""subp"") <TAB>  <TAB>  <TAB> print(""seg"", sub is None, seg) <TAB>  <TAB>  <TAB> if sub is not None: <TAB>  <TAB>  <TAB>  <TAB> sub.append(seg) <MASK> break <TAB> print(""found"", sub) <TAB> return sub","if eq ( seg . B , B ) :",180
"def on_click(self, event): <TAB> button = event[""button""] <TAB> if button in [self.button_next, self.button_previous]: <TAB>  <TAB> if self.station_data: <TAB>  <TAB>  <TAB> self.scrolling = True <MASK> self.active_index += 1 <TAB>  <TAB>  <TAB> elif button == self.button_previous: <TAB>  <TAB>  <TAB>  <TAB> self.active_index -= 1 <TAB>  <TAB>  <TAB> self.active_index %= self.count_stations <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.py3.prevent_refresh() <TAB> elif button == self.button_refresh: <TAB>  <TAB> self.idle_time = 0 <TAB> else: <TAB>  <TAB> self.py3.prevent_refresh()",if button == self . button_next :,178
"def __init_subclass__(cls, *, abstract=False): <TAB> if abstract: <TAB>  <TAB> return <TAB> fields = {} <TAB> for name in cls.__dict__: <TAB>  <TAB> attr = cls.__dict__[name] <MASK> continue <TAB>  <TAB> if not isinstance(attr, CType): <TAB>  <TAB>  <TAB> raise TypeError(f""field {cls.__name__}.{name!r} must be a Type"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> fields[name] = attr <TAB> cls._fields = fields","if name . startswith ( ""__"" ) or callable ( attr ) :",125
"def add(self, geom): <TAB> ""Add the geometry to this Geometry Collection."" <TAB> if isinstance(geom, OGRGeometry): <MASK> for g in geom: <TAB>  <TAB>  <TAB>  <TAB> capi.add_geom(self.ptr, g.ptr) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> capi.add_geom(self.ptr, geom.ptr) <TAB> elif isinstance(geom, six.string_types): <TAB>  <TAB> tmp = OGRGeometry(geom) <TAB>  <TAB> capi.add_geom(self.ptr, tmp.ptr) <TAB> else: <TAB>  <TAB> raise OGRException(""Must add an OGRGeometry."")","if isinstance ( geom , self . __class__ ) :",157
"def __str__(self): <TAB> result = [] <TAB> for x in self._fields_: <TAB>  <TAB> key = x[0] <TAB>  <TAB> value = getattr(self, key) <TAB>  <TAB> fmt = ""%s"" <TAB>  <TAB> if key in self._fmt_: <TAB>  <TAB>  <TAB> fmt = self._fmt_[key] <MASK> fmt = self._fmt_[""<default>""] <TAB>  <TAB> result.append((""%s: "" + fmt) % (key, value)) <TAB> return self.__class__.__name__ + ""("" + string.join(result, "", "") + "")""","elif ""<default>"" in self . _fmt_ :",137
"def add(self, *objs): <TAB> for obj in objs: <MASK> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""'%s' instance expected, got %r"" % (self.model._meta.object_name, obj) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> setattr(obj, rel_field.name, self.instance) <TAB>  <TAB> obj.save()","if not isinstance ( obj , self . model ) :",95
"def _eliminate_deprecated_list_indexing(idx): <TAB> # ""Basic slicing is initiated if the selection object is a non-array, <TAB> # non-tuple sequence containing slice objects, [Ellipses, or newaxis <TAB> # objects]"". Detects this case and canonicalizes to a tuple. This case is <TAB> # deprecated by NumPy and exists for backward compatibility. <TAB> if not isinstance(idx, tuple): <MASK> if _any(_should_unpack_list_index(i) for i in idx): <TAB>  <TAB>  <TAB>  <TAB> idx = tuple(idx) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> idx = (idx,) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> idx = (idx,) <TAB> return idx","if isinstance ( idx , Sequence ) and not isinstance ( idx , ndarray ) :",177
"def __init__(self, parent=None, **kwargs): <TAB> super(DefaultWidget, self).__init__(parent) <TAB> self.parent = parent <TAB> self.FSettings = SuperSettings.getInstance() <TAB> self.defaultui = [] <TAB> self.allui = [] <TAB> self.__tabbyname = {} <TAB> __defaultui = [ui(parent, self.FSettings) for ui in TabsWidget.__subclasses__()] <TAB> for ui in __defaultui: <MASK> self.defaultui.append(ui) <TAB>  <TAB> self.allui.append(ui) <TAB>  <TAB> self.__tabbyname[ui.Name] = ui <TAB>  <TAB> setattr(self.__class__, ui.ID, ui)",if not ui . isSubitem :,173
"def onMouseMove(self, event): <TAB> x, y = event.xdata, event.ydata <TAB> if x is not None: <TAB>  <TAB> extra_text = self.getExtraText(x, y) <TAB>  <TAB> # extra_text = ""TODO:"" <MASK> self.message(""x,y=%5.4e,%5.4e %s"" % (x, y, extra_text), index=0) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.message(""x,y=%5.4e,%5.4e"" % (x, y), index=0) <TAB> else: <TAB>  <TAB> self.message(None)",if extra_text :,155
"def tag_configure(self, *args, **keys): <TAB> if len(args) == 1: <TAB>  <TAB> key = args[0] <TAB>  <TAB> self.tags[key] = keys <TAB>  <TAB> val = keys.get(""foreground"") <TAB>  <TAB> underline = keys.get(""underline"") <TAB>  <TAB> if val: <TAB>  <TAB>  <TAB> self.configDict[key] = val <MASK> self.configUnderlineDict[key] = True <TAB> else: <TAB>  <TAB> g.trace(""oops"", args, keys)",if underline :,123
"def _flatten_shape(s, index): <TAB> if s.is_array(): <TAB>  <TAB> yield index, s <TAB> else: <TAB>  <TAB> assert s.is_tuple() <TAB>  <TAB> for i, sub in enumerate(s.tuple_shapes()): <TAB>  <TAB>  <TAB> subindex = index + (i,) <MASK> yield from _flatten_shape(sub, subindex) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield subindex, sub",if sub . is_tuple ( ) :,111
"def delete_if_forked(ghrequest): <TAB> FORKED = False <TAB> query = ""/user/repos"" <TAB> r = utils.query_request(query) <TAB> for repo in r.json(): <TAB>  <TAB> if repo[""description""]: <MASK> FORKED = True <TAB>  <TAB>  <TAB>  <TAB> url = f""/repos/{repo['full_name']}"" <TAB>  <TAB>  <TAB>  <TAB> utils.query_request(url, method=""DELETE"") <TAB> return FORKED","if ghrequest . target_repo_fullname in repo [ ""description"" ] :",127
def update_json(self): <TAB> n_id = node_id(self) <TAB> if self.autoreload: <TAB>  <TAB> self.reload_json() <TAB> if n_id not in self.json_data and self.current_text: <TAB>  <TAB> self.reload_json() <TAB> if n_id not in self.json_data: <TAB>  <TAB> self.use_custom_color = True <TAB>  <TAB> self.color = FAIL_COLOR <TAB>  <TAB> return <TAB> self.use_custom_color = True <TAB> self.color = READY_COLOR <TAB> json_data = self.json_data[n_id] <TAB> for item in json_data: <MASK> out = json_data[item][1] <TAB>  <TAB>  <TAB> self.outputs[item].sv_set(out),if item in self . outputs and self . outputs [ item ] . is_linked :,200
"def _check_num_states(self, num_states): <TAB> """"""Track the number of states."""""" <TAB> self._num_states += num_states <TAB> if self._max_num_states is not None: <MASK> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB> ""Too many states detected while running dynamic "" <TAB>  <TAB>  <TAB>  <TAB> ""programming: got %d states but upper limit is %d."" <TAB>  <TAB>  <TAB>  <TAB> % (self._num_states, self._max_num_states) <TAB>  <TAB>  <TAB> )",if self . _num_states > self . _max_num_states :,134
def __del__(self): <TAB> try: <MASK> if self._initialized: <TAB>  <TAB>  <TAB>  <TAB> _gmp.mpz_clear(self._mpz_p) <TAB>  <TAB> self._mpz_p = None <TAB> except AttributeError: <TAB>  <TAB> pass,if self . _mpz_p is not None :,75
"def cmp(f1, f2): <TAB> bufsize = 1024 * 8 <TAB> with open(f1, ""rb"") as fp1, open(f2, ""rb"") as fp2: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> b1 = fp1.read(bufsize) <TAB>  <TAB>  <TAB> b2 = fp2.read(bufsize) <MASK> return False <TAB>  <TAB>  <TAB> if not b1: <TAB>  <TAB>  <TAB>  <TAB> return True",if b1 != b2 :,115
"def _get_changes(diff): <TAB> """"""Get a list of changed versions from git."""""" <TAB> changes_dict = {} <TAB> for line in diff: <MASK> continue <TAB>  <TAB> if line.startswith(""+++ "") or line.startswith(""--- ""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> name, version = parse_versioned_line(line[1:]) <TAB>  <TAB> if name not in changes_dict: <TAB>  <TAB>  <TAB> changes_dict[name] = Change(name) <TAB>  <TAB> if line.startswith(""-""): <TAB>  <TAB>  <TAB> changes_dict[name].old = version <TAB>  <TAB> elif line.startswith(""+""): <TAB>  <TAB>  <TAB> changes_dict[name].new = version <TAB> return [change for _name, change in sorted(changes_dict.items())]","if not line . startswith ( ""-"" ) and not line . startswith ( ""+"" ) :",181
"def analyze(vw): <TAB> for va, dest in vw.findPointers(): <TAB>  <TAB> # Is there a location already at the target? <TAB>  <TAB> loc = vw.getLocation(dest) <TAB>  <TAB> if loc is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if loc[L_LTYPE] != LOC_IMPORT: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> offset, bytes = vw.getByteDef(va) <TAB>  <TAB> if offset < 2: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if bytes[offset - 2 : offset] == b""\xff\x15"":  # call [importloc] <TAB>  <TAB>  <TAB> # If there's a pointer here, remove it. <MASK> vw.delLocation(va) <TAB>  <TAB>  <TAB> vw.makeCode(va - 2)",if vw . getLocation ( va ) :,192
"def match_blanks(self, s, i): <TAB> if 1:  # Use Qt code to show invisibles. <TAB>  <TAB> return 0 <TAB> else:  # Old code... <TAB>  <TAB> if not self.showInvisibles: <TAB>  <TAB>  <TAB> return 0 <TAB>  <TAB> j = i <TAB>  <TAB> n = len(s) <TAB>  <TAB> while j < n and s[j] == "" "": <TAB>  <TAB>  <TAB> j += 1 <MASK> self.colorRangeWithTag(s, i, j, ""blank"") <TAB>  <TAB>  <TAB> return j - i <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return 0",if j > i :,143
"def compress(self, data_list): <TAB> # Differs from the default implementation: If only a time is given and no date, we consider the field empty <TAB> if data_list: <TAB>  <TAB> if data_list[0] in self.empty_values: <TAB>  <TAB>  <TAB> return None <MASK> raise ValidationError( <TAB>  <TAB>  <TAB>  <TAB> self.error_messages[""invalid_date""], code=""invalid_date"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> result = datetime.datetime.combine(*data_list) <TAB>  <TAB> return from_current_timezone(result) <TAB> return None",if data_list [ 1 ] in self . empty_values :,146
"def test_iter_keys(self): <TAB> for name in (""interfaces"", ""addresses"", ""neighbours"", ""routes"", ""rules""): <TAB>  <TAB> view = getattr(self.ndb, name) <TAB>  <TAB> for key in view: <TAB>  <TAB>  <TAB> assert isinstance(key, Record) <TAB>  <TAB>  <TAB> obj = view.get(key) <MASK> assert isinstance(obj, RTNL_Object)",if obj is not None :,102
"def has_selenium(): <TAB> try: <TAB>  <TAB> from selenium import selenium <TAB>  <TAB> globals().update(selenium=selenium) <TAB>  <TAB> sel = selenium(*sel_args) <TAB>  <TAB> # a little trick to see if the server is responding <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> sel.do_command(""shutdown"", """") <TAB>  <TAB> except Exception as e: <MASK> raise <TAB>  <TAB> result = True <TAB> except ImportError: <TAB>  <TAB> result = SeleniumFailed(""selenium RC not installed"") <TAB> except Exception: <TAB>  <TAB> msg = ""Error occurred initializing selenium: %s"" % e <TAB>  <TAB> result = SeleniumFailed(msg) <TAB> # overwrite has_selenium, so the same result is returned every time <TAB> globals().update(has_selenium=lambda: result) <TAB> return result","if not ""Server Exception"" in str ( e ) :",190
"def analyze(vw): <TAB> for va, dest in vw.findPointers(): <TAB>  <TAB> # Is there a location already at the target? <TAB>  <TAB> loc = vw.getLocation(dest) <TAB>  <TAB> if loc is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if loc[L_LTYPE] != LOC_IMPORT: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> offset, bytes = vw.getByteDef(va) <TAB>  <TAB> if offset < 2: <TAB>  <TAB>  <TAB> continue <MASK> # call [importloc] <TAB>  <TAB>  <TAB> # If there's a pointer here, remove it. <TAB>  <TAB>  <TAB> if vw.getLocation(va): <TAB>  <TAB>  <TAB>  <TAB> vw.delLocation(va) <TAB>  <TAB>  <TAB> vw.makeCode(va - 2)","if bytes [ offset - 2 : offset ] == b""\xff\x15"" :",192
"def get(_kwargs): <TAB> exception_raised_every_time = True <TAB> exception = None <TAB> no_match = True <TAB> for meter in self.meters: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> match = getattr(meter, func)(_kwargs) <TAB>  <TAB> except KeyError as e: <TAB>  <TAB>  <TAB> exception = e <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> exception_raised_every_time = False <MASK> selected_meters.append(meter) <TAB>  <TAB>  <TAB>  <TAB> no_match = False <TAB> if no_match: <TAB>  <TAB> raise KeyError(""'No match for {}'"".format(_kwargs)) <TAB> if exception_raised_every_time and exception is not None: <TAB>  <TAB> raise exception",if match :,164
"def derive(self, key_material): <TAB> if self._used: <TAB>  <TAB> raise AlreadyFinalized <TAB> self._used = True <TAB> if not isinstance(key_material, bytes): <TAB>  <TAB> raise TypeError(""key_material must be bytes."") <TAB> output = [b""""] <TAB> outlen = 0 <TAB> counter = 1 <TAB> while self._length > outlen: <TAB>  <TAB> h = hashes.Hash(self._algorithm, self._backend) <TAB>  <TAB> h.update(key_material) <TAB>  <TAB> h.update(_int_to_u32be(counter)) <MASK> h.update(self._sharedinfo) <TAB>  <TAB> output.append(h.finalize()) <TAB>  <TAB> outlen += len(output[-1]) <TAB>  <TAB> counter += 1 <TAB> return b"""".join(output)[: self._length]",if self . _sharedinfo is not None :,196
"def test_cat(shape, cat_dim, split, dim): <TAB> assert sum(split) == shape[cat_dim] <TAB> gaussian = random_gaussian(shape, dim) <TAB> parts = [] <TAB> end = 0 <TAB> for size in split: <TAB>  <TAB> beg, end = end, end + size <MASK> part = gaussian[..., beg:end] <TAB>  <TAB> elif cat_dim == -2: <TAB>  <TAB>  <TAB> part = gaussian[..., beg:end, :] <TAB>  <TAB> elif cat_dim == 1: <TAB>  <TAB>  <TAB> part = gaussian[:, beg:end] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError <TAB>  <TAB> parts.append(part) <TAB> actual = Gaussian.cat(parts, cat_dim) <TAB> assert_close_gaussian(actual, gaussian)",if cat_dim == - 1 :,186
"def ghci_package_db(self, cabal): <TAB> if cabal is not None and cabal != ""cabal"": <TAB>  <TAB> package_conf = [ <TAB>  <TAB>  <TAB> pkg for pkg in os.listdir(cabal) if re.match(r""packages-(.*)\.conf"", pkg) <TAB>  <TAB> ] <MASK> return os.path.join(cabal, package_conf) <TAB> return None",if package_conf :,106
"def L_op(self, inputs, outputs, gout): <TAB> (x,) = inputs <TAB> (gz,) = gout <TAB> if x.type in complex_types: <TAB>  <TAB> raise NotImplementedError() <TAB> if outputs[0].type in discrete_types: <MASK> return [x.zeros_like(dtype=theano.config.floatX)] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return [x.zeros_like()] <TAB> return (gz / x,)",if x . type in discrete_types :,115
"def __mro_entries__(self, bases): <TAB> if self._name:  # generic version of an ABC or built-in class <TAB>  <TAB> return super().__mro_entries__(bases) <TAB> if self.__origin__ is Generic: <MASK> return () <TAB>  <TAB> i = bases.index(self) <TAB>  <TAB> for b in bases[i + 1 :]: <TAB>  <TAB>  <TAB> if isinstance(b, _BaseGenericAlias) and b is not self: <TAB>  <TAB>  <TAB>  <TAB> return () <TAB> return (self.__origin__,)",if Protocol in bases :,124
"def getvars(request, excludes): <TAB> getvars = request.GET.copy() <TAB> excludes = excludes.split("","") <TAB> for p in excludes: <TAB>  <TAB> if p in getvars: <TAB>  <TAB>  <TAB> del getvars[p] <MASK> return ""&%s"" % getvars.urlencode() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return """"",if len ( getvars . keys ( ) ) > 0 :,94
"def check(self): <TAB> now = time.time() <TAB> for fn in os.listdir(self.basedir): <MASK> continue <TAB>  <TAB> absfn = os.path.join(self.basedir, fn) <TAB>  <TAB> mtime = os.stat(absfn)[stat.ST_MTIME] <TAB>  <TAB> if now - mtime > self.old: <TAB>  <TAB>  <TAB> os.remove(absfn)",if fn in self . files :,101
"def run(self): <TAB> while 1: <TAB>  <TAB> gatekeeper.wait() <TAB>  <TAB> results = [] <TAB>  <TAB> results.append(self.__queue.get()) <TAB>  <TAB> while len(results) < self.MAX_SONGS_PER_SUBMISSION: <TAB>  <TAB>  <TAB> # wait a bit to reduce overall request count. <TAB>  <TAB>  <TAB> timeout = 0.5 / len(results) <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> results.append(self.__queue.get(timeout=timeout)) <TAB>  <TAB>  <TAB> except queue.Empty: <TAB>  <TAB>  <TAB>  <TAB> break <MASK> return <TAB>  <TAB> for lookup_result in self.__process(results): <TAB>  <TAB>  <TAB> self.__idle(self.__progress_cb, lookup_result) <TAB>  <TAB>  <TAB> self.__queue.task_done()",if self . __stopped :,185
"def __getitem__(self, item): <TAB> if isinstance(item, int): <TAB>  <TAB> selected_polygons = [self.polygons[item]] <TAB> elif isinstance(item, slice): <TAB>  <TAB> selected_polygons = self.polygons[item] <TAB> else: <TAB>  <TAB> # advanced indexing on a single dimension <TAB>  <TAB> selected_polygons = [] <MASK> item = item.nonzero() <TAB>  <TAB>  <TAB> item = item.squeeze(1) if item.numel() > 0 else item <TAB>  <TAB>  <TAB> item = item.tolist() <TAB>  <TAB> for i in item: <TAB>  <TAB>  <TAB> selected_polygons.append(self.polygons[i]) <TAB> return PolygonList(selected_polygons, size=self.size)","if isinstance ( item , torch . Tensor ) and item . dtype == torch . uint8 :",179
"def gather_files(fileset): <TAB> common_type = get_common_filetype(fileset) <TAB> files = [] <TAB> for file in fileset.file: <TAB>  <TAB> filename = file.name <TAB>  <TAB> if file.is_include_file == True: <TAB>  <TAB>  <TAB> filename = {} <TAB>  <TAB>  <TAB> filename[file.name] = {""is_include_file"": True} <TAB>  <TAB> if file.file_type != common_type: <MASK> filename = {} <TAB>  <TAB>  <TAB> filename[file.name] = {""file_type"": file.file_type} <TAB>  <TAB> files.append(filename) <TAB> return files",if type ( filename ) == str :,158
"def _(node): <TAB> for __ in dir(node): <TAB>  <TAB> if not __.startswith(""_""): <TAB>  <TAB>  <TAB> candidate = getattr(node, __) <MASK> if ""\\"" in candidate: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> re.compile(candidate) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> errMsg = ""smoke test failed at compiling '%s'"" % candidate <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> logger.error(errMsg) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> _(candidate)","if isinstance ( candidate , str ) :",142
"def _handle_children(self, removed, added): <TAB> # Stop all the removed children. <TAB> for obj in removed: <TAB>  <TAB> obj.stop() <TAB> # Process the new objects. <TAB> for obj in added: <TAB>  <TAB> obj.set(scene=self.scene, parent=self) <TAB>  <TAB> if isinstance(obj, ModuleManager): <TAB>  <TAB>  <TAB> obj.source = self <TAB>  <TAB> elif is_filter(obj): <TAB>  <TAB>  <TAB> obj.inputs.append(self) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> obj.start() <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> exception()",if self . running :,148
"def mean(self): <TAB> """"""Compute the mean of the value_field in the window."""""" <TAB> if len(self.data) > 0: <TAB>  <TAB> datasum = 0 <TAB>  <TAB> datalen = 0 <TAB>  <TAB> for dat in self.data: <TAB>  <TAB>  <TAB> if ""placeholder"" not in dat[0]: <TAB>  <TAB>  <TAB>  <TAB> datasum += dat[1] <TAB>  <TAB>  <TAB>  <TAB> datalen += 1 <MASK> return datasum / float(datalen) <TAB>  <TAB> return None <TAB> else: <TAB>  <TAB> return None",if datalen > 0 :,132
"def get_master_info(accounts_config, master): <TAB> master_info = None <TAB> for a in accounts_config[""accounts""]: <TAB>  <TAB> if a[""name""] == master: <TAB>  <TAB>  <TAB> master_info = a <TAB>  <TAB>  <TAB> break <MASK> master_info = a <TAB>  <TAB>  <TAB> break <TAB> if master_info is None: <TAB>  <TAB> raise ValueError(""Master account: %s not found in accounts config"" % (master)) <TAB> return master_info","if a [ ""account_id"" ] == master :",120
"def dataset_collector(dataset_collection_description): <TAB> if dataset_collection_description is DEFAULT_DATASET_COLLECTOR_DESCRIPTION: <TAB>  <TAB> # Use 'is' and 'in' operators, so lets ensure this is <TAB>  <TAB> # treated like a singleton. <TAB>  <TAB> return DEFAULT_DATASET_COLLECTOR <TAB> else: <MASK> return DatasetCollector(dataset_collection_description) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ToolMetadataDatasetCollector(dataset_collection_description)","if dataset_collection_description . discover_via == ""pattern"" :",126
"def _eliminate_deprecated_list_indexing(idx): <TAB> # ""Basic slicing is initiated if the selection object is a non-array, <TAB> # non-tuple sequence containing slice objects, [Ellipses, or newaxis <TAB> # objects]"". Detects this case and canonicalizes to a tuple. This case is <TAB> # deprecated by NumPy and exists for backward compatibility. <TAB> if not isinstance(idx, tuple): <TAB>  <TAB> if isinstance(idx, Sequence) and not isinstance(idx, ndarray): <MASK> idx = tuple(idx) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> idx = (idx,) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> idx = (idx,) <TAB> return idx",if _any ( _should_unpack_list_index ( i ) for i in idx ) :,177
"def finalizer(): <TAB> try: <TAB>  <TAB> stdout.flush() <TAB>  <TAB> stderr.flush() <TAB> finally: <TAB>  <TAB> time.sleep(0.001)  # HACK: Sleep 1ms in the main thread to free the GIL. <TAB>  <TAB> stdout_pipe.stop_writing() <TAB>  <TAB> stderr_pipe.stop_writing() <TAB>  <TAB> writer.join(timeout=60) <MASK> raise NailgunStreamWriterError( <TAB>  <TAB>  <TAB>  <TAB> ""pantsd timed out while waiting for the stdout/err to finish writing to the socket."" <TAB>  <TAB>  <TAB> )",if writer . isAlive ( ) :,138
"def __init__(self, env, config, scope_infos, option_tracker): <TAB> # Sorting ensures that ancestors precede descendants. <TAB> scope_infos = sorted(set(list(scope_infos)), key=lambda si: si.scope) <TAB> self._parser_by_scope = {} <TAB> for scope_info in scope_infos: <TAB>  <TAB> scope = scope_info.scope <TAB>  <TAB> parent_parser = ( <TAB>  <TAB>  <TAB> None <MASK> else self._parser_by_scope[enclosing_scope(scope)] <TAB>  <TAB> ) <TAB>  <TAB> self._parser_by_scope[scope] = Parser( <TAB>  <TAB>  <TAB> env, config, scope_info, parent_parser, option_tracker=option_tracker <TAB>  <TAB> )",if scope == GLOBAL_SCOPE,176
"def _load_start_paths(self) -> None: <TAB> ""Start the Read-Eval-Print Loop."" <TAB> if self._startup_paths: <TAB>  <TAB> for path in self._startup_paths: <MASK> with open(path, ""rb"") as f: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> code = compile(f.read(), path, ""exec"") <TAB>  <TAB>  <TAB>  <TAB>  <TAB> exec(code, self.get_globals(), self.get_locals()) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> output = self.app.output <TAB>  <TAB>  <TAB>  <TAB> output.write(""WARNING | File not found: {}\n\n"".format(path))",if os . path . exists ( path ) :,159
"def validate(leaves): <TAB> for leaf in leaves: <TAB>  <TAB> if leaf.has_form((""Rule"", ""RuleDelayed""), 2): <TAB>  <TAB>  <TAB> pass <MASK> if validate(leaf.leaves) is not True: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> return True","elif leaf . has_form ( ""List"" , None ) or leaf . has_form ( ""Association"" , None ) :",97
"def add(self, name, value, package=None): <TAB> # New data, not previous value <TAB> if name not in self._data[package]: <TAB>  <TAB> self._data[package][name] = value <TAB> # There is data already <TAB> else: <TAB>  <TAB> # Only append at the end if we had a list <MASK> if isinstance(value, list): <TAB>  <TAB>  <TAB>  <TAB> self._data[package][name].extend(value) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._data[package][name].append(value)","if isinstance ( self . _data [ package ] [ name ] , list ) :",140
"def edge2str(self, nfrom, nto): <TAB> if isinstance(nfrom, ExprCompose): <TAB>  <TAB> for i in nfrom.args: <TAB>  <TAB>  <TAB> if i[0] == nto: <TAB>  <TAB>  <TAB>  <TAB> return ""[%s, %s]"" % (i[1], i[2]) <TAB> elif isinstance(nfrom, ExprCond): <TAB>  <TAB> if nfrom.cond == nto: <TAB>  <TAB>  <TAB> return ""?"" <TAB>  <TAB> elif nfrom.src1 == nto: <TAB>  <TAB>  <TAB> return ""True"" <MASK> return ""False"" <TAB> return """"",elif nfrom . src2 == nto :,149
"def _get_config(key): <TAB> config = db.session.execute( <TAB>  <TAB> Configs.__table__.select().where(Configs.key == key) <TAB> ).fetchone() <TAB> if config and config.value: <TAB>  <TAB> value = config.value <TAB>  <TAB> if value and value.isdigit(): <TAB>  <TAB>  <TAB> return int(value) <MASK> if value.lower() == ""true"": <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB> elif value.lower() == ""false"": <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return value <TAB> # Flask-Caching is unable to roundtrip a value of None. <TAB> # Return an exception so that we can still cache and avoid the db hit <TAB> return KeyError","elif value and isinstance ( value , string_types ) :",181
"def from_rows(cls, rows): <TAB> subtitles = [] <TAB> for row in rows: <MASK> subtitles.append(cls.from_row(row)) <TAB> return subtitles","if row . td . a is not None and row . td . get ( ""class"" , [ ""lazy"" ] ) [ 0 ] != ""empty"" :",75
"def _wx_node(self, parent_node, index, label, with_checkbox): <TAB> ct_type = 1 if with_checkbox else 0 <TAB> if index is not None: <TAB>  <TAB> # blame wxPython for this ugliness <MASK> return self.InsertItemByIndex(parent_node, index, label, ct_type=ct_type) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.InsertItem(parent_node, index, label, ct_type=ct_type) <TAB> return self.AppendItem(parent_node, label, ct_type=ct_type)","if isinstance ( index , int ) :",147
"def fetch(): <TAB> retval = {} <TAB> content = retrieve_content(__url__) <TAB> if __check__ in content: <TAB>  <TAB> for line in content.split(""\n""): <TAB>  <TAB>  <TAB> line = line.strip() <TAB>  <TAB>  <TAB> if not line or line.startswith(""#"") or ""."" not in line: <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> reason = line.split("" # "")[1].split()[0].lower() <TAB>  <TAB>  <TAB>  <TAB> if reason == ""scanning"":  # too many false positives <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB>  <TAB> retval[line.split("" # "")[0]] = (__info__, __reference__) <TAB> return retval","if "" # "" in line :",157
"def _remove_event(self, event): <TAB> # Find event according to its timestamp. <TAB> # Index returned should be one behind. <TAB> i = bisect.bisect(self._eventq, event) <TAB> # Having two events with identical timestamp is unlikely but possible. <TAB> # I am going to move forward and compare timestamp AND object address <TAB> # to make sure the correct object is found. <TAB> while i > 0: <TAB>  <TAB> i -= 1 <TAB>  <TAB> e = self._eventq[i] <TAB>  <TAB> if e.timestamp != event.timestamp: <TAB>  <TAB>  <TAB> raise exception.EventNotFound(event) <MASK> self._eventq.pop(i) <TAB>  <TAB>  <TAB> return <TAB> raise exception.EventNotFound(event)",elif id ( e ) == id ( event ) :,177
"def _safe_get_content(self, session, resolve_from): <TAB> try: <TAB>  <TAB> resp = session.get(resolve_from, timeout=self._timeout) <MASK> return resp.content <TAB>  <TAB> raise self.ResolverError(""Error status_code={0}"".format(resp.status_code)) <TAB> except requests.RequestException: <TAB>  <TAB> raise self.ResolverError(""Request error from {0}"".format(resolve_from))",if resp . status_code == requests . codes . ok :,116
"def splitlines(self, sep=None, replace=None): <TAB> ""Return split lines from any file descriptor"" <TAB> for fd in self.fd: <TAB>  <TAB> fd.seek(0) <TAB>  <TAB> for line in fd.readlines(): <TAB>  <TAB>  <TAB> if replace and sep: <TAB>  <TAB>  <TAB>  <TAB> yield line.replace(replace, sep).split(sep) <MASK> yield line.replace(replace, "" "").split() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield line.split(sep)",elif replace :,122
"def disable_verity(): <TAB> """"""Disables dm-verity on the device."""""" <TAB> with log.waitfor(""Disabling dm-verity on %s"" % context.device): <TAB>  <TAB> root() <TAB>  <TAB> with AdbClient() as c: <TAB>  <TAB>  <TAB> reply = c.disable_verity() <TAB>  <TAB> if ""Verity already disabled"" in reply: <TAB>  <TAB>  <TAB> return <MASK> reboot(wait=True) <TAB>  <TAB> elif ""0006closed"" in reply: <TAB>  <TAB>  <TAB> return  # Emulator doesnt support Verity? <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.error(""Could not disable verity:\n%s"" % reply)","elif ""Now reboot your device"" in reply :",165
"def _process_property_change(self, msg): <TAB> msg = super(Select, self)._process_property_change(msg) <TAB> if ""value"" in msg: <TAB>  <TAB> if not self.values: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> elif msg[""value""] is None: <TAB>  <TAB>  <TAB> msg[""value""] = self.values[0] <TAB>  <TAB> else: <MASK> idx = indexOf(msg[""value""], self.unicode_values) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> idx = indexOf(msg[""value""], self.labels) <TAB>  <TAB>  <TAB> msg[""value""] = self._items[self.labels[idx]] <TAB> msg.pop(""options"", None) <TAB> return msg","if isIn ( msg [ ""value"" ] , self . unicode_values ) :",180
"def merge(module_name, tree1, tree2): <TAB> for child in tree2.node: <TAB>  <TAB> if isinstance(child, ast.Function): <TAB>  <TAB>  <TAB> replaceFunction(tree1, child.name, child) <TAB>  <TAB> elif isinstance(child, ast.Assign): <TAB>  <TAB>  <TAB> replaceAssign(tree1, child.nodes[0].name, child) <MASK> replaceClassMethods(tree1, child.name, child) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TranslationError( <TAB>  <TAB>  <TAB>  <TAB> ""Do not know how to merge %s"" % child, child, module_name <TAB>  <TAB>  <TAB> ) <TAB> return tree1","elif isinstance ( child , ast . Class ) :",159
"def handle(d: dict): <TAB> for key, value in d.items(): <MASK> if ""url"" not in value: <TAB>  <TAB>  <TAB>  <TAB> handle(value) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> global count <TAB>  <TAB>  <TAB>  <TAB> count += 1",if type ( value ) == dict :,72
def __stop_loggers(self): <TAB> if self._console_proc: <TAB>  <TAB> utils.nuke_subprocess(self._console_proc) <TAB>  <TAB> utils.nuke_subprocess(self._followfiles_proc) <TAB>  <TAB> self._console_proc = self._followfile_proc = None <MASK> self.job.warning_loggers.discard(self._logfile_warning_stream) <TAB>  <TAB> self._logfile_warning_stream.close(),if self . job :,113
"def unicode_metrics(metrics): <TAB> for i, metric in enumerate(metrics): <TAB>  <TAB> for key, value in metric.items(): <TAB>  <TAB>  <TAB> if isinstance(value, basestring): <TAB>  <TAB>  <TAB>  <TAB> metric[key] = unicode(value, errors=""replace"") <MASK> value_list = list(value) <TAB>  <TAB>  <TAB>  <TAB> for j, value_element in enumerate(value_list): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if isinstance(value_element, basestring): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value_list[j] = unicode(value_element, errors=""replace"") <TAB>  <TAB>  <TAB>  <TAB> metric[key] = tuple(value_list) <TAB>  <TAB> metrics[i] = metric <TAB> return metrics","elif isinstance ( value , tuple ) or isinstance ( value , list ) :",177
"def __getitem__(self, idx): <TAB> if isinstance(idx, slice): <TAB>  <TAB> start, stop, step = idx.indices(len(self)) <TAB>  <TAB> return [self._revoked_cert(i) for i in range(start, stop, step)] <TAB> else: <TAB>  <TAB> idx = operator.index(idx) <MASK> idx += len(self) <TAB>  <TAB> if not 0 <= idx < len(self): <TAB>  <TAB>  <TAB> raise IndexError <TAB>  <TAB> return self._revoked_cert(idx)",if idx < 0 :,125
"def _get_columns_and_column_names(row): <TAB> column_names = [] <TAB> columns = [] <TAB> duplicate_counter = 1 <TAB> for i, column_name in enumerate(row): <MASK> column_name = ""column_{}"".format(xl_col_to_name(i)) <TAB>  <TAB> if column_name in column_names: <TAB>  <TAB>  <TAB> column_name = ""{}{}"".format(column_name, duplicate_counter) <TAB>  <TAB>  <TAB> duplicate_counter += 1 <TAB>  <TAB> column_names.append(column_name) <TAB>  <TAB> columns.append( <TAB>  <TAB>  <TAB> {""name"": column_name, ""friendly_name"": column_name, ""type"": TYPE_STRING} <TAB>  <TAB> ) <TAB> return columns, column_names",if not column_name :,179
"def format(self, format, dumper, attrib, data): <TAB> if data: <TAB>  <TAB> logger.warn(""Unexpected data in %s object: %r"", attrib[""type""], data) <TAB> try: <TAB>  <TAB> return ImageGeneratorObjectType.format(self, format, dumper, attrib, data) <TAB> except ValueError: <MASK> attrib = attrib.copy() <TAB>  <TAB>  <TAB> attrib[""type""] = attrib[""type""][6:] <TAB>  <TAB> return dumper.dump_img(IMAGE, attrib, None)","if attrib [ ""type"" ] . startswith ( ""image+"" ) :",124
"def handle_facts_wwn(facts): <TAB> disk_shares = [] <TAB> for key, wwn in facts.iteritems(): <MASK> continue <TAB>  <TAB> path = key.replace(""wwn_"", """") <TAB>  <TAB> disk_shares.append( <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB> ""serial_number"": normalize_wwn(wwn), <TAB>  <TAB>  <TAB>  <TAB> ""volume"": ""/dev/mapper/%s"" % path, <TAB>  <TAB>  <TAB> } <TAB>  <TAB> ) <TAB> return disk_shares","if not key . startswith ( ""wwn_mpath"" ) :",127
"def _finalize_load(*exc_info): <TAB> try: <TAB>  <TAB> success_keys = [k for k in data_keys if k not in failed_keys] <MASK> self._holder_ref.put_objects_by_keys( <TAB>  <TAB>  <TAB>  <TAB> session_id, success_keys, pin_token=pin_token <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if exc_info: <TAB>  <TAB>  <TAB> raise exc_info[1].with_traceback(exc_info[2]) from None <TAB>  <TAB> if failed_keys: <TAB>  <TAB>  <TAB> raise StorageFull( <TAB>  <TAB>  <TAB>  <TAB> request_size=storage_full_sizes[0], <TAB>  <TAB>  <TAB>  <TAB> capacity=storage_full_sizes[1], <TAB>  <TAB>  <TAB>  <TAB> affected_keys=list(failed_keys), <TAB>  <TAB>  <TAB> ) <TAB> finally: <TAB>  <TAB> shared_bufs[:] = []",if success_keys :,200
"def _get_base64md5(self): <TAB> if ""md5"" in self.local_hashes and self.local_hashes[""md5""]: <TAB>  <TAB> md5 = self.local_hashes[""md5""] <MASK> md5 = md5.encode(""utf-8"") <TAB>  <TAB> return binascii.b2a_base64(md5).decode(""utf-8"").rstrip(""\n"")","if not isinstance ( md5 , bytes ) :",104
"def tag_configure(self, *args, **keys): <TAB> trace = False and not g.unitTesting <TAB> if trace: <TAB>  <TAB> g.trace(args, keys) <TAB> if len(args) == 1: <TAB>  <TAB> key = args[0] <TAB>  <TAB> self.tags[key] = keys <TAB>  <TAB> val = keys.get(""foreground"") <TAB>  <TAB> underline = keys.get(""underline"") <MASK> self.configDict[key] = val <TAB>  <TAB> if underline: <TAB>  <TAB>  <TAB> self.configUnderlineDict[key] = True <TAB> else: <TAB>  <TAB> g.trace(""oops"", args, keys)",if val :,150
"def _findSubpath(self, path, A, B, inside): <TAB> print(""finding"", A, B) <TAB> sub = None <TAB> for i in xrange(0, len(path) * 2):  # iterate twice with wrap around <TAB>  <TAB> j = i % len(path) <TAB>  <TAB> seg = path[j] <TAB>  <TAB> if inside.isInside(seg.midPoint()): <MASK> sub = Path(""subp"") <TAB>  <TAB>  <TAB> print(""seg"", sub is None, seg) <TAB>  <TAB>  <TAB> if sub is not None: <TAB>  <TAB>  <TAB>  <TAB> sub.append(seg) <TAB>  <TAB>  <TAB> if eq(seg.B, B): <TAB>  <TAB>  <TAB>  <TAB> break <TAB> print(""found"", sub) <TAB> return sub","if eq ( seg . A , A ) :",180
"def indent_block(self, cursor): <TAB> """"""Indent block after enter pressed"""""" <TAB> at_start_of_line = cursor.positionInBlock() == 0 <TAB> with self._neditor: <TAB>  <TAB> cursor.insertBlock() <MASK> indent = self._compute_indent(cursor) <TAB>  <TAB>  <TAB> if indent is not None: <TAB>  <TAB>  <TAB>  <TAB> cursor.insertText(indent) <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB> return False <TAB> self._neditor.ensureCursorVisible()",if not at_start_of_line :,127
def checkpoint(): <TAB> if checkpoint_asserts: <TAB>  <TAB> self.assert_integrity_idxs_take() <TAB>  <TAB> if node in self.idxs_memo: <TAB>  <TAB>  <TAB> toposort(self.idxs_memo[node]) <MASK> for take in self.take_memo[node]: <TAB>  <TAB>  <TAB>  <TAB> toposort(take),if node in self . take_memo :,86
"def handle(self, *args, **options): <TAB> with advisory_lock(""send-notifications-command"", wait=False) as acquired: <MASK> qs = HistoryChangeNotification.objects.all().order_by(""-id"") <TAB>  <TAB>  <TAB> for change_notification in iter_queryset(qs, itersize=100): <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> send_sync_notifications(change_notification.pk) <TAB>  <TAB>  <TAB>  <TAB> except HistoryChangeNotification.DoesNotExist: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""Other process already running"")",if acquired :,142
"def _parse_version_parts(s): <TAB> for part in component_re.split(s): <TAB>  <TAB> part = replace(part, part) <TAB>  <TAB> if part in ["""", "".""]: <TAB>  <TAB>  <TAB> continue <MASK> yield part.zfill(8)  # pad for numeric comparison <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield ""*"" + part <TAB> yield ""*final""  # ensure that alpha/beta/candidate are before final","if part [ : 1 ] in ""0123456789"" :",109
"def set_password(user_id): <TAB> try: <TAB>  <TAB> user = Journalist.query.get(user_id) <TAB> except NoResultFound: <TAB>  <TAB> abort(404) <TAB> password = request.form.get(""password"") <TAB> if set_diceware_password(user, password) is not False: <MASK> revoke_token(user, user.last_token) <TAB>  <TAB> user.session_nonce += 1 <TAB>  <TAB> db.session.commit() <TAB> return redirect(url_for(""admin.edit_user"", user_id=user_id))",if user . last_token is not None :,147
"def _get_normal_median_depth(normal_counts): <TAB> depths = [] <TAB> with open(normal_counts) as in_handle: <TAB>  <TAB> header = None <TAB>  <TAB> for line in in_handle: <MASK> header = line.strip().split() <TAB>  <TAB>  <TAB> elif header: <TAB>  <TAB>  <TAB>  <TAB> n_vals = dict(zip(header, line.strip().split())) <TAB>  <TAB>  <TAB>  <TAB> depths.append(int(n_vals[""REF_COUNT""]) + int(n_vals[""ALT_COUNT""])) <TAB> return np.median(depths)","if header is None and not line . startswith ( ""@"" ) :",145
"def _gen_langs_in_db(self): <TAB> for d in os.listdir(join(self.base_dir, ""db"")): <TAB>  <TAB> if d in self._non_lang_db_dirs: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> lang_path = join(self.base_dir, ""db"", d, ""lang"") <MASK> log.warn( <TAB>  <TAB>  <TAB>  <TAB> ""unexpected lang-zone db dir without 'lang' file: "" <TAB>  <TAB>  <TAB>  <TAB> ""`%s' (skipping)"" % dirname(lang_path) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> fin = open(lang_path, ""r"") <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> lang = fin.read().strip() <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> fin.close() <TAB>  <TAB> yield lang",if not exists ( lang_path ) :,194
"def negate(monad): <TAB> sql = monad.getsql()[0] <TAB> translator = monad.translator <TAB> if translator.dialect == ""Oracle"": <TAB>  <TAB> result_sql = [""IS_NULL"", sql] <TAB> else: <TAB>  <TAB> result_sql = [""EQ"", sql, [""VALUE"", """"]] <MASK> if isinstance(monad, AttrMonad): <TAB>  <TAB>  <TAB>  <TAB> result_sql = [""OR"", result_sql, [""IS_NULL"", sql]] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> result_sql = [""EQ"", [""COALESCE"", sql, [""VALUE"", """"]], [""VALUE"", """"]] <TAB> result = BoolExprMonad(result_sql, nullable=False) <TAB> result.aggregated = monad.aggregated <TAB> return result",if monad . nullable :,188
"def _model_shorthand(self, args): <TAB> accum = [] <TAB> for arg in args: <TAB>  <TAB> if isinstance(arg, Node): <TAB>  <TAB>  <TAB> accum.append(arg) <TAB>  <TAB> elif isinstance(arg, Query): <TAB>  <TAB>  <TAB> accum.append(arg) <TAB>  <TAB> elif isinstance(arg, ModelAlias): <TAB>  <TAB>  <TAB> accum.extend(arg.get_proxy_fields()) <MASK> accum.extend(arg._meta.declared_fields) <TAB> return accum","elif isclass ( arg ) and issubclass ( arg , Model ) :",125
"def get_hashes_from_fingerprint_with_reason(event, fingerprint): <TAB> default_values = set([""{{ default }}"", ""{{default}}""]) <TAB> if any(d in fingerprint for d in default_values): <TAB>  <TAB> default_hashes = get_hashes_for_event_with_reason(event) <TAB>  <TAB> hash_count = len(default_hashes[1]) <TAB> else: <TAB>  <TAB> hash_count = 1 <TAB> hashes = OrderedDict((bit, []) for bit in fingerprint) <TAB> for idx in xrange(hash_count): <TAB>  <TAB> for bit in fingerprint: <MASK> hashes[bit].append(default_hashes) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> hashes[bit] = bit <TAB> return hashes.items()",if bit in default_values :,180
"def default(self, obj): <TAB> if hasattr(obj, ""__json__""): <TAB>  <TAB> return obj.__json__() <TAB> elif isinstance(obj, collections.Iterable): <TAB>  <TAB> return list(obj) <TAB> elif isinstance(obj, dt.datetime): <TAB>  <TAB> return obj.isoformat() <TAB> elif hasattr(obj, ""__getitem__"") and hasattr(obj, ""keys""): <TAB>  <TAB> return dict(obj) <TAB> elif hasattr(obj, ""__dict__""): <TAB>  <TAB> return { <TAB>  <TAB>  <TAB> member: getattr(obj, member) <TAB>  <TAB>  <TAB> for member in dir(obj) <MASK> and not hasattr(getattr(obj, member), ""__call__"") <TAB>  <TAB> } <TAB> return json.JSONEncoder.default(self, obj)","if not member . startswith ( ""_"" )",172
"def get_http_auth(self, name): <TAB> auth = self._config.get(""http-basic.{}"".format(name)) <TAB> if not auth: <TAB>  <TAB> username = self._config.get(""http-basic.{}.username"".format(name)) <TAB>  <TAB> password = self._config.get(""http-basic.{}.password"".format(name)) <TAB>  <TAB> if not username and not password: <TAB>  <TAB>  <TAB> return None <TAB> else: <TAB>  <TAB> username, password = auth[""username""], auth.get(""password"") <MASK> password = self.keyring.get_password(name, username) <TAB> return { <TAB>  <TAB> ""username"": username, <TAB>  <TAB> ""password"": password, <TAB> }",if password is None :,166
"def add_libdirs(self, envvar, sep, fatal=False): <TAB> v = os.environ.get(envvar) <TAB> if not v: <TAB>  <TAB> return <TAB> for dir in str.split(v, sep): <TAB>  <TAB> dir = str.strip(dir) <MASK> continue <TAB>  <TAB> dir = os.path.normpath(dir) <TAB>  <TAB> if os.path.isdir(dir): <TAB>  <TAB>  <TAB> if not dir in self.library_dirs: <TAB>  <TAB>  <TAB>  <TAB> self.library_dirs.append(dir) <TAB>  <TAB> elif fatal: <TAB>  <TAB>  <TAB> fail(""FATAL: bad directory %s in environment variable %s"" % (dir, envvar))",if not dir :,159
"def PARSE_TWO_PARAMS(x, y): <TAB> """"""used to convert different possible x/y params to a tuple"""""" <TAB> if y is not None: <TAB>  <TAB> return (x, y) <TAB> else: <TAB>  <TAB> if isinstance(x, (list, tuple)): <TAB>  <TAB>  <TAB> return (x[0], x[1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if isinstance(x, UNIVERSAL_STRING): <TAB>  <TAB>  <TAB>  <TAB> x = x.strip() <MASK> return [int(w.strip()) for w in x.split("","")] <TAB>  <TAB>  <TAB> return (x, x)","if "","" in x :",147
"def _load_from_sym_dir(self, root): <TAB> root = os.path.abspath(root) <TAB> prefix_len = len(root) + 1 <TAB> for base, _, filenames in os.walk(root): <TAB>  <TAB> for filename in filenames: <MASK> continue <TAB>  <TAB>  <TAB> path = os.path.join(base, filename) <TAB>  <TAB>  <TAB> lib_path = ""/"" + path[prefix_len:-4] <TAB>  <TAB>  <TAB> self.add(lib_path, ELF.load_dump(path))","if not filename . endswith ( "".sym"" ) :",134
"def is_vertical(self): <TAB> if not self.isFloating(): <TAB>  <TAB> par = self.parent() <MASK> return par.dockWidgetArea(self) in ( <TAB>  <TAB>  <TAB>  <TAB> Qt.LeftDockWidgetArea, <TAB>  <TAB>  <TAB>  <TAB> Qt.RightDockWidgetArea, <TAB>  <TAB>  <TAB> ) <TAB> return self.size().height() > self.size().width()","if par and hasattr ( par , ""dockWidgetArea"" ) :",106
"def writeBit(self, state, endian): <TAB> if self._bit_pos == 7: <TAB>  <TAB> self._bit_pos = 0 <TAB>  <TAB> if state: <MASK> self._byte |= 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._byte |= 128 <TAB>  <TAB> self._output.write(chr(self._byte)) <TAB>  <TAB> self._byte = 0 <TAB> else: <TAB>  <TAB> if state: <TAB>  <TAB>  <TAB> if endian is BIG_ENDIAN: <TAB>  <TAB>  <TAB>  <TAB> self._byte |= 1 << self._bit_pos <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._byte |= 1 << (7 - self._bit_pos) <TAB>  <TAB> self._bit_pos += 1",if endian is BIG_ENDIAN :,177
"def init(self): <TAB> self.sock.setblocking(True) <TAB> if self.parser is None: <TAB>  <TAB> # wrap the socket if needed <MASK> self.sock = ssl.wrap_socket( <TAB>  <TAB>  <TAB>  <TAB> self.sock, server_side=True, **self.cfg.ssl_options <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> # initialize the parser <TAB>  <TAB> self.parser = http.RequestParser(self.cfg, self.sock, self.client)",if self . cfg . is_ssl :,120
"def construct_scalar(self, node): <TAB> if isinstance(node, MappingNode): <TAB>  <TAB> for key_node, value_node in node.value: <MASK> return self.construct_scalar(value_node) <TAB> return super().construct_scalar(node)","if key_node . tag == ""tag:yaml.org,2002:value"" :",85
"def typeNewLine(self, line): <TAB> if line >= 0: <TAB>  <TAB> iter = self.buffer.get_iter_at_line(line) <MASK> iter.forward_to_line_end() <TAB>  <TAB> self.buffer.place_cursor(iter) <TAB> elif line < 0: <TAB>  <TAB> iter = self.buffer.get_end_iter() <TAB>  <TAB> for i in range(line, -1): <TAB>  <TAB>  <TAB> iter.backward_line() <TAB>  <TAB> iter.forward_to_line_end() <TAB>  <TAB> self.buffer.place_cursor(iter) <TAB> press(self.view, ""\n"")",if not iter . ends_line ( ) :,156
"def _render_ib_interfaces(cls, network_state, iface_contents, flavor): <TAB> ib_filter = renderer.filter_by_type(""infiniband"") <TAB> for iface in network_state.iter_interfaces(ib_filter): <TAB>  <TAB> iface_name = iface[""name""] <TAB>  <TAB> iface_cfg = iface_contents[iface_name] <TAB>  <TAB> iface_cfg.kind = ""infiniband"" <MASK> route_cfg = iface_cfg.routes <TAB>  <TAB> cls._render_subnets( <TAB>  <TAB>  <TAB> iface_cfg, iface_subnets, network_state.has_default_route, flavor <TAB>  <TAB> ) <TAB>  <TAB> cls._render_subnet_routes(iface_cfg, route_cfg, iface_subnets, flavor)","iface_subnets = iface . get ( ""subnets"" , [ ] )",193
"def stop(self): <TAB> """"""Stops the slapd server, and waits for it to terminate"""""" <TAB> if self._proc is not None: <TAB>  <TAB> self._log.debug(""stopping slapd"") <MASK> self._proc.terminate() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> import posix, signal <TAB>  <TAB>  <TAB> posix.kill(self._proc.pid, signal.SIGHUP) <TAB>  <TAB>  <TAB> # time.sleep(1) <TAB>  <TAB>  <TAB> # posix.kill(self._proc.pid, signal.SIGTERM) <TAB>  <TAB>  <TAB> # posix.kill(self._proc.pid, signal.SIGKILL) <TAB>  <TAB> self.wait()","if hasattr ( self . _proc , ""terminate"" ) :",160
"def _listen(self, consumer_id: str) -> AsyncIterable[Any]: <TAB> try: <TAB>  <TAB> while True: <MASK> async for msg in self._listen_to_queue(consumer_id): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if msg is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield msg <TAB>  <TAB>  <TAB>  <TAB> await asyncio.sleep(0.5) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> async for msg in self._listen_to_ws(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield msg <TAB> except asyncio.CancelledError: <TAB>  <TAB> pass <TAB> except Exception as e: <TAB>  <TAB> raise e",if self . _listening :,153
"def discover_misago_admin(): <TAB> for app in apps.get_app_configs(): <TAB>  <TAB> module = import_module(app.name) <TAB>  <TAB> if not hasattr(module, ""admin""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> admin_module = import_module(""%s.admin"" % app.name) <TAB>  <TAB> if hasattr(admin_module, ""MisagoAdminExtension""): <TAB>  <TAB>  <TAB> extension = getattr(admin_module, ""MisagoAdminExtension"")() <MASK> extension.register_navigation_nodes(site) <TAB>  <TAB>  <TAB> if hasattr(extension, ""register_urlpatterns""): <TAB>  <TAB>  <TAB>  <TAB> extension.register_urlpatterns(urlpatterns)","if hasattr ( extension , ""register_navigation_nodes"" ) :",169
"def update_job(self, job): <TAB> if not self.redis.hexists(self.jobs_key, job.id): <TAB>  <TAB> raise JobLookupError(job.id) <TAB> with self.redis.pipeline() as pipe: <TAB>  <TAB> pipe.hset( <TAB>  <TAB>  <TAB> self.jobs_key, <TAB>  <TAB>  <TAB> job.id, <TAB>  <TAB>  <TAB> pickle.dumps(job.__getstate__(), self.pickle_protocol), <TAB>  <TAB> ) <MASK> pipe.zadd( <TAB>  <TAB>  <TAB>  <TAB> self.run_times_key, <TAB>  <TAB>  <TAB>  <TAB> {job.id: datetime_to_utc_timestamp(job.next_run_time)}, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pipe.zrem(self.run_times_key, job.id) <TAB>  <TAB> pipe.execute()",if job . next_run_time :,200
"def _get_first_available_entry_node(self) -> Optional[str]: <TAB> for entry_node in self.entry_nodes: <TAB>  <TAB> if entry_node not in self.locked_entry_nodes: <TAB>  <TAB>  <TAB> _, wait_until = self._parse_entry_node(entry_node) <TAB>  <TAB>  <TAB> now = time.time() <MASK> return entry_node <TAB> return None",if wait_until <= now :,105
"def answers(self, other): <TAB> if not isinstance(other, TCP): <TAB>  <TAB> return 0 <TAB> if conf.checkIPsrc: <TAB>  <TAB> if not ((self.sport == other.sport) and (self.dport == other.dport)): <TAB>  <TAB>  <TAB> return 0 <TAB> if conf.check_TCPerror_seqack: <TAB>  <TAB> if self.seq is not None: <TAB>  <TAB>  <TAB> if self.seq != other.seq: <TAB>  <TAB>  <TAB>  <TAB> return 0 <TAB>  <TAB> if self.ack is not None: <MASK> return 0 <TAB> return 1",if self . ack != other . ack :,143
"def run(self): <TAB> if self.check(): <TAB>  <TAB> path = ""/BWT/utils/logs/read_log.jsp?filter=&log=../../../../../../../../..{}"".format( <TAB>  <TAB>  <TAB> self.filename <TAB>  <TAB> ) <TAB>  <TAB> response = self.http_request(method=""GET"", path=path) <MASK> print_success(""Exploit success"") <TAB>  <TAB>  <TAB> print_status(""Reading file: {}"".format(self.filename)) <TAB>  <TAB>  <TAB> print_info(response.text) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print_error(""Exploit failed - could not read file"") <TAB> else: <TAB>  <TAB> print_error(""Exploit failed - device seems to be not vulnerable"")",if response and response . status_code == 200 and len ( response . text ) :,186
"def write(self, s): <TAB> if self.closed: <TAB>  <TAB> raise ValueError(""write to closed file"") <TAB> if type(s) not in (unicode, str, bytearray): <TAB>  <TAB> # See issue #19481 <TAB>  <TAB> if isinstance(s, unicode): <TAB>  <TAB>  <TAB> s = unicode.__getitem__(s, slice(None)) <MASK> s = str.__str__(s) <TAB>  <TAB> elif isinstance(s, bytearray): <TAB>  <TAB>  <TAB> s = bytearray.__str__(s) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError(""must be string, not "" + type(s).__name__) <TAB> return self.shell.write(s, self.tags)","elif isinstance ( s , str ) :",161
"def test_checkblock_valid(self): <TAB> for comment, fHeader, fCheckPoW, cur_time, blk in load_test_vectors( <TAB>  <TAB> ""checkblock_valid.json"" <TAB> ): <TAB>  <TAB> try: <MASK> CheckBlockHeader(blk, fCheckPoW=fCheckPoW, cur_time=cur_time) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> CheckBlock(blk, fCheckPoW=fCheckPoW, cur_time=cur_time) <TAB>  <TAB> except ValidationError as err: <TAB>  <TAB>  <TAB> self.fail('Failed ""%s"" with error %r' % (comment, err))",if fHeader :,160
"def _lookup_fqdn(ip): <TAB> try: <TAB>  <TAB> return [socket.getfqdn(socket.gethostbyaddr(ip)[0])] <TAB> except socket.herror as err: <MASK> # No FQDN for this IP address, so we don't need to know this all the time. <TAB>  <TAB>  <TAB> log.debug(""Unable to resolve address %s: %s"", ip, err) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.error(err_message, err) <TAB> except (socket.error, socket.gaierror, socket.timeout) as err: <TAB>  <TAB> log.error(err_message, err)","if err . errno in ( 0 , HOST_NOT_FOUND , NO_DATA ) :",169
"def send_telnet(self, *args: str): <TAB> try: <TAB>  <TAB> shell = TelnetShell(self.host) <TAB>  <TAB> for command in args: <MASK> shell.check_or_download_busybox() <TAB>  <TAB>  <TAB>  <TAB> shell.run_ftp() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> shell.exec(command) <TAB>  <TAB> shell.close() <TAB> except Exception as e: <TAB>  <TAB> _LOGGER.exception(f""Telnet command error: {e}"")","if command == ""ftp"" :",127
"def write(path, data, kind=""OTHER"", dohex=0): <TAB> asserttype1(data) <TAB> kind = string.upper(kind) <TAB> try: <TAB>  <TAB> os.remove(path) <TAB> except os.error: <TAB>  <TAB> pass <TAB> err = 1 <TAB> try: <MASK> writelwfn(path, data) <TAB>  <TAB> elif kind == ""PFB"": <TAB>  <TAB>  <TAB> writepfb(path, data) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> writeother(path, data, dohex) <TAB>  <TAB> err = 0 <TAB> finally: <TAB>  <TAB> if err and not DEBUG: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> os.remove(path) <TAB>  <TAB>  <TAB> except os.error: <TAB>  <TAB>  <TAB>  <TAB> pass","if kind == ""LWFN"" :",182
"def ApplyInScriptedSection(self, codeBlock, fn, args): <TAB> self.BeginScriptedSection() <TAB> try: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> # 				print ""ApplyInSS"", codeBlock, fn, args <TAB>  <TAB>  <TAB> return self._ApplyInScriptedSection(fn, args) <TAB>  <TAB> finally: <MASK> self.debugManager.OnLeaveScript() <TAB>  <TAB>  <TAB> self.EndScriptedSection() <TAB> except: <TAB>  <TAB> self.HandleException(codeBlock)",if self . debugManager :,129
"def _escape_attrib(text): <TAB> # escape attribute value <TAB> try: <TAB>  <TAB> if ""&"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""&"", ""&amp;"") <MASK> text = text.replace(""<"", ""&lt;"") <TAB>  <TAB> if "">"" in text: <TAB>  <TAB>  <TAB> text = text.replace("">"", ""&gt;"") <TAB>  <TAB> if '""' in text: <TAB>  <TAB>  <TAB> text = text.replace('""', ""&quot;"") <TAB>  <TAB> if ""\n"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""\n"", ""&#10;"") <TAB>  <TAB> return text <TAB> except (TypeError, AttributeError):  # pragma: no cover <TAB>  <TAB> _raise_serialization_error(text)","if ""<"" in text :",160
"def compile_relation(self, method, expr, range_list, negated=False): <TAB> ranges = [] <TAB> for item in range_list[1]: <MASK> ranges.append(self.compile(item[0])) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ranges.append(""%s..%s"" % tuple(map(self.compile, item))) <TAB> return ""%s%s %s %s"" % ( <TAB>  <TAB> self.compile(expr), <TAB>  <TAB> negated and "" not"" or """", <TAB>  <TAB> method, <TAB>  <TAB> "","".join(ranges), <TAB> )",if item [ 0 ] == item [ 1 ] :,144
"def emptyTree(self): <TAB> for child in self: <TAB>  <TAB> childObj = child.getObject() <TAB>  <TAB> del childObj[NameObject(""/Parent"")] <TAB>  <TAB> if NameObject(""/Next"") in childObj: <TAB>  <TAB>  <TAB> del childObj[NameObject(""/Next"")] <MASK> del childObj[NameObject(""/Prev"")] <TAB> if NameObject(""/Count"") in self: <TAB>  <TAB> del self[NameObject(""/Count"")] <TAB> if NameObject(""/First"") in self: <TAB>  <TAB> del self[NameObject(""/First"")] <TAB> if NameObject(""/Last"") in self: <TAB>  <TAB> del self[NameObject(""/Last"")]","if NameObject ( ""/Prev"" ) in childObj :",155
"def connect_to_uri(self, uri, autoconnect=None, do_start=True): <TAB> try: <TAB>  <TAB> conn = self._check_conn(uri) <TAB>  <TAB> if not conn: <TAB>  <TAB>  <TAB> # Unknown connection, add it <TAB>  <TAB>  <TAB> conn = self.add_conn(uri) <TAB>  <TAB> if autoconnect is not None: <TAB>  <TAB>  <TAB> conn.set_autoconnect(bool(autoconnect)) <TAB>  <TAB> self.show_manager() <MASK> conn.open() <TAB>  <TAB> return conn <TAB> except Exception: <TAB>  <TAB> logging.exception(""Error connecting to %s"", uri) <TAB>  <TAB> return None",if do_start :,152
"def get_expression(self): <TAB> """"""Return the expression as a printable string."""""" <TAB> l = [] <TAB> for c in self.content: <TAB>  <TAB> if c.op is not None:  # only applies to first cell <TAB>  <TAB>  <TAB> l.append(c.op) <MASK> l.append(""("" + c.child.get_expression() + "")"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> l.append(""%d"" % c.get_value()) <TAB> return """".join(l)",if c . child is not None :,124
"def to_word_end(view, s): <TAB> if mode == modes.NORMAL: <TAB>  <TAB> pt = word_end_reverse(view, s.b, count) <TAB>  <TAB> return sublime.Region(pt) <TAB> elif mode in (modes.VISUAL, modes.VISUAL_BLOCK): <MASK> pt = word_end_reverse(view, s.b - 1, count) <TAB>  <TAB>  <TAB> if pt > s.a: <TAB>  <TAB>  <TAB>  <TAB> return sublime.Region(s.a, pt + 1) <TAB>  <TAB>  <TAB> return sublime.Region(s.a + 1, pt) <TAB>  <TAB> pt = word_end_reverse(view, s.b, count) <TAB>  <TAB> return sublime.Region(s.a, pt) <TAB> return s",if s . a < s . b :,191
"def whichmodule(obj, name): <TAB> """"""Find the module an object belong to."""""" <TAB> module_name = getattr(obj, ""__module__"", None) <TAB> if module_name is not None: <TAB>  <TAB> return module_name <TAB> # Protect the iteration by using a list copy of sys.modules against dynamic <TAB> # modules that trigger imports of other modules upon calls to getattr. <TAB> for module_name, module in sys.modules.copy().items(): <MASK> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if _getattribute(module, name)[0] is obj: <TAB>  <TAB>  <TAB>  <TAB> return module_name <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB> pass <TAB> return ""__main__""","if module_name == ""__main__"" or module is None :",171
"def summarize_scalar_dict(name_data, step, name_scope=""Losses/""): <TAB> if name_data: <TAB>  <TAB> with tf.name_scope(name_scope): <TAB>  <TAB>  <TAB> for name, data in name_data.items(): <MASK> tf.compat.v2.summary.scalar(name=name, data=data, step=step)",if data is not None :,98
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.set_content(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 18: <TAB>  <TAB>  <TAB> self.set_blob_key(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 24: <TAB>  <TAB>  <TAB> self.set_width(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 32: <TAB>  <TAB>  <TAB> self.set_height(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 10 :,182
"def gather_files(fileset): <TAB> common_type = get_common_filetype(fileset) <TAB> files = [] <TAB> for file in fileset.file: <TAB>  <TAB> filename = file.name <TAB>  <TAB> if file.is_include_file == True: <TAB>  <TAB>  <TAB> filename = {} <TAB>  <TAB>  <TAB> filename[file.name] = {""is_include_file"": True} <MASK> if type(filename) == str: <TAB>  <TAB>  <TAB>  <TAB> filename = {} <TAB>  <TAB>  <TAB> filename[file.name] = {""file_type"": file.file_type} <TAB>  <TAB> files.append(filename) <TAB> return files",if file . file_type != common_type :,158
"def data(self, index: QModelIndex, role=Qt.DisplayRole): <TAB> if not index.isValid(): <TAB>  <TAB> return None <TAB> if role == Qt.DisplayRole or role == Qt.EditRole: <TAB>  <TAB> i = index.row() <TAB>  <TAB> j = index.column() <TAB>  <TAB> fieldtype = self.field_types[i] <MASK> return fieldtype.caption <TAB>  <TAB> elif j == 1: <TAB>  <TAB>  <TAB> return fieldtype.function.name <TAB>  <TAB> elif j == 2: <TAB>  <TAB>  <TAB> return ProtocolLabel.DISPLAY_FORMATS[fieldtype.display_format_index]",if j == 0 :,142
"def format_coord(x, y): <TAB> # callback function to format coordinate display in toolbar <TAB> x = int(x + 0.5) <TAB> y = int(y + 0.5) <TAB> try: <MASK> return ""%s @ %s [%4i, %4i]"" % (cur_ax_dat[1][y, x], current, x, y) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""%s @ [%4i, %4i]"" % (data[y, x], x, y) <TAB> except IndexError: <TAB>  <TAB> return """"",if dims :,137
"def getAllUIExtensions(self): <TAB> extensions = [] <TAB> if getExecutionCodeType() == ""MEASURE"": <TAB>  <TAB> text = getMeasurementResultString(self) <TAB>  <TAB> extensions.append(TextUIExtension(text)) <TAB> errorType = self.getErrorHandlingType() <TAB> if errorType in (""MESSAGE"", ""EXCEPTION""): <TAB>  <TAB> data = infoByNode[self.identifier] <TAB>  <TAB> message = data.errorMessage <MASK> extensions.append(ErrorUIExtension(message)) <TAB> extraExtensions = self.getUIExtensions() <TAB> if extraExtensions is not None: <TAB>  <TAB> extensions.extend(extraExtensions) <TAB> return extensions",if message is not None and data . showErrorMessage :,167
"def on_notify(self, notification): <TAB> subject = notification[""subject""] <TAB> if subject.startswith(""remote_recording.""): <TAB>  <TAB> if ""should_start"" in subject and self.online: <TAB>  <TAB>  <TAB> session_name = notification[""session_name""] <TAB>  <TAB>  <TAB> self.sensor.set_control_value(""capture_session_name"", session_name) <TAB>  <TAB>  <TAB> self.sensor.set_control_value(""local_capture"", True) <MASK> self.sensor.set_control_value(""local_capture"", False)","elif ""should_stop"" in subject :",135
"def _log_conn_errors(self): <TAB> if ""connection"" in self.event.data: <TAB>  <TAB> cinfo = self.event.data[""connection""] <MASK> err_msg = cinfo.get(""error"", [None, None])[1] <TAB>  <TAB>  <TAB> if err_msg: <TAB>  <TAB>  <TAB>  <TAB> self._log_status(err_msg)","if not cinfo . get ( ""live"" ) :",96
"def setChanged(self, c, changed): <TAB> # Find the tab corresponding to c. <TAB> dw = c.frame.top  # A DynamicWindow <TAB> i = self.indexOf(dw) <TAB> if i < 0: <TAB>  <TAB> return <TAB> s = self.tabText(i) <TAB> s = g.u(s) <TAB> if len(s) > 2: <TAB>  <TAB> if changed: <MASK> title = ""* "" + s <TAB>  <TAB>  <TAB>  <TAB> self.setTabText(i, title) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if s.startswith(""* ""): <TAB>  <TAB>  <TAB>  <TAB> title = s[2:] <TAB>  <TAB>  <TAB>  <TAB> self.setTabText(i, title)","if not s . startswith ( ""* "" ) :",172
"def load_file_in_same_dir(ref_file, filename): <TAB> """"""Load a given file. Works even when the file is contained inside a zip."""""" <TAB> from couchpotato.core.helpers.encoding import toUnicode <TAB> path = split_path(toUnicode(ref_file))[:-1] + [filename] <TAB> for i, p in enumerate(path): <MASK> zfilename = os.path.join(*path[: i + 1]) <TAB>  <TAB>  <TAB> zfile = zipfile.ZipFile(zfilename) <TAB>  <TAB>  <TAB> return zfile.read(""/"".join(path[i + 1 :])) <TAB> return u(io.open(os.path.join(*path), encoding=""utf-8"").read())","if p . endswith ( "".zip"" ) :",172
def __mpcReadyInSlaveMode(self): <TAB> while True: <TAB>  <TAB> time.sleep(10) <TAB>  <TAB> if not win32gui.IsWindow(self.__listener.mpcHandle): <MASK> self.callbacks.onMpcClosed(None) <TAB>  <TAB>  <TAB> break,if self . callbacks . onMpcClosed :,79
"def _invalidate(self, resource_group_name: str, scale_set_name: str) -> None: <TAB> with self._lock: <MASK> del self._instance_cache[(resource_group_name, scale_set_name)] <TAB>  <TAB> if resource_group_name in self._scale_set_cache: <TAB>  <TAB>  <TAB> del self._scale_set_cache[resource_group_name] <TAB>  <TAB> if resource_group_name in self._remaining_instances_cache: <TAB>  <TAB>  <TAB> del self._remaining_instances_cache[resource_group_name]","if ( resource_group_name , scale_set_name ) in self . _instance_cache :",154
"def close(self): <TAB> if self._serial is not None: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self._serial.cancel_read() <MASK> self._reading_thread.join() <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> self._serial.close() <TAB>  <TAB>  <TAB>  <TAB> self._serial = None <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> logging.exception(""Couldn't close serial"")",if self . _reading_thread :,110
"def channel_sizes(self): <TAB> """"""List of channel sizes: [(width, height)]."""""" <TAB> sizes = [] <TAB> for channel in self.channel_info: <MASK> sizes.append((self.mask_data.width, self.mask_data.height)) <TAB>  <TAB> elif channel.id == ChannelID.REAL_USER_LAYER_MASK: <TAB>  <TAB>  <TAB> sizes.append((self.mask_data.real_width, self.mask_data.real_height)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sizes.append((self.width, self.height)) <TAB> return sizes",if channel . id == ChannelID . USER_LAYER_MASK :,151
"def get_module_settings(): <TAB> included_setting = [] <TAB> module = DataGetter.get_module() <TAB> if module is not None: <TAB>  <TAB> if module.ticket_include: <TAB>  <TAB>  <TAB> included_setting.append(""ticketing"") <MASK> included_setting.append(""payments"") <TAB>  <TAB> if module.donation_include: <TAB>  <TAB>  <TAB> included_setting.append(""donations"") <TAB> return included_setting",if module . payment_include :,109
"def _format_block( <TAB> self, prefix: str, lines: List[str], padding: str = None) -> List[str]: <TAB> if lines: <MASK> padding = "" "" * len(prefix) <TAB>  <TAB> result_lines = [] <TAB>  <TAB> for i, line in enumerate(lines): <TAB>  <TAB>  <TAB> if i == 0: <TAB>  <TAB>  <TAB>  <TAB> result_lines.append((prefix + line).rstrip()) <TAB>  <TAB>  <TAB> elif line: <TAB>  <TAB>  <TAB>  <TAB> result_lines.append(padding + line) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> result_lines.append("""") <TAB>  <TAB> return result_lines <TAB> else: <TAB>  <TAB> return [prefix]",if padding is None :,161
"def get_task_by_id(events, task_id): <TAB> if hasattr(Task, ""_fields""):  # Old version <TAB>  <TAB> return events.state.tasks.get(task_id) <TAB> else: <TAB>  <TAB> _fields = Task._defaults.keys() <TAB>  <TAB> task = events.state.tasks.get(task_id) <MASK> task._fields = _fields <TAB>  <TAB> return task",if task is not None :,103
"def check(self, value): <TAB> try: <MASK> v = value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> v = decimal.Decimal(str(value).replace(self.dot, ""."")) <TAB>  <TAB> return v, None <TAB> except (ValueError, TypeError, decimal.InvalidOperation): <TAB>  <TAB> return value, translate(self.message)","if isinstance ( value , decimal . Decimal ) :",90
"def check_sales_order_on_hold_or_close(self, ref_fieldname): <TAB> for d in self.get(""items""): <MASK> status = frappe.db.get_value(""Sales Order"", d.get(ref_fieldname), ""status"") <TAB>  <TAB>  <TAB> if status in (""Closed"", ""On Hold""): <TAB>  <TAB>  <TAB>  <TAB> frappe.throw( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _(""Sales Order {0} is {1}"").format(d.get(ref_fieldname), status) <TAB>  <TAB>  <TAB>  <TAB> )",if d . get ( ref_fieldname ) :,137
"def nested_match(expect, value): <TAB> if expect == value: <TAB>  <TAB> return True <TAB> if isinstance(expect, dict) and isinstance(value, dict): <TAB>  <TAB> for k, v in expect.items(): <TAB>  <TAB>  <TAB> if k in value: <TAB>  <TAB>  <TAB>  <TAB> if not nested_match(v, value[k]): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True <TAB> if isinstance(expect, list) and isinstance(value, list): <TAB>  <TAB> for x, y in zip(expect, value): <MASK> return False <TAB>  <TAB> return True <TAB> return False","if not nested_match ( x , y ) :",162
"def test_setup_app_sets_loader(self, app): <TAB> prev = os.environ.get(""CELERY_LOADER"") <TAB> try: <TAB>  <TAB> cmd = MockCommand(app=app) <TAB>  <TAB> cmd.setup_app_from_commandline([""--loader=X.Y:Z""]) <TAB>  <TAB> assert os.environ[""CELERY_LOADER""] == ""X.Y:Z"" <TAB> finally: <MASK> os.environ[""CELERY_LOADER""] = prev <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> del os.environ[""CELERY_LOADER""]",if prev is not None :,141
"def set_labels_for_constraints(self, constraints): <TAB> for label in self._constraints_to_label_args(constraints): <MASK> log.info( <TAB>  <TAB>  <TAB>  <TAB> ""setting node '%s' label '%s' to '%s'"", <TAB>  <TAB>  <TAB>  <TAB> self.name, <TAB>  <TAB>  <TAB>  <TAB> label.name, <TAB>  <TAB>  <TAB>  <TAB> label.value, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.label_add(label.name, label.value)",if label not in self . labels :,119
"def _match(self, byte_chunk): <TAB> quote_character = None <TAB> data = byte_chunk.nhtml <TAB> open_angle_bracket = data.rfind(""<"") <TAB> # We are inside <... <TAB> if open_angle_bracket <= data.rfind("">""): <TAB>  <TAB> return False <TAB> for s in data[open_angle_bracket + 1 :]: <TAB>  <TAB> if s in ATTR_DELIMITERS: <MASK> quote_character = None <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> elif not quote_character: <TAB>  <TAB>  <TAB>  <TAB> quote_character = s <TAB>  <TAB>  <TAB>  <TAB> continue <TAB> if quote_character == self.quote_character: <TAB>  <TAB> return True <TAB> return False",if quote_character and s == quote_character :,173
"def _display_history(config, script, base, head, currents=()): <TAB> for sc in script.walk_revisions(base=base or ""base"", head=head or ""heads""): <MASK> sc._db_current_indicator = sc.revision in currents <TAB>  <TAB> config.print_stdout( <TAB>  <TAB>  <TAB> sc.cmd_format( <TAB>  <TAB>  <TAB>  <TAB> verbose=verbose, <TAB>  <TAB>  <TAB>  <TAB> include_branches=True, <TAB>  <TAB>  <TAB>  <TAB> include_doc=True, <TAB>  <TAB>  <TAB>  <TAB> include_parents=True, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> )",if indicate_current :,139
"def set(self, key=None, value=None): <TAB> if key is not None: <TAB>  <TAB> k = str(key) <TAB>  <TAB> if value is not None: <TAB>  <TAB>  <TAB> self.store[k] = value <TAB>  <TAB> else: <MASK> del self.store[k] <TAB> else: <TAB>  <TAB> self.store.clear()",if self . store . has_key ( k ) :,97
"def _finalize_load(*exc_info): <TAB> try: <TAB>  <TAB> success_keys = [k for k in data_keys if k not in failed_keys] <TAB>  <TAB> if success_keys: <TAB>  <TAB>  <TAB> self._holder_ref.put_objects_by_keys( <TAB>  <TAB>  <TAB>  <TAB> session_id, success_keys, pin_token=pin_token <TAB>  <TAB>  <TAB> ) <MASK> raise exc_info[1].with_traceback(exc_info[2]) from None <TAB>  <TAB> if failed_keys: <TAB>  <TAB>  <TAB> raise StorageFull( <TAB>  <TAB>  <TAB>  <TAB> request_size=storage_full_sizes[0], <TAB>  <TAB>  <TAB>  <TAB> capacity=storage_full_sizes[1], <TAB>  <TAB>  <TAB>  <TAB> affected_keys=list(failed_keys), <TAB>  <TAB>  <TAB> ) <TAB> finally: <TAB>  <TAB> shared_bufs[:] = []",if exc_info :,200
"def ignore_module(module): <TAB> result = False <TAB> for check in ignore_these: <TAB>  <TAB> if ""/*"" in check: <TAB>  <TAB>  <TAB> if check[:-1] in module: <TAB>  <TAB>  <TAB>  <TAB> result = True <TAB>  <TAB> else: <MASK> result = True <TAB> if result: <TAB>  <TAB> print_warning(""Ignoring module: "" + module) <TAB> return result","if ( os . getcwd ( ) + ""/"" + check + "".py"" ) == module :",108
"def available(self, exception_flag=True): <TAB> """"""True if the solver is available"""""" <TAB> if exception_flag is False: <TAB>  <TAB> return cplex_import_available <TAB> else: <MASK> raise ApplicationError( <TAB>  <TAB>  <TAB>  <TAB> ""No CPLEX <-> Python bindings available - CPLEX direct "" <TAB>  <TAB>  <TAB>  <TAB> ""solver functionality is not available"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return True",if cplex_import_available is False :,115
"def close(self, checkcount=False): <TAB> self.mutex.acquire() <TAB> try: <MASK> self.openers -= 1 <TAB>  <TAB>  <TAB> if self.openers == 0: <TAB>  <TAB>  <TAB>  <TAB> self.do_close() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if self.openers > 0: <TAB>  <TAB>  <TAB>  <TAB> self.do_close() <TAB>  <TAB>  <TAB> self.openers = 0 <TAB> finally: <TAB>  <TAB> self.mutex.release()",if checkcount :,116
"def __get__(self, obj, type=None): <TAB> if obj is None: <TAB>  <TAB> return self <TAB> with self.lock: <TAB>  <TAB> value = obj.__dict__.get(self.__name__, self._default_value) <MASK> value = self.func(obj) <TAB>  <TAB>  <TAB> obj.__dict__[self.__name__] = value <TAB>  <TAB> return value",if value is self . _default_value :,96
"def _test_pooling_iteration(input_shape, **kwargs): <TAB> """"""One iteration of pool operation with given shapes and attributes"""""" <TAB> x = -np.arange(np.prod(input_shape), dtype=np.float32).reshape(input_shape) - 1 <TAB> with tf.Graph().as_default(): <TAB>  <TAB> in_data = array_ops.placeholder(shape=input_shape, dtype=""float32"") <TAB>  <TAB> nn_ops.pool(in_data, **kwargs) <MASK> out_name = ""max_pool:0"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> out_name = ""avg_pool:0"" <TAB>  <TAB> compare_tf_with_tvm(x, ""Placeholder:0"", out_name)","if kwargs [ ""pooling_type"" ] == ""MAX"" :",185
def updateValue(self): <TAB> if self._index: <TAB>  <TAB> val = toInt(self._model.data(self._index)) <MASK> self._updating = True <TAB>  <TAB>  <TAB> self.setValue(val) <TAB>  <TAB>  <TAB> self._updating = False,if self . sld . value ( ) != val :,74
"def _count(self, element, count=True): <TAB> if not isinstance(element, six.string_types): <MASK> return 1 <TAB> i = 0 <TAB> for child in self.children: <TAB>  <TAB> # child is text content and element is also text content, then <TAB>  <TAB> # make a simple ""text"" in ""text"" <TAB>  <TAB> if isinstance(child, six.string_types): <TAB>  <TAB>  <TAB> if isinstance(element, six.string_types): <TAB>  <TAB>  <TAB>  <TAB> if count: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> i += child.count(element) <TAB>  <TAB>  <TAB>  <TAB> elif element in child: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> i += child._count(element, count=count) <TAB>  <TAB>  <TAB> if not count and i: <TAB>  <TAB>  <TAB>  <TAB> return i <TAB> return i",if self == element :,196
"def test_doctests(self): <TAB> """"""Run tutorial doctests."""""" <TAB> runner = doctest.DocTestRunner() <TAB> failures = [] <TAB> for test in doctest.DocTestFinder().find(TutorialDocTestHolder): <TAB>  <TAB> failed, success = runner.run(test) <MASK> name = test.name <TAB>  <TAB>  <TAB> assert name.startswith(""TutorialDocTestHolder.doctest_"") <TAB>  <TAB>  <TAB> failures.append(name[30:]) <TAB>  <TAB>  <TAB> # raise ValueError(""Tutorial doctest %s failed"" % test.name[30:]) <TAB> if failures: <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> ""%i Tutorial doctests failed: %s"" % (len(failures), "", "".join(failures)) <TAB>  <TAB> )",if failed :,168
"def send_preamble(self): <TAB> """"""Transmit version/status/date/server, via self._write()"""""" <TAB> if self.origin_server: <TAB>  <TAB> if self.client_is_modern(): <TAB>  <TAB>  <TAB> self._write(""HTTP/%s %s\r\n"" % (self.http_version, self.status)) <MASK> self._write(""Date: %s\r\n"" % time.asctime(time.gmtime(time.time()))) <TAB>  <TAB>  <TAB> if self.server_software and not self.headers.has_key(""Server""): <TAB>  <TAB>  <TAB>  <TAB> self._write(""Server: %s\r\n"" % self.server_software) <TAB> else: <TAB>  <TAB> self._write(""Status: %s\r\n"" % self.status)","if not self . headers . has_key ( ""Date"" ) :",199
"def _verify_unique_measurement_keys(operations: Iterable[ops.Operation]): <TAB> seen: Set[str] = set() <TAB> for op in operations: <TAB>  <TAB> if isinstance(op.gate, ops.MeasurementGate): <TAB>  <TAB>  <TAB> meas = op.gate <TAB>  <TAB>  <TAB> key = protocols.measurement_key(meas) <MASK> raise ValueError(""Measurement key {} repeated"".format(key)) <TAB>  <TAB>  <TAB> seen.add(key)",if key in seen :,120
"def test_dtype_basics(df): <TAB> df[""new_virtual_column""] = df.x + 1 <TAB> for name in df.column_names: <MASK> assert df[name].values.dtype.kind in ""OSU"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert df[name].values.dtype == df.dtype(df[name])",if df . dtype ( name ) == str_type :,99
"def string_to_points(self, command, coord_string): <TAB> numbers = string_to_numbers(coord_string) <TAB> if command.upper() in [""H"", ""V""]: <TAB>  <TAB> i = {""H"": 0, ""V"": 1}[command.upper()] <TAB>  <TAB> xy = np.zeros((len(numbers), 2)) <TAB>  <TAB> xy[:, i] = numbers <MASK> xy[:, 1 - i] = self.relative_point[1 - i] <TAB> elif command.upper() == ""A"": <TAB>  <TAB> raise Exception(""Not implemented"") <TAB> else: <TAB>  <TAB> xy = np.array(numbers).reshape((len(numbers) // 2, 2)) <TAB> result = np.zeros((xy.shape[0], self.dim)) <TAB> result[:, :2] = xy <TAB> return result",if command . isupper ( ) :,193
"def get_count(self, peek=False): <TAB> if self.argument_supplied: <TAB>  <TAB> count = self.argument_value <TAB>  <TAB> if self.argument_negative: <TAB>  <TAB>  <TAB> if count == 0: <TAB>  <TAB>  <TAB>  <TAB> count = -1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> count = -count <MASK> self.argument_negative = False <TAB>  <TAB> if not peek: <TAB>  <TAB>  <TAB> self.argument_supplied = False <TAB> else: <TAB>  <TAB> count = 1 <TAB> return count",if not peek :,126
"def toggleSchedule(self, **kwargs): <TAB> schedules = cfg.schedules() <TAB> line = kwargs.get(""line"") <TAB> if line: <TAB>  <TAB> for i, schedule in enumerate(schedules): <MASK> # Toggle the schedule <TAB>  <TAB>  <TAB>  <TAB> schedule_split = schedule.split() <TAB>  <TAB>  <TAB>  <TAB> schedule_split[0] = ""%d"" % (schedule_split[0] == ""0"") <TAB>  <TAB>  <TAB>  <TAB> schedules[i] = "" "".join(schedule_split) <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> cfg.schedules.set(schedules) <TAB>  <TAB> config.save_config() <TAB>  <TAB> sabnzbd.Scheduler.restart() <TAB> raise Raiser(self.__root)",if schedule == line :,175
"def test_sanity_no_long_entities(CorpusType: Type[ColumnCorpus]): <TAB> corpus = CorpusType() <TAB> longest_entity = [] <TAB> for sentence in corpus.get_all_sentences(): <TAB>  <TAB> entities = sentence.get_spans(""ner"") <TAB>  <TAB> for entity in entities: <MASK> longest_entity = [t.text for t in entity.tokens] <TAB> assert len(longest_entity) < 10, "" "".join(longest_entity)",if len ( entity . tokens ) > len ( longest_entity ) :,123
"def _set_helper(settings, path, value, data_type=None): <TAB> path = _to_settings_path(path) <TAB> method = settings.set <TAB> if data_type is not None: <TAB>  <TAB> name = None <TAB>  <TAB> if data_type == bool: <TAB>  <TAB>  <TAB> name = ""setBoolean"" <TAB>  <TAB> elif data_type == float: <TAB>  <TAB>  <TAB> name = ""setFloat"" <MASK> name = ""setInt"" <TAB>  <TAB> if name is not None: <TAB>  <TAB>  <TAB> method = getattr(settings, name) <TAB> method(path, value) <TAB> settings.save()",elif data_type == int :,150
"def scan_page(self, address_space, page_offset, fullpage=False): <TAB> """"""Runs through patchers for a single page"""""" <TAB> if fullpage: <TAB>  <TAB> pagedata = address_space.read(page_offset, PAGESIZE) <TAB> for patcher in self.patchers: <TAB>  <TAB> for offset, data in patcher.get_constraints(): <TAB>  <TAB>  <TAB> if fullpage: <TAB>  <TAB>  <TAB>  <TAB> testdata = pagedata[offset : offset + len(data)] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> testdata = address_space.read(page_offset + offset, len(data)) <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield patcher",if data != testdata :,166
"def accessSlice(self, node): <TAB> self.visit(node.value) <TAB> node.obj = self.getObj(node.value) <TAB> self.access = _access.INPUT <TAB> lower, upper = node.slice.lower, node.slice.upper <TAB> if lower: <TAB>  <TAB> self.visit(lower) <TAB> if upper: <TAB>  <TAB> self.visit(upper) <TAB> if isinstance(node.obj, intbv): <MASK> self.require(lower, ""Expected leftmost index"") <TAB>  <TAB>  <TAB> leftind = self.getVal(lower) <TAB>  <TAB>  <TAB> if upper: <TAB>  <TAB>  <TAB>  <TAB> rightind = self.getVal(upper) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> rightind = 0 <TAB>  <TAB>  <TAB> node.obj = node.obj[leftind:rightind]",if self . kind == _kind . DECLARATION :,198
"def childConnectionLost(self, childFD): <TAB> if self.state == 1: <TAB>  <TAB> self.fail(""got connectionLost(%d) during state 1"" % childFD) <TAB>  <TAB> return <TAB> if self.state == 2: <MASK> self.fail(""got connectionLost(%d) (not 4) during state 2"" % childFD) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> self.state = 3 <TAB>  <TAB> self.transport.closeChildFD(5) <TAB>  <TAB> return",if childFD != 4 :,122
"def _find_matches(self, file, lookup, **kwargs): <TAB> matches = [] <TAB> for format in lookup.values(): <MASK> is_format, skwargs = format.sniffer_function(file, **kwargs) <TAB>  <TAB>  <TAB> file.seek(0) <TAB>  <TAB>  <TAB> if is_format: <TAB>  <TAB>  <TAB>  <TAB> matches.append((format.name, skwargs)) <TAB> return matches",if format . sniffer_function is not None :,108
"def ParseCodeLines(tokens, case): <TAB> """"""Parse uncommented code in a test case."""""" <TAB> _, kind, item = tokens.peek() <MASK> raise ParseError(""Expected a line of code (got %r, %r)"" % (kind, item)) <TAB> code_lines = [] <TAB> while True: <TAB>  <TAB> _, kind, item = tokens.peek() <TAB>  <TAB> if kind != PLAIN_LINE: <TAB>  <TAB>  <TAB> case[""code""] = ""\n"".join(code_lines) + ""\n"" <TAB>  <TAB>  <TAB> return <TAB>  <TAB> code_lines.append(item) <TAB>  <TAB> tokens.next()",if kind != PLAIN_LINE :,148
"def _recursive_process(self): <TAB> super(RecursiveObjectDownwardsVisitor, self)._recursive_process() <TAB> while self._new_for_visit: <TAB>  <TAB> func_ea, arg_idx = self._new_for_visit.pop() <MASK> continue <TAB>  <TAB> cfunc = helper.decompile_function(func_ea) <TAB>  <TAB> if cfunc: <TAB>  <TAB>  <TAB> assert arg_idx < len(cfunc.get_lvars()), ""Wrong argument at func {}"".format( <TAB>  <TAB>  <TAB>  <TAB> to_hex(func_ea) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> obj = VariableObject(cfunc.get_lvars()[arg_idx], arg_idx) <TAB>  <TAB>  <TAB> self.prepare_new_scan(cfunc, arg_idx, obj) <TAB>  <TAB>  <TAB> self._recursive_process()",if helper . is_imported_ea ( func_ea ) :,199
"def GetBoundingBoxMin(self): <TAB> """"""Get the minimum bounding box."""""" <TAB> x1, y1 = 10000, 10000 <TAB> x2, y2 = -10000, -10000 <TAB> for point in self._lineControlPoints: <TAB>  <TAB> if point[0] < x1: <TAB>  <TAB>  <TAB> x1 = point[0] <TAB>  <TAB> if point[1] < y1: <TAB>  <TAB>  <TAB> y1 = point[1] <MASK> x2 = point[0] <TAB>  <TAB> if point[1] > y2: <TAB>  <TAB>  <TAB> y2 = point[1] <TAB> return x2 - x1, y2 - y1",if point [ 0 ] > x2 :,158
"def __init__( <TAB> self, <TAB> detail=None, <TAB> headers=None, <TAB> comment=None, <TAB> body_template=None, <TAB> location=None, <TAB> add_slash=False,): <TAB> super(_HTTPMove, self).__init__( <TAB>  <TAB> detail=detail, headers=headers, comment=comment, body_template=body_template <TAB> ) <TAB> if location is not None: <TAB>  <TAB> self.location = location <MASK> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""You can only provide one of the arguments location "" ""and add_slash"" <TAB>  <TAB>  <TAB> ) <TAB> self.add_slash = add_slash",if add_slash :,155
"def __str__(self, prefix="""", printElemNumber=0): <TAB> res = """" <TAB> cnt = 0 <TAB> for e in self.presence_response_: <TAB>  <TAB> elm = """" <MASK> elm = ""(%d)"" % cnt <TAB>  <TAB> res += prefix + (""presence_response%s <\n"" % elm) <TAB>  <TAB> res += e.__str__(prefix + ""  "", printElemNumber) <TAB>  <TAB> res += prefix + "">\n"" <TAB>  <TAB> cnt += 1 <TAB> return res",if printElemNumber :,125
"def _find_first_match(self, request): <TAB> match_failed_reasons = [] <TAB> for i, match in enumerate(self._matches): <TAB>  <TAB> match_result, reason = match.matches(request) <MASK> return match, match_failed_reasons <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> match_failed_reasons.append(reason) <TAB> return None, match_failed_reasons",if match_result :,99
"def index(self, req, volume_id): <TAB> req_version = req.api_version_request <TAB> metadata = super(Controller, self).index(req, volume_id) <TAB> if req_version.matches(mv.ETAGS): <TAB>  <TAB> data = jsonutils.dumps(metadata) <MASK> data = data.encode(""utf-8"") <TAB>  <TAB> resp = webob.Response() <TAB>  <TAB> resp.headers[""Etag""] = hashlib.md5(data).hexdigest() <TAB>  <TAB> resp.body = data <TAB>  <TAB> return resp <TAB> return metadata",if six . PY3 :,140
"def init(self): <TAB> """"""Called after document is loaded."""""" <TAB> # Create div to put dynamic CSS assets in <TAB> self.asset_node = window.document.createElement(""div"") <TAB> self.asset_node.id = ""Flexx asset container"" <TAB> window.document.body.appendChild(self.asset_node) <TAB> if self.is_exported: <TAB>  <TAB> if self.is_notebook: <TAB>  <TAB>  <TAB> print(""Flexx: I am in an exported notebook!"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""Flexx: I am in an exported app!"") <TAB>  <TAB>  <TAB> self.run_exported_app() <TAB> else: <TAB>  <TAB> print(""Flexx: Initializing"") <MASK> self._remove_querystring() <TAB>  <TAB> self.init_logging()",if not self . is_notebook :,188
"def get_default_person(self): <TAB> """"""Return the default Person of the database."""""" <TAB> person_handle = self.get_default_handle() <TAB> if person_handle: <TAB>  <TAB> person = self.get_person_from_handle(person_handle) <TAB>  <TAB> if person: <TAB>  <TAB>  <TAB> return person <MASK> # Start transaction <TAB>  <TAB>  <TAB> with BSDDBTxn(self.env, self.metadata) as txn: <TAB>  <TAB>  <TAB>  <TAB> txn.put(b""default"", None) <TAB>  <TAB>  <TAB> return None <TAB> else: <TAB>  <TAB> return None",elif ( self . metadata ) and ( not self . readonly ) :,149
def reader(): <TAB> async with read: <TAB>  <TAB> await wait_all_tasks_blocked() <TAB>  <TAB> total_received = 0 <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> # 5000 is chosen because it doesn't evenly divide 2**20 <TAB>  <TAB>  <TAB> received = len(await read.receive_some(5000)) <MASK> break <TAB>  <TAB>  <TAB> total_received += received <TAB>  <TAB> assert total_received == count * replicas,if not received :,104
"def array_module(a): <TAB> if isinstance(a, np.ndarray): <TAB>  <TAB> return np <TAB> else: <TAB>  <TAB> from pyopencl.array import Array <MASK> return _CLFakeArrayModule(a.queue) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError(""array type not understood: %s"" % type(a))","if isinstance ( a , Array ) :",89
"def __str__(self): <TAB> path = super(XPathExpr, self).__str__() <TAB> if self.textnode: <MASK> path = ""text()"" <TAB>  <TAB> elif path.endswith(""::*/*""): <TAB>  <TAB>  <TAB> path = path[:-3] + ""text()"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> path += ""/text()"" <TAB> if self.attribute is not None: <TAB>  <TAB> if path.endswith(""::*/*""): <TAB>  <TAB>  <TAB> path = path[:-2] <TAB>  <TAB> path += ""/@%s"" % self.attribute <TAB> return path","if path == ""*"" :",132
"def update(self): <TAB> if self.saved(): <TAB>  <TAB> rgns = self.view.get_regions(self.region_key) <MASK> rgn = Region.from_region(self.view, rgns[0], self.region_key) <TAB>  <TAB>  <TAB> self.start = rgn.start <TAB>  <TAB>  <TAB> self.end = rgn.end",if rgns :,92
"def PrintServerName(data, entries): <TAB> if entries > 0: <TAB>  <TAB> entrieslen = 26 * entries <TAB>  <TAB> chunks, chunk_size = len(data[:entrieslen]), entrieslen / entries <TAB>  <TAB> ServerName = [data[i : i + chunk_size] for i in range(0, chunks, chunk_size)] <TAB>  <TAB> l = [] <TAB>  <TAB> for x in ServerName: <TAB>  <TAB>  <TAB> FP = WorkstationFingerPrint(x[16:18]) <TAB>  <TAB>  <TAB> Name = x[:16].replace(""\x00"", """") <MASK> l.append(Name + "" (%s)"" % FP) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> l.append(Name) <TAB>  <TAB> return l <TAB> return None",if FP :,177
"def add_lookup(self, name_type, pyname, jsname, depth=-1): <TAB> jsname = self.jsname(name_type, jsname) <TAB> if self.local_prefix is not None: <MASK> jsname = self.jsname(name_type, ""%s.%s"" % (self.local_prefix, jsname)) <TAB> if self.lookup_stack[depth].has_key(pyname): <TAB>  <TAB> name_type = self.lookup_stack[depth][pyname][0] <TAB> if self.module_name != ""pyjslib"" or pyname != ""int"": <TAB>  <TAB> self.lookup_stack[depth][pyname] = (name_type, pyname, jsname) <TAB> return jsname",if jsname . find ( self . local_prefix ) != 0 :,191
"def ensure_echo_on(): <TAB> if termios: <TAB>  <TAB> fd = sys.stdin <MASK> attr_list = termios.tcgetattr(fd) <TAB>  <TAB>  <TAB> if not attr_list[3] & termios.ECHO: <TAB>  <TAB>  <TAB>  <TAB> attr_list[3] |= termios.ECHO <TAB>  <TAB>  <TAB>  <TAB> if hasattr(signal, ""SIGTTOU""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> old_handler = signal.signal(signal.SIGTTOU, signal.SIG_IGN) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> old_handler = None <TAB>  <TAB>  <TAB>  <TAB> termios.tcsetattr(fd, termios.TCSANOW, attr_list) <TAB>  <TAB>  <TAB>  <TAB> if old_handler is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> signal.signal(signal.SIGTTOU, old_handler)",if fd . isatty ( ) :,197
"def get_query_results(user, query_id, bring_from_cache): <TAB> query = _load_query(user, query_id) <TAB> if bring_from_cache: <MASK> results = query.latest_query_data.data <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception(""No cached result available for query {}."".format(query.id)) <TAB> else: <TAB>  <TAB> results, error = query.data_source.query_runner.run_query( <TAB>  <TAB>  <TAB> query.query_text, user <TAB>  <TAB> ) <TAB>  <TAB> if error: <TAB>  <TAB>  <TAB> raise Exception(""Failed loading results for query id {}."".format(query.id)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> results = json_loads(results) <TAB> return results",if query . latest_query_data_id is not None :,188
"def on_tag_added_to_page(self, o, row, pagerow): <TAB> self.flush_cache() <TAB> if row[""name""] in self.tags and self._matches_all(pagerow[""id""]): <TAB>  <TAB> # Without the new tag it did not match, so add to view <TAB>  <TAB> # Find top level entry - ignore possible deeper matches <TAB>  <TAB> for treepath in self._find_all_pages(pagerow[""name""]): <TAB>  <TAB>  <TAB> if len(treepath) == 1: <TAB>  <TAB>  <TAB>  <TAB> treeiter = self.get_iter(treepath)  # not mytreeiter ! <TAB>  <TAB>  <TAB>  <TAB> self.emit(""row-inserted"", treepath, treeiter) <MASK> self._emit_children_inserted(pagerow[""id""], treepath)","if pagerow [ ""n_children"" ] > 0 :",196
"def _is_subnet_of(a, b): <TAB> try: <TAB>  <TAB> # Always false if one is v4 and the other is v6. <MASK> raise TypeError(f""{a} and {b} are not of the same version"") <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB> b.network_address <= a.network_address <TAB>  <TAB>  <TAB> and b.broadcast_address >= a.broadcast_address <TAB>  <TAB> ) <TAB> except AttributeError: <TAB>  <TAB> raise TypeError(f""Unable to test subnet containment "" f""between {a} and {b}"")",if a . _version != b . _version :,140
"def consume(d={}): <TAB> """"""Add attribute list to the dictionary 'd' and reset the list."""""" <TAB> if AttributeList.attrs: <TAB>  <TAB> d.update(AttributeList.attrs) <TAB>  <TAB> AttributeList.attrs = {} <TAB>  <TAB> # Generate option attributes. <MASK> options = parse_options(d[""options""], (), ""illegal option name"") <TAB>  <TAB>  <TAB> for option in options: <TAB>  <TAB>  <TAB>  <TAB> d[option + ""-option""] = """"","if ""options"" in d :",113
"def tearDown(self): <TAB> # make sure all of the subprocesses are dead <TAB> for pidfile in self.pidfiles: <TAB>  <TAB> if not os.path.exists(pidfile): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> with open(pidfile) as f: <TAB>  <TAB>  <TAB> pid = f.read() <TAB>  <TAB> if not pid: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> pid = int(pid) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> os.kill(pid, signal.SIGKILL) <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> pass <TAB> # and clean up leftover pidfiles <TAB> for pidfile in self.pidfiles: <MASK> os.unlink(pidfile) <TAB> self.tearDownBasedir()",if os . path . exists ( pidfile ) :,167
"def sort(self, items): <TAB> slow_sorts = [] <TAB> switch_slow = False <TAB> for sort in reversed(self.sorts): <TAB>  <TAB> if switch_slow: <TAB>  <TAB>  <TAB> slow_sorts.append(sort) <MASK> switch_slow = True <TAB>  <TAB>  <TAB> slow_sorts.append(sort) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pass <TAB> for sort in slow_sorts: <TAB>  <TAB> items = sort.sort(items) <TAB> return items",elif sort . order_clause ( ) is None :,121
"def shortcut(input, ch_out, stride): <TAB> ch_in = input.shape[1] <TAB> if ch_in != ch_out: <MASK> filter_size = 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> filter_size = 3 <TAB>  <TAB> return conv_bn_layer(input, ch_out, filter_size, stride) <TAB> else: <TAB>  <TAB> return input",if stride == 1 :,97
"def detab(self, text): <TAB> """"""Remove a tab from the front of each line of the given text."""""" <TAB> newtext = [] <TAB> lines = text.split(""\n"") <TAB> for line in lines: <TAB>  <TAB> if line.startswith("" "" * self.tab_length): <TAB>  <TAB>  <TAB> newtext.append(line[self.tab_length :]) <MASK> newtext.append("""") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> return ""\n"".join(newtext), ""\n"".join(lines[len(newtext) :])",elif not line . strip ( ) :,134
"def construct_instances(self, row, keys=None): <TAB> collected_models = {} <TAB> for i, (key, constructor, attr, conv) in enumerate(self.column_map): <TAB>  <TAB> if keys is not None and key not in keys: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> value = row[i] <TAB>  <TAB> if key not in collected_models: <TAB>  <TAB>  <TAB> collected_models[key] = constructor() <TAB>  <TAB> instance = collected_models[key] <MASK> attr = self.cursor.description[i][0] <TAB>  <TAB> if conv is not None: <TAB>  <TAB>  <TAB> value = conv(value) <TAB>  <TAB> setattr(instance, attr, value) <TAB> return collected_models",if attr is None :,167
"def stop_loggers(self): <TAB> super(NetconsoleHost, self).stop_loggers() <TAB> if self.__logger: <TAB>  <TAB> utils.nuke_subprocess(self.__logger) <TAB>  <TAB> self.__logger = None <MASK> self.job.warning_loggers.discard(self.__warning_stream) <TAB>  <TAB> self.__warning_stream.close()",if self . job :,93
"def get_template_context(node, context, context_lines=3): <TAB> line, source_lines, name = get_template_source_from_exception_info(node, context) <TAB> debug_context = [] <TAB> start = max(1, line - context_lines) <TAB> end = line + 1 + context_lines <TAB> for line_num, content in source_lines: <MASK> debug_context.append( <TAB>  <TAB>  <TAB>  <TAB> {""num"": line_num, ""content"": content, ""highlight"": (line_num == line)} <TAB>  <TAB>  <TAB> ) <TAB> return {""name"": name, ""context"": debug_context}",if start <= line_num <= end :,158
"def arg_names(self, lineage, command_name, positional_arg=False): <TAB> parent = ""."".join(lineage) <TAB> arg_names = self.index[""arg_names""].get(parent, {}).get(command_name, []) <TAB> filtered_arg_names = [] <TAB> for arg_name in arg_names: <TAB>  <TAB> arg_data = self.get_argument_data(lineage, command_name, arg_name) <MASK> filtered_arg_names.append(arg_name) <TAB> return filtered_arg_names",if arg_data . positional_arg == positional_arg :,140
"def attributive(adjective, gender=MALE): <TAB> w = adjective.lower() <TAB> # normal => normales <TAB> if PLURAL in gender and not is_vowel(w[-1:]): <TAB>  <TAB> return w + ""es"" <TAB> # el chico inteligente => los chicos inteligentes <TAB> if PLURAL in gender and w.endswith((""a"", ""e"")): <TAB>  <TAB> return w + ""s"" <TAB> # el chico alto => los chicos altos <TAB> if w.endswith(""o""): <MASK> return w[:-1] + ""as"" <TAB>  <TAB> if FEMININE in gender: <TAB>  <TAB>  <TAB> return w[:-1] + ""a"" <TAB>  <TAB> if PLURAL in gender: <TAB>  <TAB>  <TAB> return w + ""s"" <TAB> return w",if FEMININE in gender and PLURAL in gender :,197
"def _get_disk_size(cls, path, ignored=None): <TAB> if ignored is None: <TAB>  <TAB> ignored = [] <TAB> if path in ignored: <TAB>  <TAB> return 0 <TAB> total = 0 <TAB> for entry in scandir(path): <TAB>  <TAB> if entry.is_dir(): <TAB>  <TAB>  <TAB> total += cls._get_disk_size(entry.path, ignored=ignored) <MASK> total += entry.stat().st_size <TAB> return total",elif entry . is_file ( ) :,117
"def validateHeaders(self): <TAB> if ""Cookie"" in self.headers: <TAB>  <TAB> for session in self.factory.authenticated_sessions: <MASK> return WebSocketProtocol.validateHeaders(self) <TAB> return False","if ""TWISTED_SESSION="" + session . uid in self . headers [ ""Cookie"" ] :",74
"def _format_privilege_data(self, data): <TAB> for key in [""spcacl""]: <TAB>  <TAB> if key in data and data[key] is not None: <MASK> data[key][""added""] = parse_priv_to_db(data[key][""added""], self.acl) <TAB>  <TAB>  <TAB> if ""changed"" in data[key]: <TAB>  <TAB>  <TAB>  <TAB> data[key][""changed""] = parse_priv_to_db(data[key][""changed""], self.acl) <TAB>  <TAB>  <TAB> if ""deleted"" in data[key]: <TAB>  <TAB>  <TAB>  <TAB> data[key][""deleted""] = parse_priv_to_db(data[key][""deleted""], self.acl)","if ""added"" in data [ key ] :",168
"def show_text(text): <TAB> print(_stash.text_color(""="" * 20, ""yellow"")) <TAB> lines = text.split(""\n"") <TAB> while True: <MASK> print(""\n"".join(lines)) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""\n"".join(lines[:100])) <TAB>  <TAB>  <TAB> lines = lines[100:] <TAB>  <TAB>  <TAB> prompt = _stash.text_color(""(Press Return to continue)"", ""yellow"") <TAB>  <TAB>  <TAB> raw_input(prompt) <TAB> print(""\n"")",if len ( lines ) < 100 :,135
"def run(self): <TAB> TimeInspector.set_time_mark() <TAB> for tuner_index, tuner_config in enumerate(self.pipeline_config): <TAB>  <TAB> tuner = self.init_tuner(tuner_index, tuner_config) <TAB>  <TAB> tuner.tune() <MASK> self.global_best_res = tuner.best_res <TAB>  <TAB>  <TAB> self.global_best_params = tuner.best_params <TAB>  <TAB>  <TAB> self.best_tuner_index = tuner_index <TAB> TimeInspector.log_cost_time(""Finished tuner pipeline."") <TAB> self.save_tuner_exp_info()",if self . global_best_res is None or self . global_best_res > tuner . best_res :,194
"def OnEvent(self, propGrid, aProperty, ctrl, event): <TAB> if event.GetEventType() == wx.wxEVT_BUTTON: <TAB>  <TAB> buttons = propGrid.GetEditorControlSecondary() <TAB>  <TAB> if event.GetId() == buttons.GetButtonId(0): <TAB>  <TAB>  <TAB> # Do something when the first button is pressed <TAB>  <TAB>  <TAB> # Return true if the action modified the value in editor. <TAB>  <TAB>  <TAB> ... <MASK> # Do something when the second button is pressed <TAB>  <TAB>  <TAB> ... <TAB>  <TAB> if event.GetId() == buttons.GetButtonId(2): <TAB>  <TAB>  <TAB> # Do something when the third button is pressed <TAB>  <TAB>  <TAB> ... <TAB> return wx.propgrid.PGTextCtrlEditor.OnEvent(propGrid, aProperty, ctrl, event)",if event . GetId ( ) == buttons . GetButtonId ( 1 ) :,195
"def run(self, edit): <TAB> view = self.view <TAB> for sel in view.sel(): <TAB>  <TAB> if not self.is_valid_scope(sel): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> region = view.extract_scope(sel.end()) <TAB>  <TAB> content = self.extract_content(region) <TAB>  <TAB> resolver, content = self.resolve(content) <MASK> sublime.error_message(""Could not resolve link:\n%s"" % content) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> resolver.execute(content)",if content is None :,131
"def __init__(self, aList): <TAB> for element in aList: <TAB>  <TAB> if len(element) > 0: <TAB>  <TAB>  <TAB> if element.tag == element[0].tag: <TAB>  <TAB>  <TAB>  <TAB> self.append(ListParser(element)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.append(DictParser(element)) <MASK> text = element.text.strip() <TAB>  <TAB>  <TAB> if text: <TAB>  <TAB>  <TAB>  <TAB> self.append(text)",elif element . text :,116
"def put(self, can_split=False): <TAB> for node in (self.nodes)[:1]: <MASK> node.put(can_split=can_split) <TAB> for node in (self.nodes)[1:]: <TAB>  <TAB> self.line_more(SLICE_COLON, can_split_after=True) <TAB>  <TAB> if self.has_value(node): <TAB>  <TAB>  <TAB> node.put(can_split=can_split) <TAB> return self",if self . has_value ( node ) :,118
"def process_return_exits(self, exits): <TAB> """"""Add arcs due to jumps from `exits` being returns."""""" <TAB> for block in self.nearest_blocks(): <TAB>  <TAB> if isinstance(block, TryBlock) and block.final_start is not None: <TAB>  <TAB>  <TAB> block.return_from.update(exits) <TAB>  <TAB>  <TAB> break <MASK> for xit in exits: <TAB>  <TAB>  <TAB>  <TAB> self.add_arc( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> xit.lineno, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> -block.start, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> xit.cause, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""didn't return from function {!r}"".format(block.name), <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> break","elif isinstance ( block , FunctionBlock ) :",179
"def find_commands(management_dir): <TAB> # Modified version of function from django/core/management/__init__.py. <TAB> command_dir = os.path.join(management_dir, ""commands"") <TAB> commands = [] <TAB> try: <TAB>  <TAB> for f in os.listdir(command_dir): <TAB>  <TAB>  <TAB> if f.startswith(""_""): <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> commands.append(f[:-3]) <TAB>  <TAB>  <TAB> elif f.endswith("".pyc"") and f[:-4] not in commands: <TAB>  <TAB>  <TAB>  <TAB> commands.append(f[:-4]) <TAB> except OSError: <TAB>  <TAB> pass <TAB> return commands","elif f . endswith ( "".py"" ) and f [ : - 3 ] not in commands :",164
"def split_path_info(path): <TAB> # suitable for splitting an already-unquoted-already-decoded (unicode) <TAB> # path value <TAB> path = path.strip(""/"") <TAB> clean = [] <TAB> for segment in path.split(""/""): <MASK> continue <TAB>  <TAB> elif segment == "".."": <TAB>  <TAB>  <TAB> if clean: <TAB>  <TAB>  <TAB>  <TAB> del clean[-1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> clean.append(segment) <TAB> return tuple(clean)","if not segment or segment == ""."" :",115
"def __init__(self, source_definition, **kw): <TAB> super(RekallEFilterArtifacts, self).__init__(source_definition, **kw) <TAB> for column in self.fields: <MASK> raise errors.FormatError( <TAB>  <TAB>  <TAB>  <TAB> u""Field definition should have both name and type."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> mapped_type = column[""type""] <TAB>  <TAB> if mapped_type not in self.allowed_types: <TAB>  <TAB>  <TAB> raise errors.FormatError(u""Unsupported type %s."" % mapped_type)","if ""name"" not in column or ""type"" not in column :",143
"def _name(self, sender, short=True, full_email=False): <TAB> words = re.sub('[""<>]', """", sender).split() <TAB> nomail = [w for w in words if not ""@"" in w] <TAB> if nomail: <TAB>  <TAB> if short: <MASK> return nomail[1] <TAB>  <TAB>  <TAB> return nomail[0] <TAB>  <TAB> return "" "".join(nomail) <TAB> elif words: <TAB>  <TAB> if not full_email: <TAB>  <TAB>  <TAB> return words[0].split(""@"", 1)[0] <TAB>  <TAB> return words[0] <TAB> return ""(nobody)""",if len ( nomail ) > 1 and nomail [ 0 ] . lower ( ) in self . _NAME_TITLES :,168
"def _get_consuming_layers(self, check_layer): <TAB> """"""Returns all the layers which are out nodes from the layer."""""" <TAB> consuming_layers = [] <TAB> for layer in self._config[""layers""]: <TAB>  <TAB> for inbound_node in layer[""inbound_nodes""]: <TAB>  <TAB>  <TAB> for connection_info in inbound_node: <MASK> consuming_layers.append(layer) <TAB> return consuming_layers","if connection_info [ 0 ] == check_layer [ ""config"" ] [ ""name"" ] :",126
"def _check_feasible_fuse(self, model): <TAB> if not self.modules_to_fuse: <TAB>  <TAB> return False <TAB> for group in self.modules_to_fuse: <MASK> raise MisconfigurationException( <TAB>  <TAB>  <TAB>  <TAB> f""You have requested to fuse {group} but one or more of them is not your model attributes"" <TAB>  <TAB>  <TAB> ) <TAB> return True","if not all ( _recursive_hasattr ( model , m ) for m in group ) :",109
"def cancel_loan_repayment_entry(self): <TAB> for loan in self.loans: <MASK> repayment_entry = frappe.get_doc( <TAB>  <TAB>  <TAB>  <TAB> ""Loan Repayment"", loan.loan_repayment_entry <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> repayment_entry.cancel()",if loan . loan_repayment_entry :,94
"def update_channel_entries(self, request): <TAB> try: <TAB>  <TAB> request_parsed = await request.json() <TAB> except (ContentTypeError, ValueError): <TAB>  <TAB> return RESTResponse({""error"": ""Bad JSON""}, status=HTTP_BAD_REQUEST) <TAB> results_list = [] <TAB> for entry in request_parsed: <TAB>  <TAB> public_key = database_blob(unhexlify(entry.pop(""public_key""))) <TAB>  <TAB> id_ = entry.pop(""id"") <TAB>  <TAB> error, result = self.update_entry(public_key, id_, entry) <TAB>  <TAB> # TODO: handle the results for a list that contains some errors in a smarter way <MASK> return RESTResponse(result, status=error) <TAB>  <TAB> results_list.append(result) <TAB> return RESTResponse(results_list)",if error :,194
"def delete(self, userId: str, bucket: str, key: str) -> bool: <TAB> if not self.initialized: <TAB>  <TAB> raise Exception(""archive not initialized"") <TAB> try: <TAB>  <TAB> with db.session_scope() as dbsession: <TAB>  <TAB>  <TAB> rc = db_archivedocument.delete(userId, bucket, key, session=dbsession) <MASK> raise Exception(""failed to delete DB record"") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> except Exception as err: <TAB>  <TAB> raise err",if not rc :,130
"def handle_phase(task, config): <TAB> """"""Function that runs all of the configured plugins which act on the current phase."""""" <TAB> # Keep a list of all results, for input plugin combining <TAB> results = [] <TAB> for item in config: <TAB>  <TAB> for plugin_name, plugin_config in item.items(): <TAB>  <TAB>  <TAB> if phase in plugin.get_phases_by_plugin(plugin_name): <TAB>  <TAB>  <TAB>  <TAB> method = plugin.get_plugin_by_name(plugin_name).phase_handlers[phase] <TAB>  <TAB>  <TAB>  <TAB> log.debug(""Running plugin %s"" % plugin_name) <TAB>  <TAB>  <TAB>  <TAB> result = method(task, plugin_config) <MASK> results.append(result) <TAB> return itertools.chain(*results)","if phase == ""input"" and result :",188
"def guess_gitlab_remote(self): <TAB> upstream = self.get_upstream_for_active_branch() <TAB> integrated_remote = self.get_integrated_remote_name() <TAB> remotes = self.get_remotes() <TAB> if len(self.remotes) == 1: <TAB>  <TAB> return list(remotes.keys())[0] <TAB> elif upstream: <TAB>  <TAB> tracked_remote = upstream.split(""/"")[0] if upstream else None <MASK> return tracked_remote <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return None <TAB> else: <TAB>  <TAB> return integrated_remote",if tracked_remote and tracked_remote == integrated_remote :,154
"def do_test(self, path): <TAB> reader = paddle.reader.creator.recordio(path) <TAB> idx = 0 <TAB> for e in reader(): <TAB>  <TAB> if idx == 0: <TAB>  <TAB>  <TAB> self.assertEqual(e, (1, 2, 3)) <MASK> self.assertEqual(e, (4, 5, 6)) <TAB>  <TAB> idx += 1 <TAB> self.assertEqual(idx, 2)",elif idx == 1 :,106
"def gen_cpu_name(cpu): <TAB> if cpu == ""simple"": <TAB>  <TAB> return event_download.get_cpustr() <TAB> for j in known_cpus: <TAB>  <TAB> if cpu == j[0]: <MASK> return ""GenuineIntel-6-%02X-%d"" % j[1][0] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return ""GenuineIntel-6-%02X"" % j[1][0] <TAB> assert False","if isinstance ( j [ 1 ] [ 0 ] , tuple ) :",127
"def read_kernel_cmdline_config(cmdline=None): <TAB> if cmdline is None: <TAB>  <TAB> cmdline = util.get_cmdline() <TAB> if ""network-config="" in cmdline: <TAB>  <TAB> data64 = None <TAB>  <TAB> for tok in cmdline.split(): <TAB>  <TAB>  <TAB> if tok.startswith(""network-config=""): <TAB>  <TAB>  <TAB>  <TAB> data64 = tok.split(""="", 1)[1] <MASK> if data64 == KERNEL_CMDLINE_NETWORK_CONFIG_DISABLED: <TAB>  <TAB>  <TAB>  <TAB> return {""config"": ""disabled""} <TAB>  <TAB>  <TAB> return util.load_yaml(_b64dgz(data64)) <TAB> return None",if data64 :,152
"def _verify_bot(self, ctx: ""Context"") -> None: <TAB> if ctx.guild is None: <TAB>  <TAB> bot_user = ctx.bot.user <TAB> else: <TAB>  <TAB> bot_user = ctx.guild.me <TAB>  <TAB> cog = ctx.cog <MASK> raise discord.ext.commands.DisabledCommand() <TAB> bot_perms = ctx.channel.permissions_for(bot_user) <TAB> if not (bot_perms.administrator or bot_perms >= self.bot_perms): <TAB>  <TAB> raise BotMissingPermissions( <TAB>  <TAB>  <TAB> missing=self._missing_perms(self.bot_perms, bot_perms) <TAB>  <TAB> )","if cog and await ctx . bot . cog_disabled_in_guild ( cog , ctx . guild ) :",181
"def _split_values(self, value): <TAB> # do the regex mojo here <TAB> if not self.allowed_values: <TAB>  <TAB> return ("""",) <TAB> try: <TAB>  <TAB> r = re.compile(self.allowed_values) <TAB> except: <TAB>  <TAB> print(self.allowed_values, file=sys.stderr) <TAB>  <TAB> raise <TAB> s = str(value) <TAB> i = 0 <TAB> vals = [] <TAB> while True: <TAB>  <TAB> m = r.search(s[i:]) <MASK> break <TAB>  <TAB> vals.append(m.group()) <TAB>  <TAB> delimiter = s[i : i + m.start()] <TAB>  <TAB> if self.delimiter is None and delimiter != """": <TAB>  <TAB>  <TAB> self.delimiter = delimiter <TAB>  <TAB> i += m.end() <TAB> return tuple(vals)",if m is None :,192
"def _count(self, element, count=True): <TAB> if not isinstance(element, six.string_types): <TAB>  <TAB> if self == element: <TAB>  <TAB>  <TAB> return 1 <TAB> i = 0 <TAB> for child in self.children: <TAB>  <TAB> # child is text content and element is also text content, then <TAB>  <TAB> # make a simple ""text"" in ""text"" <TAB>  <TAB> if isinstance(child, six.string_types): <TAB>  <TAB>  <TAB> if isinstance(element, six.string_types): <TAB>  <TAB>  <TAB>  <TAB> if count: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> i += child.count(element) <TAB>  <TAB>  <TAB>  <TAB> elif element in child: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> i += child._count(element, count=count) <MASK> return i <TAB> return i",if not count and i :,196
"def set_page(self, page): <TAB> """"""If a page is present as a bookmark than select it."""""" <TAB> pagename = page.name <TAB> with self.on_bookmark_clicked.blocked(): <TAB>  <TAB> for button in self.scrolledbox.get_scrolled_children(): <MASK> button.set_active(True) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> button.set_active(False)",if button . zim_path == pagename :,112
"def get_Subclass_of(rt): <TAB> for y in [getattr(Ast, x) for x in dir(Ast)]: <TAB>  <TAB> yt = clr.GetClrType(y) <MASK> continue <TAB>  <TAB> if yt.IsAbstract: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if yt.IsSubclassOf(rt): <TAB>  <TAB>  <TAB> yield yt.Name",if rt == yt :,93
"def update_parent_columns(self): <TAB> ""Update the parent columns of the current focus column."" <TAB> f = self.columns.get_focus_column() <TAB> col = self.col_list[f] <TAB> while 1: <TAB>  <TAB> parent, pcol = self.get_parent(col) <TAB>  <TAB> if pcol is None: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> changed = pcol.update_results(start_from=parent) <MASK> return <TAB>  <TAB> col = pcol",if not changed :,121
"def get_template_engine(themes): <TAB> """"""Get template engine used by a given theme."""""" <TAB> for theme_name in themes: <TAB>  <TAB> engine_path = os.path.join(theme_name, ""engine"") <MASK> with open(engine_path) as fd: <TAB>  <TAB>  <TAB>  <TAB> return fd.readlines()[0].strip() <TAB> # default <TAB> return ""mako""",if os . path . isfile ( engine_path ) :,104
"def reConnect(self): <TAB> while self.retrymax is None or self.retries < self.retrymax: <TAB>  <TAB> logger.info(""Cobra reconnection attempt"") <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.conn = self.httpfact() <MASK> self.authUser(self.authinfo) <TAB>  <TAB>  <TAB> self.retries = 0 <TAB>  <TAB>  <TAB> return <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> time.sleep(2 ** self.retries) <TAB>  <TAB>  <TAB> self.retries += 1 <TAB> self.trashed = True <TAB> raise CobraHttpException(""Retry Exceeded!"")",if self . _cobra_sessid :,149
"def __eq__(self, other): <TAB> if isinstance(other, OrderedDict): <TAB>  <TAB> if len(self) != len(other): <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> for p, q in zip(list(self.items()), list(other.items())): <MASK> return False <TAB>  <TAB> return True <TAB> return dict.__eq__(self, other)",if p != q :,91
"def __getExpectedSampleOffsets(self, tileOrigin, area1, area2): <TAB> ts = GafferImage.ImagePlug.tileSize() <TAB> data = [] <TAB> for y in range(tileOrigin.y, tileOrigin.y + ts): <TAB>  <TAB> for x in range(tileOrigin.x, tileOrigin.x + ts): <TAB>  <TAB>  <TAB> pixel = imath.V2i(x, y) <TAB>  <TAB>  <TAB> data.append(data[-1] if data else 0) <MASK> data[-1] += 1 <TAB>  <TAB>  <TAB> if GafferImage.BufferAlgo.contains(area2, pixel): <TAB>  <TAB>  <TAB>  <TAB> data[-1] += 1 <TAB> return IECore.IntVectorData(data)","if GafferImage . BufferAlgo . contains ( area1 , pixel ) :",190
"def _get_changes(self): <TAB> """"""Get changes from CHANGES.txt."""""" <TAB> log_lines = [] <TAB> found_version = False <TAB> found_items = False <TAB> with open(""CHANGES.txt"", ""r"") as fp: <TAB>  <TAB> for line in fp.readlines(): <TAB>  <TAB>  <TAB> line = line.rstrip() <TAB>  <TAB>  <TAB> if line.endswith(VERSION_TEXT_SHORT): <TAB>  <TAB>  <TAB>  <TAB> found_version = True <TAB>  <TAB>  <TAB> if not line.strip() and found_items: <TAB>  <TAB>  <TAB>  <TAB> break <MASK> log_lines.append("" "" * 2 + ""* "" + line[2:]) <TAB>  <TAB>  <TAB>  <TAB> found_items = True <TAB> return log_lines","elif found_version and line . startswith ( ""- "" ) :",174
"def _next_hid(self, n=1): <TAB> # this is overriden in mapping.py db_next_hid() method <TAB> if len(self.datasets) == 0: <TAB>  <TAB> return n <TAB> else: <TAB>  <TAB> last_hid = 0 <TAB>  <TAB> for dataset in self.datasets: <MASK> last_hid = dataset.hid <TAB>  <TAB> return last_hid + n",if dataset . hid > last_hid :,105
"def setInt(self, path, value, **kwargs): <TAB> if value is None: <TAB>  <TAB> self.set(path, None, **kwargs) <TAB>  <TAB> return <TAB> minimum = kwargs.pop(""min"", None) <TAB> maximum = kwargs.pop(""max"", None) <TAB> try: <TAB>  <TAB> intValue = int(value) <TAB>  <TAB> if minimum is not None and intValue < minimum: <TAB>  <TAB>  <TAB> intValue = minimum <MASK> intValue = maximum <TAB> except ValueError: <TAB>  <TAB> self._logger.warning( <TAB>  <TAB>  <TAB> ""Could not convert %r to a valid integer when setting option %r"" <TAB>  <TAB>  <TAB> % (value, path) <TAB>  <TAB> ) <TAB>  <TAB> return <TAB> self.set(path, intValue, **kwargs)",if maximum is not None and intValue > maximum :,187
"def _load_idle_extensions(self, sub_section, fp, lineno): <TAB> extension_map = self.get_data(""idle extensions"") <TAB> if extension_map is None: <TAB>  <TAB> extension_map = {} <TAB> extensions = [] <TAB> while 1: <TAB>  <TAB> line, lineno, bBreak = self._readline(fp, lineno) <MASK> break <TAB>  <TAB> line = line.strip() <TAB>  <TAB> if line: <TAB>  <TAB>  <TAB> extensions.append(line) <TAB> extension_map[sub_section] = extensions <TAB> self._save_data(""idle extensions"", extension_map) <TAB> return line, lineno",if bBreak :,149
"def _get_config(key): <TAB> config = db.session.execute( <TAB>  <TAB> Configs.__table__.select().where(Configs.key == key) <TAB> ).fetchone() <TAB> if config and config.value: <TAB>  <TAB> value = config.value <MASK> return int(value) <TAB>  <TAB> elif value and isinstance(value, string_types): <TAB>  <TAB>  <TAB> if value.lower() == ""true"": <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB> elif value.lower() == ""false"": <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return value <TAB> # Flask-Caching is unable to roundtrip a value of None. <TAB> # Return an exception so that we can still cache and avoid the db hit <TAB> return KeyError",if value and value . isdigit ( ) :,181
"def check_labels(self): <TAB> print(""Checking labels if they are outside the image"") <TAB> for i in self.Dataframe.index: <TAB>  <TAB> image_name = os.path.join(self.project_path, i) <TAB>  <TAB> im = PIL.Image.open(image_name) <TAB>  <TAB> self.width, self.height = im.size <TAB>  <TAB> for ind in self.individual_names: <MASK> self.Dataframe = MainFrame.force_outside_labels_Nans( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self, i, ind, self.uniquebodyparts <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.Dataframe = MainFrame.force_outside_labels_Nans( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self, i, ind, self.multianimalbodyparts <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return self.Dataframe","if ind == ""single"" :",196
"def remove_excluded(self): <TAB> """"""Remove all sources marked as excluded."""""" <TAB> # import yaml <TAB> # print yaml.dump({k:v.__json__() for k,v in self.sources.items()}, default_flow_style=False) <TAB> sources = list(self.sources.values()) <TAB> for src in sources: <MASK> del self.sources[src.name] <TAB>  <TAB> src.imports = [m for m in src.imports if not self._exclude(m)] <TAB>  <TAB> src.imported_by = [m for m in src.imported_by if not self._exclude(m)]",if src . excluded :,146
"def parse_scientific_formats(data, tree): <TAB> scientific_formats = data.setdefault(""scientific_formats"", {}) <TAB> for elem in tree.findall("".//scientificFormats/scientificFormatLength""): <TAB>  <TAB> type = elem.attrib.get(""type"") <MASK> continue <TAB>  <TAB> pattern = text_type(elem.findtext(""scientificFormat/pattern"")) <TAB>  <TAB> scientific_formats[type] = numbers.parse_pattern(pattern)","if _should_skip_elem ( elem , type , scientific_formats ) :",132
"def _modifierCodes2Labels(cls, mods): <MASK> return [] <TAB> modconstants = cls._modifierCodes <TAB> modNameList = [] <TAB> for k in modconstants._keys: <TAB>  <TAB> mc = modconstants._names[k] <TAB>  <TAB> if mods & k == k: <TAB>  <TAB>  <TAB> modNameList.append(mc) <TAB>  <TAB>  <TAB> mods = mods - k <TAB>  <TAB>  <TAB> if mods == 0: <TAB>  <TAB>  <TAB>  <TAB> return modNameList <TAB> return modNameList",if mods == 0 :,121
"def to_pig_latin(text: str): <TAB> if text is None: <TAB>  <TAB> return """" <TAB> words = text.lower().strip().split("" "") <TAB> text = [] <TAB> for word in words: <TAB>  <TAB> if word[0] in ""aeiou"": <TAB>  <TAB>  <TAB> text.append(f""{word}yay"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for letter in word: <MASK> text.append( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f""{word[word.index(letter):]}{word[:word.index(letter)]}ay"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return "" "".join(text)","if letter in ""aeiou"" :",165
"def __connect__(self) -> H2Protocol: <MASK> async with self._connect_lock: <TAB>  <TAB>  <TAB> self._state = _ChannelState.CONNECTING <TAB>  <TAB>  <TAB> if not self._connected: <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._protocol = await self._create_connection() <TAB>  <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._state = _ChannelState.TRANSIENT_FAILURE <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._state = _ChannelState.READY <TAB> return cast(H2Protocol, self._protocol)",if not self . _connected :,147
"def run_commands(cmds): <TAB> set_kubeconfig_environment_var() <TAB> for cmd in cmds: <TAB>  <TAB> process = subprocess.run( <TAB>  <TAB>  <TAB> cmd, <TAB>  <TAB>  <TAB> shell=True, <TAB>  <TAB>  <TAB> check=True, <TAB>  <TAB>  <TAB> universal_newlines=True, <TAB>  <TAB>  <TAB> stdout=subprocess.PIPE, <TAB>  <TAB>  <TAB> stderr=subprocess.PIPE, <TAB>  <TAB>  <TAB> env=os.environ, <TAB>  <TAB> ) <TAB>  <TAB> if process.stdout: <TAB>  <TAB>  <TAB> logger.info(process.stdout) <MASK> logger.info(process.stderr) <TAB> return process.stdout",if process . stderr :,146
"def deserialize(x): <TAB> t = type(x) <TAB> if t is list: <TAB>  <TAB> return list(imap(deserialize, x)) <TAB> if t is dict: <MASK> return {key: deserialize(val) for key, val in iteritems(x)} <TAB>  <TAB> obj = objmap.get(x[""_id_""]) <TAB>  <TAB> if obj is None: <TAB>  <TAB>  <TAB> entity_name = x[""class""] <TAB>  <TAB>  <TAB> entity = database.entities[entity_name] <TAB>  <TAB>  <TAB> pk = x[""_pk_""] <TAB>  <TAB>  <TAB> obj = entity[pk] <TAB>  <TAB> return obj <TAB> return x","if ""_id_"" not in x :",150
"def _parse_arguments(self, handler_method): <TAB> spec = DynamicArgumentParser().parse(self._argspec, self.longname) <TAB> if not self._supports_kwargs: <MASK> raise DataError( <TAB>  <TAB>  <TAB>  <TAB> ""Too few '%s' method parameters for **kwargs "" <TAB>  <TAB>  <TAB>  <TAB> ""support."" % self._run_keyword_method_name <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if spec.kwonlyargs: <TAB>  <TAB>  <TAB> raise DataError( <TAB>  <TAB>  <TAB>  <TAB> ""Too few '%s' method parameters for "" <TAB>  <TAB>  <TAB>  <TAB> ""keyword-only arguments support."" % self._run_keyword_method_name <TAB>  <TAB>  <TAB> ) <TAB> spec.types = GetKeywordTypes(self.library.get_instance())(self._handler_name) <TAB> return spec",if spec . kwargs :,183
"def test_update_password_command(mocker, username, password, expected, changed): <TAB> with mocker.patch.object(UpdatePassword, ""update_password"", return_value=changed): <TAB>  <TAB> result, stdout, stderr = run_command( <TAB>  <TAB>  <TAB> ""update_password"", username=username, password=password <TAB>  <TAB> ) <MASK> assert stdout == expected <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert str(result) == expected",if result is None :,108
"def characters(self, ch): <TAB> if self.Text_tag: <TAB>  <TAB> if self.Summary_tag: <TAB>  <TAB>  <TAB> self.Summary_ch += ch <MASK> self.Attack_Prerequisite_ch += ch <TAB>  <TAB> elif self.Solution_or_Mitigation_tag: <TAB>  <TAB>  <TAB> self.Solution_or_Mitigation_ch += ch <TAB> elif self.CWE_ID_tag: <TAB>  <TAB> self.CWE_ID_ch += ch",elif self . Attack_Prerequisite_tag :,127
"def _pybin_add_zip(pybin, libname, filter, exclusions, dirs, dirs_with_init_py): <TAB> with zipfile.ZipFile(libname, ""r"") as lib: <TAB>  <TAB> name_list = lib.namelist() <TAB>  <TAB> for name in name_list: <MASK> if dirs is not None and dirs_with_init_py is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _update_init_py_dirs(name, dirs, dirs_with_init_py) <TAB>  <TAB>  <TAB>  <TAB> pybin.writestr(name, lib.read(name))","if filter ( name ) and not _is_python_excluded_path ( name , exclusions ) :",158
"def parseAGL(filename):  # -> { 2126: 'Omega', ... } <TAB> m = {} <TAB> for line in readLines(filename): <TAB>  <TAB> # Omega;2126 <TAB>  <TAB> # dalethatafpatah;05D3 05B2   # higher-level combinations; ignored <TAB>  <TAB> line = line.strip() <TAB>  <TAB> if len(line) > 0 and line[0] != ""#"": <TAB>  <TAB>  <TAB> name, uc = tuple([c.strip() for c in line.split("";"")]) <MASK> # it's a 1:1 mapping <TAB>  <TAB>  <TAB>  <TAB> m[int(uc, 16)] = name <TAB> return m","if uc . find ( "" "" ) == - 1 :",169
"def assertS_IS(self, name, mode): <TAB> # test format, lstrip is for S_IFIFO <TAB> fmt = getattr(stat, ""S_IF"" + name.lstrip(""F"")) <TAB> self.assertEqual(stat.S_IFMT(mode), fmt) <TAB> # test that just one function returns true <TAB> testname = ""S_IS"" + name <TAB> for funcname in self.format_funcs: <TAB>  <TAB> func = getattr(stat, funcname, None) <MASK> if funcname == testname: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(funcname) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if funcname == testname: <TAB>  <TAB>  <TAB> self.assertTrue(func(mode)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertFalse(func(mode))",if func is None :,180
"def metadata(draft): <TAB> test_metadata = {} <TAB> json_schema = create_jsonschema_from_metaschema(draft.registration_schema.schema) <TAB> for key, value in json_schema[""properties""].items(): <TAB>  <TAB> response = ""Test response"" <TAB>  <TAB> items = value[""properties""][""value""].get(""items"") <TAB>  <TAB> enum = value[""properties""][""value""].get(""enum"") <MASK> # multiselect <TAB>  <TAB>  <TAB> response = [items[""enum""][0]] <TAB>  <TAB> elif enum:  # singleselect <TAB>  <TAB>  <TAB> response = enum[0] <TAB>  <TAB> elif value[""properties""][""value""].get(""properties""): <TAB>  <TAB>  <TAB> response = {""question"": {""value"": ""Test Response""}} <TAB>  <TAB> test_metadata[key] = {""value"": response} <TAB> return test_metadata",if items :,185
"def decode_binary(binarystring): <TAB> """"""Decodes a binary string into it's integer value."""""" <TAB> n = 0 <TAB> for c in binarystring: <MASK> d = 0 <TAB>  <TAB> elif c == ""1"": <TAB>  <TAB>  <TAB> d = 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""Not an binary number"", binarystring) <TAB>  <TAB> # Could use ((n << 3 ) | d), but python 2.3 issues a FutureWarning. <TAB>  <TAB> n = (n * 2) + d <TAB> return n","if c == ""0"" :",126
"def getZoneOffset(d): <TAB> zoffs = 0 <TAB> try: <MASK> zoffs = 60 * int(d[""tzhour""]) + int(d[""tzminute""]) <TAB>  <TAB>  <TAB> if d[""tzsign""] != ""-"": <TAB>  <TAB>  <TAB>  <TAB> zoffs = -zoffs <TAB> except TypeError: <TAB>  <TAB> pass <TAB> return zoffs","if d [ ""zulu"" ] == None :",92
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.add_module(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 10 :,90
"def _flow_open(self): <TAB> rv = [] <TAB> for pipe in self.pipes: <TAB>  <TAB> if pipe._pipeline_all_methods_.issuperset({""open"", self._method_open}): <TAB>  <TAB>  <TAB> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB> f""{pipe.__class__.__name__} pipe has double open methods."" <TAB>  <TAB>  <TAB>  <TAB> f"" Use `open` or `{self._method_open}`, not both."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if ""open"" in pipe._pipeline_all_methods_: <TAB>  <TAB>  <TAB> rv.append(pipe.open) <MASK> rv.append(getattr(pipe, self._method_open)) <TAB> return rv",if self . _method_open in pipe . _pipeline_all_methods_ :,167
"def list_and_filter_commands(filter_str): <TAB> sorted_commands = list(_pwndbg.commands.commands) <TAB> sorted_commands.sort(key=lambda x: x.__name__) <TAB> if filter_str: <TAB>  <TAB> filter_str = filter_str.lower() <TAB> results = [] <TAB> for c in sorted_commands: <TAB>  <TAB> name = c.__name__ <TAB>  <TAB> docs = c.__doc__ <MASK> docs = docs.strip() <TAB>  <TAB> if docs: <TAB>  <TAB>  <TAB> docs = docs.splitlines()[0] <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB> not filter_str <TAB>  <TAB>  <TAB> or filter_str in name.lower() <TAB>  <TAB>  <TAB> or (docs and filter_str in docs.lower()) <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> results.append((name, docs)) <TAB> return results",if docs :,195
"def _scale_action(action: np.ndarray, spec: specs.Array): <TAB> """"""Converts a single canonical action back to the given action spec."""""" <TAB> if isinstance(spec, specs.BoundedArray): <TAB>  <TAB> # Get scale and offset of output action spec. <TAB>  <TAB> scale = spec.maximum - spec.minimum <TAB>  <TAB> offset = spec.minimum <TAB>  <TAB> # Maybe clip the action. <MASK> action = np.clip(action, -1.0, 1.0) <TAB>  <TAB> # Map action to [0, 1]. <TAB>  <TAB> action = 0.5 * (action + 1.0) <TAB>  <TAB> # Map action to [spec.minimum, spec.maximum]. <TAB>  <TAB> action *= scale <TAB>  <TAB> action += offset <TAB> return action",if clip :,176
"def genData(self, samples, inc, sps): <TAB> self.prepModData(samples, inc, sps) <TAB> data = Array.CreateInstance(float, samples) <TAB> cycleLen = float(sps) / gcdlist(self.findAllFreq()) <TAB> p = 1.0 <TAB> c = 0 <TAB> for i in range(int(cycleLen)): <TAB>  <TAB> data[i] = p * self.ampl <TAB>  <TAB> c = c + 2 * inc * self.freq * self.addModData(i) <MASK> p = 1.0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> p = -1.0 <TAB> self.fillData(cycleLen, samples, data) <TAB> return data",if int ( c ) % 2 == 0 :,175
"def data_type(data, grouped=False, columns=None, key_on=""idx"", iter_idx=None): <TAB> """"""Data type check for automatic import"""""" <TAB> if iter_idx: <TAB>  <TAB> return Data.from_mult_iters(idx=iter_idx, **data) <TAB> if pd: <MASK> return Data.from_pandas( <TAB>  <TAB>  <TAB>  <TAB> data, grouped=grouped, columns=columns, key_on=key_on <TAB>  <TAB>  <TAB> ) <TAB> if isinstance(data, (list, tuple, dict)): <TAB>  <TAB> return Data.from_iter(data) <TAB> else: <TAB>  <TAB> raise ValueError(""This data type is not supported by Vincent."")","if isinstance ( data , ( pd . Series , pd . DataFrame ) ) :",173
"def addNames(self, import_names, node_names): <TAB> for names in node_names: <TAB>  <TAB> if isinstance(names, basestring): <TAB>  <TAB>  <TAB> name = names <MASK> name = names[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = names[1] <TAB>  <TAB> import_names[name] = True",elif names [ 1 ] is None :,88
"def validate_address(address_name): <TAB> fields = [""pincode"", ""city"", ""country_code""] <TAB> data = frappe.get_cached_value(""Address"", address_name, fields, as_dict=1) or {} <TAB> for field in fields: <MASK> frappe.throw( <TAB>  <TAB>  <TAB>  <TAB> _(""Please set {0} for address {1}"").format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> field.replace(""-"", """"), address_name <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB>  <TAB> title=_(""E-Invoicing Information Missing""), <TAB>  <TAB>  <TAB> )",if not data . get ( field ) :,142
"def content(computer, name, values): <TAB> """"""Compute the ``content`` property."""""" <TAB> if len(values) == 1: <TAB>  <TAB> (value,) = values <MASK> return ""inhibit"" if computer[""pseudo_type""] else ""contents"" <TAB>  <TAB> elif value == ""none"": <TAB>  <TAB>  <TAB> return ""inhibit"" <TAB> return _content_list(computer, values)","if value == ""normal"" :",101
"def _replace_list(self, items): <TAB> results = [] <TAB> for item in items: <TAB>  <TAB> listvar = self._replace_variables_inside_possible_list_var(item) <MASK> results.extend(self[listvar]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> results.append(self.replace_scalar(item)) <TAB> return results",if listvar :,90
"def _groups_args_split(self, kwargs): <TAB> groups_args_split = [] <TAB> groups = kwargs[""groups""] <TAB> for key, group in groups.iteritems(): <TAB>  <TAB> mykwargs = kwargs.copy() <TAB>  <TAB> del mykwargs[""groups""] <MASK> mykwargs[""source_security_group_name""] = group[""group_name""] <TAB>  <TAB> if ""user_id"" in group: <TAB>  <TAB>  <TAB> mykwargs[""source_security_group_owner_id""] = group[""user_id""] <TAB>  <TAB> if ""group_id"" in group: <TAB>  <TAB>  <TAB> mykwargs[""source_security_group_id""] = group[""group_id""] <TAB>  <TAB> groups_args_split.append(mykwargs) <TAB> return groups_args_split","if ""group_name"" in group :",186
"def WriteFlowOutputPluginLogEntries(self, entries): <TAB> """"""Writes flow output plugin log entries."""""" <TAB> flow_ids = [(e.client_id, e.flow_id) for e in entries] <TAB> for f in flow_ids: <MASK> raise db.AtLeastOneUnknownFlowError(flow_ids) <TAB> for e in entries: <TAB>  <TAB> dest = self.flow_output_plugin_log_entries.setdefault( <TAB>  <TAB>  <TAB> (e.client_id, e.flow_id), [] <TAB>  <TAB> ) <TAB>  <TAB> to_write = e.Copy() <TAB>  <TAB> to_write.timestamp = rdfvalue.RDFDatetime.Now() <TAB>  <TAB> dest.append(to_write)",if f not in self . flows :,173
def connect(**auth): <TAB> key = tuple(sorted(auth.items())) <TAB> if key in connection_pool: <TAB>  <TAB> ssh = connection_pool[key] <MASK> ssh.connect(**auth) <TAB> else: <TAB>  <TAB> ssh = paramiko.SSHClient() <TAB>  <TAB> ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy()) <TAB>  <TAB> ssh.connect(**auth) <TAB>  <TAB> connection_pool[key] = ssh <TAB> return ssh,if not ssh . get_transport ( ) or not ssh . get_transport ( ) . is_active ( ) :,131
"def __call__(self, *args, **kwargs): <TAB> if self is S: <MASK> raise TypeError(""S() takes no positional arguments, got: %r"" % (args,)) <TAB>  <TAB> if not kwargs: <TAB>  <TAB>  <TAB> raise TypeError(""S() expected at least one kwarg, got none"") <TAB>  <TAB> # TODO: typecheck kwarg vals? <TAB> return _t_child(self, ""("", (args, kwargs))",if args :,101
"def read_images(self, paths=[]): <TAB> images = [] <TAB> for img_path in paths: <TAB>  <TAB> assert os.path.isfile(img_path), ""The {} isn't a valid file."".format(img_path) <TAB>  <TAB> img = cv2.imread(img_path) <MASK> logger.info(""error in loading image:{}"".format(img_path)) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> img = img[:, :, ::-1] <TAB>  <TAB> images.append(img) <TAB> return images",if img is None :,123
"def get_polymorphic_model(data): <TAB> for model in itervalues(models): <TAB>  <TAB> polymorphic = model.opts.polymorphic <TAB>  <TAB> if polymorphic: <TAB>  <TAB>  <TAB> polymorphic_key = polymorphic <MASK> polymorphic_key = ""type"" <TAB>  <TAB>  <TAB> if data.get(polymorphic_key) == model.__name__: <TAB>  <TAB>  <TAB>  <TAB> return model <TAB> raise ImproperlyConfigured(u""No model found for data: {!r}"".format(data))","if isinstance ( polymorphic_key , bool ) :",133
"def parse_counter_style_name(tokens, counter_style): <TAB> tokens = remove_whitespace(tokens) <TAB> if len(tokens) == 1: <TAB>  <TAB> (token,) = tokens <TAB>  <TAB> if token.type == ""ident"": <MASK> if token.lower_value not in counter_style: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return token.value <TAB>  <TAB>  <TAB> elif token.lower_value != ""none"": <TAB>  <TAB>  <TAB>  <TAB> return token.value","if token . lower_value in ( ""decimal"" , ""disc"" ) :",122
"def setUp(self): <TAB> yield helpers.TestHandlerWithPopulatedDB.setUp(self) <TAB> for r in (yield tw(user.db_get_users, 1, ""receiver"", ""en"")): <MASK> self.rcvr_id = r[""id""]","if r [ ""pgp_key_fingerprint"" ] == ""BFB3C82D1B5F6A94BDAC55C6E70460ABF9A4C8C1"" :",109
"def check_that_oval_and_rule_id_match(xccdftree): <TAB> for xccdfid, rule in rules_with_ids_generator(xccdftree): <TAB>  <TAB> checks = rule.find(""./{%s}check"" % XCCDF11_NS) <MASK> print(""Rule {0} doesn't have checks."".format(xccdfid), file=sys.stderr) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> assert_that_check_ids_match_rule_id(checks, xccdfid)",if checks is None :,133
"def MakeWidthArray(fm): <TAB> # Make character width array <TAB> s = ""{\n\t"" <TAB> cw = fm[""Widths""] <TAB> for i in xrange(0, 256): <MASK> s += ""'\\''"" <TAB>  <TAB> elif chr(i) == ""\\"": <TAB>  <TAB>  <TAB> s += ""'\\\\'"" <TAB>  <TAB> elif i >= 32 and i <= 126: <TAB>  <TAB>  <TAB> s += ""'"" + chr(i) + ""'"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> s += ""chr(%d)"" % i <TAB>  <TAB> s += "":"" + fm[""Widths""][i] <TAB>  <TAB> if i < 255: <TAB>  <TAB>  <TAB> s += "","" <TAB>  <TAB> if (i + 1) % 22 == 0: <TAB>  <TAB>  <TAB> s += ""\n\t"" <TAB> s += ""}"" <TAB> return s","if chr ( i ) == ""'"" :",192
"def testCheckIPGenerator(self): <TAB> for i, ip in self._ip_range(65536 if not unittest.F2B.fast else 1000): <TAB>  <TAB> if i == 254: <TAB>  <TAB>  <TAB> self.assertEqual(str(ip), ""127.0.0.255"") <TAB>  <TAB> elif i == 255: <TAB>  <TAB>  <TAB> self.assertEqual(str(ip), ""127.0.1.0"") <TAB>  <TAB> elif i == 1000: <TAB>  <TAB>  <TAB> self.assertEqual(str(ip), ""127.0.3.233"") <MASK> self.assertEqual(str(ip), ""127.0.255.255"") <TAB>  <TAB> elif i == 65535: <TAB>  <TAB>  <TAB> self.assertEqual(str(ip), ""127.1.0.0"")",elif i == 65534 :,181
"def _fetch(obj, url, body, *args, **kwargs): <TAB> if _is_running_from_main_thread(): <TAB>  <TAB> body = urlencode(body).encode(""utf-8"") <TAB>  <TAB> response = self.fetch(url, body=body, method=""POST"") <MASK> raise luigi.rpc.RPCError(""Errror when connecting to remote scheduler"") <TAB>  <TAB> return response.body.decode(""utf-8"")",if response . code >= 400 :,113
"def isOrHasChild(parent, child): <TAB> while child: <TAB>  <TAB> if compare(parent, child): <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> child = child.parentNode <MASK> return False <TAB>  <TAB> if child.nodeType != 1: <TAB>  <TAB>  <TAB> child = None <TAB> return False",if not child :,76
"def HandleCharFormatChange(self, id, code): <TAB> if code == win32con.BN_CLICKED: <TAB>  <TAB> editId = buttonControlMap.get(id) <TAB>  <TAB> assert editId is not None, ""Format button has no associated edit control"" <TAB>  <TAB> editControl = self.GetDlgItem(editId) <TAB>  <TAB> existingFormat = editControl.GetDefaultCharFormat() <TAB>  <TAB> flags = win32con.CF_SCREENFONTS <TAB>  <TAB> d = win32ui.CreateFontDialog(existingFormat, flags, None, self) <MASK> cf = d.GetCharFormat() <TAB>  <TAB>  <TAB> editControl.SetDefaultCharFormat(cf) <TAB>  <TAB>  <TAB> self.SetModified(1) <TAB>  <TAB> return 0  # We handled this fully!",if d . DoModal ( ) == win32con . IDOK :,192
"def test___iter___two_points(self): <TAB> cba = LineString([(1, 2), (3, 4)]) <TAB> for i, xy in enumerate(cba): <TAB>  <TAB> assert i in [0, 1] <MASK> assert np.allclose(xy, (1, 2)) <TAB>  <TAB> elif i == 1: <TAB>  <TAB>  <TAB> assert np.allclose(xy, (3, 4)) <TAB> assert i == 1",if i == 0 :,103
"def main(self): <TAB> self.model.clear() <TAB> active_handle = self.get_active(""Family"") <TAB> if active_handle: <TAB>  <TAB> active = self.dbstate.db.get_family_from_handle(active_handle) <MASK> self.display_attributes(active) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.set_has_data(False) <TAB> else: <TAB>  <TAB> self.set_has_data(False)",if active :,113
"def findStyleName(element, style): <TAB> oldStyle = DOM.getAttribute(element, ""className"") <TAB> if oldStyle is None: <TAB>  <TAB> return -1 <TAB> idx = oldStyle.find(style) <TAB> # Calculate matching index <TAB> lastPos = len(oldStyle) <TAB> while idx != -1: <TAB>  <TAB> if idx == 0 or (oldStyle[idx - 1] == "" ""): <TAB>  <TAB>  <TAB> last = idx + len(style) <MASK> break <TAB>  <TAB> idx = oldStyle.find(style, idx + 1) <TAB> return idx","if ( last == lastPos ) or ( ( last < lastPos ) and ( oldStyle [ last ] == "" "" ) ) :",161
"def result(self): <TAB> """"""Gets the formatted string result."""""" <TAB> if self.__group.isChecked(): <MASK> return ""gt%d"" % self.__min.value() <TAB>  <TAB> if self.__lessThan.isChecked(): <TAB>  <TAB>  <TAB> return ""lt%d"" % self.__max.value() <TAB>  <TAB> if self.__range.isChecked(): <TAB>  <TAB>  <TAB> return ""%d-%d"" % (self.__min.value(), self.__max.value()) <TAB> return """"",if self . __moreThan . isChecked ( ) :,122
"def get_generic_exception_from_err_details(err_details): <TAB> err = None <TAB> if err_details.errcls is not None: <TAB>  <TAB> err = err_details.errcls(err_details.message) <MASK> err.set_linecol( <TAB>  <TAB>  <TAB>  <TAB> err_details.detail_json.get(""line"", -1), <TAB>  <TAB>  <TAB>  <TAB> err_details.detail_json.get(""column"", -1), <TAB>  <TAB>  <TAB> ) <TAB> return err",if err_details . errcls is not errors . InternalServerError :,131
"def convert_value(self, value, expression, connection, context): <TAB> if value is None: <TAB>  <TAB> return None <TAB> geo_field = self.geo_field <TAB> if geo_field.geodetic(connection): <TAB>  <TAB> dist_att = ""m"" <TAB> else: <TAB>  <TAB> units = geo_field.units_name(connection) <MASK> dist_att = DistanceMeasure.unit_attname(units) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> dist_att = None <TAB> if dist_att: <TAB>  <TAB> return DistanceMeasure(**{dist_att: value}) <TAB> return value",if units :,144
"def __init__(self, **kwargs): <TAB> self.layout_cell = kwargs.pop(""layout_cell"") <TAB> self.theme = kwargs.pop(""theme"") <TAB> assert isinstance(self.layout_cell, LayoutCell) <TAB> super(LayoutCellFormGroup, self).__init__(**kwargs) <TAB> self.add_form_def( <TAB>  <TAB> ""general"", <TAB>  <TAB> LayoutCellGeneralInfoForm, <TAB>  <TAB> kwargs={""layout_cell"": self.layout_cell, ""theme"": self.theme}, <TAB> ) <TAB> plugin = self.layout_cell.instantiate_plugin() <TAB> if plugin: <TAB>  <TAB> form_class = plugin.get_editor_form_class() <MASK> self.add_form_def(""plugin"", form_class, kwargs={""plugin"": plugin})",if form_class :,187
"def load_model(self, model_dict): <TAB> model_param = None <TAB> model_meta = None <TAB> for _, value in model_dict[""model""].items(): <TAB>  <TAB> for model in value: <MASK> model_meta = value[model] <TAB>  <TAB>  <TAB> if model.endswith(""Param""): <TAB>  <TAB>  <TAB>  <TAB> model_param = value[model] <TAB> LOGGER.info(""load model"") <TAB> self.set_model_meta(model_meta) <TAB> self.set_model_param(model_param) <TAB> self.loss = self.get_loss_function()","if model . endswith ( ""Meta"" ) :",148
"def add_plugin_single(name, plugin_to_add, parent): <TAB> plugin_existing = parent.get_plugins(name) <TAB> if plugin_existing is None: <TAB>  <TAB> parent.add_plugin(name, plugin_to_add) <TAB> else: <MASK> parent.update_plugin(name, plugin_to_add) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> error(""Duplicated plugin {}!"".format(name))",if not plugin_existing . is_callable_plugin ( ) :,114
"def get_details(guid): <TAB> searchResultId = guid <TAB> searchResult = SearchResult.get(SearchResult.id == searchResultId) <TAB> details_link = searchResult.details <TAB> if details_link: <TAB>  <TAB> logger.info(""Redirecting to details link %s "" % details_link) <MASK> details_link = config.settings.main.dereferer.replace( <TAB>  <TAB>  <TAB>  <TAB> ""$s"", urllib.quote(details_link) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return redirect(details_link) <TAB> logger.error(""Unable to find details link for search result ID %d"" % searchResultId) <TAB> return ""Unable to find details"", 500",if config . settings . main . dereferer :,167
"def SurroundedByParens(token): <TAB> """"""Check if it's an expression surrounded by parentheses."""""" <TAB> while token: <TAB>  <TAB> if token.value == "","": <TAB>  <TAB>  <TAB> return False <MASK> return not token.next_token <TAB>  <TAB> if token.OpensScope(): <TAB>  <TAB>  <TAB> token = token.matching_bracket.next_token <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> token = token.next_token <TAB> return False","if token . value == "")"" :",109
"def __str__(self, prefix="""", printElemNumber=0): <TAB> res = """" <TAB> cnt = 0 <TAB> for e in self.stat_: <TAB>  <TAB> elm = """" <MASK> elm = ""(%d)"" % cnt <TAB>  <TAB> res += prefix + (""stat%s <\n"" % elm) <TAB>  <TAB> res += e.__str__(prefix + ""  "", printElemNumber) <TAB>  <TAB> res += prefix + "">\n"" <TAB>  <TAB> cnt += 1 <TAB> if self.has_more_files_found_: <TAB>  <TAB> res += prefix + ( <TAB>  <TAB>  <TAB> ""more_files_found: %s\n"" % self.DebugFormatBool(self.more_files_found_) <TAB>  <TAB> ) <TAB> return res",if printElemNumber :,175
"def _get_constraints(self, params): <TAB> constraints = {} <TAB> for filter_name in self._get_filter_names(): <TAB>  <TAB> raw_value = params.get(filter_name, None) <MASK> constraints[filter_name] = self._get_value(raw_value) <TAB> return constraints",if raw_value is not None :,84
"def print_nested_help(self, args: argparse.Namespace) -> None: <TAB> level = 0 <TAB> parser = self.main_parser <TAB> while True: <TAB>  <TAB> if parser._subparsers is None: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if parser._subparsers._actions is None: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> choices = parser._subparsers._actions[-1].choices <TAB>  <TAB> value = getattr(args, ""level_%d"" % level) <MASK> parser.print_help() <TAB>  <TAB>  <TAB> return <TAB>  <TAB> if not choices: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if isinstance(choices, dict): <TAB>  <TAB>  <TAB> parser = choices[value] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> level += 1",if value is None :,175
"def prompts_dict(self, *args, **kwargs): <TAB> r = super(WorkflowJobNode, self).prompts_dict(*args, **kwargs) <TAB> # Explanation - WFJT extra_vars still break pattern, so they are not <TAB> # put through prompts processing, but inventory and others are only accepted <TAB> # if JT prompts for it, so it goes through this mechanism <TAB> if self.workflow_job: <MASK> # workflow job inventory takes precedence <TAB>  <TAB>  <TAB> r[""inventory""] = self.workflow_job.inventory <TAB>  <TAB> if self.workflow_job.char_prompts: <TAB>  <TAB>  <TAB> r.update(self.workflow_job.char_prompts) <TAB> return r",if self . workflow_job . inventory_id :,175
"def _check_etc_hosts(): <TAB> debug2("" > hosts\n"") <TAB> for line in open(""/etc/hosts""): <TAB>  <TAB> line = re.sub(r""#.*"", """", line) <TAB>  <TAB> words = line.strip().split() <TAB>  <TAB> if not words: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> ip = words[0] <TAB>  <TAB> names = words[1:] <MASK> debug3(""< <TAB> %s %r\n"" % (ip, names)) <TAB>  <TAB>  <TAB> for n in names: <TAB>  <TAB>  <TAB>  <TAB> check_host(n) <TAB>  <TAB>  <TAB>  <TAB> found_host(n, ip)",if _is_ip ( ip ) :,153
"def add_variant_attribute_data_to_expected_data(data, variant, attribute_ids, pk=None): <TAB> for assigned_attribute in variant.attributes.all(): <TAB>  <TAB> header = f""{assigned_attribute.attribute.slug} (variant attribute)"" <MASK> value = get_attribute_value(assigned_attribute) <TAB>  <TAB>  <TAB> if pk: <TAB>  <TAB>  <TAB>  <TAB> data[pk][header] = value <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> data[header] = value <TAB> return data",if str ( assigned_attribute . attribute . pk ) in attribute_ids :,136
"def scrub_time(self, time):  # used externally to set time by slider scrubbing <TAB> debug(""scrub_time: {0}"".format(time)) <TAB> if time == 0: <TAB>  <TAB> self.loop_backward() <TAB> elif time == self.timer_duration: <TAB>  <TAB> self.loop_forward() <TAB> else:  # time in between 0 and duration <MASK> self.timer_status = TIMER_STATUS_PAUSED <TAB>  <TAB> elif self.timer_status == TIMER_STATUS_EXPIRED: <TAB>  <TAB>  <TAB> self.timer_status = TIMER_STATUS_PAUSED <TAB> self.timer_time = time",if self . timer_status == TIMER_STATUS_STOPPED :,163
"def leave_AssignTarget( <TAB> self, <TAB> original_node: cst.AssignTarget, <TAB> updated_node: cst.AssignTarget,) -> cst.AssignTarget: <TAB> # We can't use matchers here due to circular imports <TAB> target = updated_node.target <TAB> if isinstance(target, cst.Name): <TAB>  <TAB> var_name = unmangled_name(target.value) <MASK> return self.assignment_replacements[var_name].deep_clone() <TAB> return updated_node",if var_name in self . assignment_replacements :,132
"def step(self, action): <TAB> assert self.action_space.contains(action) <TAB> if self._state == 4: <MASK> return self._state, 10.0, True, {} <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self._state, -10, True, {} <TAB> else: <TAB>  <TAB> if action: <TAB>  <TAB>  <TAB> if self._state == 0: <TAB>  <TAB>  <TAB>  <TAB> self._state = 2 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._state += 1 <TAB>  <TAB> elif self._state == 2: <TAB>  <TAB>  <TAB> self._state = self._case <TAB> return self._state, -1, False, {}",if action and self . _case :,157
"def last_ok(nodes): <TAB> for i in range(len(nodes) - 1, -1, -1): <MASK> node = nodes[i] <TAB>  <TAB>  <TAB> if isinstance(node, ast.Starred): <TAB>  <TAB>  <TAB>  <TAB> if ok_node(node.value): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return node.value <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return nodes[i] <TAB> return None",if ok_node ( nodes [ i ] ) :,122
"def __contains__(self, table_name): <TAB> """"""Check if the given table name exists in the database."""""" <TAB> try: <TAB>  <TAB> table_name = normalize_table_name(table_name) <MASK> return True <TAB>  <TAB> if table_name in self.views: <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> return False <TAB> except ValueError: <TAB>  <TAB> return False",if table_name in self . tables :,97
"def get_history_data(self, guid, count=1): <TAB> history = {} <TAB> if count < 1: <TAB>  <TAB> return history <TAB> key = self._make_key(guid) <TAB> for i in range(0, self.db.llen(key)): <TAB>  <TAB> r = self.db.lindex(key, i) <TAB>  <TAB> c = msgpack.unpackb(r) <TAB>  <TAB> if c[""tries""] == 0 or c[""tries""] is None: <MASK> history[c[""data""]] = c[""timestamp""] <TAB>  <TAB>  <TAB>  <TAB> if len(history) >= count: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return history","if c [ ""data"" ] not in history :",161
"def _state_dec_to_imp(self, token): <TAB> if token in (""+"", ""-""): <TAB>  <TAB> self._state = self._state_global <TAB> else: <TAB>  <TAB> super(ObjCStates, self)._state_dec_to_imp(token) <MASK> self._state = self._state_objc_dec_begin <TAB>  <TAB>  <TAB> self.context.restart_new_function(token)",if self . _state != self . _state_imp :,107
"def _additional_handlers(self): <TAB> handlers = [] <TAB> if self.session.get(""proxy""): <TAB>  <TAB> protocol, host, port = self._get_proxy() <MASK> handlers.append(sockshandler.SocksiPyHandler(protocol, host, port)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ChannelException(messages.channels.error_proxy_format) <TAB> # Skip certificate checks <TAB> ctx = ssl.create_default_context() <TAB> ctx.check_hostname = False <TAB> ctx.verify_mode = ssl.CERT_NONE <TAB> handlers.append(urllib.request.HTTPSHandler(context=ctx)) <TAB> return handlers",if protocol and host and port :,161
"def loadGCodeData(self, dataStream): <TAB> if self._printing: <TAB>  <TAB> return False <TAB> self._lineCount = 0 <TAB> for line in dataStream: <TAB>  <TAB> # Strip out comments, we do not need to send comments <TAB>  <TAB> if "";"" in line: <TAB>  <TAB>  <TAB> line = line[: line.index("";"")] <TAB>  <TAB> # Strip out whitespace at the beginning/end this saves data to send. <TAB>  <TAB> line = line.strip() <MASK> continue <TAB>  <TAB> self._lineCount += 1 <TAB> self._doCallback() <TAB> return True",if len ( line ) < 1 :,139
"def get_headers_footers_xml(self, uri): <TAB> for relKey, val in self.docx._part._rels.items(): <MASK> yield relKey, self.xml_to_string(parse_xml(val.target_part.blob))",if ( val . reltype == uri ) and ( val . target_part . blob ) :,85
"def eventlist_name(name=None, key=""core""): <TAB> if not name: <TAB>  <TAB> name = get_cpustr() <TAB> cache = getdir() <TAB> fn = name <TAB> if os.path.exists(fn): <TAB>  <TAB> return fn <TAB> if "".json"" not in name: <TAB>  <TAB> fn = ""%s-%s.json"" % (name, key) <TAB> if ""/"" in fn: <TAB>  <TAB> return fn <TAB> fn = ""%s/%s"" % (cache, fn) <TAB> if not os.path.exists(fn): <TAB>  <TAB> name = cpu_without_step(name) <MASK> fn = ""%s/%s"" % (cache, name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> fn = ""%s/%s-%s.json"" % (cache, name, key) <TAB> return fn","if ""*"" in fn :",196
"def test09_authority(self): <TAB> ""Testing the authority name & code routines."" <TAB> for s in srlist: <MASK> srs = SpatialReference(s.wkt) <TAB>  <TAB>  <TAB> for target, tup in s.auth.items(): <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(tup[0], srs.auth_name(target)) <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(tup[1], srs.auth_code(target))","if hasattr ( s , ""auth"" ) :",114
"def astAssign(self, import_names, node): <TAB> for node in node.nodes: <MASK> import_names[node.name] = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.warning(""Ignoring Assign %s"" % node.flags, node.lineno)","if node . flags == ""OP_ASSIGN"" :",76
"def _autojoin(self, __): <TAB> if not self.auto_join: <TAB>  <TAB> return <TAB> try: <TAB>  <TAB> result = self.get_bookmarks(method=self.storage_method) <TAB> except XMPPError: <TAB>  <TAB> return <TAB> if self.storage_method == ""xep_0223"": <TAB>  <TAB> bookmarks = result[""pubsub""][""items""][""item""][""bookmarks""] <TAB> else: <TAB>  <TAB> bookmarks = result[""private""][""bookmarks""] <TAB> for conf in bookmarks[""conferences""]: <MASK> log.debug(""Auto joining %s as %s"", conf[""jid""], conf[""nick""]) <TAB>  <TAB>  <TAB> self.xmpp[""xep_0045""].joinMUC( <TAB>  <TAB>  <TAB>  <TAB> conf[""jid""], conf[""nick""], password=conf[""password""] <TAB>  <TAB>  <TAB> )","if conf [ ""autojoin"" ] :",195
"def config_mode(self, config_command=""conf t"", pattern=""""): <TAB> output = """" <TAB> if not self.check_config_mode(): <TAB>  <TAB> output = self.send_command_timing( <TAB>  <TAB>  <TAB> config_command, strip_command=False, strip_prompt=False <TAB>  <TAB> ) <MASK> output += self.send_command_timing( <TAB>  <TAB>  <TAB>  <TAB> ""YES"", strip_command=False, strip_prompt=False <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if not self.check_config_mode(): <TAB>  <TAB>  <TAB> raise ValueError(""Failed to enter configuration mode"") <TAB> return output","if ""to enter configuration mode anyway"" in output :",152
"def work(self): <TAB> idle_times = 0 <TAB> while True: <TAB>  <TAB> if shutting_down.is_set(): <TAB>  <TAB>  <TAB> log.info(""Stop sync worker"") <TAB>  <TAB>  <TAB> break <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> job = self.commit_queue.get(timeout=self.timeout, block=True) <TAB>  <TAB>  <TAB> if job[""type""] == ""commit"": <TAB>  <TAB>  <TAB>  <TAB> self.commits.append(job) <TAB>  <TAB>  <TAB> log.debug(""Got a commit job"") <TAB>  <TAB>  <TAB> idle_times = 0 <TAB>  <TAB>  <TAB> idle.clear() <TAB>  <TAB> except Empty: <TAB>  <TAB>  <TAB> log.debug(""Nothing to do right now, going idle"") <MASK> idle.set() <TAB>  <TAB>  <TAB> idle_times += 1 <TAB>  <TAB>  <TAB> self.on_idle()",if idle_times > self . min_idle_times :,200
"def movies_iterator(): <TAB> for row in self._tuple_iterator(query): <TAB>  <TAB> id, guid, movie = self._parse(fields, row, offset=2) <TAB>  <TAB> # Parse `guid` (if enabled, and not already parsed) <MASK> if id not in guids: <TAB>  <TAB>  <TAB>  <TAB> guids[id] = Guid.parse(guid) <TAB>  <TAB>  <TAB> guid = guids[id] <TAB>  <TAB> # Return item <TAB>  <TAB> yield id, guid, movie",if parse_guid :,119
"def timesince(value): <TAB> diff = timezone.now() - value <TAB> plural = """" <TAB> if diff.days == 0: <TAB>  <TAB> hours = int(diff.seconds / 3600.0) <TAB>  <TAB> if hours != 1: <TAB>  <TAB>  <TAB> plural = ""s"" <TAB>  <TAB> return ""%d hour%s ago"" % (int(diff.seconds / 3600.0), plural) <TAB> else: <MASK> plural = ""s"" <TAB>  <TAB> return ""%d day%s ago"" % (diff.days, plural)",if diff . days != 1 :,129
"def connect(self, *args): <TAB> if len(args) == 0: <TAB>  <TAB> self.basepath = ""/"" <TAB>  <TAB> return True  # no setup required; connect is allways successful <TAB> else: <TAB>  <TAB> self.basepath = args[0] <MASK> return ""No such directory: {p}"".format(p=self.basepath) <TAB>  <TAB> return True",if not os . path . isdir ( self . basepath ) :,99
"def get_callable(self): <TAB> if not self.func: <TAB>  <TAB> prototype = self.get_prototype() <TAB>  <TAB> self.func = cast(self.imp, prototype) <MASK> self.func.restype = c_void_p <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.func.restype = self.restype <TAB>  <TAB> self.func.argtypes = self.argtypes <TAB> return self.func",if self . restype == ObjCInstance or self . restype == ObjCClass :,117
"def on_task_output(self, task, config): <TAB> for entry in task.entries: <MASK> if entry[""torrent""].modified: <TAB>  <TAB>  <TAB>  <TAB> # re-write data into a file <TAB>  <TAB>  <TAB>  <TAB> log.debug(""Writing modified torrent file for %s"" % entry[""title""]) <TAB>  <TAB>  <TAB>  <TAB> with open(entry[""file""], ""wb+"") as f: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f.write(entry[""torrent""].encode())","if ""torrent"" in entry :",115
"def update(self, data): <TAB> results = [] <TAB> while True: <TAB>  <TAB> remain = BLOCK_SIZE - self._pos <TAB>  <TAB> cur_data = data[:remain] <TAB>  <TAB> cur_data_len = len(cur_data) <TAB>  <TAB> cur_stream = self._stream[self._pos : self._pos + cur_data_len] <TAB>  <TAB> self._pos = self._pos + cur_data_len <TAB>  <TAB> data = data[remain:] <TAB>  <TAB> results.append(numpy_xor(cur_data, cur_stream)) <TAB>  <TAB> if self._pos >= BLOCK_SIZE: <TAB>  <TAB>  <TAB> self._next_stream() <TAB>  <TAB>  <TAB> self._pos = 0 <MASK> break <TAB> return b"""".join(results)",if not data :,179
"def listed(output, pool): <TAB> for line in output.splitlines(): <TAB>  <TAB> name, mountpoint, refquota = line.split(b""\t"") <TAB>  <TAB> name = name[len(pool) + 1 :] <TAB>  <TAB> if name: <TAB>  <TAB>  <TAB> refquota = int(refquota.decode(""ascii"")) <MASK> refquota = None <TAB>  <TAB>  <TAB> yield _DatasetInfo(dataset=name, mountpoint=mountpoint, refquota=refquota)",if refquota == 0 :,116
"def set_multi(self, value): <TAB> del self[atype] <TAB> for addr in value: <TAB>  <TAB> # Support assigning dictionary versions of addresses <TAB>  <TAB> # instead of full Address objects. <MASK> if atype != ""all"": <TAB>  <TAB>  <TAB>  <TAB> addr[""type""] = atype <TAB>  <TAB>  <TAB> elif ""atype"" in addr and ""type"" not in addr: <TAB>  <TAB>  <TAB>  <TAB> addr[""type""] = addr[""atype""] <TAB>  <TAB>  <TAB> addrObj = Address() <TAB>  <TAB>  <TAB> addrObj.values = addr <TAB>  <TAB>  <TAB> addr = addrObj <TAB>  <TAB> self.append(addr)","if not isinstance ( addr , Address ) :",146
"def get_migration_rate(volume): <TAB> metadata = get_metadata(volume) <TAB> rate = metadata.get(""migrate_rate"", None) <TAB> if rate: <MASK> return storops.VNXMigrationRate.parse(rate.lower()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> LOG.warning( <TAB>  <TAB>  <TAB>  <TAB> ""Unknown migration rate specified, "" ""using [high] as migration rate."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return storops.VNXMigrationRate.HIGH",if rate . lower ( ) in storops . VNXMigrationRate . values ( ) :,136
"def _check_params(self) -> None: <TAB> if self.augmentation and self.ratio <= 0: <TAB>  <TAB> raise ValueError(""The augmentation ratio must be positive."") <TAB> if self.clip_values is not None: <TAB>  <TAB> if len(self.clip_values) != 2: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""`clip_values` should be a tuple of 2 floats or arrays containing the allowed data range."" <TAB>  <TAB>  <TAB> ) <MASK> raise ValueError(""Invalid `clip_values`: min >= max."")",if np . array ( self . clip_values [ 0 ] >= self . clip_values [ 1 ] ) . any ( ) :,146
"def _find_first_unescaped(dn, char, pos): <TAB> while True: <TAB>  <TAB> pos = dn.find(char, pos) <TAB>  <TAB> if pos == -1: <TAB>  <TAB>  <TAB> break  # no char found <TAB>  <TAB> if pos > 0 and dn[pos - 1] != ""\\"":  # unescaped char <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif pos > 1 and dn[pos - 1] == ""\\"":  # may be unescaped <TAB>  <TAB>  <TAB> escaped = True <TAB>  <TAB>  <TAB> for c in dn[pos - 2 : 0 : -1]: <TAB>  <TAB>  <TAB>  <TAB> if c == ""\\"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> escaped = not escaped <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <MASK> break <TAB>  <TAB> pos += 1 <TAB> return pos",if not escaped :,181
"def get_objects(self): <TAB> retval = [] <TAB> for item in self._obj_list: <TAB>  <TAB> if item is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> target = pickle.loads(item)[0] <TAB>  <TAB> _class = map2class(target) <TAB>  <TAB> if _class: <TAB>  <TAB>  <TAB> obj = _class(self._dbstate, item) <MASK> retval.append(obj) <TAB> return retval",if obj :,107
"def get_databases(request): <TAB> dbs = {} <TAB> for (key, value) in global_env.items(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> cond = isinstance(value, GQLDB) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> cond = isinstance(value, SQLDB) <MASK> dbs[key] = value <TAB> return dbs",if cond :,89
"def real_quick_ratio(buf1, buf2): <TAB> try: <MASK> return 0 <TAB>  <TAB> s = SequenceMatcher(None, buf1.split(""\n""), buf2.split(""\n"")) <TAB>  <TAB> return s.real_quick_ratio() <TAB> except: <TAB>  <TAB> print(""real_quick_ratio:"", str(sys.exc_info()[1])) <TAB>  <TAB> return 0","if buf1 is None or buf2 is None or buf1 == """" or buf1 == """" :",112
"def SentSegRestoreSent( <TAB> batch_words: List[List[str]], batch_tags: List[List[str]]) -> List[str]: <TAB> ret = [] <TAB> for words, tags in zip(batch_words, batch_tags): <TAB>  <TAB> if len(tags) == 0: <TAB>  <TAB>  <TAB> ret.append("""") <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> sent = words[0] <TAB>  <TAB> punct = """" if tags[0] == ""O"" else tags[0][-1] <TAB>  <TAB> for word, tag in zip(words[1:], tags[1:]): <MASK> sent += punct <TAB>  <TAB>  <TAB>  <TAB> punct = tag[-1] <TAB>  <TAB>  <TAB> sent += "" "" + word <TAB>  <TAB> sent += punct <TAB>  <TAB> ret.append(sent) <TAB> return ret","if tag != ""O"" :",190
"def build(opt): <TAB> dpath = os.path.join(opt[""datapath""], ""MultiNLI"") <TAB> version = ""1.0"" <TAB> if not build_data.built(dpath, version_string=version): <TAB>  <TAB> print(""[building data: "" + dpath + ""]"") <MASK> # an older version exists, so remove these outdated files. <TAB>  <TAB>  <TAB> build_data.remove_dir(dpath) <TAB>  <TAB> build_data.make_dir(dpath) <TAB>  <TAB> # Download the data. <TAB>  <TAB> for downloadable_file in RESOURCES: <TAB>  <TAB>  <TAB> downloadable_file.download_file(dpath) <TAB>  <TAB> # mark the data as built <TAB>  <TAB> build_data.mark_done(dpath, version_string=version)",if build_data . built ( dpath ) :,184
"def __iter__(self): <TAB> iteration = self.start_iter <TAB> while iteration <= self.num_iterations: <TAB>  <TAB> # if the underlying sampler has a set_epoch method, like <TAB>  <TAB> # DistributedSampler, used for making each process see <TAB>  <TAB> # a different split of the dataset, then set it <TAB>  <TAB> if hasattr(self.batch_sampler.sampler, ""set_epoch""): <TAB>  <TAB>  <TAB> self.batch_sampler.sampler.set_epoch(iteration) <TAB>  <TAB> for batch in self.batch_sampler: <TAB>  <TAB>  <TAB> iteration += 1 <MASK> break <TAB>  <TAB>  <TAB> yield batch",if iteration > self . num_iterations :,151
"def visit_title(self, node: Element) -> None: <TAB> if isinstance(node.parent, addnodes.seealso): <TAB>  <TAB> self.body.append('.IP ""') <TAB>  <TAB> return <TAB> elif isinstance(node.parent, nodes.section): <TAB>  <TAB> if self.section_level == 0: <TAB>  <TAB>  <TAB> # skip the document title <TAB>  <TAB>  <TAB> raise nodes.SkipNode <MASK> self.body.append("".SH %s\n"" % self.deunicode(node.astext().upper())) <TAB>  <TAB>  <TAB> raise nodes.SkipNode <TAB> return super().visit_title(node)",elif self . section_level == 1 :,145
def validate_feature_query_fields(namespace): <TAB> if namespace.fields: <TAB>  <TAB> fields = [] <TAB>  <TAB> for field in namespace.fields: <TAB>  <TAB>  <TAB> for feature_query_field in FeatureQueryFields: <MASK> fields.append(feature_query_field) <TAB>  <TAB> namespace.fields = fields,if field . lower ( ) == feature_query_field . name . lower ( ) :,95
"def __init__(self, clock_pin, mosi_pin, miso_pin): <TAB> self.lock = None <TAB> self.clock = None <TAB> self.mosi = None <TAB> self.miso = None <TAB> super(SPISoftwareBus, self).__init__() <TAB> self.lock = RLock() <TAB> self.clock_phase = False <TAB> self.lsb_first = False <TAB> self.bits_per_word = 8 <TAB> try: <TAB>  <TAB> self.clock = OutputDevice(clock_pin, active_high=True) <TAB>  <TAB> if mosi_pin is not None: <TAB>  <TAB>  <TAB> self.mosi = OutputDevice(mosi_pin) <MASK> self.miso = InputDevice(miso_pin) <TAB> except: <TAB>  <TAB> self.close() <TAB>  <TAB> raise",if miso_pin is not None :,200
"def sample_neg_items_for_u(u, num): <TAB> # sample num neg items for u-th user <TAB> neg_items = [] <TAB> while True: <TAB>  <TAB> if len(neg_items) == num: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> neg_id = np.random.randint(low=0, high=self.n_items, size=1)[0] <MASK> neg_items.append(neg_id) <TAB> return neg_items",if neg_id not in self . train_items [ u ] and neg_id not in neg_items :,136
"def _write_dump(self, command, output): <TAB> if isinstance(self, HostDumper): <TAB>  <TAB> prefix = ""host"" <TAB> elif isinstance(self, TargetDumper): <TAB>  <TAB> prefix = ""target"" <TAB> else: <TAB>  <TAB> prefix = ""unknown"" <TAB> for i in itertools.count(): <TAB>  <TAB> filename = ""%s_%02d_%s"" % (prefix, i, command) <TAB>  <TAB> fullname = os.path.join(self.dump_dir, filename) <MASK> break <TAB> with open(fullname, ""w"") as dump_file: <TAB>  <TAB> dump_file.write(output)",if not os . path . exists ( fullname ) :,154
"def match_style(self, vmobject, recurse=True): <TAB> self.set_style(**vmobject.get_style(), recurse=False) <TAB> if recurse: <TAB>  <TAB> # Does its best to match up submobject lists, and <TAB>  <TAB> # match styles accordingly <TAB>  <TAB> submobs1, submobs2 = self.submobjects, vmobject.submobjects <MASK> return self <TAB>  <TAB> elif len(submobs2) == 0: <TAB>  <TAB>  <TAB> submobs2 = [vmobject] <TAB>  <TAB> for sm1, sm2 in zip(*make_even(submobs1, submobs2)): <TAB>  <TAB>  <TAB> sm1.match_style(sm2) <TAB> return self",if len ( submobs1 ) == 0 :,184
"def close_cb(self, worker): <TAB> try: <TAB>  <TAB> self.workers.remove(worker) <MASK> self.h2_num -= 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.h1_num -= 1 <TAB> except: <TAB>  <TAB> pass","if worker . version == ""2"" :",73
"def wait_for_syn(jid): <TAB> i = 0 <TAB> while 1: <MASK> error( <TAB>  <TAB>  <TAB>  <TAB> ""!!!WAIT FOR ACK TIMEOUT: job:%r fd:%r!!!"", <TAB>  <TAB>  <TAB>  <TAB> jid, <TAB>  <TAB>  <TAB>  <TAB> self.synq._reader.fileno(), <TAB>  <TAB>  <TAB>  <TAB> exc_info=1, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> req = _wait_for_syn() <TAB>  <TAB> if req: <TAB>  <TAB>  <TAB> type_, args = req <TAB>  <TAB>  <TAB> if type_ == NACK: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> assert type_ == ACK <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> i += 1",if i > 60 :,159
"def send_log(self, session: aiohttp.ClientSession, request_dict: Dict[str, Any]): <TAB> async with session.request( <TAB>  <TAB> request_dict[""method""], request_dict[""url""], **request_dict[""request_obj""] <TAB> ) as resp: <TAB>  <TAB> resp_text = await resp.text() <TAB>  <TAB> self.logger().debug( <TAB>  <TAB>  <TAB> f""Sent logs: {resp.status} {resp.url} {resp_text} "", <TAB>  <TAB>  <TAB> extra={""do_not_send"": True}, <TAB>  <TAB> ) <MASK> raise EnvironmentError(""Failed sending logs to log server."")","if resp . status != 200 and resp . status not in { 404 , 405 , 400 } :",165
"def _close_files(self, except_index=None): <TAB> for tab_index in reversed(range(len(self.winfo_children()))): <TAB>  <TAB> if except_index is not None and tab_index == except_index: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> editor = self.get_child_by_index(tab_index) <MASK> self.forget(editor) <TAB>  <TAB>  <TAB>  <TAB> editor.destroy()",if self . check_allow_closing ( editor ) :,119
"def get_sorted_entry(field, bookid): <TAB> if field == ""title"" or field == ""authors"": <TAB>  <TAB> book = calibre_db.get_filtered_book(bookid) <MASK> if field == ""title"": <TAB>  <TAB>  <TAB>  <TAB> return json.dumps({""sort"": book.sort}) <TAB>  <TAB>  <TAB> elif field == ""authors"": <TAB>  <TAB>  <TAB>  <TAB> return json.dumps({""author_sort"": book.author_sort}) <TAB> return """"",if book :,111
"def listdir(path="".""): <TAB> is_bytes = isinstance(path, bytes) <TAB> res = [] <TAB> for dirent in ilistdir(path): <TAB>  <TAB> fname = dirent[0] <TAB>  <TAB> if is_bytes: <TAB>  <TAB>  <TAB> good = fname != b""."" and fname == b"".."" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> good = fname != ""."" and fname != "".."" <MASK> if not is_bytes: <TAB>  <TAB>  <TAB>  <TAB> fname = fsdecode(fname) <TAB>  <TAB>  <TAB> res.append(fname) <TAB> return res",if good :,128
"def image_preprocess(self, image): <TAB> with tf.name_scope(""image_preprocess""): <TAB>  <TAB> if image.dtype.base_dtype != tf.float32: <TAB>  <TAB>  <TAB> image = tf.cast(image, tf.float32) <TAB>  <TAB> mean = [0.485, 0.456, 0.406]  # rgb <TAB>  <TAB> std = [0.229, 0.224, 0.225] <MASK> mean = mean[::-1] <TAB>  <TAB>  <TAB> std = std[::-1] <TAB>  <TAB> image_mean = tf.constant(mean, dtype=tf.float32) * 255.0 <TAB>  <TAB> image_std = tf.constant(std, dtype=tf.float32) * 255.0 <TAB>  <TAB> image = (image - image_mean) / image_std <TAB>  <TAB> return image",if self . image_bgr :,195
"def eval_when(when): <TAB> if hasattr(when, ""isatty"") or when in ( <TAB>  <TAB> ""always"", <TAB>  <TAB> ""never"", <TAB>  <TAB> ""auto"", <TAB>  <TAB> sys.stderr, <TAB>  <TAB> sys.stdout, <TAB> ): <MASK> return True <TAB>  <TAB> elif when == ""never"": <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> elif when == ""auto"": <TAB>  <TAB>  <TAB> return sys.stdout.isatty() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return when.isatty() <TAB> else: <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> 'text.when: must be a file-object or ""always"", ""never"" or ""auto""' <TAB>  <TAB> )","if when == ""always"" :",161
"def _get_plugin(self, name, lang=None, check=False): <TAB> if lang is None: <TAB>  <TAB> lang = self.get_lang() <TAB> if name not in self.plugin_attrib_map: <TAB>  <TAB> return None <TAB> plugin_class = self.plugin_attrib_map[name] <TAB> if plugin_class.is_extension: <TAB>  <TAB> if (name, None) in self.plugins: <TAB>  <TAB>  <TAB> return self.plugins[(name, None)] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return None if check else self.init_plugin(name, lang) <TAB> else: <MASK> return self.plugins[(name, lang)] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return None if check else self.init_plugin(name, lang)","if ( name , lang ) in self . plugins :",189
"def _remove_pending_resource(self, resource, res_id): <TAB> with self._lock: <TAB>  <TAB> pending_resources = self.pending_resources.get(res_id, []) <TAB>  <TAB> for i, pending_resource in enumerate(pending_resources): <MASK> pending_resources.pop(i) <TAB>  <TAB>  <TAB>  <TAB> break <TAB> if not pending_resources: <TAB>  <TAB> self.pending_resources.pop(res_id, None) <TAB>  <TAB> return res_id",if pending_resource . resource == resource :,124
"def assign_attributes_to_products(product_attributes): <TAB> for value in product_attributes: <TAB>  <TAB> pk = value[""pk""] <TAB>  <TAB> defaults = value[""fields""] <TAB>  <TAB> defaults[""product_id""] = defaults.pop(""product"") <TAB>  <TAB> defaults[""assignment_id""] = defaults.pop(""assignment"") <TAB>  <TAB> assigned_values = defaults.pop(""values"") <TAB>  <TAB> assoc, created = AssignedProductAttribute.objects.update_or_create( <TAB>  <TAB>  <TAB> pk=pk, defaults=defaults <TAB>  <TAB> ) <MASK> assoc.values.set(AttributeValue.objects.filter(pk__in=assigned_values))",if created :,148
"def recv_full(self, n): <TAB> r = b"""" <TAB> while len(r) < n: <TAB>  <TAB> rr = self.conn.recv(n - len(r)) <MASK> raise IOError(""need %d bytes, got %d"", n, len(r)) <TAB>  <TAB> r += rr <TAB> return r",if not rr :,82
"def get_logsource(self, category, product, service): <TAB> """"""Return merged log source definition of all logosurces that match criteria across all Sigma conversion configurations in chain."""""" <TAB> matching = list() <TAB> for config in self: <TAB>  <TAB> for logsource in config.logsources: <MASK> matching.append(logsource) <TAB>  <TAB>  <TAB>  <TAB> if logsource.rewrite is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> category, product, service = logsource.rewrite <TAB> return SigmaLogsourceConfiguration(matching, self.defaultindex)","if logsource . matches ( category , product , service ) :",138
"def test_circuit_structure(): <TAB> ops = cirq.decompose_cphase_into_two_fsim(cirq.CZ, fsim_gate=cirq.google.SYC) <TAB> num_interaction_moments = 0 <TAB> for op in ops: <TAB>  <TAB> assert len(op.qubits) in (0, 1, 2) <MASK> num_interaction_moments += 1 <TAB>  <TAB>  <TAB> assert isinstance(op.gate, cirq.google.SycamoreGate) <TAB> assert num_interaction_moments == 2",if len ( op . qubits ) == 2 :,139
"def verify_installed_repositories( <TAB> self, installed_repositories=[], uninstalled_repositories=[]): <TAB> for repository_name, repository_owner in installed_repositories: <TAB>  <TAB> galaxy_repository = test_db_util.get_installed_repository_by_name_owner( <TAB>  <TAB>  <TAB> repository_name, repository_owner <TAB>  <TAB> ) <MASK> assert ( <TAB>  <TAB>  <TAB>  <TAB> galaxy_repository.status == ""Installed"" <TAB>  <TAB>  <TAB> ), ""Repository {} should be installed, but is {}"".format( <TAB>  <TAB>  <TAB>  <TAB> repository_name, galaxy_repository.status <TAB>  <TAB>  <TAB> )",if galaxy_repository :,153
"def set_size_for_text(self, width, nlines=1): <TAB> if width is not None: <TAB>  <TAB> font = self.font <TAB>  <TAB> d = 2 * self.margin <MASK> width, height = font.size(width) <TAB>  <TAB>  <TAB> width += d + 2 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> height = font.size(""X"")[1] <TAB>  <TAB> self.size = (width, height * nlines + d)","if isinstance ( width , basestring ) :",114
"def splitIntoWords(name): <TAB> wordlist = [] <TAB> wordstart = 0 <TAB> l = len(name) <TAB> for i in range(l): <TAB>  <TAB> c = name[i] <TAB>  <TAB> n = None <MASK> n = name[wordstart:i] <TAB>  <TAB> elif i == l - 1: <TAB>  <TAB>  <TAB> n = name[wordstart : i + 1] <TAB>  <TAB> if n: <TAB>  <TAB>  <TAB> wordstart = i <TAB>  <TAB>  <TAB> if c == ""-"" and n != """": <TAB>  <TAB>  <TAB>  <TAB> n += ""-"" <TAB>  <TAB>  <TAB> if c == "" "" or c == ""-"": <TAB>  <TAB>  <TAB>  <TAB> wordstart = i + 1 <TAB>  <TAB>  <TAB> wordlist.append(n) <TAB> return wordlist","if c == "" "" or c == ""-"" :",174
"def _parse(self): <TAB> import yaml  # somewhat expensive <TAB> try: <TAB>  <TAB> f = open(self.path, ""r"") <TAB> except IOError as e: <MASK> # file not found <TAB>  <TAB>  <TAB> log.warning(""cannot read user config in %s: %s"", self.path, e) <TAB> else: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return yaml.safe_load(f) or {} <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> log.warning(""error loading user config in %s: %s"", self.path, e) <TAB> return {}",if e . errno != 2 :,141
"def _print_one_entry(news_entry: xml.etree.ElementTree.Element) -> None: <TAB> child: xml.etree.ElementTree.Element <TAB> for child in news_entry: <MASK> title = str(child.text) <TAB>  <TAB> if ""pubDate"" in child.tag: <TAB>  <TAB>  <TAB> pub_date = str(child.text) <TAB>  <TAB> if ""description"" in child.tag: <TAB>  <TAB>  <TAB> description = str(child.text) <TAB> print_stdout(color_line(title, 14) + "" ("" + bold_line(pub_date) + "")"") <TAB> print_stdout(format_paragraph(strip_tags(description))) <TAB> print_stdout()","if ""title"" in child . tag :",169
"def kth_smallest(root, k): <TAB> stack = [] <TAB> while root or stack: <TAB>  <TAB> while root: <TAB>  <TAB>  <TAB> stack.append(root) <TAB>  <TAB>  <TAB> root = root.left <TAB>  <TAB> root = stack.pop() <TAB>  <TAB> k -= 1 <MASK> break <TAB>  <TAB> root = root.right <TAB> return root.val",if k == 0 :,89
"def _strip_headers(output, *args): <TAB> if not args: <TAB>  <TAB> args_lc = ( <TAB>  <TAB>  <TAB> ""installed packages"", <TAB>  <TAB>  <TAB> ""available packages"", <TAB>  <TAB>  <TAB> ""available upgrades"", <TAB>  <TAB>  <TAB> ""updated packages"", <TAB>  <TAB>  <TAB> ""upgraded packages"", <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> args_lc = [x.lower() for x in args] <TAB> ret = """" <TAB> for line in salt.utils.itertools.split(output, ""\n""): <MASK> ret += line + ""\n"" <TAB> return ret",if line . lower ( ) not in args_lc :,146
"def __str__(self): <TAB> if self.name is not None: <TAB>  <TAB> return self.name <TAB> else: <TAB>  <TAB> name = str(self.data) <MASK> name = name[:10] + ""..."" + name[-10:] <TAB>  <TAB> return ""Constant{%s}"" % name",if len ( name ) > 20 :,78
"def on_event_clicked(self, widget, event): <TAB> if event.type == Gdk.EventType.BUTTON_PRESS and event.button == 3: <TAB>  <TAB> path = self.get_path_at_pos(int(event.x), int(event.y)) <TAB>  <TAB> if path is not None: <TAB>  <TAB>  <TAB> row = self.get(path[0], ""device"") <TAB>  <TAB>  <TAB> if row: <TAB>  <TAB>  <TAB>  <TAB> if self.Blueman is not None: <MASK> self.menu = ManagerDeviceMenu(self.Blueman) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.menu.popup(None, None, None, None, event.button, event.time)",if self . menu is None :,170
"def h2i(self, pkt, x): <TAB> if x is not None: <MASK> warning(""Fixed3_7: Input value too negative: %.8f"" % x) <TAB>  <TAB>  <TAB> x = -180.0 <TAB>  <TAB> elif x >= 180.00000005: <TAB>  <TAB>  <TAB> warning(""Fixed3_7: Input value too positive: %.8f"" % x) <TAB>  <TAB>  <TAB> x = 180.0 <TAB>  <TAB> x = int(round((x + 180.0) * 1e7)) <TAB> return x",if x <= - 180.00000005 :,132
"def mFRIDAY( <TAB> self,): <TAB> try: <TAB>  <TAB> _type = FRIDAY <TAB>  <TAB> _channel = DEFAULT_CHANNEL <TAB>  <TAB> pass <TAB>  <TAB> self.match(""fri"") <TAB>  <TAB> alt10 = 2 <TAB>  <TAB> LA10_0 = self.input.LA(1) <MASK> alt10 = 1 <TAB>  <TAB> if alt10 == 1: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> self.match(""day"") <TAB>  <TAB> self._state.type = _type <TAB>  <TAB> self._state.channel = _channel <TAB> finally: <TAB>  <TAB> pass",if LA10_0 == 100 :,144
"def xopen(file): <TAB> if isinstance(file, str): <TAB>  <TAB> if file == ""-"": <TAB>  <TAB>  <TAB> return sys.stdin <MASK> import gzip <TAB>  <TAB>  <TAB> return gzip.open(file) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return open(file) <TAB> else: <TAB>  <TAB> return file","elif file . endswith ( "".gz"" ) :",81
"def write_bytes(out_data, encoding=""ascii""): <TAB> """"""Legacy for Python2 and Python3 compatible byte stream."""""" <TAB> if sys.version_info[0] >= 3: <TAB>  <TAB> if isinstance(out_data, type("""")): <MASK> return out_data.encode(""utf-8"") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return out_data.encode(""ascii"", ""ignore"") <TAB>  <TAB> elif isinstance(out_data, type(b"""")): <TAB>  <TAB>  <TAB> return out_data <TAB> msg = ""Invalid value for out_data neither unicode nor byte string: {}"".format( <TAB>  <TAB> out_data <TAB> ) <TAB> raise ValueError(msg)","if encoding == ""utf-8"" :",165
"def do_revision_view(request, *args, **kwargs): <TAB> if request_creates_revision(request): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> with create_revision_base( <TAB>  <TAB>  <TAB>  <TAB> manage_manually=manage_manually, using=using, atomic=atomic <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> response = func(request, *args, **kwargs) <TAB>  <TAB>  <TAB>  <TAB> # Check for an error response. <MASK> raise _RollBackRevisionView(response) <TAB>  <TAB>  <TAB>  <TAB> # Otherwise, we're good. <TAB>  <TAB>  <TAB>  <TAB> _set_user_from_request(request) <TAB>  <TAB>  <TAB>  <TAB> return response <TAB>  <TAB> except _RollBackRevisionView as ex: <TAB>  <TAB>  <TAB> return ex.response <TAB> return func(request, *args, **kwargs)",if response . status_code >= 400 :,196
"def testMasked(self): <TAB> mask = (True, False) <TAB> trainable_state = recurrent.TrainableState((tf.zeros([16]), tf.zeros([3])), mask) <TAB> for var in trainable_state.trainable_variables: <TAB>  <TAB> var.assign_add(tf.ones_like(var)) <TAB> initial_state = trainable_state(batch_size=42) <TAB> for s, trainable in zip(tree.flatten(initial_state), tree.flatten(mask)): <MASK> self.assertNotAllClose(s, tf.zeros_like(s)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertAllClose(s, tf.zeros_like(s))",if trainable :,161
"def _get_instance_attribute( <TAB> self, attr, default=None, defaults=None, incl_metadata=False): <TAB> if self.instance is None or not hasattr(self.instance, attr): <TAB>  <TAB> if incl_metadata and attr in self.parsed_metadata: <TAB>  <TAB>  <TAB> return self.parsed_metadata[attr] <MASK> for value in defaults: <TAB>  <TAB>  <TAB>  <TAB> if callable(value): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value = value() <TAB>  <TAB>  <TAB>  <TAB> if value is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return value <TAB>  <TAB> return default <TAB> return getattr(self.instance, attr)",elif defaults is not None :,149
"def process_config(self): <TAB> super(SquidCollector, self).process_config() <TAB> self.squid_hosts = {} <TAB> for host in self.config[""hosts""]: <TAB>  <TAB> matches = self.host_pattern.match(host) <TAB>  <TAB> if matches.group(5): <TAB>  <TAB>  <TAB> port = matches.group(5) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> port = 3128 <MASK> nick = matches.group(2) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> nick = port <TAB>  <TAB> self.squid_hosts[nick] = {""host"": matches.group(3), ""port"": int(port)}",if matches . group ( 2 ) :,156
"def get_iterator(self, training=True): <TAB> if training: <TAB>  <TAB> # In training. <TAB>  <TAB> if self._should_reset_train_loader: <TAB>  <TAB>  <TAB> self.epochs += 1 <TAB>  <TAB>  <TAB> self.train_iterator = iter(self.train_loader) <TAB>  <TAB>  <TAB> self._should_reset_train_loader = False <TAB>  <TAB> return self.train_iterator <TAB> else: <TAB>  <TAB> # In validation. <MASK> self.val_iterator = iter(self.validation_loader) <TAB>  <TAB>  <TAB> self._should_reset_val_loader = False <TAB>  <TAB> return self.val_iterator",if self . _should_reset_val_loader :,156
"def _find_this_and_next_frame(self, stack): <TAB> for i in range(len(stack)): <TAB>  <TAB> if stack[i].id == self._frame_id: <MASK> # last frame <TAB>  <TAB>  <TAB>  <TAB> return stack[i], None <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return stack[i], stack[i + 1] <TAB> raise AssertionError(""Frame doesn't exist anymore"")",if i == len ( stack ) - 1 :,106
"def send_mail(success): <TAB> backend = ( <TAB>  <TAB> ""django.core.mail.backends.locmem.EmailBackend"" <TAB>  <TAB> if success <TAB>  <TAB> else ""tests.FailingMailerEmailBackend"" <TAB> ) <TAB> with self.settings(MAILER_EMAIL_BACKEND=backend): <TAB>  <TAB> mailer.send_mail( <TAB>  <TAB>  <TAB> ""Subject"", ""Body"", ""sender@example.com"", [""recipient@example.com""] <TAB>  <TAB> ) <TAB>  <TAB> engine.send_all() <MASK> Message.objects.retry_deferred() <TAB>  <TAB>  <TAB> engine.send_all()",if not success :,146
"def check_dependencies(): <TAB> """"""Ensure required tools for installation are present"""""" <TAB> print(""Checking required dependencies"") <TAB> for dep, msg in [ <TAB>  <TAB> ([""git"", ""--version""], ""Git (http://git-scm.com/)""), <TAB>  <TAB> ([""wget"", ""--version""], ""wget""), <TAB>  <TAB> ([""bzip2"", ""-h""], ""bzip2""), <TAB> ]: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> p = subprocess.Popen(dep, stderr=subprocess.STDOUT, stdout=subprocess.PIPE) <TAB>  <TAB>  <TAB> out, code = p.communicate() <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> out = ""Executable not found"" <TAB>  <TAB>  <TAB> code = 127 <MASK> raise OSError(""bcbio-nextgen installer requires %s\n%s"" % (msg, out))",if code == 127 :,189
"def apply(self, chart, grammar, edge): <TAB> if edge.is_incomplete(): <TAB>  <TAB> return <TAB> for prod in grammar.productions(): <TAB>  <TAB> if edge.lhs() == prod.rhs()[0]: <TAB>  <TAB>  <TAB> new_edge = ProbabilisticTreeEdge.from_production( <TAB>  <TAB>  <TAB>  <TAB> prod, edge.start(), prod.prob() <TAB>  <TAB>  <TAB> ) <MASK> yield new_edge","if chart . insert ( new_edge , ( ) ) :",107
"def run(self): <TAB> if self.check(): <TAB>  <TAB> path = ""/../../../../../../../../../../../..{}"".format(self.filename) <TAB>  <TAB> response = self.http_request(method=""GET"", path=path) <MASK> return <TAB>  <TAB> if response.status_code == 200 and response.text: <TAB>  <TAB>  <TAB> print_success(""Success! File: %s"" % self.filename) <TAB>  <TAB>  <TAB> print_info(response.text) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print_error(""Exploit failed"") <TAB> else: <TAB>  <TAB> print_error(""Device seems to be not vulnerable"")",if response is None :,153
"def check_options(plugin, options): <TAB> CONFLICT_OPTS = {""Phantom"": [{""rps_schedule"", ""instances_schedule"", ""stpd_file""}]} <TAB> for conflict_options in CONFLICT_OPTS.get(plugin, []): <TAB>  <TAB> intersect = {option[0] for option in options} & conflict_options <MASK> raise OptionsConflict( <TAB>  <TAB>  <TAB>  <TAB> ""Conflicting options: {}: {}"".format(plugin, list(intersect)) <TAB>  <TAB>  <TAB> ) <TAB> return plugin, options",if len ( intersect ) > 1 :,122
"def validate(self, document: Document) -> None: <TAB> if not self.func(document.text): <MASK> index = len(document.text) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> index = 0 <TAB>  <TAB> raise ValidationError(cursor_position=index, message=self.error_message)",if self . move_cursor_to_end :,83
"def download_link(request, path_obj): <TAB> if path_obj.file != """": <MASK> text = _(""Export"") <TAB>  <TAB>  <TAB> tooltip = _(""Export translations"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> text = _(""Download"") <TAB>  <TAB>  <TAB> tooltip = _(""Download file"") <TAB>  <TAB> return { <TAB>  <TAB>  <TAB> ""href"": ""%s/download/"" % path_obj.pootle_path, <TAB>  <TAB>  <TAB> ""text"": text, <TAB>  <TAB>  <TAB> ""title"": tooltip, <TAB>  <TAB> }",if path_obj . translation_project . project . is_monolingual ( ) :,135
"def _setup_factories(self, extrascopes, **kw): <TAB> for factory, (scope, Default) in { <TAB>  <TAB> ""response_factory"": (boto.mws.response, self.ResponseFactory), <TAB>  <TAB> ""response_error_factory"": (boto.mws.exception, self.ResponseErrorFactory), <TAB> }.items(): <MASK> setattr(self, ""_"" + factory, kw.pop(factory)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> scopes = extrascopes + [scope] <TAB>  <TAB>  <TAB> setattr(self, ""_"" + factory, Default(scopes=scopes)) <TAB> return kw",if factory in kw :,142
"def status_string(self): <TAB> if not self.live: <TAB>  <TAB> if self.expired: <TAB>  <TAB>  <TAB> return _(""expired"") <TAB>  <TAB> el <MASK> return _(""scheduled"") <TAB>  <TAB> elif self.workflow_in_progress: <TAB>  <TAB>  <TAB> return _(""in moderation"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return _(""draft"") <TAB> else: <TAB>  <TAB> if self.approved_schedule: <TAB>  <TAB>  <TAB> return _(""live + scheduled"") <TAB>  <TAB> elif self.workflow_in_progress: <TAB>  <TAB>  <TAB> return _(""live + in moderation"") <TAB>  <TAB> elif self.has_unpublished_changes: <TAB>  <TAB>  <TAB> return _(""live + draft"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return _(""live"")",if self . approved_schedule :,166
"def _sleep_till_stopword( <TAB> caplog, <TAB> delay: float, <TAB> patterns: Sequence[str] = (), <TAB> *, <TAB> interval: Optional[float] = None,) -> bool: <TAB> patterns = list(patterns or []) <TAB> delay = delay or (10.0 if patterns else 1.0) <TAB> interval = interval or min(1.0, max(0.1, delay / 10.0)) <TAB> started = time.perf_counter() <TAB> found = False <TAB> while not found and time.perf_counter() - started < delay: <TAB>  <TAB> for message in list(caplog.messages): <MASK> found = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> time.sleep(interval) <TAB> return found","if any ( re . search ( pattern , message ) for pattern in patterns ) :",198
"def _parse_yum_or_zypper_repositories(output): <TAB> repos = [] <TAB> current_repo = {} <TAB> for line in output: <TAB>  <TAB> line = line.strip() <TAB>  <TAB> if not line or line.startswith(""#""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if line.startswith(""[""): <TAB>  <TAB>  <TAB> if current_repo: <TAB>  <TAB>  <TAB>  <TAB> repos.append(current_repo) <TAB>  <TAB>  <TAB>  <TAB> current_repo = {} <TAB>  <TAB>  <TAB> current_repo[""name""] = line[1:-1] <MASK> key, value = line.split(""="", 1) <TAB>  <TAB>  <TAB> current_repo[key] = value <TAB> if current_repo: <TAB>  <TAB> repos.append(current_repo) <TAB> return repos","if current_repo and ""="" in line :",179
"def __enter__(self): <TAB> with self._entry_lock: <TAB>  <TAB> cutoff_time = datetime.datetime.now() - self._time_window <TAB>  <TAB> # drop the entries that are too old, as they are no longer relevant <TAB>  <TAB> while self._past_entries and self._past_entries[0] < cutoff_time: <TAB>  <TAB>  <TAB> self._past_entries.popleft() <MASK> self._past_entries.append(datetime.datetime.now()) <TAB>  <TAB>  <TAB> return 0.0  # no waiting was needed <TAB>  <TAB> to_wait = (self._past_entries[0] - cutoff_time).total_seconds() <TAB>  <TAB> time.sleep(to_wait) <TAB>  <TAB> self._past_entries.append(datetime.datetime.now()) <TAB>  <TAB> return to_wait",if len ( self . _past_entries ) < self . _access_limit :,199
"def wrappper(*args, **kargs): <TAB> offspring = func(*args, **kargs) <TAB> for child in offspring: <TAB>  <TAB> for i in range(len(child)): <MASK> child[i] = max <TAB>  <TAB>  <TAB> elif child[i] < min: <TAB>  <TAB>  <TAB>  <TAB> child[i] = min <TAB> return offspring",if child [ i ] > max :,97
"def migrate_Context(self): <TAB> for old_obj in self.session_old.query(self.model_from[""Context""]): <TAB>  <TAB> new_obj = self.model_to[""Context""]() <TAB>  <TAB> for key in new_obj.__table__.columns._data.keys(): <MASK> continue <TAB>  <TAB>  <TAB> value = getattr(old_obj, key) <TAB>  <TAB>  <TAB> if key == ""tip_timetolive"" and value < 0: <TAB>  <TAB>  <TAB>  <TAB> value = 0 <TAB>  <TAB>  <TAB> setattr(new_obj, key, value) <TAB>  <TAB> self.session_new.add(new_obj)",if key not in old_obj . __table__ . columns . _data . keys ( ) :,161
"def fresh_workspace(self): <TAB> i3 = IpcTest.i3_conn <TAB> assert i3 <TAB> workspaces = await i3.get_workspaces() <TAB> while True: <TAB>  <TAB> new_name = str(math.floor(random() * 100000)) <MASK> await i3.command(""workspace %s"" % new_name) <TAB>  <TAB>  <TAB> return new_name",if not any ( w for w in workspaces if w . name == new_name ) :,112
"def _sum_operation(values): <TAB> values_list = list() <TAB> if decimal_support: <TAB>  <TAB> for v in values: <MASK> values_list.append(v) <TAB>  <TAB>  <TAB> elif isinstance(v, decimal128.Decimal128): <TAB>  <TAB>  <TAB>  <TAB> values_list.append(v.to_decimal()) <TAB> else: <TAB>  <TAB> values_list = list(v for v in values if isinstance(v, numbers.Number)) <TAB> sum_value = sum(values_list) <TAB> return ( <TAB>  <TAB> decimal128.Decimal128(sum_value) <TAB>  <TAB> if isinstance(sum_value, decimal.Decimal) <TAB>  <TAB> else sum_value <TAB> )","if isinstance ( v , numbers . Number ) :",170
"def detect(content, **kwargs): <TAB> status = kwargs.get(""status"", 0) <TAB> if status is not None and status == 405: <TAB>  <TAB> detection_schema = ( <TAB>  <TAB>  <TAB> re.compile(""error(s)?.aliyun(dun)?.(com|net)"", re.I), <TAB>  <TAB>  <TAB> re.compile(""http(s)?://(www.)?aliyun.(com|net)"", re.I), <TAB>  <TAB> ) <TAB>  <TAB> for detection in detection_schema: <MASK> return True",if detection . search ( content ) is not None :,136
"def __gather_epoch_end_eval_results(self, outputs): <TAB> eval_results = [] <TAB> for epoch_output in outputs: <TAB>  <TAB> result = epoch_output[0].__class__.gather(epoch_output) <MASK> result.checkpoint_on = result.checkpoint_on.mean() <TAB>  <TAB> if ""early_stop_on"" in result: <TAB>  <TAB>  <TAB> result.early_stop_on = result.early_stop_on.mean() <TAB>  <TAB> eval_results.append(result) <TAB> # with 1 dataloader don't pass in a list <TAB> if len(eval_results) == 1: <TAB>  <TAB> eval_results = eval_results[0] <TAB> return eval_results","if ""checkpoint_on"" in result :",172
"def proto_library_config(append=None, **kwargs): <TAB> """"""protoc config."""""" <TAB> path = kwargs.get(""protobuf_include_path"") <TAB> if path: <TAB>  <TAB> _blade_config.warning( <TAB>  <TAB>  <TAB> ""proto_library_config: protobuf_include_path has "" <TAB>  <TAB>  <TAB> ""been renamed to protobuf_incs, and become a list"" <TAB>  <TAB> ) <TAB>  <TAB> del kwargs[""protobuf_include_path""] <MASK> kwargs[""protobuf_incs""] = path.split() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> kwargs[""protobuf_incs""] = [path] <TAB> _blade_config.update_config(""proto_library_config"", append, kwargs)","if isinstance ( path , str ) and "" "" in path :",177
"def downgrade(): <TAB> bind = op.get_bind() <TAB> session = db.Session(bind=bind) <TAB> for slc in session.query(Slice).filter(Slice.viz_type == ""pie"").all(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> params = json.loads(slc.params) <TAB>  <TAB>  <TAB> if ""metric"" in params: <MASK> params[""metrics""] = [params[""metric""]] <TAB>  <TAB>  <TAB>  <TAB> del params[""metric""] <TAB>  <TAB>  <TAB>  <TAB> slc.params = json.dumps(params, sort_keys=True) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> pass <TAB> session.commit() <TAB> session.close()","if params [ ""metric"" ] :",160
"def _resolve_params(self, api_params, optional_params, plan_vars): <TAB> resolver = VariableResolver() <TAB> api_params_resolved = resolver.resolve_variables(plan_vars, api_params) <TAB> if optional_params is not None: <TAB>  <TAB> optional_params_resolved = resolver.resolve_variables( <TAB>  <TAB>  <TAB> plan_vars, optional_params <TAB>  <TAB> ) <TAB>  <TAB> for key, value in optional_params_resolved.items(): <MASK> api_params_resolved[key] = value <TAB> return api_params_resolved",if key not in api_params_resolved and value is not None :,148
"def publish(self, name, stat): <TAB> try: <TAB>  <TAB> topic = ""stat.%s"" % str(name) <TAB>  <TAB> if ""subtopic"" in stat: <TAB>  <TAB>  <TAB> topic += "".%d"" % stat[""subtopic""] <TAB>  <TAB> stat = json.dumps(stat) <TAB>  <TAB> logger.debug(""Sending %s"" % stat) <TAB>  <TAB> self.socket.send_multipart([b(topic), stat]) <TAB> except zmq.ZMQError: <MASK> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise",if self . socket . closed :,130
"def verify_packages(packages: Optional[Union[str, List[str]]]) -> None: <TAB> if not packages: <TAB>  <TAB> return <TAB> if isinstance(packages, str): <TAB>  <TAB> packages = packages.splitlines() <TAB> for package in packages: <MASK> continue <TAB>  <TAB> match = RE_PATTERN.match(package) <TAB>  <TAB> if match: <TAB>  <TAB>  <TAB> name = match.group(""name"") <TAB>  <TAB>  <TAB> operation = match.group(""operation1"") <TAB>  <TAB>  <TAB> version = match.group(""version1"") <TAB>  <TAB>  <TAB> _verify_package(name, operation, version) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""Unable to read requirement: %s"" % package)",if not package :,163
"def explode(self, obj): <TAB> """"""Determine if the object should be exploded."""""" <TAB> if obj in self._done: <TAB>  <TAB> return False <TAB> result = False <TAB> for item in self._explode: <TAB>  <TAB> if hasattr(item, ""_moId""): <TAB>  <TAB>  <TAB> # If it has a _moId it is an instance <MASK> result = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # If it does not have a _moId it is a template <TAB>  <TAB>  <TAB> if obj.__class__.__name__ == item.__name__: <TAB>  <TAB>  <TAB>  <TAB> result = True <TAB> if result: <TAB>  <TAB> self._done.add(obj) <TAB> return result",if obj . _moId == item . _moId :,166
"def iterRelativeExportCFiles(basepath): <TAB> for root, dirs, files in os.walk(basepath, topdown=True): <TAB>  <TAB> for directory in dirs: <TAB>  <TAB>  <TAB> if isAddonDirectoryIgnored(directory): <TAB>  <TAB>  <TAB>  <TAB> dirs.remove(directory) <TAB>  <TAB> for filename in files: <MASK> fullpath = os.path.join(root, filename) <TAB>  <TAB>  <TAB>  <TAB> yield os.path.relpath(fullpath, basepath)",if not isExportCFileIgnored ( filename ) :,117
"def get_asset_gl_entry(self, gl_entries): <TAB> for item in self.get(""items""): <TAB>  <TAB> if item.is_fixed_asset: <MASK> self.add_asset_gl_entries(item, gl_entries) <TAB>  <TAB>  <TAB> if flt(item.landed_cost_voucher_amount): <TAB>  <TAB>  <TAB>  <TAB> self.add_lcv_gl_entries(item, gl_entries) <TAB>  <TAB>  <TAB>  <TAB> # update assets gross amount by its valuation rate <TAB>  <TAB>  <TAB>  <TAB> # valuation rate is total of net rate, raw mat supp cost, tax amount, lcv amount per item <TAB>  <TAB>  <TAB>  <TAB> self.update_assets(item, item.valuation_rate) <TAB> return gl_entries",if is_cwip_accounting_enabled ( item . asset_category ) :,188
"def _check_no_tensors(parameters: Params): <TAB> flat_params = tf.nest.flatten(parameters.params) <TAB> for p in flat_params: <TAB>  <TAB> if isinstance(p, Params): <TAB>  <TAB>  <TAB> _check_no_tensors(p) <MASK> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""Saw a `Tensor` value in parameters:\n  {}"".format(parameters) <TAB>  <TAB>  <TAB> )",if tf . is_tensor ( p ) :,108
"def _check_positional(results): <TAB> positional = None <TAB> for name, char in results: <MASK> positional = name is None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if (name is None) != positional: <TAB>  <TAB>  <TAB>  <TAB> raise TranslationError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""format string mixes positional "" ""and named placeholders"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return bool(positional)",if positional is None :,98
def active_cursor(self): <TAB> if self.phase == _Phase.ADJUST: <TAB>  <TAB> if self.zone == _EditZone.CONTROL_NODE: <TAB>  <TAB>  <TAB> return self._crosshair_cursor <MASK> # assume button <TAB>  <TAB>  <TAB> return self._arrow_cursor <TAB> return None,elif self . zone != _EditZone . EMPTY_CANVAS :,88
"def _addPending(self, path, reason, isDir=False): <TAB> if path not in self.__pending: <TAB>  <TAB> self.__pending[path] = [Utils.DEFAULT_SLEEP_INTERVAL, isDir] <TAB>  <TAB> self.__pendingMinTime = 0 <MASK> reason = [reason.maskname, reason.pathname] <TAB>  <TAB> logSys.log( <TAB>  <TAB>  <TAB> logging.MSG, <TAB>  <TAB>  <TAB> ""Log absence detected (possibly rotation) for %s, reason: %s of %s"", <TAB>  <TAB>  <TAB> path, <TAB>  <TAB>  <TAB> *reason <TAB>  <TAB> )","if isinstance ( reason , pyinotify . Event ) :",147
"def has_safe_repr(value): <TAB> """"""Does the node have a safe representation?"""""" <TAB> if value is None or value is NotImplemented or value is Ellipsis: <TAB>  <TAB> return True <TAB> if isinstance(value, (bool, int, long, float, complex, basestring, xrange, Markup)): <TAB>  <TAB> return True <TAB> if isinstance(value, (tuple, list, set, frozenset)): <TAB>  <TAB> for item in value: <TAB>  <TAB>  <TAB> if not has_safe_repr(item): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True <TAB> elif isinstance(value, dict): <TAB>  <TAB> for key, value in value.iteritems(): <MASK> return False <TAB>  <TAB>  <TAB> if not has_safe_repr(value): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True <TAB> return False",if not has_safe_repr ( key ) :,192
"def refund_balances(self): <TAB> from liberapay.billing.transactions import refund_payin <TAB> payins = self.get_refundable_payins() <TAB> for exchange in payins: <TAB>  <TAB> balance = self.get_balance_in(exchange.amount.currency) <MASK> continue <TAB>  <TAB> amount = min(balance, exchange.refundable_amount) <TAB>  <TAB> status, e_refund = refund_payin(self.db, exchange, amount, self) <TAB>  <TAB> if status != ""succeeded"": <TAB>  <TAB>  <TAB> raise TransferError(e_refund.note)",if balance == 0 :,146
"def balanced_tokens_across_dcs(self, dcs): <TAB> tokens = [] <TAB> current_dc = dcs[0] <TAB> count = 0 <TAB> dc_count = 0 <TAB> for dc in dcs: <MASK> count += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_tokens = [tk + (dc_count * 100) for tk in self.balanced_tokens(count)] <TAB>  <TAB>  <TAB> tokens.extend(new_tokens) <TAB>  <TAB>  <TAB> current_dc = dc <TAB>  <TAB>  <TAB> count = 1 <TAB>  <TAB>  <TAB> dc_count += 1 <TAB> new_tokens = [tk + (dc_count * 100) for tk in self.balanced_tokens(count)] <TAB> tokens.extend(new_tokens) <TAB> return tokens",if dc == current_dc :,181
"def get_logsource(self, category, product, service): <TAB> """"""Return merged log source definition of all logosurces that match criteria across all Sigma conversion configurations in chain."""""" <TAB> matching = list() <TAB> for config in self: <TAB>  <TAB> for logsource in config.logsources: <TAB>  <TAB>  <TAB> if logsource.matches(category, product, service): <TAB>  <TAB>  <TAB>  <TAB> matching.append(logsource) <MASK> category, product, service = logsource.rewrite <TAB> return SigmaLogsourceConfiguration(matching, self.defaultindex)",if logsource . rewrite is not None :,138
"def fill_squares(self, loc, type): <TAB> value = type <TAB> for n in range(self.no_players): <TAB>  <TAB> self.map_data[loc[0]][loc[1]] = value <MASK> value = chr(ord(value) + 1) <TAB>  <TAB> loc = self.get_translate_loc(loc)","if type == ""0"" :",88
"def _init_ti_table(): <TAB> global _ti_table <TAB> _ti_table = [] <TAB> for fname, name in zip(kc.STRFNAMES, kc.STRNAMES): <TAB>  <TAB> seq = termcap.get(name) <MASK> continue <TAB>  <TAB> k = _name_to_key(fname) <TAB>  <TAB> if k: <TAB>  <TAB>  <TAB> _ti_table.append((list(bytearray(seq)), k))",if not seq :,109
"def OnDelete(self, event): <TAB> with wx.MessageDialog( <TAB>  <TAB> self, <TAB>  <TAB> ""Do you really want to delete the {} {}?"".format( <TAB>  <TAB>  <TAB> self.getActiveEntity().name, self.entityName <TAB>  <TAB> ), <TAB>  <TAB> ""Confirm Delete"", <TAB>  <TAB> wx.YES | wx.NO | wx.ICON_QUESTION, <TAB> ) as dlg: <TAB>  <TAB> dlg.CenterOnParent() <MASK> self.DoDelete(self.getActiveEntity()) <TAB>  <TAB>  <TAB> self.refreshEntityList() <TAB>  <TAB>  <TAB> wx.PostEvent( <TAB>  <TAB>  <TAB>  <TAB> self.entityChoices, wx.CommandEvent(wx.wxEVT_COMMAND_CHOICE_SELECTED) <TAB>  <TAB>  <TAB> )",if dlg . ShowModal ( ) == wx . ID_YES :,179
"def _add(self, queue): <TAB> if not queue.routing_key: <MASK> queue.exchange = self.default_exchange <TAB>  <TAB> queue.routing_key = self.default_routing_key <TAB> if self.ha_policy: <TAB>  <TAB> if queue.queue_arguments is None: <TAB>  <TAB>  <TAB> queue.queue_arguments = {} <TAB>  <TAB> self._set_ha_policy(queue.queue_arguments) <TAB> if self.max_priority is not None: <TAB>  <TAB> if queue.queue_arguments is None: <TAB>  <TAB>  <TAB> queue.queue_arguments = {} <TAB>  <TAB> self._set_max_priority(queue.queue_arguments) <TAB> self[queue.name] = queue <TAB> return queue","if queue . exchange is None or queue . exchange . name == """" :",187
"def ParsePlacemark(self, node): <TAB> ret = Placemark() <TAB> for child in node.childNodes: <MASK> ret.name = self.ExtractText(child) <TAB>  <TAB> if child.nodeName == ""Point"" or child.nodeName == ""LineString"": <TAB>  <TAB>  <TAB> ret.coordinates = self.ExtractCoordinates(child) <TAB> return ret","if child . nodeName == ""name"" :",94
"def find_library_nt(name): <TAB> # modified from ctypes.util <TAB> # ctypes.util.find_library just returns first result he found <TAB> # but we want to try them all <TAB> # because on Windows, users may have both 32bit and 64bit version installed <TAB> results = [] <TAB> for directory in os.environ[""PATH""].split(os.pathsep): <TAB>  <TAB> fname = os.path.join(directory, name) <TAB>  <TAB> if os.path.isfile(fname): <TAB>  <TAB>  <TAB> results.append(fname) <MASK> continue <TAB>  <TAB> fname = fname + "".dll"" <TAB>  <TAB> if os.path.isfile(fname): <TAB>  <TAB>  <TAB> results.append(fname) <TAB> return results","if fname . lower ( ) . endswith ( "".dll"" ) :",174
"def _calc_freq(item): <TAB> try: <TAB>  <TAB> if ao_index is not None and ro_index is not None: <TAB>  <TAB>  <TAB> ao = sum([int(x) for x in item.split("":"")[ao_index].split("","")]) <TAB>  <TAB>  <TAB> ro = int(item.split("":"")[ro_index]) <TAB>  <TAB>  <TAB> freq = ao / float(ao + ro) <MASK> freq = float(item.split("":"")[af_index]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> freq = 0.0 <TAB> except (IndexError, ValueError, ZeroDivisionError): <TAB>  <TAB> freq = 0.0 <TAB> return freq",elif af_index is not None :,151
def poll_kafka(self): <TAB> while True: <TAB>  <TAB> val = self.do_poll() <MASK> yield self._emit(val) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield gen.sleep(self.poll_interval) <TAB>  <TAB> if self.stopped: <TAB>  <TAB>  <TAB> break <TAB> self._close_consumer(),if val :,85
"def resolve_list_field(parent, args, ctx, info): <TAB> if ""param"" in args: <TAB>  <TAB> return ""SUCCESS-[{}]"".format( <TAB>  <TAB>  <TAB> str(args[""param""]) <MASK> else ""-"".join([str(item) for item in args[""param""]]) <TAB>  <TAB> ) <TAB> return ""SUCCESS""","if not isinstance ( args [ ""param"" ] , list )",88
"def login_hash(self, host, username, ntlmhash, domain): <TAB> lmhash, nthash = ntlmhash.split("":"") <TAB> try: <TAB>  <TAB> self.smbconn[host] = SMBConnection(host, host, sess_port=445, timeout=2) <TAB>  <TAB> self.smbconn[host].login(username, """", domain, lmhash=lmhash, nthash=nthash) <MASK> color(""[+] Guest session established on %s..."" % (host)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> color(""[+] User session establishd on %s..."" % (host)) <TAB>  <TAB> return True <TAB> except Exception as e: <TAB>  <TAB> color(""[!] Authentication error occured"") <TAB>  <TAB> color(""[!]"", e) <TAB>  <TAB> return False",if self . smbconn [ host ] . isGuestSession ( ) > 0 :,196
"def _add(self, queue): <TAB> if not queue.routing_key: <TAB>  <TAB> if queue.exchange is None or queue.exchange.name == """": <TAB>  <TAB>  <TAB> queue.exchange = self.default_exchange <TAB>  <TAB> queue.routing_key = self.default_routing_key <TAB> if self.ha_policy: <MASK> queue.queue_arguments = {} <TAB>  <TAB> self._set_ha_policy(queue.queue_arguments) <TAB> if self.max_priority is not None: <TAB>  <TAB> if queue.queue_arguments is None: <TAB>  <TAB>  <TAB> queue.queue_arguments = {} <TAB>  <TAB> self._set_max_priority(queue.queue_arguments) <TAB> self[queue.name] = queue <TAB> return queue",if queue . queue_arguments is None :,187
"def safe_delete_pod(self, jobid, ignore_not_found=True): <TAB> import kubernetes.client <TAB> body = kubernetes.client.V1DeleteOptions() <TAB> try: <TAB>  <TAB> self.kubeapi.delete_namespaced_pod(jobid, self.namespace, body=body) <TAB> except kubernetes.client.rest.ApiException as e: <MASK> # Can't find the pod. Maybe it's already been <TAB>  <TAB>  <TAB> # destroyed. Proceed with a warning message. <TAB>  <TAB>  <TAB> logger.warning( <TAB>  <TAB>  <TAB>  <TAB> ""[WARNING] 404 not found when trying to delete the pod: {jobid}\n"" <TAB>  <TAB>  <TAB>  <TAB> ""[WARNING] Ignore this error\n"".format(jobid=jobid) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise e",if e . status == 404 and ignore_not_found :,194
"def __init__(self, element, spec): <TAB> Extension.__init__(self, element, spec) <TAB> self.spec = spec <TAB> self.number = tuple(map(int, element.attrib[""number""].split("".""))) <TAB> self.api = element.attrib[""api""] <TAB> # not every spec has a ._remove member, but there shouldn't be a remove <TAB> # tag without that member, if there is, blame me! <TAB> for removed in chain.from_iterable(element.findall(""remove"")): <MASK> continue <TAB>  <TAB> data = {""enum"": spec.enums, ""command"": spec.commands}[removed.tag] <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> spec.add_remove(self.api, self.number, data[removed.attrib[""name""]]) <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> pass  # TODO","if removed . tag == ""type"" :",199
"def _convert_raw_source(self, source, languages): <TAB> for row in source: <TAB>  <TAB> example = self._read_example(row) <MASK> continue <TAB>  <TAB> for col, lang in zip(self.language_columns, languages): <TAB>  <TAB>  <TAB> example[col] = lang <TAB>  <TAB> yield example",if example is None :,81
"def check_engine(engine): <TAB> if engine == ""auto"": <TAB>  <TAB> if pa is not None: <TAB>  <TAB>  <TAB> return ""pyarrow"" <MASK> # pragma: no cover <TAB>  <TAB>  <TAB> return ""fastparquet"" <TAB>  <TAB> else:  # pragma: no cover <TAB>  <TAB>  <TAB> raise RuntimeError(""Please install either pyarrow or fastparquet."") <TAB> elif engine == ""pyarrow"": <TAB>  <TAB> if pa is None:  # pragma: no cover <TAB>  <TAB>  <TAB> raise RuntimeError(""Please install pyarrow fisrt."") <TAB>  <TAB> return engine <TAB> elif engine == ""fastparquet"": <TAB>  <TAB> if fastparquet is None:  # pragma: no cover <TAB>  <TAB>  <TAB> raise RuntimeError(""Please install fastparquet first."") <TAB>  <TAB> return engine <TAB> else:  # pragma: no cover <TAB>  <TAB> raise RuntimeError(""Unsupported engine {} to read parquet."".format(engine))",elif fastparquet is not None :,187
"def TryMerge(self, d): <TAB> while 1: <TAB>  <TAB> tt = d.getVarInt32() <MASK> break <TAB>  <TAB> if tt == 18: <TAB>  <TAB>  <TAB> self.set_value(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 29: <TAB>  <TAB>  <TAB> self.set_flags(d.get32()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 12 :,126
"def handle(self, request): <TAB> try: <TAB>  <TAB> if request.message.question[0].rdtype == dns.rdatatype.IXFR: <MASK> text = ixfr <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> text = retry_tcp_ixfr <TAB>  <TAB>  <TAB>  <TAB> self.did_truncation = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> text = axfr <TAB>  <TAB> r = dns.message.from_text(text, one_rr_per_rrset=True, origin=self.origin) <TAB>  <TAB> r.id = request.message.id <TAB>  <TAB> return r <TAB> except Exception: <TAB>  <TAB> pass",if self . did_truncation :,159
"def read_kvfile_todict(file): <TAB> if not os.path.isfile(file): <TAB>  <TAB> return {} <TAB> ret = {} <TAB> with open(file, ""r"") as FH: <TAB>  <TAB> for l in FH.readlines(): <TAB>  <TAB>  <TAB> l = l.strip() <TAB>  <TAB>  <TAB> # l = l.strip().decode('utf8') <MASK> (k, v) = re.match(r""(\S*)\s*(.*)"", l).group(1, 2) <TAB>  <TAB>  <TAB>  <TAB> k = re.sub(""____"", "" "", k) <TAB>  <TAB>  <TAB>  <TAB> ret[k] = v <TAB> return ret",if l :,153
"def wrapper(*args, **kwargs): <TAB> with capture_logs() as logs: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> function(*args, **kwargs) <TAB>  <TAB> except Exception:  # pragma: no cover <MASK> print(""%i errors logged:"" % len(logs), file=sys.stderr) <TAB>  <TAB>  <TAB>  <TAB> for message in logs: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> print(message, file=sys.stderr) <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if logs:  # pragma: no cover <TAB>  <TAB>  <TAB>  <TAB> for message in logs: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> print(message, file=sys.stderr) <TAB>  <TAB>  <TAB>  <TAB> raise AssertionError(""%i errors logged"" % len(logs))",if logs :,168
"def batchSites(self, sites): <TAB> i = 0 <TAB> res = list() <TAB> siteList = list() <TAB> for site in sites: <TAB>  <TAB> if i >= self.opts[""_maxthreads""]: <TAB>  <TAB>  <TAB> data = self.threadSites(siteList) <MASK> return res <TAB>  <TAB>  <TAB> for ret in list(data.keys()): <TAB>  <TAB>  <TAB>  <TAB> if data[ret]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # bucket:filecount <TAB>  <TAB>  <TAB>  <TAB>  <TAB> res.append(f""{ret}:{data[ret]}"") <TAB>  <TAB>  <TAB> i = 0 <TAB>  <TAB>  <TAB> siteList = list() <TAB>  <TAB> siteList.append(site) <TAB>  <TAB> i += 1 <TAB> return res",if data is None :,168
"def datagram_received(self, data, addr): <TAB> """"""Handle data from ``addr``."""""" <TAB> if self.buffer and addr in self.buffer: <TAB>  <TAB> data = self.buffer.pop(addr) + data <TAB> while data: <TAB>  <TAB> idx = data.find(self.separator) <TAB>  <TAB> if idx >= 0:  # we have a full message <TAB>  <TAB>  <TAB> idx += len(self.separator) <TAB>  <TAB>  <TAB> chunk, data = data[:idx], data[idx:] <TAB>  <TAB>  <TAB> self.response(chunk, addr) <TAB>  <TAB> else: <MASK> self.buffer = {} <TAB>  <TAB>  <TAB> self.buffer[addr] = data <TAB>  <TAB>  <TAB> data = None",if self . buffer is None :,168
"def tearDown(self): <TAB> if self.node: <MASK> with patch(""golem.task.taskserver.TaskServer.quit""): <TAB>  <TAB>  <TAB>  <TAB> self.node.client.quit() <TAB>  <TAB> if self.node._db: <TAB>  <TAB>  <TAB> self.node._db.close() <TAB> super().tearDown()",if self . node . client :,84
"def _to_sentences(self, lines): <TAB> text = """" <TAB> sentence_objects = [] <TAB> for line in lines: <MASK> if text: <TAB>  <TAB>  <TAB>  <TAB> sentences = self.tokenize_sentences(text) <TAB>  <TAB>  <TAB>  <TAB> sentence_objects += map(self._to_sentence, sentences) <TAB>  <TAB>  <TAB> sentence_objects.append(line) <TAB>  <TAB>  <TAB> text = """" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> text += "" "" + line <TAB> text = text.strip() <TAB> if text: <TAB>  <TAB> sentences = self.tokenize_sentences(text) <TAB>  <TAB> sentence_objects += map(self._to_sentence, sentences) <TAB> return sentence_objects","if isinstance ( line , Sentence ) :",164
"def _cloneComponentValues(self, myClone, cloneValueFlag): <TAB> idx = 0 <TAB> l = len(self._componentValues) <TAB> while idx < l: <TAB>  <TAB> c = self._componentValues[idx] <TAB>  <TAB> if c is not None: <MASK> myClone.setComponentByPosition( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> idx, c.clone(cloneValueFlag=cloneValueFlag) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> myClone.setComponentByPosition(idx, c.clone()) <TAB>  <TAB> idx = idx + 1","if isinstance ( c , base . AbstractConstructedAsn1Item ) :",154
"def split_quality(quality): <TAB> anyQualities = [] <TAB> bestQualities = [] <TAB> for curQual in Quality.qualityStrings.keys(): <TAB>  <TAB> if curQual & quality: <TAB>  <TAB>  <TAB> anyQualities.append(curQual) <MASK> bestQualities.append(curQual) <TAB> return sorted(anyQualities), sorted(bestQualities)",if curQual << 16 & quality :,109
"def make_pattern(wtree): <TAB> subpattern = [] <TAB> for part in wtree[1:-1]: <MASK> part = make_pattern(part) <TAB>  <TAB> elif wtree[0] != """": <TAB>  <TAB>  <TAB> for c in part: <TAB>  <TAB>  <TAB>  <TAB> # Meta-characters cannot be quoted <TAB>  <TAB>  <TAB>  <TAB> if c in special_chars: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise GlobError() <TAB>  <TAB> subpattern.append(part) <TAB> return """".join(subpattern)","if isinstance ( part , list ) :",123
"def insert_not(self, aList): <TAB> '''Change ""!"" to ""not"" except before ""=""''' <TAB> i = 0 <TAB> while i < len(aList): <TAB>  <TAB> if self.is_string_or_comment(aList, i): <TAB>  <TAB>  <TAB> i = self.skip_string_or_comment(aList, i) <MASK> aList[i : i + 1] = list(""not "") <TAB>  <TAB>  <TAB> i += 4 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> i += 1","elif aList [ i ] == ""!"" and not self . match ( aList , i + 1 , ""="" ) :",142
"def _concretize(self, n_cls, t1, t2, join_or_meet, translate): <TAB> ptr_class = self._pointer_class() <TAB> if n_cls is ptr_class: <TAB>  <TAB> if isinstance(t1, ptr_class) and isinstance(t2, ptr_class): <TAB>  <TAB>  <TAB> # we need to merge them <TAB>  <TAB>  <TAB> return ptr_class(join_or_meet(t1.basetype, t2.basetype, translate)) <TAB>  <TAB> if isinstance(t1, ptr_class): <TAB>  <TAB>  <TAB> return t1 <MASK> return t2 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # huh? <TAB>  <TAB>  <TAB> return ptr_class(BottomType()) <TAB> return n_cls()","elif isinstance ( t2 , ptr_class ) :",181
"def pre_validate(self, form): <TAB> if self.data: <TAB>  <TAB> values = list(c[0] for c in self.choices) <TAB>  <TAB> for d in self.data: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.gettext(""'%(value)s' is not a valid choice for this field"") <TAB>  <TAB>  <TAB>  <TAB>  <TAB> % dict(value=d) <TAB>  <TAB>  <TAB>  <TAB> )",if d not in values :,106
"def frontend_visible_config(config_dict): <TAB> visible_dict = {} <TAB> for name in CLIENT_WHITELIST: <TAB>  <TAB> if name.lower().find(""secret"") >= 0: <TAB>  <TAB>  <TAB> raise Exception(""Cannot whitelist secrets: %s"" % name) <MASK> visible_dict[name] = config_dict.get(name, None) <TAB>  <TAB> if ""ENTERPRISE_LOGO_URL"" in config_dict: <TAB>  <TAB>  <TAB> visible_dict[""BRANDING""] = visible_dict.get(""BRANDING"", {}) <TAB>  <TAB>  <TAB> visible_dict[""BRANDING""][""logo""] = config_dict[""ENTERPRISE_LOGO_URL""] <TAB> return visible_dict",if name in config_dict :,171
"def listdir(self, path=None): <TAB> from azure.storage.blob import Blob <TAB> dir_path = normalize_storage_path(self._append_path_to_prefix(path)) <TAB> if dir_path: <TAB>  <TAB> dir_path += ""/"" <TAB> items = list() <TAB> for blob in self.client.list_blobs(self.container, prefix=dir_path, delimiter=""/""): <MASK> items.append(self._strip_prefix_from_path(blob.name, dir_path)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> items.append( <TAB>  <TAB>  <TAB>  <TAB> self._strip_prefix_from_path( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> blob.name[: blob.name.find(""/"", len(dir_path))], dir_path <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> return items",if type ( blob ) == Blob :,198
"def diff(self, resources): <TAB> model = self.manager.resource_type <TAB> for r in resources: <TAB>  <TAB> hlabels = self.resolve_labels(r[""projectId""]) <TAB>  <TAB> if not hlabels: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> delta = False <TAB>  <TAB> rlabels = r.get(""labels"", {}) <TAB>  <TAB> for k, v in hlabels.items(): <TAB>  <TAB>  <TAB> if k not in rlabels or rlabels[k] != v: <TAB>  <TAB>  <TAB>  <TAB> delta = True <TAB>  <TAB> if not delta: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> rlabels = dict(rlabels) <TAB>  <TAB> rlabels.update(hlabels) <MASK> yield (""update"", model.get_label_params(r, rlabels))",if delta :,176
"def favorite(id): <TAB> note = Note.query.get_or_404(id) <TAB> if current_user != note.author: <TAB>  <TAB> abort(403) <TAB> else: <MASK> note.is_favorite = True <TAB>  <TAB>  <TAB> note.updated_date = datetime.utcnow() <TAB>  <TAB>  <TAB> db.session.commit() <TAB>  <TAB>  <TAB> flash(""Note marked as favorite"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> note.is_favorite = False <TAB>  <TAB>  <TAB> note.updated_date = datetime.utcnow() <TAB>  <TAB>  <TAB> db.session.commit() <TAB>  <TAB>  <TAB> flash(""Note removed as favorite"") <TAB>  <TAB> return redirect(request.referrer)",if not note . is_favorite :,163
"def enter_standby_instances(self, group_name, instance_ids, should_decrement): <TAB> group = self.autoscaling_groups[group_name] <TAB> original_size = group.desired_capacity <TAB> standby_instances = [] <TAB> for instance_state in group.instance_states: <MASK> instance_state.lifecycle_state = ""Standby"" <TAB>  <TAB>  <TAB> standby_instances.append(instance_state) <TAB> if should_decrement: <TAB>  <TAB> group.desired_capacity = group.desired_capacity - len(instance_ids) <TAB> group.set_desired_capacity(group.desired_capacity) <TAB> return standby_instances, original_size, group.desired_capacity",if instance_state . instance . id in instance_ids :,182
"def _child_complete_hook(self, child_task): <TAB> if child_task.task_spec == self.main_child_task_spec or self._should_cancel( <TAB>  <TAB> child_task.task_spec <TAB> ): <TAB>  <TAB> for sibling in child_task.parent.children: <MASK> if sibling.task_spec == self.main_child_task_spec or ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> isinstance(sibling.task_spec, BoundaryEvent) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> and not sibling._is_finished() <TAB>  <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> sibling.cancel() <TAB>  <TAB> for t in child_task.workflow._get_waiting_tasks(): <TAB>  <TAB>  <TAB> t.task_spec._update(t)",if sibling != child_task :,183
"def extract_groups(self, text: str, language_code: str): <TAB> previous = None <TAB> group = 1 <TAB> groups = [] <TAB> words = [] <TAB> ignored = IGNORES.get(language_code, {}) <TAB> for word in NON_WORD.split(text): <TAB>  <TAB> if not word: <TAB>  <TAB>  <TAB> continue <MASK> if previous == word: <TAB>  <TAB>  <TAB>  <TAB> group += 1 <TAB>  <TAB>  <TAB> elif group > 1: <TAB>  <TAB>  <TAB>  <TAB> groups.append(group) <TAB>  <TAB>  <TAB>  <TAB> words.append(previous) <TAB>  <TAB>  <TAB>  <TAB> group = 1 <TAB>  <TAB> previous = word <TAB> if group > 1: <TAB>  <TAB> groups.append(group) <TAB>  <TAB> words.append(previous) <TAB> return groups, words",if word not in ignored and len ( word ) >= 2 :,187
"def runTest(self): <TAB> """"""This function will call api providing list of op_class"""""" <TAB> if self.is_positive_test: <TAB>  <TAB> response = indexes_utils.api_create_index_get_op_class(self) <TAB> else: <MASK> with patch( <TAB>  <TAB>  <TAB>  <TAB> self.mock_data[""function_name""], <TAB>  <TAB>  <TAB>  <TAB> side_effect=eval(self.mock_data[""return_value""]), <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> response = indexes_utils.api_create_index_get_op_class(self) <TAB> indexes_utils.assert_status_code(self, response)",if self . mocking_required :,160
"def fn(value=None): <TAB> for i in [-1, 0, 1, 2, 3, 4]: <MASK> continue <TAB>  <TAB> elif i == 0: <TAB>  <TAB>  <TAB> yield 0 <TAB>  <TAB> elif i == 1: <TAB>  <TAB>  <TAB> yield 1 <TAB>  <TAB>  <TAB> i = 0 <TAB>  <TAB>  <TAB> yield value <TAB>  <TAB>  <TAB> yield 2 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> v = i / value <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> v = i <TAB>  <TAB>  <TAB> yield v",if i < 0 :,127
"def _update(self, flag): <TAB> self._modified = False <TAB> self._index = {} <TAB> try: <TAB>  <TAB> f = _io.open(self._dirfile, ""r"", encoding=""Latin-1"") <TAB> except OSError: <MASK> raise <TAB>  <TAB> self._modified = True <TAB> else: <TAB>  <TAB> with f: <TAB>  <TAB>  <TAB> for line in f: <TAB>  <TAB>  <TAB>  <TAB> line = line.rstrip() <TAB>  <TAB>  <TAB>  <TAB> key, pos_and_siz_pair = _ast.literal_eval(line) <TAB>  <TAB>  <TAB>  <TAB> key = key.encode(""Latin-1"") <TAB>  <TAB>  <TAB>  <TAB> self._index[key] = pos_and_siz_pair","if flag not in ( ""c"" , ""n"" ) :",172
"def _network_connections_in_results(data): <TAB> for plugin_name, plugin_result in data.iteritems(): <TAB>  <TAB> if plugin_result[""status""] == ""error"": <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> if ""connections"" in plugin_result[""device""]: <TAB>  <TAB>  <TAB> for conn in plugin_result[""device""][""connections""]: <TAB>  <TAB>  <TAB>  <TAB> if conn[""connection_type""] == ConnectionType.network.name: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False","if ""device"" not in plugin_result :",126
"def close(self) -> None: <TAB> """"""Stop accepting writes and write file, if needed."""""" <TAB> if not self._io: <TAB>  <TAB> raise Exception(""FileAvoidWrite does not support empty files."") <TAB> buf = self.getvalue() <TAB> self._io.close() <TAB> try: <TAB>  <TAB> with open(self._path, encoding=""utf-8"") as old_f: <TAB>  <TAB>  <TAB> old_content = old_f.read() <MASK> return <TAB> except OSError: <TAB>  <TAB> pass <TAB> with open(self._path, ""w"", encoding=""utf-8"") as f: <TAB>  <TAB> f.write(buf)",if old_content == buf :,157
"def _extract_changes(doc_map, changes, read_time): <TAB> deletes = [] <TAB> adds = [] <TAB> updates = [] <TAB> for name, value in changes.items(): <MASK> if name in doc_map: <TAB>  <TAB>  <TAB>  <TAB> deletes.append(name) <TAB>  <TAB> elif name in doc_map: <TAB>  <TAB>  <TAB> if read_time is not None: <TAB>  <TAB>  <TAB>  <TAB> value.read_time = read_time <TAB>  <TAB>  <TAB> updates.append(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if read_time is not None: <TAB>  <TAB>  <TAB>  <TAB> value.read_time = read_time <TAB>  <TAB>  <TAB> adds.append(value) <TAB> return (deletes, adds, updates)",if value == ChangeType . REMOVED :,173
"def preprocess( <TAB> self, <TAB> X: DataFrame, <TAB> is_train=False, <TAB> vect_max_features=1000, <TAB> model_specific_preprocessing=False,): <TAB> X = super().preprocess(X=X) <TAB> if ( <TAB>  <TAB> model_specific_preprocessing <TAB> ):  # This is hack to work-around pre-processing caching in bagging/stacker models <MASK> feature_types = self._get_types_of_features(X) <TAB>  <TAB>  <TAB> X = self.preprocess_train(X, feature_types, vect_max_features) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> X = self.pipeline.transform(X) <TAB> return X",if is_train :,167
"def setup_child(self, child): <TAB> child.parent = self <TAB> if self.document: <TAB>  <TAB> child.document = self.document <MASK> child.source = self.document.current_source <TAB>  <TAB> if child.line is None: <TAB>  <TAB>  <TAB> child.line = self.document.current_line",if child . source is None :,84
"def _compute_early_outs(self, quotas): <TAB> for q in quotas: <MASK> self.results[q] = Quota.AVAILABILITY_ORDERED, 0 <TAB>  <TAB> elif q.size is None: <TAB>  <TAB>  <TAB> self.results[q] = Quota.AVAILABILITY_OK, None <TAB>  <TAB> elif q.size == 0: <TAB>  <TAB>  <TAB> self.results[q] = Quota.AVAILABILITY_GONE, 0",if q . closed and not self . _ignore_closed :,118
"def parse_function(self, l): <TAB> bracket = l.find(""("") <TAB> fname = l[8:bracket] <TAB> if self.properties: <MASK> self.props[fname] = 1 <TAB>  <TAB>  <TAB> self.propget[fname] = 1 <TAB>  <TAB> elif self.properties[0] == ""propput"": <TAB>  <TAB>  <TAB> self.props[fname] = 1 <TAB>  <TAB>  <TAB> self.propput[fname] = 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.functions[fname] = 1 <TAB> self.properties = None","if self . properties [ 0 ] == ""propget"" :",139
def SetHelpListButtonStates(self): <TAB> if self.listHelp.size() < 1:  # no entries in list <TAB>  <TAB> self.buttonHelpListEdit.config(state=DISABLED) <TAB>  <TAB> self.buttonHelpListRemove.config(state=DISABLED) <TAB> else:  # there are some entries <MASK> # there currently is a selection <TAB>  <TAB>  <TAB> self.buttonHelpListEdit.config(state=NORMAL) <TAB>  <TAB>  <TAB> self.buttonHelpListRemove.config(state=NORMAL) <TAB>  <TAB> else:  # there currently is not a selection <TAB>  <TAB>  <TAB> self.buttonHelpListEdit.config(state=DISABLED) <TAB>  <TAB>  <TAB> self.buttonHelpListRemove.config(state=DISABLED),if self . listHelp . curselection ( ) :,174
"def param_names() -> FrozenSet[Tuple[str, str]]: <TAB> """"""Returns all module and parameter names as a set of pairs."""""" <TAB> out = [] <TAB> params = current_frame().params <TAB> for mod_name, bundle in params.items(): <MASK> # TODO(tomhennigan) Fix broken user code and remove this warning. <TAB>  <TAB>  <TAB> warnings.warn(f""Invalid entry {mod_name!r} in params {params}"") <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for name in bundle: <TAB>  <TAB>  <TAB> out.append((mod_name, name)) <TAB> return frozenset(out)","if not isinstance ( bundle , Mapping ) :",150
"def _classify_volume(self, ctxt, volumes): <TAB> normal_volumes = [] <TAB> replica_volumes = [] <TAB> for v in volumes: <TAB>  <TAB> volume_type = self._get_volume_replicated_type(ctxt, v) <MASK> replica_volumes.append(v) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> normal_volumes.append(v) <TAB> return normal_volumes, replica_volumes","if volume_type and v . status == ""available"" :",113
"def undump_descriptions_of_all_objects(inf): <TAB> d = {} <TAB> for l in inf: <TAB>  <TAB> dash = l.find(""-"") <TAB>  <TAB> if dash == -1: <TAB>  <TAB>  <TAB> raise l <TAB>  <TAB> mo = NRE.search(l) <MASK> typstr = l[dash + 1 : mo.start(0)] <TAB>  <TAB>  <TAB> num = int(mo.group(0)) <TAB>  <TAB>  <TAB> if str(num) != mo.group(0): <TAB>  <TAB>  <TAB>  <TAB> raise mo.group(0) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> typstr = l[dash + 1 :] <TAB>  <TAB>  <TAB> num = None <TAB>  <TAB> d[l[:dash]] = ( <TAB>  <TAB>  <TAB> typstr, <TAB>  <TAB>  <TAB> num, <TAB>  <TAB> ) <TAB> return d",if mo :,187
"def _real_len(self, s): <TAB> s_len = 0 <TAB> in_esc = False <TAB> prev = "" "" <TAB> for c in replace_all({""\0+"": """", ""\0-"": """", ""\0^"": """", ""\1"": """", ""\t"": "" ""}, s): <MASK> if c == ""m"": <TAB>  <TAB>  <TAB>  <TAB> in_esc = False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if c == ""["" and prev == ""\033"": <TAB>  <TAB>  <TAB>  <TAB> in_esc = True <TAB>  <TAB>  <TAB>  <TAB> s_len -= 1  # we counted prev when we shouldn't have <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> s_len += self._display_len(c) <TAB>  <TAB> prev = c <TAB> return s_len",if in_esc :,177
"def update_all(self, include_description=False): <TAB> if self.background_update is None: <TAB>  <TAB> episodes = [row[self.C_EPISODE] for row in self] <TAB> else: <TAB>  <TAB> # Update all episodes that have already been initialized... <TAB>  <TAB> episodes = [ <TAB>  <TAB>  <TAB> row[self.C_EPISODE] <TAB>  <TAB>  <TAB> for index, row in enumerate(self) <MASK> ] <TAB>  <TAB> # ...and also include episodes that still need to be initialized <TAB>  <TAB> episodes.extend(self.background_update.episodes) <TAB> self._update_from_episodes(episodes, include_description)",if index < self . background_update . index,170
"def _debug_log(self, text, level): <TAB> if text and ""log"" in self.config.sys.debug: <MASK> text = ""%slog(%s): %s"" % (self.log_prefix, level, text) <TAB>  <TAB> if self.log_parent is not None: <TAB>  <TAB>  <TAB> return self.log_parent.log(level, text) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.term.write(self._fmt_log(text, level=level))",if not text . startswith ( self . log_prefix ) :,129
"def save_new_objects(self, commit=True): <TAB> self.new_objects = [] <TAB> for form in self.extra_forms: <TAB>  <TAB> if not form.has_changed(): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # If someone has marked an add form for deletion, don't save the <TAB>  <TAB> # object. <TAB>  <TAB> if self.can_delete and self._should_delete_form(form): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> self.new_objects.append(self.save_new(form, commit=commit)) <MASK> self.saved_forms.append(form) <TAB> return self.new_objects",if not commit :,151
"def get_master_info(accounts_config, master): <TAB> master_info = None <TAB> for a in accounts_config[""accounts""]: <MASK> master_info = a <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if a[""account_id""] == master: <TAB>  <TAB>  <TAB> master_info = a <TAB>  <TAB>  <TAB> break <TAB> if master_info is None: <TAB>  <TAB> raise ValueError(""Master account: %s not found in accounts config"" % (master)) <TAB> return master_info","if a [ ""name"" ] == master :",120
"def update(attr, value=None): <TAB> if value is not None: <TAB>  <TAB> setattr(draft, attr, value) <MASK> # Update size, snippet too <TAB>  <TAB>  <TAB> draft.size = len(value) <TAB>  <TAB>  <TAB> draft.snippet = draft.calculate_html_snippet(value)","if attr == ""body"" :",78
"def _process_property_change(self, msg): <TAB> msg = super(Select, self)._process_property_change(msg) <TAB> if ""value"" in msg: <TAB>  <TAB> if not self.values: <TAB>  <TAB>  <TAB> pass <MASK> msg[""value""] = self.values[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if isIn(msg[""value""], self.unicode_values): <TAB>  <TAB>  <TAB>  <TAB> idx = indexOf(msg[""value""], self.unicode_values) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> idx = indexOf(msg[""value""], self.labels) <TAB>  <TAB>  <TAB> msg[""value""] = self._items[self.labels[idx]] <TAB> msg.pop(""options"", None) <TAB> return msg","elif msg [ ""value"" ] is None :",180
"def removeEmptyDir(path, removeRoot=True): <TAB> if not os.path.isdir(path): <TAB>  <TAB> return <TAB> # remove empty subfolders <TAB> _files = os.listdir(path) <TAB> if len(_files) > 0: <TAB>  <TAB> for f in _files: <TAB>  <TAB>  <TAB> if not f.startswith(""."") and not f.startswith(""_""): <TAB>  <TAB>  <TAB>  <TAB> fullpath = os.path.join(path, f) <MASK> removeEmptyDir(fullpath) <TAB> # if folder empty, delete it <TAB> _files = os.listdir(path) <TAB> if len(_files) == 0 and removeRoot: <TAB>  <TAB> Print.info(""Removing empty folder:"" + path) <TAB>  <TAB> os.rmdir(path)",if os . path . isdir ( fullpath ) :,181
"def make_relative_to(self, kwds, relative_to): <TAB> if relative_to and os.path.dirname(relative_to): <TAB>  <TAB> dirname = os.path.dirname(relative_to) <TAB>  <TAB> kwds = kwds.copy() <TAB>  <TAB> for key in ffiplatform.LIST_OF_FILE_NAMES: <TAB>  <TAB>  <TAB> if key in kwds: <TAB>  <TAB>  <TAB>  <TAB> lst = kwds[key] <MASK> raise TypeError(""keyword '%s' should be a list or tuple"" % (key,)) <TAB>  <TAB>  <TAB>  <TAB> lst = [os.path.join(dirname, fn) for fn in lst] <TAB>  <TAB>  <TAB>  <TAB> kwds[key] = lst <TAB> return kwds","if not isinstance ( lst , ( list , tuple ) ) :",173
"def ending(self, state): <TAB> print_title("" STABLE PINS "") <TAB> path_lists = trace_graph(state.graph) <TAB> for k in sorted(state.mapping): <TAB>  <TAB> print(state.mapping[k].as_line(include_hashes=False)) <TAB>  <TAB> paths = path_lists[k] <TAB>  <TAB> for path in paths: <MASK> print("" <TAB> User requirement"") <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> print(""   "", end="""") <TAB>  <TAB>  <TAB> for v in reversed(path[1:]): <TAB>  <TAB>  <TAB>  <TAB> line = state.mapping[v].as_line(include_hashes=False) <TAB>  <TAB>  <TAB>  <TAB> print("" <="", line, end="""") <TAB>  <TAB>  <TAB> print() <TAB> print()",if path == [ None ] :,183
"def fetch(): <TAB> retval = {} <TAB> content = retrieve_content(__url__) <TAB> if __check__ in content: <TAB>  <TAB> for line in content.split(""\n""): <TAB>  <TAB>  <TAB> line = line.strip() <MASK> continue <TAB>  <TAB>  <TAB> if "" # "" in line: <TAB>  <TAB>  <TAB>  <TAB> reason = line.split("" # "")[1].split()[0].lower() <TAB>  <TAB>  <TAB>  <TAB> if reason == ""scanning"":  # too many false positives <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB>  <TAB> retval[line.split("" # "")[0]] = (__info__, __reference__) <TAB> return retval","if not line or line . startswith ( ""#"" ) or ""."" not in line :",157
"def __str__(self): <TAB> """"""Returns human readable string representation, useful for debugging."""""" <TAB> buf = StringIO() <TAB> for idx, (class_batch_id, class_val) in enumerate(iteritems(self.data)): <MASK> buf.write(u""  ...\n"") <TAB>  <TAB>  <TAB> break <TAB>  <TAB> buf.write(u'  ClassBatch ""{0}""\n'.format(class_batch_id)) <TAB>  <TAB> buf.write(u"" <TAB> {0}\n"".format(str(class_val))) <TAB> return buf.getvalue()",if idx >= TO_STR_MAX_BATCHES :,142
"def find_caller(stack): <TAB> """"""Finds info about first non-sqlalchemy call in stack"""""" <TAB> for frame in stack: <TAB>  <TAB> # We don't care about sqlalchemy internals <TAB>  <TAB> module = inspect.getmodule(frame[0]) <TAB>  <TAB> if not hasattr(module, ""__name__""): <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> return (module.__name__,) + tuple(frame[2:4]) + (frame[4][0].strip(),) <TAB> log.warning(""Transaction from unknown origin"") <TAB> return None, None, None, None","if module . __name__ . startswith ( ""sqlalchemy"" ) :",137
"def format_unencoded(self, tokensource, outfile): <TAB> if self.linenos: <TAB>  <TAB> self._write_lineno(outfile) <TAB> for ttype, value in tokensource: <TAB>  <TAB> color = self._get_color(ttype) <TAB>  <TAB> for line in value.splitlines(True): <MASK> outfile.write(""<%s>%s</>"" % (color, line.rstrip(""\n""))) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> outfile.write(line.rstrip(""\n"")) <TAB>  <TAB>  <TAB> if line.endswith(""\n""): <TAB>  <TAB>  <TAB>  <TAB> if self.linenos: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._write_lineno(outfile) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> outfile.write(""\n"") <TAB> if self.linenos: <TAB>  <TAB> outfile.write(""\n"")",if color :,190
"def __new__(cls, name, bases, attrs): <TAB> klass = type.__new__(cls, name, bases, attrs) <TAB> if ""cmds"" in attrs: <TAB>  <TAB> cmds = attrs[""cmds""] <MASK> cmd_handler_mapping[cmds] = klass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for cmd in cmds: <TAB>  <TAB>  <TAB>  <TAB> cmd_handler_mapping[cmd] = klass <TAB> return klass","if isinstance ( cmds , str ) :",104
"def __getattr__(self, key): <TAB> if key == key.upper(): <MASK> return getattr(self._django_settings, key) <TAB>  <TAB> elif hasattr(self._default_settings, key): <TAB>  <TAB>  <TAB> return getattr(self._default_settings, key) <TAB> raise AttributeError( <TAB>  <TAB> ""%r object has no attribute %r"" % (self.__class__.__name__, key) <TAB> )","if hasattr ( self . _django_settings , key ) :",106
"def download_file(url): <TAB> local_filename = url.split(""/"")[-1] <TAB> outfile = os.path.join(AVATAR_DIR, local_filename) <TAB> if not os.path.isfile(outfile): <TAB>  <TAB> r = requests.get(url, stream=True) <TAB>  <TAB> with open(outfile, ""wb"") as f: <TAB>  <TAB>  <TAB> for chunk in r.iter_content(chunk_size=1024): <MASK> # filter out keep-alive new chunks <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f.write(chunk) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f.flush() <TAB> return local_filename",if chunk :,143
"def check_default(self): <TAB> if self.check(): <TAB>  <TAB> self.credentials = [] <TAB>  <TAB> data = LockedIterator(itertools.product(self.usernames, self.passwords)) <TAB>  <TAB> self.run_threads(self.threads, self.target_function, data) <MASK> return self.credentials <TAB> return None",if self . credentials :,85
"def _process_frame(self, frame_num, frame_im, callback=None): <TAB> # type(int, numpy.ndarray) -> None <TAB> """"""Adds any cuts detected with the current frame to the cutting list."""""" <TAB> for detector in self._detector_list: <TAB>  <TAB> cuts = detector.process_frame(frame_num, frame_im) <TAB>  <TAB> if cuts and callback: <TAB>  <TAB>  <TAB> callback(frame_im, frame_num) <TAB>  <TAB> self._cutting_list += cuts <TAB> for detector in self._sparse_detector_list: <TAB>  <TAB> events = detector.process_frame(frame_num, frame_im) <MASK> callback(frame_im, frame_num) <TAB>  <TAB> self._event_list += events",if events and callback :,178
"def parse(cls, api, json): <TAB> user = cls(api) <TAB> setattr(user, ""_json"", json) <TAB> for k, v in json.items(): <TAB>  <TAB> if k == ""created_at"": <TAB>  <TAB>  <TAB> setattr(user, k, parse_datetime(v)) <TAB>  <TAB> elif k == ""status"": <TAB>  <TAB>  <TAB> setattr(user, k, Status.parse(api, v)) <MASK> # twitter sets this to null if it is false <TAB>  <TAB>  <TAB> if v is True: <TAB>  <TAB>  <TAB>  <TAB> setattr(user, k, True) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> setattr(user, k, False) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> setattr(user, k, v) <TAB> return user","elif k == ""following"" :",179
def dump_token_list(tokens): <TAB> for token in tokens: <MASK> writer.write(token.contents) <TAB>  <TAB> elif token.token_type == TOKEN_VAR: <TAB>  <TAB>  <TAB> writer.print_expr(token.contents) <TAB>  <TAB>  <TAB> touch_var(token.contents),if token . token_type == TOKEN_TEXT :,83
"def parent_path(path): <TAB> parent_dir = S3FileSystem._append_separator(path) <TAB> if not s3.is_root(parent_dir): <TAB>  <TAB> bucket_name, key_name, basename = s3.parse_uri(path) <MASK> # bucket is top-level so return root <TAB>  <TAB>  <TAB> parent_dir = S3A_ROOT <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> bucket_path = ""%s%s"" % (S3A_ROOT, bucket_name) <TAB>  <TAB>  <TAB> key_path = ""/"".join(key_name.split(""/"")[:-1]) <TAB>  <TAB>  <TAB> parent_dir = s3.abspath(bucket_path, key_path) <TAB> return parent_dir",if not basename :,168
"def write_framed_message(self, message): <TAB> message_length = len(message) <TAB> total_bytes_sent = 0 <TAB> while message_length - total_bytes_sent > 0: <MASK> buffer_length = BUFFER_SIZE <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> buffer_length = message_length - total_bytes_sent <TAB>  <TAB> self.write_buffer( <TAB>  <TAB>  <TAB> message[total_bytes_sent : (total_bytes_sent + buffer_length)] <TAB>  <TAB> ) <TAB>  <TAB> total_bytes_sent += buffer_length <TAB> # A message is always terminated by a zero-length buffer. <TAB> self.write_buffer_length(0)",if message_length - total_bytes_sent > BUFFER_SIZE :,177
"def reader(): <TAB> with tarfile.open(filename, mode=""r"") as f: <TAB>  <TAB> names = (each_item.name for each_item in f if sub_name in each_item.name) <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> for name in names: <TAB>  <TAB>  <TAB>  <TAB> if six.PY2: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> batch = pickle.load(f.extractfile(name)) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> batch = pickle.load(f.extractfile(name), encoding=""bytes"") <TAB>  <TAB>  <TAB>  <TAB> for item in read_batch(batch): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield item <MASK> break",if not cycle :,157
"def splitOn(sequence, predicate, transformers): <TAB> result = [] <TAB> mode = predicate(sequence[0]) <TAB> tmp = [sequence[0]] <TAB> for e in sequence[1:]: <TAB>  <TAB> p = predicate(e) <MASK> result.extend(transformers[mode](tmp)) <TAB>  <TAB>  <TAB> tmp = [e] <TAB>  <TAB>  <TAB> mode = p <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tmp.append(e) <TAB> result.extend(transformers[mode](tmp)) <TAB> return result",if p != mode :,122
"def stroke(s): <TAB> keys = [] <TAB> on_left = True <TAB> for k in s: <TAB>  <TAB> if k in ""EU*-"": <TAB>  <TAB>  <TAB> on_left = False <TAB>  <TAB> if k == ""-"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif k == ""*"": <TAB>  <TAB>  <TAB> keys.append(k) <MASK> keys.append(k + ""-"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> keys.append(""-"" + k) <TAB> return Stroke(keys)",elif on_left :,116
"def check(data_dir, decrypter, read_only=False): <TAB> fname = os.path.join(data_dir, DIGEST_NAME) <TAB> if os.path.exists(fname): <TAB>  <TAB> if decrypter is None: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> f = open(fname, ""rb"") <TAB>  <TAB> s = f.read() <TAB>  <TAB> f.close() <TAB>  <TAB> return decrypter.decrypt(s) == MAGIC_STRING <TAB> else: <TAB>  <TAB> if decrypter is not None: <MASK> return False <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> s = decrypter.encrypt(MAGIC_STRING) <TAB>  <TAB>  <TAB>  <TAB> f = open(fname, ""wb"") <TAB>  <TAB>  <TAB>  <TAB> f.write(s) <TAB>  <TAB>  <TAB>  <TAB> f.close() <TAB>  <TAB> return True",if read_only :,198
def get_sentence(self): <TAB> while True: <TAB>  <TAB> self._seed += 1 <TAB>  <TAB> all_files = list(self._all_files) <TAB>  <TAB> if self._shuffle: <TAB>  <TAB>  <TAB> if self._n_gpus > 1: <TAB>  <TAB>  <TAB>  <TAB> random.seed(self._seed) <TAB>  <TAB>  <TAB> random.shuffle(all_files) <TAB>  <TAB> for file_path in all_files: <TAB>  <TAB>  <TAB> for ret in self._load_file(file_path): <TAB>  <TAB>  <TAB>  <TAB> yield ret <MASK> break,"if self . _mode == ""test"" :",134
"def on_epoch_end(self, batch, logs=None): <TAB> # At the end of every epoch, remask the weights. This ensures that when <TAB> # the model is saved after completion, the weights represent mask*weights. <TAB> weight_mask_ops = [] <TAB> for layer in self.prunable_layers: <MASK> if tf.executing_eagerly(): <TAB>  <TAB>  <TAB>  <TAB> layer.pruning_obj.weight_mask_op() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> weight_mask_ops.append(layer.pruning_obj.weight_mask_op()) <TAB> K.batch_get_value(weight_mask_ops)","if isinstance ( layer , pruning_wrapper . PruneLowMagnitude ) :",166
"def stroke(s): <TAB> keys = [] <TAB> on_left = True <TAB> for k in s: <MASK> on_left = False <TAB>  <TAB> if k == ""-"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif k == ""*"": <TAB>  <TAB>  <TAB> keys.append(k) <TAB>  <TAB> elif on_left: <TAB>  <TAB>  <TAB> keys.append(k + ""-"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> keys.append(""-"" + k) <TAB> return Stroke(keys)","if k in ""EU*-"" :",116
"def _plot_figure(self, idx): <TAB> with self.renderer.state(): <TAB>  <TAB> self.plot.update(idx) <MASK> figure_format = self.renderer.params(""fig"").objects[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> figure_format = self.renderer.fig <TAB>  <TAB> return self.renderer._figure_data(self.plot, figure_format, as_script=True)[0]","if self . renderer . fig == ""auto"" :",110
"def custom_format(slither, result): <TAB> elements = result[""elements""] <TAB> for element in elements: <TAB>  <TAB> target = element[""additional_fields""][""target""] <TAB>  <TAB> convention = element[""additional_fields""][""convention""] <MASK> # l_O_I_should_not_be_used cannot be automatically patched <TAB>  <TAB>  <TAB> logger.info( <TAB>  <TAB>  <TAB>  <TAB> f'The following naming convention cannot be patched: \n{result[""description""]}' <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> _patch(slither, result, element, target)","if convention == ""l_O_I_should_not_be_used"" :",155
"def refresh(self): <TAB> if self._obj: <TAB>  <TAB> person = self._db.get_person_from_handle(self._obj.get_reference_handle()) <MASK> frel = str(self._obj.get_father_relation()) <TAB>  <TAB>  <TAB> mrel = str(self._obj.get_mother_relation()) <TAB>  <TAB>  <TAB> self._title = _(""%(frel)s %(mrel)s"") % {""frel"": frel, ""mrel"": mrel} <TAB>  <TAB>  <TAB> self._value = person.get_primary_name().get_name()",if person :,136
"def append(self, child): <TAB> if child not in (None, self): <TAB>  <TAB> tag = child_tag(self._tag) <MASK> if isinstance(child, Html): <TAB>  <TAB>  <TAB>  <TAB> if child.tag != tag: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> child = Html(tag, child) <TAB>  <TAB>  <TAB> elif not child.startswith(""<%s"" % tag): <TAB>  <TAB>  <TAB>  <TAB> child = Html(tag, child) <TAB>  <TAB> super().append(child)",if tag :,113
def _forward_main_responses(self): <TAB> while self._should_keep_going(): <TAB>  <TAB> line = self._proc.stdout.readline() <TAB>  <TAB> if self._main_backend_is_fresh and self._looks_like_echo(line): <TAB>  <TAB>  <TAB> # In the beginning the backend may echo commands sent to it (perhaps this echo-avoiding trick <TAB>  <TAB>  <TAB> # takes time). Don't forward those lines. <TAB>  <TAB>  <TAB> continue <MASK> break <TAB>  <TAB> with self._response_lock: <TAB>  <TAB>  <TAB> sys.stdout.write(line) <TAB>  <TAB>  <TAB> sys.stdout.flush() <TAB>  <TAB>  <TAB> self._main_backend_is_fresh = False,if not line :,161
"def forward(self, inputs): <TAB> x = inputs[""image""] <TAB> out = self.conv0(x) <TAB> out = self.downsample0(out) <TAB> blocks = [] <TAB> for i, conv_block_i in enumerate(self.darknet_conv_block_list): <TAB>  <TAB> out = conv_block_i(out) <MASK> out.stop_gradient = True <TAB>  <TAB> if i in self.return_idx: <TAB>  <TAB>  <TAB> blocks.append(out) <TAB>  <TAB> if i < self.num_stages - 1: <TAB>  <TAB>  <TAB> out = self.downsample_list[i](out) <TAB> return blocks",if i == self . freeze_at :,159
"def check_backslashes(payload): <TAB> # Check for single quotes <TAB> if payload.count(""\\"") >= 15: <TAB>  <TAB> if not settings.TAMPER_SCRIPTS[""backslashes""]: <MASK> menu.options.tamper = menu.options.tamper + "",backslashes"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> menu.options.tamper = ""backslashes"" <TAB>  <TAB> from src.core.tamper import backslashes <TAB>  <TAB> payload = backslashes.tamper(payload)",if menu . options . tamper :,130
"def __init__(self, config_lists): <TAB> self.lens = len(config_lists) <TAB> self.spaces = [] <TAB> for config_list in config_lists: <MASK> key, config = config_list <TAB>  <TAB> elif isinstance(config_list, str): <TAB>  <TAB>  <TAB> key = config_list <TAB>  <TAB>  <TAB> config = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise NotImplementedError( <TAB>  <TAB>  <TAB>  <TAB> ""the type of config is Error!!! Please check the config information. Receive the type of config is {}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> type(config_list) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self.spaces.append(self._get_single_search_space(key, config)) <TAB> self.init_tokens()","if isinstance ( config_list , tuple ) :",186
"def _source_tuple(af, address, port): <TAB> # Make a high level source tuple, or return None if address and port <TAB> # are both None <TAB> if address or port: <MASK> if af == socket.AF_INET: <TAB>  <TAB>  <TAB>  <TAB> address = ""0.0.0.0"" <TAB>  <TAB>  <TAB> elif af == socket.AF_INET6: <TAB>  <TAB>  <TAB>  <TAB> address = ""::"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise NotImplementedError(f""unknown address family {af}"") <TAB>  <TAB> return (address, port) <TAB> else: <TAB>  <TAB> return None",if address is None :,144
"def test_compatibility(self) -> None: <TAB> for expected, user_agent in self.data: <TAB>  <TAB> result = self.client_get(""/compatibility"", HTTP_USER_AGENT=user_agent) <MASK> self.assert_json_success(result) <TAB>  <TAB> elif expected == ""old"": <TAB>  <TAB>  <TAB> self.assert_json_error(result, ""Client is too old"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert False  # nocoverage","if expected == ""ok"" :",114
"def __init__(self, parent_element): <TAB> if parent_element.items(): <TAB>  <TAB> self.update(dict(parent_element.items())) <TAB> for element in parent_element: <TAB>  <TAB> if len(element) > 0: <MASK> aDict = ListParser(element) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> aDict = DictParser(element) <TAB>  <TAB>  <TAB> if element.items(): <TAB>  <TAB>  <TAB>  <TAB> aDict.update(dict(element.items())) <TAB>  <TAB>  <TAB> self.update({element.tag: aDict}) <TAB>  <TAB> elif element.items(): <TAB>  <TAB>  <TAB> self.update({element.tag: dict(element.items())}) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.update({element.tag: element.text})",if element . tag == element [ 0 ] . tag :,190
"def delta_page(self, x: float = 0.0, y: float = 0.0) -> None: <TAB> if y.is_integer(): <TAB>  <TAB> y = int(y) <MASK> pass <TAB>  <TAB> elif y < 0: <TAB>  <TAB>  <TAB> self.page_up(count=-y) <TAB>  <TAB> elif y > 0: <TAB>  <TAB>  <TAB> self.page_down(count=y) <TAB>  <TAB> y = 0 <TAB> if x == 0 and y == 0: <TAB>  <TAB> return <TAB> size = self._widget.page().mainFrame().geometry() <TAB> self.delta(int(x * size.width()), int(y * size.height()))",if y == 0 :,160
"def reader(self, myself): <TAB> ok = True <TAB> line = """" <TAB> while True: <TAB>  <TAB> line = sys.stdin.readline().strip() <MASK> if not line: <TAB>  <TAB>  <TAB>  <TAB> ok = False <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif not line: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ok = True <TAB>  <TAB> self.Q.append(line) <TAB> os.kill(myself, signal.SIGTERM)",if ok :,112
"def leave(self, reason=None): <TAB> try: <TAB>  <TAB> if self.id.startswith(""C""): <TAB>  <TAB>  <TAB> log.info(""Leaving channel %s (%s)"", self, self.id) <TAB>  <TAB>  <TAB> self._bot.webclient.channels_leave(channel=self.id) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.info(""Leaving group %s (%s)"", self, self.id) <TAB>  <TAB>  <TAB> self._bot.webclient.groups_leave(channel=self.id) <TAB> except SlackAPIResponseError as e: <MASK> raise RoomError(f""Unable to leave channel. {USER_IS_BOT_HELPTEXT}"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise RoomError(e) <TAB> self._id = None","if e . error == ""user_is_bot"" :",191
"def wrap_lines(text, cols=60): <TAB> ret = """" <TAB> words = re.split(""(\s+)"", text) <TAB> linelen = 0 <TAB> for w in words: <MASK> ret += "" \\\n"" <TAB>  <TAB>  <TAB> ret += ""   "" <TAB>  <TAB>  <TAB> linelen = 0 <TAB>  <TAB> if linelen == 0 and w.strip() == """": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> ret += w <TAB>  <TAB> linelen += len(w) <TAB> return ret",if linelen + len ( w ) > cols - 1 :,123
"def transport_vmware_guestinfo(): <TAB> rpctool = ""vmware-rpctool"" <TAB> not_found = None <TAB> if not subp.which(rpctool): <TAB>  <TAB> return not_found <TAB> cmd = [rpctool, ""info-get guestinfo.ovfEnv""] <TAB> try: <TAB>  <TAB> out, _err = subp.subp(cmd) <TAB>  <TAB> if out: <TAB>  <TAB>  <TAB> return out <TAB>  <TAB> LOG.debug(""cmd %s exited 0 with empty stdout: %s"", cmd, out) <TAB> except subp.ProcessExecutionError as e: <MASK> LOG.warning(""%s exited with code %d"", rpctool, e.exit_code) <TAB>  <TAB>  <TAB> LOG.debug(e) <TAB> return not_found",if e . exit_code != 1 :,196
"def handle_noargs(self, **options): <TAB> # Inspired by Postfix's ""postconf -n"". <TAB> from django.conf import settings, global_settings <TAB> # Because settings are imported lazily, we need to explicitly load them. <TAB> settings._setup() <TAB> user_settings = module_to_dict(settings._wrapped) <TAB> default_settings = module_to_dict(global_settings) <TAB> output = [] <TAB> for key in sorted(user_settings.keys()): <MASK> output.append(""%s = %s  ###"" % (key, user_settings[key])) <TAB>  <TAB> elif user_settings[key] != default_settings[key]: <TAB>  <TAB>  <TAB> output.append(""%s = %s"" % (key, user_settings[key])) <TAB> return ""\n"".join(output)",if key not in default_settings :,196
"def channel_sizes(self): <TAB> """"""List of channel sizes: [(width, height)]."""""" <TAB> sizes = [] <TAB> for channel in self.channel_info: <TAB>  <TAB> if channel.id == ChannelID.USER_LAYER_MASK: <TAB>  <TAB>  <TAB> sizes.append((self.mask_data.width, self.mask_data.height)) <MASK> sizes.append((self.mask_data.real_width, self.mask_data.real_height)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sizes.append((self.width, self.height)) <TAB> return sizes",elif channel . id == ChannelID . REAL_USER_LAYER_MASK :,151
"def get(self, key, default=None, version=None): <TAB> fname = self._key_to_file(key, version) <TAB> try: <TAB>  <TAB> with io.open(fname, ""rb"") as f: <TAB>  <TAB>  <TAB> if not self._is_expired(f): <TAB>  <TAB>  <TAB>  <TAB> return pickle.loads(zlib.decompress(f.read())) <TAB> except IOError as e: <MASK> raise <TAB> return default",if e . errno != errno . ENOENT :,112
"def check_grads(grads_and_vars): <TAB> has_nan_ops = [] <TAB> amax_ops = [] <TAB> for grad, _ in grads_and_vars: <MASK> if isinstance(grad, tf.IndexedSlices): <TAB>  <TAB>  <TAB>  <TAB> x = grad.values <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> x = grad <TAB>  <TAB>  <TAB> has_nan_ops.append(tf.reduce_any(tf.is_nan(x))) <TAB>  <TAB>  <TAB> amax_ops.append(tf.reduce_max(tf.abs(x))) <TAB> has_nan = tf.reduce_any(has_nan_ops) <TAB> amax = tf.reduce_max(amax_ops) <TAB> return has_nan, amax",if grad is not None :,179
"def daily(self, component): <TAB> with component.repository.lock: <TAB>  <TAB> path = self.get_linguas_path(component) <MASK> self.commit_and_push(component, [path])","if self . sync_linguas ( component , path ) :",67
"def _set_posonly_args_def(self, argmts, vals): <TAB> for v in vals: <TAB>  <TAB> argmts.posonlyargs.append(v[""arg""]) <TAB>  <TAB> d = v[""default""] <TAB>  <TAB> if d is not None: <TAB>  <TAB>  <TAB> argmts.defaults.append(d) <MASK> self._set_error(""non-default argument follows default argument"")",elif argmts . defaults :,97
"def isOrHasChild(parent, child): <TAB> while child: <TAB>  <TAB> if compare(parent, child): <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> child = child.parentNode <TAB>  <TAB> if not child: <TAB>  <TAB>  <TAB> return False <MASK> child = None <TAB> return False",if child . nodeType != 1 :,76
def Proc2(IntParIO): <TAB> IntLoc = IntParIO + 10 <TAB> while 1: <MASK> IntLoc = IntLoc - 1 <TAB>  <TAB>  <TAB> IntParIO = IntLoc - IntGlob <TAB>  <TAB>  <TAB> EnumLoc = Ident1 <TAB>  <TAB> if EnumLoc == Ident1: <TAB>  <TAB>  <TAB> break <TAB> return IntParIO,"if Char1Glob == ""A"" :",90
"def _GetParserChains(self, events): <TAB> """"""Return a dict with a plugin count given a list of events."""""" <TAB> parser_chains = {} <TAB> for event in events: <TAB>  <TAB> parser_chain = getattr(event, ""parser"", None) <TAB>  <TAB> if not parser_chain: <TAB>  <TAB>  <TAB> continue <MASK> parser_chains[parser_chain] += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> parser_chains[parser_chain] = 1 <TAB> return parser_chains",if parser_chain in parser_chains :,122
"def _url_encode_impl(obj, charset, encode_keys, sort, key): <TAB> iterable = sdict() <TAB> for key, values in obj.items(): <TAB>  <TAB> if not isinstance(values, list): <TAB>  <TAB>  <TAB> values = [values] <TAB>  <TAB> iterable[key] = values <TAB> if sort: <TAB>  <TAB> iterable = sorted(iterable, key=key) <TAB> for key, values in iterable.items(): <TAB>  <TAB> for value in values: <MASK> continue <TAB>  <TAB>  <TAB> if not isinstance(key, bytes): <TAB>  <TAB>  <TAB>  <TAB> key = str(key).encode(charset) <TAB>  <TAB>  <TAB> if not isinstance(value, bytes): <TAB>  <TAB>  <TAB>  <TAB> value = str(value).encode(charset) <TAB>  <TAB>  <TAB> yield url_quote_plus(key) + ""="" + url_quote_plus(value)",if value is None :,198
"def getZoneOffset(d): <TAB> zoffs = 0 <TAB> try: <TAB>  <TAB> if d[""zulu""] == None: <TAB>  <TAB>  <TAB> zoffs = 60 * int(d[""tzhour""]) + int(d[""tzminute""]) <MASK> zoffs = -zoffs <TAB> except TypeError: <TAB>  <TAB> pass <TAB> return zoffs","if d [ ""tzsign"" ] != ""-"" :",92
"def run(self): <TAB> predictor = DefaultPredictor(self.cfg) <TAB> while True: <TAB>  <TAB> task = self.task_queue.get() <MASK> break <TAB>  <TAB> idx, data = task <TAB>  <TAB> result = predictor(data) <TAB>  <TAB> self.result_queue.put((idx, result))","if isinstance ( task , AsyncPredictor . _StopToken ) :",86
"def _VarRefOrWord(node, dynamic_arith): <TAB> # type: (arith_expr_t, bool) -> bool <TAB> with tagswitch(node) as case: <TAB>  <TAB> if case(arith_expr_e.VarRef): <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> elif case(arith_expr_e.Word): <MASK> return True <TAB> return False",if dynamic_arith :,96
"def command(self, reset=True, wait=True, wait_all=False, quiet=False): <TAB> try: <MASK> return self._success(_(""Loaded metadata index"")) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self._error(_(""Failed to load metadata index"")) <TAB> except IOError: <TAB>  <TAB> return self._error(_(""Failed to decrypt configuration, "" ""please log in!""))","if self . _idx ( reset = reset , wait = wait , wait_all = wait_all , quiet = quiet ) :",113
"def init_weights(self): <TAB> for module in self.decoder.modules(): <TAB>  <TAB> if isinstance(module, (nn.Linear, nn.Embedding)): <TAB>  <TAB>  <TAB> module.weight.data.normal_(mean=0.0, std=0.02) <TAB>  <TAB> elif isinstance(module, nn.LayerNorm): <TAB>  <TAB>  <TAB> module.bias.data.zero_() <TAB>  <TAB>  <TAB> module.weight.data.fill_(1.0) <MASK> module.bias.data.zero_() <TAB> for p in self.generator.parameters(): <TAB>  <TAB> if p.dim() > 1: <TAB>  <TAB>  <TAB> xavier_uniform_(p) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> p.data.zero_()","if isinstance ( module , nn . Linear ) and module . bias is not None :",179
"def write_conditional_formatting(worksheet): <TAB> """"""Write conditional formatting to xml."""""" <TAB> wb = worksheet.parent <TAB> for range_string, rules in iteritems(worksheet.conditional_formatting.cf_rules): <TAB>  <TAB> cf = Element(""conditionalFormatting"", {""sqref"": range_string}) <TAB>  <TAB> for rule in rules: <MASK> if rule.dxf != DifferentialStyle(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> rule.dxfId = len(wb._differential_styles) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> wb._differential_styles.append(rule.dxf) <TAB>  <TAB>  <TAB> cf.append(rule.to_tree()) <TAB>  <TAB> yield cf",if rule . dxf is not None :,164
"def _format_changelog(self, changelog): <TAB> """"""Format the changelog correctly and convert it to a list of strings"""""" <TAB> if not changelog: <TAB>  <TAB> return changelog <TAB> new_changelog = [] <TAB> for line in changelog.strip().split(""\n""): <TAB>  <TAB> line = line.strip() <MASK> new_changelog.extend(["""", line]) <TAB>  <TAB> elif line[0] == ""-"": <TAB>  <TAB>  <TAB> new_changelog.append(line) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_changelog.append(""  "" + line) <TAB> # strip trailing newline inserted by first changelog entry <TAB> if not new_changelog[0]: <TAB>  <TAB> del new_changelog[0] <TAB> return new_changelog","if line [ 0 ] == ""*"" :",168
"def __prep_write_total(self, comments, main, fallback, single): <TAB> lower = self.as_lowercased() <TAB> for k in [main, fallback, single]: <TAB>  <TAB> if k in comments: <TAB>  <TAB>  <TAB> del comments[k] <TAB> if single in lower: <TAB>  <TAB> parts = lower[single].split(""/"", 1) <MASK> comments[single] = [parts[0]] <TAB>  <TAB> if len(parts) > 1: <TAB>  <TAB>  <TAB> comments[main] = [parts[1]] <TAB> if main in lower: <TAB>  <TAB> comments[main] = lower.list(main) <TAB> if fallback in lower: <TAB>  <TAB> if main in comments: <TAB>  <TAB>  <TAB> comments[fallback] = lower.list(fallback) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> comments[main] = lower.list(fallback)",if parts [ 0 ] :,196
"def __str__(self): <TAB> result = [] <TAB> for mask, quality in self._parsed: <MASK> mask = ""%s;q=%0.*f"" % ( <TAB>  <TAB>  <TAB>  <TAB> mask, <TAB>  <TAB>  <TAB>  <TAB> min(len(str(quality).split(""."")[1]), 3), <TAB>  <TAB>  <TAB>  <TAB> quality, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> result.append(mask) <TAB> return "", "".join(result)",if quality != 1 :,104
"def allprocs(self): <TAB> common.set_plugin_members(self) <TAB> tasksaddr = self.addr_space.profile.get_symbol(""_tasks"") <TAB> queue_entry = obj.Object(""queue_entry"", offset=tasksaddr, vm=self.addr_space) <TAB> seen = [tasksaddr] <TAB> for task in queue_entry.walk_list(list_head=tasksaddr): <MASK> proc = task.bsd_info.dereference_as(""proc"") <TAB>  <TAB>  <TAB> yield proc <TAB>  <TAB> seen.append(task.obj_offset)",if task . bsd_info and task . obj_offset not in seen :,152
"def __walk_dir_tree(self, dirname): <TAB> dir_list = [] <TAB> self.__logger.debug(""__walk_dir_tree. START dir=%s"", dirname) <TAB> for f in os.listdir(dirname): <TAB>  <TAB> current = os.path.join(dirname, f) <TAB>  <TAB> if os.path.isfile(current) and f.endswith(""py""): <TAB>  <TAB>  <TAB> if self.module_registrant: <TAB>  <TAB>  <TAB>  <TAB> self._load_py_from_file(current) <TAB>  <TAB>  <TAB> dir_list.append(current) <MASK> ret = self.__walk_dir_tree(current) <TAB>  <TAB>  <TAB> if ret: <TAB>  <TAB>  <TAB>  <TAB> dir_list.append((f, ret)) <TAB> return dir_list",elif os . path . isdir ( current ) :,184
"def get_code(self, address: Address) -> bytes: <TAB> validate_canonical_address(address, title=""Storage Address"") <TAB> code_hash = self.get_code_hash(address) <TAB> if code_hash == EMPTY_SHA3: <TAB>  <TAB> return b"""" <TAB> else: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self._journaldb[code_hash] <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> raise MissingBytecode(code_hash) from KeyError <TAB>  <TAB> finally: <MASK> self._accessed_bytecodes.add(address)",if code_hash in self . _get_accessed_node_hashes ( ) :,150
"def _strftime(value): <TAB> if datetime: <TAB>  <TAB> if isinstance(value, datetime.datetime): <TAB>  <TAB>  <TAB> return ""%04d%02d%02dT%02d:%02d:%02d"" % ( <TAB>  <TAB>  <TAB>  <TAB> value.year, <TAB>  <TAB>  <TAB>  <TAB> value.month, <TAB>  <TAB>  <TAB>  <TAB> value.day, <TAB>  <TAB>  <TAB>  <TAB> value.hour, <TAB>  <TAB>  <TAB>  <TAB> value.minute, <TAB>  <TAB>  <TAB>  <TAB> value.second, <TAB>  <TAB>  <TAB> ) <TAB> if not isinstance(value, (TupleType, time.struct_time)): <MASK> value = time.time() <TAB>  <TAB> value = time.localtime(value) <TAB> return ""%04d%02d%02dT%02d:%02d:%02d"" % value[:6]",if value == 0 :,182
"def _read_mol2_records(filename): <TAB> lines = [] <TAB> start = True <TAB> with open(filename) as handle: <TAB>  <TAB> for line in handle: <TAB>  <TAB>  <TAB> if line.startswith(""@<TRIPOS>MOLECULE""): <MASK> start = False <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield lines <TAB>  <TAB>  <TAB>  <TAB>  <TAB> lines = [] <TAB>  <TAB>  <TAB> lines.append(line)",if start :,109
"def set_column_strategy(self, attrs, strategy, opts=None, opts_only=False): <TAB> strategy = self._coerce_strat(strategy) <TAB> self.is_class_strategy = False <TAB> for attr in attrs: <TAB>  <TAB> cloned = self._generate() <TAB>  <TAB> cloned.strategy = strategy <TAB>  <TAB> cloned._generate_path(self.path, attr, ""column"") <TAB>  <TAB> cloned.propagate_to_loaders = True <TAB>  <TAB> if opts: <TAB>  <TAB>  <TAB> cloned.local_opts.update(opts) <MASK> cloned.is_opts_only = True <TAB>  <TAB> cloned._set_path_strategy() <TAB> self.is_class_strategy = False",if opts_only :,172
"def decryptBlock(self, encryptedBlock): <TAB> """"""Decrypt a single block"""""" <TAB> if self.decryptBlockCount == 0:  # first call, process IV <MASK> # auto decrypt IV? <TAB>  <TAB>  <TAB> self.prior_CT_block = encryptedBlock <TAB>  <TAB>  <TAB> return """" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert len(self.iv) == self.blockSize, ""Bad IV size on CBC decryption"" <TAB>  <TAB>  <TAB> self.prior_CT_block = self.iv <TAB> dct = self.baseCipher.decryptBlock(encryptedBlock) <TAB> """""" XOR the prior decrypted CT with the prior CT """""" <TAB> dct_XOR_priorCT = xor(self.prior_CT_block, dct) <TAB> self.prior_CT_block = encryptedBlock <TAB> return dct_XOR_priorCT",if self . iv == None :,175
"def frontend_visible_config(config_dict): <TAB> visible_dict = {} <TAB> for name in CLIENT_WHITELIST: <TAB>  <TAB> if name.lower().find(""secret"") >= 0: <TAB>  <TAB>  <TAB> raise Exception(""Cannot whitelist secrets: %s"" % name) <TAB>  <TAB> if name in config_dict: <TAB>  <TAB>  <TAB> visible_dict[name] = config_dict.get(name, None) <MASK> visible_dict[""BRANDING""] = visible_dict.get(""BRANDING"", {}) <TAB>  <TAB>  <TAB> visible_dict[""BRANDING""][""logo""] = config_dict[""ENTERPRISE_LOGO_URL""] <TAB> return visible_dict","if ""ENTERPRISE_LOGO_URL"" in config_dict :",171
"def write(self, s): <TAB> if self.closed: <TAB>  <TAB> raise ValueError(""write to closed file"") <TAB> if type(s) not in (unicode, str, bytearray): <TAB>  <TAB> # See issue #19481 <TAB>  <TAB> if isinstance(s, unicode): <TAB>  <TAB>  <TAB> s = unicode.__getitem__(s, slice(None)) <TAB>  <TAB> elif isinstance(s, str): <TAB>  <TAB>  <TAB> s = str.__str__(s) <MASK> s = bytearray.__str__(s) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError(""must be string, not "" + type(s).__name__) <TAB> return self.shell.write(s, self.tags)","elif isinstance ( s , bytearray ) :",161
"def __get_kb_shortcuts(directory, filename, default_shortcuts, min_shortcuts): <TAB> shortcutstr, source = __read_first_in_directory_tree(directory, filename) <TAB> if shortcutstr is None: <TAB>  <TAB> shortcutstr = __read_or_default(filename, default_shortcuts) <MASK> source = ""[default kb_shortcuts]"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> source = filename <TAB> kb_shortcuts = __parse_kb_shortcuts(shortcutstr, min_shortcuts, source) <TAB> return kb_shortcuts",if shortcutstr == default_shortcuts :,133
"def demo(): <TAB> d = StatusProgressDialog(""A Demo"", ""Doing something..."") <TAB> import win32api <TAB> for i in range(100): <MASK> d.SetText(""Getting there..."") <TAB>  <TAB> if i == 90: <TAB>  <TAB>  <TAB> d.SetText(""Nearly done..."") <TAB>  <TAB> win32api.Sleep(20) <TAB>  <TAB> d.Tick() <TAB> d.Close()",if i == 50 :,99
"def __getattribute__(self, item): <TAB> try: <TAB>  <TAB> val = self[item] <TAB>  <TAB> if isinstance(val, str): <TAB>  <TAB>  <TAB> val = import_string(val) <MASK> val = [import_string(v) if isinstance(v, str) else v for v in val] <TAB>  <TAB> self[item] = val <TAB> except KeyError: <TAB>  <TAB> val = super(ObjDict, self).__getattribute__(item) <TAB> return val","elif isinstance ( val , ( list , tuple ) ) :",118
"def clear(self, key: Optional[str] = None): <TAB> with self.lock: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> rv = self.data[key] <TAB>  <TAB>  <TAB>  <TAB> self._heap_acc.remove((rv.acc, key)) <TAB>  <TAB>  <TAB>  <TAB> self._heap_exp.remove((rv.exp, key)) <TAB>  <TAB>  <TAB>  <TAB> del self.data[key] <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> self.data.clear() <TAB>  <TAB> self._heap_acc = [] <TAB>  <TAB> self._heap_exp = []",if key is not None :,148
"def resolve(self, path): <TAB> match = self.regex.search(path) <TAB> if match: <TAB>  <TAB> # If there are any named groups, use those as kwargs, ignoring <TAB>  <TAB> # non-named groups. Otherwise, pass all non-named arguments as <TAB>  <TAB> # positional arguments. <TAB>  <TAB> kwargs = match.groupdict() <MASK> args = () <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> args = match.groups() <TAB>  <TAB> # In both cases, pass any extra_kwargs as **kwargs. <TAB>  <TAB> kwargs.update(self.default_args) <TAB>  <TAB> return ResolverMatch(self.callback, args, kwargs, self.name)",if kwargs :,154
"def check_selected(menu, path): <TAB> selected = False <TAB> if ""url"" in menu: <TAB>  <TAB> chop_index = menu[""url""].find(""?"") <TAB>  <TAB> if chop_index == -1: <TAB>  <TAB>  <TAB> selected = path.startswith(menu[""url""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> selected = path.startswith(menu[""url""][:chop_index]) <TAB> if ""menus"" in menu: <TAB>  <TAB> for m in menu[""menus""]: <TAB>  <TAB>  <TAB> _s = check_selected(m, path) <MASK> selected = True <TAB> if selected: <TAB>  <TAB> menu[""selected""] = True <TAB> return selected",if _s :,153
"def check_match(word, word_list): <TAB> matches = set() <TAB> not_matches = set() <TAB> for word2 in word_list: <TAB>  <TAB> match = truncate_qgram(word, word2) <MASK> matches.add((word, word2)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> not_matches.add((word, word2)) <TAB> return matches, not_matches",if match > 0.6 :,102
"def _fatal_error(self, exc, message=""Fatal error on pipe transport""): <TAB> # should be called by exception handler only <TAB> if isinstance(exc, (BrokenPipeError, ConnectionResetError)): <MASK> logger.debug(""%r: %s"", self, message, exc_info=True) <TAB> else: <TAB>  <TAB> self._loop.call_exception_handler( <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB> ""message"": message, <TAB>  <TAB>  <TAB>  <TAB> ""exception"": exc, <TAB>  <TAB>  <TAB>  <TAB> ""transport"": self, <TAB>  <TAB>  <TAB>  <TAB> ""protocol"": self._protocol, <TAB>  <TAB>  <TAB> } <TAB>  <TAB> ) <TAB> self._close(exc)",if self . _loop . get_debug ( ) :,158
"def remove_existing_header(contents): <TAB> ""remove existing legal header, if any"" <TAB> retval = [] <TAB> skipping = False <TAB> start_pattern = re.compile(r""^(/[*]BEGIN_LEGAL)|(#BEGIN_LEGAL)"") <TAB> stop_pattern = re.compile(r""^[ ]*(END_LEGAL[ ]?[*]/)|(#[ ]*END_LEGAL)"") <TAB> for line in contents: <TAB>  <TAB> if start_pattern.match(line): <TAB>  <TAB>  <TAB> skipping = True <TAB>  <TAB> if skipping == False: <TAB>  <TAB>  <TAB> retval.append(line) <MASK> skipping = False <TAB> return retval",if stop_pattern . match ( line ) :,164
"def load_model(self, model_dict): <TAB> model_param = None <TAB> model_meta = None <TAB> for _, value in model_dict[""model""].items(): <TAB>  <TAB> for model in value: <TAB>  <TAB>  <TAB> if model.endswith(""Meta""): <TAB>  <TAB>  <TAB>  <TAB> model_meta = value[model] <MASK> model_param = value[model] <TAB> LOGGER.info(""load model"") <TAB> self.set_model_meta(model_meta) <TAB> self.set_model_param(model_param) <TAB> self.loss = self.get_loss_function()","if model . endswith ( ""Param"" ) :",148
"def __call__(self, exc_type, exc_value, exc_tb): <TAB> if not isinstance(exc_value, SystemExit): <TAB>  <TAB> enriched_tb = add_missing_qt_frames(exc_tb) if exc_tb else exc_tb <TAB>  <TAB> for handler in self._handlers: <MASK> break","if handler . handle ( exc_type , exc_value , enriched_tb ) :",100
"def skip_to_semicolon(s, i): <TAB> n = len(s) <TAB> while i < n: <TAB>  <TAB> c = s[i] <TAB>  <TAB> if c == "";"": <TAB>  <TAB>  <TAB> return i <TAB>  <TAB> elif c == ""'"" or c == '""': <TAB>  <TAB>  <TAB> i = g.skip_string(s, i) <TAB>  <TAB> elif g.match(s, i, ""//""): <TAB>  <TAB>  <TAB> i = g.skip_to_end_of_line(s, i) <MASK> i = g.skip_block_comment(s, i) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> i += 1 <TAB> return i","elif g . match ( s , i , ""/*"" ) :",161
"def validate(self, signature, timestamp, nonce): <TAB> if not self.token: <TAB>  <TAB> raise WeixinMsgError(""weixin token is missing"") <TAB> if self.expires_in: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> timestamp = int(timestamp) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> delta = time.time() - timestamp <MASK> return False <TAB> values = [self.token, str(timestamp), str(nonce)] <TAB> s = """".join(sorted(values)) <TAB> hsh = hashlib.sha1(s.encode(""utf-8"")).hexdigest() <TAB> return signature == hsh",if delta < 0 or delta > self . expires_in :,161
"def terminate(self): <TAB> """"""Terminates process (sends SIGTERM)"""""" <TAB> if not self._proc is None: <MASK> # Windows <TAB>  <TAB>  <TAB> self._proc.terminate() <TAB>  <TAB> elif HAS_SUBPROCESS: <TAB>  <TAB>  <TAB> # Gio.Subprocess <TAB>  <TAB>  <TAB> self._proc.send_signal(15) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # subprocess.Popen <TAB>  <TAB>  <TAB> self._proc.terminate() <TAB>  <TAB> self._proc = None <TAB>  <TAB> if IS_WINDOWS: <TAB>  <TAB>  <TAB> self._stdout.close() <TAB>  <TAB> self._cancel.cancel()",if IS_WINDOWS :,141
"def clear_bijector(bijector, _, state): <TAB> if not isinstance(bijector, tfp.bijectors.Bijector): <TAB>  <TAB> return  # skip submodules that are not bijectors <TAB> _clear_bijector_cache(bijector) <TAB> if isinstance(bijector, tfp.bijectors.Chain): <TAB>  <TAB> # recursively clear caches of sub-bijectors <TAB>  <TAB> for m in bijector.submodules: <MASK> _clear_bijector_cache(m) <TAB> return state","if isinstance ( m , tfp . bijectors . Bijector ) :",148
"def sanitize_args(a): <TAB> try: <TAB>  <TAB> args, kwargs = a <TAB>  <TAB> if isinstance(args, tuple) and isinstance(kwargs, dict): <TAB>  <TAB>  <TAB> return args, dict(kwargs) <TAB> except (TypeError, ValueError): <TAB>  <TAB> args, kwargs = (), {} <TAB> if a is not None: <TAB>  <TAB> if isinstance(a, dict): <TAB>  <TAB>  <TAB> args = tuple() <TAB>  <TAB>  <TAB> kwargs = a <MASK> if isinstance(a[-1], dict): <TAB>  <TAB>  <TAB>  <TAB> args, kwargs = a[0:-1], a[-1] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> args = a <TAB>  <TAB>  <TAB>  <TAB> kwargs = {} <TAB> return args, kwargs","elif isinstance ( a , tuple ) :",168
"def do_DELE(self, path): <TAB> """"""Delete the specified file."""""" <TAB> try: <TAB>  <TAB> path = self.ftp_path(path) <MASK> self.respond(b""550 Failed to delete file."") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> with self.config.vfs.check_access(path=path, user=self._uid, perms=""w""): <TAB>  <TAB>  <TAB>  <TAB> self.config.vfs.remove(path) <TAB>  <TAB>  <TAB>  <TAB> self.respond(b""250 File removed."") <TAB> except FSOperationNotPermitted: <TAB>  <TAB> self.respond(b""500 Operation not permitted."") <TAB> except (fs.errors.FSError, FilesystemError, FTPPrivilegeException): <TAB>  <TAB> self.respond(b""550 Failed to delete file."")",if not self . config . vfs . isfile ( path ) :,194
"def _get_conn(self): <TAB> """"""Get ServerProxy instance"""""" <TAB> if self.username and self.password: <MASK> raise NotImplementedError() <TAB>  <TAB> secure = self.scheme == ""https"" <TAB>  <TAB> return self.sp( <TAB>  <TAB>  <TAB> self.uri, <TAB>  <TAB>  <TAB> transport=BasicAuthTransport(secure, self.username, self.password), <TAB>  <TAB>  <TAB> **self.sp_kwargs <TAB>  <TAB> ) <TAB> return self.sp(self.uri, **self.sp_kwargs)","if self . scheme == ""scgi"" :",126
"def output(self): <TAB> """"""Transform self into a list of (name, value) tuples."""""" <TAB> header_list = [] <TAB> for k, v in self.items(): <MASK> k = self.encode(k) <TAB>  <TAB> if not isinstance(v, basestring): <TAB>  <TAB>  <TAB> v = str(v) <TAB>  <TAB> if isinstance(v, unicodestr): <TAB>  <TAB>  <TAB> v = self.encode(v) <TAB>  <TAB> # See header_translate_* constants above. <TAB>  <TAB> # Replace only if you really know what you're doing. <TAB>  <TAB> k = k.translate(header_translate_table, header_translate_deletechars) <TAB>  <TAB> v = v.translate(header_translate_table, header_translate_deletechars) <TAB>  <TAB> header_list.append((k, v)) <TAB> return header_list","if isinstance ( k , unicodestr ) :",197
"def gprv_implicit_orax(ii): <TAB> for i, op in enumerate(_gen_opnds(ii)): <MASK> if op.name == ""REG0"" and op_luf(op, ""GPRv_SB""): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> elif i == 1: <TAB>  <TAB>  <TAB> if op.name == ""REG1"" and op_luf(op, ""OrAX""): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> return True",if i == 0 :,151
"def one_xmm_reg_imm8(ii):  # also allows SSE4 2-imm8 instr <TAB> i, j, n = 0, 0, 0 <TAB> for op in _gen_opnds(ii): <MASK> n += 1 <TAB>  <TAB> elif op_imm8(op): <TAB>  <TAB>  <TAB> i += 1 <TAB>  <TAB> elif op_imm8_2(op): <TAB>  <TAB>  <TAB> j += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> return n == 1 and i == 1 and j <= 1",if op_reg ( op ) and op_xmm ( op ) :,141
"def pa(s, l, tokens): <TAB> for attrName, attrValue in attrs: <MASK> raise ParseException(s, l, ""no matching attribute "" + attrName) <TAB>  <TAB> if attrValue != withAttribute.ANY_VALUE and tokens[attrName] != attrValue: <TAB>  <TAB>  <TAB> raise ParseException( <TAB>  <TAB>  <TAB>  <TAB> s, <TAB>  <TAB>  <TAB>  <TAB> l, <TAB>  <TAB>  <TAB>  <TAB> ""attribute '%s' has value '%s', must be '%s'"" <TAB>  <TAB>  <TAB>  <TAB> % (attrName, tokens[attrName], attrValue), <TAB>  <TAB>  <TAB> )",if attrName not in tokens :,140
"def __code_color(self, code): <TAB> if code in self.last_dist.keys(): <TAB>  <TAB> if int(code) == 0: <TAB>  <TAB>  <TAB> return self.screen.markup.GREEN <MASK> return self.screen.markup.MAGENTA <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.screen.markup.RED <TAB> else: <TAB>  <TAB> return """"",elif int ( code ) == 314 :,97
"def loop_check(self): <TAB> in_loop = [] <TAB> # Add the tag for dfs check <TAB> for node in self.nodes: <TAB>  <TAB> node.dfs_loop_status = ""DFS_UNCHECKED"" <TAB> # Now do the job <TAB> for node in self.nodes: <TAB>  <TAB> # Run the dfs only if the node has not been already done */ <TAB>  <TAB> if node.dfs_loop_status == ""DFS_UNCHECKED"": <TAB>  <TAB>  <TAB> self.dfs_loop_search(node) <TAB>  <TAB> # If LOOP_INSIDE, must be returned <MASK> in_loop.append(node) <TAB> # Remove the tag <TAB> for node in self.nodes: <TAB>  <TAB> del node.dfs_loop_status <TAB> return in_loop","if node . dfs_loop_status == ""DFS_LOOP_INSIDE"" :",199
"def _append_modifier(code, modifier): <TAB> if modifier == ""euro"": <MASK> return code + "".ISO8859-15"" <TAB>  <TAB> _, _, encoding = code.partition(""."") <TAB>  <TAB> if encoding in (""ISO8859-15"", ""UTF-8""): <TAB>  <TAB>  <TAB> return code <TAB>  <TAB> if encoding == ""ISO8859-1"": <TAB>  <TAB>  <TAB> return _replace_encoding(code, ""ISO8859-15"") <TAB> return code + ""@"" + modifier","if ""."" not in code :",115
"def propagate_touch_to_touchable_widgets(self, touch, touch_event, *args): <TAB> triggered = False <TAB> for i in self._touchable_widgets: <TAB>  <TAB> if i.collide_point(touch.x, touch.y): <TAB>  <TAB>  <TAB> triggered = True <MASK> i.on_touch_down(touch) <TAB>  <TAB>  <TAB> elif touch_event == ""move"": <TAB>  <TAB>  <TAB>  <TAB> i.on_touch_move(touch, *args) <TAB>  <TAB>  <TAB> elif touch_event == ""up"": <TAB>  <TAB>  <TAB>  <TAB> i.on_touch_up(touch) <TAB> return triggered","if touch_event == ""down"" :",154
"def body(self): <TAB> order = [ <TAB>  <TAB> ""ok_header"", <TAB>  <TAB> ""affected_rows"", <TAB>  <TAB> ""last_insert_id"", <TAB>  <TAB> ""server_status"", <TAB>  <TAB> ""warning_count"", <TAB>  <TAB> ""state_track"", <TAB>  <TAB> ""info"", <TAB> ] <TAB> string = b"""" <TAB> for key in order: <TAB>  <TAB> item = getattr(self, key) <TAB>  <TAB> section_pack = b"""" <MASK> continue <TAB>  <TAB> elif isinstance(item, bytes): <TAB>  <TAB>  <TAB> section_pack = item <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> section_pack = getattr(self, key).toStringPacket() <TAB>  <TAB> string += section_pack <TAB> self.setBody(string) <TAB> return self._body",if item is None :,182
"def get_opnd_types_short(ii): <TAB> types = [] <TAB> for op in _gen_opnds(ii): <TAB>  <TAB> if op.oc2: <TAB>  <TAB>  <TAB> types.append(op.oc2) <TAB>  <TAB> elif op_luf_start(op, ""GPRv""): <TAB>  <TAB>  <TAB> types.append(""v"") <MASK> types.append(""z"") <TAB>  <TAB> elif op_luf_start(op, ""GPRy""): <TAB>  <TAB>  <TAB> types.append(""y"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> die(""Unhandled op type {}"".format(op)) <TAB> return types","elif op_luf_start ( op , ""GPRz"" ) :",161
"def load_name(self, name): <TAB> if name in self.args: <TAB>  <TAB> index = self.args[name] <MASK> self.add_opcodes(JavaOpcodes.ALOAD_2(), java.Map.get(name)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.add_opcodes( <TAB>  <TAB>  <TAB>  <TAB> JavaOpcodes.ALOAD_1(), <TAB>  <TAB>  <TAB>  <TAB> java.Array.get(index), <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> self.add_opcodes( <TAB>  <TAB>  <TAB> ALOAD_name(""#module""), <TAB>  <TAB>  <TAB> python.Object.get_attribute(name), <TAB>  <TAB> )",if index is None :,157
"def get_field_type(self, name): <TAB> fkey = (name, self.dummy) <TAB> target = None <TAB> op, name = name.split(""_"", 1) <TAB> if op in {""delete"", ""insert"", ""update""}: <TAB>  <TAB> target = super().get_field_type(name) <TAB>  <TAB> if target is None: <TAB>  <TAB>  <TAB> module, edb_name = self.get_module_and_name(name) <TAB>  <TAB>  <TAB> target = self.edb_schema.get((module, edb_name), None) <MASK> target = self.convert_edb_to_gql_type(target) <TAB> self._fields[fkey] = target <TAB> return target",if target is not None :,170
"def _parse_lines(self, lines): <TAB> for line in lines: <TAB>  <TAB> self.size += len(line) <TAB>  <TAB> words = line.strip().split(""\t"") <MASK> wset = set(words[1:]) <TAB>  <TAB>  <TAB> if words[0] in self.WORDS: <TAB>  <TAB>  <TAB>  <TAB> self.WORDS[words[0]] |= wset <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.WORDS[words[0]] = wset",if len ( words ) > 1 :,118
"def get_new_id(self) -> str: <TAB> with db.session.no_autoflush: <TAB>  <TAB> identifier = self.issued_at.strftime(""%Y%mU-"") + ""%06d"" % ( <TAB>  <TAB>  <TAB> EventInvoice.query.count() + 1 <TAB>  <TAB> ) <TAB>  <TAB> count = EventInvoice.query.filter_by(identifier=identifier).count() <MASK> return identifier <TAB>  <TAB> return self.get_new_id()",if count == 0 :,114
"def complete_use(self, text, *args, **kwargs): <TAB> if text: <TAB>  <TAB> all_possible_matches = filter( <TAB>  <TAB>  <TAB> lambda x: x.startswith(text), self.main_modules_dirs <TAB>  <TAB> ) <TAB>  <TAB> matches = set() <TAB>  <TAB> for match in all_possible_matches: <TAB>  <TAB>  <TAB> head, sep, tail = match[len(text) :].partition(""."") <MASK> sep = """" <TAB>  <TAB>  <TAB> matches.add("""".join((text, head, sep))) <TAB>  <TAB> return list(matches) <TAB> else: <TAB>  <TAB> return self.main_modules_dirs",if not tail :,149
"def get_arg_list_scalar_arg_dtypes(arg_types): <TAB> result = [] <TAB> for arg_type in arg_types: <TAB>  <TAB> if isinstance(arg_type, ScalarArg): <TAB>  <TAB>  <TAB> result.append(arg_type.dtype) <MASK> result.append(None) <TAB>  <TAB>  <TAB> if arg_type.with_offset: <TAB>  <TAB>  <TAB>  <TAB> result.append(np.int64) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise RuntimeError(""arg type not understood: %s"" % type(arg_type)) <TAB> return result","elif isinstance ( arg_type , VectorArg ) :",142
"def psea(pname): <TAB> """"""Parse PSEA output file."""""" <TAB> fname = run_psea(pname) <TAB> start = 0 <TAB> ss = """" <TAB> with open(fname) as fp: <TAB>  <TAB> for l in fp: <MASK> start = 1 <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if not start: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if l[0] == ""\n"": <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> ss = ss + l[0:-1] <TAB> return ss","if l [ 0 : 6 ] == "">p-sea"" :",142
"def pad_with_zeros(logits, labels): <TAB> """"""Pad labels on the length dimension to match logits length."""""" <TAB> with tf.name_scope(""pad_with_zeros"", values=[logits, labels]): <TAB>  <TAB> logits, labels = pad_to_same_length(logits, labels) <MASK> # 2-d labels. <TAB>  <TAB>  <TAB> logits, labels = pad_to_same_length(logits, labels, axis=2) <TAB>  <TAB> return logits, labels",if len ( labels . shape ) == 3 :,117
"def set_rating(self, value, songs, librarian): <TAB> count = len(songs) <TAB> if count > 1 and config.getboolean(""browsers"", ""rating_confirm_multiple""): <TAB>  <TAB> parent = qltk.get_menu_item_top_parent(self) <TAB>  <TAB> dialog = ConfirmRateMultipleDialog(parent, _(""Change _Rating""), count, value) <MASK> return <TAB> for song in songs: <TAB>  <TAB> song[""~#rating""] = value <TAB> librarian.changed(songs)",if dialog . run ( ) != Gtk . ResponseType . YES :,134
"def test_schema_plugin_name_mismatch(self): <TAB> # todo iterate over all clouds not just aws resources <TAB> for k, v in manager.resources.items(): <TAB>  <TAB> for fname, f in v.filter_registry.items(): <MASK> continue <TAB>  <TAB>  <TAB> self.assertIn(fname, f.schema[""properties""][""type""][""enum""]) <TAB>  <TAB> for aname, a in v.action_registry.items(): <TAB>  <TAB>  <TAB> self.assertIn(aname, a.schema[""properties""][""type""][""enum""])","if fname in ( ""or"" , ""and"" , ""not"" ) :",135
"def run(self, elem): <TAB> """"""Inline check for attrs at start of tail."""""" <TAB> if elem.tail: <TAB>  <TAB> m = self.INLINE_RE.match(elem.tail) <MASK> self.assign_attrs(elem, m.group(1)) <TAB>  <TAB>  <TAB> elem.tail = elem.tail[m.end() :]",if m :,86
"def _traverse(op): <TAB> if topi.tag.is_broadcast(op.tag): <TAB>  <TAB> if not op.same_as(output.op): <MASK> const_ops.append(op) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> ewise_ops.append(op) <TAB>  <TAB> for tensor in op.input_tensors: <TAB>  <TAB>  <TAB> if isinstance(tensor.op, tvm.te.PlaceholderOp): <TAB>  <TAB>  <TAB>  <TAB> ewise_inputs.append((op, tensor)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> _traverse(tensor.op) <TAB> else: <TAB>  <TAB> assert op.tag == ""dense_pack"" <TAB>  <TAB> dense_res.append(op)",if not op . axis :,174
"def toPostArgs(self): <TAB> """"""Return all arguments with openid. in front of namespaced arguments."""""" <TAB> args = {} <TAB> # Add namespace definitions to the output <TAB> for ns_uri, alias in self.namespaces.iteritems(): <MASK> continue <TAB>  <TAB> if alias == NULL_NAMESPACE: <TAB>  <TAB>  <TAB> ns_key = ""openid.ns"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ns_key = ""openid.ns."" + alias <TAB>  <TAB> args[ns_key] = ns_uri <TAB> for (ns_uri, ns_key), value in self.args.iteritems(): <TAB>  <TAB> key = self.getKey(ns_uri, ns_key) <TAB>  <TAB> args[key] = value.encode(""UTF-8"") <TAB> return args",if self . namespaces . isImplicit ( ns_uri ) :,190
"def test_issue_530_async(self): <TAB> try: <TAB>  <TAB> rtm_client = RTMClient(token=""I am not a token"", run_async=True) <TAB>  <TAB> await rtm_client.start() <TAB>  <TAB> self.fail(""Raising an error here was expected"") <TAB> except Exception as e: <TAB>  <TAB> self.assertEqual( <TAB>  <TAB>  <TAB> ""The request to the Slack API failed.\n"" <TAB>  <TAB>  <TAB> ""The server responded with: {'ok': False, 'error': 'invalid_auth'}"", <TAB>  <TAB>  <TAB> str(e), <TAB>  <TAB> ) <TAB> finally: <MASK> rtm_client.stop()",if not rtm_client . _stopped :,163
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 8: <TAB>  <TAB>  <TAB> self.set_format(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 18: <TAB>  <TAB>  <TAB> self.add_path(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,120
"def _iterate_files(self, files, root, include_checksums, relpath): <TAB> file_list = {} <TAB> for file in files: <TAB>  <TAB> exclude = False <TAB>  <TAB> # exclude defined filename patterns <TAB>  <TAB> for pattern in S3Sync.exclude_files: <MASK> exclude = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if not exclude: <TAB>  <TAB>  <TAB> full_path = root + ""/"" + file <TAB>  <TAB>  <TAB> if include_checksums: <TAB>  <TAB>  <TAB>  <TAB> # get checksum <TAB>  <TAB>  <TAB>  <TAB> checksum = self._hash_file(full_path) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> checksum = """" <TAB>  <TAB>  <TAB> file_list[relpath + file] = [full_path, checksum] <TAB> return file_list","if fnmatch . fnmatch ( file , pattern ) :",184
"def globs_relative_to_buildroot(self): <TAB> buildroot = get_buildroot() <TAB> globs = [] <TAB> for bundle in self.bundles: <TAB>  <TAB> fileset = bundle.fileset <MASK> continue <TAB>  <TAB> elif hasattr(fileset, ""filespec""): <TAB>  <TAB>  <TAB> globs += bundle.fileset.filespec[""globs""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # NB(nh): filemap is an OrderedDict, so this ordering is stable. <TAB>  <TAB>  <TAB> globs += [fast_relpath(f, buildroot) for f in bundle.filemap.keys()] <TAB> super_globs = super().globs_relative_to_buildroot() <TAB> if super_globs: <TAB>  <TAB> globs += super_globs[""globs""] <TAB> return {""globs"": globs}",if fileset is None :,187
"def __getstate__(self): <TAB> state = super(_ExpressionBase, self).__getstate__() <TAB> for i in _ExpressionBase.__pickle_slots__: <TAB>  <TAB> state[i] = getattr(self, i) <TAB> if safe_mode: <TAB>  <TAB> state[""_parent_expr""] = None <TAB>  <TAB> if self._parent_expr is not None: <TAB>  <TAB>  <TAB> _parent_expr = self._parent_expr() <MASK> state[""_parent_expr""] = _parent_expr <TAB> return state",if _parent_expr is not None :,126
"def content_state_equal(v1, v2): <TAB> ""Test whether two contentState structures are equal, ignoring 'key' properties"" <TAB> if type(v1) != type(v2): <TAB>  <TAB> return False <TAB> if isinstance(v1, dict): <TAB>  <TAB> if set(v1.keys()) != set(v2.keys()): <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return all(k == ""key"" or content_state_equal(v, v2[k]) for k, v in v1.items()) <TAB> elif isinstance(v1, list): <MASK> return False <TAB>  <TAB> return all(content_state_equal(a, b) for a, b in zip(v1, v2)) <TAB> else: <TAB>  <TAB> return v1 == v2",if len ( v1 ) != len ( v2 ) :,194
"def process_qemu_job( <TAB> file_path: str, arch_suffix: str, root_path: Path, results_dict: dict, uid: str): <TAB> result = check_qemu_executability(file_path, arch_suffix, root_path) <TAB> if result: <MASK> tmp_dict = dict(results_dict[uid][""results""]) <TAB>  <TAB>  <TAB> tmp_dict.update({arch_suffix: result}) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tmp_dict = {arch_suffix: result} <TAB>  <TAB> results_dict[uid] = {""path"": file_path, ""results"": tmp_dict}",if uid in results_dict :,158
"def _eq_meet(a, b): <TAB> a_dtype, b_dtype = _dtype(a), _dtype(b) <TAB> if a_dtype != b_dtype: <TAB>  <TAB> higher_dtype = dtypes.promote_types(a_dtype, b_dtype) <MASK> a = convert_element_type(a, b_dtype) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> b = convert_element_type(b, a_dtype) <TAB> return eq(a, b)",if higher_dtype == a_dtype :,125
"def _assign(self, trans, code): <TAB> try: <MASK> trans.order = self.order_qs().get( <TAB>  <TAB>  <TAB>  <TAB> code=code.rsplit(""-"", 1)[1], event__slug__iexact=code.rsplit(""-"", 1)[0] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> trans.order = self.order_qs().get(code=code.rsplit(""-"", 1)[-1]) <TAB> except Order.DoesNotExist: <TAB>  <TAB> return JsonResponse({""status"": ""error"", ""message"": _(""Unknown order code"")}) <TAB> else: <TAB>  <TAB> return self._retry(trans)","if ""-"" in code :",144
"def _recalculate(self): <TAB> # If the parent's path has changed, recalculate _path <TAB> parent_path = tuple(self._get_parent_path())  # Make a copy <TAB> if parent_path != self._last_parent_path: <TAB>  <TAB> spec = self._path_finder(self._name, parent_path) <TAB>  <TAB> # Note that no changes are made if a loader is returned, but we <TAB>  <TAB> #  do remember the new parent path <TAB>  <TAB> if spec is not None and spec.loader is None: <MASK> self._path = spec.submodule_search_locations <TAB>  <TAB> self._last_parent_path = parent_path  # Save the copy <TAB> return self._path",if spec . submodule_search_locations :,174
"def find_defined_variables(board_config_mks): <TAB> re_def = re.compile(""^[\s]*([\w\d_]*)[\s]*:="") <TAB> variables = dict() <TAB> for board_config_mk in board_config_mks: <TAB>  <TAB> for line in open(board_config_mk, encoding=""latin1""): <TAB>  <TAB>  <TAB> mo = re_def.search(line) <TAB>  <TAB>  <TAB> if mo is None: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> variable = mo.group(1) <MASK> continue <TAB>  <TAB>  <TAB> if variable not in variables: <TAB>  <TAB>  <TAB>  <TAB> variables[variable] = set() <TAB>  <TAB>  <TAB> variables[variable].add(board_config_mk[len(TOP) + 1 :]) <TAB> return variables",if variable in white_list :,188
"def ensure_echo_on(): <TAB> if termios: <TAB>  <TAB> fd = sys.stdin <TAB>  <TAB> if fd.isatty(): <TAB>  <TAB>  <TAB> attr_list = termios.tcgetattr(fd) <MASK> attr_list[3] |= termios.ECHO <TAB>  <TAB>  <TAB>  <TAB> if hasattr(signal, ""SIGTTOU""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> old_handler = signal.signal(signal.SIGTTOU, signal.SIG_IGN) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> old_handler = None <TAB>  <TAB>  <TAB>  <TAB> termios.tcsetattr(fd, termios.TCSANOW, attr_list) <TAB>  <TAB>  <TAB>  <TAB> if old_handler is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> signal.signal(signal.SIGTTOU, old_handler)",if not attr_list [ 3 ] & termios . ECHO :,197
def clean(self): <TAB> with self._lock: <TAB>  <TAB> min_index = min(self.indexes) <MASK> self.repository = self.repository[min_index:] <TAB>  <TAB>  <TAB> for pos in xrange(len(self.indexes)): <TAB>  <TAB>  <TAB>  <TAB> self.indexes[pos] -= min_index,if min_index >= self . CLEANUP_NUM :,86
"def generate_changes(self, old): <TAB> from weblate.trans.models.change import Change <TAB> tracked = ((""slug"", Change.ACTION_RENAME_PROJECT),) <TAB> for attribute, action in tracked: <TAB>  <TAB> old_value = getattr(old, attribute) <TAB>  <TAB> current_value = getattr(self, attribute) <MASK> Change.objects.create( <TAB>  <TAB>  <TAB>  <TAB> action=action, <TAB>  <TAB>  <TAB>  <TAB> old=old_value, <TAB>  <TAB>  <TAB>  <TAB> target=current_value, <TAB>  <TAB>  <TAB>  <TAB> project=self, <TAB>  <TAB>  <TAB>  <TAB> user=self.acting_user, <TAB>  <TAB>  <TAB> )",if old_value != current_value :,156
"def get_voices(cls): <TAB> cmd = [""flite"", ""-lv""] <TAB> voices = [] <TAB> with tempfile.SpooledTemporaryFile() as out_f: <TAB>  <TAB> subprocess.call(cmd, stdout=out_f) <TAB>  <TAB> out_f.seek(0) <TAB>  <TAB> for line in out_f: <MASK> voices.extend([x.strip() for x in line[18:].split() if x.strip()]) <TAB> return voices","if line . startswith ( ""Voices available: "" ) :",121
"def __init__(self, *args, **kwargs): <TAB> dict.__init__(self, *args, **kwargs) <TAB> for key, value in self.items(): <TAB>  <TAB> if not isinstance(key, string_types): <TAB>  <TAB>  <TAB> raise TypeError(""key must be a str, not {}"".format(type(key))) <TAB>  <TAB> if not isinstance(value, NUMERIC_TYPES): <TAB>  <TAB>  <TAB> raise TypeError(""value must be a NUMERIC_TYPES, not {}"".format(type(value))) <MASK> self[key] = float(value)","if not isinstance ( value , float ) :",132
"def read_track_raw(self, redundancy=1): <TAB> self._log(""read track raw"") <TAB> data = [] <TAB> await self.lower.write([CMD_READ_RAW, redundancy]) <TAB> while True: <TAB>  <TAB> packet = await self.lower.read() <TAB>  <TAB> if packet[-1] == 0xFF: <TAB>  <TAB>  <TAB> raise GlasgowAppletError(""FIFO overflow while reading track"") <MASK> data.append(packet[:-1]) <TAB>  <TAB>  <TAB> return b"""".join(data) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> data.append(packet)",elif packet [ - 1 ] == 0xFE :,147
"def init(self): <TAB> """"""Initialize from the database"""""" <TAB> self.__effect = None <TAB> if self.effectID: <TAB>  <TAB> self.__effect = next( <TAB>  <TAB>  <TAB> (x for x in self.fighter.item.effects.values() if x.ID == self.effectID), <TAB>  <TAB>  <TAB> None, <TAB>  <TAB> ) <MASK> pyfalog.error(""Effect (id: {0}) does not exist"", self.effectID) <TAB>  <TAB>  <TAB> return <TAB> self.build()",if self . __effect is None :,125
"def remove(self): <TAB> key = self._key <TAB> if key not in _key_to_collection: <TAB>  <TAB> raise exc.InvalidRequestError( <TAB>  <TAB>  <TAB> ""No listeners found for event %s / %r / %s "" <TAB>  <TAB>  <TAB> % (self.target, self.identifier, self.fn) <TAB>  <TAB> ) <TAB> dispatch_reg = _key_to_collection.pop(key) <TAB> for collection_ref, listener_ref in dispatch_reg.items(): <TAB>  <TAB> collection = collection_ref() <TAB>  <TAB> listener_fn = listener_ref() <MASK> collection.remove(self.with_wrapper(listener_fn))",if collection is not None and listener_fn is not None :,164
"def atbash(s): <TAB> translated = """" <TAB> for i in range(len(s)): <TAB>  <TAB> n = ord(s[i]) <TAB>  <TAB> if s[i].isalpha(): <MASK> x = n - ord(""A"") <TAB>  <TAB>  <TAB>  <TAB> translated += chr(ord(""Z"") - x) <TAB>  <TAB>  <TAB> if s[i].islower(): <TAB>  <TAB>  <TAB>  <TAB> x = n - ord(""a"") <TAB>  <TAB>  <TAB>  <TAB> translated += chr(ord(""z"") - x) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> translated += s[i] <TAB> return translated",if s [ i ] . isupper ( ) :,143
"def __str__(self, prefix="""", printElemNumber=0): <TAB> res = """" <TAB> if self.has_cost_: <TAB>  <TAB> res += prefix + ""cost <\n"" <TAB>  <TAB> res += self.cost_.__str__(prefix + ""  "", printElemNumber) <TAB>  <TAB> res += prefix + "">\n"" <TAB> cnt = 0 <TAB> for e in self.version_: <TAB>  <TAB> elm = """" <MASK> elm = ""(%d)"" % cnt <TAB>  <TAB> res += prefix + (""Version%s {\n"" % elm) <TAB>  <TAB> res += e.__str__(prefix + ""  "", printElemNumber) <TAB>  <TAB> res += prefix + ""}\n"" <TAB>  <TAB> cnt += 1 <TAB> return res",if printElemNumber :,171
"def readwrite(obj, flags): <TAB> try: <TAB>  <TAB> if flags & select.POLLIN: <TAB>  <TAB>  <TAB> obj.handle_read_event() <TAB>  <TAB> if flags & select.POLLOUT: <TAB>  <TAB>  <TAB> obj.handle_write_event() <TAB>  <TAB> if flags & select.POLLPRI: <TAB>  <TAB>  <TAB> obj.handle_expt_event() <TAB>  <TAB> if flags & (select.POLLHUP | select.POLLERR | select.POLLNVAL): <TAB>  <TAB>  <TAB> obj.handle_close() <TAB> except OSError as e: <MASK> obj.handle_error() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> obj.handle_close() <TAB> except _reraised_exceptions: <TAB>  <TAB> raise <TAB> except: <TAB>  <TAB> obj.handle_error()",if e . args [ 0 ] not in _DISCONNECTED :,192
"def mro(cls): <TAB> if self.ready: <MASK> B2.__bases__ = (B1,) <TAB>  <TAB> if cls.__name__ == ""B2"": <TAB>  <TAB>  <TAB> B1.__bases__ = (B2,) <TAB> return type.mro(cls)","if cls . __name__ == ""B1"" :",76
"def create_hyperswap_volume(self, vol_name, size, units, pool, opts): <TAB> vol_name = '""%s""' % vol_name <TAB> params = [] <TAB> if opts[""rsize""] != -1: <TAB>  <TAB> is_dr_pool = self.is_volume_type_dr_pools(pool, opts) <MASK> self.check_data_reduction_pool_params(opts) <TAB>  <TAB> params = self._get_hyperswap_volume_create_params(opts, is_dr_pool) <TAB> hyperpool = ""%s:%s"" % (pool, opts[""peer_pool""]) <TAB> self.ssh.mkvolume(vol_name, six.text_type(size), units, hyperpool, params)",if is_dr_pool :,182
"def save_new_objects(self, commit=True): <TAB> self.new_objects = [] <TAB> for form in self.extra_forms: <MASK> continue <TAB>  <TAB> # If someone has marked an add form for deletion, don't save the <TAB>  <TAB> # object. <TAB>  <TAB> if self.can_delete and self._should_delete_form(form): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> self.new_objects.append(self.save_new(form, commit=commit)) <TAB>  <TAB> if not commit: <TAB>  <TAB>  <TAB> self.saved_forms.append(form) <TAB> return self.new_objects",if not form . has_changed ( ) :,151
"def create_monitored_items(event, dispatcher): <TAB> print(""Monitored Item"") <TAB> for idx in range(len(event.response_params)): <MASK> nodeId = event.request_params.ItemsToCreate[idx].ItemToMonitor.NodeId <TAB>  <TAB>  <TAB> print(""Node {0} was created"".format(nodeId))",if event . response_params [ idx ] . StatusCode . is_good ( ) :,99
"def close(self, linger=None): <TAB> if not self.closed and self._fd is not None: <TAB>  <TAB> for event in list(chain(self._recv_futures or [], self._send_futures or [])): <MASK> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> event.future.cancel() <TAB>  <TAB>  <TAB>  <TAB> except RuntimeError: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # RuntimeError may be called during teardown <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> self._clear_io_state() <TAB> super(_AsyncSocket, self).close(linger=linger)",if not event . future . done ( ) :,135
"def stop_actors(self, monitor): <TAB> """"""Maintain the number of workers by spawning or killing as required"""""" <TAB> if monitor.cfg.workers: <TAB>  <TAB> num_to_kill = len(self.managed_actors) - monitor.cfg.workers <TAB>  <TAB> for i in range(num_to_kill, 0, -1): <TAB>  <TAB>  <TAB> w, kage = 0, sys.maxsize <TAB>  <TAB>  <TAB> for worker in self.managed_actors.values(): <TAB>  <TAB>  <TAB>  <TAB> age = worker.impl.age <MASK> w, kage = worker, age <TAB>  <TAB>  <TAB> self.manage_actor(monitor, w, True)",if age < kage :,160
"def get_version(module): <TAB> for key in version_keys: <TAB>  <TAB> if hasattr(module, key): <TAB>  <TAB>  <TAB> version = getattr(module, key) <MASK> version = get_version(version) <TAB>  <TAB>  <TAB> return version <TAB> return ""Unknown""","if isinstance ( version , types . ModuleType ) :",77
"def getBigramProb(self, w1, w2): <TAB> ""prob of seeing words w1 w2 next to each other."" <TAB> w1 = w1.lower() <TAB> w2 = w2.lower() <TAB> val1 = self.bigrams.get(w1) <TAB> if val1 != None: <TAB>  <TAB> val2 = val1.get(w2) <MASK> return val2 <TAB>  <TAB> return self.addK / ( <TAB>  <TAB>  <TAB> self.getUnigramProb(w1) * self.numUniqueWords + self.numUniqueWords <TAB>  <TAB> ) <TAB> return 0",if val2 != None :,147
"def _getPartAbbreviation(self): <TAB> if self._partAbbreviation is not None: <TAB>  <TAB> return self._partAbbreviation <TAB> elif ""_partAbbreviation"" in self._cache: <TAB>  <TAB> return self._cache[""_partAbbreviation""] <TAB> else: <TAB>  <TAB> pn = None <TAB>  <TAB> for e in self.recurse().getElementsByClass(""Instrument""): <TAB>  <TAB>  <TAB> pn = e.partAbbreviation <TAB>  <TAB>  <TAB> if pn is None: <TAB>  <TAB>  <TAB>  <TAB> pn = e.instrumentAbbreviation <MASK> break <TAB>  <TAB> self._cache[""_partAbbreviation""] = pn <TAB>  <TAB> return pn",if pn is not None :,158
"def set_value(self, value, storedtime=None): <TAB> self.namespace.acquire_write_lock() <TAB> try: <MASK> storedtime = time.time() <TAB>  <TAB> debug( <TAB>  <TAB>  <TAB> ""set_value stored time %r expire time %r"", storedtime, self.expire_argument <TAB>  <TAB> ) <TAB>  <TAB> self.namespace.set_value( <TAB>  <TAB>  <TAB> self.key, <TAB>  <TAB>  <TAB> (storedtime, self.expire_argument, value), <TAB>  <TAB>  <TAB> expiretime=self.expire_argument, <TAB>  <TAB> ) <TAB> finally: <TAB>  <TAB> self.namespace.release_write_lock()",if storedtime is None :,154
"def setRadioSquare(self, title, square=True): <TAB> if self.platform == self.MAC: <TAB>  <TAB> gui.warn(""Square radiobuttons not available on Mac, for radiobutton %s"", title) <TAB> elif not self.ttkFlag: <TAB>  <TAB> for k, v in self.widgetManager.group(WIDGET_NAMES.RadioButton).items(): <TAB>  <TAB>  <TAB> if k.startswith(title + ""-""): <MASK> v.config(indicatoron=1) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> v.config(indicatoron=0) <TAB> else: <TAB>  <TAB> gui.warn( <TAB>  <TAB>  <TAB> ""Square radiobuttons not available in ttk mode, for radiobutton %s"", title <TAB>  <TAB> )",if square :,177
"def render_func(self, node): <TAB> if node.id in DEFAULT_FUNCTIONS: <TAB>  <TAB> f = DEFAULT_FUNCTIONS[node.id] <MASK> return f.sympy_func <TAB> # special workaround for the ""int"" function <TAB> if node.id == ""int"": <TAB>  <TAB> return sympy.Function(""int_"") <TAB> else: <TAB>  <TAB> return sympy.Function(node.id)","if f . sympy_func is not None and isinstance ( f . sympy_func , sympy . FunctionClass ) :",117
"def __init__(self, source_definition, **kw): <TAB> super(RekallEFilterArtifacts, self).__init__(source_definition, **kw) <TAB> for column in self.fields: <TAB>  <TAB> if ""name"" not in column or ""type"" not in column: <TAB>  <TAB>  <TAB> raise errors.FormatError( <TAB>  <TAB>  <TAB>  <TAB> u""Field definition should have both name and type."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> mapped_type = column[""type""] <MASK> raise errors.FormatError(u""Unsupported type %s."" % mapped_type)",if mapped_type not in self . allowed_types :,143
"def run(self, lines): <TAB> """"""Match and store Fenced Code Blocks in the HtmlStash."""""" <TAB> text = ""\n"".join(lines) <TAB> while 1: <TAB>  <TAB> m = FENCED_BLOCK_RE.search(text) <MASK> lang = """" <TAB>  <TAB>  <TAB> if m.group(""lang""): <TAB>  <TAB>  <TAB>  <TAB> lang = LANG_TAG % m.group(""lang"") <TAB>  <TAB>  <TAB> code = CODE_WRAP % (lang, self._escape(m.group(""code""))) <TAB>  <TAB>  <TAB> placeholder = self.markdown.htmlStash.store(code, safe=True) <TAB>  <TAB>  <TAB> text = ""%s\n%s\n%s"" % (text[: m.start()], placeholder, text[m.end() :]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> return text.split(""\n"")",if m :,198
"def GetDisplayNameOf(self, pidl, flags): <TAB> item = pidl_to_item(pidl) <TAB> if flags & shellcon.SHGDN_FORPARSING: <MASK> return item[""name""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if flags & shellcon.SHGDN_FORADDRESSBAR: <TAB>  <TAB>  <TAB>  <TAB> sigdn = shellcon.SIGDN_DESKTOPABSOLUTEEDITING <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> sigdn = shellcon.SIGDN_DESKTOPABSOLUTEPARSING <TAB>  <TAB>  <TAB> parent = shell.SHGetNameFromIDList(self.pidl, sigdn) <TAB>  <TAB>  <TAB> return parent + ""\\"" + item[""name""] <TAB> else: <TAB>  <TAB> return item[""name""]",if flags & shellcon . SHGDN_INFOLDER :,188
"def test_buffer_play_stop(filled_buffer): <TAB> assert filled_buffer.current_position[0] == 0 <TAB> filled_buffer.play() <TAB> for _ in range(100): <TAB>  <TAB> assert filled_buffer.is_playing <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> time.sleep(0.001) <TAB> else: <TAB>  <TAB> pytest.fail(""Did not advance position in buffer while playing."") <TAB> filled_buffer.stop() <TAB> assert not filled_buffer.is_playing <TAB> pos = filled_buffer.current_position <TAB> for _ in range(10): <TAB>  <TAB> assert filled_buffer.current_position == pos <TAB>  <TAB> time.sleep(0.001)",if filled_buffer . current_position [ 0 ] > 0 :,179
"def delete_service(service): <TAB> try: <TAB>  <TAB> win32serviceutil.RemoveService(service) <TAB>  <TAB> logger.info( <TAB>  <TAB>  <TAB> ""Services: Succesfully removed service '{service}'"".format(service=service) <TAB>  <TAB> ) <TAB> except pywintypes.error as e: <TAB>  <TAB> errors = ( <TAB>  <TAB>  <TAB> winerror.ERROR_SERVICE_DOES_NOT_EXIST, <TAB>  <TAB>  <TAB> winerror.ERROR_SERVICE_NOT_ACTIVE, <TAB>  <TAB>  <TAB> winerror.ERROR_SERVICE_MARKED_FOR_DELETE, <TAB>  <TAB> ) <MASK> logger.exception( <TAB>  <TAB>  <TAB>  <TAB> ""Services: Failed to remove service '{service}'"".format(service=service) <TAB>  <TAB>  <TAB> )",if not any ( error == e . winerror for error in errors ) :,174
"def connect_to_server(self, server_cls): <TAB> server = client = None <TAB> try: <TAB>  <TAB> sock, port = bind_unused_port() <TAB>  <TAB> server = server_cls(ssl_options=_server_ssl_options()) <TAB>  <TAB> server.add_socket(sock) <TAB>  <TAB> client = SSLIOStream(socket.socket(), ssl_options=dict(cert_reqs=ssl.CERT_NONE)) <TAB>  <TAB> yield client.connect((""127.0.0.1"", port)) <TAB>  <TAB> self.assertIsNotNone(client.socket.cipher()) <TAB> finally: <TAB>  <TAB> if server is not None: <TAB>  <TAB>  <TAB> server.stop() <MASK> client.close()",if client is not None :,168
"def allow_request(self, request, view): <TAB> request.server = None <TAB> allow = True <TAB> view_name = view.get_view_name() <TAB> allowed_views = [u""System Data"", u""Collectd Data"", u""Legacy System Data""] <TAB> if view_name in allowed_views: <TAB>  <TAB> server_key = view.kwargs.get(""server_key"") <TAB>  <TAB> server = server_model.get_server_by_key(server_key) <TAB>  <TAB> if server: <TAB>  <TAB>  <TAB> request.server = server  # Needed in the Models <TAB>  <TAB>  <TAB> server_status = throttle_status(server=server) <MASK> allow = False <TAB> return allow",if server_status . allow == False :,173
"def log_start(self, prefix, msg): <TAB> with self._log_lock: <MASK> if self._last_log_prefix is not None: <TAB>  <TAB>  <TAB>  <TAB> self._log_file.write(""\n"") <TAB>  <TAB>  <TAB> self._log_file.write(prefix) <TAB>  <TAB> self._log_file.write(msg) <TAB>  <TAB> self._last_log_prefix = prefix",if self . _last_log_prefix != prefix :,105
"def override(self, user_conf: dict): <TAB> for k, v in user_conf.items(): <TAB>  <TAB> # handle ES options, don't override entire dict if one key is passed <MASK> for subkey, subval in v.items(): <TAB>  <TAB>  <TAB>  <TAB> self.SEARCH_CONF[subkey] = subval <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> setattr(self, k, v)","if k == ""SEARCH_CONF"" :",101
"def emit_classattribs(self, typebld): <TAB> if hasattr(self, ""_clrclassattribs""): <TAB>  <TAB> for attrib_info in self._clrclassattribs: <TAB>  <TAB>  <TAB> if isinstance(attrib_info, type): <TAB>  <TAB>  <TAB>  <TAB> ci = clr.GetClrType(attrib_info).GetConstructor(()) <TAB>  <TAB>  <TAB>  <TAB> cab = CustomAttributeBuilder(ci, ()) <MASK> cab = attrib_info.GetBuilder() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> make_decorator = attrib_info() <TAB>  <TAB>  <TAB>  <TAB> cab = make_decorator.GetBuilder() <TAB>  <TAB>  <TAB> typebld.SetCustomAttribute(cab)","elif isinstance ( attrib_info , CustomAttributeDecorator ) :",166
"def load_classes(module, base, blacklist): <TAB> classes = [] <TAB> for attr in dir(module): <TAB>  <TAB> attr = getattr(module, attr) <TAB>  <TAB> if inspect.isclass(attr): <TAB>  <TAB>  <TAB> if issubclass(attr, base): <MASK> classes.append(attr) <TAB> return classes",if attr is not base and attr not in blacklist :,90
"def search_scopes(self, key): <TAB> for scope in self.scopes: <MASK> return getattr(scope, key) <TAB>  <TAB> if hasattr(scope, ""__getitem__""): <TAB>  <TAB>  <TAB> if key in scope: <TAB>  <TAB>  <TAB>  <TAB> return scope[key]","if hasattr ( scope , key ) :",70
"def get_cfg_dict(self, with_meta=True): <TAB> options_dict = self.merged_options <TAB> if with_meta: <TAB>  <TAB> if self.plugin: <TAB>  <TAB>  <TAB> options_dict.update( <TAB>  <TAB>  <TAB>  <TAB> {""package"": ""yandextank.plugins.{}"".format(self.plugin)} <TAB>  <TAB>  <TAB> ) <MASK> options_dict.update({""enabled"": self.enabled}) <TAB> return options_dict",if self . enabled is not None :,111
"def render(self, context): <TAB> for condition, nodelist in self.conditions_nodelists: <MASK> # if / elif clause <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> match = condition.eval(context) <TAB>  <TAB>  <TAB> except VariableDoesNotExist: <TAB>  <TAB>  <TAB>  <TAB> match = None <TAB>  <TAB> else:  # else clause <TAB>  <TAB>  <TAB> match = True <TAB>  <TAB> if match: <TAB>  <TAB>  <TAB> return nodelist.render(context) <TAB> return """"",if condition is not None :,109
"def main(): <TAB> base = sys.argv[1] <TAB> filenames = sys.argv[2:] <TAB> out = OutputByLength(base) <TAB> n = 0 <TAB> for filename in filenames: <TAB>  <TAB> print(""opening"") <TAB>  <TAB> for record in screed.open(filename): <TAB>  <TAB>  <TAB> out.save(record.name, record.sequence) <TAB>  <TAB>  <TAB> n += 1 <MASK> print(""..."", n)",if n % 10000 == 0 :,110
"def load_cases(full_path): <TAB> all_test_data = json.load(open(full_path), object_pairs_hook=OrderedDict) <TAB> for test_data in all_test_data: <TAB>  <TAB> given = test_data[""given""] <TAB>  <TAB> for case in test_data[""cases""]: <TAB>  <TAB>  <TAB> if ""result"" in case: <TAB>  <TAB>  <TAB>  <TAB> test_type = ""result"" <TAB>  <TAB>  <TAB> elif ""error"" in case: <TAB>  <TAB>  <TAB>  <TAB> test_type = ""error"" <MASK> test_type = ""bench"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise RuntimeError(""Unknown test type: %s"" % json.dumps(case)) <TAB>  <TAB>  <TAB> yield (given, test_type, case)","elif ""bench"" in case :",183
"def readline(self): <TAB> if self.peek is not None: <TAB>  <TAB> return """" <TAB> line = self.file.readline() <TAB> if not line: <TAB>  <TAB> return line <TAB> if self.boundary: <TAB>  <TAB> if line == self.boundary + ""\n"": <TAB>  <TAB>  <TAB> self.peek = line <TAB>  <TAB>  <TAB> return """" <MASK> self.peek = line <TAB>  <TAB>  <TAB> return """" <TAB> return line","if line == self . boundary + ""--\n"" :",109
"def _get_cache_value(self, key, empty, type): <TAB> """"""Used internally by the accessor properties."""""" <TAB> if type is bool: <TAB>  <TAB> return key in self <TAB> if key in self: <TAB>  <TAB> value = self[key] <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB> return empty <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> value = type(value) <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> return value <TAB> return None",elif type is not None :,119
"def _load_from_data(self, data): <TAB> super(CliCommandHelpFile, self)._load_from_data(data) <TAB> if isinstance(data, str) or not self.parameters or not data.get(""parameters""): <TAB>  <TAB> return <TAB> loaded_params = [] <TAB> loaded_param = {} <TAB> for param in self.parameters: <TAB>  <TAB> loaded_param = next( <TAB>  <TAB>  <TAB> (n for n in data[""parameters""] if n[""name""] == param.name), None <TAB>  <TAB> ) <MASK> param.update_from_data(loaded_param) <TAB>  <TAB> loaded_params.append(param) <TAB> self.parameters = loaded_params",if loaded_param :,162
"def __str__(self): <TAB> s = super().__str__() <TAB> if self.print_suggestions: <TAB>  <TAB> possible_keys = set(self.captured_args) - self.SPECIAL_ARGS <MASK> s += ""\nPossible config keys are: {}"".format(possible_keys) <TAB> return s",if possible_keys :,77
"def family_add(self, handle_list): <TAB> if self.active: <TAB>  <TAB> person = self.get_active() <MASK> while not self.change_person(person): <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.change_person(None) <TAB> else: <TAB>  <TAB> self.dirty = True",if person :,85
"def recv_into(self, buffer, nbytes=None, flags=0): <TAB> if buffer and (nbytes is None): <TAB>  <TAB> nbytes = len(buffer) <TAB> elif nbytes is None: <TAB>  <TAB> nbytes = 1024 <TAB> if self._sslobj: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""non-zero flags not allowed in calls to recv_into() on %s"" <TAB>  <TAB>  <TAB>  <TAB> % self.__class__ <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> tmp_buffer = self.read(nbytes) <TAB>  <TAB> v = len(tmp_buffer) <TAB>  <TAB> buffer[:v] = tmp_buffer <TAB>  <TAB> return v <TAB> else: <TAB>  <TAB> return socket.recv_into(self, buffer, nbytes, flags)",if flags != 0 :,174
"def removeInsideIslands(self): <TAB> self.CleanPath = [] <TAB> cleanpath = Path(""Path"") <TAB> for path in self.NewPaths: <TAB>  <TAB> for seg in path: <TAB>  <TAB>  <TAB> inside = False <TAB>  <TAB>  <TAB> for island in self.IntersectedIslands: <TAB>  <TAB>  <TAB>  <TAB> issegin = island.isSegInside(seg) == 1 <TAB>  <TAB>  <TAB>  <TAB> if issegin: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if not seg in island: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> inside = True <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <MASK> cleanpath.append(seg) <TAB> cleanpath = cleanpath.split2contours() <TAB> self.CleanPath.extend(cleanpath)",if not inside :,176
"def ETA(self): <TAB> if self.done: <TAB>  <TAB> prefix = ""Done"" <TAB>  <TAB> t = self.elapsed <TAB>  <TAB> # import pdb; pdb.set_trace() <TAB> else: <TAB>  <TAB> prefix = ""ETA "" <TAB>  <TAB> if self.max is None: <TAB>  <TAB>  <TAB> t = -1 <MASK> t = 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # import pdb; pdb.set_trace() <TAB>  <TAB>  <TAB> t = float(self.max - self.min) <TAB>  <TAB>  <TAB> t /= self.cur - self.min <TAB>  <TAB>  <TAB> t = (t - 1) * self.elapsed <TAB> return ""%s: %s"" % (prefix, self.format_duration(t))",elif self . elapsed == 0 or ( self . cur == self . min ) :,184
"def columnToDataIndex(self, columnIndex): <TAB> c = 0 <TAB> for dataIndex, accessor in enumerate(self.vectorDataAccessors()): <TAB>  <TAB> nc = accessor.numColumns() <TAB>  <TAB> if c + nc > columnIndex: <MASK> return (dataIndex, -1) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return (dataIndex, columnIndex - c) <TAB>  <TAB> c += nc <TAB> raise IndexError(columnIndex)",if nc == 1 :,112
"def as_nodes(self, files): <TAB> """"""Returns a list of waflib.Nodes from a list of string of file paths"""""" <TAB> nodes = [] <TAB> for x in files: <TAB>  <TAB> if not isinstance(x, str): <TAB>  <TAB>  <TAB> d = x <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> d = self.srcnode.find_node(x) <MASK> raise Errors.WafError(""File '%s' was not found"" % x) <TAB>  <TAB> nodes.append(d) <TAB> return nodes",if not d :,127
"def register_extension(ext): <TAB> nonlocal commands <TAB> try: <TAB>  <TAB> parser = subparsers.add_parser(ext.name) <MASK> # current way, class based. <TAB>  <TAB>  <TAB> cmd = ext.plugin() <TAB>  <TAB>  <TAB> cmd.add_arguments(parser) <TAB>  <TAB>  <TAB> cmd.__name__ = ext.name <TAB>  <TAB>  <TAB> commands[ext.name] = cmd.handle <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # old school, function based. <TAB>  <TAB>  <TAB> commands[ext.name] = ext.plugin(parser) <TAB> except Exception: <TAB>  <TAB> logger.exception(""Error while loading command {}."".format(ext.name))","if isinstance ( ext . plugin , type ) and issubclass ( ext . plugin , BaseCommand ) :",171
"def names(self): <TAB> ret = {} <TAB> for line in dopen(""/proc/interrupts""): <TAB>  <TAB> l = line.split() <MASK> continue <TAB>  <TAB> l1 = l[0].split("":"")[0] <TAB>  <TAB> ### Cleanup possible names from /proc/interrupts <TAB>  <TAB> l2 = "" "".join(l[cpunr + 3 :]) <TAB>  <TAB> l2 = l2.replace(""_hcd:"", ""/"") <TAB>  <TAB> l2 = re.sub(""@pci[:\d+\.]+"", """", l2) <TAB>  <TAB> l2 = re.sub(""ahci\[[:\da-z\.]+\]"", ""ahci"", l2) <TAB>  <TAB> ret[l1] = l2 <TAB> return ret",if len ( l ) <= cpunr :,178
"def formatweekday(self, day, width): <TAB> with TimeEncoding(self.locale) as encoding: <TAB>  <TAB> if width >= 9: <TAB>  <TAB>  <TAB> names = day_name <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> names = day_abbr <TAB>  <TAB> name = names[day] <MASK> name = name.decode(encoding) <TAB>  <TAB> return name[:width].center(width)",if encoding is not None :,97
"def __walk_dir_tree(self, dirname): <TAB> dir_list = [] <TAB> self.__logger.debug(""__walk_dir_tree. START dir=%s"", dirname) <TAB> for f in os.listdir(dirname): <TAB>  <TAB> current = os.path.join(dirname, f) <MASK> if self.module_registrant: <TAB>  <TAB>  <TAB>  <TAB> self._load_py_from_file(current) <TAB>  <TAB>  <TAB> dir_list.append(current) <TAB>  <TAB> elif os.path.isdir(current): <TAB>  <TAB>  <TAB> ret = self.__walk_dir_tree(current) <TAB>  <TAB>  <TAB> if ret: <TAB>  <TAB>  <TAB>  <TAB> dir_list.append((f, ret)) <TAB> return dir_list","if os . path . isfile ( current ) and f . endswith ( ""py"" ) :",184
"def _EvalInScriptedSection(self, codeBlock, globals, locals=None): <TAB> if self.debugManager: <TAB>  <TAB> self.debugManager.OnEnterScript() <MASK> return self.debugManager.adb.runeval(codeBlock, globals, locals) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return eval(codeBlock, globals, locals) <TAB> else: <TAB>  <TAB> return eval(codeBlock, globals, locals)",if self . debugManager . adb . appDebugger :,113
"def load_multiple(fh, position=None, end=None): <TAB> loaded = list() <TAB> while position < end: <TAB>  <TAB> new_box = load(fh, position, end) <MASK> print(""Error, failed to load box."") <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> loaded.append(new_box) <TAB>  <TAB> position = new_box.position + new_box.size() <TAB> return loaded",if new_box is None :,105
"def test_loadTestsFromName__module_not_loaded(self): <TAB> # We're going to try to load this module as a side-effect, so it <TAB> # better not be loaded before we try. <TAB> # <TAB> module_name = ""unittest2.test.dummy"" <TAB> sys.modules.pop(module_name, None) <TAB> loader = unittest2.TestLoader() <TAB> try: <TAB>  <TAB> suite = loader.loadTestsFromName(module_name) <TAB>  <TAB> self.assertIsInstance(suite, loader.suiteClass) <TAB>  <TAB> self.assertEqual(list(suite), []) <TAB>  <TAB> # module should now be loaded, thanks to loadTestsFromName() <TAB>  <TAB> self.assertIn(module_name, sys.modules) <TAB> finally: <MASK> del sys.modules[module_name]",if module_name in sys . modules :,190
"def copy_file(s, d, xform=None): <TAB> with open(s, ""rb"") as f: <TAB>  <TAB> text = f.read() <TAB> if xform: <TAB>  <TAB> (d, text) = xform(d, text) <TAB> if os.path.exists(d): <MASK> print >>sys.stderr, ""Overwriting %s."" % d <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print >>sys.stderr, ""Not overwriting %s."" % d <TAB>  <TAB>  <TAB> return <TAB> else: <TAB>  <TAB> print >>sys.stderr, ""Writing %s."" % d <TAB> with open(d, ""wb"") as f: <TAB>  <TAB> f.write(text)",if opts . force :,162
"def __setitem__(self, index, image): <TAB> if isinstance(index, slice): <TAB>  <TAB> tmp_idx = self.current_index <TAB>  <TAB> slice_ = self.validate_slice(index) <TAB>  <TAB> del self[slice_] <TAB>  <TAB> self.extend(image, offset=slice_.start) <TAB>  <TAB> self.current_index = tmp_idx <TAB> else: <MASK> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""image must be an instance of wand.image."" <TAB>  <TAB>  <TAB>  <TAB> ""BaseImage, not "" + repr(image) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> with self.index_context(index) as index: <TAB>  <TAB>  <TAB> library.MagickRemoveImage(self.image.wand) <TAB>  <TAB>  <TAB> library.MagickAddImage(self.image.wand, image.wand)","if not isinstance ( image , BaseImage ) :",196
"def _configure_legacy_instrument_class(self): <TAB> if self.inherits: <TAB>  <TAB> self.dispatch._update(self.inherits.dispatch) <TAB>  <TAB> super_extensions = set( <TAB>  <TAB>  <TAB> chain(*[m._deprecated_extensions for m in self.inherits.iterate_to_root()]) <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> super_extensions = set() <TAB> for ext in self._deprecated_extensions: <MASK> ext._adapt_instrument_class(self, ext)",if ext not in super_extensions :,125
"def tearDown(self): <TAB> exc, _, _ = sys.exc_info() <TAB> if exc: <TAB>  <TAB> try: <MASK> diags = self.obj.get_error_diagnostics() <TAB>  <TAB>  <TAB>  <TAB> if diags: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for line in diags: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ROOT_LOGGER.info(line) <TAB>  <TAB> except BaseException: <TAB>  <TAB>  <TAB> pass <TAB> if self.captured_logger: <TAB>  <TAB> self.captured_logger.removeHandler(self.log_recorder) <TAB>  <TAB> self.log_recorder.close() <TAB> sys.stdout = self.stdout_backup <TAB> super(BZTestCase, self).tearDown()","if hasattr ( self , ""obj"" ) and isinstance ( self . obj , SelfDiagnosable ) :",179
"def number_operators(self, a, b, skip=[]): <TAB> dict = {""a"": a, ""b"": b} <TAB> for name, expr in self.binops.items(): <MASK> name = ""__%s__"" % name <TAB>  <TAB>  <TAB> if hasattr(a, name): <TAB>  <TAB>  <TAB>  <TAB> res = eval(expr, dict) <TAB>  <TAB>  <TAB>  <TAB> self.binop_test(a, b, res, expr, name) <TAB> for name, expr in list(self.unops.items()): <TAB>  <TAB> if name not in skip: <TAB>  <TAB>  <TAB> name = ""__%s__"" % name <TAB>  <TAB>  <TAB> if hasattr(a, name): <TAB>  <TAB>  <TAB>  <TAB> res = eval(expr, dict) <TAB>  <TAB>  <TAB>  <TAB> self.unop_test(a, res, expr, name)",if name not in skip :,189
"def _parse_cachecontrol(self, r): <TAB> if r not in self._cc_parsed: <TAB>  <TAB> cch = r.headers.get(b""Cache-Control"", b"""") <TAB>  <TAB> parsed = parse_cachecontrol(cch) <MASK> for key in self.ignore_response_cache_controls: <TAB>  <TAB>  <TAB>  <TAB> parsed.pop(key, None) <TAB>  <TAB> self._cc_parsed[r] = parsed <TAB> return self._cc_parsed[r]","if isinstance ( r , Response ) :",121
"def make_pattern(wtree): <TAB> subpattern = [] <TAB> for part in wtree[1:-1]: <TAB>  <TAB> if isinstance(part, list): <TAB>  <TAB>  <TAB> part = make_pattern(part) <MASK> for c in part: <TAB>  <TAB>  <TAB>  <TAB> # Meta-characters cannot be quoted <TAB>  <TAB>  <TAB>  <TAB> if c in special_chars: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise GlobError() <TAB>  <TAB> subpattern.append(part) <TAB> return """".join(subpattern)","elif wtree [ 0 ] != """" :",123
"def iterjlines(f, header, missing): <TAB> it = iter(f) <TAB> if header is None: <TAB>  <TAB> header = list() <TAB>  <TAB> peek, it = iterpeek(it, 1) <TAB>  <TAB> json_obj = json.loads(peek) <MASK> header += [k for k in json_obj.keys() if k not in header] <TAB> yield tuple(header) <TAB> for o in it: <TAB>  <TAB> json_obj = json.loads(o) <TAB>  <TAB> yield tuple(json_obj[f] if f in json_obj else missing for f in header)","if hasattr ( json_obj , ""keys"" ) :",149
"def logprob(self, sample): <TAB> if self._log: <TAB>  <TAB> return self._prob_dict.get(sample, _NINF) <TAB> else: <TAB>  <TAB> if sample not in self._prob_dict: <TAB>  <TAB>  <TAB> return _NINF <MASK> return _NINF <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return math.log(self._prob_dict[sample], 2)",elif self . _prob_dict [ sample ] == 0 :,102
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> length = d.getVarInt32() <TAB>  <TAB>  <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB>  <TAB>  <TAB> d.skip(length) <TAB>  <TAB>  <TAB> self.add_public_certificate_list().TryMerge(tmp) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 16: <TAB>  <TAB>  <TAB> self.set_max_client_cache_time_in_second(d.getVarInt64()) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,181
"def acquire(self, blocking=True, timeout=None): <TAB> if not blocking and timeout is not None: <TAB>  <TAB> raise ValueError(""can't specify timeout for non-blocking acquire"") <TAB> rc = False <TAB> endtime = None <TAB> self._cond.acquire() <TAB> while self._value == 0: <MASK> break <TAB>  <TAB> if timeout is not None: <TAB>  <TAB>  <TAB> if endtime is None: <TAB>  <TAB>  <TAB>  <TAB> endtime = _time() + timeout <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> timeout = endtime - _time() <TAB>  <TAB>  <TAB>  <TAB> if timeout <= 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> self._cond.wait(timeout) <TAB> else: <TAB>  <TAB> self._value = self._value - 1 <TAB>  <TAB> rc = True <TAB> self._cond.release() <TAB> return rc",if not blocking :,194
def run_train_loop(self): <TAB> self.begin_training() <TAB> for _ in self.yield_train_step(): <TAB>  <TAB> if self.should_save_model(): <TAB>  <TAB>  <TAB> self.save_model() <TAB>  <TAB> if self.should_save_checkpoint(): <TAB>  <TAB>  <TAB> self.save_checkpoint() <MASK> self.eval_model() <TAB>  <TAB> if self.should_break_training(): <TAB>  <TAB>  <TAB> break <TAB> self.eval_model() <TAB> self.done_training() <TAB> return self.returned_result(),if self . should_eval_model ( ) :,139
"def scrape_me(url_path, **options): <TAB> host_name = ( <TAB>  <TAB> get_host_name(url_path) if not options.get(""test"", False) else ""test_wild_mode"" <TAB> ) <TAB> try: <TAB>  <TAB> scraper = SCRAPERS[host_name] <TAB> except KeyError: <MASK> wild_scraper = SchemaScraperFactory.generate(url_path, **options) <TAB>  <TAB>  <TAB> if not wild_scraper.schema.data: <TAB>  <TAB>  <TAB>  <TAB> raise NoSchemaFoundInWildMode(url_path) <TAB>  <TAB>  <TAB> return wild_scraper <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise WebsiteNotImplementedError(host_name) <TAB> return scraper(url_path, **options)","if options . get ( ""wild_mode"" , False ) :",197
"def iter_expressions(self): <TAB> if not self._isrecord: <TAB>  <TAB> tri_attr_context = [(""target"", SPECIAL_INOUT)] <TAB> else: <TAB>  <TAB> tri_attr_context = [ <TAB>  <TAB>  <TAB> (""_target_o"", SPECIAL_OUTPUT), <TAB>  <TAB>  <TAB> (""_target_oe"", SPECIAL_OUTPUT), <TAB>  <TAB>  <TAB> (""_target_i"", SPECIAL_INPUT), <TAB>  <TAB> ] <TAB> tri_attr_context += [ <TAB>  <TAB> (""o"", SPECIAL_INPUT), <TAB>  <TAB> (""oe"", SPECIAL_INPUT), <TAB>  <TAB> (""i"", SPECIAL_OUTPUT), <TAB> ] <TAB> for attr, target_context in tri_attr_context: <MASK> yield self, attr, target_context","if getattr ( self , attr ) is not None :",176
"def get_field_values(self, fields): <TAB> field_values = [] <TAB> for field in fields: <TAB>  <TAB> # Title is special case <TAB>  <TAB> if field == ""title"": <TAB>  <TAB>  <TAB> value = self.get_title_display() <TAB>  <TAB> elif field == ""country"": <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> value = self.country.printable_name <TAB>  <TAB>  <TAB> except exceptions.ObjectDoesNotExist: <TAB>  <TAB>  <TAB>  <TAB> value = """" <MASK> value = self.salutation <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = getattr(self, field) <TAB>  <TAB> field_values.append(value) <TAB> return field_values","elif field == ""salutation"" :",158
"def show_panel(panel_id): <TAB> # Iterate positions to find where panel is and bring it to front. <TAB> for position in _positions_names: <TAB>  <TAB> pos_panel_ids = _get_position_panels(position) <MASK> continue <TAB>  <TAB> if len(pos_panel_ids) == 1: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> panel_widget = _get_panels_widgets_dict(gui.editor_window)[panel_id] <TAB>  <TAB> notebook = _position_notebooks[position] <TAB>  <TAB> for i in range(0, notebook.get_n_pages()): <TAB>  <TAB>  <TAB> notebook_page = notebook.get_nth_page(i) <TAB>  <TAB>  <TAB> if notebook_page == panel_widget: <TAB>  <TAB>  <TAB>  <TAB> notebook.set_current_page(i)",if len ( pos_panel_ids ) == 0 :,197
"def draw(self): <TAB> program = self._program <TAB> collection = self._collection <TAB> mode = collection._mode <TAB> if collection._need_update: <TAB>  <TAB> collection._update() <TAB>  <TAB> # self._program.bind(self._vertices_buffer) <MASK> program[""uniforms""] = collection._uniforms_texture <TAB>  <TAB>  <TAB> program[""uniforms_shape""] = collection._ushape <TAB> if collection._indices_list is not None: <TAB>  <TAB> program.draw(mode, collection._indices_buffer) <TAB> else: <TAB>  <TAB> program.draw(mode)",if collection . _uniforms_list is not None :,145
"def release(provider, connection, cache=None): <TAB> if cache is not None: <TAB>  <TAB> db_session = cache.db_session <TAB>  <TAB> if db_session is not None and db_session.ddl and cache.saved_fk_state: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> cursor = connection.cursor() <TAB>  <TAB>  <TAB>  <TAB> sql = ""SET foreign_key_checks = 1"" <MASK> log_orm(sql) <TAB>  <TAB>  <TAB>  <TAB> cursor.execute(sql) <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> provider.pool.drop(connection) <TAB>  <TAB>  <TAB>  <TAB> raise <TAB> DBAPIProvider.release(provider, connection, cache)",if core . local . debug :,164
"def expanded_output(self): <TAB> """"""Iterate over output files while dynamic output is expanded."""""" <TAB> for f, f_ in zip(self.output, self.rule.output): <MASK> expansion = self.expand_dynamic(f_) <TAB>  <TAB>  <TAB> if not expansion: <TAB>  <TAB>  <TAB>  <TAB> yield f_ <TAB>  <TAB>  <TAB> for f, _ in expansion: <TAB>  <TAB>  <TAB>  <TAB> file_to_yield = IOFile(f, self.rule) <TAB>  <TAB>  <TAB>  <TAB> file_to_yield.clone_flags(f_) <TAB>  <TAB>  <TAB>  <TAB> yield file_to_yield <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield f",if f in self . dynamic_output :,153
"def __new__(cls, xs: Tuple[Optional[AbstractValue], core.Value]): <TAB> pv, const = xs <TAB> if not core.skip_checks: <TAB>  <TAB> # type checks <TAB>  <TAB> assert isinstance(pv, (AbstractValue, type(None))), xs <TAB>  <TAB> assert ( <TAB>  <TAB>  <TAB> isinstance(const, core.Tracer) <TAB>  <TAB>  <TAB> or type(const) is Zero <TAB>  <TAB>  <TAB> or core.valid_jaxtype(const) <TAB>  <TAB> ), xs <TAB>  <TAB> # invariant checks <MASK> assert get_aval(const) == core.abstract_unit, xs <TAB> return tuple.__new__(cls, xs)","if isinstance ( pv , AbstractValue ) :",156
"def MenuItemSearch(menu, item): <TAB> for menuItem in list(menu.GetMenuItems()): <TAB>  <TAB> label = menuItem.GetItemLabel() <TAB>  <TAB> if not label: <TAB>  <TAB>  <TAB> # It's a separator <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> shortcutItem = Shortcut(menuItem=menuItem) <TAB>  <TAB> shortcutItem.FromMenuItem() <TAB>  <TAB> item.AppendItem(shortcutItem) <TAB>  <TAB> subMenu = menuItem.GetSubMenu() <MASK> MenuItemSearch(subMenu, shortcutItem)",if subMenu :,117
"def fill_potential_satellites_by_type(self, sat_type): <TAB> setattr(self, ""potential_%s"" % sat_type, []) <TAB> for satellite in getattr(self, sat_type): <TAB>  <TAB> getattr(self, ""potential_%s"" % sat_type).append(satellite) <TAB> for realm in self.higher_realms: <TAB>  <TAB> for satellite in getattr(realm, sat_type): <MASK> getattr(self, ""potential_%s"" % sat_type).append(satellite)",if satellite . manage_sub_realms :,142
"def _gen(): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> loop_val = it.next()  # e.g. x <TAB>  <TAB> except StopIteration: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> self.mem.SetValue( <TAB>  <TAB>  <TAB> lvalue.Named(iter_name), value.Obj(loop_val), scope_e.LocalOnly <TAB>  <TAB> ) <TAB>  <TAB> if comp.cond: <TAB>  <TAB>  <TAB> b = self.EvalExpr(comp.cond) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> b = True <MASK> item = self.EvalExpr(node.elt)  # e.g. x*2 <TAB>  <TAB>  <TAB> yield item",if b :,155
"def _iter_backtick_string(gen, line, back_start): <TAB> for _, tokval, start, _, _ in gen: <MASK> return ( <TAB>  <TAB>  <TAB>  <TAB> BACKTICK_TAG <TAB>  <TAB>  <TAB>  <TAB> + binascii.b2a_hex(line[back_start[1] + 1 : start[1]].encode()).decode() <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> raise SyntaxError(f""backtick quote at {back_start} does not match"")","if tokval == ""`"" :",116
"def to_internal_value(self, data): <TAB> site = get_current_site() <TAB> pages_root = reverse(""pages-root"") <TAB> ret = [] <TAB> for path in data: <TAB>  <TAB> if path.startswith(pages_root): <TAB>  <TAB>  <TAB> path = path[len(pages_root) :] <TAB>  <TAB> # strip any final slash <TAB>  <TAB> if path.endswith(""/""): <TAB>  <TAB>  <TAB> path = path[:-1] <TAB>  <TAB> page = get_page_from_path(site, path) <MASK> ret.append(page) <TAB> return ret",if page :,136
"def refresh(self): <TAB> # In MongoTrials, this method fetches from database <TAB> if self._exp_key is None: <TAB>  <TAB> self._trials = [ <TAB>  <TAB>  <TAB> tt for tt in self._dynamic_trials if tt[""state""] in JOB_VALID_STATES <TAB>  <TAB> ] <TAB> else: <TAB>  <TAB> self._trials = [ <TAB>  <TAB>  <TAB> tt <TAB>  <TAB>  <TAB> for tt in self._dynamic_trials <MASK> ] <TAB> self._ids.update([tt[""tid""] for tt in self._trials])","if ( tt [ ""state"" ] in JOB_VALID_STATES and tt [ ""exp_key"" ] == self . _exp_key )",154
"def create_model(self, model): <TAB> for field in model._meta.local_fields: <TAB>  <TAB> # Autoincrement SQL for backends with post table definition variant <TAB>  <TAB> if field.get_internal_type() == ""PositiveAutoField"": <TAB>  <TAB>  <TAB> autoinc_sql = self.connection.ops.autoinc_sql( <TAB>  <TAB>  <TAB>  <TAB> model._meta.db_table, field.column <TAB>  <TAB>  <TAB> ) <MASK> self.deferred_sql.extend(autoinc_sql) <TAB> super().create_model(model)",if autoinc_sql :,133
"def row_match(base_row, row): <TAB> # ildutil.ild_err(""ILD_DEBUG BASE ROW %s"" % (base_row,)) <TAB> for (op, val) in list(row.items()): <MASK> if base_row[op] != val: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ildutil.ild_err( <TAB>  <TAB>  <TAB>  <TAB> ""BASE ROW %s doesn't have OD %s from row %s"" % (base_row, op, row) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return None <TAB> return True",if op in base_row :,148
"def get_referrers(self): <TAB> d = [] <TAB> for o in gc.get_referrers(self.obj): <TAB>  <TAB> name = None <TAB>  <TAB> if isinstance(o, dict): <TAB>  <TAB>  <TAB> name = web.dictfind(o, self.obj) <TAB>  <TAB>  <TAB> for r in gc.get_referrers(o): <TAB>  <TAB>  <TAB>  <TAB> if getattr(r, ""__dict__"", None) is o: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> o = r <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif isinstance(o, dict):  # other dict types <TAB>  <TAB>  <TAB> name = web.dictfind(o, self.obj) <MASK> name = None <TAB>  <TAB> d.append(Object(o, name)) <TAB> return d","if not isinstance ( name , six . string_types ) :",187
"def _run(env, remote): <TAB> if device == ""vta"": <TAB>  <TAB> target = env.target <MASK> assert tvm.runtime.enabled(""rpc"") <TAB>  <TAB>  <TAB> program_fpga(remote, bitstream=None) <TAB>  <TAB>  <TAB> reconfig_runtime(remote) <TAB> elif device == ""arm_cpu"": <TAB>  <TAB> target = env.target_vta_cpu <TAB> with autotvm.tophub.context(target):  # load pre-tuned schedule parameters <TAB>  <TAB> for _, wl in resnet_wkls: <TAB>  <TAB>  <TAB> print(wl) <TAB>  <TAB>  <TAB> run_conv2d(env, remote, wl, target)","if env . TARGET not in [ ""sim"" , ""tsim"" ] :",169
"def retrieve(self, aclass): <TAB> """"""Look for a specifc class/name in the packet"""""" <TAB> resu = [] <TAB> for x in self.payload: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if isinstance(aclass, str): <MASK> resu.append(x) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> if isinstance(x, aclass): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> resu.append(x) <TAB>  <TAB>  <TAB> resu += x.retrieve(aclass) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> pass <TAB> return resu",if x . name == aclass :,144
"def summary_passes(self): <TAB> if self.config.option.tbstyle != ""no"": <TAB>  <TAB> if self.hasopt(""P""): <TAB>  <TAB>  <TAB> reports = self.getreports(""passed"") <MASK> return <TAB>  <TAB>  <TAB> self.write_sep(""="", ""PASSES"") <TAB>  <TAB>  <TAB> for rep in reports: <TAB>  <TAB>  <TAB>  <TAB> msg = self._getfailureheadline(rep) <TAB>  <TAB>  <TAB>  <TAB> self.write_sep(""_"", msg) <TAB>  <TAB>  <TAB>  <TAB> self._outrep_summary(rep)",if not reports :,127
"def fn(): <TAB> random_states = { <TAB>  <TAB> name: cls.random_state_function(state_spec=state_spec)() <TAB>  <TAB> for name, state_spec in states_spec.items() <TAB> } <TAB> for name, action_spec in actions_spec.items(): <MASK> mask = cls.random_mask(action_spec=action_spec) <TAB>  <TAB>  <TAB> random_states[name + ""_mask""] = mask <TAB> return random_states","if action_spec [ ""type"" ] == ""int"" :",121
"def _show_option(name=None): <TAB> if name is None: <TAB>  <TAB> name = """" <TAB> filename = peda.getfile() <TAB> if filename: <TAB>  <TAB> filename = os.path.basename(filename) <TAB> else: <TAB>  <TAB> filename = None <TAB> for (k, v) in sorted(config.Option.show(name).items()): <MASK> v = v.replace(""#FILENAME#"", filename) <TAB>  <TAB> msg(""%s = %s"" % (k, repr(v))) <TAB> return","if filename and isinstance ( v , str ) and ""#FILENAME#"" in v :",137
"def _set_posonly_args_def(self, argmts, vals): <TAB> for v in vals: <TAB>  <TAB> argmts.posonlyargs.append(v[""arg""]) <TAB>  <TAB> d = v[""default""] <MASK> argmts.defaults.append(d) <TAB>  <TAB> elif argmts.defaults: <TAB>  <TAB>  <TAB> self._set_error(""non-default argument follows default argument"")",if d is not None :,97
def get(self): <TAB> with self._lock: <MASK> self._connection = psycopg2.connect(**self._conn_kwargs) <TAB>  <TAB>  <TAB> self._connection.autocommit = True <TAB>  <TAB>  <TAB> self.server_version = self._connection.server_version <TAB> return self._connection,if not self . _connection or self . _connection . closed != 0 :,83
"def _Determine_Do(self): <TAB> if sys.platform == ""darwin"": <TAB>  <TAB> self.applicable = True <TAB>  <TAB> for opt, optarg in self.chosenOptions: <MASK> self.value = os.path.abspath(optarg) <TAB>  <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> self.applicable = False <TAB> self.determined = True","if opt == ""--"" + self . longopt :",97
"def delete_tags(filenames, v1, v2): <TAB> for filename in filenames: <TAB>  <TAB> with _sig.block(): <MASK> print_(u""deleting ID3 tag info in"", filename, file=sys.stderr) <TAB>  <TAB>  <TAB> mutagen.id3.delete(filename, v1, v2)",if verbose :,81
"def startJail(self, name): <TAB> with self.__lock: <TAB>  <TAB> jail = self.__jails[name] <TAB>  <TAB> if not jail.isAlive(): <TAB>  <TAB>  <TAB> jail.start() <MASK> logSys.info(""Jail %r reloaded"", name) <TAB>  <TAB>  <TAB> del self.__reload_state[name] <TAB>  <TAB> if jail.idle: <TAB>  <TAB>  <TAB> jail.idle = False",elif name in self . __reload_state :,111
"def get_field_by_name(obj, field): <TAB> # Dereference once <TAB> if obj.type.code == gdb.TYPE_CODE_PTR: <TAB>  <TAB> obj = obj.dereference() <TAB> for f in re.split(""(->|\.|\[\d+\])"", field): <MASK> continue <TAB>  <TAB> if f == ""->"": <TAB>  <TAB>  <TAB> obj = obj.dereference() <TAB>  <TAB> elif f == ""."": <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> elif f.startswith(""[""): <TAB>  <TAB>  <TAB> n = int(f.strip(""[]"")) <TAB>  <TAB>  <TAB> obj = obj.cast(obj.dereference().type.pointer()) <TAB>  <TAB>  <TAB> obj += n <TAB>  <TAB>  <TAB> obj = obj.dereference() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> obj = obj[f] <TAB> return obj",if not f :,189
"def _parse_yum_or_zypper_repositories(output): <TAB> repos = [] <TAB> current_repo = {} <TAB> for line in output: <TAB>  <TAB> line = line.strip() <TAB>  <TAB> if not line or line.startswith(""#""): <TAB>  <TAB>  <TAB> continue <MASK> if current_repo: <TAB>  <TAB>  <TAB>  <TAB> repos.append(current_repo) <TAB>  <TAB>  <TAB>  <TAB> current_repo = {} <TAB>  <TAB>  <TAB> current_repo[""name""] = line[1:-1] <TAB>  <TAB> if current_repo and ""="" in line: <TAB>  <TAB>  <TAB> key, value = line.split(""="", 1) <TAB>  <TAB>  <TAB> current_repo[key] = value <TAB> if current_repo: <TAB>  <TAB> repos.append(current_repo) <TAB> return repos","if line . startswith ( ""["" ) :",179
"def add_to_auto_transitions(cls, base): <TAB> result = {} <TAB> for name, method in base.__dict__.items(): <MASK> for name, transition in method._django_fsm.transitions.items(): <TAB>  <TAB>  <TAB>  <TAB> if transition.custom.get(""auto""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> result.update({name: method}) <TAB> return result","if callable ( method ) and hasattr ( method , ""_django_fsm"" ) :",103
"def commit(cache): <TAB> assert cache.is_alive <TAB> try: <MASK> cache.flush() <TAB>  <TAB> if cache.in_transaction: <TAB>  <TAB>  <TAB> assert cache.connection is not None <TAB>  <TAB>  <TAB> cache.database.provider.commit(cache.connection, cache) <TAB>  <TAB> cache.for_update.clear() <TAB>  <TAB> cache.query_results.clear() <TAB>  <TAB> cache.max_id_cache.clear() <TAB>  <TAB> cache.immediate = True <TAB> except: <TAB>  <TAB> cache.rollback() <TAB>  <TAB> raise",if cache . modified :,131
"def block_items(objekt, block, eldict): <TAB> if objekt not in block: <TAB>  <TAB> if isinstance(objekt.type, PyType): <MASK> block.append(objekt.type) <TAB>  <TAB> block.append(objekt) <TAB>  <TAB> if isinstance(objekt, PyType): <TAB>  <TAB>  <TAB> others = [ <TAB>  <TAB>  <TAB>  <TAB> p <TAB>  <TAB>  <TAB>  <TAB> for p in eldict.values() <TAB>  <TAB>  <TAB>  <TAB> if isinstance(p, PyElement) and p.type[1] == objekt.name <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB> for item in others: <TAB>  <TAB>  <TAB>  <TAB> if item not in block: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> block.append(item) <TAB> return block",if objekt . type not in block :,186
"def __getattr__(self, item): <TAB> import pyarrow.lib <TAB> ret = getattr(plasma, item, None) <TAB> if ret is None:  # pragma: no cover <MASK> ret = getattr(plasma, ""PlasmaObjectNonexistent"", None) or getattr( <TAB>  <TAB>  <TAB>  <TAB> pyarrow.lib, ""PlasmaObjectNonexistent"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> elif item == ""PlasmaStoreFull"": <TAB>  <TAB>  <TAB> ret = getattr(pyarrow.lib, item) <TAB> if ret is not None: <TAB>  <TAB> setattr(self, item, ret) <TAB> return ret","if item == ""PlasmaObjectNotFound"" :",133
"def clean_str(*args): <TAB> tdict = {""str"": 0, ""bytearray"": 1, ""unicode"": 2} <TAB> for obj in args: <TAB>  <TAB> k = tdict.get(type(obj).__name__) <MASK> raise RuntimeError(""Can not clean object: %s"" % obj) <TAB>  <TAB> clean_obj(obj, k)",if k is None :,87
"def incoming(): <TAB> while True: <TAB>  <TAB> m = ws.receive() <MASK> m = str(m) <TAB>  <TAB>  <TAB> print((m, len(m))) <TAB>  <TAB>  <TAB> if len(m) == 35: <TAB>  <TAB>  <TAB>  <TAB> ws.close() <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> print((""Connection closed!"",))",if m is not None :,94
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 8: <TAB>  <TAB>  <TAB> self.add_set_status(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,92
"def __init__(self, text, menu): <TAB> self.text = text <TAB> self.menu = menu <TAB> print(text) <TAB> for i, option in enumerate(menu): <TAB>  <TAB> menunum = i + 1 <TAB>  <TAB> # Check to see if this line has the 'return to main menu' code <TAB>  <TAB> match = re.search(""0D"", option) <TAB>  <TAB> # If it's not the return to menu line: <MASK> if menunum < 10: <TAB>  <TAB>  <TAB>  <TAB> print((""   %s) %s"" % (menunum, option))) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> print((""  %s) %s"" % (menunum, option))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""\n  99) Return to Main Menu\n"") <TAB> return",if not match :,193
def take_step(self): <TAB> with self.walk_lock: <TAB>  <TAB> # Share my random channels <TAB>  <TAB> peers = self.overlay.get_peers() <MASK> peer = choice(peers) <TAB>  <TAB>  <TAB> self.overlay.send_random_to(peer),if peers :,74
"def clear_highlight(self): <TAB> for doc in self._window.get_documents(): <TAB>  <TAB> start, end = doc.get_bounds() <MASK> tag = doc.create_tag( <TAB>  <TAB>  <TAB>  <TAB> ""result_highlight"", foreground=""yellow"", background=""red"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> doc.remove_tag_by_name(""result_highlight"", start, end)","if doc . get_tag_table ( ) . lookup ( ""result_highlight"" ) == None :",111
"def impl(self, to_strip=None): <TAB> mask = get_nan_mask(self._data._data) <TAB> item_count = len(self._data) <TAB> res_list = [""""] * item_count <TAB> for it in range(item_count): <TAB>  <TAB> item = self._data._data[it] <MASK> res_list[it] = usecase(item, to_strip) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> res_list[it] = item <TAB> str_arr = create_str_arr_from_list(res_list) <TAB> result = str_arr_set_na_by_mask(str_arr, mask) <TAB> return pandas.Series(result, self._data._index, name=self._data._name)",if len ( item ) > 0 :,188
"def modify_subnet_attribute(self): <TAB> subnet_id = self._get_param(""SubnetId"") <TAB> for attribute in (""MapPublicIpOnLaunch"", ""AssignIpv6AddressOnCreation""): <MASK> attr_name = camelcase_to_underscores(attribute) <TAB>  <TAB>  <TAB> attr_value = self.querystring.get(""%s.Value"" % attribute)[0] <TAB>  <TAB>  <TAB> self.ec2_backend.modify_subnet_attribute(subnet_id, attr_name, attr_value) <TAB>  <TAB>  <TAB> return MODIFY_SUBNET_ATTRIBUTE_RESPONSE","if self . querystring . get ( ""%s.Value"" % attribute ) :",149
"def join(s, *p): <TAB> path = s <TAB> for t in p: <TAB>  <TAB> if (not s) or isabs(t): <TAB>  <TAB>  <TAB> path = t <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if t[:1] == "":"": <TAB>  <TAB>  <TAB> t = t[1:] <TAB>  <TAB> if "":"" not in path: <TAB>  <TAB>  <TAB> path = "":"" + path <MASK> path = path + "":"" <TAB>  <TAB> path = path + t <TAB> return path","if path [ - 1 : ] != "":"" :",115
"def publish(self): <TAB> # monoproc <TAB> if not self.modules.has_option(self.subscriber_name, ""publish""): <TAB>  <TAB> return False <TAB> dest = self.modules.get(self.subscriber_name, ""publish"") <TAB> # We can have multiple publisher <TAB> for name in dest.split("",""): <TAB>  <TAB> self.pubsub.setup_publish(name) <TAB> while True: <TAB>  <TAB> message = self.r_temp.spop(self.subscriber_name + ""out"") <MASK> time.sleep(1) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> self.pubsub.publish(message)",if message is None :,151
"def ignore(self, other): <TAB> if isinstance(other, Suppress): <MASK> super().ignore(other) <TAB>  <TAB>  <TAB> if self.expr is not None: <TAB>  <TAB>  <TAB>  <TAB> self.expr.ignore(self.ignoreExprs[-1]) <TAB> else: <TAB>  <TAB> super().ignore(other) <TAB>  <TAB> if self.expr is not None: <TAB>  <TAB>  <TAB> self.expr.ignore(self.ignoreExprs[-1]) <TAB> return self",if other not in self . ignoreExprs :,117
"def recurse(node): <TAB> for child in node.childNodes: <TAB>  <TAB> if child.nodeType != child.ELEMENT_NODE: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if child.nodeName.upper() == ""H1"": <TAB>  <TAB>  <TAB> return child <MASK> return recurse(child)",if child not in visited :,76
"def req(s, poll, msg, expect): <TAB> do_req = True <TAB> xid = None <TAB> while True: <TAB>  <TAB> # get transaction id <TAB>  <TAB> if do_req: <TAB>  <TAB>  <TAB> xid = s.put(msg)[""xid""] <TAB>  <TAB> # wait for response <TAB>  <TAB> events = poll.poll(2) <TAB>  <TAB> for (fd, event) in events: <TAB>  <TAB>  <TAB> response = s.get() <MASK> do_req = False <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if response[""options""][""message_type""] != expect: <TAB>  <TAB>  <TAB>  <TAB> raise Exception(""DHCP protocol error"") <TAB>  <TAB>  <TAB> return response <TAB>  <TAB> do_req = True","if response [ ""xid"" ] != xid :",174
"def close(self, invalidate=False): <TAB> self.session.transaction = self._parent <TAB> if self._parent is None: <TAB>  <TAB> for connection, transaction, autoclose in set(self._connections.values()): <TAB>  <TAB>  <TAB> if invalidate: <TAB>  <TAB>  <TAB>  <TAB> connection.invalidate() <MASK> connection.close() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> transaction.close() <TAB> self._state = CLOSED <TAB> self.session.dispatch.after_transaction_end(self.session, self) <TAB> if self._parent is None: <TAB>  <TAB> if not self.session.autocommit: <TAB>  <TAB>  <TAB> self.session.begin() <TAB> self.session = None <TAB> self._connections = None",if autoclose :,172
"def visit_loop(self): <TAB> v = self.vS.top_front() <TAB> i = self.iS.top_front() <TAB> num_edges = len(self.graph[v].edges) <TAB> # Continue traversing out-edges until none left. <TAB> while i <= num_edges: <TAB>  <TAB> # Continuation <TAB>  <TAB> if i > 0: <TAB>  <TAB>  <TAB> # Update status for previously traversed out-edge <TAB>  <TAB>  <TAB> self.finish_edge(v, i - 1) <MASK> return <TAB>  <TAB> i += 1 <TAB> # Finished traversing out edges, update component info <TAB> self.finish_visiting(v)","if i < num_edges and self . begin_edge ( v , i ) :",167
"def get_objects(self): <TAB> list_type, id, handles, timestamp = self._obj_list <TAB> retval = [] <TAB> for (target, handle) in handles: <TAB>  <TAB> _class = map2class(target) <MASK> obj = _class(self._dbstate, pickle.dumps((target, id, handle, timestamp))) <TAB>  <TAB>  <TAB> if obj: <TAB>  <TAB>  <TAB>  <TAB> retval.append(obj) <TAB> return retval",if _class :,108
"def __init__(self, config_lists): <TAB> self.lens = len(config_lists) <TAB> self.spaces = [] <TAB> for config_list in config_lists: <TAB>  <TAB> if isinstance(config_list, tuple): <TAB>  <TAB>  <TAB> key, config = config_list <MASK> key = config_list <TAB>  <TAB>  <TAB> config = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise NotImplementedError( <TAB>  <TAB>  <TAB>  <TAB> ""the type of config is Error!!! Please check the config information. Receive the type of config is {}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> type(config_list) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self.spaces.append(self._get_single_search_space(key, config)) <TAB> self.init_tokens()","elif isinstance ( config_list , str ) :",186
"def fieldset_string_to_field(fieldset_dict, model): <TAB> if isinstance(fieldset_dict[""fields""], tuple): <TAB>  <TAB> fieldset_dict[""fields""] = list(fieldset_dict[""fields""]) <TAB> i = 0 <TAB> for dict_field in fieldset_dict[""fields""]: <MASK> fieldset_dict[""fields""][i] = model._meta.get_field_by_name(dict_field)[0] <TAB>  <TAB> elif isinstance(dict_field, list) or isinstance(dict_field, tuple): <TAB>  <TAB>  <TAB> dict_field[1][""recursive""] = True <TAB>  <TAB>  <TAB> fieldset_string_to_field(dict_field[1], model) <TAB>  <TAB> i += 1","if isinstance ( dict_field , string_types ) :",179
"def _get_directories(config): <TAB> for directory in config[""dump_directories""]: <TAB>  <TAB> for dname in sorted(glob.glob(os.path.join(directory, ""*[Aa]*[Xx][XxYy23]""))): <MASK> yield dname",if os . path . isdir ( dname ) :,79
"def process_event(self, event): <TAB> super().process_event(event) <TAB> if event.type == pygame.USEREVENT: <MASK> self.input_op(event.ui_object_id[-1]) <TAB>  <TAB>  <TAB> return True",if event . user_type == pygame_gui . UI_BUTTON_PRESSED :,80
"def _restore_std_streams(self): <TAB> stdout = sys.stdout.getvalue() <TAB> stderr = sys.stderr.getvalue() <TAB> close = [sys.stdout, sys.stderr] <TAB> sys.stdout = sys.__stdout__ <TAB> sys.stderr = sys.__stderr__ <TAB> for stream in close: <TAB>  <TAB> stream.close() <TAB> if stdout and stderr: <TAB>  <TAB> if not stderr.startswith((""*TRACE*"", ""*DEBUG*"", ""*INFO*"", ""*HTML*"", ""*WARN*"")): <TAB>  <TAB>  <TAB> stderr = ""*INFO* %s"" % stderr <MASK> stdout += ""\n"" <TAB> return self._handle_binary_result(stdout + stderr)","if not stdout . endswith ( ""\n"" ) :",159
"def _get_attachments(self): <TAB> if self._attachments is None: <TAB>  <TAB> alist = [] <TAB>  <TAB> for a in self._message.get_attachments(): <TAB>  <TAB>  <TAB> alist.append((AttachmentWidget(a), None)) <MASK> self._attachments = SimpleTree(alist) <TAB> return self._attachments",if alist :,79
"def __getattr__(self, name): <TAB> # if the aval property raises an AttributeError, gets caught here <TAB> assert skip_checks or name != ""aval"" <TAB> try: <TAB>  <TAB> attr = getattr(self.aval, name) <TAB> except KeyError as err: <TAB>  <TAB> raise AttributeError( <TAB>  <TAB>  <TAB> ""{} has no attribute {}"".format(self.__class__.__name__, name) <TAB>  <TAB> ) from err <TAB> else: <TAB>  <TAB> t = type(attr) <TAB>  <TAB> if t is aval_property: <TAB>  <TAB>  <TAB> return attr.fget(self) <MASK> return types.MethodType(attr.fun, self) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return attr",elif t is aval_method :,165
"def _find_first_unescaped(dn, char, pos): <TAB> while True: <TAB>  <TAB> pos = dn.find(char, pos) <MASK> break  # no char found <TAB>  <TAB> if pos > 0 and dn[pos - 1] != ""\\"":  # unescaped char <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif pos > 1 and dn[pos - 1] == ""\\"":  # may be unescaped <TAB>  <TAB>  <TAB> escaped = True <TAB>  <TAB>  <TAB> for c in dn[pos - 2 : 0 : -1]: <TAB>  <TAB>  <TAB>  <TAB> if c == ""\\"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> escaped = not escaped <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> if not escaped: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> pos += 1 <TAB> return pos",if pos == - 1 :,181
"def test_synopsis(self): <TAB> self.addCleanup(unlink, TESTFN) <TAB> for encoding in (""ISO-8859-1"", ""UTF-8""): <TAB>  <TAB> with open(TESTFN, ""w"", encoding=encoding) as script: <MASK> print(""#coding: {}"".format(encoding), file=script) <TAB>  <TAB>  <TAB> print('""""""line 1: h\xe9', file=script) <TAB>  <TAB>  <TAB> print('line 2: hi""""""', file=script) <TAB>  <TAB> synopsis = pydoc.synopsis(TESTFN, {}) <TAB>  <TAB> self.assertEqual(synopsis, ""line 1: h\xe9"")","if encoding != ""UTF-8"" :",148
"def qualify(x): <TAB> parts = x.split("";"", 1) <TAB> if len(parts) == 2: <TAB>  <TAB> match = re.match(r""(^|;)q=(0(\.\d{,3})?|1(\.0{,3})?)(;|$)"", parts[1]) <MASK> return parts[0].strip(), float(match.group(2)) <TAB> return parts[0].strip(), 1",if match :,102
"def getEndpoints(self): <TAB> endpoints = self.endpoints[:] <TAB> for i in range(len(endpoints)): <TAB>  <TAB> ep = endpoints[i] <MASK> raise TypeError(""Not an Endpoint subclass"") <TAB>  <TAB> endpoints[i] = ep(self, self.master) <TAB> return endpoints","if not issubclass ( ep , Endpoint ) :",81
"def __getitem__(self, index): <TAB> if cfg.RPN.ENABLED: <TAB>  <TAB> return self.get_rpn_sample(index) <TAB> elif cfg.RCNN.ENABLED: <MASK> if cfg.RCNN.ROI_SAMPLE_JIT: <TAB>  <TAB>  <TAB>  <TAB> return self.get_rcnn_sample_jit(index) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return self.get_rcnn_training_sample_batch(index) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.get_proposal_from_file(index) <TAB> else: <TAB>  <TAB> raise NotImplementedError","if self . mode == ""TRAIN"" :",144
"def test_data_path(self, filename): <TAB> repository_dir = self._repository_dir <TAB> test_data = None <TAB> if repository_dir: <TAB>  <TAB> return self.__walk_test_data(dir=repository_dir, filename=filename) <TAB> else: <TAB>  <TAB> if self.tool_dir: <TAB>  <TAB>  <TAB> tool_dir = self.tool_dir <MASK> tool_dir = os.path.dirname(self.tool_dir) <TAB>  <TAB>  <TAB> test_data = self.__walk_test_data(tool_dir, filename=filename) <TAB> if not test_data: <TAB>  <TAB> test_data = self.app.test_data_resolver.get_filename(filename) <TAB> return test_data","if isinstance ( self , DataManagerTool ) :",181
"def generate_forwards(cls, attrs): <TAB> # forward functions of _forwards <TAB> for attr_name, attr in cls._forwards.__dict__.items(): <TAB>  <TAB> if attr_name.startswith(""_"") or attr_name in attrs: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if isinstance(attr, property): <TAB>  <TAB>  <TAB> cls._forward.append(attr_name) <MASK> wrapper = _forward_factory(cls, attr_name, attr) <TAB>  <TAB>  <TAB> setattr(cls, attr_name, wrapper) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError(attr_name, type(attr))","elif isinstance ( attr , types . FunctionType ) :",146
"def summary(result): <TAB> if not self.options.metadata_to_dict: <MASK> pprint(Fore.CYAN + result[""title""] + Fore.RESET) <TAB>  <TAB>  <TAB> pprint( <TAB>  <TAB>  <TAB>  <TAB> Fore.CYAN <TAB>  <TAB>  <TAB>  <TAB> + Style.DIM <TAB>  <TAB>  <TAB>  <TAB> + result[""written_at""] <TAB>  <TAB>  <TAB>  <TAB> + Style.RESET_ALL <TAB>  <TAB>  <TAB>  <TAB> + Fore.RESET <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> pprint(result[""body""]) <TAB>  <TAB> writer.write(""@title:"" + result[""title""]) <TAB>  <TAB> writer.write(""@written_at:"" + result[""written_at""]) <TAB>  <TAB> writer.write(""@body:"" + result[""body""]) <TAB> else: <TAB>  <TAB> if self.options.verbose: <TAB>  <TAB>  <TAB> pprint(result) <TAB>  <TAB> writer.write(result)",if self . options . verbose :,196
"def visit_StringConstant(self, node: qlast.StringConstant) -> None: <TAB> if not _NON_PRINTABLE_RE.search(node.value): <TAB>  <TAB> for d in (""'"", '""', ""$$""): <MASK> if ""\\"" in node.value and d != ""$$"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.write(""r"", d, node.value, d) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.write(d, node.value, d) <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> self.write(edgeql_quote.dollar_quote_literal(node.value)) <TAB>  <TAB> return <TAB> self.write(repr(node.value))",if d not in node . value :,170
"def get_sql_date_trunc(col, db=""default"", grouper=""hour""): <TAB> conn = connections[db] <TAB> engine = get_db_engine(db) <TAB> # TODO: does extract work for sqlite? <TAB> if engine.startswith(""oracle""): <TAB>  <TAB> method = DATE_TRUNC_GROUPERS[""oracle""].get( <TAB>  <TAB>  <TAB> grouper, DATE_TRUNC_GROUPERS[""default""][grouper] <TAB>  <TAB> ) <MASK> col = '""%s""' % col.upper() <TAB> else: <TAB>  <TAB> method = DATE_TRUNC_GROUPERS[""default""][grouper] <TAB> return conn.ops.date_trunc_sql(method, col)","if '""' not in col :",164
"def req(s, poll, msg, expect): <TAB> do_req = True <TAB> xid = None <TAB> while True: <TAB>  <TAB> # get transaction id <TAB>  <TAB> if do_req: <TAB>  <TAB>  <TAB> xid = s.put(msg)[""xid""] <TAB>  <TAB> # wait for response <TAB>  <TAB> events = poll.poll(2) <TAB>  <TAB> for (fd, event) in events: <TAB>  <TAB>  <TAB> response = s.get() <TAB>  <TAB>  <TAB> if response[""xid""] != xid: <TAB>  <TAB>  <TAB>  <TAB> do_req = False <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> raise Exception(""DHCP protocol error"") <TAB>  <TAB>  <TAB> return response <TAB>  <TAB> do_req = True","if response [ ""options"" ] [ ""message_type"" ] != expect :",174
"def __init__(self, f): <TAB> self._refs = {} <TAB> self._peeled = {} <TAB> for line in f.readlines(): <TAB>  <TAB> sha, name = line.rstrip(b""\n"").split(b""\t"") <MASK> name = name[:-3] <TAB>  <TAB>  <TAB> if not check_ref_format(name): <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""invalid ref name %r"" % name) <TAB>  <TAB>  <TAB> self._peeled[name] = sha <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if not check_ref_format(name): <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""invalid ref name %r"" % name) <TAB>  <TAB>  <TAB> self._refs[name] = sha",if name . endswith ( ANNOTATED_TAG_SUFFIX ) :,171
"def get_defines(clang_output): <TAB> import re <TAB> defines = [] <TAB> for line in output.splitlines(): <TAB>  <TAB> m = re.search(r""#define ([\w()]+) (.+)"", line) <MASK> defines.append(""-D{}={}"".format(m.group(1), m.group(2))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> m = re.search(r""#define (\w+)"", line) <TAB>  <TAB>  <TAB> if m is not None: <TAB>  <TAB>  <TAB>  <TAB> defines.append(""-D{}"".format(m.group(1))) <TAB> _log.debug(""Got defines: %s"", defines) <TAB> return defines",if m is not None :,155
"def clean_rcs_keywords(paragraph, keyword_substitutions): <TAB> if len(paragraph) == 1 and isinstance(paragraph[0], nodes.Text): <TAB>  <TAB> textnode = paragraph[0] <TAB>  <TAB> for pattern, substitution in keyword_substitutions: <TAB>  <TAB>  <TAB> match = pattern.search(textnode.data) <MASK> textnode.data = pattern.sub(substitution, textnode.data) <TAB>  <TAB>  <TAB>  <TAB> return",if match :,107
"def reorder_incremental_state( <TAB> self, incremental_state: Dict[str, Dict[str, Optional[Tensor]]], new_order): <TAB> """"""Reorder buffered internal state (for incremental generation)."""""" <TAB> input_buffer = self._get_input_buffer(incremental_state) <TAB> if input_buffer is not None: <TAB>  <TAB> for k in input_buffer.keys(): <MASK> input_buffer[k] = input_buffer[k].index_select(0, new_order) <TAB>  <TAB> incremental_state = self._set_input_buffer(incremental_state, input_buffer) <TAB> return incremental_state",if input_buffer [ k ] is not None :,156
"def render(cls) -> str: <TAB> buf = render_utils.RenderBuffer() <TAB> buf.write(f""struct {cls.__name__} {{"") <TAB> with buf.indent(): <TAB>  <TAB> for fieldname, field in cls._fields.items(): <MASK> buf.write_comment(field.doc) <TAB>  <TAB>  <TAB> field.render_field(fieldname, buf) <TAB>  <TAB>  <TAB> buf.newline() <TAB> if buf.lastline() == """": <TAB>  <TAB> buf.popline() <TAB> buf.write(""};"") <TAB> return str(buf)",if field . doc :,134
"def prepare_text(text, style): <TAB> body = [] <TAB> for fragment, sty in parse_tags(text, style, subs.styles): <TAB>  <TAB> fragment = fragment.replace(r""\h"", "" "") <TAB>  <TAB> fragment = fragment.replace(r""\n"", ""\n"") <TAB>  <TAB> fragment = fragment.replace(r""\N"", ""\n"") <MASK> fragment = ""<i>%s</i>"" % fragment <TAB>  <TAB> if sty.underline: <TAB>  <TAB>  <TAB> fragment = ""<u>%s</u>"" % fragment <TAB>  <TAB> if sty.strikeout: <TAB>  <TAB>  <TAB> fragment = ""<s>%s</s>"" % fragment <TAB>  <TAB> if sty.drawing: <TAB>  <TAB>  <TAB> raise ContentNotUsable <TAB>  <TAB> body.append(fragment) <TAB> return re.sub(""\n+"", ""\n"", """".join(body).strip())",if sty . italic :,198
"def _show_warnings(self): <TAB> if self._warnings_handled: <TAB>  <TAB> return <TAB> self._warnings_handled = True <TAB> if self._result and (self._result.has_next or not self._result.warning_count): <TAB>  <TAB> return <TAB> ws = self._get_db().show_warnings() <TAB> if ws is None: <TAB>  <TAB> return <TAB> for w in ws: <TAB>  <TAB> msg = w[-1] <TAB>  <TAB> if PY2: <MASK> msg = msg.encode(""utf-8"", ""replace"") <TAB>  <TAB> warnings.warn(err.Warning(*w[1:3]), stacklevel=4)","if isinstance ( msg , unicode ) :",158
"def scrub_time(self, time):  # used externally to set time by slider scrubbing <TAB> debug(""scrub_time: {0}"".format(time)) <TAB> if time == 0: <TAB>  <TAB> self.loop_backward() <TAB> elif time == self.timer_duration: <TAB>  <TAB> self.loop_forward() <TAB> else:  # time in between 0 and duration <TAB>  <TAB> if self.timer_status == TIMER_STATUS_STOPPED: <TAB>  <TAB>  <TAB> self.timer_status = TIMER_STATUS_PAUSED <MASK> self.timer_status = TIMER_STATUS_PAUSED <TAB> self.timer_time = time",elif self . timer_status == TIMER_STATUS_EXPIRED :,163
"def _default_import_run(run, dest, move, copy_resources): <TAB> if move: <TAB>  <TAB> log.info(""Moving %s"", run.id) <MASK> shutil.copytree(run.path, dest) <TAB>  <TAB>  <TAB> util.safe_rmtree(run.path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> shutil.move(run.path, dest) <TAB> else: <TAB>  <TAB> log.info(""Copying %s"", run.id) <TAB>  <TAB> shutil.copytree(run.path, dest, symlinks=not copy_resources)",if copy_resources :,133
"def fn(n): <TAB> while n < 3: <MASK> yield ""less than zero"" <TAB>  <TAB> elif n == 0: <TAB>  <TAB>  <TAB> yield ""zero"" <TAB>  <TAB> elif n == 1: <TAB>  <TAB>  <TAB> yield ""one"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield ""more than one"" <TAB>  <TAB> n += 1",if n < 0 :,84
"def _check_dep_names(self): <TAB> """"""check if user input task_dep or setup_task that doesnt exist"""""" <TAB> # check task-dependencies exist. <TAB> for task in self.tasks.values(): <TAB>  <TAB> for dep in task.task_dep: <MASK> msg = ""%s. Task dependency '%s' does not exist."" <TAB>  <TAB>  <TAB>  <TAB> raise InvalidTask(msg % (task.name, dep)) <TAB>  <TAB> for setup_task in task.setup_tasks: <TAB>  <TAB>  <TAB> if setup_task not in self.tasks: <TAB>  <TAB>  <TAB>  <TAB> msg = ""Task '%s': invalid setup task '%s'."" <TAB>  <TAB>  <TAB>  <TAB> raise InvalidTask(msg % (task.name, setup_task))",if dep not in self . tasks :,176
"def urls(): <TAB> for scheme in (b""http"", b""https""): <TAB>  <TAB> for host in (b""example.com"",): <TAB>  <TAB>  <TAB> for port in (None, 100): <TAB>  <TAB>  <TAB>  <TAB> for path in (b"""", b""path""): <MASK> host = host + b"":"" + networkString(str(port)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield urlunsplit((scheme, host, path, b"""", b""""))",if port is not None :,112
"def split_hashes(cls, line): <TAB> # type: (S) -> Tuple[S, List[S]] <TAB> if ""--hash"" not in line: <TAB>  <TAB> return line, [] <TAB> split_line = line.split() <TAB> line_parts = []  # type: List[S] <TAB> hashes = []  # type: List[S] <TAB> for part in split_line: <MASK> param, _, value = part.partition(""="") <TAB>  <TAB>  <TAB> hashes.append(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> line_parts.append(part) <TAB> line = "" "".join(line_parts) <TAB> return line, hashes","if part . startswith ( ""--hash"" ) :",159
"def part(p, imaginary): <TAB> # Represent infinity as 1e1000 and NaN as 1e1000-1e1000. <TAB> s = ""j"" if imaginary else """" <TAB> try: <TAB>  <TAB> if math.isinf(p): <MASK> return ""-1e1000"" + s <TAB>  <TAB>  <TAB> return ""1e1000"" + s <TAB>  <TAB> if math.isnan(p): <TAB>  <TAB>  <TAB> return ""(1e1000%s-1e1000%s)"" % (s, s) <TAB> except OverflowError: <TAB>  <TAB> # math.isinf will raise this when given an integer <TAB>  <TAB> # that's too large to convert to a float. <TAB>  <TAB> pass <TAB> return repr(p) + s",if p < 0 :,168
"def _build_display_args(self, r): <TAB> args = [] <TAB> if self.RESULT: <MASK> result = [self.RESULT] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result = self.RESULT <TAB>  <TAB> for name in result: <TAB>  <TAB>  <TAB> value = getattr(r, name) <TAB>  <TAB>  <TAB> # Displayed offsets should be offset by the base address <TAB>  <TAB>  <TAB> if name == ""offset"": <TAB>  <TAB>  <TAB>  <TAB> value += self.config.base <TAB>  <TAB>  <TAB> args.append(value) <TAB> return args",if type ( self . RESULT ) != type ( [ ] ) :,139
"def cell_data_statusicon(column, cell, model, row, data): <TAB> """"""Display text with an icon"""""" <TAB> try: <TAB>  <TAB> state = model.get_value(row, data) <MASK> return <TAB>  <TAB> func_last_value[""cell_data_statusicon""] = state <TAB>  <TAB> icon = ICON_STATE[state] <TAB>  <TAB> # Supress Warning: g_object_set_qdata: assertion `G_IS_OBJECT (object)' failed <TAB>  <TAB> original_filters = warnings.filters[:] <TAB>  <TAB> warnings.simplefilter(""ignore"") <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> cell.set_property(""pixbuf"", icon) <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> warnings.filters = original_filters <TAB> except KeyError: <TAB>  <TAB> pass","if func_last_value [ ""cell_data_statusicon"" ] == state :",195
"def _para_exploit(self, params, part): <TAB> if len(params) == 0: <TAB>  <TAB> arr = [""*"", ""config""] + self._configs.keys() <TAB>  <TAB> return suggest(arr, part) <TAB> if len(params) == 1: <TAB>  <TAB> arr = [] <MASK> arr = self._configs.keys() <TAB>  <TAB> if params[0] == ""*"": <TAB>  <TAB>  <TAB> arr = [""stopOnFirst""] <TAB>  <TAB> return suggest(arr, part) <TAB> return []","if params [ 0 ] == ""config"" :",124
"def send(self, data, flags=0, timeout=timeout_default): <TAB> if timeout is timeout_default: <TAB>  <TAB> timeout = self.timeout <TAB> try: <TAB>  <TAB> return self._sock.send(data, flags) <TAB> except error as ex: <TAB>  <TAB> if ex.args[0] not in _socketcommon.GSENDAGAIN or timeout == 0.0: <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> sys.exc_clear() <TAB>  <TAB> self._wait(self._write_event) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self._sock.send(data, flags) <TAB>  <TAB> except error as ex2: <MASK> return 0 <TAB>  <TAB>  <TAB> raise",if ex2 . args [ 0 ] == EWOULDBLOCK :,175
"def server_decode(self, buf): <TAB> if self.has_recv_header: <TAB>  <TAB> return (buf, True, False) <TAB> self.has_recv_header = True <TAB> crc = binascii.crc32(buf) & 0xFFFFFFFF <TAB> if crc != 0xFFFFFFFF: <TAB>  <TAB> self.has_sent_header = True <MASK> return (b""E"" * 2048, False, False) <TAB>  <TAB> return (buf, True, False) <TAB> # (buffer_to_recv, is_need_decrypt, is_need_to_encode_and_send_back) <TAB> return (b"""", False, True)","if self . method == ""random_head"" :",158
"def Decode(self, filedesc): <TAB> while True: <TAB>  <TAB> chunk = filedesc.Read(4) <TAB>  <TAB> if not chunk: <TAB>  <TAB>  <TAB> return <MASK> yield b""NORF"" <TAB>  <TAB> if chunk == b""THUD"": <TAB>  <TAB>  <TAB> yield b""BLARGH""","if chunk == b""QUUX"" :",82
"def decProcess(): <TAB> while 1: <TAB>  <TAB> yield clock.posedge, reset.negedge <TAB>  <TAB> if reset == ACTIVE_LOW: <TAB>  <TAB>  <TAB> count.next = 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if enable: <MASK> count.next = n - 1 <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> count.next = count - 1",if count == - n :,100
"def set_torrent_path(self, torrent_id, path): <TAB> try: <MASK> return False <TAB>  <TAB> self.client.core.set_torrent_move_completed_path(torrent_id, path).get() <TAB>  <TAB> self.client.core.set_torrent_move_completed(torrent_id, 1).get() <TAB> except Exception: <TAB>  <TAB> return False <TAB> finally: <TAB>  <TAB> if self.client: <TAB>  <TAB>  <TAB> self.disconnect() <TAB> return True",if not self . connect ( ) :,123
"def stale_rec(node, nodes): <TAB> if node.abspath() in node.ctx.env[Build.CFG_FILES]: <TAB>  <TAB> return <TAB> if getattr(node, ""children"", []): <TAB>  <TAB> for x in node.children.values(): <MASK> stale_rec(x, nodes) <TAB> else: <TAB>  <TAB> for ext in DYNAMIC_EXT: <TAB>  <TAB>  <TAB> if node.name.endswith(ext): <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if not node in nodes: <TAB>  <TAB>  <TAB>  <TAB> if can_delete(node): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> Logs.warn(""Removing stale file -> %r"", node) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> node.delete()","if x . name != ""c4che"" :",177
"def iterate(self, prod_, rule_): <TAB> newProduction = """" <TAB> for i in range(len(prod_)): <TAB>  <TAB> step = self.production[i] <TAB>  <TAB> if step == ""W"": <TAB>  <TAB>  <TAB> newProduction = newProduction + self.ruleW <MASK> newProduction = newProduction + self.ruleX <TAB>  <TAB> elif step == ""Y"": <TAB>  <TAB>  <TAB> newProduction = newProduction + self.ruleY <TAB>  <TAB> elif step == ""Z"": <TAB>  <TAB>  <TAB> newProduction = newProduction + self.ruleZ <TAB>  <TAB> elif step != ""F"": <TAB>  <TAB>  <TAB> newProduction = newProduction + step <TAB> self.drawLength = self.drawLength * 0.5 <TAB> self.generations += 1 <TAB> return newProduction","elif step == ""X"" :",179
"def _get_app_params(self): <TAB> params = self.cfg.params.copy() <TAB> for key, value in self.__dict__.items(): <TAB>  <TAB> if key.startswith(""_""): <TAB>  <TAB>  <TAB> continue <MASK> params[""parse_console""] = not value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> params[key] = value <TAB> params[""load_config""] = False <TAB> return params","elif key == ""console_parsed"" :",102
"def __setitem__(self, key, value): <TAB> if not isinstance(value, PseudoNamespace): <TAB>  <TAB> tuple_converted = False <TAB>  <TAB> if isinstance(value, dict): <TAB>  <TAB>  <TAB> value = PseudoNamespace(value) <MASK> value = list(value) <TAB>  <TAB>  <TAB> tuple_converted = True <TAB>  <TAB> if isinstance(value, list): <TAB>  <TAB>  <TAB> for i, item in enumerate(value): <TAB>  <TAB>  <TAB>  <TAB> if isinstance(item, dict) and not isinstance(item, PseudoNamespace): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value[i] = PseudoNamespace(item) <TAB>  <TAB>  <TAB> if tuple_converted: <TAB>  <TAB>  <TAB>  <TAB> value = tuple(value) <TAB> super(PseudoNamespace, self).__setitem__(key, value)","elif isinstance ( value , tuple ) :",175
"def getNextSibling(self, node): <TAB> if isinstance(node, tuple):  # Text node <TAB>  <TAB> node, key = node <TAB>  <TAB> assert key in (""text"", ""tail""), ""Text nodes are text or tail, found %s"" % key <TAB>  <TAB> if key == ""text"": <TAB>  <TAB>  <TAB> # XXX: we cannot use a ""bool(node) and node[0] or None"" construct here <TAB>  <TAB>  <TAB> # because node[0] might evaluate to False if it has no child element <MASK> return node[0] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> else:  # tail <TAB>  <TAB>  <TAB> return node.getnext() <TAB> return (node, ""tail"") if node.tail else node.getnext()",if len ( node ) :,182
"def star_path(path): <TAB> """"""Replace integers and integer-strings in a path with *"""""" <TAB> path = list(path) <TAB> for i, p in enumerate(path): <TAB>  <TAB> if isinstance(p, int): <TAB>  <TAB>  <TAB> path[i] = ""*"" <TAB>  <TAB> else: <MASK> p = p.decode() <TAB>  <TAB>  <TAB> if r_is_int.match(p): <TAB>  <TAB>  <TAB>  <TAB> path[i] = ""*"" <TAB> return join_path(path)","if not isinstance ( p , text_type ) :",127
"def ensure_popup_selection(self): <TAB> try: <TAB>  <TAB> self.__position_at_mouse <TAB> except AttributeError: <TAB>  <TAB> path, col = self.get_cursor() <MASK> return False <TAB>  <TAB> self.scroll_to_cell(path, col) <TAB>  <TAB> # ensure current cursor path is selected, just like right-click <TAB>  <TAB> selection = self.get_selection() <TAB>  <TAB> if not selection.path_is_selected(path): <TAB>  <TAB>  <TAB> selection.unselect_all() <TAB>  <TAB>  <TAB> selection.select_path(path) <TAB>  <TAB> return True",if path is None :,141
"def release(self): <TAB> me, lock_count = self.__begin() <TAB> try: <MASK> return <TAB>  <TAB> self._count = count = self._count - 1 <TAB>  <TAB> if not count: <TAB>  <TAB>  <TAB> self._owner = None <TAB>  <TAB>  <TAB> self._block.release() <TAB> finally: <TAB>  <TAB> self.__end(me, lock_count)",if me is None :,92
"def date_match(self, date1, date2): <TAB> if date1.is_empty() or date2.is_empty(): <TAB>  <TAB> return 0 <TAB> if date1.is_equal(date2): <TAB>  <TAB> return 1 <TAB> if date1.is_compound() or date2.is_compound(): <TAB>  <TAB> return self.range_compare(date1, date2) <TAB> if date1.get_year() == date2.get_year(): <TAB>  <TAB> if date1.get_month() == date2.get_month(): <TAB>  <TAB>  <TAB> return 0.75 <MASK> return 0.75 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return -1 <TAB> else: <TAB>  <TAB> return -1",if not date1 . get_month_valid ( ) or not date2 . get_month_valid ( ) :,189
"def onMinimize(self, sender): <TAB> if self._runDialogListener(""onMinimize"") is False: <TAB>  <TAB> return <TAB> widget = self.child <TAB> if widget is not None: <MASK> widget.setVisible(False) <TAB>  <TAB>  <TAB> self.setHeight("""") <TAB>  <TAB>  <TAB> self.setWidth("""") <TAB>  <TAB>  <TAB> if self._maximized: <TAB>  <TAB>  <TAB>  <TAB> self._minimized = self._maximized <TAB>  <TAB>  <TAB>  <TAB> self._toggleMaximize() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._minimized = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if self._minimized is not None: <TAB>  <TAB>  <TAB>  <TAB> self._toggleMaximize() <TAB>  <TAB>  <TAB> widget.setVisible(True)",if widget . isVisible ( ) :,171
"def instance_reader(): <TAB> for epoch_index in range(epoch): <MASK> if shuffle_seed is not None: <TAB>  <TAB>  <TAB>  <TAB> np.random.seed(shuffle_seed) <TAB>  <TAB>  <TAB> np.random.shuffle(examples) <TAB>  <TAB> if phase == ""train"": <TAB>  <TAB>  <TAB> self.current_train_epoch = epoch_index <TAB>  <TAB> for (index, example) in enumerate(examples): <TAB>  <TAB>  <TAB> if phase == ""train"": <TAB>  <TAB>  <TAB>  <TAB> self.current_train_example = index + 1 <TAB>  <TAB>  <TAB> feature = self.convert_example( <TAB>  <TAB>  <TAB>  <TAB> index, example, self.get_labels(), self.max_seq_len, self.tokenizer <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> instance = self.generate_instance(feature) <TAB>  <TAB>  <TAB> yield instance",if shuffle :,189
"def _parse_lines(self, linesource): <TAB> """"""Parse lines of text for functions and classes"""""" <TAB> functions = [] <TAB> classes = [] <TAB> for line in linesource: <TAB>  <TAB> if line.startswith(""def "") and line.count(""(""): <TAB>  <TAB>  <TAB> # exclude private stuff <TAB>  <TAB>  <TAB> name = self._get_object_name(line) <TAB>  <TAB>  <TAB> if not name.startswith(""_""): <TAB>  <TAB>  <TAB>  <TAB> functions.append(name) <MASK> # exclude private stuff <TAB>  <TAB>  <TAB> name = self._get_object_name(line) <TAB>  <TAB>  <TAB> if not name.startswith(""_""): <TAB>  <TAB>  <TAB>  <TAB> classes.append(name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pass <TAB> functions.sort() <TAB> classes.sort() <TAB> return functions, classes","elif line . startswith ( ""class "" ) :",185
"def get_folder_version(folder): <TAB> f = os.path.join(code_path, folder, ""version.txt"") <TAB> try: <TAB>  <TAB> with open(f) as fd: <TAB>  <TAB>  <TAB> content = fd.read() <TAB>  <TAB>  <TAB> p = re.compile(r""([0-9]+)\.([0-9]+)\.([0-9]+)"") <TAB>  <TAB>  <TAB> m = p.match(content) <MASK> version = m.group(1) + ""."" + m.group(2) + ""."" + m.group(3) <TAB>  <TAB>  <TAB>  <TAB> return version <TAB> except: <TAB>  <TAB> return False",if m :,151
"def __init__( <TAB> self, plugin_name=None, builtin=False, deprecated=False, config=None, session=None): <TAB> if builtin and isinstance(builtin, (str, unicode)): <TAB>  <TAB> builtin = os.path.basename(builtin) <TAB>  <TAB> for ignore in ("".py"", "".pyo"", "".pyc""): <TAB>  <TAB>  <TAB> if builtin.endswith(ignore): <TAB>  <TAB>  <TAB>  <TAB> builtin = builtin[: -len(ignore)] <MASK> self.LOADED.append(builtin) <TAB> self.loading_plugin = plugin_name <TAB> self.loading_builtin = plugin_name and builtin <TAB> self.builtin = builtin <TAB> self.deprecated = deprecated <TAB> self.session = session <TAB> self.config = config <TAB> self.manifests = []",if builtin not in self . LOADED :,181
"def setInt(self, path, value, **kwargs): <TAB> if value is None: <TAB>  <TAB> self.set(path, None, **kwargs) <TAB>  <TAB> return <TAB> minimum = kwargs.pop(""min"", None) <TAB> maximum = kwargs.pop(""max"", None) <TAB> try: <TAB>  <TAB> intValue = int(value) <MASK> intValue = minimum <TAB>  <TAB> if maximum is not None and intValue > maximum: <TAB>  <TAB>  <TAB> intValue = maximum <TAB> except ValueError: <TAB>  <TAB> self._logger.warning( <TAB>  <TAB>  <TAB> ""Could not convert %r to a valid integer when setting option %r"" <TAB>  <TAB>  <TAB> % (value, path) <TAB>  <TAB> ) <TAB>  <TAB> return <TAB> self.set(path, intValue, **kwargs)",if minimum is not None and intValue < minimum :,187
"def __call__(self, session_path): <TAB> """"""Get raw session object from `session_path`."""""" <TAB> new_session = copy.deepcopy(self._template) <TAB> session_keys = new_session.keys() <TAB> old_session = self._load_file(session_path) <TAB> for attribute in dir(self): <MASK> target = attribute[4:].capitalize() <TAB>  <TAB>  <TAB> if target not in session_keys: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""Invalid attribute: %r"" % attribute) <TAB>  <TAB>  <TAB> function = getattr(self, attribute) <TAB>  <TAB>  <TAB> new_session[target] = function(old_session) <TAB> return new_session","if attribute . startswith ( ""set_"" ) :",161
"def add_comment_to_directory(args, dir_path): <TAB> for root, _, files in os.walk(dir_path): <TAB>  <TAB> for file_name in files: <MASK> continue <TAB>  <TAB>  <TAB> file_path = os.path.join(root, file_name) <TAB>  <TAB>  <TAB> add_comment_to_file(args, file_path)","if not re . match ( r"".*(\.c|\.h|\.cpp|\.hpp|\.cxx|\.hxx)$"" , file_name ) :",122
"def reportMemory(k, options, field=None, isBytes=False): <TAB> """"""Given k kilobytes, report back the correct format as string."""""" <TAB> if options.pretty: <TAB>  <TAB> return prettyMemory(int(k), field=field, isBytes=isBytes) <TAB> else: <MASK> k /= 1024.0 <TAB>  <TAB> if field is not None: <TAB>  <TAB>  <TAB> return ""%*dK"" % (field - 1, k)  # -1 for the ""K"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""%dK"" % int(k)",if isBytes :,135
"def resolve(self, arguments): <TAB> positional = [] <TAB> named = {} <TAB> for arg in arguments: <TAB>  <TAB> if self._is_named(arg): <TAB>  <TAB>  <TAB> self._add_named(arg, named) <MASK> self._raise_positional_after_named() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> positional.append(arg) <TAB> return positional, named",elif named :,92
"def _load_from_cache(self): <TAB> if self._cache_key in self._cache: <TAB>  <TAB> creds = deepcopy(self._cache[self._cache_key]) <MASK> return creds <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logger.debug(""Credentials were found in cache, but they are expired."") <TAB> return None",if not self . _is_expired ( creds ) :,88
"def convertstore(self, inputstore, includefuzzy=False): <TAB> """"""converts a file to .lang format"""""" <TAB> thetargetfile = lang.LangStore(mark_active=self.mark_active) <TAB> # Run over the po units <TAB> for pounit in inputstore.units: <TAB>  <TAB> if pounit.isheader() or not pounit.istranslatable(): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> newunit = thetargetfile.addsourceunit(pounit.source) <TAB>  <TAB> if includefuzzy or not pounit.isfuzzy(): <TAB>  <TAB>  <TAB> newunit.settarget(pounit.target) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> newunit.settarget("""") <MASK> newunit.addnote(pounit.getnotes(""developer""), ""developer"") <TAB> return thetargetfile","if pounit . getnotes ( ""developer"" ) :",196
"def __init__(self, *args, **kwargs): <TAB> super().__init__(*args, **kwargs) <TAB> for exclude_field in self.context[""request""].query_params.getlist(""exclude""): <TAB>  <TAB> p = exclude_field.split(""."") <MASK> if len(p) == 1: <TAB>  <TAB>  <TAB>  <TAB> del self.fields[p[0]] <TAB>  <TAB>  <TAB> elif len(p) == 2: <TAB>  <TAB>  <TAB>  <TAB> self.fields[p[0]].child.fields.pop(p[1])",if p [ 0 ] in self . fields :,130
"def __init__(self, fn, args, resources): <TAB> self.fn = fn <TAB> self.args = copy.deepcopy(args) <TAB> self.resources = resources <TAB> with Task.LOCK: <TAB>  <TAB> self.task_id = Task.TASK_ID.value <MASK> if isinstance( <TAB>  <TAB>  <TAB>  <TAB> self.args[""args""], (argparse.Namespace, argparse.ArgumentParser) <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> args_dict = vars(self.args[""args""]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> args_dict = self.args[""args""] <TAB>  <TAB>  <TAB> args_dict.update({""task_id"": self.task_id}) <TAB>  <TAB> Task.TASK_ID.value += 1","if ""args"" in self . args :",176
"def _expand_nsplit_by_reduce(splits, reduced): <TAB> if reduced == 1: <TAB>  <TAB> return splits <TAB> out = [] <TAB> for s in splits: <TAB>  <TAB> x = s <TAB>  <TAB> part = max(x / reduced, 1) <TAB>  <TAB> while x >= 2 * part: <TAB>  <TAB>  <TAB> out.append(int(part)) <TAB>  <TAB>  <TAB> x -= int(part) <MASK> out.append(x) <TAB> assert sum(splits) == sum(out) <TAB> return tuple(out)",if x :,125
"def OnDeleteLine(self, items): <TAB> for n in items: <MASK> name1 = self.items[n][2] <TAB>  <TAB>  <TAB> name2 = self.items[n][4] <TAB>  <TAB>  <TAB> del self.items[n] <TAB>  <TAB>  <TAB> if name1 in self.bindiff.matched1: <TAB>  <TAB>  <TAB>  <TAB> self.bindiff.matched1.remove(name1) <TAB>  <TAB>  <TAB> if name2 in self.bindiff.matched2: <TAB>  <TAB>  <TAB>  <TAB> self.bindiff.matched2.remove(name2) <TAB> return [Choose.ALL_CHANGED] + items",if n >= 0 :,146
"def _to_str(self, tokens: List[int]) -> str: <TAB> pos = next( <TAB>  <TAB> (idx for idx, x in enumerate(tokens) if x == self.vocab.eos_token_id), -1 <TAB> ) <TAB> if pos != -1: <TAB>  <TAB> tokens = tokens[:pos] <TAB> vocab_map = self.vocab.id_to_token_map_py <TAB> words = [vocab_map[t] for t in tokens] <TAB> if self.encoding is not None and self.perform_decode: <MASK> words = self.bpe_decode(words) <TAB>  <TAB> elif self.encoding == ""spm"": <TAB>  <TAB>  <TAB> words = self.spm_decode(words) <TAB> sentence = "" "".join(words) <TAB> return sentence","if self . encoding == ""bpe"" :",188
"def detect(content, **kwargs): <TAB> headers = kwargs.get(""headers"", {}) <TAB> content = str(content) <TAB> detection_schema = ( <TAB>  <TAB> re.compile(r""\Abarra.counter.session(=)?"", re.I), <TAB>  <TAB> re.compile(r""(\A|\b)?barracuda."", re.I), <TAB>  <TAB> re.compile(r""barracuda.networks(.)?.inc"", re.I), <TAB> ) <TAB> for detection in detection_schema: <MASK> return True <TAB>  <TAB> if detection.search(content) is not None: <TAB>  <TAB>  <TAB> return True","if detection . search ( headers . get ( HTTP_HEADER . SET_COOKIE , """" ) ) is not None :",165
"def _finish_port_forward(self, listener, listen_host, listen_port): <TAB> """"""Finish processing a TCP/IP port forwarding request"""""" <TAB> if asyncio.iscoroutine(listener): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> listener = yield from listener <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> listener = None <TAB> if listener: <MASK> listen_port = listener.get_port() <TAB>  <TAB>  <TAB> result = UInt32(listen_port) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result = True <TAB>  <TAB> self._local_listeners[listen_host, listen_port] = listener <TAB>  <TAB> self._report_global_response(result) <TAB> else: <TAB>  <TAB> self.logger.debug1(""Failed to create TCP listener"") <TAB>  <TAB> self._report_global_response(False)",if listen_port == 0 :,192
"def start(self): <TAB> """"""Start running the mainloop."""""" <TAB> with self: <TAB>  <TAB> result = pa.pa_threaded_mainloop_start(self._pa_threaded_mainloop) <MASK> raise PulseAudioException(0, ""Failed to start PulseAudio mainloop"") <TAB> assert _debug(""PulseAudioMainLoop: Started"")",if result < 0 :,85
def service(self): <TAB> try: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.start() <TAB>  <TAB>  <TAB> self.execute() <TAB>  <TAB>  <TAB> self.finish() <TAB>  <TAB> except socket.error: <TAB>  <TAB>  <TAB> self.close_on_finish = True <MASK> raise <TAB> finally: <TAB>  <TAB> pass,if self . channel . adj . log_socket_errors :,91
"def _makepath(self, path): <TAB> if not self.abspath: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> np = py.path.local().bestrelpath(path) <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> return path <MASK> path = np <TAB> return path",if len ( np ) < len ( str ( path ) ) :,78
"def upload( <TAB> youtube_resource, video_path, body, chunksize=1024 * 1024, progress_callback=None): <TAB> body_keys = "","".join(body.keys()) <TAB> media = MediaFileUpload(video_path, chunksize=chunksize, resumable=True) <TAB> videos = youtube_resource.videos() <TAB> request = videos.insert(part=body_keys, body=body, media_body=media) <TAB> while 1: <TAB>  <TAB> status, response = request.next_chunk() <MASK> if ""id"" in response: <TAB>  <TAB>  <TAB>  <TAB> return response[""id""] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise KeyError(""Response has no 'id' field"") <TAB>  <TAB> elif status and progress_callback: <TAB>  <TAB>  <TAB> progress_callback(status.total_size, status.resumable_progress)",if response :,197
"def __init__(self, *args, **kwargs): <TAB> super().__init__(*args, **kwargs) <TAB> for exclude_field in self.context[""request""].query_params.getlist(""exclude""): <TAB>  <TAB> p = exclude_field.split(""."") <TAB>  <TAB> if p[0] in self.fields: <MASK> del self.fields[p[0]] <TAB>  <TAB>  <TAB> elif len(p) == 2: <TAB>  <TAB>  <TAB>  <TAB> self.fields[p[0]].child.fields.pop(p[1])",if len ( p ) == 1 :,130
"def on_button_press_event(self, iconview, event): <TAB> # print('on_button_press_event') <TAB> if event.button == 3: <TAB>  <TAB> popup_menu = Gtk.Menu() <TAB>  <TAB> x = int(event.x) <TAB>  <TAB> y = int(event.y) <TAB>  <TAB> time = event.time <TAB>  <TAB> pathinfo = iconview.get_path_at_pos(x, y) <MASK> iconview.grab_focus() <TAB>  <TAB>  <TAB> self.do_populate_popup(popup_menu, pathinfo) <TAB>  <TAB>  <TAB> # FIXME should use a signal here <TAB>  <TAB>  <TAB> gtk_popup_at_pointer(popup_menu, event) <TAB>  <TAB>  <TAB> return True <TAB> return False",if pathinfo is not None :,180
"def __rshift__(self, other): <TAB> if not self.symbolic and type(other) is int: <TAB>  <TAB> return RegisterOffset( <TAB>  <TAB>  <TAB> self._bits, self.reg, self._to_signed(self.offset >> other) <TAB>  <TAB> ) <TAB> else: <MASK> return RegisterOffset(self._bits, self.reg, self.offset >> other) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return RegisterOffset( <TAB>  <TAB>  <TAB>  <TAB> self._bits, <TAB>  <TAB>  <TAB>  <TAB> self.reg, <TAB>  <TAB>  <TAB>  <TAB> ArithmeticExpression( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ArithmeticExpression.RShift, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.offset, <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> other, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB> )",if self . symbolic :,192
"def _slice_positional_metadata(self, indexable): <TAB> if self.has_positional_metadata(): <MASK> index = _single_index_to_slice(indexable) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> index = indexable <TAB>  <TAB> return self.positional_metadata.iloc[index] <TAB> else: <TAB>  <TAB> return None",if _is_single_index ( indexable ) :,91
"def _show_env(name=None): <TAB> if name is None: <TAB>  <TAB> name = """" <TAB> env = peda.execute_redirect(""show env"") <TAB> for line in env.splitlines(): <TAB>  <TAB> (k, v) = line.split(""="", 1) <MASK> msg(""%s = %s"" % (k, v if is_printable(v) else to_hexstr(v))) <TAB> return",if k . startswith ( name ) :,106
"def skip_to_semicolon(s, i): <TAB> n = len(s) <TAB> while i < n: <TAB>  <TAB> c = s[i] <TAB>  <TAB> if c == "";"": <TAB>  <TAB>  <TAB> return i <TAB>  <TAB> elif c == ""'"" or c == '""': <TAB>  <TAB>  <TAB> i = g.skip_string(s, i) <MASK> i = g.skip_to_end_of_line(s, i) <TAB>  <TAB> elif g.match(s, i, ""/*""): <TAB>  <TAB>  <TAB> i = g.skip_block_comment(s, i) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> i += 1 <TAB> return i","elif g . match ( s , i , ""//"" ) :",161
"def filter_iterable(cls, iterable, filterset_class, filters_name, info, **args): <TAB> filter_input = args.get(filters_name) <TAB> if filter_input and filterset_class: <TAB>  <TAB> instance = filterset_class( <TAB>  <TAB>  <TAB> data=dict(filter_input), queryset=iterable, request=info.context <TAB>  <TAB> ) <TAB>  <TAB> # Make sure filter input has valid values <MASK> raise GraphQLError(json.dumps(instance.errors.get_json_data())) <TAB>  <TAB> iterable = instance.qs <TAB> return iterable",if not instance . is_valid ( ) :,137
"def build(opt): <TAB> dpath = os.path.join(opt[""datapath""], ""self_feeding"") <TAB> version = ""3.1"" <TAB> if not build_data.built(dpath, version): <TAB>  <TAB> print(""[building data: "" + dpath + ""]"") <MASK> # An older version exists, so remove these outdated files. <TAB>  <TAB>  <TAB> build_data.remove_dir(dpath) <TAB>  <TAB> build_data.make_dir(dpath) <TAB>  <TAB> # Download the data. <TAB>  <TAB> for downloadable_file in RESOURCES: <TAB>  <TAB>  <TAB> downloadable_file.download_file(dpath) <TAB>  <TAB> build_data.mark_done(dpath, version)",if build_data . built ( dpath ) :,169
"def get_tokens_unprocessed(self, text): <TAB> for index, token, value in RegexLexer.get_tokens_unprocessed(self, text): <TAB>  <TAB> if token is Name: <TAB>  <TAB>  <TAB> if self.stdlibhighlighting and value in self.stdlib_types: <TAB>  <TAB>  <TAB>  <TAB> token = Keyword.Type <MASK> token = Keyword.Type <TAB>  <TAB>  <TAB> elif self.platformhighlighting and value in self.linux_types: <TAB>  <TAB>  <TAB>  <TAB> token = Keyword.Type <TAB>  <TAB> yield index, token, value",elif self . c99highlighting and value in self . c99_types :,141
"def searchOpcode(self, opcode, name=None): <TAB> to_return = {} <TAB> if not name: <TAB>  <TAB> for file in self.__files: <TAB>  <TAB>  <TAB> to_return[file.loader.fileName] = self.__ropper.searchOpcode( <TAB>  <TAB>  <TAB>  <TAB> file.loader, opcode <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> fc = self.getFileFor(name) <MASK> raise RopperError(""No such file opened: %s"" % name) <TAB>  <TAB> to_return[name] = self.__ropper.searchOpcode(fc.loader, opcode) <TAB> return self.__filterBadBytes(to_return)",if not fc :,158
"def logic(): <TAB> while 1: <TAB>  <TAB> yield clock.posedge, reset.negedge <MASK> count.next = 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if enable: <TAB>  <TAB>  <TAB>  <TAB> if count == -n: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> count.next = n - 1 <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> count.next = count - 1",if reset == ACTIVE_LOW :,99
"def upgrade_cursor(cursor): <TAB> count = 0 <TAB> prefix = pack_be_uint16(cursor) <TAB> key_len = HASHX_LEN + 2 <TAB> chunks = util.chunks <TAB> with self.db.write_batch() as batch: <TAB>  <TAB> batch_put = batch.put <TAB>  <TAB> for key, hist in self.db.iterator(prefix=prefix): <TAB>  <TAB>  <TAB> # Ignore non-history entries <MASK> continue <TAB>  <TAB>  <TAB> count += 1 <TAB>  <TAB>  <TAB> hist = b"""".join(item + b""\0"" for item in chunks(hist, 4)) <TAB>  <TAB>  <TAB> batch_put(key, hist) <TAB>  <TAB> self.upgrade_cursor = cursor <TAB>  <TAB> self.write_state(batch) <TAB> return count",if len ( key ) != key_len :,187
"def fork(receiver: Receiver, func, *args, **kwargs): <TAB> current_actor = self() <TAB> send(Fork(current_actor, func, args, kwargs), receiver) <TAB> while True: <TAB>  <TAB> message = recv(current_actor) <MASK> return message.new_actor <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> send(message, current_actor) <TAB> return","if isinstance ( message , ForkResponse ) :",100
"def history_move(self, n): <TAB> from ranger.container.history import HistoryEmptyException <TAB> try: <TAB>  <TAB> current = self.history.current() <TAB> except HistoryEmptyException: <TAB>  <TAB> pass <TAB> else: <MASK> self.history.modify(self.line) <TAB>  <TAB> self.history.move(n) <TAB>  <TAB> current = self.history.current() <TAB>  <TAB> if self.line != current: <TAB>  <TAB>  <TAB> self.line = self.history.current() <TAB>  <TAB>  <TAB> self.pos = len(self.line)",if self . line != current and self . line != self . history . top ( ) :,147
"def fullname(self): <TAB> if self._fullname is None: <TAB>  <TAB> pkg_name = namespace.apply_namespace(self.dist.project_name) <MASK> self._fullname = ""%s/%s"" % (pkg_name, self.name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._fullname = self.name <TAB> return self._fullname","if pkg_name and pkg_name != ""."" :",94
"def do_install(datafilename): <TAB> ifile = open(datafilename, ""rb"") <TAB> d = pickle.load(ifile) <TAB> destdir_var = ""DESTDIR"" <TAB> if destdir_var in os.environ: <MASK> subdir = d.prefix[1:] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> subdir = d.prefix <TAB>  <TAB> d.prefix = os.path.join(os.environ[destdir_var], subdir) <TAB> install_targets(d) <TAB> install_headers(d) <TAB> install_man(d) <TAB> install_data(d) <TAB> install_po(d)","if d . prefix [ 0 ] == ""/"" :",155
"def truncate(self, size=None): <TAB> # type: (Optional[int]) -> int <TAB> # Inefficient, but I don't know if truncate is possible with ftp <TAB> with self._lock: <MASK> size = self.tell() <TAB>  <TAB> with self.fs.openbin(self.path) as f: <TAB>  <TAB>  <TAB> data = f.read(size) <TAB>  <TAB> with self.fs.openbin(self.path, ""w"") as f: <TAB>  <TAB>  <TAB> f.write(data) <TAB>  <TAB>  <TAB> if len(data) < size: <TAB>  <TAB>  <TAB>  <TAB> f.write(b""\0"" * (size - len(data))) <TAB> return size",if size is None :,163
"def write(self, expression, location=None): <TAB> # If the phrase is incomplete, utop will not remember it, so <TAB> # we need to account for it here. Also, Shift+Enter will add a literal <TAB> # newline, which would otherwise break protocol. <TAB> for line in expression.split(""\n""): <TAB>  <TAB> self._phrase.append(line) <MASK> self._phrase_line_begins.append(location) <TAB>  <TAB>  <TAB> location += len(line) + 1 <TAB> self.write_command(""input"", ""allow-incomplete"", self._phrase)",if location is not None :,139
"def scan_iter(self, match=None, count=None): <TAB> nodes = await self.cluster_nodes() <TAB> for node in nodes: <TAB>  <TAB> if ""master"" in node[""flags""]: <TAB>  <TAB>  <TAB> cursor = ""0"" <TAB>  <TAB>  <TAB> while cursor != 0: <TAB>  <TAB>  <TAB>  <TAB> pieces = [cursor] <MASK> pieces.extend([""MATCH"", match]) <TAB>  <TAB>  <TAB>  <TAB> if count is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pieces.extend([""COUNT"", count]) <TAB>  <TAB>  <TAB>  <TAB> response = await self.execute_command_on_nodes([node], ""SCAN"", *pieces) <TAB>  <TAB>  <TAB>  <TAB> cursor, data = list(response.values())[0] <TAB>  <TAB>  <TAB>  <TAB> for item in data: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield item",if match is not None :,185
"def communicate(self, input_data=None): <TAB> """"""Mock subprocess.Popen.communicate."""""" <TAB> for i in range(2): <TAB>  <TAB> timeout = execute_time if i == 0 else sigterm_handler_time <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> received_signal = self.signal_queue.get(block=True, timeout=timeout) <TAB>  <TAB> except queue.Empty: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> self.received_signals.append((received_signal, time.time() - self.start_time)) <MASK> break <TAB> return output, None",if received_signal == Signal . KILL :,142
"def _add_bookmark_breakpoint(self): <TAB> """"""Add a bookmark or breakpoint to the current file in the editor."""""" <TAB> editorWidget = self.ide.mainContainer.get_actual_editor() <TAB> if editorWidget and editorWidget.hasFocus(): <TAB>  <TAB> if self.ide.mainContainer.actualTab.navigator.operation == 1: <TAB>  <TAB>  <TAB> editorWidget._sidebarWidget.set_bookmark( <TAB>  <TAB>  <TAB>  <TAB> editorWidget.textCursor().blockNumber() <TAB>  <TAB>  <TAB> ) <MASK> editorWidget._sidebarWidget.set_breakpoint( <TAB>  <TAB>  <TAB>  <TAB> editorWidget.textCursor().blockNumber() <TAB>  <TAB>  <TAB> )",elif self . ide . mainContainer . actualTab . navigator . operation == 2 :,175
"def _should_auto_select_container_version(instance_type, distribution): <TAB> """"""Returns a boolean that indicates whether to use an auto-selected container version."""""" <TAB> p4d = False <TAB> if instance_type: <TAB>  <TAB> # looks for either ""ml.<family>.<size>"" or ""ml_<family>"" <TAB>  <TAB> match = re.match(r""^ml[\._]([a-z\d]+)\.?\w*$"", instance_type) <MASK> family = match[1] <TAB>  <TAB>  <TAB> p4d = family == ""p4d"" <TAB> smdistributed = False <TAB> if distribution: <TAB>  <TAB> smdistributed = ""smdistributed"" in distribution <TAB> return p4d or smdistributed",if match :,164
"def _flush_some_if_lockable(self): <TAB> # Since our task may be appending to the outbuf, we try to acquire <TAB> # the lock, but we don't block if we can't. <TAB> if self.outbuf_lock.acquire(False): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self._flush_some() <MASK> self.outbuf_lock.notify() <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self.outbuf_lock.release()",if self . total_outbufs_len < self . adj . outbuf_high_watermark :,134
"def add_auth(self, req, **kwargs): <TAB> if not ""x-amz-content-sha256"" in req.headers: <MASK> req.headers[""x-amz-content-sha256""] = req.headers.pop(""_sha256"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> req.headers[""x-amz-content-sha256""] = self.payload(req) <TAB> req = self.mangle_path_and_params(req) <TAB> return super(S3HmacAuthV4Handler, self).add_auth(req, **kwargs)","if ""_sha256"" in req . headers :",145
"def get_objects(self): <TAB> list_type, id, handles, timestamp = self._obj_list <TAB> retval = [] <TAB> for (target, handle) in handles: <TAB>  <TAB> _class = map2class(target) <TAB>  <TAB> if _class: <TAB>  <TAB>  <TAB> obj = _class(self._dbstate, pickle.dumps((target, id, handle, timestamp))) <MASK> retval.append(obj) <TAB> return retval",if obj :,108
"def toggle_fullscreen_hide_tabbar(self): <TAB> if self.is_fullscreen(): <TAB>  <TAB> if self.settings.general.get_boolean(""fullscreen-hide-tabbar""): <MASK> self.guake.notebook_manager.set_notebooks_tabbar_visible(False) <TAB> else: <TAB>  <TAB> if self.guake and self.guake.notebook_manager: <TAB>  <TAB>  <TAB> v = self.settings.general.get_boolean(""window-tabbar"") <TAB>  <TAB>  <TAB> self.guake.notebook_manager.set_notebooks_tabbar_visible(v)",if self . guake and self . guake . notebook_manager :,159
"def __repr__(self): <TAB> parts = [] <TAB> if not approx_equal(self.constant, 0.0) or self.is_constant: <TAB>  <TAB> parts.append(repr(self.constant)) <TAB> for clv, coeff in sorted(self.terms.items(), key=lambda x: repr(x)): <MASK> parts.append(repr(clv)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> parts.append(repr(coeff) + ""*"" + repr(clv)) <TAB> return "" + "".join(parts)","if approx_equal ( coeff , 1.0 ) :",135
"def wrapper(*args, **kwds): <TAB> global bootstrap_logger_enabled <TAB> if bootstrap_logger_enabled: <MASK> bootstrap_logger.exception(msg=args[0]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> bootstrap_logger.log(level=level, msg=args[0]) <TAB> return f(*args, **kwds)","if level == ""EXCEPTION"" :",86
"def get_sorted_entry(field, bookid): <TAB> if field == ""title"" or field == ""authors"": <TAB>  <TAB> book = calibre_db.get_filtered_book(bookid) <TAB>  <TAB> if book: <TAB>  <TAB>  <TAB> if field == ""title"": <TAB>  <TAB>  <TAB>  <TAB> return json.dumps({""sort"": book.sort}) <MASK> return json.dumps({""author_sort"": book.author_sort}) <TAB> return """"","elif field == ""authors"" :",111
"def movies_iterator(): <TAB> for row in self._tuple_iterator(query): <TAB>  <TAB> id, guid, movie = self._parse(fields, row, offset=2) <TAB>  <TAB> # Parse `guid` (if enabled, and not already parsed) <TAB>  <TAB> if parse_guid: <MASK> guids[id] = Guid.parse(guid) <TAB>  <TAB>  <TAB> guid = guids[id] <TAB>  <TAB> # Return item <TAB>  <TAB> yield id, guid, movie",if id not in guids :,119
"def update_sockets(self, context): <TAB> bools = [self.min_list, self.max_list, self.size_list] <TAB> dims = int(self.dimensions[0]) <TAB> for i in range(3): <TAB>  <TAB> for j in range(3): <TAB>  <TAB>  <TAB> out_index = 4 + j + 3 * i <TAB>  <TAB>  <TAB> hidden = self.outputs[out_index].hide_safe <TAB>  <TAB>  <TAB> if bools[i][j] and j < dims: <MASK> self.outputs[out_index].hide_safe = False <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.outputs[out_index].hide_safe = True <TAB>  <TAB> updateNode(self, context)",if hidden :,173
"def broadcast(self, msg, eid): <TAB> for s in self.subs: <TAB>  <TAB> if type(self.subs[s].eid) is list: <MASK> self.subs[s].write_message(msg) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if self.subs[s].eid == eid: <TAB>  <TAB>  <TAB>  <TAB> self.subs[s].write_message(msg)",if eid in self . subs [ s ] . eid :,111
"def as_create_delta( <TAB> self: CallableObjectT, <TAB> schema: s_schema.Schema, <TAB> context: so.ComparisonContext,) -> sd.ObjectCommand[CallableObjectT]: <TAB> delta = super().as_create_delta(schema, context) <TAB> new_params = self.get_params(schema).objects(schema) <TAB> for p in new_params: <MASK> delta.add_prerequisite( <TAB>  <TAB>  <TAB>  <TAB> p.as_create_delta(schema=schema, context=context), <TAB>  <TAB>  <TAB> ) <TAB> return delta","if not param_is_inherited ( schema , self , p ) :",149
"def set_indentation_params(self, ispythonsource, guess=True): <TAB> if guess and ispythonsource: <TAB>  <TAB> i = self.guess_indent() <MASK> self.indentwidth = i <TAB>  <TAB> if self.indentwidth != self.tabwidth: <TAB>  <TAB>  <TAB> self.usetabs = False <TAB> self.set_tabwidth(self.tabwidth)",if 2 <= i <= 8 :,97
"def _test(): <TAB> """"""Simple test program to disassemble a file."""""" <TAB> argc = len(sys.argv) <TAB> if argc != 2: <MASK> fn = __file__ <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sys.stderr.write(""usage: %s [-|CPython compiled file]\n"" % __file__) <TAB>  <TAB>  <TAB> sys.exit(2) <TAB> else: <TAB>  <TAB> fn = sys.argv[1] <TAB> disassemble_file(fn)",if argc == 1 :,114
"def set_lineno(self, lineno, override=False): <TAB> """"""Set the line numbers of the node and children."""""" <TAB> todo = deque([self]) <TAB> while todo: <TAB>  <TAB> node = todo.popleft() <MASK> if node.lineno is None or override: <TAB>  <TAB>  <TAB>  <TAB> node.lineno = lineno <TAB>  <TAB> todo.extend(node.iter_child_nodes()) <TAB> return self","if ""lineno"" in node . attributes :",103
"def _connect(s, address): <TAB> try: <TAB>  <TAB> s.connect(address) <TAB> except socket.error: <TAB>  <TAB> (ty, v) = sys.exc_info()[:2] <MASK> v_err = v.errno <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> v_err = v[0] <TAB>  <TAB> if v_err not in [errno.EINPROGRESS, errno.EWOULDBLOCK, errno.EALREADY]: <TAB>  <TAB>  <TAB> raise v","if hasattr ( v , ""errno"" ) :",120
"def SurroundedByParens(token): <TAB> """"""Check if it's an expression surrounded by parentheses."""""" <TAB> while token: <MASK> return False <TAB>  <TAB> if token.value == "")"": <TAB>  <TAB>  <TAB> return not token.next_token <TAB>  <TAB> if token.OpensScope(): <TAB>  <TAB>  <TAB> token = token.matching_bracket.next_token <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> token = token.next_token <TAB> return False","if token . value == "","" :",109
"def read_vocab_list(path, max_vocab_size=20000): <TAB> vocab = {""<eos>"": 0, ""<unk>"": 1} <TAB> with io.open(path, encoding=""utf-8"", errors=""ignore"") as f: <TAB>  <TAB> for l in f: <TAB>  <TAB>  <TAB> w = l.strip() <TAB>  <TAB>  <TAB> if w not in vocab and w: <TAB>  <TAB>  <TAB>  <TAB> vocab[w] = len(vocab) <MASK> break <TAB> return vocab",if len ( vocab ) >= max_vocab_size :,125
"def _messageHandled(self, resultList): <TAB> failures = 0 <TAB> for (success, result) in resultList: <TAB>  <TAB> if not success: <TAB>  <TAB>  <TAB> failures += 1 <TAB>  <TAB>  <TAB> log.err(result) <TAB> if failures: <TAB>  <TAB> msg = ""Could not send e-mail"" <TAB>  <TAB> resultLen = len(resultList) <MASK> msg += "" ({} failures out of {} recipients)"".format(failures, resultLen) <TAB>  <TAB> self.sendCode(550, networkString(msg)) <TAB> else: <TAB>  <TAB> self.sendCode(250, b""Delivery in progress"")",if resultLen > 1 :,147
"def test_images_p_is_stochastic_parameter(self): <TAB> aug = self.create_aug(p=iap.Choice([0, 1], p=[0.7, 0.3])) <TAB> seen = [0, 0] <TAB> for _ in sm.xrange(1000): <TAB>  <TAB> observed = aug.augment_image(self.image) <TAB>  <TAB> if np.array_equal(observed, self.image): <TAB>  <TAB>  <TAB> seen[0] += 1 <MASK> seen[1] += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert False <TAB> assert np.allclose(seen, [700, 300], rtol=0, atol=75)","elif np . array_equal ( observed , self . image_flipped ) :",168
"def kill(self): <TAB> # check and execute the 'kill' method if present <TAB> if self.has_kill: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> kill_method = getattr(self.module_class, ""kill"") <MASK> kill_method() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> # legacy call parameters <TAB>  <TAB>  <TAB>  <TAB> kill_method( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.i3status_thread.json_list, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.config[""py3_config""][""general""], <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> # this would be stupid to die on exit <TAB>  <TAB>  <TAB> pass",if self . has_kill == self . PARAMS_NEW :,169
"def remove_topic(self, topic): <TAB> if topic not in self.messages: <TAB>  <TAB> return <TAB> del self.messages[topic] <TAB> for sub in self.subscribers.get(topic, set()): <MASK> sub._pyroRelease() <TAB>  <TAB> if hasattr(sub, ""_pyroUri""): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> proxy = self.proxy_cache[sub._pyroUri] <TAB>  <TAB>  <TAB>  <TAB> proxy._pyroRelease() <TAB>  <TAB>  <TAB>  <TAB> del self.proxy_cache[sub._pyroUri] <TAB>  <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB> del self.subscribers[topic]","if hasattr ( sub , ""_pyroRelease"" ) :",160
"def run_async(self, source, target, reverse): <TAB> to_load = target or self.get_next(source, reverse) <TAB> if not to_load: <TAB>  <TAB> return <TAB> view_signature = self.view_signatures[to_load] <TAB> window = self.view.window() <TAB> if window: <TAB>  <TAB> window.run_command(self.commands[to_load]) <MASK> sublime.set_timeout_async(self.view.close)",if not self . view . settings ( ) . get ( view_signature ) :,129
"def eval_operand(assembly, start, stop, prefix=""""): <TAB> imm = assembly[start + 1 : stop] <TAB> try: <TAB>  <TAB> eval_imm = eval(imm) <MASK> eval_imm = 0xFFFFFFFF - eval_imm <TAB>  <TAB>  <TAB> eval_imm += 1 <TAB>  <TAB>  <TAB> eval_imm = -eval_imm <TAB>  <TAB> return assembly.replace(prefix + imm, prefix + hex(eval_imm)) <TAB> except: <TAB>  <TAB> return assembly",if eval_imm > 0x80000000 :,122
"def admin(): <TAB> if Configuration.loginRequired(): <MASK> return render_template(""login.html"") <TAB> else: <TAB>  <TAB> person = User.get(""_dummy_"") <TAB>  <TAB> login_user(person) <TAB> output = None <TAB> if os.path.isfile(Configuration.getUpdateLogFile()): <TAB>  <TAB> with open(Configuration.getUpdateLogFile()) as updateFile: <TAB>  <TAB>  <TAB> separator = ""==========================\n"" <TAB>  <TAB>  <TAB> output = updateFile.read().split(separator)[-2:] <TAB>  <TAB>  <TAB> output = separator + separator.join(output) <TAB> return render_template(""admin.html"", status=""default"", **adminInfo(output))",if not current_user . is_authenticated ( ) :,164
"def data(self): <TAB> result = """" <TAB> for hunk in self._hunks: <MASK> hunk, f = hunk <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> f = lambda x: x <TAB>  <TAB> result += f(hunk.data()) <TAB> return result","if isinstance ( hunk , tuple ) and len ( hunk ) == 2 :",85
"def not_less_witness(self, other): <TAB> n = max(self.longest_run_of_spaces(), other.longest_run_of_spaces()) + 1 <TAB> a = [] <TAB> for ts in range(1, n + 1): <MASK> a.append((ts, self.indent_level(ts), other.indent_level(ts))) <TAB> return a",if self . indent_level ( ts ) >= other . indent_level ( ts ) :,110
"def _validate(self) -> None: <TAB> indent = self.indent <TAB> if indent is not None: <MASK> raise CSTValidationError( <TAB>  <TAB>  <TAB>  <TAB> ""An indented block must have a non-zero width indent."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if _INDENT_WHITESPACE_RE.fullmatch(indent) is None: <TAB>  <TAB>  <TAB> raise CSTValidationError( <TAB>  <TAB>  <TAB>  <TAB> ""An indent must be composed of only whitespace characters."" <TAB>  <TAB>  <TAB> )",if len ( indent ) == 0 :,116
"def sanitize_numeric_fields(info): <TAB> for numeric_field in self._NUMERIC_FIELDS: <TAB>  <TAB> field = info.get(numeric_field) <MASK> continue <TAB>  <TAB> report_force_conversion(numeric_field, ""numeric"", ""int"") <TAB>  <TAB> info[numeric_field] = int_or_none(field)","if field is None or isinstance ( field , compat_numeric_types ) :",96
"def count(self): <TAB> if self._should_cache(""count""): <TAB>  <TAB> # Optmization borrowed from overriden method: <TAB>  <TAB> # if queryset cache is already filled just return its len <MASK> return len(self._result_cache) <TAB>  <TAB> return cached_as(self)(lambda: self._no_monkey.count(self))() <TAB> else: <TAB>  <TAB> return self._no_monkey.count(self)",if self . _result_cache is not None :,112
