cleaned_method,target_block,tokens_in_method
"def _resolve_lib_imported_symbols(self, lib, imported_libs, generic_refs): <TAB> """"""Resolve the imported symbols in a library."""""" <TAB> for symbol in lib.elf.imported_symbols: <TAB>  <TAB> imported_lib = self._find_exported_symbol(symbol, imported_libs) <TAB>  <TAB> if not imported_lib: <TAB>  <TAB>  <TAB> lib.unresolved_symbols.add(symbol) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lib.linked_symbols[symbol] = imported_lib <MASK> ref_lib = generic_refs.refs.get(imported_lib.path) <TAB>  <TAB>  <TAB>  <TAB> if not ref_lib or not symbol in ref_lib.exported_symbols: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> lib.imported_ext_symbols[imported_lib].add(symbol)",if generic_refs :,189
"def make_docs_directory(output_dir, name): <TAB> if not isdir(pjoin(output_dir, name)): <TAB>  <TAB> subprocess.run([""mkdir"", pjoin(output_dir, name)], stdout=subprocess.PIPE) <TAB> for i in range(10): <MASK> subprocess.run( <TAB>  <TAB>  <TAB>  <TAB> [""mkdir"", pjoin(output_dir, name, str(i))], stdout=subprocess.PIPE <TAB>  <TAB>  <TAB> )","if not isdir ( pjoin ( output_dir , name , str ( i ) ) ) :",121
"def assert_results(self, results, activities, msg=""""): <TAB> activity_ids = [] <TAB> extra_context = [] <TAB> for result in results: <TAB>  <TAB> if hasattr(result, ""serialization_id""): <TAB>  <TAB>  <TAB> activity_ids.append(result.serialization_id) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> activity_ids.append(result) <MASK> extra_context.append(result.extra_context) <TAB> compare_lists(activity_ids, [a.serialization_id for a in activities], msg) <TAB> if extra_context: <TAB>  <TAB> self.assertEquals([a.extra_context for a in activities], extra_context)","if hasattr ( result , ""extra_context"" ) :",164
"def for_file(cls, filename: str, modname: str) -> ""ModuleAnalyzer"": <TAB> if (""file"", filename) in cls.cache: <TAB>  <TAB> return cls.cache[""file"", filename] <TAB> try: <TAB>  <TAB> with tokenize.open(filename) as f: <TAB>  <TAB>  <TAB> obj = cls(f, modname, filename, decoded=True) <TAB>  <TAB>  <TAB> cls.cache[""file"", filename] = obj <TAB> except Exception as err: <MASK> obj = cls.cache[""file"", filename] = cls.for_egg(filename, modname) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise PycodeError(""error opening %r"" % filename, err) from err <TAB> return obj","if "".egg"" + path . sep in filename :",170
"def merge_dicts(source: Dict, destination: Dict) -> Dict: <TAB> for key, value in source.items(): <MASK> # get node or create one <TAB>  <TAB>  <TAB> node = destination.setdefault(key, {}) <TAB>  <TAB>  <TAB> merge_dicts(value, node) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> destination[key] = value <TAB> return destination","if isinstance ( value , dict ) :",92
"def _escape_attrib_c14n(text): <TAB> # escape attribute value <TAB> try: <TAB>  <TAB> if ""&"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""&"", ""&amp;"") <TAB>  <TAB> if ""<"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""<"", ""&lt;"") <TAB>  <TAB> if '""' in text: <TAB>  <TAB>  <TAB> text = text.replace('""', ""&quot;"") <MASK> text = text.replace(""\t"", ""&#x9;"") <TAB>  <TAB> if ""\n"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""\n"", ""&#xA;"") <TAB>  <TAB> if ""\r"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""\r"", ""&#xD;"") <TAB>  <TAB> return text <TAB> except (TypeError, AttributeError): <TAB>  <TAB> _raise_serialization_error(text)","if ""\t"" in text :",188
"def get_oldest(class_name): <TAB> """"""Get the oldest object for a specific class name"""""" <TAB> for cls, wdict in six.iteritems(live_refs): <MASK> if not wdict: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> return min(six.iteritems(wdict), key=itemgetter(1))[0]",if cls . __name__ == class_name :,90
"def recursive_rm(*patterns): <TAB> """"""Recursively remove a file or matching a list of patterns."""""" <TAB> for root, subdirs, subfiles in os.walk(u"".""): <TAB>  <TAB> root = os.path.normpath(root) <TAB>  <TAB> if root.startswith("".git/""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for file in subfiles: <TAB>  <TAB>  <TAB> for pattern in patterns: <MASK> safe_remove(os.path.join(root, file)) <TAB>  <TAB> for dir in subdirs: <TAB>  <TAB>  <TAB> for pattern in patterns: <TAB>  <TAB>  <TAB>  <TAB> if fnmatch.fnmatch(dir, pattern): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> safe_rmtree(os.path.join(root, dir))","if fnmatch . fnmatch ( file , pattern ) :",170
"def _methods(ctx, cls, inst): <TAB> while cls.Attributes._wrapper and len(cls._type_info) > 0: <TAB>  <TAB> (cls,) = cls._type_info.values() <TAB> if cls.Attributes.methods is not None: <TAB>  <TAB> for k, v in cls.Attributes.methods.items(): <TAB>  <TAB>  <TAB> is_shown = True <MASK> is_shown = v.when(inst, ctx) <TAB>  <TAB>  <TAB> if is_shown: <TAB>  <TAB>  <TAB>  <TAB> yield k, v",if v . when is not None :,130
"def save(self): <TAB> for file_field in self.files: <TAB>  <TAB> file = self.cleaned_data[file_field] <TAB>  <TAB> self.cleaned_data[file_field] = default_storage.save(file.name, file) <TAB> for name in settings.CONFIG: <TAB>  <TAB> current = getattr(config, name) <TAB>  <TAB> new = self.cleaned_data[name] <MASK> new = normalize_newlines(new) <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB> conf.settings.USE_TZ <TAB>  <TAB>  <TAB> and isinstance(current, datetime) <TAB>  <TAB>  <TAB> and not timezone.is_aware(current) <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> current = timezone.make_aware(current) <TAB>  <TAB> if current != new: <TAB>  <TAB>  <TAB> setattr(config, name, new)","if isinstance ( new , str ) :",192
"def order_authors(self, entry): <TAB> sort_authors = entry.author_sort.split(""&"") <TAB> authors_ordered = list() <TAB> error = False <TAB> ids = [a.id for a in entry.authors] <TAB> for auth in sort_authors: <TAB>  <TAB> results = ( <TAB>  <TAB>  <TAB> self.session.query(Authors) <TAB>  <TAB>  <TAB> .filter(Authors.sort == auth.lstrip().strip()) <TAB>  <TAB>  <TAB> .all() <TAB>  <TAB> ) <TAB>  <TAB> # ToDo: How to handle not found authorname <TAB>  <TAB> if not len(results): <TAB>  <TAB>  <TAB> error = True <TAB>  <TAB>  <TAB> break <TAB>  <TAB> for r in results: <MASK> authors_ordered.append(r) <TAB> if not error: <TAB>  <TAB> entry.authors = authors_ordered <TAB> return entry",if r . id in ids :,195
"def describe_images(self, Filters=None, Owners=None): <TAB> images = [] <TAB> for image in self.mock_ec2_images: <TAB>  <TAB> if not (Owners is None or image.get(""ImageOwnerAlias"") in Owners): <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> images.append(deepcopy(image)) <TAB> return dict(Images=images)","if Filters and not _matches_image_filters ( image , Filters ) :",107
"def prefetch_related(self, *args): <TAB> try: <TAB>  <TAB> for arg in args: <TAB>  <TAB>  <TAB> if isinstance(arg, str): <TAB>  <TAB>  <TAB>  <TAB> arg = FastPrefetch.make_from_field(model=self.model, field_name=arg) <TAB>  <TAB>  <TAB> elif isinstance(arg, Prefetch): <TAB>  <TAB>  <TAB>  <TAB> arg = FastPrefetch.make_from_prefetch(arg, self.model) <MASK> raise Exception(""Must be FastPrefetch object"") <TAB>  <TAB>  <TAB> if arg.field in self.prefetches: <TAB>  <TAB>  <TAB>  <TAB> raise Exception(""Prefetch for field '%s' already exists."") <TAB>  <TAB>  <TAB> self.prefetches[arg.field] = arg <TAB> except Exception as e:  # noqa <TAB>  <TAB> traceback.print_exc() <TAB> return self","if not isinstance ( arg , FastPrefetch ) :",196
"def niap_scan(rule, extensions, paths, apath, ignore_paths=None): <TAB> """"""NIAP scan."""""" <TAB> try: <TAB>  <TAB> if not apath: <TAB>  <TAB>  <TAB> apath = """" <TAB>  <TAB> options = { <TAB>  <TAB>  <TAB> ""choice_rules"": rule, <TAB>  <TAB>  <TAB> ""alternative_path"": apath, <TAB>  <TAB>  <TAB> ""choice_extensions"": extensions, <TAB>  <TAB>  <TAB> ""ignore_paths"": ignore_paths, <TAB>  <TAB>  <TAB> ""show_progress"": False, <TAB>  <TAB> } <TAB>  <TAB> scanner = Scanner(options, paths) <TAB>  <TAB> res = scanner.scan() <MASK> return res[""choice_matcher""] <TAB> except Exception: <TAB>  <TAB> logger.exception(""NIAP scan"") <TAB> return {}",if res :,176
"def secret_generator(self, string, *args, **kwargs): <TAB> # There may be multiple strings on the same line <TAB> results = self.regex.findall(string) <TAB> for result in results: <TAB>  <TAB> # To accommodate changing self.regex, due to different filetypes <MASK> result = result[1] <TAB>  <TAB> entropy_value = self.calculate_shannon_entropy(result) <TAB>  <TAB> if entropy_value > self.entropy_limit: <TAB>  <TAB>  <TAB> yield result","if isinstance ( result , tuple ) :",121
"def encode(obj, encoding=""utf-8"", errors=""strict""): <TAB> encoder = __encoder(encoding) <TAB> if encoder: <TAB>  <TAB> result = encoder(obj, errors) <MASK> raise TypeError(""encoder must return a tuple (object, integer)"") <TAB>  <TAB> return result[0]","if not ( isinstance ( result , tuple ) and len ( result ) == 2 ) :",86
"def greetings(request): <TAB> if request.method == ""POST"": <TAB>  <TAB> form = HelloForm(request.POST) <MASK> first_name = form.cleaned_data[""fname""] <TAB>  <TAB>  <TAB> last_name = form.cleaned_data[""lname""] <TAB>  <TAB>  <TAB> return HttpResponse(""Hello, {} {}"".format(first_name, last_name)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return render(request, ""home.html"") <TAB> return render(request, ""home.html"")",if form . is_valid ( ) :,125
def logic(): <TAB> while 1: <TAB>  <TAB> yield a <TAB>  <TAB> var = 0 <TAB>  <TAB> i = len(a) - 1 <TAB>  <TAB> while i >= 0: <MASK> var += 1 <TAB>  <TAB>  <TAB> i -= 1 <TAB>  <TAB> out.next = var,if a [ i ] == 1 :,74
"def reconfigure(self, user_config) -> None: <TAB> if user_config: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""argument func_or_class must be a class to use user_config"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> elif not hasattr(self.callable, BACKEND_RECONFIGURE_METHOD): <TAB>  <TAB>  <TAB> raise RayServeException( <TAB>  <TAB>  <TAB>  <TAB> ""user_config specified but backend "" <TAB>  <TAB>  <TAB>  <TAB> + self.backend_tag <TAB>  <TAB>  <TAB>  <TAB> + "" missing "" <TAB>  <TAB>  <TAB>  <TAB> + BACKEND_RECONFIGURE_METHOD <TAB>  <TAB>  <TAB>  <TAB> + "" method"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> reconfigure_method = getattr(self.callable, BACKEND_RECONFIGURE_METHOD) <TAB>  <TAB> reconfigure_method(user_config)",if self . is_function :,190
"def convert_charged_to_paritally_charged_and_partially_refunded(apps, schema_editor): <TAB> PaymentModel = apps.get_model(""payment"", ""Payment"") <TAB> for payment in PaymentModel.objects.all(): <MASK> if is_fully_charged(payment): <TAB>  <TAB>  <TAB>  <TAB> payment.charge_status = ChargeStatus.FULLY_CHARGED <TAB>  <TAB>  <TAB> elif ( <TAB>  <TAB>  <TAB>  <TAB> payment.transactions.filter( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> kind=TransactionKind.REFUND, is_success=True <TAB>  <TAB>  <TAB>  <TAB> ).first() <TAB>  <TAB>  <TAB>  <TAB> is not None <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> payment.charge_status = ChargeStatus.PARTIALLY_REFUNDED <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> payment.charge_status = ChargeStatus.PARTIALLY_CHARGED <TAB>  <TAB>  <TAB> payment.save()",if payment . charge_status == CHARGED :,196
"def _connect_loop(self, retry): <TAB> # Iterate through the hosts a full cycle before starting over <TAB> status = None <TAB> for host, port in self.client.hosts: <MASK> status = STOP_CONNECTING <TAB>  <TAB>  <TAB> break <TAB>  <TAB> status = self._connect_attempt(host, port, retry) <TAB>  <TAB> if status is STOP_CONNECTING: <TAB>  <TAB>  <TAB> break <TAB> if status is STOP_CONNECTING: <TAB>  <TAB> return STOP_CONNECTING <TAB> else: <TAB>  <TAB> raise ForceRetryError(""Reconnecting"")",if self . client . _stopped . is_set ( ) :,133
"def Query(host, port, req): <TAB> sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) <TAB> resp = b"""" <TAB> try: <TAB>  <TAB> sock.connect((host, int(port))) <TAB>  <TAB> sock.sendall(req) <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> data = sock.recv(8096) <MASK> return resp <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> resp += data <TAB> except socket.error: <TAB>  <TAB> return resp <TAB> finally: <TAB>  <TAB> sock.close()",if not data :,133
"def execute(self, arbiter, props): <TAB> if ""name"" in props: <TAB>  <TAB> watcher = self._get_watcher(arbiter, props[""name""]) <MASK> resp = TransformableFuture() <TAB>  <TAB>  <TAB> resp.set_upstream_future(watcher.start()) <TAB>  <TAB>  <TAB> resp.set_transform_function(lambda x: {""info"": x}) <TAB>  <TAB>  <TAB> return resp <TAB>  <TAB> return watcher.start() <TAB> else: <TAB>  <TAB> return arbiter.start_watchers()","if props . get ( ""waiting"" ) :",128
"def _select_algs(alg_type, algs, possible_algs, none_value=None): <TAB> """"""Select a set of allowed algorithms"""""" <TAB> if algs == (): <TAB>  <TAB> return possible_algs <TAB> elif algs: <TAB>  <TAB> result = [] <TAB>  <TAB> for alg_str in algs: <TAB>  <TAB>  <TAB> alg = alg_str.encode(""ascii"") <MASK> raise ValueError(""%s is not a valid %s algorithm"" % (alg_str, alg_type)) <TAB>  <TAB>  <TAB> result.append(alg) <TAB>  <TAB> return result <TAB> elif none_value: <TAB>  <TAB> return [none_value] <TAB> else: <TAB>  <TAB> raise ValueError(""No %s algorithms selected"" % alg_type)",if alg not in possible_algs :,180
"def fetch(self, mutagen_file): <TAB> for frame in mutagen_file.tags.getall(self.key): <MASK> if self.key == ""USLT"": <TAB>  <TAB>  <TAB>  <TAB> return frame.text <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> return frame.text[0] <TAB>  <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB>  <TAB> return None",if frame . desc . lower ( ) == self . description . lower ( ) :,98
"def setup_widgets(self): <TAB> Editor.setup_widgets(self) <TAB> # Get app version <TAB> app_ver = ""(unknown version)"" <TAB> try: <TAB>  <TAB> import pkg_resources, scc <MASK> app_ver = ""v"" + pkg_resources.require(""sccontroller"")[0].version <TAB> except: <TAB>  <TAB> # pkg_resources is not available or __version__ file missing <TAB>  <TAB> # There is no reason to crash on this. <TAB>  <TAB> pass <TAB> # Display version in UI <TAB> self.builder.get_object(""lblVersion"").set_label(app_ver)","if scc . __file__ . startswith ( pkg_resources . require ( ""sccontroller"" ) [ 0 ] . location ) :",160
"def clean_email(self): <TAB> email = self.cleaned_data.get(""email"") <TAB> if email: <TAB>  <TAB> if self.user.email != email: <TAB>  <TAB>  <TAB> unique = User.objects.filter(email__iexact=email).count() <MASK> raise forms.ValidationError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> u""An user with this email address already exists."" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return email",if unique > 0 :,105
"def forwards(self, orm): <TAB> from sentry.constants import RESERVED_TEAM_SLUGS <TAB> from sentry.models import slugify_instance <TAB> try: <TAB>  <TAB> superuser = orm[""sentry.User""].objects.filter(is_superuser=True)[0] <TAB> except IndexError: <TAB>  <TAB> return <TAB> for project in orm[""sentry.Project""].objects.filter(team__isnull=True): <MASK> project.owner = superuser <TAB>  <TAB> project.team = orm[""sentry.Team""]( <TAB>  <TAB>  <TAB> name=project.name, <TAB>  <TAB>  <TAB> owner=project.owner, <TAB>  <TAB> ) <TAB>  <TAB> slugify_instance(project.team, project.team.name, reserved=RESERVED_TEAM_SLUGS) <TAB>  <TAB> project.team.save() <TAB>  <TAB> project.save()",if not project . owner :,196
"def list_cb(cards): <TAB> for c in cards.values(): <MASK> self.devices[device[""Address""]] = c <TAB>  <TAB>  <TAB> self.generate_menu(device) <TAB>  <TAB>  <TAB> return","if c [ ""proplist"" ] [ ""device.string"" ] == device [ ""Address"" ] :",66
"def _extract_tags_from_span(attr): <TAB> if attr is None: <TAB>  <TAB> return {} <TAB> tags = {} <TAB> for attribute_key, attribute_value in attr.items(): <MASK> value = str(attribute_value) <TAB>  <TAB> elif isinstance(attribute_value, str): <TAB>  <TAB>  <TAB> res, _ = check_str_length(str_to_check=attribute_value) <TAB>  <TAB>  <TAB> value = res <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logging.warning(""Could not serialize tag %s"", attribute_key) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> tags[attribute_key] = value <TAB> return tags","if isinstance ( attribute_value , ( int , bool , float ) ) :",161
"def visit(z, dirname, names): <TAB> for name in names: <TAB>  <TAB> path = os.path.normpath(os.path.join(dirname, name)) <MASK> p = path[len(base_dir) + 1 :] <TAB>  <TAB>  <TAB> if not dry_run: <TAB>  <TAB>  <TAB>  <TAB> z.write(path, p) <TAB>  <TAB>  <TAB> log.debug(""adding '%s'"" % p)",if os . path . isfile ( path ) :,105
"def validate(self): <TAB> if ""lb_method"" in self.resource: <TAB>  <TAB> lb_method = self.resource[""lb_method""] <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""The lb_method attribute must be "" <TAB>  <TAB>  <TAB>  <TAB> ""either ROUND_ROBIN, LEAST_CONNECTIONS "" <TAB>  <TAB>  <TAB>  <TAB> ""or SOURCE_IP"" <TAB>  <TAB>  <TAB> ) <TAB> if ""protocol"" in self.resource: <TAB>  <TAB> protocol = self.resource[""protocol""] <TAB>  <TAB> if protocol not in [""TCP"", ""HTTP"", ""HTTPS""]: <TAB>  <TAB>  <TAB> raise ValueError(""The type attribute must be "" ""either TCP, HTTP or HTTPS"") <TAB> return True","if lb_method not in [ ""ROUND_ROBIN"" , ""LEAST_CONNECTIONS"" , ""SOURCE_IP"" ] :",181
"def compute_adjlist(self, sp_adj, max_degree=32): <TAB> """"""Transfer sparse adjacent matrix to adj-list format"""""" <TAB> num_data = sp_adj.shape[0] <TAB> adj = num_data + np.zeros((num_data + 1, max_degree), dtype=np.int32) <TAB> for v in range(num_data): <TAB>  <TAB> neighbors = np.nonzero(sp_adj[v, :])[1] <TAB>  <TAB> len_neighbors = len(neighbors) <MASK> neighbors = np.random.choice(neighbors, max_degree, replace=False) <TAB>  <TAB>  <TAB> adj[v] = neighbors <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> adj[v, :len_neighbors] = neighbors <TAB> return adj",if len_neighbors > max_degree :,184
"def _fix_paused_jobs_sorting(self, jobs): <TAB> for i, job in enumerate(jobs): <TAB>  <TAB> if job.next_run_time is not None: <MASK> paused_jobs = jobs[:i] <TAB>  <TAB>  <TAB>  <TAB> del jobs[:i] <TAB>  <TAB>  <TAB>  <TAB> jobs.extend(paused_jobs) <TAB>  <TAB>  <TAB> break",if i > 0 :,91
"def random_init(self): <TAB> self.conv1.weight.data.normal_(0, math.sqrt(2.0 / (7 * 7 * 64))) <TAB> for m in self.modules(): <TAB>  <TAB> if isinstance(m, nn.Conv2d): <TAB>  <TAB>  <TAB> n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels <TAB>  <TAB>  <TAB> m.weight.data.normal_(0, math.sqrt(2.0 / n)) <TAB>  <TAB> elif isinstance(m, nn.BatchNorm2d): <TAB>  <TAB>  <TAB> m.weight.data.fill_(1) <TAB>  <TAB>  <TAB> m.bias.data.zero_() <MASK> m.weight.data.fill_(1) <TAB>  <TAB>  <TAB> m.bias.data.zero_()","elif isinstance ( m , nn . InstanceNorm2d ) :",195
"def parseUrlEncoded(self, cad): <TAB> dicc = [] <TAB> if cad == """": <TAB>  <TAB> dicc.append(Variable("""", None)) <TAB> for i in cad.split(""&""): <MASK> var_list = i.split(""="", 1) <TAB>  <TAB>  <TAB> if len(var_list) == 1: <TAB>  <TAB>  <TAB>  <TAB> dicc.append(Variable(var_list[0], None)) <TAB>  <TAB>  <TAB> elif len(var_list) == 2: <TAB>  <TAB>  <TAB>  <TAB> dicc.append(Variable(var_list[0], var_list[1])) <TAB> self.variables = dicc",if i :,147
"def get_environment_with_overrides(overrides): <TAB> env = os.environ.copy() <TAB> for key in overrides: <MASK> del env[key] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert isinstance(overrides[key], str) <TAB>  <TAB>  <TAB> if key.upper() == ""PATH"": <TAB>  <TAB>  <TAB>  <TAB> update_system_path(env, overrides[key]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> env[key] = overrides[key] <TAB> return env",if overrides [ key ] is None and key in env :,125
"def create_tuple_column(spec, column_by_spec_getter): <TAB> brackets = 0 <TAB> column_begin = 0 <TAB> inner_spec = get_inner_spec(spec) <TAB> nested_columns = [] <TAB> for i, x in enumerate(inner_spec + "",""): <TAB>  <TAB> if x == "","": <MASK> nested_columns.append(inner_spec[column_begin:i]) <TAB>  <TAB>  <TAB>  <TAB> column_begin = i + 1 <TAB>  <TAB> elif x == ""("": <TAB>  <TAB>  <TAB> brackets += 1 <TAB>  <TAB> elif x == "")"": <TAB>  <TAB>  <TAB> brackets -= 1 <TAB>  <TAB> elif x == "" "": <TAB>  <TAB>  <TAB> if brackets == 0: <TAB>  <TAB>  <TAB>  <TAB> column_begin = i + 1 <TAB> return TupleColumn([column_by_spec_getter(x) for x in nested_columns])",if brackets == 0 :,195
"def _send_launch_message(self, app_id, force_launch=False, callback_function=False): <TAB> if force_launch or self.app_id != app_id: <TAB>  <TAB> self.logger.info(""Receiver:Launching app %s"", app_id) <TAB>  <TAB> self.app_to_launch = app_id <TAB>  <TAB> self.app_launch_event.clear() <TAB>  <TAB> self.app_launch_event_function = callback_function <TAB>  <TAB> self.launch_failure = None <TAB>  <TAB> self.send_message({MESSAGE_TYPE: TYPE_LAUNCH, APP_ID: app_id}) <TAB> else: <TAB>  <TAB> self.logger.info(""Not launching app %s - already running"", app_id) <MASK> callback_function()",if callback_function :,189
"def _needs_init(self, code, name): <TAB> if code in self.init_params: <MASK> _log.warning( <TAB>  <TAB>  <TAB>  <TAB> ""Even though the %r attribute is set, it will be "" <TAB>  <TAB>  <TAB>  <TAB> ""overwritten during initialization because 'init_params' "" <TAB>  <TAB>  <TAB>  <TAB> ""contains %r"", <TAB>  <TAB>  <TAB>  <TAB> name, <TAB>  <TAB>  <TAB>  <TAB> code, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return True <TAB> if not hasattr(self, name): <TAB>  <TAB> return True <TAB> return False","if hasattr ( self , name ) :",132
"def extra_backend_context(self): <TAB> """"""Specific metadata to be included when passed to backends."""""" <TAB> context = {} <TAB> if self.in_response_to: <TAB>  <TAB> original = self.in_response_to <TAB>  <TAB> context[""in_response_to""] = original.id <MASK> context[""external_id""] = original.fields[""external_id""] <TAB> return context","if ""external_id"" in original . fields :",103
"def OnReplaceAll(self, id, code): <TAB> control = _GetControl(None) <TAB> if control is not None: <TAB>  <TAB> control.SetSel(0) <TAB>  <TAB> num = 0 <MASK> lastSearch.replaceText = self.editReplaceText.GetWindowText() <TAB>  <TAB>  <TAB> while _ReplaceIt(control) == FOUND_NORMAL: <TAB>  <TAB>  <TAB>  <TAB> num = num + 1 <TAB>  <TAB> win32ui.SetStatusText(""Replaced %d occurrences"" % num) <TAB>  <TAB> if num > 0 and not self.butKeepDialogOpen.GetCheck(): <TAB>  <TAB>  <TAB> self.DestroyWindow()",if self . DoFindNext ( ) == FOUND_NORMAL :,157
"def dict(x): <TAB> a = [""(""] <TAB> b = None <TAB> ks = sorted(x.keys()) <TAB> for i in ks: <TAB>  <TAB> v = x[i] <TAB>  <TAB> f = Encoder.encoder(v) <TAB>  <TAB> if f: <TAB>  <TAB>  <TAB> v = f(v) <TAB>  <TAB>  <TAB> if isinstance(v, (str, basestring)): <MASK> a.append("","") <TAB>  <TAB>  <TAB>  <TAB> a.append(Encoder.string(i)) <TAB>  <TAB>  <TAB>  <TAB> a.append("":"") <TAB>  <TAB>  <TAB>  <TAB> a.append(v) <TAB>  <TAB>  <TAB>  <TAB> b = True <TAB> a.append("")"") <TAB> return """".join(a)",if b :,159
"def _load_repositories(self, structure): <TAB> """"""Load other image repositories into this local repo"""""" <TAB> if ""repositories"" not in structure: <TAB>  <TAB> return False <TAB> loaded_repositories = [] <TAB> for imagerepo in structure[""repositories""]: <TAB>  <TAB> for tag in structure[""repositories""][imagerepo]: <TAB>  <TAB>  <TAB> if imagerepo and tag: <TAB>  <TAB>  <TAB>  <TAB> loaded_repo = self._load_image(structure, imagerepo, tag) <MASK> loaded_repositories.extend(loaded_repo) <TAB> return loaded_repositories",if loaded_repo :,141
"def is_valid_relation(self, parent, sub, created=False): <TAB> if sub.is_isolated(): <TAB>  <TAB> return { <TAB>  <TAB>  <TAB> ""error"": _( <TAB>  <TAB>  <TAB>  <TAB> ""Isolated instances may not be added or removed from instances groups via the API."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> } <TAB> if self.parent_model is InstanceGroup: <TAB>  <TAB> ig_obj = self.get_parent_object() <MASK> return { <TAB>  <TAB>  <TAB>  <TAB> ""error"": _( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Isolated instance group membership may not be managed via the API."" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> } <TAB> return None",if ig_obj . controller_id is not None :,163
"def durationActual(self, dA): <TAB> self._checkFrozen() <TAB> if isinstance(dA, DurationTuple): <TAB>  <TAB> self._durationActual = dA <TAB> elif isinstance(dA, Duration): <MASK> dA = copy.deepcopy(dA) <TAB>  <TAB>  <TAB> dA.consolidate() <TAB>  <TAB> self._durationActual = DurationTuple(dA.type, dA.dots, dA.quarterLength) <TAB> elif isinstance(dA, str): <TAB>  <TAB> self._durationActual = durationTupleFromTypeDots(dA, dots=0)",if len ( dA . components ) > 1 :,149
"def get_encoding(klass, name, diff=None): <TAB> cid2unicode = klass.encodings.get(name, klass.std2unicode) <TAB> if diff: <TAB>  <TAB> cid2unicode = cid2unicode.copy() <TAB>  <TAB> cid = 0 <TAB>  <TAB> for x in diff: <MASK> cid = x <TAB>  <TAB>  <TAB> elif isinstance(x, PSLiteral): <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> cid2unicode[cid] = name2unicode(x.name) <TAB>  <TAB>  <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB>  <TAB> cid += 1 <TAB> return cid2unicode","if isinstance ( x , int ) :",154
"def __getitem__(self, name): <TAB> if name in Quality.DOWNLOADED + Quality.SNATCHED + Quality.SNATCHED_PROPER: <TAB>  <TAB> status, quality = Quality.splitCompositeStatus(name) <MASK> return self.statusStrings[status] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB>  <TAB> self.statusStrings[status] <TAB>  <TAB>  <TAB>  <TAB> + "" ("" <TAB>  <TAB>  <TAB>  <TAB> + Quality.qualityStrings[quality] <TAB>  <TAB>  <TAB>  <TAB> + "")"" <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> return self.statusStrings[name]",if quality == Quality . NONE :,155
"def _set(self, function): <TAB> try: <TAB>  <TAB> self._tokens = function <TAB>  <TAB> self._next = six.next(self._tokens) <TAB> except IOError as exc: <TAB>  <TAB> error = str(exc) <MASK> self.error.set(error.split(""]"")[1].strip()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.error.set(error) <TAB>  <TAB> self._tokens = Tokeniser._off <TAB>  <TAB> self._next = [] <TAB>  <TAB> return self.error.set(""issue setting the configuration parser"") <TAB> except StopIteration: <TAB>  <TAB> self._tokens = Tokeniser._off <TAB>  <TAB> self._next = [] <TAB>  <TAB> return self.error.set(""issue setting the configuration parser, no data"") <TAB> return True","if error . count ( ""]"" ) :",179
"def is_valid(self): <TAB> # Some actions do not require comments. <TAB> action = self.helper.actions.get(self.data.get(""action"")) <TAB> if action: <MASK> self.fields[""comments""].required = False <TAB>  <TAB> if action.get(""versions"", False): <TAB>  <TAB>  <TAB> self.fields[""versions""].required = True <TAB> result = super(ReviewForm, self).is_valid() <TAB> if result: <TAB>  <TAB> self.helper.set_data(self.cleaned_data) <TAB> return result","if not action . get ( ""comments"" , True ) :",136
"def lambda_handler(event, context): <TAB> try: <MASK> print(""Connect to Redshift: %s"" % host) <TAB>  <TAB> conn = pg8000.connect( <TAB>  <TAB>  <TAB> database=database, <TAB>  <TAB>  <TAB> user=user, <TAB>  <TAB>  <TAB> password=password, <TAB>  <TAB>  <TAB> host=host, <TAB>  <TAB>  <TAB> port=port, <TAB>  <TAB>  <TAB> ssl=ssl, <TAB>  <TAB> ) <TAB> except: <TAB>  <TAB> print(""Redshift Connection Failed: exception %s"" % sys.exc_info()[1]) <TAB>  <TAB> return ""Failed"" <TAB> if debug: <TAB>  <TAB> print(""Succesfully Connected Redshift Cluster"") <TAB> # Collect Query Monitoring Rule metrics and Publish to SNS topic <TAB> query_redshift(conn) <TAB> conn.close() <TAB> return ""Finished""",if debug :,184
"def parse(self, source, parser=None): <TAB> close_source = False <TAB> if not hasattr(source, ""read""): <TAB>  <TAB> source = open(source, ""rb"") <TAB>  <TAB> close_source = True <TAB> try: <TAB>  <TAB> if not parser: <TAB>  <TAB>  <TAB> parser = XMLParser(target=TreeBuilder()) <TAB>  <TAB> while 1: <TAB>  <TAB>  <TAB> data = source.read(65536) <TAB>  <TAB>  <TAB> if not data: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> parser.feed(data) <TAB>  <TAB> self._root = parser.close() <TAB>  <TAB> return self._root <TAB> finally: <MASK> source.close()",if close_source :,155
"def set_metadata_keywords(self, toc_id, kws): <TAB> with self._lock: <TAB>  <TAB> old_fpath = self._lookup(toc_id) <TAB>  <TAB> new_fpath = old_fpath.rsplit(self.colon, 1)[0] <TAB>  <TAB> flags = """".join(sorted([k[0] for k in kws])) <TAB>  <TAB> if flags: <TAB>  <TAB>  <TAB> new_fpath += ""%s2,%s"" % (self.colon, flags) <MASK> os.rename( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> os.path.join(self._path, old_fpath), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> os.path.join(self._path, new_fpath), <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> self._toc[toc_id] = new_fpath",if new_fpath != old_fpath :,191
"def check_health(self): <TAB> ""Check the health of the connection with a PING/PONG"" <TAB> if self.health_check_interval and time() > self.next_health_check: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.send_command(""PING"", check_health=False) <MASK> raise ConnectionError(""Bad response from PING health check"") <TAB>  <TAB> except (ConnectionError, TimeoutError): <TAB>  <TAB>  <TAB> self.disconnect() <TAB>  <TAB>  <TAB> self.send_command(""PING"", check_health=False) <TAB>  <TAB>  <TAB> if nativestr(self.read_response()) != ""PONG"": <TAB>  <TAB>  <TAB>  <TAB> raise ConnectionError(""Bad response from PING health check"")","if nativestr ( self . read_response ( ) ) != ""PONG"" :",177
"def ValidateStopLongitude(self, problems): <TAB> if self.stop_lon is not None: <TAB>  <TAB> value = self.stop_lon <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if not isinstance(value, (float, int)): <TAB>  <TAB>  <TAB>  <TAB> self.stop_lon = util.FloatStringToFloat(value, problems) <TAB>  <TAB> except (ValueError, TypeError): <TAB>  <TAB>  <TAB> problems.InvalidValue(""stop_lon"", value) <TAB>  <TAB>  <TAB> del self.stop_lon <TAB>  <TAB> else: <MASK> problems.InvalidValue(""stop_lon"", value)",if self . stop_lon > 180 or self . stop_lon < - 180 :,152
"def get_closest(cls, *locale_codes: str) -> ""Locale"": <TAB> """"""Returns the closest match for the given locale code."""""" <TAB> for code in locale_codes: <TAB>  <TAB> if not code: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> code = code.replace(""-"", ""_"") <TAB>  <TAB> parts = code.split(""_"") <TAB>  <TAB> if len(parts) > 2: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif len(parts) == 2: <TAB>  <TAB>  <TAB> code = parts[0].lower() + ""_"" + parts[1].upper() <MASK> return cls.get(code) <TAB>  <TAB> if parts[0].lower() in _supported_locales: <TAB>  <TAB>  <TAB> return cls.get(parts[0].lower()) <TAB> return cls.get(_default_locale)",if code in _supported_locales :,184
"def insistent_bucket_delete(conn, bucket_name, keys): <TAB> bucket = conn.lookup(bucket_name) <TAB> if bucket: <TAB>  <TAB> # Delete key names passed by the test code. <TAB>  <TAB> _delete_keys(bucket, keys) <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> conn.delete_bucket(bucket_name) <TAB>  <TAB> except boto.exception.S3ResponseError as e: <MASK> # Create not yet visible, but it just happened above: <TAB>  <TAB>  <TAB>  <TAB> # keep trying.  Potential consistency. <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> break",if e . status == 404 :,161
"def echo(socket, address): <TAB> print(""New connection from %s:%s"" % address) <TAB> socket.sendall(b""Welcome to the echo server! Type quit to exit.\r\n"") <TAB> # using a makefile because we want to use readline() <TAB> rfileobj = socket.makefile(mode=""rb"") <TAB> while True: <TAB>  <TAB> line = rfileobj.readline() <MASK> print(""client disconnected"") <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if line.strip().lower() == b""quit"": <TAB>  <TAB>  <TAB> print(""client quit"") <TAB>  <TAB>  <TAB> break <TAB>  <TAB> socket.sendall(line) <TAB>  <TAB> print(""echoed %r"" % line) <TAB> rfileobj.close()",if not line :,168
"def parse_messages(self, data): <TAB> buf = BytesIO(data) <TAB> msgs = [] <TAB> while buf.tell() < buf.len: <TAB>  <TAB> token = buf.read(1) <MASK> continue <TAB>  <TAB> if token == b""-"": <TAB>  <TAB>  <TAB> raise NotImplementedError(""Resend packet"") <TAB>  <TAB> if token == b""$"": <TAB>  <TAB>  <TAB> packet_data = b"""" <TAB>  <TAB>  <TAB> c = buf.read(1) <TAB>  <TAB>  <TAB> while c != b""#"": <TAB>  <TAB>  <TAB>  <TAB> packet_data += c <TAB>  <TAB>  <TAB>  <TAB> c = buf.read(1) <TAB>  <TAB>  <TAB> checksum = buf.read(2) <TAB>  <TAB>  <TAB> if checksum != self.compute_checksum(packet_data): <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""Incorrect checksum"") <TAB>  <TAB>  <TAB> msgs.append(packet_data) <TAB> return msgs","if token == b""+"" :",200
"def _cancel_job_by_id(api: CustomObjectsApi, namespace: str, job_id: str): <TAB> try: <TAB>  <TAB> api.delete_namespaced_custom_object( <TAB>  <TAB>  <TAB> **_crd_args(namespace), <TAB>  <TAB>  <TAB> name=_job_id_to_resource_name(job_id), <TAB>  <TAB> ) <TAB> except client.ApiException as e: <MASK> return None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise",if e . status == 404 :,117
def __next__(self): <TAB> try: <TAB>  <TAB> self.dt = advance_iterator(self.gen) <TAB> except StopIteration: <MASK> heapq.heappop(self.genlist) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.genlist.remove(self) <TAB>  <TAB>  <TAB> heapq.heapify(self.genlist),if self . genlist [ 0 ] is self :,94
"def addPoint(self, x, y): <TAB> if self._n > 0: <MASK> pctChange = (y - self._last) / self._last <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pctChange = 0 <TAB>  <TAB> self._sum_pct_change += pctChange <TAB>  <TAB> self._sum_pct_change_abs += abs(pctChange) <TAB>  <TAB> self._window.append((x, pctChange)) <TAB> self._n += 1 <TAB> self._last = y <TAB> if len(self._window) == self._windowSize: <TAB>  <TAB> self.removePoint(*self._window.popleft())",if self . _last != 0 :,149
"def html_rewriter(self): <TAB> embed_rules = {} <TAB> link_rules = {} <TAB> for rule in self.converter_rules: <TAB>  <TAB> if isinstance(rule, EmbedTypeRule): <TAB>  <TAB>  <TAB> embed_rules[rule.embed_type] = rule.handler.expand_db_attributes <MASK> link_rules[rule.link_type] = rule.handler.expand_db_attributes <TAB> return MultiRuleRewriter([LinkRewriter(link_rules), EmbedRewriter(embed_rules)])","elif isinstance ( rule , LinkTypeRule ) :",124
"def get_entities(f): <TAB> entities = [] <TAB> for line in f: <MASK> continue <TAB>  <TAB> parts = line.split(""\t"")[1].split() <TAB>  <TAB> entity_type = parts[0] <TAB>  <TAB> char_offsets = "" "".join(parts[1:]) <TAB>  <TAB> for start_end in char_offsets.split("";""): <TAB>  <TAB>  <TAB> start, end = start_end.split("" "") <TAB>  <TAB>  <TAB> entities += [Entity((int(start), int(end)), entity_type)] <TAB> return entities","if not line . strip ( ) or line [ 0 ] != ""T"" :",139
"def _return_dbus_error(invocation, data): <TAB> if isinstance(data, DbusError): <TAB>  <TAB> invocation.return_dbus_error(data.name, data.message) <TAB> else: <MASK> et, ev, etb = sys.exc_info() <TAB>  <TAB>  <TAB> if ev is data: <TAB>  <TAB>  <TAB>  <TAB> message = """".join(traceback.format_exception(et, ev, etb)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> message = """".join(traceback.format_exception_only(data.__class__, data)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> message = str(data) <TAB>  <TAB> invocation.return_error_literal( <TAB>  <TAB>  <TAB> Gio.dbus_error_quark(), Gio.DBusError.FAILED, message <TAB>  <TAB> )","if isinstance ( data , Exception ) :",191
"def connect_skipped_ops(context): <TAB> nn_spec = context.builder.nn_spec <TAB> for layer in nn_spec.layers: <TAB>  <TAB> for i, inp_name in enumerate(layer.input): <MASK> layer.input[i] = context.skip_map_names[inp_name] <TAB>  <TAB> for i, out_name in enumerate(layer.output): <TAB>  <TAB>  <TAB> if out_name in context.skip_map_names: <TAB>  <TAB>  <TAB>  <TAB> layer.output[i] = context.skip_map_names[out_name]",if inp_name in context . skip_map_names :,148
"def check_splitter(command): <TAB> """"""Check xld or shntool installed"""""" <TAB> try: <TAB>  <TAB> env = os.environ.copy() <TAB>  <TAB> if ""xld"" in command: <TAB>  <TAB>  <TAB> env[""PATH""] += os.pathsep + ""/Applications"" <MASK> command = os.path.join(headphones.CONFIG.CUE_SPLIT_SHNTOOL_PATH, ""shntool"") <TAB>  <TAB> devnull = open(os.devnull) <TAB>  <TAB> subprocess.Popen( <TAB>  <TAB>  <TAB> [command], stdout=devnull, stderr=devnull, env=env <TAB>  <TAB> ).communicate() <TAB> except OSError as e: <TAB>  <TAB> if e.errno == os.errno.ENOENT: <TAB>  <TAB>  <TAB> return False <TAB> return True",elif headphones . CONFIG . CUE_SPLIT_FLAC_PATH :,189
"def apply_env_options(self): <TAB> ""apply options passed through environment variables"" <TAB> env_options = filter(self.is_flower_envvar, os.environ) <TAB> for env_var_name in env_options: <TAB>  <TAB> name = env_var_name.replace(self.ENV_VAR_PREFIX, """", 1).lower() <TAB>  <TAB> value = os.environ[env_var_name] <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> option = options._options[name] <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> option = options._options[name.replace(""_"", ""-"")] <MASK> value = [option.type(i) for i in value.split("","")] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = option.type(value) <TAB>  <TAB> setattr(options, name, value)",if option . multiple :,190
"def file_reader(file_path: str): <TAB> length = int(os.stat(file_path).st_size) <TAB> offset = 0 <TAB> while offset < length: <TAB>  <TAB> bytes_to_read = min((length - offset), MAX_BLOB_SIZE - 1) <MASK> break <TAB>  <TAB> blob_bytes = await asyncio.get_event_loop().run_in_executor( <TAB>  <TAB>  <TAB> None, read_bytes, file_path, offset, bytes_to_read <TAB>  <TAB> ) <TAB>  <TAB> yield blob_bytes <TAB>  <TAB> offset += bytes_to_read",if not bytes_to_read :,145
"def is_macro_call(form, ctx): <TAB> if rt.seq_QMARK_(form) is true and isinstance(rt.first(form), symbol.Symbol): <TAB>  <TAB> name = rt.name(rt.first(form)) <TAB>  <TAB> if resolve_local(ctx, name): <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> var = resolve_var(ctx, rt.first(form)) <TAB>  <TAB> if var and var.is_defined(): <TAB>  <TAB>  <TAB> val = var.deref() <MASK> return val <TAB> return None","if isinstance ( val , code . BaseCode ) and val . is_macro ( ) :",143
"def read_password(): <TAB> while True: <TAB>  <TAB> first = getpass.getpass(""password: "") <TAB>  <TAB> if len(first) < 8: <TAB>  <TAB>  <TAB> print(""Passwords must be at least eight characters."") <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> second = getpass.getpass("" (again): "") <MASK> print(""Passwords not the same. Try again."") <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> break <TAB> return first",if first != second :,101
"def _unpack_opargs(code): <TAB> extended_arg = 0 <TAB> for i in range(0, len(code), 2): <TAB>  <TAB> op = code[i] <MASK> arg = code[i + 1] | extended_arg <TAB>  <TAB>  <TAB> extended_arg = (arg << 8) if op == EXTENDED_ARG else 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> arg = None <TAB>  <TAB> yield (i, op, arg)",if op >= HAVE_ARGUMENT :,111
"def test_client_path(datasette, prefix, expected_path): <TAB> original_base_url = datasette._settings[""base_url""] <TAB> try: <MASK> datasette._settings[""base_url""] = prefix <TAB>  <TAB> response = await datasette.client.get(""/asgi-scope"") <TAB>  <TAB> path = response.json()[""path""] <TAB>  <TAB> assert path == expected_path <TAB> finally: <TAB>  <TAB> datasette._settings[""base_url""] = original_base_url",if prefix is not None :,122
"def to_dict(self): <TAB> ret = {} <TAB> for attr in self.__slots__: <TAB>  <TAB> value = getattr(self, attr, None) <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> ret[attr] = value <TAB> ret[""type""] = int(self.type) <TAB> if self.emoji: <TAB>  <TAB> ret[""emoji""] = self.emoji.to_dict() <TAB> return ret","if isinstance ( value , dict ) and len ( value ) == 0 :",120
"def test_opdm_to_ohdm_mapping(): <TAB> db = opdm_to_ohdm_mapping(6) <TAB> for dbe in db: <TAB>  <TAB> assert isinstance(dbe, DualBasisElement) <TAB>  <TAB> assert set(dbe.primal_tensors_names) == {""ck"", ""kc""} <MASK> assert np.allclose(dbe.primal_coeffs, 0.5) <TAB>  <TAB>  <TAB> assert np.isclose(dbe.dual_scalar, 0.0) <TAB>  <TAB> elif len(dbe.primal_tensors_names) == 2: <TAB>  <TAB>  <TAB> assert np.allclose(dbe.primal_coeffs, 1.0) <TAB>  <TAB>  <TAB> assert np.isclose(dbe.dual_scalar, 1.0)",if len ( dbe . primal_tensors_names ) == 4 :,196
"def replaceDerived(startSite=self): <TAB> if not allDerived: <TAB>  <TAB> return <TAB> for derivedSite in startSite.derivation.chain(): <TAB>  <TAB> for subsite in derivedSite.recurse(streamsOnly=True, includeSelf=True): <MASK> subsite.replace(target, replacement, recurse=recurse, allDerived=False)",if subsite in target . sites :,94
"def decode(self, session_data): <TAB> encoded_data = base64.b64decode(force_bytes(session_data)) <TAB> try: <TAB>  <TAB> # could produce ValueError if there is no ':' <TAB>  <TAB> hash, pickled = encoded_data.split(b"":"", 1) <TAB>  <TAB> expected_hash = self._hash(pickled) <MASK> raise SuspiciousOperation(""Session data corrupted"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return pickle.loads(pickled) <TAB> except Exception: <TAB>  <TAB> # ValueError, SuspiciousOperation, unpickling exceptions. If any of <TAB>  <TAB> # these happen, just return an empty dictionary (an empty session). <TAB>  <TAB> return {}","if not constant_time_compare ( hash . decode ( ) , expected_hash ) :",170
"def _change_case(col: str, case_type: str) -> str: <TAB> """"""Change case of a column name."""""" <TAB> case_types = [""preserve"", ""upper"", ""lower"", ""snake""] <TAB> if case_type.lower() not in case_types: <TAB>  <TAB> raise JanitorError(f""case_type must be one of: {case_types}"") <TAB> if case_type.lower() != ""preserve"": <TAB>  <TAB> if case_type.lower() == ""upper"": <TAB>  <TAB>  <TAB> col = col.upper() <TAB>  <TAB> elif case_type.lower() == ""lower"": <TAB>  <TAB>  <TAB> col = col.lower() <MASK> col = _camel2snake(col) <TAB> return col","elif case_type . lower ( ) == ""snake"" :",182
"def eval_sexp_str(sexp_str): <TAB> sr = SexpReader(InputPort(StringIO(sexp_str))) <TAB> while True: <TAB>  <TAB> sexp = sr.get_sexp() <TAB>  <TAB> if sexp is None: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if sexp is EOF: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if sexp is COMMENT: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> py_ast = translator.translate_sexp(tuple_it(sexp)) <MASK> code = compile(py_ast, ""<string>"", ""exec"") <TAB>  <TAB>  <TAB> if code is not None: <TAB>  <TAB>  <TAB>  <TAB> exec(code, global_env)",if py_ast is not None :,163
"def refresh(self): <TAB> """"""Get default value from a boto3 call for free tier instance type."""""" <TAB> if not self.value: <TAB>  <TAB> scheduler = self.pcluster_config.get_section(""cluster"").get_param_value( <TAB>  <TAB>  <TAB> ""scheduler"" <TAB>  <TAB> ) <MASK> self.value = ( <TAB>  <TAB>  <TAB>  <TAB> ""optimal"" if scheduler == ""awsbatch"" else get_default_instance_type() <TAB>  <TAB>  <TAB> )",if scheduler :,111
"def split_row(row): <TAB> new_row_0 = [] <TAB> new_row_1 = [] <TAB> for index, el in enumerate(row): <MASK> new_row_0.append(el) <TAB>  <TAB> elif index in target_columns_1: <TAB>  <TAB>  <TAB> new_row_1.append(el) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_row_0.append(el) <TAB>  <TAB>  <TAB> new_row_1.append(el) <TAB> return [new_row_0, new_row_1]",if index in target_columns_0 :,138
"def connector(sender, instance, created, **kw): <TAB> # Only email new announcements in a group. We don't want to email everyone. <TAB> if created and instance.group: <TAB>  <TAB> from kitsune.announcements.tasks import send_group_email <TAB>  <TAB> now = datetime.now() <TAB>  <TAB> if instance.is_visible(): <TAB>  <TAB>  <TAB> send_group_email.delay(instance.pk) <MASK> send_group_email.delay(instance.pk, eta=instance.show_after)",elif now < instance . show_after :,133
"def addon_requirements(ctx): <TAB> """"""Install all addon requirements."""""" <TAB> for directory in os.listdir(settings.ADDON_PATH): <TAB>  <TAB> path = os.path.join(settings.ADDON_PATH, directory) <TAB>  <TAB> requirements_file = os.path.join(path, ""requirements.txt"") <MASK> print(""Installing requirements for {0}"".format(directory)) <TAB>  <TAB>  <TAB> ctx.run( <TAB>  <TAB>  <TAB>  <TAB> pip_install(requirements_file, constraints_file=CONSTRAINTS_PATH), <TAB>  <TAB>  <TAB>  <TAB> echo=True, <TAB>  <TAB>  <TAB> ) <TAB> print(""Finished installing addon requirements"")",if os . path . isdir ( path ) and os . path . isfile ( requirements_file ) :,169
"def _get_command_help(self, commands): <TAB> help_str = """" <TAB> for name, mod in commands.items(): <TAB>  <TAB> mod_help = self._get_help(mod) <MASK> help_str += f""{name}\n"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> help_str += f""{name} - {mod_help}\n"" <TAB> return help_str.strip()",if not mod_help :,103
"def stringify(self, token_indices): <TAB> # Used in metric reporter to convert from tokens to string <TAB> res = """" <TAB> if hasattr(self, ""vocab""): <TAB>  <TAB> res = "" "".join([self.vocab._vocab[index] for index in token_indices]) <TAB>  <TAB> if hasattr(self, ""tokenizer""): <MASK> res = self.tokenizer.decode(res) <TAB> return res","if hasattr ( self . tokenizer , ""decode"" ) :",106
"def load_info(cls, path, load_model_if_required=True) -> dict: <TAB> load_path = path + cls.model_info_name <TAB> try: <TAB>  <TAB> return load_pkl.load(path=load_path) <TAB> except: <MASK> model = cls.load(path=path, reset_paths=True) <TAB>  <TAB>  <TAB> return model.get_info() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise",if load_model_if_required :,115
"def to_dict(self): <TAB> d = super().to_dict() <TAB> d[""type""] = ""select"" <TAB> d[""data""] = [] <TAB> if self.user and self.security: <TAB>  <TAB> for a in self.user.addresses: <MASK> d[""data""].append( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> {""label"": a.desc, ""value"": self.security.encode_id(a.id)} <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return d",if not a . deleted :,118
"def to_string(self): <TAB> """"""Get the string code for this asset. Even for remote assets."""""" <TAB> if self._source_str is None: <TAB>  <TAB> if callable(self._source): <TAB>  <TAB>  <TAB> self._source_str = self._source() <MASK> t = ""Source function of asset %r did not return a str, but a %s."" <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(t % (self.name, self._source.__class__.__name__)) <TAB>  <TAB> elif self._remote: <TAB>  <TAB>  <TAB> self._source_str = self._get_from_url(self._source) <TAB>  <TAB> else:  # pragma: no cover <TAB>  <TAB>  <TAB> assert False, ""This should not happen"" <TAB> return self._source_str","if not isinstance ( self . _source_str , str ) :",185
"def get_command_modules_paths(include_prefix=False): <TAB> glob_pattern = os.path.normcase( <TAB>  <TAB> ""/src/command_modules/{}*/setup.py"".format(COMMAND_MODULE_PREFIX) <TAB> ) <TAB> for path in glob.glob(get_repo_root() + glob_pattern): <TAB>  <TAB> folder = os.path.dirname(path) <TAB>  <TAB> name = os.path.basename(folder) <MASK> name = name[len(COMMAND_MODULE_PREFIX) :] <TAB>  <TAB> yield name, folder",if not include_prefix :,133
"def remove_firewall_rule( <TAB> self, <TAB> rule=""allowedprogram"", <TAB> name=""Firewall"", <TAB> mode=""ENABLE"", <TAB> program=sys.executable, <TAB> **kwargs): <TAB> netsh_args = {""program"": program} <TAB> netsh_args.update(kwargs) <TAB> try: <MASK> if name in self._rules: <TAB>  <TAB>  <TAB>  <TAB> del self._rules[name] <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> except: <TAB>  <TAB> return None","if _run_netsh_cmd ( ""firewall delete %s"" % rule , netsh_args ) :",149
"def check_ini_installed(): <TAB> """"""Raise if no GNOME Shell ini file for Quod Libet is found"""""" <TAB> quodlibet_installed = False <TAB> for path in get_gs_provider_files(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> with open(path, ""rb"") as handle: <TAB>  <TAB>  <TAB>  <TAB> data = handle.read().decode(""utf-8"", ""replace"") <MASK> quodlibet_installed = True <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> except EnvironmentError: <TAB>  <TAB>  <TAB> pass <TAB> if not quodlibet_installed: <TAB>  <TAB> raise PluginImportException( <TAB>  <TAB>  <TAB> _(""No GNOME Shell search provider for "" ""Quod Libet installed."") <TAB>  <TAB> )",if SearchProvider . BUS_NAME in data :,182
"def delete_rules(chain_name, rules): <TAB> log.debug(f""deleting rules from {chain_name}: {rules}"") <TAB> table = iptc.Table(iptc.Table.FILTER) <TAB> with iptables_txn(table): <TAB>  <TAB> chain = iptc.Chain(table, chain_name) <TAB>  <TAB> for potential_rule in chain.rules: <MASK> chain.delete_rule(potential_rule)",if Rule . from_iptc ( potential_rule ) in rules :,119
"def __gt__(self, other): <TAB> if isinstance(other, tuple): <TAB>  <TAB> return super().__gt__(other) <TAB> try: <TAB>  <TAB> if self.atEnd == 1 and other != INFINITY: <TAB>  <TAB>  <TAB> return True <MASK> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.offset > other <TAB> except ValueError: <TAB>  <TAB> return NotImplemented",elif self . atEnd == 1 :,98
"def test_related_objects_include_hidden_local_only(self): <TAB> result_key = ""get_all_related_objects_with_model_hidden_local"" <TAB> for model, expected in TEST_RESULTS[result_key].items(): <TAB>  <TAB> objects = [ <TAB>  <TAB>  <TAB> (field, self._model(model, field)) <TAB>  <TAB>  <TAB> for field in model._meta.get_fields( <TAB>  <TAB>  <TAB>  <TAB> include_hidden=True, include_parents=False <TAB>  <TAB>  <TAB> ) <MASK> ] <TAB>  <TAB> self.assertEqual( <TAB>  <TAB>  <TAB> sorted(self._map_names(objects), key=self.key_name), <TAB>  <TAB>  <TAB> sorted(expected, key=self.key_name), <TAB>  <TAB> )",if field . auto_created and not field . concrete,183
"def _cpu_stats(self): <TAB> import psutil <TAB> percents = psutil.cpu_percent(None, True) <TAB> stats = {} <TAB> if self._cpu_percent_init: <TAB>  <TAB> i = 0 <TAB>  <TAB> for percent in percents: <TAB>  <TAB>  <TAB> stats[""sys/cpu%i/util"" % i] = percent / 100 <TAB>  <TAB>  <TAB> i += 1 <MASK> stats[""sys/cpu/util""] = sum(percents) / len(percents) / 100 <TAB> self._cpu_percent_init = True <TAB> return stats",if percents :,130
"def select(self, limit=0): <TAB> """"""Match all tags under the targeted tag."""""" <MASK> limit = None <TAB> for child in self.get_descendants(self.tag): <TAB>  <TAB> if self.match(child): <TAB>  <TAB>  <TAB> yield child <TAB>  <TAB>  <TAB> if limit is not None: <TAB>  <TAB>  <TAB>  <TAB> limit -= 1 <TAB>  <TAB>  <TAB>  <TAB> if limit < 1: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break",if limit < 1 :,100
"def iterate(self, handle): <TAB> """"""Iterate over the records in the XML file."""""" <TAB> parser = self.parser <TAB> content_handler = parser.getContentHandler() <TAB> records = content_handler.records <TAB> BLOCK = self.BLOCK <TAB> while True: <MASK> # Then at least the first record is finished <TAB>  <TAB>  <TAB> record = records.pop(0) <TAB>  <TAB>  <TAB> yield record <TAB>  <TAB> # Read in another block of the file... <TAB>  <TAB> text = handle.read(BLOCK) <TAB>  <TAB> if not text: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> parser.feed(text) <TAB> # We have reached the end of the XML file; <TAB> # send out the remaining records <TAB> yield from records <TAB> records.clear() <TAB> parser.close()",if len ( records ) > 1 :,184
"def append(self, frame, ts=None): <TAB> assert ts is None or len(self._frame_ts) == 0 or ts > self._frame_ts[-1] <TAB> self._frames.append(frame) <TAB> self._next_frame_to_read = len(self._frames) <TAB> if ts is None: <MASK> self._frame_ts.append(self._frame_ts[-1] + 1000.0 / self.fps) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._frame_ts.append(0.0) <TAB> else: <TAB>  <TAB> self._frame_ts.append(ts)",if len ( self . _frame_ts ) > 0 :,157
"def map_volumes_to_size(volumes): <TAB> primary_manifestations = {} <TAB> for volume in volumes: <MASK> # FLOC-1240 non-primaries should be added in too <TAB>  <TAB>  <TAB> path = volume.get_filesystem().get_path() <TAB>  <TAB>  <TAB> primary_manifestations[path] = ( <TAB>  <TAB>  <TAB>  <TAB> volume.name.dataset_id, <TAB>  <TAB>  <TAB>  <TAB> volume.size.maximum_size, <TAB>  <TAB>  <TAB> ) <TAB> return primary_manifestations",if volume . node_id == self . volume_service . node_id :,133
"def setUp(self): <TAB> super(CompleterTest, self).setUp() <TAB> # directories must end with os.sep for completer to <TAB> # search inside the directory for possible completions <TAB> if self.tempdir[-1] != os.sep: <TAB>  <TAB> self.tempdir += os.sep <TAB> self.paths = []  # type: List[str] <TAB> # create some files and directories in temp_dir <TAB> for c in string.ascii_lowercase: <TAB>  <TAB> path = os.path.join(self.tempdir, c) <TAB>  <TAB> self.paths.append(path) <MASK> filesystem.mkdir(path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> with open(path, ""w""): <TAB>  <TAB>  <TAB>  <TAB> pass",if ord ( c ) % 2 :,174
"def pretty_list(items, cols=3): <TAB> text = [] <TAB> width = 24 <TAB> col_width = u""{"" + u"":<"" + str(width) + u""} "" <TAB> for i, lang in enumerate(items): <TAB>  <TAB> lang = lang.decode(u""utf-8"") <TAB>  <TAB> if len(lang) > width: <TAB>  <TAB>  <TAB> lang = lang[: width - 3] + ""..."" <TAB>  <TAB> text.append(u""{:>3}. "".format(i + 1)) <TAB>  <TAB> text.append(col_width.format(lang)) <MASK> text.append(u""\n"") <TAB> return u"""".join(text)",if ( i + 1 ) % cols == 0 :,165
"def to_representation(self, obj): <TAB> serializer_class = self.get_sub_serializer(obj) <TAB> if serializer_class: <TAB>  <TAB> serializer = serializer_class(instance=obj, context=self.context) <TAB>  <TAB> # preserve links for list view <TAB>  <TAB> if self.parent: <TAB>  <TAB>  <TAB> serializer.parent = self.parent <TAB>  <TAB>  <TAB> serializer.polymorphic_base = self <TAB>  <TAB>  <TAB> # capabilities prefetch is only valid for these models <MASK> serializer.capabilities_prefetch = self._capabilities_prefetch <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> serializer.capabilities_prefetch = None <TAB>  <TAB> return serializer.to_representation(obj) <TAB> else: <TAB>  <TAB> return super(UnifiedJobTemplateSerializer, self).to_representation(obj)","if isinstance ( obj , ( JobTemplate , WorkflowJobTemplate ) ) :",193
"def state_DEVAD(self, mdio): <TAB> if self.devad == -1: <TAB>  <TAB> self.devad = 0 <MASK> prtad = [""PRTAD: %02d"" % self.portad, ""PRT"", ""P""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> prtad = [""PHYAD: %02d"" % self.portad, ""PHY"", ""P""] <TAB>  <TAB> self.putff([2, prtad]) <TAB>  <TAB> self.ss_frame_field = self.samplenum <TAB> self.devad_bits -= 1 <TAB> self.devad |= mdio << self.devad_bits <TAB> if not self.devad_bits: <TAB>  <TAB> self.state = ""TA""",if self . clause45 :,183
"def colorDiffRow(self, c, row, v): <TAB> if not row: <TAB>  <TAB> return <TAB> baseval = row[self.basenum + 1] <TAB> for c in self.columns[1:]: <TAB>  <TAB> v = c.getValue(row) <TAB>  <TAB> if v != baseval: <MASK> return ""green""  # addition <TAB>  <TAB>  <TAB> elif v is None: <TAB>  <TAB>  <TAB>  <TAB> return ""red""  # deletion <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return ""yellow""  # difference",if baseval is None :,131
"def _get_ntp_entity(self, peer_type): <TAB> ntp_entities = {} <TAB> command = ""show ntp peers"" <TAB> output = self._send_command(command) <TAB> for line in output.splitlines(): <TAB>  <TAB> # Skip first two lines and last line of command output <MASK> continue <TAB>  <TAB> elif IPAddress(len(line.split()[0])).is_unicast: <TAB>  <TAB>  <TAB> peer_addr = line.split()[0] <TAB>  <TAB>  <TAB> ntp_entities[peer_addr] = {} <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""Did not correctly find a Peer IP Address"") <TAB> return ntp_entities","if line == """" or ""-----"" in line or ""Peer IP Address"" in line :",176
"def getExpandedPath(playerPath): <TAB> if not os.path.isfile(playerPath): <TAB>  <TAB> if os.path.isfile(playerPath + ""mplayer.exe""): <TAB>  <TAB>  <TAB> playerPath += ""mplayer.exe"" <TAB>  <TAB>  <TAB> return playerPath <MASK> playerPath += ""\\mplayer.exe"" <TAB>  <TAB>  <TAB> return playerPath <TAB> if os.access(playerPath, os.X_OK): <TAB>  <TAB> return playerPath <TAB> for path in os.environ[""PATH""].split("":""): <TAB>  <TAB> path = os.path.join(os.path.realpath(path), playerPath) <TAB>  <TAB> if os.access(path, os.X_OK): <TAB>  <TAB>  <TAB> return path","elif os . path . isfile ( playerPath + ""\\mplayer.exe"" ) :",181
"def main(): <TAB> args = parser.parse_args() <TAB> print_arguments(args) <TAB> check_gpu(args.use_gpu) <TAB> if args.profile: <MASK> with profiler.cuda_profiler(""cuda_profiler.txt"", ""csv"") as nvprof: <TAB>  <TAB>  <TAB>  <TAB> train(args) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> with profiler.profiler(""CPU"", sorted_key=""total"") as cpuprof: <TAB>  <TAB>  <TAB>  <TAB> train(args) <TAB> else: <TAB>  <TAB> train(args)",if args . use_gpu :,134
"def add_actions(self, lst, sched_id): <TAB> for a in lst: <TAB>  <TAB> # First we look if we do not already have it, if so <TAB>  <TAB> # do nothing, we are already working! <MASK> continue <TAB>  <TAB> a.sched_id = sched_id <TAB>  <TAB> a.status = ""queue"" <TAB>  <TAB> self.assign_to_a_queue(a)","if a . id in self . schedulers [ sched_id ] [ ""actions"" ] :",114
"def _create_data_from_iob(data_path, separator): <TAB> with open(data_path, encoding=""utf-8"") as input_file: <TAB>  <TAB> columns = [] <TAB>  <TAB> for line in input_file: <TAB>  <TAB>  <TAB> line = line.strip() <TAB>  <TAB>  <TAB> if line == """": <TAB>  <TAB>  <TAB>  <TAB> if columns: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield columns <TAB>  <TAB>  <TAB>  <TAB> columns = [] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> for i, column in enumerate(line.split(separator)): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if len(columns) < i + 1: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> columns.append([]) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> columns[i].append(column) <MASK> yield columns",if len ( columns ) > 0 :,177
"def _mock_set_magics(self): <TAB> these_magics = _magics <TAB> if self._mock_methods is not None: <TAB>  <TAB> these_magics = _magics.intersection(self._mock_methods) <TAB>  <TAB> remove_magics = set() <TAB>  <TAB> remove_magics = _magics - these_magics <TAB>  <TAB> for entry in remove_magics: <MASK> # remove unneeded magic methods <TAB>  <TAB>  <TAB>  <TAB> delattr(self, entry) <TAB> # don't overwrite existing attributes if called a second time <TAB> these_magics = these_magics - set(type(self).__dict__) <TAB> _type = type(self) <TAB> for entry in these_magics: <TAB>  <TAB> setattr(_type, entry, MagicProxy(entry, self))",if entry in type ( self ) . __dict__ :,194
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.add_blob_key(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,92
"def restart_with_reloader(argv): <TAB> args = [sys.executable] + argv <TAB> while True: <TAB>  <TAB> new_environ = os.environ.copy() <TAB>  <TAB> new_environ[""RUN_MAIN_CELERY""] = ""true"" <TAB>  <TAB> exit_code = subprocess.call(args, env=new_environ) <MASK> return exit_code",if exit_code != 3 :,96
"def batch_load_fn(self, keys: Iterable[K]) -> Promise[List[R]]: <TAB> with opentracing.global_tracer().start_active_span( <TAB>  <TAB> self.__class__.__name__ <TAB> ) as scope: <TAB>  <TAB> span = scope.span <TAB>  <TAB> span.set_tag(opentracing.tags.COMPONENT, ""dataloaders"") <TAB>  <TAB> results = self.batch_load(keys) <MASK> return Promise.resolve(results) <TAB>  <TAB> return results","if not isinstance ( results , Promise ) :",119
"def set_path(self): <TAB> """"""Set consoles PYTHONPATH if changed by the user"""""" <TAB> from spyderlib.widgets.externalshell import pythonshell <TAB> for sw in self.shellwidgets: <TAB>  <TAB> if isinstance(sw, pythonshell.ExternalPythonShell): <MASK> sw.path = self.main.get_spyder_pythonpath() <TAB>  <TAB>  <TAB>  <TAB> sw.shell.path = sw.path",if sw . is_interpreter and sw . is_running ( ) :,114
"def testCopyAndDeepcopy(self): <TAB> # Test copying all objects defined in this module <TAB> import copy <TAB> import sys <TAB> import types <TAB> for part in sys.modules[self.__module__].__dict__: <TAB>  <TAB> match = False <TAB>  <TAB> for skip in [""_"", ""__"", ""Test"", ""Exception"", ""MotionType""]: <MASK> match = True <TAB>  <TAB> if match: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> obj = getattr(sys.modules[self.__module__], part) <TAB>  <TAB> # noinspection PyTypeChecker <TAB>  <TAB> if callable(obj) and not isinstance(obj, types.FunctionType): <TAB>  <TAB>  <TAB> copy.copy(obj) <TAB>  <TAB>  <TAB> copy.deepcopy(obj)",if part . startswith ( skip ) or part . endswith ( skip ) :,174
"def list_themes(v=False): <TAB> """"""Display the list of the themes"""""" <TAB> for t, l in themes(): <TAB>  <TAB> if not v: <TAB>  <TAB>  <TAB> t = os.path.basename(t) <MASK> if v: <TAB>  <TAB>  <TAB>  <TAB> print(t + ("" (symbolic link to `"" + l + ""')"")) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> print(t + ""@"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(t)",if l :,113
"def _hasIPv6(self):  # pragma: nocover <TAB> if not socket.has_ipv6: <TAB>  <TAB> return False <TAB> try: <TAB>  <TAB> socket.getaddrinfo( <TAB>  <TAB>  <TAB> ""::1"", <TAB>  <TAB>  <TAB> 0, <TAB>  <TAB>  <TAB> socket.AF_UNSPEC, <TAB>  <TAB>  <TAB> socket.SOCK_STREAM, <TAB>  <TAB>  <TAB> socket.IPPROTO_TCP, <TAB>  <TAB>  <TAB> socket.AI_PASSIVE | socket.AI_ADDRCONFIG, <TAB>  <TAB> ) <TAB>  <TAB> return True <TAB> except socket.gaierror as e: <TAB>  <TAB> # Check to see what the error is <MASK> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise e",if e . errno == socket . EAI_ADDRFAMILY :,170
"def check_distribution_strategy(): <TAB> if tf.distribute.has_strategy(): <TAB>  <TAB> strategy = tf.distribute.get_strategy() <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Sonnet optimizers are not compatible with `{}`. "" <TAB>  <TAB>  <TAB>  <TAB> ""Please use one of `{}` instead."".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> strategy.__class__.__name__, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""`, `"".join(s.__name__ for s in _SUPPORTED_STRATEGIES), <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> )","if not isinstance ( strategy , _SUPPORTED_STRATEGIES ) :",132
"def _process_attributes(self, node, items): <TAB> attributes = [] <TAB> for child in items: <MASK> attribute = self.process(child, node) <TAB>  <TAB>  <TAB> attributes.append(attribute) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise self._create_error(""Unexpected tag `%s`"" % (child.tag), node) <TAB> return attributes","if child . tag in ( tags . attribute , tags . attributeGroup , tags . anyAttribute ) :",105
"def _verify_signature( <TAB> self, payload, signing_input, header, signature, key="""", algorithms=None): <TAB> alg = header.get(""alg"") <TAB> if algorithms is not None and alg not in algorithms: <TAB>  <TAB> raise InvalidAlgorithmError(""The specified alg value is not allowed"") <TAB> try: <TAB>  <TAB> alg_obj = self._algorithms[alg] <TAB>  <TAB> key = alg_obj.prepare_key(key) <MASK> raise InvalidSignatureError(""Signature verification failed"") <TAB> except KeyError: <TAB>  <TAB> raise InvalidAlgorithmError(""Algorithm not supported"")","if not alg_obj . verify ( signing_input , key , signature ) :",147
"def visit_Import(self, node): <TAB> # type: (ast.Import) -> None <TAB> for child in node.names: <MASK> import_name = child.name <TAB>  <TAB>  <TAB> if import_name == self._SDK_PACKAGE: <TAB>  <TAB>  <TAB>  <TAB> self._set_inferred_type_for_name(import_name, Boto3ModuleType()) <TAB> self.generic_visit(node)","if isinstance ( child , ast . alias ) :",105
"def GeneratePageMetatadata(self, proc): <TAB> address_space = self.session.GetParameter(""default_address_space"") <TAB> for map in proc.task.map.hdr.walk_list(""links.next"", include_current=False): <TAB>  <TAB> start = map.links.start <TAB>  <TAB> end = map.links.end <TAB>  <TAB> # Skip the entire region. <TAB>  <TAB> if end < self.plugin_args.start: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # Done. <MASK> break <TAB>  <TAB> for vaddr in utils.xrange(start, end, 0x1000): <TAB>  <TAB>  <TAB> if self.plugin_args.start <= vaddr <= self.plugin_args.end: <TAB>  <TAB>  <TAB>  <TAB> yield vaddr, self._CreateMetadata(address_space.describe_vtop(vaddr))",if start > self . plugin_args . end :,200
"def subhelp_macro(self, macro_name): <TAB> if macro_name in self.macros.keys(): <TAB>  <TAB> macro_def = self.macros[macro_name] <MASK> self.log(""Macro '"" + macro_name + ""' defined as:"") <TAB>  <TAB>  <TAB> self.log(self.macros[macro_name] + ""----------------"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.log(""Macro '"" + macro_name + ""' defined as: '"" + macro_def + ""'"") <TAB> else: <TAB>  <TAB> self.logError(""Macro '"" + macro_name + ""' is not defined"")","if ""\n"" in macro_def :",147
"def get_path_pairs(folder, split_f): <TAB> img_paths = [] <TAB> mask_paths = [] <TAB> with open(split_f, ""r"") as lines: <TAB>  <TAB> for line in tqdm(lines): <TAB>  <TAB>  <TAB> ll_str = re.split(""\t"", line) <TAB>  <TAB>  <TAB> imgpath = os.path.join(folder, ll_str[0].rstrip()) <TAB>  <TAB>  <TAB> maskpath = os.path.join(folder, ll_str[1].rstrip()) <MASK> img_paths.append(imgpath) <TAB>  <TAB>  <TAB>  <TAB> mask_paths.append(maskpath) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> print(""cannot find the mask:"", maskpath) <TAB> return img_paths, mask_paths",if os . path . isfile ( maskpath ) :,186
"def instant_defaults_listener(target, args, kwargs): <TAB> for key, column in sa.inspect(target.__class__).columns.items(): <TAB>  <TAB> if hasattr(column, ""default"") and column.default is not None: <MASK> setattr(target, key, column.default.arg(target)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> setattr(target, key, column.default.arg)",if callable ( column . default . arg ) :,107
"def stat_f(filename, ignore_EACCES=False): <TAB> """"""Call os.stat(), but don't die if the file isn't there. Returns None."""""" <TAB> try: <TAB>  <TAB> return os.stat(filename) <TAB> except OSError as e: <MASK> return None <TAB>  <TAB> if ignore_EACCES and e.errno == errno.EACCES: <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> raise","if e . errno in ( errno . ENOENT , errno . ENOTDIR ) :",114
"def __init__(self, noteList): <TAB> super().__init__() <TAB> self._noteList = [] <TAB> for value in noteList: <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB> self._noteList.append(None) <TAB>  <TAB> elif isinstance(value, str): <TAB>  <TAB>  <TAB> self._noteList.append(note.Note(value)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> try: <MASK> self._noteList.append(value) <TAB>  <TAB>  <TAB> except (AttributeError, NameError): <TAB>  <TAB>  <TAB>  <TAB> self._noteList.append(None)","if value . isClassOrSubclass ( [ note . Note , pitch . Pitch ] ) :",153
"def place(btn): <TAB> """"""get item from stack, and put it in the right place"""""" <TAB> if len(remove_stack) == 0: <TAB>  <TAB> app.bell() <TAB> else: <TAB>  <TAB> f = remove_stack.pop() <TAB>  <TAB> if btn == p[0]: <TAB>  <TAB>  <TAB> f.grid(row=0, column=0, sticky=""NEWS"") <MASK> f.grid(row=0, column=1, sticky=""NEWS"") <TAB>  <TAB> elif btn == p[2]: <TAB>  <TAB>  <TAB> f.grid(row=1, column=0, sticky=""NEWS"") <TAB>  <TAB> elif btn == p[3]: <TAB>  <TAB>  <TAB> f.grid(row=1, column=1, sticky=""NEWS"")",elif btn == p [ 1 ] :,177
"def _apply_color_overlay(self, layer, color, shape, alpha): <TAB> for effect in layer.effects.find(""coloroverlay""): <TAB>  <TAB> color, shape_e = draw_solid_color_fill(layer.bbox, effect.value) <TAB>  <TAB> color = paste(self._viewport, layer.bbox, color, 1.0) <MASK> shape_e = np.ones((self.height, self.width, 1), dtype=np.float32) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> shape_e = paste(self._viewport, layer.bbox, shape_e) <TAB>  <TAB> opacity = effect.opacity / 100.0 <TAB>  <TAB> self._apply_source( <TAB>  <TAB>  <TAB> color, shape * shape_e, alpha * shape_e * opacity, effect.blend_mode <TAB>  <TAB> )",if shape_e is None :,197
"def processTopTree(self, p, justOneFile=False): <TAB> current = p.copy() <TAB> for p in current.self_and_parents(): <TAB>  <TAB> h = p.h <MASK> self.processTree( <TAB>  <TAB>  <TAB>  <TAB> p, <TAB>  <TAB>  <TAB>  <TAB> ext=None, <TAB>  <TAB>  <TAB>  <TAB> toString=False, <TAB>  <TAB>  <TAB>  <TAB> justOneFile=justOneFile, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> self.processTree( <TAB>  <TAB>  <TAB> current, <TAB>  <TAB>  <TAB> ext=None, <TAB>  <TAB>  <TAB> toString=False, <TAB>  <TAB>  <TAB> justOneFile=justOneFile, <TAB>  <TAB> ) <TAB> g.blue(""done"")","if h . startswith ( ""@rst"" ) and not h . startswith ( ""@rst-"" ) :",180
"def __mul__(self, factor): <TAB> f1 = self._value <TAB> f2 = factor._value <TAB> # Make sure that f2 is the smallest, to speed up the loop <TAB> if f2 > f1: <TAB>  <TAB> f1, f2 = f2, f1 <TAB> if self.irr_poly in (f1, f2): <TAB>  <TAB> return _Element(0) <TAB> mask1 = 2 ** 128 <TAB> v, z = f1, 0 <TAB> while f2: <MASK> z ^= v <TAB>  <TAB> v <<= 1 <TAB>  <TAB> if v & mask1: <TAB>  <TAB>  <TAB> v ^= self.irr_poly <TAB>  <TAB> f2 >>= 1 <TAB> return _Element(z)",if f2 & 1 :,174
"def get_blacklist(self, guild: Optional[discord.Guild] = None) -> Set[int]: <TAB> async with self._access_lock: <TAB>  <TAB> ret: Set[int] <TAB>  <TAB> gid: Optional[int] = guild.id if guild else None <MASK> ret = self._cached_blacklist[gid].copy() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if gid is not None: <TAB>  <TAB>  <TAB>  <TAB> ret = set(await self._config.guild_from_id(gid).blacklist()) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> ret = set(await self._config.blacklist()) <TAB>  <TAB>  <TAB> self._cached_blacklist[gid] = ret.copy() <TAB>  <TAB> return ret",if gid in self . _cached_blacklist :,177
"def to_internal_value(self, data): <TAB> try: <TAB>  <TAB> if isinstance(data, (list, tuple)): <TAB>  <TAB>  <TAB> return super(StringListBooleanField, self).to_internal_value(data) <MASK> return True <TAB>  <TAB> elif data in NullBooleanField.FALSE_VALUES: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> elif data in NullBooleanField.NULL_VALUES: <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> elif isinstance(data, str): <TAB>  <TAB>  <TAB> return self.child.run_validation(data) <TAB> except TypeError: <TAB>  <TAB> pass <TAB> self.fail(""type_error"", input_type=type(data))",elif data in NullBooleanField . TRUE_VALUES :,159
"def execute(): <TAB> for wo in frappe.db.sql( <TAB>  <TAB> """"""select name from `tabWork Order` where docstatus < 2"""""", as_dict=1 <TAB> ): <TAB>  <TAB> work_order = frappe.get_doc(""Work Order"", wo.name) <MASK> work_order.flags.ignore_validate_update_after_submit = True <TAB>  <TAB>  <TAB> work_order.calculate_time() <TAB>  <TAB>  <TAB> work_order.save()",if work_order . operations :,120
"def return_load_handlers(filename, del_file_after_loading=True): <TAB> if os.path.isfile(filename) and os.path.getsize(filename) > 0: <TAB>  <TAB> with open(filename, ""rb"") as file: <MASK> handlers = pickle.load(file) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> handlers = apihelper.CUSTOM_SERIALIZER.load(file) <TAB>  <TAB> if del_file_after_loading: <TAB>  <TAB>  <TAB> os.remove(filename) <TAB>  <TAB> return handlers",if apihelper . CUSTOM_SERIALIZER is None :,139
"def setUp(self): <TAB> BaseTestCase.setUp(self) <TAB> self.rawData = [] <TAB> self.dataByKey = {} <TAB> for i in range(1, 11): <TAB>  <TAB> unicodeCol = u""Unicode \u3042 %d"" % i <TAB>  <TAB> fixedCharCol = (u""Fixed Unicode %d"" % i).ljust(40) <MASK> nullableCol = u""Nullable %d"" % i <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> nullableCol = None <TAB>  <TAB> dataTuple = (i, unicodeCol, fixedCharCol, nullableCol) <TAB>  <TAB> self.rawData.append(dataTuple) <TAB>  <TAB> self.dataByKey[i] = dataTuple",if i % 2 :,165
"def upgrade(ver, session): <TAB> if ver is None: <TAB>  <TAB> columns = table_columns(""make_rss"", session) <MASK> log.info(""Adding rsslink column to table make_rss."") <TAB>  <TAB>  <TAB> table_add_column(""make_rss"", ""rsslink"", String, session) <TAB>  <TAB> ver = 0 <TAB> return ver","if ""rsslink"" not in columns :",92
"def setlist(self): <TAB> self.list.LDelRow(0, 0) <TAB> self.list.LSetDrawingMode(0) <TAB> if self.contents: <TAB>  <TAB> self.list.LAddRow(len(self.contents), 0) <TAB>  <TAB> for i in range(len(self.contents)): <TAB>  <TAB>  <TAB> v = repr(self.contents[i][0]) <MASK> v = v + '""' + self.contents[i][1] + '""' <TAB>  <TAB>  <TAB> self.list.LSetCell(v, (0, i)) <TAB> self.list.LSetDrawingMode(1) <TAB> self.list.LUpdate(self.wid.GetWindowPort().visRgn)",if self . contents [ i ] [ 1 ] :,180
"def onStatusChanged(self, provider, status, extras): <TAB> if self.root.on_status: <TAB>  <TAB> s_status = ""unknown"" <TAB>  <TAB> if status == 0x00: <TAB>  <TAB>  <TAB> s_status = ""out-of-service"" <TAB>  <TAB> elif status == 0x01: <TAB>  <TAB>  <TAB> s_status = ""temporarily-unavailable"" <MASK> s_status = ""available"" <TAB>  <TAB> self.root.on_status(""provider-status"", ""{}: {}"".format(provider, s_status))",elif status == 0x02 :,130
"def weight_initialization(self): <TAB> for m in self.modules(): <MASK> nn.init.constant_(m.bn.weight, 1) <TAB>  <TAB>  <TAB> nn.init.constant_(m.bn.bias, 0)","if isinstance ( m , ME . MinkowskiBatchNorm ) :",69
"def _find_best_version(self): <TAB> versions_by_size = order_versions_in_descending_order(self.available_versions) <TAB> if self.version == ""latest"": <TAB>  <TAB> self.version = versions_by_size[0] <TAB> version_constraints = get_version_constraints(self.version) <TAB> num_of_matches = 0 <TAB> for version in versions_by_size: <TAB>  <TAB> for version_constraint in version_constraints: <MASK> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> num_of_matches += 1 <TAB>  <TAB> if num_of_matches == len(version_constraints): <TAB>  <TAB>  <TAB> return version <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> num_of_matches = 0 <TAB> return ""latest""",if not version_constraint . versions_matching ( version ) :,192
"def _nickname(self, ctx: commands.Context, *, nickname: str = None): <TAB> """"""Sets [botname]'s nickname."""""" <TAB> try: <MASK> await ctx.send( <TAB>  <TAB>  <TAB>  <TAB> _(""Failed to change nickname. Must be 32 characters or fewer."") <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> await ctx.guild.me.edit(nick=nickname) <TAB> except discord.Forbidden: <TAB>  <TAB> await ctx.send(_(""I lack the permissions to change my own nickname."")) <TAB> else: <TAB>  <TAB> await ctx.send(_(""Done.""))",if nickname and len ( nickname ) > 32 :,152
"def execute(self): <TAB> if self._qr is None: <MASK> ResultWrapper = TuplesQueryResultWrapper <TAB>  <TAB> elif self._dicts: <TAB>  <TAB>  <TAB> ResultWrapper = DictQueryResultWrapper <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ResultWrapper = NaiveQueryResultWrapper <TAB>  <TAB> self._qr = ResultWrapper(self.model_class, self._execute(), None) <TAB> return self._qr",if self . _tuples :,97
"def to_match_ip(value): <TAB> if ""/"" in value: <TAB>  <TAB> (ip_addr, ip_mask) = value.split(""/"") <MASK> ip = netaddr.ip.IPNetwork(value) <TAB>  <TAB>  <TAB> ip_addr = str(ip.ip) <TAB>  <TAB>  <TAB> ip_mask = str(ip.netmask) <TAB>  <TAB> return ip_addr, ip_mask <TAB> return value",if ip_mask . isdigit ( ) :,104
def correct(self): <TAB> for A in self.circles: <TAB>  <TAB> intersects = False <TAB>  <TAB> for B in self.circles: <MASK> radsq = (A.r + B.r) * (A.r + B.r) <TAB>  <TAB>  <TAB>  <TAB> d = A.sqdist_o(B) <TAB>  <TAB>  <TAB>  <TAB> if radsq > d: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> intersects = True <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if not intersects: <TAB>  <TAB>  <TAB> A.x = A.ox <TAB>  <TAB>  <TAB> A.y = A.oy,if A != B :,145
"def py_info_clear(self): <TAB> """""""""""" <TAB> py_info_folder = self.py_info_at <TAB> with py_info_folder: <TAB>  <TAB> for filename in py_info_folder.path.iterdir(): <MASK> with py_info_folder.lock_for_key(filename.stem): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if filename.exists(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> filename.unlink()","if filename . suffix == "".json"" :",111
"def _dom_node(self, domroot): <TAB> element = domroot.createElement(self.tagname) <TAB> for attribute, value in self.attlist(): <MASK> value = "" "".join([serial_escape(""%s"" % (v,)) for v in value]) <TAB>  <TAB> element.setAttribute(attribute, ""%s"" % value) <TAB> for child in self.children: <TAB>  <TAB> element.appendChild(child._dom_node(domroot)) <TAB> return element","if isinstance ( value , list ) :",116
"def remove_empty_lines(content): <TAB> try: <MASK> content = content[1 : content.rfind(""\n"")] <TAB>  <TAB> if content[-1] == ""\n"": <TAB>  <TAB>  <TAB> content = content[: content.rfind(""\n"")] <TAB> except IndexError: <TAB>  <TAB> pass <TAB> return content","if content [ 0 ] == ""\n"" :",81
"def expandNode(self, node): <TAB> event = self.getEvent() <TAB> parents = [node] <TAB> while event: <TAB>  <TAB> token, cur_node = event <TAB>  <TAB> if cur_node is node: <TAB>  <TAB>  <TAB> return <MASK> parents[-1].appendChild(cur_node) <TAB>  <TAB> if token == START_ELEMENT: <TAB>  <TAB>  <TAB> parents.append(cur_node) <TAB>  <TAB> elif token == END_ELEMENT: <TAB>  <TAB>  <TAB> del parents[-1] <TAB>  <TAB> event = self.getEvent()",if token != END_ELEMENT :,130
"def iter_pairs(items, wrap, repeat=False): <TAB> if not items: <TAB>  <TAB> return <TAB> while True: <TAB>  <TAB> for i0, i1 in zip(items[:-1], items[1:]): <TAB>  <TAB>  <TAB> yield i0, i1 <MASK> yield items[-1], items[0] <TAB>  <TAB> if not repeat: <TAB>  <TAB>  <TAB> return",if wrap :,90
"def fix_value_info(value): <TAB> num_fixed = 0 <TAB> if value.type.HasField(""tensor_type""): <TAB>  <TAB> shape = value.type.tensor_type.shape <TAB>  <TAB> if shape: <TAB>  <TAB>  <TAB> dim = shape.dim[0] <MASK> num_fixed += 1 <TAB> return num_fixed",if fix_dim ( dim ) :,90
"def isMasterFromActiveLogins(self, chat_id): <TAB> with self.bot.database as conn: <TAB>  <TAB> cur = conn.cursor() <TAB>  <TAB> cur.execute(""select count(1) from telegram_logins where uid = ?"", [chat_id]) <TAB>  <TAB> res = cur.fetchone() <MASK> return True <TAB>  <TAB> return False",if res [ 0 ] == 1 :,91
"def wrapper(cached=True, reset=False): <TAB> nonlocal cached_python_dir <TAB> if not cached or not cached_python_dir or reset: <TAB>  <TAB> python_dir = os.environ.get(""_PYTHON_DIR_"") or load_settings(lazy=True).get( <TAB>  <TAB>  <TAB> ""python_dir"" <TAB>  <TAB> ) <TAB>  <TAB> if python_dir:  # no cov <MASK> python_dir = PYTHON_DIR_ISOLATED <TAB>  <TAB>  <TAB> elif python_dir == ""shared"": <TAB>  <TAB>  <TAB>  <TAB> python_dir = PYTHON_DIR_SHARED <TAB>  <TAB> else:  # no cov <TAB>  <TAB>  <TAB> python_dir = PYTHON_DIR_SHARED <TAB>  <TAB> cached_python_dir = python_dir <TAB> return cached_python_dir","if python_dir == ""isolated"" :",183
"def _handle_call(self, call): <TAB> if call is None or self.type is not MessageType.call: <TAB>  <TAB> self.call = None <TAB>  <TAB> return <TAB> # we get the participant source from the mentions array or <TAB> # the author <TAB> participants = [] <TAB> for uid in map(int, call.get(""participants"", [])): <TAB>  <TAB> if uid == self.author.id: <TAB>  <TAB>  <TAB> participants.append(self.author) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> user = utils.find(lambda u: u.id == uid, self.mentions) <MASK> participants.append(user) <TAB> call[""participants""] = participants <TAB> self.call = CallMessage(message=self, **call)",if user is not None :,185
"def extract(self, im: np.ndarray, debug_save_name=None): <TAB> with fluid.dygraph.guard(): <MASK> np.savez(debug_save_name, im) <TAB>  <TAB> im = n2p(im) <TAB>  <TAB> output_features = self.net.extract_backbone_features(im) <TAB>  <TAB> # Store the raw backbone features which are input to estimator <TAB>  <TAB> output = TensorList([layer.numpy() for layer in output_features]) <TAB>  <TAB> return output",if debug_save_name is not None :,130
"def parseNode(self, node): <TAB> for child in node.childNodes: <TAB>  <TAB> if child.nodeType == ELEMENT_NODE: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.parseOld(child.childNodes[0].nodeValue) <TAB>  <TAB>  <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise ValidationError(""Old cannot be empty"", ""??"") <TAB>  <TAB>  <TAB> elif child.tagName == ""New"": <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.parseNew(child.childNodes[0].nodeValue) <TAB>  <TAB>  <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise ValidationError(""New cannot be empty"", ""??"")","if child . tagName == ""Old"" :",162
"def _compute_bounds_2d(vals): <TAB> minval = np.inf <TAB> maxval = -np.inf <TAB> for i in range(vals.shape[0]): <TAB>  <TAB> for j in range(vals.shape[1]): <TAB>  <TAB>  <TAB> v = vals[i][j] <TAB>  <TAB>  <TAB> if not np.isnan(v): <TAB>  <TAB>  <TAB>  <TAB> if v < minval: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> minval = v <MASK> maxval = v <TAB> return minval, maxval",if v > maxval :,122
"def truncate(s, n): <TAB> """"""Return s truncated to n characters."""""" <TAB> if len(s) <= n: <TAB>  <TAB> return s <TAB> else: <TAB>  <TAB> s2 = s[: n - 3] + ""...(%s)"" % len(s) <MASK> return s2 + ""\n"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return s2","if s . endswith ( ""\n"" ) :",92
def draw(self): <TAB> try: <TAB>  <TAB> if self.env.cmd.show_obj.draw_bookmarks: <TAB>  <TAB>  <TAB> self._draw_bookmarks() <TAB> except AttributeError: <MASK> self.win.erase() <TAB>  <TAB>  <TAB> self.need_redraw = True <TAB>  <TAB>  <TAB> self.need_clear = False <TAB>  <TAB> DisplayableContainer.draw(self),if self . need_clear :,98
"def _parse_struct_fields(inner): <TAB> fields = [] <TAB> field_tuples = _split_struct_fields(inner) <TAB> for (name, value) in field_tuples: <TAB>  <TAB> field = {} <TAB>  <TAB> field[""name""] = name <TAB>  <TAB> simple_type, inner = _parse_type(value) <TAB>  <TAB> field[""type""] = simple_type <MASK> field.update(_parse_complex(simple_type, inner)) <TAB>  <TAB> fields.append(field) <TAB> return fields",if inner :,123
"def on_task_learn(self, task, config): <TAB> config = self.prepare_config(config) <TAB> with Session() as session: <TAB>  <TAB> for entry in task.all_entries: <MASK> continue <TAB>  <TAB>  <TAB> entry[""digest_task""] = task.name <TAB>  <TAB>  <TAB> entry[""digest_state""] = entry.state <TAB>  <TAB>  <TAB> session.add(DigestEntry(list=config[""list""], entry=entry))","if entry . state not in config [ ""state"" ] :",115
"def async_post_installation(self): <TAB> """"""Run post installation steps."""""" <TAB> if self.data.config_flow: <MASK> await self.reload_custom_components() <TAB>  <TAB> if self.data.first_install: <TAB>  <TAB>  <TAB> self.pending_restart = False <TAB>  <TAB>  <TAB> return <TAB> self.pending_restart = True","if self . data . full_name != ""hacs/integration"" :",97
"def generate_copyright(template, lang=""go""): <TAB> if lang in [""Python"", ""shell""]: <TAB>  <TAB> LANG_COMMENT_MARK = ""#"" <TAB> else: <TAB>  <TAB> LANG_COMMENT_MARK = ""//"" <TAB> lines = template.split(NEW_LINE_MARK) <TAB> BLANK = "" "" <TAB> ans = LANG_COMMENT_MARK + BLANK + COPYRIGHT_HEADER + NEW_LINE_MARK <TAB> for lino, line in enumerate(lines): <MASK> continue <TAB>  <TAB> if len(line) == 0: <TAB>  <TAB>  <TAB> BLANK = """" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> BLANK = "" "" <TAB>  <TAB> ans += LANG_COMMENT_MARK + BLANK + line + NEW_LINE_MARK <TAB> return ans + ""\n""",if lino == 0 or lino == 1 or lino == len ( lines ) - 1 :,195
"def test_get_first_child(self, model): <TAB> data = [ <TAB>  <TAB> (""2"", ""21""), <TAB>  <TAB> (""21"", None), <TAB>  <TAB> (""23"", ""231""), <TAB>  <TAB> (""231"", None), <TAB> ] <TAB> for desc, expected in data: <TAB>  <TAB> node = model.objects.get(desc=desc).get_first_child() <MASK> assert node is None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert node.desc == expected <TAB>  <TAB>  <TAB> assert type(node) == model",if expected is None :,130
"def test_failures(self): <TAB> for idx, doc in enumerate(JSONDOCS): <TAB>  <TAB> idx = idx + 1 <MASK> json.loads(doc) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> json.loads(doc) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.fail(""Expected failure for fail%d.json: %r"" % (idx, doc))",if idx in SKIPS :,109
"def parse_download_link(self, line, in_download): <TAB> """"""Parse Flutter SDK download links"""""" <TAB> url = None <TAB> in_download = False <TAB> if ""Flutter "" in line: <TAB>  <TAB> p = re.search(r""Flutter\s(\S+)"", line) <MASK> in_download = True <TAB> if in_download: <TAB>  <TAB> with suppress(AttributeError): <TAB>  <TAB>  <TAB> url = ( <TAB>  <TAB>  <TAB>  <TAB> ""https://storage.googleapis.com/flutter_infra/releases/stable/linux/"" <TAB>  <TAB>  <TAB>  <TAB> + ""flutter_linux_v{}-stable.tar.xz"".format(p.group(1)) <TAB>  <TAB>  <TAB> ) <TAB> return ((url, None), in_download)",if p is not None :,180
"def yields(self): <TAB> for h4 in self.soup.findAll(""h4""): <TAB>  <TAB> for strong in h4.findAll(""strong""): <TAB>  <TAB>  <TAB> raw_yield = strong.text <TAB>  <TAB>  <TAB> for word in raw_yield.split(): <MASK> yields = word <TAB> return get_yields(""{} servings"".format(yields))",if word . isdigit ( ) :,91
"def __iter__(self) -> Iterator[List[SampledData]]: <TAB> for batch in self.data_loader: <TAB>  <TAB> # batch : List[Tensor[N, C, H, W]] <TAB>  <TAB> # images_batch : Tensor[N, C, H, W] <TAB>  <TAB> # image : Tensor[C, H, W] <TAB>  <TAB> images = [image for images_batch in batch for image in images_batch] <TAB>  <TAB> if not images: <TAB>  <TAB>  <TAB> continue <MASK> random.shuffle(images) <TAB>  <TAB> yield from self._produce_data(images)",if self . shuffle :,139
"def set_cookie(self, cookie): <TAB> """"""Set a cookie, without checking whether or not it should be set."""""" <TAB> c = self._cookies <TAB> self._cookies_lock.acquire() <TAB> try: <TAB>  <TAB> if cookie.domain not in c: <TAB>  <TAB>  <TAB> c[cookie.domain] = {} <TAB>  <TAB> c2 = c[cookie.domain] <MASK> c2[cookie.path] = {} <TAB>  <TAB> c3 = c2[cookie.path] <TAB>  <TAB> c3[cookie.name] = cookie <TAB> finally: <TAB>  <TAB> self._cookies_lock.release()",if cookie . path not in c2 :,148
"def product(self, term, ordinal): <TAB> dims = term._pyro_dims <TAB> for dim in sorted(ordinal, reverse=True): <TAB>  <TAB> pos = dims.find(dim) <TAB>  <TAB> if pos != -1: <TAB>  <TAB>  <TAB> key = ""product"", self._hash_by_id(term), dim <MASK> term = self._cache[key] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> term = term.sum(pos) <TAB>  <TAB>  <TAB>  <TAB> dims = dims.replace(dim, """") <TAB>  <TAB>  <TAB>  <TAB> self._cache[key] = term <TAB>  <TAB>  <TAB>  <TAB> term._pyro_dims = dims <TAB> return term",if key in self . _cache :,160
"def set_inputs(self, num_inputs): <TAB> if num_inputs == len(self.inputs): <TAB>  <TAB> return <TAB> if num_inputs < len(self.inputs): <TAB>  <TAB> while num_inputs < len(self.inputs): <TAB>  <TAB>  <TAB> self.inputs.remove(self.inputs[-1]) <TAB> if num_inputs > len(self.inputs): <MASK> self.inputs.new(""SvStringsSocket"", ""X"") <TAB>  <TAB> if ""Y"" not in self.inputs and num_inputs == 2: <TAB>  <TAB>  <TAB> self.inputs.new(""SvStringsSocket"", ""Y"") <TAB>  <TAB> self.change_prop_type(None)","if ""X"" not in self . inputs :",166
"def setCornerWidget(self, cornerWidget, cornerWidgetExpanded=False): <TAB> if self.__cornerWidget is not None: <TAB>  <TAB> self.removeChild(self.__cornerWidget) <TAB> if cornerWidget is not None: <TAB>  <TAB> if cornerWidgetExpanded and self.__headerLayout.stretch(1) == 1: <TAB>  <TAB>  <TAB> self.__headerLayout.setStretch(1, 0) <MASK> self.__headerLayout.setStretch(1, 1) <TAB>  <TAB> stretch = 1 if cornerWidgetExpanded else 0 <TAB>  <TAB> self.__headerLayout.addWidget(cornerWidget._qtWidget(), stretch) <TAB>  <TAB> self.__cornerWidget = cornerWidget <TAB>  <TAB> self.__cornerWidget._applyVisibility()",elif self . __headerLayout . stretch ( 1 ) == 0 :,180
"def stop(self, kill=False, timeout=15, _=False): <TAB> term = False <TAB> start_time = time.time() <TAB> timeout *= self._context.timeout_multiplier <TAB> while self._handle and self._is_running(): <MASK> self._handle.kill() <TAB>  <TAB> elif not term: <TAB>  <TAB>  <TAB> self._handle.terminate() <TAB>  <TAB>  <TAB> term = True <TAB>  <TAB> time.sleep(1) <TAB>  <TAB> if not kill and time.time() - start_time > timeout: <TAB>  <TAB>  <TAB> kill = True <TAB> if self._log: <TAB>  <TAB> self._log.close()",if kill :,147
"def filter_after(res_list, after_time): <TAB> after_time = time_parse(after_time) <TAB> new_res_list = [] <TAB> for res in res_list: <TAB>  <TAB> if ""time_last"" in res: <TAB>  <TAB>  <TAB> if res[""time_last""] > after_time: <TAB>  <TAB>  <TAB>  <TAB> new_res_list.append(res) <MASK> if res[""zone_time_last""] > after_time: <TAB>  <TAB>  <TAB>  <TAB> new_res_list.append(res) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_res_list.append(res) <TAB> return new_res_list","elif ""zone_time_last"" in res :",163
"def create(self, user, repo, add=False): <TAB> try: <TAB>  <TAB> group = self.gl.groups.search(user) <TAB>  <TAB> data = {""name"": repo} <MASK> data[""namespace_id""] = group[0].id <TAB>  <TAB> self.gl.projects.create(data=data) <TAB> except GitlabCreateError as err: <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB> json.loads(err.response_body.decode(""utf-8""))[""message""][""name""][0] <TAB>  <TAB>  <TAB> == ""has already been taken"" <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> raise ResourceExistsError(""Project already exists."") from err <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ResourceError(""Unhandled error."") from err <TAB> if add: <TAB>  <TAB> self.add(user=user, repo=repo, tracking=self.name)",if group :,195
"def __init__(self, value, timestamp, attachments): <TAB> self._value = value <TAB> self._timestamp = timestamp <TAB> if attachments is None: <TAB>  <TAB> raise TypeError(""attachments should not be empty"") <TAB> for key, value in attachments.items(): <TAB>  <TAB> if key is None or not isinstance(key, str): <TAB>  <TAB>  <TAB> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""attachment key should not be "" ""empty and should be a string"" <TAB>  <TAB>  <TAB> ) <MASK> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""attachment value should not be "" ""empty and should be a string"" <TAB>  <TAB>  <TAB> ) <TAB> self._attachments = attachments","if value is None or not isinstance ( value , str ) :",158
"def valid_stream_name_or_error(name: str): <TAB> try: <MASK> raise Exception(""Stream name cannot be blank."") <TAB>  <TAB> parsed = URL.parse(name) <TAB>  <TAB> if parsed.has_channel: <TAB>  <TAB>  <TAB> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> ""Stream names cannot start with '@' symbol. This is reserved for channels claims."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if not parsed.has_stream or parsed.stream.name != name: <TAB>  <TAB>  <TAB> raise Exception(""Stream name has invalid characters."") <TAB> except (TypeError, ValueError): <TAB>  <TAB> raise Exception(""Invalid stream name."")",if not name :,144
"def openoutputfile(self, options, fulloutputpath): <TAB> """"""Opens the output file."""""" <TAB> if self.isarchive(options.output, ""output""): <TAB>  <TAB> outputstream = options.outputarchive.openoutputfile(fulloutputpath) <MASK> self.warning( <TAB>  <TAB>  <TAB>  <TAB> ""Could not find where to put %s in output "" <TAB>  <TAB>  <TAB>  <TAB> ""archive; writing to tmp"" % fulloutputpath <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return StringIO() <TAB>  <TAB> return outputstream <TAB> else: <TAB>  <TAB> return super(ArchiveConvertOptionParser, self).openoutputfile( <TAB>  <TAB>  <TAB> options, fulloutputpath <TAB>  <TAB> )",if outputstream is None :,161
"def _response(self, request_number, t, *arg): <TAB> msg = Message() <TAB> msg.add_int(request_number) <TAB> for item in arg: <MASK> msg.add_int64(item) <TAB>  <TAB> elif isinstance(item, int): <TAB>  <TAB>  <TAB> msg.add_int(item) <TAB>  <TAB> elif isinstance(item, (string_types, bytes_types)): <TAB>  <TAB>  <TAB> msg.add_string(item) <TAB>  <TAB> elif type(item) is SFTPAttributes: <TAB>  <TAB>  <TAB> item._pack(msg) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception(""unknown type for {!r} type {!r}"".format(item, type(item))) <TAB> self._send_packet(t, msg)","if isinstance ( item , long ) :",181
"def _real_start(self): <TAB> try: <MASK> self.action_log_info(""Starting up"") <TAB>  <TAB>  <TAB> self.verify_hash_type() <TAB>  <TAB>  <TAB> self.minion.tune_in() <TAB>  <TAB>  <TAB> if self.minion.restart: <TAB>  <TAB>  <TAB>  <TAB> raise SaltClientError(""Minion could not connect to Master"") <TAB> except (KeyboardInterrupt, SaltSystemExit) as error: <TAB>  <TAB> self.action_log_info(""Stopping"") <TAB>  <TAB> if isinstance(error, KeyboardInterrupt): <TAB>  <TAB>  <TAB> log.warning(""Exiting on Ctrl-c"") <TAB>  <TAB>  <TAB> self.shutdown() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.error(error) <TAB>  <TAB>  <TAB> self.shutdown(error.code)","if check_user ( self . config [ ""user"" ] ) :",182
"def _mount(path, ftype, root=None): <TAB> mpt = None <TAB> if ftype == ""block"": <TAB>  <TAB> mpt = tempfile.mkdtemp() <TAB>  <TAB> if not __salt__[""mount.mount""](mpt, path): <TAB>  <TAB>  <TAB> os.rmdir(mpt) <TAB>  <TAB>  <TAB> return None <TAB> elif ftype == ""dir"": <TAB>  <TAB> return path <TAB> elif ftype == ""file"": <TAB>  <TAB> if ""guestfs.mount"" in __salt__: <TAB>  <TAB>  <TAB> util = ""guestfs"" <MASK> util = ""qemu_nbd"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> mpt = __salt__[""mount.mount""](path, device=root, util=util) <TAB>  <TAB> if not mpt: <TAB>  <TAB>  <TAB> return None <TAB> return mpt","elif ""qemu_nbd.init"" in __salt__ :",200
"def Visit_not_test(self, node):  # pylint: disable=invalid-name <TAB> # not_test ::= 'not' not_test | comparison <TAB> for child in node.children: <TAB>  <TAB> self.Visit(child) <MASK> _AppendTokenSubtype(child, format_token.Subtype.UNARY_OPERATOR)","if isinstance ( child , pytree . Leaf ) and child . value == ""not"" :",97
"def get_required_glibc(self) -> str: <TAB> """"""Returns the required glibc version for this ELF file."""""" <TAB> with contextlib.suppress(AttributeError): <TAB>  <TAB> return self._required_glibc  # type: ignore <TAB> version_required = """" <TAB> for lib in self.needed.values(): <TAB>  <TAB> for version in lib.versions: <MASK> continue <TAB>  <TAB>  <TAB> version = version[6:] <TAB>  <TAB>  <TAB> if parse_version(version) > parse_version(version_required): <TAB>  <TAB>  <TAB>  <TAB> version_required = version <TAB> self._required_glibc = version_required <TAB> return version_required","if not version . startswith ( ""GLIBC_"" ) :",160
"def doFilter(self, filters, **args): <TAB> plug_fils = { <TAB>  <TAB> key[5:]: value for (key, value) in filters.items() if key.startswith(""plug_"") <TAB> } <TAB> filters_ = [] <TAB> for plugin in self.getWebPlugins(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> filter_ = plugin.doFilter(plug_fils, **args) <TAB>  <TAB>  <TAB> if filter_: <MASK> filters_.append(filter_) <TAB>  <TAB>  <TAB>  <TAB> elif type(filter_) is list: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> filters_.extend(filter_) <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> print(""[!] Plugin %s failed on applying filters!"" % plugin.getName()) <TAB>  <TAB>  <TAB> print(""[!]  -> %s"" % e) <TAB> return filters_",if type ( filter_ ) is dict :,197
"def test_all_managers_are_different(self): <TAB> # all tree managers should be different. otherwise, possible infinite recursion. <TAB> seen = {} <TAB> for model in apps.get_models(): <TAB>  <TAB> if not issubclass(model, MPTTModel): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> tm = model._tree_manager <MASK> self.fail( <TAB>  <TAB>  <TAB>  <TAB> ""Tree managers for %s and %s are the same manager"" <TAB>  <TAB>  <TAB>  <TAB> % (model.__name__, seen[id(tm)].__name__) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> seen[id(tm)] = model",if id ( tm ) in seen :,149
"def build_list_params(self, params, items, label): <TAB> if isinstance(items, six.string_types): <TAB>  <TAB> items = [items] <TAB> for index, item in enumerate(items): <TAB>  <TAB> i = index + 1 <MASK> for k, v in six.iteritems(item): <TAB>  <TAB>  <TAB>  <TAB> params[label % (i, ""Name"")] = k <TAB>  <TAB>  <TAB>  <TAB> if v is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> params[label % (i, ""Value"")] = v <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> params[label % i] = item","if isinstance ( item , dict ) :",144
"def tokenize_lines_fn(x): <TAB> """"""Worker function to tokenize lines based on the tokenizer, and perform vocabulary lookup."""""" <TAB> lines, tokenizer, vocab = x <TAB> results = [] <TAB> for line in lines: <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> line = line.strip() <TAB>  <TAB> # Empty lines are used as document delimiters <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB> results.append([]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tokens = vocab[tokenizer(line)] <MASK> results.append(tokens) <TAB> return results",if tokens :,135
"def logConsumer(self): <TAB> r = re.compile(r""dpkg-genchanges  >\.\./(.+\.changes)"") <TAB> while True: <TAB>  <TAB> stream, line = yield <TAB>  <TAB> mo = r.search(line) <MASK> self.setProperty(""deb-changes"", mo.group(1), ""DebPbuilder"")",if mo :,88
"def teardown(self): <TAB> if hasattr(self, ""mod_env""): <MASK> os.remove(self.archive) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> shutil.rmtree(self.archive) <TAB>  <TAB> self.archive = None",if os . path . isfile ( self . archive ) :,69
"def __new__(cls, exceptions, result, requests): <TAB> if len(result) != len(exceptions) != len(requests): <TAB>  <TAB> raise ValueError(""Need result, exception and request for each error"") <TAB> for e, req in zip(exceptions, requests): <TAB>  <TAB> if not isinstance(e, BaseException) and e is not None: <TAB>  <TAB>  <TAB> raise TypeError(""Expected an exception object, not '%r'"" % e) <MASK> raise TypeError(""Expected TLRequest object, not '%r'"" % req) <TAB> if len(exceptions) == 1: <TAB>  <TAB> return exceptions[0] <TAB> self = BaseException.__new__(cls) <TAB> self.exceptions = list(exceptions) <TAB> self.results = list(result) <TAB> self.requests = list(requests) <TAB> return self","if not isinstance ( req , TLRequest ) :",190
"def platformAttach(self, pid): <TAB> self._connectSocket() <TAB> self.attaching = True <TAB> # Wait for the debug stub to stop the target <TAB> while True: <TAB>  <TAB> pkt = self._cmdTransact(""?"") <MASK> raise Exception(""Attach Response Error!"") <TAB>  <TAB> if int(pkt[1:3], 16) == 0: <TAB>  <TAB>  <TAB> import time <TAB>  <TAB>  <TAB> time.sleep(0.1) <TAB>  <TAB>  <TAB> self.platformSendBreak() <TAB>  <TAB>  <TAB> pkt = self._cmdTransact(""?"") <TAB>  <TAB> break <TAB> self._sendPkt(""?"")",if len ( pkt ) == 0 :,143
"def parse(filepath, variable): <TAB> f = open(filepath, ""r"") <TAB> for line in f: <TAB>  <TAB> if line.startswith(""  ""): <TAB>  <TAB>  <TAB> tokens = [t.strip() for t in line.split("":"")] <MASK> f.close() <TAB>  <TAB>  <TAB>  <TAB> return "": "".join(tokens[1:]) <TAB> f.close()",if len ( tokens ) >= 2 and tokens [ 0 ] . lower ( ) == variable . lower ( ) :,106
"def generateValueNode(self, node): <TAB> result = super().generateValueNode(node) <TAB> if result == """" or result.isspace(): <TAB>  <TAB> return '""""' <TAB> else: <MASK> # don't quote search value on keyword field <TAB>  <TAB>  <TAB> if self.CaseInSensitiveField: <TAB>  <TAB>  <TAB>  <TAB> make_ci = self.makeCaseInSensitiveValue(result) <TAB>  <TAB>  <TAB>  <TAB> result = make_ci.get(""value"") <TAB>  <TAB>  <TAB>  <TAB> if make_ci.get(""is_regex""):  # Determine if still should be a regex <TAB>  <TAB>  <TAB>  <TAB>  <TAB> result = ""/%s/"" % result  # Regex place holders for regex <TAB>  <TAB>  <TAB> return result <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return '""%s""' % result",if self . matchKeyword :,175
"def to_dict(cls, arg): <TAB> ""Generates dictionary from string or list of strings"" <TAB> if hasattr(arg, ""splitlines""): <TAB>  <TAB> arg = arg.splitlines() <TAB> if hasattr(arg, ""__reversed__""): <TAB>  <TAB> result = {} <TAB>  <TAB> for a in arg: <TAB>  <TAB>  <TAB> a = a.strip() <TAB>  <TAB>  <TAB> if a: <TAB>  <TAB>  <TAB>  <TAB> key_val = a.split(None, 1) <TAB>  <TAB>  <TAB>  <TAB> key = key_val[0] <MASK> val = key_val[1] <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> val = """" <TAB>  <TAB>  <TAB>  <TAB> result[key] = val <TAB> else: <TAB>  <TAB> result = arg <TAB> return result",if len ( key_val ) > 1 :,182
"def normalize(wtree): <TAB> result = [] <TAB> for part in wtree[1:-1]: <MASK> part = normalize(part) <TAB>  <TAB>  <TAB> if part[0] == """": <TAB>  <TAB>  <TAB>  <TAB> # Move the part content back at current level <TAB>  <TAB>  <TAB>  <TAB> result += part[1:-1] <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif not part: <TAB>  <TAB>  <TAB> # Remove empty strings <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> result.append(part) <TAB> if not result: <TAB>  <TAB> result = [""""] <TAB> return [wtree[0]] + result + [wtree[-1]]","if isinstance ( part , list ) :",147
"def parse_locked_sigs(sigfile_path): <TAB> """"""Return <pn:task>:<hash> dictionary"""""" <TAB> sig_dict = {} <TAB> with open(sigfile_path) as f: <TAB>  <TAB> lines = f.readlines() <TAB>  <TAB> for line in lines: <MASK> taskkey, _, hashval = line.rpartition("":"") <TAB>  <TAB>  <TAB>  <TAB> sig_dict[taskkey.strip()] = hashval.split()[0] <TAB> return sig_dict","if "":"" in line :",115
"def merge_configs(cfg, sec, args_dict): <TAB> assert sec in CONFIG_SECS, ""invalid config section {}"".format(sec) <TAB> sec_dict = getattr(cfg, sec.upper()) <TAB> for k, v in args_dict.items(): <MASK> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if hasattr(sec_dict, k): <TAB>  <TAB>  <TAB>  <TAB> setattr(sec_dict, k, v) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> pass <TAB> return cfg",if v is None :,119
"def _mac_check_locale(locale_string): <TAB> locale = None <TAB> calendar = None <TAB> currency = None <TAB> div = locale_string.strip().split(""@"") <TAB> LOG.debug(""Checking Locale %s"", "" "".join(div)) <TAB> locale = glocale.check_available_translations(div[0]) <TAB> if len(div) > 1: <TAB>  <TAB> div = div[1].split("";"") <TAB>  <TAB> for phrase in div: <TAB>  <TAB>  <TAB> (name, value) = phrase.split(""="") <MASK> calendar = glocale.check_available_translations(value) <TAB>  <TAB>  <TAB> elif name == ""currency"": <TAB>  <TAB>  <TAB>  <TAB> currency = value <TAB> return (locale, calendar, currency)","if name == ""calendar"" :",173
"def hilite(s, ok=True, bold=False): <TAB> """"""Return an highlighted version of 's'."""""" <TAB> if not term_supports_colors(): <TAB>  <TAB> return s <TAB> else: <TAB>  <TAB> attr = [] <TAB>  <TAB> if ok is None:  # no color <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> elif ok: <TAB>  <TAB>  <TAB> attr.append(""32"")  # green <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> attr.append(""31"")  # red <MASK> attr.append(""1"") <TAB>  <TAB> return ""\x1b[%sm%s\x1b[0m"" % ("";"".join(attr), s)",if bold :,151
"def get_hashes(self, ireq): <TAB> key = key_from_ireq(ireq) <TAB> existing_pin = self.existing_pins.get(key) <TAB> if existing_pin and ireq_satisfied_by_existing_pin(ireq, existing_pin): <TAB>  <TAB> if PIP_VERSION[:2] <= (20, 0): <TAB>  <TAB>  <TAB> hashes = existing_pin.options.get(""hashes"", {}) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> hashes = existing_pin.hash_options <TAB>  <TAB> hexdigests = hashes.get(FAVORITE_HASH) <MASK> return {"":"".join([FAVORITE_HASH, hexdigest]) for hexdigest in hexdigests} <TAB> return self.repository.get_hashes(ireq)",if hexdigests :,183
"def get_verbosename( <TAB> self, <TAB> schema: s_schema.Schema, <TAB> *, <TAB> with_parent: bool = False,) -> str: <TAB> vn = super().get_verbosename(schema) <TAB> if with_parent: <TAB>  <TAB> subject = self.get_subject(schema) <MASK> pn = subject.get_verbosename(schema, with_parent=True) <TAB>  <TAB>  <TAB> return f""{vn} of {pn}"" <TAB> return vn",if subject is not None :,118
"def checkForPathDirections(font): <TAB> headline(""Checking for path directions"") <TAB> ok = True <TAB> for layer, g in masterLayersIterator(font): <TAB>  <TAB> firstPath = layer.paths[0] <TAB>  <TAB> if firstPath and firstPath.direction != -1: <TAB>  <TAB>  <TAB> ok = False <MASK> msg = ""Bad path order or direction."" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> msg = ""Bad path direction."" <TAB>  <TAB>  <TAB> log(g.name, layer.name, msg) <TAB> if ok: <TAB>  <TAB> print(""OK"")",if len ( layer . paths ) > 1 :,146
"def test_walk_prune(self): <TAB> # Prune the search. <TAB> all = [] <TAB> for root, dirs, files in self.walk(self.walk_path): <TAB>  <TAB> all.append((root, dirs, files)) <TAB>  <TAB> # Don't descend into SUB1. <MASK> # Note that this also mutates the dirs we appended to all! <TAB>  <TAB>  <TAB> dirs.remove(""SUB1"") <TAB> self.assertEqual(len(all), 2) <TAB> self.assertEqual(all[0], (self.walk_path, [""SUB2""], [""tmp1""])) <TAB> all[1][-1].sort() <TAB> self.assertEqual(all[1], self.sub2_tree)","if ""SUB1"" in dirs :",168
"def _get_params(self, params): <TAB> from . import API_KEY <TAB> if not API_KEY: <TAB>  <TAB> raise APIKeyError <TAB> api_dict = {""api_key"": API_KEY} <TAB> if params: <TAB>  <TAB> params.update(api_dict) <TAB>  <TAB> for key, value in params.items(): <MASK> params[key] = ""true"" if value is True else ""false"" <TAB> else: <TAB>  <TAB> params = api_dict <TAB> return params","if isinstance ( params [ key ] , bool ) :",126
"def _conv_has_norm(module, sync_bn): <TAB> for m in module.modules(): <TAB>  <TAB> if isinstance(m, ConvModule): <MASK> return False <TAB>  <TAB>  <TAB> if sync_bn: <TAB>  <TAB>  <TAB>  <TAB> if not isinstance(m.bn, SyncBatchNorm): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return True",if not m . with_norm :,91
"def quads(self, quad): <TAB> for s, p, o, c in super(Dataset, self).quads(quad): <MASK> yield (s, p, o, None) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield (s, p, o, c.identifier)",if c . identifier == self . default_context :,80
"def handleMessages(self, msgs): <TAB> for msg in msgs: <TAB>  <TAB> if msg.has_key(""method"") and msg.has_key(""params""): <MASK> if msg[""id""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.handleRequest(msg) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.handleNotification(msg) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.handleNotification(msg) <TAB>  <TAB> elif msg.has_key(""result"") and msg.has_key(""error""): <TAB>  <TAB>  <TAB> self.handleResponse(msg) <TAB>  <TAB> else:  # unknown object <TAB>  <TAB>  <TAB> self.sendResponse(None, InvalidJSONMessage()) <TAB>  <TAB>  <TAB> self.close()","if msg . has_key ( ""id"" ) :",175
"def decode(self, probabilities) -> Prediction: <TAB> last_char = self.blank <TAB> chars = np.argmax(probabilities, axis=1) <TAB> sentence = [] <TAB> for idx, c in enumerate(chars): <TAB>  <TAB> if c != self.blank: <MASK> sentence.append((c, idx, idx + 1)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> _, start, end = sentence[-1] <TAB>  <TAB>  <TAB>  <TAB> del sentence[-1] <TAB>  <TAB>  <TAB>  <TAB> sentence.append((c, start, idx + 1)) <TAB>  <TAB> last_char = c <TAB> return self.find_alternatives(probabilities, sentence, self.threshold)",if c != last_char :,160
"def redrawRunning(self): <TAB> """"""Forces the running frames to be redrawn with current values"""""" <TAB> # pylint: disable=broad-except <TAB> try: <TAB>  <TAB> items = self.findItems(""Running"", QtCore.Qt.MatchExactly, STATUS_COLUMN) <MASK> self.dataChanged( <TAB>  <TAB>  <TAB>  <TAB> self.indexFromItem(items[0], RUNTIME_COLUMN), <TAB>  <TAB>  <TAB>  <TAB> self.indexFromItem(items[-1], LASTLINE_COLUMN), <TAB>  <TAB>  <TAB> ) <TAB> except Exception as e: <TAB>  <TAB> list(map(logger.warning, cuegui.Utils.exceptionOutput(e)))",if items :,150
"def get_coords_of_dots(self): <TAB> """"""Yiels the cordinates of every dot char in the world."""""" <TAB> for y, line in enumerate(self.map): <MASK> continue <TAB>  <TAB> for x, char in enumerate(line): <TAB>  <TAB>  <TAB> if char.isDot(): <TAB>  <TAB>  <TAB>  <TAB> yield Pos(x, y)","if line and line [ 0 ] == ""%"" :",93
def consume(self): <TAB> try: <MASK> # \n <TAB>  <TAB>  <TAB> self.line += 1 <TAB>  <TAB>  <TAB> self.charPositionInLine = 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.charPositionInLine += 1 <TAB>  <TAB> self.p += 1 <TAB> except IndexError: <TAB>  <TAB> # happend when we reached EOF and self.data[self.p] fails <TAB>  <TAB> # just do nothing <TAB>  <TAB> pass,if self . data [ self . p ] == 10 :,111
"def maybe_schedule(s, relative=False, app=None): <TAB> """"""Return schedule from number, timedelta, or actual schedule."""""" <TAB> if s is not None: <TAB>  <TAB> if isinstance(s, numbers.Number): <TAB>  <TAB>  <TAB> s = timedelta(seconds=s) <MASK> return schedule(s, relative, app=app) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> s.app = app <TAB> return s","if isinstance ( s , timedelta ) :",105
"def test(self, text, s, e): <TAB> ret = {} <TAB> if self.lastMatch: <TAB>  <TAB> n1 = len(self.lastMatch) <TAB>  <TAB> n2 = e - s <MASK> if n2 != n1 + 1: <TAB>  <TAB>  <TAB>  <TAB> ret[s] = ""expected %d, %d found"" % (n1 + 1, n2) <TAB> self.lastMatch = text[s:e] <TAB> return ret",if n2 > n1 :,116
"def _FillMetadata(self, vaddr, metadata): <TAB> address_space = self.session.GetParameter(""default_address_space"") <TAB> for type, _, addr in address_space.describe_vtop(vaddr): <MASK> metadata[""type""] = ""Valid"" <TAB>  <TAB>  <TAB> return self.profile._MMPTE(addr, vm=self.physical_address_space)","if type == ""pte"" and addr :",102
"def quadruples_gen(s): <TAB> t = [] <TAB> for c in s: <TAB>  <TAB> res = table_a2b_hqx[ord(c)] <MASK> continue <TAB>  <TAB> elif res == FAIL: <TAB>  <TAB>  <TAB> raise Error(""Illegal character"") <TAB>  <TAB> elif res == DONE: <TAB>  <TAB>  <TAB> yield t <TAB>  <TAB>  <TAB> raise Done <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> t.append(res) <TAB>  <TAB> if len(t) == 4: <TAB>  <TAB>  <TAB> yield t <TAB>  <TAB>  <TAB> t = [] <TAB> yield t",if res == SKIP :,135
"def renameGlyphOrderFile(filename, newNames, dryRun=False, print=print): <TAB> lines = [] <TAB> didRename = False <TAB> for line in readLines(filename): <TAB>  <TAB> line = line.lstrip() <MASK> newName = newNames.get(line) <TAB>  <TAB>  <TAB> if newName is not None: <TAB>  <TAB>  <TAB>  <TAB> didRename = True <TAB>  <TAB>  <TAB>  <TAB> line = newName <TAB>  <TAB> lines.append(line) <TAB> if didRename: <TAB>  <TAB> print(""Writing"", filename) <TAB>  <TAB> if not dryRun: <TAB>  <TAB>  <TAB> with open(filename, ""w"") as f: <TAB>  <TAB>  <TAB>  <TAB> f.write(""\n"".join(lines))","if len ( line ) > 0 and line [ 0 ] != ""#"" :",173
"def getfnl(startdir): <TAB> filenamelist = [] <TAB> for root, dirs, files in os.walk(startdir): <TAB>  <TAB> for fn in files: <TAB>  <TAB>  <TAB> fullfn = os.path.join(root, fn) <TAB>  <TAB>  <TAB> if fn.endswith("".xml""): <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> doc = ET.parse(fullfn) <TAB>  <TAB>  <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise Exception(""Oops, bad XML in '%s': %s"" % (fullfn, e)) <TAB>  <TAB>  <TAB>  <TAB> rootelement = doc.getroot() <TAB>  <TAB>  <TAB>  <TAB> # here we check if this xml file actually is a tool conf xml! <MASK> filenamelist.append(fullfn) <TAB> return filenamelist","if rootelement . tag == ""tool"" :",191
"def find_nonterminal_transitions(self, C): <TAB> trans = [] <TAB> for stateno, state in enumerate(C): <TAB>  <TAB> for p in state: <TAB>  <TAB>  <TAB> if p.lr_index < p.len - 1: <TAB>  <TAB>  <TAB>  <TAB> t = (stateno, p.prod[p.lr_index + 1]) <TAB>  <TAB>  <TAB>  <TAB> if t[1] in self.grammar.Nonterminals: <MASK> trans.append(t) <TAB> return trans",if t not in trans :,123
"def validate_project_urls(metadata): <TAB> probs = [] <TAB> for prurl in metadata.get(""project_urls"", []): <TAB>  <TAB> name, url = prurl.split("","", 1) <TAB>  <TAB> url = url.lstrip() <TAB>  <TAB> if not name: <TAB>  <TAB>  <TAB> probs.append(""No name for project URL {!r}"".format(url)) <MASK> probs.append(""Project URL name {!r} longer than 32 characters"".format(name)) <TAB>  <TAB> probs.extend(validate_url(url)) <TAB> return probs",elif len ( name ) > 32 :,131
"def check_helper(self, fn, node, s): <TAB> cct = self.CCTraverser(controller=self) <TAB> for n in 1, 2: <MASK> g.trace(""===== PASS"", n) <TAB>  <TAB> # Init this pass. <TAB>  <TAB> self.file_name = fn <TAB>  <TAB> self.indent = 0 <TAB>  <TAB> self.pass_n = n <TAB>  <TAB> cct.visit(node) <TAB> self.end_file()","if self . test_kind is ""test"" :",120
"def initialize(self): <TAB> try: <MASK> print(""connect again"") <TAB>  <TAB> self._mqttc = mqtt.Client(None) <TAB>  <TAB> self._mqttc.on_message = self.mqtt_on_message <TAB>  <TAB> self._mqttc.on_connect = self.mqtt_on_connect <TAB>  <TAB> self._mqttc.on_subscribe = self.mqtt_on_subscribe <TAB>  <TAB> self._mqttc.on_publish = self.mqtt_on_publish <TAB>  <TAB> self._mqttc.on_disconnect = self.on_disconnect <TAB>  <TAB> # Enable this line if you are doing the snip code, off stress <TAB>  <TAB> # self._mqttc.loop_start() <TAB> except TypeError: <TAB>  <TAB> print(""Connect to mqtter error"") <TAB>  <TAB> return",if DEBUG_ON :,188
"def __init__(self, version, plugins): <TAB> self.version = version <TAB> self.brand = ""vanilla"" <TAB> self.plugins = [] <TAB> if plugins: <TAB>  <TAB> parts = plugins.split("":"", 1) <TAB>  <TAB> self.brand = parts[0].strip() <MASK> self.plugins = [s.strip() for s in parts[1].split("";"")]",if len ( parts ) == 2 :,98
def __iter__(self): <TAB> while True: <TAB>  <TAB> keys = self.ns_range.make_datastore_query().Get(limit=self._batch_size) <MASK> break <TAB>  <TAB> for key in keys: <TAB>  <TAB>  <TAB> namespace = metadata.Namespace.key_to_namespace(key) <TAB>  <TAB>  <TAB> self.ns_range = self.ns_range.with_start_after(namespace) <TAB>  <TAB>  <TAB> yield namespace,if not keys :,107
"def run(self): <TAB> if self.check(): <TAB>  <TAB> print_success(""Target appears to be vulnerable."") <TAB>  <TAB> path = self.valid_resource.format(self.filename) <TAB>  <TAB> response = self.http_request( <TAB>  <TAB>  <TAB> method=""GET"", <TAB>  <TAB>  <TAB> path=path, <TAB>  <TAB> ) <MASK> print_error(""Error with reading response"") <TAB>  <TAB>  <TAB> return <TAB>  <TAB> if response.text: <TAB>  <TAB>  <TAB> print_status(""Reading file: {}"".format(self.filename)) <TAB>  <TAB>  <TAB> print_info(response.text) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print_error(""Exploit failed - empty response"") <TAB> else: <TAB>  <TAB> print_error(""Exploit failed - target seems to be not vulnerable"")",if response is None :,180
"def pack_items(self, parent, items): <TAB> if self._size > 0: <TAB>  <TAB> self.ipr = self._size <TAB> else: <TAB>  <TAB> self.ipr = int(math.sqrt(max(1, len(items) - 1)) + 1) <MASK> self.ipr = 3  # Special (common) cases <TAB>  <TAB> if len(items) == 8: <TAB>  <TAB>  <TAB> self.ipr = 4  # Special (common) cases <TAB> x, y = 0, 0 <TAB> for item in items: <TAB>  <TAB> parent.attach(item.widget, x, y, 1, 1) <TAB>  <TAB> x += 1 <TAB>  <TAB> if x >= self.ipr: <TAB>  <TAB>  <TAB> x = 0 <TAB>  <TAB>  <TAB> y += 1",if len ( items ) == 6 :,186
"def __call__(self, response, obj, headers): <TAB> for message in obj: <TAB>  <TAB> if message.message_text in [None, """", b""""]: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> content = message.message_text <MASK> content = decrypt_queue_message( <TAB>  <TAB>  <TAB>  <TAB> content, <TAB>  <TAB>  <TAB>  <TAB> response, <TAB>  <TAB>  <TAB>  <TAB> self.require_encryption, <TAB>  <TAB>  <TAB>  <TAB> self.key_encryption_key, <TAB>  <TAB>  <TAB>  <TAB> self.resolver, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> message.message_text = self.decode(content, response) <TAB> return obj",if ( self . key_encryption_key is not None ) or ( self . resolver is not None ) :,162
"def make_arg(arg): <TAB> if empty: <TAB>  <TAB> return np.empty((1,) * max(1, arg.ndim), dtype=arg.dtype) <TAB> else: <MASK> arg = arg.op.data <TAB>  <TAB> return arg[(0,) * max(1, arg.ndim)]","if hasattr ( arg , ""op"" ) and hasattr ( arg . op , ""data"" ) :",91
"def walk_node(node, **kwargs): <TAB> negated = kwargs[""negated""] <TAB> if node.negated: <TAB>  <TAB> negated = not negated <TAB> for child in node.children: <TAB>  <TAB> new_kwargs = kwargs.copy() <TAB>  <TAB> new_kwargs[""negated""] = negated <TAB>  <TAB> if not getattr(child, ""children"", []): <TAB>  <TAB>  <TAB> leaf_callback(child, **new_kwargs) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_parent = trunk_callback(child, **new_kwargs) <MASK> new_kwargs[""new_parent""] = new_parent <TAB>  <TAB>  <TAB> walk_node(child, **new_kwargs)",if new_parent :,158
"def _makeDict(instructionList): <TAB> opcodeDict = {} <TAB> mnemonicDict = {} <TAB> for op, mnemonic, argBits, name, pops, pushes in instructionList: <TAB>  <TAB> assert _mnemonicPat.match(mnemonic) <TAB>  <TAB> mnemonicDict[mnemonic] = op, argBits, name <MASK> argoffset = op <TAB>  <TAB>  <TAB> for i in range(1 << argBits): <TAB>  <TAB>  <TAB>  <TAB> opcodeDict[op + i] = mnemonic, argBits, argoffset, name <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> opcodeDict[op] = mnemonic, 0, 0, name <TAB> return opcodeDict, mnemonicDict",if argBits :,168
"def _validate_sid_uniqueness(self): <TAB> sids = [] <TAB> for statement in self._statements: <MASK> statementId = statement[""Sid""] <TAB>  <TAB>  <TAB> if statementId: <TAB>  <TAB>  <TAB>  <TAB> assert statementId not in sids <TAB>  <TAB>  <TAB>  <TAB> sids.append(statementId)","if ""Sid"" in statement :",83
"def dumpConnections(node): <TAB> ""Helper function: dump connections to node"" <TAB> for intf in node.intfList(): <TAB>  <TAB> output("" %s:"" % intf) <MASK> intfs = [intf.link.intf1, intf.link.intf2] <TAB>  <TAB>  <TAB> intfs.remove(intf) <TAB>  <TAB>  <TAB> output(intfs[0]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> output("" "")",if intf . link :,113
"def _get_warnings(log_content, return_data): <TAB> warnings = {} <TAB> missing_files = find_missing_files(log_content) <TAB> if missing_files: <TAB>  <TAB> warnings[""missing_files""] = missing_files <TAB> wrong_engine = find_wrong_renderer_warning(log_content) <TAB> if wrong_engine: <TAB>  <TAB> warnings[""wrong_engine""] = wrong_engine <TAB> if warnings: <TAB>  <TAB> if return_data.get(""warnings""): <TAB>  <TAB>  <TAB> return_warnings = return_data.get(""warnings"") <MASK> return_data[""warnings""][""missing_files""].extend( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> warnings[""missing_files""] <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return_data[""warnings""] = warnings","if return_warnings . get ( ""missing_files"" ) :",194
def add_hole(face): <TAB> used = set()  # type: Set['Face'] <TAB> stack = [hedge.twin for hedge in face.inners] <TAB> while stack: <TAB>  <TAB> next_face = stack.pop().face <MASK> continue <TAB>  <TAB> if id(face) == id(next_face): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> used.add(next_face) <TAB>  <TAB> for loop_hedge in next_face.outer.loop_hedges: <TAB>  <TAB>  <TAB> stack.append(loop_hedge.twin) <TAB>  <TAB> if next_face.inners: <TAB>  <TAB>  <TAB> del_hole(next_face),if next_face in used :,161
"def __init__(self, content=b"""", mimetype=None, code=200): <TAB> self._iter = None <TAB> self._is_str_iter = True <TAB> self.content = content <TAB> self.headers = HeaderDict() <TAB> self.cookies = SimpleCookie() <TAB> self.status_code = code <TAB> defaults = self.defaults._current_obj() <TAB> if not mimetype: <TAB>  <TAB> mimetype = defaults.get(""content_type"", ""text/html"") <TAB>  <TAB> charset = defaults.get(""charset"") <MASK> mimetype = ""%s; charset=%s"" % (mimetype, charset) <TAB> self.headers.update(defaults.get(""headers"", {})) <TAB> self.headers[""Content-Type""] = mimetype <TAB> self.errors = defaults.get(""errors"", ""strict"")",if charset :,185
"def _store_parsers( <TAB> parser, parser_keys, parser_values, sub_parser_keys, sub_parser_values): <TAB> for s in parser.subparsers.values(): <TAB>  <TAB> parser_keys.append(_get_parser_name(s)) <TAB>  <TAB> parser_values.append(s) <MASK> for c in s.choices.values(): <TAB>  <TAB>  <TAB>  <TAB> sub_parser_keys.append(_get_parser_name(c)) <TAB>  <TAB>  <TAB>  <TAB> sub_parser_values.append(c) <TAB>  <TAB>  <TAB>  <TAB> _store_parsers( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> c, parser_keys, parser_values, sub_parser_keys, sub_parser_values <TAB>  <TAB>  <TAB>  <TAB> )",if _is_group ( s ) :,174
"def get(self): <TAB> """"""Get next event from queue."""""" <TAB> inputHookFunc = c_int.from_address(self.inputHookPtr).value <TAB> Cevent = INPUT_RECORD() <TAB> count = c_int(0) <TAB> while 1: <TAB>  <TAB> if inputHookFunc: <TAB>  <TAB>  <TAB> call_function(inputHookFunc, ()) <TAB>  <TAB> status = self.ReadConsoleInputW(self.hin, byref(Cevent), 1, byref(count)) <MASK> e = event(self, Cevent) <TAB>  <TAB>  <TAB> log_sock(ensure_unicode(e.keyinfo), ""keypress"") <TAB>  <TAB>  <TAB> return e",if status and count . value == 1 :,159
"def GetItemChildren(self, item=None, recursively=False): <TAB> """"""Return the children of item as a list."""""" <MASK> item = self.GetRootItem() <TAB>  <TAB> if not item: <TAB>  <TAB>  <TAB> return [] <TAB> children = [] <TAB> child, cookie = self.GetFirstChild(item) <TAB> while child: <TAB>  <TAB> children.append(child) <TAB>  <TAB> if recursively: <TAB>  <TAB>  <TAB> children.extend(self.GetItemChildren(child, True)) <TAB>  <TAB> child, cookie = self.GetNextChild(item, cookie) <TAB> return children",if not item :,135
"def _merge_inheritable_dicts_(cls, models): <TAB> super(AuthModel, cls)._merge_inheritable_dicts_(models) <TAB> for attr in cls._additional_inheritable_dict_attrs_: <TAB>  <TAB> if isinstance(attr, tuple): <TAB>  <TAB>  <TAB> attr_name = attr[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> attr_name = attr <TAB>  <TAB> attrs = {} <TAB>  <TAB> for model in models: <MASK> continue <TAB>  <TAB>  <TAB> superattrs = getattr(model, attr_name) <TAB>  <TAB>  <TAB> for k, v in superattrs.items(): <TAB>  <TAB>  <TAB>  <TAB> attrs[k] = v <TAB>  <TAB> for k, v in getattr(cls, attr_name).items(): <TAB>  <TAB>  <TAB> attrs[k] = v <TAB>  <TAB> setattr(cls, attr_name, attrs)","if not issubclass ( model , AuthModel ) :",198
"def _initialize_weights(self) -> None: <TAB> for m in self.modules(): <TAB>  <TAB> if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear): <TAB>  <TAB>  <TAB> import scipy.stats as stats <TAB>  <TAB>  <TAB> X = stats.truncnorm(-2, 2, scale=0.01) <TAB>  <TAB>  <TAB> values = torch.as_tensor(X.rvs(m.weight.numel()), dtype=m.weight.dtype) <TAB>  <TAB>  <TAB> values = values.view(m.weight.size()) <TAB>  <TAB>  <TAB> with torch.no_grad(): <TAB>  <TAB>  <TAB>  <TAB> m.weight.copy_(values) <MASK> nn.init.constant_(m.weight, 1) <TAB>  <TAB>  <TAB> nn.init.constant_(m.bias, 0)","elif isinstance ( m , nn . BatchNorm2d ) :",191
"def _value_to_so_vector(value, ids=None): <TAB> if not isinstance(value, collections.Sequence) or _is_str(value): <TAB>  <TAB> raise TypeError( <TAB>  <TAB>  <TAB> ""Expected list/sequence of SerializableObjects;"" <TAB>  <TAB>  <TAB> "" found type '{}'"".format(type(value)) <TAB>  <TAB> ) <TAB> av = AnyVector() <TAB> for e in value: <MASK> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""Expected list/sequence of SerializableObjects;"" <TAB>  <TAB>  <TAB>  <TAB> "" found element of type '{}'"".format(type(e)) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> av.append(e) <TAB> return PyAny(av)","if not isinstance ( e , SerializableObject ) :",163
"def await_reservations(self, sc, status={}, timeout=600): <TAB> """"""Block until all reservations are received."""""" <TAB> timespent = 0 <TAB> while not self.reservations.done(): <TAB>  <TAB> logger.info( <TAB>  <TAB>  <TAB> ""waiting for {0} reservations"".format(self.reservations.remaining()) <TAB>  <TAB> ) <TAB>  <TAB> # check status flags for any errors <MASK> sc.cancelAllJobs() <TAB>  <TAB>  <TAB> sc.stop() <TAB>  <TAB>  <TAB> sys.exit(1) <TAB>  <TAB> time.sleep(1) <TAB>  <TAB> timespent += 1 <TAB>  <TAB> if timespent > timeout: <TAB>  <TAB>  <TAB> raise Exception(""timed out waiting for reservations to complete"") <TAB> logger.info(""all reservations completed"") <TAB> return self.reservations.get()","if ""error"" in status :",199
"def generate_samples(self, data_dir, tmp_dir, unused_dataset_split): <TAB> counter = 0 <TAB> done = False <TAB> while not done: <TAB>  <TAB> for frame_number, frame in enumerate(self.generate_stochastic_shape_instance()): <MASK> done = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> yield {""frame"": frame, ""frame_number"": [frame_number]} <TAB>  <TAB>  <TAB> counter += 1",if counter >= self . total_number_of_frames :,118
"def dtype_to_ctype(dtype, with_fp_tex_hack=False): <TAB> if dtype is None: <TAB>  <TAB> raise ValueError(""dtype may not be None"") <TAB> dtype = np.dtype(dtype) <TAB> if with_fp_tex_hack: <TAB>  <TAB> if dtype == np.float32: <TAB>  <TAB>  <TAB> return ""fp_tex_float"" <MASK> return ""fp_tex_double"" <TAB>  <TAB> elif dtype == np.complex64: <TAB>  <TAB>  <TAB> return ""fp_tex_cfloat"" <TAB>  <TAB> elif dtype == np.complex128: <TAB>  <TAB>  <TAB> return ""fp_tex_cdouble"" <TAB> return base_dtype_to_ctype(dtype)",elif dtype == np . float64 :,167
def __len__(self): <MASK> _fill_lock.acquire() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if self.data is None: <TAB>  <TAB>  <TAB>  <TAB> self._fill() <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> _fill_lock.release() <TAB> return len(self.data),if self . data is None :,76
def generate(self): <TAB> sample_n = 0 <TAB> # in samples <TAB> cycle_length = self.sample_rate / float(self.freq) <TAB> midpoint = cycle_length * self.duty_cycle <TAB> ascend_length = midpoint <TAB> descend_length = cycle_length - ascend_length <TAB> while True: <TAB>  <TAB> cycle_position = sample_n % cycle_length <MASK> yield (2 * cycle_position / ascend_length) - 1.0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield 1.0 - (2 * (cycle_position - midpoint) / descend_length) <TAB>  <TAB> sample_n += 1,if cycle_position < midpoint :,158
"def recurse(node): <TAB> result = []  # collections.deque() <TAB> if node is not None: <MASK> result.extend(recurse(node.leftChild)) <TAB>  <TAB>  <TAB> # This currently requires timespans not elements, and list payloads... <TAB>  <TAB>  <TAB> # TODO: Fix/disambiguate. <TAB>  <TAB>  <TAB> for el in node.payload: <TAB>  <TAB>  <TAB>  <TAB> if offset < self.elementEndTime(el, node): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> result.append(el) <TAB>  <TAB>  <TAB> result.extend(recurse(node.rightChild)) <TAB>  <TAB> elif offset <= node.position: <TAB>  <TAB>  <TAB> result.extend(recurse(node.leftChild)) <TAB> return result",if node . position < offset < node . endTimeHigh :,171
"def add_aggregates(self, queryset, display_fields): <TAB> agg_funcs = {""Avg"": Avg, ""Min"": Min, ""Max"": Max, ""Count"": Count, ""Sum"": Sum} <TAB> for display_field in display_fields: <MASK> func = agg_funcs[display_field.aggregate] <TAB>  <TAB>  <TAB> full_name = display_field.path + display_field.field <TAB>  <TAB>  <TAB> queryset = queryset.annotate(func(full_name)) <TAB> return queryset",if display_field . aggregate :,123
"def __init__( <TAB> self, setting, newValue, settings=None, autoResolve=False, ignoreOld=False): <TAB> ActionConflict.__init__(self, setting, settings, autoResolve) <TAB> self.Name = _(""button"") <TAB> if not newValue: <TAB>  <TAB> return <TAB> newValue = newValue.lower() <TAB> oldValue = self.Setting.Value.lower() <TAB> badValues = [""disabled"", ""none""] <TAB> if not ignoreOld: <TAB>  <TAB> badValues.append(oldValue) <TAB> if newValue in badValues: <TAB>  <TAB> return <TAB> for s in self.Settings: <TAB>  <TAB> if s is setting: <TAB>  <TAB>  <TAB> continue <MASK> if s.Value.lower() == newValue: <TAB>  <TAB>  <TAB>  <TAB> self.Conflicts.append(s)","if s . Type == ""Button"" :",191
"def inner(**kwargs): <TAB> coro = func(**kwargs) <TAB> if coro is not None: <TAB>  <TAB> task = asyncio.ensure_future(coro, loop=_loop) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> _loop.run_until_complete(task) <TAB>  <TAB> except BaseException: <TAB>  <TAB>  <TAB> # run_until_complete doesn't get the result from exceptions <TAB>  <TAB>  <TAB> # that are not subclasses of `Exception`. Consume all <TAB>  <TAB>  <TAB> # exceptions to prevent asyncio's warning from logging. <MASK> task.exception() <TAB>  <TAB>  <TAB> raise",if task . done ( ) and not task . cancelled ( ) :,140
"def prune(model, amount=0.3): <TAB> # Prune model to requested global sparsity <TAB> import torch.nn.utils.prune as prune <TAB> print(""Pruning model... "", end="""") <TAB> for name, m in model.named_modules(): <MASK> prune.l1_unstructured(m, name=""weight"", amount=amount)  # prune <TAB>  <TAB>  <TAB> prune.remove(m, ""weight"")  # make permanent <TAB> print("" %.3g global sparsity"" % sparsity(model))","if isinstance ( m , nn . Conv2d ) :",130
"def robot_fetch(path): <TAB> """"""Check if robots can fetch a file."""""" <TAB> for rule in kw[""robots_exclusions""]: <TAB>  <TAB> robot = robotparser.RobotFileParser() <TAB>  <TAB> robot.parse([""User-Agent: *"", ""Disallow: {0}"".format(rule)]) <MASK> if not robot.can_fetch(""*"", ""/"" + path): <TAB>  <TAB>  <TAB>  <TAB> return False  # not robot food <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if not robot.can_fetch(""*"", (""/"" + path).encode(""utf-8"")): <TAB>  <TAB>  <TAB>  <TAB> return False  # not robot food <TAB> return True",if sys . version_info [ 0 ] == 3 :,158
"def check_not_vislist_intent(self): <TAB> syntaxMsg = ( <TAB>  <TAB> ""The intent that you specified corresponds to more than one visualization. "" <TAB>  <TAB> ""Please replace the Vis constructor with VisList to generate a list of visualizations. "" <TAB>  <TAB> ""For more information, see: https://lux-api.readthedocs.io/en/latest/source/guide/vis.html#working-with-collections-of-visualization-with-vislist"" <TAB> ) <TAB> for i in range(len(self._intent)): <TAB>  <TAB> clause = self._intent[i] <TAB>  <TAB> if isinstance(clause, str): <MASK> raise TypeError(syntaxMsg) <TAB>  <TAB> if isinstance(clause, list): <TAB>  <TAB>  <TAB> raise TypeError(syntaxMsg)","if ""|"" in clause or ""?"" in clause :",186
"def __call__(self, data): <TAB> if self._apply_shift: <TAB>  <TAB> if not hasattr(data, ""coords""): <TAB>  <TAB>  <TAB> raise Exception(""should quantize first using GridSampling3D"") <MASK> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> ""The pos are expected to be coordinates, so torch.IntTensor"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> data.coords[:, :3] += (torch.rand(3) * 100).type_as(data.coords) <TAB> return data","if not isinstance ( data . coords , torch . IntTensor ) :",127
"def get_config(cls, config): <TAB> out = {} <TAB> with git_config.GitConfigParser(config, read_only=True) as config: <TAB>  <TAB> section = 'gitrepo ""{}""'.format(cls.name) <MASK> for option in cls.config_options: <TAB>  <TAB>  <TAB>  <TAB> if config.has_option(section, option): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> out[option] = config.get(section, option) <TAB> return out",if config . has_section ( section ) :,116
"def checkComments(self, line): <TAB> """"""Check to see if the line/lines is a comment."""""" <TAB> if not self.inCommentBlock: <MASK> if ""]"" not in line: <TAB>  <TAB>  <TAB>  <TAB> self.inCommentBlock = True <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return ""Nextline""  # need to move on to the nextline after getting out of comment <TAB> else: <TAB>  <TAB> if ""]"" in line: <TAB>  <TAB>  <TAB> if line.rfind(""["") > line.rfind(""]""): <TAB>  <TAB>  <TAB>  <TAB> pass  # a comment block is closed but another is open. <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.inCommentBlock = False <TAB>  <TAB>  <TAB>  <TAB> return ""Nextline""  # need to move on to the nextline after getting out of comment <TAB> return """"","if ""["" in line :",188
"def done(res): <TAB> if isinstance(res, failure.Failure): <TAB>  <TAB> res.trap(expected_failure) <MASK> self.failUnless( <TAB>  <TAB>  <TAB>  <TAB> substring in str(res), <TAB>  <TAB>  <TAB>  <TAB> ""%s: substring '%s' not in '%s'"" % (which, substring, str(res)), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> # return the Failure for further analysis, but in a form that <TAB>  <TAB> # doesn't make the Deferred chain think that we failed. <TAB>  <TAB> return [res] <TAB> else: <TAB>  <TAB> self.fail( <TAB>  <TAB>  <TAB> ""%s was supposed to raise %s, not get '%s'"" % (which, expected_failure, res) <TAB>  <TAB> )",if substring :,169
"def best_version_match(vers_num, item_dict): <TAB> """"""Attempts to find the best match in item_dict for vers_num"""""" <TAB> vers_tuple = vers_num.split(""."") <TAB> precision = 1 <TAB> while precision <= len(vers_tuple): <TAB>  <TAB> test_vers = ""."".join(vers_tuple[0:precision]) <TAB>  <TAB> match_names = [] <TAB>  <TAB> for item in item_dict.keys(): <TAB>  <TAB>  <TAB> for item_version in item_dict[item]: <TAB>  <TAB>  <TAB>  <TAB> if item_version.startswith(test_vers) and item not in match_names: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> match_names.append(item) <MASK> return match_names[0] <TAB>  <TAB> precision = precision + 1 <TAB> return None",if len ( match_names ) == 1 :,189
"def validate_work_dir(s): <TAB> dirs = s.split("":"") <TAB> if len(dirs) != 2: <TAB>  <TAB> print( <TAB>  <TAB>  <TAB> ""work-dir %s is not in format local_abs_dir:container_abs_dir"" % s, <TAB>  <TAB>  <TAB> file=sys.stderr, <TAB>  <TAB> ) <TAB>  <TAB> sys.exit(1) <TAB> for d in dirs: <MASK> print(""%s is not an absolute path"" % d, file=sys.stderr) <TAB>  <TAB>  <TAB> sys.exit(1)",if not os . path . isabs ( d ) :,137
"def unknown_endtag(self, tag): <TAB> if not tag in self.acceptable_elements: <TAB>  <TAB> if tag in self.unacceptable_elements_with_end_tag: <TAB>  <TAB>  <TAB> self.unacceptablestack -= 1 <MASK> if tag == ""math"" and self.mathmlOK: <TAB>  <TAB>  <TAB>  <TAB> self.mathmlOK -= 1 <TAB>  <TAB> elif self.svgOK and tag in self.svg_elements: <TAB>  <TAB>  <TAB> tag = self.svg_elem_map.get(tag, tag) <TAB>  <TAB>  <TAB> if tag == ""svg"" and self.svgOK: <TAB>  <TAB>  <TAB>  <TAB> self.svgOK -= 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return <TAB> _BaseHTMLProcessor.unknown_endtag(self, tag)",if self . mathmlOK and tag in self . mathml_elements :,189
"def __init__(self, message, response=None): <TAB> # Unfortunately the store doesn't give us a consistent error response, <TAB> # so we'll check the ones of which we're aware. <TAB> with contextlib.suppress(AttributeError, JSONDecodeError): <TAB>  <TAB> response_json = response.json() <TAB>  <TAB> extra_error_message = """" <MASK> extra_error_message = response_json[""error_message""] <TAB>  <TAB> elif ""message"" in response_json: <TAB>  <TAB>  <TAB> extra_error_message = response_json[""message""] <TAB>  <TAB> if extra_error_message: <TAB>  <TAB>  <TAB> message += "": {}"".format(extra_error_message) <TAB> super().__init__(response=response, message=message)","if ""error_message"" in response_json :",175
"def compile_output( <TAB> ir_set: irast.Set, *, ctx: context.CompilerContextLevel) -> pgast.OutputVar: <TAB> with ctx.new() as newctx: <TAB>  <TAB> if newctx.expr_exposed is None: <TAB>  <TAB>  <TAB> newctx.expr_exposed = True <TAB>  <TAB> dispatch.visit(ir_set, ctx=newctx) <TAB>  <TAB> path_id = ir_set.path_id <MASK> val = pathctx.get_path_serialized_output(ctx.rel, path_id, env=ctx.env) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> val = pathctx.get_path_value_output(ctx.rel, path_id, env=ctx.env) <TAB> return val",if output . in_serialization_ctx ( ctx ) and newctx . stmt is newctx . toplevel_stmt :,198
"def set_python_instance_state(self, instance, state): <TAB> if hasattr(instance, ""__setstate__""): <TAB>  <TAB> instance.__setstate__(state) <TAB> else: <TAB>  <TAB> slotstate = {} <MASK> state, slotstate = state <TAB>  <TAB> if hasattr(instance, ""__dict__""): <TAB>  <TAB>  <TAB> instance.__dict__.update(state) <TAB>  <TAB> elif state: <TAB>  <TAB>  <TAB> slotstate.update(state) <TAB>  <TAB> for key, value in slotstate.items(): <TAB>  <TAB>  <TAB> setattr(object, key, value)","if isinstance ( state , tuple ) and len ( state ) == 2 :",137
"def set_etc_timezone( <TAB> tz, tz_file=None, tz_conf=""/etc/timezone"", tz_local=""/etc/localtime""): <TAB> util.write_file(tz_conf, str(tz).rstrip() + ""\n"") <TAB> # This ensures that the correct tz will be used for the system <TAB> if tz_local and tz_file: <TAB>  <TAB> # use a symlink if there exists a symlink or tz_local is not present <TAB>  <TAB> islink = os.path.islink(tz_local) <TAB>  <TAB> if islink or not os.path.exists(tz_local): <MASK> util.del_file(tz_local) <TAB>  <TAB>  <TAB> os.symlink(tz_file, tz_local) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> util.copy(tz_file, tz_local) <TAB> return",if islink :,196
"def scan_resource_conf(self, conf): <TAB> if ""rotation_period"" in conf.keys(): <TAB>  <TAB> time = force_int(conf[""rotation_period""][0][:-1]) <MASK> return CheckResult.PASSED <TAB> return CheckResult.FAILED",if time and ONE_DAY <= time <= NINETY_DAYS :,81
"def _get_available_commands(stdout): <TAB> commands_listing = False <TAB> for line in stdout.split(""\n""): <TAB>  <TAB> if line.startswith(""where <command> is one of:""): <TAB>  <TAB>  <TAB> commands_listing = True <TAB>  <TAB> elif commands_listing: <MASK> break <TAB>  <TAB>  <TAB> for command in line.split("", ""): <TAB>  <TAB>  <TAB>  <TAB> stripped = command.strip() <TAB>  <TAB>  <TAB>  <TAB> if stripped: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield stripped",if not line :,115
"def acquire_read_lock(self, wait=True): <TAB> """"""Acquire the 'read' lock."""""" <TAB> self.condition.acquire() <TAB> try: <TAB>  <TAB> # see if a synchronous operation is waiting to start <TAB>  <TAB> # or is already running, in which case we wait (or just <TAB>  <TAB> # give up and return) <TAB>  <TAB> if wait: <TAB>  <TAB>  <TAB> while self.current_sync_operation is not None: <TAB>  <TAB>  <TAB>  <TAB> self.condition.wait() <TAB>  <TAB> else: <MASK> return False <TAB>  <TAB> self.async_ += 1 <TAB>  <TAB> log.debug(""%s acquired read lock"", self) <TAB> finally: <TAB>  <TAB> self.condition.release() <TAB> if not wait: <TAB>  <TAB> return True",if self . current_sync_operation is not None :,186
"def _linux_get_ifaces(self): <TAB> ifaces = [] <TAB> procfs_path = ""/proc/net/dev"" <TAB> try: <TAB>  <TAB> with open(procfs_path, ""r"") as f: <TAB>  <TAB>  <TAB> lines = f.read().split(""\n"") <TAB>  <TAB>  <TAB> for line in lines: <TAB>  <TAB>  <TAB>  <TAB> # Only lines with colons contain interface names <TAB>  <TAB>  <TAB>  <TAB> if "":"" in line: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> fields = line.split("":"") <MASK> except IOError as e: <TAB>  <TAB> self.logger.error( <TAB>  <TAB>  <TAB> ""Failed to open %s to enumerate interfaces: %s"" % (procfs_path, e.message) <TAB>  <TAB> ) <TAB> return ifaces",ifaces . append ( fields [ 0 ] . strip ( ) ),179
"def access_token(self): <TAB> """"""WeChat component access token"""""" <TAB> access_token = self.session.get(""component_access_token"") <TAB> if access_token: <MASK> # user provided access_token, just return it <TAB>  <TAB>  <TAB> return access_token <TAB>  <TAB> timestamp = time.time() <TAB>  <TAB> if self.expires_at - timestamp > 60: <TAB>  <TAB>  <TAB> return access_token <TAB> self.fetch_access_token() <TAB> return self.session.get(""component_access_token"")",if not self . expires_at :,131
"def apply(self, s, item, evaluation): <TAB> ""AppendTo[s_, item_]"" <TAB> if isinstance(s, Symbol): <TAB>  <TAB> resolved_s = s.evaluate(evaluation) <MASK> result = Expression(""Set"", s, Expression(""Append"", resolved_s, item)) <TAB>  <TAB>  <TAB> return result.evaluate(evaluation) <TAB> return evaluation.message(""AppendTo"", ""rvalue"", s)",if not resolved_s . is_atom ( ) :,105
def server_address(self): <MASK> self.lazy_init_lock_.acquire() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if self.server_address_ is None: <TAB>  <TAB>  <TAB>  <TAB> self.server_address_ = AddressPort() <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self.lazy_init_lock_.release() <TAB> return self.server_address_,if self . server_address_ is None :,95
"def convert_body_to_file_like_object(params, **kwargs): <TAB> if ""Body"" in params: <TAB>  <TAB> if isinstance(params[""Body""], six.string_types): <TAB>  <TAB>  <TAB> params[""Body""] = six.BytesIO(ensure_bytes(params[""Body""])) <MASK> params[""Body""] = six.BytesIO(params[""Body""])","elif isinstance ( params [ ""Body"" ] , six . binary_type ) :",98
"def get_submodel_args_dict(args): <TAB> submodel_argv = get_submodel_argv(args) <TAB> result = {} <TAB> i = 0 <TAB> while i < len(submodel_argv): <TAB>  <TAB> arg = submodel_argv[i] <TAB>  <TAB> next_arg = None if i == len(submodel_argv) - 1 else submodel_argv[i + 1] <TAB>  <TAB> if next_arg and arg.startswith(""--""): <TAB>  <TAB>  <TAB> if next_arg.startswith(""--""): <TAB>  <TAB>  <TAB>  <TAB> result[arg[2:]] = True <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> result[arg[2:]] = next_arg <TAB>  <TAB>  <TAB>  <TAB> i += 1 <MASK> result[arg[2:]] = True <TAB>  <TAB> i += 1 <TAB> return result","elif arg . startswith ( ""--"" ) :",188
"def dataStandart(data, dept, nominal_dept): <TAB> """"""data from nasting to standart: TO container( objects( lists( floats, ), ), )"""""" <TAB> deptl = dept - 1 <TAB> output = [] <TAB> for object in data: <MASK> output.extend(dataStandart(object, deptl, nominal_dept)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> output.append(data) <TAB>  <TAB>  <TAB> return output <TAB> return output",if deptl >= nominal_dept :,122
"def tamper(payload, **kwargs): <TAB> danger_chars = string.punctuation + "" "" <TAB> extra_danger_chars = (""_"", ""."") <TAB> retval = """" <TAB> for char in list(payload): <MASK> retval += char <TAB>  <TAB> elif char == extra_danger_chars[0]: <TAB>  <TAB>  <TAB> retval += quote_plus(""%255F"") <TAB>  <TAB> elif char == extra_danger_chars[1]: <TAB>  <TAB>  <TAB> retval += quote_plus(""%252E"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> retval += quote_plus(quote_plus(quote_plus(char))) <TAB> return retval",if char not in danger_chars :,150
"def hi_server(addr): <TAB> while 1: <TAB>  <TAB> ev, val = first(until_eol=True, sleep=3) <MASK> log.warn(""%s timeout!"" % time.asctime()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> send(""you said %s"" % val)","if ev == ""sleep"" :",76
"def checkForNoiseProfile(): <TAB> global processingChain <TAB> if sys.platform.startswith(""darwin""): <TAB>  <TAB> # not currently supported <TAB>  <TAB> processingChain = [[""lame"", ""rec.wav"", ""rec.mp3"", ""--noreplaygain"", ""--quiet""]] <TAB> else: <TAB>  <TAB> cmd = [""sox"", processingSrc, ""rec2.wav""] <MASK> cmd = cmd + [""noisered"", noiseProfile, NOISE_AMOUNT] <TAB>  <TAB> processingChain[0] = cmd",if os . path . exists ( noiseProfile ) :,128
"def pytest_collection_modifyitems(items): <TAB> for item in items: <TAB>  <TAB> if item.nodeid.startswith(""tests/contrib/funsor""): <TAB>  <TAB>  <TAB> if ""stage"" not in item.keywords: <TAB>  <TAB>  <TAB>  <TAB> item.add_marker(pytest.mark.stage(""funsor"")) <TAB>  <TAB>  <TAB> if ""init"" not in item.keywords: <TAB>  <TAB>  <TAB>  <TAB> item.add_marker(pytest.mark.init(rng_seed=123)) <MASK> item.add_marker(pytest.mark.xfail(reason=""not implemented""))","if ""test_pyroapi"" in item . nodeid and ""test_mean_field_ok"" in item . nodeid :",160
"def find_element(self, action, suffix, parent): <TAB> element = self.search_scopes(action + suffix) <MASK> return element <TAB> if action.endswith(""ByNextToken""): <TAB>  <TAB> element = self.search_scopes(action[: -len(""ByNextToken"")] + suffix) <TAB>  <TAB> if element is not None: <TAB>  <TAB>  <TAB> return self.element_factory(action + suffix, element) <TAB> return self.element_factory(action + suffix, parent)",if element is not None :,114
"def _to_error(*lines): <TAB> if len(lines) == 1: <TAB>  <TAB> if isinstance(lines[0], (list, tuple)): <TAB>  <TAB>  <TAB> lines = lines[0] <MASK> lines = [ <TAB>  <TAB>  <TAB>  <TAB> repr(lines[0]), <TAB>  <TAB>  <TAB> ] <TAB> return ""\n"".join(map(lambda x: _to_unicode(x, errors=""replace""), lines))","elif not isinstance ( lines [ 0 ] , ( str , unicode ) ) :",109
"def primes(n): <TAB> if n == 2: <TAB>  <TAB> return [2] <TAB> elif n < 2: <TAB>  <TAB> return [] <TAB> s = list(range(3, n + 1, 2)) <TAB> mroot = n ** 0.5 <TAB> half = (n + 1) // 2 - 1 <TAB> i = 0 <TAB> m = 3 <TAB> while m <= mroot: <MASK> j = (m * m - 3) // 2 <TAB>  <TAB>  <TAB> s[j] = 0 <TAB>  <TAB>  <TAB> while j < half: <TAB>  <TAB>  <TAB>  <TAB> s[j] = 0 <TAB>  <TAB>  <TAB>  <TAB> j += m <TAB>  <TAB> i = i + 1 <TAB>  <TAB> m = 2 * i + 3 <TAB> return [2] + [x for x in s if x]",if s [ i ] :,184
"def Poll( <TAB> generator: Callable[[], _T], <TAB> condition: Callable[[_T], bool], <TAB> interval: int = DEFAULT_POLL_INTERVAL, <TAB> timeout: int = DEFAULT_POLL_TIMEOUT,) -> _T: <TAB> """"""Periodically calls generator function until a condition is satisfied."""""" <TAB> started = time.time() <TAB> while True: <TAB>  <TAB> obj = generator() <TAB>  <TAB> check_result = condition(obj) <MASK> return obj <TAB>  <TAB> if timeout and (time.time() - started) > timeout: <TAB>  <TAB>  <TAB> raise errors.PollTimeoutError( <TAB>  <TAB>  <TAB>  <TAB> ""Polling on %s timed out after %ds."" % (obj, timeout) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> time.sleep(interval)",if check_result :,177
"def readlink(self, path): <TAB> path = self._realpath(path) <TAB> try: <TAB>  <TAB> symlink = os.readlink(path) <TAB> except OSError as e: <TAB>  <TAB> return SFTPServer.convert_errno(e.errno) <TAB> # if it's absolute, remove the root <TAB> if os.path.isabs(symlink): <MASK> symlink = symlink[len(self.ROOT) :] <TAB>  <TAB>  <TAB> if (len(symlink) == 0) or (symlink[0] != ""/""): <TAB>  <TAB>  <TAB>  <TAB> symlink = ""/"" + symlink <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> symlink = ""<error>"" <TAB> return symlink",if symlink [ : len ( self . ROOT ) ] == self . ROOT :,162
"def parse_drawings_on_layers(self, drawings, f_layer, b_layer): <TAB> front = [] <TAB> back = [] <TAB> for d in drawings: <TAB>  <TAB> if d[1].GetLayer() not in [f_layer, b_layer]: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> drawing = self.parse_drawing(d[1]) <MASK> continue <TAB>  <TAB> if d[0] in [""ref"", ""val""]: <TAB>  <TAB>  <TAB> drawing[d[0]] = 1 <TAB>  <TAB> if d[1].GetLayer() == f_layer: <TAB>  <TAB>  <TAB> front.append(drawing) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> back.append(drawing) <TAB> return {""F"": front, ""B"": back}",if not drawing :,177
"def getExecutionCode(self, required): <TAB> if self.useMatrixList: <TAB>  <TAB> if ""translations"" in required: <TAB>  <TAB>  <TAB> yield ""translations = self.toTranslations(matrices)"" <TAB>  <TAB> if ""rotations"" in required: <TAB>  <TAB>  <TAB> yield ""rotations = self.toRotations(matrices)"" <TAB>  <TAB> if ""scales"" in required: <TAB>  <TAB>  <TAB> yield ""scales = self.toScales(matrices)"" <TAB> else: <MASK> yield ""translation = matrix.to_translation()"" <TAB>  <TAB> if ""rotation"" in required: <TAB>  <TAB>  <TAB> yield ""rotation = matrix.to_euler()"" <TAB>  <TAB> if ""scale"" in required: <TAB>  <TAB>  <TAB> yield ""scale = matrix.to_scale()""","if ""translation"" in required :",173
"def load_files(self): <TAB> """"""Try to load all files specified in arguments."""""" <TAB> if self.filenames: <TAB>  <TAB> for item in self.filenames: <TAB>  <TAB>  <TAB> name_row_col = helpers.get_filename_cursor_pos(item) <TAB>  <TAB>  <TAB> name = name_row_col[""name""] <TAB>  <TAB>  <TAB> if os.path.isdir(name): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> # Avoid opening duplicate files <MASK> continue <TAB>  <TAB>  <TAB> if not self.open_file(**name_row_col): <TAB>  <TAB>  <TAB>  <TAB> self.new_file(name) <TAB> # If nothing was loaded <TAB> if not self.files: <TAB>  <TAB> self.load_default()",if self . file_is_open ( name ) :,177
"def _parse_config(self, config): <TAB> cfg = {} <TAB> for key, value in config.items(): <TAB>  <TAB> # If the value is a plain str, we will use the value <TAB>  <TAB> # If the value is a dict, we will extract the name of an environment <TAB>  <TAB> # variable stored under 'env' and optionally a default, stored under <TAB>  <TAB> # 'default'. <TAB>  <TAB> # (This is useful if the database relocates to a different host <TAB>  <TAB> # during the lifetime of the LSH object) <TAB>  <TAB> if isinstance(value, dict): <MASK> value = os.getenv(value[""env""], value.get(""default"", None)) <TAB>  <TAB> cfg[key] = value <TAB> return cfg","if ""env"" in value :",177
"def bits_per_symbol(self, value: int): <TAB> if self.__bits_per_symbol != value: <TAB>  <TAB> self.__bits_per_symbol = int(value) <TAB>  <TAB> self._qad = None <TAB>  <TAB> self.bits_per_symbol_changed.emit(self.__bits_per_symbol) <MASK> self.protocol_needs_update.emit()",if not self . block_protocol_update :,101
"def _feed_data(self, program, feed, feed_var_name, scope): <TAB> # feed var to framework <TAB> for op in program.global_block().ops: <MASK> feed_target_name = op.desc.output(""Out"")[0] <TAB>  <TAB>  <TAB> cur_feed = feed[feed_target_name] <TAB>  <TAB>  <TAB> if not isinstance(cur_feed, core.LoDTensor): <TAB>  <TAB>  <TAB>  <TAB> cur_feed = _as_lodtensor(cur_feed, self.place) <TAB>  <TAB>  <TAB> idx = op.desc.attr(""col"") <TAB>  <TAB>  <TAB> core.set_feed_variable(scope, cur_feed, feed_var_name, idx) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break","if op . desc . type ( ) == ""feed"" :",183
"def rename_profile(self, profile, newname): <TAB> """"""Rename a profile"""""" <TAB> if self.base.profiles.has_key(profile): <TAB>  <TAB> self.base.profiles[newname] = self.base.profiles[profile] <TAB>  <TAB> del self.base.profiles[profile] <MASK> self.profile = newname",if profile == self . profile :,85
def fsm(): <TAB> if tx_rst == 0: <TAB>  <TAB> tx_bit.next = 1 <TAB>  <TAB> index.next = 0 <TAB>  <TAB> state.next = st.IDLE <TAB> else: <TAB>  <TAB> if state == st.IDLE: <TAB>  <TAB>  <TAB> tx_bit.next = 1 <TAB>  <TAB>  <TAB> if tx_valid:  # a pulse <TAB>  <TAB>  <TAB>  <TAB> state.next = st.START <MASK> tx_bit.next = 0 <TAB>  <TAB>  <TAB> index.next = 7 <TAB>  <TAB>  <TAB> state.next = st.DATA <TAB>  <TAB> elif state == st.DATA: <TAB>  <TAB>  <TAB> tx_bit.next = tx_byte[index] <TAB>  <TAB>  <TAB> if index == 0: <TAB>  <TAB>  <TAB>  <TAB> state.next = st.IDLE <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> index.next = index - 1,elif state == st . START :,198
"def __call__(self, form, field): <TAB> # databases allow multiple NULL values for unique columns <TAB> if field.data is None: <TAB>  <TAB> return <TAB> try: <TAB>  <TAB> obj = self.db_session.query(self.model).filter(self.column == field.data).one() <MASK> if self.message is None: <TAB>  <TAB>  <TAB>  <TAB> self.message = field.gettext(u""Already exists."") <TAB>  <TAB>  <TAB> raise ValidationError(self.message) <TAB> except NoResultFound: <TAB>  <TAB> pass","if not hasattr ( form , ""_obj"" ) or not form . _obj == obj :",138
"def pathdirs(): <TAB> """"""Convert sys.path into a list of absolute, existing, unique paths."""""" <TAB> dirs = [] <TAB> normdirs = [] <TAB> for dir in sys.path: <TAB>  <TAB> dir = os.path.abspath(dir or ""."") <TAB>  <TAB> normdir = os.path.normcase(dir) <MASK> dirs.append(dir) <TAB>  <TAB>  <TAB> normdirs.append(normdir) <TAB> return dirs",if normdir not in normdirs and os . path . isdir ( dir ) :,116
"def test_string(self): <TAB> w = lambda x: self.wbuf().write_string(x).write_flush()  # noqa <TAB> r = lambda x: self.rbuf(x).read_string()  # noqa <TAB> tc = [(""abc1"", ""00 00 00 04 61 62 63 31""), (b""abc2"", ""00 00 00 04 61 62 63 32"")] <TAB> for p in tc: <TAB>  <TAB> v = p[0] <TAB>  <TAB> assert w(v) == self._b(p[1]) <MASK> v = bytes(bytearray(v, ""utf-8"")) <TAB>  <TAB> assert r(self._b(p[1])) == v","if not isinstance ( v , bytes ) :",167
"def skip_pp_directive(s, i): <TAB> while i < len(s): <TAB>  <TAB> if g.is_nl(s, i): <TAB>  <TAB>  <TAB> if g.escaped(s, i): <TAB>  <TAB>  <TAB>  <TAB> i = g.skip_nl(s, i) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> break <MASK> i = g.skip_to_end_of_line(s, i) <TAB>  <TAB> elif g.match(s, i, ""/*""): <TAB>  <TAB>  <TAB> i = g.skip_block_comment(s, i) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> i += 1 <TAB> return i","elif g . match ( s , i , ""//"" ) :",161
"def finalize(self, callback): <TAB> """"""Execute post wrap callback."""""" <TAB> if self.view is not None: <MASK> callback() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sublime.set_timeout(lambda: self.finalize(callback), 100)","if not self . view . settings ( ) . get ( ""bracket_highlighter.busy"" , False ) :",81
"def _forceUserPrefs(self, prefs): <TAB> prefsToSet = { <TAB>  <TAB> ""tabWidth"": ""long"", <TAB>  <TAB> ""indentWidth"": ""long"", <TAB>  <TAB> ""useTabs"": ""bool"", <TAB>  <TAB> ""useSmartTabs"": ""bool"", <TAB> } <TAB> for pref, kind in prefsToSet.iteritems(): <TAB>  <TAB> if not prefs.hasPrefHere(pref): <MASK> prefs.setLong(pref, prefs.getLong(pref)) <TAB>  <TAB>  <TAB> if kind == ""bool"": <TAB>  <TAB>  <TAB>  <TAB> prefs.setBoolean(pref, prefs.getBoolean(pref))","if kind == ""long"" :",149
"def wait(self, limit=None): <TAB> running = True <TAB> while running: <TAB>  <TAB> it = self.consumer_set.iterconsume(limit=limit) <MASK> break <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> it.next() <TAB>  <TAB>  <TAB> except StopIteration: <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> except greenlet.GreenletExit: <TAB>  <TAB>  <TAB>  <TAB> running = False <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB>  <TAB> LOG.exception(_(""Exception while processing consumer"")) <TAB>  <TAB>  <TAB>  <TAB> self.reconnect() <TAB>  <TAB>  <TAB>  <TAB> # Break to outer loop <TAB>  <TAB>  <TAB>  <TAB> break",if not it :,161
"def countbox(self): <TAB> self.box = [1000, 1000, -1000, -1000] <TAB> for i in self.body: <TAB>  <TAB> for x, y in i: <TAB>  <TAB>  <TAB> if x < self.box[0]: <TAB>  <TAB>  <TAB>  <TAB> self.box[0] = x <TAB>  <TAB>  <TAB> if x > self.box[2]: <TAB>  <TAB>  <TAB>  <TAB> self.box[2] = x <MASK> self.box[1] = y <TAB>  <TAB>  <TAB> if y > self.box[3]: <TAB>  <TAB>  <TAB>  <TAB> self.box[3] = y",if y < self . box [ 1 ] :,147
"def _GetKeys(self, key): <TAB> res = [] <TAB> for path in self.cache[self.prefix]: <TAB>  <TAB> if os.path.dirname(path) == key.value: <TAB>  <TAB>  <TAB> sub_type, stat_entry = self.cache[self.prefix][path] <MASK> res.append(os.path.basename(stat_entry.pathspec.path)) <TAB> return sorted(res)","if sub_type == ""Directory"" :",109
"def widget_attrs(self, widget): <TAB> attrs = super(DecimalField, self).widget_attrs(widget) <TAB> if isinstance(widget, NumberInput) and ""step"" not in widget.attrs: <MASK> # Use exponential notation for small values since they might <TAB>  <TAB>  <TAB> # be parsed as 0 otherwise. ref #20765 <TAB>  <TAB>  <TAB> step = str(Decimal(""1"") / 10 ** self.decimal_places).lower() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> step = ""any"" <TAB>  <TAB> attrs.setdefault(""step"", step) <TAB> return attrs",if self . decimal_places is not None :,141
"def list_inline_diff(oldlist, newlist, colors=None): <TAB> if not colors: <TAB>  <TAB> colors = init_colors(False) <TAB> diff = simplediff.diff(oldlist, newlist) <TAB> ret = [] <TAB> for change, value in diff: <TAB>  <TAB> value = "" "".join(value) <MASK> ret.append(""'%s'"" % value) <TAB>  <TAB> elif change == ""+"": <TAB>  <TAB>  <TAB> item = ""{color_add}+{value}{color_default}"".format(value=value, **colors) <TAB>  <TAB>  <TAB> ret.append(item) <TAB>  <TAB> elif change == ""-"": <TAB>  <TAB>  <TAB> item = ""{color_remove}-{value}{color_default}"".format(value=value, **colors) <TAB>  <TAB>  <TAB> ret.append(item) <TAB> return ""[%s]"" % ("", "".join(ret))","if change == ""="" :",196
"def StartNanny(self, unresponsive_kill_period=None): <TAB> # The nanny thread is a singleton. <TAB> if NannyController.nanny is None: <MASK> unresponsive_kill_period = config.CONFIG[""Nanny.unresponsive_kill_period""] <TAB>  <TAB> NannyController.nanny = NannyThread(unresponsive_kill_period) <TAB>  <TAB> NannyController.nanny.start()",if unresponsive_kill_period is None :,111
"def format_params(params): <TAB> items = list(params.items()) <TAB> for k, v in sorted(items, key=itemgetter(0), reverse=True): <MASK> v = v.decode(""utf-8"") <TAB>  <TAB> if isinstance(v, six.text_type): <TAB>  <TAB>  <TAB> v = u'""{v}""'.format(v=v) <TAB>  <TAB> yield u""{k}={v}"".format(k=k, v=v)","if isinstance ( v , bytes ) :",113
"def _init_machine_secrets(self): <TAB> try: <TAB>  <TAB> self.cred.set_machine_account(LP_CTX) <TAB> except NTSTATUSError as e: <MASK> return e.args[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise CallError( <TAB>  <TAB>  <TAB>  <TAB> f""Failed to initialize machine account secrets: {e.args[1]}"" <TAB>  <TAB>  <TAB> ) <TAB> return ntstatus.NT_STATUS_SUCCESS",if e . args [ 0 ] == ntstatus . NT_STATUS_CANT_ACCESS_DOMAIN_INFO :,131
"def _maybe_load_as_instance_attribute(self, node, obj, name): <TAB> assert isinstance(obj, abstract.SimpleValue) <TAB> if not isinstance(obj.cls, mixin.Class): <TAB>  <TAB> return <TAB> for base in obj.cls.mro: <TAB>  <TAB> if isinstance(base, abstract.ParameterizedClass): <TAB>  <TAB>  <TAB> base = base.base_cls <TAB>  <TAB> if isinstance(base, abstract.PyTDClass): <TAB>  <TAB>  <TAB> var = base.convert_as_instance_attribute(name, obj) <MASK> if name in obj.members: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> obj.members[name].PasteVariable(var, node) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> obj.members[name] = var <TAB>  <TAB>  <TAB>  <TAB> return",if var is not None :,191
"def update_state(self): <TAB> """"""Copy state to uA"""""" <TAB> self.state = { <TAB>  <TAB> ""rows"": self.ui.min_rows.value(), <TAB>  <TAB> ""sep"": self.ui.sep_txt.text(), <TAB>  <TAB> ""start"": self.ui.start_txt.text(), <TAB>  <TAB> ""end"": self.ui.end_txt.text(), <TAB> } <TAB> u = self.c.p.v.u <TAB> if ""_lep"" in u: <MASK> u[""_lep""][""csv""].update(self.state) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> u[""_lep""][""csv""] = dict(self.state) <TAB> else: <TAB>  <TAB> u[""_lep""] = {""csv"": dict(self.state)}","if ""csv"" in u [ ""_lep"" ] :",189
"def redraw_all_toplevels(): <TAB> """"""A hack to trigger redraws for all windows and widgets."""""" <TAB> for widget in Gtk.Window.list_toplevels(): <TAB>  <TAB> if not widget.get_realized(): <TAB>  <TAB>  <TAB> continue <MASK> widget.queue_draw() <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> sensitive = widget.get_sensitive() <TAB>  <TAB> widget.set_sensitive(not sensitive) <TAB>  <TAB> widget.set_sensitive(sensitive)",if widget . is_active ( ) :,116
"def save(self, *args, **kwargs): <TAB> ""Process form"" <TAB> if self.instance: <TAB>  <TAB> if self.is_valid(): <MASK> self.instance.location = self.cleaned_data[""location""] <TAB>  <TAB>  <TAB> if self.cleaned_data[""status""]: <TAB>  <TAB>  <TAB>  <TAB> self.instance.status = self.cleaned_data[""status""] <TAB>  <TAB>  <TAB> self.instance.save() <TAB>  <TAB>  <TAB> if self.cleaned_data[""delete""]: <TAB>  <TAB>  <TAB>  <TAB> if self.cleaned_data[""delete""] == ""delete"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.instance.delete() <TAB>  <TAB>  <TAB>  <TAB> if self.cleaned_data[""delete""] == ""trash"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.instance.trash = True <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.instance.save()","if self . cleaned_data [ ""location"" ] :",195
"def _get_kwargs(self): <TAB> s = u"""" <TAB> if self.kwargs: <TAB>  <TAB> s = u"", "".join(""%s=%r"" % (k, v) for k, v in self.kwargs.items()) <MASK> s = u"", "" + s <TAB> return s",if self . args :,76
"def remove_trailing_spaces(editorWidget): <TAB> cursor = editorWidget.textCursor() <TAB> cursor.beginEditBlock() <TAB> block = editorWidget.document().findBlockByLineNumber(0) <TAB> while block.isValid(): <TAB>  <TAB> text = block.text() <MASK> cursor.setPosition(block.position()) <TAB>  <TAB>  <TAB> cursor.select(QTextCursor.LineUnderCursor) <TAB>  <TAB>  <TAB> cursor.insertText(text.rstrip()) <TAB>  <TAB> block = block.next() <TAB> cursor.movePosition(QTextCursor.End, QTextCursor.MoveAnchor) <TAB> cursor.endEditBlock()","if text . endswith ( "" "" ) :",152
"def gtk_on_select(self, selection): <TAB> if self.interface.on_select: <MASK> tree_model, tree_path = selection.get_selected_rows() <TAB>  <TAB>  <TAB> if tree_path: <TAB>  <TAB>  <TAB>  <TAB> tree_iter = tree_model.get_iter(tree_path[-1]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> tree_iter = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tree_model, tree_iter = selection.get_selected() <TAB>  <TAB> # Covert the tree iter into the actual node. <TAB>  <TAB> if tree_iter: <TAB>  <TAB>  <TAB> node = tree_model.get(tree_iter, 0)[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> node = None <TAB>  <TAB> self.interface.on_select(None, node=node)",if self . interface . multiple_select :,198
"def advance(len=len): <TAB> # If some successor has only one exit, must take it. <TAB> # Else favor successors with fewer exits. <TAB> candidates = [] <TAB> for i in succs[self.lastij]: <TAB>  <TAB> e = len(succs[i]) <TAB>  <TAB> assert e > 0, ""else remove_from_successors() pruning flawed"" <TAB>  <TAB> if e == 1: <TAB>  <TAB>  <TAB> candidates = [(e, i)] <TAB>  <TAB>  <TAB> break <TAB>  <TAB> candidates.append((e, i)) <TAB> else: <TAB>  <TAB> candidates.sort() <TAB> for e, i in candidates: <MASK> if remove_from_successors(i): <TAB>  <TAB>  <TAB>  <TAB> self.lastij = i <TAB>  <TAB>  <TAB>  <TAB> yield i <TAB>  <TAB>  <TAB> add_to_successors(i)",if i != self . final :,190
"def _remove_fs_obj(path): <TAB> if os.path.exists(path): <TAB>  <TAB> log.info(""DSC: Removing {0}"".format(path)) <MASK> error = ""Failed to remove {0}"".format(path) <TAB>  <TAB>  <TAB> log.error(""DSC: {0}"".format(error)) <TAB>  <TAB>  <TAB> raise CommandExecutionError(error)","if not __salt__ [ ""file.remove"" ] ( path ) :",101
"def _deploy_k8s_resource(self, yaml_data): <TAB> for data in yaml_data: <MASK> continue <TAB>  <TAB> kind = data.get(""kind"", None) <TAB>  <TAB> name = data.get(""metadata"").get(""name"", None) <TAB>  <TAB> namespace = data.get(""metadata"").get(""namespace"", None) <TAB>  <TAB> logs = ""Deploy namespace={}, name={}, kind={}"".format(namespace, name, kind) <TAB>  <TAB> logger.info(logs) <TAB>  <TAB> if kind in self.support_namespace: <TAB>  <TAB>  <TAB> self.create_func_dict.get(kind)(namespace, data) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.create_func_dict.get(kind)(data) <TAB>  <TAB> time.sleep(3)",if data is None :,180
"def _load_npy(self, imdb_path): <TAB> self.db = np.load(imdb_path, allow_pickle=True) <TAB> self.start_idx = 0 <TAB> if type(self.db) == dict: <TAB>  <TAB> self.metadata = self.db.get(""metadata"", {}) <TAB>  <TAB> self.data = self.db.get(""data"", []) <TAB> else: <TAB>  <TAB> # TODO: Deprecate support for this <TAB>  <TAB> self.metadata = {""version"": 1} <TAB>  <TAB> self.data = self.db <TAB>  <TAB> # Handle old imdb support <MASK> self.start_idx = 1 <TAB> if len(self.data) == 0: <TAB>  <TAB> self.data = self.db","if ""image_id"" not in self . data [ 0 ] :",184
"def _infere_context_data(self, path: str) -> str: <TAB> """"""If this is a remote session, infere context data if any"""""" <TAB> if is_remote_session(self.view): <TAB>  <TAB> window = self.view.window().id() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> interpreter = Market().get(window).interpreter <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> print(""while getting interp for Window ID {}: {}"".format(window, e)) <TAB>  <TAB>  <TAB> return path <TAB>  <TAB> directory_map = interpreter.pathmap <TAB>  <TAB> if directory_map is None: <TAB>  <TAB>  <TAB> return path <TAB>  <TAB> for local_dir, remote_dir in directory_map.items(): <MASK> return path.replace(remote_dir, local_dir) <TAB> return path",if remote_dir in path :,194
def generateCoveredList2(revlist=None): <TAB> if not revlist: <TAB>  <TAB> revlist = [] <TAB> covered_list = [x for x in revlist if x.outcome == Task.OUTCOME_COVERED] <TAB> while len(covered_list): <TAB>  <TAB> revlist = [x for x in revlist if x.outcome != Task.OUTCOME_COVERED] <MASK> return revlist <TAB>  <TAB> newlist = _find_task_revdep_list(covered_list) <TAB>  <TAB> revlist = list(set(revlist + newlist)) <TAB>  <TAB> covered_list = [x for x in revlist if x.outcome == Task.OUTCOME_COVERED] <TAB> return revlist,if len ( revlist ) > 0 :,178
"def asyncproxy(proxy, asynchronous=True, **kwargs): <TAB> """"""convenience method to set proxy to asynchronous or sync mode."""""" <TAB> if kwargs: <TAB>  <TAB> kword = list(kwargs.keys()) <MASK> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""asyncproxy() got an unexpected keyword argument '{:s}'"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> kword[0] <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> asynchronous = kwargs[""async""] <TAB> proxy._pyroAsync(asynchronous)","if kword != [ ""async"" ] :",125
"def on_task_filter(self, task, config): <TAB> if not config: <TAB>  <TAB> return <TAB> with Session() as session: <TAB>  <TAB> for entry in task.entries: <TAB>  <TAB>  <TAB> # Cache all new task entries <MASK> entry.accept(""entry is marked as approved"") <TAB>  <TAB>  <TAB> elif not self._item_query(entry, task, session): <TAB>  <TAB>  <TAB>  <TAB> log.verbose(""creating new pending entry %s"", entry) <TAB>  <TAB>  <TAB>  <TAB> session.add(db.PendingEntry(task_name=task.name, entry=entry)) <TAB>  <TAB>  <TAB>  <TAB> entry.reject(""new unapproved entry, caching and waiting for approval"")","if entry . get ( ""approved"" ) :",161
"def __eq__(self, other): <TAB> if isinstance(other, Table): <TAB>  <TAB> if self.headings != other.headings: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> for my_row, their_row in zip(self.rows, other.rows): <MASK> return False <TAB> else: <TAB>  <TAB> # -- ASSUME: table <=> raw data comparison <TAB>  <TAB> other_rows = other <TAB>  <TAB> for my_row, their_row in zip(self.rows, other_rows): <TAB>  <TAB>  <TAB> if my_row != their_row: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return True",if my_row != their_row :,149
"def _dom_node(self, domroot): <TAB> element = domroot.createElement(self.tagname) <TAB> for attribute, value in self.attlist(): <MASK> value = "" "".join([serial_escape(""%s"" % v) for v in value]) <TAB>  <TAB> element.setAttribute(attribute, ""%s"" % value) <TAB> for child in self.children: <TAB>  <TAB> element.appendChild(child._dom_node(domroot)) <TAB> return element","if isinstance ( value , ListType ) :",116
"def extractor(self, fname): <TAB> fname = os.path.abspath(fname) <TAB> outfile = os.path.splitext(fname)[0] <TAB> try: <TAB>  <TAB> fpout = open(outfile, ""wb"") <TAB>  <TAB> gz = gzip.GzipFile(fname, ""rb"") <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> data = gz.read(self.BLOCK_SIZE) <MASK> fpout.write(data) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> gz.close() <TAB>  <TAB> fpout.close() <TAB> except KeyboardInterrupt as e: <TAB>  <TAB> raise e <TAB> except Exception as e: <TAB>  <TAB> return False <TAB> return True",if data :,161
"def pytest_pycollect_makeitem(collector, name, obj): <TAB> """"""A pytest hook to collect asyncio coroutines."""""" <TAB> if collector.funcnamefilter(name) and _is_coroutine(obj): <TAB>  <TAB> item = pytest.Function.from_parent(collector, name=name) <TAB>  <TAB> # Due to how pytest test collection works, module-level pytestmarks <TAB>  <TAB> # are applied after the collection step. Since this is the collection <TAB>  <TAB> # step, we look ourselves. <TAB>  <TAB> transfer_markers(obj, item.cls, item.module) <TAB>  <TAB> item = pytest.Function.from_parent(collector, name=name)  # To reload keywords. <MASK> return list(collector._genfunctions(name, obj))","if ""asyncio"" in item . keywords :",175
"def entry_from_named_pair(register_pairs, key): <TAB> """"""Returns the entry in key given results provided by register_pairs"""""" <TAB> results = register_pairs.get(""results"") <TAB> if results is None: <TAB>  <TAB> raise RuntimeError( <TAB>  <TAB>  <TAB> ""The dict argument does not have a 'results' entry. "" <TAB>  <TAB>  <TAB> ""Must not have been created using 'register' in a loop"" <TAB>  <TAB> ) <TAB> for result in results: <TAB>  <TAB> item = result.get(""item"") <MASK> name = item.get(""name"") <TAB>  <TAB>  <TAB> if name == key: <TAB>  <TAB>  <TAB>  <TAB> return result[""content""] <TAB> raise RuntimeError( <TAB>  <TAB> ""There was no entry found in the dict that had an item with a name that matched {}"".format( <TAB>  <TAB>  <TAB> key <TAB>  <TAB> ) <TAB> )",if item is not None :,196
"def _optimal_split(data, pattern): <TAB> while data: <TAB>  <TAB> match = re.search(pattern, data) <MASK> break <TAB>  <TAB> start, end = match.start(), match.end() <TAB>  <TAB> if start: <TAB>  <TAB>  <TAB> yield False, data[:start] <TAB>  <TAB> yield True, data[start:end] <TAB>  <TAB> data = data[end:] <TAB> if data: <TAB>  <TAB> yield False, data",if not match :,106
"def will_execute_instruction_callback(self, state, pc, insn): <TAB> world = state.platform <TAB> with self.manticore.locked_context(""seen_rep"", dict) as reps: <TAB>  <TAB> item = ( <TAB>  <TAB>  <TAB> world.current_transaction.sort == ""CREATE"", <TAB>  <TAB>  <TAB> world.current_transaction.address, <TAB>  <TAB>  <TAB> pc, <TAB>  <TAB> ) <TAB>  <TAB> if item not in reps: <TAB>  <TAB>  <TAB> reps[item] = 0 <TAB>  <TAB> reps[item] += 1 <MASK> state.abandon()",if reps [ item ] > self . loop_count_threshold :,146
"def _check_drift_dyn_gen(drift): <TAB> if not isinstance(drift, Qobj): <MASK> raise TypeError(""drift should be a Qobj or a list of Qobj"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for d in drift: <TAB>  <TAB>  <TAB>  <TAB> if not isinstance(d, Qobj): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise TypeError(""drift should be a Qobj or a list of Qobj"")","if not isinstance ( drift , ( list , tuple ) ) :",116
def _get_or_create_tracker_id(class_def): <TAB> with _DYNAMIC_CLASS_TRACKER_LOCK: <TAB>  <TAB> class_tracker_id = _DYNAMIC_CLASS_TRACKER_BY_CLASS.get(class_def) <MASK> class_tracker_id = uuid.uuid4().hex <TAB>  <TAB>  <TAB> _DYNAMIC_CLASS_TRACKER_BY_CLASS[class_def] = class_tracker_id <TAB>  <TAB>  <TAB> _DYNAMIC_CLASS_TRACKER_BY_ID[class_tracker_id] = class_def <TAB> return class_tracker_id,if class_tracker_id is None :,153
"def all(self): <TAB> regs = arch_to_regs[pwndbg.arch.current] <TAB> retval = [] <TAB> for regset in ( <TAB>  <TAB> regs.pc, <TAB>  <TAB> regs.stack, <TAB>  <TAB> regs.frame, <TAB>  <TAB> regs.retaddr, <TAB>  <TAB> regs.flags, <TAB>  <TAB> regs.gpr, <TAB>  <TAB> regs.misc, <TAB> ): <TAB>  <TAB> if regset is None: <TAB>  <TAB>  <TAB> continue <MASK> retval.extend(regset) <TAB>  <TAB> elif isinstance(regset, dict): <TAB>  <TAB>  <TAB> retval.extend(regset.keys()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> retval.append(regset) <TAB> return retval","elif isinstance ( regset , ( list , tuple ) ) :",172
"def unpack_tarball(tar_filename, dest): <TAB> print(""Unpacking %s into %s"" % (os.path.basename(tar_filename), dest)) <TAB> tar = tarfile.open(tar_filename) <TAB> base_dir = None <TAB> for member in tar: <TAB>  <TAB> base_name = member.name.split(""/"")[0] <TAB>  <TAB> if base_dir is None: <TAB>  <TAB>  <TAB> base_dir = base_name <TAB>  <TAB> else: <MASK> print(""Unexpected path in %s: %s"" % (tar_filename, base_name)) <TAB> _extractall(tar, dest) <TAB> tar.close() <TAB> return os.path.join(dest, base_dir)",if base_dir != base_name :,174
"def get(self, path, params={}): <TAB> final_url = ""%s/public/api/customers/%s%s"" % (self.url, self.customer_id, path) <TAB> try: <TAB>  <TAB> response = requests.get( <TAB>  <TAB>  <TAB> url=final_url, headers=self.auth_headers(), verify=self.verify_ssl <TAB>  <TAB> ) <MASK> return response.json() <TAB> except requests.exceptions.RequestException as e: <TAB>  <TAB> logger.exception(e)","if response and response . status_code in [ requests . codes . ok , requests . codes . bad ] :",139
"def _hash_literal(self): <TAB> self._expect(""{"", consume_whitespace=True) <TAB> keyvals = {} <TAB> while self._current() != ""}"": <TAB>  <TAB> key = self._key() <TAB>  <TAB> self._expect(""="", consume_whitespace=True) <TAB>  <TAB> v = self._explicit_values() <TAB>  <TAB> self._consume_whitespace() <MASK> self._expect("","") <TAB>  <TAB>  <TAB> self._consume_whitespace() <TAB>  <TAB> keyvals[key] = v <TAB> self._expect(""}"") <TAB> return keyvals","if self . _current ( ) != ""}"" :",126
"def authenticate(self, identifier, secret): <TAB> try: <TAB>  <TAB> user = self.plugin_manager.hook.flaskbb_authenticate( <TAB>  <TAB>  <TAB> identifier=identifier, secret=secret <TAB>  <TAB> ) <MASK> raise StopAuthentication(_(""Wrong username or password."")) <TAB>  <TAB> self.plugin_manager.hook.flaskbb_post_authenticate(user=user) <TAB>  <TAB> return user <TAB> except StopAuthentication as e: <TAB>  <TAB> self.plugin_manager.hook.flaskbb_authentication_failed(identifier=identifier) <TAB>  <TAB> raise <TAB> finally: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.session.commit() <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> logger.exception(""Exception while processing login"") <TAB>  <TAB>  <TAB> self.session.rollback() <TAB>  <TAB>  <TAB> raise",if user is None :,177
def compute_nullable_nonterminals(self): <TAB> nullable = set() <TAB> num_nullable = 0 <TAB> while True: <TAB>  <TAB> for p in self.grammar.Productions[1:]: <MASK> nullable.add(p.name) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> for t in p.prod: <TAB>  <TAB>  <TAB>  <TAB> if t not in nullable: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> nullable.add(p.name) <TAB>  <TAB> if len(nullable) == num_nullable: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> num_nullable = len(nullable) <TAB> return nullable,if p . len == 0 :,154
"def test_cmd_query_iter(self): <TAB> self._setup() <TAB> stmt = ""SELECT 1; INSERT INTO %s VALUES (1),(2); SELECT 3"" <TAB> results = [] <TAB> try: <TAB>  <TAB> for result in self.cnx.cmd_query_iter(stmt % self.table): <TAB>  <TAB>  <TAB> results.append(result) <TAB>  <TAB>  <TAB> if ""columns"" in result: <TAB>  <TAB>  <TAB>  <TAB> results.append(self.cnx.get_rows()) <TAB> except NotImplementedError: <TAB>  <TAB> # Some cnx are not implementing this <MASK> raise","if not isinstance ( self . cnx , CMySQLConnection ) :",148
"def test_looks_in_path(self): <TAB> path_dirs = set(environ[""PATH""].split(os.path.pathsep)) <TAB> dirs = path_dirs - set(os.defpath.split(os.path.pathsep)) <TAB> for d in dirs: <MASK> for file_path in sorted(os.listdir(d)): <TAB>  <TAB>  <TAB>  <TAB> p = os.path.join(d, file_path) <TAB>  <TAB>  <TAB>  <TAB> if os.path.isfile(p) and os.access(p, os.X_OK): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> print_d(""Testing %s"" % p) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.failUnless(iscommand(p), msg=p) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return",if os . path . isdir ( d ) :,180
"def show_consts(self, consts, level=0): <TAB> indent = INDENT * level <TAB> for i, obj in enumerate(consts): <MASK> print(""%s%s (code object)"" % (indent, i)) <TAB>  <TAB>  <TAB> # RECURSIVE CALL. <TAB>  <TAB>  <TAB> self.show_code(obj, level=level + 1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""%s%s %r"" % (indent, i, obj))","if isinstance ( obj , types . CodeType ) :",118
"def _get_table(table_name): <TAB> best_match = None <TAB> best_score = 0 <TAB> for table in VSCtl._TABLES: <TAB>  <TAB> score = VSCtl._score_partial_match(table.table_name, table_name) <MASK> best_match = table <TAB>  <TAB>  <TAB> best_score = score <TAB>  <TAB> elif score == best_score: <TAB>  <TAB>  <TAB> best_match = None <TAB> if best_match: <TAB>  <TAB> return best_match <TAB> elif best_score: <TAB>  <TAB> vsctl_fatal('multiple table names match ""%s""' % table_name) <TAB> else: <TAB>  <TAB> vsctl_fatal('unknown table ""%s""' % table_name)",if score > best_score :,172
"def test_re_escape(self): <TAB> alnum_chars = string.ascii_letters + string.digits + ""_"" <TAB> p = """".join(chr(i) for i in range(256)) <TAB> for c in p: <MASK> self.assertEqual(re.escape(c), c) <TAB>  <TAB> elif c == ""\x00"": <TAB>  <TAB>  <TAB> self.assertEqual(re.escape(c), ""\\000"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertEqual(re.escape(c), ""\\"" + c) <TAB>  <TAB> self.assertMatch(re.escape(c), c) <TAB> self.assertMatch(re.escape(p), p)",if c in alnum_chars :,160
"def get_setuptools_version(): <TAB> with open(""requirements.txt"") as f: <TAB>  <TAB> for line in f: <TAB>  <TAB>  <TAB> if line.startswith(""setuptools""): <TAB>  <TAB>  <TAB>  <TAB> line = line.rstrip() <MASK> raise ValueError('%s doesnt use "">=""' % line) <TAB>  <TAB>  <TAB>  <TAB> _, version = line.split("">="") <TAB>  <TAB>  <TAB>  <TAB> return version","if "">="" not in line :",99
"def mouse_inside_delete_button(): <TAB> for idx, obj in enumerate(img_objects): <MASK> ind, x1, y1, x2, y2 = obj <TAB>  <TAB>  <TAB> x1_c, y1_c, x2_c, y2_c = get_close_icon(x1, y1, x2, y2) <TAB>  <TAB>  <TAB> if is_mouse_inside_points(x1_c, y1_c, x2_c, y2_c): <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if idx == selected_bbox :,138
def check_sanity(self): <TAB> super().check_sanity() <TAB> if self.suicided: <TAB>  <TAB> assert self.left is None <TAB>  <TAB> assert self.right is None <TAB> else: <TAB>  <TAB> left = self.left <MASK> assert left.right is None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert left.right is self <TAB>  <TAB> right = self.right <TAB>  <TAB> if right.suicided: <TAB>  <TAB>  <TAB> assert right.left is None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert right.left is self,if left . suicided :,133
"def getbool(self, option, default=False): <TAB> try: <TAB>  <TAB> val = super(ServiceDef, self).get(self.name, option) <MASK> val = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> val = False <TAB> except: <TAB>  <TAB> val = default <TAB> return val","if val . lower ( ) == ""true"" :",82
"def get_op_number(self, prog): <TAB> graph = IrGraph(core.Graph(prog.desc), for_test=False) <TAB> quant_op_nums = 0 <TAB> op_nums = 0 <TAB> for op in graph.all_op_nodes(): <MASK> op_nums += 1 <TAB>  <TAB> elif ""fake_"" in op.name(): <TAB>  <TAB>  <TAB> quant_op_nums += 1 <TAB> return op_nums, quant_op_nums","if op . name ( ) in [ ""conv2d"" , ""depthwise_conv2d"" , ""mul"" ] :",131
"def check_eol(filename): <TAB> eol = u""\n"" <TAB> with open(filename, ""rb"") as f: <TAB>  <TAB> d = f.read() <TAB>  <TAB> if b""\r\n"" in d: <TAB>  <TAB>  <TAB> eol = u""\r\n"" <TAB>  <TAB> elif b""\n"" in d: <TAB>  <TAB>  <TAB> eol = u""\n"" <MASK> eol = u""\r"" <TAB> return eol","elif b""\r"" in d :",109
"def wait_for_parent_death(orig_parent_pid): <TAB> while True: <TAB>  <TAB> ppid = os.getppid() <MASK> return <TAB>  <TAB> # on some systems, getppid will keep returning <TAB>  <TAB> # a dead pid, so check it for liveness <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> os.kill(ppid, 0) <TAB>  <TAB> except OSError:  # Probably ENOSUCH <TAB>  <TAB>  <TAB> return",if ppid != orig_parent_pid :,117
"def _get_project_vcf(x, suffix=""""): <TAB> """"""Get our project VCF, either from the population or the variant batch file."""""" <TAB> vcfs = _get_variant_file(x, (""population"", ""vcf""), suffix=suffix) <TAB> if not vcfs: <TAB>  <TAB> vcfs = _get_variant_file( <TAB>  <TAB>  <TAB> x, (""vrn_file_batch"",), suffix=suffix, ignore_do_upload=True <TAB>  <TAB> ) <MASK> vcfs = _get_variant_file(x, (""vrn_file"",), suffix=suffix) <TAB> return vcfs","if not vcfs and x . get ( ""variantcaller"" ) == ""ensemble"" :",155
def check_parameter_types(params): <TAB> for p in params: <TAB>  <TAB> cl = p.__class__ <TAB>  <TAB> if cl not in CACHABLE_PARAM_TYPES: <TAB>  <TAB>  <TAB> if cl in ITERABLES: <TAB>  <TAB>  <TAB>  <TAB> check_parameter_types(p) <MASK> check_parameter_types(p.items()) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise UncachableQuery,elif cl is dict :,107
"def convert(self, value, param, ctx): <TAB> # Exact match <TAB> if value in self.choices: <TAB>  <TAB> return self.typ(value) <TAB> if ctx is not None and ctx.token_normalize_func is not None: <TAB>  <TAB> value = ctx.token_normalize_func(value) <TAB>  <TAB> for choice in self.casted_choices: <MASK> return choice <TAB> self.fail( <TAB>  <TAB> ""invalid choice: %s. (choose from %s)"" % (value, "", "".join(self.choices)), <TAB>  <TAB> param, <TAB>  <TAB> ctx, <TAB> )",if ctx . token_normalize_func ( choice ) == value :,155
"def do_branch_rename_test(self, repo, q): <TAB> st = monotonic() <TAB> while monotonic() - st < 1: <TAB>  <TAB> # Give inotify time to deliver events <TAB>  <TAB> ans = repo.branch() <TAB>  <TAB> if hasattr(q, ""__call__""): <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if ans == q: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> sleep(0.01) <TAB> if hasattr(q, ""__call__""): <TAB>  <TAB> self.assertTrue(q(ans)) <TAB> else: <TAB>  <TAB> self.assertEqual(ans, q)",if q ( ans ) :,143
"def make_dict(s: Sequence[T]) -> Dict[str, List[T]]: <TAB> res: Dict[str, List[T]] = {} <TAB> for a in s: <TAB>  <TAB> k = key(a) <TAB>  <TAB> ll = res.get(k, None) <MASK> ll = [] <TAB>  <TAB>  <TAB> res[k] = ll <TAB>  <TAB> ll.append(a) <TAB> return res",if ll is None :,102
"def collectAccidentalDisplayStatus(s_inner): <TAB> post = [] <TAB> for e in s_inner.flat.notes: <MASK> post.append(e.pitch.accidental.displayStatus) <TAB>  <TAB> else:  # mark as not having an accidental <TAB>  <TAB>  <TAB> post.append(""x"") <TAB> return post",if e . pitch . accidental is not None :,95
"def close(self): <TAB> if self.housekeeper: <TAB>  <TAB> self.housekeeper.stop.set() <TAB>  <TAB> self.housekeeper.join() <TAB>  <TAB> self.housekeeper = None <TAB> if self.sock: <TAB>  <TAB> sockname = None <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> sockname = self.sock.getsockname() <TAB>  <TAB> except (socket.error, OSError): <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.sock.close() <MASK> # it was a Unix domain socket, remove it from the filesystem <TAB>  <TAB>  <TAB>  <TAB> if os.path.exists(sockname): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> os.remove(sockname) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> self.sock = None <TAB> self.pool.close()",if type ( sockname ) is str :,193
"def vars(self): <TAB> ret = [] <TAB> if op.disklist: <TAB>  <TAB> varlist = list(map(self.basename, op.disklist)) <TAB> else: <TAB>  <TAB> varlist = [] <TAB>  <TAB> for name in self.discover: <MASK> continue <TAB>  <TAB>  <TAB> if name not in blockdevices(): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> varlist.append(name) <TAB>  <TAB> # <TAB>  <TAB>    if len(varlist) > 2: varlist = varlist[0:2] <TAB>  <TAB> varlist.sort() <TAB> for name in varlist: <TAB>  <TAB> if name in self.discover: <TAB>  <TAB>  <TAB> ret.append(name) <TAB> return ret",if self . diskfilter . match ( name ) :,180
"def computeShortcutModes(self, mode): <TAB> if isinstance(mode, string_types): <MASK> mode = (""failing"", ""passing"", ""warnings"", ""exception"", ""cancelled"") <TAB>  <TAB> elif mode == ""warnings"": <TAB>  <TAB>  <TAB> mode = (""failing"", ""warnings"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> mode = (mode,) <TAB> return mode","if mode == ""all"" :",93
"def content(self): <TAB> """"""Content of the response, in bytes."""""" <TAB> if self._content is False: <TAB>  <TAB> # Read the contents. <TAB>  <TAB> if self._content_consumed: <TAB>  <TAB>  <TAB> raise RuntimeError(""The content for this response was already consumed"") <MASK> self._content = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._content = b"""".join(self.iter_content(CONTENT_CHUNK_SIZE)) or b"""" <TAB> self._content_consumed = True <TAB> # don't need to release the connection; that's been handled by urllib3 <TAB> # since we exhausted the data. <TAB> return self._content",if self . status_code == 0 or self . raw is None :,161
"def _get_key_attrs(self, keydir, keyname, keysize, user): <TAB> if not keydir: <TAB>  <TAB> if ""gen_keys_dir"" in self.opts: <TAB>  <TAB>  <TAB> keydir = self.opts[""gen_keys_dir""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> keydir = self.opts[""pki_dir""] <TAB> if not keyname: <MASK> keyname = self.opts[""gen_keys""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> keyname = ""minion"" <TAB> if not keysize: <TAB>  <TAB> keysize = self.opts[""keysize""] <TAB> return keydir, keyname, keysize, user","if ""gen_keys"" in self . opts :",160
"def find_command_from_list(cls, files: str) -> Optional[str]: <TAB> for file in files: <TAB>  <TAB> if os.path.isabs(file): <MASK> return file <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> path = find_executable(file) <TAB>  <TAB>  <TAB> if path is not None: <TAB>  <TAB>  <TAB>  <TAB> return os.path.abspath(path) <TAB> return None",if os . path . exists ( file ) :,105
"def build_list_params(self, params, items, label): <TAB> if isinstance(items, basestring): <TAB>  <TAB> items = [items] <TAB> for index, item in enumerate(items): <TAB>  <TAB> i = index + 1 <TAB>  <TAB> if isinstance(item, dict): <TAB>  <TAB>  <TAB> for k, v in item.iteritems(): <TAB>  <TAB>  <TAB>  <TAB> params[label % (i, ""Name"")] = k <MASK> params[label % (i, ""Value"")] = v <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> params[label % i] = item",if v is not None :,138
"def do_commit_twophase(self, connection, xid, is_prepared=True, recover=False): <TAB> if is_prepared: <MASK> connection.execute(""ROLLBACK"") <TAB>  <TAB> connection.execute(""COMMIT PREPARED '%s'"" % xid) <TAB>  <TAB> connection.execute(""BEGIN"") <TAB>  <TAB> self.do_rollback(connection.connection) <TAB> else: <TAB>  <TAB> self.do_commit(connection.connection)",if recover :,110
"def __init__(self, language, filename, type, video, link, fps): <TAB> super(YavkaNetSubtitle, self).__init__(language) <TAB> self.filename = filename <TAB> self.page_link = link <TAB> self.type = type <TAB> self.video = video <TAB> self.fps = fps <TAB> self.release_info = filename <TAB> if fps: <MASK> self.release_info += "" <b>[{:.3f}]</b>"".format(fps) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.release_info += "" [{:.3f}]"".format(fps)",if video . fps and float ( video . fps ) == fps :,156
"def test_all(self): <TAB> # objects defined in the module should be in __all__ <TAB> expected = [] <TAB> for name in dir(socketserver): <MASK> mod_object = getattr(socketserver, name) <TAB>  <TAB>  <TAB> if getattr(mod_object, ""__module__"", None) == ""socketserver"": <TAB>  <TAB>  <TAB>  <TAB> expected.append(name) <TAB> self.assertCountEqual(socketserver.__all__, expected)","if not name . startswith ( ""_"" ) :",106
"def _get_proxy(self, url): <TAB> if self._proxy: <TAB>  <TAB> proxy = self._proxy <TAB>  <TAB> scheme = url.split("":"")[0] if url else None <MASK> if scheme in proxy: <TAB>  <TAB>  <TAB>  <TAB> return proxy[scheme] <TAB>  <TAB>  <TAB> scheme = scheme[0:-1] <TAB>  <TAB>  <TAB> if scheme in proxy: <TAB>  <TAB>  <TAB>  <TAB> return proxy[scheme] <TAB> return None",if scheme :,101
"def get_ip(self): <TAB> if self.ip is None: <TAB>  <TAB> regex = re.compile(r""^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$"") <TAB>  <TAB> result = regex.match(self.host) <MASK> self.ip = socket.gethostbyname(self.host) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.ip = self.host <TAB> return self.ip",if not result :,114
"def get_queryset(self, request, username, local_site_name=None, *args, **kwargs): <TAB> try: <TAB>  <TAB> local_site = self._get_local_site(local_site_name) <MASK> user = local_site.users.get(username=username) <TAB>  <TAB>  <TAB> profile = user.get_profile() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> profile = Profile.objects.get(user__username=username) <TAB>  <TAB> q = self.watched_resource.get_queryset( <TAB>  <TAB>  <TAB> request, local_site_name=local_site_name, *args, **kwargs <TAB>  <TAB> ) <TAB>  <TAB> q = q.filter(starred_by=profile) <TAB>  <TAB> return q <TAB> except Profile.DoesNotExist: <TAB>  <TAB> return self.watched_resource.model.objects.none()",if local_site :,197
"def _check_generated_stderr(self, stderr, n): <TAB> expected = [ <TAB>  <TAB> r""\[stderr:\d+\]"", <TAB>  <TAB> ""^stderr$"", <TAB>  <TAB> ""^stderr2$"", <TAB> ] * n <TAB> self.assertNotIn(""\n\n"", stderr) <TAB> lines = stderr.splitlines() <TAB> self.assertEqual(len(lines), len(expected), stderr) <TAB> for line, expect in zip(lines, expected): <MASK> expect = [expect] <TAB>  <TAB> for ex in expect: <TAB>  <TAB>  <TAB> assert re.search(ex, line) is not None, ""Expected %r in %r"" % (ex, line)","if isinstance ( expect , str ) :",156
"def _validate_context_aware_object_factories(cls, context_aware_object_factories): <TAB> if not context_aware_object_factories: <TAB>  <TAB> return {} <TAB> for alias, obj in context_aware_object_factories.items(): <TAB>  <TAB> cls._validate_alias(""context_aware_object_factories"", alias, obj) <TAB>  <TAB> cls._validate_not_targets(""context_aware_object_factories"", alias, obj) <MASK> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""The given context aware object factory {alias!r} must be a callable."".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> alias=alias <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> return context_aware_object_factories.copy()",if not callable ( obj ) :,181
"def _formatparam(param, value=None, quote=True): <TAB> if value is not None and len(value) > 0: <TAB>  <TAB> if isinstance(value, tuple): <TAB>  <TAB>  <TAB> value = ""a"" <MASK> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""%s=%s"" % (param, value) <TAB> else: <TAB>  <TAB> return param",if quote or param :,93
"def process_data(self, data): <TAB> host_to_ips = {} <TAB> for interface, details in data.items(): <TAB>  <TAB> ips = [] <TAB>  <TAB> ip_details = details.get(self.ip_type) <TAB>  <TAB> if not ip_details: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> ips.append(ip_details[""address""]) <MASK> ips.extend([ip[""address""] for ip in ip_details[""additional_ips""]]) <TAB>  <TAB> host_to_ips[interface] = ips <TAB> return host_to_ips","if ""additional_ips"" in ip_details :",138
"def _get_error_file(self): <TAB> for error_handler in self._server_configuration.error_handlers or []: <MASK> return os.path.join( <TAB>  <TAB>  <TAB>  <TAB> self._server_configuration.application_root, error_handler.file <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> return None","if not error_handler . error_code or error_handler . error_code == ""default"" :",98
"def setComboValue(self, combo, value, t=""int""): <TAB> for i in range(combo.count()): <MASK> combo.setCurrentIndex(i) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if t == ""str"" and value == combo.itemData(i): <TAB>  <TAB>  <TAB> combo.setCurrentIndex(i) <TAB>  <TAB>  <TAB> break","if t == ""int"" and value == combo . itemData ( i ) :",96
"def read_isbn(self, f): <TAB> found = [] <TAB> for k, v in f.get_subfields([""a"", ""z""]): <TAB>  <TAB> m = re_isbn_and_price.match(v) <MASK> m = re_isbn.match(v) <TAB>  <TAB> if not m: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> found.append(m.group(1)) <TAB> return found",if not m :,104
"def open(self, name, mode=""r"", buffering=0): <TAB> ap = self.abspath(name) <TAB> self.log(""open {ap} with mode {m}\n"".format(ap=ap, m=mode)) <TAB> if ""r"" in mode: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> reader = ZipReader(self, ap, mode, buffering) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> raise errors.OperationFailure(""Not found!"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return reader <TAB> elif ""w"" in mode: <MASK> self._update(remove=[ap]) <TAB>  <TAB> return ZipWriter(self, ap, mode, buffering) <TAB> else: <TAB>  <TAB> raise errors.OperationFailure(""Unsupported mode!"")",if ap in self . zf . namelist ( ) :,177
"def chain(nested): <TAB> """"""itertools.chain() but leaves strings untouched"""""" <TAB> for i in nested: <MASK> yield from chain(i) <TAB>  <TAB> elif isinstance(i, BlueprintGroup): <TAB>  <TAB>  <TAB> yield from i.blueprints <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield i","if isinstance ( i , ( list , tuple ) ) :",82
"def __init__(self, ref, parent, sortkey, handle, secondary): <TAB> if sortkey: <TAB>  <TAB> self.name = sortkey <TAB>  <TAB> # sortkey must be localized sort, so <TAB>  <TAB> self.sortkey = glocale.sort_key(sortkey) <MASK> self.sortkey = glocale.sort_key("""") <TAB> else: <TAB>  <TAB> self.name = """" <TAB>  <TAB> self.sortkey = glocale.sort_key("""") <TAB> self.ref = ref <TAB> self.handle = handle <TAB> self.secondary = secondary <TAB> self.parent = parent <TAB> self.prev = None <TAB> self.next = None <TAB> self.children = []",if not self . sortkey :,160
"def set_variant(self, variant): <TAB> self.clear() <TAB> if variant is not None: <MASK> self.set_package(variant) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> self.set_package(variant.parent) <TAB>  <TAB> if variant.index is not None: <TAB>  <TAB>  <TAB> self.allow_selection = True <TAB>  <TAB>  <TAB> self.selectRow(variant.index) <TAB>  <TAB>  <TAB> self.allow_selection = False <TAB> self.variant = variant","if isinstance ( variant , Package ) :",116
"def visit_entry(self, node): <TAB> self.entry += 1 <TAB> if self.pep_table and self.entry == 2 and len(node) == 1: <TAB>  <TAB> node[""classes""].append(""num"") <TAB>  <TAB> p = node[0] <MASK> text = p.astext() <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> pep = int(text) <TAB>  <TAB>  <TAB>  <TAB> ref = self.document.settings.pep_base_url + self.pep_url % pep <TAB>  <TAB>  <TAB>  <TAB> p[0] = nodes.reference(text, text, refuri=ref) <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> pass","if isinstance ( p , nodes . paragraph ) and len ( p ) == 1 :",168
"def fill_config_with_default_values(config, default_values): <TAB> for section in default_values.keys(): <TAB>  <TAB> if not config.has_section(section): <TAB>  <TAB>  <TAB> config.add_section(section) <TAB>  <TAB> for (opt, val) in default_values[section].items(): <MASK> config.set(section, opt, f""{val}"")","if not config . has_option ( section , opt ) :",105
"def _add_embeddings_internal(self, sentences: List[Sentence]): <TAB> if type(sentences) is Sentence: <TAB>  <TAB> sentences = [sentences] <TAB> for embedding in self.embeddings: <TAB>  <TAB> embedding.embed(sentences) <TAB>  <TAB> # iterate over sentences <TAB>  <TAB> for sentence in sentences: <TAB>  <TAB>  <TAB> sentence: Sentence = sentence <TAB>  <TAB>  <TAB> # if its a forward LM, take last state <MASK> sentence.set_embedding( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> embedding.name, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> sentence[len(sentence) - 1]._embeddings[embedding.name], <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> sentence.set_embedding( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> embedding.name, sentence[0]._embeddings[embedding.name] <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return sentences",if embedding . is_forward_lm :,199
"def remove(files): <TAB> """"""Remove files and directories"""""" <TAB> for f in files.split(): <TAB>  <TAB> try: <MASK> shutil.rmtree(f) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> os.remove(f) <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> pass",if os . path . isdir ( f ) and not os . path . islink ( f ) :,90
"def check_materials(): <TAB> for obj in bpy.data.objects: <MASK> if obj.TLM_ObjectProperties.tlm_mesh_lightmap_use: <TAB>  <TAB>  <TAB>  <TAB> for slot in obj.material_slots: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> mat = slot.material <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if mat is None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if bpy.context.scene.TLM_SceneProperties.tlm_verbose: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> print(""MatNone"") <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> mat = bpy.data.materials.new(name=""Material"") <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> mat.use_nodes = True <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> slot.material = mat <TAB>  <TAB>  <TAB>  <TAB>  <TAB> nodes = mat.node_tree.nodes","if obj . type == ""MESH"" :",196
"def __cleanup_file(filename): <TAB> data = None <TAB> dirty = False <TAB> with open(filename, mode=""r"", newline="""") as file: <TAB>  <TAB> data = file.read() <MASK> data = data.replace(""\r\n"", ""\n"") <TAB>  <TAB>  <TAB> dirty = True <TAB>  <TAB> if ""\r"" in data: <TAB>  <TAB>  <TAB> data = data.replace(""\r"", ""\n"") <TAB>  <TAB>  <TAB> dirty = True <TAB> if dirty: <TAB>  <TAB> new_filename = filename + "".new"" <TAB>  <TAB> with open(new_filename, mode=""w"", newline=""\n"") as new_file: <TAB>  <TAB>  <TAB> new_file.write(data) <TAB>  <TAB> os.replace(new_filename, filename)","if ""\r\n"" in data :",177
"def _ext_service(self, entity_id, typ, service, binding): <TAB> try: <TAB>  <TAB> srvs = self[entity_id][typ] <TAB> except KeyError: <TAB>  <TAB> return None <TAB> if not srvs: <TAB>  <TAB> return srvs <TAB> res = [] <TAB> for srv in srvs: <TAB>  <TAB> if ""extensions"" in srv: <TAB>  <TAB>  <TAB> for elem in srv[""extensions""][""extension_elements""]: <MASK> if elem[""binding""] == binding: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> res.append(elem) <TAB> return res","if elem [ ""__class__"" ] == service :",142
"def _set_cache_value(self, key, value, type): <TAB> """"""Used internally by the accessor properties."""""" <TAB> if type is bool: <MASK> self[key] = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.pop(key, None) <TAB> else: <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB> self.pop(key, None) <TAB>  <TAB> elif value is True: <TAB>  <TAB>  <TAB> self[key] = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self[key] = value",if value :,124
"def lngettext(self, msgid1, msgid2, n): <TAB> try: <TAB>  <TAB> tmsg = self._catalog[(msgid1, self.plural(n))] <TAB>  <TAB> if self._output_charset: <TAB>  <TAB>  <TAB> return tmsg.encode(self._output_charset) <TAB>  <TAB> return tmsg.encode(locale.getpreferredencoding()) <TAB> except KeyError: <TAB>  <TAB> if self._fallback: <TAB>  <TAB>  <TAB> return self._fallback.lngettext(msgid1, msgid2, n) <MASK> return msgid1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return msgid2",if n == 1 :,144
"def colorformat(text): <TAB> if text[0:1] == ""#"": <TAB>  <TAB> col = text[1:] <TAB>  <TAB> if len(col) == 6: <TAB>  <TAB>  <TAB> return col <MASK> return col[0] + ""0"" + col[1] + ""0"" + col[2] + ""0"" <TAB> elif text == """": <TAB>  <TAB> return """" <TAB> assert False, ""wrong color format %r"" % text",elif len ( col ) == 3 :,111
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 8: <TAB>  <TAB>  <TAB> self.set_source(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 18: <TAB>  <TAB>  <TAB> length = d.getVarInt32() <TAB>  <TAB>  <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB>  <TAB>  <TAB> d.skip(length) <TAB>  <TAB>  <TAB> self.add_index_spec().TryMerge(tmp) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,169
"def getResults(self): <TAB> if hasattr(self, ""outputFile""): <TAB>  <TAB> return [os.path.join(self.dir, self.outputFile)] <TAB> else: <TAB>  <TAB> ignore_regexps = [re.compile(s) for s in getattr(self, ""ignorePatterns"", [])] <TAB>  <TAB> results = [] <TAB>  <TAB> for root, _, files in os.walk(self.output_dir()): <TAB>  <TAB>  <TAB> for name in files: <TAB>  <TAB>  <TAB>  <TAB> path = os.path.join(root, name) <MASK> results.append(path) <TAB>  <TAB> return results",if not any ( r . search ( path ) for r in ignore_regexps ) :,160
"def __cmp__(self, other): <TAB> if self.numberOfContours <= 0: <TAB>  <TAB> return cmp(self.__dict__, other.__dict__) <TAB> else: <TAB>  <TAB> if cmp(len(self.coordinates), len(other.coordinates)): <TAB>  <TAB>  <TAB> return 1 <TAB>  <TAB> ctest = Numeric.alltrue( <TAB>  <TAB>  <TAB> Numeric.alltrue(Numeric.equal(self.coordinates, other.coordinates)) <TAB>  <TAB> ) <TAB>  <TAB> ftest = Numeric.alltrue(Numeric.equal(self.flags, other.flags)) <MASK> return 1 <TAB>  <TAB> return cmp(self.endPtsOfContours, other.endPtsOfContours) or cmp( <TAB>  <TAB>  <TAB> self.program, other.instructions <TAB>  <TAB> )",if not ctest or not ftest :,180
"def time_single_gate_transpile(self): <TAB> if self.local_qasm_simulator is None: <TAB>  <TAB> self.single_gate_circuit.compile(""single_gate"") <TAB> else: <MASK> qiskit.compile(self.single_gate_circuit, self.local_qasm_simulator) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> circ = qiskit.compiler.transpile( <TAB>  <TAB>  <TAB>  <TAB> self.single_gate_circuit, self.local_qasm_simulator <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> qiskit.compiler.assemble(circ, self.local_qasm_simulator)",if self . has_compile :,162
"def update_sockets(self): <TAB> socket_info = parse_sockets(self) <TAB> if not socket_info[""inputs""]: <TAB>  <TAB> return <TAB> for k, v in socket_info.items(): <MASK> continue <TAB>  <TAB> if not self.add_or_update_sockets(k, v): <TAB>  <TAB>  <TAB> print(""failed to load sockets for "", k) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> self.flush_excess_sockets(k, v) <TAB> self.node_dict[hash(self)] = {} <TAB> self.node_dict[hash(self)][""sockets""] = socket_info <TAB> return True","if not ( k in { ""inputs"" , ""outputs"" } ) :",158
"def test_ranks(self): <TAB> """"""ranks lists are handled correctly"""""" <TAB> rank_user = create_test_user(""Visible"", ""visible@te.com"") <TAB> for rank in Rank.objects.iterator(): <TAB>  <TAB> rank_user.rank = rank <TAB>  <TAB> rank_user.save() <TAB>  <TAB> rank_link = reverse(""misago:users-rank"", kwargs={""slug"": rank.slug}) <TAB>  <TAB> response = self.client.get(rank_link) <MASK> self.assertEqual(response.status_code, 200) <TAB>  <TAB>  <TAB> self.assertContains(response, rank_user.get_absolute_url()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertEqual(response.status_code, 404)",if rank . is_tab :,175
"def __repr__(self): <TAB> result = [""<%s.%s"" % (self.__class__.__module__, self.__class__.__qualname__)] <TAB> if not self.closed: <TAB>  <TAB> result.append("" name=%r mode=%r"" % (self.name, self.mode)) <MASK> result.append( <TAB>  <TAB>  <TAB>  <TAB> "" compress_type=%s"" <TAB>  <TAB>  <TAB>  <TAB> % compressor_names.get(self._compress_type, self._compress_type) <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> result.append("" [closed]"") <TAB> result.append("">"") <TAB> return """".join(result)",if self . _compress_type != ZIP_STORED :,154
"def _recover_tasks(self, agent_tasks): <TAB> orphans = _drone_manager.get_orphaned_autoserv_processes() <TAB> for agent_task in agent_tasks: <TAB>  <TAB> agent_task.recover() <MASK> orphans.discard(agent_task.monitor.get_process()) <TAB>  <TAB> self.add_agent_task(agent_task) <TAB> self._check_for_remaining_orphan_processes(orphans)",if agent_task . monitor and agent_task . monitor . has_process ( ) :,123
"def cookie_added(self, cookie: QNetworkCookie): <TAB> if self.check_cookie_domain(cookie): <TAB>  <TAB> name = cookie.name().data().decode() <TAB>  <TAB> value = cookie.value().data().decode() <TAB>  <TAB> self.saved_cookies[name] = value <TAB>  <TAB> for _name in self.required_cookies: <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(self.required_cookies, self.saved_cookies) <TAB>  <TAB>  <TAB> self.succeed.emit(self.saved_cookies)",if _name not in self . saved_cookies :,139
"def delete_object(self, handle_list, link_type): <TAB> model = self._widget.get_model() <TAB> if model: <TAB>  <TAB> for o in model: <TAB>  <TAB>  <TAB> if o[0] == link_type: <TAB>  <TAB>  <TAB>  <TAB> data = pickle.loads(o[1]._obj) <MASK> model.remove(o.iter)",if data [ 2 ] in handle_list :,101
"def apply_changelog_batch( <TAB> self, <TAB> batch: Iterable[EventT], <TAB> to_key: Callable[[Any], KT], <TAB> to_value: Callable[[Any], VT],) -> None: <TAB> """"""Apply batch of events from changelog topic to this store."""""" <TAB> for event in batch: <TAB>  <TAB> key = event.message.key <MASK> raise TypeError(f""Changelog entry is missing key: {event.message}"") <TAB>  <TAB> value = event.message.value <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB> self._del(key) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # keys/values are already JSON serialized in the message <TAB>  <TAB>  <TAB> self._set(key, value)",if key is None :,170
"def execute(self, app): <TAB> n = self[""name""] <TAB> if not n or n == ""default"": <TAB>  <TAB> n = ""Bowl"" <TAB> bowl = Bowl(n) <TAB> blocks = bowl.calc(self.fromMm(""D""), math.radians(self[""res""]), self[""pocket""]) <TAB> if len(blocks) > 0: <TAB>  <TAB> active = app.activeBlock() <MASK> active = 1 <TAB>  <TAB> app.gcode.insBlocks(active, blocks, ""Create BOWL"") <TAB>  <TAB> app.refresh() <TAB>  <TAB> app.setStatus(_(""Generated: BOWL"")) <TAB> else: <TAB>  <TAB> app.setStatus(_(""Error: Check the Bowl and End Mill parameters""))",if active == 0 :,181
"def check_token(self): <MASK> return True <TAB> else: <TAB>  <TAB> new_UID = input(""Censys API UID:"") <TAB>  <TAB> new_secret = input(""Censys API SECRET"") <TAB>  <TAB> self.uid = new_UID <TAB>  <TAB> self.secret = new_secret <TAB>  <TAB> if self.token_is_available(): <TAB>  <TAB>  <TAB> self.write_conf() <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logger.error( <TAB>  <TAB>  <TAB>  <TAB> ""The shodan api token is incorrect. "" <TAB>  <TAB>  <TAB>  <TAB> ""Please enter the correct api token."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.check_token()",if self . token_is_available ( ) :,165
"def coords(cls, dataset, dim, ordered=False, expanded=False, edges=False): <TAB> dim = dataset.get_dimension(dim, strict=True) <TAB> if expanded: <TAB>  <TAB> data = util.expand_grid_coords(dataset, dim) <MASK> data = cls._infer_interval_breaks(data, axis=1) <TAB>  <TAB>  <TAB> data = cls._infer_interval_breaks(data, axis=0) <TAB>  <TAB> return data <TAB> values = cls.values(dataset, dim, expanded=False) <TAB> if edges: <TAB>  <TAB> return cls._infer_interval_breaks(values) <TAB> else: <TAB>  <TAB> return values",if edges and data . shape == dataset . data . shape :,165
"def _instantiate_client(client_class, **kwargs): <TAB> """"""Instantiate a client from kwargs, filtering kwargs to match client signature."""""" <TAB> args = get_arg_spec(client_class.__init__).args <TAB> for key in [ <TAB>  <TAB> ""subscription_id"", <TAB>  <TAB> ""tenant_id"", <TAB>  <TAB> ""base_url"", <TAB>  <TAB> ""credential"", <TAB>  <TAB> ""credentials"", <TAB> ]: <TAB>  <TAB> if key not in kwargs: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if key not in args: <TAB>  <TAB>  <TAB> del kwargs[key] <MASK> kwargs[key] = kwargs[key].encode(""utf-8"") <TAB> return client_class(**kwargs)","elif sys . version_info < ( 3 , 0 ) and isinstance ( kwargs [ key ] , unicode ) :",178
"def attach_cli(self, args, sep: str = ""_"") -> dict: <TAB> data = defaultdict(dict) <TAB> for name, value in args._get_kwargs(): <MASK> continue <TAB>  <TAB> parsed = name.split(sep, maxsplit=1) <TAB>  <TAB> if len(parsed) == 1: <TAB>  <TAB>  <TAB> data[name] = value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # if old content isn't a dict, override it <TAB>  <TAB>  <TAB> if not isinstance(data[parsed[0]], dict): <TAB>  <TAB>  <TAB>  <TAB> data[parsed[0]] = dict() <TAB>  <TAB>  <TAB> data[parsed[0]][parsed[1]] = value <TAB> self.attach(data) <TAB> return dict(data)",if value is None or value is False :,173
"def update_nets(self): <TAB> if util.frame_mod( <TAB>  <TAB> self.body.env.clock.frame, self.net.update_frequency, self.body.env.num_envs <TAB> ): <MASK> net_util.copy(self.net, self.target_net) <TAB>  <TAB> elif self.net.update_type == ""polyak"": <TAB>  <TAB>  <TAB> net_util.polyak_update(self.net, self.target_net, self.net.polyak_coef) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> 'Unknown net.update_type. Should be ""replace"" or ""polyak"". Exiting.' <TAB>  <TAB>  <TAB> )","if self . net . update_type == ""replace"" :",175
"def check_package_data(package_data): <TAB> """"""verify that package_data globs make sense"""""" <TAB> print(""checking package data"") <TAB> for pkg, data in package_data.items(): <TAB>  <TAB> pkg_root = pjoin(*pkg.split(""."")) <TAB>  <TAB> for d in data: <TAB>  <TAB>  <TAB> path = pjoin(pkg_root, d) <MASK> assert len(glob(path)) > 0, ""No files match pattern %s"" % path <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> assert os.path.exists(path), ""Missing package data: %s"" % path","if ""*"" in path :",146
"def set_source(self, stdlib_sources): <TAB> if self.file.startswith(""stdlib""): <TAB>  <TAB> if self.name in stdlib_sources: <TAB>  <TAB>  <TAB> self.source = stdlib_sources[self.name] <MASK> self.source = stdlib_sources[self.name.split(""."")[0]] <TAB> elif self.file[0] != ""/"": <TAB>  <TAB> self.source = ""pyjs"" <TAB> else: <TAB>  <TAB> self.source = ""other""","elif self . name . split ( ""."" ) [ 0 ] in stdlib_sources :",124
"def make_default_short_help(help, max_length=45): <TAB> """"""Return a condensed version of help string."""""" <TAB> words = help.split() <TAB> total_length = 0 <TAB> result = [] <TAB> done = False <TAB> for word in words: <TAB>  <TAB> if word[-1:] == ""."": <TAB>  <TAB>  <TAB> done = True <TAB>  <TAB> new_length = result and 1 + len(word) or len(word) <MASK> result.append(""..."") <TAB>  <TAB>  <TAB> done = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if result: <TAB>  <TAB>  <TAB>  <TAB> result.append("" "") <TAB>  <TAB>  <TAB> result.append(word) <TAB>  <TAB> if done: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> total_length += new_length <TAB> return """".join(result)",if total_length + new_length > max_length :,190
"def linux_capture_iptables(self): <TAB> self.iptables_captured = """" <TAB> ret = None <TAB> try: <TAB>  <TAB> p = subprocess.Popen([""iptables-save""], stdout=subprocess.PIPE) <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> buf = p.stdout.read() <MASK> break <TAB>  <TAB>  <TAB> self.iptables_captured += buf <TAB>  <TAB> if self.iptables_captured == """": <TAB>  <TAB>  <TAB> self.logger.warning(""Null iptables-save output, likely not "" + ""privileged"") <TAB>  <TAB> ret = p.wait() <TAB> except OSError as e: <TAB>  <TAB> self.logger.error(""Error executing iptables-save: %s"" % (e.message)) <TAB> return ret","if buf == """" :",173
"def process_hci_events(self, data): <TAB> """"""Parse HCI events."""""" <TAB> self.evt_cnt += 1 <TAB> if len(data) < 12: <TAB>  <TAB> return <TAB> msg, binary, measuring = self.parse_raw_message(data) <TAB> if msg: <TAB>  <TAB> if binary == measuring: <TAB>  <TAB>  <TAB> self.dataqueue_bin.sync_q.put_nowait(msg) <TAB>  <TAB>  <TAB> self.dataqueue_meas.sync_q.put_nowait(msg) <TAB>  <TAB> else: <MASK> self.dataqueue_bin.sync_q.put_nowait(msg) <TAB>  <TAB>  <TAB> if measuring is True: <TAB>  <TAB>  <TAB>  <TAB> self.dataqueue_meas.sync_q.put_nowait(msg)",if binary is True :,192
"def fmtL3Csums(self): <TAB> s = ""IP csum N/A"" <TAB> if self._is_ip: <TAB>  <TAB> if self.ipver == 4: <TAB>  <TAB>  <TAB> csum0 = hex(self._ipcsum0).rstrip(""L"") <TAB>  <TAB>  <TAB> if self._mangled: <TAB>  <TAB>  <TAB>  <TAB> self._calcCsums() <TAB>  <TAB>  <TAB>  <TAB> csum = hex(self._hdr.sum).rstrip(""L"") <TAB>  <TAB>  <TAB>  <TAB> s = ""IPv4 csum %s->%s"" % (csum0, csum) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> s = ""IPv4 csum %s"" % (csum0) <MASK> s = ""IPv6 csum N/A"" <TAB> return s",elif self . ipver == 6 :,186
"def when(self, matches, context): <TAB> ret = [] <TAB> for version in matches.named(""version""): <TAB>  <TAB> episode_number = matches.previous( <TAB>  <TAB>  <TAB> version, lambda match: match.name == ""episode"", 0 <TAB>  <TAB> ) <MASK> ret.append(version) <TAB> return ret",if not episode_number and not seps_surround ( version . initiator ) :,91
"def action(scheduler, state1=None): <TAB> nonlocal first <TAB> nonlocal state <TAB> has_result = False <TAB> result = None <TAB> try: <TAB>  <TAB> if first: <TAB>  <TAB>  <TAB> first = False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> state = iterate(state) <TAB>  <TAB> has_result = condition(state) <MASK> result = state <TAB> except Exception as exception:  # pylint: disable=broad-except <TAB>  <TAB> observer.on_error(exception) <TAB>  <TAB> return <TAB> if has_result: <TAB>  <TAB> observer.on_next(result) <TAB>  <TAB> mad.disposable = scheduler.schedule(action) <TAB> else: <TAB>  <TAB> observer.on_completed()",if has_result :,166
"def getTestCaseNames(self, caseclass): <TAB> names = super().getTestCaseNames(caseclass) <TAB> unfiltered_len = len(names) <TAB> if self.include or self.exclude: <MASK> names = filter(lambda n: any(r.search(n) for r in self.include), names) <TAB>  <TAB> if self.exclude: <TAB>  <TAB>  <TAB> names = filter(lambda n: not any(r.search(n) for r in self.exclude), names) <TAB>  <TAB> names = list(names) <TAB> if self.progress_cb: <TAB>  <TAB> self.progress_cb(len(names), unfiltered_len) <TAB> return names",if self . include :,157
"def create_package(source): <TAB> ofi = None <TAB> try: <TAB>  <TAB> for line in source.splitlines(): <TAB>  <TAB>  <TAB> if type(line) != bytes: <TAB>  <TAB>  <TAB>  <TAB> line = line.encode(""utf-8"") <TAB>  <TAB>  <TAB> if line.startswith(b"" "") or line.startswith(b""\t""): <TAB>  <TAB>  <TAB>  <TAB> ofi.write(line.strip() + b""\n"") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> if ofi: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ofi.close() <MASK> line = line.decode(""utf-8"") <TAB>  <TAB>  <TAB>  <TAB> ofi = open_file(os.path.join(TEST_DIR, line.strip())) <TAB> finally: <TAB>  <TAB> if ofi: <TAB>  <TAB>  <TAB> ofi.close()",if type ( line ) == bytes :,196
"def on_adapter_selected(self, cb_adapters): <TAB> logging.info(""selected"") <TAB> tree_iter = cb_adapters.get_active_iter() <TAB> if tree_iter: <TAB>  <TAB> adapter_path = cb_adapters.get_model().get_value(tree_iter, 1) <TAB>  <TAB> if self.List.Adapter: <MASK> # Stop discovering on previous adapter <TAB>  <TAB>  <TAB>  <TAB> self.List.Adapter.stop_discovery() <TAB>  <TAB>  <TAB>  <TAB> self.List.set_adapter(os.path.basename(adapter_path)) <TAB>  <TAB>  <TAB>  <TAB> # Start discovery on selected adapter <TAB>  <TAB>  <TAB>  <TAB> self.List.Adapter.start_discovery()",if self . List . Adapter . get_object_path ( ) != adapter_path :,178
"def test_request(self, request_mock, mock_response, check_call): <TAB> mock_response(request_mock, '{""foo"": ""baz""}', 200) <TAB> for method in VALID_API_METHODS: <TAB>  <TAB> abs_url = self.valid_url <TAB>  <TAB> data = """" <MASK> abs_url = ""%s?%s"" % (abs_url, data) <TAB>  <TAB>  <TAB> data = None <TAB>  <TAB> headers = {""my-header"": ""header val""} <TAB>  <TAB> body, code, _ = self.make_request(method, abs_url, headers, data) <TAB>  <TAB> assert code == 200 <TAB>  <TAB> assert body == '{""foo"": ""baz""}' <TAB>  <TAB> check_call(request_mock, method, abs_url, data, headers)","if method != ""post"" :",184
"def clear_suffix_value(self, suffix_or_name, expand=True): <TAB> """"""Clear the suffix value for this component data"""""" <TAB> if isinstance(suffix_or_name, six.string_types): <TAB>  <TAB> import pyomo.core.base.suffix <TAB>  <TAB> for name_, suffix_ in pyomo.core.base.suffix.active_suffix_generator( <TAB>  <TAB>  <TAB> self.model() <TAB>  <TAB> ): <MASK> suffix_.clear_value(self, expand=expand) <TAB>  <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> suffix_or_name.clear_value(self, expand=expand)",if suffix_or_name == name_ :,158
"def verify_procs(hostname, old, new): <TAB> oldpids = set(pid for pid, _ in old) <TAB> if any(pid not in oldpids for pid, _ in new): <TAB>  <TAB> print(""%r had stray processes running:"" % (hostname,)) <TAB>  <TAB> for pid, line in new: <MASK> print(""New process:"", line) <TAB>  <TAB> print() <TAB>  <TAB> return False <TAB> return True",if pid not in oldpids :,107
"def _fixresult(self, widget, result): <TAB> if isinstance(result, tuple): <TAB>  <TAB> # multiple results: <TAB>  <TAB> result = tuple([getattr(r, ""string"", r) for r in result]) <MASK> import os <TAB>  <TAB>  <TAB> path, file = os.path.split(result[0]) <TAB>  <TAB>  <TAB> self.options[""initialdir""] = path <TAB>  <TAB>  <TAB> # don't set initialfile or filename, as we have multiple of these <TAB>  <TAB> return result <TAB> if not widget.tk.wantobjects() and ""multiple"" in self.options: <TAB>  <TAB> # Need to split result explicitly <TAB>  <TAB> return self._fixresult(widget, widget.tk.splitlist(result)) <TAB> return _Dialog._fixresult(self, widget, result)",if result :,183
"def __set__(self, instance, value): <TAB> if not isinstance(value, self.type): <TAB>  <TAB> raise TypeError(f""{self.name!r} values must be of type {self.type!r}"") <TAB> for validator in self.validators: <TAB>  <TAB> validator(self.name, value) <TAB> if self.name in instance.__dict__: <TAB>  <TAB> oldval = instance.__dict__[self.name] <TAB>  <TAB> for mutator in self.mutators: <TAB>  <TAB>  <TAB> value = mutator(self.name, value) <MASK> on_prop = getattr(instance, f""on_{self.name}"", None) <TAB>  <TAB>  <TAB> if on_prop: <TAB>  <TAB>  <TAB>  <TAB> on_prop(self.name, oldval, value) <TAB> instance.__dict__[self.name] = value",if value != oldval :,190
"def optimizer_array(self, p): <TAB> if self.mpi_comm != None: <MASK> self.mpi_comm.Bcast(np.int32(1), root=0) <TAB>  <TAB> self.mpi_comm.Bcast(p, root=0) <TAB> Model.optimizer_array.fset(self, p)",if self . _IN_OPTIMIZATION_ and self . mpi_comm . rank == 0 :,101
"def http_endTree(self, filename, p, justOneFile): <TAB> """"""Do end-of-tree processing to support the http plugin."""""" <TAB> if self.getOption(p, ""http_server_support"") and self.getOption(p, ""generate_rst""): <TAB>  <TAB> self.set_initial_http_attributes(filename, p) <TAB>  <TAB> self.find_anchors(p) <MASK> self.relocate_references(p.self_and_subtree) <TAB>  <TAB> g.blue(""html updated for http plugin"") <TAB>  <TAB> if self.getOption(p, ""clear_http_attributes""): <TAB>  <TAB>  <TAB> g.es_print(""http attributes cleared"")",if justOneFile :,163
"def execute(self): <TAB> options = self.get_options() <TAB> if options.command: <MASK> raise TaskError( <TAB>  <TAB>  <TAB>  <TAB> ""Buildozer custom command cannot be used together with "" <TAB>  <TAB>  <TAB>  <TAB> + ""--add-dependencies or --remove-dependencies."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self._execute_buildozer_script(options.command) <TAB> if options.add_dependencies: <TAB>  <TAB> self._execute_buildozer_script( <TAB>  <TAB>  <TAB> ""add dependencies {}"".format(options.add_dependencies) <TAB>  <TAB> ) <TAB> if options.remove_dependencies: <TAB>  <TAB> self._execute_buildozer_script( <TAB>  <TAB>  <TAB> ""remove dependencies {}"".format(options.remove_dependencies) <TAB>  <TAB> )",if options . add_dependencies or options . remove_dependencies :,186
"def getPath(self, org=False, toplevel=False): <TAB> """"""Returns this menu's path in the menu structure."""""" <TAB> parent = self <TAB> names = [] <TAB> while 1: <TAB>  <TAB> if org: <TAB>  <TAB>  <TAB> names.append(parent.Name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> names.append(parent.getName()) <MASK> parent = parent.Parent <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> names.reverse() <TAB> path = """" <TAB> if not toplevel: <TAB>  <TAB> names.pop(0) <TAB> for name in names: <TAB>  <TAB> path = os.path.join(path, name) <TAB> return path",if parent . Depth > 0 :,160
"def eval_dummy_genomes_ctrnn(genomes, config): <TAB> for genome_id, genome in genomes: <TAB>  <TAB> net = neat.ctrnn.CTRNN.create(genome, config, 0.01) <MASK> genome.fitness = 0.0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> net.reset() <TAB>  <TAB>  <TAB> genome.fitness = 1.0",if genome_id <= 150 :,109
"def AddSegments(self, points, labels, colors): <TAB> """"""DEPRECATED."""""" <TAB> warnings.warn( <TAB>  <TAB> ""PieChart.AddSegments is deprecated. Call AddPie instead. "", <TAB>  <TAB> DeprecationWarning, <TAB>  <TAB> stacklevel=2, <TAB> ) <TAB> num_colors = len(colors or []) <TAB> for i, pt in enumerate(points): <TAB>  <TAB> assert pt >= 0 <TAB>  <TAB> label = labels[i] <TAB>  <TAB> color = None <MASK> color = colors[i] <TAB>  <TAB> self.AddSegment(pt, label=label, color=color)",if i < num_colors :,142
"def add_subparser(self, subparsers): <TAB> opts = { <TAB>  <TAB> ""prog"": self.name_with_alias, <TAB>  <TAB> ""help"": self.__doc__, <TAB>  <TAB> ""description"": self.__doc__, <TAB> } <TAB> if self.usage: <TAB>  <TAB> opts[""usage""] = self.usage <TAB> # A workaround for aliases showing as duplicate command names in help output. <TAB> for cmd_name in sorted([self.name] + self.aliases): <MASK> if cmd_name in self.aliases: <TAB>  <TAB>  <TAB>  <TAB> opts[""help""] = _(""`%s` alias"" % self.name) <TAB>  <TAB>  <TAB> parser = subparsers.add_parser(cmd_name, **opts) <TAB>  <TAB>  <TAB> break <TAB> self.add_arguments(parser)",if cmd_name not in subparsers . _name_parser_map :,193
"def server(self, server): <TAB> self._server = server <TAB> if self.orm_spawner: <TAB>  <TAB> if self.orm_spawner.server is not None: <TAB>  <TAB>  <TAB> # delete the old value <TAB>  <TAB>  <TAB> db = inspect(self.orm_spawner.server).session <TAB>  <TAB>  <TAB> db.delete(self.orm_spawner.server) <MASK> self.orm_spawner.server = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.orm_spawner.server = server.orm_server",if server is None :,124
"def getnextfile(f): <TAB> while 1: <TAB>  <TAB> line = f.readline() <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> if startprog.match(line) >= 0: <TAB>  <TAB>  <TAB> file = startprog.group(1) <TAB>  <TAB>  <TAB> # Skip until first revision <TAB>  <TAB>  <TAB> while 1: <TAB>  <TAB>  <TAB>  <TAB> line = f.readline() <TAB>  <TAB>  <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return None <MASK> return None <TAB>  <TAB>  <TAB>  <TAB> if line[:10] == ""-"" * 10: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> ## <TAB>  <TAB>  <TAB>   print ""Skipped"", line, <TAB>  <TAB>  <TAB> return file","if line [ : 10 ] == ""="" * 10 :",181
"def get_process_mapping(): <TAB> """"""Try to look up the process tree via the /proc interface."""""" <TAB> stat_name = detect_proc() <TAB> self_tty = _get_stat(os.getpid(), stat_name)[0] <TAB> processes = {} <TAB> for pid in os.listdir(""/proc""): <TAB>  <TAB> if not pid.isdigit(): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> tty, ppid = _get_stat(pid, stat_name) <MASK> continue <TAB>  <TAB>  <TAB> args = _get_cmdline(pid) <TAB>  <TAB>  <TAB> processes[pid] = Process(args=args, pid=pid, ppid=ppid) <TAB>  <TAB> except IOError: <TAB>  <TAB>  <TAB> # Process has disappeared - just ignore it. <TAB>  <TAB>  <TAB> continue <TAB> return processes",if tty != self_tty :,193
"def do_batch_show(args): <TAB> rest_client = RestClient(args.url, args.user) <TAB> output = rest_client.get_batch(args.batch_id) <TAB> if args.key: <TAB>  <TAB> if args.key in output: <TAB>  <TAB>  <TAB> output = output[args.key] <MASK> output = output[""header""][args.key] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise CliException('key ""{}"" not found in batch or header'.format(args.key)) <TAB> if args.format == ""yaml"": <TAB>  <TAB> fmt.print_yaml(output) <TAB> elif args.format == ""json"": <TAB>  <TAB> fmt.print_json(output) <TAB> else: <TAB>  <TAB> raise AssertionError(""Missing handler: {}"".format(args.format))","elif args . key in output [ ""header"" ] :",190
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.add_blob_key(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 10 :,92
"def __iter__(self): <TAB> """"""Parse self.code and yield ""classified"" tokens."""""" <TAB> if self.lexer is None: <TAB>  <TAB> yield ([], self.code) <TAB>  <TAB> return <TAB> tokens = pygments.lex(self.code, self.lexer) <TAB> for tokentype, value in self.merge(tokens): <MASK> # long CSS class args <TAB>  <TAB>  <TAB> classes = str(tokentype).lower().split(""."") <TAB>  <TAB> else:  # short CSS class args <TAB>  <TAB>  <TAB> classes = [_get_ttype_class(tokentype)] <TAB>  <TAB> classes = [cls for cls in classes if cls not in unstyled_tokens] <TAB>  <TAB> yield (classes, value)","if self . tokennames == ""long"" :",160
"def actor_from_request(datasette, request): <TAB> if ""ds_actor"" not in request.cookies: <TAB>  <TAB> return None <TAB> try: <TAB>  <TAB> decoded = datasette.unsign(request.cookies[""ds_actor""], ""actor"") <TAB>  <TAB> # If it has ""e"" and ""a"" keys process the ""e"" expiry <TAB>  <TAB> if not isinstance(decoded, dict) or ""a"" not in decoded: <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> expires_at = decoded.get(""e"") <TAB>  <TAB> if expires_at: <TAB>  <TAB>  <TAB> timestamp = int(baseconv.base62.decode(expires_at)) <MASK> return None <TAB>  <TAB> return decoded[""a""] <TAB> except BadSignature: <TAB>  <TAB> return None",if time . time ( ) > timestamp :,182
"def _add_py_deps(self, zip_fileobj, deps_dir): <TAB> # type: (ZipFile, str) -> None <TAB> prefix_len = len(deps_dir) + 1 <TAB> for root, dirnames, filenames in self._osutils.walk(deps_dir): <MASK> # Don't include any chalice deps.  We cherry pick <TAB>  <TAB>  <TAB> # what we want to include in _add_app_files. <TAB>  <TAB>  <TAB> dirnames.remove(""chalice"") <TAB>  <TAB> for filename in filenames: <TAB>  <TAB>  <TAB> full_path = self._osutils.joinpath(root, filename) <TAB>  <TAB>  <TAB> zip_path = full_path[prefix_len:] <TAB>  <TAB>  <TAB> zip_fileobj.write(full_path, zip_path)","if root == deps_dir and ""chalice"" in dirnames :",196
"def get_byfilter(userId, session=None, **kwargs): <TAB> if not session: <TAB>  <TAB> session = db.Session <TAB> ret = [] <TAB> kwargs[""userId""] = userId <TAB> results = ( <TAB>  <TAB> session.query(CatalogImageDocker) <TAB>  <TAB> .filter_by(**kwargs) <TAB>  <TAB> .order_by(desc(CatalogImageDocker.created_at)) <TAB> ) <TAB> for result in results: <TAB>  <TAB> dbobj = dict( <TAB>  <TAB>  <TAB> (key, value) <TAB>  <TAB>  <TAB> for key, value in vars(result).items() <MASK> ) <TAB>  <TAB> ret.append(dbobj) <TAB> return ret","if not key . startswith ( ""_"" )",164
"def flatten_nested(data_struct): <TAB> """"""Flatten data struct of obj or `list`/`dict` of obj"""""" <TAB> if isinstance(data_struct, dict): <TAB>  <TAB> data_struct = list(flatten_nest_dict(data_struct).values()) <MASK> data_struct = [x for sublist in data_struct for x in sublist] <TAB> if isinstance(data_struct, (list, tuple)): <TAB>  <TAB> return data_struct <TAB> # Singleton <TAB> return [data_struct]","if data_struct and isinstance ( data_struct [ 0 ] , ( list , tuple ) ) :",135
"def __exit__(self, exc_type, exc_value, traceback): <TAB> if isinstance(exc_value, Utils.subprocess.CalledProcessError): <TAB>  <TAB> messages = [ <TAB>  <TAB>  <TAB> m <TAB>  <TAB>  <TAB> for m in exc_value.output.splitlines() <MASK> ] <TAB>  <TAB> for message in messages: <TAB>  <TAB>  <TAB> self.write(message) <TAB>  <TAB> return True","if ""Done processing"" not in m and ""Total errors found"" not in m",106
"def reader(): <TAB> batch_out = [] <TAB> for item in fl: <TAB>  <TAB> fileinfo = item.split("" "") <TAB>  <TAB> filepath = fileinfo[0] <TAB>  <TAB> rgb = np.load(filepath, allow_pickle=True) <TAB>  <TAB> nframes = rgb.shape[0] <TAB>  <TAB> label = [int(i) for i in fileinfo[1:]] <TAB>  <TAB> one_hot_label = make_one_hot(label, self.num_classes) <TAB>  <TAB> if self.mode != ""infer"": <TAB>  <TAB>  <TAB> batch_out.append((rgb, one_hot_label)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> batch_out.append((rgb, filepath.split(""/"")[-1])) <MASK> yield batch_out <TAB>  <TAB>  <TAB> batch_out = []",if len ( batch_out ) == self . batch_size :,191
"def form_view(request): <TAB> ""A view that tests a simple form"" <TAB> if request.method == ""POST"": <TAB>  <TAB> form = TestForm(request.POST) <MASK> t = Template(""Valid POST data."", name=""Valid POST Template"") <TAB>  <TAB>  <TAB> c = Context() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> t = Template( <TAB>  <TAB>  <TAB>  <TAB> ""Invalid POST data. {{ form.errors }}"", name=""Invalid POST Template"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> c = Context({""form"": form}) <TAB> else: <TAB>  <TAB> form = TestForm(request.GET) <TAB>  <TAB> t = Template(""Viewing base form. {{ form }}."", name=""Form GET Template"") <TAB>  <TAB> c = Context({""form"": form}) <TAB> return HttpResponse(t.render(c))",if form . is_valid ( ) :,189
"def extract(self): <TAB> for name in self.vars: <TAB>  <TAB> self.val[name] = 0 <TAB> for l in self.splitlines(): <TAB>  <TAB> if l[3] == ""07"": <TAB>  <TAB>  <TAB> self.val[""listen""] += 1 <MASK> self.val[""established""] += 1","elif l [ 3 ] == ""01"" :",84
"def OnBodyRClick(self, event=None): <TAB> try: <TAB>  <TAB> c = self.c <TAB>  <TAB> p = c.currentPosition() <MASK> pass  # By default Leo does nothing. <TAB>  <TAB> g.doHook(""bodyrclick2"", c=c, p=p, v=p, event=event) <TAB> except: <TAB>  <TAB> g.es_event_exception(""iconrclick"")","if not g . doHook ( ""bodyrclick1"" , c = c , p = p , v = p , event = event ) :",128
"def resources_to_link(self, resources): <TAB> if isinstance(self.UserPool, dict) and ""Ref"" in self.UserPool: <TAB>  <TAB> userpool_id = self.UserPool[""Ref""] <TAB>  <TAB> if not isinstance(userpool_id, string_types): <TAB>  <TAB>  <TAB> raise InvalidEventException( <TAB>  <TAB>  <TAB>  <TAB> self.logical_id, <TAB>  <TAB>  <TAB>  <TAB> ""Ref in Userpool is not a string."", <TAB>  <TAB>  <TAB> ) <MASK> return {""userpool"": resources[userpool_id], ""userpool_id"": userpool_id} <TAB> raise InvalidEventException( <TAB>  <TAB> self.relative_id, <TAB>  <TAB> ""Cognito events must reference a Cognito UserPool in the same template."", <TAB> )",if userpool_id in resources :,183
"def process(self, resources, event=None): <TAB> client = local_session(self.manager.session_factory).client( <TAB>  <TAB> ""securityhub"", region_name=self.data.get(""region"") <TAB> ) <TAB> found = [] <TAB> params = dict(self.data.get(""query"", {})) <TAB> for r_arn, resource in zip(self.manager.get_arns(resources), resources): <TAB>  <TAB> params[""ResourceId""] = [{""Value"": r_arn, ""Comparison"": ""EQUALS""}] <TAB>  <TAB> findings = client.get_findings(Filters=params).get(""Findings"") <MASK> resource[self.annotation_key] = findings <TAB>  <TAB>  <TAB> found.append(resource) <TAB> return found",if len ( findings ) > 0 :,183
"def balanced_parens(line, mincol=0, maxcol=None, lexer=None): <TAB> """"""Determines if parentheses are balanced in an expression."""""" <TAB> line = line[mincol:maxcol] <TAB> if lexer is None: <TAB>  <TAB> lexer = builtins.__xonsh__.execer.parser.lexer <TAB> if ""("" not in line and "")"" not in line: <TAB>  <TAB> return True <TAB> cnt = 0 <TAB> lexer.input(line) <TAB> for tok in lexer: <MASK> cnt += 1 <TAB>  <TAB> elif tok.type == ""RPAREN"": <TAB>  <TAB>  <TAB> cnt -= 1 <TAB>  <TAB> elif tok.type == ""ERRORTOKEN"" and "")"" in tok.value: <TAB>  <TAB>  <TAB> cnt -= 1 <TAB> return cnt == 0",if tok . type in LPARENS :,176
"def operand_name(self): <TAB> """"""A fancy name based on what operation is being performed"""""" <TAB> if self.__index == 0: <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB> ""first operand"" <TAB>  <TAB>  <TAB> if self.__operation in (O_ADD, O_MULTIPLY) <TAB>  <TAB>  <TAB> else ""minuend"" <MASK> else ""numerator"" <TAB>  <TAB> ) <TAB> elif self.__index == 1: <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB> ""second operand"" <TAB>  <TAB>  <TAB> if self.__operation in (O_ADD, O_MULTIPLY) <TAB>  <TAB>  <TAB> else ""subtrahend"" <TAB>  <TAB>  <TAB> if self.__operation == O_SUBTRACT <TAB>  <TAB>  <TAB> else ""denominator"" <TAB>  <TAB> )",if self . __operation == O_SUBTRACT,174
"def test_scanner(data_filename, canonical_filename, verbose=False): <TAB> for filename in [data_filename, canonical_filename]: <TAB>  <TAB> tokens = [] <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> for token in yaml.scan(open(filename, ""rb"")): <TAB>  <TAB>  <TAB>  <TAB> tokens.append(token.__class__.__name__) <TAB>  <TAB> finally: <MASK> pprint.pprint(tokens)",if verbose :,99
"def draw3d(self, value): <TAB> if value is True: <TAB>  <TAB> if self.depthMask is False: <TAB>  <TAB>  <TAB> self.depthMask = True <MASK> self.depthTest = True <TAB>  <TAB> if self.cullFace is False: <TAB>  <TAB>  <TAB> self.cullFace = True <TAB> elif value is False: <TAB>  <TAB> if self.depthMask is True: <TAB>  <TAB>  <TAB> self.depthMask = False <TAB>  <TAB> if self.depthTest is True: <TAB>  <TAB>  <TAB> self.depthTest = False <TAB>  <TAB> if self.cullFace is True: <TAB>  <TAB>  <TAB> self.cullFace = False <TAB> else: <TAB>  <TAB> raise TypeError(""Value must be type `bool`."") <TAB> self._draw3d = value",if self . depthTest is False :,180
"def visit_expr(self, expr): <TAB> if ( <TAB>  <TAB> expr.op == idaapi.cot_call <TAB>  <TAB> and expr.x.op == idaapi.cot_obj <TAB>  <TAB> and expr.x.obj_ea == self.__func_addr <TAB> ): <TAB>  <TAB> arg_expr = expr.a[self.__arg_idx] <MASK> cexpr_ea = helper.find_asm_address(expr, self.parents) <TAB>  <TAB>  <TAB> logger.error( <TAB>  <TAB>  <TAB>  <TAB> ""Argument is a not string at {}"".format(helper.to_hex(cexpr_ea)) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return 1 <TAB>  <TAB> self.__add_func_name(arg_expr) <TAB> return 0",if arg_expr . op != idaapi . cot_obj :,187
"def _fancy_helper(self, a, alo, ahi, b, blo, bhi): <TAB> g = [] <TAB> if alo < ahi: <MASK> g = self._fancy_replace(a, alo, ahi, b, blo, bhi) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> g = self._dump(""-"", a, alo, ahi) <TAB> elif blo < bhi: <TAB>  <TAB> g = self._dump(""+"", b, blo, bhi) <TAB> yield from g",if blo < bhi :,132
"def should_delete_both_parens(self, doc, event): <TAB> if event.keyval == gtk.keysyms.BackSpace: <TAB>  <TAB> it = doc.get_iter_at_mark(doc.get_insert()) <TAB>  <TAB> current_char = it.get_char() <MASK> it.backward_char() <TAB>  <TAB>  <TAB> previous_char = it.get_char() <TAB>  <TAB>  <TAB> matching_paren = self.get_matching_opening_paren(current_char) <TAB>  <TAB>  <TAB> return previous_char == matching_paren <TAB> return False",if self . is_closing_paren ( current_char ) :,145
"def _pci_reset(config, available_modules): <TAB> logger = get_logger() <TAB> _unload_bbswitch(available_modules) <TAB> try: <TAB>  <TAB> if config[""optimus""][""pci_reset""] == ""function_level"": <TAB>  <TAB>  <TAB> logger.info(""Performing function-level reset of Nvidia"") <TAB>  <TAB>  <TAB> pci.function_level_reset_nvidia() <MASK> logger.info(""Starting hot reset sequence"") <TAB>  <TAB>  <TAB> pci.hot_reset_nvidia() <TAB> except pci.PCIError as e: <TAB>  <TAB> raise KernelSetupError(f""Failed to perform PCI reset: {e}"") from e","elif config [ ""optimus"" ] [ ""pci_reset"" ] == ""hot_reset"" :",170
"def _threaded(self, *a): <TAB> while not self._killed: <TAB>  <TAB> self.p = subprocess.Popen(self.args, stdin=None) <TAB>  <TAB> self.p.communicate() <MASK> log.warning(""%s exited with code 8; not restarting"", self.binary_name) <TAB>  <TAB>  <TAB> self.p = None <TAB>  <TAB>  <TAB> return <TAB>  <TAB> self.p = None <TAB>  <TAB> if not self._killed: <TAB>  <TAB>  <TAB> log.warning( <TAB>  <TAB>  <TAB>  <TAB> ""%s died; restarting after %ss"", self.binary_name, self.restart_after <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> time.sleep(self.restart_after)",if self . p and self . p . returncode == 8 :,168
"def wait_for_processes(timeout=1, *processes): <TAB> started = time.time() <TAB> timeout = max(timeout, 1) <TAB> while time.time() - started < timeout: <TAB>  <TAB> all_stopped = True <TAB>  <TAB> for process in processes: <MASK> all_stopped = False <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if all_stopped: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> time.sleep(0.5)",if ProcessMonitor . is_process_alive ( process ) :,117
"def containers_built_for_services(self, services): <TAB> # Verify all images are built <TAB> for service_name in services: <TAB>  <TAB> logger.info(u""Verifying service image"", service=service_name) <TAB>  <TAB> image_id = self.get_latest_image_id_for_service(service_name) <MASK> raise exceptions.AnsibleContainerMissingImage( <TAB>  <TAB>  <TAB>  <TAB> u""Missing image for service '{}'. Run 'ansible-container build' to (re)create it."".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> service_name <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> )",if image_id is None :,146
"def _getListSpecFiles(self, path): <TAB> listSpecFiles = [] <TAB> for dirEntry in os.listdir(path): <TAB>  <TAB> dirEntryPath = os.path.join(path, dirEntry) <MASK> listSpecFiles.append(dirEntryPath) <TAB>  <TAB> elif os.path.isdir(dirEntryPath): <TAB>  <TAB>  <TAB> listSpecFiles.extend(self._getListSpecFiles(dirEntryPath)) <TAB> return listSpecFiles","if os . path . isfile ( dirEntryPath ) and dirEntryPath . endswith ( "".spec"" ) :",127
"def optimize_circuit(self, circuit: _circuit.Circuit) -> None: <TAB> deletions: List[Tuple[int, ops.Operation]] = [] <TAB> for moment_index, moment in enumerate(circuit): <TAB>  <TAB> for op in moment.operations: <MASK> deletions.append((moment_index, op)) <TAB> circuit.batch_remove(deletions)",if op is not None and protocols . trace_distance_bound ( op ) <= self . tolerance :,110
"def comment(string): <TAB> if string is not None: <MASK> print(""/* [%s]\n%s\n*/\n"" % (str(os.getpid()), string)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""-- [%s] %s"" % (str(os.getpid()), string))","if re . match ( "".*\\n.*"" , string ) is not None :",87
"def recursive_iter(self, obj): <TAB> if isinstance(obj, dict): <TAB>  <TAB> for key, value in obj.items(): <TAB>  <TAB>  <TAB> match = isinstance(value, string_types) and re.search( <TAB>  <TAB>  <TAB>  <TAB> r""(\d{4}-\d{2}-\d{2}).*"", value <TAB>  <TAB>  <TAB> ) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> obj[key] = pd.to_datetime(value, utc=True) <TAB>  <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass <TAB> elif any(isinstance(obj, t) for t in (list, tuple)): <TAB>  <TAB> for item in obj: <TAB>  <TAB>  <TAB> self.recursive_iter(item)",if match :,167
"def power_series_all_data(self, **kwargs): <TAB> chunks = [] <TAB> for series in self.power_series(**kwargs): <MASK> chunks.append(series) <TAB> if chunks: <TAB>  <TAB> # Get rid of overlapping indicies <TAB>  <TAB> prev_end = None <TAB>  <TAB> for i, chunk in enumerate(chunks): <TAB>  <TAB>  <TAB> if i > 0: <TAB>  <TAB>  <TAB>  <TAB> if chunk.index[0] <= prev_end: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> chunks[i] = chunk.iloc[1:] <TAB>  <TAB>  <TAB> prev_end = chunk.index[-1] <TAB>  <TAB> all_data = pd.concat(chunks) <TAB> else: <TAB>  <TAB> all_data = None <TAB> return all_data",if len ( series ) > 0 :,177
"def allocate_address(self): <TAB> domain = self._get_param(""Domain"", if_none=""standard"") <TAB> reallocate_address = self._get_param(""Address"", if_none=None) <TAB> if self.is_not_dryrun(""AllocateAddress""): <MASK> address = self.ec2_backend.allocate_address( <TAB>  <TAB>  <TAB>  <TAB> domain, address=reallocate_address <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> address = self.ec2_backend.allocate_address(domain) <TAB>  <TAB> template = self.response_template(ALLOCATE_ADDRESS_RESPONSE) <TAB>  <TAB> return template.render(address=address)",if reallocate_address :,161
"def main(self): <TAB> active_handle = self.get_active(""Media"") <TAB> if active_handle: <TAB>  <TAB> media = self.dbstate.db.get_media_from_handle(active_handle) <TAB>  <TAB> self.top.hide() <MASK> self.load_image(media) <TAB>  <TAB>  <TAB> self.set_has_data(True) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.photo.set_image(None) <TAB>  <TAB>  <TAB> self.set_has_data(False) <TAB>  <TAB> self.top.show() <TAB> else: <TAB>  <TAB> self.set_has_data(False)",if media :,151
"def readlines(self): <TAB> try: <TAB>  <TAB> with open(self.path, mode=""r"", encoding=""UTF-8"") as fh: <TAB>  <TAB>  <TAB> return [l.lstrip(""\ufeff"").replace(""\x00"", """") for l in fh] <TAB>  <TAB>  <TAB> # Strip unicode byte order mark <TAB>  <TAB>  <TAB> # And remove any NULL byte since they screw up parsing <TAB> except UnicodeDecodeError as err: <TAB>  <TAB> raise FileUnicodeError(self, err) <TAB> except IOError: <MASK> raise FileNotFoundError(self) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise",if not self . exists ( ) :,136
"def _filehandle(self, filename): <TAB> for name in filter( <TAB>  <TAB> lambda f: filename and f.lower() == filename.lower()[1:], <TAB>  <TAB> self.ziphandle.namelist(), <TAB> ): <TAB>  <TAB> # python2.4 fix <MASK> return StringIO(self.ziphandle.read(name)) <TAB>  <TAB> return self.ziphandle.open(name, ""r"") <TAB> return None","if not hasattr ( self . ziphandle , ""open"" ) :",117
"def attachments_dir(self, page): <TAB> if self.namespace: <MASK> return self.dir <TAB>  <TAB> elif page.ischild(self.namespace): <TAB>  <TAB>  <TAB> path = page.relname(self.namespace) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise PathLookupError(""%s not a child of %s"" % (page, self.namespace)) <TAB>  <TAB> name = page.relname(self.namespace) <TAB> else: <TAB>  <TAB> name = page.name <TAB> return self.dir.folder(encode_filename(name))",if page == self . namespace :,131
"def datetime_from_position(start, position, resolution): <TAB> """"""Finds time granularity of data."""""" <TAB> m = re.search(r""PT(\d+)([M])"", resolution) <TAB> if m: <TAB>  <TAB> digits = int(m.group(1)) <TAB>  <TAB> scale = m.group(2) <MASK> return start.replace(minutes=(position - 1) * digits) <TAB> raise NotImplementedError(""Could not recognise resolution %s"" % resolution)","if scale == ""M"" :",113
"def handle_m2m_field(self, obj, field): <TAB> if field.rel.through._meta.auto_created: <MASK> m2m_value = lambda value: value.natural_key() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> m2m_value = lambda value: smart_unicode( <TAB>  <TAB>  <TAB>  <TAB> value._get_pk_val(), strings_only=True <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self._current[field.name] = [ <TAB>  <TAB>  <TAB> m2m_value(related) for related in getattr(obj, field.name).iterator() <TAB>  <TAB> ]","if self . use_natural_keys and hasattr ( field . rel . to , ""natural_key"" ) :",162
"def add_discid(self, discid): <TAB> if not discid: <TAB>  <TAB> return <TAB> self._discids.add(discid) <TAB> for track in self.tracks: <TAB>  <TAB> medium_discids = track.metadata.getall(""~musicbrainz_discids"") <TAB>  <TAB> track_discids = list(self._discids.intersection(medium_discids)) <MASK> track.metadata[""musicbrainz_discid""] = track_discids <TAB>  <TAB>  <TAB> track.update() <TAB>  <TAB>  <TAB> for file in track.linked_files: <TAB>  <TAB>  <TAB>  <TAB> file.metadata[""musicbrainz_discid""] = track_discids <TAB>  <TAB>  <TAB>  <TAB> file.update()",if track_discids :,161
"def format(self, record: LogRecord): <TAB> record.levelname = self.get_level(record) <TAB> try: <TAB>  <TAB> cur_thread = self._ql.os.thread_management.cur_thread <MASK> record.levelname = f""{record.levelname} {str(cur_thread)}"" <TAB> except AttributeError: <TAB>  <TAB> pass <TAB> return super(QilingPlainFormatter, self).format(record)",if cur_thread is not None :,106
"def verify_emit_internet_name(self, hostname, pevent): <TAB> if f""INTERNET_NAME:{hostname}"" in self.results: <TAB>  <TAB> return False <TAB> if not self.getTarget().matches(hostname): <TAB>  <TAB> return False <TAB> if self.opts[""verify""] and not self.sf.resolveHost(hostname): <TAB>  <TAB> self.sf.debug(f""Host {hostname} could not be resolved"") <TAB>  <TAB> self.emit(""INTERNET_NAME_UNRESOLVED"", hostname, pevent) <TAB>  <TAB> return True <TAB> else: <TAB>  <TAB> self.emit(""INTERNET_NAME"", hostname, pevent) <MASK> self.emit(""DOMAIN_NAME"", hostname, pevent) <TAB>  <TAB> return True","if self . sf . isDomain ( hostname , self . opts [ ""_internettlds"" ] ) :",187
"def defineProperties(this, args): <TAB> obj = get_arg(args, 0) <TAB> properties = get_arg(args, 1) <TAB> if not is_object(obj): <TAB>  <TAB> raise MakeError(""TypeError"", ""Object.defineProperties called on non-object"") <TAB> props = to_object(properties, args.space) <TAB> for k, v in props.own.items(): <MASK> continue <TAB>  <TAB> desc = ToPropertyDescriptor(props.get(unicode(k))) <TAB>  <TAB> if not obj.define_own_property(unicode(k), desc, False): <TAB>  <TAB>  <TAB> raise MakeError(""TypeError"", ""Failed to define own property: %s"" % k) <TAB> return obj","if not v . get ( ""enumerable"" ) :",173
"def Func2(StrParI1, StrParI2): <TAB> IntLoc = 1 <TAB> while IntLoc <= 1: <MASK> CharLoc = ""A"" <TAB>  <TAB>  <TAB> IntLoc = IntLoc + 1 <TAB> if ""W"" <= CharLoc <= ""Z"": <TAB>  <TAB> IntLoc = 7 <TAB> if CharLoc == ""X"": <TAB>  <TAB> return TRUE <TAB> else: <TAB>  <TAB> if StrParI1 > StrParI2: <TAB>  <TAB>  <TAB> IntLoc = IntLoc + 7 <TAB>  <TAB>  <TAB> return TRUE <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return FALSE","if Func1 ( StrParI1 [ IntLoc ] , StrParI2 [ IntLoc + 1 ] ) == Ident1 :",161
"def insertParameterData(self, data): <TAB> for socket in self.getParameterSockets(): <TAB>  <TAB> if socket.loop.useAsInput: <TAB>  <TAB>  <TAB> socketData = data.newInputFromSocket(socket) <TAB>  <TAB>  <TAB> socketData.identifier += ""_input"" <MASK> socketData = data.newOutputFromSocket(socket) <TAB>  <TAB>  <TAB> socketData.identifier += ""_output""",if socket . loop . useAsOutput :,103
"def _build_role_scope(resource_group_name, scope, subscription_id): <TAB> subscription_scope = ""/subscriptions/"" + subscription_id <TAB> if scope: <TAB>  <TAB> if resource_group_name: <TAB>  <TAB>  <TAB> err = 'Resource group ""{}"" is redundant because scope is supplied' <TAB>  <TAB>  <TAB> raise CLIError(err.format(resource_group_name)) <TAB>  <TAB> from azure.mgmt.core.tools import is_valid_resource_id <MASK> raise CLIError(""Invalid scope. Please use --help to view the valid format."") <TAB> elif resource_group_name: <TAB>  <TAB> scope = subscription_scope + ""/resourceGroups/"" + resource_group_name <TAB> else: <TAB>  <TAB> scope = subscription_scope <TAB> return scope","if scope . startswith ( ""/subscriptions/"" ) and not is_valid_resource_id ( scope ) :",197
"def get_nowait(self, ack=False): <TAB> with self.lock: <TAB>  <TAB> message = self.channel.basic_get(self.name, not ack) <MASK> raise BaseQueue.Empty <TAB>  <TAB> if ack: <TAB>  <TAB>  <TAB> self.channel.basic_ack(message.delivery_tag) <TAB> return umsgpack.unpackb(message.body)",if message is None :,98
"def prime(self, callback): <TAB> """"""Register notification of a value change via a callback"""""" <MASK> self.cbhdl = simulator.register_value_change_callback( <TAB>  <TAB>  <TAB> self.signal._handle, callback, 3, self <TAB>  <TAB> ) <TAB>  <TAB> if self.cbhdl is None: <TAB>  <TAB>  <TAB> raise_error(self, ""Unable set up %s Trigger"" % (str(self))) <TAB> Trigger.prime(self)",if self . cbhdl is None :,114
"def setup_templates(non_dry_run): <TAB> """"""Set up templates."""""" <TAB> for name, template in six.iteritems(TEMPLATES): <TAB>  <TAB> job = data_types.JobTemplate.query(data_types.JobTemplate.name == name).get() <MASK> print(""Template with name"", name, ""already exists."") <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if non_dry_run: <TAB>  <TAB>  <TAB> print(""Creating template"", name) <TAB>  <TAB>  <TAB> data_types.JobTemplate(name=name, environment_string=template).put() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""Skip creating template"", name, ""(dry-run mode)"")",if job :,153
def correct(self): <TAB> for A in self.circles: <TAB>  <TAB> intersects = False <TAB>  <TAB> for B in self.circles: <TAB>  <TAB>  <TAB> if A != B: <TAB>  <TAB>  <TAB>  <TAB> radsq = (A.r + B.r) * (A.r + B.r) <TAB>  <TAB>  <TAB>  <TAB> d = A.sqdist_o(B) <MASK> intersects = True <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if not intersects: <TAB>  <TAB>  <TAB> A.x = A.ox <TAB>  <TAB>  <TAB> A.y = A.oy,if radsq > d :,145
"def __formatPlugs(box, plugs): <TAB> result = """" <TAB> for section in GafferUI.PlugLayout.layoutSections(box): <TAB>  <TAB> for plug in GafferUI.PlugLayout.layoutOrder(box, section=section): <MASK> continue <TAB>  <TAB>  <TAB> result += ""{}.{}\n"".format( <TAB>  <TAB>  <TAB>  <TAB> section, <TAB>  <TAB>  <TAB>  <TAB> Gaffer.Metadata.value(plug, ""label"") <TAB>  <TAB>  <TAB>  <TAB> or IECore.CamelCase.toSpaced(plug.getName()), <TAB>  <TAB>  <TAB> ) <TAB> return result",if plug not in plugs :,147
"def _waitForAck(self, type_id, timeout=5.0): <TAB> stime = getTime() <TAB> while getTime() - stime < timeout: <TAB>  <TAB> self._checkForNetData(0.25) <TAB>  <TAB> msgs = self._parseRxBuffer() <TAB>  <TAB> for m in msgs: <MASK> return m <TAB> return None","if m . get ( ""ID"" ) == type_id :",99
"def wrap_function(self, filename=None, config=None): <TAB> try: <TAB>  <TAB> netmiko_object = self._netmiko_device <MASK> raise AttributeError() <TAB> except AttributeError: <TAB>  <TAB> device_type = c.NETMIKO_MAP[self.platform] <TAB>  <TAB> netmiko_optional_args = self.netmiko_optional_args <TAB>  <TAB> if ""port"" in netmiko_optional_args: <TAB>  <TAB>  <TAB> netmiko_optional_args[""port""] = 22 <TAB>  <TAB> self._netmiko_open( <TAB>  <TAB>  <TAB> device_type=device_type, netmiko_optional_args=netmiko_optional_args <TAB>  <TAB> ) <TAB> func(self, filename=filename, config=config)",if netmiko_object is None :,188
"def _handleInvertAxesSelected(self, evt): <TAB> """"""Called when the invert all menu item is selected"""""" <TAB> if len(self._axisId) == 0: <TAB>  <TAB> return <TAB> for i in range(len(self._axisId)): <MASK> self._menu.Check(self._axisId[i], False) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._menu.Check(self._axisId[i], True) <TAB> self._toolbar.set_active(self.getActiveAxes()) <TAB> evt.Skip()",if self . _menu . IsChecked ( self . _axisId [ i ] ) :,139
"def error_str(self): <TAB> val = self.what <TAB> try: <TAB>  <TAB> val.routine <TAB> except AttributeError: <TAB>  <TAB> return str(val) <TAB> else: <TAB>  <TAB> result = """" <TAB>  <TAB> if val.code() != status_code.SUCCESS: <TAB>  <TAB>  <TAB> result = status_code.to_string(val.code(), ""<unknown error %d>"") <TAB>  <TAB> routine = val.routine() <TAB>  <TAB> if routine: <TAB>  <TAB>  <TAB> result = ""%s failed: %s"" % (routine, result) <TAB>  <TAB> what = val.what() <TAB>  <TAB> if what: <MASK> result += "" - "" <TAB>  <TAB>  <TAB> result += what <TAB>  <TAB> return result",if result :,165
"def _run(): <TAB> while not self._stopEvent.isSet(): <TAB>  <TAB> time.sleep(1) <TAB>  <TAB> ori = _refresh_by_ow() <TAB>  <TAB> if ori is None: <TAB>  <TAB>  <TAB> break <MASK> continue <TAB>  <TAB> LOGGING.info(""update orientation %s->%s"" % (self.last_result, ori)) <TAB>  <TAB> self.last_result = ori <TAB>  <TAB> # exec cb functions <TAB>  <TAB> for cb in self.ow_callback: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> cb(ori) <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> LOGGING.error(""cb: %s error"" % cb) <TAB>  <TAB>  <TAB>  <TAB> traceback.print_exc()",elif self . last_result == ori :,173
"def deindex_vcard(self, card): <TAB> attrs = [""email""] if (card.kind in self.KINDS_PEOPLE) else [""nickname""] <TAB> with self._lock: <TAB>  <TAB> for attr in attrs: <TAB>  <TAB>  <TAB> for vcl in card.get_all(attr): <TAB>  <TAB>  <TAB>  <TAB> key = vcl.value.lower() <TAB>  <TAB>  <TAB>  <TAB> indexed = self.get(key) <TAB>  <TAB>  <TAB>  <TAB> if indexed and indexed.random_uid == card.random_uid: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> del self[key] <MASK> del self[card.random_uid]",if card . random_uid in self :,151
"def PyJs_anonymous_4213_(obj, this, arguments, var=var): <TAB> var = Scope({u""this"": this, u""obj"": obj, u""arguments"": arguments}, var) <TAB> var.registers([u""keys"", u""obj"", u""key""]) <TAB> var.put(u""keys"", Js([])) <TAB> for PyJsTemp in var.get(u""obj""): <TAB>  <TAB> var.put(u""key"", PyJsTemp) <MASK> var.get(u""keys"").callprop(u""push"", var.get(u""key"")) <TAB> return var.get(u""keys"")","if var . get ( u""hasOwn"" ) . callprop ( u""call"" , var . get ( u""obj"" ) , var . get ( u""key"" ) ) :",181
"def eval_(out_values, rest_values): <TAB> pred_masks, pred_labels, pred_scores = out_values <TAB> gt_masks, gt_labels = rest_values <TAB> result = eval_instance_segmentation_voc( <TAB>  <TAB> pred_masks, pred_labels, pred_scores, gt_masks, gt_labels, use_07_metric=True <TAB> ) <TAB> print("""") <TAB> print(""mAP: {:f}"".format(result[""map""])) <TAB> for l, name in enumerate(sbd_instance_segmentation_label_names): <MASK> print(""{:s}: {:f}"".format(name, result[""ap""][l])) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""{:s}: -"".format(name))","if result [ ""ap"" ] [ l ] :",177
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 11: <TAB>  <TAB>  <TAB> self.add_element().TryMerge(d) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,88
"def get_translator_opts(args): <TAB> opts = [] <TAB> for k in translator_opts: <TAB>  <TAB> if args.has_key(k): <TAB>  <TAB>  <TAB> nk = k.replace(""_"", ""-"") <MASK> opts.append(""--%s=%s"" % (nk, args[k])) <TAB>  <TAB>  <TAB> elif args[k]: <TAB>  <TAB>  <TAB>  <TAB> opts.append(""--%s"" % nk) <TAB>  <TAB>  <TAB> elif k != ""list_imports"": <TAB>  <TAB>  <TAB>  <TAB> opts.append(""--no-%s"" % nk) <TAB> return opts",if k in non_boolean_opts :,140
"def mean_squared_error_regressor(tensor_in, labels, weights, biases, name=None): <TAB> """"""Returns prediction and loss for mean squared error regression."""""" <TAB> with tf.op_scope([tensor_in, labels], name, ""mean_squared_error_regressor""): <TAB>  <TAB> predictions = tf.nn.xw_plus_b(tensor_in, weights, biases) <MASK> labels = tf.reshape(labels, [-1, 1]) <TAB>  <TAB> diff = labels - predictions <TAB>  <TAB> loss = tf.reduce_mean(tf.mul(diff, diff)) <TAB>  <TAB> return predictions, loss",if len ( labels . get_shape ( ) ) == 1 :,153
"def unFreezeDocks(self): <TAB> """"""Un-freeze all dockable widgets on the main screen (allow them to be closed, floated, or moved, as appropriate)"""""" <TAB> for dock in self.getDocks(): <MASK> dock.setFeatures( <TAB>  <TAB>  <TAB>  <TAB> QDockWidget.DockWidgetFloatable | QDockWidget.DockWidgetMovable <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> dock.setFeatures( <TAB>  <TAB>  <TAB>  <TAB> QDockWidget.DockWidgetClosable <TAB>  <TAB>  <TAB>  <TAB> | QDockWidget.DockWidgetFloatable <TAB>  <TAB>  <TAB>  <TAB> | QDockWidget.DockWidgetMovable <TAB>  <TAB>  <TAB> )",if dock is self . dockTimeline :,178
"def _json_loader(filename): <TAB> try: <TAB>  <TAB> with open(filename, ""rb"") as data: <TAB>  <TAB>  <TAB> load.update(json.load(data)) <TAB> except ValueError: <MASK> with open(filename, ""rb"") as data: <TAB>  <TAB>  <TAB>  <TAB> lint = jsonlint() <TAB>  <TAB>  <TAB>  <TAB> rc = lint.main([""-v"", filename]) <TAB>  <TAB> logger.critical(""Error with configuration file"") <TAB>  <TAB> sys.exit(-1)",if jsonlint :,115
"def _add_source(self, repos=None): <TAB> # Add a Source <TAB> with DbTxn(""Add Source and Citation"", self._db) as tran: <TAB>  <TAB> source = Source() <MASK> repo_ref = RepoRef() <TAB>  <TAB>  <TAB> repo_ref.set_reference_handle(repos.get_handle()) <TAB>  <TAB>  <TAB> source.add_repo_reference(repo_ref) <TAB>  <TAB> self._db.add_source(source, tran) <TAB>  <TAB> self._db.commit_source(source, tran) <TAB>  <TAB> citation = Citation() <TAB>  <TAB> citation.set_reference_handle(source.get_handle()) <TAB>  <TAB> self._db.add_citation(citation, tran) <TAB>  <TAB> self._db.commit_citation(citation, tran) <TAB> return citation",if repos is not None :,197
"def get_pid_strings(self, pid): <TAB> try: <TAB>  <TAB> mw = memorpy.MemWorker(pid=pid) <TAB>  <TAB> matcher = self.policy or self.printable <TAB>  <TAB> for _, (cstring,) in mw.mem_search( <TAB>  <TAB>  <TAB> ""([\x20-\x7e]+)\x00"", ftype=""groups"", optimizations=""ixrs"" <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> if matcher.match(cstring): <MASK> yield cstring <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if len(self.duplicates) > self.maxdups: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.duplicates = set() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.duplicates.add(cstring) <TAB> except: <TAB>  <TAB> pass",if cstring not in self . duplicates :,179
"def test_dynamic_segment(self): <TAB> """"""Verify that we can process relocations on the PT_DYNAMIC segment without section headers"""""" <TAB> test_dir = os.path.join(""test"", ""testfiles_for_unittests"") <TAB> with open(os.path.join(test_dir, ""x64_bad_sections.elf""), ""rb"") as f: <TAB>  <TAB> elff = ELFFile(f) <TAB>  <TAB> for seg in elff.iter_segments(): <MASK> relos = seg.get_relocation_tables() <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(set(relos), {""JMPREL"", ""RELA""})","if isinstance ( seg , DynamicSegment ) :",165
"def flattenInfo(self, info): <TAB> # Flatten dictionary of matches (chain info) <TAB> if isinstance(info, dict): <TAB>  <TAB> return dict([(key, self.flattenInfo(value)) for key, value in info.items()]) <TAB> # Flatten matches <TAB> result = None <TAB> for match in info: <TAB>  <TAB> if isinstance(match, dict): <TAB>  <TAB>  <TAB> if result is None: <TAB>  <TAB>  <TAB>  <TAB> result = {} <TAB>  <TAB>  <TAB> for key, value in match.items(): <MASK> result[key] = [] <TAB>  <TAB>  <TAB>  <TAB> result[key].append(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if result is None: <TAB>  <TAB>  <TAB>  <TAB> result = [] <TAB>  <TAB>  <TAB> result.append(match) <TAB> return result",if key not in result :,182
"def main(): <TAB> if len(sys.argv) == 2: <TAB>  <TAB> if sys.argv[1] == ""--gui"": <TAB>  <TAB>  <TAB> QLGuiPerfApp() <TAB>  <TAB>  <TAB> sys.exit(0) <MASK> console_print(sys.argv[1]) <TAB>  <TAB>  <TAB> sys.exit(0) <TAB> usage()",elif os . path . isfile ( sys . argv [ 1 ] ) :,94
"def SetTransparency(self, selection=None): <TAB> if not self.GetParent().CanSetTransparent(): <TAB>  <TAB> return <TAB> if selection is not None: <TAB>  <TAB> intersects = False <MASK> intersects = True <TAB>  <TAB>  <TAB> self.GetParent().SetTransparent(200) <TAB>  <TAB>  <TAB> return <TAB> self.GetParent().SetTransparent(255)",if selection . GetScreenRect ( ) . Intersects ( self . GetParent ( ) . GetScreenRect ( ) ) :,111
"def add(self, dist): <TAB> """"""Add `dist` if we ``can_add()`` it and it isn't already added"""""" <TAB> if self.can_add(dist) and dist.has_version(): <TAB>  <TAB> dists = self._distmap.setdefault(dist.key, []) <TAB>  <TAB> if dist not in dists: <TAB>  <TAB>  <TAB> dists.append(dist) <MASK> _sort_dists(self._cache[dist.key])",if dist . key in self . _cache :,115
"def MemberDiff(data1, set1_name, data2, set2_name): <TAB> """"""Helper method to perform bidirectional set differences."""""" <TAB> set1 = set(data1) <TAB> set2 = set(data2) <TAB> diffs = [] <TAB> msg = ""Present in %s, missing in %s: %s"" <TAB> if set1 != set2: <TAB>  <TAB> in_set1 = set1 - set2 <TAB>  <TAB> in_set2 = set2 - set1 <MASK> diffs.append(msg % (set1_name, set2_name, "","".join(in_set1))) <TAB>  <TAB> if in_set2: <TAB>  <TAB>  <TAB> diffs.append(msg % (set2_name, set1_name, "","".join(in_set2))) <TAB> return diffs",if in_set1 :,190
"def _get_mail_spool(self): <TAB> path = os.getenv(""MAIL"") or None <TAB> user = os.getenv(""USER"") <TAB> if user and not path: <MASK> path = os.path.normpath(""/var/spool/mail/%s"" % user) <TAB>  <TAB> if os.path.exists(""/var/mail""): <TAB>  <TAB>  <TAB> path = os.path.normpath(""/var/mail/%s"" % user) <TAB> return path","if os . path . exists ( ""/var/spool/mail"" ) :",123
"def _collect_dso_modules(self): <TAB> """"""Helper function to collect dso modules, then return it."""""" <TAB> visited, stack, dso_modules = set(), [], [] <TAB> # append root module <TAB> visited.add(self) <TAB> stack.append(self) <TAB> while stack: <TAB>  <TAB> module = stack.pop() <TAB>  <TAB> if module._dso_exportable(): <TAB>  <TAB>  <TAB> dso_modules.append(module) <TAB>  <TAB> for m in module.imported_modules: <MASK> visited.add(m) <TAB>  <TAB>  <TAB>  <TAB> stack.append(m) <TAB> return dso_modules",if m not in visited :,154
"def build_mirror_data(self, ud, d): <TAB> # Generate a mirror tarball if needed <TAB> if ud.write_tarballs == ""1"" and not os.path.exists(ud.fullmirror): <TAB>  <TAB> # it's possible that this symlink points to read-only filesystem with PREMIRROR <MASK> os.unlink(ud.fullmirror) <TAB>  <TAB> logger.info(""Creating tarball of hg repository"") <TAB>  <TAB> runfetchcmd(""tar -czf %s %s"" % (ud.fullmirror, ud.module), d, workdir=ud.pkgdir) <TAB>  <TAB> runfetchcmd(""touch %s.done"" % (ud.fullmirror), d, workdir=ud.pkgdir)",if os . path . islink ( ud . fullmirror ) :,180
"def on_load(target, context): <TAB> d = target.__dict__ <TAB> for k, v in cls.get_flat_type_info(cls).items(): <MASK> if isclass(v) and issubclass(v, ComplexModelBase): <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> d[k] = None",if not k in d :,89
"def verify_references(self, options): <TAB> from filer.models.filemodels import File <TAB> for file in File.objects.all(): <TAB>  <TAB> if not file.file.storage.exists(file.file.name): <TAB>  <TAB>  <TAB> if options[""delete_missing""]: <TAB>  <TAB>  <TAB>  <TAB> file.delete() <TAB>  <TAB>  <TAB>  <TAB> msg = ""Delete missing file reference '{}/{}' from database."" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> msg = ""Referenced file '{}/{}' is missing in media folder."" <MASK> self.stdout.write(msg.format(str(file.folder), str(file))) <TAB>  <TAB>  <TAB> elif options[""verbosity""]: <TAB>  <TAB>  <TAB>  <TAB> self.stdout.write(os.path.join(str(file.folder), str(file)))","if options [ ""verbosity"" ] > 2 :",189
"def set(self, kind, key, data=None, timeout=None): <TAB> with lock: <MASK> self.store[kind] = {} <TAB>  <TAB> key = str(key) <TAB>  <TAB> self.store[kind][key] = { <TAB>  <TAB>  <TAB> ""data"": data, <TAB>  <TAB>  <TAB> ""timeout"": datetime.datetime.now() <TAB>  <TAB>  <TAB> + datetime.timedelta(milliseconds=timeout or self.timeout), <TAB>  <TAB> }",if kind not in self . store :,111
"def shell_lookup(): <TAB> """"""Find an appropriate shell for the user"""""" <TAB> try: <TAB>  <TAB> usershell = pwd.getpwuid(os.getuid())[6] <TAB> except KeyError: <TAB>  <TAB> usershell = None <TAB> shells = [usershell, ""bash"", ""zsh"", ""tcsh"", ""ksh"", ""csh"", ""sh""] <TAB> for shell in shells: <TAB>  <TAB> if shell is None: <TAB>  <TAB>  <TAB> continue <MASK> return shell <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> rshell = path_lookup(shell) <TAB>  <TAB>  <TAB> if rshell is not None: <TAB>  <TAB>  <TAB>  <TAB> dbg(""shell_lookup: Found %s at %s"" % (shell, rshell)) <TAB>  <TAB>  <TAB>  <TAB> return rshell <TAB> dbg(""shell_lookup: Unable to locate a shell"")",elif os . path . isfile ( shell ) :,195
"def test_unique(self): <TAB> """"""Assert that the numeric prefixes of the DB migrations are unique."""""" <TAB> leading_digits = re.compile(r""^\d+"") <TAB> seen_numbers = set() <TAB> path = self._migrations_path() <TAB> for filename in listdir(path): <TAB>  <TAB> match = leading_digits.match(filename) <MASK> number = match.group() <TAB>  <TAB>  <TAB> if number in seen_numbers: <TAB>  <TAB>  <TAB>  <TAB> self.fail( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""There is more than one migration #%s in %s."" % (number, path) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> seen_numbers.add(number)",if match :,156
"def handle_old_config(self, filename): <TAB> warnings.warn_explicit(self.old_warning, ConfigDeprecationWarning, filename, 0) <TAB> options = self.get_section(""options"") <TAB> if not self.has_section(""general""): <TAB>  <TAB> self.add_section(""general"") <TAB> for key, value in options.items(): <TAB>  <TAB> if self.old_settings.has_key(key): <TAB>  <TAB>  <TAB> section, setting = self.old_settings[key] <MASK> self.add_section(section) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> section = ""general"" <TAB>  <TAB>  <TAB> setting = key <TAB>  <TAB> if not self.has_option(section, setting): <TAB>  <TAB>  <TAB> self.set(section, setting, value) <TAB> self.remove_section(""options"")",if not self . has_section ( section ) :,198
"def get_keyword_names(self): <TAB> get_kw_names = getattr(self._library, ""get_keyword_names"", None) or getattr( <TAB>  <TAB> self._library, ""getKeywordNames"", None <TAB> ) <TAB> if self._is_function_or_method(get_kw_names): <TAB>  <TAB> names = get_kw_names() <TAB> else: <TAB>  <TAB> names = [ <TAB>  <TAB>  <TAB> attr <TAB>  <TAB>  <TAB> for attr in dir(self._library) <MASK> and self._is_function_or_method(getattr(self._library, attr)) <TAB>  <TAB> ] <TAB> return names + [""stop_remote_server""]","if attr [ 0 ] != ""_""",160
"def assert_traceback_matches(self, callback, expected_tb): <TAB> try: <TAB>  <TAB> callback() <TAB> except Exception as e: <TAB>  <TAB> tb = format_exception(*sys.exc_info()) <MASK> raise self.fail( <TAB>  <TAB>  <TAB>  <TAB> ""Traceback did not match:\n\n%s\nexpected:\n%s"" <TAB>  <TAB>  <TAB>  <TAB> % ("""".join(tb), expected_tb) <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> self.fail(""Expected exception"")","if re . search ( expected_tb . strip ( ) , """" . join ( tb ) ) is None :",137
"def format_num(n) -> str: <TAB> """"""Add additional padding to the formatted numbers"""""" <TAB> should_be_padded = isinstance(n, (float, str)) <TAB> if not isinstance(n, str): <TAB>  <TAB> n = _tqdm.format_num(n) <TAB> if should_be_padded and ""e"" not in n: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> _ = float(n) <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> return n <TAB>  <TAB>  <TAB> n += ""."" <TAB>  <TAB> n += ""0"" * (_PAD_SIZE - len(n)) <TAB> return n","if ""."" not in n and len ( n ) < _PAD_SIZE :",158
def _process_run(cls): <TAB> while cls._process_running: <TAB>  <TAB> # Retrieve current time <TAB>  <TAB> now = time.time() <TAB>  <TAB> # Retrieve active caches <TAB>  <TAB> with cls._lock: <TAB>  <TAB>  <TAB> caches = cls.active.values() <TAB>  <TAB> # Sync caches that have been queued <TAB>  <TAB> for cache in caches: <MASK> continue <TAB>  <TAB>  <TAB> cache.flush() <TAB>  <TAB> time.sleep(cls._process_interval),if cache . flush_at is None or cache . flush_at > now :,127
"def remotes_to_rsyslog_cfg(remotes, header=None, footer=None): <TAB> if not remotes: <TAB>  <TAB> return None <TAB> lines = [] <TAB> if header is not None: <TAB>  <TAB> lines.append(header) <TAB> for name, line in remotes.items(): <MASK> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> lines.append(str(parse_remotes_line(line, name=name))) <TAB>  <TAB> except ValueError as e: <TAB>  <TAB>  <TAB> LOG.warning(""failed loading remote %s: %s [%s]"", name, line, e) <TAB> if footer is not None: <TAB>  <TAB> lines.append(footer) <TAB> return ""\n"".join(lines) + ""\n""",if not line :,174
"def release(self, client_id: str, id: bytes) -> bool: <TAB> if client_id in self.object_refs: <TAB>  <TAB> if id in self.object_refs[client_id]: <TAB>  <TAB>  <TAB> logger.debug(f""Releasing object {id.hex()} for {client_id}"") <TAB>  <TAB>  <TAB> del self.object_refs[client_id][id] <TAB>  <TAB>  <TAB> return True <TAB> if client_id in self.actor_owners: <MASK> logger.debug(f""Releasing actor {id.hex()} for {client_id}"") <TAB>  <TAB>  <TAB> del self.actor_refs[id] <TAB>  <TAB>  <TAB> self.actor_owners[client_id].remove(id) <TAB>  <TAB>  <TAB> return True <TAB> return False",if id in self . actor_owners [ client_id ] :,194
"def getlanguageNodes(self): <TAB> """"""We override this to get source and target nodes."""""" <TAB> source = None <TAB> target = None <TAB> nodes = [] <TAB> try: <TAB>  <TAB> source = self.xmlelement.iterchildren(self.namespaced(self.languageNode)).next() <TAB>  <TAB> target = self.xmlelement.iterchildren(self.namespaced(""target"")).next() <TAB>  <TAB> nodes = [source, target] <TAB> except StopIteration: <MASK> nodes.append(source) <TAB>  <TAB> if not target is None: <TAB>  <TAB>  <TAB> nodes.append(target) <TAB> return nodes",if source is not None :,144
"def save_config(self, cmd=""admin save"", confirm=False, confirm_response=""""): <TAB> """"""Saves Config Using admin save."""""" <TAB> if confirm: <TAB>  <TAB> output = self.send_command_timing(command_string=cmd) <MASK> output += self.send_command_timing(confirm_response) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Send enter by default <TAB>  <TAB>  <TAB> output += self.send_command_timing(self.RETURN) <TAB> else: <TAB>  <TAB> # Some devices are slow so match on trailing-prompt if you can <TAB>  <TAB> output = self.send_command(command_string=cmd) <TAB> return output",if confirm_response :,154
"def scan_resource_conf(self, conf): <TAB> if ""allow"" in conf: <TAB>  <TAB> allow_blocks = conf[""allow""] <TAB>  <TAB> for block in allow_blocks: <MASK> return CheckResult.UNKNOWN <TAB>  <TAB>  <TAB> if ""ports"" in block: <TAB>  <TAB>  <TAB>  <TAB> if self._is_port_in_range(block[""ports""]): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if ""source_ranges"" in conf.keys(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> source_ranges = conf[""source_ranges""][0] <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if ""0.0.0.0/0"" in source_ranges:  # nosec <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return CheckResult.FAILED <TAB> return CheckResult.PASSED","if isinstance ( block , str ) :",179
"def _purge(self, queue): <TAB> """"""Delete all current messages in a queue."""""" <TAB> n = 0 <TAB> while True: <TAB>  <TAB> message = self.queue_service.read_delete_queue_message( <TAB>  <TAB>  <TAB> self.entity_name(queue), timeout=0.1 <TAB>  <TAB> ) <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> n += 1 <TAB> return n",if not message . body :,100
"def preclean(): <TAB> if data[""text""] is None: <MASK> self.innerText = f""{self.value:0.4g}"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.innerText = f""{self.value}"" <TAB> else: <TAB>  <TAB> self.innerText = data[""text""]",if type ( self . value ) is float :,84
"def membuf_tempfile(memfile): <TAB> memfile.seek(0, 0) <TAB> tmpfd, tmpname = mkstemp(suffix="".rar"") <TAB> tmpf = os.fdopen(tmpfd, ""wb"") <TAB> try: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> buf = memfile.read(BSIZE) <MASK> break <TAB>  <TAB>  <TAB> tmpf.write(buf) <TAB>  <TAB> tmpf.close() <TAB> except: <TAB>  <TAB> tmpf.close() <TAB>  <TAB> os.unlink(tmpname) <TAB>  <TAB> raise <TAB> return tmpname",if not buf :,140
"def clean_html(self): <TAB> html = self.cleaned_data.get(""html"") <TAB> count = 0 <TAB> for i in html: <TAB>  <TAB> if i == ""{"": <TAB>  <TAB>  <TAB> count += 1 <TAB>  <TAB> elif i == ""}"": <TAB>  <TAB>  <TAB> count -= 1 <MASK> raise forms.ValidationError(""Brackets do not match, Enter valid tags."") <TAB> if count != 0: <TAB>  <TAB> raise forms.ValidationError(""Brackets do not match, Enter valid tags."") <TAB> return html",if count < 0 :,118
"def get_all_workflows(self, access_token, timeout=None): <TAB> if timeout is None: <TAB>  <TAB> timeout = DEFAULT_TIMEOUT <TAB> headers = self.retrieve_header(access_token) <TAB> try: <TAB>  <TAB> response = await self.standard_request( <TAB>  <TAB>  <TAB> ""get"", <TAB>  <TAB>  <TAB> ""/walkoff/api/workflowqueue"", <TAB>  <TAB>  <TAB> timeout=DEFAULT_TIMEOUT, <TAB>  <TAB>  <TAB> headers=headers, <TAB>  <TAB> ) <MASK> resp = await response.json() <TAB>  <TAB>  <TAB> return resp, ""Success"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""Invalid Credentials"" <TAB> except asyncio.CancelledError: <TAB>  <TAB> return False, ""TimedOut""",if response . status == 200 :,170
"def __init__(self, lengths, batch_size=16, batch_group_size=None, permutate=True): <TAB> self.lengths, self.sorted_indices = torch.sort(torch.LongTensor(lengths)) <TAB> self.batch_size = batch_size <TAB> if batch_group_size is None: <TAB>  <TAB> batch_group_size = min(batch_size * 32, len(self.lengths)) <MASK> batch_group_size -= batch_group_size % batch_size <TAB> self.batch_group_size = batch_group_size <TAB> assert batch_group_size % batch_size == 0 <TAB> self.permutate = permutate",if batch_group_size % batch_size != 0 :,167
"def cast(arg, target_type): <TAB> # validate <TAB> op = ops.Cast(arg, to=target_type) <TAB> if op.to.equals(arg.type()): <TAB>  <TAB> # noop case if passed type is the same <TAB>  <TAB> return arg <TAB> if isinstance(op.to, (dt.Geography, dt.Geometry)): <TAB>  <TAB> from_geotype = arg.type().geotype or ""geometry"" <TAB>  <TAB> to_geotype = op.to.geotype <MASK> return arg <TAB> result = op.to_expr() <TAB> if not arg.has_name(): <TAB>  <TAB> return result <TAB> expr_name = ""cast({}, {})"".format(arg.get_name(), op.to) <TAB> return result.name(expr_name)",if from_geotype == to_geotype :,190
"def apply_action(self, action): <TAB> if isinstance(action, vnc_event.PointerEvent): <TAB>  <TAB> with self.lock: <TAB>  <TAB>  <TAB> self.cursor_position = (action.x, action.y) <TAB>  <TAB>  <TAB> # If not self._back_updated, we're not actually up to <TAB>  <TAB>  <TAB> # date, so any pixels we cached would be wrong. When <TAB>  <TAB>  <TAB> # back updates, it'll automatically render the cursor. <MASK> self._unpaint_cursor() <TAB>  <TAB>  <TAB>  <TAB> self._paint_cursor()",if self . _back_updated and self . paint_cursor :,146
"def get_subject(self): <TAB> """"""Return a string that describes the subject of the report."""""" <TAB> subject = """" <TAB> if self.__filter.get_filter().get_name(): <TAB>  <TAB> # Use the selected filter's name, if any <TAB>  <TAB> subject += self.__filter.get_filter().get_name() <TAB> if self.__places.get_value(): <TAB>  <TAB> # Add places selected individually, if any <TAB>  <TAB> for place_id in self.__places.get_value().split(): <MASK> subject += "" + "" <TAB>  <TAB>  <TAB> place = self.__db.get_place_from_gramps_id(place_id) <TAB>  <TAB>  <TAB> subject += _pd.display(self.__db, place) <TAB> return subject",if subject :,176
"def _ExtensionEquals(self, x): <TAB> extensions = self._ListExtensions() <TAB> if extensions != x._ListExtensions(): <TAB>  <TAB> return False <TAB> for ext in extensions: <TAB>  <TAB> if ext.is_repeated: <TAB>  <TAB>  <TAB> if self.ExtensionSize(ext) != x.ExtensionSize(ext): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> for e1, e2 in zip(self.ExtensionList(ext), x.ExtensionList(ext)): <TAB>  <TAB>  <TAB>  <TAB> if e1 != e2: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <MASK> return False <TAB> return True",if self . GetExtension ( ext ) != x . GetExtension ( ext ) :,164
"def to_python_interpreter(full_path_or_basename): <TAB> if os.path.isfile(full_path_or_basename): <TAB>  <TAB> return PythonInterpreter.from_binary(full_path_or_basename) <TAB> else: <TAB>  <TAB> interpreter = PythonInterpreter.from_env(full_path_or_basename) <MASK> die(""Failed to find interpreter: %s"" % full_path_or_basename) <TAB>  <TAB> return interpreter",if interpreter is None :,114
"def loop_struct(graphs_list, intervals_list): <TAB> first_graph = graphs_list[0] <TAB> for i, graph in enumerate(graphs_list): <TAB>  <TAB> interval = intervals_list[i] <TAB>  <TAB> for head in sorted(list(interval.keys()), key=lambda x: x.num): <TAB>  <TAB>  <TAB> loop_nodes = [] <TAB>  <TAB>  <TAB> for node in graph.all_preds(head): <TAB>  <TAB>  <TAB>  <TAB> if node.interval is head.interval: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> lnodes = mark_loop(first_graph, head, node, head.interval) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for lnode in lnodes: <MASK> loop_nodes.append(lnode) <TAB>  <TAB>  <TAB> head.get_head().loop_nodes = loop_nodes",if lnode not in loop_nodes :,197
"def delete_load_balancer_listeners(self, name, ports): <TAB> balancer = self.load_balancers.get(name, None) <TAB> listeners = [] <TAB> if balancer: <TAB>  <TAB> for lb_port in ports: <TAB>  <TAB>  <TAB> for listener in balancer.listeners: <MASK> continue <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> listeners.append(listener) <TAB> balancer.listeners = listeners <TAB> return balancer",if int ( lb_port ) == int ( listener . load_balancer_port ) :,128
"def add_breakpoints(self, bp_addr): <TAB> for addr in bp_addr: <TAB>  <TAB> addr = int(addr, 0) <TAB>  <TAB> good = True <TAB>  <TAB> for i, dbg_obj in enumerate(self.dbg.bp_list): <MASK> good = False <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if good is False: <TAB>  <TAB>  <TAB> print(""Breakpoint 0x%08x already set (%d)"" % (addr, i)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> l = len(self.dbg.bp_list) <TAB>  <TAB>  <TAB> self.dbg.add_breakpoint(addr) <TAB>  <TAB>  <TAB> print(""Breakpoint 0x%08x successfully added ! (%d)"" % (addr, l))",if dbg_obj . addr == addr :,179
"def is_email_available(): <TAB> email = request.json.get(""email"", None) <TAB> if email: <MASK> return jsonify(exists=True) <TAB>  <TAB> return jsonify(exists=False) <TAB> abort(make_response(jsonify(error=""Email field missing""), 422))","if get_count ( db . session . query ( User ) . filter_by ( deleted_at = None , email = email ) ) :",97
"def get_max_nesting_level(self): <TAB> max_level = 0 <TAB> for key, value in self.items(): <MASK> level = value.get_max_nesting_level() + 1 <TAB>  <TAB> elif isinstance(value, dict): <TAB>  <TAB>  <TAB> level = SvDict(value).get_max_nesting_level() + 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> level = 0 <TAB>  <TAB> if level > max_level: <TAB>  <TAB>  <TAB> max_level = level <TAB> return max_level","if isinstance ( value , SvDict ) :",129
"def validate(self, object, name, value): <TAB> """"""Validates that a specified value is valid for this trait."""""" <TAB> if isinstance(value, (str, bytes)): <TAB>  <TAB> if not self.exists: <TAB>  <TAB>  <TAB> return value <MASK> return value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TraitError( <TAB>  <TAB>  <TAB>  <TAB> args=""The trait '{}' of {} instance is {}, but the path "" <TAB>  <TAB>  <TAB>  <TAB> "" '{}' does not exist."".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> name, class_of(object), self.info_text, value <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> self.error(object, name, value)",if os . path . isdir ( value ) :,161
"def get_unique(self): <TAB> last_key = None <TAB> for version in self.iterator(): <TAB>  <TAB> key = ( <TAB>  <TAB>  <TAB> version.object_id, <TAB>  <TAB>  <TAB> version.content_type_id, <TAB>  <TAB>  <TAB> version.db, <TAB>  <TAB>  <TAB> version._local_field_dict, <TAB>  <TAB> ) <MASK> yield version <TAB>  <TAB> last_key = key",if last_key != key :,100
"def del_dir(target: Union[Path, str], only_if_empty: bool = False): <TAB> target = Path(target).expanduser() <TAB> assert target.is_dir() <TAB> for p in sorted(target.glob(""**/*""), reverse=True): <TAB>  <TAB> if not p.exists(): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> p.chmod(0o666) <MASK> p.rmdir() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if only_if_empty: <TAB>  <TAB>  <TAB>  <TAB> raise RuntimeError(f""{p.parent} is not empty!"") <TAB>  <TAB>  <TAB> p.unlink() <TAB> target.rmdir()",if p . is_dir ( ) :,151
"def parseAndRemove(stdout): <TAB> files = [] <TAB> for filename in self.getUnversionedFiles(stdout, self.keep_on_purge): <TAB>  <TAB> filename = unicode2NativeString( <TAB>  <TAB>  <TAB> self.build.path_module.join(self.workdir, filename) <TAB>  <TAB> ) <TAB>  <TAB> files.append(filename) <TAB> if not files: <TAB>  <TAB> d = defer.succeed(0) <TAB> else: <MASK> d = self.removeFiles(files) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> d = self.runRmdir(files, abandonOnFailure=False, timeout=self.timeout) <TAB> return d","if self . workerVersionIsOlderThan ( ""rmdir"" , ""2.14"" ) :",172
"def run(self): <TAB> token = HfFolder.get_token() <TAB> if token is None: <TAB>  <TAB> print(""Not logged in"") <TAB>  <TAB> exit() <TAB> try: <TAB>  <TAB> user, orgs = self._api.whoami(token) <TAB>  <TAB> print(user) <MASK> print(ANSI.bold(""orgs: ""), "","".join(orgs)) <TAB> except HTTPError as e: <TAB>  <TAB> print(e) <TAB>  <TAB> print(ANSI.red(e.response.text)) <TAB>  <TAB> exit(1)",if orgs :,130
"def validate_config(config): <TAB> if config[""entropy_coeff""] < 0.0: <TAB>  <TAB> raise DeprecationWarning(""`entropy_coeff` must be >= 0.0!"") <TAB> if config[""vtrace""] and not config[""in_evaluation""]: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Must use `batch_mode`=truncate_episodes if `vtrace` is True."" <TAB>  <TAB>  <TAB> )","if config [ ""batch_mode"" ] != ""truncate_episodes"" :",110
"def __remove_whitespace_nodes(self, node): <TAB> for child in node: <TAB>  <TAB> text = child.text.strip() <TAB>  <TAB> if not text: <TAB>  <TAB>  <TAB> child.text = """" <TAB>  <TAB> tail = child.tail.strip() <TAB>  <TAB> if not tail: <TAB>  <TAB>  <TAB> child.tail = """" <MASK> self.__remove_whilespace_nodes(child)",if len ( child ) :,97
"def resolve_toolbox(self, **kwds): <TAB> rval = [] <TAB> resolve_kwds = kwds.copy() <TAB> tool_ids = pop_tool_ids(resolve_kwds) <TAB> resolve_kwds[""resolution_cache""] = self._app.container_finder.resolution_cache() <TAB> if tool_ids is not None: <TAB>  <TAB> tool_ids = listify(tool_ids) <TAB> for tool_id, tool in self._app.toolbox.tools_by_id.items(): <TAB>  <TAB> if tool_ids is not None and tool_id not in tool_ids: <TAB>  <TAB>  <TAB> continue <MASK> rval.append(self.resolve(tool_id=tool_id, **resolve_kwds)) <TAB> return rval",if tool . tool_action . produces_real_jobs :,183
"def _stderr_supports_color() -> bool: <TAB> try: <TAB>  <TAB> if hasattr(sys.stderr, ""isatty"") and sys.stderr.isatty(): <TAB>  <TAB>  <TAB> if curses: <TAB>  <TAB>  <TAB>  <TAB> curses.setupterm() <MASK> return True <TAB>  <TAB>  <TAB> elif colorama: <TAB>  <TAB>  <TAB>  <TAB> if sys.stderr is getattr( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> colorama.initialise, ""wrapped_stderr"", object() <TAB>  <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> except Exception: <TAB>  <TAB> # Very broad exception handling because it's always better to <TAB>  <TAB> # fall back to non-colored logs than to break at startup. <TAB>  <TAB> pass <TAB> return False","if curses . tigetnum ( ""colors"" ) > 0 :",173
"def join(self): <TAB> with self._processes_lock: <TAB>  <TAB> for run_id, process in self._living_process_by_run_id.items(): <MASK> process.join() <TAB>  <TAB>  <TAB> run = self._instance.get_run_by_id(run_id) <TAB>  <TAB>  <TAB> if run and not run.is_finished: <TAB>  <TAB>  <TAB>  <TAB> self._generate_synthetic_error_from_crash(run)",if process . is_alive ( ) :,114
"def failover_nic_check(self, vm_device, verrors, schema): <TAB> if not await self.middleware.call( <TAB>  <TAB> ""system.is_freenas"" <TAB> ) and await self.middleware.call(""failover.licensed""): <TAB>  <TAB> nics = await self.nic_capability_checks([vm_device]) <MASK> verrors.add( <TAB>  <TAB>  <TAB>  <TAB> f""{schema}.nic_attach"", <TAB>  <TAB>  <TAB>  <TAB> f'Capabilities must be disabled for {"","".join(nics)} interface ' <TAB>  <TAB>  <TAB>  <TAB> ""in Network->Interfaces section before using this device with VM."", <TAB>  <TAB>  <TAB> )",if nics :,154
"def load_tail(self, q, tail): <TAB> self.msgin(4, ""load_tail"", q, tail) <TAB> m = q <TAB> while tail: <TAB>  <TAB> i = tail.find(""."") <MASK> i = len(tail) <TAB>  <TAB> head, tail = tail[:i], tail[i + 1 :] <TAB>  <TAB> mname = ""%s.%s"" % (m.__name__, head) <TAB>  <TAB> m = self.import_module(head, mname, m) <TAB>  <TAB> if not m: <TAB>  <TAB>  <TAB> self.msgout(4, ""raise ImportError: No module named"", mname) <TAB>  <TAB>  <TAB> raise ImportError(""No module named "" + mname) <TAB> self.msgout(4, ""load_tail ->"", m) <TAB> return m",if i < 0 :,186
"def mock_send(_, command, silent=False): <TAB> if silent: <TAB>  <TAB> return """" <TAB> fixture = command[6].replace(""/"", ""_"")[1:] <TAB> if command[1] == ""introspect"": <TAB>  <TAB> filetype = ""xml"" <MASK> fixture = re.sub(r""_[0-9]+$"", """", fixture) <TAB>  <TAB>  <TAB> # special case <TAB>  <TAB>  <TAB> if exists_fixture(f""{fixture}_*.{filetype}""): <TAB>  <TAB>  <TAB>  <TAB> fixture = f""{fixture}_*"" <TAB> else: <TAB>  <TAB> fixture = f""{fixture}-{command[10].split('.')[-1]}"" <TAB>  <TAB> filetype = ""fixture"" <TAB>  <TAB> dbus_commands.append(fixture) <TAB> return load_fixture(f""{fixture}.{filetype}"")","if not exists_fixture ( f""{fixture}.{filetype}"" ) :",187
"def _recv_results(self, result_dict): <TAB> rows = [] <TAB> col_descriptions = None <TAB> for msg in self._fetch_until_ready(): <TAB>  <TAB> if isinstance(msg, RowDescriptionMessage): <TAB>  <TAB>  <TAB> col_descriptions = msg.fielddescriptions <MASK> rows.append(self._convert_types(col_descriptions, msg.row, result_dict)) <TAB> return rows","elif isinstance ( msg , DataRowMessage ) :",104
"def receive(self, timeout=None): <TAB> """"""Receive data through websocket"""""" <TAB> log.debug(""Receiving"") <TAB> if not self._socket: <TAB>  <TAB> log.warn(""No connection"") <TAB>  <TAB> return <TAB> try: <TAB>  <TAB> if timeout: <TAB>  <TAB>  <TAB> rv = self._socket.poll(timeout) <MASK> log.info(""Connection timeouted"") <TAB>  <TAB>  <TAB>  <TAB> return ""Quit"" <TAB>  <TAB> data = self._socket.recv_bytes() <TAB> except Exception: <TAB>  <TAB> log.error(""Connection lost"") <TAB>  <TAB> return ""Quit"" <TAB> log.debug(""Got %s"" % data) <TAB> return data.decode(""utf-8"")",if not rv :,163
"def enumerate(self): <TAB> while self.url != """": <TAB>  <TAB> resp = self.send_req(self.url) <TAB>  <TAB> resp = json.loads(resp) <TAB>  <TAB> if ""error"" in resp: <TAB>  <TAB>  <TAB> self.print_( <TAB>  <TAB>  <TAB>  <TAB> R + ""[!] Error: Virustotal probably now is blocking our requests"" + W <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> break <MASK> self.url = resp[""links""][""next""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.url = """" <TAB>  <TAB> self.extract_domains(resp) <TAB> return self.subdomains","if ""links"" in resp and ""next"" in resp [ ""links"" ] :",156
"def UpdateText(t, wcolor=""black""): <TAB> global RunNode, Encoding <TAB> if t.TextLock.acquire(0) == 1: <MASK> if t.Text != ""\n"": <TAB>  <TAB>  <TAB>  <TAB> g.es(t.Text, color=wcolor) <TAB>  <TAB>  <TAB> t.Text = """" <TAB>  <TAB> elif not t.isAlive(): <TAB>  <TAB>  <TAB> t.TextLock.release() <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> t.TextLock.release() <TAB> return True",if t . Text :,121
"def augment(self, resources): <TAB> for r in resources: <MASK> continue <TAB>  <TAB> tags = [] <TAB>  <TAB> for k, v in r[""Tags""].items(): <TAB>  <TAB>  <TAB> tags.append({""Key"": k, ""Value"": v}) <TAB>  <TAB> r[""Tags""] = tags <TAB> return resources","if ""Tags"" not in r :",81
"def untangle_edges(orig_edges, bmesh_edges, angles): <TAB> result = [] <TAB> edges = bmesh_edges[:] <TAB> for orig_edge in orig_edges: <TAB>  <TAB> i, e = [ <TAB>  <TAB>  <TAB> (i, e) <TAB>  <TAB>  <TAB> for i, e in enumerate(edges) <MASK> ][0] <TAB>  <TAB> result.append(angles[i]) <TAB> return result",if set ( v . index for v in e . verts ) == set ( orig_edge ),118
"def flags(self): <TAB> if not self._metaschema_flags: <TAB>  <TAB> self._metaschema_flags = {} <TAB> meta_schema = self.registration_schema <TAB> if meta_schema: <TAB>  <TAB> schema = meta_schema.schema <TAB>  <TAB> flags = schema.get(""flags"", {}) <TAB>  <TAB> dirty = False <TAB>  <TAB> for flag, value in flags.items(): <MASK> self._metaschema_flags[flag] = value <TAB>  <TAB>  <TAB>  <TAB> dirty = True <TAB>  <TAB> if dirty: <TAB>  <TAB>  <TAB> self.save() <TAB> return self._metaschema_flags",if flag not in self . _metaschema_flags :,148
"def _get_initializers(self): <TAB> params_inits = self.get_initializers() <TAB> if not isinstance(params_inits, (tuple, list)): <TAB>  <TAB> raise TypeError(""`get_initializers` must return a tuple or a list."") <TAB> for param_inits in params_inits: <MASK> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""`get_initializers` must return a tuple or a list of "" <TAB>  <TAB>  <TAB>  <TAB> ""tuples or lists."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> for init in param_inits: <TAB>  <TAB>  <TAB> _check_generated_initializer(init) <TAB> return params_inits","if not isinstance ( param_inits , ( tuple , list ) ) :",151
"def getData(self, path): <TAB> result = None <TAB> cnt = len(self.flatdoc) <TAB> for j in range(cnt): <TAB>  <TAB> item = self.flatdoc[j] <MASK> (name, argt) = item.split(b""="") <TAB>  <TAB>  <TAB> argres = argt.split(b""|"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = item <TAB>  <TAB>  <TAB> argres = [] <TAB>  <TAB> if name == path: <TAB>  <TAB>  <TAB> result = argres <TAB>  <TAB>  <TAB> break <TAB> if len(argres) > 0: <TAB>  <TAB> for j in range(0, len(argres)): <TAB>  <TAB>  <TAB> argres[j] = int(argres[j]) <TAB> return result","if item . find ( b""="" ) >= 0 :",166
"def execute(cls, app, sa_session, action, job, replacement_dict): <TAB> for dataset_assoc in job.output_datasets: <TAB>  <TAB> if action.output_name == """" or dataset_assoc.name == action.output_name: <TAB>  <TAB>  <TAB> for k, v in action.action_arguments.items(): <TAB>  <TAB>  <TAB>  <TAB> if v: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # Try to use both pure integer and 'cX' format. <MASK> if v[0] == ""c"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> v = v[1:] <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> v = int(v) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if v != 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> setattr(dataset_assoc.dataset.metadata, k, v)","if not isinstance ( v , int ) :",190
"def tlv_parse(self, raw): <TAB> """"""Parse a string of TLV-encoded options."""""" <TAB> ret = {} <TAB> while raw: <TAB>  <TAB> [tag] = struct.unpack(""B"", raw[0]) <TAB>  <TAB> if tag == 0:  # padding <TAB>  <TAB>  <TAB> raw = raw[1:] <TAB>  <TAB>  <TAB> continue <MASK> # end marker <TAB>  <TAB>  <TAB> break <TAB>  <TAB> [length] = struct.unpack(""B"", raw[1]) <TAB>  <TAB> value = raw[2 : 2 + length] <TAB>  <TAB> raw = raw[2 + length :] <TAB>  <TAB> if tag in ret: <TAB>  <TAB>  <TAB> ret[tag].append(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret[tag] = [value] <TAB> return ret",if tag == 255 :,177
"def share_found(self, hash, accepted, is_block): <TAB> self.share_count[if_else(accepted, 1, 0)] += 1 <TAB> if self.options.verbose or is_block: <TAB>  <TAB> say_line( <TAB>  <TAB>  <TAB> ""%s%s, %s"", <TAB>  <TAB>  <TAB> ( <TAB>  <TAB>  <TAB>  <TAB> if_else(is_block, ""block "", """"), <TAB>  <TAB>  <TAB>  <TAB> hash, <MASK> ), <TAB>  <TAB> )","if_else ( accepted , ""accepted"" , ""_rejected_"" ) ,",125
"def save(self, *args, **kwargs): <TAB> ""Process form"" <TAB> if self.instance: <TAB>  <TAB> if self.is_valid(): <TAB>  <TAB>  <TAB> if self.cleaned_data[""status""]: <TAB>  <TAB>  <TAB>  <TAB> self.instance.status = self.cleaned_data[""status""] <TAB>  <TAB>  <TAB> if self.cleaned_data[""assignedto""]: <TAB>  <TAB>  <TAB>  <TAB> self.instance.assigned.add(self.cleaned_data[""assignedto""]) <TAB>  <TAB>  <TAB> self.instance.save() <TAB>  <TAB>  <TAB> if self.cleaned_data[""delete""]: <TAB>  <TAB>  <TAB>  <TAB> if self.cleaned_data[""delete""] == ""delete"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.instance.delete() <MASK> self.instance.trash = True <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.instance.save()","if self . cleaned_data [ ""delete"" ] == ""trash"" :",199
"def _infer_shape(f): <TAB> num_lines, vector_dim = 0, None <TAB> for line in f: <MASK> row = line.rstrip().split(b"" "") <TAB>  <TAB>  <TAB> vector = row[1:] <TAB>  <TAB>  <TAB> # Assuming word, [vector] format <TAB>  <TAB>  <TAB> if len(vector) > 2: <TAB>  <TAB>  <TAB>  <TAB> # The header present in some (w2v) formats contains two elements. <TAB>  <TAB>  <TAB>  <TAB> vector_dim = len(vector) <TAB>  <TAB>  <TAB>  <TAB> num_lines += 1  # First element read <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> num_lines += 1 <TAB> f.seek(0) <TAB> return num_lines, vector_dim",if vector_dim is None :,169
"def import_system(self, header): <TAB> if header in self.system_headers: <MASK> self.imported_headers.add(path) <TAB>  <TAB>  <TAB> self.push_file(header, self.system_headers[header]) <TAB>  <TAB> return <TAB> path = self.get_system_header_path(header) <TAB> if path: <TAB>  <TAB> if path not in self.imported_headers: <TAB>  <TAB>  <TAB> self.imported_headers.add(path) <TAB>  <TAB>  <TAB> self.push_file(path) <TAB> else: <TAB>  <TAB> print('""%s"" not found' % header, file=sys.stderr)  # TODO",if path not in self . imported_headers :,158
"def _flatten(*args): <TAB> arglist = [] <TAB> for arg in args: <TAB>  <TAB> if isinstance(arg, _Block): <TAB>  <TAB>  <TAB> arg = arg.subs <MASK> for item in arg: <TAB>  <TAB>  <TAB>  <TAB> arglist.extend(_flatten(item)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> arglist.append(arg) <TAB> return arglist","if isinstance ( arg , ( list , tuple , set ) ) :",95
"def _init_targets(self, items): <TAB> """"""convert valid targets to `str`"""""" <TAB> targets = [] <TAB> for target in items: <TAB>  <TAB> if isinstance(target, str): <TAB>  <TAB>  <TAB> targets.append(target) <MASK> targets.append(str(target)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> msg = ""%s. target must be a str or Path from pathlib. "" + ""Got '%r' (%s)"" <TAB>  <TAB>  <TAB> raise InvalidTask(msg % (self.name, target, type(target))) <TAB> return targets","elif isinstance ( target , PurePath ) :",136
"def fix(self): <TAB> super().fix() <TAB> for (midiRef, omrRef, op) in self.changes: <TAB>  <TAB> if self.checkIfNoteInstance(midiRef, omrRef) is False: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # if the are the same, don't bother to try changing it <TAB>  <TAB> # 3 is the number of noChange Ops <MASK> continue <TAB>  <TAB> m = omrRef.getContextByClass(stream.Measure) <TAB>  <TAB> self.omrStream.remove(m)","if isinstance ( op , aligner . ChangeOps ) and op == aligner . ChangeOps . NoChange :",150
"def setUpClass(cls): <TAB> for name, conn_settings in settings.HAYSTACK_CONNECTIONS.items(): <TAB>  <TAB> if conn_settings[""ENGINE""] != ""haystack.backends.whoosh_backend.WhooshEngine"": <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> # Start clean <TAB>  <TAB> if os.path.exists(conn_settings[""PATH""]): <TAB>  <TAB>  <TAB> shutil.rmtree(conn_settings[""PATH""]) <TAB>  <TAB> from haystack import connections <TAB>  <TAB> connections[name].get_backend().setup() <TAB> super(WhooshTestCase, cls).setUpClass()","if ""STORAGE"" in conn_settings and conn_settings [ ""STORAGE"" ] != ""file"" :",152
"def render_email(self, form): <TAB> content = [] <TAB> cleaned_data = form.cleaned_data <TAB> for field in form: <TAB>  <TAB> if field.name not in cleaned_data: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> value = cleaned_data.get(field.name) <TAB>  <TAB> if isinstance(value, list): <TAB>  <TAB>  <TAB> value = "", "".join(value) <TAB>  <TAB> # Format dates and datetimes with SHORT_DATE(TIME)_FORMAT <MASK> value = date_format(value, settings.SHORT_DATETIME_FORMAT) <TAB>  <TAB> elif isinstance(value, datetime.date): <TAB>  <TAB>  <TAB> value = date_format(value, settings.SHORT_DATE_FORMAT) <TAB>  <TAB> content.append(""{}: {}"".format(field.label, value)) <TAB> return ""\n"".join(content)","if isinstance ( value , datetime . datetime ) :",195
"def _parse_spec(spec): <TAB> result = """" <TAB> for ch in reversed(spec): <MASK> continue <TAB>  <TAB> elif ch in _KNOWN_TYPES: <TAB>  <TAB>  <TAB> if result: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""expected ':' after format specifier"") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> result = ch <TAB>  <TAB> elif ch.isalpha(): <TAB>  <TAB>  <TAB> raise ValueError(""Unknown conversion specified "" + ch) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> return result","if ch == ""~"" or ch in _BASIC_TYPES :",125
"def targets(self): <TAB> """"""Return a dictionary of Alexa devices."""""" <TAB> devices = {} <TAB> for _, account_dict in self.hass.data[DATA_ALEXAMEDIA][""accounts""].items(): <MASK> return devices <TAB>  <TAB> for serial, alexa in account_dict[""devices""][""media_player""].items(): <TAB>  <TAB>  <TAB> devices[alexa[""accountName""]] = serial <TAB> return devices","if ""devices"" not in account_dict :",107
"def get_push_subjects(payload: Dict[str, Any]) -> List[str]: <TAB> subjects_list = [] <TAB> for change in payload[""push""][""changes""]: <TAB>  <TAB> potential_tag = (change[""new""] or change[""old""] or {}).get(""type"") <TAB>  <TAB> if potential_tag == ""tag"": <TAB>  <TAB>  <TAB> subjects_list.append(str(get_subject(payload))) <TAB>  <TAB> else: <MASK> branch_name = change[""new""][""name""] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> branch_name = change[""old""][""name""] <TAB>  <TAB>  <TAB> subjects_list.append( <TAB>  <TAB>  <TAB>  <TAB> str(get_subject_for_branch_specified_events(payload, branch_name)) <TAB>  <TAB>  <TAB> ) <TAB> return subjects_list","if change . get ( ""new"" ) :",189
"def log_metrics(self, metrics_by_name, info): <TAB> for metric_name, metric_ptr in metrics_by_name.items(): <TAB>  <TAB> for _step, value in zip(metric_ptr[""steps""], metric_ptr[""values""]): <MASK> wandb.log({metric_name: wandb.Image(value)}) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> wandb.log({metric_name: value})","if isinstance ( value , numpy . ndarray ) :",117
"def _poll(self): <TAB> while True: <TAB>  <TAB> params = {""maxev"": 1, ""rid"": int(time.time() * 1000)} <TAB>  <TAB> async with self._http.get(self._session_url, params=params) as response: <TAB>  <TAB>  <TAB> data = await response.json() <MASK> plugin = self._plugins.get(data[""sender""], None) <TAB>  <TAB>  <TAB>  <TAB> if plugin: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> await plugin._queue.put(data) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> print(data)","if data [ ""janus"" ] == ""event"" :",143
"def __new__(mcs, name, bases, namespace, **kwargs): <TAB> rv = type.__new__(mcs, name, bases, namespace) <TAB> rv.__namespace__ = namespace <TAB> if rv.__table__ is None: <TAB>  <TAB> rv.__table__ = getattr(rv, ""_init_table"")(rv) <TAB> visited = set() <TAB> for each_cls in rv.__mro__: <TAB>  <TAB> for k, v in getattr(each_cls, ""__namespace__"", each_cls.__dict__).items(): <MASK> continue <TAB>  <TAB>  <TAB> visited.add(k) <TAB>  <TAB>  <TAB> if callable(v) and getattr(v, ""__declared_attr_with_table__"", False): <TAB>  <TAB>  <TAB>  <TAB> setattr(rv, k, v(rv)) <TAB> return rv",if k in visited :,180
"def run(self, parent, blocks): <TAB> """"""Look for and parse code block."""""" <TAB> handled = False <TAB> if not self.config.get(""disable_indented_code_blocks"", False): <TAB>  <TAB> handled = CodeBlockProcessor.test(self, parent, blocks[0]) <MASK> if self.config.get(""nested"", True): <TAB>  <TAB>  <TAB>  <TAB> blocks[0] = self.revert_greedy_fences(blocks[0]) <TAB>  <TAB>  <TAB> handled = CodeBlockProcessor.run(self, parent, blocks) is not False <TAB> return handled",if handled :,133
"def skip_array(self, writer_schema, decoder): <TAB> block_count = decoder.read_long() <TAB> while block_count != 0: <MASK> block_size = decoder.read_long() <TAB>  <TAB>  <TAB> decoder.skip(block_size) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for _ in range(block_count): <TAB>  <TAB>  <TAB>  <TAB> self.skip_data(writer_schema.items, decoder) <TAB>  <TAB> block_count = decoder.read_long()",if block_count < 0 :,121
"def visitField(self, field): <TAB> if ( <TAB>  <TAB> field.type.value not in asdl.builtin_types <TAB>  <TAB> and field.type.value not in self.data.simple_types <TAB> ): <MASK> self.emit(""if node.%s:"" % (field.name,), 2) <TAB>  <TAB>  <TAB> level = 3 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> level = 2 <TAB>  <TAB> if field.seq: <TAB>  <TAB>  <TAB> template = ""self.visit_sequence(node.%s)"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> template = ""node.%s.walkabout(self)"" <TAB>  <TAB> self.emit(template % (field.name,), level) <TAB>  <TAB> return True <TAB> return False",if field . seq or field . opt :,173
"def fcmp(x, y):  # fuzzy comparison function <TAB> if isinstance(x, float) or isinstance(y, float): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> fuzz = (abs(x) + abs(y)) * FUZZ <TAB>  <TAB>  <TAB> if abs(x - y) <= fuzz: <TAB>  <TAB>  <TAB>  <TAB> return 0 <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> pass <TAB> elif type(x) == type(y) and isinstance(x, (tuple, list)): <TAB>  <TAB> for i in range(min(len(x), len(y))): <TAB>  <TAB>  <TAB> outcome = fcmp(x[i], y[i]) <MASK> return outcome <TAB>  <TAB> return (len(x) > len(y)) - (len(x) < len(y)) <TAB> return (x > y) - (x < y)",if outcome != 0 :,199
"def __init__(self, request, *args, **kwargs): <TAB> super(AttachPort, self).__init__(*args, **kwargs) <TAB> # Populate VIF choices <TAB> vif_choices = [("""", ""Select a VIF"")] <TAB> for vif in api.get_vif_ids(request): <MASK> name = ""Instance %s VIF %s"" % (vif[""instance_name""], vif[""id""]) <TAB>  <TAB>  <TAB> vif_choices.append( <TAB>  <TAB>  <TAB>  <TAB> ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> vif[""id""], <TAB>  <TAB>  <TAB>  <TAB>  <TAB> name, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> self.fields[""vif_id""].choices = vif_choices","if vif [ ""available"" ] :",168
"def _test_ustar_link(self, name, exc=None): <TAB> with tarfile.open(tmpname, ""w"", format=self.format, encoding=""utf-8"") as tar: <TAB>  <TAB> t = tarfile.TarInfo(""foo"") <TAB>  <TAB> t.linkname = name <MASK> tar.addfile(t) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertRaises(exc, tar.addfile, t) <TAB> if exc is None: <TAB>  <TAB> with tarfile.open(tmpname, ""r"", encoding=""utf-8"") as tar: <TAB>  <TAB>  <TAB> for t in tar: <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(name, t.linkname) <TAB>  <TAB>  <TAB>  <TAB> break",if exc is None :,169
"def resolve_envs(_conf): <TAB> """"""Resolve environment variables"""""" <TAB> for k, v in _conf.items(): <MASK> resolve_envs(v) <TAB>  <TAB> if str(v).startswith(""$""): <TAB>  <TAB>  <TAB> _conf[k] = os.getenv(v[1:])","if isinstance ( v , dict ) :",76
"def y_bound(ty, bound, base, offset): <TAB> for tx in range(min_tx, max_tx + 1): <TAB>  <TAB> if (tx, ty) not in tile_coordinates: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> with surf.tile_request(tx, ty, readonly=True) as tile: <TAB>  <TAB>  <TAB> for (y, x) in product(range(base, bound, offset), range(N)): <MASK> bound = y <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return bound","if tile [ y , x , 3 ] > 0 :",135
"def _plugin_name_from_path(path): <TAB> path = os.path.normpath(path) <TAB> file = os.path.basename(path) <TAB> if os.path.isdir(path): <TAB>  <TAB> for entry in _package_entries: <TAB>  <TAB>  <TAB> if os.path.isfile(os.path.join(path, entry)): <TAB>  <TAB>  <TAB>  <TAB> return file <TAB> else: <MASK> return None <TAB>  <TAB> name, ext = os.path.splitext(file) <TAB>  <TAB> if ext in _suffixes: <TAB>  <TAB>  <TAB> return name <TAB>  <TAB> return None",if file in _package_entries :,143
"def stop(self): <TAB> self.cmdin.send(Message(type=_ATMT_Command.STOP)) <TAB> with self.started: <TAB>  <TAB> # Flush command pipes <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> r, _, _ = select([self.cmdin, self.cmdout], [], [], 0) <MASK> break <TAB>  <TAB>  <TAB> for fd in r: <TAB>  <TAB>  <TAB>  <TAB> fd.recv()",if not r :,104
"def apply3(self, expr, form, f, evaluation): <TAB> ""Catch[expr_, form_, f__:Identity]"" <TAB> try: <TAB>  <TAB> ret = expr.evaluate(evaluation) <TAB> except WLThrowInterrupt as e: <TAB>  <TAB> # TODO: check that form match tag. <TAB>  <TAB> # otherwise, re-raise the exception <TAB>  <TAB> match = Expression(""MatchQ"", e.tag, form).evaluate(evaluation) <MASK> return Expression(f, e.value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # A plain raise hide, this path and preserves the traceback <TAB>  <TAB>  <TAB> # of the call that was originally given. <TAB>  <TAB>  <TAB> raise <TAB> return ret",if match . is_true ( ) :,160
"def compute_grad(y, y_pred): <TAB> if type(y).__name__ == ""ndarray"" or type(y_pred).__name__ == ""ndarray"": <TAB>  <TAB> diff = y_pred - y <TAB>  <TAB> diff[diff > consts.FLOAT_ZERO] = 1 <TAB>  <TAB> diff[diff < consts.FLOAT_ZERO] = -1 <TAB>  <TAB> diff[np.abs(diff) <= consts.FLOAT_ZERO] = 0 <TAB>  <TAB> return diff <TAB> else: <TAB>  <TAB> diff = y_pred - y <MASK> return 1 <TAB>  <TAB> elif diff < consts.FLOAT_ZERO: <TAB>  <TAB>  <TAB> return -1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return 0",if diff > consts . FLOAT_ZERO :,171
"def _reorder_cache(self, past, beam_idx): <TAB> reord_past_buckets_states = [] <TAB> for layer_past in past: <TAB>  <TAB> # buckets <MASK> reord_buckets = layer_past[0].index_select(0, beam_idx) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> reord_buckets = None <TAB>  <TAB> # hidden states <TAB>  <TAB> reord_hidden_states = layer_past[1].index_select(0, beam_idx) <TAB>  <TAB> reord_past_buckets_states.append((reord_buckets, reord_hidden_states)) <TAB> return reord_past_buckets_states",if layer_past [ 0 ] is not None :,164
"def getParentNode(self, node): <TAB> if isinstance(node, tuple): <TAB>  <TAB> element, key, parents, flag = node <TAB> else: <TAB>  <TAB> return None <TAB> if flag == ""text"": <MASK> return element <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return element, key, parents, None <TAB> else: <TAB>  <TAB> parent = parents.pop() <TAB>  <TAB> if not parents: <TAB>  <TAB>  <TAB> return parent <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert list(parents[-1]).count(parent) == 1 <TAB>  <TAB>  <TAB> return parent, list(parents[-1]).index(parent), parents, None",if not parents :,146
"def _parse_service_aliases(envvars): <TAB> service_aliases = [] <TAB> for key, value in envvars.iteritems(): <TAB>  <TAB> match = haproxy.config.SERVICE_ALIAS_MATCH.search(key) <MASK> detailed_match = haproxy.config.DETAILED_SERVICE_ALIAS_MATCH.search(key) <TAB>  <TAB>  <TAB> if detailed_match: <TAB>  <TAB>  <TAB>  <TAB> alias = key[: detailed_match.start()] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> alias = key[: match.start()] <TAB>  <TAB>  <TAB> if alias not in service_aliases: <TAB>  <TAB>  <TAB>  <TAB> service_aliases.append(alias) <TAB> return service_aliases",if match :,158
"def get_lines(self, size=-1, last_pass=False): <TAB> if self.is_ready(): <MASK> size = -1 <TAB>  <TAB> self.fds.seek(self.offset) <TAB>  <TAB> for line in self._readlines(hint=size): <TAB>  <TAB>  <TAB> self.offset += len(line) <TAB>  <TAB>  <TAB> yield self._decode(line, last_pass)",if last_pass :,97
"def _send_once(self, data, channel=None): <TAB> try: <TAB>  <TAB> if self.channel == """" and channel: <TAB>  <TAB>  <TAB> # Message must be addressed to a specific channel <MASK> sent = self.socket.sendto(data, (channel,)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> addr = get_addr(self.socket, channel) <TAB>  <TAB>  <TAB>  <TAB> sent = libc.sendto( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.socket.fileno(), data, len(data), 0, addr, len(addr) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sent = self.socket.send(data) <TAB> except socket.error as exc: <TAB>  <TAB> raise can.CanError(""Failed to transmit: %s"" % exc) <TAB> return sent",if HAS_NATIVE_SUPPORT :,195
"def searchJmpReg(self, regs=[""esp""], name=None): <TAB> to_return = {} <TAB> if not name: <TAB>  <TAB> for file in self.__files: <TAB>  <TAB>  <TAB> to_return[file.loader.fileName] = self.__ropper.searchJmpReg( <TAB>  <TAB>  <TAB>  <TAB> file.loader, regs <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> fc = self._getFileFor(name) <MASK> raise RopperError(""No such file opened: %s"" % name) <TAB>  <TAB> to_return[name] = self.__ropper.searchJmpReg(fc.loader, regs) <TAB> return self.__filterBadBytes(to_return)",if not fc :,163
"def _parse_desc_length_file(cls, fileobj): <TAB> """"""May raise ValueError"""""" <TAB> value = 0 <TAB> for i in range(4): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> b = cdata.uint8(fileobj.read(1)) <TAB>  <TAB> except cdata.error as e: <TAB>  <TAB>  <TAB> raise ValueError(e) <TAB>  <TAB> value = (value << 7) | (b & 0x7F) <MASK> break <TAB> else: <TAB>  <TAB> raise ValueError(""invalid descriptor length"") <TAB> return value",if not b >> 7 :,130
"def finish_response(self, extra_headers): <TAB> if not extra_headers: <TAB>  <TAB> extra_headers = [] <TAB> headers = self.headers + extra_headers <TAB> write = self.start_response(self.status, headers, self.exc_info) <TAB> if write: <TAB>  <TAB> self.buffer.seek(0) <TAB>  <TAB> value = self.buffer.getvalue() <TAB>  <TAB> if value: <TAB>  <TAB>  <TAB> write(value) <MASK> write.close()","if hasattr ( write , ""close"" ) :",121
"def on_mouse_move(self, event): <TAB> if event.is_dragging: <TAB>  <TAB> dxy = event.pos - event.last_event.pos <TAB>  <TAB> button = event.press_event.button <MASK> self.points.transform.move(dxy) <TAB>  <TAB> elif button == 2: <TAB>  <TAB>  <TAB> center = event.press_event.pos <TAB>  <TAB>  <TAB> self.points.transform.zoom(np.exp(dxy * (0.01, -0.01)), center) <TAB>  <TAB> self.update()",if button == 1 :,133
"def get_failing_constraints(state, kb: Optional[KnowledgeBase] = None): <TAB> kb = kb or KnowledgeBase.default() <TAB> fail = Proposition(""fail"", []) <TAB> failed_constraints = [] <TAB> constraints = state.all_applicable_actions(kb.constraints.values()) <TAB> for constraint in constraints: <TAB>  <TAB> if state.is_applicable(constraint): <TAB>  <TAB>  <TAB> # Optimistically delay copying the state <TAB>  <TAB>  <TAB> copy = state.copy() <TAB>  <TAB>  <TAB> copy.apply(constraint) <MASK> failed_constraints.append(constraint) <TAB> return failed_constraints",if copy . is_fact ( fail ) :,153
"def slice(self, msgs): <TAB> ret = [] <TAB> now = [] <TAB> for m in msgs: <TAB>  <TAB> if len(now) >= self.size: <TAB>  <TAB>  <TAB> nowtime, lasttime = m.createTime, now[-1].createTime <MASK> ret.append(now) <TAB>  <TAB>  <TAB>  <TAB> now = [m] <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> now.append(m) <TAB> if len(now) > self.size / 2 or len(ret) == 0: <TAB>  <TAB> ret.append(now) <TAB> else: <TAB>  <TAB> ret[-1].extend(now) <TAB> assert len(msgs) == sum([len(k) for k in ret]) <TAB> return ret",if nowtime . date ( ) != lasttime . date ( ) :,179
"def get_clob_type_declaration_sql(self, column): <TAB> length = column.get(""length"") <TAB> if length: <TAB>  <TAB> if length <= self.LENGTH_LIMIT_TINYTEXT: <TAB>  <TAB>  <TAB> return ""TINYTEXT"" <MASK> return ""TEXT"" <TAB>  <TAB> if length <= self.LENGTH_LIMIT_MEDIUMTEXT: <TAB>  <TAB>  <TAB> return ""MEDIUMTEXT"" <TAB> return ""LONGTEXT""",if length <= self . LENGTH_LIMIT_TEXT :,114
"def create_row_processor( <TAB> self, context, path, loadopt, mapper, result, adapter, populators): <TAB> # look through list of columns represented here <TAB> # to see which, if any, is present in the row. <TAB> if loadopt and ""expression"" in loadopt.local_opts: <TAB>  <TAB> columns = [loadopt.local_opts[""expression""]] <TAB>  <TAB> for col in columns: <TAB>  <TAB>  <TAB> if adapter: <TAB>  <TAB>  <TAB>  <TAB> col = adapter.columns[col] <TAB>  <TAB>  <TAB> getter = result._getter(col, False) <MASK> populators[""quick""].append((self.key, getter)) <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> populators[""expire""].append((self.key, True))",if getter :,184
"def sniffer(self, q): <TAB> while not self.stopped: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> sniff( <TAB>  <TAB>  <TAB>  <TAB> iface=self.interface, <TAB>  <TAB>  <TAB>  <TAB> filter=""tcp and ( port 80 or port 8080 or port 10000)"", <TAB>  <TAB>  <TAB>  <TAB> prn=lambda x: q.put(x), <TAB>  <TAB>  <TAB>  <TAB> store=0, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> pass <MASK> break",if self . stopped :,115
"def get_package(path): <TAB> with open(path, ""r"") as fp: <TAB>  <TAB> for line in fp: <TAB>  <TAB>  <TAB> match = self.PACKAGE_RE.match(line) <MASK> return match.group(""package_name"") <TAB>  <TAB> return None",if match :,71
"def recur(node): <TAB> if not node.outputs[0] in shape_of: <TAB>  <TAB> for inp in node.inputs: <MASK> recur(inp.owner) <TAB>  <TAB> # If the output var isn't marked as being in the graph, <TAB>  <TAB> # we need to add it in the ShapeFeature. <TAB>  <TAB> shape_feature.on_import(fgraph, node, ""gof.ops.shape_i"")",if inp . owner :,106
"def test_statuses(self): <TAB> found = False <TAB> statuses = self.jira.statuses() <TAB> for status in statuses: <MASK> found = True <TAB>  <TAB>  <TAB> # find status <TAB>  <TAB>  <TAB> s = self.jira.status(status.id) <TAB>  <TAB>  <TAB> self.assertEqual(s.id, status.id) <TAB>  <TAB>  <TAB> break <TAB> self.assertTrue(found, ""Status Done not found. [%s]"" % statuses) <TAB> self.assertGreater(len(statuses), 0)","if status . name == ""Done"" :",126
"def addURL(self, stepid, name, url, _racehook=None): <TAB> validation.verifyType(self.t, ""stepid"", stepid, validation.IntValidator()) <TAB> validation.verifyType(self.t, ""name"", name, validation.IdentifierValidator(50)) <TAB> validation.verifyType(self.t, ""url"", url, validation.StringValidator()) <TAB> b = self.steps.get(stepid) <TAB> if b: <TAB>  <TAB> urls = json.loads(b[""urls_json""]) <TAB>  <TAB> url_item = dict(name=name, url=url) <MASK> urls.append(url_item) <TAB>  <TAB> b[""urls_json""] = json.dumps(urls) <TAB> return defer.succeed(None)",if url_item not in urls :,185
"def serialize_config(config): <TAB> config_pairs = [] <TAB> for key, value in config.items(): <TAB>  <TAB> if isinstance(value, str): <TAB>  <TAB>  <TAB> value = value.encode(""utf-8"") <MASK> value = base64.b64encode(value).decode(""utf-8"") <TAB>  <TAB> config_pairs.append((key, value)) <TAB> config_str = "";"".join([""{},{}"".format(*kv) for kv in config_pairs]) <TAB> assert "" "" not in config_str, ( <TAB>  <TAB> ""Config parameters currently do not support "" ""spaces:"", <TAB>  <TAB> config_str, <TAB> ) <TAB> return config_str","if isinstance ( value , bytes ) :",159
"def _udublincore(extracted): <TAB> out = [] <TAB> extracted_cpy = copy.deepcopy(extracted) <TAB> for obj in extracted_cpy: <TAB>  <TAB> context = obj.pop(""namespaces"", None) <TAB>  <TAB> obj[""@context""] = context <TAB>  <TAB> elements = obj[""elements""] <TAB>  <TAB> for element in elements: <TAB>  <TAB>  <TAB> for key, value in element.items(): <MASK> obj[""@type""] = element[""content""] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> obj[""elements""].remove(element) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> out.append(obj) <TAB> return out","if get_lower_attrib ( value ) == ""type"" :",160
"def Arrange(self, flag=0): <TAB> """"""For listview 'icon' style."""""" <TAB> if flag: <MASK> flagg = 1  # LVA_ALIGNLEFT <TAB>  <TAB> elif flag == ""top"": <TAB>  <TAB>  <TAB> flag = 2  # LVA_ALIGNTOP <TAB>  <TAB> elif flag == ""snaptogrid"": <TAB>  <TAB>  <TAB> flag = 5  # LVA_SNAPTOGRID <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""invalid flag: %s"" % flag) <TAB> else: <TAB>  <TAB> flag = 0 <TAB> if not self.SendMessage(self.Hwnd, self.Msg.LVM_ARRANGE, flag, 0): <TAB>  <TAB> raise RuntimeError(""could not arrange items"")","if flag == ""left"" :",174
"def _sock_connect_cb(self, fut, sock, address): <TAB> if fut.cancelled(): <TAB>  <TAB> return <TAB> try: <TAB>  <TAB> err = sock.getsockopt(socket.SOL_SOCKET, socket.SO_ERROR) <MASK> # Jump to any except clause below. <TAB>  <TAB>  <TAB> raise OSError(err, ""Connect call failed %s"" % (address,)) <TAB> except (BlockingIOError, InterruptedError): <TAB>  <TAB> # socket is still registered, the callback will be retried later <TAB>  <TAB> pass <TAB> except Exception as exc: <TAB>  <TAB> fut.set_exception(exc) <TAB> else: <TAB>  <TAB> fut.set_result(None)",if err != 0 :,163
"def test_random_queue_666(self): <TAB> for i in range(5): <TAB>  <TAB> self.mux.go_to(None) <TAB>  <TAB> self.pl.set([1]) <TAB>  <TAB> do_events() <TAB>  <TAB> self.failUnless(self.mux.current is None) <TAB>  <TAB> self.q.order = OrderShuffle() <TAB>  <TAB> self.failUnless(self.next() == 1) <TAB>  <TAB> self.q.set([10, 11]) <TAB>  <TAB> do_events() <TAB>  <TAB> value = self.next() <TAB>  <TAB> self.failUnless(value in [10, 11], ""got %r, expected 10 or 11"" % value) <MASK> next = 11 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> next = 10 <TAB>  <TAB> self.failUnlessEqual(self.next(), next)",if value == 10 :,192
"def convert_recursive(path, sheetid, outfile, kwargs): <TAB> for name in os.listdir(path): <TAB>  <TAB> fullpath = os.path.join(path, name) <MASK> convert_recursive(fullpath, sheetid, outfile, kwargs) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> outfilepath = outfile <TAB>  <TAB>  <TAB> if len(outfilepath) == 0 and fullpath.lower().endswith("".xlsx""): <TAB>  <TAB>  <TAB>  <TAB> outfilepath = fullpath[:-4] + ""csv"" <TAB>  <TAB>  <TAB> print(""Converting %s to %s"" % (fullpath, outfilepath)) <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> Xlsx2csv(fullpath, **kwargs).convert(outfilepath, sheetid) <TAB>  <TAB>  <TAB> except zipfile.BadZipfile: <TAB>  <TAB>  <TAB>  <TAB> print(""File %s is not a zip file"" % fullpath)",if os . path . isdir ( fullpath ) :,199
def restore_defaults(self): <TAB> try: <TAB>  <TAB> options = self.options <TAB> except AttributeError: <TAB>  <TAB> return <TAB> old_options = {} <TAB> for option in options: <MASK> old_options[option.name] = config.setting[option.name] <TAB>  <TAB>  <TAB> config.setting[option.name] = option.default <TAB> self.load() <TAB> # Restore the config values incase the user doesn't save after restoring defaults <TAB> for key in old_options: <TAB>  <TAB> config.setting[key] = old_options[key],"if option . section == ""setting"" :",138
"def _write_body(self, start_read: bool) -> None: <TAB> if self.request.body is not None: <TAB>  <TAB> self.connection.write(self.request.body) <TAB> elif self.request.body_producer is not None: <TAB>  <TAB> fut = self.request.body_producer(self.connection.write) <TAB>  <TAB> if fut is not None: <TAB>  <TAB>  <TAB> await fut <TAB> self.connection.finish() <TAB> if start_read: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> await self.connection.read_response(self) <TAB>  <TAB> except StreamClosedError: <MASK> raise",if not self . _handle_exception ( * sys . exc_info ( ) ) :,164
"def read_log_config(settings): <TAB> log = getLogger(__name__) <TAB> for key, value in settings.items(): <TAB>  <TAB> if ""."" not in key: <TAB>  <TAB>  <TAB> log.warn(""Invalid configuration option %r in section %r"" % (key, ""log"")) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> msgtype, key = key.split(""."", 1) <TAB>  <TAB> if key == ""color"": <TAB>  <TAB>  <TAB> current = _msgtype_prefixes[msgtype][0] <TAB>  <TAB>  <TAB> _msgtype_prefixes[msgtype][0] = getattr(text, value, current) <MASK> _msgtype_prefixes[msgtype][1] = value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.warn(""Unknown configuration option %r in section %r"" % (key, ""log""))","elif key == ""symbol"" :",188
"def forward(self, x): <TAB> input_vectors = {} <TAB> for name, emb in self.embeddings.items(): <MASK> input_vectors[name] = emb( <TAB>  <TAB>  <TAB>  <TAB> x[ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ..., <TAB>  <TAB>  <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.x_categoricals.index(cat_name) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for cat_name in self.categorical_groups[name] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ], <TAB>  <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> input_vectors[name] = emb(x[..., self.x_categoricals.index(name)]) <TAB> return input_vectors",if name in self . categorical_groups :,169
"def drop_duplicate_columns(df): <TAB> cols = list(df.columns) <TAB> for idx, item in enumerate(df.columns): <MASK> print(""#####################################################"") <TAB>  <TAB>  <TAB> print(""We found a duplicate column, and will be removing it"") <TAB>  <TAB>  <TAB> print( <TAB>  <TAB>  <TAB>  <TAB> ""If you intended to send in two different pieces of information, please make sure they have different column names"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> print(""Here is the duplicate column:"") <TAB>  <TAB>  <TAB> print(item) <TAB>  <TAB>  <TAB> print(""#####################################################"") <TAB>  <TAB>  <TAB> cols[idx] = ""toDROP"" <TAB> df.columns = cols <TAB> try: <TAB>  <TAB> df = df.drop(""toDROP"", axis=1) <TAB> except: <TAB>  <TAB> pass <TAB> return df",if item in df . columns [ : idx ] :,193
"def fake_fixed_ip_update(context, address, values): <TAB> ips = filter(lambda i: i[""address""] == address, fixed_ips) <TAB> if ips: <TAB>  <TAB> for key in values: <TAB>  <TAB>  <TAB> ips[0][key] = values[key] <MASK> vif = filter(lambda x: x[""id""] == values[key], virtual_interfacees) <TAB>  <TAB>  <TAB>  <TAB> if not vif: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB>  <TAB> fixed_ip_fields[""virtual_interface""] = FakeModel(vif[0])","if key == ""virtual_interface_id"" :",145
"def event_handler(event): <TAB> if isinstance(event, EndStepEvent): <TAB>  <TAB> outs = trainer.test( <TAB>  <TAB>  <TAB> reader=test_reader, <TAB>  <TAB>  <TAB> feed_order=[""firstw"", ""secondw"", ""thirdw"", ""forthw"", ""nextw""], <TAB>  <TAB> ) <TAB>  <TAB> avg_cost = outs[0] <TAB>  <TAB> print(""loss= "", avg_cost) <MASK> trainer.save_params(params_dirname) <TAB>  <TAB>  <TAB> trainer.stop() <TAB>  <TAB> if math.isnan(avg_cost): <TAB>  <TAB>  <TAB> sys.exit(""got NaN loss, training failed."")",if avg_cost < 10.0 :,154
"def _action_resize(self, req, id, body): <TAB> """"""Resizes a given instance to the flavor size requested"""""" <TAB> try: <TAB>  <TAB> flavor_ref = body[""resize""][""flavorRef""] <MASK> msg = _(""Resize request has invalid 'flavorRef' attribute."") <TAB>  <TAB>  <TAB> raise exc.HTTPBadRequest(explanation=msg) <TAB> except (KeyError, TypeError): <TAB>  <TAB> msg = _(""Resize requests require 'flavorRef' attribute."") <TAB>  <TAB> raise exc.HTTPBadRequest(explanation=msg) <TAB> kwargs = {} <TAB> if ""auto_disk_config"" in body[""resize""]: <TAB>  <TAB> kwargs[""auto_disk_config""] = body[""resize""][""auto_disk_config""] <TAB> return self._resize(req, id, flavor_ref, **kwargs)",if not flavor_ref :,190
"def parse_drawings_on_layers(self, drawings, f_layer, b_layer): <TAB> front = [] <TAB> back = [] <TAB> for d in drawings: <MASK> continue <TAB>  <TAB> drawing = self.parse_drawing(d[1]) <TAB>  <TAB> if not drawing: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if d[0] in [""ref"", ""val""]: <TAB>  <TAB>  <TAB> drawing[d[0]] = 1 <TAB>  <TAB> if d[1].GetLayer() == f_layer: <TAB>  <TAB>  <TAB> front.append(drawing) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> back.append(drawing) <TAB> return {""F"": front, ""B"": back}","if d [ 1 ] . GetLayer ( ) not in [ f_layer , b_layer ] :",177
"def main(argv): <TAB> print >>sys.stderr, argv <TAB> try: <TAB>  <TAB> command = argv[1] <TAB> except IndexError: <TAB>  <TAB> command = ""upper"" <TAB> if command == ""upper"": <TAB>  <TAB> func = lambda x: x.upper() <TAB> else: <TAB>  <TAB> func = lambda x: x.lower() <TAB> while True: <TAB>  <TAB> line = sys.stdin.readline() <MASK> print >>sys.stderr, ""DONE %s"" % command <TAB>  <TAB>  <TAB> break <TAB>  <TAB> sys.stdout.write(func(line)) <TAB>  <TAB> # If we don't do this, it hangs forever <TAB>  <TAB> sys.stdout.flush()",if not line :,159
"def _translate_alias(ctxt, path): <TAB> parts = path.split(""/"") <TAB> keys = ctxt[:] <TAB> for part in parts: <MASK> keys.pop() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> match = TYPE_ATTR_RE.match(part) <TAB>  <TAB>  <TAB> if match: <TAB>  <TAB>  <TAB>  <TAB> keys.append(match.group(1)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> assert NAME_RE.match(part) <TAB>  <TAB>  <TAB>  <TAB> keys.append(NAME_MAP.get(part, part)) <TAB> return keys","if part == "".."" :",135
"def _overwriteProjectCallback(self, result, error=False, **kwargs): <TAB> if error: <TAB>  <TAB> # A 404 could arrive if someone else as deleted the project <TAB>  <TAB> if ""status"" not in result or result[""status""] != 404: <TAB>  <TAB>  <TAB> return <MASK> QtWidgets.QMessageBox.critical( <TAB>  <TAB>  <TAB>  <TAB> self, <TAB>  <TAB>  <TAB>  <TAB> ""New Project"", <TAB>  <TAB>  <TAB>  <TAB> ""Error while overwrite project: {}"".format(result[""message""]), <TAB>  <TAB>  <TAB> ) <TAB> Controller.instance().refreshProjectList() <TAB> self.done(True)","elif ""message"" in result :",141
"def installation_report(self, req, dist, what=""Installed""): <TAB> """"""Helpful installation message for display to package users"""""" <TAB> msg = ""\n%(what)s %(eggloc)s%(extras)s"" <TAB> if self.multi_version and not self.no_report: <TAB>  <TAB> msg += ""\n"" + self.__mv_warning <MASK> msg += ""\n"" + self.__id_warning <TAB> eggloc = dist.location <TAB> name = dist.project_name <TAB> version = dist.version <TAB> extras = """"  # TODO: self.report_extras(req, dist) <TAB> return msg % locals()","if self . install_dir not in map ( normalize_path , sys . path ) :",165
"def collect(self): <TAB> artifact_profile = self.session.LoadProfile(""artifacts"") <TAB> for artifact in self.plugin_args.artifacts: <TAB>  <TAB> definition = artifact_profile.definitions_by_name.get(artifact) <MASK> yield dict(divider=artifact) <TAB>  <TAB>  <TAB> yield dict(Message=yaml_utils.safe_dump(definition))",if definition :,90
"def getCategoryInfo(filename): <TAB> config = configparser.ConfigParser() <TAB> with open(filename) as fp: <TAB>  <TAB> config.read_file(fp) <TAB> cate_list = [] <TAB> sections = config.sections() <TAB> for isection in sections: <TAB>  <TAB> category = __get_default() <TAB>  <TAB> category[""name""] = isection <TAB>  <TAB> for (name, value) in config.items(isection): <MASK> category[name] = INIT_FUNC_DICT[name](value) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> name = name[1:] <TAB>  <TAB>  <TAB>  <TAB> name = name.strip() <TAB>  <TAB>  <TAB>  <TAB> category[""keywords""][name] = INIT_FUNC_DICT[""keywords""](value) <TAB>  <TAB> cate_list.append(category) <TAB> return cate_list","if name [ 0 ] != ""*"" :",198
"def cron_frequency(self): <TAB> if ""cron_frequency"" in self.data_dict: <TAB>  <TAB> return self.data_dict[""cron_frequency""] <TAB> else: <TAB>  <TAB> # Backward compatibility <TAB>  <TAB> freq = ""0 0 * * *"" <TAB>  <TAB> if self.frequency_number == 1: <TAB>  <TAB>  <TAB> if self.frequency_unit == ""MINUTES"": <TAB>  <TAB>  <TAB>  <TAB> freq = ""* * * * *"" <TAB>  <TAB>  <TAB> elif self.frequency_unit == ""HOURS"": <TAB>  <TAB>  <TAB>  <TAB> freq = ""0 * * * *"" <TAB>  <TAB>  <TAB> elif self.frequency_unit == ""DAYS"": <TAB>  <TAB>  <TAB>  <TAB> freq = ""0 0 * * *"" <MASK> freq = ""0 0 * * *"" <TAB>  <TAB> return {""frequency"": freq, ""isAdvancedCron"": False}","elif self . frequency_unit == ""MONTH"" :",198
"def _wait_for_finish(self): <TAB> while True: <TAB>  <TAB> if self._backend: <TAB>  <TAB>  <TAB> poll_exit_resp = self._backend.interface.communicate_poll_exit() <TAB>  <TAB> logger.info(""got exit ret: %s"", poll_exit_resp) <TAB>  <TAB> if poll_exit_resp: <TAB>  <TAB>  <TAB> done = poll_exit_resp.done <TAB>  <TAB>  <TAB> pusher_stats = poll_exit_resp.pusher_stats <MASK> self._on_finish_progress(pusher_stats, done) <TAB>  <TAB>  <TAB> if done: <TAB>  <TAB>  <TAB>  <TAB> return poll_exit_resp <TAB>  <TAB> time.sleep(2)",if pusher_stats :,165
"def map_statement_list(self, content): <TAB> body = [] <TAB> for c in content: <TAB>  <TAB> mapped = self.rec(c) <TAB>  <TAB> if mapped is None: <TAB>  <TAB>  <TAB> warn(""mapping '%s' returned None"" % type(c)) <MASK> body.extend(mapped) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> body.append(mapped) <TAB> return body","elif isinstance ( mapped , list ) :",100
"def dump_as_json(results, valid=False): <TAB> first = True <MASK> yield ""["" <TAB> for result in results: <TAB>  <TAB> if valid: <TAB>  <TAB>  <TAB> if first: <TAB>  <TAB>  <TAB>  <TAB> first = False <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield "", "" <TAB>  <TAB> yield json.dumps(result, ensure_ascii=False) + ""\n"" <TAB> if valid: <TAB>  <TAB> yield ""]""",if valid :,101
"def get_static_links(self): <TAB> static_links = set() <TAB> hrefs = self._get_intrasite_link_regex() <TAB> for m in hrefs.finditer(self._content): <TAB>  <TAB> what = m.group(""what"") <TAB>  <TAB> value = urlparse(m.group(""value"")) <TAB>  <TAB> path = value.path <MASK> continue <TAB>  <TAB> if path.startswith(""/""): <TAB>  <TAB>  <TAB> path = path[1:] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # relative to the source path of this content <TAB>  <TAB>  <TAB> path = self.get_relative_source_path(os.path.join(self.relative_dir, path)) <TAB>  <TAB> path = path.replace(""%20"", "" "") <TAB>  <TAB> static_links.add(path) <TAB> return static_links","if what not in { ""static"" , ""attach"" } :",192
"def on_start_epoch(self, state): <TAB> if self.write_batch_metrics: <MASK> self.batch_log_dir = os.path.join(self.log_dir, ""epoch/"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.batch_log_dir = os.path.join( <TAB>  <TAB>  <TAB>  <TAB> self.log_dir, ""epoch-"" + str(state[torchbearer.EPOCH]) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self.batch_writer = self.get_writer(self.batch_log_dir, visdom=self.visdom)",if self . visdom :,143
"def _wait_private_link_operation( <TAB> client, resource_group_name, vault_name, private_endpoint_connection_name): <TAB> retries = 0 <TAB> max_retries = 10 <TAB> wait_second = 1 <TAB> while retries < max_retries: <TAB>  <TAB> pl = client.get( <TAB>  <TAB>  <TAB> resource_group_name=resource_group_name, <TAB>  <TAB>  <TAB> vault_name=vault_name, <TAB>  <TAB>  <TAB> private_endpoint_connection_name=private_endpoint_connection_name, <TAB>  <TAB> ) <MASK> return pl <TAB>  <TAB> time.sleep(wait_second) <TAB>  <TAB> retries += 1 <TAB> return None","if pl . provisioning_state == ""Succeeded"" :",167
"def _get_conflicts_by_artifacts(self, artifacts_by_file_name, jar_rules): <TAB> conflicts_by_artifacts = defaultdict(set) <TAB> for (file_name, artifacts) in artifacts_by_file_name.items(): <TAB>  <TAB> if (not artifacts) or len(artifacts) < 2: <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> if self._jar_rule_handled(file_name, jar_rules): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> conflicts_by_artifacts[tuple(sorted(str(a) for a in artifacts))].add(file_name) <TAB> return conflicts_by_artifacts",if self . _is_excluded ( file_name ) :,160
"def do_rollback(self, dbapi_connection): <TAB> """"""Execute a ROLLBACK."""""" <TAB> try: <TAB>  <TAB> dbapi_connection.rollback() <TAB> except Exception: <TAB>  <TAB> if self.server_version_info < (3, 23, 15): <TAB>  <TAB>  <TAB> args = sys.exc_info()[1].args <MASK> return <TAB>  <TAB> raise",if args and args [ 0 ] == 1064 :,98
"def parse(self, input): <TAB> """"""Parses the given file or file source string."""""" <TAB> if True: <TAB>  <TAB> if hasattr(input, ""name""): <TAB>  <TAB>  <TAB> self.filename = input.name <MASK> self.filename = """" <TAB>  <TAB> if isinstance(input, str): <TAB>  <TAB>  <TAB> input = StringIO(input) <TAB>  <TAB> # clear units to get rid of automatically generated headers before parsing <TAB>  <TAB> self.units = [] <TAB>  <TAB> poparser.parse_units(poparser.ParseState(input, pounit), self)","elif not getattr ( self , ""filename"" , """" ) :",135
"def stack(tensors, dim=0): <TAB> assert isinstance(tensors, list), ""input to stack must be a list"" <TAB> if len(tensors) == 1: <TAB>  <TAB> return tensors[0].unsqueeze(dim) <TAB> from .autograd_cryptensor import AutogradCrypTensor <TAB> if any(isinstance(t, AutogradCrypTensor) for t in tensors): <MASK> tensors[0] = AutogradCrypTensor(tensors[0], requires_grad=False) <TAB>  <TAB> return tensors[0].stack(*tensors[1:], dim=dim) <TAB> else: <TAB>  <TAB> return get_default_backend().stack(tensors, dim=dim)","if not isinstance ( tensors [ 0 ] , AutogradCrypTensor ) :",170
"def __init__(self, mode, file, close=True): <TAB> if mode not in (""r"", ""w"", ""a""): <TAB>  <TAB> raise IOError(""invalid mode: %s"" % mode) <TAB> self._mode = mode <TAB> self._close = close <TAB> if isinstance(file, FileWrapper): <MASK> raise IOError(0, ""Error"") <TAB>  <TAB> self._refcount = file._refcount <TAB>  <TAB> self._refcount[0] += 1 <TAB>  <TAB> self._file = file._file <TAB> else: <TAB>  <TAB> self._refcount = [1] <TAB>  <TAB> self._file = file",if file . _refcount [ 0 ] <= 0 :,147
"def setData(self, index, value, role): <TAB> if ( <TAB>  <TAB> role == QtCore.Qt.EditRole or role == QtCore.Qt.CheckStateRole <TAB> ) and index.isValid(): <TAB>  <TAB> write_field = self.field_dict[index.column()] <TAB>  <TAB> self.layoutAboutToBeChanged.emit() <TAB>  <TAB> this_path = self.filePath(index) <MASK> self.populate_dictionary(this_path) <TAB>  <TAB> self.tag_data[this_path][write_field] = value <TAB>  <TAB> self.depopulate_dictionary() <TAB>  <TAB> self.layoutChanged.emit() <TAB>  <TAB> return True",if this_path not in self . tag_data :,165
"def dict_parse(d): <TAB> tmpValues = {} <TAB> for key, value in d.iteritems(): <TAB>  <TAB> if isinstance(value, dict): <TAB>  <TAB>  <TAB> dict_parse(value) <TAB>  <TAB> if key == ""HOST"": <TAB>  <TAB>  <TAB> tmpValues[""HOST""] = value <MASK> tmpValues[""PORT""] = value <TAB>  <TAB> if key == ""MSFPAYLOAD"": <TAB>  <TAB>  <TAB> tmpValues[""MSFPAYLOAD""] = value <TAB> resourceValues.append(tmpValues)","if key == ""PORT"" :",121
"def touch_all(self): <TAB> diff = self.functions.difference(cache.touched_functions) <TAB> for address in diff: <MASK> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> cfunc = idaapi.decompile(address) <TAB>  <TAB>  <TAB> if cfunc: <TAB>  <TAB>  <TAB>  <TAB> FunctionTouchVisitor(cfunc).process() <TAB>  <TAB> except idaapi.DecompilationFailure: <TAB>  <TAB>  <TAB> logger.warn( <TAB>  <TAB>  <TAB>  <TAB> ""IDA failed to decompile function at {}"".format(to_hex(address)) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> cache.touched_functions.add(address) <TAB> idaapi.decompile(self.cfunc.entry_ea)",if is_imported_ea ( address ) :,168
"def generate_new_element(items, prefix, numeric=False): <TAB> """"""Creates a random string with prefix, that is not in 'items' list."""""" <TAB> while True: <TAB>  <TAB> if numeric: <TAB>  <TAB>  <TAB> candidate = prefix + generate_random_numeric(8) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> candidate = prefix + generate_random_alphanumeric(8) <MASK> return candidate",if candidate not in items :,99
"def find_parent(elm, eldict): <TAB> if isinstance(elm, PyElement): <TAB>  <TAB> if elm.type: <TAB>  <TAB>  <TAB> sup = eldict[elm.type[1]] <TAB>  <TAB>  <TAB> return find_parent(sup, eldict) <TAB>  <TAB> elif elm.ref: <TAB>  <TAB>  <TAB> sup = eldict[elm.ref] <MASK> return elm <TAB>  <TAB>  <TAB> return find_parent(sup, eldict) <TAB> else: <TAB>  <TAB> if elm.superior: <TAB>  <TAB>  <TAB> sup = eldict[elm.superior[0]] <TAB>  <TAB>  <TAB> if sup.done: <TAB>  <TAB>  <TAB>  <TAB> return elm <TAB>  <TAB>  <TAB> return find_parent(sup, eldict) <TAB> return elm",if sup . name == elm . name :,183
"def run(self): <TAB> try: <TAB>  <TAB> for i in range(1, 1 + self.iterations): <MASK> break <TAB>  <TAB>  <TAB> self.watchdog_event.set() <TAB>  <TAB>  <TAB> # print i, ""SEND"" <TAB>  <TAB>  <TAB> self.chan.send(""x"" * 2048) <TAB> finally: <TAB>  <TAB> self.done_event.set() <TAB>  <TAB> self.watchdog_event.set()",if self . done_event . is_set ( ) :,113
"def get_objects(self): <TAB> ctype = ContentType.objects.get_for_model(self.Model) <TAB> ids = range(1, self.users_count) <TAB> for user in User.objects.iterator(): <TAB>  <TAB> for x in xrange(self.objects_with_perms_count): <TAB>  <TAB>  <TAB> filters = { <TAB>  <TAB>  <TAB>  <TAB> ""user"": random.choice(ids), <TAB>  <TAB>  <TAB>  <TAB> ""permission__codename__in"": [self.perm], <TAB>  <TAB>  <TAB>  <TAB> ""content_type"": ctype, <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB> qs = UserObjectPermission.objects.filter(**filters).all() <MASK> qs = [v.object_pk for v in qs] <TAB>  <TAB>  <TAB> list(self.Model.objects.filter(id__in=qs))",if not self . subquery :,190
"def mPing(self, ipPool): <TAB> Sock = self.__icmpSocket <TAB> Sock.settimeout(self.timeout) <TAB> packet = self.__icmpPacket <TAB> recvFroms = set() <TAB> sendThr = SendPingThr(ipPool, packet, Sock, self.timeout) <TAB> sendThr.start() <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> ac_ip = Sock.recvfrom(1024)[1][0] <MASK> log.write(""active"", ac_ip, 0, None) <TAB>  <TAB>  <TAB>  <TAB> recvFroms.add(ac_ip) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> if not sendThr.isAlive(): <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return recvFroms & ipPool",if ac_ip not in recvFroms :,199
def getPlaylistState(self): <TAB> playlistItems = [] <TAB> for playlistItem in range(self.playlist.count()): <TAB>  <TAB> playlistItemText = self.playlist.item(playlistItem).text() <MASK> playlistItems.append(playlistItemText) <TAB> return playlistItems,"if playlistItemText != getMessage ( ""playlist-instruction-item-message"" ) :",84
"def _choose_formatting_pattern_for_number(available_formats, national_number): <TAB> for num_format in available_formats: <TAB>  <TAB> size = len(num_format.leading_digits_pattern) <TAB>  <TAB> # We always use the last leading_digits_pattern, as it is the most detailed. <TAB>  <TAB> if size > 0: <TAB>  <TAB>  <TAB> ld_pattern = re.compile(num_format.leading_digits_pattern[-1]) <TAB>  <TAB>  <TAB> ld_match = ld_pattern.match(national_number) <MASK> format_pattern = re.compile(num_format.pattern) <TAB>  <TAB>  <TAB> if fullmatch(format_pattern, national_number): <TAB>  <TAB>  <TAB>  <TAB> return num_format <TAB> return None",if size == 0 or ld_match :,183
"def __init__(self, size, color=None, ismask=False, duration=None): <TAB> w, h = size <TAB> if ismask: <TAB>  <TAB> shape = (h, w) <TAB>  <TAB> if color is None: <TAB>  <TAB>  <TAB> color = 0 <TAB>  <TAB> elif not np.isscalar(color): <TAB>  <TAB>  <TAB> raise Exception(""Color has to be a scalar when mask is true"") <TAB> else: <TAB>  <TAB> if color is None: <TAB>  <TAB>  <TAB> color = (0, 0, 0) <MASK> raise Exception(""Color has to contain RGB of the clip"") <TAB>  <TAB> shape = (h, w, len(color)) <TAB> super().__init__( <TAB>  <TAB> np.tile(color, w * h).reshape(shape), ismask=ismask, duration=duration <TAB> )","elif not hasattr ( color , ""__getitem__"" ) :",191
"def get_login_redirect_url(self, request): <TAB> if request.user.is_authenticated(): <TAB>  <TAB> for account in request.user.socialaccount_set.all(): <MASK> return self.default_login_redirect_url(request) <TAB>  <TAB> return ""/accounts/connect"" <TAB> else: <TAB>  <TAB> return self.default_login_redirect_url(request)","if account . provider == ""github"" :",101
"def close(self): <TAB> with self._global_lock: <TAB>  <TAB> if self._dbm_shutdown.is_set(): <TAB>  <TAB>  <TAB> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._dbm_shutdown.set() <MASK> atexit.unregister(self.close) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> atexit._exithandlers.remove((self.close, (), {})) <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> # shutdown the _dbm_thread <TAB>  <TAB> self._event_queue.shutdown() <TAB>  <TAB> self._event_queue.bypass((""localhost"", (ShutdownException(),))) <TAB>  <TAB> self._dbm_thread.join()","if hasattr ( atexit , ""unregister"" ) :",175
"def heartbeat(self) -> None: <TAB> for process in list(self.processes): <TAB>  <TAB> if process.poll() is not None: <TAB>  <TAB>  <TAB> self.processes.remove(process) <MASK> self.logger.info( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Process PID {} returned non-zero exit code"".format(process.pid) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> super().heartbeat()",if process . returncode :,99
"def visit_Import(self, node): <TAB> for alias in node.names: <MASK> line = self._get_line_content(self.filename, node.lineno) <TAB>  <TAB>  <TAB> raise AssertionError( <TAB>  <TAB>  <TAB>  <TAB> ""A bare 'import six' was found in %s:\n"" <TAB>  <TAB>  <TAB>  <TAB> ""\n%s: %s\n"" <TAB>  <TAB>  <TAB>  <TAB> ""Please use 'from botocore.compat import six' instead"" <TAB>  <TAB>  <TAB>  <TAB> % (self.filename, node.lineno, line) <TAB>  <TAB>  <TAB> )","if getattr ( alias , ""name"" , """" ) == ""six"" :",139
"def _on_window_focus(self, i3conn, event): <TAB> window_id = event.container.id <TAB> con = self.i3.get_tree().find_by_id(window_id) <TAB> if not self._is_window(con): <TAB>  <TAB> return <TAB> with self.window_list_lock: <TAB>  <TAB> if window_id in self.window_list: <TAB>  <TAB>  <TAB> self.window_list.remove(window_id) <TAB>  <TAB> self.window_list.insert(0, window_id) <MASK> del self.window_list[MAX_WIN_HISTORY:]",if len ( self . window_list ) > MAX_WIN_HISTORY :,161
"def imshow_item(self): <TAB> """"""Imshow item"""""" <TAB> index = self.currentIndex() <TAB> if self.__prepare_plot(): <TAB>  <TAB> key = self.model.get_key(index) <TAB>  <TAB> try: <MASK> self.show_image(key) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.imshow(key) <TAB>  <TAB> except (ValueError, TypeError) as error: <TAB>  <TAB>  <TAB> QMessageBox.critical( <TAB>  <TAB>  <TAB>  <TAB> self, <TAB>  <TAB>  <TAB>  <TAB> _(""Plot""), <TAB>  <TAB>  <TAB>  <TAB> _(""<b>Unable to show image.</b>"" ""<br><br>Error message:<br>%s"") <TAB>  <TAB>  <TAB>  <TAB> % str(error), <TAB>  <TAB>  <TAB> )",if self . is_image ( key ) :,175
"def __install_package(self, toolname, tool): <TAB> """"""Check if the package is already installed, otherwise add repo (if any) and use apt-get to install it."""""" <TAB> packages, repo = tool[""PACKAGES""], tool[""REPO""] <TAB> for pk in packages: <MASK> self.device.printer.debug(""[INSTALL] Already installed: %s."" % pk) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.device.printer.verbose( <TAB>  <TAB>  <TAB>  <TAB> ""[INSTALL] Installing %s via apt-get."" % toolname <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> if repo: <TAB>  <TAB>  <TAB>  <TAB> self.__apt_add_repo(repo) <TAB>  <TAB>  <TAB> self.__apt_install(pk)",if pk in self . _packagelist :,174
"def write(self, s): <TAB> if not isinstance(s, str): <TAB>  <TAB> s = ( <TAB>  <TAB>  <TAB> s.decode(self.encoding, ""replace"") <MASK> else s.encode(self.encoding, ""replace"") <TAB>  <TAB> ) <TAB> try: <TAB>  <TAB> self.stream.write(s) <TAB> except UnicodeEncodeError: <TAB>  <TAB> s_bytes = s.encode(self.stream.encoding, ""backslashreplace"") <TAB>  <TAB> if hasattr(self.stream, ""buffer""): <TAB>  <TAB>  <TAB> self.stream.buffer.write(s_bytes) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> s = s_bytes.decode(self.stream.encoding, ""ignore"") <TAB>  <TAB>  <TAB> self.stream.write(s)",if dnf . pycomp . PY3,179
"def scatter(self, scatter_list, src, size=None): <TAB> """"""Scatters a list of tensors to all parties."""""" <TAB> assert dist.is_initialized(), ""initialize the communicator first"" <TAB> if src != self.get_rank(): <MASK> size = scatter_list[self.get_rank()].size() <TAB>  <TAB> tensor = torch.empty(size=size, dtype=torch.long) <TAB>  <TAB> dist.scatter(tensor, [], src, group=self.main_group) <TAB> else: <TAB>  <TAB> tensor = scatter_list[self.get_rank()] <TAB>  <TAB> dist.scatter(tensor, [t for t in scatter_list], src, group=self.main_group) <TAB> return tensor",if size is None :,173
"def numeric_types_hook(dct): <TAB> if isinstance(dct, dict): <TAB>  <TAB> if ""__decimal__"" in dct: <TAB>  <TAB>  <TAB> return Decimal(dct[""__decimal__""]) <MASK> return Fraction(numerator=dct[""numerator""], denominator=dct[""denominator""]) <TAB> return dct","if ""__fraction__"" in dct :",74
"def _make_boundary(cls, text=None): <TAB> # Craft a random boundary.  If text is given, ensure that the chosen <TAB> # boundary doesn't appear in the text. <TAB> token = random.randrange(sys.maxsize) <TAB> boundary = (""="" * 15) + (_fmt % token) + ""=="" <TAB> if text is None: <TAB>  <TAB> return boundary <TAB> b = boundary <TAB> counter = 0 <TAB> while True: <TAB>  <TAB> cre = cls._compile_re(""^--"" + re.escape(b) + ""(--)?$"", re.MULTILINE) <MASK> break <TAB>  <TAB> b = boundary + ""."" + str(counter) <TAB>  <TAB> counter += 1 <TAB> return b",if not cre . search ( text ) :,166
"def _load_cookies(self): <TAB> with open(self._TMP_FILES[""cookies""].name, ""rb"") as f: <TAB>  <TAB> cookies = json.loads(f.read().decode(""utf-8"")) <TAB> for cookie in cookies: <TAB>  <TAB> if cookie[""httponly""] is True: <TAB>  <TAB>  <TAB> cookie[""rest""] = {""httpOnly"": None} <MASK> cookie[""expire_time""] = cookie[""expiry""] <TAB>  <TAB> self.extractor._set_cookie(**compat_kwargs(cookie))","if ""expiry"" in cookie :",124
"def loads(self, val): <TAB> try: <TAB>  <TAB> val = simplejson.loads(val, encoding=settings.DEFAULT_CHARSET) <TAB>  <TAB> # XXX We need to investigate why this is happening once we have <TAB>  <TAB> # <TAB>  a solid repro case. <MASK> logging.warning( <TAB>  <TAB>  <TAB>  <TAB> ""JSONField decode error. Expected dictionary, "" <TAB>  <TAB>  <TAB>  <TAB> ""got string for input '%s'"" % val <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> # For whatever reason, we may have gotten back <TAB>  <TAB>  <TAB> val = simplejson.loads(val, encoding=settings.DEFAULT_CHARSET) <TAB> except ValueError: <TAB>  <TAB> # There's probably embedded unicode markers (like u'foo') in the <TAB>  <TAB> # string. We have to eval it. <TAB>  <TAB> val = eval(val) <TAB> return val","if isinstance ( val , basestring ) :",198
"def _maybe_load_as_instance_attribute(self, node, obj, name): <TAB> assert isinstance(obj, abstract.SimpleValue) <TAB> if not isinstance(obj.cls, mixin.Class): <TAB>  <TAB> return <TAB> for base in obj.cls.mro: <TAB>  <TAB> if isinstance(base, abstract.ParameterizedClass): <TAB>  <TAB>  <TAB> base = base.base_cls <TAB>  <TAB> if isinstance(base, abstract.PyTDClass): <TAB>  <TAB>  <TAB> var = base.convert_as_instance_attribute(name, obj) <TAB>  <TAB>  <TAB> if var is not None: <MASK> obj.members[name].PasteVariable(var, node) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> obj.members[name] = var <TAB>  <TAB>  <TAB>  <TAB> return",if name in obj . members :,191
"def _get_split_points(summary, percentile_rate, allow_duplicate): <TAB> split_point = [] <TAB> for percen_rate in percentile_rate: <TAB>  <TAB> s_p = summary.query(percen_rate) <TAB>  <TAB> if not allow_duplicate: <MASK> split_point.append(s_p) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> split_point.append(s_p) <TAB> return split_point",if s_p not in split_point :,118
"def analyze(self, contract: ""ContractSolc""): <TAB> for elem_to_parse in self._elemsNotParsed: <TAB>  <TAB> elem = EventVariable() <TAB>  <TAB> # Todo: check if the source offset is always here <MASK> elem.set_offset(elem_to_parse[""src""], self._parser_contract.slither) <TAB>  <TAB> elem_parser = EventVariableSolc(elem, elem_to_parse) <TAB>  <TAB> elem_parser.analyze(contract) <TAB>  <TAB> self._event.elems.append(elem) <TAB> self._elemsNotParsed = []","if ""src"" in elem_to_parse :",147
"def _assert_valid_bound(bound): <TAB> if isinstance(bound, tuple): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> start, end = bound <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""A `bound` must be a tuple of exactly "" <TAB>  <TAB>  <TAB>  <TAB> ""two coordinates, not {!r}"".format(bound) <TAB>  <TAB>  <TAB> ) <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""`start` (%r) cannot be a larger int "" ""than `end` (%r)."" % (start, end) <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> raise TypeError(""Each `bound` must be a tuple, not {!r}"".format(bound))","if not ( isinstance ( start , int ) and isinstance ( end , int ) ) or start > end :",180
"def server_static(filename): <TAB> entries = core.find_packages(packages()) <TAB> for x in entries: <TAB>  <TAB> f = x.relfn_unix <MASK> response = static_file( <TAB>  <TAB>  <TAB>  <TAB> filename, <TAB>  <TAB>  <TAB>  <TAB> root=x.root, <TAB>  <TAB>  <TAB>  <TAB> mimetype=mimetypes.guess_type(filename)[0], <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> if config.cache_control: <TAB>  <TAB>  <TAB>  <TAB> response.set_header( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Cache-Control"", ""public, max-age=%s"" % config.cache_control <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return response <TAB> return HTTPError(404, ""Not Found (%s does not exist)\n\n"" % filename)",if f == filename :,179
"def reverse_map_path_id( <TAB> path_id: irast.PathId, path_id_map: Dict[irast.PathId, irast.PathId]) -> irast.PathId: <TAB> for outer_id, inner_id in path_id_map.items(): <TAB>  <TAB> new_path_id = path_id.replace_prefix(inner_id, outer_id) <MASK> path_id = new_path_id <TAB>  <TAB>  <TAB> break <TAB> return path_id",if new_path_id != path_id :,135
"def _check_path(self, config_path, node): <TAB> if regex.match(r""ns=\d*;[isgb]=.*"", config_path, regex.IGNORECASE): <TAB>  <TAB> return config_path <TAB> if re.search(r""^root"", config_path.lower()) is None: <TAB>  <TAB> node_path = ""\\\\."".join( <TAB>  <TAB>  <TAB> char.split("":"")[1] for char in node.get_path(200000, True) <TAB>  <TAB> ) <MASK> information_path = node_path + ""\\\\."" + config_path.replace(""\\"", ""\\\\"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> information_path = node_path + config_path.replace(""\\"", ""\\\\"") <TAB> else: <TAB>  <TAB> information_path = config_path <TAB> result = information_path[:] <TAB> return result","if config_path [ - 3 : ] != ""\\."" :",196
"def parse_generator(self): <TAB> while True: <MASK> break <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> result = self.result_queue.get(timeout=0.25) <TAB>  <TAB> except queue.Empty: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = result[1] <TAB>  <TAB>  <TAB> if isinstance(value, BaseException): <TAB>  <TAB>  <TAB>  <TAB> raise value <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield result",if self . parsed >= self . toparse :,115
"def from_update(cls, update: object, dispatcher: ""Dispatcher"") -> ""CallbackContext"": <TAB> self = cls(dispatcher) <TAB> if update is not None and isinstance(update, Update): <TAB>  <TAB> chat = update.effective_chat <TAB>  <TAB> user = update.effective_user <TAB>  <TAB> if chat: <TAB>  <TAB>  <TAB> self._chat_data = dispatcher.chat_data[chat.id]  # pylint: disable=W0212 <MASK> self._user_data = dispatcher.user_data[user.id]  # pylint: disable=W0212 <TAB> return self",if user :,137
"def __missing__(self, key): <TAB> ch = self.get(key) <TAB> if ch is not None: <TAB>  <TAB> return ch <TAB> try: <TAB>  <TAB> de = unicodedata.decomposition(unichr(key)) <TAB>  <TAB> p1, _, p2 = de.rpartition("" "") <MASK> ch = self.get(key) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ch = int(p1, 16) <TAB> except (IndexError, ValueError): <TAB>  <TAB> ch = self.get(key, key) <TAB> self[key] = ch <TAB> return ch","if int ( p2 , 16 ) == 0x308 :",143
"def _convertList(self, l): <TAB> r = [] <TAB> for i in l: <TAB>  <TAB> if isinstance(i, bytes): <TAB>  <TAB>  <TAB> r.append(str(i, ""utf-8"")) <TAB>  <TAB> elif isinstance(i, list) or isinstance(i, tuple): <TAB>  <TAB>  <TAB> r.append(self._convertList(i)) <MASK> r.append(self._convertDict(i)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> r.append(i) <TAB> return r","elif isinstance ( i , dict ) :",125
"def walk_helper(arg, dirname, files): <TAB> if "".git"" in dirname: <TAB>  <TAB> return <TAB> names = [] <TAB> (lst,) = arg <TAB> for wc in wildcards: <TAB>  <TAB> wc_name = opj(dirname, wc) <TAB>  <TAB> for f in files: <TAB>  <TAB>  <TAB> filename = opj(dirname, f) <MASK> names.append(filename) <TAB> lst.append((dirname.replace(srcdir, dstdir), names))","if fnmatch ( filename , wc_name ) and not os . path . isdir ( filename ) :",133
"def _handle_error(response): <TAB> if isinstance(response, dict): <TAB>  <TAB> error = response.get(""error"") <MASK> raise ExtractorError(error, expected=True) <TAB>  <TAB> if response.get(""type"") == ""captcha"" or ""captcha"" in response: <TAB>  <TAB>  <TAB> YandexMusicBaseIE._raise_captcha()",if error :,86
"def iter(self, name=None, wantrecurse=None): <TAB> if len(self.m) > len(INDEX_HDR) + ENTLEN: <TAB>  <TAB> dname = name <MASK> dname += ""/"" <TAB>  <TAB> root = ExistingEntry(None, ""/"", ""/"", self.m, len(self.m) - FOOTLEN - ENTLEN) <TAB>  <TAB> for sub in root.iter(name=name, wantrecurse=wantrecurse): <TAB>  <TAB>  <TAB> yield sub <TAB>  <TAB> if not dname or dname == root.name: <TAB>  <TAB>  <TAB> yield root","if dname and not dname . endswith ( ""/"" ) :",144
"def process(self) -> None: <TAB> if self._delay is None: <TAB>  <TAB> self._output = self._func(*self._args, **self._kwargs) <TAB>  <TAB> # compute the delay and add to queue <TAB>  <TAB> self._delay = 1.0 <MASK> self._delay = max( <TAB>  <TAB>  <TAB>  <TAB> 0, <TAB>  <TAB>  <TAB>  <TAB> self._func.compute_pseudotime((self._args, self._kwargs), self._output), <TAB>  <TAB>  <TAB> )","if isinstance ( self . _func , ExperimentFunction ) :",125
"def __render_pair_no_trailing(self, key, value): <TAB> data = [] <TAB> for (track, total) in value: <MASK> data.append(struct.pack("">3H"", 0, track, total)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise MP4MetadataValueError(""invalid numeric pair %r"" % ((track, total),)) <TAB> return self.__render_data(key, 0, AtomDataType.IMPLICIT, data)",if 0 <= track < 1 << 16 and 0 <= total < 1 << 16 :,123
"def __str__(self, prefix="""", printElemNumber=0): <TAB> res = """" <TAB> cnt = 0 <TAB> for e in self.status_: <TAB>  <TAB> elm = """" <MASK> elm = ""(%d)"" % cnt <TAB>  <TAB> res += prefix + (""status%s: %s\n"" % (elm, self.DebugFormatInt32(e))) <TAB>  <TAB> cnt += 1 <TAB> return res",if printElemNumber :,101
"def on_task(body, message): <TAB> ret = predicate(body, message) <TAB> if ret: <TAB>  <TAB> if transform: <TAB>  <TAB>  <TAB> ret = transform(ret) <TAB>  <TAB> if isinstance(ret, Queue): <TAB>  <TAB>  <TAB> maybe_declare(ret, conn.default_channel) <TAB>  <TAB>  <TAB> ex, rk = ret.exchange.name, ret.routing_key <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ex, rk = expand_dest(ret, exchange, routing_key) <TAB>  <TAB> republish(producer, message, exchange=ex, routing_key=rk) <TAB>  <TAB> message.ack() <TAB>  <TAB> state.filtered += 1 <MASK> callback(state, body, message) <TAB>  <TAB> if limit and state.filtered >= limit: <TAB>  <TAB>  <TAB> raise StopFiltering()",if callback :,188
"def split_args_in_optional_and_positional(args): <TAB> # manually parsing positional arguments because stupid argparse can't mix <TAB> # positional and optional arguments <TAB> positions = [] <TAB> for i, arg in enumerate(args): <TAB>  <TAB> previous = None <MASK> previous = args[i - 1] <TAB>  <TAB> if (not arg.startswith(""--"")) and ( <TAB>  <TAB>  <TAB> previous not in OPTIONAL_ARGUMENTS_THAT_TAKE_VALUES <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> positions.append(i) <TAB> positionals = [arg for i, arg in enumerate(args) if i in positions] <TAB> args = [arg for i, arg in enumerate(args) if i not in positions] <TAB> return (positionals, args)",if i > 0 :,178
"def Skip(self, characters): <TAB> skip = characters <TAB> while skip > 0: <TAB>  <TAB> line = self.stream[self._currentLine - 1] <TAB>  <TAB> eline = line[self._currentColumn - 1 :] <MASK> # pragma: no cover <TAB>  <TAB>  <TAB> self._currentLine += 1 <TAB>  <TAB>  <TAB> self._currentColumn = 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._currentColumn += skip <TAB>  <TAB> skip -= len(eline) + 1",if skip > len ( eline ) + 1 :,118
"def run(self, testlet, testletName): <TAB> testletName = self._cleanName(testletName) <TAB> self._currTestlet = testletName <TAB> if __envir__.executor_name == __envir__.transpiler_name: <TAB>  <TAB> self.testDict[self._currTestlet] = [] <TAB> else: <TAB>  <TAB> self.refDict[self._currTestlet] = [] <TAB> try: <TAB>  <TAB> testlet.run(self) <TAB> except Exception as exc: <MASK> self.ui.setOutputStatus(False) <TAB>  <TAB>  <TAB> self.ui.showException(testletName, exc) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Error - No UI yet, reraise specific exception to enable finding out why <TAB>  <TAB>  <TAB> raise",if self . ui is not None :,190
"def get_events(self, timeout): <TAB> # max_events must be > 0 or kqueue gets cranky <TAB> # and we generally want this to be strictly larger than the actual <TAB> # number of events we get, so that we can tell that we've gotten <TAB> # all the events in just 1 call. <TAB> max_events = len(self._registered) + 1 <TAB> events = [] <TAB> while True: <TAB>  <TAB> batch = self._kqueue.control([], max_events, timeout) <TAB>  <TAB> events += batch <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> timeout = 0 <TAB>  <TAB>  <TAB> # and loop back to the start <TAB> return events",if len ( batch ) < max_events :,164
"def linear(x, names, shapes, has_bias=True): <TAB> """"""Linear Layer."""""" <TAB> assert len(shapes) == 2 <TAB> with tf.variable_scope(names): <TAB>  <TAB> weights = tf.get_variable( <TAB>  <TAB>  <TAB> name=""weights"", shape=shapes, initializer=tf.initializers.glorot_uniform() <TAB>  <TAB> ) <MASK> bias = tf.get_variable( <TAB>  <TAB>  <TAB>  <TAB> name=""bias"", <TAB>  <TAB>  <TAB>  <TAB> shape=shapes[1], <TAB>  <TAB>  <TAB>  <TAB> initializer=tf.initializers.glorot_uniform(), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return tf.matmul(x, weights) + bias <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return tf.matmul(x, weights)",if has_bias :,172
"def _chunk_array_leaves_in_place(d): <TAB> """"""Convert oversized array leaves to safe chunked form in place."""""" <TAB> if isinstance(d, dict): <TAB>  <TAB> for k, v in d.items(): <TAB>  <TAB>  <TAB> if isinstance(v, np.ndarray): <TAB>  <TAB>  <TAB>  <TAB> if v.size * v.dtype.itemsize > MAX_CHUNK_SIZE: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> d[k] = _chunk(v) <MASK> _chunk_array_leaves_in_place(v) <TAB> elif isinstance(d, np.ndarray): <TAB>  <TAB> if d.size * d.dtype.itemsize > MAX_CHUNK_SIZE: <TAB>  <TAB>  <TAB> return _chunk(d) <TAB> return d","elif isinstance ( v , dict ) :",176
"def in_filter(stanza): <TAB> if isinstance(stanza, Message): <MASK> stanza[""subject""] = stanza[""body""] + "" filter"" <TAB>  <TAB>  <TAB> print("">>> %s"" % stanza[""subject""]) <TAB> return stanza","if stanza [ ""body"" ] == ""testing"" :",79
"def allow_deletion( <TAB> *, <TAB> body: bodies.Body, <TAB> patch: patches.Patch, <TAB> finalizer: str,) -> None: <TAB> if is_deletion_blocked(body=body, finalizer=finalizer): <TAB>  <TAB> finalizers = body.get(""metadata"", {}).get(""finalizers"", []) <TAB>  <TAB> patch.setdefault(""metadata"", {}).setdefault(""finalizers"", list(finalizers)) <MASK> patch[""metadata""][""finalizers""].remove(LEGACY_FINALIZER) <TAB>  <TAB> if finalizer in patch[""metadata""][""finalizers""]: <TAB>  <TAB>  <TAB> patch[""metadata""][""finalizers""].remove(finalizer)","if LEGACY_FINALIZER in patch [ ""metadata"" ] [ ""finalizers"" ] :",164
"def _call_init(self, *options, **kwds): <TAB> if not ""data"" in kwds: <TAB>  <TAB> if len(options) > 0: <MASK> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""A PyomoTask instance can only be executed with a single non-keyword argument"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> kwds[""data""] = options[0] <TAB>  <TAB>  <TAB> # options = options[1:] <TAB>  <TAB> elif not self.inputs.data.optional: <TAB>  <TAB>  <TAB> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB> ""A PyomoTask instance must be executed with at 'data' argument"" <TAB>  <TAB>  <TAB> ) <TAB> self._kwds = kwds <TAB> return PyomoTaskPlugin._call_init(self, **kwds)",if len ( options ) > 1 :,183
"def _apply_to_numpy(self, key, value, inplace=True): <TAB> if value is None: <TAB>  <TAB> return value <TAB> if key == ""_is_tensor"": <TAB>  <TAB> # set is_tensor to True <TAB>  <TAB> return False <TAB> if isinstance(value, EdgeIndex): <TAB>  <TAB> value = value.numpy(inplace=inplace) <TAB> elif isinstance(value, dict): <MASK> for k, v in value.items(): <TAB>  <TAB>  <TAB>  <TAB> value[k] = v.numpy() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_value = {} <TAB>  <TAB>  <TAB> for k, v in value.items(): <TAB>  <TAB>  <TAB>  <TAB> new_value[k] = v.numpy() <TAB>  <TAB>  <TAB> value = new_value <TAB> else: <TAB>  <TAB> value = value.numpy() <TAB> return value",if inplace :,190
"def __new__(cls, name, bases, attrs): <TAB> try: <TAB>  <TAB> Filter <TAB> except NameError: <TAB>  <TAB> # Don't generate a name for the baseclass itself. <TAB>  <TAB> pass <TAB> else: <MASK> filter_name = name <TAB>  <TAB>  <TAB> if name.endswith(""Filter""): <TAB>  <TAB>  <TAB>  <TAB> filter_name = filter_name[:-6] <TAB>  <TAB>  <TAB> filter_name = filter_name.lower() <TAB>  <TAB>  <TAB> attrs[""name""] = filter_name <TAB> return type.__new__(cls, name, bases, attrs)","if not ""name"" in attrs :",135
"def current_suggestion(self): <TAB> if self.current_line: <TAB>  <TAB> for entry in reversed(self.rl_history.entries): <MASK> return entry[len(self.current_line) :] <TAB> return """"",if entry . startswith ( self . current_line ) :,69
"def getChildById(self, id): <TAB> if self.id == id: <TAB>  <TAB> return self <TAB> # Already-closed entries don't have children <TAB> for child in getattr(self, ""children"", []): <MASK> return child <TAB>  <TAB> if hasattr(child, ""getChildById""): <TAB>  <TAB>  <TAB> found = child.getChildById(id) <TAB>  <TAB>  <TAB> if found: <TAB>  <TAB>  <TAB>  <TAB> return found <TAB> return None",if child . id == id :,108
"def _handle_tuple(target, spec, scope): <TAB> res = target <TAB> for subspec in spec: <TAB>  <TAB> scope = chain_child(scope) <TAB>  <TAB> nxt = scope[glom](res, subspec, scope) <TAB>  <TAB> if nxt is SKIP: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if nxt is STOP: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> res = nxt <MASK> scope[Path] += [getattr(subspec, ""__name__"", subspec)] <TAB> return res","if not isinstance ( subspec , list ) :",123
"def __call__(self, environ, start_response): <TAB> if not environ.get(""SERVER_SOFTWARE"", """").startswith(""Dev""): <TAB>  <TAB> if not users.is_current_user_admin(): <MASK> start_response( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""302 Found"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> [(""Location"", users.create_login_url(os.getenv(""PATH_INFO"", """")))], <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> return [] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> start_response(""403 Forbidden"", []) <TAB>  <TAB>  <TAB>  <TAB> return [""Forbidden\n""] <TAB> return self._application(environ, start_response)",if users . get_current_user ( ) is None :,165
"def _get_files(self, root): <TAB> train_files = [] <TAB> test_files = [] <TAB> files = [ <TAB>  <TAB> os.path.join(root, f) <TAB>  <TAB> for f in os.listdir(root) <TAB>  <TAB> if os.path.isfile(os.path.join(root, f)) <TAB> ] <TAB> for fname in files: <MASK> train_files.append(fname) <TAB>  <TAB> elif fname.find(""test"") != -1: <TAB>  <TAB>  <TAB> test_files.append(fname) <TAB> return train_files, test_files","if fname . find ( ""train"" ) != - 1 :",147
"def __exit__(self, exc_type, exc_val, exc_tb): <TAB> with self.database._conn_lock: <MASK> self.database.pop_execution_context() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> if self.with_transaction: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if not exc_type: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.txn.commit(False) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.txn.__exit__(exc_type, exc_val, exc_tb) <TAB>  <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB>  <TAB> self.database.pop_execution_context() <TAB>  <TAB>  <TAB>  <TAB> self.database._close(self.connection)",if self . connection is None :,164
"def test_mode_off(): <TAB> try: <TAB>  <TAB> prev_env_var_value = os.environ.pop(_AUTOLOGGING_TEST_MODE_ENV_VAR, None) <TAB>  <TAB> os.environ[_AUTOLOGGING_TEST_MODE_ENV_VAR] = ""false"" <TAB>  <TAB> assert not _is_testing() <TAB>  <TAB> yield <TAB> finally: <MASK> os.environ[_AUTOLOGGING_TEST_MODE_ENV_VAR] = prev_env_var_value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> del os.environ[_AUTOLOGGING_TEST_MODE_ENV_VAR]",if prev_env_var_value :,150
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> length = d.getVarInt32() <TAB>  <TAB>  <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB>  <TAB>  <TAB> d.skip(length) <TAB>  <TAB>  <TAB> self.mutable_scope().TryMerge(tmp) <TAB>  <TAB>  <TAB> continue <MASK> self.set_permission(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 26: <TAB>  <TAB>  <TAB> self.set_display_name(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 16 :,199
"def postprocess_query_param(self, key, field_name, operation): <TAB> if field_name == ""parent"": <MASK> operation[""source_field_name""] = ""parent___id"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if len(operation[""value""]) > 1: <TAB>  <TAB>  <TAB>  <TAB> operation[""source_field_name""] = ""parent___id__in"" <TAB>  <TAB>  <TAB> elif len(operation[""value""]) == 1: <TAB>  <TAB>  <TAB>  <TAB> operation[""source_field_name""] == ""parent___id"" <TAB>  <TAB>  <TAB>  <TAB> operation[""value""] = operation[""value""][0] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> operation[""source_field_name""] = ""parent__isnull"" <TAB>  <TAB>  <TAB>  <TAB> operation[""value""] = True","if operation [ ""value"" ] not in ( list ( ) , tuple ( ) ) :",186
"def delegate(self): <TAB> if web.ctx.path == ""/admin"": <TAB>  <TAB> return self.handle(admin_index) <TAB> for t in admin_tasks: <TAB>  <TAB> m = web.re_compile(""^"" + t.path + ""$"").match(web.ctx.path) <MASK> return self.handle(t.cls, m.groups(), librarians=t.librarians) <TAB> raise web.notfound()",if m :,108
"def decode(self, ids, strip_extraneous=False): <TAB> bases = [] <TAB> for idx in ids: <TAB>  <TAB> if idx >= self._num_reserved_ids: <TAB>  <TAB>  <TAB> chunk = self._ids_to_tokens[idx] <TAB>  <TAB>  <TAB> if self.PAD in chunk: <TAB>  <TAB>  <TAB>  <TAB> chunk = chunk[: chunk.index(self.PAD)] <TAB>  <TAB> else: <MASK> continue <TAB>  <TAB>  <TAB> chunk = [text_encoder.RESERVED_TOKENS[idx]] <TAB>  <TAB> bases.extend(chunk) <TAB> return """".join(bases)",if strip_extraneous :,144
def pop(self): <TAB> regions = self.get() <TAB> # find a non-None mark in the ring <TAB> start = self.index <TAB> while True: <TAB>  <TAB> self.index -= 1 <TAB>  <TAB> if self.index < 0: <TAB>  <TAB>  <TAB> self.index = self.MARK_RING_SIZE - 1 <MASK> break <TAB> self.display() <TAB> return regions,if self . get ( ) or self . index == start :,104
"def determine_normalization_scheme(self): <TAB> schemes = OrderedDict() <TAB> modalities = self.dataset_properties[""modalities""] <TAB> num_modalities = len(list(modalities.keys())) <TAB> for i in range(num_modalities): <MASK> schemes[i] = ""CT"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> schemes[i] = ""nonCT"" <TAB> return schemes","if modalities [ i ] == ""CT"" or modalities [ i ] == ""ct"" :",116
"def apply(self, db, person): <TAB> if not self.list[0]: <TAB>  <TAB> return False <TAB> for f_id in person.get_family_handle_list(): <TAB>  <TAB> f = db.get_family_from_handle(f_id) <TAB>  <TAB> if not f: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for attr in f.get_attribute_list(): <MASK> name_match = self.list[0] == attr.get_type() <TAB>  <TAB>  <TAB>  <TAB> value_match = self.match_substring(1, attr.get_value()) <TAB>  <TAB>  <TAB>  <TAB> if name_match and value_match: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if attr :,166
"def simplify(n): <TAB> """"""Remove joins to empty BGPs"""""" <TAB> if isinstance(n, CompValue): <MASK> if n.p1.name == ""BGP"" and len(n.p1.triples) == 0: <TAB>  <TAB>  <TAB>  <TAB> return n.p2 <TAB>  <TAB>  <TAB> if n.p2.name == ""BGP"" and len(n.p2.triples) == 0: <TAB>  <TAB>  <TAB>  <TAB> return n.p1 <TAB>  <TAB> elif n.name == ""BGP"": <TAB>  <TAB>  <TAB> n[""triples""] = reorderTriples(n.triples) <TAB>  <TAB>  <TAB> return n","if n . name == ""Join"" :",151
"def validate_input(self, page, errors): <TAB> if page is LIST_PAGE: <TAB>  <TAB> return True <TAB> elif page is CONFIRM_PAGE: <TAB>  <TAB> network = self.get_selected_network() <MASK> self.__deleted_network_name = network.get_name() <TAB>  <TAB>  <TAB> network.delete() <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> errors.append(""You must confirm undefining %s."" % network.get_name()) <TAB> elif page is REMOVE_PAGE: <TAB>  <TAB> return True <TAB> return False",if self . __confirm_remove . value ( ) :,141
"def merge_ssl_with_cnf(self, ssl, cnf): <TAB> """"""Merge SSL configuration dict with cnf dict"""""" <TAB> merged = {} <TAB> merged.update(ssl) <TAB> prefix = ""ssl-"" <TAB> for k, v in cnf.items(): <TAB>  <TAB> # skip unrelated options <TAB>  <TAB> if not k.startswith(prefix): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if v is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # special case because PyMySQL argument is significantly different <TAB>  <TAB> # from commandline <MASK> merged[""check_hostname""] = v <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # use argument name just strip ""ssl-"" prefix <TAB>  <TAB>  <TAB> arg = k[len(prefix) :] <TAB>  <TAB>  <TAB> merged[arg] = v <TAB> return merged","if k == ""ssl-verify-server-cert"" :",185
"def parse_verbatim_block(self): <TAB> add, output = text_accumulator() <TAB> self.block_start_line_number = self.line_number <TAB> while self.input: <TAB>  <TAB> line = self._line() <TAB>  <TAB> dsl_name = self.is_start_line(line) <MASK> self.dsl_name = dsl_name <TAB>  <TAB>  <TAB> break <TAB>  <TAB> add(line) <TAB> return Block(output())",if dsl_name :,115
"def parseAdditions(text): <TAB> items = [] <TAB> sMkt = Market.getInstance() <TAB> pattern = ""^(?P<typeName>{}+?)( x(?P<amount>\d+?))?$"".format(NAME_CHARS) <TAB> for line in _lineIter(text): <TAB>  <TAB> m = re.match(pattern, line) <TAB>  <TAB> if not m: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> item = sMkt.getItem(m.group(""typeName"")) <MASK> continue <TAB>  <TAB> amount = m.group(""amount"") <TAB>  <TAB> amount = 1 if amount is None else int(amount) <TAB>  <TAB> items.append((item, amount)) <TAB> return items",if item is None :,165
"def _migrate_schema(self, version, to_version) -> None: <TAB> logger.info(""Migrating database schema from version %r to %r"", version, to_version) <TAB> try: <MASK> raise MigrationError(""Invalid schema directory"") <TAB>  <TAB> migrate_schema(self, version, to_version, migrate_dir=self.schemas_dir) <TAB> except MigrationError as exc: <TAB>  <TAB> logger.warning(""Cannot migrate database schema: %s"", exc) <TAB>  <TAB> self._drop_tables() <TAB>  <TAB> self._create_tables()",if not self . schemas_dir :,139
"def handle_read(self, c): <TAB> if c == curses.KEY_LEFT: <TAB>  <TAB> self.active_index = max(0, self.active_index - 1) <MASK> self.selected_index = self.active_index <TAB> elif c == curses.KEY_RIGHT: <TAB>  <TAB> self.active_index = min(len(self.opts) - 1, self.active_index + 1) <TAB>  <TAB> if not self.require_select_action: <TAB>  <TAB>  <TAB> self.selected_index = self.active_index <TAB> elif c == ord("" ""): <TAB>  <TAB> if self.require_select_action: <TAB>  <TAB>  <TAB> self.selected_index = self.active_index <TAB> else: <TAB>  <TAB> return util.ReadState.IGNORED <TAB> return util.ReadState.READ",if not self . require_select_action :,197
"def __str__(self): <TAB> out_str = """" <TAB> for key, value in list(self.cache.items()): <MASK> out_str += "" %s => %s<br>\n"" % (key, value) <TAB>  <TAB> elif isinstance(value, dict) or isinstance(value, list): <TAB>  <TAB>  <TAB> out_str += "" %s => %s<br>\n"" % (key, json.dumps(value)) <TAB> return out_str","if isinstance ( value , str ) :",116
"def getsockopt(self, option): <TAB> result = _Socket_getsockopt(self, option) <TAB> if option == EVENTS: <TAB>  <TAB> # Getting the events causes the zmq socket to process <TAB>  <TAB> # events which may mean a msg can be sent or received. If <TAB>  <TAB> # there is a greenthread blocked and waiting for events, <TAB>  <TAB> # it will miss the edge-triggered read event, so wake it <TAB>  <TAB> # up. <TAB>  <TAB> if result & POLLOUT: <TAB>  <TAB>  <TAB> self._eventlet_send_event.wake() <MASK> self._eventlet_recv_event.wake() <TAB> return result",if result & POLLIN :,161
"def throttle_period_expired(timestamp, throttle): <TAB> if not timestamp: <TAB>  <TAB> return True <TAB> elif isinstance(timestamp, datetime): <MASK> return (timezone.now() - timestamp).total_seconds() > throttle <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB>  <TAB> timezone.now() - timestamp.replace(tzinfo=pytz.utc) <TAB>  <TAB>  <TAB> ).total_seconds() > throttle <TAB> else: <TAB>  <TAB> return (get_timestamp() - timestamp) > throttle",if timestamp . tzinfo :,119
"def _mark_file_dirty(self, dirty=True): <TAB> if self._data: <TAB>  <TAB> if dirty: <TAB>  <TAB>  <TAB> self._data.mark_data_dirty() <TAB>  <TAB>  <TAB> self._dirty = 1 <MASK> self._data.mark_data_pristine() <TAB>  <TAB>  <TAB> self._dirty = 0",elif self . _dirty == 1 :,85
def get_option_matrix(self): <TAB> option_matrix = [] <TAB> for form_field_list in self.meta.itervalues(): <TAB>  <TAB> for form_field in form_field_list: <MASK> option_matrix.append(form_field.values) <TAB> return option_matrix,if form_field . input_type in self . OPTION_MATRIX_FORM_TYPES :,94
"def callback_summary(): <TAB> reactor.processes.write(service, Neighbor.summary_header) <TAB> for peer_name in reactor.peers.keys(): <TAB>  <TAB> peer = reactor.peers.get(peer_name, None) <MASK> continue <TAB>  <TAB> if limit and limit != str(peer.neighbor.peer_address): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for line in Neighbor.summary(peer.cli_data()).split(""\n""): <TAB>  <TAB>  <TAB> reactor.processes.write(service, line) <TAB>  <TAB>  <TAB> yield True <TAB> reactor.processes.answer_done(service)",if not peer :,148
"def delete_hotspot(slicename): <TAB> hotsliceFName = slicename + "".hotspot.png"" <TAB> for i, size in enumerate(sizes): <TAB>  <TAB> subdir = ""bitmaps/{}x{}"".format(size, size) <TAB>  <TAB> hotrelslice = ""{}/{}"".format(subdir, hotsliceFName) <MASK> os.unlink(hotrelslice) <TAB>  <TAB> for scale in scale_pairs: <TAB>  <TAB>  <TAB> subdir = ""bitmaps/{}x{}_{}"".format(size, size, scale[1]) <TAB>  <TAB>  <TAB> hotrelslice = ""{}/{}"".format(subdir, hotsliceFName) <TAB>  <TAB>  <TAB> if os.path.exists(hotrelslice): <TAB>  <TAB>  <TAB>  <TAB> os.unlink(hotrelslice)",if os . path . exists ( hotrelslice ) :,176
"def mount(file_path, fs_type=""""): <TAB> mount_dir = TemporaryDirectory() <TAB> try: <TAB>  <TAB> mount_rv = execute_shell_command( <TAB>  <TAB>  <TAB> ""sudo mount {} -v -o ro,loop {} {}"".format( <TAB>  <TAB>  <TAB>  <TAB> fs_type, file_path, mount_dir.name <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <MASK> yield Path(mount_dir.name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logging.error(""could not mount {}: {}"".format(file_path, mount_rv)) <TAB>  <TAB>  <TAB> raise MountingError(""error while mounting fs"") <TAB> finally: <TAB>  <TAB> execute_shell_command(""sudo umount -v {}"".format(mount_dir.name)) <TAB>  <TAB> mount_dir.cleanup()",if _mount_was_successful ( mount_dir . name ) :,195
"def get_first_directory_in_directory(content, dirname): <TAB> """"""Return the first directory in dirname or None."""""" <TAB> directory = None <TAB> for path in content: <TAB>  <TAB> if path.full_path.startswith(dirname) and path.full_path != dirname: <MASK> directory = path.filename <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return directory",if path . is_directory :,94
"def post(self, text, media=None): <TAB> if not media: <TAB>  <TAB> return self.post_text(text) <TAB> else: <TAB>  <TAB> media_id = self.upload_image(media) <MASK> return self.post_text(text, media_id=media_id) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> frappe.log_error(""Failed to upload media."", ""LinkedIn Upload Error"")",if media_id :,107
"def _get_video_streams(self): <TAB> try: <TAB>  <TAB> if self.video_type == ""b"": <TAB>  <TAB>  <TAB> res = self.api.video_broadcast(self.video_id, schema=_video_schema) <TAB>  <TAB> elif self.video_type == ""c"": <TAB>  <TAB>  <TAB> res = self.api.video_clip(self.video_id, schema=_video_schema) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return <TAB> except PluginError as err: <MASK> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise <TAB> video = convert_jtv_to_twitch_video(res) <TAB> return self._create_playlist_streams(video)","if ""404 Client Error"" in str ( err ) :",171
"def startService(self): <TAB> WorkerBase.startService(self) <TAB> if self.allow_shutdown == ""signal"": <TAB>  <TAB> log.msg(""Setting up SIGHUP handler to initiate shutdown"") <TAB>  <TAB> signal.signal(signal.SIGHUP, self._handleSIGHUP) <TAB> elif self.allow_shutdown == ""file"": <TAB>  <TAB> log.msg(""Watching {0}'s mtime to initiate shutdown"".format(self.shutdown_file)) <MASK> self.shutdown_mtime = os.path.getmtime(self.shutdown_file) <TAB>  <TAB> self.shutdown_loop = loop = task.LoopingCall(self._checkShutdownFile) <TAB>  <TAB> loop.start(interval=10)",if os . path . exists ( self . shutdown_file ) :,176
"def run_timed(self, timeout): <TAB> if self.unique: <TAB>  <TAB> with TIMED_THREAD_LOCK: <TAB>  <TAB>  <TAB> old_thread = TIMED_THREADS.get(self.unique) <MASK> raise TimedOut(""Old thread still alive: %s"" % self.name) <TAB>  <TAB>  <TAB> TIMED_THREADS[self.unique] = self <TAB> self.start() <TAB> self.join(timeout=timeout) <TAB> if self.isAlive() or QUITTING: <TAB>  <TAB> raise TimedOut(""Timed out: %s"" % self.name) <TAB> else: <TAB>  <TAB> if self.unique: <TAB>  <TAB>  <TAB> with TIMED_THREAD_LOCK: <TAB>  <TAB>  <TAB>  <TAB> TIMED_THREADS[self.unique] = None",if ( old_thread is not None ) and old_thread . isAlive ( ) :,193
"def concat_arrow_table_partitions(axis, partitions): <TAB> if axis == 0: <TAB>  <TAB> table = pyarrow.Table.from_batches( <TAB>  <TAB>  <TAB> [part.to_batches(part.num_rows)[0] for part in partitions] <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> table = partitions[0].drop([partitions[0].columns[-1].name]) <TAB>  <TAB> for obj in partitions[1:]: <TAB>  <TAB>  <TAB> i = 0 <TAB>  <TAB>  <TAB> for col in obj.itercolumns(): <MASK> table = table.append_column(col) <TAB>  <TAB>  <TAB>  <TAB> i += 1 <TAB>  <TAB> table = table.append_column(partitions[0].columns[-1]) <TAB> return table",if i < obj . num_columns - 1 :,179
"def default(self, o): <TAB> if has_numpy: <TAB>  <TAB> if isinstance(o, np.integer): <TAB>  <TAB>  <TAB> return int(o) <MASK> return float(o) <TAB>  <TAB> elif isinstance(o, np.ndarray): <TAB>  <TAB>  <TAB> return o.tolist() <TAB> if _is_torch_tensor(o): <TAB>  <TAB> return o.detach().tolist() <TAB> if _is_tensorflow_tensor(o): <TAB>  <TAB> return o.numpy().tolist() <TAB> return json.JSONEncoder.default(self, o)","elif isinstance ( o , np . floating ) :",135
"def mock_stripe_Charge_create(error_msg=None): <TAB> json_body = {""error"": {""charge"": ""charge_id""}} <TAB> with patch(""stripe.Charge.create"") as mocked_charge_create: <MASK> mocked_charge_create.side_effect = stripe.error.CardError( <TAB>  <TAB>  <TAB>  <TAB> error_msg, param=None, code=None, json_body=json_body <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> mocked_charge_create.side_effect = lambda **kwargs: {} <TAB>  <TAB> yield mocked_charge_create",if error_msg :,144
"def _prune(self, value_map): <TAB> if self._op == self.AND: <TAB>  <TAB> matches = collections.defaultdict(set) <TAB>  <TAB> for f in self._filters: <TAB>  <TAB>  <TAB> props = f._get_prop_names() <TAB>  <TAB>  <TAB> local_value_map = dict( <TAB>  <TAB>  <TAB>  <TAB> (k, v) for k, v in value_map.iteritems() if k in props <TAB>  <TAB>  <TAB> ) <MASK> return False <TAB>  <TAB>  <TAB> for (prop, values) in local_value_map.iteritems(): <TAB>  <TAB>  <TAB>  <TAB> matches[prop].update(values) <TAB>  <TAB> for prop, value_set in matches.iteritems(): <TAB>  <TAB>  <TAB> value_map[prop] = sorted(value_set) <TAB>  <TAB> return True <TAB> raise NotImplementedError",if not f . _prune ( local_value_map ) :,194
"def gray2int(g, size): <TAB> """"""Transforms a Gray code back into an integer."""""" <TAB> res = 0 <TAB> for i in reversed(list(range(size))): <TAB>  <TAB> gi = (g >> i) % 2 <MASK> bi = gi <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> bi = bi ^ gi <TAB>  <TAB> res += bi * 2 ** i <TAB> return res",if i == size - 1 :,99
"def process_event(self, event): <TAB> if event.type == KEYDOWN: <MASK> self.move_up = True <TAB>  <TAB> if event.key == self.control_scheme.down: <TAB>  <TAB>  <TAB> self.move_down = True <TAB> if event.type == KEYUP: <TAB>  <TAB> if event.key == self.control_scheme.up: <TAB>  <TAB>  <TAB> self.move_up = False <TAB>  <TAB> if event.key == self.control_scheme.down: <TAB>  <TAB>  <TAB> self.move_down = False",if event . key == self . control_scheme . up :,138
"def upload_task_files(self, task_id, subdir): <TAB> path = os.path.join(self.job.resultdir, subdir) <TAB> for root, _, files in os.walk(path): <TAB>  <TAB> for name in files: <TAB>  <TAB>  <TAB> # strip full path <TAB>  <TAB>  <TAB> remotepath = re.sub(path, """", root) <TAB>  <TAB>  <TAB> # The localfile has the full path <TAB>  <TAB>  <TAB> localfile = os.path.join(root, name) <MASK> continue  # skip empty files <TAB>  <TAB>  <TAB> # Upload the file <TAB>  <TAB>  <TAB> self.bkr_proxy.task_upload_file(task_id, localfile, remotepath)",if os . path . getsize ( localfile ) == 0 :,171
"def __getattr__(self, name): <TAB> if ""json"" in self.__dict__ and name in self.json: <TAB>  <TAB> value = self.json[name] <TAB>  <TAB> if not isinstance(value, TentativePage) and is_relative_endpoint(value): <TAB>  <TAB>  <TAB> value = TentativePage(value, self.connection) <MASK> for key, item in value.items(): <TAB>  <TAB>  <TAB>  <TAB> if not isinstance(item, TentativePage) and is_relative_endpoint(item): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value[key] = TentativePage(item, self.connection) <TAB>  <TAB> return value <TAB> raise AttributeError( <TAB>  <TAB> ""{!r} object has no attribute {!r}"".format(self.__class__.__name__, name) <TAB> )","elif isinstance ( value , dict ) :",185
"def __mul__(self, other): <TAB> if isinstance(other, Symbol): <MASK> return self <TAB>  <TAB> if self.symbol == ""1"": <TAB>  <TAB>  <TAB> return other <TAB>  <TAB> return Symbol(""(%s * %s)"" % (self.symbol, other.symbol)) <TAB> if is_number(other): <TAB>  <TAB> if other == 1: <TAB>  <TAB>  <TAB> return self <TAB>  <TAB> if self.symbol == ""1"": <TAB>  <TAB>  <TAB> return Symbol(""%g"" % other) <TAB>  <TAB> return Symbol(""(%s * %g)"" % (self.symbol, other)) <TAB> return NotImplemented","if other . symbol == ""1"" :",142
"def get_string(token): <TAB> """"""Parse a <string> token."""""" <TAB> if token.type == ""string"": <TAB>  <TAB> return (""string"", token.value) <TAB> if token.type == ""function"": <TAB>  <TAB> if token.name == ""attr"": <TAB>  <TAB>  <TAB> return check_attr_function(token, ""string"") <TAB>  <TAB> elif token.name in (""counter"", ""counters""): <TAB>  <TAB>  <TAB> return check_counter_function(token) <TAB>  <TAB> elif token.name == ""content"": <TAB>  <TAB>  <TAB> return check_content_function(token) <MASK> return check_string_or_element_function(""string"", token)","elif token . name == ""string"" :",157
"def test_getitem_nonzero_returns_correct_field(self): <TAB> for init_case, params in itertools.product(self.INIT_CASES, self.PARAMS): <TAB>  <TAB> init_case = self.initialize_case(init_case, params) <TAB>  <TAB> mf = TextMultiField(**init_case) <TAB>  <TAB> fnames = [name for name, _ in init_case[""feats_fields""]] <MASK> ordered_names = list(sorted(fnames)) <TAB>  <TAB>  <TAB> name2field = dict(init_case[""feats_fields""]) <TAB>  <TAB>  <TAB> for i, name in enumerate(ordered_names, 1): <TAB>  <TAB>  <TAB>  <TAB> expected_field = name2field[name] <TAB>  <TAB>  <TAB>  <TAB> self.assertIs(mf[i][1], expected_field)",if len ( fnames ) > 0 :,186
"def build_context(node, fields, whitelisted_fields): <TAB> for safe_field in whitelisted_fields: <TAB>  <TAB> if type(safe_field) is dict: <TAB>  <TAB>  <TAB> field, whitelist_subnode = safe_field.copy().popitem() <TAB>  <TAB>  <TAB> # ensure content present in job serialization <TAB>  <TAB>  <TAB> if field not in fields: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> subnode = fields[field] <TAB>  <TAB>  <TAB> node[field] = {} <TAB>  <TAB>  <TAB> build_context(node[field], subnode, whitelist_subnode) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # ensure content present in job serialization <MASK> continue <TAB>  <TAB>  <TAB> node[safe_field] = fields[safe_field]",if safe_field not in fields :,172
"def has_prefix_cce(yaml_file, product_yaml=None): <TAB> rule = yaml.open_and_macro_expand(yaml_file, product_yaml) <TAB> if ""identifiers"" in rule and rule[""identifiers""] is not None: <TAB>  <TAB> for i_type, i_value in rule[""identifiers""].items(): <MASK> has_prefix = i_value[0:3].upper() == ""CCE"" <TAB>  <TAB>  <TAB>  <TAB> remainder_valid = checks.is_cce_format_valid(""CCE-"" + i_value[3:]) <TAB>  <TAB>  <TAB>  <TAB> remainder_valid |= checks.is_cce_format_valid(""CCE-"" + i_value[4:]) <TAB>  <TAB>  <TAB>  <TAB> return has_prefix and remainder_valid <TAB> return False","if i_type [ 0 : 3 ] == ""cce"" :",195
"def parse_sequence(self): <TAB> self.get_token(yaml.FlowSequenceStartToken) <MASK> self.parse_node() <TAB>  <TAB> while not self.check_token(yaml.FlowSequenceEndToken): <TAB>  <TAB>  <TAB> self.get_token(yaml.FlowEntryToken) <TAB>  <TAB>  <TAB> if not self.check_token(yaml.FlowSequenceEndToken): <TAB>  <TAB>  <TAB>  <TAB> self.parse_node() <TAB> self.get_token(yaml.FlowSequenceEndToken) <TAB> self.events.append(yaml.SequenceEndEvent(None, None))",if not self . check_token ( yaml . FlowSequenceEndToken ) :,146
"def _fill_mappings(): <TAB> for entry in _ISO_639: <TAB>  <TAB> name, _1, _2B, _2T = entry <TAB>  <TAB> _LOWER[name.lower()] = name <TAB>  <TAB> if _1: <TAB>  <TAB>  <TAB> _ISO_639_1[_1] = entry <TAB>  <TAB> _ISO_639_2[_2B] = entry <MASK> _ISO_639_2[_2T] = entry",if _2T :,107
"def _raw_nonprimary_surname(raw_surn_data_list): <TAB> """"""method for the 'r' symbol: nonprimary surnames"""""" <TAB> result = """" <TAB> for raw_surn_data in raw_surn_data_list: <MASK> result = ""%s %s %s %s"" % ( <TAB>  <TAB>  <TAB>  <TAB> result, <TAB>  <TAB>  <TAB>  <TAB> raw_surn_data[_PREFIX_IN_LIST], <TAB>  <TAB>  <TAB>  <TAB> raw_surn_data[_SURNAME_IN_LIST], <TAB>  <TAB>  <TAB>  <TAB> raw_surn_data[_CONNECTOR_IN_LIST], <TAB>  <TAB>  <TAB> ) <TAB> return "" "".join(result.split())",if not raw_surn_data [ _PRIMARY_IN_LIST ] :,174
"def findinDoc(self, tagpath, pos, end): <TAB> result = None <TAB> docList = self.flatdoc <TAB> cnt = len(docList) <TAB> if end == -1: <TAB>  <TAB> end = cnt <TAB> else: <TAB>  <TAB> end = min(cnt, end) <TAB> foundat = -1 <TAB> for j in range(pos, end): <TAB>  <TAB> item = docList[j] <TAB>  <TAB> if item.find(b""="") >= 0: <TAB>  <TAB>  <TAB> (name, argres) = item.split(b""="", 1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = item <TAB>  <TAB>  <TAB> argres = b"""" <TAB>  <TAB> if isinstance(tagpath, str): <TAB>  <TAB>  <TAB> tagpath = tagpath.encode(""utf-8"") <MASK> result = argres <TAB>  <TAB>  <TAB> foundat = j <TAB>  <TAB>  <TAB> break <TAB> return foundat, result",if name . endswith ( tagpath ) :,199
"def combine_hla_fqs(hlas, out_file, data): <TAB> """"""OptiType performs best on a combination of all extracted HLAs."""""" <TAB> if not utils.file_exists(out_file): <TAB>  <TAB> with file_transaction(data, out_file) as tx_out_file: <TAB>  <TAB>  <TAB> with open(tx_out_file, ""w"") as out_handle: <TAB>  <TAB>  <TAB>  <TAB> for hla_type, hla_fq in hlas: <MASK> with open(hla_fq) as in_handle: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> shutil.copyfileobj(in_handle, out_handle) <TAB> return out_file",if utils . file_exists ( hla_fq ) :,181
"def test___iter__(self): <TAB> cba = ia.BoundingBox(x1=1, y1=2, x2=3, y2=4) <TAB> for i, xy in enumerate(cba): <TAB>  <TAB> assert i in [0, 1] <TAB>  <TAB> if i == 0: <TAB>  <TAB>  <TAB> assert np.allclose(xy, (1, 2)) <MASK> assert np.allclose(xy, (3, 4)) <TAB> assert i == 1",elif i == 1 :,112
"def fixup(name): <TAB> try: <TAB>  <TAB> return memo[name] <TAB> except KeyError: <TAB>  <TAB> if name[0] != ""{"": <TAB>  <TAB>  <TAB> return <TAB>  <TAB> uri, tag = name[1:].split(""}"") <MASK> new_name = uri_map[uri] + "":"" + tag <TAB>  <TAB>  <TAB> memo[name] = new_name <TAB>  <TAB>  <TAB> return new_name",if uri in uri_map :,99
"def __get_hook_attrs__(self, obj): <TAB> for name in dir(obj): <TAB>  <TAB> val = getattr(obj, name, None) <TAB>  <TAB> if val is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> func_attrs = getattr(val, ""__apihook__"", None) <TAB>  <TAB> data_attrs = getattr(val, ""__datahook__"", None) <MASK> name, func, argc, conv, ordinal = func_attrs <TAB>  <TAB>  <TAB> obj.funcs[name] = (name, func, argc, conv, ordinal) <TAB>  <TAB>  <TAB> if ordinal: <TAB>  <TAB>  <TAB>  <TAB> obj.funcs[ordinal] = (name, func, argc, conv, ordinal) <TAB>  <TAB> elif data_attrs: <TAB>  <TAB>  <TAB> name, func = data_attrs <TAB>  <TAB>  <TAB> obj.data[name] = func",if func_attrs :,190
"def evaluate(env, net): <TAB> obs = env.reset() <TAB> reward = 0.0 <TAB> steps = 0 <TAB> while True: <TAB>  <TAB> obs_v = torch.FloatTensor([obs]) <TAB>  <TAB> act_prob = net(obs_v) <TAB>  <TAB> acts = act_prob.max(dim=1)[1] <TAB>  <TAB> obs, r, done, _ = env.step(acts.data.numpy()[0]) <TAB>  <TAB> reward += r <TAB>  <TAB> steps += 1 <MASK> break <TAB> return reward, steps",if done :,128
"def rest_put(url, data, timeout, show_error=False): <TAB> """"""Call rest put method"""""" <TAB> try: <TAB>  <TAB> response = requests.put( <TAB>  <TAB>  <TAB> url, <TAB>  <TAB>  <TAB> headers={""Accept"": ""application/json"", ""Content-Type"": ""application/json""}, <TAB>  <TAB>  <TAB> data=data, <TAB>  <TAB>  <TAB> timeout=timeout, <TAB>  <TAB> ) <TAB>  <TAB> return response <TAB> except Exception as exception: <MASK> print_error(exception) <TAB>  <TAB> return None",if show_error :,123
"def parse_arg(arg): <TAB> if isinstance(arg, dict): <TAB>  <TAB> return arg <TAB> result = {} <TAB> tokens = arg.split("","") <TAB> for token in tokens: <MASK> parts = token.split(""="", 1) <TAB>  <TAB>  <TAB> result[parts[0].strip()] = parts[1].strip() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result[token.strip()] = True <TAB> return result","if ""="" in token :",102
"def ssh_to_node(node_id, cfg, user=""root""): <TAB> ec2 = cfg.get_easy_ec2() <TAB> instances = ec2.get_all_instances() <TAB> node = None <TAB> for instance in instances: <MASK> node = instance <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif instance.id == node_id: <TAB>  <TAB>  <TAB> node = instance <TAB>  <TAB>  <TAB> break <TAB> if node: <TAB>  <TAB> key = cfg.get_key(node.key_name) <TAB>  <TAB> os.system(""ssh -i %s %s@%s"" % (key.key_location, user, node.dns_name)) <TAB> else: <TAB>  <TAB> log.error(""node %s does not exist"" % node_id)",if instance . dns_name == node_id :,185
"def add_to_powerline(self): <TAB> powerline = self.powerline <TAB> try: <TAB>  <TAB> p1 = subprocess.Popen([""rbenv"", ""local""], stdout=subprocess.PIPE) <TAB>  <TAB> version = p1.communicate()[0].decode(""utf-8"").rstrip() <MASK> return <TAB>  <TAB> powerline.append( <TAB>  <TAB>  <TAB> "" %s "" % version, <TAB>  <TAB>  <TAB> powerline.theme.VIRTUAL_ENV_FG, <TAB>  <TAB>  <TAB> powerline.theme.VIRTUAL_ENV_BG, <TAB>  <TAB> ) <TAB> except OSError: <TAB>  <TAB> return",if len ( version ) <= 0 :,144
"def _massage_node(node, attr): <TAB> """"""The real work for remove_rel is done here, parametrized with @rel and @rev"""""" <TAB> if node.hasAttribute(""property"") and node.hasAttribute(attr): <TAB>  <TAB> vals = node.getAttribute(attr).strip().split() <MASK> final_vals = [v for v in vals if not termname.match(v)] <TAB>  <TAB>  <TAB> if len(final_vals) == 0: <TAB>  <TAB>  <TAB>  <TAB> node.removeAttribute(attr) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> node.setAttribute(attr, reduce(lambda x, y: x + "" "" + y, final_vals))",if len ( vals ) != 0 :,165
def acl(self): <MASK> self.lazy_init_lock_.acquire() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if self.acl_ is None: <TAB>  <TAB>  <TAB>  <TAB> self.acl_ = TaskQueueAcl() <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self.lazy_init_lock_.release() <TAB> return self.acl_,if self . acl_ is None :,88
"def test_localmax(ndim, axis): <TAB> srand() <TAB> data = np.random.randn(*([7] * ndim)) <TAB> lm = librosa.util.localmax(data, axis=axis) <TAB> for hits in np.argwhere(lm): <TAB>  <TAB> for offset in [-1, 1]: <TAB>  <TAB>  <TAB> compare_idx = hits.copy() <TAB>  <TAB>  <TAB> compare_idx[axis] += offset <MASK> continue <TAB>  <TAB>  <TAB> if compare_idx[axis] >= data.shape[axis]: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if offset < 0: <TAB>  <TAB>  <TAB>  <TAB> assert data[tuple(hits)] > data[tuple(compare_idx)] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> assert data[tuple(hits)] >= data[tuple(compare_idx)]",if compare_idx [ axis ] < 0 :,195
"def recursiveChildGenerator(self): <TAB> stack = [(self, 0)] <TAB> while stack: <TAB>  <TAB> tag, start = stack.pop() <MASK> for i in range(start, len(tag.contents)): <TAB>  <TAB>  <TAB>  <TAB> a = tag.contents[i] <TAB>  <TAB>  <TAB>  <TAB> yield a <TAB>  <TAB>  <TAB>  <TAB> if isinstance(a, Tag) and tag.contents: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if i < len(tag.contents) - 1: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> stack.append((tag, i + 1)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> stack.append((a, 0)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB> raise StopIteration","if isinstance ( tag , Tag ) :",157
"def delete_tag(object_type, tag, object_id, obj_date=None): <TAB> # tag exist <TAB> if is_obj_tagged(object_id, tag): <MASK> obj_date = get_obj_date(object_type, object_id) <TAB>  <TAB> delete_obj_tag(object_type, object_id, tag, obj_date) <TAB>  <TAB> update_tag_metadata(tag, obj_date, object_type=object_type, add_tag=False) <TAB>  <TAB> update_tag_global_by_obj_type(object_type, tag) <TAB> else: <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB> {""status"": ""error"", ""reason"": ""object id or tag not found"", ""value"": tag}, <TAB>  <TAB>  <TAB> 400, <TAB>  <TAB> )",if not obj_date :,191
"def __getitem__(self, key): <TAB> val = self.file_content[key] <TAB> if isinstance(val, h5py.Dataset): <TAB>  <TAB> # these datasets are closed and inaccessible when the file is closed, need to reopen <TAB>  <TAB> dset = h5py.File(self.filename, ""r"")[key] <TAB>  <TAB> dset = da.from_array(dset, chunks=CHUNK_SIZE) <MASK> return xr.DataArray(dset, dims=[""y"", ""x""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return xr.DataArray(dset) <TAB> return val",if dset . ndim > 1 :,144
"def ask_timezone(question, default, tzurl): <TAB> """"""Prompt for time zone and validate input"""""" <TAB> lower_tz = [tz.lower() for tz in pytz.all_timezones] <TAB> while True: <TAB>  <TAB> r = ask(question, str, default) <TAB>  <TAB> r = r.strip().replace("" "", ""_"").lower() <MASK> r = pytz.all_timezones[lower_tz.index(r)] <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""Please enter a valid time zone:\n"" "" (check [{}])"".format(tzurl)) <TAB> return r",if r in lower_tz :,146
"def _get_next_token(self, parsed): <TAB> if self._more_results is not None: <TAB>  <TAB> if not self._more_results.search(parsed): <TAB>  <TAB>  <TAB> return {} <TAB> next_tokens = {} <TAB> for output_token, input_key in zip(self._output_token, self._input_token): <TAB>  <TAB> next_token = output_token.search(parsed) <TAB>  <TAB> # We do not want to include any empty strings as actual tokens. <TAB>  <TAB> # Treat them as None. <MASK> next_tokens[input_key] = next_token <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> next_tokens[input_key] = None <TAB> return next_tokens",if next_token :,168
"def getRawKeyByMeasure(self): <TAB> keyByMeasure = [] <TAB> for i in range(self.numMeasures): <TAB>  <TAB> m = self.stream.measure(i) <MASK> k = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> k = m.analyze(""key"") <TAB>  <TAB> keyByMeasure.append(k) <TAB> self.rawKeyByMeasure = keyByMeasure <TAB> return keyByMeasure",if m is None or not m . recurse ( ) . notes :,116
"def endElement(self, name, value, connection): <TAB> if len(self.stack) > 0: <TAB>  <TAB> self.stack.pop() <TAB> value = value.strip() <TAB> if value: <MASK> self.parent[self.get_name(name)] = value <TAB>  <TAB> elif isinstance(self.parent, ListElement): <TAB>  <TAB>  <TAB> self.parent.append(value)","if isinstance ( self . parent , Element ) :",102
def is_dir(self): <TAB> # type: () -> bool <TAB> if self._is_dir is None: <MASK> ret_val = False <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> ret_val = self.path.is_dir() <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> ret_val = False <TAB>  <TAB> self._is_dir = ret_val <TAB> return self._is_dir,if not self . path :,101
"def base64_output(payload): <TAB> if not settings.TAMPER_SCRIPTS[""base64encode""]: <MASK> menu.options.tamper = menu.options.tamper + "",base64encode"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> menu.options.tamper = ""base64encode""",if menu . options . tamper :,85
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> length = d.getVarInt32() <TAB>  <TAB>  <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB>  <TAB>  <TAB> d.skip(length) <TAB>  <TAB>  <TAB> self.mutable_image().TryMerge(tmp) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 10 :,137
"def get_column_name(field): <TAB> opts = meta <TAB> parts = field.split(""."") <TAB> for i, part in enumerate(parts): <TAB>  <TAB> field = opts.get_field(part) <TAB>  <TAB> parts[i] = field.column <TAB>  <TAB> if isinstance(field, AbstractIterableField): <TAB>  <TAB>  <TAB> field = field.item_field <MASK> opts = field.embedded_model._meta <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> return ""."".join(parts)","if isinstance ( field , EmbeddedModelField ) :",125
"def update_email(self, form, confirm=None): <TAB> user = self.request.user <TAB> if confirm is None: <TAB>  <TAB> confirm = settings.ACCOUNT_EMAIL_CONFIRMATION_EMAIL <TAB> # @@@ handle multiple emails per user <TAB> email = form.cleaned_data[""email""].strip() <TAB> if not self.primary_email_address: <TAB>  <TAB> user.email = email <TAB>  <TAB> EmailAddress.objects.add_email( <TAB>  <TAB>  <TAB> self.request.user, email, primary=True, confirm=confirm <TAB>  <TAB> ) <TAB>  <TAB> user.save() <TAB> else: <MASK> self.primary_email_address.change(email, confirm=confirm)",if email != self . primary_email_address . email :,171
"def getFilesFromListOfPath(paths): <TAB> result = [] <TAB> for p in paths: <MASK> result.append(p) <TAB>  <TAB> elif os.path.isdir(p): <TAB>  <TAB>  <TAB> subfiles = os.listdir(p) <TAB>  <TAB>  <TAB> toAnalyze = [] <TAB>  <TAB>  <TAB> for s in subfiles: <TAB>  <TAB>  <TAB>  <TAB> toAnalyze.append(os.path.join(p, s)) <TAB>  <TAB>  <TAB> subfilesResult = getFilesFromListOfPath(toAnalyze) <TAB>  <TAB>  <TAB> result.extend(subfilesResult) <TAB> return result",if os . path . isfile ( p ) :,140
"def load(self, directory=None): <TAB> try: <TAB>  <TAB> from PIL import Image <MASK> self.load_data() <TAB>  <TAB> elif self.url is not None: <TAB>  <TAB>  <TAB> self.load_file(directory) <TAB>  <TAB> self.set_values_by_image() <TAB> except ImportError: <TAB>  <TAB> pass",if self . data is not None :,87
"def add_property(self, key, value):  # type: (str, Any) -> None <TAB> keys = key.split(""."") <TAB> config = self._config <TAB> for i, key in enumerate(keys): <MASK> config[key] = {} <TAB>  <TAB> if i == len(keys) - 1: <TAB>  <TAB>  <TAB> config[key] = value <TAB>  <TAB>  <TAB> break <TAB>  <TAB> config = config[key]",if key not in config and i < len ( keys ) - 1 :,114
"def _refresh_peer_list(self, peers): <TAB> for conn_id in peers: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self._network.get_connection_id_by_endpoint(peers[conn_id]) <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> LOGGER.debug( <TAB>  <TAB>  <TAB>  <TAB> ""removing peer %s because "" ""connection went away"", peers[conn_id] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self._gossip.unregister_peer(conn_id) <MASK> del self._connection_statuses[conn_id]",if conn_id in self . _connection_statuses :,147
"def downgrade(): <TAB> bind = op.get_bind() <TAB> session = db.Session(bind=bind) <TAB> for slc in session.query(Slice).all(): <TAB>  <TAB> if slc.datasource_type == ""druid"": <TAB>  <TAB>  <TAB> slc.druid_datasource_id = slc.datasource_id <MASK> slc.table_id = slc.datasource_id <TAB>  <TAB> session.merge(slc) <TAB>  <TAB> session.commit() <TAB> session.close() <TAB> op.drop_column(""slices"", ""datasource_id"")","if slc . datasource_type == ""table"" :",136
"def _DecayPartValuesToString(part_vals, join_char): <TAB> # Decay ${a=x""$@""x} to string. <TAB> out = [] <TAB> for p in part_vals: <MASK> out.append(p.s) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> last = len(p.strs) - 1 <TAB>  <TAB>  <TAB> for i, s in enumerate(p.strs): <TAB>  <TAB>  <TAB>  <TAB> out.append(s) <TAB>  <TAB>  <TAB>  <TAB> if i != last: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> out.append(join_char) <TAB> return """".join(out)",if p . tag == part_value_e . StringPartValue :,153
"def configure_limit_style(store): <TAB> for val in [""native"", ""emulated""]: <TAB>  <TAB> store.config[""limit_style""] = val <TAB>  <TAB> store._set_sql_flavour() <MASK> store.log.info(""limit_style=%s"", val) <TAB>  <TAB>  <TAB> return <TAB> raise Exception(""Can not emulate LIMIT."")",if store . _test_limit_style ( ) :,93
"def wrapped_function(*args, **kwargs): <TAB> tries = 0 <TAB> while tries < self.max_tries: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return to_wrap(*args, **kwargs) <TAB>  <TAB> except self.exception as caught_exception: <MASK> raise <TAB>  <TAB>  <TAB> delay = self.delay * self.backoff ** tries <TAB>  <TAB>  <TAB> msg = ""%s, Trying again in %d seconds..."" % (caught_exception, delay) <TAB>  <TAB>  <TAB> self.logger(msg) <TAB>  <TAB>  <TAB> time.sleep(delay) <TAB>  <TAB>  <TAB> tries += 1 <TAB> return to_wrap(*args, **kwargs)",if not self . error_predicate ( caught_exception ) :,158
"def random_dag(nodes, edges): <TAB> """"""Generate a random Directed Acyclic Graph (DAG) with a given number of nodes and edges."""""" <TAB> G = nx.DiGraph() <TAB> for i in range(nodes): <TAB>  <TAB> G.add_node(i) <TAB> while edges > 0: <TAB>  <TAB> a = randint(0, nodes - 1) <TAB>  <TAB> b = a <TAB>  <TAB> while b == a: <TAB>  <TAB>  <TAB> b = randint(0, nodes - 1) <TAB>  <TAB> G.add_edge(a, b) <MASK> edges -= 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # we closed a loop! <TAB>  <TAB>  <TAB> G.remove_edge(a, b) <TAB> return G",if nx . is_directed_acyclic_graph ( G ) :,179
"def _check(request, local_site_name=None, *args, **kwargs): <TAB> if local_site_name: <MASK> raise Http404 <TAB>  <TAB> local_site = request.local_site <TAB>  <TAB> if not local_site.is_mutable_by(request.user): <TAB>  <TAB>  <TAB> return render( <TAB>  <TAB>  <TAB>  <TAB> request=request, template_name=""permission_denied.html"", status=403 <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> local_site = None <TAB> return view_func( <TAB>  <TAB> request, local_site_name=local_site_name, local_site=local_site, *args, **kwargs <TAB> )",if not request . local_site :,165
"def batch_select_greedy_action(self, batch_obs, deterministic=False): <TAB> with chainer.using_config(""train"", False), chainer.no_backprop_mode(): <TAB>  <TAB> batch_xs = self.batch_states(batch_obs, self.xp, self.phi) <MASK> batch_action = self.policy(batch_xs).most_probable.array <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> batch_action = self.policy(batch_xs).sample().array <TAB> return list(cuda.to_cpu(batch_action))",if deterministic :,136
"def _find_data_type(bases): <TAB> for chain in bases: <TAB>  <TAB> for base in chain.__mro__: <MASK> continue <TAB>  <TAB>  <TAB> elif ""__new__"" in base.__dict__: <TAB>  <TAB>  <TAB>  <TAB> if issubclass(base, Enum): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB>  <TAB> return base",if base is object :,82
"def anchor(token): <TAB> """"""Validation for ``anchor``."""""" <TAB> if get_keyword(token) == ""none"": <TAB>  <TAB> return ""none"" <TAB> function = parse_function(token) <TAB> if function: <TAB>  <TAB> name, args = function <TAB>  <TAB> prototype = (name, [a.type for a in args]) <TAB>  <TAB> args = [getattr(a, ""value"", a) for a in args] <MASK> return (""attr()"", args[0])","if prototype == ( ""attr"" , [ ""ident"" ] ) :",119
"def _validate_options(self): <TAB> for option in self.options: <TAB>  <TAB> # if value type is bool or int, then we know the options is set <TAB>  <TAB> if not type(self.options[option]) in [bool, int]: <MASK> raise FrameworkException( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Value required for the '%s' option."" % (option.upper()) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return",if self . options . required [ option ] is True and not self . options [ option ] :,120
"def test_taxonomy_parents(self, subjects, data_subject_list): <TAB> for index, subject in enumerate(subjects): <TAB>  <TAB> if index >= len(data_subject_list): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> parents_ids = [] <TAB>  <TAB> for parent in data_subject_list[index][""attributes""][""parents""]: <TAB>  <TAB>  <TAB> parents_ids.append(parent[""id""]) <MASK> assert subject.parent._id in parents_ids",if subject . parent :,112
"def get_songs_for_ids(library, ids): <TAB> songs = [] <TAB> ids = set(ids) <TAB> for song in library: <TAB>  <TAB> song_id = get_song_id(song) <TAB>  <TAB> if song_id in ids: <TAB>  <TAB>  <TAB> songs.append(song) <TAB>  <TAB>  <TAB> ids.discard(song_id) <MASK> break <TAB> return songs",if not ids :,99
"def validate_date_with_fiscal_year(self): <TAB> if self.meta.get_field(""fiscal_year""): <TAB>  <TAB> date_field = """" <TAB>  <TAB> if self.meta.get_field(""posting_date""): <TAB>  <TAB>  <TAB> date_field = ""posting_date"" <TAB>  <TAB> elif self.meta.get_field(""transaction_date""): <TAB>  <TAB>  <TAB> date_field = ""transaction_date"" <MASK> validate_fiscal_year( <TAB>  <TAB>  <TAB>  <TAB> self.get(date_field), <TAB>  <TAB>  <TAB>  <TAB> self.fiscal_year, <TAB>  <TAB>  <TAB>  <TAB> self.company, <TAB>  <TAB>  <TAB>  <TAB> self.meta.get_label(date_field), <TAB>  <TAB>  <TAB>  <TAB> self, <TAB>  <TAB>  <TAB> )",if date_field and self . get ( date_field ) :,189
"def get_dict(self): <TAB> fields = [] <TAB> for field in self._meta.fields: <TAB>  <TAB> fields.append(field.name) <TAB> dict_result = {} <TAB> import datetime <TAB> for attr in fields: <MASK> dict_result[attr] = getattr(self, attr).strftime(""%Y-%m-%d %H:%M:%S"") <TAB>  <TAB> elif isinstance(getattr(self, attr), datetime.date): <TAB>  <TAB>  <TAB> dict_result[attr] = getattr(self, attr).strftime(""%Y-%m-%d"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> dict_result[attr] = getattr(self, attr) <TAB> return dict_result","if isinstance ( getattr ( self , attr ) , datetime . datetime ) :",169
def downgrade(): <TAB> connection = op.get_bind() <TAB> for user in connection.execute(UserHelper.select()): <MASK> continue <TAB>  <TAB> new_static_roles = user.static_roles << 1 <TAB>  <TAB> connection.execute( <TAB>  <TAB>  <TAB> UserHelper.update() <TAB>  <TAB>  <TAB> .where(UserHelper.c.id == user.id) <TAB>  <TAB>  <TAB> .values(static_roles=new_static_roles) <TAB>  <TAB> ),if not user . static_roles & 0x1000 :,119
"def del_condition(self): <TAB> """"""Remove the condition element."""""" <TAB> for child in self.xml: <MASK> tag = child.tag.split(""}"", 1)[-1] <TAB>  <TAB>  <TAB> if tag in self.conditions: <TAB>  <TAB>  <TAB>  <TAB> self.xml.remove(child) <TAB> return self","if ""{%s}"" % self . condition_ns in child . tag :",87
"def __dtrace_read(self, job, proc): <TAB> while True: <TAB>  <TAB> read = proc.stdout.readline() <MASK> break <TAB>  <TAB> read = read.decode(errors=""ignore"").strip() <TAB>  <TAB> job.set_progress(None, read)","if read == b"""" :",71
"def __next__(self): <TAB> self._parse_reset() <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> line = next(self.input_iter) <TAB>  <TAB> except StopIteration: <TAB>  <TAB>  <TAB> # End of input OR exception <TAB>  <TAB>  <TAB> if len(self.field) > 0: <TAB>  <TAB>  <TAB>  <TAB> raise Error(""newline inside string"") <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> self.line_num += 1 <MASK> raise Error(""line contains NULL byte"") <TAB>  <TAB> self._parse_process_char(line) <TAB>  <TAB> self._parse_eol() <TAB>  <TAB> if self.state == self.START_RECORD: <TAB>  <TAB>  <TAB> break <TAB> fields = self.fields <TAB> self.fields = [] <TAB> return fields","if ""\0"" in line :",177
"def timestr_to_secs(timestr, round_to=3): <TAB> """"""Parses time like '1h 10s', '01:00:10' or '42' and returns seconds."""""" <TAB> if isinstance(timestr, (basestring, int, long, float)): <TAB>  <TAB> for converter in _number_to_secs, _timer_to_secs, _time_string_to_secs: <TAB>  <TAB>  <TAB> secs = converter(timestr) <MASK> return secs if round_to is None else round(secs, round_to) <TAB> raise ValueError(""Invalid time string '%s'."" % timestr)",if secs is not None :,150
"def has_path_sum3(root, sum): <TAB> if root is None: <TAB>  <TAB> return False <TAB> queue = [(root, sum - root.val)] <TAB> while queue: <TAB>  <TAB> node, val = queue.pop(0)  # popleft <TAB>  <TAB> if node.left is None and node.right is None: <TAB>  <TAB>  <TAB> if val == 0: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> if node.left is not None: <TAB>  <TAB>  <TAB> queue.append((node.left, val - node.left.val)) <MASK> queue.append((node.right, val - node.right.val)) <TAB> return False",if node . right is not None :,158
"def initialize(self, inputs, sequence_length=None, mask=None, embedding=None): <TAB> if self.embedding_fn is None: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""embedding is required as a keyword argument for "" <TAB>  <TAB>  <TAB>  <TAB> ""ScheduledEmbeddingTrainingSampler"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self.embedding_fn = lambda ids: tf.nn.embedding_lookup(embedding, ids) <TAB> return super().initialize(inputs, sequence_length=sequence_length, mask=mask)",if embedding is None :,125
"def __call__(self, results): <TAB> """"""Loading image from file."""""" <TAB> has_iuv = results[""has_iuv""] <TAB> use_iuv = results[""ann_info""][""use_IUV""] <TAB> if has_iuv and use_iuv: <TAB>  <TAB> iuv_file = results[""iuv_file""] <TAB>  <TAB> iuv = mmcv.imread(iuv_file, self.color_type, self.channel_order) <MASK> raise ValueError(f""Fail to read {iuv_file}"") <TAB> else: <TAB>  <TAB> has_iuv = 0 <TAB>  <TAB> iuv = None <TAB> results[""has_iuv""] = has_iuv <TAB> results[""iuv""] = iuv <TAB> return results",if iuv is None :,180
"def run(self): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.dispatch() <TAB>  <TAB> except greenlet.GreenletExit: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> except self.SYSTEM_EXCEPTIONS: <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> except: <MASK> self.schedule_call_global( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> 0, greenlet.getcurrent().parent.throw, *self.signal_exc_info <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> self.signal_exc_info = None <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.squelch_timer_exception(None, sys.exc_info())",if self . signal_exc_info is not None :,164
"def defined_in_subclass(klass, attr): <TAB> any_klass_method = getattr(klass, attr, None) <TAB> if any_klass_method is None: <TAB>  <TAB> # Not defined in class or parent class <TAB>  <TAB> return False <TAB> for base_klass in klass.__class__.__bases__: <TAB>  <TAB> base_method = getattr(base_klass, attr, None) <TAB>  <TAB> if base_method is None: <TAB>  <TAB>  <TAB> # In some cases one of the base classes does not <TAB>  <TAB>  <TAB> # implement all methods <TAB>  <TAB>  <TAB> continue <MASK> return True <TAB> return False",if any_klass_method . __func__ is not base_method . __func__ :,153
"def check_input_data(self, args): <TAB> input_data = [] <TAB> if args.input_path: <TAB>  <TAB> input_data = [args.input_path] <TAB> elif args.input_file: <MASK> raise RuntimeError(""File %s is not exist."" % args.input_file) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> input_data = txt_parser.parse(args.input_file, use_strip=True) <TAB> return input_data",if not os . path . exists ( args . input_file ) :,126
"def _find_media_for_devpath(self, devpath): <TAB> for path in self.hal_iface.FindDeviceByCapability(""volume""): <MASK> continue <TAB>  <TAB> label, devnode = self._fetch_media_info(path) <TAB>  <TAB> if devnode == devpath: <TAB>  <TAB>  <TAB> return (label, path) <TAB> return None, None",if not self . is_cdrom_media ( path ) :,101
"def _get_res_string_value(self, string): <TAB> if not string.startswith(""@string/""): <TAB>  <TAB> return string <TAB> string_key = string[9:] <TAB> res_parser = self.get_android_resources() <TAB> if not res_parser: <TAB>  <TAB> return """" <TAB> string_value = """" <TAB> for package_name in res_parser.get_packages_names(): <TAB>  <TAB> extracted_values = res_parser.get_string(package_name, string_key) <MASK> string_value = extracted_values[1] <TAB>  <TAB>  <TAB> break <TAB> return string_value",if extracted_values :,148
"def __starts_with(self, node): <TAB> if self.arguments[0]: <TAB>  <TAB> # this is an attribute <TAB>  <TAB> attribute_name = self.arguments[1] <TAB>  <TAB> if node.has_key(attribute_name): <TAB>  <TAB>  <TAB> first = node[attribute_name] <TAB>  <TAB>  <TAB> return first.startswith(self.arguments[2]) <TAB> elif self.arguments[1] == ""text()"": <TAB>  <TAB> first = node.contents and node.contents[0] <MASK> return first.startswith(self.arguments[2]) <TAB> return False","if isinstance ( first , BeautifulSoup . NavigableString ) :",143
"def assert_subparser_constraints(parser): <TAB> if has_subparsers(parser._actions): <MASK> raise UnsupportedConfiguration( <TAB>  <TAB>  <TAB>  <TAB> ""Gooey doesn't currently support top level required arguments "" <TAB>  <TAB>  <TAB>  <TAB> ""when subparsers are present."" <TAB>  <TAB>  <TAB> )",if has_required ( parser . _actions ) :,78
def size_of_columns(self): <TAB> number_of_columns = len(self.lines_list[0]) <TAB> columns = [] <TAB> for number in range(number_of_columns): <TAB>  <TAB> columns.append(0) <TAB> for line in self.lines_list: <TAB>  <TAB> i = 0 <TAB>  <TAB> for item in line: <MASK> # test if are greater than <TAB>  <TAB>  <TAB>  <TAB> columns[i] = len(item) <TAB>  <TAB>  <TAB> i += 1 <TAB> return columns,if len ( item ) . __cmp__ ( columns [ i ] ) == 1 :,130
"def get_code(self, header, html): <TAB> try: <TAB>  <TAB> m = re.search(r'<meta.*?charset=(.*?)""(>| |/)', html, flags=re.I) <MASK> return m.group(1).replace('""', """") <TAB> except: <TAB>  <TAB> pass <TAB> try: <TAB>  <TAB> if ""Content-Type"" in header: <TAB>  <TAB>  <TAB> Content_Type = header[""Content-Type""] <TAB>  <TAB>  <TAB> m = re.search(r"".*?charset=(.*?)(;|$)"", Content_Type, flags=re.I) <TAB>  <TAB>  <TAB> if m: <TAB>  <TAB>  <TAB>  <TAB> return m.group(1) <TAB> except: <TAB>  <TAB> pass",if m :,161
"def __getitem__(self, index): <TAB> return_dict = {} <TAB> return_list = self.dataset[index] <TAB> if isinstance(return_list, (tuple, list)): <MASK> return_dict[""img""] = return_list[0] <TAB>  <TAB>  <TAB> if self.return_label: <TAB>  <TAB>  <TAB>  <TAB> return_dict[""class_id""] = np.asarray(return_list[1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return_dict[""img""] = return_list[0] <TAB> else: <TAB>  <TAB> return_dict[""img""] = return_list <TAB> return return_dict",if len ( return_list ) == 2 :,152
"def read_exth(rec0, exth_num): <TAB> exth_values = [] <TAB> ebase, elen, enum, rlen = get_exth_params(rec0) <TAB> ebase = ebase + 12 <TAB> while enum > 0: <TAB>  <TAB> exth_id = getint(rec0, ebase) <MASK> # We might have multiple exths, so build a list. <TAB>  <TAB>  <TAB> exth_values.append(rec0[ebase + 8 : ebase + getint(rec0, ebase + 4)]) <TAB>  <TAB> enum = enum - 1 <TAB>  <TAB> ebase = ebase + getint(rec0, ebase + 4) <TAB> return exth_values",if exth_id == exth_num :,179
"def unthinkable(): <TAB> for i in range(10): <TAB>  <TAB> if i % 3 == 0: <TAB>  <TAB>  <TAB> yield slice(i, i + 1) <MASK> yield i <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield np.array([i], dtype=int)",elif i % 3 == 1 :,75
"def _search_for_nodes(stack, extender, node_types): <TAB> seen = set() <TAB> while stack: <TAB>  <TAB> expr = stack.pop() <TAB>  <TAB> op = expr.op() <TAB>  <TAB> if op not in seen: <MASK> yield op <TAB>  <TAB>  <TAB> seen.add(op) <TAB>  <TAB>  <TAB> stack.extend(extender(op))","if isinstance ( op , node_types ) :",99
"def ReadCSV(s, cols): <TAB> csv_dialect = csv.Sniffer().sniff(s[0]) <TAB> reader = csv.reader(s, csv_dialect) <TAB> header = reader.next() <TAB> col_index = [-1] * len(cols) <TAB> for i in range(len(cols)): <MASK> col_index[i] = header.index(cols[i]) <TAB> for row in reader: <TAB>  <TAB> result = [None] * len(cols) <TAB>  <TAB> for i in range(len(cols)): <TAB>  <TAB>  <TAB> ci = col_index[i] <TAB>  <TAB>  <TAB> if ci >= 0: <TAB>  <TAB>  <TAB>  <TAB> result[i] = row[ci].decode(""iso-8859-1"").strip() <TAB>  <TAB> yield result",if cols [ i ] in header :,186
"def add_torrent_file(self, filename, torrent, options, torrent_hash): <TAB> try: <TAB>  <TAB> if not self.connect(): <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> torrent_id = self.client.core.add_torrent_file( <TAB>  <TAB>  <TAB> filename, b64encode(torrent), options <TAB>  <TAB> ).get() <TAB>  <TAB> if not torrent_id: <TAB>  <TAB>  <TAB> torrent_id = self._check_torrent(torrent_hash) <TAB> except Exception: <TAB>  <TAB> return False <TAB> finally: <MASK> self.disconnect() <TAB> return torrent_id",if self . client :,148
"def add_torrent_magnet(self, torrent, options, torrent_hash): <TAB> try: <TAB>  <TAB> if not self.connect(): <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> torrent_id = self.client.core.add_torrent_magnet(torrent, options).get() <TAB>  <TAB> if not torrent_id: <TAB>  <TAB>  <TAB> torrent_id = self._check_torrent(torrent_hash) <TAB> except Exception: <TAB>  <TAB> return False <TAB> finally: <MASK> self.disconnect() <TAB> return torrent_id",if self . client :,133
"def read_record(self, dtype, shape=1, byteorder=None): <TAB> """"""Return numpy record from file."""""" <TAB> try: <TAB>  <TAB> rec = numpy.rec.fromfile(self._fh, dtype, shape, byteorder=byteorder) <TAB> except Exception: <TAB>  <TAB> dtype = numpy.dtype(dtype) <MASK> shape = self._size // dtype.itemsize <TAB>  <TAB> size = product(sequence(shape)) * dtype.itemsize <TAB>  <TAB> data = self._fh.read(size) <TAB>  <TAB> return numpy.rec.fromstring(data, dtype, shape, byteorder=byteorder) <TAB> return rec[0] if shape == 1 else rec",if shape is None :,155
"def get(): <TAB> result = [] <TAB> for b in self.key_bindings: <TAB>  <TAB> if len(keys) == len(b.keys): <TAB>  <TAB>  <TAB> match = True <TAB>  <TAB>  <TAB> any_count = 0 <TAB>  <TAB>  <TAB> for i, j in zip(b.keys, keys): <TAB>  <TAB>  <TAB>  <TAB> if i != j and i != Keys.Any: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> match = False <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <MASK> any_count += 1 <TAB>  <TAB>  <TAB> if match: <TAB>  <TAB>  <TAB>  <TAB> result.append((any_count, b)) <TAB> # Place bindings that have more 'Any' occurences in them at the end. <TAB> result = sorted(result, key=lambda item: -item[0]) <TAB> return [item[1] for item in result]",if i == Keys . Any :,194
"def __set_config(self, config): <TAB> if config is not None: <TAB>  <TAB> for name in dir(config): <MASK> self.__dict__[""config_"" + name] = lambda name=name: getattr( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> config, name <TAB>  <TAB>  <TAB>  <TAB> )","if not name . startswith ( ""_"" ) and isinstance ( getattr ( config , name ) , str ) :",87
"def get_tokens_unprocessed(self, text): <TAB> for index, token, value in RegexLexer.get_tokens_unprocessed(self, text): <TAB>  <TAB> if token is Name: <TAB>  <TAB>  <TAB> if self.smhighlighting: <MASK> token = Keyword.Type <TAB>  <TAB>  <TAB>  <TAB> elif value in self._functions: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> token = Name.Builtin <TAB>  <TAB> yield index, token, value",if value in self . SM_TYPES :,111
"def calculate_total_amount(self): <TAB> self.total_claimed_amount = 0 <TAB> self.total_sanctioned_amount = 0 <TAB> for d in self.get(""expenses""): <MASK> d.sanctioned_amount = 0.0 <TAB>  <TAB> self.total_claimed_amount += flt(d.amount) <TAB>  <TAB> self.total_sanctioned_amount += flt(d.sanctioned_amount)","if self . approval_status == ""Rejected"" :",121
"def _limit(self): <TAB> if DEBUG is True: <TAB>  <TAB> # Deterministic limit <MASK> data = list(self.data) <TAB>  <TAB>  <TAB> data.sort(key=repr) <TAB>  <TAB>  <TAB> self.data = set(data[: DataSet.maximum_size]) <TAB>  <TAB>  <TAB> l.warning( <TAB>  <TAB>  <TAB>  <TAB> ""Reached maximum size of DataSet, discarded %s."", <TAB>  <TAB>  <TAB>  <TAB> str(data[DataSet.maximum_size :]), <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> # Hash dependent implementation <TAB>  <TAB> while len(self.data) > DataSet.maximum_size: <TAB>  <TAB>  <TAB> l.warning( <TAB>  <TAB>  <TAB>  <TAB> ""Reached maximum size of DataSet, discarded %s."", str(self.data.pop()) <TAB>  <TAB>  <TAB> )",if ( len ( self . data ) ) > DataSet . maximum_size :,191
"def get_all_network_interfaces(self, eni_ids=None, filters=None): <TAB> enis = self.enis.values() <TAB> if eni_ids: <TAB>  <TAB> enis = [eni for eni in enis if eni.id in eni_ids] <MASK> invalid_id = list(set(eni_ids).difference(set([eni.id for eni in enis])))[0] <TAB>  <TAB>  <TAB> raise InvalidNetworkInterfaceIdError(invalid_id) <TAB> return generic_filter(filters, enis)",if len ( enis ) != len ( eni_ids ) :,144
def get_selection(self): <TAB> if self.interface.multiple_select: <TAB>  <TAB> selection = [] <TAB>  <TAB> current_index = self.table.selectedRowIndexes.firstIndex <TAB>  <TAB> for i in range(self.table.selectedRowIndexes.count): <TAB>  <TAB>  <TAB> selection.append(self.interface.data[current_index]) <TAB>  <TAB>  <TAB> current_index = self.table.selectedRowIndexes.indexGreaterThanIndex( <TAB>  <TAB>  <TAB>  <TAB> current_index <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return selection <TAB> else: <TAB>  <TAB> index = self.table.selectedRow <MASK> return self.interface.data[index] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return None,if index != - 1 :,165
"def raw_input(self, prompt=None): <TAB> ddbg(""debugserver: raw_input prompt = %r"" % prompt) <TAB> if prompt: <TAB>  <TAB> self.write(prompt) <TAB> buf = """" <TAB> compstate = 0 <TAB> while True: <TAB>  <TAB> data = self.server.socketio.read(1) <TAB>  <TAB> ddbg(""raw_input: char=%r"" % data) <MASK> buf = self.parse_telnet(buf + data) <TAB>  <TAB>  <TAB> if buf != """": <TAB>  <TAB>  <TAB>  <TAB> return buf <TAB>  <TAB> elif data == ""\004"" or data == """":  # ^D <TAB>  <TAB>  <TAB> raise EOFError <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> buf += data","if data == LF or data == ""\006"" :",174
"def args(src, tgt, **kwargs): <TAB> arg_list = [] <TAB> arg_list.extend([u""--errorlevel=traceback"", src, tgt]) <TAB> for flag, value in kwargs.iteritems(): <TAB>  <TAB> value = unicode(value) <MASK> arg_list.append(u""-%s"" % flag) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> arg_list.append(u""--%s"" % flag) <TAB>  <TAB> if value is not None: <TAB>  <TAB>  <TAB> arg_list.append(value) <TAB> return arg_list",if len ( flag ) == 1 :,136
"def test_not_cancel_button(self): <TAB> for status in Addon.STATUS_CHOICES: <MASK> continue <TAB>  <TAB> self.addon.update(status=status) <TAB>  <TAB> response = self.client.get(self.url) <TAB>  <TAB> doc = pq(response.content) <TAB>  <TAB> assert not doc(""#cancel-review""), status <TAB>  <TAB> assert not doc(""#modal-cancel""), status",if status == amo . STATUS_NOMINATED :,107
"def __call__(self, trainer): <TAB> self._t += 1 <TAB> optimizer = self._get_optimizer(trainer) <TAB> value = self._init * (1 + self._gamma * self._t) ** (-self._power) <TAB> if self._target is not None: <TAB>  <TAB> if self._power < 0: <TAB>  <TAB>  <TAB> # almost same as value = min(value, self._target), but this <TAB>  <TAB>  <TAB> # line supports negative values, too <TAB>  <TAB>  <TAB> if value / self._target > 1: <TAB>  <TAB>  <TAB>  <TAB> value = self._target <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # ditto <MASK> value = self._target <TAB> self._update_value(optimizer, value)",if value / self . _target < 1 :,175
"def _hits_from_getattr(self, hit, token, filter_type): <TAB> self._rec_check_inc_getattr() <TAB> try: <TAB>  <TAB> new_hits = self._hits_from_getattr_aux(hit, token, filter_type) <MASK> self.debug(""_hits_from_getattr: couldn't resolve %r.%r"", hit[0], token) <TAB>  <TAB> return new_hits <TAB> finally: <TAB>  <TAB> self._rec_check_dec_getattr()",if not new_hits :,121
"def _dtype(self): <TAB> lmeasure = discover(self.lhs).measure <TAB> lty = getattr(lmeasure, ""ty"", lmeasure) <TAB> rmeasure = discover(self.rhs).measure <TAB> rty = getattr(rmeasure, ""ty"", rmeasure) <TAB> if lty == datetime_: <TAB>  <TAB> if isinstance(rty, DateTime): <TAB>  <TAB>  <TAB> return optionify(lmeasure, rmeasure, timedelta_) <MASK> return optionify(lmeasure, rmeasure, datetime_) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""can only subtract timedelta or datetime from datetime"", <TAB>  <TAB>  <TAB> ) <TAB> return super(Sub, self)._dtype","if isinstance ( rty , TimeDelta ) :",168
"def _categorize_wheel_files(self, abi, directory): <TAB> # type: (str, str) -> Tuple[Set[Package], Set[Package]] <TAB> final_wheels = [ <TAB>  <TAB> Package(directory, filename) <TAB>  <TAB> for filename in self._osutils.get_directory_contents(directory) <TAB>  <TAB> if filename.endswith("".whl"") <TAB> ] <TAB> compatible_wheels, incompatible_wheels = set(), set() <TAB> for wheel in final_wheels: <MASK> compatible_wheels.add(wheel) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> incompatible_wheels.add(wheel) <TAB> return compatible_wheels, incompatible_wheels","if self . _is_compatible_wheel_filename ( abi , wheel . filename ) :",186
"def chunk_read(response, chunk_size=8192, reporthook=None): <TAB> content_type = response.info().get(""Content-Length"") <TAB> total_size = -1 <TAB> if content_type is not None: <TAB>  <TAB> total_size = int(content_type.strip()) <TAB> count = 0 <TAB> while True: <TAB>  <TAB> chunk = response.read(chunk_size) <TAB>  <TAB> count += 1 <MASK> reporthook(count, chunk_size, total_size) <TAB>  <TAB> if chunk: <TAB>  <TAB>  <TAB> yield chunk <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break",if reporthook is not None :,145
"def _execute_statements( <TAB> self, cursor, statements, parameters, verbosity, allow_quiet_fail=False): <TAB> for template in statements: <TAB>  <TAB> stmt = template % parameters <TAB>  <TAB> if verbosity >= 2: <TAB>  <TAB>  <TAB> print(stmt) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> cursor.execute(stmt) <TAB>  <TAB> except Exception as err: <MASK> sys.stderr.write(""Failed (%s)\n"" % (err)) <TAB>  <TAB>  <TAB> raise",if ( not allow_quiet_fail ) or verbosity >= 2 :,125
"def arrayit(self): <TAB> array = [] <TAB> # order must match self.attributes_ <TAB> # some entries must be converted to string format from arrays <TAB> for ii in Users.attributes_: <MASK> array.append("":"".join(getattr(self, ii + ""_""))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> array.append(str(getattr(self, ii + ""_""))) <TAB> return array","if ii == ""applications"" :",99
"def initConditionVariableTable(self, exp_id, sess_id, numpy_dtype): <TAB> dsfile = self.iohub.dsfile <TAB> if dsfile: <TAB>  <TAB> output = [] <TAB>  <TAB> for a in numpy_dtype: <MASK> output.append(tuple(a)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> temp = [a[0], []] <TAB>  <TAB>  <TAB>  <TAB> for i in a[1]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> temp[1].append(tuple(i)) <TAB>  <TAB>  <TAB>  <TAB> output.append(tuple(temp)) <TAB>  <TAB> return dsfile.initConditionVariableTable(exp_id, sess_id, output) <TAB> return False","if isinstance ( a [ 1 ] , basestring ) :",167
"def iter_messages(self): <TAB> """"""Yields tuples of (topic, message)"""""" <TAB> with self: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> events = dict(self.poller.poll(self.timeout * 1000)) <TAB>  <TAB>  <TAB> except zmq.ZMQError as e: <MASK> continue <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB>  <TAB> if len(events) == 0: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> topic, message = self.pubsub_socket.recv_multipart() <TAB>  <TAB>  <TAB> yield topic, message",if e . errno == errno . EINTR :,146
"def check_session_cookie_secure(app_configs, **kwargs): <TAB> errors = [] <TAB> if not settings.SESSION_COOKIE_SECURE: <TAB>  <TAB> if _session_app(): <TAB>  <TAB>  <TAB> errors.append(W010) <TAB>  <TAB> if _session_middleware(): <TAB>  <TAB>  <TAB> errors.append(patch_middleware_message(W011)) <MASK> errors = [W012] <TAB> return errors",if len ( errors ) > 1 :,106
"def __getattr__(self, item: str) -> Any: <TAB> if hasattr(MissingPandasLikeExpandingGroupby, item): <TAB>  <TAB> property_or_func = getattr(MissingPandasLikeExpandingGroupby, item) <MASK> return property_or_func.fget(self)  # type: ignore <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return partial(property_or_func, self) <TAB> raise AttributeError(item)","if isinstance ( property_or_func , property ) :",107
"def _get_recordingid_matches(self, file, recordingid): <TAB> matches = [] <TAB> tracknumber = file.metadata[""tracknumber""] <TAB> discnumber = file.metadata[""discnumber""] <TAB> for track in self.tracks: <TAB>  <TAB> tm = track.orig_metadata <MASK> if tracknumber == tm[""tracknumber""]: <TAB>  <TAB>  <TAB>  <TAB> if discnumber == tm[""discnumber""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> matches.append((4.0, track)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> matches.append((3.0, track)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> matches.append((2.0, track)) <TAB> return matches","if recordingid == tm [ ""musicbrainz_recordingid"" ] :",177
"def run_suppress_output(cmd, stop_print_on_fail=False): <TAB> process = subprocess.Popen( <TAB>  <TAB> cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True <TAB> ) <TAB> out, err = process.communicate() <TAB> if stop_print_on_fail and process.returncode != 0: <TAB>  <TAB> print( <TAB>  <TAB>  <TAB> ""exit with {} of {}"".format( <TAB>  <TAB>  <TAB>  <TAB> process.returncode, "" "".join(pipes.quote(i) for i in cmd) <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB> file=sys.stdout, <TAB>  <TAB> ) <TAB>  <TAB> if out: <TAB>  <TAB>  <TAB> print(out, file=sys.stdout) <MASK> print(err, file=sys.stderr) <TAB>  <TAB> raise SystemExit(process.returncode) <TAB> return process.returncode",if err :,197
"def addException(): <TAB> global errors <TAB> # self.widget._report_exception() <TAB> try: <TAB>  <TAB> typ, val, tb = sys.exc_info() <TAB>  <TAB> traceback.print_exception(typ, val, tb) <TAB>  <TAB> if errors: <TAB>  <TAB>  <TAB> errors.append("""") <TAB>  <TAB> exception = traceback.format_exception(typ, val, tb) <TAB>  <TAB> errors.extend(exception) <MASK> # If too many errors are found send the error report <TAB>  <TAB>  <TAB> ReportDialog(self.widget) <TAB> except: <TAB>  <TAB> say(str(sys.exc_info()))",if len ( errors ) > 100 :,149
"def text(self, charset=None, errors=None): <TAB> """"""Decode content as a string."""""" <TAB> data = self.content <TAB> if data is not None: <MASK> ct = self.headers.get(""content-type"") <TAB>  <TAB>  <TAB> if ct: <TAB>  <TAB>  <TAB>  <TAB> ct, options = parse_options_header(ct) <TAB>  <TAB>  <TAB>  <TAB> charset = options.get(""charset"") <TAB>  <TAB> return data.decode(charset or ""utf-8"", errors or ""strict"")",if charset is None :,119
"def has_elements(self, iter, num=1): <TAB> logger.debug(""has_element '%s' %i"" % (iter, num)) <TAB> c = 0 <TAB> for k in iter: <TAB>  <TAB> logger.debug(""has_element '%s' -> '%s'"" % (iter, k)) <TAB>  <TAB> path = k.name[len(self.s3_prefix) :] <TAB>  <TAB> if not self.cache.is_deleting(path): <TAB>  <TAB>  <TAB> c += 1 <MASK> logger.debug(""has_element '%s' OK"" % (iter)) <TAB>  <TAB>  <TAB> return True <TAB> logger.debug(""has_element '%s' KO"" % (iter)) <TAB> return False",if c >= num :,169
"def reverse(self, *args): <TAB> if self._path is None: <TAB>  <TAB> raise ValueError(""Cannot reverse url regex "" + self.regex.pattern) <TAB> assert len(args) == self._group_count, ""required number of arguments "" ""not found"" <TAB> if not len(args): <TAB>  <TAB> return self._path <TAB> converted_args = [] <TAB> for a in args: <MASK> a = str(a) <TAB>  <TAB> converted_args.append(url_escape(utf8(a), plus=False)) <TAB> return self._path % tuple(converted_args)","if not isinstance ( a , ( unicode_type , bytes ) ) :",150
"def __construct_children(self, task): <TAB> if self.children is None: <TAB>  <TAB> return <TAB> for cls in self.children: <TAB>  <TAB> if cls.mode is None: <TAB>  <TAB>  <TAB> log.warn('%r does not has a valid ""mode"" attribute', cls) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # `cls.mode` can be defined as a single mode, or list of modes <MASK> modes = cls.mode <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> modes = [cls.mode] <TAB>  <TAB> # Construct child module <TAB>  <TAB> obj = cls(task) <TAB>  <TAB> for mode in modes: <TAB>  <TAB>  <TAB> yield mode, obj",if type ( cls . mode ) is list :,160
"def get_filters(self, request): <TAB> filter_specs = [] <TAB> if self.list_filter: <TAB>  <TAB> for filter_name in self.list_filter: <TAB>  <TAB>  <TAB> field = get_fields_from_path(self.model, filter_name)[-1] <TAB>  <TAB>  <TAB> spec = FilterSpec.create( <TAB>  <TAB>  <TAB>  <TAB> field, <TAB>  <TAB>  <TAB>  <TAB> request, <TAB>  <TAB>  <TAB>  <TAB> self.params, <TAB>  <TAB>  <TAB>  <TAB> self.model, <TAB>  <TAB>  <TAB>  <TAB> self.model_admin, <TAB>  <TAB>  <TAB>  <TAB> field_path=filter_name, <TAB>  <TAB>  <TAB> ) <MASK> filter_specs.append(spec) <TAB> return filter_specs, bool(filter_specs)",if spec and spec . has_output ( ) :,175
"def _handle_end(self, tag): <TAB> if self._translate is True: <MASK> self._enqueue(tag, self._data, self._comments) <TAB>  <TAB> self._translate = False <TAB>  <TAB> self._data = [] <TAB>  <TAB> self._comments = []",if self . _data :,70
"def _call_function(self, function: Callable[..., Any]) -> bool: <TAB> self.actual = None <TAB> try: <TAB>  <TAB> function() <TAB> except BaseException: <TAB>  <TAB> self.actual = sys.exc_info()[1] <MASK> if self.pattern is not None: <TAB>  <TAB>  <TAB>  <TAB> if re.search(self.pattern, str(self.actual)) is None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> if self.matcher is not None: <TAB>  <TAB>  <TAB>  <TAB> if not self.matcher.matches(self.actual): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> return True <TAB> return False","if isinstance ( self . actual , self . expected ) :",158
"def markCPEs(cve): <TAB> blacklist = compile(db.getRules(""blacklist"")) <TAB> whitelist = compile(db.getRules(""whitelist"")) <TAB> for conf in cve[""vulnerable_configuration""]: <TAB>  <TAB> conf[""list""] = ""none"" <TAB>  <TAB> conf[""match""] = ""none"" <TAB>  <TAB> for w in whitelist: <TAB>  <TAB>  <TAB> if w.match(conf[""id""]): <TAB>  <TAB>  <TAB>  <TAB> conf[""list""] = ""white"" <TAB>  <TAB>  <TAB>  <TAB> conf[""match""] = w <TAB>  <TAB> for b in blacklist: <MASK> conf[""list""] = ""black"" <TAB>  <TAB>  <TAB>  <TAB> conf[""match""] = b <TAB> return cve","if b . match ( conf [ ""id"" ] ) :",165
"def _get(self, queue): <TAB> with self.conn_or_acquire() as client: <TAB>  <TAB> for pri in self.priority_steps: <TAB>  <TAB>  <TAB> item = client.rpop(self._q_for_pri(queue, pri)) <MASK> return loads(bytes_to_str(item)) <TAB>  <TAB> raise Empty()",if item :,87
"def _root_del(self, path): <TAB> json_dict = self._json_dict <TAB> for key in path[:-1]: <TAB>  <TAB> json_dict = json_dict[key] <TAB> val = json_dict[path[-1]] <TAB> del json_dict[path[-1]] <TAB> if isinstance(val, dict) and val.get(""_type"") in H5_TYPES: <MASK> wandb.termerror(""Deleting tensors in summary requires h5py"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.open_h5() <TAB>  <TAB>  <TAB> h5_key = ""summary/"" + ""."".join(path) <TAB>  <TAB>  <TAB> del self._h5[h5_key] <TAB>  <TAB>  <TAB> self._h5.flush()",if not h5py :,178
"def _delete(self, obj, entire_dir=False, **kwargs): <TAB> """"""Override `ObjectStore`'s stub; delete the file or folder on disk."""""" <TAB> path = self._get_filename(obj, **kwargs) <TAB> extra_dir = kwargs.get(""extra_dir"", None) <TAB> obj_dir = kwargs.get(""obj_dir"", False) <TAB> try: <TAB>  <TAB> if entire_dir and (extra_dir or obj_dir): <TAB>  <TAB>  <TAB> shutil.rmtree(path) <TAB>  <TAB>  <TAB> return True <MASK> os.remove(path) <TAB>  <TAB>  <TAB> return True <TAB> except OSError as ex: <TAB>  <TAB> log.critical( <TAB>  <TAB>  <TAB> ""{} delete error {}"".format(self.__get_filename(obj, **kwargs), ex) <TAB>  <TAB> ) <TAB> return False","if self . _exists ( obj , ** kwargs ) :",195
"def partial_fit(self, X, y, classes=None): <TAB> if y.ndim == 1: <TAB>  <TAB> y = y.reshape((y.shape[0], 1)) <TAB> if classes is not None: <MASK> classes = [classes] <TAB>  <TAB> LB = sklearn.preprocessing.LabelBinarizer <TAB>  <TAB> self.label_binarizers = [LB() for _ in range(y.shape[1])] <TAB>  <TAB> for lb, cls in zip(self.label_binarizers, classes): <TAB>  <TAB>  <TAB> lb.fit(cls) <TAB> return self.fit(X, y)","if isinstance ( classes [ 0 ] , int ) :",148
"def parse_color_stop(tokens): <TAB> if len(tokens) == 1: <TAB>  <TAB> color = parse_color(tokens[0]) <MASK> # TODO: return the current color instead <TAB>  <TAB>  <TAB> return parse_color(""black""), None <TAB>  <TAB> if color is not None: <TAB>  <TAB>  <TAB> return color, None <TAB> elif len(tokens) == 2: <TAB>  <TAB> color = parse_color(tokens[0]) <TAB>  <TAB> position = get_length(tokens[1], negative=True, percentage=True) <TAB>  <TAB> if color is not None and position is not None: <TAB>  <TAB>  <TAB> return color, position <TAB> raise InvalidValues","if color == ""currentColor"" :",155
"def _validate_and_parse_update_payload(self, payload): <TAB> validated_payload = {} <TAB> for key, val in payload.items(): <MASK> continue <TAB>  <TAB> if key in (""name""): <TAB>  <TAB>  <TAB> val = validation.validate_and_sanitize_basestring(key, val) <TAB>  <TAB>  <TAB> validated_payload[key] = val <TAB>  <TAB> if key in (""deleted"", ""visible""): <TAB>  <TAB>  <TAB> validated_payload[key] = validation.validate_boolean(key, val) <TAB>  <TAB> elif key == ""tags"": <TAB>  <TAB>  <TAB> validated_payload[key] = validation.validate_and_sanitize_basestring_list( <TAB>  <TAB>  <TAB>  <TAB> key, val <TAB>  <TAB>  <TAB> ) <TAB> return validated_payload",if val is None :,175
"def addStack(self, size, num_allocs, stack): <TAB> self.size += size * num_allocs <TAB> self.number += num_allocs <TAB> if len(stack) > 0: <TAB>  <TAB> child = stack[0] <MASK> self.children[child.addr] = child <TAB>  <TAB> self.children[child.addr].addStack(size, num_allocs, stack[1:])",if not ( child . addr in self . children ) :,106
"def set_current_frame(self, name): <TAB> if name is None: <TAB>  <TAB> self.notebook.set_current_page(0) <TAB> else: <TAB>  <TAB> for frame_name in self.frame_names: <TAB>  <TAB>  <TAB> if name == frame_name: <MASK> fname, child = self.frames[frame_name][0] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> page = self.notebook.page_num(child) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.notebook.set_current_page(page) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return",if len ( self . frames [ frame_name ] ) > 0 :,145
"def process(self, display=True, **args): <TAB> order = self.order() <TAB> vals = [] <TAB> for name in order: <MASK> continue <TAB>  <TAB> val = args[name] <TAB>  <TAB> if isinstance(val, np.ndarray) and len(val.dtype) > 0: <TAB>  <TAB>  <TAB> vals.append(val) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> vals.append((name, None, val)) <TAB> return {""output"": functions.concatenateColumns(vals)}",if name not in args :,120
"def mouseDragEvent(self, ev): <TAB> if not self.movable: <TAB>  <TAB> return <TAB> if ev.button() == QtCore.Qt.LeftButton: <TAB>  <TAB> if ev.isStart(): <TAB>  <TAB>  <TAB> self.moving = True <TAB>  <TAB>  <TAB> self.cursorOffset = self.pos() - self.mapToParent(ev.buttonDownPos()) <TAB>  <TAB>  <TAB> self.startPosition = self.pos() <TAB>  <TAB> ev.accept() <MASK> return <TAB>  <TAB> self.setPos(self.cursorOffset + self.mapToParent(ev.pos())) <TAB>  <TAB> if ev.isFinish(): <TAB>  <TAB>  <TAB> self.moving = False <TAB>  <TAB>  <TAB> self.sigDragged.emit(self)",if not self . moving :,172
"def ComboBoxDroppedHeightTest(windows): <TAB> """"""Check if each combobox height is the same as the reference"""""" <TAB> bugs = [] <TAB> for win in windows: <MASK> continue <TAB>  <TAB> if win.class_name() != ""ComboBox"" or win.ref.class_name() != ""ComboBox"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if win.dropped_rect().height() != win.ref.dropped_rect().height(): <TAB>  <TAB>  <TAB> bugs.append( <TAB>  <TAB>  <TAB>  <TAB> ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> win, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ], <TAB>  <TAB>  <TAB>  <TAB>  <TAB> {}, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> testname, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> 0, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> return bugs",if not win . ref :,185
"def reader(): <TAB> batch_out = [] <TAB> for item in fl: <TAB>  <TAB> fileinfo = item.split("" "") <TAB>  <TAB> filepath = fileinfo[0] <TAB>  <TAB> rgb = np.load(filepath, allow_pickle=True) <TAB>  <TAB> nframes = rgb.shape[0] <TAB>  <TAB> label = [int(i) for i in fileinfo[1:]] <TAB>  <TAB> one_hot_label = make_one_hot(label, self.num_classes) <MASK> batch_out.append((rgb, one_hot_label)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> batch_out.append((rgb, filepath.split(""/"")[-1])) <TAB>  <TAB> if len(batch_out) == self.batch_size: <TAB>  <TAB>  <TAB> yield batch_out <TAB>  <TAB>  <TAB> batch_out = []","if self . mode != ""infer"" :",191
"def yield_and_release(time_waited): <TAB> try: <TAB>  <TAB> self.logger.debug( <TAB>  <TAB>  <TAB> ""request lock acquired {}."".format( <TAB>  <TAB>  <TAB>  <TAB> ""on the first try"" <MASK> else ""in {} seconds"".format(time_waited) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB>  <TAB> yield <TAB> finally: <TAB>  <TAB> self.free_to_handle_request_lock.release() <TAB>  <TAB> self.logger.debug(""released request lock."")",if time_waited == 0,126
"def test_default(self): <TAB> with original_warnings.catch_warnings(record=True, module=self.module) as w: <TAB>  <TAB> self.module.resetwarnings() <TAB>  <TAB> self.module.filterwarnings(""default"", category=UserWarning) <TAB>  <TAB> message = UserWarning(""FilterTests.test_default"") <TAB>  <TAB> for x in range(2): <TAB>  <TAB>  <TAB> self.module.warn(message, UserWarning) <MASK> self.assertEqual(w[-1].message, message) <TAB>  <TAB>  <TAB>  <TAB> del w[:] <TAB>  <TAB>  <TAB> elif x == 1: <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(len(w), 0) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""loop variant unhandled"")",if x == 0 :,170
"def parse(self, input): <TAB> """"""parses lines and adds them to the file"""""" <TAB> if not self.filename: <TAB>  <TAB> self.filename = getattr(input, ""name"", """") <TAB> if hasattr(input, ""read""): <TAB>  <TAB> src = input.read() <TAB>  <TAB> input.close() <TAB> else: <TAB>  <TAB> src = input <TAB> for line in src.split(""\n""): <TAB>  <TAB> line = quote.rstripeol(line) <MASK> continue <TAB>  <TAB> parts = line.split(""\t"") <TAB>  <TAB> thisline = ooline(parts) <TAB>  <TAB> self.addline(thisline)",if not line :,149
"def _scoochXKids(self, nid, ninfo, lr=None): <TAB> weight = ninfo[""weight""] <TAB> for eid, n1, n2, einfo in self.graph.getRefsFromByNid(nid): <TAB>  <TAB> kinfo = self.graph.getNodeProps(n2) <TAB>  <TAB> # Only do ghost nodes (for now...) <TAB>  <TAB> if not kinfo.get(""ghost""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # Only do this to kids in the layer beneath us... <MASK> continue <TAB>  <TAB> self._scoochXAlign(ninfo, kinfo, lr=lr)","if kinfo [ ""weight"" ] != weight + 1 :",167
"def __str__(self): <TAB> readable_period = None <TAB> if self.every == 1: <TAB>  <TAB> for period, _readable_period in SINGULAR_PERIODS: <MASK> readable_period = _readable_period.lower() <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> return _(""every {}"").format(readable_period) <TAB> for period, _readable_period in PERIOD_CHOICES: <TAB>  <TAB> if period == self.period: <TAB>  <TAB>  <TAB> readable_period = _readable_period.lower() <TAB>  <TAB>  <TAB> break <TAB> return _(""every {} {}"").format(self.every, readable_period)",if period == self . period :,148
"def intread(buf): <TAB> """"""Unpacks the given buffer to an integer"""""" <TAB> try: <TAB>  <TAB> if isinstance(buf, int): <TAB>  <TAB>  <TAB> return buf <TAB>  <TAB> length = len(buf) <MASK> return buf[0] <TAB>  <TAB> elif length <= 4: <TAB>  <TAB>  <TAB> tmp = buf + b""\x00"" * (4 - length) <TAB>  <TAB>  <TAB> return struct_unpack(""<I"", tmp)[0] <TAB>  <TAB> tmp = buf + b""\x00"" * (8 - length) <TAB>  <TAB> return struct_unpack(""<Q"", tmp)[0] <TAB> except: <TAB>  <TAB> raise",if length == 1 :,147
"def add_tests_to_suite(suite, opt): <TAB> new_suite = [] <TAB> if ""all"" in opt: <TAB>  <TAB> new_suite = SUITES[:] <TAB> else: <TAB>  <TAB> for test_case in SUITES: <MASK> new_suite.append(test_case) <TAB> for test_case in new_suite: <TAB>  <TAB> for method in dir(test_case): <TAB>  <TAB>  <TAB> if method.startswith(""test_""): <TAB>  <TAB>  <TAB>  <TAB> suite.addTest(test_case(method))","if hasattr ( test_case , ""categories"" ) and opt in test_case . categories :",145
"def SetLoggedIn(cmd, user=None, redirect=False, session_id=None): <TAB> user = user or ""DEFAULT"" <TAB> sid = session_id or cmd.session.ui.html_variables.get(""http_session"") <TAB> if sid: <TAB>  <TAB> if cmd: <TAB>  <TAB>  <TAB> cmd.session.ui.debug(""Logged in %s as %s"" % (sid, user)) <TAB>  <TAB> SESSION_CACHE[sid] = UserSession( <TAB>  <TAB>  <TAB> auth=user, <TAB>  <TAB>  <TAB> data={ <TAB>  <TAB>  <TAB>  <TAB> ""t"": ""%x"" % int(time.time()), <TAB>  <TAB>  <TAB> }, <TAB>  <TAB> ) <TAB> if cmd: <MASK> return cmd._do_redirect() <TAB> else: <TAB>  <TAB> return True",if redirect :,179
def _delete_all(endpoint): <TAB> while True: <TAB>  <TAB> resource = endpoint.get() <TAB>  <TAB> for item in resource.results: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> item.delete() <TAB>  <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB>  <TAB> print(e) <MASK> return,if not resource . next :,80
"def analyze(self, file, filename): <TAB> file_type_analyzers = ( <TAB>  <TAB> (self._analyze_ini_file(), configparser.Error), <TAB>  <TAB> (self._analyze_yaml_file, yaml.YAMLError), <TAB>  <TAB> (super(HighEntropyStringsPlugin, self).analyze, Exception), <TAB>  <TAB> (self._analyze_ini_file(add_header=True), configparser.Error), <TAB> ) <TAB> for analyze_function, exception_class in file_type_analyzers: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> output = analyze_function(file, filename) <MASK> return output <TAB>  <TAB> except exception_class: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> file.seek(0) <TAB> return {}",if output :,173
"def parse(self, file): <TAB> file = EncodedIO(file) <TAB> file = io.TextIOWrapper(file, encoding=file.encoding) <TAB> data = [] <TAB> for i, line in enumerate(file, start=1): <MASK> yield data <TAB>  <TAB>  <TAB> data = [] <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> j = json.loads(line) <TAB>  <TAB>  <TAB> j[""meta""] = FileParser.encode_metadata(j.get(""meta"", {})) <TAB>  <TAB>  <TAB> data.append(j) <TAB>  <TAB> except json.decoder.JSONDecodeError: <TAB>  <TAB>  <TAB> raise FileParseException(line_num=i, line=line) <TAB> if data: <TAB>  <TAB> yield data",if len ( data ) >= settings . IMPORT_BATCH_SIZE :,172
"def __repr__(self): <TAB> if not self: <TAB>  <TAB> r = ""<Closed HDF5 dataset>"" <TAB> else: <MASK> namestr = '(""anonymous"")' <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = pp.basename(pp.normpath(self.name)) <TAB>  <TAB>  <TAB> namestr = '""%s""' % (name if name != """" else ""/"") <TAB>  <TAB> r = '<HDF5 dataset %s: shape %s, type ""%s"">' % ( <TAB>  <TAB>  <TAB> namestr, <TAB>  <TAB>  <TAB> self.shape, <TAB>  <TAB>  <TAB> self.dtype.str, <TAB>  <TAB> ) <TAB> return r",if self . name is None :,146
"def train_model(model, epochs, X_train, y_train): <TAB> criterion = nn.CrossEntropyLoss() <TAB> optimizer = torch.optim.Adam(model.parameters(), lr=0.01) <TAB> for epoch in range(epochs): <TAB>  <TAB> out = model(X_train) <TAB>  <TAB> loss = criterion(out, y_train).to(device) <TAB>  <TAB> optimizer.zero_grad() <TAB>  <TAB> loss.backward() <TAB>  <TAB> optimizer.step() <MASK> print(""number of epoch"", epoch, ""loss"", float(loss)) <TAB> return model",if epoch % 10 == 0 :,139
"def _scoochXKids(self, nid, ninfo, lr=None): <TAB> weight = ninfo[""weight""] <TAB> for eid, n1, n2, einfo in self.graph.getRefsFromByNid(nid): <TAB>  <TAB> kinfo = self.graph.getNodeProps(n2) <TAB>  <TAB> # Only do ghost nodes (for now...) <MASK> continue <TAB>  <TAB> # Only do this to kids in the layer beneath us... <TAB>  <TAB> if kinfo[""weight""] != weight + 1: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> self._scoochXAlign(ninfo, kinfo, lr=lr)","if not kinfo . get ( ""ghost"" ) :",167
"def _is_inline_hooked(self, ops, op_members, modules): <TAB> for check in op_members: <TAB>  <TAB> addr = ops.m(check) <TAB>  <TAB> if addr and addr != 0: <TAB>  <TAB>  <TAB> hook_info = self._is_hooked(addr, modules) <MASK> (hook_type, addr) = hook_info <TAB>  <TAB>  <TAB>  <TAB> yield check, hook_type, addr",if hook_info :,107
"def existing_display(self): <TAB> try: <TAB>  <TAB> return self._display <TAB> except AttributeError: <MASK> self._display = getattr(self.original, self.field.name) <TAB>  <TAB> elif isinstance(self.field.rel, models.ManyToManyRel): <TAB>  <TAB>  <TAB> self._display = "", "".join( <TAB>  <TAB>  <TAB>  <TAB> [str(obj) for obj in getattr(self.original, self.field.name).all()] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return self._display","if isinstance ( self . field . rel , models . ManyToOneRel ) :",130
"def safe_str(x): <TAB> try: <TAB>  <TAB> # For Python3, it can be int, float <MASK> x = str(x) <TAB>  <TAB> x = x.encode(""ascii"", ""xmlcharrefreplace"") if hasattr(x, ""encode"") else x <TAB>  <TAB> x = x.decode(""utf-8"") <TAB> except Exception: <TAB>  <TAB> pass <TAB> return html_escape(x, False)","if isinstance ( x , ( int , float ) ) :",106
"def iteridat(): <TAB> """"""Iterator that yields all the ``IDAT`` chunks as strings."""""" <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> type, data = self.chunk(lenient=lenient) <TAB>  <TAB> except ValueError as e: <TAB>  <TAB>  <TAB> raise ChunkError(e.args[0]) <TAB>  <TAB> if type == ""IEND"": <TAB>  <TAB>  <TAB> # http://www.w3.org/TR/PNG/#11IEND <TAB>  <TAB>  <TAB> break <MASK> continue <TAB>  <TAB> # type == 'IDAT' <TAB>  <TAB> # http://www.w3.org/TR/PNG/#11IDAT <TAB>  <TAB> if self.colormap and not self.plte: <TAB>  <TAB>  <TAB> warnings.warn(""PLTE chunk is required before IDAT chunk"") <TAB>  <TAB> yield data","if type != ""IDAT"" :",190
"def add_input(self, accumulator, next_input): <TAB> if self._is_combining_accumulators: <TAB>  <TAB> # First accumulator can be None. <TAB>  <TAB> accumulators = [] <TAB>  <TAB> if accumulator is not None: <TAB>  <TAB>  <TAB> accumulators.append(accumulator) <MASK> accumulators.append(next_input) <TAB>  <TAB> return self.merge_accumulators(accumulators) <TAB> return self._combiner.add_input(accumulator, next_input)",if next_input is not None :,126
"def __getstate__(self): <TAB> pref_map = {} <TAB> for id, (val, index) in self.pref_map.items(): <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> val = UnwrapObject(val) <TAB>  <TAB>  <TAB> except COMException: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> pref_map[id] = val, index <TAB> return ( <TAB>  <TAB> pref_map, <TAB>  <TAB> self.index_map, <TAB>  <TAB> self.index_small, <TAB>  <TAB> self.index_big, <TAB>  <TAB> self.id, <TAB>  <TAB> self.type, <TAB> )",if type ( val ) == types . InstanceType :,147
"def then(self, task, *args, **kwargs): <TAB> if self.on_complete: <TAB>  <TAB> self.on_complete.then(task, *args, **kwargs) <TAB> else: <TAB>  <TAB> if isinstance(task, Task): <MASK> task.extend_data(args) <TAB>  <TAB>  <TAB> if kwargs: <TAB>  <TAB>  <TAB>  <TAB> task.extend_data(kwargs) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> task = task.s(*args, **kwargs) <TAB>  <TAB> self.on_complete = task <TAB> return self",if args :,130
"def _save_file_from_connection(conn, filename, reporthook=None): <TAB> if not conn.ok: <TAB>  <TAB> raise TaurusNetworkError(""Connection failed, status code %s"" % conn.status_code) <TAB> total = int(conn.headers.get(""content-length"", 0)) <TAB> block_size = 1024 <TAB> count = 0 <TAB> with open(filename, ""wb"") as f: <TAB>  <TAB> for chunk in conn.iter_content(chunk_size=block_size): <MASK> f.write(chunk) <TAB>  <TAB>  <TAB>  <TAB> count += 1 <TAB>  <TAB>  <TAB>  <TAB> if reporthook: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> reporthook(count, block_size, total)",if chunk :,166
"def save(self): <TAB> updates = self.cinder_obj_get_changes() <TAB> if updates: <TAB>  <TAB> if ""connection_info"" in updates: <TAB>  <TAB>  <TAB> self._convert_connection_info_to_db_format(updates) <MASK> self._convert_connector_to_db_format(updates) <TAB>  <TAB> if ""volume"" in updates: <TAB>  <TAB>  <TAB> raise exception.ObjectActionError(action=""save"", reason=_(""volume changed"")) <TAB>  <TAB> db.volume_attachment_update(self._context, self.id, updates) <TAB>  <TAB> self.obj_reset_changes()","if ""connector"" in updates :",148
"def _render_subtree(name, rendered_children): <TAB> lines = [] <TAB> lines.append(name) <TAB> for child_lines in rendered_children: <MASK> first_prefix = END_PREFIX <TAB>  <TAB>  <TAB> rest_prefix = END_CONTINUE <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> first_prefix = MID_PREFIX <TAB>  <TAB>  <TAB> rest_prefix = MID_CONTINUE <TAB>  <TAB> lines.append(first_prefix + child_lines[0]) <TAB>  <TAB> for child_line in child_lines[1:]: <TAB>  <TAB>  <TAB> lines.append(rest_prefix + child_line) <TAB> return lines",if child_lines is rendered_children [ - 1 ] :,153
"def infinite_first_int(cls, iterable, field: ModelField): <TAB> first_value = next(iterable) <TAB> if field.sub_fields: <TAB>  <TAB> # The Iterable had a parameter type, in this case it's int <TAB>  <TAB> # We use it to validate the first value <TAB>  <TAB> sub_field = field.sub_fields[0] <TAB>  <TAB> v, error = sub_field.validate(first_value, {}, loc=""first_value"") <MASK> raise ValidationError([error], cls) <TAB> # This creates a new generator that returns the first value and then <TAB> # the rest of the values from the (already started) iterable <TAB> return itertools.chain([first_value], iterable)",if error :,164
"def output_keys_for(output_features): <TAB> keys = [] <TAB> for feature in output_features: <TAB>  <TAB> name = feature[""name""] <MASK> keys.append(""{}_predictions"".format(name)) <TAB>  <TAB>  <TAB> keys.append(""{}_probability"".format(name)) <TAB>  <TAB>  <TAB> keys.append(""{}_probabilities_<UNK>"".format(name)) <TAB>  <TAB>  <TAB> for category in feature[""idx2str""]: <TAB>  <TAB>  <TAB>  <TAB> keys.append(""{}_probabilities_{}"".format(name, category)) <TAB>  <TAB> elif feature[""type""] == ""numerical"": <TAB>  <TAB>  <TAB> keys.append(""{}_predictions"".format(name)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise NotImplementedError <TAB> return keys","if feature [ ""type"" ] == ""category"" :",163
"def update(self): <TAB> today = datetime.now().strftime(""%Y-%m-%d"") <TAB> try: <TAB>  <TAB> r = requests.get( <TAB>  <TAB>  <TAB> self.source.format(date=today), headers={""User-Agent"": ""yeti-project""} <TAB>  <TAB> ) <MASK> reader = csv.reader(r.content.decode().splitlines(), quotechar='""') <TAB>  <TAB>  <TAB> for line in reader: <TAB>  <TAB>  <TAB>  <TAB> self.analyze(line) <TAB> except Exception as e: <TAB>  <TAB> logging.error(e)",if r . ok :,130
"def _set_attrs(self, attrs): <TAB> for attr in self.ATTRS: <TAB>  <TAB> if attr in attrs: <TAB>  <TAB>  <TAB> setattr(self, attr, attrs[attr]) <TAB>  <TAB>  <TAB> del attrs[attr] <TAB>  <TAB> else: <MASK> setattr(self, attr, NO_DEFAULT) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> setattr(self, attr, None) <TAB> if attrs: <TAB>  <TAB> attrs = attrs.keys() <TAB>  <TAB> attrs.sort() <TAB>  <TAB> raise OptionError(""invalid keyword arguments: %s"" % "", "".join(attrs), self)","if attr == ""default"" :",144
"def __init__(self, field, pattern): <TAB> super(BytesQuery, self).__init__(field, pattern) <TAB> # Use a buffer/memoryview representation of the pattern for SQLite <TAB> # matching. This instructs SQLite to treat the blob as binary <TAB> # rather than encoded Unicode. <TAB> if isinstance(self.pattern, (six.text_type, bytes)): <MASK> self.pattern = self.pattern.encode(""utf-8"") <TAB>  <TAB> self.buf_pattern = buffer(self.pattern) <TAB> elif isinstance(self.pattern, buffer): <TAB>  <TAB> self.buf_pattern = self.pattern <TAB>  <TAB> self.pattern = bytes(self.pattern)","if isinstance ( self . pattern , six . text_type ) :",166
def offline_write(queue): <TAB> while True: <TAB>  <TAB> know = queue.get() <TAB>  <TAB> queue.task_done() <MASK> self._out_file.write(pickle.dumps(know)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # should close file in child thread to wait for all <TAB>  <TAB>  <TAB> # writing finished <TAB>  <TAB>  <TAB> self._out_file.close(),"if not isinstance ( know , EndSignal ) :",103
"def process_subscriptions(self, request): <TAB> agreed_channels = [] <TAB> echo_message = False <TAB> for qp in request.GET: <TAB>  <TAB> param = qp.strip().lower() <TAB>  <TAB> if param in self.possible_channels: <TAB>  <TAB>  <TAB> agreed_channels.append(param) <MASK> echo_message = True <TAB> return agreed_channels, echo_message","elif param == ""echo"" :",101
"def test_get_image_load_image(self): <TAB> with tempfile.TemporaryFile() as f: <TAB>  <TAB> stream = self.client.get_image(TEST_IMG) <TAB>  <TAB> for chunk in stream: <TAB>  <TAB>  <TAB> f.write(chunk) <TAB>  <TAB> f.seek(0) <TAB>  <TAB> result = self.client.load_image(f.read()) <TAB> success = False <TAB> result_line = ""Loaded image: {}\n"".format(TEST_IMG) <TAB> for data in result: <TAB>  <TAB> print(data) <MASK> if data[""stream""] == result_line: <TAB>  <TAB>  <TAB>  <TAB> success = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB> assert success is True","if ""stream"" in data :",167
"def _filter_completions(self, completions): <TAB> # filter out completions not applicable to MicroPython <TAB> result = [] <TAB> for completion in completions: <TAB>  <TAB> if completion.name.startswith(""__""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if completion.parent() and completion.full_name: <TAB>  <TAB>  <TAB> parent_name = completion.parent().name <TAB>  <TAB>  <TAB> name = completion.name <TAB>  <TAB>  <TAB> root = completion.full_name.split(""."")[0] <TAB>  <TAB>  <TAB> # jedi proposes names from CPython builtins <TAB>  <TAB>  <TAB> if root in self._builtins_info and name not in self._builtins_info[root]: <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> result.append({""name"": completion.name, ""complete"": completion.complete}) <TAB> return result","if parent_name == ""builtins"" and name not in self . _builtins_info :",199
"def _RequireClassAttrs(obj, attrs): <TAB> for attr in attrs: <TAB>  <TAB> attr_name = attr.upper() <MASK> msg = ""No %s specified for object of class %s."" % ( <TAB>  <TAB>  <TAB>  <TAB> attr_name, <TAB>  <TAB>  <TAB>  <TAB> type(obj).__name__, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> raise exceptions.GeneratedClientError(msg)","if not hasattr ( obj , ""%s"" % attr_name ) or not getattr ( obj , attr_name ) :",114
"def set_owner_process(uid, gid, initgroups=False): <TAB> """"""set user and group of workers processes"""""" <TAB> if gid: <TAB>  <TAB> if uid: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> username = get_username(uid) <TAB>  <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB>  <TAB> initgroups = False <TAB>  <TAB> # versions of python < 2.6.2 don't manage unsigned int for <TAB>  <TAB> # groups like on osx or fedora <TAB>  <TAB> gid = abs(gid) & 0x7FFFFFFF <MASK> os.initgroups(username, gid) <TAB>  <TAB> elif gid != os.getgid(): <TAB>  <TAB>  <TAB> os.setgid(gid) <TAB> if uid: <TAB>  <TAB> os.setuid(uid)",if initgroups :,176
"def optimize(self, graph: Graph) -> Tuple[Graph, bool]: <TAB> flag_changed = False <TAB> for op in traverse.filter_nodes(traverse.listup_operators(graph), Tensordot): <MASK> op.attributes.add(UseEigenAttribute()) <TAB>  <TAB>  <TAB> flag_changed = True <TAB>  <TAB>  <TAB> graph.licenses[""eigen""] = EIGEN_LICENSE <TAB> return graph, flag_changed",if not op . has_attribute ( UseEigenAttribute ) :,113
"def keyPressEvent(self, event): <TAB> QtWidgets.QTextEdit.keyPressEvent(self, event) <TAB> if event.key() == QtCore.Qt.Key_Space: <MASK> if ( <TAB>  <TAB>  <TAB>  <TAB> self.at_end <TAB>  <TAB>  <TAB> ):  # This makes sure the last lines of the chapter don't get skipped <TAB>  <TAB>  <TAB>  <TAB> self.common_functions.change_chapter(1, True) <TAB>  <TAB>  <TAB> self.at_end = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.at_end = False <TAB>  <TAB>  <TAB> self.set_top_line_cleanly() <TAB> self.record_position()",if self . verticalScrollBar ( ) . value ( ) == self . verticalScrollBar ( ) . maximum ( ) :,171
"def unpack(cls, attribute_id, flag, data, negotiated): <TAB> cache = cls.caching and cls.CACHING <TAB> if cache and data in cls.cache.get(cls.ID, {}): <TAB>  <TAB> return cls.cache[cls.ID].retrieve(data) <TAB> key = (attribute_id, flag | Attribute.Flag.EXTENDED_LENGTH) <TAB> if key in Attribute.registered_attributes.keys(): <TAB>  <TAB> instance = cls.klass(attribute_id, flag).unpack(data, negotiated) <MASK> cls.cache[cls.ID].cache(data, instance) <TAB>  <TAB> return instance <TAB> raise Notify(2, 4, ""can not handle attribute id %s"" % attribute_id)",if cache :,172
"def update_latlongs(geo_resolutions, values_wanted, latlongs): <TAB> """"""Add in values to the geo_resolutions section of the JSON from the latlongs"""""" <TAB> trait = [x for x in geo_resolutions if x[""key""] == SAMPLING_TRAIT][0] <TAB> for x in values_wanted: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> trait[""demes""][x] = latlongs[x] <TAB>  <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB>  <TAB> print( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""WARNING: The lat/long value for {} -> {} is missing from the lat/longs TSV. Please add it!"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> SAMPLING_TRAIT, x <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> )","if x not in trait [ ""demes"" ] . keys ( ) :",189
"def remove_duplicate_configs(config_history, task_id): <TAB> unique_configs = [] <TAB> configs_so_far = set() <TAB> for i in range(len(config_history)): <TAB>  <TAB> key = str(i + task_id) <TAB>  <TAB> config = config_history[key] <TAB>  <TAB> _config = _to_tuple(config) <MASK> unique_configs.append(config) <TAB>  <TAB>  <TAB> configs_so_far.add(_config) <TAB> return unique_configs",if _config not in configs_so_far :,129
"def scraped_rel_links(self): <TAB> for regex in (self._homepage_re, self._download_re): <TAB>  <TAB> match = regex.search(self.content) <TAB>  <TAB> if not match: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> href_match = self._href_re.search(self.content, pos=match.end()) <MASK> continue <TAB>  <TAB> url = match.group(1) or match.group(2) or match.group(3) <TAB>  <TAB> if not url: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> url = self.clean_link(urlparse.urljoin(self.base_url, url)) <TAB>  <TAB> yield Link(url, self)",if not href_match :,163
"def _purge_networks(self, container, networks): <TAB> for network in networks: <TAB>  <TAB> self.results[""actions""].append(dict(removed_from_network=network[""name""])) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> self.client.disconnect_container_from_network( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> container.Id, network[""name""] <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> except Exception as exc: <TAB>  <TAB>  <TAB>  <TAB> self.fail( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Error disconnecting container from network %s - %s"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> % (network[""name""], str(exc)) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return self._get_container(container.Id)",if not self . check_mode :,168
"def copy_remote_dir(self, source, destination, dir_mode=None, owner=None): <TAB> if owner is None: <TAB>  <TAB> owner = self.DEFAULT_USER <TAB> if dir_mode is None: <TAB>  <TAB> dir_mode = self.getDefaultDirPerms() <TAB> self.do_as_user(owner, self.mkdir, destination, mode=dir_mode) <TAB> for stat in self.listdir_stats(source): <TAB>  <TAB> source_file = stat.path <TAB>  <TAB> destination_file = posixpath.join(destination, stat.name) <MASK> self.copy_remote_dir(source_file, destination_file, dir_mode, owner) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.do_as_user(owner, self.copyfile, source_file, destination_file)",if stat . isDir :,195
"def n_listcomp(self, node): <TAB> self.write(""["") <TAB> if node[0].kind == ""load_closure"": <TAB>  <TAB> assert self.version >= 3.0 <TAB>  <TAB> self.listcomp_closure3(node) <TAB> else: <MASK> list_iter_index = 5 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> list_iter_index = 1 <TAB>  <TAB> self.comprehension_walk_newer(node, list_iter_index, 0) <TAB> self.write(""]"") <TAB> self.prune()","if node == ""listcomp_async"" :",128
"def main(argv): <TAB> # module name -> list of paths to include <TAB> c_module_srcs = {} <TAB> for c_path in glob.glob(""Modules/*.c"") + glob.glob(""Modules/_io/*.c""): <TAB>  <TAB> m = PURE_C_RE.match(c_path) <TAB>  <TAB> if m: <TAB>  <TAB>  <TAB> print(m.group(1), c_path) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> m = HELPER_C_RE.match(c_path) <TAB>  <TAB> if m: <TAB>  <TAB>  <TAB> name = m.group(1) <TAB>  <TAB>  <TAB> # Special case: <MASK> name = ""_hashlib"" <TAB>  <TAB>  <TAB> print(name, c_path)","if name == ""_hashopenssl"" :",176
"def test_shuffle(self): <TAB> case = [(0, True), (1, True), (10, False), (100, False)] <TAB> a = reader_creator_10(0) <TAB> for size, checkEq in case: <TAB>  <TAB> s = paddle.reader.shuffle(a, size) <TAB>  <TAB> total = 0 <TAB>  <TAB> for idx, e in enumerate(s()): <MASK> self.assertEqual(idx, e) <TAB>  <TAB>  <TAB> total += 1 <TAB>  <TAB> self.assertEqual(total, 10)",if checkEq :,128
"def _real_find(obj): <TAB> if obj is None or isinstance(obj, str): <TAB>  <TAB> return <TAB> if type(obj) is list: <TAB>  <TAB> for elem in obj: <TAB>  <TAB>  <TAB> _real_find(elem) <TAB> if type(obj) is dict: <MASK> entries.append(obj) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> if ""continuationCommand"" in obj: <TAB>  <TAB>  <TAB> c[""continuation""] = obj <TAB>  <TAB>  <TAB> return <TAB>  <TAB> for _, o in obj.items(): <TAB>  <TAB>  <TAB> _real_find(o)",if self . _is_entry ( obj ) :,140
"def _get_items_from_list(items): <TAB> new_items = [] <TAB> for v in items: <TAB>  <TAB> value = v <TAB>  <TAB> if isinstance(v, dict): <TAB>  <TAB>  <TAB> value = _get_items_from_dict(v) <MASK> value = _get_items_from_list(v) <TAB>  <TAB> elif not isinstance(v, (DBRef, Document)): <TAB>  <TAB>  <TAB> value = field.to_python(v) <TAB>  <TAB> new_items.append(value) <TAB> return new_items","elif isinstance ( v , list ) :",133
def subscribing(self): <TAB> while 1: <TAB>  <TAB> response = self.connection.read_response() <MASK> yield OutputRender.render_raw(response) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield OutputRender.render_subscribe(response),if config . raw :,66
"def eval_on_data(X_train, y_train, X_test, y_test, svm, Cs): <TAB> # evaluate a single svm using varying C <TAB> accuracies, times = [], [] <TAB> for C in Cs: <TAB>  <TAB> svm.C = C <TAB>  <TAB> start = clock() <TAB>  <TAB> svm.fit(X_train, y_train) <MASK> times.append(svm.runtime_) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> times.append(clock() - start) <TAB>  <TAB> accuracies.append(accuracy_score(y_test, svm.predict(X_test))) <TAB> return accuracies, times","if hasattr ( svm , ""runtime_"" ) :",158
"def _coerce_select_files_list(data, guildfile): <TAB> assert isinstance(data, list), data <TAB> all_strings = True <TAB> items = [] <TAB> for item in data: <TAB>  <TAB> if isinstance(item, six.string_types): <TAB>  <TAB>  <TAB> items.append({""include"": item}) <MASK> items.append(item) <TAB>  <TAB>  <TAB> all_strings = False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise GuildfileError( <TAB>  <TAB>  <TAB>  <TAB> guildfile, ""invalid sourcecode %r: expected a string or mapping"" % item <TAB>  <TAB>  <TAB> ) <TAB> if all_strings: <TAB>  <TAB> items.insert(0, {""exclude"": ""*""}) <TAB> return items","elif isinstance ( item , dict ) :",170
"def get_scroll_text(): <TAB> info = buffer_window.render_info <TAB> if info: <MASK> return ""All"" <TAB>  <TAB> elif info.top_visible: <TAB>  <TAB>  <TAB> return ""Top"" <TAB>  <TAB> elif info.bottom_visible: <TAB>  <TAB>  <TAB> return ""Bot"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> percentage = info.vertical_scroll_percentage <TAB>  <TAB>  <TAB> return ""%2i%%"" % percentage <TAB> return """"",if info . full_height_visible :,114
"def _set_name(self, name): <TAB> # Rename the table in the database and in any Database.relations. <TAB> # SQLite and MySQL will automatically copy indices on the new table. <TAB> self.db.execute(""alter table `%s` rename to `%s`;"" % (self._name, name)) <TAB> self.db.tables.pop(self._name) <TAB> self.db.tables[name] = self <TAB> for i, r in enumerate(self.db.relations): <TAB>  <TAB> if r[0] == self._name: <TAB>  <TAB>  <TAB> self.db.relations = (name, r[1], r[2], r[3]) <MASK> self.db.relations = (r[0], r[1], name, r[3]) <TAB> self._name = name",if r [ 2 ] == self . name :,193
"def reflow(text, maxline, shift=""""):  # type: (Text, int, Text) -> Text <TAB> if maxline < 20: <TAB>  <TAB> maxline = 20 <TAB> if len(text) > maxline: <TAB>  <TAB> sp = text.rfind("" "", 0, maxline) <TAB>  <TAB> if sp < 1: <TAB>  <TAB>  <TAB> sp = text.find("" "", sp + 1) <TAB>  <TAB>  <TAB> if sp == -1: <TAB>  <TAB>  <TAB>  <TAB> sp = len(text) <MASK> return ""%s\n%s%s"" % ( <TAB>  <TAB>  <TAB>  <TAB> text[0:sp], <TAB>  <TAB>  <TAB>  <TAB> shift, <TAB>  <TAB>  <TAB>  <TAB> reflow(text[sp + 1 :], maxline, shift), <TAB>  <TAB>  <TAB> ) <TAB> return text",if sp < len ( text ) :,182
"def send(sock, data): <TAB> if isinstance(data, six.text_type): <TAB>  <TAB> data = data.encode(""utf-8"") <TAB> if not sock: <TAB>  <TAB> raise WebSocketConnectionClosedException(""socket is already closed."") <TAB> try: <TAB>  <TAB> return sock.send(data) <TAB> except socket.timeout as e: <TAB>  <TAB> message = extract_err_message(e) <TAB>  <TAB> raise WebSocketTimeoutException(message) <TAB> except Exception as e: <TAB>  <TAB> message = extract_err_message(e) <MASK> raise WebSocketTimeoutException(message) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise","if isinstance ( message , str ) and ""timed out"" in message :",163
"def check_folder_read_permissions(request, folders): <TAB> for f in folders: <MASK> raise PermissionDenied <TAB>  <TAB> check_files_read_permissions(request, f.files) <TAB>  <TAB> check_folder_read_permissions(request, f.children.all())",if not f . has_read_permission ( request ) :,78
"def callback_for_bottom_app_bar(self, app, text, value): <TAB> if value and app.data_screens[""Bottom App Bar""][""object""]: <TAB>  <TAB> toolbar = self.ids.bottom_toolbar <TAB>  <TAB> if text == ""Off"": <TAB>  <TAB>  <TAB> toolbar.remove_notch() <TAB>  <TAB> elif text == ""On"": <TAB>  <TAB>  <TAB> toolbar.set_notch() <TAB>  <TAB> elif text == ""Attached - End"": <TAB>  <TAB>  <TAB> toolbar.mode = ""end"" <TAB>  <TAB> elif text == ""Attached - Center"": <TAB>  <TAB>  <TAB> toolbar.mode = ""center"" <MASK> toolbar.mode = ""free-end"" <TAB>  <TAB> elif text == ""Free - Center"": <TAB>  <TAB>  <TAB> toolbar.mode = ""free-center""","elif text == ""Free - End"" :",184
"def _check_arg_dir_exists(self, arg_name, dirs): <TAB> for path in dirs: <MASK> print( <TAB>  <TAB>  <TAB>  <TAB> 'error: Failed to find the directory ""{}"" specified in ' <TAB>  <TAB>  <TAB>  <TAB> '""{}""'.format(path, arg_name), <TAB>  <TAB>  <TAB>  <TAB> file=sys.stderr, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> sys.exit(1) <TAB>  <TAB> if not os.path.isdir(path): <TAB>  <TAB>  <TAB> print( <TAB>  <TAB>  <TAB>  <TAB> 'error: Path ""{}"" specified in {} is not a directory'.format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> path, arg_name <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB>  <TAB> file=sys.stderr, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> sys.exit(1)",if not os . path . exists ( path ) :,186
"def _check_tag_list(self, tags, expected_tags): <TAB> self.assertEqual(len(tags), len(expected_tags)) <TAB> actual_tags = [] <TAB> for tag in tags: <MASK> tag = ""%s:%s"" % (tag.user_tname, tag.user_value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tag = tag.user_tname <TAB>  <TAB> actual_tags.append(tag) <TAB> expected = [unicodify(e) for e in expected_tags] <TAB> assert sorted(expected) == sorted(actual_tags), ""%s vs %s"" % (expected, actual_tags)",if tag . user_value :,156
def _attrs(self): <TAB> if self._attrs_cache is None: <TAB>  <TAB> for mountpoint in self._iter_mountpoints(): <MASK> self._attrs_cache = mountpoint <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._attrs_cache = {} <TAB> return self._attrs_cache,"if mountpoint [ ""path"" ] == self . path :",90
"def get_core_modules_paths_with_tests(profile): <TAB> if profile == ""latest"": <TAB>  <TAB> for name, path in get_core_modules_paths(): <TAB>  <TAB>  <TAB> for root, dirs, files in os.walk(path): <MASK> if name == ""azure-cli-core"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> name = ""core"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield name, path, root","if os . path . basename ( root ) == ""tests"" :",116
"def itemOver(self, item): <TAB> if item is None: <TAB>  <TAB> if self.selectedItem is not None: <TAB>  <TAB>  <TAB> if self.selectedItem.getSubMenu() != None: <MASK> return <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.selectItem(item) <TAB>  <TAB>  <TAB>  <TAB> return <TAB> self.selectItem(item) <TAB> if item is not None: <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB> (self.shownChildMenu is not None) <TAB>  <TAB>  <TAB> or (self.parentMenu is not None) <TAB>  <TAB>  <TAB> or self.autoOpen <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> self.doItemAction(item, False)",if self . shownChildMenu == self . selectedItem . getSubMenu ( ) :,174
"def get_settings(self): <TAB> """"""Check for code hilite extension and gather its settings."""""" <TAB> if not self.check_for_toc: <TAB>  <TAB> self.slugify = self.config[""slugify""] <TAB>  <TAB> self.separator = self.config[""separator""] <TAB>  <TAB> self.use_toc_settings = self.config[""use_toc_settings""] <TAB>  <TAB> if self.use_toc_settings: <TAB>  <TAB>  <TAB> for ext in self.markdown.registeredExtensions: <MASK> self.separator = ext.config[""separator""][0] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.slugify = ext.config[""slugify""][0] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> self.check_for_toc = True","if isinstance ( ext , TocExtension ) :",178
"def __init__(self, *args, **kwargs): <TAB> super().__init__(*args, **kwargs) <TAB> # handle WITH_FUTURE_DATES (designate article to draft based on date) <TAB> if not self.settings[""WITH_FUTURE_DATES""] and hasattr(self, ""date""): <MASK> now = datetime.datetime.now() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> now = datetime.datetime.utcnow().replace(tzinfo=pytz.utc) <TAB>  <TAB> if self.date > now: <TAB>  <TAB>  <TAB> self.status = ""draft"" <TAB> # if we are a draft and there is no date provided, set max datetime <TAB> if not hasattr(self, ""date"") and self.status == ""draft"": <TAB>  <TAB> self.date = datetime.datetime.max.replace(tzinfo=self.timezone)",if self . date . tzinfo is None :,193
"def fromstring(self, text, loc_db, parser_result=None): <TAB> if parser_result: <TAB>  <TAB> e, start, stop = parser_result[self.parser] <TAB>  <TAB> if e is None: <TAB>  <TAB>  <TAB> return None, None <TAB>  <TAB> self.expr = e <MASK> return None, None <TAB>  <TAB> return start, stop <TAB> try: <TAB>  <TAB> v, start, stop = next(self.parser.scanString(text)) <TAB> except StopIteration: <TAB>  <TAB> return None, None <TAB> self.expr = v[0] <TAB> if self.expr is None: <TAB>  <TAB> log.debug(""cannot fromstring int %r"", text) <TAB>  <TAB> return None, None <TAB> return start, stop",if self . expr is None :,174
"def read_version_py(file_name): <TAB> try: <TAB>  <TAB> version_string_line = open(file_name, ""rt"").read() <TAB> except EnvironmentError: <TAB>  <TAB> return None <TAB> else: <TAB>  <TAB> version_regex = r""^version_str = ['\""]([^'\""]*)['\""]"" <TAB>  <TAB> mo = re.search(version_regex, version_string_line, re.M) <MASK> return mo.group(1)",if mo :,113
"def __truediv__(self, other): <TAB> if self._check(other): <MASK> return self.__class__(self._units / other._units) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> qself = 1.0 * self <TAB>  <TAB>  <TAB> return qself / other <TAB> return self._REGISTRY.Quantity(1 / other, self._units)","if isinstance ( other , self . __class__ ) :",90
"def get_facet_fieldname(self, field): <TAB> if not self._built: <TAB>  <TAB> self.build() <TAB> for fieldname, field_object in self.fields.items(): <TAB>  <TAB> if fieldname != field: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if hasattr(field_object, ""facet_for""): <MASK> return field_object.facet_for <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return field_object.instance_name <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self._facet_fieldnames.get(field) or field <TAB> return field",if field_object . facet_for :,142
"def emit_by_classname(self, classname): <TAB> for i in self.patterns: <TAB>  <TAB> if self.patterns[i][0] == 0: <MASK> self.tags.add(i)",if self . patterns [ i ] [ 1 ] . search ( classname ) is not None :,70
"def handleNotification(self, note): <TAB> try: <TAB>  <TAB> noteName = note.getName() <TAB>  <TAB> nodeBody = note.getBody() <TAB>  <TAB> if noteName == Notification.CELL_SELECTED: <TAB>  <TAB>  <TAB> alert(""Select cell is not implemented yet"") <MASK> alert(""Cell changed is not implemented yet"") <TAB>  <TAB> elif noteName == Notification.DATE_SELECTED: <TAB>  <TAB>  <TAB> self.onDateSelected(nodeBody) <TAB>  <TAB> elif noteName == Notification.EDIT_SELECTED: <TAB>  <TAB>  <TAB> self.onEditSelected() <TAB>  <TAB> elif noteName == Notification.SUM_SELECTED: <TAB>  <TAB>  <TAB> self.onSumSelected() <TAB>  <TAB> elif noteName == Notification.FILE_LOADED: <TAB>  <TAB>  <TAB> self.onFileLoaded(*nodeBody) <TAB> except: <TAB>  <TAB> raise",elif noteName == Notification . CELL_UPDATED :,195
"def data(self, column): <TAB> if column == 0: <TAB>  <TAB> return self.name <TAB> elif column == 1: <TAB>  <TAB> return self.tinfo.get_pointed_object().dstr() <TAB> elif column == 2: <TAB>  <TAB> addresses = self.addresses <MASK> return ""LIST"" <TAB>  <TAB> elif len(addresses) == 1: <TAB>  <TAB>  <TAB> return helper.to_hex(addresses[0])",if len ( addresses ) > 1 :,108
"def combineTerms(self, termA, op, termB): <TAB> if op in ("","", "" ""): <MASK> termA.append(termB) <TAB>  <TAB>  <TAB> return termA <TAB>  <TAB> return [termA, termB] <TAB> elif op is None and termB is None: <TAB>  <TAB> return [termA] <TAB> else: <TAB>  <TAB> if isinstance(termA, list): <TAB>  <TAB>  <TAB> # Bind these ""closer"" than the list operators -- i.e. work on <TAB>  <TAB>  <TAB> # the (recursively) last element of the list <TAB>  <TAB>  <TAB> termA[-1] = self.combineTerms(termA[-1], op, termB) <TAB>  <TAB>  <TAB> return termA <TAB>  <TAB> return self.TermOperatorFactory(termA, op, termB)","if isinstance ( termA , list ) :",189
"def zipfolder(foldername, target_dir): <TAB> zipobj = zipfile.ZipFile(foldername + "".zip"", ""w"", zipfile.ZIP_DEFLATED) <TAB> rootlen = len(target_dir) + 1 <TAB> for base, dirs, files in os.walk(target_dir): <TAB>  <TAB> files_list = [] <TAB>  <TAB> for f in files: <TAB>  <TAB>  <TAB> for ex in file_excludes: <TAB>  <TAB>  <TAB>  <TAB> if ex in f: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> files_list.append(f) <TAB>  <TAB> for file in files_list: <MASK> fn = os.path.join(base, file) <TAB>  <TAB>  <TAB>  <TAB> zipobj.write(fn, fn[rootlen:])","if ""sverchok"" in base and ""__pycache__"" not in base and ""kdev4"" not in base :",196
"def _parsePluginSequence(self, attr, proptext, iface): <TAB> lines = proptext.split() <TAB> for line in lines: <TAB>  <TAB> if "";"" in line: <TAB>  <TAB>  <TAB> plugin_name, classifier = line.split("";"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> plugin_name = line <TAB>  <TAB>  <TAB> classifier = None <TAB>  <TAB> plugin = self._getPlugin(plugin_name, iface) <TAB>  <TAB> if classifier is not None: <TAB>  <TAB>  <TAB> classifications = getattr(plugin, ""classifications"", None) <MASK> classifications = plugin.classifications = {} <TAB>  <TAB>  <TAB> classifications[iface] = classifier <TAB>  <TAB> attr.append((plugin_name, plugin))",if classifications is None :,167
"def calculate(self): <TAB> linux_common.set_plugin_members(self) <TAB> tasks = linux_pslist.linux_pslist(self._config).calculate() <TAB> for task in tasks: <TAB>  <TAB> proc_as = task.get_process_address_space() <TAB>  <TAB> # In cases when mm is an invalid pointer <TAB>  <TAB> if not proc_as: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # Do we scan everything or just /bin/bash instances? <MASK> continue <TAB>  <TAB> for ent in task.bash_hash_entries(): <TAB>  <TAB>  <TAB> yield task, ent","if not ( self . _config . SCAN_ALL or str ( task . comm ) == ""bash"" ) :",157
"def check_config() -> None: <TAB> for (setting_name, default) in settings.REQUIRED_SETTINGS: <TAB>  <TAB> # if required setting is the same as default OR is not found in settings, <TAB>  <TAB> # throw error to add/set that setting in config <TAB>  <TAB> try: <MASK> continue <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> raise CommandError( <TAB>  <TAB>  <TAB> f""Error: You must set {setting_name} in /etc/zulip/settings.py."" <TAB>  <TAB> )",if settings . __getattr__ ( setting_name ) != default :,135
"def build(opt): <TAB> dpath = os.path.join(opt[""datapath""], ""dialog-bAbI"") <TAB> version = None <TAB> if not build_data.built(dpath, version_string=version): <TAB>  <TAB> print(""[building data: "" + dpath + ""]"") <MASK> # An older version exists, so remove these outdated files. <TAB>  <TAB>  <TAB> build_data.remove_dir(dpath) <TAB>  <TAB> build_data.make_dir(dpath) <TAB>  <TAB> # Download the data. <TAB>  <TAB> for downloadable_file in RESOURCES: <TAB>  <TAB>  <TAB> downloadable_file.download_file(dpath) <TAB>  <TAB> # Mark the data as built. <TAB>  <TAB> build_data.mark_done(dpath, version_string=version)",if build_data . built ( dpath ) :,184
"def get(self, key): <TAB> key = self.add_prefix(key) <MASK> value = self._cache.get(key) <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB> self.autofill() <TAB>  <TAB>  <TAB> value = self._cache.get(key) <TAB> else: <TAB>  <TAB> value = None <TAB> if value is None: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> value = self._model._default_manager.get(key=key).value <TAB>  <TAB> except (OperationalError, ProgrammingError, self._model.DoesNotExist): <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if self._cache: <TAB>  <TAB>  <TAB>  <TAB> self._cache.add(key, value) <TAB> return value",if self . _cache :,166
"def build_dimension_param(self, dimension, params): <TAB> prefix = ""Dimensions.member"" <TAB> i = 0 <TAB> for dim_name in dimension: <TAB>  <TAB> dim_value = dimension[dim_name] <MASK> if isinstance(dim_value, basestring): <TAB>  <TAB>  <TAB>  <TAB> dim_value = [dim_value] <TAB>  <TAB>  <TAB> for value in dim_value: <TAB>  <TAB>  <TAB>  <TAB> params[""%s.%d.Name"" % (prefix, i + 1)] = dim_name <TAB>  <TAB>  <TAB>  <TAB> params[""%s.%d.Value"" % (prefix, i + 1)] = value <TAB>  <TAB>  <TAB>  <TAB> i += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> params[""%s.%d.Name"" % (prefix, i + 1)] = dim_name <TAB>  <TAB>  <TAB> i += 1",if dim_value :,188
"def expand_caller_kinds( <TAB> kinds_or_names: List[Union[int, str]]) -> Tuple[List[int], List[Optional[str]]]: <TAB> kinds = [] <TAB> names = []  # type: List[Optional[str]] <TAB> for k in kinds_or_names: <MASK> kinds.append(ARG_NAMED) <TAB>  <TAB>  <TAB> names.append(k) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> kinds.append(k) <TAB>  <TAB>  <TAB> names.append(None) <TAB> return kinds, names","if isinstance ( k , str ) :",132
"def on_train_end(self, **kwargs): <TAB> ""Load the best model."" <TAB> if self.save_model: <TAB>  <TAB> # Adapted from fast.ai ""SaveModelCallback"" <MASK> with self.model_path.open(""rb"") as model_file: <TAB>  <TAB>  <TAB>  <TAB> self.learn.load(model_file, purge=False) <TAB>  <TAB>  <TAB>  <TAB> print(""Loaded best saved model from {}"".format(self.model_path))",if self . model_path . is_file ( ) :,118
"def _stack_shape_func(data_shape, axis, num_inputs): <TAB> out = output_tensor((data_shape.shape[0] + 1,), ""int64"") <TAB> for i in const_range(data_shape.shape[0] + 1): <MASK> out[i] = int64(num_inputs) <TAB>  <TAB> elif i < axis: <TAB>  <TAB>  <TAB> out[i] = data_shape[i] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> out[i] = data_shape[i - 1] <TAB> return out",if i == axis :,135
"def fill_params_dict(p_dict, parameters, par): <TAB> """"""redistribute parameters"""""" <TAB> for x in PARAMS_GROUPS: <MASK> p_dict[x] = [par[p] for p in PARAMS_GROUPS[x]] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> p_dict[x] = par[PARAMS_GROUPS[x]] <TAB> p_dict[""apply_f""] = True",if type ( PARAMS_GROUPS [ x ] ) == tuple :,110
"def debug_string( <TAB> self, <TAB> nodes: List[NodeID], <TAB> pending_nodes: Dict[NodeID, int], <TAB> unused_resources_by_ip: Dict[str, ResourceDict],) -> str: <TAB> node_resources, node_type_counts = self.calculate_node_resources( <TAB>  <TAB> nodes, pending_nodes, unused_resources_by_ip <TAB> ) <TAB> out = ""Worker node types:"" <TAB> for node_type, count in node_type_counts.items(): <TAB>  <TAB> out += ""\n - {}: {}"".format(node_type, count) <MASK> out += "" ({} pending)"".format(pending_nodes[node_type]) <TAB> return out",if pending_nodes . get ( node_type ) :,174
"def __ixor__(self, it): <TAB> if it is self: <TAB>  <TAB> self.clear() <TAB> else: <TAB>  <TAB> if not isinstance(it, Set): <TAB>  <TAB>  <TAB> it = self._from_iterable(it) <TAB>  <TAB> for value in it: <MASK> self.discard(value) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.add(value) <TAB> return self",if value in self :,102
"def __eq__(self, other): <TAB> """"""Approximate numerical equality."""""" <TAB> if not isinstance(other, type(self)): <TAB>  <TAB> return NotImplemented <TAB> for term in self.terms.keys() | other.terms.keys(): <TAB>  <TAB> if term in self.terms and term in other.terms: <MASK> return False <TAB>  <TAB> elif term in self.terms: <TAB>  <TAB>  <TAB> if not numpy.isclose(self.terms[term], 0.0): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if not numpy.isclose(other.terms[term], 0.0): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return True","if not numpy . isclose ( self . terms [ term ] , other . terms [ term ] ) :",169
"def test_abs_converge(self): <TAB> loss = 50 <TAB> eps = 0.00001 <TAB> # converge_func = AbsConverge(eps=eps) <TAB> converge_func = converge_func_factory(early_stop=""abs"", tol=eps) <TAB> iter_num = 0 <TAB> while iter_num < 500: <TAB>  <TAB> loss *= 0.5 <TAB>  <TAB> converge_flag = converge_func.is_converge(loss) <MASK> break <TAB>  <TAB> iter_num += 1 <TAB> self.assertTrue(math.fabs(loss) <= eps)",if converge_flag :,145
def process_words(): <TAB> word_freqs = {} <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> word = word_space.get(timeout=1) <TAB>  <TAB> except Queue.Empty: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if not word in stopwords: <MASK> word_freqs[word] += 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> word_freqs[word] = 1 <TAB> freq_space.put(word_freqs),if word in word_freqs :,116
"def _create_transformations(all_tokens, seen_ts): <TAB> """"""Create the objects that need to know about tabstops."""""" <TAB> for parent, token in all_tokens: <MASK> if token.number not in seen_ts: <TAB>  <TAB>  <TAB>  <TAB> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Tabstop %i is not known but is used by a Transformation"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> % token.number <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> Transformation(parent, seen_ts[token.number], token)","if isinstance ( token , TransformationToken ) :",131
"def set_emails(self, create, extracted): <TAB> if not self.emails.filter(address=self.username).exists(): <MASK> if create: <TAB>  <TAB>  <TAB>  <TAB> # Perform implicit save to populate M2M <TAB>  <TAB>  <TAB>  <TAB> self.save(clean=False) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> # This might lead to strange behavior <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> self.emails.create(address=str(self.username).lower())",if not self . id :,116
"def main(): <TAB> global current <TAB> global current_file <TAB> for subdir, dirs, files in os.walk(""./praw""): <TAB>  <TAB> for file in files: <TAB>  <TAB>  <TAB> file_path = os.path.join(subdir, file) <TAB>  <TAB>  <TAB> if file_path.endswith("".py""): <TAB>  <TAB>  <TAB>  <TAB> file_ast = get_ast(file_path) <TAB>  <TAB>  <TAB>  <TAB> current_file = file_path <TAB>  <TAB>  <TAB>  <TAB> for docstring, item in get_docstrings(file_ast): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> current = item <MASK> doc = parse_rst(docstring) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> visitor = Visitor(doc) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> doc.walk(visitor)",if docstring :,177
"def _execute(self, *query): <TAB> """"""Execute a query, waiting to acquire a lock if necessary"""""" <TAB> count = 0 <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self.cursor.execute(*query) <TAB>  <TAB> except sqlite3.OperationalError as exc: <MASK> count = count + 1 <TAB>  <TAB>  <TAB>  <TAB> self.cursor.close() <TAB>  <TAB>  <TAB>  <TAB> self.cursor = connect(self.cachefile) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> raise","if ""database is locked"" in str ( exc ) and count < 500 :",132
"def _check_linux_filesystem(self) -> bool: <TAB> filesystem_type = """" <TAB> for part in disk_partitions(True): <TAB>  <TAB> if part.mountpoint == ""/"": <TAB>  <TAB>  <TAB> filesystem_type = part.fstype <TAB>  <TAB>  <TAB> continue <MASK> filesystem_type = part.fstype <TAB>  <TAB>  <TAB> break <TAB> filesystem_type = filesystem_type.lower() <TAB> is_linux = not any(fs in filesystem_type for fs in self.windows_fs) <TAB> log.info(f""Target filesystem {self._root_str} is {filesystem_type}"") <TAB> return is_linux",if self . _root_str . startswith ( part . mountpoint . lower ( ) ) :,159
"def _loadPreferences(self): <TAB> filenames = os.listdir(self.prefdir) <TAB> for filename in filenames: <MASK> key = self.file2key[filename] <TAB>  <TAB>  <TAB> filepath = os.path.join(self.prefdir, filename) <TAB>  <TAB>  <TAB> if os.path.isfile(filepath): <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> data = file(filepath, ""rb"").read() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.prefs[key] = data <TAB>  <TAB>  <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass",if filename in self . file2key :,139
def _transmit_from_storage(self): <TAB> for blob in self.storage.gets(): <TAB>  <TAB> # give a few more seconds for blob lease operation <TAB>  <TAB> # to reduce the chance of race (for perf consideration) <TAB>  <TAB> if blob.lease(self.options.timeout + 5): <TAB>  <TAB>  <TAB> envelopes = blob.get() <TAB>  <TAB>  <TAB> result = self._transmit(envelopes) <MASK> blob.lease(result) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> blob.delete(),if result > 0 :,128
"def process_set(hive, hive_name, key, flags, default_arch): <TAB> try: <TAB>  <TAB> with winreg.OpenKeyEx(hive, key, 0, winreg.KEY_READ | flags) as root_key: <TAB>  <TAB>  <TAB> for company in enum_keys(root_key): <MASK> # reserved <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB>  <TAB> for spec in process_company(hive_name, company, root_key, default_arch): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield spec <TAB> except OSError: <TAB>  <TAB> pass","if company == ""PyLauncher"" :",133
"def plugin_notification(instance, **kwargs): <TAB> if notification_dict.get(""ignore"", lambda x: False)(instance): <TAB>  <TAB> return <TAB> if kwargs.get(""created"", False) == notification_dict.get(""created"", True): <TAB>  <TAB> url = None <MASK> url = notification_dict[""get_url""](instance) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> url = default_url(notification_dict[""get_article""](instance)) <TAB>  <TAB> message = notification_dict[""message""](instance) <TAB>  <TAB> notify( <TAB>  <TAB>  <TAB> message, <TAB>  <TAB>  <TAB> notification_dict[""key""], <TAB>  <TAB>  <TAB> target_object=notification_dict[""get_article""](instance), <TAB>  <TAB>  <TAB> url=url, <TAB>  <TAB> )","if ""get_url"" in notification_dict :",180
"def execsitecustomize(): <TAB> """"""Run custom site specific code, if available."""""" <TAB> try: <TAB>  <TAB> import sitecustomize <TAB> except ImportError: <TAB>  <TAB> pass <TAB> except Exception as err: <MASK> sys.excepthook(*sys.exc_info()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sys.stderr.write( <TAB>  <TAB>  <TAB>  <TAB> ""Error in sitecustomize; set PYTHONVERBOSE for traceback:\n"" <TAB>  <TAB>  <TAB>  <TAB> ""%s: %s\n"" % (err.__class__.__name__, err) <TAB>  <TAB>  <TAB> )","if os . environ . get ( ""PYTHONVERBOSE"" ) :",141
"def monitor(self, response, **kwargs): <TAB> mon = monitor_workflow if response.type == ""workflow_job"" else monitor <TAB> if kwargs.get(""monitor"") or kwargs.get(""wait""): <TAB>  <TAB> status = mon( <TAB>  <TAB>  <TAB> response, <TAB>  <TAB>  <TAB> self.page.connection.session, <TAB>  <TAB>  <TAB> print_stdout=not kwargs.get(""wait""), <TAB>  <TAB>  <TAB> timeout=kwargs.get(""timeout""), <TAB>  <TAB> ) <MASK> response.json[""status""] = status <TAB>  <TAB>  <TAB> if status in (""failed"", ""error""): <TAB>  <TAB>  <TAB>  <TAB> setattr(response, ""rc"", 1) <TAB> return response",if status :,151
"def collect(self, top, sup, argv=None, parent=""""): <TAB> try: <TAB>  <TAB> (_namespace, typ) = _namespace_and_tag(self, self.ref, top) <TAB>  <TAB> # TODO: use definitions in other XSD <TAB>  <TAB> cti = get_type_def(typ, top.parts) <TAB>  <TAB> return cti.collect(top, sup) <TAB> except AttributeError: <MASK> return self._own, self._inherited <TAB>  <TAB> argv_copy = sd_copy(argv) <TAB>  <TAB> for prop in self.parts: <TAB>  <TAB>  <TAB> if isinstance(prop, Attribute): <TAB>  <TAB>  <TAB>  <TAB> self._own.append(prop.repr(top, sup, argv_copy, parent)) <TAB>  <TAB> return self._own, self._inherited",if self . _own or self . _inherited :,186
"def expireat(self, client, request, N, M=1): <TAB> check_input(request, N != 2) <TAB> try: <TAB>  <TAB> timeout = int(request[2]) <TAB> except ValueError: <TAB>  <TAB> client.reply_error(self.INVALID_TIMEOUT) <TAB> else: <MASK> if timeout < 0: <TAB>  <TAB>  <TAB>  <TAB> return client.reply_error(self.INVALID_TIMEOUT) <TAB>  <TAB>  <TAB> timeout = M * timeout - time.time() <TAB>  <TAB>  <TAB> if client.db.expire(request[1], timeout): <TAB>  <TAB>  <TAB>  <TAB> return client.reply_one() <TAB>  <TAB> client.reply_zero()",if timeout :,153
"def _wait_connected(self, timeout): <TAB> for i in range(timeout): <TAB>  <TAB> if self._status == self.CONNECTED: <TAB>  <TAB>  <TAB> return True <MASK> print(""[rpc]waiting for connection...%s"" % i) <TAB>  <TAB>  <TAB> time.sleep(0.5) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise RpcConnectionError(""Rpc Connection Closed"") <TAB> raise RpcConnectionError(""Connecting Timeout"")",elif self . _status == self . CONNECTING :,111
"def column_place(self, data): <TAB> if data[COLUMN_PLACE]: <TAB>  <TAB> cached, value = self.get_cached_value(data[0], ""PLACE"") <MASK> event = Event() <TAB>  <TAB>  <TAB> event.unserialize(data) <TAB>  <TAB>  <TAB> value = place_displayer.display_event(self.db, event) <TAB>  <TAB>  <TAB> self.set_cached_value(data[0], ""PLACE"", value) <TAB>  <TAB> return value <TAB> else: <TAB>  <TAB> return """"",if not cached :,122
"def get_cover_id(olkeys): <TAB> """"""Return the first cover from the list of ol keys."""""" <TAB> for olkey in olkeys: <TAB>  <TAB> doc = ol_get(olkey) <TAB>  <TAB> if not doc: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> is_author = doc[""key""].startswith(""/authors"") <TAB>  <TAB> covers = doc.get(""photos"" if is_author else ""covers"", []) <TAB>  <TAB> # Sometimes covers is stored as [None] or [-1] to indicate no covers. <TAB>  <TAB> # If so, consider there are no covers. <MASK> return covers[0]",if covers and ( covers [ 0 ] or - 1 ) >= 0 :,159
"def _conv_timetz(s, cursor): <TAB> if s: <TAB>  <TAB> from zope.datetime import tzinfo <TAB>  <TAB> hr, mn, sc, tz = parse_timetz(s) <TAB>  <TAB> sc, micro = divmod(sc, 1.0) <TAB>  <TAB> micro = round(micro * 1000000) <MASK> tz = tzinfo(tz) <TAB>  <TAB> return time(hr, mn, int(sc), int(micro), tz)",if tz :,105
"def convert_1d_data(self, meter_image): <TAB> scale_data = np.zeros((LINE_WIDTH), dtype=np.uint8) <TAB> pointer_data = np.zeros((LINE_WIDTH), dtype=np.uint8) <TAB> for col in range(LINE_WIDTH): <TAB>  <TAB> for row in range(LINE_HEIGHT): <MASK> pointer_data[col] += 1 <TAB>  <TAB>  <TAB> elif meter_image[row, col] == 2: <TAB>  <TAB>  <TAB>  <TAB> scale_data[col] += 1 <TAB> return scale_data, pointer_data","if meter_image [ row , col ] == 1 :",151
"def _title(self) -> Optional[Text]: <TAB> if self.title: <TAB>  <TAB> title_text = ( <TAB>  <TAB>  <TAB> Text.from_markup(self.title) <MASK> else self.title.copy() <TAB>  <TAB> ) <TAB>  <TAB> title_text.end = """" <TAB>  <TAB> title_text.plain = title_text.plain.replace(""\n"", "" "") <TAB>  <TAB> title_text.no_wrap = True <TAB>  <TAB> title_text.expand_tabs() <TAB>  <TAB> title_text.pad(1) <TAB>  <TAB> return title_text <TAB> return None","if isinstance ( self . title , str )",145
"def step_verify_separate_output_directories(self): <TAB> print(""Verifying task output directories."") <TAB> task_name: str = self.task_settings_dict.get(""name"") <TAB> output_contents: typing.Iterable[Path] = Path(self.output_path).glob(""*/*"") <TAB> for path in output_contents: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> datetime.strptime( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> path.name.strip(task_name), self.OUTPUT_DIR_TIME_FORMAT <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> self.fail( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f""Output directory: {path.resolve()} does not"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f""match the expected format."" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> self.next()",if path . is_dir ( ) :,193
"def skip_to_close_paren(self): <TAB> tok = self.tokenizer.get_next_token() <TAB> nestedCount = 1 <TAB> while 1: <TAB>  <TAB> ttype = tok[""style""] <MASK> return <TAB>  <TAB> elif self.classifier.is_any_operator(tok): <TAB>  <TAB>  <TAB> tval = tok[""text""] <TAB>  <TAB>  <TAB> if tval == ""("": <TAB>  <TAB>  <TAB>  <TAB> nestedCount += 1 <TAB>  <TAB>  <TAB> elif tval == "")"": <TAB>  <TAB>  <TAB>  <TAB> nestedCount -= 1 <TAB>  <TAB>  <TAB>  <TAB> if nestedCount <= 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> tok = self.tokenizer.get_next_token()",if ttype == SCE_PL_UNUSED :,159
"def extract(self): <TAB> try: <TAB>  <TAB> c = self.db.cursor() <TAB>  <TAB> c.execute(""""""show global status like 'Key_%';"""""") <TAB>  <TAB> lines = c.fetchall() <TAB>  <TAB> for line in lines: <TAB>  <TAB>  <TAB> if len(line[1]) < 2: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if line[0] in self.vars: <TAB>  <TAB>  <TAB>  <TAB> self.set2[line[0]] = float(line[1]) <TAB>  <TAB> for name in self.vars: <TAB>  <TAB>  <TAB> self.val[name] = self.set2[name] * 1.0 / elapsed <MASK> self.set1.update(self.set2) <TAB> except Exception as e: <TAB>  <TAB> for name in self.vars: <TAB>  <TAB>  <TAB> self.val[name] = -1",if step == op . delay :,199
"def get_symbols_in_region(start, end, filter_text=""""): <TAB> symbols = [] <TAB> ptr_size = pwndbg.typeinfo.pvoid.sizeof <TAB> addr = start <TAB> while addr < end: <TAB>  <TAB> name = pwndbg.symbol.get(addr) <MASK> symbols.append((name, addr)) <TAB>  <TAB> addr += ptr_size <TAB> return symbols","if name != """" and ""+"" not in name and filter_text in name :",109
"def generate_book_cover(self): <TAB> cover = None <TAB> try: <TAB>  <TAB> cover_image_xml = self.xml.find(""coverpage"") <TAB>  <TAB> for i in cover_image_xml: <TAB>  <TAB>  <TAB> cover_image_name = i.get(""l:href"") <TAB>  <TAB> cover_image_data = self.xml.find_all(""binary"") <TAB>  <TAB> for i in cover_image_data: <MASK> cover = base64.decodebytes(i.text.encode()) <TAB> except (AttributeError, TypeError): <TAB>  <TAB> # Catch TypeError in case no images exist in the book <TAB>  <TAB> logger.warning(""Cover not found: "" + self.filename) <TAB> return cover","if cover_image_name . endswith ( i . get ( ""id"" ) ) :",179
"def accept(nodeinst, visitor): <TAB> skip = visitor(nodeinst) <TAB> if skip: <TAB>  <TAB> return <TAB> for field in nodeinst.fields: <TAB>  <TAB> value = getattr(nodeinst, field) <MASK> # Add parent <TAB>  <TAB>  <TAB> value._parent_node = nodeinst <TAB>  <TAB>  <TAB> value.accept(visitor) <TAB>  <TAB> elif isinstance(value, list): <TAB>  <TAB>  <TAB> for item in value: <TAB>  <TAB>  <TAB>  <TAB> if isinstance(item, Node): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # Set parent <TAB>  <TAB>  <TAB>  <TAB>  <TAB> item._parent_node = nodeinst <TAB>  <TAB>  <TAB>  <TAB>  <TAB> item.accept(visitor)","if isinstance ( value , Node ) :",151
"def _get_conflicts_by_artifacts(self, artifacts_by_file_name, jar_rules): <TAB> conflicts_by_artifacts = defaultdict(set) <TAB> for (file_name, artifacts) in artifacts_by_file_name.items(): <TAB>  <TAB> if (not artifacts) or len(artifacts) < 2: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if self._is_excluded(file_name): <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> conflicts_by_artifacts[tuple(sorted(str(a) for a in artifacts))].add(file_name) <TAB> return conflicts_by_artifacts","if self . _jar_rule_handled ( file_name , jar_rules ) :",160
"def lift_item(self, context): <TAB> if self.up: <TAB>  <TAB> sock_ind = list(self.inputs).index(context.socket) <MASK> self.inputs.move(sock_ind, sock_ind - 1) <TAB>  <TAB> self.up = False",if sock_ind > 0 :,74
"def test_conversion_reversible(self): <TAB> tokenizers = self.get_tokenizers(do_lower_case=False) <TAB> for tokenizer in tokenizers: <TAB>  <TAB> with self.subTest(f""{tokenizer.__class__.__name__}""): <TAB>  <TAB>  <TAB> vocab = tokenizer.get_vocab() <TAB>  <TAB>  <TAB> for word, ind in vocab.items(): <MASK> continue <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(tokenizer.convert_tokens_to_ids(word), ind) <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(tokenizer.convert_ids_to_tokens(ind), word)",if word == tokenizer . unk_token :,145
"def rotate_vecs_constant_mat(props, mat, output_numpy, np_local_match, result): <TAB> if len(props[1]) > 1: <TAB>  <TAB> rotated = np_rotate_many_centers(props, mat, np_local_match) <TAB>  <TAB> result.append(rotated if output_numpy else rotated.tolist()) <TAB> else: <MASK> result.append(np_rotate_one_center(props, mat)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result.append(rotate_one_center(props, mat))",if output_numpy :,135
"def _analyze_unittests(self, plugin_type): <TAB> plugins = self.w3afcore.plugins.get_plugin_list(plugin_type) <TAB> missing = [] <TAB> for plugin in plugins: <MASK> missing.append(plugin) <TAB> if missing: <TAB>  <TAB> msg = ""The following %s plugins dont have unittests: %s"" % ( <TAB>  <TAB>  <TAB> plugin_type, <TAB>  <TAB>  <TAB> "", "".join(sorted(missing)), <TAB>  <TAB> ) <TAB>  <TAB> self.assertTrue(False, msg)","if not self . _has_test ( plugin_type , plugin ) :",136
"def _Global(self, node): <TAB> module = self.get_module() <TAB> for name in node.names: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> pyname = module[name] <TAB>  <TAB>  <TAB> except exceptions.AttributeNotFoundError: <TAB>  <TAB>  <TAB>  <TAB> pyname = pynames.AssignedName(node.lineno) <TAB>  <TAB> self.names[name] = pyname",if module is not None :,95
"def run(self): <TAB> iam_resource = confidant.clients.get_boto_resource(""iam"") <TAB> grants = keymanager.get_grants() <TAB> try: <TAB>  <TAB> roles = [x for x in iam_resource.roles.all()] <TAB> except ClientError: <TAB>  <TAB> logger.error(""Failed to fetch IAM roles."") <TAB>  <TAB> return <TAB> services = [] <TAB> for service in Service.data_type_date_index.query(""service""): <TAB>  <TAB> services.append(service.id) <TAB> for role in roles: <MASK> logger.info(""Managing grants for {0}."".format(role.name)) <TAB>  <TAB>  <TAB> keymanager._ensure_grants(role, grants) <TAB> logger.info(""Finished managing grants."")",if role . name in services :,185
"def __setitem__(self, index, entity): <TAB> if isinstance(index, slice): <TAB>  <TAB> step = index.step or 1 <TAB>  <TAB> start = index.start or 0 <MASK> start += len(self) <TAB>  <TAB> stop = index.stop or len(self) <TAB>  <TAB> if stop < 0: <TAB>  <TAB>  <TAB> stop += len(self) <TAB>  <TAB> for i in range(start, stop, step): <TAB>  <TAB>  <TAB> self.__setitem__(i, entity[i]) <TAB> else: <TAB>  <TAB> self._order_entity(index, entity, True) <TAB>  <TAB> super(OrderingList, self).__setitem__(index, entity)",if start < 0 :,153
"def get_required_sensor_refs(self): <TAB> with open(self.partition_file, ""r"") as f: <TAB>  <TAB> partition_map = yaml.safe_load(f) <TAB>  <TAB> sensor_refs = partition_map.get(self.sensor_node_name, None) <MASK> raise SensorPartitionMapMissingException( <TAB>  <TAB>  <TAB>  <TAB> ""Sensor partition not found for %s in %s."" <TAB>  <TAB>  <TAB>  <TAB> % (self.sensor_node_name, self.partition_file) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self._supported_sensor_refs = set(sensor_refs) <TAB>  <TAB> return self._supported_sensor_refs",if sensor_refs is None :,161
"def handle_mouse_event(self, mouse_event): <TAB> # unfinished <TAB> for row in self._my_widgets: <TAB>  <TAB> for c in row: <MASK> if c.grid_current_value_index != -1: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.edit_cell = list(c.grid_current_value_index) <TAB> self.display()",if c . intersted_in_mouse_event ( mouse_event ) :,106
"def dequeue(self): <TAB> if self.blocking: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> # BZPOPMIN returns (key, data, score). <TAB>  <TAB>  <TAB> _, res, _ = self.conn.bzpopmin(self.queue_key, timeout=self.read_timeout) <TAB>  <TAB> except (ConnectionError, TypeError, IndexError): <TAB>  <TAB>  <TAB> # Unfortunately, there is no way to differentiate a socket <TAB>  <TAB>  <TAB> # timing out and a host being unreachable. <TAB>  <TAB>  <TAB> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return res[8:] <TAB> else: <TAB>  <TAB> # ZPOPMIN returns a list of (data, score) 2-tuples. <TAB>  <TAB> items = self.conn.zpopmin(self.queue_key, count=1) <MASK> return items[0][0][8:]  # [(prefix+data, score)].",if items :,199
"def decorate(request, *args, **kwargs): <TAB> doc_id = {} <TAB> try: <TAB>  <TAB> if request.GET.get(""uuid""): <TAB>  <TAB>  <TAB> doc_id[""uuid""] = request.GET.get(""uuid"") <MASK> doc_id[""id""] = kwargs[""doc_id""] <TAB>  <TAB> if doc_id: <TAB>  <TAB>  <TAB> doc2 = Document2.objects.get(**doc_id) <TAB>  <TAB>  <TAB> doc2.doc.get().can_read_or_exception(request.user) <TAB> except Document2.DoesNotExist: <TAB>  <TAB> raise PopupException(_(""Job %(id)s does not exist"") % {""id"": doc_id}) <TAB> return view_func(request, *args, **kwargs)","elif ""doc_id"" in kwargs :",180
"def __getitem__(self, key): <TAB> try: <TAB>  <TAB> return super(PartialKeyDict, self).__getitem__(key) <TAB> except KeyError: <TAB>  <TAB> removed_parent, key = self._remove_parent(key) <MASK> full_key = self._find_key(key) <TAB>  <TAB>  <TAB> if full_key: <TAB>  <TAB>  <TAB>  <TAB> if removed_parent: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> key, full_key = self._add_parent(key, full_key) <TAB>  <TAB>  <TAB>  <TAB> self[key] = full_key <TAB>  <TAB>  <TAB>  <TAB> return full_key <TAB>  <TAB> six.reraise(*sys.exc_info())",if len ( key ) == 13 :,156
"def current_dict_key(cursor_offset, line): <TAB> """"""If in dictionary completion, return the current key"""""" <TAB> for m in current_dict_key_re.finditer(line): <MASK> return LinePart(m.start(1), m.end(1), m.group(1)) <TAB> return None",if m . start ( 1 ) <= cursor_offset and m . end ( 1 ) >= cursor_offset :,100
"def test_websocket_subscription_break(event_loop, client_and_server, subscription_str): <TAB> session, server = client_and_server <TAB> count = 10 <TAB> subscription = gql(subscription_str.format(count=count)) <TAB> async for result in session.subscribe(subscription): <TAB>  <TAB> number = result[""number""] <TAB>  <TAB> print(f""Number received: {number}"") <TAB>  <TAB> assert number == count <MASK> # Note: the following line is only necessary for pypy3 v3.6.1 <TAB>  <TAB>  <TAB> await session._generator.aclose() <TAB>  <TAB>  <TAB> break <TAB>  <TAB> count -= 1 <TAB> assert count == 5",if count <= 5 :,162
"def get(self): <TAB> throttled_providers = list_throttled_providers() <TAB> for i in range(len(throttled_providers)): <TAB>  <TAB> throttled_providers[i][1] = ( <TAB>  <TAB>  <TAB> throttled_providers[i][1] <MASK> else ""Good"" <TAB>  <TAB> ) <TAB>  <TAB> throttled_providers[i][2] = ( <TAB>  <TAB>  <TAB> throttled_providers[i][2] if throttled_providers[i][2] != ""now"" else ""-"" <TAB>  <TAB> ) <TAB> return jsonify(data=throttled_providers)",if throttled_providers [ i ] [ 1 ] is not None,159
"def dict_merge(source, target): <TAB> if not isinstance(source, dict) or not isinstance(target, dict): <TAB>  <TAB> return source <TAB> src = deepcopy(source) <TAB> dst = deepcopy(target) <TAB> for key, val in src.items(): <TAB>  <TAB> if key in dst and is_list_of_dict(val) and is_list_of_dict(dst[key]): <TAB>  <TAB>  <TAB> for dst_elem in dst[key]: <TAB>  <TAB>  <TAB>  <TAB> for each_key in dst_elem.keys(): <MASK> src[key].append(dst_elem) <TAB> return src","if not is_key_exist ( each_key , val ) :",161
"def __eq__(self, other): <TAB> if isinstance(other, PoXliffUnit): <TAB>  <TAB> if len(self.units) != len(other.units): <TAB>  <TAB>  <TAB> return False <MASK> return False <TAB>  <TAB> for i in range(len(self.units) - 1): <TAB>  <TAB>  <TAB> if not self.units[i + 1] == other.units[i + 1]: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True <TAB> if len(self.units) <= 1: <TAB>  <TAB> if isinstance(other, lisa.LISAunit): <TAB>  <TAB>  <TAB> return super(PoXliffUnit, self).__eq__(other) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.source == other.source and self.target == other.target <TAB> return False","if not super ( PoXliffUnit , self ) . __eq__ ( other ) :",197
"def cb_syncthing_device_sync_progress(self, daemon, device_id, sync): <TAB> if device_id in self.devices: <TAB>  <TAB> device = self.devices[device_id] <TAB>  <TAB> device[""sync""] = ""%3.f%%"" % (sync * 100.0) <TAB>  <TAB> if not device[""connected""]: <TAB>  <TAB>  <TAB> device.set_color_hex(COLOR_DEVICE_OFFLINE) <TAB>  <TAB>  <TAB> device.set_status(_(""Disconnected"")) <MASK> device.set_color_hex(COLOR_DEVICE_SYNCING) <TAB>  <TAB>  <TAB> device.set_status(_(""Syncing""), sync) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> device.set_color_hex(COLOR_DEVICE_CONNECTED) <TAB>  <TAB>  <TAB> device.set_status(_(""Up to Date""))",elif sync >= 0.0 and sync < 0.99 :,197
def body(): <TAB> with tf.control_dependencies(fn_device_dependency_dict()[key]): <TAB>  <TAB> yield outs <TAB>  <TAB> assert outs <TAB>  <TAB> deps = outs <MASK> assert len(outs) == 1 <TAB>  <TAB>  <TAB> deps = outs[0] <TAB>  <TAB> fn_device_dependency_dict()[key] = deps,"if isinstance ( outs [ 0 ] , ( list , tuple ) ) :",90
"def find_mos(parent, lst=[]): <TAB> for f in os.listdir(parent): <TAB>  <TAB> fp = os.path.join(parent, f) <MASK> find_mos(fp, lst) <TAB>  <TAB> elif fp.endswith("".mo""): <TAB>  <TAB>  <TAB> lst += [fp] <TAB> return lst",if os . path . isdir ( fp ) :,85
"def __init__(self, **kwargs): <TAB> for key, default, required in self.properties: <TAB>  <TAB> if key in kwargs: <TAB>  <TAB>  <TAB> value = kwargs[key] <MASK> raise exceptions.PropertyRequiredError(self.__class__.__name__, key) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = default <TAB>  <TAB>  <TAB> if type(value) is type: <TAB>  <TAB>  <TAB>  <TAB> value = value() <TAB>  <TAB> setattr(self, key, value)",elif required :,109
def on_poll_start(self): <TAB> for channel in self._channels: <MASK> # BRPOP mode? <TAB>  <TAB>  <TAB> if channel.qos.can_consume(): <TAB>  <TAB>  <TAB>  <TAB> self._register_BRPOP(channel) <TAB>  <TAB> if channel.active_fanout_queues:  # LISTEN mode? <TAB>  <TAB>  <TAB> self._register_LISTEN(channel),if channel . active_queues :,97
"def add_parts(self, *parts): <TAB> """"""Add one or more parts to a library."""""" <TAB> from .defines import TEMPLATE <TAB> for part in flatten(parts): <TAB>  <TAB> # Parts with the same name are not allowed in the library. <TAB>  <TAB> # Also, do not check the backup library to see if the parts <TAB>  <TAB> # are in there because that's probably a different library. <MASK> self.parts.append(part.copy(dest=TEMPLATE)) <TAB> return self","if not self . get_parts ( use_backup_lib = False , name = re . escape ( part . name ) ) :",138
"def _get_node_ip(self, node_name): <TAB> ret = self.corev1client.list_node() <TAB> ip = """" <TAB> for i in ret.items: <TAB>  <TAB> for addr in i.status.addresses: <TAB>  <TAB>  <TAB> if addr.type == ""ExternalIP"": <TAB>  <TAB>  <TAB>  <TAB> ip = addr.address <MASK> ip = addr.address <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB> return ip","elif addr . type == ""InternalIP"" :",119
"def set(self, value: Union[str, List]) -> Optional[str]: <TAB> """"""Set the list given a comma-separated string or a list"""""" <TAB> error = None <TAB> if value is not None: <TAB>  <TAB> if not isinstance(value, list): <MASK> value = value.split() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> value = RE_PARAMFINDER.findall(value) <TAB>  <TAB> if self.__validation: <TAB>  <TAB>  <TAB> error, value = self.__validation(value) <TAB>  <TAB> if not error: <TAB>  <TAB>  <TAB> super().set(value) <TAB> return error","if '""' not in value and "","" not in value :",152
"def it_should_eventually_have_only_num_tasks(context, num): <TAB> num = int(num) <TAB> for _ in range(60): <TAB>  <TAB> actual_num = len( <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB> p <TAB>  <TAB>  <TAB>  <TAB> for p in context.scheduler.task_store.get_all_tasks().values() <TAB>  <TAB>  <TAB>  <TAB> if p.mesos_task_state == TASK_RUNNING <TAB>  <TAB>  <TAB> ] <TAB>  <TAB> ) <MASK> return <TAB>  <TAB> time.sleep(1) <TAB> raise Exception(""Expected <= %d tasks before timeout, saw %d"" % (num, actual_num))",if actual_num <= num :,158
"def label_variants(self, variants, region=None): <TAB> for variant in variants: <TAB>  <TAB> is_confident, truth_variant = self._match( <TAB>  <TAB>  <TAB> variant_utils.unphase_all_genotypes(variant) <TAB>  <TAB> ) <TAB>  <TAB> genotype = None <MASK> genotype = _genotype_from_matched_truth(variant, truth_variant) <TAB>  <TAB> yield variant_labeler.VariantLabel( <TAB>  <TAB>  <TAB> is_confident=is_confident, variant=variant, genotype=genotype <TAB>  <TAB> )",if truth_variant is not None :,137
"def load_theme_config(self, name): <TAB> r = super(PDBPowerline, self).load_theme_config(name) <TAB> theme_overrides = os.environ.get(""POWERLINE_THEME_OVERRIDES"") <TAB> if theme_overrides: <TAB>  <TAB> theme_overrides_dict = mergeargs(parse_override_var(theme_overrides)) <MASK> mergedicts(r, theme_overrides_dict[name]) <TAB> return r",if name in theme_overrides_dict :,116
"def encode(self, json_line): <TAB> data = json.loads(json_line) <TAB> ids = {} <TAB> for key in self.args.json_keys: <TAB>  <TAB> text = data[key] <TAB>  <TAB> doc_ids = [] <TAB>  <TAB> for sentence in Encoder.splitter.tokenize(text): <TAB>  <TAB>  <TAB> sentence_ids = Encoder.tokenizer.tokenize(sentence) <TAB>  <TAB>  <TAB> if len(sentence_ids) > 0: <TAB>  <TAB>  <TAB>  <TAB> doc_ids.append(sentence_ids) <MASK> doc_ids[-1].append(Encoder.tokenizer.eod) <TAB>  <TAB> ids[key] = doc_ids <TAB> return ids, len(json_line)",if self . args . append_eod :,170
"def __setitem__(self, key, value): <TAB> if not isinstance(key, str): <TAB>  <TAB> raise TypeError(""key must be a str instance"") <TAB> if value is not None: <TAB>  <TAB> value = self.serializer.dumps(value) <TAB> with self._session() as session: <TAB>  <TAB> obj = self._query(session).filter_by(key=key).first() <MASK> obj = models.StorageData(namespace=self.namespace, key=key) <TAB>  <TAB> obj.value = value <TAB>  <TAB> session.add(obj) <TAB>  <TAB> session.commit()",if obj is None :,139
"def _allowed(self, public_key, policy): <TAB> for entry in policy.entries: <TAB>  <TAB> if entry.type == Policy.PERMIT_KEY: <TAB>  <TAB>  <TAB> if public_key == entry.key or entry.key == ""*"": <TAB>  <TAB>  <TAB>  <TAB> return True <MASK> if public_key == entry.key or entry.key == ""*"": <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> # Default last entry is always DENY all <TAB> return False",elif entry . type == Policy . DENY_KEY :,117
"def _set_random_joint_angles(physics, random, max_attempts=1000): <TAB> """"""Sets the joints to a random collision-free state."""""" <TAB> for _ in range(max_attempts): <TAB>  <TAB> randomizers.randomize_limited_and_rotational_joints(physics, random) <TAB>  <TAB> # Check for collisions. <TAB>  <TAB> physics.after_reset() <MASK> break <TAB> else: <TAB>  <TAB> raise RuntimeError( <TAB>  <TAB>  <TAB> ""Could not find a collision-free state "" <TAB>  <TAB>  <TAB> ""after {} attempts"".format(max_attempts) <TAB>  <TAB> )",if physics . data . ncon == 0 :,150
"def findall(self, name, recursive=False): <TAB> """"""Recursively find all child atoms by specified name."""""" <TAB> if self.children is not None: <TAB>  <TAB> for child in self.children: <TAB>  <TAB>  <TAB> if child.name == name: <TAB>  <TAB>  <TAB>  <TAB> yield child <MASK> for atom in child.findall(name, True): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield atom",if recursive :,94
"def json(self): <TAB> prop_collection = {} <TAB> props = dir(self) <TAB> for prop in props: <TAB>  <TAB> if prop.startswith(""_""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> prop_obj = getattr(self, prop) <TAB>  <TAB> if isinstance(prop_obj, (str, int, bool, float)): <TAB>  <TAB>  <TAB> prop_collection[prop] = prop_obj <MASK> prop_collection[prop] = prop_obj.timestamp() <TAB> return prop_collection","elif isinstance ( prop_obj , datetime . datetime ) :",124
"def test_move_items(item_name): <TAB> """"""Ensure that everything loads correctly."""""" <TAB> try: <TAB>  <TAB> getattr(six.moves, item_name) <TAB> except AttributeError: <TAB>  <TAB> if item_name == ""zip_longest"" and sys.version_info < (2, 6): <TAB>  <TAB>  <TAB> py.test.skip(""zip_longest only available on 2.6+"") <TAB> except ImportError: <MASK> py.test.skip(""Windows only module"") <TAB>  <TAB> if item_name.startswith(""tkinter"") and not have_tkinter: <TAB>  <TAB>  <TAB> py.test.skip(""requires tkinter"") <TAB>  <TAB> raise","if item_name == ""winreg"" and not sys . platform . startswith ( ""win"" ) :",163
"def test_negation(all_values): <TAB> for values in [{""guid_2"", ""guid_1""}, {""guid_5"", ""guid_9""}, {""guid_2""}]: <TAB>  <TAB> test_predicate = in_negate(in_set(values, ""volume_guid"")) <TAB>  <TAB> included_values = set() <TAB>  <TAB> for val in all_values: <MASK> included_values.add(val) <TAB>  <TAB> assert included_values == all_values.difference(values)","if test_predicate . do_include ( { ""volume_guid"" : val } ) :",130
"def recv_nonblocking(self, size): <TAB> self.sock.settimeout(0) <TAB> try: <TAB>  <TAB> ret = self.recv(size) <TAB> except socket.error as e: <TAB>  <TAB> # 10035 no data when nonblocking <TAB>  <TAB> if e.args[0] == 10035:  # errno.EWOULDBLOCK: errno is not always right <TAB>  <TAB>  <TAB> ret = None <TAB>  <TAB> # 10053 connection abort by client <TAB>  <TAB> # 10054 connection reset by peer <MASK> # errno.ECONNABORTED: <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise <TAB> return ret","elif e . args [ 0 ] in [ 10053 , 10054 ] :",159
"def subscribe_and_distribute(sub_socket): <TAB> global participants <TAB> while True: <TAB>  <TAB> msg = sub_socket.recv_pyobj() <TAB>  <TAB> for ws, name_id in participants.items(): <TAB>  <TAB>  <TAB> to_send = name_id.unpack_message(msg) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ws.send(to_send) <TAB>  <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> del participants[ws]",if to_send :,118
"def construct_map(client, d=None, interfaces=None): <TAB> if d is None: <TAB>  <TAB> d = {} <TAB> if interfaces is None: <TAB>  <TAB> interfaces = get_interfaces() <TAB> for path, interface in interfaces: <TAB>  <TAB> if len(path) > 0: <TAB>  <TAB>  <TAB> key = path.pop(0) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> key = None <TAB>  <TAB> if key == ""*"": <TAB>  <TAB>  <TAB> key = None <MASK> d[key] = interface(client) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> value = d.get(key, {}) <TAB>  <TAB> if type(value) is not dict: <TAB>  <TAB>  <TAB> value = {None: value} <TAB>  <TAB> construct_map(client, value, [(path, interface)]) <TAB>  <TAB> d[key] = value <TAB> return d",if len ( path ) == 0 :,196
"def _terminal_read_until_regexp(self, expected_list): <TAB> max_time = time.time() + self._timeout <TAB> regexp_list = [re.compile(rgx) for rgx in expected_list] <TAB> out = self._terminal_emulator.read_until_regexp(regexp_list) <MASK> return True, out <TAB> while time.time() < max_time: <TAB>  <TAB> output = self.expect(regexp_list, self._terminal_frequency)[-1] <TAB>  <TAB> self._terminal_emulator.feed(output) <TAB>  <TAB> out = self._terminal_emulator.read_until_regexp(regexp_list) <TAB>  <TAB> if out: <TAB>  <TAB>  <TAB> return True, out <TAB> return False, self._terminal_emulator.read()",if out :,179
def closure(table): <TAB> modules = list(table.keys()) <TAB> # <TAB> # Initialize reach with a copy of table <TAB> # <TAB> reach = {} <TAB> for mod in modules: <TAB>  <TAB> reach[mod] = table[mod][:] <TAB> # <TAB> # Iterate until no more change <TAB> # <TAB> change = 1 <TAB> while change: <TAB>  <TAB> change = 0 <TAB>  <TAB> for mod in modules: <TAB>  <TAB>  <TAB> for mo in reach[mod]: <TAB>  <TAB>  <TAB>  <TAB> if mo in modules: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for m in reach[mo]: <MASK> reach[mod].append(m) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> change = 1 <TAB> # <TAB> return reach,if m not in reach [ mod ] :,178
"def runVdb(vivgui, pid=None): <TAB> try: <TAB>  <TAB> db = vdb.Vdb() <TAB>  <TAB> extendVdb(db, vivgui) <TAB>  <TAB> vgui = vdb_qt_main.VdbWindow(db) <TAB>  <TAB> vgui.show() <MASK> fireattach(db.trace, pid) <TAB> except Exception as e: <TAB>  <TAB> vivgui.vw.vprint(""Error Running VDB: %s"" % e)",if pid is not None :,123
"def deleteDescendents(p, cond, dtor=None, descendAnyway=False, _culls=0): <TAB> childs = [child.copy() for child in p.children()] <TAB> childs.reverse() <TAB> for child in childs: <TAB>  <TAB> if descendAnyway or not cond(child): <TAB>  <TAB>  <TAB> _culls += deleteDescendents( <TAB>  <TAB>  <TAB>  <TAB> child, cond, dtor=dtor, descendAnyway=descendAnyway <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if cond(child): <TAB>  <TAB>  <TAB> _culls += 1 <MASK> dtor(child) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> child.doDelete() <TAB> return _culls",if dtor :,174
"def computeWidth(s, tab_width): <TAB> w = 0 <TAB> for ch in s: <TAB>  <TAB> if ch == ""\t"": <TAB>  <TAB>  <TAB> w += abs(tab_width) - (w % abs(tab_width)) <MASK> # Bug fix: 2012/06/05. <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> w += 1 <TAB> return w","elif ch == ""\n"" :",96
"def queryset_to_csv(self): <TAB> csv_data = [ <TAB>  <TAB> # Headers <TAB>  <TAB> "","".join([""pdu"", ""outlet"", ""device"", ""power_port"", ""reachable""]) <TAB> ] <TAB> for obj in self.queryset: <TAB>  <TAB> csv = csv_format( <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB> obj._path.destination.device.identifier <MASK> else None, <TAB>  <TAB>  <TAB>  <TAB> obj._path.destination.name if obj._path.destination else None, <TAB>  <TAB>  <TAB>  <TAB> obj.device.identifier, <TAB>  <TAB>  <TAB>  <TAB> obj.name, <TAB>  <TAB>  <TAB>  <TAB> obj._path.is_active, <TAB>  <TAB>  <TAB> ] <TAB>  <TAB> ) <TAB>  <TAB> csv_data.append(csv) <TAB> return ""\n"".join(csv_data)",if obj . _path . destination,192
"def tokenizer_marker(self, side=""src""): <TAB> """"""Return marker used in `side` tokenizer."""""" <TAB> marker = None <TAB> if self.tokenizers_opt is not None: <TAB>  <TAB> tokenizer_type = self.tokenizers_opt[side].get(""type"", None) <TAB>  <TAB> if tokenizer_type == ""pyonmttok"": <TAB>  <TAB>  <TAB> params = self.tokenizers_opt[side].get(""params"", None) <TAB>  <TAB>  <TAB> if params is not None: <MASK> marker = ""joiner"" <TAB>  <TAB>  <TAB>  <TAB> elif params.get(""spacer_annotate"", None) is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> marker = ""spacer"" <TAB>  <TAB> elif tokenizer_type == ""sentencepiece"": <TAB>  <TAB>  <TAB> marker = ""spacer"" <TAB> return marker","if params . get ( ""joiner_annotate"" , None ) is not None :",193
"def add_stats(self, *stats): <TAB> for stat in stats: <TAB>  <TAB> if stat not in self.stats_keys: <TAB>  <TAB>  <TAB> self.stats_keys.append(stat) <TAB>  <TAB> for i in self.intervals: <MASK> self.stats[i][stat] = []",if stat not in self . stats [ i ] :,84
"def update_dict(d, u):  # for deep dictionary update <TAB> for k, v in u.items(): <MASK> if isinstance(v, collections.Mapping): <TAB>  <TAB>  <TAB>  <TAB> r = update_dict(d.get(k, {}), v) <TAB>  <TAB>  <TAB>  <TAB> d[k] = r <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> d[k] = u[k] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> d = {k: u[k]} <TAB> return d","if isinstance ( d , collections . Mapping ) :",125
"def temp_file(root_dir=None): <TAB> fdesc, file_ = mkstemp(dir=root_dir) <TAB> yield file_ <TAB> os.close(fdesc) <TAB> try: <TAB>  <TAB> os.unlink(file_) <TAB> except (IOError, OSError): <MASK> logger.error( <TAB>  <TAB>  <TAB>  <TAB> ""Ignoring IOError raised when trying to delete"" <TAB>  <TAB>  <TAB>  <TAB> "" temp file %s created in `temp_file` context"" <TAB>  <TAB>  <TAB>  <TAB> "" manager"", <TAB>  <TAB>  <TAB>  <TAB> file_, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise","if ""Windows"" in platform . system ( ) :",146
"def _get_ignore_value(self, input_dtype): <TAB> ignore_value = self.ignore_value <TAB> if ignore_value is None: <MASK> ignore_value = """" <TAB>  <TAB> elif input_dtype.is_integer: <TAB>  <TAB>  <TAB> ignore_value = -1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return None <TAB> return tf.cast(ignore_value, input_dtype)",if input_dtype == tf . string :,104
"def _first_iteration(self) -> t.Tuple[t.Optional[bytes], int]: <TAB> chunk = None <TAB> if self.seekable: <TAB>  <TAB> self.iterable.seek(self.start_byte)  # type: ignore <TAB>  <TAB> self.read_length = self.iterable.tell()  # type: ignore <TAB>  <TAB> contextual_read_length = self.read_length <TAB> else: <TAB>  <TAB> while self.read_length <= self.start_byte: <TAB>  <TAB>  <TAB> chunk = self._next_chunk() <MASK> chunk = chunk[self.start_byte - self.read_length :] <TAB>  <TAB> contextual_read_length = self.start_byte <TAB> return chunk, contextual_read_length",if chunk is not None :,175
"def parse_command_line(source): <TAB> state = ParserState(source) <TAB> parse_func = parse_line_ref <TAB> # Create empty command line. <TAB> command_line = CommandLineNode(None, None) <TAB> while True: <TAB>  <TAB> parse_func, command_line = parse_func(state, command_line) <MASK> command_line.validate() <TAB>  <TAB>  <TAB> return command_line",if parse_func is None :,104
"def select_available_language(locales): <TAB> global languages <TAB> if not len(languages): <TAB>  <TAB> Log( <TAB>  <TAB>  <TAB> 'Locale Patch: no known available languages, using ""%s"" as the %s choise. Call SetAvailableLanguages(list) function to improve this.' <TAB>  <TAB>  <TAB> % (locales[0], ""only"" if len(languages) == 1 else ""first"") <TAB>  <TAB> ) <TAB>  <TAB> return locales[0] <TAB> for item in locales: <MASK> Log('Locale Patch: using available language ""%s"".' % item) <TAB>  <TAB>  <TAB> return item <TAB> Log(""Locale Patch: none of the languages matched available languages."")",if item in languages :,154
"def get_layout_objects(layout, clz, objects): <TAB> for i, layout_object in enumerate(layout.fields): <MASK> objects.append(layout_object) <TAB>  <TAB> elif hasattr(layout_object, ""get_field_names""): <TAB>  <TAB>  <TAB> get_layout_objects(layout_object, clz, objects)","if layout_object . __class__ is clz or issubclass ( layout_object . __class__ , clz ) :",99
"def http_handler(self, conn, request, response): <TAB> if not request: <TAB>  <TAB> return <TAB> if self.ioc_bytes not in request.blob.data: <TAB>  <TAB> # indicator of (potential) compromise is not here <TAB>  <TAB> return <TAB> # there is an attempt to exploit Joomla! <TAB> # The Joomla exploit could be sent any HTTP header field <TAB> for hdr, val in request.headers.items(): <MASK> cmd = self.parse_cmd(val) <TAB>  <TAB>  <TAB> if cmd: <TAB>  <TAB>  <TAB>  <TAB> self.alert(""{} -> {}"".format(hdr, cmd), **conn.info()) <TAB>  <TAB>  <TAB>  <TAB> return conn, request, response",if self . ioc in val :,164
"def remove_and_prune(a_dict, b_dict): <TAB> """"""Remove fields from a_dict that are present in b_dict"""""" <TAB> for k in b_dict: <TAB>  <TAB> if isinstance(b_dict[k], dict): <MASK> remove_and_prune(a_dict[k], b_dict[k]) <TAB>  <TAB>  <TAB>  <TAB> if not a_dict[k].sections: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> a_dict.pop(k) <TAB>  <TAB> elif k in a_dict: <TAB>  <TAB>  <TAB> a_dict.pop(k)",if k in a_dict and type ( a_dict [ k ] ) is configobj . Section :,155
"def _setMyValues(self, tree): <TAB> if tree == [] or tree == None: <TAB>  <TAB> self._myFullValues = NPSTree.NPSTreeData() <TAB> el <MASK> tree = self.convertToTree(tree) <TAB>  <TAB> self._myFullValues = tree <TAB>  <TAB> if not isinstance(tree, NPSTree.NPSTreeData): <TAB>  <TAB>  <TAB> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""MultiLineTree widget can only contain a NPSTreeData object in its values attribute"" <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> self._myFullValues = tree","if not isinstance ( tree , NPSTree . NPSTreeData ) :",147
"def one_file_or_folder(folder): <TAB> """"""If the dir only contains one file or folder, join that file/folder onto the path"""""" <TAB> if os.path.exists(folder) and os.path.isdir(folder): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> cont = os.listdir(folder) <MASK> folder = os.path.join(folder, cont[0]) <TAB>  <TAB>  <TAB>  <TAB> folder = one_file_or_folder(folder) <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> # Can occur on paths it doesn't like, for example ""C:"" <TAB>  <TAB>  <TAB> pass <TAB> return folder",if len ( cont ) == 1 :,153
"def check_rule(self, rule_type, conf): <TAB> if rule_type in conf.keys(): <TAB>  <TAB> for rule in conf[rule_type]: <TAB>  <TAB>  <TAB> if isinstance(rule, dict): <MASK> self.evaluated_keys.append( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f""{rule_type}/[{conf[rule_type].index(rule)}]"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return CheckResult.FAILED <TAB> return CheckResult.PASSED","if ""description"" not in rule . keys ( ) or not rule [ ""description"" ] :",134
"def _gen_identity(self, key, param=None): <TAB> """"""generate identity according to key and param given"""""" <TAB> if self.identity_generator and param is not None: <TAB>  <TAB> if self.serializer: <TAB>  <TAB>  <TAB> param = self.serializer.serialize(param) <MASK> param = self.compressor.compress(param) <TAB>  <TAB> identity = self.identity_generator.generate(key, param) <TAB> else: <TAB>  <TAB> identity = key <TAB> return identity",if self . compressor :,116
"def _indices(self, indices): <TAB> """"""Turn all string indices into int indices, preserving ellipsis."""""" <TAB> if isinstance(indices, tuple): <TAB>  <TAB> out = [] <TAB>  <TAB> dim = 0 <TAB>  <TAB> for i, index in enumerate(indices): <TAB>  <TAB>  <TAB> if index is Ellipsis: <TAB>  <TAB>  <TAB>  <TAB> out.append(index) <TAB>  <TAB>  <TAB>  <TAB> dim = len(self.shape) - len(indices) + i + 1 <MASK> out.append(None) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> out.append(self._get_index(dim, index)) <TAB>  <TAB>  <TAB>  <TAB> dim += 1 <TAB>  <TAB> return tuple(out) <TAB> else: <TAB>  <TAB> return self._get_index(0, indices)",elif index is np . newaxis :,179
"def set_attr(k, v): <TAB> if k in self.keys(): <TAB>  <TAB> setattr(self, k, v) <TAB> elif k in self._deprecated_keys(): <TAB>  <TAB> k0 = self._get_new(k) <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Cannot specify both '{}' and '{}' in config"".format(k0, k) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> warn(""The '{}' config key is deprecated, please use '{}' instead"".format(k, k0)) <TAB>  <TAB> set_attr(k0, v) <TAB> else: <TAB>  <TAB> raise AttributeError(k)",if k0 in data_dict :,148
"def is_audio(file): <TAB> """"""Returns `True` if the file has an audio mime type."""""" <TAB> ext = _get_extension(file) <TAB> if not ext: <TAB>  <TAB> metadata = _get_metadata(file) <MASK> return metadata.get(""mime_type"").startswith(""audio/"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> else: <TAB>  <TAB> file = ""a"" + ext <TAB>  <TAB> return (mimetypes.guess_type(file)[0] or """").startswith(""audio/"")","if metadata and metadata . has ( ""mime_type"" ) :",130
"def download_data(): <TAB> base_url = ( <TAB>  <TAB> ""https://raw.githubusercontent.com/uberspot/OpenTriviaQA/master/categories/{}"" <TAB> ) <TAB> file_list = [""animals"", ""general"", ""geography"", ""history"", ""literature"", ""people""] <TAB> for filename in file_list: <TAB>  <TAB> folder = DATA_PATH <MASK> os.mkdir(folder) <TAB>  <TAB> local_filepath = os.path.join(folder, filename) <TAB>  <TAB> print(base_url.format(filename)) <TAB>  <TAB> data = requests.get(base_url.format(filename)).content <TAB>  <TAB> fd = open(local_filepath, ""wb"") <TAB>  <TAB> fd.write(data) <TAB>  <TAB> fd.close()",if not os . path . exists ( folder ) :,187
"def _BaseCookie__set(self, key, real_value, coded_value): <TAB> key = force_str(key) <TAB> try: <TAB>  <TAB> M = self.get(key, Morsel()) <TAB>  <TAB> M.set(key, real_value, coded_value) <TAB>  <TAB> dict.__setitem__(self, key, M) <TAB> except http_cookies.CookieError: <MASK> self.bad_cookies = set() <TAB>  <TAB> self.bad_cookies.add(key) <TAB>  <TAB> dict.__setitem__(self, key, http_cookies.Morsel())","if not hasattr ( self , ""bad_cookies"" ) :",149
"def __mount(self, pool, uuid, path=SYSDATASET_PATH): <TAB> for dataset, name in self.__get_datasets(pool, uuid): <TAB>  <TAB> if name: <TAB>  <TAB>  <TAB> mountpoint = f""{path}/{name}"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> mountpoint = path <MASK> continue <TAB>  <TAB> if not os.path.isdir(mountpoint): <TAB>  <TAB>  <TAB> os.mkdir(mountpoint) <TAB>  <TAB> await run(""mount"", ""-t"", ""zfs"", dataset, mountpoint, check=True)",if os . path . ismount ( mountpoint ) :,135
"def on_done(self, success): <TAB> if not success or self._stage == ""upload"": <TAB>  <TAB> super().on_done(success) <MASK> # Returcode is required by the superclass <TAB>  <TAB>  <TAB> if success: <TAB>  <TAB>  <TAB>  <TAB> self.returncode = 0 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.returncode = -1 <TAB>  <TAB> return <TAB> assert self._stage == ""install"" <TAB> # only half of the work is done <TAB> self._stage = ""upload"" <TAB> super().send_command_to_backend()","if self . _stage == ""upload"" :",137
"def stat(self, follow_symlinks=True): <TAB> if follow_symlinks: <TAB>  <TAB> if self._stat is None: <MASK> self._stat = stat(self.path) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._stat = self._lstat <TAB>  <TAB> return self._stat <TAB> else: <TAB>  <TAB> return self._lstat",if self . is_symlink ( ) :,91
"def some_funky_spot(ilist, bitpos): <TAB> """"""Return true if some pattern has a nonterminal or operand decider"""""" <TAB> for i in ilist: <MASK> if i.ipattern.bits[bitpos].is_nonterminal(): <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB> if i.ipattern.bits[bitpos].is_operand_decider(): <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if bitpos < len ( i . ipattern . bits ) :,111
"def get_archived_from_url(node, file_node): <TAB> if file_node.copied_from: <TAB>  <TAB> trashed = TrashedFileNode.load(file_node.copied_from._id) <MASK> return node.registered_from.web_url_for( <TAB>  <TAB>  <TAB>  <TAB> ""addon_view_or_download_file"", <TAB>  <TAB>  <TAB>  <TAB> provider=file_node.provider, <TAB>  <TAB>  <TAB>  <TAB> path=file_node.copied_from._id, <TAB>  <TAB>  <TAB> ) <TAB> return None",if not trashed :,130
"def _set_attrs(self, attrs): <TAB> """"""Update machine attributes in the state file."""""" <TAB> with self.depl._db: <TAB>  <TAB> c = self.depl._db.cursor() <TAB>  <TAB> for n, v in attrs.iteritems(): <MASK> c.execute( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""delete from ResourceAttrs where machine = ? and name = ?"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> (self.id, n), <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> c.execute( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""insert or replace into ResourceAttrs(machine, name, value) values (?, ?, ?)"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> (self.id, n, v), <TAB>  <TAB>  <TAB>  <TAB> )",if v == None :,176
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> length = d.getVarInt32() <TAB>  <TAB>  <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB>  <TAB>  <TAB> d.skip(length) <TAB>  <TAB>  <TAB> self.add_data().TryMerge(tmp) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 18: <TAB>  <TAB>  <TAB> self.set_next_key(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> self.set_truncated_value(d.getBoolean()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 24 :,199
"def __matchingAction(self, keySequence, menu): <TAB> for action in menu.actions(): <TAB>  <TAB> if keySequence in action.shortcuts(): <TAB>  <TAB>  <TAB> return action <MASK> a = self.__matchingAction(keySequence, action.menu()) <TAB>  <TAB>  <TAB> if a is not None: <TAB>  <TAB>  <TAB>  <TAB> return a <TAB> return None",if action . menu ( ) is not None :,90
"def crc32(filename, slice=const.OneM): <TAB> with io.open(filename, ""rb"") as f: <TAB>  <TAB> buf = f.read(slice) <TAB>  <TAB> crc = binascii.crc32(buf) <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> buf = f.read(slice) <MASK> crc = binascii.crc32(buf, crc) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return crc & 0xFFFFFFFF",if buf :,112
"def _parser_tlvs(cls, buf): <TAB> offset = 0 <TAB> tlvs = [] <TAB> while True: <TAB>  <TAB> (type_,) = struct.unpack_from(""!B"", buf, offset) <TAB>  <TAB> cls_ = cls._TLV_TYPES.get(type_) <MASK> assert type_ is CFM_END_TLV <TAB>  <TAB>  <TAB> break <TAB>  <TAB> tlv_ = cls_.parser(buf[offset:]) <TAB>  <TAB> tlvs.append(tlv_) <TAB>  <TAB> offset += len(tlv_) <TAB> return tlvs",if not cls_ :,136
"def step(self, feed_dict): <TAB> self.i += 1 <TAB> index = 0 <TAB> threshold = 0 <TAB> for val in self.schedule: <TAB>  <TAB> threshold += val <MASK> index += 1 <TAB>  <TAB>  <TAB> if len(self.trainers) <= index: <TAB>  <TAB>  <TAB>  <TAB> index = len(self.trainers) - 1 <TAB> return self.trainers[index].step(feed_dict)",if self . i > threshold :,106
"def _get_all_tasks(gradle): <TAB> proc = Popen([gradle, ""tasks""], stdout=PIPE) <TAB> should_yield = False <TAB> for line in proc.stdout.readlines(): <TAB>  <TAB> line = line.decode().strip() <MASK> should_yield = True <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if not line.strip(): <TAB>  <TAB>  <TAB> should_yield = False <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if should_yield and not line.startswith(""All tasks runnable from root project""): <TAB>  <TAB>  <TAB> yield line.split("" "")[0]","if line . startswith ( ""----"" ) :",138
"def _process_attacks(self, charged=False): <TAB> # type: (bool) -> List[Attack] <TAB> key = ""Fast Attack(s)"" if not charged else ""Special Attack(s)"" <TAB> moves_dict = (ChargedAttacks if charged else FastAttacks).BY_NAME <TAB> moves = [] <TAB> for name in self._data[key]: <MASK> raise KeyError( <TAB>  <TAB>  <TAB>  <TAB> 'Unknown {} attack: ""{}""'.format(""charged"" if charged else ""fast"", name) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> moves.append(moves_dict[name]) <TAB> moves = sorted(moves, key=lambda m: m.dps, reverse=True) <TAB> assert len(moves) > 0 <TAB> return moves",if name not in moves_dict :,180
"def examine(result, type): <TAB> try: <TAB>  <TAB> print(""Examining %s ......"" % type) <TAB>  <TAB> nt = type(**result) <TAB>  <TAB> assert equivalent( <TAB>  <TAB>  <TAB> result, nt <TAB>  <TAB> ), ""Not equivalent:::::::::::::::\n%s\n::::::::::::::::\n%s"" % (result, nt) <TAB>  <TAB> pprint.pprint(result) <TAB>  <TAB> pprint.pprint(nt) <TAB>  <TAB> print() <TAB> except AssertionError: <TAB>  <TAB> traceback.print_exc() <TAB>  <TAB> answer = input(""Do you want to continue? [y] "") <MASK> exit(1)","if answer != ""y"" :",159
"def mouse_click_handler(event): <TAB> x, y = event.xdata, event.ydata <TAB> if x is None or y is None: <TAB>  <TAB> return <TAB> for coord, _ in rectangles.items(): <TAB>  <TAB> x0, y0, x1, y1 = coord <MASK> toolbar = pl.gcf().canvas.toolbar <TAB>  <TAB>  <TAB> toolbar.push_current() <TAB>  <TAB>  <TAB> timestamp_ax.set_xlim(x0, x1) <TAB>  <TAB>  <TAB> timestamp_ax.set_ylim(y0, stack_size + 1) <TAB>  <TAB>  <TAB> toolbar.push_current() <TAB>  <TAB>  <TAB> pl.draw() <TAB>  <TAB>  <TAB> return",if x0 < x < x1 and y0 < y < y1 :,172
"def shift_expr(self, nodelist): <TAB> # shift_expr ('<<'|'>>' shift_expr)* <TAB> node = self.com_node(nodelist[0]) <TAB> for i in range(2, len(nodelist), 2): <TAB>  <TAB> right = self.com_node(nodelist[i]) <TAB>  <TAB> if nodelist[i - 1].type == token.LEFTSHIFT: <TAB>  <TAB>  <TAB> node = LeftShift(node, right, lineno=nodelist[1].context) <MASK> node = RightShift(node, right, lineno=nodelist[1].context) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""unexpected token: %s"" % nodelist[i - 1].type) <TAB> return node",elif nodelist [ i - 1 ] . type == token . RIGHTSHIFT :,176
"def _cleanup(obj): <TAB> if obj: <TAB>  <TAB> if isinstance(obj, dict): <TAB>  <TAB>  <TAB> obj.pop(""__"", None) <TAB>  <TAB>  <TAB> for k, v in six.iteritems(obj): <TAB>  <TAB>  <TAB>  <TAB> obj[k] = _cleanup(v) <MASK> del obj[0] <TAB> return obj","elif isinstance ( obj , list ) and isinstance ( obj [ 0 ] , dict ) and ""__"" in obj [ 0 ] :",102
"def de_json( <TAB> cls, data: Optional[JSONDict], bot: ""Bot"") -> Optional[""InlineKeyboardMarkup""]: <TAB> data = cls.parse_data(data) <TAB> if not data: <TAB>  <TAB> return None <TAB> keyboard = [] <TAB> for row in data[""inline_keyboard""]: <TAB>  <TAB> tmp = [] <TAB>  <TAB> for col in row: <TAB>  <TAB>  <TAB> btn = InlineKeyboardButton.de_json(col, bot) <MASK> tmp.append(btn) <TAB>  <TAB> keyboard.append(tmp) <TAB> return cls(keyboard)",if btn :,136
"def test_tls_protocol_name_of_socket(self): <TAB> if self.tls_protocol_name is None: <TAB>  <TAB> pytest.skip(""Skipping base test class"") <TAB> with HTTPSConnectionPool(self.host, self.port, ca_certs=DEFAULT_CA) as https_pool: <TAB>  <TAB> conn = https_pool._get_conn() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> conn.connect() <MASK> pytest.skip(""SSLSocket.version() not available"") <TAB>  <TAB>  <TAB> assert conn.sock.version() == self.tls_protocol_name <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> conn.close()","if not hasattr ( conn . sock , ""version"" ) :",160
"def getitem(self, obj, argument): <TAB> """"""Subscribe an object from sandboxed code."""""" <TAB> try: <TAB>  <TAB> return obj[argument] <TAB> except (TypeError, LookupError): <TAB>  <TAB> if isinstance(argument, string_types): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> attr = str(argument) <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value = getattr(obj, attr) <TAB>  <TAB>  <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB>  <TAB> else: <MASK> return value <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return self.unsafe_undefined(obj, argument) <TAB> return self.undefined(obj=obj, name=argument)","if self . is_safe_attribute ( obj , argument , value ) :",197
"def test_dates_avoid_datetime_cast(self): <TAB> Article.objects.create(pub_date=datetime.date(2015, 10, 21)) <TAB> for kind in [""day"", ""month"", ""year""]: <TAB>  <TAB> qs = Article.objects.dates(""pub_date"", kind) <MASK> self.assertIn(""DATE("", str(qs.query)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertIn("" AS DATE)"", str(qs.query))","if kind == ""day"" :",114
"def get_content_type_mapping_for_extension(extension, subtree=None): <TAB> if subtree is None: <TAB>  <TAB> subtree = full_extension_tree() <TAB> for value in subtree.values(): <TAB>  <TAB> content_extension_matches = ( <TAB>  <TAB>  <TAB> isinstance(value, (ContentTypeMapping, ContentTypeDetector)) <TAB>  <TAB>  <TAB> and extension in value.extensions <TAB>  <TAB> ) <TAB>  <TAB> list_extension_matches = isinstance(value, (list, tuple)) and extension in value <MASK> return value <TAB>  <TAB> elif isinstance(value, dict): <TAB>  <TAB>  <TAB> result = get_content_type_mapping_for_extension(extension, subtree=value) <TAB>  <TAB>  <TAB> if result is not None: <TAB>  <TAB>  <TAB>  <TAB> return result <TAB> return None",if content_extension_matches or list_extension_matches :,185
"def foo(a): <TAB> b = output_tensor(a.shape, a.dtype) <TAB> b[0] = 1.2 <TAB> for i in range(1, a.shape[0] - 1): <MASK> b[i] = a[i] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> b[i] = 0.0 <TAB> return b",if a [ i ] * a [ i - 1 ] < a [ i ] or a [ i ] * a [ i - 1 ] < a [ i - 1 ] or i * a [ i ] == a [ i ] :,135
"def calc_callees(self): <TAB> if self.all_callees: <TAB>  <TAB> return <TAB> self.all_callees = all_callees = {} <TAB> for func, (cc, nc, tt, ct, callers) in self.stats.iteritems(): <TAB>  <TAB> if not func in all_callees: <TAB>  <TAB>  <TAB> all_callees[func] = {} <TAB>  <TAB> for func2, caller in callers.iteritems(): <MASK> all_callees[func2] = {} <TAB>  <TAB>  <TAB> all_callees[func2][func] = caller <TAB> return",if not func2 in all_callees :,138
"def insert_before(self, parent, sibling, row=None): <TAB> if row is not None: <TAB>  <TAB> value = self._get_marshalable(row[0]) <MASK> position = -1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if parent is None: <TAB>  <TAB>  <TAB>  <TAB> parent = self.iter_parent(sibling) <TAB>  <TAB>  <TAB> position = self.get_path(sibling)[-1] <TAB>  <TAB> return self.insert_with_values(parent, position, [0], [value]) <TAB> assert not self.ATOMIC <TAB> return super(ObjectTreeStore, self).insert_before(parent, sibling)",if sibling is None :,152
"def execute(self, context): <TAB> i = 0 <TAB> while True: <MASK> break <TAB>  <TAB> # Steps can change during this operation <TAB>  <TAB> # this is why index based iteration - step reference can be stale <TAB>  <TAB> step = context.steps[i] <TAB>  <TAB> step.remove_empty_columns_from_end() <TAB>  <TAB> if step.has_only_comment(): <TAB>  <TAB>  <TAB> step.remove_empty_columns_from_beginning() <TAB>  <TAB> i += 1 <TAB> context.execute(DeleteRows(context.get_empty_rows())) <TAB> context.notify_steps_changed()",if len ( context . steps ) <= i :,150
"def decode(self, ctext: T) -> Optional[U]: <TAB> result = """" <TAB> switch_to_digit_map = 0 <TAB> if re.search(""^[01]{5}$"", ctext.split()[0]): <TAB>  <TAB> for i in ctext.split(): <MASK> switch_to_digit_map = 1 <TAB>  <TAB>  <TAB> if i == ""11111"": <TAB>  <TAB>  <TAB>  <TAB> switch_to_digit_map = 0 <TAB>  <TAB>  <TAB> if switch_to_digit_map == 1: <TAB>  <TAB>  <TAB>  <TAB> result += self.BAUDOT_DICT[""+"" + i] <TAB>  <TAB>  <TAB> if switch_to_digit_map == 0: <TAB>  <TAB>  <TAB>  <TAB> result += self.BAUDOT_DICT[i] <TAB>  <TAB> return result <TAB> else: <TAB>  <TAB> return None","if i == ""11011"" :",189
"def test_seq_object_back_transcription_method(self): <TAB> for nucleotide_seq in test_seqs: <MASK> expected = Seq.back_transcribe(nucleotide_seq) <TAB>  <TAB>  <TAB> self.assertEqual(repr(nucleotide_seq.back_transcribe()), repr(expected))","if isinstance ( nucleotide_seq , Seq . Seq ) :",96
"def validate_email(form, field): <TAB> user_manager = current_app.user_manager <TAB> if user_manager.USER_SHOW_EMAIL_DOES_NOT_EXIST: <TAB>  <TAB> user, user_email = user_manager.db_manager.get_user_and_user_email_by_email( <TAB>  <TAB>  <TAB> field.data <TAB>  <TAB> ) <MASK> raise ValidationError( <TAB>  <TAB>  <TAB>  <TAB> _(""%(username_or_email)s does not exist"", username_or_email=_(""Email"")) <TAB>  <TAB>  <TAB> )",if not user :,129
"def set_task_status_message(self, task_id, status_message): <TAB> if self._state.has_task(task_id): <TAB>  <TAB> task = self._state.get_task(task_id) <TAB>  <TAB> task.status_message = status_message <MASK> for batch_task in self._state.get_batch_running_tasks(task.batch_id): <TAB>  <TAB>  <TAB>  <TAB> batch_task.status_message = status_message",if task . status == RUNNING and task . batch_id is not None :,127
"def send(self, message, *addr): <TAB> if message.should_respond: <TAB>  <TAB> # self.server.control.Counter.BusMessage += 1 <TAB>  <TAB> pdu = self.framer.buildPacket(message) <TAB>  <TAB> if _logger.isEnabledFor(logging.DEBUG): <TAB>  <TAB>  <TAB> _logger.debug(""send: [%s]- %s"" % (message, b2a_hex(pdu))) <MASK> self._send_(pdu) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._send_(pdu, *addr)","if addr == ( None , ) :",136
def lazy_seq_seq(self): <TAB> self.sval() <TAB> if self._s is not nil: <TAB>  <TAB> ls = self._s <TAB>  <TAB> while True: <MASK> ls = ls.sval() <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._s = ls <TAB>  <TAB>  <TAB>  <TAB> return rt.seq(self._s) <TAB> else: <TAB>  <TAB> return nil,"if isinstance ( ls , LazySeq ) :",112
"def scan(self, result): <TAB> if result.valid and result.display: <TAB>  <TAB> if result.description.lower().startswith(""zip archive data""): <MASK> result.extract = False <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.extraction_active = True <TAB>  <TAB> elif result.description.lower().startswith(""end of zip archive""): <TAB>  <TAB>  <TAB> self.extraction_active = False",if self . extraction_active :,102
"def validate(self, chunk): <TAB> existing_items = set() <TAB> for item in chunk.expect_sequence(""when expecting a unique sequence""): <MASK> chunk.while_parsing_found(""a sequence"", ""duplicate found"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> existing_items.add(item.contents) <TAB>  <TAB>  <TAB> item.process(self._validator(item))",if item . contents in existing_items :,97
"def pick_file(folder): <TAB> """"""Return a random file from the specified folder."""""" <TAB> folder = os.path.expanduser(folder) <TAB> if os.path.isdir(folder): <TAB>  <TAB> listFiles = [ <TAB>  <TAB>  <TAB> _f <TAB>  <TAB>  <TAB> for _f in os.listdir(folder) <MASK> ] <TAB>  <TAB> if len(listFiles) == 0: <TAB>  <TAB>  <TAB> return ""No Files found in {}"".format(folder) <TAB>  <TAB> return random.choice(listFiles) <TAB> else: <TAB>  <TAB> return ""{} is not a valid folder"".format(folder)","if not os . path . isdir ( os . path . join ( folder , _f ) )",154
"def get_config(): <TAB> """"""Get INI parser with version.ini data."""""" <TAB> # TODO(hanuszczak): See comment in `setup.py` for `grr-response-proto`. <TAB> ini_path = os.path.join(THIS_DIRECTORY, ""version.ini"") <MASK> ini_path = os.path.join(THIS_DIRECTORY, ""../version.ini"") <TAB>  <TAB> if not os.path.exists(ini_path): <TAB>  <TAB>  <TAB> raise RuntimeError(""Couldn't find version.ini"") <TAB> config = configparser.SafeConfigParser() <TAB> config.read(ini_path) <TAB> return config",if not os . path . exists ( ini_path ) :,156
"def _formats(self): <TAB> res = [] <TAB> for c, t in enumerate(self._datatypes): <TAB>  <TAB> if t == str: <TAB>  <TAB>  <TAB> items = [ <TAB>  <TAB>  <TAB>  <TAB> len(self._split(l)[c]) <TAB>  <TAB>  <TAB>  <TAB> for l in self._reallines[1:] <TAB>  <TAB>  <TAB>  <TAB> if self._datatypes_of_line(l) == self._datatypes <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB> items.append(1) <TAB>  <TAB>  <TAB> res.append(""S%i"" % max(items)) <MASK> res.append(t) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError(""Hmm, did not expect: %r"" % t) <TAB> return tuple(res)",elif t == float :,173
"def locate(path, forceload=0): <TAB> """"""Locate an object by name or dotted path, importing as necessary."""""" <TAB> parts = [part for part in path.split(""."") if part] <TAB> module, n = None, 0 <TAB> while n < len(parts): <TAB>  <TAB> nextmodule = safeimport(""."".join(parts[: n + 1]), forceload) <MASK> module, n = nextmodule, n + 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> if module: <TAB>  <TAB> object = module <TAB> else: <TAB>  <TAB> object = builtins <TAB> for part in parts[n:]: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> object = getattr(object, part) <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB> return None <TAB> return object",if nextmodule :,176
"def count(e): <TAB> tot = 0 <TAB> for y in range(0, height): <TAB>  <TAB> for x in range(0, width): <MASK> tot += 1 <TAB> return tot",if elevation [ y ] [ x ] > e and ( ocean is None or not ocean [ y ] [ x ] ) :,78
"def __init__(self, die, types, parents): <TAB> super(DW_TAG_member, self).__init__(die, types, parents) <TAB> # Add ourselves to our parent struct. <TAB> self.parent.members.append(self) <TAB> if ""DW_AT_data_member_location"" in self.attributes: <TAB>  <TAB> value = self.attributes[""DW_AT_data_member_location""].value <MASK> self.offset = value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> op_code, value = describe_DWARF_expr(value, die.cu.structs) <TAB>  <TAB>  <TAB> if op_code == ""DW_OP_plus_uconst"": <TAB>  <TAB>  <TAB>  <TAB> self.offset = int(value)","if isinstance ( value , ( int , long ) ) :",183
"def main(): <TAB> import os <TAB> for i, filename in enumerate(os.listdir(""witchcraft_dist"")): <TAB>  <TAB> if i % 8 != int(sys.argv[1]): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> solution_file = ""%s.solution"" % filename <MASK> continue <TAB>  <TAB> print(i, filename) <TAB>  <TAB> sol = solve(filename) <TAB>  <TAB> # data = sol.encode(""base64"") <TAB>  <TAB> with open(solution_file, ""wb"") as f: <TAB>  <TAB>  <TAB> f.write(sol)",if os . path . exists ( solution_file ) :,137
def _fork_rng(self): <TAB> with fork_rng(cuda=self.cuda): <MASK> set_random_generator_state(self.rng_state) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> set_seed(self.random_seed) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> yield <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self.rng_state = get_random_generator_state(cuda=self.cuda),if self . rng_state is not None :,111
"def _wait_build_state( <TAB> client, build_id, desired_phase: Optional[str], desired_states: List[str]) -> Dict[str, Any]: <TAB> """"""Wait until the build is in one of the desired states, or in the desired phase."""""" <TAB> while True: <TAB>  <TAB> resp = client.batch_get_builds(ids=[build_id]) <TAB>  <TAB> assert len(resp[""builds""]) == 1 <TAB>  <TAB> build = resp[""builds""][0] <MASK> return build <TAB>  <TAB> for phase in build[""phases""]: <TAB>  <TAB>  <TAB> if desired_phase and (phase[""phaseType""] == desired_phase): <TAB>  <TAB>  <TAB>  <TAB> return build <TAB>  <TAB> await asyncio.sleep(2)","if build [ ""buildStatus"" ] in desired_states :",180
"def _process(self, grads): <TAB> ret = [] <TAB> matched = False <TAB> for grad, var in grads: <TAB>  <TAB> if re.match(self.regex, var.op.name): <TAB>  <TAB>  <TAB> matched = True <TAB>  <TAB>  <TAB> grad = self.func(grad, var) <MASK> ret.append((grad, var)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret.append((grad, var)) <TAB> if not matched: <TAB>  <TAB> logger.warn(""[MapGradient] No match was found for regex {}."".format(self.regex)) <TAB> return ret",if grad is not None :,140
"def all_presets(): <TAB> result = [] <TAB> for f in sorted(os.listdir(""rl_coach/presets"")): <TAB>  <TAB> if f.endswith("".py"") and f != ""__init__.py"": <TAB>  <TAB>  <TAB> preset = f.split(""."")[0] <MASK> result.append(preset) <TAB> return result",if preset not in FAILING_PRESETS :,94
"def _escape_cdata(text, encoding): <TAB> # escape character data <TAB> try: <TAB>  <TAB> # it's worth avoiding do-nothing calls for strings that are <TAB>  <TAB> # shorter than 500 character, or so.  assume that's, by far, <TAB>  <TAB> # the most common case in most applications. <MASK> text = text.replace(""&"", ""&amp;"") <TAB>  <TAB> if ""<"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""<"", ""&lt;"") <TAB>  <TAB> if "">"" in text: <TAB>  <TAB>  <TAB> text = text.replace("">"", ""&gt;"") <TAB>  <TAB> return text.encode(encoding, ""xmlcharrefreplace"") <TAB> except (TypeError, AttributeError): <TAB>  <TAB> _raise_serialization_error(text)","if ""&"" in text :",166
"def cache_buster(context, url): <TAB> if ""BUILD_ID"" in context: <TAB>  <TAB> build = context[""BUILD_ID""] <TAB> else: <MASK> build = context[""BUILD_ID_JS""] <TAB>  <TAB> elif url.endswith("".css""): <TAB>  <TAB>  <TAB> build = context[""BUILD_ID_CSS""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> build = context[""BUILD_ID_IMG""] <TAB> return utils.urlparams(url, b=build)","if url . endswith ( "".js"" ) :",118
"def add(userId, password, inobj, session=None): <TAB> if not session: <TAB>  <TAB> session = db.Session() <TAB> # our_result = session.query(User).filter_by(userId=userId, password=password).first() <TAB> our_result = session.query(User).filter_by(userId=userId).first() <TAB> if not our_result: <TAB>  <TAB> our_result = User(userId=userId, password=password) <MASK> inobj[""created_at""] = int(time.time()) <TAB>  <TAB> our_result.update(inobj) <TAB>  <TAB> session.add(our_result) <TAB> else: <TAB>  <TAB> inobj[""password""] = password <TAB>  <TAB> our_result.update(inobj) <TAB> return True","if ""created_at"" not in inobj :",196
"def parse(cls, selector): <TAB> with contextlib.closing(StringIO()) as result: <MASK> for k, v in selector.items(): <TAB>  <TAB>  <TAB>  <TAB> result.write(""%s:(%s)"" % (to_utf8(k), cls.parse(v))) <TAB>  <TAB> elif type(selector) in (list, tuple): <TAB>  <TAB>  <TAB> result.write("","".join(map(cls.parse, selector))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result.write(to_utf8(selector)) <TAB>  <TAB> return result.getvalue()",if type ( selector ) == dict :,133
"def init_from(cls, other, **kwargs): <TAB> retval = (cls if cls.__orig__ is None else cls.__orig__)() <TAB> for k, v in cls.get_flat_type_info(cls).items(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if k in kwargs: <TAB>  <TAB>  <TAB>  <TAB> retval._safe_set(k, kwargs[k], v, v.Attributes) <MASK> retval._safe_set(k, getattr(other, k), v, v.Attributes) <TAB>  <TAB> except AttributeError as e: <TAB>  <TAB>  <TAB> logger.warning(""Error setting %s: %r"", k, e) <TAB> return retval","elif hasattr ( other , k ) :",158
"def wheelEvent(self, event): <TAB> if event.modifiers() == Qt.ControlModifier: <MASK> self.zoom_in() <TAB>  <TAB> elif event.angleDelta().y() == -120: <TAB>  <TAB>  <TAB> self.zoom_out() <TAB>  <TAB> event.ignore() <TAB> else: <TAB>  <TAB> QPlainTextEdit.wheelEvent(self, event)",if event . angleDelta ( ) . y ( ) == 120 :,99
"def get_repository(self, user, repo): <TAB> try: <TAB>  <TAB> return self.gl.projects.get(""{}/{}"".format(user, repo)) <TAB> except GitlabGetError as err: <MASK> raise ResourceNotFoundError( <TAB>  <TAB>  <TAB>  <TAB> ""Cannot get: repository {}/{} does not exists."".format(user, repo) <TAB>  <TAB>  <TAB> ) from err",if err . response_code == 404 :,93
"def __iter__(self): <TAB> if self.iter_timeout is None: <TAB>  <TAB> timeout = ITER_TIMEOUT_SECONDS <TAB> else: <TAB>  <TAB> timeout = self.iter_timeout <TAB> while True: <TAB>  <TAB> message = self.get_message(True, timeout) <MASK> yield message <TAB>  <TAB> elif self.iter_timeout is None: <TAB>  <TAB>  <TAB> # We did not receive any message yet but we don't have a <TAB>  <TAB>  <TAB> # timeout, so give up the CPU for a while before trying again <TAB>  <TAB>  <TAB> time.sleep(NO_MESSAGES_WAIT_TIME_SECONDS) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Timed out waiting for a message <TAB>  <TAB>  <TAB> break",if message :,163
"def load_weights(target_layers, source): <TAB> for target in target_layers: <MASK> target.load_weights(source[target.name], load_states=True) <TAB>  <TAB>  <TAB> print(target.name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""SKIPPING: {}"".format(target.name))","if hasattr ( target , ""W"" ) :",85
"def _propagate_packages(self): <TAB> """"""Make sure packages get propagated."""""" <TAB> for item in self.data: <MASK> if isinstance(item, Container): <TAB>  <TAB>  <TAB>  <TAB> item._propagate_packages() <TAB>  <TAB>  <TAB> for p in item.packages: <TAB>  <TAB>  <TAB>  <TAB> self.packages.add(p)","if isinstance ( item , LatexObject ) :",85
"def create_unified_job(self, **kwargs): <TAB> # Use special name, if name not already specified <TAB> if self.inventory: <MASK> kwargs[""_eager_fields""] = {} <TAB>  <TAB> if ""name"" not in kwargs[""_eager_fields""]: <TAB>  <TAB>  <TAB> name = ""{} - {}"".format(self.inventory.name, self.name) <TAB>  <TAB>  <TAB> name_field = self._meta.get_field(""name"") <TAB>  <TAB>  <TAB> if len(name) > name_field.max_length: <TAB>  <TAB>  <TAB>  <TAB> name = name[: name_field.max_length] <TAB>  <TAB>  <TAB> kwargs[""_eager_fields""][""name""] = name <TAB> return super(InventorySource, self).create_unified_job(**kwargs)","if ""_eager_fields"" not in kwargs :",178
"def handle(self, connection_id, message_content): <TAB> for batch in message_content.batches: <MASK> LOGGER.debug( <TAB>  <TAB>  <TAB>  <TAB> ""TRACE %s: %s"", batch.header_signature, self.__class__.__name__ <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self._completer.add_batch(batch) <TAB>  <TAB> self._gossip.broadcast_batch(batch) <TAB> return HandlerResult(status=HandlerStatus.PASS)",if batch . trace :,113
"def __setattr__(self, attr, value): <TAB> if hasattr(self, ""_attributes"") and attr in self._attributes: <TAB>  <TAB> attrValue = getattr(self, ""_"" + attr) <TAB>  <TAB> if isinstance(attrValue, Color): <TAB>  <TAB>  <TAB> # Ensure Color attributes are of type Color <TAB>  <TAB>  <TAB> value = Color(value) <MASK> object.__setattr__(self, ""_"" + attr, value) <TAB>  <TAB>  <TAB> self.changed() <TAB> else: <TAB>  <TAB> object.__setattr__(self, attr, value)",if attrValue != value :,125
"def __virtual__(): <TAB> if HAS_DOCKERCOMPOSE: <TAB>  <TAB> match = re.match(VERSION_RE, six.text_type(compose.__version__)) <MASK> version = tuple([int(x) for x in match.group(1).split(""."")]) <TAB>  <TAB>  <TAB> if version >= MIN_DOCKERCOMPOSE: <TAB>  <TAB>  <TAB>  <TAB> return __virtualname__ <TAB> return ( <TAB>  <TAB> False, <TAB>  <TAB> ""The dockercompose execution module not loaded: "" <TAB>  <TAB> ""compose python library not available."", <TAB> )",if match :,131
"def mark(self, cves, **args): <TAB> for plugin in self.getWebPlugins(): <TAB>  <TAB> for cve in cves: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> marks = plugin.mark(cve[""id""], **args) <TAB>  <TAB>  <TAB>  <TAB> if marks and type(marks) == tuple and len(marks) == 2: <MASK> cve[""icon""] = marks[0] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if marks[1]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> cve[""color""] = marks[1] <TAB>  <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB>  <TAB> print(""[!] Plugin %s failed on marking cves!"" % plugin.getName()) <TAB>  <TAB>  <TAB>  <TAB> print(""[!]  -> %s"" % e) <TAB> return cves",if marks [ 0 ] :,189
"def items(self, multi=False): <TAB> ptr = self._first_bucket <TAB> if multi: <TAB>  <TAB> while ptr is not None: <TAB>  <TAB>  <TAB> yield ptr.key, ptr.value <TAB>  <TAB>  <TAB> ptr = ptr.next <TAB> else: <TAB>  <TAB> returned_keys = set() <TAB>  <TAB> while ptr is not None: <MASK> returned_keys.add(ptr.key) <TAB>  <TAB>  <TAB>  <TAB> yield ptr.key, ptr.value <TAB>  <TAB>  <TAB> ptr = ptr.next",if ptr . key not in returned_keys :,127
"def cycleTabFocus(self, event=None, stop_w=None): <TAB> """"""Cycle keyboard focus between the tabs in the log pane."""""" <TAB> c = self.c <TAB> d = self.frameDict  # Keys are page names. Values are Tk.Frames. <TAB> w = d.get(self.tabName) <TAB> # g.trace(self.tabName,w) <TAB> values = d.values() <TAB> if self.numberOfVisibleTabs() > 1: <TAB>  <TAB> i = i2 = values.index(w) + 1 <MASK> i = 0 <TAB>  <TAB> tabName = d.keys()[i] <TAB>  <TAB> self.selectTab(tabName) <TAB>  <TAB> return",if i == len ( values ) :,171
"def node_labels(self, values): <TAB> if values is None: <TAB>  <TAB> self._node_labels = None <TAB> else: <TAB>  <TAB> values = np.asarray(values) <TAB>  <TAB> if (values.ndim < 1) or (values.shape[0] != self.n): <TAB>  <TAB>  <TAB> raise ValueError(""node_labels must be an array_like of length n"") <MASK> raise ValueError(""data in node_labels must be homogeneous in type"") <TAB>  <TAB> self._node_labels = values","if np . issubdtype ( values . dtype , np . object_ ) :",132
"def _CheckNestedClasses(typ, parent): <TAB> with _lazyLock: <TAB>  <TAB> vmodlName = typ.__name__ <TAB>  <TAB> nestedClasses = _dependencyMap.get(vmodlName, []) <TAB>  <TAB> for nestedClass in nestedClasses: <MASK> setattr(typ, nestedClass, GetVmodlType(vmodlName + ""."" + nestedClass)) <TAB>  <TAB> return typ","if hasattr ( parent , nestedClass ) :",103
"def create_session(self, dburi, short_lived_sessions=False, **kwargs): <TAB> engine = self.get_engine(dburi, **kwargs) <TAB> if self.forked: <MASK> self._sessions[dburi] = sessionmaker(bind=engine) <TAB>  <TAB> return engine, self._sessions[dburi] <TAB> else: <TAB>  <TAB> return engine, sessionmaker(bind=engine)",if short_lived_sessions or dburi not in self . _sessions :,115
"def _documented(rst_path): <TAB> documented = set() <TAB> for line in open(rst_path): <TAB>  <TAB> match = doc_re.match(line.rstrip()) <MASK> directive = match.group(1) <TAB>  <TAB>  <TAB> symbol = match.group(2) <TAB>  <TAB>  <TAB> if directive not in [""module"", ""ipython""]: <TAB>  <TAB>  <TAB>  <TAB> documented.add(symbol) <TAB> return documented",if match :,100
"def merge(*roots, merged=True, deps=None): <TAB> graph = Graph() <TAB> for root in roots: <TAB>  <TAB> graph.add(root) <TAB> resolver = Resolver(graph=graph, mutator=Mutator()) <TAB> resolved = resolver.resolve(level=1) <TAB> try: <TAB>  <TAB> assert merged == resolved <TAB> except AssertionError: <MASK> print(analyze_conflict(resolver=resolver)) <TAB>  <TAB> raise <TAB> if deps: <TAB>  <TAB> for dep in deps: <TAB>  <TAB>  <TAB> assert dep in resolver.graph <TAB>  <TAB> names = set(resolver.graph.names) - {root.name for root in roots} <TAB>  <TAB> assert names == set(deps) <TAB> return resolver",if resolved is False :,167
"def blob_exists(self, media_link): <TAB> try: <TAB>  <TAB> blob = parse_blob_url(media_link) <MASK> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> ""storage {0} provided in the deployment specification "" <TAB>  <TAB>  <TAB>  <TAB> ""doesn't match the storage of BLOB {1}"".format(self.storage, media_link) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if blob is None: <TAB>  <TAB>  <TAB> raise Exception(""failed to parse BLOB URL {0}"".format(media_link)) <TAB>  <TAB> self.bs().get_blob_properties(blob[""container""], blob[""name""]) <TAB>  <TAB> return True <TAB> except azure.common.AzureMissingResourceHttpError: <TAB>  <TAB> return False","if blob [ ""storage"" ] != self . storage :",174
"def task(self): <TAB> while self.active: <MASK> self.update_hashes() <TAB>  <TAB> if self.hashes: <TAB>  <TAB>  <TAB> for string, hash in self.get_new_passwords(): <TAB>  <TAB>  <TAB>  <TAB> self.append((string, hash)) <TAB>  <TAB> time.sleep(self.poll)",if self . autoupdate :,81
"def test_check_presence(self): <TAB> # make sure all example scripts have a test method defined <TAB> meths = dir(self) <TAB> for name in os.listdir(EXAMPLES_DIR): <MASK> if ""test_"" + os.path.splitext(name)[0] not in meths: <TAB>  <TAB>  <TAB>  <TAB> # self.assert_stdout(name) <TAB>  <TAB>  <TAB>  <TAB> self.fail( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""no test defined for %r script"" % os.path.join(EXAMPLES_DIR, name) <TAB>  <TAB>  <TAB>  <TAB> )","if name . endswith ( "".py"" ) :",137
"def process_batch_data(input_data, settings, mode, color_jitter, rotate): <TAB> batch_data = [] <TAB> for sample in input_data: <MASK> batch_data.append( <TAB>  <TAB>  <TAB>  <TAB> process_image(sample, settings, mode, color_jitter, rotate) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""File not exist : %s"" % sample[0]) <TAB> return batch_data",if os . path . isfile ( sample [ 0 ] ) :,117
"def find_library(name): <TAB> if name in (""c"", ""m""): <TAB>  <TAB> return find_msvcrt() <TAB> # See MSDN for the REAL search order. <TAB> for directory in os.environ[""PATH""].split(os.pathsep): <TAB>  <TAB> fname = os.path.join(directory, name) <TAB>  <TAB> if os.path.isfile(fname): <TAB>  <TAB>  <TAB> return fname <MASK> continue <TAB>  <TAB> fname = fname + "".dll"" <TAB>  <TAB> if os.path.isfile(fname): <TAB>  <TAB>  <TAB> return fname <TAB> return None","if fname . lower ( ) . endswith ( "".dll"" ) :",141
"def gen_ctes(self, ctes): <TAB> self.write(""WITH"") <TAB> count = len(ctes) <TAB> for i, cte in enumerate(ctes): <TAB>  <TAB> self.new_lines = 1 <MASK> self.write(""RECURSIVE "") <TAB>  <TAB> self.write(common.quote_ident(cte.name)) <TAB>  <TAB> self.write("" AS "") <TAB>  <TAB> self.indentation += 1 <TAB>  <TAB> self.new_lines = 1 <TAB>  <TAB> self.write(""("") <TAB>  <TAB> self.visit(cte.query) <TAB>  <TAB> self.write("")"") <TAB>  <TAB> if i != count - 1: <TAB>  <TAB>  <TAB> self.write("","") <TAB>  <TAB> self.indentation -= 1 <TAB> self.new_lines = 1","if getattr ( cte , ""recursive"" , None ) :",176
"def check_and_create_items(self, op_get, op_create, items, **data_create): <TAB> """"""Create the items if they don't exist already"""""" <TAB> for item in items: <TAB>  <TAB> ret = self.execute_rpc(op_get, name=item) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> data_create[""name""] = item <TAB>  <TAB>  <TAB>  <TAB> self.execute_rpc(op_create, **data_create) <TAB>  <TAB>  <TAB> except CliError: <TAB>  <TAB>  <TAB>  <TAB> continue",if len ( ret ) == 0 :,132
"def date(self, value): <TAB> delta = value - self._date if self._date else None <TAB> self._date = value <TAB> self.cmdline.default_day = value <TAB> if self.fact and delta: <TAB>  <TAB> if self.fact.start_time: <TAB>  <TAB>  <TAB> self.fact.start_time += delta <MASK> self.fact.end_time += delta",if self . fact . end_time :,100
"def hybrid_forward(self, F, *inputs, **kwargs): <TAB> """"""Compute loss"""""" <TAB> if self.aux: <MASK> return self._aux_mixup_forward(F, *inputs, **kwargs) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self._aux_forward(F, *inputs, **kwargs) <TAB> else: <TAB>  <TAB> if self.mixup: <TAB>  <TAB>  <TAB> return self._mixup_forward(F, *inputs, **kwargs) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return super(MixSoftmaxCrossEntropyLoss, self).hybrid_forward( <TAB>  <TAB>  <TAB>  <TAB> F, *inputs, **kwargs <TAB>  <TAB>  <TAB> )",if self . mixup :,158
"def in_brackets(index, string): <TAB> """"""Returns true if index is between a pair of brackets (could be non closing)"""""" <TAB> left_b = list(""({["") <TAB> right_b = list("")}]"") <TAB> count = dict([(l, 0) for l in left_b]) <TAB> index = index - 1  # Look to the character to the left to start <TAB> while index > 0: <TAB>  <TAB> char = string[index] <MASK> if count[char] == 0: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> count[char] -= 1 <TAB>  <TAB> elif char in right_b: <TAB>  <TAB>  <TAB> count[brackets[char]] += 1 <TAB>  <TAB> index -= 1 <TAB> return False",if char in left_b :,179
"def result_item(self, item, obj, field_name, row): <TAB> if self._current_layout == ""thumbnails"": <MASK> item.field_label = label_for_field( <TAB>  <TAB>  <TAB>  <TAB> field_name, self.model, model_admin=self.admin_view, return_attr=False <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if getattr(item.attr, ""thumbnail_img"", False): <TAB>  <TAB>  <TAB> setattr(item, ""thumbnail_hidden"", True) <TAB>  <TAB>  <TAB> row[""thumbnail_img""] = item <TAB>  <TAB> elif item.is_display_link: <TAB>  <TAB>  <TAB> setattr(item, ""thumbnail_hidden"", True) <TAB>  <TAB>  <TAB> row[""thumbnail_label""] = item <TAB> return item","if getattr ( item . attr , ""is_column"" , True ) :",183
"def convert(module, flag_name): <TAB> mod = module <TAB> before_ch = None <TAB> for name, child in module.named_children(): <TAB>  <TAB> if hasattr(child, flag_name) and getattr(child, flag_name): <MASK> before_ch = child.num_features <TAB>  <TAB>  <TAB>  <TAB> mod.add_module(name, FRN(num_features=child.num_features)) <TAB>  <TAB>  <TAB> # TODO bn is no good... <TAB>  <TAB>  <TAB> if isinstance(child, (ReLU, LeakyReLU)): <TAB>  <TAB>  <TAB>  <TAB> mod.add_module(name, TLU(num_features=before_ch)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> mod.add_module(name, convert(child, flag_name)) <TAB> return mod","if isinstance ( child , BatchNorm2d ) :",187
"def head_fields_to_headers(head_fields): <TAB> headers = oss2.CaseInsensitiveDict() <TAB> for header_kv in head_fields: <TAB>  <TAB> kv = header_kv.split("":"", 1) <MASK> headers[kv[0].strip()] = kv[1].strip() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> headers[kv[0].strip()] = """" <TAB> return headers",if len ( kv ) == 2 :,103
"def read_csv(l, dialect, fin=next): <TAB> try: <TAB>  <TAB> return fin(csv.reader(l, dialect)) <TAB> except csv.Error as e: <MASK> # Maybe we are inside an unfinished quoted string. Python-2.6 <TAB>  <TAB>  <TAB> # does not handle this fine <TAB>  <TAB>  <TAB> return fin(csv.reader(l[:-1] + [l[-1] + dialect.quotechar])) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise","if str ( e ) == ""newline inside string"" and dialect . quotechar :",125
"def verify_naive(self): <TAB> model_class = self.model_class <TAB> for node in self._select: <TAB>  <TAB> if isinstance(node, Field) and node.model_class != model_class: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> elif isinstance(node, Node) and node._bind_to is not None: <MASK> return False <TAB> return True",if node . _bind_to != model_class :,101
"def __doWork(self): <TAB> """"""Pops work from the queue and returns the proxy and last log line"""""" <TAB> # pylint: disable=broad-except <TAB> try: <TAB>  <TAB> if self.__queue: <TAB>  <TAB>  <TAB> (proxy, path) = self.__queue.popitem() <MASK> return ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> proxy, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> cuegui.Utils.getLastLine(path), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> cuegui.Utils.secondsToHHMMSS(time.time() - os.stat(path).st_mtime), <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return None <TAB> except Exception as e: <TAB>  <TAB> list(map(logger.warning, cuegui.Utils.exceptionOutput(e)))",if os . path . exists ( path ) :,182
def drive_and_check(): <TAB> for i in range(signal_list_length): <TAB>  <TAB> input_signal_list[i].next = update_val <TAB> if __debug__: <MASK> for i in range(signal_list_length): <TAB>  <TAB>  <TAB>  <TAB> assert output_signal_list[i] == expected_output[i] <TAB>  <TAB>  <TAB> first[0] = False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for i in range(signal_list_length): <TAB>  <TAB>  <TAB>  <TAB> assert output_signal_list[i] == update_val,if first [ 0 ] :,135
"def _resolver(instance, *args, **kwargs): <TAB> log.debug( <TAB>  <TAB> ""Locally calling %s.%s with arguments %s."", <TAB>  <TAB> instance.FQN(), <TAB>  <TAB> method.__name__, <TAB>  <TAB> args, <TAB> ) <TAB> try: <TAB>  <TAB> value = method(instance, *args, **kwargs) <MASK> raise InvocationException( <TAB>  <TAB>  <TAB>  <TAB> ""Local handler does not implement %s.%s!"" <TAB>  <TAB>  <TAB>  <TAB> % (instance.FQN(), method.__name__) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return value <TAB> except InvocationException: <TAB>  <TAB> raise <TAB> except Exception as e: <TAB>  <TAB> raise InvocationException( <TAB>  <TAB>  <TAB> ""A problem occured calling %s.%s!"" % (instance.FQN(), method.__name__), e <TAB>  <TAB> )",if value == NotImplemented :,193
"def evex_mask_dest_mem(ii):  # optional imm8 <TAB> i, msk, xyz, mem = 0, 0, 0, 0 <TAB> for op in _gen_opnds(ii): <MASK> msk += 1 <TAB>  <TAB> elif op_xmm(op) or op_ymm(op) or op_zmm(op): <TAB>  <TAB>  <TAB> xyz += 1 <TAB>  <TAB> elif op_mem(op): <TAB>  <TAB>  <TAB> mem += 1 <TAB>  <TAB> elif op_imm8(op): <TAB>  <TAB>  <TAB> i += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> return msk == 1 and xyz > 0 and i <= 1 and mem == 1",if op_mask_reg ( op ) :,169
"def get_tags(self): <TAB> """"""Returns current selected tags, or None for all tags"""""" <TAB> tags = [] <TAB> for row in self._get_selected(): <MASK> tags.append(row[0]) <TAB>  <TAB> elif row[2] == self._type_untagged: <TAB>  <TAB>  <TAB> tags.append(_NO_TAGS) <TAB> return tags or None",if row [ 2 ] == self . _type_tag :,98
"def _partial_flush(self, max_retain): <TAB> byts = self._bd.get_all() <TAB> cursor = memoryview(byts) <TAB> flushed = False <TAB> while len(cursor) > max_retain: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> n = os.write(self._fd, cursor) <TAB>  <TAB>  <TAB> flushed = True <TAB>  <TAB>  <TAB> cursor = memoryview(cursor)[n:] <TAB>  <TAB> except EnvironmentError as e: <MASK> gevent.socket.wait_write(self._fd) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise <TAB> assert self._bd.byteSz == 0 <TAB> if len(cursor) > 0: <TAB>  <TAB> self._bd.add(cursor) <TAB> return flushed","if e . errno in [ errno . EAGAIN , errno . EWOULDBLOCK ] :",191
"def on_task_learn(self, task, config): <TAB> if not config: <TAB>  <TAB> return <TAB> with Session() as session: <TAB>  <TAB> # Delete all accepted entries that have passed the pending phase <TAB>  <TAB> for entry in task.accepted: <MASK> db_entry = self._item_query(entry, task, session) <TAB>  <TAB>  <TAB>  <TAB> if db_entry and db_entry.approved: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> log.debug(""deleting approved entry %s"", db_entry) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> session.delete(db_entry)","if entry . get ( ""approved"" ) :",139
"def valid_add_kwargs() -> Dict[str, Set[str]]: <TAB> """"""Return a dict where keys are layer types & values are valid kwargs."""""" <TAB> valid = dict() <TAB> for meth in dir(ViewerModel): <MASK> continue <TAB>  <TAB> params = inspect.signature(getattr(ViewerModel, meth)).parameters <TAB>  <TAB> valid[meth[4:]] = set(params) - {""self"", ""kwargs""} <TAB> return valid","if not meth . startswith ( ""add_"" ) or meth [ 4 : ] == ""layer"" :",119
"def __getattr__(self, item: str) -> Any: <TAB> if hasattr(MissingPandasLikeMultiIndex, item): <TAB>  <TAB> property_or_func = getattr(MissingPandasLikeMultiIndex, item) <MASK> return property_or_func.fget(self)  # type: ignore <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return partial(property_or_func, self) <TAB> raise AttributeError(""'MultiIndex' object has no attribute '{}'"".format(item))","if isinstance ( property_or_func , property ) :",114
"def find_binary(self, filenames, exts, paths): <TAB> for f in filenames: <TAB>  <TAB> for ext in exts: <TAB>  <TAB>  <TAB> exe_name = f + ext <TAB>  <TAB>  <TAB> if os.path.isabs(exe_name): <MASK> return exe_name <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> for path in paths: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> x = os.path.expanduser(os.path.join(path, exe_name)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if os.path.isfile(x): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return x <TAB> return None",if os . path . isfile ( exe_name ) :,151
"def _build_lines(self, lines): <TAB> max_key_len = 1 <TAB> headerlines = [] <TAB> # calc max length of key-string <TAB> for key, value in lines: <MASK> max_key_len = len(key) <TAB> for key, value in lines: <TAB>  <TAB> # todo : even/odd <TAB>  <TAB> keyw = (""fixed"", max_key_len + 1, urwid.Text((self.key_attr, key))) <TAB>  <TAB> valuew = urwid.Text((self.value_attr, value)) <TAB>  <TAB> line = urwid.Columns([keyw, valuew]) <TAB>  <TAB> headerlines.append(line) <TAB> return headerlines",if len ( key ) > max_key_len :,179
"def ValidateFrequencies(self, problems): <TAB> # O(n^2), but we don't anticipate many headway periods per trip <TAB> for headway_index, headway in enumerate(self._headways[0:-1]): <TAB>  <TAB> for other in self._headways[headway_index + 1 :]: <MASK> problems.OtherProblem( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Trip contains overlapping headway periods "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""%s and %s"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> % ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._HeadwayOutputTuple(headway), <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._HeadwayOutputTuple(other), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> )",if ( other [ 0 ] < headway [ 1 ] ) and ( other [ 1 ] > headway [ 0 ] ) :,190
"def _children(self): <TAB> result = [] <TAB> added = set() <TAB> matcher = ""/"".join(self[:]) + ""/*"" if len(self) else ""*"" <TAB> for n in self.__classLoader.classNames(matcher): <TAB>  <TAB> child = ClassLoaderPath( <TAB>  <TAB>  <TAB> self.__classLoader, self.root() + n, filter=self.getFilter() <TAB>  <TAB> ) <TAB>  <TAB> while len(child) > len(self) + 1: <TAB>  <TAB>  <TAB> del child[-1] <MASK> result.append(child) <TAB>  <TAB>  <TAB> added.add(str(child)) <TAB> return result",if str ( child ) not in added :,152
"def _model_shorthand(self, args): <TAB> accum = [] <TAB> for arg in args: <TAB>  <TAB> if isinstance(arg, Node): <TAB>  <TAB>  <TAB> accum.append(arg) <MASK> accum.append(arg) <TAB>  <TAB> elif isinstance(arg, ModelAlias): <TAB>  <TAB>  <TAB> accum.extend(arg.get_proxy_fields()) <TAB>  <TAB> elif isclass(arg) and issubclass(arg, Model): <TAB>  <TAB>  <TAB> accum.extend(arg._meta.get_fields()) <TAB> return accum","elif isinstance ( arg , Query ) :",125
"def file_date(theFile, format=None): <TAB> if theFile and g.os_path_exists(theFile): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> n = g.os_path_getmtime(theFile) <MASK> format = ""%m/%d/%y %H:%M:%S"" <TAB>  <TAB>  <TAB> return time.strftime(format, time.gmtime(n)) <TAB>  <TAB> except (ImportError, NameError): <TAB>  <TAB>  <TAB> pass  # Time module is platform dependent. <TAB> return """"",if format is None :,124
"def _tokenize(plural): <TAB> for mo in re.finditer(_token_pattern, plural): <TAB>  <TAB> kind = mo.lastgroup <MASK> continue <TAB>  <TAB> value = mo.group(kind) <TAB>  <TAB> if kind == ""INVALID"": <TAB>  <TAB>  <TAB> raise ValueError(""invalid token in plural form: %s"" % value) <TAB>  <TAB> yield value <TAB> yield """"","if kind == ""WHITESPACES"" :",94
"def pytest_collection_modifyitems(items): <TAB> for item in items: <MASK> if ""perf"" not in item.keywords: <TAB>  <TAB>  <TAB>  <TAB> item.add_marker(pytest.mark.stage(""perf"")) <TAB>  <TAB>  <TAB> if ""init"" not in item.keywords: <TAB>  <TAB>  <TAB>  <TAB> item.add_marker(pytest.mark.init(rng_seed=123))","if item . nodeid . startswith ( ""tests/perf"" ) :",102
"def process(self, resources, events=None): <TAB> c = local_session(self.manager.session_factory).client(""iam"") <TAB> value = self.data.get(""value"", True) <TAB> res = [] <TAB> for r in resources: <TAB>  <TAB> r = self._inline_policies(c, r) <TAB>  <TAB> if len(r[""c7n:InlinePolicies""]) > 0 and value: <TAB>  <TAB>  <TAB> res.append(r) <MASK> res.append(r) <TAB> return res","if len ( r [ ""c7n:InlinePolicies"" ] ) == 0 and not value :",144
"def infer_relative_search_space( <TAB> self, study: Study, trial: FrozenTrial) -> Dict[str, BaseDistribution]: <TAB> if not self._multivariate: <TAB>  <TAB> return {} <TAB> search_space: Dict[str, BaseDistribution] = {} <TAB> for name, distribution in self._search_space.calculate(study).items(): <MASK> if self._warn_independent_sampling: <TAB>  <TAB>  <TAB>  <TAB> complete_trials = study.get_trials(deepcopy=False) <TAB>  <TAB>  <TAB>  <TAB> if len(complete_trials) >= self._n_startup_trials: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._log_independent_sampling(trial, name) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> search_space[name] = distribution <TAB> return search_space","if not isinstance ( distribution , _DISTRIBUTION_CLASSES ) :",191
"def start_server(self): <TAB> if not self.server: <MASK> return False <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.server = component.get(""DelugeWeb"") <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> self.server = server.DelugeWeb(daemon=False) <TAB> self.server.port = self.config[""port""] <TAB> self.server.https = self.config[""ssl""] <TAB> try: <TAB>  <TAB> self.server.start() <TAB> except CannotListenError as ex: <TAB>  <TAB> log.warning(""Failed to start WebUI server: %s"", ex) <TAB>  <TAB> raise <TAB> return True",if not self . got_deluge_web ( ) :,159
"def get_avrg_feature_vector(self, tokens_str): <TAB> embed = np.zeros(300, dtype=np.float64) <TAB> mention_size = 0 <TAB> for token in tokens_str.split(): <MASK> token_embed = self.word_embeddings[self.word_to_ix[token]] <TAB>  <TAB>  <TAB> embed = np.add(embed, token_embed) <TAB>  <TAB>  <TAB> mention_size += 1 <TAB> if mention_size == 0: <TAB>  <TAB> mention_size = 1 <TAB> return np.true_divide(embed, mention_size)",if token in self . word_to_ix :,147
"def _set_option(*args, **kwargs): <TAB> # must at least 1 arg deal with constraints later <TAB> nargs = len(args) <TAB> if not nargs or nargs % 2 != 0: <TAB>  <TAB> raise ValueError(""Must provide an even number of non-keyword "" ""arguments"") <TAB> # default to false <TAB> silent = kwargs.get(""silent"", False) <TAB> for k, v in zip(args[::2], args[1::2]): <TAB>  <TAB> key = _get_single_key(k, silent) <TAB>  <TAB> o = _get_registered_option(key) <MASK> o.validator(v) <TAB>  <TAB> # walk the nested dict <TAB>  <TAB> root, k = _get_root(key) <TAB>  <TAB> root[k] = v <TAB>  <TAB> if o.cb: <TAB>  <TAB>  <TAB> o.cb(key)",if o and o . validator :,199
def _get_system_version(): <TAB> if __file__ is None: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> m = 5 <TAB>  <TAB> except IOError: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> m = 10 <TAB>  <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB>  <TAB> m = 15 <MASK> m = 20 <TAB> return m,if m is not None :,96
"def test_block(self, _): <TAB> self.reddit.read_only = False <TAB> with self.use_cassette(): <TAB>  <TAB> message = None <TAB>  <TAB> for item in self.reddit.inbox.messages(): <MASK> message = item <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert False, ""no message found"" <TAB>  <TAB> message.block()",if item . author and item . author != pytest . placeholders . username :,113
"def formated(): <TAB> line = """" <TAB> for current in fileobject: <TAB>  <TAB> self.index_line += 1 <TAB>  <TAB> current = current.rstrip() <MASK> line += current <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif line: <TAB>  <TAB>  <TAB> yield line + current <TAB>  <TAB>  <TAB> line = """" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield current <TAB> if line: <TAB>  <TAB> yield line","if current . endswith ( ""\\"" ) :",98
"def __init__(self, d=None): <TAB> lowered_d = {} <TAB> if d is not None: <TAB>  <TAB> if isinstance(d, dict): <TAB>  <TAB>  <TAB> lowered_d = self._get_lowered_d(d) <MASK> return self.__init__(dict(d)) <TAB> return super(CaseInsensitiveDict, self).__init__(lowered_d)","elif isinstance ( d , list ) :",98
"def _create_simple_table(lines): <TAB> table = libdnf.smartcols.Table() <TAB> table.enableNoheadings(True) <TAB> table.setColumnSeparator("" : "") <TAB> column_name = table.newColumn(""Name"") <TAB> column_value = table.newColumn(""Value"") <TAB> column_value.setWrap(True) <TAB> column_value.setSafechars(""\n"") <TAB> column_value.setNewlineWrapFunction() <TAB> for line_name, value in lines.items(): <MASK> value = """" <TAB>  <TAB> line = table.newLine() <TAB>  <TAB> line.getColumnCell(column_name).setData(line_name) <TAB>  <TAB> line.getColumnCell(column_value).setData(str(value)) <TAB> return table",if value is None :,184
"def dump(self): <TAB> result = [""BindingInfo %17s"" % (self.kind)] <TAB> # Print all existing ivars. <TAB> table = (""commandName"", ""func"", ""nextMode"", ""pane"", ""stroke"") <TAB> for ivar in table: <MASK> val = getattr(self, ivar) <TAB>  <TAB>  <TAB> if val not in (None, ""none"", ""None"", """"): <TAB>  <TAB>  <TAB>  <TAB> if ivar == ""func"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # pylint: disable=no-member <TAB>  <TAB>  <TAB>  <TAB>  <TAB> val = val.__name__ <TAB>  <TAB>  <TAB>  <TAB> s = ""%s: %r"" % (ivar, val) <TAB>  <TAB>  <TAB>  <TAB> result.append(s) <TAB> return ""[%s]"" % "" "".join(result).strip()","if hasattr ( self , ivar ) :",187
"def __init__(self, filename): <TAB> self._word_to_id = {} <TAB> for word in [""UNK"", ""<S>"", ""</S>"", ""<PAD>""]: <TAB>  <TAB> self._word_to_id[word] = len(self._word_to_id) <TAB> with open(filename, ""r"") as fin: <TAB>  <TAB> for line in fin: <TAB>  <TAB>  <TAB> word = line.strip() <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""There has repeated token in the vocabulary file: %s"" % word <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self._word_to_id[word] = len(self._word_to_id)",if word in self . _word_to_id :,168
"def check_fs(path): <TAB> with open(path, ""rb"") as f: <TAB>  <TAB> code = source_to_unicode(f.read()) <MASK> module_name = os.path.basename(path)[:-3]  # Remove `.py`. <TAB>  <TAB>  <TAB> module = _load_module(evaluator, path, code) <TAB>  <TAB>  <TAB> add_module(evaluator, module_name, module) <TAB>  <TAB>  <TAB> return module",if name in code :,107
"def to_key(literal_or_identifier): <TAB> """"""returns string representation of this object"""""" <TAB> if literal_or_identifier[""type""] == ""Identifier"": <TAB>  <TAB> return literal_or_identifier[""name""] <TAB> elif literal_or_identifier[""type""] == ""Literal"": <TAB>  <TAB> k = literal_or_identifier[""value""] <TAB>  <TAB> if isinstance(k, float): <TAB>  <TAB>  <TAB> return unicode(float_repr(k)) <TAB>  <TAB> elif ""regex"" in literal_or_identifier: <TAB>  <TAB>  <TAB> return compose_regex(k) <TAB>  <TAB> elif isinstance(k, bool): <TAB>  <TAB>  <TAB> return u""true"" if k else u""false"" <MASK> return u""null"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return unicode(k)",elif k is None :,182
"def delVarFlags(self, var, **loginfo): <TAB> self.expand_cache = {} <TAB> if not var in self.dict: <TAB>  <TAB> self._makeShadowCopy(var) <TAB> if var in self.dict: <TAB>  <TAB> content = None <TAB>  <TAB> loginfo[""op""] = ""delete flags"" <TAB>  <TAB> self.varhistory.record(**loginfo) <TAB>  <TAB> # try to save the content <MASK> content = self.dict[var][""_content""] <TAB>  <TAB>  <TAB> self.dict[var] = {} <TAB>  <TAB>  <TAB> self.dict[var][""_content""] = content <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> del self.dict[var]","if ""_content"" in self . dict [ var ] :",166
"def do_shutdown(self): <TAB> """"""Shutdown the queue by not accepting any more URLs."""""" <TAB> with self.mutex: <TAB>  <TAB> unfinished = self.unfinished_tasks - len(self.queue) <TAB>  <TAB> self.queue.clear() <TAB>  <TAB> if unfinished <= 0: <MASK> raise ValueError(""shutdown is in error"") <TAB>  <TAB>  <TAB> self.all_tasks_done.notifyAll() <TAB>  <TAB> self.unfinished_tasks = unfinished <TAB>  <TAB> self.shutdown = True",if unfinished < 0 :,119
"def _get_staticsite_location(client, static_site_name, resource_group_name): <TAB> static_sites = client.list() <TAB> for static_site in static_sites: <TAB>  <TAB> if static_site.name.lower() == static_site_name.lower(): <TAB>  <TAB>  <TAB> found_rg = _parse_resource_group_from_arm_id(static_site.id) <TAB>  <TAB>  <TAB> if found_rg: <MASK> return static_site.location <TAB> raise CLIError( <TAB>  <TAB> ""Static site was '{}' not found in subscription and resource group '{}'."".format( <TAB>  <TAB>  <TAB> static_site_name, resource_group_name <TAB>  <TAB> ) <TAB> )",if found_rg . lower ( ) == resource_group_name . lower ( ) :,185
"def init_weights(self): <TAB> """"""Initialize weights."""""" <TAB> for head in self.heads: <MASK> self.__getattr__(head)[-1].bias.data.fill_(self.init_bias) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for m in self.__getattr__(head).modules(): <TAB>  <TAB>  <TAB>  <TAB> if isinstance(m, nn.Conv2d): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> kaiming_init(m)","if head == ""heatmap"" :",105
"def _initialize_weights(self) -> None: <TAB> for m in self.modules(): <TAB>  <TAB> if isinstance(m, nn.Conv2d): <TAB>  <TAB>  <TAB> nn.init.kaiming_normal_(m.weight, mode=""fan_out"", nonlinearity=""relu"") <MASK> nn.init.zeros_(m.bias) <TAB>  <TAB> elif isinstance(m, nn.BatchNorm2d): <TAB>  <TAB>  <TAB> nn.init.ones_(m.weight) <TAB>  <TAB>  <TAB> nn.init.zeros_(m.bias) <TAB>  <TAB> elif isinstance(m, nn.Linear): <TAB>  <TAB>  <TAB> nn.init.kaiming_uniform_(m.weight, mode=""fan_out"", nonlinearity=""sigmoid"") <TAB>  <TAB>  <TAB> nn.init.zeros_(m.bias)",if m . bias is not None :,186
"def _proto_hook(cls, other): <TAB> if not cls.__dict__.get(""_is_protocol"", None): <TAB>  <TAB> return NotImplemented <TAB> if not isinstance(other, type): <TAB>  <TAB> # Similar error as for issubclass(1, int) <TAB>  <TAB> # (also not a chance for old-style classes) <TAB>  <TAB> raise TypeError(""issubclass() arg 1 must be a new-style class"") <TAB> for attr in cls._get_protocol_attrs(): <TAB>  <TAB> for base in other.__mro__: <TAB>  <TAB>  <TAB> if attr in base.__dict__: <MASK> return NotImplemented <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return NotImplemented <TAB> return True",if base . __dict__ [ attr ] is None :,167
"def __init__( <TAB> self, <TAB> mock_s3_fs, <TAB> aws_access_key_id=None, <TAB> aws_secret_access_key=None, <TAB> aws_session_token=None, <TAB> endpoint_url=None, <TAB> region_name=None,): <TAB> self.mock_s3_fs = mock_s3_fs <TAB> region_name = region_name or _DEFAULT_AWS_REGION <TAB> if not endpoint_url: <MASK> endpoint_url = ""https://s3.amazonaws.com"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> endpoint_url = ""https://s3-%s.amazonaws.com"" % region_name <TAB> self.meta = MockClientMeta(endpoint_url=endpoint_url, region_name=region_name)",if region_name == _DEFAULT_AWS_REGION :,198
"def recv_nonblocking(self, size): <TAB> self.sock.settimeout(0) <TAB> try: <TAB>  <TAB> ret = self.recv(size) <TAB> except socket.error as e: <TAB>  <TAB> # 10035 no data when nonblocking <MASK> # errno.EWOULDBLOCK: errno is not always right <TAB>  <TAB>  <TAB> ret = None <TAB>  <TAB> # 10053 connection abort by client <TAB>  <TAB> # 10054 connection reset by peer <TAB>  <TAB> elif e.args[0] in [10053, 10054]:  # errno.ECONNABORTED: <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise <TAB> return ret",if e . args [ 0 ] == 10035 :,159
"def update_axis_length(axis_name, axis_length): <TAB> if known_lengths[axis_name] is not None: <TAB>  <TAB> # check is not performed for symbols <MASK> if axis_length != known_lengths[axis_name]: <TAB>  <TAB>  <TAB>  <TAB> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Inferred length for {} is {} not {}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> axis_name, axis_length, known_lengths[axis_name] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> known_lengths[axis_name] = axis_length","if isinstance ( axis_length , int ) and isinstance ( known_lengths [ axis_name ] , int ) :",163
"def load(self): <TAB> try: <TAB>  <TAB> available_creds = self._ini_parser(self._creds_filename) <TAB> except ConfigNotFound: <TAB>  <TAB> return None <TAB> if self._profile_name in available_creds: <TAB>  <TAB> config = available_creds[self._profile_name] <MASK> logger.info( <TAB>  <TAB>  <TAB>  <TAB> ""Found credentials in shared credentials file: %s"", self._creds_filename <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> access_key, secret_key = self._extract_creds_from_mapping( <TAB>  <TAB>  <TAB>  <TAB> config, self.ACCESS_KEY, self.SECRET_KEY <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> token = self._get_session_token(config) <TAB>  <TAB>  <TAB> return Credentials(access_key, secret_key, token, method=self.METHOD)",if self . ACCESS_KEY in config :,199
"def test_campaign_next_url_register_with_auth(self): <TAB> for campaign in get_campaigns(): <MASK> continue <TAB>  <TAB> # campaign register: user with auth <TAB>  <TAB> next_url = campaign_url_for(campaign) <TAB>  <TAB> data = login_and_register_handler( <TAB>  <TAB>  <TAB> self.auth, login=False, campaign=campaign, next_url=next_url <TAB>  <TAB> ) <TAB>  <TAB> assert_equal(data.get(""status_code""), http_status.HTTP_302_FOUND) <TAB>  <TAB> assert_equal(data.get(""next_url""), next_url)",if is_institution_login ( campaign ) :,182
"def compile(self): <TAB> patterns = self.patterns <TAB> self.patterns = [] <TAB> for pattern in patterns: <MASK> if len(pattern) == 2: <TAB>  <TAB>  <TAB>  <TAB> # Construct OR-list pattern <TAB>  <TAB>  <TAB>  <TAB> pattern = pattern[0] % ""|"".join(pattern[1]) <TAB>  <TAB>  <TAB> elif len(pattern) == 1: <TAB>  <TAB>  <TAB>  <TAB> pattern = pattern[0] <TAB>  <TAB> # Compile the pattern <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.patterns.append(re.compile(pattern, re.IGNORECASE)) <TAB>  <TAB> except Exception as ex: <TAB>  <TAB>  <TAB> Logr.error('Unable to compile pattern ""%s""', pattern) <TAB>  <TAB>  <TAB> raise ex <TAB> return len(patterns)",if type ( pattern ) is tuple :,174
"def get_serializer_class(self): <TAB> if ""identifier_id"" in self.kwargs: <TAB>  <TAB> referent = self.get_object().referent <MASK> return NodeIdentifierSerializer <TAB>  <TAB> if isinstance(referent, Registration): <TAB>  <TAB>  <TAB> return RegistrationIdentifierSerializer <TAB>  <TAB> if isinstance(referent, Preprint): <TAB>  <TAB>  <TAB> return PreprintIdentifierSerializer <TAB> return JSONAPISerializer","if isinstance ( referent , Node ) :",106
"def test_simulate_moment_steps(): <TAB> q0, q1 = cirq.LineQubit.range(2) <TAB> circuit = cirq.Circuit(cirq.H(q0), cirq.H(q1), cirq.H(q0), cirq.H(q1)) <TAB> simulator = cirq.CliffordSimulator() <TAB> for i, step in enumerate(simulator.simulate_moment_steps(circuit)): <MASK> np.testing.assert_almost_equal(step.state.to_numpy(), np.array([0.5] * 4)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> np.testing.assert_almost_equal( <TAB>  <TAB>  <TAB>  <TAB> step.state.to_numpy(), np.array([1, 0, 0, 0]) <TAB>  <TAB>  <TAB> )",if i == 0 :,196
"def _object_iter(self, names, showfile, showdir): <TAB> for name in names: <TAB>  <TAB> path = self.path + SEP + name <MASK> if showdir: <TAB>  <TAB>  <TAB>  <TAB> yield self.folder(name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if showfile: <TAB>  <TAB>  <TAB>  <TAB> yield self.file(name)",if os . path . isdir ( path ) :,94
"def flingToBeginning(self, maxSwipes=10): <TAB> if self.vertical: <TAB>  <TAB> for _ in range(maxSwipes): <MASK> print(""flinging to beginning"", file=sys.stderr) <TAB>  <TAB>  <TAB> self.flingBackward()",if DEBUG :,76
"def parseImpl(self, instring, loc, doActions=True): <TAB> tokens = [] <TAB> try: <TAB>  <TAB> loc, tokens = self.expr._parse(instring, loc, doActions, callPreParse=False) <TAB>  <TAB> hasIgnoreExprs = len(self.ignoreExprs) > 0 <TAB>  <TAB> while 1: <MASK> preloc = self._skipIgnorables(instring, loc) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> preloc = loc <TAB>  <TAB>  <TAB> loc, tmptokens = self.expr._parse(instring, preloc, doActions) <TAB>  <TAB>  <TAB> if tmptokens or tmptokens.keys(): <TAB>  <TAB>  <TAB>  <TAB> tokens += tmptokens <TAB> except (ParseException, IndexError): <TAB>  <TAB> pass <TAB> return loc, tokens",if hasIgnoreExprs :,188
"def width(self): <TAB> if self._width_cache is None: <MASK> self.drain_call_queue() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._length_cache, self._width_cache = get_index_and_columns.remote( <TAB>  <TAB>  <TAB>  <TAB> self.oid <TAB>  <TAB>  <TAB> ) <TAB> if isinstance(self._width_cache, ray.ObjectID): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self._width_cache = ray.get(self._width_cache) <TAB>  <TAB> except RayTaskError as e: <TAB>  <TAB>  <TAB> handle_ray_task_error(e) <TAB> return self._width_cache",if len ( self . call_queue ) :,158
"def remove_at_id(doc): <TAB> if isinstance(doc, MutableMapping): <TAB>  <TAB> for key in list(doc.keys()): <MASK> del doc[key] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> value = doc[key] <TAB>  <TAB>  <TAB>  <TAB> if isinstance(value, MutableMapping): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> remove_at_id(value) <TAB>  <TAB>  <TAB>  <TAB> if isinstance(value, MutableSequence): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for entry in value: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if isinstance(value, MutableMapping): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> remove_at_id(entry)","if key == ""@id"" :",151
def compress(mylist): <TAB> flate = PdfName.FlateDecode <TAB> for obj in streamobjects(mylist): <TAB>  <TAB> ftype = obj.Filter <TAB>  <TAB> if ftype is not None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> oldstr = obj.stream <TAB>  <TAB> newstr = convert_load(zlib.compress(convert_store(oldstr))) <MASK> obj.stream = newstr <TAB>  <TAB>  <TAB> obj.Filter = flate <TAB>  <TAB>  <TAB> obj.DecodeParms = None,if len ( newstr ) < len ( oldstr ) + 30 :,131
"def match(self, yield_func, expression, vars, evaluation, **kwargs): <TAB> if not expression.has_form(""Sequence"", 0): <TAB>  <TAB> if self.head is not None: <MASK> yield_func(vars, None) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield_func(vars, None)",if expression . get_head ( ) . same ( self . head ) :,91
"def parseModuliFile(filename): <TAB> with open(filename) as f: <TAB>  <TAB> lines = f.readlines() <TAB> primes = {} <TAB> for l in lines: <TAB>  <TAB> l = l.strip() <TAB>  <TAB> if not l or l[0] == ""#"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> tim, typ, tst, tri, size, gen, mod = l.split() <TAB>  <TAB> size = int(size) + 1 <TAB>  <TAB> gen = int(gen) <TAB>  <TAB> mod = int(mod, 16) <MASK> primes[size] = [] <TAB>  <TAB> primes[size].append((gen, mod)) <TAB> return primes",if size not in primes :,156
"def _extract(self, rec): <TAB> if rec is None: <TAB>  <TAB> return None <TAB> else: <TAB>  <TAB> key, data = rec <TAB>  <TAB> # Safe in Python 2.x because expresion short circuit <MASK> return key, cPickle.loads(data) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return key, cPickle.loads(bytes(data, ""iso8859-1""))  # 8 bits","if sys . version_info [ 0 ] < 3 or isinstance ( data , bytes ) :",112
"def test_from_chx(self, backend_config): <TAB> arr = backend_config.get_array(numpy.ones((2, 3), numpy.float32)) <TAB> arr_converted = backend.from_chx(arr) <TAB> src_device = backend_config.device <TAB> if src_device.xp is chainerx: <TAB>  <TAB> dst_xp = src_device.fallback_device.xp <TAB>  <TAB> assert isinstance(arr_converted, dst_xp.ndarray) <MASK> assert arr_converted.device.id == src_device.device.index <TAB> else: <TAB>  <TAB> assert arr is arr_converted <TAB> with backend_config: <TAB>  <TAB> self.check_equal_memory_shared(arr, arr_converted)",if dst_xp is cuda . cupy :,182
"def hdrToStr(self): <TAB> s = ""No valid IP headers parsed"" <TAB> if self._is_ip: <MASK> s = ""%s %s:%d->%s:%d"" % ( <TAB>  <TAB>  <TAB>  <TAB> self.proto, <TAB>  <TAB>  <TAB>  <TAB> self._src_ip, <TAB>  <TAB>  <TAB>  <TAB> self._hdr.data.sport, <TAB>  <TAB>  <TAB>  <TAB> self._dst_ip, <TAB>  <TAB>  <TAB>  <TAB> self._hdr.data.dport, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> s = ""%s->%s"" % (self._src_ip, self._dst_ip) <TAB> return s",if self . proto :,152
"def search(self, data): <TAB> search = self.res.search <TAB> fs_default = fsnative() <TAB> for name in self._names: <TAB>  <TAB> val = data.get(name) <TAB>  <TAB> if val is None: <MASK> val = fsn2text(data.get(""~"" + name, fs_default)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> val = data.get(""~"" + name, u"""") <TAB>  <TAB> if search(val): <TAB>  <TAB>  <TAB> return True <TAB> for name in self.__intern: <TAB>  <TAB> if search(data(name)): <TAB>  <TAB>  <TAB> return True <TAB> for name in self.__fs: <TAB>  <TAB> if search(fsn2text(data(name, fs_default))): <TAB>  <TAB>  <TAB> return True <TAB> return False","if name in ( ""filename"" , ""mountpoint"" ) :",193
"def has_name(self, value): <TAB> if self._row is not None: <TAB>  <TAB> for row, step in enumerate(self._controller.steps): <MASK> break <TAB>  <TAB>  <TAB> if step.is_assigning(value): <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return LocalMacroNamespace.has_name(self, value)",if self . _row == row :,89
"def preimport(self): <TAB> success = True <TAB> out = """" <TAB> try: <TAB>  <TAB> out = self._send_command({""action"": ""preimport""}) <TAB> except Exception as exc: <TAB>  <TAB> success = False <TAB>  <TAB> out = ""asv: benchmark runner crashed\n"" <MASK> out += str(exc) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> out += traceback.format_exc() <TAB>  <TAB> out = out.rstrip() <TAB> return success, out","if isinstance ( exc , util . UserError ) :",121
"def fit(self, *args): <TAB> self.reset() <TAB> tokens = chain(*args) <TAB> # filter(None, <>) -- to filter empty tokens <TAB> self.freqs = Counter(filter(None, flatten_str_batch(tokens))) <TAB> for special_token in self.special_tokens: <TAB>  <TAB> self._t2i[special_token] = self.count <TAB>  <TAB> self._i2t.append(special_token) <TAB>  <TAB> self.count += 1 <TAB> for token, freq in self.freqs.most_common()[: self._max_tokens]: <MASK> continue <TAB>  <TAB> if freq >= self._min_freq: <TAB>  <TAB>  <TAB> self._t2i[token] = self.count <TAB>  <TAB>  <TAB> self._i2t.append(token) <TAB>  <TAB>  <TAB> self.count += 1",if token in self . special_tokens :,199
"def __init__(self, route53connection, change_dict): <TAB> self.route53connection = route53connection <TAB> for key in change_dict: <MASK> self.__setattr__(key.lower(), change_dict[key].replace(""/change/"", """")) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.__setattr__(key.lower(), change_dict[key])","if key == ""Id"" :",90
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.set_application_key(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 16: <TAB>  <TAB>  <TAB> self.set_duration_minutes(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 26: <TAB>  <TAB>  <TAB> self.set_tag(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 10 :,154
"def _process_namespace(name, namespaces, ns_sep="":"", attr_prefix=""@""): <TAB> if not namespaces: <TAB>  <TAB> return name <TAB> try: <TAB>  <TAB> ns, name = name.rsplit(ns_sep, 1) <TAB> except ValueError: <TAB>  <TAB> pass <TAB> else: <TAB>  <TAB> ns_res = namespaces.get(ns.strip(attr_prefix)) <TAB>  <TAB> name = ( <TAB>  <TAB>  <TAB> ""{}{}{}{}"".format( <TAB>  <TAB>  <TAB>  <TAB> attr_prefix if ns.startswith(attr_prefix) else """", ns_res, ns_sep, name <TAB>  <TAB>  <TAB> ) <MASK> else name <TAB>  <TAB> ) <TAB> return name",if ns_res,155
"def _view(self, filepath, format): <TAB> """"""Start the right viewer based on file format and platform."""""" <TAB> methodnames = [ <TAB>  <TAB> ""_view_%s_%s"" % (format, backend.PLATFORM), <TAB>  <TAB> ""_view_%s"" % backend.PLATFORM, <TAB> ] <TAB> for name in methodnames: <TAB>  <TAB> view_method = getattr(self, name, None) <MASK> break <TAB> else: <TAB>  <TAB> raise RuntimeError( <TAB>  <TAB>  <TAB> ""%r has no built-in viewer support for %r "" <TAB>  <TAB>  <TAB> ""on %r platform"" % (self.__class__, format, backend.PLATFORM) <TAB>  <TAB> ) <TAB> view_method(filepath)",if view_method is not None :,165
"def _get_definition_from_array(prop, val, prev): <TAB> afield = None <TAB> for item in iter(val): <MASK> continue <TAB>  <TAB> field2, curr2 = _get_definition_from_type_of(prop, item, prev) <TAB>  <TAB> if field2 is not None: <TAB>  <TAB>  <TAB> afield = field2 <TAB>  <TAB> if curr2 is not None: <TAB>  <TAB>  <TAB> prev = curr2 <TAB> bfield = ""string"" if afield is None else afield <TAB> tdef = {""type"": ""array"", ""items"": bfield} <TAB> return tdef, prev",if item is None :,146
"def wrapper(): <TAB> while True: <TAB>  <TAB> knowledge = self._knowledge_queue.get() <TAB>  <TAB> self._knowledge_queue.task_done() <TAB>  <TAB> if not isinstance(knowledge, EndSignal): <TAB>  <TAB>  <TAB> batch_size = list(knowledge.values())[0].shape[0] <MASK> continue <TAB>  <TAB>  <TAB> yield knowledge <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> # After all knowledge data yielded, make current knowledge desc invalid. <TAB> self._is_knowledge_desc_ready = False <TAB> self._is_knowledge_gen_locked = False",if ( batch_size < self . _batch_size ) and drop_last :,165
"def doData(self, p, kind, name, val): <TAB> # New in Leo 4.11: do not strip lines. <TAB> # New in Leo 4.12.1: strip *nothing* here. <TAB> # New in Leo 4.12.1: allow composition of nodes: <TAB> # - Append all text in descendants in outline order. <TAB> # - Ensure all fragments end with a newline. <TAB> data = g.splitLines(p.b) <TAB> for p2 in p.subtree(): <MASK> data.extend(g.splitLines(p2.b)) <TAB>  <TAB>  <TAB> if not p2.b.endswith(""\n""): <TAB>  <TAB>  <TAB>  <TAB> data.append(""\n"") <TAB> self.set(p, kind, name, data)","if p2 . b and not p2 . h . startswith ( ""@"" ) :",193
"def _filter(src, names): <TAB> res = [] <TAB> for name in names: <TAB>  <TAB> path = os.path.join(src, name) <TAB>  <TAB> if os.path.isdir(path) and path.split()[-1] == ""subdir"": <TAB>  <TAB>  <TAB> res.append(name) <MASK> res.append(name) <TAB> return res","elif os . path . splitext ( path ) [ - 1 ] in ( "".py"" ) :",101
"def to_pydata(self): <TAB> verts = [vert for vert in self.verts if vert is not None] <TAB> lut = dict((vert, idx) for idx, vert in enumerate(verts)) <TAB> # info(lut) <TAB> edges = [] <TAB> for v1, v2 in self.all_edges: <TAB>  <TAB> i1 = lut.get(v1, None) <TAB>  <TAB> i2 = lut.get(v2, None) <TAB>  <TAB> # info(""Get: %s (%s) => %s (%s)"", v1, i1, v2, i2) <MASK> edges.append((i1, i2)) <TAB> return verts, edges",if i1 is not None and i2 is not None and i1 != i2 :,176
"def settings(self): <TAB> if self.is_live: <MASK> return self._real_settings <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise AzureTestError(""Need a mgmt_settings_real.py file to run tests live."") <TAB> else: <TAB>  <TAB> return self._fake_settings",if self . _real_settings :,79
"def param_names(self): <TAB> for parent_context_param in self.parent_context.param_names(): <MASK> yield ""%s|%s_%d"" % (parent_context_param, self.name, self.index) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield ""{}|{}"".format(parent_context_param, self.name) <TAB> if self.index is not None: <TAB>  <TAB> yield ""%s_%d"" % (self.name, self.index) <TAB> else: <TAB>  <TAB> yield self.name",if self . index is not None :,131
"def line_spacing(self, value): <TAB> pPr = self._element.get_or_add_pPr() <TAB> if value is None: <TAB>  <TAB> pPr.spacing_line = None <TAB>  <TAB> pPr.spacing_lineRule = None <TAB> elif isinstance(value, Length): <TAB>  <TAB> pPr.spacing_line = value <MASK> pPr.spacing_lineRule = WD_LINE_SPACING.EXACTLY <TAB> else: <TAB>  <TAB> pPr.spacing_line = Emu(value * Twips(240)) <TAB>  <TAB> pPr.spacing_lineRule = WD_LINE_SPACING.MULTIPLE",if pPr . spacing_lineRule != WD_LINE_SPACING . AT_LEAST :,167
"def _doImport(self, names): <TAB> for importName, importAs in names: <MASK> continue <TAB>  <TAB> if importName.endswith("".js""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> imp.add_imported_js(importName) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> self.add_imported_module(importName)","if importName == ""__pyjamas__"" :",89
"def _get_mask_string(mask): <TAB> masks = [] <TAB> for c in dir(InotifyConstants): <TAB>  <TAB> if c.startswith(""IN_"") and c not in [""IN_ALL_EVENTS"", ""IN_CLOSE"", ""IN_MOVE""]: <TAB>  <TAB>  <TAB> c_val = getattr(InotifyConstants, c) <MASK> masks.append(c) <TAB> mask_string = ""|"".join(masks) <TAB> return mask_string",if mask & c_val :,114
"def try_cmd(cmd): <TAB> try: <TAB>  <TAB> popen_params = {""stdout"": sp.PIPE, ""stderr"": sp.PIPE, ""stdin"": sp.DEVNULL} <TAB>  <TAB> # This was added so that no extra unwanted window opens on windows <TAB>  <TAB> # when the child process is created <MASK> popen_params[""creationflags""] = 0x08000000 <TAB>  <TAB> proc = sp.Popen(cmd, **popen_params) <TAB>  <TAB> proc.communicate() <TAB> except Exception as err: <TAB>  <TAB> return False, err <TAB> else: <TAB>  <TAB> return True, None","if os . name == ""nt"" :",142
"def runtime_version_greater_then_test_version(test_version, runtime_version): <TAB> runtime_ver = runtime_version.split(""."") <TAB> test_ver = test_version.split(""."") <TAB> if runtime_ver[0] > test_ver[0]: <TAB>  <TAB> return True <TAB> elif runtime_ver[0] == test_ver[0]: <MASK> return True <TAB>  <TAB> elif runtime_ver[1] == test_ver[1]: <TAB>  <TAB>  <TAB> if runtime_ver[2] > test_ver[2]: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if runtime_ver [ 1 ] > test_ver [ 1 ] :,152
"def get_implicit_operand_name(op): <TAB> if op_implicit(op): <TAB>  <TAB> if op.name.startswith(""REG""): <TAB>  <TAB>  <TAB> if op.bits and op.bits.startswith(""XED_REG_""): <TAB>  <TAB>  <TAB>  <TAB> reg_name = re.sub(""XED_REG_"", """", op.bits).lower() <TAB>  <TAB>  <TAB>  <TAB> return reg_name <MASK> ntluf = op.lookupfn_name <TAB>  <TAB>  <TAB>  <TAB> return ntluf <TAB>  <TAB> elif op.name == ""IMM0"" and op.type == ""imm_const"" and op.bits == ""1"": <TAB>  <TAB>  <TAB> return ""one"" <TAB>  <TAB> die(""Unhandled implicit operand {}"".format(op)) <TAB> return None",elif op . lookupfn_name :,178
"def reopen_files(self): <TAB> """"""Close and reopen all file handlers."""""" <TAB> for log in (self.error_log, self.access_log): <TAB>  <TAB> for h in log.handlers: <MASK> h.acquire() <TAB>  <TAB>  <TAB>  <TAB> h.stream.close() <TAB>  <TAB>  <TAB>  <TAB> h.stream = open(h.baseFilename, h.mode) <TAB>  <TAB>  <TAB>  <TAB> h.release()","if isinstance ( h , logging . FileHandler ) :",108
"def lower(self, word, max_cost, return_cost=True): <TAB> transductions = self.lower_transductions(word, max_cost, return_cost=True) <TAB> answer = dict() <TAB> for transduction, cost in transductions: <TAB>  <TAB> low = """".join(elem[1] for elem in transductions) <TAB>  <TAB> curr_cost = answer.get(low, None) <MASK> answer[low] = cost <TAB> answer = sorted(answer.items(), key=(lambda x: x[1])) <TAB> if return_cost: <TAB>  <TAB> return answer <TAB> else: <TAB>  <TAB> return [elem[0] for elem in answer]",if curr_cost is None or cost < curr_cost :,166
"def _starts_with_label(self, tokens): <TAB> text = [] <TAB> for t in tokens: <MASK> break <TAB>  <TAB> elif t[0] == TEXT: <TAB>  <TAB>  <TAB> text.append(t[1]) <TAB>  <TAB>  <TAB> if "" "" in text: <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return self.task_label_re.match("""".join(text))",if t [ 0 ] == STRIKE :,98
"def _fetch_data(urls): <TAB> # we only want warning+ messages from the requests module <TAB> logging.getLogger(""requests"").setLevel(logging.WARNING) <TAB> for url in urls: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> req = requests.get(url, timeout=5) <TAB>  <TAB>  <TAB> if req.status_code == 200: <TAB>  <TAB>  <TAB>  <TAB> data = req.text.strip() <MASK> continue <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return data <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise ConnectionError <TAB>  <TAB> except (Timeout, ConnectionError): <TAB>  <TAB>  <TAB> logger.warning(""Could not fetch public ip from %s"", url) <TAB> return None",if data is None or not _verify_address ( data ) :,175
"def _get_meta(self): <TAB> """"""Return meta data suported by this ext as a tuple"""""" <TAB> level = int(self.config[""level""]) - 1 <TAB> force = parseBoolValue(self.config[""forceid""]) <TAB> if hasattr(self.md, ""Meta""): <MASK> level = int(self.md.Meta[""header_level""][0]) - 1 <TAB>  <TAB> if ""header_forceid"" in self.md.Meta: <TAB>  <TAB>  <TAB> force = parseBoolValue(self.md.Meta[""header_forceid""][0]) <TAB> return level, force","if ""header_level"" in self . md . Meta :",149
"def byte_RETURN_VALUE(self, state, op): <TAB> """"""Get and check the return value."""""" <TAB> state, var = state.pop() <TAB> if self.frame.check_return: <TAB>  <TAB> if self.frame.f_code.has_generator(): <TAB>  <TAB>  <TAB> ret_type = self.frame.allowed_returns <TAB>  <TAB>  <TAB> self._check_return( <TAB>  <TAB>  <TAB>  <TAB> state.node, var, ret_type.get_formal_type_parameter(abstract_utils.V) <TAB>  <TAB>  <TAB> ) <MASK> self._check_return(state.node, var, self.frame.allowed_returns) <TAB> self._set_frame_return(state.node, self.frame, var) <TAB> return state.set_why(""return"")",elif not self . frame . f_code . has_async_generator ( ) :,194
"def _process_param_change(self, msg): <TAB> msg = super(Select, self)._process_param_change(msg) <TAB> values = self.values <TAB> if ""active"" in msg: <TAB>  <TAB> value = msg[""active""] <TAB>  <TAB> if value in values: <TAB>  <TAB>  <TAB> msg[""active""] = indexOf(value, values) <TAB>  <TAB> else: <MASK> self.value = None <TAB>  <TAB>  <TAB> msg[""active""] = None <TAB> if ""labels"" in msg: <TAB>  <TAB> msg[""labels""] = list(msg[""labels""]) <TAB>  <TAB> value = self.value <TAB>  <TAB> if not isIn(value, values): <TAB>  <TAB>  <TAB> self.value = None <TAB> return msg",if self . value is not None :,173
"def add_lines(self, *args, **kwargs): <TAB> lineno = None <TAB> if len(args) > 0: <MASK> lineno = args[0].lineno <TAB>  <TAB> elif isinstance(args[0], Node): <TAB>  <TAB>  <TAB> for n in args[0].children: <TAB>  <TAB>  <TAB>  <TAB> if isinstance(args[0], Leaf): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> lineno = n.lineno <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB> self.add_lines(self.js(*args, **kwargs), lineno=lineno, split=False)","if isinstance ( args [ 0 ] , Leaf ) :",134
"def get_act_of_pipeline(pipeline_tree): <TAB> for node_id, node_info in list(pipeline_tree[""activities""].items()): <MASK> return node_info <TAB>  <TAB> elif node_info[""type""] == ""SubProcess"": <TAB>  <TAB>  <TAB> act = get_act_of_pipeline(node_info[""pipeline""]) <TAB>  <TAB>  <TAB> if act: <TAB>  <TAB>  <TAB>  <TAB> return act",if node_id == act_id :,105
"def _bfs_paths_graph( <TAB> graph: defaultdict, start: int, goal: int) -> Generator[List[int], None, None]: <TAB> queue = [(start, [start])] <TAB> while queue: <TAB>  <TAB> (vertex, path) = queue.pop(0) <TAB>  <TAB> for pos in graph[vertex]: <MASK> yield path + [pos] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> queue.append((pos, path + [pos]))",if pos == goal :,116
"def compare_paths_lt(x, y): <TAB> min_length = min(len(x), len(y)) <TAB> if x[:min_length] == y[:min_length]: <TAB>  <TAB> return len(x) == min_length <TAB> for i in range(min_length): <TAB>  <TAB> a, b = x[i], y[i] <TAB>  <TAB> for _type in (_int_types, _str_type, tuple): <TAB>  <TAB>  <TAB> if isinstance(a, _type): <MASK> break <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> if a == b: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif a < b: <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> raise RuntimeError","if isinstance ( b , _type ) :",190
"def get_clients(accounts_config, account_ids, regions, service=""cloudwatch""): <TAB> clients = {} <TAB> for a in accounts_config.get(""accounts"", []): <MASK> continue <TAB>  <TAB> session = assumed_session(a[""role""], ""app-metrics"") <TAB>  <TAB> for r in regions: <TAB>  <TAB>  <TAB> clients[""%s-%s"" % (a[""account_id""], r)] = session.client( <TAB>  <TAB>  <TAB>  <TAB> service, region_name=r <TAB>  <TAB>  <TAB> ) <TAB> return clients","if a [ ""account_id"" ] not in account_ids :",133
"def stream(convert_encoding): <TAB> for byte in s: <TAB>  <TAB> headers = {""Range"": ""bytes=%s-%s"" % (byte[0], byte[1])} <TAB>  <TAB> resp, content = df.auth.Get_Http_Object().request(download_url, headers=headers) <TAB>  <TAB> if resp.status == 206: <MASK> result = chardet.detect(content) <TAB>  <TAB>  <TAB>  <TAB> content = content.decode(result[""encoding""]).encode(""utf-8"") <TAB>  <TAB>  <TAB> yield content <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.warning(""An error occurred: %s"", resp) <TAB>  <TAB>  <TAB> return",if convert_encoding :,155
"def execute(self, app): <TAB> lines = [] <TAB> for n, t, d, c in self.variables: <TAB>  <TAB> v = self[n] <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if t == ""float"": <MASK> continue <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> if v == int(CNC.vars[n]): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> lines.append(""$%s=%s"" % (n[5:], str(v))) <TAB>  <TAB> lines.append(""%wait"") <TAB> lines.append(""$$"") <TAB> app.run(lines=lines)",if v == float ( CNC . vars [ n ] ) :,164
"def _prepare_gpcontrol(self): <TAB> try: <TAB>  <TAB> response_raw = self._request(""gp/gpControl"") <TAB>  <TAB> jsondata = json.loads(response_raw) <TAB>  <TAB> response = jsondata[""info""][""firmware_version""] <TAB>  <TAB> if ""HX"" in response:  # Only session cameras. <TAB>  <TAB>  <TAB> connectedStatus = False <TAB>  <TAB>  <TAB> while connectedStatus == False: <TAB>  <TAB>  <TAB>  <TAB> req = self._request(""gp/gpControl/status"") <TAB>  <TAB>  <TAB>  <TAB> json_data = json.loads(req) <MASK> connectedStatus = True <TAB> except (HTTPError, URLError): <TAB>  <TAB> self._prepare_gpcontrol() <TAB> except timeout: <TAB>  <TAB> self._prepare_gpcontrol() <TAB> print(""Camera successfully connected!"")","if json_data [ ""status"" ] [ ""31"" ] >= 1 :",194
"def processfile(self, fileprocessor, options, fullinputpath): <TAB> """"""process an individual file"""""" <TAB> inputfile = self.openinputfile(options, fullinputpath) <TAB> inputfile = factory.getobject(inputfile) <TAB> for unit in inputfile.units: <TAB>  <TAB> if unit.isheader() or not unit.istranslated(): <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> if not options.invert: <TAB>  <TAB>  <TAB> source = self.clean(unit.source, options) <TAB>  <TAB>  <TAB> target = self.clean(unit.target, options) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> target = self.clean(unit.source, options) <TAB>  <TAB>  <TAB> source = self.clean(unit.target, options) <TAB>  <TAB> self.textmap.setdefault(source, []).append((target, unit, fullinputpath))",if unit . hasplural ( ) :,197
"def prepare(): <TAB> """"""Prepare the cache for all models, non-reentrant"""""" <TAB> if FIELDS:  # pragma: no cover <TAB>  <TAB> return <TAB> for model in apps.get_models(): <MASK> continue <TAB>  <TAB> name = get_model_name(model) <TAB>  <TAB> if model_has_filefields(name):  # pragma: no cover <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> opts = model._meta <TAB>  <TAB> for field in opts.get_fields(): <TAB>  <TAB>  <TAB> if isinstance(field, models.FileField): <TAB>  <TAB>  <TAB>  <TAB> add_field_for_model(name, field.name, field)",if ignore_model ( model ) :,153
"def _parse_ulimits(self, ulimits): <TAB> """"""Parse ulimits"""""" <TAB> if ulimits is None: <TAB>  <TAB> return None <TAB> result = [] <TAB> for name, value in ulimits.items(): <TAB>  <TAB> ulimit = {""name"": name} <TAB>  <TAB> if isinstance(value, dict): <TAB>  <TAB>  <TAB> ulimit.update(value) <MASK> ulimit.update({""hard"": value, ""soft"": value}) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> result.append(ulimit) <TAB> return result","elif isinstance ( value , int ) :",129
"def _link_props(self, model, properties, doc, root, comm=None): <TAB> ref = root.ref[""id""] <TAB> if config.embed: <TAB>  <TAB> return <TAB> for p in properties: <TAB>  <TAB> if isinstance(p, tuple): <TAB>  <TAB>  <TAB> _, p = p <MASK> model.on_change(p, partial(self._comm_change, doc, ref)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> model.on_change(p, partial(self._server_change, doc, ref))",if comm :,128
"def get_cluster_security_groups(self, region: str): <TAB> # For VPC-by-default customers, describe_cluster_parameters will throw an exception. Just try and ignore it: <TAB> try: <TAB>  <TAB> return await AWSFacadeUtils.get_all_pages( <TAB>  <TAB>  <TAB> ""redshift"", <TAB>  <TAB>  <TAB> region, <TAB>  <TAB>  <TAB> self.session, <TAB>  <TAB>  <TAB> ""describe_cluster_security_groups"", <TAB>  <TAB>  <TAB> ""ClusterSecurityGroups"", <TAB>  <TAB> ) <TAB> except ClientError as e: <MASK> print_exception(f""Failed to describe cluster security groups: {e}"") <TAB>  <TAB> return []","if e . response [ ""Error"" ] [ ""Code"" ] != ""InvalidParameterValue"" :",161
"def filter_subscriptions(key, dictionary): <TAB> for k, v in dictionary.items(): <TAB>  <TAB> if k == key: <TAB>  <TAB>  <TAB> if v == ""/subscriptions"": <TAB>  <TAB>  <TAB>  <TAB> yield dictionary <TAB>  <TAB> elif isinstance(v, dict): <TAB>  <TAB>  <TAB> for result in ManagedGroupHelper.filter_subscriptions(key, v): <TAB>  <TAB>  <TAB>  <TAB> yield result <MASK> for d in v: <TAB>  <TAB>  <TAB>  <TAB> for result in ManagedGroupHelper.filter_subscriptions(key, d): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield result","elif isinstance ( v , list ) :",131
"def __get__(self, instance, instance_type=None): <TAB> try: <TAB>  <TAB> field = super(HasOneDescriptor, self).__get__(instance, instance_type) <TAB>  <TAB> assert field is not None <TAB> except (AttributeError, AssertionError): <TAB>  <TAB> field = self.model.load(instance.storage, **{self.related_name: instance}) <MASK> setattr(field, self.related_name, instance) <TAB>  <TAB> instance.data_store.set(self.attrname, field, ""committed"") <TAB> return field","if field and not getattr ( field , self . related_name , None ) :",140
"def _walk(self, dir): <TAB> if dir.exists(): <TAB>  <TAB> for child in dir: <TAB>  <TAB>  <TAB> if isinstance(child, File): <TAB>  <TAB>  <TAB>  <TAB> yield child <MASK> for child in self._walk(child):  # recurs <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield child",elif child . exists ( ) :,76
"def run(self): <TAB> folder = os.path.dirname(os.path.abspath(__file__)) <TAB> for sub_folder in [""build"", ""dist"", ""asn1crypto.egg-info""]: <TAB>  <TAB> full_path = os.path.join(folder, sub_folder) <MASK> shutil.rmtree(full_path) <TAB> for root, dirnames, filenames in os.walk(os.path.join(folder, ""asn1crypto"")): <TAB>  <TAB> for filename in filenames: <TAB>  <TAB>  <TAB> if filename[-4:] == "".pyc"": <TAB>  <TAB>  <TAB>  <TAB> os.unlink(os.path.join(root, filename)) <TAB>  <TAB> for dirname in list(dirnames): <TAB>  <TAB>  <TAB> if dirname == ""__pycache__"": <TAB>  <TAB>  <TAB>  <TAB> shutil.rmtree(os.path.join(root, dirname))",if os . path . exists ( full_path ) :,199
"def _submenu(self, group, menubar): <TAB> try: <TAB>  <TAB> return self._menu_groups[group] <TAB> except KeyError: <MASK> submenu = menubar <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> parent_menu = self._submenu(group.parent, menubar) <TAB>  <TAB>  <TAB> submenu = Gio.Menu() <TAB>  <TAB>  <TAB> self._menu_groups[group] = submenu <TAB>  <TAB>  <TAB> label = group.label <TAB>  <TAB>  <TAB> if label == ""*"": <TAB>  <TAB>  <TAB>  <TAB> label = self.interface.name <TAB>  <TAB>  <TAB> parent_menu.append_submenu(label, submenu) <TAB>  <TAB> # Install the item in the group cache. <TAB>  <TAB> self._menu_groups[group] = submenu <TAB>  <TAB> return submenu",if group is None :,174
"def _filter_empty_sentences(dataset) -> Dataset: <TAB> # find out empty sentence indices <TAB> empty_sentence_indices = [] <TAB> non_empty_sentence_indices = [] <TAB> index = 0 <TAB> from flair.datasets import DataLoader <TAB> for batch in DataLoader(dataset): <TAB>  <TAB> for sentence in batch: <MASK> empty_sentence_indices.append(index) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> non_empty_sentence_indices.append(index) <TAB>  <TAB>  <TAB> index += 1 <TAB> # create subset of non-empty sentence indices <TAB> subset = Subset(dataset, non_empty_sentence_indices) <TAB> return subset",if len ( sentence ) == 0 :,160
"def _dep_resolve(graph, node, resolved, seen): <TAB> seen.append(node) <TAB> for edge in graph[node]: <MASK> if edge in seen: <TAB>  <TAB>  <TAB>  <TAB> raise OEQADependency( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Test cases %s and %s have a circular"" "" dependency."" % (node, edge) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> _dep_resolve(graph, edge, resolved, seen) <TAB> resolved.append(node)",if edge not in resolved :,120
"def unique_workflow_outputs(self): <TAB> # Older Galaxy workflows may have multiple WorkflowOutputs <TAB> # per ""output_name"", when serving these back to the editor <TAB> # feed only a ""best"" output per ""output_name."""" <TAB> outputs = {} <TAB> for workflow_output in self.workflow_outputs: <TAB>  <TAB> output_name = workflow_output.output_name <TAB>  <TAB> if output_name in outputs: <TAB>  <TAB>  <TAB> found_output = outputs[output_name] <MASK> outputs[output_name] = workflow_output <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> outputs[output_name] = workflow_output <TAB> return list(outputs.values())",if found_output . label is None and workflow_output . label is not None :,181
"def ensure_fromlist(self, m, fromlist, recursive=0): <TAB> self.msg(4, ""ensure_fromlist"", m, fromlist, recursive) <TAB> for sub in fromlist: <TAB>  <TAB> if sub == ""*"": <TAB>  <TAB>  <TAB> if not recursive: <TAB>  <TAB>  <TAB>  <TAB> all = self.find_all_submodules(m) <TAB>  <TAB>  <TAB>  <TAB> if all: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.ensure_fromlist(m, all, 1) <MASK> subname = ""%s.%s"" % (m.__name__, sub) <TAB>  <TAB>  <TAB> submod = self.import_module(sub, subname, m) <TAB>  <TAB>  <TAB> if not submod: <TAB>  <TAB>  <TAB>  <TAB> raise ImportError(""No module named "" + subname)","elif not hasattr ( m , sub ) :",179
"def _get_scoped_name(self, obj_name, database): <TAB> if database: <TAB>  <TAB> scoped_name = ""{}.`{}`"".format(database, obj_name) <TAB> else: <TAB>  <TAB> if not is_fully_qualified(obj_name): <MASK> return obj_name <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return ""`{}`"".format(obj_name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return obj_name <TAB> return scoped_name",if _is_quoted ( obj_name ) :,122
"def print_data(self, data): <TAB> if isinstance(data, dict): <TAB>  <TAB> output = """" <TAB>  <TAB> for key in data: <TAB>  <TAB>  <TAB> if key == ""_name"": <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> output += key <TAB>  <TAB>  <TAB> if isinstance(data[key], dict): <MASK> output += ""="" + str(data[key][""_name""]) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> output += ""/"" <TAB>  <TAB>  <TAB> output += ""\n"" <TAB>  <TAB> # Cut off last \n <TAB>  <TAB> return output[:-1] <TAB> elif isinstance(data, list): <TAB>  <TAB> return ""\n"".join(data) <TAB> else: <TAB>  <TAB> return str(data)","if ""_name"" in data [ key ] :",176
"def iternext(self, to=None): <TAB> if to is not None: <TAB>  <TAB> if not isinstance(to, sllistnode): <TAB>  <TAB>  <TAB> raise TypeError(""to argument must be a sllistnode"") <MASK> raise ValueError(""to argument belongs to another list"") <TAB> current = self <TAB> while current is not None and current != to: <TAB>  <TAB> yield current <TAB>  <TAB> current = current.__next",if to . list is not self . __list :,106
"def test_load_pretrained_model_layer1(tmp_path): <TAB> model_src = Model() <TAB> torch.save(model_src.layer1.state_dict(), tmp_path / ""layer1.pth"") <TAB> model_dst = Model() <TAB> load_pretrained_model(f""{tmp_path}/layer1.pth::layer1"", model_dst, ""cpu"") <TAB> for k in model_dst.state_dict(): <MASK> np.testing.assert_array_equal( <TAB>  <TAB>  <TAB>  <TAB> model_dst.state_dict()[k].numpy(), model_src.state_dict()[k].numpy() <TAB>  <TAB>  <TAB> )","if k . startswith ( ""layer1"" ) :",161
def cost(self): <MASK> self.lazy_init_lock_.acquire() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if self.cost_ is None: <TAB>  <TAB>  <TAB>  <TAB> self.cost_ = Cost() <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self.lazy_init_lock_.release() <TAB> return self.cost_,if self . cost_ is None :,85
"def allow_more_workers() -> None: <TAB> global WORKERS_DONE <TAB> if WORKERS_DONE: <TAB>  <TAB> return <TAB> stack = inspect.stack() <TAB> for entry in stack: <MASK> if entry.frame.f_locals[""self""]._sync_call_tp._max_workers == 1: <TAB>  <TAB>  <TAB>  <TAB> logging.info(""bumped thread worker count to 50"") <TAB>  <TAB>  <TAB>  <TAB> entry.frame.f_locals[""self""]._sync_call_tp._max_workers = 50 <TAB> WORKERS_DONE = True","if entry . filename . endswith ( ""azure_functions_worker/dispatcher.py"" ) :",148
"def validate_payload(self, func): <TAB> """"""Perform a payload validation on expected model if necessary"""""" <TAB> if getattr(func, ""__apidoc__"", False) is not False: <TAB>  <TAB> doc = func.__apidoc__ <TAB>  <TAB> validate = doc.get(""validate"", None) <TAB>  <TAB> validate = validate if validate is not None else self.api._validate <TAB>  <TAB> if validate: <TAB>  <TAB>  <TAB> for expect in doc.get(""expect"", []): <TAB>  <TAB>  <TAB>  <TAB> # TODO: handle third party handlers <MASK> if isinstance(expect[0], ModelBase): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.__validate_payload(expect[0], collection=True) <TAB>  <TAB>  <TAB>  <TAB> if isinstance(expect, ModelBase): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.__validate_payload(expect, collection=False)","if isinstance ( expect , list ) and len ( expect ) == 1 :",200
"def _register_iterable(self, iterable): <TAB> for element in iterable: <TAB>  <TAB> if isinstance(element, Module): <TAB>  <TAB>  <TAB> self._register_module(element) <MASK> continue <TAB>  <TAB> elif isinstance(element, collections.Iterable): <TAB>  <TAB>  <TAB> self._register_iterable(element)","elif isinstance ( element , str ) :",79
"def process_list_structure(data: list) -> dict: <TAB> entry = {} <TAB> for name, definition, *arguments in data: <TAB>  <TAB> kwargs = arguments[0] if arguments else {} <TAB>  <TAB> if not isinstance(kwargs, dict): <TAB>  <TAB>  <TAB> raise TypeError(""Invalid arguments type. Must be a dictionary"") <MASK> return self._format_selection(definition, **kwargs) <TAB>  <TAB> if isinstance(definition, tuple): <TAB>  <TAB>  <TAB> entry[name] = process_list_structure(definition) <TAB>  <TAB> elif isinstance(definition, (list, set)): <TAB>  <TAB>  <TAB> entry[name] = [process_list_structure([item]) for item in definition] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> entry[name] = self._format_selection(definition, **kwargs) <TAB> return entry",if name is None :,188
"def fill(img, p, num, nbs, acc, buf): <TAB> back = img[p] <TAB> img[p] = num <TAB> buf[0] = p <TAB> cur = 0 <TAB> s = 1 <TAB> while True: <TAB>  <TAB> p = buf[cur] <TAB>  <TAB> for dp in nbs: <TAB>  <TAB>  <TAB> cp = p + dp <TAB>  <TAB>  <TAB> if img[cp] == back: <TAB>  <TAB>  <TAB>  <TAB> img[cp] = num <TAB>  <TAB>  <TAB>  <TAB> buf[s] = cp <TAB>  <TAB>  <TAB>  <TAB> s += 1 <TAB>  <TAB> cur += 1 <MASK> break <TAB> return idx2rc(buf[:s], acc)",if cur == s :,157
"def test_task_set_command_with_multiple_arguments(task_definition): <TAB> task_definition.set_commands( <TAB>  <TAB> webserver=u""run-webserver arg1 arg2"", application=u""run-application arg1 arg2"" <TAB> ) <TAB> for container in task_definition.containers: <MASK> assert container[u""command""] == [u""run-webserver"", u""arg1"", u""arg2""] <TAB>  <TAB> if container[u""name""] == u""application"": <TAB>  <TAB>  <TAB> assert container[u""command""] == [u""run-application"", u""arg1"", u""arg2""]","if container [ u""name"" ] == u""webserver"" :",159
"def clearfocus(self): <TAB> if self.currentxy is not None: <TAB>  <TAB> x1, y1 = self.currentxy <TAB>  <TAB> x2, y2 = self.cornerxy or self.currentxy <MASK> x1, x2 = x2, x1 <TAB>  <TAB> if y1 > y2: <TAB>  <TAB>  <TAB> y1, y2 = y2, y1 <TAB>  <TAB> for (x, y), cell in self.gridcells.items(): <TAB>  <TAB>  <TAB> if x1 <= x <= x2 and y1 <= y <= y2: <TAB>  <TAB>  <TAB>  <TAB> cell[""bg""] = ""white""",if x1 > x2 :,151
"def find_comment(self, comment): <TAB> """"""Return an iter of jobs that match the comment field exactly."""""" <TAB> for job in list(self.crons): <MASK> if comment.findall(job.comment): <TAB>  <TAB>  <TAB>  <TAB> yield job <TAB>  <TAB> elif comment == job.comment: <TAB>  <TAB>  <TAB> yield job","if isinstance ( comment , type ( ITEMREX ) ) :",88
"def add_fc(self, fc, readonly=False): <TAB> ""Add function into known_fc"" <TAB> for name, detail in viewitems(fc): <TAB>  <TAB> fnty = llvm_ir.FunctionType(detail[""ret""], detail[""args""]) <TAB>  <TAB> fn = llvm_ir.Function(self.mod, fnty, name=name) <MASK> fn.attributes.add(""readonly"")",if readonly :,98
"def _interpret_if(self, parts, ns, out, defs): <TAB> # __traceback_hide__ = True <TAB> # @@: if/else/else gets through <TAB> for part in parts: <TAB>  <TAB> assert not isinstance(part, basestring_) <TAB>  <TAB> name, pos = part[0], part[1] <MASK> result = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result = self._eval(part[2], ns, pos) <TAB>  <TAB> if result: <TAB>  <TAB>  <TAB> self._interpret_codes(part[3], ns, out, defs) <TAB>  <TAB>  <TAB> break","if name == ""else"" :",142
"def config_validator(user): <TAB> res = [] <TAB> if not ""test"" in sys.argv:  # Avoid tests hanging <TAB>  <TAB> status = get_oozie_status(user) <MASK> res.append( <TAB>  <TAB>  <TAB>  <TAB> (NICE_NAME, _(""The app won't work without a running Oozie server"")) <TAB>  <TAB>  <TAB> ) <TAB> return res","if ""NORMAL"" not in status :",97
"def GET(self, code): <TAB> docs = web.ctx.site.store.values(type=""account-link"", name=""code"", value=code) <TAB> if docs: <TAB>  <TAB> doc = docs[0] <TAB>  <TAB> account = accounts.find(username=doc[""username""]) <MASK> if account[""status""] != ""pending"": <TAB>  <TAB>  <TAB>  <TAB> return render[""account/verify/activated""](account) <TAB>  <TAB> account.activate() <TAB>  <TAB> user = web.ctx.site.get(""/people/"" + doc[""username""])  # TBD <TAB>  <TAB> return render[""account/verify/success""](account) <TAB> else: <TAB>  <TAB> return render[""account/verify/failed""]()",if account :,162
"def update_from_message(self, k, message): <TAB> with object_session(self).no_autoflush: <MASK> # Don't change subjectdate, recentdate, or unread/unseen based <TAB>  <TAB>  <TAB> # on drafts <TAB>  <TAB>  <TAB> return message <TAB>  <TAB> if message.received_date > self.recentdate: <TAB>  <TAB>  <TAB> self.recentdate = message.received_date <TAB>  <TAB>  <TAB> self.snippet = message.snippet <TAB>  <TAB> # Subject is subject of original message in the thread <TAB>  <TAB> if message.received_date < self.subjectdate: <TAB>  <TAB>  <TAB> self.subject = message.subject <TAB>  <TAB>  <TAB> self.subjectdate = message.received_date <TAB>  <TAB> return message",if message . is_draft :,169
"def get_define_str(define, prefix=""""): <TAB> for k, v in globals().items(): <MASK> continue <TAB>  <TAB> if prefix: <TAB>  <TAB>  <TAB> if k.startswith(prefix): <TAB>  <TAB>  <TAB>  <TAB> return k <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return k","if not isinstance ( v , str ) or v != define :",79
"def codeToType(type_code, colname): <TAB> import psycopg2 <TAB> try: <TAB>  <TAB> tname = psycopg2._psycopg.string_types[type_code].name <MASK> return int <TAB>  <TAB> if ""STRING"" in tname: <TAB>  <TAB>  <TAB> return str <TAB> except KeyError: <TAB>  <TAB> vd.status(""unknown postgres type_code %s for %s"" % (type_code, colname)) <TAB> return anytype","if ""INTEGER"" in tname :",110
"def _passthrough_loop_context(loop): <TAB> if loop: <TAB>  <TAB> # loop already exists, pass it straight through <TAB>  <TAB> yield loop <TAB> else: <TAB>  <TAB> # this shadows loop_context's standard behavior <TAB>  <TAB> loop = asyncio.new_event_loop() <TAB>  <TAB> asyncio.set_event_loop(None) <TAB>  <TAB> yield loop <TAB>  <TAB> closed = loop.is_closed() <MASK> loop.call_soon(loop.stop) <TAB>  <TAB>  <TAB> loop.run_forever() <TAB>  <TAB>  <TAB> loop.close() <TAB>  <TAB>  <TAB> gc.collect() <TAB>  <TAB> asyncio.set_event_loop(None)",if not closed :,153
def __iter__(self): <MASK> _fill_lock.acquire() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if self.data is None: <TAB>  <TAB>  <TAB>  <TAB> self._fill() <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> _fill_lock.release() <TAB> return iter(self.data),if self . data is None :,76
"def remove_connection(self, connection_id): <TAB> with self._connections_lock: <TAB>  <TAB> LOGGER.debug(""Removing connection: %s"", connection_id) <MASK> connection_info = self._connections[connection_id] <TAB>  <TAB>  <TAB> if connection_info.connection_type == ConnectionType.OUTBOUND_CONNECTION: <TAB>  <TAB>  <TAB>  <TAB> connection_info.connection.stop() <TAB>  <TAB>  <TAB>  <TAB> del self._connections[connection_id] <TAB>  <TAB>  <TAB> elif connection_info.connection_type == ConnectionType.ZMQ_IDENTITY: <TAB>  <TAB>  <TAB>  <TAB> self._send_receive_thread.remove_connected_identity( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> connection_info.connection <TAB>  <TAB>  <TAB>  <TAB> )",if connection_id in self . _connections :,173
"def random(cls, order=3): <TAB> """"""Returns a unit vector in a random direction."""""" <TAB> # distribution is not without bias, need to use polar coords? <TAB> v = V(range(order)) <TAB> v._l = None <TAB> short = True <TAB> while short: <TAB>  <TAB> for i in range(order): <TAB>  <TAB>  <TAB> v._v[i] = 2.0 * random.random() - 1.0 <MASK> short = False <TAB> return v.normalize()",if not zero ( v . _v [ i ] ) :,126
"def __init__(self, items, rddconf): <TAB> self.path = path = LocalFileShuffle.get_tmp() <TAB> with atomic_file(path, bufsize=4096) as f: <MASK> items = list(items) <TAB>  <TAB> items.sort(key=itemgetter(0)) <TAB>  <TAB> serializer = get_serializer(rddconf) <TAB>  <TAB> serializer.dump_stream(items, f) <TAB>  <TAB> self.size = f.tell() <TAB>  <TAB> self.num_batch = serializer.num_batch","if not isinstance ( items , list ) :",130
"def selector(): <TAB> sel = DefaultSelector() <TAB> sel.register(proc.stdout.channel, EVENT_READ) <TAB> while True: <TAB>  <TAB> ready = sel.select(line_timeout) <MASK> raise ProcessLineTimedOut( <TAB>  <TAB>  <TAB>  <TAB> ""popen line timeout expired"", <TAB>  <TAB>  <TAB>  <TAB> getattr(proc, ""argv"", None), <TAB>  <TAB>  <TAB>  <TAB> getattr(proc, ""machine"", None), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> for key, mask in ready: <TAB>  <TAB>  <TAB> yield",if not ready and line_timeout :,125
"def mark(msg, events, log=True, clear_errors=False): <TAB> for ev in events: <TAB>  <TAB> ev.flags = Event.RUNNING <TAB>  <TAB> ev.message = msg <MASK> if ""last_error"" in ev.data: <TAB>  <TAB>  <TAB>  <TAB> del ev.data[""last_error""] <TAB>  <TAB>  <TAB> if ""last_error_details"" in ev.data: <TAB>  <TAB>  <TAB>  <TAB> del ev.data[""last_error_details""] <TAB>  <TAB> if log: <TAB>  <TAB>  <TAB> session.config.event_log.log_event(ev) <TAB> session.ui.mark(msg)",if clear_errors :,147
"def numops(a, b, skip=[]): <TAB> dict = {""a"": a, ""b"": b} <TAB> for name, expr in binops.items(): <MASK> name = ""__%s__"" % name <TAB>  <TAB>  <TAB> if hasattr(a, name): <TAB>  <TAB>  <TAB>  <TAB> res = eval(expr, dict) <TAB>  <TAB>  <TAB>  <TAB> testbinop(a, b, res, expr, name) <TAB> for name, expr in unops.items(): <TAB>  <TAB> if name not in skip: <TAB>  <TAB>  <TAB> name = ""__%s__"" % name <TAB>  <TAB>  <TAB> if hasattr(a, name): <TAB>  <TAB>  <TAB>  <TAB> res = eval(expr, dict) <TAB>  <TAB>  <TAB>  <TAB> testunop(a, res, expr, name)",if name not in skip :,174
"def transform(self, X): <TAB> features = None <TAB> for chunk in chunks(X, self.batch_size): <TAB>  <TAB> if features is not None: <TAB>  <TAB>  <TAB> features = np.vstack([features, self._compute_features(chunk)]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> features = self._compute_features(chunk) <MASK> sys.stdout.write( <TAB>  <TAB>  <TAB>  <TAB> ""\r[%s] %d%%"" <TAB>  <TAB>  <TAB>  <TAB> % ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.__class__.__name__, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> 100.0 * len(features) / len(X), <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> sys.stdout.flush() <TAB> if self.verbose: <TAB>  <TAB> sys.stdout.write(""\n"") <TAB> return features",if self . verbose :,188
"def ensemble(self, cands, other_preds): <TAB> """"""Ensemble the dict with statistical model predictions."""""" <TAB> expansions = [] <TAB> assert len(cands) == len(other_preds) <TAB> for c, pred in zip(cands, other_preds): <TAB>  <TAB> if c in self.expansion_dict: <TAB>  <TAB>  <TAB> expansions += [self.expansion_dict[c]] <MASK> expansions += [self.expansion_dict[c.lower()]] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> expansions += [pred] <TAB> return expansions",elif c . lower ( ) in self . expansion_dict :,142
"def state_startup(self, backend): <TAB> if self.current_state(self.INITIAL): <TAB>  <TAB> successful_startup = False <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.set_state(self.STARTUP) <TAB>  <TAB>  <TAB> successful_startup = backend.start_backend() <TAB>  <TAB> finally: <MASK> self.set_state(self.INITIAL)",if not successful_startup :,95
"def find_docstring_pass_pair(self, tree, spots): <TAB> for i in range(1, len(tree)): <MASK> first_line = self.first_line_of_tree(tree[i]) <TAB>  <TAB>  <TAB> last_line = self.last_line_of_tree(tree[i + 1]) <TAB>  <TAB>  <TAB> self.record_multiline(spots, first_line, last_line)",if self . is_string_constant ( tree [ i ] ) and self . is_pass_stmt ( tree [ i + 1 ] ) :,128
"def filter_result(link): <TAB> try: <TAB>  <TAB> # Decode hidden URLs. <MASK> o = urlparse(link, ""http"") <TAB>  <TAB>  <TAB> link = parse_qs(o.query)[""q""][0] <TAB>  <TAB> # Valid results are absolute URLs not pointing to a Google domain, <TAB>  <TAB> # like images.google.com or googleusercontent.com for example. <TAB>  <TAB> # TODO this could be improved! <TAB>  <TAB> o = urlparse(link, ""http"") <TAB>  <TAB> if o.netloc and ""google"" not in o.netloc: <TAB>  <TAB>  <TAB> return link <TAB> # On error, return None. <TAB> except Exception: <TAB>  <TAB> pass","if link . startswith ( ""/url?"" ) :",159
"def __axis(self, node): <TAB> if self.node_test == ""text()"": <TAB>  <TAB> return node.string == self.value <TAB> else: <TAB>  <TAB> children = node.findAll(self.node_test, recursive=False) <TAB>  <TAB> if len(children) > 0 and self.value is None: <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> for child in children: <MASK> return True <TAB>  <TAB> return False",if child . string == self . value :,111
"def semi_deepcopy(x): <TAB> copier = _semi_deepcopy_dispatch.get(type(x)) <TAB> if copier: <TAB>  <TAB> return copier(x) <TAB> else: <TAB>  <TAB> if hasattr(x, ""__semi_deepcopy__""): <TAB>  <TAB>  <TAB> return x.__semi_deepcopy__() <MASK> return x.__class__(_semi_deepcopy_dict(x)) <TAB>  <TAB> elif isinstance(x, UserList): <TAB>  <TAB>  <TAB> return x.__class__(_semi_deepcopy_list(x)) <TAB>  <TAB> return x","elif isinstance ( x , UserDict ) :",131
def native_import(name): <TAB> if PupyPackageFinder.search_lock is not None: <TAB>  <TAB> with PupyPackageFinder.search_lock: <MASK> return False <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> PupyPackageFinder.search_set.add(name) <TAB> try: <TAB>  <TAB> __import__(name) <TAB>  <TAB> return True <TAB> except: <TAB>  <TAB> return False <TAB> finally: <TAB>  <TAB> if PupyPackageFinder.search_lock is not None: <TAB>  <TAB>  <TAB> with PupyPackageFinder.search_lock: <TAB>  <TAB>  <TAB>  <TAB> PupyPackageFinder.search_set.remove(name),if name in PupyPackageFinder . search_set :,161
def _spin(self): <TAB> while not self._stop_spin.is_set(): <MASK> # Wait a bit to avoid wasting cycles <TAB>  <TAB>  <TAB> time.sleep(self._interval) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # Compose output <TAB>  <TAB> spin_phase = next(self._cycle) <TAB>  <TAB> out = self._compose_out(spin_phase) <TAB>  <TAB> # Write <TAB>  <TAB> with self._stdout_lock: <TAB>  <TAB>  <TAB> sys.stdout.write(out) <TAB>  <TAB>  <TAB> self._clear_line() <TAB>  <TAB>  <TAB> sys.stdout.flush() <TAB>  <TAB> # Wait <TAB>  <TAB> time.sleep(self._interval),if self . _hide_spin . is_set ( ) :,163
"def populate(self, data): <TAB> if data.get(""_embedded""): <TAB>  <TAB> if data[""_embedded""].get(""character""): <TAB>  <TAB>  <TAB> self.character = Character(data[""_embedded""][""character""]) <MASK> self.show = Show(data[""_embedded""][""show""])","elif data [ ""_embedded"" ] . get ( ""show"" ) :",73
"def loadConfig(filename): <TAB> options = dict(OPTIONS) <TAB> if os.path.exists(filename): <TAB>  <TAB> cp = SafeConfigParser() <TAB>  <TAB> cp.read([filename]) <TAB>  <TAB> for option in (""format"", ""prompt""): <MASK> options[option] = cp.get(""twitter"", option) <TAB>  <TAB> # process booleans <TAB>  <TAB> for option in (""invert_split"",): <TAB>  <TAB>  <TAB> if cp.has_option(""twitter"", option): <TAB>  <TAB>  <TAB>  <TAB> options[option] = cp.getboolean(""twitter"", option) <TAB> return options","if cp . has_option ( ""twitter"" , option ) :",141
"def forward(self, observations: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]: <TAB> if self._size is not None: <TAB>  <TAB> observations.update( <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB> sensor: self._transform_obs(observations[sensor]) <TAB>  <TAB>  <TAB>  <TAB> for sensor in self.trans_keys <MASK> } <TAB>  <TAB> ) <TAB> return observations",if sensor in observations,99
"def remove(self, func): <TAB> q = ""select id, message from %s"" % self.table <TAB> n = 0 <TAB> for id, msg in self.conn.execute(q): <MASK> q = ""delete from %s where id=?"" % self.table <TAB>  <TAB>  <TAB> c = self.conn.execute(q, (id,)) <TAB>  <TAB>  <TAB> if not c.rowcount:  # record vanished, so let's try again <TAB>  <TAB>  <TAB>  <TAB> self.conn.rollback() <TAB>  <TAB>  <TAB>  <TAB> return self.remove(func) <TAB>  <TAB>  <TAB> n += 1 <TAB> self.conn.commit() <TAB> return n",if func ( self . decode ( msg ) ) :,155
"def metadata_tostring_fix(desc, nspair, xmlstring=""""): <TAB> if not xmlstring: <TAB>  <TAB> xmlstring = desc.to_string(nspair) <TAB> if six.PY2: <TAB>  <TAB> if '""xs:string""' in xmlstring and XMLNSXS not in xmlstring: <TAB>  <TAB>  <TAB> xmlstring = xmlstring.replace(MDNS, MDNS + XMLNSXS) <TAB> else: <MASK> xmlstring = xmlstring.replace(bMDNS, bMDNS + bXMLNSXS) <TAB> return xmlstring","if b'""xs:string""' in xmlstring and bXMLNSXS not in xmlstring :",150
def offset_from_tz_string(tz): <TAB> offset = None <TAB> if tz in UTC_ZONES: <TAB>  <TAB> offset = 0 <TAB> else: <TAB>  <TAB> m = TIMEZONE_RE.search(tz) <TAB>  <TAB> if m: <TAB>  <TAB>  <TAB> offset = 3600 * int(m.group(2)) <TAB>  <TAB>  <TAB> if m.group(3): <TAB>  <TAB>  <TAB>  <TAB> offset = offset + 60 * int(m.group(3)) <MASK> offset = -offset <TAB> return offset,"if m . group ( 1 ) == ""-"" :",130
"def process_z3(self, payload: str): <TAB> if payload.startswith(""CLI command executed""): <TAB>  <TAB> cmd = payload[22:-1] <MASK> # reset all buffers <TAB>  <TAB>  <TAB> self.z3buffer = {} <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.z3buffer[cmd] = self.z3buffer[""buffer""] <TAB>  <TAB> self.z3buffer[""buffer""] = """" <TAB>  <TAB> if cmd == ""plugin concentrator print-table"": <TAB>  <TAB>  <TAB> self._process_gateway_info() <TAB> elif self.z3buffer: <TAB>  <TAB> self.z3buffer[""buffer""] += payload","if cmd == ""debugprint all_on"" or self . z3buffer is None :",165
def finalize(self): <TAB> dtp = min_diff = None <TAB> while self.heap: <TAB>  <TAB> if min_diff is None: <TAB>  <TAB>  <TAB> if dtp is None: <TAB>  <TAB>  <TAB>  <TAB> dtp = heapq.heappop(self.heap) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> dt = heapq.heappop(self.heap) <TAB>  <TAB> diff = dt - dtp <MASK> min_diff = diff <TAB>  <TAB> dtp = dt <TAB> if min_diff is not None: <TAB>  <TAB> return total_seconds(min_diff),if min_diff is None or min_diff > diff :,143
"def _do_tls_handshake(self): <TAB> try: <TAB>  <TAB> self.socket.do_handshake() <TAB> except ssl.SSLError as err: <TAB>  <TAB> if err.args[0] in (ssl.SSL_ERROR_WANT_READ, ssl.SSL_ERROR_WANT_WRITE): <TAB>  <TAB>  <TAB> return <MASK> return self.handle_close() <TAB>  <TAB> raise <TAB> except OSError as err: <TAB>  <TAB> if err.args[0] == errno.ECONNABORTED: <TAB>  <TAB>  <TAB> return self.handle_close() <TAB> else: <TAB>  <TAB> self.tls_active = True <TAB>  <TAB> self.tls_starting = False",elif err . args [ 0 ] == ssl . SSL_ERROR_EOF :,170
"def test_get_keyboard_codes(): <TAB> ""Test all values returned by get_keyboard_codes are from curses."" <TAB> from blessed.keyboard import ( <TAB>  <TAB> get_keyboard_codes, <TAB>  <TAB> CURSES_KEYCODE_OVERRIDE_MIXIN, <TAB> ) <TAB> exemptions = dict(CURSES_KEYCODE_OVERRIDE_MIXIN) <TAB> for value, keycode in get_keyboard_codes().items(): <MASK> assert value == exemptions[keycode] <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> assert hasattr(curses, keycode) <TAB>  <TAB> assert getattr(curses, keycode) == value",if keycode in exemptions :,154
"def _clean_text(self, text: str) -> str: <TAB> """"""Performs invalid character removal and whitespace cleanup on text."""""" <TAB> output = [] <TAB> for char in text: <TAB>  <TAB> cp = ord(char) <TAB>  <TAB> if cp == 0 or cp == 0xFFFD or _is_control(char): <TAB>  <TAB>  <TAB> continue <MASK> output.append("" "") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> output.append(char) <TAB> return """".join(output)",if _is_whitespace ( char ) :,118
"def merge(self, flags): <TAB> for flag in self.get_items(flags): <TAB>  <TAB> if isinstance(flag, tuple): <TAB>  <TAB>  <TAB> self._values[flag[0]] = flag[1:] <TAB>  <TAB>  <TAB> self._items[flag[0]] = flag <MASK> # Ignore some flags <TAB>  <TAB>  <TAB> self._items[flag] = flag","elif flag and flag not in ( ""fuzzy"" , ""#"" ) :",97
"def wait_for_daemon_pid(self, timeout=10): <TAB> """"""Wait up to timeout seconds for the PID file to appear and return the PID"""""" <TAB> endtime = time.time() + timeout <TAB> while True: <TAB>  <TAB> pid = self.daemon_pid <MASK> return pid <TAB>  <TAB> if endtime < time.time(): <TAB>  <TAB>  <TAB> raise TimeoutError( <TAB>  <TAB>  <TAB>  <TAB> 'Timeout waiting for ""{0}"" pid in ""{1}""'.format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.name, self.abs_path(self.pid_path) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> time.sleep(0.2)",if pid :,154
"def convert_data(self, tensor, layer_mkl): <TAB> if not layer_mkl and tensor is not None: <MASK> self.convert(tensor) <TAB>  <TAB>  <TAB> tensor.clean_mkl() <TAB>  <TAB> elif type(tensor) is list or type(tensor) is tuple: <TAB>  <TAB>  <TAB> for i in tensor: <TAB>  <TAB>  <TAB>  <TAB> self.convert_data(i, layer_mkl) <TAB>  <TAB> elif type(tensor) is OpTreeNode or type(tensor) is np.ndarray: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert False, ""unsupported input for convert "" + str(type(tensor))",if type ( tensor ) == MKLTensor :,156
"def _traverse(op): <TAB> if topi.tag.is_broadcast(op.tag): <TAB>  <TAB> if not op.same_as(output.op): <MASK> const_ops.append(op) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> ewise_ops.append(op) <TAB>  <TAB> for tensor in op.input_tensors: <TAB>  <TAB>  <TAB> if isinstance(tensor.op, tvm.te.PlaceholderOp): <TAB>  <TAB>  <TAB>  <TAB> ewise_inputs.append((op, tensor)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> _traverse(tensor.op) <TAB> else: <TAB>  <TAB> assert op.tag == ""packed_group_conv2d"" <TAB>  <TAB> conv2d_res.append(op)",if not op . axis :,180
"def Sleep(self, timeout): <TAB> """"""Sleeps the calling thread with heartbeat."""""" <MASK> self.nanny_controller.Heartbeat() <TAB> # Split a long sleep interval into 1 second intervals so we can heartbeat. <TAB> while timeout > 0: <TAB>  <TAB> time.sleep(min(1.0, timeout)) <TAB>  <TAB> timeout -= 1 <TAB>  <TAB> # If the output queue is full, we are ready to do a post - no <TAB>  <TAB> # point in waiting. <TAB>  <TAB> if self._out_queue.Full(): <TAB>  <TAB>  <TAB> return <TAB>  <TAB> if self.nanny_controller: <TAB>  <TAB>  <TAB> self.nanny_controller.Heartbeat()",if self . nanny_controller :,155
"def escape(text, newline=False): <TAB> """"""Escape special html characters."""""" <TAB> if isinstance(text, basestring): <TAB>  <TAB> if ""&"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""&"", ""&amp;"") <TAB>  <TAB> if "">"" in text: <TAB>  <TAB>  <TAB> text = text.replace("">"", ""&gt;"") <TAB>  <TAB> if ""<"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""<"", ""&lt;"") <TAB>  <TAB> if '""' in text: <TAB>  <TAB>  <TAB> text = text.replace('""', ""&quot;"") <TAB>  <TAB> if ""'"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""'"", ""&quot;"") <MASK> if ""\n"" in text: <TAB>  <TAB>  <TAB>  <TAB> text = text.replace(""\n"", ""<br>"") <TAB> return text",if newline :,170
"def remove_callback(self, callback): <TAB> hostname = self._cb_to_hostname.get(callback) <TAB> if hostname: <TAB>  <TAB> del self._cb_to_hostname[callback] <TAB>  <TAB> arr = self._hostname_to_cb.get(hostname, None) <TAB>  <TAB> if arr: <TAB>  <TAB>  <TAB> arr.remove(callback) <MASK> del self._hostname_to_cb[hostname] <TAB>  <TAB>  <TAB>  <TAB> if hostname in self._hostname_status: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> del self._hostname_status[hostname]",if not arr :,133
"def _poll(self, timeout=None): <TAB> self._assert_is_running() <TAB> if timeout is None: <TAB>  <TAB> return True <TAB> end_time = time.time() + timeout <TAB> delta = None <TAB> for pipe in self.parent_pipes: <TAB>  <TAB> delta = max(end_time - time.time(), 0) <TAB>  <TAB> if pipe is None: <TAB>  <TAB>  <TAB> return False <MASK> return False <TAB> return True",if pipe . closed or ( not pipe . poll ( delta ) ) :,119
"def copy_stemmer_js(self) -> None: <TAB> """"""Copy a JavaScript file for stemmer."""""" <TAB> if self.indexer is not None: <TAB>  <TAB> if hasattr(self.indexer, ""get_js_stemmer_rawcodes""): <TAB>  <TAB>  <TAB> for jsfile in self.indexer.get_js_stemmer_rawcodes(): <TAB>  <TAB>  <TAB>  <TAB> copyfile( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> jsfile, path.join(self.outdir, ""_static"", path.basename(jsfile)) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> jsfile = self.indexer.get_js_stemmer_rawcode() <MASK> copyfile(jsfile, path.join(self.outdir, ""_static"", ""_stemmer.js""))",if jsfile :,173
"def call_after_hooks(self, ctx): <TAB> cog = self.cog <TAB> if self._after_invoke is not None: <TAB>  <TAB> instance = getattr(self._after_invoke, ""__self__"", cog) <MASK> await self._after_invoke(instance, ctx) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> await self._after_invoke(ctx) <TAB> # call the cog local hook if applicable: <TAB> if cog is not None: <TAB>  <TAB> hook = Cog._get_overridden_method(cog.cog_after_invoke) <TAB>  <TAB> if hook is not None: <TAB>  <TAB>  <TAB> await hook(ctx) <TAB> hook = ctx.bot._after_invoke <TAB> if hook is not None: <TAB>  <TAB> await hook(ctx)",if instance :,177
"def largest_vl_vex(ii):  # and evex <TAB> vl = 0 <TAB> for op in _gen_opnds(ii): <TAB>  <TAB> if op_xmm(op): <TAB>  <TAB>  <TAB> vl = vl | 1 <MASK> vl = vl | 2 <TAB>  <TAB> elif op_zmm(op): <TAB>  <TAB>  <TAB> vl = vl | 4 <TAB> if vl >= 4: <TAB>  <TAB> return ""zmm"" <TAB> elif vl >= 2: <TAB>  <TAB> return ""ymm"" <TAB> return ""xmm""",elif op_ymm ( op ) :,139
def toggle_marker_edges(self): <TAB> for artist in self.artists: <MASK> artist._mt_markeredgewidth = artist.get_markeredgewidth() <TAB>  <TAB>  <TAB> artist.set_markeredgewidth(0) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> artist.set_markeredgewidth(artist._mt_markeredgewidth),if artist . get_markeredgewidth ( ) != 0 :,99
"def decorate_urlpatterns(urlpatterns, decorator): <TAB> """"""Decorate all the views in the passed urlpatterns list with the given decorator"""""" <TAB> for pattern in urlpatterns: <MASK> # this is an included RegexURLResolver; recursively decorate the views <TAB>  <TAB>  <TAB> # contained in it <TAB>  <TAB>  <TAB> decorate_urlpatterns(pattern.url_patterns, decorator) <TAB>  <TAB> if getattr(pattern, ""callback"", None): <TAB>  <TAB>  <TAB> pattern.callback = update_wrapper( <TAB>  <TAB>  <TAB>  <TAB> decorator(pattern.callback), pattern.callback <TAB>  <TAB>  <TAB> ) <TAB> return urlpatterns","if hasattr ( pattern , ""url_patterns"" ) :",137
"def _do_checkpoint(self): <TAB> if self.checkpoint_path: <MASK> _generated = list( <TAB>  <TAB>  <TAB>  <TAB> map(int, CheckpointRDD.generated_files(self.checkpoint_path)) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> if len(_generated) != len(self): <TAB>  <TAB>  <TAB>  <TAB> missing = [sp.index for sp in self.splits if sp.index not in _generated] <TAB>  <TAB>  <TAB>  <TAB> sum(self.ctx.runJob(self, lambda x: list(x), missing), []) <TAB>  <TAB>  <TAB> self._pickle_cache = None <TAB>  <TAB>  <TAB> self._checkpoint_rdd = CheckpointRDD(self.ctx, self.checkpoint_path) <TAB>  <TAB>  <TAB> self._clear_dependencies() <TAB>  <TAB> return False <TAB> return True",if not self . _checkpoint_rdd :,188
"def __getitem__(self, index): <TAB> if isinstance(index, slice): <TAB>  <TAB> start, stop, step = index.indices(self._len()) <TAB>  <TAB> return xrange(self._index(start), self._index(stop), step * self.step) <TAB> elif isinstance(index, numbers.Integral): <TAB>  <TAB> if index < 0: <TAB>  <TAB>  <TAB> fixed_index = index + self._len() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> fixed_index = index <MASK> raise IndexError(""Index %d out of %r"" % (index, self)) <TAB>  <TAB> return self._index(fixed_index) <TAB> else: <TAB>  <TAB> raise TypeError(""xrange indices must be slices or integers"")",if not 0 <= fixed_index < self . _len ( ) :,172
"def remove_private_elements(elem): <TAB> """"""Remove all the private cix elements."""""" <TAB> parent_map = dict((c, p) for p in elem.getiterator() for c in p) <TAB> for node in list(elem.getiterator()): <TAB>  <TAB> attributes = node.get(""attributes"", """").split("" "") <TAB>  <TAB> if ""private"" in attributes or ""__hidden__"" in attributes: <TAB>  <TAB>  <TAB> # Remove it <TAB>  <TAB>  <TAB> parentnode = parent_map.get(node) <MASK> parentnode.remove(node)",if parentnode is not None :,132
"def build_response_from_proxy_result(self, response, result): <TAB> """"""Make a unified response format for requests going to old Jasmin http api"""""" <TAB> if result[0] != 200: <TAB>  <TAB> response.body = json.dumps({""message"": result[1]}) <TAB> else: <MASK> # It's a json result <TAB>  <TAB>  <TAB> response.body = {""data"": json.loads(result[1])} <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> response.body = {""data"": result[1]} <TAB> response.status = getattr(falcon, ""HTTP_%s"" % result[0])","if ""{"" in result [ 1 ] :",147
"def __getattr__(self, key): <TAB> if key in self._raw: <TAB>  <TAB> val = self._raw[key] <MASK> return pd.Timestamp(val, tz=NY, unit=self._unit) <TAB>  <TAB> return val <TAB> return getattr(super(), key)",if key in self . _tskeys :,76
"def _validate_secret_list(self, secrets, expected): <TAB> async for secret in secrets: <MASK> expected_secret = expected[secret.name] <TAB>  <TAB>  <TAB> self._assert_secret_attributes_equal(expected_secret.properties, secret) <TAB>  <TAB>  <TAB> del expected[secret.name] <TAB> self.assertEqual(len(expected), 0)",if secret . name in expected . keys ( ) :,94
"def emit(self, binop, conj, *args): <TAB> assert len(args) > 1 <TAB> parts = [] <TAB> for ix, arg in enumerate(args): <MASK> op = binop[ix] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> op = binop <TAB>  <TAB> if ix > 0: <TAB>  <TAB>  <TAB> parts += ["" "", conj, "" ""] <TAB>  <TAB> parts += [""("", arg[0], "" "", op, "" "", arg[1], "")""] <TAB> yield self.part(""("", *parts, "")"")","if isinstance ( binop , ( tuple , list ) ) :",131
"def _handle(self, key, value, single, multi, unaliased): <TAB> # Attribute existence test required to not blow up when deepcopy'd <TAB> if key in getattr(self, ""aliases"", {}): <TAB>  <TAB> target = self.aliases[key] <TAB>  <TAB> # Single-string targets <TAB>  <TAB> if isinstance(target, six.string_types): <TAB>  <TAB>  <TAB> return single(self, target, value) <TAB>  <TAB> # Multi-string targets <TAB>  <TAB> else: <MASK> return multi(self, target, value) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> for subkey in target: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> single(self, subkey, value) <TAB> else: <TAB>  <TAB> return unaliased(self, key, value)",if multi :,175
"def _select(self): <TAB> """"""Does select on open connections."""""" <TAB> readable = [self.socket.handle.fileno(), self._read.fileno()] <TAB> writable = [] <TAB> for i, connection in self.clients.items(): <MASK> readable.append(connection.fileno()) <TAB>  <TAB> if connection.is_writeable(): <TAB>  <TAB>  <TAB> writable.append(connection.fileno()) <TAB>  <TAB> if connection.is_closed(): <TAB>  <TAB>  <TAB> del self.clients[i] <TAB> return select.select(readable, writable, readable)",if connection . is_readable ( ) :,131
"def unhook(self): <TAB> if not self.is_hooked: <TAB>  <TAB> return <TAB> if not self.had_module: <TAB>  <TAB> del sys.modules[""warnings""] <TAB> else: <MASK> sys.modules[""warnings""].warn = self.old_warn <TAB>  <TAB> if self.old_warn_explicit: <TAB>  <TAB>  <TAB> sys.modules[""warnings""].warn_explicit = self.old_warn_explicit <TAB> self.is_hooked = False",if self . old_warn :,116
"def htmldiff(self): <TAB> val_a = force_str( <TAB>  <TAB> dict(self.field.flatchoices).get(self.val_a, self.val_a), strings_only=True <TAB> ) <TAB> val_b = force_str( <TAB>  <TAB> dict(self.field.flatchoices).get(self.val_b, self.val_b), strings_only=True <TAB> ) <TAB> if self.val_a != self.val_b: <TAB>  <TAB> diffs = [] <TAB>  <TAB> if val_a: <TAB>  <TAB>  <TAB> diffs += [(""deletion"", val_a)] <MASK> diffs += [(""addition"", val_b)] <TAB>  <TAB> return TextDiff(diffs).to_html() <TAB> else: <TAB>  <TAB> return escape(val_a)",if val_b :,185
"def __walkInputs(parent): <TAB> for child in parent.children(): <TAB>  <TAB> if len(child): <TAB>  <TAB>  <TAB> __walkInputs(child) <TAB>  <TAB> elif isinstance(child, Gaffer.ValuePlug): <MASK> inputPlugs.append(child)",if child not in inputsToIgnore :,79
"def _load_state_geometry(self) -> None: <TAB> """"""Load the geometry from the state file."""""" <TAB> try: <TAB>  <TAB> data = configfiles.state[""inspector""][""window""] <TAB>  <TAB> geom = base64.b64decode(data, validate=True) <TAB> except KeyError: <TAB>  <TAB> # First start <TAB>  <TAB> pass <TAB> except binascii.Error: <TAB>  <TAB> log.misc.exception(""Error while reading geometry"") <TAB> else: <TAB>  <TAB> log.init.debug(""Loading geometry from {!r}"".format(geom)) <TAB>  <TAB> ok = self._widget.restoreGeometry(geom) <MASK> log.init.warning(""Error while loading geometry."")",if not ok :,156
"def _check_only_if_needed_labels(self, job_dependencies, host_labels, queue_entry): <TAB> if not queue_entry.meta_host: <TAB>  <TAB> # bypass only_if_needed labels when a specific host is selected <TAB>  <TAB> return True <TAB> for label_id in host_labels: <TAB>  <TAB> label = self._labels[label_id] <TAB>  <TAB> if not label.only_if_needed: <TAB>  <TAB>  <TAB> # we don't care about non-only_if_needed labels <TAB>  <TAB>  <TAB> continue <MASK> # if the label was requested in a metahost it's OK <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if label_id not in job_dependencies: <TAB>  <TAB>  <TAB> return False <TAB> return True",if queue_entry . meta_host == label_id :,182
"def _handle_lusubcorpus_elt(self, elt): <TAB> """"""Load a subcorpus of a lexical unit from the given xml."""""" <TAB> sc = AttrDict() <TAB> try: <TAB>  <TAB> sc[""name""] = str(elt.get(""name"")) <TAB> except AttributeError: <TAB>  <TAB> return None <TAB> sc[""_type""] = ""lusubcorpus"" <TAB> sc[""sentence""] = [] <TAB> for sub in elt: <TAB>  <TAB> if sub.tag.endswith(""sentence""): <TAB>  <TAB>  <TAB> s = self._handle_lusentence_elt(sub) <MASK> sc[""sentence""].append(s) <TAB> return sc",if s is not None :,144
"def cleanup_unused(self) -> List[str]: <TAB> """"""Removes unused strings, returning list of additional changed files."""""" <TAB> existing = {unit.context for unit in self.template_store.mono_units} <TAB> changed = False <TAB> result = [] <TAB> for ttkit_unit in self.all_store_units: <MASK> item = self.delete_unit(ttkit_unit) <TAB>  <TAB>  <TAB> if item is not None: <TAB>  <TAB>  <TAB>  <TAB> result.append(item) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> changed = True <TAB> if changed: <TAB>  <TAB> self.save() <TAB> return result","if self . unit_class ( self , ttkit_unit , ttkit_unit ) . context not in existing :",172
"def __insertion(self): <TAB> result = [] <TAB> for i in range(1, len(self.domain) - 1): <TAB>  <TAB> for keys in self.keyboards: <MASK> for c in keys[self.domain[i]]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> result.append( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.domain[:i] + c + self.domain[i] + self.domain[i + 1 :] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> result.append( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.domain[:i] + self.domain[i] + c + self.domain[i + 1 :] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return list(set(result))",if self . domain [ i ] in keys :,176
"def _replace(sec, src=None, dst=None): <TAB> if not system.has_section(sec): <TAB>  <TAB> return <TAB> if not config.has_section(sec): <TAB>  <TAB> config.add_section(sec) <TAB> if src: <TAB>  <TAB> if system.has_option(sec, src): <TAB>  <TAB>  <TAB> items = [src] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> items = [] <TAB> else: <TAB>  <TAB> items = system.options(sec) <TAB> for item in items: <TAB>  <TAB> if dst: <TAB>  <TAB>  <TAB> _dst = dst <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _dst = item <MASK> config.set(sec, _dst, system.get(sec, item))","if not config . has_option ( sec , _dst ) :",180
"def Visit_testlist_gexp(self, node):  # pylint: disable=invalid-name <TAB> self.DefaultNodeVisit(node) <TAB> prev_was_comma = False <TAB> for child in node.children: <TAB>  <TAB> if isinstance(child, pytree.Leaf) and child.value == "","": <TAB>  <TAB>  <TAB> _SetUnbreakable(child) <TAB>  <TAB>  <TAB> prev_was_comma = True <TAB>  <TAB> else: <MASK> _SetSplitPenalty(pytree_utils.FirstLeafNode(child), TOGETHER) <TAB>  <TAB>  <TAB> prev_was_comma = False",if prev_was_comma :,147
"def crop_to(self, geometry): <TAB> if self.geometry: <TAB>  <TAB> if self.geometry.is_valid and geometry.is_valid: <TAB>  <TAB>  <TAB> if self.geometry.intersects(geometry): <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.geometry = self.geometry.intersection(geometry) <TAB>  <TAB>  <TAB>  <TAB> except TopologicalError: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.geometry = None <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.geometry = None <TAB>  <TAB> else: <MASK> sys.stderr.write(""warning: geometry is invalid"")",if verbose :,141
"def _build_data(ln: str, data_path: Path) -> List[Tuple[Tuple[str, str], int]]: <TAB> data = {} <TAB> with open(data_path, ""r"") as f: <TAB>  <TAB> for line in f: <TAB>  <TAB>  <TAB> jline = json.loads(line) <TAB>  <TAB>  <TAB> if ln == ""ru"": <TAB>  <TAB>  <TAB>  <TAB> if ""label"" in jline: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> data[jline[""question""], jline[""passage""]] = int(jline[""label""]) <TAB>  <TAB>  <TAB> if ln == ""en"": <MASK> data[jline[""question""], jline[""passage""]] = int(jline[""answer""]) <TAB> return list(data.items())","if ""answer"" in jline :",180
def zigzag_level(root): <TAB> res = [] <TAB> if not root: <TAB>  <TAB> return res <TAB> level = [root] <TAB> flag = 1 <TAB> while level: <TAB>  <TAB> current = [] <TAB>  <TAB> new_level = [] <TAB>  <TAB> for node in level: <TAB>  <TAB>  <TAB> current.append(node.val) <TAB>  <TAB>  <TAB> if node.left: <TAB>  <TAB>  <TAB>  <TAB> new_level.append(node.left) <MASK> new_level.append(node.right) <TAB>  <TAB> level = new_level <TAB>  <TAB> res.append(current[::flag]) <TAB>  <TAB> flag *= -1 <TAB> return res,if node . right :,156
"def _all_op(self, doc_val, search_val): <TAB> if isinstance(doc_val, list) and doc_val and isinstance(doc_val[0], list): <TAB>  <TAB> doc_val = list(itertools.chain.from_iterable(doc_val)) <TAB> dv = _force_list(doc_val) <TAB> matches = [] <TAB> for x in search_val: <MASK> matches.append(self._elem_match_op(doc_val, x[""$elemMatch""])) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> matches.append(x in dv) <TAB> return all(matches)","if isinstance ( x , dict ) and ""$elemMatch"" in x :",159
"def open_folder(e=None): <TAB> global folder, mhf <TAB> sel = folderbox.curselection() <TAB> if len(sel) != 1: <MASK> msg = ""Please open one folder at a time"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> msg = ""Please select a folder to open"" <TAB>  <TAB> dialog(root, ""Can't Open Folder"", msg, """", 0, ""OK"") <TAB>  <TAB> return <TAB> i = sel[0] <TAB> folder = folderbox.get(i) <TAB> mhf = mh.openfolder(folder) <TAB> rescan()",if len ( sel ) > 1 :,145
"def _get_db(self): <TAB> kwargs = {} <TAB> if self.is_replica_set: <TAB>  <TAB> kwargs[""replicaSet""] = self.configuration[""replicaSetName""] <TAB>  <TAB> readPreference = self.configuration.get(""readPreference"") <MASK> kwargs[""readPreference""] = readPreference <TAB> db_connection = pymongo.MongoClient( <TAB>  <TAB> self.configuration[""connectionString""], **kwargs <TAB> ) <TAB> return db_connection[self.db_name]",if readPreference :,118
def scan(children): <TAB> for element in children: <TAB>  <TAB> if element.type in names: <TAB>  <TAB>  <TAB> yield element <MASK> for e in scan(element.children): <TAB>  <TAB>  <TAB>  <TAB> yield e,if element . type in _FUNC_CONTAINERS :,63
"def _handle_And(self, expr): <TAB> arg0, arg1 = expr.args <TAB> r0 = self._expr(arg0) <TAB> r1 = self._expr(arg1) <TAB> try: <MASK> # constants <TAB>  <TAB>  <TAB> return RichR(r0.data & r1.data) <TAB>  <TAB> r = None <TAB>  <TAB> if r0.data is not None and r1.data is not None: <TAB>  <TAB>  <TAB> r = r0.data & r1.data <TAB>  <TAB> return RichR(r) <TAB> except TypeError as e: <TAB>  <TAB> self.l.warning(e) <TAB>  <TAB> return RichR(None)","if isinstance ( r0 . data , int ) and isinstance ( r1 . data , int ) :",177
"def _calc_order(self, a, b, out): <TAB> if out is not None: <TAB>  <TAB> return out.order <TAB> if self._order in ""A"": <MASK> return TensorOrder.C_ORDER <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return TensorOrder.F_ORDER <TAB> elif self._order in ""CK"": <TAB>  <TAB> return TensorOrder.C_ORDER <TAB> else: <TAB>  <TAB> return TensorOrder.F_ORDER",if a . order == TensorOrder . C_ORDER or b . order == TensorOrder . C_ORDER :,121
"def getExprNames(text, context): <TAB> ex = stringToExpression(text, {}, context) <TAB> ast = expressionToAST(ex) <TAB> input_order = getInputOrder(ast, None) <TAB> # try to figure out if vml operations are used by expression <TAB> if not use_vml: <TAB>  <TAB> ex_uses_vml = False <TAB> else: <TAB>  <TAB> for node in ast.postorderWalk(): <MASK> ex_uses_vml = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ex_uses_vml = False <TAB> return [a.value for a in input_order], ex_uses_vml","if node . astType == ""op"" and node . value in vml_functions :",171
"def testcyc(self, sym, lv): <TAB> if self.settings == ""cyclic"": <MASK> return (self.lvs[lv] == sym, self.lvs[lv]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if sym not in self.lvs: <TAB>  <TAB>  <TAB>  <TAB> self.lvs[lv] = sym <TAB>  <TAB>  <TAB>  <TAB> return (True, None) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return (False, None) <TAB> if self.settings == ""any"": <TAB>  <TAB> if self.lvs[lv]: <TAB>  <TAB>  <TAB> return self.lvs[lv] == sym <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.lvs[lv] = sym <TAB>  <TAB>  <TAB> return (True, None) <TAB> return (None, None)",if self . lvs [ lv ] :,180
"def on_cancel(self): <TAB> super(BuyingController, self).on_cancel() <TAB> if self.get(""is_return""): <TAB>  <TAB> return <TAB> update_last_purchase_rate(self, is_submit=0) <TAB> if self.doctype in [""Purchase Receipt"", ""Purchase Invoice""]: <TAB>  <TAB> field = ( <TAB>  <TAB>  <TAB> ""purchase_invoice"" <MASK> else ""purchase_receipt"" <TAB>  <TAB> ) <TAB>  <TAB> self.delete_linked_asset() <TAB>  <TAB> self.update_fixed_asset(field, delete_asset=True)","if self . doctype == ""Purchase Invoice""",146
"def get_rules_to_compare(benchmark, rule_id): <TAB> if rule_id: <MASK> rule_id = ssg.constants.OSCAP_RULE + rule_id <TAB>  <TAB> rules = benchmark.findall("".//xccdf:Rule[@id='%s']"" % (rule_id), ns) <TAB>  <TAB> if len(rules) == 0: <TAB>  <TAB>  <TAB> raise ValueError(""Can't find rule %s"" % (rule_id)) <TAB> else: <TAB>  <TAB> rules = benchmark.findall("".//xccdf:Rule"", ns) <TAB> return rules",if not rule_id . startswith ( ssg . constants . OSCAP_RULE ) :,149
"def _process_bfc(self): <TAB> self.putc([ANN_BFC, [""Bit Field Clear"", ""BFC""]]) <TAB> if len(self.mosi) != 2: <TAB>  <TAB> self._put_command_warning(""Invalid command length."") <TAB>  <TAB> return <TAB> self._put_register_header() <TAB> self._put_data_byte(self.mosi[1], 1, True) <TAB> if self.mosi[0] & REG_ADDR_MASK == REG_ADDR_ECON1: <TAB>  <TAB> if self.mosi[1] & BIT_ECON1_BSEL0: <TAB>  <TAB>  <TAB> self.bsel0 = 0 <MASK> self.bsel1 = 0",if self . mosi [ 1 ] & BIT_ECON1_BSEL1 :,188
"def _update(self): <TAB> try: <TAB>  <TAB> while self._running: <TAB>  <TAB>  <TAB> await self._client(self._request) <TAB>  <TAB>  <TAB> await asyncio.sleep(self._delay) <TAB> except ConnectionError: <TAB>  <TAB> pass <TAB> except asyncio.CancelledError: <MASK> await self._client( <TAB>  <TAB>  <TAB>  <TAB> functions.messages.SetTypingRequest( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._chat, types.SendMessageCancelAction() <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> )",if self . _auto_cancel :,124
"def __setitem__(self, key, value): <TAB> if isinstance(key, int): <TAB>  <TAB> if not isinstance(value, ops.Moment): <TAB>  <TAB>  <TAB> raise TypeError(""Can only assign Moments into Circuits."") <TAB>  <TAB> self._device.validate_moment(value) <TAB>  <TAB> self._validate_op_tree_qids(value) <TAB> if isinstance(key, slice): <TAB>  <TAB> value = list(value) <MASK> raise TypeError(""Can only assign Moments into Circuits."") <TAB>  <TAB> for moment in value: <TAB>  <TAB>  <TAB> self._device.validate_moment(moment) <TAB>  <TAB>  <TAB> self._validate_op_tree_qids(moment) <TAB> self._moments[key] = value","if any ( not isinstance ( v , ops . Moment ) for v in value ) :",185
"def _finalize_mjbindings_options(cmd_instance): <TAB> """"""Post-process options relating to `build_mjbindings`."""""" <TAB> header_paths = [] <TAB> for filename in HEADER_FILENAMES: <TAB>  <TAB> full_path = os.path.join(cmd_instance.headers_dir, filename) <MASK> raise IOError(""Header file {!r} does not exist."".format(full_path)) <TAB>  <TAB> header_paths.append(full_path) <TAB> cmd_instance.header_paths = "" "".join(header_paths)",if not os . path . exists ( full_path ) :,140
"def depth_colors(self): <TAB> depth_colors = getattr(self, ""_depth_colors"", []) <TAB> if depth_colors: <TAB>  <TAB> return depth_colors <TAB> r = 255 <TAB> g = 0 <TAB> b = 0 <TAB> for z in range(128): <TAB>  <TAB> depth_colors.append(r) <TAB>  <TAB> depth_colors.append(g) <TAB>  <TAB> depth_colors.append(b) <TAB>  <TAB> if z < 32: <TAB>  <TAB>  <TAB> g += 7 <TAB>  <TAB> elif z < 64: <TAB>  <TAB>  <TAB> r -= 7 <MASK> b += 7 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> g -= 7 <TAB> self._depth_colors = depth_colors <TAB> return depth_colors",elif z < 96 :,169
"def _iter_basic_lines(): <TAB> _join = empty.join <TAB> buffer = [] <TAB> while 1: <TAB>  <TAB> new_data = next(_iter, """") <TAB>  <TAB> if not new_data: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> new_buf = [] <TAB>  <TAB> for item in chain(buffer, new_data.splitlines(True)): <TAB>  <TAB>  <TAB> new_buf.append(item) <MASK> yield _join(new_buf) <TAB>  <TAB>  <TAB>  <TAB> new_buf = [] <TAB>  <TAB> buffer = new_buf <TAB> if buffer: <TAB>  <TAB> yield _join(buffer)",if item and item [ - 1 : ] in crlf :,151
"def convert_gt_from_array_to_list(gt_batch, gt_batch_mask=None): <TAB> B, L = gt_batch.shape <TAB> gt_batch = gt_batch.astype(""int"") <TAB> gts = [] <TAB> for i in range(B): <MASK> l = L <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> l = int(gt_batch_mask[i, :].sum()) <TAB>  <TAB> gts.append(gt_batch[i, :l].tolist()) <TAB> return gts",if gt_batch_mask is None :,133
"def _packages(nodes): <TAB> for package_id, list_nodes in nodes.items(): <TAB>  <TAB> # The only way to have more than 1 states is to have 2 <TAB>  <TAB> # and one is BINARY_SKIP (privates) <TAB>  <TAB> binary = set(n.binary for n in list_nodes) <MASK> binary.remove(BINARY_SKIP) <TAB>  <TAB> assert len(binary) == 1 <TAB>  <TAB> binary = binary.pop() <TAB>  <TAB> out.writeln("" <TAB> %s - %s"" % (str(package_id), binary), Color.BRIGHT_CYAN)",if len ( binary ) > 1 :,144
"def update(self, t): <TAB> x, y = director.get_window_size() <TAB> for i in range(0, self.grid.x): <TAB>  <TAB> coords = self.get_original_tile(i, 0) <TAB>  <TAB> for c in range(0, len(coords), 3): <TAB>  <TAB>  <TAB> direction = 1 <MASK> direction = -1 <TAB>  <TAB>  <TAB> coords[c + 1] += direction * y * t <TAB>  <TAB> self.set_tile(i, 0, coords)",if i % 2 == 0 :,128
"def run(self, args): <TAB> pupy = self.client.remote(""pupy"") <TAB> active = obtain(pupy.manager.status) <TAB> data = [] <TAB> for task, state in active.iteritems(): <TAB>  <TAB> color = ""grey"" <TAB>  <TAB> if state[""active""]: <TAB>  <TAB>  <TAB> color = ""lightgreen"" <MASK> color = ""cyan"" <TAB>  <TAB> data.append( <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB> ""TASK"": Color(task, color), <TAB>  <TAB>  <TAB>  <TAB> ""ACTIVE"": Color(""Y"" if state[""active""] else ""N"", color), <TAB>  <TAB>  <TAB>  <TAB> ""RESULTS"": Color(""Y"" if state[""results""] else ""N"", color), <TAB>  <TAB>  <TAB> } <TAB>  <TAB> ) <TAB> self.log(Table(data, [""TASK"", ""ACTIVE"", ""RESULTS""]))","elif state [ ""results"" ] :",194
"def _sso_recurse(node, d): <TAB> d.update(node.attrib) <TAB> for c in node: <TAB>  <TAB> k = c.tag.split(""}"", 1)[-1] <TAB>  <TAB> cd = {} <MASK> if not isinstance(d[k], list): <TAB>  <TAB>  <TAB>  <TAB> d[k] = [d[k]] <TAB>  <TAB>  <TAB> d[k].append(cd) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> d[k] = cd <TAB>  <TAB> _sso_recurse(c, cd) <TAB> if node.text and node.text.strip(): <TAB>  <TAB> d[""Value""] = node.text.strip()",if k in d :,152
"def _check_account_visibility(*args, **kwargs): <TAB> v = get_config(ConfigTypes.ACCOUNT_VISIBILITY) <TAB> if v == AccountVisibilityTypes.PUBLIC: <TAB>  <TAB> return f(*args, **kwargs) <TAB> elif v == AccountVisibilityTypes.PRIVATE: <TAB>  <TAB> if authed(): <TAB>  <TAB>  <TAB> return f(*args, **kwargs) <TAB>  <TAB> else: <MASK> abort(403) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return redirect(url_for(""auth.login"", next=request.full_path)) <TAB> elif v == AccountVisibilityTypes.ADMINS: <TAB>  <TAB> if is_admin(): <TAB>  <TAB>  <TAB> return f(*args, **kwargs) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> abort(404)","if request . content_type == ""application/json"" :",191
"def scan_maps(self): <TAB> for generator in self.generator_list: <TAB>  <TAB> for ii in generator.parser_output.instructions: <TAB>  <TAB>  <TAB> if genutil.field_check(ii, ""iclass""): <TAB>  <TAB>  <TAB>  <TAB> if ii.is_vex(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.max_map_vex = max(self.max_map_vex, ii.get_map()) <MASK> self.max_map_evex = max(self.max_map_evex, ii.get_map())",elif ii . is_evex ( ) :,138
"def update_lp_progress(self): <TAB> if self.ammo_limit or self.lp_len: <MASK> if self.lp_len: <TAB>  <TAB>  <TAB>  <TAB> max_ammo = min(self.ammo_limit, self.lp_len) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> max_ammo = self.ammo_limit <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> max_ammo = self.lp_len <TAB>  <TAB> progress = int(float(self.ammo_count) / float(max_ammo) * 100.0) <TAB> else: <TAB>  <TAB> progress = 100 <TAB> if self.lp_progress != progress: <TAB>  <TAB> self.lp_progress = progress <TAB>  <TAB> self.update_view()",if self . ammo_limit :,183
"def read_deployment_config(filepaths, command: str): <TAB> from polyaxon.deploy import reader <TAB> if not filepaths: <TAB>  <TAB> return None <TAB> filepaths = to_list(filepaths) <TAB> for filepath in filepaths: <MASK> Printer.print_error( <TAB>  <TAB>  <TAB>  <TAB> ""`{}` must be a valid file"".format(filepath), <TAB>  <TAB>  <TAB>  <TAB> sys_exit=True, <TAB>  <TAB>  <TAB>  <TAB> command_help=""admin {}"".format(command), <TAB>  <TAB>  <TAB> ) <TAB> try: <TAB>  <TAB> deployment_config = reader.read(filepaths) <TAB>  <TAB> return deployment_config <TAB> except Exception as e: <TAB>  <TAB> handle_cli_error( <TAB>  <TAB>  <TAB> e, message=""Polyaxon deployment file is not valid."", sys_exit=True <TAB>  <TAB> )",if not os . path . isfile ( filepath ) :,195
"def default_property(self, value): <TAB> if hasattr(self.node, ""node_tree""):  # belong to group node <TAB>  <TAB> interface_socket = self.node.node_tree.inputs[self.index] <MASK> self.default_float_property = value <TAB>  <TAB> elif interface_socket.default_type == ""int"": <TAB>  <TAB>  <TAB> self.default_int_property = value <TAB> else: <TAB>  <TAB> if self.default_property_type == ""float"": <TAB>  <TAB>  <TAB> self.default_float_property = value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.default_int_property = value","if interface_socket . default_type == ""float"" :",157
"def __post_execution(self): <TAB> """"""Execute a script after executing the project."""""" <TAB> filePostExec = QFile(self.postExec) <TAB> if filePostExec.exists() and bool(QFile.ExeUser & filePostExec.permissions()): <TAB>  <TAB> ext = file_manager.get_file_extension(self.postExec) <TAB>  <TAB> if not self.pythonPath: <TAB>  <TAB>  <TAB> self.pythonPath = settings.PYTHON_PATH <TAB>  <TAB> self.currentProcess = self._postExecScriptProc <MASK> self._postExecScriptProc.start(self.pythonPath, [self.postExec]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._postExecScriptProc.start(self.postExec)","if ext == ""py"" :",173
"def _get_stream(self, stream_name, stream_arn): <TAB> if stream_name: <TAB>  <TAB> streams = [_ for _ in self.streams.values() if _.stream_name == stream_name] <MASK> raise ResourceNotFoundException() <TAB>  <TAB> stream = streams[0] <TAB> elif stream_arn: <TAB>  <TAB> stream = self.streams.get(stream_arn) <TAB>  <TAB> if stream is None: <TAB>  <TAB>  <TAB> raise ResourceNotFoundException() <TAB> return stream",if len ( streams ) == 0 :,120
"def has_change_permission(self, request, obj=None):  # pragma: no cover <TAB> opts = self.opts <TAB> if opts.auto_created: <TAB>  <TAB> for field in opts.fields: <MASK> opts = field.rel.to._meta <TAB>  <TAB>  <TAB>  <TAB> break <TAB> codename = get_permission_codename(""change"", opts) <TAB> return request.user.has_perm(""%s.%s"" % (opts.app_label, codename), obj)",if field . rel and field . rel . to != self . parent_model :,130
"def console(self): <TAB> """"""starts to interact (starts interactive console) Something like code.InteractiveConsole"""""" <TAB> while True: <TAB>  <TAB> if six.PY2: <TAB>  <TAB>  <TAB> code = raw_input("">>> "") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> code = input("">>>"") <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> print(self.eval(code)) <TAB>  <TAB> except KeyboardInterrupt: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> import traceback <MASK> sys.stderr.write(traceback.format_exc()) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> sys.stderr.write(""EXCEPTION: "" + str(e) + ""\n"") <TAB>  <TAB>  <TAB> time.sleep(0.01)",if DEBUG :,172
"def process_subscriptions(self, request): <TAB> agreed_channels = [] <TAB> echo_message = False <TAB> for qp in request.GET: <TAB>  <TAB> param = qp.strip().lower() <MASK> agreed_channels.append(param) <TAB>  <TAB> elif param == ""echo"": <TAB>  <TAB>  <TAB> echo_message = True <TAB> return agreed_channels, echo_message",if param in self . possible_channels :,101
"def new_record(cls, state_for_db=None, sourcewords=None, targetwords=None): <TAB> record = Record(cls.keys, compute_derived_values=cls._compute_derived_values) <TAB> if state_for_db is not None: <TAB>  <TAB> if state_for_db is UNTRANSLATED: <TAB>  <TAB>  <TAB> record[""untranslated""] = 1 <TAB>  <TAB>  <TAB> record[""untranslatedsourcewords""] = sourcewords <TAB>  <TAB> if state_for_db is TRANSLATED: <TAB>  <TAB>  <TAB> record[""translated""] = 1 <TAB>  <TAB>  <TAB> record[""translatedsourcewords""] = sourcewords <TAB>  <TAB>  <TAB> record[""translatedtargetwords""] = targetwords <MASK> record[""fuzzy""] = 1 <TAB>  <TAB>  <TAB> record[""fuzzysourcewords""] = sourcewords <TAB> return record",elif state_for_db is FUZZY :,196
"def zip_random_open_test(self, f, compression): <TAB> self.make_test_archive(f, compression) <TAB> # Read the ZIP archive <TAB> with zipfile.ZipFile(f, ""r"", compression) as zipfp: <TAB>  <TAB> zipdata1 = [] <TAB>  <TAB> with zipfp.open(TESTFN) as zipopen1: <TAB>  <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB>  <TAB> read_data = zipopen1.read(randint(1, 1024)) <MASK> break <TAB>  <TAB>  <TAB>  <TAB> zipdata1.append(read_data) <TAB>  <TAB> testdata = b"""".join(zipdata1) <TAB>  <TAB> self.assertEqual(len(testdata), len(self.data)) <TAB>  <TAB> self.assertEqual(testdata, self.data)",if not read_data :,183
"def _calc_ref_counts(t): <TAB> # calculate object refcount for t, this reduces memory usage in functions <TAB> if t.key in ref_visited: <TAB>  <TAB> return <TAB> ref_visited.add(t.key) <TAB> for inp in t.inputs: <TAB>  <TAB> _calc_ref_counts(inp) <MASK> if inp.key not in ref_counts: <TAB>  <TAB>  <TAB>  <TAB> ref_counts[inp.key] = 0 <TAB>  <TAB>  <TAB> ref_counts[inp.key] += 1","if not isinstance ( inp . op , input_op_types ) :",134
"def unlimited_query(q): <TAB> q[""limit""] = 1000 <TAB> q.setdefault(""offset"", 0) <TAB> q.setdefault(""sort"", ""key"") <TAB> while True: <TAB>  <TAB> result = self.query(q) <TAB>  <TAB> for r in result: <TAB>  <TAB>  <TAB> yield r <MASK> break <TAB>  <TAB> q[""offset""] += len(result)",if len ( result ) < 1000 :,95
"def visit_typeddict_type(self, tdt: TypedDictType) -> None: <TAB> if tdt.items: <TAB>  <TAB> for it in tdt.items.values(): <TAB>  <TAB>  <TAB> it.accept(self) <TAB> if tdt.fallback is not None: <MASK> if ( <TAB>  <TAB>  <TAB>  <TAB> lookup_qualified( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.modules, tdt.fallback.type_ref, self.allow_missing <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> is None <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> # We reject fake TypeInfos for TypedDict fallbacks because <TAB>  <TAB>  <TAB>  <TAB> # the latter are used in type checking and must be valid. <TAB>  <TAB>  <TAB>  <TAB> tdt.fallback.type_ref = ""typing._TypedDict"" <TAB>  <TAB> tdt.fallback.accept(self)",if tdt . fallback . type_ref is not None :,188
"def _find_exe(path, exe_list): <TAB> """"""Return a list of all exes in path, recursive."""""" <TAB> for filename in os.listdir(path): <TAB>  <TAB> if os.path.isfile(os.path.join(path, filename)): <MASK> exe_list.append(path + ""\\"" + filename) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> exe_list = _find_exe(path + ""\\"" + filename, exe_list) <TAB> return exe_list","if "".exe"" in filename :",121
"def readdir(self, path, buf, filler, offset, fip): <TAB> # Ignore raw_fi <TAB> for item in self.operations( <TAB>  <TAB> ""readdir"", self._decode_optional_path(path), fip.contents.fh <TAB> ): <MASK> name, st, offset = item, None, 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name, attrs, offset = item <TAB>  <TAB>  <TAB> if attrs: <TAB>  <TAB>  <TAB>  <TAB> st = c_stat() <TAB>  <TAB>  <TAB>  <TAB> set_st_attrs(st, attrs) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> st = None <TAB>  <TAB> if filler(buf, name.encode(self.encoding), st, offset) != 0: <TAB>  <TAB>  <TAB> break <TAB> return 0","if isinstance ( item , basestring ) :",182
"def _get_senders_and_signals(model): <TAB> yield model, post_save, _post_save_receiver <TAB> opts = model._meta.concrete_model._meta <TAB> for field in opts.local_many_to_many: <TAB>  <TAB> m2m_model = field.remote_field.through <MASK> if ""."" not in m2m_model: <TAB>  <TAB>  <TAB>  <TAB> m2m_model = ""{app_label}.{m2m_model}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> app_label=opts.app_label, m2m_model=m2m_model <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> yield m2m_model, m2m_changed, _m2m_changed_receiver","if isinstance ( m2m_model , str ) :",181
"def generator(self, data): <TAB> for (i, call_addr, hooked) in data: <MASK> sym_name = self.profile.get_symbol_by_address(""kernel"", call_addr) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sym_name = ""HOOKED"" <TAB>  <TAB> yield (0[Address(i), Address(call_addr), str(sym_name)])",if hooked == 0 :,97
"def _deserialize(config, raw_bytes, examples): <TAB> chainer = build_model(config, serialized=raw_bytes) <TAB> for *query, expected_response in examples: <TAB>  <TAB> query = [[q] for q in query] <TAB>  <TAB> actual_response = chainer(*query) <MASK> if actual_response is not None and len(actual_response) > 0: <TAB>  <TAB>  <TAB>  <TAB> actual_response = actual_response[0] <TAB>  <TAB>  <TAB> assert expected_response == str( <TAB>  <TAB>  <TAB>  <TAB> actual_response <TAB>  <TAB>  <TAB> ), f""Error in interacting with {model_dir} ({conf_file}): {query}""",if expected_response is not None :,158
"def generate_parameters(self, parameter_id, **kwargs): <TAB> params = {} <TAB> for k in self._space: <TAB>  <TAB> t, v = self._space[k][""_type""], self._space[k][""_value""] <MASK> params[k] = random.choice(v) <TAB>  <TAB> elif t == ""randint"": <TAB>  <TAB>  <TAB> params[k] = random.choice(range(v[0], v[1])) <TAB>  <TAB> elif t == ""uniform"": <TAB>  <TAB>  <TAB> params[k] = np.random.uniform(v[0], v[1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise RuntimeError(""parameter type {} is supported by DemoTuner!"".format(t)) <TAB> return params","if t == ""choice"" :",173
"def load_settings(mod_or_filename, settings, silent=False): <TAB> if isinstance(mod_or_filename, basestring): <TAB>  <TAB> conf = imp.new_module(""temp_config"") <TAB>  <TAB> conf.__file__ = mod_or_filename <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> execfile(mod_or_filename, conf.__dict__) <TAB>  <TAB> except IOError as e: <TAB>  <TAB>  <TAB> import errno <MASK> return settings <TAB>  <TAB>  <TAB> e.strerror = ""Unable to load configuration file (%s)"" % e.strerror <TAB>  <TAB>  <TAB> raise <TAB> else: <TAB>  <TAB> conf = mod_or_filename <TAB> add_settings(conf, settings=settings)","if silent and e . errno in ( errno . ENOENT , errno . EISDIR ) :",175
"def get_cells(): <TAB> """"""generator for sequence of code blocks to run"""""" <TAB> if fname.endswith("".ipynb""): <TAB>  <TAB> from nbformat import read <TAB>  <TAB> with io_open(fname) as f: <TAB>  <TAB>  <TAB> nb = read(f, as_version=4) <TAB>  <TAB>  <TAB> if not nb.cells: <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> for cell in nb.cells: <MASK> yield cell.source <TAB> else: <TAB>  <TAB> with open(fname) as f: <TAB>  <TAB>  <TAB> yield f.read()","if cell . cell_type == ""code"" :",141
"def can_match(self, other_structure): <TAB> if not self.collection_type_description.can_match_type( <TAB>  <TAB> other_structure.collection_type_description <TAB> ): <TAB>  <TAB> return False <TAB> if len(self.children) != len(other_structure.children): <TAB>  <TAB> return False <TAB> for my_child, other_child in zip(self.children, other_structure.children): <TAB>  <TAB> # At least one is nested collection... <MASK> return False <TAB>  <TAB> if not my_child[1].is_leaf and not my_child[1].can_match(other_child[1]): <TAB>  <TAB>  <TAB> return False <TAB> return True",if my_child [ 1 ] . is_leaf != other_child [ 1 ] . is_leaf :,179
"def run(self, doc): <TAB> for el in doc.iter(): <MASK> continue <TAB>  <TAB> class_ = self.get_class(el) <TAB>  <TAB> if class_: <TAB>  <TAB>  <TAB> # Append class <TAB>  <TAB>  <TAB> classes = (el.get(""class"", """") + "" "" + class_).strip() <TAB>  <TAB>  <TAB> el.set(""class"", classes)","if el . tag != ""a"" :",94
"def test_expire_one_user(self): <TAB> # alice should be logged out, but bob should not. <TAB> charlie, dylan = self.create_and_login_fake_users() <TAB> self.run_command(""charlie"") <TAB> start = timezone.now() <TAB> sessions = Session.objects.filter(expire_date__gte=start) <TAB> dylan_still_active = False <TAB> for session in sessions: <TAB>  <TAB> user_id = int(session.get_decoded().get(""_auth_user_id"")) <MASK> self.fail(""Charlie should not have active sessions."") <TAB>  <TAB> elif user_id == dylan.id: <TAB>  <TAB>  <TAB> dylan_still_active = True <TAB> assert dylan_still_active",if user_id == charlie . id :,191
"def update_sockets(self, context): <TAB> bools = [self.min_list, self.max_list, self.size_list] <TAB> dims = int(self.box_dimensions[0]) <TAB> for i in range(3): <TAB>  <TAB> for j in range(3): <TAB>  <TAB>  <TAB> out_index = 4 + j + 3 * i <TAB>  <TAB>  <TAB> hidden = self.outputs[out_index].hide_safe <MASK> if hidden: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.outputs[out_index].hide_safe = False <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.outputs[out_index].hide_safe = True <TAB>  <TAB> updateNode(self, context)",if bools [ i ] [ j ] and j < dims :,175
"def process_response(self, request, response): <TAB> if hasattr(request, ""_misago_online_tracker""): <TAB>  <TAB> online_tracker = request._misago_online_tracker <MASK> if request.user.is_anonymous: <TAB>  <TAB>  <TAB>  <TAB> tracker.stop_tracking(request, online_tracker) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> tracker.update_tracker(request, online_tracker) <TAB> return response",if online_tracker :,109
"def _return_from_invocation(self): <TAB> if self.return_ty != ""void"": <TAB>  <TAB> ret_value = self.state.javavm_registers.load(""invoke_return_value"") <MASK> return self.state.jni_references.create_new_reference(ret_value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ret_value","if self . return_ty == ""reference"" :",100
"def close_incident_reminder(db_session=None): <TAB> """"""Sends a reminder to the IC to close out their incident."""""" <TAB> incidents = get_all_by_status(db_session=db_session, status=IncidentStatus.stable) <TAB> for incident in incidents: <TAB>  <TAB> span = datetime.utcnow() - incident.stable_at <TAB>  <TAB> q, r = divmod( <TAB>  <TAB>  <TAB> span.days, 7 <TAB>  <TAB> )  # only for incidents that have been stable longer than a week <TAB>  <TAB> if q >= 1 and r == 0: <MASK> # lets only send on mondays <TAB>  <TAB>  <TAB>  <TAB> send_incident_close_reminder(incident, db_session)",if date . today ( ) . isoweekday ( ) == 1 :,184
"def _get_console_formatter(self, format): <TAB> colorize = self.app.config.get(""log.colorlog"", ""colorize_console_log"") <TAB> if sys.stdout.isatty() or ""CEMENT_TEST"" in os.environ: <MASK> formatter = self._meta.formatter_class(format, log_colors=self._meta.colors) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> formatter = self._meta.formatter_class_without_color(format) <TAB> else: <TAB>  <TAB> klass = self._meta.formatter_class_without_color  # pragma: nocover <TAB>  <TAB> formatter = klass(format)  # pragma: nocover <TAB> return formatter",if is_true ( colorize ) :,164
"def run_client(): <TAB> http = HTTPConnection(*server.server_address) <TAB> http.request(""GET"", ""/"") <TAB> with http.getresponse() as response: <TAB>  <TAB> response.read(100) <TAB>  <TAB> # The main thread should now be blocking in a send() system <TAB>  <TAB> # call.  But in theory, it could get interrupted by other <TAB>  <TAB> # signals, and then retried.  So keep sending the signal in a <TAB>  <TAB> # loop, in case an earlier signal happens to be delivered at <TAB>  <TAB> # an inconvenient moment. <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> pthread_kill(main_thread, signal.SIGUSR1) <MASK> break <TAB>  <TAB> nonlocal received <TAB>  <TAB> received = len(response.read()) <TAB> http.close()",if interrupted . wait ( timeout = float ( 1 ) ) :,195
"def _next_partition(self, topic): <TAB> if topic not in self.partition_cycles: <TAB>  <TAB> if not self.client.has_metadata_for_topic(topic): <TAB>  <TAB>  <TAB> self.client.ensure_topic_exists(topic) <TAB>  <TAB> self.partition_cycles[topic] = cycle( <TAB>  <TAB>  <TAB> self.client.get_partition_ids_for_topic(topic) <TAB>  <TAB> ) <TAB>  <TAB> # Randomize the initial partition that is returned <MASK> num_partitions = len(self.client.get_partition_ids_for_topic(topic)) <TAB>  <TAB>  <TAB> for _ in xrange(random.randint(0, num_partitions - 1)): <TAB>  <TAB>  <TAB>  <TAB> next(self.partition_cycles[topic]) <TAB> return next(self.partition_cycles[topic])",if self . random_start :,193
"def check_task_prereqs(cls, data: Dict) -> Dict: <TAB> for idx, task in enumerate(data[""tasks""]): <TAB>  <TAB> # prereq_tasks must refer to previously defined tasks, using the u128 <TAB>  <TAB> #  representation of the UUID as an index <MASK> for prereq in task.prereq_tasks: <TAB>  <TAB>  <TAB>  <TAB> if prereq.int >= idx: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise Exception(f""invalid task reference: {idx} - {prereq}"") <TAB> return data",if task . prereq_tasks :,129
"def _dump_one_caller(key, file, level=0): <TAB> leader = "" <TAB>   "" * level <TAB> for v, c in sorted([(-v, c) for c, v in caller_dicts[key].items()]): <TAB>  <TAB> file.write(""%s  %6d %s:%d(%s)\n"" % ((leader, -v) + func_shorten(c[-3:]))) <MASK> _dump_one_caller(c, file, level + 1)",if c in caller_dicts :,124
"def subsystem_dependencies_iter(cls): <TAB> """"""Iterate over the direct subsystem dependencies of this Optionable."""""" <TAB> for dep in cls.subsystem_dependencies(): <MASK> yield dep <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield SubsystemDependency( <TAB>  <TAB>  <TAB>  <TAB> dep, GLOBAL_SCOPE, removal_version=None, removal_hint=None <TAB>  <TAB>  <TAB> )","if isinstance ( dep , SubsystemDependency ) :",97
"def get_server_status(self): <TAB> """"""Generate a copy of the server status object that contains the public IP or hostname."""""" <TAB> server_status = {} <TAB> for item in self._server_status.items(): <TAB>  <TAB> key, value = item <TAB>  <TAB> public_host = self.headers.get(""host"").split("":"")[0] <TAB>  <TAB> if key == ""http-uri"": <TAB>  <TAB>  <TAB> server_status[key] = value.replace(self._config[""http-host""], public_host) <MASK> server_status[key] = value.replace(self._config[""https-host""], public_host) <TAB>  <TAB> if key == ""wss-uri"": <TAB>  <TAB>  <TAB> server_status[key] = value.replace(self._config[""wss-host""], public_host) <TAB> return server_status","if key == ""https-uri"" :",198
"def add_transfer_d(self, user, transfer): <TAB> if user is None: <TAB>  <TAB> self.server_transfer_dl += transfer <TAB> else: <MASK> self.server_user_transfer_dl[user] = 0 <TAB>  <TAB> self.server_user_transfer_dl[user] += transfer + self.server_transfer_dl <TAB>  <TAB> self.server_transfer_dl = 0",if user not in self . server_user_transfer_dl :,109
"def run(self): <TAB> for k, v in iteritems(self.objs): <TAB>  <TAB> if k.startswith(""_""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if v[""_class""] == ""Dataset"" and v[""task_type""] == ""Communication"": <TAB>  <TAB>  <TAB> params = json.loads(v[""task_type_parameters""]) <MASK> params = [1] <TAB>  <TAB>  <TAB> v[""task_type_parameters""] = json.dumps(params) <TAB> return self.objs",if len ( params ) < 1 :,121
"def propagate_levelling(qindex, level, x, xleveled, i): <TAB> for j in range(1, len(qlist)): <TAB>  <TAB> if i == j: <TAB>  <TAB>  <TAB> continue <MASK> newxj = x[i][0] + crt[(i, j)][qindex][0] <TAB>  <TAB>  <TAB> x[j] = (newxj, min(x[i][1], crt[(i, j)][qindex][1])) <TAB>  <TAB>  <TAB> xleveled[j] = True <TAB>  <TAB>  <TAB> propagate_levelling(qindex, level, x, xleveled, j)","if not xleveled [ j ] and crt [ ( i , j ) ] [ qindex ] [ 1 ] >= level :",166
"def run_on_module(self): <TAB> try: <TAB>  <TAB> self.module_base.switch_to(self.opts.module_spec, strict=self.base.conf.strict) <TAB> except dnf.exceptions.MarkingErrors as e: <MASK> if e.no_match_group_specs or e.error_group_specs: <TAB>  <TAB>  <TAB>  <TAB> raise e <TAB>  <TAB> logger.error(str(e))",if self . base . conf . strict :,111
"def most_visited_path(self): <TAB> node = self <TAB> output = [] <TAB> while node.children: <TAB>  <TAB> next_kid = np.argmax(node.child_N) <TAB>  <TAB> node = node.children.get(next_kid) <MASK> output.append(""GAME END"") <TAB>  <TAB>  <TAB> break <TAB>  <TAB> output.append( <TAB>  <TAB>  <TAB> ""%s (%d) ==> "" % (coords.to_kgs(coords.from_flat(node.fmove)), node.N) <TAB>  <TAB> ) <TAB> output.append(""Q: {:.5f}\n"".format(node.Q)) <TAB> return """".join(output)",if node is None :,159
"def format_xmm(self, val): <TAB> if self.config.orientation == ""vertical"": <TAB>  <TAB> height, width = self.window_size() <MASK> return val[:16] + ""\n"" + "" "" * self.XMM_INDENT + val[16:] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return val[:16] + "":"" + val[16:] <TAB> else: <TAB>  <TAB> return val",if width < len ( SHORT_ADDR_FORMAT_128 . format ( 0 ) ) + self . XMM_INDENT :,122
"def stream(): <TAB> for image in images: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.instance.remove_image(image, **kwargs) <TAB>  <TAB>  <TAB> self.is_refresh_images = True <MASK> yield ""{:.25}"".format(image) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield image <TAB>  <TAB> except APIError as ex: <TAB>  <TAB>  <TAB> yield ""{0:.25}: {1}"".format(image, ex.explanation)",if truncate_output :,111
"def _fill(self): <TAB> data = {} <TAB> zone_tab = open_resource(""zone.tab"") <TAB> try: <TAB>  <TAB> for line in zone_tab: <TAB>  <TAB>  <TAB> line = line.decode(""UTF-8"") <TAB>  <TAB>  <TAB> if line.startswith(""#""): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> code, coordinates, zone = line.split(None, 4)[:3] <MASK> continue <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> data[code].append(zone) <TAB>  <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB>  <TAB> data[code] = [zone] <TAB>  <TAB> self.data = data <TAB> finally: <TAB>  <TAB> zone_tab.close()",if zone not in all_timezones_set :,169
"def frontendediting_response_processor(page, request, response): <TAB> # Add never cache headers in case frontend editing is active <TAB> if hasattr(request, ""COOKIES"") and request.COOKIES.get(""frontend_editing"", False): <MASK> response.add_post_render_callback(add_never_cache_headers) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> add_never_cache_headers(response)","if hasattr ( response , ""add_post_render_callback"" ) :",113
"def resolve(self): <TAB> """"""Determine the final input value."""""" <TAB> if self.source: <TAB>  <TAB> if isinstance(self.source, tuple): <TAB>  <TAB>  <TAB> result = self.source[1][0][self.source[0]] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result = self.source[1][self.source[0]] <MASK> return result <TAB> return self.default",if result :,95
"def after_step(self, step, feed_dict): <TAB> if step % (self.config.step_count or 1) != 0: <TAB>  <TAB> return <TAB> # compress <TAB> for i in range(self.config.night_steps or 1): <TAB>  <TAB> self.trainer.step(feed_dict) <TAB> if self.config.reinitialize_every: <MASK> print(""Reinitializing active D"") <TAB>  <TAB>  <TAB> self.gan.session.run(self.re_init_d)",if step % ( self . config . reinitialize_every ) == 0 and step > 0 :,138
"def set_functions_list(self, functionsList, prefix="""", sufix=""""): <TAB> self.funtionsList = functionsList <TAB> self.funtionsListItems = [] <TAB> self.maxHeight = 0 <TAB> tempHeight = 0 <TAB> for element in functionsList: <TAB>  <TAB> tempElement = QGraphicsTextItem(self) <TAB>  <TAB> tempElement.setPlainText(prefix + element + sufix) <TAB>  <TAB> tempElement.setPos(0, tempHeight) <TAB>  <TAB> tempHeight += tempElement.document().size().height() <MASK> self.maxWidth = tempElement.document().size().width() <TAB>  <TAB> self.funtionsListItems.append(tempElement) <TAB> self.maxHeight = tempHeight",if self . maxWidth < tempElement . document ( ) . size ( ) . width ( ) :,176
"def __next__(self): <TAB> measure_mode = False <TAB> if self._prefetch_loop.thread is None: <MASK> measure_mode = True <TAB>  <TAB>  <TAB> batch, state = self._prefetch_loop.measure(self.dataset_timeout) <TAB>  <TAB> self._prefetch_loop.launch_thread() <TAB> if not measure_mode: <TAB>  <TAB> batch, state = self._comm.get() <TAB> self._previous_epoch_detail = self.epoch_detail <TAB> self._state = state <TAB> if batch is None: <TAB>  <TAB> raise StopIteration <TAB> else: <TAB>  <TAB> return batch",if self . _prefetch_loop . measure_required ( ) :,149
"def postprocess(self, testenv_config, value): <TAB> config = testenv_config.config <TAB> args = config.option.args <TAB> if args: <MASK> args = [] <TAB>  <TAB>  <TAB> for arg in config.option.args: <TAB>  <TAB>  <TAB>  <TAB> if arg and not os.path.isabs(arg): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> origpath = os.path.join(config.invocationcwd.strpath, arg) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if os.path.exists(origpath): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> arg = os.path.relpath( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> origpath, testenv_config.changedir.strpath <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> args.append(arg) <TAB>  <TAB> testenv_config._reader.addsubstitutions(args) <TAB> return value",if value :,196
"def _open(self, get_fileobject): <TAB> f = None  # make sure f exists even if get_fileobject() fails <TAB> try: <TAB>  <TAB> success = False <TAB>  <TAB> with get_fileobject(**self._open_kwargs) as f: <TAB>  <TAB>  <TAB> yield f <TAB>  <TAB>  <TAB> self.sync(f) <TAB>  <TAB> self.commit(f) <TAB>  <TAB> success = True <TAB> finally: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> self.rollback(f) <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> pass",if not success :,131
"def validate_expense_accounts(self): <TAB> company_currency = erpnext.get_company_currency(self.company) <TAB> for account in self.taxes: <MASK> frappe.throw( <TAB>  <TAB>  <TAB>  <TAB> _( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Row {}: Expense account currency should be same as company's default currency."" <TAB>  <TAB>  <TAB>  <TAB> ).format(account.idx) <TAB>  <TAB>  <TAB>  <TAB> + _( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Please select expense account with account currency as {}."" <TAB>  <TAB>  <TAB>  <TAB> ).format(frappe.bold(company_currency)), <TAB>  <TAB>  <TAB>  <TAB> title=_(""Invalid Account Currency""), <TAB>  <TAB>  <TAB> )",if get_account_currency ( account . expense_account ) != company_currency :,172
"def countbox(self): <TAB> self.box = [1000, 1000, -1000, -1000] <TAB> for i in self.body: <TAB>  <TAB> for x, y in i: <TAB>  <TAB>  <TAB> if x < self.box[0]: <TAB>  <TAB>  <TAB>  <TAB> self.box[0] = x <MASK> self.box[2] = x <TAB>  <TAB>  <TAB> if y < self.box[1]: <TAB>  <TAB>  <TAB>  <TAB> self.box[1] = y <TAB>  <TAB>  <TAB> if y > self.box[3]: <TAB>  <TAB>  <TAB>  <TAB> self.box[3] = y",if x > self . box [ 2 ] :,147
"def _threshold_fit( <TAB> self, values, threshold, take_high, host_thresholds=None, col_names=None): <TAB> if host_thresholds is None: <TAB>  <TAB> return super()._threshold_fit(values, threshold, take_high) <TAB> result = [] <TAB> for idx, v in enumerate(values): <TAB>  <TAB> party = col_names[idx][0] <TAB>  <TAB> if party == ""guest"": <TAB>  <TAB>  <TAB> thres = threshold <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> thres = host_thresholds[party] <MASK> if v >= thres: <TAB>  <TAB>  <TAB>  <TAB> result.append(idx) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if v <= thres: <TAB>  <TAB>  <TAB>  <TAB> result.append(idx) <TAB> return result",if take_high :,179
"def Proc2(IntParIO: int) -> int: <TAB> IntLoc = IntParIO + 10 <TAB> EnumLoc = -1  ## c++ scope style <TAB> while True: <TAB>  <TAB> if Char1Glob == ""A"": <TAB>  <TAB>  <TAB> IntLoc = IntLoc - 1 <TAB>  <TAB>  <TAB> IntParIO = IntLoc - IntGlob <TAB>  <TAB>  <TAB> EnumLoc = Ident1 <MASK> break <TAB> return IntParIO",if EnumLoc == Ident1 :,108
"def code_changed(): <TAB> global _mtimes, _win <TAB> file_list = get_files_list(STATIC_DIRS, FILE_SUFFIX) <TAB> for filename in chain(gen_filenames(), file_list): <TAB>  <TAB> stat = os.stat(filename) <TAB>  <TAB> mtime = stat.st_mtime <TAB>  <TAB> if _win: <TAB>  <TAB>  <TAB> mtime -= stat.st_ctime <TAB>  <TAB> if filename not in _mtimes: <TAB>  <TAB>  <TAB> _mtimes[filename] = mtime <TAB>  <TAB>  <TAB> continue <MASK> _mtimes = {} <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> del _error_files[_error_files.index(filename)] <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> return I18N_MODIFIED if filename.endswith("".mo"") else FILE_MODIFIED <TAB> return False",if mtime != _mtimes [ filename ] :,196
"def assertDeepEquals(self, actual, expected): <TAB> try: <MASK> # assert items equal, ignore order <TAB>  <TAB>  <TAB> self.assertListEquals(actual, expected) <TAB>  <TAB> elif type(expected) is type({}): <TAB>  <TAB>  <TAB> self.assertDictEquals(actual, expected) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertEquals(actual, expected) <TAB> except AssertionError as e: <TAB>  <TAB> raise <TAB>  <TAB> raise AssertionError(""Expected: %s\n Got: %s"" % (expected, actual))",if type ( expected ) is type ( [ ] ) or type ( expected ) is type ( tuple ( ) ) :,138
"def execute(): <TAB> frappe.reload_doc(""utilities"", ""doctype"", ""video"") <TAB> for video in frappe.get_all(""Video"", fields=[""name"", ""url"", ""youtube_video_id""]): <MASK> frappe.db.set_value( <TAB>  <TAB>  <TAB>  <TAB> ""Video"", video.name, ""youtube_video_id"", get_id_from_url(video.url) <TAB>  <TAB>  <TAB> )",if video . url and not video . youtube_video_id :,118
"def generate(self, sigmaparser): <TAB> """"""Method is called for each sigma rule and receives the parsed rule (SigmaParser)"""""" <TAB> for parsed in sigmaparser.condparsed: <TAB>  <TAB> query = self.generateQuery(parsed) <MASK> self.queries += self.panel_pre <TAB>  <TAB>  <TAB> self.queries += sigmaparser.parsedyaml.get(""title"") or """" <TAB>  <TAB>  <TAB> self.queries += self.panel_inf <TAB>  <TAB>  <TAB> query = query.replace(""<"", ""&lt;"") <TAB>  <TAB>  <TAB> query = query.replace("">"", ""&gt;"") <TAB>  <TAB>  <TAB> self.queries += query <TAB>  <TAB>  <TAB> self.queries += self.panel_suf",if query is not None :,155
"def clean(self): <TAB> super().clean() <TAB> # Validate primary IP addresses <TAB> interfaces = self.interfaces.all() <TAB> for field in [""primary_ip4"", ""primary_ip6""]: <TAB>  <TAB> ip = getattr(self, field) <MASK> if ip.assigned_object in interfaces: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> elif ( <TAB>  <TAB>  <TAB>  <TAB> ip.nat_inside is not None <TAB>  <TAB>  <TAB>  <TAB> and ip.nat_inside.assigned_object in interfaces <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise ValidationError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> field: f""The specified IP address ({ip}) is not assigned to this VM."", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB>  <TAB> )",if ip is not None :,192
"def _add_payload(self, ctrl, bytes): <TAB> """"""Take the payload and return true if more to come"""""" <TAB> for index, byte in enumerate(bytes): <MASK> if byte != _XGMII_TERMINATE: <TAB>  <TAB>  <TAB>  <TAB> self.log.error(""Got control character in XGMII payload"") <TAB>  <TAB>  <TAB>  <TAB> self.log.info(""data = :"" + "" "".join([""%02X"" % ord(b) for b in bytes])) <TAB>  <TAB>  <TAB>  <TAB> self.log.info(""ctrl = :"" + "" "".join([""%s"" % str(c) for c in ctrl])) <TAB>  <TAB>  <TAB>  <TAB> self._pkt = """" <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> self._pkt += byte <TAB> return True",if ctrl [ index ] :,174
"def _get_http_headers(req_env): <TAB> retval = {} <TAB> for k, v in req_env.items(): <MASK> key = k[5:].lower() <TAB>  <TAB>  <TAB> val = [v] <TAB>  <TAB>  <TAB> retval[key] = val <TAB>  <TAB>  <TAB> logger.debug(""Add http header %r = %r"", key, val) <TAB> return retval","if k . startswith ( ""HTTP_"" ) :",97
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_queue_name(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 18: <TAB>  <TAB>  <TAB> self.set_task_name(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 24: <TAB>  <TAB>  <TAB> self.set_eta_usec(d.getVarInt64()) <TAB>  <TAB>  <TAB> continue <MASK> self.set_lease_seconds(d.getDouble()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 33 :,187
"def getnextfile(f): <TAB> while 1: <TAB>  <TAB> line = f.readline() <MASK> return None <TAB>  <TAB> if startprog.match(line) >= 0: <TAB>  <TAB>  <TAB> file = startprog.group(1) <TAB>  <TAB>  <TAB> # Skip until first revision <TAB>  <TAB>  <TAB> while 1: <TAB>  <TAB>  <TAB>  <TAB> line = f.readline() <TAB>  <TAB>  <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB>  <TAB>  <TAB> if line[:10] == ""="" * 10: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB>  <TAB>  <TAB> if line[:10] == ""-"" * 10: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> ## <TAB>  <TAB>  <TAB>   print ""Skipped"", line, <TAB>  <TAB>  <TAB> return file",if not line :,181
"def cleanup(self, achalls):  # pylint: disable=missing-function-docstring <TAB> if self.conf(""cleanup-hook""): <TAB>  <TAB> for achall in achalls: <TAB>  <TAB>  <TAB> env = self.env.pop(achall) <MASK> os.environ.pop(""CERTBOT_TOKEN"", None) <TAB>  <TAB>  <TAB> os.environ.update(env) <TAB>  <TAB>  <TAB> self._execute_hook(""cleanup-hook"") <TAB> self.reverter.recovery_routine()","if ""CERTBOT_TOKEN"" not in env :",127
"def local_sampling_dot_csr(node): <TAB> if not theano.config.blas.ldflags: <TAB>  <TAB> # The C implementation of SamplingDotCsr relies on BLAS routines <TAB>  <TAB> return <TAB> if node.op == sparse.sampling_dot: <TAB>  <TAB> x, y, p = node.inputs <MASK> p_data, p_ind, p_ptr, p_shape = sparse.csm_properties(p) <TAB>  <TAB>  <TAB> z_data, z_ind, z_ptr = sampling_dot_csr( <TAB>  <TAB>  <TAB>  <TAB> x, y, p_data, p_ind, p_ptr, p_shape[1] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return [sparse.CSR(z_data, z_ind, z_ptr, p_shape)] <TAB> return False","if p . type . format == ""csr"" :",194
"def _same_process_iter(): <TAB> for batch in self._batch_sampler: <MASK> rets = [ <TAB>  <TAB>  <TAB>  <TAB> self._batchify_fn([self._dataset[idx] for idx in shard]) <TAB>  <TAB>  <TAB>  <TAB> for shard in batch <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB> if self._pin_memory: <TAB>  <TAB>  <TAB>  <TAB> rets = [_as_in_context(ret, context.cpu_pinned()) for ret in rets] <TAB>  <TAB>  <TAB> yield rets <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret = self._batchify_fn([self._dataset[idx] for idx in batch]) <TAB>  <TAB>  <TAB> if self._pin_memory: <TAB>  <TAB>  <TAB>  <TAB> ret = _as_in_context(ret, context.cpu_pinned()) <TAB>  <TAB>  <TAB> yield ret","if isinstance ( batch [ 0 ] , ( list , tuple ) ) :",189
"def _word_piece_tokenize(self, word: str) -> List[str]: <TAB> if word in self._token_dict: <TAB>  <TAB> return [word] <TAB> tokens = [] <TAB> start, stop = 0, 0 <TAB> while start < len(word): <TAB>  <TAB> stop = len(word) <TAB>  <TAB> while stop > start: <TAB>  <TAB>  <TAB> sub = word[start:stop] <TAB>  <TAB>  <TAB> if start > 0: <TAB>  <TAB>  <TAB>  <TAB> sub = ""##"" + sub <TAB>  <TAB>  <TAB> if sub in self._token_dict: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> stop -= 1 <MASK> stop += 1 <TAB>  <TAB> tokens.append(sub) <TAB>  <TAB> start = stop <TAB> return tokens",if start == stop :,170
"def get_body(self, obj): <TAB> if obj.notification_type in (""webhook"", ""pagerduty""): <TAB>  <TAB> if isinstance(obj.body, dict): <TAB>  <TAB>  <TAB> if ""body"" in obj.body: <TAB>  <TAB>  <TAB>  <TAB> return obj.body[""body""] <TAB>  <TAB> elif isinstance(obj.body, str): <TAB>  <TAB>  <TAB> # attempt to load json string <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> potential_body = json.loads(obj.body) <MASK> return potential_body <TAB>  <TAB>  <TAB> except json.JSONDecodeError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB> return obj.body","if isinstance ( potential_body , dict ) :",153
"def read(self, size=1): <TAB> while len(self.fifo) < size: <TAB>  <TAB> timeout_count = 0 <TAB>  <TAB> data = self.tn.read_eager() <MASK> self.fifo.extend(data) <TAB>  <TAB>  <TAB> timeout_count = 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> time.sleep(0.25) <TAB>  <TAB>  <TAB> if self.read_timeout is not None and timeout_count > 4 * self.read_timeout: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> timeout_count += 1 <TAB> data = b"""" <TAB> while len(data) < size and len(self.fifo) > 0: <TAB>  <TAB> data += bytes([self.fifo.popleft()]) <TAB> return data",if len ( data ) :,172
"def walk_eopatch(eopatch, patch_location, features=...): <TAB> """"""Recursively reads a patch_location and returns yields tuples of (feature_type, feature_name, file_path)"""""" <TAB> returned_meta_features = set() <TAB> for ftype, fname in FeatureParser(features)(eopatch): <TAB>  <TAB> name_basis = fs.path.combine(patch_location, ftype.value) <MASK> if eopatch[ftype] and ftype not in returned_meta_features: <TAB>  <TAB>  <TAB>  <TAB> yield ftype, ..., name_basis <TAB>  <TAB>  <TAB>  <TAB> returned_meta_features.add(ftype) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield ftype, fname, fs.path.combine(name_basis, fname)",if ftype . is_meta ( ) :,179
"def _decode(s, multiplier=None, neg=False): <TAB> v = None <TAB> try: <TAB>  <TAB> v = int(s, 16) <TAB>  <TAB> if neg: <TAB>  <TAB>  <TAB> bits = 4 * len(s) <MASK> v -= 1 << bits <TAB>  <TAB> if multiplier is not None: <TAB>  <TAB>  <TAB> v *= multiplier <TAB> except ValueError as e: <TAB>  <TAB> if s != ""----"": <TAB>  <TAB>  <TAB> log.debug(""decode failed for '%s': %s"" % (s, e)) <TAB> return v",if v & ( 1 << ( bits - 1 ) ) != 0 :,140
"def eval_json_path(cls, values): <TAB> result = [""$""] <TAB> append = result.append <TAB> empty_slice = slice(None, None, None) <TAB> for value in values: <TAB>  <TAB> if isinstance(value, int): <TAB>  <TAB>  <TAB> append(""[%d]"" % value) <TAB>  <TAB> elif isinstance(value, basestring): <TAB>  <TAB>  <TAB> append( <TAB>  <TAB>  <TAB>  <TAB> ""."" + value if is_ident(value) else '.""%s""' % value.replace('""', '\\""') <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> elif value is Ellipsis: <TAB>  <TAB>  <TAB> append("".*"") <MASK> append(""[*]"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert False, value <TAB> return """".join(result)",elif value == empty_slice :,170
"def load_deprel_weights(weights_file): <TAB> if weights_file is None: <TAB>  <TAB> return None <TAB> deprel_weights = {} <TAB> with open(weights_file) as f: <TAB>  <TAB> for line in f: <TAB>  <TAB>  <TAB> # Ignore comments and empty lines <MASK> continue <TAB>  <TAB>  <TAB> columns = line.rstrip(""\r\n"").split() <TAB>  <TAB>  <TAB> if len(columns) != 2: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Expected two columns in the UD Relations weights file on line"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> "" '{}'"".format(line) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> deprel_weights[columns[0]] = float(columns[1]) <TAB> return deprel_weights","if line . startswith ( ""#"" ) or not line . strip ( ) :",191
"def _overwriteProjectCallback(self, result, error=False, **kwargs): <TAB> if error: <TAB>  <TAB> # A 404 could arrive if someone else as deleted the project <MASK> return <TAB>  <TAB> elif ""message"" in result: <TAB>  <TAB>  <TAB> QtWidgets.QMessageBox.critical( <TAB>  <TAB>  <TAB>  <TAB> self, <TAB>  <TAB>  <TAB>  <TAB> ""New Project"", <TAB>  <TAB>  <TAB>  <TAB> ""Error while overwrite project: {}"".format(result[""message""]), <TAB>  <TAB>  <TAB> ) <TAB> Controller.instance().refreshProjectList() <TAB> self.done(True)","if ""status"" not in result or result [ ""status"" ] != 404 :",141
"def installDefaults(self): <TAB> koDirSvc = components.classes[""@activestate.com/koDirs;1""].getService() <TAB> dstFiles = [ <TAB>  <TAB> ""colors.less"", <TAB>  <TAB> ""userChrome.less"", <TAB>  <TAB> ""interfaceChrome.less"", <TAB>  <TAB> ""classic.less"", <TAB> ] <TAB> for dstFile in dstFiles: <TAB>  <TAB> dstFile = os.path.join(koDirSvc.userDataDir, dstFile) <MASK> fhandle = open(dstFile, ""a"") <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> os.utime(dstFile, None) <TAB>  <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB>  <TAB> fhandle.close()",if not os . path . isfile ( dstFile ) :,172
"def _draw_goals_view_points(self, episode): <TAB> if self._config.DRAW_VIEW_POINTS: <TAB>  <TAB> for goal in episode.goals: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if goal.view_points is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for view_point in goal.view_points: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._draw_point( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> view_point.agent_state.position, <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> maps.MAP_VIEW_POINT_INDICATOR, <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass",if self . _is_on_same_floor ( goal . position [ 1 ] ) :,182
"def test_success(self): <TAB> with tempfile.NamedTemporaryFile(prefix=""mitotest"") as ifp: <TAB>  <TAB> with tempfile.NamedTemporaryFile(prefix=""mitotest"") as ofp: <TAB>  <TAB>  <TAB> ifp.write(b""x"" * (1048576 * 4)) <MASK> ifp.seek(0) <TAB>  <TAB>  <TAB> self.conn.fetch_file(ifp.name, ofp.name) <TAB>  <TAB>  <TAB> # transfer_file() uses os.rename rather than direct data <TAB>  <TAB>  <TAB> # overwrite, so we must reopen. <TAB>  <TAB>  <TAB> with open(ofp.name, ""rb"") as fp: <TAB>  <TAB>  <TAB>  <TAB> self.assertEquals(ifp.read(), fp.read())",ifp . flush ( ),169
"def _boost_rank(self, boost, term, *matches): <TAB> boost = 0.0 <TAB> for match in matches: <TAB>  <TAB> match = match.lower() <TAB>  <TAB> if term in match: <MASK> boost += boost * boost * (float(len(term)) / len(match)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> boost += boost * (float(len(term)) / len(match)) <TAB> return int(boost)",if match . startswith ( term ) :,115
"def __str__(self, prefix="""", printElemNumber=0): <TAB> res = """" <TAB> cnt = 0 <TAB> for e in self.delete_status_: <TAB>  <TAB> elm = """" <MASK> elm = ""(%d)"" % cnt <TAB>  <TAB> res += prefix + (""delete_status%s: %s\n"" % (elm, self.DebugFormatInt32(e))) <TAB>  <TAB> cnt += 1 <TAB> return res",if printElemNumber :,105
"def execRcLines(self): <TAB> if not self.rcLines: <TAB>  <TAB> return <TAB> # local copy because of recursion <TAB> rcLines = self.rcLines <TAB> rcLines.reverse() <TAB> # execute every line only once <TAB> self.rcLines = [] <TAB> while rcLines: <TAB>  <TAB> line = rcLines.pop().strip() <TAB>  <TAB> if line and line[0] != ""#"": <MASK> # if onecmd returns True, the command wants to exit <TAB>  <TAB>  <TAB>  <TAB> # from the interaction, save leftover rc lines <TAB>  <TAB>  <TAB>  <TAB> # to execute before next interaction <TAB>  <TAB>  <TAB>  <TAB> self.rcLines += reversed(rcLines) <TAB>  <TAB>  <TAB>  <TAB> return True",if self . onecmd ( line ) :,168
"def check_is_block(self, raise_exception=True): <TAB> if hasattr(self.request, ""data""): <TAB>  <TAB> username = self.request.data.get(""username"") <TAB> else: <TAB>  <TAB> username = self.request.POST.get(""username"") <TAB> ip = self.get_request_ip() <TAB> if is_block_login(username, ip): <TAB>  <TAB> logger.warn(""Ip was blocked"" + "": "" + username + "":"" + ip) <TAB>  <TAB> exception = errors.BlockLoginError(username=username, ip=ip) <MASK> raise errors.BlockLoginError(username=username, ip=ip) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return exception",if raise_exception :,165
"def handle_match(m): <TAB> name = m.group(1) <TAB> if name in HTMLBuilder._entities: <TAB>  <TAB> return unichr(HTMLBuilder._entities[name]) <TAB> try: <MASK> return unichr(int(name[2:], 16)) <TAB>  <TAB> elif name.startswith(""#""): <TAB>  <TAB>  <TAB> return unichr(int(name[1:])) <TAB> except ValueError: <TAB>  <TAB> pass <TAB> return u""""","if name [ : 2 ] in ( ""#x"" , ""#X"" ) :",111
"def __call__(self, txt, *args): <TAB> if self.verbosity > 2: <TAB>  <TAB> if self.pending_sub: <MASK> self.pr() <TAB>  <TAB>  <TAB> self.pr(self.pending_sub) <TAB>  <TAB>  <TAB> self.pending_sub = None <TAB>  <TAB> elif self.pending_br: <TAB>  <TAB>  <TAB> self.pr() <TAB>  <TAB> self.pr(txt % args) <TAB>  <TAB> self.last_pr = True <TAB>  <TAB> self.pending_br = False",if self . last_pr :,125
"def href__get(self): <TAB> s = self.url <TAB> if self.vars: <TAB>  <TAB> s += ""?"" <TAB>  <TAB> vars = [] <TAB>  <TAB> for name, val in self.vars: <TAB>  <TAB>  <TAB> if isinstance(val, (list, tuple)): <TAB>  <TAB>  <TAB>  <TAB> val = [v for v in val if v is not None] <MASK> continue <TAB>  <TAB>  <TAB> vars.append((name, val)) <TAB>  <TAB> s += urlencode(vars, True) <TAB> return s",elif val is None :,121
"def get_category(**func_kwargs): <TAB> if ""category"" in func_kwargs: <TAB>  <TAB> category = func_kwargs.pop(""category"") <MASK> if 1 <= category <= 14: <TAB>  <TAB>  <TAB>  <TAB> return category <TAB>  <TAB>  <TAB> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> ""There is only 14 build-in categories available in Excel. Please use a string value to specify a custom category."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if isinstance(category, str): <TAB>  <TAB>  <TAB> return category[:255] <TAB>  <TAB> raise Exception( <TAB>  <TAB>  <TAB> ""Category {0} should either be a predefined Excel category (int value) or a custom one (str value)."".format( <TAB>  <TAB>  <TAB>  <TAB> category <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB> return ""xlwings""  # Default category","if isinstance ( category , int ) :",186
"def _decode_letter_case_overrides(field_names, overrides): <TAB> """"""Override letter case of field names for encode/decode"""""" <TAB> names = {} <TAB> for field_name in field_names: <TAB>  <TAB> field_override = overrides.get(field_name) <TAB>  <TAB> if field_override is not None: <TAB>  <TAB>  <TAB> letter_case = field_override.letter_case <MASK> names[letter_case(field_name)] = field_name <TAB> return names",if letter_case is not None :,123
"def _poll_read(self): <TAB> for event_file in self.open_event_files: <TAB>  <TAB> key_data = event_file.read(EVENT_SIZE) <TAB>  <TAB> if key_data is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> date, key_action, key_code = self.parse_event_record(key_data) <TAB>  <TAB> # Skip if date, key_action and key_code is none as that's a spacer record <MASK> continue <TAB>  <TAB> # Now if key is pressed then we record <TAB>  <TAB> self._parent.key_action(date, key_code, key_action)",if date is None :,150
"def _wrapped(*args, **kwargs): <TAB> callback = None <TAB> if ""callback"" in kwargs: <TAB>  <TAB> callback = kwargs[""callback""] <TAB> elif callback_pos and callback_pos < len(args): <TAB>  <TAB> callback = args[callback_pos] <TAB> try: <TAB>  <TAB> return func(*args, **kwargs) <TAB> except:  # noqa: E722 <TAB>  <TAB> actor = args[0] <TAB>  <TAB> logger.exception(""Unhandled exception in promise call"") <MASK> actor.tell_promise(callback, *sys.exc_info(), _accept=False) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise",if callback :,146
"def _renumber_affected_areas(self, affected_areas): <TAB> for area_id in affected_areas: <TAB>  <TAB> for coords in self.areas[area_id]: <MASK> self._label_area(coords) <TAB>  <TAB>  <TAB>  <TAB> assert self.area_numbers[coords] != area_id <TAB>  <TAB> del self.areas[area_id]",if self . area_numbers [ coords ] == area_id :,102
"def indent(elem, level=0): <TAB> i = ""\n"" + level * ""  "" <TAB> # pylint: disable=len-as-condition <TAB> if len(elem): <TAB>  <TAB> if not elem.text or not elem.text.strip(): <TAB>  <TAB>  <TAB> elem.text = i + ""  "" <TAB>  <TAB> if not elem.tail or not elem.tail.strip(): <TAB>  <TAB>  <TAB> elem.tail = i <TAB>  <TAB> for subEl in elem: <TAB>  <TAB>  <TAB> indent(subEl, level + 1) <TAB>  <TAB> if not elem.tail or not elem.tail.strip(): <TAB>  <TAB>  <TAB> elem.tail = i <TAB> else: <MASK> elem.tail = i",if level and ( not elem . tail or not elem . tail . strip ( ) ) :,175
"def authenticate(self, username=None, password=None): <TAB> users = find_users(username) <TAB> if users: <TAB>  <TAB> for user in users: <TAB>  <TAB>  <TAB> try: <MASK> return user <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB> return None",if user . password and user . check_password ( password ) :,86
"def _copy_with_secondary(f, dirname): <TAB> if len(f[""secondaryFiles""]) > 1: <TAB>  <TAB> dirname = utils.safe_makedir( <TAB>  <TAB>  <TAB> os.path.join(dirname, os.path.basename(os.path.dirname(f[""location""]))) <TAB>  <TAB> ) <TAB> if not objectstore.is_remote(f[""location""]): <TAB>  <TAB> finalf = os.path.join(dirname, os.path.basename(f[""location""])) <MASK> shutil.copy(f[""location""], dirname) <TAB> [_copy_with_secondary(sf, dirname) for sf in f[""secondaryFiles""]]","if not utils . file_uptodate ( finalf , f [ ""location"" ] ) :",166
"def _update_losses_dict(self, loss_objs, *args, **kwargs): <TAB> """"""Helper function to run loss objects on args and add to model losses."""""" <TAB> for loss_obj in ddsp.core.make_iterable(loss_objs): <MASK> losses_dict = loss_obj.get_losses_dict(*args, **kwargs) <TAB>  <TAB>  <TAB> self._losses_dict.update(losses_dict)","if hasattr ( loss_obj , ""get_losses_dict"" ) :",114
"def interaction(self): <TAB> print(""%s [https://github.com/bjarneo/Pytify]"" % self.get_package_name()) <TAB> while 1: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> search_input = custom_prompt(self.pytify.get_current_playing()) <TAB>  <TAB> except KeyboardInterrupt: <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> search = self.pytify.query(search_input) <TAB>  <TAB> if search: <TAB>  <TAB>  <TAB> self.list_songs(list=self.pytify.list())",if self . command . run ( search_input ) :,143
"def findright(self, contents, index): <TAB> ""Find the right bracket starting at the given index, or 0."" <TAB> depth = 1 <TAB> while index < len(contents): <TAB>  <TAB> if self.checkleft(contents, index): <TAB>  <TAB>  <TAB> depth += 1 <TAB>  <TAB> if self.checkright(contents, index): <TAB>  <TAB>  <TAB> depth -= 1 <MASK> return index <TAB>  <TAB> index += 1 <TAB> return None",if depth == 0 :,105
"def get_node(self, jid=None, node=None, ifrom=None): <TAB> with self.lock: <TAB>  <TAB> if jid is None: <TAB>  <TAB>  <TAB> jid = self.xmpp.boundjid.full <TAB>  <TAB> if node is None: <TAB>  <TAB>  <TAB> node = """" <MASK> ifrom = """" <TAB>  <TAB> if isinstance(ifrom, JID): <TAB>  <TAB>  <TAB> ifrom = ifrom.full <TAB>  <TAB> if (jid, node, ifrom) not in self.nodes: <TAB>  <TAB>  <TAB> self.add_node(jid, node, ifrom) <TAB>  <TAB> return self.nodes[(jid, node, ifrom)]",if ifrom is None :,157
"def to_text(self, value): <TAB> try: <MASK> display_text = ""{}: {}"".format(value.hid, value.name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> display_text = ""Element %d:%s"" % ( <TAB>  <TAB>  <TAB>  <TAB> value.identifier_index, <TAB>  <TAB>  <TAB>  <TAB> value.identifier_name, <TAB>  <TAB>  <TAB> ) <TAB> except AttributeError: <TAB>  <TAB> display_text = ""No dataset collection."" <TAB> return display_text","if isinstance ( value , galaxy . model . HistoryDatasetCollectionAssociation ) :",125
"def __setitem__(self, index, value): <TAB> if isinstance(index, (int, slice)): <TAB>  <TAB> return list.__setitem__(self, index, value) <TAB> elif isinstance(index, (list, tuple)): <MASK> raise IndexError(""The tree position () may not be "" ""assigned to."") <TAB>  <TAB> elif len(index) == 1: <TAB>  <TAB>  <TAB> self[index[0]] = value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self[index[0]][index[1:]] = value <TAB> else: <TAB>  <TAB> raise TypeError( <TAB>  <TAB>  <TAB> ""%s indices must be integers, not %s"" <TAB>  <TAB>  <TAB> % (type(self).__name__, type(index).__name__) <TAB>  <TAB> )",if len ( index ) == 0 :,170
"def _event_generator(handle): <TAB> while True: <TAB>  <TAB> event = _mpv_wait_event(handle, -1).contents <MASK> raise StopIteration() <TAB>  <TAB> yield event",if event . event_id . value == MpvEventID . NONE :,64
"def wdigest(action): <TAB> key_path = r""SYSTEM\\CurrentControlSet\\Control\\SecurityProviders\\WDigest\\"" <TAB> key_name = ""UseLogonCredential"" <TAB> if action == ""check"": <TAB>  <TAB> return queryValue(key_path, key_name) <TAB> elif action == ""enable"": <TAB>  <TAB> ok, message = modifyKey(key_path, key_name, 1) <MASK> message = ""UseLogonCredential key created, logoff the user session to dump plaintext credentials"" <TAB>  <TAB> return ok, message <TAB> elif action == ""disable"": <TAB>  <TAB> ok, message = modifyKey(key_path, key_name, 0) <TAB>  <TAB> if ok: <TAB>  <TAB>  <TAB> message = ""UseLogonCredential key deleted"" <TAB>  <TAB> return ok, message",if ok :,185
"def _parse(self, stream, context): <TAB> if ""<obj>"" in context: <TAB>  <TAB> obj = context[""<obj>""] <TAB>  <TAB> del context[""<obj>""] <TAB> else: <TAB>  <TAB> obj = Container() <TAB>  <TAB> if self.nested: <TAB>  <TAB>  <TAB> context = Container(_=context) <TAB> for sc in self.subcons: <MASK> context[""<obj>""] = obj <TAB>  <TAB>  <TAB> sc._parse(stream, context) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> subobj = sc._parse(stream, context) <TAB>  <TAB>  <TAB> if sc.name is not None: <TAB>  <TAB>  <TAB>  <TAB> obj[sc.name] = subobj <TAB>  <TAB>  <TAB>  <TAB> context[sc.name] = subobj <TAB> return obj",if sc . conflags & self . FLAG_EMBED :,182
"def compatible_with(new, existing, view): <TAB> """"""Check whether a new type can be added to a container."""""" <TAB> for data in existing: <TAB>  <TAB> k = data.get_type_key() <TAB>  <TAB> if k not in compatible_with_cache: <TAB>  <TAB>  <TAB> # This caching lets us skip duplicate matching work. Very <TAB>  <TAB>  <TAB> # unfortunately, it is also needed for correctness because <TAB>  <TAB>  <TAB> # cfg_utils.deep_variable_product() ignores bindings to values with <TAB>  <TAB>  <TAB> # duplicate type keys when generating views. <TAB>  <TAB>  <TAB> compatible_with_cache[k] = self.vm.matcher.match_var_against_type( <TAB>  <TAB>  <TAB>  <TAB> new, data.cls, {}, node, view <TAB>  <TAB>  <TAB> ) <MASK> return True <TAB> return False",if compatible_with_cache [ k ] is not None :,195
"def exc_to_unicode(ev, encoding=""utf-8""): <TAB> if is_base_exception(ev): <MASK> # 2.5- <TAB>  <TAB>  <TAB> if not hasattr(ev, ""message""): <TAB>  <TAB>  <TAB>  <TAB> # 2.4 <TAB>  <TAB>  <TAB>  <TAB> msg = len(ev.args) and ev.args[0] or """" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> msg = ev.message <TAB>  <TAB>  <TAB> msg = force_unicode(msg, encoding=encoding) <TAB>  <TAB>  <TAB> clsname = force_unicode(ev.__class__.__name__, encoding=encoding) <TAB>  <TAB>  <TAB> ev = u""%s: %s"" % (clsname, msg) <TAB> elif not isinstance(ev, unicode): <TAB>  <TAB> ev = repr(ev) <TAB> return force_unicode(ev, encoding=encoding)","if not hasattr ( ev , ""__unicode__"" ) :",197
"def track_to_metadata(node, track): <TAB> m = track.metadata <TAB> recording_to_metadata(node[""recording""], m, track) <TAB> m.add_unique(""musicbrainz_trackid"", node[""id""]) <TAB> # overwrite with data we have on the track <TAB> for key, value in node.items(): <MASK> continue <TAB>  <TAB> if key in _TRACK_TO_METADATA: <TAB>  <TAB>  <TAB> m[_TRACK_TO_METADATA[key]] = value <TAB>  <TAB> elif key == ""length"" and value: <TAB>  <TAB>  <TAB> m.length = value <TAB>  <TAB> elif key == ""artist-credit"": <TAB>  <TAB>  <TAB> artist_credit_to_metadata(value, m) <TAB> if m.length: <TAB>  <TAB> m[""~length""] = format_time(m.length) <TAB> track.orig_metadata.copy(m)",if not value :,198
"def on_headers(self, response, exc=None): <TAB> """"""Websocket upgrade as ``on_headers`` event."""""" <TAB> if response.status_code == 101: <TAB>  <TAB> connection = response.connection <TAB>  <TAB> request = response.request <TAB>  <TAB> handler = request.websocket_handler <MASK> handler = WS() <TAB>  <TAB> parser = request.client.frame_parser(kind=1) <TAB>  <TAB> consumer = partial(WebSocketClient, response, handler, parser) <TAB>  <TAB> connection.upgrade(consumer) <TAB>  <TAB> body = response.recv_body() <TAB>  <TAB> response.finished() <TAB>  <TAB> websocket = connection.current_consumer() <TAB>  <TAB> websocket.data_received(body) <TAB>  <TAB> response.request_again = lambda r: websocket",if not handler :,184
"def __new__(cls, key, secret=None, api_version=""v2"", **kwargs): <TAB> if cls is DigitalOceanBaseDriver: <MASK> raise DigitalOcean_v1_Error() <TAB>  <TAB> elif api_version == ""v2"": <TAB>  <TAB>  <TAB> cls = DigitalOcean_v2_BaseDriver <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise NotImplementedError(""Unsupported API version: %s"" % (api_version)) <TAB> return super(DigitalOceanBaseDriver, cls).__new__(cls, **kwargs)","if api_version == ""v1"" or secret is not None :",142
"def scan_resource_conf(self, conf): <TAB> if ""identity"" in conf: <TAB>  <TAB> if ""type"" in conf[""identity""]: <TAB>  <TAB>  <TAB> if conf[""identity""][""type""] == ""SystemAssigned"": <TAB>  <TAB>  <TAB>  <TAB> return CheckResult.PASSED <TAB>  <TAB>  <TAB> elif conf[""identity""][""type""] == ""UserAssigned"": <MASK> if conf[""identity""][""userAssignedIdentities""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return CheckResult.PASSED <TAB> return CheckResult.FAILED","if ""userAssignedIdentities"" in conf [ ""identity"" ] :",131
"def get_transaction(self, transaction_id): <TAB> transaction = backend.query.get_transaction(self.connection, transaction_id) <TAB> if transaction: <TAB>  <TAB> asset = backend.query.get_asset(self.connection, transaction_id) <TAB>  <TAB> metadata = backend.query.get_metadata(self.connection, [transaction_id]) <MASK> transaction[""asset""] = asset <TAB>  <TAB> if ""metadata"" not in transaction: <TAB>  <TAB>  <TAB> metadata = metadata[0] if metadata else None <TAB>  <TAB>  <TAB> if metadata: <TAB>  <TAB>  <TAB>  <TAB> metadata = metadata.get(""metadata"") <TAB>  <TAB>  <TAB> transaction.update({""metadata"": metadata}) <TAB>  <TAB> transaction = Transaction.from_dict(transaction) <TAB> return transaction",if asset :,170
"def _get_modem_proxy(self): <TAB> modemmanager_proxy = self.bus.get(STRING_MODEMMANAGER_DBUS) <TAB> modems = modemmanager_proxy.GetManagedObjects() <TAB> for objects in modems.items(): <TAB>  <TAB> modem_path = objects[0] <TAB>  <TAB> modem_proxy = self.bus.get(STRING_MODEMMANAGER_DBUS, modem_path) <TAB>  <TAB> eqid = modem_proxy.EquipmentIdentifier <MASK> return modem_proxy <TAB> else: <TAB>  <TAB> return {}",if self . modem is None or self . modem == eqid :,154
"def proc_month(d): <TAB> if expanded[3][0] != ""*"": <TAB>  <TAB> diff_month = nearest_diff_method(d.month, expanded[3], 12) <TAB>  <TAB> days = DAYS[month - 1] <TAB>  <TAB> if month == 2 and self.is_leap(year): <TAB>  <TAB>  <TAB> days += 1 <TAB>  <TAB> reset_day = days if is_prev else 1 <MASK> if is_prev: <TAB>  <TAB>  <TAB>  <TAB> d += relativedelta(months=diff_month) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> d += relativedelta( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> months=diff_month, day=reset_day, hour=0, minute=0, second=0 <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return True, d <TAB> return False, d",if diff_month is not None and diff_month != 0 :,200
"def send(*args, **kwargs): <TAB> """"""Sends the message given but prints errors instead of raising them"""""" <TAB> try: <TAB>  <TAB> OSCClient.send(*args, **kwargs) <TAB> except OSCClientError as e: <MASK> print( <TAB>  <TAB>  <TAB>  <TAB> ""Error sending message to SuperCollider server instance: make sure FoxDot quark is running and try again."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> OSCClientWrapper.error_printed = True",if not OSCClientWrapper . error_printed :,120
"def write_dict(filename, contents): <TAB> if ""__corrupted__"" in contents: <TAB>  <TAB> return <TAB> fp = None <TAB> try: <TAB>  <TAB> fp = LockedFile(filename, ""w"") <TAB>  <TAB> fp.write(""# -*- coding: utf-8 -*-\n{\n"") <TAB>  <TAB> for key in sorted(contents, key=lambda x: to_unicode(x, ""utf-8"").lower()): <TAB>  <TAB>  <TAB> fp.write(""%s: %s,\n"" % (repr(Utf8(key)), repr(Utf8(contents[key])))) <TAB>  <TAB> fp.write(""}\n"") <TAB> except (IOError, OSError): <TAB>  <TAB> if is_writable(): <TAB>  <TAB>  <TAB> logging.warning(""Unable to write to file %s"" % filename) <TAB>  <TAB> return <TAB> finally: <MASK> fp.close()",if fp :,194
"def _cleanup_tmp_user_data_dir(self) -> None: <TAB> for retry in range(100): <TAB>  <TAB> if self.temporaryUserDataDir and os.path.exists(self.temporaryUserDataDir): <TAB>  <TAB>  <TAB> shutil.rmtree(self.temporaryUserDataDir, ignore_errors=True) <MASK> time.sleep(0.01) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> raise IOError(""Unable to remove Temporary User Data"")",if os . path . exists ( self . temporaryUserDataDir ) :,130
"def add_flags_register_operand(agi, ii): <TAB> """"""If the instruction has flags, then add a flag register operand."""""" <TAB> if field_check(ii, ""flags_info"") and ii.flags_info and ii.flags_info.x86_flags(): <TAB>  <TAB> rw = ii.flags_info.rw_action() <TAB>  <TAB> (memidx_dummy, regidx) = find_max_memidx_and_regidx(ii.operands) <TAB>  <TAB> s = ""REG%d=rFLAGS():%s:SUPP"" % (regidx, rw) <TAB>  <TAB> if vflag(): <TAB>  <TAB>  <TAB> msgb(""RFLAGS-APPEND"", ""%s <-- %s"" % (ii.iclass, s)) <TAB>  <TAB> op = mk_opnd(agi, s) <MASK> ii.operands.append(op)",if op :,200
"def _mock_deactivate(authzr): <TAB> if authzr.body.status == messages.STATUS_VALID: <MASK> raise acme_errors.Error(""Mock deactivation ACME error"") <TAB>  <TAB> authzb = authzr.body.update(status=messages.STATUS_DEACTIVATED) <TAB>  <TAB> authzr = messages.AuthorizationResource(body=authzb) <TAB> else:  # pragma: no cover <TAB>  <TAB> raise errors.Error(""Can't deactivate non-valid authz"") <TAB> return authzr","if authzr . body . identifier . value == ""is_valid_but_will_fail"" :",143
"def get_parallel_rotations(): <TAB> mult90 = [0, np.pi / 2, -np.pi / 2, np.pi] <TAB> parallel_rotations = [] <TAB> for euler in itertools.product(mult90, repeat=3): <TAB>  <TAB> canonical = mat2euler(euler2mat(euler)) <TAB>  <TAB> canonical = np.round(canonical / (np.pi / 2)) <TAB>  <TAB> if canonical[0] == -2: <TAB>  <TAB>  <TAB> canonical[0] = 2 <MASK> canonical[2] = 2 <TAB>  <TAB> canonical *= np.pi / 2 <TAB>  <TAB> if all([(canonical != rot).any() for rot in parallel_rotations]): <TAB>  <TAB>  <TAB> parallel_rotations += [canonical] <TAB> assert len(parallel_rotations) == 24 <TAB> return parallel_rotations",if canonical [ 2 ] == - 2 :,194
def test_BlobPickle(): <TAB> img = Image(testimageclr) <TAB> blobs = img.findBlobs() <TAB> for b in blobs: <TAB>  <TAB> p = pickle.dumps(b) <TAB>  <TAB> ub = pickle.loads(p) <MASK> assert False <TAB> pass,if ( ub . mMask - b . mMask ) . meanColor ( ) != Color . BLACK :,90
"def save(self): <TAB> updates = self.cinder_obj_get_changes() <TAB> if updates: <TAB>  <TAB> for field in self.OPTIONAL_FIELDS: <MASK> raise exception.ObjectActionError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> action=""save"", reason=_(""%s changed"") % field <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> db.cluster_update(self._context, self.id, updates) <TAB>  <TAB> self.obj_reset_changes()",if field in updates :,113
"def resolve(self, _next, root, info, *args, **kwargs): <TAB> if should_skip_tracing(_next, info): <TAB>  <TAB> result = _next(root, info, *args, **kwargs) <MASK> # pragma: no cover <TAB>  <TAB>  <TAB> result = await result <TAB>  <TAB> return result <TAB> with self._tracer.use_span(self._root_span): <TAB>  <TAB> with self._tracer.start_span(info.field_name, kind=SpanKind.SERVER) as span: <TAB>  <TAB>  <TAB> self.add_tags(span, info, kwargs) <TAB>  <TAB>  <TAB> result = _next(root, info, *args, **kwargs) <TAB>  <TAB>  <TAB> if isawaitable(result): <TAB>  <TAB>  <TAB>  <TAB> result = await result <TAB>  <TAB>  <TAB> return result",if isawaitable ( result ) :,184
"def respond(self, input): <TAB> # find a match among keys <TAB> for pattern, responses in self.RESPONSES: <TAB>  <TAB> match = pattern.match(input) <TAB>  <TAB> if match: <TAB>  <TAB>  <TAB> # Found a match; randomly choose a response, <TAB>  <TAB>  <TAB> # and populate it with the captured regex group data. <TAB>  <TAB>  <TAB> response = random.choice(responses).format( <TAB>  <TAB>  <TAB>  <TAB> *[self.reflect(group) for group in match.groups()] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> # fix punctuation <MASK> response = response[:-2] + ""."" <TAB>  <TAB>  <TAB> if response[-2:] == ""??"": <TAB>  <TAB>  <TAB>  <TAB> response = response[:-2] + ""?"" <TAB>  <TAB>  <TAB> return response","if response [ - 2 : ] == ""?."" :",178
"def flag_membership_changed(sender, instance, action, **kwargs): <TAB> if action in (""post_add"", ""post_remove""): <TAB>  <TAB> flag_model = get_waffle_flag_model() <TAB>  <TAB> # instance could be a flag or an instance of the related model <TAB>  <TAB> # https://docs.djangoproject.com/en/dev/ref/signals/#m2m-changed <MASK> instance.flush() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for flag in flag_model.objects.filter(pk__in=kwargs[""pk_set""]): <TAB>  <TAB>  <TAB>  <TAB> flag.flush()","if isinstance ( instance , flag_model ) :",148
"def interrupter_sleep(self, length): <MASK> return True <TAB> while True: <TAB>  <TAB> sleep = min(0.5, length) <TAB>  <TAB> time.sleep(sleep) <TAB>  <TAB> length -= sleep <TAB>  <TAB> if check_global_interrupt() or self.interrupt: <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> elif length <= 0: <TAB>  <TAB>  <TAB> return False",if check_global_interrupt ( ) or self . interrupt :,98
"def _has_default_egress_rule(self, rule_list): <TAB> for rule in rule_list: <TAB>  <TAB> if rule[""IpProtocol""] == ""-1"": <TAB>  <TAB>  <TAB> for ip_range in rule[""IpRanges""]: <MASK> return True <TAB> return False","if ip_range [ ""CidrIp"" ] == ""0.0.0.0/0"" :",93
"def get_kwargs(self, x, a, e, signature, kwargs): <TAB> output = {} <TAB> for k in signature.keys(): <TAB>  <TAB> if signature[k].default is inspect.Parameter.empty or k == ""kwargs"": <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> elif k == ""x"": <TAB>  <TAB>  <TAB> output[k] = x <TAB>  <TAB> elif k == ""a"": <TAB>  <TAB>  <TAB> output[k] = a <TAB>  <TAB> elif k == ""e"": <TAB>  <TAB>  <TAB> output[k] = e <MASK> output[k] = kwargs[k] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""Missing key {} for signature {}"".format(k, signature)) <TAB> return output",elif k in kwargs :,164
def _extra_froms(self): <TAB> # TODO: this could be made memoized <TAB> # if the memoization is reset on each generative call. <TAB> froms = [] <TAB> seen = {self.table} <TAB> if self._whereclause is not None: <TAB>  <TAB> for item in _from_objects(self._whereclause): <MASK> froms.append(item) <TAB>  <TAB>  <TAB> seen.update(item._cloned_set) <TAB> return froms,if not seen . intersection ( item . _cloned_set ) :,123
"def run_and_print(self, args, **kwargs): <TAB> try: <TAB>  <TAB> instance = self.run(args, **kwargs) <MASK> raise Exception(""Configuration failed"") <TAB>  <TAB> self.print_output( <TAB>  <TAB>  <TAB> instance, <TAB>  <TAB>  <TAB> table.PropertyValueTable, <TAB>  <TAB>  <TAB> attributes=[""all""], <TAB>  <TAB>  <TAB> json=args.json, <TAB>  <TAB>  <TAB> yaml=args.yaml, <TAB>  <TAB> ) <TAB> except (KeyboardInterrupt, SystemExit): <TAB>  <TAB> raise OperationFailureException(""Interrupted"") <TAB> except Exception as e: <TAB>  <TAB> if self.app.client.debug: <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> message = str(e) <TAB>  <TAB> print(""ERROR: %s"" % (message)) <TAB>  <TAB> raise OperationFailureException(message)",if not instance :,182
"def TryMerge(self, d): <TAB> while 1: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 236: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if tt == 242: <TAB>  <TAB>  <TAB> self.set_property(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 250: <TAB>  <TAB>  <TAB> length = d.getVarInt32() <TAB>  <TAB>  <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB>  <TAB>  <TAB> d.skip(length) <TAB>  <TAB>  <TAB> self.mutable_value().TryMerge(tmp) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,177
"def qualitiesToString(self, qualities=None): <TAB> if qualities is None: <TAB>  <TAB> qualities = [] <TAB> result = """" <TAB> for quality in qualities: <MASK> result += Quality.qualityStrings[quality] + "", "" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sickrage.app.log.info(""Bad quality value: "" + str(quality)) <TAB> result = re.sub("", $"", """", result) <TAB> if not len(result): <TAB>  <TAB> result = ""None"" <TAB> return result",if quality in Quality . qualityStrings :,135
"def _ssl_echo_serve_sync(sock): <TAB> try: <TAB>  <TAB> wrapped = server_ctx.wrap_socket(sock, server_side=True) <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> data = wrapped.recv(BUFSIZE) <MASK> wrapped.unwrap() <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> wrapped.sendall(data) <TAB> except BrokenPipeError: <TAB>  <TAB> pass",if not data :,99
"def skip_population(self): <TAB> """"""Skip the current population. Returns true if there is another pop."""""" <TAB> for line in self._handle: <TAB>  <TAB> if line == """": <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> line = line.rstrip() <MASK> self.current_pop += 1 <TAB>  <TAB>  <TAB> self.current_ind = 0 <TAB>  <TAB>  <TAB> return True","if line . upper ( ) == ""POP"" :",95
"def should_restart(self): <TAB> for watcher in self.watchers: <TAB>  <TAB> change = watcher.check() <MASK> message = ""WatchGodReload detected file change in '%s'. Reloading..."" <TAB>  <TAB>  <TAB> logger.warning(message, [c[1] for c in change]) <TAB>  <TAB>  <TAB> return True <TAB> return False",if change != set ( ) :,85
"def __init__(self): <TAB> self.widget = Gtk.ComboBoxText() <TAB> self.widget.set_tooltip_text(_(""Select audio sample frequency"")) <TAB> self.sample_rates = [8000, 12000, 16000, 22500, 32000, 44100, 48000] <TAB> for rate in self.sample_rates: <TAB>  <TAB> val = rate / 1000.0 <MASK> val = int(val) <TAB>  <TAB> self.widget.append_text(str(val) + "" kHz"") <TAB> self.widget.set_active(6)",if val == math . floor ( val ) :,139
"def findTargetNS(self, node): <TAB> """"""Return the defined target namespace uri for the given node."""""" <TAB> attrget = self.getAttr <TAB> attrkey = (self.NS_XMLNS, ""xmlns"") <TAB> DOCUMENT_NODE = node.DOCUMENT_NODE <TAB> ELEMENT_NODE = node.ELEMENT_NODE <TAB> while 1: <TAB>  <TAB> if node.nodeType != ELEMENT_NODE: <TAB>  <TAB>  <TAB> node = node.parentNode <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> result = attrget(node, ""targetNamespace"", default=None) <TAB>  <TAB> if result is not None: <TAB>  <TAB>  <TAB> return result <TAB>  <TAB> node = node.parentNode <MASK> raise DOMException(""Cannot determine target namespace."")",if node . nodeType == DOCUMENT_NODE :,172
"def get_images_from_dir(img_dir, support_ext="".jpg|.jpeg""): <TAB> if not os.path.exists(img_dir) or not os.path.isdir(img_dir): <TAB>  <TAB> raise Exception(""Image Directory [%s] invalid"" % img_dir) <TAB> imgs = [] <TAB> for item in os.listdir(img_dir): <TAB>  <TAB> ext = os.path.splitext(item)[1][1:].strip().lower() <MASK> item_path = os.path.join(img_dir, item) <TAB>  <TAB>  <TAB> imgs.append(item_path) <TAB> return imgs",if len ( ext ) > 0 and ext in support_ext :,159
"def acquire(self): <TAB> start = time.time() <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self._fd = os.open(self.filename, os.O_CREAT | os.O_RDWR | os.O_EXCL) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> except OSError as err: <TAB>  <TAB>  <TAB> if err.errno not in (errno.EEXIST, errno.EACCES): <TAB>  <TAB>  <TAB>  <TAB> raise <MASK> raise TimeoutError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Could not acquire lock '{filename}'."".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> filename=self.filename <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> time.sleep(self.poll)",elif time . time ( ) - start >= self . timeout :,183
"def process(mtree): <TAB> for node in mtree.unidentified_leaves(): <TAB>  <TAB> indices = [] <TAB>  <TAB> didx = 0 <TAB>  <TAB> pattern = re.compile(sep + ""-"" + sep) <TAB>  <TAB> match = pattern.search(node.value) <TAB>  <TAB> while match: <TAB>  <TAB>  <TAB> span = match.span() <TAB>  <TAB>  <TAB> indices.extend([span[0], span[1]]) <TAB>  <TAB>  <TAB> match = pattern.search(node.value, span[1]) <MASK> node.partition(indices)",if indices :,125
"def _attribute_error_detection(self, state, attr, errors): <TAB> if not self.options.report_errors: <TAB>  <TAB> return <TAB> for error in errors: <TAB>  <TAB> combination = [error] <MASK> combination.append(self.frame.func) <TAB>  <TAB> if state.node.HasCombination(combination): <TAB>  <TAB>  <TAB> self.errorlog.attribute_error(self.frames, error, attr)",if self . frame . func :,110
"def node_testlist_gexp(self, node): <TAB> items = [] <TAB> for child in node.children: <TAB>  <TAB> if isinstance(child, Leaf): <MASK> continue <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if type_repr(child.type) == ""comp_for"": <TAB>  <TAB>  <TAB>  <TAB> return self.node_listmaker(node, cls=""tuple"") <TAB>  <TAB> items.append(self.dispatch(child)) <TAB> return items","if child . value == "","" :",113
"def dump_descriptions_of_all_objects(f): <TAB> ids = set() <TAB> ls = locals() <TAB> for o in gc.get_objects(): <TAB>  <TAB> if o is f or o is ids or o is ls: <TAB>  <TAB>  <TAB> continue <MASK> ids.add(id(o)) <TAB>  <TAB>  <TAB> dump_description_of_object(o, f) <TAB>  <TAB> for so in gc.get_referents(o): <TAB>  <TAB>  <TAB> if o is f or o is ids or o is ls: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if not id(so) in ids: <TAB>  <TAB>  <TAB>  <TAB> ids.add(id(so)) <TAB>  <TAB>  <TAB>  <TAB> dump_description_of_object(so, f) <TAB> ls = None  # break reference cycle <TAB> return len(ids)",if not id ( o ) in ids :,195
"def bulk_delete(models: Optional[List[SavedQuery]], commit: bool = True) -> None: <TAB> item_ids = [model.id for model in models] if models else [] <TAB> try: <TAB>  <TAB> db.session.query(SavedQuery).filter(SavedQuery.id.in_(item_ids)).delete( <TAB>  <TAB>  <TAB> synchronize_session=""fetch"" <TAB>  <TAB> ) <MASK> db.session.commit() <TAB> except SQLAlchemyError: <TAB>  <TAB> if commit: <TAB>  <TAB>  <TAB> db.session.rollback() <TAB>  <TAB> raise DAODeleteFailedError()",if commit :,136
"def _put_to_history(self, command_script): <TAB> """"""Puts command script to shell history."""""" <TAB> history_file_name = self._get_history_file_name() <TAB> if os.path.isfile(history_file_name): <TAB>  <TAB> with open(history_file_name, ""a"") as history: <TAB>  <TAB>  <TAB> entry = self._get_history_line(command_script) <MASK> history.write(entry.encode(""utf-8"")) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> history.write(entry)",if six . PY2 :,139
"def _remove_style_from_selection(self, style): <TAB> start, end = self._get_selection() <TAB> tags = self._get_tag_from_range(start.get_offset(), end.get_offset()) <TAB> for tag_name, tag_data in tags.items(): <MASK> for start, end in tag_data: <TAB>  <TAB>  <TAB>  <TAB> self.remove_tag_by_name( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> tag_name, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.get_iter_at_offset(start), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.get_iter_at_offset(end + 1), <TAB>  <TAB>  <TAB>  <TAB> )",if tag_name . startswith ( str ( style ) ) :,164
"def _findSubpath(self, path, A, B): <TAB> print(""finding"", A, B) <TAB> sub = None <TAB> for i in xrange(0, len(path) * 2):  # iterate twice with wrap around <TAB>  <TAB> j = i % len(path) <TAB>  <TAB> seg = path[j] <MASK> sub = Path(""subp"") <TAB>  <TAB> print(""seg"", sub is None, seg) <TAB>  <TAB> if sub is not None: <TAB>  <TAB>  <TAB> sub.append(seg) <TAB>  <TAB> if eq(seg.B, B): <TAB>  <TAB>  <TAB> break <TAB> print(""found"", sub) <TAB> return sub","if eq ( seg . A , A ) :",157
"def validate_request(self, request_headers, request_body, repo_configs, action): <TAB> for repo_config in repo_configs: <TAB>  <TAB> # Validate secret token if present <MASK> if repo_config[""secret-token""] != request_headers[""x-gitlab-token""]: <TAB>  <TAB>  <TAB>  <TAB> action.log_info( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Request token does not match the 'secret-token' configured for repository %s."" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> % repo_config[""url""] <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return True","if ""secret-token"" in repo_config and ""x-gitlab-token"" in request_headers :",159
"def _convert_pycparser_error(self, e, csource): <TAB> # xxx look for "":NUM:"" at the start of str(e) and try to interpret <TAB> # it as a line number <TAB> line = None <TAB> msg = str(e) <TAB> if msg.startswith("":"") and "":"" in msg[1:]: <TAB>  <TAB> linenum = msg[1 : msg.find("":"", 1)] <MASK> linenum = int(linenum, 10) <TAB>  <TAB>  <TAB> csourcelines = csource.splitlines() <TAB>  <TAB>  <TAB> if 1 <= linenum <= len(csourcelines): <TAB>  <TAB>  <TAB>  <TAB> line = csourcelines[linenum - 1] <TAB> return line",if linenum . isdigit ( ) :,155
"def wrapper(*args, **kwargs): <TAB> new_kwargs = {**kwargs} <TAB> for old_param, new_param in deprecated.items(): <MASK> message = f""{func.__qualname__} parameter {old_param!r} is deprecated, use {new_param!r} instead"" <TAB>  <TAB>  <TAB> warnings.warn(message, DeprecationWarning) <TAB>  <TAB>  <TAB> new_kwargs[new_param] = new_kwargs.pop(old_param) <TAB> return func(*args, **new_kwargs)",if old_param in kwargs :,124
"def _target(self, cb=None, exc=None, wait=0): <TAB> total = 0 <TAB> for i, c in enumerate(""abc"", 1): <TAB>  <TAB> total += i <TAB>  <TAB> if wait: <TAB>  <TAB>  <TAB> sleep(wait) <MASK> cb(i, c, intermediate_total=total) <TAB>  <TAB> if exc: <TAB>  <TAB>  <TAB> raise exc(""error in target"") <TAB> return total",if cb :,100
"def _known_types(self, config): <TAB> msg = ( <TAB>  <TAB> ""The config entry %r in section %r is of type %r, "" <TAB>  <TAB> ""which does not match the expected type %r."" <TAB> ) <TAB> for section, conf in config.items(): <TAB>  <TAB> if not isinstance(conf, dict): <TAB>  <TAB>  <TAB> conf = {section: conf} <TAB>  <TAB> for k, v in conf.items(): <TAB>  <TAB>  <TAB> if v is not None: <TAB>  <TAB>  <TAB>  <TAB> expected_type = self.known_config_types.get(k, None) <TAB>  <TAB>  <TAB>  <TAB> vtype = type(v) <MASK> warnings.warn( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> msg % (k, section, vtype.__name__, expected_type.__name__) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> )",if expected_type and vtype != expected_type :,200
"def data(self, index: QModelIndex, role=Qt.DisplayRole): <TAB> if not index.isValid(): <TAB>  <TAB> return None <TAB> if role == Qt.DisplayRole: <TAB>  <TAB> i = index.row() <TAB>  <TAB> j = index.column() <TAB>  <TAB> rule = self.ruleset[i] <TAB>  <TAB> assert isinstance(rule, Rule) <TAB>  <TAB> if j == 0: <TAB>  <TAB>  <TAB> return rule.start + 1 <TAB>  <TAB> elif j == 1: <TAB>  <TAB>  <TAB> return rule.end <MASK> return rule.value_type <TAB>  <TAB> elif j == 3: <TAB>  <TAB>  <TAB> return rule.operator_description <TAB>  <TAB> elif j == 4: <TAB>  <TAB>  <TAB> return rule.target_value",elif j == 2 :,168
"def get_query(self): <TAB> """"""Return the namespace of the <query> element."""""" <TAB> for child in self.xml: <TAB>  <TAB> if child.tag.endswith(""query""): <TAB>  <TAB>  <TAB> ns = child.tag.split(""}"")[0] <MASK> ns = ns[1:] <TAB>  <TAB>  <TAB> return ns <TAB> return """"","if ""{"" in ns :",87
"def fillData(self, cycleLen, samples, data): <TAB> i = cycleLen <TAB> while i < samples: <MASK> len = samples - i <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> len = cycleLen <TAB>  <TAB> Array.Copy(data, 0, data, int(i), int(len)) <TAB>  <TAB> i += cycleLen",if cycleLen > samples - i :,88
"def prepare_exog(exog): <TAB> k_exog = 0 <TAB> if exog is not None: <TAB>  <TAB> exog_is_using_pandas = _is_using_pandas(exog, None) <TAB>  <TAB> if not exog_is_using_pandas: <TAB>  <TAB>  <TAB> exog = np.asarray(exog) <TAB>  <TAB> # Make sure we have 2-dimensional array <MASK> if not exog_is_using_pandas: <TAB>  <TAB>  <TAB>  <TAB> exog = exog[:, None] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> exog = pd.DataFrame(exog) <TAB>  <TAB> k_exog = exog.shape[1] <TAB> return (k_exog, exog)",if exog . ndim == 1 :,159
"def __next__(self): <TAB> if self._next_record_index >= self._num_records: <MASK> raise CorruptRecordException( <TAB>  <TAB>  <TAB>  <TAB> ""{} unconsumed bytes after all records consumed"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> len(self._buffer) - self._pos <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> raise StopIteration <TAB> try: <TAB>  <TAB> msg = self._read_msg() <TAB> except (ValueError, IndexError) as err: <TAB>  <TAB> raise CorruptRecordException(""Found invalid record structure: {!r}"".format(err)) <TAB> else: <TAB>  <TAB> self._next_record_index += 1 <TAB> return msg",if self . _pos != len ( self . _buffer ) :,163
"def onPreSave(tag=None, keywords=None): <TAB> """"""Before saving an @nosent file, make sure that all nodes have a blank line at the end."""""" <TAB> global nosentNodes <TAB> c = keywords.get(""c"") <TAB> if c: <TAB>  <TAB> for p in c.all_positions(): <TAB>  <TAB>  <TAB> if p.isAtNoSentinelsFileNode() and p.isDirty(): <TAB>  <TAB>  <TAB>  <TAB> nosentNodes.append(p.copy()) <TAB>  <TAB>  <TAB>  <TAB> for p2 in p.self_and_subtree(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> s = p2.b <TAB>  <TAB>  <TAB>  <TAB>  <TAB> lastline = s.split(""\n"")[-1] <MASK> c.setBodyString(p2, s + ""\n"")",if lastline . strip ( ) :,188
"def i2m(self, pkt, val): <TAB> ret_string = """" <TAB> for i in range(0, len(val), 2): <TAB>  <TAB> tmp = val[i : i + 2] <MASK> ret_string += chr(int(tmp[1] + tmp[0], 16)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret_string += chr(int(""F"" + tmp[0], 16)) <TAB> return ret_string",if len ( tmp ) == 2 :,113
"def testTokenizer(): <TAB> for filename in get_data_files(""tokenizer"", ""*.test""): <TAB>  <TAB> with open(filename) as fp: <TAB>  <TAB>  <TAB> tests = json.load(fp) <TAB>  <TAB>  <TAB> if ""tests"" in tests: <TAB>  <TAB>  <TAB>  <TAB> for index, test in enumerate(tests[""tests""]): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if ""initialStates"" not in test: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> test[""initialStates""] = [""Data state""] <MASK> test = unescape(test) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for initialState in test[""initialStates""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> test[""initialState""] = capitalize(initialState) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield runTokenizerTest, test","if ""doubleEscaped"" in test :",179
"def _compute_underscore_max_num(self, exps): <TAB> max_num = 0 <TAB> for exp in exps: <TAB>  <TAB> if isinstance(exp, Symbol) and exp.name.startswith(""_""): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> n = int(exp.name[1:]) <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> n = 1 <MASK> n = self._compute_underscore_max_num(exp) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> n = 0 <TAB>  <TAB> if n > max_num: <TAB>  <TAB>  <TAB> max_num = n <TAB> return max_num",elif issequence_except_str ( exp ) :,149
"def _msg_register(fn): <TAB> for _msgType in msgType: <TAB>  <TAB> if isFriendChat: <TAB>  <TAB>  <TAB> self.functionDict[""FriendChat""][_msgType] = fn <MASK> self.functionDict[""GroupChat""][_msgType] = fn <TAB>  <TAB> if isMpChat: <TAB>  <TAB>  <TAB> self.functionDict[""MpChat""][_msgType] = fn <TAB>  <TAB> if not any((isFriendChat, isGroupChat, isMpChat)): <TAB>  <TAB>  <TAB> self.functionDict[""FriendChat""][_msgType] = fn <TAB> return fn",if isGroupChat :,145
"def __init__(self, target_list): <TAB> self.cmake_target_base_names_conficting = set() <TAB> cmake_target_base_names_seen = set() <TAB> for qualified_target in target_list: <TAB>  <TAB> cmake_target_base_name = CreateCMakeTargetBaseName(qualified_target) <MASK> cmake_target_base_names_seen.add(cmake_target_base_name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.cmake_target_base_names_conficting.add(cmake_target_base_name)",if cmake_target_base_name not in cmake_target_base_names_seen :,165
"def __lt__(self, other): <TAB> """"""Test less than."""""" <TAB> if isinstance(other, type(self)): <MASK> return self.id < other.id <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.full_id[1:] < other.full_id[1:] <TAB> else: <TAB>  <TAB> return NotImplemented",if self . parent is None :,85
"def find_pool_lss_pair(self, pool, find_new_pid, excluded_lss): <TAB> if pool: <TAB>  <TAB> node = int(pool[1:], 16) % 2 <TAB>  <TAB> lss = self._find_lss(node, excluded_lss) <MASK> return (pool, lss) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if not find_new_pid: <TAB>  <TAB>  <TAB>  <TAB> raise restclient.LssIDExhaustError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> message=_( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""All LSS/LCU IDs for configured pools "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""on storage are exhausted."" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> # find new pool id and lss for lun <TAB> return self.find_biggest_pool_and_lss(excluded_lss)",if lss :,196
"def _poll(self, timeout): <TAB> (rfds, wfds, _), _ = io_op(select.select, self._rfds, self._wfds, (), timeout) <TAB> for fd in rfds: <TAB>  <TAB> _vv and IOLOG.debug(""%r: POLLIN for %r"", self, fd) <TAB>  <TAB> data, gen = self._rfds.get(fd, (None, None)) <MASK> yield data <TAB> for fd in wfds: <TAB>  <TAB> _vv and IOLOG.debug(""%r: POLLOUT for %r"", self, fd) <TAB>  <TAB> data, gen = self._wfds.get(fd, (None, None)) <TAB>  <TAB> if gen and gen < self._generation: <TAB>  <TAB>  <TAB> yield data",if gen and gen < self . _generation :,185
"def notify(self, message="""", data=None, listener=None): <TAB> if not data: <TAB>  <TAB> data = {} <TAB> n = { <TAB>  <TAB> ""_t"": ""notification"", <TAB>  <TAB> ""time"": int(time.time()), <TAB> } <TAB> try: <TAB>  <TAB> db = get_db() <TAB>  <TAB> n[""message""] = toUnicode(message) <MASK> n[""sticky""] = True <TAB>  <TAB> if data.get(""important""): <TAB>  <TAB>  <TAB> n[""important""] = True <TAB>  <TAB> db.insert(n) <TAB>  <TAB> self.frontend(type=listener, data=n) <TAB>  <TAB> return True <TAB> except: <TAB>  <TAB> log.error('Failed notify ""%s"": %s', (n, traceback.format_exc()))","if data . get ( ""sticky"" ) :",180
"def _remove(self, key, buffer=False): <TAB> if not await self.has_key(key): <TAB>  <TAB> raise ValueError(""The given key does not exist"") <TAB> for H, hashtable in zip(await self.keys.get(key), self.hashtables): <TAB>  <TAB> await hashtable.remove_val(H, key, buffer=buffer) <MASK> await hashtable.remove(H, buffer=buffer) <TAB> await self.keys.remove(key, buffer=buffer)",if not await hashtable . get ( H ) :,131
"def _create_file_suite(self, source): <TAB> suite = self._create_suite(TestCaseFile, source) <TAB> suite.testcase_table.tests = [ <TAB>  <TAB> TestCase(suite, ""%s Fake Test %d"" % (suite.name, i)) for i in range(16) <TAB> ] <TAB> # Initialization of Tags <TAB> count = 0 <TAB> for i in suite.testcase_table.tests: <TAB>  <TAB> newtag = """" <TAB>  <TAB> for key, test in self._tags_list.items(): <TAB>  <TAB>  <TAB> newtag += key + "" <TAB> "" if count in test else """" <MASK> setattr(i.tags, ""tags"", ""{0}"".format(newtag)) <TAB>  <TAB> count += 1 <TAB> return suite",if len ( newtag ) :,180
"def simd_width(self): <TAB> if not self.command_exists(""lscpu""): <TAB>  <TAB> self.warning( <TAB>  <TAB>  <TAB> ""CPUAdam attempted to query 'lscpu' to detect the existence "" <TAB>  <TAB>  <TAB> ""of AVX instructions. However, 'lscpu' does not appear to exist on "" <TAB>  <TAB>  <TAB> ""your system, will fall back to non-vectorized execution."" <TAB>  <TAB> ) <TAB>  <TAB> return """" <TAB> result = subprocess.check_output(""lscpu"", shell=True) <TAB> result = result.decode(""utf-8"").strip().lower() <TAB> if ""genuineintel"" in result: <TAB>  <TAB> if ""avx512"" in result: <TAB>  <TAB>  <TAB> return ""-D__AVX512__"" <MASK> return ""-D__AVX256__"" <TAB> return """"","elif ""avx2"" in result :",200
"def output(self, key, obj): <TAB> items = list(TrackPlaylistRelationship.query.filter_by(playlist=obj)) <TAB> output = [] <TAB> prev = None <TAB> index = 0 <TAB> while len(items): <TAB>  <TAB> x = 0 <TAB>  <TAB> for r_track in items: <MASK> output.append(self.marshal(r_track, index)) <TAB>  <TAB>  <TAB>  <TAB> del items[x] <TAB>  <TAB>  <TAB>  <TAB> prev = r_track <TAB>  <TAB>  <TAB>  <TAB> index += 1 <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> x += 1 <TAB> return output",if r_track . previous_track == prev :,151
"def waitForID(s, wait_id, wait_name=""waited_id[]""): <TAB> while not s.eof: <TAB>  <TAB> addr = s.absolute_address + s.current_size <TAB>  <TAB> uid = s.stream.readBits(addr, 8, LITTLE_ENDIAN) <MASK> yield Enum(UInt8(s, wait_name), ID_INFO) <TAB>  <TAB>  <TAB> s.info(""Found ID %s (%u)"" % (ID_INFO[uid], uid)) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> s.info(""Skipping ID %u!=%u"" % (uid, wait_id)) <TAB>  <TAB> yield SkippedData(s, ""skipped_id[]"", ""%u != %u"" % (uid, wait_id))",if uid == wait_id :,182
def sweep_sessions(self): <TAB> # Iterate over shallow copy to avoid problems with <TAB> # dict changing size during iteration. <TAB> for node_id in tuple(self.sessions.keys()): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> session = self.sessions[node_id] <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> # Dict changed during iteration <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if session is None: <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> session.disconnect(message.base.Disconnect.REASON.NoMoreMessages) <TAB>  <TAB> self.remove_session_by_node_id(node_id),if session . is_active :,150
"def __subclasshook__(cls, C): <TAB> if cls is Awaitable: <TAB>  <TAB> for B in get_mro(C): <TAB>  <TAB>  <TAB> if ""__await__"" in B.__dict__: <MASK> return True <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return NotImplemented","if B . __dict__ [ ""__await__"" ] :",72
"def start(self): <TAB> if not self.opened: <TAB>  <TAB> self.opened = True <TAB>  <TAB> self.__r, self.__w = os.pipe() <TAB>  <TAB> cmd = [""xterm""] <TAB>  <TAB> if self.name is not None: <TAB>  <TAB>  <TAB> cmd.extend([""-title"", self.name]) <MASK> cmd.append(""-hold"") <TAB>  <TAB> cmd.extend([""-e"", ""cat 0<&%i"" % self.__r]) <TAB>  <TAB> self.__p = subprocess.Popen(cmd) <TAB>  <TAB> os.close(self.__r)",if self . keepterm :,138
"def recursiveChildGenerator(self): <TAB> stack = [(self, 0)] <TAB> while stack: <TAB>  <TAB> tag, start = stack.pop() <TAB>  <TAB> if isinstance(tag, Tag): <TAB>  <TAB>  <TAB> for i in range(start, len(tag.contents)): <TAB>  <TAB>  <TAB>  <TAB> a = tag.contents[i] <TAB>  <TAB>  <TAB>  <TAB> yield a <MASK> if i < len(tag.contents) - 1: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> stack.append((tag, i + 1)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> stack.append((a, 0)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB> raise StopIteration","if isinstance ( a , Tag ) and tag . contents :",157
"def cut(self, chars: List[str]): <TAB> words = [] <TAB> idx = 0 <TAB> while idx < len(chars): <TAB>  <TAB> matched = False <TAB>  <TAB> for i in range(self.window_size, 0, -1): <TAB>  <TAB>  <TAB> cand = chars[idx : idx + i] <TAB>  <TAB>  <TAB> if cand in self.dict: <TAB>  <TAB>  <TAB>  <TAB> words.append(cand) <TAB>  <TAB>  <TAB>  <TAB> matched = True <TAB>  <TAB>  <TAB>  <TAB> break <MASK> i = 1 <TAB>  <TAB>  <TAB> words.append(chars[idx]) <TAB>  <TAB> idx += i <TAB> return words",if not matched :,142
"def set_context(self, ctx): <TAB> if self.ctx: <MASK> if ctx.Eip != self.ctx.Eip: <TAB>  <TAB>  <TAB>  <TAB> self.modified_pc = True <TAB> self.ctx = ctx",if self . emu . get_arch ( ) == _arch . ARCH_X86 :,75
"def get_prop_dict(self): <TAB> prop_dict = {} <TAB> prop_dict[""name""] = self.new_prop_name <TAB> # we do not set the slider on the <output node> sockets <TAB> if self.kind == ""outputs"": <TAB>  <TAB> return {} <TAB> sig = self.new_prop_type.lower() <TAB> if sig in {""int"", ""float""}: <TAB>  <TAB> # prop_dict['update'] = updateNode <TAB>  <TAB> prop_dict[""default""] = getattr(self, f""new_prop_{sig}_default"") <TAB>  <TAB> properties = ""min max soft_min soft_max"".split() <TAB>  <TAB> for prop in properties: <MASK> prop_dict[prop] = getattr(self, f""new_prop_{sig}_{prop}"") <TAB> return prop_dict","if getattr ( self , f""enable_{prop}"" ) :",198
"def background_image(computer, name, values): <TAB> """"""Compute lenghts in gradient background-image."""""" <TAB> for type_, value in values: <MASK> value.stop_positions = tuple( <TAB>  <TAB>  <TAB>  <TAB> length(computer, name, pos) if pos is not None else None <TAB>  <TAB>  <TAB>  <TAB> for pos in value.stop_positions <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if type_ == ""radial-gradient"": <TAB>  <TAB>  <TAB> (value.center,) = compute_position(computer, name, (value.center,)) <TAB>  <TAB>  <TAB> if value.size_type == ""explicit"": <TAB>  <TAB>  <TAB>  <TAB> value.size = length_or_percentage_tuple(computer, name, value.size) <TAB> return values","if type_ in ( ""linear-gradient"" , ""radial-gradient"" ) :",182
"def shapeToStr(tensor_shape, keep_minus_one=False): <TAB> ret = """" <TAB> first = True <TAB> for e in tensor_shape.dim: <MASK> if first == False: <TAB>  <TAB>  <TAB>  <TAB> ret += "", "" <TAB>  <TAB>  <TAB> ret += str(e.size) <TAB>  <TAB>  <TAB> first = False <TAB> return ret",if e . size != - 1 or keep_minus_one :,97
"def havemarks(*args, **kwargs): <TAB> origin = kwargs.get(""origin"", """") <TAB> for i, v in enumerate(args): <TAB>  <TAB> if not hasattr(v, ""mark""): <TAB>  <TAB>  <TAB> raise AssertionError( <TAB>  <TAB>  <TAB>  <TAB> ""Value #{0}/{1} ({2!r}) has no attribute `mark`"".format(origin, i, v) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if isinstance(v, dict): <TAB>  <TAB>  <TAB> for key, val in v.items(): <TAB>  <TAB>  <TAB>  <TAB> havemarks( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> key, val, origin=(origin + ""["" + unicode(i) + ""]/"" + unicode(key)) <TAB>  <TAB>  <TAB>  <TAB> ) <MASK> havemarks(*v, origin=(origin + ""["" + unicode(i) + ""]""))","elif isinstance ( v , list ) :",194
"def ActivateNextMenu(self): <TAB> """"""Activates next menu and make sure all others are non-active."""""" <TAB> last_item = self.GetLastVisibleMenu() <TAB> # find the current active menu <TAB> for i in range(last_item + 1): <MASK> nextMenu = i + 1 <TAB>  <TAB>  <TAB> if nextMenu >= last_item: <TAB>  <TAB>  <TAB>  <TAB> nextMenu = 0 <TAB>  <TAB>  <TAB> self.ActivateMenu(self._items[nextMenu]) <TAB>  <TAB>  <TAB> return",if self . _items [ i ] . GetMenu ( ) . IsShown ( ) :,127
"def executable(cls, cmd): <TAB> if os.name in (""posix"", ""nt"") and not os.path.isabs(cmd): <TAB>  <TAB> # always enforce absolute path <TAB>  <TAB> cmd = shutil.which(cmd) <MASK> raise WorkflowError( <TAB>  <TAB>  <TAB>  <TAB> ""Cannot set default shell {} because it "" <TAB>  <TAB>  <TAB>  <TAB> ""is not available in your "" <TAB>  <TAB>  <TAB>  <TAB> ""PATH."".format(cmd) <TAB>  <TAB>  <TAB> ) <TAB> if os.path.split(cmd)[-1].lower() in (""bash"", ""bash.exe""): <TAB>  <TAB> cls._process_prefix = ""set -euo pipefail; "" <TAB>  <TAB> cls._win_command_prefix = ""-c"" <TAB> cls._process_args[""executable""] = cmd",if not cmd :,176
"def get_limit_choices_to(app_name, model_name, field_name): <TAB> try: <TAB>  <TAB> model = get_model(app_name, model_name) <TAB>  <TAB> field = model._meta.get_field(field_name) <TAB>  <TAB> limit_choices_to = ( <TAB>  <TAB>  <TAB> field.rel.limit_choices_to <MASK> else field.remote_field.limit_choices_to <TAB>  <TAB> ) <TAB> except Exception: <TAB>  <TAB> limit_choices_to = None <TAB> return limit_choices_to","if django . VERSION < ( 2 , 0 )",140
"def construct_trigger(trigger_args): <TAB> trigger_type = trigger_args[""type""] <TAB> trigger_args = trigger_args[""args""] <TAB> try: <TAB>  <TAB> if trigger_type == ""date"": <TAB>  <TAB>  <TAB> return DateTrigger(**trigger_args) <TAB>  <TAB> elif trigger_type == ""interval"": <TAB>  <TAB>  <TAB> return IntervalTrigger(**trigger_args) <MASK> return CronTrigger(**trigger_args) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise InvalidTriggerArgs( <TAB>  <TAB>  <TAB>  <TAB> ""Invalid scheduler type {0} with args {1}."".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> trigger_type, trigger_args <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> except (KeyError, ValueError, TypeError): <TAB>  <TAB> raise InvalidTriggerArgs(""Invalid scheduler arguments"")","elif trigger_type == ""cron"" :",188
"def on_asset_perm_deactive(instance: AssetPermission, **kwargs): <TAB> try: <TAB>  <TAB> old = AssetPermission.objects.only(""is_active"").get(id=instance.id) <MASK> create_rebuild_user_tree_task_by_asset_perm(instance) <TAB> except AssetPermission.DoesNotExist: <TAB>  <TAB> pass",if instance . is_active != old . is_active :,100
"def xpath_tokenizer(pattern, namespaces=None): <TAB> for token in xpath_tokenizer_re.findall(pattern): <TAB>  <TAB> tag = token[1] <TAB>  <TAB> if tag and tag[0] != ""{"" and "":"" in tag: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> prefix, uri = tag.split("":"", 1) <MASK> raise KeyError <TAB>  <TAB>  <TAB>  <TAB> yield token[0], ""{%s}%s"" % (namespaces[prefix], uri) <TAB>  <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB>  <TAB> raise SyntaxError(""prefix %r not found in prefix map"" % prefix) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield token",if not namespaces :,152
"def task_updated(self, task): <TAB> if self.episode.url == task.episode.url and self._status != task.status: <TAB>  <TAB> if task.status in (task.DONE, task.FAILED, task.CANCELLED): <TAB>  <TAB>  <TAB> self._on_finished() <MASK> self._on_can_resume() <TAB>  <TAB> elif task.status in (task.QUEUED, task.DOWNLOADING): <TAB>  <TAB>  <TAB> self._on_can_pause() <TAB>  <TAB> self._status = task.status",elif task . status == task . PAUSED :,129
"def session_requested(self): <TAB> """"""Handle a request to create a new session"""""" <TAB> username = self._conn.get_extra_info(""username"") <TAB> with patch(""asyncssh.connection.SSHServerChannel"", _ServerChannel): <TAB>  <TAB> channel = self._conn.create_server_channel() <TAB>  <TAB> if username == ""conn_close"": <TAB>  <TAB>  <TAB> self._conn.close() <TAB>  <TAB>  <TAB> return False <MASK> return (channel, _EchoServerSession()) <TAB>  <TAB> elif username != ""no_channels"": <TAB>  <TAB>  <TAB> return (channel, self._begin_session) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False","elif username in { ""close"" , ""echo"" , ""no_pty"" , ""task_error"" } :",168
"def correct_feed_objects(): <TAB> from core.observables import Observable <TAB> for observable in Observable.objects.filter(context__source=""Hybdrid-Analysis""): <TAB>  <TAB> for ctx in observable.context: <MASK> ctx[""source""] = ""HybridAnalysis"" <TAB>  <TAB> observable.value = observable.value.replace(""FILE: "", ""FILE:"") <TAB>  <TAB> observable.save()","if ctx [ ""source"" ] == ""Hybdrid-Analysis"" :",115
"def _visit_argument_annotations(self, arguments): <TAB> for arg in arguments: <MASK> if arg.annotation: <TAB>  <TAB>  <TAB>  <TAB> self.visit(arg.annotation) <TAB>  <TAB>  <TAB>  <TAB> yield arg.name <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for name in self._visit_argument_annotations(arg.args): <TAB>  <TAB>  <TAB>  <TAB> yield name","if isinstance ( arg , ast . SimpleArg ) :",95
def _check_stop(self): <TAB> if self._state == STOPPING: <TAB>  <TAB> hDirectory = self._hDirectory <TAB>  <TAB> self._callbacks = None <TAB>  <TAB> self._hDirectory = None <TAB>  <TAB> CloseHandle(hDirectory) <TAB>  <TAB> self._state = STOPPED <MASK> self._pending_call.cancel() <TAB>  <TAB>  <TAB> self._pending_call = None <TAB> return self._state == STOPPED,if self . _pending_call :,106
"def gids(self): <TAB> f = open(""/proc/%s/status"" % self.pid, ""rb"") <TAB> try: <TAB>  <TAB> GID = b(""Gid:"") <TAB>  <TAB> for line in f: <MASK> _, real, effective, saved, fs = line.split() <TAB>  <TAB>  <TAB>  <TAB> return _common.pgids(int(real), int(effective), int(saved)) <TAB>  <TAB> raise NotImplementedError(""line not found"") <TAB> finally: <TAB>  <TAB> f.close()",if line . startswith ( GID ) :,125
"def _prepare(self, items): <TAB> items = list(items) <TAB> try: <MASK> is_marshal, d = True, marshal.dumps(items) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> is_marshal, d = False, cPickle.dumps(items, -1) <TAB> except ValueError: <TAB>  <TAB> is_marshal, d = False, cPickle.dumps(items, -1) <TAB> data = compress(d) <TAB> size = len(data) <TAB> return (is_marshal, data), size",if marshalable ( items ) :,138
"def extras(self): <TAB> # type: () -> Dict[S, Optional[Any]] <TAB> if self._extras_requirements is None: <TAB>  <TAB> self._extras_requirements = () <TAB>  <TAB> self.get_info() <TAB> extras_dict = {} <TAB> extras = set(self._extras_requirements) <TAB> for section, deps in extras: <MASK> extras_dict[section] = deps.requirement <TAB>  <TAB> elif isinstance(deps, (list, tuple)): <TAB>  <TAB>  <TAB> extras_dict[section] = [d.requirement for d in deps] <TAB> return extras_dict","if isinstance ( deps , BaseRequirement ) :",145
"def cancel(self, kill=False): <TAB> with self._lock: <TAB>  <TAB> self._is_cancelled = True <MASK> return <TAB>  <TAB> logger.info(""Terminating %s"", self._process_cmd) <TAB>  <TAB> self._process.terminate() <TAB> for _ in polling_loop(10): <TAB>  <TAB> with self._lock: <TAB>  <TAB>  <TAB> if self._process is None or not self._process.is_running(): <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> if kill: <TAB>  <TAB>  <TAB> break <TAB> self._kill_process()",if self . _process is None or not self . _process . is_running ( ) :,142
"def set_alpn_protocols(self, alpn_protocols): <TAB> protos = bytearray() <TAB> for protocol in alpn_protocols: <TAB>  <TAB> b = protocol.encode(""ascii"") <MASK> raise SSLError(""ALPN protocols must be 1 to 255 in length"") <TAB>  <TAB> protos.append(len(b)) <TAB>  <TAB> protos.extend(b) <TAB> self._set_alpn_protocols(protos)",if len ( b ) == 0 or len ( b ) > 255 :,113
"def get_forwards(self) -> List[Forward]: <TAB> forwards: List[Forward] = [] <TAB> for entry in ProxyForward.search_forward(region=self.region): <MASK> entry.delete() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> forwards.append( <TAB>  <TAB>  <TAB>  <TAB> Forward( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> src_port=entry.port, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> dst_ip=entry.dst_ip, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> dst_port=entry.dst_port, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> return forwards",if entry . endtime < datetime . datetime . now ( tz = datetime . timezone . utc ) :,153
"def step(self, action): <TAB> """"""Repeat action, sum reward, and max over last observations."""""" <TAB> total_reward = 0.0 <TAB> done = None <TAB> for i in range(self._skip): <TAB>  <TAB> obs, reward, done, info = self.env.step(action) <MASK> self._obs_buffer[0] = obs <TAB>  <TAB> if i == self._skip - 1: <TAB>  <TAB>  <TAB> self._obs_buffer[1] = obs <TAB>  <TAB> total_reward += reward <TAB>  <TAB> if done or info.get(""needs_reset"", False): <TAB>  <TAB>  <TAB> break <TAB> # Note that the observation on the done=True frame <TAB> # doesn't matter <TAB> max_frame = self._obs_buffer.max(axis=0) <TAB> return max_frame, total_reward, done, info",if i == self . _skip - 2 :,199
"def get_selected_rules(benchmark): <TAB> rules = set() <TAB> for profile in benchmark.findall("".//{%s}Profile"" % (XCCDF12_NS)): <TAB>  <TAB> for selection in profile.findall("".//{%s}select"" % (XCCDF12_NS)): <TAB>  <TAB>  <TAB> idref = selection.get(""idref"") <TAB>  <TAB>  <TAB> selected = selection.get(""selected"") <MASK> rules.add(idref) <TAB> return rules","if idref . startswith ( OSCAP_RULE ) and selected == ""true"" :",124
"def pytest_collection_modifyitems(items): <TAB> # numpy changed the str/repr formatting of numpy arrays in 1.14. <TAB> # We want to run doctests only for numpy >= 1.14.Adapted from scikit-learn <TAB> if LooseVersion(np.__version__) < LooseVersion(""1.14""): <TAB>  <TAB> reason = ""doctests are only run for numpy >= 1.14"" <TAB>  <TAB> skip_doctests = True <TAB> else: <TAB>  <TAB> skip_doctests = False <TAB> if skip_doctests: <TAB>  <TAB> skip_marker = pytest.mark.skip(reason=reason) <TAB>  <TAB> for item in items: <MASK> item.add_marker(skip_marker)","if isinstance ( item , DoctestItem ) :",164
"def close(self, code=errno.ECONNRESET, sync=True): <TAB> with self.shutdown_lock: <MASK> self.log.debug(""already stopped"") <TAB>  <TAB>  <TAB> return <TAB>  <TAB> self.log.info(""source shutdown"") <TAB>  <TAB> self.shutdown.set() <TAB>  <TAB> if self.nl is not None: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> self.nl.close(code=code) <TAB>  <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB>  <TAB> self.log.error(""source close: %s"" % e) <TAB> if sync: <TAB>  <TAB> if self.th is not None: <TAB>  <TAB>  <TAB> self.th.join() <TAB>  <TAB>  <TAB> self.th = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.log.debug(""receiver thread missing"")",if self . shutdown . is_set ( ) :,194
"def expand_env_vars(env_variables): <TAB> """"""Convert service environment attribute into dictionary of name/value pairs."""""" <TAB> results = [] <TAB> if isinstance(env_variables, dict): <TAB>  <TAB> results = [ <TAB>  <TAB>  <TAB> {""name"": x, ""value"": env_variables[x]} for x in list(env_variables.keys()) <TAB>  <TAB> ] <TAB> elif isinstance(env_variables, list): <TAB>  <TAB> for evar in env_variables: <TAB>  <TAB>  <TAB> parts = evar.split(""="", 1) <TAB>  <TAB>  <TAB> if len(parts) == 1: <TAB>  <TAB>  <TAB>  <TAB> results.append({""name"": parts[0], ""value"": None}) <MASK> results.append({""name"": parts[0], ""value"": parts[1]}) <TAB> return results",elif len ( parts ) == 2 :,187
"def get_config(cls): <TAB> # FIXME: Replace this as soon as we have a config module <TAB> config = {} <TAB> # HMM dir <TAB> # Try to get hmm_dir from config <TAB> profile_path = dingdangpath.config(""profile.yml"") <TAB> if os.path.exists(profile_path): <TAB>  <TAB> with open(profile_path, ""r"") as f: <TAB>  <TAB>  <TAB> profile = yaml.safe_load(f) <MASK> config[""language""] = profile[""google-tts""][""language""] <TAB> return config","if ""google-tts"" in profile and ""language"" in profile [ ""google-tts"" ] :",153
"def geos_geometrycollection_from_py(ob): <TAB> """"""Creates a GEOS GeometryCollection from a list of geometries"""""" <TAB> L = len(ob) <TAB> N = 2 <TAB> subs = (c_void_p * L)() <TAB> for l in range(L): <TAB>  <TAB> assert isinstance(ob[l], BaseGeometry) <MASK> N = 3 <TAB>  <TAB> geom, n = geos_geom_from_py(ob[l]) <TAB>  <TAB> subs[l] = geom <TAB> return (lgeos.GEOSGeom_createCollection(7, subs, L), N)",if ob [ l ] . has_z :,152
"def setup_once(): <TAB> @add_global_event_processor <TAB> def processor(event, hint): <MASK> if ""modules"" not in event: <TAB>  <TAB>  <TAB>  <TAB> event[""modules""] = dict(_get_installed_modules()) <TAB>  <TAB> return event",if Hub . current . get_integration ( ModulesIntegration ) is not None :,80
"def iterTags(self, name, attrs={}, namespace=None): <TAB> """"""Iterate over all children using specified arguments as filter."""""" <TAB> for node in self.kids: <MASK> continue <TAB>  <TAB> if namespace is not None and namespace != node.getNamespace(): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if node.getName() == name: <TAB>  <TAB>  <TAB> for key in attrs.keys(): <TAB>  <TAB>  <TAB>  <TAB> if key not in node.attrs or node.attrs[key] != attrs[key]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield node",if not node :,138
"def recv(self, length: int = 0): <TAB> data = b"""" <TAB> while len(data) < length: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> chunk = await asyncio.wait_for( <TAB>  <TAB>  <TAB>  <TAB> self.reader.read(length - len(data)), TCP.TIMEOUT <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> except (OSError, asyncio.TimeoutError): <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> else: <MASK> data += chunk <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return None <TAB> return data",if chunk :,125
"def mimeData(self, items): <TAB> """"""Return MIME data for specified items."""""" <TAB> album_ids = [] <TAB> files = [] <TAB> url = QtCore.QUrl.fromLocalFile <TAB> for item in items: <TAB>  <TAB> obj = item.obj <MASK> album_ids.append(obj.id) <TAB>  <TAB> elif obj.iterfiles: <TAB>  <TAB>  <TAB> files.extend([url(f.filename) for f in obj.iterfiles()]) <TAB> mimeData = QtCore.QMimeData() <TAB> mimeData.setData(""application/picard.album-list"", ""\n"".join(album_ids).encode()) <TAB> if files: <TAB>  <TAB> mimeData.setUrls(files) <TAB> return mimeData","if isinstance ( obj , Album ) :",175
"def parse(cls, api, json): <TAB> place = cls(api) <TAB> for k, v in json.items(): <TAB>  <TAB> if k == ""bounding_box"": <TAB>  <TAB>  <TAB> # bounding_box value may be null (None.) <TAB>  <TAB>  <TAB> # Example: ""United States"" (id=96683cc9126741d1) <TAB>  <TAB>  <TAB> if v is not None: <TAB>  <TAB>  <TAB>  <TAB> t = BoundingBox.parse(api, v) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> t = v <TAB>  <TAB>  <TAB> setattr(place, k, t) <MASK> # contained_within is a list of Places. <TAB>  <TAB>  <TAB> setattr(place, k, Place.parse_list(api, v)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> setattr(place, k, v) <TAB> return place","elif k == ""contained_within"" :",199
"def natural_sort_value(self): <TAB> # docker acts weird: 'created' is provided as ordinal and is local time <TAB> # 'started' and 'finished' are UTC as timestamp; it would be awesome to unite those b/c <TAB> # atm these inconsistencies mess ordering <TAB> try: <TAB>  <TAB> # Nones are unsortable <TAB>  <TAB> return max( <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB> x <TAB>  <TAB>  <TAB>  <TAB> for x in [self.started_at, self.finished_at, super().natural_sort_value] <MASK> ] <TAB>  <TAB> ) <TAB> except NotAvailableAnymore: <TAB>  <TAB> return super().natural_sort_value",if x,157
"def get_lan_ip(): <TAB> """"""Return IP of system."""""" <TAB> try: <TAB>  <TAB> return [ <TAB>  <TAB>  <TAB> ip <TAB>  <TAB>  <TAB> for ip in socket.gethostbyname_ex(socket.gethostname())[2] <MASK> ][0] <TAB> except Exception: <TAB>  <TAB> return socket.gethostname()","if not ip . startswith ( ""127."" )",85
"def container(self, container): <TAB> if self.container: <MASK> raise RuntimeError(""Already have a container"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # existing container should be removed <TAB>  <TAB>  <TAB> self.constraints.container = None <TAB>  <TAB>  <TAB> self._container = None <TAB>  <TAB>  <TAB> self.native.removeFromSuperview() <TAB> elif container: <TAB>  <TAB> # setting container <TAB>  <TAB> self._container = container <TAB>  <TAB> self._container.native.addSubview(self.native) <TAB>  <TAB> self.constraints.container = container <TAB> for child in self.interface.children: <TAB>  <TAB> child._impl.container = container <TAB> self.rehint()",if container :,155
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.add_item().TryMerge(d) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 58: <TAB>  <TAB>  <TAB> self.set_name_space(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 82: <TAB>  <TAB>  <TAB> length = d.getVarInt32() <TAB>  <TAB>  <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB>  <TAB>  <TAB> d.skip(length) <TAB>  <TAB>  <TAB> self.mutable_override().TryMerge(tmp) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 11 :,198
"def getDescription(self, test): <TAB> try: <MASK> return ""%s [%s]"" % ( <TAB>  <TAB>  <TAB>  <TAB> test._testlib_shortname_, <TAB>  <TAB>  <TAB>  <TAB> "", "".join(test._testlib_explicit_tags_), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return test._testlib_shortname_ <TAB> except: <TAB>  <TAB> return ""<Error getting description for %s>"" % (test,)",if test . _testlib_explicit_tags_ :,110
"def soname_and_full_path(self): <TAB> """"""Return soname and full path of the shared library, if any"""""" <TAB> if ""soname_and_full_path"" not in self.data: <TAB>  <TAB> self.data[""soname_and_full_path""] = None <MASK> so_path = self._library_full_path(""so"") <TAB>  <TAB>  <TAB> soname = self._soname_of(so_path) <TAB>  <TAB>  <TAB> if soname: <TAB>  <TAB>  <TAB>  <TAB> self.data[""soname_and_full_path""] = (soname, so_path) <TAB> return self.data[""soname_and_full_path""]","if self . attr [ ""has_dynamic"" ] :",166
"def checkpoint(self, result=None): <TAB> if not self.read_only: <TAB>  <TAB> handle = self.trials.handle <TAB>  <TAB> handle.refresh(self.current_trial) <MASK> return handle.update(self.current_trial, dict(result=result))",if result is not None :,73
"def generateValueNode(self, node): <TAB> result = super().generateValueNode(node) <TAB> if result == """" or result.isspace(): <TAB>  <TAB> return '""""' <TAB> else: <TAB>  <TAB> if self.matchKeyword:  # don't quote search value on keyword field <MASK> make_ci = self.makeCaseInSensitiveValue(result) <TAB>  <TAB>  <TAB>  <TAB> result = make_ci.get(""value"") <TAB>  <TAB>  <TAB>  <TAB> if make_ci.get(""is_regex""):  # Determine if still should be a regex <TAB>  <TAB>  <TAB>  <TAB>  <TAB> result = ""/%s/"" % result  # Regex place holders for regex <TAB>  <TAB>  <TAB> return result <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return '""%s""' % result",if self . CaseInSensitiveField :,175
"def getStartupArgs(userArgs): <TAB> args = {} <TAB> if userArgs: <TAB>  <TAB> for argToAdd in userArgs: <MASK> argToAdd = argToAdd[2:] <TAB>  <TAB>  <TAB> elif argToAdd.startswith(""-""): <TAB>  <TAB>  <TAB>  <TAB> argToAdd = argToAdd[1:] <TAB>  <TAB>  <TAB> if argToAdd.strip() == """": <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if ""="" in argToAdd: <TAB>  <TAB>  <TAB>  <TAB> (argName, argValue) = argToAdd.split(""="", 1) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> argName = argToAdd <TAB>  <TAB>  <TAB>  <TAB> argValue = ""yes"" <TAB>  <TAB>  <TAB> args[argName] = argValue <TAB> return args","if argToAdd . startswith ( ""--"" ) :",178
"def dispatch(self, obj, qualifier=""default""): <TAB> if isinstance(obj, string_types): <TAB>  <TAB> targets = [obj] <TAB> elif isinstance(obj, type): <TAB>  <TAB> targets = obj.__mro__ <TAB> else: <TAB>  <TAB> targets = type(obj).__mro__ <TAB> for spcls in targets: <TAB>  <TAB> if qualifier != ""default"" and (spcls, qualifier) in self._registry: <TAB>  <TAB>  <TAB> return self._fn_or_list(self._registry[(spcls, qualifier)]) <MASK> return self._fn_or_list(self._registry[(spcls, ""default"")]) <TAB> else: <TAB>  <TAB> raise ValueError(""no dispatch function for object: %s"" % obj)","elif ( spcls , ""default"" ) in self . _registry :",176
"def after_step(self, step, feed_dict): <TAB> if step % (self.config.step_count or 1) != 0: <TAB>  <TAB> return <TAB> # compress <TAB> for i in range(self.config.night_steps or 1): <TAB>  <TAB> self.gan.session.run(self.optimize_t) <TAB> if self.config.reinitialize_every: <MASK> print(""Reinitializing active D"") <TAB>  <TAB>  <TAB> self.gan.session.run(self.re_init_d)",if step % ( self . config . reinitialize_every ) == 0 and step > 0 :,142
"def read_vocab(cls, vocab_path): <TAB> d_vocab = {} <TAB> with PathManager.open(vocab_path, ""r"") as f: <TAB>  <TAB> for line in f: <TAB>  <TAB>  <TAB> fields = line.rstrip(""\n"").split(""\t"") <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""vocab file (%s) corrupted. Line (%s)"" % (repr(line), vocab_path) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> wid, word = fields <TAB>  <TAB>  <TAB>  <TAB> d_vocab[wid] = word <TAB> return d_vocab",if len ( fields ) != 2 :,152
"def test_lchflags(self): <TAB> if hasattr(posix, ""lchflags""): <TAB>  <TAB> st = os.stat(test_support.TESTFN) <MASK> posix.lchflags(test_support.TESTFN, st.st_flags)","if hasattr ( st , ""st_flags"" ) :",69
"def reset_session(): <TAB> """"""Remove all config files"""""" <TAB> print(""*** Reset Spyder settings to defaults ***"", file=STDERR) <TAB> for fname in SAVED_CONFIG_FILES: <TAB>  <TAB> cfg_fname = get_conf_path(fname) <TAB>  <TAB> if osp.isfile(cfg_fname): <TAB>  <TAB>  <TAB> os.remove(cfg_fname) <MASK> shutil.rmtree(cfg_fname) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> print(""removing:"", cfg_fname, file=STDERR)",elif osp . isdir ( cfg_fname ) :,132
"def normalize_db_params(db_params): <TAB> try: <TAB>  <TAB> db_connect = db_params[""db_connect""] <TAB> except: <TAB>  <TAB> raise Exception(""input db_connect must be set"") <TAB> db_connect_args = db_params.get(""db_connect_args"", {}) <TAB> if ""+pg8000"" not in db_connect: <TAB>  <TAB> if ""timeout"" in db_connect_args: <TAB>  <TAB>  <TAB> timeout = db_connect_args.pop(""timeout"") <TAB>  <TAB>  <TAB> db_connect_args[""connect_timeout""] = int(timeout) <TAB>  <TAB> if ""ssl"" in db_connect_args: <TAB>  <TAB>  <TAB> ssl = db_connect_args.pop(""ssl"") <MASK> db_connect_args[""sslmode""] = ""require"" <TAB> return db_params",if ssl :,193
"def get_id(self, version: int) -> str: <TAB> if self.is_anon() and version < 3: <TAB>  <TAB> raise NoOldIdError() <TAB> if version == 1: <MASK> return ""s"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.identifier <TAB> if self.identifier == ""std"": <TAB>  <TAB> return ""St"" <TAB> elif self.identifier[0] == ""~"": <TAB>  <TAB> # a destructor, just use an arbitrary version of dtors <TAB>  <TAB> return ""D0"" <TAB> else: <TAB>  <TAB> if self.is_anon(): <TAB>  <TAB>  <TAB> return ""Ut%d_%s"" % (len(self.identifier) - 1, self.identifier[1:]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return str(len(self.identifier)) + self.identifier","if self . identifier == ""size_t"" :",195
"def handle_module(mod): <TAB> for name, mem in inspect.getmembers(mod): <MASK> handle_class(name, mem) <TAB>  <TAB> elif inspect.isfunction(mem): <TAB>  <TAB>  <TAB> handle_function(name, mem) <TAB>  <TAB> elif ""keras_preprocessing"" in name and inspect.ismodule(mem): <TAB>  <TAB>  <TAB> # Only test keras_preprocessing' modules <TAB>  <TAB>  <TAB> handle_module(mem)",if inspect . isclass ( mem ) :,105
"def init_blocklist(cls, config): <TAB> if not cls.blocklist_json: <TAB>  <TAB> bucket_config = config.get( <TAB>  <TAB>  <TAB> ""blocklist_bucket"", config.get(""blacklist_bucket"", None) <TAB>  <TAB> ) <MASK> cls.blocklist_json = get_blocklist_from_bucket(bucket_config)",if bucket_config :,89
"def get_ssh_key_file(self): <MASK> ssh_dir = os.path.expanduser(""~/.ssh"") <TAB>  <TAB> if os.path.isdir(ssh_dir): <TAB>  <TAB>  <TAB> ssh_file = os.path.join(ssh_dir, ""%s.pem"" % self.key_name) <TAB>  <TAB>  <TAB> if os.path.isfile(ssh_file): <TAB>  <TAB>  <TAB>  <TAB> self.ssh_key_file = ssh_file <TAB>  <TAB> if not self.ssh_key_file: <TAB>  <TAB>  <TAB> iobject = IObject() <TAB>  <TAB>  <TAB> self.ssh_key_file = iobject.get_filename(""Path to OpenSSH Key file"") <TAB> return self.ssh_key_file",if not self . ssh_key_file :,173
"def ComboBoxDroppedHeightTest(windows): <TAB> """"""Check if each combobox height is the same as the reference"""""" <TAB> bugs = [] <TAB> for win in windows: <TAB>  <TAB> if not win.ref: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if win.class_name() != ""ComboBox"" or win.ref.class_name() != ""ComboBox"": <TAB>  <TAB>  <TAB> continue <MASK> bugs.append( <TAB>  <TAB>  <TAB>  <TAB> ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> win, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ], <TAB>  <TAB>  <TAB>  <TAB>  <TAB> {}, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> testname, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> 0, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> return bugs",if win . dropped_rect ( ) . height ( ) != win . ref . dropped_rect ( ) . height ( ) :,185
"def make_input_node(self): <TAB> nodes = [CaffeNode(name, NodeKind.Data) for name in self.model.input] <TAB> if len(nodes): <TAB>  <TAB> input_dim = list(map(int, self.model.input_dim)) <TAB>  <TAB> if not input_dim: <MASK> input_dim = list(map(int, self.model.input_shape[0].dim)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> # TODO: raise error <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> for node in nodes: <TAB>  <TAB>  <TAB> node.output_shape = tuple(input_dim) <TAB>  <TAB>  <TAB> node.output.append(""data"") <TAB> return nodes",if len ( self . model . input_shape ) > 0 :,180
"def _repr_pretty_(self, p, cycle): <TAB> """"""Pretty print path list"""""" <TAB> if cycle: <TAB>  <TAB> p.text(""EnvPath(...)"") <TAB> else: <TAB>  <TAB> with p.group(1, ""EnvPath(\n["", ""]\n)""): <TAB>  <TAB>  <TAB> for idx, item in enumerate(self): <MASK> p.text("","") <TAB>  <TAB>  <TAB>  <TAB>  <TAB> p.breakable() <TAB>  <TAB>  <TAB>  <TAB> p.pretty(item)",if idx :,115
"def point_combinations_iterator(n, i0=0, saturated=None): <TAB> for i in range(i0, len(points)): <TAB>  <TAB> p, ieqs = points[i] <TAB>  <TAB> if saturated is None: <TAB>  <TAB>  <TAB> saturated_ieqs = ieqs <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> saturated_ieqs = saturated.intersection(ieqs) <TAB>  <TAB> if len(saturated_ieqs) == 0: <TAB>  <TAB>  <TAB> continue <MASK> yield [i] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for c in point_combinations_iterator(n - 1, i + 1, saturated_ieqs): <TAB>  <TAB>  <TAB>  <TAB> yield [i] + c",if n == 1 :,178
"def load_file(self, directory): <TAB> try: <TAB>  <TAB> # This code will not activate without PIL/Pillow installed. <TAB>  <TAB> from PIL import Image <TAB>  <TAB> if self.url is not None: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> self.image = Image.open(self.url) <TAB>  <TAB>  <TAB> except IOError: <TAB>  <TAB>  <TAB>  <TAB> try: <MASK> from os.path import join <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> relpath = join(directory, self.url) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.image = Image.open(relpath) <TAB>  <TAB>  <TAB>  <TAB> except IOError: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return <TAB> except ImportError: <TAB>  <TAB> # PIL/Pillow not found, decoding data is most we can do. <TAB>  <TAB> pass",if directory is not None :,187
"def _check_attr_func_resolution(self, structure): <TAB> for attr in structure.attributes: <TAB>  <TAB> attribute = structure.attributes[attr] <TAB>  <TAB> for d in attribute.data: <TAB>  <TAB>  <TAB> if d.data_type == late_resolution: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> for func in structure.functions: <TAB>  <TAB> function = structure.functions[func] <TAB>  <TAB> for attr in function.attributes: <TAB>  <TAB>  <TAB> attribute = function.attributes[attr] <TAB>  <TAB>  <TAB> for d in attribute.data: <TAB>  <TAB>  <TAB>  <TAB> if d.data_type == late_resolution: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> for ret in function.return_type: <MASK> return True <TAB> return False",if ret . data_type == late_resolution :,185
"def __init__( <TAB> self, setting, newValue, settings=None, autoResolve=False, ignoreOld=False): <TAB> ActionConflict.__init__(self, setting, settings, autoResolve) <TAB> self.Name = _(""key"") <TAB> if not newValue: <TAB>  <TAB> return <TAB> newValue = newValue.lower() <TAB> oldValue = self.Setting.Value.lower() <TAB> badValues = [""disabled"", ""none""] <TAB> if not ignoreOld: <TAB>  <TAB> badValues.append(oldValue) <TAB> if newValue in badValues: <TAB>  <TAB> return <TAB> for s in self.Settings: <MASK> continue <TAB>  <TAB> if s.Type == ""Key"": <TAB>  <TAB>  <TAB> if s.Value.lower() == newValue: <TAB>  <TAB>  <TAB>  <TAB> self.Conflicts.append(s)",if s is setting :,191
"def _static(path): <TAB> response = None <TAB> if ""jinja_env"" in _start_args and ""jinja_templates"" in _start_args: <TAB>  <TAB> template_prefix = _start_args[""jinja_templates""] + ""/"" <MASK> n = len(template_prefix) <TAB>  <TAB>  <TAB> template = _start_args[""jinja_env""].get_template(path[n:]) <TAB>  <TAB>  <TAB> response = btl.HTTPResponse(template.render()) <TAB> if response is None: <TAB>  <TAB> response = btl.static_file(path, root=root_path) <TAB> _set_response_headers(response) <TAB> return response",if path . startswith ( template_prefix ) :,160
"def get_training_data(self): <TAB> """"""Retrieves training data from the State domain object."""""" <TAB> state_training_data_by_answer_group = [] <TAB> for (answer_group_index, answer_group) in enumerate(self.interaction.answer_groups): <MASK> answers = copy.deepcopy(answer_group.training_data) <TAB>  <TAB>  <TAB> state_training_data_by_answer_group.append( <TAB>  <TAB>  <TAB>  <TAB> {""answer_group_index"": answer_group_index, ""answers"": answers} <TAB>  <TAB>  <TAB> ) <TAB> return state_training_data_by_answer_group",if answer_group . training_data :,152
"def _parse(self, stream, context): <TAB> if ""<obj>"" in context: <TAB>  <TAB> obj = context[""<obj>""] <TAB>  <TAB> del context[""<obj>""] <TAB> else: <TAB>  <TAB> obj = Container() <MASK> context = Container(_=context) <TAB> for sc in self.subcons: <TAB>  <TAB> if sc.conflags & self.FLAG_EMBED: <TAB>  <TAB>  <TAB> context[""<obj>""] = obj <TAB>  <TAB>  <TAB> sc._parse(stream, context) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> subobj = sc._parse(stream, context) <TAB>  <TAB>  <TAB> if sc.name is not None: <TAB>  <TAB>  <TAB>  <TAB> obj[sc.name] = subobj <TAB>  <TAB>  <TAB>  <TAB> context[sc.name] = subobj <TAB> return obj",if self . nested :,182
"def get_start_point_and_download_mode(self, download): <TAB> # Resume the previous download if possible <TAB> start_point = 0 <TAB> download_mode = ""wb"" <TAB> if os.path.isfile(download.save_location): <MASK> print(""Resuming download {}"".format(download.save_location)) <TAB>  <TAB>  <TAB> download_mode = ""ab"" <TAB>  <TAB>  <TAB> start_point = os.stat(download.save_location).st_size <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> os.remove(download.save_location) <TAB> return start_point, download_mode",if self . __is_same_download_as_before ( download ) :,155
"def _prepare_data(self, data, convert=False): <TAB> if isinstance(data, list): <TAB>  <TAB> data = np.array(data, dtype=np.uint32) <TAB> if not isinstance(data, np.ndarray): <TAB>  <TAB> raise ValueError(""Data must be a ndarray (got %s)"" % type(data)) <TAB> if not data.dtype.isbuiltin: <TAB>  <TAB> raise TypeError(""Element buffer dtype cannot be structured"") <TAB> else: <MASK> if data.dtype is not np.uint32: <TAB>  <TAB>  <TAB>  <TAB> data = data.astype(np.uint32) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if data.dtype not in [np.uint32, np.uint16, np.uint8]: <TAB>  <TAB>  <TAB>  <TAB> raise TypeError(""Invalid dtype for IndexBuffer: %r"" % data.dtype) <TAB> return data",if convert :,196
"def filter_non_printable(_str): <TAB> chars = [] <TAB> for c in str(_str): <TAB>  <TAB> if is_printable_chr(c): <TAB>  <TAB>  <TAB> chars.append(c) <TAB>  <TAB> else: <MASK> chars.append(NON_PRINTABLE_REPLACE) <TAB>  <TAB>  <TAB> elif chars[-1] != NON_PRINTABLE_REPLACE: <TAB>  <TAB>  <TAB>  <TAB> chars.append(NON_PRINTABLE_REPLACE) <TAB> return """".join(chars)",if not chars :,116
"def dict_values_to_lbc(d): <TAB> lbc_dict = {} <TAB> for key, value in d.items(): <TAB>  <TAB> if isinstance(value, int): <TAB>  <TAB>  <TAB> lbc_dict[key] = dewies_to_lbc(value) <MASK> lbc_dict[key] = dict_values_to_lbc(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lbc_dict[key] = value <TAB> return lbc_dict","elif isinstance ( value , dict ) :",123
def _pollLogin(self): <TAB> try: <TAB>  <TAB> start = time.time() <TAB>  <TAB> while not self._abort and ( <TAB>  <TAB>  <TAB> not self._loginTimeout or (time.time() - start) < self._loginTimeout <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> result = self._checkLogin() <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> self.expired = True <TAB>  <TAB>  <TAB>  <TAB> break <MASK> break <TAB>  <TAB>  <TAB> time.sleep(self.POLLINTERVAL) <TAB>  <TAB> if self.token and self._callback: <TAB>  <TAB>  <TAB> self._callback(self.token) <TAB> finally: <TAB>  <TAB> self.finished = True,if result :,163
"def __init__(self, tc, *args, **kwargs): <TAB> if xmlEnabled: <MASK> kwargs[""output""] = os.path.join( <TAB>  <TAB>  <TAB>  <TAB> os.getcwd(), <TAB>  <TAB>  <TAB>  <TAB> ""TestResults_%s_%s"" % (time.strftime(""%Y%m%d%H%M%S""), os.getpid()), <TAB>  <TAB>  <TAB> ) <TAB> kwargs[""stream""] = self.streamLoggerClass(tc.logger) <TAB> super(OETestRunner, self).__init__(*args, **kwargs) <TAB> self.tc = tc <TAB> self.resultclass = OETestResult","if not kwargs . get ( ""output"" ) :",148
"def _recursive_glob(p, matchPatterns, files, root=None): <TAB> import os <TAB> import glob <TAB> if root is None: <TAB>  <TAB> root = p <TAB> for searchExpr in matchPatterns: <TAB>  <TAB> for d in glob.glob(os.path.join(p, searchExpr)): <MASK> files.append(os.path.relpath(d, root)) <TAB> # Recurse subfolders <TAB> for fname in os.listdir(p): <TAB>  <TAB> folder = os.path.join(p, fname) <TAB>  <TAB> if os.path.isdir(folder): <TAB>  <TAB>  <TAB> _recursive_glob(folder, matchPatterns, files, root)",if os . path . isfile ( d ) :,163
"def from_yaml(self, filename, silent=False): <TAB> if self.root_path: <TAB>  <TAB> filename = os.path.join(self.root_path, filename) <TAB> try: <TAB>  <TAB> with open(filename, ""rt"", encoding=""utf8"") as f: <TAB>  <TAB>  <TAB> obj = yaml.safe_load(f) <TAB> except IOError as e: <MASK> return False <TAB>  <TAB> e.strerror = ""Unable to load configuration file (%s)"" % e.strerror <TAB>  <TAB> raise <TAB> if obj: <TAB>  <TAB> return self.from_mapping(obj) <TAB> return True","if silent and e . errno in ( errno . ENOENT , errno . EISDIR ) :",157
"def _count_diff_hashable(actual, expected): <TAB> ""Returns list of (cnt_act, cnt_exp, elem) triples where the counts differ"" <TAB> # elements must be hashable <TAB> s, t = _ordered_count(actual), _ordered_count(expected) <TAB> result = [] <TAB> for elem, cnt_s in s.items(): <TAB>  <TAB> cnt_t = t.get(elem, 0) <MASK> diff = _Mismatch(cnt_s, cnt_t, elem) <TAB>  <TAB>  <TAB> result.append(diff) <TAB> for elem, cnt_t in t.items(): <TAB>  <TAB> if elem not in s: <TAB>  <TAB>  <TAB> diff = _Mismatch(0, cnt_t, elem) <TAB>  <TAB>  <TAB> result.append(diff) <TAB> return result",if cnt_s != cnt_t :,191
"def get(filename): <TAB> for path in ["".."", "".""]: <TAB>  <TAB> filepath = os.path.join(path, filename) <MASK> with open(filepath) as infile: <TAB>  <TAB>  <TAB>  <TAB> code = infile.read() <TAB>  <TAB>  <TAB>  <TAB> # comment = '#line 0 // Start of ""%s""\n' % filename <TAB>  <TAB>  <TAB>  <TAB> comment = '// --- start of ""%s"" ---\n' % filename <TAB>  <TAB>  <TAB> return comment + code <TAB> return '#error ""%s"" not found !\n' % filename",if os . path . exists ( filepath ) :,130
"def _git_base_url(): <TAB> stdout = _capture_stdout([""git"", ""remote"", ""-v""]) <TAB> for line in stdout.splitlines(0): <MASK> root = line.split()[1].strip() <TAB>  <TAB>  <TAB> root = root.replace(""ssh://git@"", ""https://"", 1) <TAB>  <TAB>  <TAB> root = root.rsplit("".git"", 1)[0]  # reomve "".git"" <TAB>  <TAB>  <TAB> return root <TAB> # guess the root from filesystem <TAB> if exists(abspath(join(dirname(__file__), "".."", ""src"", ""dbgp""))): <TAB>  <TAB> return ""https://github.com/Komodo/KomodoIDE"" <TAB> return ""https://github.com/Komodo/KomodoEdit""","if line . startswith ( ""origin"" ) :",179
"def has_key(self, key, version=None): <TAB> key = self.make_key(key, version=version) <TAB> self.validate_key(key) <TAB> fname = self._key_to_file(key) <TAB> try: <TAB>  <TAB> with open(fname, ""rb"") as f: <TAB>  <TAB>  <TAB> exp = pickle.load(f) <TAB>  <TAB> now = time.time() <MASK> self._delete(fname) <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return True <TAB> except (IOError, OSError, EOFError, pickle.PickleError): <TAB>  <TAB> return False",if exp < now :,147
"def get_example(endpoint: Endpoint) -> Optional[Case]: <TAB> static_parameters = {} <TAB> for name in PARAMETERS: <TAB>  <TAB> parameter = getattr(endpoint, name) <TAB>  <TAB> if parameter is not None and ""example"" in parameter: <TAB>  <TAB>  <TAB> static_parameters[name] = parameter[""example""] <TAB> if static_parameters: <TAB>  <TAB> with handle_warnings(): <TAB>  <TAB>  <TAB> strategies = { <TAB>  <TAB>  <TAB>  <TAB> other: from_schema(getattr(endpoint, other)) <TAB>  <TAB>  <TAB>  <TAB> for other in PARAMETERS - set(static_parameters) <MASK> } <TAB>  <TAB>  <TAB> return _get_case_strategy(endpoint, static_parameters, strategies).example() <TAB> return None","if getattr ( endpoint , other ) is not None",176
"def _remove_timeout(self, key: object) -> None: <TAB> if key in self.waiting: <TAB>  <TAB> request, callback, timeout_handle = self.waiting[key] <MASK> self.io_loop.remove_timeout(timeout_handle) <TAB>  <TAB> del self.waiting[key]",if timeout_handle is not None :,84
"def __getitem__(self, k): <TAB> try: <TAB>  <TAB> return super(StripeObject, self).__getitem__(k) <TAB> except KeyError as err: <MASK> raise KeyError( <TAB>  <TAB>  <TAB>  <TAB> ""%r.  HINT: The %r attribute was set in the past."" <TAB>  <TAB>  <TAB>  <TAB> ""It was then wiped when refreshing the object with "" <TAB>  <TAB>  <TAB>  <TAB> ""the result returned by Stripe's API, probably as a "" <TAB>  <TAB>  <TAB>  <TAB> ""result of a save().  The attributes currently "" <TAB>  <TAB>  <TAB>  <TAB> ""available on this object are: %s"" <TAB>  <TAB>  <TAB>  <TAB> % (k, k, "", "".join(list(self.keys()))) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise err",if k in self . _transient_values :,182
"def get_libs(self, paths, report_error=None): <TAB> result = set() <TAB> for path in paths: <TAB>  <TAB> lib = self.get_lib(path) <MASK> if report_error is None: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""path not found "" + path) <TAB>  <TAB>  <TAB> report_error(path) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> result.add(lib) <TAB> return result",if not lib :,103
"def test_unicode_filenames(self): <TAB> try: <TAB>  <TAB> t1 = writeTmp(1, [""A\nB""]) <TAB>  <TAB> encoding = sys.getfilesystemencoding() <MASK> encoding = ""ascii"" <TAB>  <TAB> fi = FileInput(files=unicode(t1, encoding)) <TAB>  <TAB> lines = list(fi) <TAB>  <TAB> self.assertEqual(lines, [""A\n"", ""B""]) <TAB> finally: <TAB>  <TAB> remove_tempfiles(t1)",if encoding is None :,115
"def _get_hg_root(q): <TAB> _curpwd = builtins.__xonsh__.env[""PWD""] <TAB> while True: <TAB>  <TAB> if not os.path.isdir(_curpwd): <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> if any([b.name == "".hg"" for b in xt.scandir(_curpwd)]): <TAB>  <TAB>  <TAB> q.put(_curpwd) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _oldpwd = _curpwd <TAB>  <TAB>  <TAB> _curpwd = os.path.split(_curpwd)[0] <MASK> return False",if _oldpwd == _curpwd :,147
"def download(downloads): <TAB> for download in downloads: <TAB>  <TAB> url = download[""url""] <TAB>  <TAB> dst = download[""dst""] <TAB>  <TAB> if not os.path.exists(dst): <TAB>  <TAB>  <TAB> if not OPTS.download: <TAB>  <TAB>  <TAB>  <TAB> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Downloads not permitted. Use --download option to permit"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> urllib.urlretrieve(url, dst) <MASK> path = download.get(""path"", os.path.dirname(dst)) <TAB>  <TAB>  <TAB>  <TAB> z = zipfile.ZipFile(dst) <TAB>  <TAB>  <TAB>  <TAB> z.extractall(path)","if download . get ( ""unzip"" ) :",155
"def acquire_db_lock(db, lock_name, blocking=True): <TAB> lock_id = DB_LOCKS[lock_name] <TAB> with db.get_cursor(autocommit=True) as cursor: <MASK> cursor.run(""SELECT pg_advisory_lock(%s)"", (lock_id,)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> locked = cursor.one(""SELECT pg_try_advisory_lock(%s)"", (lock_id,)) <TAB>  <TAB>  <TAB> assert locked, ""failed to acquire the %s lock"" % lock_name <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> yield <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> cursor.run(""SELECT pg_advisory_unlock(%s)"", (lock_id,)) <TAB>  <TAB>  <TAB> except InterfaceError: <TAB>  <TAB>  <TAB>  <TAB> pass",if blocking :,192
"def set_interval(self, interval, prompt): <TAB> print(""Changing the interval will clear the station memory."") <TAB> v = self.station.getArchiveInterval() <TAB> ans = None <TAB> while ans not in [""y"", ""n""]: <TAB>  <TAB> print(""Interval is"", v) <MASK> ans = input(""Set interval to %d minutes (y/n)? "" % interval) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""Setting interval to %d minutes"" % interval) <TAB>  <TAB>  <TAB> ans = ""y"" <TAB>  <TAB> if ans == ""y"": <TAB>  <TAB>  <TAB> self.station.setArchiveInterval(interval) <TAB>  <TAB>  <TAB> v = self.station.getArchiveInterval() <TAB>  <TAB>  <TAB> print(""Interval is now"", v) <TAB>  <TAB> elif ans == ""n"": <TAB>  <TAB>  <TAB> print(""Set interval cancelled."")",if prompt :,196
"def _pygments_token_to_classname(token): <TAB> """"""Converts pygments Tokens, token names (strings) to PTK style names."""""" <TAB> if token and isinstance(token, str): <TAB>  <TAB> # if starts with non capital letter => leave it as it is <TAB>  <TAB> if token[0].islower(): <TAB>  <TAB>  <TAB> return token <TAB>  <TAB> # if starts with capital letter => pygments token name <TAB>  <TAB> if token.startswith(""Token.""): <TAB>  <TAB>  <TAB> token = token[6:] <TAB>  <TAB> # short colors - all caps <MASK> token = ""color."" + token <TAB>  <TAB> return ""pygments."" + token.lower() <TAB> return pygments_token_to_classname(token)",if token == token . upper ( ) :,161
"def add_batch(self, sample_batch: SampleBatchType) -> None: <TAB> warn_replay_buffer_size(item=sample_batch, num_items=self.num_slots) <TAB> if self.num_slots > 0: <MASK> self.replay_batches.append(sample_batch) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.replay_batches[self.replay_index] = sample_batch <TAB>  <TAB>  <TAB> self.replay_index += 1 <TAB>  <TAB>  <TAB> self.replay_index %= self.num_slots",if len ( self . replay_batches ) < self . num_slots :,142
"def inject_operational(self, peers, operational): <TAB> result = True <TAB> for neighbor in self.neighbors: <TAB>  <TAB> if neighbor in peers: <MASK> if operational.name == ""ASM"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.neighbors[neighbor].asm[operational.family()] = operational <TAB>  <TAB>  <TAB>  <TAB> self.neighbors[neighbor].messages.append(operational) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.logger.error( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""the route family is not configured on neighbor"", ""configuration"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> result = False <TAB> return result",if operational . family ( ) in self . neighbors [ neighbor ] . families ( ) :,166
"def checkFields(fields, negOk=False): <TAB> for field in fields: <TAB>  <TAB> k = bytes2NativeString(field) <TAB>  <TAB> if k[0] == ""-"" and negOk: <TAB>  <TAB>  <TAB> k = k[1:] <MASK> raise BadRequest(""no such field '{}'"".format(k))",if k not in entityType . fieldNames :,85
def has_unresolved_jumps(self): <TAB> for addr in self.block_addrs: <TAB>  <TAB> if addr in self._function_manager._kb.unresolved_indirect_jumps: <TAB>  <TAB>  <TAB> b = self._function_manager._kb._project.factory.block(addr) <MASK> return True <TAB> return False,"if b . vex . jumpkind == ""Ijk_Boring"" :",95
"def getObservation(self): <TAB> """"""inold, seeold, black, seenew, innew"""""" <TAB> res = zeros(5) <TAB> if self.env.perseus == self.env.goal: <TAB>  <TAB> res[4] = 1 <TAB> elif self.env.perseus == self.env.initPos[0]: <TAB>  <TAB> res[0] = 1 <TAB> elif self.env.perseus[1] == 3: <MASK> res[self.env.perseusDir] = 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> res[(self.env.perseusDir + 2) % 4] = 1 <TAB> else: <TAB>  <TAB> res[(self.env.perseusDir + 2) % 4] = 1 <TAB> return res",if random ( ) > 0.7 :,189
"def cleanup(files): <TAB> """"""Clean up on exit"""""" <TAB> for sfile in files: <TAB>  <TAB> if os.path.exists(sfile): <MASK> shutil.rmtree(sfile) <TAB>  <TAB>  <TAB> elif os.path.isfile(sfile): <TAB>  <TAB>  <TAB>  <TAB> os.remove(sfile)",if os . path . isdir ( sfile ) :,81
"def generate(self): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> token = self._get_next_token() <TAB>  <TAB> except StopIteration: <TAB>  <TAB>  <TAB> break <MASK> self.namespaces.append(False) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if token.name == ""}"": <TAB>  <TAB>  <TAB> if self.namespaces.pop(): <TAB>  <TAB>  <TAB>  <TAB> self.namespace_stack.pop() <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> result = self._generate_one(token) <TAB>  <TAB> if result: <TAB>  <TAB>  <TAB> yield result","if token . name == ""{"" :",130
"def _merge(self, k1, k2): <TAB> """"""Merge two components."""""" <TAB> assert self.latest_id > k1 and self.latest_id > k2 <TAB> s1 = self._find(k1) <TAB> s2 = self._find(k2) <TAB> if s1 != s2: <MASK> self.parent[s2] = s1 <TAB>  <TAB> elif self.rank[s1] < self.rank[s2]: <TAB>  <TAB>  <TAB> self.parent[s1] = s2 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.parent[s1] = s2 <TAB>  <TAB>  <TAB> self.rank[s2] += 1",if self . rank [ s1 ] > self . rank [ s2 ] :,171
"def is_visible(self): <TAB> # MUST BE CALLED AFTER `compute_style()` METHOD IS CALLED! <TAB> if self._parent: <MASK> return False <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB> self._tagName != ""summary"" <TAB>  <TAB>  <TAB> and self._parent._tagName == ""details"" <TAB>  <TAB>  <TAB> and not self._parent.open <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> return False <TAB> return self.get_is_visible()",if not self . _parent . is_visible :,119
"def parse(cls, data: bytes, fmt: int): <TAB> if len(data) < 8 or len(data) % 4: <TAB>  <TAB> raise ValueError(""RTCP RTP feedback length is invalid"") <TAB> ssrc, media_ssrc = unpack(""!LL"", data[0:8]) <TAB> lost = [] <TAB> for pos in range(8, len(data), 4): <TAB>  <TAB> pid, blp = unpack(""!HH"", data[pos : pos + 4]) <TAB>  <TAB> lost.append(pid) <TAB>  <TAB> for d in range(0, 16): <MASK> lost.append(pid + d + 1) <TAB> return cls(fmt=fmt, ssrc=ssrc, media_ssrc=media_ssrc, lost=lost)",if ( blp >> d ) & 1 :,185
"def __radd__(self, other): <TAB> if isinstance(other, list): <MASK> result = copy(other) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # To avoid accidentally convert a DedupList to normal list. <TAB>  <TAB>  <TAB> result = DedupList(other) <TAB>  <TAB> result.extend(self) <TAB>  <TAB> return result <TAB> raise TypeError(""invalid concat"")","if isinstance ( other , DedupList ) :",99
"def _findRTHook(modnm): <TAB> rslt = [] <TAB> for script in rthooks.get(modnm) or []: <TAB>  <TAB> nm = os.path.basename(script) <TAB>  <TAB> nm = os.path.splitext(nm)[0] <MASK> path = script <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> path = os.path.join(HOMEPATH, script) <TAB>  <TAB> rslt.append((nm, path, ""PYSOURCE"")) <TAB> return rslt",if os . path . isabs ( script ) :,126
"def run(self, creator, symlinks): <TAB> bin_dir = self.dest(creator, self.src).parent <TAB> dest = bin_dir / self.base <TAB> method = self.method(symlinks) <TAB> method(self.src, dest) <TAB> if not symlinks: <TAB>  <TAB> make_exe(dest) <TAB> for extra in self.aliases: <TAB>  <TAB> link_file = bin_dir / extra <MASK> link_file.unlink() <TAB>  <TAB> if symlinks: <TAB>  <TAB>  <TAB> link_file.symlink_to(self.base) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> copy(self.src, link_file) <TAB>  <TAB> if not symlinks: <TAB>  <TAB>  <TAB> make_exe(link_file)",if link_file . exists ( ) :,175
"def post_process_signature(signature): <TAB> parts = re.split(r""\.(?!\d)"", signature) <TAB> if len(parts) >= 4: <MASK> signature = ""keras.layers."" + ""."".join(parts[3:]) <TAB>  <TAB> if parts[1] == ""utils"": <TAB>  <TAB>  <TAB> signature = ""keras.utils."" + ""."".join(parts[3:]) <TAB>  <TAB> if parts[1] == ""backend"": <TAB>  <TAB>  <TAB> signature = ""keras.backend."" + ""."".join(parts[3:]) <TAB>  <TAB> if parts[1] == ""callbacks"": <TAB>  <TAB>  <TAB> signature = ""keras.callbacks."" + ""."".join(parts[3:]) <TAB> return signature","if parts [ 1 ] == ""layers"" :",164
"def _forward(self): <TAB> buf = [] <TAB> try: <TAB>  <TAB> while not self._shutdown: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> line = self.pipe_rfile.readline() <MASK> break <TAB>  <TAB>  <TAB>  <TAB> buf.append(line) <TAB>  <TAB>  <TAB>  <TAB> if line.endswith(""\n""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._send(buf) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> buf = [] <TAB>  <TAB>  <TAB> except IOError: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if buf: <TAB>  <TAB>  <TAB> self._send(buf) <TAB> except Exception as e: <TAB>  <TAB> logger.error(""_forward err: %s"", e)",if not line :,158
"def _check_data(self) -> None: <TAB> supported = (np.ndarray, pd.DataFrame, pd.Series) <TAB> for i, arg in enumerate(self._args): <MASK> raise TypeError(arg_type_error.format(i=i, arg_type=type(arg))) <TAB> for key in self._kwargs: <TAB>  <TAB> if not isinstance(self._kwargs[key], supported): <TAB>  <TAB>  <TAB> arg_type = type(self._kwargs[key]) <TAB>  <TAB>  <TAB> raise TypeError(kwarg_type_error.format(key=key, arg_type=arg_type))","if not isinstance ( arg , supported ) :",147
"def _create_examples(lines, set_type): <TAB> examples = [] <TAB> for (i, line) in enumerate(lines): <MASK> continue <TAB>  <TAB> guid = ""%s-%s"" % (set_type, i) <TAB>  <TAB> if set_type in [""train"", ""dev""]: <TAB>  <TAB>  <TAB> text_a = line[0] <TAB>  <TAB>  <TAB> label = line[1] <TAB>  <TAB>  <TAB> examples.append( <TAB>  <TAB>  <TAB>  <TAB> SequenceClsInputExample( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> guid=guid, text=text_a, text_b=None, label=label <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> text_a = line[1] <TAB>  <TAB>  <TAB> examples.append(SequenceClsInputExample(guid=guid, text=text_a)) <TAB> return examples",if i == 0 :,196
"def all_listed_files(paths): <TAB> for path in paths: <MASK> yield path <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for root, _, files in os.walk(path, topdown=False): <TAB>  <TAB>  <TAB>  <TAB> for filename in files: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield os.path.join(root, filename)",if os . path . isfile ( path ) :,88
"def sorted_by_priority(pricing_rules): <TAB> # If more than one pricing rules, then sort by priority <TAB> pricing_rules_list = [] <TAB> pricing_rule_dict = {} <TAB> for pricing_rule in pricing_rules: <MASK> continue <TAB>  <TAB> pricing_rule_dict.setdefault(cint(pricing_rule.get(""priority"")), []).append( <TAB>  <TAB>  <TAB> pricing_rule <TAB>  <TAB> ) <TAB> for key in sorted(pricing_rule_dict): <TAB>  <TAB> pricing_rules_list.append(pricing_rule_dict.get(key)) <TAB> return pricing_rules_list or pricing_rules","if not pricing_rule . get ( ""priority"" ) :",161
"def has_baked_material(bobject, materials): <TAB> for mat in materials: <MASK> continue <TAB>  <TAB> baked_mat = mat.name + ""_"" + bobject.name + ""_baked"" <TAB>  <TAB> if baked_mat in bpy.data.materials: <TAB>  <TAB>  <TAB> return True <TAB> return False",if mat is None :,82
"def domain_name_induvidual(self, request, full_url, headers): <TAB> self.setup_class(request, full_url, headers) <TAB> url_path_parts = self.path.split(""/"") <TAB> domain_name = url_path_parts[2] <TAB> domain_names = {} <TAB> try: <TAB>  <TAB> if self.method == ""GET"": <MASK> domain_names = self.backend.get_domain_name(domain_name) <TAB>  <TAB> return 200, {}, json.dumps(domain_names) <TAB> except DomainNameNotFound as error: <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB> error.code, <TAB>  <TAB>  <TAB> {}, <TAB>  <TAB>  <TAB> '{{""message"":""{0}"",""code"":""{1}""}}'.format(error.message, error.error_type), <TAB>  <TAB> )",if domain_name is not None :,199
"def run(self): <TAB> try: <TAB>  <TAB> not_running = self.cluster.stop( <TAB>  <TAB>  <TAB> wait=not self.options.no_wait, signal_event=self.options.signal_event <TAB>  <TAB> ) <MASK> sys.stdout.write(""The following nodes were not running: "") <TAB>  <TAB>  <TAB> for node in not_running: <TAB>  <TAB>  <TAB>  <TAB> sys.stdout.write(node.name + "" "") <TAB>  <TAB>  <TAB> print_("""") <TAB> except NodeError as e: <TAB>  <TAB> print_(str(e), file=sys.stderr) <TAB>  <TAB> exit(1)",if self . options . verbose and len ( not_running ) > 0 :,155
"def index(self, featureId): <TAB> """"""Gets the Feature Index for a given Feature ID"""""" <TAB> if self._check(): <TAB>  <TAB> may_have = False <TAB>  <TAB> ivalue = int(featureId) <TAB>  <TAB> for index, f in enumerate(self.features): <TAB>  <TAB>  <TAB> if f is None: <TAB>  <TAB>  <TAB>  <TAB> may_have = True <TAB>  <TAB>  <TAB> elif ivalue == int(f): <TAB>  <TAB>  <TAB>  <TAB> return index <TAB>  <TAB> if may_have: <TAB>  <TAB>  <TAB> reply = self.device.request(0x0000, _pack(""!H"", ivalue)) <MASK> index = ord(reply[0:1]) <TAB>  <TAB>  <TAB>  <TAB> self.features[index] = FEATURE[ivalue] <TAB>  <TAB>  <TAB>  <TAB> return index <TAB> raise ValueError(""%r not in list"" % featureId)",if reply :,193
"def close(self) -> None: <TAB> with self._lock: <MASK> return <TAB>  <TAB> if isinstance(self._sock, socket): <TAB>  <TAB>  <TAB> self._sock.shutdown(SHUT_WR) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._sock.shutdown() <TAB>  <TAB> self._sock.close() <TAB>  <TAB> self._closed = True",if self . _closed :,87
"def _push_to_remote(branch: str) -> None: <TAB> try: <TAB>  <TAB> subprocess.check_output( <TAB>  <TAB>  <TAB> (""git"", ""push"", ""origin"", branch), stderr=subprocess.STDOUT <TAB>  <TAB> ) <TAB> except subprocess.CalledProcessError as e: <MASK> raise PushNotFastForwardError() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.error(f""Push to {branch} failed with:\n {e.stdout}"") <TAB>  <TAB>  <TAB> raise","if ""Updates were rejected"" in str ( e . stdout ) :",123
"def load_ckpt(args, model, optimizer=None): <TAB> if args.init_from_ckpt: <TAB>  <TAB> params_state_dict = paddle.load(args.init_from_ckpt + "".pdparams"") <TAB>  <TAB> model.set_state_dict(params_state_dict) <MASK> opt_state_dict = paddle.load(args.init_from_ckpt + "".pdopt"") <TAB>  <TAB>  <TAB> optimizer.set_state_dict(opt_state_dict) <TAB>  <TAB> print(""Loaded checkpoint from %s"" % args.init_from_ckpt)",if optimizer :,141
"def _add_top_counts(self): <TAB> for key, counts in list(self.match.items()): <MASK> self.text += ""%s:\n"" % (key[11:]) <TAB>  <TAB>  <TAB> top_events = list(counts.items()) <TAB>  <TAB>  <TAB> if not top_events: <TAB>  <TAB>  <TAB>  <TAB> self.text += ""No events found.\n"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> top_events.sort(key=lambda x: x[1], reverse=True) <TAB>  <TAB>  <TAB>  <TAB> for term, count in top_events: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.text += ""%s: %s\n"" % (term, count) <TAB>  <TAB>  <TAB> self.text += ""\n""","if key . startswith ( ""top_events_"" ) :",176
"def get_list_of_var_names(self): <TAB> resArray = [] <TAB> while 1: <TAB>  <TAB> tok = self.tokenizer.get_next_token() <TAB>  <TAB> if self.classifier.is_variable(tok): <TAB>  <TAB>  <TAB> resArray.append([tok[""text""], tok[""start_line""]]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> tok = self.tokenizer.get_next_token() <MASK> break <TAB> return resArray","if not self . classifier . is_operator ( tok , "","" ) :",125
"def _weekly_to_loc(self, index: Union[pd.DatetimeIndex, pd.PeriodIndex]) -> np.ndarray: <TAB> if self._freq.freqstr == ""H"": <TAB>  <TAB> return index.hour + 24 * index.dayofweek <TAB> elif self._freq.freqstr == ""D"": <TAB>  <TAB> return index.dayofweek <TAB> else:  # ""B"" <TAB>  <TAB> bdays = pd.bdate_range(""2000-1-1"", periods=10).dayofweek.unique() <TAB>  <TAB> loc = index.dayofweek <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""freq is B but index contains days that are not business "" ""days."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return loc",if not loc . isin ( bdays ) . all ( ) :,181
"def _scandir(dir_path, suffix, recursive): <TAB> for entry in os.scandir(dir_path): <TAB>  <TAB> if not entry.name.startswith(""."") and entry.is_file(): <TAB>  <TAB>  <TAB> if full_path: <TAB>  <TAB>  <TAB>  <TAB> return_path = entry.path <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return_path = osp.relpath(entry.path, root) <TAB>  <TAB>  <TAB> if suffix is None: <TAB>  <TAB>  <TAB>  <TAB> yield return_path <MASK> yield return_path <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if recursive: <TAB>  <TAB>  <TAB>  <TAB> yield from _scandir(entry.path, suffix=suffix, recursive=recursive) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> continue",elif return_path . endswith ( suffix ) :,176
"def main(): <TAB> what = os.environ.get(""DCS"", sys.argv[1] if len(sys.argv) > 1 else ""all"") <TAB> if what != ""all"": <TAB>  <TAB> if sys.platform.startswith(""linux""): <TAB>  <TAB>  <TAB> r = install_packages(what) <TAB>  <TAB>  <TAB> if r == 0 and what == ""kubernetes"": <TAB>  <TAB>  <TAB>  <TAB> r = setup_kubernetes() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> r = install_postgres() <TAB>  <TAB> if r == 0 and what.startswith(""etcd""): <TAB>  <TAB>  <TAB> r = install_etcd() <MASK> return r <TAB> return install_requirements(what)",if r != 0 :,155
"def flatten_fieldsets(fieldsets): <TAB> """"""Returns a list of field names from an admin fieldsets structure."""""" <TAB> field_names = [] <TAB> for name, opts in fieldsets: <TAB>  <TAB> for field in opts[""fields""]: <TAB>  <TAB>  <TAB> # type checking feels dirty, but it seems like the best way here <MASK> field_names.extend(field) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> field_names.append(field) <TAB> return field_names",if type ( field ) == tuple :,122
"def get_config(self, maxtries): <TAB> start_ts = None <TAB> ntries = 0 <TAB> while ntries < maxtries or maxtries == 0: <TAB>  <TAB> cfg = self.station.get_config() <MASK> return cfg <TAB>  <TAB> ntries += 1 <TAB>  <TAB> if start_ts is None: <TAB>  <TAB>  <TAB> start_ts = int(time.time()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> dur = int(time.time()) - start_ts <TAB>  <TAB>  <TAB> print(""No data after %d seconds (press SET to sync)"" % dur) <TAB>  <TAB> time.sleep(30) <TAB> return None",if cfg is not None :,154
"def get_version_from_app(self, app): <TAB> if hasattr(app, ""get_version""): <TAB>  <TAB> get_version = app.get_version <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> return get_version() <TAB>  <TAB>  <TAB> except TypeError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return get_version <TAB> if hasattr(app, ""VERSION""): <TAB>  <TAB> return app.VERSION <TAB> if hasattr(app, ""__version__""): <TAB>  <TAB> return app.__version__ <TAB> return",if callable ( get_version ) :,128
"def on_click(self, event): <TAB> level = self._get_backlight_level() <TAB> button = event[""button""] <TAB> if button == self.button_up: <TAB>  <TAB> delta = self.brightness_delta if level >= self.low_tune_threshold else 1 <TAB>  <TAB> level += delta <MASK> level = 100 <TAB>  <TAB> self._set_backlight_level(level) <TAB> elif button == self.button_down: <TAB>  <TAB> delta = self.brightness_delta if level > self.low_tune_threshold else 1 <TAB>  <TAB> level -= delta <TAB>  <TAB> if level < self.brightness_minimal: <TAB>  <TAB>  <TAB> level = self.brightness_minimal <TAB>  <TAB> self._set_backlight_level(level)",if level > 100 :,172
"def os_path_split(path): <TAB> """"""Split a path."""""" <TAB> result = [] <TAB> while True: <TAB>  <TAB> previous_path = path <TAB>  <TAB> path, tail = os.path.split(path) <MASK> result.insert(0, path) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> result.insert(0, tail) <TAB>  <TAB> if len(path) == 0: <TAB>  <TAB>  <TAB> break <TAB> return result","if path == previous_path and tail == """" :",111
"def handle_restore_headers(self, response): <TAB> provider = self.bucket.connection.provider <TAB> header = response.getheader(provider.restore_header) <TAB> if header is None: <TAB>  <TAB> return <TAB> parts = header.split("","", 1) <TAB> for part in parts: <TAB>  <TAB> key, val = [i.strip() for i in part.split(""="")] <TAB>  <TAB> val = val.replace('""', """") <MASK> self.ongoing_restore = True if val.lower() == ""true"" else False <TAB>  <TAB> elif key == ""expiry-date"": <TAB>  <TAB>  <TAB> self.expiry_date = val","if key == ""ongoing-request"" :",152
"def builder(): <TAB> for term in terms.get(self.param, []): <TAB>  <TAB> arg = term[""arg""] <TAB>  <TAB> escaped_arg, sql_expr = ( <TAB>  <TAB>  <TAB> (arg, self.qual_expr) <TAB>  <TAB>  <TAB> if term[""qualified""] <TAB>  <TAB>  <TAB> else (like_escape(arg), self.like_expr) <TAB>  <TAB> ) <TAB>  <TAB> for start, end in execute_sql(self.ext_sql % sql_expr, [file_id, escaped_arg]): <TAB>  <TAB>  <TAB> # Nones used to occur in the DB. Is this still true? <MASK> yield start, end, []",if start and end :,152
"def draw(self): <TAB> """"""draw the block"""""" <TAB> for i in range(self.x): <TAB>  <TAB> for j in range(self.x): <TAB>  <TAB>  <TAB> c = self.get(i, j) <MASK> Colors.images[c].blit( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> (i + self.pos.x) * SQUARE_SIZE, (j + self.pos.y) * SQUARE_SIZE <TAB>  <TAB>  <TAB>  <TAB> )",if c :,113
"def _find_dir(d): <TAB> dir = os.getcwd() <TAB> last = """" <TAB> while dir != last: <TAB>  <TAB> target_dir = os.path.join(dir, d) <MASK> return target_dir <TAB>  <TAB> last = dir <TAB>  <TAB> (dir, tail) = os.path.split(dir) <TAB> return None",if os . path . exists ( target_dir ) :,95
"def remove_trailing_spaces(self): <TAB> """"""Remove trailing spaces"""""" <TAB> cursor = self.textCursor() <TAB> cursor.beginEditBlock() <TAB> cursor.movePosition(QTextCursor.Start) <TAB> while True: <TAB>  <TAB> cursor.movePosition(QTextCursor.EndOfBlock) <TAB>  <TAB> text = to_text_string(cursor.block().text()) <TAB>  <TAB> length = len(text) - len(text.rstrip()) <MASK> cursor.movePosition(QTextCursor.Left, QTextCursor.KeepAnchor, length) <TAB>  <TAB>  <TAB> cursor.removeSelectedText() <TAB>  <TAB> if cursor.atEnd(): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> cursor.movePosition(QTextCursor.NextBlock) <TAB> cursor.endEditBlock()",if length > 0 :,181
"def send_messages(self, email_messages): <TAB> """"""Write all messages to the stream in a thread-safe way."""""" <TAB> if not email_messages: <TAB>  <TAB> return <TAB> with self._lock: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> stream_created = self.open() <TAB>  <TAB>  <TAB> for message in email_messages: <TAB>  <TAB>  <TAB>  <TAB> self.stream.write(""%s\n"" % message.message().as_string()) <TAB>  <TAB>  <TAB>  <TAB> self.stream.write(""-"" * 79) <TAB>  <TAB>  <TAB>  <TAB> self.stream.write(""\n"") <TAB>  <TAB>  <TAB>  <TAB> self.stream.flush()  # flush after each message <TAB>  <TAB>  <TAB> if stream_created: <TAB>  <TAB>  <TAB>  <TAB> self.close() <TAB>  <TAB> except: <MASK> raise <TAB> return len(email_messages)",if not self . fail_silently :,193
"def get_source_files(self): <TAB> self.check_library_list(self.libraries) <TAB> filenames = [] <TAB> for (lib_name, build_info) in self.libraries: <TAB>  <TAB> sources = build_info.get(""sources"") <MASK> raise DistutilsSetupError( <TAB>  <TAB>  <TAB>  <TAB> ""in 'libraries' option (library '%s'), "" <TAB>  <TAB>  <TAB>  <TAB> ""'sources' must be present and must be "" <TAB>  <TAB>  <TAB>  <TAB> ""a list of source filenames"" % lib_name <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> filenames.extend(sources) <TAB> return filenames","if sources is None or not isinstance ( sources , ( list , tuple ) ) :",153
"def put(self): <TAB> group_name = request.json.get(""group_name"") <TAB> action = request.json.get(""action"", ""activate"") <TAB> for _id in context.application.data_manager.id_map: <TAB>  <TAB> group = context.application.data_manager.id_map.get(_id) <MASK> if action == ""activate"": <TAB>  <TAB>  <TAB>  <TAB> context.application.data_manager.deactivate() <TAB>  <TAB>  <TAB>  <TAB> context.application.data_manager.activate(group[""id""]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> context.application.data_manager.deactivate() <TAB>  <TAB>  <TAB> return context.make_ok_response() <TAB> return context.make_fail_response(f""Group not found. name={group_name}"")","if group [ ""name"" ] == group_name :",192
def close(self) -> None: <TAB> with self._lock: <TAB>  <TAB> if self._closed: <TAB>  <TAB>  <TAB> return <MASK> self._sock.shutdown(SHUT_WR) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._sock.shutdown() <TAB>  <TAB> self._sock.close() <TAB>  <TAB> self._closed = True,"if isinstance ( self . _sock , socket ) :",87
"def _xrange_eqv_range(r, o): <TAB> Assert(len(r) == len(o)) <TAB> for i in range(len(r)): <TAB>  <TAB> Assert(r[i] == o[i]) <MASK> AssertError(IndexError, lambda: r[1 - i]) <TAB>  <TAB>  <TAB> AssertError(IndexError, lambda: o[1 - i]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> Assert(r[1 - i] == o[1 - i])",if ( 1 - i ) == len ( r ) :,124
"def main(): <TAB> filename = sys.argv[1] <TAB> prefix = sys.argv[2] <TAB> size = int(float(sys.argv[3]))  # e.g. 1e9 <TAB> division = -1 <TAB> for n, record in enumerate(screed.open(filename)): <TAB>  <TAB> if n % 100000 == 0: <TAB>  <TAB>  <TAB> print(""..."", n) <MASK> division += 1 <TAB>  <TAB>  <TAB> new_name = ""%s.%04d.fa"" % (prefix, division) <TAB>  <TAB>  <TAB> print(""opening"", new_name) <TAB>  <TAB>  <TAB> fp = open(new_name, ""w"") <TAB>  <TAB> fp.write("">%s\n%s\n"" % (record[""name""], record[""sequence""]))",if n % size == 0 :,180
"def _get_patterns(self): <TAB> self.allowed_cube_suffix = [] <TAB> self.allowed_cube_prefix = [] <TAB> self.denied_cube_suffix = [] <TAB> self.denied_cube_prefix = [] <TAB> for cube in self.allowed_cubes: <MASK> self.allowed_cube_suffix.append(cube[1:]) <TAB>  <TAB> if cube.endswith(""*""): <TAB>  <TAB>  <TAB> self.allowed_cube_prefix.append(cube[:-1]) <TAB> for cube in self.denied_cubes: <TAB>  <TAB> if cube.startswith(""*""): <TAB>  <TAB>  <TAB> self.denied_cube_suffix.append(cube[1:]) <TAB>  <TAB> if cube.endswith(""*""): <TAB>  <TAB>  <TAB> self.denied_cube_prefix.append(cube[:-1])","if cube . startswith ( ""*"" ) :",181
"def set_state(chain, state): <TAB> assert isinstance(chain, (chainer.Chain, chainer.ChainList)) <TAB> for l, s in zip(chain.children(), state): <TAB>  <TAB> if isinstance(l, chainer.links.LSTM): <TAB>  <TAB>  <TAB> c, h = s <TAB>  <TAB>  <TAB> # LSTM.set_state doesn't accept None state <TAB>  <TAB>  <TAB> if c is not None: <TAB>  <TAB>  <TAB>  <TAB> l.set_state(c, h) <MASK> l.set_state(s) <TAB>  <TAB> elif isinstance(l, (chainer.Chain, chainer.ChainList)): <TAB>  <TAB>  <TAB> set_state(l, s) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert s is None","elif isinstance ( l , Recurrent ) :",177
"def listfiles(self, line): <TAB> if ""Begin file list"" in line: <TAB>  <TAB> self.sdlisting = 1 <TAB> elif ""End file list"" in line: <TAB>  <TAB> self.sdlisting = 0 <TAB>  <TAB> self.recvlisteners.remove(self.listfiles) <MASK> self.log(_(""Files on SD card:"")) <TAB>  <TAB>  <TAB> self.log(""\n"".join(self.sdfiles)) <TAB> elif self.sdlisting: <TAB>  <TAB> self.sdfiles.append(re.sub("" \d+$"", """", line.strip().lower()))",if self . sdlisting_echo :,137
"def test_loc_is_stochastic_parameter(self): <TAB> param = iap.Normal(iap.Choice([-100, 100]), 1) <TAB> seen = [0, 0] <TAB> for _ in sm.xrange(1000): <TAB>  <TAB> samples = param.draw_samples((100,)) <TAB>  <TAB> exp = np.mean(samples) <TAB>  <TAB> if -100 - 10 < exp < -100 + 10: <TAB>  <TAB>  <TAB> seen[0] += 1 <MASK> seen[1] += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert False <TAB> assert 500 - 100 < seen[0] < 500 + 100 <TAB> assert 500 - 100 < seen[1] < 500 + 100",elif 100 - 10 < exp < 100 + 10 :,167
"def write_timeout(self, timeout): <TAB> """"""Change timeout setting."""""" <TAB> if timeout is not None: <MASK> raise ValueError(""Not a valid timeout: {!r}"".format(timeout)) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> timeout + 1  # test if it's a number, will throw a TypeError if not... <TAB>  <TAB> except TypeError: <TAB>  <TAB>  <TAB> raise ValueError(""Not a valid timeout: {!r}"".format(timeout)) <TAB> self._write_timeout = timeout <TAB> if self.is_open: <TAB>  <TAB> self._reconfigure_port()",if timeout < 0 :,133
"def format_query_field(k, v): <TAB> if k in [""nsfw"", ""self""]: <TAB>  <TAB> # even though documentation lists ""no"" and ""yes"" <TAB>  <TAB> # as possible values, in reality they don't work <MASK> raise PRAWException( <TAB>  <TAB>  <TAB>  <TAB> ""Invalid value for the extra"" <TAB>  <TAB>  <TAB>  <TAB> ""field {}. Only '0' and '1' are"" <TAB>  <TAB>  <TAB>  <TAB> ""valid values."".format(k) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return ""{}:{}"".format(k, v) <TAB> return ""{}:'{}'"".format(k, v)","if v not in [ 0 , 1 , ""0"" , ""1"" ] :",151
"def gist_fetch(self, gist, fname=None): <TAB> try: <TAB>  <TAB> gist = self.gh.gist(self._format_gist(gist)) <TAB> except Exception as err: <TAB>  <TAB> raise ResourceNotFoundError(""Error while fetching gist"") from err <TAB> if not gist: <TAB>  <TAB> raise ResourceNotFoundError(""Could not find gist"") <TAB> if gist.files == 1 and not fname: <TAB>  <TAB> gist_file = list(gist.iter_files())[0] <TAB> else: <TAB>  <TAB> for gist_file in gist.iter_files(): <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ResourceNotFoundError(""Could not find file within gist."") <TAB> return gist_file.content",if gist_file . filename == fname :,187
"def finalize_invitation(node, contributor, auth, email_template=""default""): <TAB> try: <TAB>  <TAB> record = contributor.get_unclaimed_record(node._primary_key) <TAB> except ValueError: <TAB>  <TAB> pass <TAB> else: <MASK> send_claim_email( <TAB>  <TAB>  <TAB>  <TAB> record[""email""], <TAB>  <TAB>  <TAB>  <TAB> contributor, <TAB>  <TAB>  <TAB>  <TAB> node, <TAB>  <TAB>  <TAB>  <TAB> notify=True, <TAB>  <TAB>  <TAB>  <TAB> email_template=email_template, <TAB>  <TAB>  <TAB> )","if record [ ""email"" ] :",130
"def get_concatenated_files(directory, suffix, init): <TAB> paths = [Path(directory, f) for f in listdir if f.endswith(suffix)] <TAB> concatenated = """".join(path.read_text() for path in paths) <TAB> result = set() <TAB> for x in concatenated.split(""\n""): <MASK> address = int(x.split("":"")[0], 16) <TAB>  <TAB>  <TAB> pc = int(x.split("":"")[1].split("" "")[0], 16) <TAB>  <TAB>  <TAB> at_init = ""*"" in x <TAB>  <TAB>  <TAB> if at_init == init: <TAB>  <TAB>  <TAB>  <TAB> result.add(pc) <TAB> return result","if "":"" in x :",153
"def expand_languages(languages=None): <TAB> # Get some reasonable defaults for arguments that were not supplied <TAB> if languages is None: <TAB>  <TAB> languages = [] <TAB>  <TAB> for envar in (""LANGUAGE"", ""LC_ALL"", ""LC_MESSAGES"", ""LANG""): <TAB>  <TAB>  <TAB> val = os.environ.get(envar) <MASK> languages = val.split("":"") <TAB>  <TAB>  <TAB>  <TAB> break <TAB> # if 'C' not in languages: <TAB> #   languages.append('C') <TAB> # now normalize and expand the languages <TAB> nelangs = [] <TAB> for lang in languages: <TAB>  <TAB> for nelang in _expand_lang(lang): <TAB>  <TAB>  <TAB> if nelang not in nelangs: <TAB>  <TAB>  <TAB>  <TAB> nelangs.append(nelang) <TAB> return nelangs",if val :,195
"def total_time(self): <TAB> total_time = 0 <TAB> tt = self.soup.find(""span"", {""data-epi-property-name"": ""RecipeTime""}) <TAB> if tt: <TAB>  <TAB> tt1 = normalize_string(tt.get_text()) <TAB>  <TAB> tt2 = get_minutes(tt1) <MASK> total_time = tt1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> total_time = tt2 <TAB> return total_time",if tt1 and ( tt2 == 0 ) :,120
"def parseString(self, s): <TAB> s = self.remaining + s <TAB> try: <TAB>  <TAB> while s or self.state: <MASK> raise IllegalClientResponse(""Invalid Argument"") <TAB>  <TAB>  <TAB> # print 'Entering state_' + self.state[-1] + ' with', repr(s) <TAB>  <TAB>  <TAB> state = self.state.pop() <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> used = getattr(self, ""state_"" + state)(s) <TAB>  <TAB>  <TAB> except BaseException: <TAB>  <TAB>  <TAB>  <TAB> self.state.append(state) <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> # print state, 'consumed', repr(s[:used]) <TAB>  <TAB>  <TAB>  <TAB> s = s[used:] <TAB> finally: <TAB>  <TAB> self.remaining = s",if not self . state :,190
"def set_missing_values(self): <TAB> for data in self.taxes: <MASK> data.rate = frappe.db.get_value(""Account"", data.account_head, ""tax_rate"")","if data . charge_type == ""On Net Total"" and flt ( data . rate ) == 0.0 :",78
"def check_for_node(nodes): <TAB> for node in nodes: <MASK> self.log.debug( <TAB>  <TAB>  <TAB>  <TAB> ""%s successfully resolved as %s"" % (guid.encode(""hex""), node) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return node <TAB> self.log.debug(""%s was not found in the dht"" % guid.encode(""hex"")) <TAB> return None",if node . id == node_to_find . id :,105
"def get_call_args(f, *args, **kwargs): <TAB> sig = signature(f) <TAB> arguments = sig.bind(*args, **kwargs).arguments <TAB> # apply defaults: <TAB> new_arguments = [] <TAB> for name, param in sig.parameters.items(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> new_arguments.append((name, arguments[name])) <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> if param.default is not param.empty: <TAB>  <TAB>  <TAB>  <TAB> val = param.default <MASK> val = () <TAB>  <TAB>  <TAB> elif param.kind is param.VAR_KEYWORD: <TAB>  <TAB>  <TAB>  <TAB> val = {} <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> new_arguments.append((name, val)) <TAB> return collections.OrderedDict(new_arguments)",elif param . kind is param . VAR_POSITIONAL :,198
"def __call__(self, value): <TAB> try: <TAB>  <TAB> value = super(NewType, self).__call__(value) <TAB>  <TAB> return function(value) <TAB> except Exception as exception: <TAB>  <TAB> for take_exception, rewrite in exception_handlers.items(): <MASK> if isinstance(rewrite, str): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(rewrite) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise rewrite(value) <TAB>  <TAB> if error_text: <TAB>  <TAB>  <TAB> raise ValueError(error_text) <TAB>  <TAB> raise exception","if isinstance ( exception , take_exception ) :",137
"def remove_mounted_resources(resource_list): <TAB> if not isinstance(resource_list, list): <TAB>  <TAB> return resource_list <TAB> resources = deepcopy(resource_list) <TAB> for resource in resources: <MASK> for key, mounted_resource_type in resource[ <TAB>  <TAB>  <TAB>  <TAB> ""terraform-compliance.mounted_resources"" <TAB>  <TAB>  <TAB> ].items(): <TAB>  <TAB>  <TAB>  <TAB> if mounted_resource_type in resource[""values""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> del resource[""values""][mounted_resource_type] <TAB> return resources","if ""terraform-compliance.mounted_resources"" in resource :",151
"def run_instance(interface, options): <TAB> print(""setting function inputs"") <TAB> for input_name, _ in list(interface.inputs.items()): <MASK> value = getattr(options, input_name) <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> setattr(interface.inputs, input_name, value) <TAB>  <TAB>  <TAB> except ValueError as e: <TAB>  <TAB>  <TAB>  <TAB> print(""Error when setting the value of %s: '%s'"" % (input_name, str(e))) <TAB> print(interface.inputs) <TAB> res = interface.run() <TAB> print(res.outputs)","if getattr ( options , input_name ) is not None :",150
"def convert_command(args): <TAB> if len(args.files) >= 2: <TAB>  <TAB> output = args.files.pop() <TAB>  <TAB> resolve_file_format(args, args.files, output) <TAB>  <TAB> if args.import_format not in nnabla.utils.converter.formats.import_name: <TAB>  <TAB>  <TAB> print(""Import format ({}) is not supported."".format(args.import_format)) <TAB>  <TAB>  <TAB> return False <MASK> print(""Export format ({}) is not supported."".format(args.export_format)) <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> nnabla.utils.converter.convert_files(args, args.files, output) <TAB>  <TAB> return True <TAB> print(""Input and Output arg is mandatory."") <TAB> return False",if args . export_format not in nnabla . utils . converter . formats . export_name :,195
"def _reschedule_deferred(self): <TAB> picked = None <TAB> try: <TAB>  <TAB> for deferred in self.deferred_requests: <MASK> picked = deferred <TAB>  <TAB>  <TAB>  <TAB> self._schedule_request(deferred) <TAB>  <TAB>  <TAB>  <TAB> break <TAB> except: <TAB>  <TAB> logging.exception(""Failed to re-schedule a deferred task: {}"".format(picked)) <TAB>  <TAB> return <TAB> self.deferred_requests.remove(picked)",if not self . _is_clashing ( deferred ) :,114
"def _add_tuple_parameter(self, children, arg): <TAB> children.append(""("") <TAB> for index, token in enumerate(arg): <MASK> children.append("","") <TAB>  <TAB> if isinstance(token, (list, tuple)): <TAB>  <TAB>  <TAB> self._add_tuple_parameter(children, token) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> children.append(token) <TAB> children.append("")"")",if index > 0 :,98
"def test_distinct(self): <TAB> class Doc(Document): <TAB>  <TAB> structure = {""foo"": unicode, ""bla"": int} <TAB> self.connection.register([Doc]) <TAB> for i in range(15): <MASK> foo = u""blo"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> foo = u""bla"" <TAB>  <TAB> doc = self.col.Doc(doc={""foo"": foo, ""bla"": i}) <TAB>  <TAB> doc.save() <TAB> assert self.col.find().distinct(""foo"") == [""blo"", ""bla""] <TAB> assert self.col.find().distinct(""bla"") == range(15)",if i % 2 == 0 :,158
"def whole(self, mapper, x, y, what): <TAB> side = self.compute_side(x, y) <TAB> # 8-way dpad presses only one button at time, so only one index <TAB> # in dpad_state is used. <TAB> if side != self.dpad_state[0]: <TAB>  <TAB> if self.dpad_state[0] is not None: <TAB>  <TAB>  <TAB> self.actions[self.dpad_state[0]].button_release(mapper) <MASK> self.actions[side].button_press(mapper) <TAB>  <TAB> self.dpad_state[0] = side",if side is not None :,147
"def check_args(self, function, supported_arguments): <TAB> argspec = inspect.getargspec(function) <TAB> function_arguments = dict(zip(argspec[0][1:], argspec[3])) <TAB> for argument, default in function_arguments.items(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.assertEqual( <TAB>  <TAB>  <TAB>  <TAB> supported_arguments[argument], <TAB>  <TAB>  <TAB>  <TAB> default, <TAB>  <TAB>  <TAB>  <TAB> msg=""Argument '{0}' has wrong default"".format(argument), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> self.fail(""Found unsupported or new argument '%s'"" % argument) <TAB> for argument, default in supported_arguments.items(): <MASK> self.fail(""Supported argument '{0}' fails"".format(argument))",if not argument in function_arguments :,180
"def get_gpu(self): <TAB> res = self.shell(""dumpsys SurfaceFlinger"") <TAB> pat = re.compile(r""GLES:\s+(.*)"") <TAB> m = pat.search(res) <TAB> if not m: <TAB>  <TAB> return None <TAB> _list = m.group(1).split("","") <TAB> gpuModel = """" <TAB> opengl = """" <TAB> if len(_list) > 0: <TAB>  <TAB> gpuModel = _list[1].strip() <TAB> if len(_list) > 1: <TAB>  <TAB> m2 = re.search(r""(\S+\s+\S+\s+\S+).*"", _list[2]) <MASK> opengl = m2.group(1) <TAB> return dict(gpuModel=gpuModel, opengl=opengl)",if m2 :,186
"def process(self, formdata=None, obj=None, **kwargs): <TAB> if self.is_submitted(): <TAB>  <TAB> if formdata is None: <TAB>  <TAB>  <TAB> formdata = request.form <TAB>  <TAB> # ensure csrf validation occurs ONLY when formdata is passed <TAB>  <TAB> # in case ""csrf"" is the only field in the form <MASK> self.csrf_is_valid = False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.csrf_is_valid = None <TAB> super(Form, self).process(formdata, obj, **kwargs)",if not formdata and not request . files :,136
"def _assert_expected_object_types_for_predicates(graph, predicates, types): <TAB> for s, p, o in graph: <MASK> someTrue = [isinstance(o, t) for t in types] <TAB>  <TAB>  <TAB> assert ( <TAB>  <TAB>  <TAB>  <TAB> True in someTrue <TAB>  <TAB>  <TAB> ), ""Bad type %s for object when predicate is <%s>."" % (type(o), p)",if p in predicates :,100
"def edges_eq(): <TAB> for edge in self.edges(): <MASK> return False <TAB>  <TAB> if self.edge_label(edge) != other.edge_label(edge): <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> if not attrs_eq(self.edge_attributes(edge), other.edge_attributes(edge)): <TAB>  <TAB>  <TAB> return False <TAB> return True",if self . edge_weight ( edge ) != other . edge_weight ( edge ) :,104
"def _merge_dicts_(a, b): <TAB> for key in set(a.keys()).union(b.keys()): <TAB>  <TAB> if key in a and key in b: <MASK> yield (key, dict(_merge_dicts_(a[key], b[key]))) <TAB>  <TAB>  <TAB> elif b[key] is not None: <TAB>  <TAB>  <TAB>  <TAB> yield (key, b[key]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield (key, a[key]) <TAB>  <TAB> elif key in a: <TAB>  <TAB>  <TAB> yield (key, a[key]) <TAB>  <TAB> elif b[key] is not None: <TAB>  <TAB>  <TAB> yield (key, b[key])","if isinstance ( a [ key ] , dict ) and isinstance ( b [ key ] , dict ) :",174
"def get_device_codename(): <TAB> """"""Return the device codename."""""" <TAB> serial = environment.get_value(""ANDROID_SERIAL"") <TAB> devices_output = adb.run_command([""devices"", ""-l""]) <TAB> serial_pattern = r""(^|\s){serial}\s"".format(serial=re.escape(serial)) <TAB> serial_regex = re.compile(serial_pattern) <TAB> for line in devices_output.splitlines(): <TAB>  <TAB> values = line.strip().split() <TAB>  <TAB> if not serial_regex.search(line): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for value in values: <TAB>  <TAB>  <TAB> if not value.startswith(""device:""): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> device_codename = value.split("":"")[-1] <MASK> return device_codename <TAB> # Unable to get code name. <TAB> return """"",if device_codename :,198
"def for_dataset_collection(dataset_collection, collection_type_description): <TAB> children = [] <TAB> for element in dataset_collection.elements: <MASK> child_collection = element.child_collection <TAB>  <TAB>  <TAB> subcollection_type_description = ( <TAB>  <TAB>  <TAB>  <TAB> collection_type_description.subcollection_type_description() <TAB>  <TAB>  <TAB> )  # Type description of children <TAB>  <TAB>  <TAB> tree = Tree.for_dataset_collection( <TAB>  <TAB>  <TAB>  <TAB> child_collection, <TAB>  <TAB>  <TAB>  <TAB> collection_type_description=subcollection_type_description, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> children.append((element.element_identifier, tree)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> children.append((element.element_identifier, leaf)) <TAB> return Tree(children, collection_type_description)",if collection_type_description . has_subcollections ( ) :,199
"def user_lookup(request): <TAB> """"""Returns partial username matches"""""" <TAB> userlist = [] <TAB> if request.is_ajax(): <TAB>  <TAB> user = request.GET.get(""user"", """") <MASK> matches = User.objects.filter(username__istartswith=user) <TAB>  <TAB>  <TAB> for match in matches: <TAB>  <TAB>  <TAB>  <TAB> userlist.append({""label"": match.username}) <TAB> data = json.dumps(userlist) <TAB> return HttpResponse(data, content_type=""application/json; charset=utf-8"")",if user :,126
"def pair_process(item, strict_one=True): <TAB> if hasattr(item, ""__iter__""): <TAB>  <TAB> for i in item: <MASK> if strict_one: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""number in item {} must be the same"".format(item)) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> print( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""IMPORTANT WARNING: number in item {} must be the same"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> item <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return item[0] <TAB> return item",if i != item [ 0 ] :,149
"def get_searchable_content(self, value): <TAB> # Return the display value as the searchable value <TAB> content = [] <TAB> text_value = force_str(value) <TAB> for k, v in self.field.choices: <TAB>  <TAB> if isinstance(v, (list, tuple)): <TAB>  <TAB>  <TAB> # This is an optgroup, so look inside the group for options <TAB>  <TAB>  <TAB> for k2, v2 in v: <TAB>  <TAB>  <TAB>  <TAB> if value == k2 or text_value == force_str(k2): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> content.append(force_str(k)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> content.append(force_str(v2)) <TAB>  <TAB> else: <MASK> content.append(force_str(v)) <TAB> return content",if value == k or text_value == force_str ( k ) :,194
"def clean(self): <TAB> if self.id: <TAB>  <TAB> # We're only concerned with edits - self.guid isn't set at this <TAB>  <TAB> # point for new instances anyway. <TAB>  <TAB> choices = list(version.version for version in self.addon_versions) <MASK> raise ValidationError({""min_version"": _(""Invalid version"")}) <TAB>  <TAB> if self.max_version not in choices + [self.MAX]: <TAB>  <TAB>  <TAB> raise ValidationError({""max_version"": _(""Invalid version"")}) <TAB> if self.min_version > self.max_version: <TAB>  <TAB> raise ValidationError(_(""Min version can not be greater than Max version""))",if self . min_version not in choices + [ self . MIN ] :,159
"def add_paos_headers(self, headers=None): <TAB> if headers: <TAB>  <TAB> headers = set_list2dict(headers) <TAB>  <TAB> headers[""PAOS""] = PAOS_HEADER_INFO <TAB>  <TAB> if ""Accept"" in headers: <TAB>  <TAB>  <TAB> headers[""Accept""] += "";%s"" % MIME_PAOS <MASK> headers[""Accept""] = headers[""accept""] <TAB>  <TAB>  <TAB> headers[""Accept""] += "";%s"" % MIME_PAOS <TAB>  <TAB>  <TAB> del headers[""accept""] <TAB>  <TAB> headers = dict2set_list(headers) <TAB> else: <TAB>  <TAB> headers = [(""Accept"", ""text/html; %s"" % MIME_PAOS), (""PAOS"", PAOS_HEADER_INFO)] <TAB> return headers","elif ""accept"" in headers :",180
"def onCreate(tag, key): <TAB> global controllers <TAB> c = key.get(""c"") <TAB> if c: <TAB>  <TAB> h = c.hash() <TAB>  <TAB> vc = controllers.get(h) <MASK> controllers[h] = vc = ValueSpaceController(c)",if not vc :,78
"def validate_tags(tags): <TAB> proper_tags = {} <TAB> if len(tags) > 50: <TAB>  <TAB> raise TooManyTags(tags) <TAB> for tag in tags: <TAB>  <TAB> # Validate the Key: <TAB>  <TAB> validate_tag_key(tag[""Key""]) <TAB>  <TAB> check_tag_duplicate(proper_tags, tag[""Key""]) <TAB>  <TAB> # Validate the Value: <MASK> raise TagValueTooBig(tag[""Value""]) <TAB>  <TAB> proper_tags[tag[""Key""]] = tag[""Value""] <TAB> return proper_tags","if len ( tag [ ""Value"" ] ) > 256 :",137
"def main(): <TAB> args = parser.parse_args() <TAB> print_arguments(args) <TAB> check_gpu(args.use_gpu) <TAB> if args.profile: <MASK> with profiler.cuda_profiler(""cuda_profiler.txt"", ""csv"") as nvprof: <TAB>  <TAB>  <TAB>  <TAB> inference(args) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> with profiler.profiler(""CPU"", sorted_key=""total"") as cpuprof: <TAB>  <TAB>  <TAB>  <TAB> inference(args) <TAB> else: <TAB>  <TAB> inference(args)",if args . use_gpu :,134
"def test_list_sizes_valid_regions(self): <TAB> unsupported_regions = list() <TAB> for region in VALID_EC2_REGIONS: <TAB>  <TAB> no_pricing = region in [""cn-north-1""] <TAB>  <TAB> driver = EC2NodeDriver(*EC2_PARAMS, **{""region"": region}) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> sizes = driver.list_sizes() <MASK> self.assertTrue(all([s.price is None for s in sizes])) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> unsupported_regions.append(region) <TAB> if unsupported_regions: <TAB>  <TAB> self.fail(""Cannot list sizes from ec2 regions: %s"" % unsupported_regions)",if no_pricing :,167
"def _validate_properties( <TAB> self, properties: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]: <TAB> """"""Validates the type and size of the properties"""""" <TAB> for k, v in properties.items(): <MASK> raise ValueError(""the number of properties must equal the number of points"") <TAB>  <TAB> # ensure the property values are a numpy array <TAB>  <TAB> if type(v) != np.ndarray: <TAB>  <TAB>  <TAB> properties[k] = np.asarray(v) <TAB> return properties",if len ( v ) != len ( self . data ) :,131
"def refresh_from_db(self, using=None, fields=None, **kwargs): <TAB> # Reloads all deferred fields if any of the fields is deferred. <TAB> if fields is not None: <TAB>  <TAB> fields = set(fields) <TAB>  <TAB> deferred_fields = self.get_deferred_fields() <MASK> fields = fields.union(deferred_fields) <TAB> super(RefreshPrimaryProxy, self).refresh_from_db(using, fields, **kwargs)",if fields . intersection ( deferred_fields ) :,118
"def iterLinkedSocketsWithInfo(socket, node, nodeByID): <TAB> socketID = ((node.id_data.name, node.name), socket.is_output, socket.identifier) <TAB> linkedIDs = _forestData.linkedSockets[socketID] <TAB> for linkedID in linkedIDs: <TAB>  <TAB> linkedIdentifier = linkedID[2] <TAB>  <TAB> linkedNode = nodeByID[linkedID[0]] <TAB>  <TAB> sockets = linkedNode.outputs if linkedID[1] else linkedNode.inputs <TAB>  <TAB> for socket in sockets: <MASK> yield socket",if socket . identifier == linkedIdentifier :,146
"def func(img): <TAB> try: <TAB>  <TAB> h, w, _ = img.shape <TAB>  <TAB> if h > w: <TAB>  <TAB>  <TAB> off = (h - w) // 2 <TAB>  <TAB>  <TAB> if off > 0: <TAB>  <TAB>  <TAB>  <TAB> img = img[off:-off, :, :] <MASK> off = (w - h) // 2 <TAB>  <TAB>  <TAB> if off > 0: <TAB>  <TAB>  <TAB>  <TAB> img = img[:, off:-off, :] <TAB>  <TAB> img = cv2.resize(img, (256, 256)) <TAB>  <TAB> return img <TAB> except Exception: <TAB>  <TAB> return None",if w > h :,143
"def open_func(filename): <TAB> if not use_cache or filename not in cached_files: <TAB>  <TAB> output = self.run( <TAB>  <TAB>  <TAB> ""cat '%s'"" % filename, stdout_tee=open(""/dev/null"", ""w"") <TAB>  <TAB> ).stdout <TAB>  <TAB> fd = cStringIO.StringIO(output) <MASK> return fd <TAB>  <TAB> cached_files[filename] = fd <TAB> else: <TAB>  <TAB> cached_files[filename].seek(0) <TAB> return cached_files[filename]",if not use_cache :,125
"def run(self, paths=[]): <TAB> items = [] <TAB> for item in SideBarSelection(paths).getSelectedItems(): <TAB>  <TAB> items.append(item.pathRelativeFromView()) <TAB> if len(items) > 0: <TAB>  <TAB> sublime.set_clipboard(""\n"".join(items)) <MASK> sublime.status_message(""Items copied"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sublime.status_message(""Item copied"")",if len ( items ) > 1 :,116
"def __setRowEnabledState(self, enabledPlugs, enabled): <TAB> self.__setPlugValues(enabledPlugs, enabled) <TAB> # Clear the row name column selection if rows have been disabled. <TAB> # They don't show up in selectionModel.selection(). <TAB> if not enabled: <TAB>  <TAB> selectionModel = self._qtWidget().selectionModel() <TAB>  <TAB> nameColumnIndex = self._qtWidget().model().index(0, 0) <TAB>  <TAB> flags = QtCore.QItemSelectionModel.Columns | QtCore.QItemSelectionModel.Deselect <TAB>  <TAB> selectionModel.select(nameColumnIndex, flags) <MASK> selectionModel.clearCurrentIndex()",if selectionModel . currentIndex ( ) . column ( ) == 0 :,168
"def ensure_object( <TAB> self, data_block, name: str, object_template: bpy.types.Object = None): <TAB> """"""Add object if it does not exist, if object_template is given new object will be copied from it"""""" <TAB> if not self.obj: <TAB>  <TAB> # it looks like it means only that the property group item was created newly <MASK> self.obj = object_template.copy() <TAB>  <TAB>  <TAB> self.obj.data = data_block <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.obj = bpy.data.objects.new(name=name, object_data=data_block) <TAB> else: <TAB>  <TAB> # in case if data block was changed <TAB>  <TAB> self.obj.data = data_block",if object_template :,178
"def mSATURDAY( <TAB> self,): <TAB> try: <TAB>  <TAB> _type = SATURDAY <TAB>  <TAB> _channel = DEFAULT_CHANNEL <TAB>  <TAB> pass <TAB>  <TAB> self.match(""sat"") <TAB>  <TAB> alt11 = 2 <TAB>  <TAB> LA11_0 = self.input.LA(1) <MASK> alt11 = 1 <TAB>  <TAB> if alt11 == 1: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> self.match(""urday"") <TAB>  <TAB> self._state.type = _type <TAB>  <TAB> self._state.channel = _channel <TAB> finally: <TAB>  <TAB> pass",if LA11_0 == 117 :,148
"def get_dewies_or_error(argument: str, lbc: str, positive_value=False): <TAB> try: <TAB>  <TAB> dewies = lbc_to_dewies(lbc) <MASK> raise ValueError(f""'{argument}' value must be greater than 0.0"") <TAB>  <TAB> return dewies <TAB> except ValueError as e: <TAB>  <TAB> raise ValueError(f""Invalid value for '{argument}': {e.args[0]}"")",if positive_value and dewies <= 0 :,120
"def attr(**kw): <TAB> kw = list(iteritems(kw)) <TAB> kw.sort() <TAB> parts = [] <TAB> for name, value in kw: <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB> continue <MASK> name = name[:-1] <TAB>  <TAB> parts.append('%s=""%s""' % (html_quote(name), html_quote(value))) <TAB> return html("" "".join(parts))","if name . endswith ( ""_"" ) :",102
"def get_port(node): <TAB> if len(node) > 1: <TAB>  <TAB> if isinstance(node[1], ParseResults): <TAB>  <TAB>  <TAB> if len(node[1][0]) == 2: <MASK> return node[1][0][1] <TAB> return None","if node [ 1 ] [ 0 ] [ 0 ] == "":"" :",82
"def get_last_traded_prices(cls, trading_pairs: List[str]) -> Dict[str, float]: <TAB> results = dict() <TAB> async with aiohttp.ClientSession() as client: <TAB>  <TAB> resp = await client.get(Constants.GET_EXCHANGE_MARKETS_URL) <TAB>  <TAB> resp_json = await resp.json() <TAB>  <TAB> for record in resp_json: <TAB>  <TAB>  <TAB> trading_pair = f""{record['base_currency']}-{record['quoted_currency']}"" <MASK> results[trading_pair] = float(record[""last_traded_price""]) <TAB> return results",if trading_pair in trading_pairs :,161
"def get_container(self, container, prefix=None, full_listing=None): <TAB> container_entries = self.containers[container] <TAB> objs = [] <TAB> for path, data in list(container_entries.items()): <MASK> objs.append( <TAB>  <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""name"": path, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""bytes"": len(data[""content""]), <TAB>  <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB> ) <TAB> return {}, objs",if not prefix or path . startswith ( prefix ) :,121
"def test_csv_retweet_hashtag(): <TAB> toplevel_hashtags = 0 <TAB> rt_hashtags = 0 <TAB> for tweet in T.search(""#auspol filter:nativeretweets filter:hashtags""): <TAB>  <TAB> hashtag_rendered = json2csv.hashtags(tweet) <TAB>  <TAB> if hashtag_rendered: <TAB>  <TAB>  <TAB> hashtags = hashtag_rendered.split("" "") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> hashtags = [] <MASK> break <TAB> else: <TAB>  <TAB> assert False","if len ( hashtags ) > len ( tweet [ ""entities"" ] [ ""hashtags"" ] ) :",153
"def __del__(self): <TAB> if self.key_handle: <MASK> res = self._lib.CryptDestroyKey(self.key_handle) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> res = self._lib.BCryptDestroyKey(self.key_handle) <TAB>  <TAB> handle_error(res) <TAB>  <TAB> self.key_handle = None <TAB> if self.context_handle and _backend == ""winlegacy"": <TAB>  <TAB> close_context_handle(self.context_handle) <TAB>  <TAB> self.context_handle = None <TAB> self._lib = None","if _backend == ""winlegacy"" :",140
"def parse_postfix(self, node): <TAB> while 1: <TAB>  <TAB> token_type = self.stream.current.type <MASK> node = self.parse_subscript(node) <TAB>  <TAB> elif token_type == ""lparen"": <TAB>  <TAB>  <TAB> node = self.parse_call(node) <TAB>  <TAB> elif token_type == ""pipe"": <TAB>  <TAB>  <TAB> node = self.parse_filter(node) <TAB>  <TAB> elif token_type == ""name"" and self.stream.current.value == ""is"": <TAB>  <TAB>  <TAB> node = self.parse_test(node) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> return node","if token_type == ""dot"" or token_type == ""lbracket"" :",163
"def init_weights(self): <TAB> """"""Initialize model weights."""""" <TAB> for _, m in self.deconv_layers.named_modules(): <TAB>  <TAB> if isinstance(m, nn.ConvTranspose2d): <TAB>  <TAB>  <TAB> normal_init(m, std=0.001) <TAB>  <TAB> elif isinstance(m, nn.BatchNorm2d): <TAB>  <TAB>  <TAB> constant_init(m, 1) <TAB> for m in self.final_layer.modules(): <MASK> normal_init(m, std=0.001, bias=0) <TAB>  <TAB> elif isinstance(m, nn.BatchNorm2d): <TAB>  <TAB>  <TAB> constant_init(m, 1)","if isinstance ( m , nn . Conv2d ) :",161
"def onPavloviaSync(self, evt=None): <TAB> if self._getExportPref(""on sync""): <TAB>  <TAB> htmlPath = self._getHtmlPath(self.filename) <MASK> self.fileExport(htmlPath=htmlPath) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return <TAB> self.enablePavloviaButton([""pavloviaSync"", ""pavloviaRun""], False) <TAB> try: <TAB>  <TAB> retVal = pavlovia_ui.syncProject(parent=self, project=self.project) <TAB>  <TAB> pavlovia.knownProjects.save()  # update projects.json <TAB>  <TAB> self.gitFeedback(retVal) <TAB> finally: <TAB>  <TAB> self.enablePavloviaButton([""pavloviaSync"", ""pavloviaRun""], True)",if htmlPath :,194
"def iteridat(): <TAB> """"""Iterator that yields all the ``IDAT`` chunks as strings."""""" <TAB> while True: <TAB>  <TAB> type, data = self.chunk(lenient=lenient) <TAB>  <TAB> if type == b""IEND"": <TAB>  <TAB>  <TAB> # http://www.w3.org/TR/PNG/#11IEND <TAB>  <TAB>  <TAB> break <MASK> continue <TAB>  <TAB> # type == b'IDAT' <TAB>  <TAB> # http://www.w3.org/TR/PNG/#11IDAT <TAB>  <TAB> if self.colormap and not self.plte: <TAB>  <TAB>  <TAB> warnings.warn(""PLTE chunk is required before IDAT chunk"") <TAB>  <TAB> yield data","if type != b""IDAT"" :",165
"def file_lines(stdin): <TAB> split_lines = [""""] <TAB> paren_depth = 0 <TAB> for line in stdin.split(""\n""): <TAB>  <TAB> line = line.strip() <TAB>  <TAB> if line.startswith(""#""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> paren_depth += tokenize(line).count(""("") - tokenize(line).count("")"") <MASK> split_lines[-1] += line <TAB>  <TAB>  <TAB> split_lines.append("""") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> split_lines[-1] += line <TAB> return [x for x in split_lines if x]",if paren_depth == 0 :,138
"def _join_edge_feature(self, graph_list): <TAB> """"""join edge features for multiple graph"""""" <TAB> edge_feat = defaultdict(lambda: []) <TAB> for graph in graph_list: <TAB>  <TAB> for key in graph.edge_feat: <TAB>  <TAB>  <TAB> efeat = graph.edge_feat[key] <MASK> edge_feat[key].append(efeat) <TAB> ret_edge_feat = {} <TAB> for key in edge_feat: <TAB>  <TAB> ret_edge_feat[key] = np.vstack(edge_feat[key]) <TAB> return ret_edge_feat",if len ( efeat ) > 0 :,149
"def login(): <TAB> """"""Authenticate users"""""" <TAB> if not self.access.is_anon(): <TAB>  <TAB> return self._raise_error(403, ""already_logged_in"") <TAB> include_colls = get_bool(request.query.get(""include_colls"", False)) <TAB> result = self.user_manager.login_user(request.json or {}) <TAB> if ""success"" in result: <TAB>  <TAB> data = {""user"": self.access.session_user.serialize(include_colls)} <MASK> data[""new_coll_name""] = result[""new_coll_name""] <TAB>  <TAB> return data <TAB> # self._raise_error(401, result.get('error', '')) <TAB> response.status = 401 <TAB> return result","if result . get ( ""new_coll_name"" ) :",186
"def parse_qsl_text(qs, encoding=""utf-8""): <TAB> qs = qs.encode(""latin-1"") <TAB> qs = qs.replace(b""+"", b"" "") <TAB> pairs = [s2 for s1 in qs.split(b""&"") for s2 in s1.split(b"";"") if s2] <TAB> for name_value in pairs: <TAB>  <TAB> nv = name_value.split(b""="", 1) <MASK> nv.append("""") <TAB>  <TAB> name = unquote(nv[0]) <TAB>  <TAB> value = unquote(nv[1]) <TAB>  <TAB> yield (name.decode(encoding), value.decode(encoding))",if len ( nv ) != 2 :,158
"def process_request(self, request): <TAB> authentication = request.META.get(""HTTP_AUTHORIZATION"") <TAB> if authentication: <TAB>  <TAB> (authmeth, auth) = authentication.split("" "", 1) <TAB>  <TAB> if ""basic"" == authmeth.lower(): <TAB>  <TAB>  <TAB> auth = auth.strip().decode(""base64"") <TAB>  <TAB>  <TAB> username, password = auth.split("":"", 1) <TAB>  <TAB>  <TAB> user = authenticate(username=username, password=password) <MASK> if user.is_active: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> auth_login(request, user)",if user is not None :,140
"def operate_on_dict_of_models( <TAB> input_dict, <TAB> suffix, <TAB> folder, <TAB> operation, <TAB> logging_string="""", <TAB> log_if_successful=False, <TAB> assert_success=False,): <TAB> for k, v in input_dict.items(): <TAB>  <TAB> model_path = modelpath_creator(folder, k, suffix) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> operation(k, v, model_path) <TAB>  <TAB>  <TAB> if log_if_successful: <TAB>  <TAB>  <TAB>  <TAB> logging.info(""%s %s"" % (logging_string, model_path)) <TAB>  <TAB> except IOError: <TAB>  <TAB>  <TAB> logging.warning(""Could not %s %s"" % (logging_string, model_path)) <MASK> raise IOError",if assert_success :,186
"def _check_MHWD_conf(): <TAB> if is_there_a_MHWD_file(): <TAB>  <TAB> print( <TAB>  <TAB>  <TAB> ""WARNING : Found a Xorg config file at /etc/X11/xorg.conf.d/90-mhwd.conf that was auto-generated"" <TAB>  <TAB>  <TAB> "" by the Manjaro driver utility (MHWD). This will likely interfere with GPU switching, so"" <TAB>  <TAB>  <TAB> "" optimus-manager will delete this file automatically if you proceded with GPU switching.\n"" <TAB>  <TAB>  <TAB> ""Proceed ? (y/N)"" <TAB>  <TAB> ) <TAB>  <TAB> confirmation = ask_confirmation() <MASK> sys.exit(0)",if not confirmation :,166
"def get_module_inputs(self): <TAB> for name, module in iteritems(self._modules): <TAB>  <TAB> for input in module.inputs: <MASK> yield name <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield ""%s_%s"" % (name, input)","if input == ""default"" :",73
def get_strided_spans(docs: Iterable[Doc]) -> List[List[Span]]: <TAB> spans = [] <TAB> for doc in docs: <TAB>  <TAB> start = 0 <TAB>  <TAB> spans.append([]) <TAB>  <TAB> for i in range(len(doc) // stride): <TAB>  <TAB>  <TAB> spans[-1].append(doc[start : start + window]) <MASK> break <TAB>  <TAB>  <TAB> start += stride <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if start < len(doc): <TAB>  <TAB>  <TAB>  <TAB> spans[-1].append(doc[start:]) <TAB> return spans,if ( start + window ) >= len ( doc ) :,143
"def get_variables_to_restore(cls, tvars, init_checkpoint): <TAB> """"""Determine correspondence of checkpoint variables to current variables."""""" <TAB> assignment_map = OrderedDict() <TAB> graph_names = [] <TAB> for var in tvars: <TAB>  <TAB> name = var.name <TAB>  <TAB> m = re.match(""^(.*):\\d+$"", name) <TAB>  <TAB> if m is not None: <TAB>  <TAB>  <TAB> name = m.group(1) <TAB>  <TAB>  <TAB> graph_names.append(name) <TAB> ckpt_names = [el[0] for el in tf.train.list_variables(init_checkpoint)] <TAB> for u in ckpt_names: <TAB>  <TAB> for v in graph_names: <MASK> assignment_map[u] = v <TAB> return assignment_map",if u in v :,183
"def validate_feature(namespace): <TAB> if namespace.feature: <TAB>  <TAB> invalid_pattern = re.compile(r""[^a-zA-Z0-9._-]"") <TAB>  <TAB> invalid = re.search(invalid_pattern, namespace.feature) <MASK> raise CLIError( <TAB>  <TAB>  <TAB>  <TAB> ""Feature name is invalid. Only alphanumeric characters, '.', '-' and '_' are allowed."" <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> raise CLIError(""Feature name cannot be empty."")",if invalid :,114
"def _run_suite(suite): <TAB> """"""Run tests from a unittest.TestSuite-derived class."""""" <TAB> if verbose: <TAB>  <TAB> runner = unittest.TextTestRunner(sys.stdout, verbosity=2, failfast=failfast) <TAB> else: <TAB>  <TAB> runner = BasicTestRunner() <TAB> result = runner.run(suite) <TAB> if not result.wasSuccessful(): <TAB>  <TAB> if len(result.errors) == 1 and not result.failures: <TAB>  <TAB>  <TAB> err = result.errors[0][1] <MASK> err = result.failures[0][1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> err = ""multiple errors occurred"" <TAB>  <TAB>  <TAB> if not verbose: <TAB>  <TAB>  <TAB>  <TAB> err += ""; run in verbose mode for details"" <TAB>  <TAB> raise TestFailed(err)",elif len ( result . failures ) == 1 and not result . errors :,193
"def wait_on_job(job_id, max_timeout): <TAB> global job_results <TAB> timeout = 0 <TAB> while True: <TAB>  <TAB> job_results = GET(f""/core/get_jobs/?id={job_id}"") <TAB>  <TAB> job_state = job_results.json()[0][""state""] <MASK> sleep(5) <TAB>  <TAB> elif job_state in (""SUCCESS"", ""FAILED""): <TAB>  <TAB>  <TAB> return {""state"": job_state, ""results"": job_results.json()[0]} <TAB>  <TAB> if timeout >= max_timeout: <TAB>  <TAB>  <TAB> return {""state"": ""TIMEOUT"", ""results"": job_results.json()[0]} <TAB>  <TAB> timeout += 5","if job_state in ( ""RUNNING"" , ""WAITING"" ) :",169
"def pre_save(self, model_instance, add): <TAB> if self.auto and add: <TAB>  <TAB> value = self.create_uuid() <TAB>  <TAB> setattr(model_instance, self.attname, value) <TAB> else: <TAB>  <TAB> value = super(UUIDField, self).pre_save(model_instance, add) <MASK> value = self.create_uuid() <TAB>  <TAB>  <TAB> setattr(model_instance, self.attname, value) <TAB> return value",if self . auto and not value :,118
"def _lookupValue(self, myDict, val): <TAB> for name in myDict: <MASK> # array of cbs <TAB>  <TAB>  <TAB> for rb in myDict[name]: <TAB>  <TAB>  <TAB>  <TAB> if rb == val: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return name <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if myDict[name] == val: <TAB>  <TAB>  <TAB>  <TAB> return name <TAB> return None","if isinstance ( myDict [ name ] , type ( [ ] ) ) :",100
"def extract_sql_from_network_parameters( <TAB> request_data, request_arguments, request_form_data): <TAB> if request_data: <TAB>  <TAB> sql_parameters = json.loads(request_data, encoding=""utf-8"") <MASK> return dict(sql=str(sql_parameters), explain_plan=None) <TAB>  <TAB> return sql_parameters <TAB> else: <TAB>  <TAB> return request_arguments or request_form_data","if isinstance ( sql_parameters , str ) :",113
"def _get_data(url): <TAB> """"""Helper function to get data over http or from a local file"""""" <TAB> if url.startswith(""http://""): <TAB>  <TAB> resp = urllib2.urlopen(url) <TAB>  <TAB> encoding = resp.headers.dict.get(""content-encoding"", ""plain"") <TAB>  <TAB> data = resp.read() <TAB>  <TAB> if encoding == ""plain"": <TAB>  <TAB>  <TAB> pass <MASK> data = StringIO(data) <TAB>  <TAB>  <TAB> data = gzip.GzipFile(fileobj=data).read() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise RuntimeError(""unknown encoding"") <TAB> else: <TAB>  <TAB> with open(url, ""r"") as fid: <TAB>  <TAB>  <TAB> data = fid.read() <TAB>  <TAB> fid.close() <TAB> return data","elif encoding == ""gzip"" :",178
"def get_series(): <TAB> series_to_set = {} <TAB> for doctype in doctype_series_map: <TAB>  <TAB> if not frappe.db.exists(""DocType"", doctype): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if not frappe.db.a_row_exists(doctype): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> series_to_preserve = get_series_to_preserve(doctype) <MASK> continue <TAB>  <TAB> # set autoname property setter <TAB>  <TAB> if series_to_preserve: <TAB>  <TAB>  <TAB> series_to_set[doctype] = {""value"": series_to_preserve} <TAB> return series_to_set",if not series_to_preserve :,160
"def _get_platformset_name(data, platform_name): <TAB> for item in data: <TAB>  <TAB> if platform_name in item and item.startswith(""PlatformEdit.html?""): <TAB>  <TAB>  <TAB> parameter_list = item.split(""&"") <TAB>  <TAB>  <TAB> for parameter in parameter_list: <MASK> return parameter.split(""="")[1] <TAB> return None","if parameter . startswith ( ""platformSetName"" ) :",97
"def _visit(self, expr): <TAB> node = expr.op() <TAB> for arg in node.flat_args(): <TAB>  <TAB> if isinstance(arg, ir.TableExpr): <TAB>  <TAB>  <TAB> self._visit_table(arg) <MASK> for sub_expr in L.flatten_predicate(arg): <TAB>  <TAB>  <TAB>  <TAB> self.predicates.append(sub_expr) <TAB>  <TAB>  <TAB>  <TAB> self._visit(sub_expr) <TAB>  <TAB> elif isinstance(arg, ir.Expr): <TAB>  <TAB>  <TAB> self._visit(arg) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> continue","elif isinstance ( arg , ir . BooleanColumn ) :",143
"def _compare_item(obj, spec): <TAB> for key, value in spec.items(): <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> self.assert_unordered_result(getattr(obj, key), value[0], *value[1]) <TAB>  <TAB>  <TAB> except AssertionError: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if getattr(obj, key, NOVALUE) != value: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return True","if isinstance ( value , tuple ) :",113
"def _execute(self, options, args): <TAB> if len(args) < 3: <TAB>  <TAB> raise CommandError(_(""Not enough arguments"")) <TAB> tag = fsn2text(args[0]) <TAB> value = fsn2text(args[1]) <TAB> paths = args[2:] <TAB> songs = [] <TAB> for path in paths: <TAB>  <TAB> song = self.load_song(path) <MASK> raise CommandError(_(""Can not set %r"") % tag) <TAB>  <TAB> self.log(""Set %r to %r"" % (value, tag)) <TAB>  <TAB> if tag in song: <TAB>  <TAB>  <TAB> del song[tag] <TAB>  <TAB> song.add(tag, value) <TAB>  <TAB> songs.append(song) <TAB> if not options.dry_run: <TAB>  <TAB> self.save_songs(songs)",if not song . can_change ( tag ) :,197
"def printsentcb(self, gline): <TAB> """"""Callback when a print gcode has been sent"""""" <TAB> if gline.is_move: <MASK> wx.CallAfter(self.gwindow.set_current_gline, gline) <TAB>  <TAB> if hasattr(self.gviz, ""set_current_gline""): <TAB>  <TAB>  <TAB> wx.CallAfter(self.gviz.set_current_gline, gline)","if hasattr ( self . gwindow , ""set_current_gline"" ) :",120
"def compute_missing_checksums(): <TAB> for image in store.list_directory(store.images): <TAB>  <TAB> image_id = image.split(""/"").pop() <MASK> warning(""{0} is orphan"".format(image_id)) <TAB>  <TAB> json_data = load_image_json(image_id) <TAB>  <TAB> if not json_data: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> checksum_path = store.image_checksum_path(image_id) <TAB>  <TAB> if store.exists(checksum_path): <TAB>  <TAB>  <TAB> # Checksum already there, skipping <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> compute_image_checksum(image_id, json_data)",if image_id not in ancestry_cache :,162
"def _escape_attrib(text, encoding=None, replace=string.replace): <TAB> # escape attribute value <TAB> try: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> text = _encode(text, encoding) <TAB>  <TAB>  <TAB> except UnicodeError: <TAB>  <TAB>  <TAB>  <TAB> return _encode_entity(text) <TAB>  <TAB> text = replace(text, ""&"", ""&amp;"") <TAB>  <TAB> text = replace(text, ""'"", ""&apos;"")  # FIXME: overkill <TAB>  <TAB> text = replace(text, '""', ""&quot;"") <TAB>  <TAB> text = replace(text, ""<"", ""&lt;"") <TAB>  <TAB> text = replace(text, "">"", ""&gt;"") <TAB>  <TAB> return text <TAB> except (TypeError, AttributeError): <TAB>  <TAB> _raise_serialization_error(text)",if encoding :,175
"def test_methods_take_force_interactive(self): <TAB> # Every IDisplay method implemented by FileDisplay must take <TAB> # force_interactive to prevent workflow regressions. <TAB> for name in interfaces.IDisplay.names(): <MASK> getargspec = inspect.getargspec <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> getargspec = inspect.getfullargspec <TAB>  <TAB> arg_spec = getargspec( <TAB>  <TAB>  <TAB> getattr(self.displayer, name) <TAB>  <TAB> )  # pylint: disable=deprecated-method <TAB>  <TAB> self.assertTrue(""force_interactive"" in arg_spec.args)",if six . PY2 :,139
"def __GetNodeOptions(self, vnode): <TAB> bodyString = vnode.bodyString() <TAB> lines = bodyString.splitlines() <TAB> for line in lines: <TAB>  <TAB> containsAscConfigDirective = patternAscDirectiveConfig.match(line) <MASK> # Leo uses unicode, convert to plain ascii <TAB>  <TAB>  <TAB> name = str(containsAscConfigDirective.group(1)) <TAB>  <TAB>  <TAB> value = str(containsAscConfigDirective.group(2)) <TAB>  <TAB>  <TAB> if name in self.current: <TAB>  <TAB>  <TAB>  <TAB> self.current[name] = value <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> g.es(vnode.headString()) <TAB>  <TAB>  <TAB>  <TAB> g.es(""  No such config option: %s"" % name)",if containsAscConfigDirective :,181
"def visitImport(self, node): <TAB> self.set_lineno(node) <TAB> level = 0 if self.graph.checkFlag(CO_FUTURE_ABSIMPORT) else -1 <TAB> for name, alias in node.names: <MASK> self.emit(""LOAD_CONST"", level) <TAB>  <TAB>  <TAB> self.emit(""LOAD_CONST"", None) <TAB>  <TAB> self.emit(""IMPORT_NAME"", name) <TAB>  <TAB> mod = name.split(""."")[0] <TAB>  <TAB> if alias: <TAB>  <TAB>  <TAB> self._resolveDots(name) <TAB>  <TAB>  <TAB> self.storeName(alias) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.storeName(mod)",if VERSION > 1 :,160
"def ready(self): <TAB> if not hasattr(django_settings, ""APIGW_PUBLIC_KEY""): <TAB>  <TAB> get_client_by_user = settings.ESB_GET_CLIENT_BY_USER <TAB>  <TAB> client = get_client_by_user(settings.SYSTEM_USE_API_ACCOUNT) <TAB>  <TAB> esb_result = client.esb.get_api_public_key() <MASK> api_public_key = esb_result[""data""][""public_key""] <TAB>  <TAB>  <TAB> django_settings.APIGW_PUBLIC_KEY = api_public_key <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logger.warning(""[API] get api public key error: %s"" % esb_result[""message""])","if esb_result [ ""result"" ] :",175
"def ls(self, path_glob): <TAB> bare_path_glob = _from_file_uri(path_glob) <TAB> uri_scheme = path_glob[0 : -len(bare_path_glob)]  # 'file:///' or '' <TAB> for path in glob.glob(bare_path_glob): <MASK> for dirname, _, filenames in os.walk(path, followlinks=True): <TAB>  <TAB>  <TAB>  <TAB> for filename in filenames: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield uri_scheme + os.path.join(dirname, filename) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield uri_scheme + path",if os . path . isdir ( path ) :,151
def can_see_menu(self): <TAB> if self.auth.user: <MASK> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> groups = self.settings.groups <TAB>  <TAB>  <TAB> if any(t in self.settings.menu_groups for t in groups): <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False,if self . settings . menu_groups is None :,87
"def _get_profile(config, profile_name, config_path): <TAB> profile = {} <TAB> if profile_name: <TAB>  <TAB> profiles = config.get_option(""profiles"") or {} <TAB>  <TAB> profile = profiles.get(profile_name) <MASK> raise utils.ProfileNotFound(config_path, profile_name) <TAB>  <TAB> LOG.debug(""read in legacy profile '%s': %s"", profile_name, profile) <TAB> else: <TAB>  <TAB> profile[""include""] = set(config.get_option(""tests"") or []) <TAB>  <TAB> profile[""exclude""] = set(config.get_option(""skips"") or []) <TAB> return profile",if profile is None :,154
"def generate_label_data(ids): <TAB> if len(ids) != SAMPLE_NUM: <TAB>  <TAB> raise ValueError(""len ids should equal to sample number"") <TAB> header = [""id"", ""y""] + [""x"" + str(i) for i in range(FEATURE_NUM)] <TAB> yield header <TAB> counter = 0 <TAB> for sample_i in range(SAMPLE_NUM): <TAB>  <TAB> one_data = [ids[sample_i], round(random.random())] + list( <TAB>  <TAB>  <TAB> np.random.random(FEATURE_NUM) <TAB>  <TAB> ) <TAB>  <TAB> counter += 1 <MASK> print(""generate data {}"".format(counter)) <TAB>  <TAB> yield one_data",if counter % 10000 == 0 :,163
"def length_bounds_from_validators(field): <TAB> min_size = 1 <TAB> max_size = field.max_length <TAB> for v in field.validators: <TAB>  <TAB> if isinstance(v, django.core.validators.MinLengthValidator): <TAB>  <TAB>  <TAB> min_size = max(min_size, v.limit_value) <MASK> max_size = min(max_size or v.limit_value, v.limit_value) <TAB> return min_size, max_size","elif isinstance ( v , django . core . validators . MaxLengthValidator ) :",131
"def _set_field_value(self, dateval, fieldnum, new_value): <TAB> values = {} <TAB> for i, field in enumerate(self.fields): <TAB>  <TAB> if field.REAL: <TAB>  <TAB>  <TAB> if i < fieldnum: <TAB>  <TAB>  <TAB>  <TAB> values[field.name] = field.get_value(dateval) <MASK> values[field.name] = field.get_min(dateval) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> values[field.name] = new_value <TAB> return datetime(**values)",elif i > fieldnum :,137
"def stop_modules(self, *modules): <TAB> """"""[UNIT]... -- stop these units"""""" <TAB> found_all = True <TAB> units = [] <TAB> for module in modules: <TAB>  <TAB> matched = self.match_units([module]) <MASK> logg.error(""no such service '%s'"", module) <TAB>  <TAB>  <TAB> found_all = False <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for unit in matched: <TAB>  <TAB>  <TAB> if unit not in units: <TAB>  <TAB>  <TAB>  <TAB> units += [unit] <TAB> return self.stop_units(units) and found_all",if not matched :,136
"def _get_shortcut_data(target, current=True): <TAB> wpgroup = utils.create_winpython_start_menu_folder(current=current) <TAB> wpdir = osp.join(target, os.pardir) <TAB> data = [] <TAB> for name in os.listdir(wpdir): <TAB>  <TAB> bname, ext = osp.splitext(name) <MASK> data.append( <TAB>  <TAB>  <TAB>  <TAB> ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> osp.join(wpdir, name), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> bname, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> osp.join(wpgroup, bname), <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> return data","if ext == "".exe"" :",161
"def setData(self, index: QModelIndex, value, role=None): <TAB> if index.row() == 0 and role == Qt.CheckStateRole: <TAB>  <TAB> if bool(value) != self.show_unassigned: <TAB>  <TAB>  <TAB> self.show_unassigned = bool(value) <TAB>  <TAB>  <TAB> self.show_state_changed.emit() <TAB> elif role == Qt.CheckStateRole: <TAB>  <TAB> try: <MASK> self.participants[index.row() - 1].show = value <TAB>  <TAB>  <TAB>  <TAB> self.show_state_changed.emit() <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB> return False <TAB> return True",if self . participants [ index . row ( ) - 1 ] . show != value :,169
"def get_last_word(self): <TAB> line, column = index(self.text.index(INSERT)) <TAB> string = """" <TAB> while True: <TAB>  <TAB> char = self.text.get(index(line, column - 1)) <MASK> string = char + string <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> column -= 1 <TAB>  <TAB> if column == 0: <TAB>  <TAB>  <TAB> break <TAB> self.last_word = string <TAB> return self.last_word",if char . isalpha ( ) :,118
"def compute(self, t): <TAB> if self.queue: <MASK> return self.queue.pop(0) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> r = self.ssc.sc.union(self.queue) <TAB>  <TAB>  <TAB> self.queue = [] <TAB>  <TAB>  <TAB> return r <TAB> elif self.defaultRDD: <TAB>  <TAB> return self.defaultRDD",if self . oneAtAtime :,96
"def merge(self, otherunit, overwrite=False, comments=True, authoritative=False): <TAB> # TODO: consider other attributes like ""approved"" <TAB> super(xliffunit, self).merge(otherunit, overwrite, comments) <TAB> if self.target: <TAB>  <TAB> self.marktranslated() <MASK> self.markfuzzy() <TAB>  <TAB> elif otherunit.source == self.source: <TAB>  <TAB>  <TAB> self.markfuzzy(False) <TAB> if comments: <TAB>  <TAB> self.addnote(otherunit.getnotes())",if otherunit . isfuzzy ( ) :,135
"def __fill_rpc_requests(self): <TAB> for rpc_request in self.__config.get(""serverSideRpc"", []): <MASK> converter = TBUtility.check_and_import(""request"", rpc_request[""converter""])( <TAB>  <TAB>  <TAB>  <TAB> rpc_request <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> converter = JsonRequestDownlinkConverter(rpc_request) <TAB>  <TAB> rpc_request_dict = {**rpc_request, ""converter"": converter} <TAB>  <TAB> self.__rpc_requests.append(rpc_request_dict)","if rpc_request . get ( ""converter"" ) is not None :",152
"def get_cs5_uninstall_xml(option_xml_file): <TAB> """"""Gets the uninstall deployment data from a CS5 installer"""""" <TAB> xml = """" <TAB> dom = minidom.parse(option_xml_file) <TAB> deployment_info = dom.getElementsByTagName(""DeploymentInfo"") <TAB> if deployment_info: <TAB>  <TAB> for info_item in deployment_info: <TAB>  <TAB>  <TAB> deployment_uninstall = info_item.getElementsByTagName(""DeploymentUninstall"") <TAB>  <TAB>  <TAB> if deployment_uninstall: <TAB>  <TAB>  <TAB>  <TAB> deployment_data = deployment_uninstall[0].getElementsByTagName( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Deployment"" <TAB>  <TAB>  <TAB>  <TAB> ) <MASK> deployment = deployment_data[0] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> xml += deployment.toxml(""UTF-8"") <TAB> return xml",if deployment_data :,188
"def EnumerateFilesystemsFromClient(args): <TAB> """"""List all local filesystems mounted on this system."""""" <TAB> del args  # Unused. <TAB> for drive in win32api.GetLogicalDriveStrings().split(""\x00""): <MASK> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> volume = win32file.GetVolumeNameForVolumeMountPoint(drive).rstrip(""\\"") <TAB>  <TAB>  <TAB> label, _, _, _, fs_type = win32api.GetVolumeInformation(drive) <TAB>  <TAB> except win32api.error: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if compatibility.PY2: <TAB>  <TAB>  <TAB> label = UnicodeFromCodePage(label) <TAB>  <TAB> yield rdf_client_fs.Filesystem( <TAB>  <TAB>  <TAB> device=volume, mount_point=""/%s:/"" % drive[0], type=fs_type, label=label <TAB>  <TAB> )",if not drive :,199
"def to_ical(self): <TAB> # SequenceTypes <TAB> result = [] <TAB> for key, vals in self.sorted_items(): <TAB>  <TAB> typ = self.types[key] <MASK> vals = [vals] <TAB>  <TAB> vals = "","".join([typ(val).to_ical() for val in vals]) <TAB>  <TAB> result.append(""%s=%s"" % (key, vals)) <TAB> return "";"".join(result)",if not type ( vals ) in SequenceTypes :,110
"def on_end_date_changed(self, widget): <TAB> if not self.master_is_cmdline: <MASK> time = self.fact.end_time.time() <TAB>  <TAB>  <TAB> self.fact.end_time = dt.datetime.combine(self.end_date.date, time) <TAB>  <TAB>  <TAB> self.validate_fields() <TAB>  <TAB>  <TAB> self.update_cmdline() <TAB>  <TAB> elif self.end_date.date: <TAB>  <TAB>  <TAB> # No end time means on-going, hence date would be meaningless. <TAB>  <TAB>  <TAB> # And a default end date may be provided when end time is set, <TAB>  <TAB>  <TAB> # so there should never be a date without time. <TAB>  <TAB>  <TAB> self.end_date.date = None",if self . fact . end_time :,180
"def __call__(self, *args, **kwargs): <TAB> if self.binding == ""function"": <MASK> instance, args = args[0], args[1:] <TAB>  <TAB>  <TAB> wrapped = functools.partial(self.__wrapped__, instance) <TAB>  <TAB>  <TAB> return self.wrapper(wrapped, instance, args, kwargs) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.wrapper(self.__wrapped__, self.instance, args, kwargs) <TAB> else: <TAB>  <TAB> instance = getattr(self.__wrapped__, ""__self__"", None) <TAB>  <TAB> return self.wrapper(self.__wrapped__, instance, args, kwargs)",if self . instance is None :,146
"def visit_Call(self, node): <TAB> if self._check_call_names(node, [""str"", ""unicode""]): <TAB>  <TAB> if node not in self.already_checked: <TAB>  <TAB>  <TAB> self.already_checked.append(node) <TAB>  <TAB>  <TAB> if isinstance(node.args[0], ast.Name): <MASK> self.add_error(node.args[0]) <TAB> super(CheckForStrUnicodeExc, self).generic_visit(node)",if node . args [ 0 ] . id in self . name :,127
"def post(self, request, *args, **kwargs): <TAB> self.comment_obj = get_object_or_404(Comment, id=request.POST.get(""commentid"")) <TAB> if request.user == self.comment_obj.commented_by: <TAB>  <TAB> form = AccountCommentForm(request.POST, instance=self.comment_obj) <MASK> return self.form_valid(form) <TAB>  <TAB> return self.form_invalid(form) <TAB> data = {""error"": ""You don't have permission to edit this comment.""} <TAB> return JsonResponse(data)",if form . is_valid ( ) :,142
"def get_new_datasets(self, output_name): <TAB> datasets = self.tool_provided_job_metadata.get(output_name, {}).get(""datasets"", []) <TAB> if not datasets: <TAB>  <TAB> elements = self.tool_provided_job_metadata.get(output_name, {}).get( <TAB>  <TAB>  <TAB> ""elements"", [] <TAB>  <TAB> ) <MASK> datasets = self._elements_to_datasets(elements) <TAB> return datasets",if elements :,108
"def unixgetaddr(program): <TAB> """"""Get the hardware address on a Unix machine."""""" <TAB> from os import popen <TAB> for line in popen(program): <TAB>  <TAB> words = line.lower().split() <MASK> addr = words[words.index(""hwaddr"") + 1] <TAB>  <TAB>  <TAB> return int(addr.replace("":"", """"), 16) <TAB>  <TAB> if ""ether"" in words: <TAB>  <TAB>  <TAB> addr = words[words.index(""ether"") + 1] <TAB>  <TAB>  <TAB> return int(addr.replace("":"", """"), 16)","if ""hwaddr"" in words :",132
"def _jcolnames_from_rowstmps(self, tmps): <TAB> colnames = [] <TAB> all_colnames = {} <TAB> jcolnames = {} <TAB> for colname in tmps: <TAB>  <TAB> all_colnames[colname[0]] = colname[0] <TAB>  <TAB> jcolnames[colname[0]] = jcolnames.get(colname[0], []) <TAB>  <TAB> jcolnames[colname[0]].append(colname[1]) <TAB> for colname in all_colnames.keys(): <MASK> colnames.append(colname) <TAB>  <TAB>  <TAB> del jcolnames[colname] <TAB> return colnames, jcolnames",if colname == self . _stable_ :,158
"def get(self): <TAB> choice = self.choice <TAB> trans = self.trans <TAB> n = self.histsize <TAB> seq = choice(trans[None]) <TAB> while True: <TAB>  <TAB> subseq = seq[max(0, len(seq) - n) :] <TAB>  <TAB> options = trans[subseq] <TAB>  <TAB> next = choice(options) <MASK> break <TAB>  <TAB> seq += next <TAB> return seq",if not next :,104
"def _get_endpoint(self, endpoint, params=(), format=None, filter_=None): <TAB> result = {} <TAB> if filter_: <TAB>  <TAB> params.update({""filter"": filter_}) <TAB> self.optional_params = params <TAB> self.endpoints = [endpoint] <TAB> data = self.fetch(format=no_pandas) <TAB> # IEX Cloud returns multiple symbol requests as as a list of dicts <TAB> # so convert to dict of dicts <TAB> if isinstance(data, list): <TAB>  <TAB> data = data[0] <TAB> for symbol in self.symbols: <MASK> continue <TAB>  <TAB> if endpoint not in data[symbol]: <TAB>  <TAB>  <TAB> result[symbol] = [] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result[symbol] = data[symbol][endpoint] <TAB> return self._output_format_one(result, format=format)",if symbol not in data :,199
"def end_generation(self, config, population, species_set): <TAB> checkpoint_due = False <TAB> if self.time_interval_seconds is not None: <TAB>  <TAB> dt = time.time() - self.last_time_checkpoint <TAB>  <TAB> if dt >= self.time_interval_seconds: <TAB>  <TAB>  <TAB> checkpoint_due = True <TAB> if (checkpoint_due is False) and (self.generation_interval is not None): <TAB>  <TAB> dg = self.current_generation - self.last_generation_checkpoint <MASK> checkpoint_due = True <TAB> if checkpoint_due: <TAB>  <TAB> self.save_checkpoint(config, population, species_set, self.current_generation) <TAB>  <TAB> self.last_generation_checkpoint = self.current_generation <TAB>  <TAB> self.last_time_checkpoint = time.time()",if dg >= self . generation_interval :,198
"def feed(self, aBuf, aCharLen): <TAB> """"""feed a character with known length"""""" <TAB> if aCharLen == 2: <TAB>  <TAB> # we only care about 2-bytes character in our distribution analysis <TAB>  <TAB> order = self.get_order(aBuf) <TAB> else: <TAB>  <TAB> order = -1 <TAB> if order >= 0: <TAB>  <TAB> self._mTotalChars += 1 <TAB>  <TAB> # order is valid <TAB>  <TAB> if order < self._mTableSize: <MASK> self._mFreqChars += 1",if 512 > self . _mCharToFreqOrder [ order ] :,142
"def write(self, text): <TAB> if self.enabled: <MASK> log_line = ""[{0}] {1}"".format(datetime.datetime.utcnow().isoformat(), text) <TAB>  <TAB>  <TAB> self.lines.append(log_line)",if text and text . strip ( ) :,65
"def getvalue(self, name): <TAB> if name in self.face.features: <TAB>  <TAB> feature = self.face.features[name] <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> return int(feature[""Value""], 0) <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> return -1 <TAB> return -1","if feature [ ""FeatureType"" ] != ""evt"" :",85
"def write_scatterfunctions_within_if(self, ifstatement): <TAB> fn_section = """" <TAB> for assignment in ifstatement: <MASK> fn_section += self.write_scatterfunction( <TAB>  <TAB>  <TAB>  <TAB> ifstatement[assignment], assignment <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if assignment.startswith(""if""): <TAB>  <TAB>  <TAB> fn_section += self.write_scatterfunctions_within_if( <TAB>  <TAB>  <TAB>  <TAB> ifstatement[assignment][""body""] <TAB>  <TAB>  <TAB> ) <TAB> return fn_section","if assignment . startswith ( ""scatter"" ) :",124
"def get_col_default(self, col_name: str) -> Any: <TAB> default = getattr(self.list_columns[col_name], ""default"", None) <TAB> if default is not None: <TAB>  <TAB> value = getattr(default, ""arg"", None) <TAB>  <TAB> if value is not None: <MASK> return lambda: default.arg(None) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> if not getattr(default, ""is_scalar"", True): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB>  <TAB> return value","if getattr ( default , ""is_callable"" , False ) :",139
"def _init_connections(cls, connections_config: dict, create_db: bool) -> None: <TAB> for name, info in connections_config.items(): <TAB>  <TAB> if isinstance(info, str): <TAB>  <TAB>  <TAB> info = expand_db_url(info) <TAB>  <TAB> client_class = cls._discover_client_class(info.get(""engine"")) <TAB>  <TAB> db_params = info[""credentials""].copy() <TAB>  <TAB> db_params.update({""connection_name"": name}) <TAB>  <TAB> connection = client_class(**db_params) <MASK> await connection.db_create() <TAB>  <TAB> await connection.create_connection(with_db=True) <TAB>  <TAB> cls._connections[name] = connection <TAB>  <TAB> current_transaction_map[name] = ContextVar(name, default=connection)",if create_db :,190
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.add_filenames(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,90
"def before_write_items(items, nulls_map=None): <TAB> # TODO: cythonize <TAB> null_value = self.null_value <TAB> for i, item in enumerate(items): <TAB>  <TAB> if nulls_map and nulls_map[i]: <TAB>  <TAB>  <TAB> items[i] = null_value <TAB>  <TAB>  <TAB> continue <MASK> sign = 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sign = -1 <TAB>  <TAB>  <TAB> item = -item <TAB>  <TAB> items[i] = sign * (item & self.mask)",if item >= 0 :,133
"def _sendDatapointsNow(self, datapoints): <TAB> for metric, datapoint in datapoints: <MASK> value = (""%.10f"" % datapoint[1]).rstrip(""0"").rstrip(""."") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = ""%d"" % datapoint[1] <TAB>  <TAB> to_send = ""%s %s %d"" % (metric, value, datapoint[0]) <TAB>  <TAB> self.sendLine(to_send.encode(""utf-8""))","if isinstance ( datapoint [ 1 ] , float ) :",121
"def logs_like(action, **kwargs): <TAB> matches = [] <TAB> for entry in LoggingVolumeDriver._LOGS: <TAB>  <TAB> if entry[""action""] != action: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> match = True <TAB>  <TAB> for k, v in kwargs.iteritems(): <MASK> match = False <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if match: <TAB>  <TAB>  <TAB> matches.append(entry) <TAB> return matches",if entry . get ( k ) != v :,109
def report(msg): <TAB> if log and conf.get_bucket_host() not in cls._bucket_location_failure_reported: <MASK> log.debug(msg) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.warning(msg) <TAB>  <TAB> cls._bucket_location_failure_reported.add(conf.get_bucket_host()),if report_info :,87
"def deleteTab(self, tabName): <TAB> c = self.c <TAB> nb = self.nb <TAB> if tabName not in (""Log"", ""Find"", ""Spell""): <TAB>  <TAB> for i in range(nb.GetPageCount()): <TAB>  <TAB>  <TAB> s = nb.GetPageText(i) <MASK> nb.DeletePage(i) <TAB>  <TAB>  <TAB>  <TAB> self.textDict[tabName] = None <TAB>  <TAB>  <TAB>  <TAB> self.frameDict[tabName] = False  # A bit of a kludge. <TAB>  <TAB>  <TAB>  <TAB> self.tabName = None <TAB>  <TAB>  <TAB>  <TAB> break <TAB> self.selectTab(""Log"") <TAB> c.invalidateFocus() <TAB> c.bodyWantsFocus()",if s == tabName :,174
"def check_app_engine_sdk_version(app_configs=None, **kwargs): <TAB> errors = [] <TAB> if GetVersionObject: <TAB>  <TAB> sdk_version = tuple(_VersionList(GetVersionObject()[""release""])) <MASK> errors.append( <TAB>  <TAB>  <TAB>  <TAB> Warning( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""MAX_APP_ENGINE_SDK_VERSION"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> hint=""You are using a version of the App Engine SDK that is not yet supported"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> id=""djangae.W002"", <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> return errors",if sdk_version > MAX_APP_ENGINE_SDK_VERSION :,159
"def set_inter_state_supply(self, inter_state_supply): <TAB> osup_det = self.report_dict[""sup_details""][""osup_det""] <TAB> for key, value in iteritems(inter_state_supply): <TAB>  <TAB> if key[0] == ""Unregistered"": <TAB>  <TAB>  <TAB> self.report_dict[""inter_sup""][""unreg_details""].append(value) <MASK> self.report_dict[""inter_sup""][""comp_details""].append(value) <TAB>  <TAB> if key[0] == ""UIN Holders"": <TAB>  <TAB>  <TAB> self.report_dict[""inter_sup""][""uin_details""].append(value)","if key [ 0 ] == ""Registered Composition"" :",170
"def com_list_constructor(self, nodelist): <TAB> # listmaker: test ( list_for | (',' test)* [','] ) <TAB> values = [] <TAB> for i in range(1, len(nodelist)): <TAB>  <TAB> if PY2 and nodelist[i][0] == symbol.list_for: <TAB>  <TAB>  <TAB> assert len(nodelist[i:]) == 1 <TAB>  <TAB>  <TAB> return self.com_list_comprehension(values[0], nodelist[i]) <MASK> continue <TAB>  <TAB> values.append(self.com_node(nodelist[i])) <TAB> return List(values, lineno=values[0].lineno)",elif nodelist [ i ] [ 0 ] == token . COMMA :,156
"def _validate_traffic_dict(self, traffic_dict: Dict[str, float]): <TAB> for backend in traffic_dict: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Attempted to assign traffic to a backend '{}' that "" <TAB>  <TAB>  <TAB>  <TAB> ""is not registered."".format(backend) <TAB>  <TAB>  <TAB> )",if self . backend_state . get_backend ( backend ) is None :,91
"def run(self, command, *args, **kwargs): <TAB> command = self.get_command(command, *args) <TAB> command = self.encode(command) <TAB> try: <TAB>  <TAB> rc, stdout, stderr = self._exec_command(command) <TAB> except paramiko.ssh_exception.SSHException: <MASK> # try to reinit connection (once) <TAB>  <TAB>  <TAB> del self.client <TAB>  <TAB>  <TAB> rc, stdout, stderr = self._exec_command(command) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise <TAB> return self.result(rc, command, stdout, stderr)",if not self . client . get_transport ( ) . is_active ( ) :,153
"def saveFile(self): <TAB> """"""User clicked Save menu. Display a Dialog to ask whwre to save."""""" <TAB> filepath, _ = QtWidgets.QFileDialog.getSaveFileName( <TAB>  <TAB> self, ""Save File"", """", ""Androguard Session (*.ag)"" <TAB> ) <TAB> if filepath: <TAB>  <TAB> # Ensure .ag as file ending <MASK> filepath = ""{}.ag"".format(filepath) <TAB>  <TAB> self.showStatus(""Saving %s..."" % str(filepath)) <TAB>  <TAB> self.saveSession(filepath) <TAB>  <TAB> self.showStatus(""Saved Session to %s!"" % str(filepath))","if not filepath . endswith ( "".ag"" ) :",151
"def __cleanup(cls, expire): <TAB> now = time.time() <TAB> for storage in six.itervalues(cls.data): <TAB>  <TAB> for key, data in list(storage.items()): <MASK> del storage[key] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> break",if data [ 0 ] + expire < now :,80
"def getaddr(): <TAB> """"""Get the hardware address as a 48-bit integer."""""" <TAB> from os.path import join, isfile <TAB> for dir in [ <TAB>  <TAB> ""/sbin"", <TAB>  <TAB> ""/usr/sbin"", <TAB>  <TAB> r""c:\windows"", <TAB>  <TAB> r""c:\windows\system"", <TAB>  <TAB> r""c:\windows\system32"", <TAB> ]: <MASK> return unixgetaddr(join(dir, ""ifconfig"")) <TAB>  <TAB> if isfile(join(dir, ""ipconfig.exe"")): <TAB>  <TAB>  <TAB> return wingetaddr(join(dir, ""ipconfig.exe""))","if isfile ( join ( dir , ""ifconfig"" ) ) :",146
def verify_logs_filter(files): <TAB> to_verify = [] <TAB> for filename in files: <TAB>  <TAB> verify_file = True <TAB>  <TAB> for scheme in DEFAULT_SCHEMES: <MASK> verify_file = False <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if verify_file: <TAB>  <TAB>  <TAB> to_verify.append(filename) <TAB> return to_verify,if filename . startswith ( scheme ) :,96
"def calc_paired_insert_stats(in_bam, nsample=1000000): <TAB> """"""Retrieve statistics for paired end read insert distances."""""" <TAB> dists = [] <TAB> n = 0 <TAB> with pysam.Samfile(in_bam, ""rb"") as in_pysam: <TAB>  <TAB> for read in in_pysam: <TAB>  <TAB>  <TAB> if read.is_proper_pair and read.is_read1: <TAB>  <TAB>  <TAB>  <TAB> n += 1 <TAB>  <TAB>  <TAB>  <TAB> dists.append(abs(read.isize)) <MASK> break <TAB> return insert_size_stats(dists)",if n >= nsample :,149
"def _handle_backend_response(self, msg): <TAB> if hasattr(msg, ""source""): <TAB>  <TAB> # check if the response is relevant for current state <MASK> self._close() <TAB>  <TAB> elif msg.get(""error""): <TAB>  <TAB>  <TAB> self._close() <TAB>  <TAB>  <TAB> messagebox.showerror(""Autocomplete error"", msg.error, master=self) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._present_completions(msg.completions)",if msg . source != self . _get_prefix ( ) :,115
"def perform(self, recordUndo=True): <TAB> level = self.tool.editor.level <TAB> if isinstance(level, pymclevel.MCInfdevOldLevel): <MASK> if SpawnSettings.spawnProtection.get(): <TAB>  <TAB>  <TAB>  <TAB> raise SpawnPositionInvalid( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""You cannot have two air blocks at Y=63 and Y=64 in your spawn point's column. Additionally, you cannot have a solid block in the three blocks above your spawn point. It's weird, I know."" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> self.undoPos = level.playerSpawnPosition() <TAB> level.setPlayerSpawnPosition(self.pos) <TAB> self.tool.markerList.invalidate()","if not positionValid ( level , self . pos ) :",178
"def interact(self, case, interactor): <TAB> N = int(case.input_data()) <TAB> guesses = 0 <TAB> guess = 0 <TAB> while guess != N: <TAB>  <TAB> guess = interactor.readint(1, 2000000000) <TAB>  <TAB> guesses += 1 <MASK> interactor.writeln(""OK"") <TAB>  <TAB> elif guess > N: <TAB>  <TAB>  <TAB> interactor.writeln(""FLOATS"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> interactor.writeln(""SINKS"") <TAB> return guesses <= 31",if guess == N :,125
"def _get_service_list(include_enabled=True, include_disabled=False): <TAB> enabled_services = dict() <TAB> disabled_services = set() <TAB> lines = _list_services() <TAB> for line in lines: <TAB>  <TAB> if ""|"" not in line: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> service = [l.strip() for l in line.split(""|"")] <TAB>  <TAB> # enabled service should have runlevels <TAB>  <TAB> if service[1]: <TAB>  <TAB>  <TAB> if include_enabled: <TAB>  <TAB>  <TAB>  <TAB> enabled_services.update({service[0]: sorted(service[1].split())}) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # in any other case service is disabled <MASK> disabled_services.update({service[0]: []}) <TAB> return enabled_services, disabled_services",if include_disabled :,185
"def calc_callees(self): <TAB> if self.all_callees: <TAB>  <TAB> return <TAB> self.all_callees = all_callees = {} <TAB> for func, (cc, nc, tt, ct, callers) in self.stats.iteritems(): <MASK> all_callees[func] = {} <TAB>  <TAB> for func2, caller in callers.iteritems(): <TAB>  <TAB>  <TAB> if not func2 in all_callees: <TAB>  <TAB>  <TAB>  <TAB> all_callees[func2] = {} <TAB>  <TAB>  <TAB> all_callees[func2][func] = caller <TAB> return",if not func in all_callees :,138
"def process_path(self): <TAB> for project in PROJECTS: <MASK> continue <TAB>  <TAB> project = os.path.abspath(project) <TAB>  <TAB> package = os.path.basename(project) <TAB>  <TAB> self.projects_modules[package] = project <TAB>  <TAB> for root, dirs, files in os.walk(project, followlinks=True): <TAB>  <TAB>  <TAB> if ""__init__.py"" in files: <TAB>  <TAB>  <TAB>  <TAB> package = root[len(project) + 1 :].replace(os.path.sep, ""."") <TAB>  <TAB>  <TAB>  <TAB> self.projects_modules[package] = root",if PROJECTS [ project ] :,142
"def get_value(self, section, option): <TAB> if self._type: <TAB>  <TAB> if self._type == int: <TAB>  <TAB>  <TAB> getfunc = getattr(self._configparser, ""getint"") <MASK> getfunc = getattr(self._configparser, ""getfloat"") <TAB>  <TAB> elif self._type == bool: <TAB>  <TAB>  <TAB> getfunc = getattr(self._configparser, ""getboolean"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> getfunc = getattr(self._configparser, ""get"") <TAB>  <TAB> value = getfunc(section, option) <TAB> else: <TAB>  <TAB> log.debug(""No type message, so use the generic get"") <TAB>  <TAB> value = self._configparser.get(section, option) <TAB> value = self._type_convert_get(value) <TAB> return value",elif self . _type == float :,191
"def perform_rollover(self): <TAB> self.stream.close() <TAB> for x in xrange(self.backup_count - 1, 0, -1): <TAB>  <TAB> src = ""%s.%d"" % (self._filename, x) <TAB>  <TAB> dst = ""%s.%d"" % (self._filename, x + 1) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> rename(src, dst) <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> e = sys.exc_info()[1] <MASK> raise <TAB> rename(self._filename, self._filename + "".1"") <TAB> self._open(""w"")",if e . errno != errno . ENOENT :,151
"def relevantPart(l): <TAB> """"""the part of the vector that's above the cutoff."""""" <TAB> if targetcutoff != None: <TAB>  <TAB> for i, val in enumerate(l): <MASK> return l[: i + 1] <TAB>  <TAB>  <TAB> elif not minimize and val >= targetcutoff: <TAB>  <TAB>  <TAB>  <TAB> return l[: i + 1] <TAB> return l",if minimize and val <= targetcutoff :,94
"def send_video(self, frame_type, data): <TAB> """"""Only called by camera thread."""""" <TAB> with self._lock: <MASK> pass <TAB>  <TAB> elif self._state == ClientState.ENABLED_NEEDS_SPS: <TAB>  <TAB>  <TAB> if frame_type == NAL.SPS: <TAB>  <TAB>  <TAB>  <TAB> dropped = self._queue_video(data) <TAB>  <TAB>  <TAB>  <TAB> if not dropped: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._state = ClientState.ENABLED <TAB>  <TAB> elif self._state == ClientState.ENABLED: <TAB>  <TAB>  <TAB> dropped = self._queue_video(data) <TAB>  <TAB>  <TAB> if dropped: <TAB>  <TAB>  <TAB>  <TAB> self._state = ClientState.ENABLED_NEEDS_SPS <TAB>  <TAB> return self._state",if self . _state == ClientState . DISABLED :,179
"def OnCloseWindow(self, event): <TAB> pParentFrame = self.GetMDIParentFrame() <TAB> if pParentFrame: <TAB>  <TAB> if pParentFrame.GetActiveChild() == self: <TAB>  <TAB>  <TAB> pParentFrame.SetActiveChild(None) <TAB>  <TAB>  <TAB> pParentFrame.SetChildMenuBar(None) <TAB>  <TAB> pClientWindow = pParentFrame.GetClientWindow() <TAB>  <TAB> idx = pClientWindow.GetPageIndex(self) <MASK> pClientWindow.RemovePage(idx) <TAB> self.Destroy()",if idx != wx . NOT_FOUND :,135
"def new(): <TAB> if request.method == ""POST"": <TAB>  <TAB> if not request.form[""title""]: <TAB>  <TAB>  <TAB> flash(""Title is required"", ""error"") <MASK> flash(""Text is required"", ""error"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> todo = Todo(request.form[""title""], request.form[""text""]) <TAB>  <TAB>  <TAB> db.session.add(todo) <TAB>  <TAB>  <TAB> db.session.commit() <TAB>  <TAB>  <TAB> flash(u""Todo item was successfully created"") <TAB>  <TAB>  <TAB> return redirect(url_for(""show_all"")) <TAB> return render_template(""new.html"")","elif not request . form [ ""text"" ] :",150
"def preprocess_tokens(tokens): <TAB> else_count = 0 <TAB> if_stack = [] <TAB> for token in tokens: <TAB>  <TAB> if token.startswith(""#""): <TAB>  <TAB>  <TAB> if_stack.append(token) <TAB>  <TAB>  <TAB> else_count += token.count(""#else"") <TAB>  <TAB>  <TAB> if token.startswith(""#endif""): <TAB>  <TAB>  <TAB>  <TAB> while if_stack: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> last = if_stack.pop() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> else_count -= last.count(""#else"") <MASK> break <TAB>  <TAB> elif not else_count and not (if_stack and if_stack[-1].startswith(""#elif"")): <TAB>  <TAB>  <TAB> yield token <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for _ in range(token.count(""\n"")): <TAB>  <TAB>  <TAB>  <TAB> yield ""\n""","if last . startswith ( ""#if"" ) :",195
"def assert_same(self, val1, val2): <TAB> try: <TAB>  <TAB> self.assertEqual(val1, val2) <TAB> except AssertionError: <TAB>  <TAB> if val1 is pd.NaT: <TAB>  <TAB>  <TAB> self.assertTrue(val2 is pd.NaT) <MASK> self.assertTrue(np.isnan(val2)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise",elif np . isnan ( val1 ) :,98
"def check_msgq(self): <TAB> while not self.msgq.empty(): <TAB>  <TAB> msg = self.msgq.get() <TAB>  <TAB> if msg is None: <TAB>  <TAB>  <TAB> self.go_button.configure(state=NORMAL) <TAB>  <TAB>  <TAB> self.auto_button.configure(state=NORMAL) <TAB>  <TAB>  <TAB> self.cancel_button.configure(state=DISABLED) <MASK> self.sucker.stopit = 0 <TAB>  <TAB>  <TAB> self.top.bell() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.message(msg) <TAB> self.top.after(100, self.check_msgq)",if self . sucker :,156
"def save(self, *args, **kwargs): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> with transaction.atomic(): <TAB>  <TAB>  <TAB>  <TAB> return _base_save(self, *args, **kwargs) <TAB>  <TAB> except OperationalError as err: <MASK> logger.warning( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""%s, model: %s, args: %s, kwargs: %s"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> err, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.__class__, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> args, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> kwargs, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> sleep(0.5) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> raise","if ""database is locked"" in str ( err ) :",168
"def http_handler(self, conn, request, response): <TAB> if not request: <TAB>  <TAB> return <TAB> if self.ioc_bytes not in request.blob.data: <TAB>  <TAB> # indicator of (potential) compromise is not here <TAB>  <TAB> return <TAB> # there is an attempt to exploit Joomla! <TAB> # The Joomla exploit could be sent any HTTP header field <TAB> for hdr, val in request.headers.items(): <TAB>  <TAB> if self.ioc in val: <TAB>  <TAB>  <TAB> cmd = self.parse_cmd(val) <MASK> self.alert(""{} -> {}"".format(hdr, cmd), **conn.info()) <TAB>  <TAB>  <TAB>  <TAB> return conn, request, response",if cmd :,164
"def main(hostname, port, encryption, password): <TAB> notif = NSCANotifier(hostname, port, encryption, password) <TAB> for line in sys.stdin.readlines(): <TAB>  <TAB> line = line.rstrip() <MASK> continue <TAB>  <TAB> notif = line.split(opts.delimiter) <TAB>  <TAB> if len(notif) == 3: <TAB>  <TAB>  <TAB> # only host, rc, output <TAB>  <TAB>  <TAB> notif.insert(1, """")  # insert service <TAB>  <TAB> # line consists of host, service, rc, output <TAB>  <TAB> assert len(notif) == 4 <TAB>  <TAB> notif.svc_result(*notif)",if not line :,153
"def __call__(self, data): <TAB> for curr_ax in self._horz_axes: <MASK> coords = data.coords <TAB>  <TAB>  <TAB> coord_max = torch.max(coords[:, curr_ax]) <TAB>  <TAB>  <TAB> data.coords[:, curr_ax] = coord_max - coords[:, curr_ax] <TAB> return data",if random . random ( ) < self . _p :,91
"def get_included_serializers(serializer): <TAB> included_serializers = copy.copy( <TAB>  <TAB> getattr(serializer, ""included_serializers"", dict()) <TAB> ) <TAB> for name, value in iter(included_serializers.items()): <MASK> if value == ""self"": <TAB>  <TAB>  <TAB>  <TAB> included_serializers[name] = ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> serializer if isinstance(serializer, type) else serializer.__class__ <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> included_serializers[name] = import_class_from_dotted_path(value) <TAB> return included_serializers","if not isinstance ( value , type ) :",154
"def key_press_event(self, widget, event): <TAB> if event.type == Gdk.EventType.KEY_PRESS: <TAB>  <TAB> if event.keyval == Gdk.KEY_Delete: <TAB>  <TAB>  <TAB> model, paths = self.get_selection().get_selected_rows() <TAB>  <TAB>  <TAB> # reverse, to delete from the end <TAB>  <TAB>  <TAB> paths.sort(key=lambda x: -x[0]) <TAB>  <TAB>  <TAB> for path in paths: <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> node = model.get_iter(path) <TAB>  <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> node = None <MASK> model.remove(node) <TAB>  <TAB>  <TAB> return True",if node :,167
"def deep_layer_ids(self): <TAB> ret = [] <TAB> for layer_id in self.get_main_chain_layers(): <TAB>  <TAB> layer = self.layer_list[layer_id] <TAB>  <TAB> if is_layer(layer, ""GlobalAveragePooling""): <TAB>  <TAB>  <TAB> break <MASK> continue <TAB>  <TAB> ret.append(layer_id) <TAB> return ret","if is_layer ( layer , ""Add"" ) or is_layer ( layer , ""Concatenate"" ) :",109
"def get_next(self, start_from): <TAB> i, sub = start_from <TAB> assert sub in (0, 1, 2) <TAB> if sub == 0: <TAB>  <TAB> show_result = self.content[i].show_result(self.get_cell(i + 1)) <MASK> return self._get_at_pos((i, 1)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self._get_at_pos((i + 1, 0)) <TAB> elif sub == 1: <TAB>  <TAB> return self._get_at_pos((i, 2)) <TAB> else: <TAB>  <TAB> return self._get_at_pos((i + 1, 0))",if show_result :,161
"def __call__(self, pl, segment_info, create_watcher): <TAB> name = self.get_directory(segment_info) <TAB> if name: <TAB>  <TAB> repo = guess(path=name, create_watcher=create_watcher) <TAB>  <TAB> if repo is not None: <TAB>  <TAB>  <TAB> stash = getattr(repo, ""stash"", None) <TAB>  <TAB>  <TAB> if stash: <TAB>  <TAB>  <TAB>  <TAB> stashes = stash() <MASK> return [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""contents"": str(stashes), <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""highlight_groups"": [""stash""], <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""divider_highlight_group"": self.divider_highlight_group, <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ]",if stashes :,198
"def get_docstring_cix(parse_tree_node, cix_node): <TAB> if len(parse_tree_node.doc_lines) >= 1: <TAB>  <TAB> summarylines = util.parseDocSummary(parse_tree_node.doc_lines) <MASK> cix_node.set(""doc"", ""\n"".join(summarylines))",if len ( summarylines ) > 0 :,91
"def func(*events): <TAB> for ev in events: <TAB>  <TAB> if isinstance(ev.new_value, (float, int)): <TAB>  <TAB>  <TAB> res.append(ev.new_value) <MASK> if ev.source.val: <TAB>  <TAB>  <TAB>  <TAB> res.append(""id%i"" % ev.source.val) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> res.append(None)","elif ev . type == ""children"" :",101
"def _combine_lines(self, lines): <TAB> current = [] <TAB> for line in lines: <TAB>  <TAB> line = line.strip() <TAB>  <TAB> if not line.startswith(""- ""): <TAB>  <TAB>  <TAB> current.append(line) <TAB>  <TAB>  <TAB> continue <MASK> yield "" "".join(current) <TAB>  <TAB> current = [line[2:].strip()] <TAB> yield "" "".join(current)",if current :,95
"def predict_proba(self, devX): <TAB> self.model.eval() <TAB> probas = [] <TAB> with torch.no_grad(): <TAB>  <TAB> for i in range(0, len(devX), self.batch_size): <TAB>  <TAB>  <TAB> Xbatch = devX[i : i + self.batch_size] <MASK> probas = self.model(Xbatch).data.cpu().numpy() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> probas = np.concatenate( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> (probas, self.model(Xbatch).data.cpu().numpy()), axis=0 <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return probas",if len ( probas ) == 0 :,158
"def get_tokens_unprocessed(self, text): <TAB> for index, token, value in CppLexer.get_tokens_unprocessed(self, text): <TAB>  <TAB> if value in self.structure: <TAB>  <TAB>  <TAB> yield index, Name.Builtin, value <TAB>  <TAB> elif value in self.operators: <TAB>  <TAB>  <TAB> yield index, Operator, value <TAB>  <TAB> elif value in self.variables: <TAB>  <TAB>  <TAB> yield index, Keyword.Reserved, value <TAB>  <TAB> elif value in self.suppress_highlight: <TAB>  <TAB>  <TAB> yield index, Name, value <MASK> yield index, Name.Function, value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield index, token, value",elif value in self . functions :,160
"def __new__(metaclass, name, bases, dict): <TAB> hits = {} <TAB> for key, val in dict.iteritems(): <MASK> key = key[5:] <TAB>  <TAB>  <TAB> get, set = hits.get(key, (None, None)) <TAB>  <TAB>  <TAB> get = val <TAB>  <TAB>  <TAB> hits[key] = get, set <TAB>  <TAB> elif key.startswith(""_set_""): <TAB>  <TAB>  <TAB> key = key[5:] <TAB>  <TAB>  <TAB> get, set = hits.get(key, (None, None)) <TAB>  <TAB>  <TAB> set = val <TAB>  <TAB>  <TAB> hits[key] = get, set <TAB> for key, (get, set) in hits.iteritems(): <TAB>  <TAB> dict[key] = property(get, set) <TAB> return super(autoproperty, metaclass).__new__(metaclass, name, bases, dict)","if key . startswith ( ""_get_"" ) :",196
"def reject_times(jsons, lowest_wall): <TAB> print() <TAB> print(""Reject Times"") <TAB> print(""Main Time (h)\tRejected"") <TAB> for j in jsons: <MASK> continue <TAB>  <TAB> if j[""name""] != ""evaluate_choice"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if j[""value""] == ""new"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> print(""{:f}\t{}%"".format((j[""wall_time""] - lowest_wall), 1))","if j [ ""type"" ] != ""value"" :",125
"def add_callers(target, source): <TAB> """"""Combine two caller lists in a single list."""""" <TAB> new_callers = {} <TAB> for func, caller in target.items(): <TAB>  <TAB> new_callers[func] = caller <TAB> for func, caller in source.items(): <TAB>  <TAB> if func in new_callers: <MASK> # format used by cProfile <TAB>  <TAB>  <TAB>  <TAB> new_callers[func] = tuple( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> i + j for i, j in zip(caller, new_callers[func]) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> # format used by profile <TAB>  <TAB>  <TAB>  <TAB> new_callers[func] += caller <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_callers[func] = caller <TAB> return new_callers","if isinstance ( caller , tuple ) :",190
"def _fire(self): <TAB> if self._enabled: <MASK> if app.player.song is None: <TAB>  <TAB>  <TAB>  <TAB> app.player.next() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> app.player.paused = False <TAB> GLib.timeout_add(60000, self._longer_check)",if app . player . paused :,82
"def readlines(self, sizehint=None): <TAB> """"""Read lines from the request body and return them."""""" <TAB> if self.length is not None: <TAB>  <TAB> if sizehint is None: <TAB>  <TAB>  <TAB> sizehint = self.length - self.bytes_read <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sizehint = min(sizehint, self.length - self.bytes_read) <TAB> lines = [] <TAB> seen = 0 <TAB> while True: <TAB>  <TAB> line = self.readline() <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> lines.append(line) <TAB>  <TAB> seen += len(line) <MASK> break <TAB> return lines",if seen >= sizehint :,159
"def bodyString(self): <TAB> # This message should never be printed and we want to avoid crashing here! <TAB> if g.isUnicode(self._bodyString): <TAB>  <TAB> return self._bodyString <TAB> else: <MASK> self.body_unicode_warning = True <TAB>  <TAB>  <TAB> g.internalError(""not unicode:"", repr(self._bodyString), self._headString) <TAB>  <TAB> return g.toUnicode(self._bodyString)",if not self . body_unicode_warning :,113
"def proxy(self: ""DebugReprGenerator"", obj: t.Iterable, recursive: bool) -> str: <TAB> if recursive: <TAB>  <TAB> return _add_subclass_info(f""{left}...{right}"", obj, base) <TAB> buf = [left] <TAB> have_extended_section = False <TAB> for idx, item in enumerate(obj): <TAB>  <TAB> if idx: <TAB>  <TAB>  <TAB> buf.append("", "") <MASK> buf.append('<span class=""extended"">') <TAB>  <TAB>  <TAB> have_extended_section = True <TAB>  <TAB> buf.append(self.repr(item)) <TAB> if have_extended_section: <TAB>  <TAB> buf.append(""</span>"") <TAB> buf.append(right) <TAB> return _add_subclass_info("""".join(buf), obj, base)",if idx == limit :,185
"def _assert_series_equal(left_s, right_s, ignore_index=False, decimal=7): <TAB> # assert_series_equal doesn't like None... <TAB> if left_s is None or right_s is None: <TAB>  <TAB> assert left_s is None and right_s is None <TAB> else: <TAB>  <TAB> npt.assert_almost_equal(left_s.values, right_s.values, decimal=decimal) <MASK> pdt.assert_index_equal(left_s.index, right_s.index)",if not ignore_index :,135
"def _get_rss_data(self): <TAB> results = {""entries"": []} <TAB> for result in self.get_rss_feed(self.provider.urls[""rss""]).get(""entries"", []): <MASK> title = self.provider._process_title(result.title, result.link) <TAB>  <TAB>  <TAB> link = self.provider._process_link(result.link) <TAB>  <TAB>  <TAB> results[""entries""].append({""title"": title, ""link"": link}) <TAB> return results","if ""Series"" in result . category :",120
"def _cmp_(entity, other): <TAB> if entity is other: <TAB>  <TAB> return 0 <TAB> if isinstance(other, Entity): <TAB>  <TAB> pkval = entity._pkval_ <TAB>  <TAB> other_pkval = other._pkval_ <MASK> if other_pkval is None: <TAB>  <TAB>  <TAB>  <TAB> return -1 <TAB>  <TAB>  <TAB> result = cmp(pkval, other_pkval) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if other_pkval is not None: <TAB>  <TAB>  <TAB>  <TAB> return 1 <TAB>  <TAB>  <TAB> result = cmp(entity._newid_, other._newid_) <TAB>  <TAB> if result: <TAB>  <TAB>  <TAB> return result <TAB> return cmp(id(entity), id(other))",if pkval is not None :,168
"def captcha_check(page): <TAB> if not settings.CAPTCHA_DETECED and re.search(r""(?i)captcha"", page or """"): <TAB>  <TAB> for match in re.finditer(r""(?si)<form.+?</form>"", page): <MASK> settings.CAPTCHA_DETECED = True <TAB>  <TAB>  <TAB>  <TAB> warn_msg = ""Potential CAPTCHA protection mechanism detected"" <TAB>  <TAB>  <TAB>  <TAB> if re.search(r""(?i)<title>[^<]*CloudFlare"", page): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> warn_msg += "" (CloudFlare)."" <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> warn_msg += ""."" <TAB>  <TAB>  <TAB>  <TAB> print(settings.print_bold_warning_msg(warn_msg)) <TAB>  <TAB>  <TAB>  <TAB> break","if re . search ( r""(?i)captcha"" , match . group ( 0 ) ) :",196
"def _config_print(thing, buf, print_doc=True): <TAB> for cv in _config_var_list: <TAB>  <TAB> print(cv, file=buf) <MASK> print("" <TAB> Doc: "", cv.doc, file=buf) <TAB>  <TAB> print("" <TAB> Value: "", cv.__get__(True, None), file=buf) <TAB>  <TAB> print("""", file=buf)",if print_doc :,100
"def CreatePopupMenu(self): <TAB> if not self.menu: <TAB>  <TAB> self.menu = wx.Menu() <TAB>  <TAB> self.open_menu = self.menu.Append(self.TBMENU_OPEN, ""Open"") <TAB>  <TAB> self.setting_menu = self.menu.Append(self.TBMENU_SETTINGS, ""About"") <TAB>  <TAB> self.exit_menu = self.menu.Append(self.TBMENU_EXIT, ""Quit"") <MASK> self.open_menu.Enable(False) <TAB>  <TAB>  <TAB> self.setting_menu.Enable(False) <TAB>  <TAB>  <TAB> self.open_menu.SetText(""Loading..."") <TAB> return self.menu",if not self . enabled :,165
"def check_data(cls, values: Any) -> Any: <TAB> data = values.get(""data"") <TAB> if data: <TAB>  <TAB> state = values[""state""] <TAB>  <TAB> if state == NodeState.setting_up: <MASK> return values <TAB>  <TAB> if state == NodeState.done: <TAB>  <TAB>  <TAB> if isinstance(data, NodeDoneEventData): <TAB>  <TAB>  <TAB>  <TAB> return values <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> ""data for node state update event does not match state = %s"" % state <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> # For now, `data` is always optional. <TAB>  <TAB> return values","if isinstance ( data , NodeSettingUpEventData ) :",160
"def get_plot_range(values, all_values, option): <TAB> if option == ""System`Automatic"": <TAB>  <TAB> result = automatic_plot_range(values) <TAB> elif option == ""System`All"": <TAB>  <TAB> if not all_values: <TAB>  <TAB>  <TAB> result = [0, 1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result = min(all_values), max(all_values) <TAB> else: <TAB>  <TAB> result = option <TAB> if result[0] == result[1]: <TAB>  <TAB> value = result[0] <MASK> return 0, value * 2 <TAB>  <TAB> if value < 0: <TAB>  <TAB>  <TAB> return value * 2, 0 <TAB>  <TAB> return -1, 1 <TAB> return result",if value > 0 :,171
"def flatten_shows(shows): <TAB> for show in shows.itervalues(): <TAB>  <TAB> if ""seasons"" not in show: <TAB>  <TAB>  <TAB> yield show <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> show[""seasons""] = show[""seasons""].values() <TAB>  <TAB> for season in show[""seasons""]: <MASK> continue <TAB>  <TAB>  <TAB> season[""episodes""] = season[""episodes""].values() <TAB>  <TAB> yield show","if ""episodes"" not in season :",118
"def resources_to_link(self, resources): <TAB> if isinstance(self.UserPool, dict) and ""Ref"" in self.UserPool: <TAB>  <TAB> userpool_id = self.UserPool[""Ref""] <MASK> raise InvalidEventException( <TAB>  <TAB>  <TAB>  <TAB> self.logical_id, <TAB>  <TAB>  <TAB>  <TAB> ""Ref in Userpool is not a string."", <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if userpool_id in resources: <TAB>  <TAB>  <TAB> return {""userpool"": resources[userpool_id], ""userpool_id"": userpool_id} <TAB> raise InvalidEventException( <TAB>  <TAB> self.relative_id, <TAB>  <TAB> ""Cognito events must reference a Cognito UserPool in the same template."", <TAB> )","if not isinstance ( userpool_id , string_types ) :",183
"def warn_already_imported_files(self): <TAB> """"""Warn if files have already been imported that we will be measuring."""""" <TAB> if self.include or self.source or self.source_pkgs: <TAB>  <TAB> warned = set() <TAB>  <TAB> for mod in list(sys.modules.values()): <TAB>  <TAB>  <TAB> filename = getattr(mod, ""__file__"", None) <MASK> continue <TAB>  <TAB>  <TAB> if filename in warned: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> disp = self.should_trace(filename) <TAB>  <TAB>  <TAB> if disp.trace: <TAB>  <TAB>  <TAB>  <TAB> msg = ""Already imported a file that will be measured: {}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> filename <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> self.warn(msg, slug=""already-imported"") <TAB>  <TAB>  <TAB>  <TAB> warned.add(filename)",if filename is None :,199
"def escape_string(self, value): <TAB> value = EscapedString.promote(value) <TAB> value = value.expanduser() <TAB> result = """" <TAB> for is_literal, txt in value.strings: <MASK> txt = pipes.quote(txt) <TAB>  <TAB>  <TAB> if not txt.startswith(""'""): <TAB>  <TAB>  <TAB>  <TAB> txt = ""'%s'"" % txt <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> txt = txt.replace('""', '""\\""""') <TAB>  <TAB>  <TAB> txt = txt.replace(""!"", ""\\!"") <TAB>  <TAB>  <TAB> txt = '""%s""' % txt <TAB>  <TAB> result += txt <TAB> return result",if is_literal :,144
"def add_parameter(text): <TAB> nonlocal line_length <TAB> nonlocal first_parameter <TAB> if first_parameter: <TAB>  <TAB> s = text <TAB>  <TAB> first_parameter = False <TAB> else: <TAB>  <TAB> s = "" "" + text <MASK> add(""\n"") <TAB>  <TAB>  <TAB> add(indent) <TAB>  <TAB>  <TAB> line_length = len(indent) <TAB>  <TAB>  <TAB> s = text <TAB> line_length += len(s) <TAB> add(s)",if line_length + len ( s ) >= 72 :,120
"def makeDynamicTable(vw, va, maxva): <TAB> ret = [] <TAB> sname = ""elf.Elf%dDynamic"" % (vw.getPointerSize() * 8) <TAB> while va < maxva: <TAB>  <TAB> s = vw.makeStructure(va, sname) <TAB>  <TAB> ret.append(s) <TAB>  <TAB> dtag = s.d_tag <TAB>  <TAB> dtype = Elf.dt_types.get(dtag, ""Unknown Dynamic Type"") <TAB>  <TAB> vw.setComment(va, dtype) <TAB>  <TAB> va += len(s) <MASK> break <TAB> return ret",if dtag == Elf . DT_NULL :,154
"def _version_1(netcfg): <TAB> physdevs = [] <TAB> for ent in netcfg.get(""config"", {}): <TAB>  <TAB> if ent.get(""type"") != ""physical"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> mac = ent.get(""mac_address"") <MASK> continue <TAB>  <TAB> name = ent.get(""name"") <TAB>  <TAB> driver = ent.get(""params"", {}).get(""driver"") <TAB>  <TAB> device_id = ent.get(""params"", {}).get(""device_id"") <TAB>  <TAB> if not driver: <TAB>  <TAB>  <TAB> driver = device_driver(name) <TAB>  <TAB> if not device_id: <TAB>  <TAB>  <TAB> device_id = device_devid(name) <TAB>  <TAB> physdevs.append([mac, name, driver, device_id]) <TAB> return physdevs",if not mac :,186
"def collect_related_fields(self, model, accum, path, seen=None): <TAB> seen = seen or set() <TAB> path_str = ""__"".join(path) <TAB> for field in model._meta.sorted_fields: <TAB>  <TAB> if isinstance(field, ForeignKeyField) and field not in seen: <TAB>  <TAB>  <TAB> seen.add(field) <TAB>  <TAB>  <TAB> self.collect_related_fields( <TAB>  <TAB>  <TAB>  <TAB> field.rel_model, accum, path + [field.name], seen <TAB>  <TAB>  <TAB> ) <MASK> accum.setdefault((model, path_str), []) <TAB>  <TAB>  <TAB> accum[(model, path_str)].append(field) <TAB> return accum",elif model != self . model :,163
"def read(self, path=""/""): <TAB> url = self.URL + path <TAB> try: <TAB>  <TAB> kwargs = {} <MASK> kwargs = {""context"": self.ssl_ctx} <TAB>  <TAB> response = urllib2.urlopen(url, None, DEFAULT_XPC_SOCKET_TIMEOUT, **kwargs) <TAB> except urllib2.HTTPError: <TAB>  <TAB> response = sys.exc_info()[1] <TAB> result = ""%s %s"" % (response.code, response.msg), response.read() <TAB> # XXX: It looks like under PyPy this isn't directly closing the socket <TAB> # when SSL is in use. It takes a GC cycle to make that true. <TAB> response.close() <TAB> return result",if self . ssl_ctx is not None :,171
"def decode(data, a, parser, *b): <TAB> args = [] <TAB> for button in data[ModeModifier.PROFILE_KEYS[0]]: <MASK> args += [ <TAB>  <TAB>  <TAB>  <TAB> getattr(SCButtons, button), <TAB>  <TAB>  <TAB>  <TAB> parser.from_json_data(data[ModeModifier.PROFILE_KEYS[0]][button]), <TAB>  <TAB>  <TAB> ] <TAB> if a: <TAB>  <TAB> args += [a] <TAB> mm = ModeModifier(*args) <TAB> if ""name"" in data: <TAB>  <TAB> mm.name = data[""name""] <TAB> return mm","if hasattr ( SCButtons , button ) :",141
"def do_status(self): <TAB> iq = self.sd.get_obj(""input_queue"") <TAB> if iq: <TAB>  <TAB> print( <TAB>  <TAB>  <TAB> ""The input_queue (%s) contains approximately %s messages"" <TAB>  <TAB>  <TAB> % (iq.id, iq.count()) <TAB>  <TAB> ) <TAB> ob = self.sd.get_obj(""output_bucket"") <TAB> ib = self.sd.get_obj(""input_bucket"") <TAB> if ob: <MASK> return <TAB>  <TAB> total = 0 <TAB>  <TAB> for k in ob: <TAB>  <TAB>  <TAB> total += 1 <TAB>  <TAB> print(""The output_bucket (%s) contains %d keys"" % (ob.name, total))",if ib and ob . name == ib . name :,174
"def testBigramConstructionFromGenerator(self): <TAB> """"""Test Phrases bigram construction building when corpus is a generator"""""" <TAB> bigram1_seen = False <TAB> bigram2_seen = False <TAB> for s in self.bigram[gen_sentences()]: <TAB>  <TAB> if not bigram1_seen and ""response_time"" in s: <TAB>  <TAB>  <TAB> bigram1_seen = True <MASK> bigram2_seen = True <TAB>  <TAB> if bigram1_seen and bigram2_seen: <TAB>  <TAB>  <TAB> break <TAB> self.assertTrue(bigram1_seen and bigram2_seen)","if not bigram2_seen and ""graph_minors"" in s :",149
"def load_resources_if_needed(self, language): <TAB> if self.resources is None or self.fitted: <TAB>  <TAB> required_resources = None <MASK> required_resources = self.config.get_required_resources() <TAB>  <TAB> self.resources = load_resources(language, required_resources)",if self . config is not None :,81
"def _list(dir, args): <TAB> for root, dirs, files in os.walk(dir, followlinks=args.follow_links): <TAB>  <TAB> if root == dir: <TAB>  <TAB>  <TAB> _maybe_rm_guild_dir(dirs, args) <TAB>  <TAB> for name in dirs + files: <TAB>  <TAB>  <TAB> full_path = os.path.join(root, name) <TAB>  <TAB>  <TAB> rel_path = os.path.relpath(full_path, dir) <MASK> continue <TAB>  <TAB>  <TAB> yield _list_path(full_path, rel_path, args)","if not _match_path ( rel_path , args . path ) :",151
"def make_theano_batch(self, name=None, dtype=None, batch_size=None): <TAB> rval = tensor.matrix(name=name, dtype=dtype) <TAB> if config.compute_test_value != ""off"": <MASK> n = 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # TODO: try to extract constant scalar value from batch_size <TAB>  <TAB>  <TAB> n = 4 <TAB>  <TAB> rval.tag.test_value = self.get_origin_batch(batch_size=n, dtype=dtype) <TAB> return rval",if batch_size == 1 :,133
"def flatten_objs_inplace(df, cols): <TAB> for c in cols: <TAB>  <TAB> name = df[c].dtype.name <TAB>  <TAB> if name == ""category"": <TAB>  <TAB>  <TAB> # Avoid warning <TAB>  <TAB>  <TAB> df[c] = df[c].astype(str).where(~df[c].isnull(), df[c]) <MASK> df[c] = df[c].where(df[c].isnull(), df[c].astype(str))","elif name == ""object"" :",114
"def run(self): <TAB> global counter <TAB> while not self.event.is_set(): <TAB>  <TAB> with self.lock: <MASK> return <TAB>  <TAB>  <TAB> counter += 1 <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> x = phpInfoLFI(*self.args) <TAB>  <TAB>  <TAB> if self.event.is_set(): <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> if x: <TAB>  <TAB>  <TAB>  <TAB> print(""\nGot it! Shell created in /tmp/g"") <TAB>  <TAB>  <TAB>  <TAB> self.event.set() <TAB>  <TAB> except socket.error: <TAB>  <TAB>  <TAB> return",if counter >= self . maxattempts :,144
"def regularization(model: nn.Module, mode: str): <TAB> regu, counter = 0, 0 <TAB> for name, param in model.named_parameters(): <TAB>  <TAB> if ""mask_scores"" in name: <MASK> regu += torch.norm(torch.sigmoid(param), p=1) / param.numel() <TAB>  <TAB>  <TAB> elif mode == ""l0"": <TAB>  <TAB>  <TAB>  <TAB> regu += ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> torch.sigmoid(param - 2 / 3 * np.log(0.1 / 1.1)).sum() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> / param.numel() <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> ValueError(""Don't know this mode."") <TAB>  <TAB>  <TAB> counter += 1 <TAB> return regu / counter","if mode == ""l1"" :",187
"def get_header_values(directive): <TAB> if directive.name == ""add_header"": <TAB>  <TAB> return [directive.args[1]] <TAB> # See headers more documentation: https://github.com/openresty/headers-more-nginx-module#description <TAB> result = [] <TAB> skip_next = False <TAB> for arg in directive.args: <TAB>  <TAB> if arg in [""-s"", ""-t""]: <TAB>  <TAB>  <TAB> # Skip next value, because it's not a header <TAB>  <TAB>  <TAB> skip_next = True <TAB>  <TAB> elif arg.startswith(""-""): <TAB>  <TAB>  <TAB> # Skip any options <TAB>  <TAB>  <TAB> pass <MASK> skip_next = False <TAB>  <TAB> elif not skip_next: <TAB>  <TAB>  <TAB> result.append(arg) <TAB> return result",elif skip_next :,178
"def datestr(then, now=None, lang=None, relative=True): <TAB> """"""Internationalized version of web.datestr."""""" <TAB> lang = lang or web.ctx.get(""lang"") or ""en"" <TAB> if relative: <TAB>  <TAB> if now is None: <TAB>  <TAB>  <TAB> now = datetime.now() <TAB>  <TAB> delta = then - now <MASK> # Threshold from web.py <TAB>  <TAB>  <TAB> return babel.dates.format_timedelta( <TAB>  <TAB>  <TAB>  <TAB> delta, add_direction=True, locale=_get_babel_locale(lang) <TAB>  <TAB>  <TAB> ) <TAB> return format_date(then, lang=lang)",if abs ( delta . days ) < 4 :,156
"def umount_fuse(self): <TAB> with open(""/dev/null"", ""wb"") as devnull: <MASK> subprocess.call([""umount"", ""-l"", self.mnt_dir], stderr=devnull) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> subprocess.call([""fusermount"", ""-z"", ""-u"", self.mnt_dir], stderr=devnull)","if platform . system ( ) == ""Darwin"" :",96
"def interact(self, device, args, ice40_iface): <TAB> await ice40_iface.set_reset(True) <TAB> await super().interact(device, args, ice40_iface.lower) <TAB> await ice40_iface.set_reset(False) <TAB> if args.pin_done is not None: <TAB>  <TAB> for _ in range(200):  # Wait up to 2s <TAB>  <TAB>  <TAB> await asyncio.sleep(0.010)  # Poll every 10 ms <TAB>  <TAB>  <TAB> done = await ice40_iface.get_done() <MASK> break <TAB>  <TAB> if done: <TAB>  <TAB>  <TAB> self.logger.info(""FPGA configured from flash"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.logger.warning(""FPGA failed to configure after releasing reset"")",if done :,192
"def __get_hook_attrs__(self, obj): <TAB> for name in dir(obj): <TAB>  <TAB> val = getattr(obj, name, None) <MASK> continue <TAB>  <TAB> func_attrs = getattr(val, ""__apihook__"", None) <TAB>  <TAB> data_attrs = getattr(val, ""__datahook__"", None) <TAB>  <TAB> if func_attrs: <TAB>  <TAB>  <TAB> name, func, argc, conv, ordinal = func_attrs <TAB>  <TAB>  <TAB> obj.funcs[name] = (name, func, argc, conv, ordinal) <TAB>  <TAB>  <TAB> if ordinal: <TAB>  <TAB>  <TAB>  <TAB> obj.funcs[ordinal] = (name, func, argc, conv, ordinal) <TAB>  <TAB> elif data_attrs: <TAB>  <TAB>  <TAB> name, func = data_attrs <TAB>  <TAB>  <TAB> obj.data[name] = func",if val is None :,190
"def prompt_environment_name(prompt, values): <TAB> environment_name = None <TAB> while not environment_name: <TAB>  <TAB> environment_name = input(prompt) <MASK> print('""%s"" is not a valid environment name.' % environment_name) <TAB>  <TAB>  <TAB> environment_name = None <TAB> return environment_name",if not environment_name or values . index ( environment_name ) < 0 :,93
"def test_print_with_invalid_locale(self): <TAB> old_lang = os.environ.get(""LANG"") <TAB> os.environ[""LANG""] = """" <TAB> old_ctype = os.environ.get(""LC_CTYPE"") <TAB> os.environ[""LC_CTYPE""] = ""UTF-8"" <TAB> try: <TAB>  <TAB> ui.print_(u""something"") <TAB> except ValueError: <TAB>  <TAB> self.fail(u""ValueError during print"") <TAB> finally: <TAB>  <TAB> if old_lang: <TAB>  <TAB>  <TAB> os.environ[""LANG""] = old_lang <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> del os.environ[""LANG""] <MASK> os.environ[""LC_CTYPE""] = old_ctype <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> del os.environ[""LC_CTYPE""]",if old_ctype :,187
"def patched_imshow(*args, **kw): <TAB> ret = PatchedMatplotlib._patched_original_imshow(*args, **kw) <TAB> try: <TAB>  <TAB> from matplotlib import _pylab_helpers <TAB>  <TAB> # store on the plot that this is an imshow plot <TAB>  <TAB> stored_figure = _pylab_helpers.Gcf.get_active() <MASK> stored_figure._trains_is_imshow = ( <TAB>  <TAB>  <TAB>  <TAB> 1 <TAB>  <TAB>  <TAB>  <TAB> if not hasattr(stored_figure, ""_trains_is_imshow"") <TAB>  <TAB>  <TAB>  <TAB> else stored_figure._trains_is_imshow + 1 <TAB>  <TAB>  <TAB> ) <TAB> except Exception: <TAB>  <TAB> pass <TAB> return ret",if stored_figure :,167
"def __getFileObj(self, f): <TAB> """"""Safety handler to verify file-like objects"""""" <TAB> if not f: <TAB>  <TAB> raise ShapefileException(""No file-like object available."") <TAB> elif hasattr(f, ""write""): <TAB>  <TAB> return f <TAB> else: <TAB>  <TAB> pth = os.path.split(f)[0] <MASK> os.makedirs(pth) <TAB>  <TAB> return open(f, ""wb"")",if pth and not os . path . exists ( pth ) :,114
"def atomic_rename(src, dst): <TAB> # Try atomic or pseudo-atomic rename <TAB> if _rename(src, dst): <TAB>  <TAB> return <TAB> # Fall back to ""move away and replace"" <TAB> try: <TAB>  <TAB> os.rename(src, dst) <TAB> except OSError as err: <MASK> raise <TAB>  <TAB> old = ""{0}-{1:08x}"".format(dst, random.randint(0, sys.maxint)) <TAB>  <TAB> os.rename(dst, old) <TAB>  <TAB> os.rename(src, dst) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> os.unlink(old) <TAB>  <TAB> except Exception:  # pylint: disable=broad-except <TAB>  <TAB>  <TAB> pass",if err . errno != errno . EEXIST :,170
"def _timeout_for_target(self, target): <TAB> timeout = getattr(target, ""timeout"", None) <TAB> timeout_maximum = self.get_options().timeout_maximum <TAB> if timeout is not None and timeout_maximum is not None: <MASK> self.context.log.warn( <TAB>  <TAB>  <TAB>  <TAB> ""Warning: Timeout for {target} ({timeout}s) exceeds {timeout_maximum}s. Capping."".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> target=target.address.spec, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> timeout=timeout, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> timeout_maximum=timeout_maximum, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return timeout_maximum <TAB> return timeout",if timeout > timeout_maximum :,170
"def as_value_expr(val): <TAB> import pandas as pd <TAB> if not isinstance(val, Expr): <MASK> val = sequence(val) <TAB>  <TAB> elif isinstance(val, pd.Series): <TAB>  <TAB>  <TAB> val = sequence(list(val)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> val = literal(val) <TAB> return val","if isinstance ( val , ( tuple , list ) ) :",93
"def verify_result(self, result_data_path) -> bool: <TAB> result_json_file = None <TAB> for f in result_data_path: <TAB>  <TAB> if f.endswith(""result.json""): <TAB>  <TAB>  <TAB> result_json_file = f <TAB> if not result_json_file: <TAB>  <TAB> return False <TAB> with open(result_json_file, ""r"") as f: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> json_obj = json.loads(f.read()) <TAB>  <TAB> except json.decoder.JSONDecodeError: <TAB>  <TAB>  <TAB> return False <MASK> return False <TAB>  <TAB> return json_obj[""data""] == self.EXPECTED_OUTPUT","if ""data"" not in json_obj :",164
"def set_all_filters_active_state(self, is_active): <TAB> for i in range(1, len(self.tracks)): <TAB>  <TAB> track = self.tracks[i] <TAB>  <TAB> for clip in track.clips: <MASK> for f in clip.filters: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f.active = is_active <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f.update_mlt_disabled_value()",if clip . is_blanck_clip == False :,113
"def OnGetLineAttr(self, n): <TAB> if not self.title.startswith(""Unmatched""): <TAB>  <TAB> item = self.items[n] <TAB>  <TAB> ratio = float(item[5]) <MASK> return [LITTLE_ORANGE, 0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> red = int(164 * (1 - ratio)) <TAB>  <TAB>  <TAB> green = int(128 * ratio) <TAB>  <TAB>  <TAB> blue = int(255 * (1 - ratio)) <TAB>  <TAB>  <TAB> color = int(""0x%02x%02x%02x"" % (blue, green, red), 16) <TAB>  <TAB> return [color, 0] <TAB> return [0xFFFFFF, 0]",if self . seems_false_positive ( item ) :,170
"def dispatch(self, name): <TAB> while True: <TAB>  <TAB> self.tokeniser() <MASK> if self._run(name): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> if self.tokeniser.end == ""{"": <TAB>  <TAB>  <TAB> if self._enter(name): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> if self.tokeniser.end == ""}"": <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> if not self.tokeniser.end:  # finished <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> return self.error.set(""invalid syntax line %d"" % self.tokeniser.index_line) <TAB> return False","if self . tokeniser . end == "";"" :",154
"def collect(results): <TAB> verified = set() <TAB> corrupt = set() <TAB> incompatible = set() <TAB> for succ, sharenum, whynot in results: <TAB>  <TAB> if succ: <TAB>  <TAB>  <TAB> verified.add(sharenum) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if whynot == ""corrupt"": <TAB>  <TAB>  <TAB>  <TAB> corrupt.add(sharenum) <MASK> incompatible.add(sharenum) <TAB> return (verified, s, corrupt, incompatible, success)","elif whynot == ""incompatible"" :",119
"def __init__(self, *filename): <TAB> import pstats <TAB> try: <TAB>  <TAB> self.stats = pstats.Stats(*filename) <TAB> except ValueError: <MASK> sys.stderr.write(""error: failed to load %s\n"" % "", "".join(filename)) <TAB>  <TAB>  <TAB> sys.exit(1) <TAB>  <TAB> import hotshot.stats <TAB>  <TAB> self.stats = hotshot.stats.load(filename[0]) <TAB> self.profile = Profile() <TAB> self.function_ids = {}",if PYTHON_3 :,124
"def close(self): <TAB> """"""Close the connection without assuming anything about it."""""" <TAB> try: <TAB>  <TAB> file = self.file <TAB>  <TAB> self.file = None <TAB>  <TAB> if file is not None: <TAB>  <TAB>  <TAB> file.close() <TAB> finally: <TAB>  <TAB> sock = self.sock <TAB>  <TAB> self.sock = None <TAB>  <TAB> if sock is not None: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> sock.shutdown(socket.SHUT_RDWR) <TAB>  <TAB>  <TAB> except OSError as e: <TAB>  <TAB>  <TAB>  <TAB> # The server might already have closed the connection <MASK> raise <TAB>  <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB>  <TAB> sock.close()",if e . errno != errno . ENOTCONN :,167
"def do_longs(opts, opt, longopts, args): <TAB> try: <TAB>  <TAB> i = opt.index(""="") <TAB> except ValueError: <TAB>  <TAB> optarg = None <TAB> else: <TAB>  <TAB> opt, optarg = opt[:i], opt[i + 1 :] <TAB> has_arg, opt = long_has_args(opt, longopts) <TAB> if has_arg: <MASK> if not args: <TAB>  <TAB>  <TAB>  <TAB> raise GetoptError(""option --%s requires argument"" % opt, opt) <TAB>  <TAB>  <TAB> optarg, args = args[0], args[1:] <TAB> elif optarg is not None: <TAB>  <TAB> raise GetoptError(""option --%s must not have an argument"" % opt, opt) <TAB> opts.append((""--"" + opt, optarg or """")) <TAB> return opts, args",if optarg is None :,184
"def detect(stream): <TAB> """"""Returns True if the given stream is valid DBF"""""" <TAB> # _dbf = dbf.Table(StringIO(stream)) <TAB> try: <MASK> if type(stream) is not bytes: <TAB>  <TAB>  <TAB>  <TAB> stream = bytes(stream, ""utf-8"") <TAB>  <TAB>  <TAB> _dbf = dbf.Dbf(io.BytesIO(stream), readOnly=True) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _dbf = dbf.Dbf(StringIO(stream), readOnly=True) <TAB>  <TAB> return True <TAB> except Exception: <TAB>  <TAB> return False",if is_py3 :,146
"def add_root(self, path): <TAB> path = os.path.realpath(path) <TAB> if os.path.isdir(path): <TAB>  <TAB> for filepath in find_files(path, allowed_extensions=("".py"",)): <MASK> self.log.info(""Skipping: %s"" % filepath) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> self.filenames.add(filepath) <TAB> elif path.endswith("".py""): <TAB>  <TAB> self.filenames.add(path)","if filepath . startswith ( ""test_"" ) :",121
"def readline(self, size=-1): <TAB> if size < 0: <TAB>  <TAB> size = None <TAB> str = """" <TAB> chr = None <TAB> while chr != ""\n"": <MASK> break <TAB>  <TAB> chr = self.sslobj.read(1) <TAB>  <TAB> if not chr: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> str += chr <TAB> return str",if size is not None and len ( str ) >= size :,99
"def print_cross_files( <TAB> self, bbpath, keyword, layername, f, needed_filename, show_filenames, ignore_layers): <TAB> """"""Print the depends that crosses a layer boundary"""""" <TAB> needed_file = bb.utils.which(bbpath, needed_filename) <TAB> if needed_file: <TAB>  <TAB> # Which layer is this file from <TAB>  <TAB> needed_layername = self.get_file_layer(needed_file) <TAB>  <TAB> if needed_layername != layername and not needed_layername in ignore_layers: <MASK> f = self.remove_layer_prefix(f) <TAB>  <TAB>  <TAB>  <TAB> needed_file = self.remove_layer_prefix(needed_file) <TAB>  <TAB>  <TAB> logger.plain(""%s %s %s"" % (f, keyword, needed_file))",if not show_filenames :,197
"def set_value(self, value): <TAB> with self.valueLock: <TAB>  <TAB> self.__value = value <TAB>  <TAB> # walk the call chain if the result is not an exception, otherwise invoke the errorhandler (if any) <MASK> if self.exceptionhandler: <TAB>  <TAB>  <TAB>  <TAB> self.exceptionhandler(value.exception) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for call, args, kwargs in self.callchain: <TAB>  <TAB>  <TAB>  <TAB> call = functools.partial(call, self.__value) <TAB>  <TAB>  <TAB>  <TAB> self.__value = call(*args, **kwargs) <TAB>  <TAB>  <TAB>  <TAB> if isinstance(self.__value, _ExceptionWrapper): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> self.callchain = [] <TAB>  <TAB> self.__ready.set()","if isinstance ( value , _ExceptionWrapper ) :",179
"def get_all_languages(): <TAB> results = [] <TAB> for path in os.listdir(os.path.join(MODULE_ROOT, ""locale"")): <MASK> continue <TAB>  <TAB> if ""_"" in path: <TAB>  <TAB>  <TAB> pre, post = path.split(""_"", 1) <TAB>  <TAB>  <TAB> path = ""{}-{}"".format(pre, post.lower()) <TAB>  <TAB> results.append(path) <TAB> return results","if path . startswith ( ""."" ) :",99
"def switchTo(self, url): <TAB> exists = False <TAB> for i in range(0, self.stackedWidget.count()): <MASK> self.stackedWidget.setCurrentIndex(i) <TAB>  <TAB>  <TAB> self.quicklist(self.current().listChannels()) <TAB>  <TAB>  <TAB> self.current().setFocus() <TAB>  <TAB>  <TAB> self.leftPane.click(i) <TAB>  <TAB>  <TAB> self.clearMemory() <TAB>  <TAB>  <TAB> exists = True <TAB>  <TAB>  <TAB> break <TAB> if not exists: <TAB>  <TAB> self.addWrapper(url)",if self . stackedWidget . widget ( i ) . url ( ) . toString ( ) . startswith ( url ) :,145
"def find_occurrences(self, resource=None, pymodule=None): <TAB> """"""Generate `Occurrence` instances"""""" <TAB> tools = _OccurrenceToolsCreator( <TAB>  <TAB> self.pycore, resource=resource, pymodule=pymodule, docs=self.docs <TAB> ) <TAB> for offset in self._textual_finder.find_offsets(tools.source_code): <TAB>  <TAB> occurrence = Occurrence(tools, offset) <TAB>  <TAB> for filter in self.filters: <TAB>  <TAB>  <TAB> result = filter(occurrence) <MASK> continue <TAB>  <TAB>  <TAB> if result: <TAB>  <TAB>  <TAB>  <TAB> yield occurrence <TAB>  <TAB>  <TAB> break",if result is None :,152
"def _setJustify(self, value): <TAB> if value is None: <TAB>  <TAB> self._justify = None <TAB> else: <MASK> raise TextFormatException(f""Not a supported justification: {value}"") <TAB>  <TAB> self._justify = value.lower()","if value . lower ( ) not in ( ""left"" , ""center"" , ""right"" , ""full"" ) :",83
"def on_app_selection_changed(self, widget): <TAB> model, iter = widget.get_selected() <TAB> if iter: <TAB>  <TAB> appinfo = model.get_value(iter, self.ADD_TYPE_APPINFO) <TAB>  <TAB> description = appinfo.get_description() <MASK> self.description_label.set_label(description) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.description_label.set_label("""") <TAB>  <TAB> self.command_entry.set_text(appinfo.get_executable())",if description :,127
"def run_unittest(*classes): <TAB> """"""Run tests from unittest.TestCase-derived classes."""""" <TAB> valid_types = (unittest.TestSuite, unittest.TestCase) <TAB> suite = unittest.TestSuite() <TAB> for cls in classes: <TAB>  <TAB> if isinstance(cls, str): <TAB>  <TAB>  <TAB> if cls in sys.modules: <TAB>  <TAB>  <TAB>  <TAB> suite.addTest(unittest.findTestCases(sys.modules[cls])) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""str arguments must be keys in sys.modules"") <MASK> suite.addTest(cls) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> suite.addTest(unittest.makeSuite(cls)) <TAB> _run_suite(suite)","elif isinstance ( cls , valid_types ) :",171
def run(self): <TAB> try: <MASK> self.pagekite_thread = PagekiteThread(self) <TAB>  <TAB>  <TAB> self.pagekite_thread.start() <TAB>  <TAB> self.launch_xmlrpc_server() <TAB> finally: <TAB>  <TAB> self.quitting = True,if self . pagekite_args :,79
"def __init__(self, argument): <TAB> allowed = (""+"", ""-"") <TAB> self.sum = int(argument) <TAB> if argument and argument[0] in allowed: <TAB>  <TAB> if self.sum < 0: <TAB>  <TAB>  <TAB> self.operation = ""withdraw"" <MASK> self.operation = ""deposit"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise RuntimeError <TAB>  <TAB> self.sum = abs(self.sum) <TAB> elif argument.isdigit(): <TAB>  <TAB> self.operation = ""set"" <TAB> else: <TAB>  <TAB> raise RuntimeError",elif self . sum > 0 :,131
"def _get_age(self, fileid, speaker, month): <TAB> xmldoc = ElementTree.parse(fileid).getroot() <TAB> for pat in xmldoc.findall("".//{%s}Participants/{%s}participant"" % (NS, NS)): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if pat.get(""id"") == speaker: <TAB>  <TAB>  <TAB>  <TAB> age = pat.get(""age"") <MASK> age = self.convert_age(age) <TAB>  <TAB>  <TAB>  <TAB> return age <TAB>  <TAB> # some files don't have age data <TAB>  <TAB> except (TypeError, AttributeError) as e: <TAB>  <TAB>  <TAB> return None",if month :,145
"def find_nonterminal_transitions(C): <TAB> trans = [] <TAB> for state in range(len(C)): <TAB>  <TAB> for p in C[state]: <MASK> t = (state, p.prod[p.lr_index + 1]) <TAB>  <TAB>  <TAB>  <TAB> if Nonterminals.has_key(t[1]): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if t not in trans: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> trans.append(t) <TAB>  <TAB> state = state + 1 <TAB> return trans",if p . lr_index < p . len - 1 :,129
"def _resolve_address(self, destaddr, default, use_remote_dns): <TAB> try: <TAB>  <TAB> return socket.inet_aton(destaddr) <TAB> except socket.error: <MASK> return default <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return socket.inet_aton(socket.gethostbyname(destaddr))",if use_remote_dns and self . _proxy . remote_dns :,96
"def read_file(self, file): <TAB> assert file.endswith("".gz""), ""[ERROR] %s is not a gzip file"" % file <TAB> file_path = self.data_dir + ""/"" + file <TAB> with gzip.open(file_path, ""rb"") as f: <TAB>  <TAB> for line in f: <TAB>  <TAB>  <TAB> parsed_line = self.parse_line(line, max_seq_len=self.max_seq_len) <MASK> continue <TAB>  <TAB>  <TAB> yield parsed_line",if parsed_line is None :,127
"def combine_stats( <TAB> overall_stats: Dict[str, float], new_stats: Dict[str, Any]) -> Dict[str, float]: <TAB> INTERESTING_KEYS = [""build_time"", ""gc_time""] <TAB> # For now, we only support float keys <TAB> relevant_stats = {}  # type: Dict[str, float] <TAB> for key in INTERESTING_KEYS: <MASK> value = float(new_stats[key]) <TAB>  <TAB>  <TAB> relevant_stats[key] = value <TAB>  <TAB>  <TAB> overall_stats[key] = overall_stats.get(key, 0.0) + value <TAB> return relevant_stats",if key in new_stats :,160
"def describe(self, context): <TAB> if self.name: <TAB>  <TAB> return self.name <TAB> # Two special, most used cases of dpad <TAB> wsad = [a.button for a in self.actions if isinstance(a, ButtonAction)] <TAB> if len(wsad) == 4: <TAB>  <TAB> if wsad == [Keys.KEY_UP, Keys.KEY_DOWN, Keys.KEY_LEFT, Keys.KEY_RIGHT]: <TAB>  <TAB>  <TAB> return _(""Arrows"") <MASK> return _(""WSAD"") <TAB> return ""DPad""","if wsad == [ Keys . KEY_W , Keys . KEY_S , Keys . KEY_A , Keys . KEY_D ] :",157
"def get_conditional(self, **cols): <TAB> ret = [] <TAB> matches = 0 <TAB> for i in range(len(self.liststore)): <TAB>  <TAB> row = self.get(i) <TAB>  <TAB> for k, v in cols.items(): <TAB>  <TAB>  <TAB> if row[k] == v: <TAB>  <TAB>  <TAB>  <TAB> matches += 1 <MASK> ret.append(i) <TAB>  <TAB> matches = 0 <TAB> return ret",if matches == len ( cols ) :,107
"def post(self, request, *args, **kwargs): <TAB> self.comment_obj = get_object_or_404(Comment, id=request.POST.get(""commentid"")) <TAB> if request.user == self.comment_obj.commented_by: <TAB>  <TAB> form = InvoiceCommentForm(request.POST, instance=self.comment_obj) <MASK> return self.form_valid(form) <TAB>  <TAB> return self.form_invalid(form) <TAB> data = {""error"": ""You don't have permission to edit this comment.""} <TAB> return JsonResponse(data)",if form . is_valid ( ) :,142
"def get_max_column_name_length(): <TAB> allowed_len = None <TAB> db_alias = None <TAB> for db in settings.DATABASES.keys(): <TAB>  <TAB> connection = connections[db] <TAB>  <TAB> max_name_length = connection.ops.max_name_length() <TAB>  <TAB> if max_name_length is None or connection.features.truncates_names: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> else: <MASK> allowed_len = max_name_length <TAB>  <TAB>  <TAB>  <TAB> db_alias = db <TAB>  <TAB>  <TAB> elif max_name_length < allowed_len: <TAB>  <TAB>  <TAB>  <TAB> allowed_len = max_name_length <TAB>  <TAB>  <TAB>  <TAB> db_alias = db <TAB> return (allowed_len, db_alias)",if allowed_len is None :,183
"def _validate_resource_like_for_formats(self, key): <TAB> for statement in self._statements: <MASK> if isinstance(statement[key], string_types): <TAB>  <TAB>  <TAB>  <TAB> self._validate_resource_format(statement[key]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> for resource in sorted(statement[key], reverse=True): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._validate_resource_format(resource) <TAB>  <TAB>  <TAB> if self._resource_error == """": <TAB>  <TAB>  <TAB>  <TAB> IAMPolicyDocumentValidator._legacy_parse_resource_like(statement, key)",if key in statement :,142
"def setup_connection(self, client_socket): <TAB> if self.block_non_clients: <MASK> self.logger.debug( <TAB>  <TAB>  <TAB>  <TAB> ""Connection from non-client %s blocked"", client_socket.getpeername()[0] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> client_socket.close() <TAB>  <TAB>  <TAB> return <TAB> connection = self.connection_class( <TAB>  <TAB> self, <TAB>  <TAB> client_socket, <TAB>  <TAB> self.handler_selector, <TAB>  <TAB> self.ssl_handler_selector, <TAB>  <TAB> self.data_handler_selector, <TAB>  <TAB> self.app_blame, <TAB> ) <TAB> if connection.start(): <TAB>  <TAB> self.set_select_fds(connection)",if not self . app_blame . client_available ( client_socket . getpeername ( ) [ 0 ] ) :,190
"def find_module(self, fullname, path=None): <TAB> file_path = find_file(fullname) <TAB> if file_path: <TAB>  <TAB> pyc_file_path = Path(file_path.with_suffix("".pyc"")) <TAB>  <TAB> if pyc_file_path.exists(): <TAB>  <TAB>  <TAB> pyc_file_mtime = pyc_file_path.stat().st_mtime <TAB>  <TAB>  <TAB> mochi_file_mtime = file_path.stat().st_mtime <MASK> return Loader(file_path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return Loader(file_path)",if mochi_file_mtime > pyc_file_mtime :,153
"def release(provider, connection, cache=None): <TAB> if cache is not None: <TAB>  <TAB> db_session = cache.db_session <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> cursor = connection.cursor() <TAB>  <TAB>  <TAB>  <TAB> sql = ""PRAGMA foreign_keys = true"" <TAB>  <TAB>  <TAB>  <TAB> if core.local.debug: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> log_orm(sql) <TAB>  <TAB>  <TAB>  <TAB> cursor.execute(sql) <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> provider.pool.drop(connection) <TAB>  <TAB>  <TAB>  <TAB> raise <TAB> DBAPIProvider.release(provider, connection, cache)",if db_session is not None and db_session . ddl and cache . saved_fk_state :,162
"def run(self): <TAB> while True: <TAB>  <TAB> # Get a callable from the queue. <TAB>  <TAB> task, args, kwargs = self.queue.get() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> # Stop the worker by sending it a task of None. <TAB>  <TAB>  <TAB> if task is None: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> on_error = kwargs.pop(""on_error"") <MASK> on_error = lambda x: None <TAB>  <TAB>  <TAB> task(*args, **kwargs) <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> print(e) <TAB>  <TAB>  <TAB> logging.error(""Worker raised %s"", e) <TAB>  <TAB>  <TAB> traceback.print_exc() <TAB>  <TAB>  <TAB> on_error(e) <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self.queue.task_done()",if on_error is None :,192
"def get_pixbuf(cls, size=32): <TAB> """"""Return gtk Pixbuf"""""" <TAB> if cls.__icon__: <MASK> if cls.__icon__.endswith("".png""): <TAB>  <TAB>  <TAB>  <TAB> icon_path = os.path.join(DATA_DIR, ""pixmaps"", cls.__icon__) <TAB>  <TAB>  <TAB>  <TAB> pixbuf = GdkPixbuf.Pixbuf.new_from_file(icon_path) <TAB>  <TAB>  <TAB>  <TAB> pixbuf = pixbuf.scale_simple(size, size, GdkPixbuf.InterpType.BILINEAR) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> pixbuf = icon.get_from_name(cls.__icon__, size=size) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pixbuf = icon.get_from_list(cls.__icon__, size=size) <TAB>  <TAB> return pixbuf",if type ( cls . __icon__ ) != list :,195
"def chainMatch(self, chain, group, tags): <TAB> info = self.flattenInfo(chain.info[group]) <TAB> found_tags = [] <TAB> for tag, accepted in tags.items(): <TAB>  <TAB> values = [self.simplifyValue(x) for x in info.get(tag, [None])] <MASK> found_tags.append(tag) <TAB> log.debug(""tags found: %s, required: %s"" % (found_tags, tags.keys())) <TAB> if set(tags.keys()) == set(found_tags): <TAB>  <TAB> return True <TAB> return all([key in found_tags for key, value in tags.items()])",if any ( [ val in accepted for val in values ] ) :,164
"def available_dataset_ids(self): <TAB> for ds_id in self.all_dataset_ids: <TAB>  <TAB> fts = self.ids[ds_id][""file_type""] <TAB>  <TAB> if isinstance(fts, str) and fts in self.file_handlers: <TAB>  <TAB>  <TAB> yield ds_id <MASK> yield ds_id",elif any ( ft in self . file_handlers for ft in fts ) :,99
"def is_parent_of(self, parent, grandchild): <TAB> """"""Check if grandchild is a subnode of parent."""""" <TAB> if grandchild == parent or grandchild in self.chain[parent].get_succ(): <TAB>  <TAB> return True <TAB> else: <TAB>  <TAB> for sn in self.chain[parent].get_succ(): <MASK> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False","if self . is_parent_of ( sn , grandchild ) :",105
"def prefix_shared_name_attributes(meta_graph, absolute_import_scope): <TAB> """"""In-place prefixes shared_name attributes of nodes."""""" <TAB> shared_name_attr = ""shared_name"" <TAB> for node in meta_graph.graph_def.node: <TAB>  <TAB> shared_name_value = node.attr.get(shared_name_attr, None) <MASK> if shared_name_value.s: <TAB>  <TAB>  <TAB>  <TAB> node.attr[shared_name_attr].s = tf.compat.as_bytes( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> prepend_name_scope( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> shared_name_value.s, import_scope=absolute_import_scope <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> )","if shared_name_value and shared_name_value . HasField ( ""s"" ) :",193
"def __focus(self, item): <TAB> """"""Called when focus item has changed"""""" <TAB> cols = self.__get_display_columns() <TAB> for col in cols: <TAB>  <TAB> self.__event_info = (col, item) <TAB>  <TAB> self.event_generate(""<<TreeviewInplaceEdit>>"") <MASK> w = self._inplace_widgets[col] <TAB>  <TAB>  <TAB> w.bind(""<Key-Tab>"", lambda e: w.tk_focusNext().focus_set()) <TAB>  <TAB>  <TAB> w.bind(""<Shift-Key-Tab>"", lambda e: w.tk_focusPrev().focus_set())",if col in self . _inplace_widgets :,147
"def filter_discount_type( <TAB> qs: VoucherQueryset, _, value: List[VoucherDiscountType]) -> VoucherQueryset: <TAB> if value: <TAB>  <TAB> query = Q() <TAB>  <TAB> if VoucherDiscountType.FIXED in value: <TAB>  <TAB>  <TAB> query |= Q( <TAB>  <TAB>  <TAB>  <TAB> discount_value_type=VoucherDiscountType.FIXED.value  # type: ignore <TAB>  <TAB>  <TAB> ) <MASK> query |= Q( <TAB>  <TAB>  <TAB>  <TAB> discount_value_type=VoucherDiscountType.PERCENTAGE.value  # type: ignore <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if VoucherDiscountType.SHIPPING in value: <TAB>  <TAB>  <TAB> query |= Q(type=VoucherDiscountType.SHIPPING) <TAB>  <TAB> qs = qs.filter(query).distinct() <TAB> return qs",if VoucherDiscountType . PERCENTAGE in value :,166
"def clean_data(data: dict) -> dict: <TAB> """"""Removes all empty values and converts tuples into lists"""""" <TAB> new_data = {} <TAB> for key, value in data.items(): <TAB>  <TAB> # Verify that only explicitly passed args get passed on <TAB>  <TAB> if not isinstance(value, bool) and not value: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # Multiple choice command are passed as tuples, convert to list to match schema <MASK> value = list(value) <TAB>  <TAB> new_data[key] = value <TAB> return new_data","if isinstance ( value , tuple ) :",132
"def _find_cmd_in_json(self, id, json_object): <TAB> if isinstance(json_object, list): <TAB>  <TAB> for elem in json_object: <TAB>  <TAB>  <TAB> cmd = self._find_cmd_in_json(id, elem) <MASK> return cmd <TAB> elif isinstance(json_object, dict): <TAB>  <TAB> if ""id"" in json_object and json_object[""id""] == id: <TAB>  <TAB>  <TAB> return json_object <TAB>  <TAB> elif ""children"" in json_object: <TAB>  <TAB>  <TAB> return self._find_cmd_in_json(id, json_object[""children""]) <TAB> return None",if cmd :,153
"def _get_direction(self) -> str: <TAB> direction = str(self._context[""direction""]) <TAB> if direction == ""dynamictop"" or direction == ""dynamicbottom"": <TAB>  <TAB> self._update_displayed_texts() <TAB>  <TAB> winwidth = self._vim.call(""winwidth"", 0) <TAB>  <TAB> is_fit = not [ <TAB>  <TAB>  <TAB> x for x in self._displayed_texts if self._vim.call(""strwidth"", x) > winwidth <TAB>  <TAB> ] <MASK> direction = ""aboveleft"" if is_fit else ""topleft"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> direction = ""belowright"" if is_fit else ""botright"" <TAB> return direction","if direction == ""dynamictop"" :",170
"def __init__( <TAB> self, <TAB> fixed: MQTTFixedHeader = None, <TAB> variable_header: ConnackVariableHeader = None, <TAB> payload=None,): <TAB> if fixed is None: <TAB>  <TAB> header = MQTTFixedHeader(CONNACK, 0x00) <TAB> else: <MASK> raise HBMQTTException( <TAB>  <TAB>  <TAB>  <TAB> ""Invalid fixed packet type %s for ConnackPacket init"" <TAB>  <TAB>  <TAB>  <TAB> % fixed.packet_type <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> header = fixed <TAB> super().__init__(header) <TAB> self.variable_header = variable_header <TAB> self.payload = None",if fixed . packet_type is not CONNACK :,167
"def start_response(status, response_headers, exc_info=None): <TAB> if exc_info: <TAB>  <TAB> try: <MASK> # Re-raise original exception if headers sent <TAB>  <TAB>  <TAB>  <TAB> six.reraise(exc_info[0], exc_info[1], exc_info[2]) <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> exc_info = None  # avoid dangling circular ref <TAB> elif headers_set: <TAB>  <TAB> raise AssertionError(""Headers already set!"") <TAB> headers_set[:] = [status, response_headers] <TAB> return write",if headers_sent :,136
"def ensure_fromlist(self, module, fromlist, recursive=0):  # pragma: nocover <TAB> self.msg(4, ""ensure_fromlist"", module, fromlist, recursive) <TAB> for sub in fromlist: <TAB>  <TAB> if sub == ""*"": <TAB>  <TAB>  <TAB> if not recursive: <TAB>  <TAB>  <TAB>  <TAB> submodules = self.find_all_submodules(module) <TAB>  <TAB>  <TAB>  <TAB> if submodules: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.ensure_fromlist(module, submodules, 1) <TAB>  <TAB> elif not hasattr(module, sub): <TAB>  <TAB>  <TAB> subname = ""%s.%s"" % (module.__name__, sub) <TAB>  <TAB>  <TAB> submod = self.import_module(sub, subname, module) <MASK> raise ImportError(""No module named "" + subname)",if not submod :,185
"def find_symlinks(root): <TAB> for dirpath, dirnames, filenames in os.walk(root): <TAB>  <TAB> for name in dirnames + filenames: <TAB>  <TAB>  <TAB> pathname = os.path.join(dirpath, name) <TAB>  <TAB>  <TAB> if is_symlink(pathname): <TAB>  <TAB>  <TAB>  <TAB> yield pathname <TAB>  <TAB>  <TAB>  <TAB> # don't traverse symlinks <MASK> dirnames.remove(name)",if name in dirnames :,100
"def adopt_attr_modules(cache, queue, suffix, subvalue): <TAB> if isinstance(subvalue, Module): <MASK> # module was passed from outside. It needs to be cloned <TAB>  <TAB>  <TAB> key = id(subvalue) <TAB>  <TAB>  <TAB> if key not in cache: <TAB>  <TAB>  <TAB>  <TAB> cache[key] = subvalue.clone() <TAB>  <TAB>  <TAB> subvalue = cache[key] <TAB>  <TAB> if subvalue.name is None: <TAB>  <TAB>  <TAB> object.__setattr__(subvalue, ""parent"", self) <TAB>  <TAB>  <TAB> object.__setattr__(subvalue, ""name"", f""{name}{suffix}"") <TAB>  <TAB>  <TAB> queue.append(subvalue) <TAB> return subvalue",if subvalue . parent is None :,158
"def fmItem(argName, argVal): <TAB> if py2and3.isstring(argVal): <TAB>  <TAB> MIN_OFFSET = 5 <TAB>  <TAB> lenAV = width - MIN_OFFSET - len(argName) <MASK> argVal = repr(argVal[:lenAV] + ""..."") <TAB> elif argName == ""fileObj"": <TAB>  <TAB> argVal = fileObj.__class__.__name__ <TAB> return ""# - %s: %s"" % (argName, argVal)",if lenAV > 0 :,118
"def get_prog(): <TAB> # type: () -> str <TAB> try: <TAB>  <TAB> prog = os.path.basename(sys.argv[0]) <MASK> return ""%s -m pip"" % sys.executable <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return prog <TAB> except (AttributeError, TypeError, IndexError): <TAB>  <TAB> pass <TAB> return ""pip""","if prog in ( ""__main__.py"" , ""-c"" ) :",95
"def _create_engine(self): <TAB> if ""${"" in self.options[""url""]:  # URL parameters substitution <TAB>  <TAB> vars = {""user"": self.user.username} <TAB>  <TAB> for _prop in self.options[""session""][""properties""]: <MASK> vars[""USER""] = _prop[""value""] <TAB>  <TAB>  <TAB> if _prop[""name""] == ""password"": <TAB>  <TAB>  <TAB>  <TAB> vars[""PASSWORD""] = _prop[""value""] <TAB>  <TAB> raw_url = Template(self.options[""url""]) <TAB>  <TAB> url = raw_url.safe_substitute(**vars) <TAB> else: <TAB>  <TAB> url = self.options[""url""] <TAB> return create_engine(url)","if _prop [ ""name"" ] == ""user"" :",167
"def get_terms( <TAB> self, fn2index: Dict) -> Tuple[Dict[str, List[str]], Dict[str, List[str]]]: <TAB> rvs = {}, {}  # type: Tuple[Dict[str, List[str]], Dict[str, List[str]]] <TAB> for rv, mapping in zip(rvs, (self._mapping, self._title_mapping)): <TAB>  <TAB> for k, v in mapping.items(): <MASK> (fn,) = v <TAB>  <TAB>  <TAB>  <TAB> if fn in fn2index: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> rv[k] = fn2index[fn] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> rv[k] = sorted([fn2index[fn] for fn in v if fn in fn2index]) <TAB> return rvs",if len ( v ) == 1 :,187
"def _get_with_retry(self, create_func, args, kwargs): <TAB> retries = self.RETRIES <TAB> delay = self.DELAY <TAB> while retries: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return create_func(*args, **kwargs) <TAB>  <TAB> except KeyError as e: <MASK> raise <TAB>  <TAB>  <TAB> backoff = (self.RETRIES - retries + delay) * self.BACKOFF <TAB>  <TAB>  <TAB> sleep(backoff)","if str ( e ) not in [ ""'credential_provider'"" , ""'endpoint_resolver'"" ] :",122
"def __scenePlugs(node): <TAB> result = [] <TAB> for plug in node.children(Gaffer.Plug): <TAB>  <TAB> if plug.direction() != plug.Direction.In: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if isinstance(plug, Gaffer.ArrayPlug) and len(plug): <TAB>  <TAB>  <TAB> plug = plug[0] <MASK> result.append(plug) <TAB> return result","if isinstance ( plug , GafferScene . ScenePlug ) :",118
"def __setitem__(self, name, value): <TAB> for program in self._programs: <TAB>  <TAB> snippet = program[""filter""] <MASK> snippet[name] = value <TAB>  <TAB>  <TAB> return <TAB>  <TAB> if name in program.keys(): <TAB>  <TAB>  <TAB> program[name] = value <TAB>  <TAB>  <TAB> return <TAB> raise IndexError(""Unknown uniform or attribute"")","if isinstance ( snippet , gloo . Snippet ) and name in snippet . globals . keys ( ) :",104
"def convert_vectors(p): <TAB> d = None <TAB> for q in p: <TAB>  <TAB> if q.get_head_name() != ""System`List"": <TAB>  <TAB>  <TAB> raise _IllegalDataPoint <TAB>  <TAB> v = list(convert_scalars(q.leaves)) <MASK> d = len(v) <TAB>  <TAB> elif len(v) != d: <TAB>  <TAB>  <TAB> raise _IllegalDataPoint <TAB>  <TAB> yield v",if d is None :,101
"def test_gradient(self): <TAB> for scale in (0.1, 0.5, 1.0, 2.0): <TAB>  <TAB> prior = HorseshoePrior(scale=scale, rng=np.random.RandomState(1)) <TAB>  <TAB> # The function appears to be unstable above 15 <TAB>  <TAB> for theta in range(-20, 15): <MASK> continue <TAB>  <TAB>  <TAB> error = scipy.optimize.check_grad( <TAB>  <TAB>  <TAB>  <TAB> lambda x: prior.lnprob(x[0]), <TAB>  <TAB>  <TAB>  <TAB> lambda x: prior.gradient(x[0]), <TAB>  <TAB>  <TAB>  <TAB> np.array([theta]), <TAB>  <TAB>  <TAB>  <TAB> epsilon=1e-5, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.assertAlmostEqual(error, 0, delta=5)",if theta == 0 :,186
"def recursive_rm(*patterns): <TAB> """"""Recursively remove a file or matching a list of patterns."""""" <TAB> for root, subdirs, subfiles in os.walk(u"".""): <TAB>  <TAB> root = os.path.normpath(root) <MASK> continue <TAB>  <TAB> for file in subfiles: <TAB>  <TAB>  <TAB> for pattern in patterns: <TAB>  <TAB>  <TAB>  <TAB> if fnmatch.fnmatch(file, pattern): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> safe_remove(os.path.join(root, file)) <TAB>  <TAB> for dir in subdirs: <TAB>  <TAB>  <TAB> for pattern in patterns: <TAB>  <TAB>  <TAB>  <TAB> if fnmatch.fnmatch(dir, pattern): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> safe_rmtree(os.path.join(root, dir))","if root . startswith ( "".git/"" ) :",170
"def Eval(self, expr, *args): <TAB> globals = None <TAB> locals = None <TAB> for arg in args: <TAB>  <TAB> arg = FromVariant(arg) <TAB>  <TAB> if type(arg) is dict: <TAB>  <TAB>  <TAB> if globals is None: <TAB>  <TAB>  <TAB>  <TAB> globals = arg <MASK> locals = arg <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise Exception( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Eval can be called with at most 2 dictionary arguments"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pass <TAB> return ToVariant(eval(expr, globals, locals))",elif locals is None :,146
"def _read_ready(self): <TAB> try: <TAB>  <TAB> data = os.read(self._fileno, self.max_size) <TAB> except (BlockingIOError, InterruptedError): <TAB>  <TAB> pass <TAB> except OSError as exc: <TAB>  <TAB> self._fatal_error(exc, ""Fatal read error on pipe transport"") <TAB> else: <MASK> self._protocol.data_received(data) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if self._loop.get_debug(): <TAB>  <TAB>  <TAB>  <TAB> logger.info(""%r was closed by peer"", self) <TAB>  <TAB>  <TAB> self._closing = True <TAB>  <TAB>  <TAB> self._loop._remove_reader(self._fileno) <TAB>  <TAB>  <TAB> self._loop.call_soon(self._protocol.eof_received) <TAB>  <TAB>  <TAB> self._loop.call_soon(self._call_connection_lost, None)",if data :,200
"def is_available(self, port, proto): <TAB> try: <TAB>  <TAB> if proto.lower() == ""tcp"": <TAB>  <TAB>  <TAB> serversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM) <MASK> serversocket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) <TAB>  <TAB> serversocket.bind(("""", port)) <TAB>  <TAB> serversocket.listen(5) <TAB> except: <TAB>  <TAB> return False <TAB> else: <TAB>  <TAB> serversocket.close() <TAB>  <TAB> return True","if proto . lower ( ) == ""udp"" :",133
"def parameters(self): <TAB> params = [] <TAB> for key in self.__dict__.keys(): <TAB>  <TAB> value = self.__dict__[key] <TAB>  <TAB> if isinstance(value, framework.Parameter): <TAB>  <TAB>  <TAB> params.append(value) <TAB>  <TAB> elif isinstance(value, core.Layer): <TAB>  <TAB>  <TAB> params.extend(value.parameters()) <TAB>  <TAB> elif isinstance(value, collections.Container): <MASK> continue <TAB>  <TAB>  <TAB> if isinstance(value[0], framework.Parameter): <TAB>  <TAB>  <TAB>  <TAB> params.extend(value) <TAB>  <TAB>  <TAB> elif isinstance(value[0], core.Layer): <TAB>  <TAB>  <TAB>  <TAB> for v in value: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> params.extend(v.parameters()) <TAB> return params",if len ( value ) == 0 :,178
"def postprocess_query_param(self, key, field_name, operation): <TAB> # TODO: Queries on 'parents' should be deprecated <TAB> if field_name == ""parents"": <TAB>  <TAB> if operation[""value""] not in (list(), tuple()): <TAB>  <TAB>  <TAB> operation[""source_field_name""] = ""parent___id"" <TAB>  <TAB> else: <MASK> operation[""source_field_name""] = ""parent___id__in"" <TAB>  <TAB>  <TAB> elif len(operation[""value""]) == 1: <TAB>  <TAB>  <TAB>  <TAB> operation[""source_field_name""] == ""parent___id"" <TAB>  <TAB>  <TAB>  <TAB> operation[""value""] = operation[""value""][0] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> operation[""source_field_name""] = ""parent__isnull"" <TAB>  <TAB>  <TAB>  <TAB> operation[""value""] = True","if len ( operation [ ""value"" ] ) > 1 :",200
"def run(self, commands, comment=None): <TAB> if comment != None: <TAB>  <TAB> self.logger.info(""Installer: {} "".format(comment)) <TAB>  <TAB> if self.install_config[""ui""]: <TAB>  <TAB>  <TAB> self.progress_bar.update_loading_message(comment) <TAB> for command in commands: <TAB>  <TAB> retval = self.cmd.run(command) <MASK> self.logger.error( <TAB>  <TAB>  <TAB>  <TAB> ""Installer: failed in {} with error code {}"".format(command, retval) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.exit_gracefully() <TAB> return retval","if retval != 0 and ""systemd-tmpfiles"" not in command :",157
"def _value__set(self, value): <TAB> if self.checkable: <MASK> self.checked = False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.checked = True <TAB>  <TAB>  <TAB> if isinstance(value, basestring): <TAB>  <TAB>  <TAB>  <TAB> self.set(""value"", value) <TAB> else: <TAB>  <TAB> self.set(""value"", value)",if not value :,88
"def get_choice_names(self): <TAB> choice_names = [choice[0] for choice in self.choices] <TAB> if self.checked != ""None"": <TAB>  <TAB> for item in self.checked: <MASK> choice_names.insert(0, item) <TAB>  <TAB>  <TAB>  <TAB> self.choices.insert(0, (item, None, 0, True)) <TAB> return choice_names",if item not in choice_names :,103
"def matches( <TAB> self, item: Sequence[T], mismatch_description: Optional[Description] = None) -> bool: <TAB> try: <TAB>  <TAB> matchsequence = MatchingInOrder(self.matchers, mismatch_description) <TAB>  <TAB> for element in item: <TAB>  <TAB>  <TAB> if not matchsequence.matches(element): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return matchsequence.isfinished() <TAB> except TypeError: <MASK> super(IsSequenceContainingInOrder, self).describe_mismatch( <TAB>  <TAB>  <TAB>  <TAB> item, mismatch_description <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return False",if mismatch_description :,141
"def __next__(self): <TAB> try: <TAB>  <TAB> record, not_done = self._raw_next() <TAB> except AttributeError: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""No underlying iterable. This may occur if trying to "" <TAB>  <TAB>  <TAB>  <TAB> ""create multiple concurrent iterators from the same "" <TAB>  <TAB>  <TAB>  <TAB> ""reader. Try wrapping your call to the iterator in a "" <TAB>  <TAB>  <TAB>  <TAB> ""`with` block or materializing the entire iterable "" <TAB>  <TAB>  <TAB>  <TAB> ""explicitly."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise <TAB> if not_done: <TAB>  <TAB> return record <TAB> else: <TAB>  <TAB> raise StopIteration",if self . _cc_iterable is None :,159
"def clear_formatting(self): <TAB> """"""Menu item to remove formatting from current (auto-)selection"""""" <TAB> buffer = self.textview.get_buffer() <TAB> mark = buffer.create_mark(None, buffer.get_insert_iter()) <TAB> selected = self.autoselect() <TAB> if buffer.get_has_selection(): <TAB>  <TAB> start, end = buffer.get_selection_bounds() <TAB>  <TAB> buffer.remove_textstyle_tags(start, end) <MASK> # If we keep the selection we can not continue typing <TAB>  <TAB>  <TAB> # so remove the selection and restore the cursor. <TAB>  <TAB>  <TAB> buffer.unset_selection() <TAB>  <TAB>  <TAB> buffer.place_cursor(buffer.get_iter_at_mark(mark)) <TAB> else: <TAB>  <TAB> buffer.set_textstyles(None) <TAB> buffer.delete_mark(mark)",if selected :,199
"def _gather_connectors(self, expr, connectors): <TAB> if expr.is_expression(): <MASK> for e in expr._numerator: <TAB>  <TAB>  <TAB>  <TAB> self._gather_connectors(e, connectors) <TAB>  <TAB>  <TAB> for e in expr._denominator: <TAB>  <TAB>  <TAB>  <TAB> self._gather_connectors(e, connectors) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for e in expr._args: <TAB>  <TAB>  <TAB>  <TAB> self._gather_connectors(e, connectors) <TAB> elif isinstance(expr, _ConnectorValue): <TAB>  <TAB> connectors.append(expr)",if expr . __class__ is _ProductExpression :,148
"def test_cwl_docker_joint_calling_workflow(self): <TAB> with install_cwl_test_files() as workdir: <TAB>  <TAB> with utils.chdir(os.path.join(workdir, ""gvcf_joint"")): <TAB>  <TAB>  <TAB> subprocess.check_call([""bash"", ""./run_generate_cwl.sh""]) <MASK> shutil.rmtree(""cromwell_work"") <TAB>  <TAB>  <TAB> subprocess.check_call([""bash"", ""./run_cromwell.sh""])","if os . path . exists ( ""cromwell_work"" ) :",131
"def exclude(rule, *args): <TAB> for arg in args: <TAB>  <TAB> if isinstance(arg, EntityMeta): <TAB>  <TAB>  <TAB> entity = arg <TAB>  <TAB>  <TAB> rule.entities_to_exclude.add(entity) <TAB>  <TAB>  <TAB> rule.entities_to_exclude.update(entity._subclasses_) <TAB>  <TAB> elif isinstance(arg, Attribute): <TAB>  <TAB>  <TAB> attr = arg <MASK> throw(TypeError, ""Primary key attribute %s cannot be excluded"" % attr) <TAB>  <TAB>  <TAB> rule.attrs_to_exclude.add(attr) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> throw(TypeError, ""Entity or attribute expected. Got: %r"" % arg)",if attr . pk_offset is not None :,164
"def item_completed(self, results, item, info): <TAB> """"""Called per item when all media requests has been processed"""""" <TAB> if self.LOG_FAILED_RESULTS: <TAB>  <TAB> for ok, value in results: <MASK> logger.error( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""%(class)s found errors processing %(item)s"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> {""class"": self.__class__.__name__, ""item"": item}, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> exc_info=failure_to_exc_info(value), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> extra={""spider"": info.spider}, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return item",if not ok :,149
"def __eq__(self, other): <TAB> if self.name.upper() == other.name.upper(): <TAB>  <TAB> v1 = [_.upper() if isinstance(_, str) else _ for _ in self.values] <TAB>  <TAB> v2 = [_.upper() if isinstance(_, str) else _ for _ in other.values] <MASK> if self.units == self.units: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if v1 == v2 :,107
"def bump(self, part_name, order): <TAB> bumped = False <TAB> new_values = {} <TAB> for label in order: <TAB>  <TAB> if not label in self._values: <TAB>  <TAB>  <TAB> continue <MASK> new_values[label] = self._values[label].bump() <TAB>  <TAB>  <TAB> bumped = True <TAB>  <TAB> elif bumped: <TAB>  <TAB>  <TAB> new_values[label] = self._values[label].null() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_values[label] = self._values[label].copy() <TAB> new_version = Version(new_values) <TAB> return new_version",elif label == part_name :,153
"def read_bucket_table(f): <TAB> html = """" <TAB> bucket = False <TAB> table = False <TAB> for line in f: <MASK> bucket = True <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB> bucket <TAB>  <TAB>  <TAB> and line[:-1] == '   <table border=""0"" cellpadding=""2"" cellspacing=""0"">' <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> table = True <TAB>  <TAB> if table: <TAB>  <TAB>  <TAB> html += line <TAB>  <TAB>  <TAB> if line[:-1] == ""   </table>"": <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return html","if line [ : - 1 ] == '<div class=""bucket"">' :",150
def dispose(): <TAB> global session <TAB> old_session = session <TAB> session = None <TAB> if old_session: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> old_session.close() <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> pass <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> old_session.bind.dispose() <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> pass,if old_session . bind :,95
"def writeMemory(self, va, bytes): <TAB> for mapdef in self._map_defs: <TAB>  <TAB> mva, mmaxva, mmap, mbytes = mapdef <MASK> mva, msize, mperms, mfname = mmap <TAB>  <TAB>  <TAB> if not (mperms & MM_WRITE or self._supervisor): <TAB>  <TAB>  <TAB>  <TAB> raise envi.SegmentationViolation(va) <TAB>  <TAB>  <TAB> offset = va - mva <TAB>  <TAB>  <TAB> mapdef[3] = mbytes[:offset] + bytes + mbytes[offset + len(bytes) :] <TAB>  <TAB>  <TAB> return <TAB> raise envi.SegmentationViolation(va)",if mva <= va < mmaxva :,159
"def hasGrant(self, name, permission): <TAB> name = name.lower() <TAB> permission = permission.upper() <TAB> for grantee in self.grantees: <TAB>  <TAB> if grantee.name.lower() == name: <TAB>  <TAB>  <TAB> if grantee.permission == ""FULL_CONTROL"": <TAB>  <TAB>  <TAB>  <TAB> return True <MASK> return True <TAB> return False",elif grantee . permission . upper ( ) == permission :,107
"def mASCII_LETTER( <TAB> self,): <TAB> try: <TAB>  <TAB> pass <MASK> self.input.consume() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> mse = MismatchedSetException(None, self.input) <TAB>  <TAB>  <TAB> self.recover(mse) <TAB>  <TAB>  <TAB> raise mse <TAB> finally: <TAB>  <TAB> pass",if ( 65 <= self . input . LA ( 1 ) <= 90 ) or ( 97 <= self . input . LA ( 1 ) <= 122 ) :,113
"def ensure_fromlist(self, module, fromlist, recursive=0):  # pragma: nocover <TAB> self.msg(4, ""ensure_fromlist"", module, fromlist, recursive) <TAB> for sub in fromlist: <TAB>  <TAB> if sub == ""*"": <TAB>  <TAB>  <TAB> if not recursive: <TAB>  <TAB>  <TAB>  <TAB> submodules = self.find_all_submodules(module) <MASK> self.ensure_fromlist(module, submodules, 1) <TAB>  <TAB> elif not hasattr(module, sub): <TAB>  <TAB>  <TAB> subname = ""%s.%s"" % (module.__name__, sub) <TAB>  <TAB>  <TAB> submod = self.import_module(sub, subname, module) <TAB>  <TAB>  <TAB> if not submod: <TAB>  <TAB>  <TAB>  <TAB> raise ImportError(""No module named "" + subname)",if submodules :,185
"def sniff(self, filename): <TAB> # Match the keyword 'CORD' at position 4 or 8 - intsize dependent <TAB> # Not checking for endianness <TAB> try: <TAB>  <TAB> with open(filename, ""rb"") as header: <TAB>  <TAB>  <TAB> intsize = 4 <TAB>  <TAB>  <TAB> header.seek(intsize) <MASK> return True <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> intsize = 8 <TAB>  <TAB>  <TAB>  <TAB> header.seek(intsize) <TAB>  <TAB>  <TAB>  <TAB> if header.read(intsize) == self._magic_number: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> return False <TAB> except Exception: <TAB>  <TAB> return False",if header . read ( intsize ) == self . _magic_number :,167
"def get_websocket_setting(vhosts, service_alias): <TAB> websocket_setting = [] <TAB> for v in vhosts: <TAB>  <TAB> if service_alias == v[""service_alias""]: <MASK> websocket_setting.append(""option http-server-close"") <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return websocket_setting","if v [ ""scheme"" ] . lower ( ) in [ ""ws"" , ""wss"" ] :",97
"def tag(self, media_id, tag, update_edited=False): <TAB> try: <TAB>  <TAB> db = get_db() <TAB>  <TAB> m = db.get(""id"", media_id) <TAB>  <TAB> if update_edited: <TAB>  <TAB>  <TAB> m[""last_edit""] = int(time.time()) <TAB>  <TAB> tags = m.get(""tags"") or [] <MASK> tags.append(tag) <TAB>  <TAB>  <TAB> m[""tags""] = tags <TAB>  <TAB>  <TAB> db.update(m) <TAB>  <TAB> return True <TAB> except: <TAB>  <TAB> log.error(""Failed tagging: %s"", traceback.format_exc()) <TAB> return False",if tag not in tags :,157
"def get_local_urls(port): <TAB> """"""get urls of local machine"""""" <TAB> url_list = [] <TAB> for _, info in psutil.net_if_addrs().items(): <TAB>  <TAB> for addr in info: <MASK> url_list.append(""http://{}:{}"".format(addr.address, port)) <TAB> return url_list",if socket . AddressFamily . AF_INET == addr . family :,97
"def _ScanSimpleCommand(self): <TAB> """"""First pass: Split into redirects and words."""""" <TAB> redirects = [] <TAB> words = [] <TAB> while True: <TAB>  <TAB> if not self._Peek(): <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> if self.c_kind == Kind.Redir: <TAB>  <TAB>  <TAB> node = self.ParseRedirect() <MASK> return None  # e.g. EOF <TAB>  <TAB>  <TAB> redirects.append(node) <TAB>  <TAB> elif self.c_kind == Kind.Word: <TAB>  <TAB>  <TAB> words.append(self.cur_word) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> self._Next() <TAB> return redirects, words",if not node :,162
"def _compute_losses(self): <TAB> if self._weight_classes is not None: <TAB>  <TAB> self._weight_classes = self._weight_classes.to(self.device) <TAB> losses = votenet_module.get_loss( <TAB>  <TAB> self.input, self.output, self.loss_params, weight_classes=self._weight_classes <TAB> ) <TAB> for loss_name, loss in losses.items(): <MASK> if not self.losses_has_been_added: <TAB>  <TAB>  <TAB>  <TAB> self.loss_names += [loss_name] <TAB>  <TAB>  <TAB> setattr(self, loss_name, loss) <TAB> self.losses_has_been_added = True",if torch . is_tensor ( loss ) :,171
"def row_iterator(self): <TAB> headers = self._keywords.get(""custom_headers"") <TAB> for index, row in enumerate(self._native_sheet): <TAB>  <TAB> if index == 0: <MASK> if isinstance(row, OrderedDict): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> headers = list(row.keys()) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> headers = sorted(row.keys()) <TAB>  <TAB>  <TAB> yield headers <TAB>  <TAB> values = [] <TAB>  <TAB> for k in headers: <TAB>  <TAB>  <TAB> values.append(row.get(k, constants.DEFAULT_NA)) <TAB>  <TAB> yield values",if headers is None :,146
"def _user_for_api_key(self, api_key): <TAB> with self._keys_lock: <TAB>  <TAB> for user_id, data in self._keys.items(): <MASK> return self._user_manager.find_user(userid=user_id) <TAB> return None","if any ( filter ( lambda x : x . api_key == api_key , data ) ) :",92
"def addText(self, text): <TAB> if isinstance(text, str): <TAB>  <TAB> text = text.decode(""utf-8"") <TAB> ngrams = dict() <TAB> for word in white_space_re.split(text): <TAB>  <TAB> word = ""_%s_"" % word <TAB>  <TAB> size = len(word) <TAB>  <TAB> for i in xrange(size - 1): <TAB>  <TAB>  <TAB> for s in (1, 2, 3, 4): <TAB>  <TAB>  <TAB>  <TAB> end = i + s <MASK> break <TAB>  <TAB>  <TAB>  <TAB> sub = word[i:end] <TAB>  <TAB>  <TAB>  <TAB> if not sub in ngrams: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ngrams[sub] = 0 <TAB>  <TAB>  <TAB>  <TAB> ngrams[sub] += 1 <TAB> self.ngrams = ngrams <TAB> return self",if end >= size :,184
"def callback(lexer, match, context): <TAB> text = match.group() <TAB> if context.block_scalar_indent is None or len(text) <= context.block_scalar_indent: <MASK> yield match.start(), IndentTokenClass, text <TAB> else: <TAB>  <TAB> indentation = text[: context.block_scalar_indent] <TAB>  <TAB> content = text[context.block_scalar_indent :] <TAB>  <TAB> yield match.start(), IndentTokenClass, indentation <TAB>  <TAB> yield (match.start() + context.block_scalar_indent, ContentTokenClass, content) <TAB> context.pos = match.end()",if text :,144
"def _send(self, data, sensitive=True): <TAB> try: <TAB>  <TAB> line = self._encoder.encode(data) <TAB>  <TAB> data = (line + ""\n"").encode(""utf-8"") <MASK> logger.debug(""Sending %d bytes of data"", len(data)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logging.debug(""Sending data: %s"", line) <TAB>  <TAB> self._writer.write(data) <TAB> except TypeError as error: <TAB>  <TAB> logger.error(str(error))",if sensitive :,122
"def _dict_to_size_tuple(val1, val2): <TAB> kaa = ""keep-aspect-ratio"" <TAB> not_both_kaa = val1 != kaa or val2 != kaa <TAB> assert not_both_kaa, ( <TAB>  <TAB> 'Expected at least one value to not be ""keep-aspect-ratio"", ' <TAB>  <TAB> ""but got it two times."" <TAB> ) <TAB> size_tuple = [] <TAB> for k in [val1, val2]: <MASK> entry = iap.Deterministic(k) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> entry = cls._handle_size_arg(k, True) <TAB>  <TAB> size_tuple.append(entry) <TAB> return tuple(size_tuple)","if k in [ ""keep-aspect-ratio"" , ""keep"" ] :",178
"def wait_for_host(self, host): <TAB> """"""Throttle requests to one host."""""" <TAB> t = time.time() <TAB> if host in self.times: <TAB>  <TAB> due_time = self.times[host] <MASK> wait = due_time - t <TAB>  <TAB>  <TAB> time.sleep(wait) <TAB>  <TAB>  <TAB> t = time.time() <TAB> wait_time = random.uniform(self.wait_time_min, self.wait_time_max) <TAB> self.times[host] = t + wait_time",if due_time > t :,132
"def handleRequest(self, msg):  # msg is a json object <TAB> method = msg.get(""method"") <TAB> seqNum = msg.get(""seqNum"", 0) <TAB> # print(""handle message: "", str(id(self)), method, seqNum) <TAB> service = self.service <TAB> if service: <TAB>  <TAB> # let the text service handle the message <TAB>  <TAB> reply = service.handleRequest(msg) <TAB> else:  # the text service is not yet initialized <TAB>  <TAB> reply = {""seqNum"": seqNum} <TAB>  <TAB> success = False <MASK> # initialize the text service <TAB>  <TAB>  <TAB> success = self.init(msg) <TAB>  <TAB> reply[""success""] = success <TAB> # print(reply) <TAB> return reply","if method == ""init"" :",173
"def suite(): <TAB> suite = unittest.TestSuite() <TAB> for fn in os.listdir(here): <MASK> modname = ""unittest.test."" + fn[:-3] <TAB>  <TAB>  <TAB> __import__(modname) <TAB>  <TAB>  <TAB> module = sys.modules[modname] <TAB>  <TAB>  <TAB> suite.addTest(loader.loadTestsFromModule(module)) <TAB> suite.addTest(loader.loadTestsFromName(""unittest.test.testmock"")) <TAB> return suite","if fn . startswith ( ""test"" ) and fn . endswith ( "".py"" ) :",116
"def parse_module_declaration(mod_decl, parse_module_info=True): <TAB> try: <TAB>  <TAB> mod_id = None <MASK> mod_id = parse_module_id(mod_decl[""module-id""]) <TAB>  <TAB> # loc = parse_location(d['module-id'].get('location')) <TAB>  <TAB> decl = parse_declaration(mod_decl[""declaration""]) <TAB>  <TAB> if decl: <TAB>  <TAB>  <TAB> decl.module = mod_id <TAB>  <TAB>  <TAB> return decl <TAB>  <TAB> return None <TAB> except AttributeError: <TAB>  <TAB> return None","if ""module-id"" in mod_decl and parse_module_info :",147
"def get_finished_timelapses(): <TAB> files = [] <TAB> basedir = settings().getBaseFolder(""timelapse"", check_writable=False) <TAB> for entry in scandir(basedir): <MASK> continue <TAB>  <TAB> files.append( <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB> ""name"": entry.name, <TAB>  <TAB>  <TAB>  <TAB> ""size"": util.get_formatted_size(entry.stat().st_size), <TAB>  <TAB>  <TAB>  <TAB> ""bytes"": entry.stat().st_size, <TAB>  <TAB>  <TAB>  <TAB> ""date"": util.get_formatted_datetime( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> datetime.datetime.fromtimestamp(entry.stat().st_mtime) <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB> } <TAB>  <TAB> ) <TAB> return files",if util . is_hidden_path ( entry . path ) or not valid_timelapse ( entry . path ) :,194
"def run(self, **kwargs):  # pylint: disable=arguments-differ <TAB> if not kwargs.get(""verbatim_args""): <TAB>  <TAB> args = kwargs.setdefault(""args"", []) <MASK> args.extend([""--config-dir"", self.abs_path(self.config_dir)]) <TAB> return super(TestSaltProgram, self).run(**kwargs)","if ""-c"" not in args and ""--config-dir"" not in args :",103
"def assert_http_error(status, msg=None): <TAB> try: <TAB>  <TAB> yield <TAB> except requests.HTTPError as e: <TAB>  <TAB> real_status = e.response.status_code <TAB>  <TAB> assert real_status == status, ""Expected status %d, got %d"" % ( <TAB>  <TAB>  <TAB> real_status, <TAB>  <TAB>  <TAB> status, <TAB>  <TAB> ) <MASK> assert msg in str(e), e <TAB> else: <TAB>  <TAB> assert False, ""Expected HTTP error status""",if msg :,119
"def _stamp_version(filename): <TAB> found, out = False, [] <TAB> try: <TAB>  <TAB> with open(filename, ""r"") as f: <TAB>  <TAB>  <TAB> for line in f: <MASK> line = line.replace(""'git'"", ""'%s'"" % VERSION) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> found = True <TAB>  <TAB>  <TAB>  <TAB> out.append(line) <TAB> except (IOError, OSError): <TAB>  <TAB> print(""Couldn't find file %s to stamp version"" % filename, file=sys.stderr) <TAB> if found: <TAB>  <TAB> with open(filename, ""w"") as f: <TAB>  <TAB>  <TAB> f.writelines(out) <TAB> else: <TAB>  <TAB> print( <TAB>  <TAB>  <TAB> ""WARNING: Couldn't find version line in file %s"" % filename, file=sys.stderr <TAB>  <TAB> )","if ""__version__ ="" in line :",198
"def __init__(self, servers=None, default_timeout=300, key_prefix=None): <TAB> BaseCache.__init__(self, default_timeout) <TAB> if servers is None or isinstance(servers, (list, tuple)): <MASK> servers = [""127.0.0.1:11211""] <TAB>  <TAB> self._client = self.import_preferred_memcache_lib(servers) <TAB>  <TAB> if self._client is None: <TAB>  <TAB>  <TAB> raise RuntimeError(""no memcache module found"") <TAB> else: <TAB>  <TAB> # NOTE: servers is actually an already initialized memcache <TAB>  <TAB> # client. <TAB>  <TAB> self._client = servers <TAB> self.key_prefix = key_prefix",if servers is None :,164
"def build_root_urlpatterns(self): <TAB> root_urlpatterns = [] <TAB> for namespace in self._namespaces: <MASK> child_patterns = self.get_child_patterns(namespace[""namespace""]) <TAB>  <TAB>  <TAB> included_patterns = include( <TAB>  <TAB>  <TAB>  <TAB> (child_patterns, namespace[""namespace""]), <TAB>  <TAB>  <TAB>  <TAB> namespace=namespace[""namespace""], <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> root_urlpatterns.append(url(namespace[""path""], included_patterns)) <TAB> return root_urlpatterns","if not namespace [ ""parent"" ] :",121
"def _get_items_from_dict(items): <TAB> new_items = {} <TAB> for k, v in items.items(): <TAB>  <TAB> value = v <MASK> value = _get_items_from_list(v) <TAB>  <TAB> elif isinstance(v, dict): <TAB>  <TAB>  <TAB> value = _get_items_from_dict(v) <TAB>  <TAB> elif not isinstance(v, (DBRef, Document)): <TAB>  <TAB>  <TAB> value = field.to_python(v) <TAB>  <TAB> new_items[k] = value <TAB> return new_items","if isinstance ( v , list ) :",137
"def y_bound(ty, bound, base, offset): <TAB> for tx in range(min_tx, max_tx + 1): <MASK> continue <TAB>  <TAB> with surf.tile_request(tx, ty, readonly=True) as tile: <TAB>  <TAB>  <TAB> for (y, x) in product(range(base, bound, offset), range(N)): <TAB>  <TAB>  <TAB>  <TAB> if tile[y, x, 3] > 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> bound = y <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return bound","if ( tx , ty ) not in tile_coordinates :",135
"def _extract_integer(self, s): <TAB> charset = string.digits if self._base == 10 else string.digits + ""abcdefABCDEF"" <TAB> component = """" <TAB> digit_start_pos = None <TAB> for i, c in enumerate(s): <MASK> if c not in charset: <TAB>  <TAB>  <TAB>  <TAB> component = s[:i] <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if c in charset and s[i : i + 2] not in (""0x"", ""0X""): <TAB>  <TAB>  <TAB>  <TAB> digit_start_pos = c <TAB> if not component: <TAB>  <TAB> component = s <TAB> return component",if digit_start_pos is not None :,159
"def _get_timeout_seconds(self, value): <TAB> if value is self.default: <TAB>  <TAB> value = pwnlib.context.context.timeout <TAB> elif value is self.forever: <TAB>  <TAB> value = self.maximum <TAB> else: <TAB>  <TAB> value = float(value) <MASK> raise AttributeError(""timeout: Timeout cannot be negative"") <TAB>  <TAB> if value > self.maximum: <TAB>  <TAB>  <TAB> value = self.maximum <TAB> return value",if value is value < 0 :,113
"def build(datapath): <TAB> version = ""v1.0"" <TAB> dpath = os.path.join(datapath, ""genderation_bias"") <TAB> if not build_data.built(dpath, version): <TAB>  <TAB> logging.info(""[building data: "" + dpath + ""]"") <MASK> # An older version exists, so remove these outdated files. <TAB>  <TAB>  <TAB> build_data.remove_dir(dpath) <TAB>  <TAB> build_data.make_dir(dpath) <TAB>  <TAB> # Download the data. <TAB>  <TAB> for downloadable_file in RESOURCES: <TAB>  <TAB>  <TAB> downloadable_file.download_file(dpath) <TAB>  <TAB> # Mark the data as built. <TAB>  <TAB> build_data.mark_done(dpath, version)",if build_data . built ( dpath ) :,182
"def Get_XX(self, id, xx): <TAB> """"""Retrieve the information with a given line code (e.g. ID, AC)."""""" <TAB> entry = self.Get(id) <TAB> if not entry: <TAB>  <TAB> return """" <TAB> XX = """" <TAB> for line in string.split(entry, ""\n""): <MASK> XX = XX + string.strip(line[5:]) <TAB>  <TAB>  <TAB> if XX[-1] == ""."": <TAB>  <TAB>  <TAB>  <TAB> XX = XX[0:-1] <TAB>  <TAB> if line[0:2] == ""//"": <TAB>  <TAB>  <TAB> break <TAB> return XX","if line [ 0 : 5 ] == ""%s   "" % xx :",153
"def apply_acceleration(self, veh_id, acc): <TAB> """"""See parent class."""""" <TAB> # to hand the case of a single vehicle <TAB> if type(veh_id) == str: <TAB>  <TAB> veh_id = [veh_id] <TAB>  <TAB> acc = [acc] <TAB> for i, veh_id in enumerate(veh_id): <MASK> this_vel = self.get_speed(veh_id) <TAB>  <TAB>  <TAB> next_vel = max(this_vel + acc[i] * self.sim_step, 0) <TAB>  <TAB>  <TAB> aimsun_id = self._id_flow2aimsun[veh_id] <TAB>  <TAB>  <TAB> self.kernel_api.set_speed(aimsun_id, next_vel)",if acc [ i ] is not None :,192
"def test_median_stop(self): <TAB> config = [(""MobileNetV2Space"")] <TAB> sanas = SANAS(config, server_addr=("""", 8732), save_checkpoint=None) <TAB> earlystop = MedianStop(sanas, 2) <TAB> avg_loss = 1.0 <TAB> for step in range(steps): <TAB>  <TAB> status = earlystop.get_status(step, avg_loss, epochs) <TAB>  <TAB> self.assertTrue(status, ""GOOD"") <TAB> avg_loss = 0.5 <TAB> for step in range(steps): <TAB>  <TAB> status = earlystop.get_status(step, avg_loss, epochs) <MASK> self.assertTrue(status, ""GOOD"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertTrue(status, ""BAD"")",if step < 2 :,185
"def processEager(eager): <TAB> if eager is None: <TAB>  <TAB> return tuple() <TAB> else: <TAB>  <TAB> l = [] <MASK> eager = (eager,) <TAB>  <TAB> for e in eager: <TAB>  <TAB>  <TAB> l.append(eagerload(_replacements(e))) <TAB>  <TAB> return l","if isinstance ( eager , str ) :",77
"def run(sock): <TAB> with sock: <TAB>  <TAB> conn, _ = sock.accept() <TAB>  <TAB> conn.settimeout(self.timeout) <TAB>  <TAB> with conn, open(TESTFN2, ""wb"") as f: <TAB>  <TAB>  <TAB> event.wait(self.timeout) <TAB>  <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB>  <TAB> chunk = conn.recv(65536) <MASK> return <TAB>  <TAB>  <TAB>  <TAB> f.write(chunk)",if not chunk :,109
"def iter_GetSocketValues(nodes, variables): <TAB> for node in nodes: <TAB>  <TAB> for i, socket in enumerate(node.inputs): <MASK> yield getLoadSocketValueLine(socket, node, variables, i)","if not isSocketLinked ( socket , node ) :",68
"def keyfunc3(item: Tuple[str, List]) -> str: <TAB> # hack: mutating the subitems dicts to a list in the keyfunc <TAB> k, v = item <TAB> v[1] = sorted(((si, se) for (si, (se, void, void)) in v[1].items()), key=keyfunc2) <TAB> if v[2] is None: <TAB>  <TAB> # now calculate the key <MASK> k = k[1:] <TAB>  <TAB> letter = unicodedata.normalize(""NFD"", k[0])[0].upper() <TAB>  <TAB> if letter.isalpha() or letter == ""_"": <TAB>  <TAB>  <TAB> return letter <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # get all other symbols under one heading <TAB>  <TAB>  <TAB> return _(""Symbols"") <TAB> else: <TAB>  <TAB> return v[2]","if k . startswith ( ""\N{RIGHT-TO-LEFT MARK}"" ) :",195
"def Visit_testlist_gexp(self, node):  # pylint: disable=invalid-name <TAB> self.DefaultNodeVisit(node) <TAB> prev_was_comma = False <TAB> for child in node.children: <MASK> _SetUnbreakable(child) <TAB>  <TAB>  <TAB> prev_was_comma = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if prev_was_comma: <TAB>  <TAB>  <TAB>  <TAB> _SetSplitPenalty(pytree_utils.FirstLeafNode(child), TOGETHER) <TAB>  <TAB>  <TAB> prev_was_comma = False","if isinstance ( child , pytree . Leaf ) and child . value == "","" :",147
"def objects_equals(self, expected_obj, obj): <TAB> for name in vars(expected_obj): <TAB>  <TAB> expected_data = getattr(expected_obj, name) <TAB>  <TAB> actual_data = getattr(obj, name) <TAB>  <TAB> same_data = self.data_equals(expected_data, actual_data) <MASK> break <TAB> return same_data",if not same_data :,94
"def load_upload_form(self): <TAB> url = helpers.submit_url(""upload-unlisted"") <TAB> response = self.client.get(url, allow_redirects=False, catch_response=True) <TAB> if response.status_code == 200: <TAB>  <TAB> response.success() <TAB>  <TAB> html = lxml.html.fromstring(response.content) <TAB>  <TAB> return html.get_element_by_id(""create-addon"") <TAB> else: <TAB>  <TAB> more_info = """" <MASK> more_info = ""Location: {}"".format(response.headers[""Location""]) <TAB>  <TAB> response.failure( <TAB>  <TAB>  <TAB> ""Unexpected status: {}; {}"".format(response.status_code, more_info) <TAB>  <TAB> )","if response . status_code in ( 301 , 302 ) :",180
"def _generate_simplifications(self, normalize=False): <TAB> simplifications = [] <TAB> for simplification in self.info.get(""simplifications"", []): <TAB>  <TAB> c_simplification = {} <TAB>  <TAB> key, value = list(simplification.items())[0] <MASK> key = normalize_unicode(key) <TAB>  <TAB> if isinstance(value, int): <TAB>  <TAB>  <TAB> c_simplification[key] = str(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> c_simplification[key] = normalize_unicode(value) if normalize else value <TAB>  <TAB> simplifications.append(c_simplification) <TAB> return simplifications",if normalize :,164
"def main(argv): <TAB> if len(argv) > 1: <MASK> wpUpdateAll() <TAB>  <TAB> elif argv[1] == ""update"" and len(argv) > 2: <TAB>  <TAB>  <TAB> wpUpdate(argv[2:]) <TAB>  <TAB> elif argv[1] == ""init"": <TAB>  <TAB>  <TAB> wpInit() <TAB>  <TAB> elif argv[1] == ""usestyle"" and len(argv) == 3: <TAB>  <TAB>  <TAB> wpUseStyle(argv[2]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> printUsage() <TAB> else: <TAB>  <TAB> printUsage()","if argv [ 1 ] == ""updateall"" :",142
def maybe_init_external_session_folders(): <TAB> if _render_data == None: <TAB>  <TAB> return <TAB> if _render_data.save_internally == False: <MASK> os.mkdir(clip_frames_folder()) <TAB>  <TAB> if not os.path.exists(rendered_frames_folder()): <TAB>  <TAB>  <TAB> os.mkdir(rendered_frames_folder()),if not os . path . exists ( clip_frames_folder ( ) ) :,103
"def emit(self, record): <TAB> while True: <TAB>  <TAB> try: <MASK> with self.rotate_lock: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.doRollover() <TAB>  <TAB>  <TAB> logging.FileHandler.emit(self, record) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> except (dnf.exceptions.ProcessLockError, dnf.exceptions.ThreadLockError): <TAB>  <TAB>  <TAB> time.sleep(0.01) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> self.handleError(record) <TAB>  <TAB>  <TAB> return",if self . shouldRollover ( record ) :,130
"def close_fds(low_fd, max_fd=None): <TAB> if max_fd is None: <TAB>  <TAB> max_fd = resource.getrlimit(resource.RLIMIT_NOFILE)[1] <TAB>  <TAB> # Avoid infinity as thats not practical <MASK> max_fd = 8192 <TAB> os.closerange(low_fd, max_fd)",if max_fd == resource . RLIM_INFINITY :,103
"def __getaddr(self, keyword, arg): <TAB> address = None <TAB> keylen = len(keyword) <TAB> if arg[:keylen].upper() == keyword: <TAB>  <TAB> address = arg[keylen:].strip() <TAB>  <TAB> if not address: <TAB>  <TAB>  <TAB> pass <MASK> # Addresses can be in the form <person@dom.com> but watch out <TAB>  <TAB>  <TAB> # for null address, e.g. <> <TAB>  <TAB>  <TAB> address = address[1:-1] <TAB> return address","elif address [ 0 ] == ""<"" and address [ - 1 ] == "">"" and address != ""<>"" :",136
"def _done_callback(fut): <TAB> e = fut.exception() <TAB> if e is not None: <TAB>  <TAB> log_utils.print_and_log( <TAB>  <TAB>  <TAB> logging.ERROR, <TAB>  <TAB>  <TAB> ""World {} had error {}"".format(task_id, repr(e)), <TAB>  <TAB>  <TAB> should_print=True, <TAB>  <TAB> ) <TAB>  <TAB> traceback.print_exc(file=sys.stdout) <MASK> raise e",if self . debug :,111
"def v_opmode_info(size, opmode, rex_w, stk): <TAB> if size in [16, 32]: <TAB>  <TAB> if opmode: <TAB>  <TAB>  <TAB> return invmode[size] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return size <TAB> elif size == 64: <TAB>  <TAB> # Rex has the maximum priority <TAB>  <TAB> # Then opmode <TAB>  <TAB> # Then stacker <MASK> return 64 <TAB>  <TAB> elif opmode == 1: <TAB>  <TAB>  <TAB> return 16 <TAB>  <TAB> elif stk: <TAB>  <TAB>  <TAB> return 64 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return 32",if rex_w == 1 :,145
def walk_under_code_boundary(node): <TAB> it = controlled_ast_walk(node) <TAB> traverse = None <TAB> try: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> subn = it.send(traverse) <TAB>  <TAB>  <TAB> yield subn <MASK> traverse = False  # continue traversing sub names <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> traverse = True <TAB> except StopIteration: <TAB>  <TAB> pass,"if isinstance ( subn , CODE_BLOCK_STMTS ) :",113
"def decode(self, message): <TAB> assert message.command == SMB_COM_WRITE_ANDX <TAB> if not message.status.hasError: <MASK> raise ProtocolError( <TAB>  <TAB>  <TAB>  <TAB> ""Not enough data to decode SMB_COM_WRITE_ANDX parameters"", <TAB>  <TAB>  <TAB>  <TAB> message.raw_data, <TAB>  <TAB>  <TAB>  <TAB> message, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> _, _, _, count, self.available, high_count, _ = struct.unpack( <TAB>  <TAB>  <TAB> self.PAYLOAD_STRUCT_FORMAT, <TAB>  <TAB>  <TAB> message.parameters_data[: self.PAYLOAD_STRUCT_SIZE], <TAB>  <TAB> ) <TAB>  <TAB> self.count = (count & 0xFFFF) | (high_count << 16)",if len ( message . parameters_data ) < self . PAYLOAD_STRUCT_SIZE :,189
"def get_sle_for_target_warehouse(self, item_row): <TAB> sle = self.get_sl_entries( <TAB>  <TAB> item_row, <TAB>  <TAB> {""actual_qty"": flt(item_row.qty), ""warehouse"": item_row.target_warehouse}, <TAB> ) <TAB> if self.docstatus == 1: <TAB>  <TAB> if not cint(self.is_return): <TAB>  <TAB>  <TAB> sle.update({""incoming_rate"": item_row.incoming_rate, ""recalculate_rate"": 1}) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sle.update({""outgoing_rate"": item_row.incoming_rate}) <MASK> sle.dependant_sle_voucher_detail_no = item_row.name <TAB> return sle",if item_row . warehouse :,189
"def yield_tokens(line): <TAB> for i, part in enumerate(re.split(r""\{\{(.*?)\}\}"", line)): <TAB>  <TAB> if i % 2: <MASK> yield ""RAW"", part[1:] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield ""CMD"", part <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield ""TXT"", part","if part . startswith ( ""!"" ) :",91
"def set(self, key, record): <TAB> with self.lock: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.cache.pop(key) <TAB>  <TAB> except KeyError: <MASK> self.cache.popitem(last=False) <TAB>  <TAB> self.cache[key] = record",if len ( self . cache ) >= self . capacity :,82
"def _get_local_versions(): <TAB> # get locally installed versions <TAB> versions = {} <TAB> for dist in get_installed_cli_distributions(): <TAB>  <TAB> if dist.key == CLI_PACKAGE_NAME: <TAB>  <TAB>  <TAB> versions[CLI_PACKAGE_NAME] = {""local"": dist.version} <MASK> comp_name = dist.key.replace(COMPONENT_PREFIX, """") <TAB>  <TAB>  <TAB> versions[comp_name] = {""local"": dist.version} <TAB> return versions",elif dist . key . startswith ( COMPONENT_PREFIX ) :,123
"def _read_ready(self): <TAB> try: <TAB>  <TAB> data = os.read(self._fileno, self.max_size) <TAB> except (BlockingIOError, InterruptedError): <TAB>  <TAB> pass <TAB> except OSError as exc: <TAB>  <TAB> self._fatal_error(exc, ""Fatal read error on pipe transport"") <TAB> else: <TAB>  <TAB> if data: <TAB>  <TAB>  <TAB> self._protocol.data_received(data) <TAB>  <TAB> else: <MASK> logger.info(""%r was closed by peer"", self) <TAB>  <TAB>  <TAB> self._closing = True <TAB>  <TAB>  <TAB> self._loop._remove_reader(self._fileno) <TAB>  <TAB>  <TAB> self._loop.call_soon(self._protocol.eof_received) <TAB>  <TAB>  <TAB> self._loop.call_soon(self._call_connection_lost, None)",if self . _loop . get_debug ( ) :,200
"def destination(self, type, name, arglist): <TAB> classname = ""Function"" <TAB> listname = ""functions"" <TAB> if arglist: <TAB>  <TAB> t, n, m = arglist[-1] <TAB>  <TAB> # This is non-functional today <MASK> classname = ""Method"" <TAB>  <TAB>  <TAB> listname = ""methods"" <TAB> return classname, listname","if t in ( ""ListHandle"" , ""ListRef"" ) and m == ""InMode"" :",102
"def select_path_if_visible(self, path, node_id=""""): <TAB> for child_id in self.tree.get_children(node_id): <TAB>  <TAB> if self.tree.set(child_id, ""path"") == path: <TAB>  <TAB>  <TAB> self.tree.selection_set(child_id) <TAB>  <TAB>  <TAB> return <MASK> self.select_path_if_visible(path, child_id)","if self . tree . item ( child_id , ""open"" ) :",115
"def sorted(iterable): <TAB> result = list(iterable) <TAB> for passnum in range(len(result) - 1, 0, -1): <TAB>  <TAB> for i in range(passnum): <MASK> temp = result[i] <TAB>  <TAB>  <TAB>  <TAB> result[i] = result[i + 1] <TAB>  <TAB>  <TAB>  <TAB> result[i + 1] = temp <TAB> return result",if result [ i ] > result [ i + 1 ] :,103
"def valueInRange(self, value): <TAB> if not isnan(value): <TAB>  <TAB> bounds = self.opts[""bounds""] <MASK> return False <TAB>  <TAB> if bounds[1] is not None and value > bounds[1]: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> if self.opts.get(""int"", False): <TAB>  <TAB>  <TAB> if int(value) != value: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return True",if bounds [ 0 ] is not None and value < bounds [ 0 ] :,114
"def remove_building(self, building): <TAB> """"""Stop taking the coverage area of the given building into account."""""" <TAB> self._buildings.remove(building) <TAB> removed_coords_list = [] <TAB> for coords in building.position.get_radius_coordinates(building.radius, True): <MASK> continue <TAB>  <TAB> if self._area_coverage[coords] == 1: <TAB>  <TAB>  <TAB> removed_coords_list.append(coords) <TAB>  <TAB>  <TAB> del self._area_coverage[coords] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._area_coverage[coords] -= 1 <TAB> self._area_cache.remove_area(removed_coords_list)",if coords not in self . terrain_cache . land_or_coast :,172
"def _load_aliases(self, filenames=None): <TAB> if filenames is None: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> filenames = self._dropin_dir_filenames() <TAB>  <TAB> except dnf.exceptions.ConfigError: <TAB>  <TAB>  <TAB> return <TAB> for filename in filenames: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> conf = self._load_conf(filename) <MASK> self.aliases.update(conf.aliases) <TAB>  <TAB> except dnf.exceptions.ConfigError as e: <TAB>  <TAB>  <TAB> logger.warning(_(""Config error: %s""), e)",if conf . enabled :,133
"def _validate(self, data): <TAB> verrors = ValidationErrors() <TAB> realms = await self.query() <TAB> for realm in realms: <MASK> verrors.add( <TAB>  <TAB>  <TAB>  <TAB> f""kerberos_realm"", <TAB>  <TAB>  <TAB>  <TAB> f'kerberos realm with name {realm[""realm""]} already exists.', <TAB>  <TAB>  <TAB> ) <TAB> return verrors","if realm [ ""realm"" ] . upper ( ) == data [ ""realm"" ] . upper ( ) :",106
"def validate_time_sheets_are_submitted(self): <TAB> for data in self.timesheets: <TAB>  <TAB> if data.time_sheet: <TAB>  <TAB>  <TAB> status = frappe.db.get_value(""Timesheet"", data.time_sheet, ""status"") <MASK> frappe.throw( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _(""Timesheet {0} is already completed or cancelled"").format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> data.time_sheet <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> )","if status not in [ ""Submitted"" , ""Payslip"" ] :",136
"def on_copy_action_triggered(self): <TAB> cells = self.selectedIndexes() <TAB> cells.sort() <TAB> current_row = 0 <TAB> text = """" <TAB> for cell in cells: <TAB>  <TAB> if len(text) > 0 and cell.row() != current_row: <TAB>  <TAB>  <TAB> text += ""\n"" <TAB>  <TAB> current_row = cell.row() <MASK> text += str(cell.data()) <TAB> QApplication.instance().clipboard().setText(text)",if cell . data ( ) is not None :,123
"def read(self, size=None): <TAB> if size < 0: <TAB>  <TAB> size = None <TAB> remaining = size <TAB> data = [] <TAB> while self.current and (remaining > 0 or remaining is None): <TAB>  <TAB> data_read = self.current.read(remaining or -1) <TAB>  <TAB> if len(data_read) < remaining or remaining is None:  # Exhausted file <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> self.current = next(self.g) <TAB>  <TAB>  <TAB> except StopIteration: <TAB>  <TAB>  <TAB>  <TAB> self.current = None <MASK> remaining -= len(data_read) <TAB>  <TAB> data.extend(data_read) <TAB> return data",if not remaining is None :,163
"def find_inpath(self, path, rootdir=""""): <TAB> """"""Find file in a path set such as PATH=/usr/bin:/bin"""""" <TAB> if isinstance(path, str): <TAB>  <TAB> if ""="" in path: <TAB>  <TAB>  <TAB> path = """".join(path.split(""="", 1)[1:]) <TAB>  <TAB> path = path.split("":"") <TAB> if isinstance(path, (list, tuple)): <TAB>  <TAB> for directory in path: <TAB>  <TAB>  <TAB> full_path = rootdir + directory + ""/"" + self.basename <MASK> return directory + ""/"" + self.basename <TAB>  <TAB> return """" <TAB> return """"",if os . path . lexists ( full_path ) :,150
"def lock(self): <TAB> """"""Implement node lock (triggered by ""Lock node"" action)."""""" <TAB> # Lock ""action"" has been triggered, so state will have changed. <TAB> if self.lock_mode_action.isChecked():  # Just become active <TAB>  <TAB> self.plock = self.pc.c.p.copy()  # make a copy of node position <TAB>  <TAB> self.plockmode = self.get_mode()  # make a copy of the current node <MASK> self.pc.scrollbar_pos_dict[self.pr.v] = ( <TAB>  <TAB>  <TAB>  <TAB> self.view.page().mainFrame().scrollBarValue(QtCore.Qt.Vertical) <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> self.render_delegate()",if self . pr :,181
"def _get_fullpackagespec(package): <TAB> r = package.name <TAB> version_good = package.version != None and package.version != """" <TAB> revision_good = package.revision != None and package.revision != """" <TAB> if version_good or revision_good: <TAB>  <TAB> r += ""_"" <MASK> r += package.version <TAB>  <TAB>  <TAB> if revision_good: <TAB>  <TAB>  <TAB>  <TAB> r += ""-"" <TAB>  <TAB> if revision_good: <TAB>  <TAB>  <TAB> r += package.revision <TAB> return r",if version_good :,124
"def check_banned_words(text: str) -> List[str]: <TAB> lower_cased_text = text.lower() <TAB> errors = [] <TAB> for word, reason in BANNED_WORDS.items(): <MASK> # Hack: Should move this into BANNED_WORDS framework; for <TAB>  <TAB>  <TAB> # now, just hand-code the skips: <TAB>  <TAB>  <TAB> if ""realm_name"" in lower_cased_text: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> kwargs = dict(word=word, text=text, reason=reason) <TAB>  <TAB>  <TAB> msg = ""{word} found in '{text}'. {reason}"".format(**kwargs) <TAB>  <TAB>  <TAB> errors.append(msg) <TAB> return errors",if word in lower_cased_text :,174
"def parse_optional_create(argv): <TAB> optional_args = {} <TAB> for arg in argv: <MASK> ips = [ip for ip in arg[2:].split("","") if ip] <TAB>  <TAB>  <TAB> if not ips: <TAB>  <TAB>  <TAB>  <TAB> usage() <TAB>  <TAB>  <TAB> optional_args[""portals_ips""] = ips <TAB>  <TAB> elif arg.startswith(""-p""): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> optional_args[""portals_port""] = int(arg[2:]) <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> usage() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> optional_args[""initiator_iqns""] = arg <TAB> return optional_args","if arg . startswith ( ""-a"" ) :",161
"def store(self): <TAB> if getattr(self._data, ""id"", None) is None: <TAB>  <TAB> new_id = self.shorty_id if self.shorty_id else None <TAB>  <TAB> while 1: <TAB>  <TAB>  <TAB> id = new_id if new_id else get_random_uid() <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> docid = URL.db.resource.put(content=self._data, path=f""/{id}/"")[""id""] <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> break <TAB>  <TAB> self._data = URL.db.get(docid) <TAB> else: <TAB>  <TAB> super().store(URL.db) <TAB> return self",if docid :,168
"def sniff(self, filename): <TAB> rdata_header = b""RDX2\nX\n"" <TAB> try: <TAB>  <TAB> header = open(filename, ""rb"").read(7) <MASK> return True <TAB>  <TAB> header = gzip.open(filename).read(7) <TAB>  <TAB> if header == rdata_header: <TAB>  <TAB>  <TAB> return True <TAB> except Exception: <TAB>  <TAB> return False",if header == rdata_header :,107
def read(self): <TAB> try: <TAB>  <TAB> first_packet = await self.connection._read_packet() <TAB>  <TAB> # TODO: use classes for different packet types? <TAB>  <TAB> if first_packet.is_ok_packet(): <TAB>  <TAB>  <TAB> self._read_ok_packet(first_packet) <MASK> await self._read_load_local_packet(first_packet) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> await self._read_result_packet(first_packet) <TAB> finally: <TAB>  <TAB> self.connection = None,elif first_packet . is_load_local_packet ( ) :,138
"def recursionFolder(self, client, folder=0, tfolder=""""): <TAB> files = client.File.list(folder) <TAB> for f in files: <TAB>  <TAB> if f.content_type == ""application/x-directory"": <TAB>  <TAB>  <TAB> if f.name == tfolder: <TAB>  <TAB>  <TAB>  <TAB> return f.id <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> result = self.recursionFolder(client, f.id, tfolder) <MASK> return result <TAB> return 0",if result != 0 :,122
"def _generate_dir_lines(prefix_path, varname, dirs): <TAB> lines = [] <TAB> varnames = [] <TAB> for i, directory in enumerate(dirs): <TAB>  <TAB> directory = os.path.normpath(directory).replace(""\\"", ""/"") <TAB>  <TAB> name = varname if i == 0 else ""%s%d"" % (varname, (i + 1)) <TAB>  <TAB> prefix = """" <MASK> prefix = ""${prefix}/"" <TAB>  <TAB> elif directory.startswith(prefix_path): <TAB>  <TAB>  <TAB> prefix = ""${prefix}/"" <TAB>  <TAB>  <TAB> directory = os.path.relpath(directory, prefix_path).replace(""\\"", ""/"") <TAB>  <TAB> lines.append(""%s=%s%s"" % (name, prefix, directory)) <TAB>  <TAB> varnames.append(name) <TAB> return lines, varnames",if not os . path . isabs ( directory ) :,187
"def complete(self, text, state): <TAB> if state == 0: <TAB>  <TAB> line = readline.get_line_buffer().lstrip() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> context = CompletionContext(self.pupsrv, self, self.config, self.commands) <TAB>  <TAB>  <TAB> compfunc, module, args = self.commands.completer(context, line) <TAB>  <TAB>  <TAB> self.completion_matches = compfunc(module, args, text, context) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> logger.debug(traceback.format_exc()) <TAB> try: <MASK> return self.completion_matches[state] <TAB> except IndexError: <TAB>  <TAB> return None",if self . completion_matches :,160
"def fetch(): <TAB> retval = {} <TAB> content = retrieve_content(__url__) <TAB> if __check__ in content: <TAB>  <TAB> for line in content.split(""\n""): <TAB>  <TAB>  <TAB> line = line.strip() <MASK> continue <TAB>  <TAB>  <TAB> retval[line.split()[0]] = (__info__, __reference__) <TAB> return retval","if not line or line . startswith ( ""#"" ) or ""."" not in line :",97
"def serialize(self, serializer): <TAB> self.updater.serialize(serializer[""updater""]) <TAB> if hasattr(self.stop_trigger, ""serialize""): <TAB>  <TAB> self.stop_trigger.serialize(serializer[""stop_trigger""]) <TAB> s = serializer[""extensions""] <TAB> t = serializer[""extension_triggers""] <TAB> for name, entry in six.iteritems(self._extensions): <TAB>  <TAB> if hasattr(entry.extension, ""serialize""): <TAB>  <TAB>  <TAB> entry.extension.serialize(s[name]) <MASK> entry.trigger.serialize(t[name]) <TAB> if isinstance(serializer, serializer_module.Serializer): <TAB>  <TAB> serializer(""_snapshot_elapsed_time"", self.elapsed_time) <TAB> else: <TAB>  <TAB> self._snapshot_elapsed_time = serializer(""_snapshot_elapsed_time"", 0.0)","if hasattr ( entry . trigger , ""serialize"" ) :",195
"def old_parse_version(s): <TAB> parts = [] <TAB> for part in _parse_version_parts(s.lower()): <MASK> # remove '-' before a prerelease tag <TAB>  <TAB>  <TAB> if part < ""*final"": <TAB>  <TAB>  <TAB>  <TAB> while parts and parts[-1] == ""*final-"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> parts.pop() <TAB>  <TAB>  <TAB> # remove trailing zeros from each series of numeric parts <TAB>  <TAB>  <TAB> while parts and parts[-1] == ""00000000"": <TAB>  <TAB>  <TAB>  <TAB> parts.pop() <TAB>  <TAB> parts.append(part) <TAB> return tuple(parts)","if part . startswith ( ""*"" ) :",141
"def parse_strings(data, counter, l): <TAB> i = 0 <TAB> error_count = 0 <TAB> while i < len(data): <TAB>  <TAB> data_slice = data[i : i + 2] <TAB>  <TAB> if len(data_slice) < 2: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> len_ = struct.unpack(""<h"", data_slice)[0] <TAB>  <TAB> i += 2 <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> l[counter] = data[i : i + len_ * 2].decode(""utf-16"") <TAB>  <TAB>  <TAB> except UnicodeDecodeError: <TAB>  <TAB>  <TAB>  <TAB> error_count += 1 <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> if error_count >= 3: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> i += len_ * 2 <TAB>  <TAB> counter += 1",if len_ != 0 and 0 <= len_ * 2 <= len ( data ) :,199
"def generate_pingback_content(soup, target, max_length, trunc_char=""...""): <TAB> """"""Generate a description text for the pingback"""""" <TAB> link = soup.find(""a"", href=target) <TAB> content = strip_tags(unicode(link.findParent())) <TAB> index = content.index(link.string) <TAB> if len(content) > max_length: <TAB>  <TAB> middle = max_length / 2 <TAB>  <TAB> start = index - middle <TAB>  <TAB> end = index + middle <TAB>  <TAB> if start <= 0: <TAB>  <TAB>  <TAB> end -= start <TAB>  <TAB>  <TAB> extract = content[0:end] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> extract = ""%s%s"" % (trunc_char, content[start:end]) <MASK> extract += trunc_char <TAB>  <TAB> return extract <TAB> return content",if end < len ( content ) :,195
"def _get_active_outputs(self): <TAB> data = self.py3.command_output([""xrandr""]).splitlines() <TAB> connected_outputs = [x.split() for x in data if "" connected"" in x] <TAB> active_outputs = [] <TAB> for output in connected_outputs: <TAB>  <TAB> for x in output[2:]: <MASK> active_outputs.append(output[0]) <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> elif ""("" in x: <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return active_outputs","if ""x"" in x and ""+"" in x :",135
"def set_cart_count(quotation=None): <TAB> if cint(frappe.db.get_singles_value(""Shopping Cart Settings"", ""enabled"")): <TAB>  <TAB> if not quotation: <TAB>  <TAB>  <TAB> quotation = _get_cart_quotation() <TAB>  <TAB> cart_count = cstr(len(quotation.get(""items""))) <MASK> frappe.local.cookie_manager.set_cookie(""cart_count"", cart_count)","if hasattr ( frappe . local , ""cookie_manager"" ) :",124
"def run_all_blocks( <TAB> self, <TAB> definition, <TAB> definitions_context, <TAB> full_file_path, <TAB> root_folder, <TAB> report, <TAB> scanned_file, <TAB> runner_filter,): <TAB> for block_type in definition.keys(): <MASK> self.run_block( <TAB>  <TAB>  <TAB>  <TAB> definition[block_type], <TAB>  <TAB>  <TAB>  <TAB> definitions_context, <TAB>  <TAB>  <TAB>  <TAB> full_file_path, <TAB>  <TAB>  <TAB>  <TAB> root_folder, <TAB>  <TAB>  <TAB>  <TAB> report, <TAB>  <TAB>  <TAB>  <TAB> scanned_file, <TAB>  <TAB>  <TAB>  <TAB> block_type, <TAB>  <TAB>  <TAB>  <TAB> runner_filter, <TAB>  <TAB>  <TAB> )",if block_type in CHECK_BLOCK_TYPES :,167
"def visit_Name(self, node): <TAB> n = node.id <TAB> node.kind = _kind.UNDEFINED <TAB> if n in self.root.symdict: <TAB>  <TAB> obj = self.root.symdict[n] <TAB>  <TAB> if isinstance(obj, _Signal): <TAB>  <TAB>  <TAB> node.kind = _kind.SIGNAL <TAB>  <TAB> elif obj is delay: <TAB>  <TAB>  <TAB> node.kind = _kind.DELAY <MASK> node.kind = _kind.EDGE",elif obj is posedge or obj is negedge :,124
"def logic(): <TAB> a = Signal(bool()) <TAB> while 1: <TAB>  <TAB> yield clock.posedge, reset.negedge <TAB>  <TAB> if reset == ACTIVE_LOW: <TAB>  <TAB>  <TAB> count.next = 0 <TAB>  <TAB> else: <MASK> count.next = (count + 1) % n",if enable :,79
"def admins_only_wrapper(*args, **kwargs): <TAB> if is_admin(): <TAB>  <TAB> return f(*args, **kwargs) <TAB> else: <MASK> abort(403) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return redirect(url_for(""auth.login"", next=request.full_path))","if request . content_type == ""application/json"" :",87
"def getIp(self, prefix=""192.168.""): <TAB> # ip addr | grep 'inet' | awk '{print $2}' \ <TAB> # <TAB> | awk -F/ '{print $1}' | fgrep '192.168.' | head -n1 <TAB> out = self.cmd(""ip addr"") <TAB> for line in out.splitlines(): <TAB>  <TAB> line = line.strip() <TAB>  <TAB> if line.startswith(""inet""): <TAB>  <TAB>  <TAB> ip = line.split()[1].split(""/"")[0] <MASK> return ip <TAB> raise RuntimeError(""Could not determine ip of host "" + repr(self.name))",if ip . startswith ( prefix ) :,155
"def onEventPreview(self, event): <TAB> # preventDefault on mousedown events, outside of the <TAB> # dialog, to stop text-selection on dragging <TAB> type = DOM.eventGetType(event) <TAB> if type == ""mousedown"": <TAB>  <TAB> target = DOM.eventGetTarget(event) <TAB>  <TAB> elem = self.caption.getElement() <TAB>  <TAB> event_targets_popup = target and DOM.isOrHasChild(elem, target) <MASK> DOM.eventPreventDefault(event) <TAB> return PopupPanel.onEventPreview(self, event)",if event_targets_popup :,143
"def write_tr(values, tag): <TAB> print(u""<tr>"", end="""", file=file) <TAB> for i, value in enumerate(values): <TAB>  <TAB> if tag == ""th"": <TAB>  <TAB>  <TAB> template = u""<{}>{}</{}>"" <MASK> template = u'<{} style=""text-align:right"">{}</{}>' <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> template = u'<{} style=""text-align:left"">{}</{}>' <TAB>  <TAB> print( <TAB>  <TAB>  <TAB> template.format(tag, html_escape(cypher_str(value)), tag), end="""", file=file <TAB>  <TAB> ) <TAB> print(u""</tr>"", end="""", file=file)","elif auto_align and self . _fields [ i ] [ ""numeric"" ] :",166
"def _normalized_jdk_paths(self): <TAB> normalized = {} <TAB> jdk_paths = self.get_options().paths or {} <TAB> for name, paths in sorted(jdk_paths.items()): <TAB>  <TAB> rename = normalize_os_name(name) <MASK> logger.warning( <TAB>  <TAB>  <TAB>  <TAB> 'Multiple OS names alias to ""{}""; combining results.'.format(rename) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> normalized[rename].extend(paths) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> normalized[rename] = paths <TAB> return normalized",if rename in normalized :,134
"def resolve_bases(bases): <TAB> """"""Resolve MRO entries dynamically as specified by PEP 560."""""" <TAB> new_bases = list(bases) <TAB> updated = False <TAB> shift = 0 <TAB> for i, base in enumerate(bases): <TAB>  <TAB> if isinstance(base, type): <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> new_base = base.__mro_entries__(bases) <TAB>  <TAB> updated = True <TAB>  <TAB> if not isinstance(new_base, tuple): <TAB>  <TAB>  <TAB> raise TypeError(""__mro_entries__ must return a tuple"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_bases[i + shift : i + shift + 1] = new_base <TAB>  <TAB>  <TAB> shift += len(new_base) - 1 <TAB> if not updated: <TAB>  <TAB> return bases <TAB> return tuple(new_bases)","if not hasattr ( base , ""__mro_entries__"" ) :",198
"def __init__(self, parent, keypart): <TAB> if keypart is None: <TAB>  <TAB> self.__dict__[""_parser""] = parent <TAB>  <TAB> self.__dict__[""__root__""] = self <TAB>  <TAB> self.__dict__[""__key__""] = """" <TAB>  <TAB> self.__dict__[""_setvalue""] = getattr(parent, ""setvalue"") <TAB>  <TAB> self.__dict__[""_removekey""] = getattr(parent, ""removekey"") <TAB>  <TAB> self.__dict__[""_resolve""] = getattr(parent, ""resolveconfigobject"") <TAB>  <TAB> self.__dict__[""_assignments""] = {} <TAB> else: <TAB>  <TAB> self.__dict__[""__root__""] = parent.__root__ <MASK> self.__dict__[""__key__""] = keypart <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.__dict__[""__key__""] = parent.__key__ + ""."" + keypart","if parent . __key__ == """" :",192
"def _search_start(self): <TAB> while 1: <TAB>  <TAB> pos = self.fp.tell() <TAB>  <TAB> line = self.fp.readline() <MASK> raise EOFError <TAB>  <TAB> if line[:5] == ""From "" and self._isrealfromline(line): <TAB>  <TAB>  <TAB> self.fp.seek(pos) <TAB>  <TAB>  <TAB> return",if not line :,88
"def update(self): <TAB> torrent_ids = component.get(""TorrentView"").get_selected_torrents() <TAB> # Set True if torrent(s) selected in torrentview, else False. <TAB> self._child_widget.set_sensitive(bool(torrent_ids)) <TAB> if torrent_ids: <MASK> self.clear() <TAB>  <TAB> component.get(""SessionProxy"").get_torrents_status( <TAB>  <TAB>  <TAB> {""id"": torrent_ids}, self.status_keys <TAB>  <TAB> ).addCallback(self.parse_torrents_statuses) <TAB>  <TAB> self.prev_torrent_ids = torrent_ids",if torrent_ids != self . prev_torrent_ids :,170
"def __hash__(self): <TAB> if self._hashcode == -1: <TAB>  <TAB> tzoff = self.utcoffset() <MASK> self._hashcode = hash(self._getstate()[0]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> days = _ymd2ord(self.year, self.month, self.day) <TAB>  <TAB>  <TAB> seconds = self.hour * 3600 + self.minute * 60 + self.second <TAB>  <TAB>  <TAB> self._hashcode = hash(timedelta(days, seconds, self.microsecond) - tzoff) <TAB> return self._hashcode",if tzoff is None :,138
"def _wait_for(fd, readable, writable, error, expiration): <TAB> done = False <TAB> while not done: <TAB>  <TAB> if expiration is None: <TAB>  <TAB>  <TAB> timeout = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> timeout = expiration - time.time() <TAB>  <TAB>  <TAB> if timeout <= 0.0: <TAB>  <TAB>  <TAB>  <TAB> raise dns.exception.Timeout <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if not _polling_backend(fd, readable, writable, error, timeout): <TAB>  <TAB>  <TAB>  <TAB> raise dns.exception.Timeout <TAB>  <TAB> except select_error as e: <MASK> raise e <TAB>  <TAB> done = True",if e . args [ 0 ] != errno . EINTR :,161
"def _configure_lr_scheduler(self, client_lr_scheduler): <TAB> # First check for scheduler in json configuration <TAB> lr_scheduler = self._scheduler_from_config(self.optimizer) <TAB> if lr_scheduler: <MASK> logger.info( <TAB>  <TAB>  <TAB>  <TAB> f""DeepSpeed using configured LR scheduler = {self.scheduler_name()}"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self.lr_scheduler = lr_scheduler <TAB> else: <TAB>  <TAB> if self.global_rank == 0: <TAB>  <TAB>  <TAB> logger.info(""DeepSpeed using client LR scheduler"") <TAB>  <TAB> self.lr_scheduler = client_lr_scheduler <TAB> log_dist(f""DeepSpeed LR Scheduler = {self.lr_scheduler}"", ranks=[0])",if self . global_rank == 0 :,183
"def find_ranking_tokens(self, node: Node) -> list: <TAB> ranking_tokens = [] <TAB> for elem in node.descendants: <MASK> ranking_tokens.append(elem.ord) <TAB>  <TAB>  <TAB> ranking_tokens.append(elem.parent.ord) <TAB>  <TAB>  <TAB> return ranking_tokens <TAB> return ranking_tokens",if self . morph . parse ( elem . form ) [ 0 ] . normal_form in self . ranking_tokens :,103
"def request(self, host, handler, request_body, verbose=False): <TAB> # retry request once if cached connection has gone cold <TAB> for i in (0, 1): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self.single_request(host, handler, request_body, verbose) <TAB>  <TAB> except http.client.RemoteDisconnected: <TAB>  <TAB>  <TAB> if i: <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> except OSError as e: <MASK> raise","if i or e . errno not in ( errno . ECONNRESET , errno . ECONNABORTED , errno . EPIPE ) :",138
"def to_tree(self, tagname=None, value=None, namespace=None): <TAB> namespace = getattr(self, ""namespace"", namespace) <TAB> if value is not None: <MASK> tagname = ""{%s}%s"" % (namespace, tagname) <TAB>  <TAB> value = safe_string(value) <TAB>  <TAB> return Element(tagname, {self.attribute: value})",if namespace is not None :,95
"def consume(self): <TAB> for token in self.snakefile: <TAB>  <TAB> self.indentation(token) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> for t, orig in self.state(token): <MASK> yield INDENT * self.effective_indent, orig <TAB>  <TAB>  <TAB>  <TAB> yield t, orig <TAB>  <TAB>  <TAB>  <TAB> self.lasttoken = t <TAB>  <TAB> except tokenize.TokenError as e: <TAB>  <TAB>  <TAB> self.error( <TAB>  <TAB>  <TAB>  <TAB> str(e).split("","")[0].strip(""()''""), token <TAB>  <TAB>  <TAB> )  # TODO the inferred line number seems to be wrong sometimes","if self . lasttoken == ""\n"" and not t . isspace ( ) :",156
"def run(self): <TAB> while True: <TAB>  <TAB> (host, port), attempt = self._resolve_queue.get() <TAB>  <TAB> response = self._do_resolve(host, port) <MASK> self._cache[(host, port)] = (time.time(), response) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if attempt < 10: <TAB>  <TAB>  <TAB>  <TAB> self.resolve_async(host, port, attempt + 1) <TAB>  <TAB>  <TAB>  <TAB> time.sleep(1)",if response :,114
"def wrapped(cls, ctx, op): <TAB> from .session import Session <TAB> from .context import ContextBase <TAB> # skip in some test cases <TAB> if not hasattr(ctx, ""get_current_session""): <TAB>  <TAB> return func(cls, ctx, op) <TAB> session = ctx.get_current_session() <TAB> prev_default_session = Session.default <TAB> session.as_default() <TAB> try: <MASK> with ctx: <TAB>  <TAB>  <TAB>  <TAB> result = func(cls, ctx, op) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result = func(cls, ctx, op) <TAB> finally: <TAB>  <TAB> Session._set_default_session(prev_default_session) <TAB> return result","if isinstance ( ctx , ContextBase ) :",172
"def __iter__(self): <TAB> # Iterate over this file-like object by newlines <TAB> buffer_ = None <TAB> for chunk in self.chunks(): <TAB>  <TAB> chunk_buffer = BytesIO(chunk) <TAB>  <TAB> for line in chunk_buffer: <TAB>  <TAB>  <TAB> if buffer_: <TAB>  <TAB>  <TAB>  <TAB> line = buffer_ + line <TAB>  <TAB>  <TAB>  <TAB> buffer_ = None <TAB>  <TAB>  <TAB> # If this is the end of a line, yield <TAB>  <TAB>  <TAB> # otherwise, wait for the next round <MASK> yield line <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> buffer_ = line <TAB> if buffer_ is not None: <TAB>  <TAB> yield buffer_","if line [ - 1 ] in ( ""\n"" , ""\r"" ) :",162
"def get_stat_string(self, mode: int = 1) -> str: <TAB> stat_string = """" <TAB> for k, v in self.info.items(): <TAB>  <TAB> stat_string += ""[{}:{}]"".format(k, v) <TAB> stat_string += ""[iters:{}]\n"".format(self.num_iters) <TAB> for i in range(len(self.metric_names)): <MASK> stat_string += ""[{}:{:.3f}]"".format( <TAB>  <TAB>  <TAB>  <TAB> self.metric_names[i], <TAB>  <TAB>  <TAB>  <TAB> self.metrics[i][mode], <TAB>  <TAB>  <TAB> ) <TAB> return stat_string",if self . metrics [ i ] [ mode ] is not None :,160
"def _forward(self): <TAB> buf = [] <TAB> try: <TAB>  <TAB> while not self._shutdown: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> line = self.pipe_rfile.readline() <TAB>  <TAB>  <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB>  <TAB> buf.append(line) <TAB>  <TAB>  <TAB>  <TAB> if line.endswith(""\n""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._send(buf) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> buf = [] <TAB>  <TAB>  <TAB> except IOError: <TAB>  <TAB>  <TAB>  <TAB> break <MASK> self._send(buf) <TAB> except Exception as e: <TAB>  <TAB> logger.error(""_forward err: %s"", e)",if buf :,158
"def join(url1, url2): <TAB> if not url1: <TAB>  <TAB> return url2 <TAB> if not url2: <TAB>  <TAB> return url1 <TAB> for s in customSchemes: <MASK> dummyScheme = ""http://localhost"" <TAB>  <TAB>  <TAB> tempUrl = dummyScheme + url1[len(s) :] <TAB>  <TAB>  <TAB> if not tempUrl.endswith(""/""): <TAB>  <TAB>  <TAB>  <TAB> tempUrl = tempUrl + ""/"" <TAB>  <TAB>  <TAB> tempUrl = urllib.parse.urljoin(tempUrl, url2) <TAB>  <TAB>  <TAB> return s + tempUrl[len(dummyScheme) :] <TAB> if Fs.driver.registry.isNative(url1): <TAB>  <TAB> return os.path.join(url1, url2).replace(""/"", ""\\"") <TAB> return urllib.parse.urljoin(url1, url2)",if url1 . startswith ( s ) :,197
"def run_recursive(c): <TAB> """"""Recursive descent."""""" <TAB> c.__active_path[""start_time""] = time.time() <TAB> p = c.p <TAB> aList = [z.copy() for z in c.p.self_and_subtree()] <TAB> for p2 in reversed(aList): <MASK> g.es( <TAB>  <TAB>  <TAB>  <TAB> ""Recursive processing aborts after %f seconds"" <TAB>  <TAB>  <TAB>  <TAB> % c.__active_path[""timeout""] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> yield p2 <TAB> c.redraw(p)","if time . time ( ) - c . __active_path [ ""start_time"" ] >= c . __active_path [ ""timeout"" ] :",162
"def _get_existing_target_items(self, prepared_items: List[Dict]) -> Dict[str, Dict]: <TAB> result = {} <TAB> for item in prepared_items: <TAB>  <TAB> target_path = item[""target_path""] <TAB>  <TAB> if os.path.exists(target_path): <MASK> kind = ""dir"" <TAB>  <TAB>  <TAB>  <TAB> size = None <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> kind = ""file"" <TAB>  <TAB>  <TAB>  <TAB> size = os.path.getsize(target_path) <TAB>  <TAB>  <TAB> result[target_path] = { <TAB>  <TAB>  <TAB>  <TAB> ""kind"": kind, <TAB>  <TAB>  <TAB>  <TAB> ""size"": size, <TAB>  <TAB>  <TAB> } <TAB> return result",if os . path . isdir ( target_path ) :,176
"def _best_nrepeats_for_scaling(src_size, max_dest_size): <TAB> min_remainder = N <TAB> min_remainder_nrepeats = 1 <TAB> nrepeats = 0 <TAB> dest_size = 0 <TAB> while dest_size <= max_dest_size: <TAB>  <TAB> nrepeats += 1 <TAB>  <TAB> dest_size += src_size <TAB>  <TAB> remainder = dest_size % N <TAB>  <TAB> if remainder < min_remainder: <TAB>  <TAB>  <TAB> min_remainder_nrepeats = nrepeats <TAB>  <TAB>  <TAB> min_remainder = remainder <MASK> break <TAB> return min_remainder_nrepeats",if remainder == 0 :,146
"def _canSet(cls, data, nameValuePlug): <TAB> if isinstance(data, IECore.CompoundData) and ""value"" in data: <TAB>  <TAB> valueData = data[""value""] <MASK> if ""enabled"" in data and not ValueAdaptor.canSet( <TAB>  <TAB>  <TAB>  <TAB> data[""enabled""], nameValuePlug[""enabled""] <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> else: <TAB>  <TAB> # Allow simple data to be pasted onto the value plug <TAB>  <TAB> valueData = data <TAB> return ValueAdaptor.canSet(valueData, nameValuePlug[""value""])","if ""enabled"" in nameValuePlug :",151
"def _add_plugin_views_to_compare_view(self, compare_view, plugin_views): <TAB> key = ""{# individual plugin views #}"" <TAB> insertion_index = compare_view.find(key) <TAB> if insertion_index == -1: <TAB>  <TAB> logging.error(""compare view insertion point not found in compare template"") <TAB> else: <TAB>  <TAB> insertion_index += len(key) <TAB>  <TAB> for plugin, view in plugin_views: <MASK> view = ""{}\n{}"".format(if_case, view.decode()) <TAB>  <TAB>  <TAB> compare_view = self._insert_plugin_into_view_at_index( <TAB>  <TAB>  <TAB>  <TAB> view, compare_view, insertion_index <TAB>  <TAB>  <TAB> ) <TAB> return compare_view","if_case = ""{{% elif plugin == '{}' %}}"" . format ( plugin )",190
"def before_write_items(self, items, nulls_map=None): <TAB> null_value = self.null_value <TAB> for i, item in enumerate(items): <MASK> items[i] = null_value <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # allow Ipv4 in integer, string or IPv4Address object <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if isinstance(item, int): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if not isinstance(item, IPv4Address): <TAB>  <TAB>  <TAB>  <TAB> item = IPv4Address(item) <TAB>  <TAB>  <TAB> items[i] = int(item) <TAB>  <TAB> except AddressValueError: <TAB>  <TAB>  <TAB> raise errors.CannotParseDomainError(""Cannot parse IPv4 '{}'"".format(item))",if nulls_map and nulls_map [ i ] :,181
"def save_list(self, doc, items, prop_node): <TAB> items_node = doc.createElement(""items"") <TAB> prop_node.appendChild(items_node) <TAB> for item in items: <TAB>  <TAB> item_node = doc.createElement(""item"") <TAB>  <TAB> items_node.appendChild(item_node) <MASK> item_node.appendChild(item) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> text_node = doc.createTextNode(item) <TAB>  <TAB>  <TAB> item_node.appendChild(text_node)","if isinstance ( item , Node ) :",130
"def get_extensions(type, subtree=None): <TAB> if subtree is None: <TAB>  <TAB> subtree = full_extension_tree() <TAB> for key, value in subtree.items(): <TAB>  <TAB> if key == type: <TAB>  <TAB>  <TAB> return get_all_extensions(subtree=value) <TAB>  <TAB> elif isinstance(value, dict): <TAB>  <TAB>  <TAB> sub_extensions = get_extensions(type, subtree=value) <MASK> return sub_extensions <TAB> return None",if sub_extensions :,114
"def prettyIn(self, value): <TAB> try: <TAB>  <TAB> if isinstance(value, str): <TAB>  <TAB>  <TAB> return value <TAB>  <TAB> elif isinstance(value, str): <TAB>  <TAB>  <TAB> return value.decode(self.encoding) <MASK> return self.prettyIn("""".join([chr(x) for x in value])) <TAB>  <TAB> elif isinstance(value, univ.OctetString): <TAB>  <TAB>  <TAB> return value.asOctets().decode(self.encoding) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return str(value) <TAB> except (UnicodeDecodeError, LookupError): <TAB>  <TAB> raise error.PyAsn1Error( <TAB>  <TAB>  <TAB> ""Can't decode string '%s' with codec %s"" % (value, self.encoding) <TAB>  <TAB> )","elif isinstance ( value , ( tuple , list ) ) :",182
"def cleanup(path): <TAB> CLEANUP_BINARIES = [ <TAB>  <TAB> ""gtk3-widget-factory"", <TAB>  <TAB> ""gtk3-demo-application"", <TAB>  <TAB> ""gtk3-demo"", <TAB> ] <TAB> if KEEP_BUSYBOX: <TAB>  <TAB> if os.path.exists(os.path.join(path, ""usr/bin/busybox"")): <TAB>  <TAB>  <TAB> symlink(""busybox.static"", os.path.join(path, ""usr/bin/busybox"")) <TAB> else: <TAB>  <TAB> CLEANUP_BINARIES += [""busybox"", ""busybox.static""] <TAB> for filename in CLEANUP_BINARIES: <TAB>  <TAB> full_path = os.path.join(path, ""usr/bin"", filename) <MASK> os.unlink(full_path)",if os . path . exists ( full_path ) :,198
"def __new__(cls, clsname, bases, dict): <TAB> if decorator: <TAB>  <TAB> for name, method in dict.items(): <MASK> dict[name] = decorator(_run_on_failure_decorator, method) <TAB> return type.__new__(cls, clsname, bases, dict)","if not name . startswith ( ""_"" ) and inspect . isroutine ( method ) :",87
"def load_defense_output(filename): <TAB> """"""Loads output of defense from given file."""""" <TAB> result = {} <TAB> with open(filename) as f: <TAB>  <TAB> for row in csv.reader(f): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> image_filename = row[0] <MASK> image_filename += "".png"" <TAB>  <TAB>  <TAB>  <TAB> label = int(row[1]) <TAB>  <TAB>  <TAB> except (IndexError, ValueError): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> result[image_filename] = label <TAB> return result","if not image_filename . endswith ( "".png"" ) :",140
"def sh_rrx(num, shval, size=4, emu=None): <TAB> # shval should always be 0 <TAB> newC = num & 1 <TAB> if emu is not None: <TAB>  <TAB> oldC = emu.getFlag(PSR_C_bit) <MASK> emu.setFlag(PSR_C_bit, newC) <TAB> else: <TAB>  <TAB> # total hack!  should we just bomb here without an emu? <TAB>  <TAB> oldC = 0 <TAB> half1 = (num & e_bits.u_maxes[size]) >> 1 <TAB> half2 = oldC << (31) <TAB> retval = (half1 | half2 | (oldC << (32 - shval))) & e_bits.u_maxes[size] <TAB> return retval","if emu . getMeta ( ""forrealz"" , False ) :",199
"def format_money(self, m, format=""standard"", trailing_zeroes=True): <TAB> s = self.currency_formats[format].apply( <TAB>  <TAB> m.amount, <TAB>  <TAB> self, <TAB>  <TAB> currency=m.currency, <TAB>  <TAB> currency_digits=True, <TAB>  <TAB> decimal_quantization=True, <TAB> ) <TAB> if trailing_zeroes is False: <TAB>  <TAB> i = s.find(self.number_symbols[""decimal""]) <MASK> s = s[:i] <TAB> return s",if i != - 1 and set ( s [ i + 1 : ] ) == ONLY_ZERO :,140
"def parse_name(self, content): <TAB> path, name = _name_parser_regex.match(content).groups() <TAB> if path: <TAB>  <TAB> modulename = path.rstrip(""."") <TAB> else: <TAB>  <TAB> modulename = self.env.temp_data.get(""autodoc:module"") <MASK> modulename = self.env.ref_context.get(""py:module"") <TAB> if modulename is None: <TAB>  <TAB> raise RuntimeError( <TAB>  <TAB>  <TAB> ""modulename somehow None for %s in %s."" % (content, self.env.docname) <TAB>  <TAB> ) <TAB> return modulename, name",if not modulename :,150
"def set_thread_count(self, count): <TAB> with self.lock: <TAB>  <TAB> threads = self.threads <TAB>  <TAB> thread_no = 0 <TAB>  <TAB> running = len(threads) - self.stop_count <TAB>  <TAB> while running < count: <TAB>  <TAB>  <TAB> # Start threads. <TAB>  <TAB>  <TAB> while thread_no in threads: <TAB>  <TAB>  <TAB>  <TAB> thread_no = thread_no + 1 <TAB>  <TAB>  <TAB> threads.add(thread_no) <TAB>  <TAB>  <TAB> running += 1 <TAB>  <TAB>  <TAB> self.start_new_thread(self.handler_thread, thread_no) <TAB>  <TAB>  <TAB> self.active_count += 1 <TAB>  <TAB>  <TAB> thread_no = thread_no + 1 <MASK> # Stop threads. <TAB>  <TAB>  <TAB> self.stop_count += running - count <TAB>  <TAB>  <TAB> self.queue_cv.notify_all()",if running > count :,199
"def check(): <TAB> now = datetime.datetime.now() <TAB> diff = now - starttime <TAB> if (diff.seconds * 1000 * 1000 + diff.microseconds) < (timeout * 1000): <MASK> if ( <TAB>  <TAB>  <TAB>  <TAB> winprocess.QueryInformationJobObject(self._job, 8)[""BasicInfo""][ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""ActiveProcesses"" <TAB>  <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB>  <TAB> > 0 <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return True <TAB> return False",if self . _job :,130
"def _parse_inputs(self, skip=None): <TAB> fname, ext = op.splitext(self.inputs.in_coords) <TAB> setattr(self, ""_in_file"", fname) <TAB> setattr(self, ""_outformat"", ext[1:]) <TAB> first_args = super(WarpPoints, self)._parse_inputs(skip=[""in_coords"", ""out_file""]) <TAB> second_args = fname + "".txt"" <TAB> if ext in ["".vtk"", "".trk""]: <MASK> self._tmpfile = tempfile.NamedTemporaryFile( <TAB>  <TAB>  <TAB>  <TAB> suffix="".txt"", dir=os.getcwd(), delete=False <TAB>  <TAB>  <TAB> ).name <TAB>  <TAB> second_args = self._tmpfile <TAB> return first_args + [second_args]",if self . _tmpfile is None :,178
"def _add_default_intents( <TAB> cls, <TAB> intent_properties: Dict[Text, Dict[Text, Union[bool, List]]], <TAB> entities: List[Text], <TAB> roles: Optional[Dict[Text, List[Text]]], <TAB> groups: Optional[Dict[Text, List[Text]]],) -> None: <TAB> for intent_name in rasa.shared.core.constants.DEFAULT_INTENTS: <MASK> _, properties = cls._intent_properties(intent_name, entities, roles, groups) <TAB>  <TAB>  <TAB> intent_properties.update(properties)",if intent_name not in intent_properties :,144
"def _setup(self, mod, target): <TAB> tgts = {} <TAB> if isinstance(target, dict): <TAB>  <TAB> for dev, tgt in target.items(): <MASK> raise Exception(""Unknown target type"") <TAB>  <TAB>  <TAB> tgts[dev] = Target(tgt) <TAB> elif isinstance(target, (str, Target)): <TAB>  <TAB> tgts[_expr.IntImm(""int32"", 0)] = Target(target) <TAB> self._init(mod, tgts)","if not isinstance ( tgt , ( str , Target ) ) :",128
"def where(self, **overrides): <TAB> if ""urls"" in overrides: <TAB>  <TAB> existing_urls = self.route.get(""urls"", ()) <TAB>  <TAB> use_urls = [] <TAB>  <TAB> for url in ( <TAB>  <TAB>  <TAB> (overrides[""urls""],) <TAB>  <TAB>  <TAB> if isinstance(overrides[""urls""], str) <TAB>  <TAB>  <TAB> else overrides[""urls""] <TAB>  <TAB> ): <MASK> use_urls.append(url) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> for existing in existing_urls: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> use_urls.append(urljoin(existing.rstrip(""/"") + ""/"", url)) <TAB>  <TAB> overrides[""urls""] = tuple(use_urls) <TAB> return super().where(**overrides)","if url . startswith ( ""/"" ) or not existing_urls :",175
"def get_final_resort_exe_cmd(game, files): <TAB> # This is the final resort, applies to FTL <TAB> exe_cmd = [""""] <TAB> game_files = os.listdir(""game"") <TAB> for file in game_files: <MASK> os.chdir(os.path.join(game.install_dir, ""game"")) <TAB>  <TAB>  <TAB> with open(file, ""r"") as info_file: <TAB>  <TAB>  <TAB>  <TAB> info = json.loads(info_file.read()) <TAB>  <TAB>  <TAB>  <TAB> exe_cmd = [""./{}"".format(info[""playTasks""][0][""path""])] <TAB> return exe_cmd","if re . match ( r""^goggame-[0-9]*\.info$"" , file ) :",169
"def assert_widget(self, widget, response): <TAB> if hasattr(WIDGETS[widget], ""redirect""): <MASK> self.assertEqual(response.redirect_chain[0][1], 301) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertEqual(response.status_code, 301) <TAB> elif ""svg"" in WIDGETS[widget].content_type: <TAB>  <TAB> self.assert_svg(response) <TAB> else: <TAB>  <TAB> self.assert_png(response)","if hasattr ( response , ""redirect_chain"" ) :",125
"def _queue_upload(self, obj): <TAB> """"""Put *obj* into upload queue"""""" <TAB> while True: <TAB>  <TAB> if self.to_upload.put(obj, timeout=5): <TAB>  <TAB>  <TAB> return <TAB>  <TAB> for t in self.upload_threads: <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise NoWorkerThreads(""no upload threads"")",if t . is_alive ( ) :,97
"def print_callees(self, *amount): <TAB> width, list = self.get_print_list(amount) <TAB> if list: <TAB>  <TAB> self.calc_callees() <TAB>  <TAB> self.print_call_heading(width, ""called..."") <TAB>  <TAB> for func in list: <MASK> self.print_call_line(width, func, self.all_callees[func]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.print_call_line(width, func, {}) <TAB>  <TAB> print(file=self.stream) <TAB>  <TAB> print(file=self.stream) <TAB> return self",if func in self . all_callees :,153
"def _handle_join(self, query, field, joins): <TAB> model_class = None <TAB> try: <TAB>  <TAB> model_class = field.model_class <TAB> except AttributeError: <TAB>  <TAB> model_class = field.model <TAB> if model_class != self.model: <TAB>  <TAB> model_name = model_class.__name__ <MASK> query = query.join(model_class, JOIN.LEFT_OUTER) <TAB>  <TAB>  <TAB> joins.add(model_name) <TAB> return query",if model_name not in joins :,125
"def validate_max_discount(self): <TAB> for d in self.get(""items""): <TAB>  <TAB> if d.item_code: <TAB>  <TAB>  <TAB> discount = flt(frappe.get_cached_value(""Item"", d.item_code, ""max_discount"")) <MASK> frappe.throw( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _(""Maximum discount for Item {0} is {1}%"").format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> d.item_code, discount <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> )",if discount and flt ( d . discount_percentage ) > discount :,141
"def OnPopupTimer(self, event): <TAB> _tooltipallowed = False <TAB> # TODO This prevents tool tip for ex. Template edit field in wxPhoenix <TAB> try: <TAB>  <TAB> _tooltipallowed = self.Parent.tooltip_allowed(self._tooltip) <TAB> except AttributeError: <TAB>  <TAB> # print(""DEBUG: There was an attempt to show a Tool Tip.\n"") <TAB>  <TAB> pass <TAB> if _tooltipallowed: <TAB>  <TAB> details, title = self._get_details_for_tooltip() <MASK> self._tooltip.set_content(details, title) <TAB>  <TAB>  <TAB> self._tooltip.show_at(self._tooltip_position())",if details :,156
"def GetMenuItems(self, menu_name): <TAB> # Get all menu items for the menu name (eg, ""edit"") <TAB> bindings = self.edit.bindings <TAB> ret = [] <TAB> for ext in self.extensions.itervalues(): <TAB>  <TAB> menudefs = getattr(ext, ""menudefs"", []) <TAB>  <TAB> for name, items in menudefs: <MASK> for text, event in [item for item in items if item is not None]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> text = text.replace(""&"", ""&&"") <TAB>  <TAB>  <TAB>  <TAB>  <TAB> text = text.replace(""_"", ""&"") <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ret.append((text, event)) <TAB> return ret",if name == menu_name :,159
"def build(opt): <TAB> dpath = os.path.join(opt[""datapath""], ""COPA"") <TAB> version = None <TAB> if not build_data.built(dpath, version_string=version): <TAB>  <TAB> print(""[building data: "" + dpath + ""]"") <MASK> # an older version exists, so remove these outdated files. <TAB>  <TAB>  <TAB> build_data.remove_dir(dpath) <TAB>  <TAB> build_data.make_dir(dpath) <TAB>  <TAB> # Download the data. <TAB>  <TAB> for downloadable_file in RESOURCES: <TAB>  <TAB>  <TAB> downloadable_file.download_file(dpath) <TAB>  <TAB> # mark the data as built <TAB>  <TAB> build_data.mark_done(dpath, version_string=version)",if build_data . built ( dpath ) :,180
"def _get_normalized_property_set( <TAB> self, property_name, property_list: List[str]) -> Set[str]: <TAB> """"""Return a normalized set from a requirements or constraints list."""""" <TAB> normalized = set()  # type: Set[str] <TAB> for entry in property_list: <MASK> normalized.add(entry) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> entry_file = self._find_file(filename=entry) <TAB>  <TAB>  <TAB> if not entry_file: <TAB>  <TAB>  <TAB>  <TAB> raise SnapcraftPluginPythonFileMissing( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> plugin_property=property_name, plugin_property_value=entry <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> normalized.add(entry_file) <TAB> return normalized",if isurl ( entry ) :,179
"def collect_static_analysis_tests(base_dir, test_files): <TAB> for f_name in os.listdir(base_dir): <TAB>  <TAB> files_to_execute = [a for a in test_files.items() if a[0] in f_name] <MASK> path = os.path.join(base_dir, f_name) <TAB>  <TAB>  <TAB> yield StaticAnalysisCase(path)","if f_name . endswith ( "".py"" ) and ( not test_files or files_to_execute ) :",119
"def __call__(self, other):  # noqa: F811 <TAB> if isinstance(other, MultiVector): <MASK> null = self.cga.null_vector(other) <TAB>  <TAB>  <TAB> return self.mv * null * ~self.mv <TAB>  <TAB> return self.mv * other * ~self.mv <TAB> else: <TAB>  <TAB> klass = other.__class__ <TAB>  <TAB> return klass(self.cga, self.mv * other.mv * ~self.mv)",if other . grades ( ) == { 1 } :,122
"def assertSuccessful(self, result): <TAB> if not result.wasSuccessful(): <TAB>  <TAB> output = ""expected success"" <MASK> output += ""\ntest failed: %s"" % result.failures[0][1].getErrorMessage() <TAB>  <TAB> if result.errors: <TAB>  <TAB>  <TAB> output += ""\nerrors: %s"" % [error[1].value for error in result.errors] <TAB>  <TAB> raise self.failureException(output) <TAB> self.assertTrue(result.wasSuccessful())",if result . failures :,117
"def __cleanup_file(filename): <TAB> data = None <TAB> dirty = False <TAB> with open(filename, mode=""r"", newline="""") as file: <TAB>  <TAB> data = file.read() <TAB>  <TAB> if ""\r\n"" in data: <TAB>  <TAB>  <TAB> data = data.replace(""\r\n"", ""\n"") <TAB>  <TAB>  <TAB> dirty = True <MASK> data = data.replace(""\r"", ""\n"") <TAB>  <TAB>  <TAB> dirty = True <TAB> if dirty: <TAB>  <TAB> new_filename = filename + "".new"" <TAB>  <TAB> with open(new_filename, mode=""w"", newline=""\n"") as new_file: <TAB>  <TAB>  <TAB> new_file.write(data) <TAB>  <TAB> os.replace(new_filename, filename)","if ""\r"" in data :",177
"def __call__(self, node): <TAB> for text in goal: <MASK> self.result = node <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if node.__class__.__name__.startswith(text): <TAB>  <TAB>  <TAB> self.result = node <TAB>  <TAB>  <TAB> break <TAB> return self.result is not None",if str ( node ) . startswith ( text ) :,79
"def match_tabs(self, s, i): <TAB> if 1:  # Use Qt code to show invisibles. <TAB>  <TAB> return 0 <TAB> else:  # Old code... <TAB>  <TAB> if not self.showInvisibles: <TAB>  <TAB>  <TAB> return 0 <TAB>  <TAB> if self.trace_leo_matches: <TAB>  <TAB>  <TAB> g.trace() <TAB>  <TAB> j = i <TAB>  <TAB> n = len(s) <TAB>  <TAB> while j < n and s[j] == ""\t"": <TAB>  <TAB>  <TAB> j += 1 <MASK> self.colorRangeWithTag(s, i, j, ""tab"") <TAB>  <TAB>  <TAB> return j - i <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return 0",if j > i :,165
"def _add_names(self, pymodule, modname, underlined): <TAB> if underlined is None: <TAB>  <TAB> underlined = self.underlined <TAB> globals = [] <TAB> if isinstance(pymodule, pyobjects.PyDefinedObject): <TAB>  <TAB> attributes = pymodule._get_structural_attributes() <TAB> else: <TAB>  <TAB> attributes = pymodule.get_attributes() <TAB> for name, pyname in attributes.items(): <TAB>  <TAB> if not underlined and name.startswith(""_""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if isinstance(pyname, (pynames.AssignedName, pynames.DefinedName)): <TAB>  <TAB>  <TAB> globals.append(name) <MASK> globals.append(name) <TAB> self.names[modname] = globals","if isinstance ( pymodule , builtins . BuiltinModule ) :",176
"def parse_args(cls, obj: Dict[str, Any]) -> Tuple[List[Any], Dict[str, Any]]: <TAB> args = [] <TAB> kwargs = {} <TAB> for key, value in obj.items(): <TAB>  <TAB> if not key.startswith(""@""): <TAB>  <TAB>  <TAB> if key == ARGS_FIELD: <TAB>  <TAB>  <TAB>  <TAB> args = value <MASK> continue <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> kwargs[key] = value <TAB> return args, kwargs",elif key in RESERVED_FIELDS . values ( ) :,123
"def _get_target_vol(self, volume): <TAB> tgt_vol = volume[""name""] <TAB> if self._active_backend_id: <TAB>  <TAB> ctxt = context.get_admin_context() <TAB>  <TAB> rep_type = self._get_volume_replicated_type(ctxt, volume) <MASK> tgt_vol = storwize_const.REPLICA_AUX_VOL_PREFIX + volume[""name""] <TAB> return tgt_vol",if rep_type :,116
"def get_relative_expiration_time(remaining): <TAB> values = [] <TAB> prev_non_zero_attr = False <TAB> for attr in [""years"", ""months"", ""days"", ""hours"", ""minutes""]: <TAB>  <TAB> value = getattr(remaining, attr) <TAB>  <TAB> if value > 0: <MASK> values.append(""and"") <TAB>  <TAB>  <TAB> values.append(str(value)) <TAB>  <TAB>  <TAB> values.append(attr[:-1] if value == 1 else attr) <TAB>  <TAB> if prev_non_zero_attr: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> prev_non_zero_attr = value > 0 <TAB> message = "" "".join(values) <TAB> return message",if prev_non_zero_attr :,167
"def get_page_title(self): <TAB> if self.creating: <TAB>  <TAB> if self.parent is None: <TAB>  <TAB>  <TAB> return _(""Create new %(product_class)s product"") % { <TAB>  <TAB>  <TAB>  <TAB> ""product_class"": self.product_class.name <TAB>  <TAB>  <TAB> } <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return _(""Create new variant of %(parent_product)s"") % { <TAB>  <TAB>  <TAB>  <TAB> ""parent_product"": self.parent.title <TAB>  <TAB>  <TAB> } <TAB> else: <MASK> return self.object.title <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return _(""Editing variant of %(parent_product)s"") % { <TAB>  <TAB>  <TAB>  <TAB> ""parent_product"": self.parent.title <TAB>  <TAB>  <TAB> }",if self . object . title or not self . parent :,184
"def _is_missing(self) -> bool: <TAB> try: <TAB>  <TAB> if self._is_interpolation(): <TAB>  <TAB>  <TAB> node = self._dereference_node( <TAB>  <TAB>  <TAB>  <TAB> throw_on_resolution_failure=False, throw_on_missing=True <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> if node is None: <TAB>  <TAB>  <TAB>  <TAB> # resolution failure <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> node = self <TAB>  <TAB> assert node is not None <MASK> ret = node._is_missing() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret = node._value() == ""???"" <TAB> except MissingMandatoryValue: <TAB>  <TAB> ret = True <TAB> assert isinstance(ret, bool) <TAB> return ret","if isinstance ( node , Container ) :",179
"def statusDone(self): <TAB> if self.printloop: <TAB>  <TAB> self.printloop.stop() <TAB>  <TAB> self.printloop = None <TAB> output(""All Builds Complete"") <TAB> # TODO: include a URL for all failing builds <TAB> names = sorted(self.buildRequests.keys()) <TAB> happy = True <TAB> for n in names: <TAB>  <TAB> code, text = self.results[n] <TAB>  <TAB> t = ""%s: %s"" % (n, builder.Results[code]) <MASK> t += "" (%s)"" % "" "".join(text) <TAB>  <TAB> output(t) <TAB>  <TAB> if code != builder.SUCCESS: <TAB>  <TAB>  <TAB> happy = False <TAB> if happy: <TAB>  <TAB> self.exitcode = 0 <TAB> else: <TAB>  <TAB> self.exitcode = 1 <TAB> self.running.callback(self.exitcode)",if text :,197
"def bmes_to_index(tags): <TAB> result = [] <TAB> if len(tags) == 0: <TAB>  <TAB> return result <TAB> word = (0, 0) <TAB> for i, t in enumerate(tags): <TAB>  <TAB> if i == 0: <TAB>  <TAB>  <TAB> word = (0, 0) <MASK> result.append(word) <TAB>  <TAB>  <TAB> word = (i, 0) <TAB>  <TAB> word = (word[0], word[1] + 1) <TAB> if word[1] != 0: <TAB>  <TAB> result.append(word) <TAB> return result","elif t . upper ( ) == ""B"" or t . upper ( ) == ""S"" :",151
"def convert_array_to_iq(arr: np.ndarray) -> np.ndarray: <TAB> if arr.ndim == 1: <TAB>  <TAB> if arr.dtype == np.complex64: <TAB>  <TAB>  <TAB> arr = arr.view(np.float32) <MASK> arr = arr.view(np.float64) <TAB>  <TAB> return arr.reshape((-1, 2), order=""C"") <TAB> elif arr.ndim == 2: <TAB>  <TAB> return arr <TAB> else: <TAB>  <TAB> raise ValueError(""Too many dimensions"")",elif arr . dtype == np . complex128 :,130
"def _tree_repr(self, tree): <TAB> if self._gorg is not Callable: <TAB>  <TAB> return super()._tree_repr(tree) <TAB> # For actual Callable (not its subclass) we override <TAB> # super()._tree_repr() for nice formatting. <TAB> arg_list = [] <TAB> for arg in tree[1:]: <MASK> arg_list.append(_type_repr(arg)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> arg_list.append(arg[0]._tree_repr(arg)) <TAB> if arg_list[0] == ""..."": <TAB>  <TAB> return repr(tree[0]) + ""[..., %s]"" % arg_list[1] <TAB> return repr(tree[0]) + ""[[%s], %s]"" % ("", "".join(arg_list[:-1]), arg_list[-1])","if not isinstance ( arg , tuple ) :",197
"def _callback(fut): <TAB> try: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> result = future.result() <TAB>  <TAB> except Exception as exc: <TAB>  <TAB>  <TAB> if errback: <TAB>  <TAB>  <TAB>  <TAB> result = errback(exc) <TAB>  <TAB>  <TAB>  <TAB> exc = None <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if callback: <TAB>  <TAB>  <TAB>  <TAB> result = callback(result) <TAB> except Exception as exc: <TAB>  <TAB> next.set_exception(exc) <TAB> else: <MASK> chain_future(result, next=next) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> next.set_result(result)","if isinstance ( result , Future ) :",161
"def _mixin_after_parsed(self): <TAB> if not self.args and not self.options.grains_run and not self.options.doc: <TAB>  <TAB> self.print_help() <TAB>  <TAB> self.error(""Requires function, --grains or --doc"") <TAB> elif len(self.args) >= 1: <MASK> self.error(""-g/--grains does not accept any arguments"") <TAB>  <TAB> if self.options.doc and len(self.args) > 1: <TAB>  <TAB>  <TAB> self.error(""You can only get documentation for one method at one time"") <TAB>  <TAB> self.config[""fun""] = self.args[0] <TAB>  <TAB> self.config[""arg""] = self.args[1:]",if self . options . grains_run :,176
"def test_jacobi(self, mod): <TAB> if is_prime(mod): <TAB>  <TAB> squares = set() <TAB>  <TAB> for root in range(1, mod): <TAB>  <TAB>  <TAB> assert jacobi(root * root, mod) == 1 <TAB>  <TAB>  <TAB> squares.add(root * root % mod) <TAB>  <TAB> for i in range(1, mod): <MASK> assert jacobi(i, mod) == -1 <TAB> else: <TAB>  <TAB> factors = factorization(mod) <TAB>  <TAB> for a in range(1, mod): <TAB>  <TAB>  <TAB> c = 1 <TAB>  <TAB>  <TAB> for i in factors: <TAB>  <TAB>  <TAB>  <TAB> c *= jacobi(a, i[0]) ** i[1] <TAB>  <TAB>  <TAB> assert c == jacobi(a, mod)",if i not in squares :,188
"def explicit_mlp(scope, x, sizes=(3, 1)): <TAB> for i, size in enumerate(sizes): <TAB>  <TAB> dense = scope.param(f""dense_{i}"", ExplicitDense.create, x.shape[-1], size) <TAB>  <TAB> x = dense(x) <MASK> x = nn.relu(x) <TAB> return x",if i + 1 < len ( sizes ) :,92
"def test___all__(self): <TAB> for name in self.io.__all__: <TAB>  <TAB> obj = getattr(self.io, name, None) <TAB>  <TAB> self.assertTrue(obj is not None, name) <MASK> continue <TAB>  <TAB> elif ""error"" in name.lower() or name == ""UnsupportedOperation"": <TAB>  <TAB>  <TAB> self.assertTrue(issubclass(obj, Exception), name) <TAB>  <TAB> elif not name.startswith(""SEEK_""): <TAB>  <TAB>  <TAB> self.assertTrue(issubclass(obj, self.IOBase))","if name == ""open"" :",125
"def _potential_locations(self, name=None, must_exist=False, is_dir=False): <TAB> # Will give an iterator over the full path of potential locations <TAB> # according to the search path. <TAB> for path in self.search_paths: <TAB>  <TAB> if os.path.isdir(path): <TAB>  <TAB>  <TAB> full_path = path <TAB>  <TAB>  <TAB> if name is not None: <TAB>  <TAB>  <TAB>  <TAB> full_path = os.path.join(path, name) <TAB>  <TAB>  <TAB> if not must_exist: <TAB>  <TAB>  <TAB>  <TAB> yield full_path <TAB>  <TAB>  <TAB> else: <MASK> yield full_path <TAB>  <TAB>  <TAB>  <TAB> elif os.path.exists(full_path): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield full_path",if is_dir and os . path . isdir ( full_path ) :,190
"def get_rules_given_trigger(trigger): <TAB> if isinstance(trigger, six.string_types): <TAB>  <TAB> return get_rules_with_trigger_ref(trigger_ref=trigger) <TAB> if isinstance(trigger, dict): <TAB>  <TAB> trigger_ref = trigger.get(""ref"", None) <MASK> return get_rules_with_trigger_ref(trigger_ref=trigger_ref) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""Trigger dict %s is missing ``ref``."" % trigger) <TAB> raise ValueError( <TAB>  <TAB> ""Unknown type %s for trigger. Cannot do rule lookups."" % type(trigger) <TAB> )",if trigger_ref :,154
"def send(self, data): <TAB> try: <TAB>  <TAB> result = self.socket.send(data) <TAB>  <TAB> return result <TAB> except socket.error as why: <TAB>  <TAB> if why.args[0] == EWOULDBLOCK: <TAB>  <TAB>  <TAB> return 0 <MASK> self.handle_close() <TAB>  <TAB>  <TAB> return 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise",elif why . args [ 0 ] in _DISCONNECTED :,103
"def exist_permission_on_roles( <TAB> self, view_name: str, permission_name: str, role_ids: List[int]) -> bool: <TAB> for role_id in role_ids: <TAB>  <TAB> role = self.role_model.objects(id=role_id).first() <TAB>  <TAB> permissions = role.permissions <MASK> for permission in permissions: <TAB>  <TAB>  <TAB>  <TAB> if (view_name == permission.view_menu.name) and ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> permission_name == permission.permission.name <TAB>  <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if permissions :,147
"def get_client(): <TAB> # Attempt a direct connection to each node until one succeeds. Using a <TAB> # non-PRIMARY read preference allows us to use the node even if it's a <TAB> # secondary. <TAB> for i, node in enumerate(nodes.keys()): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return connected( <TAB>  <TAB>  <TAB>  <TAB> pymongo.MongoClient( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> node, read_preference=ReadPreference.PRIMARY_PREFERRED <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> except pymongo.errors.ConnectionFailure: <MASK> raise",if i == len ( nodes ) - 1 :,144
"def get_cookies(self, response): <TAB> cookie_headers = None <TAB> if hasattr(response, ""msg""): <TAB>  <TAB> cookies = response.msg.getheaders(""set-cookie"") <MASK> log.debug(""Full cookies: %s"", cookies) <TAB>  <TAB>  <TAB> cookie_headers = [c.split("";"", 1)[0] for c in cookies] <TAB> return cookie_headers",if cookies :,93
"def test_wrong_datetime_insert(self): <TAB> with self.create_table(""a Date""): <TAB>  <TAB> wrongTime = date(5555, 1, 1) <TAB>  <TAB> nullTime = date(1, 1, 1) <TAB>  <TAB> self.client.execute(""INSERT INTO test (a) VALUES"", [(wrongTime,), (nullTime,)]) <TAB>  <TAB> query = ""SELECT * FROM test"" <TAB>  <TAB> inserted = self.emit_cli(query) <TAB>  <TAB> expected = ( <TAB>  <TAB>  <TAB> ""1970-01-01\n1970-01-01\n"" <MASK> else ""0000-00-00\n0000-00-00\n"" <TAB>  <TAB> ) <TAB>  <TAB> self.assertEqual(inserted, expected)","if self . server_version > ( 20 , 7 , 2 )",182
"def analyze_script(self, index=None): <TAB> """"""Analyze current script with pyflakes + find todos"""""" <TAB> if self.is_analysis_done: <TAB>  <TAB> return <TAB> if index is None: <TAB>  <TAB> index = self.get_stack_index() <TAB> if self.data: <TAB>  <TAB> finfo = self.data[index] <TAB>  <TAB> run_pyflakes, run_pep8 = self.pyflakes_enabled, self.pep8_enabled <MASK> finfo.run_code_analysis(run_pyflakes, run_pep8) <TAB>  <TAB> if self.todolist_enabled: <TAB>  <TAB>  <TAB> finfo.run_todo_finder() <TAB> self.is_analysis_done = True",if run_pyflakes or run_pep8 :,175
"def walk_from_files(self): <TAB> bucket = [] <TAB> while True: <TAB>  <TAB> for filename in self.walkpath_files: <TAB>  <TAB>  <TAB> with io.open(filename) as inf: <TAB>  <TAB>  <TAB>  <TAB> for line in inf: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # walk = [hash_map[x] for x in line.strip('\n\t').split('\t')] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> walk = [int(x) for x in line.strip(""\n\t"").split(""\t"")] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> bucket.append(walk) <MASK> yield bucket <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> bucket = [] <TAB>  <TAB> if len(bucket): <TAB>  <TAB>  <TAB> yield bucket",if len ( bucket ) == self . batch_size :,179
"def stress(seed, deque): <TAB> random.seed(seed) <TAB> for count in range(OPERATIONS): <MASK> function = random.choice([stress_pop, stress_popleft]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> function = random.choice(functions) <TAB>  <TAB> function(deque)",if len ( deque ) > 100 :,84
"def _recipient_to_cloud(self, recipient): <TAB> """"""Transforms a Recipient object to a cloud dict"""""" <TAB> data = None <TAB> if recipient: <TAB>  <TAB> data = {self._cc(""emailAddress""): {self._cc(""address""): recipient.address}} <MASK> data[self._cc(""emailAddress"")][self._cc(""name"")] = recipient.name <TAB> return data",if recipient . name :,96
"def when(self, matches, context): <TAB> to_remove = [] <TAB> for filepart in matches.markers.named(""path""): <TAB>  <TAB> patterns = defaultdict(list) <TAB>  <TAB> for match in reversed( <TAB>  <TAB>  <TAB> matches.range( <TAB>  <TAB>  <TAB>  <TAB> filepart.start, <TAB>  <TAB>  <TAB>  <TAB> filepart.end, <TAB>  <TAB>  <TAB>  <TAB> predicate=lambda match: ""weak-duplicate"" in match.tags, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ): <MASK> to_remove.append(match) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> patterns[match.name].append(match.pattern) <TAB> return to_remove",if match . pattern in patterns [ match . name ] :,162
"def replay_paths(paths): <TAB> """"""A generator yielding the full path to the replays under `replay_dir`."""""" <TAB> for path in paths: <MASK> yield path <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for f in os.listdir(path): <TAB>  <TAB>  <TAB>  <TAB> if f.lower().endswith("".sc2replay""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield os.path.join(path, f)","if path . lower ( ) . endswith ( "".sc2replay"" ) :",105
"def on_pathlist_browse_folder(self, event, default_dir=wx.EmptyString): <TAB> """"""Handle request for browsing for pathlist folder"""""" <TAB> with wx.DirDialog(self.__path_list_ctrl, ""Select image folder"") as dlg: <TAB>  <TAB> assert isinstance(dlg, wx.DirDialog) <MASK> path = dlg.GetPath() <TAB>  <TAB>  <TAB> self.add_paths_to_pathlist([path])",if dlg . ShowModal ( ) == wx . ID_OK :,111
"def __init__(self, initlist=None): <TAB> self.data = [] <TAB> if initlist is not None: <TAB>  <TAB> # XXX should this accept an arbitrary sequence? <TAB>  <TAB> if type(initlist) == type(self.data): <TAB>  <TAB>  <TAB> self.data[:] = initlist <MASK> self.data[:] = initlist.data[:] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.data = list(initlist)","elif isinstance ( initlist , UserList ) :",111
def others_iterator(p): <TAB> after = p.nodeAfterTree() <TAB> p1 = p.threadNext() <TAB> while p1 and p1 != after: <MASK> p1.moveToNodeAfterTree() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield p1.copy() <TAB>  <TAB>  <TAB> if others_pat.search(p1.b): <TAB>  <TAB>  <TAB>  <TAB> p1.moveToNodeAfterTree() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> p1.moveToThreadNext(),if p1 . isAtIgnoreNode ( ) or section_pat . match ( p1 . h ) :,140
"def __keyPress(self, widget, event): <TAB> if event.key == ""F"": <TAB>  <TAB> bound = self.__gadgetWidget.getViewportGadget().getPrimaryChild().bound() <MASK> bound = imath.Box3f(imath.V3f(0), imath.V3f(1, 1, 0)) <TAB>  <TAB> self.__gadgetWidget.getViewportGadget().frame(bound) <TAB>  <TAB> return True <TAB> return False",if bound . isEmpty ( ) :,121
def two_x87_reg(ii):  # one implicit <TAB> n = 0 <TAB> implicit = 0 <TAB> for op in _gen_opnds(ii): <TAB>  <TAB> if op_reg(op) and op_x87(op): <TAB>  <TAB>  <TAB> n = n + 1 <MASK> implicit = implicit + 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> return n == 2 and implicit == 1,if op_implicit ( op ) :,108
"def _write_all(self, data): <TAB> # the underlying stream may be something that does partial writes (like <TAB> # a socket). <TAB> while len(data) > 0: <TAB>  <TAB> count = self._write(data) <TAB>  <TAB> data = data[count:] <MASK> self._size += count <TAB>  <TAB>  <TAB> self._pos = self._realpos = self._size <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._pos += count <TAB>  <TAB>  <TAB> self._realpos += count <TAB> return None",if self . _flags & self . FLAG_APPEND :,129
"def cleanup_temp_file(self, entry): <TAB> if ""file"" in entry: <MASK> log.debug(""removing temp file %s from %s"", entry[""file""], entry[""title""]) <TAB>  <TAB>  <TAB> os.remove(entry[""file""]) <TAB>  <TAB> if os.path.exists(os.path.dirname(entry[""file""])): <TAB>  <TAB>  <TAB> shutil.rmtree(os.path.dirname(entry[""file""])) <TAB>  <TAB> del entry[""file""]","if os . path . exists ( entry [ ""file"" ] ) :",118
"def __init__(self, aggregate=""sum"", **kwargs): <TAB> super().__init__(**{k: v for k, v in kwargs.items() if is_keras_kwarg(k)}) <TAB> self.kwargs_keys = [] <TAB> for key in kwargs: <MASK> attr = kwargs[key] <TAB>  <TAB>  <TAB> attr = deserialize_kwarg(key, attr) <TAB>  <TAB>  <TAB> self.kwargs_keys.append(key) <TAB>  <TAB>  <TAB> setattr(self, key, attr) <TAB> self.msg_signature = inspect.signature(self.message).parameters <TAB> self.agg_signature = inspect.signature(self.aggregate).parameters <TAB> self.upd_signature = inspect.signature(self.update).parameters <TAB> self.agg = deserialize_scatter(aggregate)",if is_layer_kwarg ( key ) :,184
"def _verify_checkpoint_does_not_exist( <TAB> context: DataContext, checkpoint: str, usage_event: str) -> None: <TAB> try: <MASK> toolkit.exit_with_failure_message_and_stats( <TAB>  <TAB>  <TAB>  <TAB> context, <TAB>  <TAB>  <TAB>  <TAB> usage_event, <TAB>  <TAB>  <TAB>  <TAB> f""A checkpoint named `{checkpoint}` already exists. Please choose a new name."", <TAB>  <TAB>  <TAB> ) <TAB> except InvalidTopLevelConfigKeyError as e: <TAB>  <TAB> toolkit.exit_with_failure_message_and_stats( <TAB>  <TAB>  <TAB> context, usage_event, f""<red>{e}</red>"" <TAB>  <TAB> )",if checkpoint in context . list_checkpoints ( ) :,159
"def __init__(self, app_name, icon): <TAB> self.icon = icon <TAB> try: <MASK> Notify.init(app_name) <TAB>  <TAB>  <TAB> self.notifier = Notify <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> notify2.init(app_name) <TAB>  <TAB>  <TAB> self.notifier = notify2 <TAB>  <TAB> self.enabled = True <TAB> except DBusException: <TAB>  <TAB> print( <TAB>  <TAB>  <TAB> ""WARNING: No notification daemon found! "" ""Notifications will be ignored."" <TAB>  <TAB> ) <TAB>  <TAB> self.enabled = False",if Notify is not None :,136
"def add_op_link_var(op, var, op2var=False): <TAB> for arg in var.arguments: <TAB>  <TAB> if arg not in vars: <TAB>  <TAB>  <TAB> # add missing variables as argument <TAB>  <TAB>  <TAB> vars[arg] = graph.add_arg(arg, highlight=need_highlight(arg)) <TAB>  <TAB> varn = vars[arg] <TAB>  <TAB> highlight = need_highlight(op.description) or need_highlight(varn.description) <MASK> graph.add_edge(op, varn, highlight=highlight) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> graph.add_edge(varn, op, highlight=highlight)",if op2var :,157
"def __call__(self, context, request): <TAB> path = decode_path_info(request.environ[""PATH_INFO""] or ""/"") <TAB> registry = request.registry <TAB> mapper = registry.queryUtility(IRoutesMapper) <TAB> if mapper is not None and not path.endswith(""/""): <TAB>  <TAB> slashpath = path + ""/"" <TAB>  <TAB> for route in mapper.get_routes(): <MASK> qs = request.query_string <TAB>  <TAB>  <TAB>  <TAB> if qs: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> qs = ""?"" + qs <TAB>  <TAB>  <TAB>  <TAB> return self.redirect_class(location=request.path + ""/"" + qs) <TAB> return self.notfound_view(context, request)",if route . match ( slashpath ) is not None :,168
def _next(self): <TAB> max_entries = self.max_entries <TAB> while max_entries is None or self._num_entries < max_entries: <TAB>  <TAB> entry = next(self._queue) <TAB>  <TAB> if entry is not None: <TAB>  <TAB>  <TAB> self._out_queue.append(entry) <MASK> if not self._out_queue: <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB>  <TAB> entry = self._out_queue.popleft() <TAB>  <TAB>  <TAB> if self._should_return(entry): <TAB>  <TAB>  <TAB>  <TAB> self._num_entries += 1 <TAB>  <TAB>  <TAB>  <TAB> return entry <TAB> return None,if entry is None or len ( self . _out_queue ) > _MAX_EXTRA_COMMITS :,165
"def MoveRects(self, Dir): <TAB> for Object in self.MovingRects: <TAB>  <TAB> X, Y = Object.XY <TAB>  <TAB> if Dir == ""left"": <TAB>  <TAB>  <TAB> X -= 10 <MASK> X += 10 <TAB>  <TAB> elif Dir == ""up"": <TAB>  <TAB>  <TAB> Y += 10 <TAB>  <TAB> elif Dir == ""down"": <TAB>  <TAB>  <TAB> Y -= 10 <TAB>  <TAB> Object.SetPoint((X, Y)) <TAB> self.Canvas.Draw()","elif Dir == ""right"" :",115
"def echo_all(self): <TAB> if self.message: <TAB>  <TAB> self.echoerr(problem=self.message, indent=(self.indent - self.indent_shift)) <TAB> for variant in self.errs: <TAB>  <TAB> if not variant: <TAB>  <TAB>  <TAB> continue <MASK> self.echoerr( <TAB>  <TAB>  <TAB>  <TAB> problem=self.separator_message, indent=(self.indent - self.indent_shift) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> for kwargs in variant: <TAB>  <TAB>  <TAB> self.echoerr(**kwargs)",if self . separator_message and variant is not self . errs [ 0 ] :,139
"def statistics(self): <TAB> tasks_waiting_read = 0 <TAB> tasks_waiting_write = 0 <TAB> for waiter in self._registered.values(): <MASK> tasks_waiting_read += 1 <TAB>  <TAB> if waiter.write_task is not None: <TAB>  <TAB>  <TAB> tasks_waiting_write += 1 <TAB> return _EpollStatistics( <TAB>  <TAB> tasks_waiting_read=tasks_waiting_read, <TAB>  <TAB> tasks_waiting_write=tasks_waiting_write, <TAB> )",if waiter . read_task is not None :,132
"def _compare_metrics(self, other: Any): <TAB> if not isinstance(other, MetricList): <TAB>  <TAB> raise ValueError(""Cannot compare to an object not of type MetricList"") <TAB> for (name, metric), (other_name, other_metric) in zip( <TAB>  <TAB> self.metrics.items(), other.metrics.items() <TAB> ): <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Cannot compare two metric lists with "" ""different base metrics"" <TAB>  <TAB>  <TAB> )",if name != other_name or type ( metric ) is not type ( other_metric ) :,131
"def __uid_to_dn(self, uid, search=True): <TAB> """"""Convert uid to dn"""""" <TAB> # By default return a generated DN <TAB> userdn = FLAGS.ldap_user_id_attribute + ""=%s,%s"" % (uid, FLAGS.ldap_user_subtree) <TAB> if search: <TAB>  <TAB> query = ""%s=%s"" % (FLAGS.ldap_user_id_attribute, uid) <TAB>  <TAB> user = self.__find_dns(FLAGS.ldap_user_subtree, query) <MASK> userdn = user[0] <TAB> return userdn",if len ( user ) > 0 :,153
"def peers_from_features(cls, features, source): <TAB> peers = [] <TAB> if isinstance(features, dict): <TAB>  <TAB> hosts = features.get(""hosts"") <MASK> peers = [ <TAB>  <TAB>  <TAB>  <TAB> Peer(host, features, source=source) <TAB>  <TAB>  <TAB>  <TAB> for host in hosts <TAB>  <TAB>  <TAB>  <TAB> if isinstance(host, str) <TAB>  <TAB>  <TAB> ] <TAB> return peers","if isinstance ( hosts , dict ) :",106
"def match(self, module_name): <TAB> """"""Does `module_name` indicate a module in one of our packages?"""""" <TAB> if not module_name: <TAB>  <TAB> return False <TAB> for m in self.modules: <TAB>  <TAB> if module_name.startswith(m): <MASK> return True <TAB>  <TAB>  <TAB> if module_name[len(m)] == ""."": <TAB>  <TAB>  <TAB>  <TAB> # This is a module in the package <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if module_name == m :,119
"def execute(self): <TAB> for x in list(Context.g_module.variants): <TAB>  <TAB> self.make_variant(x) <TAB> lst = [""remote""] <TAB> for k in Options.commands: <MASK> name = k.replace(""_all"", """") <TAB>  <TAB>  <TAB> for x in Context.g_module.variants: <TAB>  <TAB>  <TAB>  <TAB> lst.append(""%s_%s"" % (name, x)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lst.append(k) <TAB> del Options.commands[:] <TAB> Options.commands += lst","if k . endswith ( ""_all"" ) :",134
"def _find_data_type(bases): <TAB> data_types = [] <TAB> for chain in bases: <TAB>  <TAB> candidate = None <TAB>  <TAB> for base in chain.__mro__: <TAB>  <TAB>  <TAB> if base is object: <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> if issubclass(base, Enum): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB>  <TAB> data_types.append(candidate or base) <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> elif not issubclass(base, Enum): <TAB>  <TAB>  <TAB>  <TAB> candidate = base <TAB> if len(data_types) > 1: <TAB>  <TAB> raise TypeError(""%r: too many data types: %r"" % (class_name, data_types)) <TAB> elif data_types: <TAB>  <TAB> return data_types[0] <TAB> else: <TAB>  <TAB> return None","elif ""__new__"" in base . __dict__ :",193
"def save(self, *args, **kwargs): <TAB> ""Process form"" <TAB> if self.instance: <MASK> if self.cleaned_data[""location""]: <TAB>  <TAB>  <TAB>  <TAB> self.instance.location = self.cleaned_data[""location""] <TAB>  <TAB>  <TAB> if self.cleaned_data[""status""]: <TAB>  <TAB>  <TAB>  <TAB> self.instance.status = self.cleaned_data[""status""] <TAB>  <TAB>  <TAB> self.instance.save() <TAB>  <TAB>  <TAB> if self.cleaned_data[""delete""]: <TAB>  <TAB>  <TAB>  <TAB> if self.cleaned_data[""delete""] == ""delete"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.instance.delete() <TAB>  <TAB>  <TAB>  <TAB> if self.cleaned_data[""delete""] == ""trash"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.instance.trash = True <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.instance.save()",if self . is_valid ( ) :,195
"def _flatten_shapely_collection(collection): <TAB> import shapely.geometry <TAB> if not isinstance(collection, list): <TAB>  <TAB> collection = [collection] <TAB> for item in collection: <MASK> for subitem in _flatten_shapely_collection(item.geoms): <TAB>  <TAB>  <TAB>  <TAB> # MultiPoint.geoms actually returns a GeometrySequence <TAB>  <TAB>  <TAB>  <TAB> if isinstance(subitem, shapely.geometry.base.GeometrySequence): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for subsubel in subitem: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield subsubel <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield _flatten_shapely_collection(subitem) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield item","if hasattr ( item , ""geoms"" ) :",162
"def Set_ParmValue(ph, ParmName, NewVal): <TAB> # set the value of the named parm in all instances (unindexed) <TAB> rootnode = ph._scenario_tree._stages[0]._tree_nodes[0] <TAB> for scenario in rootnode._scenarios: <TAB>  <TAB> instance = ph._instances[scenario._name] <TAB>  <TAB> pm = getattr(instance, ParmName) <MASK> for index in pm: <TAB>  <TAB>  <TAB>  <TAB> pm[index].value = NewVal[index] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pm.value = NewVal  ##### dlw adds value :(  Jan 2014 <TAB>  <TAB> # required for advanced preprocessing that takes <TAB>  <TAB> # place in PySP <TAB>  <TAB> ph._problem_states.user_constraints_updated[scenario._name] = True",if pm . is_indexed ( ) :,193
"def _generate_refs(self, count=10): <TAB> random_word_count = int(math.sqrt(count)) + 1 <TAB> words = RandomWords().random_words(count=random_word_count) <TAB> x_index = 0 <TAB> y_index = 0 <TAB> while count > 0: <TAB>  <TAB> yield ""%s.%s"" % (words[x_index], words[y_index]) <MASK> y_index += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> x_index += 1 <TAB>  <TAB>  <TAB> y_index = 0 <TAB>  <TAB> count -= 1 <TAB> return",if y_index < len ( words ) - 1 :,150
"def exists(self, path, value): <TAB> """"""check if value exists at path"""""" <TAB> try: <TAB>  <TAB> entry = Yedit.get_entry(self.yaml_dict, path, self.separator) <TAB> except KeyError: <TAB>  <TAB> entry = None <TAB> if isinstance(entry, list): <TAB>  <TAB> if value in entry: <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> return False <TAB> elif isinstance(entry, dict): <TAB>  <TAB> if isinstance(value, dict): <TAB>  <TAB>  <TAB> rval = False <TAB>  <TAB>  <TAB> for key, val in value.items(): <MASK> rval = False <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> rval = True <TAB>  <TAB>  <TAB> return rval <TAB>  <TAB> return value in entry <TAB> return entry == value",if entry [ key ] != val :,187
"def format_message(self): <TAB> bits = [self.message] <TAB> if self.possibilities: <MASK> bits.append(""Did you mean {}?"".format(self.possibilities[0])) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> possibilities = sorted(self.possibilities) <TAB>  <TAB>  <TAB> bits.append(""(Possible options: {})"".format("", "".join(possibilities))) <TAB> return ""  "".join(bits)",if len ( self . possibilities ) == 1 :,103
"def register(name, klass, instance=None, *, preferred=False): <TAB> """"""Register a browser connector."""""" <TAB> with _lock: <MASK> register_standard_browsers() <TAB>  <TAB> _browsers[name.lower()] = [klass, instance] <TAB>  <TAB> # Preferred browsers go to the front of the list. <TAB>  <TAB> # Need to match to the default browser returned by xdg-settings, which <TAB>  <TAB> # may be of the form e.g. ""firefox.desktop"". <TAB>  <TAB> if preferred or (_os_preferred_browser and name in _os_preferred_browser): <TAB>  <TAB>  <TAB> _tryorder.insert(0, name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _tryorder.append(name)",if _tryorder is None :,171
"def _snap_poll(self, url): <TAB> eventlet.sleep(datc.DEFAULT_SNAP_SLEEP) <TAB> TIMEOUT = 10 <TAB> retry = 0 <TAB> poll = True <TAB> while poll and retry < TIMEOUT: <TAB>  <TAB> retry += 1 <TAB>  <TAB> snap = self._issue_api_request(url, api_version=""2"") <MASK> poll = False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> eventlet.sleep(1) <TAB> if retry >= TIMEOUT: <TAB>  <TAB> raise exception.VolumeDriverException(message=_(""Snapshot not ready.""))","if snap [ ""op_state"" ] == ""available"" :",139
"def _add_import(self, node): <TAB> lineno = node.lineno <TAB> for target in node.names: <MASK> name, _, _ = target.name.partition(""."") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = target.asname <TAB>  <TAB> self.entry(name, lineno)",if target . asname is None :,77
"def _update_keymap(self, accel_path): <TAB> if not accel_path: <TAB>  <TAB> return <TAB> for k, v in list(self.keymap.items()): <MASK> del self.keymap[k] <TAB> found, key = Gtk.AccelMap.lookup_entry(accel_path) <TAB> if found: <TAB>  <TAB> for action in self.actions: <TAB>  <TAB>  <TAB> if action.get_accel_path() == accel_path: <TAB>  <TAB>  <TAB>  <TAB> shortcut = (key.accel_key, key.accel_mods) <TAB>  <TAB>  <TAB>  <TAB> self.keymap[shortcut] = action <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> logger.warning(""Ignoring keybinding for %r"", accel_path)",if v . get_accel_path ( ) == accel_path :,183
"def depth_first(self, filter=None): <TAB> """"""Returns a list of the nodes in the tree in depth-first order."""""" <TAB> if filter is None or not callable(filter): <TAB>  <TAB> filter = lambda e: True <TAB> elems = [] <TAB> if filter(self): <TAB>  <TAB> elems.append(self) <TAB> for sub in self.sub: <MASK> continue <TAB>  <TAB> if sub.isleaf() and filter(sub): <TAB>  <TAB>  <TAB> elems.append(sub) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> elems.extend(sub.depth_first()) <TAB> return elems","if not isinstance ( sub , StringElem ) :",146
"def validator(namespace): <TAB> if namespace.permission: <MASK> help_string = get_permission_help_string(permission_class) <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""valid values are {} or a combination thereof."".format(help_string) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> namespace.permission = permission_class(_str=namespace.permission)",if set ( namespace . permission ) - set ( allowed_string ) :,100
"def extract(self): <TAB> for name in self.vars: <TAB>  <TAB> self.val[name] = 0 <TAB> for l in self.splitlines(): <TAB>  <TAB> if l[4] == ""0002"": <TAB>  <TAB>  <TAB> self.val[""datagram""] += 1 <TAB>  <TAB> elif l[4] == ""0001"": <TAB>  <TAB>  <TAB> self.val[""stream""] += 1 <TAB>  <TAB>  <TAB> if l[5] == ""01"": <TAB>  <TAB>  <TAB>  <TAB> self.val[""listen""] += 1 <MASK> self.val[""established""] += 1","elif l [ 5 ] == ""03"" :",137
"def _uncached_match(self, text, pos, cache, error): <TAB> new_pos = pos <TAB> children = [] <TAB> while True: <TAB>  <TAB> node = self.members[0].match_core(text, new_pos, cache, error) <TAB>  <TAB> if node is None: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> children.append(node) <TAB>  <TAB> length = node.end - node.start <MASK> # Don't loop infinitely. <TAB>  <TAB>  <TAB> break <TAB>  <TAB> new_pos += length <TAB> if len(children) >= self.min: <TAB>  <TAB> return Node(self, text, pos, new_pos, children)",if length == 0 :,152
"def load(self): <TAB> import iris <TAB> imp.reload(iris) <TAB> imp.reload(iris.config) <TAB> config = iris.config.load_config(sys.argv[1]) <TAB> import iris.api <TAB> app = iris.api.get_api(config) <TAB> if not self.skip_build_assets: <TAB>  <TAB> for r in gc.get_referrers(self): <MASK> gunicorn_arbiter = r <TAB>  <TAB> # only build assets on one worker to avoid race conditions <TAB>  <TAB> if gunicorn_arbiter[""worker_age""] % self.options[""workers""] == 0: <TAB>  <TAB>  <TAB> import iris.ui <TAB>  <TAB>  <TAB> iris.ui.build_assets() <TAB> return app","if isinstance ( r , dict ) and ""_num_workers"" in r :",197
"def download_installer(remote_path, local_path): <TAB> retries = 0 <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> urllib.request.urlretrieve(remote_path, local_path) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> print(e) <TAB>  <TAB>  <TAB> retries += 1 <MASK> print( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Unable to recover after attempting to download {} {} times"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> remote_path, retries <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> exit(1) <TAB>  <TAB>  <TAB> time.sleep(10)",if retries >= MAX_INSTALLER_RETRY :,160
"def sync(self): <TAB> for key, val in self.mod.MAP[""fro""].items(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> assert self.mod.MAP[""to""][val] == key <TAB>  <TAB> except KeyError:  # missing value <TAB>  <TAB>  <TAB> print(""# Added %s=%s"" % (self.mod.MAP[""to""][val], key)) <TAB>  <TAB>  <TAB> self.mod.MAP[""to""][val] = key <TAB>  <TAB> except AssertionError: <TAB>  <TAB>  <TAB> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> ""Mismatch key:%s '%s' != '%s'"" % (key, val, self.mod.MAP[""to""][val]) <TAB>  <TAB>  <TAB> ) <TAB> for val in self.mod.MAP[""to""].values(): <MASK> print(""# Missing URN '%s'"" % val)","if val not in self . mod . MAP [ ""fro"" ] :",193
"def FindExtensions(object, kind, t_type=type(())): <TAB> if isinstance(kind, t_type): <TAB>  <TAB> result = [] <TAB>  <TAB> namespaceURI, name = kind <TAB>  <TAB> return [ <TAB>  <TAB>  <TAB> item <TAB>  <TAB>  <TAB> for item in object.extensions <MASK> and DOM.nsUriMatch(namespaceURI, item.namespaceURI) <TAB>  <TAB>  <TAB> and item.name == name <TAB>  <TAB> ] <TAB> return [item for item in object.extensions if isinstance(item, kind)]","if hasattr ( item , ""nodeType"" )",127
"def test_salt(self): <TAB> self.assertEqual(len(crypt._saltchars), 64) <TAB> for method in crypt.methods: <TAB>  <TAB> salt = crypt.mksalt(method) <TAB>  <TAB> self.assertIn(len(salt) - method.salt_chars, {0, 1, 3, 4, 6, 7}) <MASK> self.assertIn(method.ident, salt[: len(salt) - method.salt_chars])",if method . ident :,115
"def send_host(self, connection, host): <TAB> extra_headers = self._extra_headers <TAB> if extra_headers: <MASK> extra_headers = extra_headers.items() <TAB>  <TAB> for key, value in extra_headers: <TAB>  <TAB>  <TAB> connection.putheader(key, value)","if isinstance ( extra_headers , DictType ) :",82
def _get_mtimes(filenames): <TAB> filename_to_mtime = {} <TAB> for filename in filenames: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> filename_to_mtime[filename] = os.path.getmtime(filename) <TAB>  <TAB> except OSError as e: <TAB>  <TAB>  <TAB> # Ignore deleted includes. <MASK> raise <TAB> return filename_to_mtime,if e . errno != errno . ENOENT :,95
"def load_word_tag(self, f): <TAB> self.word_tag_tab = {} <TAB> f_name = resolve_filename(f) <TAB> for lineno, line in enumerate(f, 1): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> line = line.strip().decode(""utf-8"") <MASK> continue <TAB>  <TAB>  <TAB> word, _, tag = line.split("" "") <TAB>  <TAB>  <TAB> self.word_tag_tab[word] = tag <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""invalid POS dictionary entry in %s at Line %s: %s"" <TAB>  <TAB>  <TAB>  <TAB> % (f_name, lineno, line) <TAB>  <TAB>  <TAB> ) <TAB> f.close()",if not line :,173
"def handle_write_timeout(self): <TAB> try: <MASK> self.logger.debug(""Scheduling Ping"") <TAB>  <TAB>  <TAB> self._ping_task = asyncio.ensure_future(self.mqtt_ping()) <TAB> except BaseException as be: <TAB>  <TAB> self.logger.debug(""Exception ignored in ping task: %r"" % be)",if not self . _ping_task :,90
"def collect_optional_args( <TAB> self, <TAB> dispatcher: ""Dispatcher"", <TAB> update: Update = None, <TAB> check_result: Optional[Union[bool, Dict[str, Any]]] = None,) -> Dict[str, object]: <TAB> optional_args = super().collect_optional_args(dispatcher, update, check_result) <TAB> if isinstance(check_result, dict): <TAB>  <TAB> if self.pass_groups: <TAB>  <TAB>  <TAB> optional_args[""groups""] = check_result[""matches""][0].groups() <MASK> optional_args[""groupdict""] = check_result[""matches""][0].groupdict() <TAB> return optional_args",if self . pass_groupdict :,158
"def checkdep_ghostscript(): <TAB> try: <MASK> command_args = [""gswin32c"", ""--version""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> command_args = [""gs"", ""--version""] <TAB>  <TAB> s = subprocess.Popen( <TAB>  <TAB>  <TAB> command_args, stdout=subprocess.PIPE, stderr=subprocess.PIPE <TAB>  <TAB> ) <TAB>  <TAB> v = s.stdout.read()[:-1] <TAB>  <TAB> return v <TAB> except (IndexError, ValueError, OSError): <TAB>  <TAB> return None","if sys . platform == ""win32"" :",126
"def force_list_to_strings(lst): <TAB> if not lst: <TAB>  <TAB> return lst <TAB> new_list = [] <TAB> for item in lst: <TAB>  <TAB> if isinstance(item, basestring): <TAB>  <TAB>  <TAB> # Strings should not be unicode. <TAB>  <TAB>  <TAB> new_list.append(smart_str(item)) <MASK> # Recursively force dicts to strings. <TAB>  <TAB>  <TAB> new_list.append(force_dict_to_strings(item)) <TAB>  <TAB> elif isinstance(item, list): <TAB>  <TAB>  <TAB> new_list.append(force_list_to_strings(item)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Normal objects, or other literals, should not be converted. <TAB>  <TAB>  <TAB> new_list.append(item) <TAB> return new_list","elif isinstance ( item , dict ) :",185
"def visit_spec_seq(self, printer, seq, in_repeat=0, active=1): <TAB> for elem in seq: <MASK> count = len(elem.split()) <TAB>  <TAB>  <TAB> for i in xrange(count): <TAB>  <TAB>  <TAB>  <TAB> if active: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> printer.writeln(""last = tracker.visit_cur_forward()"") <TAB>  <TAB>  <TAB>  <TAB>  <TAB> printer.writeln(""effect |= last"") <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> printer.writeln(""tracker.skip()"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if active: <TAB>  <TAB>  <TAB>  <TAB> elem.active(printer, in_repeat) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> elem.passive(printer, in_repeat)","if isinstance ( elem , types . StringType ) :",185
"def search_box_callback(text): <TAB> with tree_widget: <MASK> print(""Loading..."") <TAB>  <TAB>  <TAB> tree_widget.clear_output(wait=True) <TAB>  <TAB>  <TAB> display(tree) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tree_widget.clear_output() <TAB>  <TAB>  <TAB> print(""Searching..."") <TAB>  <TAB>  <TAB> tree_widget.clear_output(wait=True) <TAB>  <TAB>  <TAB> sub_tree = search_api_tree(text.value, tree_dict) <TAB>  <TAB>  <TAB> display(sub_tree)","if text . value == """" :",131
"def get_tokens_unprocessed(self, text): <TAB> for index, token, value in CLexer.get_tokens_unprocessed(self, text): <TAB>  <TAB> if token is Name: <TAB>  <TAB>  <TAB> if value in self.variable_qualifiers: <TAB>  <TAB>  <TAB>  <TAB> token = Keyword.Type <TAB>  <TAB>  <TAB> elif value in self.vector_types: <TAB>  <TAB>  <TAB>  <TAB> token = Keyword.Type <TAB>  <TAB>  <TAB> elif value in self.variables: <TAB>  <TAB>  <TAB>  <TAB> token = Name.Builtin <TAB>  <TAB>  <TAB> elif value in self.execution_confs: <TAB>  <TAB>  <TAB>  <TAB> token = Keyword.Pseudo <MASK> token = Keyword.Reserved <TAB>  <TAB>  <TAB> elif value in self.functions: <TAB>  <TAB>  <TAB>  <TAB> token = Name.Function <TAB>  <TAB> yield index, token, value",elif value in self . function_qualifiers :,190
"def __call__(self, obj): <TAB> if isinstance(obj, SharedVariable): <MASK> if obj.name == ""pkl"": <TAB>  <TAB>  <TAB>  <TAB> ValueError(""can't pickle shared variable with name `pkl`"") <TAB>  <TAB>  <TAB> self.ndarray_names[id(obj.container.storage[0])] = obj.name <TAB>  <TAB> elif not self.allow_unnamed: <TAB>  <TAB>  <TAB> raise ValueError(""unnamed shared variable, {0}"".format(obj)) <TAB> return super(PersistentSharedVariableID, self).__call__(obj)",if obj . name :,127
"def tlv_parse(self, raw): <TAB> """"""Parse a string of TLV-encoded options."""""" <TAB> ret = {} <TAB> while raw: <TAB>  <TAB> [tag] = struct.unpack(""B"", raw[0]) <TAB>  <TAB> if tag == 0:  # padding <TAB>  <TAB>  <TAB> raw = raw[1:] <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tag == 255:  # end marker <TAB>  <TAB>  <TAB> break <TAB>  <TAB> [length] = struct.unpack(""B"", raw[1]) <TAB>  <TAB> value = raw[2 : 2 + length] <TAB>  <TAB> raw = raw[2 + length :] <MASK> ret[tag].append(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret[tag] = [value] <TAB> return ret",if tag in ret :,177
"def _to_bool_transformer(val=None): <TAB> if isinstance(val, (bool, int, float, complex, list, set, dict, tuple)): <TAB>  <TAB> return bool(val) <TAB> if isinstance(val, (type(""""), str)): <MASK> return True <TAB>  <TAB> if val.strip().lower() in (""false"", ""no"", """", ""n"", ""0""): <TAB>  <TAB>  <TAB> return False <TAB> raise TransformError(""bool"", val)","if val . strip ( ) . lower ( ) in ( ""yes"" , ""true"" , ""y"" , ""1"" ) :",126
"def collect_works(result_list): <TAB> wds = defaultdict(list) <TAB> rs = [] <TAB> # split result_list into two lists, those editions that have been assigned <TAB> # to a work and those that have not. <TAB> for r in result_list: <TAB>  <TAB> ws = r.get(""works"") <MASK> for w in ws: <TAB>  <TAB>  <TAB>  <TAB> wds[w[""key""]].append(r) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> rs.append(r) <TAB> # print >> web.debug, ('collect works', rs,wds) <TAB> s_works = sorted(wds.items(), key=lambda a_b: len(a_b[1]), reverse=True) <TAB> return rs, [(web.ctx.site.get(a), b) for a, b in s_works]",if ws :,197
"def extend_functions(self, func_data): <TAB> # func_data is a list of function metadata namedtuples <TAB> # dbmetadata['schema_name']['functions']['function_name'] should return <TAB> # the function metadata namedtuple for the corresponding function <TAB> metadata = self.dbmetadata[""functions""] <TAB> for f in func_data: <TAB>  <TAB> schema, func = self.escaped_names([f.schema_name, f.func_name]) <MASK> metadata[schema][func].append(f) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> metadata[schema][func] = [f] <TAB>  <TAB> self.all_completions.add(func) <TAB> self._refresh_arg_list_cache()",if func in metadata [ schema ] :,165
"def check(self): <TAB> cmd = ""cat+/etc/passwd;"" <TAB> for injection in self.injections: <TAB>  <TAB> path = injection.format(cmd) <TAB>  <TAB> response = self.http_request(method=""GET"", path=path) <TAB>  <TAB> if response is None: <TAB>  <TAB>  <TAB> continue <MASK> self.valid = injection <TAB>  <TAB>  <TAB> return True  # target is vulnerable <TAB> return False  # target not vulnerable","if utils . detect_file_content ( response . text , ""/etc/passwd"" ) :",120
"def match(self, yield_func, expression, vars, evaluation, **kwargs): <TAB> leaves = expression.get_sequence() <TAB> if self.head: <TAB>  <TAB> ok = True <TAB>  <TAB> for leaf in leaves: <TAB>  <TAB>  <TAB> if leaf.get_head() != self.head: <TAB>  <TAB>  <TAB>  <TAB> ok = False <TAB>  <TAB>  <TAB>  <TAB> break <MASK> yield_func(vars, None) <TAB> else: <TAB>  <TAB> yield_func(vars, None)",if ok :,113
"def _validate_orderby_items(self, res1, res2): <TAB> if len(res1) != len(res2): <TAB>  <TAB> # error <TAB>  <TAB> raise ValueError(""orderByItems cannot have different size"") <TAB> if len(res1) != len(self._sort_order): <TAB>  <TAB> # error <TAB>  <TAB> raise ValueError(""orderByItems cannot have a different size than sort orders."") <TAB> for elt1, elt2 in zip(res1, res2): <TAB>  <TAB> type1 = _OrderByHelper.getTypeStr(elt1) <TAB>  <TAB> type2 = _OrderByHelper.getTypeStr(elt2) <MASK> raise ValueError(""Expected {}, but got {}."".format(type1, type2))",if type1 != type2 :,174
"def __subclasshook__(cls, C): <TAB> if cls is Awaitable: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> for B in C.__mro__: <TAB>  <TAB>  <TAB>  <TAB> if ""__await__"" in B.__dict__: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if B.__dict__[""__await__""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB> # Old-style class <MASK> return True <TAB> return NotImplemented","if getattr ( C , ""__await__"" , None ) :",116
def _init_watcher(self): <TAB> with events._lock: <TAB>  <TAB> if self._watcher is None:  # pragma: no branch <TAB>  <TAB>  <TAB> self._watcher = ThreadedChildWatcher() <MASK> self._watcher.attach_loop(self._local._loop),"if isinstance ( threading . current_thread ( ) , threading . _MainThread ) :",81
"def get_new_files(self): <TAB> parser = _ahref_parser() <TAB> files = {} <TAB> for url, pattern in self.urls: <TAB>  <TAB> links = parser.get_ahref_list(urlparse.urljoin(self.prefix, url), pattern) <TAB>  <TAB> for link in links: <TAB>  <TAB>  <TAB> item = self._get_item(link) <MASK> files[item.name] = item <TAB> return self._get_new_files(files)",if item :,117
"def _doubleClick(self, widg, event): <TAB> """"""If double click, expand/collapse the row."""""" <TAB> if event.type == gtk.gdk._2BUTTON_PRESS: <TAB>  <TAB> path = self.get_cursor()[0] <MASK> self.collapse_row(path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.expand_row(path, False)",if self . row_expanded ( path ) :,100
"def _followBranch(self): <TAB> cursorX, cursorY = self.cursor.getPosition() <TAB> asm = self.OPCODES[cursorY] <TAB> if asm.isBranch(): <TAB>  <TAB> value = asm.branchAddress() <TAB>  <TAB> if value: <TAB>  <TAB>  <TAB> fofs = self.plugin.disasmVAtoFA(value) <TAB>  <TAB>  <TAB> if fofs is not None: <TAB>  <TAB>  <TAB>  <TAB> rowOfs = self._getOffsetOfRow(cursorY) <MASK> self.FlowHistory.append(rowOfs + self.dataModel.getOffset()) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.goTo(fofs)",if rowOfs is not None :,162
"def apply(self, symbols, attributes, evaluation): <TAB> ""SetAttributes[symbols_, attributes_]"" <TAB> symbols = get_symbol_list( <TAB>  <TAB> symbols, lambda item: evaluation.message(""SetAttributes"", ""sym"", item, 1) <TAB> ) <TAB> if symbols is None: <TAB>  <TAB> return <TAB> values = get_symbol_list( <TAB>  <TAB> attributes, lambda item: evaluation.message(""SetAttributes"", ""sym"", item, 2) <TAB> ) <TAB> if values is None: <TAB>  <TAB> return <TAB> for symbol in symbols: <MASK> evaluation.message(""SetAttributes"", ""locked"", Symbol(symbol)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for value in values: <TAB>  <TAB>  <TAB>  <TAB> evaluation.definitions.set_attribute(symbol, value) <TAB> return SymbolNull","if ""System`Locked"" in evaluation . definitions . get_attributes ( symbol ) :",190
"def test_gettext_literalblock(app): <TAB> app.build() <TAB> # --- gettext builder always ignores ``only`` directive <TAB> expect = read_po(app.srcdir / ""xx"" / ""LC_MESSAGES"" / ""literalblock.po"") <TAB> actual = read_po(app.outdir / ""literalblock.pot"") <TAB> for expect_msg in [m for m in expect if m.id]: <MASK> # compare tranlsations only labels <TAB>  <TAB>  <TAB> assert expect_msg.id in [m.id for m in actual if m.id] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pass  # skip code-blocks and literalblocks",if len ( expect_msg . id . splitlines ( ) ) == 1 :,165
"def _location(self, pyobject, add_module=False): <TAB> location = [] <TAB> parent = pyobject.parent <TAB> while parent and not isinstance(parent, pyobjects.AbstractModule): <TAB>  <TAB> location.append(parent.get_name()) <TAB>  <TAB> location.append(""."") <TAB>  <TAB> parent = parent.parent <TAB> if add_module: <TAB>  <TAB> if isinstance(pyobject, pyobjects.PyFunction): <TAB>  <TAB>  <TAB> module = pyobject.get_module() <TAB>  <TAB>  <TAB> location.insert(0, self._get_module(pyobject)) <MASK> location.insert(0, parent.get_name() + ""."") <TAB> return """".join(location)","if isinstance ( parent , builtins . BuiltinModule ) :",166
"def fill(img, p, num, nbs, acc, buf): <TAB> back = img[p] <TAB> img[p] = num <TAB> buf[0] = p <TAB> cur = 0 <TAB> s = 1 <TAB> while True: <TAB>  <TAB> p = buf[cur] <TAB>  <TAB> for dp in nbs: <TAB>  <TAB>  <TAB> cp = p + dp <MASK> img[cp] = num <TAB>  <TAB>  <TAB>  <TAB> buf[s] = cp <TAB>  <TAB>  <TAB>  <TAB> s += 1 <TAB>  <TAB> cur += 1 <TAB>  <TAB> if cur == s: <TAB>  <TAB>  <TAB> break <TAB> return idx2rc(buf[:s], acc)",if img [ cp ] == back :,157
"def resolve(self, *args, **kwargs): <TAB> try: <TAB>  <TAB> return func(self, *args, **kwargs) <TAB> except gaierror as ex: <MASK> # dnspython doesn't set an error message <TAB>  <TAB>  <TAB> ex.args = (EAI_NONAME, self.EAI_NONAME_MSG) <TAB>  <TAB>  <TAB> ex.errno = EAI_NONAME <TAB>  <TAB> raise",if ex . args [ 0 ] == EAI_NONAME and len ( ex . args ) == 1 :,118
"def assert_results(self, results, activities, msg=""""): <TAB> activity_ids = [] <TAB> extra_context = [] <TAB> for result in results: <MASK> activity_ids.append(result.serialization_id) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> activity_ids.append(result) <TAB>  <TAB> if hasattr(result, ""extra_context""): <TAB>  <TAB>  <TAB> extra_context.append(result.extra_context) <TAB> compare_lists(activity_ids, [a.serialization_id for a in activities], msg) <TAB> if extra_context: <TAB>  <TAB> self.assertEquals([a.extra_context for a in activities], extra_context)","if hasattr ( result , ""serialization_id"" ) :",164
"def run_drop(args): <TAB> """"""Drop the database"""""" <TAB> dbname = bigchaindb.config[""database""][""name""] <TAB> if not args.yes: <TAB>  <TAB> response = input_on_stderr( <TAB>  <TAB>  <TAB> ""Do you want to drop `{}` database? [y/n]: "".format(dbname) <TAB>  <TAB> ) <MASK> return <TAB> conn = backend.connect() <TAB> try: <TAB>  <TAB> schema.drop_database(conn, dbname) <TAB> except DatabaseDoesNotExist: <TAB>  <TAB> print( <TAB>  <TAB>  <TAB> ""Cannot drop '{name}'. The database does not exist."".format(name=dbname), <TAB>  <TAB>  <TAB> file=sys.stderr, <TAB>  <TAB> )","if response != ""y"" :",161
"def subkeys(key): <TAB> if not key.is_valid(): <TAB>  <TAB> return <TAB> for index in range(2): <MASK> sk_off = key.SubKeyLists[index] <TAB>  <TAB>  <TAB> sk = obj.Object(""_CM_KEY_INDEX"", sk_off, key.obj_vm) <TAB>  <TAB>  <TAB> if not sk or not sk.is_valid(): <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> for i in read_sklist(sk): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> i.Signature.v() == NK_SIG <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> and i.Parent.dereference().Name == key.Name <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield i",if int ( key . SubKeyCounts [ index ] ) > 0 :,194
"def inner_f(queue, **kwargs): <TAB> try: <TAB>  <TAB> func(**kwargs) <TAB>  <TAB> queue.put(1) <TAB> except Exception: <TAB>  <TAB> _trace = traceback.format_exc() <TAB>  <TAB> print(_trace) <TAB>  <TAB> # code 17 means RuntimeError: tensorflow/compiler/xla/xla_client/mesh_service.cc:364 : <TAB>  <TAB> # Failed to meet rendezvous 'torch_xla.core.xla_model.save': Socket closed (14) <MASK> queue.put(1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> queue.put(-1)","if ""terminated with exit code 17"" in _trace :",156
"def __eq__(self, other): <TAB> if isinstance(other, PackData): <TAB>  <TAB> return self.get_stored_checksum() == other.get_stored_checksum() <TAB> if isinstance(other, list): <TAB>  <TAB> if len(self) != len(other): <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> for o1, o2 in zip(self.iterobjects(), other): <MASK> return False <TAB>  <TAB> return True <TAB> return False",if o1 != o2 :,114
"def get_latency_60s(self): <TAB> """"""Returns the average request latency over the last 60s in seconds."""""" <TAB> with self._condition: <TAB>  <TAB> self._trim_request_history_to_60s() <MASK> return 0.0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> total_latency = sum(end - start for (start, end) in self._request_history) <TAB>  <TAB>  <TAB> return total_latency / len(self._request_history)",if not self . _request_history :,121
"def generate_guid(length=5): <TAB> while True: <TAB>  <TAB> guid_id = """".join(random.sample(ALPHABET, length)) <TAB>  <TAB> # is the guid in the blacklist <TAB>  <TAB> if _check_blacklist(guid_id): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # it's not, check and see if it's already in the database <MASK> return guid_id",if not Guid . objects . filter ( _id = guid_id ) . exists ( ) :,110
"def ps_for(self): <TAB> proc = self.pop(""proceduretype"") <TAB> limit = self.pop(""integertype"", ""realtype"").value <TAB> increment = self.pop(""integertype"", ""realtype"").value <TAB> i = self.pop(""integertype"", ""realtype"").value <TAB> while 1: <MASK> if i > limit: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if i < limit: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if type(i) == type(0.0): <TAB>  <TAB>  <TAB> self.push(ps_real(i)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.push(ps_integer(i)) <TAB>  <TAB> self.call_procedure(proc) <TAB>  <TAB> i = i + increment",if increment > 0 :,184
"def read(cls, fd): <TAB> rval = cls() <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> key = ScriptDataString.read(fd) <TAB>  <TAB>  <TAB> value = ScriptDataValue.read(fd) <TAB>  <TAB> except ScriptDataObjectEnd: <TAB>  <TAB>  <TAB> break <MASK> break <TAB>  <TAB> rval[key] = value <TAB> return rval",if len ( key ) == 0 :,95
"def check_monitoring(self) -> Tuple[bool, str]: <TAB> monitoring = self.get_monitoring() <TAB> valid_teams = list_teams() <TAB> if monitoring is not None: <TAB>  <TAB> team_name = monitoring.get(""team"", None) <TAB>  <TAB> if team_name is None: <TAB>  <TAB>  <TAB> return False, ""Team name is required for monitoring"" <MASK> suggest_teams = difflib.get_close_matches( <TAB>  <TAB>  <TAB>  <TAB> word=team_name, possibilities=valid_teams <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB>  <TAB> False, <TAB>  <TAB>  <TAB>  <TAB> f""Invalid team name: {team_name}. Do you mean one of these: {suggest_teams}"", <TAB>  <TAB>  <TAB> ) <TAB> return True, """"",elif team_name not in valid_teams :,191
"def _visit_argument_annotations(self, arguments): <TAB> for arg in arguments: <TAB>  <TAB> if isinstance(arg, ast.SimpleArg): <MASK> self.visit(arg.annotation) <TAB>  <TAB>  <TAB>  <TAB> yield arg.name <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for name in self._visit_argument_annotations(arg.args): <TAB>  <TAB>  <TAB>  <TAB> yield name",if arg . annotation :,95
"def _getval_except(self, arg, frame=None): <TAB> try: <MASK> return eval(arg, self.curframe.f_globals, self.curframe_locals) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return eval(arg, frame.f_globals, frame.f_locals) <TAB> except: <TAB>  <TAB> exc_info = sys.exc_info()[:2] <TAB>  <TAB> err = traceback.format_exception_only(*exc_info)[-1].strip() <TAB>  <TAB> return _rstr(""** raised %s **"" % err)",if frame is None :,135
"def get_tracker_sparkline(tracker_uuid, num_day=6): <TAB> date_range_sparkline = Date.get_date_range(num_day) <TAB> sparklines_value = [] <TAB> for date_day in date_range_sparkline: <TAB>  <TAB> nb_seen_this_day = r_serv_tracker.scard( <TAB>  <TAB>  <TAB> ""tracker:item:{}:{}"".format(tracker_uuid, date_day) <TAB>  <TAB> ) <MASK> nb_seen_this_day = 0 <TAB>  <TAB> sparklines_value.append(int(nb_seen_this_day)) <TAB> return sparklines_value",if nb_seen_this_day is None :,167
"def check_transposehw(origin_img, result_img): <TAB> """"""Check if the origin_imgs are transposed correctly"""""" <TAB> h, w, c = origin_img.shape <TAB> # yapf: disable <TAB> for i in range(c): <TAB>  <TAB> for j in range(h): <TAB>  <TAB>  <TAB> for k in range(w): <MASK> # noqa:E501 <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> # yapf: enable <TAB> return True","if result_img [ k , j , i ] != origin_img [ j , k , i ] :",129
"def save_osenv(self, filename, save=None): <TAB> """"""Save host info for is_same_host()"""""" <TAB> if save is None: <TAB>  <TAB> save = dict() <TAB> try: <TAB>  <TAB> save[""osversion""] = self.osversion() <TAB>  <TAB> save[""oskernel""] = self.oskernel() <TAB>  <TAB> save[""arch""] = self.arch() <TAB>  <TAB> save[""osdistribution""] = str(self.osdistribution()) <MASK> return True <TAB> except (AttributeError, ValueError, TypeError, IndexError, KeyError): <TAB>  <TAB> pass <TAB> return False",if FileUtil ( filename ) . putdata ( json . dumps ( save ) ) :,148
"def processSegment(self, segment): <TAB> for field in segment: <TAB>  <TAB> if field.name.startswith(""Info[""): <TAB>  <TAB>  <TAB> self.processInfo(field) <TAB>  <TAB> elif field.name.startswith(""Tags[""): <TAB>  <TAB>  <TAB> for tag in field.array(""Tag""): <TAB>  <TAB>  <TAB>  <TAB> self.processTag(tag) <TAB>  <TAB> elif field.name.startswith(""Tracks[""): <TAB>  <TAB>  <TAB> self.processTracks(field) <TAB>  <TAB> elif field.name.startswith(""Cluster[""): <MASK> return",if self . quality < QUALITY_GOOD :,136
"def _str_param_list(self, name): <TAB> out = [] <TAB> if self[name]: <TAB>  <TAB> out += self._str_field_list(name) <TAB>  <TAB> out += [""""] <TAB>  <TAB> for param, param_type, desc in self[name]: <MASK> out += self._str_indent([""**%s** : %s"" % (param.strip(), param_type)]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> out += self._str_indent([""**%s**"" % param.strip()]) <TAB>  <TAB>  <TAB> if desc: <TAB>  <TAB>  <TAB>  <TAB> out += [""""] <TAB>  <TAB>  <TAB>  <TAB> out += self._str_indent(desc, 8) <TAB>  <TAB>  <TAB> out += [""""] <TAB> return out",if param_type :,174
"def test_expanduser(self): <TAB> self.assertEqual(posixpath.expanduser(""foo""), ""foo"") <TAB> try: <TAB>  <TAB> import pwd <TAB> except ImportError: <TAB>  <TAB> pass <TAB> else: <TAB>  <TAB> self.assertIsInstance(posixpath.expanduser(""~/""), basestring) <TAB>  <TAB> # if home directory == root directory, this test makes no sense <MASK> self.assertEqual( <TAB>  <TAB>  <TAB>  <TAB> posixpath.expanduser(""~"") + ""/"", posixpath.expanduser(""~/"") <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self.assertIsInstance(posixpath.expanduser(""~root/""), basestring) <TAB>  <TAB> self.assertIsInstance(posixpath.expanduser(""~foo/""), basestring) <TAB>  <TAB> with test_support.EnvironmentVarGuard() as env: <TAB>  <TAB>  <TAB> env[""HOME""] = ""/"" <TAB>  <TAB>  <TAB> self.assertEqual(posixpath.expanduser(""~""), ""/"")","if posixpath . expanduser ( ""~"" ) != ""/"" :",180
"def test_expect_setecho_off_exact(self): <TAB> p = pexpect.spawn(""cat"", echo=True, timeout=5) <TAB> p.expect = p.expect_exact <TAB> try: <TAB>  <TAB> self._expect_echo_toggle(p) <TAB> except IOError: <TAB>  <TAB> if sys.platform.lower().startswith(""sunos""): <MASK> raise unittest.SkipTest(""Not supported on this platform."") <TAB>  <TAB>  <TAB> return ""skip"" <TAB>  <TAB> raise","if hasattr ( unittest , ""SkipTest"" ) :",122
"def run(self): <TAB> """"""Run the example code by connecting and then starting the IOLoop."""""" <TAB> while not self._stopping: <TAB>  <TAB> self._connection = None <TAB>  <TAB> self._deliveries = [] <TAB>  <TAB> self._acked = 0 <TAB>  <TAB> self._nacked = 0 <TAB>  <TAB> self._message_number = 0 <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self._connection = self.connect() <TAB>  <TAB>  <TAB> self._connection.ioloop.start() <TAB>  <TAB> except KeyboardInterrupt: <TAB>  <TAB>  <TAB> self.stop() <MASK> # Finish closing <TAB>  <TAB>  <TAB>  <TAB> self._connection.ioloop.start() <TAB> LOGGER.info(""Stopped"")",if self . _connection is not None and not self . _connection . is_closed :,173
"def setup_datadir( <TAB> node_id: NodeId, node_configs: ""typing.Union[NodeConfig, typing.List[NodeConfig]]"") -> None: <TAB> if isinstance(node_configs, list): <TAB>  <TAB> datadir: typing.Optional[str] = None <TAB>  <TAB> for node_config in node_configs: <MASK> if datadir is None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> datadir = helpers.mkdatadir(node_id.value) <TAB>  <TAB>  <TAB>  <TAB> node_config.datadir = datadir <TAB> else: <TAB>  <TAB> if node_configs.datadir is None: <TAB>  <TAB>  <TAB> node_configs.datadir = helpers.mkdatadir(node_id.value)",if node_config . datadir is None :,165
"def send(self, data): <TAB> try: <TAB>  <TAB> result = self.socket.send(data) <TAB>  <TAB> return result <TAB> except socket.error as why: <MASK> return 0 <TAB>  <TAB> elif why.args[0] in _DISCONNECTED: <TAB>  <TAB>  <TAB> self.handle_close() <TAB>  <TAB>  <TAB> return 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise",if why . args [ 0 ] == EWOULDBLOCK :,103
"def write_enums(self, features): <TAB> e = self._f_enums <TAB> self.write_module(e, self.ENUMS) <TAB> self.write_imports(e, [self.TYPES]) <TAB> for v in self.TYPE_DICT[""SpecialNumbers""][self.spec.NAME]: <TAB>  <TAB> self.write_enum(e, *v) <TAB> written = set() <TAB> for feature in features: <TAB>  <TAB> for enum in feature.enums: <TAB>  <TAB>  <TAB> if enum.group == ""SpecialNumbers"": <TAB>  <TAB>  <TAB>  <TAB> written.add(enum) <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> self.write_enum(e, enum.name, enum.value) <TAB>  <TAB>  <TAB> written.add(enum)",if not enum in written :,178
"def suite(): <TAB> import os <TAB> import json <TAB> suite = unittest.TestSuite() <TAB> # Look for test cases in samples dir <TAB> samples_dir = os.path.join(os.path.dirname(os.path.realpath(__file__)), ""samples"") <TAB> for item in os.listdir(samples_dir): <MASK> continue <TAB>  <TAB> file = open(os.path.join(samples_dir, item), ""r"") <TAB>  <TAB> test_case = json.loads(file.read()) <TAB>  <TAB> t = WebhookTestCase() <TAB>  <TAB> t.set_test_case(test_case, item) <TAB>  <TAB> suite.addTest(t) <TAB> return suite","if not item [ - 15 : ] == "".test-case.json"" :",170
"def assertS_IS(self, name, mode): <TAB> # test format, lstrip is for S_IFIFO <TAB> fmt = getattr(self.statmod, ""S_IF"" + name.lstrip(""F"")) <TAB> self.assertEqual(self.statmod.S_IFMT(mode), fmt) <TAB> # test that just one function returns true <TAB> testname = ""S_IS"" + name <TAB> for funcname in self.format_funcs: <TAB>  <TAB> func = getattr(self.statmod, funcname, None) <TAB>  <TAB> if func is None: <MASK> raise ValueError(funcname) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if funcname == testname: <TAB>  <TAB>  <TAB> self.assertTrue(func(mode)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertFalse(func(mode))",if funcname == testname :,189
"def test_few_values(): <TAB> digest = TDigest() <TAB> length = random.randint(1, 10) <TAB> values = [] <TAB> for i in range(length): <MASK> value = random.random() * 100 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = values[-1] <TAB>  <TAB> digest.add(value) <TAB>  <TAB> values.append(value) <TAB> values = sorted(values) <TAB> assert len(digest.centroids) == len(values) <TAB> for q in [0, 1e-10, random.random(), 0.5, 1 - 1e-10, 1]: <TAB>  <TAB> q1 = quantile(values, q) <TAB>  <TAB> q2 = digest.quantile(q) <TAB>  <TAB> assert abs(q1 - q2) < 0.03",if i == 0 or random . random ( ) < 0.5 :,195
"def resolve(self, dispatcher, event_handler, full_config): <TAB> if not self._check_event_handler(event_handler): <TAB>  <TAB> return <TAB> config = self.resolver(full_config) <TAB> if config: <TAB>  <TAB> if ""dispatcher"" not in config: <TAB>  <TAB>  <TAB> spec = inspect.getfullargspec(self.callback) <MASK> config[""dispatcher""] = dispatcher <TAB>  <TAB> for key in config: <TAB>  <TAB>  <TAB> if key in full_config: <TAB>  <TAB>  <TAB>  <TAB> full_config.pop(key) <TAB>  <TAB> return self.callback(**config)","if ""dispatcher"" in spec . args :",144
"def init_project(self): <TAB> self.validate_filename(self.name) <TAB> for filename, templatename in iteritems(self.default_files): <MASK> template = templates.get(templatename, """") % { <TAB>  <TAB>  <TAB>  <TAB> ""name"": self.name, <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB> self.save(filename, ContentFile(template, filename))",if not self . exists ( filename ) :,98
"def clear_path_node(graph, reg, loc1, loc2): <TAB> for loc in range(loc1, loc2): <TAB>  <TAB> ins = graph.get_ins_from_loc(loc) <TAB>  <TAB> logger.debug(""  treat loc: %d, ins: %s"", loc, ins) <MASK> continue <TAB>  <TAB> logger.debug(""  LHS: %s, side_effect: %s"", ins.get_lhs(), ins.has_side_effect()) <TAB>  <TAB> if ins.get_lhs() == reg or ins.has_side_effect(): <TAB>  <TAB>  <TAB> return False <TAB> return True",if ins is None :,149
"def __init__(self, tag, tag_node): <TAB> super().__init__() <TAB> self.tag = tag <TAB> if tag_node is not None: <MASK> self.romaji = tag_node[""romaji""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.romaji = tag.lower() <TAB>  <TAB> if ""translation"" in tag_node: <TAB>  <TAB>  <TAB> self.translation_data = tag_node[""translation""] <TAB> else: <TAB>  <TAB> self.romaji = tag.lower()","if ""romaji"" in tag_node :",127
"def get_service_targets(self, service): <TAB> try: <TAB>  <TAB> targets = self.config.getdict(""config:"" + service, ""targets"") <MASK> logger.error(""No targets for service `%s'"" % service) <TAB> except: <TAB>  <TAB> logger.error(""No targets for service `%s'"" % service) <TAB> if targets is None: <TAB>  <TAB> return {} <TAB> return dict(targets)",if type ( targets ) != dict :,105
"def transform_mapping(self): <TAB> for k, v in self._template.get(""Mappings"", {}).items(): <MASK> name = v[""Fn::Transform""][""Name""] <TAB>  <TAB>  <TAB> params = v[""Fn::Transform""][""Parameters""] <TAB>  <TAB>  <TAB> if name == ""AWS::Include"": <TAB>  <TAB>  <TAB>  <TAB> location = params[""Location""] <TAB>  <TAB>  <TAB>  <TAB> bucket_name, name = bucket_and_name_from_url(location) <TAB>  <TAB>  <TAB>  <TAB> key = s3_backend.get_object(bucket_name, name) <TAB>  <TAB>  <TAB>  <TAB> self._parsed_resources.update(json.loads(key.value))","if ""Fn::Transform"" in v :",156
"def write_modules_api(self, modules, outdir): <TAB> # write the list <TAB> written_modules = [] <TAB> for m in modules: <TAB>  <TAB> api_str = self.generate_api_doc(m) <MASK> continue <TAB>  <TAB> # write out to file <TAB>  <TAB> outfile = os.path.join(outdir, m + self.rst_extension) <TAB>  <TAB> fileobj = open(outfile, ""wt"") <TAB>  <TAB> fileobj.write(api_str) <TAB>  <TAB> fileobj.close() <TAB>  <TAB> written_modules.append(m) <TAB> self.written_modules = written_modules",if not api_str :,146
"def generate(self, corpus_length=0): <TAB> corpus = """" <TAB> if corpus_length == 0: <TAB>  <TAB> corpus_length = random.randint(5, 15) <TAB> for i in range(corpus_length): <MASK> corpus += ""{}"".format(random.choice(self.en_char_list)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> corpus += ""{}"".format(random.choice(self.num_list)) <TAB> return ""en"", corpus",if random . random ( ) < 0.2 :,117
"def _query_conjunction(self, queries): <TAB> """"""Merges query dicts - effectively &ing them together."""""" <TAB> query_ops = set() <TAB> combined_query = {} <TAB> for query in queries: <TAB>  <TAB> ops = set(query.keys()) <TAB>  <TAB> # Make sure that the same operation isn't applied more than once <TAB>  <TAB> # to a single field <TAB>  <TAB> intersection = ops.intersection(query_ops) <MASK> raise DuplicateQueryConditionsError() <TAB>  <TAB> query_ops.update(ops) <TAB>  <TAB> combined_query.update(copy.deepcopy(query)) <TAB> return combined_query",if intersection :,145
"def clear_ud(self, user): <TAB> up = {""u"": 0, ""d"": 0} <TAB> self.data.load(self.config_path) <TAB> for row in self.data.json: <TAB>  <TAB> match = True <MASK> match = False <TAB>  <TAB> if ""port"" in user and row[""port""] != user[""port""]: <TAB>  <TAB>  <TAB> match = False <TAB>  <TAB> if match: <TAB>  <TAB>  <TAB> row.update(up) <TAB>  <TAB>  <TAB> print(""clear user [%s]"" % row[""user""]) <TAB> self.data.save(self.config_path)","if ""user"" in user and row [ ""user"" ] != user [ ""user"" ] :",153
"def stop_loggers(self): <TAB> super(SerialHost, self).stop_loggers() <TAB> if self.__logger: <TAB>  <TAB> utils.nuke_subprocess(self.__logger) <TAB>  <TAB> self.__logger = None <MASK> self.job.warning_loggers.discard(self.__warning_stream) <TAB>  <TAB> self.__warning_stream.close()",if self . job :,92
"def _try_prompt_if_dest_exists(self, target): <TAB> if self.settings.get(WARN_OVERWRITE_ON_MOVE_SETTING, False): <MASK> return sublime.ok_cancel_dialog( <TAB>  <TAB>  <TAB>  <TAB> target <TAB>  <TAB>  <TAB>  <TAB> + ""already exists. "" <TAB>  <TAB>  <TAB>  <TAB> + ""move will overwrite "" <TAB>  <TAB>  <TAB>  <TAB> + ""existing file. Continue?"" <TAB>  <TAB>  <TAB> ) <TAB> return True",if os . path . exists ( target ) :,115
"def serialize(self, payload, prev): <TAB> hdr = bytearray(struct.pack(icmpv6._PACK_STR, self.type_, self.code, self.csum)) <TAB> if self.data: <MASK> assert isinstance(self.data, _ICMPv6Payload) <TAB>  <TAB>  <TAB> hdr += self.data.serialize() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> hdr += self.data <TAB> if self.csum == 0: <TAB>  <TAB> self.csum = packet_utils.checksum_ip(prev, len(hdr), hdr + payload) <TAB>  <TAB> struct.pack_into(""!H"", hdr, 2, self.csum) <TAB> return hdr",if self . type_ in icmpv6 . _ICMPV6_TYPES :,173
"def get_actors(self): <TAB> if not self._actors: <TAB>  <TAB> log.debug(""Looking up actors for series %s"", self.name) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> actors_query = TVDBRequest().get(""series/%s/actors"" % self.id) <TAB>  <TAB>  <TAB> self.actors_list = [a[""name""] for a in actors_query] if actors_query else [] <TAB>  <TAB> except requests.RequestException as e: <MASK> self.actors_list = [] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise LookupError(""Error updating actors from tvdb: %s"" % e) <TAB> return self.actors_list",if None is not e . response and e . response . status_code == 404 :,173
"def __call__(self, *args, **kwargs): <TAB> try: <TAB>  <TAB> return RunningCoroutine(self._func(*args, **kwargs), self) <TAB> except Exception as e: <TAB>  <TAB> traceback.print_exc() <TAB>  <TAB> result = TestError(str(e)) <MASK> buff = StringIO() <TAB>  <TAB>  <TAB> traceback.print_exc(file=buff) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> buff_bytes = BytesIO() <TAB>  <TAB>  <TAB> traceback.print_exc(file=buff_bytes) <TAB>  <TAB>  <TAB> buff = StringIO(buff_bytes.getvalue().decode(""UTF-8"")) <TAB>  <TAB> result.stderr.write(buff.getvalue()) <TAB>  <TAB> raise result",if sys . version_info . major >= 3 :,168
"def _getInputConnectionsOfLayer(self, layer): <TAB> """"""Return a list of all input connections for the layer."""""" <TAB> connections = [] <TAB> all_cons = list(self._network.recurrentConns) <TAB> all_cons += sum(list(self._network.connections.values()), []) <TAB> for c in all_cons: <MASK> if not isinstance(c, FullConnection): <TAB>  <TAB>  <TAB>  <TAB> raise NotImplementedError(""Only FullConnections are supported"") <TAB>  <TAB>  <TAB> connections.append(c) <TAB> return connections",if c . outmod is layer :,130
"def on_settings_migrate(self, target, current): <TAB> if current is None: <TAB>  <TAB> config = self._settings.global_get([""gcodeViewer""]) <TAB>  <TAB> if config: <TAB>  <TAB>  <TAB> self._logger.info( <TAB>  <TAB>  <TAB>  <TAB> ""Migrating settings from gcodeViewer to plugins.gcodeviewer..."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> if ""mobileSizeThreshold"" in config: <TAB>  <TAB>  <TAB>  <TAB> self._settings.set_int( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> [""mobileSizeThreshold""], config[""mobileSizeThreshold""] <TAB>  <TAB>  <TAB>  <TAB> ) <MASK> self._settings.set_int([""sizeThreshold""], config[""sizeThreshold""]) <TAB>  <TAB>  <TAB> self._settings.global_remove([""gcodeViewer""])","if ""sizeThreshold"" in config :",181
"def cause_wtimeout(self, batch): <TAB> if self.need_replication_stopped: <MASK> raise SkipTest(""Test commands must be enabled."") <TAB>  <TAB> self.secondary.admin.command( <TAB>  <TAB>  <TAB> ""configureFailPoint"", ""rsSyncApplyStop"", mode=""alwaysOn"" <TAB>  <TAB> ) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return batch.execute({""w"": self.w, ""wtimeout"": 1}) <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self.secondary.admin.command( <TAB>  <TAB>  <TAB>  <TAB> ""configureFailPoint"", ""rsSyncApplyStop"", mode=""off"" <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> return batch.execute({""w"": self.w + 1, ""wtimeout"": 1})",if not client_context . test_commands_enabled :,180
"def goo(a, b): <TAB> c = output_tensor(a.shape, a.dtype) <TAB> len_b = len(b) <TAB> for i in const_range(len_b * 2): <MASK> c[i] = a[i] + b[i] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> c[i - len_b] = a[i - len_b] + b[i - len_b] <TAB> return c",if i < len_b :,117
"def remove_dimensions(outs, steps_return, offsets=None): <TAB> out_ls = [] <TAB> for idx, out in enumerate(outs): <TAB>  <TAB> if idx in steps_return: <TAB>  <TAB>  <TAB> if steps_return[idx] > 1: <TAB>  <TAB>  <TAB>  <TAB> out_ls.append(out[-steps_return[idx] :]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> out_ls.append(out[-1]) <TAB>  <TAB> else: <MASK> out_ls.append(out) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> out_ls.append(out[offsets[idx] :]) <TAB> return out_ls",if offsets is None :,156
"def rreload(module, mdict=None): <TAB> """"""Recursively reload modules."""""" <TAB> name = module.__name__ <TAB> if mdict is None: <TAB>  <TAB> mdict = [] <TAB> for attribute_name in getattr(module, ""__all__"", []) or []: <TAB>  <TAB> attribute = getattr(module, attribute_name, None) <MASK> mdict.append(attribute) <TAB>  <TAB>  <TAB> rreload(attribute, mdict) <TAB> try: <TAB>  <TAB> _reload(module) <TAB> except Exception as e: <TAB>  <TAB> pass","if isinstance ( attribute , types . ModuleType ) and attribute not in mdict :",135
"def _repr_iterable(self, x, level, left, right, maxiter, trail=""""): <TAB> n = len(x) <TAB> if level <= 0 and n: <TAB>  <TAB> s = ""..."" <TAB> else: <TAB>  <TAB> newlevel = level - 1 <TAB>  <TAB> repr1 = self.repr1 <TAB>  <TAB> pieces = [repr1(elem, newlevel) for elem in islice(x, maxiter)] <MASK> pieces.append(""..."") <TAB>  <TAB> s = "", "".join(pieces) <TAB>  <TAB> if n == 1 and trail: <TAB>  <TAB>  <TAB> right = trail + right <TAB> return ""%s%s%s"" % (left, s, right)",if n > maxiter :,154
"def _deserialize(self, value, attr, data): <TAB> if not self.truthy: <TAB>  <TAB> return bool(value) <TAB> else: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if value in self.truthy: <TAB>  <TAB>  <TAB>  <TAB> return True <MASK> return False <TAB>  <TAB> except TypeError: <TAB>  <TAB>  <TAB> pass <TAB> self.fail(""invalid"")",elif value in self . falsy :,94
"def __doWork(self): <TAB> """"""Pops work from the queue and returns the proxy and last log line"""""" <TAB> # pylint: disable=broad-except <TAB> try: <MASK> (proxy, path) = self.__queue.popitem() <TAB>  <TAB>  <TAB> if os.path.exists(path): <TAB>  <TAB>  <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> proxy, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> cuegui.Utils.getLastLine(path), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> cuegui.Utils.secondsToHHMMSS(time.time() - os.stat(path).st_mtime), <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return None <TAB> except Exception as e: <TAB>  <TAB> list(map(logger.warning, cuegui.Utils.exceptionOutput(e)))",if self . __queue :,182
"def is_botocore(): <TAB> try: <TAB>  <TAB> import botocore <TAB>  <TAB> return True <TAB> except ImportError: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> import boto <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> except ImportError: <TAB>  <TAB>  <TAB>  <TAB> raise NotConfigured(""missing botocore or boto library"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise NotConfigured(""missing botocore library"")",if six . PY2 :,93
"def apply(self, rule, data, sources): <TAB> rule_value = rule[""value""] <TAB> tag_prefix = ""group:%s:"" % rule_value <TAB> new_rows = [] <TAB> for index, row in enumerate(data): <TAB>  <TAB> group_tag_value = None <TAB>  <TAB> source = sources[index] <TAB>  <TAB> tags = source[""tags""] <TAB>  <TAB> for tag in sorted(tags): <TAB>  <TAB>  <TAB> if tag.startswith(tag_prefix): <TAB>  <TAB>  <TAB>  <TAB> group_tag_value = tag[len(tag_prefix) :] <TAB>  <TAB>  <TAB>  <TAB> break <MASK> group_tag_value = rule.get(""default_value"", """") <TAB>  <TAB> new_rows.append(row + [group_tag_value]) <TAB> return new_rows, sources",if group_tag_value is None :,189
"def test_buffer(): <TAB> for s in ["""", "" "", ""abc "", ""abcdef""]: <TAB>  <TAB> x = marshal.dumps(buffer(s)) <TAB>  <TAB> AreEqual(marshal.loads(x), s) <TAB> for s in ["""", "" "", ""abc "", ""abcdef""]: <MASK> break <TAB>  <TAB> f = file(tfn, ""wb"") <TAB>  <TAB> marshal.dump(buffer(s), f) <TAB>  <TAB> f.close() <TAB>  <TAB> f = file(tfn, ""rb"") <TAB>  <TAB> x2 = marshal.load(f) <TAB>  <TAB> f.close() <TAB>  <TAB> AreEqual(s, x2)",if is_silverlight :,160
"def citation_src_private(self, data): <TAB> source_handle = data[COLUMN_SOURCE] <TAB> cached, value = self.get_cached_value(source_handle, ""SRC_PRIVATE"") <TAB> if not cached: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> source = self.db.get_source_from_handle(source_handle) <MASK> value = ""gramps-lock"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> # There is a problem returning None here. <TAB>  <TAB>  <TAB>  <TAB> value = """" <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> value = """" <TAB>  <TAB> self.set_cached_value(source_handle, ""SRC_PRIVATE"", value) <TAB> return value",if source . get_privacy ( ) :,173
"def __get_name(place, date, lang): <TAB> endonym = None <TAB> for place_name in place.get_all_names(): <TAB>  <TAB> name_date = place_name.get_date_object() <TAB>  <TAB> if name_date.is_empty() or date.match_exact(name_date): <MASK> return place_name.get_value() <TAB>  <TAB>  <TAB> if endonym is None: <TAB>  <TAB>  <TAB>  <TAB> endonym = place_name.get_value() <TAB> return endonym if endonym is not None else ""?""",if place_name . get_language ( ) == lang :,143
"def __cbStore(self, result, tag, mbox, uid, silent): <TAB> if result and not silent: <TAB>  <TAB> for (k, v) in result.items(): <MASK> uidstr = b"" UID %d"" % (mbox.getUID(k),) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> uidstr = b"""" <TAB>  <TAB>  <TAB> flags = [networkString(flag) for flag in v] <TAB>  <TAB>  <TAB> self.sendUntaggedResponse( <TAB>  <TAB>  <TAB>  <TAB> b""%d FETCH (FLAGS (%b)%b)"" % (k, b"" "".join(flags), uidstr) <TAB>  <TAB>  <TAB> ) <TAB> self.sendPositiveResponse(tag, b""STORE completed"")",if uid :,167
"def _buildVsType(self, tname, tsize, tflags): <TAB> if tflags & VSFF_POINTER: <TAB>  <TAB> if tsize == 4: <TAB>  <TAB>  <TAB> return vs_prim.v_ptr32() <MASK> return vs_prim.v_ptr64() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception(""Invalid Pointer Width: %d"" % tsize) <TAB> if tname is not None: <TAB>  <TAB> return self.buildVStruct(tname) <TAB> if tsize not in TSIZES: <TAB>  <TAB> return v_bytes(size=tsize) <TAB> return prim_types[tsize]()",elif tsize == 8 :,160
"def __pre_selection_changed(self, view, event, fs, nb): <TAB> if self.__save: <TAB>  <TAB> resp = CancelRevertSave(self).run() <TAB>  <TAB> if resp == Gtk.ResponseType.YES: <TAB>  <TAB>  <TAB> self.__save.clicked() <MASK> fs.rescan() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> nb.grab_focus() <TAB>  <TAB>  <TAB> return True  # cancel or closed",elif resp == Gtk . ResponseType . NO :,109
"def create(self, filename): <TAB> """"""Backup functions."""""" <TAB> from HardcodeTray.app import App <TAB> if not App.get(""backup_ignore""): <MASK> self.create_backup_dir() <TAB>  <TAB> backup_file = path.join(self.backup_dir, path.basename(filename)) <TAB>  <TAB> if path.exists(filename): <TAB>  <TAB>  <TAB> Logger.debug(""Backup file: {0} to: {1}"".format(filename, backup_file)) <TAB>  <TAB>  <TAB> copy_file(filename, backup_file, True)",if not self . backup_dir :,137
"def _shard_generator( <TAB> self, shards: List[Union[str, Path]], shuffle: bool = False) -> List[str]: <TAB> shards_to_choose = list(shards) <MASK> self.np_random.shuffle(shards_to_choose) <TAB> for shard in shards_to_choose: <TAB>  <TAB> log.info(f""Loaded shard from {shard}"") <TAB>  <TAB> with open(shard, encoding=""utf-8"") as f: <TAB>  <TAB>  <TAB> lines = f.readlines() <TAB>  <TAB> if shuffle: <TAB>  <TAB>  <TAB> self.np_random.shuffle(lines) <TAB>  <TAB> yield lines",if shuffle :,146
"def get_since_text(cls, versions: List[Optional[str]]) -> Optional[str]: <TAB> tv = [] <TAB> if len(versions) == 0 or versions[0] is None: <TAB>  <TAB> return None <TAB> for v in versions[0].split("",""): <TAB>  <TAB> ssh_prod, ssh_ver, is_cli = cls.get_ssh_version(v) <TAB>  <TAB> if not ssh_ver: <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> if is_cli: <TAB>  <TAB>  <TAB> ssh_ver = ""{} (client only)"".format(ssh_ver) <TAB>  <TAB> tv.append(""{} {}"".format(ssh_prod, ssh_ver)) <TAB> if len(tv) == 0: <TAB>  <TAB> return None <TAB> return ""available since "" + "", "".join(tv).rstrip("", "")",if ssh_prod in [ Product . LibSSH ] :,196
"def check_if_installed(self): <TAB> candidates = [""npm""] <TAB> if is_windows(): <TAB>  <TAB> candidates.append(""npm.cmd"") <TAB> for candidate in candidates: <TAB>  <TAB> self.log.debug(""Trying '%r' as NPM Tool..."", candidate) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> out, err = self.call([candidate, ""--version""]) <TAB>  <TAB> except CALL_PROBLEMS as exc: <TAB>  <TAB>  <TAB> self.log.debug(""%r is not installed: %s"", candidate, exc) <TAB>  <TAB>  <TAB> continue <MASK> out += err <TAB>  <TAB> self.log.debug(""%s output: %s"", candidate, out) <TAB>  <TAB> self.tool_path = candidate <TAB>  <TAB> return True <TAB> return False",if err :,176
"def split_docstring(self, block): <TAB> """"""Split a code block into a docstring and a body."""""" <TAB> try: <TAB>  <TAB> first_line, rest_of_lines = block.split(""\n"", 1) <TAB> except ValueError: <TAB>  <TAB> pass <TAB> else: <TAB>  <TAB> raw_first_line = split_leading_trailing_indent(rem_comment(first_line))[1] <MASK> return first_line, rest_of_lines <TAB> return None, block","if match_in ( self . just_a_string , raw_first_line ) :",131
"def get_learning_rate_decay_list( <TAB> base_learning_rate, decay, max_iter, decay_examples, total_batch_size): <TAB> decay_step = decay_examples // total_batch_size <TAB> lr_bounds = [] <TAB> lr_values = [base_learning_rate] <TAB> i = 1 <TAB> while True: <MASK> break <TAB>  <TAB> lr_bounds.append(i * decay_step) <TAB>  <TAB> lr_values.append(base_learning_rate * (decay ** i)) <TAB>  <TAB> i += 1 <TAB> return lr_bounds, lr_values",if i * decay_step >= max_iter :,151
"def _get_service_list(include_enabled=True, include_disabled=False): <TAB> enabled_services = dict() <TAB> disabled_services = set() <TAB> lines = _list_services() <TAB> for line in lines: <TAB>  <TAB> if ""|"" not in line: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> service = [l.strip() for l in line.split(""|"")] <TAB>  <TAB> # enabled service should have runlevels <MASK> if include_enabled: <TAB>  <TAB>  <TAB>  <TAB> enabled_services.update({service[0]: sorted(service[1].split())}) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # in any other case service is disabled <TAB>  <TAB> if include_disabled: <TAB>  <TAB>  <TAB> disabled_services.update({service[0]: []}) <TAB> return enabled_services, disabled_services",if service [ 1 ] :,185
"def preset_modules(self, *modules): <TAB> """"""[UNIT]... -- set 'enabled' when in *.preset"""""" <TAB> found_all = True <TAB> units = [] <TAB> for module in modules: <TAB>  <TAB> matched = self.match_units([module]) <TAB>  <TAB> if not matched: <TAB>  <TAB>  <TAB> logg.error(""no such service '%s'"", module) <TAB>  <TAB>  <TAB> found_all = False <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for unit in matched: <MASK> units += [unit] <TAB> return self.preset_units(units) and found_all",if unit not in units :,144
"def _convert_to_tensor(self, current: Any, use_tpu: bool, device: torch.device): <TAB> if current is not None: <TAB>  <TAB> if isinstance(current, Metric): <TAB>  <TAB>  <TAB> current = current.compute().detach() <TAB>  <TAB> elif isinstance(current, numbers.Number): <MASK> current = torch.tensor(current, dtype=torch.float) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> current = torch.tensor(current, device=device, dtype=torch.float) <TAB> if isinstance(current, torch.Tensor) and current.device.type == ""xla"": <TAB>  <TAB> current = current.cpu() <TAB> return current",if device is None :,162
"def Visit_subscript(self, node):  # pylint: disable=invalid-name <TAB> # subscript ::= test | [test] ':' [test] [sliceop] <TAB> for child in node.children: <TAB>  <TAB> self.Visit(child) <MASK> _AppendTokenSubtype(child, format_token.Subtype.SUBSCRIPT_COLON)","if isinstance ( child , pytree . Leaf ) and child . value == "":"" :",97
"def extract_version(): <TAB> """"""extract pyzmq version from sugar/version.py, so it's not multiply defined"""""" <TAB> with open(pjoin(""zmq"", ""sugar"", ""version.py"")) as f: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> line = f.readline() <MASK> lines = [""from typing import *\n""] <TAB>  <TAB>  <TAB>  <TAB> while line and not line.startswith(""def""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> lines.append(line) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> line = f.readline() <TAB>  <TAB>  <TAB>  <TAB> break <TAB> ns = {} <TAB> exec("""".join(lines), ns) <TAB> return ns[""__version__""]","if line . startswith ( ""VERSION"" ) :",163
"def init_weights(modules): <TAB> for m in modules: <TAB>  <TAB> if isinstance(m, nn.Conv2d): <TAB>  <TAB>  <TAB> init.xavier_uniform_(m.weight.data) <MASK> m.bias.data.zero_() <TAB>  <TAB> elif isinstance(m, nn.BatchNorm2d): <TAB>  <TAB>  <TAB> m.weight.data.fill_(1) <TAB>  <TAB>  <TAB> m.bias.data.zero_() <TAB>  <TAB> elif isinstance(m, nn.Linear): <TAB>  <TAB>  <TAB> m.weight.data.normal_(0, 0.01) <TAB>  <TAB>  <TAB> m.bias.data.zero_()",if m . bias is not None :,152
"def use_bcbio_variation_recall(algs): <TAB> """"""Processing uses bcbio-variation-recall. Avoids core requirement if not used."""""" <TAB> for alg in algs: <TAB>  <TAB> jointcaller = alg.get(""jointcaller"", []) <MASK> jointcaller = [jointcaller] <TAB>  <TAB> for caller in jointcaller: <TAB>  <TAB>  <TAB> if caller not in set([""gatk-haplotype-joint"", None, False]): <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False","if not isinstance ( jointcaller , ( tuple , list ) ) :",130
"def _get_row(self, indices): <TAB> if self.source is None: <TAB>  <TAB> return None <TAB> s = self.source <TAB> if self.is_tree: <TAB>  <TAB> for i in indices: <MASK> if i < len(s): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> s = s[i] <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> return s <TAB> else: <TAB>  <TAB> if len(indices) == 1: <TAB>  <TAB>  <TAB> i = indices[0] <TAB>  <TAB>  <TAB> if i < len(s): <TAB>  <TAB>  <TAB>  <TAB> return s[i] <TAB>  <TAB> return None",if s . can_have_children ( ) :,170
"def iter_inis(path): <TAB> try: <TAB>  <TAB> for filename in os.listdir(path): <MASK> continue <TAB>  <TAB>  <TAB> fn = os.path.join(path, filename) <TAB>  <TAB>  <TAB> if os.path.isfile(fn): <TAB>  <TAB>  <TAB>  <TAB> base = filename[:-4] <TAB>  <TAB>  <TAB>  <TAB> base = base.encode(""utf-8"").decode(""ascii"", ""replace"") <TAB>  <TAB>  <TAB>  <TAB> inifile = IniFile(fn) <TAB>  <TAB>  <TAB>  <TAB> yield base, inifile <TAB> except OSError as e: <TAB>  <TAB> if e.errno != errno.ENOENT: <TAB>  <TAB>  <TAB> raise","if not filename . endswith ( "".ini"" ) or filename [ : 1 ] in ""_."" :",161
"def remove_resource(self, name, **kwargs): <TAB> if self.is_live and self._need_creation: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if ""wait_timeout"" in kwargs: <TAB>  <TAB>  <TAB>  <TAB> azure_poller = self.client.resource_groups.delete(name) <TAB>  <TAB>  <TAB>  <TAB> azure_poller.wait(kwargs.get(""wait_timeout"")) <MASK> return <TAB>  <TAB>  <TAB>  <TAB> raise AzureTestError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Timed out waiting for resource group to be deleted."" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.client.resource_groups.delete(name, polling=False) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> pass",if azure_poller . done ( ) :,184
"def option_value(name): <TAB> for index, option in enumerate(sys.argv): <TAB>  <TAB> if option == ""--"" + name: <MASK> raise DistutilsOptionError(""The option %s requires a value"" % option) <TAB>  <TAB>  <TAB> value = sys.argv[index + 1] <TAB>  <TAB>  <TAB> sys.argv[index : index + 2] = [] <TAB>  <TAB>  <TAB> return value <TAB>  <TAB> if option.startswith(""--"" + name + ""=""): <TAB>  <TAB>  <TAB> value = option[len(name) + 3 :] <TAB>  <TAB>  <TAB> sys.argv[index : index + 1] = [] <TAB>  <TAB>  <TAB> return value <TAB> env_val = os.getenv(name.upper().replace(""-"", ""_"")) <TAB> return env_val",if index + 1 >= len ( sys . argv ) :,178
"def response_to_file(self, target, raw=False, indent=4, sort=True): <TAB> with self.connection_lock: <MASK> if isinstance(target, STRING_TYPES): <TAB>  <TAB>  <TAB>  <TAB> target = open(target, ""w+"") <TAB>  <TAB>  <TAB> if log_enabled(BASIC): <TAB>  <TAB>  <TAB>  <TAB> log(BASIC, ""writing response to file for <%s>"", self) <TAB>  <TAB>  <TAB> target.writelines(self.response_to_json(raw=raw, indent=indent, sort=sort)) <TAB>  <TAB>  <TAB> target.close()",if self . response :,135
"def get_last_events(self, instance): <TAB> logging.debug(""Getting last events for {}"".format(instance)) <TAB> last_run = self.last_run_for(instance) <TAB> seen_last_run = False <TAB> for date_from, date_to, imported in self.week_events(instance): <TAB>  <TAB> logging.debug( <TAB>  <TAB>  <TAB> ""Imported {} attributes from {} to {}"".format(imported, date_from, date_to) <TAB>  <TAB> ) <TAB>  <TAB> if seen_last_run: <TAB>  <TAB>  <TAB> break <MASK> seen_last_run = True",if date_from <= last_run <= date_to :,150
"def appendNames(uc2names, extraUc2names, uc, name, isDestination): <TAB> if uc in uc2names: <TAB>  <TAB> names = uc2names[uc] <MASK> names.append(name) <TAB> elif isDestination: <TAB>  <TAB> uc2names[uc] = [name] <TAB> else: <TAB>  <TAB> if uc in extraUc2names: <TAB>  <TAB>  <TAB> names = extraUc2names[uc] <TAB>  <TAB>  <TAB> if name not in names: <TAB>  <TAB>  <TAB>  <TAB> names.append(name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> extraUc2names[uc] = [name]",if name not in names :,157
"def findFileByURI(self, uri): <TAB> uri = self._uriParser.URI = uri <TAB> file_weakref = self._files.get(uri) <TAB> if file_weakref: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> kofile = file_weakref() <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> kofile = None  # The object is dead. <MASK> self._statuscheck_files[uri] = file_weakref  # opt for status check <TAB>  <TAB>  <TAB> return kofile <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._files.pop(uri, None) <TAB> return None",if kofile :,142
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_server(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 18: <TAB>  <TAB>  <TAB> self.set_version(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 26: <TAB>  <TAB>  <TAB> self.set_instance(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,150
"def get_string(token): <TAB> """"""Parse a <string> token."""""" <TAB> if token.type == ""string"": <TAB>  <TAB> return (""string"", token.value) <TAB> if token.type == ""function"": <TAB>  <TAB> if token.name == ""attr"": <TAB>  <TAB>  <TAB> return check_attr_function(token, ""string"") <TAB>  <TAB> elif token.name in (""counter"", ""counters""): <TAB>  <TAB>  <TAB> return check_counter_function(token) <MASK> return check_content_function(token) <TAB>  <TAB> elif token.name == ""string"": <TAB>  <TAB>  <TAB> return check_string_or_element_function(""string"", token)","elif token . name == ""content"" :",157
"def update_common_parameters(self, common_parameters: RunParameters): <TAB> if int(self.job_runtime_conf.get(""dsl_version"", 1)) == 2: <MASK> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB> ""the configuration format for v2 version must be job_parameters:common"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self.job_runtime_conf[""job_parameters""][""common""] = common_parameters.to_dict() <TAB> else: <TAB>  <TAB> self.job_runtime_conf[""job_parameters""] = common_parameters.to_dict() <TAB> return self.job_runtime_conf","if ""common"" not in self . job_runtime_conf [ ""job_parameters"" ] :",160
"def clean(self): <TAB> # Search pick must have at least one recommended page to be valid <TAB> # Check there is at least one non-deleted form. <TAB> non_deleted_forms = self.total_form_count() <TAB> non_empty_forms = 0 <TAB> for i in range(0, self.total_form_count()): <TAB>  <TAB> form = self.forms[i] <TAB>  <TAB> if self.can_delete and self._should_delete_form(form): <TAB>  <TAB>  <TAB> non_deleted_forms -= 1 <MASK> non_empty_forms += 1 <TAB> if non_deleted_forms < self.minimum_forms or non_empty_forms < self.minimum_forms: <TAB>  <TAB> raise forms.ValidationError(self.minimum_forms_message)",if not ( form . instance . id is None and not form . has_changed ( ) ) :,194
"def _value__set(self, value): <TAB> if self.checkable: <TAB>  <TAB> if not value: <TAB>  <TAB>  <TAB> self.checked = False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.checked = True <MASK> self.set(""value"", value) <TAB> else: <TAB>  <TAB> self.set(""value"", value)","if isinstance ( value , basestring ) :",88
"def asbool(obj): <TAB> if isinstance(obj, compat.string_types): <TAB>  <TAB> obj = obj.strip().lower() <TAB>  <TAB> if obj in [""true"", ""yes"", ""on"", ""y"", ""t"", ""1""]: <TAB>  <TAB>  <TAB> return True <MASK> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""String is not true/false: %r"" % obj) <TAB> return bool(obj)","elif obj in [ ""false"" , ""no"" , ""off"" , ""n"" , ""f"" , ""0"" ] :",123
"def checkHTTPSpelling(tag, start, end, style, passage=None): <TAB> if style == tweelexer.TweeLexer.EXTERNAL: <TAB>  <TAB> # Corrects the incorrect spellings ""http//"" and ""http:/"" (and their https variants) <TAB>  <TAB> regex = re.search(r""\bhttp(s?)(?:\/\/|\:\/(?=[^\/]))"", tag) <MASK> yield ( <TAB>  <TAB>  <TAB>  <TAB> r""You appear to have misspelled 'http"" + regex.group(1) + ""://'."", <TAB>  <TAB>  <TAB>  <TAB> ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> start + regex.start(0), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""http"" + regex.group(1) + ""://"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> start + regex.end(0), <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB> )",if regex :,196
"def _pkgs2name_dict(self, sections): <TAB> installed = self.sack.query().installed()._name_dict() <TAB> available = self.sack.query().available()._name_dict() <TAB> d = {} <TAB> for pkg_name in itertools.chain(*list(zip(*sections))[1]): <TAB>  <TAB> if pkg_name in installed: <TAB>  <TAB>  <TAB> d[pkg_name] = installed[pkg_name][0] <MASK> d[pkg_name] = available[pkg_name][0] <TAB> return d",elif pkg_name in available :,133
"def __eq__(self, other: object) -> bool: <TAB> if isinstance(other, self.__class__): <MASK> return False <TAB>  <TAB> for idx, row in enumerate(self.inline_keyboard): <TAB>  <TAB>  <TAB> if len(row) != len(other.inline_keyboard[idx]): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> for jdx, button in enumerate(row): <TAB>  <TAB>  <TAB>  <TAB> if button != other.inline_keyboard[idx][jdx]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True <TAB> return super().__eq__(other)",if len ( self . inline_keyboard ) != len ( other . inline_keyboard ) :,150
"def has_changed(self, maximum, symbols): <TAB> # timestamp for the most recently changed part of a given expression. <TAB> for name in symbols: <TAB>  <TAB> symb = self.get_definition(name, only_if_exists=True) <TAB>  <TAB> if symb is None: <TAB>  <TAB>  <TAB> # symbol doesn't exist so it was never changed <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> changed = getattr(symb, ""changed"", None) <TAB>  <TAB>  <TAB> if changed is None: <TAB>  <TAB>  <TAB>  <TAB> # must be system symbol <TAB>  <TAB>  <TAB>  <TAB> symb.changed = 0 <MASK> return True <TAB> return False",elif changed > maximum :,154
"def log(self, header=""Opt""): <TAB> from parlai.core.params import print_git_commit <TAB> logging.info(header + "":"") <TAB> for key in sorted(self.keys()): <TAB>  <TAB> valstr = str(self[key]) <MASK> # show newlines as escaped keys, whitespace with quotes, etc <TAB>  <TAB>  <TAB> valstr = repr(valstr) <TAB>  <TAB> logging.info(f"" <TAB> {key}: {valstr}"") <TAB> print_git_commit()","if valstr . replace ( "" "" , """" ) . replace ( ""\n"" , """" ) != valstr :",133
"def substr(s1, s2): <TAB> ""Search for a string in another string"" <TAB> s1 = to_binary_string(s1) <TAB> s2 = to_binary_string(s2) <TAB> i = 1 <TAB> found = 0 <TAB> while i <= len(s1): <MASK> found = 1 <TAB>  <TAB>  <TAB> i += 1 <TAB>  <TAB>  <TAB> if s1[: i - 1][-1:] == b""\x00"": <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> if found == 1: <TAB>  <TAB> return i - 1 <TAB> else: <TAB>  <TAB> return -1",if s2 . find ( s1 [ : i ] ) != - 1 :,161
"def gen_dict_extract(key: str, obj: Dict) -> Generator[Any, None, None]: <TAB> if hasattr(obj, ""items""): <TAB>  <TAB> for k, v in obj.items(): <MASK> yield v <TAB>  <TAB>  <TAB> if isinstance(v, dict): <TAB>  <TAB>  <TAB>  <TAB> for result in gen_dict_extract(key, v): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield result <TAB>  <TAB>  <TAB> elif isinstance(v, list): <TAB>  <TAB>  <TAB>  <TAB> for d in v: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for result in gen_dict_extract(key, d): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield result",if k == key :,149
"def _format_privilege_data(self, data): <TAB> # To format privileges data coming from client <TAB> for key in [""relacl""]: <TAB>  <TAB> if key in data and data[key] is not None: <TAB>  <TAB>  <TAB> if ""added"" in data[key]: <TAB>  <TAB>  <TAB>  <TAB> data[key][""added""] = parse_priv_to_db(data[key][""added""], self.acl) <TAB>  <TAB>  <TAB> if ""changed"" in data[key]: <TAB>  <TAB>  <TAB>  <TAB> data[key][""changed""] = parse_priv_to_db(data[key][""changed""], self.acl) <MASK> data[key][""deleted""] = parse_priv_to_db(data[key][""deleted""], self.acl)","if ""deleted"" in data [ key ] :",177
"def find_project_base_dir(): <TAB> cur_dir = dirname(nc(__file__)) <TAB> while True: <TAB>  <TAB> if exists(jp(cur_dir, ""build.py"")): <TAB>  <TAB>  <TAB> return cur_dir <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_cur_dir = nc(jp(cur_dir, "".."")) <MASK> return None <TAB>  <TAB>  <TAB> cur_dir = new_cur_dir",if new_cur_dir == cur_dir :,112
"def add(self, dep) -> None: <TAB> if dep.name not in self._mapping: <TAB>  <TAB> self._mapping[dep.name] = dep <TAB>  <TAB> return <TAB> # if it is the first layer (requirements.txt) try to merge these deps <TAB> if self.level == 1: <TAB>  <TAB> self._mapping[dep.name] += dep <MASK> raise ValueError(""Cannot resolve root dependency: "" + dep.name) <TAB>  <TAB> return <TAB> raise KeyError(""Dependency already added in layer: "" + dep.name)",if not self . _mapping [ dep . name ] . compat :,135
"def compdb_generated(future): <TAB> """"""Generate a compilation database."""""" <TAB> if future.done() and not future.cancelled(): <TAB>  <TAB> output_text = future.result() <TAB>  <TAB> log.debug(""Database generated. Output: \n%s"", output_text) <MASK> log.error( <TAB>  <TAB>  <TAB>  <TAB> ""Could not generate compilation database. Output: %s"", output_text <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> OutputPanelHandler.show( <TAB>  <TAB>  <TAB>  <TAB> ""Could not generate compilation database.\n"" + output_text <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> OutputPanelHandler.show(""Could not generate compilation database."")","if ""ERROR: "" in output_text :",160
"def load(self): <TAB> cls = type(self.configuration) <TAB> with open(self.path, ""r"") as config_file: <TAB>  <TAB> raw = config_file.read() <TAB> serialized = yaml.safe_load(raw) or {} <TAB> for key, value in serialized.items(): <TAB>  <TAB> attr = getattr(cls, key, None) <MASK> for setting in self.configuration.settings: <TAB>  <TAB>  <TAB>  <TAB> if key in setting.previous_names: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> attr = setting <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if attr is not None: <TAB>  <TAB>  <TAB> self.data[key] = attr.deserialize(value)",if attr is None :,159
"def ant_glob(self, *k, **kw): <TAB> if k: <TAB>  <TAB> lst = Utils.to_list(k[0]) <TAB>  <TAB> for pat in lst: <TAB>  <TAB>  <TAB> sp = pat.split(""/"") <MASK> Logs.error( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""In ant_glob pattern %r: '..' means 'two dots', not 'parent directory'"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> k[0], <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> if ""."" in sp: <TAB>  <TAB>  <TAB>  <TAB> Logs.error( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""In ant_glob pattern %r: '.' means 'one dot', not 'current directory'"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> k[0], <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return self.old_ant_glob(*k, **kw)","if "".."" in sp :",190
"def run(self, edit, command_name, args): <TAB> # add selections <TAB> end = settings().get(""paste_gun_ammo_xarg"", 1) + 1 <TAB> if len(self.view.sel()) == 1 and end > 1: <TAB>  <TAB> region = self.view.sel()[0] <MASK> pos = region.begin() <TAB>  <TAB>  <TAB> for i in range(1, end): <TAB>  <TAB>  <TAB>  <TAB> self.view.sel().add(pos) <TAB>  <TAB>  <TAB>  <TAB> self.view.insert(edit, pos, ""\n"") <TAB> # mark <TAB> self.view.settings().set(""tp_ammo_extend_selection"", True) <TAB> self.view.run_command(command_name, args)",if region . begin ( ) == region . end ( ) :,182
"def print_tree(self, tree, indent=""""): <TAB> for item in tree: <MASK> self.print_tree(item, indent + "" "") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(indent, symbol.sym_name.get(item, item))","if isinstance ( item , tuple ) :",70
"def _make_attribute(self, tok): <TAB> """"""Compose a c_ast.CAttribute() object for each attribute."""""" <TAB> result = [] <TAB> for attr_specifier in tok: <TAB>  <TAB> expression = [] <MASK> # Try to parse the expression if possible. <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> expression = [self.expression_parser.parse(attr_specifier.args)] <TAB>  <TAB>  <TAB> except pyparsing.ParseException: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> result.append(c_ast.CAttribute(attr_specifier.name.first, *expression)) <TAB> return result",if attr_specifier . args :,144
"def __poll_for_result(self, url): <TAB> # docs: ""The most efficient approach would be to wait at least 10 seconds <TAB> # before starting to poll, and then only polling 2-second intervals with an <TAB> # eventual upper timeout in case the scan does not return."" <TAB> max_tries = 10 <TAB> poll_distance = 2 <TAB> result = {} <TAB> time.sleep(10) <TAB> for chance in range(max_tries): <MASK> time.sleep(poll_distance) <TAB>  <TAB> resp = self.session.get(url) <TAB>  <TAB> if resp.status_code == 404: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result = resp.json() <TAB>  <TAB>  <TAB> break <TAB> return result",if chance :,174
"def environ(self, **kwargs): <TAB> old_vals = {} <TAB> for key in kwargs: <TAB>  <TAB> if key in os.environ: <TAB>  <TAB>  <TAB> old_vals[key] = os.environ[key] <TAB> for key, val in kwargs.items(): <MASK> if key in os.environ: <TAB>  <TAB>  <TAB>  <TAB> del os.environ[key] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> os.environ[key] = val <TAB> try: <TAB>  <TAB> yield <TAB> finally: <TAB>  <TAB> for key in kwargs: <TAB>  <TAB>  <TAB> if key in os.environ: <TAB>  <TAB>  <TAB>  <TAB> del os.environ[key] <TAB>  <TAB> for key, val in old_vals.items(): <TAB>  <TAB>  <TAB> os.environ[key] = val",if val is None :,178
"def _massage_node(node, attr): <TAB> """"""The real work for remove_rel is done here, parametrized with @rel and @rev"""""" <TAB> if node.hasAttribute(""property"") and node.hasAttribute(attr): <TAB>  <TAB> vals = node.getAttribute(attr).strip().split() <TAB>  <TAB> if len(vals) != 0: <TAB>  <TAB>  <TAB> final_vals = [v for v in vals if not termname.match(v)] <MASK> node.removeAttribute(attr) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> node.setAttribute(attr, reduce(lambda x, y: x + "" "" + y, final_vals))",if len ( final_vals ) == 0 :,165
"def test_get_new_branch_commits(two_branch_repo_case, existing, expected): <TAB> dvcs, master, r, conf = two_branch_repo_case <TAB> existing_commits = set() <TAB> for branch in conf.branches: <TAB>  <TAB> for commit in r.get_branch_commits(branch): <TAB>  <TAB>  <TAB> message = dvcs.get_commit_message(commit) <MASK> existing_commits.add(commit) <TAB> assert len(existing_commits) == len(existing) <TAB> new_commits = r.get_new_branch_commits(conf.branches, existing_commits) <TAB> commits = [dvcs.get_commit_message(commit) for commit in new_commits] <TAB> assert commits == expected",if message in existing :,181
"def negative(tokens, base_url): <TAB> """"""``negative`` descriptor validation."""""" <TAB> if len(tokens) > 2: <TAB>  <TAB> return <TAB> values = [] <TAB> tokens = list(tokens) <TAB> while tokens: <TAB>  <TAB> token = tokens.pop(0) <MASK> values.append((""string"", token.value)) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> url = get_url(token, base_url) <TAB>  <TAB> if url is not None and url[0] == ""url"": <TAB>  <TAB>  <TAB> values.append((""url"", url[1])) <TAB> if len(values) == 1: <TAB>  <TAB> values.append((""string"", """")) <TAB> if len(values) == 2: <TAB>  <TAB> return values","if token . type in ( ""string"" , ""ident"" ) :",176
"def filterPackets(self, pkt): <TAB> if pkt.haslayer(TCP) and pkt.haslayer(Raw) and pkt.haslayer(IP): <TAB>  <TAB> self.dport = pkt[TCP].dport <TAB>  <TAB> self.sport = pkt[TCP].sport <TAB>  <TAB> if self.dport == 110 or self.sport == 25 or self.dport == 143: <MASK> email_pkt = str(ptk[TCP].payload) <TAB>  <TAB>  <TAB>  <TAB> if ""user"" in email_pkt.lower() or ""pass"" in email_pkt.lower(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.logging.info(""[*] Server {}"".format(pkt[IP].dst)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.logging.info(""[*] {}"".format(pkt[TCP].payload))",if ptk [ TCP ] . payload :,182
"def _map_fun(args, ctx): <TAB> import tensorflow as tf <TAB> tf_feed = TFNode.DataFeed(ctx.mgr, False) <TAB> while not tf_feed.should_stop(): <TAB>  <TAB> batch = tf_feed.next_batch(10) <MASK> squares = tf.math.square(batch) <TAB>  <TAB>  <TAB> tf_feed.batch_results(squares.numpy()) <TAB> # simulate post-feed actions that raise an exception <TAB> time.sleep(2) <TAB> raise Exception(""FAKE exception after feeding"")",if len ( batch ) > 0 :,133
"def update(client: Any, issue: Any, issue_fields: dict, transition: str = None) -> dict: <TAB> """"""Updates a Jira issue."""""" <TAB> data = {""resource_id"": issue.key, ""link"": f""{JIRA_BROWSER_URL}/browse/{issue.key}""} <TAB> if issue_fields: <TAB>  <TAB> issue.update(fields=issue_fields) <TAB> if transition: <TAB>  <TAB> transitions = client.transitions(issue) <TAB>  <TAB> for t in transitions: <MASK> client.transition_issue(issue, t[""id""]) <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return data","if t [ ""name"" ] . lower ( ) == transition . lower ( ) :",156
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.set_destination_url(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 18: <TAB>  <TAB>  <TAB> self.set_auth_domain(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 26: <TAB>  <TAB>  <TAB> self.set_federated_identity(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 10 :,158
"def gen_typecache_storage(cw): <TAB> types = {} <TAB> for x in data: <MASK> types[x.typeType].append(x) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> types[x.typeType] = [x] <TAB> for type in types: <TAB>  <TAB> for a_type in types[type]: <TAB>  <TAB>  <TAB> cw.write(""private static %s %s;"" % (type, a_type.name))",if types . has_key ( x . typeType ) :,117
"def before_write_items(items, nulls_map=None): <TAB> null_value = self.null_value <TAB> for i, item in enumerate(items): <MASK> items[i] = null_value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> items[i] = c_float(item).value",if nulls_map and nulls_map [ i ] :,88
"def try_start_scheduler(self, app): <TAB> t = None <TAB> with self.scheduler_processes_lock: <TAB>  <TAB> if not is_appdir(self.options.folder, app): <TAB>  <TAB>  <TAB> self.schedmenu.delete(""start %s"" % app) <TAB>  <TAB>  <TAB> return <MASK> t = threading.Thread(target=self.start_schedulers, args=(app,)) <TAB> if t is not None: <TAB>  <TAB> t.start()",if app not in self . scheduler_processes :,119
"def send(self, v): <TAB> try: <TAB>  <TAB> if self._i == 0: <TAB>  <TAB>  <TAB> assert v is None <TAB>  <TAB>  <TAB> return self._fut <TAB>  <TAB> if self._i == 1: <TAB>  <TAB>  <TAB> raise StopIteration(v * 2) <MASK> raise StopIteration <TAB> finally: <TAB>  <TAB> self._i += 1",if self . _i > 1 :,88
"def _extract_subject_public_key_info(x509_certificate): <TAB> """"""Extract subjectPublicKeyInfo from a DER X.509 certificate."""""" <TAB> certificate = DerSequence().decode(x509_certificate, nr_elements=3) <TAB> tbs_certificate = DerSequence().decode(certificate[0], nr_elements=range(6, 11)) <TAB> index = 5 <TAB> try: <TAB>  <TAB> tbs_certificate[0] + 1 <TAB>  <TAB> # Version not present <TAB>  <TAB> version = 1 <TAB> except TypeError: <TAB>  <TAB> version = DerInteger(explicit=0).decode(tbs_certificate[0]).value <MASK> raise ValueError(""Incorrect X.509 certificate version"") <TAB>  <TAB> index = 6 <TAB> return tbs_certificate[index]","if version not in ( 2 , 3 ) :",183
"def headers(self): <TAB> headers = self._get_headers_from_yaml(self.read(body=False)) <TAB> if not headers: <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> ""YAML header is missing. Please ensure that the top of your post has a header of the following form:\n"" <TAB>  <TAB>  <TAB> + HEADER_SAMPLE <TAB>  <TAB> ) <TAB> for key, value in headers.copy().items(): <TAB>  <TAB> if isinstance(value, datetime.date): <TAB>  <TAB>  <TAB> headers[key] = datetime.datetime.combine(value, datetime.time(0)) <MASK> headers[key] = [str(v) for v in value] <TAB> return headers","if key == ""tags"" and isinstance ( value , list ) :",167
"def _update_last_full_sync_timestamp(self): <TAB> db = get_session() <TAB> try: <MASK> db.refresh(self.metadata) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""metadata object not found"") <TAB>  <TAB> # Update timestamps <TAB>  <TAB> self.metadata.last_update = datetime.datetime.utcnow() <TAB>  <TAB> self.metadata.last_full_sync = self.metadata.last_update <TAB>  <TAB> db.commit() <TAB> except Exception as e: <TAB>  <TAB> logger.exception(""Failed updating feed metadata timestamps."") <TAB>  <TAB> db.rollback() <TAB>  <TAB> raise e",if self . metadata :,146
"def verify_interface(iface, klass): <TAB> for method in iface.__abstractmethods__: <TAB>  <TAB> if not hasattr(klass, method): <TAB>  <TAB>  <TAB> raise InterfaceNotImplemented( <TAB>  <TAB>  <TAB>  <TAB> ""{0} is missing a {1!r} method"".format(klass, method) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if isinstance(getattr(iface, method), abc.abstractproperty): <TAB>  <TAB>  <TAB> # Can't properly verify these yet. <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> sig = signature(getattr(iface, method)) <TAB>  <TAB> actual = signature(getattr(klass, method)) <MASK> raise InterfaceNotImplemented( <TAB>  <TAB>  <TAB>  <TAB> ""{0}.{1}'s signature differs from the expected. Expected: "" <TAB>  <TAB>  <TAB>  <TAB> ""{2!r}. Received: {3!r}"".format(klass, method, sig, actual) <TAB>  <TAB>  <TAB> )",if sig != actual :,195
"def transform_one(self, x): <TAB> x_hashed = collections.defaultdict(int) <TAB> for feature, value in x.items(): <MASK> feature = f""{feature}={value}"" <TAB>  <TAB>  <TAB> value = 1 <TAB>  <TAB> if value == 0: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> h = mmh3.hash(feature, seed=self._hash_seed) <TAB>  <TAB> i = h % self.n_features <TAB>  <TAB> if self.alternate_sign: <TAB>  <TAB>  <TAB> value *= (h >= 0) * 2 - 1 <TAB>  <TAB> x_hashed[i] += value <TAB> return x_hashed","if isinstance ( value , str ) :",149
"def get_provisioning_state(instance): <TAB> provisioning_state = getattr(instance, ""provisioning_state"", None) <TAB> if not provisioning_state: <TAB>  <TAB> # some SDK, like resource-group, has 'provisioning_state' under 'properties' <TAB>  <TAB> properties = getattr(instance, ""properties"", None) <MASK> provisioning_state = getattr(properties, ""provisioning_state"", None) <TAB>  <TAB>  <TAB> # some SDK, like keyvault, has 'provisioningState' under 'properties.additional_properties' <TAB>  <TAB>  <TAB> if not provisioning_state: <TAB>  <TAB>  <TAB>  <TAB> additional_properties = getattr(properties, ""additional_properties"", {}) <TAB>  <TAB>  <TAB>  <TAB> provisioning_state = additional_properties.get(""provisioningState"") <TAB> return provisioning_state",if properties :,177
"def _recurs_find(self, path, *args, **kargs): <TAB> if self in path: <TAB>  <TAB> return None <TAB> if self._my_find(*args, **kargs): <TAB>  <TAB> return self <TAB> for o in self: <TAB>  <TAB> if isinstance(o, DADict): <TAB>  <TAB>  <TAB> p = o._recurs_find(path + (self,), *args, **kargs) <MASK> return p <TAB> return None",if p is not None :,111
"def parse(self, asf, data): <TAB> super(ContentDescriptionObject, self).parse(asf, data) <TAB> lengths = struct.unpack(""<HHHHH"", data[:10]) <TAB> texts = [] <TAB> pos = 10 <TAB> for length in lengths: <TAB>  <TAB> end = pos + length <MASK> texts.append(data[pos:end].decode(""utf-16-le"").strip(u""\x00"")) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> texts.append(None) <TAB>  <TAB> pos = end <TAB> for key, value in zip(self.NAMES, texts): <TAB>  <TAB> if value is not None: <TAB>  <TAB>  <TAB> value = ASFUnicodeAttribute(value=value) <TAB>  <TAB>  <TAB> asf._tags.setdefault(self.GUID, []).append((key, value))",if length > 0 :,186
"def clip(token): <TAB> """"""Validation for the ``clip`` property."""""" <TAB> function = parse_function(token) <TAB> if function: <TAB>  <TAB> name, args = function <TAB>  <TAB> if name == ""rect"" and len(args) == 4: <TAB>  <TAB>  <TAB> values = [] <TAB>  <TAB>  <TAB> for arg in args: <TAB>  <TAB>  <TAB>  <TAB> if get_keyword(arg) == ""auto"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> values.append(""auto"") <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> length = get_length(arg) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if length: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> values.append(length) <MASK> return tuple(values) <TAB> if get_keyword(token) == ""auto"": <TAB>  <TAB> return ()",if len ( values ) == 4 :,184
"def _add_match_items(self): <TAB> match_items = list(self.match.items()) <TAB> match_items.sort(key=lambda x: x[0]) <TAB> for key, value in match_items: <MASK> continue <TAB>  <TAB> value_str = str(value) <TAB>  <TAB> value_str.replace(""\\n"", ""\n"") <TAB>  <TAB> if type(value) in [list, dict]: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> value_str = self._pretty_print_as_json(value) <TAB>  <TAB>  <TAB> except TypeError: <TAB>  <TAB>  <TAB>  <TAB> # Non serializable object, fallback to str <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> self.text += ""%s: %s\n"" % (key, value_str)","if key . startswith ( ""top_events_"" ) :",185
"def boolval(v): <TAB> if isinstance(v, bool): <TAB>  <TAB> return v <TAB> if isinstance(v, int): <TAB>  <TAB> return bool(v) <TAB> if is_string(v): <TAB>  <TAB> v = v.lower() <TAB>  <TAB> if v in {""j"", ""y"", ""ja"", ""yes"", ""1"", ""true""}: <TAB>  <TAB>  <TAB> return True <MASK> return False <TAB> raise ValueError(""Don't know how to convert %r to bool"" % v)","if v in { ""n"" , ""nei"" , ""no"" , ""0"" , ""false"" } :",133
"def get_primary_source_title(db, obj): <TAB> for citation_handle in obj.get_citation_list(): <TAB>  <TAB> citation = db.get_citation_from_handle(citation_handle) <TAB>  <TAB> source = db.get_source_from_handle(citation.get_reference_handle()) <MASK> return source.get_title() <TAB> return """"",if source :,94
"def _send_startup_msg(self): <TAB> list_names = [] <TAB> for idx, tup in enumerate(self.settings[""lists""].items()): <TAB>  <TAB> name, author = tup <MASK> title = _(""{trivia_list} (by {author})"").format( <TAB>  <TAB>  <TAB>  <TAB> trivia_list=name, author=author <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> title = name <TAB>  <TAB> list_names.append(title) <TAB> await self.ctx.send( <TAB>  <TAB> _(""Starting Trivia: {list_names}"").format(list_names=humanize_list(list_names)) <TAB> )",if author :,152
"def get_cut_info(edge_len_list, cut_len): <TAB> for idx, edge_len in enumerate(edge_len_list): <TAB>  <TAB> cut_len -= edge_len <MASK> ratio = (cut_len + edge_len_list[idx]) / edge_len_list[idx] <TAB>  <TAB>  <TAB> return idx, ratio",if cut_len <= 0.000001 :,93
"def format(self, record: LogRecord): <TAB> record.levelname = self.get_colored_level(record) <TAB> try: <TAB>  <TAB> cur_thread = self._ql.os.thread_management.cur_thread <MASK> record.levelname = f""{record.levelname} {COLOR_CODE.GREEN}{str(cur_thread)}{COLOR_CODE.ENDC}"" <TAB> except AttributeError: <TAB>  <TAB> pass <TAB> return super(QilingColoredFormatter, self).format(record)",if cur_thread is not None :,123
"def _output_for(self, content, mode=None, context=None): <TAB> for request_content in self._response_map: <MASK> continue <TAB>  <TAB> responses = self._response_map[request_content] <TAB>  <TAB> if mode is None or mode == ""markdown"": <TAB>  <TAB>  <TAB> return responses[""markdown""] <TAB>  <TAB> elif context is None: <TAB>  <TAB>  <TAB> return responses[""user-content""] <TAB>  <TAB> elif context == USER_CONTEXT: <TAB>  <TAB>  <TAB> return responses[""user-context""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Markdown group not found for user context: {0}"".format(USER_CONTEXT) <TAB>  <TAB>  <TAB> ) <TAB> raise ValueError(""Markdown group not found for: {!r}"".format(content))",if request_content != content :,184
"def _find(self, filename, in_dir): <TAB> """"""is a specific layer filename referenced by another image TAG"""""" <TAB> found_list = [] <TAB> if FileUtil(in_dir).isdir(): <TAB>  <TAB> for fullname in os.listdir(in_dir): <TAB>  <TAB>  <TAB> f_path = in_dir + ""/"" + fullname <TAB>  <TAB>  <TAB> if os.path.islink(f_path): <TAB>  <TAB>  <TAB>  <TAB> if filename in fullname:  # match .layer or .json <TAB>  <TAB>  <TAB>  <TAB>  <TAB> found_list.append(f_path)  # found reference to layer <MASK> found_list.extend(self._find(filename, f_path)) <TAB> return found_list",elif os . path . isdir ( f_path ) :,172
"def _str2id(self, text): <TAB> for definition in self.card.board.get_custom_field_definitions(): <MASK> for key, val in definition.list_options.items(): <TAB>  <TAB>  <TAB>  <TAB> if val == text: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return key <TAB>  <TAB>  <TAB> return None <TAB> raise Exception(""Definition not found"")",if definition . id == self . definition_id :,94
"def getPassword(prompt="""", confirm=0): <TAB> while 1: <TAB>  <TAB> try1 = tkSimpleDialog.askstring(""Password Dialog"", prompt, show=""*"") <MASK> return try1 <TAB>  <TAB> try2 = tkSimpleDialog.askstring(""Password Dialog"", ""Confirm Password"", show=""*"") <TAB>  <TAB> if try1 == try2: <TAB>  <TAB>  <TAB> return try1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tkMessageBox.showerror( <TAB>  <TAB>  <TAB>  <TAB> ""Password Mismatch"", ""Passwords did not match, starting over"" <TAB>  <TAB>  <TAB> )",if not confirm :,131
"def parse_codeowners(text: str) -> CodeOwners: <TAB> result = [] <TAB> for i, line in enumerate(text.splitlines()): <TAB>  <TAB> line = line.strip() <TAB>  <TAB> if line == """": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if line[0] == ""#"":  # comment <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elements = list(filter(lambda x: x != """", line.split("" ""))) <TAB>  <TAB> pattern = check_pattern(elements[0], i) <TAB>  <TAB> users = [check_user(user, i) for user in elements[1:]] <TAB>  <TAB> users = [user for user in users if user is not None] <MASK> result.append((pattern, users)) <TAB> return result",if users :,170
"def _home(self, line): <TAB> x = y = z = e = None <TAB> if ""X"" in line: <TAB>  <TAB> x = True <TAB> if ""Y"" in line: <TAB>  <TAB> y = True <TAB> if ""Z"" in line: <TAB>  <TAB> z = True <TAB> if ""E"" in line: <TAB>  <TAB> e = True <TAB> if x is None and y is None and z is None and e is None: <TAB>  <TAB> self._lastX = self._lastY = self._lastZ = self._lastE[self.currentExtruder] = 0 <TAB> else: <MASK> self._lastX = 0 <TAB>  <TAB> if y: <TAB>  <TAB>  <TAB> self._lastY = 0 <TAB>  <TAB> if z: <TAB>  <TAB>  <TAB> self._lastZ = 0 <TAB>  <TAB> if e: <TAB>  <TAB>  <TAB> self._lastE = 0",if x :,200
"def create_report_from_func(function_attr): <TAB> func_content = { <TAB>  <TAB> ""name"": function_attr.__name__, <TAB>  <TAB> ""metadata"": getattr(function_attr, ""metadata"", {}), <TAB>  <TAB> ""parameters"": [], <TAB> } <TAB> signature = inspect.signature(function_attr) <TAB> for parameter_name in signature.parameters: <MASK> continue <TAB>  <TAB> if parameter_name == ""custom_headers"": <TAB>  <TAB>  <TAB> break  # We reach Autorest generic <TAB>  <TAB> parameter = signature.parameters[parameter_name] <TAB>  <TAB> func_content[""parameters""].append( <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB> ""name"": parameter.name, <TAB>  <TAB>  <TAB> } <TAB>  <TAB> ) <TAB> return func_content","if parameter_name == ""self"" :",180
"def append(self, value): <TAB> if isinstance(value, str): <TAB>  <TAB> value = Path(value) <MASK> return <TAB>  <TAB> if len(value) > 1: <TAB>  <TAB>  <TAB> self.extend(value) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> value = value[0] <TAB> self._length = None <TAB> index = len(self._segments) - 1 <TAB> self._segments.append(value) <TAB> self._validate_connection(index) <TAB> if isinstance(value, Close): <TAB>  <TAB> self._validate_close(index + 1)",if len ( value ) == 0 :,138
"def _submenu(self, group, menubar): <TAB> try: <TAB>  <TAB> return self._menu_groups[group] <TAB> except KeyError: <TAB>  <TAB> if group is None: <TAB>  <TAB>  <TAB> submenu = menubar <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> parent_menu = self._submenu(group.parent, menubar) <TAB>  <TAB>  <TAB> submenu = Gio.Menu() <TAB>  <TAB>  <TAB> self._menu_groups[group] = submenu <TAB>  <TAB>  <TAB> label = group.label <MASK> label = self.interface.name <TAB>  <TAB>  <TAB> parent_menu.append_submenu(label, submenu) <TAB>  <TAB> # Install the item in the group cache. <TAB>  <TAB> self._menu_groups[group] = submenu <TAB>  <TAB> return submenu","if label == ""*"" :",174
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_module(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 18: <TAB>  <TAB>  <TAB> self.set_version(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 26: <TAB>  <TAB>  <TAB> self.set_instance(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,150
"def _do_arguments(self, scope, arguments): <TAB> for node in arguments: <MASK> scope.add_param(node.name) <TAB>  <TAB>  <TAB> if node.annotation: <TAB>  <TAB>  <TAB>  <TAB> self.visit(node.annotation, scope) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._do_arguments(scope, node.args)","if isinstance ( node , ast . SimpleArg ) :",92
"def findChild(self, child): <TAB> if getattr(child, ""tag"", None) and child.tag in self.tag.contents: <TAB>  <TAB> childHash = hash(child.tag._node) <TAB>  <TAB> for p in self.tag.contents: <MASK> continue <TAB>  <TAB>  <TAB> if childHash == hash(p._node): <TAB>  <TAB>  <TAB>  <TAB> return self.tag.contents.index(p) <TAB> return -1","if getattr ( p , ""_node"" , None ) is None :",116
"def __repr__(self) -> str: <TAB> representation = """" <TAB> for attribute in ""name"", ""description"", ""number"": <TAB>  <TAB> value = getattr(self, attribute) <MASK> representation += ""{}{}={}"".format( <TAB>  <TAB>  <TAB>  <TAB> "", "" if representation else """", attribute, repr(value) <TAB>  <TAB>  <TAB> ) <TAB> representation += ""{}segments={}"".format( <TAB>  <TAB> "", "" if representation else """", repr(self.segments) <TAB> ) <TAB> return ""GPXTrack(%s)"" % representation",if value is not None :,120
"def _parse_user_spark_args(spark_args: Optional[str]) -> Dict[str, str]: <TAB> if not spark_args: <TAB>  <TAB> return {} <TAB> user_spark_opts = {} <TAB> for spark_arg in spark_args.split(): <TAB>  <TAB> fields = spark_arg.split(""="", 1) <MASK> print( <TAB>  <TAB>  <TAB>  <TAB> PaastaColors.red( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Spark option %s is not in format option=value."" % spark_arg <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB>  <TAB> file=sys.stderr, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> sys.exit(1) <TAB>  <TAB> user_spark_opts[fields[0]] = fields[1] <TAB> return user_spark_opts",if len ( fields ) != 2 :,196
"def inject_refresh(self, peers, refresh): <TAB> result = True <TAB> for neighbor in self.neighbors: <TAB>  <TAB> if neighbor in peers: <TAB>  <TAB>  <TAB> family = (refresh.afi, refresh.safi) <MASK> self.neighbors[neighbor].refresh.append( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> refresh.__class__(refresh.afi, refresh.safi) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> result = False <TAB> return result",if family in self . neighbors [ neighbor ] . families ( ) :,127
"def _do_partial_selection(files, curr_b): <TAB> partials = [] <TAB> for fp in files: <TAB>  <TAB> f_st = curr_b.status_file(fp) <TAB>  <TAB> if not f_st.exists_at_head: <TAB>  <TAB>  <TAB> pprint.warn(""Can't select segments for new file {0}"".format(fp)) <TAB>  <TAB>  <TAB> continue <MASK> pprint.warn(""Can't select segments for deleted file {0}"".format(fp)) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> subprocess.call([""git"", ""add"", ""-p"", fp]) <TAB>  <TAB> # TODO: check that at least one hunk was staged <TAB>  <TAB> partials.append(fp) <TAB> return partials",if not f_st . exists_in_wd :,174
"def get_candidates(self, ssa, head, max_expr_depth): <TAB> defuse = SSADefUse.from_ssa(ssa) <TAB> to_replace = {} <TAB> node_to_reg = {} <TAB> for node in defuse.nodes(): <TAB>  <TAB> src = defuse.get_node_target(node) <MASK> continue <TAB>  <TAB> if src.is_function_call(): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if node.var.is_mem(): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> to_replace[node.var] = src <TAB>  <TAB> node_to_reg[node] = node.var <TAB> return node_to_reg, to_replace, defuse",if not src . is_int ( ) :,172
"def tamper(payload): <TAB> if settings.WHITESPACE[0] == ""+"": <TAB>  <TAB> err_msg = ( <TAB>  <TAB>  <TAB> ""Tamper script '"" <TAB>  <TAB>  <TAB> + __tamper__ <TAB>  <TAB>  <TAB> + ""' is unlikely to work combined with the tamper script 'space2plus'."" <TAB>  <TAB> ) <MASK> print("""") <TAB>  <TAB> print(settings.print_critical_msg(err_msg)) <TAB>  <TAB> raise SystemExit() <TAB> else: <TAB>  <TAB> payload = _urllib.parse.unquote(payload) <TAB>  <TAB> payload = payload.encode(""hex"") <TAB>  <TAB> return payload",if settings . VERBOSITY_LEVEL == 0 :,151
"def _expand_vars(scheme, vars): <TAB> res = {} <TAB> if vars is None: <TAB>  <TAB> vars = {} <TAB> _extend_dict(vars, get_config_vars()) <TAB> for key, value in _INSTALL_SCHEMES[scheme].items(): <TAB>  <TAB> # not affected by JyNI-monkeypatching, because 'java' <TAB>  <TAB> # is in the list anyway: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> value = os.path.expanduser(value) <TAB>  <TAB>  <TAB> except ImportError: <TAB>  <TAB>  <TAB>  <TAB> pass  # ignore missing pwd if no native posix for Jython <TAB>  <TAB> res[key] = os.path.normpath(_subst_vars(value, vars)) <TAB> return res","if os . name in ( ""posix"" , ""nt"" , ""java"" ) :",181
"def _animate_match_backtrack_frame(self, frame, widget, dy): <TAB> if frame > 0: <TAB>  <TAB> self._animating_lock = 1 <TAB>  <TAB> widget.move(0, dy) <TAB>  <TAB> self._top.after(10, self._animate_match_backtrack_frame, frame - 1, widget, dy) <TAB> else: <TAB>  <TAB> widget.parent().remove_child(widget) <TAB>  <TAB> widget.destroy() <TAB>  <TAB> self._animating_lock = 0 <MASK> self._step()",if self . _autostep :,126
"def centroid_dist(self, centroid_list): <TAB> cluster_dist_list = [] <TAB> for i in range(0, len(centroid_list)): <TAB>  <TAB> for j in range(0, len(centroid_list)): <MASK> cluster_dist_list.append( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> np.sum( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> (np.array(centroid_list[i]) - np.array(centroid_list[j])) ** 2 <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return cluster_dist_list",if j != i :,136
"def quote_original(token_type, original):  # 2007 May 01 <TAB> if token_type in [tokenize.STRING]: <MASK> result = force_quote(original, double=True) <TAB>  <TAB> elif SINGLE_QUOTED_STRINGS: <TAB>  <TAB>  <TAB> result = force_quote(original, double=False) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result = original <TAB> else: <TAB>  <TAB> result = original <TAB> return result",if DOUBLE_QUOTED_STRINGS :,117
"def _codegen_impl(self, state: CodegenState) -> None: <TAB> for ll in self.leading_lines: <TAB>  <TAB> ll._codegen(state) <TAB> state.add_indent_tokens() <TAB> end_node = self.body if self.orelse is None else self.orelse <TAB> with state.record_syntactic_position(self, end_node=end_node): <TAB>  <TAB> state.add_token(""while"") <TAB>  <TAB> self.whitespace_after_while._codegen(state) <TAB>  <TAB> self.test._codegen(state) <TAB>  <TAB> self.whitespace_before_colon._codegen(state) <TAB>  <TAB> state.add_token("":"") <TAB>  <TAB> self.body._codegen(state) <TAB>  <TAB> orelse = self.orelse <MASK> orelse._codegen(state)",if orelse is not None :,196
"def set(self, key_chain, value, delete=False): <TAB> self._read() <TAB> c = self._config <TAB> for i, k in enumerate(key_chain): <TAB>  <TAB> if k in c and i + 1 < len(key_chain): <TAB>  <TAB>  <TAB> c = c[k] <TAB>  <TAB> elif k not in c and i + 1 < len(key_chain): <TAB>  <TAB>  <TAB> c[k] = {} <TAB>  <TAB>  <TAB> c = c[k] <TAB>  <TAB> else: <MASK> del c[k] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> c[k] = value <TAB> self._save()",if delete :,154
"def _list_comb_wires_regs(f): <TAB> w, r = set(), set() <TAB> groups = group_by_targets(f.comb) <TAB> for g in groups: <MASK> w |= g[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> r |= g[0] <TAB> return w, r","if len ( g [ 1 ] ) == 1 and isinstance ( g [ 1 ] [ 0 ] , _Assign ) :",100
"def update_arbiter_params(self, arbiter): <TAB> for s in self.cfg.settings.values(): <TAB>  <TAB> if s.is_global and s.modified: <TAB>  <TAB>  <TAB> a = arbiter.cfg.settings[s.name] <MASK> a.set(s.value)",if not a . modified :,84
"def join(self): <TAB> """"""Block until all workers are terminated."""""" <TAB> for w in self._workers: <TAB>  <TAB> if w.isAlive(): <TAB>  <TAB>  <TAB> w.join() <TAB> if self._profiling_enabled: <TAB>  <TAB> # If we have profiling set, collect stats and print them <TAB>  <TAB> stats = None <TAB>  <TAB> for w in self._workers: <MASK> stats.add(w.prof) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> stats = pstats.Stats(w.prof) <TAB>  <TAB> stats.sort_stats(""cumulative"").print_stats()",if stats :,138
"def _generate_examples(self, path, selection): <TAB> """"""Yields examples."""""" <TAB> for filename in tf.io.gfile.glob(os.path.join(path, ""*"", ""*"")): <TAB>  <TAB> label = os.path.split(filename)[-1].split(""_"")[0] <MASK> record = { <TAB>  <TAB>  <TAB>  <TAB> ""image"": filename, <TAB>  <TAB>  <TAB>  <TAB> ""label"": label, <TAB>  <TAB>  <TAB>  <TAB> ""filename"": os.path.basename(filename), <TAB>  <TAB>  <TAB> } <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> record = { <TAB>  <TAB>  <TAB>  <TAB> ""sentinel2"": _extract_channels(filename), <TAB>  <TAB>  <TAB>  <TAB> ""label"": label, <TAB>  <TAB>  <TAB>  <TAB> ""filename"": os.path.basename(filename), <TAB>  <TAB>  <TAB> } <TAB>  <TAB> yield f""{label}_{os.path.basename(filename)}"", record","if selection == ""rgb"" :",195
"def process_ajax_refs(self, info): <TAB> refs = getattr(info, ""form_ajax_refs"", None) <TAB> result = {} <TAB> if refs: <TAB>  <TAB> for name, opts in iteritems(refs): <TAB>  <TAB>  <TAB> new_name = ""%s.%s"" % (info.model.__name__.lower(), name) <TAB>  <TAB>  <TAB> loader = None <MASK> loader = create_ajax_loader(info.model, new_name, name, opts) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> loader = opts <TAB>  <TAB>  <TAB> result[name] = loader <TAB>  <TAB>  <TAB> self.view._form_ajax_refs[new_name] = loader <TAB> return result","if isinstance ( opts , ( list , tuple ) ) :",170
"def _rightClick(self, event, menu=""EDIT""): <TAB> event.widget.focus() <TAB> if menu == ""EDIT"": <MASK> self.widgetManager.get(WIDGET_NAMES.Menu, menu).focus_set() <TAB>  <TAB>  <TAB> self.widgetManager.get(WIDGET_NAMES.Menu, menu).post( <TAB>  <TAB>  <TAB>  <TAB> event.x_root - 10, event.y_root - 10 <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> self.widgetManager.get(WIDGET_NAMES.Menu, menu).focus_set() <TAB>  <TAB> self.widgetManager.get(WIDGET_NAMES.Menu, menu).post( <TAB>  <TAB>  <TAB> event.x_root - 10, event.y_root - 10 <TAB>  <TAB> ) <TAB> return ""break""",if self . _prepareCopyAndPasteMenu ( event ) :,197
"def _get_server(self, key): <TAB> if isinstance(key, tuple): <TAB>  <TAB> serverhash, key = key <TAB> else: <TAB>  <TAB> serverhash = serverHashFunction(key) <TAB> if not self.buckets: <TAB>  <TAB> return None, None <TAB> for i in range(Client._SERVER_RETRIES): <TAB>  <TAB> server = self.buckets[serverhash % len(self.buckets)] <MASK> # print(""(using server %s)"" % server,) <TAB>  <TAB>  <TAB> return server, key <TAB>  <TAB> serverhash = str(serverhash) + str(i) <TAB>  <TAB> if isinstance(serverhash, six.text_type): <TAB>  <TAB>  <TAB> serverhash = serverhash.encode(""ascii"") <TAB>  <TAB> serverhash = serverHashFunction(serverhash) <TAB> return None, None",if server . connect ( ) :,186
def all_prob(self): <TAB> with chainer.force_backprop_mode(): <MASK> return ( <TAB>  <TAB>  <TAB>  <TAB> F.softmax(self.beta * self.logits) * (1 - self.min_prob * self.n) <TAB>  <TAB>  <TAB> ) + self.min_prob <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return F.softmax(self.beta * self.logits),if self . min_prob > 0 :,103
"def get_version_and_doc(filename): <TAB> NS = dict(__version__="""", __doc__="""") <TAB> docStatus = 0  # Not started, in progress, done <TAB> for line in open(filename, ""rb"").read().decode().splitlines(): <TAB>  <TAB> if line.startswith(""__version__""): <TAB>  <TAB>  <TAB> exec(line.strip(), NS, NS) <MASK> if docStatus == 0: <TAB>  <TAB>  <TAB>  <TAB> docStatus = 1 <TAB>  <TAB>  <TAB>  <TAB> line = line.lstrip('""') <TAB>  <TAB>  <TAB> elif docStatus == 1: <TAB>  <TAB>  <TAB>  <TAB> docStatus = 2 <TAB>  <TAB> if docStatus == 1: <TAB>  <TAB>  <TAB> NS[""__doc__""] += line.rstrip() + ""\n"" <TAB> if not NS[""__version__""]: <TAB>  <TAB> raise RuntimeError(""Could not find __version__"") <TAB> return NS[""__version__""], NS[""__doc__""]","elif line . startswith ( '""""""' ) :",198
"def WriteClientSnapshotHistory(self, clients): <TAB> if not clients: <TAB>  <TAB> raise ValueError(""Clients are empty"") <TAB> client_id = None <TAB> for client in clients: <TAB>  <TAB> precondition.AssertType(client, rdf_objects.ClientSnapshot) <TAB>  <TAB> if client.timestamp is None: <TAB>  <TAB>  <TAB> raise AttributeError(""Client without a `timestamp` attribute"") <TAB>  <TAB> client_id = client_id or client.client_id <MASK> message = ""Unexpected client id '%s' instead of '%s'"" <TAB>  <TAB>  <TAB> raise ValueError(message % (client.client_id, client_id)) <TAB> return self.delegate.WriteClientSnapshotHistory(clients)",if client . client_id != client_id :,167
"def __new__(cls, name, bases, attrs): <TAB> super_new = ModelBase.__new__(cls, name, bases, attrs) <TAB> module_name = camel_to_underscore(name) <TAB> app_label = super_new.__module__.split(""."")[-2] <TAB> db_table = ""%s_%s"" % (app_label, module_name) <TAB> django_default = ""%s_%s"" % (app_label, name.lower()) <TAB> if not getattr(super_new._meta, ""proxy"", False): <TAB>  <TAB> db_table_is_default = django_default == super_new._meta.db_table <TAB>  <TAB> # Don't overwrite when people customize the db_table <MASK> super_new._meta.db_table = db_table <TAB> return super_new",if db_table_is_default :,194
"def getp(self): <TAB> if not self.p: <TAB>  <TAB> p = self.validated_ptrs() <TAB>  <TAB> if not p: <TAB>  <TAB>  <TAB> self.p = ""unknown"" <TAB>  <TAB> elif self.d in p: <TAB>  <TAB>  <TAB> self.p = self.d <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sfx = ""."" + self.d <TAB>  <TAB>  <TAB> for d in p: <MASK> self.p = d <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.p = p[0] <TAB> return self.p",if d . endswith ( sfx ) :,147
"def get_reverse_fields(model, local_field_names): <TAB> for name, attr in model.__dict__.items(): <TAB>  <TAB> # Don't duplicate any local fields <TAB>  <TAB> if name in local_field_names: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # ""rel"" for FK and M2M relations and ""related"" for O2O Relations <TAB>  <TAB> related = getattr(attr, ""rel"", None) or getattr(attr, ""related"", None) <TAB>  <TAB> if isinstance(related, models.ManyToOneRel): <TAB>  <TAB>  <TAB> yield (name, related) <MASK> yield (name, related)","elif isinstance ( related , models . ManyToManyRel ) and not related . symmetrical :",160
"def _convert_keywords(self, item): <TAB> for kw in getattr(item, ""keywords"", []): <TAB>  <TAB> if kw.type == ""setup"": <TAB>  <TAB>  <TAB> yield self._convert_keyword(kw, ""SETUP"") <MASK> yield self._convert_keyword(kw, ""TEARDOWN"") <TAB>  <TAB> elif kw.is_for_loop(): <TAB>  <TAB>  <TAB> yield self._convert_for_loop(kw) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield self._convert_keyword(kw, ""KEYWORD"")","elif kw . type == ""teardown"" :",128
"def _validate_hooks(self): <TAB> if self.config.validate_hooks: <TAB>  <TAB> for name in (""auth-hook"", ""cleanup-hook""): <TAB>  <TAB>  <TAB> hook = self.conf(name) <MASK> hook_prefix = self.option_name(name)[: -len(""-hook"")] <TAB>  <TAB>  <TAB>  <TAB> hooks.validate_hook(hook, hook_prefix)",if hook is not None :,97
"def handle_request_sampled_history(self, record): <TAB> result = wandb_internal_pb2.Result(uuid=record.uuid) <TAB> for key, sampled in six.iteritems(self._sampled_history): <TAB>  <TAB> item = wandb_internal_pb2.SampledHistoryItem() <TAB>  <TAB> item.key = key <TAB>  <TAB> values = sampled.get() <MASK> item.values_int.extend(values) <TAB>  <TAB> elif all(isinstance(i, numbers.Real) for i in values): <TAB>  <TAB>  <TAB> item.values_float.extend(values) <TAB>  <TAB> result.response.sampled_history_response.item.append(item) <TAB> self._result_q.put(result)","if all ( isinstance ( i , numbers . Integral ) for i in values ) :",184
"def _get_firmware_uid(self, request_data): <TAB> if ""uid"" not in request_data: <TAB>  <TAB> return None <TAB> with ConnectTo(FrontEndDbInterface, self.config) as db_interface: <MASK> raise RestBinarySearchException( <TAB>  <TAB>  <TAB>  <TAB> ""Firmware with UID {uid} not found in database"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> uid=request_data[""uid""] <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> return request_data[""uid""]","if not db_interface . is_firmware ( request_data [ ""uid"" ] ) :",134
"def _on_file_changed(self): <TAB> LOG.debug(""%r: file changed, reloading"", self) <TAB> for key, value in self._load(): <MASK> LOG.debug( <TAB>  <TAB>  <TAB>  <TAB> ""%r: existing key %r=%r exists, not setting %r"", <TAB>  <TAB>  <TAB>  <TAB> self, <TAB>  <TAB>  <TAB>  <TAB> key, <TAB>  <TAB>  <TAB>  <TAB> self.environ[key], <TAB>  <TAB>  <TAB>  <TAB> value, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> LOG.debug(""%r: setting key %r to %r"", self, key, value) <TAB>  <TAB>  <TAB> self._keys.append(key) <TAB>  <TAB>  <TAB> self.environ[key] = value",if key in self . environ :,166
"def work(self): <TAB> while self.active: <TAB>  <TAB> stat = os.stat(self.filename) <MASK> self.callback(self.last_stat, stat)  # notify the client of the change <TAB>  <TAB> self.last_stat = stat <TAB>  <TAB> time.sleep(self.interval) <TAB> print(""client closed."")",if self . last_stat is not None and self . last_stat != stat :,99
"def pack(string): <TAB> if string is not None: <MASK> string = string.encode(""utf-8"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # we do not want this test to happen with python3 <TAB>  <TAB>  <TAB> if isinstance(string, unicode): <TAB>  <TAB>  <TAB>  <TAB> string = string.encode(""utf-8"") <TAB> return _Bytes.pack(string)",if sys . version_info . major > 2 :,99
"def display(self): <TAB> state = self._state[0] <TAB> s = """" <TAB> for row in range(3): <TAB>  <TAB> for col in range(3): <MASK> s += ""_"" <TAB>  <TAB>  <TAB> if np.all(state[row][col] == TicTacToeEnvironment.X): <TAB>  <TAB>  <TAB>  <TAB> s += ""X"" <TAB>  <TAB>  <TAB> if np.all(state[row][col] == TicTacToeEnvironment.O): <TAB>  <TAB>  <TAB>  <TAB> s += ""O"" <TAB>  <TAB> s += ""\n"" <TAB> return s",if np . all ( state [ row ] [ col ] == TicTacToeEnvironment . EMPTY ) :,158
"def make_path(self, path=[], cfg={}): <TAB> if cfg.get(""version_only_path""): <TAB>  <TAB> return ""/"" + self.storage_url.split(""/"")[1] <TAB> if path: <TAB>  <TAB> quote = urllib.quote <MASK> quote = lambda x: x <TAB>  <TAB> return ""%s/%s"" % (self.storage_url, ""/"".join([quote(i) for i in path])) <TAB> else: <TAB>  <TAB> return self.storage_url","if cfg . get ( ""no_quote"" ) or cfg . get ( ""no_path_quote"" ) :",129
"def get_rules_list(self): <TAB> from mathics.core.rules import Rule <TAB> list_expr = self.flatten(Symbol(""List"")) <TAB> list = [] <TAB> if list_expr.has_form(""List"", None): <TAB>  <TAB> list.extend(list_expr.leaves) <TAB> else: <TAB>  <TAB> list.append(list_expr) <TAB> rules = [] <TAB> for item in list: <MASK> return None <TAB>  <TAB> rule = Rule(item.leaves[0], item.leaves[1]) <TAB>  <TAB> rules.append(rule) <TAB> return rules","if not item . has_form ( ( ""Rule"" , ""RuleDelayed"" ) , 2 ) :",150
"def __setitem__(self, name, value): <TAB> if name.lower() in self.keys: <MASK> value = value.encode(""latin1"", ""ignore"") <TAB>  <TAB> elif value is None: <TAB>  <TAB>  <TAB> value = """" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = str(value) <TAB>  <TAB> self.texts[self.pg_no][name.lower()] = value","if not PY3K and isinstance ( value , unicode ) :",103
"def undo(self): <TAB> if len(self.undoStack) == 0: <TAB>  <TAB> return <TAB> with mceutils.setWindowCaption(""UNDOING - ""): <TAB>  <TAB> self.freezeStatus(""Undoing the previous operation..."") <TAB>  <TAB> op = self.undoStack.pop() <TAB>  <TAB> op.undo() <TAB>  <TAB> changedBox = op.dirtyBox() <MASK> self.invalidateBox(changedBox) <TAB>  <TAB> if op.changedLevel: <TAB>  <TAB>  <TAB> self.addUnsavedEdit()",if changedBox is not None :,126
"def __init__(self, metrics, summary_writer=None): <TAB> """"""doc"""""" <TAB> self.writer = summary_writer <TAB> self._result = None <TAB> if not isinstance(metrics, dict): <TAB>  <TAB> raise ValueError(""metrics should be dict, got %s"" % repr(metrics)) <TAB> for k, m in six.iteritems(metrics): <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""metrics %s should be instance of propeller.Metrics, got %s"" <TAB>  <TAB>  <TAB>  <TAB> % (k, repr(m)) <TAB>  <TAB>  <TAB> ) <TAB> if len(metrics): <TAB>  <TAB> self.names = list(metrics.keys()) <TAB>  <TAB> self.metrics = list(metrics.values()) <TAB> else: <TAB>  <TAB> self.names, self.metrics = [], []","if not isinstance ( m , Metrics ) :",190
"def vertices(self, data): <TAB> if data is None: <TAB>  <TAB> self._data[""vertices""] = None <TAB> else: <TAB>  <TAB> # we want to copy data for new object <TAB>  <TAB> data = np.array(data, dtype=np.float64, copy=True) <MASK> raise ValueError(""Point clouds must be (n, 3)!"") <TAB>  <TAB> self._data[""vertices""] = data","if not util . is_shape ( data , ( - 1 , 3 ) ) :",110
"def add(self, doc, parent, tag, value=None): <TAB> el = doc.createElement(tag) <TAB> if value: <TAB>  <TAB> if type(value) == type(str()): <TAB>  <TAB>  <TAB> el.appendChild(doc.createTextNode(value)) <MASK> self.setAttributes(el, value) <TAB> parent.appendChild(el) <TAB> return el",elif type ( value ) == type ( dict ( ) ) :,98
"def cached_strategy(*args, **kwargs): <TAB> try: <TAB>  <TAB> kwargs_cache_key = {(k, convert_value(v)) for k, v in kwargs.items()} <TAB> except TypeError: <TAB>  <TAB> return fn(*args, **kwargs) <TAB> cache_key = (fn, tuple(map(convert_value, args)), frozenset(kwargs_cache_key)) <TAB> cache = get_cache() <TAB> try: <TAB>  <TAB> if cache_key in cache: <TAB>  <TAB>  <TAB> return cache[cache_key] <TAB> except TypeError: <TAB>  <TAB> return fn(*args, **kwargs) <TAB> else: <TAB>  <TAB> result = fn(*args, **kwargs) <MASK> cache[cache_key] = result <TAB>  <TAB> return result","if not isinstance ( result , SearchStrategy ) or result . is_cacheable :",188
"def get_udf_temp_dir(): <TAB> tmp_base_path = os.path.join(tempfile.gettempdir(), ""xlwingsudfs"") <TAB> os.makedirs(tmp_base_path, exist_ok=True) <TAB> try: <TAB>  <TAB> # HACK: Clean up directories that are older than 30 days <TAB>  <TAB> # This should be done in the C++ part when the Python process is killed from there <TAB>  <TAB> for subdir in glob.glob(tmp_base_path + ""/*/""): <MASK> shutil.rmtree(subdir, ignore_errors=True) <TAB> except Exception: <TAB>  <TAB> pass  # we don't care if it fails <TAB> tempdir = tempfile.TemporaryDirectory(dir=tmp_base_path) <TAB> return tempdir",if os . path . getmtime ( subdir ) < time . time ( ) - 30 * 86400 :,189
"def describe_key(self, kms, key_id, **kwargs): <TAB> try: <TAB>  <TAB> response = self.wrap_aws_rate_limited_call(kms.describe_key, KeyId=key_id) <TAB> except ClientError as e: <MASK> raise <TAB>  <TAB> arn = ARN_PREFIX + "":kms:{}:{}:key/{}"".format( <TAB>  <TAB>  <TAB> kwargs[""region""], kwargs[""account_name""], key_id <TAB>  <TAB> ) <TAB>  <TAB> return { <TAB>  <TAB>  <TAB> ""Error"": ""Unauthorized"", <TAB>  <TAB>  <TAB> ""Arn"": arn, <TAB>  <TAB>  <TAB> ""AWSAccountId"": kwargs[""account_name""], <TAB>  <TAB>  <TAB> ""Policies"": [], <TAB>  <TAB>  <TAB> ""Grants"": [], <TAB>  <TAB> } <TAB> return response.get(""KeyMetadata"")","if e . response . get ( ""Error"" , { } ) . get ( ""Code"" ) != ""AccessDeniedException"" :",197
def __reversed__(self): <TAB> root = self.root <TAB> curr = root[PREV] <TAB> while curr is not root: <MASK> curr = curr[SPREV] <TAB>  <TAB>  <TAB> if curr is root: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> yield curr[KEY] <TAB>  <TAB> curr = curr[PREV],if curr [ SPREV ] [ SNEXT ] is not curr :,93
"def main(): <TAB> import sys <TAB> import getopt <TAB> try: <TAB>  <TAB> opts, args = getopt.getopt(sys.argv[1:], ""ho:"", [""help"", ""output=""]) <TAB> except getopt.GetoptError as err: <TAB>  <TAB> usage() <TAB>  <TAB> sys.exit(1) <TAB> output = None <TAB> for o, a in opts: <MASK> usage() <TAB>  <TAB>  <TAB> sys.exit() <TAB>  <TAB> elif o in (""-o"", ""--output""): <TAB>  <TAB>  <TAB> output = a <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> usage() <TAB>  <TAB>  <TAB> sys.exit(1) <TAB> if not args: <TAB>  <TAB> usage() <TAB>  <TAB> sys.exit(1) <TAB> concat_flv(args, output)","if o in ( ""-h"" , ""--help"" ) :",177
"def po_required(self): <TAB> if frappe.db.get_value(""Buying Settings"", None, ""po_required"") == ""Yes"": <TAB>  <TAB> for d in self.get(""items""): <MASK> frappe.throw( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _(""Purchase Order number required for Item {0}"").format(d.item_code) <TAB>  <TAB>  <TAB>  <TAB> )",if not d . purchase_order :,101
"def has_variant_regions(items, base_file, chrom=None): <TAB> """"""Determine if we should process this chromosome: needs variant regions defined."""""" <TAB> if chrom: <TAB>  <TAB> all_vrs = _get_variant_regions(items) <MASK> test = shared.subset_variant_regions( <TAB>  <TAB>  <TAB>  <TAB> tz.first(all_vrs), chrom, base_file, items <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> if test == chrom: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return True",if len ( all_vrs ) > 0 :,137
"def __updatePath(self): <TAB> d = self.__pathListing.getPath().dict() <TAB> d.clear() <TAB> if self.__plug is not None: <TAB>  <TAB> for name in Gaffer.Metadata.registeredValues( <TAB>  <TAB>  <TAB> self.__plug, instanceOnly=True, persistentOnly=True <TAB>  <TAB> ): <MASK> d[name[7:]] = Gaffer.Metadata.value(self.__plug, name) <TAB> self.__pathListing.getPath().pathChangedSignal()(self.__pathListing.getPath())","if name . startswith ( ""preset:"" ) :",134
"def get_pid_strings(self, pid): <TAB> try: <TAB>  <TAB> mw = memorpy.MemWorker(pid=pid) <TAB>  <TAB> matcher = self.policy or self.printable <TAB>  <TAB> for _, (cstring,) in mw.mem_search( <TAB>  <TAB>  <TAB> ""([\x20-\x7e]+)\x00"", ftype=""groups"", optimizations=""ixrs"" <TAB>  <TAB> ): <MASK> if cstring not in self.duplicates: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield cstring <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if len(self.duplicates) > self.maxdups: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.duplicates = set() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.duplicates.add(cstring) <TAB> except: <TAB>  <TAB> pass",if matcher . match ( cstring ) :,179
"def _get_debug_parent_dir(cls): <TAB> if cls._DEBUG_PARENT_DIR is None: <TAB>  <TAB> all_parents = f""{tempfile.gettempdir()}/tvm-debug-mode-tempdirs"" <MASK> os.makedirs(all_parents) <TAB>  <TAB> cls._DEBUG_PARENT_DIR = tempfile.mkdtemp( <TAB>  <TAB>  <TAB> prefix=datetime.datetime.now().strftime(""%Y-%m-%dT%H-%M-%S___""), <TAB>  <TAB>  <TAB> dir=all_parents, <TAB>  <TAB> ) <TAB> return cls._DEBUG_PARENT_DIR",if not os . path . isdir ( all_parents ) :,146
"def _range_values(self, value, start, end): <TAB> start = int(start) <TAB> end = int(end) <TAB> if value is not None: <MASK> start = len(value) + start <TAB>  <TAB> if end < 0: <TAB>  <TAB>  <TAB> end = len(value) + end + 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> end += 1 <TAB> return start, end",if start < 0 :,99
"def warningregistry(func): <TAB> def wrapper(*args, **kws): <TAB>  <TAB> missing = object() <TAB>  <TAB> saved = getattr(warnings, ""__warningregistry__"", missing).copy() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return func(*args, **kws) <TAB>  <TAB> finally: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> del warnings.__warningregistry__ <TAB>  <TAB>  <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> warnings.__warningregistry__ = saved",if saved is missing :,121
"def info_for(view): <TAB> if isinstance(view, sublime.Window): <TAB>  <TAB> window = view <TAB> else: <TAB>  <TAB> window = view.window() <TAB> if window: <TAB>  <TAB> info = isearch_info.get(window.id(), None) <MASK> info.finish(abort=False, input_panel_hack=True) <TAB>  <TAB>  <TAB> info = None <TAB>  <TAB> return info <TAB> return None",if info is not None and not info . is_valid ( ) :,115
"def get_matches(self, video): <TAB> matches = set() <TAB> if isinstance(video, Movie): <TAB>  <TAB> # title <MASK> matches.add(""title"") <TAB>  <TAB> if video.year and self.year == video.year: <TAB>  <TAB>  <TAB> matches.add(""year"") <TAB>  <TAB> if video.imdb_id and self.imdb_id == video.imdb_id: <TAB>  <TAB>  <TAB> matches.add(""imdb_id"") <TAB>  <TAB> if video.release_group and video.release_group in self.comments: <TAB>  <TAB>  <TAB> matches.add(""release_group"") <TAB>  <TAB> if video.resolution and video.resolution.lower() in self.comments: <TAB>  <TAB>  <TAB> matches.add(""resolution"") <TAB> self.matches = matches <TAB> return matches",if video . title and sanitize ( self . title ) == fix_inconsistent_naming ( video . title ) :,197
def notifyPackageBuildCompleted(package): <TAB> with Scheduler.lock: <TAB>  <TAB> if package in Scheduler.listOfPackagesCurrentlyBuilding: <TAB>  <TAB>  <TAB> Scheduler.listOfPackagesCurrentlyBuilding.remove(package) <TAB>  <TAB>  <TAB> Scheduler.listOfAlreadyBuiltPackages.add(package) <MASK> Scheduler._markPkgNodeAsBuilt(package),if not constants . rpmCheck :,94
"def _compare_group(cls, stats1, stats2): <TAB> attr_list = [""type"", ""group_id"", ""buckets""] <TAB> for attr in attr_list: <TAB>  <TAB> value1 = getattr(stats1, attr) <TAB>  <TAB> value2 = getattr(stats2, attr) <MASK> return False, ""group_stats(%s != %s)"" % (value1, value2) <TAB>  <TAB> return True, None",if str ( value1 ) != str ( value2 ) :,114
"def _force_run(path, func, *args): <TAB> try: <TAB>  <TAB> return func(*args) <TAB> except OSError as err: <MASK> print(""%s: %s"" % (err.__class__.__name__, err)) <TAB>  <TAB>  <TAB> print(""re-run %s%r"" % (func.__name__, args)) <TAB>  <TAB> os.chmod(path, stat.S_IRWXU) <TAB>  <TAB> return func(*args)",if verbose >= 2 :,107
"def SortCmp(x, y): <TAB> """"""The comparison function for sort keys."""""" <TAB> for i, val_tuple in enumerate(zip(x, y)): <TAB>  <TAB> cmp_val = cmp(*val_tuple) <TAB>  <TAB> if cmp_val: <MASK> return -cmp_val <TAB>  <TAB>  <TAB> return cmp_val <TAB> return 0",if search_params . sort_spec ( i ) . sort_descending ( ) :,98
"def get_serializer_class(self): <TAB> if ""identifier_id"" in self.kwargs: <TAB>  <TAB> referent = self.get_object().referent <TAB>  <TAB> if isinstance(referent, Node): <TAB>  <TAB>  <TAB> return NodeIdentifierSerializer <MASK> return RegistrationIdentifierSerializer <TAB>  <TAB> if isinstance(referent, Preprint): <TAB>  <TAB>  <TAB> return PreprintIdentifierSerializer <TAB> return JSONAPISerializer","if isinstance ( referent , Registration ) :",106
"def _syncthing_cb_folder_data(self, data, rid): <TAB> state = data[""state""] <TAB> if state in (""error"", ""stopped""): <TAB>  <TAB> if not rid in self._stopped_folders: <TAB>  <TAB>  <TAB> self._stopped_folders.add(rid) <TAB>  <TAB>  <TAB> reason = data[""invalid""] or data[""error""] <TAB>  <TAB>  <TAB> self.emit(""folder-stopped"", rid, reason) <TAB> self.emit(""folder-data-changed"", rid, data) <TAB> p = 0.0 <TAB> if state == ""syncing"": <MASK> p = float(data[""inSyncBytes""]) / float(data[""globalBytes""]) <TAB> self._folder_state_changed(rid, state, p)","if float ( data [ ""globalBytes"" ] ) > 0.0 :",182
"def get_task_extra(self, task): <TAB> result = dict( <TAB>  <TAB> encryption="""", server_side_encryption=task[""attributes""].get(""encryption"") or """" <TAB> ) <TAB> if not task[""credentials""][""attributes""].get(""skip_region"", False): <TAB>  <TAB> if not task[""credentials""][""attributes""].get(""region"", """").strip(): <TAB>  <TAB>  <TAB> # Some legacy tasks have region=None, it's easier to fix it here than in migration <TAB>  <TAB>  <TAB> result[""region""] = task[""attributes""].get(""region"") or ""us-east-1"" <TAB> else: <MASK> result[""region""] = ""other-v2-signature"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result[""region""] = """" <TAB> return result","if task [ ""credentials"" ] [ ""attributes"" ] . get ( ""signatures_v2"" , False ) :",185
"def edges_eq(): <TAB> for edge in self.edges(): <TAB>  <TAB> if self.edge_weight(edge) != other.edge_weight(edge): <TAB>  <TAB>  <TAB> return False <MASK> return False <TAB>  <TAB> if not attrs_eq(self.edge_attributes(edge), other.edge_attributes(edge)): <TAB>  <TAB>  <TAB> return False <TAB> return True",if self . edge_label ( edge ) != other . edge_label ( edge ) :,104
"def fromlist(cls, data, fields): <TAB> ex = cls() <TAB> for (name, field), val in zip(fields, data): <MASK> if isinstance(val, str): <TAB>  <TAB>  <TAB>  <TAB> val = val.rstrip(""\n"") <TAB>  <TAB>  <TAB> # Handle field tuples <TAB>  <TAB>  <TAB> if isinstance(name, tuple): <TAB>  <TAB>  <TAB>  <TAB> for n, f in zip(name, field): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> setattr(ex, n, f.preprocess(val)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> setattr(ex, name, field.preprocess(val)) <TAB> return ex",if field is not None :,145
"def validate_external_account_field_data( <TAB> field_data: ProfileFieldData,) -> ProfileFieldData: <TAB> field_validator = check_dict_only( <TAB>  <TAB> [(""subtype"", check_required_string)], <TAB>  <TAB> [(""url_pattern"", check_external_account_url_pattern)], <TAB> ) <TAB> field_validator(""field_data"", field_data) <TAB> field_subtype = field_data.get(""subtype"") <TAB> if field_subtype not in DEFAULT_EXTERNAL_ACCOUNTS.keys(): <TAB>  <TAB> if field_subtype == ""custom"": <MASK> raise ValidationError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _(""Custom external account must define URL pattern"") <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValidationError(_(""Invalid external account type"")) <TAB> return field_data","if ""url_pattern"" not in field_data . keys ( ) :",199
"def set_status(self, status=None): <TAB> if status: <TAB>  <TAB> self.status = status <TAB>  <TAB> self.db_set(""status"", status) <TAB>  <TAB> for d in self.invoices: <TAB>  <TAB>  <TAB> frappe.get_doc(""Sales Invoice"", d.sales_invoice).set_status( <TAB>  <TAB>  <TAB>  <TAB> update=True, update_modified=False <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> self.status = ""Draft"" <TAB>  <TAB> if self.docstatus == 1: <TAB>  <TAB>  <TAB> self.status = ""Sanctioned"" <MASK> self.status = ""Cancelled""",elif self . docstatus == 2 :,156
"def update_search(self): <TAB> from website import search <TAB> try: <TAB>  <TAB> search.search.update_node(self, bulk=False, async_update=True) <MASK> search.search.update_collected_metadata(self._id) <TAB> except search.exceptions.SearchUnavailableError as e: <TAB>  <TAB> logger.exception(e) <TAB>  <TAB> log_exception()",if self . is_collected and self . is_public :,104
"def test_who_am_i_extension(self): <TAB> if not test_server_type == ""EDIR"" and not self.connection.strategy.no_real_dsa: <TAB>  <TAB> result = self.connection.extended(""1.3.6.1.4.1.4203.1.11.3"") <MASK> _, result = self.connection.get_response(result) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result = self.connection.result <TAB>  <TAB> self.assertEqual(result[""description""], ""success"")",if not self . connection . strategy . sync :,133
"def backup_file(filename, backups=5, min_age_delta=0): <TAB> if os.path.exists(filename): <TAB>  <TAB> if os.stat(filename).st_mtime >= time.time() - min_age_delta: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> for ver in reversed(range(1, backups)): <TAB>  <TAB>  <TAB> bf = ""%s.%d"" % (filename, ver) <TAB>  <TAB>  <TAB> if os.path.exists(bf): <TAB>  <TAB>  <TAB>  <TAB> nbf = ""%s.%d"" % (filename, ver + 1) <MASK> os.remove(nbf) <TAB>  <TAB>  <TAB>  <TAB> os.rename(bf, nbf) <TAB>  <TAB> os.rename(filename, ""%s.1"" % filename)",if os . path . exists ( nbf ) :,185
"def validate_instance(params): <TAB> if platform.system() == ""Linux"": <TAB>  <TAB> distribution = awscli.compat.linux_distribution()[0] <TAB>  <TAB> if ""Ubuntu"" in distribution: <TAB>  <TAB>  <TAB> params.system = Ubuntu(params) <MASK> params.system = RHEL(params) <TAB> elif platform.system() == ""Windows"": <TAB>  <TAB> params.system = Windows(params) <TAB> if ""system"" not in params: <TAB>  <TAB> raise RuntimeError(System.UNSUPPORTED_SYSTEM_MSG) <TAB> try: <TAB>  <TAB> urlopen(""http://169.254.169.254/latest/meta-data/"", timeout=1) <TAB>  <TAB> raise RuntimeError(""Amazon EC2 instances are not supported."") <TAB> except (URLError, timeout): <TAB>  <TAB> pass","if ""Red Hat Enterprise Linux Server"" in distribution :",186
"def _to_dataframe(self, rs): <TAB> result = {} <TAB> if isinstance(rs, list): <TAB>  <TAB> return map(self._to_dataframe, rs) <TAB> for key, data in rs.items(): <TAB>  <TAB> name, tags = key <MASK> key = name <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> key = (name, tuple(sorted(tags.items()))) <TAB>  <TAB> df = pd.DataFrame(data) <TAB>  <TAB> df.time = pd.to_datetime(df.time) <TAB>  <TAB> df.set_index(""time"", inplace=True) <TAB>  <TAB> df.index = df.index.tz_localize(""UTC"") <TAB>  <TAB> df.index.name = None <TAB>  <TAB> result[key] = df <TAB> return result",if tags is None :,178
"def on_btn_save_rx_clicked(self): <TAB> rx_device = self.simulator.sniffer.rcv_device <TAB> if isinstance(rx_device.data, np.ndarray) or isinstance(rx_device.data, IQArray): <TAB>  <TAB> data = IQArray(rx_device.data[: rx_device.current_index]) <TAB>  <TAB> filename = FileOperator.ask_signal_file_name_and_save( <TAB>  <TAB>  <TAB> ""simulation_capture"", data, sample_rate=rx_device.sample_rate, parent=self <TAB>  <TAB> ) <MASK> data.tofile(filename) <TAB>  <TAB>  <TAB> self.rx_file_saved.emit(filename)",if filename :,168
"def set_custom_options(self, flags_with_values, binary_flags): <TAB> """"""Merge self.custom_options into flags_with_values and binary_flags."""""" <TAB> for dest, value in self.custom_options: <TAB>  <TAB> arg_info = config.get_pytype_single_item(dest).arg_info <MASK> value = arg_info.to_command_line(value) <TAB>  <TAB> if isinstance(value, bool): <TAB>  <TAB>  <TAB> if value: <TAB>  <TAB>  <TAB>  <TAB> binary_flags.add(arg_info.flag) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> binary_flags.discard(arg_info.flag) <TAB>  <TAB> elif value: <TAB>  <TAB>  <TAB> flags_with_values[arg_info.flag] = str(value)",if arg_info . to_command_line :,192
"def _re_init_capture_by_names(self, names): <TAB> # burn-in test specific. Do not change text! <TAB> self.devices.update() <TAB> for d in self.devices: <TAB>  <TAB> for name in names: <TAB>  <TAB>  <TAB> if d[""name""] == name: <TAB>  <TAB>  <TAB>  <TAB> logger.info(""Found device. {}."".format(name)) <MASK> self._re_init_capture(d[""uid""]) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._init_capture(d[""uid""]) <TAB>  <TAB>  <TAB>  <TAB> return <TAB> raise InitialisationError( <TAB>  <TAB> ""Could not find Camera {} during re initilization."".format(names) <TAB> )",if self . uvc_capture :,173
"def __init__(self, use_cuda_events=True): <TAB> self._host_stats: Mapping[str, PerfMetric] = defaultdict(PerfMetric) <TAB> self._cuda_stats: Mapping[str, PerfMetric] = defaultdict(PerfMetric) <TAB> if use_cuda_events: <MASK> self._cuda_pending_timers = deque(maxlen=PerfStats.MAX_PENDING_TIMERS) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logging.warning(""CUDA unavailable: CUDA events are not logged."") <TAB>  <TAB>  <TAB> self._cuda_pending_timers = None <TAB> else: <TAB>  <TAB> self._cuda_pending_timers = None",if torch . cuda . is_available ( ) :,164
"def find_test_filenames(directory): <TAB> filenames = {} <TAB> for filename in os.listdir(directory): <TAB>  <TAB> if os.path.isfile(os.path.join(directory, filename)): <TAB>  <TAB>  <TAB> base, ext = os.path.splitext(filename) <TAB>  <TAB>  <TAB> if base.endswith(""-py3""): <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB>  <TAB> filenames.setdefault(base, []).append(ext) <TAB> filenames = filenames.items() <TAB> filenames.sort() <TAB> return filenames","if not has_ucs4 and base . find ( ""-ucs4-"" ) > - 1 :",143
"def allprocs(self): <TAB> p = self.addr_space.profile.get_symbol(""_allproc"") <TAB> procsaddr = obj.Object(""proclist"", offset=p, vm=self.addr_space) <TAB> proc = obj.Object(""proc"", offset=procsaddr.lh_first, vm=self.addr_space) <TAB> seen = [] <TAB> while proc.is_valid(): <MASK> debug.warning( <TAB>  <TAB>  <TAB>  <TAB> ""Recursive process list detected (a result of non-atomic acquisition). Use mac_tasks or mac_psxview)"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> seen.append(proc.obj_offset) <TAB>  <TAB> yield proc <TAB>  <TAB> proc = proc.p_list.le_next.dereference()",if proc . obj_offset in seen :,194
def partition(blamed_lines): <TAB> prev_line = None <TAB> current_hunk = [] <TAB> for line in blamed_lines: <MASK> yield current_hunk <TAB>  <TAB>  <TAB> current_hunk = [] <TAB>  <TAB> prev_line = line <TAB>  <TAB> current_hunk.append(line) <TAB> yield current_hunk,if prev_line and line . commit_hash != prev_line . commit_hash :,104
"def get_bases_abstract_fields(self, c): <TAB> _abstract_fields = [] <TAB> for e in c.__bases__: <MASK> _abstract_fields.extend(e._meta.fields) <TAB>  <TAB>  <TAB> _abstract_fields.extend(self.get_bases_abstract_fields(e)) <TAB> return _abstract_fields","if hasattr ( e , ""_meta"" ) and e . _meta . abstract :",96
"def step(self, actions): <TAB> """"""Step."""""" <TAB> self._elapsed_steps += 1 <TAB> obs, rewards, dones = [np.array(r) for r in self.batch_env.step(actions)] <TAB> if self._elapsed_steps > self._max_episode_steps: <TAB>  <TAB> done = True <MASK> rewards.fill(0) <TAB> else: <TAB>  <TAB> done = dones[0] <TAB>  <TAB> assert np.all(done == dones), ( <TAB>  <TAB>  <TAB> ""Current modifications of Dopamine "" <TAB>  <TAB>  <TAB> ""require same number of steps for each "" <TAB>  <TAB>  <TAB> ""environment in batch"" <TAB>  <TAB> ) <TAB>  <TAB> del dones <TAB> self.game_over = done <TAB> return obs, rewards, done, {}",if self . _elapsed_steps > self . _max_episode_steps + 1 :,197
"def _delete_domain(self, domain): <TAB> for attempt in retry_sdb(): <TAB>  <TAB> with attempt: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> domain.delete() <TAB>  <TAB>  <TAB> except SDBResponseError as e: <MASK> pass <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise",if no_such_sdb_domain ( e ) :,91
"def _parse_column_changes(changes): <TAB> rv = {} <TAB> for change in changes: <TAB>  <TAB> if change[0] == ""modify_type"": <TAB>  <TAB>  <TAB> rv[""type""] = [change[4], change[5], change[3][""existing_length""]] <MASK> rv[""length""] = [change[4], change[5], change[3][""existing_type""]] <TAB>  <TAB> elif change[0] == ""modify_notnull"": <TAB>  <TAB>  <TAB> rv[""notnull""] = [change[4], change[5]] <TAB>  <TAB> elif change[0] == ""modify_default"": <TAB>  <TAB>  <TAB> rv[""default""] = [change[4], change[5], change[3][""existing_type""]] <TAB> return rv","elif change [ 0 ] == ""modify_length"" :",181
"def mapModel(self): <TAB> self.beginResetModel() <TAB> src = self.sourceModel() <TAB> self._map = [] <TAB> for i, cat in enumerate(self._cats): <TAB>  <TAB> self._map.append(cat) <TAB>  <TAB> for p in range(src.rowCount()): <TAB>  <TAB>  <TAB> item = src.item(p, Perso.importance.value) <TAB>  <TAB>  <TAB> if item and item.text(): <TAB>  <TAB>  <TAB>  <TAB> imp = int(item.text()) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> imp = 0 <MASK> self._map.append(p) <TAB> self.endResetModel()",if 2 - imp == i :,157
"def class_prepared_mongodb_signal(sender, *args, **kwargs): <TAB> mongo_meta = getattr(sender, ""MongoMeta"", None) <TAB> if mongo_meta is not None: <TAB>  <TAB> for attr in dir(mongo_meta): <MASK> if attr == ""index_together"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> attr_name = ""mongo_index_together"" <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> attr_name = attr <TAB>  <TAB>  <TAB>  <TAB> setattr(sender._meta, attr_name, getattr(mongo_meta, attr))","if not attr . startswith ( ""_"" ) :",140
"def bad_function(exit_how=""break""): <TAB> with loops.Scope() as s: <TAB>  <TAB> for i in s.range(555): <TAB>  <TAB>  <TAB> if exit_how == ""break"": <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> elif exit_how == ""return"": <TAB>  <TAB>  <TAB>  <TAB> return 1.0 <MASK> raise ValueError(""test exception"") <TAB>  <TAB> # Start another range, we get here after a ""break"" above <TAB>  <TAB> for i in s.range(5): <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> return 0.0","elif exit_how == ""exception"" :",137
"def __checks_1(self, token): <TAB> for prefix in self.__checks1: <MASK> if prefix in self.__articles_3len and len(token) > 4: <TAB>  <TAB>  <TAB>  <TAB> self.is_noun = True <TAB>  <TAB>  <TAB>  <TAB> self.is_verb = False <TAB>  <TAB>  <TAB>  <TAB> self.is_defined = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> if prefix in self.__articles_2len and len(token) > 3: <TAB>  <TAB>  <TAB>  <TAB> self.is_noun = True <TAB>  <TAB>  <TAB>  <TAB> self.is_verb = False <TAB>  <TAB>  <TAB>  <TAB> self.is_defined = True <TAB>  <TAB>  <TAB>  <TAB> break",if token . startswith ( prefix ) :,157
"def get_root_dir(): <TAB> """"""Find root directory of nikola site by looking for conf.py."""""" <TAB> root = os.getcwd() <TAB> if sys.version_info[0] == 2: <TAB>  <TAB> confname = b""conf.py"" <TAB> else: <TAB>  <TAB> confname = ""conf.py"" <TAB> while True: <MASK> return root <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> basedir = os.path.split(root)[0] <TAB>  <TAB>  <TAB> # Top directory, already checked <TAB>  <TAB>  <TAB> if basedir == root: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> root = basedir <TAB> return None","if os . path . exists ( os . path . join ( root , confname ) ) :",165
"def stringify(self, token_indices): <TAB> # Used in metric reporter to convert from tokens to string <TAB> res = """" <TAB> if hasattr(self, ""vocab""): <TAB>  <TAB> res = "" "".join([self.vocab._vocab[index] for index in token_indices]) <MASK> if hasattr(self.tokenizer, ""decode""): <TAB>  <TAB>  <TAB>  <TAB> res = self.tokenizer.decode(res) <TAB> return res","if hasattr ( self , ""tokenizer"" ) :",106
"def before_write_items(self, items, nulls_map=None): <TAB> null_value = self.null_value <TAB> date_lut_reverse = self.date_lut_reverse <TAB> epoch_start = self.epoch_start <TAB> epoch_end = self.epoch_end <TAB> for i, item in enumerate(items): <MASK> items[i] = null_value <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if type(item) != date: <TAB>  <TAB>  <TAB> item = date(item.year, item.month, item.day) <TAB>  <TAB> if item > epoch_end or item < epoch_start: <TAB>  <TAB>  <TAB> items[i] = 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> items[i] = date_lut_reverse[item]",if nulls_map and nulls_map [ i ] :,190
"def _end_dcterms_valid(self): <TAB> for validity_detail in self.pop(""validity"").split("";""): <MASK> key, value = validity_detail.split(""="", 1) <TAB>  <TAB>  <TAB> if key == ""start"": <TAB>  <TAB>  <TAB>  <TAB> self._save(""validity_start"", value, overwrite=True) <TAB>  <TAB>  <TAB>  <TAB> self._save(""validity_start_parsed"", _parse_date(value), overwrite=True) <TAB>  <TAB>  <TAB> elif key == ""end"": <TAB>  <TAB>  <TAB>  <TAB> self._save(""validity_end"", value, overwrite=True) <TAB>  <TAB>  <TAB>  <TAB> self._save(""validity_end_parsed"", _parse_date(value), overwrite=True)","if ""="" in validity_detail :",165
"def _load_all_identifiers(self): <TAB> results = {} <TAB> for entry in scandir(self._folder): <MASK> continue <TAB>  <TAB> if not entry.is_file(): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> identifier = entry.name[: -len("".profile"")] <TAB>  <TAB> results[identifier] = entry.path <TAB> return results","if is_hidden_path ( entry . name ) or not entry . name . endswith ( "".profile"" ) :",103
def close(self): <TAB> got_e = None <TAB> try: <TAB>  <TAB> _RawIOBase.close(self) <TAB> except Exception as e: <TAB>  <TAB> got_e = e <TAB> if not self.__closefd__: <TAB>  <TAB> self.__fd__ = -1 <TAB> else: <MASK> fd = self.__fd__ <TAB>  <TAB>  <TAB> self.__fd__ = -1 <TAB>  <TAB>  <TAB> _os.close(fd) <TAB>  <TAB> if got_e: <TAB>  <TAB>  <TAB> raise got_e,if self . __fd__ >= 0 :,126
"def format_params(params): <TAB> items = list(params.items()) <TAB> for k, v in sorted(items, key=itemgetter(0), reverse=True): <TAB>  <TAB> if isinstance(v, bytes): <TAB>  <TAB>  <TAB> v = v.decode(""utf-8"") <MASK> v = u'""{v}""'.format(v=v) <TAB>  <TAB> yield u""{k}={v}"".format(k=k, v=v)","if isinstance ( v , six . text_type ) :",113
"def __call__(self, data): <TAB> if self._apply_shift: <MASK> raise Exception(""should quantize first using GridSampling3D"") <TAB>  <TAB> if not isinstance(data.coords, torch.IntTensor): <TAB>  <TAB>  <TAB> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> ""The pos are expected to be coordinates, so torch.IntTensor"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> data.coords[:, :3] += (torch.rand(3) * 100).type_as(data.coords) <TAB> return data","if not hasattr ( data , ""coords"" ) :",127
"def cygpath(path): <TAB> """"""Use :meth:`git.cmd.Git.polish_url()` instead, that works on any environment."""""" <TAB> if not path.startswith((""/cygdrive"", ""//"")): <TAB>  <TAB> for regex, parser, recurse in _cygpath_parsers: <TAB>  <TAB>  <TAB> match = regex.match(path) <MASK> path = parser(*match.groups()) <TAB>  <TAB>  <TAB>  <TAB> if recurse: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> path = cygpath(path) <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> path = _cygexpath(None, path) <TAB> return path",if match :,150
"def _Determine_Do(self): <TAB> self.applicable = 1 <TAB> for opt, optarg in self.chosenOptions: <TAB>  <TAB> if opt in (""-V"", ""--komodo-version""): <TAB>  <TAB>  <TAB> self.value = optarg <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> versionInfoFile = black.configure.items[""versionInfoFile""].Get() <MASK> self.value = open(versionInfoFile).readline().strip() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.value = None <TAB> self.determined = 1",if versionInfoFile :,124
"def index(self, featureId): <TAB> """"""Gets the Feature Index for a given Feature ID"""""" <TAB> if self._check(): <TAB>  <TAB> may_have = False <TAB>  <TAB> ivalue = int(featureId) <TAB>  <TAB> for index, f in enumerate(self.features): <TAB>  <TAB>  <TAB> if f is None: <TAB>  <TAB>  <TAB>  <TAB> may_have = True <TAB>  <TAB>  <TAB> elif ivalue == int(f): <TAB>  <TAB>  <TAB>  <TAB> return index <MASK> reply = self.device.request(0x0000, _pack(""!H"", ivalue)) <TAB>  <TAB>  <TAB> if reply: <TAB>  <TAB>  <TAB>  <TAB> index = ord(reply[0:1]) <TAB>  <TAB>  <TAB>  <TAB> self.features[index] = FEATURE[ivalue] <TAB>  <TAB>  <TAB>  <TAB> return index <TAB> raise ValueError(""%r not in list"" % featureId)",if may_have :,193
"def _not_op(self, d, k, s): <TAB> if isinstance(s, dict): <TAB>  <TAB> for key in s.keys(): <MASK> raise OperationFailure(""unknown operator: %s"" % key) <TAB> elif isinstance(s, _RE_TYPES): <TAB>  <TAB> pass <TAB> else: <TAB>  <TAB> raise OperationFailure(""$not needs a regex or a document"") <TAB> return not self.apply({k: s}, d)",if key not in self . _operator_map and key not in LOGICAL_OPERATOR_MAP :,126
"def unpack(cls, data, negotiated): <TAB> sr_attrs = [] <TAB> while data: <TAB>  <TAB> # Type = 1 octet <TAB>  <TAB> scode = six.indexbytes(data, 0) <TAB>  <TAB> # L = 2 octet  :| <TAB>  <TAB> length = unpack(""!H"", data[1:3])[0] <MASK> klass = cls.registered_srids[scode].unpack(data[3 : length + 3], length) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> klass = GenericSRId(scode, data[3 : length + 3]) <TAB>  <TAB> klass.TLV = scode <TAB>  <TAB> sr_attrs.append(klass) <TAB>  <TAB> data = data[length + 3 :] <TAB> return cls(sr_attrs=sr_attrs)",if scode in cls . registered_srids :,193
"def getExecutionFunctionName(self): <TAB> if self.mode == ""INDEX"": <MASK> if self.useWeightsList: <TAB>  <TAB>  <TAB>  <TAB> return ""execute_Indices_WeightsList"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return ""execute_Indices_SingleWeight"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""execute_Index_Weight"" <TAB> elif self.mode == ""ALL"": <TAB>  <TAB> if self.useWeightsList: <TAB>  <TAB>  <TAB> return ""execute_All_WeightsList"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""execute_All_SingleWeight""",if self . useIndexList :,142
"def check_if_query_contains_only_schema(self, document: GraphQLDocument): <TAB> query_with_schema = False <TAB> for definition in document.document_ast.definitions: <TAB>  <TAB> selections = definition.selection_set.selections <TAB>  <TAB> selection_count = len(selections) <TAB>  <TAB> for selection in selections: <TAB>  <TAB>  <TAB> selection_name = str(selection.name.value) <TAB>  <TAB>  <TAB> if selection_name == ""__schema"": <TAB>  <TAB>  <TAB>  <TAB> query_with_schema = True <MASK> msg = ""`__schema` must be fetched in separete query"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise GraphQLError(msg) <TAB> return query_with_schema",if selection_count > 1 :,167
"def remove_href_prohibited_attr(element): <TAB> try: <MASK> t = element.toxml() <TAB>  <TAB>  <TAB> if re.search('href=""http', t) or re.search('href=""https', t): <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> element.removeAttribute(""href"") <TAB> except (AttributeError, KeyError): <TAB>  <TAB> pass","if element . hasAttribute ( ""href"" ) :",100
"def dump(self): <TAB> """"""Dump all error/debug/module code to the output .bp file."""""" <TAB> self.runner.init_bp_file(self.outf_name) <TAB> with open(self.outf_name, ""a"") as outf: <TAB>  <TAB> self.outf = outf <MASK> self.dump_line() <TAB>  <TAB>  <TAB> self.write(self.errors) <TAB>  <TAB> elif self.skip_crate(): <TAB>  <TAB>  <TAB> self.dump_skip_crate(self.skip_crate()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if self.debug: <TAB>  <TAB>  <TAB>  <TAB> self.dump_debug_info() <TAB>  <TAB>  <TAB> self.dump_android_module()",if self . errors :,164
"def downgrade(): <TAB> bind = op.get_bind() <TAB> session = db.Session(bind=bind) <TAB> for slc in session.query(Slice).filter( <TAB>  <TAB> or_(Slice.viz_type.like(""line""), Slice.viz_type.like(""bar"")) <TAB> ): <TAB>  <TAB> params = json.loads(slc.params) <TAB>  <TAB> layers = params.get(""annotation_layers"", []) <MASK> params[""annotation_layers""] = [layer[""value""] for layer in layers] <TAB>  <TAB>  <TAB> slc.params = json.dumps(params) <TAB>  <TAB>  <TAB> session.merge(slc) <TAB>  <TAB>  <TAB> session.commit() <TAB> session.close()",if layers :,159
"def _splitBalancedParen(delim, arg): <TAB> parenCount = 0 <TAB> for i in range(0, len(arg)): <TAB>  <TAB> if arg[i] == ""("": <TAB>  <TAB>  <TAB> parenCount += 1 <TAB>  <TAB> if arg[i] == "")"": <TAB>  <TAB>  <TAB> parenCount -= 1 <MASK> raise ValueError <TAB>  <TAB> if parenCount == 0 and arg[i] == delim: <TAB>  <TAB>  <TAB> return arg[0:i], arg[i + 1 :] <TAB> return arg",if parenCount < 0 :,122
"def autoname(self): <TAB> self.coupon_name = strip(self.coupon_name) <TAB> self.name = self.coupon_name <TAB> if not self.coupon_code: <TAB>  <TAB> if self.coupon_type == ""Promotional"": <TAB>  <TAB>  <TAB> self.coupon_code = """".join( <TAB>  <TAB>  <TAB>  <TAB> [i for i in self.coupon_name if not i.isdigit()] <TAB>  <TAB>  <TAB> )[0:8].upper() <MASK> self.coupon_code = frappe.generate_hash()[:10].upper()","elif self . coupon_type == ""Gift Card"" :",159
"def reverse_code(apps: StateApps, schema_editor: DatabaseSchemaEditor) -> None: <TAB> Realm = apps.get_model(""zerver"", ""Realm"") <TAB> Realm.BOT_CREATION_EVERYONE = 1 <TAB> for realm in Realm.objects.all(): <MASK> realm.create_generic_bot_by_admins_only = False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> realm.create_generic_bot_by_admins_only = True <TAB>  <TAB> realm.save(update_fields=[""create_generic_bot_by_admins_only""])",if realm . bot_creation_policy == Realm . BOT_CREATION_EVERYONE :,163
"def group_backend_by_type(items): <TAB> """"""Group items by backend type."""""" <TAB> result = defaultdict(list) <TAB> backends_defined = get_backends() <TAB> for item in items: <TAB>  <TAB> name = getattr(item, ""provider"", item) <TAB>  <TAB> backend = backends_defined[name] <TAB>  <TAB> if issubclass(backend, OpenIdAuth): <TAB>  <TAB>  <TAB> result[""openid""].append(item) <TAB>  <TAB> elif issubclass(backend, BaseOAuth2): <TAB>  <TAB>  <TAB> result[""oauth2""].append(item) <MASK> result[""oauth""].append(item) <TAB> return dict(result)","elif issubclass ( backend , BaseOAuth1 ) :",154
"def _reprInternal(self): <TAB> msg = [] <TAB> for key in self._parameterKeys: <TAB>  <TAB> attr = self._parameterKeys[key] <TAB>  <TAB> if attr in self._parameters:  # only show those defined <MASK> msg.append(key) <TAB>  <TAB>  <TAB>  <TAB> msg.append("":"") <TAB>  <TAB>  <TAB>  <TAB> msg.append(self._parameters[attr]) <TAB> if self._note is not None: <TAB>  <TAB> msg.append("" of "") <TAB>  <TAB> msg.append(repr(self._note)) <TAB> return """".join(msg)",if self . _parameters [ attr ] :,137
"def __wrapped(*args, **kwargs): <TAB> info = """" <TAB> if self.ident: <TAB>  <TAB> info += self.ident.format(self.instance) <TAB> info += ""{0.__name__}("".format(meth) <MASK> info += "", "".join(map(repr, args)) <TAB> if kwargs: <TAB>  <TAB> if args: <TAB>  <TAB>  <TAB> info += "", "" <TAB>  <TAB> info += "", "".join( <TAB>  <TAB>  <TAB> ""{k}={v!r}"".format(k=key, v=value) for key, value in items(kwargs) <TAB>  <TAB> ) <TAB> info += "")"" <TAB> self.logger.debug(info) <TAB> return meth(*args, **kwargs)",if args :,158
"def on_context_menuInbox(self, point): <TAB> tableWidget = self.getCurrentMessagelist() <TAB> if tableWidget: <TAB>  <TAB> currentFolder = self.getCurrentFolder() <TAB>  <TAB> if currentFolder == False: <TAB>  <TAB>  <TAB> pass <MASK> self.on_context_menuSent(point) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.popMenuInbox.exec_(tableWidget.mapToGlobal(point))","if currentFolder == ""sent"" :",110
"def updateSelection(self): <TAB> # Track selected items <TAB> self.selected = self.selectionModel().selectedIndexes() <TAB> # Track selected file ids on main window <TAB> rows = [] <TAB> self.win.selected_files = [] <TAB> for selection in self.selected: <TAB>  <TAB> selected_row = self.files_model.model.itemFromIndex(selection).row() <MASK> self.win.selected_files.append( <TAB>  <TAB>  <TAB>  <TAB> self.files_model.model.item(selected_row, 5).text() <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> rows.append(selected_row)",if selected_row not in rows :,150
"def set_child_quota(self, context): <TAB> # was used for string child property <TAB> updateNode(self, context) <TAB> # post update check <TAB> if self.auto_release: <TAB>  <TAB> parent = self.name_node_generated_parent <TAB>  <TAB> if parent: <TAB>  <TAB>  <TAB> for obj in bpy.data.objects[parent].children: <MASK> obj.parent = None",if not obj . name == self . name_child :,111
def docompute(num): <TAB> for i in range(num): <TAB>  <TAB> sum = 0 <TAB>  <TAB> j = 0 <TAB>  <TAB> while j < i: <MASK> temp = 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> temp = i % 3 <TAB>  <TAB>  <TAB> j += temp <TAB>  <TAB> sum = sum + j <TAB> return sum,if i % 3 == 0 :,90
"def __getitem__(self, index): <TAB> ""Allows use of the index [] operator to get a layer at the index."" <TAB> if isinstance(index, six.string_types): <TAB>  <TAB> l = capi.get_layer_by_name(self.ptr, force_bytes(index)) <TAB>  <TAB> if not l: <TAB>  <TAB>  <TAB> raise OGRIndexError('invalid OGR Layer name given: ""%s""' % index) <TAB> elif isinstance(index, int): <MASK> raise OGRIndexError(""index out of range"") <TAB>  <TAB> l = capi.get_layer(self._ptr, index) <TAB> else: <TAB>  <TAB> raise TypeError(""Invalid index type: %s"" % type(index)) <TAB> return Layer(l, self)",if index < 0 or index >= self . layer_count :,183
"def find_data_files(source, prefix=None): <TAB> result = [] <TAB> for directory, _, files in os.walk(source): <TAB>  <TAB> files = [os.path.join(directory, x) for x in files] <MASK> result.append((os.path.join(prefix, directory), files)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result.append((directory, files)) <TAB> return result",if prefix :,101
"def change_items(self, message): <TAB> """"""An iterator of changelog updates from a commit message in the form (category, message)"""""" <TAB> for line in message.split(""\n""): <TAB>  <TAB> for cat_match in re.finditer(""\[(\w+)\]"", line): <TAB>  <TAB>  <TAB> found_cat = self.cat_lookup(cat_match.group(1)) <MASK> line = line.replace(cat_match.group(0), """").strip() <TAB>  <TAB>  <TAB>  <TAB> yield found_cat, line",if found_cat :,124
def linkText(text): <TAB> if text: <TAB>  <TAB> if result: <TAB>  <TAB>  <TAB> if result[-1].tail: <TAB>  <TAB>  <TAB>  <TAB> result[-1].tail += text <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> result[-1].tail = text <TAB>  <TAB> else: <MASK> parent.text += text <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> parent.text = text,if parent . text :,99
def score(input): <TAB> if (input[5]) <= (6.941): <MASK> if (input[7]) <= (1.43365): <TAB>  <TAB>  <TAB>  <TAB> var0 = 45.58 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> var0 = 22.865022421524642 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> var0 = 14.924358974358983 <TAB> else: <TAB>  <TAB> if (input[5]) <= (7.4370003): <TAB>  <TAB>  <TAB> var0 = 32.09534883720931 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> var0 = 45.275 <TAB> return var0,if ( input [ 12 ] ) <= ( 14.395 ) :,165
"def coerce_vars(self, vars): <TAB> global variabledecode <TAB> need_variable_encode = False <TAB> for key, value in vars.items(): <MASK> need_variable_encode = True <TAB>  <TAB> if key.endswith(""_""): <TAB>  <TAB>  <TAB> vars[key[:-1]] = vars[key] <TAB>  <TAB>  <TAB> del vars[key] <TAB> if need_variable_encode: <TAB>  <TAB> if variabledecode is None: <TAB>  <TAB>  <TAB> from formencode import variabledecode <TAB>  <TAB> vars = variabledecode.variable_encode(vars) <TAB> return vars","if isinstance ( value , dict ) :",134
"def parse_signature(self, sig, signode): <TAB> """"""Transform an option description into RST nodes."""""" <TAB> count = 0 <TAB> firstname = """" <TAB> for m in option_desc_re.finditer(sig): <TAB>  <TAB> optname, args = m.groups() <TAB>  <TAB> if count: <TAB>  <TAB>  <TAB> signode += addnodes.desc_addname("", "", "", "") <TAB>  <TAB> signode += addnodes.desc_name(optname, optname) <TAB>  <TAB> signode += addnodes.desc_addname(args, args) <MASK> firstname = optname <TAB>  <TAB> count += 1 <TAB> if not firstname: <TAB>  <TAB> raise ValueError <TAB> return firstname",if not count :,159
"def callback(lexer, match, context): <TAB> text = match.group() <TAB> if context.block_scalar_indent is None: <TAB>  <TAB> if len(text) <= max(context.indent, 0): <TAB>  <TAB>  <TAB> context.stack.pop() <TAB>  <TAB>  <TAB> context.stack.pop() <TAB>  <TAB>  <TAB> return <TAB>  <TAB> context.block_scalar_indent = len(text) <TAB> else: <MASK> context.stack.pop() <TAB>  <TAB>  <TAB> context.stack.pop() <TAB>  <TAB>  <TAB> return <TAB> if text: <TAB>  <TAB> yield match.start(), TokenClass, text <TAB>  <TAB> context.pos = match.end()",if len ( text ) < context . block_scalar_indent :,162
"def _detect(self): <TAB> """""""""""" <TAB> results = [] <TAB> for c in self.contracts: <TAB>  <TAB> cst = c.constructor <MASK> for constructor_call in cst.explicit_base_constructor_calls_statements: <TAB>  <TAB>  <TAB>  <TAB> for node in constructor_call.nodes: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if any(isinstance(ir, Nop) for ir in node.irs): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> info = [""Void constructor called in "", cst, "":\n""] <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> info += [""\t- "", node, ""\n""] <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> res = self.generate_result(info) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> results.append(res) <TAB> return results",if cst :,176
"def initialize_weights(model): <TAB> for m in model.modules(): <TAB>  <TAB> t = type(m) <TAB>  <TAB> if t is nn.Conv2d: <TAB>  <TAB>  <TAB> pass  # nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') <TAB>  <TAB> elif t is nn.BatchNorm2d: <TAB>  <TAB>  <TAB> m.eps = 1e-3 <TAB>  <TAB>  <TAB> m.momentum = 0.03 <MASK> m.inplace = True","elif t in [ nn . Hardswish , nn . LeakyReLU , nn . ReLU , nn . ReLU6 ] :",140
"def update(self, x): <TAB> if len(self) >= self.size: <TAB>  <TAB> # Subtract the counter of the last element <TAB>  <TAB> first_in = self[0] <TAB>  <TAB> self.counts[first_in] -= 1 <TAB>  <TAB> # No need to store the value if it's counter is 0 <MASK> self.counts.pop(first_in) <TAB> self.counts[x] += 1 <TAB> super().append(x) <TAB> return self",if self . counts [ first_in ] == 0 :,122
"def toggle_group_enabled(feed, group, enabled): <TAB> if type(enabled) != bool: <TAB>  <TAB> raise BadRequest(message=""state must be a boolean"", detail={""value"": enabled}) <TAB> session = db.get_session() <TAB> try: <TAB>  <TAB> g = db.set_feed_group_enabled(session, feed, group, enabled) <MASK> raise ResourceNotFound(group, detail={}) <TAB>  <TAB> session.flush() <TAB>  <TAB> grp = _marshall_group_response(g).to_json() <TAB>  <TAB> session.commit() <TAB>  <TAB> return jsonify(grp), 200 <TAB> except AnchoreApiError: <TAB>  <TAB> session.rollback() <TAB>  <TAB> raise <TAB> except Exception: <TAB>  <TAB> log.error(""Could not update feed group enabled status"") <TAB>  <TAB> session.rollback() <TAB>  <TAB> raise",if not g :,195
"def _parse_cmudict(file): <TAB> cmudict = {} <TAB> for line in file: <MASK> parts = line.split(""  "") <TAB>  <TAB>  <TAB> word = re.sub(_alt_re, """", parts[0]) <TAB>  <TAB>  <TAB> pronunciation = _get_pronunciation(parts[1]) <TAB>  <TAB>  <TAB> if pronunciation: <TAB>  <TAB>  <TAB>  <TAB> if word in cmudict: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> cmudict[word].append(pronunciation) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> cmudict[word] = [pronunciation] <TAB> return cmudict","if len ( line ) and ( line [ 0 ] >= ""A"" and line [ 0 ] <= ""Z"" or line [ 0 ] == ""'"" ) :",186
"def getBuildid(self, kwargs): <TAB> # need to look in the context of a step, specified by build or <TAB> # builder or whatever <TAB> if ""buildid"" in kwargs: <TAB>  <TAB> defer.returnValue(kwargs[""buildid""]) <TAB> else: <TAB>  <TAB> builderid = yield self.getBuilderId(kwargs) <TAB>  <TAB> if builderid is None: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> build = yield self.master.db.builds.getBuildByNumber( <TAB>  <TAB>  <TAB> builderid=builderid, number=kwargs[""build_number""] <TAB>  <TAB> ) <MASK> return <TAB>  <TAB> defer.returnValue(build[""id""])",if not build :,155
"def access(self, path, mode): <TAB> if hasattr(self, ""relative_path"") and self.relative_path != ""/"": <TAB>  <TAB> path_elems = split_path_into_components(self.relative_path) <TAB>  <TAB> is_valid_path = self._validate_commit_path(self.commit.tree, path_elems) <MASK> raise FuseOSError(ENOENT) <TAB> return 0",if not is_valid_path :,103
"def get_config(self, section, option, default=_None, boolean=False): <TAB> try: <TAB>  <TAB> if boolean: <TAB>  <TAB>  <TAB> return self.config.getboolean(section, option) <TAB>  <TAB> item = self.config.get(section, option) <TAB>  <TAB> if option.endswith("".furl"") and self._contains_unescaped_hash(item): <TAB>  <TAB>  <TAB> raise UnescapedHashError(section, option, item) <TAB>  <TAB> return item <TAB> except (ConfigParser.NoOptionError, ConfigParser.NoSectionError): <MASK> fn = os.path.join(self.basedir, u""tahoe.cfg"") <TAB>  <TAB>  <TAB> raise MissingConfigEntry( <TAB>  <TAB>  <TAB>  <TAB> ""%s is missing the [%s]%s entry"" % (quote_output(fn), section, option) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return default",if default is _None :,200
"def _latex(self, *args): <TAB> parts = [] <TAB> for i in range(len(self._dims)): <MASK> s = _ilabel[i] <TAB>  <TAB>  <TAB> if self._dims[i] != 1: <TAB>  <TAB>  <TAB>  <TAB> s += ""^{%s}"" % str(self._dims[i]) <TAB>  <TAB>  <TAB> parts.append(s) <TAB> s = ""\\,"".join(parts) <TAB> if not len(s): <TAB>  <TAB> return ""1"" <TAB> return s.strip()",if self . _dims [ i ] :,127
"def get_scale_factor(img, auto_scale, as_uint16): <TAB> if auto_scale: <TAB>  <TAB> if img.dtype == np.uint8: <TAB>  <TAB>  <TAB> if as_uint16: <TAB>  <TAB>  <TAB>  <TAB> return 256 <MASK> return 65535 if as_uint16 else 255 <TAB> return 1",elif img . dtype != np . uint16 :,86
"def _do_background(self): <TAB> while True: <TAB>  <TAB> with handle_exception(self._error_listeners): <TAB>  <TAB>  <TAB> cb = self._task_queue.get() <MASK> break <TAB>  <TAB>  <TAB> func, args, kwargs = cb <TAB>  <TAB>  <TAB> func(*args, **kwargs) <TAB>  <TAB>  <TAB> # release before possible idle <TAB>  <TAB>  <TAB> del cb, func, args, kwargs",if cb is self . _STOP :,102
"def get_snapshot_range(self, snaps, start_date=None, end_date=None): <TAB> l = [] <TAB> for snap in snaps: <TAB>  <TAB> if start_date and end_date: <TAB>  <TAB>  <TAB> if snap.date >= start_date and snap.date <= end_date: <TAB>  <TAB>  <TAB>  <TAB> l.append(snap) <MASK> if snap.date >= start_date: <TAB>  <TAB>  <TAB>  <TAB> l.append(snap) <TAB>  <TAB> elif end_date: <TAB>  <TAB>  <TAB> if snap.date <= end_date: <TAB>  <TAB>  <TAB>  <TAB> l.append(snap) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> l.append(snap) <TAB> return l",elif start_date :,167
"def genMinTagSet(self): <TAB> if self.__minTagSet is None: <TAB>  <TAB> for t in self.__namedTypes: <TAB>  <TAB>  <TAB> __type = t.getType() <TAB>  <TAB>  <TAB> tagSet = getattr(__type, ""getMinTagSet"", __type.getTagSet)() <MASK> self.__minTagSet = tagSet <TAB> return self.__minTagSet",if self . __minTagSet is None or tagSet < self . __minTagSet :,102
"def identifier(self, limit=99): <TAB> s = [] <TAB> for i, fa in enumerate(self.flag_actions): <MASK> die(""Bogus flag!"") <TAB>  <TAB> s.append(""{}-{}"".format(fa.flag, fa.action)) <TAB>  <TAB> if i >= limit: <TAB>  <TAB>  <TAB> break <TAB> return "":"".join(s)",if not fa . flag :,88
"def load_job_config_dict(job_conf_dict): <TAB> for runner in job_conf_dict.get(""runners""): <MASK> self.job_runners.append(runner.get(""load"")) <TAB>  <TAB> if ""rules_module"" in runner: <TAB>  <TAB>  <TAB> self.job_rule_modules.append(plugin.text) <TAB>  <TAB> if ""params"" in runner: <TAB>  <TAB>  <TAB> runner_params = runner[""params""] <TAB>  <TAB>  <TAB> if ""rules_module"" in runner_params: <TAB>  <TAB>  <TAB>  <TAB> self.job_rule_modules.append(plugin.text)","if ""load"" in runner :",145
"def _read_next(self, end): <TAB> if end is not None and end < len(self._lines): <TAB>  <TAB> return <TAB> try: <TAB>  <TAB> output, index = self._ensure_open() <TAB> except IOError as e: <MASK> raise <TAB> else: <TAB>  <TAB> lines = self._lines <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> line = output.readline().rstrip().decode() <TAB>  <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> time, stream = struct.unpack(""!QB"", index.read(9)) <TAB>  <TAB>  <TAB> lines.append((time, stream, line)) <TAB>  <TAB>  <TAB> if end is not None and end < len(self._lines): <TAB>  <TAB>  <TAB>  <TAB> break",if e . errno != errno . EEXIST :,177
"def get(self, instance_id): <TAB> if instance_id not in self.instances: <TAB>  <TAB> raise NotFound <TAB> inst = self.instances[instance_id] <TAB> if not self.fail_to_get or inst.gets < self.gets_until_disappears: <TAB>  <TAB> if not inst.status.startswith(""BUILD""): <TAB>  <TAB>  <TAB> return inst <TAB>  <TAB> inst.gets += 1 <TAB>  <TAB> if inst.gets >= self.gets_until_active: <MASK> inst.status = ACTIVE <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> inst.status = ERROR <TAB>  <TAB> return inst <TAB> else: <TAB>  <TAB> raise NotFound",if not self . fail_to_start :,166
"def gen_ies_md(ies): <TAB> for ie in ies: <TAB>  <TAB> ie_md = ""**{0}**"".format(ie.IE_NAME) <TAB>  <TAB> ie_desc = getattr(ie, ""IE_DESC"", None) <TAB>  <TAB> if ie_desc is False: <TAB>  <TAB>  <TAB> continue <MASK> ie_md += "": {0}"".format(ie.IE_DESC) <TAB>  <TAB> if not ie.working(): <TAB>  <TAB>  <TAB> ie_md += "" (Currently broken)"" <TAB>  <TAB> yield ie_md",if ie_desc is not None :,132
"def profile_tests(): <TAB> test_functions = [ <TAB>  <TAB> fn <TAB>  <TAB> for fn in inspect.getmembers(vector_test, inspect.isfunction) <TAB>  <TAB> if fn[0].startswith(""test_"") <TAB> ] <TAB> for name, fn in test_functions: <TAB>  <TAB> # There are a couple of tests that are not run for the C implementation, skip those <TAB>  <TAB> fn_args = inspect.getargspec(fn)[0] <MASK> print(""Executing %s"" % name) <TAB>  <TAB>  <TAB> result = memory_profiler.memory_usage( <TAB>  <TAB>  <TAB>  <TAB> (run_function, (fn,), {}), interval=0.1 <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> assert not detect_memory_leak(result), (name, result)","if ""pvector"" in fn_args :",181
"def __getitem__(self, index: int) -> nn.Module: <TAB> """"""Gets a layer in the underlying sequential module."""""" <TAB> partitions: List[Any] <TAB> partitions = self.partitions <TAB> if index < 0: <TAB>  <TAB> partitions = partitions[::-1] <TAB> for partition in partitions: <TAB>  <TAB> try: <MASK> return partition.module[index] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return partition[index] <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> shift = len(partition) <TAB>  <TAB> if index < 0: <TAB>  <TAB>  <TAB> index += shift <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> index -= shift <TAB> raise IndexError","if isinstance ( partition , ModuleWrapper ) :",162
"def main(): <TAB> args = parser.parse_args() <TAB> found = 0 <TAB> if not args.all and len(args.users) == 0: <TAB>  <TAB> sys.exit(""Need a list of users or --all"") <TAB> for user in get_users(all_users=args.all, users_list=args.users): <MASK> repos = repos_for_namespace(user.username) <TAB>  <TAB>  <TAB> found += ensure_admin(user, repos, dry_run=args.dry_run) <TAB> print( <TAB>  <TAB> (""\nFound {} user repos missing admin"" "" permissions for owner."".format(found)) <TAB> )",if user is not None :,157
"def __deleteHotkeys(self, removed_item): <TAB> if model.TriggerMode.HOTKEY in removed_item.modes: <TAB>  <TAB> self.window().app.hotkey_removed(removed_item) <TAB> if isinstance(removed_item, model.Folder): <TAB>  <TAB> for subFolder in removed_item.folders: <TAB>  <TAB>  <TAB> self.__deleteHotkeys(subFolder) <TAB>  <TAB> for item in removed_item.items: <MASK> self.window().app.hotkey_removed(item)",if model . TriggerMode . HOTKEY in item . modes :,136
"def invoke(): <TAB> cmd = t.get(""promptEnd + 1 char"", AtInsert()) <TAB> if t.getboolean(tk.call(""info"", ""complete"", cmd)):  # XXX <MASK> msg = tk.call(""eval"", cmd)  # XXX <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> msg = t.send(app, cmd) <TAB>  <TAB> if msg: <TAB>  <TAB>  <TAB> t.insert(AtInsert(), msg + ""\n"") <TAB>  <TAB> prompt() <TAB> t.yview_pickplace(AtInsert())",if app == root . winfo_name ( ) :,129
"def printcallee(): <TAB> flist = sorted(file2undef.keys()) <TAB> for filename in flist: <TAB>  <TAB> print(filename + "":"") <TAB>  <TAB> elist = file2undef[filename] <TAB>  <TAB> elist.sort() <TAB>  <TAB> for ext in elist: <MASK> tabs = ""\t"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> tabs = ""\t\t"" <TAB>  <TAB>  <TAB> if ext not in def2file: <TAB>  <TAB>  <TAB>  <TAB> print(""\t"" + ext + tabs + "" *undefined"") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> print(""\t"" + ext + tabs + flat(def2file[ext]))",if len ( ext ) >= 8 :,163
"def writePlistToString(rootObject, binary=True): <TAB> if not binary: <TAB>  <TAB> rootObject = wrapDataObject(rootObject, binary) <TAB>  <TAB> if hasattr(plistlib, ""dumps""): <TAB>  <TAB>  <TAB> return plistlib.dumps(rootObject) <MASK> return plistlib.writePlistToBytes(rootObject) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return plistlib.writePlistToString(rootObject) <TAB> else: <TAB>  <TAB> ioObject = io.BytesIO() <TAB>  <TAB> writer = PlistWriter(ioObject) <TAB>  <TAB> writer.writeRoot(rootObject) <TAB>  <TAB> return ioObject.getvalue()","elif hasattr ( plistlib , ""writePlistToBytes"" ) :",153
"def jj(line: str) -> str: <TAB> if line.startswith(""GRUB_CMDLINE_LINUX=""): <TAB>  <TAB> return grub_cmdline <TAB> if args.qemu_headless: <TAB>  <TAB> if ""GRUB_TERMINAL_INPUT"" in line: <TAB>  <TAB>  <TAB> return 'GRUB_TERMINAL_INPUT=""console serial""' <MASK> return 'GRUB_TERMINAL_OUTPUT=""console serial""' <TAB> return line","if ""GRUB_TERMINAL_OUTPUT"" in line :",113
"def fetch(self, url, body=None, headers=None): <TAB> if body is None: <MASK> return self.get_responses[url] <TAB> else: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> body.index(""openid.mode=associate"") <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> pass  # fall through <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert body.find(""DH-SHA1"") != -1 <TAB>  <TAB>  <TAB> response = associate(body, self.assoc_secret, self.assoc_handle) <TAB>  <TAB>  <TAB> self.num_assocs += 1 <TAB>  <TAB>  <TAB> return self.response(url, 200, response) <TAB> return self.response(url, 404, ""Not found"")",if url in self . get_responses :,173
"def get_intra_links(webdriver, url): <TAB> ps1 = du.get_ps_plus_1(url) <TAB> links = list() <TAB> for elem in webdriver.find_elements_by_tag_name(""a""): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> href = elem.get_attribute(""href"") <TAB>  <TAB> except StaleElementReferenceException: <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> full_href = urlparse.urljoin(url, href) <TAB>  <TAB> if not full_href.startswith(""http""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if du.get_ps_plus_1(full_href) == ps1: <TAB>  <TAB>  <TAB> links.append(elem) <TAB> return links",if href is None :,171
"def _get_hg_root(q): <TAB> _curpwd = builtins.__xonsh__.env[""PWD""] <TAB> while True: <MASK> return False <TAB>  <TAB> if any([b.name == "".hg"" for b in xt.scandir(_curpwd)]): <TAB>  <TAB>  <TAB> q.put(_curpwd) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _oldpwd = _curpwd <TAB>  <TAB>  <TAB> _curpwd = os.path.split(_curpwd)[0] <TAB>  <TAB>  <TAB> if _oldpwd == _curpwd: <TAB>  <TAB>  <TAB>  <TAB> return False",if not os . path . isdir ( _curpwd ) :,147
"def _gen_filename(self, name): <TAB> if name == ""cortical_thickness"": <TAB>  <TAB> output = self.inputs.cortical_thickness <MASK> _, name, ext = split_filename(self.inputs.segmentation_image) <TAB>  <TAB>  <TAB> output = name + ""_cortical_thickness"" + ext <TAB>  <TAB> return output <TAB> if name == ""warped_white_matter"": <TAB>  <TAB> output = self.inputs.warped_white_matter <TAB>  <TAB> if not isdefined(output): <TAB>  <TAB>  <TAB> _, name, ext = split_filename(self.inputs.segmentation_image) <TAB>  <TAB>  <TAB> output = name + ""_warped_white_matter"" + ext <TAB>  <TAB> return output <TAB> return None",if not isdefined ( output ) :,176
"def _update_searcher(self, task, result): <TAB> config = task.args[""config""] <TAB> if self.searcher_data == ""rungs_and_last"": <TAB>  <TAB> with self._hyperband_lock: <TAB>  <TAB>  <TAB> task_info = self._running_tasks[str(task.task_id)] <MASK> # Remove last recently added result for this task, <TAB>  <TAB>  <TAB>  <TAB> # unless it fell on a rung level <TAB>  <TAB>  <TAB>  <TAB> if not task_info[""keep_case""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> rem_result = task_info[""reported_result""] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.searcher.remove_case(config, **rem_result) <TAB> self.searcher.update(config, **result)","if task_info [ ""reported_result"" ] is not None :",186
"def copy(self, dst, override=None): <TAB> if isinstance(dst, RemotePath): <TAB>  <TAB> raise TypeError(""Cannot copy local path {} to {!r}"".format(self, dst)) <TAB> dst = LocalPath(dst) <TAB> if override is False and dst.exists(): <TAB>  <TAB> raise TypeError(""File exists and override was not specified"") <TAB> if override: <TAB>  <TAB> dst.delete() <TAB> if self.is_dir(): <TAB>  <TAB> shutil.copytree(str(self), str(dst)) <TAB> else: <TAB>  <TAB> dst_dir = LocalPath(dst).dirname <MASK> dst_dir.mkdir() <TAB>  <TAB> shutil.copy2(str(self), str(dst)) <TAB> return dst",if not dst_dir . exists ( ) :,171
"def _add_tags_to_statistics(self, test): <TAB> for tag in test.tags: <TAB>  <TAB> if self._is_included(tag): <MASK> self.stats.tags[tag] = self._info.get_stat(tag) <TAB>  <TAB>  <TAB> self.stats.tags[tag].add_test(test)",if tag not in self . stats . tags :,92
"def single(self, data_table, request, obj_id): <TAB> try: <TAB>  <TAB> datum = self.get_data(request, obj_id) <TAB>  <TAB> error = False <TAB> except: <TAB>  <TAB> datum = None <TAB>  <TAB> error = exceptions.handle(request, ignore=True) <TAB> if request.is_ajax(): <MASK> row = data_table._meta.row_class(data_table, datum) <TAB>  <TAB>  <TAB> return http.HttpResponse(row.render()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return http.HttpResponse(status=error.status_code) <TAB> # NOTE(gabriel): returning None from the action continues <TAB> # with the view as normal. This will generally be the equivalent <TAB> # of refreshing the page. <TAB> return None",if not error :,187
"def __getitem__(self, key): <TAB> key = key.lower() <TAB> try: <TAB>  <TAB> return BASE_DATA_TYPES_REVERSE[key] <TAB> except KeyError: <TAB>  <TAB> import re <TAB>  <TAB> m = re.search(r""^\s*(?:var)?char\s*\(\s*(\d+)\s*\)\s*$"", key) <MASK> return (""CharField"", {""maxlength"": int(m.group(1))}) <TAB>  <TAB> raise KeyError",if m :,110
"def clone(expr, memo=None): <TAB> if memo is None: <TAB>  <TAB> memo = {} <TAB> nodes = dfs(expr) <TAB> for node in nodes: <MASK> new_inputs = [memo[arg] for arg in node.inputs()] <TAB>  <TAB>  <TAB> new_node = node.clone_from_inputs(new_inputs) <TAB>  <TAB>  <TAB> memo[node] = new_node <TAB> return memo[expr]",if node not in memo :,106
"def get_pkcs12_cert(strings=None, binary=None): <TAB> keys = [] <TAB> for string in strings: <TAB>  <TAB> index, _, _ = string <TAB>  <TAB> text_cert = read_pkcs_cert(binary=binary, offset=index) <MASK> keys.append(text_cert) <TAB> return keys",if text_cert is not None :,88
"def _prunetraceback(self, excinfo): <TAB> if hasattr(self, ""fspath""): <TAB>  <TAB> traceback = excinfo.traceback <TAB>  <TAB> ntraceback = traceback.cut(path=self.fspath) <MASK> ntraceback = ntraceback.cut(excludepath=tracebackcutdir) <TAB>  <TAB> excinfo.traceback = ntraceback.filter()",if ntraceback == traceback :,88
"def fails(filterfunction, str1, str2, message=None): <TAB> """"""returns whether the given strings fail on the given test, handling only FilterFailures"""""" <TAB> str1, str2, message = strprep(str1, str2, message) <TAB> try: <TAB>  <TAB> filterresult = filterfunction(str1, str2) <TAB> except checks.SeriousFilterFailure as e: <TAB>  <TAB> filterresult = True <TAB> except checks.FilterFailure as e: <MASK> exc_message = e.messages[0] <TAB>  <TAB>  <TAB> filterresult = exc_message != message <TAB>  <TAB>  <TAB> print(exc_message.encode(""utf-8"")) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> filterresult = False <TAB> filterresult = filterresult and check_category(filterfunction) <TAB> return not filterresult",if message :,188
"def xonshrc_context(rcfiles=None, execer=None, ctx=None, env=None, login=True): <TAB> """"""Attempts to read in all xonshrc files and return the context."""""" <TAB> loaded = env[""LOADED_RC_FILES""] = [] <TAB> ctx = {} if ctx is None else ctx <TAB> if rcfiles is None: <TAB>  <TAB> return env <TAB> env[""XONSHRC""] = tuple(rcfiles) <TAB> for rcfile in rcfiles: <MASK> loaded.append(False) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> _, ext = os.path.splitext(rcfile) <TAB>  <TAB> status = xonsh_script_run_control(rcfile, ctx, env, execer=execer, login=login) <TAB>  <TAB> loaded.append(status) <TAB> return ctx",if not os . path . isfile ( rcfile ) :,197
"def acquire(self): <TAB> try: <TAB>  <TAB> timeout = self.blocking <MASK> timeout = None <TAB>  <TAB> elif timeout is False: <TAB>  <TAB>  <TAB> timeout = 0 <TAB>  <TAB> await asyncio.wait_for(self._lock.acquire(), timeout=timeout) <TAB>  <TAB> self._schedule_timeout() <TAB>  <TAB> self._locked = True <TAB> except asyncio.TimeoutError: <TAB>  <TAB> self._locked = False <TAB> return self._locked",if timeout is True :,106
"def Convert(self, argument): <TAB> __pychecker__ = ""no-returnvalues"" <TAB> if type(argument) == str: <TAB>  <TAB> base = 10 <MASK> base = 16 <TAB>  <TAB> return int(argument, base) <TAB> else: <TAB>  <TAB> return int(argument)","if len ( argument ) > 2 and argument [ 0 ] == ""0"" and argument [ 1 ] == ""x"" :",94
"def emit(self, record): <TAB> try: <TAB>  <TAB> msg = self.format(record) <TAB>  <TAB> if record.levelno >= logging.ERROR: <TAB>  <TAB>  <TAB> servicemanager.LogErrorMsg(msg) <MASK> servicemanager.LogiNFOMsg(msg) <TAB> except Exception: <TAB>  <TAB> pass",elif record . levelno >= logging . INFO :,84
"def test_variantcall_format_roundtrip(self, field_name, setter, getter, values): <TAB> vc = variants_pb2.VariantCall() <TAB> self.assertNotIn(field_name, vc.info) <TAB> for value in values: <TAB>  <TAB> setter(vc, value) <MASK> self.assertIn(field_name, vc.info) <TAB>  <TAB> actual = getter(vc) <TAB>  <TAB> self.assertEqual(actual, value)","if field_name not in [ ""GT"" , ""GL"" ] :",118
"def _init_arguments( <TAB> self, context: UserContext, args: typing.Dict[int, str]) -> typing.List[str]: <TAB> arguments: typing.List[str] = [] <TAB> arg: typing.Union[str, typing.List[str]] = args.get(1, []) <TAB> if arg: <TAB>  <TAB> if isinstance(arg, str): <TAB>  <TAB>  <TAB> if arg == ""!"": <TAB>  <TAB>  <TAB>  <TAB> arg = str(self.vim.call(""denite#util#input"", ""Argument: "")) <TAB>  <TAB>  <TAB> arguments = shlex.split(arg) <MASK> arguments = arg[:] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise AttributeError(""`args[1]` needs to be a `str` or `list`"") <TAB> return arguments","elif isinstance ( arg , list ) :",181
"def _run_timeit(func, number): <TAB> # common setup <TAB> gc.collect() <TAB> manager = getattr(func, ""_benchmark_manager"", None) <TAB> try: <TAB>  <TAB> # TODO collect allocations count, memory usage <TAB>  <TAB> # TODO collect custom MB/sec metric reported by benchmark <MASK> with manager(number) as ctx: <TAB>  <TAB>  <TAB>  <TAB> return timeit.Timer(lambda: func(ctx)).timeit(number=number) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return timeit.Timer(func).timeit(number=number) <TAB> finally: <TAB>  <TAB> # common cleanup <TAB>  <TAB> eventlet.sleep(0.01)",if manager is not None :,153
"def table_row(self, *row, **options): <TAB> self.section() <TAB> values = [c.render_row(x) for c, x in zip(self.table.columns, row)] <TAB> for c, cell in zip(self.table.columns, values): <TAB>  <TAB> column_name = getattr(c.object_renderer, ""name"", None) or c.options.get(""name"") <TAB>  <TAB> # Skip empty columns. <MASK> continue <TAB>  <TAB> self.delegate_renderer.table_row(column_name, cell, **options)",if not cell . lines :,138
"def quote(s, quote='""'): <TAB> buf = [quote] <TAB> for ch in s: <TAB>  <TAB> if ch == quote or ch == ""\\"": <TAB>  <TAB>  <TAB> buf.append(""\\"") <TAB>  <TAB>  <TAB> buf.append(ch) <TAB>  <TAB> elif ch == ""\n"": <TAB>  <TAB>  <TAB> buf.append(""\\n"") <TAB>  <TAB> elif ch == ""\r"": <TAB>  <TAB>  <TAB> buf.append(""\\r"") <TAB>  <TAB> elif ch == ""\t"": <TAB>  <TAB>  <TAB> buf.append(""\\t"") <MASK> buf.append(ch) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Hex escape <TAB>  <TAB>  <TAB> buf.append(""\\x"") <TAB>  <TAB>  <TAB> buf.append(hex(ord(ch))[2:]) <TAB> buf.append(quote) <TAB> return """".join(buf)",elif ch in PRINTABLE :,183
"def __new__(mcls, name, bases, dct, *, source_date_epoch): <TAB> cls = super().__new__(mcls, name, bases, dct) <TAB> for attr in dir(cls): <MASK> meth = getattr(cls, attr) <TAB>  <TAB>  <TAB> if source_date_epoch: <TAB>  <TAB>  <TAB>  <TAB> wrapper = with_source_date_epoch(meth) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> wrapper = without_source_date_epoch(meth) <TAB>  <TAB>  <TAB> setattr(cls, attr, wrapper) <TAB> return cls","if attr . startswith ( ""test_"" ) :",136
"def CountInOutOptArgs(self, argTuple): <TAB> ""Return tuple counting in/outs/OPTS.  Sum of result may not be len(argTuple), as some args may be in/out."" <TAB> ins = out = opts = 0 <TAB> for argCheck in argTuple: <TAB>  <TAB> inOut = argCheck[1] <TAB>  <TAB> if inOut == 0: <TAB>  <TAB>  <TAB> ins = ins + 1 <TAB>  <TAB>  <TAB> out = out + 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if inOut & pythoncom.PARAMFLAG_FIN: <TAB>  <TAB>  <TAB>  <TAB> ins = ins + 1 <TAB>  <TAB>  <TAB> if inOut & pythoncom.PARAMFLAG_FOPT: <TAB>  <TAB>  <TAB>  <TAB> opts = opts + 1 <MASK> out = out + 1 <TAB> return ins, out, opts",if inOut & pythoncom . PARAMFLAG_FOUT :,198
"def _glsl_step(controls=None): <TAB> assert (controls[0], controls[-1]) == (0.0, 1.0) <TAB> ncolors = len(controls) - 1 <TAB> assert ncolors >= 2 <TAB> s = """" <TAB> for i in range(ncolors - 1): <TAB>  <TAB> if i == 0: <TAB>  <TAB>  <TAB> ifs = ""if (t < %.6f)"" % (controls[i + 1]) <MASK> ifs = ""else"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ifs = ""else if (t < %.6f)"" % (controls[i + 1]) <TAB>  <TAB> s += """"""%s {\n <TAB> return $color_%d;\n} """""" % (ifs, i) <TAB> return """"""vec4 colormap(float t) {\n%s\n}"""""" % s",elif i == ( ncolors - 2 ) :,196
"def _get_encoder(self): <TAB> block = rnn.HybridSequentialRNNCell() <TAB> with block.name_scope(): <TAB>  <TAB> for _ in range(self._num_layers): <TAB>  <TAB>  <TAB> block.add(contrib.rnn.LSTMPCell(self._hidden_size, self._projection_size)) <MASK> block.add(rnn.DropoutCell(self._encode_dropout)) <TAB> return block",if self . _encode_dropout :,106
"def test_decoded_motion_vectors_no_flag(self): <TAB> container = av.open(fate_suite(""h264/interlaced_crop.mp4"")) <TAB> stream = container.streams.video[0] <TAB> for packet in container.demux(stream): <TAB>  <TAB> for frame in packet.decode(): <TAB>  <TAB>  <TAB> vectors = frame.side_data.get(""MOTION_VECTORS"") <MASK> assert vectors is None <TAB>  <TAB>  <TAB>  <TAB> return",if not frame . key_frame :,125
"def _load_workflow_tag_set( <TAB> self, item, panel_dict, integrated_panel_dict, load_panel_dict, index=None): <TAB> try: <TAB>  <TAB> # TODO: should id be encoded? <TAB>  <TAB> workflow_id = item.get(""id"") <TAB>  <TAB> workflow = self._load_workflow(workflow_id) <TAB>  <TAB> self._workflows_by_id[workflow_id] = workflow <TAB>  <TAB> key = ""workflow_"" + workflow_id <MASK> panel_dict[key] = workflow <TAB>  <TAB> # Always load workflows into the integrated_panel_dict. <TAB>  <TAB> integrated_panel_dict.update_or_append(index, key, workflow) <TAB> except Exception: <TAB>  <TAB> log.exception(""Error loading workflow: %s"", workflow_id)",if load_panel_dict :,193
"def _get_hooked_name(self, addr): <TAB> hook_vma = None <TAB> hookdesc = ""<Unknown mapping>"" <TAB> for i in self.get_proc_maps(): <TAB>  <TAB> if addr >= i.vm_start and addr < i.vm_end: <TAB>  <TAB>  <TAB> hook_vma = i <TAB>  <TAB>  <TAB> break <TAB> if hook_vma: <MASK> hookdesc = linux_common.get_path(self, hook_vma.vm_file) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> hookdesc = ""[{0:x}:{1:x},{2}]"".format( <TAB>  <TAB>  <TAB>  <TAB> hook_vma.vm_start, hook_vma.vm_end, hook_vma.vm_flags <TAB>  <TAB>  <TAB> ) <TAB> return (hook_vma, hookdesc)",if hook_vma . vm_file :,200
"def create_backend(backend_name, cache_name, options): <TAB> if isinstance(backend_name, BaseCache): <TAB>  <TAB> return backend_name <TAB> if backend_name is None: <TAB>  <TAB> backend_name = _get_default_backend_name() <TAB> try: <TAB>  <TAB> return registry[backend_name](cache_name, **options) <TAB> except KeyError: <MASK> raise ImportError( <TAB>  <TAB>  <TAB>  <TAB> ""You must install the python package: %s"" <TAB>  <TAB>  <TAB>  <TAB> % _backend_dependencies[backend_name] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> 'Unsupported backend ""%s"" try one of: %s' <TAB>  <TAB>  <TAB>  <TAB> % (backend_name, "", "".join(registry.keys())) <TAB>  <TAB>  <TAB> )",if backend_name in _backend_dependencies :,196
"def version_11(cls, node, **kwargs): <TAB> # create an empty sequence first <TAB> tensor_dict = kwargs[""tensor_dict""] <TAB> dtype = tensor_dict[node.inputs[0]].dtype <TAB> input_sequence = tf.ragged.constant([], dtype=dtype) <TAB> # insert tensors at the end of sequence <TAB> for i in range(len(node.inputs)): <TAB>  <TAB> input_tensor = tf.expand_dims(tensor_dict[node.inputs[i]], 0) <MASK> output_seq = tf.RaggedTensor.from_tensor(input_tensor) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> output_seq = tf.concat([input_sequence, input_tensor], axis=0) <TAB>  <TAB> input_sequence = output_seq <TAB> return [output_seq]",if input_sequence . shape [ 0 ] == 0 :,194
"def addHeadlineMatches(self, poslist): <TAB> for p in poslist: <TAB>  <TAB> it = QtWidgets.QListWidgetItem(p.h, self.lw) <TAB>  <TAB> f = it.font() <TAB>  <TAB> f.setBold(True) <TAB>  <TAB> it.setFont(f) <MASK> return","if self . addItem ( it , ( p , None ) ) :",92
"def update(self, accounts, regions, parameters): <TAB> for account in accounts: <TAB>  <TAB> for region in regions: <TAB>  <TAB>  <TAB> instance = self.get_instance(account, region) <MASK> instance[""ParameterOverrides""] = parameters <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> instance[""ParameterOverrides""] = []",if parameters :,82
"def generate_tokens_with_regex(source_code, _=""""): <TAB> regx_regx = r""\/(\S*?[^\s\\]\/)+?(igm)*"" <TAB> regx_pattern = re.compile(regx_regx) <TAB> word_pattern = re.compile(r""\w+"") <TAB> tokens = func(source_code, r""|"" + regx_regx) <TAB> leading_by_word = False <TAB> for token in tokens: <MASK> for subtoken in func(token, _): <TAB>  <TAB>  <TAB>  <TAB> yield subtoken <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield token <TAB>  <TAB> if not token.isspace(): <TAB>  <TAB>  <TAB> leading_by_word = word_pattern.match(token)",if leading_by_word and regx_pattern . match ( token ) :,185
"def comparison(cls, nodelist): <TAB> if len(nodelist) > 4: <TAB>  <TAB> msg = ""Chained comparison not allowed in environment markers"" <TAB>  <TAB> raise SyntaxError(msg) <TAB> comp = nodelist[2][1] <TAB> cop = comp[1] <TAB> if comp[0] == token.NAME: <MASK> if cop == ""not"": <TAB>  <TAB>  <TAB>  <TAB> cop = ""not in"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> cop = ""is not"" <TAB> try: <TAB>  <TAB> cop = cls.get_op(cop) <TAB> except KeyError: <TAB>  <TAB> msg = repr(cop) + "" operator not allowed in environment markers"" <TAB>  <TAB> raise SyntaxError(msg) <TAB> return cop(cls.evaluate(nodelist[1]), cls.evaluate(nodelist[3]))",if len ( nodelist [ 2 ] ) == 3 :,197
"def _remove_imports_from_import_stmt( <TAB> self, local_name: str, import_node: cst.Import) -> None: <TAB> for import_alias in import_node.names: <MASK> prefix = import_alias.evaluated_name <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> prefix = import_alias.evaluated_alias <TAB>  <TAB> if local_name == prefix or local_name.startswith(f""{prefix}.""): <TAB>  <TAB>  <TAB> RemoveImportsVisitor.remove_unused_import( <TAB>  <TAB>  <TAB>  <TAB> self.context, <TAB>  <TAB>  <TAB>  <TAB> import_alias.evaluated_name, <TAB>  <TAB>  <TAB>  <TAB> asname=import_alias.evaluated_alias, <TAB>  <TAB>  <TAB> )",if import_alias . evaluated_alias is None :,171
"def __getitem__(self, key): <TAB> if key == slice(None): <TAB>  <TAB> return dict(self.items()) <TAB> with self.lock: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> with open(self._keypath(key), ""rb"") as f: <TAB>  <TAB>  <TAB>  <TAB> return self.deserialize(f) <TAB>  <TAB> except IOError as e: <MASK> raise <TAB>  <TAB>  <TAB> raise KeyError(key)",if e . errno != errno . ENOENT :,107
"def delete_decoding(self): <TAB> num = self.ui.combobox_decodings.currentIndex() <TAB> if num >= 0: <TAB>  <TAB> reply = QMessageBox.question( <TAB>  <TAB>  <TAB> self, <TAB>  <TAB>  <TAB> self.tr(""Delete Decoding?""), <TAB>  <TAB>  <TAB> self.tr( <TAB>  <TAB>  <TAB>  <TAB> ""Do you really want to delete "" <TAB>  <TAB>  <TAB>  <TAB> + ""'{}'?"".format(self.decodings[num].name) <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB> QMessageBox.Yes | QMessageBox.No, <TAB>  <TAB> ) <MASK> self.decodings.pop(num) <TAB>  <TAB>  <TAB> self.ui.combobox_decodings.removeItem(num) <TAB>  <TAB>  <TAB> self.save_to_file()",if reply == QMessageBox . Yes :,177
"def get(self, timeout=None): <TAB> start = time.time() <TAB> self.last = start <TAB> while True: <TAB>  <TAB> if self.shut: <TAB>  <TAB>  <TAB> raise e_exc.QueueShutdown() <TAB>  <TAB> with self.lock: <TAB>  <TAB>  <TAB> if self.items: <TAB>  <TAB>  <TAB>  <TAB> return self.items.popleft() <TAB>  <TAB>  <TAB> # Clear the event so we can wait... <TAB>  <TAB>  <TAB> self.event.clear() <TAB>  <TAB> deltat = None <TAB>  <TAB> if timeout: <TAB>  <TAB>  <TAB> deltat = max(0, timeout - (time.time() - start)) <MASK> return None",if not self . event . wait ( timeout = deltat ) :,162
"def main(): <TAB> # various smoke tests on an installed PyYAML with extension <TAB> if not getattr(yaml, ""_yaml"", None): <TAB>  <TAB> raise Exception(""C extension is not available at `yaml._yaml`"") <TAB> print(""embedded libyaml version is {0}"".format(yaml._yaml.get_version_string())) <TAB> for loader, dumper in [(yaml.CLoader, yaml.CDumper), (yaml.Loader, yaml.Dumper)]: <TAB>  <TAB> testyaml = ""dude: mar"" <TAB>  <TAB> loaded = yaml.load(testyaml, Loader=loader) <TAB>  <TAB> dumped = yaml.dump(loaded, Dumper=dumper) <MASK> raise Exception(""roundtrip failed with {0}/{1}"".format(loader, dumper)) <TAB> print(""smoke test passed for {0}"".format(sys.executable))",if testyaml != dumped . strip ( ) :,193
"def get_ordering_default(self): <TAB> if not self.ordering_default: <TAB>  <TAB> return ""asc"" <TAB> else: <MASK> raise ImproperlyConfigured( <TAB>  <TAB>  <TAB>  <TAB> ""{0} only allows asc or desc as ordering option"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.__class__.__name__ <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return self.ordering_default","if self . ordering_default not in [ ""asc"" , ""desc"" ] :",106
"def addListener(self, callback, last_id=None): <TAB> if last_id: <TAB>  <TAB> messages = self.getMessages(last_id) <MASK> return callback( <TAB>  <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""success"": True, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""result"": messages, <TAB>  <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB> ) <TAB> self.m_lock.acquire() <TAB> self.listeners.append((callback, last_id)) <TAB> self.m_lock.release()",if len ( messages ) > 0 :,127
"def cd_imagerepo(self, imagerepo, tag): <TAB> """"""Select an image TAG for further operations"""""" <TAB> if imagerepo and tag: <TAB>  <TAB> tag_dir = self.reposdir + ""/"" + imagerepo + ""/"" + tag <TAB>  <TAB> if os.path.exists(tag_dir): <MASK> self.cur_repodir = self.reposdir + ""/"" + imagerepo <TAB>  <TAB>  <TAB>  <TAB> self.cur_tagdir = self.cur_repodir + ""/"" + tag <TAB>  <TAB>  <TAB>  <TAB> return self.cur_tagdir <TAB> return """"",if self . _is_tag ( tag_dir ) :,141
"def test_songtypes(self): <TAB> from quodlibet import formats <TAB> pat = TagsFromPattern(""<tracknumber>. <title>"") <TAB> tracktitle = {""tracknumber"": ""01"", ""title"": ""Title""} <TAB> for ext, kind in formats.loaders.items(): <TAB>  <TAB> f = formats._audio.AudioFile() <TAB>  <TAB> if not isinstance(kind, type): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> f.__class__ = kind <MASK> f[""~filename""] = u""C:\\path\\Artist - Album\\01. Title"" + ext <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> f[""~filename""] = ""/path/Artist - Album/01. Title"" + ext <TAB>  <TAB> self.assertEquals(pat.match(f), tracktitle, ext)","if os . name == ""nt"" :",183
"def get_album(self, name, artist_name): <TAB> album = self.cache.get(artist_name, {}).get(""albums"", {}).get(name) <TAB> if not album: <TAB>  <TAB> artist = self.get_artist(artist_name) <TAB>  <TAB> log.debug('[ Last.FM ] Retrieving album ""%s"" by ""%s""' % (name, artist.name)) <TAB>  <TAB> with ignored(Exception, print_traceback=True): <TAB>  <TAB>  <TAB> album = self.lib.get_album(artist, name) <MASK> self.cache.update({artist.name: {""albums"": {album.name: album}}}) <TAB> return album",if album and self . use_cache :,163
"def OnReplaceAll(self, id, code): <TAB> control = _GetControl(None) <TAB> if control is not None: <TAB>  <TAB> control.SetSel(0) <TAB>  <TAB> num = 0 <TAB>  <TAB> if self.DoFindNext() == FOUND_NORMAL: <TAB>  <TAB>  <TAB> lastSearch.replaceText = self.editReplaceText.GetWindowText() <TAB>  <TAB>  <TAB> while _ReplaceIt(control) == FOUND_NORMAL: <TAB>  <TAB>  <TAB>  <TAB> num = num + 1 <TAB>  <TAB> win32ui.SetStatusText(""Replaced %d occurrences"" % num) <MASK> self.DestroyWindow()",if num > 0 and not self . butKeepDialogOpen . GetCheck ( ) :,157
"def __repr__(self): <TAB> """"""Return a compact unambiguous string representation of a property."""""" <TAB> args = [] <TAB> cls = self.__class__ <TAB> for i, attr in enumerate(self._attributes): <TAB>  <TAB> val = getattr(self, attr) <TAB>  <TAB> if val is not getattr(cls, attr): <MASK> s = val.__name__ <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> s = repr(val) <TAB>  <TAB>  <TAB> if i >= cls._positional: <TAB>  <TAB>  <TAB>  <TAB> if attr.startswith(""_""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> attr = attr[1:] <TAB>  <TAB>  <TAB>  <TAB> s = ""%s=%s"" % (attr, s) <TAB>  <TAB>  <TAB> args.append(s) <TAB> s = ""%s(%s)"" % (self.__class__.__name__, "", "".join(args)) <TAB> return s","if isinstance ( val , type ) :",197
"def match_data(self, data, max_pri=100, min_pri=0): <TAB> for priority in sorted(self.types.keys(), reverse=True): <TAB>  <TAB> # print priority, max_pri, min_pri <MASK> continue <TAB>  <TAB> if priority < min_pri: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> for type in self.types[priority]: <TAB>  <TAB>  <TAB> m = type.match(data) <TAB>  <TAB>  <TAB> if m: <TAB>  <TAB>  <TAB>  <TAB> return m",if priority > max_pri :,121
"def entitydecode(match): <TAB> entity = match.group(1) <TAB> # In some cases the entity is invalid and it triggers an exception <TAB> # in unichr, that's why I need to have a try/except <TAB> try: <TAB>  <TAB> if entity.startswith(""#x""): <TAB>  <TAB>  <TAB> return unichr(int(entity[2:], 16)) <TAB>  <TAB> elif entity.startswith(""#""): <TAB>  <TAB>  <TAB> return unichr(int(entity[1:])) <MASK> return unichr(name2codepoint[entity]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return match.group(0) <TAB> except: <TAB>  <TAB> return match.group(0)",elif entity in name2codepoint :,152
"def topology_sort(members): <TAB> topology = defaultdict(list) <TAB> leader = next((m for m in members if m[""role""].endswith(""leader"")), {""name"": None}) <TAB> replicas = set( <TAB>  <TAB> member[""name""] for member in members if not member[""role""].endswith(""leader"") <TAB> ) <TAB> for member in members: <TAB>  <TAB> if not member[""role""].endswith(""leader""): <TAB>  <TAB>  <TAB> parent = member.get(""tags"", {}).get(""replicatefrom"") <TAB>  <TAB>  <TAB> parent = ( <TAB>  <TAB>  <TAB>  <TAB> parent <MASK> else leader[""name""] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> topology[parent].append(member) <TAB> for member in generate_topology(0, leader, topology): <TAB>  <TAB> yield member","if parent and parent != member [ ""name"" ] and parent in replicas",196
"def remove_subsets_from_list_of_sets(list_of_sets: List[set]): <TAB> sets_to_delete = [] <TAB> for set1, set2 in combinations(list_of_sets, 2): <TAB>  <TAB> if set1.issubset(set2): <TAB>  <TAB>  <TAB> sets_to_delete.append(set1) <TAB>  <TAB> elif set2.issubset(set1): <TAB>  <TAB>  <TAB> sets_to_delete.append(set2) <TAB> for subset in sets_to_delete: <MASK> list_of_sets.remove(subset)",if subset in list_of_sets :,144
"def parse_line_thread(self): <TAB> for line in iter(self.bully_proc.pid.stdout.readline, b""""): <TAB>  <TAB> if line == """": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> line = line.decode(""utf-8"") <TAB>  <TAB> line = line.replace(""\r"", """").replace(""\n"", """").strip() <TAB>  <TAB> if Configuration.verbose > 1: <TAB>  <TAB>  <TAB> Color.pe(""\n{P} [bully:stdout] %s"" % line) <TAB>  <TAB> self.state = self.parse_state(line) <TAB>  <TAB> self.crack_result = self.parse_crack_result(line) <MASK> break",if self . crack_result :,162
"def __setattr__(self, name, value): <TAB> if name == ""value"": <MASK> raise TypeError(""must assign a string"") <TAB>  <TAB> elif self.readonly: <TAB>  <TAB>  <TAB> raise AttributeError(""control '%s' is readonly"" % self.name) <TAB>  <TAB> elif self.disabled: <TAB>  <TAB>  <TAB> raise AttributeError(""control '%s' is disabled"" % self.name) <TAB>  <TAB> self.__dict__[""_value""] = value <TAB> elif name in (""name"", ""type""): <TAB>  <TAB> raise AttributeError(""%s attribute is readonly"" % name) <TAB> else: <TAB>  <TAB> self.__dict__[name] = value",if not isstringlike ( value ) :,148
"def export_theme(wallpaper, json_path="".""): <TAB> """"""export a colorscheme to json format"""""" <TAB> try: <MASK> json_path = path.join(json_path, wallpaper + "".json"") <TAB>  <TAB> shutil.copy2(path.join(files.get_cache_path(wallpaper)), json_path) <TAB>  <TAB> logging.info(""theme for %s successfully exported"", wallpaper) <TAB> except IOError as e: <TAB>  <TAB> logging.error(""file not available"") <TAB>  <TAB> logging.error(e.message)",if path . isdir ( json_path ) :,134
"def OnIndentMore(self, evt): <TAB> attr = wx.TextAttr() <TAB> attr.SetFlags(wx.TEXT_ATTR_LEFT_INDENT) <TAB> ip = self.rtc.GetInsertionPoint() <TAB> if self.rtc.GetStyle(ip, attr): <TAB>  <TAB> r = rt.RichTextRange(ip, ip) <MASK> r = self.rtc.GetSelectionRange() <TAB>  <TAB> attr.SetLeftIndent(attr.GetLeftIndent() + 100) <TAB>  <TAB> attr.SetFlags(wx.TEXT_ATTR_LEFT_INDENT) <TAB>  <TAB> self.rtc.SetStyle(r, attr)",if self . rtc . HasSelection ( ) :,159
"def run(self): <TAB> self.thread.start() <TAB> while self.thread.isRunning(): <TAB>  <TAB> self.update.emit(config.percentage) <TAB>  <TAB> self.status.emit(config.status_text) <MASK> config.status_text = ""Please wait..."" <TAB>  <TAB> time.sleep(0.1) <TAB> self.update.emit(100) <TAB> self.update.emit(0) <TAB> config.percentage = 0 <TAB> self.status.emit(""Updating syslinux.cfg file..."") <TAB> if self.thread.isFinished(): <TAB>  <TAB> config.status_text = """" <TAB>  <TAB> self.finished.emit() <TAB> log(""Distro uninstall is complete..."") <TAB> return",if not self . thread . isFinished ( ) and config . percentage == 100 :,180
def test(): <TAB> for i in range(get_n(10)): <TAB>  <TAB> undefined = 10 <TAB>  <TAB> if get_false(): <TAB>  <TAB>  <TAB> del undefined <MASK> del undefined <TAB>  <TAB> if get_true(): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> undefined = 10 <TAB> else: <TAB>  <TAB> undefined = 20 <TAB> x = undefined,if get_true ( ) :,85
"def _dtype(self): <TAB> lmeasure = discover(self.lhs).measure <TAB> lty = getattr(lmeasure, ""ty"", lmeasure) <TAB> rmeasure = discover(self.rhs).measure <TAB> rty = getattr(rmeasure, ""ty"", rmeasure) <TAB> if lty == datetime_: <MASK> return optionify(lmeasure, rmeasure, timedelta_) <TAB>  <TAB> if isinstance(rty, TimeDelta): <TAB>  <TAB>  <TAB> return optionify(lmeasure, rmeasure, datetime_) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""can only subtract timedelta or datetime from datetime"", <TAB>  <TAB>  <TAB> ) <TAB> return super(Sub, self)._dtype","if isinstance ( rty , DateTime ) :",168
"def extract(self): <TAB> for l in self.splitlines(): <TAB>  <TAB> if len(l) < 2: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if l[0].startswith(""Node""): <TAB>  <TAB>  <TAB> zone = l[3] <TAB>  <TAB>  <TAB> found_high = 0 <TAB>  <TAB> if l[0].startswith(""pages""): <TAB>  <TAB>  <TAB> self.val[zone + ""_free""] = int(l[2]) <MASK> self.val[zone + ""_high""] = int(l[1]) <TAB>  <TAB>  <TAB> found_high = 1","if l [ 0 ] . startswith ( ""high"" ) and not found_high :",141
"def open(self, mode=""r""): <TAB> if self.read_only and mode != ""r"": <TAB>  <TAB> raise RuntimeError( <TAB>  <TAB>  <TAB> ""The backend has been loaded in read-only "" <TAB>  <TAB>  <TAB> ""mode. Set `read_only = False` to make "" <TAB>  <TAB>  <TAB> ""changes."" <TAB>  <TAB> ) <TAB> f = h5py.File(self.filename, mode) <TAB> if not self.dtype_set and self.name in f: <TAB>  <TAB> g = f[self.name] <MASK> self.dtype = g[""chain""].dtype <TAB>  <TAB>  <TAB> self.dtype_set = True <TAB> return f","if ""chain"" in g :",155
"def non_terminated_nodes(self, tag_filters): <TAB> workers = self.state.get() <TAB> matching_ips = [] <TAB> for worker_ip, info in workers.items(): <MASK> continue <TAB>  <TAB> ok = True <TAB>  <TAB> for k, v in tag_filters.items(): <TAB>  <TAB>  <TAB> if info[""tags""].get(k) != v: <TAB>  <TAB>  <TAB>  <TAB> ok = False <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if ok: <TAB>  <TAB>  <TAB> matching_ips.append(worker_ip) <TAB> return matching_ips","if info [ ""state"" ] == ""terminated"" :",137
"def __repr__(self): <TAB> try: <TAB>  <TAB> if self._semlock._is_mine(): <TAB>  <TAB>  <TAB> name = process.current_process().name <TAB>  <TAB>  <TAB> if threading.current_thread().name != ""MainThread"": <TAB>  <TAB>  <TAB>  <TAB> name += ""|"" + threading.current_thread().name <TAB>  <TAB> elif self._semlock._get_value() == 1: <TAB>  <TAB>  <TAB> name = ""None"" <MASK> name = ""SomeOtherThread"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = ""SomeOtherProcess"" <TAB> except Exception: <TAB>  <TAB> name = ""unknown"" <TAB> return ""<%s(owner=%s)>"" % (self.__class__.__name__, name)",elif self . _semlock . _count ( ) > 0 :,170
"def getShortcut(self, h): <TAB> """"""Return the keyboard shortcut from the given headline string"""""" <TAB> shortcut = None <TAB> i = h.find(""@key"") <TAB> if i > -1: <TAB>  <TAB> j = g.skip_ws(h, i + len(""@key"")) <TAB>  <TAB> if g.match(h, j, ""=""): <TAB>  <TAB>  <TAB> j += 1 <TAB>  <TAB> if 0: <TAB>  <TAB>  <TAB> shortcut = h[j:].strip() <TAB>  <TAB> else:  # new logic 1/3/2014 Jake Peck <TAB>  <TAB>  <TAB> k = h.find(""@"", j + 1) <MASK> k = len(h) <TAB>  <TAB>  <TAB> shortcut = h[j:k].strip() <TAB> return shortcut",if k == - 1 :,174
"def addClassConstant(self, name, vartype, doc=None): <TAB> """"""Add a constant variable into the current class."""""" <TAB> if self.currentClass: <TAB>  <TAB> phpConstant = self.currentClass.constants.get(name) <MASK> log.debug(""CLASS CONST: %r"", name) <TAB>  <TAB>  <TAB> self.currentClass.constants[name] = PHPConstant( <TAB>  <TAB>  <TAB>  <TAB> name, self.lineno, vartype, fileinfo=self.fileinfo <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> elif vartype: <TAB>  <TAB>  <TAB> log.debug( <TAB>  <TAB>  <TAB>  <TAB> ""Adding type information for CLASS CONST: %r, "" ""vartype: %r"", <TAB>  <TAB>  <TAB>  <TAB> name, <TAB>  <TAB>  <TAB>  <TAB> vartype, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> phpConstant.addType(self.lineno, vartype)",if phpConstant is None :,192
"def wakeup(self): <TAB> if not self._closed: <MASK> # Compat for python2.7 on windows, where poll return false for <TAB>  <TAB>  <TAB> # b"""" messages. Use the slightly larger message b""0"". <TAB>  <TAB>  <TAB> self._writer.send_bytes(b""0"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._writer.send_bytes(b"""")","if sys . platform == ""win32"" and sys . version_info [ : 2 ] < ( 3 , 4 ) :",115
"def __exit__(self, exc_type, exc_val, exc_tb): <TAB> with self.database._conn_lock: <TAB>  <TAB> if self.connection is None: <TAB>  <TAB>  <TAB> self.database.pop_execution_context() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> try: <MASK> if not exc_type: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.txn.commit(False) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.txn.__exit__(exc_type, exc_val, exc_tb) <TAB>  <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB>  <TAB> self.database.pop_execution_context() <TAB>  <TAB>  <TAB>  <TAB> self.database._close(self.connection)",if self . with_transaction :,164
"def testNumpy(self): <TAB> test_vals = [ <TAB>  <TAB> np.array(np.random.rand(100, 100)), <TAB>  <TAB> np.array(np.random.rand(100, 100).T), <TAB>  <TAB> np.array([""a"", ""bcd"", None]), <TAB> ] <TAB> for val in test_vals: <TAB>  <TAB> deserialized = deserialize(*serialize(val)) <TAB>  <TAB> self.assertEqual(type(val), type(deserialized)) <TAB>  <TAB> np.testing.assert_equal(val, deserialized) <MASK> self.assertTrue(deserialized.flags.f_contiguous)",if val . flags . f_contiguous :,144
"def sendMessage(self, chat_id=None, parse_mode=""Markdown"", text=None): <TAB> try: <MASK> self.connect() <TAB>  <TAB> self._tbot.sendMessage(chat_id=chat_id, parse_mode=parse_mode, text=text) <TAB> except telegram.error.NetworkError: <TAB>  <TAB> time.sleep(1) <TAB> except telegram.error.TelegramError: <TAB>  <TAB> time.sleep(10) <TAB> except telegram.error.Unauthorized: <TAB>  <TAB> self.update_id += 1",if self . _tbot is None :,135
"def process_formdata(self, valuelist): <TAB> if valuelist: <MASK> self.data = [ <TAB>  <TAB>  <TAB>  <TAB> self.coerce(v.strip()) for v in valuelist[0].split("","") if v.strip() <TAB>  <TAB>  <TAB> ] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.data = self.coerce(valuelist[0])",if self . save_as_list :,90
"def list_reduce(self, list1, list2): <TAB> value = 0 <TAB> for name in list1: <TAB>  <TAB> for name2 in list2: <TAB>  <TAB>  <TAB> if is_initial(name) and name[0] == name2[0]: <TAB>  <TAB>  <TAB>  <TAB> value += 0.25 <MASK> value += 0.25 <TAB>  <TAB>  <TAB> elif name == name2: <TAB>  <TAB>  <TAB>  <TAB> value += 0.5 <TAB>  <TAB>  <TAB> elif name[0] == name2[0] and self.name_compare(name, name2): <TAB>  <TAB>  <TAB>  <TAB> value += 0.25 <TAB> return min(value, 1) if value else -1",elif is_initial ( name2 ) and name2 [ 0 ] == name [ 0 ] :,173
"def config(self, **options): <TAB> for key, value in options.iteritems(): <TAB>  <TAB> if key == ""usetabs"": <TAB>  <TAB>  <TAB> self.usetabs = value <MASK> self.indentwidth = value <TAB>  <TAB> elif key == ""tabwidth"": <TAB>  <TAB>  <TAB> self.tabwidth = value <TAB>  <TAB> elif key == ""context_use_ps1"": <TAB>  <TAB>  <TAB> self.context_use_ps1 = value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise KeyError(""bad option name: %s"" % repr(key))","elif key == ""indentwidth"" :",134
"def _is_ipv6_enabled(): <TAB> """"""Check whether IPv6 is enabled on this host."""""" <TAB> if socket.has_ipv6: <TAB>  <TAB> sock = None <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> sock = socket.socket(socket.AF_INET6, socket.SOCK_STREAM) <TAB>  <TAB>  <TAB> sock.bind((""::1"", 0)) <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> except (socket.error, socket.gaierror): <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> finally: <MASK> sock.close() <TAB> return False",if sock :,129
"def get_value_of_satisfying_items(self, offer, basket): <TAB> covered_ids = [] <TAB> value = D(""0.00"") <TAB> for line in basket.all_lines(): <TAB>  <TAB> if self.can_apply_condition(line) and line.product.id not in covered_ids: <TAB>  <TAB>  <TAB> covered_ids.append(line.product.id) <TAB>  <TAB>  <TAB> value += unit_price(offer, line) <MASK> return value <TAB> return value",if len ( covered_ids ) >= self . value :,132
"def get_chunks(self): <TAB> try: <TAB>  <TAB> with open(self.path, ""rb"") as fd: <TAB>  <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB>  <TAB> chunk = fd.read(16 * 1024) <MASK> break <TAB>  <TAB>  <TAB>  <TAB> yield chunk <TAB> except Exception: <TAB>  <TAB> return",if not chunk :,82
"def batchSites(self, sites): <TAB> i = 0 <TAB> res = list() <TAB> siteList = list() <TAB> for site in sites: <TAB>  <TAB> if i >= self.opts[""_maxthreads""]: <TAB>  <TAB>  <TAB> data = self.threadSites(siteList) <MASK> return res <TAB>  <TAB>  <TAB> for ret in list(data.keys()): <TAB>  <TAB>  <TAB>  <TAB> if data[ret]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # bucket:filecount <TAB>  <TAB>  <TAB>  <TAB>  <TAB> res.append(ret + "":"" + str(data[ret])) <TAB>  <TAB>  <TAB> i = 0 <TAB>  <TAB>  <TAB> siteList = list() <TAB>  <TAB> siteList.append(site) <TAB>  <TAB> i += 1 <TAB> return res",if data is None :,169
"def __iter__(self): <TAB> for attr in self.__attrs__: <TAB>  <TAB> value = getattr(self, attr) <TAB>  <TAB> if attr.startswith(""_""): <TAB>  <TAB>  <TAB> attr = attr[1:] <MASK> yield attr, safe_string(value)","if attr != ""attr_text"" and value is not None :",75
"def _evaluateSequence(self, f, seq, verbose=False): <TAB> """"""Return the ponderated MSE over one sequence."""""" <TAB> totalError = 0.0 <TAB> ponderation = 0.0 <TAB> for input, target in seq: <TAB>  <TAB> res = f(input) <TAB>  <TAB> e = 0.5 * sum((target - res).flatten() ** 2) <TAB>  <TAB> totalError += e <TAB>  <TAB> ponderation += len(target) <MASK> print((""out: <TAB> "", fListToString(list(res)))) <TAB>  <TAB>  <TAB> print((""correct:"", fListToString(target))) <TAB>  <TAB>  <TAB> print((""error: % .8f"" % e)) <TAB> return totalError, ponderation",if verbose :,168
"def main(trans, webhook, params): <TAB> error = """" <TAB> data = {} <TAB> try: <TAB>  <TAB> if not params or ""tool_id"" not in params.keys(): <TAB>  <TAB>  <TAB> raise KeyError(""Tool id is missing."") <MASK> raise KeyError(""Tool version is missing."") <TAB>  <TAB> tool_id = params[""tool_id""] <TAB>  <TAB> tool_version = params[""tool_version""] <TAB>  <TAB> tour_generator = TourGenerator(trans, tool_id, tool_version) <TAB>  <TAB> data = tour_generator.get_data() <TAB> except Exception as e: <TAB>  <TAB> error = str(e) <TAB>  <TAB> log.exception(e) <TAB> return {""success"": not error, ""error"": error, ""data"": data}","if not params or ""tool_version"" not in params . keys ( ) :",187
"def __init__(self, config_path, s3_helper=None): <TAB> self.s3_helper = s3_helper <TAB> if config_path.startswith(""s3://""): <MASK> raise Exception(""No region set to get config file but it resides on S3"") <TAB>  <TAB> self.config = s3_helper.get_json_config_as_dict(config_path) <TAB> else: <TAB>  <TAB> with open(config_path) as f: <TAB>  <TAB>  <TAB> self.config = json.load(f)",if s3_helper is None :,133
"def lackadaisical_mkdir(place): <TAB> ok = False <TAB> place = path.realpath(place) <TAB> try: <TAB>  <TAB> os.makedirs(place, 0o700) <TAB>  <TAB> ok = True <TAB> except EnvironmentError as e: <MASK> # Has already been created: this is the most <TAB>  <TAB>  <TAB> # common situation, and is fine. <TAB>  <TAB>  <TAB> ok = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logger.warning( <TAB>  <TAB>  <TAB>  <TAB> msg=""could not create prefetch directory"", <TAB>  <TAB>  <TAB>  <TAB> detail=( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Prefetch directory creation target: {0}, {1}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> place, e.strerror <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB> ) <TAB> return ok",if e . errno == errno . EEXIST :,189
"def _initialize_weights(self): <TAB> for m in self.modules(): <TAB>  <TAB> if isinstance(m, nn.Conv2d): <TAB>  <TAB>  <TAB> n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels <TAB>  <TAB>  <TAB> m.weight.data.normal_(0, math.sqrt(2.0 / n)) <TAB>  <TAB>  <TAB> if m.bias is not None: <TAB>  <TAB>  <TAB>  <TAB> m.bias.data.zero_() <TAB>  <TAB> elif isinstance(m, nn.BatchNorm2d): <TAB>  <TAB>  <TAB> m.weight.data.fill_(0.5) <TAB>  <TAB>  <TAB> m.bias.data.zero_() <MASK> m.weight.data.normal_(0, 0.01) <TAB>  <TAB>  <TAB> m.bias.data.zero_()","elif isinstance ( m , nn . Linear ) :",194
"def assertRaises(self, exception, *args, **kw): <TAB> if args: <TAB>  <TAB> callable, *args = args <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> callable(*args, **kw) <TAB>  <TAB> except Exception as exc: <MASK> print(callable, args, kw, ""does not raise"", exception) <TAB> else: <TAB>  <TAB> return CtxManager(exception, **kw)","if not isinstance ( exc , exception ) :",101
"def __init__( <TAB> self, <TAB> choices, <TAB> callback, <TAB> cancel=None, <TAB> select=None, <TAB> separator="" "", <TAB> choices_to_return=None,): <TAB> self.choices = choices <TAB> self.choices_to_return = choices_to_return or {} <TAB> self.callback = callback <TAB> self.cancel = cancel <TAB> self.select = select <TAB> self.separator = separator <TAB> items = [] <TAB> for k, v in choices.items(): <MASK> items += [""["", k, ""]:"", v] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> items += [""("", k, ""):"", v] <TAB>  <TAB> items += [self.separator] <TAB> urwid.Text.__init__(self, items)",if v == select and select is not None :,183
"def readall(read_fn, sz): <TAB> buff = b"""" <TAB> have = 0 <TAB> while have < sz: <TAB>  <TAB> chunk = read_fn(sz - have) <TAB>  <TAB> have += len(chunk) <TAB>  <TAB> buff += chunk <MASK> raise TTransportException( <TAB>  <TAB>  <TAB>  <TAB> TTransportException.END_OF_FILE, ""End of file reading from transport"" <TAB>  <TAB>  <TAB> ) <TAB> return buff",if len ( chunk ) == 0 :,109
"def layout_len(layout): <TAB> r = 0 <TAB> for f in layout: <TAB>  <TAB> if isinstance(f[1], (int, tuple)):  # cases 1/2 <TAB>  <TAB>  <TAB> if len(f) == 3: <TAB>  <TAB>  <TAB>  <TAB> fname, fsize, fdirection = f <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> fname, fsize = f <MASK> # case 3 <TAB>  <TAB>  <TAB> fname, fsublayout = f <TAB>  <TAB>  <TAB> fsize = layout_len(fsublayout) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError <TAB>  <TAB> if isinstance(fsize, tuple): <TAB>  <TAB>  <TAB> r += fsize[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> r += fsize <TAB> return r","elif isinstance ( f [ 1 ] , list ) :",170
"def split(self, s, maxsplit=0): <TAB> res = [] <TAB> while True: <TAB>  <TAB> m = self.search(s) <TAB>  <TAB> g = None <TAB>  <TAB> if m: <TAB>  <TAB>  <TAB> g = m.group(0) <TAB>  <TAB> if not m or not g: <TAB>  <TAB>  <TAB> res.append(s) <TAB>  <TAB>  <TAB> return res <TAB>  <TAB> beg, end = m.span(0) <TAB>  <TAB> res.append(s[:beg]) <TAB>  <TAB> if m.num > 1: <TAB>  <TAB>  <TAB> res.extend(m.groups()) <TAB>  <TAB> s = s[end:] <TAB>  <TAB> if maxsplit > 0: <TAB>  <TAB>  <TAB> maxsplit -= 1 <MASK> res.append(s) <TAB>  <TAB>  <TAB>  <TAB> return res",if maxsplit == 0 :,180
"def _read(self, ignored, consumer, offset, size): <TAB> if isinstance(self.my_uri, uri.LiteralFileURI): <TAB>  <TAB> data = self.my_uri.data <TAB> else: <MASK> raise NotEnoughSharesError(None, 0, 3) <TAB>  <TAB> data = self.all_contents[self.my_uri.to_string()] <TAB> start = offset <TAB> if size is not None: <TAB>  <TAB> end = offset + size <TAB> else: <TAB>  <TAB> end = len(data) <TAB> consumer.write(data[start:end]) <TAB> return consumer",if self . my_uri . to_string ( ) not in self . all_contents :,163
"def _sloprovisioning_volume(self, url, params): <TAB> return_object = self.data.volume_list[2] <TAB> if ""/private"" in url: <TAB>  <TAB> return_object = self.data.private_vol_details <TAB> elif params: <TAB>  <TAB> if ""1"" in params.values(): <TAB>  <TAB>  <TAB> return_object = self.data.volume_list[0] <TAB>  <TAB> elif ""2"" in params.values(): <TAB>  <TAB>  <TAB> return_object = self.data.volume_list[1] <TAB> else: <TAB>  <TAB> for vol in self.data.volume_details: <MASK> return_object = vol <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return return_object","if vol [ ""volumeId"" ] in url :",173
"def main(): <TAB> import sys <TAB> import getopt <TAB> try: <TAB>  <TAB> opts, args = getopt.getopt(sys.argv[1:], ""ho:"", [""help"", ""output=""]) <TAB> except getopt.GetoptError as err: <TAB>  <TAB> usage() <TAB>  <TAB> sys.exit(1) <TAB> output = None <TAB> for o, a in opts: <MASK> usage() <TAB>  <TAB>  <TAB> sys.exit() <TAB>  <TAB> elif o in (""-o"", ""--output""): <TAB>  <TAB>  <TAB> output = a <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> usage() <TAB>  <TAB>  <TAB> sys.exit(1) <TAB> if not args: <TAB>  <TAB> usage() <TAB>  <TAB> sys.exit(1) <TAB> concat_ts(args, output)","if o in ( ""-h"" , ""--help"" ) :",176
"def _compute_training_loss(self, X, Y, iteration): <TAB> # optionally compute training loss for output / training curve <TAB> if self.show_loss_every != 0 and not iteration % self.show_loss_every: <MASK> self.loss_curve_ = [] <TAB>  <TAB> display_loss = 1 - self.score(X, Y) <TAB>  <TAB> if self.verbose > 0: <TAB>  <TAB>  <TAB> print(""current loss: %f"" % (display_loss)) <TAB>  <TAB> self.loss_curve_.append(display_loss)","if not hasattr ( self , ""loss_curve_"" ) :",139
"def save(self, *args, **kwargs): <TAB> if self.crop is True: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""PhotoSize width and/or height can not be zero if crop=True."" <TAB>  <TAB>  <TAB> ) <TAB> super(PhotoSize, self).save(*args, **kwargs) <TAB> PhotoSizeCache().reset() <TAB> self.clear_cache()",if self . width == 0 or self . height == 0 :,106
"def __setitem__(self, key, value): <TAB> if isinstance(key, int): <TAB>  <TAB> if self.is_list(): <TAB>  <TAB>  <TAB> if key >= len(self.value): <TAB>  <TAB>  <TAB>  <TAB> # DynamoDB doesn't care you are out of box just add it to the end. <TAB>  <TAB>  <TAB>  <TAB> self.value.append(value) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.value[key] = value <TAB> elif isinstance(key, six.string_types): <MASK> self.value[key] = value <TAB> else: <TAB>  <TAB> raise NotImplementedError(""No set_item for {t}"".format(t=type(key)))",if self . is_map ( ) :,158
"def update_email(self, email, name=None, change_name=True): <TAB> eid = self.EMAIL_IDS.get(email.lower()) <TAB> if (eid is not None) and not change_name: <TAB>  <TAB> el = self.EMAILS[eid].split("" "") <MASK> en = el[1][1:-1] <TAB>  <TAB>  <TAB> if ""@"" not in en: <TAB>  <TAB>  <TAB>  <TAB> name = en <TAB> return self.add_email(email, name=name, eid=eid)",if len ( el ) == 2 :,133
"def _get_rsc_path(self, rsc_name): <TAB> rsc_list_reply = self._get_api_resource_list() <TAB> for rsc in rsc_list_reply[""resources""]: <MASK> for volume in rsc[""vlms""]: <TAB>  <TAB>  <TAB>  <TAB> if volume[""vlmNr""] == 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return volume[""devicePath""]","if rsc [ ""name"" ] == rsc_name and rsc [ ""nodeName"" ] == self . host_name :",120
"def __get_albums_property(self, interface, name): <TAB> if interface == MediaContainer.IFACE: <TAB>  <TAB> if name == ""ChildCount"": <TAB>  <TAB>  <TAB> return len(self.__library) <TAB>  <TAB> elif name == ""ItemCount"": <TAB>  <TAB>  <TAB> return 0 <TAB>  <TAB> elif name == ""ContainerCount"": <TAB>  <TAB>  <TAB> return len(self.__library) <TAB>  <TAB> elif name == ""Searchable"": <TAB>  <TAB>  <TAB> return False <TAB> elif interface == MediaObject.IFACE: <TAB>  <TAB> if name == ""Parent"": <TAB>  <TAB>  <TAB> return self.parent.PATH <TAB>  <TAB> elif name == ""Type"": <TAB>  <TAB>  <TAB> return ""container"" <MASK> return self.PATH <TAB>  <TAB> elif name == ""DisplayName"": <TAB>  <TAB>  <TAB> return self.DISPLAY_NAME","elif name == ""Path"" :",184
"def _get_line(self, n, attempt_to_read=True): <TAB> try: <TAB>  <TAB> return self.lines[n] <TAB> except (KeyError, IndexError): <TAB>  <TAB> if attempt_to_read and self.source_is_stream: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> for l in self.source: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.lines.append(l) <MASK> break <TAB>  <TAB>  <TAB> except UnicodeError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> return self._get_line(n, attempt_to_read=False) <TAB>  <TAB> return """"",if len ( self . lines ) > n :,154
"def home_exists(self, home, schema_name, verrors, old=None): <TAB> home_filters = [(""home"", ""="", True)] <TAB> home_result = None <TAB> if home: <TAB>  <TAB> if old and old[""id""] is not None: <TAB>  <TAB>  <TAB> id = old[""id""] <MASK> home_filters.append((""id"", ""!="", id)) <TAB>  <TAB>  <TAB>  <TAB> # The user already had this set as the home share <TAB>  <TAB>  <TAB>  <TAB> home_result = await self.middleware.call( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""datastore.query"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._config.datastore, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> home_filters, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> {""prefix"": self._config.datastore_prefix}, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return home_result","if not old [ ""home"" ] :",191
"def propagate_function_calls(self): <TAB> for f in self.functions_and_modifiers: <TAB>  <TAB> for node in f.nodes: <TAB>  <TAB>  <TAB> for ir in node.irs_ssa: <MASK> ir.function.add_reachable_from_node(node, ir)","if isinstance ( ir , InternalCall ) :",83
"def remove(self, obj, config, cache_key): <TAB> request = get_request() <TAB> if request: <TAB>  <TAB> caches_dict = request.session.setdefault(self.CONTAINER_KEY, {}) <TAB>  <TAB> model_cache = caches_dict.get(cache_key, {}) <MASK> model_cache = strip_old_objects(model_cache, config[""cache_time""]) <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> del model_cache[obj.pk] <TAB>  <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> caches_dict[cache_key] = model_cache",if model_cache :,146
"def convert(self, source, destination): <TAB> tmpdir = tempfile.mkdtemp() <TAB> self._log(""Temporary dir {} created"".format(tmpdir)) <TAB> try: <TAB>  <TAB> self._log(""Prepare csv data"") <TAB>  <TAB> csv_data, data_files = self.createCsvData(source) <MASK> self._log(""Prepare tar file"") <TAB>  <TAB>  <TAB> name = os.path.splitext(os.path.basename(source))[0] <TAB>  <TAB>  <TAB> tarfile = self.createTemporaryTar(name, csv_data, data_files, tmpdir) <TAB>  <TAB>  <TAB> shutil.copyfile(tarfile, destination) <TAB> finally: <TAB>  <TAB> shutil.rmtree(tmpdir, ignore_errors=True) <TAB>  <TAB> self._log(""Temporary dir removed"")",if csv_data is not None :,179
"def find_addresses(): <TAB> # originally by Greg Smith, hacked by Zooko and then Daira <TAB> # We don't reach here for cygwin. <TAB> if platform == ""win32"": <TAB>  <TAB> commands = _win32_commands <TAB> else: <TAB>  <TAB> commands = _unix_commands <TAB> for (pathtotool, args, regex) in commands: <TAB>  <TAB> if platform != ""win32"": <TAB>  <TAB>  <TAB> assert os.path.isabs(pathtotool), pathtotool <TAB>  <TAB> if not os.path.isfile(pathtotool): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> addresses = _query(pathtotool, args, regex) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> addresses = [] <MASK> return addresses <TAB> return [""127.0.0.1""]",if addresses :,200
"def match(self, node: Node) -> bool: <TAB> try: <TAB>  <TAB> if self.classes and not isinstance(node, self.classes): <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> if self.attrs: <TAB>  <TAB>  <TAB> if not isinstance(node, nodes.Element): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> for key, value in self.attrs.items(): <TAB>  <TAB>  <TAB>  <TAB> if key not in node: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <MASK> continue <TAB>  <TAB>  <TAB>  <TAB> elif node.get(key) != value: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True <TAB> except Exception: <TAB>  <TAB> # for non-Element nodes <TAB>  <TAB> return False",elif value is Any :,167
"def __str__(self): <TAB> if not six.PY3 and hasattr(self, ""__unicode__""): <MASK> klass_name = type(self).__name__ <TAB>  <TAB>  <TAB> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB> ""%s.__unicode__ is aliased to __str__. Did"" <TAB>  <TAB>  <TAB>  <TAB> "" you apply @python_2_unicode_compatible"" <TAB>  <TAB>  <TAB>  <TAB> "" without defining __str__?"" % klass_name <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return force_text(self).encode(""utf-8"") <TAB> return ""%s object"" % self.__class__.__name__",if type ( self ) . __unicode__ == Model . __str__ :,145
"def get_connection(self, url, proxies=None): <TAB> with self.pools.lock: <TAB>  <TAB> pool = self.pools.get(url) <MASK> return pool <TAB>  <TAB> pool = UnixHTTPConnectionPool( <TAB>  <TAB>  <TAB> url, self.socket_path, self.timeout, maxsize=self.max_pool_size <TAB>  <TAB> ) <TAB>  <TAB> self.pools[url] = pool <TAB> return pool",if pool :,102
"def execute_job(self, job, queue): <TAB> statsd_client.incr(""rq.jobs.running.{}"".format(queue.name)) <TAB> statsd_client.incr(""rq.jobs.started.{}"".format(queue.name)) <TAB> try: <TAB>  <TAB> super().execute_job(job, queue) <TAB> finally: <TAB>  <TAB> statsd_client.decr(""rq.jobs.running.{}"".format(queue.name)) <MASK> statsd_client.incr(""rq.jobs.finished.{}"".format(queue.name)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> statsd_client.incr(""rq.jobs.failed.{}"".format(queue.name))",if job . get_status ( ) == JobStatus . FINISHED :,169
"def get_schema(self, routes: typing.List[BaseRoute]) -> dict: <TAB> schema = dict(self.base_schema) <TAB> schema.setdefault(""paths"", {}) <TAB> endpoints_info = self.get_endpoints(routes) <TAB> for endpoint in endpoints_info: <TAB>  <TAB> parsed = self.parse_docstring(endpoint.func) <TAB>  <TAB> if not parsed: <TAB>  <TAB>  <TAB> continue <MASK> schema[""paths""][endpoint.path] = {} <TAB>  <TAB> schema[""paths""][endpoint.path][endpoint.http_method] = parsed <TAB> return schema","if endpoint . path not in schema [ ""paths"" ] :",141
def verify_logs_filter(files): <TAB> to_verify = [] <TAB> for filename in files: <TAB>  <TAB> verify_file = True <TAB>  <TAB> for scheme in DEFAULT_SCHEMES: <TAB>  <TAB>  <TAB> if filename.startswith(scheme): <TAB>  <TAB>  <TAB>  <TAB> verify_file = False <TAB>  <TAB>  <TAB>  <TAB> break <MASK> to_verify.append(filename) <TAB> return to_verify,if verify_file :,96
"def _validate_version(version): <TAB> """"""Validate requested SSH version"""""" <TAB> if version == (): <TAB>  <TAB> from .version import __version__ <TAB>  <TAB> version = b""AsyncSSH_"" + __version__.encode(""ascii"") <TAB> else: <TAB>  <TAB> if isinstance(version, str): <TAB>  <TAB>  <TAB> version = version.encode(""ascii"") <TAB>  <TAB> # Version including 'SSH-2.0-' and CRLF must be 255 chars or less <TAB>  <TAB> if len(version) > 245: <TAB>  <TAB>  <TAB> raise ValueError(""Version string is too long"") <TAB>  <TAB> for b in version: <MASK> raise ValueError(""Version string must be printable ASCII"") <TAB> return version",if b < 0x20 or b > 0x7E :,168
"def get_serializer_class(self): <TAB> if ""identifier_id"" in self.kwargs: <TAB>  <TAB> referent = self.get_object().referent <TAB>  <TAB> if isinstance(referent, Node): <TAB>  <TAB>  <TAB> return NodeIdentifierSerializer <TAB>  <TAB> if isinstance(referent, Registration): <TAB>  <TAB>  <TAB> return RegistrationIdentifierSerializer <MASK> return PreprintIdentifierSerializer <TAB> return JSONAPISerializer","if isinstance ( referent , Preprint ) :",106
"def jointhreads(): <TAB> """"""Join all threads to the main thread"""""" <TAB> for thread in threading.enumerate(): <TAB>  <TAB> if hasattr(thread, ""BUGGY""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if thread.getName() != ""MainThread"" and thread.isAlive(): <MASK> thread.close() <TAB>  <TAB>  <TAB> thread.join(1) <TAB>  <TAB>  <TAB> if thread.isAlive(): <TAB>  <TAB>  <TAB>  <TAB> print(""Thread problem. Some thread doesn't want to stop."") <TAB>  <TAB>  <TAB>  <TAB> thread.BUGGY = True","if hasattr ( thread , ""close"" ) :",133
"def clean_fields(fields, prefix, group): <TAB> for field in fields: <TAB>  <TAB> clean_string_field(field, ""description"") <TAB>  <TAB> clean_string_field(field, ""footnote"") <TAB>  <TAB> clean_string_field(field, ""example"") <TAB>  <TAB> clean_string_field(field, ""type"") <TAB>  <TAB> # Add prefix if needed <MASK> field[""name""] = prefix + ""."" + field[""name""] <TAB>  <TAB> if ""level"" not in field.keys(): <TAB>  <TAB>  <TAB> field[""level""] = ""(use case)"" <TAB>  <TAB> if ""group"" not in field.keys(): <TAB>  <TAB>  <TAB> # If no group set, set parent group <TAB>  <TAB>  <TAB> field[""group""] = group","if prefix != """" :",169
"def _auth(api_key=None, profile=""telemetry""): <TAB> # return telemetry api key in the header <TAB> if api_key is None and profile is None: <TAB>  <TAB> raise Exception(""Missing api_key and profile"") <TAB> if profile: <MASK> _profile = __salt__[""config.option""](profile) <TAB>  <TAB> elif isinstance(profile, dict): <TAB>  <TAB>  <TAB> _profile = profile <TAB>  <TAB> if _profile: <TAB>  <TAB>  <TAB> api_key = _profile.get(""telemetry_api_keys"")[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception(""Missing api_key"") <TAB> return {""Telemetry-API-Key"": api_key, ""content-type"": ""application/json""}","if isinstance ( profile , six . string_types ) :",178
"def _on_error(func, path, exc_info): <TAB> try: <MASK> path = windows_long_path(path) <TAB>  <TAB> parent_path = os.path.dirname(path) <TAB>  <TAB> if not os.access(parent_path, os.W_OK): <TAB>  <TAB>  <TAB> st = os.stat(parent_path) <TAB>  <TAB>  <TAB> os.chmod(parent_path, st.st_mode | stat.S_IWUSR) <TAB>  <TAB> if not os.access(path, os.W_OK): <TAB>  <TAB>  <TAB> st = os.stat(path) <TAB>  <TAB>  <TAB> os.chmod(path, st.st_mode | stat.S_IWUSR) <TAB> except: <TAB>  <TAB> # avoid confusion by ensuring original exception is reraised <TAB>  <TAB> pass <TAB> func(path)",if is_windows :,192
"def get_object(self, g=None): <TAB> from numpy import frombuffer <TAB> data = self.buffers[0] <TAB> if self.pickled: <TAB>  <TAB> from . import serialize <TAB>  <TAB> # we just pickled it <TAB>  <TAB> return serialize.pickle.loads(buffer_to_bytes_py2(data)) <TAB> else: <MASK> # frombuffer doesn't accept memoryviews on Python 2, <TAB>  <TAB>  <TAB> # so cast to old-style buffer <TAB>  <TAB>  <TAB> data = buffer(data.tobytes()) <TAB>  <TAB> return frombuffer(data, dtype=self.dtype).reshape(self.shape)","if not py3compat . PY3 and isinstance ( data , memoryview ) :",155
"def do_handshake(self, block=False): <TAB> """"""Perform a TLS/SSL handshake."""""" <TAB> self._check_connected() <TAB> timeout = self.gettimeout() <TAB> try: <TAB>  <TAB> if timeout == 0.0 and block: <TAB>  <TAB>  <TAB> self.settimeout(None) <TAB>  <TAB> self._sslobj.do_handshake() <TAB> finally: <TAB>  <TAB> self.settimeout(timeout) <TAB> if self.context.check_hostname: <MASK> raise ValueError(""check_hostname needs server_hostname "" ""argument"") <TAB>  <TAB> match_hostname(self.getpeercert(), self.server_hostname)",if not self . server_hostname :,150
"def is_query(body): <TAB> # FIXME: handle urlencoded requests too in the future <TAB> try: <TAB>  <TAB> content = json.loads(body) <MASK> content = [content] <TAB>  <TAB> ret = all([""query"" in c or ""operationName"" in c for c in content]) <TAB>  <TAB> return ret <TAB> except: <TAB>  <TAB> return False","if not isinstance ( content , list ) :",93
"def actually_bytes(stringy): <TAB> if PY_3_OR_HIGHER: <TAB>  <TAB> if type(stringy) == bytes: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> elif type(stringy) != str: <TAB>  <TAB>  <TAB> stringy = str(stringy) <TAB>  <TAB> if type(stringy) == str: <TAB>  <TAB>  <TAB> stringy = stringy.encode(""utf-8"") <TAB> else: <TAB>  <TAB> if type(stringy) == str: <TAB>  <TAB>  <TAB> pass <MASK> stringy = str(stringy) <TAB>  <TAB> if type(stringy) == unicode: <TAB>  <TAB>  <TAB> stringy = stringy.encode(""utf-8"") <TAB> return stringy",elif type ( stringy ) != unicode :,167
"def Clean(): <TAB> """"""Clean out compiled protos."""""" <TAB> # Find all the compiled proto files and unlink them. <TAB> for (root, _, files) in os.walk(ROOT): <TAB>  <TAB> for filename in files: <TAB>  <TAB>  <TAB> full_filename = os.path.join(root, filename) <MASK> os.unlink(full_filename)","if full_filename . endswith ( ""_pb2.py"" ) or full_filename . endswith ( ""_pb2.pyc"" ) :",108
"def get_vpc_offering(self, vpc_offering_name): <TAB> cs_args = { <TAB>  <TAB> ""command"": ""listVPCOfferings"", <TAB> } <TAB> vpc_offerings = self._cs.request(cs_args) <TAB> if vpc_offerings and ""vpcoffering"" in vpc_offerings: <TAB>  <TAB> for vpc_off in vpc_offerings[""vpcoffering""]: <MASK> return vpc_off <TAB> return None","if vpc_off [ ""name"" ] == vpc_offering_name :",136
def proto_flow(self): <TAB> self.proto_logger() <TAB> if self.create_conn_obj(): <TAB>  <TAB> self.enum_host_info() <TAB>  <TAB> self.print_host_info() <TAB>  <TAB> self.login() <MASK> self.call_modules() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.call_cmd_args(),"if hasattr ( self . args , ""module"" ) and self . args . module :",103
"def box_text_before(box): <TAB> if isinstance(box, boxes.ParentBox): <TAB>  <TAB> return """".join( <TAB>  <TAB>  <TAB> box_text(child) <TAB>  <TAB>  <TAB> for child in box.descendants() <MASK> and not isinstance(child, boxes.ParentBox) <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> return """"","if child . element_tag . endswith ( ""::before"" )",94
"def fizzbuzz(n): <TAB> # Validate the input <TAB> if n < 1: <TAB>  <TAB> raise ValueError(""n cannot be less than one"") <TAB> if n is None: <TAB>  <TAB> raise TypeError(""n cannot be None"") <TAB> result = [] <TAB> for i in range(1, n + 1): <TAB>  <TAB> if i % 3 == 0 and i % 5 == 0: <TAB>  <TAB>  <TAB> result.append(""FizzBuzz"") <TAB>  <TAB> elif i % 3 == 0: <TAB>  <TAB>  <TAB> result.append(""Fizz"") <MASK> result.append(""Buzz"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result.append(i) <TAB> return result",elif i % 5 == 0 :,164
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_sort_expression(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 16: <TAB>  <TAB>  <TAB> self.set_sort_descending(d.getBoolean()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 34: <TAB>  <TAB>  <TAB> self.set_default_value_text(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 41: <TAB>  <TAB>  <TAB> self.set_default_value_numeric(d.getDouble()) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,188
def get_mode(self): <TAB> if self.mode: <TAB>  <TAB> if self.mode == self.common.gui.MODE_SHARE: <TAB>  <TAB>  <TAB> return self.share_mode <MASK> return self.receive_mode <TAB>  <TAB> elif self.mode == self.common.gui.MODE_CHAT: <TAB>  <TAB>  <TAB> return self.chat_mode <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.website_mode <TAB> else: <TAB>  <TAB> return None,elif self . mode == self . common . gui . MODE_RECEIVE :,127
"def _clean_header(self, line): <TAB> for idx, el in enumerate(line): <TAB>  <TAB> el = el.lower() <MASK> line[idx] = ""RT"" <TAB>  <TAB> elif el.startswith(""int""): <TAB>  <TAB>  <TAB> line[idx] = ""intensity"" <TAB>  <TAB> elif el.startswith(""mz""): <TAB>  <TAB>  <TAB> line[idx] = ""m/z"" <TAB>  <TAB> elif el.startswith(""charge""): <TAB>  <TAB>  <TAB> line[idx] = ""charge"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if idx // 4 > 0: <TAB>  <TAB>  <TAB> line[idx] += str(idx // 4) <TAB> return line","if el . startswith ( ""rt"" ) :",160
"def _change_case(col: str, case_type: str) -> str: <TAB> """"""Change case of a column name."""""" <TAB> case_types = [""preserve"", ""upper"", ""lower"", ""snake""] <TAB> if case_type.lower() not in case_types: <TAB>  <TAB> raise JanitorError(f""case_type must be one of: {case_types}"") <TAB> if case_type.lower() != ""preserve"": <TAB>  <TAB> if case_type.lower() == ""upper"": <TAB>  <TAB>  <TAB> col = col.upper() <MASK> col = col.lower() <TAB>  <TAB> elif case_type.lower() == ""snake"": <TAB>  <TAB>  <TAB> col = _camel2snake(col) <TAB> return col","elif case_type . lower ( ) == ""lower"" :",182
"def generateTypedValueNode(self, node): <TAB> try: <TAB>  <TAB> val = str(node) <MASK> val = re.sub(""\\*"", "".*"", val) <TAB>  <TAB> return self.typedValueExpression[type(node)] % (val) <TAB> except KeyError: <TAB>  <TAB> raise NotImplementedError( <TAB>  <TAB>  <TAB> ""Type modifier '{}' is not supported by backend"".format(node.identifier) <TAB>  <TAB> )","if ""*"" in val :",101
"def define_function(self, name, params, replacements): <TAB> # TODO check not already existing in objects or functions <TAB> for r in replacements: <TAB>  <TAB> if hasattr(r, ""lexer""): <TAB>  <TAB>  <TAB> del r.lexer <TAB> replacements = list(replacements) <TAB> params = list(params) <TAB> numargs = len(params) <TAB> for i, t in enumerate(replacements): <TAB>  <TAB> if hasattr(t, ""lexer""): <TAB>  <TAB>  <TAB> del t.lexer <TAB>  <TAB> if t.type == ""IDENTIFIER"" and t.value in params: <TAB>  <TAB>  <TAB> replacements[i] = params.index(t.value) <MASK> replacements[i] = len(params) - 1 <TAB> self.functions[name] = replacements, numargs","elif t . type == ""IDENTIFIER"" and t . value == ""__VA_ARGS__"" and ""..."" in params :",196
"def __check_limits(self): <TAB> if self.locust_start_time is None: <TAB>  <TAB> self.locust_start_time = time.time() <TAB> # Only raise an exception if the actual test is running <TAB> if self.locust_stop_time is None: <MASK> raise StopUser(""Duration limit reached"") <TAB>  <TAB> if self.num_requests <= 0: <TAB>  <TAB>  <TAB> raise StopUser(""Request limit reached"")",if time . time ( ) - self . locust_start_time >= self . locust_duration :,127
"def tovar(self): <TAB> parts = [self.var.name] <TAB> for arg in self.args: <TAB>  <TAB> if isinstance(arg, (int, float)): <TAB>  <TAB>  <TAB> parts.append(repr(arg).replace(""-"", ""_min_"")) <MASK> parts.append(arg.name) <TAB>  <TAB> elif arg is None: <TAB>  <TAB>  <TAB> parts.append(""None"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> s = """" <TAB>  <TAB>  <TAB> s += repr(arg.start) <TAB>  <TAB>  <TAB> s += ""_"" <TAB>  <TAB>  <TAB> s += repr(arg.stop) <TAB>  <TAB>  <TAB> s += ""_"" <TAB>  <TAB>  <TAB> s += repr(arg.step) <TAB>  <TAB>  <TAB> parts.append(s) <TAB> return ""__"".join(parts)","elif isinstance ( arg , Var ) :",179
"def extract_paths_from_string(str): <TAB> # Check we have a correct number of quotes <TAB> if str.count('""') == 4 or str.count(""'"") == 4: <TAB>  <TAB> # Try to get from double quotes <TAB>  <TAB> paths = re.findall(r""\""(.+?)\"""", str) <MASK> return paths[0], paths[1] <TAB>  <TAB> # Try to get from single quotes <TAB>  <TAB> paths = re.findall(r""\'(.+?)\'"", str) <TAB>  <TAB> if len(paths) == 2: <TAB>  <TAB>  <TAB> return paths[0], paths[1] <TAB> # Error <TAB> return None, None",if len ( paths ) == 2 :,154
"def _check_plugin_version(plugin_module, plugin_name): <TAB> if hasattr(plugin_module, ""pyb_version"") and plugin_module.pyb_version: <MASK> raise IncompatiblePluginException( <TAB>  <TAB>  <TAB>  <TAB> plugin_name, plugin_module.pyb_version, PYB_VERSION <TAB>  <TAB>  <TAB> )","if not version_satisfies_spec ( plugin_module . pyb_version , PYB_VERSION ) :",101
"def get_out_regs(self, block): <TAB> regs_todo = super(self.__class__, self).get_out_regs(block) <TAB> out = {} <TAB> for assignblk in block: <TAB>  <TAB> for dst in assignblk: <TAB>  <TAB>  <TAB> reg = self.ssa_var.get(dst, None) <TAB>  <TAB>  <TAB> if reg is None: <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> out[reg] = dst <TAB> return set(viewvalues(out))",if reg in regs_todo :,124
"def _process_attachment_filters(query, filters): <TAB> if filters: <TAB>  <TAB> project_id = filters.pop(""project_id"", None) <TAB>  <TAB> # Ensure that filters' keys exist on the model <MASK> return <TAB>  <TAB> if project_id: <TAB>  <TAB>  <TAB> volume = models.Volume <TAB>  <TAB>  <TAB> query = query.filter( <TAB>  <TAB>  <TAB>  <TAB> volume.id == models.VolumeAttachment.volume_id, <TAB>  <TAB>  <TAB>  <TAB> volume.project_id == project_id, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> query = query.filter_by(**filters) <TAB> return query","if not is_valid_model_filters ( models . VolumeAttachment , filters ) :",157
"def _print_run_info_ordered(data): <TAB> for name, val in data: <MASK> _print_run_info_list(name, val) <TAB>  <TAB> elif isinstance(val, dict): <TAB>  <TAB>  <TAB> _print_run_info_dict(name, val) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> cli.out(""%s: %s"" % (name, val))","if isinstance ( val , list ) :",100
"def scan_folder(self, folder: Path, index: Callable): <TAB> if folder.exists(): <TAB>  <TAB> log.debug(""scanning %s"", folder) <TAB>  <TAB> for pth in folder.iterdir(): <TAB>  <TAB>  <TAB> if pth.is_dir(): <TAB>  <TAB>  <TAB>  <TAB> # IGNORE_FOLDERS for comparing against 'self' <TAB>  <TAB>  <TAB>  <TAB> if pth not in self._ignore_folders: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.scan_folder(pth, index) <MASK> if not pth.match(self._ignore_files): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.count += index(pth) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if self.count and self.count % 20000 == 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._db.store()",elif not pth . is_symlink ( ) :,181
"def _CompileAll(pat_list): <TAB> # type: (List[Tuple[bool, str, Id_t]]) -> LexerPairs <TAB> result = [] <TAB> for is_regex, pat, token_id in pat_list: <MASK> pat = re.escape(pat)  # type: ignore  # turn $ into \$ <TAB>  <TAB> result.append((re.compile(pat), token_id))  # type: ignore <TAB> return result",if not is_regex :,113
"def chunk_tag(evidence): <TAB> result = set() <TAB> tree = evidence.segment.lex_trees[0] <TAB> for i, _ in enumerate(tree.leaves()): <TAB>  <TAB> path = tree.leaf_treeposition(i) <TAB>  <TAB> parent = walk_tree(tree, path[:-2]) <TAB>  <TAB> parent_label = parent.label() <TAB>  <TAB> position_in_sentence = path[-2] <MASK> tag = ""O"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> modifier = ""B"" if position_in_sentence == 0 else ""I"" <TAB>  <TAB>  <TAB> tag = ""{}-{}"".format(modifier, parent_label) <TAB>  <TAB> result.add(tag) <TAB> return result","if parent_label == ""S"" :",170
"def main(): <TAB> for i, filename in enumerate(os.listdir(""acdde83f055b5bf9211d9ca1cbafbce2"")): <TAB>  <TAB> if i % 8 != int(sys.argv[1]): <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> print(i, filename, '""%s""' % solve(filename))","if ""."" in filename :",88
"def __setattr__(self, name, value): <TAB> if name == ""value"": <TAB>  <TAB> if not isstringlike(value): <TAB>  <TAB>  <TAB> raise TypeError(""must assign a string"") <MASK> raise AttributeError(""control '%s' is readonly"" % self.name) <TAB>  <TAB> elif self.disabled: <TAB>  <TAB>  <TAB> raise AttributeError(""control '%s' is disabled"" % self.name) <TAB>  <TAB> self.__dict__[""_value""] = value <TAB> elif name in (""name"", ""type""): <TAB>  <TAB> raise AttributeError(""%s attribute is readonly"" % name) <TAB> else: <TAB>  <TAB> self.__dict__[name] = value",elif self . readonly :,148
"def FlattenBlocks(blocks): <TAB> insts = [] <TAB> pc = 0 <TAB> offsets = {}  # block -> bytecode offset <TAB> for b in blocks: <TAB>  <TAB> offsets[b] = pc <TAB>  <TAB> for inst in b.Instructions(): <TAB>  <TAB>  <TAB> insts.append(inst) <MASK> pc += 1 <TAB>  <TAB>  <TAB> elif inst[0] != ""SET_LINENO"":  # arg takes 2 bytes <TAB>  <TAB>  <TAB>  <TAB> pc += 3 <TAB> return insts, offsets",if len ( inst ) == 1 :,121
"def getLanguage(users): <TAB> i = 0 <TAB> count = len(users) <TAB> for user in users: <TAB>  <TAB> i += 1 <TAB>  <TAB> user, gmail = buildGmailGAPIObject(user) <MASK> continue <TAB>  <TAB> result = gapi.call( <TAB>  <TAB>  <TAB> gmail.users().settings(), ""getLanguage"", soft_errors=True, userId=""me"" <TAB>  <TAB> ) <TAB>  <TAB> if result: <TAB>  <TAB>  <TAB> print( <TAB>  <TAB>  <TAB>  <TAB> f'User: {user}, Language: {result[""displayLanguage""]}{currentCount(i, count)}' <TAB>  <TAB>  <TAB> )",if not gmail :,146
"def _parse_relation(element): <TAB> new_relation = Relation() <TAB> new_relation.entry1 = int(element.attrib[""entry1""]) <TAB> new_relation.entry2 = int(element.attrib[""entry2""]) <TAB> new_relation.type = element.attrib[""type""] <TAB> for subtype in element: <TAB>  <TAB> name, value = subtype.attrib[""name""], subtype.attrib[""value""] <MASK> new_relation.subtypes.append((name, int(value))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_relation.subtypes.append((name, value)) <TAB> self.pathway.add_relation(new_relation)","if name in ( ""compound"" , ""hidden compound"" ) :",160
"def parse_font_for_string(self, s): <TAB> for c in s: <MASK> # tabs rely on space char to calculate offset <TAB>  <TAB>  <TAB> self.parsed_font["" ""] = self.parse_font_char("" "") <TAB>  <TAB> if c not in self.parsed_font and ord(c) >= ord("" ""): <TAB>  <TAB>  <TAB> self.parsed_font[c] = self.parse_font_char(c)","if c == ""\t"" and "" "" not in self . parsed_font :",119
"def login(self, email: str, password: str): <TAB> user = self.models[""user""].get(email=email) <TAB> if user and user.get(""password"", False): <TAB>  <TAB> password = self.models[""user""].password.validate(password)[0] <MASK> self.ext.login_user(user) <TAB>  <TAB>  <TAB> return user <TAB> return None",if not user . registration_key and password == user . password :,103
def _out_of_memory_close(self): <TAB> if not self.external_file_handle: <TAB>  <TAB> self._ref_counts[self.path] -= 1 <MASK> del self._ref_counts[self.path] <TAB>  <TAB>  <TAB> self._file_handles[self.path].close() <TAB>  <TAB>  <TAB> del self._file_handles[self.path],if not self . _ref_counts [ self . path ] :,101
"def get_extra_select(self, order_by, select): <TAB> extra_select = [] <TAB> select_sql = [t[1] for t in select] <TAB> if self.query.distinct and not self.query.distinct_fields: <TAB>  <TAB> for expr, (sql, params, is_ref) in order_by: <TAB>  <TAB>  <TAB> without_ordering = self.ordering_parts.search(sql).group(1) <MASK> extra_select.append((expr, (without_ordering, params), None)) <TAB> return extra_select","if not is_ref and ( without_ordering , params ) not in select_sql :",150
"def process_rawq(self, cmd, cmd2): <TAB> while self.rawq: <MASK> if cmd: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> elif cmd2: <TAB>  <TAB>  <TAB>  <TAB> if self.option_callback: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.option = 2 <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.option = 3",if self . iacseq :,93
"def _resolve_group(client, identifier): <TAB> if not is_guid(identifier): <TAB>  <TAB> res = list(list_groups(client, display_name=identifier)) <MASK> raise CLIError(""Group {} is not found in Graph "".format(identifier)) <TAB>  <TAB> if len(res) != 1: <TAB>  <TAB>  <TAB> raise CLIError( <TAB>  <TAB>  <TAB>  <TAB> ""More than 1 group objects has the display name of "" + identifier <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> identifier = res[0].object_id <TAB> return identifier",if not res :,126
"def selectadd_deselect(self): <TAB> if not self.rfcontext.actions.using([""select single"", ""select single add""]): <TAB>  <TAB> self.rfcontext.undo_push(""deselect"") <TAB>  <TAB> edge, _ = self.rfcontext.accel_nearest2D_edge(max_dist=10) <MASK> self.rfcontext.deselect(edge) <TAB>  <TAB> return ""main"" <TAB> delta = Vec2D(self.rfcontext.actions.mouse - self.mousedown) <TAB> if delta.length > self.drawing.scale(5): <TAB>  <TAB> self.rfcontext.undo_push(""select add"") <TAB>  <TAB> return ""select""",if edge and edge . select :,160
"def splitOptions(options): <TAB> optsList = [] <TAB> opt = """" <TAB> quoted = False <TAB> for char in options: <TAB>  <TAB> if char == "" "" and not quoted: <MASK> optsList += [opt] <TAB>  <TAB>  <TAB>  <TAB> opt = """" <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif char == '""': <TAB>  <TAB>  <TAB> quoted = not quoted <TAB>  <TAB> opt += char <TAB> if opt != """": <TAB>  <TAB> optsList += [opt] <TAB> return optsList","if opt != """" :",115
"def jacobi(a, b): <TAB> """"""Calculates the value of the Jacobi symbol (a/b)"""""" <TAB> if a % b == 0: <TAB>  <TAB> return 0 <TAB> result = 1 <TAB> while a > 1: <MASK> if ((a - 1) * (b - 1) >> 2) & 1: <TAB>  <TAB>  <TAB>  <TAB> result = -result <TAB>  <TAB>  <TAB> b, a = a, b % a <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if ((b ** 2 - 1) >> 3) & 1: <TAB>  <TAB>  <TAB>  <TAB> result = -result <TAB>  <TAB>  <TAB> a = a >> 1 <TAB> return result",if a & 1 :,150
"def set_selected(self, val): <TAB> if self.selected != val: <TAB>  <TAB> self.selected = val <TAB>  <TAB> if self.line: <TAB>  <TAB>  <TAB> # self.set_color(Dark2[8][current_color]) <TAB>  <TAB>  <TAB> # current_color = (current_color + 1) % len(Dark2[8]) <TAB>  <TAB>  <TAB> self.line.visible = self.selected <MASK> self.bands.visible = self.selected and self.show_bollinger_bands <TAB>  <TAB> elif self.selected: <TAB>  <TAB>  <TAB> # lazy plotting - plot only when selected for the first time <TAB>  <TAB>  <TAB> self.plot_line()",if self . bands :,161
"def _bert_name_replacement(var_name, name_replacements): <TAB> """"""Gets the variable name replacement."""""" <TAB> for src_pattern, tgt_pattern in name_replacements: <MASK> old_var_name = var_name <TAB>  <TAB>  <TAB> var_name = var_name.replace(src_pattern, tgt_pattern) <TAB>  <TAB>  <TAB> tf.logging.info(""Converted: %s --> %s"", old_var_name, var_name) <TAB> return var_name",if src_pattern in var_name :,122
"def __assert_connected(self, workflow, steps): <TAB> disconnected_inputs = [] <TAB> for key, value in steps.items(): <TAB>  <TAB> if value[""type""] == ""tool"": <TAB>  <TAB>  <TAB> input_connections = value[""input_connections""] <MASK> disconnected_inputs.append(value) <TAB> if disconnected_inputs: <TAB>  <TAB> template = ""%d steps disconnected in extracted workflow - disconnectect steps are %s - workflow is %s"" <TAB>  <TAB> message = template % (len(disconnected_inputs), disconnected_inputs, workflow) <TAB>  <TAB> raise AssertionError(message)",if not input_connections :,144
"def on_train_epoch_start(self, trainer, *args, **kwargs): <TAB> if self.logging_interval != ""step"": <TAB>  <TAB> interval = ""epoch"" if self.logging_interval is None else ""any"" <TAB>  <TAB> latest_stat = self._extract_stats(trainer, interval) <MASK> trainer.logger.log_metrics(latest_stat, step=trainer.global_step)",if latest_stat :,101
"def apply_weights_correction(self, m): <TAB> if self.gg[""hook""] is None or not self.gg[""correction_needed""]: <TAB>  <TAB> return <TAB> if (isinstance(m, nn.Conv2d)) or (isinstance(m, nn.Linear)): <MASK> self.gg[""counter_to_apply_correction""] += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> weight = self.gg[""weight_lambda""](m) <TAB>  <TAB>  <TAB> weight.data *= float(self.gg[""current_coef""]) <TAB>  <TAB>  <TAB> self.gg[""correction_needed""] = False","if self . gg [ ""counter_to_apply_correction"" ] < self . gg [ ""hook_position"" ] :",157
"def _extract_solidity_variable_usage( <TAB> slither: SlitherCore, sol_var: SolidityVariable) -> Dict[str, List[str]]: <TAB> ret: Dict[str, List[str]] = {} <TAB> for contract in slither.contracts: <TAB>  <TAB> functions_using_sol_var = [] <TAB>  <TAB> for f in contract.functions_entry_points: <TAB>  <TAB>  <TAB> for v in f.all_solidity_variables_read(): <MASK> functions_using_sol_var.append(_get_name(f)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if functions_using_sol_var: <TAB>  <TAB>  <TAB> ret[contract.name] = functions_using_sol_var <TAB> return ret",if v == sol_var :,183
"def _process_items(items): <TAB> for i, item in enumerate(items): <TAB>  <TAB> if isinstance(item, dict): <TAB>  <TAB>  <TAB> new = {} <TAB>  <TAB>  <TAB> for key, value in item.items(): <MASK> continue <TAB>  <TAB>  <TAB>  <TAB> new[key] = _process_items(value) if isinstance(value, list) else value <TAB>  <TAB>  <TAB> items[i] = new <TAB>  <TAB> elif isinstance(item, list): <TAB>  <TAB>  <TAB> items[i] = _process_items(item) <TAB> return items","if key and key . startswith ( ""_"" ) :",135
"def get_input(self): <TAB> chars = list(self.orig_stdin.readline()[:-1]) <TAB> while chars or self.requested_events: <TAB>  <TAB> if self.requested_events: <TAB>  <TAB>  <TAB> self.process_event(self.requested_events.pop()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> c = chars.pop(0) <TAB>  <TAB> if c in ""/"": <TAB>  <TAB>  <TAB> c = ""\n"" <MASK> c = key_dispatch[self.config.undo_key][0] <TAB>  <TAB> elif c in ""$"": <TAB>  <TAB>  <TAB> c = key_dispatch[self.config.pastebin_key][0] <TAB>  <TAB> elif c in ""|"": <TAB>  <TAB>  <TAB> c = key_dispatch[self.config.reimport_key][0] <TAB>  <TAB> self.process_event(c)","elif c in ""\\"" :",189
"def choose_session_storage(self): <TAB> _spec = self.config.getattr(""session_storage"", ""idp"") <TAB> if not _spec: <TAB>  <TAB> return SessionStorage() <TAB> elif isinstance(_spec, six.string_types): <TAB>  <TAB> if _spec.lower() == ""memory"": <TAB>  <TAB>  <TAB> return SessionStorage() <TAB> else:  # Should be tuple <TAB>  <TAB> typ, data = _spec <MASK> from saml2.mongo_store import SessionStorageMDB <TAB>  <TAB>  <TAB> return SessionStorageMDB(database=data, collection=""session"") <TAB> raise NotImplementedError(""No such storage type implemented"")","if typ . lower ( ) == ""mongodb"" :",152
"def get_imports_from_children(children: List[LN]) -> Generator[str, None, None]: <TAB> for child in children: <TAB>  <TAB> if isinstance(child, Leaf): <MASK> yield child.value <TAB>  <TAB> elif child.type == syms.import_as_name: <TAB>  <TAB>  <TAB> orig_name = child.children[0] <TAB>  <TAB>  <TAB> assert isinstance(orig_name, Leaf), ""Invalid syntax parsing imports"" <TAB>  <TAB>  <TAB> assert orig_name.type == token.NAME, ""Invalid syntax parsing imports"" <TAB>  <TAB>  <TAB> yield orig_name.value <TAB>  <TAB> elif child.type == syms.import_as_names: <TAB>  <TAB>  <TAB> yield from get_imports_from_children(child.children) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise AssertionError(""Invalid syntax parsing imports"")",if child . type == token . NAME :,195
"def deleteMenuItem(self, itemName, menuName=""top""): <TAB> """"""Delete itemName from the menu whose name is menuName."""""" <TAB> try: <TAB>  <TAB> menu = self.getMenu(menuName) <MASK> realItemName = self.getRealMenuName(itemName) <TAB>  <TAB>  <TAB> self.delete(menu, realItemName) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> g.es(""menu not found:"", menuName) <TAB> except Exception: <TAB>  <TAB> g.es(""exception deleting"", itemName, ""from"", menuName, ""menu"") <TAB>  <TAB> g.es_exception()",if menu :,141
"def create_prefix_dir(self, path, fmt): <TAB> """"""Create the prefix dir, if missing"""""" <TAB> if ""prefix"" in fmt and ""/"" in path: <TAB>  <TAB> parent_dir = self.get_parent_dir(path) <MASK> self.create_prefix_dir(parent_dir, fmt) <TAB>  <TAB>  <TAB> self.log.info(""Creating directory %s"", parent_dir) <TAB>  <TAB>  <TAB> self.super.save(dict(type=""directory""), parent_dir)",if not self . dir_exists ( parent_dir ) :,127
"def _listify(channel, maxlen, *args): <TAB> if not isinstance(channel, list): <TAB>  <TAB> channel = [channel] <TAB> elif len(channel) > maxlen: <TAB>  <TAB> raise ValueError(""Too many channels."") <TAB> ret = [channel] <TAB> for arg in args: <MASK> if len(arg) == len(channel): <TAB>  <TAB>  <TAB>  <TAB> ret.append(arg) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""Dimension mismatch."") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret.append(len(channel) * [arg]) <TAB> return ret","if isinstance ( arg , list ) :",142
"def _process_transfer_filters(query, filters): <TAB> if filters: <TAB>  <TAB> project_id = filters.pop(""project_id"", None) <TAB>  <TAB> # Ensure that filters' keys exist on the model <TAB>  <TAB> if not is_valid_model_filters(models.Transfer, filters): <TAB>  <TAB>  <TAB> return <MASK> volume = models.Volume <TAB>  <TAB>  <TAB> query = query.filter( <TAB>  <TAB>  <TAB>  <TAB> volume.id == models.Transfer.volume_id, volume.project_id == project_id <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> query = query.filter_by(**filters) <TAB> return query",if project_id :,147
"def reset(self): <TAB> with self.lock: <TAB>  <TAB> user = self.users.get(current_user.id, None) <TAB>  <TAB> if user is not None: <TAB>  <TAB>  <TAB> # This will not decrement if session expired <TAB>  <TAB>  <TAB> user[""session_count""] -= 1 <MASK> del self.users[current_user.id]","if user [ ""session_count"" ] == 0 :",95
"def clean(self): <TAB> username = self.cleaned_data.get(""username"") <TAB> password = self.cleaned_data.get(""password"") <TAB> if username and password: <TAB>  <TAB> self.user_cache = authenticate(username=username, password=password) <TAB>  <TAB> if self.user_cache is None: <TAB>  <TAB>  <TAB> raise forms.ValidationError( <TAB>  <TAB>  <TAB>  <TAB> self.error_messages[""invalid_login""] <TAB>  <TAB>  <TAB>  <TAB> % {""username"": self.username_field.verbose_name} <TAB>  <TAB>  <TAB> ) <MASK> raise forms.ValidationError(self.error_messages[""inactive""]) <TAB> self.check_for_test_cookie() <TAB> return self.cleaned_data",elif not self . user_cache . is_active :,172
"def __iter__(self): <TAB> more_results = True <TAB> num_results = 0 <TAB> while more_results: <TAB>  <TAB> rs = self.domain.connection.select( <TAB>  <TAB>  <TAB> self.domain, <TAB>  <TAB>  <TAB> self.query, <TAB>  <TAB>  <TAB> next_token=self.next_token, <TAB>  <TAB>  <TAB> consistent_read=self.consistent_read, <TAB>  <TAB> ) <TAB>  <TAB> for item in rs: <MASK> raise StopIteration <TAB>  <TAB>  <TAB> yield item <TAB>  <TAB>  <TAB> num_results += 1 <TAB>  <TAB> self.next_token = rs.next_token <TAB>  <TAB> if self.max_items and num_results >= self.max_items: <TAB>  <TAB>  <TAB> raise StopIteration <TAB>  <TAB> more_results = self.next_token != None",if self . max_items and num_results >= self . max_items :,194
"def narrower(request, factors, param_groups): <TAB> anamolous_params = [] <TAB> threadpool = ThreadPoolExecutor(max_workers=mem.var[""threads""]) <TAB> futures = ( <TAB>  <TAB> threadpool.submit(bruter, request, factors, params) for params in param_groups <TAB> ) <TAB> for i, result in enumerate(as_completed(futures)): <TAB>  <TAB> if result.result(): <TAB>  <TAB>  <TAB> anamolous_params.extend(slicer(result.result())) <MASK> print( <TAB>  <TAB>  <TAB>  <TAB> ""%s Processing chunks: %i/%-6i"" % (info, i + 1, len(param_groups)), <TAB>  <TAB>  <TAB>  <TAB> end=""\r"", <TAB>  <TAB>  <TAB> ) <TAB> return anamolous_params","if not mem . var [ ""kill"" ] :",183
"def _mark_as_changed(self, key=None): <TAB> if hasattr(self._instance, ""_mark_as_changed""): <MASK> self._instance._mark_as_changed(f""{self._name}.{key}"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._instance._mark_as_changed(self._name)",if key :,82
"def __deleteHotkeys(self, theItem): <TAB> if model.TriggerMode.HOTKEY in theItem.modes: <TAB>  <TAB> self.app.hotkey_removed(theItem) <TAB> if isinstance(theItem, model.Folder): <TAB>  <TAB> for subFolder in theItem.folders: <TAB>  <TAB>  <TAB> self.__deleteHotkeys(subFolder) <TAB>  <TAB> for item in theItem.items: <MASK> self.app.hotkey_removed(item)",if model . TriggerMode . HOTKEY in item . modes :,126
"def parse_roc_plot_data(self, f): <TAB> header = f[""f""].readline() <TAB> sample_names = [self.clean_s_name(x, f[""root""]) for x in header.strip().split()[2:]] <TAB> for parts in (l.rstrip().split() for l in f[""f""]): <TAB>  <TAB> if len(parts) > 2: <TAB>  <TAB>  <TAB> chrom, cov = parts[:2] <TAB>  <TAB>  <TAB> sample_vals = parts[2:] <TAB>  <TAB>  <TAB> if self._short_chrom(chrom) is not None: <TAB>  <TAB>  <TAB>  <TAB> for val, sample in zip(sample_vals, sample_names): <MASK> self.roc_plot_data[chrom][sample][float(cov)] = float(val)",if not self . is_ignore_sample ( sample ) :,197
"def _get_object_types(self, details: dict) -> List[str]: <TAB> type_ = details.get(""type"", None) <TAB> any_of = details.get(""anyOf"", None) <TAB> types_list = [] <TAB> if isinstance(type_, list): <TAB>  <TAB> types_list.extend(type_) <TAB> elif type_: <TAB>  <TAB> types_list.append(type_) <TAB> elif any_of: <TAB>  <TAB> for schema in any_of: <TAB>  <TAB>  <TAB> schema_type = schema.get(""type"", None) <MASK> types_list.extend(schema_type) <TAB>  <TAB>  <TAB> elif schema_type: <TAB>  <TAB>  <TAB>  <TAB> types_list.append(schema_type) <TAB> return types_list","if isinstance ( schema_type , list ) :",182
"def find_reached(board, c): <TAB> color = board[c] <TAB> chain = set([c]) <TAB> reached = set() <TAB> frontier = [c] <TAB> while frontier: <TAB>  <TAB> current = frontier.pop() <TAB>  <TAB> chain.add(current) <TAB>  <TAB> for n in NEIGHBORS[current]: <MASK> frontier.append(n) <TAB>  <TAB>  <TAB> elif board[n] != color: <TAB>  <TAB>  <TAB>  <TAB> reached.add(n) <TAB> return chain, reached",if board [ n ] == color and not n in chain :,136
"def __repr__(self): <TAB> clsname = type(self).__name__ <TAB> if self.argv is not None: <TAB>  <TAB> args = [repr(self.argv)] <MASK> args.append(""env=%r"" % self.env) <TAB>  <TAB> if self.launch_dir is not None: <TAB>  <TAB>  <TAB> args.append(""cwd=%r"" % self.launch_dir) <TAB>  <TAB> return ""{}.spawn({})"".format(clsname, "", "".join(args)) <TAB> else: <TAB>  <TAB> return ""{}(pid={}, fd={})"".format(clsname, self.pid, self.fd)",if self . env is not None :,145
"def __init_subclass__(cls, **kwargs): <TAB> super().__init_subclass__() <TAB> missing = [] <TAB> for attr in (""start"", ""stop"", ""poll""): <MASK> missing.append(attr) <TAB> if missing: <TAB>  <TAB> raise NotImplementedError( <TAB>  <TAB>  <TAB> ""class `{}` needs to redefine the `start`,"" <TAB>  <TAB>  <TAB> ""`stop` and `poll` methods. `{}` not redefined."".format( <TAB>  <TAB>  <TAB>  <TAB> cls.__name__, ""`, `"".join(missing) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> )","if getattr ( Spawner , attr ) is getattr ( cls , attr ) :",139
"def has_only_gpu_op(self, function): <TAB> has_cpu_instance = False <TAB> has_gpu_instance = False <TAB> for node in function.maker.fgraph.apply_nodes: <MASK> has_cpu_instance = True <TAB>  <TAB> if isinstance(node.op, GpuConnectionistTemporalClassification): <TAB>  <TAB>  <TAB> has_gpu_instance = True <TAB> return has_gpu_instance and (not has_cpu_instance)","if isinstance ( node . op , ConnectionistTemporalClassification ) :",120
"def __iter__(self): <TAB> if self.shuffle: <TAB>  <TAB> self.rng.shuffle(self.files) <TAB> for f in self.files: <TAB>  <TAB> im = cv2.imread(f, self.imread_mode) <TAB>  <TAB> assert im is not None, f <MASK> im = im[:, :, ::-1] <TAB>  <TAB> if self.resize is not None: <TAB>  <TAB>  <TAB> im = cv2.resize(im, tuple(self.resize[::-1])) <TAB>  <TAB> if self.channel == 1: <TAB>  <TAB>  <TAB> im = im[:, :, np.newaxis] <TAB>  <TAB> yield [im]",if self . channel == 3 :,148
"def test_inner(extra_burning_oil=1, count=0): <TAB> big_hippo = 2 <TAB> while big_hippo: <TAB>  <TAB> count += 1 <TAB>  <TAB> try: <MASK> extra_burning_oil -= 1 <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> big_hippo -= 1 <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> raise <TAB> if count > 2 or big_hippo != 1: <TAB>  <TAB> self.fail(""continue then break in try/except in loop broken!"")",if extra_burning_oil and big_hippo == 1 :,139
"def legacy_delete_blocks(blocks): <TAB> bucket = settings.REMOTE_SETTINGS_WRITER_BUCKET <TAB> server = RemoteSettings(bucket, REMOTE_SETTINGS_COLLECTION_LEGACY) <TAB> for block in blocks: <MASK> if block.is_imported_from_legacy_regex: <TAB>  <TAB>  <TAB>  <TAB> log.info( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f""Block [{block.guid}] was imported from a regex guid so "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""can't be safely deleted.  Skipping."" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> server.delete_record(block.legacy_id) <TAB>  <TAB>  <TAB> block.update(legacy_id="""") <TAB> server.complete_session()",if block . legacy_id :,173
"def run(self, repeat=5): <TAB> wrapper_time = _run_timeit(self.func, 0) <TAB> times = [] <TAB> for _ in range(repeat): <TAB>  <TAB> t = _run_timeit(self.func, self.iters) <MASK> raise Exception(""{} time=0"".format(repr(self))) <TAB>  <TAB> times.append(t) <TAB> best_time = min(times) - wrapper_time <TAB> self.ns_per_op = int((best_time * 1e9) / self.iters)",if t == 0.0 :,134
"def __init__(self, filename): <TAB> with translate_errors(): <TAB>  <TAB> data = open(filename, ""rb"").read() <TAB>  <TAB> f = _modplug.ModPlug_Load(data, len(data)) <MASK> raise IOError(""%r not a valid MOD file"" % filename) <TAB>  <TAB> self[""~#length""] = _modplug.ModPlug_GetLength(f) // 1000 <TAB>  <TAB> title = _modplug.ModPlug_GetName(f) or os.path.basename(filename) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self[""title""] = title.decode(""utf-8"") <TAB>  <TAB> except UnicodeError: <TAB>  <TAB>  <TAB> self[""title""] = title.decode(""iso-8859-1"") <TAB>  <TAB> _modplug.ModPlug_Unload(f) <TAB> self.sanitize(filename)",if not f :,199
"def to(self, device): <TAB> for k in dir(self): <TAB>  <TAB> v = getattr(self, k) <TAB>  <TAB> if isinstance(v, (list, tuple)) and all(torch.is_tensor(elem) for elem in v): <TAB>  <TAB>  <TAB> v = [elem.to(device) for elem in v] <TAB>  <TAB>  <TAB> setattr(self, k, v) <MASK> setattr(self, k, v.to(device)) <TAB> self.device = device <TAB> return self",if torch . is_tensor ( v ) and v . device != device :,133
"def linkify(self, timeperiods): <TAB> new_exclude = [] <TAB> if self.has(""exclude"") and self.exclude != []: <TAB>  <TAB> logger.debug(""[timeentry::%s] have excluded %s"", self.get_name(), self.exclude) <TAB>  <TAB> excluded_tps = self.exclude <TAB>  <TAB> # print ""I will exclude from:"", excluded_tps <TAB>  <TAB> for tp_name in excluded_tps: <TAB>  <TAB>  <TAB> tp = timeperiods.find_by_name(tp_name.strip()) <MASK> new_exclude.append(tp) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> logger.error( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""[timeentry::%s] unknown %s timeperiod"", self.get_name(), tp_name <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> self.exclude = new_exclude",if tp is not None :,196
"def __init__(self, content=None, parent=None): <TAB> Element.__init__(self, content, parent) <TAB> if isinstance(content, str): <TAB>  <TAB> self._transform = Transform() <TAB>  <TAB> self._computed_transform = self._transform <TAB> else: <TAB>  <TAB> self._transform = Transform(content.get(""transform"", None)) <TAB>  <TAB> self._computed_transform = self._transform <MASK> self._computed_transform = self._transform + self.parent.transform",if parent :,115
"def scanfiles(self): <TAB> """"""Populate the internal file data."""""" <TAB> self.filedata = [] <TAB> for dirpath, dirnames, filenames in os.walk(self.dir): <TAB>  <TAB> fnames = dirnames + filenames <TAB>  <TAB> for fname in fnames: <MASK> self.filedata.append((dirpath, fname))","if os . path . isfile ( os . path . join ( dirpath , fname ) ) :",92
"def _get_lh_extra_specs(self, extra_specs, valid_keys): <TAB> """"""Get LeftHand extra_specs (valid_keys only)."""""" <TAB> extra_specs_of_interest = {} <TAB> for key, value in extra_specs.items(): <MASK> prefix = key.split("":"") <TAB>  <TAB>  <TAB> if prefix[0] == ""hplh"": <TAB>  <TAB>  <TAB>  <TAB> LOG.warning(""The 'hplh' prefix is deprecated. Use "" ""'hpelh' instead."") <TAB>  <TAB>  <TAB> extra_specs_of_interest[key] = value <TAB> return extra_specs_of_interest",if key in valid_keys :,151
"def process_request(self, request): <TAB> is_authenticated = request.user.is_authenticated <TAB> if django.VERSION < (1, 10): <TAB>  <TAB> is_authenticated = is_authenticated() <TAB> if is_authenticated and not request.user.is_staff: <TAB>  <TAB> url_name = resolve(request.path).url_name <TAB>  <TAB> if url_name not in settings.PINAX_STRIPE_SUBSCRIPTION_REQUIRED_EXCEPTION_URLS: <TAB>  <TAB>  <TAB> customer = customers.get_customer_for_user(request.user) <MASK> return redirect(settings.PINAX_STRIPE_SUBSCRIPTION_REQUIRED_REDIRECT)",if not subscriptions . has_active_subscription ( customer ) :,169
"def run_py2dsc_deb_build(python_env, build_command, task_name, logger, project): <TAB> logger.info(""Running %s"" % task_name) <TAB> log_file = project.expand_path(""$dir_target"", ""reports"", task_name) <TAB> if project.get_property(""verbose""): <TAB>  <TAB> logger.info(build_command) <TAB>  <TAB> exit_code = python_env.execute_command(build_command, log_file, shell=True) <MASK> raise BuildFailedException( <TAB>  <TAB>  <TAB>  <TAB> ""py2dsc_deb build command failed. See %s for full details:\n%s"", <TAB>  <TAB>  <TAB>  <TAB> log_file, <TAB>  <TAB>  <TAB>  <TAB> tail_log(log_file), <TAB>  <TAB>  <TAB> )",if exit_code != 0 :,191
"def get_value(self): <TAB> for child in self.xml: <MASK> elem_name = child.tag.split(""}"")[-1] <TAB>  <TAB>  <TAB> if elem_name in self.moods: <TAB>  <TAB>  <TAB>  <TAB> return elem_name <TAB> return """"","if child . tag . startswith ( ""{%s}"" % self . namespace ) :",78
"def env_vars(self): <TAB> ret = {} <TAB> for section, values in self._table_vars.items(): <TAB>  <TAB> for env_var, var_name, default_value in values: <TAB>  <TAB>  <TAB> var_name = ""."".join([section, var_name]) if var_name else section <TAB>  <TAB>  <TAB> value = self._env_c(var_name, env_var, default_value) <MASK> ret[env_var] = str(value) <TAB> return ret",if value is not None :,123
"def save_existing_objects(self, commit=True): <TAB> objs = super().save_existing_objects(commit=commit) <TAB> for form in self.initial_forms: <MASK> admin_log.info( <TAB>  <TAB>  <TAB>  <TAB> 'Addon ""%s"" file (ID:%d) status changed to: %s' <TAB>  <TAB>  <TAB>  <TAB> % ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.instance.slug, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> form.instance.id, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> form.cleaned_data[""status""], <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> return objs","if ""status"" in form . changed_data :",149
"def generator(self, data): <TAB> for (good, filter, filter_name, filter_socket, member, ptr, module) in data: <MASK> status = ""UNKNOWN"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> status = ""OK"" <TAB>  <TAB> yield ( <TAB>  <TAB>  <TAB> 0, <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB> Address(filter.obj_offset), <TAB>  <TAB>  <TAB>  <TAB> str(filter_name), <TAB>  <TAB>  <TAB>  <TAB> str(member), <TAB>  <TAB>  <TAB>  <TAB> Address(filter_socket), <TAB>  <TAB>  <TAB>  <TAB> Address(ptr), <TAB>  <TAB>  <TAB>  <TAB> str(module), <TAB>  <TAB>  <TAB>  <TAB> str(status), <TAB>  <TAB>  <TAB> ], <TAB>  <TAB> )",if good == 0 :,160
"def writeChar(self, c): <TAB> if c == ""\n"": <TAB>  <TAB> self.cursor_y += self.textsize * 8 <TAB>  <TAB> self.cursor_x = 0 <TAB> elif c == ""\r"": <TAB>  <TAB> pass <TAB> else: <TAB>  <TAB> self.drawChar( <TAB>  <TAB>  <TAB> self.cursor_x, <TAB>  <TAB>  <TAB> self.cursor_y, <TAB>  <TAB>  <TAB> c, <TAB>  <TAB>  <TAB> self.textcolor, <TAB>  <TAB>  <TAB> self.textbgcolor, <TAB>  <TAB>  <TAB> self.textsize, <TAB>  <TAB> ) <TAB>  <TAB> self.cursor_x += self.textsize * 6 <MASK> self.cursor_y += self.textsize * 8 <TAB>  <TAB>  <TAB> self.cursor_x = 0",if self . wrap and ( self . cursor_x > ( self . _width - self . textsize * 6 ) ) :,191
"def _range_check(current_index, element_intervals, tensor_size): <TAB> results = [] <TAB> for comm_idx, interval in enumerate(element_intervals): <TAB>  <TAB> start_index, end_index = interval <TAB>  <TAB> contained, offset = _single_range_check( <TAB>  <TAB>  <TAB> current_index, start_index, end_index, tensor_size <TAB>  <TAB> ) <MASK> results.append((contained, offset, comm_idx)) <TAB> if len(results) == 0: <TAB>  <TAB> return [(False, 0, -1)] <TAB> return results",if contained :,138
"def test_time(self): <TAB> f = open(test_support.TESTFN, ""wb"") <TAB> try: <TAB>  <TAB> f.write(""foo"") <TAB>  <TAB> f.close() <TAB>  <TAB> f = open(test_support.TESTFN, ""ab"") <TAB>  <TAB> f.write(""bar"") <TAB>  <TAB> f.close() <TAB>  <TAB> f = open(test_support.TESTFN, ""rb"") <TAB>  <TAB> d = f.read() <TAB>  <TAB> f.close() <TAB>  <TAB> self.assertEqual(d, ""foobar"") <TAB>  <TAB> self.assertLessEqual( <TAB>  <TAB>  <TAB> self.pathmodule.getctime(test_support.TESTFN), <TAB>  <TAB>  <TAB> self.pathmodule.getmtime(test_support.TESTFN), <TAB>  <TAB> ) <TAB> finally: <MASK> f.close() <TAB>  <TAB> test_support.unlink(test_support.TESTFN)",if not f . closed :,198
"def process(stuff): <TAB> if isinstance(stuff, dict): <TAB>  <TAB> l = [(k, process(v)) for (k, v) in stuff.items()] <TAB>  <TAB> keys = set(stuff) <TAB>  <TAB> for order in orders: <MASK> return OrderedDict(sorted(l, key=lambda x: order.get(x[0], 0))) <TAB>  <TAB> return OrderedDict(sorted(l)) <TAB> if isinstance(stuff, list): <TAB>  <TAB> return [process(x) for x in stuff] <TAB> return stuff",if keys . issubset ( order ) or keys . issuperset ( order ) :,137
def jag_distortion(x): <TAB> is_in_mask = False <TAB> if x > 0: <TAB>  <TAB> for mask in positive_mask: <TAB>  <TAB>  <TAB> if x >= mask[0] and x <= mask[1]: <TAB>  <TAB>  <TAB>  <TAB> is_in_mask = True <TAB>  <TAB>  <TAB>  <TAB> return x <TAB>  <TAB> if not is_in_mask: <TAB>  <TAB>  <TAB> return 0.0 <TAB> elif x < 0: <TAB>  <TAB> abs_x = abs(x) <TAB>  <TAB> for mask in negative_mask: <MASK> is_in_mask = True <TAB>  <TAB>  <TAB>  <TAB> return x <TAB>  <TAB> if not is_in_mask: <TAB>  <TAB>  <TAB> return 0.0 <TAB> return x,if abs_x >= mask [ 0 ] and abs_x <= mask [ 1 ] :,183
"def exists(env): <TAB> if not (is_mac or is_linux or is_windows): <TAB>  <TAB> # can't handle this platform <TAB>  <TAB> return 0 <TAB> try: <TAB>  <TAB> versions = get_all_compiler_versions() <TAB> except (SCons.Util.RegError, IntelCError): <TAB>  <TAB> versions = None <TAB> detected = versions is not None and len(versions) > 0 <TAB> if not detected: <TAB>  <TAB> # try env.Detect, maybe that will work <MASK> return env.Detect(""icl"") <TAB>  <TAB> elif is_linux: <TAB>  <TAB>  <TAB> return env.Detect(""icc"") <TAB>  <TAB> elif is_mac: <TAB>  <TAB>  <TAB> return env.Detect(""icc"") <TAB> return detected",if is_windows :,174
"def copy(): <TAB> try: <TAB>  <TAB> rbytes = 0 <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> r = debug_job.pipes.output.r.read(1048576) <TAB>  <TAB>  <TAB> if r == b"""": <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> rbytes += len(r) <MASK> raise CallError(""Debug too large to attach"", errno.EFBIG) <TAB>  <TAB>  <TAB> tjob.pipes.input.w.write(r) <TAB> finally: <TAB>  <TAB> tjob.pipes.input.w.close()",if rbytes > DEBUG_MAX_SIZE * 1048576 :,144
"def name_or_ref(elem, top): <TAB> try: <TAB>  <TAB> (namespace, name) = _namespace_and_tag(elem, elem.ref, top) <MASK> return name <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return elem.ref <TAB> except AttributeError: <TAB>  <TAB> return elem.name",if namespace and elem . xmlns_map [ namespace ] == top . target_namespace :,92
"def run_message_listeners(self, message: dict) -> None: <TAB> type = message.get(""type"") <MASK> self.logger.debug(f""Message processing started (type: {type})"") <TAB> try: <TAB>  <TAB> for listener in self.message_listeners: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> listener(self, message) <TAB>  <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB>  <TAB> self.logger.exception(f""Failed to run a message listener: {e}"") <TAB> except Exception as e: <TAB>  <TAB> self.logger.exception(f""Failed to run message listeners: {e}"") <TAB> finally: <TAB>  <TAB> if self.logger.level <= logging.DEBUG: <TAB>  <TAB>  <TAB> self.logger.debug(f""Message processing completed (type: {type})"")",if self . logger . level <= logging . DEBUG :,191
"def close(self): <TAB> for item_type, file in self.file_mapping.items(): <TAB>  <TAB> close_silently(file) <TAB>  <TAB> counter = self.counter_mapping[item_type] <MASK> self.logger.info( <TAB>  <TAB>  <TAB>  <TAB> ""{} items exported: {}"".format(item_type, counter.increment() - 1) <TAB>  <TAB>  <TAB> )",if counter is not None :,94
"def run(self): <TAB> try: <TAB>  <TAB> out = subprocess.check_output([""cmake"", ""--version""]) <TAB> except OSError: <TAB>  <TAB> raise RuntimeError( <TAB>  <TAB>  <TAB> ""CMake must be installed to build the following extensions: "" <TAB>  <TAB>  <TAB> + "", "".join(e.name for e in self.extensions) <TAB>  <TAB> ) <TAB> if platform.system() == ""Windows"": <TAB>  <TAB> cmake_version = LooseVersion( <TAB>  <TAB>  <TAB> re.search(r""version\s*([\d.]+)"", out.decode()).group(1) <TAB>  <TAB> ) <MASK> raise RuntimeError(""CMake >= 3.1.0 is required on Windows"") <TAB> for ext in self.extensions: <TAB>  <TAB> self.build_extension(ext)","if cmake_version < ""3.1.0"" :",184
"def remote_run(cmd, instance_name, detach=False, retries=1): <TAB> """"""Run command on GCS instance, optionally detached."""""" <TAB> if detach: <TAB>  <TAB> cmd = SCREEN.format(command=cmd) <TAB> args = SSH.format(instance_name=instance_name).split() <TAB> args.append(cmd) <TAB> for i in range(retries + 1): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if i > 0: <TAB>  <TAB>  <TAB>  <TAB> tf.logging.info(""Retry %d for %s"", i, args) <TAB>  <TAB>  <TAB> return sp.check_call(args) <TAB>  <TAB> except sp.CalledProcessError as e: <MASK> raise e",if i == retries :,166
"def _handle_log_message(self, args): <TAB> a = args[0] <TAB> if self.show_message_log and LOG_LEVELS[a[""level""]] >= self._min_log_level_number: <TAB>  <TAB> prefix = ""%s : %s : "" % (a[""timestamp""], a[""level""].rjust(5)) <TAB>  <TAB> message = a[""message""] <MASK> message = ""\n"" + message <TAB>  <TAB> self._messages_log_texts.put(prefix + message)","if ""\n"" in message :",126
"def set_totals(self): <TAB> total_sessions = 0 <TAB> total_sessions_completed = 0 <TAB> for entry in self.therapy_plan_details: <TAB>  <TAB> if entry.no_of_sessions: <TAB>  <TAB>  <TAB> total_sessions += entry.no_of_sessions <MASK> total_sessions_completed += entry.sessions_completed <TAB> self.db_set(""total_sessions"", total_sessions) <TAB> self.db_set(""total_sessions_completed"", total_sessions_completed)",if entry . sessions_completed :,127
"def elementClicked(self, root, hElem): <TAB> chain = [] <TAB> self.collectElementChain(chain, self.getElement(), hElem) <TAB> item = self.findItemByChain(chain, 0, root) <TAB> if item is not None: <TAB>  <TAB> if DOM.compare(item.getImageElement(), hElem): <TAB>  <TAB>  <TAB> item.setState(not item.getState(), True) <TAB>  <TAB>  <TAB> return True <MASK> self.onSelection(item, True) <TAB>  <TAB>  <TAB> return True <TAB> return False","elif DOM . isOrHasChild ( item . getElement ( ) , hElem ) :",145
"def log_sender_master(): <TAB> while True: <TAB>  <TAB> sender_master = coordinator.get_current_master() <MASK> logger.info(""Current sender master: %s"" % sender_master) <TAB>  <TAB> sleep(30)",if sender_master :,65
"def can_unify(self, other): <TAB> if other.is_var(): <TAB>  <TAB> return [(other, self)] <TAB> if other.is_function(): <TAB>  <TAB> sa = self._res.can_unify(other.res()) <TAB>  <TAB> sd = self._dir.can_unify(other.dir()) <TAB>  <TAB> if sa is not None and sd is not None: <TAB>  <TAB>  <TAB> sb = self._arg.substitute(sa).can_unify(other.arg().substitute(sa)) <MASK> return sa + sb <TAB> return None",if sb is not None :,134
"def add_entity(table, entity): <TAB> for e in table.entities: <MASK> throw( <TAB>  <TAB>  <TAB>  <TAB> MappingError, <TAB>  <TAB>  <TAB>  <TAB> ""Entities %s and %s cannot be mapped to table %s "" <TAB>  <TAB>  <TAB>  <TAB> ""because they don't belong to the same hierarchy"" <TAB>  <TAB>  <TAB>  <TAB> % (e, entity, table.name), <TAB>  <TAB>  <TAB> ) <TAB> assert ""_table_options_"" not in entity.__dict__ <TAB> table.entities.add(entity)",if e . _root_ is not entity . _root_ :,128
"def configure(self, **kw): <TAB> """"""Configure the image."""""" <TAB> res = () <TAB> for k, v in _cnfmerge(kw).items(): <TAB>  <TAB> if v is not None: <MASK> k = k[:-1] <TAB>  <TAB>  <TAB> if callable(v): <TAB>  <TAB>  <TAB>  <TAB> v = self._register(v) <TAB>  <TAB>  <TAB> res = res + (""-"" + k, v) <TAB> self.tk.call((self.name, ""config"") + res)","if k [ - 1 ] == ""_"" :",121
"def setter(tags, key, value): <TAB> encoded = [] <TAB> for v in value: <TAB>  <TAB> if not isinstance(v, text_type): <MASK> raise TypeError(""%r not str"" % v) <TAB>  <TAB>  <TAB> v = v.decode(""utf-8"") <TAB>  <TAB> encoded.append(v.encode(""utf-8"")) <TAB> tags[atomid] = encoded",if PY3 :,96
"def generate_tag_data(ids): <TAB> if len(ids) != SAMPLE_NUM: <TAB>  <TAB> raise ValueError(""len ids should equal to sample number"") <TAB> counter = 0 <TAB> for sample_i in range(SAMPLE_NUM): <TAB>  <TAB> one_data = [ids[sample_i]] <TAB>  <TAB> valid_set = [x for x in range(TAG_INTERVAL[0], TAG_INTERVAL[1])] <TAB>  <TAB> tags = np.random.choice(valid_set, FEATURE_NUM, replace=False) <TAB>  <TAB> one_data += [str(tag) for tag in tags] <TAB>  <TAB> counter += 1 <MASK> print(""generate data {}"".format(counter)) <TAB>  <TAB> yield one_data",if counter % 10000 == 0 :,171
"def _parse_date(dateString): <TAB> """"""Parses a variety of date formats into a 9-tuple in GMT"""""" <TAB> if not dateString: <TAB>  <TAB> return None <TAB> for handler in _date_handlers: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> date9tuple = handler(dateString) <TAB>  <TAB> except (KeyError, OverflowError, ValueError): <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> if len(date9tuple) != 9: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> return date9tuple <TAB> return None",if not date9tuple :,126
"def eval_f(x_value, y_value): <TAB> try: <TAB>  <TAB> return stored[(x_value, y_value)] <TAB> except KeyError: <TAB>  <TAB> value = cf(x_value, y_value) <MASK> value = float(value) <TAB>  <TAB> stored[(x_value, y_value)] = value <TAB>  <TAB> return value",if value is not None :,91
"def get_blob(self, blobname, ctlr=None): <TAB> self._acquire_lock() <TAB> try: <TAB>  <TAB> dbsubpath = self._dbsubpath_from_blobname(blobname, ctlr=ctlr) <MASK> return self.lang_zone.load_blob(dbsubpath) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return None <TAB> finally: <TAB>  <TAB> self._release_lock()",if dbsubpath is not None :,105
"def run(self, task_id): <TAB> try: <MASK> env.meminfo.start(task_id, int(self.mem)) <TAB>  <TAB>  <TAB> if dpark.conf.MULTI_SEGMENT_DUMP: <TAB>  <TAB>  <TAB>  <TAB> env.meminfo.check = False <TAB>  <TAB> return self._run(task_id) <TAB> except KeyboardInterrupt as e: <TAB>  <TAB> if self.mem != 0 and env.meminfo.oom: <TAB>  <TAB>  <TAB> os._exit(ERROR_TASK_OOM) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise e <TAB> finally: <TAB>  <TAB> if self.mem != 0: <TAB>  <TAB>  <TAB> env.meminfo.check = True <TAB>  <TAB>  <TAB> env.meminfo.stop()",if self . mem != 0 :,174
"def wrapper(self, *args, **kwargs): <TAB> try: <TAB>  <TAB> return fun(self, *args, **kwargs) <TAB> except OSError: <TAB>  <TAB> # support for private module import <TAB>  <TAB> if NoSuchProcess is None or AccessDenied is None: <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> err = sys.exc_info()[1] <TAB>  <TAB> if err.errno in ACCESS_DENIED_SET: <TAB>  <TAB>  <TAB> raise AccessDenied(self.pid, self._name) <MASK> raise NoSuchProcess(self.pid, self._name) <TAB>  <TAB> raise",if err . errno == errno . ESRCH :,137
"def getData(self, tagpath, pos, end, clean=False): <TAB> if clean: <TAB>  <TAB> digits_only = re.compile(rb""""""([0-9]+)"""""") <TAB> argres = [] <TAB> (foundat, argt) = self.findinDoc(tagpath, pos, end) <TAB> if (argt != None) and (len(argt) > 0): <TAB>  <TAB> argList = argt.split(b""|"") <TAB>  <TAB> for strval in argList: <TAB>  <TAB>  <TAB> if clean: <TAB>  <TAB>  <TAB>  <TAB> m = re.search(digits_only, strval) <MASK> strval = m.group() <TAB>  <TAB>  <TAB> argres.append(int(strval)) <TAB> return argres",if m != None :,164
"def save_related(self, request, form, formsets, change): <TAB> old_cms_pages = form.instance.cms_pages.all() <TAB> new_cms_pages = form.cleaned_data.pop(""cms_pages"") <TAB> # remove old <TAB> for page in old_cms_pages: <MASK> for pp in ProductPageModel.objects.filter(product=form.instance, page=page): <TAB>  <TAB>  <TAB>  <TAB> pp.delete() <TAB> # add new <TAB> for page in new_cms_pages: <TAB>  <TAB> if page not in old_cms_pages: <TAB>  <TAB>  <TAB> ProductPageModel.objects.create(product=form.instance, page=page) <TAB> return super().save_related(request, form, formsets, change)",if page not in new_cms_pages :,193
"def __mul__(self, other): <TAB> if isinstance(other, Vector3): <TAB>  <TAB> # TODO component-wise mul/div in-place and on Vector2; docs. <MASK> _class = Point3 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _class = Vector3 <TAB>  <TAB> return _class(self.x * other.x, self.y * other.y, self.z * other.z) <TAB> else: <TAB>  <TAB> assert type(other) in scalar_types <TAB>  <TAB> return Vector3(self.x * other, self.y * other, self.z * other)",if self . __class__ is Point3 or other . __class__ is Point3 :,155
"def create_time(self): <TAB> # special case for kernel process PIDs; return system boot time <TAB> if self.pid in (0, 4): <TAB>  <TAB> return boot_time() <TAB> try: <TAB>  <TAB> return cext.proc_create_time(self.pid) <TAB> except OSError: <TAB>  <TAB> err = sys.exc_info()[1] <MASK> return cext.proc_create_time_2(self.pid) <TAB>  <TAB> raise",if err . errno in ACCESS_DENIED_SET :,123
"def _chk_addr_relation_route(self, address_id): <TAB> # Check exist of related routing data. <TAB> relate_list = [] <TAB> gateways = self.routing_tbl.get_gateways() <TAB> for gateway in gateways: <TAB>  <TAB> address = self.address_data.get_data(ip=gateway) <TAB>  <TAB> if address is not None: <MASK> relate_list.append(address.address_id) <TAB>  <TAB>  <TAB> elif address.address_id == address_id: <TAB>  <TAB>  <TAB>  <TAB> relate_list = [address_id] <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return relate_list",if address_id == REST_ALL and address . address_id not in relate_list :,170
"def check_acl_unknown(self, item): <TAB> acl = item.config.get(""Grants"", {}) <TAB> for key in acl.keys(): <MASK> entity = Entity(category=""ACL"", value=key) <TAB>  <TAB>  <TAB> self.record_unknown_access(item, entity, actions=acl[key])",if key . lower ( ) not in self . KNOWN_ACLS :,91
"def createFields(self): <TAB> i = 1 <TAB> while i < self.constant_pool_length: <TAB>  <TAB> name = ""%s[%d]"" % (self.name, i) <TAB>  <TAB> yield CPInfo(self, name) <TAB>  <TAB> i += 1 <MASK> i += 1","if self [ name ] . constant_type in ( ""Long"" , ""Double"" ) :",85
"def elb_ref_policy(elb_name, policy_names): <TAB> ref_policies = list() <TAB> client = get_client() <TAB> response = client.describe_load_balancer_policies( <TAB>  <TAB> LoadBalancerName=elb_name, PolicyNames=policy_names <TAB> ) <TAB> policies = response[""PolicyDescriptions""] <TAB> for policy in policies: <MASK> for attribute in policy[""PolicyAttributeDescriptions""]: <TAB>  <TAB>  <TAB>  <TAB> if attribute[""AttributeName""] == ""Reference-Security-Policy"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ref_policies.append(attribute[""AttributeValue""]) <TAB> return ref_policies","if policy [ ""PolicyTypeName"" ] == ""SSLNegotiationPolicyType"" :",173
"def Decode(decoder): <TAB> type_id = 0 <TAB> message = None <TAB> while 1: <TAB>  <TAB> tag = decoder.getVarInt32() <TAB>  <TAB> if tag == TAG_END_ITEM_GROUP: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if tag == TAG_TYPE_ID: <TAB>  <TAB>  <TAB> type_id = decoder.getVarUint64() <TAB>  <TAB>  <TAB> continue <MASK> message = decoder.getPrefixedString() <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tag == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> decoder.skipData(tag) <TAB> if type_id == 0 or message is None: <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB> return (type_id, message)",if tag == TAG_MESSAGE :,177
"def readfd(fd): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return os.read(fd, 1) <TAB>  <TAB> except OSError as e: <MASK> raise <TAB>  <TAB>  <TAB> hubs.trampoline(fd, read=True)",if e . errno != errno . EAGAIN :,78
"def set_menu_bar(self, menubar): <TAB> if menubar is not self._menubar: <MASK> self.remove(self._menubar) <TAB>  <TAB> self._menubar = menubar <TAB>  <TAB> if menubar: <TAB>  <TAB>  <TAB> if menubar.width == 0: <TAB>  <TAB>  <TAB>  <TAB> menubar.width = self.width <TAB>  <TAB>  <TAB>  <TAB> menubar.anchor = ""lr"" <TAB>  <TAB>  <TAB> self.add(menubar)",if self . _menubar :,101
"def _socket_opts(): <TAB> for opt in (""https"", ""http"", ""socket""): <TAB>  <TAB> if opt in uwsgi.opt: <TAB>  <TAB>  <TAB> val = uwsgi.opt[opt] <MASK> for v in val: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield (opt, v) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield (opt, val)","if isinstance ( val , list ) :",95
"def validate_seat_category_mapping(self, value): <TAB> if not self.instance or not self.instance.pk: <MASK> raise ValidationError( <TAB>  <TAB>  <TAB>  <TAB> ""You cannot specify seat category mappings on event creation."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return {""seat_category_mapping"": {}} <TAB> item_cache = {i.pk: i for i in self.instance.items.all()} <TAB> result = {} <TAB> for k, item in value[""seat_category_mapping""].items(): <TAB>  <TAB> if item not in item_cache: <TAB>  <TAB>  <TAB> raise ValidationError(""Item '{id}' does not exist."".format(id=item)) <TAB>  <TAB> result[k] = item_cache[item] <TAB> return {""seat_category_mapping"": result}","if value and value [ ""seat_category_mapping"" ] :",198
"def clear_suffix_value(self, suffix_or_name, expand=True): <TAB> """"""Set the suffix value for this component data"""""" <TAB> if isinstance(suffix_or_name, six.string_types): <TAB>  <TAB> import pyomo.core.base.suffix <TAB>  <TAB> for name_, suffix_ in pyomo.core.base.suffix.active_suffix_generator( <TAB>  <TAB>  <TAB> self.model() <TAB>  <TAB> ): <MASK> suffix_.clear_value(self, expand=expand) <TAB>  <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> suffix_or_name.clear_value(self, expand=expand)",if suffix_or_name == name_ :,158
"def testDBStatus(self): <TAB> ""Verify db status function"" <TAB> self.assertRaises(TypeError, self.db.status, ""zebra"") <TAB> self.assertRaises(apsw.SQLError, self.db.status, 2323) <TAB> for i in apsw.mapping_db_status: <MASK> continue <TAB>  <TAB> res = self.db.status(getattr(apsw, i)) <TAB>  <TAB> self.assertEqual(len(res), 2) <TAB>  <TAB> self.assertEqual(type(res), tuple) <TAB>  <TAB> if i != ""SQLITE_DBSTATUS_CACHE_USED"": <TAB>  <TAB>  <TAB> self.assertTrue(res[0] <= res[1])","if type ( i ) != type ( """" ) :",166
"def _current_url(self): <TAB> """"""Convenience method to get the current url."""""" <TAB> try: <TAB>  <TAB> return self._tabbed_browser.current_url() <TAB> except qtutils.QtValueError as e: <TAB>  <TAB> msg = ""Current URL is invalid"" <MASK> msg += "" ({})"".format(e.reason) <TAB>  <TAB> msg += ""!"" <TAB>  <TAB> raise cmdutils.CommandError(msg)",if e . reason :,103
"def match_instances_and_subnets_callback( <TAB> self, current_config, path, current_path, instance_id, callback_args): <TAB> if ( <TAB>  <TAB> ""ec2"" in self.service_list and ""vpc"" in self.service_list <TAB> ):  # validate both services were included in run <TAB>  <TAB> subnet_id = current_config[""SubnetId""] <TAB>  <TAB> if subnet_id: <TAB>  <TAB>  <TAB> vpc = self.subnet_map[subnet_id] <TAB>  <TAB>  <TAB> subnet = self.services[""vpc""][""regions""][vpc[""region""]][""vpcs""][ <TAB>  <TAB>  <TAB>  <TAB> vpc[""vpc_id""] <TAB>  <TAB>  <TAB> ][""subnets""][subnet_id] <TAB>  <TAB>  <TAB> manage_dictionary(subnet, ""instances"", []) <MASK> subnet[""instances""].append(instance_id)","if instance_id not in subnet [ ""instances"" ] :",200
"def best_match(self, offers, default_match=None): <TAB> best_quality = -1 <TAB> best_match = default_match <TAB> for offer in offers: <TAB>  <TAB> _check_offer(offer) <TAB>  <TAB> if isinstance(offer, (list, tuple)): <TAB>  <TAB>  <TAB> offer, quality = offer <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> quality = 1 <MASK> best_offer = offer <TAB>  <TAB>  <TAB> best_quality = quality <TAB> return best_offer",if quality > best_quality :,118
"def common_dir_prefix(paths: List[str]) -> str: <TAB> if not paths: <TAB>  <TAB> return ""."" <TAB> cur = os.path.dirname(os.path.normpath(paths[0])) <TAB> for path in paths[1:]: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> path = os.path.dirname(os.path.normpath(path)) <MASK> cur = path <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return cur or "".""",if ( cur + os . sep ) . startswith ( path + os . sep ) :,123
"def test_chflags(self): <TAB> if hasattr(posix, ""chflags""): <TAB>  <TAB> st = os.stat(test_support.TESTFN) <MASK> posix.chflags(test_support.TESTFN, st.st_flags)","if hasattr ( st , ""st_flags"" ) :",66
"def reset_signals(handler=_shutdown_cleanup, full=False): <TAB> for sig in TERMSIGS_FULL if full else TERMSIGS_DEFAULT: <TAB>  <TAB> num = signum(sig) <TAB>  <TAB> if num: <MASK> maybe_setsignal(num, handler) <TAB> for sig in TERMSIGS_IGNORE: <TAB>  <TAB> num = signum(sig) <TAB>  <TAB> if num: <TAB>  <TAB>  <TAB> maybe_setsignal(num, signal.SIG_IGN)","if _should_override_term_signal ( sig , signal . getsignal ( num ) ) :",135
"def layout_len(layout): <TAB> r = 0 <TAB> for f in layout: <TAB>  <TAB> if isinstance(f[1], (int, tuple)):  # cases 1/2 <TAB>  <TAB>  <TAB> if len(f) == 3: <TAB>  <TAB>  <TAB>  <TAB> fname, fsize, fdirection = f <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> fname, fsize = f <TAB>  <TAB> elif isinstance(f[1], list):  # case 3 <TAB>  <TAB>  <TAB> fname, fsublayout = f <TAB>  <TAB>  <TAB> fsize = layout_len(fsublayout) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError <MASK> r += fsize[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> r += fsize <TAB> return r","if isinstance ( fsize , tuple ) :",170
"def _check_launch_index(value): <TAB> if ""instance_properties"" in value: <TAB>  <TAB> if ""launch_index"" in value[""instance_properties""]: <TAB>  <TAB>  <TAB> index = value[""instance_properties""][""launch_index""] <MASK> return True <TAB> return False",if index == expected_index :,76
"def _iterateElementsPairwise(self, inputStream): <TAB> elementBuffer = [] <TAB> prototype = ( <TAB>  <TAB> chord.Chord, <TAB>  <TAB> note.Note, <TAB>  <TAB> note.Rest, <TAB> ) <TAB> for element in inputStream.flat: <TAB>  <TAB> if not isinstance(element, prototype): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elementBuffer.append(element) <MASK> yield tuple(elementBuffer) <TAB>  <TAB>  <TAB> elementBuffer.pop(0)",if len ( elementBuffer ) == 2 :,119
"def do_PASS(self, arg): <TAB> if self.authenticated: <TAB>  <TAB> self.respond(b""503 User already authenticated."") <TAB> if not self.username: <TAB>  <TAB> self.respond(b""503 Login with USER first."") <TAB> if self.authentication_ok(user_pass=arg): <MASK> self.respond(b""230 Log in Successful."") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _msg = ""220-{}\r\n"".format(self.config.motd) <TAB>  <TAB>  <TAB> self.respond(_msg) <TAB>  <TAB>  <TAB> self.respond(b""220 "") <TAB> else: <TAB>  <TAB> self.invalid_login_attempt += 1 <TAB>  <TAB> self.respond(b""530 Authentication Failed."")",if not self . config . motd :,185
"def step(self, simgr, stash=""active"", **kwargs): <TAB> simgr = simgr.step(stash=stash, **kwargs) <TAB> if len(simgr.stashes[stash]) > 1: <TAB>  <TAB> self._random.shuffle(simgr.stashes[stash]) <TAB>  <TAB> simgr.split(from_stash=stash, to_stash=self.deferred_stash, limit=1) <TAB> if len(simgr.stashes[stash]) == 0: <MASK> return simgr <TAB>  <TAB> simgr.stashes[stash].append(simgr.stashes[self.deferred_stash].pop()) <TAB> return simgr",if len ( simgr . stashes [ self . deferred_stash ] ) == 0 :,195
"def _wait_operation(self, id, timeout=DEFAULT_TIMEOUT, check_interval=DEFAULT_INTERVAL): <TAB> """"""Wait for an operation to succeed"""""" <TAB> for i in range(0, timeout, check_interval): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> # pylint: disable=no-member <TAB>  <TAB>  <TAB> op = self.connection.request(""operation.info"", int(id)).object <MASK> return True <TAB>  <TAB>  <TAB> if op[""step""] in [""ERROR"", ""CANCEL""]: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> except (KeyError, IndexError): <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> raise GandiException(1002, e) <TAB>  <TAB> time.sleep(check_interval) <TAB> return False","if op [ ""step"" ] == ""DONE"" :",183
"def decorator(inner): <TAB> doc = inner.__doc__.split(""\n"") <TAB> i = 0 <TAB> s = 0 <TAB> for line in doc: <TAB>  <TAB> sline = line.strip() <MASK> for char in line: <TAB>  <TAB>  <TAB>  <TAB> if char == "" "": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> s += 1 <TAB>  <TAB>  <TAB> break <TAB>  <TAB> i += 1 <TAB> spaces = "" "" * (s + 4) <TAB> to_insert = "" "" * s + ""::\n\n"" + spaces <TAB> to_insert += bibtex.strip().replace(""\n"", ""\n"" + spaces).rstrip() <TAB> doc.insert(i, """") <TAB> doc.insert(i, to_insert) <TAB> set_doc(inner, ""\n"".join(doc)) <TAB> return inner","if sline == ""Args:"" or sline == ""Returns:"" :",196
"def test_ls(self): <TAB> with patch(""salt.modules.pillar.items"", MagicMock(return_value=pillar_value_1)): <TAB>  <TAB> ls = sorted(pillarmod.ls()) <MASK> self.assertCountEqual(ls, [""a"", ""b""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertEqual(ls, [""a"", ""b""])",if six . PY3 :,98
"def completemacro(self, macro): <TAB> ""Complete the macro with the parameters read."" <TAB> self.contents = [macro.instantiate()] <TAB> replaced = [False] * len(self.values) <TAB> for parameter in self.searchall(MacroParameter): <TAB>  <TAB> index = parameter.number - 1 <MASK> Trace.error(""Macro parameter index out of bounds: "" + unicode(index)) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> replaced[index] = True <TAB>  <TAB> parameter.contents = [self.values[index].clone()] <TAB> for index in range(len(self.values)): <TAB>  <TAB> if not replaced[index]: <TAB>  <TAB>  <TAB> self.addfilter(index, self.values[index])",if index >= len ( self . values ) :,170
"def get_logged_in_user(self): <TAB> if session.get(""logged_in""): <MASK> return g.user <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB>  <TAB> self.User.select() <TAB>  <TAB>  <TAB>  <TAB> .where(self.User.active == True, self.User.id == session.get(""user_pk"")) <TAB>  <TAB>  <TAB>  <TAB> .get() <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> except self.User.DoesNotExist: <TAB>  <TAB>  <TAB> pass","if getattr ( g , ""user"" , None ) :",124
"def _request(self, method, url, msg_on_fail=None, **kwargs): <TAB> try: <TAB>  <TAB> response = self.session.request(method, url, **kwargs) <MASK> msg = ( <TAB>  <TAB>  <TAB>  <TAB> ""Failure. URL: {}, data: {}"".format(url, kwargs) <TAB>  <TAB>  <TAB>  <TAB> if not msg_on_fail <TAB>  <TAB>  <TAB>  <TAB> else msg_on_fail <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return response <TAB> except RequestException as e: <TAB>  <TAB> msg = str(e) <TAB> raise plugin.PluginError( <TAB>  <TAB> ""Error when trying to send request to qBittorrent: {}"".format(msg) <TAB> )","if response == ""Fails."" :",168
"def update(self, project, taskid, obj={}, **kwargs): <TAB> obj = dict(obj) <TAB> obj.update(kwargs) <TAB> obj[""updatetime""] = time.time() <TAB> pipe = self.redis.pipeline(transaction=False) <TAB> pipe.hmset(self._gen_key(project, taskid), self._stringify(obj)) <TAB> if ""status"" in obj: <TAB>  <TAB> for status in range(1, 5): <MASK> pipe.sadd(self._gen_status_key(project, status), taskid) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> pipe.srem(self._gen_status_key(project, status), taskid) <TAB> pipe.execute()","if status == obj [ ""status"" ] :",176
"def send_welcome(message): <TAB> unique_code = extract_unique_code(message.text) <TAB> if unique_code:  # if the '/start' command contains a unique_code <TAB>  <TAB> username = get_username_from_storage(unique_code) <MASK> # if the username exists in our database <TAB>  <TAB>  <TAB> save_chat_id(message.chat.id, username) <TAB>  <TAB>  <TAB> reply = ""Hello {0}, how are you?"".format(username) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> reply = ""I have no clue who you are..."" <TAB> else: <TAB>  <TAB> reply = ""Please visit me via a provided URL from the website."" <TAB> bot.reply_to(message, reply)",if username :,167
"def getVerbosityFormat(verbosity, fmt="" %(message)s"", addtime=True): <TAB> """"""Custom log format for the verbose runs"""""" <TAB> if verbosity > 1:  # pragma: no cover <TAB>  <TAB> if verbosity > 3: <TAB>  <TAB>  <TAB> fmt = "" | %(module)15.15s-%(levelno)-2d: %(funcName)-20.20s |"" + fmt <TAB>  <TAB> if verbosity > 2: <TAB>  <TAB>  <TAB> fmt = ( <TAB>  <TAB>  <TAB>  <TAB> "" +%(relativeCreated)5d %(thread)X %(name)-25.25s %(levelname)-5.5s"" <TAB>  <TAB>  <TAB>  <TAB> + fmt <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> fmt = "" %(thread)X %(levelname)-5.5s"" + fmt <MASK> fmt = "" %(asctime)-15s"" + fmt <TAB> return fmt",if addtime :,199
def nodes_to_build(self): <TAB> ret = [] <TAB> for node in self.ordered_iterate(): <MASK> if node.ref.copy_clear_rev() not in ret: <TAB>  <TAB>  <TAB>  <TAB> ret.append(node.ref.copy_clear_rev()) <TAB> return ret,if node . binary == BINARY_BUILD :,80
"def update_environment(self, d): <TAB> for k in d: <MASK> if k in os.environ: <TAB>  <TAB>  <TAB>  <TAB> del os.environ[k] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> os.environ[k] = d[k]",if d [ k ] is None :,71
"def load_label_dict(filename): <TAB> d = dict() <TAB> tag_dict = set() <TAB> with open(filename, ""r"") as f: <TAB>  <TAB> for i, line in enumerate(f): <TAB>  <TAB>  <TAB> line = line.strip() <TAB>  <TAB>  <TAB> if line.startswith(""B-""): <TAB>  <TAB>  <TAB>  <TAB> tag_dict.add(line[2:]) <MASK> tag_dict.add(line[2:]) <TAB>  <TAB> index = 0 <TAB>  <TAB> for tag in tag_dict: <TAB>  <TAB>  <TAB> d[""B-"" + tag] = index <TAB>  <TAB>  <TAB> index += 1 <TAB>  <TAB>  <TAB> d[""I-"" + tag] = index <TAB>  <TAB>  <TAB> index += 1 <TAB>  <TAB> d[""O""] = index <TAB> return d","elif line . startswith ( ""I-"" ) :",180
"def __call__(self, string, lexer=shnake_lex): <TAB> """"""Interpret `file` data as a command line sequence."""""" <TAB> line = 0 <TAB> result = [] <TAB> buffer = LineBuffer(string) <TAB> data = """" <TAB> while True: <MASK> data = buffer.readline() <TAB>  <TAB>  <TAB> if not data: <TAB>  <TAB>  <TAB>  <TAB> return result <TAB>  <TAB> line += 1 <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> pipeline = lexer(data[:-1], line=line) <TAB>  <TAB>  <TAB> result += pipeline <TAB>  <TAB>  <TAB> data = """" <TAB>  <TAB>  <TAB> if string is None: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> except SyntaxWarning as error: <TAB>  <TAB>  <TAB> addline = buffer.readline() <TAB>  <TAB>  <TAB> if not addline: <TAB>  <TAB>  <TAB>  <TAB> raise error <TAB>  <TAB>  <TAB> data += addline <TAB> return result",if not data :,197
"def _process_property_change(self, msg): <TAB> msg = super(VTKVolume, self)._process_property_change(msg) <TAB> if self.object is not None: <TAB>  <TAB> slice_params = {""slice_i"": 0, ""slice_j"": 1, ""slice_k"": 2} <TAB>  <TAB> for k, v in msg.items(): <TAB>  <TAB>  <TAB> sub_dim = self._subsample_dimensions <TAB>  <TAB>  <TAB> ori_dim = self._orginal_dimensions <MASK> index = slice_params[k] <TAB>  <TAB>  <TAB>  <TAB> msg[k] = int(np.round(v * ori_dim[index] / sub_dim[index])) <TAB> return msg",if k in slice_params :,170
"def prepare_query_value(self, op, value): <TAB> if not isinstance(op, basestring): <TAB>  <TAB> return value <TAB> if op.lstrip(""i"") in (""startswith"", ""endswith"", ""contains"", ""exact""): <TAB>  <TAB> flags = 0 <MASK> flags = re.IGNORECASE <TAB>  <TAB>  <TAB> op = op.lstrip(""i"") <TAB>  <TAB> regex = r""%s"" <TAB>  <TAB> if op == ""startswith"": <TAB>  <TAB>  <TAB> regex = r""^%s"" <TAB>  <TAB> elif op == ""endswith"": <TAB>  <TAB>  <TAB> regex = r""%s$"" <TAB>  <TAB> elif op == ""exact"": <TAB>  <TAB>  <TAB> regex = r""^%s$"" <TAB>  <TAB> # escape unsafe characters which could lead to a re.error <TAB>  <TAB> value = re.escape(value) <TAB>  <TAB> value = re.compile(regex % value, flags) <TAB> return value","if op . startswith ( ""i"" ) :",199
"def test_save_to_path(httpserver): <TAB> """"""Save directly to file"""""" <TAB> filepath = os.path.join(tempdir, ""fubar.txt"") <TAB> assert not os.path.exists(tempdir) <TAB> assert not os.path.exists(filepath) <TAB> httpserver.serve_content(fubar_bytes, headers={""Content-Type"": ""text/plain""}) <TAB> try: <TAB>  <TAB> r = web.get(httpserver.url) <TAB>  <TAB> assert r.status_code == 200 <TAB>  <TAB> r.save_to_path(filepath) <TAB>  <TAB> assert os.path.exists(filepath) <TAB>  <TAB> data = open(filepath).read() <TAB>  <TAB> assert data == fubar_bytes <TAB> finally: <MASK> shutil.rmtree(tempdir)",if os . path . exists ( tempdir ) :,189
"def output(self, data, context): <TAB> """"""Outputs the provided data using the transformations and output format specified for this CLI endpoint"""""" <TAB> if self.transform: <MASK> self.transform.context = context <TAB>  <TAB> data = self.transform(data) <TAB> if hasattr(data, ""read""): <TAB>  <TAB> data = data.read().decode(""utf8"") <TAB> if data is not None: <TAB>  <TAB> data = self.outputs(data) <TAB>  <TAB> if data: <TAB>  <TAB>  <TAB> sys.stdout.buffer.write(data) <TAB>  <TAB>  <TAB> if not data.endswith(b""\n""): <TAB>  <TAB>  <TAB>  <TAB> sys.stdout.buffer.write(b""\n"") <TAB> return data","if hasattr ( self . transform , ""context"" ) :",170
"def _connect(self): <TAB> for vertex in list(self._representation.keys()): <TAB>  <TAB> for ref, ref_object in enumerate(self._representation[vertex][""referenceList""]): <TAB>  <TAB>  <TAB> reference = ref_object[""reference""] <TAB>  <TAB>  <TAB> self.edges += 1 <TAB>  <TAB>  <TAB> if reference not in self._representation: <MASK> self._representation[reference] = { <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""vertexID"": reference, <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""referenceList"": [], <TAB>  <TAB>  <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise Exception(""Field %s not defined"" % reference) <TAB>  <TAB>  <TAB> ref_object[""reference""] = self._representation[reference]",if reference in self . excludeList :,175
"def configure_and_update_options(options): <TAB> if ( <TAB>  <TAB> options.dac_connection <TAB>  <TAB> and options.server <TAB>  <TAB> and not options.server.lower().startswith(""admin:"") <TAB> ): <TAB>  <TAB> options.server = ""admin:"" + options.server <TAB> if not options.integrated_auth: <TAB>  <TAB> if not options.username: <TAB>  <TAB>  <TAB> options.username = input(u""Username (press enter for sa):"") or u""sa"" <MASK> pw = getpass.getpass() <TAB>  <TAB>  <TAB> if pw is not None: <TAB>  <TAB>  <TAB>  <TAB> pw = pw.replace(""\r"", """").replace(""\n"", """") <TAB>  <TAB>  <TAB> options.password = pw",if not options . password :,164
"def get_mtime(filename): <TAB> if settings.COMPRESS_MTIME_DELAY: <TAB>  <TAB> key = get_mtime_cachekey(filename) <TAB>  <TAB> mtime = cache.get(key) <MASK> mtime = os.path.getmtime(filename) <TAB>  <TAB>  <TAB> cache.set(key, mtime, settings.COMPRESS_MTIME_DELAY) <TAB>  <TAB> return mtime <TAB> return os.path.getmtime(filename)",if mtime is None :,102
"def list_all_notempty(session=None): <TAB> ret = [] <TAB> results = session.query( <TAB>  <TAB> LegacyArchiveDocument.bucket, <TAB>  <TAB> LegacyArchiveDocument.archiveId, <TAB>  <TAB> LegacyArchiveDocument.userId, <TAB> ).filter(LegacyArchiveDocument.jsondata != ""{}"") <TAB> for result in results: <TAB>  <TAB> obj = {} <TAB>  <TAB> for i in range(0, len(list(result.keys()))): <TAB>  <TAB>  <TAB> k = list(result.keys())[i] <TAB>  <TAB>  <TAB> obj[k] = result[i] <MASK> ret.append(obj) <TAB> return ret",if obj :,148
"def get_settings_with_defaults(defaults, org): <TAB> values = org.settings.get(""settings"", {}) <TAB> settings = {} <TAB> for setting, default_value in defaults.items(): <TAB>  <TAB> current_value = values.get(setting) <MASK> continue <TAB>  <TAB> if current_value is None: <TAB>  <TAB>  <TAB> settings[setting] = default_value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> settings[setting] = current_value <TAB> settings[""auth_google_apps_domains""] = org.google_apps_domains <TAB> return settings",if current_value is None and default_value is None :,142
"def on_edit(self): <TAB> name = self.listview.get_selected() <TAB> if name: <TAB>  <TAB> tool = self.manager.get_tool(name) <TAB>  <TAB> properties = EditCustomToolDialog(self, tool=tool).run() <MASK> tool.update(**properties) <TAB>  <TAB>  <TAB> tool.write() <TAB> self.listview.refresh()",if properties :,92
"def wait(self, timeout): <TAB> try: <TAB>  <TAB> self.notify() <TAB>  <TAB> ret = select.select(self.wait_fds, [], [], timeout) <MASK> if self.PIPE[0] in ret[0]: <TAB>  <TAB>  <TAB>  <TAB> os.read(self.PIPE[0], 1) <TAB>  <TAB>  <TAB> return ret[0] <TAB> except select.error as e: <TAB>  <TAB> if e.args[0] == errno.EINTR: <TAB>  <TAB>  <TAB> return self.sockets <TAB>  <TAB> if e.args[0] == errno.EBADF: <TAB>  <TAB>  <TAB> if self.nr < 0: <TAB>  <TAB>  <TAB>  <TAB> return self.sockets <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise StopWaiting <TAB>  <TAB> raise",if ret [ 0 ] :,177
"def wait_for_no_account(client, rg, acc_name, live=False): <TAB> # a workaround for the async nature of certain ARM processes <TAB> co = 0 <TAB> while co < 5: <TAB>  <TAB> co += 1 <MASK> time.sleep(2) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> account = client.accounts.get(rg, acc_name) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> # not found is an exception case (status code 200 expected) <TAB>  <TAB>  <TAB> # and is actually what we are waiting for <TAB>  <TAB>  <TAB> break",if live :,134
def percentage(self): <TAB> if self._percentage is None: <MASK> matches = self._get_matches_for_ref() <TAB>  <TAB>  <TAB> self._percentage = sum(match.percentage for match in matches) // len( <TAB>  <TAB>  <TAB>  <TAB> matches <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._percentage = 0 <TAB> return self._percentage,if self . dupes :,92
"def print_state(self): <TAB> for t in self.trajectories.trajectories: <TAB>  <TAB> print(""---------"") <MASK> print(""trajectory isn't active."") <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> last_obs = t.last_time_step.observation <TAB>  <TAB> print(str(last_obs))",if not t . is_active :,80
"def doGetResoldSubscriptions(): <TAB> res = buildGAPIObject(""reseller"") <TAB> customerId = sys.argv[3] <TAB> customerAuthToken = None <TAB> i = 4 <TAB> while i < len(sys.argv): <TAB>  <TAB> myarg = sys.argv[i].lower().replace(""_"", """") <MASK> customerAuthToken = sys.argv[i + 1] <TAB>  <TAB>  <TAB> i += 2 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> controlflow.invalid_argument_exit(myarg, ""gam info resoldsubscriptions"") <TAB> result = gapi.call( <TAB>  <TAB> res.subscriptions(), <TAB>  <TAB> ""list"", <TAB>  <TAB> customerId=customerId, <TAB>  <TAB> customerAuthToken=customerAuthToken, <TAB> ) <TAB> display.print_json(result)","if myarg in [ ""customerauthtoken"" , ""transfertoken"" ] :",195
"def convert_mixinrefs(elem): <TAB> global adjusted_node <TAB> for child in elem: <TAB>  <TAB> convert_mixinrefs(child) <TAB> mixinrefs = elem.get(""mixinrefs"") <TAB> if mixinrefs and elem.tag == ""scope"": <TAB>  <TAB> for m in mixinrefs.split("" ""): <MASK> continue <TAB>  <TAB>  <TAB> ET.SubElement(elem, ""import"", symbol=m) <TAB>  <TAB>  <TAB> adjusted_node += 1 <TAB>  <TAB> # XXX Trent - non-deprecated way to delete an attribute? <TAB>  <TAB> del elem.attrib[""mixinrefs""]","if m == ""Kernel"" and elem . get ( ""classrefs"" ) :",149
"def build_lazyref(self, value): <TAB> if isinstance(value, LazyReference): <MASK> value = LazyReference( <TAB>  <TAB>  <TAB>  <TAB> value.document_type, value.pk, passthrough=self.passthrough <TAB>  <TAB>  <TAB> ) <TAB> elif value is not None: <TAB>  <TAB> if isinstance(value, (dict, SON)): <TAB>  <TAB>  <TAB> value = LazyReference( <TAB>  <TAB>  <TAB>  <TAB> get_document(value[""_cls""]), <TAB>  <TAB>  <TAB>  <TAB> value[""_ref""].id, <TAB>  <TAB>  <TAB>  <TAB> passthrough=self.passthrough, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> elif isinstance(value, Document): <TAB>  <TAB>  <TAB> value = LazyReference(type(value), value.pk, passthrough=self.passthrough) <TAB> return value",if value . passthrough != self . passthrough :,183
"def add_checker(self, namespace, checker): <TAB> for c in pyomo.checker.runner.ModelCheckRunner._checkers(all=True): <TAB>  <TAB> if c._checkerName() == checker: <MASK> namespace.checkers[c._checkerPackage()] = [] <TAB>  <TAB>  <TAB> if c._checkerName() not in namespace.checkers[c._checkerPackage()]: <TAB>  <TAB>  <TAB>  <TAB> namespace.checkers[c._checkerPackage()].append(c._checkerName())","if namespace . checkers . get ( c . _checkerPackage ( ) , None ) is None :",126
"def wrapper(*args, schedule, **kwargs): <TAB> for loop, n in schedule: <TAB>  <TAB> approx_n = axis_size if n is None else n <MASK> raise SkipTest(""this test requires more XLA devices"") <TAB> return fun(*args, schedule=schedule, **kwargs)","if loop == ""parallel"" and approx_n > xla_bridge . device_count ( ) :",88
"def _con_write(self, data): <TAB> if self._setting_prompt: <MASK> self._setting_prompt = False <TAB>  <TAB> return <TAB> if not self._complete.is_set(): <TAB>  <TAB> if self._codepage: <TAB>  <TAB>  <TAB> data = data.decode(self._codepage, errors=""replace"") <TAB>  <TAB> self.stdout.write(data) <TAB>  <TAB> self.stdout.flush() <TAB>  <TAB> if ""\n"" in data: <TAB>  <TAB>  <TAB> self.prompt = data.rsplit(""\n"", 1)[-1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.prompt += data",if self . prompt in data :,147
"def handle_match_etags(self, match): <TAB> etags = match.meta.get(""etags"", None) <TAB> if etags is None: <TAB>  <TAB> return <TAB> _etags = [t.strip() for t in etags.split("","")] <TAB> for s in match.strings: <TAB>  <TAB> if s[1] not in _etags: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> tag = s[2].decode() if isinstance(s[2], bytes) else s[2] <MASK> match.tags.append(tag)",if tag not in match . tags :,136
"def _get_rules_to_test(self, target): <TAB> rules_to_test = [] <TAB> for rule in common.iterate_over_rules(): <MASK> continue <TAB>  <TAB> if not xml_operations.find_rule_in_benchmark( <TAB>  <TAB>  <TAB> self.datastream, self.benchmark_id, rule.id <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> logging.error( <TAB>  <TAB>  <TAB>  <TAB> ""Rule '{0}' isn't present in benchmark '{1}' in '{2}'"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> rule.id, self.benchmark_id, self.datastream <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> rules_to_test.append(rule) <TAB> return rules_to_test","if not self . _rule_should_be_tested ( rule , target ) :",189
"def init(self, result_row=None): <TAB> for col, col_type in self.cols_def.items(): <TAB>  <TAB> if not result_row: <TAB>  <TAB>  <TAB> value = None <MASK> value = Utils.string_to_date(result_row[col]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = result_row[col] <TAB>  <TAB> setattr(self, col, value) <TAB> if not result_row: <TAB>  <TAB> self.empty = True",elif col_type == datetime :,119
"def remove_submissions_for_task(contest_id, task_name): <TAB> with SessionGen() as session: <TAB>  <TAB> task = ( <TAB>  <TAB>  <TAB> session.query(Task) <TAB>  <TAB>  <TAB> .filter(Task.contest_id == contest_id) <TAB>  <TAB>  <TAB> .filter(Task.name == task_name) <TAB>  <TAB>  <TAB> .first() <TAB>  <TAB> ) <MASK> print(""Unable to find task."") <TAB>  <TAB>  <TAB> return <TAB>  <TAB> submissions = ( <TAB>  <TAB>  <TAB> session.query(Submission).filter(Submission.task_id == task.id).all() <TAB>  <TAB> ) <TAB>  <TAB> ask_and_remove(session, submissions)",if task is None :,160
"def visitAugSlice(self, node, mode): <TAB> if mode == ""load"": <TAB>  <TAB> self.visitSlice(node, 1) <TAB> elif mode == ""store"": <TAB>  <TAB> slice = 0 <TAB>  <TAB> if node.lower: <TAB>  <TAB>  <TAB> slice = slice | 1 <TAB>  <TAB> if node.upper: <TAB>  <TAB>  <TAB> slice = slice | 2 <TAB>  <TAB> if slice == 0: <TAB>  <TAB>  <TAB> self.emit(""ROT_TWO"") <MASK> self.emit(""ROT_FOUR"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.emit(""ROT_THREE"") <TAB>  <TAB> self.emit(""STORE_SLICE+%d"" % slice)",elif slice == 3 :,154
"def __init__(self): <TAB> if sys.platform.startswith(""win""): <TAB>  <TAB> pathExt = os.environ.get(""PATHEXT"", None) <MASK> exts = pathExt.split(os.pathsep) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> exts = ["".EXE"", "".COM"", "".BAT""] <TAB> else: <TAB>  <TAB> exts = [] <TAB> black.configure.SetPathEnvVar.__init__(self, ""PATH"", serializeAs=[""env""], exts=exts)",if pathExt :,119
"def save(self, *args, **kwargs): <TAB> ""Process form"" <TAB> if self.instance: <TAB>  <TAB> if self.is_valid(): <TAB>  <TAB>  <TAB> if self.cleaned_data[""location""]: <TAB>  <TAB>  <TAB>  <TAB> self.instance.location = self.cleaned_data[""location""] <TAB>  <TAB>  <TAB> if self.cleaned_data[""status""]: <TAB>  <TAB>  <TAB>  <TAB> self.instance.status = self.cleaned_data[""status""] <TAB>  <TAB>  <TAB> self.instance.save() <TAB>  <TAB>  <TAB> if self.cleaned_data[""delete""]: <MASK> self.instance.delete() <TAB>  <TAB>  <TAB>  <TAB> if self.cleaned_data[""delete""] == ""trash"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.instance.trash = True <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.instance.save()","if self . cleaned_data [ ""delete"" ] == ""delete"" :",195
"def _process_variable_description(self, name_or_desc): <TAB> vname = name_or_desc <TAB> vtype = ""string""  # default type if not defined <TAB> if "":"" in name_or_desc: <TAB>  <TAB> vtype, vname = name_or_desc.split("":"") <TAB>  <TAB> #  Fix incorrect order bug #33 <MASK> #  Swap order <TAB>  <TAB>  <TAB> vtype, vname = vname, vtype <TAB>  <TAB>  <TAB> if vtype not in self.TK_VARIABLE_TYPES: <TAB>  <TAB>  <TAB>  <TAB> msg = 'Undefined variable type in ""{0}""'.format(vname) <TAB>  <TAB>  <TAB>  <TAB> raise Exception(msg) <TAB> return (vname, vtype)",if vtype not in self . TK_VARIABLE_TYPES :,167
"def handle_data(self, data): <TAB> ""Handle date segments in help.html."" <TAB> if self.show and not self.hdrlink: <TAB>  <TAB> d = data if self.pre else data.replace(""\n"", "" "") <TAB>  <TAB> if self.tags == ""h1"": <TAB>  <TAB>  <TAB> self.hprefix = d[0 : d.index("" "")] <TAB>  <TAB> if self.tags in [""h1"", ""h2"", ""h3""] and self.hprefix != """": <MASK> d = d[len(self.hprefix) :].strip() <TAB>  <TAB>  <TAB> self.header += d <TAB>  <TAB> self.text.insert(""end"", d, (self.tags, self.chartags))",if d [ 0 : len ( self . hprefix ) ] == self . hprefix :,184
"def prepare_config(self, config): <TAB> if isinstance(config, bool): <TAB>  <TAB> config = {} <TAB> if ""filter"" in config: <TAB>  <TAB> filter = config[""filter""] <MASK> filter[""label""] = filter[""label""].lower() <TAB>  <TAB> if ""state"" in filter: <TAB>  <TAB>  <TAB> filter[""state""] = filter[""state""].capitalize() <TAB> super().prepare_config(config) <TAB> return config","if ""label"" in filter :",107
"def _AddBuildTarget(self, test_suite, target_tree, extra_args_set): <TAB> if not test_suite.IsFullMake(): <TAB>  <TAB> build_dir = test_suite.GetBuildPath() <MASK> extra_args_set.append(test_suite.GetExtraBuildArgs()) <TAB>  <TAB> for path in test_suite.GetBuildDependencies(self._options): <TAB>  <TAB>  <TAB> self._AddBuildTargetPath(path, target_tree)","if self . _AddBuildTargetPath ( build_dir , target_tree ) :",125
"def ope(self, state): <TAB> try: <MASK> self.__last_epoch__ = state[torchbearer.EPOCH] <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> return False <TAB> except AttributeError: <TAB>  <TAB> self.__last_epoch__ = state[torchbearer.EPOCH] <TAB>  <TAB> return True",if state [ torchbearer . EPOCH ] != self . __last_epoch__ :,90
"def message(self): <TAB> if not self._message: <TAB>  <TAB> if self.drip_base.from_email_name: <TAB>  <TAB>  <TAB> from_ = ""%s <%s>"" % ( <TAB>  <TAB>  <TAB>  <TAB> self.drip_base.from_email_name, <TAB>  <TAB>  <TAB>  <TAB> self.drip_base.from_email, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> from_ = self.drip_base.from_email <TAB>  <TAB> self._message = EmailMultiAlternatives( <TAB>  <TAB>  <TAB> self.subject, self.plain, from_, [self.user.email] <TAB>  <TAB> ) <TAB>  <TAB> # check if there are html tags in the rendered template <MASK> self._message.attach_alternative(self.body, ""text/html"") <TAB> return self._message",if len ( self . plain ) != len ( self . body ) :,200
"def load_rc(self, rc_filename): <TAB> self.processing_rc = True <TAB> try: <TAB>  <TAB> rc = codecs.open(rc_filename, ""r"", ""utf-8"") <TAB>  <TAB> self.rc_filename = os.path.abspath(rc_filename) <TAB>  <TAB> for rc_cmd in rc: <TAB>  <TAB>  <TAB> if not rc_cmd.lstrip().startswith(""#""): <TAB>  <TAB>  <TAB>  <TAB> logging.debug(rc_cmd.rstrip()) <TAB>  <TAB>  <TAB>  <TAB> self.onecmd(rc_cmd) <TAB>  <TAB> rc.close() <MASK> self.end_macro() <TAB>  <TAB> self.rc_loaded = True <TAB> finally: <TAB>  <TAB> self.processing_rc = False","if hasattr ( self , ""cur_macro_def"" ) :",174
"def _get_key(key_name, config): <TAB> ec2 = _resource(""ec2"", config) <TAB> try: <TAB>  <TAB> for key in ec2.key_pairs.filter( <TAB>  <TAB>  <TAB> Filters=[{""Name"": ""key-name"", ""Values"": [key_name]}] <TAB>  <TAB> ): <MASK> return key <TAB> except botocore.exceptions.ClientError as exc: <TAB>  <TAB> handle_boto_error( <TAB>  <TAB>  <TAB> exc, ""Failed to fetch EC2 key pair {} from AWS."", cf.bold(key_name) <TAB>  <TAB> ) <TAB>  <TAB> raise exc",if key . name == key_name :,146
"def trailing_lines(self): <TAB> """"""return any remaining ignored lines."""""" <TAB> trailing = [] <TAB> i = self.first_leading_line <TAB> while i < len(self.ignored_lines): <TAB>  <TAB> token = self.ignored_lines[i] <MASK> s = self.token_raw_val(token).rstrip() + ""\n"" <TAB>  <TAB>  <TAB> trailing.append(s) <TAB>  <TAB> i += 1 <TAB> self.first_leading_line = i <TAB> return trailing",if token :,118
"def modulators(self, value): <TAB> if value: <TAB>  <TAB> self.__modulators[:] = value <MASK> self.main_controller.generator_tab_controller.refresh_modulators()","if hasattr ( self . main_controller , ""generator_tab_controller"" ) :",67
"def localized(self, context): <TAB> """"""Returns a copy of the cube translated with `translation`"""""" <TAB> acopy = self.__class__.__new__(self.__class__) <TAB> acopy.__dict__ = self.__dict__.copy() <TAB> d = acopy.__dict__ <TAB> for attr in self.localizable_attributes: <TAB>  <TAB> d[attr] = context.get(attr, getattr(self, attr)) <TAB> for attr in self.localizable_lists: <TAB>  <TAB> list_copy = [] <MASK> for obj in getattr(acopy, attr): <TAB>  <TAB>  <TAB>  <TAB> obj_context = context.object_localization(attr, obj.name) <TAB>  <TAB>  <TAB>  <TAB> list_copy.append(obj.localized(obj_context)) <TAB>  <TAB>  <TAB> setattr(acopy, attr, list_copy) <TAB> return acopy","if hasattr ( acopy , attr ) :",197
"def write(self, msg, level=logging.INFO): <TAB> if self.reportIncrementFlag: <TAB>  <TAB> if ""MiB"" in msg and float(msg.split(""MiB"")[1].strip()) > 0: <TAB>  <TAB>  <TAB> self.logger.log(level, msg) <MASK> self.logger.log(level, msg) <TAB> else: <TAB>  <TAB> self.logger.log(level, msg)","elif msg . __contains__ ( ""Filename:"" ) or msg . __contains__ ( ""Line Contents"" ) :",111
"def assertNamedItemNotInContainer(self, container, item_name, msg=None): <TAB> for item in container: <MASK> standardMsg = ""{0} unexpectedly found in {1}"".format( <TAB>  <TAB>  <TAB>  <TAB> repr(item_name), repr(container) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.fail(self._formatMessage(msg, standardMsg))",if item . name == item_name :,94
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.set_app_id(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 18: <TAB>  <TAB>  <TAB> self.add_queue_name(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 24: <TAB>  <TAB>  <TAB> self.set_max_num_tasks(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 10 :,158
"def on_success(result): <TAB> if result[0]: <TAB>  <TAB> print(""Created task."") <TAB>  <TAB> self.task_in_creation = False <TAB>  <TAB> self.next() <TAB> else: <TAB>  <TAB> msg = result[1] <MASK> print(f""Waiting for {node_id.value}'s GNTB..."") <TAB>  <TAB>  <TAB> time.sleep(30) <TAB>  <TAB>  <TAB> self.task_in_creation = False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""Failed to create task {}"".format(msg)) <TAB>  <TAB>  <TAB> self.fail()","if re . match ( ""Not enough GNT"" , msg ) :",143
"def enqueue_barrier(queue, wait_for=None): <TAB> if queue._get_cl_version() >= (1, 2) and get_cl_header_version() >= (1, 2): <TAB>  <TAB> return _cl._enqueue_barrier_with_wait_list(queue, wait_for) <TAB> else: <TAB>  <TAB> _cl._enqueue_barrier(queue) <MASK> _cl._enqueue_wait_for_events(queue, wait_for) <TAB>  <TAB> return _cl._enqueue_marker(queue)",if wait_for :,127
"def _get_urn_id(self, video_data): <TAB> urn = video_data.get(""urn"") <TAB> if urn: <TAB>  <TAB> mobj = re.search(r""urn:li:lyndaCourse:\d+,(\d+)"", urn) <MASK> return mobj.group(1)",if mobj :,81
"def to_python(self, value): <TAB> if isinstance(value, dict) and ""_cls"" in value: <TAB>  <TAB> doc_cls = get_document(value[""_cls""]) <MASK> value = doc_cls._get_db().dereference(value[""_ref""]) <TAB>  <TAB> return doc_cls._from_son(value) <TAB> return super().to_python(value)","if ""_ref"" in value :",97
"def waiter(): <TAB> check_time = time.time() <TAB> while True: <TAB>  <TAB> if not resource_ref.get_workers_meta(): <TAB>  <TAB>  <TAB> gevent.sleep(0.1) <MASK> raise SystemError(f""Worker dead. exit code {proc.poll()}"") <TAB>  <TAB>  <TAB> if time.time() - check_time > timeout: <TAB>  <TAB>  <TAB>  <TAB> raise TimeoutError(""Check meta_timestamp timeout"") <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> val = resource_ref.get_workers_meta() <TAB> worker_ips.extend(val.keys())",if proc . poll ( ) is not None :,150
"def pad_and_tensorize_batches(tensorizers, batches): <TAB> for raw_batch, numberized_batch in batches: <TAB>  <TAB> tensor_dict = {} <TAB>  <TAB> for name, tensorizer in tensorizers.items(): <MASK> tensor_dict[name] = tensorizer.tensorize(numberized_batch) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> tensor_dict[name] = tensorizer.tensorize(numberized_batch[name]) <TAB>  <TAB> yield raw_batch, tensor_dict","if isinstance ( tensorizer , MetricTensorizer ) :",131
"def file_exists(s): <TAB> if s in exists_cache: <TAB>  <TAB> return exists_cache[s] <TAB> global topology <TAB> if topology is None: <TAB>  <TAB> top = os.getenv(""TOPOLOGY"") <TAB>  <TAB> topology = set() <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> topology = set([x.strip() for x in open(top).readlines()]) <TAB>  <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB>  <TAB> print(""Cannot open"", top, file=sys.stderr) <TAB> if s in topology: <TAB>  <TAB> return True <TAB> found = os.path.exists(s) <TAB> exists_cache[s] = found <TAB> return found",if top :,161
"def _scan_json_string(rdr): <TAB> ret = rdr.getc()  # '""' <TAB> while True: <TAB>  <TAB> c = rdr.getc() <TAB>  <TAB> if c == """": <TAB>  <TAB>  <TAB> raise SyntaxError(""End of file in JSON string"") <TAB>  <TAB> # Accept raw control characters for readability. <TAB>  <TAB> if c == ""\n"": <TAB>  <TAB>  <TAB> c = ""\\n"" <MASK> c = ""\\r"" <TAB>  <TAB> if c == ""\t"": <TAB>  <TAB>  <TAB> c = ""\\t"" <TAB>  <TAB> ret += c <TAB>  <TAB> if c == '""': <TAB>  <TAB>  <TAB> return ret <TAB>  <TAB> if c == ""\\"": <TAB>  <TAB>  <TAB> ret += rdr.getc()","if c == ""\r"" :",165
"def prepare_timing_data(cls, intervals): <TAB> min_interval = intervals[0] <TAB> max_interval = 0 <TAB> avg_interval = 0 <TAB> total = 0 <TAB> count = 0 <TAB> for interval in intervals: <TAB>  <TAB> interval = float(interval) <TAB>  <TAB> count += 1 <TAB>  <TAB> total += interval <MASK> max_interval = interval <TAB>  <TAB> if interval < min_interval: <TAB>  <TAB>  <TAB> min_interval = interval <TAB> if count: <TAB>  <TAB> avg_interval = round(total / count, 2) <TAB> return { <TAB>  <TAB> ""min"": min_interval, <TAB>  <TAB> ""max"": max_interval, <TAB>  <TAB> ""avg"": avg_interval, <TAB>  <TAB> ""count"": count, <TAB> }",if interval > max_interval :,177
"def _drawBorderLine(bstyle, width, color, x1, y1, x2, y2): <TAB> # We need width and border style to be able to draw a border <TAB> if width and getBorderStyle(bstyle): <TAB>  <TAB> # If no color for border is given, the text color is used (like defined by W3C) <MASK> color = style.textColor <TAB>  <TAB>  <TAB> # print ""Border"", bstyle, width, color <TAB>  <TAB> if color is not None: <TAB>  <TAB>  <TAB> canvas.setStrokeColor(color) <TAB>  <TAB>  <TAB> canvas.setLineWidth(width) <TAB>  <TAB>  <TAB> canvas.line(x1, y1, x2, y2)",if color is None :,168
"def iterOutputListCreationLines(self, node): <TAB> for name, index in zip(self.listOutputNames, self.outputIndices): <TAB>  <TAB> socket = node.outputs[index] <MASK> yield ""{} = self.outputs[{}].getDefaultValue()"".format(name, index)",if socket . isLinked and name not in self . listInputNames :,84
"def post_torrent_add(self, torrent_id, from_state): <TAB> if from_state: <TAB>  <TAB> return <TAB> log.debug(""post_torrent_add"") <TAB> torrent = self.torrents[torrent_id] <TAB> for label_id, options in self.labels.items(): <TAB>  <TAB> if options[""auto_add""]: <MASK> self.set_torrent(torrent_id, label_id) <TAB>  <TAB>  <TAB>  <TAB> return","if self . _has_auto_match ( torrent , options ) :",123
"def select_previous(self, shift=False): <TAB> """"""Selects previous item from list."""""" <TAB> selected = [] <TAB> for i in range(len(self)): <MASK> selected.append(i) <TAB> if len(selected) > 0: <TAB>  <TAB> if selected[0] == 0: <TAB>  <TAB>  <TAB> if shift is False: <TAB>  <TAB>  <TAB>  <TAB> self.unselect_all(ignore=self[0]) <TAB>  <TAB> elif selected[0] > 0: <TAB>  <TAB>  <TAB> if shift is False: <TAB>  <TAB>  <TAB>  <TAB> self.unselect_all(ignore=self[selected[0] - 1]) <TAB>  <TAB>  <TAB> self[selected[0] - 1].selected = True <TAB> elif len(self) > 0: <TAB>  <TAB> self[0].selected = True",if self [ i ] . selected :,184
"def delete(self): <TAB> """"""Deletes the dataset"""""" <TAB> fs, path = self._fs, self._path <TAB> exist_meta = fs.exists(posixpath.join(path, ""meta.json"")) <TAB> if exist_meta: <TAB>  <TAB> fs.rm(path, recursive=True) <MASK> HubControlClient().delete_dataset_entry(self.username, self.dataset_name) <TAB>  <TAB> return True <TAB> return False",if self . username is not None :,111
"def __init__(self, loader): <TAB> if args.train: <TAB>  <TAB> print( <TAB>  <TAB>  <TAB> ""{}Training {} epochs on random image sections with batch size {}.{}"".format( <TAB>  <TAB>  <TAB>  <TAB> ansi.BLUE_B, args.epochs, args.batch_size, ansi.BLUE <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB> else: <MASK> error(""Specify the image(s) to enhance on the command-line."") <TAB>  <TAB> print( <TAB>  <TAB>  <TAB> ""{}Enhancing {} image(s) specified on the command-line.{}"".format( <TAB>  <TAB>  <TAB>  <TAB> ansi.BLUE_B, len(args.files), ansi.BLUE <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB> self.thread = DataLoader() if loader else None <TAB> self.model = Model() <TAB> print(""{}"".format(ansi.ENDC))",if len ( args . files ) == 0 :,197
"def read(file_object): <TAB> number = 0 <TAB> # Limit of 5 bytes, otherwise its possible to cause <TAB> # a DOS attack by sending VarInts that just keep <TAB> # going <TAB> bytes_encountered = 0 <TAB> while True: <TAB>  <TAB> byte = file_object.read(1) <MASK> raise EOFError(""Unexpected end of message."") <TAB>  <TAB> byte = ord(byte) <TAB>  <TAB> number |= (byte & 0x7F) << 7 * bytes_encountered <TAB>  <TAB> if not byte & 0x80: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> bytes_encountered += 1 <TAB>  <TAB> if bytes_encountered > 5: <TAB>  <TAB>  <TAB> raise ValueError(""Tried to read too long of a VarInt"") <TAB> return number",if len ( byte ) < 1 :,180
"def gauge(self, key, gauge=None, default=float(""nan"")): <TAB> if key not in self._gauges: <TAB>  <TAB> if gauge is None: <TAB>  <TAB>  <TAB> gauge = SimpleGauge( <TAB>  <TAB>  <TAB>  <TAB> default <TAB>  <TAB>  <TAB> )  # raise TypeError(""gauge required for registering"") <TAB>  <TAB> elif not isinstance(gauge, Gauge): <MASK> raise TypeError(""gauge getter not callable"") <TAB>  <TAB>  <TAB> gauge = CallbackGauge(gauge) <TAB>  <TAB> self._gauges[key] = gauge <TAB> return self._gauges[key]",if not callable ( gauge ) :,165
"def ray_intersection(self, p, line): <TAB> p = Vector(center(line.sites)) <TAB> intersection = self.circle.intersect_with_line(line) <TAB> # info(""RI: {line} X {self.circle} => {intersection}"") <TAB> if intersection is None: <TAB>  <TAB> return None <TAB> else: <TAB>  <TAB> v1, v2 = intersection <TAB>  <TAB> r1 = (p - v1).length <TAB>  <TAB> r2 = (p - v2).length <MASK> return v1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return v2",if r1 < r2 :,141
"def scan_spec_conf(self, conf): <TAB> metadata = conf.get(""metadata"") <TAB> if metadata: <MASK> return CheckResult.FAILED <TAB>  <TAB> labels = metadata.get(""labels"") <TAB>  <TAB> if labels: <TAB>  <TAB>  <TAB> for v in labels.values(): <TAB>  <TAB>  <TAB>  <TAB> if ""tiller"" in str(v).lower(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return CheckResult.FAILED <TAB> spec = conf.get(""spec"") <TAB> if spec: <TAB>  <TAB> selector = spec.get(""selector"") <TAB>  <TAB> if selector: <TAB>  <TAB>  <TAB> for v in selector.values(): <TAB>  <TAB>  <TAB>  <TAB> if ""tiller"" in str(v).lower(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return CheckResult.FAILED <TAB> return CheckResult.UNKNOWN","if ""name"" in metadata and ""tiller"" in str ( metadata [ ""name"" ] ) . lower ( ) :",196
"def sample(self, **config): <TAB> kwargs = copy.deepcopy(self.kwargs) <TAB> kwspaces = copy.deepcopy(autogluonobject.kwspaces) <TAB> for k, v in kwargs.items(): <MASK> sub_config = _strip_config_space(config, prefix=k) <TAB>  <TAB>  <TAB> kwargs[k] = kwspaces[k].sample(**sub_config) <TAB>  <TAB> elif k in config: <TAB>  <TAB>  <TAB> kwargs[k] = config[k] <TAB> args = self.args <TAB> return Cls(*args, **kwargs)","if k in kwspaces and isinstance ( kwspaces [ k ] , NestedSpace ) :",148
"def get_pid_comm(self, pkt): <TAB> conn_pid, process_name = None, None <TAB> if pkt.proto and pkt.sport: <TAB>  <TAB> if pkt.proto == ""TCP"": <TAB>  <TAB>  <TAB> conn_pid = self._get_pid_port_tcp(pkt.sport) <MASK> conn_pid = self._get_pid_port_udp(pkt.sport) <TAB>  <TAB> if conn_pid: <TAB>  <TAB>  <TAB> process_name = self.get_process_image_filename(conn_pid) <TAB> return conn_pid, process_name","elif pkt . proto == ""UDP"" :",143
"def validate(self): <TAB> if self.data.get(""remove"") == ""matched"": <TAB>  <TAB> found = False <TAB>  <TAB> for f in self.manager.iter_filters(): <MASK> found = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if not found: <TAB>  <TAB>  <TAB> raise PolicyValidationError( <TAB>  <TAB>  <TAB>  <TAB> ""policy:%s filter:%s with matched requires cross-account filter"" <TAB>  <TAB>  <TAB>  <TAB> % (self.manager.ctx.policy.name, self.type) <TAB>  <TAB>  <TAB> )","if isinstance ( f , SnapshotCrossAccountAccess ) :",130
"def encode(c): <TAB> retval = c <TAB> i = ord(c) <TAB> for low, high in escape_range: <MASK> break <TAB>  <TAB> if i >= low and i <= high: <TAB>  <TAB>  <TAB> retval = """".join([""%%%2X"" % o for o in c.encode(""utf-8"")]) <TAB>  <TAB>  <TAB> break <TAB> return retval",if i < low :,91
"def __load(self) -> bytes: <TAB> while True: <TAB>  <TAB> event = await self._receive() <TAB>  <TAB> if event[""type""] == ""http.request"": <TAB>  <TAB>  <TAB> self.append(event[""body""]) <TAB>  <TAB>  <TAB> if not event.get(""more_body"", False): <TAB>  <TAB>  <TAB>  <TAB> break <MASK> raise RequestCancelled <TAB> return bytes(self._data)","elif event [ ""type"" ] == ""http.disconnect"" :",104
def _run(self): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> state = self._queue.get_nowait() <MASK> break <TAB>  <TAB>  <TAB> it = itertools.cycle(state.duty_cycles()) <TAB>  <TAB> except queue.Empty: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> self._pwm.ChangeDutyCycle(int(self._brightness * next(it))) <TAB>  <TAB> self._updated.wait(state.pause) <TAB>  <TAB> self._updated.clear(),if state is None :,116
"def confirm_module_ready(port): <TAB> if port == 0: <TAB>  <TAB> xlog.error(""confirm_module_ready with port: 0"") <TAB>  <TAB> time.sleep(1) <TAB>  <TAB> return False <TAB> for i in range(200): <TAB>  <TAB> req = http_request(""http://127.0.0.1:%d/is_ready"" % port) <TAB>  <TAB> if req == False: <TAB>  <TAB>  <TAB> time.sleep(1) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> content = req.read(1024) <TAB>  <TAB> req.close() <TAB>  <TAB> # xlog.debug(""cert_import_ready return:%s"", content) <MASK> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> time.sleep(1) <TAB> return False","if content == ""True"" :",181
"def _confirm(question): <TAB> """"""Confirm before proceeding."""""" <TAB> try: <MASK> print(""Cancelled"", file=sys.stderr) <TAB>  <TAB>  <TAB> sys.exit(1) <TAB> except KeyboardInterrupt: <TAB>  <TAB> print(""Cancelled"", file=sys.stderr) <TAB>  <TAB> sys.exit(1)","if input ( question + "" [yn] "" ) . lower ( ) not in { ""y"" , ""yes"" } :",94
"def Activate(self): <TAB> pParentFrame = self.GetMDIParentFrame() <TAB> if not pParentFrame: <TAB>  <TAB> raise Exception(""Missing MDI Parent Frame"") <TAB> pClientWindow = pParentFrame.GetClientWindow() <TAB> if pClientWindow is not None: <TAB>  <TAB> for pos in range(pClientWindow.GetPageCount()): <MASK> pClientWindow.SetSelection(pos) <TAB>  <TAB>  <TAB>  <TAB> break",if pClientWindow . GetPage ( pos ) == self :,114
"def press_neighbor_cells(self, cell): <TAB> self.count_flags = 0 <TAB> self.bomb_explodes_on = [] <TAB> self.to_be_released = [] <TAB> for one in self.get_neighbors(cell): <MASK> continue <TAB>  <TAB> one.addStyleName(""pressed"") <TAB>  <TAB> self.to_be_released.append(one) <TAB>  <TAB> if one.state == 1: <TAB>  <TAB>  <TAB> self.count_flags += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if one.count == -1: <TAB>  <TAB>  <TAB>  <TAB> self.bomb_explodes_on.append(one)",if one . state == 3 :,156
"def get_extended_config_file(name): <TAB> # Is it a standard conf shipped with yamllint... <TAB> if ""/"" not in name: <TAB>  <TAB> std_conf = os.path.join( <TAB>  <TAB>  <TAB> os.path.dirname(os.path.realpath(__file__)), ""conf"", name + "".yaml"" <TAB>  <TAB> ) <MASK> return std_conf <TAB> # or a custom conf on filesystem? <TAB> return name",if os . path . isfile ( std_conf ) :,115
"def getsetscenedeps(tid): <TAB> deps = set() <TAB> (mc, fn, taskname, _) = split_tid_mcfn(tid) <TAB> realtid = tid + ""_setscene"" <TAB> idepends = self.rqdata.taskData[mc].taskentries[realtid].idepends <TAB> for (depname, idependtask) in idepends: <MASK> continue <TAB>  <TAB> depfn = self.rqdata.taskData[mc].build_targets[depname][0] <TAB>  <TAB> if depfn is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> deptid = depfn + "":"" + idependtask.replace(""_setscene"", """") <TAB>  <TAB> deps.add(deptid) <TAB> return deps",if depname not in self . rqdata . taskData [ mc ] . build_targets :,199
"def set_event_listeners(self, elem): <TAB> p = getattr(elem, ""_node"", None) <TAB> if p: <TAB>  <TAB> for evt in self.handled_on_events: <TAB>  <TAB>  <TAB> h = getattr(p, evt, None) <MASK> self.attach_event(elem, evt, h) <TAB> listeners = getattr(elem, ""_listeners"", None) <TAB> if listeners: <TAB>  <TAB> for (eventType, listener, capture) in listeners: <TAB>  <TAB>  <TAB> if eventType in self.handled_events: <TAB>  <TAB>  <TAB>  <TAB> self.listeners.append((elem, eventType, listener, capture))",if h :,149
"def find_variable(self, vname, line): <TAB> """"""Function to find a variable 'vname' in a line."""""" <TAB> idx = line.find(vname) <TAB> if ((idx > 0 and line[idx - 1] == "" "") or idx == 0) and line[0] != ""*"": <MASK> return idx <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB> line[idx + len(vname)] == ""="" <TAB>  <TAB>  <TAB> or line[idx + len(vname)] == "" "" <TAB>  <TAB>  <TAB> or line[idx + len(vname)] == "":"" <TAB>  <TAB>  <TAB> or line[idx + len(vname)] == "";"" <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> return idx <TAB> return -1",if idx + len ( vname ) == len ( line ) :,167
"def visit_excepthandler(self, node): <TAB> self.newline(node) <TAB> self.write(""except"") <TAB> if node.type is not None: <TAB>  <TAB> self.write("" "") <TAB>  <TAB> self.visit(node.type) <MASK> self.write("" as "") <TAB>  <TAB>  <TAB> self.visit(node.name) <TAB> self.write("":"") <TAB> self.body(node.body)",if node . name is not None :,105
"def cleanup(self, doctrees: bool = False) -> None: <TAB> ModuleAnalyzer.cache.clear() <TAB> locale.translators.clear() <TAB> sys.path[:] = self._saved_path <TAB> sys.modules.pop(""autodoc_fodder"", None) <TAB> directives._directives = self._saved_directives  # type: ignore <TAB> roles._roles = self._saved_roles  # type: ignore <TAB> for method in dir(nodes.GenericNodeVisitor): <MASK> delattr(nodes.GenericNodeVisitor, ""visit_"" + method[6:]) <TAB>  <TAB>  <TAB> delattr(nodes.GenericNodeVisitor, ""depart_"" + method[6:])","if method . startswith ( ""visit_"" ) and method not in self . _saved_nodeclasses :",172
"def process_archive_subtitle_files( <TAB> self, archiveStream, language, video, link, fps, num_cds): <TAB> subtitles = [] <TAB> type = ""episode"" if isinstance(video, Episode) else ""movie"" <TAB> for file_name in sorted(archiveStream.namelist()): <MASK> logger.info(""Found subtitle file %r"", file_name) <TAB>  <TAB>  <TAB> subtitle = SubsSabBzSubtitle( <TAB>  <TAB>  <TAB>  <TAB> language, file_name, type, video, link, fps, num_cds <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> subtitle.content = fix_line_ending(archiveStream.read(file_name)) <TAB>  <TAB>  <TAB> subtitles.append(subtitle) <TAB> return subtitles","if file_name . lower ( ) . endswith ( ( "".srt"" , "".sub"" ) ) :",188
def hours(self): <TAB> if self._h is None: <TAB>  <TAB> seconds = self._seconds <TAB>  <TAB> self._h = 0 <MASK> self._h = (abs(seconds) // 3600 % 24) * self._sign(seconds) <TAB> return self._h,if abs ( seconds ) >= 3600 :,73
"def add_retina_images(app, env): <TAB> retina_images = [] <TAB> for full_path, (docnames, filename) in env.images.iteritems(): <TAB>  <TAB> base, ext = os.path.splitext(full_path) <TAB>  <TAB> retina_path = base + ""@2x"" + ext <MASK> retina_images += [(docname, retina_path) for docname in docnames] <TAB> for docname, path in retina_images: <TAB>  <TAB> env.images.add_file(docname, path)",if os . path . exists ( retina_path ) :,148
"def validate_bom_for_subcontracting_items(self): <TAB> if self.is_subcontracted == ""Yes"": <TAB>  <TAB> for item in self.items: <MASK> frappe.throw( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""BOM is not specified for subcontracting item {0} at row {1}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> item.item_code, item.idx <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> )",if not item . bom :,133
"def wrapper(*args, **kwargs): <TAB> for flag in feature_flags: <TAB>  <TAB> flag_value = getattr(settings, flag, None) <TAB>  <TAB> if not isinstance(flag_value, bool): <TAB>  <TAB>  <TAB> raise Exception(""Setting {} must be either True or "" ""False."".format(flag)) <MASK> # Don't run the function if the flag is false. <TAB>  <TAB>  <TAB> return <TAB> return func(*args, **kwargs)",elif not flag_value :,108
"def __getitem__(self, key): <TAB> n = len(self) <TAB> if isinstance(key, int): <TAB>  <TAB> if key >= n: <TAB>  <TAB>  <TAB> raise IndexError <TAB>  <TAB> if key < 0: <TAB>  <TAB>  <TAB> key += n <TAB>  <TAB> return _Slice(self, key, key + 1) <TAB> elif isinstance(key, slice): <TAB>  <TAB> start, stop, step = key.indices(n) <MASK> return Cat(self[i] for i in range(start, stop, step)) <TAB>  <TAB> return _Slice(self, start, stop) <TAB> else: <TAB>  <TAB> raise TypeError(""Cannot use type {} ({}) as key"".format(type(key), repr(key)))",if step != 1 :,165
"def merge(h, i): <TAB> j = 0 <TAB> while True: <MASK> if i == count and j < depth: <TAB>  <TAB>  <TAB>  <TAB> h = hash( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> h + zerohashes[j] <TAB>  <TAB>  <TAB>  <TAB> )  # keep going if we are complementing the void to the next power of 2 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> h = hash(tmp[j] + h) <TAB>  <TAB> j += 1 <TAB> tmp[j] = h",if i & ( 1 << j ) == 0 :,136
"def f(vm): <TAB> stack = vm.stack <TAB> conditional_stack = vm.conditional_stack <TAB> the_bool = False <TAB> if conditional_stack.all_if_true(): <TAB>  <TAB> if len(stack) < 1: <TAB>  <TAB>  <TAB> raise ScriptError(""IF with no condition"", errno.UNBALANCED_CONDITIONAL) <TAB>  <TAB> item = vm.pop() <MASK> if item not in (vm.VM_FALSE, vm.VM_TRUE): <TAB>  <TAB>  <TAB>  <TAB> raise ScriptError(""non-minimal IF"", errno.MINIMALIF) <TAB>  <TAB> the_bool = vm.bool_from_script_bytes(item) <TAB> vm.conditional_stack.OP_IF(the_bool, reverse_bool=reverse_bool)",if vm . flags & VERIFY_MINIMALIF :,187
"def set_nap(self, on): <TAB> logging.info(""set nap %s"" % on) <TAB> if self.parent.manager_state: <TAB>  <TAB> adapters = self.parent.Manager.get_adapters() <TAB>  <TAB> for adapter in adapters: <TAB>  <TAB>  <TAB> object_path = adapter.get_object_path() <TAB>  <TAB>  <TAB> registered = self._registered.setdefault(object_path, False) <TAB>  <TAB>  <TAB> s = NetworkServer(object_path) <MASK> s.register(""nap"", ""pan1"") <TAB>  <TAB>  <TAB>  <TAB> self._registered[object_path] = True <TAB>  <TAB>  <TAB> elif not on and registered: <TAB>  <TAB>  <TAB>  <TAB> s.unregister(""nap"") <TAB>  <TAB>  <TAB>  <TAB> self._registered[object_path] = False",if on and not registered :,186
def _acceptable_polymorphic_identities(self): <TAB> identities = set() <TAB> stack = deque([self]) <TAB> while stack: <TAB>  <TAB> item = stack.popleft() <MASK> identities.add(item.polymorphic_identity) <TAB>  <TAB>  <TAB> stack.extend(item._inheriting_mappers) <TAB> return identities,if item . mapped_table is self . mapped_table :,96
"def iter_distribution_names(self): <TAB> """"""Yield all packages, modules, and extension names in distribution"""""" <TAB> for pkg in self.packages or (): <TAB>  <TAB> yield pkg <TAB> for module in self.py_modules or (): <TAB>  <TAB> yield module <TAB> for ext in self.ext_modules or (): <MASK> name, buildinfo = ext <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = ext.name <TAB>  <TAB> if name.endswith(""module""): <TAB>  <TAB>  <TAB> name = name[:-6] <TAB>  <TAB> yield name","if isinstance ( ext , tuple ) :",128
def consumeFirst(self): <TAB> self.consume() <TAB> p = None <TAB> while self.hideMask.member(self.LA(1).getType()) or self.discardMask.member( <TAB>  <TAB> self.LA(1).getType() <TAB> ): <MASK> if not p: <TAB>  <TAB>  <TAB>  <TAB> p = self.LA(1) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> p.setHiddenAfter(self.LA(1)) <TAB>  <TAB>  <TAB>  <TAB> self.LA(1).setHiddenBefore(p) <TAB>  <TAB>  <TAB>  <TAB> p = self.LA(1) <TAB>  <TAB>  <TAB> self.lastHiddenToken = p <TAB>  <TAB>  <TAB> if not self.firstHidden: <TAB>  <TAB>  <TAB>  <TAB> self.firstHidden = p <TAB>  <TAB> self.consume(),if self . hideMask . member ( self . LA ( 1 ) . getType ( ) ) :,194
"def split_to_blobs(makeblob, files, keep_boundaries, progress): <TAB> global total_split <TAB> for (blob, level) in hashsplit_iter(files, keep_boundaries, progress): <TAB>  <TAB> sha = makeblob(blob) <TAB>  <TAB> total_split += len(blob) <MASK> progress_callback(len(blob)) <TAB>  <TAB> yield (sha, len(blob), level)",if progress_callback :,101
"def _more(self): <TAB> while self.pos < self.limit: <TAB>  <TAB> match = num_re.match(self.pathd, self.pos) <MASK> return False <TAB>  <TAB> kind = match.lastgroup <TAB>  <TAB> if kind == ""CLOSE"": <TAB>  <TAB>  <TAB> self.inline_close = match.group() <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> if kind == ""SKIP"": <TAB>  <TAB>  <TAB> # move skipped elements forward. <TAB>  <TAB>  <TAB> self.pos = match.end() <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> return True <TAB> return None",if match is None :,135
"def save_hdf5(data_fp, data, metadata=None): <TAB> if metadata is None: <TAB>  <TAB> metadata = {} <TAB> mode = ""w"" <TAB> if os.path.isfile(data_fp): <TAB>  <TAB> mode = ""r+"" <TAB> with h5py.File(data_fp, mode) as h5_file: <TAB>  <TAB> for key, value in data.items(): <TAB>  <TAB>  <TAB> dataset = h5_file.create_dataset(key, data=value) <MASK> if ""in_memory"" in metadata[key][""preprocessing""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if metadata[key][""preprocessing""][""in_memory""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> dataset.attrs[""in_memory""] = True <TAB>  <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> dataset.attrs[""in_memory""] = False",if key in metadata :,198
"def add_extractors_to_descriptors(descriptors, extractors): <TAB> new_extractors = {} <TAB> for _id, data in extractors.items(): <MASK> extractor = create_regex_extractor(data[""regular_expression""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> extractor = create_type_extractor(data[""type_extractor""]) <TAB>  <TAB> new_extractors[_id] = extractor <TAB> for descriptor in descriptors.values(): <TAB>  <TAB> if isinstance(descriptor, SlybotItemDescriptor): <TAB>  <TAB>  <TAB> descriptor.extractors = new_extractors","if ""regular_expression"" in data :",138
"def _parse_time(expression, clock=_clock): <TAB> best = float(""inf"") <TAB> p = Parser() <TAB> duration = 0 <TAB> i = 0 <TAB> while True: <TAB>  <TAB> i += 1 <TAB>  <TAB> p.purge() <TAB>  <TAB> start = clock() <TAB>  <TAB> p.parse(expression) <TAB>  <TAB> end = clock() <TAB>  <TAB> total = end - start <TAB>  <TAB> duration += total <MASK> break <TAB> return duration / i",if duration >= APPROX_RUN_TIME :,116
"def getTransparent(self): <TAB> if sys.platform[0:4] == ""java"": <TAB>  <TAB> return None <TAB> elif ""transparency"" in self._image.info: <TAB>  <TAB> transparency = self._image.info[""transparency""] * 3 <TAB>  <TAB> palette = self._image.palette <TAB>  <TAB> if hasattr(palette, ""palette""): <TAB>  <TAB>  <TAB> palette = palette.palette <MASK> palette = palette.data <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> # 8-bit PNGs could give an empty string as transparency value, so <TAB>  <TAB> # we have to be careful here. <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return list(six.iterbytes(palette[transparency : transparency + 3])) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> return None <TAB> else: <TAB>  <TAB> return None","elif hasattr ( palette , ""data"" ) :",196
"def pop(self, key, value=None): <TAB> if not value: <TAB>  <TAB> if key in self._data: <TAB>  <TAB>  <TAB> value = self._data.pop(key) <TAB>  <TAB>  <TAB> return value <MASK> t = self._expires.pop(key) <TAB>  <TAB>  <TAB> t.handle.cancel() <TAB>  <TAB>  <TAB> return t.value",elif key in self . _expires :,90
"def _resize_image_file(self, path, new_size): <TAB> """"""Resize the image file on share to new size."""""" <TAB> LOG.debug(""Checking file for resize"") <MASK> return <TAB> else: <TAB>  <TAB> LOG.info(""Resizing file to %sG"", new_size) <TAB>  <TAB> image_utils.resize_image(path, new_size, run_as_root=self._execute_as_root) <TAB>  <TAB> if self._is_file_size_equal(path, new_size): <TAB>  <TAB>  <TAB> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise exception.InvalidResults(_(""Resizing image file failed.""))","if self . _is_file_size_equal ( path , new_size ) :",164
"def get_history(hstart=0): <TAB> res = [] <TAB> ohist = ip.IP.output_hist <TAB> for idx in range(hstart, len(ip.IP.input_hist)): <TAB>  <TAB> val = ohist.get(idx, None) <TAB>  <TAB> has_output = True <TAB>  <TAB> inp = ip.IP.input_hist_raw[idx] <TAB>  <TAB> if inp.strip(): <TAB>  <TAB>  <TAB> res.append(""In [%d]: %s"" % (idx, inp)) <MASK> res.append(pprint.pformat(val)) <TAB>  <TAB>  <TAB> res.append(""\n"") <TAB> return """".join(res)",if val :,154
"def _create_examples(self, lines, set_type): <TAB> """"""Creates examples for the training and dev sets."""""" <TAB> examples = [] <TAB> for (i, line) in enumerate(lines): <MASK> print(""data format error: %s"" % ""\t"".join(line)) <TAB>  <TAB>  <TAB> print(""data row contains two parts: label \t conversation_content"") <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> guid = ""%s-%d"" % (set_type, i) <TAB>  <TAB> text_a = line[1] <TAB>  <TAB> text_a = tokenization.convert_to_unicode(text_a) <TAB>  <TAB> label = tokenization.convert_to_unicode(line[0]) <TAB>  <TAB> examples.append(InputExample(guid=guid, text_a=text_a, label=label)) <TAB> return examples",if len ( line ) != 2 :,198
"def run(self, edit, trim_whitespace, ensure_newline): <TAB> # make sure you trim trailing whitespace FIRST and THEN check for Newline <TAB> if trim_whitespace: <TAB>  <TAB> trailing_white_space = self.view.find_all(""[\t ]+$"") <TAB>  <TAB> trailing_white_space.reverse() <TAB>  <TAB> for r in trailing_white_space: <TAB>  <TAB>  <TAB> self.view.erase(edit, r) <TAB> if ensure_newline: <MASK> self.view.insert(edit, self.view.size(), ""\n"")","if self . view . size ( ) > 0 and self . view . substr ( self . view . size ( ) - 1 ) != ""\n"" :",159
"def handle_response(response, *args, **kwargs): <TAB> if response.error: <TAB>  <TAB> self.statsd.increment(""http_stats.error"") <TAB>  <TAB> self.statsd.increment(""http_stats.error.%s"" % response.code) <MASK> self.cast(""restart"", name=self.restart_on_error) <TAB>  <TAB>  <TAB> self.statsd.increment(""http_stats.restart_on_error"") <TAB>  <TAB> return <TAB> self.statsd.timed(""http_stats.request_time"", int(response.request_time * 1000))",if self . restart_on_error :,145
"def get_req_headers(self): <TAB> headers = {} <TAB> for name, value in iteritems(self.env): <TAB>  <TAB> # will be set by requests to match actual host <TAB>  <TAB> if name == ""HTTP_HOST"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif name.startswith(""HTTP_""): <TAB>  <TAB>  <TAB> name = name[5:].title().replace(""_"", ""-"") <TAB>  <TAB> elif name in (""CONTENT_LENGTH"", ""CONTENT_TYPE""): <TAB>  <TAB>  <TAB> name = name.title().replace(""_"", ""-"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = None <MASK> headers[name] = value <TAB> return headers",if value :,143
"def extract_groups_of_builds(self): <TAB> """"""Return a dict mapping each variants to the commands to build"""""" <TAB> self.vgroups = {} <TAB> for x in reversed(Options.commands): <TAB>  <TAB> _, _, variant = x.partition(""_"") <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> dct = self.vgroups[variant] <TAB>  <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB>  <TAB> dct = self.vgroups[variant] = OrderedDict() <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> dct[variant].append(x) <TAB>  <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB>  <TAB> dct[variant] = [x] <TAB>  <TAB>  <TAB> Options.commands.remove(x)",if variant in Context . g_module . variants :,167
"def _parseSTRL(self, t): <TAB> retval = {} <TAB> size = len(t) <TAB> i = 0 <TAB> while i < len(t) - 8: <TAB>  <TAB> key = t[i : i + 4] <TAB>  <TAB> sz = struct.unpack(""<I"", t[i + 4 : i + 8])[0] <TAB>  <TAB> i += 8 <TAB>  <TAB> value = t[i:] <TAB>  <TAB> if key == ""strh"": <TAB>  <TAB>  <TAB> retval[key] = self._parseSTRH(value) <MASK> retval[key] = self._parseSTRF(value, retval[""strh""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.debug(u""_parseSTRL: unsupported stream tag %r"", key) <TAB>  <TAB> i += sz <TAB> return retval, i","elif key == ""strf"" :",190
"def prepare_query_value(self, op, value): <TAB> if not isinstance(op, basestring): <TAB>  <TAB> return value <TAB> if op.lstrip(""i"") in (""startswith"", ""endswith"", ""contains"", ""exact""): <TAB>  <TAB> flags = 0 <TAB>  <TAB> if op.startswith(""i""): <TAB>  <TAB>  <TAB> flags = re.IGNORECASE <TAB>  <TAB>  <TAB> op = op.lstrip(""i"") <TAB>  <TAB> regex = r""%s"" <TAB>  <TAB> if op == ""startswith"": <TAB>  <TAB>  <TAB> regex = r""^%s"" <TAB>  <TAB> elif op == ""endswith"": <TAB>  <TAB>  <TAB> regex = r""%s$"" <MASK> regex = r""^%s$"" <TAB>  <TAB> # escape unsafe characters which could lead to a re.error <TAB>  <TAB> value = re.escape(value) <TAB>  <TAB> value = re.compile(regex % value, flags) <TAB> return value","elif op == ""exact"" :",199
"def _wait_for_volume_available(conn, volume_id, retries=5, interval=5): <TAB> i = 0 <TAB> while True: <TAB>  <TAB> i = i + 1 <TAB>  <TAB> time.sleep(interval) <TAB>  <TAB> vols = conn.get_all_volumes(volume_ids=[volume_id]) <TAB>  <TAB> if len(vols) != 1: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> vol = vols[0] <TAB>  <TAB> if vol.status == ""available"": <TAB>  <TAB>  <TAB> return True <MASK> return False",if i > retries :,131
"def get_start_end(val): <TAB> if isinstance(val, slice): <TAB>  <TAB> start = val.start <TAB>  <TAB> if not start: <TAB>  <TAB>  <TAB> start = 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> start -= 1 <TAB>  <TAB> end = val.stop or self.total <TAB>  <TAB> if end < 0: <TAB>  <TAB>  <TAB> end = self.total + end <MASK> end = self._max_item <TAB>  <TAB> return start, end <TAB> return val, val + 1",if self . _max_item is not None and end > self . _max_item :,131
"def fire(self, event, data=None): <TAB> for entry in tuple(self.callbacks.values()): <TAB>  <TAB> match = entry.regex.match(event) <MASK> match = match.group() <TAB>  <TAB>  <TAB> for callback in tuple(entry.callbacks): <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> callback(self, match, data) <TAB>  <TAB>  <TAB>  <TAB> except CallbackError: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._remove_callback(entry, callback) <TAB>  <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._remove_callback(entry, callback) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.channels.logger.exception( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> 'callback exception: channel ""%s"" event ""%s""', self.name, event <TAB>  <TAB>  <TAB>  <TAB>  <TAB> )",if match :,182
"def check_format(fmt, row): <TAB> if all([x(n.strip()) for (x, n) in zip(fmt, row)]): <TAB>  <TAB> vals = [None] * 6 <TAB>  <TAB> for i, j in enumerate(fmt): <MASK> vals[fmtmaps[j]] = row[i] <TAB>  <TAB> r = Row._make(vals) <TAB>  <TAB> return r <TAB> return False",if j in fmtmaps :,103
"def action(self, appid, action): <TAB> message = {""message"": """", ""status"": 0} <TAB> if action.get(""action"") == ""kill"": <TAB>  <TAB> api = DataEngApi(self.user) <TAB>  <TAB> for _id in appid: <TAB>  <TAB>  <TAB> result = api.delete_cluster(_id) <TAB>  <TAB>  <TAB> if result.get(""error""): <TAB>  <TAB>  <TAB>  <TAB> message[""message""] = result.get(""error"") <TAB>  <TAB>  <TAB>  <TAB> message[""status""] = -1 <MASK> message[""message""] = result.get(""contents"") <TAB> return message","elif result . get ( ""contents"" ) and message . get ( ""status"" ) != - 1 :",155
def reloader_thread(): <TAB> ensure_echo_on() <TAB> if USE_INOTIFY: <TAB>  <TAB> fn = inotify_code_changed <TAB> else: <TAB>  <TAB> fn = code_changed <TAB> while RUN_RELOADER: <TAB>  <TAB> change = fn() <MASK> auto_collectstatic() <TAB>  <TAB>  <TAB> sys.exit(3)  # force reload <TAB>  <TAB> elif change == I18N_MODIFIED: <TAB>  <TAB>  <TAB> reset_translations() <TAB>  <TAB> time.sleep(1),if change == FILE_MODIFIED :,125
"def linkedViewChanged(self, view, newRange=None): <TAB> if self.orientation in [""right"", ""left""]: <TAB>  <TAB> if newRange is None: <TAB>  <TAB>  <TAB> newRange = view.viewRange()[1] <TAB>  <TAB> if view.yInverted(): <TAB>  <TAB>  <TAB> self.setRange(*newRange[::-1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.setRange(*newRange) <TAB> else: <TAB>  <TAB> if newRange is None: <TAB>  <TAB>  <TAB> newRange = view.viewRange()[0] <MASK> self.setRange(*newRange[::-1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.setRange(*newRange)",if view . xInverted ( ) :,160
"def distance_to_furthest( <TAB> self, ps: Union[""Units"", List[""Point2""], Set[""Point2""]]) -> Union[int, float]: <TAB> """"""This function assumes the 2d distance is meant"""""" <TAB> assert ps <TAB> furthest_distance_squared = -math.inf <TAB> for p2 in ps: <TAB>  <TAB> if not isinstance(p2, Point2): <TAB>  <TAB>  <TAB> p2 = p2.position <TAB>  <TAB> distance = (self[0] - p2[0]) ** 2 + (self[1] - p2[1]) ** 2 <MASK> furthest_distance_squared = distance <TAB> return furthest_distance_squared ** 0.5",if furthest_distance_squared < distance :,171
"def find_extra_output(self, data: str) -> None: <TAB> lines = data.split(""\n"") <TAB> for line in lines: <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> found_extra_output = True <TAB>  <TAB> for compiled_pattern in self.compiled_line_patterns: <MASK> found_extra_output = False <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if found_extra_output: <TAB>  <TAB>  <TAB> self.full_extra_output += f""{line}\n""",if compiled_pattern . match ( line ) :,131
"def logfile(self, logfile: Union[str, Path, TextIO, None]): <TAB> if not hasattr(logfile, ""write"") and logfile: <TAB>  <TAB> self.logpath = logfile <TAB> else:  # file object <MASK> # None or '' <TAB>  <TAB>  <TAB> logfile = sys.stdout if self._is_run_from_ipython() else sys.stderr <TAB>  <TAB> self._logfile = logfile <TAB>  <TAB> self._logpath = None <TAB>  <TAB> _set_log_file(self)",if not logfile :,112
"def _parse_inner_rulesets(self): <TAB> self._parse_required_operator(""{"") <TAB> while True: <TAB>  <TAB> tok = self._tokenizer.get_next_token() <MASK> self._add_result(""expecting '}'"", tok) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> elif self._classifier.is_operator(tok, ""}""): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> self._tokenizer.put_back(tok) <TAB>  <TAB> self._parse_ruleset()","if tok [ ""style"" ] == EOF_STYLE :",120
"def controler(): <TAB> while True: <TAB>  <TAB> x = input("""") <TAB>  <TAB> # input and async <MASK> answer = options.get(x, return_error) <TAB>  <TAB>  <TAB> Biliconsole().append2list_console(answer) <TAB>  <TAB> # normal <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> options.get(x, return_error)()","if x in [ ""3"" , ""4"" , ""5"" , ""6"" , ""7"" ] :",102
"def exclude(self, d, item): <TAB> """"""check metadata for excluded items"""""" <TAB> try: <TAB>  <TAB> md = d.__metadata__ <TAB>  <TAB> pmd = getattr(md, ""__print__"", None) <MASK> return False <TAB>  <TAB> excludes = getattr(pmd, ""excludes"", []) <TAB>  <TAB> return item[0] in excludes <TAB> except: <TAB>  <TAB> pass <TAB> return False",if pmd is None :,98
"def broadcast_shape(*shapes): <TAB> if len(shapes) == 1: <TAB>  <TAB> return shapes[0] <TAB> out_shapes = [] <TAB> for ss in itertools.zip_longest(*[reversed(s) for s in shapes], fillvalue=-1): <TAB>  <TAB> shape = max(s for s in ss if s != -1) <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Operands could not be broadcast together "" <TAB>  <TAB>  <TAB>  <TAB> ""with shape {0}"".format("" "".join(map(str, shapes))) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> out_shapes.append(shape) <TAB> return tuple(reversed(out_shapes))",if any ( i != - 1 and i != 1 and i != shape and not np . isnan ( i ) for i in ss ) :,177
"def _init_weights(self, module): <TAB> std = self.config.init_std <TAB> if isinstance(module, nn.Linear): <TAB>  <TAB> module.weight.data.normal_(mean=0.0, std=std) <MASK> module.bias.data.zero_() <TAB> elif isinstance(module, MarianSinusoidalPositionalEmbedding): <TAB>  <TAB> pass <TAB> elif isinstance(module, nn.Embedding): <TAB>  <TAB> module.weight.data.normal_(mean=0.0, std=std) <TAB>  <TAB> if module.padding_idx is not None: <TAB>  <TAB>  <TAB> module.weight.data[module.padding_idx].zero_()",if module . bias is not None :,160
"def test_c_nan(self): <TAB> for dtype in self.dtypes: <MASK> continue <TAB>  <TAB> for op in self.reds: <TAB>  <TAB>  <TAB> self.with_mode( <TAB>  <TAB>  <TAB>  <TAB> Mode(linker=""c"", optimizer=mode_with_gpu.optimizer), <TAB>  <TAB>  <TAB>  <TAB> op, <TAB>  <TAB>  <TAB>  <TAB> dtype=dtype, <TAB>  <TAB>  <TAB>  <TAB> test_nan=True, <TAB>  <TAB>  <TAB>  <TAB> pre_scalar_op=self.pre_scalar_op, <TAB>  <TAB>  <TAB> )","if not dtype . startswith ( ""float"" ) :",129
def worker(session): <TAB> while True: <TAB>  <TAB> data = await queue.get() <MASK> return <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> await self.loop.create_task(session.send(data)) <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> log.error(e),if data is None :,76
"def update(self): <TAB> resp = self._make_request() <TAB> reader = csv.reader(resp.content.splitlines(), quotechar='""') <TAB> for line in reader: <TAB>  <TAB> if line[0].startswith(""#""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> first_seen = parser.parse(line[4]) <TAB>  <TAB> if self.last_run is not None: <MASK> continue <TAB>  <TAB> self.analyze(line, first_seen)",if self . last_run > first_seen . replace ( tzinfo = None ) :,123
"def __enter__(self): <TAB> if isinstance(self._target, dict): <TAB>  <TAB> self._original_values = self._target.copy() <MASK> self._target.clear() <TAB>  <TAB> self._target.update(self._replacement_values) <TAB> else: <TAB>  <TAB> self._original_values = self._target[:] <TAB>  <TAB> if self._clear: <TAB>  <TAB>  <TAB> self._target[:] = self._replacement_values <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._target.extend(self._replacement_values)",if self . _clear :,126
"def PushMessage(self, label, argv): <TAB> # type: (str, Optional[List[str]]) -> None <TAB> """"""For synchronous constructs that aren't processes."""""" <TAB> buf = self._RichTraceBegin("">"") <TAB> if buf: <TAB>  <TAB> buf.write(label) <TAB>  <TAB> if label == ""proc"": <TAB>  <TAB>  <TAB> _PrintArgv(argv, buf) <MASK> _PrintArgv(argv[1:], buf) <TAB>  <TAB> elif label == ""wait"": <TAB>  <TAB>  <TAB> _PrintArgv(argv[1:], buf) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> buf.write(""\n"") <TAB>  <TAB> self.f.write(buf.getvalue()) <TAB> self._Inc()","elif label == ""source"" :",167
"def bind(**kwargs): <TAB> for event, callback in kwargs.items(): <TAB>  <TAB> if event not in _callbacks: <TAB>  <TAB>  <TAB> raise Exception(""Unknown {!r} event"".format(event)) <MASK> listener = NewIntentListener(callback) <TAB>  <TAB>  <TAB> _activity.registerNewIntentListener(listener) <TAB>  <TAB>  <TAB> _callbacks[event].append(listener) <TAB>  <TAB> elif event == ""on_activity_result"": <TAB>  <TAB>  <TAB> listener = ActivityResultListener(callback) <TAB>  <TAB>  <TAB> _activity.registerActivityResultListener(listener) <TAB>  <TAB>  <TAB> _callbacks[event].append(listener)","elif event == ""on_new_intent"" :",149
"def __call__(self, x, deterministic=False, rng=None): <TAB> if self.rate == 0.0: <TAB>  <TAB> return x <TAB> keep_prob = 1.0 - self.rate <TAB> if deterministic: <TAB>  <TAB> return x <TAB> else: <MASK> rng = self.scope.make_rng(""dropout"") <TAB>  <TAB> mask = random.bernoulli(rng, p=keep_prob, shape=x.shape) <TAB>  <TAB> return lax.select(mask, x / keep_prob, jnp.zeros_like(x))",if rng is None :,133
"def interp_order(self, interp_order): <TAB> try: <MASK> self._interp_order = tuple(int(order) for order in interp_order) <TAB>  <TAB>  <TAB> return <TAB> except (TypeError, ValueError): <TAB>  <TAB> pass <TAB> try: <TAB>  <TAB> interp_order = int(interp_order) <TAB>  <TAB> self._interp_order = (int(interp_order),) * len(self.file_path) <TAB> except (TypeError, ValueError): <TAB>  <TAB> tf.logging.fatal( <TAB>  <TAB>  <TAB> ""output interp_order should be an integer or "" <TAB>  <TAB>  <TAB> ""a sequence of integers that matches len(self.file_path)"" <TAB>  <TAB> ) <TAB>  <TAB> raise ValueError",if len ( interp_order ) == len ( self . file_path ) :,177
"def _delete_cell(self, row, column): <TAB> for i in range(row, self.rowCount()): <TAB>  <TAB> edit = self.cellWidget(i, column) <TAB>  <TAB> if edit and isinstance(edit, PackageSelectWidget): <TAB>  <TAB>  <TAB> next_edit = self.cellWidget(i + 1, column) <MASK> next_edit.clone_into(edit) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.removeCellWidget(i, column)","if next_edit and isinstance ( next_edit , PackageSelectWidget ) :",129
"def _callback(self, data): <TAB> try: <TAB>  <TAB> messages = list(fifo.split_message(data)) <TAB> except ValueError: <TAB>  <TAB> print_w(""invalid message: %r"" % data) <TAB>  <TAB> return <TAB> for command, path in messages: <TAB>  <TAB> command = bytes2fsn(command, None) <TAB>  <TAB> response = self._cmd_registry.handle_line(self._app, command) <MASK> path = bytes2fsn(path, None) <TAB>  <TAB>  <TAB> with open(path, ""wb"") as h: <TAB>  <TAB>  <TAB>  <TAB> if response is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> assert isinstance(response, fsnative) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> h.write(fsn2bytes(response, None))",if path is not None :,181
"def __exit__(self, exc_type, exc_val, exc_tb) -> None: <TAB> if exc_type is None: <TAB>  <TAB> with self._console._lock: <TAB>  <TAB>  <TAB> buffer: List[Segment] = self._console._buffer[:] <TAB>  <TAB>  <TAB> del self._console._buffer[:] <TAB>  <TAB>  <TAB> segments: Iterable[Segment] = buffer <MASK> segments = Segment.strip_styles(segments) <TAB>  <TAB>  <TAB> elif not self.links: <TAB>  <TAB>  <TAB>  <TAB> segments = Segment.strip_links(segments) <TAB>  <TAB>  <TAB> content = self._console._render_buffer(segments) <TAB>  <TAB> self.pager.show(content) <TAB> self._console._exit_buffer()",if not self . styles :,170
"def detect(stream): <TAB> """"""Returns True if the given stream is valid DBF"""""" <TAB> # _dbf = dbf.Table(StringIO(stream)) <TAB> try: <TAB>  <TAB> if is_py3: <MASK> stream = bytes(stream, ""utf-8"") <TAB>  <TAB>  <TAB> _dbf = dbf.Dbf(io.BytesIO(stream), readOnly=True) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _dbf = dbf.Dbf(StringIO(stream), readOnly=True) <TAB>  <TAB> return True <TAB> except Exception: <TAB>  <TAB> return False",if type ( stream ) is not bytes :,146
"def check_incompatible_property_override(self, e: Decorator) -> None: <TAB> if not e.var.is_settable_property and e.func.info: <TAB>  <TAB> name = e.func.name <TAB>  <TAB> for base in e.func.info.mro[1:]: <TAB>  <TAB>  <TAB> base_attr = base.names.get(name) <MASK> continue <TAB>  <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB>  <TAB> isinstance(base_attr.node, OverloadedFuncDef) <TAB>  <TAB>  <TAB>  <TAB> and base_attr.node.is_property <TAB>  <TAB>  <TAB>  <TAB> and cast(Decorator, base_attr.node.items[0]).var.is_settable_property <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> self.fail(message_registry.READ_ONLY_PROPERTY_OVERRIDES_READ_WRITE, e)",if not base_attr :,192
"def checkfiles(path, speclist, recursive=False, excludedirs=None): <TAB> results = [] <TAB> if recursive: <TAB>  <TAB> for root, dirs, files in os.walk(path, topdown=True): <TAB>  <TAB>  <TAB> if excludedirs: <TAB>  <TAB>  <TAB>  <TAB> dirs[:] = [d for d in dirs if d not in excludedirs] <TAB>  <TAB>  <TAB> for fn in files: <TAB>  <TAB>  <TAB>  <TAB> for spec in speclist: <MASK> results.append(os.path.join(root, fn)) <TAB> else: <TAB>  <TAB> for spec in speclist: <TAB>  <TAB>  <TAB> results.extend(glob.glob(os.path.join(path, spec))) <TAB> return results","if fnmatch . fnmatch ( fn , spec ) :",174
"def VType(self): <TAB> if ""DW_AT_type"" in self.attributes: <TAB>  <TAB> target_type = self.types[self.type_id].VType() <MASK> target_type = [target_type, None] <TAB>  <TAB> return [ <TAB>  <TAB>  <TAB> ""Array"", <TAB>  <TAB>  <TAB> dict(target=target_type[0], target_args=target_type[1], count=self.count), <TAB>  <TAB> ] <TAB> return [""Array"", dict(count=self.count)]","if not isinstance ( target_type , list ) :",131
"def _write_chartsheets(self): <TAB> for idx, sheet in enumerate(self.workbook.chartsheets, 1): <TAB>  <TAB> sheet._id = idx <TAB>  <TAB> xml = tostring(sheet.to_tree()) <TAB>  <TAB> self._archive.writestr(sheet.path[1:], xml) <TAB>  <TAB> self.manifest.append(sheet) <MASK> self._write_drawing(sheet._drawing) <TAB>  <TAB>  <TAB> rel = Relationship(type=""drawing"", Target=sheet._drawing.path) <TAB>  <TAB>  <TAB> rels = RelationshipList() <TAB>  <TAB>  <TAB> rels.append(rel) <TAB>  <TAB>  <TAB> tree = rels.to_tree() <TAB>  <TAB>  <TAB> rels_path = get_rels_path(sheet.path[1:]) <TAB>  <TAB>  <TAB> self._archive.writestr(rels_path, tostring(tree))",if sheet . _drawing :,192
"def remove_all_subdirs(root, subdir_name): <TAB> for (dirpath, dirnames, filenames) in os.walk(root): <MASK> dir_to_remove = os.path.join(dirpath, subdir_name) <TAB>  <TAB>  <TAB> dirnames[:] = [dn for dn in dirnames if dn != subdir_name] <TAB>  <TAB>  <TAB> print(""Removing directory %s"" % dir_to_remove) <TAB>  <TAB>  <TAB> shutil.rmtree(dir_to_remove)",if subdir_name in dirnames :,117
"def update_permission(self, user, name=""read"", users=None, groups=None): <TAB> # Check if user has access to grant permissions <TAB> if users or groups: <TAB>  <TAB> if name == ""read"": <TAB>  <TAB>  <TAB> self.can_read_or_exception(user) <MASK> self.can_write_or_exception(user) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(_(""Invalid permission type: %s"") % name) <TAB> perm, created = Document2Permission.objects.get_or_create(doc=self, perms=name) <TAB> perm.users = [] <TAB> if users is not None: <TAB>  <TAB> perm.users = users <TAB> perm.groups = [] <TAB> if groups is not None: <TAB>  <TAB> perm.groups = groups <TAB> perm.save()","elif name == ""write"" :",191
"def __str__(self): <TAB> try: <TAB>  <TAB> return super().__str__() <TAB> except Exception: <TAB>  <TAB> pass <TAB> if self.strRepr is None: <MASK> self.strRepr = ""!W:(%s...)"" % self.notChars[:4] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.strRepr = ""!W:(%s)"" % self.notChars <TAB> return self.strRepr",if len ( self . notChars ) > 4 :,115
"def format(self, limit=None): <TAB> lines = [] <TAB> if limit is not None and limit < 0: <TAB>  <TAB> return lines <TAB> for frame in self[:limit]: <TAB>  <TAB> lines.append('  File ""%s"", line %s' % (frame.filename, frame.lineno)) <TAB>  <TAB> line = linecache.getline(frame.filename, frame.lineno).strip() <MASK> lines.append("" <TAB> %s"" % line) <TAB> return lines",if line :,115
"def _verify_readline(self, readline, expected): <TAB> all = [] <TAB> while True: <TAB>  <TAB> # short readlines <TAB>  <TAB> line = readline(5) <TAB>  <TAB> if line and line != b""foo"": <MASK> self.assertTrue(line.endswith(b""\n"")) <TAB>  <TAB> all.append(line) <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB> break <TAB> self.assertEqual(b"""".join(all), expected)",if len ( line ) < 5 :,115
"def load_and_encode(infile, vmodel, ext=None, nsamples=None, **kwargs): <TAB> r = dict() <TAB> if infile.endswith("".npz""): <TAB>  <TAB> r = load_cache(infile, nsamples=nsamples) <TAB> else: <TAB>  <TAB> contracts = load_contracts(infile, ext=ext, nsamples=nsamples) <TAB>  <TAB> for contract in contracts: <TAB>  <TAB>  <TAB> for x, ir in encode_contract(contract, **kwargs).items(): <MASK> y = "" "".join(ir) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> r[x] = vmodel.get_sentence_vector(y) <TAB> return r",if ir != [ ] :,162
"def msg_ser_json(inst, sformat=""json"", lev=0): <TAB> # sformat = ""json"" always except when dict <TAB> if lev: <TAB>  <TAB> sformat = ""dict"" <TAB> if sformat == ""dict"": <TAB>  <TAB> if isinstance(inst, Message): <TAB>  <TAB>  <TAB> res = inst.serialize(sformat, lev) <MASK> res = inst <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise MessageException(""Wrong type: %s"" % type(inst)) <TAB> else: <TAB>  <TAB> sformat = ""json"" <TAB>  <TAB> if isinstance(inst, Message): <TAB>  <TAB>  <TAB> res = inst.serialize(sformat, lev) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> res = inst <TAB> return res","elif isinstance ( inst , dict ) :",174
"def print_map(node, l, lvl=0): <TAB> for n in node.children: <TAB>  <TAB> if lvl == 0: <TAB>  <TAB>  <TAB> l.append(""%s"" % n.title) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> l.append(""{} {}"".format(""\t"" * lvl, n.title)) <MASK> print_map(n, l, lvl + 1)",if len ( n . children ) > 0 :,100
"def _join(cls, query, models, account, exclude=None): <TAB> if exclude is None: <TAB>  <TAB> exclude = [] <TAB> for model in models: <MASK> continue <TAB>  <TAB> if model in exclude: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if model == MetadataItemSettings: <TAB>  <TAB>  <TAB> query = cls._join_settings(query, account) <TAB>  <TAB> elif model == MediaItem: <TAB>  <TAB>  <TAB> query = query.join( <TAB>  <TAB>  <TAB>  <TAB> MediaItem, <TAB>  <TAB>  <TAB>  <TAB> JOIN_LEFT_OUTER, <TAB>  <TAB>  <TAB>  <TAB> on=(MediaItem.metadata_item == MetadataItem.id).alias(""media""), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""Unable to join unknown model: %r"" % model) <TAB> return query",if model == MetadataItem :,185
"def GET(self): <TAB> ret = ""<html><body><ul>"" <TAB> for filename in os.listdir(arc_dir): <MASK> continue <TAB>  <TAB> f = open(arc_dir + ""/"" + filename) <TAB>  <TAB> line = f.readline() <TAB>  <TAB> f.close() <TAB>  <TAB> ret += '<li><a href=""/%s"">%s</a> - %s' % (filename, filename, line) <TAB> ret += ""</body></html>"" <TAB> return ret","if not filename . endswith ( "".arc"" ) :",120
"def from_tree(cls, tree: DictTree) -> ""TensorDict"": <TAB> res = cls() <TAB> for k, v in tree.items(): <MASK> res[k] = cls.from_tree(v) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> res[k] = torch.as_tensor(v) <TAB> return res","if isinstance ( v , dict ) :",88
"def init_FaceProcessing(model_path): <TAB> global globGraph <TAB> if globGraph != None: <TAB>  <TAB> return globGraph <TAB> globGraph = load_graph(model_path) <TAB> previous = ""no"" <TAB> for op in globGraph.get_operations(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> firstLevel = op.name.split(""/"")[1] <MASK> print(op.name) <TAB>  <TAB>  <TAB>  <TAB> previous = firstLevel <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> print(op.name) <TAB> return globGraph",if firstLevel . startswith ( previous ) is not True :,138
"def _next_non_empty_row(view, pt): <TAB> r = utils.row_at(view, pt) <TAB> while True: <TAB>  <TAB> r += 1 <TAB>  <TAB> reg = view.line(view.text_point(r, 0)) <TAB>  <TAB> if r >= utils.last_row(view): <TAB>  <TAB>  <TAB> return view.size(), True <MASK> return reg.a, False",if not reg . empty ( ) :,102
"def _get_wholeText(self): <TAB> L = [self.data] <TAB> n = self.previousSibling <TAB> while n is not None: <MASK> L.insert(0, n.data) <TAB>  <TAB>  <TAB> n = n.previousSibling <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> n = self.nextSibling <TAB> while n is not None: <TAB>  <TAB> if n.nodeType in (Node.TEXT_NODE, Node.CDATA_SECTION_NODE): <TAB>  <TAB>  <TAB> L.append(n.data) <TAB>  <TAB>  <TAB> n = n.nextSibling <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> return """".join(L)","if n . nodeType in ( Node . TEXT_NODE , Node . CDATA_SECTION_NODE ) :",177
"def pytest_collection_modifyitems(items): <TAB> for item in items: <TAB>  <TAB> if item.nodeid.startswith(""tests/distributions""): <TAB>  <TAB>  <TAB> if ""stage"" not in item.keywords: <TAB>  <TAB>  <TAB>  <TAB> item.add_marker(pytest.mark.stage(""unit"")) <MASK> item.add_marker(pytest.mark.init(rng_seed=123))","if ""init"" not in item . keywords :",102
"def bind(self, *argv, **kwarg): <TAB> with self.lock: <MASK> raise socket.error(22, ""Invalid argument"") <TAB>  <TAB> self.fd = self.libc.inotify_init() <TAB>  <TAB> self._poll.register(self.fd) <TAB>  <TAB> for path in self.path: <TAB>  <TAB>  <TAB> self.register_path(path)",if self . fd is not None :,97
"def load_auth_credentials_from_file(cookie_file): <TAB> """"""Load credentials from an opened .gitcookies file."""""" <TAB> credentials = {} <TAB> for line in cookie_file: <TAB>  <TAB> if line.startswith(""#HttpOnly_""): <TAB>  <TAB>  <TAB> line = line[len(""#HttpOnly_"") :] <MASK> continue <TAB>  <TAB> row = line.split(""\t"") <TAB>  <TAB> if len(row) != 7: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> domain = row[0] <TAB>  <TAB> cookie = row[6] <TAB>  <TAB> sep = cookie.find(""="") <TAB>  <TAB> if sep == -1: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> username = cookie[0:sep] <TAB>  <TAB> password = cookie[sep + 1 :] <TAB>  <TAB> credentials[domain] = (username, password) <TAB> return credentials","if not line or line [ 0 ] == ""#"" :",191
"def _save_file(self, parsed, **kwargs): <TAB> if not is_parsed_result_successful(parsed): <TAB>  <TAB> return <TAB> method = self._method.value <TAB> outfile = self._outfile.value <TAB> if method in parsed[""VirtualMFADevice""]: <TAB>  <TAB> body = parsed[""VirtualMFADevice""][method] <TAB>  <TAB> with open(outfile, ""wb"") as fp: <TAB>  <TAB>  <TAB> fp.write(base64.b64decode(body)) <TAB>  <TAB> for choice in CHOICES: <MASK> del parsed[""VirtualMFADevice""][choice]","if choice in parsed [ ""VirtualMFADevice"" ] :",135
"def transform_dict(sols): <TAB> if not sols: <TAB>  <TAB> yield sols <TAB> for var, sol in sols.items(): <TAB>  <TAB> rest = sols.copy() <TAB>  <TAB> del rest[var] <TAB>  <TAB> rest = transform_dict(rest) <TAB>  <TAB> if not isinstance(sol, (tuple, list)): <TAB>  <TAB>  <TAB> sol = [sol] <MASK> for r in rest: <TAB>  <TAB>  <TAB>  <TAB> yield r <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for r in rest: <TAB>  <TAB>  <TAB>  <TAB> for item in sol: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> new_sols = r.copy() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> new_sols[var] = item <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield new_sols <TAB>  <TAB> break",if not sol :,170
"def prune_safe_curie(node, name): <TAB> if node.hasAttribute(name): <TAB>  <TAB> av = node.getAttribute(name) <MASK> node.removeAttribute(name) <TAB>  <TAB>  <TAB> node.setAttribute(name + ""_pruned"", """") <TAB>  <TAB>  <TAB> msg = ( <TAB>  <TAB>  <TAB>  <TAB> ""Attribute @%s uses an empty safe CURIE; the attribute is ignored"" <TAB>  <TAB>  <TAB>  <TAB> % name <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> options.add_warning(msg, node=node)","if av == ""[]"" :",125
"def __get_rule_schema(cls, method_name): <TAB> docstring = getattr(cls, method_name).__doc__ <TAB> if docstring is None: <TAB>  <TAB> result = {} <TAB> else: <MASK> docstring = docstring.split(RULE_SCHEMA_SEPARATOR)[1] <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> result = literal_eval(docstring.strip()) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> result = {} <TAB> if not result and method_name != ""_validate_meta"": <TAB>  <TAB> warn( <TAB>  <TAB>  <TAB> ""No validation schema is defined for the arguments of rule "" <TAB>  <TAB>  <TAB> ""'%s'"" % method_name.split(""_"", 2)[-1] <TAB>  <TAB> ) <TAB> return result",if RULE_SCHEMA_SEPARATOR in docstring :,176
"def read_trees(source, max_sents=-1): <TAB> with open(source) as fp: <TAB>  <TAB> trees = [] <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> tree = read_tree(fp) <TAB>  <TAB>  <TAB> if tree is None: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> trees.append(tree) <MASK> break <TAB>  <TAB> return trees",if len ( trees ) >= max_sents > 0 :,100
"def _to_ops(self, ops: Ops) -> None:  # pragma: no cover <TAB> """"""Common method for to_cpu/to_gpu."""""" <TAB> for node in self.walk(): <TAB>  <TAB> node.ops = ops <TAB>  <TAB> for name in node.param_names: <TAB>  <TAB>  <TAB> if node.has_param(name): <TAB>  <TAB>  <TAB>  <TAB> node.set_param(name, ops.asarray_f(node.get_param(name))) <MASK> node.set_grad(name, ops.asarray_f(node.get_grad(name))) <TAB>  <TAB> for shim in node.shims: <TAB>  <TAB>  <TAB> shim.to_device(ops.device_type, ops.device_id)",if node . has_grad ( name ) :,178
"def _split_dict_items(self, items): <TAB> separate = [] <TAB> for item in items: <TAB>  <TAB> name, value = split_from_equals(item) <MASK> break <TAB>  <TAB> separate.append(item) <TAB> return separate, items[len(separate) :]",if value is not None or VariableSplitter ( item ) . is_dict_variable ( ) :,86
"def merge_symbols(self, other, *args): <TAB> for arg in args: <TAB>  <TAB> if arg in other.vtypes: <TAB>  <TAB>  <TAB> self.vtypes[arg] = other.vtypes[arg] <MASK> self.overlays[arg] = other.overlays[arg] <TAB>  <TAB> if arg in other.object_classes: <TAB>  <TAB>  <TAB> self.object_classes[arg] = other.object_classes[arg] <TAB> self.flush_cache()",if arg in other . overlays :,121
"def list_templates(self): <TAB> result = set() <TAB> loader = self.app.jinja_loader <TAB> if loader is not None: <TAB>  <TAB> result.update(loader.list_templates()) <TAB> for name, blueprint in iteritems(self.app.blueprints): <TAB>  <TAB> loader = blueprint.jinja_loader <TAB>  <TAB> if loader is not None: <TAB>  <TAB>  <TAB> for template in loader.list_templates(): <TAB>  <TAB>  <TAB>  <TAB> prefix = """" <MASK> prefix = name + ""/"" <TAB>  <TAB>  <TAB>  <TAB> result.add(prefix + template) <TAB> return list(result)",if blueprint_is_module ( blueprint ) :,152
"def get_funcrva(self, f_str): <TAB> if self.expdesc is None: <TAB>  <TAB> return None <TAB> for i, entry in enumerate(self.f_names): <MASK> continue <TAB>  <TAB> ordinal = self.f_nameordinals[i].ordinal <TAB>  <TAB> rva = self.f_address[ordinal].rva <TAB>  <TAB> return rva <TAB> return None",if f_str != entry . name . name :,105
"def on_log(self, args, state, control, model=None, logs=None, **kwargs): <TAB> if not self._initialized: <TAB>  <TAB> self.setup(args, state, model) <TAB> if state.is_world_process_zero: <TAB>  <TAB> experiment = comet_ml.config.get_global_experiment() <MASK> experiment._log_metrics( <TAB>  <TAB>  <TAB>  <TAB> logs, <TAB>  <TAB>  <TAB>  <TAB> step=state.global_step, <TAB>  <TAB>  <TAB>  <TAB> epoch=state.epoch, <TAB>  <TAB>  <TAB>  <TAB> framework=""transformers"", <TAB>  <TAB>  <TAB> )",if experiment is not None :,141
"def undo_func(): <TAB> obj._status_ = status <TAB> obj._wbits_ = wbits <TAB> if status in (""loaded"", ""inserted"", ""updated""): <TAB>  <TAB> assert objects_to_save <TAB>  <TAB> obj2 = objects_to_save.pop() <TAB>  <TAB> assert obj2 is obj and obj._save_pos_ == len(objects_to_save) <TAB>  <TAB> obj._save_pos_ = None <TAB> for cache_index, old_key, new_key in undo: <MASK> del cache_index[new_key] <TAB>  <TAB> if old_key is not None: <TAB>  <TAB>  <TAB> cache_index[old_key] = obj",if new_key is not None :,162
"def with_warn_for_invalid_lines(mappings): <TAB> # type: (Iterator[Binding]) -> Iterator[Binding] <TAB> for mapping in mappings: <MASK> logger.warning( <TAB>  <TAB>  <TAB>  <TAB> ""Python-dotenv could not parse statement starting at line %s"", <TAB>  <TAB>  <TAB>  <TAB> mapping.original.line, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> yield mapping",if mapping . error :,93
"def from_text(cls, rdclass, rdtype, tok, origin=None, relativize=True): <TAB> chunks = [] <TAB> while 1: <TAB>  <TAB> t = tok.get().unescape() <MASK> break <TAB>  <TAB> if not t.is_identifier(): <TAB>  <TAB>  <TAB> raise dns.exception.SyntaxError <TAB>  <TAB> chunks.append(t.value.encode()) <TAB> b64 = b"""".join(chunks) <TAB> data = base64.b64decode(b64) <TAB> return cls(rdclass, rdtype, data)",if t . is_eol_or_eof ( ) :,139
"def sanitize(potentially_sensitive): <TAB> if isinstance(potentially_sensitive, Mapping): <TAB>  <TAB> # Makes new dict so we don't modify the original <TAB>  <TAB> # Also case-insensitive--possibly important for HTTP headers. <TAB>  <TAB> return dict(redacted(k.lower(), v) for k, v in potentially_sensitive.items()) <TAB> else: <MASK> potentially_sensitive = str(potentially_sensitive) <TAB>  <TAB> return SANITIZE_REGEX.sub(r""\1{}"".format(REPLACEMENT), potentially_sensitive)","if not isinstance ( potentially_sensitive , str ) :",129
"def build_class_directories(dir): <TAB> dir_id = 0 <TAB> class_dir = os.path.join(dir, str(dir_id)) <TAB> if not os.path.exists(class_dir): <TAB>  <TAB> os.mkdir(class_dir) <TAB> for i in range(1, 1361): <TAB>  <TAB> fname = ""image_"" + (""%.4i"" % i) + "".jpg"" <TAB>  <TAB> os.rename(os.path.join(dir, fname), os.path.join(class_dir, fname)) <MASK> dir_id += 1 <TAB>  <TAB>  <TAB> class_dir = os.path.join(dir, str(dir_id)) <TAB>  <TAB>  <TAB> os.mkdir(class_dir)",if i % 80 == 0 and dir_id < 16 :,183
"def _getparser(self): <TAB> from _pytest._argcomplete import filescompleter <TAB> optparser = MyOptionParser(self, self.extra_info) <TAB> groups = self._groups + [self._anonymous] <TAB> for group in groups: <MASK> desc = group.description or group.name <TAB>  <TAB>  <TAB> arggroup = optparser.add_argument_group(desc) <TAB>  <TAB>  <TAB> for option in group.options: <TAB>  <TAB>  <TAB>  <TAB> n = option.names() <TAB>  <TAB>  <TAB>  <TAB> a = option.attrs() <TAB>  <TAB>  <TAB>  <TAB> arggroup.add_argument(*n, **a) <TAB> # bash like autocompletion for dirs (appending '/') <TAB> optparser.add_argument(FILE_OR_DIR, nargs=""*"").completer = filescompleter <TAB> return optparser",if group . options :,185
"def __getitem__(self, key): <TAB> val = self.file_content[key] <TAB> if isinstance(val, netCDF4.Variable): <TAB>  <TAB> # these datasets are closed and inaccessible when the file is <TAB>  <TAB> # closed, need to reopen <TAB>  <TAB> # TODO: Handle HDF4 versus NetCDF3 versus NetCDF4 <TAB>  <TAB> parts = key.rsplit(""/"", 1) <MASK> group, key = parts <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> group = None <TAB>  <TAB> with xr.open_dataset(self.filename, group=group, **self._xarray_kwargs) as nc: <TAB>  <TAB>  <TAB> val = nc[key] <TAB> return val",if len ( parts ) == 2 :,164
"def topological_sort_feature_dependencies(features): <TAB> # topological sorting of output features for resolving dependencies <TAB> dependencies_graph = {} <TAB> output_features_dict = {} <TAB> for feature in features: <TAB>  <TAB> dependencies = [] <TAB>  <TAB> if ""dependencies"" in feature: <TAB>  <TAB>  <TAB> dependencies.extend(feature[""dependencies""]) <MASK> dependencies.append(feature[""tied_weights""]) <TAB>  <TAB> dependencies_graph[feature[""name""]] = dependencies <TAB>  <TAB> output_features_dict[feature[""name""]] = feature <TAB> return [ <TAB>  <TAB> output_features_dict[node[0]] for node in topological_sort(dependencies_graph) <TAB> ]","if ""tied_weights"" in feature :",164
"def get_similarly_tagged_fuzzers(current_fully_qualified_fuzzer_name): <TAB> """"""Get all fuzz targets with any similar tags to current fuzzer."""""" <TAB> similarly_tagged_targets = {} <TAB> for tag in get_fuzz_target_tags(current_fully_qualified_fuzzer_name): <TAB>  <TAB> targets = [ <TAB>  <TAB>  <TAB> target.fully_qualified_fuzz_target_name <TAB>  <TAB>  <TAB> for target in get_targets_with_tag(tag.tag) <MASK> != current_fully_qualified_fuzzer_name <TAB>  <TAB> ] <TAB>  <TAB> if targets: <TAB>  <TAB>  <TAB> similarly_tagged_targets[tag.tag] = targets <TAB> return similarly_tagged_targets",if target . fully_qualified_fuzz_target_name,187
"def wait_for_server_start(stdoutfile): <TAB> print(""Waiting for server start reading file "" + stdoutfile) <TAB> n = 0 <TAB> while True: <MASK> with open(stdoutfile, encoding=""utf-8"", errors=""ignore"") as f: <TAB>  <TAB>  <TAB>  <TAB> out = f.read() <TAB>  <TAB>  <TAB>  <TAB> if ""Server waiting for client requests"" in out: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB>  <TAB> # Handle error case when the server failed to start and gave <TAB>  <TAB>  <TAB>  <TAB> # some error message. <TAB>  <TAB>  <TAB>  <TAB> if ""usage: CodeChecker"" in out: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> time.sleep(1) <TAB>  <TAB> n += 1 <TAB>  <TAB> print(""Waiting for server to start for "" + str(n) + "" seconds..."")",if os . path . isfile ( stdoutfile ) :,193
def ctypes(self): <TAB> if not self._ctypes_data: <TAB>  <TAB> array_type = c_double * self._ndim <TAB>  <TAB> array = array_type() <TAB>  <TAB> xy = self.coords[0] <TAB>  <TAB> array[0] = xy[0] <TAB>  <TAB> array[1] = xy[1] <MASK> array[2] = xy[2] <TAB>  <TAB> self._ctypes_data = array <TAB> return self._ctypes_data,if self . _ndim == 3 :,115
"def clearData(self, format=None): <TAB> thelist = self.dataStore.items <TAB> if self.dataStore is not None: <TAB>  <TAB> if format is None: <TAB>  <TAB>  <TAB> thelist.clear() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> format = format.lower() <TAB>  <TAB>  <TAB> to_del = [] <TAB>  <TAB>  <TAB> for idx, item in enumerate(thelist): <MASK> to_del.append(idx) <TAB>  <TAB>  <TAB> to_del.reverse() <TAB>  <TAB>  <TAB> for idx in to_del: <TAB>  <TAB>  <TAB>  <TAB> del thelist[idx]",if item . type == format :,146
"def publish(self): <TAB> pending = self._publish.getUnpublished() <TAB> pendingCount = len(pending) <TAB> if not self._context[""silent""]: <TAB>  <TAB> if pendingCount == 0: <TAB>  <TAB>  <TAB> print(""No pending changes to publish."") <TAB>  <TAB>  <TAB> return <TAB>  <TAB> print(""Found %d pending files to publish"" % pendingCount) <TAB>  <TAB> choice = input(""Continue? y/N:"") <MASK> print(""Aborted on user command"") <TAB>  <TAB>  <TAB> return <TAB>  <TAB> print(self._publish.publish())","if choice != ""y"" :",130
"def _find_function_address(self, search_tuple): <TAB> name, handle = search_tuple <TAB> dprint(""PupyCDLL._find_function_address: {}"".format(name)) <TAB> if not type(name) in (str, unicode): <TAB>  <TAB> return self._FuncPtr_orig(search_tuple) <TAB> else: <TAB>  <TAB> addr = pupy.find_function_address(self._name, name) <TAB>  <TAB> dprint(""PupyCDLL._find_function_address: {} = {}"".format(name, addr)) <MASK> return self._FuncPtr_orig(addr) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self._FuncPtr_orig(search_tuple)",if addr :,165
"def run(self): <TAB> try: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> client_socket, addr = self.listen_socket.accept() <TAB>  <TAB>  <TAB>  <TAB> logging.debug(""[ ++ ] Client %s connected."" % (addr,)) <TAB>  <TAB>  <TAB>  <TAB> self.client_handler_type(self, client_socket).run() <TAB>  <TAB>  <TAB>  <TAB> logging.debug(""[ -- ] Client %s disconnected."" % (addr,)) <TAB>  <TAB>  <TAB> except socket.timeout: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> with self.lock: <MASK> logging.debug(""[ ** ] Server stopped normally."") <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB> finally: <TAB>  <TAB> self.listen_socket.close()",if self . stopping :,174
"def indent_lines(source_code, amount): <TAB> if amount == 0: <TAB>  <TAB> return source_code <TAB> lines = source_code.splitlines(True) <TAB> result = [] <TAB> for l in lines: <MASK> result.append(""\n"") <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if amount < 0: <TAB>  <TAB>  <TAB> indents = codeanalyze.count_line_indents(l) <TAB>  <TAB>  <TAB> result.append(max(0, indents + amount) * "" "" + l.lstrip()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result.append("" "" * amount + l) <TAB> return """".join(result)","if l . strip ( ) == """" :",153
"def per_property_preprocessors(self, uow): <TAB> if self.prop._reverse_property: <MASK> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if False in (prop.passive_updates for prop in self.prop._reverse_property): <TAB>  <TAB>  <TAB>  <TAB> return <TAB> uow.register_preprocessor(self, False)",if self . passive_updates :,90
"def get_env_dir(opt, args): <TAB> if opt.python_virtualenv: <TAB>  <TAB> if hasattr(sys, ""real_prefix""): <TAB>  <TAB>  <TAB> res = sys.prefix <TAB>  <TAB> elif hasattr(sys, ""base_prefix"") and sys.base_prefix != sys.prefix: <TAB>  <TAB>  <TAB> res = sys.prefix <MASK> res = sys.prefix <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logger.error(""No python virtualenv is available"") <TAB>  <TAB>  <TAB> sys.exit(2) <TAB> else: <TAB>  <TAB> res = args[0] <TAB> return to_utf8(res)","elif ""CONDA_PREFIX"" in os . environ :",153
"def remove_machine_only_from_element(root, element_spec): <TAB> query = BENCHMARK_QUERY + ""//{0}"".format(element_spec) <TAB> elements = root.findall(query, PREFIX_TO_NS) <TAB> for el in elements: <TAB>  <TAB> platforms = el.findall(""./xccdf-1.2:platform"", PREFIX_TO_NS) <TAB>  <TAB> for p in platforms: <MASK> el.remove(p)","if p . get ( ""idref"" ) == ""cpe:/a:machine"" :",125
"def _parse_string(s, b): <TAB> code_0 = ord(""0"") <TAB> code_a = ord(""a"") <TAB> assert code_a > code_0 <TAB> value = Integer(0) <TAB> for char in s.lower(): <TAB>  <TAB> code = ord(char) <TAB>  <TAB> if code >= code_a: <TAB>  <TAB>  <TAB> digit = 10 + code - code_a <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> digit = code - code_0 <MASK> value = Expression(""Plus"", Expression(""Times"", value, b), Integer(digit)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return None <TAB> return value",if 0 <= digit < 36 :,153
"def gen_IR(self): <TAB> for layer in self.keras_graph.topological_sort: <TAB>  <TAB> current_node = self.keras_graph.get_node(layer) <TAB>  <TAB> node_type = current_node.type <MASK> func = getattr(self, ""rename_"" + node_type) <TAB>  <TAB>  <TAB> func(current_node) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""KerasParser has not supported operator [%s]."" % (node_type)) <TAB>  <TAB>  <TAB> self.rename_UNKNOWN(current_node) <TAB> _K.clear_session()","if hasattr ( self , ""rename_"" + node_type ) :",147
"def decode_prop(self, prop, value): <TAB> if prop.data_type == list: <MASK> item_type = getattr(prop, ""item_type"") <TAB>  <TAB>  <TAB> if Model in item_type.mro(): <TAB>  <TAB>  <TAB>  <TAB> item_type = Model <TAB>  <TAB>  <TAB> values = [] <TAB>  <TAB>  <TAB> for item_node in value.getElementsByTagName(""item""): <TAB>  <TAB>  <TAB>  <TAB> value = self.decode(item_type, item_node) <TAB>  <TAB>  <TAB>  <TAB> values.append(value) <TAB>  <TAB>  <TAB> return values <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.get_text_value(value) <TAB> else: <TAB>  <TAB> return self.decode(prop.data_type, value)","if hasattr ( prop , ""item_type"" ) :",174
"def walk(prefix): <TAB> child_dirs, files = storage.listdir(prefix) <TAB> for filename in files: <TAB>  <TAB> relfilename = os.path.join(prefix, filename) <MASK> if options[""delete_orphans""]: <TAB>  <TAB>  <TAB>  <TAB> storage.delete(relfilename) <TAB>  <TAB>  <TAB>  <TAB> msg = ""Deleted orphaned file '{}'"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> msg = ""Found orphaned file '{}'"" <TAB>  <TAB>  <TAB> if options[""verbosity""] > 2: <TAB>  <TAB>  <TAB>  <TAB> self.stdout.write(msg.format(relfilename)) <TAB>  <TAB>  <TAB> elif options[""verbosity""]: <TAB>  <TAB>  <TAB>  <TAB> self.stdout.write(relfilename) <TAB> for child in child_dirs: <TAB>  <TAB> walk(os.path.join(prefix, child))",if not File . objects . filter ( file = relfilename ) . exists ( ) :,193
"def persistent_search_response_to_ldif(change): <TAB> ldif_lines = [""# "" + datetime.now().isoformat()] <TAB> control = decode_persistent_search_control(change) <TAB> if control: <TAB>  <TAB> if control[""changeNumber""]: <TAB>  <TAB>  <TAB> ldif_lines.append(""# change number: "" + str(control[""changeNumber""])) <TAB>  <TAB> ldif_lines.append(control[""changeType""]) <MASK> ldif_lines.append(""# previous dn: "" + str(control[""previousDN""])) <TAB> ldif_lines += operation_to_ldif(""searchResponse"", [change]) <TAB> return ldif_lines[:-1]  # removes ""total number of entries""","if control [ ""previousDN"" ] :",168
"def _get_metric_count(cls, metric, variant, next=True): <TAB> """"""Returns the next count number for the given metric/variant (rotates every few calls)"""""" <TAB> counters = cls._metric_counters <TAB> key = ""%s_%s"" % (metric, variant) <TAB> try: <TAB>  <TAB> cls._metric_counters_lock.acquire() <TAB>  <TAB> value = counters.get(key, -1) <MASK> value = counters[key] = value + 1 <TAB>  <TAB> return value <TAB> finally: <TAB>  <TAB> cls._metric_counters_lock.release()",if next :,137
"def from_cfn_params(self, cfn_params): <TAB> """"""Initialize param value by parsing CFN input only if the scheduler is a traditional one."""""" <TAB> cfn_converter = self.definition.get(""cfn_param_mapping"", None) <TAB> if cfn_converter and cfn_params: <MASK> self.value = float(get_cfn_param(cfn_params, cfn_converter)) <TAB> return self","if get_cfn_param ( cfn_params , ""Scheduler"" ) != ""awsbatch"" :",127
"def exclude_bracket(enabled, filter_type, language_list, language): <TAB> """"""Exclude or include brackets based on filter lists."""""" <TAB> exclude = True <TAB> if enabled: <TAB>  <TAB> # Black list languages <MASK> exclude = False <TAB>  <TAB>  <TAB> if language is not None: <TAB>  <TAB>  <TAB>  <TAB> for item in language_list: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if language == item.lower(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> exclude = True <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> # White list languages <TAB>  <TAB> elif filter_type == ""allowlist"": <TAB>  <TAB>  <TAB> if language is not None: <TAB>  <TAB>  <TAB>  <TAB> for item in language_list: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if language == item.lower(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> exclude = False <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return exclude","if filter_type == ""blocklist"" :",194
"def on_replace_text_changed(self, replace_text_entry): <TAB> if not self.enable_replace: <TAB>  <TAB> replace_text = replace_text_entry.get_text() <TAB>  <TAB> search_text = self._search_text_box.get_text() <MASK> self._replace_button.set_sensitive(True) <TAB>  <TAB>  <TAB> self._replace_all_button.set_sensitive(True) <TAB>  <TAB>  <TAB> self.enable_replace = True",if len ( search_text ) > 0 and len ( replace_text ) > 0 :,131
"def __getitem__(self, idx): <TAB> final_sample = {} <TAB> for dataset in self.datasets: <TAB>  <TAB> curr_sample = dataset[idx] <TAB>  <TAB> assert isinstance(curr_sample, dict), ""Merge dataset only supports dicts"" <TAB>  <TAB> for key in curr_sample.keys(): <TAB>  <TAB>  <TAB> # If keys are distinct, then <TAB>  <TAB>  <TAB> if key not in final_sample: <TAB>  <TAB>  <TAB>  <TAB> final_sample[key] = curr_sample[key] <MASK> final_sample[key] = [final_sample[key], curr_sample[key]] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> final_sample[key].append(curr_sample[key]) <TAB> return final_sample","elif not isinstance ( final_sample [ key ] , list ) :",180
"def raise_app(self, app): <TAB> app_zi = self.window_zindex[app.identifier] <TAB> for t in self.window_zindex.keys(): <TAB>  <TAB> w = self.window[t] <TAB>  <TAB> zi = self.window_zindex[t] <MASK> self.set_app_zindex(t, zi - 1) <TAB> app_zi = len(self.window) - 1 <TAB> self.set_app_zindex(app.identifier, app_zi)",if zi > app_zi :,128
"def get_tax(self, request, product=None): <TAB> """"""Returns the absolute tax of the voucher."""""" <TAB> price_gross = self.get_price_gross(request, product) <TAB> if self.tax: <TAB>  <TAB> return price_gross * (self.tax.rate / (100 + self.tax.rate)) <TAB> else: <MASK> return 0.0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> cart = lfs.cart.utils.get_cart(request) <TAB>  <TAB>  <TAB> return cart.get_tax(request) * (self.value / 100)",if self . type == DISCOUNT_TYPE_ABSOLUTE :,147
"def list_colls(self): <TAB> print(""Collections:"") <TAB> if not os.path.isdir(self.colls_dir): <TAB>  <TAB> msg = ( <TAB>  <TAB>  <TAB> '""Collections"" directory not found. ' <TAB>  <TAB>  <TAB> + ""To create a new collection, run:\n\n{0} init <name>"" <TAB>  <TAB> ) <TAB>  <TAB> raise IOError(msg.format(sys.argv[0])) <TAB> for d in os.listdir(self.colls_dir): <MASK> print(""- "" + d)","if os . path . isdir ( os . path . join ( self . colls_dir , d ) ) :",147
"def _format_arg(self, opt, spec, val): <TAB> if opt == ""num_cores"": <TAB>  <TAB> if self.inputs.parallelization == 2: <TAB>  <TAB>  <TAB> return ""-j "" + str(val) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return """" <TAB> if opt == ""in_files"": <MASK> start = ""-z "" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> start = """" <TAB>  <TAB> return start + "" "".join(name for name in val) <TAB> return super(buildtemplateparallel, self)._format_arg(opt, spec, val)",if self . inputs . use_first_as_target :,148
"def __assignNumericBookmark(node, numericBookmark): <TAB> with Gaffer.UndoScope(node.scriptNode()): <MASK> # Remove the current numeric bookmark from selection <TAB>  <TAB>  <TAB> current = Gaffer.MetadataAlgo.numericBookmark(node) <TAB>  <TAB>  <TAB> if current: <TAB>  <TAB>  <TAB>  <TAB> Gaffer.MetadataAlgo.setNumericBookmark(node.scriptNode(), current, None) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> Gaffer.MetadataAlgo.setNumericBookmark( <TAB>  <TAB>  <TAB>  <TAB> node.scriptNode(), numericBookmark, node <TAB>  <TAB>  <TAB> )",if numericBookmark == 0 :,145
"def add_act(ability_id, color, pos, timeout=1): <TAB> if ability_id: <TAB>  <TAB> ability = self._static_data.abilities[ability_id] <MASK> # Prefer general abilities. <TAB>  <TAB>  <TAB> ability_id = ability.remaps_to_ability_id <TAB> self._past_actions.append(PastAction(ability_id, color, pos, now, now + timeout))",if ability . remaps_to_ability_id :,110
"def _unc_columns(self, line): <TAB> cols = {} <TAB> current_col = u("""") <TAB> newcol = False <TAB> start, end = 0, 0 <TAB> for char in line: <TAB>  <TAB> if char.isalpha(): <MASK> cols[current_col.strip().lower()] = (start, end) <TAB>  <TAB>  <TAB>  <TAB> current_col = u("""") <TAB>  <TAB>  <TAB>  <TAB> start = end <TAB>  <TAB>  <TAB>  <TAB> newcol = False <TAB>  <TAB>  <TAB> current_col += u(char) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> newcol = True <TAB>  <TAB> end += 1 <TAB> if start != end and current_col: <TAB>  <TAB> cols[current_col.strip().lower()] = (start, -1) <TAB> return cols",if newcol :,177
"def _disk_merge_sorted(self, iters): <TAB> t = time.time() <TAB> s = AutoBatchedSerializer() <TAB> iters = iter(iters) <TAB> while True: <TAB>  <TAB> batch = list(islice(iters, 100)) <MASK> break <TAB>  <TAB> path = LocalFileShuffle.get_tmp() <TAB>  <TAB> with open(path, ""wb"") as f: <TAB>  <TAB>  <TAB> s.dump_stream(self._merge_sorted(batch), f) <TAB>  <TAB> self.paths.append(path) <TAB>  <TAB> env.task_stats.num_fetch_rotate += 1 <TAB> files = [s.load_stream(open(p)) for p in self.paths] <TAB> env.task_stats.secs_fetch = time.time() - t <TAB> return self._merge_sorted(files)",if not batch :,193
"def process_pr(pr): <TAB> lines = [pr[""title""]] <TAB> body = pr[""body""] <TAB> content = """" <TAB> search_result = re.search(r""\*\*History Notes\*\*(.*)---"", body, flags=re.DOTALL) <TAB> if search_result is None: <TAB>  <TAB> search_result = re.search(r""\*\*History Notes\*\*(.*)"", body, flags=re.DOTALL) <MASK> content = search_result.group(1) <TAB> else: <TAB>  <TAB> content = search_result.group(1) <TAB> if content: <TAB>  <TAB> lines.extend(content.splitlines()) <TAB> process_lines(lines, pr[""number""])",if search_result is not None :,168
"def _expand_number(m): <TAB> num = int(m.group(0)) <TAB> if num > 1000 and num < 3000: <MASK> return ""two thousand"" <TAB>  <TAB> elif num > 2000 and num < 2010: <TAB>  <TAB>  <TAB> return ""two thousand "" + _inflect.number_to_words(num % 100) <TAB>  <TAB> elif num % 100 == 0: <TAB>  <TAB>  <TAB> return _inflect.number_to_words(num // 100) + "" hundred"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return _inflect.number_to_words( <TAB>  <TAB>  <TAB>  <TAB> num, andword="""", zero=""oh"", group=2 <TAB>  <TAB>  <TAB> ).replace("", "", "" "") <TAB> else: <TAB>  <TAB> return _inflect.number_to_words(num, andword="""")",if num == 2000 :,192
"def convert_value(self, value, expression, connection, context): <TAB> if isinstance(self.output_field, DateTimeField): <TAB>  <TAB> if settings.USE_TZ: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Database returned an invalid datetime value. "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Are time zone definitions for your database installed?"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> value = value.replace(tzinfo=None) <TAB>  <TAB>  <TAB> value = timezone.make_aware(value, self.tzinfo) <TAB> elif isinstance(value, datetime): <TAB>  <TAB> if isinstance(self.output_field, DateField): <TAB>  <TAB>  <TAB> value = value.date() <TAB>  <TAB> elif isinstance(self.output_field, TimeField): <TAB>  <TAB>  <TAB> value = value.time() <TAB> return value",if value is None :,189
"def pretty_flags(flags): <TAB> """"""Return pretty representation of code flags."""""" <TAB> names = [] <TAB> for i in range(32): <TAB>  <TAB> flag = 1 << i <MASK> names.append(COMPILER_FLAG_NAMES.get(flag, hex(flag))) <TAB>  <TAB>  <TAB> flags ^= flag <TAB>  <TAB>  <TAB> if not flags: <TAB>  <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> names.append(hex(flags)) <TAB> return "", "".join(names)",if flags & flag :,117
"def run(self): <TAB> super().run() <TAB> if not self.dry_run: <TAB>  <TAB> for file in self.get_outputs(): <MASK> # this is the value distutils use on its shebang translation <TAB>  <TAB>  <TAB>  <TAB> bs_cmd = self.get_finalized_command(""build_scripts"") <TAB>  <TAB>  <TAB>  <TAB> exec_param = getattr(bs_cmd, ""executable"", None) <TAB>  <TAB>  <TAB>  <TAB> with open(file, ""r"") as f: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> content = f.read() <TAB>  <TAB>  <TAB>  <TAB> processed = content.replace("" python3 "", ' ""{}"" '.format(exec_param)) <TAB>  <TAB>  <TAB>  <TAB> with open(file, ""w"") as f: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f.write(processed)","if file . endswith ( ""xon.sh"" ) :",186
def _get_import_alias_names(import_aliases: Sequence[cst.ImportAlias]) -> Set[str]: <TAB> import_names = set() <TAB> for imported_name in import_aliases: <TAB>  <TAB> asname = imported_name.asname <MASK> import_names.add(get_full_name_for_node(asname.name)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> import_names.add(get_full_name_for_node(imported_name.name)) <TAB> return import_names,if asname is not None :,127
"def set_entity_group_associations( <TAB> self, groups=[], users=[], roles=[], delete_existing_assocs=True): <TAB> for group in groups: <TAB>  <TAB> if delete_existing_assocs: <TAB>  <TAB>  <TAB> flush_needed = False <TAB>  <TAB>  <TAB> for a in group.roles + group.users: <TAB>  <TAB>  <TAB>  <TAB> self.sa_session.delete(a) <TAB>  <TAB>  <TAB>  <TAB> flush_needed = True <MASK> self.sa_session.flush() <TAB>  <TAB> for role in roles: <TAB>  <TAB>  <TAB> self.associate_components(group=group, role=role) <TAB>  <TAB> for user in users: <TAB>  <TAB>  <TAB> self.associate_components(group=group, user=user)",if flush_needed :,170
"def getNewFiles(oldContents, newContents, destinationFolder): <TAB> result = [] <TAB> for (filename, newTime) in list(newContents.items()): <TAB>  <TAB> destFile = os.path.join(destinationFolder, filename.lstrip(""/"")) <TAB>  <TAB> if not os.path.isfile(destFile): <TAB>  <TAB>  <TAB> result.append(filename) <TAB>  <TAB> elif filename in oldContents: <TAB>  <TAB>  <TAB> oldTime = oldContents[filename] <MASK> result.append(filename) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result.append(filename) <TAB> return result",if newTime > oldTime :,143
"def arrow_right(self): <TAB> """"""Move cursors right."""""" <TAB> for cursor in self.cursors: <TAB>  <TAB> line = self.lines[cursor.y] <TAB>  <TAB> # If we are at the end of the line <TAB>  <TAB> if cursor.x >= len(line) or len(line) == 0: <TAB>  <TAB>  <TAB> # If there is another line, then move down <MASK> cursor.move_down() <TAB>  <TAB>  <TAB>  <TAB> cursor.set_x(0) <TAB>  <TAB> # Otherwise, move the cursor right <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> cursor.move_right() <TAB> self.move_cursors() <TAB> self.scroll_down()",if cursor . y != len ( self . lines ) - 1 :,170
"def vtop(self, vaddr): <TAB> retVal = None <TAB> pdpe = self.get_pdpi(vaddr) <TAB> if not self.entry_present(pdpe): <TAB>  <TAB> return retVal <TAB> pgd = self.get_pgd(vaddr, pdpe) <TAB> if self.entry_present(pgd): <TAB>  <TAB> if self.page_size_flag(pgd): <TAB>  <TAB>  <TAB> retVal = self.get_large_paddr(vaddr, pgd) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pte = self.get_pte(vaddr, pgd) <MASK> retVal = self.get_paddr(vaddr, pte) <TAB> return retVal",if self . entry_present ( pte ) :,178
"def teardown(config_file, manager_path): <TAB> """"""Teardown a polyaxon deployment given a config file."""""" <TAB> config = read_deployment_config(config_file, command=""teardown"") <TAB> manager = DeployConfigManager( <TAB>  <TAB> config=config, filepath=config_file, manager_path=manager_path <TAB> ) <TAB> exception = None <TAB> try: <MASK> manager.teardown(hooks=True) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> manager.teardown(hooks=False) <TAB> except Exception as e: <TAB>  <TAB> Printer.print_error(""Polyaxon could not teardown the deployment."") <TAB>  <TAB> exception = e <TAB> if exception: <TAB>  <TAB> Printer.print_error(""Error message: {}."".format(exception))","if click . confirm ( ""Would you like to execute pre-delete hooks?"" , default = True ) :",189
"def _assert_grad_tensor_metric( <TAB> self, name: str, x: Union[torch.Tensor, Any], additional_err: str = """"): <TAB> if x is not None: <MASK> raise TypeError(f""{name} must be a torch.Tensor"") <TAB>  <TAB> m = f""{name} must have a computational graph."" <TAB>  <TAB> if additional_err: <TAB>  <TAB>  <TAB> m += f"" {additional_err}"" <TAB>  <TAB> assert x.grad_fn is not None, m","if not isinstance ( x , Tensor ) :",124
"def validate_storageaccount(cmd, namespace): <TAB> from azure.cli.core.commands.client_factory import get_subscription_id <TAB> from msrestazure.tools import is_valid_resource_id, resource_id <TAB> if namespace.storage_account_resource_id: <MASK> namespace.storage_account_resource_id = resource_id( <TAB>  <TAB>  <TAB>  <TAB> subscription=get_subscription_id(cmd.cli_ctx), <TAB>  <TAB>  <TAB>  <TAB> resource_group=namespace.resource_group_name, <TAB>  <TAB>  <TAB>  <TAB> namespace=""Microsoft.Storage"", <TAB>  <TAB>  <TAB>  <TAB> type=""storageAccounts"", <TAB>  <TAB>  <TAB>  <TAB> name=namespace.storage_account_resource_id, <TAB>  <TAB>  <TAB> )",if not is_valid_resource_id ( namespace . storage_account_resource_id ) :,189
"def get_many(self, keys): <TAB> with self.client_pool.get_and_release(destroy_on_fail=True) as client: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return client.get_many(keys) <TAB>  <TAB> except Exception: <MASK> return {} <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise",if self . ignore_exc :,90
"def on_bodykey1(tag, keywords): <TAB> c = keywords.get(""c"") <TAB> p = keywords.get(""p"") <TAB> if g.match_word(p.h, 0, ""@read-only""): <TAB>  <TAB> # The following code causes problems with scrolling and syntax coloring. <TAB>  <TAB> # Its advantage is that it makes clear that the text can't be changed, <TAB>  <TAB> # but perhaps that is obvious anyway... <MASK> # Davide Salomoni requests that this code be eliminated. <TAB>  <TAB>  <TAB> # An @read-only node: do not change its text. <TAB>  <TAB>  <TAB> w = c.frame.body.wrapper <TAB>  <TAB>  <TAB> w.delete(""1.0"", ""end"") <TAB>  <TAB>  <TAB> w.insert(""1.0"", p.b) <TAB>  <TAB> return 1  # Override the body key event handler.",if 0 :,196
"def validate_settings(self): <TAB> if self.enable_sync: <TAB>  <TAB> if not self.secret: <TAB>  <TAB>  <TAB> self.set(""secret"", frappe.generate_hash()) <MASK> frappe.throw(_(""Please enter Woocommerce Server URL"")) <TAB>  <TAB> if not self.api_consumer_key: <TAB>  <TAB>  <TAB> frappe.throw(_(""Please enter API Consumer Key"")) <TAB>  <TAB> if not self.api_consumer_secret: <TAB>  <TAB>  <TAB> frappe.throw(_(""Please enter API Consumer Secret""))",if not self . woocommerce_server_url :,139
"def _find_start_index(current, target_section, index=0): <TAB> if current == target_section: <TAB>  <TAB> return index, True <TAB> index += current.n <TAB> for child in current.children: <TAB>  <TAB> if child == target_section: <TAB>  <TAB>  <TAB> return index, True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> index, found = _find_start_index(child, target_section, index) <MASK> return index, True <TAB> return index, False",if found :,119
"def sort_as_subsets(tuples, allitems, deterministic_order=False): <TAB> edges = util.defaultdict(set) <TAB> for parent, child in tuples: <TAB>  <TAB> edges[child].add(parent) <TAB> Set = util.OrderedSet if deterministic_order else set <TAB> todo = Set(allitems) <TAB> while todo: <TAB>  <TAB> output = Set() <TAB>  <TAB> for node in todo: <TAB>  <TAB>  <TAB> if todo.isdisjoint(edges[node]): <TAB>  <TAB>  <TAB>  <TAB> output.add(node) <MASK> raise CircularDependencyError( <TAB>  <TAB>  <TAB>  <TAB> ""Circular dependency detected."", <TAB>  <TAB>  <TAB>  <TAB> find_cycles(tuples, allitems), <TAB>  <TAB>  <TAB>  <TAB> _gen_edges(edges), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> todo.difference_update(output) <TAB>  <TAB> yield output",if not output :,190
"def get_fieldsets(self, request, obj=None): <TAB> fieldsets = list(super().get_fieldsets(request, obj=obj)) <TAB> if obj: <TAB>  <TAB> fieldsets[0][1][""fields""] = [""username"", ""recognized"", ""password""] <TAB>  <TAB> fieldsets[3][1][""fields""] = [""date_joined"", ""last_login"", ""last_access""] <MASK> fieldsets.pop(2) <TAB> return fieldsets",if not obj . has_usable_password ( ) :,119
"def __getitem__(self, key): <TAB> if isinstance(key, six.string_types): <TAB>  <TAB> value = self._xxx_field_to_index.get(key) <MASK> raise KeyError(""no row field {!r}"".format(key)) <TAB>  <TAB> key = value <TAB> return self._xxx_values[key]",if value is None :,83
"def get_context_data(self, **kwargs): <TAB> context = super(MultiTableView, self).get_context_data(**kwargs) <TAB> tables = self.get_tables() <TAB> for name, table in tables.items(): <MASK> raise AttributeError( <TAB>  <TAB>  <TAB>  <TAB> ""%s has no data associated with it."" % table.__class__.__name__ <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> context[""%s_table"" % name] = table <TAB> return context",if table . data is None :,115
def deal_answers(self): <TAB> while not self.answers_queue.empty(): <TAB>  <TAB> answer = self.answers_queue.get() <MASK> continue <TAB>  <TAB> for item in answer: <TAB>  <TAB>  <TAB> record = str(item) <TAB>  <TAB>  <TAB> subdomains = self.match_subdomains(record) <TAB>  <TAB>  <TAB> self.subdomains.update(subdomains),if answer is None :,94
"def mJUNE( <TAB> self,): <TAB> try: <TAB>  <TAB> _type = JUNE <TAB>  <TAB> _channel = DEFAULT_CHANNEL <TAB>  <TAB> pass <TAB>  <TAB> self.match(""jun"") <TAB>  <TAB> alt17 = 2 <TAB>  <TAB> LA17_0 = self.input.LA(1) <TAB>  <TAB> if LA17_0 == 101: <TAB>  <TAB>  <TAB> alt17 = 1 <MASK> pass <TAB>  <TAB>  <TAB> self.match(101) <TAB>  <TAB> self._state.type = _type <TAB>  <TAB> self._state.channel = _channel <TAB> finally: <TAB>  <TAB> pass",if alt17 == 1 :,142
"def _set_http_extra_headers(): <TAB> if conf.headers: <TAB>  <TAB> conf.headers = ( <TAB>  <TAB>  <TAB> conf.headers.split(""\n"") <TAB>  <TAB>  <TAB> if ""\n"" in conf.headers <TAB>  <TAB>  <TAB> else conf.headers.split(""\\n"") <TAB>  <TAB> ) <TAB>  <TAB> for header_value in conf.headers: <MASK> continue <TAB>  <TAB>  <TAB> if header_value.count("":"") >= 1: <TAB>  <TAB>  <TAB>  <TAB> header, value = (_.lstrip() for _ in header_value.split("":"", 1)) <TAB>  <TAB>  <TAB>  <TAB> if header and value: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if header not in conf.http_headers: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> conf.http_headers[header] = value",if not header_value . strip ( ) :,178
"def _edit_files(self, files): <TAB> if len(files): <TAB>  <TAB> if self.prefs.edit_command_type == ""internal"": <TAB>  <TAB>  <TAB> for f in files: <TAB>  <TAB>  <TAB>  <TAB> self.emit(""create-diff"", (f,)) <MASK> cmd = self.prefs.get_gnome_editor_command(files) <TAB>  <TAB>  <TAB> os.spawnvp(os.P_NOWAIT, cmd[0], cmd) <TAB>  <TAB> elif self.prefs.edit_command_type == ""custom"": <TAB>  <TAB>  <TAB> cmd = self.prefs.get_custom_editor_command(files) <TAB>  <TAB>  <TAB> os.spawnvp(os.P_NOWAIT, cmd[0], cmd)","elif self . prefs . edit_command_type == ""gnome"" :",180
"def put(self, obj, block=True, timeout=None): <TAB> if not block: <TAB>  <TAB> return self.put_nowait() <TAB> start_time = time.time() <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self.put_nowait(obj) <TAB>  <TAB> except BaseQueue.Full: <TAB>  <TAB>  <TAB> if timeout: <TAB>  <TAB>  <TAB>  <TAB> lasted = time.time() - start_time <MASK> time.sleep(min(self.max_timeout, timeout - lasted)) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> time.sleep(self.max_timeout)",if timeout > lasted :,166
"def verifyDict(obj, sig, signame): <TAB> for att in obj: <TAB>  <TAB> if att not in sig.keys(): <TAB>  <TAB>  <TAB> raise Exception(""invalid attribute '%s' in %s"" % (att, signame)) <TAB> for key, (required, atypes) in sig.items(): <TAB>  <TAB> if required and not obj.has_key(key): <TAB>  <TAB>  <TAB> raise Exception(""missing mandatory %s attribute '%s'"" % (signame, key)) <MASK> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> ""invalid type '%s' for %s attribute '%s'"" <TAB>  <TAB>  <TAB>  <TAB> % (type(sig[key]), signame, key) <TAB>  <TAB>  <TAB> )",if obj . has_key ( key ) and type ( obj [ key ] ) not in atypes :,180
"def convert(self, value, program): <TAB> l = [] <TAB> for v in value: <TAB>  <TAB> boolean = Boolean(None) <TAB>  <TAB> status = boolean.convert(v.status, program) <MASK> l += status <TAB>  <TAB> l.append(v.value) <TAB>  <TAB> l.append(v.text) <TAB>  <TAB> if not self.status_first: <TAB>  <TAB>  <TAB> l += status <TAB> return l",if self . status_first :,107
"def find_nonterminal_transitions(self, C): <TAB> trans = [] <TAB> for stateno, state in enumerate(C): <TAB>  <TAB> for p in state: <MASK> t = (stateno, p.prod[p.lr_index + 1]) <TAB>  <TAB>  <TAB>  <TAB> if t[1] in self.grammar.Nonterminals: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if t not in trans: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> trans.append(t) <TAB> return trans",if p . lr_index < p . len - 1 :,123
"def get_all_sales_channels(): <TAB> global _ALL_CHANNELS <TAB> if _ALL_CHANNELS: <TAB>  <TAB> return _ALL_CHANNELS <TAB> types = OrderedDict() <TAB> for recv, ret in register_sales_channels.send(None): <MASK> for r in ret: <TAB>  <TAB>  <TAB>  <TAB> types[r.identifier] = r <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> types[ret.identifier] = ret <TAB> _ALL_CHANNELS = types <TAB> return types","if isinstance ( ret , ( list , tuple ) ) :",120
"def _filter_stateful_actuators(physics, actuator_names): <TAB> """"""Removes any stateless actuators from the list of actuator names."""""" <TAB> if physics.model.na: <TAB>  <TAB> # MuJoCo requires that stateful actuators always come after stateless <TAB>  <TAB> # actuators in the model, so we keep actuator names only if their <TAB>  <TAB> # corresponding IDs are >= to the total number of stateless actuators. <TAB>  <TAB> num_stateless_actuators = physics.model.nu - physics.model.na <TAB>  <TAB> return [ <TAB>  <TAB>  <TAB> name <TAB>  <TAB>  <TAB> for name in actuator_names <MASK> ] <TAB> else: <TAB>  <TAB> return []","if physics . model . name2id ( name , ""actuator"" ) >= num_stateless_actuators",194
"def get_volume_mapping(self, resources): <TAB> volume_map = {} <TAB> manager = self.manager.get_resource_manager(""ebs"") <TAB> for instance_set in utils.chunks(resources, 200): <TAB>  <TAB> volume_ids = [] <TAB>  <TAB> for i in instance_set: <TAB>  <TAB>  <TAB> for bd in i.get(""BlockDeviceMappings"", ()): <MASK> continue <TAB>  <TAB>  <TAB>  <TAB> volume_ids.append(bd[""Ebs""][""VolumeId""]) <TAB>  <TAB> for v in manager.get_resources(volume_ids): <TAB>  <TAB>  <TAB> if not v[""Attachments""]: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> volume_map.setdefault(v[""Attachments""][0][""InstanceId""], []).append(v) <TAB> return volume_map","if ""Ebs"" not in bd :",187
"def _read_thread(proc, ready_event): <TAB> """"""Thread to continuously read from the process stdout."""""" <TAB> ready = False <TAB> while True: <TAB>  <TAB> line = proc.stdout.readline() <MASK> break <TAB>  <TAB> if output_lines is not None: <TAB>  <TAB>  <TAB> output_lines.append(line) <TAB>  <TAB> if not ready and indicator in line: <TAB>  <TAB>  <TAB> ready = True <TAB>  <TAB>  <TAB> ready_event.set()",if not line :,110
"def unpack_list(self, unpack_item): <TAB> list = [] <TAB> while 1: <TAB>  <TAB> x = self.unpack_uint() <MASK> break <TAB>  <TAB> if x != 1: <TAB>  <TAB>  <TAB> raise ConversionError(""0 or 1 expected, got %r"" % (x,)) <TAB>  <TAB> item = unpack_item() <TAB>  <TAB> list.append(item) <TAB> return list",if x == 0 :,97
"def create_counters(counter_defs, records): <TAB> counters = {}  # indexed by thread id giving another dict of counters <TAB> for record in records: <TAB>  <TAB> thread_counters = counters.setdefault(record.thread_id, {}) <TAB>  <TAB> text = record.detail.strip() <TAB>  <TAB> for name, regex in counter_defs: <MASK> thread_counters[name] = thread_counters.get(name, 0) + 1 <TAB> return counters",if regex . match ( text ) :,115
"def _process_attributes(self, item, descriptor, htmlpage): <TAB> new_item = {} <TAB> try: <TAB>  <TAB> attr_map = descriptor.attribute_map <TAB> except AttributeError: <TAB>  <TAB> attr_map = {} <TAB> page = getattr(htmlpage, ""htmlpage"", htmlpage) <TAB> for field, value in item.items(): <TAB>  <TAB> if field.startswith(""_sticky""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if field == ""variants"": <TAB>  <TAB>  <TAB> value = [self._process_attributes(v, descriptor, page) for v in value] <MASK> value = [attr_map[field].adapt(v, page) for v in value] <TAB>  <TAB> new_item[field] = value <TAB> return new_item",elif field in attr_map :,176
"def heatup(p, temp, s=0): <TAB> curtemp = gettemp(p) <TAB> p.send_now(""M109 S%03d"" % temp) <TAB> p.temp = 0 <TAB> if not s: <TAB>  <TAB> w(""Heating extruder up.."") <TAB> f = False <TAB> while curtemp <= (temp - 1): <TAB>  <TAB> p.send_now(""M105"") <TAB>  <TAB> time.sleep(0.5) <MASK> time.sleep(1.5) <TAB>  <TAB>  <TAB> f = True <TAB>  <TAB> curtemp = gettemp(p) <TAB>  <TAB> if curtemp: <TAB>  <TAB>  <TAB> w(""\rHeating extruder up.. %3d \xb0C"" % curtemp) <TAB> if s: <TAB>  <TAB> print() <TAB> else: <TAB>  <TAB> print(""\nReady."")",if not f :,198
"def run_with_num_hosts(self, num_hosts): <TAB> arbiter, guest, *hosts = self.run_results(num_hosts=num_hosts) <TAB> for i in range(len(hosts)): <MASK> self.assertEqual(hosts[i][0], arbiter[0][i]) <TAB>  <TAB>  <TAB> final_decrypted = arbiter[1][i].decrypt_list(hosts[i][2]) <TAB>  <TAB>  <TAB> init_w = hosts[i][1] <TAB>  <TAB>  <TAB> for j in range(len(final_decrypted)): <TAB>  <TAB>  <TAB>  <TAB> self.assertAlmostEqual(init_w[j], final_decrypted[j])",if hosts [ i ] is not None :,162
"def reload_modules(self, *modules): <TAB> """"""[UNIT]... -- reload these units"""""" <TAB> found_all = True <TAB> units = [] <TAB> for module in modules: <TAB>  <TAB> matched = self.match_units([module]) <TAB>  <TAB> if not matched: <TAB>  <TAB>  <TAB> logg.error(""no such service '%s'"", module) <TAB>  <TAB>  <TAB> found_all = False <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for unit in matched: <MASK> units += [unit] <TAB> return self.reload_units(units) and found_all",if unit not in units :,136
"def _sanitize_callable(val): <TAB> # Give them one chance to return a value. Don't go rabbit hole of recursive call <TAB> if isinstance(val, Callable): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> _val = val() <MASK> return val.__name__ <TAB>  <TAB>  <TAB> return _val <TAB>  <TAB> # todo: specify the possible exception <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> return getattr(val, ""__name__"", None) <TAB> return val","if isinstance ( _val , Callable ) :",115
"def env(**kwargs): <TAB> """"""Context manager to alter and restore system environment."""""" <TAB> prev = os.environ.copy() <TAB> for k, v in kwargs.items(): <TAB>  <TAB> if v is None: <MASK> del os.environ[k] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if isinstance(v, unicode): <TAB>  <TAB>  <TAB>  <TAB> v = v.encode(""utf-8"") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> v = str(v) <TAB>  <TAB>  <TAB> os.environ[k] = v <TAB> yield <TAB> os.environ = prev",if k in os . environ :,140
"def remove_shipping_charge(self): <TAB> if self.shipping_rule: <TAB>  <TAB> shipping_rule = frappe.get_doc(""Shipping Rule"", self.shipping_rule) <TAB>  <TAB> existing_shipping_charge = self.get( <TAB>  <TAB>  <TAB> ""taxes"", <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB> ""doctype"": ""Sales Taxes and Charges"", <TAB>  <TAB>  <TAB>  <TAB> ""charge_type"": ""Actual"", <TAB>  <TAB>  <TAB>  <TAB> ""account_head"": shipping_rule.account, <TAB>  <TAB>  <TAB>  <TAB> ""cost_center"": shipping_rule.cost_center, <TAB>  <TAB>  <TAB> }, <TAB>  <TAB> ) <MASK> self.get(""taxes"").remove(existing_shipping_charge[-1]) <TAB>  <TAB>  <TAB> self.calculate_taxes_and_totals()",if existing_shipping_charge :,186
"def parse_xml(clazz, config_xml): <TAB> extra_dirs = [] <TAB> config_dict = {} <TAB> if config_xml is not None: <TAB>  <TAB> store_by = config_xml.attrib.get(""store_by"", None) <MASK> config_dict[""store_by""] = store_by <TAB>  <TAB> for e in config_xml: <TAB>  <TAB>  <TAB> if e.tag == ""files_dir"": <TAB>  <TAB>  <TAB>  <TAB> config_dict[""files_dir""] = e.get(""path"") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> extra_dirs.append({""type"": e.get(""type""), ""path"": e.get(""path"")}) <TAB> config_dict[""extra_dirs""] = extra_dirs <TAB> return config_dict",if store_by is not None :,183
"def update_nexusport_binding(port_id, new_vlan_id): <TAB> """"""Updates nexusport binding"""""" <TAB> LOG.debug(""update_nexusport_binding called"") <TAB> session = db.get_session() <TAB> try: <TAB>  <TAB> binding = ( <TAB>  <TAB>  <TAB> session.query(nexus_models.NexusPortBinding) <TAB>  <TAB>  <TAB> .filter_by(port_id=port_id) <TAB>  <TAB>  <TAB> .one() <TAB>  <TAB> ) <MASK> binding[""vlan_id""] = new_vlan_id <TAB>  <TAB> session.merge(binding) <TAB>  <TAB> session.flush() <TAB>  <TAB> return binding <TAB> except exc.NoResultFound: <TAB>  <TAB> raise c_exc.NexusPortBindingNotFound()",if new_vlan_id :,188
"def enter_Field(self, node, key, parent, path, ancestors): <TAB> type = self.context.get_type() <TAB> if not type: <TAB>  <TAB> return <TAB> if is_leaf_type(get_named_type(type)): <MASK> self.context.report_error( <TAB>  <TAB>  <TAB>  <TAB> GraphQLError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.no_subselection_allowed_message(node.name.value, type), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> [node.selection_set], <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> elif not node.selection_set: <TAB>  <TAB> self.context.report_error( <TAB>  <TAB>  <TAB> GraphQLError( <TAB>  <TAB>  <TAB>  <TAB> self.required_subselection_message(node.name.value, type), [node] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> )",if node . selection_set :,196
"def getProcessFromName(pnames, id_only=False): <TAB> procs = [] <TAB> if isinstance(pnames, basestring): <TAB>  <TAB> pnames = [ <TAB>  <TAB>  <TAB> pnames, <TAB>  <TAB> ] <TAB> for p in psutil.process_iter(): <MASK> if id_only: <TAB>  <TAB>  <TAB>  <TAB> procs.append(p.pid) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> procs.append(p) <TAB> return procs",if p . name ( ) in pnames :,115
"def _float_to_int(api: CheckerPluginInterface, typ: Type) -> Type: <TAB> if isinstance(typ, Instance): <TAB>  <TAB> if typ.type.fullname == ""builtins.float"": <TAB>  <TAB>  <TAB> return api.named_generic_type(""builtins.int"", []) <MASK> return typ.copy_modified(args=[_float_to_int(api, t) for t in typ.args]) <TAB> return typ",elif typ . args :,104
"def getstr(self, begin, end): <TAB> r = """" <TAB> for i in viml_range(begin.i, end.i - 1): <TAB>  <TAB> if i >= viml_len(self.buf): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> c = self.buf[i] <MASK> c = ""\n"" <TAB>  <TAB> r += c <TAB> return r","if c == ""<EOL>"" :",95
"def get_server(self): <TAB> ""Better than monkeypatching for now; merge into Server ultimately"" <TAB> if self._state.value != State.INITIAL: <MASK> raise ProcessError(""Already started SharedMemoryServer"") <TAB>  <TAB> elif self._state.value == State.SHUTDOWN: <TAB>  <TAB>  <TAB> raise ProcessError(""SharedMemoryManager has shut down"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ProcessError(""Unknown state {!r}"".format(self._state.value)) <TAB> return self._Server(self._registry, self._address, self._authkey, self._serializer)",if self . _state . value == State . STARTED :,145
"def pretty_print_xml(elem, level=0): <TAB> pad = "" <TAB> "" <TAB> i = ""\n"" + level * pad <TAB> if len(elem): <MASK> elem.text = i + pad + pad <TAB>  <TAB> if not elem.tail or not elem.tail.strip(): <TAB>  <TAB>  <TAB> elem.tail = i <TAB>  <TAB> for e in elem: <TAB>  <TAB>  <TAB> pretty_print_xml(e, level + 1) <TAB>  <TAB> if not elem.tail or not elem.tail.strip(): <TAB>  <TAB>  <TAB> elem.tail = i <TAB> else: <TAB>  <TAB> if level and (not elem.tail or not elem.tail.strip()): <TAB>  <TAB>  <TAB> elem.tail = i + pad <TAB> return elem",if not elem . text or not elem . text . strip ( ) :,182
"def _process_bfs(self): <TAB> self.putc([ANN_BFS, [""Bit Field Set"", ""BFS""]]) <TAB> if len(self.mosi) != 2: <TAB>  <TAB> self._put_command_warning(""Invalid command length."") <TAB>  <TAB> return <TAB> self._put_register_header() <TAB> self._put_data_byte(self.mosi[1], 1, True) <TAB> if self.mosi[0] & REG_ADDR_MASK == REG_ADDR_ECON1: <TAB>  <TAB> if self.mosi[1] & BIT_ECON1_BSEL0: <TAB>  <TAB>  <TAB> self.bsel0 = 1 <MASK> self.bsel1 = 1",if self . mosi [ 1 ] & BIT_ECON1_BSEL1 :,187
"def GetHotkey(self): <TAB> result = self.SendMessage(self.Hwnd, self.Msg.HKM_GETHOTKEY, 0, 0) <TAB> if result: <TAB>  <TAB> fMod = HIBYTE(result) <TAB>  <TAB> out = [ <TAB>  <TAB>  <TAB> LOBYTE(result), <TAB>  <TAB> ] <TAB>  <TAB> for name, value in MODKEYS.items(): <MASK> out.append(name) <TAB>  <TAB> return out",if fMod & value :,117
"def __enter__(self): <TAB> with self.connection_lock: <TAB>  <TAB> self._context_state.append( <TAB>  <TAB>  <TAB> (self.bound, self.closed) <TAB>  <TAB> )  # save status out of context as a tuple in a list <TAB>  <TAB> if self.auto_bind != AUTO_BIND_NONE: <TAB>  <TAB>  <TAB> if self.auto_bind == AUTO_BIND_DEFAULT: <TAB>  <TAB>  <TAB>  <TAB> self.auto_bind = AUTO_BIND_NO_TLS <TAB>  <TAB>  <TAB> if self.closed: <TAB>  <TAB>  <TAB>  <TAB> self.open() <TAB>  <TAB>  <TAB> if not self.bound: <MASK> raise LDAPBindError(""unable to bind"") <TAB>  <TAB> return self",if not self . bind ( ) :,169
"def update_buttons(self): <TAB> for i in range(len(self.clipboard_history)): <TAB>  <TAB> info = self.clipboard_history[i] <MASK> button = self.buttons[i] <TAB>  <TAB>  <TAB> if info.text: <TAB>  <TAB>  <TAB>  <TAB> button.set_label("" "".join(info.text[:16].split(""\n""))) <TAB>  <TAB>  <TAB> if info.targets: <TAB>  <TAB>  <TAB>  <TAB> # put target info in button tootip <TAB>  <TAB>  <TAB>  <TAB> self.button_tips.set_tip(button, info.targets) <TAB> return",if info :,135
"def parse(self, input): <TAB> if isinstance(input, basestring): <TAB>  <TAB> # Gaupol does not allow parsing from strings <MASK> tmpfile, tmpfilename = tempfile.mkstemp(suffix=self.filename) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tmpfile, tmpfilename = tempfile.mkstemp() <TAB>  <TAB> tmpfile = open(tmpfilename, ""w"") <TAB>  <TAB> tmpfile.write(input) <TAB>  <TAB> tmpfile.close() <TAB>  <TAB> self._parsefile(tmpfilename) <TAB>  <TAB> os.remove(tmpfilename) <TAB> else: <TAB>  <TAB> self._parsefile(input)",if self . filename :,140
"def dump(self, not_none=True): <TAB> """""" """""" <TAB> with self._write_lock: <TAB>  <TAB> res = {} <TAB>  <TAB> for key in self: <MASK> if isinstance(self[key], Transactional): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> res[key] = self[key].dump() <TAB>  <TAB>  <TAB>  <TAB> elif isinstance(self[key], LinkedSet): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> res[key] = tuple(self[key]) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> res[key] = self[key] <TAB>  <TAB> return res","if self [ key ] is not None and key [ 0 ] != ""_"" :",150
"def _find_keygrip(gpg2_output, type_re): <TAB> lines = gpg2_output.split(""\n"") <TAB> for i, line in enumerate(lines): <TAB>  <TAB> if re.match(r"".*\[%s\]$"" % type_re, line): <TAB>  <TAB>  <TAB> for keygrip_line in lines[i + 1 :]: <TAB>  <TAB>  <TAB>  <TAB> m = re.match(r"" +Keygrip = ([A-Z0-9]{40})"", keygrip_line) <MASK> return m.group(1)",if m :,138
"def f(child_conn): <TAB> ctrl_command = b"""" <TAB> while ctrl_command != b""stop"": <TAB>  <TAB> child_conn.send_bytes(bytearray([1, 2, 3, 4, 5])) <TAB>  <TAB> time.sleep(0.1) <MASK> ctrl_command = child_conn.recv_bytes() <TAB>  <TAB>  <TAB> print(""Got from server"", ctrl_command) <TAB> print(""Stopping...."") <TAB> child_conn.send(""goodbye"") <TAB> child_conn.close()",if child_conn . poll ( ) :,127
"def get_list_display_links(self, list_display_links): <TAB> if self.actions: <MASK> return list(self.admin_view.list_display[1:2]) <TAB> return list_display_links","if len ( list_display_links ) == 1 and list_display_links [ 0 ] == ""action_checkbox"" :",83
"def add_route(self, route): <TAB> if route.rule.startswith(self.api_root): <TAB>  <TAB> path, path_vars = self.bottle_path_to_openapi(route.rule) <TAB>  <TAB> self.api_map[path][route.method.lower()] = route.callback <TAB>  <TAB> self.funcs[route.callback][""path""] = (path,) <TAB>  <TAB> self.funcs[route.callback][""path_params""] = self.make_params(path_vars, ""path"") <MASK> self.funcs[route.callback][""tags""] = [self.curr_tag]",if self . curr_tag :,149
"def SeekToNode(node1, child2): <TAB> # A text node does not have properties. <TAB> if child2.nodeType == Node.TEXT_NODE: <TAB>  <TAB> return None <TAB> # Get the name of the current node. <TAB> current_name = child2.getAttribute(""Name"") <TAB> if not current_name: <TAB>  <TAB> # There is no name. We don't know how to merge. <TAB>  <TAB> return None <TAB> # Look through all the nodes to find a match. <TAB> for sub_node in node1.childNodes: <TAB>  <TAB> if sub_node.nodeName == child2.nodeName: <TAB>  <TAB>  <TAB> name = sub_node.getAttribute(""Name"") <MASK> return sub_node <TAB> # No match. We give up. <TAB> return None",if name == current_name :,190
"def _get(self, url, params=None): <TAB> url, params = self._make_url(url, params) <TAB> num_tries = 0 <TAB> while 1: <TAB>  <TAB> response = urllib.request.urlopen(""%s?%s"" % (url, params)) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> out = json.loads(response.read()) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> except ValueError as msg: <MASK> raise <TAB>  <TAB>  <TAB> time.sleep(3) <TAB>  <TAB>  <TAB> num_tries += 1 <TAB> return out",if num_tries > self . _max_tries :,138
"def can_access_job(self, trans, job): <TAB> if job: <MASK> galaxy_session = trans.get_galaxy_session() <TAB>  <TAB>  <TAB> if galaxy_session is None or job.session_id != galaxy_session.id: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> elif job.user != trans.user: <TAB>  <TAB>  <TAB> return False <TAB> else: <TAB>  <TAB> return False <TAB> return True",if trans . user is None :,114
"def open_if_satisfies(self, cell): <TAB> if self.count_flags == cell.count: <MASK> self.show_all_bombs(self.bomb_explodes_on) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.open_neighboring_cells(cell)",if self . bomb_explodes_on :,84
"def process(value): <TAB> if value is None: <TAB>  <TAB> return None <TAB> cls = value.__class__ <TAB> kwargs = {} <TAB> for column in self.columns: <MASK> kwargs[column.name] = column.type.process_result_value( <TAB>  <TAB>  <TAB>  <TAB> getattr(value, column.name), dialect <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> kwargs[column.name] = getattr(value, column.name) <TAB> return cls(**kwargs)","if isinstance ( column . type , TypeDecorator ) :",124
"def _convertFolder(folderData, parent): <TAB> f = model.Folder("""") <TAB> f.inject_json_data(folderData) <TAB> f.parent = parent <TAB> f.persist() <TAB> for subfolder in folderData[""folders""]: <TAB>  <TAB> _convertFolder(subfolder, f) <TAB> for itemData in folderData[""items""]: <TAB>  <TAB> i = None <TAB>  <TAB> if itemData[""type""] == ""script"": <TAB>  <TAB>  <TAB> i = model.Script("""", """") <TAB>  <TAB>  <TAB> i.code = itemData[""code""] <TAB>  <TAB> elif itemData[""type""] == ""phrase"": <TAB>  <TAB>  <TAB> i = model.Phrase("""", """") <TAB>  <TAB>  <TAB> i.phrase = itemData[""phrase""] <MASK> i.inject_json_data(itemData) <TAB>  <TAB>  <TAB> i.parent = f <TAB>  <TAB>  <TAB> i.persist()",if i is not None :,200
"def reader(): <TAB> with open(file_list) as flist: <TAB>  <TAB> full_lines = [line.strip() for line in flist] <TAB>  <TAB> if shuffle: <TAB>  <TAB>  <TAB> np.random.shuffle(full_lines) <TAB>  <TAB> lines = full_lines <TAB>  <TAB> for line in lines: <TAB>  <TAB>  <TAB> img_path, label = line.split() <TAB>  <TAB>  <TAB> img_path = os.path.join(data_dir, img_path) <MASK> continue <TAB>  <TAB>  <TAB> yield img_path, int(label)",if not os . path . exists ( img_path ) :,142
"def get_systems(repo, issues): <TAB> systems = OrderedDict() <TAB> # get all systems and mark them as operational <TAB> for name in sorted(iter_systems(labels=repo.get_labels())): <TAB>  <TAB> systems[name] = { <TAB>  <TAB>  <TAB> ""status"": ""operational"", <TAB>  <TAB> } <TAB> for issue in issues: <MASK> labels = issue.get_labels() <TAB>  <TAB>  <TAB> severity = get_severity(labels) <TAB>  <TAB>  <TAB> affected_systems = list(iter_systems(labels)) <TAB>  <TAB>  <TAB> # shit is hitting the fan RIGHT NOW. Mark all affected systems <TAB>  <TAB>  <TAB> for affected_system in affected_systems: <TAB>  <TAB>  <TAB>  <TAB> systems[affected_system][""status""] = severity <TAB> return systems","if issue . state == ""open"" :",180
"def wrapper(*args, **kwargs): <TAB> now = datetime.now() <TAB> time_since_last_call = now - self.time_of_last_call <TAB> with self.lock: <MASK> self.first = False <TAB>  <TAB>  <TAB> self.time_of_last_call = now <TAB>  <TAB>  <TAB> self.cached_return = fn(*args, **kwargs) <TAB> return self.cached_return",if time_since_last_call > self . refresh_period or self . first :,116
"def GetSetIndexBinder(self, info): <TAB> with self._lock: <MASK> return self._setIndexBinders[info] <TAB>  <TAB> b = runtime.SymplSetIndexBinder(info) <TAB>  <TAB> self._setIndexBinders[info] = b <TAB> return b",if self . _setIndexBinders . ContainsKey ( info ) :,83
"def add(self, res, rev, valstats, env): <TAB> # assume perf always outputs the same <TAB> if self.rev: <TAB>  <TAB> assert rev == self.rev <TAB> for j in res.keys(): <MASK> self.res[j] = res[j] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.res[j] = [a + b for a, b in zip(self.res[j], res[j])] <TAB> self.rev = rev <TAB> for j in valstats.keys(): <TAB>  <TAB> self.valstats[j] = self.valstats[j] + valstats[j] <TAB> for j in env.keys(): <TAB>  <TAB> self.env[j] += env[j]",if len ( self . res [ j ] ) == 0 :,180
def __iter__(self): <TAB> with self._guard: <TAB>  <TAB> for dp in self._inf_iter: <TAB>  <TAB>  <TAB> self._iter_cnt = (self._iter_cnt + 1) % self.shuffle_interval <TAB>  <TAB>  <TAB> # fill queue <MASK> self.rng.shuffle(self.q) <TAB>  <TAB>  <TAB> for _ in range(self.num_reuse): <TAB>  <TAB>  <TAB>  <TAB> if self.q.maxlen == len(self.q): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield self.q.popleft() <TAB>  <TAB>  <TAB>  <TAB> self.q.append(dp),if self . _iter_cnt == 0 :,145
"def _add_timeout(self, _, exc=None, **kw): <TAB> if not self.closed: <TAB>  <TAB> self._cancel_timeout(_, exc=exc) <MASK> self._timeout_handler = self._loop.call_later( <TAB>  <TAB>  <TAB>  <TAB> self._timeout, self._timed_out <TAB>  <TAB>  <TAB> )",if self . _timeout and not exc :,87
"def _resolve(self): <TAB> if self._resolved: <TAB>  <TAB> return <TAB> self._operations_groups_value = {} <TAB> for operation_group_name, operation_type in self._client_type.__dict__.items(): <MASK> continue <TAB>  <TAB> value_to_save = self._sdk_profile.profile.get( <TAB>  <TAB>  <TAB> operation_group_name, self._sdk_profile.default_api_version <TAB>  <TAB> ) <TAB>  <TAB> self._operations_groups_value[operation_group_name] = self._post_process( <TAB>  <TAB>  <TAB> value_to_save <TAB>  <TAB> ) <TAB> self._resolved = True","if not isinstance ( operation_type , property ) :",158
"def __init__(self, *args, **kwargs): <TAB> self._datastore = dict() <TAB> self.prohibited_attrs = set(dir(self)) <TAB> self.prohibited_attrs.update(dir(self._datastore)) <TAB> for candidate in kwargs.keys(): <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""kwarg '{kwarg}' is already an attribute "" <TAB>  <TAB>  <TAB>  <TAB> ""of {datastore} or {obj}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> kwarg=candidate, datastore=type(self._datastore), obj=type(self) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> self.update(dict(*args, **kwargs))",if candidate in self . prohibited_attrs :,159
"def _gen_filter_tuples(): <TAB> """"""Bootstrap function to figure out what filters are available."""""" <TAB> dec = [] <TAB> enc = [] <TAB> for name, code in _COMP_FILTERS.items(): <TAB>  <TAB> if h5z.filter_avail(code): <TAB>  <TAB>  <TAB> info = h5z.get_filter_info(code) <MASK> enc.append(name) <TAB>  <TAB>  <TAB> if info & h5z.FILTER_CONFIG_DECODE_ENABLED: <TAB>  <TAB>  <TAB>  <TAB> dec.append(name) <TAB> return tuple(dec), tuple(enc)",if info & h5z . FILTER_CONFIG_ENCODE_ENABLED :,151
"def _smartLink(source, target, env, for_signature, defaultLinker=linkcom, dc=dc): <TAB> if isD(source): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> libs = env[""LIBS""] <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> libs = [] <MASK> if dc is ""dmd"": <TAB>  <TAB>  <TAB>  <TAB> env.Append(LIBS=[""phobos""]) <TAB>  <TAB>  <TAB> elif dc is ""gdmd"": <TAB>  <TAB>  <TAB>  <TAB> env.Append(LIBS=[""gphobos""]) <TAB>  <TAB> if ""pthread"" not in libs: <TAB>  <TAB>  <TAB> env.Append(LIBS=[""pthread""]) <TAB>  <TAB> if ""m"" not in libs: <TAB>  <TAB>  <TAB> env.Append(LIBS=[""m""]) <TAB> return defaultLinker","if ""phobos"" not in libs and ""gphobos"" not in libs :",194
"def scan_resource_conf(self, conf): <TAB> if ""extended_auditing_policy"" in conf: <TAB>  <TAB> policy = conf[""extended_auditing_policy""][0] <TAB>  <TAB> if not isinstance(policy, dict): <TAB>  <TAB>  <TAB> return CheckResult.UNKNOWN <TAB>  <TAB> retention = force_int( <TAB>  <TAB>  <TAB> conf[""extended_auditing_policy""][0][""retention_in_days""][0] <TAB>  <TAB> ) <MASK> return CheckResult.PASSED <TAB> return CheckResult.FAILED",if retention and retention >= 90 :,128
"def run(self): <TAB> """"""Called automatically when the thread is created."""""" <TAB> global Encoding <TAB> if not self.File: <TAB>  <TAB> return <TAB> s = self.File.readline() <TAB> while s: <MASK> self.TextLock.acquire() <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> self.Text = self.Text + g.ue(s, Encoding) <TAB>  <TAB>  <TAB> except IOError as ioerr: <TAB>  <TAB>  <TAB>  <TAB> self.Text = self.Text + ""\n"" + ""[@run] ioerror :"" + str(ioerr) <TAB>  <TAB>  <TAB> self.TextLock.release() <TAB>  <TAB> s = self.File.readline() <TAB>  <TAB> time.sleep(0.01)","if s != ""\n"" :",168
"def __init__(self, items=()): <TAB> # Using _dictEntries instead of directly assigning to self is about <TAB> # twice as fast. Please do careful performance testing before changing <TAB> # anything here. <TAB> _dictEntries = [] <TAB> for name, value in items: <MASK> for item in name: <TAB>  <TAB>  <TAB>  <TAB> _dictEntries.append((item, value)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _dictEntries.append((name, value)) <TAB> dict.__init__(self, _dictEntries) <TAB> self.default = None","if type ( name ) in ( list , tuple , frozenset , set ) :",140
"def wait(conn): <TAB> while 1: <TAB>  <TAB> state = conn.poll() <TAB>  <TAB> if state == psycopg2.extensions.POLL_OK: <TAB>  <TAB>  <TAB> break <MASK> select.select([], [conn.fileno()], []) <TAB>  <TAB> elif state == psycopg2.extensions.POLL_READ: <TAB>  <TAB>  <TAB> select.select([conn.fileno()], [], []) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise psycopg2.OperationalError( <TAB>  <TAB>  <TAB>  <TAB> ""poll() returned %s from _wait function"" % state <TAB>  <TAB>  <TAB> )",elif state == psycopg2 . extensions . POLL_WRITE :,136
"def cpu_count(output=None): <TAB> try: <TAB>  <TAB> env_cpu_count = os.getenv(""CONAN_CPU_COUNT"", None) <TAB>  <TAB> if env_cpu_count is not None and not env_cpu_count.isdigit(): <TAB>  <TAB>  <TAB> raise ConanException( <TAB>  <TAB>  <TAB>  <TAB> ""Invalid CONAN_CPU_COUNT value '%s', "" <TAB>  <TAB>  <TAB>  <TAB> ""please specify a positive integer"" % env_cpu_count <TAB>  <TAB>  <TAB> ) <MASK> return int(env_cpu_count) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return CpuProperties().get_cpus() <TAB> except NotImplementedError: <TAB>  <TAB> output.warn(""multiprocessing.cpu_count() not implemented. Defaulting to 1 cpu"") <TAB> return 1  # Safe guess",if env_cpu_count :,184
"def get_kubernetes_secret_hashes( <TAB> environment_variables: Mapping[str, str], service: str) -> Mapping[str, str]: <TAB> hashes = {} <TAB> to_get_hash = [] <TAB> for v in environment_variables.values(): <MASK> to_get_hash.append(v) <TAB> if to_get_hash: <TAB>  <TAB> kube_client = KubeClient() <TAB>  <TAB> for value in to_get_hash: <TAB>  <TAB>  <TAB> hashes[value] = get_kubernetes_secret_signature( <TAB>  <TAB>  <TAB>  <TAB> kube_client=kube_client, <TAB>  <TAB>  <TAB>  <TAB> secret=get_secret_name_from_ref(value), <TAB>  <TAB>  <TAB>  <TAB> service=SHARED_SECRET_SERVICE if is_shared_secret(value) else service, <TAB>  <TAB>  <TAB> ) <TAB> return hashes",if is_secret_ref ( v ) :,198
"def _get_provider_methods(provider_class): <TAB> try: <TAB>  <TAB> provider_module_name, obj_name = provider_class.rsplit(""."", 1) <TAB>  <TAB> provider_module = importlib.import_module(provider_module_name) <TAB>  <TAB> provider = getattr(provider_module, obj_name, None) <TAB> except (ModuleNotFoundError, AttributeError): <TAB>  <TAB> return """" <TAB> else: <TAB>  <TAB> return "", "".join( <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB> name <TAB>  <TAB>  <TAB>  <TAB> for name, method in inspect.getmembers(provider, inspect.isfunction) <MASK> ] <TAB>  <TAB> )","if not name . startswith ( ""_"" ) and name not in BASE_PROVIDER_METHOD_NAMES",162
"def add_field_attrs(self, attr_dict, name, cls): <TAB> if self.field_name_attr: <TAB>  <TAB> self.add_html_attr(self.field_name_attr, attr_dict, name) <TAB> if self.field_type_name_attr: <TAB>  <TAB> types = set() <TAB>  <TAB> c = cls <TAB>  <TAB> while c is not None: <MASK> types.add(c.get_type_name()) <TAB>  <TAB>  <TAB> c = c.__extends__ <TAB>  <TAB> self.add_html_attr(self.field_type_name_attr, attr_dict, "" "".join(types))",if c . Attributes . _explicit_type_name or c . __extends__ is None :,171
"def useIFD(self, ifd): <TAB> for field in ifd: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> attrname = self.key_to_attr[field.name] <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> value = field[""value""].value <TAB>  <TAB> setattr(self, attrname, value)","if ""value"" not in field :",91
"def wait_until_start(): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> results = urlopen(EXAMPLE_APP) <MASK> raise Exception(""%s returned unexpected 404"" % EXAMPLE_APP) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> except IOError: <TAB>  <TAB>  <TAB> pass",if results . code == 404 :,75
"def check_p4a_sign_env(self, error=False): <TAB> keys = [""KEYALIAS"", ""KEYSTORE_PASSWD"", ""KEYSTORE"", ""KEYALIAS_PASSWD""] <TAB> check = True <TAB> for key in keys: <TAB>  <TAB> key = ""P4A_RELEASE_{}"".format(key) <MASK> if error: <TAB>  <TAB>  <TAB>  <TAB> self.buildozer.error( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Asking for release but {} is missing"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""--sign will not be passed"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ).format(key) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> check = False <TAB> return check",if key not in os . environ :,171
"def assert_none(obj, msg=None, values=True): <TAB> """"""Fail the test if given object is not None."""""" <TAB> _msg = ""%r is not None"" % obj <TAB> if obj is not None: <TAB>  <TAB> if msg is None: <TAB>  <TAB>  <TAB> msg = _msg <MASK> msg = ""%s: %s"" % (msg, _msg) <TAB>  <TAB> _report_failure(msg)",elif values is True :,103
"def test_active_plan_summary(self): <TAB> for plan in Customer.objects.active_plan_summary(): <TAB>  <TAB> if plan[""subscription__plan""] == self.plan: <TAB>  <TAB>  <TAB> self.assertEquals(plan[""count""], 10) <MASK> self.assertEquals(plan[""count""], 1)","if plan [ ""subscription__plan"" ] == self . plan2 :",88
"def paths(self): <TAB> """"""Generate all paths for this collection."""""" <TAB> for type, item in self.items: <TAB>  <TAB> if type == ""path"": <TAB>  <TAB>  <TAB> yield item <MASK> path = _local_path_from_url(item.url) <TAB>  <TAB>  <TAB> if path is not None: <TAB>  <TAB>  <TAB>  <TAB> yield path <TAB>  <TAB> elif type == ""container"": <TAB>  <TAB>  <TAB> container = UnwrapObject(item) <TAB>  <TAB>  <TAB> for path in container.genLocalPaths( <TAB>  <TAB>  <TAB>  <TAB> extraIncludes=self.extraIncludes, extraExcludes=self.extraExcludes <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> yield path","elif type == ""file"" :",156
"def public_modules(module): <TAB> yield module <TAB> for name, class_ in module.__dict__.items(): <TAB>  <TAB> if name.startswith(""_""):  # pragma: no cover <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if not isinstance(class_, types.ModuleType): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if not class_.__name__.startswith(module.__name__):  # pragma: no cover <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> # We should rename the trio.tests module (#274), but until then we use <TAB>  <TAB> # a special-case hack: <TAB>  <TAB> if class_.__name__ == ""trio.tests"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> yield from public_modules(class_)",if class_ is module :,166
"def traverse(obj, namespace): <TAB> for name in dir(obj): <TAB>  <TAB> # Hack for 3.2's warning about body_params <TAB>  <TAB> if name == ""body_params"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> vtype = type(getattr(obj, name, None)) <MASK> self.known_config_types[namespace + ""."" + name] = vtype",if vtype in b :,92
"def findTotalWhoNeeds(self, depList, whoNeeds): <TAB> while depList: <TAB>  <TAB> pkg = depList.pop(0) <TAB>  <TAB> for depPackage in SPECS.getData().getListPackages(): <TAB>  <TAB>  <TAB> for version in SPECS.getData().getVersions(depPackage): <TAB>  <TAB>  <TAB>  <TAB> depBasePkg = depPackage + ""-"" + version <TAB>  <TAB>  <TAB>  <TAB> if depBasePkg in whoNeeds: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB>  <TAB> if pkg in self.getBasePackagesRequired(depBasePkg): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> whoNeeds.append(depBasePkg) <MASK> depList.append(depBasePkg)",if depBasePkg not in depList :,177
"def _move_tick(self, resume=False): <TAB> del self.session.world.ground_unit_map[self.position.to_tuple()] <TAB> try: <TAB>  <TAB> super()._move_tick(resume) <TAB> except PathBlockedError: <MASK> self.session.world.ground_unit_map[self.position.to_tuple()] = weakref.ref( <TAB>  <TAB>  <TAB>  <TAB> self <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> raise <TAB> self.session.world.ground_unit_map[self.position.to_tuple()] = weakref.ref(self) <TAB> self.session.world.ground_unit_map[self._next_target.to_tuple()] = weakref.ref(self)",if resume :,168
"def _check_add_window(self, n): <TAB> self.lock.acquire() <TAB> try: <MASK> return 0 <TAB>  <TAB> if self.ultra_debug: <TAB>  <TAB>  <TAB> self._log(DEBUG, ""addwindow %d"" % n) <TAB>  <TAB> self.in_window_sofar += n <TAB>  <TAB> if self.in_window_sofar <= self.in_window_threshold: <TAB>  <TAB>  <TAB> return 0 <TAB>  <TAB> if self.ultra_debug: <TAB>  <TAB>  <TAB> self._log(DEBUG, ""addwindow send %d"" % self.in_window_sofar) <TAB>  <TAB> out = self.in_window_sofar <TAB>  <TAB> self.in_window_sofar = 0 <TAB>  <TAB> return out <TAB> finally: <TAB>  <TAB> self.lock.release()",if self . closed or self . eof_received or not self . active :,197
"def updater(table: dict): <TAB> for document in documents: <TAB>  <TAB> # Make sure the document implements the ``Mapping`` interface <MASK> raise ValueError(""Document is not a Mapping"") <TAB>  <TAB> # Get the document ID for this document and store it so we <TAB>  <TAB> # can return all document IDs later <TAB>  <TAB> doc_id = self._get_next_id() <TAB>  <TAB> doc_ids.append(doc_id) <TAB>  <TAB> # Convert the document to a ``dict`` (see Table.insert) and <TAB>  <TAB> # store it <TAB>  <TAB> table[doc_id] = dict(document)","if not isinstance ( document , Mapping ) :",146
"def filter(self, projection_expression): <TAB> expressions = [x.strip() for x in projection_expression.split("","")] <TAB> top_level_expressions = [ <TAB>  <TAB> expr[0 : expr.index(""."")] for expr in expressions if ""."" in expr <TAB> ] <TAB> for attr in list(self.attrs): <TAB>  <TAB> if attr not in expressions and attr not in top_level_expressions: <TAB>  <TAB>  <TAB> self.attrs.pop(attr) <MASK> relevant_expressions = [ <TAB>  <TAB>  <TAB>  <TAB> expr[len(attr + ""."") :] <TAB>  <TAB>  <TAB>  <TAB> for expr in expressions <TAB>  <TAB>  <TAB>  <TAB> if expr.startswith(attr + ""."") <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB> self.attrs[attr].filter(relevant_expressions)",if attr in top_level_expressions :,177
"def coalesce_lines(): <TAB> line_iter = iter(lines) <TAB> try: <TAB>  <TAB> buffer = """" <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> line = next(line_iter) <MASK> # Continuation. <TAB>  <TAB>  <TAB>  <TAB> buffer += line.strip()[:-1] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> if buffer: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # Continuation join, preserve left hand ws (could be a kv separator) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> buffer += line.rstrip() <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # Plain old line <TAB>  <TAB>  <TAB>  <TAB>  <TAB> buffer = line.strip() <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield buffer <TAB>  <TAB>  <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> buffer = """" <TAB> except StopIteration: <TAB>  <TAB> pass","if line . strip ( ) . endswith ( ""\\"" ) :",194
"def override_state(k, suffix, new_suffix, idx): <TAB> new_key = k[: -len(suffix)] + new_suffix <TAB> dim = state[k].shape[0] <TAB> if new_key not in items_to_add: <TAB>  <TAB> items_to_add[new_key] = ( <TAB>  <TAB>  <TAB> torch.zeros_like(state[k]).repeat(3, 1) <MASK> else torch.zeros_like(state[k]).repeat(3) <TAB>  <TAB> ) <TAB> items_to_add[new_key][idx * dim : (idx + 1) * dim] = state[k] <TAB> keys_to_remove.append(k)",if len ( state [ k ] . shape ) > 1,173
"def _preprocess_decorator_list(self, node): <TAB> decorators = [] <TAB> for d in node.decorator_list: <MASK> decorators.append(d.id) <TAB>  <TAB> elif isinstance(d, ast3.Attribute): <TAB>  <TAB>  <TAB> decorators.append(f""{d.value.id}.{d.attr}"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ParseError(f""Unexpected decorator: {d}"") <TAB> node.decorator_list = decorators","if isinstance ( d , ast3 . Name ) :",116
"def rename_placeholder(app, schema_editor): <TAB> EventSettingsStore = app.get_model(""pretixbase"", ""Event_SettingsStore"") <TAB> for setting in EventSettingsStore.objects.all(): <MASK> new_value = setting.value.replace(""{paymentinfo}"", ""{payment_info}"") <TAB>  <TAB>  <TAB> setting.value = new_value <TAB>  <TAB>  <TAB> cache.delete(""hierarkey_{}_{}"".format(""event"", setting.object_id)) <TAB>  <TAB>  <TAB> setting.save()","if setting . key == ""mail_text_order_placed"" :",128
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_url(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,90
"def get_study_id_from_trial_id(self, trial_id: int) -> int: <TAB> with self._lock: <MASK> return self._trial_id_to_study_id_and_number[trial_id][0] <TAB> return self._backend.get_study_id_from_trial_id(trial_id)",if trial_id in self . _trial_id_to_study_id_and_number :,106
"def prepare_http01_modules(self): <TAB> """"""Make sure that we have the needed modules available for http01"""""" <TAB> if self.configurator.conf(""handle-modules""): <TAB>  <TAB> needed_modules = [""rewrite""] <MASK> needed_modules.append(""authz_host"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> needed_modules.append(""authz_core"") <TAB>  <TAB> for mod in needed_modules: <TAB>  <TAB>  <TAB> if mod + ""_module"" not in self.configurator.parser.modules: <TAB>  <TAB>  <TAB>  <TAB> self.configurator.enable_mod(mod, temp=True)","if self . configurator . version < ( 2 , 4 ) :",157
"def add_edge(s): <TAB> deps = [] <TAB> if s == ""1"": <TAB>  <TAB> deps.extend([""1L"", ""1R""]) <TAB> else: <TAB>  <TAB> if s[-1] == ""R"": <TAB>  <TAB>  <TAB> deps.append(s[0:-1] + ""L"") <TAB>  <TAB> if len(s) < self.N: <TAB>  <TAB>  <TAB> deps.extend([s + ""L"", s + ""R""]) <TAB>  <TAB> for k in range(len(s) - 2): <TAB>  <TAB>  <TAB> base = s[1 : -1 - k] <MASK> deps.append(""1"" + base[:-1] + ""L"") <TAB> for dep in deps: <TAB>  <TAB> g.add_edge(""loc_latent_"" + dep, ""loc_latent_"" + s)","if base [ - 1 ] == ""R"" :",194
"def update_settings(self, settings=None): <TAB> """"""Updates the trainer settings. Must be called to update internal settings."""""" <TAB> if settings is not None: <TAB>  <TAB> self.settings = settings <TAB> if self.settings.env.workspace_dir is not None: <TAB>  <TAB> self.settings.env.workspace_dir = os.path.expanduser( <TAB>  <TAB>  <TAB> self.settings.env.workspace_dir <TAB>  <TAB> ) <TAB>  <TAB> self._checkpoint_dir = os.path.join( <TAB>  <TAB>  <TAB> self.settings.env.workspace_dir, ""checkpoints"" <TAB>  <TAB> ) <MASK> os.makedirs(self._checkpoint_dir) <TAB> else: <TAB>  <TAB> self._checkpoint_dir = None",if not os . path . exists ( self . _checkpoint_dir ) :,177
"def generate_non_label_data(ids): <TAB> if len(ids) != SAMPLE_NUM: <TAB>  <TAB> raise ValueError(""len ids should equal to sample number"") <TAB> header = [""id""] + [""x"" + str(i) for i in range(FEATURE_NUM)] <TAB> yield header <TAB> counter = 0 <TAB> for sample_i in range(SAMPLE_NUM): <TAB>  <TAB> one_data = [ids[sample_i]] + list(np.random.random(FEATURE_NUM)) <TAB>  <TAB> counter += 1 <MASK> print(""generate data {}"".format(counter)) <TAB>  <TAB> yield one_data",if counter % 10000 == 0 :,148
"def save(self, *args, **kwargs): <TAB> if self.user_id and not self.pk:  # Copy things <TAB>  <TAB> user = self.user <MASK> self.name = user.get_full_name() <TAB>  <TAB> if not self.email: <TAB>  <TAB>  <TAB> self.email = getattr(user, ""email"", """") <TAB>  <TAB> if not self.first_name and not self.last_name: <TAB>  <TAB>  <TAB> self.first_name = getattr(user, ""first_name"", """") <TAB>  <TAB>  <TAB> self.last_name = getattr(user, ""last_name"", """") <TAB> return super(PersonContact, self).save(*args, **kwargs)",if not self . name :,165
"def run_with_sudo_loop(function: Callable) -> Optional[Any]: <TAB> sudo_loop(once=True) <TAB> with ThreadPool(processes=2) as pool: <TAB>  <TAB> main_thread = pool.apply_async(function, ()) <TAB>  <TAB> pool.apply_async(sudo_loop) <TAB>  <TAB> pool.close() <TAB>  <TAB> catched_exc = None <TAB>  <TAB> result: Optional[Any] = None <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> result = main_thread.get() <TAB>  <TAB> except Exception as exc: <TAB>  <TAB>  <TAB> catched_exc = exc <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> pool.terminate() <TAB>  <TAB> if catched_exc: <TAB>  <TAB>  <TAB> raise catched_exc  # pylint: disable=raising-bad-type <MASK> return result <TAB>  <TAB> return None",if result :,191
"def iter_objects( <TAB> mod, ignore_private=True, restrict_to_type=None, restrict_to_subclass=None): <TAB> for name in dir(mod): <TAB>  <TAB> obj = getattr(mod, name) <TAB>  <TAB> if ignore_private: <MASK> continue <TAB>  <TAB> if restrict_to_type is not None: <TAB>  <TAB>  <TAB> if not isinstance(obj, restrict_to_type): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if restrict_to_subclass is not None: <TAB>  <TAB>  <TAB> if not (isinstance(obj, type) and issubclass(obj, restrict_to_subclass)): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> yield name","if name . startswith ( ""_"" ) :",158
"def neo4j_driver(target, auth): <TAB> try: <TAB>  <TAB> driver = GraphDatabase.neo4j_driver(target, auth=auth) <TAB> except ServiceUnavailable as error: <TAB>  <TAB> if isinstance(error.__cause__, BoltHandshakeError): <TAB>  <TAB>  <TAB> pytest.skip(error.args[0]) <MASK> pytest.skip(error.args[0]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise <TAB> else: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> yield driver <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> driver.close()","elif error . args [ 0 ] == ""Server does not support routing"" :",147
"def _ensure_header_written(self): <TAB> if not self._nframeswritten: <MASK> raise Error(""# of channels not specified"") <TAB>  <TAB> if not self._sampwidth: <TAB>  <TAB>  <TAB> raise Error(""sample width not specified"") <TAB>  <TAB> if not self._framerate: <TAB>  <TAB>  <TAB> raise Error(""frame rate not specified"") <TAB>  <TAB> self._write_header()",if not self . _nchannels :,94
"def sane(x): <TAB> r = """" <TAB> for i in x: <TAB>  <TAB> if type(x) is str: <TAB>  <TAB>  <TAB> j = ord(i) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> j = i <MASK> r = r + ""."" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> r = r + chb(i) <TAB> return r",if ( j < 32 ) or ( j >= 127 ) :,97
"def _write(self, string): <TAB> self._line_buffer += string <TAB> # self._break_long_lines() <TAB> lines = self._line_buffer.splitlines() <TAB> for i, line in enumerate(lines): <TAB>  <TAB> last = i == len(lines) - 1 <MASK> self._line_buffer = line <TAB>  <TAB>  <TAB> return <TAB>  <TAB> self._log_line(line) <TAB> self._line_buffer = """"","if last and not self . _line_buffer . endswith ( ""\n"" ) :",118
"def test_xbin_sync(seq): <TAB> for start_ind in range(64): <TAB>  <TAB> path = [start_ind] <TAB>  <TAB> cur_ind = start_ind <TAB>  <TAB> while cur_ind < len(seq): <MASK> cur_ind += 3 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> assert seq[cur_ind] & (64 + 128) == 128 <TAB>  <TAB>  <TAB>  <TAB> cur_ind += (seq[cur_ind] & 63) + 3 <TAB>  <TAB>  <TAB> path.append(cur_ind) <TAB>  <TAB> assert cur_ind == len(seq), ""problem for path {}"".format(path)",if seq [ cur_ind ] == 0 :,158
"def node_arglist(self, node): <TAB> childs = node.children.__iter__() <TAB> arglist = [] <TAB> try: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> child = childs.next() <TAB>  <TAB>  <TAB> if isinstance(child, Leaf): <TAB>  <TAB>  <TAB>  <TAB> if child.value == "","": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> value = self.dispatch(childs.next()) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> arglist.append(Argument(child.value, value)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB>  <TAB> arglist.append(self.dispatch(child)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> arglist.append(self.dispatch(child)) <TAB> except StopIteration: <TAB>  <TAB> pass <TAB> return arglist","if child . value in [ ""*"" , ""**"" ] :",180
"def RecExpression(node, first_child_leaf): <TAB> if node is first_child_leaf: <TAB>  <TAB> return <TAB> if isinstance(node, pytree.Leaf): <MASK> return <TAB>  <TAB> penalty_annotation = pytree_utils.GetNodeAnnotation( <TAB>  <TAB>  <TAB> node, pytree_utils.Annotation.SPLIT_PENALTY, default=0 <TAB>  <TAB> ) <TAB>  <TAB> if penalty_annotation < penalty: <TAB>  <TAB>  <TAB> _SetSplitPenalty(node, penalty) <TAB> else: <TAB>  <TAB> for child in node.children: <TAB>  <TAB>  <TAB> RecExpression(child, first_child_leaf)","if node . value in { ""("" , ""for"" , ""if"" } :",157
"def _check_scenario_syntax(self, lines, filename): <TAB> empty_scenario = (""%s:"" % (self.language.first_of_scenario)).lower() <TAB> for line in lines: <MASK> raise LettuceSyntaxError( <TAB>  <TAB>  <TAB>  <TAB> filename, <TAB>  <TAB>  <TAB>  <TAB> ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> 'In the feature ""%s"", scenarios ' <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""must have a name, make sure to declare a scenario like "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""this: `Scenario: name of your scenario`"" % self.name <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB> )",if line . lower ( ) == empty_scenario :,151
"def _decode( <TAB> self, elements: AbstractTensor, is_scaled: bool) -> Union[tf.Tensor, np.ndarray]: <TAB> """"""Decode tensor of ring elements into tensor of rational numbers."""""" <TAB> with tf.compat.v1.name_scope(""decode""): <TAB>  <TAB> bound = self.fixedpoint_config.bound_single_precision <TAB>  <TAB> scaled = (elements + bound).to_native() - bound <MASK> return scaled <TAB>  <TAB> return scaled / self.fixedpoint_config.scaling_factor",if not is_scaled :,125
"def _doCommand(self, player): <TAB> rm = player.room <TAB> availItems = rm.inv + player.inv <TAB> if self.subject in availItems: <MASK> if self.subject.isOpened: <TAB>  <TAB>  <TAB>  <TAB> self.subject.closeItem(player) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> print(""You can't close that, it's not open."") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""You can't close that."") <TAB> else: <TAB>  <TAB> print(""There is no %s here to close."" % self.subject)",if self . subject . isOpenable :,139
"def colorize(tokens, ansi_level): <TAB> output = """" <TAB> for type_, value in tokens: <TAB>  <TAB> if type_ == TokenType.LEVEL: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""The '<level>' color tag is not allowed in this context, "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""it has not yet been associated to any color value."" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> value = ansi_level <TAB>  <TAB> output += value <TAB> return output",if ansi_level is None :,119
"def replace(self, old, new): <TAB> v_m = self.var_map <TAB> reg = v_m[self.reg] <TAB> if not (reg.is_const() or reg.is_ident()): <TAB>  <TAB> reg.replace(old, new) <TAB> else: <MASK> v_m[new.value()] = new <TAB>  <TAB>  <TAB> self.reg = new.value() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> v_m[old] = new",if new . is_ident ( ) :,119
"def run(self): <TAB> while True: <TAB>  <TAB> self.finished.wait(self.interval) <MASK> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.function(*self.args, **self.kwargs)",if self . finished . is_set ( ) :,63
"def readframes(self, nframes): <TAB> if self._ssnd_seek_needed: <TAB>  <TAB> self._ssnd_chunk.seek(0) <TAB>  <TAB> dummy = self._ssnd_chunk.read(8) <TAB>  <TAB> pos = self._soundpos * self._framesize <MASK> self._ssnd_chunk.seek(pos + 8) <TAB>  <TAB> self._ssnd_seek_needed = 0 <TAB> if nframes == 0: <TAB>  <TAB> return b"""" <TAB> data = self._ssnd_chunk.read(nframes * self._framesize) <TAB> if self._convert and data: <TAB>  <TAB> data = self._convert(data) <TAB> self._soundpos = self._soundpos + len(data) // (self._nchannels * self._sampwidth) <TAB> return data",if pos :,186
"def filter_unique_decoded(decoded_strings): <TAB> unique_values = set() <TAB> originals = [] <TAB> for decoded in decoded_strings: <TAB>  <TAB> hashable = (decoded.s, decoded.decoded_at_va, decoded.fva) <MASK> unique_values.add(hashable) <TAB>  <TAB>  <TAB> originals.append(decoded) <TAB> return originals",if hashable not in unique_values :,96
"def _add_ava(ava, decompose, remove_space, space_around_equal): <TAB> if not ava: <TAB>  <TAB> return """" <TAB> space = "" "" if space_around_equal else """" <TAB> attr_name, _, value = ava.partition(""="") <TAB> if decompose: <MASK> component = (attr_name.strip(), value.strip()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> component = (attr_name, value) <TAB> else: <TAB>  <TAB> if remove_space: <TAB>  <TAB>  <TAB> component = attr_name.strip() + space + ""="" + space + value.strip() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> component = attr_name + space + ""="" + space + value <TAB> return component",if remove_space :,170
"def _search_resource_changes(self, resource): <TAB> changed = set() <TAB> if resource in self.resources and self._is_changed(resource): <TAB>  <TAB> changed.add(resource) <TAB> if resource.is_folder(): <TAB>  <TAB> for file in self.resources: <MASK> if self._is_changed(file): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> changed.add(file) <TAB> return changed",if file . exists ( ) and resource . contains ( file ) :,110
"def call_action(self): <TAB> self.body = json.loads(self.body or ""{}"") <TAB> endpoint = self.get_endpoint_name(self.headers) <TAB> if endpoint: <TAB>  <TAB> endpoint = camelcase_to_underscores(endpoint) <TAB>  <TAB> response = getattr(self, endpoint)() <MASK> return 200, self.response_headers, response <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> status_code, new_headers, response_content = response <TAB>  <TAB>  <TAB> self.response_headers.update(new_headers) <TAB>  <TAB>  <TAB> return status_code, self.response_headers, response_content <TAB> else: <TAB>  <TAB> return 404, self.response_headers, """"","if isinstance ( response , six . string_types ) :",172
"def cookies(self): <TAB> cookies = SimpleCookie() <TAB> cookie_header = self.environ.get(""HTTP_COOKIE"") <TAB> if cookie_header: <TAB>  <TAB> galaxy_cookies = ""; "".join( <TAB>  <TAB>  <TAB> x.strip() for x in cookie_header.split(""; "") if x.startswith(""galaxy"") <TAB>  <TAB> ) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> cookies.load(galaxy_cookies) <TAB>  <TAB>  <TAB> except CookieError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB> return cookies",if galaxy_cookies :,129
"def __compact_key_values(key_values): <TAB> if isinstance(key_values, list): <TAB>  <TAB> compacted = [] <TAB>  <TAB> for item in key_values: <MASK> compacted.append(__compact_key_values(item)) <TAB>  <TAB>  <TAB> elif not isinstance(item, Undef): <TAB>  <TAB>  <TAB>  <TAB> compacted.append(item) <TAB> else: <TAB>  <TAB> compacted = {} <TAB>  <TAB> for key in key_values: <TAB>  <TAB>  <TAB> value = key_values[key] <TAB>  <TAB>  <TAB> if isinstance(value, (list, dict)): <TAB>  <TAB>  <TAB>  <TAB> compacted.update({key: __compact_key_values(value)}) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> compacted.update({key: value}) <TAB> return compacted","if isinstance ( item , ( list , dict ) ) :",191
"def reset_session(): <TAB> """"""Remove all config files"""""" <TAB> print(""*** Reset Spyder settings to defaults ***"", file=STDERR) <TAB> for fname in SAVED_CONFIG_FILES: <TAB>  <TAB> cfg_fname = get_conf_path(fname) <MASK> os.remove(cfg_fname) <TAB>  <TAB> elif osp.isdir(cfg_fname): <TAB>  <TAB>  <TAB> shutil.rmtree(cfg_fname) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> print(""removing:"", cfg_fname, file=STDERR)",if osp . isfile ( cfg_fname ) :,132
"def _state_change_handler(self, ev): <TAB> datapath = ev.datapath <TAB> if ev.state == MAIN_DISPATCHER: <TAB>  <TAB> if datapath.id not in self.datapaths: <TAB>  <TAB>  <TAB> self.logger.debug(""register datapath: %016x"", datapath.id) <TAB>  <TAB>  <TAB> self.datapaths[datapath.id] = datapath <TAB> elif ev.state == DEAD_DISPATCHER: <MASK> self.logger.debug(""unregister datapath: %016x"", datapath.id) <TAB>  <TAB>  <TAB> del self.datapaths[datapath.id]",if datapath . id in self . datapaths :,159
"def pickle(self, torv, val, tag): <TAB> """"""Pickle val and return the hexlified result."""""" <TAB> try: <TAB>  <TAB> s = pickle.dumps(val, protocol=1) <TAB>  <TAB> s2 = binascii.hexlify(s) <TAB>  <TAB> s3 = g.ue(s2, ""utf-8"") <TAB>  <TAB> field = ' %s=""%s""' % (tag, s3) <TAB>  <TAB> return field <TAB> except pickle.PicklingError: <MASK> # The caller will print the error if tag is None. <TAB>  <TAB>  <TAB> g.warning(""ignoring non-pickleable value"", val, ""in"", torv) <TAB>  <TAB> return """" <TAB> except Exception: <TAB>  <TAB> g.error(""fc.pickle: unexpected exception in"", torv) <TAB>  <TAB> g.es_exception() <TAB>  <TAB> return """"",if tag :,191
"def do_modified(self, _view, filename): <TAB> if filename: <MASK> print(""{0} invoked."".format(type(self).__name__ + "".on_modified"")) <TAB>  <TAB> self.type_cache.remove(filename)",if Settings . COMPONENT_DEBUG . event_viewer :,70
"def _find_orphan_files(self, registering, draft): <TAB> from website.archiver.utils import find_selected_files <TAB> files = find_selected_files(draft.registration_schema, draft.registration_metadata) <TAB> orphan_files = [] <TAB> for key, value in files.items(): <TAB>  <TAB> if ""extra"" in value: <TAB>  <TAB>  <TAB> for file_metadata in value[""extra""]: <MASK> orphan_files.append(file_metadata) <TAB> return orphan_files","if not self . _is_attached_file_valid ( file_metadata , registering ) :",142
"def remove_metrics_not_in(self, metrics): <TAB> bulk_size = 1000 <TAB> bulk_list = [] <TAB> affected = 0 <TAB> self.assure_index() <TAB> index = set(metrics) <TAB> for es_metrics in self.get_all_metrics(): <TAB>  <TAB> for hit in es_metrics[""hits""][""hits""]: <TAB>  <TAB>  <TAB> if hit[""_id""] not in index: <TAB>  <TAB>  <TAB>  <TAB> bulk_list.append({""delete"": {""_id"": hit[""_id""]}}) <TAB>  <TAB>  <TAB>  <TAB> affected += 1 <MASK> self.es_bulk(bulk_list) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> bulk_list = [] <TAB> self.es_bulk(bulk_list) <TAB> self.logger.debug(""removed %d metrics from elasticsearch"", affected)",if len ( bulk_list ) >= bulk_size :,194
"def trial_end(self, parameter_id, success, **kwargs): <TAB> if not success: <TAB>  <TAB> del self.history[parameter_id] <MASK> self.initial_population.append(self._random_model()) <TAB>  <TAB> del self._from_initial[parameter_id]",if self . _from_initial [ parameter_id ] :,81
"def _dataReceived_CHUNK_LENGTH(self, data): <TAB> if b""\r\n"" in data: <TAB>  <TAB> line, rest = data.split(b""\r\n"", 1) <TAB>  <TAB> parts = line.split(b"";"") <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.length = int(parts[0], 16) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> raise _MalformedChunkedDataError(""Chunk-size must be an integer."") <MASK> self.state = ""TRAILER"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.state = ""BODY"" <TAB>  <TAB> return rest <TAB> else: <TAB>  <TAB> self._buffer = data <TAB>  <TAB> return b""""",if self . length == 0 :,165
"def _containers_config_file(args): <TAB> containers_config_file = args.containers_config_file <TAB> if not containers_config_file: <TAB>  <TAB> for path in (""./config"", "".""): <TAB>  <TAB>  <TAB> testf = os.path.join(path, ""containers_conf.yml"") <MASK> containers_config_file = testf <TAB> assert ( <TAB>  <TAB> containers_config_file <TAB> ), ""containers_conf.yml cannot be found, please set with '-c' or '--containers-config-file'"" <TAB> return containers_config_file",if os . path . exists ( testf ) :,143
"def _parse(self): <TAB> image_dir = self.image_dir <TAB> if not isinstance(image_dir, Sequence): <TAB>  <TAB> image_dir = [image_dir] <TAB> images = [] <TAB> for im_dir in image_dir: <TAB>  <TAB> if os.path.isdir(im_dir): <TAB>  <TAB>  <TAB> im_dir = os.path.join(self.dataset_dir, im_dir) <TAB>  <TAB>  <TAB> images.extend(_make_dataset(im_dir)) <MASK> images.append(im_dir) <TAB> return images",elif os . path . isfile ( im_dir ) and _is_valid_file ( im_dir ) :,154
"def _provide_cmd_arguments(arguments, config): <TAB> for model in config[""models""]: <TAB>  <TAB> for launcher_entry in model[""launchers""]: <MASK> continue <TAB>  <TAB>  <TAB> converted_models = ( <TAB>  <TAB>  <TAB>  <TAB> arguments.converted_models <TAB>  <TAB>  <TAB>  <TAB> if arguments.converted_models <TAB>  <TAB>  <TAB>  <TAB> else arguments.models <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> launcher_entry[""_converted_models""] = converted_models <TAB>  <TAB>  <TAB> launcher_entry[""_models_prefix""] = arguments.models <TAB>  <TAB>  <TAB> launcher_entry[""_model_optimizer""] = arguments.model_optimizer <TAB>  <TAB>  <TAB> launcher_entry[""_tf_custom_config_dir""] = arguments.tf_custom_op_config","if launcher_entry [ ""framework"" ] . lower ( ) != ""dlsdk"" :",182
"def wrapper(*args, **kargs): <TAB> rval = None <TAB> try: <TAB>  <TAB> rval = f(*args, **kargs) <TAB> except ExitMainLoop: <MASK> self.reactor.stop() <TAB> except: <TAB>  <TAB> import sys <TAB>  <TAB> print(sys.exc_info()) <TAB>  <TAB> self._exc_info = sys.exc_info() <TAB>  <TAB> if self.manage_reactor: <TAB>  <TAB>  <TAB> self.reactor.crash() <TAB> if enable_idle: <TAB>  <TAB> self._enable_twisted_idle() <TAB> return rval",if self . manage_reactor :,139
"def assertNotAlmostEqual(self, x, y, places=None, msg="""", delta=None): <TAB> if delta is not None and places is not None: <TAB>  <TAB> raise TypeError(""specify delta or places not both"") <TAB> if delta is not None: <TAB>  <TAB> if not (x == y) and abs(x - y) > delta: <TAB>  <TAB>  <TAB> return <MASK> msg = ""%r == %r within %r delta"" % (x, y, delta) <TAB> else: <TAB>  <TAB> if places is None: <TAB>  <TAB>  <TAB> places = 7 <TAB>  <TAB> if not (x == y) and round(abs(y - x), places) != 0: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> if not msg: <TAB>  <TAB>  <TAB> msg = ""%r == %r within %r places"" % (x, y, places) <TAB> assert False, msg",if not msg :,197
"def __new__(mcs, name, bases, dct): <TAB> description = dct.get(""description"", """") <TAB> if description: <MASK> description = description[1:] <TAB>  <TAB> description = textwrap.dedent(description) <TAB>  <TAB> description = description.split(""\n\n"") <TAB>  <TAB> description = [chunk.replace(""\n"", "" "").strip() for chunk in description] <TAB>  <TAB> dct[""description""] = ""\n\n"".join(description) <TAB> return super(PluginBaseMeta, mcs).__new__(mcs, name, bases, dct)","if description [ 0 ] == ""\n"" :",134
"def inherit(self, name, prop, recursive=False): <TAB> try: <TAB>  <TAB> with libzfs.ZFS() as zfs: <TAB>  <TAB>  <TAB> dataset = zfs.get_dataset(name) <TAB>  <TAB>  <TAB> zprop = dataset.properties.get(prop) <MASK> raise CallError(f""Property {prop!r} not found."", errno.ENOENT) <TAB>  <TAB>  <TAB> zprop.inherit(recursive=recursive) <TAB> except libzfs.ZFSException as e: <TAB>  <TAB> raise CallError(str(e))",if not zprop :,133
"def callbacks(self): <TAB> """"""Return all callbacks"""""" <TAB> import skorch.callbacks <TAB> callbacks = [] <TAB> for name in dir(skorch.callbacks): <TAB>  <TAB> attr = getattr(skorch.callbacks, name) <TAB>  <TAB> # pylint: disable=unidiomatic-typecheck <MASK> continue <TAB>  <TAB> if issubclass(attr, skorch.callbacks.Callback): <TAB>  <TAB>  <TAB> callbacks.append(attr) <TAB> return callbacks",if not type ( attr ) is type :,111
"def _build_sub_query(self, search_node): <TAB> term_list = [] <TAB> for child in search_node.children: <TAB>  <TAB> if isinstance(child, SearchNode): <TAB>  <TAB>  <TAB> term_list.append(self._build_sub_query(child)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = child[1] <MASK> value = PythonData(value) <TAB>  <TAB>  <TAB> term_list.append(value.prepare(self)) <TAB> return ("" "").join(map(str, term_list))","if not hasattr ( value , ""input_type_name"" ) :",139
"def preprocessTriple(self, triple): <TAB> super(TurtleSerializer, self).preprocessTriple(triple) <TAB> for i, node in enumerate(triple): <MASK> continue <TAB>  <TAB> # Don't use generated prefixes for subjects and objects <TAB>  <TAB> self.getQName(node, gen_prefix=(i == VERB)) <TAB>  <TAB> if isinstance(node, Literal) and node.datatype: <TAB>  <TAB>  <TAB> self.getQName(node.datatype, gen_prefix=_GEN_QNAME_FOR_DT) <TAB> p = triple[1] <TAB> if isinstance(p, BNode):  # hmm - when is P ever a bnode? <TAB>  <TAB> self._references[p] += 1",if node in self . keywords :,166
"def _updateWidth(self, event): <TAB> if self.resize: <TAB>  <TAB> canvas_width = event.width <MASK> canvas_width = self.canvas.winfo_width() <TAB>  <TAB> interior_width = self.interior.winfo_reqwidth() <TAB>  <TAB> if canvas_width < interior_width: <TAB>  <TAB>  <TAB> canvas_width = interior_width <TAB>  <TAB> self.canvas.itemconfig(self.interior_id, width=canvas_width) <TAB> else: <TAB>  <TAB> size = (self.interior.winfo_reqwidth(), self.interior.winfo_reqheight()) <TAB>  <TAB> self.canvas.config(scrollregion=""0 0 %s %s"" % size)",if canvas_width == 0 :,169
"def execute(): <TAB> for dt in (""Sales Invoice Advance"", ""Purchase Invoice Advance""): <TAB>  <TAB> frappe.reload_doctype(dt) <TAB>  <TAB> frappe.db.sql(""update `tab{0}` set reference_type = 'Journal Entry'"".format(dt)) <TAB>  <TAB> if frappe.get_meta(dt).has_field(""journal_entry""): <TAB>  <TAB>  <TAB> rename_field(dt, ""journal_entry"", ""reference_name"") <MASK> rename_field(dt, ""jv_detail_no"", ""reference_row"")","if frappe . get_meta ( dt ) . has_field ( ""jv_detail_no"" ) :",157
"def fix_refuris(self, tree: Node) -> None: <TAB> # fix refuris with double anchor <TAB> fname = self.config.master_doc + self.out_suffix <TAB> for refnode in tree.traverse(nodes.reference): <TAB>  <TAB> if ""refuri"" not in refnode: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> refuri = refnode[""refuri""] <TAB>  <TAB> hashindex = refuri.find(""#"") <MASK> continue <TAB>  <TAB> hashindex = refuri.find(""#"", hashindex + 1) <TAB>  <TAB> if hashindex >= 0: <TAB>  <TAB>  <TAB> refnode[""refuri""] = fname + refuri[hashindex:]",if hashindex < 0 :,152
"def _get_object(self, sha, cls): <TAB> assert len(sha) in (20, 40) <TAB> ret = self.get_object(sha) <TAB> if not isinstance(ret, cls): <MASK> raise NotCommitError(ret) <TAB>  <TAB> elif cls is Blob: <TAB>  <TAB>  <TAB> raise NotBlobError(ret) <TAB>  <TAB> elif cls is Tree: <TAB>  <TAB>  <TAB> raise NotTreeError(ret) <TAB>  <TAB> elif cls is Tag: <TAB>  <TAB>  <TAB> raise NotTagError(ret) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception(""Type invalid: %r != %r"" % (ret.type_name, cls.type_name)) <TAB> return ret",if cls is Commit :,165
"def _generate_smart_str(params): <TAB> for key, value in params.items(): <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB> continue <MASK> for item in value: <TAB>  <TAB>  <TAB>  <TAB> yield _smart_str(key), _smart_str(item) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield _smart_str(key), _smart_str(value)","if isinstance ( value , ( list , tuple ) ) :",101
"def _on_event(self, _): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> conn, addr = self._sock.accept() <TAB>  <TAB>  <TAB> TCPEventHandler(self, conn, addr) <TAB>  <TAB> except socket.error as err: <MASK> break","if err . args [ 0 ] in ( errno . EAGAIN , errno . EWOULDBLOCK ) :",93
"def check_collection(mul): <TAB> paths = [""123"", ""456""] <TAB> for c in savers: <TAB>  <TAB> paths.remove(c.path) <TAB>  <TAB> if c.path == ""123"": <TAB>  <TAB>  <TAB> assert c._count == 2 * mul <MASK> assert c._count == 1 * mul <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert False, ""invalid path""","elif c . path == ""456"" :",99
"def _showfields_add_dynamic_fields(self, field_list, title, parts): <TAB> ""helper for __unicode__"" <TAB> parts.append((True, ""- "" + title, "":"")) <TAB> for field_name in field_list: <TAB>  <TAB> out = field_name <TAB>  <TAB> content = getattr(self, field_name) <TAB>  <TAB> if self.polymorphic_showfield_type: <TAB>  <TAB>  <TAB> out += "" ("" + type(content).__name__ + "")"" <MASK> out += self._showfields_get_content(field_name) <TAB>  <TAB> parts.append((False, out, "",""))",if self . polymorphic_showfield_content :,156
"def OnDoubleClick(self): <TAB> if self.flist: <TAB>  <TAB> frame, lineno = self.info <TAB>  <TAB> filename = frame.f_code.co_filename <MASK> self.flist.gotofileline(filename, lineno)",if os . path . isfile ( filename ) :,69
"def conda_env_file(self): <TAB> if self._conda_env_file is None: <TAB>  <TAB> expanded_env = self.rule.expand_conda_env(self.wildcards_dict) <TAB>  <TAB> if expanded_env is not None: <TAB>  <TAB>  <TAB> scheme, _, path, *_ = urlparse(expanded_env) <TAB>  <TAB>  <TAB> # Normalize 'file:///my/path.yml' to '/my/path.yml' <MASK> self._conda_env_file = path <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._conda_env_file = expanded_env <TAB> return self._conda_env_file","if scheme == ""file"" or not scheme :",158
"def NullContact(cls, tinfo, uin): <TAB> tmaker = tMaker(tinfo) <TAB> fields = [] <TAB> for row in tmaker.columns.strip().split(""\n""): <TAB>  <TAB> field, ftype = row.strip().split(None, 1) <TAB>  <TAB> if field == ""uin"": <TAB>  <TAB>  <TAB> val = uin <MASK> val = ""uin"" + uin <TAB>  <TAB> elif ftype.startswith(""VARCHAR""): <TAB>  <TAB>  <TAB> val = ""#NULL"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> val = -1 <TAB>  <TAB> fields.append(val) <TAB> return tmaker(*fields)","elif field == ""name"" :",153
"def can_move_back_to_pending(request, current_user, groups): <TAB> if request.get(""status"") in [""cancelled"", ""rejected""]: <TAB>  <TAB> # Don't allow returning requests to pending state if more than a day has passed since the last update <MASK> return False <TAB>  <TAB> # Allow admins to return requests back to pending state <TAB>  <TAB> if can_admin_policies(current_user, groups): <TAB>  <TAB>  <TAB> return True <TAB> return False","if request . get ( ""last_updated"" , 0 ) < int ( time . time ( ) ) - 86400 :",131
"def release(provider, connection, cache=None): <TAB> if cache is not None: <TAB>  <TAB> db_session = cache.db_session <TAB>  <TAB> if db_session is not None and db_session.ddl and cache.saved_fk_state: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> cursor = connection.cursor() <TAB>  <TAB>  <TAB>  <TAB> sql = ""PRAGMA foreign_keys = true"" <MASK> log_orm(sql) <TAB>  <TAB>  <TAB>  <TAB> cursor.execute(sql) <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> provider.pool.drop(connection) <TAB>  <TAB>  <TAB>  <TAB> raise <TAB> DBAPIProvider.release(provider, connection, cache)",if core . local . debug :,162
"def applies(self, filters): <TAB> if filters: <TAB>  <TAB> applicable = False <TAB>  <TAB> for f in filters: <TAB>  <TAB>  <TAB> acceptable_values = f[""values""] <TAB>  <TAB>  <TAB> if f[""name""] == ""instance-state-name"": <MASK> applicable = True <TAB>  <TAB>  <TAB> if f[""name""] == ""instance-state-code"": <TAB>  <TAB>  <TAB>  <TAB> if str(self._state.code) in acceptable_values: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> applicable = True <TAB>  <TAB> return applicable <TAB> # If there are no filters, all instances are valid <TAB> return True",if self . _state . name in acceptable_values :,148
"def read(self, f, start, end): <TAB> for line in f: <TAB>  <TAB> size = len(line) <TAB>  <TAB> if not six.PY2: <TAB>  <TAB>  <TAB> line = line.decode(""utf-8"") <MASK> yield line[:-1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield line <TAB>  <TAB> start += size <TAB>  <TAB> if start >= end: <TAB>  <TAB>  <TAB> break","if line . endswith ( ""\n"" ) :",101
"def bring_view_to_topmost(self, view): <TAB> # move the view to the top of the group <TAB> if not view_is_visible(view): <TAB>  <TAB> window = view.window() <MASK> window_active_view = window.active_view() <TAB>  <TAB>  <TAB> window.focus_view(view) <TAB>  <TAB>  <TAB> # do not refocus if view and active_view are of the same group <TAB>  <TAB>  <TAB> group, _ = window.get_view_index(view) <TAB>  <TAB>  <TAB> if window.get_view_index(window_active_view)[0] != group: <TAB>  <TAB>  <TAB>  <TAB> window.focus_view(window_active_view)",if window :,160
"def validate(self): <TAB> magic = OggPage.MAGIC <TAB> if self.stream.readBytes(0, len(magic)) != magic: <TAB>  <TAB> return ""Invalid magic string"" <TAB> # Validate first 3 pages <TAB> for index in xrange(3): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> page = self[index] <TAB>  <TAB> except MissingField: <TAB>  <TAB>  <TAB> if self.done: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB> return ""Unable to get page #%u"" % index <TAB>  <TAB> except (InputStreamError, ParserError): <TAB>  <TAB>  <TAB> return ""Unable to create page #%u"" % index <TAB>  <TAB> err = page.validate() <MASK> return ""Invalid page #%s: %s"" % (index, err) <TAB> return True",if err :,176
"def encode(self, s): <TAB> s = tf.compat.as_text(s) <TAB> if self.lowercase: <TAB>  <TAB> s = s.lower() <TAB> ids = [] <TAB> for token in self._tokenizer.tokenize(s): <TAB>  <TAB> int_id = self._token_to_id.get(token, -1) <MASK> int_id = self._oov_bucket(token) <TAB>  <TAB>  <TAB> if int_id is None: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""Out of vocabulary token %s"" % token) <TAB>  <TAB> ids.append(int_id) <TAB> # Increment for pad id 0 <TAB> return pad_incr(ids)",if int_id < 0 :,161
"def read(f): <TAB> while True: <TAB>  <TAB> line = f.readline() <TAB>  <TAB> assert line, ""Read an empty line, please check file IO settings"" <TAB>  <TAB> line = line.strip() <MASK> return map(float, line.split())",if line :,66
"def find_cycle(stack, visited): <TAB> if stack[-1] in visited: <TAB>  <TAB> return None <TAB> visited.add(stack[-1]) <TAB> for n in stack[-1].waiting_parents: <TAB>  <TAB> stack.append(n) <TAB>  <TAB> if stack[0] == stack[-1]: <TAB>  <TAB>  <TAB> return stack <MASK> return stack <TAB>  <TAB> stack.pop() <TAB> return None","if find_cycle ( stack , visited ) :",106
"def show_checked_page(self, page_number): <TAB> max_pages = self._source.get_max_pages() <TAB> try: <TAB>  <TAB> if max_pages is None: <TAB>  <TAB>  <TAB> # If it doesn't give maximum pages, it cannot be checked <TAB>  <TAB>  <TAB> await self.show_page(page_number) <MASK> await self.show_page(page_number) <TAB> except IndexError: <TAB>  <TAB> # An error happened that can be handled, so ignore it. <TAB>  <TAB> pass",elif max_pages > page_number >= 0 :,130
"def _printattr(attr, attr_translate): <TAB> r = """" <TAB> firsta = True <TAB> for attr in sorted(attr, key=lambda x: ("""", x) if isinstance(x, str) else x): <TAB>  <TAB> if isinstance(attr, tuple): <TAB>  <TAB>  <TAB> # platform-dependent attribute <TAB>  <TAB>  <TAB> attr_name, attr_value = attr <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # translated attribute <TAB>  <TAB>  <TAB> at = attr_translate[attr] <MASK> continue <TAB>  <TAB>  <TAB> attr_name, attr_value = at <TAB>  <TAB> if not firsta: <TAB>  <TAB>  <TAB> r += "", "" <TAB>  <TAB> firsta = False <TAB>  <TAB> r += attr_name + ' = ""' + attr_value + '""' <TAB> if r: <TAB>  <TAB> r = ""(* "" + r + "" *)"" <TAB> return r",if at is None :,198
"def make_save(expr): <TAB> save_expr = """" <TAB> for char in expr: <MASK> if char in string.ascii_letters or char in string.digits or char in ""._"": <TAB>  <TAB>  <TAB>  <TAB> save_expr += char <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> save_expr += ""_"" <TAB> return save_expr",if char not in string . whitespace :,89
"def find_matching_branches(config, branches): <TAB> if ""branchtag_regex"" in config: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> regex = re.compile(config[""branchtag_regex""]) <TAB>  <TAB>  <TAB> return [ <TAB>  <TAB>  <TAB>  <TAB> branch <TAB>  <TAB>  <TAB>  <TAB> for branch in branches <MASK> ] <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> pass <TAB> return branches","if matches_ref ( ""refs/heads/"" + branch , regex )",105
"def _list_outputs(self): <TAB> outputs = self._outputs().get() <TAB> outputs[""components_file""] = os.path.abspath(self.inputs.components_file) <TAB> save_pre_filter = self.inputs.save_pre_filter <TAB> if save_pre_filter: <MASK> save_pre_filter = os.path.abspath(""pre_filter.tsv"") <TAB>  <TAB> outputs[""pre_filter_file""] = save_pre_filter <TAB> return outputs","if isinstance ( save_pre_filter , bool ) :",125
"def done_prepare(self): <TAB> """"""Touch a sign file after the prepare process is done."""""" <TAB> if self.done_sign != """" and not os.path.exists(self.done_sign): <MASK> os.makedirs(os.path.dirname(self.done_sign)) <TAB>  <TAB> Path(self.done_sign).touch()",if not os . path . exists ( os . path . dirname ( self . done_sign ) ) :,103
"def _close_all(self, actor): <TAB> # Close monitors and actors <TAB> try: <TAB>  <TAB> waiters = [] <TAB>  <TAB> for m in tuple(self.monitors.values()): <TAB>  <TAB>  <TAB> stop = m.stop(exit_code=actor.exit_code) <MASK> waiters.append(stop) <TAB>  <TAB> waiters.append(self._close_actors(actor)) <TAB>  <TAB> await asyncio.gather(*waiters) <TAB> except Exception: <TAB>  <TAB> actor.logger.exception(""Exception while closing arbiter"") <TAB> self._exit_arbiter(actor, True)",if stop :,144
"def convert_to_setting(self, dt=None): <TAB> try: <TAB>  <TAB> if app.TIMEZONE_DISPLAY == ""local"": <TAB>  <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB>  <TAB> dt.astimezone(app_timezone) <MASK> else self.astimezone(app_timezone) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return dt if self is None else self <TAB> except Exception: <TAB>  <TAB> return dt if self is None else self",if self is None,115
"def restart_with_reloader(): <TAB> while True: <TAB>  <TAB> args = [sys.executable] + [""-W%s"" % o for o in sys.warnoptions] + sys.argv <TAB>  <TAB> if sys.platform == ""win32"": <TAB>  <TAB>  <TAB> args = ['""%s""' % arg for arg in args] <TAB>  <TAB> new_environ = os.environ.copy() <TAB>  <TAB> new_environ[""RUN_MAIN""] = ""true"" <TAB>  <TAB> exit_code = os.spawnve(os.P_WAIT, sys.executable, args, new_environ) <MASK> return exit_code",if exit_code != 3 :,147
def last_uploaded(self): <TAB> if self._last_uploaded_time: <TAB>  <TAB> # Check rate limit by time elapsed <TAB>  <TAB> time_elapsed = time.time() - self._last_uploaded_time <MASK> return time_elapsed <TAB>  <TAB> # Check rate limit by size increase <TAB>  <TAB> if float(self._last_uploaded_size) > 0: <TAB>  <TAB>  <TAB> size_increase = self.current_size / float(self._last_uploaded_size) <TAB>  <TAB>  <TAB> if size_increase < self.RATE_LIMIT_SIZE_INCREASE: <TAB>  <TAB>  <TAB>  <TAB> return time_elapsed <TAB> return 0,if time_elapsed < self . RATE_LIMIT_SECONDS :,156
"def _recur_strip(s): <TAB> if isinstance(s, str): <MASK> return "" "".join(s.strip().split()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return "" "".join(s.strip().split()).replace(bos_token + "" "", """") <TAB> else: <TAB>  <TAB> s_ = [_recur_strip(si) for si in s] <TAB>  <TAB> return _maybe_list_to_array(s_, s)","if bos_token == """" :",110
"def stop_if_complete(self) -> bool: <TAB> # returns True on stopping the node and False if this doesn't stop the node <TAB> from ..tasks.main import Task <TAB> node_tasks = NodeTasks.get_by_machine_id(self.machine_id) <TAB> for node_task in node_tasks: <TAB>  <TAB> task = Task.get_by_task_id(node_task.task_id) <TAB>  <TAB> # ignore invalid tasks when deciding if the node should be <TAB>  <TAB> # shutdown <MASK> continue <TAB>  <TAB> if task.state not in TaskState.shutting_down(): <TAB>  <TAB>  <TAB> return False <TAB> logging.info( <TAB>  <TAB> ""node: stopping busy node with all tasks complete: %s"", <TAB>  <TAB> self.machine_id, <TAB> ) <TAB> self.stop() <TAB> return True","if isinstance ( task , Error ) :",199
"def getranking(self, cpeid=None, loosy=True): <TAB> if cpeid is None: <TAB>  <TAB> return False <TAB> result = False <TAB> if loosy: <TAB>  <TAB> for x in cpeid.split("":""): <TAB>  <TAB>  <TAB> if x is not """": <TAB>  <TAB>  <TAB>  <TAB> i = db.findRanking(x, regex=True) <MASK> continue <TAB>  <TAB>  <TAB> if ""rank"" in i: <TAB>  <TAB>  <TAB>  <TAB> result = i[""rank""] <TAB> else: <TAB>  <TAB> i = db.findRanking(cpeid, regex=True) <TAB>  <TAB> if i is None: <TAB>  <TAB>  <TAB> return result <TAB>  <TAB> if ""rank"" in i: <TAB>  <TAB>  <TAB> result = i[""rank""] <TAB> return result",if i is None :,181
"def _enqueue_event(self, mid, eventdata, size, queue): <TAB> with self._lock: <TAB>  <TAB> if mid not in queue: <TAB>  <TAB>  <TAB> queue[mid] = [eventdata] <TAB>  <TAB>  <TAB> self._trigger_publish() <TAB>  <TAB>  <TAB> return <MASK> if len(queue[mid]) >= size: <TAB>  <TAB>  <TAB>  <TAB> queue[mid].pop(0) <TAB>  <TAB> queue[mid].append(eventdata)",if size != 0 :,109
"def act(self): <TAB> for size in self.sizes: <TAB>  <TAB> option_name = ""size_{:d}"".format(size) <MASK> self._windows.close() <TAB>  <TAB>  <TAB> # the empty list is interpreted as the empty list of random map island strings <TAB>  <TAB>  <TAB> options = StartGameOptions.create_editor_load([]) <TAB>  <TAB>  <TAB> options.map_padding = size // 2 <TAB>  <TAB>  <TAB> horizons.main.start_singleplayer(options) <TAB>  <TAB>  <TAB> return",if self . _gui . findChild ( name = option_name ) . marked :,133
"def process_word(word): <TAB> if word.parent == ""remapping"": <TAB>  <TAB> raise UDError(""There is a cycle in a sentence"") <TAB> if word.parent is None: <TAB>  <TAB> head = int(word.columns[HEAD]) <MASK> raise UDError( <TAB>  <TAB>  <TAB>  <TAB> ""HEAD '{}' points outside of the sentence"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _encode(word.columns[HEAD]) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if head: <TAB>  <TAB>  <TAB> parent = ud.words[sentence_start + head - 1] <TAB>  <TAB>  <TAB> word.parent = ""remapping"" <TAB>  <TAB>  <TAB> process_word(parent) <TAB>  <TAB>  <TAB> word.parent = parent",if head < 0 or head > len ( ud . words ) - sentence_start :,182
"def stream_response(self, send: Send) -> None: <TAB> await send( <TAB>  <TAB> { <TAB>  <TAB>  <TAB> ""type"": ""http.response.start"", <TAB>  <TAB>  <TAB> ""status"": self.status_code, <TAB>  <TAB>  <TAB> ""headers"": self.raw_headers, <TAB>  <TAB> } <TAB> ) <TAB> async for chunk in self.body_iterator: <MASK> chunk = chunk.encode(self.charset) <TAB>  <TAB> await send({""type"": ""http.response.body"", ""body"": chunk, ""more_body"": True}) <TAB> await send({""type"": ""http.response.body"", ""body"": b"""", ""more_body"": False})","if not isinstance ( chunk , bytes ) :",161
"def _init_inheritable_dicts_(cls): <TAB> for attr in cls._additional_inheritable_dict_attrs_: <MASK> attr_name, default = attr <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> attr_name, default = attr, {} <TAB>  <TAB> if not isinstance(default, dict): <TAB>  <TAB>  <TAB> raise SyntaxError(""{} is not a dictionary"".format(attr_name)) <TAB>  <TAB> setattr(cls, attr_name, default)","if isinstance ( attr , tuple ) :",109
"def is_application_code(self): <TAB> if self.identifier: <TAB>  <TAB> file_path = self.file_path <TAB>  <TAB> if (""%slib%s"" % (os.sep, os.sep)) in file_path: <TAB>  <TAB>  <TAB> return False <MASK> if file_path.startswith(""<ipython-input-""): <TAB>  <TAB>  <TAB>  <TAB> # lines typed at a console or in a notebook are app code <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> # otherwise, this is probably some library-internal code gen <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True","if file_path . startswith ( ""<"" ) :",145
"def set_provider_item(self, items, required=False): <TAB> """"""set a provider item based on the list of item names provided."""""" <TAB> for item in items: <TAB>  <TAB> provider_key = items[0] <TAB>  <TAB> if item in self._idp: <TAB>  <TAB>  <TAB> self.provider[provider_key] = self._idp.pop(item) <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> default = self.get_default(provider_key) <MASK> self.provider[provider_key] = default <TAB>  <TAB> elif required: <TAB>  <TAB>  <TAB> raise errors.AnsibleFilterError( <TAB>  <TAB>  <TAB>  <TAB> ""|failed provider {0} missing "" <TAB>  <TAB>  <TAB>  <TAB> ""required key {1}"".format(self.__class__.__name__, provider_key) <TAB>  <TAB>  <TAB> )",if default is not None :,184
"def run(): <TAB> await sleep(10, loop=loop) <TAB> print(""Connecting..."") <TAB> await driver.connect() <TAB> print(""Wait for login..."") <TAB> await driver.wait_for_login() <TAB> for contact in await driver.get_unread(): <MASK> break <TAB>  <TAB> for message in contact.messages: <TAB>  <TAB>  <TAB> if isinstance(message, Message):  # Currently works for text messages only. <TAB>  <TAB>  <TAB>  <TAB> print(""Message from {}: {}"".format(message.sender, message.content)) <TAB>  <TAB>  <TAB>  <TAB> print(""Resending..."") <TAB>  <TAB>  <TAB>  <TAB> contact.chat.chat_send_message(message.safe_content) <TAB>  <TAB> await sleep(1, loop=loop) <TAB> await driver.quit()",if Task . current_task ( ) . cancelled ( ) :,177
"def perform_destroy(self, instance): <TAB> data = self.request.data[""data""] <TAB> user = self.request.user <TAB> ids = [datum[""id""] for datum in data] <TAB> nodes = [] <TAB> for id_ in ids: <TAB>  <TAB> node = Node.load(id_) <MASK> raise exceptions.PermissionDenied( <TAB>  <TAB>  <TAB>  <TAB> detail=""Write permission on node {} required"".format(id_) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> nodes.append(node) <TAB> for node in nodes: <TAB>  <TAB> node.remove_affiliated_institution(inst=instance[""self""], user=user) <TAB>  <TAB> node.save()","if not node . has_permission ( user , osf_permissions . WRITE ) :",173
def test_write_non_existing(self): <TAB> for t in format_types: <MASK> continue <TAB>  <TAB> instance = AudioFile.__new__(t) <TAB>  <TAB> instance.sanitize(self.filename) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> instance.write() <TAB>  <TAB> except AudioFileError: <TAB>  <TAB>  <TAB> pass,if not t . is_file :,85
"def _descendants(self, s, fn): <TAB> handles = [] <TAB> adding = 0 <TAB> for line in s.split(""\n""): <TAB>  <TAB> if line.endswith(""child:"") or line.endswith(""children:""): <MASK> adding = 1 <TAB>  <TAB> elif adding and line: <TAB>  <TAB>  <TAB> handle, name = self._get_descendant_handle_and_name(line) <TAB>  <TAB>  <TAB> if fn(name): <TAB>  <TAB>  <TAB>  <TAB> handles.append(handle) <TAB> return [Window(handle) for handle in handles]",if not adding :,128
"def _fixup_types(self, api, items): <TAB> # Update our replay profiles. <TAB> for item in items: <MASK> # Re-apply any appropriate replay profiles. <TAB>  <TAB>  <TAB> item[""status""] = ""available"" <TAB>  <TAB>  <TAB> rps = item[""specs""][""replay_profile_string""] <TAB>  <TAB>  <TAB> if rps: <TAB>  <TAB>  <TAB>  <TAB> svol = api.get_volume(item[""nvol""]) <TAB>  <TAB>  <TAB>  <TAB> if not api.update_replay_profiles(svol, rps): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> item[""status""] = ""error""","if item [ ""status"" ] == ""reattached"" :",145
"def _lookup_logs(logs_model, start_time, end_time, **kwargs): <TAB> logs_found = [] <TAB> page_token = None <TAB> while True: <TAB>  <TAB> found = logs_model.lookup_logs( <TAB>  <TAB>  <TAB> start_time, end_time, page_token=page_token, **kwargs <TAB>  <TAB> ) <TAB>  <TAB> logs_found.extend(found.logs) <TAB>  <TAB> page_token = found.next_page_token <MASK> break <TAB> assert len(logs_found) == len(set(logs_found)) <TAB> return logs_found",if not found . logs or not page_token :,150
"def get_pe_subsystem(filename): <TAB> with open(filename, ""rb"") as f: <TAB>  <TAB> if f.read(2) != six.b(""MZ""): <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> f.seek(LFANEW_OFFSET) <TAB>  <TAB> lfanew = struct.unpack(""L"", f.read(4))[0] <TAB>  <TAB> f.seek(lfanew) <MASK> return None <TAB>  <TAB> f.seek(FILE_HEADER_SIZE + SUBSYSTEM_OFFSET, 1) <TAB>  <TAB> subsystem = struct.unpack(""H"", f.read(2))[0] <TAB>  <TAB> return subsystem","if f . read ( 4 ) != six . b ( ""PE\x00\x00"" ) :",168
"def do_draw(self, data): <TAB> while True: <TAB>  <TAB> data.start_example(FLOAT_STRATEGY_DO_DRAW_LABEL) <TAB>  <TAB> i = self.sampler.sample(data) <TAB>  <TAB> if i == 0: <TAB>  <TAB>  <TAB> result = flt.draw_float(data) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result = self.nasty_floats[i - 1] <TAB>  <TAB>  <TAB> flt.write_float(data, result) <MASK> data.stop_example() <TAB>  <TAB>  <TAB> if self.width < 64: <TAB>  <TAB>  <TAB>  <TAB> return float_of(result, self.width) <TAB>  <TAB>  <TAB> return result <TAB>  <TAB> data.stop_example(discard=True)",if self . permitted ( result ) :,174
"def restore_states(self): <TAB> """"""Restore the states of files that are currently open."""""" <TAB> for file in self.app.get_files(): <TAB>  <TAB> path = file.get_path() <TAB>  <TAB> if path in self.storage.get_data().keys(): <TAB>  <TAB>  <TAB> state = self.storage[path] <TAB>  <TAB>  <TAB> if ""hash"" not in state: <TAB>  <TAB>  <TAB>  <TAB> self.set_file_state(file, state) <MASK> self.set_file_state(file, state)","elif state [ ""hash"" ] == self . get_hash ( file . get_editor ( ) ) :",141
"def process_scope(scope): <TAB> if isinstance(scope, tree.Function): <TAB>  <TAB> # process all children after name node, <TAB>  <TAB> # (otherwise name of global function will be marked as local def) <TAB>  <TAB> local_names = set() <TAB>  <TAB> global_names = set() <TAB>  <TAB> for child in scope.children[2:]: <TAB>  <TAB>  <TAB> process_node(child, local_names, global_names) <TAB> else: <MASK> for child in scope.subscopes: <TAB>  <TAB>  <TAB>  <TAB> process_scope(child) <TAB>  <TAB> elif hasattr(scope, ""children""): <TAB>  <TAB>  <TAB> for child in scope.children: <TAB>  <TAB>  <TAB>  <TAB> process_scope(child)","if hasattr ( scope , ""subscopes"" ) :",167
"def emit(self, record): <TAB> try: <TAB>  <TAB> message = stdout_encode(self.format(record)) <TAB>  <TAB> stream = self.stream <TAB>  <TAB> if not self.is_tty: <MASK> message = message[1:] <TAB>  <TAB>  <TAB> stream.write(message) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.output_colorized(message) <TAB>  <TAB> stream.write(getattr(self, ""terminator"", ""\n"")) <TAB>  <TAB> self.flush() <TAB> except (KeyboardInterrupt, SystemExit): <TAB>  <TAB> raise <TAB> except IOError: <TAB>  <TAB> pass <TAB> except Exception as e: <TAB>  <TAB> self.handleError(record)","if message and message [ 0 ] == ""\r"" :",160
"def _focus_body(browser, num_tries=5): <TAB> for i in range(num_tries): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> browser.execute_script(""$('body').focus();"") <TAB>  <TAB> except WebDriverException: <MASK> raise <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> print(""Couldn't focus body, waiting and trying again..."") <TAB>  <TAB>  <TAB>  <TAB> time.sleep(1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break",if i == ( num_tries - 1 ) :,117
"def __post_execution(self): <TAB> """"""Execute a script after executing the project."""""" <TAB> filePostExec = QFile(self.postExec) <TAB> if filePostExec.exists() and bool(QFile.ExeUser & filePostExec.permissions()): <TAB>  <TAB> ext = file_manager.get_file_extension(self.postExec) <MASK> self.pythonPath = settings.PYTHON_PATH <TAB>  <TAB> self.currentProcess = self._postExecScriptProc <TAB>  <TAB> if ext == ""py"": <TAB>  <TAB>  <TAB> self._postExecScriptProc.start(self.pythonPath, [self.postExec]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._postExecScriptProc.start(self.postExec)",if not self . pythonPath :,173
"def default(self, value): <TAB> try: <TAB>  <TAB> if np.isnan(value): <TAB>  <TAB>  <TAB> return self.nan_str <MASK> return value.tolist() <TAB>  <TAB> if issubclass(type(value), numbers.Integral): <TAB>  <TAB>  <TAB> return int(value) <TAB>  <TAB> if issubclass(type(value), numbers.Number): <TAB>  <TAB>  <TAB> return float(value) <TAB>  <TAB> return super(SafeFallbackEncoder, self).default(value) <TAB> except Exception: <TAB>  <TAB> return str(value)  # give up, just stringify it (ok for logs)","if type ( value ) . __module__ == np . __name__ and isinstance ( value , np . ndarray ) :",153
"def _target(self, cb=None, exc=None, wait=0): <TAB> total = 0 <TAB> for i, c in enumerate(""abc"", 1): <TAB>  <TAB> total += i <TAB>  <TAB> if wait: <TAB>  <TAB>  <TAB> sleep(wait) <TAB>  <TAB> if cb: <TAB>  <TAB>  <TAB> cb(i, c, intermediate_total=total) <MASK> raise exc(""error in target"") <TAB> return total",if exc :,100
"def _send_request(self, request, *args, want_reply=False): <TAB> """"""Send a channel request"""""" <TAB> if request == b""exit-signal"": <TAB>  <TAB> if args[0] == String(""invalid""): <TAB>  <TAB>  <TAB> args = (String(b""\xff""),) + args[1:] <MASK> args = args[:3] + (String(b""\xff""),) <TAB> super()._send_request(request, *args, want_reply=want_reply)","if args [ 3 ] == String ( ""invalid"" ) :",122
"def close(self): <TAB> ""Extend EditorWindow.close()"" <TAB> if self.executing: <TAB>  <TAB> response = tkMessageBox.askokcancel( <TAB>  <TAB>  <TAB> ""Kill?"", <TAB>  <TAB>  <TAB> ""The program is still running!\n Do you want to kill it?"", <TAB>  <TAB>  <TAB> default=""ok"", <TAB>  <TAB>  <TAB> parent=self.text, <TAB>  <TAB> ) <MASK> return ""cancel"" <TAB> if self.reading: <TAB>  <TAB> self.top.quit() <TAB> self.canceled = True <TAB> self.closing = True <TAB> # Wait for poll_subprocess() rescheduling to stop <TAB> self.text.after(2 * self.pollinterval, self.close2)",if response is False :,162
"def map_bool(data: Any) -> bool: <TAB> if not isinstance(data, bool): <TAB>  <TAB> # Be lenient. <TAB>  <TAB> if isinstance(data, int): <TAB>  <TAB>  <TAB> if data == 0: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> if data == 1: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> if isinstance(data, str): <MASK> return True <TAB>  <TAB>  <TAB> if data.lower() in FALSE_STRINGS: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> raise DeepTypeError(""Not a bool"") <TAB> return data",if data . lower ( ) in TRUE_STRINGS :,143
"def load_schemas_from_git(ref, target_dir=""schemas""): <TAB> tree = ecs_helpers.get_tree_by_ref(ref) <TAB> fields_nested = {} <TAB> # Handles case if target dir doesn't exists in git ref <TAB> if ecs_helpers.path_exists_in_git_tree(tree, target_dir): <TAB>  <TAB> for blob in tree[target_dir].blobs: <MASK> new_fields = read_schema_blob(blob, ref) <TAB>  <TAB>  <TAB>  <TAB> fields_nested = ecs_helpers.safe_merge_dicts(fields_nested, new_fields) <TAB> else: <TAB>  <TAB> raise KeyError( <TAB>  <TAB>  <TAB> f""Target directory './{target_dir}' not present in git ref '{ref}'!"" <TAB>  <TAB> ) <TAB> return fields_nested","if blob . name . endswith ( "".yml"" ) :",199
"def cache_buster(context, url): <TAB> if ""BUILD_ID"" in context: <TAB>  <TAB> build = context[""BUILD_ID""] <TAB> else: <TAB>  <TAB> if url.endswith("".js""): <TAB>  <TAB>  <TAB> build = context[""BUILD_ID_JS""] <MASK> build = context[""BUILD_ID_CSS""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> build = context[""BUILD_ID_IMG""] <TAB> return utils.urlparams(url, b=build)","elif url . endswith ( "".css"" ) :",118
"def _gen_pythons(self): <TAB> sys.path.insert(0, join(self.dir, ""externals"", ""which"")) <TAB> import which  # get it from http://trentm.com/projects/which <TAB> python_from_ver = {} <TAB> for name in self._gen_python_names(): <TAB>  <TAB> for python in which.whichall(name): <TAB>  <TAB>  <TAB> ver = self._python_ver_from_python(python) <MASK> python_from_ver[ver] = python <TAB> for ver, python in sorted(python_from_ver.items()): <TAB>  <TAB> yield ver, python",if ver not in python_from_ver :,159
"def scan_resource_conf(self, conf): <TAB> bucket_name = conf[""name""] <TAB> # check fot logging <TAB> if ""logging"" in conf.keys(): <TAB>  <TAB> if conf[""logging""][0][""log_bucket""]: <TAB>  <TAB>  <TAB> log_bucket_name = conf[""logging""][0][""log_bucket""] <MASK> return CheckResult.PASSED <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return CheckResult.FAILED <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return CheckResult.FAILED <TAB>  <TAB> return CheckResult.FAILED <TAB> return CheckResult.UNKNOWN",if log_bucket_name != bucket_name :,146
"def check_content_function(token): <TAB> function = parse_function(token) <TAB> if function is None: <TAB>  <TAB> return <TAB> name, args = function <TAB> if name == ""content"": <MASK> return (""content()"", ""text"") <TAB>  <TAB> elif len(args) == 1: <TAB>  <TAB>  <TAB> ident = args.pop(0) <TAB>  <TAB>  <TAB> if ident.type == ""ident"" and ident.lower_value in ( <TAB>  <TAB>  <TAB>  <TAB> ""text"", <TAB>  <TAB>  <TAB>  <TAB> ""before"", <TAB>  <TAB>  <TAB>  <TAB> ""after"", <TAB>  <TAB>  <TAB>  <TAB> ""first-letter"", <TAB>  <TAB>  <TAB>  <TAB> ""marker"", <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> return (""content()"", ident.lower_value)",if len ( args ) == 0 :,173
"def _equal(self, item, col_name, value): <TAB> source_value = getattr(item, col_name) <TAB> try: <TAB>  <TAB> # whatever we have to copare it will never match <TAB>  <TAB> if source_value is None: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> # date has special constructor, tested only on sqlite <MASK> value = datetime.strptime(value, ""%Y-%m-%d"").date() <TAB>  <TAB> # fallback to native python types <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = type(source_value)(value) <TAB>  <TAB> return source_value == value <TAB> except Exception: <TAB>  <TAB> # when everything fails silently report False <TAB>  <TAB> return False","elif isinstance ( source_value , date ) :",166
"def minDeltaMJD(inputMJD, im_List): <TAB> # returns the image whose MJD most closely matches the inputMJD <TAB> index = 0 <TAB> minDelta = 10000 <TAB> for i in range(len(im_List)): <TAB>  <TAB> oldDelta = minDelta <TAB>  <TAB> minDelta = min(minDelta, abs(inputMJD - im_List[i].mjd)) <MASK> index = i <TAB> # return im_List[index].copy() <TAB> return index",if not ( minDelta == oldDelta ) :,131
"def run_process(args): <TAB> try: <TAB>  <TAB> proc = subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.STDOUT) <TAB>  <TAB> dat = """" <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> line = proc.stdout.readline() <MASK> break <TAB>  <TAB>  <TAB> dat += str(line) <TAB>  <TAB> return dat <TAB> except Exception: <TAB>  <TAB> logger.error(""Finding Java path - Cannot Run Process"") <TAB>  <TAB> return """"",if not line :,113
"def _get_item_index(self, ident): <TAB> ""Get the index for the item with this 'ident'"" <TAB> if isinstance(ident, int): <TAB>  <TAB> if ident >= self.ItemCount(): <TAB>  <TAB>  <TAB> raise IndexError( <TAB>  <TAB>  <TAB>  <TAB> ""Combobox has %d items, you requested item %d (0 based)"" <TAB>  <TAB>  <TAB>  <TAB> % (self.ItemCount(), ident) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> # negative index <MASK> # convert it to a positive index <TAB>  <TAB>  <TAB> ident = self.ItemCount() + ident <TAB> elif isinstance(ident, str): <TAB>  <TAB> # todo - implement fuzzy lookup for ComboBox items <TAB>  <TAB> # todo - implement appdata lookup for combobox items <TAB>  <TAB> ident = self.ItemTexts().index(ident) <TAB> return ident",if ident < 0 :,189
"def do_report_error(self, response): <TAB> """"""Report a codeintel error into the error log"""""" <TAB> message = response.get(""message"") <TAB> if message: <TAB>  <TAB> stack = response.get(""stack"") <MASK> self._codeintel_logger.error(message.rstrip() + ""\n"" + stack) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._codeintel_logger.error(message.rstrip())",if stack :,106
"def __getattr__(self, key): <TAB> if key in self._raw: <TAB>  <TAB> val = self._raw[key] <MASK> return pd.Timestamp(val) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return val <TAB> return super().__getattr__(key)","if key in ( ""timestamp"" , ""next_open"" , ""next_close"" ) :",79
"def addWriter(self, writer): <TAB> if writer in self._writers: <TAB>  <TAB> return <TAB> fd = writer.fileno() <TAB> self._writers[writer] = fd <TAB> if fd in self._fds: <TAB>  <TAB> (reader, _) = self._fds[fd] <TAB>  <TAB> self._fds[fd] = (reader, writer) <MASK> # We already registered this fd for read events, <TAB>  <TAB>  <TAB> # update it for write events as well. <TAB>  <TAB>  <TAB> self._io_loop.update_handler(fd, IOLoop.READ | IOLoop.WRITE) <TAB> else: <TAB>  <TAB> with NullContext(): <TAB>  <TAB>  <TAB> self._fds[fd] = (None, writer) <TAB>  <TAB>  <TAB> self._io_loop.add_handler(fd, self._invoke_callback, IOLoop.WRITE)",if reader :,191
"def program_equal(a, b): <TAB> for k, v in six.iteritems(a.__dict__): <TAB>  <TAB> if isinstance(v, core.ProgramDesc): <TAB>  <TAB>  <TAB> continue <MASK> for i in range(0, len(a.blocks)): <TAB>  <TAB>  <TAB>  <TAB> if not block_equal(a.blocks[i], b.blocks[i]): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""In operator_equal not equal:{0}\n"".format(k)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> assert len(a.blocks) == len(b.blocks) <TAB>  <TAB> elif v != b.__dict__[k]: <TAB>  <TAB>  <TAB> raise ValueError(""In program_equal not equal:{0}\n"".format(k)) <TAB> return True","elif k == ""blocks"" :",181
"def _wrapper(*args, **kwargs): <TAB> """"""Regular function wrapper."""""" <TAB> from metrics import monitoring_metrics <TAB> for num_try in range(1, tries + 1): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> result = func(*args, **kwargs) <MASK> if not handle_retry(num_try): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return result <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> monitoring_metrics.TRY_COUNT.increment( <TAB>  <TAB>  <TAB>  <TAB> {""function"": function, ""is_succeeded"": True} <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return result <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> if not handle_retry(num_try, exception=e): <TAB>  <TAB>  <TAB>  <TAB> raise",if retry_on_false and not result :,175
"def items_to_show(self): <TAB> """"""Present errors as list of lists."""""" <TAB> contents = [] <TAB> for error_dict in self.errors: <TAB>  <TAB> error_type = ""ERROR"" <MASK> error_type = ""WARNING"" <TAB>  <TAB> contents.append( <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB> ErrorQuickPanelHandler.ENTRY_TEMPLATE.format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> type=error_type, error=error_dict[""error""] <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB>  <TAB> error_dict[""file""], <TAB>  <TAB>  <TAB> ] <TAB>  <TAB> ) <TAB> return contents","if error_dict [ ""severity"" ] < MIN_ERROR_SEVERITY :",155
"def on_done(self, idx): <TAB> if idx >= 0: <TAB>  <TAB> selected = self.select_candidates[idx] <MASK> self.view.window().open_file(selected[0][1], sublime.ENCODED_POSITION) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.view.window().open_file(selected[0][1])",if selected [ 1 ] :,92
"def _check_bom(self): <TAB> # Normalize our encoding name <TAB> enc = re.sub(""[ -]"", """", self.encoding.lower()) <TAB> # Look up our encoding in the BOM table. <TAB> bom_info = self._BOM_TABLE.get(enc) <TAB> if bom_info: <TAB>  <TAB> # Read a prefix, to check against the BOM(s) <TAB>  <TAB> bytes = self.stream.read(16) <TAB>  <TAB> self.stream.seek(0) <TAB>  <TAB> # Check for each possible BOM. <TAB>  <TAB> for (bom, new_encoding) in bom_info: <MASK> if new_encoding: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.encoding = new_encoding <TAB>  <TAB>  <TAB>  <TAB> return len(bom) <TAB> return None",if bytes . startswith ( bom ) :,182
"def __getattr__(self, attr): <TAB> ret = getattr(self._ob, attr)  # Attribute error just goes up <TAB> # If not collecting, or we have any methods, and ours isn't listed, don't profile. <TAB> methods = self._methods <TAB> if (not self._profiler_service_.collecting) or ( <TAB>  <TAB> methods is not None and not methods.has_key(attr) <TAB> ): <TAB>  <TAB> return ret <TAB> if callable(ret): <TAB>  <TAB> return TracerDelegate(ret) <TAB> else: <MASK> ps = self._profiler_service_ <TAB>  <TAB>  <TAB> ps.getter_accesses[attr] = ps.getter_accesses.setdefault(attr, 0) + 1 <TAB>  <TAB> return ret","if not attr . startswith ( ""_com_"" ) and not attr . startswith ( ""_reg_"" ) :",187
"def _get_vdisk_create_params(opts): <TAB> intier = ""on"" if opts[""intier""] else ""off"" <TAB> if opts[""rsize""] == -1: <TAB>  <TAB> params = [] <TAB> else: <TAB>  <TAB> params = [ <TAB>  <TAB>  <TAB> ""-rsize"", <TAB>  <TAB>  <TAB> ""%s%%"" % str(opts[""rsize""]), <TAB>  <TAB>  <TAB> ""-autoexpand"", <TAB>  <TAB>  <TAB> ""-warning"", <TAB>  <TAB>  <TAB> ""%s%%"" % str(opts[""warning""]), <TAB>  <TAB> ] <TAB>  <TAB> if not opts[""autoexpand""]: <TAB>  <TAB>  <TAB> params.remove(""-autoexpand"") <MASK> params.append(""-compressed"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> params.extend([""-grainsize"", str(opts[""grainsize""])]) <TAB> params.extend([""-intier"", intier]) <TAB> return params","if opts [ ""compression"" ] :",195
"def __del__(self) -> None: <TAB> if self._protocol is not None: <TAB>  <TAB> message = ""Unclosed connection: {!r}"".format(self) <TAB>  <TAB> warnings.warn(message, ResourceWarning) <MASK> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.close() <TAB>  <TAB>  <TAB> self._loop.call_exception_handler({""message"": message})",if self . _loop . is_closed ( ) :,98
"def layers(self, features): <TAB> for i, f in enumerate(self.in_features): <MASK> x = self.scale_heads[i](features[f]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> x = x + self.scale_heads[i](features[f]) <TAB> x = self.predictor(x) <TAB> return x",if i == 0 :,88
"def export_item(self, item): <TAB> # Double-checked locking (safe in Python because of GIL) https://en.wikipedia.org/wiki/Double-checked_locking <MASK> with self._write_headers_lock: <TAB>  <TAB>  <TAB> if self._headers_not_written: <TAB>  <TAB>  <TAB>  <TAB> self._write_headers_and_set_fields_to_export(item) <TAB>  <TAB>  <TAB>  <TAB> self._headers_not_written = False <TAB> fields = self._get_serialized_fields(item, default_value="""", include_empty=True) <TAB> values = list(self._build_row(x for _, x in fields)) <TAB> self.csv_writer.writerow(values)",if self . _headers_not_written :,170
"def wrap(request, *args, **kwargs): <TAB> ""Wrap"" <TAB> user = request.user.profile <TAB> if ""massform"" in request.POST: <TAB>  <TAB> for key in request.POST: <TAB>  <TAB>  <TAB> if ""mass-item"" in key: <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> item = KnowledgeItem.objects.get(pk=request.POST[key]) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> form = MassActionForm(user, request.POST, instance=item) <MASK> form.save() <TAB>  <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass <TAB> return f(request, *args, **kwargs)","if form . is_valid ( ) and user . has_permission ( item , mode = ""w"" ) :",181
"def convert_blkio_config(blkio_config): <TAB> result = {} <TAB> if blkio_config is None: <TAB>  <TAB> return result <TAB> result[""weight""] = blkio_config.get(""weight"") <TAB> for field in [ <TAB>  <TAB> ""device_read_bps"", <TAB>  <TAB> ""device_read_iops"", <TAB>  <TAB> ""device_write_bps"", <TAB>  <TAB> ""device_write_iops"", <TAB>  <TAB> ""weight_device"", <TAB> ]: <MASK> continue <TAB>  <TAB> arr = [] <TAB>  <TAB> for item in blkio_config[field]: <TAB>  <TAB>  <TAB> arr.append({k.capitalize(): v for k, v in item.items()}) <TAB>  <TAB> result[field] = arr <TAB> return result",if field not in blkio_config :,180
"def handle_read(self, c): <TAB> if self.child_active: <TAB>  <TAB> if c == util.KEY_ESC:  # leave child on esc <TAB>  <TAB>  <TAB> self.child_active = False <TAB>  <TAB>  <TAB> return util.ReadState.READ <TAB>  <TAB> # pass keys through to child <TAB>  <TAB> return self.child.handle_read(c) <TAB> else: <MASK> self.set_value(not self.checked) <TAB>  <TAB>  <TAB> return util.ReadState.CHANGED <TAB>  <TAB> if (self.checked or self.child_always_visible) and c == curses.KEY_RIGHT: <TAB>  <TAB>  <TAB> self.child_active = True <TAB>  <TAB>  <TAB> return util.ReadState.READ <TAB> return util.ReadState.IGNORED",if c == util . KEY_SPACE :,183
"def valid_value(self, value): <TAB> ""Check to see if the provided value is a valid choice"" <TAB> for k, v in self.choices: <MASK> # This is an optgroup, so look inside the group for options <TAB>  <TAB>  <TAB> for k2, v2 in v: <TAB>  <TAB>  <TAB>  <TAB> if value == smart_unicode(k2): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if value == smart_unicode(k): <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False","if isinstance ( v , ( list , tuple ) ) :",131
"def set_name_group_mapping(self, name, group): <TAB> if not self.readonly: <TAB>  <TAB> # Start transaction <TAB>  <TAB> with BSDDBTxn(self.env, self.name_group) as txn: <TAB>  <TAB>  <TAB> sname = name.encode(""utf-8"") <TAB>  <TAB>  <TAB> data = txn.get(sname) <MASK> txn.delete(sname) <TAB>  <TAB>  <TAB> if group is not None: <TAB>  <TAB>  <TAB>  <TAB> txn.put(sname, group) <TAB>  <TAB> if group is None: <TAB>  <TAB>  <TAB> grouppar = """" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> grouppar = group <TAB>  <TAB> self.emit(""person-groupname-rebuild"", (name, grouppar))",if data is not None :,172
"def list_grid(self, trans, **kwargs): <TAB> """"""List user's stored workflows."""""" <TAB> # status = message = None <TAB> if ""operation"" in kwargs: <TAB>  <TAB> operation = kwargs[""operation""].lower() <MASK> return self.rename(trans, **kwargs) <TAB>  <TAB> history_ids = util.listify(kwargs.get(""id"", [])) <TAB>  <TAB> if operation == ""sharing"": <TAB>  <TAB>  <TAB> return self.sharing(trans, id=history_ids) <TAB> return self.stored_list_grid(trans, **kwargs)","if operation == ""rename"" :",135
"def __del__(self): <TAB> try: <TAB>  <TAB> if self._matrix: <TAB>  <TAB>  <TAB> res = gdiplus.GdipDeleteMatrix(self._matrix) <TAB>  <TAB> if self._brush: <TAB>  <TAB>  <TAB> res = gdiplus.GdipDeleteBrush(self._brush) <TAB>  <TAB> if self._graphics: <TAB>  <TAB>  <TAB> res = gdiplus.GdipDeleteGraphics(self._graphics) <MASK> res = gdiplus.GdipDisposeImage(self._bitmap) <TAB>  <TAB> if self._dc: <TAB>  <TAB>  <TAB> res = user32.ReleaseDC(0, self._dc) <TAB> except: <TAB>  <TAB> pass",if self . _bitmap :,161
"def find_static(function_node): <TAB> tokens = [] <TAB> static_found = False <TAB> for node in function_node.body: <TAB>  <TAB> if node.name == ""static"": <TAB>  <TAB>  <TAB> static_found = True <TAB>  <TAB> if static_found: <TAB>  <TAB>  <TAB> tokens.append(node) <MASK> body = list(ast.ASTBuilder(iter(tokens), filename).generate()) <TAB>  <TAB>  <TAB>  <TAB> _find_warnings(filename, lines, body, False) <TAB>  <TAB>  <TAB>  <TAB> tokens = [] <TAB>  <TAB>  <TAB>  <TAB> static_found = False","if node . name == "";"" :",139
"def copyTreeWithMD5(src, dst): <TAB> """"""Copies the tree but checks SHA for each file first"""""" <TAB> # despite time to check the md5 hashes this func gives speed-up <TAB> # over about 20% over using shutil.rmtree() and copytree() <TAB> for root, subDirs, files in os.walk(src): <TAB>  <TAB> relPath = os.path.relpath(root, src) <TAB>  <TAB> for thisDir in subDirs: <MASK> os.makedirs(join(root, thisDir)) <TAB>  <TAB> for thisFile in files: <TAB>  <TAB>  <TAB> copyFileWithMD5(join(root, thisFile), join(dst, relPath, thisFile))","if not os . path . isdir ( join ( root , thisDir ) ) :",172
"def to_python(self, value): <TAB> if isinstance(self.crypt.primary_key, keyczar.keys.RsaPublicKey): <TAB>  <TAB> retval = value <TAB> elif value and (value.startswith(self.prefix)): <TAB>  <TAB> if hasattr(self.crypt, ""Decrypt""): <TAB>  <TAB>  <TAB> retval = self.crypt.Decrypt(value[len(self.prefix) :]) <MASK> retval = retval.decode(""utf-8"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> retval = value <TAB> else: <TAB>  <TAB> retval = value <TAB> return retval",if six . PY2 and retval :,140
"def parse(self, file): <TAB> file = EncodedIO(file) <TAB> file = io.TextIOWrapper(file, encoding=file.encoding) <TAB> while True: <TAB>  <TAB> batch = list(itertools.islice(file, settings.IMPORT_BATCH_SIZE)) <MASK> break <TAB>  <TAB> yield [{""text"": line.strip()} for line in batch]",if not batch :,88
"def verify_img(self, filename): <TAB> with handle_opencv_image_error(logger): <TAB>  <TAB> image = OpenCVImgRepr.from_image_file(filename) <TAB>  <TAB> img_size = image.get_size() <TAB>  <TAB> expected = self._task_definition.resolution <MASK> return True <TAB>  <TAB> logger.warning( <TAB>  <TAB>  <TAB> ""Bad resolution\nExpected %sx%s, but got %sx%s"", <TAB>  <TAB>  <TAB> expected[0], <TAB>  <TAB>  <TAB> expected[1], <TAB>  <TAB>  <TAB> img_size[0], <TAB>  <TAB>  <TAB> img_size[1], <TAB>  <TAB> ) <TAB> return False",if tuple ( img_size ) == tuple ( expected ) :,163
"def _parse_size(value): <TAB> try: <MASK> value_type = ""px"" <TAB>  <TAB>  <TAB> value = float(value) <TAB>  <TAB>  <TAB> assert value > 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value_type = ""%"" <TAB>  <TAB>  <TAB> value = float(value.strip(""%"")) <TAB>  <TAB>  <TAB> assert 0 <= value <= 100 <TAB> except Exception: <TAB>  <TAB> msg = ""Cannot parse value {!r} as {!r}"".format <TAB>  <TAB> raise ValueError(msg(value, value_type)) <TAB> return value, value_type","if isinstance ( value , ( int , float ) ) :",136
"def test_open_append(self, sftp): <TAB> """"""Test appending data to an existing file"""""" <TAB> f = None <TAB> try: <TAB>  <TAB> self._create_file(""file"", ""xxx"") <TAB>  <TAB> f = yield from sftp.open(""file"", ""a+"") <TAB>  <TAB> yield from f.write(""yyy"") <TAB>  <TAB> self.assertEqual((yield from f.read()), """") <TAB>  <TAB> yield from f.close() <TAB>  <TAB> with open(""file"") as localf: <TAB>  <TAB>  <TAB> self.assertEqual(localf.read(), ""xxxyyy"") <TAB> finally: <MASK> # pragma: no branch <TAB>  <TAB>  <TAB> yield from f.close() <TAB>  <TAB> remove(""file"")",if f :,161
"def __new__(mcs, name, bases, attrs): <TAB> for b in bases: <TAB>  <TAB> if not hasattr(b, ""_fields""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for k, v in b.__dict__.items(): <TAB>  <TAB>  <TAB> if k in attrs: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if isinstance(v, FieldDescriptor): <TAB>  <TAB>  <TAB>  <TAB> attrs[k] = copy.deepcopy(v.field) <TAB> mcs = super().__new__(mcs, name, bases, attrs) <TAB> mcs._fields = {} <TAB> for name, field in mcs.__dict__.items(): <MASK> field.add_to_class(mcs, name) <TAB> return mcs","if isinstance ( field , BaseField ) :",163
"def gen(vals, nil=""""): <TAB> n = len(vals) <TAB> cases = [] <TAB> for i in range(2 ** n): <TAB>  <TAB> j = 1 <TAB>  <TAB> case = [] <TAB>  <TAB> for c in range(n): <MASK> case.append(vals[c]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> case.append(nil) <TAB>  <TAB>  <TAB> j *= 2 <TAB>  <TAB> cases.append(tuple(case)) <TAB> return cases",if i & j :,116
"def indent(self, elem, level=0): <TAB> i = ""\n"" + level * ""  "" <TAB> if len(elem): <MASK> elem.text = i + ""  "" <TAB>  <TAB> if not elem.tail or not elem.tail.strip(): <TAB>  <TAB>  <TAB> elem.tail = i <TAB>  <TAB> for elem in elem: <TAB>  <TAB>  <TAB> self.indent(elem, level + 1) <TAB>  <TAB> if not elem.tail or not elem.tail.strip(): <TAB>  <TAB>  <TAB> elem.tail = i <TAB> else: <TAB>  <TAB> if level and (not elem.tail or not elem.tail.strip()): <TAB>  <TAB>  <TAB> elem.tail = i",if not elem . text or not elem . text . strip ( ) :,165
"def wait_for_server_start(stdoutfile): <TAB> print(""Waiting for server start reading file "" + stdoutfile) <TAB> n = 0 <TAB> while True: <TAB>  <TAB> if os.path.isfile(stdoutfile): <TAB>  <TAB>  <TAB> with open(stdoutfile, encoding=""utf-8"", errors=""ignore"") as f: <TAB>  <TAB>  <TAB>  <TAB> out = f.read() <TAB>  <TAB>  <TAB>  <TAB> if ""Server waiting for client requests"" in out: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB>  <TAB> # Handle error case when the server failed to start and gave <TAB>  <TAB>  <TAB>  <TAB> # some error message. <MASK> return <TAB>  <TAB> time.sleep(1) <TAB>  <TAB> n += 1 <TAB>  <TAB> print(""Waiting for server to start for "" + str(n) + "" seconds..."")","if ""usage: CodeChecker"" in out :",193
"def init(self, mode_settings=None): <TAB> if mode_settings: <TAB>  <TAB> # Load this tab <TAB>  <TAB> self.settings = mode_settings <TAB>  <TAB> mode = self.settings.get(""persistent"", ""mode"") <MASK> self.filenames = self.settings.get(""share"", ""filenames"") <TAB>  <TAB>  <TAB> self.share_mode_clicked() <TAB>  <TAB> elif mode == ""receive"": <TAB>  <TAB>  <TAB> self.receive_mode_clicked() <TAB>  <TAB> elif mode == ""website"": <TAB>  <TAB>  <TAB> self.filenames = self.settings.get(""website"", ""filenames"") <TAB>  <TAB>  <TAB> self.website_mode_clicked() <TAB> else: <TAB>  <TAB> # This is a new tab <TAB>  <TAB> self.settings = ModeSettings(self.common)","if mode == ""share"" :",183
"def add_lookaheads(self, lookbacks, followset): <TAB> for trans, lb in lookbacks.items(): <TAB>  <TAB> # Loop over productions in lookback <TAB>  <TAB> for state, p in lb: <MASK> p.lookaheads[state] = [] <TAB>  <TAB>  <TAB> f = followset.get(trans, []) <TAB>  <TAB>  <TAB> for a in f: <TAB>  <TAB>  <TAB>  <TAB> if a not in p.lookaheads[state]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> p.lookaheads[state].append(a)",if not state in p . lookaheads :,137
"def main(): <TAB> args = sys.argv[1:] <TAB> if not args: <TAB>  <TAB> print(""Usage: %s querystring"" % sys.argv[0]) <TAB>  <TAB> return <TAB> list = [] <TAB> for arg in args: <MASK> arg = arg.replace(""+"", ""%2B"") <TAB>  <TAB> if "" "" in arg: <TAB>  <TAB>  <TAB> arg = '""%s""' % arg <TAB>  <TAB> arg = arg.replace("" "", ""+"") <TAB>  <TAB> list.append(arg) <TAB> s = ""+"".join(list) <TAB> url = ""http://www.google.com/search?q=%s"" % s <TAB> webbrowser.open(url)","if ""+"" in arg :",158
"def attributes_to_bytes(attributes): <TAB> byte_attributes = dict() <TAB> for key, value in attributes.items(): <MASK> # Python 2 <TAB>  <TAB>  <TAB> byte_attributes[key] = value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if isinstance(value, SEQUENCE_TYPES): <TAB>  <TAB>  <TAB>  <TAB> byte_attributes[key] = [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> v.encode(""utf-8"") if isinstance(v, STRING_TYPES) else v <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for v in value <TAB>  <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> byte_attributes[key] = ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value.encode(""utf-8"") if isinstance(value, STRING_TYPES) else value <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return byte_attributes",if str is bytes :,183
"def _cython_build_cleanup(tdname, build_dir=None): <TAB> if build_dir is None: <TAB>  <TAB> build_dir = os.path.join(os.path.expanduser(""~""), "".pyxbld"") <TAB> # Remove tdname.pyx <TAB> pyx_file = tdname + "".pyx"" <TAB> try: <TAB>  <TAB> os.remove(pyx_file) <TAB> except: <TAB>  <TAB> pass <TAB> # Remove temp build files <TAB> for dirpath, subdirs, files in os.walk(build_dir): <TAB>  <TAB> for f in files: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> os.remove(os.path.join(dirpath, f)) <TAB>  <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass",if f . startswith ( tdname ) :,180
"def handleSIGCHLD(self, signum, frame): <TAB> if self.runqemu and self.runqemu.poll(): <MASK> self.logger.debug(""runqemu exited with code %d"" % self.runqemu.returncode) <TAB>  <TAB>  <TAB> self.logger.debug( <TAB>  <TAB>  <TAB>  <TAB> ""Output from runqemu:\n%s"" % self.getOutput(self.runqemu.stdout) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.stop() <TAB>  <TAB>  <TAB> self._dump_host() <TAB>  <TAB>  <TAB> raise SystemExit",if self . runqemu . returncode :,146
"def handle(self, *args, **options): <TAB> queuename = options.get(""queuename"") <TAB> if not queuename: <TAB>  <TAB> raise CommandError(""Must specify `--queuename` in order to use command."") <TAB> with advisory_lock(""instance_group_registration_%s"" % queuename): <TAB>  <TAB> ig = InstanceGroup.objects.filter(name=queuename) <MASK> print(""Instance group doesn't exist"") <TAB>  <TAB>  <TAB> sys.exit(1) <TAB>  <TAB> ig = ig.first() <TAB>  <TAB> ig.delete() <TAB>  <TAB> print(""Instance Group Removed"") <TAB>  <TAB> print(""(changed: True)"")",if not ig . exists ( ) :,158
"def tokens_to_indices( <TAB> self, tokens: List[Token], vocabulary: Vocabulary) -> Dict[str, List[int]]: <TAB> indices: List[int] = [] <TAB> for token in itertools.chain(self._start_tokens, tokens, self._end_tokens): <TAB>  <TAB> text = token.text <TAB>  <TAB> assert isinstance(text, str) <MASK> text = text.lower() <TAB>  <TAB> indices.append(vocabulary.get_token_index(text, ""tokens"")) <TAB> return {""tokens"": indices}",if self . lowercase_tokens :,130
"def remote_list(self, remotes, raw): <TAB> for r in remotes: <MASK> disabled_str = "" True"" if r.disabled else """" <TAB>  <TAB>  <TAB> self._output.info( <TAB>  <TAB>  <TAB>  <TAB> ""%s %s %s %s"" % (r.name, r.url, r.verify_ssl, disabled_str) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> disabled_str = "", Disabled: True"" if r.disabled else """" <TAB>  <TAB>  <TAB> self._output.info( <TAB>  <TAB>  <TAB>  <TAB> ""%s: %s [Verify SSL: %s%s]"" <TAB>  <TAB>  <TAB>  <TAB> % (r.name, r.url, r.verify_ssl, disabled_str) <TAB>  <TAB>  <TAB> )",if raw :,176
"def _process_variants(cls, retval): <TAB> orig = getattr(retval, ""__orig__"", None) <TAB> if orig is not None: <MASK> orig.Attributes._variants = WeakKeyDictionary() <TAB>  <TAB> orig.Attributes._variants[retval] = True <TAB>  <TAB> # _variants is only for the root class. <TAB>  <TAB> retval.Attributes._variants = None",if orig . Attributes . _variants is None :,94
"def __device_has_gr_scripts(self, devname: str): <TAB> if not hasattr(sys, ""frozen""): <TAB>  <TAB> script_path = os.path.join(self.path, ""gr"", ""scripts"") <TAB> else: <TAB>  <TAB> script_path = self.path <TAB> devname = devname.lower().split("" "")[0] <TAB> has_send_file = False <TAB> has_recv_file = False <TAB> for f in os.listdir(script_path): <TAB>  <TAB> if f == ""{0}_send.py"".format(devname): <TAB>  <TAB>  <TAB> has_send_file = True <MASK> has_recv_file = True <TAB> return has_recv_file, has_send_file","elif f == ""{0}_recv.py"" . format ( devname ) :",184
"def on_selection_changed(self, treeselection): <TAB> # Show the correct notebook page based on what row is selected. <TAB> (model, row) = treeselection.get_selected() <TAB> try: <MASK> # Let's see update the accounts related stuff <TAB>  <TAB>  <TAB> if client.connected(): <TAB>  <TAB>  <TAB>  <TAB> self._get_accounts_tab_data() <TAB>  <TAB> self.notebook.set_current_page(model.get_value(row, 0)) <TAB> except TypeError: <TAB>  <TAB> pass","if model . get_value ( row , 1 ) == ""daemon"" :",134
"def track_to_metadata(node, track): <TAB> m = track.metadata <TAB> recording_to_metadata(node[""recording""], m, track) <TAB> m.add_unique(""musicbrainz_trackid"", node[""id""]) <TAB> # overwrite with data we have on the track <TAB> for key, value in node.items(): <TAB>  <TAB> if not value: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if key in _TRACK_TO_METADATA: <TAB>  <TAB>  <TAB> m[_TRACK_TO_METADATA[key]] = value <MASK> m.length = value <TAB>  <TAB> elif key == ""artist-credit"": <TAB>  <TAB>  <TAB> artist_credit_to_metadata(value, m) <TAB> if m.length: <TAB>  <TAB> m[""~length""] = format_time(m.length) <TAB> track.orig_metadata.copy(m)","elif key == ""length"" and value :",198
"def get_identifiers(self): <TAB> ids = [] <TAB> cp = subprocess.run([""df"", ""-t"", ""zfs""], capture_output=True, text=True) <TAB> for line in cp.stdout.strip().split(""\n""): <TAB>  <TAB> entry = line.split()[-1].strip() <MASK> continue <TAB>  <TAB> path = os.path.join( <TAB>  <TAB>  <TAB> self._base_path, ""df-"" + self.encode(entry), ""df_complex-free.rrd"" <TAB>  <TAB> ) <TAB>  <TAB> if os.path.exists(path): <TAB>  <TAB>  <TAB> ids.append(entry) <TAB> return ids","if entry != ""/"" and not entry . startswith ( ""/mnt"" ) :",159
"def _check_run(self, gv, opt, loss, lr, num_steps, tolerance, options): <TAB> """"""Run opt for num_steps times and check if the final loss is small."""""" <TAB> for i in range(num_steps): <TAB>  <TAB> g, v = gv() <MASK> opt(lr, g, options[0], options[1]) <TAB>  <TAB> elif options: <TAB>  <TAB>  <TAB> opt(lr, g, options) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> opt(lr, g) <TAB> self.assertLess(loss(), tolerance)","if options and isinstance ( options , tuple ) :",139
"def clip_last_batch(last_batch, true_size): <TAB> last_batch_clipped = [] <TAB> for val in last_batch: <MASK> last_batch_clipped.append(clip_sparse(val, true_size)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> last_batch_clipped.append(val[:true_size]) <TAB> return last_batch_clipped","if isinstance ( val , tf . SparseTensorValue ) :",100
"def loadMachineSettings(filename): <TAB> global settingsList <TAB> # Read a configuration file as global config <TAB> profileParser = ConfigParser.ConfigParser() <TAB> try: <TAB>  <TAB> profileParser.read(filename) <TAB> except ConfigParser.ParsingError: <TAB>  <TAB> return <TAB> for set in settingsList: <TAB>  <TAB> if set.isMachineSetting(): <MASK> set.setValue( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> unicode( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> profileParser.get(""machine"", set.getName()), ""utf-8"", ""replace"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> checkAndUpdateMachineName()","if profileParser . has_option ( ""machine"" , set . getName ( ) ) :",160
"def process(self, stacks): <TAB> client = local_session(self.manager.session_factory).client(""cloudformation"") <TAB> with self.executor_factory(max_workers=3) as w: <TAB>  <TAB> futures = {} <TAB>  <TAB> for s in stacks: <TAB>  <TAB>  <TAB> futures[w.submit(self.process_stacks, client, s)] = s <TAB>  <TAB> for f in as_completed(futures): <TAB>  <TAB>  <TAB> s = futures[f] <MASK> self.log.error( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Error updating protection stack:%s error:%s"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> s[""StackName""], <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f.exception(), <TAB>  <TAB>  <TAB>  <TAB> )",if f . exception ( ) :,168
"def _format_cpu_memory(container_group): <TAB> """"""Format CPU and memory."""""" <TAB> containers = container_group.get(""containers"") <TAB> if containers is not None and containers: <TAB>  <TAB> total_cpu = 0 <TAB>  <TAB> total_memory = 0 <TAB>  <TAB> for container in containers: <TAB>  <TAB>  <TAB> resources = container.get(""resources"") <TAB>  <TAB>  <TAB> if resources is not None: <TAB>  <TAB>  <TAB>  <TAB> resources_requests = resources.get(""requests"") <MASK> total_cpu += resources_requests.get(""cpu"", 0) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> total_memory += resources_requests.get(""memoryInGb"", 0) <TAB>  <TAB>  <TAB> return ""{0} core/{1} gb"".format(total_cpu, total_memory) <TAB> return None",if resources_requests is not None :,187
"def __repr__(self): <TAB> result = [""GeneralSetting kind: %s"" % (self.kind)] <TAB> ivars = (""ivar"", ""path"", ""setting"", ""val"", ""tag"") <TAB> for ivar in ivars: <MASK> val = getattr(self, ivar) <TAB>  <TAB>  <TAB> if val is not None: <TAB>  <TAB>  <TAB>  <TAB> result.append(""%s: %s"" % (ivar, val)) <TAB> return "","".join(result)","if hasattr ( self , ivar ) :",116
"def incomplete(self, incomplete_item, retry_after=300, restore_retry=False): <TAB> with self._transaction_factory(db): <TAB>  <TAB> retry_date = datetime.utcnow() + timedelta(seconds=retry_after) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> incomplete_item_obj = self._item_by_id_for_update(incomplete_item.id) <TAB>  <TAB>  <TAB> incomplete_item_obj.available_after = retry_date <TAB>  <TAB>  <TAB> incomplete_item_obj.available = True <MASK> incomplete_item_obj.retries_remaining += 1 <TAB>  <TAB>  <TAB> incomplete_item_obj.save() <TAB>  <TAB>  <TAB> self._currently_processing = False <TAB>  <TAB>  <TAB> return incomplete_item_obj.retries_remaining > 0 <TAB>  <TAB> except QueueItem.DoesNotExist: <TAB>  <TAB>  <TAB> return False",if restore_retry :,195
"def msvc_runtime_flag(conanfile): <TAB> settings = conanfile.settings <TAB> compiler = settings.get_safe(""compiler"") <TAB> runtime = settings.get_safe(""compiler.runtime"") <TAB> if compiler == ""Visual Studio"": <TAB>  <TAB> return runtime <TAB> if compiler == ""msvc"": <TAB>  <TAB> runtime_type = settings.get_safe(""compiler.runtime_type"") <TAB>  <TAB> runtime = ""MT"" if runtime == ""static"" else ""MD"" <MASK> runtime = ""{}d"".format(runtime) <TAB>  <TAB> return runtime","if runtime_type == ""Debug"" :",136
"def comparer(left, right): <TAB> for fn, d in comparers: <TAB>  <TAB> left_val = fn(left) <TAB>  <TAB> right_val = fn(right) <TAB>  <TAB> if isinstance(left_val, dict): <TAB>  <TAB>  <TAB> left_val = sorted(left_val.values())[0] <MASK> right_val = sorted(right_val.values())[0] <TAB>  <TAB> if left_val == right_val: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if d == ""asc"": <TAB>  <TAB>  <TAB> return -1 if left_val < right_val else 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return -1 if left_val > right_val else 1 <TAB> else: <TAB>  <TAB> return 0","if isinstance ( right_val , dict ) :",175
"def write_vint(port, x): <TAB> # Sign is handled with the second bit of the first byte.  All else <TAB> # matches vuint. <TAB> if x == 0: <TAB>  <TAB> port.write(""\0"") <TAB> else: <TAB>  <TAB> if x < 0: <TAB>  <TAB>  <TAB> x = -x <TAB>  <TAB>  <TAB> sign_and_six_bits = (x & 0x3F) | 0x40 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sign_and_six_bits = x & 0x3F <TAB>  <TAB> x >>= 6 <MASK> port.write(chr(0x80 | sign_and_six_bits)) <TAB>  <TAB>  <TAB> write_vuint(port, x) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> port.write(chr(sign_and_six_bits))",if x :,189
"def _base64_decode(s): <TAB> """"""Recover base64 if it is broken."""""" <TAB> try: <TAB>  <TAB> return base64.b64decode(s) <TAB> except (TypeError, ValueError): <TAB>  <TAB> s = _recover_base64(s) <TAB>  <TAB> tail_size = len(s) & 3 <MASK> # crop last character as adding padding does not help <TAB>  <TAB>  <TAB> return base64.b64decode(s[:-1]) <TAB>  <TAB> # add padding <TAB>  <TAB> return base64.b64decode(s + ""="" * (4 - tail_size))",if tail_size == 1 :,141
"def box_text_first_letter(box): <TAB> # TODO: use the same code as in inlines.first_letter_to_box <TAB> character_found = False <TAB> first_letter = """" <TAB> text = box_text(box) <TAB> while text: <TAB>  <TAB> next_letter = text[0] <TAB>  <TAB> category = unicodedata.category(next_letter) <TAB>  <TAB> if category not in (""Ps"", ""Pe"", ""Pi"", ""Pf"", ""Po""): <MASK> break <TAB>  <TAB>  <TAB> character_found = True <TAB>  <TAB> first_letter += next_letter <TAB>  <TAB> text = text[1:] <TAB> return first_letter",if character_found :,159
"def decode(self, parser, result): <TAB> parser._current = None <TAB> length = self._length <TAB> if length >= 0: <TAB>  <TAB> b = parser._inbuffer <MASK> parser._inbuffer, chunk = b[length + 2 :], bytes(b[:length]) <TAB>  <TAB>  <TAB> if parser.encoding: <TAB>  <TAB>  <TAB>  <TAB> return chunk.decode(parser.encoding) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return chunk <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> parser._current = self <TAB>  <TAB>  <TAB> return False",if len ( b ) >= length + 2 :,132
"def parse_declaration(self, i): <TAB> # override internal declaration handler to handle CDATA blocks <TAB> if _debug: <TAB>  <TAB> sys.stderr.write(""entering parse_declaration\n"") <TAB> if self.rawdata[i : i + 9] == ""<![CDATA["": <TAB>  <TAB> k = self.rawdata.find(""]]>"", i) <MASK> k = len(self.rawdata) <TAB>  <TAB> self.handle_data(_xmlescape(self.rawdata[i + 9 : k]), 0) <TAB>  <TAB> return k + 3 <TAB> else: <TAB>  <TAB> k = self.rawdata.find("">"", i) <TAB>  <TAB> return k + 1",if k == - 1 :,155
"def consolidateRests(templateInner): <TAB> consecutiveRests = [] <TAB> for el in list(templateInner.getElementsByClass(""GeneralNote"")): <MASK> removeConsecutiveRests(templateInner, consecutiveRests) <TAB>  <TAB>  <TAB> consecutiveRests = [] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> consecutiveRests.append(el) <TAB> removeConsecutiveRests(templateInner, consecutiveRests)","if ""Rest"" not in el . classes :",108
"def _Determine_Sufficient(self): <TAB> if not self.applicable: <TAB>  <TAB> return <TAB> if self.value is not None: <MASK> raise black.configure.ConfigureError( <TAB>  <TAB>  <TAB>  <TAB> ""Windows code-signing certificate %s does not exist"" % (self.value,) <TAB>  <TAB>  <TAB> )",if not os . path . exists ( self . value ) :,87
"def requiredFor(self): <TAB> if self.__requiredFor is None: <TAB>  <TAB> self.__requiredFor = {} <TAB>  <TAB> if self.requiredfor: <TAB>  <TAB>  <TAB> for typeID, skillLevel in json.loads(self.requiredfor).items(): <TAB>  <TAB>  <TAB>  <TAB> requiredForItem = eos.db.getItem(int(typeID)) <MASK> self.__requiredFor[requiredForItem] = skillLevel <TAB> return self.__requiredFor",if requiredForItem :,115
"def _parse_int(s, start, end): <TAB> """"""Parse a number and check for overflows"""""" <TAB> result = 0 <TAB> i = start <TAB> while i < end: <TAB>  <TAB> c = ord(s[i]) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> result = result * 10 <TAB>  <TAB>  <TAB>  <TAB> if result > 1000000000:  # this is not going to overflow in CPython <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise OverflowError <TAB>  <TAB>  <TAB> except OverflowError: <TAB>  <TAB>  <TAB>  <TAB> msg = ""too many decimal digits in format string"" <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(msg) <TAB>  <TAB>  <TAB> result += c - ord(""0"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> i += 1 <TAB> if i == start: <TAB>  <TAB> result = -1 <TAB> return result, i","if ord ( ""0"" ) <= c <= ord ( ""9"" ) :",193
"def apply(self, dbase, person): <TAB> for event_ref in person.get_event_ref_list(): <MASK> continue <TAB>  <TAB> if int(self.list[5]) and event_ref.role != EventRoleType.PRIMARY: <TAB>  <TAB>  <TAB> # Only match primaries, no witnesses <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> event = dbase.get_event_from_handle(event_ref.ref) <TAB>  <TAB> if HasEventBase.apply(self, dbase, event): <TAB>  <TAB>  <TAB> return True <TAB> return False",if not event_ref :,134
"def __init__(self, component, cuid_buffer=None, context=None): <TAB> # A CUID can be initialized from either a reference component or <TAB> # the string representation. <TAB> if isinstance(component, string_types): <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Context is not allowed when initializing a "" <TAB>  <TAB>  <TAB>  <TAB> ""ComponentUID object from a string type"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self._cids = tuple(self.parse_cuid(component)) <TAB> else: <TAB>  <TAB> self._cids = tuple( <TAB>  <TAB>  <TAB> self._generate_cuid(component, cuid_buffer=cuid_buffer, context=context) <TAB>  <TAB> )",if context is not None :,166
"def serve_forever(self, poll_interval=0.5): <TAB> self.__running = False <TAB> self.__mainloop = gobject.MainLoop() <TAB> if hasattr(self, ""socket""): <TAB>  <TAB> gobject.io_add_watch(self, gobject.IO_IN | gobject.IO_PRI, self._on_new_request) <TAB> context = self.__mainloop.get_context() <TAB> while not self.__running: <TAB>  <TAB> try: <MASK> context.iteration(True) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> time.sleep(0.1) <TAB>  <TAB> except KeyboardInterrupt: <TAB>  <TAB>  <TAB> break <TAB> logger.debug(""SSDPListener.serve_forever() quit"")",if context . pending ( ) :,171
"def sanitize_dict(dictionary): <TAB> for key in dictionary: <TAB>  <TAB> value = dictionary[key] <MASK> dictionary[key] = re.sub( <TAB>  <TAB>  <TAB>  <TAB> r""("" + ""|"".join(self._keys) + r"")"", self._replacement, dictionary[key] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> elif isinstance(value, dict): <TAB>  <TAB>  <TAB> sanitize_dict(value)","if isinstance ( value , str ) :",100
"def _read_file(self, file_name: typing.Union[str, Path]) -> typing.Dict[str, str]: <TAB> file_values = {}  # type: typing.Dict[str, str] <TAB> with open(file_name) as input_file: <TAB>  <TAB> for line in input_file.readlines(): <TAB>  <TAB>  <TAB> line = line.strip() <MASK> key, value = line.split(""="", 1) <TAB>  <TAB>  <TAB>  <TAB> key = key.strip() <TAB>  <TAB>  <TAB>  <TAB> value = value.strip().strip(""\""'"") <TAB>  <TAB>  <TAB>  <TAB> file_values[key] = value <TAB> return file_values","if ""="" in line and not line . startswith ( ""#"" ) :",159
"def json_object_hook_handler(obj): <TAB> obj_data = obj.get(""$obj"") <TAB> if obj_data: <TAB>  <TAB> object_type, obj_data = obj_data <TAB>  <TAB> if object_type == ""oid"": <TAB>  <TAB>  <TAB> return ObjectId(obj_data) <MASK> return datetime.datetime.fromtimestamp(obj_data / 1000.0, bson.tz_util.utc) <TAB> return obj","elif object_type == ""date"" :",111
"def process_token_list(tokens): <TAB> for token in tokens: <MASK> process_token_list(token) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> name, value = token <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> more_tokens, words = token_handlers[name](value) <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> raise NotImplementedError(""Unsupported token type "" + name) <TAB>  <TAB> if more_tokens: <TAB>  <TAB>  <TAB> self.process_tokens(more_tokens) <TAB>  <TAB> if words: <TAB>  <TAB>  <TAB> self.process_words(words)","if isinstance ( token , list ) :",135
"def _extract_first_or_bytes(blob, size): <TAB> # Extract the first line or upto X symbols for text objects <TAB> # Extract first X bytes for binary objects <TAB> try: <MASK> start = blob.split(""\n"", 1)[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # We want to avoid decoding the whole blob (it might be huge) <TAB>  <TAB>  <TAB> # By taking 4*size bytes we guarantee to decode size utf8 chars <TAB>  <TAB>  <TAB> start = blob[: 4 * size].decode(errors=""ignore"").split(""\n"", 1)[0] <TAB>  <TAB> if len(start) >= size: <TAB>  <TAB>  <TAB> start = start[:size] <TAB> except UnicodeDecodeError: <TAB>  <TAB> # Bytes array doesn't contain text so return chunk of raw bytes <TAB>  <TAB> start = blob[0:size] <TAB> return start","if isinstance ( blob , str ) :",197
"def link(self, key, location): <TAB> """"""Change location of an existing item."""""" <TAB> n = self.keyOrder.index(key) <TAB> del self.keyOrder[n] <TAB> try: <TAB>  <TAB> i = self.index_for_location(location) <MASK> self.keyOrder.insert(i, key) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.keyOrder.append(key) <TAB> except Exception as e: <TAB>  <TAB> # restore to prevent data loss and reraise <TAB>  <TAB> self.keyOrder.insert(n, key) <TAB>  <TAB> raise e",if i is not None :,141
"def job_put_on_hold(self, blocking=True): <TAB> if not self._job_on_hold.acquire(blocking=blocking): <TAB>  <TAB> raise RuntimeError(""Could not acquire job_on_hold lock"") <TAB> self._job_on_hold.set() <TAB> try: <TAB>  <TAB> yield <TAB> finally: <TAB>  <TAB> self._job_on_hold.clear() <MASK> self._continue_sending() <TAB>  <TAB> self._job_on_hold.release()",if self . _job_on_hold . counter == 0 :,126
"def registeredExamples(node=None): <TAB> if node: <TAB>  <TAB> filtered = collections.OrderedDict() <TAB>  <TAB> for k, e in __examples.items(): <MASK> filtered[k] = e <TAB>  <TAB> return filtered <TAB> else: <TAB>  <TAB> return collections.OrderedDict(__examples)","if node in e [ ""notableNodes"" ] :",79
"def commit(self, *args, **kwargs): <TAB> """"""Activate changes from private candidate for Nokia SR OS"""""" <TAB> output = self._exit_all() <TAB> if ""@"" in self.base_prompt and ""*(ex)["" in output: <TAB>  <TAB> log.info(""Apply uncommitted changes!"") <TAB>  <TAB> cmd = ""commit"" <TAB>  <TAB> self.write_channel(self.normalize_cmd(cmd)) <TAB>  <TAB> new_output = """" <TAB>  <TAB> if self.global_cmd_verify is not False: <TAB>  <TAB>  <TAB> new_output += self.read_until_pattern(pattern=re.escape(cmd)) <MASK> new_output += self.read_until_pattern(r""@"") <TAB>  <TAB> output += new_output <TAB> return output","if ""@"" not in new_output :",183
"def extend_processing(self, seconds_from_now, updated_data=None): <TAB> with self._current_item_lock: <MASK> self._queue.extend_processing( <TAB>  <TAB>  <TAB>  <TAB> self.current_queue_item, seconds_from_now, updated_data=updated_data <TAB>  <TAB>  <TAB> )",if self . current_queue_item is not None :,89
"def validate_uom_conversion_factor(self): <TAB> if self.uoms: <TAB>  <TAB> for d in self.uoms: <TAB>  <TAB>  <TAB> value = get_uom_conv_factor(d.uom, self.stock_uom) <MASK> d.conversion_factor = value",if value :,78
"def __updateFilter(self, newInfoKey=None): <TAB> infoKey, matcher = self.pathFilter().getMatcher() <TAB> if newInfoKey is not None: <TAB>  <TAB> infoKey = newInfoKey <TAB> t = self.__filterText.getText() <TAB> if t == """": <TAB>  <TAB> matcher = None <TAB> else: <TAB>  <TAB> if ""?"" not in t and ""*"" not in t: <TAB>  <TAB>  <TAB> t = ""*"" + t + ""*"" <TAB>  <TAB> stringifier = str <MASK> stringifier = time.ctime <TAB>  <TAB> regex = re.compile(fnmatch.translate(t)) <TAB>  <TAB> matcher = lambda v: regex.match(stringifier(v)) is not None <TAB> self.pathFilter().setMatcher(infoKey, matcher)","if infoKey == ""fileSystem:modificationTime"" :",182
"def _backup_get_all( <TAB> context, <TAB> filters=None, <TAB> marker=None, <TAB> limit=None, <TAB> offset=None, <TAB> sort_keys=None, <TAB> sort_dirs=None,): <TAB> if filters and not is_valid_model_filters(models.Backup, filters): <TAB>  <TAB> return [] <TAB> session = get_session() <TAB> with session.begin(): <TAB>  <TAB> # Generate the paginate query <TAB>  <TAB> query = _generate_paginate_query( <TAB>  <TAB>  <TAB> context, <TAB>  <TAB>  <TAB> session, <TAB>  <TAB>  <TAB> marker, <TAB>  <TAB>  <TAB> limit, <TAB>  <TAB>  <TAB> sort_keys, <TAB>  <TAB>  <TAB> sort_dirs, <TAB>  <TAB>  <TAB> filters, <TAB>  <TAB>  <TAB> offset, <TAB>  <TAB>  <TAB> models.Backup, <TAB>  <TAB> ) <MASK> return [] <TAB>  <TAB> return query.all()",if query is None :,200
"def _get_and_set_cluster_snapshot_attributes(self, snapshot: {}, region: str): <TAB> client = AWSFacadeUtils.get_client(""rds"", self.session, region) <TAB> try: <TAB>  <TAB> attributes = await run_concurrently( <TAB>  <TAB>  <TAB> lambda: client.describe_db_cluster_snapshot_attributes( <TAB>  <TAB>  <TAB>  <TAB> DBClusterSnapshotIdentifier=snapshot[""DBClusterSnapshotIdentifier""] <TAB>  <TAB>  <TAB> )[""DBClusterSnapshotAttributesResult""] <TAB>  <TAB> ) <TAB>  <TAB> snapshot[""Attributes""] = ( <TAB>  <TAB>  <TAB> attributes[""DBClusterSnapshotAttributes""] <MASK> else {} <TAB>  <TAB> ) <TAB> except Exception as e: <TAB>  <TAB> print_exception(f""Failed to describe RDS cluster snapshot attributes: {e}"") <TAB>  <TAB> snapshot[""Attributes""] = {}","if ""DBClusterSnapshotAttributes"" in attributes",191
"def test_composer(data_filename, canonical_filename, verbose=False): <TAB> nodes1 = None <TAB> nodes2 = None <TAB> try: <TAB>  <TAB> nodes1 = list(yaml.compose_all(open(data_filename, ""rb""))) <TAB>  <TAB> nodes2 = list(yaml.canonical_compose_all(open(canonical_filename, ""rb""))) <TAB>  <TAB> assert len(nodes1) == len(nodes2), (len(nodes1), len(nodes2)) <TAB>  <TAB> for node1, node2 in zip(nodes1, nodes2): <TAB>  <TAB>  <TAB> _compare_nodes(node1, node2) <TAB> finally: <MASK> print(""NODES1:"") <TAB>  <TAB>  <TAB> pprint.pprint(nodes1) <TAB>  <TAB>  <TAB> print(""NODES2:"") <TAB>  <TAB>  <TAB> pprint.pprint(nodes2)",if verbose :,193
"def _get_named_device(name, get_input): <TAB> # Look for the device by name and type (input / output) <TAB> for device in get_devices(): <MASK> continue <TAB>  <TAB> # Skip if device is the wrong type <TAB>  <TAB> if get_input: <TAB>  <TAB>  <TAB> if not device[""is_input""]: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if not device[""is_output""]: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if device[""opened""]: <TAB>  <TAB>  <TAB> raise IOError(""port already opened: {!r}"".format(name)) <TAB>  <TAB> return device <TAB> else: <TAB>  <TAB> raise IOError(""unknown port {!r}"".format(name))","if device [ ""name"" ] != name :",166
"def count_tokens(samples): <TAB> """"""Count tokens in the data set."""""" <TAB> token_counter = collections.Counter() <TAB> for sample in samples: <TAB>  <TAB> for token in sample: <MASK> token_counter[token] = 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> token_counter[token] += 1 <TAB> return token_counter",if token not in token_counter :,93
"def filter_data(data, idx): <TAB> data_filtered = [] <TAB> for sentence in data: <TAB>  <TAB> flag = True <TAB>  <TAB> for token in sentence: <MASK> flag = False <TAB>  <TAB> if flag: <TAB>  <TAB>  <TAB> data_filtered.append(sentence) <TAB> return data_filtered",if token [ idx ] is None :,82
"def safe_kill(pid: Pid, signum: int) -> None: <TAB> """"""Kill a process with the specified signal, catching nonfatal errors."""""" <TAB> assert isinstance(pid, Pid) <TAB> assert isinstance(signum, int) <TAB> try: <TAB>  <TAB> os.kill(pid, signum) <TAB> except (IOError, OSError) as e: <MASK> pass <TAB>  <TAB> elif e.errno == errno.EINVAL: <TAB>  <TAB>  <TAB> raise ValueError(""Invalid signal number {}: {}"".format(signum, e), e) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise","if e . errno in [ errno . ESRCH , errno . EPERM ] :",150
"def __new__(cls, name, bases, attrs): <TAB> attrs[""fields""] = {} <TAB> # Inherit any fields from parent(s). <TAB> parents = [b for b in bases if isinstance(b, ConditionSetBase)] <TAB> for p in parents: <TAB>  <TAB> fields = getattr(p, ""fields"", None) <TAB>  <TAB> if fields: <TAB>  <TAB>  <TAB> attrs[""fields""].update(fields) <TAB> for field_name, obj in attrs.items(): <MASK> field = attrs.pop(field_name) <TAB>  <TAB>  <TAB> field.set_values(field_name) <TAB>  <TAB>  <TAB> attrs[""fields""][field_name] = field <TAB> instance = super(ConditionSetBase, cls).__new__(cls, name, bases, attrs) <TAB> return instance","if isinstance ( obj , Field ) :",181
"def get_submodel_args_dict(args): <TAB> submodel_argv = get_submodel_argv(args) <TAB> result = {} <TAB> i = 0 <TAB> while i < len(submodel_argv): <TAB>  <TAB> arg = submodel_argv[i] <TAB>  <TAB> next_arg = None if i == len(submodel_argv) - 1 else submodel_argv[i + 1] <MASK> if next_arg.startswith(""--""): <TAB>  <TAB>  <TAB>  <TAB> result[arg[2:]] = True <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> result[arg[2:]] = next_arg <TAB>  <TAB>  <TAB>  <TAB> i += 1 <TAB>  <TAB> elif arg.startswith(""--""): <TAB>  <TAB>  <TAB> result[arg[2:]] = True <TAB>  <TAB> i += 1 <TAB> return result","if next_arg and arg . startswith ( ""--"" ) :",188
"def _get_display_source_name( <TAB> self, context: UserContext, is_multi: bool, name: str) -> str: <TAB> source_names = context[""source_names""] <TAB> if not is_multi or source_names == ""hide"": <TAB>  <TAB> source_name = """" <TAB> else: <TAB>  <TAB> short_name = ( <TAB>  <TAB>  <TAB> re.sub(r""([a-zA-Z])[a-zA-Z]+"", r""\1"", name) <MASK> else name[:2] <TAB>  <TAB> ) <TAB>  <TAB> source_name = short_name if source_names == ""short"" else name <TAB> return source_name","if re . search ( r""[^a-zA-Z]"" , name )",166
"def getentries(self): <TAB> """"""Read the contents of CVS/Entries"""""" <TAB> self.entries = {} <TAB> f = self.cvsopen(""Entries"") <TAB> while 1: <TAB>  <TAB> line = f.readline() <MASK> break <TAB>  <TAB> e = self.FileClass() <TAB>  <TAB> e.getentry(line) <TAB>  <TAB> self.entries[e.file] = e <TAB> f.close()",if not line :,103
"def parse_scheduled(scheduled): <TAB> if (scheduled or ""now"") != ""now"": <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> scheduled_at = dateutil.parser.parse(scheduled) <MASK> scheduled_at = scheduled_at.replace(tzinfo=dateutil.tz.tzlocal()) <TAB>  <TAB> except (ValueError, TypeError): <TAB>  <TAB>  <TAB> message = ""Unable to parse scheduled timestamp ({0}). It should be in an unambiguous format (e.g. ISO 8601)"" <TAB>  <TAB>  <TAB> raise PatroniCtlException(message.format(scheduled)) <TAB>  <TAB> return scheduled_at <TAB> return None",if scheduled_at . tzinfo is None :,149
"def SetMenuBar(self, menu_bar): <TAB> pOldMenuBar = self._pMenuBar <TAB> self._pMenuBar = menu_bar <TAB> if self._pMenuBar: <TAB>  <TAB> pParentFrame = self.GetMDIParentFrame() <TAB>  <TAB> if not pParentFrame: <TAB>  <TAB>  <TAB> raise Exception(""Missing MDI Parent Frame"") <TAB>  <TAB> self._pMenuBar.Reparent(pParentFrame) <MASK> # replace current menu bars <TAB>  <TAB>  <TAB> if pOldMenuBar: <TAB>  <TAB>  <TAB>  <TAB> pParentFrame.SetChildMenuBar(None) <TAB>  <TAB>  <TAB> pParentFrame.SetChildMenuBar(self)",if pParentFrame . GetActiveChild ( ) == self :,162
"def _validate_options(self): <TAB> for option in self.options: <TAB>  <TAB> # if value type is bool or int, then we know the options is set <TAB>  <TAB> if not type(self.options[option]) in [bool, int]: <MASK> raise FrameworkException(f""Value required for the '{option}' option."") <TAB> return",if self . options . required [ option ] is True and not self . options [ option ] :,103
"def _get_char(self): <TAB> """"""Read a character from input."""""" <TAB> if self.ungotten_char is None: <TAB>  <TAB> if self.eof: <TAB>  <TAB>  <TAB> c = """" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> c = self.file.read(1) <TAB>  <TAB>  <TAB> if c == """": <TAB>  <TAB>  <TAB>  <TAB> self.eof = True <MASK> self.line_number += 1 <TAB> else: <TAB>  <TAB> c = self.ungotten_char <TAB>  <TAB> self.ungotten_char = None <TAB> return c","elif c == ""\n"" :",137
"def AddListener(self, listener): <TAB> if operator.isSequenceType(listener): <TAB>  <TAB> for obj in listener: <TAB>  <TAB>  <TAB> self.AddKeyListener(obj) <TAB> else: <TAB>  <TAB> if issubclass(type(listener), type) or type(listener) == ClassType: <TAB>  <TAB>  <TAB> listener = listener() <TAB>  <TAB> for key in self.KeyListeners.Keys: <MASK> self.KeyListeners[key].Add(getattr(listener, key))","if hasattr ( listener , key ) :",121
"def check_no_global( <TAB> self, name: str, ctx: Context, is_overloaded_func: bool = False) -> None: <TAB> if name in self.globals: <TAB>  <TAB> prev_is_overloaded = isinstance(self.globals[name], OverloadedFuncDef) <TAB>  <TAB> if is_overloaded_func and prev_is_overloaded: <TAB>  <TAB>  <TAB> self.fail(""Nonconsecutive overload {} found"".format(name), ctx) <MASK> self.fail(""Definition of '{}' missing 'overload'"".format(name), ctx) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.name_already_defined(name, ctx, self.globals[name])",elif prev_is_overloaded :,155
"def assertCellValues(referencedRows, removedColumns={}): <TAB> for i, row in enumerate(script[""reference""][""rows""]): <TAB>  <TAB> if ""c1"" not in removedColumns: <TAB>  <TAB>  <TAB> self.assertEqual(row[""cells""][""c1""][""value""].getValue(), i) <MASK> self.assertEqual(row[""cells""][""c2""][""value""].getValue(), i + 1)","if ""c2"" not in removedColumns :",99
"def _likely_same(a, b): <TAB> try: <TAB>  <TAB> # Samefile not availible on windows <TAB>  <TAB> if sys.platform == ""win32"": <TAB>  <TAB>  <TAB> if os.stat(a) == os.stat(b): <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <MASK> return True <TAB> except OSError: <TAB>  <TAB> # m.__file__ is not always accessible.  eg. egg <TAB>  <TAB> return False <TAB> if chop_py_suffix(a) == chop_py_suffix(b): <TAB>  <TAB> return True <TAB> return False","if os . path . samefile ( a , b ) :",148
"def get_hash(self): <TAB> directive = self.effective_directive <TAB> uri = self._normalized_blocked_uri <TAB> # We want to distinguish between the different script-src <TAB> # violations that happen in <TAB> if _is_unsafe_script(directive, uri) and self.violated_directive: <TAB>  <TAB> if ""'unsafe-inline"" in self.violated_directive: <TAB>  <TAB>  <TAB> uri = ""'unsafe-eval'"" <MASK> uri = ""'unsafe-inline"" <TAB> return [directive, uri]","elif ""'unsafe-eval'"" in self . violated_directive :",136
"def get_block_parent(self): <TAB> """"""Get the block parent for a filter"""""" <TAB> block_stack = [self.manager] <TAB> for f in self.manager.iter_filters(block_end=True): <TAB>  <TAB> if f is None: <TAB>  <TAB>  <TAB> block_stack.pop() <TAB>  <TAB> elif f == self: <TAB>  <TAB>  <TAB> return block_stack[-1] <MASK> block_stack.append(f)","elif f . type in ( ""and"" , ""or"" , ""not"" ) :",117
"def _replace_list(self, items, ignore_errors): <TAB> for item in items: <MASK> yield unescape(item) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for value in self._replace_list_item(item, ignore_errors): <TAB>  <TAB>  <TAB>  <TAB> yield value",if self . _cannot_have_variables ( item ) :,78
"def _get_switch_info(self, cmd_list): <TAB> stdout, stderr, sw_data = None, None, None <TAB> try: <TAB>  <TAB> stdout, stderr = self._run_ssh(cmd_list, True, 1) <TAB>  <TAB> LOG.debug(""CLI output from ssh - output: %s"", stdout) <MASK> sw_data = stdout.splitlines() <TAB>  <TAB> return sw_data <TAB> except processutils.ProcessExecutionError as e: <TAB>  <TAB> msg = _( <TAB>  <TAB>  <TAB> ""Error while getting data via ssh: (command=%(cmd)s "" ""error=%(err)s)."" <TAB>  <TAB> ) % {""cmd"": cmd_list, ""err"": six.text_type(e)} <TAB>  <TAB> LOG.error(msg) <TAB>  <TAB> raise exception.CiscoZoningCliException(reason=msg)",if stdout :,193
"def get_service_container( <TAB> self, service_name, attempts=20, interval=0.5, include_stopped=False): <TAB> # There is some delay between the service's creation and the creation <TAB> # of the service's containers. This method deals with the uncertainty <TAB> # when trying to retrieve the container associated with a service. <TAB> while True: <TAB>  <TAB> containers = self.client.containers( <TAB>  <TAB>  <TAB> filters={""name"": [service_name]}, quiet=True, all=include_stopped <TAB>  <TAB> ) <TAB>  <TAB> if len(containers) > 0: <TAB>  <TAB>  <TAB> return containers[0] <TAB>  <TAB> attempts -= 1 <MASK> return None <TAB>  <TAB> time.sleep(interval)",if attempts <= 0 :,170
"def _threshold_fit(self, values, threshold, take_high): <TAB> result = [] <TAB> for idx, v in enumerate(values): <MASK> if v >= threshold: <TAB>  <TAB>  <TAB>  <TAB> result.append(idx) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if v <= threshold: <TAB>  <TAB>  <TAB>  <TAB> result.append(idx) <TAB> return result",if take_high :,90
"def add_members(self, members): <TAB> self.buffer.extend(members) <TAB> if self.cache: <TAB>  <TAB> guild = self.resolver(self.guild_id) <MASK> return <TAB>  <TAB> for member in members: <TAB>  <TAB>  <TAB> existing = guild.get_member(member.id) <TAB>  <TAB>  <TAB> if existing is None or existing.joined_at is None: <TAB>  <TAB>  <TAB>  <TAB> guild._add_member(member)",if guild is None :,114
"def src(tokens, base_url): <TAB> """"""``src`` descriptor validation."""""" <TAB> if len(tokens) <= 2: <TAB>  <TAB> tokens, token = tokens[:-1], tokens[-1] <MASK> tokens, token = tokens[:-1], tokens[-1] <TAB>  <TAB> if token.type == ""function"" and token.lower_name == ""local"": <TAB>  <TAB>  <TAB> return ""local"", font_family(token.arguments, allow_spaces=True) <TAB>  <TAB> url = get_url(token, base_url) <TAB>  <TAB> if url is not None and url[0] == ""url"": <TAB>  <TAB>  <TAB> return url[1]","if token . type == ""function"" and token . lower_name == ""format"" :",165
"def add(node, changes): <TAB> for key, value in changes: <TAB>  <TAB> dest = dot_lookup(destination, node) <MASK> dest.insert(key, value) <TAB>  <TAB> elif isinstance(dest, SET_TYPES): <TAB>  <TAB>  <TAB> dest |= value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> dest[key] = value","if isinstance ( dest , LIST_TYPES ) :",89
"def moveDown(self): <TAB> """"""Move selected items down"""""" <TAB> sz = self.size() - 1 <TAB> lst = map(int, self.curselection()) <TAB> lst.reverse() <TAB> for i in lst: <TAB>  <TAB> if i >= sz: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> next = i + 1 <MASK> act = self.index(ACTIVE) <TAB>  <TAB>  <TAB> self.swap(i, next) <TAB>  <TAB>  <TAB> self.selection_set(next) <TAB>  <TAB>  <TAB> if act == i: <TAB>  <TAB>  <TAB>  <TAB> self.activate(next) <TAB> self.event_generate(""<<ListboxSelect>>"")",if not self . selection_includes ( next ) :,151
"def draw_obj_names(self, layout): <TAB> # display names currently being tracked, stop at the first 5.. <TAB> if self.object_names: <TAB>  <TAB> remain = len(self.object_names) - 5 <TAB>  <TAB> for i, obj_ref in enumerate(self.object_names): <TAB>  <TAB>  <TAB> layout.label(text=obj_ref.name) <MASK> postfix = """" if remain == 1 else ""s"" <TAB>  <TAB>  <TAB>  <TAB> more_items = ""... {0} more item"" + postfix <TAB>  <TAB>  <TAB>  <TAB> layout.label(text=more_items.format(remain)) <TAB>  <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> layout.label(text=""--None--"")",if i > 4 and remain > 0 :,173
"def _all(config, parent_key=""""): <TAB> all_ = {} <TAB> for key in config: <TAB>  <TAB> value = self.get(parent_key + key) <MASK> all_[key] = _all(config[key], parent_key=key + ""."") <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> all_[key] = value <TAB> return all_","if isinstance ( value , dict ) :",91
def default_config(self): <MASK> self.lazy_init_lock_.acquire() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if self.default_config_ is None: <TAB>  <TAB>  <TAB>  <TAB> self.default_config_ = CapabilityConfig() <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self.lazy_init_lock_.release() <TAB> return self.default_config_,if self . default_config_ is None :,96
"def _insideArc(self, P): <TAB> phi = atan2(P[1] - self.C[1], P[0] - self.C[0]) <TAB> if self.type == Segment.CW: <TAB>  <TAB> if phi < self.endPhi - EPS / self.radius: <TAB>  <TAB>  <TAB> phi += PI2 <TAB>  <TAB> if phi <= self.startPhi + EPS / self.radius: <TAB>  <TAB>  <TAB> return True <TAB> elif self.type == Segment.CCW: <MASK> phi += PI2 <TAB>  <TAB> if phi <= self.endPhi + EPS / self.radius: <TAB>  <TAB>  <TAB> return True <TAB> if eq(self.A, P, EPS) or eq(self.B, P, EPS): <TAB>  <TAB> return True <TAB> return False",if phi < self . startPhi - EPS / self . radius :,198
"def startElement(self, name, attrs): <TAB> top = self.top() <TAB> node = Element(unicode(name), parent=top) <TAB> for a in attrs.getNames(): <TAB>  <TAB> n = unicode(a) <TAB>  <TAB> v = unicode(attrs.getValue(a)) <TAB>  <TAB> attribute = Attribute(n, v) <MASK> continue <TAB>  <TAB> node.append(attribute) <TAB> node.charbuffer = [] <TAB> top.append(node) <TAB> self.push(node)","if self . mapPrefix ( node , attribute ) :",128
"def __init__(self, hub=None, use_environ=True, **kwargs): <TAB> if hub is None: <TAB>  <TAB> hub = get_hub() <TAB> self.hub = hub <TAB> if use_environ: <TAB>  <TAB> for setting in config.settings.values(): <TAB>  <TAB>  <TAB> if isinstance(setting, AresSettingMixin): <TAB>  <TAB>  <TAB>  <TAB> value = setting.get() <MASK> kwargs.setdefault(setting.kwarg_name, value) <TAB> self.cares = self.cares_class(hub.loop, **kwargs) <TAB> self.pid = os.getpid() <TAB> self.params = kwargs <TAB> self.fork_watcher = hub.loop.fork(ref=False) <TAB> self.fork_watcher.start(self._on_fork)",if value is not None :,192
"def move_left(cls, terminal): <TAB> box = terminal.get_parent() <TAB> while not isinstance(box, RootTerminalBox): <TAB>  <TAB> box = box.get_parent() <MASK> if box.get_orientation() == Gtk.Orientation.HORIZONTAL: <TAB>  <TAB>  <TAB>  <TAB> _, __, p = cls.list_allocation(box) <TAB>  <TAB>  <TAB>  <TAB> if p - SplitMover.STEP > SplitMover.THRESHOLD: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> box.set_position(p - SplitMover.STEP) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> box.set_position(SplitMover.THRESHOLD) <TAB>  <TAB>  <TAB>  <TAB> break","if isinstance ( box , DualTerminalBox ) :",165
"def _mock_manager_jdm(self, *args, **kwargs): <TAB> if args: <TAB>  <TAB> if args[0].tag == ""command"": <MASK> raise RpcError() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return self._read_file(""sw_info_jdm_command_"" + args[0].text + "".xml"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self._read_file(""sw_info_jdm_"" + args[0].tag + "".xml"")","if args [ 0 ] . text == ""show version invoke-on all-routing-engines"" :",141
"def _list_tables_files(self, path=None): <TAB> # tables are files in a dir <TAB> if path is None: <TAB>  <TAB> path = self.root <TAB> tables = [] <TAB> if path.is_dir(): <TAB>  <TAB> for d in path.iterdir(): <TAB>  <TAB>  <TAB> if d.is_file(): <MASK> tables.append(d.stem) <TAB> elif path.is_file(): <TAB>  <TAB> if str(path).endswith(self.extension): <TAB>  <TAB>  <TAB> tables.append(path.stem) <TAB> return tables",if str ( d ) . endswith ( self . extension ) :,143
"def leading_zero_radix(self, radix): <TAB> if isinstance(radix, basestring): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> radix = int(radix) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> radix = radix.lower() <TAB>  <TAB>  <TAB> if radix == ""octal"" or radix == ""oct"" or radix == ""8"": <TAB>  <TAB>  <TAB>  <TAB> radix = 8 <MASK> radix = 10 <TAB> if radix not in (8, 10): <TAB>  <TAB> raise ValueError(""Radix must either be 8 (octal) or 10 (decimal)"") <TAB> self._leading_zero_radix = radix","elif radix == ""decimal"" or radix == ""dec"" :",148
"def _hash_outputs(self, hash_type, tx_in_idx): <TAB> txs_out = self.tx.txs_out <TAB> if hash_type & 0x1F == SIGHASH_SINGLE: <MASK> return ZERO32 <TAB>  <TAB> txs_out = txs_out[tx_in_idx : tx_in_idx + 1] <TAB> elif hash_type & 0x1F == SIGHASH_NONE: <TAB>  <TAB> return ZERO32 <TAB> f = io.BytesIO() <TAB> for tx_out in txs_out: <TAB>  <TAB> stream_struct(""QS"", f, tx_out.coin_value, tx_out.script) <TAB> return sha256(f.getvalue())",if tx_in_idx >= len ( txs_out ) :,182
def clone_list(l): <TAB> l2 = [] <TAB> for x in l: <MASK> l2.append(newstyle(x.value)) <TAB>  <TAB> elif x is oldstyle: <TAB>  <TAB>  <TAB> l2.append(oldstyle(x.value)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> l2.append(x) <TAB> return l2,if x is newstyle :,92
"def showResultsWindow(self): <TAB> if self.resultWindow is not None: <MASK> if self.main_window.indexOfWidget(self.resultWindow) < 0: <TAB>  <TAB>  <TAB>  <TAB> self.main_window.addTab(self.resultWindow, ""Results"", switch=True) <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> self.main_window.showTab(self.resultWindow) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.resultWindow.show()",if self . use_tabs :,118
"def __human_sort_key(self, text, reg=re.compile(""<.*?>"")): <TAB> try: <TAB>  <TAB> return self.__sort_cache[text], text <TAB> except KeyError: <TAB>  <TAB> # remove the markup so it doesn't affect the sort order <MASK> text_stripped = reg.sub("""", text) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> text_stripped = text <TAB>  <TAB> self.__sort_cache[text] = util.human_sort_key(text_stripped) <TAB>  <TAB> return self.__sort_cache[text], text",if self . config . has_markup :,136
"def __lt__(self, other) -> bool: <TAB> if isinstance(other, CountableInteger): <MASK> return other._finite and cast(int, self._integer) < cast( <TAB>  <TAB>  <TAB>  <TAB> int, other._integer <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> elif isinstance(other, int): <TAB>  <TAB> return self._finite and cast(int, self._integer) < other <TAB> else: <TAB>  <TAB> return False",if self . _finite :,111
"def wrapper(event, context): <TAB> try: <TAB>  <TAB> middleware = functools.partial(decorator, func, event, context, **kwargs) <MASK> tracer = Tracer(auto_patch=False) <TAB>  <TAB>  <TAB> with tracer.provider.in_subsegment(name=f""## {decorator.__qualname__}""): <TAB>  <TAB>  <TAB>  <TAB> response = middleware() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> response = middleware() <TAB>  <TAB> return response <TAB> except Exception: <TAB>  <TAB> logger.exception(f""Caught exception in {decorator.__qualname__}"") <TAB>  <TAB> raise",if trace_execution :,134
"def get_candle_frequencies(self, data_frequency=None): <TAB> frequencies = [] <TAB> try: <TAB>  <TAB> for timeframe in self.api.timeframes: <TAB>  <TAB>  <TAB> freq = CCXT.get_frequency(timeframe, raise_error=False) <TAB>  <TAB>  <TAB> # TODO: support all frequencies <MASK> continue <TAB>  <TAB>  <TAB> elif data_frequency == ""hourly"" and not freq.endswith(""D""): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> elif data_frequency == ""daily"" and not freq.endswith(""D""): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> frequencies.append(freq) <TAB> except Exception as e: <TAB>  <TAB> log.warn(""candle frequencies not available for exchange {}"".format(self.name)) <TAB> return frequencies","if data_frequency == ""minute"" and not freq . endswith ( ""T"" ) :",193
"def _checkSize(self, size, strict): <TAB> field = self <TAB> while field._size is None: <MASK> assert self.stream.size is None <TAB>  <TAB>  <TAB> if not strict: <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB>  <TAB> if self.stream.sizeGe(size): <TAB>  <TAB>  <TAB>  <TAB> return 0 <TAB>  <TAB>  <TAB> break <TAB>  <TAB> size += field._address <TAB>  <TAB> field = field._parent <TAB> return field._size - size",if not field . _parent :,112
"def _init_TZ_ABBR(): <TAB> """"""Initialized TZ_ABBR_OFFS dictionary (TZ -> offset in minutes)"""""" <TAB> for tzline in map(str.split, TZ_STR.split(""\n"")): <MASK> continue <TAB>  <TAB> tzoffset = int(float(tzline[0]) * 60) <TAB>  <TAB> for tz in tzline[1:]: <TAB>  <TAB>  <TAB> TZ_ABBR_OFFS[tz] = tzoffset",if not len ( tzline ) :,110
"def get_points_minmax(points): <TAB> xmin = xmax = ymin = ymax = None <TAB> for line in points: <TAB>  <TAB> for x, y in line: <MASK> xmin = x <TAB>  <TAB>  <TAB> if xmax is None or x > xmax: <TAB>  <TAB>  <TAB>  <TAB> xmax = x <TAB>  <TAB>  <TAB> if ymin is None or y < ymin: <TAB>  <TAB>  <TAB>  <TAB> ymin = y <TAB>  <TAB>  <TAB> if ymax is None or y > ymax: <TAB>  <TAB>  <TAB>  <TAB> ymax = y <TAB> return xmin, xmax, ymin, ymax",if xmin is None or x < xmin :,132
"def project_before_template(auth, node, **kwargs): <TAB> prompts = [] <TAB> for addon in node.get_addons(): <MASK> if addon.to_json(auth.user)[""addon_full_name""]: <TAB>  <TAB>  <TAB>  <TAB> prompts.append(addon.to_json(auth.user)[""addon_full_name""]) <TAB> return {""prompts"": prompts, ""isRegistration"": node.is_registration}","if ""node"" in addon . config . configs :",115
"def __init__( <TAB> self, <TAB> size: tp.Union[int, core.Parameter], <TAB> axes: tp.Optional[tp.Union[int, tp.Iterable[int]]] = None,): <TAB> if not isinstance(axes, core.Parameter): <TAB>  <TAB> axes = ( <TAB>  <TAB>  <TAB> (axes,) <MASK> else tuple(axes) <TAB>  <TAB>  <TAB> if axes is not None <TAB>  <TAB>  <TAB> else None <TAB>  <TAB> ) <TAB> super().__init__(axes=axes, size=size)","if isinstance ( axes , int )",125
"def cross_compiler_prefix(self): <TAB> try: <TAB>  <TAB> # cross-compilation of x86 32bit binaries on a x86_64 host is <TAB>  <TAB> # possible by reusing the native toolchain - let Kbuild figure <TAB>  <TAB> # it out by itself and pass down an empty cross-compiler-prefix <TAB>  <TAB> # to start the build <MASK> return """" <TAB>  <TAB> return self.__machine_info[""cross-compiler-prefix""] <TAB> except KeyError: <TAB>  <TAB> raise errors.SnapcraftEnvironmentError( <TAB>  <TAB>  <TAB> ""Cross compilation not supported for target arch {!r}"".format( <TAB>  <TAB>  <TAB>  <TAB> self.__target_machine <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> )","if self . __platform_arch == ""x86_64"" and self . __target_machine == ""i686"" :",182
"def generate(self, menuhandler): <TAB> rv = [] <TAB> for p in menuhandler.config[""recent_profiles""]: <TAB>  <TAB> filename = find_profile(p) <TAB>  <TAB> if filename: <TAB>  <TAB>  <TAB> menuitem = MenuItem(""generated"", p) <TAB>  <TAB>  <TAB> menuitem.filename = filename <TAB>  <TAB>  <TAB> menuitem.callback = ProfileListMenuGenerator.callback <TAB>  <TAB>  <TAB> rv.append(menuitem) <MASK> break <TAB> return rv",if len ( rv ) >= self . rows :,116
"def test_insensitive(self): <TAB> with test_support.EnvironmentVarGuard() as env: <TAB>  <TAB> env.set(""PYTHONCASEOK"", ""1"") <MASK> self.skipTest(""os.environ changes not reflected in "" ""_os.environ"") <TAB>  <TAB> sensitive, insensitive = self.sensitivity_test() <TAB>  <TAB> self.assertIsNotNone(sensitive) <TAB>  <TAB> self.assertIn(self.name, sensitive.get_filename(self.name)) <TAB>  <TAB> self.assertIsNotNone(insensitive) <TAB>  <TAB> self.assertIn(self.name, insensitive.get_filename(self.name))","if b""PYTHONCASEOK"" not in self . importlib . _bootstrap_external . _os . environ :",154
"def dump_encoded_string(encoding, s): <TAB> """"""Dump s, assumed to be an encoded string."""""" <TAB> # Can't use g.trace here: it calls this function! <TAB> print(""dump_encoded_string: %s"" % g.callers()) <TAB> print(""dump_encoded_string: encoding %s\n"" % encoding) <TAB> print(s) <TAB> in_comment = False <TAB> for ch in s: <TAB>  <TAB> if ch == ""#"": <TAB>  <TAB>  <TAB> in_comment = True <MASK> print(""%02x %s"" % (ord(ch), repr(ch))) <TAB>  <TAB> elif ch == ""\n"": <TAB>  <TAB>  <TAB> in_comment = False",elif not in_comment :,162
"def strokes_to_lines(strokes): <TAB> """"""Convert stroke-3 format to polyline format."""""" <TAB> x = 0 <TAB> y = 0 <TAB> lines = [] <TAB> line = [] <TAB> for i in range(len(strokes)): <MASK> x += float(strokes[i, 0]) <TAB>  <TAB>  <TAB> y += float(strokes[i, 1]) <TAB>  <TAB>  <TAB> line.append([x, y]) <TAB>  <TAB>  <TAB> lines.append(line) <TAB>  <TAB>  <TAB> line = [] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> x += float(strokes[i, 0]) <TAB>  <TAB>  <TAB> y += float(strokes[i, 1]) <TAB>  <TAB>  <TAB> line.append([x, y]) <TAB> return lines","if strokes [ i , 2 ] == 1 :",175
"def load(self, inp, get_all=False): <TAB> current = self.get(measure_str_key(inp)) <TAB> if current is not None: <TAB>  <TAB> records = [decode(x) for x in current.split(RedisDatabase.MAGIC_SPLIT)] <TAB>  <TAB> results = [rec[1] for rec in records if rec is not None] <MASK> return results <TAB>  <TAB> return max(results, key=lambda result: result.timestamp) <TAB> return current",if get_all :,117
"def format_counter(self, format, counter): <TAB> label = """" <TAB> for c in format: <TAB>  <TAB> if c == ""1"": <TAB>  <TAB>  <TAB> label = label + (""%d"" % counter) <MASK> if counter > 0: <TAB>  <TAB>  <TAB>  <TAB> label = label + self.format_letter(c, counter) <TAB>  <TAB> elif c in ""iI"": <TAB>  <TAB>  <TAB> if counter > 0: <TAB>  <TAB>  <TAB>  <TAB> label = label + self.format_roman(c, counter) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> label = label + c <TAB> return label","elif c in ""aA"" :",141
"def check_worker_status(self): <TAB> for i in range(self.worker_num): <TAB>  <TAB> worker_pod = self.client.get_worker_pod(i) <TAB>  <TAB> worker_pod_name = self.client.get_worker_pod_name(i) <TAB>  <TAB> if worker_pod is None: <TAB>  <TAB>  <TAB> logger.error(""Worker {} Not Found"".format(worker_pod_name)) <MASK> logger.error( <TAB>  <TAB>  <TAB>  <TAB> ""Worker {} {}"".format(worker_pod_name, worker_pod.status.phase) <TAB>  <TAB>  <TAB> )",elif worker_pod . status . phase == PodStatus . FAILED :,152
"def scan_maps(self): <TAB> for generator in self.generator_list: <TAB>  <TAB> for ii in generator.parser_output.instructions: <MASK> if ii.is_vex(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.max_map_vex = max(self.max_map_vex, ii.get_map()) <TAB>  <TAB>  <TAB>  <TAB> elif ii.is_evex(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.max_map_evex = max(self.max_map_evex, ii.get_map())","if genutil . field_check ( ii , ""iclass"" ) :",138
"def get_searchable_content(self, value): <TAB> # Return the display value as the searchable value <TAB> content = [] <TAB> text_value = force_str(value) <TAB> for k, v in self.field.choices: <TAB>  <TAB> if isinstance(v, (list, tuple)): <TAB>  <TAB>  <TAB> # This is an optgroup, so look inside the group for options <TAB>  <TAB>  <TAB> for k2, v2 in v: <MASK> content.append(force_str(k)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> content.append(force_str(v2)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if value == k or text_value == force_str(k): <TAB>  <TAB>  <TAB>  <TAB> content.append(force_str(v)) <TAB> return content",if value == k2 or text_value == force_str ( k2 ) :,194
"def _read_thread(proc, ready_event): <TAB> """"""Thread to continuously read from the process stdout."""""" <TAB> ready = False <TAB> while True: <TAB>  <TAB> line = proc.stdout.readline() <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB> break <MASK> output_lines.append(line) <TAB>  <TAB> if not ready and indicator in line: <TAB>  <TAB>  <TAB> ready = True <TAB>  <TAB>  <TAB> ready_event.set()",if output_lines is not None :,110
"def readline(self): <TAB> while True: <TAB>  <TAB> # check if there is no unprocessed data in the buffer <TAB>  <TAB> if not self._buffer or self._processed_buffer_it != 0: <TAB>  <TAB>  <TAB> chunk = await self._reader.read(1024 * 1024) <TAB>  <TAB>  <TAB> if not chunk: <TAB>  <TAB>  <TAB>  <TAB> return bytes()  # EOF <TAB>  <TAB>  <TAB> self._buffer += chunk <TAB>  <TAB> it = self._buffer.find(b""\n"", self._processed_buffer_it) <MASK> self._processed_buffer_it = len(self._buffer) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> line = self._buffer[:it] <TAB>  <TAB> self._buffer = self._buffer[it + 1 :] <TAB>  <TAB> self._processed_buffer_it = 0 <TAB>  <TAB> return line",if it < 0 :,186
"def add_model_to_list(self): <TAB> found_task = False <TAB> match_file = open(""match.yml"", ""r"") <TAB> lines = match_file.readlines() <TAB> match_file.close() <TAB> match_file = open(""match.yml"", ""w"") <TAB> for line in lines: <MASK> found_task = True <TAB>  <TAB> if ""dataset"" in line and found_task: <TAB>  <TAB>  <TAB> line = "" "" * 4 + ""- %s\n"" % self.model_name + line <TAB>  <TAB>  <TAB> found_task = False <TAB>  <TAB> match_file.write(line) <TAB> print(""Added model to the list --- match.yml"")","if self . model_task + "":\n"" == line :",173
"def _preprocess_decorator_list(self, node): <TAB> decorators = [] <TAB> for d in node.decorator_list: <TAB>  <TAB> if isinstance(d, ast3.Name): <TAB>  <TAB>  <TAB> decorators.append(d.id) <MASK> decorators.append(f""{d.value.id}.{d.attr}"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ParseError(f""Unexpected decorator: {d}"") <TAB> node.decorator_list = decorators","elif isinstance ( d , ast3 . Attribute ) :",116
"def path_sum3(root, sum): <TAB> if root is None: <TAB>  <TAB> return [] <TAB> res = [] <TAB> queue = [(root, root.val, [root.val])] <TAB> while queue: <TAB>  <TAB> node, val, ls = queue.pop(0)  # popleft <TAB>  <TAB> if node.left is None and node.right is None and val == sum: <TAB>  <TAB>  <TAB> res.append(ls) <MASK> queue.append((node.left, val + node.left.val, ls + [node.left.val])) <TAB>  <TAB> if node.right is not None: <TAB>  <TAB>  <TAB> queue.append((node.right, val + node.right.val, ls + [node.right.val])) <TAB> return res",if node . left is not None :,182
"def __init__(self, client, checked, obj, trello_card=None): <TAB> super(Checklist, self).__init__() <TAB> self.client = client <TAB> self.trello_card = trello_card <TAB> self.id = obj[""id""] <TAB> self.name = obj[""name""] <TAB> self.items = sorted(obj[""checkItems""], key=lambda items: items.get(""pos"")) <TAB> for i in self.items: <TAB>  <TAB> i[""checked""] = False <TAB>  <TAB> for cis in checked: <MASK> i[""checked""] = True","if cis [ ""idCheckItem"" ] == i [ ""id"" ] and cis [ ""state"" ] == ""complete"" :",163
"def storage_path(cls, data, snapshots=None): <TAB> # in the nested item case try to get the path from parent <TAB> try: <TAB>  <TAB> return super(Annotation, cls).storage_path(data, snapshots) <TAB> except PathResolutionError as e: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> parent = data.data_store.get(""parent"", snapshots=snapshots) <TAB>  <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB>  <TAB> raise e <TAB>  <TAB>  <TAB> return Item.storage_path(parent, snapshots) <TAB>  <TAB> raise e","if isinstance ( data , cls ) :",131
"def _port_default(self): <TAB> if os.environ.get(""JUPYTERHUB_SERVICE_URL""): <TAB>  <TAB> url = urlparse(os.environ[""JUPYTERHUB_SERVICE_URL""]) <TAB>  <TAB> if url.port: <TAB>  <TAB>  <TAB> return url.port <MASK> return 80 <TAB>  <TAB> elif url.scheme == ""https"": <TAB>  <TAB>  <TAB> return 443 <TAB> return 8888","elif url . scheme == ""http"" :",100
"def packet_generator(self): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> packet = self.receive_packet() <TAB>  <TAB>  <TAB> if not packet: <TAB>  <TAB>  <TAB>  <TAB> break <MASK> continue <TAB>  <TAB>  <TAB> yield packet <TAB>  <TAB> except (Exception, KeyboardInterrupt): <TAB>  <TAB>  <TAB> self.disconnect() <TAB>  <TAB>  <TAB> raise",if packet is True :,87
"def _refresh_registry(cls): <TAB> """"""Refreshes the registry to add new visualization instances."""""" <TAB> cls._calculations_dict.clear() <TAB> # Add new visualization instances to the registry. <TAB> for name, clazz in inspect.getmembers(models, predicate=inspect.isclass): <TAB>  <TAB> if name.endswith(""_test"") or name == ""BaseCalculation"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> ancestor_names = [base_class.__name__ for base_class in inspect.getmro(clazz)] <MASK> continue <TAB>  <TAB> cls._calculations_dict[clazz.__name__] = clazz","if ""BaseCalculation"" not in ancestor_names :",151
"def findallfiles(dirname): <TAB> """"""Generate all files in given directory or children thereof."""""" <TAB> contents = os.listdir(dirname) <TAB> for f in contents: <TAB>  <TAB> fullpath = os.path.join(dirname, f) <TAB>  <TAB> if os.path.isfile(fullpath): <TAB>  <TAB>  <TAB> yield fullpath <MASK> for subdirname in findallfiles(fullpath): <TAB>  <TAB>  <TAB>  <TAB> yield subdirname",if os . path . isdir ( fullpath ) :,105
"def determine_block_hints(self, text): <TAB> hints = u"""" <TAB> if text: <TAB>  <TAB> if text[0] in u"" \n\x85\u2028\u2029"": <TAB>  <TAB>  <TAB> hints += unicode(self.best_indent) <MASK> hints += u""-"" <TAB>  <TAB> elif len(text) == 1 or text[-2] in u""\n\x85\u2028\u2029"": <TAB>  <TAB>  <TAB> hints += u""+"" <TAB> return hints","if text [ - 1 ] not in u""\n\x85\u2028\u2029"" :",139
"def attach_user_data(report, ui=None): <TAB> """"""Optionally provide user-data if desired."""""" <TAB> if ui: <TAB>  <TAB> prompt = ( <TAB>  <TAB>  <TAB> ""Your user-data or cloud-config file can optionally be provided"" <TAB>  <TAB>  <TAB> "" from {0} and could be useful to developers when addressing this"" <TAB>  <TAB>  <TAB> "" bug. Do you wish to attach user-data to this bug?"".format(USER_DATA_FILE) <TAB>  <TAB> ) <TAB>  <TAB> response = ui.yesno(prompt) <MASK> raise StopIteration  # User cancelled <TAB>  <TAB> if response: <TAB>  <TAB>  <TAB> attach_file(report, USER_DATA_FILE, ""user_data.txt"")",if response is None :,166
"def _splitall(path): <TAB> """"""Split 'path' into all its components."""""" <TAB> # From http://my.safaribooksonline.com/book/programming/ <TAB> # python/0596001673/files/pythoncook-chp-4-sect-16 <TAB> allparts = [] <TAB> while True: <TAB>  <TAB> parts = os.path.split(path) <MASK> # sentinel for absolute paths <TAB>  <TAB>  <TAB> allparts.insert(0, parts[0]) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif parts[1] == path:  # sentinel for relative paths <TAB>  <TAB>  <TAB> allparts.insert(0, parts[1]) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> path = parts[0] <TAB>  <TAB>  <TAB> allparts.insert(0, parts[1]) <TAB> return allparts",if parts [ 0 ] == path :,196
"def PyJsHoisted_find_(callback, this, arguments, var=var): <TAB> var = Scope({u""this"": this, u""callback"": callback, u""arguments"": arguments}, var) <TAB> var.registers([u""path"", u""callback""]) <TAB> var.put(u""path"", var.get(u""this"")) <TAB> while 1: <TAB>  <TAB> if var.get(u""callback"")(var.get(u""path"")): <TAB>  <TAB>  <TAB> return var.get(u""path"") <MASK> break <TAB> return var.get(u""null"")","if not var . put ( u""path"" , var . get ( u""path"" ) . get ( u""parentPath"" ) ) :",160
"def on_click(self, event): <TAB> button = event[""button""] <TAB> if button == self.button_share: <TAB>  <TAB> share = self.speedtest_data.get(""share"") <TAB>  <TAB> if share: <TAB>  <TAB>  <TAB> self.py3.command_run(f""xdg-open {share}"") <TAB> if button == self.button_refresh: <TAB>  <TAB> if self.thread and not self.thread.isAlive(): <TAB>  <TAB>  <TAB> self.thread = None <MASK> self.thread = Thread(target=self._set_speedtest_data) <TAB>  <TAB>  <TAB> self.thread.daemon = True <TAB>  <TAB>  <TAB> self.thread.start()",if self . thread is None :,159
"def _modifiers(self, pygletmod=None): <TAB> mod = () <TAB> if pygletmod is None: <TAB>  <TAB> pygletmod = self._current_modifiers <TAB> if isinstance(pygletmod, set): <TAB>  <TAB> for key in pygletmod: <TAB>  <TAB>  <TAB> mod += (KEYMAP[key],) <TAB> else: <TAB>  <TAB> if pygletmod & pyglet.window.key.MOD_SHIFT: <TAB>  <TAB>  <TAB> mod += (keys.SHIFT,) <TAB>  <TAB> if pygletmod & pyglet.window.key.MOD_CTRL: <TAB>  <TAB>  <TAB> mod += (keys.CONTROL,) <MASK> mod += (keys.ALT,) <TAB> return mod",if pygletmod & pyglet . window . key . MOD_ALT :,183
"def handle_js_int_overflow(data): <TAB> for d in data.get(""records"", dict()): <TAB>  <TAB> for k, v in list(d.items()): <MASK> # if an int is too big for Java Script to handle <TAB>  <TAB>  <TAB>  <TAB> # convert it to a string <TAB>  <TAB>  <TAB>  <TAB> if abs(v) > JS_MAX_INTEGER: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> d[k] = str(v) <TAB> return data","if isinstance ( v , int ) :",114
"def fit(self, data): <TAB> with timer((""fit %s"" % self.name), logging.DEBUG): <TAB>  <TAB> series = self.series(data) <TAB>  <TAB> self.__min = series.min() <TAB>  <TAB> self.__range = series.max() - self.__min <MASK> logger.warning( <TAB>  <TAB>  <TAB>  <TAB> ""Discrete timedelta requires (slower) 64bit float math. "" <TAB>  <TAB>  <TAB>  <TAB> ""Could you use the epoch instead for %s?"" % self.name <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.__range = self.__range.total_seconds() * 1000000000","if isinstance ( self . __range , timedelta ) :",145
"def multi_device(reader, dev_count): <TAB> """"""multi device"""""" <TAB> if dev_count == 1: <TAB>  <TAB> for batch in reader: <TAB>  <TAB>  <TAB> yield batch <TAB> else: <TAB>  <TAB> batches = [] <TAB>  <TAB> for batch in reader: <TAB>  <TAB>  <TAB> batches.append(batch) <MASK> yield batches <TAB>  <TAB>  <TAB>  <TAB> batches = []",if len ( batches ) == dev_count :,98
"def preload_download_archive(self): <TAB> fn = self.params.get(""download_archive"") <TAB> if fn is None: <TAB>  <TAB> return False <TAB> try: <TAB>  <TAB> with locked_file(fn, ""r"", encoding=""utf-8"") as archive_file: <TAB>  <TAB>  <TAB> for line in archive_file: <TAB>  <TAB>  <TAB>  <TAB> self.archive.add(line.strip()) <TAB> except IOError as ioe: <MASK> raise <TAB>  <TAB> return False <TAB> return True",if ioe . errno != errno . ENOENT :,125
"def _clean_array(myarray): <TAB> for value in myarray: <TAB>  <TAB> if isinstance(value, dict): <TAB>  <TAB>  <TAB> yield _expand(_clean_dict(value)) <MASK> yield list(_clean_array(value)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield value","elif isinstance ( value , ( list , tuple , set ) ) :",81
"def filter_items_with_no_transactions(iwb_map, float_precision): <TAB> for (company, item, warehouse) in sorted(iwb_map): <TAB>  <TAB> qty_dict = iwb_map[(company, item, warehouse)] <TAB>  <TAB> no_transactions = True <TAB>  <TAB> for key, val in iteritems(qty_dict): <TAB>  <TAB>  <TAB> val = flt(val, float_precision) <TAB>  <TAB>  <TAB> qty_dict[key] = val <TAB>  <TAB>  <TAB> if key != ""val_rate"" and val: <TAB>  <TAB>  <TAB>  <TAB> no_transactions = False <MASK> iwb_map.pop((company, item, warehouse)) <TAB> return iwb_map",if no_transactions :,163
"def compute_grad(y, y_pred): <TAB> if type(y).__name__ == ""ndarray"" or type(y_pred).__name__ == ""ndarray"": <TAB>  <TAB> diff = y_pred - y <TAB>  <TAB> diff[diff > consts.FLOAT_ZERO] = 1 <TAB>  <TAB> diff[diff < consts.FLOAT_ZERO] = -1 <TAB>  <TAB> diff[np.abs(diff) <= consts.FLOAT_ZERO] = 0 <TAB>  <TAB> return diff <TAB> else: <TAB>  <TAB> diff = y_pred - y <TAB>  <TAB> if diff > consts.FLOAT_ZERO: <TAB>  <TAB>  <TAB> return 1 <MASK> return -1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return 0",elif diff < consts . FLOAT_ZERO :,171
"def so_required(self): <TAB> """"""check in manage account if sales order required or not"""""" <TAB> if frappe.db.get_value(""Selling Settings"", None, ""so_required"") == ""Yes"": <TAB>  <TAB> for d in self.get(""items""): <MASK> frappe.throw(_(""Sales Order required for Item {0}"").format(d.item_code))",if not d . against_sales_order :,105
"def load_image(fn): <TAB> # important: assuming all images have distinct names! <TAB> if fn not in load_image._cache: <TAB>  <TAB> # have not seen this image before <TAB>  <TAB> path = get_image_path(fn) <TAB>  <TAB> _, ext = os.path.splitext(fn) <TAB>  <TAB> # print(f'UI: Loading image ""{fn}"" (path={path})') <TAB>  <TAB> if ext == "".png"": <TAB>  <TAB>  <TAB> img = load_image_png(path) <MASK> img = load_image_apng(path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert False, f""load_image: unhandled type ({ext}) for {fn}"" <TAB>  <TAB> load_image._cache[fn] = img <TAB> return load_image._cache[fn]","elif ext == "".apng"" :",189
"def save_gradient(self): <TAB> filetypes = [(""Gradient Files"", ""*.grad""), (""All Files"", ""*"")] <TAB> file_name = tkFileDialog.asksaveasfilename( <TAB>  <TAB> defaultextension="".grad"", filetypes=filetypes <TAB> ) <TAB> if file_name: <TAB>  <TAB> # there is probably a way to find out which file type the user <TAB>  <TAB> # actually selected. But since I don't know it and also don't really <TAB>  <TAB> # know how to find it out, i rely on this error prone method... <MASK> self.gradient_table.save(file_name) <TAB>  <TAB> self.gradient_table.save(file_name)","if "".lut"" == file_name [ len ( file_name ) - 4 : ] :",164
"def crawl(self, parser): <TAB> html_parser = Html_Parser() <TAB> for url in parser[""urls""]: <TAB>  <TAB> response = Html_Downloader.download(url) <TAB>  <TAB> if response is not None: <TAB>  <TAB>  <TAB> proxylist = html_parser.parse(response, parser) <MASK> for proxy in proxylist: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> proxy_str = ""%s:%s"" % (proxy[""ip""], proxy[""port""]) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if proxy_str not in self.proxies: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.proxies.add(proxy_str) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.queue.put(proxy)",if proxylist is not None :,159
"def get_request_headers(self): <TAB> if self.is_request_edited: <TAB>  <TAB> self.flow[""request""][""headers""] = HeadersHelper.flow2origin( <TAB>  <TAB>  <TAB> self.flow[""request""] <TAB>  <TAB> ) <TAB> headers = {} <TAB> unproxy_headers = application.config.get(""proxy.ignored_headers"", {}) <TAB> for name, value in self.flow[""request""][""headers""].items(): <MASK> continue <TAB>  <TAB> if name in unproxy_headers and unproxy_headers[name] in value: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> headers[name] = value <TAB> return headers","if not value or name in [ ""Cache-Control"" , ""Host"" ] :",158
"def stmt_lambda_proc(self, inputstring, **kwargs): <TAB> """"""Add statement lambda definitions."""""" <TAB> regexes = [] <TAB> for i in range(len(self.stmt_lambdas)): <TAB>  <TAB> name = self.stmt_lambda_name(i) <TAB>  <TAB> regex = compile_regex(r""\b%s\b"" % (name,)) <TAB>  <TAB> regexes.append(regex) <TAB> out = [] <TAB> for line in inputstring.splitlines(): <TAB>  <TAB> for i, regex in enumerate(regexes): <MASK> indent, line = split_leading_indent(line) <TAB>  <TAB>  <TAB>  <TAB> out.append(indent + self.stmt_lambdas[i]) <TAB>  <TAB> out.append(line) <TAB> return ""\n"".join(out)",if regex . search ( line ) :,187
"def find_root(y_over_dy, start, steps=10, bounds=(None, None)): <TAB> guess = start <TAB> for i in xrange(steps): <TAB>  <TAB> prev, guess = guess, guess - y_over_dy(guess) <MASK> guess = bounds[0] <TAB>  <TAB> if bounds[1] is not None and guess > bounds[1]: <TAB>  <TAB>  <TAB> guess = bounds[1] <TAB>  <TAB> if guess == prev: <TAB>  <TAB>  <TAB> break <TAB> return guess",if bounds [ 0 ] is not None and guess < bounds [ 0 ] :,130
"def _deprecated_imp(*args, **kwargs): <TAB> # Poor man's replacement for the with statement <TAB> ctx = WarningManager(record=True) <TAB> l = ctx.__enter__() <TAB> warnings.simplefilter(""always"") <TAB> try: <TAB>  <TAB> f(*args, **kwargs) <MASK> raise AssertionError(""No warning raised when calling %s"" % f.__name__) <TAB>  <TAB> if not l[0].category is DeprecationWarning: <TAB>  <TAB>  <TAB> raise AssertionError( <TAB>  <TAB>  <TAB>  <TAB> ""First warning for %s is not a "" <TAB>  <TAB>  <TAB>  <TAB> ""DeprecationWarning( is %s)"" % (f.__name__, l[0]) <TAB>  <TAB>  <TAB> ) <TAB> finally: <TAB>  <TAB> ctx.__exit__()",if not len ( l ) > 0 :,170
"def run(self): <TAB> while not self.closed: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> segment = self.queue.get(block=True, timeout=0.5) <TAB>  <TAB> except queue.Empty: <TAB>  <TAB>  <TAB> continue <MASK> self.write(segment) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> self.close()",if segment is not None :,89
"def ngettext(self, msgid1, msgid2, n): <TAB> try: <TAB>  <TAB> tmsg = self._catalog[(msgid1, self.plural(n))] <TAB> except KeyError: <TAB>  <TAB> if self._fallback: <TAB>  <TAB>  <TAB> return self._fallback.ngettext(msgid1, msgid2, n) <MASK> tmsg = msgid1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tmsg = msgid2 <TAB> return tmsg",if n == 1 :,113
"def update_name_to_match_tag(self): <TAB> parent_tag_id = self.my_config.discovery.parent_tag <TAB> if parent_tag_id and parent_tag_id != ""!CREATE"": <TAB>  <TAB> tag = self.session.config.get_tag(parent_tag_id) <TAB>  <TAB> if tag and self.name != tag.name: <TAB>  <TAB>  <TAB> self.name = self.my_config.name = tag.name <MASK> self.event.data[""name""] = self.name",if self . event :,131
"def _ensure_db(self): <TAB> ""The database isn't opened until first use.  This function ensures it is now open."" <TAB> if not self._db: <MASK> self.dbfilename = "":memory:"" <TAB>  <TAB> self._db = apsw.Connection( <TAB>  <TAB>  <TAB> self.dbfilename, <TAB>  <TAB>  <TAB> flags=apsw.SQLITE_OPEN_URI <TAB>  <TAB>  <TAB> | apsw.SQLITE_OPEN_READWRITE <TAB>  <TAB>  <TAB> | apsw.SQLITE_OPEN_CREATE, <TAB>  <TAB> ) <TAB> return self._db",if not self . dbfilename :,139
"def set_selected_bbox(): <TAB> global is_bbox_selected, selected_bbox <TAB> smallest_area = -1 <TAB> # if clicked inside multiple bboxes selects the smallest one <TAB> for idx, obj in enumerate(img_objects): <TAB>  <TAB> ind, x1, y1, x2, y2 = obj <TAB>  <TAB> if is_mouse_inside_points(x1, y1, x2, y2): <TAB>  <TAB>  <TAB> is_bbox_selected = True <TAB>  <TAB>  <TAB> tmp_area = get_bbox_area(x1, y1, x2, y2) <MASK> smallest_area = tmp_area <TAB>  <TAB>  <TAB>  <TAB> selected_bbox = idx",if tmp_area < smallest_area or smallest_area == - 1 :,175
"def preferences_s(): <TAB> """"""Fetch all preferences for caching."""""" <TAB> # Load Preferences <TAB> pref = Preferences.preferences() <TAB> res = [] <TAB> for m in pref: <MASK> for c in m[""categories""]: <TAB>  <TAB>  <TAB>  <TAB> for p in c[""preferences""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> p[""module""] = m[""name""] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> res.append(p) <TAB> return ajax_response(response=res, status=200)","if len ( m [ ""categories"" ] ) :",115
"def add_columns(columns): <TAB> for name in columns: <TAB>  <TAB> if name in self.columns: <TAB>  <TAB>  <TAB> df.add_column( <TAB>  <TAB>  <TAB>  <TAB> name, self.columns[name], dtype=self._dtypes_override.get(name) <TAB>  <TAB>  <TAB> ) <MASK> if virtual: <TAB>  <TAB>  <TAB>  <TAB> df.add_virtual_column(name, self.virtual_columns[name]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # this might be an expression, create a valid name <TAB>  <TAB>  <TAB> expression = name <TAB>  <TAB>  <TAB> name = vaex.utils.find_valid_name(name) <TAB>  <TAB>  <TAB> df[name] = df._expr(expression)",elif name in self . virtual_columns :,168
"def emit_traceback(self, op: Branch) -> None: <TAB> if op.traceback_entry is not None: <TAB>  <TAB> globals_static = self.emitter.static_name(""globals"", self.module_name) <TAB>  <TAB> self.emit_line( <TAB>  <TAB>  <TAB> 'CPy_AddTraceback(""%s"", ""%s"", %d, %s);' <TAB>  <TAB>  <TAB> % ( <TAB>  <TAB>  <TAB>  <TAB> self.source_path.replace(""\\"", ""\\\\""), <TAB>  <TAB>  <TAB>  <TAB> op.traceback_entry[0], <TAB>  <TAB>  <TAB>  <TAB> op.traceback_entry[1], <TAB>  <TAB>  <TAB>  <TAB> globals_static, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <MASK> self.emit_line('assert(PyErr_Occurred() != NULL && ""failure w/o err!"");')",if DEBUG_ERRORS :,180
"def post_process_context(token_ids, reader, merge=True): <TAB> """"""Post-process the context sequence."""""" <TAB> context = [] <TAB> utt = [] <TAB> for tok_id in token_ids[1:]: <TAB>  <TAB> if tok_id == reader.eos_id: <TAB>  <TAB>  <TAB> utt = reader.tokenizer.convert_ids_to_tokens(utt) <MASK> utt = reader.tokenizer.merge_subword(utt) <TAB>  <TAB>  <TAB> context.append(utt) <TAB>  <TAB>  <TAB> utt = [] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> utt.append(tok_id) <TAB> return context",if merge :,155
"def count(self, obj): <TAB> try: <TAB>  <TAB> jo = _jpype.JObject(obj) <TAB>  <TAB> c = 0 <TAB>  <TAB> for i in self: <MASK> c += 1 <TAB>  <TAB> return c <TAB> except TypeError: <TAB>  <TAB> return 0",if i . equals ( jo ) :,74
"def equals(self, dst): <TAB> if self._attribute and is_iterable(self._src): <TAB>  <TAB> msg = ""%r[%d].%s should be %r, but is %r"" <TAB>  <TAB> for index, item in enumerate(self._src): <TAB>  <TAB>  <TAB> if self._range: <TAB>  <TAB>  <TAB>  <TAB> if index < self._range[0] or index > self._range[1]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> attribute = getattr(item, self._attribute) <TAB>  <TAB>  <TAB> error = msg % (self._src, index, self._attribute, dst, attribute) <MASK> raise AssertionError(error) <TAB> else: <TAB>  <TAB> return self.deep_equals(dst) <TAB> return True",if attribute != dst :,174
"def substitute(self, *args, **kw): <TAB> if args: <TAB>  <TAB> if kw: <TAB>  <TAB>  <TAB> raise TypeError(""You can only give positional *or* keyword arguments"") <MASK> raise TypeError(""You can only give on positional argument"") <TAB>  <TAB> kw = args[0] <TAB> ns = self.default_namespace.copy() <TAB> ns.update(self.namespace) <TAB> ns.update(kw) <TAB> result = self._interpret(ns) <TAB> return result",if len ( args ) > 1 :,120
"def load_all(cls, ir: ""IR"", aconf: Config) -> None: <TAB> assert ir <TAB> # Save TLS contexts from the aconf into the IR. Note that the contexts in the aconf <TAB> # are just ACResources; they need to be turned into IRTLSContexts. <TAB> tls_contexts = aconf.get_config(""tls_contexts"") <TAB> if tls_contexts is not None: <TAB>  <TAB> for config in tls_contexts.values(): <TAB>  <TAB>  <TAB> ctx = IRTLSContext(ir, aconf, **config) <MASK> ctx.referenced_by(config) <TAB>  <TAB>  <TAB>  <TAB> ctx.sourced_by(config) <TAB>  <TAB>  <TAB>  <TAB> ir.save_tls_context(ctx)",if ctx . is_active ( ) :,176
"def render_text(self, outfd, data): <TAB> self.table_header( <TAB>  <TAB> outfd, <TAB>  <TAB> [ <TAB>  <TAB>  <TAB> (""Allocation"", ""[addrpad]""), <TAB>  <TAB>  <TAB> (""Tag"", ""8""), <TAB>  <TAB>  <TAB> (""PoolType"", ""26""), <TAB>  <TAB>  <TAB> (""NumberOfBytes"", """"), <TAB>  <TAB> ], <TAB> ) <TAB> for entry in data: <TAB>  <TAB> # Not available until Vista <TAB>  <TAB> pool_type = """" <MASK> pool_type = entry.PoolType <TAB>  <TAB> # Not available until Vista <TAB>  <TAB> num_bytes = """" <TAB>  <TAB> if hasattr(entry, ""NumberOfBytes""): <TAB>  <TAB>  <TAB> num_bytes = hex(entry.NumberOfBytes) <TAB>  <TAB> self.table_row(outfd, entry.Va, entry.Key, pool_type, num_bytes)","if hasattr ( entry , ""PoolType"" ) :",199
"def _run_rules(self, rule_group): <TAB> from colorama import Fore <TAB> for rule_name, (rule_func, linter_callable) in self._rules.get(rule_group).items(): <TAB>  <TAB> # use new linter if needed <TAB>  <TAB> with LinterScope(self, linter_callable): <TAB>  <TAB>  <TAB> violations = sorted(rule_func()) or [] <MASK> print(""- {} FAIL{}: {}"".format(Fore.RED, Fore.RESET, rule_name)) <TAB>  <TAB>  <TAB>  <TAB> for violation_msg in violations: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> print(violation_msg) <TAB>  <TAB>  <TAB>  <TAB> print() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> print(""- {} pass{}: {} "".format(Fore.GREEN, Fore.RESET, rule_name))",if violations :,191
"def isURITrusted(self, URIToTest): <TAB> URIToTest = URIToTest + ""/"" <TAB> for trustedProtocol in constants.TRUSTABLE_WEB_PROTOCOLS: <TAB>  <TAB> if URIToTest.startswith(trustedProtocol): <TAB>  <TAB>  <TAB> if self._config[""onlySwitchToTrustedDomains""]: <MASK> for trustedDomain in self._config[""trustedDomains""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> trustableURI = """".join([trustedProtocol, trustedDomain, ""/*""]) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if fnmatch(URIToTest, trustableURI): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False","if self . _config [ ""trustedDomains"" ] :",181
"def init_weights(self): <TAB> for m in self.modules(): <MASK> nn.init.normal_(m.weight, 0, 0.01) <TAB>  <TAB>  <TAB> nn.init.constant_(m.bias, 0) <TAB>  <TAB> if isinstance(m, nn.Conv3d): <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> if isinstance(m, nn.BatchNorm3d): <TAB>  <TAB>  <TAB> m.weight.data.fill_(1) <TAB>  <TAB>  <TAB> m.bias.data.fill_(0)","if isinstance ( m , nn . Linear ) :",126
"def write_scatterfunctions_within_if(self, ifstatement): <TAB> fn_section = """" <TAB> for assignment in ifstatement: <TAB>  <TAB> if assignment.startswith(""scatter""): <TAB>  <TAB>  <TAB> fn_section += self.write_scatterfunction( <TAB>  <TAB>  <TAB>  <TAB> ifstatement[assignment], assignment <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if assignment.startswith(""if""): <TAB>  <TAB>  <TAB> fn_section += self.write_scatterfunctions_within_if( <MASK> ) <TAB> return fn_section","ifstatement [ assignment ] [ ""body"" ]",124
"def generate_collection(parent, collection_status, contents_statuses, recurse=False): <TAB> chan = metadata_store.CollectionNode( <TAB>  <TAB> title=parent.title + ""->child_new_nonempty"", <TAB>  <TAB> origin_id=parent.id_, <TAB>  <TAB> status=collection_status, <TAB> ) <TAB> for s in contents_statuses: <TAB>  <TAB> metadata_store.TorrentMetadata( <TAB>  <TAB>  <TAB> infohash=random_infohash(), origin_id=chan.id_, status=s <TAB>  <TAB> ) <MASK> for status in status_types: <TAB>  <TAB>  <TAB>  <TAB> generate_collection(chan, status, [NEW]) <TAB> return chan",if recurse :,156
"def default_plugin_options(plugin, project): <TAB> form_class = plugin.get_conf_form(project) <TAB> if form_class is None: <TAB>  <TAB> return {} <TAB> NOTSET = object() <TAB> plugin_key = plugin.get_conf_key() <TAB> initials = plugin.get_form_initial(project) <TAB> for field in form_class.base_fields: <TAB>  <TAB> key = ""%s:%s"" % (plugin_key, field) <MASK> value = ProjectOption.objects.get_value(project, key, NOTSET) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = options.get(key) <TAB>  <TAB> if value is not NOTSET: <TAB>  <TAB>  <TAB> initials[field] = value <TAB> return initials",if project is not None :,181
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_name(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 16: <TAB>  <TAB>  <TAB> self.add_address_families(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,122
"def auto_process(cls, state, data): <TAB> filters = itertools.chain( <TAB>  <TAB> ( <TAB>  <TAB>  <TAB> filtercls <TAB>  <TAB>  <TAB> for _, filtercls in sorted( <TAB>  <TAB>  <TAB>  <TAB> cls.__subclasses__.items(), key=lambda k_v: k_v[0] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ), <TAB>  <TAB> cls.__anonymous_subclasses__, <TAB> ) <TAB> for filtercls in filters: <TAB>  <TAB> filter_instance = filtercls(state.job, state) <MASK> logger.info( <TAB>  <TAB>  <TAB>  <TAB> ""Auto-applying filter %r to %s"", <TAB>  <TAB>  <TAB>  <TAB> filter_instance, <TAB>  <TAB>  <TAB>  <TAB> state.job.get_location(), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> # filters require a subfilter argument <TAB>  <TAB>  <TAB> data = filter_instance.filter(data, None) <TAB> return data",if filter_instance . match ( ) :,197
"def share_source_strings(catalog, shared_strings): <TAB> """"""Share message IDs between catalogs to save memory."""""" <TAB> if not shared_strings: <TAB>  <TAB> shared_strings.update((m.id, m.id) for m in catalog) <TAB>  <TAB> return <TAB> for m in list(catalog): <TAB>  <TAB> if not m.id: <TAB>  <TAB>  <TAB> continue <MASK> m.id = shared_strings[m.id] <TAB>  <TAB>  <TAB> catalog.delete(m.id) <TAB>  <TAB>  <TAB> catalog[m.id] = m <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> shared_strings[m.id] = m.id",if m . id in shared_strings :,158
"def do_deactivate(self): <TAB> for view in self.window.get_views(): <TAB>  <TAB> handler_id = getattr(view, self.ViewHandlerName, None) <MASK> view.disconnect(handler_id) <TAB>  <TAB> setattr(view, self.ViewHandlerName, None)",if handler_id is not None :,79
"def append_in_normal_order(index, mode): <TAB> phase = 1 <TAB> mode = n - 1 - mode <TAB> for i in range(n): <TAB>  <TAB> bit = 1 << i <MASK> if index & bit != 0: <TAB>  <TAB>  <TAB>  <TAB> return None, None <TAB>  <TAB>  <TAB> return index | bit, phase <TAB>  <TAB> elif index & bit: <TAB>  <TAB>  <TAB> phase *= -1",if i == mode :,99
"def get_unique_symbol_name(self, symbol_name): <TAB> if symbol_name not in self.symbol_names: <TAB>  <TAB> self.symbol_names.add(symbol_name) <TAB>  <TAB> return symbol_name <TAB> i = 0 <TAB> while True: <TAB>  <TAB> name = ""%s_%d"" % (symbol_name, i) <MASK> self.symbol_names.add(name) <TAB>  <TAB>  <TAB> return name <TAB>  <TAB> i += 1",if name not in self . symbol_names :,119
"def IsContainer(t): <TAB> assert isinstance(t, Class) <TAB> if t.name == ""typing.Generic"": <TAB>  <TAB> return True <TAB> for p in t.parents: <MASK> base = p.base_type <TAB>  <TAB>  <TAB> if isinstance(base, ClassType) and IsContainer(base.cls): <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False","if isinstance ( p , GenericType ) :",95
"def delete_all_cookies(self, environ, headers, type_): <TAB> cookie_header = environ.get(""webrec.request_cookie"") <TAB> if not cookie_header: <TAB>  <TAB> cookie_header = environ.get(""HTTP_COOKIE"") <TAB> if not cookie_header: <TAB>  <TAB> return <TAB> all_cooks = cookie_header.split("";"") <TAB> for cook in all_cooks: <TAB>  <TAB> cook = cook.split(""="")[0] <MASK> continue <TAB>  <TAB> self._delete_cookie(headers, cook)","if type_ != ""all"" and cook == self . sesh_key :",140
"def _body(self): <TAB> maxread = max(0, self.content_length) <TAB> stream = self.environ[""wsgi.input""] <TAB> body = BytesIO() if maxread < self.MEMFILE_MAX else TemporaryFile(mode=""w+b"") <TAB> while maxread > 0: <TAB>  <TAB> part = stream.read(min(maxread, self.MEMFILE_MAX)) <MASK> break <TAB>  <TAB> body.write(part) <TAB>  <TAB> maxread -= len(part) <TAB> self.environ[""wsgi.input""] = body <TAB> body.seek(0) <TAB> return body",if not part :,143
"def fulfil(self): <TAB> ""Fulfil"" <TAB> for p in self.orderedproduct_set.all(): <MASK> product = p.product <TAB>  <TAB>  <TAB> product.stock_quantity -= p.quantity <TAB>  <TAB>  <TAB> product.save() <TAB>  <TAB>  <TAB> p.fulfilled = True <TAB>  <TAB>  <TAB> p.save() <TAB>  <TAB> if p.subscription: <TAB>  <TAB>  <TAB> p.subscription.renew()",if not p . fulfilled :,104
"def __getitem__(self, key): <TAB> if isinstance(key, int): <MASK> if self.config[""cache_enabled""]: <TAB>  <TAB>  <TAB>  <TAB> return self.shows[key] <TAB>  <TAB>  <TAB> del self.shows[key] <TAB>  <TAB> return self._getShowData(key) <TAB> return self._getSeries(key)",if key in self . shows :,89
"def dtype_to_ctype(dtype, with_fp_tex_hack=False): <TAB> if dtype is None: <TAB>  <TAB> raise ValueError(""dtype may not be None"") <TAB> dtype = np.dtype(dtype) <TAB> if with_fp_tex_hack: <TAB>  <TAB> if dtype == np.float32: <TAB>  <TAB>  <TAB> return ""fp_tex_float"" <TAB>  <TAB> elif dtype == np.float64: <TAB>  <TAB>  <TAB> return ""fp_tex_double"" <MASK> return ""fp_tex_cfloat"" <TAB>  <TAB> elif dtype == np.complex128: <TAB>  <TAB>  <TAB> return ""fp_tex_cdouble"" <TAB> return base_dtype_to_ctype(dtype)",elif dtype == np . complex64 :,167
def scan(self): <TAB> for i in range(len(self.permutations)): <TAB>  <TAB> self.jobs.put(self.permutations[i]) <TAB> for _ in range(self.thread_count): <TAB>  <TAB> worker = DomainThread(self.jobs) <TAB>  <TAB> worker.setDaemon(True) <TAB>  <TAB> worker.option_extdns = True <TAB>  <TAB> worker.option_geoip = True <MASK> worker.nameservers = [self.nameserver] <TAB>  <TAB> worker.start() <TAB>  <TAB> self.threads.append(worker),if self . nameserver :,130
"def _add_dev_switch(ip, pairs, parent, raw, counts, dev_id): <TAB> dev_type = DeviceType.switch <TAB> if pairs[""Mach type/model""].startswith(""Fibre Channel SM""): <TAB>  <TAB> dev_type = DeviceType.fibre_channel_switch <TAB> dev = _dev(dev_type, pairs, parent, raw) <TAB> mac = pairs.get(""MAC Address"") <TAB> if mac: <MASK> dev[""mac_addresses""] = [] <TAB>  <TAB> if mac.replace("":"", """").upper()[:6] not in MAC_PREFIX_BLACKLIST: <TAB>  <TAB>  <TAB> dev[""mac_addresses""].append(MACAddressField.normalize(mac)) <TAB>  <TAB> dev[""mac_addresses""] = list(set(dev[""mac_addresses""])) <TAB> return dev","if ""mac_addresses"" not in dev :",192
"def get_app_urls(urls): <TAB> for urlconf in urls: <MASK> mod = import_module(urlconf) <TAB>  <TAB>  <TAB> if not hasattr(mod, ""urlpatterns""): <TAB>  <TAB>  <TAB>  <TAB> raise ImproperlyConfigured( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""URLConf `%s` has no urlpatterns attribute"" % urlconf <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> yield getattr(mod, ""urlpatterns"") <TAB>  <TAB> elif isinstance(urlconf, (list, tuple)): <TAB>  <TAB>  <TAB> yield urlconf <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield [urlconf]","if isinstance ( urlconf , str ) :",136
"def assertRaisesRegexp(self, exc, r, fun, *args, **kwargs): <TAB> try: <TAB>  <TAB> fun(*args, **kwargs) <TAB>  <TAB> self.fail(""Exception not raised"") <TAB> except exc as e: <TAB>  <TAB> msg = stderr(e) if isinstance(e, ErrorReturnCode) else str(e) <MASK> self.fail('No ""{0}"" found in ""{1}""'.format(r, msg))","if not re . search ( r , msg ) :",109
"def POST(self): <TAB> user = accounts.get_current_user() <TAB> if user: <TAB>  <TAB> account = OpenLibraryAccount.get_by_email(user.email) <TAB>  <TAB> s3_keys = web.ctx.site.store.get(account._key).get(""s3_keys"") <MASK> response = post_observation(web.data(), s3_keys) <TAB>  <TAB>  <TAB> return delegate.RawText(response)",if s3_keys :,112
"def ListFiles(self): <TAB> top_level = os.path.join(self.dump_dir, self.version) <TAB> for root, _, files in os.walk(top_level): <TAB>  <TAB> for f in files: <TAB>  <TAB>  <TAB> path = os.path.normpath(os.path.join(root, f)) <MASK> path = path[:-3] <TAB>  <TAB>  <TAB> # Return paths relative to the dump dir. <TAB>  <TAB>  <TAB> yield path[len(top_level) + 1 :]","if path . endswith ( "".gz"" ) :",126
"def test_global_only_routes(self): <TAB> require_user(""root"") <TAB> try: <TAB>  <TAB> with IPDB(plugins=[""routes""]) as ipdb: <TAB>  <TAB>  <TAB> (ipdb.routes.add(dst=""172.18.0.0/24"", gateway=""127.0.0.2"", table=100)) <TAB>  <TAB>  <TAB> ipdb.commit() <TAB>  <TAB>  <TAB> assert grep(""ip ro show table 100"", pattern=""172.18.0.0/24"") <TAB> finally: <TAB>  <TAB> with IPDB() as ipdb: <MASK> ipdb.routes.tables[100][""172.18.0.0/24""].remove().commit()","if ""172.18.0.0/24"" in ipdb . routes . tables . get ( 100 , { } ) :",183
"def decide(chosen, not_chosen, rest, count): <TAB> if count < 0 or len(rest) < count: <TAB>  <TAB> return <TAB> if count == 0: <TAB>  <TAB> yield chosen, list(chain(not_chosen, rest)) <TAB> elif len(rest) == count: <MASK> yield list(chain(chosen, rest)), not_chosen <TAB> elif rest: <TAB>  <TAB> item = rest[0] <TAB>  <TAB> if included is None or item in included: <TAB>  <TAB>  <TAB> for set in decide(chosen + [item], not_chosen, rest[1:], count - 1): <TAB>  <TAB>  <TAB>  <TAB> yield set <TAB>  <TAB> for set in decide(chosen, not_chosen + [item], rest[1:], count): <TAB>  <TAB>  <TAB> yield set",if included is None or all ( item in included for item in rest ) :,187
"def run(self): <TAB> while True: <TAB>  <TAB> with self._condition: <TAB>  <TAB>  <TAB> if self._cmd is None: <TAB>  <TAB>  <TAB>  <TAB> self._condition.wait() <TAB>  <TAB>  <TAB> cmd, self._cmd = self._cmd, None <TAB>  <TAB> with self._lock: <MASK> continue <TAB>  <TAB> self._process.wait() <TAB>  <TAB> self._kill_children()","if not self . _start_process ( cmd , close_fds = True ) :",108
"def get_related_ids(self, resources): <TAB> sg_ids = set() <TAB> for r in resources: <TAB>  <TAB> for exp in self.expressions: <TAB>  <TAB>  <TAB> ids = jmespath.search(exp, r) <MASK> sg_ids.update(tuple(ids)) <TAB>  <TAB>  <TAB> elif isinstance(ids, str): <TAB>  <TAB>  <TAB>  <TAB> sg_ids.add(ids) <TAB> return list(sg_ids)","if isinstance ( ids , list ) :",110
"def _load(self, amount): <TAB> """"""Load ``amount`` number of bytes into the buffer."""""" <TAB> self._buffer.smart_truncate() <TAB> part = self._current_part or self._next_part() <TAB> while amount == -1 or amount > 0: <TAB>  <TAB> written = 0 <TAB>  <TAB> if part and not part.bytes_left_to_write(): <TAB>  <TAB>  <TAB> written += self._write(b""\r\n"") <TAB>  <TAB>  <TAB> written += self._write_boundary() <TAB>  <TAB>  <TAB> part = self._next_part() <MASK> written += self._write_closing_boundary() <TAB>  <TAB>  <TAB> self.finished = True <TAB>  <TAB>  <TAB> break <TAB>  <TAB> written += part.write_to(self._buffer, amount) <TAB>  <TAB> if amount != -1: <TAB>  <TAB>  <TAB> amount -= written",if not part :,192
"def __call__(self, string): <TAB> # the special argument ""-"" means sys.std{in,out} <TAB> if string == ""-"": <MASK> return sys.stdin <TAB>  <TAB> elif ""w"" in self._mode: <TAB>  <TAB>  <TAB> return sys.stdout <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> msg = 'argument ""-"" with mode %r' % self._mode <TAB>  <TAB>  <TAB> raise ValueError(msg) <TAB> # all other arguments are used as file names <TAB> try: <TAB>  <TAB> return io.open(string, self._mode, self._bufsize, encoding=""UTF-8"") <TAB> except IOError as e: <TAB>  <TAB> message = ""can't open '%s': %s"" <TAB>  <TAB> raise argparse.ArgumentTypeError(message % (string, e))","if ""r"" in self . _mode :",180
"def _insert_token_positions(self, tokens): <TAB> position = 0 <TAB> for token in tokens: <TAB>  <TAB> if ""start"" not in token: <TAB>  <TAB>  <TAB> token[""start""] = position <MASK> token[""end""] = token[""start""] + len(str(token[""value""])) <TAB>  <TAB> position = token[""end""] + 1","if ""end"" not in token :",90
"def _eval(self, y_true, y_pred): <TAB> one_and_ones = 0 <TAB> zero_or_ones = 0 <TAB> for i in y_true: <TAB>  <TAB> if y_true[i] and y_pred[i]: <TAB>  <TAB>  <TAB> one_and_ones += 1 <MASK> zero_or_ones += 1 <TAB> return one_and_ones / (zero_or_ones + one_and_ones)",elif y_true [ i ] or y_pred [ i ] :,120
"def is_elf(path): <TAB> exec_type = 0 <TAB> ret, result = oe.utils.getstatusoutput(""file -b '%s'"" % path) <TAB> if ret: <TAB>  <TAB> bb.error(""split_and_strip_files: 'file %s' failed"" % path) <TAB>  <TAB> return exec_type <TAB> if ""ELF"" in result: <TAB>  <TAB> exec_type |= 1 <MASK> exec_type |= 2 <TAB>  <TAB> if ""executable"" in result: <TAB>  <TAB>  <TAB> exec_type |= 4 <TAB>  <TAB> if ""shared"" in result: <TAB>  <TAB>  <TAB> exec_type |= 8 <TAB>  <TAB> if ""relocatable"" in result and is_kernel_module(path): <TAB>  <TAB>  <TAB> exec_type |= 16 <TAB> return exec_type","if ""not stripped"" not in result :",187
"def _update_db_schema_res(data, did, sid): <TAB> database = Database.query.filter_by(id=did, server=sid).first() <TAB> if ""schema_res"" in data: <MASK> data[""schema_res""] = "","".join(data[""schema_res""]) <TAB>  <TAB>  <TAB> setattr(database, ""schema_res"", data[""schema_res""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> database_obj = Database( <TAB>  <TAB>  <TAB>  <TAB> id=did, server=sid, schema_res="","".join(data[""schema_res""]) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> db.session.add(database_obj)",if database :,154
"def __call__(self, value, context): <TAB> try: <TAB>  <TAB> value = super(NewType, self).__call__(value) <TAB>  <TAB> return function(value, context) <TAB> except Exception as exception: <TAB>  <TAB> for take_exception, rewrite in exception_handlers.items(): <TAB>  <TAB>  <TAB> if isinstance(exception, take_exception): <MASK> raise ValueError(rewrite) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise rewrite(value) <TAB>  <TAB> if error_text: <TAB>  <TAB>  <TAB> raise ValueError(error_text) <TAB>  <TAB> raise exception","if isinstance ( rewrite , str ) :",141
"def check_suspicious_constructs(fn, lines): <TAB> """"""Check for suspicious reST constructs."""""" <TAB> inprod = False <TAB> for lno, line in enumerate(lines): <TAB>  <TAB> if seems_directive_re.search(line): <TAB>  <TAB>  <TAB> yield lno + 1, ""comment seems to be intended as a directive"" <MASK> inprod = True <TAB>  <TAB> elif not inprod and default_role_re.search(line): <TAB>  <TAB>  <TAB> yield lno + 1, ""default role used"" <TAB>  <TAB> elif inprod and not line.strip(): <TAB>  <TAB>  <TAB> inprod = False","if "".. productionlist::"" in line :",146
"def get_tag_values(self, tags, columns): <TAB> """"""function to get the tag values from tags and columns"""""" <TAB> tag_values = [] <TAB> i = 0 <TAB> while i < len(columns): <TAB>  <TAB> tag_key = columns[i] <MASK> tag_values.append(tags.get(tag_key)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tag_values.append(None) <TAB>  <TAB> i += 1 <TAB> return tag_values",if tag_key in tags :,117
"def __iter__(self): <TAB> iter_rows, self._rows[:] = self._rows[:], () <TAB> while True: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> self._consume_next() <TAB>  <TAB>  <TAB> except StopIteration: <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> iter_rows, self._rows[:] = self._rows[:], () <TAB>  <TAB> while iter_rows: <TAB>  <TAB>  <TAB> yield iter_rows.pop(0)",if not iter_rows :,106
"def default_visit(self, node): <TAB> if isinstance(node, (nodes.Text, nodes.image)):  # direct text containers <TAB>  <TAB> text = node.astext() <TAB>  <TAB> # lineno seems to go backwards sometimes (?) <TAB>  <TAB> self.lastlineno = lineno = max(get_lineno(node) or 0, self.lastlineno) <TAB>  <TAB> seen = set()  # don't report the same issue more than only once per line <TAB>  <TAB> for match in detect_all(text): <TAB>  <TAB>  <TAB> # import pdb; pdb.set_trace() <TAB>  <TAB>  <TAB> issue = match.group() <TAB>  <TAB>  <TAB> line = extract_line(text, match.start()) <MASK> self.builder.check_issue(line, lineno, issue) <TAB>  <TAB>  <TAB>  <TAB> seen.add((issue, line))","if ( issue , line ) not in seen :",197
"def _add_dev_switch(ip, pairs, parent, raw, counts, dev_id): <TAB> dev_type = DeviceType.switch <TAB> if pairs[""Mach type/model""].startswith(""Fibre Channel SM""): <TAB>  <TAB> dev_type = DeviceType.fibre_channel_switch <TAB> dev = _dev(dev_type, pairs, parent, raw) <TAB> mac = pairs.get(""MAC Address"") <TAB> if mac: <TAB>  <TAB> if ""mac_addresses"" not in dev: <TAB>  <TAB>  <TAB> dev[""mac_addresses""] = [] <MASK> dev[""mac_addresses""].append(MACAddressField.normalize(mac)) <TAB>  <TAB> dev[""mac_addresses""] = list(set(dev[""mac_addresses""])) <TAB> return dev","if mac . replace ( "":"" , """" ) . upper ( ) [ : 6 ] not in MAC_PREFIX_BLACKLIST :",192
"def find_subclasses( <TAB> root_python_module: types.ModuleType, <TAB> base_class: T,) -> Generator[T, None, None]: <TAB> """"""Recursively traverse modules finding subclasses of the given type."""""" <TAB> seen = set() <TAB> for _, module in find_internal_python_modules(root_python_module): <TAB>  <TAB> for _, value in module.__dict__.items(): <MASK> if value not in seen: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> seen.add(value) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield value","if inspect . isclass ( value ) and issubclass ( value , base_class ) :",139
"def _format_obj_count(objects): <TAB> """"""Formats object count."""""" <TAB> result = [] <TAB> regex = re.compile(r""<(?P<type>\w+) \'(?P<name>\S+)\'>"") <TAB> for obj_type, obj_count in objects.items(): <TAB>  <TAB> if obj_count != 0: <TAB>  <TAB>  <TAB> match = re.findall(regex, repr(obj_type)) <MASK> obj_type, obj_name = match[0] <TAB>  <TAB>  <TAB>  <TAB> result.append((""%s %s"" % (obj_type, obj_name), obj_count)) <TAB> return sorted(result, key=operator.itemgetter(1), reverse=True)",if match :,163
"def repo_path(self, app): <TAB> tool_shed = common_util.remove_protocol_and_port_from_tool_shed_url(self.tool_shed) <TAB> for shed_tool_conf_dict in app.toolbox.dynamic_confs( <TAB>  <TAB> include_migrated_tool_conf=True <TAB> ): <TAB>  <TAB> tool_path = shed_tool_conf_dict[""tool_path""] <TAB>  <TAB> relative_path = os.path.join( <TAB>  <TAB>  <TAB> tool_path, <TAB>  <TAB>  <TAB> tool_shed, <TAB>  <TAB>  <TAB> ""repos"", <TAB>  <TAB>  <TAB> self.owner, <TAB>  <TAB>  <TAB> self.name, <TAB>  <TAB>  <TAB> self.installed_changeset_revision, <TAB>  <TAB> ) <MASK> return relative_path <TAB> return None",if os . path . exists ( relative_path ) :,193
"def _resolve_lib_imported_symbols(self, lib, imported_libs, generic_refs): <TAB> """"""Resolve the imported symbols in a library."""""" <TAB> for symbol in lib.elf.imported_symbols: <TAB>  <TAB> imported_lib = self._find_exported_symbol(symbol, imported_libs) <TAB>  <TAB> if not imported_lib: <TAB>  <TAB>  <TAB> lib.unresolved_symbols.add(symbol) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lib.linked_symbols[symbol] = imported_lib <TAB>  <TAB>  <TAB> if generic_refs: <TAB>  <TAB>  <TAB>  <TAB> ref_lib = generic_refs.refs.get(imported_lib.path) <MASK> lib.imported_ext_symbols[imported_lib].add(symbol)",if not ref_lib or not symbol in ref_lib . exported_symbols :,189
"def add_tag(self, tag, auth, save=True, log=True): <TAB> from osf.models import Tag, NodeLog  # Prevent import error <TAB> if not self.tags.filter(system=False, name=tag).exists() and not getattr( <TAB>  <TAB> self.target, ""is_registration"", False <TAB> ): <TAB>  <TAB> new_tag = Tag.load(tag) <TAB>  <TAB> if not new_tag: <TAB>  <TAB>  <TAB> new_tag = Tag(name=tag) <TAB>  <TAB> new_tag.save() <TAB>  <TAB> self.tags.add(new_tag) <MASK> self.add_tag_log(NodeLog.FILE_TAG_ADDED, tag, auth) <TAB>  <TAB> if save: <TAB>  <TAB>  <TAB> self.save() <TAB>  <TAB> return True <TAB> return False",if log :,189
"def __init__(self): <TAB> self.word_map = {} <TAB> self.phonemes_map = {} <TAB> filename = ""../../dictionaries/VoxForgeDict"" <TAB> for line in csv.reader(open(filename), delimiter="" "", skipinitialspace=True): <MASK> self.word_map[line[0]] = line[2:] <TAB> for file in glob.glob(""phonemes/*.wav""): <TAB>  <TAB> wf = wave.open(file, ""rb"") <TAB>  <TAB> n_frames = wf.getnframes() <TAB>  <TAB> self.phonemes_map[file[9:][:-4]] = wf.readframes(n_frames)",if len ( line ) > 2 :,160
"def clip(token): <TAB> """"""Validation for the ``clip`` property."""""" <TAB> function = parse_function(token) <TAB> if function: <TAB>  <TAB> name, args = function <TAB>  <TAB> if name == ""rect"" and len(args) == 4: <TAB>  <TAB>  <TAB> values = [] <TAB>  <TAB>  <TAB> for arg in args: <MASK> values.append(""auto"") <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> length = get_length(arg) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if length: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> values.append(length) <TAB>  <TAB>  <TAB> if len(values) == 4: <TAB>  <TAB>  <TAB>  <TAB> return tuple(values) <TAB> if get_keyword(token) == ""auto"": <TAB>  <TAB> return ()","if get_keyword ( arg ) == ""auto"" :",184
"def load(cls, machine_name, _path=None): <TAB> if _path is None: <TAB>  <TAB> path = cls.get_machine_file_path() <TAB> else: <TAB>  <TAB> path = _path <TAB> d = {} <TAB> if os.path.isfile(path): <TAB>  <TAB> d = util.load_json(path, cls.api_version) <TAB>  <TAB> if machine_name in d: <TAB>  <TAB>  <TAB> return d[machine_name] <MASK> return d[list(d.keys())[0]] <TAB> raise util.UserError( <TAB>  <TAB> ""No information stored about machine '{0}'. I know about {1}."".format( <TAB>  <TAB>  <TAB> machine_name, util.human_list(d.keys()) <TAB>  <TAB> ) <TAB> )",elif len ( d ) == 1 and machine_name == _get_unique_machine_name ( ) :,196
"def _Dict(self, node): <TAB> children = [] <TAB> children.append(""{"") <TAB> if node.keys: <TAB>  <TAB> for index, (key, value) in enumerate(list(zip(node.keys, node.values))): <TAB>  <TAB>  <TAB> children.extend([key, "":"", value]) <MASK> children.append("","") <TAB> children.append(""}"") <TAB> self._handle(node, children)",if index < len ( node . keys ) - 1 :,107
"def run(self): <TAB> if self.get_ifacesAllWireless(): <MASK> for interface in self.ifaceAvaliable: <TAB>  <TAB>  <TAB>  <TAB> if not self.check_interfaceinNetWorkManager(interface): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> Refactor.settingsNetworkManager(interface) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.flag = 1 <TAB>  <TAB> if self.flag: <TAB>  <TAB>  <TAB> Refactor.kill_procInterfaceBusy() <TAB>  <TAB>  <TAB> Popen([""service"", ""network-manager"", ""restart""]) <TAB>  <TAB>  <TAB> return True <TAB> return False",if self . ifaceAvaliable != [ ] :,136
"def check_logging(self, alb): <TAB> attributes = alb.config.get(""Attributes"", []) <TAB> for attribute in attributes: <MASK> if attribute[""Value""] == ""false"": <TAB>  <TAB>  <TAB>  <TAB> self.add_issue( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> 1, Categories.RECOMMENDATION, alb, notes=""Enable access logs"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return","if attribute . get ( ""Key"" ) == ""access_logs.s3.enabled"" :",110
"def start_font(self, attrs): <TAB> for key, value in attrs.items(): <TAB>  <TAB> if key == ""size"": <TAB>  <TAB>  <TAB> value = int(value) <TAB>  <TAB> elif key == ""family"": <TAB>  <TAB>  <TAB> value = _families[value] <MASK> value = _styles[value] <TAB>  <TAB> elif key == ""weight"": <TAB>  <TAB>  <TAB> value = _weights[value] <TAB>  <TAB> elif key == ""encoding"": <TAB>  <TAB>  <TAB> value = int(value) <TAB>  <TAB> elif key == ""color"": <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""unknown font attribute '%s'"" % key) <TAB>  <TAB> attrs[key] = value <TAB> font = copy.copy(self.fonts[-1]) <TAB> font.update(attrs) <TAB> self.fonts.append(font)","elif key == ""style"" :",195
"def handle_starttag(self, tag, attrs): <TAB> if tag == ""input"": <TAB>  <TAB> attr_dict = {} <TAB>  <TAB> for k, v in attrs: <TAB>  <TAB>  <TAB> attr_dict[k] = v <MASK> self.code = attr_dict[""value""]","if attr_dict [ ""id"" ] == ""code"" :",78
"def f(view, s): <TAB> if mode == modes.VISUAL: <TAB>  <TAB> if s.a <= s.b: <MASK> return R(s.a + 1, address.b) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return R(s.a, address.b) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return R(s.a + 1, address.b) <TAB> elif mode == modes.NORMAL: <TAB>  <TAB> return address <TAB> elif mode == modes.INTERNAL_NORMAL: <TAB>  <TAB> return R(s.a, address.b) <TAB> return s",if address . b < s . b :,147
"def _slice_string(self): <TAB> if isinstance(self.slice, slice): <TAB>  <TAB> sl_start = """" if self.slice.start is None else self.slice.start <TAB>  <TAB> sl_stop = """" if self.slice.stop is None else self.slice.stop <MASK> return ""%s:%s"" % (sl_start, sl_stop) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""%s:%s:%s"" % (sl_start, sl_stop, self.slice.step) <TAB> else: <TAB>  <TAB> return str(self.slice)",if self . slice . step is None :,143
"def mark_inactive(self, save=True): <TAB> """"""Use instead of delete to rename and mark inactive."""""" <TAB> if self.active: <TAB>  <TAB> if ""name"" in self._meta.get_all_field_names(): <TAB>  <TAB>  <TAB> self.original_name = self.name <TAB>  <TAB>  <TAB> self.name = ""_deleted_%s_%s"" % (now().isoformat(), self.name) <TAB>  <TAB> self.active = False <MASK> self.save()",if save :,112
"def get_scale_factor(img, auto_scale, as_uint16): <TAB> if auto_scale: <TAB>  <TAB> if img.dtype == np.uint8: <MASK> return 256 <TAB>  <TAB> elif img.dtype != np.uint16: <TAB>  <TAB>  <TAB> return 65535 if as_uint16 else 255 <TAB> return 1",if as_uint16 :,86
"def dispatch(id_or_ins): <TAB> nonlocal data_proxy <TAB> if isinstance(id_or_ins, Instrument): <TAB>  <TAB> instype = id_or_ins.type <TAB> else: <TAB>  <TAB> if not data_proxy: <TAB>  <TAB>  <TAB> from rqalpha.environment import Environment <TAB>  <TAB>  <TAB> data_proxy = Environment.get_instance().data_proxy <TAB>  <TAB> ins = data_proxy.instruments(id_or_ins) <MASK> raise rq_invalid_argument(id_or_ins) <TAB>  <TAB> instype = ins.type <TAB> try: <TAB>  <TAB> return registry[instype] <TAB> except KeyError: <TAB>  <TAB> raise rq_invalid_argument(id_or_ins)",if not ins :,173
"def check_eol(filename): <TAB> eol = u""\n"" <TAB> with open(filename, ""rb"") as f: <TAB>  <TAB> d = f.read() <MASK> eol = u""\r\n"" <TAB>  <TAB> elif b""\n"" in d: <TAB>  <TAB>  <TAB> eol = u""\n"" <TAB>  <TAB> elif b""\r"" in d: <TAB>  <TAB>  <TAB> eol = u""\r"" <TAB> return eol","if b""\r\n"" in d :",109
"def _startRunCallbacks(self, result): <TAB> if self.called: <TAB>  <TAB> if self._suppressAlreadyCalled: <TAB>  <TAB>  <TAB> self._suppressAlreadyCalled = False <TAB>  <TAB>  <TAB> return <TAB>  <TAB> if self.debug: <MASK> self._debugInfo = DebugInfo() <TAB>  <TAB>  <TAB> extra = ""\n"" + self._debugInfo._getDebugTracebacks() <TAB>  <TAB>  <TAB> raise AlreadyCalledError(extra) <TAB>  <TAB> raise AlreadyCalledError <TAB> if self.debug: <TAB>  <TAB> if self._debugInfo is None: <TAB>  <TAB>  <TAB> self._debugInfo = DebugInfo() <TAB>  <TAB> self._debugInfo.invoker = traceback.format_stack()[:-2] <TAB> self.called = True <TAB> self.result = result <TAB> self._runCallbacks()",if self . _debugInfo is None :,188
"def _get_response_template(self, method_name, http_status): <TAB> if method_name == ""options"" or not self._is_http_error_rescode(http_status): <TAB>  <TAB> response_templates = ( <TAB>  <TAB>  <TAB> {""application/json"": self._response_template} <TAB>  <TAB>  <TAB> if self._response_template <TAB>  <TAB>  <TAB> else self.RESPONSE_OPTION_TEMPLATE <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> response_templates = ( <TAB>  <TAB>  <TAB> {""application/json"": self._error_response_template} <MASK> else self.RESPONSE_TEMPLATE <TAB>  <TAB> ) <TAB> return response_templates",if self . _error_response_template,156
"def _format_param(self, optimizer, param_value, param_name): <TAB> if isinstance(param_value, list) or isinstance(param_value, tuple): <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""expected {} value for {}, got {}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> len(optimizer.param_groups), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> param_name, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> FileNotFoundError(param_value), <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return list(param_value) <TAB> return [param_value] * len(optimizer.param_groups)",if len ( param_value ) != len ( optimizer . param_groups ) :,154
"def _set_setting(self, path, value): <TAB> s = self._settings <TAB> for p in path[:-1]: <TAB>  <TAB> if p not in s: <TAB>  <TAB>  <TAB> s[p] = {} <MASK> s[p] = {} <TAB>  <TAB> s = s[p] <TAB> key = path[-1] <TAB> s[key] = value <TAB> return True","if not isinstance ( s [ p ] , dict ) :",100
"def on_set_proxy(self, scheme, ip, port, user, password): <TAB> if not scheme or scheme.lower() == ""none"": <TAB>  <TAB> self.proxy = None <TAB> elif scheme.lower() == ""any"": <TAB>  <TAB> self.proxy = True <TAB> else: <MASK> auth = ""%s:%s@"".format(user, password) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> auth = """" <TAB>  <TAB> self.proxy = ""%s://%s%s:%s"".format(scheme, auth, ip, port)",if user and password :,129
"def gen_indexes(): <TAB> for index in indexes: <MASK> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""%r is not an instance of "" ""pymongo.operations.IndexModel"" % (index,) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> document = index.document <TAB>  <TAB> names.append(document[""name""]) <TAB>  <TAB> yield document","if not isinstance ( index , IndexModel ) :",87
"def linkify_s_by_sd(self): <TAB> for sd in self: <TAB>  <TAB> dsc = sd.dependent_service_description <TAB>  <TAB> sdval = sd.service_description <MASK> dp = getattr(sd, ""dependency_period"", None) <TAB>  <TAB>  <TAB> dsc.add_service_act_dependency( <TAB>  <TAB>  <TAB>  <TAB> sdval, sd.notification_failure_criteria, dp, sd.inherits_parent <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> dsc.add_service_chk_dependency( <TAB>  <TAB>  <TAB>  <TAB> sdval, sd.execution_failure_criteria, dp, sd.inherits_parent <TAB>  <TAB>  <TAB> )",if dsc is not None and sdval is not None :,163
"def test_validate_setup_for_nested_quota_use_with_param(self, param, result): <TAB> with mock.patch( <TAB>  <TAB> ""cinder.quota_utils.validate_setup_for_nested_quota_use"" <TAB> ) as mock_quota_utils: <MASK> self.req.params[""fix_allocated_quotas""] = param <TAB>  <TAB> self.controller.validate_setup_for_nested_quota_use(self.req) <TAB>  <TAB> mock_quota_utils.assert_called_once_with( <TAB>  <TAB>  <TAB> self.req.environ[""cinder.context""], <TAB>  <TAB>  <TAB> mock.ANY, <TAB>  <TAB>  <TAB> mock.ANY, <TAB>  <TAB>  <TAB> fix_allocated_quotas=result, <TAB>  <TAB> )",if param :,177
"def activate_command(ctx, username): <TAB> """"""Activate a user account."""""" <TAB> try: <TAB>  <TAB> ctx.obj.user_manager.change_user_activation(username, True) <TAB>  <TAB> click.echo(""User {} activated."".format(username)) <TAB>  <TAB> user = ctx.obj.user_manager.find_user(username) <MASK> click.echo(""User created:"") <TAB>  <TAB>  <TAB> click.echo(""\t{}"".format(_user_to_line(user.asDict()))) <TAB> except UnknownUser: <TAB>  <TAB> click.echo(""User {} does not exist!"".format(username), err=True)",if user :,144
"def cleanup_raw_materials_supplied(self, parent_items, raw_material_table): <TAB> """"""Remove all those child items which are no longer present in main item table"""""" <TAB> delete_list = [] <TAB> for d in self.get(raw_material_table): <MASK> # mark for deletion from doclist <TAB>  <TAB>  <TAB> delete_list.append(d) <TAB> # delete from doclist <TAB> if delete_list: <TAB>  <TAB> rm_supplied_details = self.get(raw_material_table) <TAB>  <TAB> self.set(raw_material_table, []) <TAB>  <TAB> for d in rm_supplied_details: <TAB>  <TAB>  <TAB> if d not in delete_list: <TAB>  <TAB>  <TAB>  <TAB> self.append(raw_material_table, d)","if [ d . main_item_code , d . reference_name ] not in parent_items :",199
"def insert_cell(self, col_index, cell_obj): <TAB> if col_index in self.__cells: <MASK> msg = ""Attempt to overwrite cell: sheetname=%r rowx=%d colx=%d"" % ( <TAB>  <TAB>  <TAB>  <TAB> self.__parent.name, <TAB>  <TAB>  <TAB>  <TAB> self.__idx, <TAB>  <TAB>  <TAB>  <TAB> col_index, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> raise Exception(msg) <TAB>  <TAB> prev_cell_obj = self.__cells[col_index] <TAB>  <TAB> sst_idx = getattr(prev_cell_obj, ""sst_idx"", None) <TAB>  <TAB> if sst_idx is not None: <TAB>  <TAB>  <TAB> self.__parent_wb.del_str(sst_idx) <TAB> self.__cells[col_index] = cell_obj",if not self . __parent . _cell_overwrite_ok :,195
"def source(self): <TAB> src = getattr(self, ""_source"", None) <TAB> if not src: <TAB>  <TAB> field_data = getattr(self, ""_field_data"", None) <MASK> src = self._source = getattr(field_data[""instance""], field_data[""attname""]) <TAB>  <TAB>  <TAB> del self._field_data <TAB> return src",if field_data :,89
"def export_items(self, items): <TAB> items_grouped_by_type = group_by_item_type(items) <TAB> for item_type, insert_stmt in self.item_type_to_insert_stmt_mapping.items(): <TAB>  <TAB> item_group = items_grouped_by_type.get(item_type) <MASK> connection = self.engine.connect() <TAB>  <TAB>  <TAB> converted_items = list(self.convert_items(item_group)) <TAB>  <TAB>  <TAB> connection.execute(insert_stmt, converted_items)",if item_group :,134
"def remove_watch(self, path): <TAB> _logger.debug(""Removing watch for %s"", path) <TAB> wd = self.manager.get_wd(path) <TAB> self.manager.rm_watch(wd, True) <TAB> self.watches.remove(path) <TAB> for i in range(len(self.watches)): <TAB>  <TAB> try: <MASK> self.watches.remove(self.watches[i]) <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB> break",if self . watches [ i ] . startswith ( path ) :,129
"def process_preserve_minions(self): <TAB> if hasattr(self.options, ""preserve_minions"") and isinstance( <TAB>  <TAB> self.options.preserve_minions, six.string_types <TAB> ): <TAB>  <TAB> if self.options.preserve_minions.lower() == ""true"": <TAB>  <TAB>  <TAB> self.options.preserve_minions = True <MASK> self.options.preserve_minions = False","elif self . options . preserve_minions . lower ( ) == ""false"" :",115
"def targets(self): <TAB> for fn in listdir(join(dirname(__file__), ""targets"")): <MASK> continue <TAB>  <TAB> if not fn.endswith("".py""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> target = fn[:-3] <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> m = __import__( <TAB>  <TAB>  <TAB>  <TAB> ""buildozer.targets.{0}"".format(target), fromlist=[""buildozer""] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> yield target, m <TAB>  <TAB> except NotImplementedError: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> raise <TAB>  <TAB>  <TAB> pass","if fn . startswith ( ""."" ) or fn . startswith ( ""__"" ) :",142
"def write_sentences(sentences, file_path): <TAB> with io.open(file_path, ""w"", encoding=""utf-8"") as of: <TAB>  <TAB> for sent in sentences: <MASK> of.write("" "".join(sent) + ""\n"") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> of.write(sent + ""\n"")","if isinstance ( sent , ( list , tuple ) ) :",95
def process(self): <TAB> if self.inputs[0].is_linked: <TAB>  <TAB> out = self.inputs[0].sv_get(deepcopy=False) <TAB>  <TAB> for s in self.outputs: <MASK> s.sv_set(out),if s . is_linked :,72
"def _transform_overwrites(entry, data): <TAB> overwrites = [] <TAB> for elem in data: <TAB>  <TAB> allow = Permissions(elem[""allow""]) <TAB>  <TAB> deny = Permissions(elem[""deny""]) <TAB>  <TAB> ow = PermissionOverwrite.from_pair(allow, deny) <TAB>  <TAB> ow_type = elem[""type""] <TAB>  <TAB> ow_id = int(elem[""id""]) <MASK> target = entry.guild.get_role(ow_id) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> target = entry._get_member(ow_id) <TAB>  <TAB> if target is None: <TAB>  <TAB>  <TAB> target = Object(id=ow_id) <TAB>  <TAB> overwrites.append((target, ow)) <TAB> return overwrites","if ow_type == ""role"" :",177
"def make_libraries(product, variant, vndk_version, targets, libs): <TAB> """"""Build lsdump files for specific libs."""""" <TAB> lsdump_paths = read_lsdump_paths( <TAB>  <TAB> product, variant, vndk_version, targets, build=True <TAB> ) <TAB> make_target_paths = [] <TAB> for name in libs: <MASK> raise KeyError(""Cannot find lsdump for %s."" % name) <TAB>  <TAB> for tag_path_dict in lsdump_paths[name].values(): <TAB>  <TAB>  <TAB> make_target_paths.extend(tag_path_dict.values()) <TAB> make_targets(product, variant, make_target_paths)",if not ( name in lsdump_paths and lsdump_paths [ name ] ) :,175
"def __setstate__(self, state: Mapping[str, Any]) -> None: <TAB> self._in_init_ = True <TAB> try: <MASK> state, slotstate = state <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> slotstate = None <TAB>  <TAB> if state: <TAB>  <TAB>  <TAB> self.update(**state) <TAB>  <TAB> if slotstate: <TAB>  <TAB>  <TAB> self.update(**slotstate) <TAB> finally: <TAB>  <TAB> self._in_init_ = False","if isinstance ( state , tuple ) and len ( state ) == 2 :",120
"def _build_row(self, row, parent, align): <TAB> """"""Given a row of text, build table cells."""""" <TAB> tr = etree.SubElement(parent, ""tr"") <TAB> tag = ""td"" <TAB> if parent.tag == ""thead"": <TAB>  <TAB> tag = ""th"" <TAB> cells = self._split_row(row) <TAB> # We use align here rather than cells to ensure every row <TAB> # contains the same number of columns. <TAB> for i, a in enumerate(align): <TAB>  <TAB> c = etree.SubElement(tr, tag) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> c.text = cells[i].strip("" "") <TAB>  <TAB> except IndexError:  # pragma: no cover <TAB>  <TAB>  <TAB> c.text = """" <MASK> c.set(""align"", a)",if a :,185
"def format_libraries(libraries, settings): <TAB> result = [] <TAB> compiler = settings.get_safe(""compiler"") <TAB> compiler_base = settings.get_safe(""compiler.base"") <TAB> for library in libraries: <MASK> if not library.endswith("".lib""): <TAB>  <TAB>  <TAB>  <TAB> library += "".lib"" <TAB>  <TAB>  <TAB> result.append(library) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result.append(""-l%s"" % library) <TAB> return result","if str ( compiler ) == ""Visual Studio"" or str ( compiler_base ) == ""Visual Studio"" :",133
"def enable_cursor(self): <TAB> if self._file.isatty(): <MASK> ci = _CursorInfo() <TAB>  <TAB>  <TAB> handle = ctypes.windll.kernel32.GetStdHandle(-11) <TAB>  <TAB>  <TAB> ctypes.windll.kernel32.GetConsoleCursorInfo(handle, ctypes.byref(ci)) <TAB>  <TAB>  <TAB> ci.visible = True <TAB>  <TAB>  <TAB> ctypes.windll.kernel32.SetConsoleCursorInfo(handle, ctypes.byref(ci)) <TAB>  <TAB> elif os.name == ""posix"": <TAB>  <TAB>  <TAB> self.stream.write(""\033[?25h"")","if os . name == ""nt"" :",141
"def dat_share_api(self, cmd, collection=None, data=None): <TAB> res = None <TAB> try: <MASK> data = {""collDir"": collection.get_dir_path()} <TAB>  <TAB> res = requests.post(self.dat_url + cmd, json=data) <TAB>  <TAB> res.raise_for_status() <TAB>  <TAB> return res.json() <TAB> except Exception as e: <TAB>  <TAB> print(e) <TAB>  <TAB> print(""API Error: "" + cmd) <TAB>  <TAB> if res: <TAB>  <TAB>  <TAB> print(res.text) <TAB>  <TAB> return None",if not data :,141
"def stats(self, *args): <TAB> with self.client_pool.get_and_release(destroy_on_fail=True) as client: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return client.stats(*args) <TAB>  <TAB> except Exception: <MASK> return {} <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise",if self . ignore_exc :,87
"def register(*args, **kwargs): <TAB> option_name = Parser.parse_dest(*args, **kwargs) <TAB> default = kwargs.get(""default"") <TAB> if default is None: <MASK> default = False <TAB>  <TAB> if kwargs.get(""type"") == list: <TAB>  <TAB>  <TAB> default = [] <TAB> defaults[option_name] = RankedValue(RankedValue.HARDCODED, default) <TAB> fingerprint = kwargs.get(""fingerprint"", False) <TAB> if fingerprint: <TAB>  <TAB> if is_list_option(kwargs): <TAB>  <TAB>  <TAB> val_type = kwargs.get(""member_type"", str) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> val_type = kwargs.get(""type"", str) <TAB>  <TAB> fingerprintables[option_name] = val_type","if kwargs . get ( ""type"" ) == bool :",187
"def _get_metadata_objects(self, objs): <TAB> for obj in objs: <TAB>  <TAB> if hasattr(obj, ""metadata""): <TAB>  <TAB>  <TAB> yield obj <TAB>  <TAB> if isinstance(obj, Cluster): <TAB>  <TAB>  <TAB> yield from self._get_metadata_objects(obj.files) <TAB>  <TAB> if isinstance(obj, ClusterList): <TAB>  <TAB>  <TAB> yield from self._get_metadata_objects(obj) <TAB>  <TAB> if isinstance(obj, Album): <TAB>  <TAB>  <TAB> yield from self._get_metadata_objects(obj.tracks) <TAB>  <TAB>  <TAB> yield from self._get_metadata_objects(obj.unmatched_files.iterfiles()) <MASK> yield from self._get_metadata_objects(obj.linked_files)","if isinstance ( obj , Track ) :",173
"def generate_parameters(self, parameter_id, **kwargs): <TAB> params = {} <TAB> for k in self._space: <TAB>  <TAB> t, v = self._space[k][""_type""], self._space[k][""_value""] <TAB>  <TAB> if t == ""choice"": <TAB>  <TAB>  <TAB> params[k] = random.choice(v) <MASK> params[k] = random.choice(range(v[0], v[1])) <TAB>  <TAB> elif t == ""uniform"": <TAB>  <TAB>  <TAB> params[k] = np.random.uniform(v[0], v[1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise RuntimeError(""parameter type {} is supported by DemoTuner!"".format(t)) <TAB> return params","elif t == ""randint"" :",173
"def dump_constants(header): <TAB> output = StringIO() <TAB> output.write(header) <TAB> for attribute in dir(FSEvents): <TAB>  <TAB> value = getattr(FSEvents, attribute) <MASK> output.write("" <TAB> %s = %s\n"" % (attribute, hex(value))) <TAB> content = output.getvalue() <TAB> output.close() <TAB> return content","if attribute . startswith ( ""k"" ) and isinstance ( value , int ) :",110
def proto_flow(self): <TAB> if self.create_conn_obj(): <TAB>  <TAB> self.enum_host_info() <TAB>  <TAB> self.proto_logger() <TAB>  <TAB> self.print_host_info() <TAB>  <TAB> self.login() <MASK> self.call_modules() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.call_cmd_args(),"if hasattr ( self . args , ""module"" ) and self . args . module :",104
"def local_structured_dot(node): <TAB> if node.op == sparse._structured_dot: <TAB>  <TAB> a, b = node.inputs <TAB>  <TAB> if a.type.format == ""csc"": <TAB>  <TAB>  <TAB> a_val, a_ind, a_ptr, a_shape = csm_properties(a) <TAB>  <TAB>  <TAB> a_nsparse = a_shape[0] <TAB>  <TAB>  <TAB> return [sd_csc(a_val, a_ind, a_ptr, a_nsparse, b)] <MASK> a_val, a_ind, a_ptr, a_shape = csm_properties(a) <TAB>  <TAB>  <TAB> return [sd_csr(a_val, a_ind, a_ptr, b)] <TAB> return False","if a . type . format == ""csr"" :",181
"def gethelp(): <TAB> d = path + ""/../.."" <TAB> h = [] <TAB> for root, dirs, files in os.walk(d, topdown=False): <TAB>  <TAB> for name in files: <MASK> h.append((appname(os.path.join(root, name)), os.path.join(root, name))) <TAB> h.sort(key=lambda r: r[0]) <TAB> return h","if ""README"" in name :",109
"def button_press_addon(self, obj): <TAB> """"""Callback function from the user clicking on a line in reg plugin"""""" <TAB> selection = self.addon_list.get_selection() <TAB> if selection: <TAB>  <TAB> model, node = selection.get_selected() <MASK> url = model.get_value(node, 9) <TAB>  <TAB>  <TAB> self.install_addon_path.set_text(url)",if node :,100
"def assertNotAlmostEqual(self, x, y, places=None, msg="""", delta=None): <TAB> if delta is not None and places is not None: <TAB>  <TAB> raise TypeError(""specify delta or places not both"") <TAB> if delta is not None: <TAB>  <TAB> if not (x == y) and abs(x - y) > delta: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> if not msg: <TAB>  <TAB>  <TAB> msg = ""%r == %r within %r delta"" % (x, y, delta) <TAB> else: <TAB>  <TAB> if places is None: <TAB>  <TAB>  <TAB> places = 7 <MASK> return <TAB>  <TAB> if not msg: <TAB>  <TAB>  <TAB> msg = ""%r == %r within %r places"" % (x, y, places) <TAB> assert False, msg","if not ( x == y ) and round ( abs ( y - x ) , places ) != 0 :",197
"def prime(self, callback): <MASK> self.cbhdl = simulator.register_readonly_callback(callback, self) <TAB>  <TAB> if self.cbhdl is None: <TAB>  <TAB>  <TAB> raise_error(self, ""Unable set up %s Trigger"" % (str(self))) <TAB> Trigger.prime(self)",if self . cbhdl is None :,84
"def _assertRankAtLeast2(*arrays): <TAB> for a in arrays: <MASK> raise np.linalg.LinAlgError( <TAB>  <TAB>  <TAB>  <TAB> ""%d-dimensional array given. Array must be "" <TAB>  <TAB>  <TAB>  <TAB> ""at least two-dimensional"" % a.ndim <TAB>  <TAB>  <TAB> )",if a . ndim < 2 :,77
"def test_songtypes(self): <TAB> from quodlibet import formats <TAB> pat = TagsFromPattern(""<tracknumber>. <title>"") <TAB> tracktitle = {""tracknumber"": ""01"", ""title"": ""Title""} <TAB> for ext, kind in formats.loaders.items(): <TAB>  <TAB> f = formats._audio.AudioFile() <MASK> continue <TAB>  <TAB> f.__class__ = kind <TAB>  <TAB> if os.name == ""nt"": <TAB>  <TAB>  <TAB> f[""~filename""] = u""C:\\path\\Artist - Album\\01. Title"" + ext <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> f[""~filename""] = ""/path/Artist - Album/01. Title"" + ext <TAB>  <TAB> self.assertEquals(pat.match(f), tracktitle, ext)","if not isinstance ( kind , type ) :",183
"def add(self, key, value, timeout=None): <TAB> self.validate_key(key) <TAB> self._lock.writer_enters() <TAB> try: <TAB>  <TAB> exp = self._expire_info.get(key) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> self._set(key, pickle.dumps(value), timeout) <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB> except pickle.PickleError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> return False <TAB> finally: <TAB>  <TAB> self._lock.writer_leaves()",if exp is None or exp <= time . time ( ) :,135
"def __init__(self, outfile, show_process, filters): <TAB> self.outfile = outfile <TAB> self.show_process = show_process <TAB> self.filters = list(filters) <TAB> if self.show_process: <TAB>  <TAB> self.filters.insert(0, CwdTracker().filter) <TAB>  <TAB> self.write(""New process: executable: %r\n"" % (sys.executable,)) <TAB>  <TAB> self.write(""New process: cmd: %r\n"" % (getattr(sys, ""argv"", None),)) <MASK> self.write( <TAB>  <TAB>  <TAB>  <TAB> ""New process: pid: %r, parent pid: %r\n"" % (os.getpid(), os.getppid()) <TAB>  <TAB>  <TAB> )","if hasattr ( os , ""getppid"" ) :",180
"def _dynamic_level(level): <TAB> if isinstance(level, str): <TAB>  <TAB> return (level, None) <TAB> if isinstance(level, int): <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Invalid level value, it should be a positive integer, not: %d"" % level <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return (None, level) <TAB> raise TypeError( <TAB>  <TAB> ""Invalid level, it should be an integer or a string, not: '%s'"" <TAB>  <TAB> % type(level).__name__ <TAB> )",if level < 0 :,128
"def _update_crf_order(self, training_data: TrainingData): <TAB> """"""Train only CRFs we actually have training data for."""""" <TAB> _crf_order = [] <TAB> for tag_name in self.crf_order: <TAB>  <TAB> if tag_name == ENTITY_ATTRIBUTE_TYPE and training_data.entities: <TAB>  <TAB>  <TAB> _crf_order.append(ENTITY_ATTRIBUTE_TYPE) <MASK> _crf_order.append(ENTITY_ATTRIBUTE_ROLE) <TAB>  <TAB> elif tag_name == ENTITY_ATTRIBUTE_GROUP and training_data.entity_groups: <TAB>  <TAB>  <TAB> _crf_order.append(ENTITY_ATTRIBUTE_GROUP) <TAB> self.crf_order = _crf_order",elif tag_name == ENTITY_ATTRIBUTE_ROLE and training_data . entity_roles :,180
"def tour_loader(contents_dict): <TAB> #  Some of this can be done on the clientside.  Maybe even should? <TAB> title_default = contents_dict.get(""title_default"", None) <TAB> for step in contents_dict[""steps""]: <TAB>  <TAB> if ""intro"" in step: <TAB>  <TAB>  <TAB> step[""content""] = step.pop(""intro"") <TAB>  <TAB> if ""position"" in step: <TAB>  <TAB>  <TAB> step[""placement""] = step.pop(""position"") <TAB>  <TAB> if ""element"" not in step: <TAB>  <TAB>  <TAB> step[""orphan""] = True <MASK> step[""title""] = title_default <TAB> return contents_dict","if title_default and ""title"" not in step :",164
"def __init__(self, involucro_bin=None, shell_exec=None, verbose=""3""): <TAB> if involucro_bin is None: <MASK> self.involucro_bin = ""./involucro"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.involucro_bin = ""involucro"" <TAB> else: <TAB>  <TAB> self.involucro_bin = involucro_bin <TAB> self.shell_exec = shell_exec or commands.shell <TAB> self.verbose = verbose","if os . path . exists ( ""./involucro"" ) :",131
"def _get_missing_applications_for_steps(self, specified_apps, parsed_args): <TAB> allowed_app_steps = set([constants.HIVE, constants.PIG, constants.IMPALA]) <TAB> missing_apps = set([]) <TAB> if parsed_args.steps is not None: <TAB>  <TAB> for step in parsed_args.steps: <MASK> break <TAB>  <TAB>  <TAB> step_type = step.get(""Type"") <TAB>  <TAB>  <TAB> if step_type is not None: <TAB>  <TAB>  <TAB>  <TAB> step_type = step_type.lower() <TAB>  <TAB>  <TAB>  <TAB> if step_type in allowed_app_steps and step_type not in specified_apps: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> missing_apps.add(step[""Type""].title()) <TAB> return missing_apps",if len ( missing_apps ) == len ( allowed_app_steps ) :,193
"def submitBatch(self, *commands): <TAB> for command in commands: <MASK> # Undo what we already submitted <TAB>  <TAB>  <TAB> for commandToUndo in reversed(self.__buffer.Commands): <TAB>  <TAB>  <TAB>  <TAB> if commandToUndo in commands: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.__buffer.Undo() <TAB>  <TAB>  <TAB> return False <TAB> return True",if not self . __buffer . Submit ( command ) :,92
"def _hash_bundle(bundle): <TAB> hasher = sha1() <TAB> hasher.update(bundle.rel_path.encode()) <TAB> for abs_path in sorted(bundle.filemap.keys()): <TAB>  <TAB> buildroot_relative_path = os.path.relpath(abs_path, get_buildroot()).encode() <TAB>  <TAB> hasher.update(buildroot_relative_path) <TAB>  <TAB> hasher.update(bundle.filemap[abs_path].encode()) <MASK> # Update with any additional string to differentiate empty file with non-existing file. <TAB>  <TAB>  <TAB> hasher.update(b""e"") <TAB>  <TAB>  <TAB> with open(abs_path, ""rb"") as f: <TAB>  <TAB>  <TAB>  <TAB> hasher.update(f.read()) <TAB> return hasher.hexdigest()",if os . path . isfile ( abs_path ) :,195
"def Save(self): <TAB> bar, obj = self._window, self._pObject <TAB> menuCount = bar.GetMenuCount() <TAB> if menuCount == 0: <TAB>  <TAB> # Nothing to save <TAB>  <TAB> return False <TAB> checkRadioItems = {} <TAB> for indx in range(menuCount): <TAB>  <TAB> menu = bar.GetMenu(indx) <TAB>  <TAB> for item in menu.GetMenuItems(): <MASK> checkRadioItems[item.GetId()] = item.IsChecked() <TAB> obj.SaveValue(PERSIST_MENUBAR_CHECKRADIO_ITEMS, checkRadioItems) <TAB> return True","if item . GetKind ( ) in [ wx . ITEM_CHECK , wx . ITEM_RADIO ] :",165
"def sync_pointer_and_stored_name(node, pointer_prop_name, prop_name): <TAB> # in the event that the text datablock is renamed elsewhere, this will automatically <TAB> # resync the stored name of the datablock. updates to datablock names do not <TAB> # automatically call the pointer updatefunction. hence this nonsense <TAB> if hasattr(node, pointer_prop_name): <TAB>  <TAB> pointer = getattr(node, pointer_prop_name) <TAB>  <TAB> if not pointer: <TAB>  <TAB>  <TAB> return <MASK> setattr(node, prop_name, pointer.name) <TAB>  <TAB>  <TAB> node.info(f""synchronized name of {node} from datablock name change"")","if pointer . name != getattr ( node , prop_name ) :",172
"def convertstore(self, inputstore, columnorder=None): <TAB> if columnorder is None: <TAB>  <TAB> columnorder = [""location"", ""source"", ""target""] <TAB> outputstore = csvl10n.csvfile(fieldnames=columnorder) <TAB> for inputunit in inputstore.units: <TAB>  <TAB> outputunit = self.convertunit(inputunit) <MASK> outputstore.addunit(outputunit) <TAB>  <TAB> if inputunit.hasplural(): <TAB>  <TAB>  <TAB> outputunit = self.convertplurals(inputunit) <TAB>  <TAB>  <TAB> if outputunit is not None: <TAB>  <TAB>  <TAB>  <TAB> outputstore.addunit(outputunit) <TAB> return outputstore",if outputunit is not None :,161
"def move_right(cls, terminal): <TAB> box = terminal.get_parent() <TAB> while not isinstance(box, RootTerminalBox): <TAB>  <TAB> box = box.get_parent() <TAB>  <TAB> if isinstance(box, DualTerminalBox): <MASK> x, _, p = cls.list_allocation(box) <TAB>  <TAB>  <TAB>  <TAB> if p + SplitMover.STEP < x - SplitMover.THRESHOLD: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> box.set_position(p + SplitMover.STEP) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> box.set_position(x - SplitMover.THRESHOLD) <TAB>  <TAB>  <TAB>  <TAB> break",if box . get_orientation ( ) == Gtk . Orientation . HORIZONTAL :,169
"def find_supported(ranked): <TAB> """"""Given a ranked language list, return the best-matching locale."""""" <TAB> langs = dict(settings.LANGUAGE_URL_MAP) <TAB> for lang, _ in ranked: <TAB>  <TAB> lang = lang.lower() <TAB>  <TAB> if lang in langs: <TAB>  <TAB>  <TAB> return langs[lang] <TAB>  <TAB> # Add derived language tags to the end of the list as a fallback. <TAB>  <TAB> pre = ""-"".join(lang.split(""-"")[0:-1]) <MASK> ranked.append((pre, None)) <TAB> # Couldn't find any acceptable locale. <TAB> return False",if pre :,140
"def metadata(): <TAB> result = as_dict() <TAB> if result: <TAB>  <TAB> result = {""meta-data"": result} <TAB>  <TAB> user_data = get("""", section=""user-data"") <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> result.update( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> {""user-data"": dict(x.split(""="", 1) for x in user_data.split("";""))} <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> result.update({""user-data"": user_data}) <TAB>  <TAB> result.update({""dynamic"": as_dict(""/"", section=""dynamic"")}) <TAB>  <TAB> return ""EC2"", result <TAB> result = as_dict("""", ""metadata"", ""v1"") <TAB> if result: <TAB>  <TAB> return ""DO"", result <TAB> return None, None",if user_data :,185
"def julian_valid(date_tuple): <TAB> """"""Checks if date_tuple is a valid date in Julian Calendar"""""" <TAB> day = date_tuple[0] <TAB> month = date_tuple[1] <TAB> valid = True <TAB> try: <MASK> valid = False <TAB>  <TAB> elif (date_tuple[2]) % 4 == 0: <TAB>  <TAB>  <TAB> # julian always have leapyear every 4 year <TAB>  <TAB>  <TAB> if day > _leap_days[month - 1]: <TAB>  <TAB>  <TAB>  <TAB> valid = False <TAB>  <TAB> elif day > _max_days[month - 1]: <TAB>  <TAB>  <TAB> valid = False <TAB> except: <TAB>  <TAB> valid = False <TAB> return valid",if month > 12 :,165
"def get_env_dir(opt, args): <TAB> if opt.python_virtualenv: <MASK> res = sys.prefix <TAB>  <TAB> elif hasattr(sys, ""base_prefix"") and sys.base_prefix != sys.prefix: <TAB>  <TAB>  <TAB> res = sys.prefix <TAB>  <TAB> elif ""CONDA_PREFIX"" in os.environ: <TAB>  <TAB>  <TAB> res = sys.prefix <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logger.error(""No python virtualenv is available"") <TAB>  <TAB>  <TAB> sys.exit(2) <TAB> else: <TAB>  <TAB> res = args[0] <TAB> return to_utf8(res)","if hasattr ( sys , ""real_prefix"" ) :",153
"def display(self): <TAB> """"""using the formatter, display the results"""""" <TAB> if self.formatter and self.verbose > 0: <TAB>  <TAB> res = self.results <MASK> print >>self.out, """" <TAB>  <TAB>  <TAB> for a in self.formatter(res, map(lambda x: x[0], self.headers)): <TAB>  <TAB>  <TAB>  <TAB> print >>self.out, a <TAB>  <TAB>  <TAB> print >>self.out, """"",if res :,104
"def _unfold_header_lines(lines): <TAB> headers = deque() <TAB> for line in lines: <TAB>  <TAB> # ignore unix from <TAB>  <TAB> if line.startswith(""From ""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # this is continuation <MASK> _extend_last_header(headers, line) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> headers.append(line) <TAB> new_headers = deque() <TAB> for h in headers: <TAB>  <TAB> if isinstance(h, deque): <TAB>  <TAB>  <TAB> new_headers.append("""".join(h).rstrip(""\r\n"")) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> new_headers.append(h.rstrip(""\r\n"")) <TAB> return new_headers","if line [ 0 ] in "" \t"" :",168
"def format_shared_key_credential(account, credential): <TAB> if isinstance(credential, six.string_types): <TAB>  <TAB> if len(account) < 2: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Unable to determine account name for shared key credential."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> credential = {""account_name"": account[0], ""account_key"": credential} <TAB> if isinstance(credential, dict): <TAB>  <TAB> if ""account_name"" not in credential: <TAB>  <TAB>  <TAB> raise ValueError(""Shared key credential missing 'account_name"") <MASK> raise ValueError(""Shared key credential missing 'account_key"") <TAB>  <TAB> return SharedKeyCredentialPolicy(**credential) <TAB> return credential","if ""account_key"" not in credential :",169
"def read(self, size=None): <TAB> data = """" <TAB> while True: <TAB>  <TAB> if size and len(data) >= size: <TAB>  <TAB>  <TAB> return data <TAB>  <TAB> if not self.buffer: <TAB>  <TAB>  <TAB> self._fetch() <TAB>  <TAB>  <TAB> if not self.buffer: <TAB>  <TAB>  <TAB>  <TAB> # EOF <TAB>  <TAB>  <TAB>  <TAB> return data <MASK> remaining = size - len(data) <TAB>  <TAB>  <TAB> data += self.buffer[:remaining] <TAB>  <TAB>  <TAB> self.buffer = self.buffer[remaining:] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> data += self.buffer",if size :,138
"def value(self, value): <TAB> for component in value: <TAB>  <TAB> if not 0 <= component <= 1: <TAB>  <TAB>  <TAB> raise OutputDeviceBadValue( <TAB>  <TAB>  <TAB>  <TAB> ""each RGB color component must be between 0 and 1"" <TAB>  <TAB>  <TAB> ) <MASK> if component not in (0, 1): <TAB>  <TAB>  <TAB>  <TAB> raise OutputDeviceBadValue( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""each RGB color component must be 0 or 1 with non-PWM RGBLEDs"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> self._stop_blink() <TAB> self.red, self.green, self.blue = value","if isinstance ( self . _leds [ 0 ] , LED ) :",150
"def scan_resource_conf(self, conf): <TAB> log_types = [""profiler"", ""audit""] <TAB> if ""Properties"" in conf.keys(): <MASK> if all( <TAB>  <TAB>  <TAB>  <TAB> elem in conf[""Properties""][""EnableCloudwatchLogsExports""] <TAB>  <TAB>  <TAB>  <TAB> for elem in log_types <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> return CheckResult.PASSED <TAB> return CheckResult.FAILED","if ""EnableCloudwatchLogsExports"" in conf [ ""Properties"" ] . keys ( ) :",114
"def TryMerge(self, d): <TAB> while 1: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 36: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if tt == 41: <TAB>  <TAB>  <TAB> self.set_lat(d.getDouble()) <TAB>  <TAB>  <TAB> continue <MASK> self.set_lng(d.getDouble()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 49 :,124
"def is_subtree(big, small): <TAB> flag = False <TAB> queue = collections.deque() <TAB> queue.append(big) <TAB> while queue: <TAB>  <TAB> node = queue.popleft() <MASK> flag = comp(node, small) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> queue.append(node.left) <TAB>  <TAB>  <TAB> queue.append(node.right) <TAB> return flag",if node . val == small . val :,108
"def eval( <TAB> self, input, glbs=None, locs=None, stacklevel=2, filename=None, transform=True): <TAB> """"""Evaluates (and returns) xonsh code."""""" <TAB> if isinstance(input, types.CodeType): <TAB>  <TAB> code = input <TAB> else: <MASK> filename = self.filename <TAB>  <TAB> code = self.compile( <TAB>  <TAB>  <TAB> input=input, <TAB>  <TAB>  <TAB> glbs=glbs, <TAB>  <TAB>  <TAB> locs=locs, <TAB>  <TAB>  <TAB> mode=""eval"", <TAB>  <TAB>  <TAB> stacklevel=stacklevel, <TAB>  <TAB>  <TAB> filename=filename, <TAB>  <TAB>  <TAB> transform=transform, <TAB>  <TAB> ) <TAB> if code is None: <TAB>  <TAB> return None  # handles comment only input <TAB> return eval(code, glbs, locs)",if filename is None :,187
"def parse_vcs_bundle_file(self, content): <TAB> url = rev = None <TAB> for line in content.splitlines(): <MASK> continue <TAB>  <TAB> match = re.search(r""^bzr\s*branch\s*-r\s*(\d*)"", line) <TAB>  <TAB> if match: <TAB>  <TAB>  <TAB> rev = match.group(1).strip() <TAB>  <TAB> url = line[match.end() :].strip().split(None, 1)[0] <TAB>  <TAB> if url and rev: <TAB>  <TAB>  <TAB> return url, rev <TAB> return None, None","if not line . strip ( ) or line . strip ( ) . startswith ( ""#"" ) :",144
"def index_nodes(self, c): <TAB> writer = self.ix.writer() <TAB> doc = c.mFileName <TAB> for p in c.all_unique_positions(): <TAB>  <TAB> # print ""pushing"",p <MASK> par = p.parent().get_UNL() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> par = c.mFileName <TAB>  <TAB> writer.add_document(h=p.h, b=p.b, gnx=unicode(p.gnx), parent=par, doc=doc) <TAB> writer.commit() <TAB> g._gnxcache.clear()",if p . hasParent ( ) :,145
"def compile_const(self, node): <TAB> left = """" <TAB> if node.left is not NIL: <TAB>  <TAB> left = self.compile(node.left) <TAB> else: <TAB>  <TAB> left = viml_join([self.compile(vval) for vval in node.list], "" "") <MASK> left += "" . "" + self.compile(node.rest) <TAB>  <TAB> left = ""("" + left + "")"" <TAB> right = self.compile(node.right) <TAB> self.out(""(const %s %s %s)"", node.op, left, right)",if node . rest is not NIL :,144
"def sending_profile(self, address): <TAB> default = None <TAB> which_email = None <TAB> for vcl in self.get_all(""x-mailpile-prefer-profile""): <TAB>  <TAB> addr = vcl.get(""address"") <TAB>  <TAB> value = vcl.value <TAB>  <TAB> if addr: <MASK> if "","" in value: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value, which_email = value.split("","") <TAB>  <TAB>  <TAB>  <TAB> return (value, which_email) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if "","" in value: <TAB>  <TAB>  <TAB>  <TAB> default, which_email = value.split("","") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> default, which_email = value, None <TAB> return (default, which_email)",if addr == address . lower ( ) :,180
"def update(self): <TAB> # this code should work only first time a socket was added <TAB> if self.node_tree: <TAB>  <TAB> for n_in_s, t_in_s in zip(self.inputs, self.node_tree.inputs): <TAB>  <TAB>  <TAB> # also before getting data from socket `socket.use_prop` property should be set <TAB>  <TAB>  <TAB> if hasattr(n_in_s, ""default_property""): <TAB>  <TAB>  <TAB>  <TAB> n_in_s.use_prop = not t_in_s.hide_value <MASK> n_in_s.default_property_type = t_in_s.default_type","if hasattr ( t_in_s , ""default_type"" ) :",168
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_server(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> self.set_version(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 24: <TAB>  <TAB>  <TAB> self.set_instances(d.getVarInt64()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 18 :,150
"def vk_o(string): <TAB> result = [] <TAB> index2 = 0 <TAB> for s in string: <TAB>  <TAB> sym_index = VK_STR.find(s) <TAB>  <TAB> if sym_index != -1: <MASK> i = (i << 6) + sym_index <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> i = sym_index <TAB>  <TAB>  <TAB> if index2 % 4 != 0: <TAB>  <TAB>  <TAB>  <TAB> index2 += 1 <TAB>  <TAB>  <TAB>  <TAB> shift = -2 * index2 & 6 <TAB>  <TAB>  <TAB>  <TAB> result += [chr(0xFF & (i >> shift))] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> index2 += 1 <TAB> return """".join(result)",if index2 % 4 != 0 :,174
"def extractAnim(self, riff): <TAB> if ""anim_rate/rate[0]"" in riff: <TAB>  <TAB> count = 0 <TAB>  <TAB> total = 0 <TAB>  <TAB> for rate in riff.array(""anim_rate/rate""): <TAB>  <TAB>  <TAB> count += 1 <MASK> break <TAB>  <TAB>  <TAB> total += rate.value / 60.0 <TAB>  <TAB> if count and total: <TAB>  <TAB>  <TAB> self.frame_rate = count / total <TAB> if not self.has(""frame_rate"") and ""anim_hdr/jiffie_rate"" in riff: <TAB>  <TAB> self.frame_rate = 60.0 / riff[""anim_hdr/jiffie_rate""].value",if 100 < count :,169
"def _get_field_info_by_number(oxx, num_to_field, n): <TAB> try: <TAB>  <TAB> f = num_to_field[n] <TAB>  <TAB> t = f.type <TAB>  <TAB> name = f.name <TAB> except KeyError: <TAB>  <TAB> t = type_desc.UnknownType <MASK> name = ""field_%d"" % (n,) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise KeyError(""unknown %s field number: %s"" % (oxx.upper(), n)) <TAB> return name, t","if isinstance ( n , six . integer_types ) :",138
"def add(self, word): <TAB> with open(self.filename, ""a"") as f: <MASK> log.info(""Adding "" + word + "" to the wordlist.."") <TAB>  <TAB>  <TAB> self.wordlist.append(word + ""\n"") <TAB>  <TAB>  <TAB> f.write(word + ""\n"")","if not word + ""\n"" in self . wordlist :",84
"def file_exists(uri: str, include_dir: bool = True) -> bool: <TAB> try: <TAB>  <TAB> response = urllib.request.urlopen(uri) <MASK> return int(response.headers[""content-length""]) > 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False  # pragma: no cover <TAB> except urllib.error.URLError: <TAB>  <TAB> return False",if response . getcode ( ) == 200 :,98
"def endPacket(self): <TAB> # put in TX mode <TAB> self.SPIWrite(self.REG_OP_MODE, [self.MODE_LONG_RANGE_MODE | self.MODE_TX]) <TAB> while 1:  # Wait for TX done <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""wait..."") <TAB>  <TAB>  <TAB> time.sleep(0.1) <TAB> self.SPIWrite(self.REG_IRQ_FLAGS, [self.IRQ_TX_DONE_MASK])","if self . SPIRead ( self . REG_IRQ_FLAGS , 1 ) [ 0 ] & self . IRQ_TX_DONE_MASK :",155
"def handle_write_event(self): <TAB> if not self._ssl_requested: <TAB>  <TAB> super(SSLConnection, self).handle_write_event() <TAB> else: <TAB>  <TAB> with self._handle_ssl_want_rw(): <TAB>  <TAB>  <TAB> self._ssl_want_write = False <MASK> self._do_ssl_handshake() <TAB>  <TAB>  <TAB> elif self._ssl_closing: <TAB>  <TAB>  <TAB>  <TAB> self._do_ssl_shutdown() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> super(SSLConnection, self).handle_write_event()",if self . _ssl_accepting :,140
"def test_connect( <TAB> ipaddr, port, device, partition, method, path, headers=None, query_string=None): <TAB> if path == ""/a/c"": <TAB>  <TAB> for k, v in headers.iteritems(): <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> test_errors.append(""%s: %s not in %s"" % (test_header, test_value, headers))",if k . lower ( ) == test_header . lower ( ) and v == test_value :,118
"def get_tokens_unprocessed(self, text): <TAB> for index, token, value in RegexLexer.get_tokens_unprocessed(self, text): <TAB>  <TAB> # check for reserved words and pervasives <TAB>  <TAB> if token is Name: <MASK> token = Keyword.Reserved <TAB>  <TAB>  <TAB> elif value in self.pervasives: <TAB>  <TAB>  <TAB>  <TAB> token = Keyword.Pervasive <TAB>  <TAB> # return result <TAB>  <TAB> yield index, token, value",if value in self . reserved_words :,119
def _daemon(self): <TAB> last_ping = time() <TAB> while self._task is not None: <TAB>  <TAB> try: <MASK> return <TAB>  <TAB>  <TAB> # send ping request <TAB>  <TAB>  <TAB> if self._support_ping and (time() - last_ping) >= self.ping_period: <TAB>  <TAB>  <TAB>  <TAB> self.ping() <TAB>  <TAB>  <TAB>  <TAB> last_ping = time() <TAB>  <TAB>  <TAB> if self._dev_stop_signal: <TAB>  <TAB>  <TAB>  <TAB> stop_reason = self._dev_stop_signal.test() <TAB>  <TAB>  <TAB>  <TAB> if stop_reason and self._task: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._task._dev_mode_stop_task(stop_reason) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> pass,"if self . _exit_event . wait ( min ( self . ping_period , self . report_period ) ) :",196
"def apply(self, m, evaluation): <TAB> ""Transpose[m_?MatrixQ]"" <TAB> result = [] <TAB> for row_index, row in enumerate(m.leaves): <TAB>  <TAB> for col_index, item in enumerate(row.leaves): <MASK> result.append([item]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> result[col_index].append(item) <TAB> return Expression(""List"", *[Expression(""List"", *row) for row in result])",if row_index == 0 :,118
"def global_matches(self, text): <TAB> matches = [] <TAB> for p in self.path: <TAB>  <TAB> for k in p.keys(): <MASK> k = k.replace(""_"", ""-"") <TAB>  <TAB>  <TAB>  <TAB> if k.startswith(text): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> matches.append(k) <TAB> return matches","if isinstance ( k , string_types ) :",87
"def get_version(self, game: Game, gameinfo=None, dlc_name="""") -> str: <TAB> if gameinfo is None: <TAB>  <TAB> gameinfo = self.get_info(game) <TAB> version = ""0"" <TAB> if dlc_name: <TAB>  <TAB> installers = {} <TAB>  <TAB> for dlc in gameinfo[""expanded_dlcs""]: <MASK> installers = dlc[""downloads""][""installers""] <TAB>  <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> installers = gameinfo[""downloads""][""installers""] <TAB> for installer in installers: <TAB>  <TAB> if installer[""os""] == game.platform: <TAB>  <TAB>  <TAB> version = installer[""version""] <TAB>  <TAB>  <TAB> break <TAB> return version","if dlc [ ""title"" ] == dlc_name :",174
"def _potential_locations(self, name=None, must_exist=False, is_dir=False): <TAB> # Will give an iterator over the full path of potential locations <TAB> # according to the search path. <TAB> for path in self.search_paths: <MASK> full_path = path <TAB>  <TAB>  <TAB> if name is not None: <TAB>  <TAB>  <TAB>  <TAB> full_path = os.path.join(path, name) <TAB>  <TAB>  <TAB> if not must_exist: <TAB>  <TAB>  <TAB>  <TAB> yield full_path <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> if is_dir and os.path.isdir(full_path): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield full_path <TAB>  <TAB>  <TAB>  <TAB> elif os.path.exists(full_path): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield full_path",if os . path . isdir ( path ) :,190
"def parse_success_codes(self, success_codes_str: str) -> Set[int]: <TAB> """"""Expand a string like 200-399,407-409,500 to a set containing all the integers in between."""""" <TAB> acceptable_response_codes: Set[int] = set() <TAB> for series_str in str(success_codes_str).split("",""): <MASK> start, end = series_str.split(""-"") <TAB>  <TAB>  <TAB> acceptable_response_codes.update(range(int(start), int(end) + 1)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> acceptable_response_codes.add(int(series_str)) <TAB> return acceptable_response_codes","if ""-"" in series_str :",163
"def get(cls, progressbar_length: int, progressbar_id: str) -> ProgressBar: <MASK> cls._progressbar_lock.acquire() <TAB>  <TAB> if progressbar_id not in cls._progressbar_storage: <TAB>  <TAB>  <TAB> sys.stderr.write(""\n"") <TAB>  <TAB>  <TAB> cls._progressbar_storage[progressbar_id] = ProgressBar( <TAB>  <TAB>  <TAB>  <TAB> length=progressbar_length, message=""Synchronizing AUR database... "" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> cls._progressbar_lock.release() <TAB> return cls._progressbar_storage[progressbar_id]",if progressbar_id not in cls . _progressbar_storage :,146
"def create_fb_format(outpath, dtype, inpath): <TAB> print(""building fbformat:"" + dtype) <TAB> with PathManager.open(os.path.join(outpath, dtype + "".txt""), ""w"") as fout: <TAB>  <TAB> for f in os.listdir(inpath): <MASK> fname = os.path.join(inpath, f) <TAB>  <TAB>  <TAB>  <TAB> _process(fname, fout)","if f . endswith ( "".question"" ) :",106
"def __getattr__(self, key): <TAB> try: <TAB>  <TAB> res = self.perform_request(""registers"", registers=[key]) <MASK> return res.registers[key] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""Error getting register: {}"".format(res.message)) <TAB> except Exception as e: <TAB>  <TAB> print(""Exception getting register: {}"".format(repr(e)))",if res . is_success :,96
"def rotateRange(n, idx, reverse=False): <TAB> ""Wraps an iter starting from idx. Yields indices from idx to n and then 0 to idx."" <TAB> if reverse: <TAB>  <TAB> rng = range(idx - 1, -1, -1) <TAB>  <TAB> rng2 = range(n - 1, idx - 1, -1) <TAB> else: <TAB>  <TAB> rng = range(idx + 1, n) <TAB>  <TAB> rng2 = range(0, idx + 1) <TAB> wrapped = False <TAB> with Progress(total=n) as prog: <TAB>  <TAB> for r in itertools.chain(rng, rng2): <TAB>  <TAB>  <TAB> prog.addProgress(1) <MASK> vd.status(""search wrapped"") <TAB>  <TAB>  <TAB>  <TAB> wrapped = True <TAB>  <TAB>  <TAB> yield r",if not wrapped and r in rng2 :,191
"def rstrip_last_element(children): <TAB> if children: <TAB>  <TAB> if isinstance(children[-1], basestring): <TAB>  <TAB>  <TAB> children[-1] = children[-1].rstrip() <MASK> children.pop() <TAB>  <TAB>  <TAB>  <TAB> children = rstrip_last_element(children) <TAB> return children",if not children [ - 1 ] :,80
"def scan_resource_conf(self, conf): <TAB> self.evaluated_keys = ""access_logs"" <TAB> if ""access_logs"" in conf: <MASK> return CheckResult.PASSED <TAB>  <TAB> self.evaluated_keys = ""access_logs/[0]/enabled"" <TAB>  <TAB> if conf[""access_logs""][0][""enabled""] == [True]: <TAB>  <TAB>  <TAB> return CheckResult.PASSED <TAB> return CheckResult.FAILED","if ""enabled"" not in conf [ ""access_logs"" ] [ 0 ] :",119
"def get_problem_root(problem_id): <TAB> cached_root = _problem_root_cache.get(problem_id) <TAB> if cached_root is None or not os.path.isfile(os.path.join(cached_root, ""init.yml"")): <TAB>  <TAB> for root_dir in get_problem_roots(): <TAB>  <TAB>  <TAB> problem_root_dir = os.path.join(root_dir, problem_id) <TAB>  <TAB>  <TAB> problem_init = os.path.join(problem_root_dir, ""init.yml"") <MASK> _problem_root_cache[problem_id] = problem_root_dir <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return _problem_root_cache[problem_id]",if os . path . isfile ( problem_init ) :,182
"def arrayit(self): <TAB> array = [] <TAB> # order must match self.attributes <TAB> # some entries must be converted to string format from arrays <TAB> for ii in Apps.attributes_: <MASK> array.append("":"".join(getattr(self, ii + ""_""))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> array.append(str(getattr(self, ii + ""_""))) <TAB> return array","if ii == ""admins_list"" or ii == ""host"" or ii == ""port"" or ii == ""classes"" :",120
"def validate_depends_on(service_config, service_names): <TAB> deps = service_config.config.get(""depends_on"", {}) <TAB> for dependency in deps.keys(): <MASK> raise ConfigurationError( <TAB>  <TAB>  <TAB>  <TAB> ""Service '{s.name}' depends on service '{dep}' which is "" <TAB>  <TAB>  <TAB>  <TAB> ""undefined."".format(s=service_config, dep=dependency) <TAB>  <TAB>  <TAB> )",if dependency not in service_names :,107
"def add_corrections_regions(views, corrs): <TAB> for view in views: <MASK> continue <TAB>  <TAB> corrs_ = [ <TAB>  <TAB>  <TAB> corr for corr in corrs if os.path.samefile(corr.file, view.file_name()) <TAB>  <TAB> ] <TAB>  <TAB> view.add_regions( <TAB>  <TAB>  <TAB> ""autofix"", <TAB>  <TAB>  <TAB> [corr.to_region(view) for corr in corrs_], <TAB>  <TAB>  <TAB> ""autofix"", <TAB>  <TAB>  <TAB> """", <TAB>  <TAB>  <TAB> sublime.HIDDEN, <TAB>  <TAB> )",if view . file_name ( ) is None :,141
"def findranking(cpe=None, loosy=True): <TAB> if cpe is None: <TAB>  <TAB> return False <TAB> result = False <TAB> if loosy: <TAB>  <TAB> for x in cpe.split("":""): <MASK> i = db.findRanking(x, regex=True) <TAB>  <TAB>  <TAB> if i is None: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if ""rank"" in i: <TAB>  <TAB>  <TAB>  <TAB> result = i[""rank""] <TAB> else: <TAB>  <TAB> i = db.findRanking(cpe, regex=True) <TAB>  <TAB> print(cpe) <TAB>  <TAB> if i is None: <TAB>  <TAB>  <TAB> return result <TAB>  <TAB> if ""rank"" in i: <TAB>  <TAB>  <TAB> result = i[""rank""] <TAB> return result","if x is not """" :",183
"def __enabledAndValueData(data): <TAB> enabledData = None <TAB> if isinstance(data, IECore.CompoundData) and ""value"" in data: <TAB>  <TAB> valueData = data[""value""] <MASK> enabledData = data[""enabled""] <TAB>  <TAB> elif ""enabled"" in valueData: <TAB>  <TAB>  <TAB> enabledData = valueData[""enabled""] <TAB> else: <TAB>  <TAB> valueData = data <TAB> return enabledData, valueData","if ""enabled"" in data :",109
"def _on_listbox_select(self, event): <TAB> self.listbox.focus_set() <TAB> selection = self.listbox.curselection() <TAB> if len(selection) == 1: <TAB>  <TAB> self.listbox.activate(selection[0]) <MASK> # special first item <TAB>  <TAB>  <TAB> self._show_instructions() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._on_listbox_select_package(self.listbox.get(selection[0]).strip())",if selection [ 0 ] == 0 :,113
"def parse_tags(raw_tags_list): <TAB> tags_dict_list = [] <TAB> if raw_tags_list: <TAB>  <TAB> for tag in raw_tags_list: <MASK> key, value = tag, """" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> key, value = tag.split(""="", 1) <TAB>  <TAB>  <TAB> tags_dict_list.append({""Key"": key, ""Value"": value}) <TAB> return tags_dict_list","if tag . find ( ""="" ) == - 1 :",117
"def show(ev): <TAB> global state <TAB> if state == ""on"": <TAB>  <TAB> for div in document.select("".show_source""): <TAB>  <TAB>  <TAB> div.remove() <TAB>  <TAB> state = ""off"" <TAB>  <TAB> btn.text = ""Show source code"" <TAB> else: <TAB>  <TAB> scripts = document.select(""script"") <TAB>  <TAB> for script in scripts: <MASK> show_source(script.text) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> if script.src.endswith("".py"") and not script.src.endswith( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""show_source.py"" <TAB>  <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> req = ajax.get(script.src, oncomplete=show_external) <TAB>  <TAB> state = ""on"" <TAB>  <TAB> btn.text = ""Hide source code""",if not script . src :,196
"def GrabCookie(data, host): <TAB> Cookie = re.search(""(Cookie:*.\=*)[^\r\n]*"", data) <TAB> if Cookie: <TAB>  <TAB> Cookie = Cookie.group(0).replace(""Cookie: "", """") <MASK> log.info(""[HTTP] Cookie <TAB>  <TAB>    : {}"".format(Cookie)) <TAB>  <TAB> return Cookie <TAB> else: <TAB>  <TAB> return False",if len ( Cookie ) > 1 and settings . Config . Verbose :,112
"def new_record(cls, state_for_db=None, sourcewords=None, targetwords=None): <TAB> record = Record(cls.keys, compute_derived_values=cls._compute_derived_values) <TAB> if state_for_db is not None: <MASK> record[""untranslated""] = 1 <TAB>  <TAB>  <TAB> record[""untranslatedsourcewords""] = sourcewords <TAB>  <TAB> if state_for_db is TRANSLATED: <TAB>  <TAB>  <TAB> record[""translated""] = 1 <TAB>  <TAB>  <TAB> record[""translatedsourcewords""] = sourcewords <TAB>  <TAB>  <TAB> record[""translatedtargetwords""] = targetwords <TAB>  <TAB> elif state_for_db is FUZZY: <TAB>  <TAB>  <TAB> record[""fuzzy""] = 1 <TAB>  <TAB>  <TAB> record[""fuzzysourcewords""] = sourcewords <TAB> return record",if state_for_db is UNTRANSLATED :,196
"def log_url(response, **kwargs): <TAB> """"""Response hook to log request URL."""""" <TAB> request = response.request <TAB> sickrage.app.log.debug( <TAB>  <TAB> ""{} URL: {} [Status: {}]"".format( <TAB>  <TAB>  <TAB> request.method, request.url, response.status_code <TAB>  <TAB> ) <TAB> ) <TAB> sickrage.app.log.debug(""User-Agent: {}"".format(request.headers[""User-Agent""])) <TAB> if request.method.upper() == ""POST"": <TAB>  <TAB> sickrage.app.log.debug( <TAB>  <TAB>  <TAB> ""With post data: {!r}"".format( <TAB>  <TAB>  <TAB>  <TAB> request.body.decode() <MASK> else request.body <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> )","if isinstance ( request . body , bytes )",190
"def lpushx(self, client, request, N): <TAB> check_input(request, N != 2) <TAB> key = request[1] <TAB> db = client.db <TAB> value = db.get(key) <TAB> if value is None: <TAB>  <TAB> client.reply_zero() <TAB> elif not isinstance(value, self.list_type): <TAB>  <TAB> client.reply_wrongtype() <TAB> else: <TAB>  <TAB> assert value <MASK> value.appendleft(request[2]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value.append(request[2]) <TAB>  <TAB> client.reply_int(len(value)) <TAB>  <TAB> self._signal(self.NOTIFY_LIST, db, request[0], key, 1)","if request [ 0 ] == ""lpushx"" :",180
"def injection_test_results(response, TAG, randvcalc): <TAB> if response == False: <TAB>  <TAB> return False <TAB> else: <TAB>  <TAB> html_data = response.read().decode(settings.UNICODE_ENCODING) <TAB>  <TAB> html_data = re.sub(""\n"", "" "", html_data) <MASK> shell = re.findall(r"""" + TAG + "" "" + TAG + "" "" + TAG + "" "", html_data) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> shell = re.findall( <TAB>  <TAB>  <TAB>  <TAB> r"""" + TAG + "" "" + str(randvcalc) + "" "" + TAG + "" "" + TAG + "" "", <TAB>  <TAB>  <TAB>  <TAB> html_data, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return shell",if settings . SKIP_CALC :,176
"def HandleGetAllSentMessageIds(self, params): <TAB> queryreturn = sqlQuery( <TAB>  <TAB> """"""SELECT msgid FROM sent where folder='sent' ORDER BY lastactiontime"""""" <TAB> ) <TAB> data = '{""sentMessageIds"":[' <TAB> for row in queryreturn: <TAB>  <TAB> msgid = row[0] <MASK> data += "","" <TAB>  <TAB> data += json.dumps( <TAB>  <TAB>  <TAB> {""msgid"": msgid.encode(""hex"")}, indent=4, separators=("","", "": "") <TAB>  <TAB> ) <TAB> data += ""]}"" <TAB> return data",if len ( data ) > 25 :,137
"def dump_embedded_code(book, target_dir): <TAB> for sheet in book.sheets: <MASK> last_cell = sheet.used_range.last_cell <TAB>  <TAB>  <TAB> sheet_content = ( <TAB>  <TAB>  <TAB>  <TAB> sheet.range((1, 1), (last_cell.row, 1)).options(ndim=1).value <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> with open(os.path.join(target_dir, sheet.name), ""w"") as f: <TAB>  <TAB>  <TAB>  <TAB> for row in sheet_content: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if row is None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f.write(""\n"") <TAB>  <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f.write(row + ""\n"") <TAB> sys.path[0:0] = [target_dir]","if sheet . name . endswith ( "".py"" ) :",198
"def __setattr__(self, key, value): <TAB> if key.startswith(""_""): <TAB>  <TAB> super(Options, self).__setattr__(key, value) <TAB> else: <TAB>  <TAB> old = self.__options_dict[key] <TAB>  <TAB> self.__checkOptions({key: value}) <TAB>  <TAB> self.__options_dict[key] = value <TAB>  <TAB> self.__checkOptions(self.__options_dict) <MASK> self.__option_changed(key, old, value)",if self . __option_changed :,115
"def select(cfg: Container, key: str, throw_on_missing: bool = False) -> Any: <TAB> try: <TAB>  <TAB> _root, _last_key, value = cfg._select_impl( <TAB>  <TAB>  <TAB> key, throw_on_missing=throw_on_missing, throw_on_resolution_failure=True <TAB>  <TAB> ) <MASK> # throw_on_missing must be False <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> return _get_value(value) <TAB> except Exception as e: <TAB>  <TAB> format_and_raise(node=cfg, key=key, value=None, cause=e, msg=str(e))",if value is not None and value . _is_missing ( ) :,162
def close(self): <TAB> try: <TAB>  <TAB> closehook = self.closehook <TAB>  <TAB> hookargs = self.hookargs <MASK> self.closehook = None <TAB>  <TAB>  <TAB> self.hookargs = None <TAB>  <TAB>  <TAB> closehook(*hookargs) <TAB> finally: <TAB>  <TAB> addbase.close(self),if closehook :,81
"def checkWidgetList(self, tag): <TAB> return True  # This will fail when the headline actually changes! <TAB> for w in self.visibleText: <TAB>  <TAB> p = w.leo_position <TAB>  <TAB> if p: <TAB>  <TAB>  <TAB> s = w.getAllText().strip() <TAB>  <TAB>  <TAB> h = p.h.strip() <MASK> self.dumpWidgetList(tag) <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.dumpWidgetList(tag) <TAB>  <TAB>  <TAB> return False <TAB> return True",if h != s :,134
"def test_valid(self): <TAB> cases = self.get_image_resize_cases() <TAB> for case in cases: <MASK> continue <TAB>  <TAB> params = case[""source_query_params""] <TAB>  <TAB> params[""client""] = self.NAME <TAB>  <TAB> qs = sign(self.KEY, urlencode(params)) <TAB>  <TAB> resp = self.fetch_success(""/?%s"" % qs) <TAB>  <TAB> msg = ""/?%s does not match %s"" % (qs, case[""expected_path""]) <TAB>  <TAB> with open(case[""expected_path""], ""rb"") as expected: <TAB>  <TAB>  <TAB> self.assertEqual(resp.buffer.read(), expected.read(), msg)","if case . get ( ""mode"" ) == ""crop"" and case . get ( ""position"" ) == ""face"" :",177
"def decode(self, ctext: T) -> Optional[U]: <TAB> result = """" <TAB> for x in ctext.split(): <MASK> # Check if it's a space <TAB>  <TAB>  <TAB> result += "" "" <TAB>  <TAB> elif not Multi_tap.valid_code_part(x): <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result += self.decode_num_to_char(x) <TAB> return result",if x == self . SPACE_DIGIT :,108
"def lookup(d): <TAB> if ""Limits"" in d: <TAB>  <TAB> (k1, k2) = list_value(d[""Limits""]) <TAB>  <TAB> if key < k1 or k2 < key: <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> if ""Names"" in d: <TAB>  <TAB>  <TAB> objs = list_value(d[""Names""]) <TAB>  <TAB>  <TAB> names = dict(choplist(2, objs)) <TAB>  <TAB>  <TAB> return names[key] <TAB> if ""Kids"" in d: <TAB>  <TAB> for c in list_value(d[""Kids""]): <TAB>  <TAB>  <TAB> v = lookup(dict_value(c)) <MASK> return v <TAB> raise KeyError((cat, key))",if v :,166
"def autofit(self, axis=None): <TAB> if self.xl is not None: <TAB>  <TAB> if axis == ""rows"" or axis == ""r"": <TAB>  <TAB>  <TAB> self.xl.Rows.AutoFit() <TAB>  <TAB> elif axis == ""columns"" or axis == ""c"": <TAB>  <TAB>  <TAB> self.xl.Columns.AutoFit() <MASK> self.xl.Columns.AutoFit() <TAB>  <TAB>  <TAB> self.xl.Rows.AutoFit()",elif axis is None :,112
"def __plugValueChanged(plug): <TAB> ## \todo This mirrors LabelPlugValueWidget. This doesn't handle child plug defaults/connections <TAB> # properly. We need to improve NodeAlgo when we have the next API break. <TAB> valueChanged = plug.getInput() is not None <TAB> if not valueChanged and isinstance(plug, Gaffer.ValuePlug): <MASK> valueChanged = not Gaffer.NodeAlgo.isSetToUserDefault(plug) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> valueChanged = not plug.isSetToDefault() <TAB> return valueChanged",if Gaffer . NodeAlgo . hasUserDefault ( plug ) :,150
"def handle_read(self, c): <TAB> if self.popup: <TAB>  <TAB> ret = self.popup.handle_read(c) <MASK> self.pop_popup() <TAB>  <TAB> self.refresh() <TAB>  <TAB> return ret <TAB> return BaseInputPane.handle_read(self, c)",if self . popup and self . popup . closed ( ) :,84
"def adj_hibernation(self): <TAB> """"""Used to increase the ""sleep"" interval for DISABLED workers."""""" <TAB> with self.w_stats_lock: <MASK> wk_st = self.w_stats.sleep <TAB>  <TAB>  <TAB> hibernation = ( <TAB>  <TAB>  <TAB>  <TAB> wk_st + HEARTBEAT if wk_st < MAXHIBERNATION else MAXHIBERNATION <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.w_stats.sleep = hibernation",if self . w_stats . status == DISABLED :,134
"def get_check_class(name): <TAB> check_module = _load_sdk_module(name) <TAB> check_class = None <TAB> classes = inspect.getmembers(check_module, inspect.isclass) <TAB> for _, clsmember in classes: <MASK> continue <TAB>  <TAB> if issubclass(clsmember, AgentCheck): <TAB>  <TAB>  <TAB> check_class = clsmember <TAB>  <TAB>  <TAB> if AgentCheck in clsmember.__bases__: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return check_class",if clsmember == AgentCheck :,134
"def read_csv(device): <TAB> csv_file = ""netmiko_performance_releases.csv"" <TAB> entries = [] <TAB> with open(csv_file) as f: <TAB>  <TAB> read_csv = csv.DictReader(f) <TAB>  <TAB> for entry in read_csv: <TAB>  <TAB>  <TAB> entry = dict(entry) <MASK> entries.append(entry) <TAB> return entries","if entry [ ""device_name"" ] == device :",105
"def add_middle_menu_items(self, context): <TAB> if self.supports_trash(): <MASK> trash_label = tr(""Move to Recycle Bin"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> trash_label = tr(""Move to Trash"") <TAB>  <TAB> self.menu.add_command(label=trash_label, command=self.move_to_trash) <TAB> else: <TAB>  <TAB> self.menu.add_command(label=tr(""Delete""), command=self.delete) <TAB> if self.supports_directories(): <TAB>  <TAB> self.menu.add_command(label=tr(""New directory"") + ""..."", command=self.mkdir)",if running_on_windows ( ) :,158
"def __new__(mcs, name, bases, attrs): <TAB> for b in bases: <TAB>  <TAB> if not hasattr(b, ""_fields""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for k, v in b.__dict__.items(): <MASK> continue <TAB>  <TAB>  <TAB> if isinstance(v, FieldDescriptor): <TAB>  <TAB>  <TAB>  <TAB> attrs[k] = copy.deepcopy(v.field) <TAB> mcs = super().__new__(mcs, name, bases, attrs) <TAB> mcs._fields = {} <TAB> for name, field in mcs.__dict__.items(): <TAB>  <TAB> if isinstance(field, BaseField): <TAB>  <TAB>  <TAB> field.add_to_class(mcs, name) <TAB> return mcs",if k in attrs :,163
"def __init__(self, config, parent=None): <TAB> QWidget.__init__(self, parent=parent) <TAB> self.enviconfig = config <TAB> lyt = QFormLayout() <TAB> optnames = list(config.keys()) <TAB> optnames.sort() <TAB> for optname in optnames: <TAB>  <TAB> optval = config.get(optname) <TAB>  <TAB> cls = cfgtypes.get(type(optval)) <TAB>  <TAB> if cls is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> label = QLabel(optname) <TAB>  <TAB> clsobj = cls(config, optname, optval, parent=self) <TAB>  <TAB> doc = config.getOptionDoc(optname) <MASK> label.setToolTip(doc) <TAB>  <TAB> lyt.addRow(label, clsobj) <TAB> self.setLayout(lyt)",if doc is not None :,193
"def test_center_unicode(self, size): <TAB> SUBSTR = u"" abc def ghi"" <TAB> try: <TAB>  <TAB> s = SUBSTR.center(size) <TAB> except OverflowError: <TAB>  <TAB> pass  # acceptable on 32-bit <TAB> else: <TAB>  <TAB> self.assertEqual(len(s), size) <TAB>  <TAB> lpadsize = rpadsize = (len(s) - len(SUBSTR)) // 2 <MASK> lpadsize += 1 <TAB>  <TAB> self.assertEqual(s[lpadsize:-rpadsize], SUBSTR) <TAB>  <TAB> self.assertEqual(s.strip(), SUBSTR.strip()) <TAB>  <TAB> del s",if len ( s ) % 2 :,158
"def is_less(lhs, rhs): <TAB> for field in queryset.query.order_by: <TAB>  <TAB> # Go through the fields specified in the order by <TAB>  <TAB> negative = field.startswith(""-"") <MASK> field = field[1:] <TAB>  <TAB>  <TAB> # If the ordering was negated, but the lhs < rhs then return false <TAB>  <TAB>  <TAB> if getattr(lhs, field, None) < getattr(rhs, field, None): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # If the ordering was not negated, and the lhs >= rhs, return false <TAB>  <TAB>  <TAB> if getattr(lhs, field, None) >= getattr(rhs, field, None): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> else: <TAB>  <TAB> return True",if negative :,172
"def my_fn(x): <TAB> layer_sizes = [input_size] + hidden_sizes + [output_size] <TAB> for i in range(1 + len(hidden_sizes)): <TAB>  <TAB> w = tf.get_variable(""w_%d"" % i, layer_sizes[i : i + 2], tf.float32) <TAB>  <TAB> x = tf.matmul(x, w) <MASK> x = hidden_activation(x) <TAB>  <TAB> if layer_sizes[i] != input_size: <TAB>  <TAB>  <TAB> x *= (layer_sizes[i] / float(input_size)) ** -0.5 <TAB> return x",if i < len ( hidden_sizes ) :,158
"def get_sort_arg_defs(self): <TAB> """"""Expand all abbreviations that are unique."""""" <TAB> if not self.sort_arg_dict: <TAB>  <TAB> self.sort_arg_dict = dict = {} <TAB>  <TAB> bad_list = {} <TAB>  <TAB> for word, tup in self.sort_arg_dict_default.iteritems(): <TAB>  <TAB>  <TAB> fragment = word <TAB>  <TAB>  <TAB> while fragment: <TAB>  <TAB>  <TAB>  <TAB> if not fragment: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <MASK> bad_list[fragment] = 0 <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB>  <TAB> dict[fragment] = tup <TAB>  <TAB>  <TAB>  <TAB> fragment = fragment[:-1] <TAB>  <TAB> for word in bad_list: <TAB>  <TAB>  <TAB> del dict[word] <TAB> return self.sort_arg_dict",if fragment in dict :,188
"def can_change_type_to(self, app, new_type_label): <TAB> if self.type == new_type_label: <TAB>  <TAB> return False <TAB> if self.can_change_type(): <TAB>  <TAB> new_type = app.repository_types_registry.get_class_by_label(new_type_label) <MASK> return True <TAB> return False",if new_type . is_valid_for_type ( self ) :,106
"def _get_options(self, parsed): <TAB> options, labels, initial = [], [], [] <TAB> for option in parsed: <TAB>  <TAB> value = option.get(""value"", ""on"") <TAB>  <TAB> checked = option.get(""checked"") <TAB>  <TAB> options.append(value) <TAB>  <TAB> labels.append( <TAB>  <TAB>  <TAB> option.next.string if isinstance(option.next, string_types) else None <TAB>  <TAB> ) <MASK> initial.append(value) <TAB> return options, labels, initial",if checked is not None :,123
"def execute(self, args): <TAB> """"""Generate the file in the target_dir."""""" <TAB> if self._dirarg: <TAB>  <TAB> target_dir = None <TAB>  <TAB> for i, arg in enumerate(args): <MASK> target_dir = args[i + 1] <TAB>  <TAB> if target_dir: <TAB>  <TAB>  <TAB> filepath = os.path.join(target_dir, self._filename) <TAB>  <TAB>  <TAB> if filepath.endswith("".whl""): <TAB>  <TAB>  <TAB>  <TAB> self._build_fake_whl(target_dir, self._filename) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._build_fake_sdist(filepath)",if arg == self . _dirarg :,156
"def __contains__(self, featureId): <TAB> """"""Tests whether the list contains given Feature ID"""""" <TAB> if self._check(): <TAB>  <TAB> ivalue = int(featureId) <TAB>  <TAB> may_have = False <TAB>  <TAB> for f in self.features: <TAB>  <TAB>  <TAB> if f is None: <TAB>  <TAB>  <TAB>  <TAB> may_have = True <TAB>  <TAB>  <TAB> elif ivalue == int(f): <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> if may_have: <TAB>  <TAB>  <TAB> reply = self.device.request(0x0000, _pack(""!H"", ivalue)) <TAB>  <TAB>  <TAB> if reply: <TAB>  <TAB>  <TAB>  <TAB> index = ord(reply[0:1]) <MASK> self.features[index] = FEATURE[ivalue] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True",if index :,185
"def merge_trading_period(trading_period): <TAB> result = [] <TAB> for time_range in sorted(set(trading_period)): <MASK> result[-1] = TimeRange( <TAB>  <TAB>  <TAB>  <TAB> start=result[-1].start, end=max(result[-1].end, time_range.end) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result.append(time_range) <TAB> return result",if result and result [ - 1 ] . end >= time_range . start :,120
"def _create_sub_pool( <TAB> actor_config: ActorPoolConfig, process_index: int, started: multiprocessing.Event): <TAB> try: <TAB>  <TAB> env = actor_config.get_pool_config(process_index)[""env""] <MASK> os.environ.update(env) <TAB>  <TAB> pool = await SubActorPool.create( <TAB>  <TAB>  <TAB> {""actor_pool_config"": actor_config, ""process_index"": process_index} <TAB>  <TAB> ) <TAB>  <TAB> await pool.start() <TAB> finally: <TAB>  <TAB> started.set() <TAB> await pool.join()",if env :,137
"def report_exception(self, title: str = ""Internal error"") -> None: <TAB> logging.exception(title) <TAB> if tk._default_root and not self._closing:  # type: ignore <TAB>  <TAB> (typ, value, _) = sys.exc_info() <TAB>  <TAB> assert typ is not None <MASK> msg = str(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> msg = traceback.format_exc() <TAB>  <TAB> dlg = ui_utils.LongTextDialog(title, msg, parent=self) <TAB>  <TAB> ui_utils.show_dialog(dlg, self)","if issubclass ( typ , UserError ) :",143
"def _insert_items(self, index, items): <TAB> self[index : index + 1] = items <TAB> add = len(items) - 1 <TAB> for name, (i, j) in self._names.items(): <TAB>  <TAB> if i > index: <TAB>  <TAB>  <TAB> self._names[name] = (i + add, None if j is None else j + add) <MASK> self._set_name(name, i, end=i + len(items))",elif i == index :,116
"def mirror_kernel_components(mirrors, components): <TAB> new_components = [] <TAB> for component in components: <TAB>  <TAB> new_patches = [] <TAB>  <TAB> for mirror in mirrors: <TAB>  <TAB>  <TAB> (prefix, local) = mirror <TAB>  <TAB>  <TAB> for patch in component: <MASK> new_patch = local + patch[len(prefix) :] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> new_patches.append(new_patch) <TAB>  <TAB> for patch in component: <TAB>  <TAB>  <TAB> new_patches.append(patch) <TAB>  <TAB> new_components.append(new_patches) <TAB> return new_components",if patch . startswith ( prefix ) :,149
"def truncateAtWordBreak(name): <TAB> # urllib only handles ascii chars, so we do our own quoting with the <TAB> # other bits <TAB> if len(name) > _MAX_FILENAME_LEN: <TAB>  <TAB> m1 = _re_capture_word_chars.match(name, _MAX_FILENAME_LEN) <TAB>  <TAB> if m1: <TAB>  <TAB>  <TAB> g1 = m1.group(1) <MASK> return name[:_MAX_FILENAME_LEN] + g1 <TAB>  <TAB> return name[:_MAX_FILENAME_LEN] <TAB> else: <TAB>  <TAB> return name",if len ( g1 ) < 10 :,146
"def run(self): <TAB> # we choose to remove breakpoints only for active files, so not for unrelated sites <TAB> # so we need to be debugging a site <TAB> for file_to_script_object in file_to_scriptId: <TAB>  <TAB> file_name = file_to_script_object[""file""] <TAB>  <TAB> breaks = get_breakpoints_by_full_path(file_name) <MASK> for row in breaks: <TAB>  <TAB>  <TAB>  <TAB> if ""breakpointId"" in breaks[row]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> channel.send( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> webkit.Debugger.removeBreakpoint(breaks[row][""breakpointId""]) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> del brk_object[file_name.lower()] <TAB> save_breaks() <TAB> update_overlays()",if breaks :,193
"def set_states(self, pdict): <TAB> if ""states"" not in pdict: <TAB>  <TAB> # if states was not serialized then leave <TAB>  <TAB> # this empty, the optimizer will initialize it <TAB>  <TAB> self.states = [] <TAB> else: <TAB>  <TAB> # this needs to be done in two steps for MGPU backend <MASK> self.states = [ <TAB>  <TAB>  <TAB>  <TAB> self.be.zeros_like(self.dW) for i in range(len(pdict[""states""])) <TAB>  <TAB>  <TAB> ] <TAB>  <TAB> for ind in range(len(pdict[""states""])): <TAB>  <TAB>  <TAB> self.states[ind].set(pdict[""states""][ind])",if self . states is None or len ( self . states ) == 0 :,167
"def cnv_to_event(name, data): <TAB> """"""Convert a CNV to an event name."""""" <TAB> cur_ploidy = ploidy.get_ploidy([data]) <TAB> if name.startswith(""cnv""): <TAB>  <TAB> num = max([int(x) for x in name.split(""_"")[0].replace(""cnv"", """").split("";"")]) <TAB>  <TAB> if num < cur_ploidy: <TAB>  <TAB>  <TAB> return ""DEL"" <MASK> return ""DUP"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return name <TAB> else: <TAB>  <TAB> return name",elif num > cur_ploidy :,140
"def _parse_arg_var(args_var): <TAB> variables = {} <TAB> for var in args_var: <MASK> key, value = var.split(""="", 1) <TAB>  <TAB>  <TAB> key = key.strip() <TAB>  <TAB>  <TAB> value = value.strip() <TAB>  <TAB>  <TAB> variables[key] = value <TAB> return variables","if ""="" in var :",83
"def acc(self): <TAB> a = Vec(0, 0) <TAB> for planet in self.gravSys.planets: <MASK> v = planet.pos() - self.pos() <TAB>  <TAB>  <TAB> a += (G * planet.m / abs(v) ** 3) * v <TAB> return a",if planet != self :,84
"def process_dynamodb_backups(self, table_set, c): <TAB> for t in table_set: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> c.delete_backup(BackupArn=t[""BackupArn""]) <TAB>  <TAB> except ClientError as e: <MASK> self.log.warning( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Could not complete DynamoDB backup deletion for table:%s"", t <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> raise","if e . response [ ""Error"" ] [ ""Code"" ] == ""ResourceNotFoundException"" :",121
"def handle_output(self, workunit, label, s): <TAB> """"""Implementation of Reporter callback."""""" <TAB> if os.path.exists( <TAB>  <TAB> self._html_dir <TAB> ):  # Make sure we're not immediately after a clean-all. <TAB>  <TAB> path = os.path.join(self._html_dir, ""{}.{}"".format(workunit.id, label)) <TAB>  <TAB> output_files = self._output_files[workunit.id] <MASK> f = open(path, ""w"") <TAB>  <TAB>  <TAB> output_files[path] = f <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> f = output_files[path] <TAB>  <TAB> f.write(self._htmlify_text(s)) <TAB>  <TAB> # We must flush in the same thread as the write. <TAB>  <TAB> f.flush()",if path not in output_files :,194
"def _get_attr(self, doc, name, default="""", upper=False): <TAB> name = ""ROBOT_LIBRARY_"" + name <TAB> for field in doc.fields(): <TAB>  <TAB> if field.name() == name and field.isPublic(): <TAB>  <TAB>  <TAB> value = field.constantValue() <MASK> value = utils.normalize(value, ignore=""_"").upper() <TAB>  <TAB>  <TAB> return value <TAB> return default",if upper :,102
"def decrypt(self, data): <TAB> clear = b"""" <TAB> for i in range(0, len(data), 16): <TAB>  <TAB> out = create_string_buffer(16) <TAB>  <TAB> rv = AES_ecb_encrypt(data[i : i + 16], out, self._key, 0) <MASK> raise ENCRYPTIONError(_(""AES decryption failed"")) <TAB>  <TAB> clear += out.raw <TAB> return clear",if rv == 0 :,101
"def update_ui(self): <TAB> if self.active_item is not None: <TAB>  <TAB> text = self.tr(""Detail view for item #"") + self.active_item.index() <MASK> text += "" ("" + self.active_item.message_type.name + "")"" <TAB>  <TAB>  <TAB> self.ui.spinBoxRepeat.setValue(self.active_item.repeat) <TAB>  <TAB>  <TAB> self.ui.lblEncodingDecoding.setText(self.active_item.decoder.name) <TAB>  <TAB> self.ui.lblMsgFieldsValues.setText(text) <TAB> else: <TAB>  <TAB> self.ui.lblMsgFieldsValues.setText(self.tr(""Detail view for item""))","if isinstance ( self . active_item , SimulatorMessage ) :",175
"def _find_old_style_function(outputs): <TAB> """"""Find old-style functions in the computational graph."""""" <TAB> found = [] <TAB> for v in outputs: <TAB>  <TAB> assert isinstance(v, (chainer.Variable, chainer.variable.VariableNode)) <MASK> continue <TAB>  <TAB> if isinstance(v.creator, chainer.Function): <TAB>  <TAB>  <TAB> found.append(v.creator) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert isinstance(v.creator, chainer.FunctionNode) <TAB>  <TAB> found.extend(_find_old_style_function(v.creator.inputs)) <TAB> return found",if v . creator is None :,149
def get_sentence(self): <TAB> while True: <MASK> self._ids = self._load_random_shard() <TAB>  <TAB> ret = self._ids[self._i] <TAB>  <TAB> self._i += 1 <TAB>  <TAB> yield ret,if self . _i == self . _nids :,68
"def unregister(self, fd): <TAB> try: <TAB>  <TAB> del self.socket_map[fd] <TAB> except KeyError: <TAB>  <TAB> debug(""call: unregister(); fd was no longer in socket_map"", self) <TAB> else: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self._poller.unregister(fd) <TAB>  <TAB> except EnvironmentError as err: <MASK> debug( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""call: unregister(); poller returned %r; "" ""ignoring it"" % err, self <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise","if err . errno in ( errno . ENOENT , errno . EBADF ) :",150
"def __filesystem_monitor(self): <TAB> while self.running: <TAB>  <TAB> new_weighted_backend_ids = self.original_weighted_backend_ids <TAB>  <TAB> for id, backend in self.backends.items(): <TAB>  <TAB>  <TAB> maxpct = self.max_percent_full[id] or self.global_max_percent_full <TAB>  <TAB>  <TAB> pct = backend.get_store_usage_percent() <MASK> new_weighted_backend_ids = [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _ for _ in new_weighted_backend_ids if _ != id <TAB>  <TAB>  <TAB>  <TAB> ] <TAB>  <TAB> self.weighted_backend_ids = new_weighted_backend_ids <TAB>  <TAB> self.sleeper.sleep(120)  # Test free space every 2 minutes",if pct > maxpct :,181
"def _reflect_col_sequence(self, col_d, colargs): <TAB> if ""sequence"" in col_d: <TAB>  <TAB> # TODO: mssql and sybase are using this. <TAB>  <TAB> seq = col_d[""sequence""] <TAB>  <TAB> sequence = sa_schema.Sequence(seq[""name""], 1, 1) <MASK> sequence.start = seq[""start""] <TAB>  <TAB> if ""increment"" in seq: <TAB>  <TAB>  <TAB> sequence.increment = seq[""increment""] <TAB>  <TAB> colargs.append(sequence)","if ""start"" in seq :",129
"def package_ids(self): <TAB> """"""get a list of all package_ids for this recipe"""""" <TAB> packages_dir = self.packages() <TAB> try: <TAB>  <TAB> packages = [ <TAB>  <TAB>  <TAB> dirname <TAB>  <TAB>  <TAB> for dirname in os.listdir(packages_dir) <MASK> ] <TAB> except OSError:  # if there isn't any package folder <TAB>  <TAB> packages = [] <TAB> return packages","if os . path . isdir ( os . path . join ( packages_dir , dirname ) )",115
"def _wpr(entity, fp, pdbid, chainid): <TAB> if entity.internal_coord: <TAB>  <TAB> if not chainid or not pdbid: <TAB>  <TAB>  <TAB> chain = entity.parent <MASK> chainid = chain.id <TAB>  <TAB>  <TAB> if not pdbid: <TAB>  <TAB>  <TAB>  <TAB> struct = chain.parent.parent <TAB>  <TAB>  <TAB>  <TAB> pdbid = struct.header.get(""idcode"") <TAB>  <TAB> fp.write(entity.internal_coord.write_PIC(pdbid, chainid)) <TAB> else: <TAB>  <TAB> fp.write(IC_Residue._residue_string(entity))",if not chainid :,153
"def send(self, data): <TAB> try: <TAB>  <TAB> return self.socket.send(data) <TAB> except socket.error as err: <TAB>  <TAB> debug(""call: send(), err: %s"" % err, inst=self) <MASK> return 0 <TAB>  <TAB> elif err.errno in _ERRNOS_DISCONNECTED: <TAB>  <TAB>  <TAB> self.handle_close() <TAB>  <TAB>  <TAB> return 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise",if err . errno in _ERRNOS_RETRY :,117
"def resolve(self, arguments, variables=None): <TAB> positional = [] <TAB> named = [] <TAB> for arg in arguments: <MASK> named.append(arg) <TAB>  <TAB> elif self._is_named(arg, named, variables): <TAB>  <TAB>  <TAB> named.append(split_from_equals(arg)) <TAB>  <TAB> elif named: <TAB>  <TAB>  <TAB> self._raise_positional_after_named() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> positional.append(arg) <TAB> return positional, named",if self . _is_dict_var ( arg ) :,126
"def dfs(node): <TAB> visited_nodes[node] = GRAY <TAB> for k in graph.get(node, set()): <TAB>  <TAB> sk = visited_nodes.get(k, None) <TAB>  <TAB> if sk == GRAY: <TAB>  <TAB>  <TAB> removed_edges.add((node, k)) <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> unprocessed.remove(k) <TAB>  <TAB> dfs(k) <TAB> ordered.appendleft(node) <TAB> visited_nodes[node] = BLACK",if sk == BLACK :,120
"def variableNameFromId(obj): <TAB> var = None <TAB> _id = obj.resource_id <TAB> if callable(_id): <TAB>  <TAB> _id = _id() <TAB> if _id: <TAB>  <TAB> var = _id.replace(""."", ""_"").replace("":"", ""___"").replace(""/"", ""_"") <TAB> else: <TAB>  <TAB> _id = obj.unique_id <TAB>  <TAB> if callable(_id): <TAB>  <TAB>  <TAB> _id = _id() <TAB>  <TAB> m = ID_RE.match(_id) <MASK> var = m.group(1) <TAB>  <TAB>  <TAB> if m.group(3): <TAB>  <TAB>  <TAB>  <TAB> var += m.group(3) <TAB>  <TAB>  <TAB> if re.match(r""^\d"", var): <TAB>  <TAB>  <TAB>  <TAB> var = ""id_"" + var <TAB> return var",if m :,184
"def wrapper(*args, **kwargs): <TAB> try: <TAB>  <TAB> return func(*args, **kwargs) <TAB> except requests.HTTPError as err: <TAB>  <TAB> if err.response.status_code == 400: <TAB>  <TAB>  <TAB> raise AuthCanceled(args[0], response=err.response) <TAB>  <TAB> elif err.response.status_code == 401: <TAB>  <TAB>  <TAB> raise AuthForbidden(args[0]) <MASK> raise AuthUnreachableProvider(args[0]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise",elif err . response . status_code == 503 :,129
"def index(): <TAB> data_dir = Path(app.config[""USER_DIR""]) / ""data"" <TAB> if not app.config[""SEARCH_CONF""][""enabled""]: <TAB>  <TAB> click.echo(""Search must be enabled for this command."") <TAB>  <TAB> return <TAB> for filename in data_dir.rglob(""*.md""): <TAB>  <TAB> cur_file = open(filename) <TAB>  <TAB> dataobj = DataObj.from_md(cur_file.read()) <TAB>  <TAB> cur_file.close() <MASK> click.echo(f""Indexed {dataobj.title}..."") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> click.echo(f""Failed to index {dataobj.title}"")",if dataobj . index ( ) :,162
"def _dist_info(self): <TAB> if self._extracted is False: <TAB>  <TAB> return None  # pragma: no cover <TAB> if self.__dist_info is None: <TAB>  <TAB> files = [] <TAB>  <TAB> for filename in self._image_dir.iterdir(): <TAB>  <TAB>  <TAB> files.append(filename.name) <MASK> self.__dist_info = filename <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> msg = ""no .dist-info at {}, has {}"".format( <TAB>  <TAB>  <TAB>  <TAB> self._image_dir, "", "".join(files) <TAB>  <TAB>  <TAB> )  # pragma: no cover <TAB>  <TAB>  <TAB> raise RuntimeError(msg)  # pragma: no cover <TAB> return self.__dist_info","if filename . suffix == "".dist-info"" :",179
"def get_droplet_ip_by_name(s, name): <TAB> response = s.get(""{}/droplets"".format(BASE_API_URL)) <TAB> d = json.loads(response.text) <TAB> if verbose: <TAB>  <TAB> logger(""d={}"".format(d)) <TAB> droplet_ip = None <TAB> for droplet in d[""droplets""]: <MASK> for net in droplet[""networks""][""v4""]: <TAB>  <TAB>  <TAB>  <TAB> if net[""type""] == ""public"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> droplet_ip = net[""ip_address""] <TAB> return droplet_ip","if name in droplet [ ""name"" ] :",148
"def pop_and_collect(lst): <TAB> gc_ctr = 0 <TAB> while lst: <TAB>  <TAB> i = random.randint(0, len(lst) - 1) <TAB>  <TAB> gc_ctr += 1 <TAB>  <TAB> lst.pop(i) <MASK> gc.collect()  # just in case",if gc_ctr % 10000 == 0 :,82
"def extract_box_data(data, box_sequence): <TAB> data_reader = io.BytesIO(data) <TAB> while True: <TAB>  <TAB> box_size = u32.unpack(data_reader.read(4))[0] <TAB>  <TAB> box_type = data_reader.read(4) <MASK> box_data = data_reader.read(box_size - 8) <TAB>  <TAB>  <TAB> if len(box_sequence) == 1: <TAB>  <TAB>  <TAB>  <TAB> return box_data <TAB>  <TAB>  <TAB> return extract_box_data(box_data, box_sequence[1:]) <TAB>  <TAB> data_reader.seek(box_size - 8, 1)",if box_type == box_sequence [ 0 ] :,163
"def _Determine_Do(self): <TAB> self.applicable = 1 <TAB> if sys.platform.startswith(""win""): <TAB>  <TAB> buildType = black.configure.items[""buildType""].Get() <MASK> self.value = ""python_d.exe"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.value = ""python.exe"" <TAB> else: <TAB>  <TAB> self.value = ""python"" <TAB> self.determined = 1","if buildType == ""debug"" :",108
"def scroll_into_view(cls, view, regions): <TAB> if regions and len(regions) > 0: <TAB>  <TAB> # scroll to the first selection if no selections in viewport <TAB>  <TAB> found_region = False <TAB>  <TAB> visible_region = view.visible_region() <TAB>  <TAB> for region in regions: <TAB>  <TAB>  <TAB> if region.intersects(visible_region): <TAB>  <TAB>  <TAB>  <TAB> # we have found a selection in the visible region, do nothing <TAB>  <TAB>  <TAB>  <TAB> found_region = True <TAB>  <TAB>  <TAB>  <TAB> break <MASK> view.show(regions[0], True)",if not found_region :,141
"def _apply_shipping_rule(party=None, quotation=None, cart_settings=None): <TAB> if not quotation.shipping_rule: <TAB>  <TAB> shipping_rules = get_shipping_rules(quotation, cart_settings) <TAB>  <TAB> if not shipping_rules: <TAB>  <TAB>  <TAB> return <MASK> quotation.shipping_rule = shipping_rules[0] <TAB> if quotation.shipping_rule: <TAB>  <TAB> quotation.run_method(""apply_shipping_rule"") <TAB>  <TAB> quotation.run_method(""calculate_taxes_and_totals"")",elif quotation . shipping_rule not in shipping_rules :,142
"def close(self): <TAB> """"""Close this stream."""""" <TAB> if self.socket is not None: <TAB>  <TAB> self.io_loop.remove_handler(self.socket.fileno()) <TAB>  <TAB> self.socket.close() <TAB>  <TAB> self.socket = None <MASK> self._run_callback(self._close_callback)",if self . _close_callback :,85
"def _get_dest_path(self, use_directory_urls): <TAB> """"""Return destination path based on source path."""""" <TAB> if self.is_documentation_page(): <TAB>  <TAB> parent, filename = os.path.split(self.src_path) <MASK> # index.md or README.md => index.html <TAB>  <TAB>  <TAB> # foo.md => foo.html <TAB>  <TAB>  <TAB> return os.path.join(parent, self.name + "".html"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # foo.md => foo/index.html <TAB>  <TAB>  <TAB> return os.path.join(parent, self.name, ""index.html"") <TAB> return self.src_path","if not use_directory_urls or self . name == ""index"" :",173
"def var_tag(var): <TAB> """"""Parse tag attribute of variable node."""""" <TAB> tag = var.tag <TAB> if hasattr(tag, ""trace"") and len(tag.trace) and len(tag.trace[0]) == 4: <MASK> path, line, _, src = tag.trace[0][-1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> path, line, _, src = tag.trace[0] <TAB>  <TAB> path = os.path.basename(path) <TAB>  <TAB> path = path.replace(""<"", """") <TAB>  <TAB> path = path.replace("">"", """") <TAB>  <TAB> src = src.encode() <TAB>  <TAB> return [path, line, src] <TAB> else: <TAB>  <TAB> return None","if isinstance ( tag . trace [ 0 ] [ 0 ] , ( tuple , list ) ) :",176
"def update(self, file_path=None): <TAB> if file_path is not None: <TAB>  <TAB> self.name = os.path.basename(file_path) <TAB>  <TAB> self.media_type, stream_type = guess_media_type(file_path) <MASK> raise Exception(f""File does not exist: {file_path}"") <TAB>  <TAB> self.size = os.path.getsize(file_path) <TAB>  <TAB> if self.size == 0: <TAB>  <TAB>  <TAB> raise Exception(f""Cannot publish empty file: {file_path}"") <TAB>  <TAB> self.file_hash_bytes = calculate_sha384_file_hash(file_path) <TAB>  <TAB> return stream_type",if not os . path . isfile ( file_path ) :,173
"def read_binary(self): <TAB> """"""Internal: read binary data."""""" <TAB> self.file = self.make_file(""b"") <TAB> todo = self.length <TAB> if todo >= 0: <TAB>  <TAB> while todo > 0: <TAB>  <TAB>  <TAB> data = self.fp.read(min(todo, self.bufsize)) <MASK> self.done = -1 <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> self.file.write(data) <TAB>  <TAB>  <TAB> todo = todo - len(data)",if not data :,123
"def execute(self, *args, **kwargs): <TAB> if ""CREATE TABLE"" not in args[0]: <TAB>  <TAB> args = list(args) <TAB>  <TAB> args[0] = args[0].replace(""%s"", ""?"") <MASK> self.cache_result = self.db.execute(*args, **kwargs).fetchone() <TAB>  <TAB> elif ""INSERT"" in args[0]: <TAB>  <TAB>  <TAB> args = [ <TAB>  <TAB>  <TAB>  <TAB> ""INSERT OR REPLACE INTO WeRoBot (id, value) VALUES (?,?);"", <TAB>  <TAB>  <TAB>  <TAB> (args[1][0], args[1][1]), <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB> self.db.execute(*args, **kwargs) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.db.execute(*args, **kwargs)","if ""SELECT"" in args [ 0 ] :",186
"def tamper(payload, **kwargs): <TAB> payload = str(payload) <TAB> retval = """" <TAB> skip = "";"" <TAB> encoding_schema = { <TAB>  <TAB> "" "": ""&nbsp;"", <TAB>  <TAB> ""<"": ""&lt;"", <TAB>  <TAB> "">"": ""&gt;"", <TAB>  <TAB> ""&"": ""&amp;"", <TAB>  <TAB> '""': ""&quot;"", <TAB>  <TAB> ""'"": ""&apos;"", <TAB> } <TAB> if not any(c in payload for c in encoding_schema.keys()): <TAB>  <TAB> return payload <TAB> for char in payload: <TAB>  <TAB> if char in encoding_schema.keys(): <TAB>  <TAB>  <TAB> retval += encoding_schema[char] <MASK> retval += char <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> retval += char <TAB> return retval",elif char not in encoding_schema . keys ( ) and char != skip :,183
"def initialize(self): <TAB> self.session = Session() <TAB> self.session.headers[""User-Agent""] = ""Subliminal/%s"" % __short_version__ <TAB> # login <TAB> if self.username and self.password: <TAB>  <TAB> logger.info(""Logging in"") <TAB>  <TAB> data = { <TAB>  <TAB>  <TAB> ""username"": self.username, <TAB>  <TAB>  <TAB> ""password"": self.password, <TAB>  <TAB>  <TAB> ""Submit"": ""Log in"", <TAB>  <TAB> } <TAB>  <TAB> r = self.session.post( <TAB>  <TAB>  <TAB> self.server_url + ""dologin.php"", data, allow_redirects=False, timeout=10 <TAB>  <TAB> ) <MASK> raise AuthenticationError(self.username) <TAB>  <TAB> logger.debug(""Logged in"") <TAB>  <TAB> self.logged_in = True",if r . status_code != 302 :,195
"def process(self): <TAB> if self.outputs[""data""].is_linked: <TAB>  <TAB> slots = [] <TAB>  <TAB> for socket in self.inputs: <TAB>  <TAB>  <TAB> if socket.is_linked: <TAB>  <TAB>  <TAB>  <TAB> slots.append(socket.sv_get()) <TAB>  <TAB> if len(slots) < 2: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> output = self.myZip(slots, self.level) <MASK> output = preobrazovatel(output, [2, 3]) <TAB>  <TAB> self.outputs[0].sv_set(output)",if self . unwrap :,137
"def FilterDelete(cfg, *filter_ids): <TAB> filter_ids = list(filter_ids) <TAB> filter_ids.sort(key=lambda fid: int(fid, 36)) <TAB> filters = cfg.filters <TAB> for fid in reversed(filter_ids): <TAB>  <TAB> lastid = b36(len(filters) - 1).lower() <MASK> if lastid != fid: <TAB>  <TAB>  <TAB>  <TAB> cfg.filter_move(fid, lastid) <TAB>  <TAB>  <TAB> del filters[lastid]",if fid <= lastid :,124
"def scanAtPagewidthDirectives(aList, issue_error_flag=False): <TAB> """"""Scan aList for @pagewidth directives."""""" <TAB> for d in aList: <TAB>  <TAB> s = d.get(""pagewidth"") <MASK> i, val = g.skip_long(s, 0) <TAB>  <TAB>  <TAB> if val is not None and val > 0: <TAB>  <TAB>  <TAB>  <TAB> return val <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> if issue_error_flag and not g.app.unitTesting: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> g.error(""ignoring @pagewidth"", s) <TAB> return None",if s is not None :,147
"def render_header(self): <TAB> current_ws = self.renderer.current_ws <TAB> for column in self.columns: <MASK> object_renderer = column.object_renderer <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> object_renderer = XLSObjectRenderer( <TAB>  <TAB>  <TAB>  <TAB> session=self.session, renderer=self.renderer <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> object_renderer.RenderHeader(self.renderer.current_ws, column) <TAB> current_ws.current_row += 1 <TAB> current_ws.current_column = 1",if column . object_renderer :,133
"def convert_bandwidth(value): <TAB> types = [(""kbit"", 1000), (""mbit"", 1000000), (""gbit"", 1000000000)] <TAB> if ""unlimited"" == value: <TAB>  <TAB> return 0 <TAB> try: <TAB>  <TAB> # Value is passed as an int <TAB>  <TAB> x = int(value) <TAB>  <TAB> return x >> 3 <TAB> except ValueError: <TAB>  <TAB> value = value.lower() <TAB>  <TAB> for t, mul in types: <MASK> x = int(value.split(t)[0]) * mul <TAB>  <TAB>  <TAB>  <TAB> return x >> 3 <TAB> raise ValueError( <TAB>  <TAB> ""Invalid bandwidth value. Specify either an integer, "" <TAB>  <TAB> '""unlimited"" or a value with ""kbit"", ""mbit"" or ' <TAB>  <TAB> '""gbit"" appended' <TAB> )",if len ( value . split ( t ) ) == 2 :,197
"def is_valid(s: str) -> bool: <TAB> stack = [] <TAB> dic = {"")"": ""("", ""}"": ""{"", ""]"": ""[""} <TAB> for char in s: <MASK> stack.append(char) <TAB>  <TAB> elif char in dic: <TAB>  <TAB>  <TAB> if not stack or dic[char] != stack.pop(): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return not stack",if char in dic . values ( ) :,96
"def process(self, resources, event=None): <TAB> session = local_session(self.manager.session_factory) <TAB> config = session.client(""config"") <TAB> self.model = self.manager.get_model() <TAB> results = [] <TAB> for r in resources: <TAB>  <TAB> revisions = self.get_revisions(config, r) <TAB>  <TAB> r[""c7n:previous-revision""] = rev = self.select_revision(revisions) <MASK> continue <TAB>  <TAB> delta = self.diff(rev[""resource""], r) <TAB>  <TAB> if delta: <TAB>  <TAB>  <TAB> r[""c7n:diff""] = delta <TAB>  <TAB>  <TAB> results.append(r) <TAB> return results",if not rev :,164
"def _flush_batch(self, batch): <TAB> self.on_before_batch_flush(batch) <TAB> try: <MASK> start = utime() <TAB>  <TAB>  <TAB> batch.flush() <TAB>  <TAB>  <TAB> batch.dump_perf_stats(utime() - start) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> batch.flush() <TAB> finally: <TAB>  <TAB> self.on_after_batch_flush(batch) <TAB> return 0",if _debug_options . COLLECT_PERF_STATS :,116
"def get_menu_title(self): <TAB> if self.obj and self.obj.get_handle(): <TAB>  <TAB> name = name_displayer.display(self.obj) <TAB>  <TAB> title = _(""Person: %(name)s"") % {""name"": name} <TAB> else: <TAB>  <TAB> name = name_displayer.display(self.obj) <MASK> title = _(""New Person: %(name)s"") % {""name"": name} <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> title = _(""New Person"") <TAB> return title",if name :,129
"def search(self): <TAB> if Backend.getIdentifiedDbms() in UPPER_CASE_DBMSES: <TAB>  <TAB> for item in (""db"", ""tbl"", ""col""): <MASK> setattr(conf, item, getattr(conf, item).upper()) <TAB> if conf.col: <TAB>  <TAB> self.searchColumn() <TAB> elif conf.tbl: <TAB>  <TAB> self.searchTable() <TAB> elif conf.db: <TAB>  <TAB> self.searchDb() <TAB> else: <TAB>  <TAB> errMsg = ""missing parameter, provide -D, -T or -C along "" <TAB>  <TAB> errMsg += ""with --search"" <TAB>  <TAB> raise SqlmapMissingMandatoryOptionException(errMsg)","if getattr ( conf , item , None ) :",172
"def is_known_player(player): <TAB> """"""Return true if the set player is known."""""" <TAB> for allowed_player in g.playerargs_defaults: <TAB>  <TAB> regex = r""(?:\b%s($|\.[a-zA-Z0-9]+$))"" % re.escape(allowed_player) <TAB>  <TAB> match = re.search(regex, player) <TAB>  <TAB> if mswin: <TAB>  <TAB>  <TAB> match = re.search(regex, player, re.IGNORECASE) <MASK> return allowed_player <TAB> return None",if match :,126
"def prune_dead_workers(self): <TAB> all_workers = Worker.all(self.resq) <TAB> known_workers = Worker.worker_pids() <TAB> for worker in all_workers: <TAB>  <TAB> host, pid, queues = worker.id.split("":"") <TAB>  <TAB> if host != self.hostname: <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> logger.warning(""pruning dead worker: %s"" % worker) <TAB>  <TAB> worker.unregister_worker()",if pid in known_workers :,117
"def readline_kill(self, e): <TAB> func = self.edit_keys[e] <TAB> self.cursor_offset, self.current_line, cut = func( <TAB>  <TAB> self.cursor_offset, self.current_line <TAB> ) <TAB> if self.last_events[-2] == e:  # consecutive kill commands accumulative <MASK> self.cut_buffer += cut <TAB>  <TAB> elif func.kills == ""behind"": <TAB>  <TAB>  <TAB> self.cut_buffer = cut + self.cut_buffer <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""cut value other than 'ahead' or 'behind'"") <TAB> else: <TAB>  <TAB> self.cut_buffer = cut","if func . kills == ""ahead"" :",169
"def will_decode_instruction_callback(self, state, pc): <TAB> world = state.platform <TAB> with self.manticore.locked_context(""seen_rep"", dict) as reps: <TAB>  <TAB> item = ( <TAB>  <TAB>  <TAB> world.current_transaction.sort == ""CREATE"", <TAB>  <TAB>  <TAB> world.current_transaction.address, <TAB>  <TAB>  <TAB> pc, <TAB>  <TAB> ) <MASK> reps[item] = 0 <TAB>  <TAB> reps[item] += 1 <TAB>  <TAB> if reps[item] > 2: <TAB>  <TAB>  <TAB> state.abandon()",if not item in reps :,138
"def _valid_target(self, argument_table): <TAB> # We need to ensure that the target parameter is a shape that <TAB> # looks like it is the Image shape. This means checking that it <TAB> # has a member named Bytes of the blob type. <TAB> if self._source_param in argument_table: <TAB>  <TAB> param = argument_table[self._source_param] <TAB>  <TAB> input_model = param.argument_model <TAB>  <TAB> bytes_member = input_model.members.get(""Bytes"") <MASK> return True <TAB> return False","if bytes_member is not None and bytes_member . type_name == ""blob"" :",146
"def get_length(self, features, ignore_special_tokens=False): <TAB> length = features[""length""] <TAB> if ignore_special_tokens: <TAB>  <TAB> # Decoder mode shifts the sequences by one timesteps. <TAB>  <TAB> num_special_tokens = -1 if self.decoder_mode else 0 <TAB>  <TAB> if self.mark_start: <TAB>  <TAB>  <TAB> num_special_tokens += 1 <MASK> num_special_tokens += 1 <TAB>  <TAB> length -= num_special_tokens <TAB> return length",if self . mark_end :,123
def fsm(): <TAB> if state == st.IDLE: <TAB>  <TAB> tx_bit.next = 1 <MASK> # a pulse <TAB>  <TAB>  <TAB> state.next = st.START <TAB> elif state == st.START: <TAB>  <TAB> tx_bit.next = 0 <TAB>  <TAB> index.next = 7 <TAB>  <TAB> state.next = st.DATA <TAB> elif state == st.DATA: <TAB>  <TAB> tx_bit.next = tx_byte[index] <TAB>  <TAB> if index == 0: <TAB>  <TAB>  <TAB> state.next = st.IDLE <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> index.next = index - 1,if tx_valid :,143
"def get_field_type(self, name): <TAB> if self.dummy: <TAB>  <TAB> return None <TAB> # this is just shadowing a real EdgeDB type <TAB> fkey = (name, self.dummy) <TAB> target = self._fields.get(fkey) <TAB> if target is None: <TAB>  <TAB> # special handling of '__typename' <MASK> target = self.convert_edb_to_gql_type(""std::str"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> target = self.edb_base.getptr(self.edb_schema, name) <TAB>  <TAB>  <TAB> if target is not None: <TAB>  <TAB>  <TAB>  <TAB> target = self.convert_edb_to_gql_type(target) <TAB>  <TAB> self._fields[fkey] = target <TAB> return target","if name == ""__typename"" :",185
"def get_kubernetes_secret_signature( <TAB> kube_client: KubeClient, secret: str, service: str) -> Optional[str]: <TAB> service = sanitise_kubernetes_name(service) <TAB> secret = sanitise_kubernetes_name(secret) <TAB> try: <TAB>  <TAB> signature = kube_client.core.read_namespaced_config_map( <TAB>  <TAB>  <TAB> name=f""paasta-secret-{service}-{secret}-signature"", namespace=""paasta"" <TAB>  <TAB> ) <TAB> except ApiException as e: <MASK> return None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise <TAB> if not signature: <TAB>  <TAB> return None <TAB> else: <TAB>  <TAB> return signature.data[""signature""]",if e . status == 404 :,171
"def name(self): <TAB> if ""DW_AT_name"" in self.attributes: <TAB>  <TAB> return self.attributes[""DW_AT_name""].value <TAB> if ""DW_AT_sibling"" in self.attributes: <TAB>  <TAB> sibling = self.types.get( <TAB>  <TAB>  <TAB> self.attributes[""DW_AT_sibling""].value + self.die.cu.cu_offset <TAB>  <TAB> ) <MASK> return sibling.name <TAB> return utils.SmartStr(""__unnamed_%s"" % self.die.offset)","if sibling and sibling . die . tag == ""DW_TAG_typedef"" :",144
"def fix_latency(row): <TAB> if row[""latency""] < row[""connect_time""]: <MASK> latency = 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> latency = row[""interval_real""] - row[""connect_time""] <TAB> else: <TAB>  <TAB> latency = row[""latency""] - row[""connect_time""] <TAB> return latency","if row [ ""interval_real"" ] < row [ ""connect_time"" ] :",101
"def OnSetIconsOnPanes(self, event): <TAB> panes = self._mgr.GetAllPanes() <TAB> checked = event.IsChecked() <TAB> self._pane_icons = checked <TAB> for pane in panes: <MASK> randimage = random.randint(0, len(ArtIDs) - 1) <TAB>  <TAB>  <TAB> bmp = wx.ArtProvider.GetBitmap( <TAB>  <TAB>  <TAB>  <TAB> eval(ArtIDs[randimage]), wx.ART_OTHER, (16, 16) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> bmp = None <TAB>  <TAB> pane.Icon(bmp) <TAB> self._mgr.Update()",if checked :,156
"def _get_seg_home(): <TAB> if ""SEG_HOME"" in os.environ: <TAB>  <TAB> home_path = os.environ[""SEG_HOME""] <TAB>  <TAB> if os.path.exists(home_path): <MASK> return home_path <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> logger.warning(""SEG_HOME {} is a file!"".format(home_path)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return home_path <TAB> return os.path.join(_get_user_home(), "".paddleseg"")",if os . path . isdir ( home_path ) :,141
"def data(self, index: QModelIndex, role=None): <TAB> if role == Qt.FontRole or role == Qt.TextColorRole: <TAB>  <TAB> file_name = self.get_file_path(index) <TAB>  <TAB> if hasattr(self, ""open_files"") and file_name in self.open_files: <MASK> font = QFont() <TAB>  <TAB>  <TAB>  <TAB> font.setBold(True) <TAB>  <TAB>  <TAB>  <TAB> return font <TAB>  <TAB>  <TAB> elif role == Qt.TextColorRole: <TAB>  <TAB>  <TAB>  <TAB> return QColor(""orange"") <TAB> return super().data(index, role)",if role == Qt . FontRole :,151
"def _request_module(self, fullname, callback): <TAB> self._lock.acquire() <TAB> try: <TAB>  <TAB> present = fullname in self._cache <TAB>  <TAB> if not present: <TAB>  <TAB>  <TAB> funcs = self._callbacks.get(fullname) <MASK> _v and self._log.debug(""existing request for %s in flight"", fullname) <TAB>  <TAB>  <TAB>  <TAB> funcs.append(callback) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> _v and self._log.debug(""sending new %s request to parent"", fullname) <TAB>  <TAB>  <TAB>  <TAB> self._callbacks[fullname] = [callback] <TAB>  <TAB>  <TAB>  <TAB> self._context.send(Message(data=b(fullname), handle=GET_MODULE)) <TAB> finally: <TAB>  <TAB> self._lock.release() <TAB> if present: <TAB>  <TAB> callback()",if funcs is not None :,195
def _update_indices(self) -> Iterable[str]: <TAB> self._topic_name_index.clear() <TAB> self._tp_to_callback.clear() <TAB> for channel in self._topics: <TAB>  <TAB> if channel.internal: <TAB>  <TAB>  <TAB> await channel.maybe_declare() <TAB>  <TAB> for topic in channel.topics: <MASK> self._acking_topics.add(topic) <TAB>  <TAB>  <TAB> self._topic_name_index[topic].add(channel) <TAB> return self._topic_name_index,if channel . acks :,130
"def execute(cls, app, sa_session, action, job, replacement_dict): <TAB> for dataset_assoc in job.output_datasets: <MASK> for k, v in action.action_arguments.items(): <TAB>  <TAB>  <TAB>  <TAB> if v: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # Try to use both pure integer and 'cX' format. <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if not isinstance(v, int): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if v[0] == ""c"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> v = v[1:] <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> v = int(v) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if v != 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> setattr(dataset_assoc.dataset.metadata, k, v)","if action . output_name == """" or dataset_assoc . name == action . output_name :",190
"def __repr__(self): <TAB> if self._repr_cache is None: <TAB>  <TAB> # Include the base names of the selected resources in the name. <MASK> selection_names = [""(all)""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> selection_names = [] <TAB>  <TAB>  <TAB> for s in self.selections: <TAB>  <TAB>  <TAB>  <TAB> if isabs(s): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> selection_names.append(splitext(basename(s))[0]) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> selection_names.append(s) <TAB>  <TAB> self._repr_cache = ""<%s cataloglib: %s>"" % ( <TAB>  <TAB>  <TAB> self.lang, <TAB>  <TAB>  <TAB> "", "".join(selection_names), <TAB>  <TAB> ) <TAB> return self._repr_cache",if self . selection_res_id_set is None :,188
"def _mock_manager_jdm(self, *args, **kwargs): <TAB> if args: <MASK> if args[0].text == ""show version invoke-on all-routing-engines"": <TAB>  <TAB>  <TAB>  <TAB> raise RpcError() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return self._read_file(""sw_info_jdm_command_"" + args[0].text + "".xml"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self._read_file(""sw_info_jdm_"" + args[0].tag + "".xml"")","if args [ 0 ] . tag == ""command"" :",141
"def _create_get_utility_mock(): <TAB> display = FreezableMock() <TAB> # Use pylint code for disable to keep on single line under line length limit <TAB> for name in interfaces.IDisplay.names():  # pylint: E1120 <MASK> frozen_mock = FreezableMock(frozen=True, func=_assert_valid_call) <TAB>  <TAB>  <TAB> setattr(display, name, frozen_mock) <TAB> display.freeze() <TAB> return FreezableMock(frozen=True, return_value=display)","if name != ""notification"" :",129
"def set_todolist_enabled(self, state, current_finfo=None): <TAB> # CONF.get(self.CONF_SECTION, 'todo_list') <TAB> self.todolist_enabled = state <TAB> if self.data: <TAB>  <TAB> for finfo in self.data: <TAB>  <TAB>  <TAB> self.__update_editor_margins(finfo.editor) <TAB>  <TAB>  <TAB> finfo.cleanup_todo_results() <TAB>  <TAB>  <TAB> if state and current_finfo is not None: <MASK> finfo.run_todo_finder()",if current_finfo is not finfo :,133
"def _analyze_all_enums(self, contracts_to_be_analyzed: List[ContractSolc]): <TAB> while contracts_to_be_analyzed: <TAB>  <TAB> contract = contracts_to_be_analyzed[0] <TAB>  <TAB> contracts_to_be_analyzed = contracts_to_be_analyzed[1:] <TAB>  <TAB> all_father_analyzed = all( <TAB>  <TAB>  <TAB> self._underlying_contract_to_parser[father].is_analyzed <TAB>  <TAB>  <TAB> for father in contract.underlying_contract.inheritance <TAB>  <TAB> ) <MASK> self._analyze_enums(contract) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> contracts_to_be_analyzed += [contract]",if not contract . underlying_contract . inheritance or all_father_analyzed :,183
"def match(filename, pathname, pattern): <TAB> dir_only = ""/"" == pattern[-1] <TAB> pattern = pattern.rstrip(""/"") <TAB> if ""/"" not in pattern: <MASK> return os.path.isdir(pathname) if dir_only else True <TAB> else: <TAB>  <TAB> for p in glob.glob(os.path.join(dirname, pattern)): <TAB>  <TAB>  <TAB> p = util.unicodeme(p) <TAB>  <TAB>  <TAB> if pathname == p or pathname.startswith(""{0}/"".format(p)): <TAB>  <TAB>  <TAB>  <TAB> return os.path.isdir(pathname) if dir_only else True <TAB> return False","if fnmatch . fnmatch ( filename , pattern ) :",150
"def _scan_json_compound(rdr): <TAB> # Scan a JSON array or object. <TAB> ret = rdr.getc() <TAB> if ret == ""{"": <TAB>  <TAB> end = ""}"" <TAB> if ret == ""["": <TAB>  <TAB> end = ""]"" <TAB> ret += _scan_json_space(rdr) <MASK> return ret + rdr.getc() <TAB> while True: <TAB>  <TAB> if rdr.eof(): <TAB>  <TAB>  <TAB> raise SyntaxError(""End of file in JSON value"") <TAB>  <TAB> ret += scan_json(rdr) <TAB>  <TAB> ret += _scan_json_space(rdr) <TAB>  <TAB> if rdr.peek() == end: <TAB>  <TAB>  <TAB> return ret + rdr.getc()",if rdr . peek ( ) == end :,173
"def _get_tensorboard_url(self, check_interval=5, wait_timeout=120): <TAB> start_time = time.time() <TAB> while True: <MASK> return None <TAB>  <TAB> service = self._get_tensorboard_service() <TAB>  <TAB> if service is None or service[""status""][""load_balancer""][""ingress""] is None: <TAB>  <TAB>  <TAB> time.sleep(check_interval) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return service[""status""][""load_balancer""][""ingress""][0][""ip""]",if time . time ( ) - start_time > wait_timeout :,133
"def make_theano_batch(self, name=None, dtype=None, batch_size=None): <MASK> rval = tensor.lrow(name=name) <TAB> else: <TAB>  <TAB> rval = tensor.lmatrix(name=name) <TAB> if theano.config.compute_test_value != ""off"": <TAB>  <TAB> if batch_size == 1: <TAB>  <TAB>  <TAB> n = 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # TODO: try to extract constant scalar value from batch_size <TAB>  <TAB>  <TAB> n = 4 <TAB>  <TAB> rval.tag.test_value = self.get_origin_batch(batch_size=n, dtype=dtype) <TAB> return rval",if batch_size == 1 :,160
"def child_pids(pid): <TAB> """"""Return a list of direct child PIDs for the given PID."""""" <TAB> children = set() <TAB> for p in LocalPath(""/proc"").listdir(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> stat = open(p.join(""stat"").strpath).read() <TAB>  <TAB>  <TAB> m = re.match(r""^\d+ \(.+?\) [a-zA-Z] (\d+) "", stat) <TAB>  <TAB>  <TAB> assert m, stat <TAB>  <TAB>  <TAB> ppid = int(m.group(1)) <MASK> children.add(int(p.basename)) <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> # Happens when the process exits after listing it, or between <TAB>  <TAB>  <TAB> # opening stat and reading it. <TAB>  <TAB>  <TAB> pass <TAB> return children",if ppid == pid :,188
"def doesUserHaveRole(self, user, role): <TAB> hasRole = False <TAB> for i in range(len(self.data)): <MASK> userRoles = self.data[i].roles <TAB>  <TAB>  <TAB> for j in range(len(userRoles)): <TAB>  <TAB>  <TAB>  <TAB> if userRoles[j] == role: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> hasRole = True <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return hasRole",if self . data [ i ] . username == user . username :,113
"def __init__(self, initlist=None): <TAB> self.data = [] <TAB> if initlist is not None: <TAB>  <TAB> # XXX should this accept an arbitrary sequence? <MASK> self.data[:] = initlist <TAB>  <TAB> elif isinstance(initlist, UserList): <TAB>  <TAB>  <TAB> self.data[:] = initlist.data[:] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.data = list(initlist)",if type ( initlist ) == type ( self . data ) :,111
"def move_down(self, terminal): <TAB> window_width, window_height = self.window.get_size() <TAB> tx, ty, tw, th = self.list_allocation(terminal) <TAB> if ty + th == window_height: <TAB>  <TAB> return <TAB> search_x = tx + (tw / 2) - FocusMover.BORDER_THICKNESS <TAB> search_y = ty + th + FocusMover.THRESHOLD <TAB> for term in terminal.get_parent().get_root_box().iter_terminals(): <TAB>  <TAB> sx, sy, sw, sh = self.list_allocation(term) <MASK> term.grab_focus()",if sx <= search_x <= sx + sw and sy <= search_y <= sy + sh :,178
"def _merge_new_vocabulary_tokens( <TAB> self, existing_vocabulary: Dict[Text, int], vocabulary: Set[Text]) -> None: <TAB> available_empty_index = self._get_starting_empty_index(existing_vocabulary) <TAB> for token in vocabulary: <MASK> existing_vocabulary[token] = available_empty_index <TAB>  <TAB>  <TAB> del existing_vocabulary[f""{BUFFER_SLOTS_PREFIX}{available_empty_index}""] <TAB>  <TAB>  <TAB> available_empty_index += 1 <TAB>  <TAB>  <TAB> if available_empty_index == len(existing_vocabulary): <TAB>  <TAB>  <TAB>  <TAB> # We have exhausted all available vocabulary slots. <TAB>  <TAB>  <TAB>  <TAB> # Drop the remaining vocabulary. <TAB>  <TAB>  <TAB>  <TAB> return",if token not in existing_vocabulary :,174
"def getrruleset(child, ignore=()): <TAB> if ( <TAB>  <TAB> hasattr(child, ""rrule"") <TAB>  <TAB> and "";UNTIL="" not in child.rrule.value.upper() <TAB>  <TAB> and "";COUNT="" not in child.rrule.value.upper() <TAB> ): <TAB>  <TAB> for dtstart in child.getrruleset(addRDate=True): <TAB>  <TAB>  <TAB> if dtstart in ignore: <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> return (), True <TAB>  <TAB>  <TAB> break <TAB> return ( <TAB>  <TAB> filter(lambda dtstart: dtstart not in ignore, child.getrruleset(addRDate=True)), <TAB>  <TAB> False, <TAB> )",if infinity_fn ( date_to_datetime ( dtstart ) ) :,158
"def _get_unique_child(xtag, eltname): <TAB> """"""Get the unique child element under xtag with name eltname"""""" <TAB> try: <TAB>  <TAB> results = xtag.findall(eltname) <MASK> raise Exception(""Multiple elements found where 0/1 expected"") <TAB>  <TAB> elif len(results) == 1: <TAB>  <TAB>  <TAB> return results[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return None <TAB> except Exception: <TAB>  <TAB> return None",if len ( results ) > 1 :,116
"def convert_ast(self, ast): <TAB> for (node, entering) in ast.walker(): <TAB>  <TAB> fn_prefix = ""visit"" if entering else ""depart"" <TAB>  <TAB> fn_name = ""{0}_{1}"".format(fn_prefix, node.t.lower()) <TAB>  <TAB> fn_default = ""default_{0}"".format(fn_prefix) <TAB>  <TAB> fn = getattr(self, fn_name, None) <MASK> fn = getattr(self, fn_default) <TAB>  <TAB> fn(node)",if fn is None :,126
"def insert(self, value): <TAB> """"""Insert an occurrence of `value` into the btree."""""" <TAB> i = 0 <TAB> n = len(self._tree) <TAB> while i < n: <TAB>  <TAB> cur = self._tree[i] <TAB>  <TAB> self._counts[i] += 1 <MASK> i = 2 * i + 1 <TAB>  <TAB> elif value > cur: <TAB>  <TAB>  <TAB> i = 2 * i + 2 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return <TAB> raise ValueError( <TAB>  <TAB> ""Value %s not contained in tree."" ""Also, the counts are now messed up."" % value <TAB> )",if value < cur :,147
"def do_toggle(self): <TAB> try: <MASK> accelerometer.enable() <TAB>  <TAB>  <TAB> Clock.schedule_interval(self.get_acceleration, 1 / 20.0) <TAB>  <TAB>  <TAB> self.sensorEnabled = True <TAB>  <TAB>  <TAB> self.ids.toggle_button.text = ""Stop Accelerometer"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> accelerometer.disable() <TAB>  <TAB>  <TAB> self.reset_plots() <TAB>  <TAB>  <TAB> Clock.unschedule(self.get_acceleration) <TAB>  <TAB>  <TAB> self.sensorEnabled = False <TAB>  <TAB>  <TAB> self.ids.toggle_button.text = ""Start Accelerometer"" <TAB> except NotImplementedError: <TAB>  <TAB> popup = ErrorPopup() <TAB>  <TAB> popup.open()",if not self . sensorEnabled :,180
"def get_short_group_name(release_group): <TAB> short_group_list = [] <TAB> try: <TAB>  <TAB> group = app.ADBA_CONNECTION.group(gname=release_group) <TAB> except AniDBCommandTimeoutError: <TAB>  <TAB> log.debug(""Timeout while loading group from AniDB. Trying next group"") <TAB> except Exception: <TAB>  <TAB> log.debug(""Failed while loading group from AniDB. Trying next group"") <TAB> else: <TAB>  <TAB> for line in group.datalines: <TAB>  <TAB>  <TAB> if line[""shortname""]: <TAB>  <TAB>  <TAB>  <TAB> short_group_list.append(line[""shortname""]) <TAB>  <TAB>  <TAB> else: <MASK> short_group_list.append(release_group) <TAB> return short_group_list",if release_group not in short_group_list :,192
"def __init__(self, policy_str, partition_book): <TAB> splits = policy_str.split("":"") <TAB> if len(splits) == 1: <TAB>  <TAB> assert policy_str in ( <TAB>  <TAB>  <TAB> EDGE_PART_POLICY, <TAB>  <TAB>  <TAB> NODE_PART_POLICY, <TAB>  <TAB> ), ""policy_str must contain 'edge' or 'node'."" <MASK> policy_str = NODE_PART_POLICY + "":_N"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> policy_str = EDGE_PART_POLICY + "":_E"" <TAB> self._policy_str = policy_str <TAB> self._part_id = partition_book.partid <TAB> self._partition_book = partition_book",if NODE_PART_POLICY == policy_str :,176
"def module(self) -> str: <TAB> result = self.func[0] <TAB> edgedb = str(EDGEDB_DIR) + os.sep <TAB> if result.startswith(edgedb): <TAB>  <TAB> return result[len(edgedb) :] <TAB> parts = [] <TAB> maybe_stdlib = False <TAB> for part in pathlib.Path(result).parts[::-1]: <TAB>  <TAB> parts.append(part) <TAB>  <TAB> if part in {""python3.6"", ""python3.7"", ""python3.8"", ""python3.9""}: <TAB>  <TAB>  <TAB> maybe_stdlib = True <MASK> if part == ""lib"": <TAB>  <TAB>  <TAB>  <TAB> parts.pop() <TAB>  <TAB>  <TAB>  <TAB> return os.sep.join(parts[::-1]) <TAB>  <TAB>  <TAB> break <TAB> return result",elif maybe_stdlib :,184
"def migrate_FieldAttr(self): <TAB> for old_obj in self.session_old.query(self.model_from[""FieldAttr""]): <TAB>  <TAB> new_obj = self.model_to[""FieldAttr""]() <TAB>  <TAB> for key in new_obj.__table__.columns._data.keys(): <TAB>  <TAB>  <TAB> setattr(new_obj, key, getattr(old_obj, key)) <MASK> new_obj.value = False <TAB>  <TAB> self.session_new.add(new_obj)","if new_obj . name == ""display_alphabetically"" :",130
"def __eq__(self, other): <TAB> if isinstance(other, OrderedDict): <MASK> return False <TAB>  <TAB> for p, q in zip(self.items(), other.items()): <TAB>  <TAB>  <TAB> if p != q: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True <TAB> return dict.__eq__(self, other)",if len ( self ) != len ( other ) :,87
"def addClass(self, cn): <TAB> """"""Add the specific class names to the class set and return ``self``."""""" <TAB> if cn: <MASK> add = self.addClass <TAB>  <TAB>  <TAB> for c in cn: <TAB>  <TAB>  <TAB>  <TAB> add(c) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> classes = self._classes <TAB>  <TAB>  <TAB> if classes is None: <TAB>  <TAB>  <TAB>  <TAB> self._extra[""classes""] = classes = set() <TAB>  <TAB>  <TAB> add = classes.add <TAB>  <TAB>  <TAB> for cn in cn.split(): <TAB>  <TAB>  <TAB>  <TAB> add(slugify(cn)) <TAB> return self","if isinstance ( cn , ( tuple , list , set , frozenset ) ) :",150
def _is_amd3dnow(agi): <TAB> for g in agi.generator_list: <TAB>  <TAB> ii = g.parser_output.instructions[0] <MASK> for ii in g.parser_output.instructions: <TAB>  <TAB>  <TAB>  <TAB> if ii.category == _xed_3dnow_category: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False,"if genutil . field_check ( ii , ""iclass"" ) :",104
"def markers_at_position(self, position): <TAB> """"""Return a list of markers with the given position"""""" <MASK> # TODO: remove below once python2 has ended <TAB>  <TAB> # currently in python2, can receive either an int or <TAB>  <TAB> # a long <TAB>  <TAB> if isinstance(position, numbers.Integral): <TAB>  <TAB>  <TAB> position = int(position) <TAB>  <TAB>  <TAB> # may still be an int if the position is too big <TAB>  <TAB> if type(position) is not int: <TAB>  <TAB>  <TAB> _wrong_type_for_arg(position, ""int"", ""position"") <TAB> return [mrk for mrk in self.markers if mrk.position == position]",if type ( position ) is not int :,162
"def get_key_visitors(account_info): <TAB> if not account_info.get(""visitors""): <TAB>  <TAB> return [EncryptExtantKeys(keyconfig)] <TAB> visitors = [] <TAB> for v in account_info.get(""visitors""): <MASK> vi = EncryptExtantKeys(v) <TAB>  <TAB>  <TAB> vi.visitor_name = ""encrypt-keys"" <TAB>  <TAB>  <TAB> vi.inventory_filter = filter_encrypted <TAB>  <TAB>  <TAB> visitors.append(vi) <TAB>  <TAB> elif v[""type""] == ""object-acl"": <TAB>  <TAB>  <TAB> vi = ObjectAclCheck(v) <TAB>  <TAB>  <TAB> vi.visitor_name = ""object-acl"" <TAB>  <TAB>  <TAB> vi.inventory_filter = None <TAB>  <TAB>  <TAB> visitors.append(vi) <TAB> return visitors","if v [ ""type"" ] == ""encrypt-keys"" :",188
"def _response(self, request_number, t, *arg): <TAB> msg = Message() <TAB> msg.add_int(request_number) <TAB> for item in arg: <TAB>  <TAB> if isinstance(item, long): <TAB>  <TAB>  <TAB> msg.add_int64(item) <TAB>  <TAB> elif isinstance(item, int): <TAB>  <TAB>  <TAB> msg.add_int(item) <MASK> msg.add_string(item) <TAB>  <TAB> elif type(item) is SFTPAttributes: <TAB>  <TAB>  <TAB> item._pack(msg) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> ""unknown type for "" + repr(item) + "" type "" + repr(type(item)) <TAB>  <TAB>  <TAB> ) <TAB> self._send_packet(t, msg)","elif isinstance ( item , ( string_types , bytes_types ) ) :",194
"def assign_attrs(self, elem, attrs): <TAB> """"""Assign attrs to element."""""" <TAB> for k, v in get_attrs(attrs): <TAB>  <TAB> if k == ""."": <TAB>  <TAB>  <TAB> # add to class <TAB>  <TAB>  <TAB> cls = elem.get(""class"") <MASK> elem.set(""class"", ""%s %s"" % (cls, v)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> elem.set(""class"", v) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # assign attr k with v <TAB>  <TAB>  <TAB> elem.set(self.sanitize_name(k), v)",if cls :,141
"def to_dict(self): <TAB> if self.is_singleton(): <TAB>  <TAB> spec = self.singleton() <MASK> return spec <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return spec.to_dict() <TAB> else: <TAB>  <TAB> return OrderedDict( <TAB>  <TAB>  <TAB> ( <TAB>  <TAB>  <TAB>  <TAB> (name, (spec if isinstance(spec, self.value_type) else spec.to_dict())) <TAB>  <TAB>  <TAB>  <TAB> for name, spec in super(NestedDict, self).items() <TAB>  <TAB>  <TAB>  <TAB> if isinstance(spec, self.value_type) or len(spec) > 0 <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> )","if isinstance ( spec , self . value_type ) :",156
"def _circuit_measurements(circuit: ""cirq.Circuit"") -> Iterator[MeasureInfo]: <TAB> for i, moment in enumerate(circuit): <TAB>  <TAB> for op in moment: <MASK> yield MeasureInfo( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> key=op.gate.key, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> qubits=_grid_qubits(op), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> slot=i, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> invert_mask=list(op.gate.full_invert_mask()), <TAB>  <TAB>  <TAB>  <TAB> )","if isinstance ( op . gate , ops . MeasurementGate ) :",140
"def apply_msvcdeps_flags(taskgen): <TAB> if taskgen.env.CC_NAME not in supported_compilers: <TAB>  <TAB> return <TAB> for flag in (""CFLAGS"", ""CXXFLAGS""): <MASK> taskgen.env.append_value(flag, PREPROCESSOR_FLAG)",if taskgen . env . get_flat ( flag ) . find ( PREPROCESSOR_FLAG ) < 0 :,95
"def _fill(self): <TAB> data = {} <TAB> zone_tab = open_resource(""zone.tab"") <TAB> for line in zone_tab: <MASK> continue <TAB>  <TAB> code, coordinates, zone = line.split(None, 4)[:3] <TAB>  <TAB> if not resource_exists(zone): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> data[code].append(zone) <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> data[code] = [zone] <TAB> self.data = data","if line . startswith ( ""#"" ) :",125
"def _get_function(self, func): <TAB> f = None <TAB> if type(func) is str: <TAB>  <TAB> f = self.cfg.kb.functions.function(name=func) <MASK> l.warning(""Function '%s' doesn't exist in the CFG. Skipping..."", func) <TAB> elif type(func) is int: <TAB>  <TAB> f = self.cfg.kb.functions.function(addr=func) <TAB>  <TAB> if f is None: <TAB>  <TAB>  <TAB> l.warning(""Function at 0x%x doesn't exist in the CFG. Skipping..."", func) <TAB> elif type(func) is Function: <TAB>  <TAB> f = func <TAB> return f",if f is None :,158
"def _sorted_layers(self, structure, top_layer_id): <TAB> """"""Return the layers sorted"""""" <TAB> sorted_layers = [] <TAB> next_layer = top_layer_id <TAB> while next_layer: <TAB>  <TAB> sorted_layers.append(next_layer) <MASK> break <TAB>  <TAB> next_layer = structure[""repolayers""][next_layer][""json""][""parent""] <TAB>  <TAB> if not next_layer: <TAB>  <TAB>  <TAB> break <TAB> return sorted_layers","if ""parent"" not in structure [ ""repolayers"" ] [ next_layer ] [ ""json"" ] :",132
"def _exists(self, type): <TAB> self.artwork_files = [] <TAB> self.thumb_files = [] <TAB> if type == ""artwork"": <TAB>  <TAB> self.artwork_files = self._findfilesstartingwith( <TAB>  <TAB>  <TAB> self.id, self.path_to_art_cache <TAB>  <TAB> ) <MASK> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> elif type == ""thumb"": <TAB>  <TAB> self.thumb_files = self._findfilesstartingwith( <TAB>  <TAB>  <TAB> ""T_"" + self.id, self.path_to_art_cache <TAB>  <TAB> ) <TAB>  <TAB> if self.thumb_files: <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False",if self . artwork_files :,175
"def predict(self):  # Let paddle react on keys <TAB> self.vY = 0 <TAB> if self.index:  # Right player <TAB>  <TAB> if self.game.keyCode == ord(""K""):  # Letter K pressed <TAB>  <TAB>  <TAB> self.vY = self.speed <TAB>  <TAB> elif self.game.keyCode == ord(""M""): <TAB>  <TAB>  <TAB> self.vY = -self.speed <TAB> else:  # Left player <MASK> self.vY = self.speed <TAB>  <TAB> elif self.game.keyCode == ord(""Z""): <TAB>  <TAB>  <TAB> self.vY = -self.speed <TAB> Sprite.predict(self)  # Do not yet commit, paddle may bounce with walls","if self . game . keyCode == ord ( ""A"" ) :",184
"def re_list(string, br=""[]""): <TAB> new = """" <TAB> nested = False <TAB> n, m = 0, 0 <TAB> while n < len(string): <TAB>  <TAB> char = string[n] <MASK> if nested is False: <TAB>  <TAB>  <TAB>  <TAB> nested = True <TAB>  <TAB>  <TAB>  <TAB> m = n <TAB>  <TAB>  <TAB>  <TAB> n += 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> sub = string[n + 1 : string.rfind(br[1])] <TAB>  <TAB>  <TAB>  <TAB> value = re_list(sub) <TAB>  <TAB>  <TAB>  <TAB> n += len(value) + 1 <TAB>  <TAB> elif char == br[1]: <TAB>  <TAB>  <TAB> new_string = string[m : n + 1] <TAB>  <TAB>  <TAB> return new_string <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> n += 1",if char == br [ 0 ] :,191
"def fetch(self, job: Job): <TAB> for entry in self._get_remotes(job): <MASK> self.raise_cache_miss_exception(job) <TAB>  <TAB> # download to outputfile <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> entry.download() <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> self.raise_read_error(entry, exception=e)",if not entry . exists ( ) :,96
"def _process_system_args(): <TAB> global _args_system <TAB> # try using argparse <TAB> parser = SafeArgumentParser(add_help=False) <TAB> for num, arg in enumerate(sys.argv): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> next_arg = sys.argv[num + 1] <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB> next_arg = """" <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> parser.add_argument(arg) <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB> try: <TAB>  <TAB> parsed, unknown = parser.parse_known_args() <TAB> except ArgumentException: <TAB>  <TAB> pass <TAB> else: <TAB>  <TAB> _args_system = vars(parsed)","if arg . startswith ( ( ""-"" , ""--"" ) ) and not next_arg . startswith ( ( ""-"" , ""--"" ) ) :",183
"def _get_all_public_classes(module) -> Iterator[Tuple[str, Type]]: <TAB> for name, obj in inspect.getmembers(module): <TAB>  <TAB> if inspect.isfunction(obj) or inspect.ismodule(obj): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if name in SHOULDNT_BE_SERIALIZED: <TAB>  <TAB>  <TAB> continue <MASK> # singletons, for instance <TAB>  <TAB>  <TAB> obj = obj.__class__ <TAB>  <TAB> if name.startswith(""_""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if inspect.isclass(obj) and inspect.isabstract(obj): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # assert name != 'XPowGate' <TAB>  <TAB> yield name, obj",if not inspect . isclass ( obj ) :,165
"def partition(head, x): <TAB> left = None <TAB> right = None <TAB> prev = None <TAB> current = head <TAB> while current: <MASK> if not right: <TAB>  <TAB>  <TAB>  <TAB> right = current <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if not left: <TAB>  <TAB>  <TAB>  <TAB> left = current <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> prev.next = current.next <TAB>  <TAB>  <TAB>  <TAB> left.next = current <TAB>  <TAB>  <TAB>  <TAB> left = current <TAB>  <TAB>  <TAB>  <TAB> left.next = right <TAB>  <TAB> if prev and prev.next is None: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> # cache previous value in case it needs to be pointed elsewhere <TAB>  <TAB> prev = current <TAB>  <TAB> current = current.next",if int ( current . val ) >= x :,175
"def set_edited_object_value(self, objects, obj_name, prop_path, value): <TAB> for obj in objects: <MASK> # editor_data is [prop_path, label, tooltip, editor_type, value], see blenderprojectinit.py, containerprogramedit.EditorManagerWindow.get_current_editor_data() <TAB>  <TAB>  <TAB> for json_editor_data in obj[2]: <TAB>  <TAB>  <TAB>  <TAB> if json_editor_data[0] == prop_path: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> json_editor_data[4] = value",if obj [ 0 ] == obj_name :,145
"def streamer(stream, chunk_size=DEFAULT_CHUNK_SIZE, bytes=None, callback=None): <TAB> try: <TAB>  <TAB> offset = 0 <TAB>  <TAB> while bytes is None or offset < bytes: <TAB>  <TAB>  <TAB> if not bytes is None and bytes - offset < chunk_size: <TAB>  <TAB>  <TAB>  <TAB> chunk_size = bytes - offset <TAB>  <TAB>  <TAB> data = stream.read(chunk_size) <TAB>  <TAB>  <TAB> length = len(data) <TAB>  <TAB>  <TAB> if not length: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield data <MASK> break <TAB>  <TAB>  <TAB> offset += length <TAB> finally: <TAB>  <TAB> stream.close() <TAB>  <TAB> if callback: <TAB>  <TAB>  <TAB> callback()",if length < chunk_size :,175
"def store_to_file(self, filename, add_single_quotes=True): <TAB> with tf.gfile.Open(filename, ""w"") as f: <TAB>  <TAB> for subtoken_string in self._all_subtoken_strings: <MASK> f.write(""'"" + unicode_to_native(subtoken_string) + ""'\n"") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> f.write(unicode_to_native(subtoken_string) + ""\n"")",if add_single_quotes :,118
"def printJobLog(self): <TAB> """"""Takes a list of jobs, finds their log files, and prints them to the terminal."""""" <TAB> for job in self.jobsToReport: <MASK> msg = ""LOG_FILE_OF_JOB:%s LOG: =======>\n"" % job <TAB>  <TAB>  <TAB> with job.getLogFileHandle(self.jobStore) as fH: <TAB>  <TAB>  <TAB>  <TAB> msg += fH.read() <TAB>  <TAB>  <TAB> msg += ""<========="" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> msg = ""LOG_FILE_OF_JOB:%s LOG: Job has no log file"" % job <TAB>  <TAB> print(msg)",if job . logJobStoreFileID is not None :,159
"def _create_embeddings( <TAB> cls, config: Config, tensorizers: Dict[str, Tensorizer]) -> nn.ModuleList: <TAB> embeddings = [] <TAB> for inputs in cls.INPUTS_PAIR: <TAB>  <TAB> embedding_list = [] <TAB>  <TAB> for emb, input in zip(cls.EMBEDDINGS, inputs): <TAB>  <TAB>  <TAB> if hasattr(config, emb) and input in tensorizers: <TAB>  <TAB>  <TAB>  <TAB> embedding_list.append( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> cls._create_embedding(getattr(config, emb), tensorizers[input]) <TAB>  <TAB>  <TAB>  <TAB> ) <MASK> embeddings.append(embedding_list[0]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> embeddings.append(EmbeddingList(embeddings=embedding_list, concat=True)) <TAB> return nn.ModuleList(embeddings)",if len ( embedding_list ) == 1 :,191
"def _update_preferred_sizes(self): <TAB> for pane in self.pane_widgets(): <TAB>  <TAB> if getattr(pane, ""preferred_size_in_pw"", None) is not None: <MASK> current_size = pane.winfo_width() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> current_size = pane.winfo_height() <TAB>  <TAB>  <TAB> if current_size > 20: <TAB>  <TAB>  <TAB>  <TAB> pane.preferred_size_in_pw = current_size","if self . cget ( ""orient"" ) == ""horizontal"" :",131
"def _create_examples(self, data_dir): <TAB> examples = [] <TAB> for label in [""neg"", ""pos""]: <TAB>  <TAB> cur_dir = os.path.join(data_dir, label) <TAB>  <TAB> for filename in os.listdir(cur_dir): <MASK> continue <TAB>  <TAB>  <TAB> path = os.path.join(cur_dir, filename) <TAB>  <TAB>  <TAB> with io.open(path, ""r"", encoding=""utf8"") as f: <TAB>  <TAB>  <TAB>  <TAB> text = f.read().strip().replace(""<br />"", "" "") <TAB>  <TAB>  <TAB> examples.append( <TAB>  <TAB>  <TAB>  <TAB> InputExample(guid=""unused_id"", text_a=text, text_b=None, label=label) <TAB>  <TAB>  <TAB> ) <TAB> return examples","if not filename . endswith ( ""txt"" ) :",187
"def endTagP(self, token): <TAB> if not self.tree.elementInScope(""p"", variant=""button""): <TAB>  <TAB> self.startTagCloseP(impliedTagToken(""p"", ""StartTag"")) <TAB>  <TAB> self.parser.parseError(""unexpected-end-tag"", {""name"": ""p""}) <TAB>  <TAB> self.endTagP(impliedTagToken(""p"", ""EndTag"")) <TAB> else: <TAB>  <TAB> self.tree.generateImpliedEndTags(""p"") <MASK> self.parser.parseError(""unexpected-end-tag"", {""name"": ""p""}) <TAB>  <TAB> node = self.tree.openElements.pop() <TAB>  <TAB> while node.name != ""p"": <TAB>  <TAB>  <TAB> node = self.tree.openElements.pop()","if self . tree . openElements [ - 1 ] . name != ""p"" :",191
"def add_default_values(self, pipeline): <TAB> for stage in pipeline[""stages""]: <TAB>  <TAB> for action in stage[""actions""]: <TAB>  <TAB>  <TAB> if ""runOrder"" not in action: <TAB>  <TAB>  <TAB>  <TAB> action[""runOrder""] = 1 <TAB>  <TAB>  <TAB> if ""configuration"" not in action: <TAB>  <TAB>  <TAB>  <TAB> action[""configuration""] = {} <TAB>  <TAB>  <TAB> if ""outputArtifacts"" not in action: <TAB>  <TAB>  <TAB>  <TAB> action[""outputArtifacts""] = [] <MASK> action[""inputArtifacts""] = [] <TAB> return pipeline","if ""inputArtifacts"" not in action :",137
"def test_error_through_destructor(self): <TAB> # Test that the exception state is not modified by a destructor, <TAB> # even if close() fails. <TAB> rawio = self.CloseFailureIO() <TAB> with support.catch_unraisable_exception() as cm: <TAB>  <TAB> with self.assertRaises(AttributeError): <TAB>  <TAB>  <TAB> self.TextIOWrapper(rawio).xyzzy <MASK> self.assertIsNone(cm.unraisable) <TAB>  <TAB> elif cm.unraisable is not None: <TAB>  <TAB>  <TAB> self.assertEqual(cm.unraisable.exc_type, OSError)",if not IOBASE_EMITS_UNRAISABLE :,157
"def tearDownClass(cls): <TAB> if not os.getenv(""REZ_KEEP_TMPDIRS""): <TAB>  <TAB> # The retries are here because there is at least one case in the <TAB>  <TAB> # tests where a subproc can be writing to files in a tmpdir after <TAB>  <TAB> # the tests are completed (this is the rez-pkg-cache proc in the <TAB>  <TAB> # test_package_cache:test_caching_on_resolve test). <TAB>  <TAB> # <TAB>  <TAB> retries = 5 <TAB>  <TAB> if os.path.exists(cls.root): <TAB>  <TAB>  <TAB> for i in range(retries): <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> shutil.rmtree(cls.root) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB>  <TAB> except: <MASK> time.sleep(0.2)",if i < ( retries - 1 ) :,197
"def _unlocked_GetMaxMsgIdxPos(cls): <TAB> global GLOBAL_GPL <TAB> try: <TAB>  <TAB> max_idx = 0 <TAB>  <TAB> for hits in GLOBAL_GPL.values(): <MASK> max_idx = max(max_idx, max(int(id, 36) for id in hits)) <TAB>  <TAB> return max_idx <TAB> except: <TAB>  <TAB> return 0",if hits :,97
"def switchToChapter(self, w): <TAB> """"""select w.leo_chapter."""""" <TAB> c = self.c <TAB> cc = c.chapterController <TAB> if hasattr(w, ""leo_chapter"") and w.leo_chapter: <TAB>  <TAB> chapter = w.leo_chapter <TAB>  <TAB> name = chapter and chapter.name <TAB>  <TAB> oldChapter = cc.getSelectedChapter() <MASK> cc.selectChapterByName(name) <TAB>  <TAB>  <TAB> c.bodyWantsFocus()",if chapter != oldChapter :,130
"def test_core_is_properly_reexported(): <TAB> # Each export from _core should be re-exported by exactly one of these <TAB> # three modules: <TAB> sources = [trio, trio.lowlevel, trio.testing] <TAB> for symbol in dir(_core): <MASK> continue <TAB>  <TAB> found = 0 <TAB>  <TAB> for source in sources: <TAB>  <TAB>  <TAB> if symbol in dir(source) and getattr(source, symbol) is getattr( <TAB>  <TAB>  <TAB>  <TAB> _core, symbol <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> found += 1 <TAB>  <TAB> print(symbol, found) <TAB>  <TAB> assert found == 1","if symbol . startswith ( ""_"" ) or symbol == ""tests"" :",158
"def __new__(mcs, name, bases, newattrs): <TAB> klass = type.__new__(mcs, name, bases, newattrs) <TAB> klass.callable_methods = {} <TAB> klass.deprecated_methods = {} <TAB> for methodname in dir(klass): <MASK> method = getattr(klass, methodname) <TAB>  <TAB>  <TAB> if not hasattr(method, ""_deprecated""): <TAB>  <TAB>  <TAB>  <TAB> klass.callable_methods.update({methodname.split(""jsonrpc_"")[1]: method}) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> klass.deprecated_methods.update( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> {methodname.split(""jsonrpc_"")[1]: method} <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return klass","if methodname . startswith ( ""jsonrpc_"" ) :",170
"def convert_osc(self, text): <TAB> for match in self.ANSI_OSC_RE.finditer(text): <TAB>  <TAB> start, end = match.span() <TAB>  <TAB> text = text[:start] + text[end:] <TAB>  <TAB> paramstring, command = match.groups() <MASK> # \x07 = BEL <TAB>  <TAB>  <TAB> params = paramstring.split("";"") <TAB>  <TAB>  <TAB> # 0 - change title and icon (we will only change title) <TAB>  <TAB>  <TAB> # 1 - change icon (we don't support this) <TAB>  <TAB>  <TAB> # 2 - change title <TAB>  <TAB>  <TAB> if params[0] in ""02"": <TAB>  <TAB>  <TAB>  <TAB> winterm.set_title(params[1]) <TAB> return text","if command in ""\x07"" :",171
"def colname(colx, _A2Z=""ABCDEFGHIJKLMNOPQRSTUVWXYZ""): <TAB> assert colx >= 0 <TAB> name = """" <TAB> while True: <TAB>  <TAB> quot, rem = divmod(colx, 26) <TAB>  <TAB> name = _A2Z[rem] + name <MASK> return name <TAB>  <TAB> colx = quot - 1",if not quot :,89
"def parse(self, rawInput): <TAB> ws = "" \t"" <TAB> heads = {} <TAB> curhead = None <TAB> curbuf = [] <TAB> for line in rawInput.splitlines(): <TAB>  <TAB> if not line.strip(): <TAB>  <TAB>  <TAB> continue <MASK> curbuf.append(line.strip()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if curhead: <TAB>  <TAB>  <TAB>  <TAB> heads.setdefault(curhead, []).append("" "".join(curbuf)) <TAB>  <TAB>  <TAB> name, body = map(str.strip, line.split("":"", 1)) <TAB>  <TAB>  <TAB> curhead = name.lower() <TAB>  <TAB>  <TAB> curbuf = [body] <TAB> if curhead: <TAB>  <TAB> heads.setdefault(curhead, []).append("" "".join(curbuf)) <TAB> self._headers = heads <TAB> self.link()",if line [ 0 ] in ws :,195
"def _gen_LessEqual(self, args, ret_type): <TAB> result = [] <TAB> for lhs, rhs in pairwise(args): <TAB>  <TAB> if ret_type == real_type: <TAB>  <TAB>  <TAB> result.append(self.builder.fcmp_ordered(""<="", lhs, rhs)) <MASK> result.append(self.builder.icmp_signed(""<="", lhs, rhs)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise CompileError() <TAB> return reduce(self.builder.and_, result)",elif ret_type == int_type :,120
"def _mock_manager(self, *args, **kwargs): <TAB> if kwargs: <TAB>  <TAB> device_params = kwargs[""device_params""] <TAB>  <TAB> device_handler = make_device_handler(device_params) <TAB>  <TAB> session = SSHSession(device_handler) <TAB>  <TAB> return Manager(session, device_handler) <TAB> if args: <MASK> return self._read_file(args[0].tag + ""_RE0-RE0.xml"") <TAB>  <TAB> return self._read_file(args[0].tag + "".xml"")","if ""version_RE0-RE0"" in self . facts :",142
"def set_process_lowest_prio(): <TAB> try: <TAB>  <TAB> if sys.platform[0:3] == ""win"": <TAB>  <TAB>  <TAB> GetCurrentProcess = windll.kernel32.GetCurrentProcess <TAB>  <TAB>  <TAB> GetCurrentProcess.restype = wintypes.HANDLE <TAB>  <TAB>  <TAB> SetPriorityClass = windll.kernel32.SetPriorityClass <TAB>  <TAB>  <TAB> SetPriorityClass.argtypes = (wintypes.HANDLE, wintypes.DWORD) <TAB>  <TAB>  <TAB> SetPriorityClass(GetCurrentProcess(), 0x00000040) <TAB>  <TAB> elif ""darwin"" in sys.platform: <TAB>  <TAB>  <TAB> os.nice(10) <MASK> os.nice(20) <TAB> except: <TAB>  <TAB> print(""Unable to set lowest process priority"")","elif ""linux"" in sys . platform :",174
"def stop(self) -> None: <TAB> """"""Stops the polling/webhook thread, the dispatcher and the job queue."""""" <TAB> self.job_queue.stop() <TAB> with self.__lock: <TAB>  <TAB> if self.running or self.dispatcher.has_running_threads: <TAB>  <TAB>  <TAB> self.logger.debug(""Stopping Updater and Dispatcher..."") <TAB>  <TAB>  <TAB> self.running = False <TAB>  <TAB>  <TAB> self._stop_httpd() <TAB>  <TAB>  <TAB> self._stop_dispatcher() <TAB>  <TAB>  <TAB> self._join_threads() <TAB>  <TAB>  <TAB> # Stop the Request instance only if it was created by the Updater <MASK> self._request.stop()",if self . _request :,159
"def is_connection_closed(self, connection): <TAB> is_closing = getattr(connection.transport, ""is_closing"", None) <TAB> if is_closing: <TAB>  <TAB> return is_closing() <TAB> else: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> sock = connection.sock <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB> return True <MASK> connection.close() <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> return False <TAB> return True",if is_socket_closed ( sock ) :,111
"def test_too_many_params(): <TAB> try: <TAB>  <TAB> substitute_params( <TAB>  <TAB>  <TAB> ""SELECT * FROM cust WHERE salesrep = %s and foo = %s"", (""bar"",) <TAB>  <TAB> ) <TAB>  <TAB> assert False, ""expected exception b/c too many params in sql"" <TAB> except ValueError as exc: <MASK> raise","if ""more placeholders in sql than params available"" not in str ( exc ) :",98
"def get_response_cls(request_cls): <TAB> """"""Extract a request's response class using the mapping found in the module defining the request's service"""""" <TAB> for req_cls in request_cls.mro(): <TAB>  <TAB> module = sys.modules[req_cls.__module__] <MASK> return module.action_mapping[(request_cls._action, request_cls._version)][1] <TAB>  <TAB> elif hasattr(module, ""response_mapping""): <TAB>  <TAB>  <TAB> return module.response_mapping[req_cls] <TAB> raise TypeError(""no response class!"")","if hasattr ( module , ""action_mapping"" ) :",137
"def ready(self, other_values): <TAB> value = self._get_dataset_like_object(other_values) <TAB> if value: <TAB>  <TAB> if value.state == value.states.OK: <TAB>  <TAB>  <TAB> return True <MASK> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> ""A data display parameter is in the error state: %s"" % (self.name) <TAB>  <TAB>  <TAB> ) <TAB> return False",elif value . state == value . states . ERROR :,108
"def concat_examples(batch, device=None): <TAB> # batch: img, mask, label, scale <TAB> if len(batch) == 0: <TAB>  <TAB> raise ValueError(""batch is empty"") <TAB> first_elem = batch[0] <TAB> result = [] <TAB> for i in six.moves.range(len(first_elem)): <TAB>  <TAB> array = _concat_arrays([example[i] for example in batch], None) <MASK> # img <TAB>  <TAB>  <TAB> result.append(to_device(device, array)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result.append(array) <TAB> return tuple(result)",if i == 0 :,146
"def download(downloads): <TAB> for download in downloads: <TAB>  <TAB> url = download[""url""] <TAB>  <TAB> dst = download[""dst""] <TAB>  <TAB> if not os.path.exists(dst): <MASK> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Downloads not permitted. Use --download option to permit"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> urllib.urlretrieve(url, dst) <TAB>  <TAB>  <TAB> if download.get(""unzip""): <TAB>  <TAB>  <TAB>  <TAB> path = download.get(""path"", os.path.dirname(dst)) <TAB>  <TAB>  <TAB>  <TAB> z = zipfile.ZipFile(dst) <TAB>  <TAB>  <TAB>  <TAB> z.extractall(path)",if not OPTS . download :,155
def process(self): <TAB> while True: <TAB>  <TAB> current_hash = self.generate_hash() <MASK> self.manager = self.manager_cls(**self.options) <TAB>  <TAB>  <TAB> self.manager.process() <TAB>  <TAB> self.last_hash = current_hash <TAB>  <TAB> time.sleep(0.2),if self . last_hash != current_hash :,89
"def __init__(self, iterable=None, languages=None, strict=True): <TAB> iterable = iterable or [] <TAB> languages = languages or LANGUAGES <TAB> items = [] <TAB> for i in iterable: <MASK> items.append(i) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if isinstance(i, tuple): <TAB>  <TAB>  <TAB> items.append(Language(i[0], languages=languages, strict=strict)) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> items.append(Language(i, languages=languages, strict=strict)) <TAB> super(language_set, self).__init__(items)","if isinstance ( i , Language ) :",140
"def run(self): <TAB> if self.check(): <TAB>  <TAB> print_success(""Target is vulnerable"") <TAB>  <TAB> print_status(""Invoking command loop..."") <TAB>  <TAB> print_status(""It is blind command injection - response is not available"") <MASK> shell(self, architecture=""mipsbe"", method=""wget"", location=""/tmp"") <TAB>  <TAB> elif self.arch == ""mipsle"": <TAB>  <TAB>  <TAB> shell(self, architecture=""mipsle"", method=""wget"", location=""/tmp"") <TAB> else: <TAB>  <TAB> print_error(""Target is not vulnerable"")","if self . arch == ""mipsbe"" :",143
"def _find_qos_policy_info(self, policy_name): <TAB> url = ""/ioclass"" <TAB> result = self.call(url, None, ""GET"") <TAB> msg = _(""Get QoS policy error."") <TAB> self._assert_rest_result(result, msg) <TAB> qos_info = {} <TAB> if ""data"" in result: <TAB>  <TAB> for item in result[""data""]: <MASK> qos_info[""ID""] = item[""ID""] <TAB>  <TAB>  <TAB>  <TAB> lun_list = json.loads(item[""LUNLIST""]) <TAB>  <TAB>  <TAB>  <TAB> qos_info[""LUNLIST""] = lun_list <TAB>  <TAB>  <TAB>  <TAB> qos_info[""RUNNINGSTATUS""] = item[""RUNNINGSTATUS""] <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return qos_info","if policy_name == item [ ""NAME"" ] :",195
"def test_re_escape(self): <TAB> alnum_chars = unicode(string.ascii_letters + string.digits) <TAB> p = u"""".join(unichr(i) for i in range(256)) <TAB> for c in p: <TAB>  <TAB> if c in alnum_chars: <TAB>  <TAB>  <TAB> self.assertEqual(re.escape(c), c) <MASK> self.assertEqual(re.escape(c), u""\\000"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertEqual(re.escape(c), u""\\"" + c) <TAB>  <TAB> self.assertMatch(re.escape(c), c) <TAB> self.assertMatch(re.escape(p), p)","elif c == u""\x00"" :",166
"def items(self, multi=False): <TAB> found = set() <TAB> for d in self.dicts: <TAB>  <TAB> for key, value in iteritems(d, multi): <TAB>  <TAB>  <TAB> if multi: <TAB>  <TAB>  <TAB>  <TAB> yield key, value <MASK> found.add(key) <TAB>  <TAB>  <TAB>  <TAB> yield key, value",elif key not in found :,85
"def unwep(self, key=None, warn=1): <TAB> if self.FCfield & 0x40 == 0: <TAB>  <TAB> if warn: <TAB>  <TAB>  <TAB> warning(""No WEP to remove"") <TAB>  <TAB> return <MASK> if key or conf.wepkey: <TAB>  <TAB>  <TAB> self.payload.decrypt(key) <TAB>  <TAB> if isinstance(self.payload.payload, NoPayload): <TAB>  <TAB>  <TAB> if warn: <TAB>  <TAB>  <TAB>  <TAB> warning(""Dot11 can't be decrypted. Check conf.wepkey."") <TAB>  <TAB>  <TAB> return <TAB> self.FCfield &= ~0x40 <TAB> self.payload = self.payload.payload","if isinstance ( self . payload . payload , NoPayload ) :",158
"def _split_corpus(path, shard_size): <TAB> """"""Yield a `list` containing `shard_size` line of `path`."""""" <TAB> with open(path, ""rb"") as f: <MASK> yield f.readlines() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB>  <TAB> shard = list(islice(f, shard_size)) <TAB>  <TAB>  <TAB>  <TAB> if not shard: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB>  <TAB> yield shard",if shard_size <= 0 :,116
"def test_read1_10(self): <TAB> with LZMAFile(BytesIO(COMPRESSED_XZ)) as f: <TAB>  <TAB> blocks = [] <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> result = f.read1(10) <MASK> break <TAB>  <TAB>  <TAB> blocks.append(result) <TAB>  <TAB> self.assertEqual(b"""".join(blocks), INPUT) <TAB>  <TAB> self.assertEqual(f.read1(), b"""")",if not result :,110
"def _filter_paths(self, finder): <TAB> # type: (Callable) -> Iterator <TAB> for path in self._get_paths(): <TAB>  <TAB> if path is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> python_versions = finder(path) <MASK> for python in python_versions: <TAB>  <TAB>  <TAB>  <TAB> if python is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield python",if python_versions is not None :,97
"def rec(item, rest_lists, current): <TAB> evaluation.check_stopped() <TAB> if item.is_atom() or not item.head.same(head): <MASK> return rec(rest_lists[0], rest_lists[1:], current + [item]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return Expression(f, *(current + [item])) <TAB> else: <TAB>  <TAB> leaves = [] <TAB>  <TAB> for leaf in item.leaves: <TAB>  <TAB>  <TAB> leaves.append(rec(leaf, rest_lists, current)) <TAB>  <TAB> return Expression(head, *leaves)",if rest_lists :,140
"def get_current_user(): <TAB> if authed(): <TAB>  <TAB> user = Users.query.filter_by(id=session[""id""]).first() <TAB>  <TAB> # Check if the session is still valid <TAB>  <TAB> session_hash = session.get(""hash"") <MASK> if session_hash != hmac(user.password): <TAB>  <TAB>  <TAB>  <TAB> logout_user() <TAB>  <TAB>  <TAB>  <TAB> if request.content_type == ""application/json"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> error = 401 <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> error = redirect(url_for(""auth.login"", next=request.full_path)) <TAB>  <TAB>  <TAB>  <TAB> abort(error) <TAB>  <TAB> return user <TAB> else: <TAB>  <TAB> return None",if session_hash :,173
"def __exit__(self, exc_type, exc_val, exc_tb): <TAB> if exc_val is not None: <TAB>  <TAB> exc_from_type = getattr(exc_val, EXC_EXT_NAME, const.EXC_TYPE.NOTSET) <MASK> setattr(exc_val, EXC_EXT_NAME, self.exc_from_type)",if self . force or exc_from_type == const . EXC_TYPE . NOTSET :,108
"def __check_state(self, opname): <TAB> if self._state is not TransactionState.STARTED: <MASK> raise apg_errors.InterfaceError( <TAB>  <TAB>  <TAB>  <TAB> ""cannot {}; the transaction is not yet started"".format(opname) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self.__check_state_base(opname)",if self . _state is TransactionState . NEW :,86
"def __remove_images(self, menu_item, songs): <TAB> win = WritingWindow(self.plugin_window, len(songs)) <TAB> win.show() <TAB> for song in songs: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> song.clear_images() <TAB>  <TAB>  <TAB> except AudioFileError: <TAB>  <TAB>  <TAB>  <TAB> util.print_exc() <TAB>  <TAB>  <TAB>  <TAB> WriteFailedError(win, song).run() <TAB>  <TAB> if win.step(): <TAB>  <TAB>  <TAB> break <TAB> win.destroy() <TAB> self.plugin_finish()",if song . has_images and song . can_change_images :,140
"def list_subtitles(self, video, languages): <TAB> subtitles = [] <TAB> with ThreadPoolExecutor(self.max_workers) as executor: <TAB>  <TAB> for provider, provider_subtitles in executor.map( <TAB>  <TAB>  <TAB> self.list_subtitles_provider, <TAB>  <TAB>  <TAB> self.providers, <TAB>  <TAB>  <TAB> itertools.repeat(video, len(self.providers)), <TAB>  <TAB>  <TAB> itertools.repeat(languages, len(self.providers)), <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> # discard provider that failed <MASK> logger.info(""Discarding provider %s"", provider) <TAB>  <TAB>  <TAB>  <TAB> self.discarded_providers.add(provider) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> # add subtitles <TAB>  <TAB>  <TAB> subtitles.extend(provider_subtitles) <TAB> return subtitles",if provider_subtitles is None :,195
"def _infer_shape(f): <TAB> num_lines, vector_dim = 0, None <TAB> for line in f: <TAB>  <TAB> if vector_dim is None: <TAB>  <TAB>  <TAB> row = line.rstrip().split(b"" "") <TAB>  <TAB>  <TAB> vector = row[1:] <TAB>  <TAB>  <TAB> # Assuming word, [vector] format <MASK> # The header present in some (w2v) formats contains two elements. <TAB>  <TAB>  <TAB>  <TAB> vector_dim = len(vector) <TAB>  <TAB>  <TAB>  <TAB> num_lines += 1  # First element read <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> num_lines += 1 <TAB> f.seek(0) <TAB> return num_lines, vector_dim",if len ( vector ) > 2 :,169
"def set_prompt(self, prompt=None): <TAB> if self.isatty: <MASK> self.prompt = ""%s > "" % (prompt) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.prompt = ""%s > "" % (self.session.ptr.__class__.__name__) <TAB>  <TAB> self.prompt = ""%s@%s : %s"" % ( <TAB>  <TAB>  <TAB> getpass.getuser(), <TAB>  <TAB>  <TAB> (socket.gethostname().split(""."")[0]), <TAB>  <TAB>  <TAB> self.prompt, <TAB>  <TAB> )",if prompt is not None :,124
"def comparison(cls, nodelist): <TAB> if len(nodelist) > 4: <TAB>  <TAB> raise SyntaxError(""Chained comparison not allowed in environment markers"") <TAB> comp = nodelist[2][1] <TAB> cop = comp[1] <TAB> if comp[0] == token.NAME: <TAB>  <TAB> if len(nodelist[2]) == 3: <MASK> cop = ""not in"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> cop = ""is not"" <TAB> try: <TAB>  <TAB> cop = cls.get_op(cop) <TAB> except KeyError: <TAB>  <TAB> raise SyntaxError(repr(cop) + "" operator not allowed in environment markers"") <TAB> return cop(cls.evaluate(nodelist[1]), cls.evaluate(nodelist[3]))","if cop == ""not"" :",182
"def run_source(self, source): <TAB> for i, statement in enumerate(self.lexer.get_statements(source)): <TAB>  <TAB> if i > 0: <TAB>  <TAB>  <TAB> self.write(u"""") <TAB>  <TAB> if statement.upper() == ""BEGIN"": <TAB>  <TAB>  <TAB> self.begin_transaction() <MASK> self.commit_transaction() <TAB>  <TAB> elif statement.upper() == ""ROLLBACK"": <TAB>  <TAB>  <TAB> self.rollback_transaction() <TAB>  <TAB> elif self.tx is None: <TAB>  <TAB>  <TAB> self.run_cypher(self.graph.run, statement, {}) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.run_cypher(self.tx.run, statement, {}, query_id=self.qid) <TAB>  <TAB>  <TAB> self.qid += 1","elif statement . upper ( ) == ""COMMIT"" :",189
"def check_if_machine_only(dirpath, name, is_machine_only_group): <TAB> if name in os.listdir(dirpath): <MASK> return True <TAB>  <TAB> yml_path = os.path.join(dirpath, name) <TAB>  <TAB> with io.open(yml_path, ""r"", encoding=""utf-8"") as yml_file: <TAB>  <TAB>  <TAB> yml_file_contents = yml_file.read() <TAB>  <TAB>  <TAB> if ""platform: machine"" in yml_file_contents: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if is_machine_only_group :,138
"def render(self): <TAB> translate(width / 4, height / 2) <TAB> self.steps += 3 <TAB> if self.steps > len(self.production): <TAB>  <TAB> self.steps = len(self.production) <TAB> for i in range(self.steps): <TAB>  <TAB> step = self.production[i] <TAB>  <TAB> if step == ""F"": <TAB>  <TAB>  <TAB> noFill() <TAB>  <TAB>  <TAB> stroke(255) <TAB>  <TAB>  <TAB> line(0, 0, 0, -self.drawLength) <TAB>  <TAB>  <TAB> translate(0, -self.drawLength) <MASK> rotate(self.theta) <TAB>  <TAB> elif step == ""-"": <TAB>  <TAB>  <TAB> rotate(-self.theta) <TAB>  <TAB> elif step == ""["": <TAB>  <TAB>  <TAB> pushMatrix() <TAB>  <TAB> elif step == ""]"": <TAB>  <TAB>  <TAB> popMatrix()","elif step == ""+"" :",191
"def _convert_states(self, root): <TAB> key = ""states"" if getattr(self, ""scoped"", self) == self else ""children"" <TAB> root[key] = [] <TAB> for state_name, state in self.states.items(): <TAB>  <TAB> s_def = _convert(state, self.state_attributes, self.skip_references) <MASK> s_def[""name""] = state_name.name <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> s_def[""name""] = state_name <TAB>  <TAB> if getattr(state, ""states"", []): <TAB>  <TAB>  <TAB> with self(state_name): <TAB>  <TAB>  <TAB>  <TAB> self._convert_states_and_transitions(s_def) <TAB>  <TAB> root[key].append(s_def)","if isinstance ( state_name , Enum ) :",183
"def _apply_data(self, extends_seen): <TAB> for item in self.data: <TAB>  <TAB> item_type, name = self._validated_item_type(item) <TAB>  <TAB> if item_type == ""model"": <TAB>  <TAB>  <TAB> self._apply_model(name, item, extends_seen) <MASK> self._apply_package(name, item)","elif item_type == ""package"" :",95
"def start_and_len(file, start, count): <TAB> f = urllib.request.urlopen(""http://archive.org/download/bpl_marc/"" + file) <TAB> pos = 0 <TAB> num = 0 <TAB> start_pos = None <TAB> while num < start + count: <TAB>  <TAB> data = f.read(5) <MASK> break <TAB>  <TAB> rec_len = int(data) <TAB>  <TAB> f.read(rec_len - 5) <TAB>  <TAB> pos += rec_len <TAB>  <TAB> num += 1 <TAB>  <TAB> if num == start: <TAB>  <TAB>  <TAB> start_pos = pos <TAB> f.close() <TAB> return (start_pos, pos - start_pos)","if data == """" :",165
"def add(our_key, wp_key, is_int=False, ignore_zero=False, is_float=False): <TAB> if wp_key in image_meta: <TAB>  <TAB> value = image_meta[wp_key] <TAB>  <TAB> if is_int: <TAB>  <TAB>  <TAB> value = int(value) <TAB>  <TAB>  <TAB> if ignore_zero and value == 0: <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> elif is_float: <TAB>  <TAB>  <TAB> value = float(value) <TAB>  <TAB>  <TAB> if ignore_zero and value == 0: <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = value.decode(""utf-8"")  # assume UTF-8 <MASK> # skip empty values <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> dst_meta[our_key] = value","if value == """" :",185
"def run_and_print(self, args, **kwargs): <TAB> try: <TAB>  <TAB> instance = self.run(args, **kwargs) <MASK> raise Exception(""Server did not create instance."") <TAB>  <TAB> self.print_output( <TAB>  <TAB>  <TAB> instance, <TAB>  <TAB>  <TAB> table.PropertyValueTable, <TAB>  <TAB>  <TAB> attributes=[""all""], <TAB>  <TAB>  <TAB> json=args.json, <TAB>  <TAB>  <TAB> yaml=args.yaml, <TAB>  <TAB> ) <TAB> except Exception as e: <TAB>  <TAB> message = str(e) <TAB>  <TAB> print(""ERROR: %s"" % (message)) <TAB>  <TAB> raise OperationFailureException(message)",if not instance :,150
"def _partial_bn(self): <TAB> logger = get_root_logger() <TAB> logger.info(""Freezing BatchNorm2D except the first one."") <TAB> count_bn = 0 <TAB> for m in self.modules(): <TAB>  <TAB> if isinstance(m, nn.BatchNorm2d): <TAB>  <TAB>  <TAB> count_bn += 1 <MASK> m.eval() <TAB>  <TAB>  <TAB>  <TAB> # shutdown update in frozen mode <TAB>  <TAB>  <TAB>  <TAB> m.weight.requires_grad = False <TAB>  <TAB>  <TAB>  <TAB> m.bias.requires_grad = False",if count_bn >= 2 :,133
"def replace(self, edit: sublime.Edit) -> None: <TAB> """"""Replace the old code with what autopep8 gave to us"""""" <TAB> view = get_window_view(self.data[""vid""]) <TAB> if self.code != self.data.get(""buffer""): <TAB>  <TAB> region = sublime.Region(0, view.size()) <TAB>  <TAB> view.replace(edit, region, self.data.get(""buffer"")) <MASK> sublime.set_timeout(lambda: view.run_command(""save""), 0) <TAB> self.code = None <TAB> self.data = None","if get_settings ( view , ""auto_formatting"" ) :",153
"def _check_num_nodes(self): <TAB> if self.num_nodes < 1: <TAB>  <TAB> raise ValueError(""Must provision at least one node."") <TAB> elif self.num_nodes < 3: <TAB>  <TAB> linodeutils.log_warning( <TAB>  <TAB>  <TAB> ""A Deis cluster must have 3 or more nodes, only continue if you adding to a current cluster."" <TAB>  <TAB> ) <TAB>  <TAB> linodeutils.log_warning(""Continue? (y/n)"") <TAB>  <TAB> accept = None <TAB>  <TAB> while True: <MASK> return <TAB>  <TAB>  <TAB> elif accept == ""n"": <TAB>  <TAB>  <TAB>  <TAB> raise StandardError(""User canceled provisioning"") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> accept = self._get_user_input(""--> "").strip().lower()","if accept == ""y"" :",182
"def __init__(self): <TAB> self.shutdown = False <TAB> self.queue = OrderedSetQueue() <TAB> self.version = Rating.VERSION <TAB> self.ratings = {} <TAB> self.nzo_indexer_map = {} <TAB> try: <TAB>  <TAB> rating_data = sabnzbd.load_admin(RATING_FILE_NAME) <MASK> self.version, self.ratings, self.nzo_indexer_map = rating_data <TAB> except: <TAB>  <TAB> logging.info(""Corrupt %s file, discarding"", RATING_FILE_NAME) <TAB>  <TAB> logging.info(""Traceback: "", exc_info=True) <TAB> super().__init__()",if rating_data :,160
"def kill_modules(self, *modules): <TAB> """"""[UNIT]... -- kill these units"""""" <TAB> found_all = True <TAB> units = [] <TAB> for module in modules: <TAB>  <TAB> matched = self.match_units([module]) <TAB>  <TAB> if not matched: <TAB>  <TAB>  <TAB> logg.error(""no such service '%s'"", module) <TAB>  <TAB>  <TAB> found_all = False <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for unit in matched: <MASK> units += [unit] <TAB> return self.kill_units(units) and found_all",if unit not in units :,136
"def run(self): <TAB> if ""aspect"" in self.options: <TAB>  <TAB> aspect = self.options.get(""aspect"") <TAB>  <TAB> m = re.match(""(\d+):(\d+)"", aspect) <MASK> raise ValueError(""invalid aspect ratio %r"" % aspect) <TAB>  <TAB> aspect = tuple(int(x) for x in m.groups()) <TAB> else: <TAB>  <TAB> aspect = None <TAB> width = get_size(self.options, ""width"") <TAB> height = get_size(self.options, ""height"") <TAB> return [youtube(id=self.arguments[0], aspect=aspect, width=width, height=height)]",if m is None :,155
"def _report_keyboardinterrupt(self): <TAB> excrepr = self._keyboardinterrupt_memo <TAB> msg = excrepr.reprcrash.message <TAB> self.write_sep(""!"", msg) <TAB> if ""KeyboardInterrupt"" in msg: <MASK> excrepr.toterminal(self._tw) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._tw.line( <TAB>  <TAB>  <TAB>  <TAB> ""to show a full traceback on KeyboardInterrupt use --fulltrace"", <TAB>  <TAB>  <TAB>  <TAB> yellow=True, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> excrepr.reprcrash.toterminal(self._tw)",if self . config . option . fulltrace :,149
"def decorated_function(*args, **kwargs): <TAB> try: <TAB>  <TAB> return func(*args, **kwargs) <TAB> except Exception as e: <TAB>  <TAB> if isinstance(e, LibcloudError): <TAB>  <TAB>  <TAB> raise e <TAB>  <TAB> if len(args) >= 1: <TAB>  <TAB>  <TAB> driver = args[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> driver = None <TAB>  <TAB> fault = getattr(e, ""fault"", None) <MASK> message = fault.string <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> message = str(e) <TAB>  <TAB> raise LibcloudError(value=message, driver=driver)","if fault and getattr ( fault , ""string"" , None ) :",155
"def list_or_empty(content, contype=None): <TAB> assert isinstance(content, list), ""content is not list: {}"".format(content) <TAB> if content: <TAB>  <TAB> return contype(content[0]) if contype else content[0] <TAB> else: <TAB>  <TAB> if contype: <MASK> return 0 <TAB>  <TAB>  <TAB> elif contype == str: <TAB>  <TAB>  <TAB>  <TAB> return """" <TAB>  <TAB>  <TAB> elif contype == list: <TAB>  <TAB>  <TAB>  <TAB> return [] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise Exception(""only can deal int str list"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return """"",if contype == int :,153
"def havemarks(*args, **kwargs): <TAB> origin = kwargs.get(""origin"", """") <TAB> for i, v in enumerate(args): <MASK> raise AssertionError( <TAB>  <TAB>  <TAB>  <TAB> ""Value #{0}/{1} ({2!r}) has no attribute `mark`"".format(origin, i, v) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if isinstance(v, dict): <TAB>  <TAB>  <TAB> for key, val in v.items(): <TAB>  <TAB>  <TAB>  <TAB> havemarks( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> key, val, origin=(origin + ""["" + unicode(i) + ""]/"" + unicode(key)) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> elif isinstance(v, list): <TAB>  <TAB>  <TAB> havemarks(*v, origin=(origin + ""["" + unicode(i) + ""]""))","if not hasattr ( v , ""mark"" ) :",194
"def _wrapper(*args, **kwargs): <TAB> try: <TAB>  <TAB> return fn(*args, **kwargs) <TAB> except Exception as e:  # pylint: disable=broad-except <TAB>  <TAB> logging.exception(""Error raised by `%s`:"", fn.__name__) <MASK> raise <TAB>  <TAB> raise status_lib.StatusNotOkError( <TAB>  <TAB>  <TAB> code=status_lib.Code.UNKNOWN, message=f""`{fn.__name__}` error: {str(e)}"" <TAB>  <TAB> )","if isinstance ( e , status_lib . StatusNotOkError ) :",129
"def _wrapper(session, *args, **kwargs): <TAB> ret = None <TAB> try: <TAB>  <TAB> ret = func(session, *args, **kwargs) <MASK> # If the given function has any update to records, <TAB>  <TAB>  <TAB> # commits them. <TAB>  <TAB>  <TAB> session.commit() <TAB> except Exception as e: <TAB>  <TAB> # If any exception raised, rollbacks the transaction. <TAB>  <TAB> LOG.error(""Error in %s: %s"", func.__name__, e) <TAB>  <TAB> if session.dirty: <TAB>  <TAB>  <TAB> LOG.error(""Do rolling back %s table"", session.dirty[0].__tablename__) <TAB>  <TAB>  <TAB> session.rollback() <TAB> return ret",if session . dirty :,161
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> length = d.getVarInt32() <TAB>  <TAB>  <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB>  <TAB>  <TAB> d.skip(length) <TAB>  <TAB>  <TAB> self.add_status().TryMerge(tmp) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 10 :,137
"def get_cvs_command(self, op=None): <TAB> cmd = [self.cvs_binary] <TAB> if self.cvs_quiet: <TAB>  <TAB> cmd.append(""-q"") <TAB> if self.cvs_compression: <TAB>  <TAB> cmd.append(""-z%i"" % self.cvs_compression_value) <TAB> if self.cvs_ignore_cvsrc: <TAB>  <TAB> cmd.append(""-f"") <TAB> if op: <TAB>  <TAB> cmd.append(op) <TAB>  <TAB> if op == ""update"": <MASK> cmd.append(""-d"") <TAB>  <TAB>  <TAB> if self.cvs_prune_empty: <TAB>  <TAB>  <TAB>  <TAB> cmd.append(""-P"") <TAB> return cmd",if self . cvs_create_missing :,176
"def replace_nan_with_flag(pdf, flag=-1): <TAB> new_df = pd.DataFrame() <TAB> for c in pdf.columns: <MASK> new_df[c] = pdf[c].map(lambda l: [flag if np.isnan(x) else x for x in l]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_df[c] = pdf[c] <TAB> return new_df","if isinstance ( pdf [ c ] . iloc [ 0 ] , list ) :",113
"def __del__(self): <TAB> if self._state == futures._PENDING and self._log_destroy_pending: <TAB>  <TAB> context = { <TAB>  <TAB>  <TAB> ""task"": self, <TAB>  <TAB>  <TAB> ""message"": ""Task was destroyed but it is pending!"", <TAB>  <TAB> } <MASK> context[""source_traceback""] = self._source_traceback <TAB>  <TAB> self._loop.call_exception_handler(context) <TAB> futures.Future.__del__(self)",if self . _source_traceback :,112
"def process_locales(series): <TAB> """"""Convert locale codes to pretty names, skip any unknown locales."""""" <TAB> languages = {key.lower(): value[""native""] for key, value in ALL_LANGUAGES.items()} <TAB> for row in series: <TAB>  <TAB> if ""data"" in row: <TAB>  <TAB>  <TAB> new = {} <TAB>  <TAB>  <TAB> for key, count in row[""data""].items(): <MASK> k = ""%s (%s)"" % (languages[key.lower()], key) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> new[k] = count <TAB>  <TAB>  <TAB> row[""data""] = new <TAB>  <TAB> yield row",if key and key . lower ( ) in languages :,152
"def getBuildsets(self, complete=None, resultSpec=None): <TAB> rv = [] <TAB> for bs in itervalues(self.buildsets): <TAB>  <TAB> if complete is not None: <MASK> rv.append(self._row2dict(bs)) <TAB>  <TAB>  <TAB> elif not complete and not bs[""complete""]: <TAB>  <TAB>  <TAB>  <TAB> rv.append(self._row2dict(bs)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> rv.append(self._row2dict(bs)) <TAB> if resultSpec is not None: <TAB>  <TAB> rv = self.applyResultSpec(rv, resultSpec) <TAB> return defer.succeed(rv)","if complete and bs [ ""complete"" ] :",157
"def parse_git_stats(status): <TAB> stats = RepoStats() <TAB> for statusline in status[1:]: <TAB>  <TAB> code = statusline[:2] <TAB>  <TAB> if code == ""??"": <TAB>  <TAB>  <TAB> stats.new += 1 <TAB>  <TAB> elif code in (""DD"", ""AU"", ""UD"", ""UA"", ""DU"", ""AA"", ""UU""): <TAB>  <TAB>  <TAB> stats.conflicted += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if code[1] != "" "": <TAB>  <TAB>  <TAB>  <TAB> stats.changed += 1 <MASK> stats.staged += 1 <TAB> return stats","if code [ 0 ] != "" "" :",148
"def test_osrandom_engine_implementation(self): <TAB> name = backend.osrandom_engine_implementation() <TAB> assert name in [""/dev/urandom"", ""CryptGenRandom"", ""getentropy"", ""getrandom""] <TAB> if sys.platform.startswith(""linux""): <TAB>  <TAB> assert name in [""getrandom"", ""/dev/urandom""] <TAB> if sys.platform == ""darwin"": <TAB>  <TAB> # macOS 10.12+ supports getentropy <MASK> assert name == ""getentropy"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert name == ""/dev/urandom"" <TAB> if ""bsd"" in sys.platform: <TAB>  <TAB> assert name in [""getentropy"", ""/dev/urandom""] <TAB> if sys.platform == ""win32"": <TAB>  <TAB> assert name == ""CryptGenRandom""","if parse_version ( os . uname ( ) [ 2 ] ) >= parse_version ( ""16.0"" ) :",197
"def _remap_device(self, short_name): <TAB> # LP: #611137 <TAB> # the metadata service may believe that devices are named 'sda' <TAB> # when the kernel named them 'vda' or 'xvda' <TAB> # we want to return the correct value for what will actually <TAB> # exist in this instance <TAB> mappings = {""sd"": (""vd"", ""xvd"", ""vtb"")} <TAB> for (nfrom, tlist) in mappings.items(): <MASK> continue <TAB>  <TAB> for nto in tlist: <TAB>  <TAB>  <TAB> cand = ""/dev/%s%s"" % (nto, short_name[len(nfrom) :]) <TAB>  <TAB>  <TAB> if os.path.exists(cand): <TAB>  <TAB>  <TAB>  <TAB> return cand <TAB> return None",if not short_name . startswith ( nfrom ) :,194
"def add_ones(query_points, x, add_one): <TAB> if add_one: <TAB>  <TAB> ones = ( <TAB>  <TAB>  <TAB> torch.ones(query_points.shape[0], dtype=torch.float) <TAB>  <TAB>  <TAB> .unsqueeze(-1) <TAB>  <TAB>  <TAB> .to(query_points.device) <TAB>  <TAB> ) <MASK> x = torch.cat([ones.to(x.dtype), x], dim=-1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> x = ones <TAB> return x",if x is not None :,126
"def _launch_and_get_progress_html(self, ssh_tunnel=True): <TAB> job = MRTwoStepJob([""-r"", ""emr""]) <TAB> job.sandbox() <TAB> with job.make_runner() as runner: <TAB>  <TAB> self.launch(runner) <MASK> runner._ssh_tunnel_url = self.MOCK_TUNNEL_URL <TAB>  <TAB> self.log.debug.reset_mock() <TAB>  <TAB> return runner._progress_html_from_tunnel()",if ssh_tunnel :,127
"def memorize_finish(self): <TAB> tmp = self._tmp <TAB> constraints = self._tmp[""constraints""] <TAB> # Guards against invalid subsequent memorize_chunk() calls. <TAB> del self._tmp <TAB> if constraints is not None: <MASK> constraints = np.atleast_2d(tmp[""sum""] / tmp[""count""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> constraints = np.atleast_2d(constraints) <TAB>  <TAB>  <TAB> if constraints.ndim != 2: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""Constraints must be 2-d array or "" ""1-d vector."") <TAB> self._constraints = constraints","if safe_string_eq ( constraints , ""center"" ) :",155
"def extract_fb_episodes(datafile): <TAB> opt = {""datatype"": ""train"", ""datafile"": datafile} <TAB> episode = None <TAB> for parley in FbDeprecatedDialogTeacher(opt).setup_data(datafile): <TAB>  <TAB> fields, is_new_episode = parley <MASK> if episode is not None: <TAB>  <TAB>  <TAB>  <TAB> yield episode <TAB>  <TAB>  <TAB> episode = [] <TAB>  <TAB> raw_parley = Parley(*fields) <TAB>  <TAB> parley = sanitize_parley(raw_parley) <TAB>  <TAB> episode.append(parley) <TAB> yield episode",if is_new_episode :,144
"def on_move_cursor(self, view, step_size, count, extend_selection): <TAB> # If you try to move the cursor out of the sourceview <TAB> # release the cursor to the parent textview <TAB> buffer = view.get_buffer() <TAB> iter = buffer.get_iter_at_mark(buffer.get_insert()) <TAB> if (iter.is_start() or iter.is_end()) and not extend_selection: <TAB>  <TAB> if iter.is_start() and count < 0: <TAB>  <TAB>  <TAB> self.release_cursor(POSITION_BEGIN) <TAB>  <TAB>  <TAB> return None <MASK> self.release_cursor(POSITION_END) <TAB>  <TAB>  <TAB> return None <TAB> return None  # let parent handle this signal",elif iter . is_end ( ) and count > 0 :,182
"def restoreGeom(widget, key, offset=None, adjustSize=False): <TAB> key += ""Geom"" <TAB> if aqt.mw.pm.profile.get(key): <TAB>  <TAB> widget.restoreGeometry(aqt.mw.pm.profile[key]) <MASK> if qtminor > 6: <TAB>  <TAB>  <TAB>  <TAB> # bug in osx toolkit <TAB>  <TAB>  <TAB>  <TAB> s = widget.size() <TAB>  <TAB>  <TAB>  <TAB> widget.resize(s.width(), s.height() + offset * 2) <TAB> else: <TAB>  <TAB> if adjustSize: <TAB>  <TAB>  <TAB> widget.adjustSize()",if isMac and offset :,149
"def _render_mono(self, buf, pixel_data): <TAB> i = 0 <TAB> nibble_order = self._nibble_order <TAB> for pix in pixel_data: <MASK> if i % 2 == nibble_order: <TAB>  <TAB>  <TAB>  <TAB> buf[i // 2] |= 0xF0 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> buf[i // 2] |= 0x0F <TAB>  <TAB> i += 1",if pix > 0 :,110
"def _context_call(self, name, offset): <TAB> if self.handle_ignores: <TAB>  <TAB> if not hasattr(self, ""starts""): <TAB>  <TAB>  <TAB> self._init_ignores() <TAB>  <TAB> start = bisect.bisect(self.starts, offset) <MASK> return getattr(self.dumb_finder, name)(offset) <TAB> return getattr(self.code_finder, name)(offset)",if start > 0 and offset < self . ends [ start - 1 ] :,110
"def _list_event(self, db, key, command): <TAB> if command.write: <TAB>  <TAB> self._modified_key(key) <TAB> # the key is blocking clients <TAB> if key in db._blocking_keys: <MASK> value = db._data[key] <TAB>  <TAB> elif key in self._expires: <TAB>  <TAB>  <TAB> value = db._expires[key] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = None <TAB>  <TAB> for client in db._blocking_keys.pop(key): <TAB>  <TAB>  <TAB> client.blocked.unblock(client, key, value)",if key in db . _data :,141
"def test_len(self): <TAB> eq = self.assertEqual <TAB> eq(base64mime.header_length(""hello""), len(base64mime.body_encode(b""hello"", eol=""""))) <TAB> for size in range(15): <TAB>  <TAB> if size == 0: <TAB>  <TAB>  <TAB> bsize = 0 <TAB>  <TAB> elif size <= 3: <TAB>  <TAB>  <TAB> bsize = 4 <MASK> bsize = 8 <TAB>  <TAB> elif size <= 9: <TAB>  <TAB>  <TAB> bsize = 12 <TAB>  <TAB> elif size <= 12: <TAB>  <TAB>  <TAB> bsize = 16 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> bsize = 20 <TAB>  <TAB> eq(base64mime.header_length(""x"" * size), bsize)",elif size <= 6 :,162
"def from_str(cls, value): <TAB> value = re.sub(r""[\s_]"", """", value) <TAB> if value: <TAB>  <TAB> if value[0] == ""-"": <TAB>  <TAB>  <TAB> raise ValueError(""invalid negative input for bits(): '{}'"".format(value)) <MASK> length = len(value) - 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> length = len(value) <TAB>  <TAB> return cls.from_int(int(value, 2), length) <TAB> else: <TAB>  <TAB> return cls.from_int(0)","elif value [ 0 ] == ""+"" :",130
"def _get_super_node_blocks(self, start_node: Block) -> List[Block]: <TAB> lst: List[Block] = [start_node] <TAB> while True: <TAB>  <TAB> b = lst[-1] <TAB>  <TAB> successors = list(self.func_graph.successors(b)) <TAB>  <TAB> if len(successors) == 0: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if len(successors) == 1: <TAB>  <TAB>  <TAB> succ = successors[0] <TAB>  <TAB>  <TAB> # check its predecessors <TAB>  <TAB>  <TAB> succ_predecessors = list(self.func_graph.predecessors(succ)) <MASK> lst.append(succ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # too many successors <TAB>  <TAB>  <TAB> break <TAB> return lst",if len ( succ_predecessors ) == 1 :,193
"def parseKindleString(keystuff): <TAB> pids = [] <TAB> serials = [] <TAB> ar = keystuff.split("","") <TAB> for keystring in ar: <TAB>  <TAB> keystring = str(keystring).strip().replace("" "", """") <TAB>  <TAB> if len(keystring) == 10 or len(keystring) == 8 and keystring not in pids: <TAB>  <TAB>  <TAB> pids.append(keystring) <MASK> serials.append(keystring) <TAB> return (pids, serials)","elif len ( keystring ) == 16 and keystring [ 0 ] == ""B"" and keystring not in serials :",124
"def handle_close(self): <TAB> # With the new IO loop, handle_close() gets called in case <TAB> # the fd appears in the list of exceptional fds. <TAB> # This means connect() failed. <TAB> if not self._closed: <TAB>  <TAB> self.close() <MASK> msg = ""Can't connect to specified address."" <TAB>  <TAB>  <TAB> self.cmd_channel.respond(""425 "" + msg) <TAB>  <TAB>  <TAB> self.cmd_channel.log_cmd(self._cmd, self._normalized_addr, 425, msg)",if self . cmd_channel . connected :,138
"def _search_in_locators(self, browser, locators, content): <TAB> for locator in locators: <TAB>  <TAB> elements = self._element_finder.find(browser, locator) <TAB>  <TAB> for element in elements: <MASK> return element <TAB>  <TAB>  <TAB> element_text = element.text <TAB>  <TAB>  <TAB> if element_text and content in element_text: <TAB>  <TAB>  <TAB>  <TAB> return element <TAB> return None",if content is None :,105
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.set_destination_url(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 18: <TAB>  <TAB>  <TAB> self.set_auth_domain(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 10 :,124
"def get_hash(self): <TAB> directive = self.effective_directive <TAB> uri = self._normalized_blocked_uri <TAB> # We want to distinguish between the different script-src <TAB> # violations that happen in <TAB> if _is_unsafe_script(directive, uri) and self.violated_directive: <MASK> uri = ""'unsafe-eval'"" <TAB>  <TAB> elif ""'unsafe-eval'"" in self.violated_directive: <TAB>  <TAB>  <TAB> uri = ""'unsafe-inline"" <TAB> return [directive, uri]","if ""'unsafe-inline"" in self . violated_directive :",136
"def plot_koalas(data, kind, **kwargs): <TAB> if kind not in _koalas_all_kinds: <TAB>  <TAB> raise ValueError(""{} is not a valid plot kind"".format(kind)) <TAB> from databricks.koalas import DataFrame, Series <TAB> if isinstance(data, Series): <TAB>  <TAB> if kind not in _series_kinds: <TAB>  <TAB>  <TAB> return unsupported_function(class_name=""pd.Series"", method_name=kind)() <TAB>  <TAB> return plot_series(data=data, kind=kind, **kwargs) <TAB> elif isinstance(data, DataFrame): <MASK> return unsupported_function(class_name=""pd.DataFrame"", method_name=kind)() <TAB>  <TAB> return plot_frame(data=data, kind=kind, **kwargs)",if kind not in _dataframe_kinds :,188
"def lineify_fileobjs(ifo, ofo, strip=False): <TAB> from pyutil.strutil import pop_trailing_newlines, split_on_newlines <TAB> for l in ifo: <TAB>  <TAB> for sl in split_on_newlines(pop_trailing_newlines(l)): <MASK> sl = sl.strip() <TAB>  <TAB>  <TAB> ofo.write(pop_trailing_newlines(sl) + ""\n"")",if strip :,105
"def _lookup_annotation(self, _name: str) -> str: <TAB> if self._config.napoleon_attr_annotations: <TAB>  <TAB> if self._what in (""module"", ""class"", ""exception"") and self._obj: <TAB>  <TAB>  <TAB> # cache the class annotations <TAB>  <TAB>  <TAB> if not hasattr(self, ""_annotations""): <TAB>  <TAB>  <TAB>  <TAB> localns = getattr(self._config, ""autodoc_type_aliases"", {}) <TAB>  <TAB>  <TAB>  <TAB> localns.update(getattr(self._config, ""napoleon_type_aliases"", {}) or {}) <TAB>  <TAB>  <TAB>  <TAB> self._annotations = get_type_hints(self._obj, None, localns) <MASK> return stringify_annotation(self._annotations[_name]) <TAB> # No annotation found <TAB> return """"",if _name in self . _annotations :,189
"def visit_Import(self, node: ast.Import) -> None: <TAB> """"""Handles Import node and record it to definition orders."""""" <TAB> for name in node.names: <TAB>  <TAB> self.add_entry(name.asname or name.name) <TAB>  <TAB> if name.name == ""typing"": <TAB>  <TAB>  <TAB> self.typing = name.asname or name.name <MASK> self.typing_final = name.asname or name.name <TAB>  <TAB> elif name.name == ""typing.overload"": <TAB>  <TAB>  <TAB> self.typing_overload = name.asname or name.name","elif name . name == ""typing.final"" :",143
"def _install_groups(self, group_specs, excludes, skipped, strict=True): <TAB> for group_spec in group_specs: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> types = self.conf.group_package_types <MASK> split = group_spec.split(""/"") <TAB>  <TAB>  <TAB>  <TAB> group_spec = split[0] <TAB>  <TAB>  <TAB>  <TAB> types = split[1].split("","") <TAB>  <TAB>  <TAB> self.env_group_install( <TAB>  <TAB>  <TAB>  <TAB> [group_spec], types, strict, excludes.pkg_specs, excludes.grp_specs <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> except dnf.exceptions.Error: <TAB>  <TAB>  <TAB> skipped.append(""@"" + group_spec)","if ""/"" in group_spec :",168
"def _force_string(owner, tag): <TAB> if tag.string: <TAB>  <TAB> return tag.string <TAB> else: <TAB>  <TAB> out = """" <TAB>  <TAB> for i in tag: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> '""%s"" tags must contain only strings: ' <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""got %r: %r"" % (owner.name, tag.name, tag) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> out += _force_string(owner, i) <TAB>  <TAB> return out","if not ( i . string or i . name in [ ""a"" , ""br"" ] ) :",141
"def close_log_file_handler(self, tempdir, filename): <TAB> logger = logging.getLogger(""botocore"") <TAB> handlers = logger.handlers <TAB> for handler in handlers[:]: <MASK> handler.stream.close() <TAB>  <TAB>  <TAB> logger.removeHandler(handler) <TAB>  <TAB>  <TAB> os.remove(filename) <TAB>  <TAB>  <TAB> # logging has an atexit handler that will try to flush/close <TAB>  <TAB>  <TAB> # the file.  By setting this flag to False, we'll prevent it <TAB>  <TAB>  <TAB> # from raising an exception, which is fine because we're <TAB>  <TAB>  <TAB> # handling the closing of the file ourself. <TAB>  <TAB>  <TAB> logging.raiseExceptions = False <TAB> shutil.rmtree(tempdir)","if hasattr ( handler , ""stream"" ) and handler . stream . name == filename :",176
"def package_and_class_tags(self, cov): <TAB> """"""Run an XML report on `cov`, and get the package and class tags."""""" <TAB> cov.xml_report() <TAB> dom = ElementTree.parse(""coverage.xml"") <TAB> for node in dom.iter(): <MASK> yield ( <TAB>  <TAB>  <TAB>  <TAB> node.tag, <TAB>  <TAB>  <TAB>  <TAB> {a: v for a, v in node.items() if a in (""name"", ""filename"")}, <TAB>  <TAB>  <TAB> )","if node . tag in ( ""package"" , ""class"" ) :",123
"def substitute(values): <TAB> if isinstance(values, str): <TAB>  <TAB> return libdnf.conf.ConfigParser.substitute(values, conf.substitutions) <TAB> elif isinstance(values, list) or isinstance(values, tuple): <TAB>  <TAB> substituted = [] <TAB>  <TAB> for value in values: <MASK> substituted.append( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> libdnf.conf.ConfigParser.substitute(value, conf.substitutions) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> if substituted: <TAB>  <TAB>  <TAB>  <TAB> return substituted <TAB> return values","if isinstance ( value , str ) :",131
"def convert_idx(text: str, tokens: List[str]) -> List[Tuple[int, int]]: <TAB> current = 0 <TAB> spans = [] <TAB> for token in tokens: <TAB>  <TAB> current = text.find(token, current) <MASK> logger.error(""Token {} cannot be found"".format(token)) <TAB>  <TAB>  <TAB> raise Exception() <TAB>  <TAB> spans.append((current, current + len(token))) <TAB>  <TAB> current += len(token) <TAB> return spans",if current < 0 :,116
"def create_release_urls_from_list(urls, name=None): <TAB> # type: (Union[TReleasesList, List[ReleaseUrl]], Optional[str]) -> List[ReleaseUrl] <TAB> url_list = [] <TAB> for release_dict in urls: <TAB>  <TAB> if isinstance(release_dict, ReleaseUrl): <MASK> release_dict = attr.evolve(release_dict, name=name) <TAB>  <TAB>  <TAB> url_list.append(release_dict) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> url_list.append(ReleaseUrl.create(release_dict, name=name)) <TAB> return url_list",if name and not release_dict . name :,158
"def main(self): <TAB> self.model.clear() <TAB> active_handle = self.get_active(""Media"") <TAB> if active_handle: <TAB>  <TAB> active = self.dbstate.db.get_media_from_handle(active_handle) <MASK> self.display_attributes(active) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.set_has_data(False) <TAB> else: <TAB>  <TAB> self.set_has_data(False)",if active :,113
"def read(self): <TAB> """"""read a single line"""""" <TAB> rxb = six.b("""") <TAB> while True: <TAB>  <TAB> data = self._ssh.recv(self.RECVSZ) <MASK> raise ValueError(""Unable to detect device prompt"") <TAB>  <TAB> elif PY6.NEW_LINE in data: <TAB>  <TAB>  <TAB> rxb += data.split(PY6.NEW_LINE)[0] <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> rxb += data <TAB> return rxb",if data is None or len ( data ) <= 0 :,129
"def find_events(self, name=None, type=None): <TAB> self.fetch_events() <TAB> results = [] <TAB> for event in self.events_local: <MASK> continue <TAB>  <TAB> if type is not None and event[""type""] != type: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> results.append(event) <TAB> return results","if name is not None and event [ ""name"" ] != name :",95
"def _parse_string(self) -> str: <TAB> if self.current_char != '""': <TAB>  <TAB> return None <TAB> startPos = self.pos <TAB> self.pos += 1 <TAB> escape = False <TAB> while True: <MASK> self.fail(""Unexpected end during inside string."") <TAB>  <TAB> elif self.current_char == '""' and not escape: <TAB>  <TAB>  <TAB> self.pos += 1 <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif self.current_char == ""\\"": <TAB>  <TAB>  <TAB> escape = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> escape = False <TAB>  <TAB> self.pos += 1 <TAB> return self.definition[startPos : self.pos]",if self . eof :,155
"def check_unique(data): <TAB> counter = Counter([p[""name""] for p in data.get(""policies"", [])]) <TAB> for k, v in list(counter.items()): <MASK> counter.pop(k) <TAB> if counter: <TAB>  <TAB> return [ <TAB>  <TAB>  <TAB> ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Only one policy with a given name allowed, duplicates: {}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> counter <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB> list(counter.keys())[0], <TAB>  <TAB> ]",if v == 1 :,132
"def run(self): <TAB> if self.check(): <TAB>  <TAB> print_status(""Sending payload request"") <TAB>  <TAB> response = self.http_request( <TAB>  <TAB>  <TAB> method=""GET"", <TAB>  <TAB>  <TAB> path=self.valid, <TAB>  <TAB> ) <TAB>  <TAB> if response is None: <TAB>  <TAB>  <TAB> return <MASK> print_success(""Exploit success"") <TAB>  <TAB>  <TAB> print_info(response.text) <TAB> else: <TAB>  <TAB> print_error(""Exploit failed - target seems to be not vulnerable"")",if response . status_code == 200 and len ( response . text ) :,134
"def __exit__(self, exc_type, exc_val, exc_tb): <TAB> if not self._stop_spinner.is_set(): <MASK> self._stop_spinner.set() <TAB>  <TAB>  <TAB> self._spinner_thread.join() <TAB>  <TAB> self._frame_index = 0 <TAB>  <TAB> if self.enabled: <TAB>  <TAB>  <TAB> self.clear() <TAB>  <TAB>  <TAB> self.enable_cursor() <TAB> return self",if self . _spinner_thread :,111
"def do_exceptional_blocking_test( <TAB> self, block_func, block_args, trigger_func, trigger_args, expected_exception_class): <TAB> thread = _TriggerThread(trigger_func, trigger_args) <TAB> thread.start() <TAB> try: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> block_func(*block_args) <TAB>  <TAB> except expected_exception_class: <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.fail(""expected exception of kind %r"" % expected_exception_class) <TAB> finally: <TAB>  <TAB> support.join_thread(thread, 10)  # make sure the thread terminates <MASK> self.fail(""trigger thread ended but event never set"")",if not thread . startedEvent . is_set ( ) :,176
"def _on_route(self, route: Route, request: Request) -> None: <TAB> for handler_entry in self._routes: <TAB>  <TAB> if handler_entry.matcher.matches(request.url): <TAB>  <TAB>  <TAB> result = cast(Any, handler_entry.handler)(route, request) <MASK> asyncio.create_task(result) <TAB>  <TAB>  <TAB> return <TAB> asyncio.create_task(route.continue_())",if inspect . iscoroutine ( result ) :,110
"def get_property_names(node: ast.AST, attribute_names: Dict) -> None: <TAB> func_nodes = [node for node in node.body if isinstance(node, ast.FunctionDef)] <TAB> if func_nodes: <TAB>  <TAB> assigns = [node for node in func_nodes[0].body if isinstance(node, ast.Assign)] <MASK> for assign in assigns: <TAB>  <TAB>  <TAB>  <TAB> if hasattr(assign, ""targets""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for attr in assign.targets: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if hasattr(attr, ""attr"") and not attr.attr.startswith(""_""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> attribute_names.update({attr.attr: attr.attr})",if assigns :,165
"def consume_queue(queue, cascade_stop): <TAB> """"""Consume the queue by reading lines off of it and yielding them."""""" <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> item = queue.get(timeout=0.1) <TAB>  <TAB> except Empty: <TAB>  <TAB>  <TAB> yield None <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # See https://github.com/docker/compose/issues/189 <TAB>  <TAB> except thread.error: <TAB>  <TAB>  <TAB> raise ShutdownException() <MASK> raise item.exc <TAB>  <TAB> if item.is_stop and not cascade_stop: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> yield item.item",if item . exc :,152
"def get_user_groups(user): <TAB> result = local.user_groups_cache.get(user) <TAB> if result is not None: <TAB>  <TAB> return result <TAB> if user is None: <TAB>  <TAB> return anybody_frozenset <TAB> result = {""anybody""} <TAB> for cls, func in usergroup_functions: <MASK> groups = func(user) <TAB>  <TAB>  <TAB> if isinstance(groups, basestring):  # single group name <TAB>  <TAB>  <TAB>  <TAB> result.add(groups) <TAB>  <TAB>  <TAB> elif groups is not None: <TAB>  <TAB>  <TAB>  <TAB> result.update(groups) <TAB> result = frozenset(result) <TAB> local.user_groups_cache[user] = result <TAB> return result","if cls is None or isinstance ( user , cls ) :",172
"def test_missing(): <TAB> """"""Missing members of Qt.py have been defined with placeholders"""""" <TAB> import Qt <TAB> missing_members = Qt._missing_members.copy() <TAB> missing = list() <TAB> for module, members in missing_members.items(): <TAB>  <TAB> mod = getattr(Qt, module) <TAB>  <TAB> missing.extend( <TAB>  <TAB>  <TAB> member <TAB>  <TAB>  <TAB> for member in members <MASK> or not isinstance(getattr(mod, member), Qt.MissingMember) <TAB>  <TAB> ) <TAB> binding = Qt.__binding__ <TAB> assert not missing, ( <TAB>  <TAB> ""Some members did not exist in {binding} as "" <TAB>  <TAB> ""a Qt.MissingMember type\n{missing}"".format(**locals()) <TAB> )","if not hasattr ( mod , member )",176
def _walk_rec(addr): <TAB> if addr not in walked: <TAB>  <TAB> walked.add(addr) <TAB>  <TAB> target = self._target_by_address[addr] <TAB>  <TAB> if not predicate or predicate(target): <TAB>  <TAB>  <TAB> if not postorder: <TAB>  <TAB>  <TAB>  <TAB> work(target) <MASK> prelude(target) <TAB>  <TAB>  <TAB> for dep_address in self._target_dependees_by_address[addr]: <TAB>  <TAB>  <TAB>  <TAB> _walk_rec(dep_address) <TAB>  <TAB>  <TAB> if epilogue: <TAB>  <TAB>  <TAB>  <TAB> epilogue(target) <TAB>  <TAB>  <TAB> if postorder: <TAB>  <TAB>  <TAB>  <TAB> work(target),if prelude :,166
"def _wrap_path_elements(self, classpath_elements): <TAB> wrapped_path_elements = [] <TAB> for element in classpath_elements: <MASK> raise ValueError(""Input must be a list of tuples containing two elements."") <TAB>  <TAB> if isinstance(element[1], ClasspathEntry): <TAB>  <TAB>  <TAB> wrapped_path_elements.append(element) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> wrapped_path_elements.append((element[0], ClasspathEntry(element[1]))) <TAB> return wrapped_path_elements",if len ( element ) != 2 :,127
"def _Visit(node, visitor, *args, **kwargs): <TAB> """"""Visit the node."""""" <TAB> name = type(visitor).__name__ <TAB> recursive = name in _visiting <TAB> _visiting.add(name) <TAB> start = metrics.get_cpu_clock() <TAB> try: <TAB>  <TAB> return _VisitNode(node, visitor, *args, **kwargs) <TAB> finally: <MASK> _visiting.remove(name) <TAB>  <TAB>  <TAB> elapsed = metrics.get_cpu_clock() - start <TAB>  <TAB>  <TAB> metrics.get_metric(""visit_"" + name, metrics.Distribution).add(elapsed) <TAB>  <TAB>  <TAB> if _visiting: <TAB>  <TAB>  <TAB>  <TAB> metrics.get_metric(""visit_nested_"" + name, metrics.Distribution).add( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> elapsed <TAB>  <TAB>  <TAB>  <TAB> )",if not recursive :,192
"def readEntities(self): <TAB> """"""Read entities section"""""" <TAB> while True: <TAB>  <TAB> tag, value = self.read() <TAB>  <TAB> if tag is None: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> elif value == ""ENDSEC"": <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> entity = Entity(value) <TAB>  <TAB> entity.read(self) <TAB>  <TAB> # 			print <TAB>  <TAB> # 			print "">>>"",entity <TAB>  <TAB> # 			for n in sorted(entity.keys()): print n,"":"",entity[n] <MASK> continue  # ignore <TAB>  <TAB> self.addEntity(entity)","if entity . type in ( ""HATCH"" , ) :",155
"def handle_execute_plan_result(res): <TAB> res_data = res[""data""][""executePlan""] <TAB> res_type = res_data[""__typename""] <TAB> handle_error_states(res_type, res_data) <TAB> if res_type == ""ExecutePlanSuccess"": <TAB>  <TAB> pipeline_name = res_data[""pipeline""][""name""] <TAB>  <TAB> return [ <TAB>  <TAB>  <TAB> dagster_event_from_dict(e, pipeline_name) <TAB>  <TAB>  <TAB> for e in res_data[""stepEvents""] <MASK> ] <TAB> raise DagsterGraphQLClientError(""Unexpected result type"")","if e [ ""__typename"" ] in HANDLED_EVENTS",155
"def grep_loss_from_file(file_name): <TAB> loss = 0.0 <TAB> with open(file_name, ""r"") as f: <TAB>  <TAB> lines = f.readlines() <TAB>  <TAB> line_filter = ""validation loss at the end of training for test data | LM loss:"" <TAB>  <TAB> match_number = re.compile(""LM loss: ([-+]?[0-9]+\.?[0-9]*(?:[Ee][-+]?[0-9]+)?)"") <TAB>  <TAB> for line in lines: <MASK> loss = re.findall(match_number, line) <TAB>  <TAB>  <TAB>  <TAB> loss = float(loss[0]) <TAB> if loss == 0.0: <TAB>  <TAB> print(""no loss found in file "", file_name) <TAB> return loss",if line_filter in line :,183
"def createDescription(self): <TAB> desc = ""Inode %s: "" % self.uniq_id <TAB> size = self[""size""].value <TAB> if self[""blocks""].value == 0: <TAB>  <TAB> desc += ""(unused)"" <TAB> elif 11 <= self.uniq_id: <TAB>  <TAB> size = humanFilesize(size) <TAB>  <TAB> desc += ""file, size=%s, mode=%s"" % (size, self.getMode()) <TAB> else: <MASK> desc += self.inode_type_name[self.uniq_id] <TAB>  <TAB>  <TAB> if self.uniq_id == 2: <TAB>  <TAB>  <TAB>  <TAB> desc += "" (%s)"" % self.getMode() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> desc += ""special"" <TAB> return desc",if self . uniq_id in self . inode_type_name :,191
"def create_branches_strs(self, branches): <TAB> branches_strings = set() <TAB> for branch in branches: <MASK> branches_strings.add(branch[1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> branches_strings.add(""{}/{}"".format(branch[0], branch[1])) <TAB> return branches_strings",if branch [ 0 ] is None :,83
"def _formatter(self, cursor, fmt=None, header=None, transform=None): <TAB> fmt = fmt or self._fmt <TAB> if fmt == ""csv"": <TAB>  <TAB> if header: <TAB>  <TAB>  <TAB> yield "","".join(header) <TAB>  <TAB> for record in cursor: <MASK> record = transform(record) <TAB>  <TAB>  <TAB> if isinstance(record, (list, tuple)): <TAB>  <TAB>  <TAB>  <TAB> yield "","".join([str(x) for x in record]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield record <TAB> elif fmt == ""raw"": <TAB>  <TAB> if header: <TAB>  <TAB>  <TAB> yield header <TAB>  <TAB> for record in cursor: <TAB>  <TAB>  <TAB> if transform: <TAB>  <TAB>  <TAB>  <TAB> record = transform(record) <TAB>  <TAB>  <TAB> yield record <TAB> else: <TAB>  <TAB> raise TypeError(""format not supported"")",if transform :,191
"def _check_component_in_requirements(require): <TAB> if COMPONENT_SCOPE in require: <TAB>  <TAB> req_name, req_comp_name = require.split(COMPONENT_SCOPE) <MASK> return <TAB>  <TAB> if req_comp_name not in self.deps_build_info[req_name].components: <TAB>  <TAB>  <TAB> raise ConanException( <TAB>  <TAB>  <TAB>  <TAB> ""Component '%s' not found in '%s' package requirement"" <TAB>  <TAB>  <TAB>  <TAB> % (require, req_name) <TAB>  <TAB>  <TAB> )",if req_name == req_comp_name :,134
"def _parse_service_aliases(envvars): <TAB> service_aliases = [] <TAB> for key, value in envvars.iteritems(): <TAB>  <TAB> match = haproxy.config.SERVICE_ALIAS_MATCH.search(key) <TAB>  <TAB> if match: <TAB>  <TAB>  <TAB> detailed_match = haproxy.config.DETAILED_SERVICE_ALIAS_MATCH.search(key) <MASK> alias = key[: detailed_match.start()] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> alias = key[: match.start()] <TAB>  <TAB>  <TAB> if alias not in service_aliases: <TAB>  <TAB>  <TAB>  <TAB> service_aliases.append(alias) <TAB> return service_aliases",if detailed_match :,158
"def display_all(data_dict): <TAB> """"""Display all pkgs and PACKAGECONFIG information"""""" <TAB> print(str("""").ljust(50, ""="")) <TAB> for fn in data_dict: <TAB>  <TAB> print(""%s"" % data_dict[fn].getVar(""P"")) <TAB>  <TAB> print(fn) <TAB>  <TAB> packageconfig = data_dict[fn].getVar(""PACKAGECONFIG"") or """" <MASK> packageconfig = ""None"" <TAB>  <TAB> print(""PACKAGECONFIG %s"" % packageconfig) <TAB>  <TAB> for flag, flag_val in data_dict[fn].getVarFlags(""PACKAGECONFIG"").items(): <TAB>  <TAB>  <TAB> if flag == ""doc"": <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> print(""PACKAGECONFIG[%s] %s"" % (flag, flag_val)) <TAB>  <TAB> print("""")","if packageconfig . strip ( ) == """" :",194
"def getJarOutputStream(self): <TAB> if not self._jarOutputStream: <MASK> self._jarOutputStream = JarOutputStream( <TAB>  <TAB>  <TAB>  <TAB> FileOutputStream(self._jarFile), self._manifest <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._jarOutputStream = JarOutputStream(FileOutputStream(self._jarFile)) <TAB> return self._jarOutputStream",if self . _manifest :,90
"def get_app(self, appid): <TAB> assert isinstance(appid, type(u"""")) <TAB> if not appid in self._apps: <MASK> log.msg(""spawning appid %s"" % (appid,)) <TAB>  <TAB> self._apps[appid] = AppNamespace( <TAB>  <TAB>  <TAB> self._db, self._welcome, self._blur_usage, self._log_requests, appid <TAB>  <TAB> ) <TAB> return self._apps[appid]",if self . _log_requests :,119
"def convert_key_raw_str(self, needle, haystack): <TAB> num_levels = needle.split(""."") <TAB> if len(num_levels) == 0: <TAB>  <TAB> return False <TAB> current_pointer = haystack <TAB> for updated_key in num_levels: <TAB>  <TAB> if updated_key == num_levels[-1]: <TAB>  <TAB>  <TAB> current_pointer[updated_key] = { <TAB>  <TAB>  <TAB>  <TAB> ""raw_value"": str(current_pointer[updated_key]) <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB> return haystack <MASK> current_pointer = current_pointer[updated_key] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return haystack",if updated_key in current_pointer :,159
"def _infer_dockerfile(self): <TAB> dockerfile_contents = ""FROM scratch\n"" <TAB> for hel in self._history(): <TAB>  <TAB> patt = re.match(r""^/bin/sh -c #\(nop\) +(.*)"", hel[""CreatedBy""]) <TAB>  <TAB> if patt: <TAB>  <TAB>  <TAB> cmd = patt.group(1) <TAB>  <TAB> elif hel[""CreatedBy""]: <TAB>  <TAB>  <TAB> cmd = ""RUN "" + hel[""CreatedBy""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> cmd = None <MASK> dockerfile_contents = dockerfile_contents + cmd + ""\n"" <TAB> return dockerfile_contents",if cmd :,147
"def get_property(self, interface, name): <TAB> if interface == MediaContainer.IFACE: <TAB>  <TAB> if name == ""ChildCount"" or name == ""ItemCount"": <TAB>  <TAB>  <TAB> return len(self.__album.songs) <TAB>  <TAB> elif name == ""ContainerCount"": <TAB>  <TAB>  <TAB> return 0 <TAB>  <TAB> elif name == ""Searchable"": <TAB>  <TAB>  <TAB> return False <TAB> elif interface == MediaObject.IFACE: <TAB>  <TAB> if name == ""Parent"": <TAB>  <TAB>  <TAB> return self.parent.PATH <MASK> return ""container"" <TAB>  <TAB> elif name == ""Path"": <TAB>  <TAB>  <TAB> return self.PATH <TAB>  <TAB> elif name == ""DisplayName"": <TAB>  <TAB>  <TAB> return unival(self.__pattern % self.__album)","elif name == ""Type"" :",175
"def tearDownClass(cls): <TAB> if cls._tempBaseDir is None: <TAB>  <TAB> while cls._tempDirs: <TAB>  <TAB>  <TAB> tempDir = cls._tempDirs.pop() <MASK> shutil.rmtree(tempDir) <TAB> else: <TAB>  <TAB> cls._tempDirs = [] <TAB> super(ToilTest, cls).tearDownClass()",if os . path . exists ( tempDir ) :,92
"def finalize(self, result): <TAB> """"""Clean up stats file, if configured to do so."""""" <TAB> if not self.available(): <TAB>  <TAB> return <TAB> try: <TAB>  <TAB> self.prof.close() <TAB> except AttributeError: <TAB>  <TAB> # TODO: is this trying to catch just the case where not <TAB>  <TAB> # hasattr(self.prof, ""close"")?  If so, the function call should be <TAB>  <TAB> # moved out of the try: suite. <TAB>  <TAB> pass <TAB> if self.clean_stats_file: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> os.close(self.fileno) <TAB>  <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> os.unlink(self.pfile) <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> pass <TAB> return None",if self . fileno :,191
"def __iter__(self): <TAB> # wait for the log file to appear or app to finish (whichever happens first) <TAB> while True: <TAB>  <TAB> self._check_finished()  # check to see if app has finished running <TAB>  <TAB> if os.path.isfile(self._log_file): <TAB>  <TAB>  <TAB> self._log_fp = open(self._log_file, ""r"")  # noqa: P201 <TAB>  <TAB>  <TAB> break <MASK> # app finished without ever writing a log file <TAB>  <TAB>  <TAB> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB> f""app: {self._app_id} finished without writing: {self._log_file}"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> time.sleep(1) <TAB> return self",if self . _app_finished :,175
"def setAttributes(self, attributes): <TAB> if attributes: <TAB>  <TAB> for name, value in list(attributes.items()): <MASK> if name[0] is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> qualifiedName = name[0] + "":"" + name[1] <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> qualifiedName = name[1] <TAB>  <TAB>  <TAB>  <TAB> self.element.setAttributeNS(name[2], qualifiedName, value) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.element.setAttribute(name, value)","if isinstance ( name , tuple ) :",135
"def _terminate_task(self, t): <TAB> if hasattr(t, ""terminate""): <TAB>  <TAB> logger.debug(""terminate()ing task %r"" % t) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if not _BSD: <TAB>  <TAB>  <TAB>  <TAB> t.terminate() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> # XXX - On FreeBSD using SIGTERM doesn't work <TAB>  <TAB>  <TAB>  <TAB> # as the process hangs on kqueue.control() or <TAB>  <TAB>  <TAB>  <TAB> # select.select(). Use SIGKILL instead. <TAB>  <TAB>  <TAB>  <TAB> os.kill(t.pid, signal.SIGKILL) <TAB>  <TAB> except OSError as err: <MASK> raise",if err . errno != errno . ESRCH :,163
"def test_has_projection(self, resnet_class_and_has_projection, resnet_v2): <TAB> resnet_class, has_projection = resnet_class_and_has_projection <TAB> model = resnet_class(1000, resnet_v2=resnet_v2) <TAB> for i, block_group in enumerate(model.block_groups): <MASK> self.assertEqual( <TAB>  <TAB>  <TAB>  <TAB> hasattr(block_group.blocks[0], ""proj_conv""), has_projection <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertTrue(hasattr(block_group.blocks[0], ""proj_conv"")) <TAB>  <TAB> for block in block_group.blocks[1:]: <TAB>  <TAB>  <TAB> self.assertFalse(hasattr(block, ""proj_conv""))",if i == 0 :,184
"def contains_violation(self, conf): <TAB> from_port = force_int(force_list(conf.get(""from_port"", [{-1}]))[0]) <TAB> to_port = force_int(force_list(conf.get(""to_port"", [{-1}]))[0]) <TAB> if ( <TAB>  <TAB> from_port is not None <TAB>  <TAB> and to_port is not None <TAB>  <TAB> and (from_port <= self.port <= to_port) <TAB> ): <TAB>  <TAB> cidr_blocks = force_list(conf.get(""cidr_blocks"", [[]])[0]) <MASK> return True <TAB> return False","if ""0.0.0.0/0"" in cidr_blocks :",166
"def delete(self): <TAB> """"""Delete the downloaded file."""""" <TAB> try: <MASK> os.remove(self._filename) <TAB>  <TAB>  <TAB> log.downloads.debug(""Deleted {}"".format(self._filename)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.downloads.debug(""Not deleting {}"".format(self._filename)) <TAB> except OSError: <TAB>  <TAB> log.downloads.exception(""Failed to remove partial file"")",if self . _filename is not None and os . path . exists ( self . _filename ) :,113
"def consume_socket_content(sock, timeout=0.5): <TAB> chunks = 65536 <TAB> content = b"""" <TAB> while True: <TAB>  <TAB> more_to_read = select.select([sock], [], [], timeout)[0] <TAB>  <TAB> if not more_to_read: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> new_content = sock.recv(chunks) <MASK> break <TAB>  <TAB> content += new_content <TAB> return content",if not new_content :,108
"def get_receiver_nos(self): <TAB> receiver_nos = [] <TAB> if self.receiver_list: <TAB>  <TAB> for d in self.receiver_list.split(""\n""): <TAB>  <TAB>  <TAB> receiver_no = d <MASK> receiver_no = receiver_no.split(""-"")[1] <TAB>  <TAB>  <TAB> if receiver_no.strip(): <TAB>  <TAB>  <TAB>  <TAB> receiver_nos.append(cstr(receiver_no).strip()) <TAB> else: <TAB>  <TAB> msgprint(_(""Receiver List is empty. Please create Receiver List"")) <TAB> return receiver_nos","if ""-"" in d :",134
"def __init__(self, apps=None, *args, **kwargs): <TAB> # The list of apps that are handled <TAB> self.apps = [] <TAB> # Mapping of app module paths to storage instances <TAB> self.storages = SortedDict() <TAB> if apps is None: <TAB>  <TAB> apps = settings.INSTALLED_APPS <TAB> for app in apps: <TAB>  <TAB> app_storage = self.storage_class(app) <MASK> self.storages[app] = app_storage <TAB>  <TAB>  <TAB> if app not in self.apps: <TAB>  <TAB>  <TAB>  <TAB> self.apps.append(app) <TAB> super(AppDirectoriesFinder, self).__init__(*args, **kwargs)",if os . path . isdir ( app_storage . location ) :,169
"def song_url(cls, song): <TAB> if ""url"" in song: <TAB>  <TAB> # songs_url resp <TAB>  <TAB> url = song[""url""] <TAB>  <TAB> if url is None: <TAB>  <TAB>  <TAB> return Parse._song_url_by_id(song[""id""]) <TAB>  <TAB> br = song[""br""] <TAB>  <TAB> if br >= 320000: <TAB>  <TAB>  <TAB> quality = ""HD"" <MASK> quality = ""MD"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> quality = ""LD"" <TAB>  <TAB> return url, ""{} {}k"".format(quality, br // 1000) <TAB> else: <TAB>  <TAB> # songs_detail resp <TAB>  <TAB> return Parse._song_url_by_id(song[""id""])",elif br >= 192000 :,171
"def get_dataset(paths, has_class_directories=True): <TAB> dataset = [] <TAB> for path in paths.split("":""): <TAB>  <TAB> path_exp = os.path.expanduser(path) <TAB>  <TAB> classes = os.listdir(path_exp) <TAB>  <TAB> classes.sort() <TAB>  <TAB> nrof_classes = len(classes) <TAB>  <TAB> for i in range(nrof_classes): <TAB>  <TAB>  <TAB> class_name = classes[i] <TAB>  <TAB>  <TAB> facedir = os.path.join(path_exp, class_name) <TAB>  <TAB>  <TAB> image_paths = get_image_paths(facedir) <MASK> dataset.append(ImageClass(class_name, image_paths)) <TAB> return dataset",if len ( image_paths ) > 0 :,180
"def visit_all_module(mod): <TAB> if mod.__name__ in experimental_namespace: <TAB>  <TAB> return <TAB> for member_name in ( <TAB>  <TAB> name <TAB>  <TAB> for name in (mod.__all__ if hasattr(mod, ""__all__"") else dir(mod)) <TAB>  <TAB> if not name.startswith(""_"") <TAB> ): <TAB>  <TAB> instance = getattr(mod, member_name, None) <TAB>  <TAB> if instance is None: <TAB>  <TAB>  <TAB> continue <MASK> visit_all_module(instance) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> visit_member(mod.__name__, instance)",if inspect . ismodule ( instance ) :,143
"def number_label(list_numbers): <TAB> list_numbers = sorted(list_numbers) <TAB> divide = [[]] <TAB> divide[0].append(list_numbers[0]) <TAB> group = 0 <TAB> for i in range(1, len(list_numbers)): <TAB>  <TAB> if list_numbers[i] == list_numbers[i - 1] + 1: <TAB>  <TAB>  <TAB> divide[group].append(list_numbers[i]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> group += 1 <TAB>  <TAB>  <TAB> divide.append([list_numbers[i]]) <TAB> label = """" <TAB> for elem in divide: <MASK> label += str(elem[0]) + ""-"" + str(elem[-1]) + "","" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> label += str(elem[0]) + "","" <TAB> return label[:-1]",if len ( elem ) > 1 :,197
"def fuse_subtree( <TAB> self, <TAB> node: ScopeTreeNode,) -> None: <TAB> node.remove() <TAB> if node.path_id is not None: <MASK> self.optional = True <TAB>  <TAB> subtree = ScopeTreeNode(fenced=True) <TAB>  <TAB> for child in tuple(node.children): <TAB>  <TAB>  <TAB> subtree.attach_child(child) <TAB> else: <TAB>  <TAB> subtree = node <TAB> self.attach_subtree(subtree)",if node . optional :,115
"def get_returned(self, pyobject, args): <TAB> result = self.get_exact_returned(pyobject, args) <TAB> if result is not None: <TAB>  <TAB> return result <TAB> path, key = self._get_scope(pyobject) <TAB> if path is None: <TAB>  <TAB> return None <TAB> for call_info in self.objectdb.get_callinfos(path, key): <TAB>  <TAB> returned = call_info.get_returned() <MASK> result = returned <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if result is None: <TAB>  <TAB>  <TAB> result = returned <TAB> if result is not None: <TAB>  <TAB> return self.to_pyobject(result)","if returned and returned [ 0 ] not in ( ""unknown"" , ""none"" ) :",170
"def addNode(val): <TAB> global node, left, right <TAB> pos = len(node) <TAB> node.append(val) <TAB> left.append(-1) <TAB> right.append(-1) <TAB> if pos > 0: <TAB>  <TAB> curr = 0 <TAB>  <TAB> while True: <MASK> if left[curr] == -1: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> left[curr] = pos <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> curr = left[curr] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> if right[curr] == -1: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> right[curr] = pos <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> curr = right[curr]",if val < node [ curr ] :,187
"def get(self, key, timeout=None): <TAB> self.lock.acquire() <TAB> try: <TAB>  <TAB> # check to see if we have this key <TAB>  <TAB> entry = self._entries.get(key) <TAB>  <TAB> if not entry: <TAB>  <TAB>  <TAB> # no hit, return nothing <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> # use provided timeout in arguments if provided <TAB>  <TAB> # otherwise use the one provided during init. <MASK> timeout = self.timeout <TAB>  <TAB> # make sure entry is not expired <TAB>  <TAB> if self._is_expired(entry, timeout): <TAB>  <TAB>  <TAB> # entry expired, delete and return nothing <TAB>  <TAB>  <TAB> del self._entries[key] <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> # entry found and not expired, return it <TAB>  <TAB> return entry[1] <TAB> finally: <TAB>  <TAB> self.lock.release()",if timeout is None :,198
"def _to_ctypes(x): <TAB> if not isinstance(x, (int, long)): <MASK> x = int(x) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError(""integer expected, got %s"" % type(x).__name__) <TAB> if ctype(x).value != x: <TAB>  <TAB> if not is_signed and x < 0: <TAB>  <TAB>  <TAB> raise OverflowError(""%s: negative integer"" % name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise OverflowError(""%s: integer out of bounds"" % name) <TAB> return x","if isinstance ( x , CTypesData ) :",135
"def load_data(self): <TAB> try: <TAB>  <TAB> # This code will not activate without PIL/Pillow installed. <TAB>  <TAB> from PIL import Image <MASK> from io import BytesIO <TAB>  <TAB>  <TAB> self.image = Image.open(BytesIO(self.data)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return <TAB> except ImportError: <TAB>  <TAB> # PIL/Pillow not found, decoding data is most we can do. <TAB>  <TAB> pass",if self . data is not None :,110
"def adjust_deprecated_values(rule): <TAB> # From rename of simple HTTP alerter <TAB> if rule.get(""type"") == ""simple"": <TAB>  <TAB> rule[""type""] = ""post"" <TAB>  <TAB> if ""simple_proxy"" in rule: <TAB>  <TAB>  <TAB> rule[""http_post_proxy""] = rule[""simple_proxy""] <MASK> rule[""http_post_url""] = rule[""simple_webhook_url""] <TAB>  <TAB> logging.warning( <TAB>  <TAB>  <TAB> '""simple"" alerter has been renamed ""post"" and comptability may be removed in a future release.' <TAB>  <TAB> )","if ""simple_webhook_url"" in rule :",150
"def detect(get_page): <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS: <TAB>  <TAB> page, headers, code = get_page(get=vector) <TAB>  <TAB> retval = ( <TAB>  <TAB>  <TAB> re.search( <TAB>  <TAB>  <TAB>  <TAB> r""\Ast8(id|_wat|_wlf)"", headers.get(HTTP_HEADER.SET_COOKIE, """"), re.I <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> is not None <TAB>  <TAB> ) <MASK> break <TAB> return retval",if retval :,125
"def append_in_normal_order(index, mode): <TAB> phase = 1 <TAB> mode = n - 1 - mode <TAB> for i in range(n): <TAB>  <TAB> bit = 1 << i <TAB>  <TAB> if i == mode: <MASK> return None, None <TAB>  <TAB>  <TAB> return index | bit, phase <TAB>  <TAB> elif index & bit: <TAB>  <TAB>  <TAB> phase *= -1",if index & bit != 0 :,99
"def tokens_to_idx(self, tokens): <TAB> res = [] <TAB> for token in tokens: <TAB>  <TAB> idx = self.token_to_id.get(token) <MASK> if self.next_id == self.max_dict_size: <TAB>  <TAB>  <TAB>  <TAB> self.log.warning( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Maximum size of dict reached, token '%s' converted to #UNK token"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> token, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> idx = 0 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> idx = self.next_id <TAB>  <TAB>  <TAB>  <TAB> self.next_id += 1 <TAB>  <TAB>  <TAB>  <TAB> self.token_to_id[token] = idx <TAB>  <TAB> res.append(idx) <TAB> return res",if idx is None :,184
"def tearDown(self): <TAB> try: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> for i in range(self.TEST_DIRS): <TAB>  <TAB>  <TAB>  <TAB> dir = getattr(self, ""dir%i"" % (i + 1)) <MASK> shutil.rmtree(dir) <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> for i in range(self.TEST_FILES): <TAB>  <TAB>  <TAB>  <TAB> filename = getattr(self, ""filename%i"" % (i + 1)) <TAB>  <TAB>  <TAB>  <TAB> if os.path.exists(filename): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> os.remove(filename) <TAB> finally: <TAB>  <TAB> sys.path = self.orig_syspath <TAB>  <TAB> os.chdir(self.orig_cwd)",if os . path . exists ( dir ) :,175
"def isdir(self, path): <TAB> bucket, obj = self._path_to_bucket_and_key(path) <TAB> if self._is_root(obj): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.client.buckets().get(bucket=bucket).execute() <TAB>  <TAB> except errors.HttpError as ex: <MASK> return False <TAB>  <TAB>  <TAB> raise <TAB> obj = self._add_path_delimiter(obj) <TAB> if self._obj_exists(bucket, obj): <TAB>  <TAB> return True <TAB> # Any objects with this prefix <TAB> resp = ( <TAB>  <TAB> self.client.objects().list(bucket=bucket, prefix=obj, maxResults=20).execute() <TAB> ) <TAB> lst = next(iter(resp.get(""items"", [])), None) <TAB> return bool(lst)","if ex . resp [ ""status"" ] == ""404"" :",198
"def get_link(layer, base_ch, growth_rate, grmul): <TAB> if layer == 0: <TAB>  <TAB> return base_ch, 0, [] <TAB> out_channels = growth_rate <TAB> link = [] <TAB> for i in range(10): <TAB>  <TAB> dv = 2 ** i <TAB>  <TAB> if layer % dv == 0: <TAB>  <TAB>  <TAB> k = layer - dv <TAB>  <TAB>  <TAB> link.insert(0, k) <MASK> out_channels *= grmul <TAB> out_channels = int(int(out_channels + 1) / 2) * 2 <TAB> in_channels = 0 <TAB> for i in link: <TAB>  <TAB> ch, _, _ = get_link(i, base_ch, growth_rate, grmul) <TAB>  <TAB> in_channels += ch <TAB> return out_channels, in_channels, link",if i > 0 :,199
"def merge_accumulators( <TAB> self, accumulators: List[MatrixAccumulator]) -> MatrixAccumulator: <TAB> result = accumulators[0] <TAB> for accumulator in accumulators[1:]: <TAB>  <TAB> for threshold in self._thresholds: <MASK> continue <TAB>  <TAB>  <TAB> result[threshold] = self._merge_matrix( <TAB>  <TAB>  <TAB>  <TAB> result, threshold, accumulator[threshold] <TAB>  <TAB>  <TAB> ) <TAB> return result",if threshold not in accumulator :,114
"def _add_occur_indexing(self, base, ex): <TAB> if self._occur_index and ex.sent_index is not None: <MASK> base += ""_%s"" % ex.discourse_id <TAB>  <TAB> base += ""_s%s"" % ex.sent_index <TAB>  <TAB> base += ""_w%s"" % sorted(ex.word_indices)[0] <TAB> return base",if ex . discourse_id :,99
"def op_funcdef_handle(tokens): <TAB> """"""Process infix defs."""""" <TAB> func, base_args = get_infix_items(tokens) <TAB> args = [] <TAB> for arg in base_args[:-1]: <TAB>  <TAB> rstrip_arg = arg.rstrip() <MASK> if not rstrip_arg.endswith("",""): <TAB>  <TAB>  <TAB>  <TAB> arg += "", "" <TAB>  <TAB>  <TAB> elif arg.endswith("",""): <TAB>  <TAB>  <TAB>  <TAB> arg += "" "" <TAB>  <TAB> args.append(arg) <TAB> last_arg = base_args[-1] <TAB> if last_arg.rstrip().endswith("",""): <TAB>  <TAB> last_arg = last_arg.rsplit("","")[0] <TAB> args.append(last_arg) <TAB> return func + ""("" + """".join(args) + "")""",if not rstrip_arg . endswith ( unwrapper ) :,186
"def from_text(cls, rdclass, rdtype, tok, origin=None, relativize=True): <TAB> algorithm = tok.get_uint8() <TAB> fp_type = tok.get_uint8() <TAB> chunks = [] <TAB> while 1: <TAB>  <TAB> t = tok.get().unescape() <MASK> break <TAB>  <TAB> if not t.is_identifier(): <TAB>  <TAB>  <TAB> raise dns.exception.SyntaxError <TAB>  <TAB> chunks.append(t.value.encode()) <TAB> fingerprint = b"""".join(chunks) <TAB> fingerprint = binascii.unhexlify(fingerprint) <TAB> return cls(rdclass, rdtype, algorithm, fp_type, fingerprint)",if t . is_eol_or_eof ( ) :,164
"def test_create_option_buttons(self): <TAB> e = self.engine <TAB> for state in (0, 1): <TAB>  <TAB> for var in (e.revar, e.casevar, e.wordvar, e.wrapvar): <TAB>  <TAB>  <TAB> var.set(state) <TAB>  <TAB> frame, options = self.btn_test_setup(self.dialog.create_option_buttons) <TAB>  <TAB> for spec, button in zip(options, frame.pack_slaves()): <TAB>  <TAB>  <TAB> var, label = spec <TAB>  <TAB>  <TAB> self.assertEqual(button[""text""], label) <TAB>  <TAB>  <TAB> self.assertEqual(var.get(), state) <MASK> button.deselect() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> button.select() <TAB>  <TAB>  <TAB> self.assertEqual(var.get(), 1 - state)",if state == 1 :,196
"def _expander(fringe, iteration, viewer): <TAB> T = schedule(iteration) <TAB> current = fringe[0] <TAB> neighbors = current.expand(local_search=True) <TAB> if viewer: <TAB>  <TAB> viewer.event(""expanded"", [current], [neighbors]) <TAB> if neighbors: <TAB>  <TAB> succ = random.choice(neighbors) <TAB>  <TAB> delta_e = succ.value - current.value <MASK> fringe.pop() <TAB>  <TAB>  <TAB> fringe.append(succ) <TAB>  <TAB>  <TAB> if viewer: <TAB>  <TAB>  <TAB>  <TAB> viewer.event(""chosen_node"", succ)",if delta_e > 0 or random . random ( ) < math . exp ( delta_e / T ) :,160
"def filename_for_module(module, abs_path): <TAB> try: <MASK> abs_path = abs_path[:-1] <TAB>  <TAB> base_module = module.split(""."", 1)[0] <TAB>  <TAB> if base_module == module: <TAB>  <TAB>  <TAB> return os.path.basename(abs_path) <TAB>  <TAB> base_module_path = sys.modules[base_module].__file__ <TAB>  <TAB> return abs_path.split(base_module_path.rsplit(os.sep, 2)[0], 1)[-1].lstrip( <TAB>  <TAB>  <TAB> os.sep <TAB>  <TAB> ) <TAB> except Exception: <TAB>  <TAB> return abs_path","if abs_path . endswith ( "".pyc"" ) :",158
"def generate(self, *arg, **kw): <TAB> """"""Call all plugins, yielding each item in each non-None result."""""" <TAB> for p, meth in self.plugins: <TAB>  <TAB> result = None <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> result = meth(*arg, **kw) <MASK> for r in result: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield r <TAB>  <TAB> except (KeyboardInterrupt, SystemExit): <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> exc = sys.exc_info() <TAB>  <TAB>  <TAB> yield Failure(*exc) <TAB>  <TAB>  <TAB> continue",if result is not None :,137
"def poll(self, flag=os.WNOHANG): <TAB> if self.returncode is None: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> pid, sts = os.waitpid(self.pid, flag) <TAB>  <TAB> except os.error: <TAB>  <TAB>  <TAB> # Child process not yet created. See #1731717 <TAB>  <TAB>  <TAB> # e.errno == errno.ECHILD == 10 <TAB>  <TAB>  <TAB> return None <MASK> if os.WIFSIGNALED(sts): <TAB>  <TAB>  <TAB>  <TAB> self.returncode = -os.WTERMSIG(sts) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> assert os.WIFEXITED(sts) <TAB>  <TAB>  <TAB>  <TAB> self.returncode = os.WEXITSTATUS(sts) <TAB> return self.returncode",if pid == self . pid :,181
"def dict_parse(d): <TAB> tmpValues = {} <TAB> for key, value in d.iteritems(): <TAB>  <TAB> if isinstance(value, dict): <TAB>  <TAB>  <TAB> dict_parse(value) <MASK> tmpValues[""HOST""] = value <TAB>  <TAB> if key == ""PORT"": <TAB>  <TAB>  <TAB> tmpValues[""PORT""] = value <TAB>  <TAB> if key == ""MSFPAYLOAD"": <TAB>  <TAB>  <TAB> tmpValues[""MSFPAYLOAD""] = value <TAB> resourceValues.append(tmpValues)","if key == ""HOST"" :",121
"def test_finding_characters(self): <TAB> for a in self.dna + self.rna + self.nuc + self.protein: <TAB>  <TAB> for char in self.test_chars: <TAB>  <TAB>  <TAB> str_char = str(char) <MASK> self.assertEqual(a.find(char), str(a).find(str_char)) <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(a.find(char, 2, -2), str(a).find(str_char, 2, -2)) <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(a.rfind(char), str(a).rfind(str_char)) <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(a.rfind(char, 2, -2), str(a).rfind(str_char, 2, -2))","if isinstance ( a , Seq . Seq ) :",191
"def test04_proj(self): <TAB> ""Test PROJ.4 import and export."" <TAB> for s in srlist: <MASK> srs1 = SpatialReference(s.wkt) <TAB>  <TAB>  <TAB> srs2 = SpatialReference(s.proj) <TAB>  <TAB>  <TAB> self.assertEqual(srs1.proj, srs2.proj)",if s . proj :,88
"def recurse_path(path, count=0): <TAB> if count > 10: <TAB>  <TAB> raise ValueError(""too deep recursion"") <TAB> for file in self.env.container.files(parms={""path"": path}): <TAB>  <TAB> self.assert_(file.startswith(path)) <MASK> recurse_path(file, count + 1) <TAB>  <TAB>  <TAB> found_dirs.append(file) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> found_files.append(file)","if file . endswith ( ""/"" ) :",112
"def get_midpanel_data(self, fname): <TAB> pth = os.path.join(os.getcwd(), ""structure"") <TAB> pth = ""%s/%s"" % (pth, fname) <TAB> f = open(pth) <TAB> res = [] <TAB> for l in f.readlines(): <TAB>  <TAB> l = l.strip() <TAB>  <TAB> if not l: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> l = l.split("":"") <MASK> continue <TAB>  <TAB> l = map(strip, l) <TAB>  <TAB> res.append(l) <TAB> return res",if not len ( l ) == 2 :,138
def child_writer(self): <TAB> queue = self.child_queue <TAB> stdin = self.child.stdin <TAB> while True: <TAB>  <TAB> ln = queue.get() <TAB>  <TAB> if ln is None: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> stdin.write(ln) <TAB>  <TAB>  <TAB> stdin.flush() <TAB>  <TAB> except IOError as exc: <MASK> break <TAB>  <TAB>  <TAB> raise,if exc . errno == 32 :,106
"def proc_second(d): <TAB> if len(expanded) == 6: <TAB>  <TAB> if expanded[5][0] != ""*"": <TAB>  <TAB>  <TAB> diff_sec = nearest_diff_method(d.second, expanded[5], 60) <MASK> d += relativedelta(seconds=diff_sec) <TAB>  <TAB>  <TAB>  <TAB> return True, d <TAB> else: <TAB>  <TAB> d += relativedelta(second=0) <TAB> return False, d",if diff_sec is not None and diff_sec != 0 :,119
"def generate_api(self): <TAB> # All plugins are registered with the base plugin. <TAB> for plugin_name, cls in sorted(six.iteritems(self.classes)): <TAB>  <TAB> if not cls.name: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> docstring = self._clean_up_doc(cls.__doc__ or cls.__init__.__doc__ or """") <TAB>  <TAB> # Control the order of entries in the yaml file. <TAB>  <TAB> result = yaml_utils.OrderedYamlDict() <TAB>  <TAB> result[""plugin""] = plugin_name <TAB>  <TAB> result[""name""] = cls.name <TAB>  <TAB> result[""description""] = docstring <TAB>  <TAB> args = self.get_plugin_args(cls) <MASK> result[""args""] = args <TAB>  <TAB> result[""active_modes""] = self.get_active_modes(cls) <TAB>  <TAB> yield result",if args :,193
"def restore_by_tag(self, tag, client=None, leftmost=False): <TAB> with self.channel.conn_or_acquire(client) as client: <TAB>  <TAB> with client.pipeline() as pipe: <TAB>  <TAB>  <TAB> p, _, _ = self._remove_from_indices( <TAB>  <TAB>  <TAB>  <TAB> tag, pipe.hget(self.unacked_key, tag) <TAB>  <TAB>  <TAB> ).execute() <MASK> M, EX, RK = loads(bytes_to_str(p))  # json is unicode <TAB>  <TAB>  <TAB> self.channel._do_restore_message(M, EX, RK, client, leftmost)",if p :,152
"def createAcceleratorTables(self): <TAB> return  ### <TAB> d = self.acceleratorDict <TAB> entries = [] <TAB> for menu in d.keys(): <TAB>  <TAB> aList = d.get(menu) <TAB>  <TAB> for data in aList: <TAB>  <TAB>  <TAB> ch, accel, id, label = data <MASK> # g.trace(ch,id,label) <TAB>  <TAB>  <TAB>  <TAB> entry = wx.AcceleratorEntry(wx.ACCEL_NORMAL, ord(ch), id) <TAB>  <TAB>  <TAB>  <TAB> entries.append(entry) <TAB> table = wx.AcceleratorTable(entries) <TAB> self.menuBar.SetAcceleratorTable(table)",if ch :,163
"def __addFiles(self, dir, subdir, prefix, legacy): <TAB> for item in os.listdir(os.path.join(dir, subdir)): <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> menuentry = MenuEntry(os.path.join(subdir, item), dir, prefix) <TAB>  <TAB>  <TAB> except ParsingError: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> self.cacheEntries[dir].append(menuentry) <TAB>  <TAB>  <TAB> if legacy == True: <TAB>  <TAB>  <TAB>  <TAB> self.cacheEntries[""legacy""].append(menuentry) <TAB>  <TAB> elif os.path.isdir(os.path.join(dir, subdir, item)) and legacy == False: <TAB>  <TAB>  <TAB> self.__addFiles(dir, os.path.join(subdir, item), prefix, legacy)","if os . path . splitext ( item ) [ 1 ] == "".desktop"" :",192
"def extract_pghoard_bb_v2_metadata(fileobj): <TAB> # | in mode to use tarfile's internal stream buffer manager, currently required because our SnappyFile <TAB> # interface doesn't do proper buffering for reads <TAB> with tarfile.open(fileobj=fileobj, mode=""r|"", bufsize=IO_BLOCK_SIZE) as tar: <TAB>  <TAB> for tarinfo in tar: <MASK> tar_meta_bytes = tar.extractfile(tarinfo).read() <TAB>  <TAB>  <TAB>  <TAB> return json.loads(tar_meta_bytes.decode(""utf-8"")) <TAB> raise Exception("".pghoard_tar_metadata.json not found"")","if tarinfo . name == "".pghoard_tar_metadata.json"" :",162
"def _pressed_on_one_roll_active_area(frame): <TAB> trim_limits = edit_data[""trim_limits""] <TAB> if edit_data[""to_side_being_edited""]: <TAB>  <TAB> if frame < trim_limits[""to_start""]: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> if frame > trim_limits[""both_end""]: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> if frame < edit_data[""edit_frame""]: <TAB>  <TAB>  <TAB> return False <TAB> else: <TAB>  <TAB> if frame < trim_limits[""both_start""]: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> if frame > trim_limits[""from_end""]: <TAB>  <TAB>  <TAB> return False <MASK> return False <TAB> return True","if frame > edit_data [ ""edit_frame"" ] :",176
"def _get_db_parameter_group_parameters(self): <TAB> parameter_group_parameters = defaultdict(dict) <TAB> for param_name, value in self.querystring.items(): <MASK> continue <TAB>  <TAB> split_param_name = param_name.split(""."") <TAB>  <TAB> param_id = split_param_name[2] <TAB>  <TAB> param_setting = split_param_name[3] <TAB>  <TAB> parameter_group_parameters[param_id][param_setting] = value[0] <TAB> return parameter_group_parameters.values()","if not param_name . startswith ( ""Parameters.Parameter"" ) :",141
"def dict_parse(d): <TAB> tmpValues = {} <TAB> for key, value in d.iteritems(): <MASK> dict_parse(value) <TAB>  <TAB> if key == ""HOST"": <TAB>  <TAB>  <TAB> tmpValues[""HOST""] = value <TAB>  <TAB> if key == ""PORT"": <TAB>  <TAB>  <TAB> tmpValues[""PORT""] = value <TAB>  <TAB> if key == ""MSFPAYLOAD"": <TAB>  <TAB>  <TAB> tmpValues[""MSFPAYLOAD""] = value <TAB> resourceValues.append(tmpValues)","if isinstance ( value , dict ) :",121
"def getAttribs(self, v): <TAB> ans = [] <TAB> parts = v.b.split(""\n"", 100) <TAB> for i in parts[:99]: <MASK> continue <TAB>  <TAB> words = i.split(None, 1) <TAB>  <TAB> if words and words[0] and words[0][-1] == "":"": <TAB>  <TAB>  <TAB> if len(words) == 1: <TAB>  <TAB>  <TAB>  <TAB> words.append("""") <TAB>  <TAB>  <TAB> ans.append((self, words[0][:-1], words[1], words[0][:-1], str, False)) <TAB> return ans",if not i or i [ 0 ] . isspace ( ) :,144
"def tag(self, sent): <TAB> """"""Tagger with output a la Stanford (no start/end markers)."""""" <TAB> entities = self.entities(sent) <TAB> # dummy entity for nicer code: <TAB> entities.append(((len(sent), len(sent)), ""X"")) <TAB> next_entity = entities.pop(0) <TAB> result = [] <TAB> for i, t in enumerate(sent): <MASK> # assert entities <TAB>  <TAB>  <TAB> next_entity = entities.pop(0) <TAB>  <TAB> if i < next_entity[0][0]: <TAB>  <TAB>  <TAB> result.append((t, ""O"")) <TAB>  <TAB> elif i < next_entity[0][1]: <TAB>  <TAB>  <TAB> result.append((t, next_entity[1])) <TAB> return result",if i >= next_entity [ 0 ] [ 1 ] :,184
"def lines_add_section_len(lines): <TAB> line_prevsection = None <TAB> counter = 0 <TAB> for i, line in enumerate(lines): <MASK> if line_prevsection: <TAB>  <TAB>  <TAB>  <TAB> line_prevsection.section_len = counter <TAB>  <TAB>  <TAB> line_prevsection = line <TAB>  <TAB>  <TAB> counter = 0 <TAB>  <TAB> counter += 1 <TAB> if line_prevsection: <TAB>  <TAB> line_prevsection.section_len = counter <TAB> return lines",if line . section :,117
"def _extract_data(data, kind): <TAB> stripped = [] <TAB> begin_headers = False <TAB> begin_data = False <TAB> for line in data.split(""\n""): <TAB>  <TAB> if not begin_headers and ""BEGIN PGP %s"" % kind in line: <TAB>  <TAB>  <TAB> begin_headers = True <TAB>  <TAB>  <TAB> continue <MASK> begin_data = True <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if ""END PGP %s"" % kind in line: <TAB>  <TAB>  <TAB> return ""\n"".join(stripped) <TAB>  <TAB> if begin_data: <TAB>  <TAB>  <TAB> stripped.append(line) <TAB> return """"","if begin_headers and line . strip ( ) == """" :",154
def CheckRefreshList(self): <TAB> if self.bDirty: <TAB>  <TAB> if self.list is None: <TAB>  <TAB>  <TAB> self.CheckMadeList() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_root = self._MakeRoot() <MASK> self.rootitem.modName = new_root.modName <TAB>  <TAB>  <TAB>  <TAB> self.rootitem.clbrdata = new_root.clbrdata <TAB>  <TAB>  <TAB>  <TAB> self.list.Refresh() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.list.AcceptRoot(self._MakeRoot()) <TAB>  <TAB> self.bDirty = 0,if self . rootitem . __class__ == new_root . __class__ == HierListCLBRModule :,167
"def TryMerge(self, d): <TAB> while 1: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 60: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if tt == 66: <TAB>  <TAB>  <TAB> self.set_index_name(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> self.add_prefix_value(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 160: <TAB>  <TAB>  <TAB> self.set_value_prefix(d.getBoolean()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 74 :,162
def get_formats(): <TAB> with context(): <TAB>  <TAB> format_index = 0 <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> format_index = clipboard.EnumClipboardFormats(format_index) <MASK> break <TAB>  <TAB>  <TAB> yield format_index,if format_index == 0 :,70
"def sync_metadata(self, metadata={}, cfg={}): <TAB> self.metadata.update(metadata) <TAB> if self.metadata: <TAB>  <TAB> headers = self.make_headers(cfg=cfg) <TAB>  <TAB> if not cfg.get(""no_content_length""): <MASK> headers[""Content-Length""] = cfg.get(""set_content_length"") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> headers[""Content-Length""] = 0 <TAB>  <TAB> self.conn.make_request(""POST"", self.path, hdrs=headers, cfg=cfg) <TAB>  <TAB> if self.conn.response.status not in (201, 202): <TAB>  <TAB>  <TAB> raise ResponseError(self.conn.response) <TAB> return True","if cfg . get ( ""set_content_length"" ) :",177
"def pinfo(self, obj, oname="""", formatter=None, info=None, detail_level=0, **kw): <TAB> if isinstance(obj, session_module.PluginRunner): <TAB>  <TAB> # Delegate info generation for PluginRunners. <TAB>  <TAB> result = self.plugin_pinfo(obj, detail_level=detail_level) <MASK> page.page(result) <TAB> else: <TAB>  <TAB> oinspect.Inspector.pinfo( <TAB>  <TAB>  <TAB> self, <TAB>  <TAB>  <TAB> obj, <TAB>  <TAB>  <TAB> oname=oname, <TAB>  <TAB>  <TAB> formatter=formatter, <TAB>  <TAB>  <TAB> info=info, <TAB>  <TAB>  <TAB> detail_level=detail_level, <TAB>  <TAB> )",if result :,160
"def gen_giftcard_secret(length=8): <TAB> charset = list(""ABCDEFGHJKLMNPQRSTUVWXYZ3789"") <TAB> while True: <TAB>  <TAB> code = get_random_string(length=length, allowed_chars=charset) <MASK> return code",if not banned ( code ) and not GiftCard . objects . filter ( secret = code ) . exists ( ) :,88
"def process_event(self, event): <TAB> if event is not None: <TAB>  <TAB> if isinstance(event, KeyboardEvent): <TAB>  <TAB>  <TAB> if event.key_code in [Screen.ctrl(""M""), Screen.ctrl(""J""), ord("" "")]: <TAB>  <TAB>  <TAB>  <TAB> event = None <MASK> if event.buttons != 0: <TAB>  <TAB>  <TAB>  <TAB> if self.is_mouse_over(event, include_label=False): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> event = None <TAB>  <TAB> if event is None: <TAB>  <TAB>  <TAB> self._child = _DatePickerPopup(self, year_range=self._year_range) <TAB>  <TAB>  <TAB> self.frame.scene.add_effect(self._child) <TAB> return event","elif isinstance ( event , MouseEvent ) :",179
"def save(self, *args, **kwargs): <TAB> # Set interface assignment <TAB> if self.cleaned_data[""interface""]: <TAB>  <TAB> self.instance.assigned_object = self.cleaned_data[""interface""] <TAB> ipaddress = super().save(*args, **kwargs) <TAB> # Set as primary for device/VM <TAB> if self.cleaned_data[""is_primary""]: <TAB>  <TAB> parent = self.cleaned_data[""device""] or self.cleaned_data[""virtual_machine""] <MASK> parent.primary_ip4 = ipaddress <TAB>  <TAB> elif self.instance.address.version == 6: <TAB>  <TAB>  <TAB> parent.primary_ip6 = ipaddress <TAB>  <TAB> parent.save() <TAB> return ipaddress",if self . instance . address . version == 4 :,172
def should_print_obj(obj): <TAB> if obj.val is None: <TAB>  <TAB> return False <TAB> if obj.thresh or args.verbose: <TAB>  <TAB> if not match(obj): <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> elif obj.metric: <TAB>  <TAB>  <TAB> if args.verbose or obj.val != 0: <TAB>  <TAB>  <TAB>  <TAB> return True <MASK> return True <TAB> return False,elif check_ratio ( obj . val ) :,101
"def json_conv(val, sformat=None, lev=0): <TAB> if isinstance(val, dict): <TAB>  <TAB> for key, _val in val.items(): <MASK> val[key] = ""none"" <TAB>  <TAB>  <TAB> elif _val is True: <TAB>  <TAB>  <TAB>  <TAB> val[key] = ""true"" <TAB>  <TAB>  <TAB> elif _val is False: <TAB>  <TAB>  <TAB>  <TAB> val[key] = ""false"" <TAB> return val",if _val is None :,112
"def set_request_receipt(self, val): <TAB> self.del_request_receipt() <TAB> if val: <TAB>  <TAB> parent = self.parent() <TAB>  <TAB> parent._set_sub_text(""{%s}request"" % self.namespace, keep=True) <TAB>  <TAB> if not parent[""id""]: <MASK> parent[""id""] = parent.stream.new_id()",if parent . stream :,100
"def split_to_base_quote(exchange_trading_pair: str) -> (Optional[str], Optional[str]): <TAB> base, quote = None, None <TAB> for quote_asset in constants.QUOTES: <MASK> base, quote = ( <TAB>  <TAB>  <TAB>  <TAB> exchange_trading_pair[: -len(quote_asset)], <TAB>  <TAB>  <TAB>  <TAB> exchange_trading_pair[-len(quote_asset) :], <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> break <TAB> return base, quote",if quote_asset == exchange_trading_pair [ - len ( quote_asset ) : ] :,139
"def set_initial_value_for_invited_as( <TAB> apps: StateApps, schema_editor: DatabaseSchemaEditor) -> None: <TAB> PreregistrationUser = apps.get_model(""zerver"", ""PreregistrationUser"") <TAB> for user in PreregistrationUser.objects.all(): <MASK> user.invited_as = 2  # PreregistrationUser.INVITE_AS['REALM_ADMIN'] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> user.invited_as = 1  # PreregistrationUser.INVITE_AS['MEMBER'] <TAB>  <TAB> user.save(update_fields=[""invited_as""])",if user . invited_as_admin :,156
"def check(self): <TAB> response = self.http_request(method=""GET"", path=""/ayefeaturesconvert.js"") <TAB> if response and ""DSL-2750B"" in response.text: <TAB>  <TAB> version = re.findall(r""AYECOM_FWVER=\""(.*?)\"";"", response.text) <MASK> if ( <TAB>  <TAB>  <TAB>  <TAB> utils.Version(""1.01"") <TAB>  <TAB>  <TAB>  <TAB> <= utils.Version(version[0]) <TAB>  <TAB>  <TAB>  <TAB> <= utils.Version(""1.03"") <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> return True  # target is vulnerable <TAB> return False  # target is not vulnerable",if version :,155
"def rmv_parts(self, *parts): <TAB> """"""Remove some Part objects from the circuit."""""" <TAB> for part in parts: <TAB>  <TAB> if part.is_movable(): <MASK> part.circuit = None <TAB>  <TAB>  <TAB>  <TAB> part.hierarchy = None <TAB>  <TAB>  <TAB>  <TAB> self.parts.remove(part) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> logger.warning( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Removing non-existent part {} from this circuit."".format(part.ref) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log_and_raise( <TAB>  <TAB>  <TAB>  <TAB> logger, <TAB>  <TAB>  <TAB>  <TAB> ValueError, <TAB>  <TAB>  <TAB>  <TAB> ""Can't remove part {} from this circuit."".format(part.ref), <TAB>  <TAB>  <TAB> )",if part . circuit == self and part in self . parts :,190
"def _load_folder(self, folderStructure, folder, parentItem): <TAB> items = folderStructure[folder] <TAB> if items[1] is not None: <TAB>  <TAB> items[1].sort() <TAB> for _file in items[1]: <MASK> continue <TAB>  <TAB> subfolder = QTreeWidgetItem(parentItem) <TAB>  <TAB> subfolder.setText(0, _file) <TAB>  <TAB> subfolder.setToolTip(0, os.path.join(folder, _file)) <TAB>  <TAB> subfolder.setIcon(0, QIcon(resources.IMAGES[""tree-folder""])) <TAB>  <TAB> self._load_folder(folderStructure, os.path.join(folder, _file), subfolder)","if _file . startswith ( ""."" ) :",163
"def run(self): <TAB> eid = self.start_episode() <TAB> obs = self.env.reset() <TAB> while True: <TAB>  <TAB> action = self.fixed_action <TAB>  <TAB> self.log_action(eid, obs, action) <TAB>  <TAB> obs, reward, done, info = self.env.step(action) <TAB>  <TAB> self.log_returns(eid, reward, info=info) <MASK> self.end_episode(eid, obs) <TAB>  <TAB>  <TAB> obs = self.env.reset() <TAB>  <TAB>  <TAB> eid = self.start_episode()",if done :,141
def run(self): <TAB> while self.abort == False: <TAB>  <TAB> for job in _jobs: <TAB>  <TAB>  <TAB> if job.status == RENDERING: <TAB>  <TAB>  <TAB>  <TAB> job.callback_object.update_render_status()  # Make sure these methods enter/exit Gtk threads. <TAB>  <TAB> # Handling post-app-close jobs rendering. <MASK> _jobs_render_progress_window.update_render_progress() <TAB>  <TAB> elif _jobs_render_progress_window != None and len(_jobs) == 0: <TAB>  <TAB>  <TAB> _jobs_render_progress_window.jobs_completed() <TAB>  <TAB>  <TAB> self.abort = True <TAB>  <TAB> time.sleep(0.5),if _jobs_render_progress_window != None and len ( _jobs ) != 0 :,180
"def extract_output(self, accumulator: _State) -> Dict[Text, Any]: <TAB> avg_dict = {} <TAB> for at in self._at_vals: <MASK> avg_ndcg = accumulator.ndcg[at] / accumulator.weight <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> avg_ndcg = 0 <TAB>  <TAB> avg_dict[metric_keys.base_key(""ndcg@%d"" % at)] = avg_ndcg <TAB> return avg_dict",if accumulator . weight > 0 :,112
"def get_invalid_modules(): <TAB> modules = [] <TAB> for loc, dirpath in ( <TAB>  <TAB> (MODEL_TESTS_DIR_NAME, MODEL_TEST_DIR), <TAB>  <TAB> (REGRESSION_TESTS_DIR_NAME, REGRESSION_TEST_DIR), <TAB>  <TAB> (CONTRIB_DIR_NAME, CONTRIB_DIR), <TAB> ): <TAB>  <TAB> for f in os.listdir(dirpath): <TAB>  <TAB>  <TAB> if f.startswith(""__init__"") or f.startswith(""."") or f.startswith(""sql""): <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> modules.append((loc, f)) <TAB> return modules","if f . startswith ( ""invalid"" ) :",150
"def iterate(Z): <TAB> shape = len(Z), len(Z[0]) <TAB> N = compute_neighbours(Z) <TAB> for x in range(1, shape[0] - 1): <TAB>  <TAB> for y in range(1, shape[1] - 1): <TAB>  <TAB>  <TAB> if Z[x][y] == 1 and (N[x][y] < 2 or N[x][y] > 3): <TAB>  <TAB>  <TAB>  <TAB> Z[x][y] = 0 <MASK> Z[x][y] = 1 <TAB> return Z",elif Z [ x ] [ y ] == 0 and N [ x ] [ y ] == 3 :,150
"def getArgs(s): <TAB> degree, kwargs = """", {} <TAB> # Find degree <TAB> match = re_degree.match(s) <TAB> if match: <TAB>  <TAB> degree = match.group(0) <MASK> degree = degree[:-1] <TAB>  <TAB> s = s[match.end() :] <TAB> # Find kwargs <TAB> match = re_kwargs.findall(s) <TAB> if match: <TAB>  <TAB> for g1, g2 in match: <TAB>  <TAB>  <TAB> if g1.endswith("",""): <TAB>  <TAB>  <TAB>  <TAB> g1 = g1[:-1] <TAB>  <TAB>  <TAB> key, value = g1.split(""="") <TAB>  <TAB>  <TAB> kwargs[key] = value <TAB> return degree, kwargs","if degree . endswith ( "","" ) :",164
"def on_delete_item(self, widget): <TAB> model, iter = self.get_selection().get_selected() <TAB> if not iter: <TAB>  <TAB> return <TAB> filepath = model.get_value(iter, self.DIR_PATH) <TAB> if filepath != self.dir: <MASK> shutil.rmtree(filepath) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> os.remove(filepath) <TAB>  <TAB> self.emit(""deleted"") <TAB>  <TAB> self.update_model() <TAB> else: <TAB>  <TAB> ErrorDialog(_(""Can't delete the root folder"")).launch()",if os . path . isdir ( filepath ) :,139
"def when_show_tree(self, vl): <TAB> if self.wMessageTree.hidden: <TAB>  <TAB> self.wEmailBody.hidden = True <MASK> self.wEmailBody.h_exit_tree(vl) <TAB>  <TAB> self.wMessageTree.hidden = False <TAB>  <TAB> self.wStatusLine.value = """" <TAB>  <TAB> self.display()",if self . wEmailBody . editing :,98
"def puzzle_results(jsons): <TAB> print() <TAB> print() <TAB> for j in jsons: <MASK> continue <TAB>  <TAB> if j[""name""] != ""puzzle_result"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> res = eval(j[""value""]) <TAB>  <TAB> print() <TAB>  <TAB> print(j[""times""][""main""][""time""]) <TAB>  <TAB> for puz in sorted(res): <TAB>  <TAB>  <TAB> correct_count = len(list(filter(lambda t: t[2], res[puz]))) <TAB>  <TAB>  <TAB> print(""{:>2.0f}% <TAB> {}"".format(correct_count * 100.0 / len(res[puz]), puz))","if j [ ""type"" ] != ""value"" :",166
"def parse_whiteboard(whiteboard): <TAB> bits = {""u"": """", ""c"": """", ""p"": """", ""s"": """"} <TAB> for part in whiteboard.split("" ""): <TAB>  <TAB> part = part.split(""="") <MASK> continue <TAB>  <TAB> if part[0] in bits: <TAB>  <TAB>  <TAB> bits[part[0]] = part[1] <TAB> return bits",if len ( part ) != 2 :,96
"def platform_fix_filename(fname): <TAB> if platform.system() == ""Darwin"": <MASK> return fname[:-2] + ""dylib"" <TAB>  <TAB> return fname.replace("".so."", "".dylib."") <TAB> elif platform.system() == ""Windows"": <TAB>  <TAB> if fname.endswith("".so""): <TAB>  <TAB>  <TAB> (p, f) = os.path.split(fname) <TAB>  <TAB>  <TAB> f = f[3:-2] + ""dll"" <TAB>  <TAB>  <TAB> return os.path.join(p, f) <TAB>  <TAB> if fname.endswith("".a""): <TAB>  <TAB>  <TAB> return fname[:-1] + ""lib"" <TAB> return fname","if fname . endswith ( "".so"" ) :",154
"def append(self, member, tarobj): <TAB> header = """" <TAB> for field in self.header_fields: <TAB>  <TAB> value = getattr(member, field) <TAB>  <TAB> if field == ""type"": <TAB>  <TAB>  <TAB> field = ""typeflag"" <TAB>  <TAB> elif field == ""name"": <MASK> value += ""/"" <TAB>  <TAB> header += ""{0}{1}"".format(field, value) <TAB> h = None <TAB> try: <TAB>  <TAB> if member.size > 0: <TAB>  <TAB>  <TAB> f = tarobj.extractfile(member) <TAB>  <TAB>  <TAB> h = sha256_file(f, header) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> h = sha256_string(header) <TAB> except KeyError: <TAB>  <TAB> h = sha256_string(header) <TAB> self.hashes.append(h)","if member . isdir ( ) and not value . endswith ( ""/"" ) :",195
"def submitBatch(self, *commands): <TAB> for command in commands: <TAB>  <TAB> if not self.__buffer.Submit(command): <TAB>  <TAB>  <TAB> # Undo what we already submitted <TAB>  <TAB>  <TAB> for commandToUndo in reversed(self.__buffer.Commands): <MASK> self.__buffer.Undo() <TAB>  <TAB>  <TAB> return False <TAB> return True",if commandToUndo in commands :,92
"def __init__(self, test, cases): <TAB> self.test = wrap(test) <TAB> self.cases = dict() <TAB> for k, v in cases.items(): <TAB>  <TAB> if isinstance(k, (bool, int)): <TAB>  <TAB>  <TAB> k = Constant(k) <TAB>  <TAB> if not isinstance(k, Constant) and not (isinstance(k, str) and k == ""default""): <TAB>  <TAB>  <TAB> raise TypeError(""Case object is not a Migen constant"") <TAB>  <TAB> if not isinstance(v, _collections_abc.Iterable): <TAB>  <TAB>  <TAB> v = [v] <MASK> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""Not all objects for case {} "" ""are Migen statements"".format(k) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self.cases[k] = v",if not _check_statement ( v ) :,188
"def data_row(values): <TAB> for value in values: <MASK> yield """" <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if isinstance(value, string_types): <TAB>  <TAB>  <TAB> value = ustr(value) <TAB>  <TAB>  <TAB> if any(ch in value for ch in quotable): <TAB>  <TAB>  <TAB>  <TAB> value = quote + value.replace(quote, escaped_quote) + quote <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = cypher_repr(value) <TAB>  <TAB> yield value",if value is None :,116
"def fix_tree(cls, destructive=False): <TAB> super().fix_tree(destructive) <TAB> for node in cls.get_root_nodes(): <TAB>  <TAB> # ancestors_are_public *must* be True for root nodes, or all trees <TAB>  <TAB> # will become non-public <MASK> node.ancestors_are_public = True <TAB>  <TAB>  <TAB> node.save() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> node.set_ancestors_are_public()",if not node . ancestors_are_public :,118
"def _reversed_impl(self, original_state, giveup): <MASK> giveup() <TAB> block = self.right <TAB> while block: <TAB>  <TAB> l, r = 0, n <TAB>  <TAB> if block is self.left: <TAB>  <TAB>  <TAB> l = self.leftndx <TAB>  <TAB> if block is self.right: <TAB>  <TAB>  <TAB> r = self.rightndx + 1 <TAB>  <TAB> for elem in reversed(block[l:r]): <TAB>  <TAB>  <TAB> yield elem <TAB>  <TAB>  <TAB> if self.state != original_state: <TAB>  <TAB>  <TAB>  <TAB> giveup() <TAB>  <TAB> block = block[LFTLNK]",if self . state != original_state :,152
"def aggregate_per_host(requests): <TAB> per_host = dict() <TAB> for link in requests: <TAB>  <TAB> if b""fingerprint"" not in link.meta[b""domain""]: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> host_fprint = link.meta[b""domain""][b""fingerprint""] <MASK> per_host[host_fprint] = [] <TAB>  <TAB> per_host[host_fprint].append(link) <TAB> return per_host",if host_fprint not in per_host :,119
"def set_binstr(self, string): <TAB> for char in string: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Attempting to assign character %s to a %s"" <TAB>  <TAB>  <TAB>  <TAB> % (char, self.__class__.__name__) <TAB>  <TAB>  <TAB> ) <TAB> self._str = string <TAB> self._adjust()",if char not in BinaryValue . _permitted_chars :,89
"def process_z3(self, payload: str): <TAB> if payload.startswith(""CLI command executed""): <TAB>  <TAB> cmd = payload[22:-1] <TAB>  <TAB> if cmd == ""debugprint all_on"" or self.z3buffer is None: <TAB>  <TAB>  <TAB> # reset all buffers <TAB>  <TAB>  <TAB> self.z3buffer = {} <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.z3buffer[cmd] = self.z3buffer[""buffer""] <TAB>  <TAB> self.z3buffer[""buffer""] = """" <MASK> self._process_gateway_info() <TAB> elif self.z3buffer: <TAB>  <TAB> self.z3buffer[""buffer""] += payload","if cmd == ""plugin concentrator print-table"" :",165
"def __init__(self, body="""", status=None, header=None, **headers): <TAB> if header or ""output"" in headers: <TAB>  <TAB> depr(""Call signature changed (for the better)"") <TAB>  <TAB> if header: <TAB>  <TAB>  <TAB> headers.update(header) <MASK> body = headers.pop(""output"") <TAB> super(HTTPResponse, self).__init__(body, status, **headers)","if ""output"" in headers :",101
"def _cleanup_ports(bound_addresses, maxtries=30, sleeptime=2): <TAB> # Wait for the server to bind to the port. <TAB> for bound_address in bound_addresses: <TAB>  <TAB> for _i in range(maxtries): <TAB>  <TAB>  <TAB> sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> sock.connect(bound_address) <TAB>  <TAB>  <TAB> except OSError as e: <MASK> raise <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> time.sleep(sleeptime) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise SystemExit(""Timeout waiting for port."") <TAB>  <TAB> sock.close()",if e . errno != errno . ECONNREFUSED :,178
"def _get_daemon_config_value(self, coin, key): <TAB> try: <TAB>  <TAB> with (Path.home() / f"".{coin}"" / coin).open() as cfg: <TAB>  <TAB>  <TAB> for line in cfg.readlines(): <TAB>  <TAB>  <TAB>  <TAB> line = line.strip() <MASK> continue <TAB>  <TAB>  <TAB>  <TAB> fields = line.split(""="", 1) <TAB>  <TAB>  <TAB>  <TAB> if len(fields) == 2 and fields[0].strip() == key: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return fields[1].strip() <TAB> except OSError as err: <TAB>  <TAB> if err.errno == ENOENT: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> raise","if line . startswith ( ""#"" ) :",160
"def next(self): <TAB> while 1: <TAB>  <TAB> self.fp.seek(self.seekp) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self._search_start() <TAB>  <TAB> except EOFError: <TAB>  <TAB>  <TAB> self.seekp = self.fp.tell() <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> start = self.fp.tell() <TAB>  <TAB> self._search_end() <TAB>  <TAB> self.seekp = stop = self.fp.tell() <MASK> break <TAB> return self.factory(_PartialFile(self.fp, start, stop))",if start != stop :,134
"def filter(self, types=None, keys=None, titles=None): <TAB> types = to_iterable(types) <TAB> keys = to_iterable(keys) <TAB> titles = to_iterable(titles) <TAB> if titles: <TAB>  <TAB> # Flatten titles <TAB>  <TAB> titles = [flatten(x) for x in titles] <TAB> for section in self: <MASK> continue <TAB>  <TAB> if not self.filter_passes(keys, section.key): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if not self.filter_passes(titles, flatten(section.title)): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> yield section","if not self . filter_passes ( types , section . type ) :",154
"def collect_related_fields(self, model, accum, path, seen=None): <TAB> seen = seen or set() <TAB> path_str = ""__"".join(path) <TAB> for field in model._meta.sorted_fields: <MASK> seen.add(field) <TAB>  <TAB>  <TAB> self.collect_related_fields( <TAB>  <TAB>  <TAB>  <TAB> field.rel_model, accum, path + [field.name], seen <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> elif model != self.model: <TAB>  <TAB>  <TAB> accum.setdefault((model, path_str), []) <TAB>  <TAB>  <TAB> accum[(model, path_str)].append(field) <TAB> return accum","if isinstance ( field , ForeignKeyField ) and field not in seen :",163
"def wrap(request, *args, **kwargs): <TAB> ""Wrap"" <TAB> user = request.user.profile <TAB> if ""massform"" in request.POST: <TAB>  <TAB> for key in request.POST: <TAB>  <TAB>  <TAB> if ""mass-report"" in key: <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> report = Report.objects.get(pk=request.POST[key]) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> form = MassActionForm(user, request.POST, instance=report) <MASK> form.save() <TAB>  <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass <TAB> return f(request, *args, **kwargs)","if form . is_valid ( ) and user . has_permission ( report , mode = ""w"" ) :",178
"def OnSelChanging(self, event): <TAB> item = event.GetItem() <TAB> olditem = event.GetOldItem() <TAB> if item: <MASK> olditemtext = ""None"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> olditemtext = self.GetItemText(olditem) <TAB>  <TAB> self.log.write( <TAB>  <TAB>  <TAB> ""OnSelChanging: From %s"" % olditemtext <TAB>  <TAB>  <TAB> + "" To %s"" % self.GetItemText(item) <TAB>  <TAB>  <TAB> + ""\n"" <TAB>  <TAB> ) <TAB> event.Skip()",if not olditem :,138
"def _generate_url_iterable(self, url_iterable): <TAB> parsed_urls = [] <TAB> for url in url_iterable: <TAB>  <TAB> method = not_provided <TAB>  <TAB> if is_list_or_tuple(url): <TAB>  <TAB>  <TAB> url, method = url <MASK> methods = (method,) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> methods = method <TAB>  <TAB> for method in methods: <TAB>  <TAB>  <TAB> method_pattern = re.compile(method) <TAB>  <TAB>  <TAB> url_pattern = self.url_pattern(url) <TAB>  <TAB>  <TAB> parsed_urls.append((url_pattern, method_pattern)) <TAB> return parsed_urls",if not is_list_or_tuple ( method ) :,160
"def asbool(obj): <TAB> if isinstance(obj, string_types): <TAB>  <TAB> obj = obj.strip().lower() <MASK> return True <TAB>  <TAB> elif obj in [""false"", ""no"", ""off"", ""n"", ""f"", ""0""]: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""String is not true/false: %r"" % obj) <TAB> return bool(obj)","if obj in [ ""true"" , ""yes"" , ""on"" , ""y"" , ""t"" , ""1"" ] :",121
"def execute(): <TAB> frappe.reload_doctype(""Task"") <TAB> for t in frappe.get_all(""Task"", fields=[""name""]): <TAB>  <TAB> task = frappe.get_doc(""Task"", t.name) <TAB>  <TAB> task.update_depends_on() <MASK> task.db_set( <TAB>  <TAB>  <TAB>  <TAB> ""depends_on_tasks"", task.depends_on_tasks, update_modified=False <TAB>  <TAB>  <TAB> )",if task . depends_on_tasks :,117
"def connectCB(connect_message, **kwargs): <TAB> messages_history.append(connect_message) <TAB> if not connect_message.status.hasError: <TAB>  <TAB> self.connected_trees[service_name] = connect_message.tid <MASK> sendDFSReferral(connect_message.tid) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sendFindFirst(connect_message.tid, False) <TAB> else: <TAB>  <TAB> errback( <TAB>  <TAB>  <TAB> OperationFailure( <TAB>  <TAB>  <TAB>  <TAB> ""Failed to list %s on %s: Unable to connect to shared device"" <TAB>  <TAB>  <TAB>  <TAB> % (path, service_name), <TAB>  <TAB>  <TAB>  <TAB> messages_history, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> )",if connect_message . payload . optional_support & SMB_TREE_CONNECTX_SUPPORT_DFS :,190
"def __eq__(self, other: [mkosi.CommandLineArguments]) -> bool: <TAB> """"""Compare the configuration returned by parse_args against self.reference_config"""""" <TAB> if len(self.reference_config) != len(other): <TAB>  <TAB> return False <TAB> is_eq = True <TAB> for other_job, other_args in other.items(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> this_args = self.reference_config[other_job] <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> other_args_v = vars(other_args) <MASK> is_eq = False <TAB> return is_eq",if this_args != other_args_v :,160
"def get_msk(self, mode=""in""): <TAB> if self.roi == None: <TAB>  <TAB> return None <TAB> if self.msk is None: <TAB>  <TAB> self.msk = np.zeros(self.size, dtype=np.bool) <TAB> if self.roi.update or mode != self.mskmode: <TAB>  <TAB> self.msk[:] = 0 <MASK> self.roi.sketch(self.msk, w=mode, color=True) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.roi.fill(self.msk, color=True) <TAB>  <TAB> if mode == ""out"": <TAB>  <TAB>  <TAB> self.msk ^= True <TAB>  <TAB> self.roi.update = False <TAB>  <TAB> self.mskmode = mode <TAB> return self.msk","if isinstance ( mode , int ) :",196
"def recv_some(p, t=0.1, e=1, tr=5, stderr=0): <TAB> if tr < 1: <TAB>  <TAB> tr = 1 <TAB> x = time.time() + t <TAB> y = [] <TAB> r = """" <TAB> pr = p.recv <TAB> if stderr: <TAB>  <TAB> pr = p.recv_err <TAB> while time.time() < x or r: <TAB>  <TAB> r = pr() <MASK> if e: <TAB>  <TAB>  <TAB>  <TAB> raise DisconnectException(DISCONNECT_MESSAGE) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif r: <TAB>  <TAB>  <TAB> y.append(r) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> time.sleep(max((x - time.time()) / tr, 0)) <TAB> return """".join(y)",if r is None :,191
def predicate(proc): <TAB> if proc.name() == NailgunExecutor._PROCESS_NAME: <MASK> return NailgunExecutor._PANTS_NG_BUILDROOT_ARG in proc.cmdline() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return any( <TAB>  <TAB>  <TAB>  <TAB> arg.startswith(NailgunExecutor._PANTS_NG_ARG_PREFIX) <TAB>  <TAB>  <TAB>  <TAB> for arg in proc.cmdline() <TAB>  <TAB>  <TAB> ),if not everywhere :,108
"def getCellText(self, row_idx, col): <TAB> if col.id == ""repls-marked"": <TAB>  <TAB> return """" <TAB> assert col.id == ""repls-desc"" <TAB> with self._lock: <TAB>  <TAB> event = self.events[row_idx] <MASK> return ""%s (%d replacements)"" % (event.path, event.length) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return str(event)","if isinstance ( event , findlib2 . ReplaceHitGroup ) :",116
"def _match(self, check): <TAB> """"""Find all the matches for a check dict."""""" <TAB> matches = [] <TAB> tests = {} <TAB> for k, v in iteritems(check): <MASK> tests[k] = CompositeFilter(v) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tests[k] = lambda o: _add_tz(o) == _add_tz(v) <TAB> for rec in itervalues(self._records): <TAB>  <TAB> if self._match_one(rec, tests): <TAB>  <TAB>  <TAB> matches.append(deepcopy(rec)) <TAB> return matches","if isinstance ( v , dict ) :",141
"def julian_valid(date_tuple): <TAB> """"""Checks if date_tuple is a valid date in Julian Calendar"""""" <TAB> day = date_tuple[0] <TAB> month = date_tuple[1] <TAB> valid = True <TAB> try: <TAB>  <TAB> if month > 12: <TAB>  <TAB>  <TAB> valid = False <TAB>  <TAB> elif (date_tuple[2]) % 4 == 0: <TAB>  <TAB>  <TAB> # julian always have leapyear every 4 year <TAB>  <TAB>  <TAB> if day > _leap_days[month - 1]: <TAB>  <TAB>  <TAB>  <TAB> valid = False <MASK> valid = False <TAB> except: <TAB>  <TAB> valid = False <TAB> return valid",elif day > _max_days [ month - 1 ] :,165
"def try_read(path, default=None, apply=None): <TAB> try: <TAB>  <TAB> f = open(path, ""r"") <TAB> except IOError as e: <TAB>  <TAB> if e.errno != errno.ENOENT: <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> return default <TAB> else: <TAB>  <TAB> out = f.read() <TAB>  <TAB> if apply: <MASK> apply = [apply] <TAB>  <TAB>  <TAB> for f in apply: <TAB>  <TAB>  <TAB>  <TAB> out = f(out) <TAB>  <TAB> return out","if not isinstance ( apply , list ) :",127
"def shutdown(cls): <TAB> for attr in (""_cached_client"", ""_cached_pillar_client""): <TAB>  <TAB> client = getattr(cls, attr, None) <TAB>  <TAB> if client is not None: <TAB>  <TAB>  <TAB> # PillarClient and LocalClient objects do not have a destroy method <MASK> client.destroy() <TAB>  <TAB>  <TAB> setattr(cls, attr, None)","if hasattr ( client , ""destroy"" ) :",99
"def display_console(self, request): <TAB> """"""Display a standalone shell."""""" <TAB> if 0 not in self.frames: <MASK> ns = {} <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ns = dict(self.console_init_func()) <TAB>  <TAB> ns.setdefault(""app"", self.app) <TAB>  <TAB> self.frames[0] = _ConsoleFrame(ns) <TAB> is_trusted = bool(self.check_pin_trust(request.environ)) <TAB> return Response( <TAB>  <TAB> render_console_html(secret=self.secret, evalex_trusted=is_trusted), <TAB>  <TAB> mimetype=""text/html"", <TAB> )",if self . console_init_func is None :,160
"def _initialize_weights(self) -> None: <TAB> for m in self.modules(): <TAB>  <TAB> if isinstance(m, nn.Conv2d): <TAB>  <TAB>  <TAB> nn.init.kaiming_normal_(m.weight, mode=""fan_out"", nonlinearity=""relu"") <TAB>  <TAB>  <TAB> if m.bias is not None: <TAB>  <TAB>  <TAB>  <TAB> nn.init.zeros_(m.bias) <MASK> nn.init.ones_(m.weight) <TAB>  <TAB>  <TAB> nn.init.zeros_(m.bias) <TAB>  <TAB> elif isinstance(m, nn.Linear): <TAB>  <TAB>  <TAB> nn.init.kaiming_uniform_(m.weight, mode=""fan_out"", nonlinearity=""sigmoid"") <TAB>  <TAB>  <TAB> nn.init.zeros_(m.bias)","elif isinstance ( m , nn . BatchNorm2d ) :",186
"def run(self): <TAB> for fd in self.stream_iterator: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> chunks = self.concater.iter_chunks(fd, skip_header=self.stream.skip_header) <TAB>  <TAB>  <TAB> for chunk in chunks: <TAB>  <TAB>  <TAB>  <TAB> self.stream.buffer.write(chunk) <MASK> return <TAB>  <TAB> except IOError as err: <TAB>  <TAB>  <TAB> self.error = err <TAB>  <TAB>  <TAB> break <TAB> self.stop()",if not self . running :,121
"def test_longer_random_sequence_of_queue_ops(buffer_type): <TAB> """"""A long random sequence of added and retrieved values"""""" <TAB> q = buffer_type(100, 80) <TAB> for _ in six.moves.xrange(10000): <TAB>  <TAB> if q.can_add(): <TAB>  <TAB>  <TAB> _add_many(q, np.random.random((np.random.randint(1, 10),))) <TAB>  <TAB> assert q.size < 100 + 10 <TAB>  <TAB> for _ in range(np.random.randint(1, 10)): <MASK> break <TAB>  <TAB>  <TAB> # Make sure never get to less than `min_after_retrieve` elements <TAB>  <TAB>  <TAB> assert 80 <= q.size <TAB>  <TAB>  <TAB> _retrieve(q)",if not q . can_retrieve ( ) :,181
"def PopMessage(self, label, arg): <TAB> # type: (str, Optional[str]) -> None <TAB> """"""For synchronous constructs that aren't processes."""""" <TAB> self._Dec() <TAB> buf = self._RichTraceBegin(""<"") <TAB> if buf: <TAB>  <TAB> buf.write(label) <MASK> buf.write("" "") <TAB>  <TAB>  <TAB> buf.write(qsn.maybe_encode(arg)) <TAB>  <TAB> buf.write(""\n"") <TAB>  <TAB> self.f.write(buf.getvalue())",if arg is not None :,124
def focusin(): <TAB> if v is c.p.v: <MASK> # only when needed to avoid scroll jumping <TAB>  <TAB>  <TAB> nf.setPlainText(g.u(v.b)) <TAB>  <TAB> nf.setWindowTitle(v.h) <TAB>  <TAB> nf.dirty = False,"if v . b . encode ( ""utf-8"" ) != nf . toPlainText ( ) :",86
"def check_ps_status(self): <TAB> for i in range(self.ps_num): <TAB>  <TAB> ps_pod = self.client.get_ps_pod(i) <TAB>  <TAB> ps_pod_name = self.client.get_ps_pod_name(i) <TAB>  <TAB> if ps_pod is None: <TAB>  <TAB>  <TAB> logger.error(""PS {} Not Found"".format(ps_pod_name)) <MASK> logger.error(""PS {} {}"".format(ps_pod_name, ps_pod.status.phase))",elif ps_pod . status . phase == PodStatus . FAILED :,141
"def put(self, can_split=False): <TAB> self.line_init() <TAB> self.line_more(""print "") <TAB> if self.dest is None: <TAB>  <TAB> pass <TAB> else: <TAB>  <TAB> self.line_more("">> "") <TAB>  <TAB> self.dest.put(can_split=can_split) <MASK> self.line_more(LIST_SEP, can_break_after=True) <TAB> for node in self.nodes: <TAB>  <TAB> node.put(can_split=can_split) <TAB>  <TAB> self.line_more(LIST_SEP, can_break_after=True) <TAB> self.line_term() <TAB> return self",if self . nodes :,161
"def get_head_response(url, headers=fake_headers): <TAB> try: <TAB>  <TAB> req = Request(url, headers=headers) <TAB>  <TAB> req.get_method = lambda: ""HEAD"" <TAB>  <TAB> response = urlopen(req) <TAB> except IOError as e: <TAB>  <TAB> # if HEAD method is not supported <MASK> req = Request(url, headers=headers) <TAB>  <TAB>  <TAB> response = urlopen(req) <TAB>  <TAB>  <TAB> response.close() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise <TAB> # urllib will follow redirections and it's too much code to tell urllib <TAB> # not to do that <TAB> return response","if ""HTTP Error 405"" in str ( e ) :",158
"def set_result(self, correlation_id, result): <TAB> with self._lock: <TAB>  <TAB> future = self._remove(correlation_id) <TAB>  <TAB> future.set_result(result) <MASK> self._resolving_threadpool.submit(future.run_callback) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> future.run_callback() <TAB>  <TAB> future.timer_stop()",if self . _resolving_threadpool is not None :,102
"def _api_get_repository(self, account_domain, repository_name, tool_name): <TAB> url = self._build_api_url(account_domain, ""repositories/"") <TAB> # Let the exception bubble up. <TAB> results = self._api_get(url) <TAB> for repo in results: <MASK> unfuddle_tool_name = self.TOOL_NAME_MAP.get(repo[""system""]) <TAB>  <TAB>  <TAB> if unfuddle_tool_name == tool_name: <TAB>  <TAB>  <TAB>  <TAB> return repo <TAB> raise RepositoryError(ugettext(""A repository with this name was not found""))","if repo [ ""abbreviation"" ] == repository_name :",157
"def layers_along_path(self, path): <TAB> """"""Yields all layers along a path, not including the root"""""" <TAB> if not path: <TAB>  <TAB> return <TAB> unused_path = list(path) <TAB> layer = self <TAB> while len(unused_path) > 0: <TAB>  <TAB> if not isinstance(layer, group.LayerStack): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> idx = unused_path.pop(0) <MASK> break <TAB>  <TAB> layer = layer[idx] <TAB>  <TAB> yield layer",if not ( 0 <= idx < len ( layer ) ) :,129
"def _checkExpected(self): <TAB> s = self.__bytes__()[self._mark :] <TAB> while self._expecting: <TAB>  <TAB> expr, timer, deferred = self._expecting[0] <MASK> del self._expecting[0] <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for match in expr.finditer(s): <TAB>  <TAB>  <TAB> if timer: <TAB>  <TAB>  <TAB>  <TAB> timer.cancel() <TAB>  <TAB>  <TAB> del self._expecting[0] <TAB>  <TAB>  <TAB> self._mark += match.end() <TAB>  <TAB>  <TAB> s = s[match.end() :] <TAB>  <TAB>  <TAB> deferred.callback(match) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return",if timer and not timer . active ( ) :,162
"def _load(self): <TAB> data = self.parent._data.copy() <TAB> if ""versions"" in data: <TAB>  <TAB> del data[""versions""] <TAB>  <TAB> version_str = self.get(""version"") <TAB>  <TAB> data[""version""] = version_str <TAB>  <TAB> version = Version(version_str) <TAB>  <TAB> overrides = self.parent.version_overrides <TAB>  <TAB> if overrides: <TAB>  <TAB>  <TAB> for range_, data_ in overrides.items(): <MASK> data.update(data_) <TAB>  <TAB>  <TAB> del data[""version_overrides""] <TAB> return data",if version in range_ :,140
"def test_ESPnetDataset_feats_scp( <TAB> feats_scp,): <TAB> dataset = IterableESPnetDataset( <TAB>  <TAB> path_name_type_list=[(feats_scp, ""data2"", ""kaldi_ark"")], <TAB>  <TAB> preprocess=preprocess, <TAB> ) <TAB> for key, data in dataset: <MASK> assert data[""data2""].shape == ( <TAB>  <TAB>  <TAB>  <TAB> 100, <TAB>  <TAB>  <TAB>  <TAB> 80, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if key == ""b"": <TAB>  <TAB>  <TAB> assert data[""data2""].shape == ( <TAB>  <TAB>  <TAB>  <TAB> 150, <TAB>  <TAB>  <TAB>  <TAB> 80, <TAB>  <TAB>  <TAB> )","if key == ""a"" :",157
"def cygpath(path): <TAB> """"""Use :meth:`git.cmd.Git.polish_url()` instead, that works on any environment."""""" <TAB> if not path.startswith((""/cygdrive"", ""//"")): <TAB>  <TAB> for regex, parser, recurse in _cygpath_parsers: <TAB>  <TAB>  <TAB> match = regex.match(path) <TAB>  <TAB>  <TAB> if match: <TAB>  <TAB>  <TAB>  <TAB> path = parser(*match.groups()) <MASK> path = cygpath(path) <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> path = _cygexpath(None, path) <TAB> return path",if recurse :,150
"def _create_examples(self, lines, set_type): <TAB> """"""Creates examples for the training, dev and test sets."""""" <TAB> examples = [] <TAB> for (i, line) in enumerate(lines): <MASK> continue <TAB>  <TAB> guid = ""%s-%s"" % (set_type, i) <TAB>  <TAB> text_a = line[3] <TAB>  <TAB> text_b = line[4] <TAB>  <TAB> label = None if set_type == ""test"" else line[0] <TAB>  <TAB> examples.append( <TAB>  <TAB>  <TAB> InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label) <TAB>  <TAB> ) <TAB> return examples",if i == 0 :,165
"def get_folder_sizes_recursively(self, folder): <TAB> files = os.listdir(folder) <TAB> size = 0 <TAB> for f in files: <MASK> size += self.get_folder_sizes_recursively(folder + ""/"" + f) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> size += os.path.getsize(folder + ""/"" + f) <TAB> return size","if os . path . isdir ( folder + ""/"" + f ) and self . recursive == True :",108
"def _create_decoder(self, n_layers, dropout): <TAB> """"""Create the decoder as a tf.keras.Model."""""" <TAB> input = Input(shape=(self._embedding_dimension,)) <TAB> prev_layer = layers.Stack()(self._max_output_length * [input]) <TAB> for i in range(n_layers): <MASK> prev_layer = Dropout(dropout)(prev_layer) <TAB>  <TAB> prev_layer = GRU(self._embedding_dimension, return_sequences=True)(prev_layer) <TAB> output = Dense(len(self._output_tokens), activation=tf.nn.softmax)(prev_layer) <TAB> return tf.keras.Model(inputs=input, outputs=output)",if dropout > 0.0 :,169
"def add_controls(controls, all_base64): <TAB> lines = [] <TAB> if controls: <TAB>  <TAB> for control in controls: <TAB>  <TAB>  <TAB> line = ""control: "" + control[0] <TAB>  <TAB>  <TAB> line += "" "" + (""true"" if control[1] else ""false"") <MASK> lines.append(_convert_to_ldif(line, control[2], all_base64)) <TAB> return lines",if control [ 2 ] :,107
"def load_records(self, kfi, keyset, count, pos, want=[]): <TAB> values = [] <TAB> try: <TAB>  <TAB> for inc in range(0, count): <TAB>  <TAB>  <TAB> rpos = (pos + inc) % len(keyset) <TAB>  <TAB>  <TAB> rval = keyset.get(rpos, self._UNUSED) <TAB>  <TAB>  <TAB> values.append((rpos, rval)) <TAB>  <TAB>  <TAB> for w in want: <MASK> return values <TAB>  <TAB> return values <TAB> finally: <TAB>  <TAB> with self._lock: <TAB>  <TAB>  <TAB> self.load_factor[kfi] = (self.load_factor[kfi] * 9 + len(values)) / 10",if rval . startswith ( w ) :,170
"def on_task_filter(self, task, config): <TAB> if not config: <TAB>  <TAB> return <TAB> config = self.prepare_config(config) <TAB> for entry in task.entries: <MASK> entry.reject( <TAB>  <TAB>  <TAB>  <TAB> reason=""Had < %d required seeds. (%s)"" <TAB>  <TAB>  <TAB>  <TAB> % (config[""min_seeds""], entry[""torrent_seeds""]) <TAB>  <TAB>  <TAB> )","if ""torrent_seeds"" in entry and entry [ ""torrent_seeds"" ] < config [ ""min_seeds"" ] :",120
"def _dict_merge(d1, d2): <TAB> all_keys = set(d1.keys()) | set(d2.keys()) <TAB> merged = {} <TAB> for k in all_keys: <TAB>  <TAB> if k not in d1 or d1[k] is TOP: <TAB>  <TAB>  <TAB> # don't add it to the dict, which is the same as top <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> elif k not in d2 or d2[k] is TOP: <TAB>  <TAB>  <TAB> # don't add it to the dict, which is the same as top <TAB>  <TAB>  <TAB> pass <MASK> merged[k] = d1[k] <TAB> return merged",elif d1 [ k ] == d2 [ k ] :,165
"def getToken(self, index, data): <TAB> token = self.tokenDictionary.getToken(index) <MASK> index = self.readInt8(data) <TAB>  <TAB> token = self.tokenDictionary.getToken(index, True) <TAB>  <TAB> if not token: <TAB>  <TAB>  <TAB> raise ValueError(""Invalid token %s"" % token) <TAB> return token",if not token :,87
"def loop_once(self): <TAB> self.setup() <TAB> self.wasfailing = self.failures and len(self.failures) <TAB> result = self.runsession() <TAB> failures, reports, collection_failed = result <TAB> if collection_failed: <TAB>  <TAB> pass  # ""Collection failed, keeping previous failure set"" <TAB> else: <TAB>  <TAB> uniq_failures = [] <TAB>  <TAB> for failure in failures: <MASK> uniq_failures.append(failure) <TAB>  <TAB> self.failures = uniq_failures",if failure not in uniq_failures :,131
"def exists(self, path, value): <TAB> """"""check if value exists at path"""""" <TAB> try: <TAB>  <TAB> entry = Yedit.get_entry(self.yaml_dict, path, self.separator) <TAB> except KeyError: <TAB>  <TAB> entry = None <TAB> if isinstance(entry, list): <MASK> return True <TAB>  <TAB> return False <TAB> elif isinstance(entry, dict): <TAB>  <TAB> if isinstance(value, dict): <TAB>  <TAB>  <TAB> rval = False <TAB>  <TAB>  <TAB> for key, val in value.items(): <TAB>  <TAB>  <TAB>  <TAB> if entry[key] != val: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> rval = False <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> rval = True <TAB>  <TAB>  <TAB> return rval <TAB>  <TAB> return value in entry <TAB> return entry == value",if value in entry :,187
"def iterate(self, contextualized_node=None): <TAB> debug.dbg(""iterate"") <TAB> try: <TAB>  <TAB> iter_method = self.py__iter__ <TAB> except AttributeError: <MASK> from jedi.evaluate import analysis <TAB>  <TAB>  <TAB> analysis.add( <TAB>  <TAB>  <TAB>  <TAB> contextualized_node.context, <TAB>  <TAB>  <TAB>  <TAB> ""type-error-not-iterable"", <TAB>  <TAB>  <TAB>  <TAB> contextualized_node.node, <TAB>  <TAB>  <TAB>  <TAB> message=""TypeError: '%s' object is not iterable"" % self, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return iter([]) <TAB> else: <TAB>  <TAB> return iter_method()",if contextualized_node is not None :,158
"def test_exists(self) -> None: <TAB> self.assertIs(self.pathmodule.exists(support.TESTFN), False) <TAB> f = open(support.TESTFN, ""wb"") <TAB> try: <TAB>  <TAB> f.write(b""foo"") <TAB>  <TAB> f.close() <TAB>  <TAB> self.assertIs(self.pathmodule.exists(support.TESTFN), True) <TAB>  <TAB> if not self.pathmodule == genericpath: <TAB>  <TAB>  <TAB> self.assertIs(self.pathmodule.lexists(support.TESTFN), True) <TAB> finally: <MASK> f.close() <TAB>  <TAB> support.unlink(support.TESTFN)",if not f . closed :,147
"def replace_word_size(text: List[str]) -> List[str]: <TAB> """"""Replace WORDSIZE with platform specific word sizes"""""" <TAB> result = [] <TAB> for line in text: <TAB>  <TAB> index = line.find(""WORD_SIZE"") <MASK> # get 'WORDSIZE*n' token <TAB>  <TAB>  <TAB> word_size_token = line[index:].split()[0] <TAB>  <TAB>  <TAB> n = int(word_size_token[10:]) <TAB>  <TAB>  <TAB> replace_str = str(PLATFORM_SIZE * n) <TAB>  <TAB>  <TAB> result.append(line.replace(word_size_token, replace_str)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result.append(line) <TAB> return result",if index != - 1 :,169
"def _diff_constraints(old_values, new_values): <TAB> result = dict() <TAB> for key in CONSTRAINT_KEYS.values(): <TAB>  <TAB> old_value = old_values.get(key) <TAB>  <TAB> new_value = new_values.get(key) <TAB>  <TAB> logger.debug( <TAB>  <TAB>  <TAB> ""_diff_constraint. key=%r, old_value=%r, new_value=%r"", <TAB>  <TAB>  <TAB> key, <TAB>  <TAB>  <TAB> old_value, <TAB>  <TAB>  <TAB> new_value, <TAB>  <TAB> ) <MASK> result[key] = new_value <TAB> return result",if new_value != old_value and new_value is not None :,158
"def _read_into_queue(samples, mapper, queue): <TAB> end = EndSignal() <TAB> try: <TAB>  <TAB> for sample in samples: <MASK> raise ValueError(""sample has None"") <TAB>  <TAB>  <TAB> if len(sample) == 2: <TAB>  <TAB>  <TAB>  <TAB> result = mapper(sample[0], sample[1]) <TAB>  <TAB>  <TAB> elif len(sample) == 3: <TAB>  <TAB>  <TAB>  <TAB> result = mapper(sample[0], sample[1], sample[2]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise Exception(""The sample's length must be 2 or 3."") <TAB>  <TAB>  <TAB> if is_valid(result): <TAB>  <TAB>  <TAB>  <TAB> queue.put(result) <TAB>  <TAB> queue.put(end) <TAB> except: <TAB>  <TAB> queue.put("""") <TAB>  <TAB> six.reraise(*sys.exc_info())",if sample is None :,196
"def _add_index(self, restr_keys): <TAB> # Make sure it's a valid index. <TAB> for key in restr_keys: <MASK> raise ValueError(""Bad restriction: %s"" % key) <TAB> # Create the index. <TAB> index = self._indexes[restr_keys] = tuple({} for x in self._positions()) <TAB> # Add all existing edges to the index. <TAB> for end, edgelist in enumerate(self._edgelists): <TAB>  <TAB> this_index = index[end] <TAB>  <TAB> for edge in edgelist: <TAB>  <TAB>  <TAB> vals = tuple( <TAB>  <TAB>  <TAB>  <TAB> self._get_type_if_possible(getattr(edge, key)()) for key in restr_keys <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> this_index.setdefault(vals, []).append(edge)","if not hasattr ( EdgeI , key ) :",189
"def _connect_and_configure(self, *args, **kwargs): <TAB> self._connection_reconnect(*args, **kwargs) <TAB> with self._reconnect_lock: <MASK> self._configure_on_first_reconnect() <TAB>  <TAB>  <TAB> self.reconnect = self._connection_reconnect <TAB>  <TAB>  <TAB> self._reconnect_mocked = False",if self . _reconnect_mocked :,94
"def __subdomain(self): <TAB> result = [] <TAB> for i in range(1, len(self.domain) - 1): <MASK> result.append(self.domain[:i] + ""."" + self.domain[i:]) <TAB> return result","if self . domain [ i ] not in [ ""-"" , ""."" ] and self . domain [ i - 1 ] not in [ ""-"" , ""."" ] :",88
"def __len__(self): <TAB> res = 0 <TAB> for l, h in self.ranges: <MASK> res += 1 <TAB>  <TAB> elif h is None: <TAB>  <TAB>  <TAB> raise TypeError(""Can't size object; last value not set"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> res += (h - l) + 1 <TAB> return res",if l is None :,85
"def get_analysis_definition(self): <TAB> if not hasattr(self, ""filters""): <TAB>  <TAB> return {} <TAB> fs = {} <TAB> d = {""filter"": fs} <TAB> for filters in self.filters: <TAB>  <TAB> if isinstance(filters, six.string_types): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> fs.update( <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB> f._name: f.get_definition() <TAB>  <TAB>  <TAB>  <TAB> for f in filters <MASK> } <TAB>  <TAB> ) <TAB> return d","if hasattr ( f , ""get_definition"" )",132
"def _read_http_response_line(sock: ssl.SSLSocket) -> str: <TAB> cs = [] <TAB> while True: <TAB>  <TAB> c: str = sock.recv(1).decode(""utf-8"") <TAB>  <TAB> if c == ""\r"": <TAB>  <TAB>  <TAB> break <MASK> cs.append(c) <TAB> return """".join(cs)","if c != ""\n"" :",92
"def copy_tensor(src, dst): <TAB> assert dst.numel() == src.numel() <TAB> if move_eos_to_beginning: <MASK> # if no eos_idx is specified, then use the last token in src <TAB>  <TAB>  <TAB> dst[0] = src[-1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> dst[0] = eos_idx <TAB>  <TAB> dst[1:] = src[:-1] <TAB> else: <TAB>  <TAB> dst.copy_(src)",if eos_idx is None :,118
"def _around(x, y, width, height): <TAB> ps = [] <TAB> for dx in range(-1, 2): <TAB>  <TAB> nx = x + dx <MASK> for dy in range(-1, 2): <TAB>  <TAB>  <TAB>  <TAB> ny = y + dy <TAB>  <TAB>  <TAB>  <TAB> if 0 <= ny < height and (dx != 0 or dy != 0): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ps.append((nx, ny)) <TAB> return ps",if 0 <= nx < width :,109
"def add_job(self, job): <TAB> if self.redis.hexists(self.jobs_key, job.id): <TAB>  <TAB> raise ConflictingIdError(job.id) <TAB> with self.redis.pipeline() as pipe: <TAB>  <TAB> pipe.multi() <TAB>  <TAB> pipe.hset( <TAB>  <TAB>  <TAB> self.jobs_key, <TAB>  <TAB>  <TAB> job.id, <TAB>  <TAB>  <TAB> pickle.dumps(job.__getstate__(), self.pickle_protocol), <TAB>  <TAB> ) <MASK> pipe.zadd( <TAB>  <TAB>  <TAB>  <TAB> self.run_times_key, <TAB>  <TAB>  <TAB>  <TAB> {job.id: datetime_to_utc_timestamp(job.next_run_time)}, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> pipe.execute()",if job . next_run_time :,184
"def train(model, quantizer, device, train_loader, optimizer): <TAB> model.train() <TAB> for batch_idx, (data, target) in enumerate(train_loader): <TAB>  <TAB> data, target = data.to(device), target.to(device) <TAB>  <TAB> optimizer.zero_grad() <TAB>  <TAB> output = model(data) <TAB>  <TAB> loss = F.nll_loss(output, target) <TAB>  <TAB> loss.backward() <TAB>  <TAB> optimizer.step() <MASK> print( <TAB>  <TAB>  <TAB>  <TAB> ""{:2.0f}%  Loss {}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> 100 * batch_idx / len(train_loader), loss.item() <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> )",if batch_idx % 100 == 0 :,176
def resolve(self): <TAB> resolved = [] <TAB> for attribute in self._attributes: <TAB>  <TAB> value = attribute.resolve() <TAB>  <TAB> assert value is not None <MASK> resolved.extend(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> resolved.append(value) <TAB> self._attributes = resolved <TAB> return self,"if isinstance ( value , list ) :",83
"def proc_day_of_month(d): <TAB> if expanded[2][0] != ""*"": <TAB>  <TAB> days = DAYS[month - 1] <TAB>  <TAB> if month == 2 and self.is_leap(year): <TAB>  <TAB>  <TAB> days += 1 <TAB>  <TAB> diff_day = nearest_diff_method(d.day, expanded[2], days) <MASK> if is_prev: <TAB>  <TAB>  <TAB>  <TAB> d += relativedelta(days=diff_day) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> d += relativedelta(days=diff_day, hour=0, minute=0, second=0) <TAB>  <TAB>  <TAB> return True, d <TAB> return False, d",if diff_day is not None and diff_day != 0 :,173
"def clean(destination, recursive): <TAB> """"""Delete a file or directory either locally or on S3."""""" <TAB> if destination[:5] == ""s3://"": <TAB>  <TAB> rm_args = [""aws"", ""s3"", ""rm"", ""--quiet"", destination] <MASK> rm_args.append(""--recursive"") <TAB>  <TAB> subprocess.check_call(rm_args) <TAB> else: <TAB>  <TAB> if recursive: <TAB>  <TAB>  <TAB> shutil.rmtree(destination) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> os.remove(destination)",if recursive :,124
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.set_name(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 16: <TAB>  <TAB>  <TAB> self.set_type(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 24: <TAB>  <TAB>  <TAB> self.set_meaning(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 10 :,150
"def populate_netmodel_combo(vm, combo): <TAB> model = combo.get_model() <TAB> model.clear() <TAB> # [xml value, label] <TAB> model.append([None, _(""Hypervisor default"")]) <TAB> if vm.is_hvm(): <TAB>  <TAB> mod_list = [""rtl8139"", ""ne2k_pci"", ""pcnet"", ""e1000""] <TAB>  <TAB> if vm.get_hv_type() in [""kvm"", ""qemu"", ""test""]: <TAB>  <TAB>  <TAB> mod_list.append(""virtio"") <MASK> mod_list.append(""netfront"") <TAB>  <TAB> mod_list.sort() <TAB>  <TAB> for m in mod_list: <TAB>  <TAB>  <TAB> model.append([m, m])","if vm . get_hv_type ( ) in [ ""xen"" , ""test"" ] :",194
"def _add_font_to_properties(properties: Dict, fonts: List) -> None: <TAB> # Wire up with actual font object <TAB> for font in fonts: <TAB>  <TAB> face = font[""meta""][""font-face""] <MASK> continue <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB> ""font-style"" in face and ""font-style"" in properties <TAB>  <TAB> ):  # Fine if either do not mention style, so defaults to regular or not italic <TAB>  <TAB>  <TAB> if face[""font-style""] != properties[""font-style""]: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> properties[""font""] = font <TAB>  <TAB> return  # One chunk of text can only have one font/variant","if face [ ""font-family"" ] != properties [ ""font-family"" ] :",171
"def run_validators(self, value): <TAB> if value in validators.EMPTY_VALUES: <TAB>  <TAB> return <TAB> errors = [] <TAB> for v in self.validators: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> v(value) <TAB>  <TAB> except ValidationError as e: <TAB>  <TAB>  <TAB> if hasattr(e, ""code"") and e.code in self.error_messages: <TAB>  <TAB>  <TAB>  <TAB> message = self.error_messages[e.code] <MASK> message = message % e.params <TAB>  <TAB>  <TAB>  <TAB> errors.append(message) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> errors.extend(e.messages) <TAB> if errors: <TAB>  <TAB> raise ValidationError(errors)",if e . params :,166
"def reverse(self, data): <TAB> out = {} <TAB> for l in data.split(""\n""): <TAB>  <TAB> line = l.strip() <MASK> prep = line.split(""#"", 1)[0].split("";"", 1)[0].split(""="", 1) <TAB>  <TAB>  <TAB> varname = prep[0].strip() <TAB>  <TAB>  <TAB> val = prep[1].strip() <TAB>  <TAB>  <TAB> out[varname.replace(""-"", ""_"")] = val <TAB> return out","if len ( line ) and line [ 0 ] not in ( ""#"" , "";"" ) :",118
"def is_compressed_variant(path, stat_cache=None): <TAB> if path[-3:] in ("".gz"", "".br""): <TAB>  <TAB> uncompressed_path = path[:-3] <MASK> return os.path.isfile(uncompressed_path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return uncompressed_path in stat_cache <TAB> return False",if stat_cache is None :,89
"def link(computer, name, values): <TAB> """"""Compute the ``link`` property."""""" <TAB> if values == ""none"": <TAB>  <TAB> return None <TAB> else: <TAB>  <TAB> type_, value = values <MASK> return get_link_attribute(computer[""element""], value, computer[""base_url""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return values","if type_ == ""attr()"" :",91
"def _load_pmg_settings(): <TAB> try: <TAB>  <TAB> with open(SETTINGS_FILE, ""rt"") as f: <TAB>  <TAB>  <TAB> d = yaml.safe_load(f) <TAB> except IOError: <TAB>  <TAB> # If there are any errors, default to using environment variables <TAB>  <TAB> # if present. <TAB>  <TAB> d = {} <TAB>  <TAB> for k, v in os.environ.items(): <TAB>  <TAB>  <TAB> if k.startswith(""PMG_""): <TAB>  <TAB>  <TAB>  <TAB> d[k] = v <MASK> d[""PMG_"" + k] = v <TAB> d = d or {} <TAB> return dict(d)","elif k in [ ""VASP_PSP_DIR"" , ""MAPI_KEY"" , ""DEFAULT_FUNCTIONAL"" ] :",172
"def walk_class_hierarchy(clazz, encountered=None): <TAB> """"""Walk class hierarchy, yielding most derived classes first."""""" <TAB> if not encountered: <TAB>  <TAB> encountered = [] <TAB> for subclass in clazz.__subclasses__(): <MASK> encountered.append(subclass) <TAB>  <TAB>  <TAB> # drill down to leaves first <TAB>  <TAB>  <TAB> for subsubclass in walk_class_hierarchy(subclass, encountered): <TAB>  <TAB>  <TAB>  <TAB> yield subsubclass <TAB>  <TAB>  <TAB> yield subclass",if subclass not in encountered :,115
"def conforms_to(self, lang): <TAB> """"""Returns True iff this language conforms to the given `lang`."""""" <TAB> if lang == self.name: <TAB>  <TAB> return True <TAB> if self.conforms_to_bases: <TAB>  <TAB> if lang in self.conforms_to_bases: <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> for base in self.conforms_to_bases: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> base_li = self._db.langinfo_from_lang(base) <TAB>  <TAB>  <TAB> except LangInfoError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> else: <MASK> return True <TAB> return False",if base_li . conforms_to ( lang ) :,166
"def reconnect(self): <TAB> if hasattr(self, ""pub_channel""): <TAB>  <TAB> self.pub_channel.on_recv(None) <MASK> self.pub_channel.close() <TAB>  <TAB> del self.pub_channel <TAB> # if eval_master finds a new master for us, self.connected <TAB> # will be True again on successful master authentication <TAB> master, self.pub_channel = yield self.eval_master(opts=self.opts) <TAB> if self.connected: <TAB>  <TAB> self.opts[""master""] = master <TAB>  <TAB> self.pub_channel.on_recv(self._process_cmd_socket) <TAB>  <TAB> log.info(""Minion is ready to receive requests!"") <TAB> raise salt.ext.tornado.gen.Return(self)","if hasattr ( self . pub_channel , ""close"" ) :",190
"def StoreBlob(self, blob_key, blob_stream): <TAB> """"""Store blob stream."""""" <TAB> content = StringIO.StringIO() <TAB> try: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> block = blob_stream.read(1 << 20) <MASK> break <TAB>  <TAB>  <TAB> content.write(block) <TAB>  <TAB> self.CreateBlob(blob_key, content.getvalue()) <TAB> finally: <TAB>  <TAB> content.close()",if not block :,109
"def get_nested_keys_at(self, level): <TAB> if level == 0: <TAB>  <TAB> return set(self.keys()) <TAB> else: <TAB>  <TAB> keys = set() <TAB>  <TAB> for value in self.values(): <TAB>  <TAB>  <TAB> if isinstance(value, SvDict): <TAB>  <TAB>  <TAB>  <TAB> v_keys = value.get_nested_keys_at(level - 1) <MASK> v_keys = SvDict(value).get_nested_keys_at(level - 1) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> v_keys = set() <TAB>  <TAB>  <TAB> keys.update(v_keys) <TAB>  <TAB> return keys","elif isinstance ( value , dict ) :",160
"def load_vocab(self, vocab_file): <TAB> """"""Loads a vocabulary file into a dictionary."""""" <TAB> vocab = collections.OrderedDict() <TAB> fin = open(vocab_file) <TAB> for num, line in enumerate(fin): <TAB>  <TAB> items = self.convert_to_unicode(line.strip()).split(""\t"") <MASK> break <TAB>  <TAB> token = items[0] <TAB>  <TAB> index = items[1] if len(items) == 2 else num <TAB>  <TAB> token = token.strip() <TAB>  <TAB> vocab[token] = int(index) <TAB> return vocab",if len ( items ) > 2 :,141
"def _add_permitopen(self, option, value): <TAB> """"""Add a permitopen host/port pair"""""" <TAB> try: <TAB>  <TAB> host, port = value.rsplit("":"", 1) <MASK> host = host[1:-1] <TAB>  <TAB> port = None if port == ""*"" else int(port) <TAB> except: <TAB>  <TAB> raise ValueError(""Illegal permitopen value: %s"" % value) from None <TAB> self.options.setdefault(option, set()).add((host, port))","if host . startswith ( ""["" ) and host . endswith ( ""]"" ) :",125
"def add_terms_data(self, terms): <TAB> # With terms query, len(self.fields) is always 1 and the 0'th entry is always a string <TAB> field = self.fields[0] <TAB> for timestamp, buckets in terms.items(): <TAB>  <TAB> for bucket in buckets: <TAB>  <TAB>  <TAB> if bucket[""doc_count""]: <MASK> match = { <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> field: bucket[""key""], <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.rules[""timestamp_field""]: timestamp, <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""new_field"": field, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.add_match(match) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.seen_values[field].append(bucket[""key""])","if bucket [ ""key"" ] not in self . seen_values [ field ] :",192
"def post_process_signature(signature): <TAB> parts = re.split(r""\.(?!\d)"", signature) <TAB> if len(parts) >= 4: <TAB>  <TAB> if parts[1] == ""layers"": <TAB>  <TAB>  <TAB> signature = ""spektral.layers."" + ""."".join(parts[3:]) <MASK> signature = ""spektral.utils."" + ""."".join(parts[3:]) <TAB> return signature","if parts [ 1 ] == ""utils"" :",110
"def is_network_capable(self): <TAB> if self.network_capable == None: <TAB>  <TAB> self.network_capable = virtinst.support.check_conn_support( <TAB>  <TAB>  <TAB> self.vmm, virtinst.support.SUPPORT_CONN_NETWORK <TAB>  <TAB> ) <MASK> logging.debug( <TAB>  <TAB>  <TAB>  <TAB> ""Connection doesn't seem to support network "" <TAB>  <TAB>  <TAB>  <TAB> ""APIs. Skipping all network polling."" <TAB>  <TAB>  <TAB> ) <TAB> return self.network_capable",if self . network_capable is False :,135
"def _indent_at_beg(line): <TAB> count = 0 <TAB> byte = ""X"" <TAB> for byte in line: <MASK> break <TAB>  <TAB> count += 1 <TAB> if byte not in (""-"", ""*"", ""."", ""o"", ""\xe2""): <TAB>  <TAB> return count, 0 <TAB> list_chr = chop_str(line[count:], 1)[1] <TAB> if list_chr in (""-"", ""*"", ""."", ""o"", ""\u2022"", ""\u2023"", ""\u2218""): <TAB>  <TAB> nxt = _indent_at_beg(line[count + len(list_chr) :]) <TAB>  <TAB> nxt = nxt[1] or nxt[0] <TAB>  <TAB> if nxt: <TAB>  <TAB>  <TAB> return count, count + 1 + nxt <TAB> return count, 0","if byte != "" "" :",181
"def destination(self, type, name, arglist): <TAB> classname = ""Function"" <TAB> listname = ""functions"" <TAB> if arglist: <TAB>  <TAB> t, n, m = arglist[0] <TAB>  <TAB> # <TAB>  <TAB> # FindNextComponent is a special case, since it call also be called <TAB>  <TAB> # with None as the argument. Hence, we make it a function <TAB>  <TAB> # <TAB>  <TAB> if t == ""Component"" and m == ""InMode"" and name != ""FindNextComponent"": <TAB>  <TAB>  <TAB> classname = ""Method"" <TAB>  <TAB>  <TAB> listname = ""c_methods"" <MASK> classname = ""Method"" <TAB>  <TAB>  <TAB> listname = ""ci_methods"" <TAB> return classname, listname","elif t == ""ComponentInstance"" and m == ""InMode"" :",178
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 8: <TAB>  <TAB>  <TAB> self.set_data_sent(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,92
"def _update_parameters_by_gradients(self, grads_and_vars): <TAB> """"""Update parameters by gradients received by GRPC"""""" <TAB> grads_and_vars_new = [] <TAB> for grad, var in grads_and_vars: <TAB>  <TAB> # If var is a string, create the grad var pair for <TAB>  <TAB> # ElasticDL embedding <MASK> grads_and_vars_new.append(self._get_embedding_var_and_grad(grad, var)) <TAB>  <TAB>  <TAB> self._has_embedding = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> grads_and_vars_new.append((grad, var)) <TAB> self._opt.apply_gradients(grads_and_vars_new) <TAB> self._update_embedding_param() <TAB> self._delete_slots_and_weights_in_optimizer()","if isinstance ( var , str ) :",196
"def make_boxes_infix(leaves, ops, precedence, grouping, form): <TAB> result = [] <TAB> for index, leaf in enumerate(leaves): <TAB>  <TAB> if index > 0: <TAB>  <TAB>  <TAB> result.append(ops[index - 1]) <TAB>  <TAB> parenthesized = False <TAB>  <TAB> if grouping == ""System`NonAssociative"": <TAB>  <TAB>  <TAB> parenthesized = True <TAB>  <TAB> elif grouping == ""System`Left"" and index > 0: <TAB>  <TAB>  <TAB> parenthesized = True <MASK> parenthesized = True <TAB>  <TAB> leaf_boxes = MakeBoxes(leaf, form) <TAB>  <TAB> leaf = parenthesize(precedence, leaf, leaf_boxes, parenthesized) <TAB>  <TAB> result.append(leaf) <TAB> return Expression(""RowBox"", Expression(""List"", *result))","elif grouping == ""System`Right"" and index == 0 :",190
def hasnext(self): <TAB> while self.needhasnext and not self.eof: <TAB>  <TAB> self.hasnextraw() <TAB>  <TAB> if len(self.containerstack) == 0 and not self.valueisnull: <TAB>  <TAB>  <TAB> if self.valuetid == TID_SYMBOL: <TAB>  <TAB>  <TAB>  <TAB> if self.value == SID_ION_1_0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.needhasnext = True <TAB>  <TAB>  <TAB> elif self.valuetid == TID_STRUCT: <TAB>  <TAB>  <TAB>  <TAB> for a in self.annotations: <MASK> self.parsesymboltable() <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.needhasnext = True <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return not self.eof,if a == SID_ION_SYMBOL_TABLE :,171
"def lift_indexedslices(binary_op, x, y, with_assertions): <TAB> if isinstance(x, tf.IndexedSlices): <TAB>  <TAB> assert isinstance(y, tf.IndexedSlices) <TAB>  <TAB> assertions = list() <MASK> assertions.append(tf.debugging.assert_equal(x=x.indices, y=y.indices)) <TAB>  <TAB> with tf.control_dependencies(control_inputs=assertions): <TAB>  <TAB>  <TAB> return tf.IndexedSlices( <TAB>  <TAB>  <TAB>  <TAB> values=binary_op(x.values, y.values), <TAB>  <TAB>  <TAB>  <TAB> indices=x.indices, <TAB>  <TAB>  <TAB>  <TAB> dense_shape=x.dense_shape, <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> return binary_op(x, y)",if with_assertions :,190
"def handle_email_bounces(): <TAB> """"""Process SES notifications, fetching them from SQS."""""" <TAB> sqs = boto3.resource(""sqs"", region_name=website.app_conf.ses_region) <TAB> ses_queue = sqs.Queue(website.app_conf.ses_feedback_queue_url) <TAB> while True: <TAB>  <TAB> messages = ses_queue.receive_messages( <TAB>  <TAB>  <TAB> WaitTimeSeconds=20, MaxNumberOfMessages=10 <TAB>  <TAB> ) <MASK> break <TAB>  <TAB> for msg in messages: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> _handle_ses_notification(msg) <TAB>  <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB>  <TAB> website.tell_sentry(e, {}) <TAB>  <TAB> time.sleep(1)",if not messages :,188
"def get_interfaces(self): <TAB> result = [] <TAB> for key, data in self.data.iteritems(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> cls = get_interface(key) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> value = safe_execute(cls.to_python, data) <MASK> continue <TAB>  <TAB> result.append((key, value)) <TAB> return OrderedDict( <TAB>  <TAB> (k, v) for k, v in sorted(result, key=lambda x: x[1].get_score(), reverse=True) <TAB> )",if not value :,136
"def mergestore(self, inputstore, templatetext, includefuzzy): <TAB> """"""converts a file to txt format"""""" <TAB> txtresult = templatetext <TAB> # TODO: make a list of blocks of text and translate them individually <TAB> # rather than using replace <TAB> for unit in inputstore.units: <TAB>  <TAB> if unit.isheader(): <TAB>  <TAB>  <TAB> continue <MASK> txtsource = unit.source <TAB>  <TAB>  <TAB> txttarget = self.wrapmessage(unit.target) <TAB>  <TAB>  <TAB> if unit.istranslated(): <TAB>  <TAB>  <TAB>  <TAB> txtresult = txtresult.replace(txtsource, txttarget) <TAB> return txtresult",if not unit . isfuzzy ( ) or includefuzzy :,160
"def search(document, search): <TAB> """"""Search a document for a regex, return success / fail result"""""" <TAB> result = False <TAB> searchre = re.compile(search) <TAB> for element in document.iter(): <MASK> # t (text) elements <TAB>  <TAB>  <TAB> if element.text: <TAB>  <TAB>  <TAB>  <TAB> if searchre.search(element.text): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> result = True <TAB> return result","if element . tag == ""{%s}t"" % nsprefixes [ ""w"" ] :",112
"def isValid(self): <TAB> if self[""nb_color""].value == 0: <TAB>  <TAB> if self[""bpp""].value in (8, 24, 32) and self[""planes""].value == 1: <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> if self[""planes""].value == 4 and self[""bpp""].value == 0: <TAB>  <TAB>  <TAB> return True <TAB> elif self[""nb_color""].value == 16: <MASK> return True <TAB> else: <TAB>  <TAB> return False <TAB> if self[""bpp""].value == 0 and self[""planes""].value == 0: <TAB>  <TAB> return True <TAB> return False","if self [ ""bpp"" ] . value in ( 4 , 16 ) and self [ ""planes"" ] . value == 1 :",162
"def handle(self, *args, **options): <TAB> reverse = options.get(""reverse"", False) <TAB> dry_run = options.get(""dry_run"", False) <TAB> if not dry_run: <TAB>  <TAB> script_utils.add_file_logger(logger, __file__) <TAB> with transaction.atomic(): <MASK> unset_date_retracted() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> set_date_retracted() <TAB>  <TAB> if dry_run: <TAB>  <TAB>  <TAB> raise RuntimeError(""Dry run, transaction rolled back."")",if reverse :,129
"def resolve(self, path): <TAB> match = self.regex.search(path) <TAB> if match: <TAB>  <TAB> # If there are any named groups, use those as kwargs, ignoring <TAB>  <TAB> # non-named groups. Otherwise, pass all non-named arguments as <TAB>  <TAB> # positional arguments. <TAB>  <TAB> kwargs = match.groupdict() <MASK> args = () <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> args = match.groups() <TAB>  <TAB> # In both cases, pass any extra_kwargs as **kwargs. <TAB>  <TAB> kwargs.update(self.default_args) <TAB>  <TAB> return self.callback, args, kwargs",if kwargs :,145
"def annotations_to_instance_types(self, node, annots): <TAB> """"""Get instance types for annotations not present in the members map."""""" <TAB> if annots: <TAB>  <TAB> for name, typ in annots.get_annotations(node): <TAB>  <TAB>  <TAB> contained_type = abstract_utils.match_type_container(typ, ""typing.ClassVar"") <MASK> typ = contained_type <TAB>  <TAB>  <TAB> yield name, typ.get_instance_type(node)",if contained_type :,116
"def get_device_codename(): <TAB> """"""Return the device codename."""""" <TAB> serial = environment.get_value(""ANDROID_SERIAL"") <TAB> devices_output = adb.run_command([""devices"", ""-l""]) <TAB> serial_pattern = r""(^|\s){serial}\s"".format(serial=re.escape(serial)) <TAB> serial_regex = re.compile(serial_pattern) <TAB> for line in devices_output.splitlines(): <TAB>  <TAB> values = line.strip().split() <TAB>  <TAB> if not serial_regex.search(line): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for value in values: <MASK> continue <TAB>  <TAB>  <TAB> device_codename = value.split("":"")[-1] <TAB>  <TAB>  <TAB> if device_codename: <TAB>  <TAB>  <TAB>  <TAB> return device_codename <TAB> # Unable to get code name. <TAB> return """"","if not value . startswith ( ""device:"" ) :",198
"def active_scalars(self) -> Optional[pyvista_ndarray]: <TAB> """"""Return the active scalars as an array."""""" <TAB> field, name = self.active_scalars_info <TAB> try: <TAB>  <TAB> if field == FieldAssociation.POINT: <TAB>  <TAB>  <TAB> return self.point_arrays[name] <MASK> return self.cell_arrays[name] <TAB> except KeyError: <TAB>  <TAB> return None <TAB> return None",if field == FieldAssociation . CELL :,108
"def _progress_alive(self): <TAB> c = self._progressbar <TAB> if not self._downloading: <TAB>  <TAB> c.itemconfig(""gradient"", state=""hidden"") <TAB> else: <TAB>  <TAB> c.itemconfig(""gradient"", state=""normal"") <TAB>  <TAB> x1, y1, x2, y2 = c.bbox(""gradient"") <MASK> c.move(""gradient"", (self._gradient_width * 6) - 4, 0) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> c.move(""gradient"", -4, 0) <TAB>  <TAB> afterid = self.top.after(200, self._progress_alive) <TAB>  <TAB> self._afterid[""_progress_alive""] = afterid",if x1 <= - 100 :,161
"def set_total_incoming_outgoing_value(self): <TAB> self.total_incoming_value = self.total_outgoing_value = 0.0 <TAB> for d in self.get(""items""): <TAB>  <TAB> if d.t_warehouse: <TAB>  <TAB>  <TAB> self.total_incoming_value += flt(d.amount) <MASK> self.total_outgoing_value += flt(d.amount) <TAB> self.value_difference = self.total_incoming_value - self.total_outgoing_value",if d . s_warehouse :,127
"def get_component_output_data_schema(output_table_meta, have_data_label, is_str=False): <TAB> # get schema <TAB> schema = output_table_meta.get_schema() <TAB> if not schema: <TAB>  <TAB> return [""sid""] <TAB> header = [schema.get(""sid_name"", ""sid"")] <TAB> if have_data_label: <TAB>  <TAB> header.append(schema.get(""label_name"")) <TAB> if is_str: <TAB>  <TAB> if not schema.get(""header""): <MASK> return [schema.get(""sid"")] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> header.extend([feature for feature in schema.get(""header"").split("","")]) <TAB> else: <TAB>  <TAB> header.extend(schema.get(""header"", [])) <TAB> return header","if schema . get ( ""sid"" ) :",199
"def _generator(): <TAB> for line in text.splitlines(True):  # True keeps trailing linebreaks <TAB>  <TAB> max_width = min((line.endswith(""\n"") and width + 1 or width), width) <TAB>  <TAB> while len(line) > max_width: <TAB>  <TAB>  <TAB> space = line[: max_width + 1].rfind("" "") + 1 <TAB>  <TAB>  <TAB> if space == 0: <TAB>  <TAB>  <TAB>  <TAB> space = line.find("" "") + 1 <TAB>  <TAB>  <TAB>  <TAB> if space == 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield line <TAB>  <TAB>  <TAB>  <TAB>  <TAB> line = """" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> yield ""%s\n"" % line[: space - 1] <TAB>  <TAB>  <TAB> line = line[space:] <TAB>  <TAB>  <TAB> max_width = min((line.endswith(""\n"") and width + 1 or width), width) <MASK> yield line",if line :,199
"def env(ctx, key): <TAB> """"""Print information about the Rasterio environment."""""" <TAB> with ctx.obj[""env""] as env: <TAB>  <TAB> if key == ""formats"": <TAB>  <TAB>  <TAB> for k, v in sorted(env.drivers().items()): <TAB>  <TAB>  <TAB>  <TAB> click.echo(""{0}: {1}"".format(k, v)) <MASK> click.echo(json.dumps(env.session.credentials)) <TAB>  <TAB> elif key == ""gdal_data"": <TAB>  <TAB>  <TAB> click.echo(os.environ.get(""GDAL_DATA"") or GDALDataFinder().search()) <TAB>  <TAB> elif key == ""proj_data"": <TAB>  <TAB>  <TAB> click.echo(os.environ.get(""PROJ_LIB"") or PROJDataFinder().search())","elif key == ""credentials"" :",183
"def parse(cls, mount_dict, normalize=False, win_host=False): <TAB> if mount_dict.get(""source""): <MASK> raise ConfigurationError(""tmpfs mounts can not specify a source"") <TAB>  <TAB> mount_dict[""source""] = normpath(mount_dict[""source""], win_host) <TAB>  <TAB> if normalize: <TAB>  <TAB>  <TAB> mount_dict[""source""] = normalize_path_for_engine(mount_dict[""source""]) <TAB> return cls(**mount_dict)","if mount_dict [ ""type"" ] == ""tmpfs"" :",125
"def _diff_dict(orig, new): <TAB> """"""Diff a nested dictionary, returning only key/values that differ."""""" <TAB> final = {} <TAB> for k, v in new.items(): <TAB>  <TAB> if isinstance(v, dict): <TAB>  <TAB>  <TAB> v = _diff_dict(orig.get(k, {}), v) <MASK> final[k] = v <TAB>  <TAB> elif v != orig.get(k): <TAB>  <TAB>  <TAB> final[k] = v <TAB> for k, v in orig.items(): <TAB>  <TAB> if k not in new: <TAB>  <TAB>  <TAB> final[k] = None <TAB> return final",if len ( v ) > 0 :,152
"def before_request(self): <TAB> uri = self.args.uri <TAB> try: <TAB>  <TAB> lineno = int(uri) <TAB> except ValueError: <TAB>  <TAB> pass <TAB> else: <TAB>  <TAB> with open(OUTPUT_CACHE_FILEPATH) as f: <TAB>  <TAB>  <TAB> i = 0 <TAB>  <TAB>  <TAB> for line in f: <MASK> uri = line.split(""#"")[0].strip() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB>  <TAB> i += 1 <TAB> self._req.cmd_args = (uri,)",if i == lineno :,129
"def popevent(self, name=None): <TAB> while 1: <MASK> data = self.events.get(timeout=WAIT_TIMEOUT) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> data = self.slp.channel.receive(timeout=WAIT_TIMEOUT) <TAB>  <TAB> ev = EventCall(data) <TAB>  <TAB> if name is None or ev.name == name: <TAB>  <TAB>  <TAB> return ev <TAB>  <TAB> print(""skipping {}"".format(ev))",if self . use_callback :,112
"def forward(self, input_feed, hidden): <TAB> h_1 = [] <TAB> for i, layer in enumerate(self.layers): <TAB>  <TAB> h_1_i = layer(input_feed, hidden[0][i]) <TAB>  <TAB> input_feed = h_1_i <MASK> input_feed = self.dropout(input_feed) <TAB>  <TAB> h_1 += [h_1_i] <TAB> h_1 = torch.stack(h_1) <TAB> return input_feed, (h_1,)",if i + 1 != self . num_layers :,135
"def run_async__await__(coro): <TAB> assert coro.__class__ is types.CoroutineType <TAB> aw = coro.__await__() <TAB> buffer = [] <TAB> result = None <TAB> i = 0 <TAB> while True: <TAB>  <TAB> try: <MASK> buffer.append(next(aw)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> buffer.append(aw.send(None)) <TAB>  <TAB>  <TAB> i += 1 <TAB>  <TAB> except StopIteration as ex: <TAB>  <TAB>  <TAB> result = ex.args[0] if ex.args else None <TAB>  <TAB>  <TAB> break <TAB> return buffer, result",if i % 2 :,142
"def check_runAsUser(spec): <TAB> if ""securityContext"" in spec: <MASK> if spec[""securityContext""][""runAsUser""] >= 10000: <TAB>  <TAB>  <TAB>  <TAB> return ""PASSED"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return ""FAILED"" <TAB> return ""ABSENT""","if ""runAsUser"" in spec [ ""securityContext"" ] :",82
"def __init__( <TAB> self, varname, force_categorical=False, contrast=None, levels=None, origin=None): <TAB> self._varname = varname <TAB> self._force_categorical = force_categorical <TAB> self._contrast = contrast <TAB> self._levels = levels <TAB> self.origin = origin <TAB> if not self._force_categorical: <MASK> raise ValueError(""contrast= requires force_categorical=True"") <TAB>  <TAB> if levels is not None: <TAB>  <TAB>  <TAB> raise ValueError(""levels= requires force_categorical=True"")",if contrast is not None :,128
"def decoder(s, *args, **kwargs): <TAB> r = [] <TAB> decoded = bytearray() <TAB> for c in s: <TAB>  <TAB> if c == ord(""&"") and not decoded: <TAB>  <TAB>  <TAB> decoded.append(ord(""&"")) <TAB>  <TAB> elif c == ord(""-"") and decoded: <MASK> r.append(""&"") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> r.append(modified_unutf7(decoded[1:])) <TAB>  <TAB>  <TAB> decoded = bytearray() <TAB>  <TAB> elif decoded: <TAB>  <TAB>  <TAB> decoded.append(c) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> r.append(chr(c)) <TAB> if decoded: <TAB>  <TAB> r.append(modified_unutf7(decoded[1:])) <TAB> bin_str = """".join(r) <TAB> return (bin_str, len(s))",if len ( decoded ) == 1 :,198
"def deleteChildren(p, cond, dtor=None): <TAB> cull = [child.copy() for child in p.children() if cond(child)] <TAB> if cull: <TAB>  <TAB> cull.reverse() <TAB>  <TAB> for child in cull: <MASK> dtor(child) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> child.doDelete() <TAB>  <TAB> return len(cull) <TAB> return 0",if dtor :,106
"def _ignore_package(self, pkg_name: str) -> None: <TAB> self.manually_excluded_packages_names.append(pkg_name) <TAB> for name in ( <TAB>  <TAB> pkg_name, <TAB>  <TAB> strip_repo_name(pkg_name), <TAB> ): <TAB>  <TAB> if name in self.install_package_names: <TAB>  <TAB>  <TAB> self.install_package_names.remove(name) <MASK> self.not_found_repo_pkgs_names.remove(name)",if name in self . not_found_repo_pkgs_names :,134
"def valid_collection_name_or_error(name: str): <TAB> try: <TAB>  <TAB> if not name: <TAB>  <TAB>  <TAB> raise Exception(""Collection name cannot be blank."") <TAB>  <TAB> parsed = URL.parse(name) <MASK> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> ""Collection names cannot start with '@' symbol. This is reserved for channels claims."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if not parsed.has_stream or parsed.stream.name != name: <TAB>  <TAB>  <TAB> raise Exception(""Collection name has invalid characters."") <TAB> except (TypeError, ValueError): <TAB>  <TAB> raise Exception(""Invalid collection name."")",if parsed . has_channel :,144
"def get(self): <TAB> if self._queue: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> if len(self._queue) == 1: <TAB>  <TAB>  <TAB>  <TAB> return self._queue[0] <TAB>  <TAB>  <TAB> index = random.randint(0, len(self._queue) - 1) <TAB>  <TAB>  <TAB> addr = self._queue[index] <MASK> self._queue[index] = self._queue[len(self._queue) - 1] <TAB>  <TAB>  <TAB>  <TAB> del self._queue[len(self._queue) - 1] <TAB>  <TAB>  <TAB>  <TAB> del self._addr_map[addr] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> return addr <TAB> else: <TAB>  <TAB> return None",if self . _addr_map [ addr ] . is_timeout ( ) :,179
"def tidy(): <TAB> new_dict = {} <TAB> for phrases, pinyins in env[""phrases_dict""].items(): <TAB>  <TAB> pinyins_via_pinyin_dict = get_pinyins_via_pinyin_dict(phrases) <MASK> new_dict[phrases] = pinyins <TAB> return new_dict",if pinyins != pinyins_via_pinyin_dict :,103
"def search(priority=None, target=None, first=False): <TAB> if priority is None: <TAB>  <TAB> priority = DEFAULT_PRIORITY <TAB> available = NAME_TO_RENDERER <TAB> unknown = [i for i in priority if i not in available] <TAB> if unknown: <TAB>  <TAB> raise ValueError(""Unknown renderers provided in priority list: %s"" % unknown) <TAB> found = [] <TAB> for name in priority: <TAB>  <TAB> render_mod = available[name] <TAB>  <TAB> if render_mod.available(target): <TAB>  <TAB>  <TAB> cur = (name, render_mod.Renderer) <MASK> return cur <TAB>  <TAB>  <TAB> found.append(cur) <TAB> return found",if first :,164
"def output_mintime(self): <TAB> """"""Return oldest output file."""""" <TAB> try: <TAB>  <TAB> mintime = min( <TAB>  <TAB>  <TAB> f.mtime.local_or_remote() for f in self.expanded_output if f.exists <TAB>  <TAB> ) <TAB> except ValueError: <TAB>  <TAB> # no existing output <TAB>  <TAB> mintime = None <TAB> if self.benchmark and self.benchmark.exists: <TAB>  <TAB> mintime_benchmark = self.benchmark.mtime.local_or_remote() <MASK> return min(mintime, mintime_benchmark) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return mintime_benchmark <TAB> return mintime",if mintime is not None :,164
"def get_scaffolding_and_config_name(named_config, scaffolding): <TAB> if os.path.exists(named_config): <TAB>  <TAB> path, cfg_name = """", named_config <TAB> else: <TAB>  <TAB> path, _, cfg_name = named_config.rpartition(""."") <MASK> raise KeyError( <TAB>  <TAB>  <TAB>  <TAB> 'Ingredient for named config ""{}"" not found'.format(named_config) <TAB>  <TAB>  <TAB> ) <TAB> scaff = scaffolding[path] <TAB> return scaff, cfg_name",if path not in scaffolding :,135
"def get_parents(obj, objs): <TAB> res = [] <TAB> for address in obj.parents: <MASK> parent = objs[address] <TAB>  <TAB>  <TAB> url = u""#%d"" % address <TAB>  <TAB>  <TAB> if parent.type_str != obj.type_str: <TAB>  <TAB>  <TAB>  <TAB> url = parent.type_str + u"".html"" + url <TAB>  <TAB>  <TAB> entry = u'<a href=""%s"">%d</a>' % (url, address) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> entry = u""%d"" % address <TAB>  <TAB> res.append(entry) <TAB> return res",if address in objs :,144
"def endog_names(self): <TAB> """"""Names of endogenous variables"""""" <TAB> if self._endog_names is not None: <TAB>  <TAB> return self._endog_names <TAB> else: <MASK> return self.data.ynames <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> d = 0 <TAB>  <TAB>  <TAB> n = self.corr.shape[0] - 1 <TAB>  <TAB>  <TAB> while n > 0: <TAB>  <TAB>  <TAB>  <TAB> d += 1 <TAB>  <TAB>  <TAB>  <TAB> n //= 10 <TAB>  <TAB>  <TAB> return [(""var%0"" + str(d) + ""d"") % i for i in range(self.corr.shape[0])]",if self . endog is not None :,151
"def createSensorCode(sensor, eCodes, idx): <TAB> """"""Creates event codes for trial list based on sensors requested."""""" <TAB> idx += 1 <TAB> key = ""event"" + str(idx)  # Get dict key <TAB> eCodes[key] = ""0"" * 12 <TAB> if type(sensor) is str: <TAB>  <TAB> sensor = [ <TAB>  <TAB>  <TAB> sensor, <TAB>  <TAB> ] <TAB> if sensor is not None: <MASK> for sensors in sensor: <TAB>  <TAB>  <TAB>  <TAB> eCodes[key] = ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> eCodes[key][: sensorDict[sensors]] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> + ""1"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> + eCodes[key][sensorDict[sensors] + 1 :] <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return eCodes",if type ( sensor ) in allowedListTypes :,198
"def _extract_filters(self): <TAB> filters = super()._extract_filters() <TAB> filters_str_id = [] <TAB> for filt in filters: <TAB>  <TAB> if filt.field in (""record_id"", ""collection_id"", ""bucket_id""): <MASK> filt = Filter(filt.field, str(filt.value), filt.operator) <TAB>  <TAB> filters_str_id.append(filt) <TAB> return filters_str_id","if isinstance ( filt . value , int ) :",115
"def _get_transformations(self, current_text, indices_to_modify): <TAB> transformed_texts = [] <TAB> for idx in indices_to_modify: <TAB>  <TAB> synonyms = [] <TAB>  <TAB> # try to find a word with synonyms, and deal with edge case where there aren't any <TAB>  <TAB> for attempt in range(7): <TAB>  <TAB>  <TAB> synonyms = self._get_synonyms(random.choice(current_text.words)) <MASK> break <TAB>  <TAB>  <TAB> elif attempt == 6: <TAB>  <TAB>  <TAB>  <TAB> return [current_text] <TAB>  <TAB> random_synonym = random.choice(synonyms) <TAB>  <TAB> transformed_texts.append( <TAB>  <TAB>  <TAB> current_text.insert_text_after_word_index(idx, random_synonym) <TAB>  <TAB> ) <TAB> return transformed_texts",if synonyms :,191
"def unpack(self, generator): <TAB> for index, func_args in enumerate(generator): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> func, args = func_args <MASK> args = (args,) <TAB>  <TAB>  <TAB> yield index, (func, args) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> func, args = func_args[0], func_args[1:] <TAB>  <TAB>  <TAB> yield index, (func, args)","if not isinstance ( args , tuple ) :",109
"def start(*args, **kwargs): <TAB> try: <TAB>  <TAB> ret = func(*args, **kwargs) <TAB> except TypeError as e: <TAB>  <TAB> logger.error( <TAB>  <TAB>  <TAB> ""Function %r at %s:%d got error %r"", <TAB>  <TAB>  <TAB> func.func_name, <TAB>  <TAB>  <TAB> func.__module__, <TAB>  <TAB>  <TAB> func.__code__.co_firstlineno, <TAB>  <TAB>  <TAB> e, <TAB>  <TAB> ) <TAB>  <TAB> raise <TAB> try: <TAB>  <TAB> next(ret) <TAB> except StopIteration: <TAB>  <TAB> return None <TAB> except Exception as e: <MASK> logger.error(""Exception in coroutine"") <TAB>  <TAB>  <TAB> logger.exception(e) <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> e.logged = True <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> raise <TAB> return ret","if not hasattr ( e , ""logged"" ) :",199
"def _extract_from_PYG(self, item, pos_idx): <TAB> num_samples = item.batch.shape[0] <TAB> batch_mask = item.batch == pos_idx <TAB> out_data = {} <TAB> for k in item.keys: <MASK> if item[k].shape[0] == num_samples: <TAB>  <TAB>  <TAB>  <TAB> out_data[k] = item[k][batch_mask] <TAB> return out_data",if torch . is_tensor ( item [ k ] ) and k in self . _saved_keys . keys ( ) :,130
def dismiss_staging_site_warning_if_present(self): <TAB> if self.is_element_present(*self._staging_site_warning_close_button_locator): <MASK> self.selenium.find_element( <TAB>  <TAB>  <TAB>  <TAB> *self._staging_site_warning_close_button_locator <TAB>  <TAB>  <TAB> ).click(),if self . is_element_visible ( * self . _staging_site_warning_close_button_locator ) :,110
"def testExecuteCudaWorker(self): <TAB> dev_id = os.environ.get(""CUDA_VISIBLE_DEVICES"", ""0"").split("","", 1)[0] <TAB> with self._start_worker_process(cuda=True, cuda_device=dev_id) as ( <TAB>  <TAB> pool, <TAB>  <TAB> worker_endpoint, <TAB> ): <TAB>  <TAB> test_ref = pool.create_actor(WorkerProcessTestActor) <TAB>  <TAB> test_ref.run_test(worker_endpoint, calc_device=""cuda"", _tell=True) <TAB>  <TAB> check_time = time.time() <TAB>  <TAB> while not test_ref.get_reply(): <TAB>  <TAB>  <TAB> gevent.sleep(0.1) <MASK> raise TimeoutError(""Check reply timeout"")",if time . time ( ) - check_time > 2000 :,182
def main_sequence(self): <TAB> try: <TAB>  <TAB> self.get_all_packages_info() <TAB>  <TAB> if self.news: <TAB>  <TAB>  <TAB> self.news.print_news() <TAB>  <TAB> if not self.args.noconfirm: <TAB>  <TAB>  <TAB> self.install_prompt() <TAB>  <TAB> self.get_package_builds() <TAB>  <TAB> # @TODO: ask to install optdepends (?) <MASK> self.ask_about_package_conflicts() <TAB>  <TAB> self.review_build_files() <TAB>  <TAB> self.install_packages() <TAB> except self.ExitMainSequence: <TAB>  <TAB> pass,if not self . args . downloadonly :,152
"def _check_ok(self, onempty): <TAB> self.outp.flush() <TAB> rl = """" <TAB> for rl in linereader(self): <TAB>  <TAB> # log('%d got line: %r\n' % (os.getpid(), rl)) <TAB>  <TAB> if not rl:  # empty line <TAB>  <TAB>  <TAB> continue <MASK> return None <TAB>  <TAB> elif rl.startswith(""error ""): <TAB>  <TAB>  <TAB> # log('client: error: %s\n' % rl[6:]) <TAB>  <TAB>  <TAB> return NotOk(rl[6:]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> onempty(rl) <TAB> raise Exception(""server exited unexpectedly; see errors above"")","elif rl == ""ok"" :",166
"def populate_obj(self, obj, name): <TAB> values = getattr(obj, name, None) <TAB> try: <TAB>  <TAB> ivalues = iter(values) <TAB> except TypeError: <TAB>  <TAB> ivalues = iter([]) <TAB> candidates = itertools.chain(ivalues, itertools.repeat(None)) <TAB> _fake = type(str(""_fake""), (object,), {}) <TAB> output = [] <TAB> for field, data in zip(self.entries, candidates): <MASK> fake_obj = _fake() <TAB>  <TAB>  <TAB> fake_obj.data = data <TAB>  <TAB>  <TAB> field.populate_obj(fake_obj, ""data"") <TAB>  <TAB>  <TAB> output.append(fake_obj.data) <TAB> setattr(obj, name, output)",if not self . should_delete ( field ) :,179
"def history_subs(self, tokens, parsed): <TAB> history_found = False <TAB> for t in tokens: <MASK> t.tok = self.stash.runtime.history.search(t.tok) <TAB>  <TAB>  <TAB> history_found = True <TAB> if history_found: <TAB>  <TAB> # The line is set to the string with history replaced <TAB>  <TAB> # Re-parse the line <TAB>  <TAB> line = "" "".join(t.tok for t in tokens) <TAB>  <TAB> if self.debug: <TAB>  <TAB>  <TAB> self.logger.debug(""history found: %s"" % line) <TAB>  <TAB> tokens, parsed = self.stash.runtime.parser.parse(line) <TAB> return tokens, parsed","if t . ttype == ShToken . _CMD and t . tok . startswith ( ""!"" ) :",177
"def last_zero_init(m): <TAB> if isinstance(m, nn.Sequential): <TAB>  <TAB> nn.init.constant_(m[-1].weight, val=0) <MASK> nn.init.constant_(m[-1].bias, 0) <TAB> else: <TAB>  <TAB> nn.init.constant_(m.weight, val=0) <TAB>  <TAB> if hasattr(m, ""bias"") and m.bias is not None: <TAB>  <TAB>  <TAB> nn.init.constant_(m.bias, 0)","if hasattr ( m [ - 1 ] , ""bias"" ) and m [ - 1 ] . bias is not None :",137
"def download_content(repository): <TAB> """"""Download the content of a directory."""""" <TAB> queue = QueueManager() <TAB> contents = gather_files_to_download(repository) <TAB> repository.logger.debug(repository.data.filename) <TAB> if not contents: <TAB>  <TAB> raise HacsException(""No content to download"") <TAB> for content in contents: <TAB>  <TAB> if repository.data.content_in_root and repository.data.filename: <MASK> continue <TAB>  <TAB> queue.add(dowload_repository_content(repository, content)) <TAB> await queue.execute() <TAB> return repository.validate",if content . name != repository . data . filename :,153
"def get_branches(): <TAB> proc = subprocess.Popen( <TAB>  <TAB> [""git"", ""branch"", ""-a"", ""--no-color"", ""--no-column""], stdout=subprocess.PIPE <TAB> ) <TAB> for line in proc.stdout.readlines(): <TAB>  <TAB> line = line.decode(""utf-8"") <TAB>  <TAB> if ""->"" in line:  # Remote HEAD like b'  remotes/origin/HEAD -> origin/master' <TAB>  <TAB>  <TAB> continue <MASK> line = line.split("" "")[1] <TAB>  <TAB> if line.strip().startswith(""remotes/""): <TAB>  <TAB>  <TAB> line = ""/"".join(line.split(""/"")[2:]) <TAB>  <TAB> yield line.strip()","if line . startswith ( ""*"" ) :",157
"def _cleanup(**kwargs): <TAB> if not kwargs: <TAB>  <TAB> return _cleanup_old(**kwargs) <TAB> if ""kubeconfig"" in kwargs: <TAB>  <TAB> kubeconfig = kwargs.get(""kubeconfig"") <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> os.unlink(kubeconfig) <TAB>  <TAB>  <TAB> except (IOError, OSError) as err: <TAB>  <TAB>  <TAB>  <TAB> if err.errno != errno.ENOENT: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> log.exception(err)","if kubeconfig and os . path . basename ( kubeconfig ) . startswith ( ""salt-kubeconfig-"" ) :",121
"def get_content(self, wait_until_cleared_proplist=None): <TAB> with self.get_lock(wait_until_cleared_proplist): <MASK> filename = self.cache.get_cache_filename(self.path) <TAB>  <TAB>  <TAB> return open(filename, mode=""rb+"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.content","if self . store == ""disk"" :",94
def findAllPotentiallyDirtyNodes(self): <TAB> v = self <TAB> c = v.context <TAB> # Set the starting nodes. <TAB> nodes = [] <TAB> newNodes = [v] <TAB> # Add nodes until no more are added. <TAB> while newNodes: <TAB>  <TAB> addedNodes = [] <TAB>  <TAB> nodes.extend(newNodes) <TAB>  <TAB> for v in newNodes: <TAB>  <TAB>  <TAB> for v2 in v.parents: <MASK> addedNodes.append(v2) <TAB>  <TAB> newNodes = addedNodes[:] <TAB> # Remove the hidden VNode. <TAB> if c.hiddenRootNode in nodes: <TAB>  <TAB> nodes.remove(c.hiddenRootNode) <TAB> return nodes,if v2 not in nodes and v2 not in addedNodes :,178
"def __init__(self, base_url, **kwargs): <TAB> if ""policies"" not in kwargs: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Current implementation requires to pass 'config' if you don't pass 'policies'"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> kwargs[""policies""] = self._default_policies(**kwargs) <TAB> super(ARMPipelineClient, self).__init__(base_url, **kwargs)","if ""config"" not in kwargs :",113
"def format_to_text(data): <TAB> deptl = levels_of_list_or_np(data) <TAB> out = """" <TAB> if deptl > 1: <TAB>  <TAB> for i, sub_data in enumerate(data): <TAB>  <TAB>  <TAB> if i > 0: <TAB>  <TAB>  <TAB>  <TAB> out += ""\n"" <TAB>  <TAB>  <TAB> sub_data_len = len(sub_data) - 1 <TAB>  <TAB>  <TAB> for i, d in enumerate(sub_data): <TAB>  <TAB>  <TAB>  <TAB> out += str(d) <MASK> out += ""\n"" <TAB> else: <TAB>  <TAB> for d in data: <TAB>  <TAB>  <TAB> out += str(d) + ""\n"" <TAB> return out",if i < sub_data_len :,173
"def get_or_parse_value(item, supported_values, default=None): <TAB> if isinstance(item, str): <TAB>  <TAB> item = item.lower() <MASK> return supported_values[item] <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return string_to_tuple(item) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> message = 'Invalid value ""{}"", expected one of precomputed: ({}) or list of values'.format( <TAB>  <TAB>  <TAB>  <TAB> item, "", "".join(supported_values.keys()) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> raise ValueError(message) <TAB> if isinstance(item, (float, int)): <TAB>  <TAB> return item <TAB> return default",if item in supported_values :,158
"def openItem(self, player): <TAB> if not self.isOpened: <TAB>  <TAB> self.isOpened = not self.isOpened <MASK> for item in self.contents: <TAB>  <TAB>  <TAB>  <TAB> player.room.addItem(item) <TAB>  <TAB>  <TAB> self.contents = [] <TAB>  <TAB> self.desc = ""open "" + self.desc",if self . contents is not None :,86
"def __get_secondary_ratio(self): <TAB> """"""Return the splitter ratio of the secondary splitter."""""" <TAB> c = self.c <TAB> free_layout = c.free_layout <TAB> if free_layout: <TAB>  <TAB> w = free_layout.get_secondary_splitter() <TAB>  <TAB> if w: <TAB>  <TAB>  <TAB> aList = w.sizes() <MASK> n1, n2 = aList <TAB>  <TAB>  <TAB>  <TAB> ratio = float(n1) / float(n1 + n2) <TAB>  <TAB>  <TAB>  <TAB> return ratio <TAB> return 0.5",if len ( aList ) == 2 :,142
"def set_theme(self, theme, settings): <TAB> for entry in settings: <MASK> continue <TAB>  <TAB> scope_str = entry.get(""scope"") or ""global"" <TAB>  <TAB> scopes = scope_str.split("","") <TAB>  <TAB> settings = entry.get(""settings"") <TAB>  <TAB> if settings is not None: <TAB>  <TAB>  <TAB> for scope in scopes: <TAB>  <TAB>  <TAB>  <TAB> theme.scopes[scope.strip()] = settings","if not isinstance ( entry , dict ) :",107
"def greedy_actions(self): <TAB> with chainer.force_backprop_mode(): <TAB>  <TAB> a = self.mu <MASK> a = F.maximum(self.xp.broadcast_to(self.min_action, a.array.shape), a) <TAB>  <TAB> if self.max_action is not None: <TAB>  <TAB>  <TAB> a = F.minimum(self.xp.broadcast_to(self.max_action, a.array.shape), a) <TAB>  <TAB> return a",if self . min_action is not None :,124
"def list_to_string(lst, det, det_type=""a""): <TAB> """"""Convert a list to a natural language string."""""" <TAB> string = """" <TAB> if len(lst) == 1: <TAB>  <TAB> return ""{}{}"".format(det_type + "" "" if det else """", lst[0]) <TAB> for i in range(len(lst)): <MASK> string = ""{} and {}{}"".format( <TAB>  <TAB>  <TAB>  <TAB> string[:-2], ""{} "".format(det_type) if det else """", lst[i] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> string += ""{}{}, "".format(""{} "".format(det_type) if det else """", lst[i]) <TAB> return string",if i >= ( len ( lst ) - 1 ) :,169
"def encode(self): <TAB> if self.expr in gpregs.expr: <TAB>  <TAB> self.value = gpregs.expr.index(self.expr) <TAB>  <TAB> self.parent.rot5.value = 0 <TAB> elif isinstance(self.expr, ExprOp) and self.expr.op == allshifts[self.index_op]: <TAB>  <TAB> reg, value = self.expr.args <MASK> return False <TAB>  <TAB> self.value = gpregs.expr.index(reg) <TAB>  <TAB> if not isinstance(value, ExprInt): <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> value = int(value) <TAB>  <TAB> if not 0 <= value < 32: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> self.parent.rot5.value = value <TAB> return True",if reg not in gpregs . expr :,191
def show_only_diffs(self): <TAB> visible_rows = [ <TAB>  <TAB> i <TAB>  <TAB> for i in range(self.protocol_model.row_count) <TAB>  <TAB> if not self.ui.tblViewProtocol.isRowHidden(i) <TAB>  <TAB> and i != self.protocol_model.refindex <TAB> ] <TAB> visible_diff_columns = [ <TAB>  <TAB> diff_col <TAB>  <TAB> for i in visible_rows <TAB>  <TAB> for diff_col in self.protocol_model.diff_columns[i] <TAB> ] <TAB> for j in range(self.protocol_model.col_count): <MASK> self.ui.tblViewProtocol.showColumn(j) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.ui.tblViewProtocol.hideColumn(j),if j in visible_diff_columns :,190
"def __setattr__(self, name, val): <TAB> graphics.Label.__setattr__(self, name, val) <TAB> if name in (""text"", ""markup"", ""size"", ""wrap"", ""ellipsize"", ""max_width""): <MASK> self._cached_w, self._cached_h = None, None <TAB>  <TAB> self._cached_wh_w, self._cached_wh_h = None, None","if name != ""max_width"" :",104
"def perform_create(self, serializer): <TAB> try: <TAB>  <TAB> user = self.get_user_from_session() <TAB>  <TAB> code = serializer.validated_data.get(""code"") <TAB>  <TAB> valid = user.check_mfa(code) <MASK> self.request.session[""auth_mfa""] = """" <TAB>  <TAB>  <TAB> raise errors.MFAFailedError(username=user.username, request=self.request) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.request.session[""auth_mfa""] = ""1"" <TAB> except errors.AuthFailedError as e: <TAB>  <TAB> data = {""error"": e.error, ""msg"": e.msg} <TAB>  <TAB> raise ValidationError(data) <TAB> except errors.NeedMoreInfoError as e: <TAB>  <TAB> return Response(e.as_data(), status=200)",if not valid :,191
"def version_from_string(version_str): <TAB> m = _version_re.search(version_str) <TAB> if m: <TAB>  <TAB> g = m.groups() <TAB>  <TAB> if g[2] is None: <TAB>  <TAB>  <TAB> return (int(g[0]), int(g[1]), 0, ""final"", 0) <MASK> return (int(g[0]), int(g[1]), int(g[2]), ""final"", 0) <TAB>  <TAB> return (int(g[0]), int(g[1]), int(g[2]), g[3], int(g[4])) <TAB> raise VersionError( <TAB>  <TAB> ""String '%s' does not match regex '%s'"" % (version_str, _version_re.pattern) <TAB> )",if g [ 3 ] is None :,187
def re_compile(regex): <TAB> try: <TAB>  <TAB> return CACHED_REGEXES[regex] <TAB> except KeyError: <MASK> CACHED_REGEXES.clear() <TAB>  <TAB> compiled_regex = CACHED_REGEXES[regex] = re.compile(regex) <TAB>  <TAB> return compiled_regex,if len ( CACHED_REGEXES ) >= CACHED_REGEXES_MAX_SIZE :,96
"def tamper(payload, **kwargs): <TAB> modifiers = (""/**/"", ""/**//**/"", ""/**//**//**/"") <TAB> retval = """" <TAB> for char in payload: <TAB>  <TAB> num = random.choice([1, 2, 3]) <TAB>  <TAB> if char != "" "": <TAB>  <TAB>  <TAB> retval += char <TAB>  <TAB> if num == 1: <TAB>  <TAB>  <TAB> if char == "" "": <TAB>  <TAB>  <TAB>  <TAB> retval += modifiers[0] <MASK> if char == "" "": <TAB>  <TAB>  <TAB>  <TAB> retval += modifiers[1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if char == "" "": <TAB>  <TAB>  <TAB>  <TAB> retval += modifiers[2] <TAB> return retval",elif num == 2 :,158
"def fixUrl(self, url, useHttps=True): <TAB> # url = str(url) <TAB> if not url.startswith(""http""): <MASK> url = ""/"" + url <TAB>  <TAB> if useHttps: <TAB>  <TAB>  <TAB> return ""https://www.pixiv.net"" + url <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""http://www.pixiv.net"" + url <TAB> return url","if not url . startswith ( ""/"" ) :",105
"def get_named_fields_list(self): <TAB> rval = [] <TAB> named_columns = self.get_column_name_list() <TAB> for fields in self.get_fields(): <TAB>  <TAB> field_dict = {} <TAB>  <TAB> for i, field in enumerate(fields): <TAB>  <TAB>  <TAB> if i == len(named_columns): <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> field_name = named_columns[i] <MASK> field_name = i  # check that this is supposed to be 0 based. <TAB>  <TAB>  <TAB> field_dict[field_name] = field <TAB>  <TAB> rval.append(field_dict) <TAB> return rval",if field_name is None :,159
"def return_connection_handler(nodes, exit_node): <TAB> """"""Connect all return statements to the Exit node."""""" <TAB> for function_body_node in nodes: <TAB>  <TAB> if isinstance(function_body_node, ConnectToExitNode): <MASK> function_body_node.connect(exit_node)",if exit_node not in function_body_node . outgoing :,86
"def create_lun(self, lun_params): <TAB> # Set the mirror switch always on <TAB> lun_params[""MIRRORPOLICY""] = ""1"" <TAB> url = ""/lun"" <TAB> result = self.call(url, lun_params, ""POST"") <TAB> if result[""error""][""code""] == constants.ERROR_VOLUME_ALREADY_EXIST: <TAB>  <TAB> lun_id = self.get_lun_id_by_name(lun_params[""NAME""]) <MASK> return self.get_lun_info(lun_id) <TAB> msg = _(""Create lun error."") <TAB> self._assert_rest_result(result, msg) <TAB> self._assert_data_in_result(result, msg) <TAB> return result[""data""]",if lun_id :,190
"def convert_input_media_array(array): <TAB> media = [] <TAB> files = {} <TAB> for input_media in array: <TAB>  <TAB> if isinstance(input_media, types.InputMedia): <TAB>  <TAB>  <TAB> media_dict = input_media.to_dict() <MASK> key = media_dict[""media""].replace(""attach://"", """") <TAB>  <TAB>  <TAB>  <TAB> files[key] = input_media.media <TAB>  <TAB>  <TAB> media.append(media_dict) <TAB> return json.dumps(media), files","if media_dict [ ""media"" ] . startswith ( ""attach://"" ) :",132
"def process(self): <TAB> for idx, layer in enumerate(self.net.layers): <TAB>  <TAB> param = layer.blobs <TAB>  <TAB> name = self.layer_names[idx] <TAB>  <TAB> if layer.type in self.processors: <TAB>  <TAB>  <TAB> logger.info(""Processing layer {} of type {}"".format(name, layer.type)) <TAB>  <TAB>  <TAB> dic = self.processors[layer.type](idx, name, param) <TAB>  <TAB>  <TAB> self.param_dict.update(dic) <MASK> logger.warn( <TAB>  <TAB>  <TAB>  <TAB> ""{} layer contains parameters but is not supported!"".format(layer.type) <TAB>  <TAB>  <TAB> ) <TAB> return self.param_dict",elif len ( layer . blobs ) != 0 :,164
"def update(self, E, **F): <TAB> # E and F are throwback names to the dict() __doc__ <TAB> with self._lock: <MASK> return <TAB>  <TAB> setitem = self.__setitem__ <TAB>  <TAB> if callable(getattr(E, ""keys"", None)): <TAB>  <TAB>  <TAB> for k in E.keys(): <TAB>  <TAB>  <TAB>  <TAB> setitem(k, E[k]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for k, v in E: <TAB>  <TAB>  <TAB>  <TAB> setitem(k, v) <TAB>  <TAB> for k in F: <TAB>  <TAB>  <TAB> setitem(k, F[k]) <TAB>  <TAB> return",if E is self :,147
"def _get_child_resources(self): <TAB> result = {} <TAB> for child in self.resource.get_children(): <MASK> result[child.name] = child <TAB>  <TAB> elif child.name.endswith("".py"") and child.name != ""__init__.py"": <TAB>  <TAB>  <TAB> name = child.name[:-3] <TAB>  <TAB>  <TAB> result[name] = child <TAB> return result",if child . is_folder ( ) :,99
"def find_script_url(scriptId_or_file): <TAB> # sha = hashlib.sha1(scriptId_or_file_or_url.encode('utf-8')).hexdigest() <TAB> for item in file_to_scriptId: <TAB>  <TAB> if item[""scriptId""].lower() == scriptId_or_file.lower(): <TAB>  <TAB>  <TAB> return item[""url""] <MASK> return item[""url""] <TAB> return None","if item [ ""file"" ] . lower ( ) == scriptId_or_file . lower ( ) :",120
"def get_popup_sample(view): <TAB> add_external_clipboard() <TAB> index = kill_index <TAB> result = [] <TAB> seen = {} <TAB> while True: <TAB>  <TAB> kill = entries[index] <TAB>  <TAB> if kill: <TAB>  <TAB>  <TAB> text = kill.get_sample(view) <TAB>  <TAB>  <TAB> if text not in seen: <TAB>  <TAB>  <TAB>  <TAB> result.append((index, text)) <TAB>  <TAB>  <TAB>  <TAB> seen[text] = True <TAB>  <TAB> index = (index - 1) % kill_ring_size <MASK> break <TAB> return result",if index == kill_index :,138
"def getPath(c, p): <TAB> for n in p.self_and_parents(): <TAB>  <TAB> if n.h.startswith(""@path""): <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> return None  # must have a full fledged @path in parents <TAB> aList = g.get_directives_dict_list(p) <TAB> path = c.scanAtPathDirectives(aList) <TAB> if not isDirNode(p):  # add file name <TAB>  <TAB> h = p.h.split(None, 1) <MASK> path = os.path.join(path, h[1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> path = os.path.join(path, p.h.strip()) <TAB> return path","if h [ 0 ] . startswith ( ""@"" ) and len ( h ) == 2 :",188
"def canonicalize_filenames(self): <TAB> for filename, lineno in self.c.keys(): <TAB>  <TAB> if filename == ""<string>"": <TAB>  <TAB>  <TAB> # Can't do anything useful with exec'd strings, so skip them. <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> f = self.canonical_filename(filename) <MASK> self.cexecuted[f] = {} <TAB>  <TAB> self.cexecuted[f][lineno] = 1 <TAB> self.c = {}",if not self . cexecuted . has_key ( f ) :,121
"def add(self, user): <TAB> assert iwords.IChatClient.providedBy(user), ""{!r} is not a chat client"".format(user) <TAB> if user.name not in self.users: <TAB>  <TAB> additions = [] <TAB>  <TAB> self.users[user.name] = user <TAB>  <TAB> for p in self.users.values(): <MASK> d = defer.maybeDeferred(p.userJoined, self, user) <TAB>  <TAB>  <TAB>  <TAB> d.addErrback(self._ebUserCall, p=p) <TAB>  <TAB>  <TAB>  <TAB> additions.append(d) <TAB>  <TAB> defer.DeferredList(additions).addCallback(self._cbUserCall) <TAB> return defer.succeed(None)",if p is not user :,175
"def _refresh_addon(self) -> None: <TAB> """"""Refresh addon state."""""" <TAB> for addon in self.sys_addons.installed: <TAB>  <TAB> # if watchdog need looking for <TAB>  <TAB> if addon.watchdog or addon.state != AddonState.STARTED: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # if Addon have running actions <MASK> continue <TAB>  <TAB> # Adjust state <TAB>  <TAB> addon.state = AddonState.STOPPED",if addon . in_progress or await addon . is_running ( ) :,122
"def test_df_is_stochastic_parameter(self): <TAB> param = iap.ChiSquare(iap.Choice([1, 10])) <TAB> seen = [0, 0] <TAB> for _ in sm.xrange(1000): <TAB>  <TAB> samples = param.draw_samples((100,)) <TAB>  <TAB> exp = np.mean(samples) <MASK> seen[0] += 1 <TAB>  <TAB> elif 10 - 4.0 < exp < 10 + 4.0: <TAB>  <TAB>  <TAB> seen[1] += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert False <TAB> assert 500 - 100 < seen[0] < 500 + 100 <TAB> assert 500 - 100 < seen[1] < 500 + 100",if 1 - 1.0 < exp < 1 + 1.0 :,172
"def test_read_bytes(self): <TAB> """"""Read a number of bytes from a buffer"""""" <TAB> buf = bytearray(b""ABCDEFghijklm"") <TAB> readsize = 6 <TAB> exp = bytearray(b""ghijklm"") <TAB> expsize = len(exp) <TAB> try: <TAB>  <TAB> (result, _) = utils.read_bytes(buf, readsize) <TAB> except: <TAB>  <TAB> self.fail(""Failed reading bytes using read_bytes."") <TAB> else: <MASK> self.fail( <TAB>  <TAB>  <TAB>  <TAB> ""Wrong result. Expected: '%s' / %d, got '%s'/%d"" <TAB>  <TAB>  <TAB>  <TAB> % (exp, expsize, result, len(result)) <TAB>  <TAB>  <TAB> )",if result != exp or len ( result ) != expsize :,182
"def getRaw(self, idx): <TAB> if idx < 0 or self.m_stringOffsets == [] or idx >= len(self.m_stringOffsets): <TAB>  <TAB> return None <TAB> offset = self.m_stringOffsets[idx].get_value() <TAB> length = self.getShort(self.m_strings, offset) <TAB> data = """" <TAB> while length > 0: <TAB>  <TAB> offset += 2 <TAB>  <TAB> # Unicode character <TAB>  <TAB> data += unichr(self.getShort(self.m_strings, offset)) <TAB>  <TAB> # FIXME <MASK> data = data[:-1] <TAB>  <TAB> length -= 1 <TAB> return data","if data [ - 1 ] == ""&"" :",157
"def __new__(cls, name, bases, d): <TAB> rv = type.__new__(cls, name, bases, d) <TAB> if ""methods"" not in d: <TAB>  <TAB> methods = set(rv.methods or []) <TAB>  <TAB> for key in d: <TAB>  <TAB>  <TAB> if key in http_method_funcs: <TAB>  <TAB>  <TAB>  <TAB> methods.add(key.upper()) <TAB>  <TAB> # if we have no method at all in there we don't want to <TAB>  <TAB> # add a method list.  (This is for instance the case for <TAB>  <TAB> # the baseclass or another subclass of a base method view <TAB>  <TAB> # that does not introduce new methods). <MASK> rv.methods = sorted(methods) <TAB> return rv",if methods :,168
"def iterfillleft(table, missing): <TAB> it = iter(table) <TAB> hdr = next(it) <TAB> yield tuple(hdr) <TAB> for row in it: <TAB>  <TAB> outrow = list(reversed(row)) <TAB>  <TAB> for i, _ in enumerate(outrow): <MASK> outrow[i] = outrow[i - 1] <TAB>  <TAB> yield tuple(reversed(outrow))",if i > 0 and outrow [ i ] == missing and outrow [ i - 1 ] != missing :,121
"def logger_isa(l, p, max=1000): <TAB> this, seen = l, set() <TAB> for _ in range(max): <TAB>  <TAB> if this == p: <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <MASK> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Logger {0!r} parents recursive"".format(l.name), <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> seen.add(this) <TAB>  <TAB>  <TAB> this = this.parent <TAB>  <TAB>  <TAB> if not this: <TAB>  <TAB>  <TAB>  <TAB> break <TAB> else:  # pragma: no cover <TAB>  <TAB> raise RuntimeError(""Logger hierarchy exceeds {0}"".format(max)) <TAB> return False",if this in seen :,161
"def dev_test1(input_dir): <TAB> input_path = Path(input_dir) <TAB> dir_names = pathex.get_all_dir_names(input_path) <TAB> for dir_name in io.progress_bar_generator(dir_names, desc=""Processing""): <TAB>  <TAB> img_paths = pathex.get_image_paths(input_path / dir_name) <TAB>  <TAB> for filename in img_paths: <TAB>  <TAB>  <TAB> filepath = Path(filename) <TAB>  <TAB>  <TAB> dflimg = DFLIMG.x(filepath) <MASK> raise ValueError",if dflimg is None :,145
"def __call__(self, exception=True): <TAB> """"""Evaluate the expression"""""" <TAB> try: <TAB>  <TAB> ans = self._coef <TAB>  <TAB> for n in self._evaluate_arglist(self._numerator, exception=exception): <TAB>  <TAB>  <TAB> ans *= n <TAB>  <TAB> for n in self._evaluate_arglist(self._denominator, exception=exception): <TAB>  <TAB>  <TAB> ans /= n <TAB>  <TAB> return ans <TAB> except (TypeError, ValueError): <MASK> raise <TAB>  <TAB> return None",if exception :,113
"def resolve_none(self, data): <TAB> # replace None to '_' <TAB> for sent_idx in range(len(data)): <TAB>  <TAB> for tok_idx in range(len(data[sent_idx])): <TAB>  <TAB>  <TAB> for feat_idx in range(len(data[sent_idx][tok_idx])): <MASK> data[sent_idx][tok_idx][feat_idx] = ""_"" <TAB> return data",if data [ sent_idx ] [ tok_idx ] [ feat_idx ] is None :,120
"def prepare_exog(exog): <TAB> k_exog = 0 <TAB> if exog is not None: <TAB>  <TAB> exog_is_using_pandas = _is_using_pandas(exog, None) <MASK> exog = np.asarray(exog) <TAB>  <TAB> # Make sure we have 2-dimensional array <TAB>  <TAB> if exog.ndim == 1: <TAB>  <TAB>  <TAB> if not exog_is_using_pandas: <TAB>  <TAB>  <TAB>  <TAB> exog = exog[:, None] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> exog = pd.DataFrame(exog) <TAB>  <TAB> k_exog = exog.shape[1] <TAB> return (k_exog, exog)",if not exog_is_using_pandas :,159
"def generate_text_for_vocab(self, data_dir, tmp_dir): <TAB> files = [os.path.join(tmp_dir, f) for f in self.TRAIN_FILES] <TAB> inputs_file, targets_file = files <TAB> for i, sample in enumerate( <TAB>  <TAB> text_problems.text2text_txt_iterator(inputs_file, targets_file) <TAB> ): <TAB>  <TAB> yield sample[""inputs""] <TAB>  <TAB> yield sample[""targets""] <MASK> break",if self . max_samples_for_vocab and ( i + 1 ) >= self . max_samples_for_vocab :,143
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 11: <TAB>  <TAB>  <TAB> self.add_item().TryMerge(d) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 34: <TAB>  <TAB>  <TAB> self.set_name_space(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 42: <TAB>  <TAB>  <TAB> length = d.getVarInt32() <TAB>  <TAB>  <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB>  <TAB>  <TAB> d.skip(length) <TAB>  <TAB>  <TAB> self.mutable_override().TryMerge(tmp) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,197
"def loadInfo(self): <TAB> self._pendingEntries = [] <TAB> self._leadingLinesCount = 0 <TAB> try: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> wordDefi = self.nextPair() <TAB>  <TAB>  <TAB> if not wordDefi: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> word, defi = wordDefi <MASK> self._pendingEntries.append(Entry(word, defi)) <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> self._leadingLinesCount += 1 <TAB>  <TAB>  <TAB> word = self.fixInfoWord(word) <TAB>  <TAB>  <TAB> if not word: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> self._glos.setInfo(word, defi) <TAB> except StopIteration: <TAB>  <TAB> pass",if not self . isInfoWord ( word ) :,179
"def __init_children(self, node): <TAB> if self.has_children: <TAB>  <TAB> idx = 0 <TAB>  <TAB> tagname = ""%sproperty"" % self.ns <TAB>  <TAB> children = list(node) <MASK> for c in children: <TAB>  <TAB>  <TAB>  <TAB> if c.tag == tagname: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> idx += 1 <TAB>  <TAB>  <TAB>  <TAB>  <TAB> p = self._create_child(c, self, self.depth + 1) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.children.append(p) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if idx == self.num_declared_children: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> p.mark_as_last_child()",if children is not None :,160
"def eval(self, ctx): <TAB> value = ctx.stack.pop() <TAB> name = ctx.stack.pop() <TAB> left = ctx.stack.pop() <TAB> typ = type(left) <TAB> if typ in PRIMITIVES: <TAB>  <TAB> prop = to_string(name) <TAB>  <TAB> if typ == NULL_TYPE: <TAB>  <TAB>  <TAB> raise MakeError(""TypeError"", ""Cannot set property '%s' of null"" % prop) <MASK> raise MakeError(""TypeError"", ""Cannot set property '%s' of undefined"" % prop) <TAB>  <TAB> # just ignore... <TAB> else: <TAB>  <TAB> left.put_member(name, value) <TAB> ctx.stack.append(value)",elif typ == UNDEFINED_TYPE :,168
"def matches(self, shape): <TAB> assert isinstance(shape, BufferStructure) <TAB> if ""..."" not in self.shape and shape.nr_dims != len(self.shape): <TAB>  <TAB> return False <TAB> if ""..."" in self.shape and shape.nr_dims < len(self.shape): <TAB>  <TAB> return False <TAB> for s, t in zip(shape.shape, self.shape): <MASK> continue <TAB>  <TAB> if t == ""F"" and isinstance(s, int): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if t == ""..."": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if t != s: <TAB>  <TAB>  <TAB> return False <TAB> return True",if t == s :,153
"def _replace_conditional(match, string): <TAB> """"""Replaces a conditional match in a transformation."""""" <TAB> conditional_match = _CONDITIONAL.search(string) <TAB> while conditional_match: <TAB>  <TAB> start = conditional_match.start() <TAB>  <TAB> end = _find_closing_brace(string, start + 4) <TAB>  <TAB> args = _split_conditional(string[start + 4 : end - 1]) <TAB>  <TAB> rv = """" <MASK> rv = unescape(_replace_conditional(match, args[0])) <TAB>  <TAB> elif len(args) > 1: <TAB>  <TAB>  <TAB> rv = unescape(_replace_conditional(match, args[1])) <TAB>  <TAB> string = string[:start] + rv + string[end:] <TAB>  <TAB> conditional_match = _CONDITIONAL.search(string) <TAB> return string",if match . group ( int ( conditional_match . group ( 1 ) ) ) :,199
"def _verify_readline(self, readline, expected): <TAB> all = [] <TAB> while True: <TAB>  <TAB> # short readlines <TAB>  <TAB> line = readline(5) <MASK> if len(line) < 5: <TAB>  <TAB>  <TAB>  <TAB> self.assertTrue(line.endswith(b""\n"")) <TAB>  <TAB> all.append(line) <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB> break <TAB> self.assertEqual(b"""".join(all), expected)","if line and line != b""foo"" :",115
"def path_select_files(paths, pattern=""*.xml""): <TAB> if not paths: <TAB>  <TAB> paths = [REPORT_DIR] <TAB> selected = [] <TAB> for pathname in paths: <TAB>  <TAB> if os.path.isdir(pathname): <TAB>  <TAB>  <TAB> for root, dirs, files in os.walk(pathname): <TAB>  <TAB>  <TAB>  <TAB> for filename in files: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if fnmatch(filename, pattern): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> filename2 = os.path.join(root, filename) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> selected.append(os.path.normpath(filename2)) <MASK> selected.append(pathname) <TAB> return selected","elif os . path . isfile ( pathname ) and fnmatch ( pathname , pattern ) :",167
"def check_2nd_arg(d, ind): <TAB> d = d[ind[0] :] <TAB> for t, i, (n, r), _, line in d: <MASK> return 0 <TAB>  <TAB> elif t == token.NAME: <TAB>  <TAB>  <TAB> self.known_dicts_in_mkv.append((i, (n, r))) <TAB>  <TAB>  <TAB> return 0 <TAB>  <TAB> elif t == token.STRING or t == token.NUMBER: <TAB>  <TAB>  <TAB> raise IndexCreatorValueException( <TAB>  <TAB>  <TAB>  <TAB> ""Second return value of make_key_value function has to be a dictionary!"", <TAB>  <TAB>  <TAB>  <TAB> self.cnt_line_nr(line, 1), <TAB>  <TAB>  <TAB> )","if i == ""{"" or i is None :",169
"def _get_element_ends_with_newline(self, element): <TAB> if element.tail: <TAB>  <TAB> return element.tail.endswith(""\n"") <TAB> elif element.tag in (""li"", ""h""): <TAB>  <TAB> return True  # implicit newline <TAB> else: <TAB>  <TAB> children = list(element) <TAB>  <TAB> if children: <TAB>  <TAB>  <TAB> return self._get_element_ends_with_newline(children[-1])  # recurs <MASK> return element.text.endswith(""\n"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False  # empty element like image",elif element . text :,139
"def _to_rst(args, app_desc, heading_level=""~""): <TAB> rst = StringIO() <TAB> schema = app_desc.schema <TAB> for key, value in schema.app_schema.items(): <TAB>  <TAB> default = None if ""default"" not in value else value[""default""] <TAB>  <TAB> if default is True: <TAB>  <TAB>  <TAB> default = ""true"" <MASK> default = ""false"" <TAB>  <TAB> option = schema.get_app_option(key) <TAB>  <TAB> option_value = OptionValue(key, default, option) <TAB>  <TAB> _write_option_rst(args, rst, key, heading_level, option_value) <TAB> print(rst.getvalue())",elif default is False :,163
"def close(self): <TAB> """"""Closes the connection to the email server."""""" <TAB> if self.connection is None: <TAB>  <TAB> return <TAB> try: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.connection.quit() <TAB>  <TAB> except (ssl.SSLError, smtplib.SMTPServerDisconnected): <TAB>  <TAB>  <TAB> # This happens when calling quit() on a TLS connection <TAB>  <TAB>  <TAB> # sometimes, or when the connection was already disconnected <TAB>  <TAB>  <TAB> # by the server. <TAB>  <TAB>  <TAB> self.connection.close() <TAB>  <TAB> except smtplib.SMTPException: <MASK> return <TAB>  <TAB>  <TAB> raise <TAB> finally: <TAB>  <TAB> self.connection = None",if self . fail_silently :,158
"def run(self): <TAB> if self.check(): <TAB>  <TAB> print_success(""Target seems to be vulnerable"") <TAB>  <TAB> path = ""/../../../../..{}"".format(self.filename) <TAB>  <TAB> response = self.http_request(method=""GET"", path=path) <MASK> print_error(""Exploit failed - could not read response"") <TAB>  <TAB>  <TAB> return <TAB>  <TAB> print_status(""Reading file: {}"".format(self.filename)) <TAB>  <TAB> if response.text: <TAB>  <TAB>  <TAB> print_info(response.text) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print_status(""File seems to be empty"") <TAB> else: <TAB>  <TAB> print_error(""Exploit failed - target seems to be not vulnerable"")",if response is None :,171
"def setup_child_rollout_worker(): <TAB> nonlocal lock <TAB> nonlocal child_rollout_worker <TAB> nonlocal inference_thread <TAB> with lock: <MASK> (child_rollout_worker, inference_thread) = _create_embedded_rollout_worker( <TAB>  <TAB>  <TAB>  <TAB> rollout_worker.creation_args(), report_data <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> child_rollout_worker.set_weights(rollout_worker.get_weights())",if child_rollout_worker is None :,129
"def _get_vod_streams(self, params): <TAB> manifest_url = params.get(""autoURL"") <TAB> if not manifest_url: <TAB>  <TAB> return <TAB> res = http.get(manifest_url) <TAB> manifest = http.json(res, schema=_vod_manifest_schema) <TAB> streams = {} <TAB> for params in manifest[""alternates""]: <TAB>  <TAB> name = ""{0}p"".format(params[""height""]) <TAB>  <TAB> stream = self._create_flv_playlist(params[""template""]) <TAB>  <TAB> streams[name] = stream <TAB>  <TAB> failover = params.get(""failover"") <MASK> stream = self._create_flv_playlist(failover[0]) <TAB>  <TAB>  <TAB> streams[name + ""_alt""] = stream <TAB> return streams",if failover :,181
"def run(): <TAB> try: <TAB>  <TAB> result = func(*args, **kwargs) <TAB>  <TAB> if result is None: <TAB>  <TAB>  <TAB> result = () <TAB>  <TAB> elif not isinstance(result, tuple): <TAB>  <TAB>  <TAB> result = (result,) <MASK> sublime.set_timeout(functools.partial(finish, args[0], *result), 0) <TAB> finally: <TAB>  <TAB> func.running = 0",if finish :,100
"def set_global_trayicon(classic=False): <TAB> global GLOBAL_TRAYICON <TAB> if AppIndicator and not classic: <TAB>  <TAB> cls = AppIndicatorTrayIcon <TAB> else: <TAB>  <TAB> cls = StatusIconTrayIcon <TAB> if GLOBAL_TRAYICON and isinstance(GLOBAL_TRAYICON, cls): <TAB>  <TAB> pass <TAB> else: <TAB>  <TAB> new = cls() <TAB>  <TAB> ZIM_APPLICATION.add_window(new) <MASK> GLOBAL_TRAYICON.destroy() <TAB>  <TAB> GLOBAL_TRAYICON = new",if GLOBAL_TRAYICON :,140
"def _api_auth(name, output, kwargs): <TAB> """"""API: accepts output"""""" <TAB> auth = ""None"" <TAB> if not cfg.disable_key(): <TAB>  <TAB> auth = ""badkey"" <TAB>  <TAB> key = kwargs.get(""key"", """") <TAB>  <TAB> if not key: <TAB>  <TAB>  <TAB> auth = ""apikey"" <TAB>  <TAB> else: <MASK> auth = ""nzbkey"" <TAB>  <TAB>  <TAB> if key == cfg.api_key(): <TAB>  <TAB>  <TAB>  <TAB> auth = ""apikey"" <TAB> elif cfg.username() and cfg.password(): <TAB>  <TAB> auth = ""login"" <TAB> return report(output, keyword=""auth"", data=auth)",if key == cfg . nzb_key ( ) :,164
"def interact_model(config: Union[str, Path, dict]) -> None: <TAB> """"""Start interaction with the model described in corresponding configuration file."""""" <TAB> model = build_model(config) <TAB> while True: <TAB>  <TAB> args = [] <TAB>  <TAB> for in_x in model.in_x: <TAB>  <TAB>  <TAB> args.append((input(""{}::"".format(in_x)),)) <TAB>  <TAB>  <TAB> # check for exit command <MASK> return <TAB>  <TAB> pred = model(*args) <TAB>  <TAB> if len(model.out_params) > 1: <TAB>  <TAB>  <TAB> pred = zip(*pred) <TAB>  <TAB> print("">>"", *pred)","if args [ - 1 ] [ 0 ] in { ""exit"" , ""stop"" , ""quit"" , ""q"" } :",169
"def expire_tool(self, tool_id): <TAB> with self._lock: <MASK> config_filename = self._tool_paths_by_id[tool_id] <TAB>  <TAB>  <TAB> del self._hash_by_tool_paths[config_filename] <TAB>  <TAB>  <TAB> del self._tool_paths_by_id[tool_id] <TAB>  <TAB>  <TAB> del self._tools_by_path[config_filename] <TAB>  <TAB>  <TAB> if tool_id in self._new_tool_ids: <TAB>  <TAB>  <TAB>  <TAB> self._new_tool_ids.remove(tool_id)",if tool_id in self . _tool_paths_by_id :,150
"def force_handle_meta_x_ua_compatible(self): <TAB> for meta in self.window.doc.doc.find_all(""meta""): <TAB>  <TAB> http_equiv = meta.get(""http-equiv"", None) <TAB>  <TAB> if http_equiv is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if not http_equiv.lower() in (""x-ua-compatible"",): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> content = meta.get(""content"", None) <MASK> continue <TAB>  <TAB> self.handle_meta_x_ua_compatible(http_equiv, content)",if content is None :,138
"def _post_data_initialization(self, Y=None): <TAB> if Y is not None: <TAB>  <TAB> if self.label_encoder is None: <TAB>  <TAB>  <TAB> self.label_encoder = self._target_encoder() <MASK> self.label_encoder.fit(Y) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> Y_fit = list(itertools.islice(Y(), 10000)) <TAB>  <TAB>  <TAB>  <TAB> self.label_encoder.fit(Y_fit) <TAB>  <TAB> self.config.pad_idx = self.pad_idx <TAB>  <TAB> target_dim = self.label_encoder.target_dim <TAB>  <TAB> self.lm_loss_coef = self.config.lm_loss_coef if target_dim is not None else 1.0 <TAB>  <TAB> self.target_dim = target_dim",if not callable ( Y ) :,194
"def _validate_password(self, password): <TAB> if not (6 < len(password) < 13): <TAB>  <TAB> raise ValueError(""Password must be 7-12 characters long"") <TAB> has_lower = has_upper = has_number = has_invalid = False <TAB> for char in password: <TAB>  <TAB> if char.islower(): <TAB>  <TAB>  <TAB> has_lower = True <MASK> has_upper = True <TAB>  <TAB> elif char.isdigit(): <TAB>  <TAB>  <TAB> has_number = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> has_invalid = True <TAB>  <TAB>  <TAB> break <TAB> if has_invalid or not (has_lower and has_upper and has_number): <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> ""Password must be a combination of lowercase "" <TAB>  <TAB>  <TAB> ""and uppercase letters and numbers"" <TAB>  <TAB> )",elif char . isupper ( ) :,191
"def get_primary_source(self, reflist): <TAB> ret = """" <TAB> if reflist: <TAB>  <TAB> for handle in reflist: <TAB>  <TAB>  <TAB> citation = self.db.get_citation_from_handle(handle) <TAB>  <TAB>  <TAB> src_handle = citation.get_reference_handle() <TAB>  <TAB>  <TAB> source = self.db.get_source_from_handle(src_handle) <TAB>  <TAB>  <TAB> if source: <MASK> ret = ret + "", "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ret = ret + source.get_title() <TAB> return ret","if ret != """" :",141
"def handle(self, **options): <TAB> for path in options[""path""]: <MASK> path = settings.FILE_CACHE_DIR <TAB>  <TAB> os.system(r'find %s -type f \! -iname ""\."" -mmin +0 -delete' % path)","if path == ""default"" :",72
"def _parse_env_var(self, value): <TAB> items = value.split("","") <TAB> result = {} <TAB> for item in items: <MASK> raise ConfigurationError( <TAB>  <TAB>  <TAB>  <TAB> ""Expected dict string in form 'k1:v1,k2:v2,...kN:vN': %s"" % value <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> k, v = item.split("":"", 1) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> v = int(v) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> v = float(v) <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> result[k] = v <TAB> return result","if "":"" not in item :",167
"def get_flavor_backend(model, build_docker=True, **kwargs): <TAB> from mlflow.pyfunc.backend import PyFuncBackend <TAB> from mlflow.rfunc.backend import RFuncBackend <TAB> _flavor_backends = {pyfunc.FLAVOR_NAME: PyFuncBackend, ""crate"": RFuncBackend} <TAB> for flavor_name, flavor_config in model.flavors.items(): <TAB>  <TAB> if flavor_name in _flavor_backends: <TAB>  <TAB>  <TAB> backend = _flavor_backends[flavor_name](flavor_config, **kwargs) <MASK> return flavor_name, backend <TAB> return None, None",if build_docker and backend . can_build_image ( ) or backend . can_score_model ( ) :,181
"def find_objects(nested, types): <TAB> found = [] <TAB> stack = [nested] <TAB> while len(stack) > 0: <TAB>  <TAB> it = stack.pop() <TAB>  <TAB> if isinstance(it, types): <TAB>  <TAB>  <TAB> found.append(it) <TAB>  <TAB>  <TAB> continue <MASK> stack.extend(list(it)[::-1]) <TAB>  <TAB> elif isinstance(it, dict): <TAB>  <TAB>  <TAB> stack.extend(list(it.values())[::-1]) <TAB> return found","if isinstance ( it , ( list , tuple , set ) ) :",126
"def _get_request_token(self, access_type=None): <TAB> try: <TAB>  <TAB> url = self._get_oauth_url(""request_token"") <MASK> url += ""?x_auth_access_type=%s"" % access_type <TAB>  <TAB> return self.oauth.fetch_request_token(url) <TAB> except Exception as e: <TAB>  <TAB> raise TweepError(e)",if access_type :,100
"def test_basebackups_replica_local_tar_pgespresso( <TAB> self, capsys, recovery_db, pghoard, tmpdir): <TAB> conn_str = pgutil.create_connection_string(recovery_db.user) <TAB> with psycopg2.connect(conn_str) as conn: <TAB>  <TAB> conn.autocommit = True <TAB>  <TAB> cursor = conn.cursor() <TAB>  <TAB> cursor.execute( <TAB>  <TAB>  <TAB> ""SELECT 1 FROM pg_available_extensions WHERE name = 'pgespresso' AND default_version >= '1.2'"" <TAB>  <TAB> ) <MASK> pytest.skip(""pgespresso not available"") <TAB> self._test_basebackups( <TAB>  <TAB> capsys, recovery_db, pghoard, tmpdir, ""local-tar"", replica=True <TAB> )",if not cursor . fetchone ( ) :,193
"def __lt__(self, other): <TAB> """"""Test less than."""""" <TAB> if isinstance(other, Atom): <MASK> return self.parent < other.parent <TAB>  <TAB> order_s = self._sorting_keys.get(self.name, 4) <TAB>  <TAB> order_o = self._sorting_keys.get(other.name, 4) <TAB>  <TAB> if order_s != order_o: <TAB>  <TAB>  <TAB> return order_s < order_o <TAB>  <TAB> elif self.name != other.name: <TAB>  <TAB>  <TAB> return self.name < other.name <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.altloc < other.altloc <TAB> else: <TAB>  <TAB> return NotImplemented",if self . parent != other . parent :,167
"def strip(self, elem, preserve=True, current_ns=None, top=True): <TAB> if elem.tag.startswith(""{"") and ""}"" in elem.tag: <TAB>  <TAB> ns, elem.tag = elem.tag[1:].split(""}"", 1) <MASK> elem.attrib[""xmlns""] = ns <TAB>  <TAB>  <TAB> current_ns = ns <TAB> elif current_ns: <TAB>  <TAB> elem.attrib[""xmlns""] = """" <TAB>  <TAB> current_ns = None <TAB> for child in elem: <TAB>  <TAB> self.strip(child, preserve, current_ns, top=False) <TAB> if top and not preserve and self.lxml_tree: <TAB>  <TAB> self.etree.cleanup_namespaces(elem)",if preserve and ns != current_ns :,169
"def __wait(self, imdata, timeout=30.0, threshold=0.8): <TAB> deadline = time.time() + timeout <TAB> while time.time() < deadline: <TAB>  <TAB> m = self.match(imdata) <TAB>  <TAB> sim = m[""similarity""] <TAB>  <TAB> self.logger.debug( <TAB>  <TAB>  <TAB> ""similarity %.2f [~%.2f], left time: %.1fs"", <TAB>  <TAB>  <TAB> sim, <TAB>  <TAB>  <TAB> threshold, <TAB>  <TAB>  <TAB> deadline - time.time(), <TAB>  <TAB> ) <MASK> continue <TAB>  <TAB> time.sleep(0.1) <TAB>  <TAB> return m <TAB> self.logger.debug(""image not found"")",if sim < threshold :,163
"def writer(datasets, dataset_names, output_dir): <TAB> """"""Write the results."""""" <TAB> for dataset, dataset_name in zip(datasets, dataset_names): <MASK> filepath = output_dir + ""/"" + dataset_name + "".txt"" <TAB>  <TAB>  <TAB> with open(filepath, ""w+"") as out_file: <TAB>  <TAB>  <TAB>  <TAB> joined = ""\n"".join(dataset) <TAB>  <TAB>  <TAB>  <TAB> out_file.write(str(joined.encode(""utf-8"").decode(""utf-8""))) <TAB>  <TAB>  <TAB>  <TAB> out_file.write(""\n"")",if dataset :,134
"def printLexHFile(f): <TAB> out = [] <TAB> for name in f.order: <TAB>  <TAB> v = f.features[name] <MASK> if ""SCE_"" in name or ""SCLEX_"" in name: <TAB>  <TAB>  <TAB>  <TAB> out.append(""#define "" + name + "" "" + v[""Value""]) <TAB> return out","if v [ ""FeatureType"" ] in [ ""val"" ] :",91
"def testDeleteArtifactDeletesMultiple(self): <TAB> for i in range(42): <TAB>  <TAB> self.db.WriteArtifact(rdf_artifacts.Artifact(name=""Art%s"" % i)) <TAB> for i in range(42): <MASK> continue <TAB>  <TAB> self.db.DeleteArtifact(""Art%s"" % i) <TAB> for i in range(42): <TAB>  <TAB> if i % 2 == 0: <TAB>  <TAB>  <TAB> self.assertEqual(self.db.ReadArtifact(""Art%s"" % i).name, ""Art%s"" % i) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> with self.assertRaises(db.UnknownArtifactError): <TAB>  <TAB>  <TAB>  <TAB> self.db.ReadArtifact(""Art%s"" % i)",if i % 2 == 0 :,175
"def _copy_color_in(self, col, name=None): <TAB> if col is self._EMPTY_SLOT_ITEM or col is None: <TAB>  <TAB> result = self._EMPTY_SLOT_ITEM <TAB> else: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> name = col.__name <TAB>  <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> if name is not None: <TAB>  <TAB>  <TAB> name = unicode(name) <TAB>  <TAB> result = RGBColor(color=col) <TAB>  <TAB> result.__name = name <TAB> return result",if name is None :,131
"def validate_priority(namespace): <TAB> """"""Validates the node pool priority string."""""" <TAB> if namespace.priority is not None: <MASK> return <TAB>  <TAB> if namespace.priority != ""Spot"" and namespace.priority != ""Regular"": <TAB>  <TAB>  <TAB> raise CLIError(""--priority can only be Spot or Regular"")","if namespace . priority == """" :",78
"def generic(self, args, kws): <TAB> assert not kws <TAB> [ary, idx] = args <TAB> if isinstance(ary, StringArrayType): <MASK> return signature(string_array_type, *args) <TAB>  <TAB> # elif isinstance(idx, types.Integer): <TAB>  <TAB> # <TAB>  return signature(string_type, *args) <TAB>  <TAB> elif idx == types.Array(types.bool_, 1, ""C""): <TAB>  <TAB>  <TAB> return signature(string_array_type, *args) <TAB>  <TAB> elif idx == types.Array(types.intp, 1, ""C""): <TAB>  <TAB>  <TAB> return signature(string_array_type, *args)","if isinstance ( idx , types . SliceType ) :",165
"def next(self): <TAB> if self.limit > 0: <MASK> raise StopIteration <TAB> if self.current_page is None or self.page_index == len(self.current_page) - 1: <TAB>  <TAB> # Reached end of current page, get the next page... <TAB>  <TAB> self.current_page = self.page_iterator.next() <TAB>  <TAB> while len(self.current_page) == 0: <TAB>  <TAB>  <TAB> self.current_page = self.page_iterator.next() <TAB>  <TAB> self.page_index = -1 <TAB> self.page_index += 1 <TAB> self.num_tweets += 1 <TAB> return self.current_page[self.page_index]",if self . num_tweets == self . limit :,175
"def configure_online(request): <TAB> seen = {None} <TAB> session = request.node <TAB> online = request.config.getoption(""--online"") <TAB> for item in session.items: <TAB>  <TAB> cls = item.getparent(pytest.Class) <TAB>  <TAB> if cls not in seen: <MASK> cls.obj.online = online <TAB>  <TAB>  <TAB> seen.add(cls)","if hasattr ( cls . obj , ""online"" ) :",101
"def __init__(self, s): <TAB> self.string = s <TAB> m = nt_name_pattern.search(s) <TAB> if m: <TAB>  <TAB> self.nt = True <TAB>  <TAB> self.value = m.group(""ntname"") <TAB> else: <TAB>  <TAB> self.nt = False <MASK> # _vmsgb(""MAKING NUMERIC FOR %s"" %(s)) <TAB>  <TAB>  <TAB> self.value = str(make_numeric(s)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # _vmsgb(""AVOIDING NUMERIC FOR %s"" %(s)) <TAB>  <TAB>  <TAB> self.value = s",if decimal_pattern . match ( s ) or binary_pattern . match ( s ) :,162
"def assertSubDictMatch(self, sub_dict, super_dict): <TAB> """"""Assert a sub_dict is subset of super_dict."""""" <TAB> self.assertTrue(set(sub_dict.keys()).issubset(set(super_dict.keys()))) <TAB> for k, sub_value in sub_dict.items(): <TAB>  <TAB> super_value = super_dict[k] <TAB>  <TAB> if isinstance(sub_value, dict): <TAB>  <TAB>  <TAB> self.assertSubDictMatch(sub_value, super_value) <MASK> continue <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertEqual(sub_value, super_value)","elif ""DONTCARE"" in ( sub_value , super_value ) :",160
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_data(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,90
"def add_answer_info(self, sample_info, sample): <TAB> if ""answers"" in sample_info: <TAB>  <TAB> answers = sample_info[""answers""] <TAB>  <TAB> answer_processor_arg = {""answers"": answers} <MASK> answer_processor_arg[""tokens""] = sample_info[""ocr_tokens""] <TAB>  <TAB> processed_soft_copy_answers = self.answer_processor(answer_processor_arg) <TAB>  <TAB> sample.answers = processed_soft_copy_answers[""answers""] <TAB>  <TAB> sample.targets = processed_soft_copy_answers[""answers_scores""] <TAB> return sample",if self . use_ocr :,146
"def Visit_or_test(self, node):  # pylint: disable=invalid-name <TAB> # or_test ::= and_test ('or' and_test)* <TAB> for child in node.children: <TAB>  <TAB> self.Visit(child) <MASK> _AppendTokenSubtype(child, format_token.Subtype.BINARY_OPERATOR)","if isinstance ( child , pytree . Leaf ) and child . value == ""or"" :",99
"def _reduce_lr(self, epoch): <TAB> for i, param_group in enumerate(self.optimizer.param_groups): <TAB>  <TAB> old_lr = float(param_group[""lr""]) <TAB>  <TAB> new_lr = max(old_lr * self.factor, self.min_lrs[i]) <TAB>  <TAB> if old_lr - new_lr > self.eps: <TAB>  <TAB>  <TAB> param_group[""lr""] = new_lr <MASK> print( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Epoch {:5d}: reducing learning rate"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> "" of group {} to {:.4e}."".format(epoch, i, new_lr) <TAB>  <TAB>  <TAB>  <TAB> )",if self . verbose :,163
"def create_semaphore(max_size, max_waiters): <TAB> if max_size is None: <TAB>  <TAB> return DummySemaphore() <TAB> else: <MASK> return BoundedSemaphore(max_size) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return MaxWaitersBoundedSemaphoreThread(max_size, max_waiters)",if max_waiters is None :,86
"def get_ifacesAllWireless(self): <TAB> """"""get only wireless interface"""""" <TAB> if self.isWiFiConnected(): <TAB>  <TAB> for iface in self.interfaces[""all""]: <MASK> if iface != self.interfaces[""activated""][0]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.ifaceAvaliable.append(iface) <TAB>  <TAB> return True <TAB> return False","if iface [ : 2 ] in [ ""wl"" , ""wi"" , ""ra"" , ""at"" ] :",106
"def generate_inputs(self): <TAB> in_socket = [] <TAB> for idx, socket in enumerate(self.input_node.outputs): <MASK> socket_name, socket_bl_idname, prop_name = get_socket_data(socket) <TAB>  <TAB>  <TAB> if prop_name: <TAB>  <TAB>  <TAB>  <TAB> prop_data = {""prop_name"": prop_name} <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> prop_data = {} <TAB>  <TAB>  <TAB> data = [socket_name, socket_bl_idname, prop_data] <TAB>  <TAB>  <TAB> in_socket.append(data) <TAB> return in_socket",if socket . is_linked :,152
"def addType(dict_, ret_type): <TAB> if ret_type not in dict_: <TAB>  <TAB> new_list = [] <TAB>  <TAB> for type_, list_ in dict_.items(): <TAB>  <TAB>  <TAB> if issubclass(type_, ret_type): <TAB>  <TAB>  <TAB>  <TAB> for item in list_: <MASK> new_list.append(item) <TAB>  <TAB> dict_[ret_type] = new_list",if item not in new_list :,107
"def _get_source_class(self): <TAB> try: <TAB>  <TAB> module_name, class_name = CleanText( <TAB>  <TAB>  <TAB> self.source, banned=CleanText.NONDNS <TAB>  <TAB> ).clean.rsplit(""."", 1) <MASK> module_name = ""mailpile"" + module_name <TAB>  <TAB> module = __import__(module_name, globals(), locals(), class_name) <TAB>  <TAB> return getattr(module, class_name) <TAB> except (ValueError, AttributeError, ImportError): <TAB>  <TAB> return None","if module_name . startswith ( ""."" ) :",128
"def _set_projection(self, projection): <TAB> by_prefix = {} <TAB> for propname in projection: <TAB>  <TAB> if ""."" in propname: <TAB>  <TAB>  <TAB> head, tail = propname.split(""."", 1) <MASK> by_prefix[head].append(tail) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> by_prefix[head] = [tail] <TAB> self._projection = tuple(projection) <TAB> for propname, proj in by_prefix.iteritems(): <TAB>  <TAB> prop = self._properties.get(propname) <TAB>  <TAB> subval = prop._get_base_value_unwrapped_as_list(self) <TAB>  <TAB> for item in subval: <TAB>  <TAB>  <TAB> assert item is not None <TAB>  <TAB>  <TAB> item._set_projection(proj)",if head in by_prefix :,183
"def note_doctag(self, key, document_no, document_length): <TAB> """"""Note a document tag during initial corpus scan, for structure sizing."""""" <TAB> if isinstance(key, integer_types + (integer,)): <TAB>  <TAB> self.max_rawint = max(self.max_rawint, key) <TAB> else: <MASK> self.doctags[key] = self.doctags[key].repeat(document_length) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.doctags[key] = Doctag(len(self.offset2doctag), document_length, 1) <TAB>  <TAB>  <TAB> self.offset2doctag.append(key) <TAB> self.count = self.max_rawint + 1 + len(self.offset2doctag)",if key in self . doctags :,188
"def cancel(self): <TAB> # unclean shutdown, the file is probably truncated, so delete it <TAB> # altogether rather than deliver a corrupted file <TAB> fp = getattr(self, ""fp"", None) <TAB> if fp: <TAB>  <TAB> fp.close() <MASK> os.unlink(self.destfile) <TAB>  <TAB> if self.tmpname and os.path.exists(self.tmpname): <TAB>  <TAB>  <TAB> os.unlink(self.tmpname)",if self . destfile and os . path . exists ( self . destfile ) :,120
"def test_no_notgeoref_warning(transform, gcps, rpcs): <TAB> with rasterio.MemoryFile() as mem: <TAB>  <TAB> with mem.open( <TAB>  <TAB>  <TAB> driver=""GTiff"", <TAB>  <TAB>  <TAB> width=10, <TAB>  <TAB>  <TAB> height=10, <TAB>  <TAB>  <TAB> dtype=""uint8"", <TAB>  <TAB>  <TAB> count=1, <TAB>  <TAB>  <TAB> transform=transform, <TAB>  <TAB> ) as src: <TAB>  <TAB>  <TAB> if gcps: <TAB>  <TAB>  <TAB>  <TAB> src.gcps = (gcps, rasterio.crs.CRS.from_epsg(4326)) <MASK> src.rpcs = rpcs <TAB>  <TAB> with pytest.warns(None) as record: <TAB>  <TAB>  <TAB> with mem.open() as dst: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> assert len(record) == 0",if rpcs :,198
"def forward(self, input): <TAB> outs = [] <TAB> for idx, conv_bn_func in enumerate(self.conv_bn_func_list): <TAB>  <TAB> if conv_bn_func is None: <TAB>  <TAB>  <TAB> outs.append(input[idx]) <TAB>  <TAB> else: <MASK> outs.append(conv_bn_func(input[idx])) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> outs.append(conv_bn_func(input[-1])) <TAB> return outs",if idx < len ( input ) :,124
"def forwards(self, orm): <TAB> ""Migrate TimeSlots to set .user"" <TAB> for obj in orm[""projects.TaskTimeSlot""].objects.all(): <MASK> obj.user = obj.object_ptr.creator <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> obj.user = orm[""core.User""].objects.all()[0] <TAB>  <TAB> obj.save()",if obj . object_ptr . creator :,95
"def __setitem__(self, key, value): <TAB> dict.__setitem__(self, key, value) <TAB> try: <TAB>  <TAB> idx = self.recent_keys.index(key) <TAB> except ValueError: <TAB>  <TAB> self.recent_keys.append(key) <MASK> k = self.recent_keys.pop(0) <TAB>  <TAB>  <TAB> dict.__delitem__(self, k) <TAB> else: <TAB>  <TAB> del self.recent_keys[idx] <TAB>  <TAB> self.recent_keys.append(key)",if len ( self . recent_keys ) > self . limit :,134
"def pickup(self, open_players, open_buf, wrap_buf): <TAB> for aplayer in self._game.active_players: <TAB>  <TAB> if aplayer in open_players: <TAB>  <TAB>  <TAB> aplayer.send(open_players) <MASK> for awatcher in self._watchers: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if awatcher._can_see_detail: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> awatcher.send(open_buf) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> awatcher.send(wrap_buf) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._game.send(aplayer.side) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._game.send(aplayer.side, wrap_buf)",if self == aplayer :,177
"def pythagoras(opposite, adjacent, hypotenuse): <TAB> try: <MASK> return ""Opposite = "" + str(((hypotenuse ** 2) - (adjacent ** 2)) ** 0.5) <TAB>  <TAB> elif adjacent == str(""?""): <TAB>  <TAB>  <TAB> return ""Adjacent = "" + str(((hypotenuse ** 2) - (opposite ** 2)) ** 0.5) <TAB>  <TAB> elif hypotenuse == str(""?""): <TAB>  <TAB>  <TAB> return ""Hypotenuse = "" + str(((opposite ** 2) + (adjacent ** 2)) ** 0.5) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""You already know the answer!"" <TAB> except: <TAB>  <TAB> raise ValueError(""invalid argument were given."")","if opposite == str ( ""?"" ) :",185
"def getAll(self): <TAB> r = {} <TAB> for key, value in SMPPClientConfigKeyMap.items(): <MASK> if isinstance(getattr(self, value), Enum): <TAB>  <TAB>  <TAB>  <TAB> r[key] = castOutputToBuiltInType(key, getattr(self, value).name) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> r[key] = castOutputToBuiltInType(key, getattr(self, value)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Related to #192 <TAB>  <TAB>  <TAB> r[key] = ""Unknown (object is from an old Jasmin release !)"" <TAB> return r","if hasattr ( self , value ) :",154
"def asList(nodes): <TAB> l = [] <TAB> for item in nodes: <TAB>  <TAB> if hasattr(item, ""asList""): <TAB>  <TAB>  <TAB> l.append(item.asList()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if type(item) is type((None, None)): <TAB>  <TAB>  <TAB>  <TAB> l.append(tuple(asList(item))) <MASK> l.append(asList(item)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> l.append(item) <TAB> return l",elif type ( item ) is type ( [ ] ) :,129
"def run(): <TAB> try: <TAB>  <TAB> result = func() <TAB>  <TAB> if result is not None: <TAB>  <TAB>  <TAB> from tornado.gen import convert_yielded <TAB>  <TAB>  <TAB> result = convert_yielded(result) <TAB> except Exception: <TAB>  <TAB> future_cell[0] = TracebackFuture() <TAB>  <TAB> future_cell[0].set_exc_info(sys.exc_info()) <TAB> else: <MASK> future_cell[0] = result <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> future_cell[0] = TracebackFuture() <TAB>  <TAB>  <TAB> future_cell[0].set_result(result) <TAB> self.add_future(future_cell[0], lambda future: self.stop())",if is_future ( result ) :,171
"def __init__(self, size, color=None, ismask=False, duration=None): <TAB> w, h = size <TAB> if ismask: <TAB>  <TAB> shape = (h, w) <TAB>  <TAB> if color is None: <TAB>  <TAB>  <TAB> color = 0 <MASK> raise Exception(""Color has to be a scalar when mask is true"") <TAB> else: <TAB>  <TAB> if color is None: <TAB>  <TAB>  <TAB> color = (0, 0, 0) <TAB>  <TAB> elif not hasattr(color, ""__getitem__""): <TAB>  <TAB>  <TAB> raise Exception(""Color has to contain RGB of the clip"") <TAB>  <TAB> shape = (h, w, len(color)) <TAB> super().__init__( <TAB>  <TAB> np.tile(color, w * h).reshape(shape), ismask=ismask, duration=duration <TAB> )",elif not np . isscalar ( color ) :,191
"def on_clearb_clicked(self, clicked_button): <TAB> for i in xrange(0, len(self.action_widgets)): <TAB>  <TAB> button, clearb = self.action_widgets[i] <MASK> self.actions[i] = NoAction() <TAB>  <TAB>  <TAB> self._update() <TAB>  <TAB>  <TAB> return",if clearb == clicked_button :,86
"def auxsmbconf_dict(self, aux, direction=""TO""): <TAB> ret = None <TAB> if direction == ""TO"": <TAB>  <TAB> ret = {} <TAB>  <TAB> for entry in aux.splitlines(): <MASK> continue <TAB>  <TAB>  <TAB> if entry.startswith((""#"", "";"")): <TAB>  <TAB>  <TAB>  <TAB> # Special handling for comments <TAB>  <TAB>  <TAB>  <TAB> ret[entry] = None <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> kv = entry.split(""="", 1) <TAB>  <TAB>  <TAB> ret[kv[0].strip()] = kv[1].strip() <TAB>  <TAB> return ret <TAB> if direction == ""FROM"": <TAB>  <TAB> return ""\n"".join([f""{k}={v}"" if v is not None else k for k, v in aux.items()])","if entry == """" :",174
"def loadCsv(self, line, map=[]): <TAB> split = line.split(""|"") <TAB> for i, value in enumerate(split): <MASK> Print.info(""invalid map index: "" + str(i) + "", "" + str(len(map))) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> i = str(map[i]) <TAB>  <TAB> methodName = ""set"" + i[0].capitalize() + i[1:] <TAB>  <TAB> method = getattr(self, methodName, lambda x: None) <TAB>  <TAB> method(value.strip())",if i >= len ( map ) :,132
"def emit_message(c, parent, root, message): <TAB> """"""Create all the children of p."""""" <TAB> for part in message.walk(): <TAB>  <TAB> part.get_content_maintype() <TAB>  <TAB> payload = part.get_payload() <TAB>  <TAB> subject = g.toUnicode(message.get(""subject"")) <TAB>  <TAB> from_ = g.toUnicode(message.get(""from"")) <MASK> p = parent.insertAsLastChild() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> p = parent = root.insertAsLastChild() <TAB>  <TAB> payload = g.toUnicode(payload) <TAB>  <TAB> p.h = ""%s [%s]"" % (subject, from_) <TAB>  <TAB> p.b = g.toUnicode(strip_tags(payload)) <TAB>  <TAB> return parent","if parent and subject . lower ( ) . startswith ( ""re:"" ) :",189
"def squasher(): <TAB> while 1: <TAB>  <TAB> ch = co.tran(codisassembler) <TAB>  <TAB> if ch == ""*"": <TAB>  <TAB>  <TAB> ch2 = co.tran(codisassembler) <TAB>  <TAB>  <TAB> if ch2 == ""*"": <TAB>  <TAB>  <TAB>  <TAB> ch = ""^"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> co.tran(coassembler, ch) <TAB>  <TAB>  <TAB>  <TAB> ch = ch2 <MASK> while 1: <TAB>  <TAB>  <TAB>  <TAB> ch2 = co.tran(codisassembler) <TAB>  <TAB>  <TAB>  <TAB> if ch2 not in "" \t"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> co.tran(coassembler, "" "") <TAB>  <TAB>  <TAB> ch = ch2 <TAB>  <TAB> co.tran(coassembler, ch)","if ch in "" \t"" :",191
"def dump(self, filename=None, indent=0, **kwargs): <TAB> if filename is None: <TAB>  <TAB> filename = self._anno_path <TAB>  <TAB> anno_dir = os.path.dirname(self._anno_path) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> os.mkdir(anno_dir) <TAB>  <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB> save_json(self._to_dict(), filename, indent=indent, **kwargs)",if not os . path . exists ( anno_dir ) :,121
"def clean(self): <TAB> email = self.cleaned_data.get(""email"") <TAB> password = self.cleaned_data.get(""password"") <TAB> if email and password: <TAB>  <TAB> self.user = authenticate(username=email, password=password) <TAB>  <TAB> if self.user: <MASK> pass <TAB>  <TAB>  <TAB>  <TAB> # raise forms.ValidationError(""User is Inactive"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> # raise forms.ValidationError(""Invalid email and password"") <TAB> return self.cleaned_data",if not self . user . is_active :,135
"def decode_script(bytes): <TAB> result = """" <TAB> for (opcode, vch, i) in script_GetOp(bytes): <TAB>  <TAB> if len(result) > 0: <TAB>  <TAB>  <TAB> result += "" "" <MASK> result += ""%d:"" % (opcode,) <TAB>  <TAB>  <TAB> result += short_hex(vch) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result += script_GetOpName(opcode) <TAB> return result",if opcode <= opcodes . OP_PUSHDATA4 :,115
"def toggle_disabling(doc): <TAB> doc = json.loads(doc) <TAB> if doc.get(""disabled""): <TAB>  <TAB> df = {""read_only"": 1} <TAB> else: <TAB>  <TAB> df = {""read_only"": 0} <TAB> doclist = get_doctypes_with_dimensions() <TAB> for doctype in doclist: <TAB>  <TAB> field = frappe.db.get_value( <TAB>  <TAB>  <TAB> ""Custom Field"", {""dt"": doctype, ""fieldname"": doc.get(""fieldname"")} <TAB>  <TAB> ) <MASK> custom_field = frappe.get_doc(""Custom Field"", field) <TAB>  <TAB>  <TAB> custom_field.update(df) <TAB>  <TAB>  <TAB> custom_field.save() <TAB>  <TAB> frappe.clear_cache(doctype=doctype)",if field :,185
"def _added(diffs, prefix): <TAB> keys = [] <TAB> for key in diffs.keys(): <MASK> keys.extend(_added(diffs[key], prefix=""{0}{1}."".format(prefix, key))) <TAB>  <TAB> elif diffs[key][""old""] == self.NONE_VALUE: <TAB>  <TAB>  <TAB> if isinstance(diffs[key][""new""], dict): <TAB>  <TAB>  <TAB>  <TAB> keys.extend( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _added(diffs[key][""new""], prefix=""{0}{1}."".format(prefix, key)) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> keys.append(""{0}{1}"".format(prefix, key)) <TAB> return keys","if isinstance ( diffs [ key ] , dict ) and ""old"" not in diffs [ key ] :",174
"def shell_complete(ctx, param, incomplete): <TAB> from click.shell_completion import CompletionItem <TAB> out = [] <TAB> for c in autocompletion(ctx, [], incomplete): <TAB>  <TAB> if isinstance(c, tuple): <TAB>  <TAB>  <TAB> c = CompletionItem(c[0], help=c[1]) <TAB>  <TAB> elif isinstance(c, str): <TAB>  <TAB>  <TAB> c = CompletionItem(c) <MASK> out.append(c) <TAB> return out",if c . value . startswith ( incomplete ) :,113
"def start_generation(self) -> None: <TAB> while True: <TAB>  <TAB> turn = self.get_id_input( <TAB>  <TAB>  <TAB> prompt=""choose turn (1 for user, 2 for bot, 3 to start a new dialog or 10 for saving and exit): "", <TAB>  <TAB>  <TAB> valid_vals=[1, 2, 3, 10], <TAB>  <TAB> ) <TAB>  <TAB> print(""\n"" + ""*"" * 10) <TAB>  <TAB> if turn == 1: <TAB>  <TAB>  <TAB> self.get_user_input() <TAB>  <TAB> elif turn == 2: <TAB>  <TAB>  <TAB> self.get_bot_output() <MASK> self.add_and_reset_utters() <TAB>  <TAB> elif turn == 10: <TAB>  <TAB>  <TAB> self.add_and_reset_utters() <TAB>  <TAB>  <TAB> self.save_dialogs() <TAB>  <TAB>  <TAB> return",elif turn == 3 :,194
"def create_attr_dict(yaml_config): <TAB> from ast import literal_eval <TAB> for key, value in yaml_config.items(): <MASK> yaml_config[key] = value = AttrDict(value) <TAB>  <TAB> if isinstance(value, str): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> value = literal_eval(value) <TAB>  <TAB>  <TAB> except BaseException: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> if isinstance(value, AttrDict): <TAB>  <TAB>  <TAB> create_attr_dict(yaml_config[key]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yaml_config[key] = value <TAB> return",if type ( value ) is dict :,149
"def get_integration_responses(self, resource): <TAB> default_integration_responses = [{""pattern"": """", ""code"": ""200""}] <TAB> responses = [] <TAB> for response in resource[""integration""].get( <TAB>  <TAB> ""responses"", default_integration_responses <TAB> ): <TAB>  <TAB> extra = {} <TAB>  <TAB> if ""parameters"" in response: <TAB>  <TAB>  <TAB> extra[""ResponseParameters""] = response[""parameters""] <MASK> extra[""ResponseTemplates""] = response[""template""] <TAB>  <TAB> responses.append( <TAB>  <TAB>  <TAB> IntegrationResponse( <TAB>  <TAB>  <TAB>  <TAB> SelectionPattern=six.text_type(response[""pattern""]), <TAB>  <TAB>  <TAB>  <TAB> StatusCode=six.text_type(response[""code""]), <TAB>  <TAB>  <TAB>  <TAB> **extra <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB> return responses","if ""template"" in response :",185
def to_wchar(argtypes): <TAB> if argtypes:  # Under IronPython some argtypes are not declared <TAB>  <TAB> result = [] <TAB>  <TAB> for x in argtypes: <MASK> result.append(wchar_pointer) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> result.append(x) <TAB>  <TAB> return result <TAB> else: <TAB>  <TAB> return argtypes,if x == ctypes . c_char_p :,97
"def __rpow__(self, other): <TAB> if self.is_dimensionless: <MASK> new_array = np.array(other, copy=False) ** np.array(self, copy=False) <TAB>  <TAB>  <TAB> return Quantity(new_array, DIMENSIONLESS) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return NotImplemented <TAB> else: <TAB>  <TAB> raise DimensionMismatchError( <TAB>  <TAB>  <TAB> ( <TAB>  <TAB>  <TAB>  <TAB> ""Cannot calculate "" <TAB>  <TAB>  <TAB>  <TAB> ""{base} ** {exponent}, the "" <TAB>  <TAB>  <TAB>  <TAB> ""exponent has to be "" <TAB>  <TAB>  <TAB>  <TAB> ""dimensionless"" <TAB>  <TAB>  <TAB> ).format(base=_short_str(other), exponent=_short_str(self)), <TAB>  <TAB>  <TAB> self.dim, <TAB>  <TAB> )","if isinstance ( other , np . ndarray ) or isinstance ( other , np . ndarray ) :",193
"def get_history(self, state, dict_, passive=PASSIVE_OFF): <TAB> if self.key in dict_: <TAB>  <TAB> return History.from_object_attribute(self, state, dict_[self.key]) <TAB> else: <MASK> passive ^= INIT_OK <TAB>  <TAB> current = self.get(state, dict_, passive=passive) <TAB>  <TAB> if current is PASSIVE_NO_RESULT: <TAB>  <TAB>  <TAB> return HISTORY_BLANK <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return History.from_object_attribute(self, state, current)",if passive & INIT_OK :,143
"def process_event(self, event): <TAB> if isinstance(event, KeyboardEvent): <MASK> self._on_click() <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Ignore any other key press. <TAB>  <TAB>  <TAB> return event <TAB> elif isinstance(event, MouseEvent): <TAB>  <TAB> if event.buttons != 0: <TAB>  <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB>  <TAB> self._x <= event.x < self._x + self._w <TAB>  <TAB>  <TAB>  <TAB> and self._y <= event.y < self._y + self._h <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> self._on_click() <TAB>  <TAB>  <TAB>  <TAB> return None <TAB> # Ignore other events <TAB> return event","if event . key_code in [ ord ( "" "" ) , 10 , 13 ] :",178
"def isRootMatch(self, elem): <TAB> if ( <TAB>  <TAB> self.elementName == None or self.elementName == elem.name <TAB> ) and self.matchesPredicates(elem): <MASK> for c in elem.elements(): <TAB>  <TAB>  <TAB>  <TAB> if self.childLocation.matches(c): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return True <TAB> return False",if self . childLocation != None :,104
"def get_inverse_graphkeys(): <TAB> ret = {} <TAB> for name in dir(tf.GraphKeys): <TAB>  <TAB> if name.startswith(""_""): <TAB>  <TAB>  <TAB> continue <MASK> # will produce deprecated warning <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> ret[getattr(tf.GraphKeys, name)] = ""tf.GraphKeys.{}"".format(name) <TAB> return ret","if name in [ ""VARIABLES"" ] :",85
"def _emulate_form_rejection(processor, partial_tracker): <TAB> if partial_tracker.active_form.get(""name""): <TAB>  <TAB> for p in processor.policy_ensemble.policies: <TAB>  <TAB>  <TAB> if isinstance(p, FormPolicy): <TAB>  <TAB>  <TAB>  <TAB> # emulate form rejection <TAB>  <TAB>  <TAB>  <TAB> partial_tracker.update( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ActionExecutionRejected(partial_tracker.active_form[""name""]) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> # check if unhappy path is covered by the train stories <MASK> # this state is not covered by the stories <TAB>  <TAB>  <TAB>  <TAB>  <TAB> del partial_tracker.events[-1] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> partial_tracker.active_form[""rejected""] = False","if not p . state_is_unhappy ( partial_tracker , processor . domain ) :",199
"def stop(self, kill=False, timeout=15, _=False): <TAB> term = False <TAB> start_time = time.time() <TAB> timeout *= self._context.timeout_multiplier <TAB> while self._handle and self._is_running(): <TAB>  <TAB> if kill: <TAB>  <TAB>  <TAB> self._handle.kill() <TAB>  <TAB> elif not term: <TAB>  <TAB>  <TAB> self._handle.terminate() <TAB>  <TAB>  <TAB> term = True <TAB>  <TAB> time.sleep(1) <MASK> kill = True <TAB> if self._log: <TAB>  <TAB> self._log.close()",if not kill and time . time ( ) - start_time > timeout :,147
"def _args_to_clause(self, args, clauses=()): <TAB> clauses = list(clauses) <TAB> for column, value in args.items(): <TAB>  <TAB> column = self._get_column_name(column) <TAB>  <TAB> if not self.has_column(column): <TAB>  <TAB>  <TAB> clauses.append(false()) <MASK> clauses.append(self._generate_clause(column, ""in"", value)) <TAB>  <TAB> elif isinstance(value, dict): <TAB>  <TAB>  <TAB> for op, op_value in value.items(): <TAB>  <TAB>  <TAB>  <TAB> clauses.append(self._generate_clause(column, op, op_value)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> clauses.append(self._generate_clause(column, ""="", value)) <TAB> return and_(*clauses)","elif isinstance ( value , ( list , tuple , set ) ) :",188
"def nspawn_params_for_build_sources( <TAB> args: CommandLineArguments, sft: SourceFileTransfer) -> List[str]: <TAB> params = [] <TAB> if args.build_sources is not None: <TAB>  <TAB> params.append(""--setenv=SRCDIR=/root/src"") <TAB>  <TAB> params.append(""--chdir=/root/src"") <TAB>  <TAB> if sft == SourceFileTransfer.mount: <TAB>  <TAB>  <TAB> params.append(""--bind="" + args.build_sources + "":/root/src"") <MASK> params.append(""--overlay=+/root/src::/root/src"") <TAB> else: <TAB>  <TAB> params.append(""--chdir=/root"") <TAB> return params",if args . read_only :,163
"def _download_worker(self): <TAB> """"""Download worker thread function"""""" <TAB> while not self.__to_download.empty(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> id, classifier, transitive, target = self.__to_download.get_nowait() <TAB>  <TAB> except queue.Empty: <TAB>  <TAB>  <TAB> return <MASK> # Only download really used artifacts <TAB>  <TAB>  <TAB> self._download_artifact(id, classifier, transitive, target) <TAB>  <TAB> self.__to_download.task_done()",if target . dependents :,116
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.set_blob_key(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 16: <TAB>  <TAB>  <TAB> self.set_create_secure_url(d.getBoolean()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 10 :,124
"def _generate_cache_key(self, path): <TAB> serialized = () <TAB> for val in self._to_bind: <TAB>  <TAB> opt = val._bind_loader([path.path[0]], None, None, False) <TAB>  <TAB> if opt: <TAB>  <TAB>  <TAB> c_key = opt._generate_cache_key(path) <TAB>  <TAB>  <TAB> if c_key is False: <TAB>  <TAB>  <TAB>  <TAB> return False <MASK> serialized += c_key <TAB> if not serialized: <TAB>  <TAB> return None <TAB> else: <TAB>  <TAB> return serialized",elif c_key :,133
"def construct_instances(self, row, keys=None): <TAB> collected_models = {} <TAB> for i, (key, constructor, attr, conv) in enumerate(self.column_map): <TAB>  <TAB> if keys is not None and key not in keys: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> value = row[i] <MASK> collected_models[key] = constructor() <TAB>  <TAB> instance = collected_models[key] <TAB>  <TAB> if attr is None: <TAB>  <TAB>  <TAB> attr = self.cursor.description[i][0] <TAB>  <TAB> setattr(instance, attr, value if conv is None else conv(value)) <TAB> return collected_models",if key not in collected_models :,156
"def get_files(self, flags): <TAB> src_files = [] <TAB> for fs in self._get_filesets(flags): <TAB>  <TAB> src_files += fs.files <TAB> _src_files = [] <TAB> for f in src_files: <TAB>  <TAB> pf = f.name.parse(flags) <MASK> _f = {} <TAB>  <TAB>  <TAB> for k, v in vars(f).items(): <TAB>  <TAB>  <TAB>  <TAB> if v: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _f[k] = v <TAB>  <TAB>  <TAB> _f[""name""] = pf <TAB>  <TAB>  <TAB> _src_files.append(_f) <TAB> return _src_files",if pf :,155
"def _remove_all(self, k): <TAB> cells = self._map.pop(k) <TAB> while cells: <TAB>  <TAB> cell = cells.pop() <MASK> cell[PREV][SPREV][SNEXT] = cell[NEXT] <TAB>  <TAB> elif cell[SNEXT] is cell[NEXT]: <TAB>  <TAB>  <TAB> cell[SPREV][SNEXT], cell[SNEXT][SPREV] = cell[SNEXT], cell[SPREV] <TAB>  <TAB> cell[PREV][NEXT], cell[NEXT][PREV] = cell[NEXT], cell[PREV] <TAB> cell[PREV][SNEXT] = cell[SNEXT]",if cell [ PREV ] [ SPREV ] [ SNEXT ] is cell :,173
"def parse_metrics( <TAB> metrics: Iterable[Union[str, dict]], in_y: List[str], out_vars: List[str]) -> List[Metric]: <TAB> metrics_functions = [] <TAB> for metric in metrics: <MASK> metric = {""name"": metric, ""alias"": metric} <TAB>  <TAB> metric_name = metric[""name""] <TAB>  <TAB> alias = metric.get(""alias"", metric_name) <TAB>  <TAB> f = get_metric_by_name(metric_name) <TAB>  <TAB> inputs = metric.get(""inputs"", in_y + out_vars) <TAB>  <TAB> if isinstance(inputs, str): <TAB>  <TAB>  <TAB> inputs = [inputs] <TAB>  <TAB> metrics_functions.append(Metric(metric_name, f, inputs, alias)) <TAB> return metrics_functions","if isinstance ( metric , str ) :",188
"def _create_next_frame_visualizer(self, next_frame_info): <TAB> if next_frame_info.code_name == ""<module>"": <TAB>  <TAB> return ModuleLoadDialog(self._text, next_frame_info) <TAB> else: <TAB>  <TAB> dialog = FunctionCallDialog(self._text.master, next_frame_info) <MASK> dialog.title(self._expression_box.get_focused_text()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> dialog.title(tr(""Function call at %s"") % hex(self._frame_id)) <TAB>  <TAB> return dialog",if self . _expression_box . winfo_ismapped ( ) :,151
"def read(self, size=None): <TAB> data = EMPTY <TAB> while True: <TAB>  <TAB> if size and len(data) >= size: <TAB>  <TAB>  <TAB> return data <MASK> self._fetch() <TAB>  <TAB>  <TAB> if not self.buffer: <TAB>  <TAB>  <TAB>  <TAB> # EOF <TAB>  <TAB>  <TAB>  <TAB> return data <TAB>  <TAB> if size: <TAB>  <TAB>  <TAB> remaining = size - len(data) <TAB>  <TAB>  <TAB> data += self.buffer[:remaining] <TAB>  <TAB>  <TAB> self.buffer = self.buffer[remaining:] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> data += self.buffer",if not self . buffer :,138
"def split_trading_pair(trading_pair: str) -> Optional[Tuple[str, str]]: <TAB> try: <MASK> m = trading_pair.split(""/"") <TAB>  <TAB>  <TAB> return m[0], m[1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> m = TRADING_PAIR_SPLITTER.match(trading_pair) <TAB>  <TAB>  <TAB> return m.group(1), m.group(2) <TAB> # Exceptions are now logged as warnings in trading pair fetcher <TAB> except Exception: <TAB>  <TAB> return None","if ""/"" in trading_pair :",135
"def main(): <TAB> encodings = [] <TAB> f = urllib.request.urlopen(sys.argv[1]) <TAB> for line in f: <TAB>  <TAB> if line.startswith(""Name: "") or line.startswith(""Alias: ""): <TAB>  <TAB>  <TAB> enc = line.split()[1] <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> codecs.lookup(enc) <MASK> encodings.append(enc.lower()) <TAB>  <TAB>  <TAB> except LookupError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB> sys.stdout.write(""encodings = frozenset((\n"") <TAB> for enc in encodings: <TAB>  <TAB> sys.stdout.write(' <TAB> ""%s"",\n' % enc) <TAB> sys.stdout.write("" <TAB> ))"")",if enc . lower not in encodings :,177
"def pages(self): <TAB> yield self.response <TAB> while self.next: <TAB>  <TAB> response = requests.get(self.next) <MASK> self.response = response.json() <TAB>  <TAB>  <TAB> yield self.response <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> msg = ""Server responded with a {} HTTP Status"" <TAB>  <TAB>  <TAB> print(msg.format(response.status_code)) <TAB>  <TAB>  <TAB> break",if 200 <= response . status_code < 400 :,108
"def list_modules(project): <TAB> source_path = project.expand_path(""$"" + PYTHON_SOURCES_PROPERTY) <TAB> result = [] <TAB> for potential_module_file in listdir(source_path): <TAB>  <TAB> potential_module_path = np(jp(source_path, potential_module_file)) <MASK> result.append(potential_module_file[:-3]) <TAB> return sorted(result)","if isfile ( potential_module_path ) and potential_module_file . endswith ( "".py"" ) :",117
"def decrypt_string(value, prefix=""jwe:::""): <TAB> prefix = ensure_bytes(prefix) <TAB> if value: <TAB>  <TAB> value = ensure_bytes(value) <TAB>  <TAB> if value.startswith(prefix): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> value = jwe.decrypt(value[len(prefix) :], SENSITIVE_DATA_KEY).decode() <TAB>  <TAB>  <TAB> except InvalidTag: <TAB>  <TAB>  <TAB>  <TAB> # Allow use of an encrypted DB locally without decrypting fields <MASK> pass <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise <TAB> return value",if settings . DEBUG_MODE :,146
"def process(self, resources, event=None): <TAB> client = utils.local_session(self.manager.session_factory).client(""ec2"") <TAB> results = [] <TAB> with self.executor_factory(max_workers=3) as w: <TAB>  <TAB> futures = {} <TAB>  <TAB> for instance_set in utils.chunks(resources, self.batch_size): <TAB>  <TAB>  <TAB> futures[ <TAB>  <TAB>  <TAB>  <TAB> w.submit(self.process_instance_set, client, instance_set) <TAB>  <TAB>  <TAB> ] = instance_set <TAB>  <TAB> for f in as_completed(futures): <MASK> self.log.error( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Error processing userdata on instance set %s"", f.exception() <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> results.extend(f.result()) <TAB> return results",if f . exception ( ) :,196
"def obtain_session(self, env): <TAB> cookie_str = env.get(""HTTP_COOKIE"", None) <TAB> session = None <TAB> if cookie_str: <TAB>  <TAB> cookie = Cookies.from_request( <TAB>  <TAB>  <TAB> cookie_str, <TAB>  <TAB>  <TAB> ignore_bad_cookies=True, <TAB>  <TAB> ).get(""session"", None) <TAB>  <TAB> if cookie and cookie.value: <TAB>  <TAB>  <TAB> if cookie.value in self.sessions: <TAB>  <TAB>  <TAB>  <TAB> # Session found <TAB>  <TAB>  <TAB>  <TAB> session = self.sessions[cookie.value] <MASK> session = None <TAB> return session",if session . is_dead ( ) :,150
"def func(*events): <TAB> for ev in events: <TAB>  <TAB> if isinstance(ev.new_value, (float, int)): <TAB>  <TAB>  <TAB> res.append(ev.new_value) <TAB>  <TAB> elif ev.type == ""children"": <MASK> res.append(""id%i"" % ev.source.val) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> res.append(None)",if ev . source . val :,101
"def find_file_in_folders(filename, paths, opt_in): <TAB> for d in paths: <MASK> continue <TAB>  <TAB> if os.path.isfile(d): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for f in os.listdir(d): <TAB>  <TAB>  <TAB> if f != filename: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> filepath = os.path.join(d, f) <TAB>  <TAB>  <TAB> if opt_in and not check_contains_cppimport(filepath): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> return filepath <TAB> return None",if not os . path . exists ( d ) :,138
"def try_iter(): <TAB> yielded = set() <TAB> try: <TAB>  <TAB> successor_select = self.successor._select_from <TAB>  <TAB> for starting_point in self._iterate_directories(parent_path, is_dir, scandir): <TAB>  <TAB>  <TAB> for p in successor_select(starting_point, is_dir, exists, scandir): <MASK> yield p <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yielded.add(p) <TAB> finally: <TAB>  <TAB> yielded.clear()",if p not in yielded :,126
"def search_chatrooms(self, name=None, userName=None): <TAB> with self.updateLock: <TAB>  <TAB> if userName is not None: <TAB>  <TAB>  <TAB> for m in self.chatroomList: <MASK> return copy.deepcopy(m) <TAB>  <TAB> elif name is not None: <TAB>  <TAB>  <TAB> matchList = [] <TAB>  <TAB>  <TAB> for m in self.chatroomList: <TAB>  <TAB>  <TAB>  <TAB> if name in m[""NickName""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> matchList.append(copy.deepcopy(m)) <TAB>  <TAB>  <TAB> return matchList","if m [ ""UserName"" ] == userName :",145
"def emu_perms_to_win_perms(self, emu_perms): <TAB> new = 0 <TAB> if emu_perms & common.PERM_MEM_RWX: <TAB>  <TAB> new = windefs.PAGE_EXECUTE_READWRITE <TAB> elif emu_perms & common.PERM_MEM_NONE: <TAB>  <TAB> new = windefs.PAGE_NOACCESS <TAB> else: <TAB>  <TAB> if emu_perms & common.PERM_MEM_EXEC: <TAB>  <TAB>  <TAB> new |= windefs.PAGE_EXECUTE <TAB>  <TAB> if emu_perms & common.PERM_MEM_READ:  # noqa <TAB>  <TAB>  <TAB> new |= windefs.PAGE_READONLY <MASK> new |= windefs.PAGE_READWRITE <TAB> return new",if emu_perms & common . PERM_MEM_WRITE :,192
"def extract_links_from_notebook(self, notebook_id): <TAB> try: <TAB>  <TAB> authorizationId = self._extract_notebook_text(notebook_id) <TAB>  <TAB> ret = self._get_notebook_json(notebook_id, authorizationId) <TAB>  <TAB> return ret <TAB> except requests.exceptions.HTTPError as exception: <TAB>  <TAB> logging.error(""Could not download notebook %s: %s"", notebook_id, exception) <MASK> logging.exception( <TAB>  <TAB>  <TAB>  <TAB> ""Could not download notebook %s: %s"", notebook_id, exception <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return None",if is_debug_run ( ) :,146
"def __repr__(self): <TAB> try: <TAB>  <TAB> if self._semlock._is_mine(): <TAB>  <TAB>  <TAB> name = process.current_process().name <TAB>  <TAB>  <TAB> if threading.current_thread().name != ""MainThread"": <TAB>  <TAB>  <TAB>  <TAB> name += ""|"" + threading.current_thread().name <MASK> name = ""None"" <TAB>  <TAB> elif self._semlock._count() > 0: <TAB>  <TAB>  <TAB> name = ""SomeOtherThread"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = ""SomeOtherProcess"" <TAB> except Exception: <TAB>  <TAB> name = ""unknown"" <TAB> return ""<%s(owner=%s)>"" % (self.__class__.__name__, name)",elif self . _semlock . _get_value ( ) == 1 :,170
"def _filter_examples(generator, axes=None): <TAB> for example in generator: <TAB>  <TAB> correct = True <TAB>  <TAB> for i, unused_tuple_element in enumerate(example): <TAB>  <TAB>  <TAB> if axes is None or i in axes: <TAB>  <TAB>  <TAB>  <TAB> if example[i].shape == (0,): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> correct = False <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <MASK> yield example",if correct :,98
"def dimensions(self, selection=""all"", label=False): <TAB> dimensions = super(Graph, self).dimensions(selection, label) <TAB> if selection == ""ranges"": <TAB>  <TAB> if self._nodes: <TAB>  <TAB>  <TAB> node_dims = self.nodes.dimensions(selection, label) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> node_dims = self.node_type.kdims + self.node_type.vdims <MASK> node_dims = [d.name for d in node_dims] <TAB>  <TAB>  <TAB> elif label in [""long"", ""label""]: <TAB>  <TAB>  <TAB>  <TAB> node_dims = [d.label for d in node_dims] <TAB>  <TAB> return dimensions + node_dims <TAB> return dimensions","if label in [ ""name"" , True , ""short"" ] :",175
"def __init__(self, iterable=None, languages=None, strict=True): <TAB> iterable = iterable or [] <TAB> languages = languages or LANGUAGES <TAB> items = [] <TAB> for i in iterable: <TAB>  <TAB> if isinstance(i, Language): <TAB>  <TAB>  <TAB> items.append(i) <TAB>  <TAB>  <TAB> continue <MASK> items.append(Language(i[0], languages=languages, strict=strict)) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> items.append(Language(i, languages=languages, strict=strict)) <TAB> super(language_set, self).__init__(items)","if isinstance ( i , tuple ) :",140
"def remove_name_illegal_chars( <TAB> apps: StateApps, schema_editor: DatabaseSchemaEditor) -> None: <TAB> UserProfile = apps.get_model(""zerver"", ""UserProfile"") <TAB> for user in UserProfile.objects.all(): <TAB>  <TAB> stripped = [] <TAB>  <TAB> for char in user.full_name: <MASK> stripped.append(char) <TAB>  <TAB> user.full_name = """".join(stripped) <TAB>  <TAB> user.save(update_fields=[""full_name""])","if ( char not in NAME_INVALID_CHARS ) and ( category ( char ) [ 0 ] != ""C"" ) :",141
"def __hash__(self): <TAB> if self._hashcode == -1: <MASK> t = self.replace(fold=0) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> t = self <TAB>  <TAB> tzoff = t.utcoffset() <TAB>  <TAB> if tzoff is None: <TAB>  <TAB>  <TAB> self._hashcode = hash(t._getstate()[0]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> days = _ymd2ord(self.year, self.month, self.day) <TAB>  <TAB>  <TAB> seconds = self.hour * 3600 + self.minute * 60 + self.second <TAB>  <TAB>  <TAB> self._hashcode = hash(timedelta(days, seconds, self.microsecond) - tzoff) <TAB> return self._hashcode",if self . fold :,172
"def set_music_enabled(state): <TAB> global music_enabled <TAB> if music_enabled != state: <TAB>  <TAB> music_enabled = state <MASK> # Music pausing doesn't always seem to work. <TAB>  <TAB>  <TAB> # music.unpause() <TAB>  <TAB>  <TAB> if current_music: <TAB>  <TAB>  <TAB>  <TAB> # After stopping and restarting currently loaded music, <TAB>  <TAB>  <TAB>  <TAB> # fadeout no longer works. <TAB>  <TAB>  <TAB>  <TAB> # print ""albow.music: reloading"", repr(current_music) ### <TAB>  <TAB>  <TAB>  <TAB> music.load(current_music) <TAB>  <TAB>  <TAB>  <TAB> music.play() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> jog_music() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # music.pause() <TAB>  <TAB>  <TAB> music.stop()",if state :,181
"def decode(self, parser, result): <TAB> parser._current = None <TAB> length = self._length <TAB> if length >= 0: <TAB>  <TAB> response = self._response <TAB>  <TAB> if result is not False: <TAB>  <TAB>  <TAB> response.append(result) <TAB>  <TAB> while len(response) < length: <TAB>  <TAB>  <TAB> result = parser._get(self) <TAB>  <TAB>  <TAB> if result is False: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> response.append(result) <TAB>  <TAB> if len(response) == length: <TAB>  <TAB>  <TAB> parser._current = None <TAB>  <TAB>  <TAB> return response <MASK> parser._current = self <TAB>  <TAB> return False",elif not parser . _current :,155
"def topic_lookup(request): <TAB> """"""Returns partial topic matches"""""" <TAB> topiclist = [] <TAB> if request.is_ajax(): <TAB>  <TAB> topic = request.GET.get(""topic"", """") <MASK> matches = Document.objects.filter(slug__icontains=topic) <TAB>  <TAB>  <TAB> for match in matches: <TAB>  <TAB>  <TAB>  <TAB> topiclist.append({""label"": match.slug}) <TAB> data = json.dumps(topiclist) <TAB> return HttpResponse(data, content_type=""application/json; charset=utf-8"")",if topic :,126
"def response_value(cls, payload): <TAB> # Return result, unless it is None and there is an error <TAB> if payload.get(""error"") is not None: <MASK> raise ProtocolError.invalid_request( <TAB>  <TAB>  <TAB>  <TAB> 'response contains both ""result"" and ""error""' <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return JSONRPCv1._best_effort_error(payload[""error""]) <TAB> if ""result"" not in payload: <TAB>  <TAB> raise ProtocolError.invalid_request( <TAB>  <TAB>  <TAB> 'response contains neither ""result"" nor ""error""' <TAB>  <TAB> ) <TAB> # Can be None <TAB> return payload[""result""]","if payload . get ( ""result"" ) is not None :",160
"def export(self, metrics): <TAB> if not metrics: <TAB>  <TAB> return <TAB> prepared_metrics = self.prepare_metrics(metrics) <TAB> data = prepared_metrics.pop(0) <TAB> while prepared_metrics: <TAB>  <TAB> stat = prepared_metrics.pop(0) <MASK> self.send(data) <TAB>  <TAB>  <TAB> data = stat <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> data += ""\n"" + stat <TAB> self.send(data)",if len ( stat ) + len ( data ) + 1 >= self . max_udp_size :,129
"def _wait_for_result(self): <TAB> job = self._refresh_job() <TAB> total_seconds_waited = 0.0 <TAB> timeout = self.context.timeout <TAB> while True: <TAB>  <TAB> if timeout and total_seconds_waited >= timeout: <TAB>  <TAB>  <TAB> break <MASK> break <TAB>  <TAB> time.sleep(0.5) <TAB>  <TAB> total_seconds_waited += 0.5 <TAB>  <TAB> job = self._refresh_job() <TAB> self._raise_on_failure(job) <TAB> response = self.context.client.get_job_results( <TAB>  <TAB> self.project_id, self.program_id, self.job_id <TAB> ) <TAB> return response.result",if job . execution_status . state in TERMINAL_STATES :,183
def close(self): <TAB> if not self._sender: <TAB>  <TAB> return <TAB> try: <TAB>  <TAB> if self._exported: <TAB>  <TAB>  <TAB> await self.client._return_exported_sender(self._sender) <MASK> await self._sender.disconnect() <TAB> finally: <TAB>  <TAB> self._sender = None,elif self . _sender != self . client . _sender :,86
"def validate(self, value): <TAB> if value is None and self.default is not None: <TAB>  <TAB> value = {""name"": self.default} <TAB> if isinstance(value, str): <TAB>  <TAB> value = {""name"": value} <TAB> themes = utils.get_theme_names() <TAB> if isinstance(value, dict): <TAB>  <TAB> if ""name"" in value: <MASK> return value <TAB>  <TAB>  <TAB> raise ValidationError( <TAB>  <TAB>  <TAB>  <TAB> ""Unrecognised theme name: '{}'. The available installed themes "" <TAB>  <TAB>  <TAB>  <TAB> ""are: {}"".format(value[""name""], "", "".join(themes)) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> raise ValidationError(""No theme name set."") <TAB> raise ValidationError( <TAB>  <TAB> 'Invalid type ""{}"". Expected a string or key/value pairs.'.format(type(value)) <TAB> )","if value [ ""name"" ] is None or value [ ""name"" ] in themes :",200
"def getToolTip(self): <TAB> result = GafferUI.PlugValueWidget.getToolTip(self) <TAB> srcNode = None <TAB> if self.getPlug() is not None: <TAB>  <TAB> input = self.getPlug().getInput() <TAB>  <TAB> if input is not None: <TAB>  <TAB>  <TAB> srcNode = input.node() <TAB> if srcNode is not None: <MASK> result += ""\n"" <TAB>  <TAB> result += ""## Actions\n\n"" <TAB>  <TAB> result += "" - Left drag to drag source plug\n"" <TAB>  <TAB> result += "" - Left click to edit source node\n"" <TAB> return result",if result :,152
"def transform_coords(self, mapper): <TAB> if self.needs_query_screen: <TAB>  <TAB> w_size = X.get_window_size(mapper.get_xdisplay(), mapper.get_current_window()) <TAB>  <TAB> x1, y1, x2, y2 = self.coords <MASK> x1 = w_size[0] + x1 <TAB>  <TAB> if y1 < 0: <TAB>  <TAB>  <TAB> y1 = w_size[1] + y1 <TAB>  <TAB> if x2 < 0: <TAB>  <TAB>  <TAB> x2 = w_size[0] + x2 <TAB>  <TAB> if y2 < 0: <TAB>  <TAB>  <TAB> y2 = w_size[1] + y2 <TAB>  <TAB> return x1, y1, x2, y2 <TAB> return self.coords",if x1 < 0 :,190
"def test_schema_file_names(self): <TAB> alembic_directory = find.data_directory(""alembic"") <TAB> versions = os.listdir(os.path.join(alembic_directory, ""versions"")) <TAB> for schema_file in versions: <MASK> continue <TAB>  <TAB> self.assertRegex(schema_file, r""[a-f0-9]{10,16}_schema_v\d+\.py"", schema_file)","if not schema_file . endswith ( "".py"" ) :",114
"def listdir( <TAB> path, include=""."", exclude=r""\.pyc$|^\."", show_all=False, folders_only=False): <TAB> """"""List files and directories"""""" <TAB> namelist = [] <TAB> dirlist = [to_text_string(osp.pardir)] <TAB> for item in os.listdir(to_text_string(path)): <TAB>  <TAB> if re.search(exclude, item) and not show_all: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if osp.isdir(osp.join(path, item)): <TAB>  <TAB>  <TAB> dirlist.append(item) <MASK> continue <TAB>  <TAB> elif re.search(include, item) or show_all: <TAB>  <TAB>  <TAB> namelist.append(item) <TAB> return sorted(dirlist, key=str_lower) + sorted(namelist, key=str_lower)",elif folders_only :,192
"def _test_branches(conf, branch_commits, require_describe=False): <TAB> r = repo.get_repo(conf) <TAB> assert len(conf.branches) == 2 <TAB> for branch in conf.branches: <TAB>  <TAB> commits = r.get_branch_commits(branch) <TAB>  <TAB> for commit in branch_commits[branch]: <TAB>  <TAB>  <TAB> assert commit in commits <TAB>  <TAB>  <TAB> name = r.get_name_from_hash(commit) <TAB>  <TAB>  <TAB> if require_describe: <TAB>  <TAB>  <TAB>  <TAB> assert name is not None <MASK> assert r.get_hash_from_name(name) == commit <TAB>  <TAB>  <TAB>  <TAB> assert name in r.get_decorated_hash(commit)",if name is not None :,171
"def actorSystemCapabilityCheck(capabilities, requirements): <TAB> logger = logging.getLogger(__name__) <TAB> for name, value in requirements.items(): <TAB>  <TAB> current = capabilities.get(name, None) <MASK> # A mismatch by is not a problem by itself as long as at least one actor system instance matches the requirements. <TAB>  <TAB>  <TAB> logger.info( <TAB>  <TAB>  <TAB>  <TAB> ""Checking capabilities [%s] against requirements [%s] failed."", <TAB>  <TAB>  <TAB>  <TAB> capabilities, <TAB>  <TAB>  <TAB>  <TAB> requirements, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return False <TAB> logger.info( <TAB>  <TAB> ""Capabilities [%s] match requirements [%s]."", capabilities, requirements <TAB> ) <TAB> return True",if current != value :,162
"def get(self, block=True, timeout=None): <TAB> # The SQLAlchemy Queue class uses a re-entrant mutext by default, <TAB> # so it's safe to acquire it both here and in the superclass method. <TAB> with self.mutex: <TAB>  <TAB> self.cur_backlog += 1 <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if self.max_backlog >= 0: <MASK> block = False <TAB>  <TAB>  <TAB>  <TAB>  <TAB> timeout = None <TAB>  <TAB>  <TAB> return Queue.get(self, block, timeout) <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self.cur_backlog -= 1",if self . cur_backlog > self . max_backlog :,158
"def _skip_sdc_test(obj): <TAB> if ismodule(obj): <TAB>  <TAB> name = obj.__name__ <TAB>  <TAB> for mod_name in exclude_sdc_submodules: <MASK> return True <TAB>  <TAB> return not name.startswith(""sdc"") and not name.startswith(""hpat"")",if name . startswith ( mod_name ) :,84
"def __preview_tracks(self, ctx, start, total, model, save, revert): <TAB> start = start.get_value_as_int() <TAB> total = total.get_value_as_int() <TAB> for row in model: <MASK> s = u""%d/%d"" % (row.path.get_indices()[0] + start, total) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> s = str(row.path.get_indices()[0] + start) <TAB>  <TAB> entry = row[0] <TAB>  <TAB> entry.tracknumber = s <TAB>  <TAB> model.row_changed(row.path, row.iter) <TAB> save.set_sensitive(True) <TAB> revert.set_sensitive(True)",if total :,172
"def __setitem__(self, key, value): <TAB> if self.mode == ""r"": <TAB>  <TAB> raise ReadOnlyError() <TAB> key = self._normalize_key(key) <TAB> path = self.dir_path(key) <TAB> try: <MASK> self.fs.rm(path, recursive=True) <TAB>  <TAB> self.map[key] = value <TAB>  <TAB> self.fs.invalidate_cache(self.fs._parent(path)) <TAB> except self.exceptions as e: <TAB>  <TAB> raise KeyError(key) from e",if self . fs . isdir ( path ) :,133
"def handle_charref(self, d): <TAB> try: <MASK> val = int(d[1:], 16) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> val = int(d) <TAB>  <TAB> self.fed.append(unichr(val)) <TAB> except (ValueError, OverflowError): <TAB>  <TAB> return","if d . startswith ( ""x"" ) :",79
"def _get_object_to_dump(self, model, parent_snapshots): <TAB> child = model <TAB> while child.opts.owner: <TAB>  <TAB> parent = child._get_parent_object(parent_snapshots) <MASK> parent = next(iter(parent)) <TAB>  <TAB> if parent is None: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> to_save = getattr( <TAB>  <TAB>  <TAB> parent.with_snapshots((""staged"", ""committed"")), <TAB>  <TAB>  <TAB> child._fields[child.opts.owner].related_name, <TAB>  <TAB> ) <TAB>  <TAB> child = parent <TAB> if child.__class__ is model._file_model: <TAB>  <TAB> to_save = child <TAB> return to_save","if isinstance ( parent , ModelCollection ) :",168
"def stress(sequence, deque): <TAB> for count in range(OPERATIONS): <TAB>  <TAB> function = random.choice(functions) <TAB>  <TAB> function(sequence, deque) <MASK> print(""\r"", len(sequence), "" "" * 7, end="""") <TAB> print()",if count % 100 == 0 :,72
"def _daemon(self): <TAB> last_ping = time() <TAB> while self._task is not None: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if self._exit_event.wait(min(self.ping_period, self.report_period)): <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> # send ping request <TAB>  <TAB>  <TAB> if self._support_ping and (time() - last_ping) >= self.ping_period: <TAB>  <TAB>  <TAB>  <TAB> self.ping() <TAB>  <TAB>  <TAB>  <TAB> last_ping = time() <TAB>  <TAB>  <TAB> if self._dev_stop_signal: <TAB>  <TAB>  <TAB>  <TAB> stop_reason = self._dev_stop_signal.test() <MASK> self._task._dev_mode_stop_task(stop_reason) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> pass",if stop_reason and self . _task :,196
"def repo(self): <TAB> if self._repo is None: <MASK> self._repo = False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> self._repo = Repo( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._root or os.getcwd(), search_parent_directories=True <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> except exc.InvalidGitRepositoryError: <TAB>  <TAB>  <TAB>  <TAB> logger.debug(""git repository is invalid"") <TAB>  <TAB>  <TAB>  <TAB> self._repo = False <TAB> return self._repo",if self . remote_name is None :,128
"def _fix(self): <TAB> if self.fmt is None: <TAB>  <TAB> return ""."".join(map(str, [self.idnum for i in range(1 + self.depth)])) <TAB> else: <TAB>  <TAB> oid = [] <TAB>  <TAB> for i in self.fmt: <TAB>  <TAB>  <TAB> if i == ""*"": <TAB>  <TAB>  <TAB>  <TAB> oid.append(str(self.idnum)) <MASK> oid += map(str, [self.idnum for i in range(1 + self.depth)]) <TAB>  <TAB>  <TAB> elif type(i) is tuple: <TAB>  <TAB>  <TAB>  <TAB> oid.append(str(random.randrange(*i))) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> oid.append(i) <TAB>  <TAB> return ""."".join(oid)","elif i == ""**"" :",178
"def read_dbpedia(tf, split, shrink=1, char_based=False): <TAB> dataset = [] <TAB> f = tf.extractfile(""dbpedia_csv/{}.csv"".format(split)) <TAB> if sys.version_info > (3, 0): <TAB>  <TAB> f = io.TextIOWrapper(f, encoding=""utf-8"") <TAB> for i, (label, title, text) in enumerate(csv.reader(f)): <MASK> continue <TAB>  <TAB> label = int(label) - 1  # Index begins from 1 <TAB>  <TAB> tokens = split_text(normalize_text(text), char_based) <TAB>  <TAB> dataset.append((tokens, label)) <TAB> return dataset",if i % shrink != 0 :,161
"def distinct(self, fieldname): <TAB> """"""Set of unique values for the given field."""""" <TAB> rv = set() <TAB> for item in self: <TAB>  <TAB> if fieldname in item._data: <TAB>  <TAB>  <TAB> value = item._data[fieldname] <TAB>  <TAB>  <TAB> if isinstance(value, (list, tuple)): <TAB>  <TAB>  <TAB>  <TAB> rv |= set(value) <MASK> rv.add(value) <TAB> return rv","elif not isinstance ( value , Undefined ) :",107
"def parse(self, service, key, value): <TAB> key = key.lower() <TAB> if service in self.service_aliases: <TAB>  <TAB> for attr in self.attrs: <MASK> self.details[service][key] = getattr(self, ""parse_%s"" % key)(value)",if key == attr and not self . details [ service ] [ key ] :,87
"def process(self): <TAB> ng = self.id_data <TAB> wifi_dict = { <TAB>  <TAB> node.var_name: node <TAB>  <TAB> for name, node in ng.nodes.items() <TAB>  <TAB> if node.bl_idname == ""WifiInNode"" <TAB> } <TAB> node = wifi_dict.get(self.var_name) <TAB> # transfer data <TAB> for in_socket, out_socket in zip(node.inputs, self.outputs): <MASK> data = in_socket.sv_get(deepcopy=False) <TAB>  <TAB>  <TAB> out_socket.sv_set(data)",if in_socket . is_linked and out_socket . is_linked :,163
"def target_detach(self): <TAB> if self._state == ""Running"": <TAB>  <TAB> await self.target_stop() <TAB> for index, address in enumerate(self._instr_brkpts): <MASK> await self._pracc_write_word(self._DRSEG_IBCn_addr(index), 0) <TAB>  <TAB>  <TAB> self._instr_brkpts[index] = None <TAB> for address, saved_instr in self._softw_brkpts.items(): <TAB>  <TAB> await self._pracc_write_word(address, self._softw_brkpts[address]) <TAB>  <TAB> await self._pracc_sync_icache(address) <TAB> self._softw_brkpts = {} <TAB> await self._pracc_debug_return()",if address is not None :,190
"def to_dict(self, get_value=None): <TAB> """"""Dump counters as a dict"""""" <TAB> self.trim() <TAB> result = {} <TAB> for key, value in iteritems(self.counters): <MASK> value = getattr(value, get_value) <TAB>  <TAB> r = result <TAB>  <TAB> for _key in key[:-1]: <TAB>  <TAB>  <TAB> r = r.setdefault(_key, {}) <TAB>  <TAB> r[key[-1]] = value <TAB> return result",if get_value is not None :,117
"def _list(self, includehidden, includetmp): <TAB> if self.exists(): <TAB>  <TAB> files = [] <TAB>  <TAB> for file in os.listdir(self.path): <TAB>  <TAB>  <TAB> if file.startswith(""."") and not includehidden: <TAB>  <TAB>  <TAB>  <TAB> continue  # skip hidden files <MASK> continue  # skip temporary files <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> files.append(file) <TAB>  <TAB> return files <TAB> else: <TAB>  <TAB> return []","elif ( file . endswith ( ""~"" ) or file . startswith ( ""~"" ) ) and not includetmp :",128
"def getsects(section): <TAB> if not isinstance(section, nodes.section): <TAB>  <TAB> return [getsects(n) for n in section.children] <TAB> title = section.next_node(nodes.title).astext().strip() <TAB> subsects = [] <TAB> children = section.children[:] <TAB> while children: <TAB>  <TAB> node = children.pop(0) <MASK> subsects.append(node) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> children = list(node.children) + children <TAB> return [title, [getsects(subsect) for subsect in subsects]]","if isinstance ( node , nodes . section ) :",151
"def push_broks_to_broker(self): <TAB> for brk in self.conf.brokers: <TAB>  <TAB> # Send only if alive of course <TAB>  <TAB> if brk.manage_arbiters and brk.alive: <TAB>  <TAB>  <TAB> is_send = brk.push_broks(self.broks) <MASK> # They are gone, we keep none! <TAB>  <TAB>  <TAB>  <TAB> self.broks.clear()",if is_send :,111
"def can_move_back_to_pending(request, current_user, groups): <TAB> if request.get(""status"") in [""cancelled"", ""rejected""]: <TAB>  <TAB> # Don't allow returning requests to pending state if more than a day has passed since the last update <TAB>  <TAB> if request.get(""last_updated"", 0) < int(time.time()) - 86400: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> # Allow admins to return requests back to pending state <MASK> return True <TAB> return False","if can_admin_policies ( current_user , groups ) :",131
"def get_current_user_can_comment(self, obj): <TAB> user = self.context[""request""].user <TAB> auth = Auth(user if not user.is_anonymous else None) <TAB> if hasattr(obj, ""has_read""): <MASK> return auth.logged_in and (obj.is_public or (auth.user and obj.has_read)) <TAB>  <TAB> return obj.has_read or False <TAB> else: <TAB>  <TAB> return obj.can_comment(auth)","if obj . comment_level == ""public"" :",125
"def _is_iscsi_frontend_port(port): <TAB> if ( <TAB>  <TAB> port.PortType == ""iSCSI"" <TAB>  <TAB> and port.PortMode == ""Target"" <TAB>  <TAB> and port.HostId <TAB>  <TAB> and port.PresenceStatus == ""Present"" <TAB>  <TAB> and hasattr(port, ""IScsiPortStateInfo"") <TAB> ): <TAB>  <TAB> port_roles = port.ServerPortProperties.Role.split() <TAB>  <TAB> port_state = port.IScsiPortStateInfo.PortalsState.PortalStateInfo[0].State <MASK> return True <TAB> return False","if ""Frontend"" in port_roles and port_state == ""Ready"" :",159
"def _ask_user_to_verify(description): <TAB> failure_description = None <TAB> print() <TAB> print(description) <TAB> while True: <TAB>  <TAB> response = input(""Passed [Yn]: "") <TAB>  <TAB> if not response: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif response in ""Nn"": <TAB>  <TAB>  <TAB> failure_description = input(""Enter failure description: "") <MASK> failure_description = ""No description entered"" <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif response in ""Yy"": <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""Invalid response"") <TAB> return failure_description",if not failure_description :,148
"def mouse_down(self, event): <TAB> if event.button == 1: <MASK> p = event.local <TAB>  <TAB>  <TAB> if self.scroll_up_rect().collidepoint(p): <TAB>  <TAB>  <TAB>  <TAB> self.scroll_up() <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> elif self.scroll_down_rect().collidepoint(p): <TAB>  <TAB>  <TAB>  <TAB> self.scroll_down() <TAB>  <TAB>  <TAB>  <TAB> return <TAB> if event.button == 4: <TAB>  <TAB> self.scroll_up() <TAB> if event.button == 5: <TAB>  <TAB> self.scroll_down() <TAB> Dialog.mouse_down(self, event)",if self . scrolling :,159
"def _find_html_report(self, ivy_report_dir): <TAB> html_report_file = None <TAB> pattern = re.compile(""internal-.*-default\.html$"") <TAB> listdir = os.listdir(ivy_report_dir) <TAB> for f in listdir: <TAB>  <TAB> if os.path.isfile(os.path.join(ivy_report_dir, f)): <MASK> html_report_file = f <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return html_report_file, listdir",if pattern . match ( f ) :,129
"def __warn_incorrect_bitness(self): <TAB> if self.backend.name == ""win32"" and self.is64bit() != is_x64_Python(): <MASK> warnings.warn( <TAB>  <TAB>  <TAB>  <TAB> ""32-bit application should be automated using 32-bit Python (you use 64-bit Python)"", <TAB>  <TAB>  <TAB>  <TAB> UserWarning, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> warnings.warn( <TAB>  <TAB>  <TAB>  <TAB> ""64-bit application should be automated using 64-bit Python (you use 32-bit Python)"", <TAB>  <TAB>  <TAB>  <TAB> UserWarning, <TAB>  <TAB>  <TAB> )",if is_x64_Python ( ) :,150
"def get_sdkDir(self): <TAB> if self._isDevTree():  # in a development tree <TAB>  <TAB> sdkDir = join(self._getKomodoBitsDir(), ""sdk"") <TAB> else: <MASK> sdkDir = join(self.get_supportDir(), ""sdk"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # mozBinDir: <installdir>/lib/mozilla <TAB>  <TAB>  <TAB> # sdkDir: <TAB> <installdir>/lib/sdk <TAB>  <TAB>  <TAB> sdkDir = join(dirname(self.get_mozBinDir()), ""sdk"") <TAB> return sdkDir","if sys . platform == ""darwin"" :",147
"def bad_function(exit_how=""break""): <TAB> with loops.Scope() as s: <TAB>  <TAB> for i in s.range(555): <MASK> break <TAB>  <TAB>  <TAB> elif exit_how == ""return"": <TAB>  <TAB>  <TAB>  <TAB> return 1.0 <TAB>  <TAB>  <TAB> elif exit_how == ""exception"": <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""test exception"") <TAB>  <TAB> # Start another range, we get here after a ""break"" above <TAB>  <TAB> for i in s.range(5): <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> return 0.0","if exit_how == ""break"" :",137
"def getDefaultSansFont(self): <TAB> """"""Load and return the FontInfo for the first found default font"""""" <TAB> for name in [""Verdana"", ""DejaVu Sans"", ""Bitstream Vera Sans"", ""Tahoma""]: <TAB>  <TAB> these = self.getFontsMatching(name, fallback=False) <MASK> continue <TAB>  <TAB> if type(these) in (list, set): <TAB>  <TAB>  <TAB> this = these[0] <TAB>  <TAB> # if str or Path then get a FontInfo object <TAB>  <TAB> if type(this) in [str, Path]: <TAB>  <TAB>  <TAB> this = self.addFontFiles(this) <TAB>  <TAB> return this <TAB> raise MissingFontError( <TAB>  <TAB> ""Failed to find any of the default fonts. "" <TAB>  <TAB> ""Existing fonts: {}"".format(list(self._fontInfos)) <TAB> )",if not these :,199
"def get_tokens_unprocessed(self, text): <TAB> for index, token, value in RegexLexer.get_tokens_unprocessed(self, text): <MASK> if value in self._functions: <TAB>  <TAB>  <TAB>  <TAB> yield index, Name.Builtin, value <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> elif ""."" in value: <TAB>  <TAB>  <TAB>  <TAB> a, b = value.split(""."") <TAB>  <TAB>  <TAB>  <TAB> yield index, Name, a <TAB>  <TAB>  <TAB>  <TAB> yield index + len(a), Punctuation, u""."" <TAB>  <TAB>  <TAB>  <TAB> yield index + len(a) + 1, Name, b <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> yield index, token, value",if token is Name :,155
"def check_additional_host_info(additional_host_info: List[HostInfoGetter]): <TAB> names_taken = [x.name for x in _host_info_gatherers_list] <TAB> for getter in additional_host_info: <MASK> error_msg = ( <TAB>  <TAB>  <TAB>  <TAB> ""Key {} used in `additional_host_info` already exists as a "" <TAB>  <TAB>  <TAB>  <TAB> ""default gatherer function. Do not use the following keys: "" <TAB>  <TAB>  <TAB>  <TAB> ""{}"" <TAB>  <TAB>  <TAB> ).format(getter.name, names_taken) <TAB>  <TAB>  <TAB> raise KeyError(error_msg)",if getter . name in names_taken :,155
"def _get_senders_and_signals(model): <TAB> yield model, post_save, _post_save_receiver <TAB> opts = model._meta.concrete_model._meta <TAB> for field in opts.local_many_to_many: <TAB>  <TAB> m2m_model = field.remote_field.through <TAB>  <TAB> if isinstance(m2m_model, str): <MASK> m2m_model = ""{app_label}.{m2m_model}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> app_label=opts.app_label, m2m_model=m2m_model <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> yield m2m_model, m2m_changed, _m2m_changed_receiver","if ""."" not in m2m_model :",181
"def attach_history_handler(session, parsed_args, **kwargs): <TAB> if _should_enable_cli_history(session, parsed_args): <TAB>  <TAB> LOG.debug(""Enabling CLI history"") <TAB>  <TAB> history_filename = os.environ.get( <TAB>  <TAB>  <TAB> HISTORY_FILENAME_ENV_VAR, DEFAULT_HISTORY_FILENAME <TAB>  <TAB> ) <MASK> os.makedirs(os.path.dirname(history_filename)) <TAB>  <TAB> connection = DatabaseConnection(history_filename) <TAB>  <TAB> writer = DatabaseRecordWriter(connection) <TAB>  <TAB> record_builder = RecordBuilder() <TAB>  <TAB> db_handler = DatabaseHistoryHandler(writer, record_builder) <TAB>  <TAB> HISTORY_RECORDER.add_handler(db_handler) <TAB>  <TAB> HISTORY_RECORDER.enable()",if not os . path . isdir ( os . path . dirname ( history_filename ) ) :,192
"def remove_breakpoint_by_id(self, id): <TAB> id = str(id) <TAB> if id not in self.breakpoints: <TAB>  <TAB> raise BreakpointError(""No breakpoint matching ID %s"" % id) <TAB> vdebug.log.Log(""Removing breakpoint id %s"" % id) <TAB> if self.api is not None: <TAB>  <TAB> dbg_id = self.breakpoints[id].get_debugger_id() <MASK> self.api.breakpoint_remove(dbg_id) <TAB> self.breakpoints[id].on_remove() <TAB> del self.breakpoints[id]",if dbg_id is not None :,154
"def on_update(self): <TAB> if self.company: <TAB>  <TAB> # We need a Cost Center corresponding to the selected erpnext Company <TAB>  <TAB> self.default_cost_center = frappe.db.get_value( <TAB>  <TAB>  <TAB> ""Company"", self.company, ""cost_center"" <TAB>  <TAB> ) <TAB>  <TAB> company_warehouses = frappe.get_all( <TAB>  <TAB>  <TAB> ""Warehouse"", filters={""company"": self.company, ""is_group"": 0} <TAB>  <TAB> ) <MASK> self.default_warehouse = company_warehouses[0].name <TAB> if self.authorization_endpoint: <TAB>  <TAB> self.authorization_url = self.oauth.authorization_url( <TAB>  <TAB>  <TAB> self.authorization_endpoint <TAB>  <TAB> )[0]",if company_warehouses :,181
"def webhook(): <TAB> request.get_data() <TAB> if request.json: <TAB>  <TAB> output = request.json <MASK> sender_name = output.get(""user_name"", None) <TAB>  <TAB>  <TAB> text = output.get(""text"", None) <TAB>  <TAB>  <TAB> recipient_id = output.get(""channel_id"", None) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> messages_list = output.get(""messages"", None) <TAB>  <TAB>  <TAB> text = messages_list[0].get(""msg"", None) <TAB>  <TAB>  <TAB> sender_name = messages_list[0].get(""username"", None) <TAB>  <TAB>  <TAB> recipient_id = output.get(""_id"") <TAB>  <TAB> self.send_message(text, sender_name, recipient_id, on_new_message) <TAB> return make_response()","if ""visitor"" not in output :",193
"def iter_playlistitems(format): <TAB> for string_segment in format.split("",""): <MASK> start, end = string_segment.split(""-"") <TAB>  <TAB>  <TAB> for item in range(int(start), int(end) + 1): <TAB>  <TAB>  <TAB>  <TAB> yield int(item) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield int(string_segment)","if ""-"" in string_segment :",90
"def as_dict(self, datetime_to_str=False, custom_types=None): <TAB> rv = {} <TAB> for key, val in self.items(): <MASK> val = val.as_dict() <TAB>  <TAB> elif isinstance(val, _IDReference): <TAB>  <TAB>  <TAB> val = int(val) <TAB>  <TAB> elif isinstance(val, decimal.Decimal): <TAB>  <TAB>  <TAB> val = float(val) <TAB>  <TAB> elif not isinstance(val, self._as_dict_types_): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> rv[key] = val <TAB> return rv","if isinstance ( val , Row ) :",139
"def _normalize_init_args(dtype, shape=None): <TAB> """"""Checks init arguments and converts to a normalized representation."""""" <TAB> if not isinstance(dtype, tf.DType): <MASK> dtype = tf.dtypes.as_dtype(dtype) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError(""Unrecognized dtype {}."".format(str(dtype))) <TAB> if shape is None: <TAB>  <TAB> shape = tf.TensorShape([]) <TAB> elif not isinstance(shape, tf.TensorShape): <TAB>  <TAB> shape = tf.TensorShape(shape) <TAB> return (dtype, shape)",if _is_dtype_spec ( dtype ) :,138
"def _dump_sequences(self, message, key): <TAB> """"""Inspect a new MHMessage and update sequences appropriately."""""" <TAB> pending_sequences = message.get_sequences() <TAB> all_sequences = self.get_sequences() <TAB> for name, key_list in all_sequences.items(): <TAB>  <TAB> if name in pending_sequences: <TAB>  <TAB>  <TAB> key_list.append(key) <TAB>  <TAB> elif key in key_list: <TAB>  <TAB>  <TAB> del key_list[key_list.index(key)] <TAB> for sequence in pending_sequences: <MASK> all_sequences[sequence] = [key] <TAB> self.set_sequences(all_sequences)",if sequence not in all_sequences :,161
"def main(files: List[str]) -> None: <TAB> if not files: <TAB>  <TAB> fix_directory(EDB_DIR) <TAB>  <TAB> return <TAB> for file in sys.argv[1:]: <TAB>  <TAB> path = Path(file) <TAB>  <TAB> if path.is_dir(): <TAB>  <TAB>  <TAB> fix_directory(path) <MASK> fix_one(path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print( <TAB>  <TAB>  <TAB>  <TAB> f""warning: skipped {file}, not a file or directory."", <TAB>  <TAB>  <TAB>  <TAB> file=sys.stderr, <TAB>  <TAB>  <TAB> )",elif path . is_file ( ) :,141
"def untranslate_store(cls, store, language, fuzzy=False): <TAB> """"""Remove translations from Translate Toolkit store."""""" <TAB> store.settargetlanguage(cls.get_language_code(language.code)) <TAB> plural = language.plural <TAB> for unit in store.units: <MASK> if hasattr(unit, ""markapproved""): <TAB>  <TAB>  <TAB>  <TAB> # Xliff only <TAB>  <TAB>  <TAB>  <TAB> unit.markapproved(False) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> unit.markfuzzy(fuzzy) <TAB>  <TAB>  <TAB> if unit.hasplural(): <TAB>  <TAB>  <TAB>  <TAB> unit.target = [""""] * plural.number <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> unit.target = """"",if unit . istranslatable ( ) :,170
"def open_file(filename): <TAB> import subprocess <TAB> try: <TAB>  <TAB> if sys.platform.startswith(""win""): <TAB>  <TAB>  <TAB> os.startfile(filename) <MASK> subprocess.call((""open"", filename)) <TAB>  <TAB> elif sys.platform.startswith(""linux""): <TAB>  <TAB>  <TAB> subprocess.call((""xdg-open"", filename)) <TAB> except OSError as oe: <TAB>  <TAB> log.warn(""Failed to open browser: {}"".format(oe.message))","elif sys . platform . startswith ( ""darwin"" ) :",116
"def add_fade_in(compositor, fade_in_length): <TAB> clip = _get_compositor_clip(compositor) <TAB> keyframe_property, property_klass, keyframes = _get_kfproperty_klass_and_keyframes( <TAB>  <TAB> compositor, clip <TAB> ) <TAB> if fade_in_length > 0: <MASK> return _do_user_add_fade_in( <TAB>  <TAB>  <TAB>  <TAB> keyframe_property, property_klass, keyframes, fade_in_length <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _show_length_error_dialog() <TAB>  <TAB>  <TAB> return None",if fade_in_length <= clip . clip_length ( ) :,163
"def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=False, delimiter=None): <TAB> pending = None <TAB> async for chunk in self.iter_content( <TAB>  <TAB> chunk_size=chunk_size, decode_unicode=decode_unicode <TAB> ): <MASK> chunk = pending + chunk <TAB>  <TAB> if delimiter: <TAB>  <TAB>  <TAB> lines = chunk.split(delimiter) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lines = chunk.splitlines() <TAB>  <TAB> if lines and lines[-1] and chunk and lines[-1][-1] == chunk[-1]: <TAB>  <TAB>  <TAB> pending = lines.pop() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pending = None <TAB>  <TAB> for line in lines: <TAB>  <TAB>  <TAB> yield line <TAB> if pending is not None: <TAB>  <TAB> yield pending",if pending is not None :,190
"def links_extracted(self, request, links): <TAB> for link in links: <TAB>  <TAB> link.meta[b""depth""] = request.meta[b""depth""] + 1 <MASK> link.meta[b""state""] = States.QUEUED <TAB>  <TAB>  <TAB> self.schedule(link, self.get_score(link))","if link . meta [ b""state"" ] is States . NOT_CRAWLED :",100
"def remFromStr(self, deltags, tags): <TAB> ""Delete tags if they don't exists."" <TAB> currentTags = self.split(tags) <TAB> for tag in self.split(deltags): <TAB>  <TAB> # find tags, ignoring case <TAB>  <TAB> remove = [] <TAB>  <TAB> for tx in currentTags: <MASK> remove.append(tx) <TAB>  <TAB> # remove them <TAB>  <TAB> for r in remove: <TAB>  <TAB>  <TAB> currentTags.remove(r) <TAB> return self.join(currentTags)",if tag . lower ( ) == tx . lower ( ) :,131
"def visit_Raise(self, n: ast27.Raise) -> RaiseStmt: <TAB> if n.type is None: <TAB>  <TAB> e = None <TAB> else: <TAB>  <TAB> if n.inst is None: <TAB>  <TAB>  <TAB> e = self.visit(n.type) <TAB>  <TAB> else: <MASK> e = TupleExpr([self.visit(n.type), self.visit(n.inst)]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> e = TupleExpr( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> [self.visit(n.type), self.visit(n.inst), self.visit(n.tback)] <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> stmt = RaiseStmt(e, None) <TAB> return self.set_line(stmt, n)",if n . tback is None :,179
"def closeRecvmsgFDs(self, recvmsg_result): <TAB> # Close all file descriptors specified in the ancillary data <TAB> # of the given return value from recvmsg() or recvmsg_into(). <TAB> for cmsg_level, cmsg_type, cmsg_data in recvmsg_result[1]: <MASK> fds = array.array(""i"") <TAB>  <TAB>  <TAB> fds.frombytes(cmsg_data[: len(cmsg_data) - (len(cmsg_data) % fds.itemsize)]) <TAB>  <TAB>  <TAB> for fd in fds: <TAB>  <TAB>  <TAB>  <TAB> os.close(fd)",if cmsg_level == socket . SOL_SOCKET and cmsg_type == socket . SCM_RIGHTS :,171
"def check_schedulers(self): <TAB> # don't perform this check in multiMaster mode <TAB> if self.multiMaster: <TAB>  <TAB> return <TAB> all_buildernames = set([b.name for b in self.builders]) <TAB> for s in itervalues(self.schedulers): <TAB>  <TAB> builderNames = s.listBuilderNames() <MASK> continue <TAB>  <TAB> for n in builderNames: <TAB>  <TAB>  <TAB> if interfaces.IRenderable.providedBy(n): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if n not in all_buildernames: <TAB>  <TAB>  <TAB>  <TAB> error(""Unknown builder '%s' in scheduler '%s'"" % (n, s.name))",if interfaces . IRenderable . providedBy ( builderNames ) :,165
"def test_simulate_moment_steps(dtype): <TAB> q0, q1 = cirq.LineQubit.range(2) <TAB> circuit = cirq.Circuit(cirq.H(q0), cirq.H(q1), cirq.H(q0), cirq.H(q1)) <TAB> simulator = cirq.Simulator(dtype=dtype) <TAB> for i, step in enumerate(simulator.simulate_moment_steps(circuit)): <MASK> np.testing.assert_almost_equal(step.state_vector(), np.array([0.5] * 4)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> np.testing.assert_almost_equal(step.state_vector(), np.array([1, 0, 0, 0]))",if i == 0 :,185
"def get_default_configs(): <TAB> """"""returns default configs list, from /etc and home dir"""""" <TAB> # initialize basic defaults <TAB> configs = [resource_filename(__name__, ""config/00-base.ini"")] <TAB> baseconfigs_location = ""/etc/yandex-tank"" <TAB> try: <TAB>  <TAB> conf_files = sorted(os.listdir(baseconfigs_location)) <TAB>  <TAB> for filename in conf_files: <MASK> configs += [os.path.realpath(baseconfigs_location + os.sep + filename)] <TAB> except OSError: <TAB>  <TAB> logger.info(baseconfigs_location + "" is not accessible to get configs list"") <TAB> configs += [os.path.expanduser(""~/.yandex-tank"")] <TAB> return configs","if fnmatch . fnmatch ( filename , ""*.ini"" ) :",181
"def filtered_icon(options, filter): <TAB> """"""Returns btn-primary if the filter matches one of the filter options"""""" <TAB> for option in options: <TAB>  <TAB> if filter == option[1]: <TAB>  <TAB>  <TAB> return ""btn-primary"" <MASK> return ""btn-primary"" <TAB> return """"","if ( ""daterange"" == option [ 1 ] ) and filter . startswith ( option [ 4 ] ) :",90
"def parse_templates(template_lines): <TAB> o = {} <TAB> for line in template_lines: <MASK> continue <TAB>  <TAB> k, v = line.strip().split("" = "") <TAB>  <TAB> if not k.startswith(""catalog.""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> parts = k.split(""."") <TAB>  <TAB> region = parts[1] <TAB>  <TAB> # NOTE(termie): object-store insists on having a dash <TAB>  <TAB> service = parts[2].replace(""_"", ""-"") <TAB>  <TAB> key = parts[3] <TAB>  <TAB> region_ref = o.get(region, {}) <TAB>  <TAB> service_ref = region_ref.get(service, {}) <TAB>  <TAB> service_ref[key] = v <TAB>  <TAB> region_ref[service] = service_ref <TAB>  <TAB> o[region] = region_ref <TAB> return o","if "" = "" not in line :",198
"def encode_tensor(data, device): <TAB> if isinstance(data, list): <MASK> return torch.tensor( <TAB>  <TAB>  <TAB>  <TAB> data, dtype=torch.bool, device=device <TAB>  <TAB>  <TAB> )  # pylint: disable=not-callable <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return torch.tensor( <TAB>  <TAB>  <TAB>  <TAB> data, dtype=torch.float, device=device <TAB>  <TAB>  <TAB> )  # pylint: disable=not-callable <TAB> if isinstance(data, dict): <TAB>  <TAB> return {k: encode_tensor(v, device) for k, v in data.items()} <TAB> return data","if all ( map ( lambda o : isinstance ( o , bool ) , data ) ) :",158
"def _handle(self): <TAB> current_time = monotonic() <TAB> for thread_id, deadline in self.deadlines.items(): <MASK> self.logger.warning( <TAB>  <TAB>  <TAB>  <TAB> ""Time limit exceeded. Raising exception in worker thread %r."", thread_id <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.deadlines[thread_id] = None <TAB>  <TAB>  <TAB> raise_thread_exception(thread_id, TimeLimitExceeded)",if deadline and current_time >= deadline :,113
"def __init__(self, device, presets=()): <TAB> if not device: <TAB>  <TAB> super().__init__() <TAB>  <TAB> return <TAB> if presets: <TAB>  <TAB> # presets: list of (option, value)-tuples <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> device.set_device_options(*zip(*presets)) <TAB>  <TAB> except pyrs.RealsenseError as err: <TAB>  <TAB>  <TAB> logger.error(""Setting device option presets failed"") <TAB>  <TAB>  <TAB> logger.debug(""Reason: {}"".format(err)) <TAB> controls = {} <TAB> for opt_range, value in device.get_available_options(): <MASK> controls[opt_range.option] = Control(device, opt_range, value) <TAB> super().__init__(controls)",if opt_range . min < opt_range . max :,186
"def splitoutput(output): <TAB> files = {} <TAB> curpkg = None <TAB> for line in output.splitlines(): <MASK> self.assertTrue(curpkg, ""Unexpected non-package line:\n%s"" % line) <TAB>  <TAB>  <TAB> files[curpkg].append(line.strip()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertTrue( <TAB>  <TAB>  <TAB>  <TAB> line.rstrip().endswith("":""), <TAB>  <TAB>  <TAB>  <TAB> ""Invalid package line in output:\n%s"" % line, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> curpkg = line.split("":"")[0] <TAB>  <TAB>  <TAB> files[curpkg] = [] <TAB> return files","if line . startswith ( ""\t"" ) :",154
"def __init__(self, drawing=None): <TAB> with self.allocate(): <MASK> wand = library.NewDrawingWand() <TAB>  <TAB> elif not isinstance(drawing, type(self)): <TAB>  <TAB>  <TAB> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""drawing must be a wand.drawing.Drawing "" <TAB>  <TAB>  <TAB>  <TAB> ""instance, not "" + repr(drawing) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> wand = library.CloneDrawingWand(drawing.resource) <TAB>  <TAB> self.resource = wand",if not drawing :,132
"def execute_on_mapped_over( <TAB> cls, trans, sa_session, action, step_inputs, step_outputs, replacement_dict): <TAB> if action.action_arguments: <TAB>  <TAB> tags = [ <TAB>  <TAB>  <TAB> t.replace(""#"", ""name:"") if t.startswith(""#"") else t <TAB>  <TAB>  <TAB> for t in [ <TAB>  <TAB>  <TAB>  <TAB> t.strip() <TAB>  <TAB>  <TAB>  <TAB> for t in action.action_arguments.get(""tags"", """").split("","") <MASK> ] <TAB>  <TAB> ] <TAB>  <TAB> if tags: <TAB>  <TAB>  <TAB> for name, step_output in step_outputs.items(): <TAB>  <TAB>  <TAB>  <TAB> if action.output_name == """" or name == action.output_name: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> cls._execute(trans.app, trans.user, step_output, tags)",if t . strip ( ),193
"def __getitem__(self, index: int) -> nn.Module: <TAB> """"""Gets a layer in the underlying sequential module."""""" <TAB> partitions = self.partitions <MASK> partitions = partitions[::-1] <TAB> for partition in partitions: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return partition[index] <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> shift = len(partition) <TAB>  <TAB> if index < 0: <TAB>  <TAB>  <TAB> index += shift <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> index -= shift <TAB> raise IndexError",if index < 0 :,123
"def FormatImages(appearance): <TAB> text = ""<p><br>"" + _appearanceTable <TAB> for indx in range(2): <TAB>  <TAB> text += ""\n<tr>\n"" <TAB>  <TAB> for key in _platformNames: <MASK> src = appearance[key] <TAB>  <TAB>  <TAB>  <TAB> alt = key + ""Appearance"" <TAB>  <TAB>  <TAB>  <TAB> text += _imageTag % (src, src, alt) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> text += _platformTag % key <TAB>  <TAB> text += ""</tr>\n"" <TAB> text += ""\n</table>\n\n<p>"" <TAB> return text",if indx == 0 :,154
"def open(self, event=None, url=None): <TAB> url = url or self.server.url <TAB> try: <TAB>  <TAB> import webbrowser <TAB>  <TAB> webbrowser.open(url) <TAB> except ImportError:  # pre-webbrowser.py compatibility <TAB>  <TAB> if sys.platform == ""win32"": <TAB>  <TAB>  <TAB> os.system('start ""%s""' % url) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> rc = os.system('netscape -remote ""openURL(%s)"" &' % url) <MASK> os.system('netscape ""%s"" &' % url)",if rc :,141
"def GetValue(self): <TAB> """"""The setting value underlying the text representation"""""" <TAB> value = """" <TAB> for token in self.__tokens: <MASK> value += ""\\g<"" + token.value + "">"" <TAB>  <TAB> elif token == ""\\"": <TAB>  <TAB>  <TAB> value += ""\\\\"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value += token <TAB> return value","if isinstance ( token , self . MetadataToken ) :",91
"def query(self, l, r): <TAB> l, r = l + self.size, r + self.size <TAB> res = None <TAB> while l <= r: <TAB>  <TAB> if l % 2 == 1: <TAB>  <TAB>  <TAB> res = self.tree[l] if res is None else self.fn(res, self.tree[l]) <MASK> res = self.tree[r] if res is None else self.fn(res, self.tree[r]) <TAB>  <TAB> l, r = (l + 1) // 2, (r - 1) // 2 <TAB> return res",if r % 2 == 0 :,143
"def set_dimension(self, w=0, h=0): <TAB> xratio = w / self._width <TAB> yratio = h / self._height <TAB> if self.resize_proportional and w and h: <MASK> self._height = math.ceil(xratio * self._height) <TAB>  <TAB>  <TAB> self._width = w <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._width = math.ceil(yratio * self._width) <TAB>  <TAB>  <TAB> self._height = h",if ( xratio * self . _height ) < h :,125
"def on_task_output(self, task, config): <TAB> if not config: <TAB>  <TAB> return <TAB> for entry in task.accepted: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> db.remove_series_entity(entry[""series_name""], entry[""series_id""]) <TAB>  <TAB>  <TAB>  <TAB> log.info( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Removed episode `%s` from series `%s` download history."" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> % (entry[""series_id""], entry[""series_name""]) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> log.debug( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Series (%s) or id (%s) unknown."" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> % (entry[""series_name""], entry[""series_id""]) <TAB>  <TAB>  <TAB>  <TAB> )","if ""series_name"" in entry and ""series_id"" in entry :",199
"def _iter_module_files(): <TAB> for module in sys.modules.values(): <TAB>  <TAB> filename = getattr(module, ""__file__"", None) <TAB>  <TAB> if filename: <TAB>  <TAB>  <TAB> old = None <TAB>  <TAB>  <TAB> while not os.path.isfile(filename): <TAB>  <TAB>  <TAB>  <TAB> old = filename <TAB>  <TAB>  <TAB>  <TAB> filename = os.path.dirname(filename) <MASK> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> if filename[-4:] in ("".pyc"", "".pyo""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> filename = filename[:-1] <TAB>  <TAB>  <TAB>  <TAB> yield filename",if filename == old :,143
"def dhcp(deployment_id): <TAB> deployment = Deployment.objects.get(id=deployment_id) <TAB> try: <TAB>  <TAB> entry = DHCPEntry.objects.get(ip=deployment.ip, mac=deployment.mac) <TAB> except DHCPEntry.DoesNotExist: <TAB>  <TAB> reset_dhcp(deployment.ip, deployment.mac) <TAB> else: <TAB>  <TAB> # Check that all DHCP servers already have this entry. <TAB>  <TAB> servers = DHCPServer.objects.all() <MASK> return False <TAB>  <TAB> for server in servers: <TAB>  <TAB>  <TAB> if entry.created > server.last_synchronized: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True <TAB> return False",if not servers . count ( ) :,171
"def req(self, req_method, url, params=None): <TAB> params = params or {} <TAB> headers = dict(self.headers) <TAB> headers[""Referer""] = ""https://dnsdumpster.com"" <TAB> try: <MASK> resp = self.session.get(url, headers=headers, timeout=self.timeout) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> resp = self.session.post( <TAB>  <TAB>  <TAB>  <TAB> url, data=params, headers=headers, timeout=self.timeout <TAB>  <TAB>  <TAB> ) <TAB> except Exception as e: <TAB>  <TAB> self.print_(e) <TAB>  <TAB> resp = None <TAB> return self.get_response(resp)","if req_method == ""GET"" :",165
"def _associate_dests_to_pages(self, pages): <TAB> for nd in self.named_dests: <TAB>  <TAB> pageno = None <TAB>  <TAB> np = nd[""/Page""] <TAB>  <TAB> if isinstance(np, NumberObject): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for p in pages: <TAB>  <TAB>  <TAB> if np.getObject() == p.pagedata.getObject(): <TAB>  <TAB>  <TAB>  <TAB> pageno = p.id <MASK> nd[NameObject(""/Page"")] = NumberObject(pageno) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""Unresolved named destination '%s'"" % (nd[""/Title""],))",if pageno != None :,149
"def splittest(element): <TAB> for klass in classes: <TAB>  <TAB> b = bool.get(klass.__name__, True) <TAB>  <TAB> if issubclass(element, klass): <TAB>  <TAB>  <TAB> if b: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return False <MASK> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> continue <TAB> return True",elif b :,91
"def process_event(self, event): <TAB> if event is not None: <MASK> if event.key_code in [Screen.ctrl(""M""), Screen.ctrl(""J""), ord("" "")]: <TAB>  <TAB>  <TAB>  <TAB> event = None <TAB>  <TAB> elif isinstance(event, MouseEvent): <TAB>  <TAB>  <TAB> if event.buttons != 0: <TAB>  <TAB>  <TAB>  <TAB> if self.is_mouse_over(event, include_label=False): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> event = None <TAB>  <TAB> if event is None: <TAB>  <TAB>  <TAB> self._child = _DatePickerPopup(self, year_range=self._year_range) <TAB>  <TAB>  <TAB> self.frame.scene.add_effect(self._child) <TAB> return event","if isinstance ( event , KeyboardEvent ) :",179
"def restore_test_support_TESTFN(self, saved_value): <TAB> if saved_value is None: <MASK> os.unlink(test_support.TESTFN) <TAB>  <TAB> elif os.path.isdir(test_support.TESTFN): <TAB>  <TAB>  <TAB> shutil.rmtree(test_support.TESTFN)",if os . path . isfile ( test_support . TESTFN ) :,85
"def comment(self, arg): <TAB> if arg.startswith(""AXIS,""): <TAB>  <TAB> parts = arg.split("","") <TAB>  <TAB> command = parts[1] <TAB>  <TAB> if command == ""stop"": <TAB>  <TAB>  <TAB> self.aborted = True <TAB>  <TAB> if command == ""hide"": <TAB>  <TAB>  <TAB> self.suppress += 1 <MASK> self.suppress -= 1","if command == ""show"" :",91
"def assert_shapes_equal(ref_shape, *shapes): <TAB> if isinstance(ref_shape, DebugArray): <TAB>  <TAB> ref_shape = ref_shape.shape <TAB> assert_is_shape(ref_shape) <TAB> for i, shape in enumerate(shapes, start=1): <MASK> shape = shape.shape <TAB>  <TAB> assert_is_shape(shape) <TAB>  <TAB> assert ( <TAB>  <TAB>  <TAB> shape == ref_shape <TAB>  <TAB> ), ""Shape mismatch: {}[arg_nr={}] != {}[arg_nr=0]"".format(shape, i, ref_shape)","if isinstance ( shape , DebugArray ) :",145
"def pytest_collection_modifyitems(config, items): <TAB> if not config.getoption(""--runtor""): <TAB>  <TAB> # --runtor given in cli: do not skip tor tests <TAB>  <TAB> skip_tor = pytest.mark.skip(reason=""need --runtor option to run"") <TAB>  <TAB> for item in items: <MASK> item.add_marker(skip_tor)","if ""tor"" in item . keywords :",103
"def users(): <TAB> """"""Return currently connected users as a list of namedtuples."""""" <TAB> retlist = [] <TAB> rawlist = cext.users() <TAB> for item in rawlist: <TAB>  <TAB> user, tty, hostname, tstamp, user_process = item <TAB>  <TAB> # note: the underlying C function includes entries about <TAB>  <TAB> # system boot, run level and others.  We might want <TAB>  <TAB> # to use them in the future. <TAB>  <TAB> if not user_process: <TAB>  <TAB>  <TAB> continue <MASK> hostname = ""localhost"" <TAB>  <TAB> nt = _common.suser(user, tty or None, hostname, tstamp) <TAB>  <TAB> retlist.append(nt) <TAB> return retlist","if hostname == "":0.0"" :",169
"def format(self, text): <TAB> text = text.decode(""utf-8"") <TAB> formatter = getattr(self.options, ""formatter_version"") <TAB> if formatter == ""bs4"": <MASK> sublime.error_message( <TAB>  <TAB>  <TAB>  <TAB> u""CodeFormatter\n\nUnable to load BeautifulSoup HTML "" <TAB>  <TAB>  <TAB>  <TAB> u""formatter. The old RegExp-based formatter was "" <TAB>  <TAB>  <TAB>  <TAB> u""automatically used for you instead."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.format_with_bs4(text) <TAB> return self.format_with_beautifier(text)",if not use_bs4 :,155
"def __exit__(self, ex_type, ex_value, traceback): <TAB> super(SPA, self).__exit__(ex_type, ex_value, traceback) <TAB> if ex_type is not None: <TAB>  <TAB> # re-raise the exception that triggered this __exit__ <TAB>  <TAB> return False <TAB> module_list = frozenset(self._modules.values()) <TAB> for net in self.networks: <TAB>  <TAB> # Since there are no attributes to distinguish what's been added <TAB>  <TAB> # and what hasn't, we have to ask the network <MASK> raise SpaModuleError( <TAB>  <TAB>  <TAB>  <TAB> ""%s must be set as an attribute of "" ""a SPA network"" % (net) <TAB>  <TAB>  <TAB> )","if isinstance ( net , Module ) and ( net not in module_list ) :",180
"def run(self): <TAB> try: <MASK> if self.previous_thread.is_alive(): <TAB>  <TAB>  <TAB>  <TAB> self.previous_thread.join() <TAB>  <TAB>  <TAB> with self.connection._write_lock: <TAB>  <TAB>  <TAB>  <TAB> self.connection.networking_thread = self <TAB>  <TAB>  <TAB>  <TAB> self.connection.new_networking_thread = None <TAB>  <TAB> self._run() <TAB>  <TAB> self.connection._handle_exit() <TAB> except Exception as e: <TAB>  <TAB> self.interrupt = True <TAB>  <TAB> self.connection._handle_exception(e, sys.exc_info()) <TAB> finally: <TAB>  <TAB> with self.connection._write_lock: <TAB>  <TAB>  <TAB> self.connection.networking_thread = None",if self . previous_thread is not None :,178
"def generate_rand_list( <TAB> size, with_arrays=False, with_string=False, array_shape=(10, 10)): <TAB> """"""Generate list with random values from list of keys."""""" <TAB> ret = [] <TAB> rnd = np.random.RandomState(0) <TAB> for random in rnd.random_sample((size)): <MASK> ret.append(rnd.random_sample(array_shape)) <TAB>  <TAB> elif with_string: <TAB>  <TAB>  <TAB> ret.append(str(random)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret.append(int(random)) <TAB> return ret",if with_arrays :,143
"def sort(self): <TAB> sorted_models = [] <TAB> concrete_models = set() <TAB> models = self.data.keys() <TAB> while len(sorted_models) < len(models): <TAB>  <TAB> found = False <TAB>  <TAB> for model in models: <TAB>  <TAB>  <TAB> if model in sorted_models: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> dependencies = self.dependencies.get(model._meta.concrete_model) <TAB>  <TAB>  <TAB> if not (dependencies and dependencies.difference(concrete_models)): <TAB>  <TAB>  <TAB>  <TAB> sorted_models.append(model) <TAB>  <TAB>  <TAB>  <TAB> concrete_models.add(model._meta.concrete_model) <TAB>  <TAB>  <TAB>  <TAB> found = True <MASK> return <TAB> self.data = SortedDict([(model, self.data[model]) for model in sorted_models])",if not found :,190
"def bring_out_your_dead(self): <TAB> # Remove dead threads from the pool <TAB> dead_threads = [t for t in self.threads if not t.isAlive()] <TAB> for t in dead_threads: <MASK> log.debug(""Removing dead thread: %s."" % t.getName()) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> # Py2.4 complains here so we put it in a try block <TAB>  <TAB>  <TAB> self.threads.remove(t) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> pass <TAB> self.check_for_dead_threads -= len(dead_threads)",if __debug__ :,142
"def format_unencoded(self, tokensource, outfile): <TAB> if self.linenos: <TAB>  <TAB> self._write_lineno(outfile) <TAB> for ttype, value in tokensource: <TAB>  <TAB> color = self._get_color(ttype) <TAB>  <TAB> for line in value.splitlines(True): <MASK> outfile.write(ansiformat(color, line.rstrip(""\n""))) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> outfile.write(line.rstrip(""\n"")) <TAB>  <TAB>  <TAB> if line.endswith(""\n""): <TAB>  <TAB>  <TAB>  <TAB> if self.linenos: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._write_lineno(outfile) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> outfile.write(""\n"") <TAB> if self.linenos: <TAB>  <TAB> outfile.write(""\n"")",if color :,185
"def symlink(link_to, link_from): <TAB> """"""Link link_from to the directory link_to universally."""""" <TAB> if os.path.exists(link_from) and not os.path.islink(link_from): <TAB>  <TAB> shutil.rmtree(link_from) <TAB> try: <MASK> os.symlink(link_to, link_from, target_is_directory=True) <TAB>  <TAB> elif not WINDOWS: <TAB>  <TAB>  <TAB> os.symlink(link_to, link_from) <TAB> except OSError: <TAB>  <TAB> logger.log_exc() <TAB> else: <TAB>  <TAB> return <TAB> if not os.path.islink(link_from): <TAB>  <TAB> shutil.copytree(link_to, link_from)",if PY32 :,174
"def _hookForMethod(self, method): <TAB> # return recording hook for most hooks, normal hook for those <TAB> # (like test loading and subprocess events) that we don't want <TAB> # to send back to the main process. <TAB> try: <TAB>  <TAB> return self.hooks[method] <TAB> except KeyError: <MASK> hook = events.Hook(method) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> hook = self.hookClass(method, self) <TAB> self.hooks[method] = hook <TAB> return hook","if method in self . noLogMethods or method . startswith ( ""loadTest"" ) :",136
"def intread(buf): <TAB> """"""Unpacks the given buffer to an integer"""""" <TAB> try: <MASK> return buf <TAB>  <TAB> length = len(buf) <TAB>  <TAB> if length == 1: <TAB>  <TAB>  <TAB> return buf[0] <TAB>  <TAB> elif length <= 4: <TAB>  <TAB>  <TAB> tmp = buf + b""\x00"" * (4 - length) <TAB>  <TAB>  <TAB> return struct_unpack(""<I"", tmp)[0] <TAB>  <TAB> tmp = buf + b""\x00"" * (8 - length) <TAB>  <TAB> return struct_unpack(""<Q"", tmp)[0] <TAB> except: <TAB>  <TAB> raise","if isinstance ( buf , int ) :",147
"def ioctl(self): <TAB> try: <TAB>  <TAB> if fcntl.ioctl(self.sock, SIOCETHTOOL, self.ifreq): <TAB>  <TAB>  <TAB> raise NotSupportedError() <TAB> except OSError as e: <TAB>  <TAB> if e.errno == errno.ENOTSUP: <TAB>  <TAB>  <TAB> raise NotSupportedError(self.ifname.decode(""utf-8"")) <MASK> raise NoSuchDevice(self.ifname.decode(""utf-8"")) <TAB>  <TAB> raise",elif e . errno == errno . ENODEV :,119
"def valueFromRemoteObject(remoteObject: Dict) -> Any: <TAB> """"""Serialize value of remote object."""""" <TAB> if remoteObject.get(""objectId""): <TAB>  <TAB> raise ElementHandleError(""Cannot extract value when objectId is given"") <TAB> value = remoteObject.get(""unserializableValue"") <TAB> if value: <MASK> return -0 <TAB>  <TAB> elif value == ""NaN"": <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> elif value == ""Infinity"": <TAB>  <TAB>  <TAB> return math.inf <TAB>  <TAB> elif value == ""-Infinity"": <TAB>  <TAB>  <TAB> return -math.inf <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ElementHandleError( <TAB>  <TAB>  <TAB>  <TAB> ""Unsupported unserializable value: {}"".format(value) <TAB>  <TAB>  <TAB> ) <TAB> return remoteObject.get(""value"")","if value == ""-0"" :",181
"def deserialize_metadata(response, obj, headers):  # pylint: disable=unused-argument <TAB> try: <TAB>  <TAB> raw_metadata = { <TAB>  <TAB>  <TAB> k: v <TAB>  <TAB>  <TAB> for k, v in response.http_response.headers.items() <MASK> } <TAB> except AttributeError: <TAB>  <TAB> raw_metadata = { <TAB>  <TAB>  <TAB> k: v for k, v in response.headers.items() if k.startswith(""x-ms-meta-"") <TAB>  <TAB> } <TAB> return {k[10:]: v for k, v in raw_metadata.items()}","if k . startswith ( ""x-ms-meta-"" )",144
"def ql_syscall_recv(ql, recv_sockfd, recv_buf, recv_len, recv_flags, *args, **kw): <TAB> if recv_sockfd < 256 and ql.os.fd[recv_sockfd] != 0: <TAB>  <TAB> tmp_buf = ql.os.fd[recv_sockfd].recv(recv_len, recv_flags) <MASK> ql.log.debug(""recv() CONTENT:"") <TAB>  <TAB>  <TAB> ql.log.debug(""%s"" % tmp_buf) <TAB>  <TAB> ql.mem.write(recv_buf, tmp_buf) <TAB>  <TAB> regreturn = len(tmp_buf) <TAB> else: <TAB>  <TAB> regreturn = -1 <TAB> return regreturn",if tmp_buf :,175
"def gen_hex_map(meta, h): <TAB> r = [] <TAB> cell = None <TAB> for i, m in enumerate(meta): <TAB>  <TAB> c = [] <TAB>  <TAB> r.append(c) <TAB>  <TAB> for j, info in enumerate(m): <TAB>  <TAB>  <TAB> if cell is None: <TAB>  <TAB>  <TAB>  <TAB> cell = HexCell(0, 0, h, None, None) <TAB>  <TAB>  <TAB> k = j <MASK> k += 1 <TAB>  <TAB>  <TAB> c.append(HexCell(i, j, h, dict(info), Tile(""dbg"", {}, None))) <TAB> return HexMap(""debug"", h, r)",if not i % 2 :,154
"def flatten_dict(dct, delim=""."", prefix=""""): <TAB> ret = {} <TAB> for key, val in list(dct.items()): <MASK> ret.update(flatten_dict(val, prefix=prefix + key + delim)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret[prefix + key] = val <TAB> return ret",if type ( val ) == dict :,84
"def _format_extension_header(self, parsed_extensions): <TAB> if not parsed_extensions: <TAB>  <TAB> return None <TAB> parts = [] <TAB> for name, config in parsed_extensions.items(): <TAB>  <TAB> ext_parts = [six.b(name)] <TAB>  <TAB> for key, value in config.items(): <TAB>  <TAB>  <TAB> if value is False: <TAB>  <TAB>  <TAB>  <TAB> pass <MASK> ext_parts.append(six.b(key)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> ext_parts.append(six.b(""%s=%s"" % (key, str(value)))) <TAB>  <TAB> parts.append(b""; "".join(ext_parts)) <TAB> return b"", "".join(parts)",elif value is True :,172
"def pause(self): <TAB> try: <TAB>  <TAB> import psutil <TAB>  <TAB> p = psutil.Process(self.pid) <TAB>  <TAB> p.suspend() <TAB> except ImportError: <MASK> common.warning( <TAB>  <TAB>  <TAB>  <TAB> ""psutil not installed. Pause functionality will not work properly on Windows."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> os.kill(self.pid, signal.SIGSTOP)",if common . is_win ( ) :,105
"def set_menu_bar(self, menubar): <TAB> if menubar is not self._menubar: <TAB>  <TAB> if self._menubar: <TAB>  <TAB>  <TAB> self.remove(self._menubar) <TAB>  <TAB> self._menubar = menubar <TAB>  <TAB> if menubar: <MASK> menubar.width = self.width <TAB>  <TAB>  <TAB>  <TAB> menubar.anchor = ""lr"" <TAB>  <TAB>  <TAB> self.add(menubar)",if menubar . width == 0 :,101
"def read(self, size): <TAB> if self._file_end is not None: <TAB>  <TAB> max_size = self._file_end - self._buf.tell() <MASK> size = max_size <TAB>  <TAB> size = max(min(size, max_size), 0) <TAB> return self._buf.read(size)",if size == - 1 :,85
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.set_new_limit(d.getVarInt64()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 8 :,92
"def useAviHeader(self, header): <TAB> microsec = header[""microsec_per_frame""].value <TAB> if microsec: <TAB>  <TAB> self.frame_rate = 1000000.0 / microsec <TAB>  <TAB> total_frame = getValue(header, ""total_frame"") <MASK> self.duration = timedelta(microseconds=total_frame * microsec) <TAB> self.width = header[""width""].value <TAB> self.height = header[""height""].value","if total_frame and not self . has ( ""duration"" ) :",120
"def update_event_source_mapping(self, uuid, spec): <TAB> esm = self.get_event_source_mapping(uuid) <TAB> if not esm: <TAB>  <TAB> return False <TAB> for key, value in spec.items(): <TAB>  <TAB> if key == ""FunctionName"": <TAB>  <TAB>  <TAB> func = self._lambdas.get_function_by_name_or_arn(spec[key]) <TAB>  <TAB>  <TAB> esm.function_arn = func.function_arn <MASK> esm.batch_size = spec[key] <TAB>  <TAB> elif key == ""Enabled"": <TAB>  <TAB>  <TAB> esm.enabled = spec[key] <TAB> esm.last_modified = time.mktime(datetime.datetime.utcnow().timetuple()) <TAB> return esm","elif key == ""BatchSize"" :",182
"def __init__(self, attributes=None, fields=None, **kw): <TAB> super(CEnum, self).__init__(**kw) <TAB> self.add_attributes(attributes) <TAB> self.fields = fields or [] <TAB> # Number the enum constants. <TAB> counter = CNumber(0) <TAB> for x in self.fields: <MASK> x.value = counter <TAB>  <TAB>  <TAB> counter = CFunctionCall(""+"", (counter, CNumber(1))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Start counting the next free field from the current assigned <TAB>  <TAB>  <TAB> # one. <TAB>  <TAB>  <TAB> counter = CFunctionCall(""+"", [x.value, CNumber(1)])",if x . value is None :,160
"def __validate_unknown_fields(self, field): <TAB> if self.allow_unknown: <TAB>  <TAB> value = self.document[field] <MASK> # validate that unknown fields matches the schema <TAB>  <TAB>  <TAB> # for unknown_fields <TAB>  <TAB>  <TAB> schema_crumb = ""allow_unknown"" if self.is_child else ""__allow_unknown__"" <TAB>  <TAB>  <TAB> validator = self._get_child_validator( <TAB>  <TAB>  <TAB>  <TAB> schema_crumb=schema_crumb, schema={field: self.allow_unknown} <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> if not validator({field: value}, normalize=False): <TAB>  <TAB>  <TAB>  <TAB> self._error(validator._errors) <TAB> else: <TAB>  <TAB> self._error(field, errors.UNKNOWN_FIELD)","if isinstance ( self . allow_unknown , ( Mapping , _str_type ) ) :",189
"def draw(self): <TAB> """"""draw the map and the block"""""" <TAB> glPushMatrix() <TAB> self.transform() <TAB> for i in range(COLUMNS): <TAB>  <TAB> for j in range(ROWS): <TAB>  <TAB>  <TAB> color = self.model.map.get((i, j)) <MASK> Colors.images[color].blit(i * SQUARE_SIZE, j * SQUARE_SIZE) <TAB> if self.model.block: <TAB>  <TAB> self.model.block.draw() <TAB> glPopMatrix()",if color :,127
"def add_featured(request): <TAB> """"""Adds featured by given ids (within request body)."""""" <TAB> for temp_id in request.POST.keys(): <MASK> continue <TAB>  <TAB> temp_id = temp_id.split(""-"")[1] <TAB>  <TAB> FeaturedProduct.objects.create(product_id=temp_id) <TAB> _update_positions() <TAB> html = [[""#featured-inline"", manage_featured_inline(request, as_string=True)]] <TAB> result = json.dumps( <TAB>  <TAB> {""html"": html, ""message"": _(u""Featured product has been added."")}, <TAB>  <TAB> cls=LazyEncoder, <TAB> ) <TAB> return HttpResponse(result, content_type=""application/json"")","if temp_id . startswith ( ""product"" ) == False :",175
"def page_add(request, response_format=""html""): <TAB> ""Static Page add"" <TAB> if request.POST: <TAB>  <TAB> form = PageForm(request.POST) <MASK> page = form.save() <TAB>  <TAB>  <TAB> return HttpResponseRedirect(reverse(""core_admin_page_view"", args=[page.id])) <TAB> else: <TAB>  <TAB> form = PageForm() <TAB> return render_to_response( <TAB>  <TAB> ""core/administration/page_add"", <TAB>  <TAB> {""form"": form}, <TAB>  <TAB> context_instance=RequestContext(request), <TAB>  <TAB> response_format=response_format, <TAB> )",if form . is_valid ( ) :,152
"def _maybe_name_to_id(self, name_or_id): <TAB> if is_str(name_or_id): <MASK> raise ValueError(""Unknown data name: {}"".format(name_or_id)) <TAB>  <TAB> return self._name_to_id[name_or_id] <TAB> return name_or_id",if name_or_id not in self . _name_to_id :,97
"def run(self, fileStore): <TAB> with fileStore.readGlobalFileStream(self.failFileID) as failValue: <MASK> raise RuntimeError(""planned exception"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> with fileStore.readGlobalFileStream(self.inputFileID) as fi: <TAB>  <TAB>  <TAB>  <TAB> with fileStore.writeGlobalFileStream() as (fo, outputFileID): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> fo.write((fi.read().decode(""utf-8"") + ""World!"").encode(""utf-8"")) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return outputFileID","if failValue . read ( ) . decode ( ""utf-8"" ) == ""True"" :",150
"def __eq__(self, other: object) -> bool: <TAB> if isinstance(other, TypedDictType): <MASK> return False <TAB>  <TAB> for (_, left_item_type, right_item_type) in self.zip(other): <TAB>  <TAB>  <TAB> if not left_item_type == right_item_type: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB> self.fallback == other.fallback <TAB>  <TAB>  <TAB> and self.required_keys == other.required_keys <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> return NotImplemented",if frozenset ( self . items . keys ( ) ) != frozenset ( other . items . keys ( ) ) :,144
"def follow(self, proto): <TAB> conn = Database.connect_database(self.PATH) <TAB> with conn: <TAB>  <TAB> cursor = conn.cursor() <TAB>  <TAB> f = Following() <TAB>  <TAB> ser = self.get_following() <TAB>  <TAB> if ser is not None: <TAB>  <TAB>  <TAB> f.ParseFromString(ser) <TAB>  <TAB>  <TAB> for user in f.users: <MASK> f.users.remove(user) <TAB>  <TAB> f.users.extend([proto]) <TAB>  <TAB> cursor.execute( <TAB>  <TAB>  <TAB> """"""INSERT OR REPLACE INTO following(id, serializedFollowing) VALUES (?,?)"""""", <TAB>  <TAB>  <TAB> (1, f.SerializeToString()), <TAB>  <TAB> ) <TAB>  <TAB> conn.commit() <TAB> conn.close()",if user . guid == proto . guid :,179
"def autoBeautify(self, p): <TAB> """"""Auto beautify p's tree if allowed by settings and directives."""""" <TAB> c = self.c <TAB> try: <TAB>  <TAB> if not p.isDirty(): <TAB>  <TAB>  <TAB> return <MASK> return <TAB>  <TAB> if c.config.getBool(""tidy-autobeautify""): <TAB>  <TAB>  <TAB> leoBeautify.beautifyPythonTree(event={""c"": c, ""p0"": p.copy()}) <TAB> except Exception: <TAB>  <TAB> g.es(""unexpected exception"") <TAB>  <TAB> g.es_exception()",if leoBeautify . should_kill_beautify ( p ) :,146
"def on_task_filter(self, task, config): <TAB> if not config: <TAB>  <TAB> return <TAB> with Session() as session: <TAB>  <TAB> for entry in task.entries: <TAB>  <TAB>  <TAB> # Cache all new task entries <TAB>  <TAB>  <TAB> if entry.get(""approved""): <TAB>  <TAB>  <TAB>  <TAB> entry.accept(""entry is marked as approved"") <MASK> log.verbose(""creating new pending entry %s"", entry) <TAB>  <TAB>  <TAB>  <TAB> session.add(db.PendingEntry(task_name=task.name, entry=entry)) <TAB>  <TAB>  <TAB>  <TAB> entry.reject(""new unapproved entry, caching and waiting for approval"")","elif not self . _item_query ( entry , task , session ) :",161
"def index_nodes(self, c): <TAB> writer = self.ix.writer() <TAB> doc = c.mFileName <TAB> for p in c.all_unique_positions(): <TAB>  <TAB> # print ""pushing"",p <MASK> par = p.parent().get_UNL() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> par = c.mFileName <TAB>  <TAB> writer.add_document(h=p.h, b=p.b, gnx=g.toUnicode(p.gnx), parent=par, doc=doc) <TAB> writer.commit() <TAB> self.gnxcache.clear()",if p . hasParent ( ) :,148
"def generate_files(self, path, filenames): <TAB> pathfiles = [] <TAB> for f in filenames: <TAB>  <TAB> pathfile = os.path.join(path, f) <MASK> os.makedirs(os.path.dirname(pathfile)) <TAB>  <TAB> with open(pathfile, ""w"") as fh: <TAB>  <TAB>  <TAB> fh.write(f) <TAB>  <TAB> pathfiles.append(pathfile) <TAB> return pathfiles",if not os . path . isdir ( os . path . dirname ( pathfile ) ) :,119
"def changes(): <TAB> """"""Extract part of changelog pertaining to version."""""" <TAB> _version = version() <TAB> f = open(os.path.join(get_base_dir(), ""CHANGES.txt""), ""r"") <TAB> lines = [] <TAB> for line in f: <MASK> if len(lines) > 1: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if lines: <TAB>  <TAB>  <TAB> lines.append(line) <TAB>  <TAB> elif line.startswith(_version): <TAB>  <TAB>  <TAB> lines.append(line) <TAB> f.close() <TAB> return """".join(lines[:-1])","if line . startswith ( ""====="" ) :",142
"def generateSensorsState(): <TAB> for sensor in bridge_config[""sensors""]: <MASK> sensors_state[sensor] = {""state"": {}} <TAB>  <TAB>  <TAB> for key in bridge_config[""sensors""][sensor][""state""].iterkeys(): <TAB>  <TAB>  <TAB>  <TAB> if key in [""lastupdated"", ""presence"", ""flag"", ""dark"", ""status""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> sensors_state[sensor][""state""].update({key: ""2017-01-01T00:00:00""})","if sensor not in sensors_state and ""state"" in bridge_config [ ""sensors"" ] [ sensor ] :",141
"def tearDown(self): <TAB> try: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> for i in range(self.TEST_DIRS): <TAB>  <TAB>  <TAB>  <TAB> dir = getattr(self, ""dir%i"" % (i + 1)) <TAB>  <TAB>  <TAB>  <TAB> if os.path.exists(dir): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> shutil.rmtree(dir) <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> for i in range(self.TEST_FILES): <TAB>  <TAB>  <TAB>  <TAB> filename = getattr(self, ""filename%i"" % (i + 1)) <MASK> os.remove(filename) <TAB> finally: <TAB>  <TAB> sys.path = self.orig_syspath <TAB>  <TAB> os.chdir(self.orig_cwd)",if os . path . exists ( filename ) :,175
"def addArgs(arglist): <TAB> for arg in arglist: <TAB>  <TAB> if isinstance(arg, ast.Tuple): <TAB>  <TAB>  <TAB> addArgs(arg.elts) <TAB>  <TAB> else: <MASK> self.report(messages.DuplicateArgument, node, arg.id) <TAB>  <TAB>  <TAB> args.append(arg.id)",if arg . id in args :,85
"def expand_tree_globs(root, subdirs, globs): <TAB> if root.endswith(""/""): <TAB>  <TAB> root = root[:-1] <TAB> dirglobs = [] <TAB> for subdir in subdirs: <TAB>  <TAB> for g in globs: <MASK> dirglobs.append(path.join(subdir, g)) <TAB>  <TAB> for dirpath, dirs, files in os.walk(path.join(root, subdir)): <TAB>  <TAB>  <TAB> curdir = dirpath[len(root) + 1 :] <TAB>  <TAB>  <TAB> for d in dirs: <TAB>  <TAB>  <TAB>  <TAB> for g in globs: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if glob.glob(path.join(root, curdir, d, g)): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> dirglobs.append(path.join(curdir, d, g)) <TAB> return dirglobs","if glob . glob ( path . join ( root , subdir , g ) ) :",194
"def find_next_implementations(all_names: Set[str]) -> bool: <TAB> next_implemented_by = {} <TAB> for name in all_names: <TAB>  <TAB> if has_some_implementation(name): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> value = getattr(cls, name, None) <MASK> continue <TAB>  <TAB> for alt_name, impl in getattr(value, ""_abstract_alternatives_""): <TAB>  <TAB>  <TAB> if has_some_implementation(alt_name): <TAB>  <TAB>  <TAB>  <TAB> next_implemented_by[name] = impl <TAB>  <TAB>  <TAB>  <TAB> break <TAB> implemented_by.update(next_implemented_by) <TAB> return bool(next_implemented_by)","if not hasattr ( value , ""_abstract_alternatives_"" ) :",168
"def get_bigrams(words): <TAB> result = [] <TAB> for i, w in enumerate(words): <MASK> result.append(words[i] + words[i + 1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result.append(words[i] + ""<end>"") <TAB> return result",if i != len ( words ) - 1 :,81
"def test_all_vulnerability_names_from_db_are_used(self): <TAB> vuln_names = VULNS.keys() <TAB> all_plugin_sources = self.get_all_plugins_source() <TAB> missing_ignore = {""TestCase"", ""Blind SQL injection vulnerability""} <TAB> for vuln_name in vuln_names: <MASK> continue <TAB>  <TAB> msg = '""%s"" not in plugin sources' % vuln_name <TAB>  <TAB> self.assertIn(vuln_name, all_plugin_sources, msg)",if vuln_name in missing_ignore :,130
"def dynload_modules(): <TAB> result = set(sys.builtin_module_names) <TAB> dynload_path = os.path.join(_stdlib_path(), ""lib-dynload"") <TAB> if os.path.exists(dynload_path): <TAB>  <TAB> for name in os.listdir(dynload_path): <TAB>  <TAB>  <TAB> path = os.path.join(dynload_path, name) <MASK> if name.endswith("".so"") or name.endswith("".dll""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> result.add(os.path.splitext(name)[0]) <TAB> return result",if os . path . isfile ( path ) :,154
"def transform_chunk(self, chunk: bytes, finishing: bool) -> bytes: <TAB> if self._gzipping: <TAB>  <TAB> self._gzip_file.write(chunk) <MASK> self._gzip_file.close() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._gzip_file.flush() <TAB>  <TAB> chunk = self._gzip_value.getvalue() <TAB>  <TAB> self._gzip_value.truncate(0) <TAB>  <TAB> self._gzip_value.seek(0) <TAB> return chunk",if finishing :,120
"def test_report_key_pattern(self): <TAB> self.trainer.extend(self.create_extension()) <TAB> self.trainer.run() <TAB> pattern = r""^(.+/){2,}(data|grad)/.+[^/]$"" <TAB> for name in six.iterkeys(self.trainer.observation): <MASK> assert name.startswith(self.prefix) <TAB>  <TAB> match = re.match(pattern, name) <TAB>  <TAB> assert match is not None <TAB>  <TAB> if self.report_params and self.report_grads: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> elif self.report_params: <TAB>  <TAB>  <TAB> assert ""data"" == match.group(2) <TAB>  <TAB> elif self.report_grads: <TAB>  <TAB>  <TAB> assert ""grad"" == match.group(2)",if self . prefix is not None :,189
"def _parse_reponse(self, response): <TAB> root = parseString(response).firstChild <TAB> for elem in root.childNodes: <MASK> continue <TAB>  <TAB> if elem.tagName == ""success"": <TAB>  <TAB>  <TAB> res = dict(elem.attributes.items()) <TAB>  <TAB>  <TAB> res[""message""] = """" <TAB>  <TAB>  <TAB> res[""type""] = elem.tagName <TAB>  <TAB>  <TAB> return res <TAB>  <TAB> if elem.tagName == ""error"": <TAB>  <TAB>  <TAB> res = dict(elem.attributes.items()) <TAB>  <TAB>  <TAB> res[""message""] = elem.firstChild.nodeValue <TAB>  <TAB>  <TAB> res[""type""] = elem.tagName <TAB>  <TAB>  <TAB> return res",if elem . nodeType == elem . TEXT_NODE :,169
"def SetStyle(self, *styles): <TAB> out = [] <TAB> fReadonly = None <TAB> for i in styles: <TAB>  <TAB> if ""readonly"" in i: <TAB>  <TAB>  <TAB> fReadonly = i <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> out.append(i) <TAB> if fReadonly: <TAB>  <TAB> flag = 1 <MASK> flag = 0 <TAB>  <TAB> if fReadonly[0] == ""~"": <TAB>  <TAB>  <TAB> ES_READONLY = 2048 <TAB>  <TAB>  <TAB> if self.GetStyleL(""style"") & ES_READONLY: <TAB>  <TAB>  <TAB>  <TAB> flag = 0 <TAB>  <TAB> self.SendMessage(self.Hwnd, self.Msg.EM_SETREADONLY, flag, 0) <TAB> if out: <TAB>  <TAB> ControlMethods.SetStyle(self, *out)","if fReadonly [ 0 ] == ""-"" :",188
"def linerange_fix(node): <TAB> """"""Try and work around a known Python bug with multi-line strings."""""" <TAB> # deal with multiline strings lineno behavior (Python issue #16806) <TAB> lines = linerange(node) <TAB> if hasattr(node, ""_bandit_sibling"") and hasattr(node._bandit_sibling, ""lineno""): <TAB>  <TAB> start = min(lines) <TAB>  <TAB> delta = node._bandit_sibling.lineno - start <MASK> return list(range(start, node._bandit_sibling.lineno)) <TAB> return lines",if delta > 1 :,135
"def do_read(self, size): <TAB> res = """" <TAB> while size > 0: <TAB>  <TAB> data = self.socket.recv(size) <TAB>  <TAB> l = len(data) <MASK> logger.warning(""0 size read"") <TAB>  <TAB>  <TAB> return res  #: TODO raise an error <TAB>  <TAB> size = size - l <TAB>  <TAB> res = res + data <TAB> return res",if l == 0 :,96
"def addDirectory(self, path): <TAB> if path.endswith(""/""): <TAB>  <TAB> if path in [directory + ""/"" for directory in self.excludeSubdirs]: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> dir = self.currentDirectory + path <MASK> return False <TAB>  <TAB> if self.recursive_level_max and dir.count(""/"") > self.recursive_level_max: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> self.directories.put(dir) <TAB>  <TAB> self.allJobs += 1 <TAB>  <TAB> self.doneDirs.append(dir) <TAB>  <TAB> return True <TAB> else: <TAB>  <TAB> return False",if dir in self . doneDirs :,147
"def update_availability(self, address, available): <TAB> cont = 0 <TAB> while cont < len(self._address_info): <MASK> self._address_info[cont][5] = True if available else False <TAB>  <TAB>  <TAB> self._address_info[cont][6] = datetime.now() <TAB>  <TAB>  <TAB> break <TAB>  <TAB> cont += 1",if self . address_info [ cont ] == address :,95
"def get_toctree_for(self, docname, builder, collapse): <TAB> """"""Return the global TOC nodetree."""""" <TAB> doctree = self.get_doctree(self.config.master_doc) <TAB> for toctreenode in doctree.traverse(addnodes.toctree): <TAB>  <TAB> result = self.resolve_toctree( <TAB>  <TAB>  <TAB> docname, builder, toctreenode, prune=True, collapse=collapse <TAB>  <TAB> ) <MASK> return result",if result is not None :,118
"def _call_ratios_cycle(self, cycle, function, ranks, call_ratios, visited): <TAB> if function not in visited: <TAB>  <TAB> visited.add(function) <TAB>  <TAB> for call in function.calls.itervalues(): <TAB>  <TAB>  <TAB> if call.callee_id != function.id: <TAB>  <TAB>  <TAB>  <TAB> callee = self.functions[call.callee_id] <TAB>  <TAB>  <TAB>  <TAB> if callee.cycle is cycle: <MASK> call_ratios[callee] = call_ratios.get(callee, 0.0) + call.ratio <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._call_ratios_cycle( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> cycle, callee, ranks, call_ratios, visited <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> )",if ranks [ callee ] > ranks [ function ] :,184
"def scan_resource_conf(self, conf): <TAB> if ""Properties"" in conf.keys(): <TAB>  <TAB> properties = conf[""Properties""] <TAB>  <TAB> if ""Environment"" in properties.keys(): <TAB>  <TAB>  <TAB> environment = properties[""Environment""] <MASK> variables = environment[""Variables""] <TAB>  <TAB>  <TAB>  <TAB> for value in variables.values(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if string_has_secrets(str(value)): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return CheckResult.FAILED <TAB> return CheckResult.PASSED","if ""Variables"" in environment . keys ( ) :",130
"def isstaticmethod(obj: Any, cls: Any = None, name: str = None) -> bool: <TAB> """"""Check if the object is staticmethod."""""" <TAB> if isinstance(obj, staticmethod): <TAB>  <TAB> return True <TAB> elif cls and name: <TAB>  <TAB> # trace __mro__ if the method is defined in parent class <TAB>  <TAB> # <TAB>  <TAB> # .. note:: This only works well with new style classes. <TAB>  <TAB> for basecls in getattr(cls, ""__mro__"", [cls]): <TAB>  <TAB>  <TAB> meth = basecls.__dict__.get(name) <TAB>  <TAB>  <TAB> if meth: <MASK> return True <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return False","if isinstance ( meth , staticmethod ) :",169
"def _cudaGetFunctionPointer(name): <TAB> global cudaLib <TAB> if name in _cudaGetFunctionPointer_cache: <TAB>  <TAB> return _cudaGetFunctionPointer_cache[name] <TAB> libLoadLock.acquire() <TAB> try: <TAB>  <TAB> # ensure library was loaded <MASK> raise NVMLError(NVML_ERROR_UNINITIALIZED) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> _cudaGetFunctionPointer_cache[name] = getattr(cudaLib, name) <TAB>  <TAB>  <TAB> return _cudaGetFunctionPointer_cache[name] <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB> raise NVMLError(NVML_ERROR_FUNCTION_NOT_FOUND) <TAB> finally: <TAB>  <TAB> # lock is always freed <TAB>  <TAB> libLoadLock.release()",if cudaLib == None :,177
"def f1(self, x: int, y: int, a: A, b: A, c: A) -> A: <TAB> w = A(0, 0, 0) <TAB> flip = False <TAB> for i in range(x): <MASK> flip = False <TAB>  <TAB>  <TAB> w.iadd(self.f2(y, a, b, c, 1, 2, 3)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> flip = True <TAB>  <TAB>  <TAB> w.iadd(self.f2(y, a, b, c, 4, 5, 6)) <TAB> return w",if flip :,139
"def pre_validate(self, form): <TAB> if self._invalid_formdata: <TAB>  <TAB> raise ValidationError(self.gettext(u""Not a valid choice"")) <TAB> elif self.data: <TAB>  <TAB> obj_list = list(x[1] for x in self._get_object_list()) <TAB>  <TAB> for v in self.data: <MASK> raise ValidationError(self.gettext(u""Not a valid choice""))",if v not in obj_list :,108
"def _transform_single_init_kwarg(prop, field, value, kwargs): <TAB> if value is not None and not isinstance(value, prop.value_class): <TAB>  <TAB> raise TypeError( <TAB>  <TAB>  <TAB> 'Expecting type %s for field ""%s"" (got %r)' <TAB>  <TAB>  <TAB> % (prop.value_class.__name__, field, value) <TAB>  <TAB> ) <TAB> for (attr, path) in prop._fields.items(): <TAB>  <TAB> if ""."" in path: <TAB>  <TAB>  <TAB> continue  # Only set ""local"" fields <MASK> f = (field, path) <TAB>  <TAB>  <TAB> raise TypeError(""Fields %s and %s conflict"" % f) <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB> kwargs[path] = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> kwargs[path] = getattr(value, attr)",if path in kwargs :,196
"def distinct(self, fieldname): <TAB> """"""Set of unique values for the given field."""""" <TAB> rv = set() <TAB> for item in self: <MASK> value = item._data[fieldname] <TAB>  <TAB>  <TAB> if isinstance(value, (list, tuple)): <TAB>  <TAB>  <TAB>  <TAB> rv |= set(value) <TAB>  <TAB>  <TAB> elif not isinstance(value, Undefined): <TAB>  <TAB>  <TAB>  <TAB> rv.add(value) <TAB> return rv",if fieldname in item . _data :,107
"def _data_paths(self, mbx): <TAB> mbx_path = FilePath(self._path(mbx)).raw_fp <TAB> if os.path.exists(mbx_path): <TAB>  <TAB> yield mbx_path <TAB> if os.path.isdir(mbx_path): <TAB>  <TAB> # Maildir, WERVD <TAB>  <TAB> for s in (""cur"", ""new"", ""tmp"", ""wervd.ver""): <TAB>  <TAB>  <TAB> sub_path = os.path.join(mbx_path, s) <MASK> yield sub_path <TAB>  <TAB> # Mac Maildir <TAB>  <TAB> sub_path = self._get_macmaildir_data(mbx_path) <TAB>  <TAB> if sub_path: <TAB>  <TAB>  <TAB> yield sub_path",if os . path . exists ( sub_path ) :,191
"def run(*args, die=True): <TAB> # Add wrappers to $PATH <TAB> env = os.environ.copy() <TAB> env[""PATH""] += "":%s"" % os.environ[""SNAP""] <TAB> result = subprocess.run( <TAB>  <TAB> args, <TAB>  <TAB> stdin=subprocess.PIPE, <TAB>  <TAB> stdout=subprocess.PIPE, <TAB>  <TAB> stderr=subprocess.PIPE, <TAB>  <TAB> env=env, <TAB> ) <TAB> try: <TAB>  <TAB> result.check_returncode() <TAB> except subprocess.CalledProcessError as err: <MASK> if result.stderr: <TAB>  <TAB>  <TAB>  <TAB> print(result.stderr.decode(""utf-8"")) <TAB>  <TAB>  <TAB> print(err) <TAB>  <TAB>  <TAB> sys.exit(1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise <TAB> return result.stdout.decode(""utf-8"")",if die :,192
"def step(self, epoch=None, metrics=None): <TAB> if not isinstance(self.after_scheduler, ReduceLROnPlateau): <TAB>  <TAB> if self.finished and self.after_scheduler: <MASK> self.after_scheduler.step(None) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.after_scheduler.step(epoch - self.total_epoch) <TAB>  <TAB>  <TAB> self._last_lr = self.after_scheduler.get_last_lr() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return super(GradualWarmupScheduler, self).step(epoch) <TAB> else: <TAB>  <TAB> self.step_ReduceLROnPlateau(metrics, epoch)",if epoch is None :,160
"def find_first_text(self, start, end, text): <TAB> """"""Gets first location, if any, the string appears at in the line range."""""" <TAB> for l in self.get_closest_line_range(start, end): <TAB>  <TAB> col = self.line(l).find(text) <MASK> # TODO(mdemello): Temporary hack, replace with a token stream! <TAB>  <TAB>  <TAB> # This will break if we have a # in a string before our desired text. <TAB>  <TAB>  <TAB> comment_marker = self.line(l).find(""#"") <TAB>  <TAB>  <TAB> if -1 < comment_marker < col: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> return Location(l, col) <TAB> return None",if col > - 1 :,171
"def requestAvatarId(self, creds): <TAB> if creds.blob == keys.Key.fromString(keydata.publicRSA_openssh).blob(): <MASK> obj = keys.Key.fromString(creds.blob) <TAB>  <TAB>  <TAB> if obj.verify(creds.signature, creds.sigData): <TAB>  <TAB>  <TAB>  <TAB> return creds.username <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValidPublicKey() <TAB> raise UnauthorizedLogin()",if creds . signature is not None :,111
"def _get_requirements(): <TAB> """"""Parses requirements.txt file."""""" <TAB> install_requires_tmp = [] <TAB> dependency_links_tmp = [] <TAB> with open(os.path.join(os.path.dirname(__file__), ""../requirements.txt""), ""r"") as f: <TAB>  <TAB> for line in f: <TAB>  <TAB>  <TAB> package_name = line.strip() <TAB>  <TAB>  <TAB> # Skip empty line or comments starting with ""#"". <MASK> continue <TAB>  <TAB>  <TAB> if package_name.startswith(""-e ""): <TAB>  <TAB>  <TAB>  <TAB> dependency_links_tmp.append(package_name[3:].strip()) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> install_requires_tmp.append(package_name) <TAB> return install_requires_tmp, dependency_links_tmp","if not package_name or package_name [ 0 ] == ""#"" :",193
"def LineEnding(lines): <TAB> """"""Retrieve the line ending of the original source."""""" <TAB> endings = {CRLF: 0, CR: 0, LF: 0} <TAB> for line in lines: <TAB>  <TAB> if line.endswith(CRLF): <TAB>  <TAB>  <TAB> endings[CRLF] += 1 <MASK> endings[CR] += 1 <TAB>  <TAB> elif line.endswith(LF): <TAB>  <TAB>  <TAB> endings[LF] += 1 <TAB> return (sorted(endings, key=endings.get, reverse=True) or [LF])[0]",elif line . endswith ( CR ) :,132
"def wait_until_optimization_complete(): <TAB> """"""Waits for package optimization to finish."""""" <TAB> start_time = time.time() <TAB> while time.time() - start_time < PACKAGE_OPTIMIZATION_TIMEOUT: <TAB>  <TAB> package_optimization_finished = ""dex2oat"" not in adb.get_ps_output() <MASK> return <TAB>  <TAB> logs.log(""Waiting for package optimization to finish."") <TAB>  <TAB> time.sleep(PACKAGE_OPTIMIZATION_INTERVAL)",if package_optimization_finished :,122
def test_is_running(self): <TAB> for state in WorkerState: <MASK> self.assertTrue(WorkerState.is_running(state)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertFalse(WorkerState.is_running(state)),if state == WorkerState . HEALTHY or state == WorkerState . UNHEALTHY :,82
"def template_strftime(format, date=None): <TAB> """"""Template function wrapper for strftime"""""" <TAB> try: <MASK> string = datetime.strftime(format, datetime.now()) <TAB>  <TAB> elif isinstance(date, (datetime.date, datetime.datetime)): <TAB>  <TAB>  <TAB> string = datetime.strftime(format, date) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Error(""Not a datetime object: %s"" % date) <TAB>  <TAB> # strftime returns locale as understood by the C api <TAB>  <TAB> # unfortunately there is no guarantee we can actually <TAB>  <TAB> # decode it ... <TAB>  <TAB> return string <TAB> except: <TAB>  <TAB> logger.exception('Error in strftime ""%s""', format)",if date is None :,159
"def handle_events(self): <TAB> for event in self.conn.events(): <TAB>  <TAB> if isinstance(event, events.Request): <TAB>  <TAB>  <TAB> self.handle_connect(event) <TAB>  <TAB> elif isinstance(event, events.TextMessage): <TAB>  <TAB>  <TAB> self.handle_text(event) <TAB>  <TAB> elif isinstance(event, events.BytesMessage): <TAB>  <TAB>  <TAB> self.handle_bytes(event) <MASK> self.handle_no_connect(event) <TAB>  <TAB> elif isinstance(event, events.RejectData): <TAB>  <TAB>  <TAB> self.handle_no_connect(event) <TAB>  <TAB> elif isinstance(event, events.CloseConnection): <TAB>  <TAB>  <TAB> self.handle_close(event) <TAB>  <TAB> elif isinstance(event, events.Ping): <TAB>  <TAB>  <TAB> self.handle_ping(event)","elif isinstance ( event , events . RejectConnection ) :",196
"def __init__(cls, name, bases, kwds): <TAB> super(YAMLObjectMetaclass, cls).__init__(name, bases, kwds) <TAB> if ""yaml_tag"" in kwds and kwds[""yaml_tag""] is not None: <MASK> for loader in cls.yaml_loader: <TAB>  <TAB>  <TAB>  <TAB> loader.add_constructor(cls.yaml_tag, cls.from_yaml) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> cls.yaml_loader.add_constructor(cls.yaml_tag, cls.from_yaml) <TAB>  <TAB> cls.yaml_dumper.add_representer(cls, cls.to_yaml)","if isinstance ( cls . yaml_loader , list ) :",159
"def request( <TAB> self, <TAB> action, <TAB> params=None, <TAB> data=None, <TAB> headers=None, <TAB> method=""GET"", <TAB> raw=False, <TAB> stream=False, <TAB> region=None,): <TAB> if region: <TAB>  <TAB> old_host = self.host <TAB>  <TAB> self.host = SCALEWAY_API_HOSTS[ <TAB>  <TAB>  <TAB> region.id if isinstance(region, NodeLocation) else region <TAB>  <TAB> ] <MASK> self.connect() <TAB> return super(ScalewayConnection, self).request( <TAB>  <TAB> action, params, data, headers, method, raw, stream <TAB> )",if not self . host == old_host :,160
"def shipIn(theme): <TAB> """"""Return component icons from component folders to corresponding Resources folder"""""" <TAB> for comp in components: <TAB>  <TAB> # Set destination (Resources folder for this theme) <TAB>  <TAB> dest = join(os.getcwd(), theme, ""components"") <TAB>  <TAB> # Get origin location & files <TAB>  <TAB> orig = join(cmpFolder, comp, theme) <MASK> files = os.listdir(orig) <TAB>  <TAB>  <TAB> for fname in files: <TAB>  <TAB>  <TAB>  <TAB> # Move back to resources folder <TAB>  <TAB>  <TAB>  <TAB> shutil.move(join(orig, fname), join(dest, fname))",if isdir ( orig ) and isdir ( dest ) :,147
"def _validate_key(value, entity=None): <TAB> if not isinstance(value, Key): <TAB>  <TAB> # TODO: BadKeyError. <TAB>  <TAB> raise datastore_errors.BadValueError(""Expected Key, got %r"" % value) <TAB> if entity and entity.__class__ not in (Model, Expando): <MASK> raise KindError( <TAB>  <TAB>  <TAB>  <TAB> ""Expected Key kind to be %s; received %s"" <TAB>  <TAB>  <TAB>  <TAB> % (entity._get_kind(), value.kind()) <TAB>  <TAB>  <TAB> ) <TAB> return value",if value . kind ( ) != entity . _get_kind ( ) :,138
"def _insideArc(self, P): <TAB> phi = atan2(P[1] - self.C[1], P[0] - self.C[0]) <TAB> if self.type == Segment.CW: <MASK> phi += PI2 <TAB>  <TAB> if phi <= self.startPhi + EPS / self.radius: <TAB>  <TAB>  <TAB> return True <TAB> elif self.type == Segment.CCW: <TAB>  <TAB> if phi < self.startPhi - EPS / self.radius: <TAB>  <TAB>  <TAB> phi += PI2 <TAB>  <TAB> if phi <= self.endPhi + EPS / self.radius: <TAB>  <TAB>  <TAB> return True <TAB> if eq(self.A, P, EPS) or eq(self.B, P, EPS): <TAB>  <TAB> return True <TAB> return False",if phi < self . endPhi - EPS / self . radius :,198
"def classify_vectorspace(self, vector): <TAB> best = None <TAB> for j in range(self._num_clusters): <TAB>  <TAB> p = self._priors[j] * self._gaussian( <TAB>  <TAB>  <TAB> self._means[j], self._covariance_matrices[j], vector <TAB>  <TAB> ) <MASK> best = (p, j) <TAB> return best[1]",if not best or p > best [ 0 ] :,98
"def get_mail_domains(env, filter_aliases=lambda alias: True, users_only=False): <TAB> # Returns the domain names (IDNA-encoded) of all of the email addresses <TAB> # configured on the system. If users_only is True, only return domains <TAB> # with email addresses that correspond to user accounts. <TAB> domains = [] <TAB> domains.extend( <TAB>  <TAB> [get_domain(login, as_unicode=False) for login in get_mail_users(env)] <TAB> ) <TAB> if not users_only: <TAB>  <TAB> domains.extend( <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB> get_domain(address, as_unicode=False) <TAB>  <TAB>  <TAB>  <TAB> for address, *_ in get_mail_aliases(env) <MASK> ] <TAB>  <TAB> ) <TAB> return set(domains)",if filter_aliases ( address ),197
"def _prepare_database(self, migrator, database): <TAB> migrator.set_connection(database) <TAB> if not migrator.repository_exists(): <TAB>  <TAB> options = [] <TAB>  <TAB> if database: <TAB>  <TAB>  <TAB> options.append((""--database"", database)) <MASK> options.append((""--config"", self.option(""config""))) <TAB>  <TAB> self.call(""migrate:install"", options)","if self . get_definition ( ) . has_option ( ""config"" ) :",108
"def setup_logging(self): <TAB> # Galaxy will attempt to setup logging if loggers is not present in <TAB> # ini config file - this handles that loggers block however if present <TAB> # (the way paste normally would) <TAB> if not self.config_file: <TAB>  <TAB> return <TAB> if self.config_is_ini: <TAB>  <TAB> raw_config = ConfigParser() <TAB>  <TAB> raw_config.read([self.config_file]) <MASK> config_file = os.path.abspath(self.config_file) <TAB>  <TAB>  <TAB> fileConfig( <TAB>  <TAB>  <TAB>  <TAB> config_file, <TAB>  <TAB>  <TAB>  <TAB> dict(__file__=config_file, here=os.path.dirname(config_file)), <TAB>  <TAB>  <TAB> )","if raw_config . has_section ( ""loggers"" ) :",182
"def run_plugins(plugins, url_data, stop_after_match=False, **kwargs): <TAB> """"""Run the check(url_data) method of given plugins."""""" <TAB> for plugin in plugins: <TAB>  <TAB> log.debug(LOG_PLUGIN, ""Run plugin %s"", plugin.__class__.__name__) <TAB>  <TAB> if plugin.applies_to(url_data, **kwargs): <TAB>  <TAB>  <TAB> plugin.check(url_data) <MASK> break",if stop_after_match :,115
"def getp(self): <TAB> if not self.p: <TAB>  <TAB> p = self.validated_ptrs() <MASK> self.p = ""unknown"" <TAB>  <TAB> elif self.d in p: <TAB>  <TAB>  <TAB> self.p = self.d <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sfx = ""."" + self.d <TAB>  <TAB>  <TAB> for d in p: <TAB>  <TAB>  <TAB>  <TAB> if d.endswith(sfx): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.p = d <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.p = p[0] <TAB> return self.p",if not p :,147
def Proc2(IntParIO: int) -> int: <TAB> IntLoc = IntParIO + 10 <TAB> EnumLoc = -1  ## c++ scope style <TAB> while True: <MASK> IntLoc = IntLoc - 1 <TAB>  <TAB>  <TAB> IntParIO = IntLoc - IntGlob <TAB>  <TAB>  <TAB> EnumLoc = Ident1 <TAB>  <TAB> if EnumLoc == Ident1: <TAB>  <TAB>  <TAB> break <TAB> return IntParIO,"if Char1Glob == ""A"" :",108
"def as_dict(self): <TAB> ret = {} <TAB> for message in self.messages: <TAB>  <TAB> lookup = ret <MASK> for key in message.index[:-1]: <TAB>  <TAB>  <TAB>  <TAB> lookup.setdefault(key, {}) <TAB>  <TAB>  <TAB>  <TAB> lookup = lookup[key] <TAB>  <TAB> key = message.index[-1] if message.index else None <TAB>  <TAB> lookup[key] = message.text <TAB> return ret",if message . index :,104
"def _replace_relative_links(regex: tp.Match[str]) -> str: <TAB> """"""Converts relative links into links to master"""""" <TAB> string = regex.group() <TAB> link = regex.group(""link"") <TAB> name = regex.group(""name"") <TAB> if not link.startswith(""http"") and Path(link).exists(): <TAB>  <TAB> githuburl = ( <TAB>  <TAB>  <TAB> ""github.com/facebookresearch/nevergrad/blob/master"" <MASK> else ""raw.githubusercontent.com/facebookresearch/nevergrad/master"" <TAB>  <TAB> ) <TAB>  <TAB> string = f""[{name}](https://{githuburl}/{link})"" <TAB> return string","if not link . endswith ( ( "".png"" , "".gif"" ) )",160
"def find_ipv6_ifaces(): <TAB> info = netinfo.netdev_info() <TAB> ifaces = [] <TAB> for iface, data in info.items(): <TAB>  <TAB> if iface == ""lo"": <TAB>  <TAB>  <TAB> LOG.debug(""Skipping localhost interface"") <MASK> # skip this interface, as it has ipv4 addrs <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> ifaces.append(iface) <TAB> return ifaces","if len ( data . get ( ""ipv4"" , [ ] ) ) != 0 :",109
"def unescape(text): <TAB> """"""Inverse of escape."""""" <TAB> if isinstance(text, str): <MASK> text = text.replace(""&amp;"", ""&"") <TAB>  <TAB> if ""&gt;"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""&gt;"", "">"") <TAB>  <TAB> if ""&lt;"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""&lt;"", ""<"") <TAB>  <TAB> if ""&quot;"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""&quot;"", '""') <TAB> return text","if ""&amp;"" in text :",118
"def __compute_res_value(self, tokens): <TAB> fuzz_val, token_tuple = tokens[0] <TAB> if token_tuple: <TAB>  <TAB> location, operator_match = token_tuple <MASK> return diff(operator_match, fuzz_val) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if operator_match and operator_match.groupdict()[""operator""]: <TAB>  <TAB>  <TAB>  <TAB> fuzz_val = self._get_operator_value( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> location, fuzz_val, operator_match.groupdict() <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> if isinstance(fuzz_val, list): <TAB>  <TAB> return [fuzz_val] <TAB> return fuzz_val","if location == ""diff"" :",163
"def parse_data(self, data): <TAB> # Parse data for specific tag if it's present <TAB> if self.tag: <MASK> total_responses = data[""tagged""][self.tag][""interval_real""][""len""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> total_responses = data[""overall""][""interval_real""][""len""] <TAB> # Parse data for overall <TAB> else: <TAB>  <TAB> total_responses = data[""overall""][""interval_real""][""len""] <TAB> return total_responses","if data [ ""tagged"" ] . get ( self . tag ) :",122
"def ensure_posix_directory( <TAB> path: str, <TAB> stat_mode_fun: Callable[[str], Optional[int]], <TAB> mkdir_fun: Callable[[str], None],) -> None: <TAB> assert path.startswith(""/"") <TAB> if path == ""/"": <TAB>  <TAB> return <TAB> for step in list(reversed(list(map(str, pathlib.PurePosixPath(path).parents)))) + [ <TAB>  <TAB> path <TAB> ]: <MASK> mode = stat_mode_fun(step) <TAB>  <TAB>  <TAB> if mode is None: <TAB>  <TAB>  <TAB>  <TAB> mkdir_fun(step) <TAB>  <TAB>  <TAB> elif not stat.S_ISDIR(mode): <TAB>  <TAB>  <TAB>  <TAB> raise AssertionError(""'%s' is file, not a directory"" % step)","if step != ""/"" :",173
"def get_existing_job_status(task: dict) -> Optional[kubernetes.client.V1Job]: <TAB> try: <TAB>  <TAB> return _kube.read_namespaced_job_status(f""contract-{task['id']}"", NAMESPACE) <TAB> except kubernetes.client.rest.ApiException as e: <MASK> _log.info(""No existing job found"") <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> _log.info(""Kubernetes API error"") <TAB>  <TAB> raise RuntimeError(""Could not get existing job status"")",if e . status == 404 :,125
"def reset_linearization_variables(instance): <TAB> for variable_name, variable in iteritems(instance.component_map(Var, active=True)): <MASK> for var_value in itervalues(variable): <TAB>  <TAB>  <TAB>  <TAB> var_value.value = None <TAB>  <TAB>  <TAB>  <TAB> var_value.stale = True","if variable_name . startswith ( ""PHQUADPENALTY"" ) :",89
"def set_target_exchange_rate(self, ref_doc=None): <TAB> if self.paid_to and not self.target_exchange_rate: <MASK> if self.paid_to_account_currency == ref_doc.currency: <TAB>  <TAB>  <TAB>  <TAB> self.target_exchange_rate = ref_doc.get(""exchange_rate"") <TAB>  <TAB> if not self.target_exchange_rate: <TAB>  <TAB>  <TAB> self.target_exchange_rate = get_exchange_rate( <TAB>  <TAB>  <TAB>  <TAB> self.paid_to_account_currency, self.company_currency, self.posting_date <TAB>  <TAB>  <TAB> )",if ref_doc :,158
"def __init__( <TAB> self, getter, attribute, new, spec, create, spec_set, autospec, new_callable, kwargs): <TAB> if new_callable is not None: <MASK> raise ValueError(""Cannot use 'new' and 'new_callable' together"") <TAB>  <TAB> if autospec is not None: <TAB>  <TAB>  <TAB> raise ValueError(""Cannot use 'autospec' and 'new_callable' together"") <TAB> self.getter = getter <TAB> self.attribute = attribute <TAB> self.new = new <TAB> self.new_callable = new_callable <TAB> self.spec = spec <TAB> self.create = create <TAB> self.has_local = False <TAB> self.spec_set = spec_set <TAB> self.autospec = autospec <TAB> self.kwargs = kwargs <TAB> self.additional_patchers = []",if new is not DEFAULT :,197
"def process_event_and_paint(self, e): <TAB> """"""If None is passed in, just paint the screen"""""" <TAB> try: <MASK> self.process_event(e) <TAB> except (SystemExitFromCodeRunner, SystemExit) as err: <TAB>  <TAB> array, cursor_pos = self.paint( <TAB>  <TAB>  <TAB> about_to_exit=True, <TAB>  <TAB>  <TAB> user_quit=isinstance(err, SystemExitFromCodeRunner), <TAB>  <TAB> ) <TAB>  <TAB> scrolled = self.window.render_to_terminal(array, cursor_pos) <TAB>  <TAB> self.scroll_offset += scrolled <TAB>  <TAB> raise <TAB> else: <TAB>  <TAB> array, cursor_pos = self.paint() <TAB>  <TAB> scrolled = self.window.render_to_terminal(array, cursor_pos) <TAB>  <TAB> self.scroll_offset += scrolled",if e is not None :,200
"def unique(enumeration): <TAB> """"""Class decorator that ensures only unique members exist in an enumeration."""""" <TAB> duplicates = [] <TAB> for name, member in enumeration.__members__.items(): <MASK> duplicates.append((name, member.name)) <TAB> if duplicates: <TAB>  <TAB> duplicate_names = "", "".join( <TAB>  <TAB>  <TAB> [""%s -> %s"" % (alias, name) for (alias, name) in duplicates] <TAB>  <TAB> ) <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> ""duplicate names found in %r: %s"" % (enumeration, duplicate_names) <TAB>  <TAB> ) <TAB> return enumeration",if name != member . name :,152
"def clean_input(cls, info, instance, data): <TAB> validation_errors = {} <TAB> for field in [""url"", ""number""]: <MASK> validation_errors[field] = ValidationError( <TAB>  <TAB>  <TAB>  <TAB> f""{field} cannot be empty."", <TAB>  <TAB>  <TAB>  <TAB> code=InvoiceErrorCode.REQUIRED, <TAB>  <TAB>  <TAB> ) <TAB> if validation_errors: <TAB>  <TAB> raise ValidationError(validation_errors) <TAB> return data[""input""]","if data [ ""input"" ] [ field ] == """" :",110
"def _find_matching_deindent(self, line_number): <TAB> indents = _get_line_indents(self.lines[line_number]) <TAB> current_line = line_number + 1 <TAB> while current_line < len(self.lines): <TAB>  <TAB> line = self.lines[current_line] <TAB>  <TAB> if not line.strip().startswith(""#"") and not line.strip() == """": <TAB>  <TAB>  <TAB> # HACK: We should have used logical lines here <MASK> return current_line <TAB>  <TAB> current_line += 1 <TAB> return len(self.lines) - 1",if _get_line_indents ( self . lines [ current_line ] ) <= indents :,159
"def _get_blocks(self, addr, idx=None) -> Generator[ailment.Block, None, None]: <TAB> if not self._blocks_by_addr: <TAB>  <TAB> return <TAB> else: <MASK> blocks = self._blocks_by_addr.get(addr, None) <TAB>  <TAB>  <TAB> if blocks is not None: <TAB>  <TAB>  <TAB>  <TAB> yield from blocks <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> block = self._blocks_by_addr_and_idx.get((addr, idx), None) <TAB>  <TAB>  <TAB> if block is not None: <TAB>  <TAB>  <TAB>  <TAB> yield block",if idx is None :,141
"def _validate_arg_level(self, ns, **_):  # pylint: disable=no-self-use <TAB> from azure.cli.core.azclierror import AzCLIError <TAB> for validator in getattr(ns, ""_argument_validators"", []): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> validator(**self._build_kwargs(validator, ns)) <TAB>  <TAB> except AzCLIError: <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> except Exception as ex: <TAB>  <TAB>  <TAB> # Delay the import and mimic an exception handler <TAB>  <TAB>  <TAB> from msrest.exceptions import ValidationError <MASK> logger.debug(""Validation error in %s."", str(validator)) <TAB>  <TAB>  <TAB> raise <TAB> try: <TAB>  <TAB> delattr(ns, ""_argument_validators"") <TAB> except AttributeError: <TAB>  <TAB> pass","if isinstance ( ex , ValidationError ) :",184
"def __setitem__(self, index, item): <TAB> """"""Set item at position i to item."""""" <TAB> if isinstance(index, SliceType): <TAB>  <TAB> # NOTE: item must be an iterable (list of tuples) <TAB>  <TAB> self._main[index] = OrderedDict(item) <TAB> else: <TAB>  <TAB> # FIXME: Does this raise a sensible error ? <TAB>  <TAB> orig = self._main.keys[index] <TAB>  <TAB> key, value = item <MASK> raise ValueError(""slice assignment must be from "" ""unique keys"") <TAB>  <TAB> # delete the current one <TAB>  <TAB> del self._main[self._main._sequence[index]] <TAB>  <TAB> self._main.insert(index, key, value)",if self . _main . strict and key in self and ( key != orig ) :,175
"def get_relative_path(roots, file_name, n_components=2): <TAB> if file_name is not None: <MASK> for root in roots: <TAB>  <TAB>  <TAB>  <TAB> if file_name.startswith(root): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> file_name = file_name[len(root) + 1 :] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> # show (no more than the) last 2 components of the matching path name <TAB>  <TAB> return os.path.sep.join(file_name.split(os.path.sep)[-n_components:]) <TAB> else: <TAB>  <TAB> return ""<no file>""",if roots is not None :,149
"def __init__(self, path="""", prefix=""train""): <TAB> assert os.path.isdir(path) <TAB> self.documents = [] <TAB> filename_list = os.listdir(path) <TAB> for file in filename_list: <TAB>  <TAB> path_to_file = os.path.join(path, file) <MASK> continue <TAB>  <TAB> self.documents.append(path_to_file)",if not os . path . isfile ( path_to_file ) :,108
"def get_next_scoperef(self, scoperef): <TAB> blob, lpath = scoperef <TAB> elem = self._elem_from_scoperef(scoperef) <TAB> linenum = self.line + 1  # convert to 1-based <TAB> for subelem in elem.getchildren(): <TAB>  <TAB> start = int(subelem.get(""line"")) <MASK> if subelem.tag == ""scope"": <TAB>  <TAB>  <TAB>  <TAB> lpath.append(subelem.get(""name"")) <TAB>  <TAB>  <TAB> break <TAB> return (blob, lpath)",if start > linenum :,128
"def __getitem__(self, key): <TAB> with self.lock: <MASK> return super(RulesDict, self).__getitem__(key) <TAB>  <TAB> elif isinstance(key, tuple): <TAB>  <TAB>  <TAB> return super(RulesDict, self).__getitem__(RuleKey(*key)) <TAB>  <TAB> elif isinstance(key, int): <TAB>  <TAB>  <TAB> for k in self.keys(): <TAB>  <TAB>  <TAB>  <TAB> if key == k[2]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return super(RulesDict, self).__getitem__(k) <TAB>  <TAB> elif isinstance(key, dict): <TAB>  <TAB>  <TAB> for v in self.values(): <TAB>  <TAB>  <TAB>  <TAB> for k in key: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if key[k] != v.get(k, None): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return v","if isinstance ( key , RuleKey ) :",197
"def get_all_children_rec(self, node): <TAB> stack = [node] <TAB> visited = {node} <TAB> while stack: <TAB>  <TAB> node = stack.pop() <TAB>  <TAB> for child in self.cached_relations[node]: <MASK> continue <TAB>  <TAB>  <TAB> yield child <TAB>  <TAB>  <TAB> visited.add(node) <TAB>  <TAB>  <TAB> stack.append(child[""id""])","if child [ ""id"" ] in visited :",102
"def visit_productionlist(self, node: Element) -> None: <TAB> self.new_state() <TAB> names = [] <TAB> productionlist = cast(Iterable[addnodes.production], node) <TAB> for production in productionlist: <TAB>  <TAB> names.append(production[""tokenname""]) <TAB> maxlen = max(len(name) for name in names) <TAB> lastname = None <TAB> for production in productionlist: <TAB>  <TAB> if production[""tokenname""]: <TAB>  <TAB>  <TAB> self.add_text(production[""tokenname""].ljust(maxlen) + "" ::="") <TAB>  <TAB>  <TAB> lastname = production[""tokenname""] <MASK> self.add_text(""%s <TAB> "" % ("" "" * len(lastname))) <TAB>  <TAB> self.add_text(production.astext() + self.nl) <TAB> self.end_state(wrap=False) <TAB> raise nodes.SkipNode",elif lastname is not None :,200
"def set_locale(): <TAB> try:  # XXX This can't be right. <TAB>  <TAB> locale.setlocale(locale.LC_ALL, b""en_US.utf8"")  # Heroku <TAB> except locale.Error: <TAB>  <TAB> import sys <MASK> locale.setlocale(locale.LC_ALL, b"""")  # Windows <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> locale.setlocale(locale.LC_ALL, b""en_US.UTF-8"")  # Mac OS <TAB>  <TAB>  <TAB> except locale.Error: <TAB>  <TAB>  <TAB>  <TAB> locale.setlocale(locale.LC_ALL, b""C.UTF-8"")  # Read the Docs","if sys . platform == ""win32"" :",166
"def __iter__(self): <TAB> if self.shuffle: <TAB>  <TAB> self.rng.shuffle(self.files) <TAB> for f in self.files: <TAB>  <TAB> im = cv2.imread(f, self.imread_mode) <TAB>  <TAB> assert im is not None, f <TAB>  <TAB> if self.channel == 3: <TAB>  <TAB>  <TAB> im = im[:, :, ::-1] <MASK> im = cv2.resize(im, tuple(self.resize[::-1])) <TAB>  <TAB> if self.channel == 1: <TAB>  <TAB>  <TAB> im = im[:, :, np.newaxis] <TAB>  <TAB> yield [im]",if self . resize is not None :,148
"def postprocess(self, testenv_config, value): <TAB> config = testenv_config.config <TAB> args = config.option.args <TAB> if args: <TAB>  <TAB> if value: <TAB>  <TAB>  <TAB> args = [] <TAB>  <TAB>  <TAB> for arg in config.option.args: <TAB>  <TAB>  <TAB>  <TAB> if arg and not os.path.isabs(arg): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> origpath = os.path.join(config.invocationcwd.strpath, arg) <MASK> arg = os.path.relpath( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> origpath, testenv_config.changedir.strpath <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> args.append(arg) <TAB>  <TAB> testenv_config._reader.addsubstitutions(args) <TAB> return value",if os . path . exists ( origpath ) :,196
"def filter_streams(self, streams: list, channel: discord.TextChannel) -> list: <TAB> filtered = [] <TAB> for stream in streams: <TAB>  <TAB> tw_id = str(stream[""channel""][""_id""]) <TAB>  <TAB> for alert in self.streams: <TAB>  <TAB>  <TAB> if isinstance(alert, TwitchStream) and alert.id == tw_id: <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> filtered.append(stream) <TAB> return filtered",if channel . id in alert . channels :,123
"def get_urls(self): <TAB> """"""Return list of future-types needing URL"""""" <TAB> lst = [] <TAB> for nzo_id in self.__nzo_table: <TAB>  <TAB> nzo = self.__nzo_table[nzo_id] <TAB>  <TAB> if nzo.futuretype: <TAB>  <TAB>  <TAB> url = nzo.url <MASK> lst.append((url, nzo)) <TAB> return lst","if nzo . futuretype and url . lower ( ) . startswith ( ""http"" ) :",115
"def shrink_one_end(line, s): <TAB> while s > 0.0: <MASK> return [] <TAB>  <TAB> xy, length = setback(line[0].p, line[1].p, s) <TAB>  <TAB> if xy is not None: <TAB>  <TAB>  <TAB> line[0] = line[0].add(*xy) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> line = line[1:] <TAB>  <TAB> s -= length <TAB> return line",if len ( line ) < 2 :,112
"def process_result(self, result, method_name, obj, **kwargs): <TAB> if method_name == ""get_paginated_response"" and isinstance(result, openapi.Schema): <TAB>  <TAB> next = result.properties[""next""] <TAB>  <TAB> if isinstance(next, openapi.Schema): <TAB>  <TAB>  <TAB> next[""x-nullable""] = True <TAB>  <TAB> previous = result.properties[""previous""] <MASK> previous[""x-nullable""] = True <TAB> return result","if isinstance ( previous , openapi . Schema ) :",119
"def from_obj(cls, data): <TAB> inst = cls() <TAB> for field in cls.fields: <MASK> val = getattr(data, field[0] + ""_dbus"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> val = getattr(data, field[0], None) <TAB>  <TAB> if hasattr(val, ""__call__""): <TAB>  <TAB>  <TAB> val = val() <TAB>  <TAB> setattr(inst, field[0], val) <TAB> return inst","if hasattr ( data , field [ 0 ] + ""_dbus"" ) :",116
"def iter(cls, type, readonly=False): <TAB> for key in dir(cls): <TAB>  <TAB> if key.startswith(""__""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if key.endswith(MUTABLE): <TAB>  <TAB>  <TAB> key = key[: -len(MUTABLE)] <TAB>  <TAB> if type == ""keys"": <TAB>  <TAB>  <TAB> yield key <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if readonly: <TAB>  <TAB>  <TAB>  <TAB> value = cls.__getreadonly__(key) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> value = cls[key] <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if type == ""values"": <TAB>  <TAB>  <TAB> yield value <MASK> yield (key, value) <TAB> raise StopIteration()","if type == ""items"" :",167
"def configure_logger(self, logger): <TAB> if logger is True: <TAB>  <TAB> version = os.environ.get(""PL_EXP_VERSION"", self.trainer.slurm_job_id) <TAB>  <TAB> # default logger <TAB>  <TAB> self.trainer.logger = TensorBoardLogger( <TAB>  <TAB>  <TAB> save_dir=self.trainer.default_root_dir, <TAB>  <TAB>  <TAB> version=version, <TAB>  <TAB>  <TAB> name=""lightning_logs"", <TAB>  <TAB> ) <TAB> elif logger is False: <TAB>  <TAB> self.trainer.logger = None <TAB> else: <MASK> self.trainer.logger = LoggerCollection(logger) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.trainer.logger = logger","if isinstance ( logger , Iterable ) :",167
"def _match(pattern, node, context): <TAB> result = None <TAB> if isinstance(pattern, AlternativeMatchPattern): <TAB>  <TAB> for alternative in pattern.alternatives: <TAB>  <TAB>  <TAB> result = _match(alternative, node, context) <MASK> break <TAB> elif isinstance(pattern, MatchGroupNode): <TAB>  <TAB> with context(): <TAB>  <TAB>  <TAB> result = _match(pattern.node, node, context) <TAB>  <TAB>  <TAB> if result: <TAB>  <TAB>  <TAB>  <TAB> result = context.get_match_group() <TAB>  <TAB>  <TAB>  <TAB> result.node = node <TAB>  <TAB> if result: <TAB>  <TAB>  <TAB> match_group = context.get_match_group() <TAB>  <TAB>  <TAB> match_group.add(pattern.name, result) <TAB> else: <TAB>  <TAB> result = _match_node(pattern, node, context) <TAB> return result",if result :,193
"def _items(self, main_value, normalize=False): <TAB> result = [(self.source, utils.get_shortish_repr(main_value, normalize=normalize))] <TAB> for key in self._safe_keys(main_value): <TAB>  <TAB> try: <MASK> continue <TAB>  <TAB>  <TAB> value = self._get_value(main_value, key) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> result.append( <TAB>  <TAB>  <TAB> ( <TAB>  <TAB>  <TAB>  <TAB> ""{}{}"".format(self.unambiguous_source, self._format_key(key)), <TAB>  <TAB>  <TAB>  <TAB> utils.get_shortish_repr(value), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB> return result",if key in self . exclude :,172
"def run(self): <TAB> if not os.path.exists(""config.status""): <MASK> raise RuntimeError(""chmod error"") <TAB>  <TAB> cmd = ""sh configure""  # we use ""sh"" here so that it'll work on mingw32 with standard python.org binaries <TAB>  <TAB> if self.verbose < 1: <TAB>  <TAB>  <TAB> cmd += "" -q"" <TAB>  <TAB> if os.system(cmd) != 0: <TAB>  <TAB>  <TAB> raise RuntimeError(""autoconf error"")","if os . system ( ""chmod 0755 configure"" ) != 0 :",125
"def as_arg(self): <TAB> if self.arg_format: <TAB>  <TAB> from polyaxon.polyaxonfile.specs.libs.parser import Parser <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB> Parser.parse_expression(self.arg_format, {self.name: self.param.value}) <MASK> else """" <TAB>  <TAB> ) <TAB> if self.type == types.BOOL: <TAB>  <TAB> return ""--{}"".format(self.name) if self.param.value else """" <TAB> return ( <TAB>  <TAB> ""--{}={}"".format(self.name.replace(""_"", ""-""), self.as_str()) <TAB>  <TAB> if self.param.value is not None <TAB>  <TAB> else """" <TAB> )",if self . param . value is not None,167
"def _log_paths_str(self): <TAB> for bbid, succs in self.paths.items(): <MASK> logging.info(f""{self._block_str(bbid)} -> {self._block_str(succs[0])}"") <TAB>  <TAB> elif len(succs) == 2: <TAB>  <TAB>  <TAB> logging.info( <TAB>  <TAB>  <TAB>  <TAB> f""{self._block_str(bbid)} --(force jump)--> {self._block_str(succs[0])}"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> logging.info(f""|----(skip jump)----> {self._block_str(succs[1])}"") <TAB>  <TAB> elif len(succs) > 2: <TAB>  <TAB>  <TAB> logging.warning(f""succs: {succs} found from {self._block_str(bbid)}!"")",if len ( succs ) == 1 :,194
"def _connectedTo(self, workerid, masterid=None): <TAB> conns = [] <TAB> for cs in itervalues(self.connected): <TAB>  <TAB> if cs[""workerid""] != workerid: <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> conns.append(cs[""masterid""]) <TAB> return conns","if masterid is not None and cs [ ""masterid"" ] != masterid :",93
"def _read_until(self, match, timeout=None): <TAB> rxb = six.b("""") <TAB> timeout = time() + self.READ_PROMPT_DELAY <TAB> while time() < timeout: <TAB>  <TAB> sleep(0.1) <TAB>  <TAB> rd, _, _ = select.select([self._ssh], [], [], 0.1) <TAB>  <TAB> sleep(0.05) <MASK> rxb += self._ssh.recv(self.MAX_BUFFER) <TAB>  <TAB>  <TAB> if re.search(match, rxb): <TAB>  <TAB>  <TAB>  <TAB> return rxb <TAB>  <TAB>  <TAB> timeout = time() + self.READ_PROMPT_DELAY",if rd :,149
"def __define_computations(self): <TAB> err = ""computations should have the name of an existing field to "" + ""compute!"" <TAB> field_names = [field.name for field in self.fields] <TAB> for name, obj in self._all_computations_.items(): <MASK> raise RuntimeError(err) <TAB>  <TAB> # TODO add check virtuals <TAB>  <TAB> self.table[obj.field_name].compute = lambda row, obj=obj, self=self: obj.f( <TAB>  <TAB>  <TAB> self, row <TAB>  <TAB> )",if obj . field_name not in field_names :,141
"def register_timers(self, timer_requests: List[TimerRequest]) -> None: <TAB> for request in timer_requests: <TAB>  <TAB> pid = request.worker_id <TAB>  <TAB> scope_id = request.scope_id <TAB>  <TAB> expiration_time = request.expiration_time <TAB>  <TAB> # negative expiration is a proxy for a release call <MASK> self._timers.pop((pid, scope_id), None) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._timers[(pid, scope_id)] = request",if expiration_time < 0 :,128
"def _safe_unpickle(file_name): <TAB> with open(file_name, ""rb"") as data_file: <MASK> # python3 unpickling of python2 unicode <TAB>  <TAB>  <TAB> data = pickle.load(data_file, encoding=""latin1"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> data = pickle.load(data_file) <TAB> return data","if sys . version_info >= ( 3 , 0 ) :",98
"def button_clicked(self, button): <TAB> if button == ""add_bot"" and self.open_for_signups: <TAB>  <TAB> for i in range(5): <TAB>  <TAB>  <TAB> name = ""local_bot_%d"" % self.gui.listbox.size() <TAB>  <TAB>  <TAB> gameobserver = remote.LocalGameObserver(name) <TAB>  <TAB>  <TAB> robot = self.signup_robot(name, gameobserver) <TAB>  <TAB>  <TAB> gameobserver.robot = robot <TAB> elif button == ""start_round"": <TAB>  <TAB> self.open_for_signups = False <MASK> self.survivor.delete_from_grid() <TAB>  <TAB> self.gui.enable_buttons(False) <TAB>  <TAB> self.start_round()",if self . survivor :,178
"def _getExecutableFromRegistry(self, exeName): <TAB> """"""Windows allow application paths to be registered in the registry."""""" <TAB> import _winreg <TAB> try: <TAB>  <TAB> key = ""SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\App Paths\\"" + exeName <TAB>  <TAB> registered = _winreg.QueryValue(_winreg.HKEY_LOCAL_MACHINE, key) <MASK> return registered <TAB> except _winreg.error: <TAB>  <TAB> pass <TAB> return None",if registered and os . path . exists ( registered ) :,116
"def get_full_path_from_pid(pid): <TAB> if pid: <TAB>  <TAB> filename = create_unicode_buffer("""", 256) <TAB>  <TAB> hProcess = OpenProcess(PROCESS_QUERY_INFORMATION, False, int(pid)) <MASK> return False <TAB>  <TAB> size = GetModuleFileNameEx(hProcess, None, filename, 256) <TAB>  <TAB> CloseHandle(hProcess) <TAB>  <TAB> if size: <TAB>  <TAB>  <TAB> return filename.value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False",if not hProcess :,120
"def joinInBezierSpline(splines): <TAB> newSpline = BezierSpline() <TAB> for spline in splines: <TAB>  <TAB> newSpline.points.extend(spline.points) <TAB>  <TAB> newSpline.radii.extend(spline.radii) <TAB>  <TAB> newSpline.tilts.extend(spline.tilts) <MASK> newSpline.leftHandles.extend(spline.points) <TAB>  <TAB>  <TAB> newSpline.rightHandles.extend(spline.points) <TAB>  <TAB> elif isinstance(spline, BezierSpline): <TAB>  <TAB>  <TAB> newSpline.leftHandles.extend(spline.leftHandles) <TAB>  <TAB>  <TAB> newSpline.rightHandles.extend(spline.rightHandles) <TAB> return newSpline","if isinstance ( spline , PolySpline ) :",174
"def build_order(self): <TAB> # First do a topological order by levels, the ids of the nodes are stored <TAB> levels = [] <TAB> opened = list(self._nodes.keys()) <TAB> while opened: <TAB>  <TAB> current_level = [] <TAB>  <TAB> for o in opened: <TAB>  <TAB>  <TAB> node = self._nodes[o] <TAB>  <TAB>  <TAB> requires = node.get(""requires"", []) <MASK> current_level.append(o) <TAB>  <TAB> current_level.sort() <TAB>  <TAB> levels.append(current_level) <TAB>  <TAB> # now initialize new level <TAB>  <TAB> opened = set(opened).difference(current_level) <TAB> return levels",if not any ( n in opened for n in requires ) :,166
"def call(self, fn, *args, **kwargs): <TAB> self.begin(fn) <TAB> retry_state = RetryCallState(retry_object=self, fn=fn, args=args, kwargs=kwargs) <TAB> while True: <TAB>  <TAB> do = self.iter(retry_state=retry_state) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> result = fn(*args, **kwargs) <TAB>  <TAB>  <TAB> except BaseException: <TAB>  <TAB>  <TAB>  <TAB> retry_state.set_exception(sys.exc_info()) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> retry_state.set_result(result) <TAB>  <TAB> elif isinstance(do, DoSleep): <TAB>  <TAB>  <TAB> retry_state.prepare_for_next_attempt() <TAB>  <TAB>  <TAB> self.sleep(do) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return do","if isinstance ( do , DoAttempt ) :",198
"def execute_codegen(self, target, target_workdir): <TAB> for source in target.sources_relative_to_buildroot(): <TAB>  <TAB> if source.endswith("".avsc""): <TAB>  <TAB>  <TAB> self._compile_schema(source, target_workdir) <TAB>  <TAB> elif source.endswith("".avpr""): <TAB>  <TAB>  <TAB> self._compile_protocol(source, target_workdir) <MASK> self._compile_idl(source, target_workdir) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TaskError( <TAB>  <TAB>  <TAB>  <TAB> ""File {} is not supported. The Avro task only supports "" <TAB>  <TAB>  <TAB>  <TAB> ""Avro schema (.avsc), protocol (.avpr), and IDL (.avdl) files."".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> source <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> )","elif source . endswith ( "".avdl"" ) :",196
"def callback(input, prefixed_name, **kwargs): <TAB> if isinstance(input, DataToolParameter) or isinstance( <TAB>  <TAB> input, DataCollectionToolParameter <TAB> ): <TAB>  <TAB> data_input_names[prefixed_name] = True <TAB>  <TAB> multiple_input[prefixed_name] = input.multiple <TAB>  <TAB> if isinstance(input, DataToolParameter): <TAB>  <TAB>  <TAB> input_connections_type[input.name] = ""dataset"" <MASK> input_connections_type[input.name] = ""dataset_collection""","if isinstance ( input , DataCollectionToolParameter ) :",134
"def _parse_sentences(sentences): <TAB> encoded_sentences = [] <TAB> for sen in sentences: <TAB>  <TAB> tokens = [] <TAB>  <TAB> tags = [] <TAB>  <TAB> intent = None <TAB>  <TAB> for line in sen: <TAB>  <TAB>  <TAB> t, s, i = line.split() <TAB>  <TAB>  <TAB> tokens.append(t) <TAB>  <TAB>  <TAB> tags.append(s) <TAB>  <TAB>  <TAB> intent = i <MASK> intent = i <TAB>  <TAB> encoded_sentences.append((tokens, tags, intent)) <TAB> return encoded_sentences",if intent is None :,128
"def LooksLikeStaticGlob(w): <TAB> # type: (compound_word) -> bool <TAB> """"""Like LooksLikeGlob, but for static words."""""" <TAB> left_bracket = False <TAB> for part in w.parts: <MASK> id_ = cast(Token, part).id <TAB>  <TAB>  <TAB> if id_ in (Id.Lit_Star, Id.Lit_QMark): <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB> elif id_ == Id.Lit_LBracket: <TAB>  <TAB>  <TAB>  <TAB> left_bracket = True <TAB>  <TAB>  <TAB> elif id_ == Id.Lit_RBracket and left_bracket: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if part . tag_ ( ) == word_part_e . Literal :,165
"def check_consistency(self): <TAB> """"""Do consistency checks."""""" <TAB> for docname in sorted(self.all_docs): <MASK> if docname == self.config.master_doc: <TAB>  <TAB>  <TAB>  <TAB> # the master file is not included anywhere ;) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> self.warn(docname, ""document isn't included in any toctree"")",if docname not in self . files_to_rebuild :,99
"def write(self, data): <TAB> try: <TAB>  <TAB> self._backend._enter_io_function() <TAB>  <TAB> # click may send bytes instead of strings <TAB>  <TAB> if isinstance(data, bytes): <TAB>  <TAB>  <TAB> data = data.decode(errors=""replace"") <MASK> self._backend._send_output(data=data, stream_name=self._stream_name) <TAB>  <TAB>  <TAB> self._processed_symbol_count += len(data) <TAB> finally: <TAB>  <TAB> self._backend._exit_io_function()","if data != """" :",126
"def set_finished_at(cls, entity) -> bool: <TAB> if cls.is_done(entity.status) and entity.finished_at is None: <TAB>  <TAB> entity.finished_at = now() <MASK> # We should not have this case <TAB>  <TAB>  <TAB> entity.started_at = entity.created_at <TAB>  <TAB> # Update duration <TAB>  <TAB> if entity.duration is None: <TAB>  <TAB>  <TAB> entity.duration = (entity.finished_at - entity.started_at).seconds <TAB>  <TAB> return True <TAB> return False",if entity . started_at is None :,130
"def replaceRegexpInSelectedWidget(self, findRegexp, replacementRegexp, flags): <TAB> for widget in self.widgets: <MASK> widget.replaceRegexp(findRegexp, replacementRegexp, flags) <TAB>  <TAB>  <TAB> widget.clearPaintCache() <TAB>  <TAB>  <TAB> self.Refresh() <TAB>  <TAB>  <TAB> self.parent.setDirty(True, action=""Replace in Currently Selected Widget"")",if widget . selected :,93
"def invoke(self, arg, from_tty): <TAB> """"""GDB calls this to perform the command."""""" <TAB> for name in arg.split(): <TAB>  <TAB> ok = False <TAB>  <TAB> for objfile in gdb.objfiles(): <MASK> ok = True <TAB>  <TAB> if self.set_some(name, gdb.current_progspace().type_printers): <TAB>  <TAB>  <TAB> ok = True <TAB>  <TAB> if self.set_some(name, gdb.type_printers): <TAB>  <TAB>  <TAB> ok = True <TAB>  <TAB> if not ok: <TAB>  <TAB>  <TAB> print(""No type printer named '%s'"" % name)","if self . set_some ( name , objfile . type_printers ) :",164
"def extract(self): <TAB> for l in self.splitlines(): <MASK> continue <TAB>  <TAB> l[0].split() <TAB>  <TAB> name = l[0] <TAB>  <TAB> if name in self.vars: <TAB>  <TAB>  <TAB> self.set2[name] = int(l[2]) <TAB> for i, name in enumerate(self.vars): <TAB>  <TAB> if self.counter[i]: <TAB>  <TAB>  <TAB> self.val[name] = (self.set2[name] - self.set1[name]) * 1.0 / elapsed <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.val[name] = self.set2[name] <TAB> if step == op.delay: <TAB>  <TAB> self.set1.update(self.set2)",if len ( l ) < 2 :,180
"def _clobber_some_shares(ign): <TAB> # find the three shares that were used, and delete them. Then <TAB> # download again, forcing the downloader to fail over to other <TAB> # shares <TAB> for s in n._cnode._node._shares: <TAB>  <TAB> for clientnum in immutable_shares: <TAB>  <TAB>  <TAB> for shnum in immutable_shares[clientnum]: <MASK> fn = os.path.join( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.get_serverdir(clientnum), ""shares"", si_dir, str(shnum) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> os.unlink(fn)",if s . _shnum == shnum :,162
"def stop(self): <TAB> """"""Stop the worker threads and empty all queues."""""" <TAB> with self._state_change: <MASK> return <TAB>  <TAB> self._running = False <TAB>  <TAB> for queue in (self.completion_queue, self.callback_queue): <TAB>  <TAB>  <TAB> queue.put(_STOP) <TAB>  <TAB> self._workers.reverse() <TAB>  <TAB> while self._workers: <TAB>  <TAB>  <TAB> worker = self._workers.pop() <TAB>  <TAB>  <TAB> worker.join() <TAB>  <TAB> # Clear the queues <TAB>  <TAB> self.callback_queue = self.queue_impl() <TAB>  <TAB> self.completion_queue = self.queue_impl() <TAB>  <TAB> python2atexit.unregister(self.stop)",if not self . _running :,166
"def validate(self, data, config_sets): <TAB> if isinstance(data, InitConfigSets): <TAB>  <TAB> for k, v in sorted(config_sets.iteritems()): <TAB>  <TAB>  <TAB> if not isinstance(v, InitConfig): <TAB>  <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""init configs must of type "", ""cloudformation.InitConfigSet"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> else: <MASK> raise ValueError(""config property is required"") <TAB>  <TAB> if not isinstance(data[""config""], InitConfig): <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""config property must be of type cloudformation.InitConfig"" <TAB>  <TAB>  <TAB> )","if ""config"" not in data :",157
"def match_multirun_collections(self, trans, history, dataset_collection_matcher): <TAB> for history_dataset_collection in history.active_visible_dataset_collections: <TAB>  <TAB> if not self._history_query(trans).can_map_over(history_dataset_collection): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> match = dataset_collection_matcher.hdca_match(history_dataset_collection) <MASK> yield history_dataset_collection, match.implicit_conversion",if match :,115
"def gw_unsubscribe(self, subscription_id): <TAB> with self._lock: <TAB>  <TAB> for attribute in self.__sub_dict: <TAB>  <TAB>  <TAB> if self.__sub_dict[attribute].get(subscription_id): <TAB>  <TAB>  <TAB>  <TAB> del self.__sub_dict[attribute][subscription_id] <TAB>  <TAB>  <TAB>  <TAB> log.info( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Unsubscribed from %s, subscription id %i"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> attribute, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> subscription_id, <TAB>  <TAB>  <TAB>  <TAB> ) <MASK> self.__sub_dict = {}","if subscription_id == ""*"" :",149
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_application_key(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 16: <TAB>  <TAB>  <TAB> self.set_duration_minutes(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <MASK> self.set_tag(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 26 :,154
"def update_values(self, conf_dict): <TAB> for ipt in self.inputs: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> ipt.set_value(conf_dict[ipt.name]) <TAB>  <TAB>  <TAB> except KeyError:  # just ignore if it's not in dict <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> if hasattr(ipt, ""get_child""): <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> c = ipt.get_child() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> c.set_value(conf_dict[c.name]) <TAB>  <TAB>  <TAB>  <TAB> except KeyError:  # just ignore if it's not in dict <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass",if ipt . has_input ( ) :,165
def _cut_subword(tokens: List[str]) -> List[str]: <TAB> len_tokens = len(tokens) <TAB> i = 0 <TAB> while True: <MASK> break <TAB>  <TAB> if _RE_ENDING_CHAR.search(tokens[i]) and i > 0 and len(tokens[i]) == 1: <TAB>  <TAB>  <TAB> tokens[i - 1] += tokens[i] <TAB>  <TAB>  <TAB> del tokens[i] <TAB>  <TAB>  <TAB> len_tokens -= 1 <TAB>  <TAB> i += 1 <TAB> return tokens,if i == len_tokens :,127
"def _rating(app, value): <TAB> song = app.player.song <TAB> if not song: <TAB>  <TAB> return <TAB> if value[0] in (""+"", ""-""): <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> change = float(value[1:]) <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> change = 1 / RATINGS.number <TAB>  <TAB> if value[0] == ""-"": <TAB>  <TAB>  <TAB> change = -change <TAB>  <TAB> rating = song[""~#rating""] + change <TAB> else: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> rating = float(value) <TAB>  <TAB> except (ValueError, TypeError): <TAB>  <TAB>  <TAB> return <TAB> song[""~#rating""] = max(0.0, min(1.0, rating)) <TAB> app.library.changed([song])",if len ( value ) > 1 :,196
"def build_embedding(embed_file, targ_vocab, dim_vec): <TAB> vocab_size = len(targ_vocab) <TAB> emb = np.zeros((vocab_size, dim_vec)) <TAB> w2id = {w: i for i, w in enumerate(targ_vocab)} <TAB> with open(embed_file) as f: <TAB>  <TAB> for line in f: <TAB>  <TAB>  <TAB> elems = line.split() <TAB>  <TAB>  <TAB> token = normalize_text("""".join(elems[0:-wv_dim])) <MASK> emb[w2id[token]] = [float(v) for v in elems[-wv_dim:]] <TAB> return emb",if token in w2id :,162
"def _validate_enum_value(field_name, value, enum_value): <TAB> if isinstance(enum_value, list): <TAB>  <TAB> if value not in enum_value: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Invalid value %s assigned "" ""to field %s"" % (value, field_name) <TAB>  <TAB>  <TAB> ) <TAB> elif isinstance(enum_value, str): <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Invalid value %s assigned "" ""to field %s"" % (value, field_name) <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> raise TypeError( <TAB>  <TAB>  <TAB> ""Value of enum should "" ""be either a string or list of strings.\n"" <TAB>  <TAB> )",if not value == enum_value :,175
"def _check_all_tasks(tasks): <TAB> """"""Checks the results of all tasks."""""" <TAB> running_tasks_data = [] <TAB> for task in tasks: <TAB>  <TAB> if task.isAlive(): <TAB>  <TAB>  <TAB> running_tasks_data.append( <TAB>  <TAB>  <TAB>  <TAB> ""  %s (started %s)"" <TAB>  <TAB>  <TAB>  <TAB> % ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> task.name, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> time.strftime(""%H:%M:%S"", time.localtime(task.start_time)), <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <MASK> ALL_ERRORS.append(task.exception) <TAB> if running_tasks_data: <TAB>  <TAB> log(""----------------------------------------"") <TAB>  <TAB> log(""Tasks still running:"") <TAB>  <TAB> for task_details in running_tasks_data: <TAB>  <TAB>  <TAB> log(task_details)",if task . exception :,197
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.set_start(d.getVarInt64()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 16: <TAB>  <TAB>  <TAB> self.set_end(d.getVarInt64()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 8 :,120
"def test_test_writable_dir_win(): <TAB> with tempfile.TemporaryDirectory() as td: <TAB>  <TAB> assert install._test_writable_dir_win(td) is True <TAB>  <TAB> # Ironically, I don't know how to make a non-writable dir on Windows, <TAB>  <TAB> # so although the functionality is for Windows, the test is for Posix <MASK> return <TAB>  <TAB> # Remove write permissions from the directory <TAB>  <TAB> os.chmod(td, 0o444) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> assert install._test_writable_dir_win(td) is False <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> os.chmod(td, 0o644)","if os . name != ""posix"" :",163
"def export_ctf(path=None): <TAB> with app.app_context(): <TAB>  <TAB> backup = export_ctf_util() <MASK> with open(path, ""wb"") as target: <TAB>  <TAB>  <TAB>  <TAB> shutil.copyfileobj(backup, target) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = ctf_name() <TAB>  <TAB>  <TAB> day = datetime.datetime.now().strftime(""%Y-%m-%d"") <TAB>  <TAB>  <TAB> full_name = f""{name}.{day}.zip"" <TAB>  <TAB>  <TAB> with open(full_name, ""wb"") as target: <TAB>  <TAB>  <TAB>  <TAB> shutil.copyfileobj(backup, target) <TAB>  <TAB>  <TAB> print(f""Exported {full_name}"")",if path :,163
"def test_setting_reducers(self): <TAB> for loss in [TripletMarginLoss, ContrastiveLoss]: <TAB>  <TAB> for reducer in [ <TAB>  <TAB>  <TAB> ThresholdReducer(low=0), <TAB>  <TAB>  <TAB> MeanReducer(), <TAB>  <TAB>  <TAB> AvgNonZeroReducer(), <TAB>  <TAB> ]: <TAB>  <TAB>  <TAB> L = loss(reducer=reducer) <MASK> assert type(L.reducer) == type(reducer) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> for v in L.reducer.reducers.values(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> assert type(v) == type(reducer)","if isinstance ( L , TripletMarginLoss ) :",153
"def ReadBytes(self, address, num_bytes): <TAB> for region in self.regions: <MASK> offset = address - region.start <TAB>  <TAB>  <TAB> return region.data[offset : offset + num_bytes]",if address >= region . start and address + num_bytes <= region . end :,70
"def validate(self): <TAB> if self.scheduled_time: <TAB>  <TAB> current_time = frappe.utils.now_datetime() <TAB>  <TAB> scheduled_time = frappe.utils.get_datetime(self.scheduled_time) <MASK> frappe.throw(_(""Invalid Scheduled Time""))",if scheduled_time < current_time :,83
"def _daemon(self): <TAB> last_ping = time() <TAB> while self._task is not None: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if self._exit_event.wait(min(self.ping_period, self.report_period)): <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> # send ping request <MASK> self.ping() <TAB>  <TAB>  <TAB>  <TAB> last_ping = time() <TAB>  <TAB>  <TAB> if self._dev_stop_signal: <TAB>  <TAB>  <TAB>  <TAB> stop_reason = self._dev_stop_signal.test() <TAB>  <TAB>  <TAB>  <TAB> if stop_reason and self._task: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._task._dev_mode_stop_task(stop_reason) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> pass",if self . _support_ping and ( time ( ) - last_ping ) >= self . ping_period :,196
"def test_avg_values_list_group_by(self): <TAB> ret = ( <TAB>  <TAB> await Book.annotate(avg=Avg(""rating"")) <TAB>  <TAB> .group_by(""author_id"") <TAB>  <TAB> .values_list(""author_id"", ""avg"") <TAB> ) <TAB> for item in ret: <TAB>  <TAB> author_id = item[0] <TAB>  <TAB> avg = item[1] <TAB>  <TAB> if author_id == self.a1.pk: <TAB>  <TAB>  <TAB> self.assertEqual(avg, 4.5) <MASK> self.assertEqual(avg, 2.0)",elif author_id == self . a2 . pk :,150
"def _process_multiple(self): <TAB> if not self.fixed_input: <MASK> self.H_multi = np.tile(self.H, (self.num_frames, 1)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.H_multi = np.tile(self.H, (self.num_frames, 1, 1)) <TAB> np.multiply(self.X, self.H_multi, self.X)",if self . mono :,108
"def _keys_iter(self): <TAB> work_queue = [] <TAB> work_queue.append(([], self._data)) <TAB> while work_queue: <TAB>  <TAB> path, data = work_queue.pop(0) <MASK> for key in sorted(data.keys()): <TAB>  <TAB>  <TAB>  <TAB> work_queue.append((path + [key], data[key])) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield ""."".join(path)","if isinstance ( data , dict ) :",109
"def get_inverse_graphkeys(): <TAB> ret = {} <TAB> for name in dir(tf.GraphKeys): <MASK> continue <TAB>  <TAB> if name in [""VARIABLES""]:  # will produce deprecated warning <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> ret[getattr(tf.GraphKeys, name)] = ""tf.GraphKeys.{}"".format(name) <TAB> return ret","if name . startswith ( ""_"" ) :",85
"def parse_cg(self): <TAB> """"""Parse the call graph."""""" <TAB> # skip call graph header <TAB> while not self._cg_header_re.match(self.readline()): <TAB>  <TAB> pass <TAB> line = self.readline() <TAB> while self._cg_header_re.match(line): <TAB>  <TAB> line = self.readline() <TAB> # process call graph entries <TAB> entry_lines = [] <TAB> while line != ""\014"":  # form feed <TAB>  <TAB> if line and not line.isspace(): <MASK> self.parse_cg_entry(entry_lines) <TAB>  <TAB>  <TAB>  <TAB> entry_lines = [] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> entry_lines.append(line) <TAB>  <TAB> line = self.readline()",if self . _cg_sep_re . match ( line ) :,186
"def request(self, host, handler, request_body, verbose=0): <TAB> # retry request once if cached connection has gone cold <TAB> for i in (0, 1): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self.single_request(host, handler, request_body, verbose) <TAB>  <TAB> except socket.error as e: <MASK> raise <TAB>  <TAB> except BadStatusLine:  # close after we sent request <TAB>  <TAB>  <TAB> if i: <TAB>  <TAB>  <TAB>  <TAB> raise","if i or e . errno not in ( errno . ECONNRESET , errno . ECONNABORTED , errno . EPIPE ) :",142
"def GET(self, key): <TAB> account = accounts.find(username=key) or accounts.find(email=key) <TAB> if account: <MASK> raise web.seeother(""/admin/people/"" + account.username) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return render_template(""admin/people/view"", account) <TAB> else: <TAB>  <TAB> raise web.notfound()","if ""@"" in key :",95
"def run(self): <TAB> try: <TAB>  <TAB> self.status(""Removing previous builds..."") <TAB>  <TAB> rmtree(os.path.join(HERE, ""dist"")) <TAB>  <TAB> rmtree(os.path.join(HERE, ""build"")) <TAB>  <TAB> rmtree(os.path.join(HERE, ""pyexcel.egg-info"")) <TAB> except OSError: <TAB>  <TAB> pass <TAB> self.status(""Building Source and Wheel (universal) distribution..."") <TAB> run_status = True <TAB> if has_gease(): <TAB>  <TAB> run_status = os.system(GS_COMMAND) == 0 <TAB> else: <TAB>  <TAB> self.status(NO_GS_MESSAGE) <TAB> if run_status: <MASK> self.status(UPLOAD_FAILED_MSG) <TAB> sys.exit()",if os . system ( PUBLISH_COMMAND ) != 0 :,191
"def scan_spec_conf(self, conf): <TAB> if ""image"" in conf: <TAB>  <TAB> image_val = conf[""image""] <TAB>  <TAB> if not isinstance(image_val, str) or image_val.strip() == """": <TAB>  <TAB>  <TAB> return CheckResult.UNKNOWN <TAB>  <TAB> # If there's a digest, then this is even better than the tag, so the check passes <TAB>  <TAB> if ""@"" in image_val: <TAB>  <TAB>  <TAB> return CheckResult.PASSED <TAB>  <TAB> (image, tag) = re.findall(DOCKER_IMAGE_REGEX, image_val)[0] <MASK> return CheckResult.FAILED <TAB> else: <TAB>  <TAB> return CheckResult.FAILED <TAB> return CheckResult.PASSED","if tag == ""latest"" or tag == """" :",177
def create_default_success_action(): <TAB> for success_action in get_default_success_action(): <MASK> doc = frappe.get_doc(success_action) <TAB>  <TAB>  <TAB> doc.insert(ignore_permissions=True),"if not frappe . db . exists ( ""Success Action"" , success_action . get ( ""ref_doctype"" ) ) :",83
"def _validate_user_str(self, user): <TAB> """"""Parse string with uid:gid or username"""""" <TAB> user_id = dict() <TAB> if not isinstance(user, str): <TAB>  <TAB> return user_id <TAB> if re.match(""^[a-zA-Z_][a-zA-Z0-9_-]*$"", user): <TAB>  <TAB> user_id[""user""] = user <TAB>  <TAB> return user_id <TAB> else: <TAB>  <TAB> match = re.match(""^(\\d+)(:(\\d+)){0,1}$"", user) <MASK> user_id[""uid""] = match.group(1) <TAB>  <TAB>  <TAB> if match.group(3): <TAB>  <TAB>  <TAB>  <TAB> user_id[""gid""] = match.group(3) <TAB> return user_id",if match :,181
"def module(foldername): <TAB> ret = [foldername] <TAB> for i in os.listdir(foldername): <MASK> continue <TAB>  <TAB> subfolder = os.path.join(foldername, i) <TAB>  <TAB> if os.path.isdir(subfolder) and _ispackage(subfolder): <TAB>  <TAB>  <TAB> ret += module(subfolder) <TAB>  <TAB>  <TAB> ret += [subfolder.replace(os.sep, ""."")] <TAB> return ret","if i == ""__pycache__"" :",108
"def formatmonthname(self, theyear, themonth, withyear=True): <TAB> with different_locale(self.locale): <TAB>  <TAB> s = month_name[themonth] <MASK> s = ""%s %s"" % (s, theyear) <TAB>  <TAB> return '<tr><th colspan=""7"" class=""month"">%s</th></tr>' % s",if withyear :,92
"def feed(self, char, char_len): <TAB> """"""feed a character with known length"""""" <TAB> if char_len == 2: <TAB>  <TAB> # we only care about 2-bytes character in our distribution analysis <TAB>  <TAB> order = self.get_order(char) <TAB> else: <TAB>  <TAB> order = -1 <TAB> if order >= 0: <TAB>  <TAB> self._total_chars += 1 <TAB>  <TAB> # order is valid <TAB>  <TAB> if order < self._table_size: <MASK> self._freq_chars += 1",if 512 > self . _char_to_freq_order [ order ] :,138
"def mouse_drag(self, evt): <TAB> # if 'button' not in evt.dict or evt.button != 1: <TAB> # <TAB> return <TAB> if self.level: <TAB>  <TAB> f = self.blockFaceUnderCursor <MASK> (focusPoint, direction) = f <TAB>  <TAB>  <TAB> self.currentTool.mouseDrag(evt, focusPoint, direction)",if None != f :,93
"def mousePressEvent(self, event): <TAB> if event.button() == QtCore.Qt.LeftButton: <TAB>  <TAB> x = event.x() <TAB>  <TAB> if x < self._offset: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> rating = self._getRatingFromPosition(x) <MASK> rating = 0 <TAB>  <TAB> self._rating = rating <TAB>  <TAB> self._update_track() <TAB>  <TAB> self.update() <TAB>  <TAB> event.accept()",if self . _rating == rating :,112
"def test_sync_attrs_match_wrapper(async_file, wrapped): <TAB> for attr_name in _FILE_SYNC_ATTRS: <MASK> continue <TAB>  <TAB> with pytest.raises(AttributeError): <TAB>  <TAB>  <TAB> getattr(async_file, attr_name) <TAB>  <TAB> with pytest.raises(AttributeError): <TAB>  <TAB>  <TAB> getattr(wrapped, attr_name)",if attr_name in dir ( async_file ) :,97
"def wrapper(self, *args, **kwargs): <TAB> if not self.current_user: <TAB>  <TAB> if self.request.method in (""GET"", ""HEAD""): <TAB>  <TAB>  <TAB> url = self.get_login_url() <MASK> if urlparse.urlsplit(url).scheme: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # if login url is absolute, make next absolute too <TAB>  <TAB>  <TAB>  <TAB>  <TAB> next_url = self.request.full_url() <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> next_url = self.request.uri <TAB>  <TAB>  <TAB>  <TAB> url += ""?"" + urlencode(dict(next=next_url)) <TAB>  <TAB>  <TAB> self.redirect(url) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> raise HTTPError(403) <TAB> return method(self, *args, **kwargs)","if ""?"" not in url :",189
"def actually_bytes(stringy): <TAB> if PY_3_OR_HIGHER: <TAB>  <TAB> if type(stringy) == bytes: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> elif type(stringy) != str: <TAB>  <TAB>  <TAB> stringy = str(stringy) <MASK> stringy = stringy.encode(""utf-8"") <TAB> else: <TAB>  <TAB> if type(stringy) == str: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> elif type(stringy) != unicode: <TAB>  <TAB>  <TAB> stringy = str(stringy) <TAB>  <TAB> if type(stringy) == unicode: <TAB>  <TAB>  <TAB> stringy = stringy.encode(""utf-8"") <TAB> return stringy",if type ( stringy ) == str :,167
"def test_move_items(item_name): <TAB> """"""Ensure that everything loads correctly."""""" <TAB> try: <TAB>  <TAB> item = getattr(six.moves, item_name) <MASK> __import__(""six.moves."" + item_name) <TAB> except ImportError: <TAB>  <TAB> if item_name == ""winreg"" and not sys.platform.startswith(""win""): <TAB>  <TAB>  <TAB> pytest.skip(""Windows only module"") <TAB>  <TAB> if item_name.startswith(""tkinter""): <TAB>  <TAB>  <TAB> if not have_tkinter: <TAB>  <TAB>  <TAB>  <TAB> pytest.skip(""requires tkinter"") <TAB>  <TAB> if item_name.startswith(""dbm_gnu"") and not have_gdbm: <TAB>  <TAB>  <TAB> pytest.skip(""requires gdbm"") <TAB>  <TAB> raise <TAB> assert item_name in dir(six.moves)","if isinstance ( item , types . ModuleType ) :",193
"def __next__(self): <TAB> for event, node in self.event_stream: <MASK> self.event_stream.expandNode(node) <TAB>  <TAB>  <TAB> return self._handle_object(node) <TAB> raise StopIteration","if event == ""START_ELEMENT"" and node . nodeName == ""object"" :",72
"def get_section_bounds(section_name): <TAB> local_path = pwndbg.file.get_file(pwndbg.proc.exe) <TAB> with open(local_path, ""rb"") as f: <TAB>  <TAB> elffile = ELFFile(f) <TAB>  <TAB> section = elffile.get_section_by_name(section_name) <MASK> return (None, None) <TAB>  <TAB> start = section[""sh_addr""] <TAB>  <TAB> size = section[""sh_size""] <TAB>  <TAB> return (start, start + size)",if not section :,134
"def test_tell(self): <TAB> with LZMAFile(BytesIO(COMPRESSED_XZ)) as f: <TAB>  <TAB> pos = 0 <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> self.assertEqual(f.tell(), pos) <TAB>  <TAB>  <TAB> result = f.read(183) <MASK> break <TAB>  <TAB>  <TAB> pos += len(result) <TAB>  <TAB> self.assertEqual(f.tell(), len(INPUT)) <TAB> with LZMAFile(BytesIO(), ""w"") as f: <TAB>  <TAB> for pos in range(0, len(INPUT), 144): <TAB>  <TAB>  <TAB> self.assertEqual(f.tell(), pos) <TAB>  <TAB>  <TAB> f.write(INPUT[pos : pos + 144]) <TAB>  <TAB> self.assertEqual(f.tell(), len(INPUT))",if not result :,184
"def column_chunks(columns, n): <TAB> for column in columns: <TAB>  <TAB> if not isinstance(column, (np.ndarray, pd.DatetimeIndex)): <TAB>  <TAB>  <TAB> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""Unsupported column type: {}. "" <TAB>  <TAB>  <TAB>  <TAB> ""ndarray/DatetimeIndex is expected."".format(type(column)) <TAB>  <TAB>  <TAB> ) <TAB> # create chunk generator for every column <TAB> chunked = [ <TAB>  <TAB> iter(np.array_split(c, range(0, len(c), n)) if len(c) > n else [c]) <TAB>  <TAB> for c in columns <TAB> ] <TAB> while True: <TAB>  <TAB> # get next chunk for every column <TAB>  <TAB> item = [next(column, []) for column in chunked] <MASK> break <TAB>  <TAB> yield item",if not any ( len ( x ) for x in item ) :,192
"def _stringify(self, transform: StringifyTransform) -> str: <TAB> res = []  # type: List[str] <TAB> l = transform(self.leftSpecs) <TAB> if len(l) > 0: <TAB>  <TAB> res.append(l) <TAB> if self.trailingTypeSpec: <TAB>  <TAB> if len(res) > 0: <TAB>  <TAB>  <TAB> res.append("" "") <TAB>  <TAB> res.append(transform(self.trailingTypeSpec)) <TAB>  <TAB> r = str(self.rightSpecs) <MASK> if len(res) > 0: <TAB>  <TAB>  <TAB>  <TAB> res.append("" "") <TAB>  <TAB>  <TAB> res.append(r) <TAB> return """".join(res)",if len ( r ) > 0 :,169
"def on_button_add_section_clicked(self, widget): <TAB> text = self.show_text_edit_dialog( <TAB>  <TAB> _(""Add section""), _(""New section:""), affirmative_text=Gtk.STOCK_ADD <TAB> ) <TAB> if text is not None: <TAB>  <TAB> for index, (section,) in enumerate(self.section_list): <MASK> self.combo_section.set_active(index) <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> self.section_list.append([text]) <TAB>  <TAB> self.combo_section.set_active(len(self.section_list) - 1)",if text == section :,152
"def _run_suite(suite): <TAB> """"""Run tests from a unittest.TestSuite-derived class."""""" <TAB> if verbose: <TAB>  <TAB> runner = unittest.TextTestRunner(sys.stdout, verbosity=2) <TAB> else: <TAB>  <TAB> runner = BasicTestRunner() <TAB> result = runner.run(suite) <TAB> if not result.wasSuccessful(): <MASK> err = result.errors[0][1] <TAB>  <TAB> elif len(result.failures) == 1 and not result.errors: <TAB>  <TAB>  <TAB> err = result.failures[0][1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> err = ""multiple errors occurred"" <TAB>  <TAB>  <TAB> if not verbose: <TAB>  <TAB>  <TAB>  <TAB> err += ""; run in verbose mode for details"" <TAB>  <TAB> raise TestFailed(err)",if len ( result . errors ) == 1 and not result . failures :,187
"def load_training_data(): <TAB> words_data = [] <TAB> words = [] <TAB> for filename in os.listdir(TRAINING_DATA_DIRECTORY): <MASK> wav_path = os.path.join(TRAINING_DATA_DIRECTORY, filename) <TAB>  <TAB>  <TAB> words_data = words_data + SpeechRecognition.extract_words_from_audio( <TAB>  <TAB>  <TAB>  <TAB> wav_path <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> txt_path = os.path.join(TRAINING_DATA_DIRECTORY, filename[:-4] + "".txt"") <TAB>  <TAB>  <TAB> with open(txt_path) as f: <TAB>  <TAB>  <TAB>  <TAB> words = words + [x.strip() for x in f.readlines()] <TAB> return (words_data, words)","if filename . endswith ( "".wav"" ) :",181
"def wrapper(*args, **kwargs): <TAB> encoded_token = request.args.get(""token"") <TAB> if encoded_token: <TAB>  <TAB> handler = TokenHandler.from_string(encoded_token) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> res = handler.to_response() <TAB>  <TAB> except TokenHandlerNotFound as e: <TAB>  <TAB>  <TAB> raise HTTPError( <TAB>  <TAB>  <TAB>  <TAB> http_status.HTTP_400_BAD_REQUEST, <TAB>  <TAB>  <TAB>  <TAB> data={ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""message_short"": ""Invalid Token"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""message_long"": ""No token handler for action: {} found"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> e.action <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB>  <TAB> }, <TAB>  <TAB>  <TAB> ) <MASK> return res <TAB> return func(*args, **kwargs)",if res :,192
"def test_ols_sigma(): <MASK> if ""Sigma_u"" not in to_test: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> print(""\n\nSIGMA_U"", end="""") <TAB> for ds in datasets: <TAB>  <TAB> for dt in dt_s_list: <TAB>  <TAB>  <TAB> if debug_mode: <TAB>  <TAB>  <TAB>  <TAB> print(""\n"" + dt_s_tup_to_string(dt) + "": "", end="""") <TAB>  <TAB>  <TAB> err_msg = build_err_msg(ds, dt, ""Sigma_u"") <TAB>  <TAB>  <TAB> obtained = results_sm[ds][dt].sigma_u <TAB>  <TAB>  <TAB> desired = results_ref[ds][dt][""est""][""Sigma_u""] <TAB>  <TAB>  <TAB> assert_allclose(obtained, desired, rtol, atol, False, err_msg)",if debug_mode :,192
"def _get_windows_sysinfo(self): <TAB> sysinfo = {} <TAB> for line in self.check_output('systeminfo | findstr /B /C:""OS""').splitlines(): <TAB>  <TAB> key, value = line.split("":"", 1) <TAB>  <TAB> key = key.strip().replace("" "", ""_"").lower() <TAB>  <TAB> value = value.strip() <MASK> sysinfo[""distribution""] = value <TAB>  <TAB>  <TAB> sysinfo[""type""] = value.split("" "")[1].lower() <TAB>  <TAB> elif key == ""os_version"": <TAB>  <TAB>  <TAB> sysinfo[""release""] = value <TAB> sysinfo[""arch""] = self.check_output(""echo %PROCESSOR_ARCHITECTURE%"") <TAB> return sysinfo","if key == ""os_name"" :",171
"def getRunningJobIDs(self): <TAB> times = {} <TAB> with self.runningJobsLock: <TAB>  <TAB> currentjobs = dict((str(self.batchJobIDs[x][0]), x) for x in self.runningJobs) <TAB> process = subprocess.Popen( <TAB>  <TAB> [""bjobs"", ""-o"", ""jobid stat start_time delimiter='|'""], stdout=subprocess.PIPE <TAB> ) <TAB> stdout, _ = process.communicate() <TAB> for curline in stdout.decode(""utf-8"").split(""\n""): <TAB>  <TAB> items = curline.strip().split(""|"") <MASK> jobstart = parse(items[2], default=datetime.now(tzlocal())) <TAB>  <TAB>  <TAB> times[currentjobs[items[0]]] = datetime.now(tzlocal()) - jobstart <TAB> return times","if items [ 0 ] in currentjobs and items [ 1 ] == ""RUN"" :",198
"def _filter_templates(templates, template_filter): <TAB> filtered_templates = {} <TAB> for template_type, template_collection in templates.items(): <TAB>  <TAB> filtered_entries = {} <TAB>  <TAB> for template_key, template_entry in template_collection[""entries""].items(): <MASK> filtered_entries[template_key] = template_entry <TAB>  <TAB> filtered_templates[template_type] = { <TAB>  <TAB>  <TAB> ""order"": list( <TAB>  <TAB>  <TAB>  <TAB> filter(lambda x: x in filtered_entries, template_collection[""order""]) <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB> ""entries"": filtered_entries, <TAB>  <TAB> } <TAB> return filtered_templates","if template_filter ( template_type , template_key ) :",167
"def match_expression(self): <TAB> match = self.match(r""\${"") <TAB> if match: <TAB>  <TAB> line, pos = self.matched_lineno, self.matched_charpos <TAB>  <TAB> text, end = self.parse_until_text(True, r""\|"", r""}"") <MASK> escapes, end = self.parse_until_text(True, r""}"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> escapes = """" <TAB>  <TAB> text = text.replace(""\r\n"", ""\n"") <TAB>  <TAB> self.append_node( <TAB>  <TAB>  <TAB> parsetree.Expression, text, escapes.strip(), lineno=line, pos=pos <TAB>  <TAB> ) <TAB>  <TAB> return True <TAB> else: <TAB>  <TAB> return False","if end == ""|"" :",172
"def wrapper(*args, **kwargs): <TAB> lock_path = os.path.join(""./"", ""registry.{0}.lock"".format(f.func_name)) <TAB> if os.path.exists(lock_path): <TAB>  <TAB> x = 0 <TAB>  <TAB> while os.path.exists(lock_path) and x < 100: <TAB>  <TAB>  <TAB> logger.warn(""Another process is creating the search database"") <TAB>  <TAB>  <TAB> x += 1 <TAB>  <TAB>  <TAB> time.sleep(1) <MASK> raise Exception(""Timedout waiting for db init"") <TAB>  <TAB> return <TAB> lock_file = open(lock_path, ""w"") <TAB> lock_file.close() <TAB> try: <TAB>  <TAB> result = f(*args, **kwargs) <TAB> finally: <TAB>  <TAB> os.remove(lock_path) <TAB> return result",if x == 100 :,191
"def patchMenuTree(self, orig, targetPath, path=""""): <TAB> for n, z in enumerate(orig): <TAB>  <TAB> kind, val, val2 = z <TAB>  <TAB> if kind == ""@item"": <TAB>  <TAB>  <TAB> name = self.getName(val, val2) <TAB>  <TAB>  <TAB> curPath = path + ""/"" + name <MASK> return orig, n <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = self.getName(kind.replace(""@menu "", """")) <TAB>  <TAB>  <TAB> curPath = path + ""/"" + name <TAB>  <TAB>  <TAB> if curPath == targetPath: <TAB>  <TAB>  <TAB>  <TAB> return orig, n <TAB>  <TAB>  <TAB> ans = self.patchMenuTree(val, targetPath, path=path + ""/"" + name) <TAB>  <TAB>  <TAB> if ans: <TAB>  <TAB>  <TAB>  <TAB> return ans <TAB> return None",if curPath == targetPath :,192
"def _create_temp_volume_from_snapshot( <TAB> self, context, volume, snapshot, volume_options=None): <TAB> temp_vol_ref = self._create_temp_volume( <TAB>  <TAB> context, volume, volume_options=volume_options <TAB> ) <TAB> try: <TAB>  <TAB> model_update = self.create_volume_from_snapshot(temp_vol_ref, snapshot) <MASK> temp_vol_ref.update(model_update) <TAB> except Exception: <TAB>  <TAB> with excutils.save_and_reraise_exception(): <TAB>  <TAB>  <TAB> temp_vol_ref.destroy() <TAB> temp_vol_ref.status = ""available"" <TAB> temp_vol_ref.save() <TAB> return temp_vol_ref",if model_update :,178
"def load_schemas(path): <TAB> schemas = {} <TAB> for f in os.listdir(path): <TAB>  <TAB> filename, ext = os.path.splitext(f) <MASK> schemas[filename] = json.load(open(os.path.join(path, f))) <TAB> return schemas","if ext == "".json"" :",77
"def _dereference_placeholders(parts): <TAB> for part, is_placeholder in parts: <TAB>  <TAB> if is_placeholder: <MASK> log.debug( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> 'Found placeholder for unknown value ""{}"" in late config: {}'.format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> part, repr(content) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> raise Exception( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> 'Bad late config file: Found placeholder for unknown value ""{}""'.format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> part <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> yield late_values[part] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield part",if part not in late_values :,171
"def do_exceptional_blocking_test( <TAB> self, block_func, block_args, trigger_func, trigger_args, expected_exception_class): <TAB> thread = _TriggerThread(trigger_func, trigger_args) <TAB> thread.start() <TAB> try: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> block_func(*block_args) <TAB>  <TAB> except expected_exception_class: <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.fail(""expected exception of kind %r"" % expected_exception_class) <TAB> finally: <TAB>  <TAB> support.join_thread(thread)  # make sure the thread terminates <MASK> self.fail(""trigger thread ended but event never set"")",if not thread . startedEvent . is_set ( ) :,174
"def is_ready(self): <TAB> if not self.fds: <TAB>  <TAB> if self.name: <MASK> self.log.debug(""File not appeared yet: %s"", self.name) <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> if not os.path.getsize(self.name): <TAB>  <TAB>  <TAB>  <TAB> self.log.debug(""File is empty: %s"", self.name) <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> self.log.debug(""Opening file: %s"", self.name) <TAB>  <TAB> # call opener regardless of the name value as it can use empty name as flag <TAB>  <TAB> self.fds = self.file_opener(self.name) <TAB> if self.fds: <TAB>  <TAB> self.name = self.fds.name <TAB>  <TAB> return True",if not os . path . isfile ( self . name ) :,195
"def queue_top(self, torrent_ids): <TAB> log.debug(""Attempting to queue %s to top"", torrent_ids) <TAB> # torrent_ids must be sorted in reverse before moving to preserve order <TAB> for torrent_id in sorted( <TAB>  <TAB> torrent_ids, key=self.torrentmanager.get_queue_position, reverse=True <TAB> ): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> # If the queue method returns True, then we should emit a signal <MASK> component.get(""EventManager"").emit(TorrentQueueChangedEvent()) <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> log.warning(""torrent_id: %s does not exist in the queue"", torrent_id)",if self . torrentmanager . queue_top ( torrent_id ) :,184
"def _process_kwds(self, kwds, ix): <TAB> kwds = kwds.copy() <TAB> for k in kwds: <TAB>  <TAB> v = kwds[k] <MASK> mat = patsy.dmatrix(v.formula, self.data, return_type=""dataframe"") <TAB>  <TAB>  <TAB> mat = np.asarray(mat)[ix, :] <TAB>  <TAB>  <TAB> if mat.shape[1] == 1: <TAB>  <TAB>  <TAB>  <TAB> mat = mat[:, 0] <TAB>  <TAB>  <TAB> kwds[k] = mat <TAB> return kwds","if isinstance ( v , PatsyFormula ) :",128
"def find_iter_by_name(self, name): <TAB> iter = self.model.get_iter_root() <TAB> path = self.model.value_path(iter, 0) <TAB> while iter: <MASK> return iter <TAB>  <TAB> elif name.startswith(path): <TAB>  <TAB>  <TAB> child = self.model.iter_children(iter) <TAB>  <TAB>  <TAB> while child: <TAB>  <TAB>  <TAB>  <TAB> path = self.model.value_path(child, 0) <TAB>  <TAB>  <TAB>  <TAB> if name == path: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return child <TAB>  <TAB>  <TAB>  <TAB> elif name.startswith(path): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> child = self.model.iter_next(child) <TAB>  <TAB>  <TAB> iter = child <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> return None",if name == path :,198
"def clean(self): <TAB> if self._errors: <TAB>  <TAB> return <TAB> user = authenticate(**self.user_credentials()) <TAB> if user: <TAB>  <TAB> if user.is_active: <TAB>  <TAB>  <TAB> self.user = user <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise forms.ValidationError(_(""This account is currently inactive."")) <TAB> else: <MASK> error = _( <TAB>  <TAB>  <TAB>  <TAB> ""The email address and/or password you specified are not correct."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> error = _(""The username and/or password you specified are not correct."") <TAB>  <TAB> raise forms.ValidationError(error) <TAB> return self.cleaned_data",if EMAIL_AUTHENTICATION :,163
"def test_get_source_none_filter(self, path_filter, param_sets): <TAB> loader = self.loader_factory(path_filter=path_filter) <TAB> for param_set in param_sets: <TAB>  <TAB> template, success = param_set <MASK> self._test_get_source_success(loader, template) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._test_get_source_notfound(loader, template)",if success :,108
"def set_default_policy(self, peer, typ, default): <TAB> if typ in [""in"", ""out"", ""import"", ""export""] and default in [""reject"", ""accept""]: <MASK> self.peers[peer][""default-policy""] = {} <TAB>  <TAB> self.peers[peer][""default-policy""][typ] = default <TAB> else: <TAB>  <TAB> raise Exception(""wrong type or default"")","if ""default-policy"" not in self . peers [ peer ] :",110
"def auth_error(error): <TAB> if ""audit_object"" in g: <TAB>  <TAB> message = """" <MASK> message = error.message <TAB>  <TAB> if hasattr(error, ""details""): <TAB>  <TAB>  <TAB> if error.details: <TAB>  <TAB>  <TAB>  <TAB> if ""message"" in error.details: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> message = u""{}|{}"".format(message, error.details[""message""]) <TAB>  <TAB> g.audit_object.add_to_log({""info"": message}, add_with_comma=True) <TAB> return send_error(error.message, error_code=error.id, details=error.details), 401","if hasattr ( error , ""message"" ) :",154
"def do_hash_password(password): <TAB> if password is None: <TAB>  <TAB> password = """" <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> password = input(""Password: "") <MASK> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> log.error(""Must provide a non-empty password"") <TAB> print_header(""HASHING PASSWORD TO SHA512"") <TAB> hashed_password = sha512_crypt.encrypt(password) <TAB> return hashed_password",if password :,111
"def _clear_related(self, related): <TAB> if related and self.owner: <MASK> related = [related] <TAB>  <TAB> for r in (r.with_snapshots(self.snapshots) for r in related): <TAB>  <TAB>  <TAB> clear_related(r, self.related_name, self.owner)","if not isinstance ( related , list ) :",82
"def set_actor(self, user, sender, instance, **kwargs): <TAB> if sender == ActivityStream: <TAB>  <TAB> if isinstance(user, User) and instance.actor is None: <TAB>  <TAB>  <TAB> user = User.objects.filter(id=user.id) <MASK> user = user[0] <TAB>  <TAB>  <TAB>  <TAB> instance.actor = user <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if instance.id not in self.instance_ids: <TAB>  <TAB>  <TAB>  <TAB> self.instance_ids.append(instance.id)",if user . exists ( ) :,129
"def removeNonTests(self, suite): <TAB> for test in list(suite): <TAB>  <TAB> if not getattr(test, ""__test__"", True): <TAB>  <TAB>  <TAB> suite._tests.remove(test) <MASK> self.removeNonTests(test)","elif isinstance ( test , TestSuite ) :",68
"def close(self): <TAB> """"""Close the session: close websocket, close runtime, dispose app."""""" <TAB> # Stop guarding objects to break down any circular refs <TAB> self._ping_calls = [] <TAB> self._closing = True  # suppress warnings for session being closed. <TAB> try: <TAB>  <TAB> # Close the websocket <MASK> self._ws.close_this() <TAB>  <TAB> # Close the runtime <TAB>  <TAB> if self._runtime: <TAB>  <TAB>  <TAB> self._runtime.close() <TAB>  <TAB> # Dispose the component and break the circular reference <TAB>  <TAB> if self._component is not None: <TAB>  <TAB>  <TAB> self._component.dispose() <TAB>  <TAB>  <TAB> self._component = None <TAB>  <TAB> # Discard data <TAB>  <TAB> self._data = {} <TAB> finally: <TAB>  <TAB> self._closing = False",if self . _ws :,187
"def on_key_press(self, window, event): <TAB> """"""Handle a keyboard event"""""" <TAB> maker = Factory() <TAB> self.set_urgency_hint(False) <TAB> mapping = self.terminator.keybindings.lookup(event) <TAB> if mapping: <TAB>  <TAB> dbg(""Window::on_key_press: looked up %r"" % mapping) <TAB>  <TAB> if mapping == ""full_screen"": <TAB>  <TAB>  <TAB> self.set_fullscreen(not self.isfullscreen) <TAB>  <TAB> elif mapping == ""close_window"": <MASK> self.on_destroy_event(window, Gdk.Event.new(Gdk.EventType.DESTROY)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> return True","if not self . on_delete_event ( window , Gdk . Event . new ( Gdk . EventType . DELETE ) ) :",198
"def __iter__(self): <TAB> """"""Yields (tag, val, step) for all scalars in dir."""""" <TAB> for event in EventReader(self.dir): <TAB>  <TAB> for val in event.summary.value: <TAB>  <TAB>  <TAB> scalar_info = _try_scalar_event(event, val) <MASK> yield scalar_info",if scalar_info is not None :,88
"def _removeEuroLocale(self): <TAB> envvars = [""LC_ALL"", ""LC_CTYPE"", ""LANG"", ""LANGUAGE""] <TAB> for var in envvars: <TAB>  <TAB> orig_lang = os.getenv(var) <MASK> lang = orig_lang[: orig_lang.find(""@euro"")] <TAB>  <TAB>  <TAB> os.environ[var] = lang","if orig_lang and orig_lang . lower ( ) . endswith ( ""@euro"" ) :",105
"def _parse_inner_rulesets(self): <TAB> self._parse_required_operator(""{"") <TAB> while True: <TAB>  <TAB> tok = self._tokenizer.get_next_token() <TAB>  <TAB> if tok[""style""] == EOF_STYLE: <TAB>  <TAB>  <TAB> self._add_result(""expecting '}'"", tok) <TAB>  <TAB>  <TAB> return <MASK> break <TAB>  <TAB> self._tokenizer.put_back(tok) <TAB>  <TAB> self._parse_ruleset()","elif self . _classifier . is_operator ( tok , ""}"" ) :",120
"def generate_ha_loader_config(middleware): <TAB> if middleware.call_sync(""iscsi.global.alua_enabled""): <TAB>  <TAB> node = middleware.call_sync(""failover.node"") <TAB>  <TAB> if node == ""A"": <TAB>  <TAB>  <TAB> return [""kern.cam.ctl.ha_id=1""] <MASK> return [""kern.cam.ctl.ha_id=2""] <TAB>  <TAB> return [] <TAB> return [""kern.cam.ctl.ha_id=0""]","if node == ""B"" :",122
"def enum_types(mimedb): <TAB> i = 0 <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> ctype = _winreg.EnumKey(mimedb, i) <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <MASK> yield ctype <TAB>  <TAB> i += 1","if ""\0"" not in ctype :",82
"def describe_tags(self): <TAB> elbs = [] <TAB> for key, value in self.querystring.items(): <TAB>  <TAB> if ""LoadBalancerNames.member"" in key: <TAB>  <TAB>  <TAB> number = key.split(""."")[2] <TAB>  <TAB>  <TAB> load_balancer_name = self._get_param( <TAB>  <TAB>  <TAB>  <TAB> ""LoadBalancerNames.member.{0}"".format(number) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> elb = self.elb_backend.get_load_balancer(load_balancer_name) <MASK> raise LoadBalancerNotFoundError(load_balancer_name) <TAB>  <TAB>  <TAB> elbs.append(elb) <TAB> template = self.response_template(DESCRIBE_TAGS_TEMPLATE) <TAB> return template.render(load_balancers=elbs)",if not elb :,191
"def url_rewrite(self, task, entry): <TAB> for name, config in self.resolves.get(task.name, {}).items(): <TAB>  <TAB> regexp = config[""regexp_compiled""] <TAB>  <TAB> format = config[""format""] <TAB>  <TAB> if regexp.search(entry[""url""]): <TAB>  <TAB>  <TAB> log.debug(""Regexp resolving %s with %s"" % (entry[""url""], name)) <TAB>  <TAB>  <TAB> # run the regexp <TAB>  <TAB>  <TAB> entry[""url""] = regexp.sub(format, entry[""url""]) <MASK> entry.fail(""urlrewriting"") <TAB>  <TAB>  <TAB>  <TAB> raise UrlRewritingError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Regexp %s result should NOT continue to match!"" % name <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return","if regexp . match ( entry [ ""url"" ] ) :",184
"def do_state(self, d, mode_name): <TAB> """"""General dispatcher code. d is a dispatch dict."""""" <TAB> try: <TAB>  <TAB> func = d.get(self.stroke) <MASK> func() <TAB>  <TAB> elif self.is_plain_key(self.stroke): <TAB>  <TAB>  <TAB> self.ignore() <TAB>  <TAB>  <TAB> self.quit() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Pass non-plain keys to k.masterKeyHandler <TAB>  <TAB>  <TAB> self.delegate() <TAB> except Exception: <TAB>  <TAB> g.es_exception() <TAB>  <TAB> self.quit()",if func :,138
"def prepareRadiusList(self, radii, length): <TAB> if len(radii) == length: <TAB>  <TAB> return FloatList.fromValues(radii) <TAB> elif len(radii) < length: <MASK> return FloatList.fromValue(0, length=length) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return FloatList.fromValues(radii).repeated(length=length) <TAB> else: <TAB>  <TAB> return FloatList.fromValues(radii[:length])",if len ( radii ) == 0 :,120
"def handle_messages(self, request: Request, receive: Callable) -> None: <TAB> while True: <TAB>  <TAB> message = await receive() <TAB>  <TAB> if message[""type""] == ""http.request"": <TAB>  <TAB>  <TAB> request.body.append(message.get(""body"", b"""")) <MASK> request.body.set_complete() <TAB>  <TAB> elif message[""type""] == ""http.disconnect"": <TAB>  <TAB>  <TAB> return","if not message . get ( ""more_body"" , False ) :",112
"def get_cmd(): <TAB> cmd, end_recved = None, False <TAB> try: <TAB>  <TAB> if not cmd_queue.empty(): <TAB>  <TAB>  <TAB> cmd = cmd_queue.get() <TAB>  <TAB>  <TAB> cmd_queue.task_done() <MASK> end_recved = True <TAB> except IOError: <TAB>  <TAB> end_recved = True <TAB> return cmd, end_recved","if isinstance ( cmd , EndSignal ) :",103
"def _getenv(self, search_key): <TAB> """"""A getenv() for the container environment metadata."""""" <TAB> for pair in self.opt[""env""]: <TAB>  <TAB> if pair: <MASK> (key, val) = pair.split(""="", 1) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> key = pair <TAB>  <TAB>  <TAB>  <TAB> val = """" <TAB>  <TAB>  <TAB> if key == search_key: <TAB>  <TAB>  <TAB>  <TAB> return str(val) <TAB> return None","if ""="" in pair :",114
"def getDigitPlaces(minValue, maxValue): <TAB> minDigits = 3 <TAB> maxDigits = 5 <TAB> currentDecision = minDigits <TAB> for value in (floatUnerr(minValue), floatUnerr(maxValue)): <TAB>  <TAB> for currentDigit in range(minDigits, maxDigits + 1): <MASK> if currentDigit > currentDecision: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> currentDecision = currentDigit <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> # Max decimal places we can afford to show was not enough <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return maxDigits <TAB> return currentDecision","if round ( value , currentDigit ) == value :",149
"def _find_exceptions(): <TAB> for name, obj in iteritems(globals()): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> is_http_exception = issubclass(obj, HTTPException) <TAB>  <TAB> except TypeError: <TAB>  <TAB>  <TAB> is_http_exception = False <TAB>  <TAB> if not is_http_exception or obj.code is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> __all__.append(obj.__name__) <TAB>  <TAB> old_obj = default_exceptions.get(obj.code, None) <MASK> continue <TAB>  <TAB> default_exceptions[obj.code] = obj","if old_obj is not None and issubclass ( obj , old_obj ) :",147
"def merge_entry_paths(keys, value): <TAB> for field, argument in keys.items(): <MASK> continue <TAB>  <TAB> config_path = Path(value[field]) <TAB>  <TAB> if config_path.is_absolute(): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> value[field] = args[argument] / config_path",if field not in value :,83
"def check_msal_error(value: Dict[str, Any], expected: List[str]) -> None: <TAB> if ""error"" in value: <TAB>  <TAB> if ""error_description"" in value: <TAB>  <TAB>  <TAB> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> ""error: %s\n%s"" % (value[""error""], value[""error_description""]) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> raise Exception(""error: %s"" % (value[""error""])) <TAB> for entry in expected: <MASK> raise Exception(""interactive login missing value: %s - %s"" % (entry, value))",if entry not in value :,143
"def sqs(self): <TAB> if self._sqs is None: <TAB>  <TAB> session = boto3.session.Session( <TAB>  <TAB>  <TAB> region_name=self.region, <TAB>  <TAB>  <TAB> aws_access_key_id=self.conninfo.userid, <TAB>  <TAB>  <TAB> aws_secret_access_key=self.conninfo.password, <TAB>  <TAB> ) <TAB>  <TAB> is_secure = self.is_secure if self.is_secure is not None else True <TAB>  <TAB> client_kwargs = {""use_ssl"": is_secure} <MASK> client_kwargs[""endpoint_url""] = self.endpoint_url <TAB>  <TAB> self._sqs = session.client(""sqs"", **client_kwargs) <TAB> return self._sqs",if self . endpoint_url is not None :,176
"def isAvailable(self): <TAB> if self.programDir: <TAB>  <TAB> path = os.path.join(self.programDir, self.name) <MASK> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # I don't have commercial versions of MSVC so I can't test this <TAB>  <TAB>  <TAB> name = ""devenv.com"" <TAB>  <TAB>  <TAB> path = os.path.join(self.programDir, name) <TAB>  <TAB>  <TAB> if os.path.exists(path): <TAB>  <TAB>  <TAB>  <TAB> self.name = ""devenv.com"" <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if os . path . exists ( path ) :,150
"def winner(num_candidates): <TAB> if num_candidates == 0: <TAB>  <TAB> return True, """", 0 <TAB> leader = 0 <TAB> total_votes = candidates[0][""num_votes""] <TAB> for i in range(1, num_candidates): <TAB>  <TAB> total_votes += candidates[i][""num_votes""] <MASK> leader = i <TAB> if candidates[leader][""char""] is None: <TAB>  <TAB> return False, """", 0 <TAB> return ( <TAB>  <TAB> True, <TAB>  <TAB> candidates[leader][""char""], <TAB>  <TAB> candidates[leader][""num_votes""] / total_votes, <TAB> )","if candidates [ i ] [ ""num_votes"" ] > candidates [ leader ] [ ""num_votes"" ] :",171
"def import_system_file(mod, safe=True): <TAB> if os.path.isfile(mod): <TAB>  <TAB> return _import_system_file(mod) <TAB> else: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return import_module(mod) <TAB>  <TAB> except ImportError: <TAB>  <TAB>  <TAB> mod2 = os.path.join(mod, ""__init__.py"") <MASK> return _import_system_file(mod2) <TAB>  <TAB>  <TAB> elif not safe: <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB>  <TAB> pass",if os . path . isfile ( mod2 ) :,133
"def get_id_input(self, prompt: str, valid_vals: List[int]) -> int: <TAB> # for neat output <TAB> print(""\n"" + ""*"" * 10) <TAB> idx = -1 <TAB> while idx == -1: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> idx = int(input(""[INPUT] "" + prompt)) <MASK> print(""[INFO] please input a valid integer in: "", valid_vals) <TAB>  <TAB>  <TAB>  <TAB> idx = -1 <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> print(""[INFO] please enter integer value"") <TAB> return idx",if not idx in valid_vals :,143
def clearLayout(l): <TAB> while l.count() != 0: <TAB>  <TAB> i = l.takeAt(0) <TAB>  <TAB> if i.widget(): <TAB>  <TAB>  <TAB> i.widget().deleteLater() <MASK> clearLayout(i.layout()),if i . layout ( ) :,68
"def dynamicImport(cls, name): <TAB> if name not in captchaSolvers: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> __import__(""{}.{}"".format(cls.__module__, name)) <MASK> raise ImportError(""The anti captcha provider was not initialized."") <TAB>  <TAB> except ImportError: <TAB>  <TAB>  <TAB> logging.error(""Unable to load {} anti captcha provider"".format(name)) <TAB>  <TAB>  <TAB> raise <TAB> return captchaSolvers[name]","if not isinstance ( captchaSolvers . get ( name ) , Captcha ) :",123
"def recall_at_k_insQA(y_true, y_pred, k): <TAB> labels = np.repeat(np.expand_dims(np.asarray(y_true), axis=1), k, axis=1) <TAB> predictions = np.array(y_pred) <TAB> predictions = np.flip(np.argsort(predictions, -1), -1)[:, :k] <TAB> flags = np.zeros_like(predictions) <TAB> for i in range(predictions.shape[0]): <TAB>  <TAB> for j in range(predictions.shape[1]): <MASK> flags[i][j] = 1.0 <TAB> return np.mean((np.sum(flags, -1) >= 1.0).astype(float))",if predictions [ i ] [ j ] in np . arange ( labels [ i ] [ j ] ) :,189
"def insertFromMimeData(self, source): <TAB> # not sure really necessary since it actually appears to paste URLs correctly <TAB> # I am stripping the http <TAB> print(""Paste"") <TAB> text = g.u(source.text()) <TAB> if len(text.split()) == 1 and ( <TAB>  <TAB> text.startswith(""http://"") or ""www"" in text or "".com"" in text or "".html"" in text <TAB> ): <MASK> text = '<a href=""{0}"">{1}</a> '.format(text, text[7:]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> text = '<a href=""http://{0}"">{0}</a> '.format(text) <TAB>  <TAB> self.insertHtml(text) <TAB> else: <TAB>  <TAB> QTextEdit.insertFromMimeData(self, source)","if text . startswith ( ""http://"" ) :",192
def drop_one(mask_to_drop): <TAB> for i in np.nonzero(mask_to_drop)[0]: <TAB>  <TAB> new_mask = np.copy(mask_to_drop) <TAB>  <TAB> new_mask[i] = 0 <MASK> yield new_mask,if sum ( new_mask ) > 0 :,78
"def convert_key_raw_str(self, needle, haystack): <TAB> num_levels = needle.split(""."") <TAB> if len(num_levels) == 0: <TAB>  <TAB> return False <TAB> current_pointer = haystack <TAB> for updated_key in num_levels: <MASK> current_pointer[updated_key] = { <TAB>  <TAB>  <TAB>  <TAB> ""raw_value"": str(current_pointer[updated_key]) <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB> return haystack <TAB>  <TAB> if updated_key in current_pointer: <TAB>  <TAB>  <TAB> current_pointer = current_pointer[updated_key] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return haystack",if updated_key == num_levels [ - 1 ] :,159
"def numpy_serialize_data(data): <TAB> """"""serialize_data"""""" <TAB> ret_data = copy.deepcopy(data) <TAB> if isinstance(ret_data, (dict, list)): <TAB>  <TAB> for key in index_iter(ret_data): <MASK> ret_data[key] = _np_serialized_data( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value=ret_data[key].tobytes(), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> shape=list(ret_data[key].shape), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> dtype=""%s"" % ret_data[key].dtype, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return ret_data","if isinstance ( ret_data [ key ] , np . ndarray ) :",158
"def instance_masks(self): <TAB> for sid in self._seg_ids: <TAB>  <TAB> sinfo = self._sinfo.get(sid) <TAB>  <TAB> if sinfo is None or not sinfo[""isthing""]: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> mask = (self._seg == sid).numpy().astype(np.bool) <MASK> yield mask, sinfo",if mask . sum ( ) > 0 :,95
"def test_integrationtest(self): <TAB> rng = iarandom.RNG(0) <TAB> for size in [20, 100]: <TAB>  <TAB> shape = (size, size, 3) <TAB>  <TAB> image = rng.integers(50, 150, size=shape) <TAB>  <TAB> image = image.astype(np.uint8) <TAB>  <TAB> aug = iaa.pillike.Equalize() <TAB>  <TAB> image_aug = aug(image=image) <MASK> channelwise_sums = np.sum(image_aug, axis=(0, 1)) <TAB>  <TAB>  <TAB> assert np.all(channelwise_sums > 0) <TAB>  <TAB> assert np.min(image_aug) < 50 <TAB>  <TAB> assert np.max(image_aug) > 150",if size > 1 :,168
"def _init_choices(self, choices): <TAB> # helper to convert from question format to internal format <TAB> self.choices = []  # list (key, name, value) <TAB> searching_first_choice = True <TAB> key = 1  # used for numeric keys <TAB> for i, c in enumerate(choices): <TAB>  <TAB> if isinstance(c, Separator): <TAB>  <TAB>  <TAB> self.choices.append(c) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if isinstance(c, basestring): <TAB>  <TAB>  <TAB>  <TAB> self.choices.append((key, c, c)) <TAB>  <TAB>  <TAB>  <TAB> key += 1 <MASK> self.pointer_index = i  # found the first choice <TAB>  <TAB>  <TAB>  <TAB> searching_first_choice = False",if searching_first_choice :,176
"def close(self): <TAB> if hasattr(self.socket, ""_sock""): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.socket._sock.close() <TAB>  <TAB> except socket.error: <TAB>  <TAB>  <TAB> info = sys.exc_info() <MASK> raise info[1] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB> self.socket.close()",if info [ 1 ] . args [ 0 ] != socket . EBADF :,105
"def find_open_ports(self, address, port): <TAB> result = 1 <TAB> try: <TAB>  <TAB> sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) <TAB>  <TAB> sock.settimeout(1) <TAB>  <TAB> result = sock.connect_ex((address, port)) <TAB>  <TAB> if result == 0: <TAB>  <TAB>  <TAB> sock.close() <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if self.verbose: <TAB>  <TAB>  <TAB>  <TAB> print(""[!] 445 not open on {}...."".format(address)) <TAB>  <TAB>  <TAB> return False <TAB> except: <MASK> print(""[!] 445 not open on {}...."".format(address)) <TAB>  <TAB> return False",if self . verbose ( ) :,166
"def get_match_count(self, vars={}): <TAB> range = None <TAB> for alternative in self.alternatives: <TAB>  <TAB> sub = alternative.get_match_count(vars) <MASK> range = list(sub) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if sub[0] < range[0]: <TAB>  <TAB>  <TAB>  <TAB> range[0] = sub[0] <TAB>  <TAB>  <TAB> if range[1] is None or sub[1] > range[1]: <TAB>  <TAB>  <TAB>  <TAB> range[1] = sub[1] <TAB> return range",if range is None :,131
"def expand_nested_tokens(tokens): <TAB> for token_name in tokens.keys(): <TAB>  <TAB> for current_token_name, current_token_value in tokens.items(): <MASK> if token_name == current_token_name: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise Exception(""Token '%s' cannot contain itself"" % token_name) <TAB>  <TAB>  <TAB>  <TAB> tokens[current_token_name] = current_token_value.replace( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> token_name, tokens[token_name] <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return tokens",if token_name in current_token_value :,142
"def get_inventory_delta(self, client, inventory, b): <TAB> inventories = client.list_bucket_inventory_configurations(Bucket=b[""Name""]) <TAB> found = None <TAB> for i in inventories.get(""InventoryConfigurationList"", []): <TAB>  <TAB> if i[""Id""] != inventory[""Id""]: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> found = True <TAB>  <TAB> for k, v in inventory.items(): <MASK> found = False <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if isinstance(v, list): <TAB>  <TAB>  <TAB>  <TAB> v.sort() <TAB>  <TAB>  <TAB>  <TAB> i[k].sort() <TAB>  <TAB>  <TAB> if i[k] != v: <TAB>  <TAB>  <TAB>  <TAB> found = False <TAB> return found",if k not in i :,174
"def platform_fix_filename(fname): <TAB> if platform.system() == ""Darwin"": <TAB>  <TAB> if fname.endswith("".so""): <TAB>  <TAB>  <TAB> return fname[:-2] + ""dylib"" <TAB>  <TAB> return fname.replace("".so."", "".dylib."") <TAB> elif platform.system() == ""Windows"": <TAB>  <TAB> if fname.endswith("".so""): <TAB>  <TAB>  <TAB> (p, f) = os.path.split(fname) <TAB>  <TAB>  <TAB> f = f[3:-2] + ""dll"" <TAB>  <TAB>  <TAB> return os.path.join(p, f) <MASK> return fname[:-1] + ""lib"" <TAB> return fname","if fname . endswith ( "".a"" ) :",154
"def _get_flavor_and_index(self, declaration): <TAB> for index, item in enumerate(declaration): <TAB>  <TAB> if item in self.flavors: <TAB>  <TAB>  <TAB> return item, index <TAB>  <TAB> if item in self.normalized_flavors: <TAB>  <TAB>  <TAB> correct = self.normalized_flavors[item] <TAB>  <TAB>  <TAB> self._report_deprecated_flavor_syntax(item, correct) <TAB>  <TAB>  <TAB> return correct, index <MASK> return item.upper(), index <TAB> return ""IN"", len(declaration)","if normalize ( item ) . startswith ( ""in"" ) :",136
"def test_ESPnetDataset_feats_scp( <TAB> feats_scp,): <TAB> dataset = IterableESPnetDataset( <TAB>  <TAB> path_name_type_list=[(feats_scp, ""data2"", ""kaldi_ark"")], <TAB>  <TAB> preprocess=preprocess, <TAB> ) <TAB> for key, data in dataset: <TAB>  <TAB> if key == ""a"": <TAB>  <TAB>  <TAB> assert data[""data2""].shape == ( <TAB>  <TAB>  <TAB>  <TAB> 100, <TAB>  <TAB>  <TAB>  <TAB> 80, <TAB>  <TAB>  <TAB> ) <MASK> assert data[""data2""].shape == ( <TAB>  <TAB>  <TAB>  <TAB> 150, <TAB>  <TAB>  <TAB>  <TAB> 80, <TAB>  <TAB>  <TAB> )","if key == ""b"" :",157
"def update_merge(base, override): <TAB> if not isinstance(base, dict) or not isinstance(override, dict): <TAB>  <TAB> return <TAB> for k, v in override.items(): <TAB>  <TAB> if k in base and type(base[k]) != type(v): <TAB>  <TAB>  <TAB> base[k] = v <TAB>  <TAB> else: <MASK> update_merge(base[k], v) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> base[k] = v <TAB> return","if k in base and isinstance ( base [ k ] , dict ) :",129
"def some_funky_spot(ilist, bitpos): <TAB> """"""Return true if some pattern has a nonterminal or operand decider"""""" <TAB> for i in ilist: <TAB>  <TAB> if bitpos < len(i.ipattern.bits): <TAB>  <TAB>  <TAB> if i.ipattern.bits[bitpos].is_nonterminal(): <TAB>  <TAB>  <TAB>  <TAB> return True <MASK> return True <TAB> return False",if i . ipattern . bits [ bitpos ] . is_operand_decider ( ) :,111
"def set_kwargs(parsed_args): <TAB> kwargs = {} <TAB> for key, arg in parsed_args.items(): <TAB>  <TAB> if arg is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> k = None <MASK> k = remove_brackets(key[2:]) <TAB>  <TAB> elif remove_brackets(key) not in kwargs: <TAB>  <TAB>  <TAB> k = remove_brackets(key) <TAB>  <TAB> kwargs[k] = normalize_value(arg, k) <TAB> return kwargs","if key . startswith ( ""--"" ) and remove_brackets ( key [ 2 : ] ) not in kwargs :",128
"def split_leading_indent(line, max_indents=None): <TAB> """"""Split line into leading indent and main."""""" <TAB> indent = """" <TAB> while ( <TAB>  <TAB> (max_indents is None or max_indents > 0) <TAB>  <TAB> and line.startswith((openindent, closeindent)) <TAB> ) or line.lstrip() != line: <MASK> max_indents -= 1 <TAB>  <TAB> indent += line[0] <TAB>  <TAB> line = line[1:] <TAB> return indent, line","if max_indents is not None and line . startswith ( ( openindent , closeindent ) ) :",136
"def srcdir_duplicate(self, name): <TAB> for dir in self.srcdir_list(): <TAB>  <TAB> if self.is_under(dir): <TAB>  <TAB>  <TAB> # We shouldn't source from something in the build path; <TAB>  <TAB>  <TAB> # variant_dir is probably under src_dir, in which case <TAB>  <TAB>  <TAB> # we are reflecting. <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if dir.entry_exists_on_disk(name): <TAB>  <TAB>  <TAB> srcnode = dir.Entry(name).disambiguate() <MASK> node = self.Entry(name).disambiguate() <TAB>  <TAB>  <TAB>  <TAB> node.do_duplicate(srcnode) <TAB>  <TAB>  <TAB>  <TAB> return node <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return srcnode <TAB> return None",if self . duplicate :,178
"def _okButtonClickedSlot(self): <TAB> missing = [ <TAB>  <TAB> v for v in self._variables if v.get(""name"") and v.get(""value"", """").strip() == """" <TAB> ] <TAB> if len(missing) > 0: <TAB>  <TAB> reply = QtWidgets.QMessageBox.warning( <TAB>  <TAB>  <TAB> self, <TAB>  <TAB>  <TAB> ""Missing values"", <TAB>  <TAB>  <TAB> ""Are you sure you want to continue without providing missing values?"", <TAB>  <TAB>  <TAB> QtWidgets.QMessageBox.Yes, <TAB>  <TAB>  <TAB> QtWidgets.QMessageBox.No, <TAB>  <TAB> ) <MASK> return <TAB> self._project.setVariables(self._variables) <TAB> self._project.update() <TAB> self.accept()",if reply == QtWidgets . QMessageBox . No :,181
"def test_introspection4(self): <TAB> # the SimpleXMLRPCServer doesn't support signatures, but <TAB> # at least check that we can try making the call <TAB> try: <TAB>  <TAB> p = xmlrpclib.ServerProxy(URL) <TAB>  <TAB> divsig = p.system.methodSignature(""div"") <TAB>  <TAB> self.assertEqual(divsig, ""signatures not supported"") <TAB> except (xmlrpclib.ProtocolError, OSError) as e: <TAB>  <TAB> # ignore failures due to non-blocking socket 'unavailable' errors <MASK> # protocol error; provide additional information in test output <TAB>  <TAB>  <TAB> self.fail(""%s\n%s"" % (e, getattr(e, ""headers"", """")))",if not is_unavailable_exception ( e ) :,169
"def worst_asns(address): <TAB> if not address: <TAB>  <TAB> return None <TAB> try: <TAB>  <TAB> _ = addr_to_int(address) <TAB>  <TAB> for prefix, mask, name in WORST_ASNS.get(address.split(""."")[0], {}): <MASK> return name <TAB> except (IndexError, ValueError): <TAB>  <TAB> pass <TAB> return None",if _ & mask == prefix :,97
"def formatDoc(self, flat_xml): <TAB> rlst = [] <TAB> for j in self.doc: <MASK> if flat_xml: <TAB>  <TAB>  <TAB>  <TAB> rlst.append(self.flattenTag(j)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> rlst.append(self.formatTag(j)) <TAB> result = b"""".join(rlst) <TAB> if self.debug: <TAB>  <TAB> print(result) <TAB> return result",if len ( j ) > 0 :,110
"def write(self, x, level=""info"", donot_print=False, log_all=False): <TAB> if self.logger is None: <TAB>  <TAB> return <TAB> if log_all is False and not self._is_main_process: <TAB>  <TAB> return <TAB> # if it should not log then just print it <TAB> if self.should_log: <TAB>  <TAB> if hasattr(self.logger, level): <MASK> getattr(self._file_only_logger, level)(str(x)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> getattr(self.logger, level)(str(x)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.logger.error(""Unknown log level type: %s"" % level) <TAB> else: <TAB>  <TAB> print(str(x) + ""\n"")",if donot_print :,190
"def ADD_NEW_KWARG(*args, **kwargs): <TAB> new_kw = [kw for kw in Keywords if kw not in kwargs[""kwargs""]] <TAB> if len(new_kw) > 0: <MASK> new_kw = ""dur"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_kw = choose(new_kw) <TAB>  <TAB> kwargs[""kwargs""][new_kw] = GEN_CHOOSE_VALUE(new_kw) <TAB> return kwargs","if ""dur"" not in new_kw and random ( ) > 0.25 :",124
"def __init__(self, note_list, db): <TAB> Gtk.ListStore.__init__(self, str, str, bool, str) <TAB> self.db = db <TAB> for handle in note_list: <TAB>  <TAB> note = self.db.get_note_from_handle(handle) <TAB>  <TAB> text = note.get()[:85].replace(""\n"", "" "") <MASK> text = text[:80] + ""..."" <TAB>  <TAB> self.append( <TAB>  <TAB>  <TAB> row=[ <TAB>  <TAB>  <TAB>  <TAB> str(note.get_type()), <TAB>  <TAB>  <TAB>  <TAB> text, <TAB>  <TAB>  <TAB>  <TAB> note.get_privacy(), <TAB>  <TAB>  <TAB>  <TAB> handle, <TAB>  <TAB>  <TAB> ] <TAB>  <TAB> )",if len ( text ) > 80 :,166
"def suspend(self): <TAB> """"""Suspends serving for this server, quitting all running instances."""""" <TAB> with self._instances_change_lock: <MASK> raise request_info.ServerAlreadyStoppedError() <TAB>  <TAB> self._suspended = True <TAB>  <TAB> with self._condition: <TAB>  <TAB>  <TAB> instances_to_stop = zip(self._instances, self._wsgi_servers) <TAB>  <TAB>  <TAB> for wsgi_servr in self._wsgi_servers: <TAB>  <TAB>  <TAB>  <TAB> wsgi_servr.set_error(404) <TAB> for inst, wsgi_servr in instances_to_stop: <TAB>  <TAB> self._async_suspend_instance(inst, wsgi_servr.port)",if self . _suspended :,168
def fsm(): <TAB> if tx_rst == 0: <TAB>  <TAB> tx_bit.next = 1 <TAB>  <TAB> index.next = 0 <TAB>  <TAB> state.next = st.IDLE <TAB> else: <TAB>  <TAB> if state == st.IDLE: <TAB>  <TAB>  <TAB> tx_bit.next = 1 <MASK> # a pulse <TAB>  <TAB>  <TAB>  <TAB> state.next = st.START <TAB>  <TAB> elif state == st.START: <TAB>  <TAB>  <TAB> tx_bit.next = 0 <TAB>  <TAB>  <TAB> index.next = 7 <TAB>  <TAB>  <TAB> state.next = st.DATA <TAB>  <TAB> elif state == st.DATA: <TAB>  <TAB>  <TAB> tx_bit.next = tx_byte[index] <TAB>  <TAB>  <TAB> if index == 0: <TAB>  <TAB>  <TAB>  <TAB> state.next = st.IDLE <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> index.next = index - 1,if tx_valid :,198
"def _visit(self, expr): <TAB> node = expr.op() <TAB> for arg in node.flat_args(): <MASK> self._visit_table(arg) <TAB>  <TAB> elif isinstance(arg, ir.BooleanColumn): <TAB>  <TAB>  <TAB> for sub_expr in L.flatten_predicate(arg): <TAB>  <TAB>  <TAB>  <TAB> self.predicates.append(sub_expr) <TAB>  <TAB>  <TAB>  <TAB> self._visit(sub_expr) <TAB>  <TAB> elif isinstance(arg, ir.Expr): <TAB>  <TAB>  <TAB> self._visit(arg) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> continue","if isinstance ( arg , ir . TableExpr ) :",143
def expire_tags(self): <TAB> for tag in self.tags: <TAB>  <TAB> if tag.expiration: <TAB>  <TAB>  <TAB> if (tag.last_seen + tag.expiration) < datetime.utcnow() and tag.fresh: <TAB>  <TAB>  <TAB>  <TAB> tag.fresh = False <TAB>  <TAB>  <TAB>  <TAB> self.save() <MASK> tag.fresh = True <TAB>  <TAB>  <TAB>  <TAB> self.save() <TAB> return self,elif ( tag . last_seen + tag . expiration ) > datetime . utcnow ( ) and not tag . fresh :,120
"def poll_thread(): <TAB> time.sleep(0.5) <TAB> if web_process.wait() and web_process_state: <TAB>  <TAB> time.sleep(0.25) <MASK> stdout, stderr = web_process._communicate(None) <TAB>  <TAB>  <TAB> logger.error( <TAB>  <TAB>  <TAB>  <TAB> ""Setup web server process exited unexpectedly"", <TAB>  <TAB>  <TAB>  <TAB> ""setup"", <TAB>  <TAB>  <TAB>  <TAB> stdout=stdout, <TAB>  <TAB>  <TAB>  <TAB> stderr=stderr, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> set_global_interrupt() <TAB> else: <TAB>  <TAB> server.interrupt = ServerStop(""Stop server"")",if not check_global_interrupt ( ) :,148
"def on_button_clicked(b): <TAB> with ldf.output: <MASK> self._toggle_pandas_display = not self._toggle_pandas_display <TAB>  <TAB> clear_output() <TAB>  <TAB> if self._toggle_pandas_display: <TAB>  <TAB>  <TAB> print(series_repr) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # b.layout.display = ""none"" <TAB>  <TAB>  <TAB> display(ldf._widget)",if b :,103
"def get_color_name(value): <TAB> """"""Return color name depending on value type"""""" <TAB> if not is_known_type(value): <TAB>  <TAB> return CUSTOM_TYPE_COLOR <TAB> for typ, name in list(COLORS.items()): <MASK> return name <TAB> else: <TAB>  <TAB> np_dtype = get_numpy_dtype(value) <TAB>  <TAB> if np_dtype is None or not hasattr(value, ""size""): <TAB>  <TAB>  <TAB> return UNSUPPORTED_COLOR <TAB>  <TAB> elif value.size == 1: <TAB>  <TAB>  <TAB> return SCALAR_COLOR <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ARRAY_COLOR","if isinstance ( value , typ ) :",151
"def s2n(self, offset, length, signed=0, debug=False): <TAB> slice = self.data[offset : offset + length] <TAB> val = self.s2nfunc(slice) <TAB> # Sign extension ? <TAB> if signed: <TAB>  <TAB> msb = 1 << (8 * length - 1) <MASK> val = val - (msb << 1) <TAB> if debug: <TAB>  <TAB> logging.debug(self.endian) <TAB>  <TAB> logging.debug( <TAB>  <TAB>  <TAB> ""Slice for offset %d length %d: %r and value: %d"", <TAB>  <TAB>  <TAB> offset, <TAB>  <TAB>  <TAB> length, <TAB>  <TAB>  <TAB> slice, <TAB>  <TAB>  <TAB> val, <TAB>  <TAB> ) <TAB> return val",if val & msb :,173
"def write_functions(self, f, write, written, extensions): <TAB> self.write_prototype_pre(f) <TAB> for ext in extensions: <TAB>  <TAB> for func in ext.functions: <MASK> self.write_function_prototype(f, func) <TAB>  <TAB>  <TAB>  <TAB> write.add(func) <TAB>  <TAB>  <TAB> written.add(func.proto.name) <TAB> self.write_prototype_post(f) <TAB> self.write_function_pre(f) <TAB> for func in write: <TAB>  <TAB> self.write_function(f, func) <TAB> self.write_function_post(f)",if not func . proto . name in written :,160
"def list_analyses(self): <TAB> print(""ID\t\t\t\t| URL\t\t\t\t| Analysis datetime\n"") <TAB> for analysis in self.analyses.find(): <TAB>  <TAB> urls = self.urls.find(_id=analysis[""url_id""]) <MASK> continue <TAB>  <TAB> url = urls[0][""url""] <TAB>  <TAB> print(""%s\t| %s\t| %s"" % (analysis[""_id""], url, analysis[""timestamp""]))",if not urls :,121
def _isexecutable(cmd): <TAB> if os.path.isfile(cmd): <TAB>  <TAB> mode = os.stat(cmd)[stat.ST_MODE] <MASK> return True <TAB> return False,if mode & stat . S_IXUSR or mode & stat . S_IXGRP or mode & stat . S_IXOTH :,78
"def _retrieve_datasets(self) -> List[DatasetRef]: <TAB> datasets = [] <TAB> for page in self._page_dataset_list_results(): <MASK> continue <TAB>  <TAB> for dataset in page[""datasets""]: <TAB>  <TAB>  <TAB> dataset_ref = dataset[""datasetReference""] <TAB>  <TAB>  <TAB> ref = DatasetRef(**dataset_ref) <TAB>  <TAB>  <TAB> datasets.append(ref) <TAB> return datasets","if ""datasets"" not in page :",101
"def tearDownClass(cls): <TAB> try: <TAB>  <TAB> conns = net_connections() <TAB>  <TAB> pid = [ <TAB>  <TAB>  <TAB> x.pid <TAB>  <TAB>  <TAB> for x in conns <TAB>  <TAB>  <TAB> if x.status == ""LISTEN"" and x.laddr[1] == 47334 and x.pid is not None <TAB>  <TAB> ] <MASK> os.kill(pid[0], 9) <TAB> except Exception: <TAB>  <TAB> pass",if len ( pid ) > 0 :,109
"def read_distance(reader, root): <TAB> """"""Read distance value."""""" <TAB> node = root <TAB> while True: <TAB>  <TAB> code = reader.read(1) <TAB>  <TAB> child = node.children[code] <MASK> dist_code = child.char <TAB>  <TAB>  <TAB> if dist_code < 3: <TAB>  <TAB>  <TAB>  <TAB> distance = dist_code + 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> nb = (dist_code // 2) - 1 <TAB>  <TAB>  <TAB>  <TAB> extra = reader.read(nb) <TAB>  <TAB>  <TAB>  <TAB> half, delta = divmod(dist_code, 2) <TAB>  <TAB>  <TAB>  <TAB> distance = 1 + (2 ** half) + delta * (2 ** (half - 1)) + extra <TAB>  <TAB>  <TAB> return distance <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> node = child",if child . is_leaf :,190
def _parse(self): <TAB> self._parse_target_clause(self._operand_factory_class()) <TAB> while self._binop_factory_class().is_possible_start(self.get_next_token()): <TAB>  <TAB> self._parse_target_clause(self._binop_factory_class()) <MASK> self._parse_target_clause(self._operand_factory_class()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.raise_unexpected_token() <TAB> return self._create_node(),if self . _operand_factory_class ( ) . is_possible_start ( self . get_next_token ( ) ) :,143
"def generate(self, sigmaparser): <TAB> translation = super().generate(sigmaparser) <TAB> if translation: <TAB>  <TAB> index = sigmaparser.get_logsource().index <MASK> index = [ <TAB>  <TAB>  <TAB>  <TAB> ""apm-*-transaction"", <TAB>  <TAB>  <TAB>  <TAB> ""auditbeat-*"", <TAB>  <TAB>  <TAB>  <TAB> ""endgame-*"", <TAB>  <TAB>  <TAB>  <TAB> ""filebeat-*"", <TAB>  <TAB>  <TAB>  <TAB> ""packetbeat-*"", <TAB>  <TAB>  <TAB>  <TAB> ""winlogbeat-*"", <TAB>  <TAB>  <TAB> ] <TAB>  <TAB> configs = sigmaparser.parsedyaml <TAB>  <TAB> configs.update({""translation"": translation}) <TAB>  <TAB> rule = self.create_rule(configs, index) <TAB>  <TAB> return rule",if len ( index ) == 0 :,170
"def soname_and_full_path(self): <TAB> """"""Return soname and full path of the shared library, if any"""""" <TAB> if ""soname_and_full_path"" not in self.data: <TAB>  <TAB> self.data[""soname_and_full_path""] = None <TAB>  <TAB> if self.attr[""has_dynamic""]: <TAB>  <TAB>  <TAB> so_path = self._library_full_path(""so"") <TAB>  <TAB>  <TAB> soname = self._soname_of(so_path) <MASK> self.data[""soname_and_full_path""] = (soname, so_path) <TAB> return self.data[""soname_and_full_path""]",if soname :,166
"def _invoke_client_enum(self, client, enum_op, params, path): <TAB> if client.supports_pagination(enum_op): <TAB>  <TAB> results = [] <TAB>  <TAB> for page in client.execute_paged_query(enum_op, params): <TAB>  <TAB>  <TAB> page_items = jmespath.search(path, page) <MASK> results.extend(page_items) <TAB>  <TAB> return results <TAB> else: <TAB>  <TAB> return jmespath.search( <TAB>  <TAB>  <TAB> path, client.execute_query(enum_op, verb_arguments=params) <TAB>  <TAB> )",if page_items :,142
"def matches(self, category, product, service): <TAB> """"""Match log source definition against given criteria, None = ignore"""""" <TAB> searched = 0 <TAB> for searchval, selfval in zip( <TAB>  <TAB> (category, product, service), (self.category, self.product, self.service) <TAB> ): <MASK> return False <TAB>  <TAB> if selfval != None: <TAB>  <TAB>  <TAB> searched += 1 <TAB>  <TAB>  <TAB> if searchval != selfval: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> if searched: <TAB>  <TAB> return True",if searchval == None and selfval != None :,133
"def __init__(self, config, logger=None, reporter=None): <TAB> super(YOLOv3Estimator, self).__init__(config, logger, reporter) <TAB> self.last_train = None <TAB> if self._cfg.yolo3.amp: <TAB>  <TAB> amp.init() <TAB> if self._cfg.horovod: <MASK> raise SystemExit( <TAB>  <TAB>  <TAB>  <TAB> ""Horovod not found, please check if you installed it correctly."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> hvd.init()",if hvd is None :,131
"def print_result_exception(result): <TAB> ex = result.exception <TAB> if ex: <TAB>  <TAB> # This only works on Python 3 <MASK> print( <TAB>  <TAB>  <TAB>  <TAB> """".join( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> traceback.format_exception( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> etype=type(ex), value=ex, tb=ex.__traceback__ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(ex)","if hasattr ( ex , ""__traceback__"" ) :",123
"def setupEnvironment(self, cmd): <TAB> ShellCommand.setupEnvironment(self, cmd) <TAB> if self.testpath is not None: <TAB>  <TAB> e = cmd.args[""env""] <TAB>  <TAB> if e is None: <TAB>  <TAB>  <TAB> cmd.args[""env""] = {""PYTHONPATH"": self.testpath} <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # this bit produces a list, which can be used <TAB>  <TAB>  <TAB> # by buildbot_worker.runprocess.RunProcess <TAB>  <TAB>  <TAB> ppath = e.get(""PYTHONPATH"", self.testpath) <MASK> ppath = [ppath] <TAB>  <TAB>  <TAB> if self.testpath not in ppath: <TAB>  <TAB>  <TAB>  <TAB> ppath.insert(0, self.testpath) <TAB>  <TAB>  <TAB> e[""PYTHONPATH""] = ppath","if isinstance ( ppath , str ) :",185
"def _iter_mountpoints(cls): <TAB> check_output = cls(None).check_output <TAB> for line in check_output(""cat /proc/mounts"").splitlines(): <TAB>  <TAB> splitted = line.split() <TAB>  <TAB> # ignore rootfs <TAB>  <TAB> # https://www.kernel.org/doc/Documentation/filesystems/ramfs-rootfs-initramfs.txt <TAB>  <TAB> # suggests that most OS mount the filesystem over it, leaving <TAB>  <TAB> # rootfs would result in ambiguity when resolving a mountpoint. <MASK> continue <TAB>  <TAB> yield { <TAB>  <TAB>  <TAB> ""path"": splitted[1], <TAB>  <TAB>  <TAB> ""device"": splitted[0], <TAB>  <TAB>  <TAB> ""filesystem"": splitted[2], <TAB>  <TAB>  <TAB> ""options"": splitted[3].split("",""), <TAB>  <TAB> }","if splitted [ 0 ] == ""rootfs"" :",190
"def __query_node(vm_): <TAB> data = show_instance(vm_[""name""], conn=conn, call=""action"") <TAB> if ""wait_for_metadata"" in vm_: <TAB>  <TAB> for key, value in six.iteritems(vm_.get(""wait_for_metadata"", {})): <TAB>  <TAB>  <TAB> log.debug(""Waiting for metadata: %s=%s"", key, value) <MASK> log.debug( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Metadata is not ready: %s=%s"", key, data[""metadata""].get(key) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return preferred_ip(vm_, data[ssh_interface(vm_)])","if data [ ""metadata"" ] . get ( key , None ) != value :",172
def offsetChanged(self): <TAB> if self.panel: <TAB>  <TAB> if not self.panel.useOffsetInput: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> box = self.selectionBox() <MASK> return <TAB>  <TAB> delta = self.panel.offsetInput.coords <TAB>  <TAB> self.destPoint = box.origin + delta,if box is None :,81
"def build_change_log(old_report, new_report): <TAB> change_log = ChangeLog(old_report, new_report) <TAB> result = diff(old_report, new_report) <TAB> for diff_line in result: <TAB>  <TAB> # Operations <MASK> change_log.operation(diff_line) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> change_log.models(diff_line) <TAB> return change_log","if diff_line [ 0 ] [ 0 ] == ""operations"" :",117
"def baidu_download_lyric(sid, file_name, output_dir): <TAB> if common.dry_run: <TAB>  <TAB> return <TAB> html = get_html(""http://music.baidu.com/song/"" + sid) <TAB> href = r1( <TAB>  <TAB> r'<a class=""down-lrc-btn"" data-lyricdata=\'{ ""href"":""(.+?)"" }\' href=""#"">', html <TAB> ) <TAB> if href: <TAB>  <TAB> lrc = get_html(""http://music.baidu.com"" + href) <MASK> with open( <TAB>  <TAB>  <TAB>  <TAB> output_dir + ""/"" + file_name.replace(""/"", ""-"") + "".lrc"", ""w"" <TAB>  <TAB>  <TAB> ) as x: <TAB>  <TAB>  <TAB>  <TAB> x.write(lrc)",if len ( lrc ) > 0 :,189
"def _ravel_and_check_weights(a, weights): <TAB> """"""Check a and weights have matching shapes, and ravel both"""""" <TAB> a = astensor(a) <TAB> # Ensure that the array is a ""subtractable"" dtype <TAB> if a.dtype == np.bool_: <TAB>  <TAB> warnings.warn( <TAB>  <TAB>  <TAB> f""Converting input from {a.dtype} to {np.uint8} for compatibility."", <TAB>  <TAB>  <TAB> RuntimeWarning, <TAB>  <TAB>  <TAB> stacklevel=3, <TAB>  <TAB> ) <TAB>  <TAB> a = a.astype(np.uint8) <TAB> if weights is not None: <TAB>  <TAB> weights = astensor(weights) <MASK> raise ValueError(""weights should have the same shape as a."") <TAB>  <TAB> weights = weights.ravel() <TAB> a = a.ravel() <TAB> return a, weights",if weights . shape != a . shape :,195
"def test_change_view(self): <TAB> for i in self.pks: <TAB>  <TAB> url = reverse(""admin:admin_views_emptymodel_change"", args=(i,)) <TAB>  <TAB> response = self.client.get(url, follow=True) <MASK> self.assertEqual(response.status_code, 200) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertRedirects(response, reverse(""admin:index"")) <TAB>  <TAB>  <TAB> self.assertEqual( <TAB>  <TAB>  <TAB>  <TAB> [m.message for m in response.context[""messages""]], <TAB>  <TAB>  <TAB>  <TAB> [""""""empty model with ID ""1"" doesn't exist. Perhaps it was deleted?""""""], <TAB>  <TAB>  <TAB> )",if i > 1 :,159
"def feed(self, aBuf): <TAB> for c in aBuf: <TAB>  <TAB> codingState = self._mCodingSM.next_state(c) <TAB>  <TAB> if codingState == eError: <TAB>  <TAB>  <TAB> self._mState = constants.eNotMe <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif codingState == eItsMe: <TAB>  <TAB>  <TAB> self._mState = constants.eFoundIt <TAB>  <TAB>  <TAB> break <MASK> if self._mCodingSM.get_current_charlen() >= 2: <TAB>  <TAB>  <TAB>  <TAB> self._mNumOfMBChar += 1 <TAB> if self.get_state() == constants.eDetecting: <TAB>  <TAB> if self.get_confidence() > constants.SHORTCUT_THRESHOLD: <TAB>  <TAB>  <TAB> self._mState = constants.eFoundIt <TAB> return self.get_state()",elif codingState == eStart :,200
"def link_elastic_ips_callback2( <TAB> ec2_config, current_config, path, current_path, instance_id, callback_args): <TAB> if instance_id == callback_args[""instance_id""]: <MASK> current_config[""PublicIpAddress""] = callback_args[""elastic_ip""] <TAB>  <TAB> elif current_config[""PublicIpAddress""] != callback_args[""elastic_ip""]: <TAB>  <TAB>  <TAB> printInfo( <TAB>  <TAB>  <TAB>  <TAB> ""Warning: public IP address exists (%s) for an instance associated with an elastic IP (%s)"" <TAB>  <TAB>  <TAB>  <TAB> % (current_config[""PublicIpAddress""], callback_args[""elastic_ip""]) <TAB>  <TAB>  <TAB> )","if not ""PublicIpAddress"" in current_config :",161
"def validate(self): <TAB> pattern = Template.pattern <TAB> fields = set() <TAB> for m in pattern.finditer(self._fmt): <TAB>  <TAB> d = m.groupdict() <TAB>  <TAB> if d[""named""]: <TAB>  <TAB>  <TAB> fields.add(d[""named""]) <TAB>  <TAB> elif d[""braced""]: <TAB>  <TAB>  <TAB> fields.add(d[""braced""]) <MASK> raise ValueError(""invalid format: bare '$' not allowed"") <TAB> if not fields: <TAB>  <TAB> raise ValueError(""invalid format: no fields"")","elif m . group ( 0 ) == ""$"" :",130
"def check_hardware(): <TAB> print(""----------Hardware Info----------"") <TAB> print(""machine <TAB>   :"", platform.machine()) <TAB> print(""processor <TAB> :"", platform.processor()) <TAB> if sys.platform.startswith(""darwin""): <TAB>  <TAB> pipe = subprocess.Popen((""sysctl"", ""-a""), stdout=subprocess.PIPE) <TAB>  <TAB> output = pipe.communicate()[0] <TAB>  <TAB> for line in output.split(b""\n""): <MASK> print(line.strip()) <TAB> elif sys.platform.startswith(""linux""): <TAB>  <TAB> subprocess.call([""lscpu""]) <TAB> elif sys.platform.startswith(""win32""): <TAB>  <TAB> subprocess.call([""wmic"", ""cpu"", ""get"", ""name""])","if b""brand_string"" in line or b""features"" in line :",188
def update_external_status(self) -> bool: <TAB> external = await self.config.use_external_lavalink() <TAB> if not external: <MASK> await self.player_manager.shutdown() <TAB>  <TAB> await self.config.use_external_lavalink.set(True) <TAB>  <TAB> return True <TAB> else: <TAB>  <TAB> return False,if self . player_manager is not None :,96
"def check_git_status(): <TAB> # Suggest 'git pull' if repo is out of date <TAB> if platform.system() in [""Linux"", ""Darwin""] and not os.path.isfile(""/.dockerenv""): <TAB>  <TAB> s = subprocess.check_output( <TAB>  <TAB>  <TAB> ""if [ -d .git ]; then git fetch && git status -uno; fi"", shell=True <TAB>  <TAB> ).decode(""utf-8"") <MASK> print(s[s.find(""Your branch is behind"") : s.find(""\n\n"")] + ""\n"")","if ""Your branch is behind"" in s :",142
"def add(self, item): <TAB> for option in self.options: <TAB>  <TAB> opt_value = option.get(""value"") <MASK> opt_value = option.text or """" <TAB>  <TAB> if opt_value: <TAB>  <TAB>  <TAB> opt_value = opt_value.strip() <TAB>  <TAB> if opt_value == item: <TAB>  <TAB>  <TAB> option.set(""selected"", """") <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> raise ValueError(""There is no option with the value %r"" % item)",if opt_value is None :,124
"def transformed_bounds(self): <TAB> if self.transform_ == ""normalize"": <TAB>  <TAB> return 0.0, 1.0 <TAB> else: <MASK> return self.low, self.high <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return np.log10(self.low), np.log10(self.high)","if self . prior == ""uniform"" :",85
"def raw_input(self, prompt=None): <TAB> ddbg(""debugserver: raw_input prompt = %r"" % prompt) <TAB> if prompt: <TAB>  <TAB> self.write(prompt) <TAB> buf = """" <TAB> compstate = 0 <TAB> while True: <TAB>  <TAB> data = self.server.socketio.read(1) <TAB>  <TAB> ddbg(""raw_input: char=%r"" % data) <TAB>  <TAB> if data == LF or data == ""\006"": <TAB>  <TAB>  <TAB> buf = self.parse_telnet(buf + data) <TAB>  <TAB>  <TAB> if buf != """": <TAB>  <TAB>  <TAB>  <TAB> return buf <MASK> # ^D <TAB>  <TAB>  <TAB> raise EOFError <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> buf += data","elif data == ""\004"" or data == """" :",174
"def uninstall(package: str, ostream: IO = None, estream: IO = None) -> bool: <TAB> """"""Uninstall the python package."""""" <TAB> with typein(""y""): <TAB>  <TAB> # type in 'y' to confirm the uninstall operation <TAB>  <TAB> cmd = ""pip uninstall {}"".format(package) <TAB>  <TAB> result, content = subprocess.getstatusoutput(cmd) <MASK> estream.write(content) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ostream.write(content) <TAB> return result == 0",if result :,123
"def __call__(self, value): <TAB> if self.splitter is not None and isinstance(value, str): <TAB>  <TAB> values = self.splitter.findall(value) <TAB> else: <MASK> values = [value] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> values = value <TAB>  <TAB> values = [val for val in values if str(val).strip()] <TAB> nvals = [] <TAB> for val in values: <TAB>  <TAB> v = val <TAB>  <TAB> for child in self.children: <TAB>  <TAB>  <TAB> v, e = child(v) <TAB>  <TAB>  <TAB> if e: <TAB>  <TAB>  <TAB>  <TAB> return val, e <TAB>  <TAB> nvals.append(v) <TAB> values = nvals <TAB> return values, None","if not isinstance ( value , list ) :",171
"def _defaultdict_pprint(obj, p, cycle): <TAB> name = obj.__class__.__name__ <TAB> with p.group(len(name) + 1, name + ""("", "")""): <MASK> p.text(""..."") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> p.pretty(obj.default_factory) <TAB>  <TAB>  <TAB> p.text("","") <TAB>  <TAB>  <TAB> p.breakable() <TAB>  <TAB>  <TAB> p.pretty(dict(obj))",if cycle :,105
"def validate(self): <TAB> if self.stream.readBytes(0, 2) != ""\xFF\xD8"": <TAB>  <TAB> return ""Invalid file signature"" <TAB> try: <TAB>  <TAB> for index, field in enumerate(self): <TAB>  <TAB>  <TAB> chunk_type = field[""type""].value <MASK> return ""Unknown chunk type: 0x%02X (chunk #%s)"" % (chunk_type, index) <TAB>  <TAB>  <TAB> if index == 2: <TAB>  <TAB>  <TAB>  <TAB> # Only check 3 fields <TAB>  <TAB>  <TAB>  <TAB> break <TAB> except HachoirError: <TAB>  <TAB> return ""Unable to parse at least three chunks"" <TAB> return True",if chunk_type not in JpegChunk . TAG_INFO :,163
"def reverse_url(self, name, *args): <TAB> if name in self.named_rules: <TAB>  <TAB> return self.named_rules[name].matcher.reverse(*args) <TAB> for rule in self.rules: <MASK> reversed_url = rule.target.reverse_url(name, *args) <TAB>  <TAB>  <TAB> if reversed_url is not None: <TAB>  <TAB>  <TAB>  <TAB> return reversed_url <TAB> return None","if isinstance ( rule . target , ReversibleRouter ) :",112
"def scan_command_print(state): <TAB> params = { <TAB>  <TAB> ""count"": """", <TAB>  <TAB> ""flags"": [], <TAB> } <TAB> while True: <TAB>  <TAB> c = state.consume() <TAB>  <TAB> state.skip("" "") <TAB>  <TAB> state.ignore() <MASK> return None, [TokenCommandPrint(params), TokenEof()] <TAB>  <TAB> if c.isdigit(): <TAB>  <TAB>  <TAB> state.match(r""\d*"") <TAB>  <TAB>  <TAB> params[""count""] = state.emit() <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> m = state.expect_match(r""[l#p]+"") <TAB>  <TAB> params[""flags""] = list(m.group(0)) <TAB>  <TAB> state.ignore() <TAB>  <TAB> state.expect(EOF) <TAB>  <TAB> break <TAB> return None, [TokenCommandPrint(params), TokenEof()]",if c == EOF :,194
"def quote_str(string): <TAB> new_string = """" <TAB> string_enumerator = enumerate(string) <TAB> for index, char in string_enumerator: <TAB>  <TAB> if char == ""\\"": <TAB>  <TAB>  <TAB> index, char = next(string_enumerator) <TAB>  <TAB>  <TAB> if char == ""n"": <TAB>  <TAB>  <TAB>  <TAB> char = ""\n"" <MASK> char = ""\t"" <TAB>  <TAB>  <TAB> elif char == ""r"": <TAB>  <TAB>  <TAB>  <TAB> char = ""\r"" <TAB>  <TAB>  <TAB> elif char in {""\\"", ""'"", '""'}: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> char = ""\\"" + char <TAB>  <TAB> new_string = new_string + char <TAB> return new_string","elif char == ""t"" :",176
"def process_saves(self, uowcommit, states): <TAB> for state in states: <TAB>  <TAB> history = uowcommit.get_attribute_history( <TAB>  <TAB>  <TAB> state, self.key, attributes.PASSIVE_NO_INITIALIZE <TAB>  <TAB> ) <TAB>  <TAB> if history: <TAB>  <TAB>  <TAB> if history.added: <TAB>  <TAB>  <TAB>  <TAB> for child in history.added: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._synchronize(state, child, None, False, uowcommit, ""add"") <MASK> self._post_update(state, uowcommit, history.sum())",if self . post_update :,144
"def __new__(cls, string): <TAB> specifiers = (specifier.strip() for specifier in string.split("","")) <TAB> kwargs = {} <TAB> for specifier in specifiers: <TAB>  <TAB> match = re.match(r""^(\d+)\s*(\w+)$"", specifier) <TAB>  <TAB> if not match: <TAB>  <TAB>  <TAB> raise ValueError(""Invalid delta specifier: %r"" % (specifier,)) <TAB>  <TAB> number, unit_alias = match.groups() <TAB>  <TAB> number, unit_alias = int(number), unit_alias.lower() <TAB>  <TAB> unit_cname = cls.UNIT_ALIASES.get(unit_alias) <MASK> raise ValueError(""Invalid unit: %r"" % (unit_alias,)) <TAB>  <TAB> kwargs[unit_cname] = kwargs.get(unit_cname, 0) + number <TAB> return datetime.timedelta(**kwargs)",if not unit_cname :,192
"def logical_and(a, b): <TAB> """"""A version of tf.logical_and that eagerly evaluates if possible."""""" <TAB> a_value = get_static_value(a) <TAB> if a_value is not None: <TAB>  <TAB> if np.isscalar(a_value): <MASK> return _maybe_static(b) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return a_value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return a_value & _maybe_static(b) <TAB> else: <TAB>  <TAB> return a & _maybe_static(b)",if a_value :,138
def init_if_necessary(self): <TAB> if not self.is_checkpoint_loaded: <MASK> self.exe.run(self._base_startup_program) <TAB>  <TAB> self.is_checkpoint_loaded = True <TAB>  <TAB> self.is_best_model_loaded = False,if not self . load_checkpoint ( ) :,77
"def find_test(module): <TAB> for key in dir(module): <TAB>  <TAB> value = getattr(module, key, None) <MASK> continue <TAB>  <TAB> if not inspect.isclass(value): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if value.__module__ != module.__name__: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> return value <TAB> return None",if not value :,85
"def fetch(self, mutagen_file): <TAB> images = [] <TAB> for cover_type, cover_tag in self.TAG_NAMES.items(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> frame = mutagen_file[cover_tag] <TAB>  <TAB>  <TAB> text_delimiter_index = frame.value.find(b""\x00"") <MASK> comment = frame.value[0:text_delimiter_index] <TAB>  <TAB>  <TAB>  <TAB> comment = comment.decode(""utf-8"", ""replace"") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> comment = None <TAB>  <TAB>  <TAB> image_data = frame.value[text_delimiter_index + 1 :] <TAB>  <TAB>  <TAB> images.append(Image(data=image_data, type=cover_type, desc=comment)) <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> pass <TAB> return images",if text_delimiter_index > 0 :,199
"def onDrop(self, event): <TAB> dt = event.dataTransfer <TAB> text = dt.getData(""Text"") <TAB> target = DOM.eventGetTarget(event) <TAB> t = Widget(Element=target) <TAB> class_names = t.getStyleName() <TAB> if class_names is not None: <MASK> self.addMessage( <TAB>  <TAB>  <TAB>  <TAB> ""%s onto %s<br>effectAllowed=%s, dropEffect=%s"" <TAB>  <TAB>  <TAB>  <TAB> % (text, target.id, dt.effectAllowed, dt.dropEffect) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> DOM.eventPreventDefault(event)","if ""drophere"" in class_names :",157
"def search(self, gadgets, filter, quality=None, pprinter=None): <TAB> filter = self.prepareFilter(filter) <TAB> filtered = {} <TAB> count = 0 <TAB> max_count = len(gadgets) <TAB> fg = [] <TAB> for g in gadgets: <TAB>  <TAB> if g.match(filter): <TAB>  <TAB>  <TAB> if quality: <TAB>  <TAB>  <TAB>  <TAB> if len(g) <= quality + 1: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> fg.append(g) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> fg.append(g) <TAB>  <TAB> count += 1 <MASK> pprinter.printProgress(""searching gadgets..."", float(count) / max_count) <TAB> if pprinter: <TAB>  <TAB> pprinter.finishProgress() <TAB> return fg",if pprinter :,188
def keep_commissioning_alive(readiness): <TAB> try: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> await api(gateway.set_commissioning_timeout(60)) <MASK> readiness() <TAB>  <TAB>  <TAB> readiness = None <TAB>  <TAB>  <TAB> await asyncio.sleep(45) <TAB> finally: <TAB>  <TAB> await api(gateway.set_commissioning_timeout(00)),if readiness is not None :,99
"def hash_dir(hasher, path): <TAB> filenames = os.listdir(path) <TAB> filenames.sort() <TAB> filenames = [f for f in filenames if not should_ignore_file(f)] <TAB> hasher.update(str(filenames)) <TAB> for filename in filenames: <TAB>  <TAB> child = os.path.join(path, filename) <MASK> hash_dir(hasher, child) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> hasher.update(open(child).read()) <TAB> return hasher",if os . path . isdir ( child ) :,130
"def reload_all_files(force=False): <TAB> pause_auto_update() <TAB> for file_to_load in signals_files.values(): <MASK> show_spinner(""Updating files from the disk..."") <TAB>  <TAB>  <TAB> file_to_load.load() <TAB>  <TAB>  <TAB> hide_spinner() <TAB>  <TAB> refresh_info.text = ""Last Update: "" + str(datetime.datetime.now()).split(""."")[0] <TAB> resume_auto_update_according_to_toggle()",if force or file_to_load . file_was_modified_on_disk ( ) :,134
"def _literals_to_types(evaluator, result): <TAB> # Changes literals ('a', 1, 1.0, etc) to its type instances (str(), <TAB> # int(), float(), etc). <TAB> new_result = NO_CONTEXTS <TAB> for typ in result: <MASK> # Literals are only valid as long as the operations are <TAB>  <TAB>  <TAB> # correct. Otherwise add a value-free instance. <TAB>  <TAB>  <TAB> cls = compiled.builtin_from_name(evaluator, typ.name.string_name) <TAB>  <TAB>  <TAB> new_result |= cls.execute_evaluated() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_result |= ContextSet(typ) <TAB> return new_result",if is_literal ( typ ) :,164
"def _get_environ_vars(self): <TAB> # type: () -> Iterable[Tuple[str, str]] <TAB> """"""Returns a generator with all environmental vars with prefix PIP_"""""" <TAB> for key, val in os.environ.items(): <TAB>  <TAB> should_be_yielded = ( <TAB>  <TAB>  <TAB> key.startswith(""PIP_"") and key[4:].lower() not in self._ignore_env_names <TAB>  <TAB> ) <MASK> yield key[4:].lower(), val",if should_be_yielded :,120
"def _init_modules(self): <TAB> for cls in module_classes: <TAB>  <TAB> if cls.type == GROUP_MONGO: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> group_cls = cls() <MASK> group_cls.load() <TAB>  <TAB> setattr(self, cls.group, group_cls)",if group_cls . type == GROUP_FILE :,84
"def parse_error(self): <TAB> if self.status == httplib.UNAUTHORIZED: <TAB>  <TAB> body = self.parse_body() <TAB>  <TAB> raise InvalidCredsError(body.get(""error"")) <TAB> else: <TAB>  <TAB> body = self.parse_body() <MASK> error = ""%s (code: %s)"" % (body.get(""message""), self.status) <TAB>  <TAB> elif ""errors"" in body: <TAB>  <TAB>  <TAB> error = body.get(""errors"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> error = body <TAB>  <TAB> raise Exception(error)","if ""message"" in body :",141
"def layers_to_optimize(self): <TAB> lto = [] <TAB> for l in self.layers: <TAB>  <TAB> if isinstance(l, LayerContainer): <TAB>  <TAB>  <TAB> lto += l.layers_to_optimize <TAB>  <TAB> elif l.has_params: <MASK> continue <TAB>  <TAB>  <TAB> lto.append(l) <TAB> return lto","if hasattr ( l , ""init"" ) and l . init . name == ""Identity"" :",104
"def _validate_sid_uniqueness(self): <TAB> sids = [] <TAB> for statement in self._statements: <TAB>  <TAB> if ""Sid"" in statement: <TAB>  <TAB>  <TAB> statementId = statement[""Sid""] <MASK> assert statementId not in sids <TAB>  <TAB>  <TAB>  <TAB> sids.append(statementId)",if statementId :,83
"def home_exists(self, home, schema_name, verrors, old=None): <TAB> home_filters = [(""home"", ""="", True)] <TAB> home_result = None <TAB> if home: <MASK> id = old[""id""] <TAB>  <TAB>  <TAB> if not old[""home""]: <TAB>  <TAB>  <TAB>  <TAB> home_filters.append((""id"", ""!="", id)) <TAB>  <TAB>  <TAB>  <TAB> # The user already had this set as the home share <TAB>  <TAB>  <TAB>  <TAB> home_result = await self.middleware.call( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""datastore.query"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._config.datastore, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> home_filters, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> {""prefix"": self._config.datastore_prefix}, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return home_result","if old and old [ ""id"" ] is not None :",191
"def _parse_content_type(content_type): <TAB> """"""best efforts on pulling out the content type and encoding from Content-Type header"""""" <TAB> try: <TAB>  <TAB> content_type = content_type.strip() <TAB> except AttributeError: <TAB>  <TAB> pass <TAB> char_set = None <TAB> if content_type.strip(): <TAB>  <TAB> splt = content_type.split("";"") <TAB>  <TAB> content_type = splt[0] <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> raw_char_set = splt[1].strip() <TAB>  <TAB>  <TAB> key, char_set = raw_char_set.split(""="") <MASK> char_set = None <TAB>  <TAB> except (IndexError, ValueError): <TAB>  <TAB>  <TAB> pass <TAB> return content_type, char_set","if key != ""charset"" :",184
"def __init__(self, *args, **kwargs): <TAB> super(Context, self).__init__(*args, **kwargs) <TAB> if self._fields: <TAB>  <TAB> unknowns = [name for name in self._keys() if name not in self._fields] <MASK> raise ValueError(""Unexpected field names: %r"" % unknowns)",if unknowns :,86
"def http_addNodeMarker(self, p): <TAB> if self.getOption(""http_server_support"") and self.getOption(""generate_rst""): <TAB>  <TAB> self.nodeNumber += 1 <TAB>  <TAB> anchorname = ""%s%s"" % (self.getOption(""node_begin_marker""), self.nodeNumber) <TAB>  <TAB> s = ""\n\n.. _%s:\n\n"" % anchorname <TAB>  <TAB> self.write(s) <TAB>  <TAB> self.http_map[anchorname] = p.copy() <MASK> print >> bwm_file, ""addNodeMarker"", anchorname, p",if bwm_file :,150
"def _populate_function_table(cls): <TAB> function_table = {} <TAB> # Any method with a @signature decorator that also <TAB> # starts with ""_func_"" is registered as a function. <TAB> # _func_max_by -> max_by function. <TAB> for name, method in get_methods(cls): <TAB>  <TAB> if not name.startswith(""_func_""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> signature = getattr(method, ""signature"", None) <MASK> function_table[name[6:]] = { <TAB>  <TAB>  <TAB>  <TAB> ""function"": method, <TAB>  <TAB>  <TAB>  <TAB> ""signature"": signature, <TAB>  <TAB>  <TAB> } <TAB> cls.FUNCTION_TABLE = function_table",if signature is not None :,161
"def base_type_name(self, data): <TAB> """"""Replace references to base types."""""" <TAB> if ""AT_name"" in data: <TAB>  <TAB> return self.tp2vol[data[""AT_name""]] <TAB> else: <TAB>  <TAB> sz = int(data[""AT_byte_size""]) <MASK> return ""unsigned "" + self.sz2tp[sz] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.sz2tp[sz]","if data [ ""AT_encoding"" ] == ""ATE_unsigned"" :",118
"def render_POST(self, txrequest): <TAB> jrequest = self.parse_jsonrpc(txrequest) <TAB> method = jrequest[""method""] <TAB> try: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self.process_request(method, jrequest) <TAB>  <TAB> except Exception as err: <MASK> raise err <TAB>  <TAB>  <TAB> trace_lines = format_exception(*exc_info()) <TAB>  <TAB>  <TAB> raise JsonRpcError( <TAB>  <TAB>  <TAB>  <TAB> 500, ""Error processing request: %s"" % (str("""").join(trace_lines)) <TAB>  <TAB>  <TAB> ) <TAB> except JsonRpcError as err: <TAB>  <TAB> return err(jrequest[""id""])","if isinstance ( err , JsonRpcError ) :",168
"def get_default_value(name, evaluation, k=None, n=None): <TAB> pos = [] <TAB> if k is not None: <TAB>  <TAB> pos.append(k) <TAB> if n is not None: <TAB>  <TAB> pos.append(n) <TAB> for pos_len in reversed(range(len(pos) + 1)): <TAB>  <TAB> # Try patterns from specific to general <TAB>  <TAB> defaultexpr = Expression( <TAB>  <TAB>  <TAB> ""Default"", Symbol(name), *[Integer(index) for index in pos[:pos_len]] <TAB>  <TAB> ) <TAB>  <TAB> result = evaluation.definitions.get_value( <TAB>  <TAB>  <TAB> name, ""System`DefaultValues"", defaultexpr, evaluation <TAB>  <TAB> ) <MASK> if result.same(defaultexpr): <TAB>  <TAB>  <TAB>  <TAB> result = result.evaluate(evaluation) <TAB>  <TAB>  <TAB> return result <TAB> return None",if result is not None :,199
"def __init__(self, types): <TAB> super(GraphQLTypeMap, self).__init__() <TAB> self.update(reduce(self.reducer, types, OrderedDict())) <TAB> self._possible_type_map = defaultdict(set) <TAB> # Keep track of all implementations by interface name. <TAB> self._implementations = {} <TAB> for gql_type in self.values(): <TAB>  <TAB> if isinstance(gql_type, GraphQLObjectType): <TAB>  <TAB>  <TAB> for interface in gql_type.interfaces: <TAB>  <TAB>  <TAB>  <TAB> self._implementations.setdefault(interface.name, []).append(gql_type) <TAB> # Enforce correct interface implementations. <TAB> for type in self.values(): <MASK> for interface in type.interfaces: <TAB>  <TAB>  <TAB>  <TAB> self.assert_object_implements_interface(self, type, interface)","if isinstance ( type , GraphQLObjectType ) :",199
"def escape_code_start(source, ext, language=""python""): <TAB> """"""Escape code start with '# '"""""" <TAB> parser = StringParser(language) <TAB> for pos, line in enumerate(source): <MASK> source[pos] = ( <TAB>  <TAB>  <TAB>  <TAB> _SCRIPT_EXTENSIONS.get(ext, {}).get(""comment"", ""#"") + "" "" + line <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> parser.read_line(line) <TAB> return source","if not parser . is_quoted ( ) and is_escaped_code_start ( line , ext ) :",124
"def __get__(self, obj, objtype): <TAB> if obj: <TAB>  <TAB> value = getattr(obj, self.slot_name) <MASK> return value <TAB>  <TAB> # If the value is still the UUID for the referenced object, we need to create <TAB>  <TAB> # the object now that is the attribute has actually been accessed.  This lazy <TAB>  <TAB> # instantiation saves unnecessary roundtrips to SimpleDB <TAB>  <TAB> if isinstance(value, str) or isinstance(value, unicode): <TAB>  <TAB>  <TAB> value = self.reference_class(value) <TAB>  <TAB>  <TAB> setattr(obj, self.name, value) <TAB>  <TAB> return value",if value == self . default_value ( ) :,152
"def type(self): <TAB> with translation.override(settings.LANGUAGE_CODE): <MASK> type_ = translation.gettext(amo.ADDON_TYPE[self.addon.type]) <TAB>  <TAB> elif self.user: <TAB>  <TAB>  <TAB> type_ = ""User"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> type_ = ""Addon"" <TAB> return type_",if self . addon and self . addon . type in amo . ADDON_TYPE :,104
"def get_widget(self): <TAB> if not self.widget: <MASK> label = ""Siege Benchmark"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> label = None <TAB>  <TAB> self.widget = ExecutorWidget(self, label) <TAB> return self.widget",if self . get_load ( ) . hold :,74
"def process(self, resources, event=None): <TAB> results = [] <TAB> accounts = self.get_accounts() <TAB> owners = map( <TAB>  <TAB> jmespath.compile, (""AccepterVpcInfo.OwnerId"", ""RequesterVpcInfo.OwnerId"") <TAB> ) <TAB> for r in resources: <TAB>  <TAB> for o_expr in owners: <TAB>  <TAB>  <TAB> account_id = o_expr.search(r) <MASK> r.setdefault(""c7n:CrossAccountViolations"", []).append(account_id) <TAB>  <TAB>  <TAB>  <TAB> results.append(r) <TAB> return results",if account_id and account_id not in accounts :,153
"def get_float_value(self, permit_complex=False) -> typing.Optional[complex]: <TAB> if permit_complex: <TAB>  <TAB> real = self.real.get_float_value() <TAB>  <TAB> imag = self.imag.get_float_value() <MASK> return complex(real, imag) <TAB> else: <TAB>  <TAB> return None",if real is not None and imag is not None :,94
"def populate(self, data): <TAB> if data.get(""_embedded""): <MASK> self.castcredits = [ <TAB>  <TAB>  <TAB>  <TAB> CastCredit(credit) for credit in data[""_embedded""][""castcredits""] <TAB>  <TAB>  <TAB> ] <TAB>  <TAB> elif data[""_embedded""].get(""crewcredits""): <TAB>  <TAB>  <TAB> self.crewcredits = [ <TAB>  <TAB>  <TAB>  <TAB> CrewCredit(credit) for credit in data[""_embedded""][""crewcredits""] <TAB>  <TAB>  <TAB> ]","if data [ ""_embedded"" ] . get ( ""castcredits"" ) :",119
"def _get_bases(node, recurse=False): <TAB> bases = [x.attrib[""ref""] for x in node.findall(""base"")] <TAB> if recurse: <TAB>  <TAB> j = 0 <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> b = bases[j] <TAB>  <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB>  <TAB> break <MASK> bases.extend(_get_bases(all_nodes[b])) <TAB>  <TAB>  <TAB> j += 1 <TAB> return bases",if b in all_nodes :,121
"def getv3groupmembers(groupid): <TAB> for group in groups: <MASK> group_data = { <TAB>  <TAB>  <TAB>  <TAB> ""links"": {}, <TAB>  <TAB>  <TAB>  <TAB> ""users"": [_get_user(username) for username in group[""members""]], <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB> return json.dumps(group_data) <TAB> abort(404)","if group [ ""id"" ] == groupid :",93
"def offensive(self): <TAB> """"""Detects if item can be used as something offensive"""""" <TAB> # Make sure we cache results <TAB> if self.__offensive is None: <TAB>  <TAB> offensive = False <TAB>  <TAB> # Go through all effects and find first offensive <TAB>  <TAB> for effect in self.effects.values(): <MASK> # If we find one, stop and mark item as offensive <TAB>  <TAB>  <TAB>  <TAB> offensive = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> self.__offensive = offensive <TAB> return self.__offensive",if effect . isOffensive is True :,135
"def local_pow_canonicalize(node): <TAB> if node.op == T.pow: <TAB>  <TAB> cst = local_mul_canonizer.get_constant(node.inputs[1]) <MASK> return [broadcast_like(1, node.outputs[0], node.fgraph)] <TAB>  <TAB> if cst == 1: <TAB>  <TAB>  <TAB> return [broadcast_like(node.inputs[0], node.outputs[0], node.fgraph)] <TAB> else: <TAB>  <TAB> return False",if cst == 0 :,119
"def __init__(self, *args, **kwargs): <TAB> super().__init__(*args, **kwargs) <TAB> # set up classes for colors <TAB> self._ndefs = dict(self.style) <TAB> for t in Color.subtypes: <MASK> self._set_ndef_for_color_token(t) <TAB>  <TAB> classname = str(t)[5:].replace(""."", """").lower() <TAB>  <TAB> self.ttype2class[t] = classname <TAB>  <TAB> self.class2style[classname] = self._get_color_token_style(t) <TAB> del self._ndefs",if t not in self . style . _styles :,145
"def _pre_cell_callback(self, *args, **_): <TAB> # noinspection PyBroadException <TAB> try: <TAB>  <TAB> if args: <TAB>  <TAB>  <TAB> self._current_cell = args[0].raw_cell <TAB>  <TAB> # we might have this value from somewhere else <MASK> self._current_cell = self._conform_code( <TAB>  <TAB>  <TAB>  <TAB> self._current_cell, replace_magic_bang=True <TAB>  <TAB>  <TAB> ) <TAB> except Exception: <TAB>  <TAB> pass",if self . _current_cell :,121
"def _safe_recv(self, *args, **kwargs): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self._handle.recv(*args, **kwargs) <TAB>  <TAB> except socket.error as e: <TAB>  <TAB>  <TAB> # Interrupted system call <MASK> raise",if e . errno != errno . EINTR :,81
"def parseModuliFile(filename): <TAB> with open(filename) as f: <TAB>  <TAB> lines = f.readlines() <TAB> primes = {} <TAB> for l in lines: <TAB>  <TAB> l = l.strip() <MASK> continue <TAB>  <TAB> tim, typ, tst, tri, size, gen, mod = l.split() <TAB>  <TAB> size = int(size) + 1 <TAB>  <TAB> gen = int(gen) <TAB>  <TAB> mod = int(mod, 16) <TAB>  <TAB> if size not in primes: <TAB>  <TAB>  <TAB> primes[size] = [] <TAB>  <TAB> primes[size].append((gen, mod)) <TAB> return primes","if not l or l [ 0 ] == ""#"" :",156
"def collect_metrics(clients, tasks): <TAB> metrics = [] <TAB> for (resource, rtype, metric, params) in tasks: <TAB>  <TAB> client = clients.get(""%s-%s"" % (resource[""account_id""], resource[""region""])) <TAB>  <TAB> points = client.get_metric_statistics(**params).get(""Datapoints"", []) <TAB>  <TAB> # log.info(""getting metrics r:%s %s %s %s points:%d"", <TAB>  <TAB> # <TAB>  <TAB>   Resource.get_type(rtype).id(resource), <TAB>  <TAB> # <TAB>  <TAB>   metric['name'], params['StartTime'], <TAB>  <TAB> # <TAB>  <TAB>   params['EndTime'], len(points)) <MASK> continue <TAB>  <TAB> metrics.append((resource, rtype, metric, points)) <TAB> return metrics",if not points :,198
"def encode_sents(self, sents, ordered=False, verbose=False): <TAB> if verbose: <TAB>  <TAB> logger.info(""encoding {} sents ..."".format(len(sents))) <TAB> encoded = [] <TAB> for idx, symbols in enumerate(sents): <MASK> logger.info("" <TAB> line {}"".format(idx)) <TAB>  <TAB> encoded.append(self.convert_to_tensor(symbols)) <TAB> if ordered: <TAB>  <TAB> encoded = torch.cat(encoded) <TAB> return encoded",if verbose and idx > 0 and idx % 500000 == 0 :,127
"def authenticate_account(self, authc_token: JwtToken): <TAB> try: <TAB>  <TAB> assert authc_token.identifier is not None <TAB>  <TAB> # Lookup the account info to verify the user identified by the token is still valid <TAB>  <TAB> authc_info = self.get_authentication_info(authc_token.identifier) <TAB>  <TAB> # Overwrite any creds found in db. Cleanup of token vs password is outside the scope of this handler. <MASK> # No user exists for the identifier <TAB>  <TAB>  <TAB> raise IncorrectCredentialsException <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return authc_info <TAB> except: <TAB>  <TAB> logger.debug_exception(""Could not authenticate token"") <TAB>  <TAB> raise IncorrectCredentialsException()","if not authc_info or not authc_info [ ""authc_info"" ] :",180
"def _send_signal(self, sig): <TAB> try: <TAB>  <TAB> os.kill(self.pid, sig) <TAB> except OSError: <TAB>  <TAB> err = sys.exc_info()[1] <TAB>  <TAB> if err.errno == errno.ESRCH: <TAB>  <TAB>  <TAB> self._gone = True <TAB>  <TAB>  <TAB> raise NoSuchProcess(self.pid, self._name) <MASK> raise AccessDenied(self.pid, self._name) <TAB>  <TAB> raise",if err . errno == errno . EPERM :,117
"def parser(cls, buf): <TAB> (src_port, dst_port, vtag, csum) = struct.unpack_from(cls._PACK_STR, buf) <TAB> chunks = [] <TAB> offset = cls._MIN_LEN <TAB> while offset < len(buf): <TAB>  <TAB> (type_,) = struct.unpack_from(""!B"", buf, offset) <TAB>  <TAB> cls_ = cls._SCTP_CHUNK_TYPE.get(type_) <MASK> break <TAB>  <TAB> ins = cls_.parser(buf[offset:]) <TAB>  <TAB> chunks.append(ins) <TAB>  <TAB> offset += len(ins) <TAB> msg = cls(src_port, dst_port, vtag, csum, chunks) <TAB> return msg, None, buf[offset:]",if not cls_ :,179
"def _areAllSDRsUnique(sdrDict): <TAB> """"""Return True iff all the SDR's in the dict are unique."""""" <TAB> for k1, v1 in sdrDict.iteritems(): <TAB>  <TAB> for k2, v2 in sdrDict.iteritems(): <TAB>  <TAB>  <TAB> # Return false if two different keys have identical SDR's <MASK> return False <TAB> return True",if ( k2 != k1 ) and ( ( v1 == v2 ) . sum ( ) == v1 . size ) :,117
"def validate_sources(self): <TAB> for s in self.sources: <TAB>  <TAB> num = int(s.split(""."")[-1]) <MASK> raise InvalidArguments( <TAB>  <TAB>  <TAB>  <TAB> ""Man file must have a file extension of a number between 1 and 8"" <TAB>  <TAB>  <TAB> )",if num < 1 or num > 8 :,76
"def colorize(tokens, ansi_level): <TAB> output = """" <TAB> for type_, value in tokens: <MASK> if ansi_level is None: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""The '<level>' color tag is not allowed in this context, "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""it has not yet been associated to any color value."" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> value = ansi_level <TAB>  <TAB> output += value <TAB> return output",if type_ == TokenType . LEVEL :,119
"def _parse_value(self, kind): <TAB> if isinstance(self._parse_token(), kind): <TAB>  <TAB> return self._token <TAB> else: <TAB>  <TAB> if kind == int: <TAB>  <TAB>  <TAB> expected = ""integer"" <TAB>  <TAB> elif kind == float: <TAB>  <TAB>  <TAB> expected = ""real"" <TAB>  <TAB> elif kind == (int, float): <TAB>  <TAB>  <TAB> expected = ""number"" <MASK> expected = ""scan data"" <TAB>  <TAB> elif kind == tuple: <TAB>  <TAB>  <TAB> expected = ""data"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert False <TAB>  <TAB> self._parse_unexpected(expected)",elif kind == bits :,146
"def handle_fk_field(self, obj, field): <TAB> related = getattr(obj, field.name) <TAB> if related is not None: <MASK> related = related.natural_key() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if field.rel.field_name == related._meta.pk.name: <TAB>  <TAB>  <TAB>  <TAB> # Related to remote object via primary key <TAB>  <TAB>  <TAB>  <TAB> related = related._get_pk_val() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> # Related to remote object via other field <TAB>  <TAB>  <TAB>  <TAB> related = smart_unicode( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> getattr(related, field.rel.field_name), strings_only=True <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> self._current[field.name] = related","if self . use_natural_keys and hasattr ( related , ""natural_key"" ) :",192
"def users(): <TAB> retlist = [] <TAB> rawlist = cext.users() <TAB> for item in rawlist: <TAB>  <TAB> user, tty, hostname, tstamp = item <MASK> continue  # reboot or shutdown <TAB>  <TAB> nt = _common.suser(user, tty or None, hostname, tstamp) <TAB>  <TAB> retlist.append(nt) <TAB> return retlist","if tty == ""~"" :",94
def _reader(): <TAB> n = 0 <TAB> while True: <TAB>  <TAB> for _batch in reader: <TAB>  <TAB>  <TAB> if len(_batch) > 0: <TAB>  <TAB>  <TAB>  <TAB> yield _batch <TAB>  <TAB>  <TAB>  <TAB> n += 1 <MASK> return <TAB>  <TAB> reader.reset() <TAB>  <TAB> if max_iter <= 0: <TAB>  <TAB>  <TAB> return,if max_iter > 0 and n == max_iter :,97
"def clear(self, **kwargs): <TAB> for x in range(0, 50): <TAB>  <TAB> path = ""%s%s"" % (Env.get(""log_path""), "".%s"" % x if x > 0 else """") <MASK> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> # Create empty file for current logging <TAB>  <TAB>  <TAB> if x is 0: <TAB>  <TAB>  <TAB>  <TAB> self.createFile(path, """") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> os.remove(path) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> log.error('Couldn\'t delete file ""%s"": %s', (path, traceback.format_exc())) <TAB> return {""success"": True}",if not os . path . isfile ( path ) :,165
"def fire_callbacks(self, log_level, log_message=None, log_extra=None): <TAB> log_extra = log_extra or {} <TAB> callbacks = self.callbacks[log_level] <TAB> for cb, criteria in callbacks: <TAB>  <TAB> unmatched_criteria = criteria and not self.is_subdict(criteria, log_extra) <MASK> continue <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> cb(log_message, log_extra)",if unmatched_criteria :,111
"def _process_row(self, row): <TAB> values = OrderedDict() <TAB> if len(row) == len(self._columns): <TAB>  <TAB> for column, column_value in enumerate(row): <TAB>  <TAB>  <TAB> variable, index, label = self._columns[column] <TAB>  <TAB>  <TAB> if index is None: <TAB>  <TAB>  <TAB>  <TAB> values[variable] = self._get_value(column_value, is_vector=True) <TAB>  <TAB>  <TAB> else: <MASK> values[variable] = [] <TAB>  <TAB>  <TAB>  <TAB> values[variable].append(self._get_value(column_value)) <TAB> return values.values()",if variable not in values :,153
"def tearDown(self): <TAB> if self.obj.modified_jmx and os.path.exists(self.obj.modified_jmx): <TAB>  <TAB> os.remove(self.obj.modified_jmx) <TAB> if self.obj.reader: <TAB>  <TAB> if isinstance(self.obj.reader, FuncJTLReader): <TAB>  <TAB>  <TAB> close_reader_file(self.obj.reader) <MASK> close_reader_file(self.obj.reader.csvreader) <TAB>  <TAB>  <TAB> close_reader_file(self.obj.reader.errors_reader) <TAB> super(TestJMeterExecutor, self).tearDown()","if isinstance ( self . obj . reader , JTLReader ) :",162
"def __call__(self, im: np.ndarray): <TAB> if self.prob <= 0: <TAB>  <TAB> n = 0 <TAB> elif self.prob >= 1: <TAB>  <TAB> n = 1 <TAB> else: <TAB>  <TAB> n = int(1.0 / self.prob) <TAB> if n > 0: <TAB>  <TAB> if np.random.randint(0, n) == 0: <TAB>  <TAB>  <TAB> radius = np.random.randint(3, 10) <TAB>  <TAB>  <TAB> if radius % 2 != 1: <TAB>  <TAB>  <TAB>  <TAB> radius = radius + 1 <MASK> radius = 9 <TAB>  <TAB>  <TAB> im = cv2.GaussianBlur(im, (radius, radius), 0, 0) <TAB> return im",if radius > 9 :,166
"def __eq__(self, other): <TAB> attrs = [""name"", ""value""] + list(self.attribute_names.keys()) <TAB> for attr in attrs: <TAB>  <TAB> mine = getattr(self, attr, None) <TAB>  <TAB> his = getattr(other, attr, None) <TAB>  <TAB> if isinstance(mine, bytes): <TAB>  <TAB>  <TAB> mine = mine.decode(""utf-8"") <TAB>  <TAB> if isinstance(his, bytes): <TAB>  <TAB>  <TAB> his = his.decode(""utf-8"") <TAB>  <TAB> if attr == ""domain"": <MASK> mine = mine[1:] <TAB>  <TAB>  <TAB> if his and his[0] == ""."": <TAB>  <TAB>  <TAB>  <TAB> his = his[1:] <TAB>  <TAB> if mine != his: <TAB>  <TAB>  <TAB> return False <TAB> return True","if mine and mine [ 0 ] == ""."" :",191
"def decompress(self, data): <TAB> res = bytearray() <TAB> for item in data: <MASK> res.append(item) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> length, distance = item <TAB>  <TAB>  <TAB> end = -distance + length <TAB>  <TAB>  <TAB> if end < 0: <TAB>  <TAB>  <TAB>  <TAB> match = res[-distance : -distance + length] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> match = res[-distance:] <TAB>  <TAB>  <TAB> res += match <TAB> return res","if isinstance ( item , int ) :",118
"def __str__(self, prefix="""", printElemNumber=0): <TAB> res = """" <TAB> cnt = 0 <TAB> for e in self.log_line_: <TAB>  <TAB> elm = """" <MASK> elm = ""(%d)"" % cnt <TAB>  <TAB> res += prefix + (""log_line%s <\n"" % elm) <TAB>  <TAB> res += e.__str__(prefix + ""  "", printElemNumber) <TAB>  <TAB> res += prefix + "">\n"" <TAB>  <TAB> cnt += 1 <TAB> return res",if printElemNumber :,123
"def execute(cls, ctx, op): <TAB> chunk = op.outputs[0] <TAB> (a,), device_id, xp = as_same_device( <TAB>  <TAB> [ctx[c.key] for c in op.inputs], device=op.device, ret_extra=True <TAB> ) <TAB> with device(device_id): <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> import scipy.linalg <TAB>  <TAB>  <TAB>  <TAB> ctx[chunk.key] = scipy.linalg.cholesky(a, lower=op.lower) <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> except ImportError:  # pragma: no cover <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> r = xp.linalg.cholesky(a) <TAB>  <TAB> if not chunk.op.lower: <TAB>  <TAB>  <TAB> r = r.T.conj() <TAB>  <TAB> ctx[chunk.key] = r",if xp is np :,198
"def from_wire_parser(cls, parser, origin=None):  # pylint: disable=W0613 <TAB> keys = [] <TAB> last_key = -1 <TAB> while parser.remaining() > 0: <TAB>  <TAB> key = parser.get_uint16() <MASK> raise dns.exception.FormError(""manadatory keys not ascending"") <TAB>  <TAB> last_key = key <TAB>  <TAB> keys.append(key) <TAB> return cls(keys)",if key < last_key :,114
"def check_call(func, taints): <TAB> for node in func.nodes: <TAB>  <TAB> for ir in node.irs: <TAB>  <TAB>  <TAB> if isinstance(ir, HighLevelCall): <MASK> print(""Call to tainted address found in {}"".format(function.name))",if ir . destination in taints :,77
"def _insert(node, path, itemid): <TAB> """"""Insert an item into a virtual filesystem node."""""" <TAB> if len(path) == 1: <TAB>  <TAB> # Last component. Insert file. <TAB>  <TAB> node.files[path[0]] = itemid <TAB> else: <TAB>  <TAB> # In a directory. <TAB>  <TAB> dirname = path[0] <TAB>  <TAB> rest = path[1:] <MASK> node.dirs[dirname] = Node({}, {}) <TAB>  <TAB> _insert(node.dirs[dirname], rest, itemid)",if dirname not in node . dirs :,127
"def translate_to_declarations(self, read, write, indices): <TAB> lines = [] <TAB> # simply declare variables that will be written but not read <TAB> for varname in write: <MASK> var = self.variables[varname] <TAB>  <TAB>  <TAB> line = self.c_data_type(var.dtype) + "" "" + varname + "";"" <TAB>  <TAB>  <TAB> lines.append(line) <TAB> return lines",if varname not in read and varname not in indices :,106
"def dict_build(indict, pre=None): <TAB> pre = pre[:] if pre else [] <TAB> if len(indict): <TAB>  <TAB> for key, value in indict.items(): <MASK> for d in dict_build(value, pre=pre + [key]): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield d <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield pre + [key] <TAB> else: <TAB>  <TAB> yield pre",if len ( value ) :,108
def io_counters(self): <TAB> try: <TAB>  <TAB> ret = cext.proc_io_counters(self.pid) <TAB> except OSError: <TAB>  <TAB> err = sys.exc_info()[1] <MASK> ret = cext.proc_io_counters_2(self.pid) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise <TAB> return _common.pio(*ret),if err . errno in ACCESS_DENIED_SET :,106
"def check_replication_flags(self, options, required_flags): <TAB> for flag in required_flags: <MASK> msg = ( <TAB>  <TAB>  <TAB>  <TAB> _( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""%s is not set and is required for the replication "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""device to be valid."" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> % flag <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> LOG.error(msg) <TAB>  <TAB>  <TAB> raise exception.InvalidInput(reason=msg)","if not options . get ( flag , None ) :",124
"def clean_up_joinables(names): <TAB> """"""Remove joinable files and their .1 backups"""""" <TAB> for name in names: <TAB>  <TAB> if os.path.exists(name): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> remove_file(name) <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> name1 = name + "".1"" <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> remove_file(name1) <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> pass",if os . path . exists ( name1 ) :,126
"def get_available_addresses(self): <TAB> """"""A generator that returns (addr, size) for each valid address block"""""" <TAB> runLength = None <TAB> currentOffset = None <TAB> for (offset, size) in self.get_available_pages(): <TAB>  <TAB> if runLength == None: <TAB>  <TAB>  <TAB> runLength = size <TAB>  <TAB>  <TAB> currentOffset = offset <TAB>  <TAB> else: <MASK> runLength += (currentOffset + runLength - offset) + size <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield (currentOffset, runLength) <TAB>  <TAB>  <TAB>  <TAB> runLength = size <TAB>  <TAB>  <TAB>  <TAB> currentOffset = offset <TAB> if runLength != None and currentOffset != None: <TAB>  <TAB> yield (currentOffset, runLength) <TAB> raise StopIteration",if offset <= ( currentOffset + runLength ) :,185
"def save_as(self, event): <TAB> filename = self.asksavefile() <TAB> if filename: <MASK> self.set_filename(filename) <TAB>  <TAB>  <TAB> self.set_saved(1) <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> self.editwin.store_file_breaks() <TAB>  <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB> self.text.focus_set() <TAB> self.updaterecentfileslist(filename) <TAB> return ""break""",if self . writefile ( filename ) :,122
"def resolve_xref(self, env, fromdocname, builder, type, target, node, contnode): <TAB> if type == ""formula"" and target in self.data[""formulas""]: <TAB>  <TAB> doc, _, _, _ = self.data[""formulas""].get(target, (None, None)) <MASK> return make_refnode(builder, fromdocname, doc, target, contnode, target) <TAB> else: <TAB>  <TAB> super(SaltDomain, self).resolve_xref( <TAB>  <TAB>  <TAB> env, fromdocname, builder, type, target, node, contnode <TAB>  <TAB> )",if doc :,136
"def parse_target(target_str): <TAB> if ""="" in target_str: <TAB>  <TAB> package_name, version = target_str.split(""="", 1) <TAB>  <TAB> build = None <MASK> version, build = version.split(""="") <TAB>  <TAB> elif ""--"" in version: <TAB>  <TAB>  <TAB> version, build = version.split(""--"") <TAB>  <TAB> target = build_target(package_name, version, build) <TAB> else: <TAB>  <TAB> target = build_target(target_str) <TAB> return target","if ""="" in version :",120
"def page(self): <TAB> # TODO count wrapped lines with respect to terminal width by <TAB> # taking in account ANSI formatting codes <TAB> row_count = 0 <TAB> while self.index < len(self.data): <TAB>  <TAB> line = self.data[self.index] <TAB>  <TAB> self.reader.print(line + ""\n"") <TAB>  <TAB> self.index += 1 <TAB>  <TAB> row_count += 1 <TAB>  <TAB> if row_count == self.visible or self.index == len(self.data): <TAB>  <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB>  <TAB> action = self.handle_prompt() <TAB>  <TAB>  <TAB>  <TAB> if action == ""quit"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return <MASK> break <TAB>  <TAB>  <TAB> row_count = 0 <TAB> self.reader.resetPromptLine("""", """", 0)","elif action != ""reprompt"" :",192
"def _field_type(self, tp_struct, field_name, tp_field): <TAB> if isinstance(tp_field, model.ArrayType): <TAB>  <TAB> actual_length = tp_field.length <MASK> ptr_struct_name = tp_struct.get_c_name(""*"") <TAB>  <TAB>  <TAB> actual_length = ""_cffi_array_len(((%s)0)->%s)"" % ( <TAB>  <TAB>  <TAB>  <TAB> ptr_struct_name, <TAB>  <TAB>  <TAB>  <TAB> field_name, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> tp_item = self._field_type(tp_struct, ""%s[0]"" % field_name, tp_field.item) <TAB>  <TAB> tp_field = model.ArrayType(tp_item, actual_length) <TAB> return tp_field","if actual_length == ""..."" :",187
"def __init__(self, *args):  # pylint: disable=super-init-not-called <TAB> self._eigvals_cache = None <TAB> self.obs = [] <TAB> for o in args: <MASK> self.obs.extend(o.obs) <TAB>  <TAB> elif isinstance(o, Observable): <TAB>  <TAB>  <TAB> self.obs.append(o) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""Can only perform tensor products between observables."")","if isinstance ( o , Tensor ) :",116
"def read_lines(fin, fout, line_head): <TAB> line = """" <TAB> while not fin.channel.exit_status_ready(): <TAB>  <TAB> line += fin.read(1).decode(""utf8"") <MASK> print(f""{line_head}{line[:-1]}"", file=fout) <TAB>  <TAB>  <TAB> line = """" <TAB> if line: <TAB>  <TAB> # print what remains in line buffer, in case fout does not <TAB>  <TAB> # end with '\n' <TAB>  <TAB> print(f""{line_head}{line[:-1]}"", file=fout)","if line . endswith ( ""\n"" ) :",141
"def process(self, clusters): <TAB> with self.executor_factory(max_workers=2) as w: <TAB>  <TAB> futures = [] <TAB>  <TAB> for cluster in clusters: <TAB>  <TAB>  <TAB> futures.append(w.submit(self.process_snapshot_retention, cluster)) <TAB>  <TAB> for f in as_completed(futures): <MASK> self.log.error( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Exception setting Redshift retention  \n %s"", f.exception() <TAB>  <TAB>  <TAB>  <TAB> )",if f . exception ( ) :,123
"def __next__(self): <TAB> """"""Return the next record when iterating over the file."""""" <TAB> self.table_record = BlastTableRec() <TAB> self._n += 1 <TAB> inline = self._lookahead <TAB> if not inline: <TAB>  <TAB> return None <TAB> while inline: <TAB>  <TAB> if inline[0] == ""#"": <MASK> self._in_header = self._consume_header(inline) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._consume_entry(inline) <TAB>  <TAB>  <TAB> self._in_header = 0 <TAB>  <TAB> inline = self.handle.readline() <TAB> self._lookahead = inline <TAB> self._in_header = 1 <TAB> return self.table_record",if self . _in_header :,178
"def skip_map(self, writer_schema, decoder): <TAB> block_count = decoder.read_long() <TAB> while block_count != 0: <MASK> block_size = decoder.read_long() <TAB>  <TAB>  <TAB> decoder.skip(block_size) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for _ in range(block_count): <TAB>  <TAB>  <TAB>  <TAB> decoder.skip_utf8() <TAB>  <TAB>  <TAB>  <TAB> self.skip_data(writer_schema.values, decoder) <TAB>  <TAB> block_count = decoder.read_long()",if block_count < 0 :,133
"def get_req_headers(self): <TAB> headers = {} <TAB> for name, value in iteritems(self.env): <TAB>  <TAB> # will be set by requests to match actual host <TAB>  <TAB> if name == ""HTTP_HOST"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif name.startswith(""HTTP_""): <TAB>  <TAB>  <TAB> name = name[5:].title().replace(""_"", ""-"") <MASK> name = name.title().replace(""_"", ""-"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = None <TAB>  <TAB> if value: <TAB>  <TAB>  <TAB> headers[name] = value <TAB> return headers","elif name in ( ""CONTENT_LENGTH"" , ""CONTENT_TYPE"" ) :",143
"def match(self, module_name): <TAB> """"""Does `module_name` indicate a module in one of our packages?"""""" <TAB> if not module_name: <TAB>  <TAB> return False <TAB> for m in self.modules: <MASK> if module_name == m: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB> if module_name[len(m)] == ""."": <TAB>  <TAB>  <TAB>  <TAB> # This is a module in the package <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if module_name . startswith ( m ) :,119
"def testTnRef(self): <TAB> partition = {} <TAB> for key, value in TNREF.items(): <TAB>  <TAB> self.assertEqual(len(key), 3) <TAB>  <TAB> # the third value of the key should be -1, 1, or 0 <TAB>  <TAB> self.assertTrue(key[2] in [-1, 0, 1]) <MASK> partition[key[0]] = [] <TAB>  <TAB>  <TAB> partition[key[0]].append(value)  # append unique ids <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> partition[key[0]].append(value)  # append unique ids <TAB> for key, value in partition.items(): <TAB>  <TAB> # the length of the list should be the max value stored <TAB>  <TAB> self.assertEqual(max(value), len(partition[key]))",if key [ 0 ] not in partition :,187
"def stage(self, x, num_modules, channels, multi_scale_output=True, name=None): <TAB> out = x <TAB> for i in range(num_modules): <MASK> out = self.high_resolution_module( <TAB>  <TAB>  <TAB>  <TAB> out, channels, multi_scale_output=False, name=name + ""_"" + str(i + 1) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> out = self.high_resolution_module( <TAB>  <TAB>  <TAB>  <TAB> out, channels, name=name + ""_"" + str(i + 1) <TAB>  <TAB>  <TAB> ) <TAB> return out",if i == num_modules - 1 and multi_scale_output == False :,159
"def cleanup_archive_status(self): <TAB> status_dir = os.path.join(self._postgresql.wal_dir, ""archive_status"") <TAB> try: <TAB>  <TAB> for f in os.listdir(status_dir): <TAB>  <TAB>  <TAB> path = os.path.join(status_dir, f) <TAB>  <TAB>  <TAB> try: <MASK> os.unlink(path) <TAB>  <TAB>  <TAB>  <TAB> elif os.path.isfile(path): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> os.remove(path) <TAB>  <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB>  <TAB> logger.exception(""Unable to remove %s"", path) <TAB> except OSError: <TAB>  <TAB> logger.exception(""Unable to list %s"", status_dir)",if os . path . islink ( path ) :,175
"def ReadUntilClose(self): <TAB> """"""Yield packets until a Close packet is received."""""" <TAB> while True: <TAB>  <TAB> cmd, data = self.ReadUntil(b""CLSE"", b""WRTE"") <MASK> self._Send(b""CLSE"", arg0=self.local_id, arg1=self.remote_id) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if cmd != b""WRTE"": <TAB>  <TAB>  <TAB> if cmd == b""FAIL"": <TAB>  <TAB>  <TAB>  <TAB> raise usb_exceptions.AdbCommandFailureException(""Command failed."", data) <TAB>  <TAB>  <TAB> raise InvalidCommandError( <TAB>  <TAB>  <TAB>  <TAB> ""Expected a WRITE or a CLOSE, got %s (%s)"", cmd, data <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> yield data","if cmd == b""CLSE"" :",181
"def split_words(msg: str) -> List[str]: <TAB> """"""Split line of text into words (but not within quoted groups)."""""" <TAB> next_word = """" <TAB> res = []  # type: List[str] <TAB> allow_break = True <TAB> for c in msg: <TAB>  <TAB> if c == "" "" and allow_break: <TAB>  <TAB>  <TAB> res.append(next_word) <TAB>  <TAB>  <TAB> next_word = """" <TAB>  <TAB>  <TAB> continue <MASK> allow_break = not allow_break <TAB>  <TAB> next_word += c <TAB> res.append(next_word) <TAB> return res","if c == '""' :",145
"def finder(element): <TAB> for child in element: <TAB>  <TAB> if child.text: <TAB>  <TAB>  <TAB> if child.text.find(self.getConfig(""PLACE_MARKER"")) > -1: <TAB>  <TAB>  <TAB>  <TAB> return child, True <TAB>  <TAB> if child.tail: <MASK> return (child, element), False <TAB>  <TAB> finder(child) <TAB> return None","if child . tail . find ( self . getConfig ( ""PLACE_MARKER"" ) ) > - 1 :",109
"def _apply_choice_vals(flagdefs, user_vals, target_vals): <TAB> for flagdef in flagdefs: <TAB>  <TAB> if not flagdef.choices: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> flag_val = target_vals.get(flagdef.name) <MASK> continue <TAB>  <TAB> for choice in flagdef.choices: <TAB>  <TAB>  <TAB> if (choice.alias or choice.value) != flag_val: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if choice.alias: <TAB>  <TAB>  <TAB>  <TAB> target_vals[flagdef.name] = choice.value <TAB>  <TAB>  <TAB> if choice.flags: <TAB>  <TAB>  <TAB>  <TAB> _apply_choice_flags(choice.flags, user_vals, target_vals)",if flag_val is None :,173
"def run(self): <TAB> if self.check(): <TAB>  <TAB> path = ( <TAB>  <TAB>  <TAB> ""/cgi-bin/webproc?getpage={}&errorpage=html/main.html&var:language=en_us"" <TAB>  <TAB>  <TAB> ""&var:menu=setup&var:page=wizard"".format(self.filename) <TAB>  <TAB> ) <TAB>  <TAB> response = self.http_request(method=""GET"", path=path) <MASK> return <TAB>  <TAB> if response.status_code == 200 and len(response.text): <TAB>  <TAB>  <TAB> print_success(""Success! File: %s"" % self.filename) <TAB>  <TAB>  <TAB> print_info(response.text) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print_error(""Exploit failed"") <TAB> else: <TAB>  <TAB> print_error(""Device seems to be not vulnerable"")",if response is None :,196
"def set_form_value(self, html, value): <TAB> if html.attr(""multiple"") == ""multiple"": <TAB>  <TAB> for child in html.children: <MASK> child.attr(""selected"", ""selected"") <TAB>  <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> for child in html.children: <TAB>  <TAB>  <TAB> if child.attr(""value"") == value: <TAB>  <TAB>  <TAB>  <TAB> child.attr(""selected"", ""selected"") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> child._attr.pop(""selected"", None)","if child . attr ( ""value"" ) == value :",134
"def getNegatives(self, target, size):  # TODO check equality with target <TAB> if self.care_type == 0: <TAB>  <TAB> response = self.negatives[self.negpos : self.negpos + size] <TAB>  <TAB> self.negpos = (self.negpos + size) % len(self.negatives) <MASK> return np.concatenate((response, self.negatives[0 : self.negpos])) <TAB> return response",if len ( response ) != size :,116
"def printer(self, string, info, color, printable=True): <TAB> ctm = self.current_time() <TAB> tmp = ""["" + str(info) + ""]"" <TAB> if printable: <TAB>  <TAB> msg = ""{:<22}{:<10}{:<20}"".format(str(ctm), str(tmp), str(string)) <TAB>  <TAB> print(colored(msg, color), flush=True) <MASK> with open(""log.txt"", ""a+"", encoding=""utf-8"") as f: <TAB>  <TAB>  <TAB>  <TAB> f.write(msg + ""\n"") <TAB> else: <TAB>  <TAB> pass","if self . thoroughly_log or info in [ ""Error"" , ""Warning"" ] :",158
"def filter_windows(windows): <TAB> if scene.aoi_polygons: <TAB>  <TAB> windows = Box.filter_by_aoi(windows, scene.aoi_polygons) <TAB>  <TAB> filt_windows = [] <TAB>  <TAB> for w in windows: <TAB>  <TAB>  <TAB> label_arr = label_source.get_labels(w).get_label_arr(w) <TAB>  <TAB>  <TAB> null_inds = label_arr.ravel() == class_config.get_null_class_id() <MASK> filt_windows.append(w) <TAB>  <TAB> windows = filt_windows <TAB> return windows",if not np . all ( null_inds ) :,151
"def read_device_conf_dict(tag: ET.Element, target_dict): <TAB> if tag is None: <TAB>  <TAB> return <TAB> for dev_tag in tag: <TAB>  <TAB> if dev_tag.text is None: <TAB>  <TAB>  <TAB> logger.warn(""{} has None text"".format(str(dev_tag))) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> value = int(dev_tag.text) <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> value = float(dev_tag.text) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> value = dev_tag.text <MASK> target_dict[""samples_per_symbol""] = value  # legacy <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> target_dict[dev_tag.tag] = value","if dev_tag . tag == ""bit_len"" :",197
"def _needToHackAroundStdHandles(cls): <TAB> if cls.__needToHackAroundStdHandles is None: <MASK> cls.__needToHackAroundStdHandles = False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> from _subprocess import GetStdHandle, STD_INPUT_HANDLE <TAB>  <TAB>  <TAB> stdin_handle = GetStdHandle(STD_INPUT_HANDLE) <TAB>  <TAB>  <TAB> if stdin_handle is not None: <TAB>  <TAB>  <TAB>  <TAB> cls.__needToHackAroundStdHandles = True <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> cls.__needToHackAroundStdHandles = False <TAB> return cls.__needToHackAroundStdHandles","if sys . platform != ""win32"" :",163
"def exit_player(self): <TAB> # If mpv use render api to show video, we should <TAB> # free resource explicitly <TAB> if not self.player.use_opengl_cb: <TAB>  <TAB> mpv_render_ctx = self.ui.mpv_widget.ctx <MASK> mpv_render_ctx.free() <TAB>  <TAB> self.ui.mpv_widget.close() <TAB> self.player.shutdown()",if mpv_render_ctx is not None :,113
"def cov_params(self): <TAB> if hasattr(self.model.data, ""frame""): <TAB>  <TAB> # Return the covariance matrix as a dataframe or series <TAB>  <TAB> na = self.model.fep_names + self.model.vcp_names + self.model.vc_names <MASK> return pd.DataFrame(self._cov_params, index=na, columns=na) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return pd.Series(self._cov_params, index=na) <TAB> # Return the covariance matrix as a ndarray <TAB> return self._cov_params",if self . _cov_params . ndim == 2 :,144
"def _restore_plugins_states(self): <TAB> for item in self.items(): <TAB>  <TAB> plugin = item.plugin <TAB>  <TAB> if plugin.module_name in self._preserve: <TAB>  <TAB>  <TAB> item.restore_state(self._preserve[plugin.module_name]) <MASK> self.set_current_item(item, scroll=True)",if self . _preserve_selected == plugin . module_name :,98
"def api_dropbox_webhook( <TAB> request: HttpRequest, <TAB> user_profile: UserProfile, <TAB> challenge: Optional[str] = REQ(default=None),) -> HttpResponse: <TAB> if request.method == ""POST"": <TAB>  <TAB> topic = ""Dropbox"" <TAB>  <TAB> check_send_webhook_message( <TAB>  <TAB>  <TAB> request, user_profile, topic, ""File has been updated on Dropbox!"" <TAB>  <TAB> ) <TAB>  <TAB> return json_success() <TAB> else: <MASK> raise RequestVariableMissingError(""challenge"") <TAB>  <TAB> return HttpResponse(challenge, content_type=""text/plain; charset=UTF-8"")",if challenge is None :,150
def cleanup(soup): <TAB> for tag in soup: <MASK> if tag.name not in acceptable_elements: <TAB>  <TAB>  <TAB>  <TAB> tag.extract() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> for attr in tag._getAttrMap().keys(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if attr not in acceptable_attributes: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> del tag[attr] <TAB>  <TAB>  <TAB>  <TAB> cleanup(tag),"if not isinstance ( tag , NavigableString ) :",105
"def mixed_segmentation(text): <TAB> segs_out = [] <TAB> temp_str = """" <TAB> for char in text: <MASK> if temp_str != """": <TAB>  <TAB>  <TAB>  <TAB> ss = whitespace_tokenize(temp_str) <TAB>  <TAB>  <TAB>  <TAB> segs_out.extend(ss) <TAB>  <TAB>  <TAB>  <TAB> temp_str = """" <TAB>  <TAB>  <TAB> segs_out.append(char) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> temp_str += char <TAB> if temp_str != """": <TAB>  <TAB> ss = whitespace_tokenize(temp_str) <TAB>  <TAB> segs_out.extend(ss) <TAB> return segs_out","if re . search ( r""[\u4e00-\u9fa5]"" , char ) or char in PUNCT :",170
def _unittest_count(docstring): <TAB> words = 0 <TAB> count = 0 <TAB> for p in _para_re.split(docstring): <TAB>  <TAB> p = p.strip() <TAB>  <TAB> if not p: <TAB>  <TAB>  <TAB> continue <MASK> if words: <TAB>  <TAB>  <TAB>  <TAB> count += 1 <TAB>  <TAB>  <TAB>  <TAB> words = 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> words = 1 <TAB> return count or 1,"if p . startswith ( "">>> "" ) :",105
"def drop_temporary( <TAB> pr: PullRequestDetails, <TAB> problem: Optional[CannotAutomergeError], <TAB> prev_seen_times: Dict[int, datetime.datetime], <TAB> next_seen_times: Dict[int, datetime.datetime],) -> Optional[CannotAutomergeError]: <TAB> """"""Filters out problems that may be temporary."""""" <TAB> if problem is not None and problem.may_be_temporary: <TAB>  <TAB> since = prev_seen_times.get(pr.pull_id, datetime.datetime.utcnow()) <MASK> next_seen_times[pr.pull_id] = since <TAB>  <TAB>  <TAB> return None <TAB> return problem",if is_recent_date ( since ) :,160
"def findPackageContents(name, searchpath=None): <TAB> head = name.split(""."")[-1] <TAB> if identifierRE.match(head) is None: <TAB>  <TAB> return {} <TAB> try: <TAB>  <TAB> fp, path, (ext, mode, tp) = imp.find_module(head, searchpath) <TAB> except ImportError: <TAB>  <TAB> return {} <TAB> modules = {name: None} <TAB> if tp == imp.PKG_DIRECTORY and path: <TAB>  <TAB> files = os.listdir(path) <TAB>  <TAB> for sub in files: <TAB>  <TAB>  <TAB> sub, ext = os.path.splitext(sub) <TAB>  <TAB>  <TAB> fullname = name + ""."" + sub <MASK> modules.update(findPackageContents(fullname, [path])) <TAB> return modules","if sub != ""__init__"" and fullname not in modules :",185
"def register_udf_groups(conn, *groups): <TAB> seen = set() <TAB> for group in groups: <TAB>  <TAB> functions = UDF_COLLECTION[group] <TAB>  <TAB> for function in functions: <TAB>  <TAB>  <TAB> name = function.__name__ <MASK> seen.add(name) <TAB>  <TAB>  <TAB>  <TAB> conn.create_function(name, -1, function)",if name not in seen :,95
"def _str_index(self): <TAB> idx = self[""index""] <TAB> out = [] <TAB> if len(idx) == 0: <TAB>  <TAB> return out <TAB> out += ["".. index:: %s"" % idx.get(""default"", """")] <TAB> for section, references in idx.items(): <TAB>  <TAB> if section == ""default"": <TAB>  <TAB>  <TAB> continue <MASK> out += [""   single: %s"" % ("", "".join(references))] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> out += [""   {}: {}"".format(section, "","".join(references))] <TAB> out += [""""] <TAB> return out","elif section == ""refguide"" :",146
"def recreateGnxDict(self): <TAB> """"""Recreate the gnx dict prior to refreshing nodes from disk."""""" <TAB> c, d = self, {} <TAB> for v in c.all_unique_nodes(): <TAB>  <TAB> gnxString = v.fileIndex <TAB>  <TAB> if g.isString(gnxString): <TAB>  <TAB>  <TAB> d[gnxString] = v <MASK> g.trace(c.shortFileName(), gnxString, v) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> g.internalError(""no gnx for vnode: %s"" % (v)) <TAB> c.fileCommands.gnxDict = d","if ""gnx"" in g . app . debug :",159
"def copy_region_to_clipboard(self):  # () <TAB> """"""Copy the text in the region to the windows clipboard."""""" <TAB> if self.enable_win32_clipboard: <TAB>  <TAB> mark = min(self.mark, len(self.line_buffer)) <TAB>  <TAB> cursor = min(self.point, len(self.line_buffer)) <MASK> return <TAB>  <TAB> begin = min(cursor, mark) <TAB>  <TAB> end = max(cursor, mark) <TAB>  <TAB> toclipboard = """".join(self.line_buffer[begin:end]) <TAB>  <TAB> clipboard.SetClipboardText(toclipboard)",if self . mark == - 1 :,150
"def filter_output(output, incoming): <TAB> for filter in output.filters: <TAB>  <TAB> try: <MASK> return True  # do not create this dataset <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> log.debug(""Dataset output filter failed: %s"" % e) <TAB> return False","if not eval ( filter . text . strip ( ) , globals ( ) , incoming ) :",87
"def _generate_upgrade_checklist(self): <TAB> for (store_name, store) in self.data_context.stores.items(): <MASK> continue <TAB>  <TAB> elif isinstance(store, ValidationsStore): <TAB>  <TAB>  <TAB> self._process_validations_store_for_checklist(store_name, store) <TAB>  <TAB> elif isinstance(store, MetricStore): <TAB>  <TAB>  <TAB> self._process_metrics_store_for_checklist(store_name, store) <TAB> sites = self.data_context.project_config_with_variables_substituted.data_docs_sites <TAB> if sites: <TAB>  <TAB> for site_name, site_config in sites.items(): <TAB>  <TAB>  <TAB> self._process_docs_site_for_checklist(site_name, site_config)","if not isinstance ( store , ( ValidationsStore , MetricStore ) ) :",197
"def loadConfiguration(systemOnly=False): <TAB> global config, _errorReport, language <TAB> if systemOnly: <TAB>  <TAB> config.read(iniSystem) <TAB> else: <TAB>  <TAB> config.read([iniSystem, iniUser]) <TAB>  <TAB> _errorReport = getInt(""Connection"", ""errorreport"", 1) <TAB>  <TAB> language = getStr(__prg__, ""language"") <MASK> # replace language <TAB>  <TAB>  <TAB> __builtin__._ = gettext.translation( <TAB>  <TAB>  <TAB>  <TAB> ""bCNC"", <TAB>  <TAB>  <TAB>  <TAB> os.path.join(prgpath, ""locale""), <TAB>  <TAB>  <TAB>  <TAB> fallback=True, <TAB>  <TAB>  <TAB>  <TAB> languages=[language], <TAB>  <TAB>  <TAB> ).gettext",if language :,162
"def harmonic_mean(a, weights=None): <TAB> if any([x == 0 for x in a]): <TAB>  <TAB> return 0 <TAB> else: <TAB>  <TAB> assert weights is None or len(weights) == len( <TAB>  <TAB>  <TAB> a <TAB>  <TAB> ), ""Weights has length {} which is different from that of the array ({})."".format( <TAB>  <TAB>  <TAB> len(weights), len(a) <TAB>  <TAB> ) <MASK> return len(a) / sum([1 / x for x in a]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return sum(weights) / sum(w / x for x, w in zip(a, weights))",if weights is None :,151
"def add_child(self, router, index=None): <TAB> """"""Add a new :class:`Router` to the :attr:`routes` list."""""" <TAB> assert isinstance(router, Router), ""Not a valid Router"" <TAB> assert router is not self, ""cannot add self to children"" <TAB> for r in self.routes: <TAB>  <TAB> if r == router: <TAB>  <TAB>  <TAB> return r <MASK> raise ValueError(""Cannot add route %s. Already avalable"" % r._route) <TAB> # <TAB> # Remove from previous parent <TAB> if router.parent: <TAB>  <TAB> router.parent.remove_child(router) <TAB> router._parent = self <TAB> if index is None: <TAB>  <TAB> self.routes.append(router) <TAB> else: <TAB>  <TAB> self.routes.insert(index, router) <TAB> return router",elif r . _route == router . _route :,199
"def is_parseable(val): <TAB> try: <MASK> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""Values passed to expect_column_values_to_be_edtf_parseable must be of type string.\nIf you want to validate a column of dates or timestamps, please call the expectation before converting from string format."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> parse_edtf(val) <TAB>  <TAB> return True <TAB> except (ValueError, OverflowError): <TAB>  <TAB> return False",if type ( val ) != str :,117
"def update(self, gold_sent, pred_sent): <TAB> i = 0 <TAB> j = 0 <TAB> id = 0 <TAB> for w in gold_sent: <MASK> self.tot += 1 <TAB>  <TAB>  <TAB> while i + len(pred_sent[id]) <= j: <TAB>  <TAB>  <TAB>  <TAB> i += len(pred_sent[id]) <TAB>  <TAB>  <TAB>  <TAB> id += 1 <TAB>  <TAB>  <TAB> if i == j and len(pred_sent[id]) == len(w) and w.find(pred_sent[id]) != -1: <TAB>  <TAB>  <TAB>  <TAB> self.recall += 1 <TAB>  <TAB> j += len(w)",if w not in self . dic :,155
"def starttag(self): <TAB> parts = [self.tagname] <TAB> for name, value in self.attlist(): <MASK> # boolean attribute <TAB>  <TAB>  <TAB> parts.append(name) <TAB>  <TAB> elif isinstance(value, ListType): <TAB>  <TAB>  <TAB> values = [serial_escape(""%s"" % v) for v in value] <TAB>  <TAB>  <TAB> parts.append('%s=""%s""' % (name, "" "".join(values))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> parts.append('%s=""%s""' % (name, value)) <TAB> return ""<%s>"" % "" "".join(parts)",if value is None :,140
"def generate(): <TAB> try: <TAB>  <TAB> # Special case for urllib3. <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> for chunk in self.raw.stream(chunk_size, decode_content=True): <TAB>  <TAB>  <TAB>  <TAB> yield chunk <TAB>  <TAB> except IncompleteRead as e: <TAB>  <TAB>  <TAB> raise ChunkedEncodingError(e) <TAB>  <TAB> except DecodeError as e: <TAB>  <TAB>  <TAB> raise ContentDecodingError(e) <TAB> except AttributeError: <TAB>  <TAB> # Standard file-like object. <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> chunk = self.raw.read(chunk_size) <MASK> break <TAB>  <TAB>  <TAB> yield chunk <TAB> self._content_consumed = True",if not chunk :,161
"def inner_wrapper(request, *args, **kwargs): <TAB> url = initial_url = request.full_url if isinstance(request, Request) else request <TAB> for _ in range(max_redirects + 1): <TAB>  <TAB> response = fn(request, *args, **kwargs) <TAB>  <TAB> if response.url == url or response.url is None: <MASK> warnings.warn(f""The URL {initial_url} ultimately redirects to {url}."") <TAB>  <TAB>  <TAB> return response <TAB>  <TAB> url = response.url <TAB> else: <TAB>  <TAB> raise RecursionError( <TAB>  <TAB>  <TAB> f""Request to {initial_url} exceeded {max_redirects} redirects."" <TAB>  <TAB> )",if url != initial_url :,167
"def filter_before(res_list, before_time): <TAB> before_time = time_parse(before_time) <TAB> new_res_list = [] <TAB> for res in res_list: <TAB>  <TAB> if ""time_first"" in res: <MASK> new_res_list.append(res) <TAB>  <TAB> elif ""zone_time_first"" in res: <TAB>  <TAB>  <TAB> if res[""zone_time_first""] < before_time: <TAB>  <TAB>  <TAB>  <TAB> new_res_list.append(res) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_res_list.append(res) <TAB> return new_res_list","if res [ ""time_first"" ] < before_time :",163
"def split_types(rawdump): <TAB> """"""Write each type of objects in separate files."""""" <TAB> files = {} <TAB> if not os.path.exists(""type""): <TAB>  <TAB> os.mkdir(""type"") <TAB> for key, type, json_data in read_rawdump(rawdump): <MASK> files[type] = open(type[1:] + "".txt"", ""w"") <TAB>  <TAB> files[type].write(""\t"".join([key, type, json_data])) <TAB> for t in files: <TAB>  <TAB> files[t].close()",if type not in files :,134
"def vector_values(v, types): <TAB> vv = {} <TAB> first = v.index(int(np.nanmin(v))) <TAB> last = v.index(int(np.nanmax(v))) <TAB> vv[""size""] = (last - first) + 1 <TAB> vv[""distance""] = len(v) - last <TAB> vv[""stop_count""] = 0 <TAB> vv[""misses""] = 0 <TAB> for i in range(first, last + 1): <TAB>  <TAB> if v[i] >= 0 and types[i] == ""s"": <TAB>  <TAB>  <TAB> vv[""stop_count""] += 1 <MASK> vv[""misses""] += 1 <TAB> return vv","elif v [ i ] is None and types [ i ] not in [ ""s"" , ""h"" ] :",173
"def swap(self): <TAB> if self.picked_pair: <TAB>  <TAB> swap_inds = self.manager.get_swap_indices(*self.picked_pair) <TAB>  <TAB> inds = np.insert(swap_inds, [0, len(swap_inds)], [0, self.manager.nframes - 1]) <MASK> ind = np.argmax(inds > self.curr_frame) <TAB>  <TAB>  <TAB> self.manager.swap_tracklets( <TAB>  <TAB>  <TAB>  <TAB> *self.picked_pair, range(inds[ind - 1], inds[ind] + 1) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.display_traces() <TAB>  <TAB>  <TAB> self.slider.set_val(self.curr_frame)",if len ( inds ) :,169
"def addDirectory(self, dir, parentDirName=None): <TAB> if not dir.isDirectory(): <TAB>  <TAB> return <TAB> filesInDir = dir.listFiles() <TAB> for currentFile in filesInDir: <TAB>  <TAB> if currentFile.isFile(): <MASK> self.addFile(currentFile, parentDirName + ""/"" + dir.getName()) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.addFile(currentFile, dir.getName()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if parentDirName: <TAB>  <TAB>  <TAB>  <TAB> newParentDirName = parentDirName + ""/"" + dir.getName() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> newParentDirName = dir.getName() <TAB>  <TAB>  <TAB> self.addDirectory(currentFile, newParentDirName)",if parentDirName :,189
"def scan_batch_iter(data, batch_size, fid, num_workers): <TAB> """"""scan_batch_iter"""""" <TAB> batch = [] <TAB> cc = 0 <TAB> for line_example in data.scan(): <TAB>  <TAB> cc += 1 <MASK> continue <TAB>  <TAB> batch.append(line_example) <TAB>  <TAB> if len(batch) == batch_size: <TAB>  <TAB>  <TAB> yield batch <TAB>  <TAB>  <TAB> batch = [] <TAB> if len(batch) > 0: <TAB>  <TAB> yield batch",if cc % num_workers != fid :,125
"def test_documentation_includes_signals(app): <TAB> with suppress(ImportError): <TAB>  <TAB> module = importlib.import_module(app + "".signals"") <TAB>  <TAB> missing = [] <TAB>  <TAB> for key in dir(module): <TAB>  <TAB>  <TAB> attrib = getattr(module, key) <MASK> if key not in plugin_docs: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> missing.append(key) <TAB>  <TAB> assert not missing, ""The following signals are undocumented: %r"" % missing","if isinstance ( attrib , Signal ) and not isinstance ( attrib , DeprecatedSignal ) :",127
"def result(success, message=None, comment=None): <TAB> if request.is_xhr: <TAB>  <TAB> result = dict(success=success, message=message) <MASK> result[""comment""] = render( <TAB>  <TAB>  <TAB>  <TAB> ""comments/_list.html"", {""comment_to_render"": comment}, method=""xhtml"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return result <TAB> elif success: <TAB>  <TAB> return redirect(action=""view"") <TAB> else: <TAB>  <TAB> return self.view(slug, name=name, email=email, body=body, **kwargs)",if comment :,134
"def read_bzs(fn): <TAB> result = [] <TAB> for l in file(fn): <TAB>  <TAB> z = [float(z) for z in l.split()] <TAB>  <TAB> bz = ((z[0], z[1]), (z[2], z[3]), (z[4], z[5])) <MASK> bz = (bz[0], bz[2]) <TAB>  <TAB> result.append(bz) <TAB> return result","if bz [ 1 ] == lerppt ( 0.5 , bz [ 0 ] , bz [ 2 ] ) :",126
"def __getitem__(cls, grade) -> ""_GradedTypesMeta"": <TAB> """"""Get the grade-specific type. Used to implement ``Blade[n]``."""""" <TAB> if cls.__instantiated: <TAB>  <TAB> raise TypeError(""Cannot index multiple times"") <TAB> try: <TAB>  <TAB> return cls.__graded_types[grade] <TAB> except KeyError: <TAB>  <TAB> # augment the bases with the instantiated versions of themselves <TAB>  <TAB> bases = (cls,) <TAB>  <TAB> for b in cls.__bases__: <MASK> bases = (b[grade],) + bases <TAB>  <TAB> subcls = cls.__graded_types[grade] = type( <TAB>  <TAB>  <TAB> ""{}[{}]"".format(cls.__name__, grade), bases, dict(_grade=grade) <TAB>  <TAB> ) <TAB>  <TAB> return subcls","if isinstance ( b , _GradedTypesMeta ) and not b . __instantiated :",193
"def _flow_close(self): <TAB> rv = [] <TAB> for pipe in reversed(self.pipes): <TAB>  <TAB> if pipe._pipeline_all_methods_.issuperset({""close"", self._method_close}): <TAB>  <TAB>  <TAB> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB> f""{pipe.__class__.__name__} pipe has double close methods."" <TAB>  <TAB>  <TAB>  <TAB> f"" Use `close` or `{self._method_close}`, not both."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if ""close"" in pipe._pipeline_all_methods_: <TAB>  <TAB>  <TAB> rv.append(pipe.close) <MASK> rv.append(getattr(pipe, self._method_close)) <TAB> return rv",if self . _method_close in pipe . _pipeline_all_methods_ :,169
"def test_slow_interrupted(self): <TAB> # Issue #25373: test --slowest with an interrupted test <TAB> code = TEST_INTERRUPTED <TAB> test = self.create_test(""sigint"", code=code) <TAB> try: <TAB>  <TAB> import threading <TAB>  <TAB> tests = (False, True) <TAB> except ImportError: <TAB>  <TAB> tests = (False,) <TAB> for multiprocessing in tests: <MASK> args = (""--slowest"", ""-j2"", test) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> args = (""--slowest"", test) <TAB>  <TAB> output = self.run_tests(*args, exitcode=130) <TAB>  <TAB> self.check_executed_tests(output, test, omitted=test, interrupted=True) <TAB>  <TAB> regex = ""10 slowest tests:\n"" <TAB>  <TAB> self.check_line(output, regex)",if multiprocessing :,198
"def get_volume_io_group(self, vol_name): <TAB> vdisk = self.ssh.lsvdisk(vol_name) <TAB> if vdisk: <TAB>  <TAB> resp = self.ssh.lsiogrp() <TAB>  <TAB> for iogrp in resp: <MASK> return int(iogrp[""id""]) <TAB> return None","if iogrp [ ""name"" ] == vdisk [ ""IO_group_name"" ] :",100
"def close(self): <TAB> if self._data is not None: <TAB>  <TAB> filename = self.filename() <TAB>  <TAB> exists = os.path.exists(filename) <MASK> if exists: <TAB>  <TAB>  <TAB>  <TAB> os.unlink(filename) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> f = open(filename, ""wb"") <TAB>  <TAB>  <TAB> cPickle.dump(self._data, f) <TAB>  <TAB>  <TAB> f.close() <TAB>  <TAB>  <TAB> if not exists and self.chmod: <TAB>  <TAB>  <TAB>  <TAB> os.chmod(filename, self.chmod)",if not self . _data :,132
"def sizeof_fmt(size): <TAB> for x in (""B"", ""kB"", ""MB"", ""GB"", ""TB""): <MASK> if x in (""B"", ""kB""): <TAB>  <TAB>  <TAB>  <TAB> return ""%3.0f %s"" % (size, x) <TAB>  <TAB>  <TAB> return ""%3.2f %s"" % (size, x) <TAB>  <TAB> size /= 1024.0",if size < 1024.0 :,101
"def worker(m): <TAB> try: <TAB>  <TAB> if not should_do(m, include, exclude): <TAB>  <TAB>  <TAB> return <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> for dep in m._wait_for: <TAB>  <TAB>  <TAB>  <TAB> dep._destroyed_event.wait() <TAB>  <TAB>  <TAB>  <TAB> # !!! Should we print a message here? <MASK> m._errored = True <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> if m.destroy(wipe=wipe): <TAB>  <TAB>  <TAB> self.delete_resource(m) <TAB> except: <TAB>  <TAB> m._errored = True <TAB>  <TAB> raise <TAB> finally: <TAB>  <TAB> m._destroyed_event.set()",if dep . _errored :,175
"def __call__(self, value): <TAB> try: <TAB>  <TAB> value = super(NewType, self).__call__(value) <TAB>  <TAB> return function(value) <TAB> except Exception as exception: <TAB>  <TAB> for take_exception, rewrite in exception_handlers.items(): <TAB>  <TAB>  <TAB> if isinstance(exception, take_exception): <TAB>  <TAB>  <TAB>  <TAB> if isinstance(rewrite, str): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(rewrite) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise rewrite(value) <MASK> raise ValueError(error_text) <TAB>  <TAB> raise exception",if error_text :,137
"def _dispatch(self, msg): <TAB> channel = msg.get(""ev"") <TAB> for pat, handler in self._handlers.items(): <MASK> handled_symbols = self._handler_symbols.get(handler) <TAB>  <TAB>  <TAB> if handled_symbols is None or msg[""sym""] in handled_symbols: <TAB>  <TAB>  <TAB>  <TAB> if self._use_raw_data: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> await handler(self, channel, msg) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ent = self._cast(channel, msg) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> await handler(self, channel, ent)",if pat . match ( channel ) :,147
"def load_framework(self, path): <TAB> realpath = self.find_framework(path) <TAB> if realpath: <TAB>  <TAB> lib = ctypes.cdll.LoadLibrary(realpath) <TAB>  <TAB> if _debug_lib: <TAB>  <TAB>  <TAB> print(realpath) <MASK> lib = _TraceLibrary(lib) <TAB>  <TAB> return lib <TAB> raise ImportError(""Can't find framework %s."" % path)",if _debug_trace :,100
"def _reopen(self): <TAB> if self.file and self.file.closed: <TAB>  <TAB> mod_type = self.etc[2] <TAB>  <TAB> if mod_type == imp.PY_SOURCE: <TAB>  <TAB>  <TAB> self.file = open(self.filename, ""r"") <MASK> self.file = open(self.filename, ""rb"")","elif mod_type in ( imp . PY_COMPILED , imp . C_EXTENSION ) :",105
"def add_members(self, members): <TAB> self.buffer.extend(members) <TAB> if self.cache: <TAB>  <TAB> guild = self.resolver(self.guild_id) <TAB>  <TAB> if guild is None: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> for member in members: <TAB>  <TAB>  <TAB> existing = guild.get_member(member.id) <MASK> guild._add_member(member)",if existing is None or existing . joined_at is None :,114
"def add_resources(self, resource_arns): <TAB> for resource in resource_arns: <TAB>  <TAB> match = re.search( <TAB>  <TAB>  <TAB> r""^arn:aws:[a-z0-9-]+:[a-z0-9-]*:[0-9]{12}:([a-z-]+)[/:].*$"", resource <TAB>  <TAB> ) <MASK> raise MalformedArnException( <TAB>  <TAB>  <TAB>  <TAB> ""The specified resource ARN {} is not valid. "" <TAB>  <TAB>  <TAB>  <TAB> ""Verify the ARN and try again."".format(resource) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if match.group(1) not in self.SHAREABLE_RESOURCES: <TAB>  <TAB>  <TAB> raise MalformedArnException(""You cannot share the selected resource type."") <TAB> for resource in resource_arns: <TAB>  <TAB> self.resource_arns.append(resource)",if not match :,192
"def make_key_value(self, data): <TAB> if data.get(""_t"") == ""media"" and ( <TAB>  <TAB> data.get(""identifier"") or data.get(""identifiers"") <TAB> ): <TAB>  <TAB> identifiers = data.get(""identifiers"", {}) <MASK> identifiers[""imdb""] = data.get(""identifier"") <TAB>  <TAB> ids = [] <TAB>  <TAB> for x in identifiers: <TAB>  <TAB>  <TAB> ids.append(md5(""%s-%s"" % (x, identifiers[x])).hexdigest()) <TAB>  <TAB> return ids, None","if data . get ( ""identifier"" ) and ""imdb"" not in identifiers :",137
"def func_shorten(func_tuple): <TAB> f = func_tuple[0] <TAB> for t in shorten_list: <TAB>  <TAB> i = f.find(t[0]) <TAB>  <TAB> if i >= 0: <MASK> i = i + len(t[0]) <TAB>  <TAB>  <TAB> return (f[i:],) + func_tuple[1:] <TAB> return func_tuple",if t [ 1 ] :,98
"def get_profile_name(profile_file): <TAB> """"""Read the profile name from file."""""" <TAB> profiles = set() <TAB> try: <TAB>  <TAB> with profile_file.open(""r"") as profile_data: <TAB>  <TAB>  <TAB> for line in profile_data: <TAB>  <TAB>  <TAB>  <TAB> match = RE_PROFILE.match(line) <MASK> continue <TAB>  <TAB>  <TAB>  <TAB> profiles.add(match.group(1)) <TAB> except OSError as err: <TAB>  <TAB> _LOGGER.error(""Can't read AppArmor profile: %s"", err) <TAB>  <TAB> raise AppArmorFileError() from err <TAB> if len(profiles) != 1: <TAB>  <TAB> _LOGGER.error(""To many profiles inside file: %s"", profiles) <TAB>  <TAB> raise AppArmorInvalidError() <TAB> return profiles.pop()",if not match :,193
"def _get_streams(self): <TAB> res = http.get(self.url, schema=_schema) <TAB> streams = {} <TAB> for url in res[""urls""]: <TAB>  <TAB> parsed = urlparse(url) <TAB>  <TAB> if parsed.scheme.startswith(""rtmp""): <TAB>  <TAB>  <TAB> params = {""rtmp"": url, ""pageUrl"": self.url, ""live"": True} <TAB>  <TAB>  <TAB> if res[""swf""]: <TAB>  <TAB>  <TAB>  <TAB> params[""swfVfy""] = res[""swf""] <TAB>  <TAB>  <TAB> stream = RTMPStream(self.session, params) <TAB>  <TAB>  <TAB> streams[""live""] = stream <MASK> name = splitext(parsed.path)[1][1:] <TAB>  <TAB>  <TAB> stream = HTTPStream(self.session, url) <TAB>  <TAB>  <TAB> streams[name] = stream <TAB> return streams","elif parsed . scheme . startswith ( ""http"" ) :",197
"def test_errorhandle(self): <TAB> for source, scheme, expected in self.codectests: <MASK> func = self.decode <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> func = self.encode <TAB>  <TAB> if expected: <TAB>  <TAB>  <TAB> result = func(source, scheme)[0] <TAB>  <TAB>  <TAB> self.assertEqual(result, expected) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertRaises(UnicodeError, func, source, scheme)","if type ( source ) == type ( """" ) :",112
"def _parse(self): <TAB> logger = logging.getLogger(""beaver"") <TAB> glob_paths = {} <TAB> inputs = {} <TAB> for filename in self._config.sections(): <MASK> raise Exception('%s: missing mandatory config ""type""' % filename) <TAB>  <TAB> config = dict((x[0], x[1]) for x in self._config.items(filename)) <TAB>  <TAB> glob_paths[filename] = config <TAB>  <TAB> globs = glob.glob(filename) <TAB>  <TAB> if not globs: <TAB>  <TAB>  <TAB> logger.info(""Skipping glob due to no files found: %s"" % filename) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for globbed in globs: <TAB>  <TAB>  <TAB> inputs[os.path.realpath(globbed)] = config <TAB> return inputs, glob_paths","if not self . _config . get ( filename , ""type"" ) :",191
"def _return_wrapped(*args, **kwargs): <TAB> """"""Internal wrapper function."""""" <TAB> argspec = inspect.getfullargspec(function_to_decorate) <TAB> valid_names = set(argspec.args + argspec.kwonlyargs) <TAB> if ""self"" in valid_names: <TAB>  <TAB> valid_names.remove(""self"") <TAB> for arg_name in kwargs: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Unknown argument seen '%s', expected: [%s]"" <TAB>  <TAB>  <TAB>  <TAB> % (arg_name, "", "".join(valid_names)) <TAB>  <TAB>  <TAB> ) <TAB> return function_to_decorate(*args, **kwargs)",if arg_name not in valid_names :,155
"def __iter__(self): <TAB> bs = self.batch_size <TAB> for i in range((self.n_samples + bs - 1) // bs): <TAB>  <TAB> sl = slice(i * bs, (i + 1) * bs) <TAB>  <TAB> Xb = _sldict(self.X, sl) <MASK> yb = _sldict(self.y, sl) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yb = None <TAB>  <TAB> yield self.transform(Xb, yb)",if self . y is not None :,125
"def find_files_by_output_prefix(cls, output_file_prefix, endswith=None): <TAB> """"""Finds all files in the temp directory that start with the output_file_prefix"""""" <TAB> result = [] <TAB> temp = Configuration.temp() <TAB> for fil in os.listdir(temp): <TAB>  <TAB> if not fil.startswith(output_file_prefix): <TAB>  <TAB>  <TAB> continue <MASK> result.append(os.path.join(temp, fil)) <TAB> return result",if endswith is None or fil . endswith ( endswith ) :,126
"def can_add_hostname(args): <TAB> # return False if --hostname is already specified or if --network=host <TAB> if is_network_host(args): <TAB>  <TAB> return False <TAB> for index, arg in enumerate(args): <TAB>  <TAB> # Check for --hostname and variants <TAB>  <TAB> if arg == ""-h"": <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> if arg.startswith(""--hostname""): <TAB>  <TAB>  <TAB> return False <MASK> # several short args <TAB>  <TAB>  <TAB> arg = arg.partition(""="")[0] <TAB>  <TAB>  <TAB> if ""h"" in arg: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return True","if len ( arg ) > 1 and arg [ 0 ] == ""-"" and arg [ 1 ] != ""-"" :",161
"def get(self): <TAB> """"""Get the value"""""" <TAB> val = self.db.get_attributes(self.id, consistent_read=True) <TAB> if val: <MASK> self.timestamp = val[""timestamp""] <TAB>  <TAB> if ""current_value"" in val: <TAB>  <TAB>  <TAB> self._value = self.item_type(val[""current_value""]) <TAB>  <TAB> if ""last_value"" in val and val[""last_value""] is not None: <TAB>  <TAB>  <TAB> self.last_value = self.item_type(val[""last_value""]) <TAB> return self._value","if ""timestamp"" in val :",144
"def do_longs(opts, opt, longopts, args): <TAB> try: <TAB>  <TAB> i = opt.index(""="") <TAB> except ValueError: <TAB>  <TAB> optarg = None <TAB> else: <TAB>  <TAB> opt, optarg = opt[:i], opt[i + 1 :] <TAB> has_arg, opt = long_has_args(opt, longopts) <TAB> if has_arg: <TAB>  <TAB> if optarg is None: <MASK> raise GetoptError(_(""option --%s requires argument"") % opt, opt) <TAB>  <TAB>  <TAB> optarg, args = args[0], args[1:] <TAB> elif optarg is not None: <TAB>  <TAB> raise GetoptError(_(""option --%s must not have an argument"") % opt, opt) <TAB> opts.append((""--"" + opt, optarg or """")) <TAB> return opts, args",if not args :,184
"def _process_msg(self, msg): <TAB> if all(c in msg for c in [""x0"", ""y0"", ""x1"", ""y1""]): <MASK> msg[""x0""] = convert_timestamp(msg[""x0""]) <TAB>  <TAB>  <TAB> msg[""x1""] = convert_timestamp(msg[""x1""]) <TAB>  <TAB> if isinstance(self.plot.handles.get(""yaxis""), DatetimeAxis): <TAB>  <TAB>  <TAB> msg[""y0""] = convert_timestamp(msg[""y0""]) <TAB>  <TAB>  <TAB> msg[""y1""] = convert_timestamp(msg[""y1""]) <TAB>  <TAB> return {""bounds"": (msg[""x0""], msg[""y0""], msg[""x1""], msg[""y1""])} <TAB> else: <TAB>  <TAB> return {}","if isinstance ( self . plot . handles . get ( ""xaxis"" ) , DatetimeAxis ) :",190
"def create(self, private=False): <TAB> try: <MASK> log.info(""Creating group %s."", self) <TAB>  <TAB>  <TAB> self._bot.webclient.groups_create(name=self.name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.info(""Creating channel %s."", self) <TAB>  <TAB>  <TAB> self._bot.webclient.channels_create(name=self.name) <TAB> except SlackAPIResponseError as e: <TAB>  <TAB> if e.error == ""user_is_bot"": <TAB>  <TAB>  <TAB> raise RoomError(f""Unable to create channel. {USER_IS_BOT_HELPTEXT}"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise RoomError(e)",if private :,164
"def filter_after(res_list, after_time): <TAB> after_time = time_parse(after_time) <TAB> new_res_list = [] <TAB> for res in res_list: <MASK> if res[""time_last""] > after_time: <TAB>  <TAB>  <TAB>  <TAB> new_res_list.append(res) <TAB>  <TAB> elif ""zone_time_last"" in res: <TAB>  <TAB>  <TAB> if res[""zone_time_last""] > after_time: <TAB>  <TAB>  <TAB>  <TAB> new_res_list.append(res) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_res_list.append(res) <TAB> return new_res_list","if ""time_last"" in res :",163
"def CmdMemberListbox(self, id, code): <TAB> if code == win32con.LBN_SELCHANGE: <TAB>  <TAB> self.paramlb.ResetContent() <TAB>  <TAB> pos = self.memberlb.GetCurSel() <TAB>  <TAB> realPos, isMethod = self._GetRealMemberPos(pos) <TAB>  <TAB> if isMethod: <TAB>  <TAB>  <TAB> id = self.typeinfo.GetFuncDesc(realPos)[0] <TAB>  <TAB>  <TAB> names = self.typeinfo.GetNames(id) <TAB>  <TAB>  <TAB> for i in range(len(names)): <MASK> self.paramlb.AddString(names[i]) <TAB>  <TAB> self.SetupAllInfoTypes() <TAB>  <TAB> return 1",if i > 0 :,168
"def fixfocus(near, itop): <TAB> n = scanbox.size() <TAB> for i in range(n): <TAB>  <TAB> line = scanbox.get(repr(i)) <TAB>  <TAB> if scanparser.match(line) >= 0: <TAB>  <TAB>  <TAB> num = string.atoi(scanparser.group(1)) <MASK> break <TAB> else: <TAB>  <TAB> i = ""end"" <TAB> scanbox.select_from(i) <TAB> scanbox.yview(itop)",if num >= near :,122
"def _find_loop(self, u, vis, stack, loops): <TAB> vis[u] = True <TAB> stack.append(u) <TAB> for down_name in self.component_downstream[u]: <TAB>  <TAB> if loops: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> v = self.component_name_index.get(down_name) <MASK> if not vis[v]: <TAB>  <TAB>  <TAB>  <TAB> self._find_loop(v, vis, stack, loops) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> index = stack.index(v) <TAB>  <TAB>  <TAB> for node in stack[index:]: <TAB>  <TAB>  <TAB>  <TAB> loops.append(self.components[node].get_name()) <TAB>  <TAB>  <TAB> return <TAB> stack.pop(-1)",if v not in stack :,177
"def _get_start_char(cx, cy): <TAB> needle = self.get_from(cx, cy) <TAB> if needle is not None: <TAB>  <TAB> letter, cfg, _, cbg = needle <MASK> return line_chars.find(chr(letter)) <TAB> return 0",if colour == cfg and bg == cbg and chr ( letter ) in line_chars :,88
"def replace_dict(src, dest): <TAB> seen = [] <TAB> for name in dest.copy().keys(): <TAB>  <TAB> seen.append(name) <MASK> del dest[name] <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if dest[name] is not src[name]: <TAB>  <TAB>  <TAB> dest[name] = src[name] <TAB> for name in src.keys(): <TAB>  <TAB> if name in seen: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> dest[name] = src[name] <TAB> assert src == dest",if name not in src :,125
"def non_terminated_node_ips(self, tag_filters): <TAB> with self.lock: <MASK> raise Exception(""oops"") <TAB>  <TAB> return [ <TAB>  <TAB>  <TAB> n.internal_ip <TAB>  <TAB>  <TAB> for n in self.mock_nodes.values() <TAB>  <TAB>  <TAB> if n.matches(tag_filters) and n.state not in [""stopped"", ""terminated""] <TAB>  <TAB> ]",if self . throw :,98
"def check_splitter(command): <TAB> """"""Check xld or shntool installed"""""" <TAB> try: <TAB>  <TAB> env = os.environ.copy() <TAB>  <TAB> if ""xld"" in command: <TAB>  <TAB>  <TAB> env[""PATH""] += os.pathsep + ""/Applications"" <TAB>  <TAB> elif headphones.CONFIG.CUE_SPLIT_FLAC_PATH: <TAB>  <TAB>  <TAB> command = os.path.join(headphones.CONFIG.CUE_SPLIT_SHNTOOL_PATH, ""shntool"") <TAB>  <TAB> devnull = open(os.devnull) <TAB>  <TAB> subprocess.Popen( <TAB>  <TAB>  <TAB> [command], stdout=devnull, stderr=devnull, env=env <TAB>  <TAB> ).communicate() <TAB> except OSError as e: <MASK> return False <TAB> return True",if e . errno == os . errno . ENOENT :,189
"def _choose_nonull_or_dflt(self, dflt, *args): <TAB> if isinstance(dflt, basestring): <TAB>  <TAB> dflttyp = basestring  # Allow any string type <TAB> else: <TAB>  <TAB> dflttyp = type(dflt) <TAB> for arg in args: <TAB>  <TAB> if arg is not None: <MASK> return arg <TAB>  <TAB>  <TAB> if __debug__: <TAB>  <TAB>  <TAB>  <TAB> self._log(0, ""bad arg is %s, expecting %s"" % (type(arg), dflttyp)) <TAB> return dflt","if isinstance ( arg , dflttyp ) :",142
"def add_images(self, images, image_group): <TAB> self.images = [] <TAB> for image in images: <TAB>  <TAB> image_name = os.path.basename(image[""url""]) <MASK> continue <TAB>  <TAB> new_image = { <TAB>  <TAB>  <TAB> ""file_name"": image_name, <TAB>  <TAB>  <TAB> ""id"": image[""image_id""], <TAB>  <TAB>  <TAB> ""height"": image[""height""], <TAB>  <TAB>  <TAB> ""width"": image[""width""], <TAB>  <TAB> } <TAB>  <TAB> self.images.append(new_image)",if image_name not in image_group :,136
"def checkdep_pdftops(): <TAB> try: <TAB>  <TAB> s = subprocess.Popen( <TAB>  <TAB>  <TAB> [""pdftops"", ""-v""], stdout=subprocess.PIPE, stderr=subprocess.PIPE <TAB>  <TAB> ) <TAB>  <TAB> for line in s.stderr: <MASK> v = line.split()[-1] <TAB>  <TAB> return v <TAB> except (IndexError, ValueError, UnboundLocalError, OSError): <TAB>  <TAB> return None","if ""version"" in line :",107
"def get_modes(self): <TAB> device_name = self.get_device_name() <TAB> i = 0 <TAB> modes = [] <TAB> while True: <TAB>  <TAB> mode = DEVMODE() <TAB>  <TAB> mode.dmSize = sizeof(DEVMODE) <TAB>  <TAB> r = _user32.EnumDisplaySettingsW(device_name, i, byref(mode)) <MASK> break <TAB>  <TAB> modes.append(Win32ScreenMode(self, mode)) <TAB>  <TAB> i += 1 <TAB> return modes",if not r :,122
"def start_webplugin(self, web_handlers): <TAB> random_path = ""/"" + """".join( <TAB>  <TAB> random.choice(string.ascii_uppercase + string.ascii_lowercase + string.digits) <TAB>  <TAB> for _ in range(10) <TAB> ) <TAB> for tab in web_handlers: <MASK> path, handler = tab <TAB>  <TAB>  <TAB> kwargs = {} <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> path, handler, kwargs = tab <TAB>  <TAB> logging.warning(""adding handler http://127.0.0.1:9000%s"" % (random_path + path)) <TAB>  <TAB> self.app.add_handlers("".*"", [(random_path + path, handler, kwargs)]) <TAB> return ""http://127.0.0.1:%s%s"" % (self.port, random_path)",if len ( tab ) == 2 :,195
"def _should_use_real_time(): <TAB> if not call_stack_inspection_limit: <TAB>  <TAB> return False <TAB> if not ignore_lists[-1]: <TAB>  <TAB> return False <TAB> frame = inspect.currentframe().f_back.f_back <TAB> for _ in range(call_stack_inspection_limit): <TAB>  <TAB> module_name = frame.f_globals.get(""__name__"") <TAB>  <TAB> if module_name and module_name.startswith(ignore_lists[-1]): <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> frame = frame.f_back <MASK> break <TAB> return False",if frame is None :,143
"def testFeatureCount(self): <TAB> from music21 import features <TAB> fs = features.jSymbolic.extractorsById <TAB> feTotal = 0 <TAB> feImplemented = 0 <TAB> for k in fs: <TAB>  <TAB> for i in range(len(fs[k])): <TAB>  <TAB>  <TAB> if fs[k][i] is not None: <TAB>  <TAB>  <TAB>  <TAB> feTotal += 1 <MASK> feImplemented += 1 <TAB> environLocal.printDebug( <TAB>  <TAB> [ <TAB>  <TAB>  <TAB> ""fe total:"", <TAB>  <TAB>  <TAB> feTotal, <TAB>  <TAB>  <TAB> ""fe implemented"", <TAB>  <TAB>  <TAB> feImplemented, <TAB>  <TAB>  <TAB> ""percent"", <TAB>  <TAB>  <TAB> feImplemented / feTotal, <TAB>  <TAB> ] <TAB> )",if fs [ k ] [ i ] in features . jSymbolic . featureExtractors :,184
"def test_init(self): <TAB> for id_, plugin in self.plugins.items(): <MASK> self.h.plugin_enable(plugin) <TAB>  <TAB>  <TAB> self.h.handle(id_, None, None, []) <TAB>  <TAB>  <TAB> self.h.plugin_disable(plugin)",if self . h . plugin_handle ( plugin ) :,80
"def prepare_query_value(self, op, value): <TAB> if value is None: <TAB>  <TAB> return None <TAB> # XXX ValidationError raised outside of the ""validate"" method. <TAB> if isinstance(value, Document): <MASK> self.error( <TAB>  <TAB>  <TAB>  <TAB> ""You can only reference documents once they have"" <TAB>  <TAB>  <TAB>  <TAB> "" been saved to the database"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> value_dict = {""_id"": value.pk} <TAB>  <TAB> for field in self.fields: <TAB>  <TAB>  <TAB> value_dict.update({field: value[field]}) <TAB>  <TAB> return value_dict <TAB> raise NotImplementedError",if value . pk is None :,150
"def _generator(): <TAB> it = iter(text.split("" "")) <TAB> word = next(it) <TAB> yield word <TAB> pos = len(word) - word.rfind(""\n"") - 1 <TAB> for word in it: <MASK> lines = word.split(""\n"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lines = (word,) <TAB>  <TAB> pos += len(lines[0]) + 1 <TAB>  <TAB> if pos > width: <TAB>  <TAB>  <TAB> yield ""\n"" <TAB>  <TAB>  <TAB> pos = len(lines[-1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield "" "" <TAB>  <TAB>  <TAB> if len(lines) > 1: <TAB>  <TAB>  <TAB>  <TAB> pos = len(lines[-1]) <TAB>  <TAB> yield word","if ""\n"" in word :",171
"def constants_pyx(): <TAB> """"""generate CONST = ZMQ_CONST and __all__ for constants.pxi"""""" <TAB> all_lines = [] <TAB> assign_lines = [] <TAB> for name in all_names: <MASK> # avoid conflict with NULL in Cython <TAB>  <TAB>  <TAB> assign_lines.append(""globals()['NULL'] = ZMQ_NULL"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assign_lines.append(""{0} = ZMQ_{0}"".format(name)) <TAB>  <TAB> all_lines.append('  ""{0}"",'.format(name)) <TAB> return dict(ASSIGNMENTS=""\n"".join(assign_lines), ALL=""\n"".join(all_lines))","if name == ""NULL"" :",163
"def _column_default_generator( <TAB> self, <TAB> table: str, <TAB> column: str, <TAB> default: Any, <TAB> auto_now_add: bool = False, <TAB> auto_now: bool = False,) -> str: <TAB> default_str = "" DEFAULT"" <TAB> if not (auto_now or auto_now_add): <TAB>  <TAB> default_str += f"" {default}"" <TAB> else: <MASK> default_str += "" CURRENT_TIMESTAMP(6)"" <TAB>  <TAB> if auto_now: <TAB>  <TAB>  <TAB> default_str += "" ON UPDATE CURRENT_TIMESTAMP(6)"" <TAB> return default_str",if auto_now_add :,157
"def attach_to(device, changed_callback): <TAB> assert device <TAB> assert changed_callback <TAB> if not hasattr(device, ""status"") or device.status is None: <MASK> device.status = ReceiverStatus(device, changed_callback) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> device.status = DeviceStatus(device, changed_callback)",if device . kind is None :,89
"def run(self): <TAB> self.running = True <TAB> while self.running: <TAB>  <TAB> sleep(1) <TAB>  <TAB> if self.content and GUI.conversionAlive: <TAB>  <TAB>  <TAB> MW.addMessage.emit(self.content + self.progress * ""."", ""info"", True) <TAB>  <TAB>  <TAB> self.progress += 1 <MASK> self.progress = 0",if self . progress == 4 :,96
"def validate_to_follow_calendar_months(self): <TAB> if self.follow_calendar_months: <TAB>  <TAB> billing_info = self.get_billing_cycle_and_interval() <MASK> frappe.throw( <TAB>  <TAB>  <TAB>  <TAB> _(""Subscription End Date is mandatory to follow calendar months"") <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if billing_info[0][""billing_interval""] != ""Month"": <TAB>  <TAB>  <TAB> frappe.throw( <TAB>  <TAB>  <TAB>  <TAB> ""Billing Interval in Subscription Plan must be Month to follow calendar months"" <TAB>  <TAB>  <TAB> )",if not self . end_date :,143
"def add_module(self, mod): <TAB> """"""Add all the functions in a module and its classes."""""" <TAB> from inspect import isclass, isfunction <TAB> nfuncsadded = 0 <TAB> for item in mod.__dict__.values(): <TAB>  <TAB> if isclass(item): <TAB>  <TAB>  <TAB> for k, v in item.__dict__.items(): <TAB>  <TAB>  <TAB>  <TAB> if isfunction(v): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.add_function(v) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> nfuncsadded += 1 <MASK> self.add_function(item) <TAB>  <TAB>  <TAB> nfuncsadded += 1 <TAB> return nfuncsadded",elif isfunction ( item ) :,146
"def userToList(self, w, minSize=1): <TAB> items = unicode(w.text()).split("" "") <TAB> ret = [] <TAB> for i in items: <TAB>  <TAB> if not i: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> i = float(i) <TAB>  <TAB>  <TAB> assert i > 0 <MASK> i = int(i) <TAB>  <TAB>  <TAB> ret.append(i) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> # invalid, don't update <TAB>  <TAB>  <TAB> showWarning(_(""Steps must be numbers."")) <TAB>  <TAB>  <TAB> return <TAB> if len(ret) < minSize: <TAB>  <TAB> showWarning(_(""At least one step is required."")) <TAB>  <TAB> return <TAB> return ret",if i == int ( i ) :,171
"def to_dict(self): <TAB> data = {} <TAB> for item, value in self.__dict__.items(): <TAB>  <TAB> # ignore private attributes <MASK> if isinstance(value, ConfigEmptyDictable): <TAB>  <TAB>  <TAB>  <TAB> data[ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> snake_to_camels(item, self.capitalize_start, self.capitalize_arn) <TAB>  <TAB>  <TAB>  <TAB> ] = value.to_dict() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> data[ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> snake_to_camels(item, self.capitalize_start, self.capitalize_arn) <TAB>  <TAB>  <TAB>  <TAB> ] = value <TAB> # Cleanse the extra properties: <TAB> for prop in POP_STRINGS: <TAB>  <TAB> data.pop(prop, None) <TAB> return data","if not item . startswith ( ""_"" ) and value is not None :",194
"def parse_utf8_qsl(s): <TAB> d = dict(parse_qsl(s)) <TAB> for k, v in d.items():  # pragma: no cover <TAB>  <TAB> if not isinstance(k, bytes) and not isinstance(v, bytes): <TAB>  <TAB>  <TAB> # skip this iteration if we have no keys or values to update <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> d.pop(k) <MASK> k = k.decode(""utf-8"") <TAB>  <TAB> if isinstance(v, bytes): <TAB>  <TAB>  <TAB> v = v.decode(""utf-8"") <TAB>  <TAB> d[k] = v <TAB> return d","if isinstance ( k , bytes ) :",153
"def _member_key_name(self, shape, member_name): <TAB> # This method is needed because we have to special case flattened list <TAB> # with a serialization name.  If this is the case we use the <TAB> # locationName from the list's member shape as the key name for the <TAB> # surrounding structure. <TAB> if shape.type_name == ""list"" and shape.serialization.get(""flattened""): <TAB>  <TAB> list_member_serialized_name = shape.member.serialization.get(""name"") <MASK> return list_member_serialized_name <TAB> serialized_name = shape.serialization.get(""name"") <TAB> if serialized_name is not None: <TAB>  <TAB> return serialized_name <TAB> return member_name",if list_member_serialized_name is not None :,178
"def reorder_items(items): <TAB> argkeys_cache = {} <TAB> for scopenum in range(0, scopenum_function): <TAB>  <TAB> argkeys_cache[scopenum] = d = {} <TAB>  <TAB> for item in items: <TAB>  <TAB>  <TAB> keys = set(get_parametrized_fixture_keys(item, scopenum)) <MASK> d[item] = keys <TAB> return reorder_items_atscope(items, set(), argkeys_cache, 0)",if keys :,120
"def _consume_until(self, delimiter): <TAB> # Consume until the delimiter is reached, <TAB> # allowing for the delimiter to be escaped with ""\"". <TAB> start = self._position <TAB> buff = """" <TAB> self._next() <TAB> while self._current != delimiter: <TAB>  <TAB> if self._current == ""\\"": <TAB>  <TAB>  <TAB> buff += ""\\"" <TAB>  <TAB>  <TAB> self._next() <MASK> # We're at the EOF. <TAB>  <TAB>  <TAB> raise LexerError( <TAB>  <TAB>  <TAB>  <TAB> message=""Unclosed %s delimiter"" % delimiter, <TAB>  <TAB>  <TAB>  <TAB> position=start, <TAB>  <TAB>  <TAB>  <TAB> expression=self._expression, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> buff += self._current <TAB>  <TAB> self._next() <TAB> # Skip the closing delimiter. <TAB> self._next() <TAB> return buff",if self . _current is None :,188
"def wrapped(*args, **kwargs): <TAB> ctx = click.get_current_context() <TAB> non_interactive = ctx.params.get(""no_interactive"") <TAB> # only run in non interactive mode <TAB> if non_interactive: <TAB>  <TAB> package_type = ctx.params.get(""package_type"") <TAB>  <TAB> base_image = ctx.params.get(""base_image"") <TAB>  <TAB> dependency_manager = ctx.params.get(""dependency_manager"") <TAB>  <TAB> # dependency manager is only required for ZIP package type and for java based IMAGE package types <MASK> if not dependency_manager: <TAB>  <TAB>  <TAB>  <TAB> raise click.UsageError(""Missing parameter --dependency-manager"") <TAB> return func(*args, **kwargs)","if package_type == ZIP or ( base_image and ""java"" in base_image ) :",184
"def select_spks(self, spk_list): <TAB> """"""Select speakers and perform a shallow copy."""""" <TAB> new_meta = KaldiMetaData() <TAB> for spk in spk_list: <MASK> for utt_key in self.spks[spk].utts: <TAB>  <TAB>  <TAB>  <TAB> new_meta.utts[utt_key] = self.utts[utt_key] <TAB> new_meta.collect_spks_from_utts() <TAB> return new_meta",if spk in self . spks :,125
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_app_id(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 18: <TAB>  <TAB>  <TAB> self.add_queue_name(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> self.set_max_num_tasks(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 24 :,158
"def get_action(self, values, option_string):  # pylint: disable=no-self-use <TAB> try: <TAB>  <TAB> properties = defaultdict(list) <TAB>  <TAB> for (k, v) in (x.split(""="", 1) for x in values): <TAB>  <TAB>  <TAB> properties[k].append(v) <TAB>  <TAB> properties = dict(properties) <TAB> except ValueError: <TAB>  <TAB> raise CLIError(""usage error: {} [KEY=VALUE ...]"".format(option_string)) <TAB> d = {} <TAB> for k in properties: <TAB>  <TAB> kl = k.lower() <TAB>  <TAB> v = properties[k] <MASK> d[""sku_id""] = v[0] <TAB> return d","if kl == ""sku-id"" :",169
"def _delete_cell(self, row, column): <TAB> for i in range(row, self.rowCount()): <TAB>  <TAB> edit = self.cellWidget(i, column) <MASK> next_edit = self.cellWidget(i + 1, column) <TAB>  <TAB>  <TAB> if next_edit and isinstance(next_edit, PackageSelectWidget): <TAB>  <TAB>  <TAB>  <TAB> next_edit.clone_into(edit) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.removeCellWidget(i, column)","if edit and isinstance ( edit , PackageSelectWidget ) :",129
"def __init__(self, row=None, *arguments, **keywords): <TAB> super().__init__(*arguments, **keywords) <TAB> if row is not None: <TAB>  <TAB> self.row = row <TAB> else: <TAB>  <TAB> self.row = [] <TAB> for pc in self.row: <TAB>  <TAB> if not isinstance(pc, (pitch.Pitch, note.Note)): <TAB>  <TAB>  <TAB> pc = pitch.Pitch(pc) <MASK> n = note.Note(pitch=pc) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> n = pc <TAB>  <TAB> n.pitch.octave = None <TAB>  <TAB> self.append(n)","if not isinstance ( pc , note . Note ) :",160
"def _parse_handler(self, handler_id, process_dict): <TAB> for plugin_id in process_dict.get(""plugins"") or []: <MASK> self.handler_runner_plugins[handler_id] = [] <TAB>  <TAB> self.handler_runner_plugins[handler_id].append(plugin_id)",if handler_id not in self . handler_runner_plugins :,90
"def getChildByAttributeValue(self, attrname, attrvalue, recurse): <TAB> for child in self.children: <MASK> return child <TAB>  <TAB> elif recurse and hasattr(child, ""children""): <TAB>  <TAB>  <TAB> c = child.getChildByAttributeValue(attrname, attrvalue, recurse) <TAB>  <TAB>  <TAB> if c: <TAB>  <TAB>  <TAB>  <TAB> return c <TAB> return None","if child . _attributes . get ( attrname , None ) == attrvalue :",100
"def post(self, request): <TAB> self.request = request <TAB> for p in self.provider_forms: <TAB>  <TAB> if p[""provider""].identifier == request.POST.get(""payment"", """"): <TAB>  <TAB>  <TAB> self.cart_session[""payment""] = p[""provider""].identifier <TAB>  <TAB>  <TAB> resp = p[""provider""].checkout_prepare(request, self.get_cart()) <TAB>  <TAB>  <TAB> if isinstance(resp, str): <TAB>  <TAB>  <TAB>  <TAB> return redirect(resp) <MASK> return redirect(self.get_next_url(request)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return self.render() <TAB> messages.error(self.request, _(""Please select a payment method."")) <TAB> return self.render()",elif resp is True :,173
"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.add_item().TryMerge(d) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 34: <TAB>  <TAB>  <TAB> self.set_name_space(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 42: <TAB>  <TAB>  <TAB> length = d.getVarInt32() <TAB>  <TAB>  <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB>  <TAB>  <TAB> d.skip(length) <TAB>  <TAB>  <TAB> self.mutable_override().TryMerge(tmp) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 11 :,197
"def get_inherited_managers(self, attrs): <TAB> parent = super(PolyTransModelBase, self) <TAB> result = [] <TAB> for (base_name, key, manager) in parent.get_inherited_managers(attrs): <TAB>  <TAB> if base_name == ""PolymorphicModel"": <TAB>  <TAB>  <TAB> model = manager.model <TAB>  <TAB>  <TAB> if key == ""objects"": <TAB>  <TAB>  <TAB>  <TAB> manager = _PolyTransManager() <TAB>  <TAB>  <TAB>  <TAB> manager.model = model <MASK> manager = parler.models.TranslatableManager() <TAB>  <TAB>  <TAB>  <TAB> manager.model = model <TAB>  <TAB> result.append((base_name, key, manager)) <TAB> return result","elif key == ""base_objects"" :",165
"def remove_old_tasks(self): <TAB> for t in list(self.task_headers.values()): <TAB>  <TAB> cur_time = common.get_timestamp_utc() <MASK> logger.debug( <TAB>  <TAB>  <TAB>  <TAB> ""Task owned by %s removed after deadline, "" ""task_id: %s"", <TAB>  <TAB>  <TAB>  <TAB> t.task_owner.key, <TAB>  <TAB>  <TAB>  <TAB> t.task_id, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.remove_task_header(t.task_id) <TAB> for task_id, remove_time in list(self.removed_tasks.items()): <TAB>  <TAB> cur_time = time.time() <TAB>  <TAB> if cur_time - remove_time > self.removed_task_timeout: <TAB>  <TAB>  <TAB> del self.removed_tasks[task_id]",if cur_time > t . deadline :,199
"def run(self): <TAB> """"""Overrides base class run method. Do not call directly."""""" <TAB> self._ready() <TAB> for packet in self._iter_packets(BYTES_PER_STROKE): <TAB>  <TAB> if (packet[0] & 0x80) or packet[3] != 0xFF: <TAB>  <TAB>  <TAB> log.error(""discarding invalid packet: %s"", binascii.hexlify(packet)) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> steno_keys = self.keymap.keys_to_actions(self.process_steno_packet(packet)) <MASK> self._notify(steno_keys)",if steno_keys :,147
"def _cleanup(self, exc): <TAB> """"""Clean up this SFTP server session"""""" <TAB> if self._server:  # pragma: no branch <TAB>  <TAB> for file_obj in self._file_handles.values(): <TAB>  <TAB>  <TAB> result = self._server.close(file_obj) <MASK> result = yield from result <TAB>  <TAB> result = self._server.exit() <TAB>  <TAB> if asyncio.iscoroutine(result): <TAB>  <TAB>  <TAB> result = yield from result <TAB>  <TAB> self._server = None <TAB>  <TAB> self._file_handles = [] <TAB>  <TAB> self._dir_handles = [] <TAB> self.logger.info(""SFTP server exited%s"", "": "" + str(exc) if exc else """") <TAB> yield from super()._cleanup(exc)",if asyncio . iscoroutine ( result ) :,184
"def fill_value(wb, infos, para): <TAB> for worksheet in infos: <TAB>  <TAB> ws, info = worksheet <TAB>  <TAB> for pos, key in info: <MASK> continue <TAB>  <TAB>  <TAB> if key[0] in (""str"", ""int"", ""float"", ""bool"", ""txt"", ""list"", ""date""): <TAB>  <TAB>  <TAB>  <TAB> wb[ws].cell(pos[0], pos[1], para[key[1]]) <TAB>  <TAB>  <TAB> if key[0] == ""img"": <TAB>  <TAB>  <TAB>  <TAB> add_image(wb, ws, pos, key, para[key[1]]) <TAB>  <TAB>  <TAB> if key[0] == ""tab"": <TAB>  <TAB>  <TAB>  <TAB> add_table(wb, ws, pos, key, para[key[1]])",if not key [ 1 ] in para :,184
"def press(self, key): <TAB> try: <TAB>  <TAB> tup = self.env.keybuffer.tuple_without_numbers() <MASK> cmd = self.commandlist[tup] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return <TAB> except KeyError: <TAB>  <TAB> self.env.key_clear() <TAB> else: <TAB>  <TAB> if hasattr(cmd, ""execute""): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> cmd.execute_wrap(self) <TAB>  <TAB>  <TAB> except Exception as error: <TAB>  <TAB>  <TAB>  <TAB> self.fm.notify(error) <TAB>  <TAB>  <TAB> self.env.key_clear()",if tup :,143
"def copy_from_text(self, context): <TAB> """"""make sure self.dynamic_strings has enough strings to do this"""""" <TAB> try: <TAB>  <TAB> text = self.text_pointer <MASK> self.info(""no text selected"") <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> slines = text.lines <TAB>  <TAB> self.dynamic_strings.clear() <TAB>  <TAB> for line in slines: <TAB>  <TAB>  <TAB> self.dynamic_strings.add().line = line.body <TAB> except Exception as err: <TAB>  <TAB> self.info(f""copy_from_text: encountered error {err}"")",if not text :,140
"def _put_unit(self, name, body): <TAB> for attempt in xrange(RETRIES): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> resp = self._request_unit(""PUT"", name, body) <TAB>  <TAB>  <TAB> data = resp.read() <TAB>  <TAB>  <TAB> if not 200 <= resp.status <= 299: <TAB>  <TAB>  <TAB>  <TAB> errmsg = ""Failed to create unit: {} {} - {}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> resp.status, resp.reason, data <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> raise RuntimeError(errmsg) <TAB>  <TAB>  <TAB> return data <TAB>  <TAB> except: <MASK> raise",if attempt >= ( RETRIES - 1 ) :,149
"def send_button_click(widget, button, primary=False, shift=False, recursive=False): <TAB> """"""See send_key_click_event"""""" <TAB> state = Gdk.ModifierType(0) <TAB> if primary: <TAB>  <TAB> state |= get_primary_accel_mod() <TAB> if shift: <TAB>  <TAB> state |= Gdk.ModifierType.SHIFT_MASK <TAB> assert isinstance(widget, Gtk.Widget) <TAB> handled = _send_button_click_event(widget, button=button, state=state) <TAB> if recursive: <MASK> for child in widget.get_children(): <TAB>  <TAB>  <TAB>  <TAB> handled += send_button_click(child, button, primary, shift, recursive) <TAB> return handled","if isinstance ( widget , Gtk . Container ) :",174
"def connectionsTo(self, node): <TAB> ""Return [ intf1, intf2... ] for all intfs that connect self to node."" <TAB> # We could optimize this if it is important <TAB> connections = [] <TAB> for intf in self.intfList(): <TAB>  <TAB> link = intf.link <TAB>  <TAB> if link: <TAB>  <TAB>  <TAB> node1, node2 = link.intf1.node, link.intf2.node <MASK> connections += [(intf, link.intf2)] <TAB>  <TAB>  <TAB> elif node1 == node and node2 == self: <TAB>  <TAB>  <TAB>  <TAB> connections += [(intf, link.intf1)] <TAB> return connections",if node1 == self and node2 == node :,169
"def _get_stop_initiated_nodes( <TAB> pipeline_state: pstate.PipelineState,) -> List[pipeline_pb2.PipelineNode]: <TAB> """"""Returns list of all stop initiated nodes."""""" <TAB> nodes = pstate.get_all_pipeline_nodes(pipeline_state.pipeline) <TAB> result = [] <TAB> for node in nodes: <TAB>  <TAB> node_uid = task_lib.NodeUid.from_pipeline_node(pipeline_state.pipeline, node) <MASK> result.append(node) <TAB> return result",if pipeline_state . is_node_stop_initiated ( node_uid ) :,146
"def __IsFlagFileDirective(self, flag_string): <TAB> """"""Checks whether flag_string contain a --flagfile=<foo> directive."""""" <TAB> if isinstance(flag_string, type("""")): <TAB>  <TAB> if flag_string.startswith(""--flagfile=""): <TAB>  <TAB>  <TAB> return 1 <TAB>  <TAB> elif flag_string == ""--flagfile"": <TAB>  <TAB>  <TAB> return 1 <MASK> return 1 <TAB>  <TAB> elif flag_string == ""-flagfile"": <TAB>  <TAB>  <TAB> return 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return 0 <TAB> return 0","elif flag_string . startswith ( ""-flagfile="" ) :",133
"def send_response_only(self, code, message=None): <TAB> """"""Send the response header only."""""" <TAB> if self.request_version != ""HTTP/0.9"": <MASK> if code in self.responses: <TAB>  <TAB>  <TAB>  <TAB> message = self.responses[code][0] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> message = """" <TAB>  <TAB> if not hasattr(self, ""_headers_buffer""): <TAB>  <TAB>  <TAB> self._headers_buffer = [] <TAB>  <TAB> self._headers_buffer.append( <TAB>  <TAB>  <TAB> (""%s %d %s\r\n"" % (self.protocol_version, code, message)).encode( <TAB>  <TAB>  <TAB>  <TAB> ""latin-1"", ""strict"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> )",if message is None :,176
"def mapper(self, newMapper=None): <TAB> """"""Return the ``vtkMapper`` data object, or update it with a new one."""""" <TAB> if newMapper: <TAB>  <TAB> self.SetMapper(newMapper) <TAB>  <TAB> if self._mapper: <TAB>  <TAB>  <TAB> iptdata = self._mapper.GetInput() <MASK> newMapper.SetInputData(self._mapper.GetInput()) <TAB>  <TAB> self._mapper = newMapper <TAB>  <TAB> self._mapper.Modified() <TAB> return self._mapper",if iptdata :,123
"def _put(self, item): <TAB> # Remove a possible existing request for the same file (there can <TAB> # be only one). <TAB> priority, timestamp, request = item <TAB> id = request.id <TAB> if id in self._item_from_id: <TAB>  <TAB> i = self._item_from_id[id] <TAB>  <TAB> self.queue.remove(i) <TAB>  <TAB> p, t, r = i <TAB>  <TAB> item = (min(priority, p), t, request) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> r.complete(""skipped"") <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB> # Add the (possibly updated) item to the queue. <TAB> self._item_from_id[id] = item <TAB> _PriorityQueue._put(self, item)","if isinstance ( r , ScanRequest ) :",192
"def stopButtonPressed(self, button): <TAB> selected_row_return = self.selectedRow() <TAB> if selected_row_return != None: <TAB>  <TAB> gid = self.download_table.item(selected_row_return, 8).text() <TAB>  <TAB> answer = download.downloadStop(gid) <MASK> notifySend(""Aria2 did not respond!"", ""Try agian!"", 10000, ""critical"") <TAB> else: <TAB>  <TAB> self.statusbar.showMessage(""Please select an item first!"")","if answer == ""None"" :",124
"def set_value(self, value): <TAB> with self.valueLock: <TAB>  <TAB> self.__value = value <TAB>  <TAB> # walk the call chain if the result is not an exception, otherwise invoke the errorhandler (if any) <TAB>  <TAB> if isinstance(value, _ExceptionWrapper): <MASK> self.exceptionhandler(value.exception) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for call, args, kwargs in self.callchain: <TAB>  <TAB>  <TAB>  <TAB> call = functools.partial(call, self.__value) <TAB>  <TAB>  <TAB>  <TAB> self.__value = call(*args, **kwargs) <TAB>  <TAB>  <TAB>  <TAB> if isinstance(self.__value, _ExceptionWrapper): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> self.callchain = [] <TAB>  <TAB> self.__ready.set()",if self . exceptionhandler :,179
"def _mutate(self): <TAB> result = dict() <TAB> for contract in self.slither.contracts: <TAB>  <TAB> # Create fault for state variables declaration <TAB>  <TAB> for variable in contract.state_variables_declared: <TAB>  <TAB>  <TAB> if variable.initialized: <TAB>  <TAB>  <TAB>  <TAB> # Cannot remove the initialization of constant variables <TAB>  <TAB>  <TAB>  <TAB> if variable.is_constant: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB>  <TAB> if isinstance(variable.expression, Literal): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> remove_assignement(variable, contract, result) <TAB>  <TAB> for function in contract.functions_declared + contract.modifiers_declared: <TAB>  <TAB>  <TAB> for variable in function.local_variables: <MASK> remove_assignement(variable, contract, result) <TAB> return result","if variable . initialized and isinstance ( variable . expression , Literal ) :",194
"def unmount(self): <TAB> pathname = os.path.abspath(os.path.join(self.dirname, self.filename)) <TAB> if pathname not in sys.path: <TAB>  <TAB> logger.debug(""%s not in path"", pathname) <TAB> else: <TAB>  <TAB> sys.path.remove(pathname) <TAB>  <TAB> if pathname in _hook.impure_wheels: <TAB>  <TAB>  <TAB> _hook.remove(pathname) <TAB>  <TAB> if not _hook.impure_wheels: <MASK> sys.meta_path.remove(_hook)",if _hook in sys . meta_path :,141
"def __delitem__(self, index): <TAB> if isinstance(index, slice): <TAB>  <TAB> range_ = self.validate_slice(index, as_range=True) <TAB>  <TAB> for i in reversed(range_): <TAB>  <TAB>  <TAB> del self[i] <TAB> else: <TAB>  <TAB> with self.index_context(index) as index: <TAB>  <TAB>  <TAB> library.MagickRemoveImage(self.image.wand) <MASK> del self.instances[index]",if index < len ( self . instances ) :,118
"def reduce(self, *e): <TAB> if self._animating_lock: <TAB>  <TAB> return <TAB> production = self._parser.reduce() <TAB> if production: <TAB>  <TAB> self._lastoper1[""text""] = ""Reduce:"" <TAB>  <TAB> self._lastoper2[""text""] = ""%s"" % production <MASK> self._animate_reduce() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._redraw() <TAB> return production",if self . _animate . get ( ) :,104
"def listdir(self, root, impl_fn): <TAB> with self.listdir_lock: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self.listdir_cache[root] <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> # check to see if we're watching <TAB>  <TAB>  <TAB> with self.watch_lock: <MASK> self._watch(root) <TAB>  <TAB>  <TAB> v = list(impl_fn(root)) <TAB>  <TAB>  <TAB> self.listdir_cache[root] = v <TAB>  <TAB>  <TAB> return v",if root not in self . watched :,127
"def handle_input(self, event): <TAB> done = Viewer.handle_input(self, event) <TAB> if not done: <TAB>  <TAB> if event.is_typeable: <MASK> self.type(event.key_code) <TAB>  <TAB>  <TAB> elif event.key_name: <TAB>  <TAB>  <TAB>  <TAB> self.type(event.key_name) <TAB>  <TAB>  <TAB> return True <TAB> return False","if isinstance ( event . key_code , str ) :",108
"def node_simple_stmt(self, node): <TAB> for child in node.children: <TAB>  <TAB> if isinstance(child, Leaf): <TAB>  <TAB>  <TAB> if child.value in [""break"", ""continue""]: <TAB>  <TAB>  <TAB>  <TAB> self.add_lines(""%s;"" % child.value, self.get_lineno(child)) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> code = self.dispatch(child) <TAB>  <TAB> if isinstance(code, Code): <TAB>  <TAB>  <TAB> code = code.code <TAB>  <TAB>  <TAB> code = str(code) <MASK> if code[-1] not in ["";"", ""}""]: <TAB>  <TAB>  <TAB>  <TAB> code += "";"" <TAB>  <TAB>  <TAB> self.add_lines(code, self.get_lineno(child))",if code is not None :,170
"def upgrade_web2py(): <TAB> dialog = FORM.confirm(T(""Upgrade""), {T(""Cancel""): URL(""site"")}) <TAB> if dialog.accepted: <TAB>  <TAB> (success, error) = upgrade(request) <MASK> session.flash = T(""web2py upgraded; please restart it"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> session.flash = T('unable to upgrade because ""%s""', error) <TAB>  <TAB> redirect(URL(""site"")) <TAB> return dict(dialog=dialog)",if success :,119
"def _fetch_examples(): <TAB> parsing = False <TAB> examples = [] <TAB> filepath = join(dirname(dirname(abspath(__file__))), ""README.rst"") <TAB> with open(filepath, ""r"") as handle: <TAB>  <TAB> for line in handle.read().split(""\n""): <TAB>  <TAB>  <TAB> line = line[4:] <TAB>  <TAB>  <TAB> if line.startswith(""# Example ""): <TAB>  <TAB>  <TAB>  <TAB> parsing = True <TAB>  <TAB>  <TAB>  <TAB> title = line.lstrip(""# "") <TAB>  <TAB>  <TAB>  <TAB> examples.append([title, []]) <TAB>  <TAB>  <TAB> elif parsing and line == """": <TAB>  <TAB>  <TAB>  <TAB> parsing = False <MASK> examples[-1][1].append(line) <TAB> return examples",elif parsing :,161
"def __str__(self): <TAB> """"""Multi line string representation of matrix"""""" <TAB> s = """" <TAB> for i in range(self.rows): <TAB>  <TAB> if i == 0: <TAB>  <TAB>  <TAB> first = ""/"" <TAB>  <TAB>  <TAB> last = ""\\"" <MASK> first = ""\\"" <TAB>  <TAB>  <TAB> last = ""/"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> first = last = ""|"" <TAB>  <TAB> s += first <TAB>  <TAB> for j in range(self.cols): <TAB>  <TAB>  <TAB> s += "" "" + _format % self[i][j] <TAB>  <TAB> s += "" "" + last + ""\n"" <TAB> return s",elif i == self . rows - 1 :,148
"def _build(self): <TAB> self._paths = [] <TAB> self._clipboard_record = None <TAB> self._initial_fill_rule = None <TAB> for x in self._data.path: <TAB>  <TAB> if isinstance(x, InitialFillRule): <TAB>  <TAB>  <TAB> self._initial_fill_rule = x <MASK> self._clipboard_record = x <TAB>  <TAB> elif isinstance(x, Subpath): <TAB>  <TAB>  <TAB> self._paths.append(x)","elif isinstance ( x , ClipboardRecord ) :",116
"def read(self): <TAB> if self.type == cs.arm64.ARM64_OP_REG: <TAB>  <TAB> return self.cpu.regfile.read(self.reg) <TAB> elif self.type == cs.arm64.ARM64_OP_REG_MRS: <TAB>  <TAB> name = SYS_REG_MAP.get(self.op.sys) <MASK> raise NotImplementedError( <TAB>  <TAB>  <TAB>  <TAB> f""Unsupported system register: '0x{self.op.sys:x}'"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return self.cpu.regfile.read(name) <TAB> elif self.type == cs.arm64.ARM64_OP_IMM: <TAB>  <TAB> return self.op.imm <TAB> else: <TAB>  <TAB> raise NotImplementedError(f""Unsupported operand type: '{self.type}'"")",if not name :,196
"def __eq__(self, other): <TAB> attrs = [""name"", ""value""] + list(self.attribute_names.keys()) <TAB> for attr in attrs: <TAB>  <TAB> mine = getattr(self, attr, None) <TAB>  <TAB> his = getattr(other, attr, None) <TAB>  <TAB> if isinstance(mine, bytes): <TAB>  <TAB>  <TAB> mine = mine.decode(""utf-8"") <TAB>  <TAB> if isinstance(his, bytes): <TAB>  <TAB>  <TAB> his = his.decode(""utf-8"") <TAB>  <TAB> if attr == ""domain"": <TAB>  <TAB>  <TAB> if mine and mine[0] == ""."": <TAB>  <TAB>  <TAB>  <TAB> mine = mine[1:] <MASK> his = his[1:] <TAB>  <TAB> if mine != his: <TAB>  <TAB>  <TAB> return False <TAB> return True","if his and his [ 0 ] == ""."" :",191
"def func2(): <TAB> cluster = StrictRedisCluster( <TAB>  <TAB> startup_nodes=[{""host"": ""127.0.0.1"", ""port"": 7001}], decode_responses=True <TAB> ) <TAB> while True: <TAB>  <TAB> foobar = int(await cluster.get(""foobar"")) <TAB>  <TAB> print(""thread: get `foobar` = {}"".format(foobar)) <TAB>  <TAB> if foobar >= 0: <TAB>  <TAB>  <TAB> print(""thread: cluster get foobar == {}, decrease it"".format(foobar)) <TAB>  <TAB>  <TAB> await cluster.decr(""foobar"", 1) <MASK> print(""thread: break loop now"") <TAB>  <TAB>  <TAB> break",if foobar < 0 :,151
"def newTitle(self, title): <TAB> """"""Check if a title is being used, and increment its number if it is."""""" <TAB> while self.storyPanel.passageExists(title): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> match = re.search(r""(\s\d+)$"", title) <MASK> title = title[: match.start(1)] + "" "" + str(int(match.group(1)) + 1) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> title += "" 2"" <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> pass <TAB> return title",if match :,135
"def setCompositionBufferChar( <TAB> self, cbTS, compositionType, compositionChar, compositionCursor): <TAB> if compositionCursor - 1 in cbTS.compositionBufferChar: <TAB>  <TAB> for key in sorted(cbTS.compositionBufferChar.keys(), reverse=True): <MASK> cbTS.compositionBufferChar[key + 1] = cbTS.compositionBufferChar.pop( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> key <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> cbTS.compositionBufferChar[compositionCursor - 1] = [ <TAB>  <TAB> compositionType, <TAB>  <TAB> compositionChar, <TAB> ]",if key >= compositionCursor - 1 :,148
"def _on_tick(self, player_state): <TAB> if not self.did_restore: <TAB>  <TAB> self.log(""Did not restore streams yet, ignoring tick"") <TAB>  <TAB> return <TAB> for stype in STREAMS: <TAB>  <TAB> current_stream = self.current_streams[stype] <TAB>  <TAB> player_stream = player_state.get(STREAMS[stype][""current""]) <MASK> self.log( <TAB>  <TAB>  <TAB>  <TAB> ""{} has changed from {} to {}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> stype, current_stream, player_stream <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self._set_current_stream(stype, player_state) <TAB>  <TAB>  <TAB> self._ask_to_save(stype, player_stream)",if player_stream != current_stream :,180
"def renameGlyphOrderFile(filename, newNames, dryRun=False, print=print): <TAB> lines = [] <TAB> didRename = False <TAB> for line in readLines(filename): <TAB>  <TAB> line = line.lstrip() <TAB>  <TAB> if len(line) > 0 and line[0] != ""#"": <TAB>  <TAB>  <TAB> newName = newNames.get(line) <MASK> didRename = True <TAB>  <TAB>  <TAB>  <TAB> line = newName <TAB>  <TAB> lines.append(line) <TAB> if didRename: <TAB>  <TAB> print(""Writing"", filename) <TAB>  <TAB> if not dryRun: <TAB>  <TAB>  <TAB> with open(filename, ""w"") as f: <TAB>  <TAB>  <TAB>  <TAB> f.write(""\n"".join(lines))",if newName is not None :,173
"def _set_function(self, value): <TAB> super(MockChargingPin, self)._set_function(value) <TAB> if value == ""input"": <MASK> self._charge_stop.set() <TAB>  <TAB>  <TAB> self._charge_thread.join() <TAB>  <TAB> self._charge_stop.clear() <TAB>  <TAB> self._charge_thread = Thread(target=self._charge) <TAB>  <TAB> self._charge_thread.start() <TAB> elif value == ""output"": <TAB>  <TAB> if self._charge_thread: <TAB>  <TAB>  <TAB> self._charge_stop.set() <TAB>  <TAB>  <TAB> self._charge_thread.join()",if self . _charge_thread :,152
"def _fill_mappings(): <TAB> for entry in _ISO_639: <TAB>  <TAB> name, _1, _2B, _2T = entry <TAB>  <TAB> _LOWER[name.lower()] = name <MASK> _ISO_639_1[_1] = entry <TAB>  <TAB> _ISO_639_2[_2B] = entry <TAB>  <TAB> if _2T: <TAB>  <TAB>  <TAB> _ISO_639_2[_2T] = entry",if _1 :,107
"def merge_stsc(chunks_list, total_chunk_number_list): <TAB> results = [] <TAB> chunk_index = 1 <TAB> for chunks, total in zip(chunks_list, total_chunk_number_list): <TAB>  <TAB> for i in range(len(chunks)): <MASK> chunk_number = chunks[i + 1][0] - chunks[i][0] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> chunk_number = total + 1 - chunks[i][0] <TAB>  <TAB>  <TAB> sample_number = chunks[i][1] <TAB>  <TAB>  <TAB> description = chunks[i][2] <TAB>  <TAB>  <TAB> results.append((chunk_index, sample_number, description)) <TAB>  <TAB>  <TAB> chunk_index += chunk_number <TAB> return results",if i < len ( chunks ) - 1 :,186
"def _get_global_remote_service(): <TAB> L = sorted(list(_global_remote_services), reverse=True) <TAB> for k in L: <TAB>  <TAB> c = _global_remote_services[k] <MASK> return c <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> del _global_remote_services[k] <TAB> del L <TAB> return None","if c . status != ""closed"" :",94
"def is_in_notebook(): <TAB> try: <TAB>  <TAB> # Test adapted from tqdm.autonotebook: https://github.com/tqdm/tqdm/blob/master/tqdm/autonotebook.py <TAB>  <TAB> get_ipython = sys.modules[""IPython""].get_ipython <MASK> raise ImportError(""console"") <TAB>  <TAB> if ""VSCODE_PID"" in os.environ: <TAB>  <TAB>  <TAB> raise ImportError(""vscode"") <TAB>  <TAB> return importlib.util.find_spec(""IPython"") is not None <TAB> except (AttributeError, ImportError, KeyError): <TAB>  <TAB> return False","if ""IPKernelApp"" not in get_ipython ( ) . config :",150
"def _apply_operation(self, result): <TAB> args = result[-len(self._args) :] <TAB> result[-len(self._args) :] = [] <TAB> _l = args.pop(0) <TAB> for i, a in enumerate(args): <MASK> if not _l < a: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if not _l <= a: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> _l = a <TAB> return True",if self . _strict [ i ] :,121
"def getNodeText(n): <TAB> result = [] <TAB> for l in n.childNodes: <TAB>  <TAB> if l.nodeType == TEXT_NODE: <TAB>  <TAB>  <TAB> result.append(l.data) <MASK> result.append(getNodeText(l)) <TAB> return """".join(result)","if l . nodeType == ELEMENT_NODE and l . nodeName == ""font"" :",91
"def generateGCode(self): <TAB> gcode = ""(GCode generated by RepRap Plot)\nG21 (Millimeters)\nG28 (Go Home)\nG90 (Absolute Positioning)\n(Start Plot)\n"" <TAB> for x, y, z in self.coordinates: <MASK> gcode += ""G1 X"" + str(x) + "" Y"" + str(y) + ""\n"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> gcode += ""G1 Z"" + str(z) + ""\n"" <TAB> gcode += ""G28 (Go Home)"" <TAB> return gcode",if z == None :,147
"def indent(elem, level=0): <TAB> i = ""\n"" + level * ""  "" <TAB> # pylint: disable=len-as-condition <TAB> if len(elem): <MASK> elem.text = i + ""  "" <TAB>  <TAB> if not elem.tail or not elem.tail.strip(): <TAB>  <TAB>  <TAB> elem.tail = i <TAB>  <TAB> for subEl in elem: <TAB>  <TAB>  <TAB> indent(subEl, level + 1) <TAB>  <TAB> if not elem.tail or not elem.tail.strip(): <TAB>  <TAB>  <TAB> elem.tail = i <TAB> else: <TAB>  <TAB> if level and (not elem.tail or not elem.tail.strip()): <TAB>  <TAB>  <TAB> elem.tail = i",if not elem . text or not elem . text . strip ( ) :,175
"def lineColor(self, lc=None): <TAB> """"""Set/get color of mesh edges. Same as `lc()`."""""" <TAB> if lc is not None: <MASK> self.GetProperty().EdgeVisibilityOff() <TAB>  <TAB>  <TAB> self.color(lc) <TAB>  <TAB>  <TAB> return self <TAB>  <TAB> self.GetProperty().EdgeVisibilityOn() <TAB>  <TAB> self.GetProperty().SetEdgeColor(colors.getColor(lc)) <TAB> else: <TAB>  <TAB> return self.GetProperty().GetEdgeColor() <TAB> return self","if ""ireframe"" in self . GetProperty ( ) . GetRepresentationAsString ( ) :",139
"def get_tokens_unprocessed(self, text): <TAB> for index, token, value in RegexLexer.get_tokens_unprocessed(self, text): <MASK> if self.smhighlighting: <TAB>  <TAB>  <TAB>  <TAB> if value in self.SM_TYPES: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> token = Keyword.Type <TAB>  <TAB>  <TAB>  <TAB> elif value in self._functions: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> token = Name.Builtin <TAB>  <TAB> yield index, token, value",if token is Name :,111
"def pre_install(cls, component, request): <TAB> if cls.trigger_update: <TAB>  <TAB> perform_update.delay(""Component"", component.pk, auto=True) <MASK> messages.warning( <TAB>  <TAB>  <TAB>  <TAB> request, <TAB>  <TAB>  <TAB>  <TAB> _( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""The repository is outdated, you might not get "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""expected results until you update it."" <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB> )",if component . repo_needs_merge ( ) :,115
"def trainable_weights(self): <TAB> """"""Return trainable weights of this network in a list."""""" <TAB> if self._trainable_weights is not None and len(self._trainable_weights) > 0: <TAB>  <TAB> # self._trainable_weights already extracted, so do nothing <TAB>  <TAB> pass <TAB> else: <TAB>  <TAB> self._trainable_weights = [] <TAB>  <TAB> for layer in self.all_layers: <MASK> self._trainable_weights.extend(layer.trainable_weights) <TAB> return self._trainable_weights.copy()",if layer . trainable_weights is not None :,133
"def cleanup(self, timeout): <TAB> if not os.path.isdir(self.root): <TAB>  <TAB> return <TAB> now = time.time() <TAB> for f in os.listdir(self.root): <TAB>  <TAB> path = self._get_path(f) <TAB>  <TAB> atime = os.stat(path).st_atime <MASK> if os.path.isdir(path): <TAB>  <TAB>  <TAB>  <TAB> shutil.rmtree(path) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> os.remove(path)",if now - atime > timeout :,126
"def visit_index_expr(self, node: IndexExpr) -> IndexExpr: <TAB> new = IndexExpr(self.expr(node.base), self.expr(node.index)) <TAB> if node.method_type: <TAB>  <TAB> new.method_type = self.type(node.method_type) <TAB> if node.analyzed: <MASK> new.analyzed = self.visit_type_application(node.analyzed) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new.analyzed = self.visit_type_alias_expr(node.analyzed) <TAB>  <TAB> new.analyzed.set_line(node.analyzed.line) <TAB> return new","if isinstance ( node . analyzed , TypeApplication ) :",154
"def process_response(self, request, response): <TAB> """"""If request.anonymous was modified set the anonymous cookie."""""" <TAB> try: <TAB>  <TAB> modified = request.anonymous.modified <TAB> except AttributeError: <TAB>  <TAB> pass <TAB> else: <MASK> max_age = settings.ANONYMOUS_COOKIE_MAX_AGE <TAB>  <TAB>  <TAB> expires_time = time.time() + max_age <TAB>  <TAB>  <TAB> expires = cookie_date(expires_time) <TAB>  <TAB>  <TAB> response.set_cookie( <TAB>  <TAB>  <TAB>  <TAB> settings.ANONYMOUS_COOKIE_NAME, <TAB>  <TAB>  <TAB>  <TAB> request.anonymous.anonymous_id, <TAB>  <TAB>  <TAB>  <TAB> max_age=max_age, <TAB>  <TAB>  <TAB>  <TAB> expires=expires, <TAB>  <TAB>  <TAB> ) <TAB> return response",if modified :,181
"def _resolver( <TAB> self, <TAB> isinstance=isinstance, <TAB> enumerate=enumerate, <TAB> listiter=list.__iter__, <TAB> PdfIndirect=PdfIndirect, <TAB> resolved=_resolved, <TAB> PdfNull=PdfObject(""null""),): <TAB> for index, value in enumerate(list.__iter__(self)): <MASK> value = value.real_value() <TAB>  <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB>  <TAB> value = PdfNull <TAB>  <TAB>  <TAB> self[index] = value <TAB> self._resolve = resolved","if isinstance ( value , PdfIndirect ) :",134
"def get_selection(self): <TAB> if self.interface.multiple_select: <TAB>  <TAB> tree_model, tree_paths = self.selection.get_selected_rows() <TAB>  <TAB> return [tree_model.get(tree_model.get_iter(path), 0)[0] for path in tree_paths] <TAB> else: <TAB>  <TAB> tree_model, tree_iter = self.selection.get_selected() <MASK> row = tree_model.get(tree_iter, 0)[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> row = None <TAB> return row",if tree_iter :,139
"def _CreateMetadata(self, collection): <TAB> metadata = {} <TAB> for descriptor_cls, _, kwargs in reversed(collection.descriptors): <MASK> metadata[""offset""] = kwargs[""address""] <TAB>  <TAB>  <TAB> metadata.setdefault(""type"", ""Valid"") <TAB>  <TAB> elif issubclass(descriptor_cls, intel.InvalidAddress): <TAB>  <TAB>  <TAB> metadata[""type""] = ""Invalid"" <TAB> return metadata","if issubclass ( descriptor_cls , intel . PhysicalAddressDescriptor ) :",109
"def release_voucher_usage(order_data: dict): <TAB> voucher = order_data.get(""voucher"") <TAB> if voucher: <TAB>  <TAB> decrease_voucher_usage(voucher) <MASK> remove_voucher_usage_by_customer(voucher, order_data[""user_email""])","if ""user_email"" in order_data :",80
"def rec(node, i): <TAB> if i == key_len: <MASK> yield node.value <TAB> else: <TAB>  <TAB> nd = node.get(key[i]) <TAB>  <TAB> if nd is not None: <TAB>  <TAB>  <TAB> for e in rec(nd, i + 1): <TAB>  <TAB>  <TAB>  <TAB> yield e <TAB>  <TAB> nd = node.get("""")  # wildcard <TAB>  <TAB> if nd is not None: <TAB>  <TAB>  <TAB> for e in rec(nd, i + 1): <TAB>  <TAB>  <TAB>  <TAB> yield e","if hasattr ( node , ""value"" ) :",127
"def set_peek(self, dataset, is_multi_byte=False): <TAB> if not dataset.dataset.purged: <TAB>  <TAB> dataset.peek = get_file_peek(dataset.file_name) <MASK> dataset.blurb = ""1 significant component"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> dataset.blurb = ""%s significant components"" % dataset.metadata.number_comp <TAB> else: <TAB>  <TAB> dataset.peek = ""file does not exist"" <TAB>  <TAB> dataset.blurb = ""file purged from disk""",if dataset . metadata . number_comp == 1 :,135
"def _find_coding(text): <TAB> coding = ""coding"" <TAB> try: <TAB>  <TAB> start = text.index(coding) + len(coding) <TAB>  <TAB> if text[start] not in ""=:"": <TAB>  <TAB>  <TAB> return <TAB>  <TAB> start += 1 <TAB>  <TAB> while start < len(text) and text[start].isspace(): <TAB>  <TAB>  <TAB> start += 1 <TAB>  <TAB> end = start <TAB>  <TAB> while end < len(text): <TAB>  <TAB>  <TAB> c = text[end] <MASK> break <TAB>  <TAB>  <TAB> end += 1 <TAB>  <TAB> return text[start:end] <TAB> except ValueError: <TAB>  <TAB> pass","if not c . isalnum ( ) and c not in ""-_"" :",157
"def recv(self, buflen): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> data = os.read(self._fileno, buflen) <TAB>  <TAB>  <TAB> return data <TAB>  <TAB> except OSError as e: <MASK> raise IOError(*e.args) <TAB>  <TAB> self._trampoline(self, read=True)",if get_errno ( e ) not in SOCKET_BLOCKING :,97
"def onStreamError(self, streamErrorEntity): <TAB> logger.error(streamErrorEntity) <TAB> if self.getProp(self.__class__.PROP_RECONNECT_ON_STREAM_ERR, True): <MASK> logger.warn(""Not reconnecting because you signed in in another location"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logger.info(""Initiating reconnect"") <TAB>  <TAB>  <TAB> self.reconnect = True <TAB> else: <TAB>  <TAB> logger.warn( <TAB>  <TAB>  <TAB> ""Not reconnecting because property %s is not set"" <TAB>  <TAB>  <TAB> % self.__class__.PROP_RECONNECT_ON_STREAM_ERR <TAB>  <TAB> ) <TAB> self.toUpper(streamErrorEntity) <TAB> self.disconnect()",if streamErrorEntity . getErrorType ( ) == StreamErrorProtocolEntity . TYPE_CONFLICT :,183
"def _iter_items(): <TAB> if shuffle: <TAB>  <TAB> numpy.random.shuffle(indices) <TAB> queue = [] <TAB> i = 0 <TAB> for size in sizes: <TAB>  <TAB> size = int(size) <TAB>  <TAB> idx_batch = indices[i : i + size] <TAB>  <TAB> queue.append([]) <TAB>  <TAB> for sequence in sequences: <TAB>  <TAB>  <TAB> queue[-1].append(self._get_batch(sequence, idx_batch)) <MASK> yield from queue <TAB>  <TAB>  <TAB> queue = [] <TAB>  <TAB> i += size <TAB> yield from queue",if len ( queue ) >= buffer :,137
"def classify_using_version_endpoint(self): <TAB> """"""Tries to classify by accessing /version. if could not access succeded, returns"""""" <TAB> config = get_config() <TAB> try: <TAB>  <TAB> endpoint = ( <TAB>  <TAB>  <TAB> f""{self.event.protocol}://{self.event.host}:{self.event.port}/version"" <TAB>  <TAB> ) <TAB>  <TAB> versions = self.session.get(endpoint, timeout=config.network_timeout).json() <MASK> if versions.get(""major"") == """": <TAB>  <TAB>  <TAB>  <TAB> self.event = MetricsServer() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.event = ApiServer() <TAB> except Exception: <TAB>  <TAB> logging.warning(""Could not access /version on API service"", exc_info=True)","if ""major"" in versions :",186
"def _add_options(options, func, hidden): <TAB> for option in reversed(options): <TAB>  <TAB> # Pop param_decls option to prevent exception further on down the <TAB>  <TAB> # line for: `got multiple values for keyword argument`. <TAB>  <TAB> option = option.copy() <TAB>  <TAB> param_decls = option.pop(""param_decls"") <TAB>  <TAB> # Pop supported_providers option because it is snapcraft-only. <MASK> option.pop(""supported_providers"") <TAB>  <TAB> hidden_override = option.pop(""hidden"", hidden) <TAB>  <TAB> click_option = click.option(param_decls, **option, hidden=hidden_override) <TAB>  <TAB> func = click_option(func) <TAB> return func","if ""supported_providers"" in option :",172
"def sethtmloutput(self, htmlfile): <TAB> self.closehtml() <TAB> if htmlfile: <MASK> file = self.openoutput(htmlfile) <TAB>  <TAB>  <TAB> mine = 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> file = htmlfile <TAB>  <TAB>  <TAB> mine = 0 <TAB>  <TAB> self.htmlfile = file <TAB>  <TAB> self.htmlmine = mine <TAB>  <TAB> self.htmlfile.write(BEGINHTMLREPORT)",if type ( htmlfile ) == StringType :,112
"def make_base_requirements(reqs): <TAB> # type: (Sequence[STRING_TYPE]) -> Set[BaseRequirement] <TAB> requirements = set() <TAB> if not isinstance(reqs, (list, tuple, set)): <TAB>  <TAB> reqs = [reqs] <TAB> for req in reqs: <MASK> requirements.add(req) <TAB>  <TAB> elif pkg_resources_requirements is not None and isinstance( <TAB>  <TAB>  <TAB> req, pkg_resources_requirements.Requirement <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> requirements.add(BaseRequirement.from_req(req)) <TAB>  <TAB> elif req and isinstance(req, six.string_types) and not req.startswith(""#""): <TAB>  <TAB>  <TAB> requirements.add(BaseRequirement.from_string(req)) <TAB> return requirements","if isinstance ( req , BaseRequirement ) :",182
"def _drawBorderLine(bstyle, width, color, x1, y1, x2, y2): <TAB> # We need width and border style to be able to draw a border <TAB> if width and getBorderStyle(bstyle): <TAB>  <TAB> # If no color for border is given, the text color is used (like defined by W3C) <TAB>  <TAB> if color is None: <TAB>  <TAB>  <TAB> color = style.textColor <TAB>  <TAB>  <TAB> # print ""Border"", bstyle, width, color <MASK> canvas.setStrokeColor(color) <TAB>  <TAB>  <TAB> canvas.setLineWidth(width) <TAB>  <TAB>  <TAB> canvas.line(x1, y1, x2, y2)",if color is not None :,168
"def get_mail_source(config, src_id, start=False, changed=False): <TAB> ms_thread = config.mail_sources.get(src_id) <TAB> if ms_thread and not ms_thread.isAlive(): <TAB>  <TAB> ms_thread = None <TAB> if not ms_thread: <TAB>  <TAB> from mailpile.mail_source import MailSource <TAB>  <TAB> src_config = config.sources[src_id] <TAB>  <TAB> ms_thread = MailSource(config.background, src_config) <MASK> config.mail_sources[src_id] = ms_thread <TAB>  <TAB>  <TAB> ms_thread.start() <TAB>  <TAB>  <TAB> if changed: <TAB>  <TAB>  <TAB>  <TAB> ms_thread.wake_up() <TAB> return ms_thread",if start :,178
"def get_rdbms_metadata(self, cursor): <TAB> product = """" <TAB> version = """" <TAB> vendor = ""Microsoft Corporation"" <TAB> cursor.execute(""xp_msver"") <TAB> rs = cursor.fetchone() <TAB> while rs is not None: <TAB>  <TAB> name = rs[1].lower() <TAB>  <TAB> value = rs[3] <TAB>  <TAB> if name == ""productname"": <TAB>  <TAB>  <TAB> product = value <MASK> version = value <TAB>  <TAB> elif name == ""companyname"": <TAB>  <TAB>  <TAB> vendor == value <TAB>  <TAB> rs = cursor.fetchone() <TAB> return RDBMSMetadata(vendor, product, version)","elif name == ""productversion"" :",154
"def unpin_data_keys(self, session_id, data_keys, token, devices=None): <TAB> if not devices: <TAB>  <TAB> devices = functools.reduce( <TAB>  <TAB>  <TAB> operator.or_, <TAB>  <TAB>  <TAB> self._manager_ref.get_data_locations(session_id, data_keys), <TAB>  <TAB>  <TAB> set(), <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> devices = self._normalize_devices(devices) <TAB> for dev in devices: <TAB>  <TAB> handler = self.get_storage_handler(dev) <MASK> continue <TAB>  <TAB> handler.unpin_data_keys(session_id, data_keys, token)","if not getattr ( handler , ""_spillable"" , False ) :",160
"def GetSaveData(self): <TAB> saveData = {} <TAB> saveData[""detailClass_class""] = self.detail.child.__class__.__name__ <TAB> saveData[""detailClass_mod""] = self.detail.child.__module__ <TAB> if hasattr(self.detail.child, ""GetSaveData""): <TAB>  <TAB> attr = getattr(self.detail.child, ""GetSaveData"") <MASK> dData = attr() <TAB>  <TAB>  <TAB> if dData: <TAB>  <TAB>  <TAB>  <TAB> saveData[""detail""] = dData <TAB> v1, v2 = self.GetPosition() <TAB> saveData[""x""] = v1 <TAB> saveData[""y""] = v2 <TAB> v1, v2 = self.GetSize() <TAB> saveData[""w""] = v1 <TAB> saveData[""h""] = v2 <TAB> return saveData",if callable ( attr ) :,196
"def __repr__(self): <TAB> status = """" <TAB> if self.jumptable: <TAB>  <TAB> status = ""jumptable"" <MASK> status += ""@%#08x"" % self.jumptable_addr <TAB>  <TAB> if self.jumptable_entries is not None: <TAB>  <TAB>  <TAB> status += "" with %d entries"" % len(self.jumptable_entries) <TAB> return ""<IndirectJump %#08x - ins %#08x%s>"" % ( <TAB>  <TAB> self.addr, <TAB>  <TAB> self.ins_addr, <TAB>  <TAB> "" "" + status if status else """", <TAB> )",if self . jumptable_addr is not None :,149
"def readDir_r(self, file_list, dir_path, dire, r): <TAB> if (dire.fFlag & 0x02) != 0x02: <TAB>  <TAB> return <TAB> dirs = self.readDirItems(dire.locExtent, dire.lenData) <TAB> for d in dirs: <TAB>  <TAB> if not d.fIdentifier in [""."", ""..""]: <TAB>  <TAB>  <TAB> p = dir_path + ""/"" + d.fIdentifier <TAB>  <TAB>  <TAB> file_list.append(p) <MASK> self.readDir_r(file_list, p, d, r)",if r :,145
"def parse_font_for_string(self, s): <TAB> for c in s: <TAB>  <TAB> if c == ""\t"" and "" "" not in self.parsed_font: <TAB>  <TAB>  <TAB> # tabs rely on space char to calculate offset <TAB>  <TAB>  <TAB> self.parsed_font["" ""] = self.parse_font_char("" "") <MASK> self.parsed_font[c] = self.parse_font_char(c)","if c not in self . parsed_font and ord ( c ) >= ord ( "" "" ) :",119
"def audit(self, directive): <TAB> for location in directive.parents: <TAB>  <TAB> if location.name != ""location"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if not location.modifier or location.modifier == ""^~"": <TAB>  <TAB>  <TAB> # We need non-strict prefixed locations <MASK> self.add_issue( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> severity=gixy.severity.HIGH <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if directive.path.endswith(""/"") <TAB>  <TAB>  <TAB>  <TAB>  <TAB> else gixy.severity.MEDIUM, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> directive=[directive, location], <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> break","if not location . path . endswith ( ""/"" ) :",151
"def emit_post_migrate_signal(verbosity, interactive, db, **kwargs): <TAB> # Emit the post_migrate signal for every application. <TAB> for app_config in apps.get_app_configs(): <MASK> continue <TAB>  <TAB> if verbosity >= 2: <TAB>  <TAB>  <TAB> print(""Running post-migrate handlers for application %s"" % app_config.label) <TAB>  <TAB> models.signals.post_migrate.send( <TAB>  <TAB>  <TAB> sender=app_config, <TAB>  <TAB>  <TAB> app_config=app_config, <TAB>  <TAB>  <TAB> verbosity=verbosity, <TAB>  <TAB>  <TAB> interactive=interactive, <TAB>  <TAB>  <TAB> using=db, <TAB>  <TAB>  <TAB> **kwargs <TAB>  <TAB> )",if app_config . models_module is None :,166
"def join(self): <TAB> """"""Wait for transfer to exit, raising errors as necessary."""""" <TAB> self.closed = True <TAB> while self.expect > 0: <TAB>  <TAB> val = self.wait_change.get() <TAB>  <TAB> self.expect -= 1 <MASK> # Wait a while for all running greenlets to exit, and <TAB>  <TAB>  <TAB> # then attempt to force them to exit so join() <TAB>  <TAB>  <TAB> # terminates in a reasonable amount of time. <TAB>  <TAB>  <TAB> gevent.joinall(list(self.greenlets), timeout=30) <TAB>  <TAB>  <TAB> gevent.killall(list(self.greenlets), block=True, timeout=30) <TAB>  <TAB>  <TAB> raise val",if val is not None :,161
"def cmpRegs(emu, trace): <TAB> ctx = trace.getRegisterContext() <TAB> for rname, idx in ctx.getRegisterNameIndexes(): <TAB>  <TAB> er = emu.getRegister(idx) <TAB>  <TAB> tr = trace.getRegisterByName(rname) <TAB>  <TAB> # debug registers aren't really used much anymore... <MASK> raise RegisterException( <TAB>  <TAB>  <TAB>  <TAB> ""REGISTER MISMATCH: %s (trace: 0x%.8x) (emulated: 0x%.8x)"" <TAB>  <TAB>  <TAB>  <TAB> % (rname, tr, er) <TAB>  <TAB>  <TAB> ) <TAB> return True","if er != tr and not rname . startswith ( ""debug"" ) :",152
"def _to_datalibrary_safe(fname, gi, folder_name, sample_info, config): <TAB> """"""Upload with retries for intermittent JSON failures."""""" <TAB> num_tries = 0 <TAB> max_tries = 5 <TAB> while 1: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> _to_datalibrary(fname, gi, folder_name, sample_info, config) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> except ( <TAB>  <TAB>  <TAB> simplejson.scanner.JSONDecodeError, <TAB>  <TAB>  <TAB> bioblend.galaxy.client.ConnectionError, <TAB>  <TAB> ) as e: <TAB>  <TAB>  <TAB> num_tries += 1 <MASK> raise <TAB>  <TAB>  <TAB> print(""Retrying upload, failed with:"", str(e)) <TAB>  <TAB>  <TAB> time.sleep(5)",if num_tries > max_tries :,187
"def process_bind_param(self, value, dialect): <TAB> # Convert list of values to unicode separator-separated list <TAB> # Example: [1, 2, 3, 4] -> u'1, 2, 3, 4' <TAB> if value is not None: <MASK> raise ScalarListException( <TAB>  <TAB>  <TAB>  <TAB> ""List values can't contain string '%s' (its being used as "" <TAB>  <TAB>  <TAB>  <TAB> ""separator. If you wish for scalar list values to contain "" <TAB>  <TAB>  <TAB>  <TAB> ""these strings, use a different separator string.)"" % self.separator <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return self.separator.join(map(six.text_type, value))",if any ( self . separator in six . text_type ( item ) for item in value ) :,175
"def _parse_content(self, content): <TAB> for n, line in enumerate(content.splitlines()): <MASK> continue <TAB>  <TAB> if line: <TAB>  <TAB>  <TAB> req = RequirementsTXTLineParser.parse(line) <TAB>  <TAB>  <TAB> if req: <TAB>  <TAB>  <TAB>  <TAB> req.dependency_type = self.obj.file_type <TAB>  <TAB>  <TAB>  <TAB> self.obj.dependencies.append(req)",if self . is_marked_line ( line ) :,106
"def prepared(self): <TAB> if self.order_by: <TAB>  <TAB> norm_order_by = [] <TAB>  <TAB> for item in self.order_by: <TAB>  <TAB>  <TAB> if isinstance(item, Field): <TAB>  <TAB>  <TAB>  <TAB> prefix = ""-"" if item._ordering == ""DESC"" else """" <TAB>  <TAB>  <TAB>  <TAB> item = prefix + item.name <TAB>  <TAB>  <TAB> field = self.fields[item.lstrip(""-"")] <MASK> norm_order_by.append(field.desc()) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> norm_order_by.append(field.asc()) <TAB>  <TAB> self.order_by = norm_order_by","if item . startswith ( ""-"" ) :",155
"def loadDictionary(fname): <TAB> result = {} <TAB> for lineNo, line in enumerate(open(fname)): <TAB>  <TAB> pair = line[:-1].split(""\t"") <MASK> continue <TAB>  <TAB> wordId, word = pair <TAB>  <TAB> result[int(wordId)] = word <TAB> return result",if len ( pair ) != 2 :,80
"def update_examples_box(data, examples_box, old, new): <TAB> examples_box.source.data = {""Examples"": []} <TAB> unselected = list(set(old) - set(new)) <TAB> selected = list(set(new) - set(old)) <TAB> if len(selected) <= 1 and len(unselected) <= 1: <TAB>  <TAB> examples_box.source.data.update( <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB> ""Examples"": [str(data.iloc[unselected[0], i]) for i in range(4, 24)] <MASK> else [str(data.iloc[selected[0], i]) for i in range(4, 24)] <TAB>  <TAB>  <TAB> } <TAB>  <TAB> )",if len ( unselected ) != 0,176
"def _get_sfaccount_by_name(self, sf_account_name, endpoint=None): <TAB> """"""Get SolidFire account object by name."""""" <TAB> sfaccount = None <TAB> params = {""username"": sf_account_name} <TAB> try: <TAB>  <TAB> data = self._issue_api_request(""GetAccountByName"", params, endpoint=endpoint) <MASK> LOG.debug(""Found solidfire account: %s"", sf_account_name) <TAB>  <TAB>  <TAB> sfaccount = data[""result""][""account""] <TAB> except exception.SolidFireAPIException as ex: <TAB>  <TAB> if ""xUnknownAccount"" in ex.msg: <TAB>  <TAB>  <TAB> return sfaccount <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise <TAB> return sfaccount","if ""result"" in data and ""account"" in data [ ""result"" ] :",192
"def forget(self, identity=None): <TAB> """"""See IAPI."""""" <TAB> headers = () <TAB> if identity is None: <TAB>  <TAB> identity = self.environ.get(""repoze.who.identity"", {}) <TAB> identifier = identity.get(""identifier"") <TAB> if identifier: <TAB>  <TAB> got_headers = identifier.forget(self.environ, identity) <MASK> headers = got_headers <TAB>  <TAB>  <TAB> logger = self.logger <TAB>  <TAB>  <TAB> logger and logger.info( <TAB>  <TAB>  <TAB>  <TAB> ""forgetting via headers from %s: %s"" % (identifier, headers) <TAB>  <TAB>  <TAB> ) <TAB> return headers",if got_headers :,148
"def _get_uniq_name(self, stem): <TAB> count = 0 <TAB> for name_i in self.accounts.keys(): <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> count = max(count, int(name_i[len(stem) :]) + 1) <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB> name = ""{:s}{:d}"".format(stem, count) <TAB> assert name not in self.accounts <TAB> return name",if name_i . startswith ( stem ) :,117
"def is_meta_keywords(self, node: addnodes.meta, nodetype: Any = None) -> bool: <TAB> if nodetype is not None: <TAB>  <TAB> warnings.warn( <TAB>  <TAB>  <TAB> '""nodetype"" argument for WordCollector.is_meta_keywords() ' <TAB>  <TAB>  <TAB> ""is deprecated."", <TAB>  <TAB>  <TAB> RemovedInSphinx40Warning, <TAB>  <TAB>  <TAB> stacklevel=2, <TAB>  <TAB> ) <TAB> if isinstance(node, addnodes.meta) and node.get(""name"") == ""keywords"": <TAB>  <TAB> meta_lang = node.get(""lang"") <MASK> # lang not specified <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> elif meta_lang == self.lang.lang:  # matched to html_search_language <TAB>  <TAB>  <TAB> return True <TAB> return False",if meta_lang is None :,185
"def get_lexicon(self, sentence): <TAB> result = [] <TAB> for i in range(len(sentence)): <TAB>  <TAB> current = self.root <TAB>  <TAB> for j in range(i, len(sentence)): <TAB>  <TAB>  <TAB> current = current.children.get(sentence[j]) <TAB>  <TAB>  <TAB> if current is None: <TAB>  <TAB>  <TAB>  <TAB> break <MASK> result.append([i, j, sentence[i : j + 1]]) <TAB> return result",if current . is_w :,115
def post(self): <TAB> self._split() <TAB> routes = self.scope.pop_routes() <TAB> if routes: <TAB>  <TAB> for route in routes: <TAB>  <TAB>  <TAB> if route.nlri.has_rd() and route.nlri.rd is not RouteDistinguisher.NORD: <TAB>  <TAB>  <TAB>  <TAB> route.nlri.safi = SAFI.mpls_vpn <MASK> route.nlri.safi = SAFI.nlri_mpls <TAB>  <TAB>  <TAB> self.scope.append_route(route) <TAB> return True,elif route . nlri . has_label ( ) and route . nlri . labels is not Labels . NOLABEL :,156
"def _adjust_recovery_parameters(self): <TAB> # It is not strictly necessary, but we can make patroni configs crossi-compatible with all postgres versions. <TAB> recovery_conf = { <TAB>  <TAB> n: v <TAB>  <TAB> for n, v in self._server_parameters.items() <TAB>  <TAB> if n.lower() in self._RECOVERY_PARAMETERS <TAB> } <TAB> if recovery_conf: <TAB>  <TAB> self._config[""recovery_conf""] = recovery_conf <TAB> if self.get(""recovery_conf""): <TAB>  <TAB> value = self._config[""recovery_conf""].pop(self._triggerfile_wrong_name, None) <MASK> self._config[""recovery_conf""][self._triggerfile_good_name] = value","if self . _triggerfile_good_name not in self . _config [ ""recovery_conf"" ] and value :",200
"def open(self): <TAB> with self._lock: <TAB>  <TAB> mailboxes = self.my_config.mailbox.values() <TAB>  <TAB> if self.watching == len(mailboxes): <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.watching = len(mailboxes) <TAB>  <TAB> for d in (""mailbox_state"",): <MASK> self.event.data[d] = {} <TAB>  <TAB> self.event.data[""connection""] = { <TAB>  <TAB>  <TAB> ""live"": False, <TAB>  <TAB>  <TAB> ""error"": [False, _(""Nothing is wrong"")], <TAB>  <TAB> } <TAB> self._log_status(_(""Watching %d POP3 mailboxes"") % self.watching) <TAB> return True",if d not in self . event . data :,175
"def players_from_games(existing, games): <TAB> for g in games: <MASK> continue <TAB>  <TAB> for d in g.drives: <TAB>  <TAB>  <TAB> for p in d.plays: <TAB>  <TAB>  <TAB>  <TAB> for player in p.players: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if player.playerid not in existing: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield player.playerid, player.name",if g is None :,100
"def findall(self, string, pos=0, endpos=None): <TAB> # Return a list of all non-overlapping matches of pattern in string. <TAB> if not endpos is None: <TAB>  <TAB> string = string[:endpos] <TAB> all = [] <TAB> while True: <TAB>  <TAB> m = self.search(string, pos) <TAB>  <TAB> if m is None: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> span = m.span() <MASK> all.append(string[span[0] : span[1]]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> all.append(tuple([group or """" for group in m.groups()])) <TAB>  <TAB> pos = span[1] <TAB> return all <TAB> # Next line bugs in FF2 <TAB> return list(string[pos:].match(self.findall_code))",if not m . groups ( ) :,191
"def check_in_list(self, dataset_loc, ip): <TAB> # Checks the IP in a list(S.No,IP,Rating). <TAB> with open(dataset_loc, ""r"") as f: <TAB>  <TAB> db = f.read() <TAB> db_list = db.split(""\n"") <TAB> for ip_tuple in enumerate(db_list): <TAB>  <TAB> if ip_tuple[0] >= 2: <MASK> ip_rating = ((ip_tuple[1].split("",""))[2]).strip() <TAB>  <TAB>  <TAB>  <TAB> return ip_rating <TAB> return """"",if ip in ip_tuple [ 1 ] :,145
"def header_elements(fieldname, fieldvalue): <TAB> """"""Return a sorted HeaderElement list from a comma-separated header string."""""" <TAB> if not fieldvalue: <TAB>  <TAB> return [] <TAB> result = [] <TAB> for element in fieldvalue.split("",""): <MASK> hv = AcceptElement.from_str(element) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> hv = HeaderElement.from_str(element) <TAB>  <TAB> result.append(hv) <TAB> return list(reversed(sorted(result)))","if fieldname . startswith ( ""Accept"" ) or fieldname == ""TE"" :",129
"def getPassword(prompt="""", confirm=0): <TAB> while 1: <TAB>  <TAB> try1 = tkSimpleDialog.askstring(""Password Dialog"", prompt, show=""*"") <TAB>  <TAB> if not confirm: <TAB>  <TAB>  <TAB> return try1 <TAB>  <TAB> try2 = tkSimpleDialog.askstring(""Password Dialog"", ""Confirm Password"", show=""*"") <MASK> return try1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tkMessageBox.showerror( <TAB>  <TAB>  <TAB>  <TAB> ""Password Mismatch"", ""Passwords did not match, starting over"" <TAB>  <TAB>  <TAB> )",if try1 == try2 :,131
"def setup_data(self, path): <TAB> print(""loading: "" + path) <TAB> with PathManager.open(path) as data_file: <TAB>  <TAB> self.squad = json.load(data_file)[""data""] <TAB> for article in self.squad: <TAB>  <TAB> # each paragraph is a context for the attached questions <TAB>  <TAB> for paragraph in article[""paragraphs""]: <TAB>  <TAB>  <TAB> # each question is an example <TAB>  <TAB>  <TAB> for qa in paragraph[""qas""]: <TAB>  <TAB>  <TAB>  <TAB> question = qa[""question""] <TAB>  <TAB>  <TAB>  <TAB> ans_iter = [{""text"": self.opt[""impossible_answer_string""]}] <MASK> ans_iter = qa[""answers""] <TAB>  <TAB>  <TAB>  <TAB> answers = [a[""text""] for a in ans_iter] <TAB>  <TAB>  <TAB>  <TAB> yield (question, answers), True","if not qa [ ""is_impossible"" ] :",200
"def _init_watcher(self): <TAB> with events._lock: <MASK> # pragma: no branch <TAB>  <TAB>  <TAB> self._watcher = ThreadedChildWatcher() <TAB>  <TAB>  <TAB> if isinstance(threading.current_thread(), threading._MainThread): <TAB>  <TAB>  <TAB>  <TAB> self._watcher.attach_loop(self._local._loop)",if self . _watcher is None :,81
"def dirname(a, sep=sep, mindirlen=mindirlen): <TAB> for i in range(len(a) - 1, -1, -1): <TAB>  <TAB> c = a[i] <MASK> if i < mindirlen: <TAB>  <TAB>  <TAB>  <TAB> return a[: i + 1] <TAB>  <TAB>  <TAB> return a[:i] <TAB> return """"","if c == ""/"" or c == sep :",95
"def installed_conda_targets(conda_context): <TAB> envs_path = conda_context.envs_path <TAB> dir_contents = os.listdir(envs_path) if os.path.exists(envs_path) else [] <TAB> for name in dir_contents: <TAB>  <TAB> versioned_match = VERSIONED_ENV_DIR_NAME.match(name) <TAB>  <TAB> if versioned_match: <TAB>  <TAB>  <TAB> yield CondaTarget(versioned_match.group(1), versioned_match.group(2)) <TAB>  <TAB> unversioned_match = UNVERSIONED_ENV_DIR_NAME.match(name) <MASK> yield CondaTarget(unversioned_match.group(1))",if unversioned_match :,163
"def main(): <TAB> r = redis.StrictRedis.from_url(os.environ[""REDIS_BASE_URL""], decode_responses=True) <TAB> if len(sys.argv) > 1 and sys.argv[1] == ""-d"": <TAB>  <TAB> print(""Dry Run"") <TAB>  <TAB> dry = True <TAB> else: <TAB>  <TAB> print(""Adding u:{user}:colls keys"") <TAB>  <TAB> dry = False <TAB> for key in r.scan_iter(""c:*:*:info""): <TAB>  <TAB> _, user, coll, _2 = key.split("":"") <TAB>  <TAB> target_key = ""u:{user}:colls"".format(user=user) <TAB>  <TAB> print(""sadd {0} {1}"".format(target_key, coll)) <MASK> r.sadd(target_key, coll)",if not dry :,189
"def draw_group_property(self, layout, text, interface_socket): <TAB> # only for input sockets group node nodes with sub trees <TAB> if not interface_socket.hide_value: <TAB>  <TAB> if interface_socket.default_type == ""float"": <TAB>  <TAB>  <TAB> layout.prop(self, ""default_float_property"", text=text) <MASK> layout.prop(self, ""default_int_property"", text=text) <TAB> else: <TAB>  <TAB> layout.label(text=text)","elif interface_socket . default_type == ""int"" :",130
"def main(force_download=True): <TAB> if force_download or not is_available_locally(): <TAB>  <TAB> download_selenium_server() <TAB>  <TAB> for filename in os.listdir("".""): <TAB>  <TAB>  <TAB> # If multiple copies exist, keep only the latest and rename it. <MASK> shutil.move(filename, RENAMED_JAR_FILE) <TAB>  <TAB>  <TAB>  <TAB> if FULL_DOWNLOAD_PATH != FULL_EXPECTED_PATH: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> shutil.move(RENAMED_JAR_FILE, FULL_EXPECTED_PATH) <TAB>  <TAB> print(""%s\n"" % FULL_EXPECTED_PATH)","if filename . startswith ( ""selenium-server-standalone-"" ) :",152
"def getFragTblInfo(self, pos): <TAB> for j in range(len(self.fragtbl)): <TAB>  <TAB> [insertpos, idtext, filenum, seqnum, startpos, length] = self.fragtbl[j] <TAB>  <TAB> if pos >= insertpos and pos < (insertpos + length): <TAB>  <TAB>  <TAB> # why are these ""in: and before: added here <TAB>  <TAB>  <TAB> return seqnum, b""in: "" + idtext <MASK> return seqnum, b""before: "" + idtext <TAB> return None, None",if pos < insertpos :,135
"def __init__(self, application): <TAB> from django.conf import settings <TAB> from django.core.exceptions import ImproperlyConfigured <TAB> for app in settings.INSTALLED_APPS: <MASK> raise ImproperlyConfigured( <TAB>  <TAB>  <TAB>  <TAB> ""You must place 'djangae' before any 'django' apps in INSTALLED_APPS"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> elif app == ""djangae"": <TAB>  <TAB>  <TAB> break <TAB> self.wrapped_app = application","if app . startswith ( ""django."" ) :",110
"def ant_glob(self, *k, **kw): <TAB> if k: <TAB>  <TAB> lst = Utils.to_list(k[0]) <TAB>  <TAB> for pat in lst: <TAB>  <TAB>  <TAB> sp = pat.split(""/"") <TAB>  <TAB>  <TAB> if "".."" in sp: <TAB>  <TAB>  <TAB>  <TAB> Logs.error( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""In ant_glob pattern %r: '..' means 'two dots', not 'parent directory'"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> k[0], <TAB>  <TAB>  <TAB>  <TAB> ) <MASK> Logs.error( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""In ant_glob pattern %r: '.' means 'one dot', not 'current directory'"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> k[0], <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return self.old_ant_glob(*k, **kw)","if ""."" in sp :",190
"def disk_used(path): <TAB> """"""Return the disk usage in a directory."""""" <TAB> size = 0 <TAB> for file in os.listdir(path) + ["".""]: <TAB>  <TAB> stat = os.stat(os.path.join(path, file)) <MASK> size += stat.st_blocks * 512 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # on some platform st_blocks is not available (e.g., Windows) <TAB>  <TAB>  <TAB> # approximate by rounding to next multiple of 512 <TAB>  <TAB>  <TAB> size += (stat.st_size // 512 + 1) * 512 <TAB> # We need to convert to int to avoid having longs on some systems (we <TAB> # don't want longs to avoid problems we SQLite) <TAB> return int(size / 1024.0)","if hasattr ( stat , ""st_blocks"" ) :",185
"def sum_repeats(operand, names, counts, keep_names): <TAB> for name, count in counts.items(): <TAB>  <TAB> if count > 1: <TAB>  <TAB>  <TAB> axes = [i for i, n in enumerate(names) if n == name] <TAB>  <TAB>  <TAB> eye = lax._delta(operand.dtype, operand.shape, axes) <MASK> operand = sum(operand * eye, axes) <TAB>  <TAB>  <TAB>  <TAB> names = names.replace(name, """") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> operand = sum(operand * eye, axes[:-1]) <TAB>  <TAB>  <TAB>  <TAB> names = names.replace(name, """", count - 1) <TAB> return operand, names",if name not in keep_names :,166
"def apply(self, df): <TAB> if cudf and isinstance(df, cudf.DataFrame): <TAB>  <TAB> import cupy <MASK> nullval = np.nan <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> nullval = 0 <TAB>  <TAB> return cupy.array(df[self.column].to_gpu_array(fillna=nullval)) <TAB> elif isinstance(df, xr.Dataset): <TAB>  <TAB> # DataArray could be backed by numpy or cupy array <TAB>  <TAB> return df[self.column].data <TAB> else: <TAB>  <TAB> return df[self.column].values","if df [ self . column ] . dtype . kind == ""f"" :",142
"def _is_valid_batch(self, batch): <TAB> for txn in batch.transactions: <TAB>  <TAB> if txn.header_signature not in self._txn_results: <TAB>  <TAB>  <TAB> raise _UnscheduledTransactionError() <TAB>  <TAB> result = self._txn_results[txn.header_signature] <MASK> return False <TAB> return True",if not result . is_valid :,89
"def _save_checkpoint_callback(fut): <TAB> self._cleaning_tasks() <TAB> self.save() <TAB> # training_history callback <TAB> with self._fifo_lock: <MASK> logger.debug(""Execute training_history callback"") <TAB>  <TAB>  <TAB> self.training_history_callback(self.training_history, self._start_time)",if self . _trigger_training_history_callback ( ) :,95
"def _handle_luannotationset_elt(self, elt): <TAB> """"""Load an annotation set from a sentence in an subcorpus of an LU"""""" <TAB> info = self._load_xml_attributes(AttrDict(), elt) <TAB> info[""_type""] = ""luannotationset"" <TAB> info[""layer""] = [] <TAB> for sub in elt: <TAB>  <TAB> if sub.tag.endswith(""layer""): <TAB>  <TAB>  <TAB> l = self._handle_lulayer_elt(sub) <MASK> info[""layer""].append(l) <TAB> return info",if l is not None :,126
"def get_sorted_mapping(mapping_tuple, len1, len2): <TAB> # Get sorted mapping of nodes/edges <TAB> result_0 = [None] * len1 <TAB> result_1 = [None] * len2 <TAB> for i in range(len(mapping_tuple[0])): <MASK> result_0[mapping_tuple[0][i]] = mapping_tuple[1][i] <TAB>  <TAB>  <TAB> result_1[mapping_tuple[1][i]] = mapping_tuple[0][i] <TAB> return (result_0, result_1)",if mapping_tuple [ 0 ] [ i ] is not None and mapping_tuple [ 1 ] [ i ] is not None :,157
"def assign_type(self, wb_type: ""Type"") -> t.Union[""ListType"", InvalidType]: <TAB> if isinstance(wb_type, ListType): <TAB>  <TAB> assigned_type = self.params[""element_type""].assign_type( <TAB>  <TAB>  <TAB> wb_type.params[""element_type""] <TAB>  <TAB> ) <MASK> return ListType(assigned_type) <TAB> return InvalidType()","if not isinstance ( assigned_type , InvalidType ) :",106
"def to_python(self, value): <TAB> if not self._binary: <TAB>  <TAB> original_value = value <TAB>  <TAB> try: <MASK> value = str(value) <TAB>  <TAB>  <TAB> return uuid.UUID(value) <TAB>  <TAB> except (ValueError, TypeError, AttributeError): <TAB>  <TAB>  <TAB> return original_value <TAB> return value","if not isinstance ( value , str ) :",88
"def __call__(self, value): <TAB> try: <TAB>  <TAB> super(URLValidator, self).__call__(value) <TAB> except ValidationError as e: <TAB>  <TAB> # Trivial case failed. Try for possible IDN domain <MASK> value = force_text(value) <TAB>  <TAB>  <TAB> scheme, netloc, path, query, fragment = urlsplit(value) <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> netloc = netloc.encode(""idna"").decode(""ascii"")  # IDN -> ACE <TAB>  <TAB>  <TAB> except UnicodeError:  # invalid domain part <TAB>  <TAB>  <TAB>  <TAB> raise e <TAB>  <TAB>  <TAB> url = urlunsplit((scheme, netloc, path, query, fragment)) <TAB>  <TAB>  <TAB> super(URLValidator, self).__call__(url) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise <TAB> else: <TAB>  <TAB> url = value",if value :,189
"def _generateDataValues(self, cellsData): <TAB> result = [] <TAB> for data in cellsData: <MASK> result.append( <TAB>  <TAB>  <TAB>  <TAB> TypeConverter.convert(data[:8], Raw, Integer) <TAB>  <TAB>  <TAB> )  # We take only the first 8 octets <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result.append(0) <TAB> return result",if len ( data ) > 0 :,96
"def expect_first_flow_sequence_item(self): <TAB> if isinstance(self.event, SequenceEndEvent): <TAB>  <TAB> self.indent = self.indents.pop() <TAB>  <TAB> self.flow_level -= 1 <TAB>  <TAB> self.write_indicator(u""]"", False) <TAB>  <TAB> self.state = self.states.pop() <TAB> else: <MASK> self.write_indent() <TAB>  <TAB> self.states.append(self.expect_flow_sequence_item) <TAB>  <TAB> self.expect_node(sequence=True)",if self . canonical or self . column > self . best_width :,142
"def iterTags(self, name, attrs={}, namespace=None): <TAB> """"""Iterate over all children using specified arguments as filter."""""" <TAB> for node in self.kids: <TAB>  <TAB> if not node: <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> if node.getName() == name: <TAB>  <TAB>  <TAB> for key in attrs.keys(): <TAB>  <TAB>  <TAB>  <TAB> if key not in node.attrs or node.attrs[key] != attrs[key]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield node",if namespace is not None and namespace != node . getNamespace ( ) :,138
"def update_image(self, image_id, metadata, data): <TAB> for i, image in enumerate(self.images): <TAB>  <TAB> if image[""id""] == str(image_id): <MASK> metadata[""id""] = str(metadata[""id""]) <TAB>  <TAB>  <TAB> self.images[i].update(metadata) <TAB>  <TAB>  <TAB> return self.images[i] <TAB> raise exception.ImageNotFound(image_id=image_id)","if ""id"" in metadata :",112
"def dec(request, *args, **kwargs): <TAB> if request.user.is_authenticated(): <TAB>  <TAB> roles = set([role[""name""].lower() for role in request.user.roles]) <TAB>  <TAB> # set operator <= tests that all members of set 1 are in set 2 <MASK> return view_func(request, *args, **kwargs) <TAB> raise NotAuthorized(_(""You are not authorized to access %s"") % request.path)",if view_func . _required_roles <= set ( roles ) :,117
"def get_type(self, typeDesc): <TAB> for ttype in typeDesc.types: <TAB>  <TAB> if ttype.primitiveEntry is not None: <TAB>  <TAB>  <TAB> return TTypeId._VALUES_TO_NAMES[ttype.primitiveEntry.type] <TAB>  <TAB> elif ttype.mapEntry is not None: <TAB>  <TAB>  <TAB> return ttype.mapEntry <MASK> return ttype.unionEntry <TAB>  <TAB> elif ttype.arrayEntry is not None: <TAB>  <TAB>  <TAB> return ttype.arrayEntry <TAB>  <TAB> elif ttype.structEntry is not None: <TAB>  <TAB>  <TAB> return ttype.structEntry <TAB>  <TAB> elif ttype.userDefinedTypeEntry is not None: <TAB>  <TAB>  <TAB> return ttype.userDefinedTypeEntry",elif ttype . unionEntry is not None :,164
"def set(self, value: Any): <TAB> """"""set new value, limited by range"""""" <TAB> if value is not None: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if self.__int: <TAB>  <TAB>  <TAB>  <TAB> value = int(value) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> value = float(value) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> value = super().default() <TAB>  <TAB> if self.__validation: <TAB>  <TAB>  <TAB> _, val = self.__validation(value) <TAB>  <TAB>  <TAB> super().set(val) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if self.__maxval is not None and value > self.__maxval: <TAB>  <TAB>  <TAB>  <TAB> value = self.__maxval <MASK> value = self.__minval <TAB>  <TAB>  <TAB> super().set(value)",elif self . __minval is not None and value < self . __minval :,189
"def _handle_cors(self): <TAB> origin = self.request.headers.get(""Origin"") <TAB> if not origin: <TAB>  <TAB> return <TAB> if origin == ""null"": <TAB>  <TAB> if self._cors_config.allow_null_origin: <TAB>  <TAB>  <TAB> self.set_header(""Access-Control-Allow-Origin"", ""null"") <TAB> else: <TAB>  <TAB> if self._cors_config.allow_any_origin: <TAB>  <TAB>  <TAB> self.set_header(""Access-Control-Allow-Origin"", ""*"") <MASK> self.set_header(""Access-Control-Allow-Origin"", origin) <TAB>  <TAB>  <TAB> self.set_header(""Vary"", ""Origin"")",elif origin in self . _cors_config . allowed_origins :,169
"def test_setitems_on_non_dicts(self): <TAB> obj = REX_seven({1: -1, 2: -2, 3: -3}) <TAB> for proto in protocols: <MASK> self._check_pickling_with_opcode(obj, pickle.SETITEM, proto) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._check_pickling_with_opcode(obj, pickle.SETITEMS, proto)",if proto == 0 :,112
"def remove_tiles(self, indices): <TAB> """"""Removes a set of tiles from the surface by tile index."""""" <TAB> if self.mipmap_level != 0: <TAB>  <TAB> raise ValueError(""Only call this on the top-level surface."") <TAB> removed = set() <TAB> for tx, ty in indices: <TAB>  <TAB> pos = (tx, ty) <MASK> continue <TAB>  <TAB> self.tiledict.pop(pos) <TAB>  <TAB> removed.add(pos) <TAB>  <TAB> self._mark_mipmap_dirty(tx, ty) <TAB> bbox = lib.surface.get_tiles_bbox(removed) <TAB> self.notify_observers(*bbox)",if pos not in self . tiledict :,162
"def generate_package(args): <TAB> path = args[0] <TAB> manifest = args[1:] <TAB> assert len(manifest) % 2 == 0 <TAB> middle = len(manifest) // 2 <TAB> sources = manifest[:middle] <TAB> destinations = manifest[middle:] <TAB> if path.endswith("".zip""): <TAB>  <TAB> generate_zip_package(path, sources, destinations) <TAB> else: <TAB>  <TAB> for ext in _TAR_WRITE_MODES: <MASK> suffix = ext <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> generate_tar_package(path, sources, destinations, suffix)",if path . endswith ( ext ) :,145
"def execute(self): <TAB> timeout = _get_retry_timeouts() <TAB> stack = self._pipeline.command_stack <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self._pipeline.execute() <TAB>  <TAB> except ConnectionError: <TAB>  <TAB>  <TAB> self._logger.exception(""Connection to Redis failed when executing pipeline"") <TAB>  <TAB>  <TAB> pause = timeout.next() <MASK> break <TAB>  <TAB>  <TAB> sleep(pause) <TAB>  <TAB>  <TAB> self._pipeline.command_stack = stack <TAB>  <TAB> except ResponseError: <TAB>  <TAB>  <TAB> self._logger.exception(""Redis operation failed when executing pipeline"") <TAB>  <TAB>  <TAB> break",if pause is None :,150
"def __iter__(self): <TAB> print(""Iterating corpus from the start..."") <TAB> i = 0 <TAB> for language, filename in self.input_files: <TAB>  <TAB> for text in open(filename): <MASK> yield Sentence(language, text.lower()) <TAB>  <TAB>  <TAB> i += 1 <TAB>  <TAB>  <TAB> if i % 10000 == 0: <TAB>  <TAB>  <TAB>  <TAB> print(""\tReaded {} examples"".format(i))",if self . accept_criteria ( i ) :,108
"def _is_section_header(self) -> bool: <TAB> section = self._line_iter.peek().lower() <TAB> match = _google_section_regex.match(section) <TAB> if match and section.strip("":"") in self._sections: <TAB>  <TAB> header_indent = self._get_indent(section) <TAB>  <TAB> section_indent = self._get_current_indent(peek_ahead=1) <TAB>  <TAB> return section_indent > header_indent <TAB> elif self._directive_sections: <TAB>  <TAB> if _directive_regex.match(section): <TAB>  <TAB>  <TAB> for directive_section in self._directive_sections: <MASK> return True <TAB> return False",if section . startswith ( directive_section ) :,167
def nbytes(self) -> int: <TAB> if self._use_arrow: <TAB>  <TAB> return sum( <TAB>  <TAB>  <TAB> x.size <TAB>  <TAB>  <TAB> for chunk in self._arrow_array.chunks <TAB>  <TAB>  <TAB> for x in chunk.buffers() <MASK> ) <TAB> else: <TAB>  <TAB> return self._ndarray.nbytes,if x is not None,82
"def run_sequential(config, venv_dict): <TAB> for venv in venv_dict.values(): <TAB>  <TAB> if venv.setupenv(): <TAB>  <TAB>  <TAB> if venv.envconfig.skip_install: <TAB>  <TAB>  <TAB>  <TAB> venv.finishvenv() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> if venv.envconfig.usedevelop: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> develop_pkg(venv, config.setupdir) <TAB>  <TAB>  <TAB>  <TAB> elif config.skipsdist: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> venv.finishvenv() <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> installpkg(venv, venv.package) <MASK> runenvreport(venv, config) <TAB>  <TAB> if venv.status == 0: <TAB>  <TAB>  <TAB> runtestenv(venv, config)",if venv . status == 0 :,182
"def threshold_detector(low_threshold, high_threshold): <TAB> """"""Yields 'low', 'high', and None events."""""" <TAB> assert low_threshold < high_threshold <TAB> event = None <TAB> prev_score = 0.0 <TAB> while True: <TAB>  <TAB> score = yield event <TAB>  <TAB> if score > high_threshold > prev_score: <TAB>  <TAB>  <TAB> event = ""high"" <MASK> event = ""low"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> event = None <TAB>  <TAB> prev_score = score",elif score < low_threshold < prev_score :,130
"def rm(path): <TAB> path = try_unicode(path) <TAB> path = os.path.expanduser(path) <TAB> path = os.path.expandvars(path) <TAB> found = False <TAB> for path in glob.iglob(path): <MASK> found = True <TAB>  <TAB>  <TAB> if os.path.isdir(path): <TAB>  <TAB>  <TAB>  <TAB> shutil.rmtree(path) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> os.remove(path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""File/directory does not exists"") <TAB> if not found: <TAB>  <TAB> raise ValueError(""File/directory does not exists"")",if os . path . exists ( path ) :,154
"def distinct(seq, key=EMPTY): <TAB> """"""Iterates over sequence skipping duplicates"""""" <TAB> seen = set() <TAB> # check if key is supplied out of loop for efficiency <TAB> if key is EMPTY: <TAB>  <TAB> for item in seq: <MASK> seen.add(item) <TAB>  <TAB>  <TAB>  <TAB> yield item <TAB> else: <TAB>  <TAB> key = make_func(key) <TAB>  <TAB> for item in seq: <TAB>  <TAB>  <TAB> k = key(item) <TAB>  <TAB>  <TAB> if k not in seen: <TAB>  <TAB>  <TAB>  <TAB> seen.add(k) <TAB>  <TAB>  <TAB>  <TAB> yield item",if item not in seen :,142
"def _time_from_json(value, field): <TAB> """"""Coerce 'value' to a datetime date, if set or not nullable"""""" <TAB> if _not_null(value, field): <TAB>  <TAB> if len(value) == 8:  # HH:MM:SS <TAB>  <TAB>  <TAB> fmt = _TIMEONLY_WO_MICROS <MASK> # HH:MM:SS.micros <TAB>  <TAB>  <TAB> fmt = _TIMEONLY_W_MICROS <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""Unknown time format: {}"".format(value)) <TAB>  <TAB> return datetime.datetime.strptime(value, fmt).time()",elif len ( value ) == 15 :,152
"def _test_export(self, model, framework, opset, tokenizer=None): <TAB> try: <TAB>  <TAB> # Compute path <TAB>  <TAB> with TemporaryDirectory() as tempdir: <TAB>  <TAB>  <TAB> path = Path(tempdir).joinpath(""model.onnx"") <TAB>  <TAB> # Remove folder if exists <MASK> path.parent.rmdir() <TAB>  <TAB> # Export <TAB>  <TAB> convert(framework, model, path, opset, tokenizer) <TAB>  <TAB> return path <TAB> except Exception as e: <TAB>  <TAB> self.fail(e)",if path . parent . exists ( ) :,127
"def load(self): <TAB> session_data = {} <TAB> try: <TAB>  <TAB> session_file = open(self._key_to_file(), ""rb"") <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> file_data = session_file.read() <TAB>  <TAB>  <TAB> # Don't fail if there is no data in the session file. <TAB>  <TAB>  <TAB> # We may have opened the empty placeholder file. <MASK> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> session_data = self.decode(file_data) <TAB>  <TAB>  <TAB>  <TAB> except (EOFError, SuspiciousOperation): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.create() <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> session_file.close() <TAB> except IOError: <TAB>  <TAB> pass <TAB> return session_data",if file_data :,175
"def _chunk_array_leaves_in_place(d): <TAB> """"""Convert oversized array leaves to safe chunked form in place."""""" <TAB> if isinstance(d, dict): <TAB>  <TAB> for k, v in d.items(): <MASK> if v.size * v.dtype.itemsize > MAX_CHUNK_SIZE: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> d[k] = _chunk(v) <TAB>  <TAB>  <TAB> elif isinstance(v, dict): <TAB>  <TAB>  <TAB>  <TAB> _chunk_array_leaves_in_place(v) <TAB> elif isinstance(d, np.ndarray): <TAB>  <TAB> if d.size * d.dtype.itemsize > MAX_CHUNK_SIZE: <TAB>  <TAB>  <TAB> return _chunk(d) <TAB> return d","if isinstance ( v , np . ndarray ) :",176
"def __subclasshook__(cls, C): <TAB> if cls is PrivateChannel: <TAB>  <TAB> if Snowflake.__subclasshook__(C) is NotImplemented: <TAB>  <TAB>  <TAB> return NotImplemented <TAB>  <TAB> mro = C.__mro__ <TAB>  <TAB> for base in mro: <MASK> return True <TAB>  <TAB> return NotImplemented <TAB> return NotImplemented","if ""me"" in base . __dict__ :",86
"def next(self): <TAB> if not self.expvar: <MASK> raise StopIteration <TAB>  <TAB> return [{""ts"": int(time.time() - 1), ""metrics"": {""instances"": 0, ""reqps"": 0}}] <TAB> else: <TAB>  <TAB> if self.closed: <TAB>  <TAB>  <TAB> raise StopIteration() <TAB>  <TAB> elif not self.started: <TAB>  <TAB>  <TAB> self.poller.start() <TAB>  <TAB>  <TAB> self.started = True <TAB>  <TAB> return self.poller.get_data()",if self . closed :,121
"def start_font(self, attrs): <TAB> for key, value in attrs.items(): <TAB>  <TAB> if key == ""size"": <TAB>  <TAB>  <TAB> value = int(value) <MASK> value = _families[value] <TAB>  <TAB> elif key == ""style"": <TAB>  <TAB>  <TAB> value = _styles[value] <TAB>  <TAB> elif key == ""weight"": <TAB>  <TAB>  <TAB> value = _weights[value] <TAB>  <TAB> elif key == ""encoding"": <TAB>  <TAB>  <TAB> value = int(value) <TAB>  <TAB> elif key == ""color"": <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""unknown font attribute '%s'"" % key) <TAB>  <TAB> attrs[key] = value <TAB> font = copy.copy(self.fonts[-1]) <TAB> font.update(attrs) <TAB> self.fonts.append(font)","elif key == ""family"" :",195
"def mark_current_incomplete(self, restore_retry=False): <TAB> with self._current_item_lock: <MASK> self._queue.incomplete( <TAB>  <TAB>  <TAB>  <TAB> self.current_queue_item, <TAB>  <TAB>  <TAB>  <TAB> restore_retry=restore_retry, <TAB>  <TAB>  <TAB>  <TAB> retry_after=self._retry_after_seconds, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.current_queue_item = None",if self . current_queue_item is not None :,113
"def scan_resource_conf(self, conf): <TAB> if ""allow"" in conf: <TAB>  <TAB> allow_blocks = conf[""allow""] <TAB>  <TAB> for block in allow_blocks: <TAB>  <TAB>  <TAB> if isinstance(block, str): <TAB>  <TAB>  <TAB>  <TAB> return CheckResult.UNKNOWN <MASK> if self._is_port_in_range(block[""ports""]): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if ""source_ranges"" in conf.keys(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> source_ranges = conf[""source_ranges""][0] <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if ""0.0.0.0/0"" in source_ranges:  # nosec <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return CheckResult.FAILED <TAB> return CheckResult.PASSED","if ""ports"" in block :",179
"def assertRaisesErrno(self, errnos, func, *args): <TAB> try: <TAB>  <TAB> func(*args) <TAB> except zmq.ZMQError as e: <TAB>  <TAB> if not hasattr(errnos, ""__iter__""): <TAB>  <TAB>  <TAB> errnos = (errnos,) <MASK> raise AssertionError( <TAB>  <TAB>  <TAB>  <TAB> ""wrong error raised, expected one of ['%s'], got '%s'"" <TAB>  <TAB>  <TAB>  <TAB> % ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> "", "".join(""%s"" % zmq.ZMQError(errno) for errno in errnos), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> zmq.ZMQError(e.errno), <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> self.fail(""Function did not raise any error"")",if e . errno not in errnos :,184
"def detect(get_page): <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS: <TAB>  <TAB> page, headers, code = get_page(get=vector) <TAB>  <TAB> retval = headers.get(""X-Varnish"") is not None <TAB>  <TAB> retval |= ( <TAB>  <TAB>  <TAB> re.search(r""varnish\Z"", headers.get(HTTP_HEADER.VIA, """"), re.I) is not None <TAB>  <TAB> ) <MASK> break <TAB> return retval",if retval :,123
"def _add_bind(self, key, bind): <TAB> try: <TAB>  <TAB> insp = inspect(key) <TAB> except sa_exc.NoInspectionAvailable: <TAB>  <TAB> if not isinstance(key, type): <TAB>  <TAB>  <TAB> raise sa_exc.ArgumentError(""Not an acceptable bind target: %s"" % key) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.__binds[key] = bind <TAB> else: <MASK> self.__binds[insp] = bind <TAB>  <TAB> elif insp.is_mapper: <TAB>  <TAB>  <TAB> self.__binds[insp.class_] = bind <TAB>  <TAB>  <TAB> for selectable in insp._all_tables: <TAB>  <TAB>  <TAB>  <TAB> self.__binds[selectable] = bind <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise sa_exc.ArgumentError(""Not an acceptable bind target: %s"" % key)",if insp . is_selectable :,196
"def run(self): <TAB> optional = True <TAB> disabled = True <TAB> for ext in self.extensions: <TAB>  <TAB> with_ext = self.distribution.ext_status(ext) <TAB>  <TAB> if with_ext is None: <TAB>  <TAB>  <TAB> disabled = False <MASK> optional = False <TAB>  <TAB>  <TAB> disabled = False <TAB>  <TAB>  <TAB> break <TAB> if disabled: <TAB>  <TAB> return <TAB> try: <TAB>  <TAB> _build_ext.run(self) <TAB> except DistutilsPlatformError: <TAB>  <TAB> exc = sys.exc_info()[1] <TAB>  <TAB> if optional: <TAB>  <TAB>  <TAB> log.warn(str(exc)) <TAB>  <TAB>  <TAB> log.warn(""skipping build_ext"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise",elif with_ext :,173
"def _reset(self, verify_external_attributes): <TAB> self.expected_files = 0 <TAB> self.expected_symlinks = 0 <TAB> self.actual_files = 0 <TAB> self.actual_symlinks = 0 <TAB> if verify_external_attributes: <TAB>  <TAB> for filename, data in self.files_with_external_attr.items(): <TAB>  <TAB>  <TAB> if data[""file_type""] == 0o12: <TAB>  <TAB>  <TAB>  <TAB> self.expected_symlinks += 1 <MASK> self.expected_files += 1","elif data [ ""file_type"" ] == 0o10 :",134
"def apply(self, db, person): <TAB> for event_ref in person.get_event_ref_list(): <TAB>  <TAB> if event_ref: <TAB>  <TAB>  <TAB> event = db.get_event_from_handle(event_ref.ref) <MASK> return True <TAB>  <TAB>  <TAB> if not event.get_date_object(): <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if not event . get_place_handle ( ) :,103
"def _drawBorderLine(bstyle, width, color, x1, y1, x2, y2): <TAB> # We need width and border style to be able to draw a border <TAB> if width and bstyle: <TAB>  <TAB> # If no color for border is given, the text color is used (like defined by W3C) <TAB>  <TAB> if color is None: <TAB>  <TAB>  <TAB> color = self.get(""textColor"", Color(0, 0, 0)) <MASK> canvas.setStrokeColor(color) <TAB>  <TAB>  <TAB> canvas.setLineWidth(width) <TAB>  <TAB>  <TAB> canvas.line(x1, y1, x2, y2)",if color is not None :,158
"def lispify_field(field, child): <TAB> yield field <TAB> if not isinstance(child, list): <TAB>  <TAB> children = [child] <TAB> else: <TAB>  <TAB> children = child <TAB> for node in children: <MASK> yield lispify_ast(node) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if isinstance(node, float): <TAB>  <TAB>  <TAB>  <TAB> # stringify floats so they match Java's float representation better <TAB>  <TAB>  <TAB>  <TAB> yield str(node) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield node","if isinstance ( node , _ast . AST ) :",132
"def _infere_context_data(self, path: str) -> str: <TAB> """"""If this is a remote session, infere context data if any"""""" <TAB> if is_remote_session(self.view): <TAB>  <TAB> window = self.view.window().id() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> interpreter = Market().get(window).interpreter <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> print(""while getting interp for Window ID {}: {}"".format(window, e)) <TAB>  <TAB>  <TAB> return path <TAB>  <TAB> directory_map = interpreter.pathmap <MASK> return path <TAB>  <TAB> for local_dir, remote_dir in directory_map.items(): <TAB>  <TAB>  <TAB> if remote_dir in path: <TAB>  <TAB>  <TAB>  <TAB> return path.replace(remote_dir, local_dir) <TAB> return path",if directory_map is None :,194
"def _hang_shares(self, shnums, **kwargs): <TAB> # hang all servers who are holding the given shares <TAB> hung_serverids = set() <TAB> for (i_shnum, i_serverid, i_sharefile) in self.shares: <TAB>  <TAB> if i_shnum in shnums: <MASK> self.g.hang_server(i_serverid, **kwargs) <TAB>  <TAB>  <TAB>  <TAB> hung_serverids.add(i_serverid)",if i_serverid not in hung_serverids :,128
"def process_event(self, event): <TAB> if event is not None: <TAB>  <TAB> if isinstance(event, KeyboardEvent): <TAB>  <TAB>  <TAB> if event.key_code in [Screen.ctrl(""M""), Screen.ctrl(""J""), ord("" "")]: <TAB>  <TAB>  <TAB>  <TAB> event = None <MASK> if event.buttons != 0: <TAB>  <TAB>  <TAB>  <TAB> if self.is_mouse_over(event, include_label=False): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> event = None <TAB>  <TAB> if event is None: <TAB>  <TAB>  <TAB> self._child = _DropdownPopup(self) <TAB>  <TAB>  <TAB> self.frame.scene.add_effect(self._child) <TAB> return event","elif isinstance ( event , MouseEvent ) :",169
"def __init__(self, **kwargs): <TAB> unset = self._props.copy() <TAB> for k, v in kwargs.items(): <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Event %s has no parameter called %s"" % (self.event_name, k) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> setattr(self, k, v) <TAB>  <TAB> unset.remove(k) <TAB> for k in unset: <TAB>  <TAB> setattr(self, k, None) <TAB> self._delivered_to = set()",if k not in self . _props :,130
"def CountInOutOptArgs(self, argTuple): <TAB> ""Return tuple counting in/outs/OPTS.  Sum of result may not be len(argTuple), as some args may be in/out."" <TAB> ins = out = opts = 0 <TAB> for argCheck in argTuple: <TAB>  <TAB> inOut = argCheck[1] <TAB>  <TAB> if inOut == 0: <TAB>  <TAB>  <TAB> ins = ins + 1 <TAB>  <TAB>  <TAB> out = out + 1 <TAB>  <TAB> else: <MASK> ins = ins + 1 <TAB>  <TAB>  <TAB> if inOut & pythoncom.PARAMFLAG_FOPT: <TAB>  <TAB>  <TAB>  <TAB> opts = opts + 1 <TAB>  <TAB>  <TAB> if inOut & pythoncom.PARAMFLAG_FOUT: <TAB>  <TAB>  <TAB>  <TAB> out = out + 1 <TAB> return ins, out, opts",if inOut & pythoncom . PARAMFLAG_FIN :,198
"def get_config_grid(dict_space): <TAB> param_grid = {} <TAB> constants = {} <TAB> for k, v in dict_space.items(): <MASK> param_grid[k] = v.data <TAB>  <TAB> elif isinstance(v, Space): <TAB>  <TAB>  <TAB> raise NotImplementedError <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> constants[k] = v <TAB> from sklearn.model_selection import ParameterGrid <TAB> configs = list(ParameterGrid(param_grid)) <TAB> for config in configs: <TAB>  <TAB> config.update(constants) <TAB> return configs","if isinstance ( v , Categorical ) :",136
"def init_weight(self): <TAB> for layer in self.sublayers(): <MASK> param_init.normal_init(layer.weight, std=0.001) <TAB>  <TAB> elif isinstance(layer, (nn.BatchNorm, nn.SyncBatchNorm)): <TAB>  <TAB>  <TAB> param_init.constant_init(layer.weight, value=1.0) <TAB>  <TAB>  <TAB> param_init.constant_init(layer.bias, value=0.0) <TAB> if self.pretrained is not None: <TAB>  <TAB> utils.load_pretrained_model(self, self.pretrained)","if isinstance ( layer , nn . Conv2D ) :",143
"def translate_block(self, mochi_block, filename=""<string>"", show_tokens=False): <TAB> """"""Translate sexpressions into a Python AST."""""" <TAB> sexps = parse(lex(mochi_block, debug=show_tokens), filename) <TAB> body = [] <TAB> for sexp in sexps: <MASK> sexp = tuple_it(sexp) <TAB>  <TAB> if sexp is COMMENT: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> pre, value = self.translate(sexp) <TAB>  <TAB> body.extend([self.enclose(exp, True) for exp in pre]) <TAB>  <TAB> body.append(self.enclose(value, True)) <TAB> return ast.Module(body=body)","if isinstance ( sexp , MutableSequence ) :",172
"def __call__(self, data: Data, ind): <TAB> pos = data.pos <TAB> point = pos[ind].view(1, 3) <TAB> ind, dist = ball_query(point, pos, radius=self.radius_patch, max_num=-1, mode=1) <TAB> row, col = ind[dist[:, 0] > 0].t() <TAB> patch = Data() <TAB> for key in data.keys: <TAB>  <TAB> if torch.is_tensor(data[key]): <MASK> patch[key] = data[key][col] <TAB> return patch",if torch . all ( col < data [ key ] . shape [ 0 ] ) :,151
"def get_component_id(self): <TAB> SENTINEL = 5000 <TAB> for i in range(self.component_index, SENTINEL): <TAB>  <TAB> id = ""component%s"" % i <MASK> self.component_index = i + 1 <TAB>  <TAB>  <TAB> return id <TAB> else: <TAB>  <TAB> raise Error( <TAB>  <TAB>  <TAB> ""hit sentinel on number of 'component<num>' "" <TAB>  <TAB>  <TAB> ""Component ids: if you *do* actually have more "" <TAB>  <TAB>  <TAB> ""than %d components in your WiX project then "" <TAB>  <TAB>  <TAB> ""you'll need to increase SENTINEL in the code, "" <TAB>  <TAB>  <TAB> ""otherwise there is a bug"" % SENTINEL <TAB>  <TAB> )",if id not in self . component_ids :,178
"def _save_program_edit_info_callback(self, dialog, response_id, edit_data): <TAB> if response_id != Gtk.ResponseType.ACCEPT: <TAB>  <TAB> dialog.destroy() <TAB> else: <MASK> save_file = dialog.get_filename() <TAB>  <TAB>  <TAB> dialog.destroy() <TAB>  <TAB>  <TAB> if save_file == None: <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> with open(save_file, ""w"") as f: <TAB>  <TAB>  <TAB>  <TAB> json.dump(edit_data, f, indent=4)",if self . container_data . container_type == appconsts . CONTAINER_CLIP_BLENDER :,149
"def candidates() -> Generator[Symbol, None, None]: <TAB> s = self <TAB> if Symbol.debug_lookup: <TAB>  <TAB> Symbol.debug_print(""searching in self:"") <TAB>  <TAB> print(s.to_string(Symbol.debug_indent + 1), end="""") <TAB> while True: <TAB>  <TAB> if matchSelf: <TAB>  <TAB>  <TAB> yield s <MASK> yield from s.children_recurse_anon <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield from s._children <TAB>  <TAB> if s.siblingAbove is None: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> s = s.siblingAbove <TAB>  <TAB> if Symbol.debug_lookup: <TAB>  <TAB>  <TAB> Symbol.debug_print(""searching in sibling:"") <TAB>  <TAB>  <TAB> print(s.to_string(Symbol.debug_indent + 1), end="""")",if recurseInAnon :,190
"def test_full_hd_web_dl(self): <TAB> cur_test = ""full_hd_web_dl"" <TAB> cur_qual = common.Quality.FULLHDWEBDL <TAB> for name, tests in iteritems(self.test_cases): <TAB>  <TAB> for test in tests: <MASK> self.assertEqual(cur_qual, common.Quality.name_quality(test)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.assertNotEqual(cur_qual, common.Quality.name_quality(test))",if name == cur_test :,136
"def inner(*args, **kwargs): <TAB> auth_token = get_auth_token() <TAB> if auth_token is not None: <TAB>  <TAB> user = ( <TAB>  <TAB>  <TAB> ub.session.query(ub.User) <TAB>  <TAB>  <TAB> .join(ub.RemoteAuthToken) <TAB>  <TAB>  <TAB> .filter(ub.RemoteAuthToken.auth_token == auth_token) <TAB>  <TAB>  <TAB> .filter(ub.RemoteAuthToken.token_type == 1) <TAB>  <TAB>  <TAB> .first() <TAB>  <TAB> ) <MASK> login_user(user) <TAB>  <TAB>  <TAB> return f(*args, **kwargs) <TAB>  <TAB> log.debug(""Received Kobo request without a recognizable auth token."") <TAB>  <TAB> return abort(401)",if user is not None :,170
"def mesh(self, df): <TAB> # allow PyntCloud to don't have mesh assigned <TAB> if df is not None: <TAB>  <TAB> if not isinstance(df, pd.DataFrame): <TAB>  <TAB>  <TAB> raise TypeError(""Mesh argument must be a DataFrame"") <MASK> print(df.columns) <TAB>  <TAB>  <TAB> raise ValueError(""Mesh must have v1, v2 and v3 columns, at least"") <TAB>  <TAB> self.__mesh = df <TAB> else: <TAB>  <TAB> self.__mesh = None","elif not set ( [ ""v1"" , ""v2"" , ""v3"" ] ) . issubset ( df . columns ) :",137
"def _check_valid_s3_path( <TAB> path: str,) -> None: <TAB> """"""Performs a basic check for validity of the S3 path"""""" <TAB> bad_chars = [c for c in INVALID_S3_CHARS if c in path] <TAB> if len(bad_chars) > 0: <TAB>  <TAB> msg = ( <TAB>  <TAB>  <TAB> f""The parsed S3 path={path} contains the invalid characters {bad_chars}."" <TAB>  <TAB>  <TAB> ""Please make sure your regex is correct and characters are escaped."" <TAB>  <TAB> ) <MASK> msg += ""Note: `*` is internally used to replace the regex for `.`."" <TAB>  <TAB> raise ParserError(msg)","if ""*"" in bad_chars :",160
"def fit(self, X, y): <TAB> import scipy.sparse <TAB> import sklearn.feature_selection <TAB> self.preprocessor = sklearn.feature_selection.SelectPercentile( <TAB>  <TAB> score_func=self.score_func, <TAB>  <TAB> percentile=self.percentile, <TAB> ) <TAB> # Because the pipeline guarantees that each feature is positive, <TAB> # clip all values below zero to zero <TAB> if self.score_func == sklearn.feature_selection.chi2: <MASK> X.data[X.data < 0] = 0.0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> X[X < 0] = 0.0 <TAB> self.preprocessor.fit(X, y) <TAB> return self",if scipy . sparse . issparse ( X ) :,170
"def findNeighbors(self, node, k=None, exclude=None): <TAB> k = k or self.ksize <TAB> nodes = [] <TAB> for neighbor in TableTraverser(self, node): <MASK> heapq.heappush(nodes, (node.distanceTo(neighbor), neighbor)) <TAB>  <TAB> if len(nodes) == k: <TAB>  <TAB>  <TAB> break <TAB> return map(operator.itemgetter(1), heapq.nsmallest(k, nodes))",if exclude is None or not neighbor . sameHomeAs ( exclude ) :,118
"def _peek_unlocked(self, n=0): <TAB> want = min(n, self.buffer_size) <TAB> have = len(self._read_buf) - self._read_pos <TAB> if have < want: <TAB>  <TAB> to_read = self.buffer_size - have <TAB>  <TAB> current = self.raw.read(to_read) <MASK> self._read_buf = self._read_buf[self._read_pos :] + current <TAB>  <TAB>  <TAB> self._read_pos = 0 <TAB> return self._read_buf[self._read_pos :]",if current :,138
"def scan(self, string): <TAB> result = [] <TAB> append = result.append <TAB> match = self.scanner.scanner(string).match <TAB> i = 0 <TAB> while 1: <TAB>  <TAB> m = match() <TAB>  <TAB> if not m: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> j = m.end() <MASK> break <TAB>  <TAB> action = self.lexicon[m.lastindex - 1][1] <TAB>  <TAB> if callable(action): <TAB>  <TAB>  <TAB> self.match = m <TAB>  <TAB>  <TAB> action = action(self, m.group()) <TAB>  <TAB> if action is not None: <TAB>  <TAB>  <TAB> append(action) <TAB>  <TAB> i = j <TAB> return result, string[i:]",if i == j :,165
"def parse_precision(p): <TAB> """"""Calculate the min and max allowed digits"""""" <TAB> min = max = 0 <TAB> for c in p: <TAB>  <TAB> if c in ""@0"": <TAB>  <TAB>  <TAB> min += 1 <TAB>  <TAB>  <TAB> max += 1 <TAB>  <TAB> elif c == ""#"": <TAB>  <TAB>  <TAB> max += 1 <MASK> continue <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> return min, max","elif c == "","" :",98
"def sniff(self, filename): <TAB> # The first 4 bytes of any GROMACS binary file containing the magic number <TAB> try: <TAB>  <TAB> header = open(filename, ""rb"").read(struct.calcsize("">1i"")) <MASK> return True <TAB>  <TAB> return False <TAB> except Exception: <TAB>  <TAB> return False","if struct . unpack ( "">1i"" , header ) [ 0 ] == self . magic_number :",97
"def _from_bin(cls, addr): <TAB> rest = addr <TAB> labels = [] <TAB> if cls._has_no_label(rest): <TAB>  <TAB> return ([],) + cls._prefix_from_bin(rest) <TAB> while True: <TAB>  <TAB> (label, rest) = cls._label_from_bin(rest) <TAB>  <TAB> labels.append(label >> 4) <MASK> break <TAB> return (labels,) + cls._prefix_from_bin(rest)",if label & 1 or label in cls . _WITHDRAW_LABELS :,125
"def join(a, *p): <TAB> """"""Join two or more pathname components, inserting sep as needed"""""" <TAB> path = a <TAB> for b in p: <TAB>  <TAB> if isabs(b): <TAB>  <TAB>  <TAB> path = b <MASK> path = path + b <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> path = path + ""/"" + b <TAB> return path","elif path == """" or path [ - 1 : ] in ""/\\:"" :",96
"def check_for_setup_error(self): <TAB> """"""Returns an error if prerequisites aren't met"""""" <TAB> try: <TAB>  <TAB> # NOTE(francois-charlier) Since 0.24 'collie cluster info -r' <TAB>  <TAB> #  gives short output, but for compatibility reason we won't <TAB>  <TAB> #  use it and just check if 'running' is in the output. <TAB>  <TAB> (out, err) = self._execute(""collie"", ""cluster"", ""info"") <MASK> raise exception.Error(_(""Sheepdog is not working: %s"") % out) <TAB> except exception.ProcessExecutionError: <TAB>  <TAB> raise exception.Error(_(""Sheepdog is not working""))","if not ""running"" in out . split ( ) :",175
"def run(self, edit, external_id, text, with_auto_postfix=True): <TAB> for rv in manager.find_repl(external_id): <TAB>  <TAB> if with_auto_postfix: <TAB>  <TAB>  <TAB> text += rv.repl.cmd_postfix <MASK> rv.append_input_text(text) <TAB>  <TAB>  <TAB> rv.adjust_end() <TAB>  <TAB> SENDERS[external_id](rv.repl, text, self.view, rv) <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> sublime.error_message(""Cannot find REPL for '{}'"".format(external_id))","if sublime . load_settings ( SETTINGS_FILE ) . get ( ""show_transferred_text"" ) :",161
"def process_config(self): <TAB> super(HttpdCollector, self).process_config() <TAB> if ""url"" in self.config: <TAB>  <TAB> self.config[""urls""].append(self.config[""url""]) <TAB> self.urls = {} <TAB> if isinstance(self.config[""urls""], basestring): <TAB>  <TAB> self.config[""urls""] = self.config[""urls""].split("","") <TAB> for url in self.config[""urls""]: <TAB>  <TAB> # Handle the case where there is a trailing comman on the urls list <MASK> continue <TAB>  <TAB> if "" "" in url: <TAB>  <TAB>  <TAB> parts = url.split("" "") <TAB>  <TAB>  <TAB> self.urls[parts[0]] = parts[1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.urls[""""] = url",if len ( url ) == 0 :,187
"def check_for_required_installed_apps(app_configs, **kwargs): <TAB> errors = [] <TAB> for app in REQUIRED_INSTALLED_APPS: <MASK> errors.append( <TAB>  <TAB>  <TAB>  <TAB> Error( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""needs %s in INSTALLED_APPS"" % app[1], <TAB>  <TAB>  <TAB>  <TAB>  <TAB> id=""wiki.%s"" % app[2], <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> return errors",if not apps . is_installed ( app [ 0 ] ) :,117
"def gevent_wait_callback(conn, timeout=None): <TAB> """"""A wait callback useful to allow gevent to work with Psycopg."""""" <TAB> while 1: <TAB>  <TAB> state = conn.poll() <TAB>  <TAB> if state == extensions.POLL_OK: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif state == extensions.POLL_READ: <TAB>  <TAB>  <TAB> wait_read(conn.fileno(), timeout=timeout) <MASK> wait_write(conn.fileno(), timeout=timeout) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise psycopg2.OperationalError(""Bad result from poll: %r"" % state)",elif state == extensions . POLL_WRITE :,143
"def _verify_condition(condition, default_msg, given_msg, include_default=False): <TAB> if not condition: <MASK> raise AssertionError(default_msg) <TAB>  <TAB> if _include_default_message(include_default): <TAB>  <TAB>  <TAB> raise AssertionError(given_msg + ""\n"" + default_msg) <TAB>  <TAB> raise AssertionError(given_msg)",if not given_msg :,93
"def logCoordY(self, coordY): <TAB> if self._minY is None: <TAB>  <TAB> self._minY = coordY <TAB>  <TAB> self._maxY = coordY <TAB> else: <MASK> self._minY = coordY <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if self._maxY < coordY: <TAB>  <TAB>  <TAB>  <TAB> self._maxY = coordY",if self . _minY > coordY :,99
"def _run(command, project: Path) -> Tuple[bool, str]: <TAB> result = subprocess.run( <TAB>  <TAB> command, <TAB>  <TAB> stdout=subprocess.PIPE, <TAB>  <TAB> stderr=subprocess.PIPE, <TAB>  <TAB> cwd=str(project), <TAB> ) <TAB> stdout = result.stdout.decode().strip() <TAB> if result.returncode != 0: <TAB>  <TAB> stderr = result.stderr.decode().strip() <TAB>  <TAB> if stderr: <TAB>  <TAB>  <TAB> logger.debug(stderr) <MASK> logger.debug(stdout) <TAB>  <TAB> return False, stderr <TAB> return True, stdout",if stdout :,140
"def _recursive_func(self, obj, func): <TAB> if isinstance(obj, np.ndarray): <MASK> return np.reshape([func(val) for val in obj], obj.shape) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return np.reshape([self._recursive_func(o, func) for o in obj], obj.shape) <TAB> elif isinstance(obj, Iterable): <TAB>  <TAB> return type(obj)( <TAB>  <TAB>  <TAB> self._recursive_func(o, func) if isinstance(o, Iterable) else func(o) <TAB>  <TAB>  <TAB> for o in obj <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> return func(obj)",if len ( obj . shape ) == 1 :,159
"def isslotsattribute(self) -> bool: <TAB> """"""Check the subject is an attribute in __slots__."""""" <TAB> try: <TAB>  <TAB> __slots__ = inspect.getslots(self.parent) <MASK> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> except (ValueError, TypeError): <TAB>  <TAB> return False",if __slots__ and self . objpath [ - 1 ] in __slots__ :,93
"def classes_changed(change): <TAB> colormap_options = vdir(cmap.step) <TAB> if change[""new""]: <TAB>  <TAB> selected = change[""owner""].value <MASK> colormap.options = colormap_options <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sel_class = selected.zfill(2) <TAB>  <TAB>  <TAB> colormap.options = [ <TAB>  <TAB>  <TAB>  <TAB> color for color in colormap_options if color[-2:] == sel_class <TAB>  <TAB>  <TAB> ]","if selected == ""Any"" :",112
"def _get_data_from_section(section, delimiter): <TAB> # Remove the delimiter <TAB> if section: <TAB>  <TAB> section = section.split(delimiter)[-1] <MASK> sections_split_by_backtick = section.split(""```"") <TAB>  <TAB>  <TAB> section = ""\n"".join(sections_split_by_backtick) <TAB>  <TAB> data = yaml.safe_load(section) <TAB>  <TAB> if data is None: <TAB>  <TAB>  <TAB> data = {} <TAB> else: <TAB>  <TAB> data = {} <TAB> return data","if ""```"" in section :",127
"def _decode_dict_response(response: Mapping[Any, Any], decode: bool) -> Any: <TAB> if decode is True: <TAB>  <TAB> new_response = {} <TAB>  <TAB> for key, value in response.items(): <TAB>  <TAB>  <TAB> if isinstance(key, bytes): <TAB>  <TAB>  <TAB>  <TAB> key = key.decode(""utf-8"") <MASK> value = value.decode(""utf-8"") <TAB>  <TAB>  <TAB> new_response[key] = value <TAB>  <TAB> return new_response <TAB> return response","if isinstance ( value , bytes ) :",126
"def _flatten(*args): <TAB> arglist = [] <TAB> for arg in args: <TAB>  <TAB> if isinstance(arg, _Block): <TAB>  <TAB>  <TAB> if arg.verilog_code is not None: <TAB>  <TAB>  <TAB>  <TAB> arglist.append(arg.verilog_code) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> arg = arg.subs <TAB>  <TAB> if id(arg) in _userCodeMap[""verilog""]: <TAB>  <TAB>  <TAB> arglist.append(_userCodeMap[""verilog""][id(arg)]) <MASK> for item in arg: <TAB>  <TAB>  <TAB>  <TAB> arglist.extend(_flatten(item)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> arglist.append(arg) <TAB> return arglist","elif isinstance ( arg , ( list , tuple , set ) ) :",175
"def stats(self, mean=True, last=False): <TAB> aggregates = {} <TAB> for k, t in self._timers.items(): <TAB>  <TAB> if t.count > 0: <MASK> aggregates[f""mean_{k}_s""] = t.mean <TAB>  <TAB>  <TAB> if last: <TAB>  <TAB>  <TAB>  <TAB> aggregates[f""last_{k}_s""] = t.last <TAB> return aggregates",if mean :,103
"def remove(self, item): <TAB> for option in self.options: <TAB>  <TAB> opt_value = option.get(""value"") <TAB>  <TAB> if opt_value is None: <TAB>  <TAB>  <TAB> opt_value = option.text or """" <MASK> opt_value = opt_value.strip() <TAB>  <TAB> if opt_value == item: <TAB>  <TAB>  <TAB> if ""selected"" in option.attrib: <TAB>  <TAB>  <TAB>  <TAB> del option.attrib[""selected""] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""The option %r is not currently selected"" % item) <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> raise ValueError(""There is not option with the value %r"" % item)",if opt_value :,164
"def _decode_children(cls, key, value, protocol): <MASK> : <TAB>  <TAB> # Decode `value` with `protocol` <TAB>  <TAB> return cls.decode(value, protocol.get_protocol(key)) <TAB> if type(value) is list: <TAB>  <TAB> # Decode items in `value` with `protocol` <TAB>  <TAB> return [ <TAB>  <TAB>  <TAB> ( <TAB>  <TAB>  <TAB>  <TAB> cls.decode(value, protocol.get_protocol(key)) <TAB>  <TAB>  <TAB>  <TAB> if type(value) is dict <TAB>  <TAB>  <TAB>  <TAB> else value <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> for value in value <TAB>  <TAB> ] <TAB> return value",if type ( value ) is dict,148
"def check_splitter(command): <TAB> """"""Check xld or shntool installed"""""" <TAB> try: <TAB>  <TAB> env = os.environ.copy() <MASK> env[""PATH""] += os.pathsep + ""/Applications"" <TAB>  <TAB> elif headphones.CONFIG.CUE_SPLIT_FLAC_PATH: <TAB>  <TAB>  <TAB> command = os.path.join(headphones.CONFIG.CUE_SPLIT_SHNTOOL_PATH, ""shntool"") <TAB>  <TAB> devnull = open(os.devnull) <TAB>  <TAB> subprocess.Popen( <TAB>  <TAB>  <TAB> [command], stdout=devnull, stderr=devnull, env=env <TAB>  <TAB> ).communicate() <TAB> except OSError as e: <TAB>  <TAB> if e.errno == os.errno.ENOENT: <TAB>  <TAB>  <TAB> return False <TAB> return True","if ""xld"" in command :",189
"def _notify_canvas_observers(self, layer_bboxes): <TAB> """"""Notifies the document's redraw observers"""""" <TAB> warn( <TAB>  <TAB> ""Layers should issue their own canvas updates"", <TAB>  <TAB> PendingDeprecationWarning, <TAB>  <TAB> stacklevel=2, <TAB> ) <TAB> redraw_bbox = helpers.Rect() <TAB> for layer_bbox in layer_bboxes: <MASK> redraw_bbox = layer_bbox <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> redraw_bbox.expandToIncludeRect(layer_bbox) <TAB> self.doc.canvas_area_modified(*redraw_bbox)",if layer_bbox . w == 0 and layer_bbox . h == 0 :,158
"def _MatchFindings(self, expected, found): <TAB> """"""Check that every expected finding is a substring of a found finding."""""" <TAB> matched_so_far = set() <TAB> for finding_str in expected: <TAB>  <TAB> no_match = True <TAB>  <TAB> for found_str in found: <MASK> matched_so_far.add(found_str) <TAB>  <TAB>  <TAB>  <TAB> no_match = False <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if no_match: <TAB>  <TAB>  <TAB> return False <TAB> # If we got here, all expected's match at least one item. <TAB> # Now check if every item in found was matched at least once. <TAB> # If so, everything is as expected, If not, Badness. <TAB> if not matched_so_far.symmetric_difference(found): <TAB>  <TAB> return True",if finding_str in found_str :,197
"def __iter__(self): <TAB> while True: <TAB>  <TAB> y = self.rng.randint(2) <MASK> pick_label, pick_other = self.rng.choice(10, size=2, replace=False) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pick_label = self.rng.randint(10) <TAB>  <TAB>  <TAB> pick_other = pick_label <TAB>  <TAB> yield [self.pick(pick_label), self.pick(pick_other), y]",if y == 0 :,116
"def _transpose(self, ns, amount, stats): <TAB> """"""Transposes a note sequence by the specified amount."""""" <TAB> ts = copy.deepcopy(ns) <TAB> for note in ts.notes: <TAB>  <TAB> if not note.is_drum: <TAB>  <TAB>  <TAB> note.pitch += amount <MASK> stats[""skipped_due_to_range_exceeded""].increment() <TAB>  <TAB>  <TAB>  <TAB> return None <TAB> return ts",if note . pitch < self . _min_pitch or note . pitch > self . _max_pitch :,126
"def OnLeftDown(self, event): <TAB> """"""Select tab on mouse down and start dragging logic"""""" <TAB> mposx, mposy = event.GetPosition() <TAB> if not self.start_drag: <TAB>  <TAB> tab = self.FindTabAtPos(mposx, mposy) <MASK> self.CheckTabSelected(tab, mposx, mposy) <TAB>  <TAB>  <TAB> if self.show_add_button: <TAB>  <TAB>  <TAB>  <TAB> # If we can add tabs, we can drag them. Set flag <TAB>  <TAB>  <TAB>  <TAB> self.start_drag = True <TAB>  <TAB>  <TAB>  <TAB> tx, ty = tab.GetPosition() <TAB>  <TAB>  <TAB>  <TAB> self.dragx = mposx - tx <TAB>  <TAB>  <TAB>  <TAB> self.dragy = self.container_height - self.height <TAB>  <TAB>  <TAB> self.Refresh() <TAB>  <TAB> self.dragged_tab = tab",if tab :,199
"def expr_term(tl): <TAB> if tl[0] == ""("": <TAB>  <TAB> out, tl = expr(tl[1:]) <MASK> out = [out] <TAB>  <TAB> tl = expect(tl, "")"") <TAB> else: <TAB>  <TAB> out = [tl[0]] <TAB>  <TAB> tl = tl[1:] <TAB>  <TAB> if tl and tl[0] == ""{"": <TAB>  <TAB>  <TAB> fl, vl, tl = parse_list(tl[1:]) <TAB>  <TAB>  <TAB> tl = expect(tl, ""}"") <TAB>  <TAB>  <TAB> out = apply_list(out, fl, vl) <TAB> if not tl: <TAB>  <TAB> return out, tl <TAB> if tl and tl[0] == ""with:"": <TAB>  <TAB> out, tl = parse_with(tl[1:], out) <TAB> return out, tl","if isinstance ( out , list ) :",190
"def __init__(self, name, template, index=None, order=None, **kwargs): <TAB> if index is None: <TAB>  <TAB> self._index = Index(template, **kwargs) <TAB> else: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""You cannot specify options for Index when"" <TAB>  <TAB>  <TAB>  <TAB> "" passing an Index instance."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self._index = index.clone() <TAB>  <TAB> self._index._name = template <TAB> self._template_name = name <TAB> self.order = order",if kwargs :,127
"def clean_file_list(inp_list, folder, files): <TAB> """"""Remove elements of ""inp_list"" not found in ""files"" """""" <TAB> for path in sorted(inp_list): <TAB>  <TAB> fld, name = os.path.split(path) <TAB>  <TAB> if fld == folder: <TAB>  <TAB>  <TAB> present = False <TAB>  <TAB>  <TAB> for name in files: <TAB>  <TAB>  <TAB>  <TAB> if os.path.join(folder, name) == path: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> present = True <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <MASK> del inp_list[path]",if not present :,139
"def TryMerge(self, d): <TAB> while 1: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 44: <TAB>  <TAB>  <TAB> break <MASK> self.set_x(d.getDouble()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 57: <TAB>  <TAB>  <TAB> self.set_y(d.getDouble()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 49 :,125
"def __get_boot_type_freebsd(self): <TAB> await self.middleware.run_in_thread(geom.scan) <TAB> labelclass = geom.class_by_name(""PART"") <TAB> efi = bios = 0 <TAB> for disk in await self.get_disks(): <TAB>  <TAB> for e in labelclass.xml.findall(f"".//geom[name='{disk}']/provider/config/type""): <TAB>  <TAB>  <TAB> if e.text == ""efi"": <TAB>  <TAB>  <TAB>  <TAB> efi += 1 <MASK> bios += 1 <TAB> if efi == 0 and bios == 0: <TAB>  <TAB> return None <TAB> if bios > 0: <TAB>  <TAB> return ""BIOS"" <TAB> return ""EFI""","elif e . text == ""freebsd-boot"" :",183
"def __getattr__(self, attr): <TAB> """"""Get a setting."""""" <TAB> if attr not in self._cache: <TAB>  <TAB> if attr not in self.keys: <TAB>  <TAB>  <TAB> raise AttributeError(""Invalid API setting: '%s'"" % attr) <MASK> val = self.settings[attr] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> val = self.defaults[attr] <TAB>  <TAB> if attr in self.class_attrs and val: <TAB>  <TAB>  <TAB> val = self._load_class(attr, val) <TAB>  <TAB> # Cache the result <TAB>  <TAB> self._cache[attr] = val <TAB> return self._cache[attr]",if attr in self . settings :,150
"def check_app_config_brackets(self): <TAB> """"""Check for Application config with extraneous brackets in section names."""""" <TAB> for sn, app in cherrypy.tree.apps.items(): <MASK> continue <TAB>  <TAB> if not app.config: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for key in app.config.keys(): <TAB>  <TAB>  <TAB> if key.startswith(""["") or key.endswith(""]""): <TAB>  <TAB>  <TAB>  <TAB> warnings.warn( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""The application mounted at %r has config "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""section names with extraneous brackets: %r. "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Config *files* need brackets; config *dicts* "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""(e.g. passed to tree.mount) do not."" % (sn, key) <TAB>  <TAB>  <TAB>  <TAB> )","if not isinstance ( app , cherrypy . Application ) :",200
"def get_order(self, byte_str): <TAB> # for big5 encoding, we are interested <TAB> #   first  byte range: 0xa4 -- 0xfe <TAB> #   second byte range: 0x40 -- 0x7e , 0xa1 -- 0xfe <TAB> # no validation needed here. State machine has done that <TAB> first_char, second_char = byte_str[0], byte_str[1] <TAB> if first_char >= 0xA4: <MASK> return 157 * (first_char - 0xA4) + second_char - 0xA1 + 63 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return 157 * (first_char - 0xA4) + second_char - 0x40 <TAB> else: <TAB>  <TAB> return -1",if second_char >= 0xA1 :,188
"def process_break_exits(self, exits): <TAB> """"""Add arcs due to jumps from `exits` being breaks."""""" <TAB> for block in self.nearest_blocks(): <TAB>  <TAB> if isinstance(block, LoopBlock): <TAB>  <TAB>  <TAB> block.break_exits.update(exits) <TAB>  <TAB>  <TAB> break <MASK> block.break_from.update(exits) <TAB>  <TAB>  <TAB> break","elif isinstance ( block , TryBlock ) and block . final_start is not None :",113
"def __init__(cls, name, superclasses, *args, **kwargs): <TAB> super(MixinMeta, cls).__init__(name, superclasses, *args, **kwargs) <TAB> for sup in superclasses: <TAB>  <TAB> if hasattr(sup, ""overloads""): <TAB>  <TAB>  <TAB> for method in sup.overloads: <MASK> setattr(cls, method, getattr(sup, method)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # Record the fact that we have set a method on the class, to do <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # superclass lookups. <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if ""__mixin_overloads__"" in cls.__dict__: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> cls.__mixin_overloads__[method] = sup <TAB>  <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> setattr(cls, ""__mixin_overloads__"", {method: sup})",if method not in cls . __dict__ :,193
"def _number_literal_format(translator, expr): <TAB> value = expr.op().value <TAB> if math.isfinite(value): <TAB>  <TAB> formatted = repr(value) <TAB> else: <TAB>  <TAB> if math.isnan(value): <TAB>  <TAB>  <TAB> formatted_val = ""NaN"" <MASK> if value > 0: <TAB>  <TAB>  <TAB>  <TAB> formatted_val = ""Infinity"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> formatted_val = ""-Infinity"" <TAB>  <TAB> formatted = ""CAST({!r} AS DOUBLE)"".format(formatted_val) <TAB> return formatted",elif math . isinf ( value ) :,141
"def _community_list(self, subtype): <TAB> _list = [] <TAB> for comm in ( <TAB>  <TAB> c for c in self.communities if hasattr(c, ""subtype"") and c.subtype == subtype <TAB> ): <MASK> _list.append(""%d:%d"" % (comm.as_number, comm.local_administrator)) <TAB>  <TAB> elif comm.type == 1: <TAB>  <TAB>  <TAB> _list.append(""%s:%d"" % (comm.ipv4_address, comm.local_administrator)) <TAB> return _list",if comm . type == 0 or comm . type == 2 :,146
"def _ensure_no_duplicate_column_names(self, X: DataFrame): <TAB> if len(X.columns) != len(set(X.columns)): <TAB>  <TAB> count_dict = defaultdict(int) <TAB>  <TAB> invalid_columns = [] <TAB>  <TAB> for column in list(X.columns): <TAB>  <TAB>  <TAB> count_dict[column] += 1 <TAB>  <TAB> for column in count_dict: <MASK> invalid_columns.append(column) <TAB>  <TAB> raise AssertionError( <TAB>  <TAB>  <TAB> f""Columns appear multiple times in X. Columns must be unique. Invalid columns: {invalid_columns}"" <TAB>  <TAB> )",if count_dict [ column ] > 1 :,153
"def __setattr__(self, key, value): <TAB> if ( <TAB>  <TAB> hasattr(self, ""key"") and key == ""key"" <TAB> ):  # key cannot be changed because is being used for __hash__ <TAB>  <TAB> error_message = ""key '%s' already set"" % key <MASK> log(ERROR, ""%s for <%s>"", error_message, self) <TAB>  <TAB> raise LDAPKeyError(error_message) <TAB> else: <TAB>  <TAB> object.__setattr__(self, key, value)",if log_enabled ( ERROR ) :,125
"def __init__(self, vw=None, **kwargs): <TAB> self._ve_vw = vw <TAB> self._ve_ehand = [None for x in range(VWE_MAX)] <TAB> self._ve_thand = [None for x in range(VTE_MAX)] <TAB> self._ve_lock = threading.Lock() <TAB> # Find and put handler functions into the list <TAB> for name in dir(self): <MASK> idx = getattr(viv_const, name, None) <TAB>  <TAB>  <TAB> self._ve_ehand[idx] = getattr(self, name) <TAB>  <TAB> if name.startswith(""VTE_""): <TAB>  <TAB>  <TAB> idx = getattr(viv_const, name, None) <TAB>  <TAB>  <TAB> self._ve_thand[idx] = getattr(self, name)","if name . startswith ( ""VWE_"" ) :",196
"def add_semicolon(self, action): <TAB> doc = self._window.get_active_document() <TAB> if not doc: <TAB>  <TAB> return <TAB> try: <TAB>  <TAB> # get vars <TAB>  <TAB> cursor = doc.get_iter_at_mark(doc.get_insert()) <MASK> cursor.forward_to_line_end() <TAB>  <TAB> # select start->end <TAB>  <TAB> cursor.get_buffer().insert(cursor, "";"") <TAB> except: <TAB>  <TAB> err = ""Exception\n"" <TAB>  <TAB> err += traceback.format_exc() <TAB>  <TAB> doc.set_text(err)",if not cursor . ends_line ( ) :,150
"def collect(img, mark, nbs, pts): <TAB> bins = np.zeros(img.max() + 1, dtype=np.uint32) <TAB> cur = 0 <TAB> for p in range(len(mark)): <TAB>  <TAB> bins[img[p]] += 1 <TAB>  <TAB> if mark[p] == 0xFFFFFFFF: <TAB>  <TAB>  <TAB> continue  # edge <TAB>  <TAB> if mark[p] == 0: <TAB>  <TAB>  <TAB> continue  # zero <TAB>  <TAB> for dp in nbs: <MASK> pts[cur] = p <TAB>  <TAB>  <TAB>  <TAB> cur += 1 <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return cur, bins",if mark [ p + dp ] != mark [ p ] :,157
"def find_video(result): <TAB> if isinstance(result, dict): <TAB>  <TAB> return result <TAB> elif isinstance(result, list): <TAB>  <TAB> vid = int(video_id) <TAB>  <TAB> for v in result: <MASK> return v <TAB> return None","if try_get ( v , lambda x : x [ ""general"" ] [ ""ID"" ] , int ) == vid :",86
"def render(self, screen): <TAB> res = [] <TAB> candidates = self.owner.get_counting() <TAB> for candidate in candidates: <TAB>  <TAB> text, perc = candidate.widget_explain() <TAB>  <TAB> if perc >= 0.95: <TAB>  <TAB>  <TAB> res += [screen.markup.RED_DARK + text + screen.markup.RESET] <TAB>  <TAB> elif perc >= 0.8: <TAB>  <TAB>  <TAB> res += [screen.markup.RED + text + screen.markup.RESET] <MASK> res += [screen.markup.YELLOW + text + screen.markup.RESET] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> res += [text] <TAB> if res: <TAB>  <TAB> return ""Autostop:\n  "" + (""\n  "".join(res)) <TAB> else: <TAB>  <TAB> return """"",elif perc >= 0.5 :,189
"def get_component_template(cls, component): <TAB> """"""Returns the component template data given a component NAME"""""" <TAB> for entry in cls.component_templates: <TAB>  <TAB> if isinstance(entry, dict): <TAB>  <TAB>  <TAB> for key, value in entry.items(): <MASK> return value <TAB> raise KeyError( <TAB>  <TAB> ""This class does not contain a component with name: {0}"".format(component) <TAB> )",if cls . class_mapping [ key ] == component or key == component :,117
"def main(dry=True): <TAB> count = 0 <TAB> for node in paginated(AbstractNode, increment=1000): <TAB>  <TAB> true_root = node.get_root() <TAB>  <TAB> if not node.root or node.root.id != true_root.id: <TAB>  <TAB>  <TAB> count += 1 <TAB>  <TAB>  <TAB> logger.info( <TAB>  <TAB>  <TAB>  <TAB> ""Setting root for node {} to {}"".format(node._id, true_root._id) <TAB>  <TAB>  <TAB> ) <MASK> AbstractNode.objects.filter(id=node.id).update(root=true_root) <TAB> logger.info(""Finished migrating {} nodes"".format(count))",if not dry :,156
"def autoname(self): <TAB> naming_method = frappe.db.get_value( <TAB>  <TAB> ""Education Settings"", None, ""instructor_created_by"" <TAB> ) <TAB> if not naming_method: <TAB>  <TAB> frappe.throw( <TAB>  <TAB>  <TAB> _(""Please setup Instructor Naming System in Education > Education Settings"") <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> if naming_method == ""Naming Series"": <TAB>  <TAB>  <TAB> set_name_by_naming_series(self) <MASK> if not self.employee: <TAB>  <TAB>  <TAB>  <TAB> frappe.throw(_(""Please select Employee"")) <TAB>  <TAB>  <TAB> self.name = self.employee <TAB>  <TAB> elif naming_method == ""Full Name"": <TAB>  <TAB>  <TAB> self.name = self.instructor_name","elif naming_method == ""Employee Number"" :",200
"def optimize_image(imgpath, imgformat, optimizers): <TAB> for opt in optimizers: <TAB>  <TAB> if imgformat == ""png"": <TAB>  <TAB>  <TAB> if isinstance(opt, PNGOptimizer): <TAB>  <TAB>  <TAB>  <TAB> opt.optimize(imgpath) <MASK> if isinstance(opt, JPEGOptimizer): <TAB>  <TAB>  <TAB>  <TAB> opt.optimize(imgpath)","elif imgformat == ""jpg"" :",86
"def _types(self): <TAB> if not self.config.exists(): <TAB>  <TAB> return {} <TAB> mytypes = {} <TAB> for key, value in self.config.items(): <MASK> mytypes[key] = types.INTEGER <TAB>  <TAB> elif value.get() == ""float"": <TAB>  <TAB>  <TAB> mytypes[key] = types.FLOAT <TAB>  <TAB> elif value.get() == ""bool"": <TAB>  <TAB>  <TAB> mytypes[key] = types.BOOLEAN <TAB>  <TAB> elif value.get() == ""date"": <TAB>  <TAB>  <TAB> mytypes[key] = library.DateType() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ConfigValueError( <TAB>  <TAB>  <TAB>  <TAB> u""unknown type '{0}' for the '{1}' field"".format(value, key) <TAB>  <TAB>  <TAB> ) <TAB> return mytypes","if value . get ( ) == ""int"" :",189
"def create(self): <TAB> if not os.path.exists(SYSTEM_DIR): <TAB>  <TAB> os.makedirs(SYSTEM_DIR) <TAB> for path, des in self.templates.items(): <TAB>  <TAB> realname = ""%s.%s"" % (des, path.split(""."")[1]) <MASK> shutil.copy( <TAB>  <TAB>  <TAB>  <TAB> os.path.join(DATA_DIR, ""templates/%s"" % path), <TAB>  <TAB>  <TAB>  <TAB> os.path.join(SYSTEM_DIR, realname), <TAB>  <TAB>  <TAB> )","if not os . path . exists ( os . path . join ( SYSTEM_DIR , realname ) ) :",143
"def _on_local_error(self): <TAB> if self._local_sock: <TAB>  <TAB> err = eventloop.get_sock_error(self._local_sock) <MASK> logging.error(err) <TAB>  <TAB>  <TAB> logging.error( <TAB>  <TAB>  <TAB>  <TAB> ""local error, exception from %s:%d"" <TAB>  <TAB>  <TAB>  <TAB> % (self._client_address[0], self._client_address[1]) <TAB>  <TAB>  <TAB> ) <TAB> self.destroy()","if err . errno not in [ errno . ECONNRESET , errno . EPIPE ] :",129
"def _markers_contains_key(markers, key): <TAB> for element in reversed(markers): <TAB>  <TAB> if isinstance(element, tuple) and element[0].value == key: <TAB>  <TAB>  <TAB> return True <MASK> if _markers_contains_key(element, key): <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False","elif isinstance ( element , list ) :",84
"def create_xccdf_id_to_cce_id_mapping(xccdftree): <TAB> # <TAB> # Create dictionary having form of <TAB> # <TAB> # 'XCCDF ID' : 'CCE ID' <TAB> # <TAB> # for each XCCDF rule having <ident system='http://cce.mitre.org'>CCE-ID</ident> <TAB> # element set in the XCCDF document <TAB> xccdftocce_idmapping = {} <TAB> for xccdfid, rule in rules_with_ids_generator(xccdftree): <TAB>  <TAB> identcce = _find_identcce(rule) <MASK> continue <TAB>  <TAB> xccdftocce_idmapping[xccdfid] = identcce.text <TAB> return xccdftocce_idmapping",if identcce is None :,200
"def OnTimer(self, event): <TAB> mposx, mposy = wx.GetMousePosition() <TAB> cposx, cposy = self.ScreenToClient((mposx, mposy)) <TAB> if self.FindTabAtPos(cposx, cposy) == self.preview_tab: <MASK> page = self.Parent.GetPage(self.GetTabIndex(self.preview_tab)) <TAB>  <TAB>  <TAB> if page.Snapshot(): <TAB>  <TAB>  <TAB>  <TAB> self.preview_wnd = PFNotebookPagePreview( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self, (mposx + 3, mposy + 3), page.Snapshot(), self.preview_tab.text <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> self.preview_wnd.Show() <TAB> event.Skip()",if not self . preview_tab . GetSelected ( ) :,193
"def walk_helper(arg, dirname, files): <TAB> if "".svn"" in dirname: <TAB>  <TAB> return <TAB> names = [] <TAB> lst, wildcards = arg <TAB> for wc in wildcards: <TAB>  <TAB> wc_name = opj(dirname, wc) <TAB>  <TAB> for f in files: <TAB>  <TAB>  <TAB> filename = opj(dirname, f) <MASK> names.append(filename) <TAB> if names: <TAB>  <TAB> lst.append((dirname, names))","if fnmatch . fnmatch ( filename , wc_name ) and not os . path . isdir ( filename ) :",134
"def touch_all(self): <TAB> diff = self.functions.difference(cache.touched_functions) <TAB> for address in diff: <TAB>  <TAB> if is_imported_ea(address): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> cfunc = idaapi.decompile(address) <MASK> FunctionTouchVisitor(cfunc).process() <TAB>  <TAB> except idaapi.DecompilationFailure: <TAB>  <TAB>  <TAB> logger.warn( <TAB>  <TAB>  <TAB>  <TAB> ""IDA failed to decompile function at {}"".format(to_hex(address)) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> cache.touched_functions.add(address) <TAB> idaapi.decompile(self.cfunc.entry_ea)",if cfunc :,168
"def sanitize_address(addr, encoding): <TAB> if isinstance(addr, basestring): <TAB>  <TAB> addr = parseaddr(force_unicode(addr)) <TAB> nm, addr = addr <TAB> nm = str(Header(nm, encoding)) <TAB> try: <TAB>  <TAB> addr = addr.encode(""ascii"") <TAB> except UnicodeEncodeError:  # IDN <MASK> localpart, domain = addr.split(u""@"", 1) <TAB>  <TAB>  <TAB> localpart = str(Header(localpart, encoding)) <TAB>  <TAB>  <TAB> domain = domain.encode(""idna"") <TAB>  <TAB>  <TAB> addr = ""@"".join([localpart, domain]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> addr = str(Header(addr, encoding)) <TAB> return formataddr((nm, addr))","if u""@"" in addr :",177
"def delete(self, request, *args, **kwargs): <TAB> pkfield = self.model._meta.pk.name <TAB> if pkfield in kwargs: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> profile = self.model.objects.get(pk=kwargs.get(pkfield)) <MASK> self.status = 401 <TAB>  <TAB>  <TAB>  <TAB> return _(""This is you!"") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> profile.delete() <TAB>  <TAB>  <TAB>  <TAB> return rc.DELETED <TAB>  <TAB> except self.model.MultipleObjectsReturned: <TAB>  <TAB>  <TAB> return rc.DUPLICATE_ENTRY <TAB>  <TAB> except self.model.DoesNotExist: <TAB>  <TAB>  <TAB> return rc.NOT_HERE <TAB> else: <TAB>  <TAB> return rc.BAD_REQUEST",if profile == request . user . profile :,175
"def pp(self) -> None: <TAB> for op in self.pcode.opcache: <TAB>  <TAB> out = op.getOutput() <MASK> sys.stdout.write(""%-20s = "" % (self.pp_vardata(out))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sys.stdout.write("" "" * 23) <TAB>  <TAB> sys.stdout.write(""%-12s "" % pypcode.get_opname(op.getOpcode())) <TAB>  <TAB> for i in range(op.numInput()): <TAB>  <TAB>  <TAB> sys.stdout.write(self.pp_vardata(op.getInput(i))) <TAB>  <TAB> sys.stdout.write(""\n"")",if out :,157
"def _Determine_Do(self): <TAB> self.applicable = 1 <TAB> if sys.platform == ""win32"": <TAB>  <TAB> self.value = ""x86"" <TAB> else: <TAB>  <TAB> uname = os.uname() <MASK> # XXX Currently disabling linux-distro differentiation until <TAB>  <TAB>  <TAB> # <TAB> we have a concrete reason for it. <TAB>  <TAB>  <TAB> # distro = _getLinuxDistro() <TAB>  <TAB>  <TAB> # validPlats = [""linux-%s-x86"" % distro] <TAB>  <TAB>  <TAB> self.value = ""x86"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.value = uname[4] <TAB> self.determined = 1","if re . match ( ""i\d86"" , uname [ 4 ] ) :",173
"def _rows_from_item(self, item, indent=0): <TAB> for child in item: <TAB>  <TAB> if child.is_set(): <TAB>  <TAB>  <TAB> yield [""""] * indent + child.as_list() <MASK> for row in self._rows_from_item(child, indent + 1): <TAB>  <TAB>  <TAB>  <TAB> yield row",if child . is_for_loop ( ) :,89
"def _get_backups(self): <TAB> backups = [] <TAB> for entry in scandir(self.get_plugin_data_folder()): <TAB>  <TAB> if is_hidden_path(entry.path): <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> if not entry.name.endswith("".zip""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> backups.append( <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB> ""name"": entry.name, <TAB>  <TAB>  <TAB>  <TAB> ""date"": entry.stat().st_mtime, <TAB>  <TAB>  <TAB>  <TAB> ""size"": entry.stat().st_size, <TAB>  <TAB>  <TAB>  <TAB> ""url"": flask.url_for(""index"") + ""plugin/backup/download/"" + entry.name, <TAB>  <TAB>  <TAB> } <TAB>  <TAB> ) <TAB> return backups",if not entry . is_file ( ) :,184
"def iter_blogposts(): <TAB> for post in glob.glob(os.path.join(Page.pagedir, ""*.md"")): <TAB>  <TAB> name = os.path.basename(post)[:-3] <MASK> yield Page(name)","if re . match ( r""20[0-9]{2}-[0-9]{2}-[0-9]{2}_"" , name ) :",89
"def parse(text, pos=0, endpos=None): <TAB> pos = 0 <TAB> if endpos is None: <TAB>  <TAB> endpos = len(text) <TAB> d = {} <TAB> while 1: <TAB>  <TAB> m = entityRE.search(text, pos, endpos) <MASK> break <TAB>  <TAB> name, charcode, comment = m.groups() <TAB>  <TAB> d[name] = charcode, comment <TAB>  <TAB> pos = m.end() <TAB> return d",if not m :,116
"def setData(self, index, value, role=Qt.EditRole): <TAB> if ( <TAB>  <TAB> index.isValid() <TAB>  <TAB> and 0 <= index.row() < len(self.packages) <TAB>  <TAB> and role == Qt.CheckStateRole <TAB> ): <TAB>  <TAB> package = self.packages[index.row()] <MASK> self.checked.remove(package) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.checked.add(package) <TAB>  <TAB> # PyQt4 old SIGNAL: self.emit(SIGNAL(""dataChanged(QModelIndex,QModelIndex)""), <TAB>  <TAB> # PyQt4 old SIGNAL: <TAB>  <TAB>    index, index) <TAB>  <TAB> self.dataChanged.emit(index, index) <TAB>  <TAB> return True <TAB> return False",if package in self . checked :,189
"def rmtree(path): <TAB> for name in os.listdir(path): <TAB>  <TAB> fname = os.path.join(path, name) <MASK> rmtree(fname) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> os.chmod(fname, 0o666) <TAB>  <TAB>  <TAB> os.remove(fname) <TAB> os.rmdir(path)",if os . path . isdir ( fname ) :,89
"def capture_obj_method_calls(obj_name, code): <TAB> capturers = [] <TAB> for (token_type, token, origin, props) in annotated_tokens(code): <TAB>  <TAB> for capturer in capturers: <TAB>  <TAB>  <TAB> capturer.add_token(token_type, token) <MASK> capturers.append(_FuncallCapturer(token_type, token)) <TAB> return [ <TAB>  <TAB> ("""".join(capturer.func), pretty_untokenize(capturer.tokens)) <TAB>  <TAB> for capturer in capturers <TAB> ]","if props [ ""bare_ref"" ] and token == obj_name :",145
"def unpack_tarball(tar_filename, dest): <TAB> print(""Unpacking %s into %s"" % (os.path.basename(tar_filename), dest)) <TAB> tar = tarfile.open(tar_filename) <TAB> base_dir = None <TAB> for member in tar: <TAB>  <TAB> base_name = member.name.split(""/"")[0] <MASK> base_dir = base_name <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if base_dir != base_name: <TAB>  <TAB>  <TAB>  <TAB> print(""Unexpected path in %s: %s"" % (tar_filename, base_name)) <TAB> _extractall(tar, dest) <TAB> tar.close() <TAB> return os.path.join(dest, base_dir)",if base_dir is None :,174
"def top(name, count, enable, clock, reset, n, arch=""myhdl""): <TAB> if arch == ""verilog"": <TAB>  <TAB> return setupCosimulation(**locals()) <MASK> os.remove(objfile) <TAB>  <TAB> os.system(analyze_cmd) <TAB>  <TAB> return Cosimulation(simulate_cmd, **locals()) <TAB> else: <TAB>  <TAB> inc_initial_inst = inc_initial(count, enable, clock, reset, n) <TAB>  <TAB> return inc_initial_inst",if path . exists ( objfile ) :,127
"def update(self, **kwargs): <TAB> # means that the session has been found and needs an update <TAB> if self.op == ""eq"" and self.field == ""id"" and self.value: <TAB>  <TAB> key = self.keyprefix + "":"" + str(self.value) <TAB>  <TAB> if not self.db.r_server.exists(key): <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> with self.db.r_server.pipeline() as pipe: <TAB>  <TAB>  <TAB> pipe.hmset(key, kwargs) <MASK> pipe.expire(key, self.session_expiry) <TAB>  <TAB>  <TAB> rtn = pipe.execute()[0] <TAB>  <TAB> if self.with_lock: <TAB>  <TAB>  <TAB> release_lock(self.db, key + "":lock"", self.value) <TAB>  <TAB> return rtn",if self . session_expiry :,194
"def walk_drive(self, folder_id): <TAB> dirs, nondirs = {}, {} <TAB> for item in sickrage.app.api.google.list_files(folder_id)[""data""]: <MASK> dirs.update({str(item[""id""]): item[""name""]}) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> nondirs.update({str(item[""id""]): item[""name""]}) <TAB> yield folder_id, dirs, nondirs <TAB> for name in dirs.keys(): <TAB>  <TAB> for x in self.walk_drive(name): <TAB>  <TAB>  <TAB> yield x","if item [ ""type"" ] == ""application/vnd.google-apps.folder"" :",152
"def _excepthandler(self, node): <TAB> if node.name is not None and isinstance(node.name, str): <TAB>  <TAB> type_node = node.type <MASK> type_node = type_node.elts[0] <TAB>  <TAB> self._update_evaluated(node.name, type_node, eval_type=True) <TAB> for child in node.body: <TAB>  <TAB> ast.walk(child, self)","if isinstance ( node . type , ast . Tuple ) and type_node . elts :",118
def total_size(self): <TAB> _total_size = 0 <TAB> _related_episodes = set() <TAB> for episode_object in self.episodes: <TAB>  <TAB> [ <TAB>  <TAB>  <TAB> _related_episodes.add(related_episode.indexer_id) <TAB>  <TAB>  <TAB> for related_episode in episode_object.related_episodes <TAB>  <TAB> ] <MASK> _total_size += episode_object.file_size <TAB> return _total_size,if episode_object . indexer_id not in _related_episodes :,125
"def __init__(self, specs=None, params=None): <TAB> self.specs = specs or dict() <TAB> self.params = params or dict() <TAB> for name, value in self.params.items(): <TAB>  <TAB> if name not in self.specs: <TAB>  <TAB>  <TAB> self._param_unknown_error(name) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> self.params[name] = self.specs[name][""map""](value) <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> self._param_map_error(name, value) <TAB>  <TAB> if ""valid"" in self.specs[name]: <TAB>  <TAB>  <TAB> if not self.specs[name][""valid""](value): <TAB>  <TAB>  <TAB>  <TAB> self._param_vaildation_error(name, value) <TAB> self.update(self.params)","if ""map"" in self . specs [ name ] :",198
"def select(self, timeout=None): <TAB> ready = [] <TAB> fd_events = _syscall_wrapper(self._wrap_poll, True, timeout=timeout) <TAB> for fd, event_mask in fd_events: <TAB>  <TAB> events = 0 <TAB>  <TAB> if event_mask & ~select.POLLIN: <TAB>  <TAB>  <TAB> events |= EVENT_WRITE <MASK> events |= EVENT_READ <TAB>  <TAB> key = self._key_from_fd(fd) <TAB>  <TAB> if key: <TAB>  <TAB>  <TAB> ready.append((key, events & key.events)) <TAB> return ready",if event_mask & ~ select . POLLOUT :,147
"def to_json_schema(self, parent=None): <TAB> schema = { <TAB>  <TAB> ""type"": [""integer"", ""null""] if self.null else ""integer"", <TAB> } <TAB> if not parent: <TAB>  <TAB> schema[""title""] = self.title <TAB>  <TAB> if self.description: <TAB>  <TAB>  <TAB> schema[""description""] = self.description <MASK> schema[""default""] = self.default <TAB>  <TAB> schema[""_required_""] = self.required <TAB> return schema",if self . has_default :,116
"def _load_async_markets(self, reload: bool = False) -> None: <TAB> try: <MASK> asyncio.get_event_loop().run_until_complete( <TAB>  <TAB>  <TAB>  <TAB> self._api_async.load_markets(reload=reload) <TAB>  <TAB>  <TAB> ) <TAB> except (asyncio.TimeoutError, ccxt.BaseError) as e: <TAB>  <TAB> logger.warning(""Could not load async markets. Reason: %s"", e) <TAB>  <TAB> return",if self . _api_async :,123
"def find_session_pool_descriptors(self): <TAB> descriptors = {} <TAB> for task in self.session.plugins.pslist().list_eprocess(): <TAB>  <TAB> desc = task.Session.PagedPool.cast(vm=task.get_process_address_space()) <MASK> desc.PoolStart = task.Session.PagedPoolStart.v() <TAB>  <TAB>  <TAB> desc.PoolEnd = task.Session.PagedPoolEnd.v() <TAB>  <TAB>  <TAB> desc.Comment = ""Session %s"" % task.Session.SessionId <TAB>  <TAB>  <TAB> descriptors[desc.obj_offset] = desc <TAB> return list(descriptors.values())",if desc :,151
"def _get_relative_to_absolute_list(self, import_info): <TAB> result = [] <TAB> for name, alias in import_info.names_and_aliases: <TAB>  <TAB> if alias is not None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> resource = self.pycore.find_module(name, folder=self.folder) <MASK> continue <TAB>  <TAB> absolute_name = self.pycore.modname(resource) <TAB>  <TAB> if absolute_name != name: <TAB>  <TAB>  <TAB> result.append((name, absolute_name)) <TAB> return result",if resource is None :,134
"def gl_display(self): <TAB> if self._recent_blink and self.visualize: <MASK> cygl.utils.push_ortho(1, 1) <TAB>  <TAB>  <TAB> cygl.utils.draw_gl_texture( <TAB>  <TAB>  <TAB>  <TAB> np.zeros((1, 1, 3), dtype=np.uint8), <TAB>  <TAB>  <TAB>  <TAB> alpha=self._recent_blink[""confidence""] * 0.5, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> cygl.utils.pop_ortho()","if self . _recent_blink [ ""type"" ] == ""onset"" :",131
"def get_object_attribute(data, many=False): <TAB> if many: <TAB>  <TAB> ids = [d.get(""id"") for d in data] <TAB>  <TAB> names = [d.get(""name"") for d in data] <TAB>  <TAB> if None in ids: <MASK> raise ValidationError(""Associated object require a name or id."") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return ""name"" <TAB>  <TAB> return ""id"" <TAB> else: <TAB>  <TAB> if data.get(""id""): <TAB>  <TAB>  <TAB> return ""id"" <TAB>  <TAB> elif data.get(""name""): <TAB>  <TAB>  <TAB> return ""name"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValidationError(""Associated object require a name or id."")",if None in names :,170
"def postprocess(self, target, postprocess_values): <TAB> """"""Fill postprocess values."""""" <TAB> mixed = [] <TAB> for name, deffered in postprocess_values: <TAB>  <TAB> value = deffered.value <TAB>  <TAB> if isinstance(value, GeneratorType): <TAB>  <TAB>  <TAB> value = next(value) <MASK> mixed.append((name, value)) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if isinstance(getattr(target, name), InstrumentedList) and not isinstance( <TAB>  <TAB>  <TAB> value, list <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> value = [value] <TAB>  <TAB> setattr(target, name, value) <TAB> for name, mix in mixed: <TAB>  <TAB> setattr(target, name, mix & target) <TAB> if self.__mixer: <TAB>  <TAB> target = self.__mixer.postprocess(target) <TAB> return target","if isinstance ( value , t . Mix ) :",195
"def timerThread(self): <TAB> # Internal function to monitor work unit time <TAB> while self.go: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> for id, work in self.inprog.items(): <MASK> self.timeoutWork(work) <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> logger.info(""ClusterTimer: %s"", e) <TAB>  <TAB> time.sleep(2)",if work . isTimedOut ( ) :,103
"def readdir(self, path, buf, filler, offset, fip): <TAB> # Ignore raw_fi <TAB> for item in self.operations( <TAB>  <TAB> ""readdir"", self._decode_optional_path(path), fip.contents.fh <TAB> ): <TAB>  <TAB> if isinstance(item, basestring): <TAB>  <TAB>  <TAB> name, st, offset = item, None, 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name, attrs, offset = item <MASK> st = c_stat() <TAB>  <TAB>  <TAB>  <TAB> set_st_attrs(st, attrs) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> st = None <TAB>  <TAB> if filler(buf, name.encode(self.encoding), st, offset) != 0: <TAB>  <TAB>  <TAB> break <TAB> return 0",if attrs :,182
"def hash_fn(x): <TAB> tmp = [0 for _ in range(N)] <TAB> for val in x.values: <MASK> hasher = hashlib.new(hashing_method) <TAB>  <TAB>  <TAB> if sys.version_info[0] == 2: <TAB>  <TAB>  <TAB>  <TAB> hasher.update(str(val)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> hasher.update(bytes(str(val), ""utf-8"")) <TAB>  <TAB>  <TAB> tmp[int(hasher.hexdigest(), 16) % N] += 1 <TAB> return pd.Series(tmp, index=new_cols)",if val is not None :,147