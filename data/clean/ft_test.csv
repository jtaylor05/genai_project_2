,cleaned_method,target_block,tokens_in_method
0,"def read(self, count=True, timeout=None, ignore_non_errors=True, ignore_timeouts=True): <TAB> try: <TAB>  <TAB> return self._read(count, timeout) <TAB> except usb.USBError as e: <TAB>  <TAB> if DEBUG_COMM: <TAB>  <TAB>  <TAB> log.info( <TAB>  <TAB>  <TAB>  <TAB> ""read: e.errno=%s e.strerror=%s e.message=%s repr=%s"" <TAB>  <TAB>  <TAB>  <TAB> % (e.errno, e.strerror, e.message, repr(e)) <TAB>  <TAB>  <TAB> ) <MASK> return [] <TAB>  <TAB> if ignore_non_errors and is_noerr(e): <TAB>  <TAB>  <TAB> return [] <TAB>  <TAB> raise",if ignore_timeouts and is_timeout ( e ) :,174
1,"def _cache_mem(curr_out, prev_mem, mem_len, reuse_len=None): <TAB> """"""cache hidden states into memory."""""" <TAB> if mem_len is None or mem_len == 0: <TAB>  <TAB> return None <TAB> else: <TAB>  <TAB> if reuse_len is not None and reuse_len > 0: <TAB>  <TAB>  <TAB> curr_out = curr_out[:reuse_len] <MASK> new_mem = curr_out[-mem_len:] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_mem = tf.concat([prev_mem, curr_out], 0)[-mem_len:] <TAB> new_mem.stop_gradient = True <TAB> return new_mem",if prev_mem is None :,165
2,def filtered(gen): <TAB> for example in gen: <TAB>  <TAB> example_len = length_fn(example) <TAB>  <TAB> # Checking max length boundary. <TAB>  <TAB> if max_length is not None: <MASK> continue <TAB>  <TAB> # Checking min length boundary. <TAB>  <TAB> if min_length is not None: <TAB>  <TAB>  <TAB> if example_len < min_length: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # Within bounds. <TAB>  <TAB> yield example,if example_len > max_length :,117
3,"def search(self, query): <TAB> # ""Search.ashx?query="" + query + filterVal <TAB> if not query: <TAB>  <TAB> logger.debug(""Empty search query"") <TAB>  <TAB> return [] <TAB> logger.debug('Searching TuneIn for ""%s""' % query) <TAB> args = ""&query="" + query <TAB> search_results = self._tunein(""Search.ashx"", args) <TAB> results = [] <TAB> for item in self._flatten(search_results): <MASK> # Only return stations <TAB>  <TAB>  <TAB> self._stations[item[""guide_id""]] = item <TAB>  <TAB>  <TAB> results.append(item) <TAB> return results","if item . get ( ""type"" , """" ) == ""audio"" :",163
4,"def _check_script(self, script, directive): <TAB> for var in compile_script(script): <MASK> # Skip variable checks <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> if var.can_contain("".""): <TAB>  <TAB>  <TAB> # Yay! Our variable can contain any symbols! <TAB>  <TAB>  <TAB> reason = ( <TAB>  <TAB>  <TAB>  <TAB> 'At least variable ""${var}"" can contain untrusted user input'.format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> var=var.name <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.add_issue(directive=[directive] + var.providers, reason=reason) <TAB>  <TAB>  <TAB> return True <TAB> return False","if var . must_contain ( ""/"" ) :",157
5,"def getAllDataLinkIDs(): <TAB> linkDataIDs = set() <TAB> dataType = _forestData.dataTypeBySocket <TAB> for socketID, linkedIDs in _forestData.linkedSockets.items(): <TAB>  <TAB> for linkedID in linkedIDs: <MASK> # check which one is origin/target <TAB>  <TAB>  <TAB>  <TAB> linkDataIDs.add( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> (socketID, linkedID, dataType[socketID], dataType[linkedID]) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> linkDataIDs.add( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> (linkedID, socketID, dataType[linkedID], dataType[socketID]) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return linkDataIDs",if socketID [ 1 ] :,174
6,"def _stderr_supports_color(): <TAB> try: <TAB>  <TAB> if hasattr(sys.stderr, ""isatty"") and sys.stderr.isatty(): <TAB>  <TAB>  <TAB> if curses: <TAB>  <TAB>  <TAB>  <TAB> curses.setupterm() <MASK> return True <TAB>  <TAB>  <TAB> elif colorama: <TAB>  <TAB>  <TAB>  <TAB> if sys.stderr is getattr( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> colorama.initialise, ""wrapped_stderr"", object() <TAB>  <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> except Exception: <TAB>  <TAB> # Very broad exception handling because it's always better to <TAB>  <TAB> # fall back to non-colored logs than to break at startup. <TAB>  <TAB> pass <TAB> return False","if curses . tigetnum ( ""colors"" ) > 0 :",170
7,"def offsets(self): <TAB> offsets = {} <TAB> offset_so_far = 0 <TAB> for name, ty in self.fields.items(): <TAB>  <TAB> if isinstance(ty, SimTypeBottom): <TAB>  <TAB>  <TAB> l.warning( <TAB>  <TAB>  <TAB>  <TAB> ""Found a bottom field in struct %s. Ignore and increment the offset using the default "" <TAB>  <TAB>  <TAB>  <TAB> ""element size."", <TAB>  <TAB>  <TAB>  <TAB> self.name, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if not self._pack: <TAB>  <TAB>  <TAB> align = ty.alignment <MASK> offset_so_far += align - offset_so_far % align <TAB>  <TAB> offsets[name] = offset_so_far <TAB>  <TAB> offset_so_far += ty.size // self._arch.byte_width <TAB> return offsets",if offset_so_far % align != 0 :,196
8,"def Restore(self): <TAB> picker, obj = self._window, self._pObject <TAB> value = obj.RestoreValue(PERSIST_FILEDIRPICKER_PATH) <TAB> if value is not None: <TAB>  <TAB> if issubclass(picker.__class__, wx.FileDialog): <MASK> value = value[-1] <TAB>  <TAB> picker.SetPath(value) <TAB>  <TAB> return True <TAB> return False",if type ( value ) == list :,102
9,"def dt_s_tup_to_string(dt_s_tup): <TAB> dt_string = dt_s_tup[0]  # string for identifying the file to parse. <TAB> if dt_s_tup[1] > 0:  # if there are seasons in the model <MASK> dt_string = dt_string[:2] + ""s"" + dt_string[2:] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> dt_string = ""s"" + dt_string <TAB> return dt_string","if ""co"" in dt_string or ""ci"" in dt_string or ""nc"" in dt_string :",146
10,"def writer(stream, items): <TAB> sep = """" <TAB> for item in items: <TAB>  <TAB> stream.write(sep) <TAB>  <TAB> sep = "" "" <MASK> item = str(item) <TAB>  <TAB> if not PY3K: <TAB>  <TAB>  <TAB> if not isinstance(item, unicode): <TAB>  <TAB>  <TAB>  <TAB> item = str(item) <TAB>  <TAB> stream.write(item) <TAB> stream.write(""\n"")","if not isinstance ( item , str ) :",106
11,"def _get_result_keys(self, config): <TAB> result_key = config.get(""result_key"") <TAB> if result_key is not None: <MASK> result_key = [result_key] <TAB>  <TAB> result_key = [jmespath.compile(rk) for rk in result_key] <TAB>  <TAB> return result_key","if not isinstance ( result_key , list ) :",92
12,"def _download_build_artifacts(self, build: Dict[str, Any]) -> None: <TAB> arch = build[""arch_tag""] <TAB> snap_build = self._lp_load_url(build[""self_link""]) <TAB> urls = snap_build.getFileUrls() <TAB> if not urls: <TAB>  <TAB> logger.error(f""Snap file not available for arch {arch!r}."") <TAB>  <TAB> return <TAB> for url in urls: <TAB>  <TAB> file_name = _get_url_basename(url) <TAB>  <TAB> self._download_file(url=url, dst=file_name) <MASK> logger.info(f""Snapped {file_name}"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logger.info(f""Fetched {file_name}"")","if file_name . endswith ( "".snap"" ) :",187
13,"def _add_custom_statement(self, custom_statements): <TAB> if custom_statements is None: <TAB>  <TAB> return <TAB> self.resource_policy[""Version""] = ""2012-10-17"" <TAB> if self.resource_policy.get(""Statement"") is None: <TAB>  <TAB> self.resource_policy[""Statement""] = custom_statements <TAB> else: <TAB>  <TAB> if not isinstance(custom_statements, list): <TAB>  <TAB>  <TAB> custom_statements = [custom_statements] <TAB>  <TAB> statement = self.resource_policy[""Statement""] <TAB>  <TAB> if not isinstance(statement, list): <TAB>  <TAB>  <TAB> statement = [statement] <TAB>  <TAB> for s in custom_statements: <MASK> statement.append(s) <TAB>  <TAB> self.resource_policy[""Statement""] = statement",if s not in statement :,184
14,"def display_failures_for_single_test(result: TestResult) -> None: <TAB> """"""Display a failure for a single method / endpoint."""""" <TAB> display_subsection(result) <TAB> checks = _get_unique_failures(result.checks) <TAB> for idx, check in enumerate(checks, 1): <TAB>  <TAB> message: Optional[str] <MASK> message = f""{idx}. {check.message}"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> message = None <TAB>  <TAB> example = cast(Case, check.example)  # filtered in `_get_unique_failures` <TAB>  <TAB> display_example(example, check.name, message, result.seed) <TAB>  <TAB> # Display every time except the last check <TAB>  <TAB> if idx != len(checks): <TAB>  <TAB>  <TAB> click.echo(""\n"")",if check . message :,188
15,"def build(opt): <TAB> dpath = os.path.join(opt[""datapath""], ""qangaroo"") <TAB> version = ""v1.1"" <TAB> if not build_data.built(dpath, version_string=version): <TAB>  <TAB> print(""[building data: "" + dpath + ""]"") <MASK> # An older version exists, so remove these outdated files. <TAB>  <TAB>  <TAB> build_data.remove_dir(dpath) <TAB>  <TAB> build_data.make_dir(dpath) <TAB>  <TAB> # Download the data. <TAB>  <TAB> for downloadable_file in RESOURCES: <TAB>  <TAB>  <TAB> downloadable_file.download_file(dpath) <TAB>  <TAB> # Mark the data as built. <TAB>  <TAB> build_data.mark_done(dpath, version_string=version)",if build_data . built ( dpath ) :,188
16,"def call(self, step_input, states): <TAB> new_states = [] <TAB> for i in range(self.num_layers): <TAB>  <TAB> out, new_state = self.lstm_cells[i](step_input, states[i]) <TAB>  <TAB> step_input = ( <TAB>  <TAB>  <TAB> layers.dropout( <TAB>  <TAB>  <TAB>  <TAB> out, self.dropout_prob, dropout_implementation=""upscale_in_train"" <TAB>  <TAB>  <TAB> ) <MASK> else out <TAB>  <TAB> ) <TAB>  <TAB> new_states.append(new_state) <TAB> return step_input, new_states",if self . dropout_prob > 0.0,148
17,"def jupyter_progress_bar(min=0, max=1.0): <TAB> """"""Returns an ipywidget progress bar or None if we can't import it"""""" <TAB> widgets = wandb.util.get_module(""ipywidgets"") <TAB> try: <MASK> # TODO: this currently works in iPython but it's deprecated since 4.0 <TAB>  <TAB>  <TAB> from IPython.html import widgets  # type: ignore <TAB>  <TAB> assert hasattr(widgets, ""VBox"") <TAB>  <TAB> assert hasattr(widgets, ""Label"") <TAB>  <TAB> assert hasattr(widgets, ""FloatProgress"") <TAB>  <TAB> return ProgressWidget(widgets, min=min, max=max) <TAB> except (ImportError, AssertionError): <TAB>  <TAB> return None",if widgets is None :,168
18,"def _record_event(self, path, fsevent_handle, filename, events, error): <TAB> with self.lock: <TAB>  <TAB> self.events[path].append(events) <MASK> if not os.path.exists(path): <TAB>  <TAB>  <TAB>  <TAB> self.watches.pop(path).close()",if events | pyuv . fs . UV_RENAME :,89
19,"def _get_v1_id_from_tags(self, tags_obj, tag): <TAB> """"""Get image id from array of tags"""""" <TAB> if isinstance(tags_obj, dict): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return tags_obj[tag] <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> pass <TAB> elif isinstance(tags_obj, []): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> for tag_dict in tags_obj: <MASK> return tag_dict[""layer""] <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> pass <TAB> return """"","if tag_dict [ ""name"" ] == tag :",142
20,"def query_lister(domain, query="""", max_items=None, attr_names=None): <TAB> more_results = True <TAB> num_results = 0 <TAB> next_token = None <TAB> while more_results: <TAB>  <TAB> rs = domain.connection.query_with_attributes( <TAB>  <TAB>  <TAB> domain, query, attr_names, next_token=next_token <TAB>  <TAB> ) <TAB>  <TAB> for item in rs: <MASK> if num_results == max_items: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise StopIteration <TAB>  <TAB>  <TAB> yield item <TAB>  <TAB>  <TAB> num_results += 1 <TAB>  <TAB> next_token = rs.next_token <TAB>  <TAB> more_results = next_token != None",if max_items :,166
21,"def filter(this, args): <TAB> array = to_object(this, args.space) <TAB> callbackfn = get_arg(args, 0) <TAB> arr_len = js_arr_length(array) <TAB> if not is_callable(callbackfn): <TAB>  <TAB> raise MakeError(""TypeError"", ""callbackfn must be a function"") <TAB> _this = get_arg(args, 1) <TAB> k = 0 <TAB> res = [] <TAB> while k < arr_len: <MASK> kValue = array.get(unicode(k)) <TAB>  <TAB>  <TAB> if to_boolean(callbackfn.call(_this, (kValue, float(k), array))): <TAB>  <TAB>  <TAB>  <TAB> res.append(kValue) <TAB>  <TAB> k += 1 <TAB> return args.space.ConstructArray(res)",if array . has_property ( unicode ( k ) ) :,194
22,"def every_one_is(self, dst): <TAB> msg = ""all members of %r should be %r, but the %dth is %r"" <TAB> for index, item in enumerate(self._src): <TAB>  <TAB> if self._range: <TAB>  <TAB>  <TAB> if index < self._range[0] or index > self._range[1]: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> error = msg % (self._src, dst, index, item) <MASK> raise AssertionError(error) <TAB> return True",if item != dst :,124
23,"def schedule_logger(job_id=None, delete=False): <TAB> if not job_id: <TAB>  <TAB> return getLogger(""fate_flow_schedule"") <TAB> else: <TAB>  <TAB> if delete: <TAB>  <TAB>  <TAB> with LoggerFactory.lock: <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for key in LoggerFactory.schedule_logger_dict.keys(): <MASK> del LoggerFactory.schedule_logger_dict[key] <TAB>  <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> key = job_id + ""schedule"" <TAB>  <TAB> if key in LoggerFactory.schedule_logger_dict: <TAB>  <TAB>  <TAB> return LoggerFactory.schedule_logger_dict[key] <TAB>  <TAB> return LoggerFactory.get_schedule_logger(job_id)",if job_id in key :,198
24,"def Tokenize(s): <TAB> # type: (str) -> Iterator[Token] <TAB> for item in TOKEN_RE.findall(s): <TAB>  <TAB> # The type checker can't know the true type of item! <TAB>  <TAB> item = cast(TupleStr4, item) <TAB>  <TAB> if item[0]: <TAB>  <TAB>  <TAB> typ = ""number"" <TAB>  <TAB>  <TAB> val = item[0] <TAB>  <TAB> elif item[1]: <TAB>  <TAB>  <TAB> typ = ""name"" <TAB>  <TAB>  <TAB> val = item[1] <MASK> typ = item[2] <TAB>  <TAB>  <TAB> val = item[2] <TAB>  <TAB> elif item[3]: <TAB>  <TAB>  <TAB> typ = item[3] <TAB>  <TAB>  <TAB> val = item[3] <TAB>  <TAB> yield Token(typ, val)",elif item [ 2 ] :,181
25,"def _read_data_from_all_categories(self, directory, config, categories): <TAB> lines = [] <TAB> for category in categories: <TAB>  <TAB> data_file = os.path.join(directory, _DATASET_VERSION, category, config) <MASK> with open(data_file) as f: <TAB>  <TAB>  <TAB>  <TAB> ls = f.read().split(""\n"") <TAB>  <TAB>  <TAB>  <TAB> for l in ls[::-1]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if not l: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ls.remove(l) <TAB>  <TAB>  <TAB>  <TAB> lines.extend(ls) <TAB> return lines",if os . path . exists ( data_file ) :,150
26,"def find_handlers(self, forms): <TAB> handlers = {} <TAB> for form in forms.itervalues(): <TAB>  <TAB> for action_name, _action_label in form.actions: <MASK> handlers[action_name] = form <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise HandlerError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""More than one form defines the handler %s"" % action_name <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return handlers",if action_name not in handlers :,112
27,"def get_story_task_completed_body(payload: Dict[str, Any]) -> Optional[str]: <TAB> action = get_action_with_primary_id(payload) <TAB> kwargs = { <TAB>  <TAB> ""task_description"": action[""description""], <TAB> } <TAB> story_id = action[""story_id""] <TAB> for ref in payload[""references""]: <MASK> kwargs[""name_template""] = STORY_NAME_TEMPLATE.format( <TAB>  <TAB>  <TAB>  <TAB> name=ref[""name""], <TAB>  <TAB>  <TAB>  <TAB> app_url=ref[""app_url""], <TAB>  <TAB>  <TAB> ) <TAB> if action[""changes""][""complete""][""new""]: <TAB>  <TAB> return STORY_TASK_COMPLETED_TEMPLATE.format(**kwargs) <TAB> else: <TAB>  <TAB> return None","if ref [ ""id"" ] == story_id :",188
28,"def _create_valid_graph(graph): <TAB> nodes = graph.nodes() <TAB> for i in range(len(nodes)): <TAB>  <TAB> for j in range(len(nodes)): <MASK> continue <TAB>  <TAB>  <TAB> edge = (nodes[i], nodes[j]) <TAB>  <TAB>  <TAB> if graph.has_edge(edge): <TAB>  <TAB>  <TAB>  <TAB> graph.del_edge(edge) <TAB>  <TAB>  <TAB> graph.add_edge(edge, 1)",if i == j :,112
29,"def _post_order(op): <TAB> if isinstance(op, tvm.tir.Allocate): <TAB>  <TAB> lift_stmt[-1].append(op) <TAB>  <TAB> return op.body <TAB> if isinstance(op, tvm.tir.AttrStmt): <MASK> lift_stmt[-1].append(op) <TAB>  <TAB>  <TAB> return op.body <TAB>  <TAB> if op.attr_key == ""virtual_thread"": <TAB>  <TAB>  <TAB> return _merge_block(lift_stmt.pop() + [op], op.body) <TAB>  <TAB> return op <TAB> if isinstance(op, tvm.tir.For): <TAB>  <TAB> return _merge_block(lift_stmt.pop() + [op], op.body) <TAB> raise RuntimeError(""not reached"")","if op . attr_key == ""storage_scope"" :",188
30,"def format_lazy_import(names): <TAB> """"""Formats lazy import lines"""""" <TAB> lines = """" <TAB> for _, name, asname in names: <TAB>  <TAB> pkg, _, _ = name.partition(""."") <MASK> line = ""{pkg} = _LazyModule.load({pkg!r}, {mod!r})\n"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> line = ""{asname} = _LazyModule.load({pkg!r}, {mod!r}, {asname!r})\n"" <TAB>  <TAB> lines += line.format(pkg=pkg, mod=name, asname=asname) <TAB> return lines",if asname is None :,140
31,"def evaluateWord(self, argument): <TAB> wildcard_count = argument[0].count(""*"") <TAB> if wildcard_count > 0: <TAB>  <TAB> if wildcard_count == 1 and argument[0].startswith(""*""): <TAB>  <TAB>  <TAB> return self.GetWordWildcard(argument[0][1:], method=""endswith"") <TAB>  <TAB> if wildcard_count == 1 and argument[0].endswith(""*""): <TAB>  <TAB>  <TAB> return self.GetWordWildcard(argument[0][:-1], method=""startswith"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _regex = argument[0].replace(""*"", "".+"") <TAB>  <TAB>  <TAB> matched = False <TAB>  <TAB>  <TAB> for w in self.words: <TAB>  <TAB>  <TAB>  <TAB> matched = bool(re.search(_regex, w)) <MASK> break <TAB>  <TAB>  <TAB> return matched <TAB> return self.GetWord(argument[0])",if matched :,194
32,"def setup(self, ir: ""IR"", aconf: Config) -> bool: <TAB> if self.kind == ""ConsulResolver"": <TAB>  <TAB> self.resolve_with = ""consul"" <MASK> self.post_error(""ConsulResolver is required to have a datacenter"") <TAB>  <TAB>  <TAB> return False <TAB> elif self.kind == ""KubernetesServiceResolver"": <TAB>  <TAB> self.resolve_with = ""k8s"" <TAB> elif self.kind == ""KubernetesEndpointResolver"": <TAB>  <TAB> self.resolve_with = ""k8s"" <TAB> else: <TAB>  <TAB> self.post_error(f""Resolver kind {self.kind} unknown"") <TAB>  <TAB> return False <TAB> return True","if not self . get ( ""datacenter"" ) :",170
33,"def get_success_url(self): <TAB> """"""Continue to the flow index or redirect according `?back` parameter."""""" <TAB> if ""back"" in self.request.GET: <TAB>  <TAB> back_url = self.request.GET[""back""] <MASK> back_url = ""/"" <TAB>  <TAB> return back_url <TAB> return reverse(self.success_url)","if not is_safe_url ( url = back_url , allowed_hosts = { self . request . get_host ( ) } ) :",111
34,"def download_main( <TAB> download, download_playlist, urls, playlist, output_dir, merge, info_only): <TAB> for url in urls: <TAB>  <TAB> if url.startswith(""https://""): <TAB>  <TAB>  <TAB> url = url[8:] <MASK> url = ""http://"" + url <TAB>  <TAB> if playlist: <TAB>  <TAB>  <TAB> download_playlist( <TAB>  <TAB>  <TAB>  <TAB> url, output_dir=output_dir, merge=merge, info_only=info_only <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> download(url, output_dir=output_dir, merge=merge, info_only=info_only)","if not url . startswith ( ""http://"" ) :",155
35,"def __str__(self): <TAB> buf = [""""] <TAB> if self.fileName: <TAB>  <TAB> buf.append(self.fileName + "":"") <TAB> if self.line != -1: <MASK> buf.append(""line "") <TAB>  <TAB> buf.append(str(self.line)) <TAB>  <TAB> if self.column != -1: <TAB>  <TAB>  <TAB> buf.append("":"" + str(self.column)) <TAB>  <TAB> buf.append("":"") <TAB> buf.append("" "") <TAB> return str("""").join(buf)",if not self . fileName :,124
36,"def parse_bash_set_output(output): <TAB> """"""Parse Bash-like 'set' output"""""" <TAB> if not sys.platform.startswith(""win""): <TAB>  <TAB> # Replace ""\""-continued lines in *Linux* environment dumps. <TAB>  <TAB> # Cannot do this on Windows because a ""\"" at the end of the <TAB>  <TAB> # line does not imply a continuation. <TAB>  <TAB> output = output.replace(""\\\n"", """") <TAB> environ = {} <TAB> for line in output.splitlines(0): <TAB>  <TAB> line = line.rstrip() <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB> continue  # skip black lines <TAB>  <TAB> item = _ParseBashEnvStr(line) <MASK> environ[item[0]] = item[1] <TAB> return environ",if item :,177
37,"def remove_selected(self): <TAB> """"""Removes selected items from list."""""" <TAB> to_delete = [] <TAB> for i in range(len(self)): <TAB>  <TAB> if self[i].selected: <TAB>  <TAB>  <TAB> to_delete.append(i) <TAB> to_delete.reverse() <TAB> for i in to_delete: <TAB>  <TAB> self.pop(i) <TAB> if len(to_delete) > 0: <TAB>  <TAB> first_to_delete = to_delete[-1] <MASK> self[0].selected = True <TAB>  <TAB> elif first_to_delete > 0: <TAB>  <TAB>  <TAB> self[first_to_delete - 1].selected = True",if first_to_delete == 0 and len ( self ) > 0 :,169
38,"def update(self, update_tracks=True): <TAB> self.enable_update_metadata_images(False) <TAB> old_album_title = self.metadata[""album""] <TAB> self.metadata[""album""] = config.setting[""nat_name""] <TAB> for track in self.tracks: <MASK> track.metadata[""album""] = self.metadata[""album""] <TAB>  <TAB> for file in track.linked_files: <TAB>  <TAB>  <TAB> track.update_file_metadata(file) <TAB> self.enable_update_metadata_images(True) <TAB> super().update(update_tracks)","if old_album_title == track . metadata [ ""album"" ] :",149
39,"def on_input(self, target, message): <TAB> if message.strip() == """": <TAB>  <TAB> self.panel(""No commit message provided"") <TAB>  <TAB> return <TAB> if target: <TAB>  <TAB> command = [""git"", ""add""] <MASK> command.append(""--all"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> command.extend((""--"", target)) <TAB>  <TAB> self.run_command(command, functools.partial(self.add_done, message)) <TAB> else: <TAB>  <TAB> self.add_done(message, """")","if target == ""*"" :",125
40,"def go_to_last_edit_location(self): <TAB> if self.last_edit_cursor_pos is not None: <TAB>  <TAB> filename, position = self.last_edit_cursor_pos <MASK> self.last_edit_cursor_pos = None <TAB>  <TAB>  <TAB> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.load(filename) <TAB>  <TAB>  <TAB> editor = self.get_current_editor() <TAB>  <TAB>  <TAB> if position < editor.document().characterCount(): <TAB>  <TAB>  <TAB>  <TAB> editor.set_cursor_position(position)",if not osp . isfile ( filename ) :,135
41,"def returnByType(self, results): <TAB> new_results = {} <TAB> for r in results: <TAB>  <TAB> type_name = r.get(""type"", ""movie"") + ""s"" <MASK> new_results[type_name] = [] <TAB>  <TAB> new_results[type_name].append(r) <TAB> # Combine movies, needs a cleaner way.. <TAB> if ""movies"" in new_results: <TAB>  <TAB> new_results[""movies""] = self.combineOnIMDB(new_results[""movies""]) <TAB> return new_results",if type_name not in new_results :,144
42,"def cache_sns_topics_across_accounts() -> bool: <TAB> function: str = f""{__name__}.{sys._getframe().f_code.co_name}"" <TAB> # First, get list of accounts <TAB> accounts_d: list = async_to_sync(get_account_id_to_name_mapping)() <TAB> for account_id in accounts_d.keys(): <TAB>  <TAB> if config.get(""environment"") == ""prod"": <TAB>  <TAB>  <TAB> cache_sns_topics_for_account.delay(account_id) <TAB>  <TAB> else: <MASK> cache_sns_topics_for_account.delay(account_id) <TAB> stats.count(f""{function}.success"") <TAB> return True","if account_id in config . get ( ""celery.test_account_ids"" , [ ] ) :",185
43,"def get(self, subject, topic): <TAB> """"""Handles GET requests."""""" <TAB> if subject in feconf.AVAILABLE_LANDING_PAGES: <MASK> self.render_template(""topic-landing-page.mainpage.html"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise self.PageNotFoundException <TAB> else: <TAB>  <TAB> raise self.PageNotFoundException",if topic in feconf . AVAILABLE_LANDING_PAGES [ subject ] :,100
44,"def callback(compiled): <MASK> logger.show_tabulated( <TAB>  <TAB>  <TAB> ""Compiled"", showpath(codepath), ""without writing to file."" <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> with univ_open(destpath, ""w"") as opened: <TAB>  <TAB>  <TAB> writefile(opened, compiled) <TAB>  <TAB> logger.show_tabulated(""Compiled to"", showpath(destpath), ""."") <TAB> if self.show: <TAB>  <TAB> print(compiled) <TAB> if run: <TAB>  <TAB> if destpath is None: <TAB>  <TAB>  <TAB> self.execute(compiled, path=codepath, allow_show=False) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.execute_file(destpath)",if destpath is None :,166
45,"def _find_start_index(self, string, start, end): <TAB> while True: <TAB>  <TAB> index = string.find(""{"", start, end) - 1 <TAB>  <TAB> if index < 0: <TAB>  <TAB>  <TAB> return -1 <MASK> return index <TAB>  <TAB> start = index + 2","if self . _start_index_is_ok ( string , index ) :",84
46,"def _get_nlu_target_format(export_path: Text) -> Text: <TAB> guessed_format = loading.guess_format(export_path) <TAB> if guessed_format not in {MARKDOWN, RASA, RASA_YAML}: <TAB>  <TAB> if rasa.shared.data.is_likely_json_file(export_path): <TAB>  <TAB>  <TAB> guessed_format = RASA <TAB>  <TAB> elif rasa.shared.data.is_likely_markdown_file(export_path): <TAB>  <TAB>  <TAB> guessed_format = MARKDOWN <MASK> guessed_format = RASA_YAML <TAB> return guessed_format",elif rasa . shared . data . is_likely_yaml_file ( export_path ) :,166
47,"def moveToThreadNext(self): <TAB> """"""Move a position to threadNext position."""""" <TAB> p = self <TAB> if p.v: <TAB>  <TAB> if p.v.children: <TAB>  <TAB>  <TAB> p.moveToFirstChild() <TAB>  <TAB> el <MASK> p.moveToNext() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> p.moveToParent() <TAB>  <TAB>  <TAB> while p: <TAB>  <TAB>  <TAB>  <TAB> if p.hasNext(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> p.moveToNext() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break  # found <TAB>  <TAB>  <TAB>  <TAB> p.moveToParent() <TAB>  <TAB>  <TAB> # not found. <TAB> return p",if p . hasNext ( ) :,150
48,"def copy_attributes(info_add, obj, name_fmt, attributes, formatter=None): <TAB> for attr in attributes: <TAB>  <TAB> value = getattr(obj, attr, None) <MASK> continue <TAB>  <TAB> name = name_fmt % attr <TAB>  <TAB> if formatter is not None: <TAB>  <TAB>  <TAB> value = formatter(attr, value) <TAB>  <TAB> info_add(name, value)",if value is None :,97
49,"def getElement(self, aboutUri, namespace, name): <TAB> for desc in self.rdfRoot.getElementsByTagNameNS(RDF_NAMESPACE, ""Description""): <MASK> attr = desc.getAttributeNodeNS(namespace, name) <TAB>  <TAB>  <TAB> if attr != None: <TAB>  <TAB>  <TAB>  <TAB> yield attr <TAB>  <TAB>  <TAB> for element in desc.getElementsByTagNameNS(namespace, name): <TAB>  <TAB>  <TAB>  <TAB> yield element","if desc . getAttributeNS ( RDF_NAMESPACE , ""about"" ) == aboutUri :",113
50,def run(self): <TAB> while not self.completed: <TAB>  <TAB> if self.block: <TAB>  <TAB>  <TAB> time.sleep(self.period) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._completed.wait(self.period) <TAB>  <TAB> self.counter += 1 <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.callback(self.counter) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> self.stop() <MASK> dt = time.time() - self._start_time <TAB>  <TAB>  <TAB> if dt > self.timeout: <TAB>  <TAB>  <TAB>  <TAB> self.stop() <TAB>  <TAB> if self.counter == self.count: <TAB>  <TAB>  <TAB> self.stop(),if self . timeout is not None :,159
51,"def _parse_fixits(message, titer, line): <TAB> """"""Parses fixit messages."""""" <TAB> while ( <TAB>  <TAB> OutputParser.message_line_re.match(line) is None <TAB>  <TAB> and OutputParser.note_line_re.match(line) is None <TAB> ): <TAB>  <TAB> message_text = line.strip() <MASK> message.fixits.append( <TAB>  <TAB>  <TAB>  <TAB> Note( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> message.path, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> message.line, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> line.find(message_text) + 1, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> message_text, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> line = next(titer) <TAB> return line","if message_text != """" :",177
52,"def _connect_db(self, force_reconnect=False): <TAB> thread_id = thread.get_ident() <TAB> if force_reconnect and thread_id in ENGINES: <TAB>  <TAB> del ENGINES[thread_id] <TAB> conn = None <TAB> try: <TAB>  <TAB> engine = ENGINES[thread_id] <TAB>  <TAB> conn = engine.connect() <TAB>  <TAB> _test = conn.execute(""SELECT 1"") <TAB>  <TAB> _test.fetchall() <TAB> except (KeyError, MySQLdb.OperationalError): <MASK> conn.close() <TAB>  <TAB> engine = sqla.create_engine(self.db_url, pool_recycle=3600) <TAB>  <TAB> ENGINES[thread_id] = engine <TAB>  <TAB> conn = engine.connect() <TAB> return conn",if conn :,183
53,"def read(self, n): <TAB> if self.current_frame: <TAB>  <TAB> data = self.current_frame.read(n) <MASK> self.current_frame = None <TAB>  <TAB>  <TAB> return self.file_read(n) <TAB>  <TAB> if len(data) < n: <TAB>  <TAB>  <TAB> raise UnpicklingError(""pickle exhausted before end of frame"") <TAB>  <TAB> return data <TAB> else: <TAB>  <TAB> return self.file_read(n)",if not data and n != 0 :,115
54,"def __setLoadCmd(self): <TAB> base = self.__rawLoadCmd <TAB> for _ in range(self.__machHeader.ncmds): <TAB>  <TAB> command = LOAD_COMMAND.from_buffer_copy(base) <MASK> segment = SEGMENT_COMMAND.from_buffer_copy(base) <TAB>  <TAB>  <TAB> self.__setSections(segment, base[56:], 32) <TAB>  <TAB> elif command.cmd == MACHOFlags.LC_SEGMENT_64: <TAB>  <TAB>  <TAB> segment = SEGMENT_COMMAND64.from_buffer_copy(base) <TAB>  <TAB>  <TAB> self.__setSections(segment, base[72:], 64) <TAB>  <TAB> base = base[command.cmdsize :]",if command . cmd == MACHOFlags . LC_SEGMENT :,174
55,"def emit_post_sync_signal(created_models, verbosity, interactive, db): <TAB> # Emit the post_sync signal for every application. <TAB> for app in models.get_apps(): <TAB>  <TAB> app_name = app.__name__.split(""."")[-2] <MASK> print(""Running post-sync handlers for application %s"" % app_name) <TAB>  <TAB> models.signals.post_syncdb.send( <TAB>  <TAB>  <TAB> sender=app, <TAB>  <TAB>  <TAB> app=app, <TAB>  <TAB>  <TAB> created_models=created_models, <TAB>  <TAB>  <TAB> verbosity=verbosity, <TAB>  <TAB>  <TAB> interactive=interactive, <TAB>  <TAB>  <TAB> db=db, <TAB>  <TAB> )",if verbosity >= 2 :,158
56,"def git_pull(args): <TAB> if len(args) <= 1: <TAB>  <TAB> repo = _get_repo() <TAB>  <TAB> _confirm_dangerous() <TAB>  <TAB> url = args[0] if len(args) == 1 else repo.remotes.get(""origin"", """") <TAB>  <TAB> if url in repo.remotes: <TAB>  <TAB>  <TAB> origin = url <TAB>  <TAB>  <TAB> url = repo.remotes.get(origin) <MASK> repo.pull(origin_uri=url) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""No pull URL."") <TAB> else: <TAB>  <TAB> print(command_help[""git pull""])",if url :,147
57,"def version(self): <TAB> try: <TAB>  <TAB> return self._version <TAB> except AttributeError: <TAB>  <TAB> for line in self._get_metadata(self.PKG_INFO): <MASK> self._version = safe_version(line.split("":"", 1)[1].strip()) <TAB>  <TAB>  <TAB>  <TAB> return self._version <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tmpl = ""Missing 'Version:' header and/or %s file"" <TAB>  <TAB>  <TAB> raise ValueError(tmpl % self.PKG_INFO, self)","if line . lower ( ) . startswith ( ""version:"" ) :",127
58,"def increment(self, metric, labels, delta): <TAB> """"""Increment a value by |delta|."""""" <TAB> with self._lock: <TAB>  <TAB> key = self._get_key(metric.name, labels) <MASK> start_time = self._store[key].start_time <TAB>  <TAB>  <TAB> value = self._store[key].value + delta <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> start_time = time.time() <TAB>  <TAB>  <TAB> value = metric.default_value + delta <TAB>  <TAB> self._store[key] = _StoreValue(metric, labels, start_time, value)",if key in self . _store :,143
59,"def get_current_connections(session): <TAB> """"""Retrieves open connections using the the given session"""""" <TAB> # Use Show process list to count the open sesions. <TAB> res = session.sql(""SHOW PROCESSLIST"").execute() <TAB> rows = res.fetch_all() <TAB> connections = {} <TAB> for row in rows: <MASK> connections[row.get_string(""User"")] = [row.get_string(""Host"")] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> connections[row.get_string(""User"")].append(row.get_string(""Host"")) <TAB> return connections","if row . get_string ( ""User"" ) not in connections :",148
60,"def asset(*paths): <TAB> for path in paths: <TAB>  <TAB> fspath = www_root + ""/assets/"" + path <TAB>  <TAB> etag = """" <TAB>  <TAB> try: <MASK> etag = asset_etag(fspath) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> os.stat(fspath) <TAB>  <TAB> except FileNotFoundError as e: <TAB>  <TAB>  <TAB> if path == paths[-1]: <TAB>  <TAB>  <TAB>  <TAB> if not os.path.exists(fspath + "".spt""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> tell_sentry(e, {}) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> tell_sentry(e, {}) <TAB>  <TAB> return asset_url + path + (etag and ""?etag="" + etag)",if env . cache_static :,182
61,def thread_loop(self) -> None: <TAB> while not self.stop_event.is_set(): <TAB>  <TAB> time.sleep(1) <TAB>  <TAB> new_trials = self.study.trials <TAB>  <TAB> with self.lock: <TAB>  <TAB>  <TAB> need_to_add_callback = self.new_trials is None <TAB>  <TAB>  <TAB> self.new_trials = new_trials <MASK> self.doc.add_next_tick_callback(self.update_callback),if need_to_add_callback :,122
62,"def _cache_db_tables_iterator(tables, cache_alias, db_alias): <TAB> no_tables = not tables <TAB> cache_aliases = settings.CACHES if cache_alias is None else (cache_alias,) <TAB> db_aliases = settings.DATABASES if db_alias is None else (db_alias,) <TAB> for db_alias in db_aliases: <TAB>  <TAB> if no_tables: <TAB>  <TAB>  <TAB> tables = connections[db_alias].introspection.table_names() <MASK> for cache_alias in cache_aliases: <TAB>  <TAB>  <TAB>  <TAB> yield cache_alias, db_alias, tables",if tables :,145
63,"def remove_subscriber(self, topic, subscriber): <TAB> if subscriber in self.subscribers[topic]: <TAB>  <TAB> if hasattr(subscriber, ""_pyroRelease""): <TAB>  <TAB>  <TAB> subscriber._pyroRelease() <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> proxy = self.proxy_cache[subscriber._pyroUri] <TAB>  <TAB>  <TAB>  <TAB> proxy._pyroRelease() <TAB>  <TAB>  <TAB>  <TAB> del self.proxy_cache[subscriber._pyroUri] <TAB>  <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> self.subscribers[topic].discard(subscriber)","if hasattr ( subscriber , ""_pyroUri"" ) :",139
64,"def test_constructor(job_id): <TAB> with patch(""apscheduler.job.Job._modify"") as _modify: <TAB>  <TAB> scheduler_mock = MagicMock(BaseScheduler) <TAB>  <TAB> job = Job(scheduler_mock, id=job_id) <TAB>  <TAB> assert job._scheduler is scheduler_mock <TAB>  <TAB> assert job._jobstore_alias is None <TAB>  <TAB> modify_kwargs = _modify.call_args[1] <MASK> assert len(modify_kwargs[""id""]) == 32 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert modify_kwargs[""id""] == job_id",if job_id is None :,141
65,"def get_connection(self): <TAB> if self.config.proxy_host != """": <TAB>  <TAB> return httplib.HTTPConnection(self.config.proxy_host, self.config.proxy_port) <TAB> else: <MASK> return httplib.HTTPSConnection(self.config.simpledb_host) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return httplib.HTTPConnection(self.config.simpledb_host)",if self . config . use_https :,107
66,"def notify_login(self, ipaddress=""""): <TAB> if app.NOTIFY_ON_LOGIN: <TAB>  <TAB> update_text = common.notifyStrings[common.NOTIFY_LOGIN_TEXT] <TAB>  <TAB> title = common.notifyStrings[common.NOTIFY_LOGIN] <MASK> self._notify_pht(title, update_text.format(ipaddress))",if update_text and title and ipaddress :,93
67,"def _getItemHeight(self, item, ctrl=None): <TAB> """"""Returns the full height of the item to be inserted in the form"""""" <TAB> if type(ctrl) == psychopy.visual.TextBox2: <TAB>  <TAB> return ctrl.size[1] <TAB> if type(ctrl) == psychopy.visual.Slider: <TAB>  <TAB> # Set radio button layout <TAB>  <TAB> if item[""layout""] == ""horiz"": <TAB>  <TAB>  <TAB> return 0.03 + ctrl.labelHeight * 3 <MASK> # for vertical take into account the nOptions <TAB>  <TAB>  <TAB> return ctrl.labelHeight * len(item[""options""])","elif item [ ""layout"" ] == ""vert"" :",155
68,"def _get_errors_lines(self): <TAB> """"""Return the number of lines that contains errors to highlight."""""" <TAB> errors_lines = [] <TAB> block = self.document().begin() <TAB> while block.isValid(): <TAB>  <TAB> user_data = get_user_data(block) <MASK> errors_lines.append(block.blockNumber()) <TAB>  <TAB> block = block.next() <TAB> return errors_lines",if user_data . error :,105
69,"def set_pbar_fraction(self, frac, progress, stage=None): <TAB> gtk.gdk.threads_enter() <TAB> try: <TAB>  <TAB> self.is_pulsing = False <TAB>  <TAB> self.set_stage_text(stage or _(""Processing..."")) <TAB>  <TAB> self.pbar.set_text(progress) <TAB>  <TAB> if frac > 1: <TAB>  <TAB>  <TAB> frac = 1.0 <MASK> frac = 0 <TAB>  <TAB> self.pbar.set_fraction(frac) <TAB> finally: <TAB>  <TAB> gtk.gdk.threads_leave()",if frac < 0 :,135
70,"def list_files(basedir): <TAB> """"""List files in the directory rooted at |basedir|."""""" <TAB> if not os.path.isdir(basedir): <TAB>  <TAB> raise NoSuchDirectory(basedir) <TAB> directories = [""""] <TAB> while directories: <TAB>  <TAB> d = directories.pop() <TAB>  <TAB> for basename in os.listdir(os.path.join(basedir, d)): <TAB>  <TAB>  <TAB> filename = os.path.join(d, basename) <TAB>  <TAB>  <TAB> if os.path.isdir(os.path.join(basedir, filename)): <TAB>  <TAB>  <TAB>  <TAB> directories.append(filename) <MASK> yield filename","elif os . path . exists ( os . path . join ( basedir , filename ) ) :",159
71,"def assistive(self): <TAB> """"""Detects if item can be used as assistance"""""" <TAB> # Make sure we cache results <TAB> if self.__assistive is None: <TAB>  <TAB> assistive = False <TAB>  <TAB> # Go through all effects and find first assistive <TAB>  <TAB> for effect in self.effects.values(): <MASK> # If we find one, stop and mark item as assistive <TAB>  <TAB>  <TAB>  <TAB> assistive = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> self.__assistive = assistive <TAB> return self.__assistive",if effect . isAssistance is True :,141
72,"def closest_unseen(self, row1, col1, filter=None): <TAB> # find the closest unseen from this row/col <TAB> min_dist = maxint <TAB> closest_unseen = None <TAB> for row in range(self.height): <TAB>  <TAB> for col in range(self.width): <TAB>  <TAB>  <TAB> if filter is None or (row, col) not in filter: <TAB>  <TAB>  <TAB>  <TAB> if self.map[row][col] == UNSEEN: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> dist = self.distance(row1, col1, row, col) <MASK> min_dist = dist <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> closest_unseen = (row, col) <TAB> return closest_unseen",if dist < min_dist :,174
73,"def _maybe_has_default_route(self): <TAB> for route in self.iter_routes(): <MASK> return True <TAB> for iface in self.iter_interfaces(): <TAB>  <TAB> for subnet in iface.get(""subnets"", []): <TAB>  <TAB>  <TAB> for route in subnet.get(""routes"", []): <TAB>  <TAB>  <TAB>  <TAB> if self._is_default_route(route): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if self . _is_default_route ( route ) :,113
74,"def data(self, data): <TAB> if data is None: <TAB>  <TAB> raise Exception(""Data cannot be None"") <TAB> val = [] <TAB> for d in data: <TAB>  <TAB> if isinstance(d, str): <TAB>  <TAB>  <TAB> val.append(bytes(d, ""utf-8"")) <MASK> val.append(d) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> ""Invalid type, data can only be an str or a bytes not {}: {}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> type(data), d <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> self.__data = val","elif isinstance ( d , bytes ) :",149
75,"def get_one_segment_function(data, context, echoerr): <TAB> ext = data[""ext""] <TAB> function_name = context[-2][1].get(""function"") <TAB> if function_name: <TAB>  <TAB> module, function_name = get_function_strings(function_name, context, ext) <TAB>  <TAB> func = import_segment(function_name, data, context, echoerr, module=module) <MASK> yield func",if func :,107
76,"def generic_visit(self, node, parents=None): <TAB> parents = (parents or []) + [node] <TAB> for field, value in iter_fields(node): <TAB>  <TAB> if isinstance(value, list): <TAB>  <TAB>  <TAB> for item in value: <MASK> self.visit(item, parents) <TAB>  <TAB> elif isinstance(value, AST): <TAB>  <TAB>  <TAB> self.visit(value, parents)","if isinstance ( item , AST ) :",106
77,"def find_scintilla_constants(f): <TAB> lexers = [] <TAB> states = [] <TAB> for name in f.order: <TAB>  <TAB> v = f.features[name] <MASK> if v[""FeatureType""] == ""val"": <TAB>  <TAB>  <TAB>  <TAB> if name.startswith(""SCE_""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> states.append((name, v[""Value""])) <TAB>  <TAB>  <TAB>  <TAB> elif name.startswith(""SCLEX_""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> lexers.append((name, v[""Value""])) <TAB> return (lexers, states)","if v [ ""Category"" ] != ""Deprecated"" :",137
78,"def things(self, query): <TAB> limit = query.pop(""limit"", 100) <TAB> offset = query.pop(""offset"", 0) <TAB> keys = set(self.docs) <TAB> for k, v in query.items(): <MASK> # query keys need to be flattened properly, <TAB>  <TAB>  <TAB> # this corrects any nested keys that have been included <TAB>  <TAB>  <TAB> # in values. <TAB>  <TAB>  <TAB> flat = common.flatten_dict(v)[0] <TAB>  <TAB>  <TAB> k += ""."" + web.rstrips(flat[0], "".key"") <TAB>  <TAB>  <TAB> v = flat[1] <TAB>  <TAB> keys = set(k for k in self.filter_index(self.index, k, v) if k in keys) <TAB> keys = sorted(keys) <TAB> return keys[offset : offset + limit]","if isinstance ( v , dict ) :",194
79,"def del_(self, key): <TAB> initial_hash = hash_ = self.hash(key) <TAB> while True: <TAB>  <TAB> if self._keys[hash_] is self._empty: <TAB>  <TAB>  <TAB> # That key was never assigned <TAB>  <TAB>  <TAB> return None <MASK> # key found, assign with deleted sentinel <TAB>  <TAB>  <TAB> self._keys[hash_] = self._deleted <TAB>  <TAB>  <TAB> self._values[hash_] = self._deleted <TAB>  <TAB>  <TAB> self._len -= 1 <TAB>  <TAB>  <TAB> return <TAB>  <TAB> hash_ = self._rehash(hash_) <TAB>  <TAB> if initial_hash == hash_: <TAB>  <TAB>  <TAB> # table is full and wrapped around <TAB>  <TAB>  <TAB> return None",elif self . _keys [ hash_ ] == key :,166
80,"def test_204_invalid_content_length(self): <TAB> # 204 status with non-zero content length is malformed <TAB> with ExpectLog(gen_log, "".*Response with code 204 should not have body""): <TAB>  <TAB> response = self.fetch(""/?error=1"") <MASK> self.skipTest(""requires HTTP/1.x"") <TAB>  <TAB> if self.http_client.configured_class != SimpleAsyncHTTPClient: <TAB>  <TAB>  <TAB> self.skipTest(""curl client accepts invalid headers"") <TAB>  <TAB> self.assertEqual(response.code, 599)",if not self . http1 :,136
81,"def __str__(self) -> str: <TAB> text = ""\n"" <TAB> for k, r in self.result.items(): <TAB>  <TAB> text += ""{}\n"".format(""#"" * 40) <MASK> text += ""# {} (failed)\n"".format(k) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> text += ""# {} (succeeded)\n"".format(k) <TAB>  <TAB> text += ""{}\n"".format(""#"" * 40) <TAB>  <TAB> for sub_r in r: <TAB>  <TAB>  <TAB> text += ""**** {}\n"".format(sub_r.name) <TAB>  <TAB>  <TAB> text += ""{}\n"".format(sub_r) <TAB> return text",if r . failed :,153
82,"def DeleteTask(): <TAB> oid = request.form.get(""oid"", """") <TAB> if oid: <TAB>  <TAB> result = Mongo.coll[""Task""].delete_one({""_id"": ObjectId(oid)}) <MASK> result = Mongo.coll[""Result""].delete_many({""task_id"": ObjectId(oid)}) <TAB>  <TAB>  <TAB> if result: <TAB>  <TAB>  <TAB>  <TAB> return ""success"" <TAB> return ""fail""",if result . deleted_count > 0 :,108
83,"def _replace_vars(self, line, extracted, env_variables): <TAB> for e in extracted: <MASK> value = env_variables.get(e) <TAB>  <TAB>  <TAB> if isinstance(value, dict) or isinstance(value, list): <TAB>  <TAB>  <TAB>  <TAB> value = pprint.pformat(value) <TAB>  <TAB>  <TAB> decorated = self._decorate_var(e) <TAB>  <TAB>  <TAB> line = line.replace(decorated, str(value)) <TAB> return line",if e in env_variables :,113
84,"def should_include(service): <TAB> for f in filt: <TAB>  <TAB> if f == ""status"": <TAB>  <TAB>  <TAB> state = filt[f] <TAB>  <TAB>  <TAB> containers = project.containers([service.name], stopped=True) <TAB>  <TAB>  <TAB> if not has_container_with_state(containers, state): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> elif f == ""source"": <TAB>  <TAB>  <TAB> source = filt[f] <TAB>  <TAB>  <TAB> if source == ""image"" or source == ""build"": <MASK> return False <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise UserError(""Invalid value for source filter: %s"" % source) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise UserError(""Invalid filter: %s"" % f) <TAB> return True",if source not in service . options :,184
85,def state_callback_loop(): <TAB> if usercallback: <TAB>  <TAB> when = 1 <TAB>  <TAB> while ( <TAB>  <TAB>  <TAB> when <TAB>  <TAB>  <TAB> and not self.future_removed.done() <TAB>  <TAB>  <TAB> and not self.session.shutdownstarttime <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> result = usercallback(self.get_state()) <TAB>  <TAB>  <TAB> when = (await result) if iscoroutine(result) else result <MASK> await sleep(when),if when > 0.0 and not self . session . shutdownstarttime :,122
86,"def __get_new_timeout(self, timeout): <TAB> """"""When using --timeout_multiplier=#.#"""""" <TAB> self.__check_scope() <TAB> try: <TAB>  <TAB> timeout_multiplier = float(self.timeout_multiplier) <MASK> timeout_multiplier = 0.5 <TAB>  <TAB> timeout = int(math.ceil(timeout_multiplier * timeout)) <TAB>  <TAB> return timeout <TAB> except Exception: <TAB>  <TAB> # Wrong data type for timeout_multiplier (expecting int or float) <TAB>  <TAB> return timeout",if timeout_multiplier <= 0.5 :,126
87,"def readexactly(self, n): <TAB> buf = b"""" <TAB> while n: <TAB>  <TAB> yield IORead(self.s) <TAB>  <TAB> res = self.s.read(n) <TAB>  <TAB> assert res is not None <MASK> yield IOReadDone(self.s) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> buf += res <TAB>  <TAB> n -= len(res) <TAB> return buf",if not res :,99
88,"def contract_rendering_pane(event): <TAB> """"""Expand the rendering pane."""""" <TAB> c = event.get(""c"") <TAB> if c: <TAB>  <TAB> vr = c.frame.top.findChild(QtWidgets.QWidget, ""viewrendered_pane"") <MASK> vr.contract() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Just open the pane. <TAB>  <TAB>  <TAB> viewrendered(event)",if vr :,103
89,"def translate_headers(self, environ): <TAB> """"""Translate CGI-environ header names to HTTP header names."""""" <TAB> for cgiName in environ: <TAB>  <TAB> # We assume all incoming header keys are uppercase already. <MASK> yield self.headerNames[cgiName], environ[cgiName] <TAB>  <TAB> elif cgiName[:5] == ""HTTP_"": <TAB>  <TAB>  <TAB> # Hackish attempt at recovering original header names. <TAB>  <TAB>  <TAB> translatedHeader = cgiName[5:].replace(""_"", ""-"") <TAB>  <TAB>  <TAB> yield translatedHeader, environ[cgiName]",if cgiName in self . headerNames :,134
90,"def get_value_from_string(self, string_value): <TAB> """"""Return internal representation starting from CFN/user-input value."""""" <TAB> param_value = self.get_default_value() <TAB> try: <MASK> string_value = str(string_value).strip() <TAB>  <TAB>  <TAB> if string_value != ""NONE"": <TAB>  <TAB>  <TAB>  <TAB> param_value = int(string_value) <TAB> except ValueError: <TAB>  <TAB> self.pcluster_config.warn( <TAB>  <TAB>  <TAB> ""Unable to convert the value '{0}' to an Integer. "" <TAB>  <TAB>  <TAB> ""Using default value for parameter '{1}'"".format(string_value, self.key) <TAB>  <TAB> ) <TAB> return param_value",if string_value is not None :,172
91,"def monitor_filter(self): <TAB> """"""Return filtered service objects list"""""" <TAB> services = self.client.services.list(filters={""label"": ""com.ouroboros.enable""}) <TAB> monitored_services = [] <TAB> for service in services: <TAB>  <TAB> ouro_label = service.attrs[""Spec""][""Labels""].get(""com.ouroboros.enable"") <MASK> monitored_services.append(service) <TAB> self.data_manager.monitored_containers[self.socket] = len(monitored_services) <TAB> self.data_manager.set(self.socket) <TAB> return monitored_services","if not self . config . label_enable or ouro_label . lower ( ) in [ ""true"" , ""yes"" ] :",176
92,"def nextEditable(self): <TAB> """"""Moves focus of the cursor to the next editable window"""""" <TAB> if self.currentEditable is None: <TAB>  <TAB> if len(self._editableChildren): <TAB>  <TAB>  <TAB> self._currentEditableRef = self._editableChildren[0] <TAB> else: <TAB>  <TAB> for ref in weakref.getweakrefs(self.currentEditable): <TAB>  <TAB>  <TAB> if ref in self._editableChildren: <TAB>  <TAB>  <TAB>  <TAB> cei = self._editableChildren.index(ref) <TAB>  <TAB>  <TAB>  <TAB> nei = cei + 1 <MASK> nei = 0 <TAB>  <TAB>  <TAB>  <TAB> self._currentEditableRef = self._editableChildren[nei] <TAB> return self.currentEditable",if nei >= len ( self . _editableChildren ) :,179
93,"def linkify_cm_by_tp(self, timeperiods): <TAB> for rm in self: <TAB>  <TAB> mtp_name = rm.modulation_period.strip() <TAB>  <TAB> # The new member list, in id <TAB>  <TAB> mtp = timeperiods.find_by_name(mtp_name) <MASK> err = ( <TAB>  <TAB>  <TAB>  <TAB> ""Error: the business impact modulation '%s' got an unknown "" <TAB>  <TAB>  <TAB>  <TAB> ""modulation_period '%s'"" % (rm.get_name(), mtp_name) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> rm.configuration_errors.append(err) <TAB>  <TAB> rm.modulation_period = mtp","if mtp_name != """" and mtp is None :",169
94,def close_open_fds(keep=None):  # noqa <TAB> keep = [maybe_fileno(f) for f in (keep or []) if maybe_fileno(f) is not None] <TAB> for fd in reversed(range(get_fdmax(default=2048))): <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> os.close(fd) <TAB>  <TAB>  <TAB> except OSError as exc: <TAB>  <TAB>  <TAB>  <TAB> if exc.errno != errno.EBADF: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise,if fd not in keep :,120
95,"def _append_child_from_unparsed_xml(father_node, unparsed_xml): <TAB> """"""Append child xml nodes to a node."""""" <TAB> dom_tree = parseString(unparsed_xml) <TAB> if dom_tree.hasChildNodes(): <TAB>  <TAB> first_child = dom_tree.childNodes[0] <MASK> child_nodes = first_child.childNodes <TAB>  <TAB>  <TAB> for _ in range(len(child_nodes)): <TAB>  <TAB>  <TAB>  <TAB> childNode = child_nodes.item(0) <TAB>  <TAB>  <TAB>  <TAB> father_node.appendChild(childNode) <TAB>  <TAB>  <TAB> return <TAB> raise DistutilsInternalError( <TAB>  <TAB> ""Could not Append append elements to "" ""the Windows msi descriptor."" <TAB> )",if first_child . hasChildNodes ( ) :,178
96,"def process_request(self, request): <TAB> for old, new in self.names_name: <TAB>  <TAB> request.uri = request.uri.replace(old, new) <MASK> body = six.ensure_str(request.body) <TAB>  <TAB>  <TAB> if old in body: <TAB>  <TAB>  <TAB>  <TAB> request.body = body.replace(old, new) <TAB> return request",if is_text_payload ( request ) and request . body :,103
97,"def __init__(self, **options): <TAB> self.func_name_highlighting = get_bool_opt(options, ""func_name_highlighting"", True) <TAB> self.disabled_modules = get_list_opt(options, ""disabled_modules"", []) <TAB> self._functions = set() <TAB> if self.func_name_highlighting: <TAB>  <TAB> from pygments.lexers._luabuiltins import MODULES <TAB>  <TAB> for mod, func in MODULES.iteritems(): <MASK> self._functions.update(func) <TAB> RegexLexer.__init__(self, **options)",if mod not in self . disabled_modules :,153
98,"def GetBestSizeForParentSize(self, parentSize): <TAB> """"""Finds the best width and height given the parent's width and height."""""" <TAB> if len(self.GetChildren()) == 1: <TAB>  <TAB> win = self.GetChildren()[0] <MASK> temp_dc = wx.ClientDC(self) <TAB>  <TAB>  <TAB> childSize = win.GetBestSizeForParentSize(parentSize) <TAB>  <TAB>  <TAB> clientParentSize = self._art.GetPanelClientSize( <TAB>  <TAB>  <TAB>  <TAB> temp_dc, self, wx.Size(*parentSize), None <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> overallSize = self._art.GetPanelSize( <TAB>  <TAB>  <TAB>  <TAB> temp_dc, self, wx.Size(*clientParentSize), None <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return overallSize <TAB> return self.GetSize()","if isinstance ( win , RibbonControl ) :",199
99,"def pid_from_name(name): <TAB> processes = [] <TAB> for pid in os.listdir(""/proc""): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> pid = int(pid) <TAB>  <TAB>  <TAB> pname, cmdline = SunProcess._name_args(pid) <MASK> return pid <TAB>  <TAB>  <TAB> if name in cmdline.split("" "", 1)[0]: <TAB>  <TAB>  <TAB>  <TAB> return pid <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> pass <TAB> raise ProcessException(""No process with such name: %s"" % name)",if name in pname :,126
100,"def __get_file_by_num(self, num, file_list, idx=0): <TAB> for element in file_list: <TAB>  <TAB> if idx == num: <TAB>  <TAB>  <TAB> return element <MASK> i = self.__get_file_by_num(num, element[3], idx + 1) <TAB>  <TAB>  <TAB> if not isinstance(i, int): <TAB>  <TAB>  <TAB>  <TAB> return i <TAB>  <TAB>  <TAB> idx = i <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> idx += 1 <TAB> return idx",if element [ 3 ] and element [ 4 ] :,127
101,"def scan_block_scalar_indentation(self): <TAB> # See the specification for details. <TAB> chunks = [] <TAB> max_indent = 0 <TAB> end_mark = self.get_mark() <TAB> while self.peek() in "" \r\n\x85\u2028\u2029"": <TAB>  <TAB> if self.peek() != "" "": <TAB>  <TAB>  <TAB> chunks.append(self.scan_line_break()) <TAB>  <TAB>  <TAB> end_mark = self.get_mark() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.forward() <MASK> max_indent = self.column <TAB> return chunks, max_indent, end_mark",if self . column > max_indent :,161
102,"def ant_map(m): <TAB> tmp = ""rows %s\ncols %s\n"" % (len(m), len(m[0])) <TAB> players = {} <TAB> for row in m: <TAB>  <TAB> tmp += ""m "" <TAB>  <TAB> for col in row: <TAB>  <TAB>  <TAB> if col == LAND: <TAB>  <TAB>  <TAB>  <TAB> tmp += ""."" <TAB>  <TAB>  <TAB> elif col == BARRIER: <TAB>  <TAB>  <TAB>  <TAB> tmp += ""%"" <MASK> tmp += ""*"" <TAB>  <TAB>  <TAB> elif col == UNSEEN: <TAB>  <TAB>  <TAB>  <TAB> tmp += ""?"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> players[col] = True <TAB>  <TAB>  <TAB>  <TAB> tmp += chr(col + 97) <TAB>  <TAB> tmp += ""\n"" <TAB> tmp = (""players %s\n"" % len(players)) + tmp <TAB> return tmp",elif col == FOOD :,199
103,"def prepare_data(entry): <TAB> branch_wise_entries = {} <TAB> gross_pay = 0 <TAB> for d in entry: <TAB>  <TAB> gross_pay += d.gross_pay <MASK> branch_wise_entries[d.branch][d.mode_of_payment] = d.net_pay <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> branch_wise_entries.setdefault(d.branch, {}).setdefault( <TAB>  <TAB>  <TAB>  <TAB> d.mode_of_payment, d.net_pay <TAB>  <TAB>  <TAB> ) <TAB> return branch_wise_entries, gross_pay",if branch_wise_entries . get ( d . branch ) :,146
104,"def __init__(self, uuid=None, cluster_state=None, children=None, **kwargs): <TAB> self.uuid = uuid <TAB> self.cluster_state = cluster_state <TAB> if self.cluster_state is not None: <TAB>  <TAB> self.children = WeakSet( <TAB>  <TAB>  <TAB> self.cluster_state.tasks.get(task_id) <TAB>  <TAB>  <TAB> for task_id in children or () <MASK> ) <TAB> else: <TAB>  <TAB> self.children = WeakSet() <TAB> self._serializer_handlers = { <TAB>  <TAB> ""children"": self._serializable_children, <TAB>  <TAB> ""root"": self._serializable_root, <TAB>  <TAB> ""parent"": self._serializable_parent, <TAB> } <TAB> if kwargs: <TAB>  <TAB> self.__dict__.update(kwargs)",if task_id in self . cluster_state . tasks,192
105,"def listdir(self, d): <TAB> try: <TAB>  <TAB> return [ <TAB>  <TAB>  <TAB> p <TAB>  <TAB>  <TAB> for p in os.listdir(d) <MASK> ] <TAB> except OSError: <TAB>  <TAB> return []","if os . path . basename ( p ) != ""CVS"" and os . path . isdir ( os . path . join ( d , p ) )",84
106,"def send_packed_command(self, command, check_health=True): <TAB> if not self._sock: <TAB>  <TAB> self.connect() <TAB> try: <MASK> command = [command] <TAB>  <TAB> for item in command: <TAB>  <TAB>  <TAB> self._sock.sendall(item) <TAB> except socket.error as e: <TAB>  <TAB> self.disconnect() <TAB>  <TAB> if len(e.args) == 1: <TAB>  <TAB>  <TAB> _errno, errmsg = ""UNKNOWN"", e.args[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _errno, errmsg = e.args <TAB>  <TAB> raise ConnectionError( <TAB>  <TAB>  <TAB> ""Error %s while writing to socket. %s."" % (_errno, errmsg) <TAB>  <TAB> ) <TAB> except Exception: <TAB>  <TAB> self.disconnect() <TAB>  <TAB> raise","if isinstance ( command , str ) :",188
107,"def run(self): <TAB> """"""Start the scanner"""""" <TAB> logging.info(""Dirscanner starting up"") <TAB> self.shutdown = False <TAB> while not self.shutdown: <TAB>  <TAB> # Wait to be woken up or triggered <TAB>  <TAB> with self.loop_condition: <TAB>  <TAB>  <TAB> self.loop_condition.wait(self.dirscan_speed) <MASK> self.scan()",if self . dirscan_speed and not self . shutdown :,104
108,"def __aexit__( <TAB> self, exc_type: type, exc_value: BaseException, tb: TracebackType) -> None: <TAB> if exc_type is not None: <TAB>  <TAB> await self.close() <TAB> await self._task <TAB> while not self._receive_queue.empty(): <TAB>  <TAB> data = await self._receive_queue.get() <TAB>  <TAB> if isinstance(data, bytes): <TAB>  <TAB>  <TAB> self.response_data.extend(data) <MASK> raise data","elif not isinstance ( data , HTTPDisconnect ) :",121
109,"def f(msg): <TAB> text = extractor(msg) <TAB> for px in prefix: <MASK> chunks = text[len(px) :].split(separator) <TAB>  <TAB>  <TAB> return chunks[0], (chunks[1:],) if pass_args else () <TAB> return ((None,),)  # to distinguish with `None`",if text . startswith ( px ) :,83
110,"def _flatten(*args): <TAB> ahs = set() <TAB> if len(args) > 0: <TAB>  <TAB> for item in args: <TAB>  <TAB>  <TAB> if type(item) is ActionHandle: <TAB>  <TAB>  <TAB>  <TAB> ahs.add(item) <MASK> for ah in item: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if type(ah) is not ActionHandle:  # pragma:nocover <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise ActionManagerError(""Bad argument type %s"" % str(ah)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ahs.add(ah) <TAB>  <TAB>  <TAB> else:  # pragma:nocover <TAB>  <TAB>  <TAB>  <TAB> raise ActionManagerError(""Bad argument type %s"" % str(item)) <TAB> return ahs","elif type ( item ) in ( list , tuple , dict , set ) :",183
111,"def find_class(self, module, name): <TAB> # Subclasses may override this. <TAB> sys.audit(""pickle.find_class"", module, name) <TAB> if self.proto < 3 and self.fix_imports: <TAB>  <TAB> if (module, name) in _compat_pickle.NAME_MAPPING: <TAB>  <TAB>  <TAB> module, name = _compat_pickle.NAME_MAPPING[(module, name)] <MASK> module = _compat_pickle.IMPORT_MAPPING[module] <TAB> __import__(module, level=0) <TAB> if self.proto >= 4: <TAB>  <TAB> return _getattribute(sys.modules[module], name)[0] <TAB> else: <TAB>  <TAB> return getattr(sys.modules[module], name)",elif module in _compat_pickle . IMPORT_MAPPING :,178
112,"def _send_until_done(self, data): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self.connection.send(data) <TAB>  <TAB> except OpenSSL.SSL.WantWriteError: <TAB>  <TAB>  <TAB> wr = util.wait_for_write(self.socket, self.socket.gettimeout()) <MASK> raise timeout() <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> except OpenSSL.SSL.SysCallError as e: <TAB>  <TAB>  <TAB> raise SocketError(str(e))",if not wr :,120
113,"def __new__(cls, *args, **kwargs): <TAB> """"""Hack to ensure method defined as async are implemented as such."""""" <TAB> coroutines = inspect.getmembers(BaseManager, predicate=inspect.iscoroutinefunction) <TAB> for coroutine in coroutines: <TAB>  <TAB> implemented_method = getattr(cls, coroutine[0]) <MASK> raise RuntimeError(""The method %s must be a coroutine"" % implemented_method) <TAB> return super().__new__(cls, *args, **kwargs)",if not inspect . iscoroutinefunction ( implemented_method ) :,120
114,"def add_directive(self, name, obj, content=None, arguments=None, **options): <TAB> if isinstance(obj, clstypes) and issubclass(obj, Directive): <MASK> raise ExtensionError( <TAB>  <TAB>  <TAB>  <TAB> ""when adding directive classes, no "" ""additional arguments may be given"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> directives.register_directive(name, directive_dwim(obj)) <TAB> else: <TAB>  <TAB> obj.content = content <TAB>  <TAB> obj.arguments = arguments <TAB>  <TAB> obj.options = options <TAB>  <TAB> directives.register_directive(name, obj)",if content or arguments or options :,144
115,"def create(self, w): <TAB> if w.use_eventloop: <TAB>  <TAB> # does not use dedicated timer thread. <TAB>  <TAB> w.timer = _Timer(max_interval=10.0) <TAB> else: <MASK> # Default Timer is set by the pool, as for example, the <TAB>  <TAB>  <TAB> # eventlet pool needs a custom timer implementation. <TAB>  <TAB>  <TAB> w.timer_cls = w.pool_cls.Timer <TAB>  <TAB> w.timer = self.instantiate( <TAB>  <TAB>  <TAB> w.timer_cls, <TAB>  <TAB>  <TAB> max_interval=w.timer_precision, <TAB>  <TAB>  <TAB> on_error=self.on_timer_error, <TAB>  <TAB>  <TAB> on_tick=self.on_timer_tick, <TAB>  <TAB> )",if not w . timer_cls :,182
116,"def _config(_molecule_file, request): <TAB> with open(_molecule_file) as f: <TAB>  <TAB> d = util.safe_load(f) <TAB> if hasattr(request, ""param""): <MASK> d2 = util.safe_load(request.getfixturevalue(request.param)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> d2 = request.getfixturevalue(request.param) <TAB>  <TAB> # print(100, d) <TAB>  <TAB> # print(200, d2) <TAB>  <TAB> d = util.merge_dicts(d, d2) <TAB>  <TAB> # print(300, d) <TAB> return d","if isinstance ( request . getfixturevalue ( request . param ) , str ) :",164
117,"def _instrument_model(self, model): <TAB> for key, value in list( <TAB>  <TAB> model.__dict__.items() <TAB> ):  # avoid ""dictionary keys changed during iteration"" <MASK> new_layer = self._instrument(value) <TAB>  <TAB>  <TAB> if new_layer is not value: <TAB>  <TAB>  <TAB>  <TAB> setattr(model, key, new_layer) <TAB>  <TAB> elif isinstance(value, list): <TAB>  <TAB>  <TAB> for i, item in enumerate(value): <TAB>  <TAB>  <TAB>  <TAB> if isinstance(item, tf.keras.layers.Layer): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value[i] = self._instrument(item) <TAB> return model","if isinstance ( value , tf . keras . layers . Layer ) :",164
118,"def is_accepted_drag_event(self, event): <TAB> if event.source() == self.table: <TAB>  <TAB> return True <TAB> mime = event.mimeData() <TAB> if mime.hasUrls(): <TAB>  <TAB> for url in mime.urls(): <TAB>  <TAB>  <TAB> # Only support local files. <MASK> break <TAB>  <TAB>  <TAB> # And only allow supported extensions. <TAB>  <TAB>  <TAB> filename = url.toLocalFile() <TAB>  <TAB>  <TAB> extension = os.path.splitext(filename)[1].lower()[1:] <TAB>  <TAB>  <TAB> if extension not in _dictionary_formats(): <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return True <TAB> return False",if not url . isLocalFile ( ) :,163
119,"def explain(self, other, depth=0): <TAB> exp = super(UnionType, self).explain(other, depth) <TAB> for ndx, subtype in enumerate(self.params[""allowed_types""]): <MASK> exp += ""\n{}and"".format("""".join([""\t""] * depth)) <TAB>  <TAB> exp += ""\n"" + subtype.explain(other, depth=depth + 1) <TAB> return exp",if ndx > 0 :,101
120,"def test_k_is_stochastic_parameter(self): <TAB> # k as stochastic parameter <TAB> aug = iaa.MedianBlur(k=iap.Choice([3, 5])) <TAB> seen = [False, False] <TAB> for i in sm.xrange(100): <TAB>  <TAB> observed = aug.augment_image(self.base_img) <TAB>  <TAB> if np.array_equal(observed, self.blur3x3): <TAB>  <TAB>  <TAB> seen[0] += True <MASK> seen[1] += True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception(""Unexpected result in MedianBlur@2"") <TAB>  <TAB> if all(seen): <TAB>  <TAB>  <TAB> break <TAB> assert np.all(seen)","elif np . array_equal ( observed , self . blur5x5 ) :",176
121,"def test_get_message(self): <TAB> async with self.chat_client: <TAB>  <TAB> await self._create_thread() <TAB>  <TAB> async with self.chat_thread_client: <TAB>  <TAB>  <TAB> message_id = await self._send_message() <TAB>  <TAB>  <TAB> message = await self.chat_thread_client.get_message(message_id) <TAB>  <TAB>  <TAB> assert message.id == message_id <TAB>  <TAB>  <TAB> assert message.type == ChatMessageType.TEXT <TAB>  <TAB>  <TAB> assert message.content.message == ""hello world"" <TAB>  <TAB> # delete chat threads <MASK> await self.chat_client.delete_chat_thread(self.thread_id)",if not self . is_playback ( ) :,163
122,"def do_write_property(self, device, callback=None): <TAB> try: <TAB>  <TAB> iocb = ( <TAB>  <TAB>  <TAB> device <MASK> else self.form_iocb(device, request_type=""writeProperty"") <TAB>  <TAB> ) <TAB>  <TAB> deferred(self.request_io, iocb) <TAB>  <TAB> self.requests_in_progress.update({iocb: {""callback"": callback}}) <TAB>  <TAB> iocb.add_callback(self.__general_cb) <TAB> except Exception as error: <TAB>  <TAB> log.exception(""exception: %r"", error)","if isinstance ( device , IOCB )",146
123,"def fit(self, dataset, force_retrain): <TAB> if force_retrain: <TAB>  <TAB> self.sub_unit_1[""fitted""] = True <TAB>  <TAB> self.sub_unit_1[""calls""] += 1 <TAB>  <TAB> self.sub_unit_2[""fitted""] = True <TAB>  <TAB> self.sub_unit_2[""calls""] += 1 <TAB> else: <TAB>  <TAB> if not self.sub_unit_1[""fitted""]: <TAB>  <TAB>  <TAB> self.sub_unit_1[""fitted""] = True <TAB>  <TAB>  <TAB> self.sub_unit_1[""calls""] += 1 <MASK> self.sub_unit_2[""fitted""] = True <TAB>  <TAB>  <TAB> self.sub_unit_2[""calls""] += 1 <TAB> return self","if not self . sub_unit_2 [ ""fitted"" ] :",183
124,"def _insert_with_loop(self): <TAB> id_list = [] <TAB> last_id = None <TAB> return_id_list = self._return_id_list <TAB> for row in self._rows: <TAB>  <TAB> last_id = InsertQuery(self.model_class, row).upsert(self._upsert).execute() <MASK> id_list.append(last_id) <TAB> if return_id_list: <TAB>  <TAB> return id_list <TAB> else: <TAB>  <TAB> return last_id",if return_id_list :,126
125,"def merge_block(self): <TAB> """"""merges a block in the map"""""" <TAB> for i in range(self.block.x): <TAB>  <TAB> for j in range(self.block.x): <TAB>  <TAB>  <TAB> c = self.block.get(i, j) <MASK> self.map[(i + self.block.pos.x, j + self.block.pos.y)] = c",if c :,99
126,"def configure_plex(config): <TAB> core.PLEX_SSL = int(config[""Plex""][""plex_ssl""]) <TAB> core.PLEX_HOST = config[""Plex""][""plex_host""] <TAB> core.PLEX_PORT = config[""Plex""][""plex_port""] <TAB> core.PLEX_TOKEN = config[""Plex""][""plex_token""] <TAB> plex_section = config[""Plex""][""plex_sections""] or [] <TAB> if plex_section: <MASK> plex_section = "","".join(plex_section)  # fix in case this imported as list. <TAB>  <TAB> plex_section = [tuple(item.split("","")) for item in plex_section.split(""|"")] <TAB> core.PLEX_SECTION = plex_section","if isinstance ( plex_section , list ) :",182
127,"def select(self): <TAB> e = xlib.XEvent() <TAB> while xlib.XPending(self._display): <TAB>  <TAB> xlib.XNextEvent(self._display, e) <TAB>  <TAB> # Key events are filtered by the xlib window event <TAB>  <TAB> # handler so they get a shot at the prefiltered event. <MASK> if xlib.XFilterEvent(e, e.xany.window): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> dispatch = self._window_map[e.xany.window] <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> dispatch(e)","if e . xany . type not in ( xlib . KeyPress , xlib . KeyRelease ) :",171
128,"def format_message(self): <TAB> bits = [self.message] <TAB> if self.possibilities: <MASK> bits.append(""Did you mean %s?"" % self.possibilities[0]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> possibilities = sorted(self.possibilities) <TAB>  <TAB>  <TAB> bits.append(""(Possible options: %s)"" % "", "".join(possibilities)) <TAB> return ""  "".join(bits)",if len ( self . possibilities ) == 1 :,106
129,"def _collect_logs(model): <TAB> page_token = None <TAB> all_logs = [] <TAB> while True: <TAB>  <TAB> paginated_logs = model.lookup_logs(now, later, page_token=page_token) <TAB>  <TAB> page_token = paginated_logs.next_page_token <TAB>  <TAB> all_logs.extend(paginated_logs.logs) <MASK> break <TAB> return all_logs",if page_token is None :,105
130,"def run(self): <TAB> while True: <TAB>  <TAB> context_id_list_tuple = self._inflated_addresses.get(block=True) <MASK> break <TAB>  <TAB> c_id, inflated_address_list = context_id_list_tuple <TAB>  <TAB> inflated_value_map = dict(inflated_address_list) <TAB>  <TAB> if c_id in self._contexts: <TAB>  <TAB>  <TAB> self._contexts[c_id].set_from_tree(inflated_value_map)",if context_id_list_tuple is _SHUTDOWN_SENTINEL :,135
131,"def _setup_prefix(self): <TAB> # we assume here that our metadata may be nested inside a ""basket"" <TAB> # of multiple eggs; that's why we use module_path instead of .archive <TAB> path = self.module_path <TAB> old = None <TAB> while path != old: <MASK> self.egg_name = os.path.basename(path) <TAB>  <TAB>  <TAB> self.egg_info = os.path.join(path, ""EGG-INFO"") <TAB>  <TAB>  <TAB> self.egg_root = path <TAB>  <TAB>  <TAB> break <TAB>  <TAB> old = path <TAB>  <TAB> path, base = os.path.split(path)","if path . lower ( ) . endswith ( "".egg"" ) :",160
132,"def get_filename(self, prompt): <TAB> okay = False <TAB> val = """" <TAB> while not okay: <TAB>  <TAB> val = raw_input(""%s: %s"" % (prompt, val)) <TAB>  <TAB> val = os.path.expanduser(val) <TAB>  <TAB> if os.path.isfile(val): <TAB>  <TAB>  <TAB> okay = True <MASK> path = val <TAB>  <TAB>  <TAB> val = self.choose_from_list(os.listdir(path)) <TAB>  <TAB>  <TAB> if val: <TAB>  <TAB>  <TAB>  <TAB> val = os.path.join(path, val) <TAB>  <TAB>  <TAB>  <TAB> okay = True <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> val = """" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""Invalid value: %s"" % val) <TAB>  <TAB>  <TAB> val = """" <TAB> return val",elif os . path . isdir ( val ) :,194
133,"def versions(self, sitename, data): <TAB> # handle the query of type {""query"": '{""key"": ""/books/ia:foo00bar"", ...}} <TAB> if ""query"" in data: <TAB>  <TAB> q = json.loads(data[""query""]) <TAB>  <TAB> itemid = self._get_itemid(q.get(""key"")) <MASK> key = q[""key""] <TAB>  <TAB>  <TAB> return json.dumps([self.dummy_edit(key)]) <TAB> # if not just go the default way <TAB> return ConnectionMiddleware.versions(self, sitename, data)",if itemid :,133
134,"def read_stanza(self): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> stanza_end = self._buffer.index(b""\n"") <TAB>  <TAB>  <TAB> stanza = self.decoder.decode(self._buffer[:stanza_end]) <TAB>  <TAB>  <TAB> self._buffer = self._buffer[stanza_end + 1 :] <TAB>  <TAB>  <TAB> colon = stanza.index("":"") <TAB>  <TAB>  <TAB> return stanza[:colon], stanza[colon + 1 :] <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> bytes = self.read_bytes() <MASK> return None <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._buffer += bytes",if not bytes :,164
135,def decodeattrs(attrs): <TAB> names = [] <TAB> for bit in range(16): <TAB>  <TAB> mask = 1 << bit <MASK> if attrnames.has_key(mask): <TAB>  <TAB>  <TAB>  <TAB> names.append(attrnames[mask]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> names.append(hex(mask)) <TAB> return names,if attrs & mask :,88
136,"def _set_http_cookie(): <TAB> if conf.cookie: <MASK> conf.http_headers[HTTP_HEADER.COOKIE] = ""; "".join( <TAB>  <TAB>  <TAB>  <TAB> map(lambda x: ""="".join(x), conf.cookie.items()) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> conf.http_headers[HTTP_HEADER.COOKIE] = conf.cookie","if isinstance ( conf . cookie , dict ) :",101
137,"def __ne__(self, other): <TAB> if isinstance(other, WeakMethod): <MASK> return self is not other <TAB>  <TAB> return weakref.ref.__ne__(self, other) or self._func_ref != other._func_ref <TAB> return True",if not self . _alive or not other . _alive :,72
138,"def update_unread(self, order_id, reset=False): <TAB> conn = Database.connect_database(self.PATH) <TAB> with conn: <TAB>  <TAB> cursor = conn.cursor() <MASK> cursor.execute( <TAB>  <TAB>  <TAB>  <TAB> """"""UPDATE sales SET unread = unread + 1 WHERE id=?;"""""", (order_id,) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> cursor.execute(""""""UPDATE sales SET unread=0 WHERE id=?;"""""", (order_id,)) <TAB>  <TAB> conn.commit() <TAB> conn.close()",if reset is False :,131
139,"def _get_field_value(self, test, key, match): <TAB> if test.ver == ofproto_v1_0.OFP_VERSION: <TAB>  <TAB> members = inspect.getmembers(match) <TAB>  <TAB> for member in members: <TAB>  <TAB>  <TAB> if member[0] == key: <TAB>  <TAB>  <TAB>  <TAB> field_value = member[1] <TAB>  <TAB>  <TAB> elif member[0] == ""wildcards"": <TAB>  <TAB>  <TAB>  <TAB> wildcards = member[1] <TAB>  <TAB> if key == ""nw_src"": <TAB>  <TAB>  <TAB> field_value = test.nw_src_to_str(wildcards, field_value) <MASK> field_value = test.nw_dst_to_str(wildcards, field_value) <TAB> else: <TAB>  <TAB> field_value = match[key] <TAB> return field_value","elif key == ""nw_dst"" :",200
140,"def nested_filter(self, items, mask): <TAB> keep_current = self.current_mask(mask) <TAB> keep_nested_lookup = self.nested_masks(mask) <TAB> for k, v in items: <TAB>  <TAB> keep_nested = keep_nested_lookup.get(k) <MASK> if keep_nested is not None: <TAB>  <TAB>  <TAB>  <TAB> if isinstance(v, dict): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield k, dict(self.nested_filter(v.items(), keep_nested)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield k, v",if k in keep_current :,142
141,"def goToPrevMarkedHeadline(self, event=None): <TAB> """"""Select the next marked node."""""" <TAB> c = self <TAB> p = c.p <TAB> if not p: <TAB>  <TAB> return <TAB> p.moveToThreadBack() <TAB> wrapped = False <TAB> while 1: <MASK> break <TAB>  <TAB> elif p: <TAB>  <TAB>  <TAB> p.moveToThreadBack() <TAB>  <TAB> elif wrapped: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> wrapped = True <TAB>  <TAB>  <TAB> p = c.rootPosition() <TAB> if not p: <TAB>  <TAB> g.blue(""done"") <TAB> c.treeSelectHelper(p)  # Sets focus.",if p and p . isMarked ( ) :,164
142,"def sample(self, **config): <TAB> """"""Sample a configuration from this search space."""""" <TAB> ret = {} <TAB> ret.update(self.data) <TAB> kwspaces = self.kwspaces <TAB> kwspaces.update(config) <TAB> striped_keys = [k.split(SPLITTER)[0] for k in config.keys()] <TAB> for k, v in kwspaces.items(): <MASK> if isinstance(v, NestedSpace): <TAB>  <TAB>  <TAB>  <TAB> sub_config = _strip_config_space(config, prefix=k) <TAB>  <TAB>  <TAB>  <TAB> ret[k] = v.sample(**sub_config) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> ret[k] = v <TAB> return ret",if k in striped_keys :,172
143,"def update_gradients_full(self, dL_dK, X, X2=None): <TAB> if self.ARD: <TAB>  <TAB> phi1 = self.phi(X) <MASK> self.variance.gradient = np.einsum(""ij,iq,jq->q"", dL_dK, phi1, phi1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> phi2 = self.phi(X2) <TAB>  <TAB>  <TAB> self.variance.gradient = np.einsum(""ij,iq,jq->q"", dL_dK, phi1, phi2) <TAB> else: <TAB>  <TAB> self.variance.gradient = np.einsum(""ij,ij"", dL_dK, self._K(X, X2)) * self.beta",if X2 is None or X is X2 :,185
144,"def post(self): <TAB> host_json = json.loads(request.data) <TAB> host_os = host_json.get(""os"") <TAB> if host_os: <TAB>  <TAB> result = get_monkey_executable(host_os.get(""type""), host_os.get(""machine"")) <TAB>  <TAB> if result: <TAB>  <TAB>  <TAB> # change resulting from new base path <TAB>  <TAB>  <TAB> executable_filename = result[""filename""] <TAB>  <TAB>  <TAB> real_path = MonkeyDownload.get_executable_full_path(executable_filename) <MASK> result[""size""] = os.path.getsize(real_path) <TAB>  <TAB>  <TAB>  <TAB> return result <TAB> return {}",if os . path . isfile ( real_path ) :,167
145,"def _encode_data( <TAB> self, <TAB> data, <TAB> content_type,): <TAB> if content_type is MULTIPART_CONTENT: <TAB>  <TAB> return encode_multipart(BOUNDARY, data) <TAB> else: <TAB>  <TAB> # Encode the content so that the byte representation is correct. <TAB>  <TAB> match = CONTENT_TYPE_RE.match(content_type) <MASK> charset = match.group(1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> charset = settings.DEFAULT_CHARSET <TAB>  <TAB> return force_bytes(data, encoding=charset)",if match :,130
146,"def _merge_scientific_float_tokens(tokens: Iterable[str]) -> List[str]: <TAB> tokens = list(tokens) <TAB> i = 0 <TAB> while ""e"" in tokens[i + 1 :]: <TAB>  <TAB> i = tokens.index(""e"", i + 1) <TAB>  <TAB> s = i - 1 <TAB>  <TAB> e = i + 1 <TAB>  <TAB> if not re.match(""[0-9]"", str(tokens[s])): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if re.match(""[+-]"", str(tokens[e])): <TAB>  <TAB>  <TAB> e += 1 <MASK> e += 1 <TAB>  <TAB>  <TAB> tokens[s:e] = ["""".join(tokens[s:e])] <TAB>  <TAB>  <TAB> i -= 1 <TAB> return tokens","if re . match ( ""[0-9]"" , str ( tokens [ e ] ) ) :",184
147,"def convert_with_key(self, key, value, replace=True): <TAB> result = self.configurator.convert(value) <TAB> # If the converted value is different, save for next time <TAB> if value is not result: <MASK> self[key] = result <TAB>  <TAB> if type(result) in (ConvertingDict, ConvertingList, ConvertingTuple): <TAB>  <TAB>  <TAB> result.parent = self <TAB>  <TAB>  <TAB> result.key = key <TAB> return result",if replace :,111
148,"def OnListEndLabelEdit(self, std, extra): <TAB> item = extra[0] <TAB> text = item[4] <TAB> if text is None: <TAB>  <TAB> return <TAB> item_id = self.GetItem(item[0])[6] <TAB> from bdb import Breakpoint <TAB> for bplist in Breakpoint.bplist.itervalues(): <TAB>  <TAB> for bp in bplist: <MASK> if text.strip().lower() == ""none"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> text = None <TAB>  <TAB>  <TAB>  <TAB> bp.cond = text <TAB>  <TAB>  <TAB>  <TAB> break <TAB> self.RespondDebuggerData()",if id ( bp ) == item_id :,151
149,"def add(self, url: str, future_nzo: NzbObject, when: Optional[int] = None): <TAB> """"""Add an URL to the URLGrabber queue, 'when' is seconds from now"""""" <TAB> if future_nzo and when: <TAB>  <TAB> # Always increase counter <TAB>  <TAB> future_nzo.url_tries += 1 <TAB>  <TAB> # Too many tries? Cancel <MASK> self.fail_to_history(future_nzo, url, T(""Maximum retries"")) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> future_nzo.url_wait = time.time() + when <TAB> self.queue.put((url, future_nzo))",if future_nzo . url_tries > cfg . max_url_retries ( ) :,172
150,def _is_datetime_string(series): <TAB> if series.dtype == object: <TAB>  <TAB> not_numeric = False <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> pd.to_numeric(series) <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> not_numeric = True <TAB>  <TAB> datetime_col = None <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> datetime_col = pd.to_datetime(series) <TAB>  <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> if datetime_col is not None: <TAB>  <TAB>  <TAB> return True <TAB> return False,if not_numeric :,138
151,"def _getEventAndObservers(self, event): <TAB> if isinstance(event, xpath.XPathQuery): <TAB>  <TAB> # Treat as xpath <TAB>  <TAB> observers = self._xpathObservers <TAB> else: <MASK> # Treat as event <TAB>  <TAB>  <TAB> observers = self._eventObservers <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Treat as xpath <TAB>  <TAB>  <TAB> event = xpath.internQuery(event) <TAB>  <TAB>  <TAB> observers = self._xpathObservers <TAB> return event, observers",if self . prefix == event [ : len ( self . prefix ) ] :,131
152,"def test_wildcard_import(): <TAB> bonobo = __import__(""bonobo"") <TAB> assert bonobo.__version__ <TAB> for name in dir(bonobo): <TAB>  <TAB> # ignore attributes starting by underscores <TAB>  <TAB> if name.startswith(""_""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> attr = getattr(bonobo, name) <MASK> continue <TAB>  <TAB> assert name in bonobo.__all__",if inspect . ismodule ( attr ) :,97
153,"def relint_views(wid=None): <TAB> windows = [sublime.Window(wid)] if wid else sublime.windows() <TAB> for window in windows: <TAB>  <TAB> for view in window.views(): <MASK> hit(view, ""relint_views"")",if view . buffer_id ( ) in persist . assigned_linters and view . is_primary ( ) :,93
154,def _check_for_unknown_gender(self): <TAB> if self.obj.get_gender() == Person.UNKNOWN: <TAB>  <TAB> d = GenderDialog(parent=self.window) <TAB>  <TAB> gender = d.run() <TAB>  <TAB> d.destroy() <MASK> self.obj.set_gender(gender),if gender >= 0 :,83
155,"def add_to_path(self, fnames): <TAB> """"""Add fnames to path"""""" <TAB> indexes = [] <TAB> for path in fnames: <TAB>  <TAB> project = self.get_source_project(path) <MASK> self.parent_widget.emit(SIGNAL(""pythonpath_changed()"")) <TAB>  <TAB>  <TAB> indexes.append(self.get_index(path)) <TAB> if indexes: <TAB>  <TAB> self.reset_icon_provider() <TAB>  <TAB> for index in indexes: <TAB>  <TAB>  <TAB> self.update(index)",if project . add_to_pythonpath ( path ) :,132
156,"def validate(self, value): <TAB> if value.grid_id is not None: <TAB>  <TAB> if not isinstance(value, self.proxy_class): <TAB>  <TAB>  <TAB> self.error(""FileField only accepts GridFSProxy values"") <MASK> self.error(""Invalid GridFSProxy value"")","if not isinstance ( value . grid_id , ObjectId ) :",82
157,"def shortcut(self, input, ch_out, stride, name, if_first=False): <TAB> ch_in = input.shape[1] <TAB> if ch_in != ch_out or stride != 1: <MASK> return self.conv_bn_layer(input, ch_out, 1, stride, name=name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.conv_bn_layer_new(input, ch_out, 1, stride, name=name) <TAB> else: <TAB>  <TAB> return input",if if_first :,127
158,"def convert_path(ctx, tpath): <TAB> for points, code in tpath.iter_segments(): <TAB>  <TAB> if code == Path.MOVETO: <TAB>  <TAB>  <TAB> ctx.move_to(*points) <TAB>  <TAB> elif code == Path.LINETO: <TAB>  <TAB>  <TAB> ctx.line_to(*points) <TAB>  <TAB> elif code == Path.CURVE3: <TAB>  <TAB>  <TAB> ctx.curve_to( <TAB>  <TAB>  <TAB>  <TAB> points[0], points[1], points[0], points[1], points[2], points[3] <TAB>  <TAB>  <TAB> ) <MASK> ctx.curve_to(*points) <TAB>  <TAB> elif code == Path.CLOSEPOLY: <TAB>  <TAB>  <TAB> ctx.close_path()",elif code == Path . CURVE4 :,172
159,"def _get_build_status(self, job_name, build_number): <TAB> try: <TAB>  <TAB> build_info = self.server.get_build_info(job_name, build_number) <MASK> return ""building"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""built"" <TAB> except jenkins.NotFoundException: <TAB>  <TAB> return ""not found""","if build_info [ ""building"" ] :",96
160,"def _parse_param_value(name, datatype, default): <TAB> if datatype == ""bool"": <TAB>  <TAB> if default.lower() == ""true"": <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> elif default.lower() == ""false"": <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _s = ""{}: Invalid default value '{}' for bool parameter {}"" <TAB>  <TAB>  <TAB> raise SyntaxError(_s.format(self.name, default, p)) <TAB> elif datatype == ""int"": <TAB>  <TAB> if type(default) == int: <TAB>  <TAB>  <TAB> return default <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return int(default, 0) <TAB> elif datatype == ""real"": <MASK> return default <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return float(default) <TAB> else: <TAB>  <TAB> return str(default)",if type ( default ) == float :,191
161,"def get_fills(self, exchange_order_id): <TAB> async with aiohttp.ClientSession() as client: <TAB>  <TAB> response: aiohttp.ClientResponse = await client.get( <TAB>  <TAB>  <TAB> f""{BASE_URL}{FILLS_ROUTE}"", <TAB>  <TAB>  <TAB> params={""orderId"": exchange_order_id, ""limit"": 100}, <TAB>  <TAB> ) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> msg = await response.json() <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> msg = await response.text() <TAB>  <TAB>  <TAB> raise DydxAsyncAPIError(response.status, msg) <TAB>  <TAB> return await response.json()",if response . status >= 300 :,156
162,"def semanticTags(self, semanticTags): <TAB> if semanticTags is None: <TAB>  <TAB> self.__semanticTags = OrderedDict() <TAB> # check <TAB> for key, value in list(semanticTags.items()): <TAB>  <TAB> if not isinstance(key, int): <TAB>  <TAB>  <TAB> raise TypeError(""At least one key is not a valid int position"") <TAB>  <TAB> if not isinstance(value, list): <TAB>  <TAB>  <TAB> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""At least one value of the provided dict is not a list of string"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> for x in value: <MASK> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""At least one value of the provided dict is not a list of string"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> self.__semanticTags = semanticTags","if not isinstance ( x , str ) :",184
163,"def start_cutting_tool(self, event, axis, direction): <TAB> toggle = event.EventObject <TAB> self.cutting = toggle.Value <TAB> if toggle.Value: <TAB>  <TAB> # Disable the other toggles <TAB>  <TAB> for child in self.cutsizer.Children: <TAB>  <TAB>  <TAB> child = child.Window <MASK> child.Value = False <TAB>  <TAB> self.cutting_axis = axis <TAB>  <TAB> self.cutting_direction = direction <TAB> else: <TAB>  <TAB> self.cutting_axis = None <TAB>  <TAB> self.cutting_direction = None <TAB> self.cutting_dist = None",if child != toggle :,150
164,"def decoration_helper(self, patched, args, keywargs): <TAB> extra_args = [] <TAB> with contextlib.ExitStack() as exit_stack: <TAB>  <TAB> for patching in patched.patchings: <TAB>  <TAB>  <TAB> arg = exit_stack.enter_context(patching) <TAB>  <TAB>  <TAB> if patching.attribute_name is not None: <TAB>  <TAB>  <TAB>  <TAB> keywargs.update(arg) <MASK> extra_args.append(arg) <TAB>  <TAB> args += tuple(extra_args) <TAB>  <TAB> yield (args, keywargs)",elif patching . new is DEFAULT :,134
165,def decodeattrs(attrs): <TAB> names = [] <TAB> for bit in range(16): <TAB>  <TAB> mask = 1 << bit <TAB>  <TAB> if attrs & mask: <MASK> names.append(attrnames[mask]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> names.append(hex(mask)) <TAB> return names,if attrnames . has_key ( mask ) :,88
166,"def pytest_collection_modifyitems(items): <TAB> for item in items: <TAB>  <TAB> if item.nodeid.startswith(""tests/params""): <TAB>  <TAB>  <TAB> if ""stage"" not in item.keywords: <TAB>  <TAB>  <TAB>  <TAB> item.add_marker(pytest.mark.stage(""unit"")) <MASK> item.add_marker(pytest.mark.init(rng_seed=123))","if ""init"" not in item . keywords :",102
167,"def handle_socket(self, request): <TAB> conn = request.connection <TAB> while True: <TAB>  <TAB> chunk = conn.recv(4) <MASK> break <TAB>  <TAB> slen = struct.unpack("">L"", chunk)[0] <TAB>  <TAB> chunk = conn.recv(slen) <TAB>  <TAB> while len(chunk) < slen: <TAB>  <TAB>  <TAB> chunk = chunk + conn.recv(slen - len(chunk)) <TAB>  <TAB> obj = pickle.loads(chunk) <TAB>  <TAB> record = logging.makeLogRecord(obj) <TAB>  <TAB> self.log_output += record.msg + ""\n"" <TAB>  <TAB> self.handled.release()",if len ( chunk ) < 4 :,156
168,"def on_source_foreach(self, model, path, iter, id): <TAB> m_id = model.get_value(iter, self.COLUMN_ID) <TAB> if m_id == id: <TAB>  <TAB> if self._foreach_mode == ""get"": <TAB>  <TAB>  <TAB> self._foreach_take = model.get_value(iter, self.COLUMN_ENABLED) <MASK> self._foreach_take = iter","elif self . _foreach_mode == ""set"" :",113
169,"def parts(): <TAB> for l in lists.leaves: <TAB>  <TAB> head_name = l.get_head_name() <TAB>  <TAB> if head_name == ""System`List"": <TAB>  <TAB>  <TAB> yield l.leaves <MASK> raise MessageException(""Catenate"", ""invrp"", l)","elif head_name != ""System`Missing"" :",78
170,"def __fill_counter_values(self, command: str): <TAB> result = [] <TAB> regex = r""(item[0-9]+\.counter_value)"" <TAB> for token in re.split(regex, command): <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> result.append(str(self.simulator_config.item_dict[token].value)) <TAB>  <TAB>  <TAB> except (KeyError, ValueError, AttributeError): <TAB>  <TAB>  <TAB>  <TAB> logger.error(""Could not get counter value for "" + token) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result.append(token) <TAB> return """".join(result)","if re . match ( regex , token ) is not None :",152
171,"def IMPORTFROM(self, node): <MASK> if not self.futuresAllowed: <TAB>  <TAB>  <TAB> self.report(messages.LateFutureImport, node, [n.name for n in node.names]) <TAB> else: <TAB>  <TAB> self.futuresAllowed = False <TAB> for alias in node.names: <TAB>  <TAB> if alias.name == ""*"": <TAB>  <TAB>  <TAB> self.scope.importStarred = True <TAB>  <TAB>  <TAB> self.report(messages.ImportStarUsed, node, node.module) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> name = alias.asname or alias.name <TAB>  <TAB> importation = Importation(name, node) <TAB>  <TAB> if node.module == ""__future__"": <TAB>  <TAB>  <TAB> importation.used = (self.scope, node) <TAB>  <TAB> self.addBinding(node, importation)","if node . module == ""__future__"" :",190
172,"def _split_batch_list(args, batch_list): <TAB> new_list = [] <TAB> for batch in batch_list.batches: <TAB>  <TAB> new_list.append(batch) <MASK> yield batch_pb2.BatchList(batches=new_list) <TAB>  <TAB>  <TAB> new_list = [] <TAB> if new_list: <TAB>  <TAB> yield batch_pb2.BatchList(batches=new_list)",if len ( new_list ) == args . batch_size_limit :,116
173,"def get_branch_or_use_upstream(branch_name, arg, repo): <TAB> if not branch_name:  # use upstream branch <TAB>  <TAB> current_b = repo.current_branch <TAB>  <TAB> upstream_b = current_b.upstream <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""No {0} branch specified and the current branch has no upstream "" <TAB>  <TAB>  <TAB>  <TAB> ""branch set"".format(arg) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ret = current_b.upstream <TAB> else: <TAB>  <TAB> ret = get_branch(branch_name, repo) <TAB> return ret",if not upstream_b :,148
174,"def __init__(self, **settings): <TAB> default_settings = self.get_default_settings() <TAB> for name, value in default_settings.items(): <MASK> setattr(self, name, value) <TAB> for name, value in settings.items(): <TAB>  <TAB> if name not in default_settings: <TAB>  <TAB>  <TAB> raise ImproperlyConfigured( <TAB>  <TAB>  <TAB>  <TAB> ""Invalid setting '{}' for {}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> name, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.__class__.__name__, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> setattr(self, name, value)","if not hasattr ( self , name ) :",144
175,"def _declare(self, name, obj, included=False, quals=0): <TAB> if name in self._declarations: <TAB>  <TAB> prevobj, prevquals = self._declarations[name] <TAB>  <TAB> if prevobj is obj and prevquals == quals: <TAB>  <TAB>  <TAB> return <MASK> raise api.FFIError( <TAB>  <TAB>  <TAB>  <TAB> ""multiple declarations of %s (for interactive usage, "" <TAB>  <TAB>  <TAB>  <TAB> ""try cdef(xx, override=True))"" % (name,) <TAB>  <TAB>  <TAB> ) <TAB> assert ""__dotdotdot__"" not in name.split() <TAB> self._declarations[name] = (obj, quals) <TAB> if included: <TAB>  <TAB> self._included_declarations.add(obj)",if not self . _override :,174
176,"def include_file(name, fdir=tmp_dir, b64=False): <TAB> try: <TAB>  <TAB> if fdir is None: <TAB>  <TAB>  <TAB> fdir = """" <MASK> with io.open(os.path.join(fdir, name), ""rb"") as f: <TAB>  <TAB>  <TAB>  <TAB> return base64.b64encode(f.read()).decode(""utf-8"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> with io.open(os.path.join(fdir, name), ""r"", encoding=""utf-8"") as f: <TAB>  <TAB>  <TAB>  <TAB> return f.read() <TAB> except (OSError, IOError) as e: <TAB>  <TAB> logger.error(""Could not include file '{}': {}"".format(name, e))",if b64 :,174
177,"def to_raw_json(self): <TAB> parts = {} <TAB> for p in self.parts: <MASK> parts[p[0]] = [] <TAB>  <TAB> parts[p[0]].append({""value"": p[2], ""parameters"": p[1]}) <TAB> children = [x.to_raw_json() for x in self.children] <TAB> return { <TAB>  <TAB> ""type"": self.__class__.__name__, <TAB>  <TAB> ""children"": children, <TAB>  <TAB> ""parts"": parts, <TAB> }",if p [ 0 ] not in parts :,127
178,"def process_output( <TAB> output: str, filename: str, start_line: int) -> Tuple[Optional[str], bool]: <TAB> error_found = False <TAB> for line in output.splitlines(): <TAB>  <TAB> t = get_revealed_type(line, filename, start_line) <MASK> return t, error_found <TAB>  <TAB> elif ""error:"" in line: <TAB>  <TAB>  <TAB> error_found = True <TAB> return None, True  # finding no reveal_type is an error",if t :,117
179,"def __init__( <TAB> self, resize_keyboard=None, one_time_keyboard=None, selective=None, row_width=3): <TAB> if row_width > self.max_row_keys: <TAB>  <TAB> # Todo: Will be replaced with Exception in future releases <MASK> logger.error( <TAB>  <TAB>  <TAB>  <TAB> ""Telegram does not support reply keyboard row width over %d."" <TAB>  <TAB>  <TAB>  <TAB> % self.max_row_keys <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> row_width = self.max_row_keys <TAB> self.resize_keyboard = resize_keyboard <TAB> self.one_time_keyboard = one_time_keyboard <TAB> self.selective = selective <TAB> self.row_width = row_width <TAB> self.keyboard = []",if not DISABLE_KEYLEN_ERROR :,188
180,"def realizeElementExpressions(innerElement): <TAB> elementHasBeenRealized = False <TAB> for exp in innerElement.expressions: <TAB>  <TAB> if not hasattr(exp, ""realize""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # else: <TAB>  <TAB> before, during, after = exp.realize(innerElement) <TAB>  <TAB> elementHasBeenRealized = True <TAB>  <TAB> for n in before: <TAB>  <TAB>  <TAB> newStream.append(n) <MASK> newStream.append(during) <TAB>  <TAB> for n in after: <TAB>  <TAB>  <TAB> newStream.append(n) <TAB> if elementHasBeenRealized is False: <TAB>  <TAB> newStream.append(innerElement)",if during is not None :,164
181,"def lex_number(self, pos): <TAB> # numeric literal <TAB> start = pos <TAB> found_dot = False <TAB> while pos < len(self.string) and ( <TAB>  <TAB> self.string[pos].isdigit() or self.string[pos] == ""."" <TAB> ): <MASK> if found_dot is True: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""Invalid number. Found multiple '.'"") <TAB>  <TAB>  <TAB> found_dot = True <TAB>  <TAB> # technically we allow more than one ""."" and let float()'s parsing <TAB>  <TAB> # complain later <TAB>  <TAB> pos += 1 <TAB> val = self.string[start:pos] <TAB> return Token(TokenType.LNUM, val, len(val))","if self . string [ pos ] == ""."" :",168
182,"def rename(src, dst): <TAB> # Try atomic or pseudo-atomic rename <TAB> if _rename(src, dst): <TAB>  <TAB> return <TAB> # Fall back to ""move away and replace"" <TAB> try: <TAB>  <TAB> os.rename(src, dst) <TAB> except OSError as e: <MASK> raise <TAB>  <TAB> old = ""%s-%08x"" % (dst, random.randint(0, sys.maxsize)) <TAB>  <TAB> os.rename(dst, old) <TAB>  <TAB> os.rename(src, dst) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> os.unlink(old) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> pass",if e . errno != errno . EEXIST :,156
183,"def _the_callback(widget, event_id): <TAB> point = widget.GetCenter() <TAB> index = widget.WIDGET_INDEX <TAB> if hasattr(callback, ""__call__""): <TAB>  <TAB> if num > 1: <TAB>  <TAB>  <TAB> args = [point, index] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> args = [point] <MASK> args.append(widget) <TAB>  <TAB> try_callback(callback, *args) <TAB> return",if pass_widget :,109
184,"def run(self): <TAB> for _ in range(self.n): <TAB>  <TAB> error = True <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.collection.insert_one({""test"": ""insert""}) <TAB>  <TAB>  <TAB> error = False <TAB>  <TAB> except: <MASK> raise <TAB>  <TAB> if self.expect_exception: <TAB>  <TAB>  <TAB> assert error",if not self . expect_exception :,91
185,"def handle(self, *args: Any, **options: Any) -> None: <TAB> realm = self.get_realm(options) <TAB> if options[""all""]: <MASK> raise CommandError( <TAB>  <TAB>  <TAB>  <TAB> ""You must specify a realm if you choose the --all option."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self.fix_all_users(realm) <TAB>  <TAB> return <TAB> self.fix_emails(realm, options[""emails""])",if realm is None :,108
186,"def recv_tdi(self, nbits, pos): <TAB> bits = 0 <TAB> for n in range(nbits * 2): <TAB>  <TAB> yield from self._wait_for_tck() <MASK> bits = (bits << 1) | (yield self.tdi.o) <TAB> return bits",if ( yield self . tck . o ) == pos :,86
187,"def _split_head(self): <TAB> if not hasattr(self, ""_severed_head""): <MASK> tree = self._tree.copy() <TAB>  <TAB>  <TAB> head = tree.get_heading_text() <TAB>  <TAB>  <TAB> tree.remove_heading() <TAB>  <TAB>  <TAB> self._severed_head = (head, tree) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._severed_head = (None, None) <TAB> return self._severed_head",if self . _tree :,113
188,"def buildSearchTrie(self, choices): <TAB> searchtrie = trie.Trie() <TAB> for choice in choices: <TAB>  <TAB> for token in self.tokenizeChoice(choice): <MASK> searchtrie[token] = [] <TAB>  <TAB>  <TAB> searchtrie[token].append(choice) <TAB> return searchtrie",if not searchtrie . has_key ( token ) :,85
189,"def format_sql(sql, params): <TAB> rv = [] <TAB> if isinstance(params, dict): <TAB>  <TAB> # convert sql with named parameters to sql with unnamed parameters <TAB>  <TAB> conv = _FormatConverter(params) <TAB>  <TAB> if params: <TAB>  <TAB>  <TAB> sql = sql_to_string(sql) <TAB>  <TAB>  <TAB> sql = sql % conv <TAB>  <TAB>  <TAB> params = conv.params <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> params = () <TAB> for param in params or (): <MASK> rv.append(""NULL"") <TAB>  <TAB> param = safe_repr(param) <TAB>  <TAB> rv.append(param) <TAB> return sql, rv",if param is None :,151
190,def on_completed2(): <TAB> doner[0] = True <TAB> if not qr: <TAB>  <TAB> if len(ql) > 0: <TAB>  <TAB>  <TAB> observer.on_next(False) <TAB>  <TAB>  <TAB> observer.on_completed() <MASK> observer.on_next(True) <TAB>  <TAB>  <TAB> observer.on_completed(),elif donel [ 0 ] :,86
191,"def notify_digest(self, frequency, changes): <TAB> notifications = defaultdict(list) <TAB> users = {} <TAB> for change in changes: <TAB>  <TAB> for user in self.get_users(frequency, change): <MASK> notifications[user.pk].append(change) <TAB>  <TAB>  <TAB>  <TAB> users[user.pk] = user <TAB> for user in users.values(): <TAB>  <TAB> self.send_digest( <TAB>  <TAB>  <TAB> user.profile.language, <TAB>  <TAB>  <TAB> user.email, <TAB>  <TAB>  <TAB> notifications[user.pk], <TAB>  <TAB>  <TAB> subscription=user.current_subscription, <TAB>  <TAB> )",if change . project is None or user . can_access_project ( change . project ) :,163
192,"def _any_listener_using(self, target_group_arn): <TAB> for load_balancer in self.load_balancers.values(): <TAB>  <TAB> for listener in load_balancer.listeners.values(): <TAB>  <TAB>  <TAB> for rule in listener.rules: <TAB>  <TAB>  <TAB>  <TAB> for action in rule.actions: <MASK> return True <TAB> return False","if action . data . get ( ""target_group_arn"" ) == target_group_arn :",110
193,"def train_dict(self, triples): <TAB> """"""Train a dict lemmatizer given training (word, pos, lemma) triples."""""" <TAB> # accumulate counter <TAB> ctr = Counter() <TAB> ctr.update([(p[0], p[1], p[2]) for p in triples]) <TAB> # find the most frequent mappings <TAB> for p, _ in ctr.most_common(): <TAB>  <TAB> w, pos, l = p <TAB>  <TAB> if (w, pos) not in self.composite_dict: <TAB>  <TAB>  <TAB> self.composite_dict[(w, pos)] = l <MASK> self.word_dict[w] = l <TAB> return",if w not in self . word_dict :,158
194,"def parse_git_config(path): <TAB> """"""Parse git config file."""""" <TAB> config = dict() <TAB> section = None <TAB> with open(os.path.join(path, ""config""), ""r"") as f: <TAB>  <TAB> for line in f: <TAB>  <TAB>  <TAB> line = line.strip() <MASK> section = line[1:-1].strip() <TAB>  <TAB>  <TAB>  <TAB> config[section] = dict() <TAB>  <TAB>  <TAB> elif section: <TAB>  <TAB>  <TAB>  <TAB> key, value = line.replace("" "", """").split(""="") <TAB>  <TAB>  <TAB>  <TAB> config[section][key] = value <TAB> return config","if line . startswith ( ""["" ) :",146
195,"def send_signal(self, pid, signum): <TAB> if pid in self.processes: <TAB>  <TAB> process = self.processes[pid] <TAB>  <TAB> hook_result = self.call_hook(""before_signal"", pid=pid, signum=signum) <MASK> logger.debug( <TAB>  <TAB>  <TAB>  <TAB> ""before_signal hook didn't return True "" <TAB>  <TAB>  <TAB>  <TAB> ""=> signal %i is not sent to %i"" % (signum, pid) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> process.send_signal(signum) <TAB>  <TAB> self.call_hook(""after_signal"", pid=pid, signum=signum) <TAB> else: <TAB>  <TAB> logger.debug(""process %s does not exist"" % pid)",if signum != signal . SIGKILL and not hook_result :,186
196,"def validate_pos_return(self): <TAB> if self.is_pos and self.is_return: <TAB>  <TAB> total_amount_in_payments = 0 <TAB>  <TAB> for payment in self.payments: <TAB>  <TAB>  <TAB> total_amount_in_payments += payment.amount <TAB>  <TAB> invoice_total = self.rounded_total or self.grand_total <MASK> frappe.throw( <TAB>  <TAB>  <TAB>  <TAB> _(""Total payments amount can't be greater than {}"").format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> -invoice_total <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> )",if total_amount_in_payments < invoice_total :,144
197,"def delete(key, inner_key=None): <TAB> if inner_key is not None: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> del cache[key][inner_key] <TAB>  <TAB>  <TAB> del use_count[key][inner_key] <MASK> del cache[key] <TAB>  <TAB>  <TAB>  <TAB> del use_count[key] <TAB>  <TAB>  <TAB> wrapper.cache_size -= 1 <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return True <TAB> else: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> wrapper.cache_size -= len(cache[key]) <TAB>  <TAB>  <TAB> del cache[key] <TAB>  <TAB>  <TAB> del use_count[key] <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return True",if not cache [ key ] :,189
198,"def insertionsort(array): <TAB> size = array.getsize() <TAB> array.reset(""Insertion sort"") <TAB> for i in range(1, size): <TAB>  <TAB> j = i - 1 <TAB>  <TAB> while j >= 0: <MASK> break <TAB>  <TAB>  <TAB> array.swap(j, j + 1) <TAB>  <TAB>  <TAB> j = j - 1 <TAB> array.message(""Sorted"")","if array . compare ( j , j + 1 ) <= 0 :",109
199,"def publish_state(cls, payload, state): <TAB> try: <TAB>  <TAB> if isinstance(payload, LiveActionDB): <MASK> cls.process(payload) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> worker.get_worker().process(payload) <TAB> except Exception: <TAB>  <TAB> traceback.print_exc() <TAB>  <TAB> print(payload)",if state == action_constants . LIVEACTION_STATUS_REQUESTED :,99
200,"def change_opacity_function(self, new_f): <TAB> self.opacity_function = new_f <TAB> dr = self.radius / self.num_levels <TAB> sectors = [] <TAB> for submob in self.submobjects: <TAB>  <TAB> if type(submob) == AnnularSector: <TAB>  <TAB>  <TAB> sectors.append(submob) <TAB> for (r, submob) in zip(np.arange(0, self.radius, dr), sectors): <MASK> # it's the shadow, don't dim it <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> alpha = self.opacity_function(r) <TAB>  <TAB> submob.set_fill(opacity=alpha)",if type ( submob ) != AnnularSector :,180
201,"def is_suppressed_warning( <TAB> type: str, subtype: str, suppress_warnings: List[str]) -> bool: <TAB> """"""Check the warning is suppressed or not."""""" <TAB> if type is None: <TAB>  <TAB> return False <TAB> for warning_type in suppress_warnings: <MASK> target, subtarget = warning_type.split(""."", 1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> target, subtarget = warning_type, None <TAB>  <TAB> if target == type: <TAB>  <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB>  <TAB> subtype is None <TAB>  <TAB>  <TAB>  <TAB> or subtarget is None <TAB>  <TAB>  <TAB>  <TAB> or subtarget == subtype <TAB>  <TAB>  <TAB>  <TAB> or subtarget == ""*"" <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False","if ""."" in warning_type :",178
202,"def set_many(self, mapping, timeout=None): <TAB> timeout = self._normalize_timeout(timeout) <TAB> # Use transaction=False to batch without calling redis MULTI <TAB> # which is not supported by twemproxy <TAB> pipe = self._client.pipeline(transaction=False) <TAB> for key, value in _items(mapping): <TAB>  <TAB> dump = self.dump_object(value) <MASK> pipe.set(name=self.key_prefix + key, value=dump) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pipe.setex(name=self.key_prefix + key, value=dump, time=timeout) <TAB> return pipe.execute()",if timeout == - 1 :,160
203,"def maybe_relative_path(path): <TAB> if not os.path.isabs(path): <TAB>  <TAB> return path  # already relative <TAB> dir = path <TAB> names = [] <TAB> while True: <TAB>  <TAB> prevdir = dir <TAB>  <TAB> dir, name = os.path.split(prevdir) <TAB>  <TAB> if dir == prevdir or not dir: <TAB>  <TAB>  <TAB> return path  # failed to make it relative <TAB>  <TAB> names.append(name) <TAB>  <TAB> try: <MASK> names.reverse() <TAB>  <TAB>  <TAB>  <TAB> return os.path.join(*names) <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> pass","if samefile ( dir , os . curdir ) :",155
204,"def word_range(word): <TAB> for ind in range(len(word)): <TAB>  <TAB> temp = word[ind] <TAB>  <TAB> for c in [chr(x) for x in range(ord(""a""), ord(""z"") + 1)]: <MASK> yield word[:ind] + c + word[ind + 1 :]",if c != temp :,83
205,"def validate(self): <TAB> self.update_soil_edit(""sand_composition"") <TAB> for soil_type in self.soil_types: <MASK> frappe.throw(_(""{0} should be a value between 0 and 100"").format(soil_type)) <TAB> if sum(self.get(soil_type) for soil_type in self.soil_types) != 100: <TAB>  <TAB> frappe.throw(_(""Soil compositions do not add up to 100""))",if self . get ( soil_type ) > 100 or self . get ( soil_type ) < 0 :,142
206,"def on_click(self, event): <TAB> run = self._is_running() <TAB> if event[""button""] == self.button_activate: <TAB>  <TAB> self.py3.command_run([""xscreensaver-command"", ""-activate""]) <TAB> if event[""button""] == self.button_toggle: <MASK> self.py3.command_run([""xscreensaver-command"", ""-exit""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Because we want xscreensaver to continue running after <TAB>  <TAB>  <TAB> # exit, we instead use preexec_fn=setpgrp here. <TAB>  <TAB>  <TAB> Popen( <TAB>  <TAB>  <TAB>  <TAB> [""xscreensaver"", ""-no-splash"", ""-no-capture-stderr""], <TAB>  <TAB>  <TAB>  <TAB> stdout=PIPE, <TAB>  <TAB>  <TAB>  <TAB> stderr=PIPE, <TAB>  <TAB>  <TAB>  <TAB> preexec_fn=setpgrp, <TAB>  <TAB>  <TAB> )",if run :,199
207,"def maybe_relative_path(path): <TAB> if not os.path.isabs(path): <TAB>  <TAB> return path  # already relative <TAB> dir = path <TAB> names = [] <TAB> while True: <TAB>  <TAB> prevdir = dir <TAB>  <TAB> dir, name = os.path.split(prevdir) <MASK> return path  # failed to make it relative <TAB>  <TAB> names.append(name) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if samefile(dir, os.curdir): <TAB>  <TAB>  <TAB>  <TAB> names.reverse() <TAB>  <TAB>  <TAB>  <TAB> return os.path.join(*names) <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> pass",if dir == prevdir or not dir :,155
208,"def _format_micros(self, datestring): <TAB> parts = datestring[:-1].split(""."") <TAB> if len(parts) == 1: <MASK> return datestring[:-1] + "".000000Z"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return datestring + "".000000Z"" <TAB> else: <TAB>  <TAB> micros = parts[-1][:6] if len(parts[-1]) > 6 else parts[-1] <TAB>  <TAB> return ""."".join(parts[:-1] + [""{:06d}"".format(int(micros))]) + ""Z""","if datestring . endswith ( ""Z"" ) :",135
209,"def preprocess_raw_enwik9(input_filename, output_filename): <TAB> with open(input_filename, ""r"") as f1: <TAB>  <TAB> with open(output_filename, ""w"") as f2: <TAB>  <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB>  <TAB> line = f1.readline() <TAB>  <TAB>  <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB>  <TAB> line = list(enwik9_norm_transform([line]))[0] <MASK> if line[0] == "" "": <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> line = line[1:] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f2.writelines(line + ""\n"")","if line != "" "" and line != """" :",164
210,"def set(self, item, data): <TAB> if not type(item) is slice: <TAB>  <TAB> item = slice(item, item + len(data), None) <TAB> virt_item = self.item2virtitem(item) <TAB> if not virt_item: <TAB>  <TAB> return <TAB> off = 0 <TAB> for s, n_item in virt_item: <MASK> i = slice(off, n_item.stop + off - n_item.start, n_item.step) <TAB>  <TAB>  <TAB> data_slice = data.__getitem__(i) <TAB>  <TAB>  <TAB> s.content.__setitem__(n_item, data_slice) <TAB>  <TAB>  <TAB> off = i.stop <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""TODO XXX"") <TAB> return","if isinstance ( s , ProgBits ) :",184
211,"def walk(msg, callback, data): <TAB> partnum = 0 <TAB> for part in msg.walk(): <TAB>  <TAB> # multipart/* are just containers <TAB>  <TAB> if part.get_content_maintype() == ""multipart"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> ctype = part.get_content_type() <TAB>  <TAB> if ctype is None: <TAB>  <TAB>  <TAB> ctype = OCTET_TYPE <TAB>  <TAB> filename = part.get_filename() <MASK> filename = PART_FN_TPL % (partnum) <TAB>  <TAB> headers = dict(part) <TAB>  <TAB> LOG.debug(headers) <TAB>  <TAB> headers[""Content-Type""] = ctype <TAB>  <TAB> payload = util.fully_decoded_payload(part) <TAB>  <TAB> callback(data, filename, payload, headers) <TAB>  <TAB> partnum = partnum + 1",if not filename :,190
212,"def _run_wes(args): <TAB> """"""Run CWL using a Workflow Execution Service (WES) endpoint"""""" <TAB> main_file, json_file, project_name = _get_main_and_json(args.directory) <TAB> main_file = _pack_cwl(main_file) <TAB> if args.host and ""stratus"" in args.host: <TAB>  <TAB> _run_wes_stratus(args, main_file, json_file) <TAB> else: <TAB>  <TAB> opts = [""--no-wait""] <MASK> opts += [""--host"", args.host] <TAB>  <TAB> if args.auth: <TAB>  <TAB>  <TAB> opts += [""--auth"", args.auth] <TAB>  <TAB> cmd = [""wes-client""] + opts + [main_file, json_file] <TAB>  <TAB> _run_tool(cmd)",if args . host :,197
213,"def insertTestData(self, rows): <TAB> for row in rows: <TAB>  <TAB> if isinstance(row, Worker): <TAB>  <TAB>  <TAB> self.workers[row.id] = dict( <TAB>  <TAB>  <TAB>  <TAB> id=row.id, name=row.name, paused=0, graceful=0, info=row.info <TAB>  <TAB>  <TAB> ) <MASK> row.id = row.buildermasterid * 10000 + row.workerid <TAB>  <TAB>  <TAB> self.configured[row.id] = dict( <TAB>  <TAB>  <TAB>  <TAB> buildermasterid=row.buildermasterid, workerid=row.workerid <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> elif isinstance(row, ConnectedWorker): <TAB>  <TAB>  <TAB> self.connected[row.id] = dict(masterid=row.masterid, workerid=row.workerid)","elif isinstance ( row , ConfiguredWorker ) :",194
214,"def local_shape_to_shape_i(node): <TAB> if node.op == T.shape: <TAB>  <TAB> # This optimization needs ShapeOpt and fgraph.shape_feature <MASK> return <TAB>  <TAB> shape_feature = node.fgraph.shape_feature <TAB>  <TAB> ret = shape_feature.make_vector_shape(node.inputs[0]) <TAB>  <TAB> # We need to copy over stack trace from input to output <TAB>  <TAB> copy_stack_trace(node.outputs[0], ret) <TAB>  <TAB> return [ret]","if not hasattr ( node . fgraph , ""shape_feature"" ) :",136
215,"def get_config(): <TAB> """"""Get INI parser with version.ini data."""""" <TAB> # TODO(hanuszczak): See comment in `setup.py` for `grr-response-proto`. <TAB> ini_path = os.path.join(THIS_DIRECTORY, ""version.ini"") <MASK> ini_path = os.path.join(THIS_DIRECTORY, ""../../version.ini"") <TAB>  <TAB> if not os.path.exists(ini_path): <TAB>  <TAB>  <TAB> raise RuntimeError(""Couldn't find version.ini"") <TAB> config = configparser.ConfigParser() <TAB> config.read(ini_path) <TAB> return config",if not os . path . exists ( ini_path ) :,156
216,"def init_weights(self, pretrained=None): <TAB> if isinstance(pretrained, str): <TAB>  <TAB> logger = logging.getLogger() <TAB>  <TAB> load_checkpoint(self, pretrained, strict=False, logger=logger) <TAB> elif pretrained is None: <TAB>  <TAB> for m in self.modules(): <MASK> kaiming_init(m) <TAB>  <TAB>  <TAB> elif isinstance(m, (_BatchNorm, nn.GroupNorm)): <TAB>  <TAB>  <TAB>  <TAB> constant_init(m, 1) <TAB> else: <TAB>  <TAB> raise TypeError(""pretrained must be a str or None"")","if isinstance ( m , nn . Conv2d ) :",141
217,"def isValidDateString(config_param_name, value, valid_value): <TAB> try: <MASK> return value <TAB>  <TAB> day, month, year = value.split(""-"") <TAB>  <TAB> if int(day) < 1 or int(day) > 31: <TAB>  <TAB>  <TAB> raise DateStringValueError(config_param_name, value) <TAB>  <TAB> if int(month) < 1 or int(month) > 12: <TAB>  <TAB>  <TAB> raise DateStringValueError(config_param_name, value) <TAB>  <TAB> if int(year) < 1900 or int(year) > 2013: <TAB>  <TAB>  <TAB> raise DateStringValueError(config_param_name, value) <TAB>  <TAB> return value <TAB> except Exception: <TAB>  <TAB> raise DateStringValueError(config_param_name, value)","if value == ""DD-MM-YYYY"" :",187
218,"def from_obj(cls, py_obj): <TAB> if not isinstance(py_obj, Image): <TAB>  <TAB> raise TypeError(""py_obj must be a wandb.Image"") <TAB> else: <MASK> box_keys = list(py_obj._boxes.keys()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> box_keys = [] <TAB>  <TAB> if hasattr(py_obj, ""masks"") and py_obj.masks: <TAB>  <TAB>  <TAB> mask_keys = list(py_obj.masks.keys()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> mask_keys = [] <TAB>  <TAB> return cls(box_keys, mask_keys)","if hasattr ( py_obj , ""_boxes"" ) and py_obj . _boxes :",164
219,"def _path_type(st, lst): <TAB> parts = [] <TAB> if st: <TAB>  <TAB> if stat.S_ISREG(st.st_mode): <TAB>  <TAB>  <TAB> parts.append(""file"") <MASK> parts.append(""dir"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> parts.append(""other"") <TAB> if lst: <TAB>  <TAB> if stat.S_ISLNK(lst.st_mode): <TAB>  <TAB>  <TAB> parts.append(""link"") <TAB> return "" "".join(parts)",elif stat . S_ISDIR ( st . st_mode ) :,130
220,"def is_destructive(queries): <TAB> """"""Returns if any of the queries in *queries* is destructive."""""" <TAB> keywords = (""drop"", ""shutdown"", ""delete"", ""truncate"", ""alter"") <TAB> for query in sqlparse.split(queries): <TAB>  <TAB> if query: <MASK> return True <TAB>  <TAB>  <TAB> elif query_starts_with( <TAB>  <TAB>  <TAB>  <TAB> query, [""update""] <TAB>  <TAB>  <TAB> ) is True and not query_has_where_clause(query): <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False","if query_starts_with ( query , keywords ) is True :",136
221,"def _store_gsuite_membership_post(self): <TAB> """"""Flush storing gsuite memberships."""""" <TAB> if not self.member_cache: <TAB>  <TAB> return <TAB> self.session.flush() <TAB> # session.execute automatically flushes <TAB> if self.membership_items: <MASK> # SQLite doesn't support bulk insert <TAB>  <TAB>  <TAB> for item in self.membership_items: <TAB>  <TAB>  <TAB>  <TAB> stmt = self.dao.TBL_MEMBERSHIP.insert(item) <TAB>  <TAB>  <TAB>  <TAB> self.session.execute(stmt) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> stmt = self.dao.TBL_MEMBERSHIP.insert(self.membership_items) <TAB>  <TAB>  <TAB> self.session.execute(stmt)","if get_sql_dialect ( self . session ) == ""sqlite"" :",182
222,"def forward(self, inputs: paddle.Tensor): <TAB> outputs = [] <TAB> blocks = self.block(inputs) <TAB> route = None <TAB> for i, block in enumerate(blocks): <MASK> block = paddle.concat([route, block], axis=1) <TAB>  <TAB> route, tip = self.yolo_blocks[i](block) <TAB>  <TAB> block_out = self.block_outputs[i](tip) <TAB>  <TAB> outputs.append(block_out) <TAB>  <TAB> if i < 2: <TAB>  <TAB>  <TAB> route = self.route_blocks_2[i](route) <TAB>  <TAB>  <TAB> route = self.upsample(route) <TAB> return outputs",if i > 0 :,163
223,"def deep_dict(self, root=None): <TAB> if root is None: <TAB>  <TAB> root = self <TAB> result = {} <TAB> for key, value in root.items(): <MASK> result[key] = self.deep_dict(root=self.__class__._get_next(key, root)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result[key] = value <TAB> return result","if isinstance ( value , dict ) :",99
224,"def _parse_param_list(self, content): <TAB> r = Reader(content) <TAB> params = [] <TAB> while not r.eof(): <TAB>  <TAB> header = r.read().strip() <MASK> arg_name, arg_type = header.split("" : "")[:2] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> arg_name, arg_type = header, """" <TAB>  <TAB> desc = r.read_to_next_unindented_line() <TAB>  <TAB> desc = dedent_lines(desc) <TAB>  <TAB> params.append((arg_name, arg_type, desc)) <TAB> return params","if "" : "" in header :",147
225,"def _ungroup(sequence, groups=None): <TAB> for v in sequence: <MASK> if groups is not None: <TAB>  <TAB>  <TAB>  <TAB> groups.append(list(_ungroup(v, groups=None))) <TAB>  <TAB>  <TAB> for v in _ungroup(v, groups): <TAB>  <TAB>  <TAB>  <TAB> yield v <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield v","if isinstance ( v , ( list , tuple ) ) :",95
226,"def _add_resource_group(obj): <TAB> if isinstance(obj, list): <TAB>  <TAB> for array_item in obj: <TAB>  <TAB>  <TAB> _add_resource_group(array_item) <TAB> elif isinstance(obj, dict): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if ""resourcegroup"" not in [x.lower() for x in obj.keys()]: <TAB>  <TAB>  <TAB>  <TAB> if obj[""id""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> obj[""resourceGroup""] = _parse_id(obj[""id""])[""resource-group""] <TAB>  <TAB> except (KeyError, IndexError, TypeError): <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> for item_key in obj: <MASK> _add_resource_group(obj[item_key])","if item_key != ""sourceVault"" :",175
227,"def haslayer(self, cls): <TAB> """"""true if self has a layer that is an instance of cls. Superseded by ""cls in self"" syntax."""""" <TAB> if self.__class__ == cls or self.__class__.__name__ == cls: <TAB>  <TAB> return 1 <TAB> for f in self.packetfields: <TAB>  <TAB> fvalue_gen = self.getfieldval(f.name) <TAB>  <TAB> if fvalue_gen is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if not f.islist: <TAB>  <TAB>  <TAB> fvalue_gen = SetGen(fvalue_gen, _iterpacket=0) <TAB>  <TAB> for fvalue in fvalue_gen: <MASK> ret = fvalue.haslayer(cls) <TAB>  <TAB>  <TAB>  <TAB> if ret: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return ret <TAB> return self.payload.haslayer(cls)","if isinstance ( fvalue , Packet ) :",199
228,"def _post_attachment(self, message, channel, color, sub_fields=None): <TAB> if channel is None: <TAB>  <TAB> message_channels = self.channels <TAB> else: <TAB>  <TAB> message_channels = [channel] <TAB> for message_channel in message_channels: <TAB>  <TAB> attachment = { <TAB>  <TAB>  <TAB> ""fallback"": message, <TAB>  <TAB>  <TAB> ""text"": message, <TAB>  <TAB>  <TAB> ""color"": color, <TAB>  <TAB> } <MASK> attachment[""fields""] = sub_fields <TAB>  <TAB> self.slack_client.api_call( <TAB>  <TAB>  <TAB> ""chat.postMessage"", <TAB>  <TAB>  <TAB> channel=message_channel, <TAB>  <TAB>  <TAB> attachments=[attachment], <TAB>  <TAB>  <TAB> as_user=True, <TAB>  <TAB> )",if sub_fields is not None :,178
229,"def create(cls, repository, args): <TAB> key = cls() <TAB> passphrase = os.environ.get(""ATTIC_PASSPHRASE"") <TAB> if passphrase is not None: <TAB>  <TAB> passphrase2 = passphrase <TAB> else: <TAB>  <TAB> passphrase, passphrase2 = 1, 2 <TAB> while passphrase != passphrase2: <TAB>  <TAB> passphrase = getpass(""Enter passphrase: "") <MASK> print(""Passphrase must not be blank"") <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> passphrase2 = getpass(""Enter same passphrase again: "") <TAB>  <TAB> if passphrase != passphrase2: <TAB>  <TAB>  <TAB> print(""Passphrases do not match"") <TAB> key.init(repository, passphrase) <TAB> if passphrase: <TAB>  <TAB> print(""Remember your passphrase. Your data will be inaccessible without it."") <TAB> return key",if not passphrase :,184
230,"def _generate_create_date(self): <TAB> if self.timezone is not None: <TAB>  <TAB> # First, assume correct capitalization <TAB>  <TAB> tzinfo = tz.gettz(self.timezone) <MASK> # Fall back to uppercase <TAB>  <TAB>  <TAB> tzinfo = tz.gettz(self.timezone.upper()) <TAB>  <TAB> if tzinfo is None: <TAB>  <TAB>  <TAB> raise util.CommandError(""Can't locate timezone: %s"" % self.timezone) <TAB>  <TAB> create_date = ( <TAB>  <TAB>  <TAB> datetime.datetime.utcnow().replace(tzinfo=tz.tzutc()).astimezone(tzinfo) <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> create_date = datetime.datetime.now() <TAB> return create_date",if tzinfo is None :,168
231,"def _read_header_lines(fp): <TAB> """"""Read lines with headers until the start of body"""""" <TAB> lines = deque() <TAB> for line in fp: <TAB>  <TAB> if is_empty(line): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> # tricky case if it's not a header and not an empty line <TAB>  <TAB> # usually means that user forgot to separate the body and newlines <TAB>  <TAB> # so ""unread"" this line here, what means to treat it like a body <MASK> fp.seek(fp.tell() - len(line)) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> lines.append(line) <TAB> return lines",if not _RE_HEADER . match ( line ) :,153
232,"def _media_files_drag_received(widget, context, x, y, data, info, timestamp): <TAB> uris = data.get_uris() <TAB> files = [] <TAB> for uri in uris: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> uri_tuple = GLib.filename_from_uri(uri) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> uri, unused = uri_tuple <MASK> if utils.is_media_file(uri) == True: <TAB>  <TAB>  <TAB>  <TAB> files.append(uri) <TAB> if len(files) == 0: <TAB>  <TAB> return <TAB> open_dropped_files(files)",if os . path . exists ( uri ) == True :,159
233,"def remove_importlib(frame, options): <TAB> if frame is None: <TAB>  <TAB> return None <TAB> for child in frame.children: <TAB>  <TAB> remove_importlib(child, options=options) <MASK> # remove this node, moving the self_time and children up to the parent <TAB>  <TAB>  <TAB> frame.self_time += child.self_time <TAB>  <TAB>  <TAB> frame.add_children(child.children, after=child) <TAB>  <TAB>  <TAB> child.remove_from_parent() <TAB> return frame","if ""<frozen importlib._bootstrap"" in child . file_path :",132
234,"def __call__(self, graph): <TAB> for layer_name, data in self.params: <MASK> node = graph.get_node(layer_name) <TAB>  <TAB>  <TAB> node.data = self.adjust_parameters(node, data) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print_stderr(""Ignoring parameters for non-existent layer: %s"" % layer_name) <TAB> return graph",if layer_name in graph :,99
235,"def test_with_three_points(self): <TAB> cba = ia.Polygon([(1, 2), (3, 4), (5, 5)]) <TAB> for i, xy in enumerate(cba): <TAB>  <TAB> assert i in [0, 1, 2] <TAB>  <TAB> if i == 0: <TAB>  <TAB>  <TAB> assert np.allclose(xy, (1, 2)) <MASK> assert np.allclose(xy, (3, 4)) <TAB>  <TAB> elif i == 2: <TAB>  <TAB>  <TAB> assert np.allclose(xy, (5, 5)) <TAB> assert i == 2",elif i == 1 :,136
236,"def _serve(self): <TAB> self._conn = self.manager.request(REQUEST_DNS_LISTENER, self.domain) <TAB> conn = MsgPackMessages(self._conn) <TAB> while self.active: <TAB>  <TAB> request = conn.recv() <TAB>  <TAB> if not request: <TAB>  <TAB>  <TAB> logger.warning(""DNS: Recieved empty request. Shutdown"") <TAB>  <TAB>  <TAB> self.stop() <TAB>  <TAB>  <TAB> break <TAB>  <TAB> now = time.time() <TAB>  <TAB> response = self.handler.process(request) <TAB>  <TAB> if not response: <TAB>  <TAB>  <TAB> response = [] <TAB>  <TAB> used = time.time() - now <MASK> logger.warning(""DNS: Slow processing speed (%s)s"", used) <TAB>  <TAB> conn.send(response)",if used > 1 :,180
237,"def read(cls, fp, **kwargs): <TAB> major_version, minor_version, count = read_fmt(""2HI"", fp) <TAB> items = [] <TAB> for _ in range(count): <TAB>  <TAB> length = read_fmt(""I"", fp)[0] - 4 <MASK> with io.BytesIO(fp.read(length)) as f: <TAB>  <TAB>  <TAB>  <TAB> items.append(Annotation.read(f)) <TAB> return cls(major_version=major_version, minor_version=minor_version, items=items)",if length > 0 :,129
238,"def save_uploaded_files(): <TAB> files = [] <TAB> unzip = bool(request.form.get(""unzip"") in [""true"", ""on""]) <TAB> for uploaded_file in request.files.getlist(""files""): <MASK> with zipfile.ZipFile(uploaded_file, ""r"") as zf: <TAB>  <TAB>  <TAB>  <TAB> for info in zf.infolist(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> name = info.filename <TAB>  <TAB>  <TAB>  <TAB>  <TAB> size = info.file_size <TAB>  <TAB>  <TAB>  <TAB>  <TAB> data = zf.read(name) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if size > 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> files.append(save_file(data, filename=name.split(""/"")[-1])) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> files.append(save_file(uploaded_file)) <TAB> return files",if unzip and zipfile . is_zipfile ( uploaded_file ) :,195
239,"def analyze_string_content(self, string, line_num, filename): <TAB> output = {} <TAB> if self.keyword_exclude and self.keyword_exclude.search(string): <TAB>  <TAB> return output <TAB> for identifier in self.secret_generator( <TAB>  <TAB> string, <TAB>  <TAB> filetype=determine_file_type(filename), <TAB> ): <MASK> continue <TAB>  <TAB> secret = PotentialSecret( <TAB>  <TAB>  <TAB> self.secret_type, <TAB>  <TAB>  <TAB> filename, <TAB>  <TAB>  <TAB> identifier, <TAB>  <TAB>  <TAB> line_num, <TAB>  <TAB> ) <TAB>  <TAB> output[secret] = secret <TAB> return output",if self . is_secret_false_positive ( identifier ) :,157
240,"def _validate_and_set_default_hyperparameters(self): <TAB> """"""Placeholder docstring"""""" <TAB> # Check if all the required hyperparameters are set. If there is a default value <TAB> # for one, set it. <TAB> for name, definition in self.hyperparameter_definitions.items(): <TAB>  <TAB> if name not in self.hyperparam_dict: <TAB>  <TAB>  <TAB> spec = definition[""spec""] <TAB>  <TAB>  <TAB> if ""DefaultValue"" in spec: <TAB>  <TAB>  <TAB>  <TAB> self.hyperparam_dict[name] = spec[""DefaultValue""] <MASK> raise ValueError(""Required hyperparameter: %s is not set"" % name)","elif ""IsRequired"" in spec and spec [ ""IsRequired"" ] :",158
241,"def get_code(self, fullname=None): <TAB> fullname = self._fix_name(fullname) <TAB> if self.code is None: <TAB>  <TAB> mod_type = self.etc[2] <TAB>  <TAB> if mod_type == imp.PY_SOURCE: <TAB>  <TAB>  <TAB> source = self.get_source(fullname) <TAB>  <TAB>  <TAB> self.code = compile(source, self.filename, ""exec"") <TAB>  <TAB> elif mod_type == imp.PY_COMPILED: <TAB>  <TAB>  <TAB> self._reopen() <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> self.code = read_code(self.file) <TAB>  <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB>  <TAB> self.file.close() <MASK> self.code = self._get_delegate().get_code() <TAB> return self.code",elif mod_type == imp . PKG_DIRECTORY :,196
242,"def eigh_abstract_eval(operand, lower): <TAB> if isinstance(operand, ShapedArray): <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Argument to symmetric eigendecomposition must have shape [..., n, n],"" <TAB>  <TAB>  <TAB>  <TAB> ""got shape {}"".format(operand.shape) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> batch_dims = operand.shape[:-2] <TAB>  <TAB> n = operand.shape[-1] <TAB>  <TAB> v = ShapedArray(batch_dims + (n, n), operand.dtype) <TAB>  <TAB> w = ShapedArray(batch_dims + (n,), lax.lax._complex_basetype(operand.dtype)) <TAB> else: <TAB>  <TAB> v, w = operand, operand <TAB> return v, w",if operand . ndim < 2 or operand . shape [ - 2 ] != operand . shape [ - 1 ] :,191
243,"def conninfo_parse(dsn): <TAB> ret = {} <TAB> length = len(dsn) <TAB> i = 0 <TAB> while i < length: <TAB>  <TAB> if dsn[i].isspace(): <TAB>  <TAB>  <TAB> i += 1 <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> param_match = PARAMETER_RE.match(dsn[i:]) <MASK> return <TAB>  <TAB> param = param_match.group(1) <TAB>  <TAB> i += param_match.end() <TAB>  <TAB> if i >= length: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> value, end = read_param_value(dsn[i:]) <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> i += end <TAB>  <TAB> ret[param] = value <TAB> return ret",if not param_match :,175
244,"def load_weights_from_unsupervised(self, unsupervised_model): <TAB> update_state_dict = copy.deepcopy(self.network.state_dict()) <TAB> for param, weights in unsupervised_model.network.state_dict().items(): <TAB>  <TAB> if param.startswith(""encoder""): <TAB>  <TAB>  <TAB> # Convert encoder's layers name to match <TAB>  <TAB>  <TAB> new_param = ""tabnet."" + param <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_param = param <MASK> # update only common layers <TAB>  <TAB>  <TAB> update_state_dict[new_param] = weights <TAB> self.network.load_state_dict(update_state_dict)",if self . network . state_dict ( ) . get ( new_param ) is not None :,170
245,"def viewer_setup(self): <TAB> for key, value in DEFAULT_CAMERA_CONFIG.items(): <MASK> getattr(self.viewer.cam, key)[:] = value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> setattr(self.viewer.cam, key, value)","if isinstance ( value , np . ndarray ) :",75
246,"def colormap_changed(change): <TAB> if change[""new""]: <TAB>  <TAB> cmap_colors = [ <TAB>  <TAB>  <TAB> color[1:] for color in cmap.step.__dict__[""_schemes""][colormap.value] <TAB>  <TAB> ] <TAB>  <TAB> palette.value = "", "".join(cmap_colors) <TAB>  <TAB> colorbar = getattr(cmap.step, colormap.value) <TAB>  <TAB> colorbar_output = self.colorbar_widget <TAB>  <TAB> with colorbar_output: <TAB>  <TAB>  <TAB> colorbar_output.clear_output() <TAB>  <TAB>  <TAB> display(colorbar) <MASK> labels = [f""Class {i+1}"" for i in range(len(palette.value.split("","")))] <TAB>  <TAB>  <TAB> legend_labels.value = "", "".join(labels)","if len ( palette . value ) > 0 and "","" in palette . value :",185
247,"def invalidate(self, layers=None): <TAB> if layers is None: <TAB>  <TAB> layers = Layer.AllLayers <TAB> if layers: <TAB>  <TAB> layers = set(layers) <TAB>  <TAB> self.invalidLayers.update(layers) <TAB>  <TAB> blockRenderers = [ <TAB>  <TAB>  <TAB> br <TAB>  <TAB>  <TAB> for br in self.blockRenderers <TAB>  <TAB>  <TAB> if br.layer is Layer.Blocks or br.layer not in layers <TAB>  <TAB> ] <MASK> self.forgetDisplayLists() <TAB>  <TAB> self.blockRenderers = blockRenderers <TAB>  <TAB> if self.renderer.showRedraw and Layer.Blocks in layers: <TAB>  <TAB>  <TAB> self.needsRedisplay = True",if len ( blockRenderers ) < len ( self . blockRenderers ) :,184
248,"def fromstring(cls, input): <TAB> productions = [] <TAB> for linenum, line in enumerate(input.split(""\n"")): <TAB>  <TAB> line = line.strip() <MASK> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> productions += _read_dependency_production(line) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> raise ValueError(""Unable to parse line %s: %s"" % (linenum, line)) <TAB> if len(productions) == 0: <TAB>  <TAB> raise ValueError(""No productions found!"") <TAB> return DependencyGrammar(productions)","if line . startswith ( ""#"" ) or line == """" :",130
249,"def repl(m, base_path, rel_path=None): <TAB> if m.group(""comments""): <TAB>  <TAB> tag = m.group(""comments"") <TAB> else: <TAB>  <TAB> tag = m.group(""open"") <MASK> tag += RE_TAG_LINK_ATTR.sub( <TAB>  <TAB>  <TAB>  <TAB> lambda m2: repl_absolute(m2, base_path), m.group(""attr"") <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tag += RE_TAG_LINK_ATTR.sub( <TAB>  <TAB>  <TAB>  <TAB> lambda m2: repl_relative(m2, base_path, rel_path), m.group(""attr"") <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> tag += m.group(""close"") <TAB> return tag",if rel_path is None :,179
250,"def encode(path): <TAB> if isinstance(path, str_cls): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> path = path.encode(fs_encoding, ""strict"") <TAB>  <TAB> except UnicodeEncodeError: <MASK> raise <TAB>  <TAB>  <TAB> path = path.encode(fs_fallback_encoding, ""strict"") <TAB> return path",if not platform . is_linux ( ) :,86
251,"def __iter__(self): <TAB> base_iterator = super(ProcessIterable, self).__iter__() <TAB> if getattr(self.queryset, ""_coerced"", False): <TAB>  <TAB> for process in base_iterator: <MASK> process = coerce_to_related_instance( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> process, process.flow_class.process_class <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> yield process <TAB> else: <TAB>  <TAB> for process in base_iterator: <TAB>  <TAB>  <TAB> yield process","if isinstance ( process , self . queryset . model ) :",125
252,"def footnotes_under(n: Element) -> Iterator[nodes.footnote]: <TAB> if isinstance(n, nodes.footnote): <TAB>  <TAB> yield n <TAB> else: <TAB>  <TAB> for c in n.children: <MASK> continue <TAB>  <TAB>  <TAB> elif isinstance(c, nodes.Element): <TAB>  <TAB>  <TAB>  <TAB> yield from footnotes_under(c)","if isinstance ( c , addnodes . start_of_file ) :",99
253,"def _process_submissions(self) -> None: <TAB> """"""Process all submissions which have not been processed yet."""""" <TAB> while self._to_be_processed: <TAB>  <TAB> job = self._to_be_processed[0] <TAB>  <TAB> job.process()  # trigger computation <MASK> heapq.heappush( <TAB>  <TAB>  <TAB>  <TAB> self._steady_priority_queue, <TAB>  <TAB>  <TAB>  <TAB> OrderedJobs(job.release_time, self._order, job), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self._to_be_processed.popleft()  # remove right after it is added to the heap queue <TAB>  <TAB> self._order += 1",if not self . batch_mode :,156
254,"def valid_localparts(strip_delimiters=False): <TAB> for line in ABRIDGED_LOCALPART_VALID_TESTS.split(""\n""): <TAB>  <TAB> # strip line, skip over empty lines <TAB>  <TAB> line = line.strip() <TAB>  <TAB> if line == """": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # skip over comments or empty lines <TAB>  <TAB> match = COMMENT.match(line) <MASK> continue <TAB>  <TAB> # skip over localparts with delimiters <TAB>  <TAB> if strip_delimiters: <TAB>  <TAB>  <TAB> if "","" in line or "";"" in line: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> yield line",if match :,145
255,"def _get_payload_hash(self, method, data=None): <TAB> if method in (""POST"", ""PUT""): <TAB>  <TAB> if data: <MASK> # File upload; don't try to read the entire payload <TAB>  <TAB>  <TAB>  <TAB> return UNSIGNED_PAYLOAD <TAB>  <TAB>  <TAB> return _hash(data) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return UNSIGNED_PAYLOAD <TAB> else: <TAB>  <TAB> return _hash("""")","if hasattr ( data , ""next"" ) or hasattr ( data , ""__next__"" ) :",118
256,"def get_download_info(self): <TAB> try: <TAB>  <TAB> download_info = self.api.get_download_info(self.game) <TAB>  <TAB> result = True <TAB> except NoDownloadLinkFound as e: <TAB>  <TAB> print(e) <MASK> Config.unset(""current_download"") <TAB>  <TAB> GLib.idle_add( <TAB>  <TAB>  <TAB> self.parent.parent.show_error, <TAB>  <TAB>  <TAB> _(""Download error""), <TAB>  <TAB>  <TAB> _( <TAB>  <TAB>  <TAB>  <TAB> ""There was an error when trying to fetch the download link!\n{}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> e <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ), <TAB>  <TAB> ) <TAB>  <TAB> download_info = False <TAB>  <TAB> result = False <TAB> return result, download_info","if Config . get ( ""current_download"" ) == self . game . id :",191
257,"def find_id(self, doc_id): <TAB> self._lock.acquire() <TAB> try: <TAB>  <TAB> doc = self._docs.get(doc_id) <MASK> doc = copy.deepcopy(doc) <TAB>  <TAB>  <TAB> doc[""id""] = doc_id <TAB>  <TAB>  <TAB> return doc <TAB> finally: <TAB>  <TAB> self._lock.release()",if doc :,88
258,"def assign_art(self, session, task): <TAB> """"""Place the discovered art in the filesystem."""""" <TAB> if task in self.art_candidates: <TAB>  <TAB> candidate = self.art_candidates.pop(task) <TAB>  <TAB> self._set_art(task.album, candidate, not self.src_removed) <MASK> task.prune(candidate.path)",if self . src_removed :,93
259,"def _replace_named(self, named, replace_scalar): <TAB> for item in named: <TAB>  <TAB> for name, value in self._get_replaced_named(item, replace_scalar): <MASK> raise DataError(""Argument names must be strings."") <TAB>  <TAB>  <TAB> yield name, value",if not is_string ( name ) :,79
260,"def qtTypeIdent(conn, *args): <TAB> # We're not using the conn object at the moment, but - we will <TAB> # modify the <TAB> # logic to use the server version specific keywords later. <TAB> res = None <TAB> value = None <TAB> for val in args: <TAB>  <TAB> # DataType doesn't have len function then convert it to string <TAB>  <TAB> if not hasattr(val, ""__len__""): <TAB>  <TAB>  <TAB> val = str(val) <TAB>  <TAB> if len(val) == 0: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> value = val <MASK> value = value.replace('""', '""""') <TAB>  <TAB>  <TAB> value = '""' + value + '""' <TAB>  <TAB> res = ((res and res + ""."") or """") + value <TAB> return res","if Driver . needsQuoting ( val , True ) :",181
261,"def _update_tileable_and_chunk_shape(self, tileable_graph, chunk_result, failed_ops): <TAB> for n in tileable_graph: <MASK> continue <TAB>  <TAB> tiled_n = get_tiled(n) <TAB>  <TAB> if has_unknown_shape(tiled_n): <TAB>  <TAB>  <TAB> if any(c.key not in chunk_result for c in tiled_n.chunks): <TAB>  <TAB>  <TAB>  <TAB> # some of the chunks has been fused <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> new_nsplits = self.get_tileable_nsplits(n, chunk_result=chunk_result) <TAB>  <TAB>  <TAB> for node in (n, tiled_n): <TAB>  <TAB>  <TAB>  <TAB> node._update_shape(tuple(sum(nsplit) for nsplit in new_nsplits)) <TAB>  <TAB>  <TAB> tiled_n._nsplits = new_nsplits",if n . op in failed_ops :,200
262,"def _read_filter(self, data): <TAB> if data: <MASK> self.inner_sha.update(data) <TAB>  <TAB> if self.expected_inner_md5sum: <TAB>  <TAB>  <TAB> self.inner_md5.update(data) <TAB> return data",if self . expected_inner_sha256 :,76
263,"def find_previous_editable(self, *args): <TAB> if self.editw == 0: <TAB>  <TAB> if self._active_page > 0: <TAB>  <TAB>  <TAB> self.switch_page(self._active_page - 1) <TAB> if not self.editw == 0: <TAB>  <TAB> # remember that xrange does not return the 'last' value, <TAB>  <TAB> # so go to -1, not 0! (fence post error in reverse) <TAB>  <TAB> for n in range(self.editw - 1, -1, -1): <MASK> self.editw = n <TAB>  <TAB>  <TAB>  <TAB> break",if self . _widgets__ [ n ] . editable and not self . _widgets__ [ n ] . hidden :,161
264,"def _get_event_for_message(self, message_id): <TAB> with self.event_lock: <MASK> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB> ""Event for message[{}] should have been created before accessing"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> message_id <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return self._events[message_id]",if message_id not in self . _events :,97
265,"def _get_deepest(self, t): <TAB> if isinstance(t, list): <TAB>  <TAB> if len(t) == 1: <TAB>  <TAB>  <TAB> return t[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for part in t: <TAB>  <TAB>  <TAB>  <TAB> res = self._get_deepest(part) <MASK> return res <TAB>  <TAB>  <TAB> return None <TAB> return None",if res :,95
266,"def _get_notify(self, action_node): <TAB> if action_node.name not in self._skip_notify_tasks: <MASK> task_notify = NotificationsHelper.to_model(action_node.notify) <TAB>  <TAB>  <TAB> return task_notify <TAB>  <TAB> elif self._chain_notify: <TAB>  <TAB>  <TAB> return self._chain_notify <TAB> return None",if action_node . notify :,95
267,"def __init__(self, centered=None, shape_params=()): <TAB> assert centered is None or isinstance(centered, (float, torch.Tensor)) <TAB> assert isinstance(shape_params, (tuple, list)) <TAB> assert all(isinstance(name, str) for name in shape_params) <TAB> if is_validation_enabled(): <TAB>  <TAB> if isinstance(centered, float): <TAB>  <TAB>  <TAB> assert 0 <= centered and centered <= 1 <MASK> assert (0 <= centered).all() <TAB>  <TAB>  <TAB> assert (centered <= 1).all() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert centered is None <TAB> self.centered = centered <TAB> self.shape_params = shape_params","elif isinstance ( centered , torch . Tensor ) :",163
268,"def collect(self): <TAB> for nickname in self.squid_hosts.keys(): <TAB>  <TAB> squid_host = self.squid_hosts[nickname] <TAB>  <TAB> fulldata = self._getData(squid_host[""host""], squid_host[""port""]) <TAB>  <TAB> if fulldata is not None: <TAB>  <TAB>  <TAB> fulldata = fulldata.splitlines() <TAB>  <TAB>  <TAB> for data in fulldata: <TAB>  <TAB>  <TAB>  <TAB> matches = self.stat_pattern.match(data) <MASK> self.publish_counter( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""%s.%s"" % (nickname, matches.group(1)), float(matches.group(2)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> )",if matches :,166
269,"def test_len(self): <TAB> eq = self.assertEqual <TAB> eq(base64MIME.base64_len(""hello""), len(base64MIME.encode(""hello"", eol=""""))) <TAB> for size in range(15): <TAB>  <TAB> if size == 0: <TAB>  <TAB>  <TAB> bsize = 0 <TAB>  <TAB> elif size <= 3: <TAB>  <TAB>  <TAB> bsize = 4 <TAB>  <TAB> elif size <= 6: <TAB>  <TAB>  <TAB> bsize = 8 <MASK> bsize = 12 <TAB>  <TAB> elif size <= 12: <TAB>  <TAB>  <TAB> bsize = 16 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> bsize = 20 <TAB>  <TAB> eq(base64MIME.base64_len(""x"" * size), bsize)",elif size <= 9 :,160
270,"def wait_for_initial_conf(self, timeout=1.0): <TAB> logger.info(""Waiting for initial configuration"") <TAB> cur_timeout = timeout <TAB> # Arbiter do not already set our have_conf param <TAB> while not self.new_conf and not self.interrupted: <TAB>  <TAB> elapsed, _, _ = self.handleRequests(cur_timeout) <TAB>  <TAB> if elapsed: <TAB>  <TAB>  <TAB> cur_timeout -= elapsed <MASK> continue <TAB>  <TAB>  <TAB> cur_timeout = timeout <TAB>  <TAB> sys.stdout.write(""."") <TAB>  <TAB> sys.stdout.flush()",if cur_timeout > 0 :,142
271,"def __init__(self, querylist=None): <TAB> self.query_id = -1 <TAB> if querylist is None: <TAB>  <TAB> self.querylist = [] <TAB> else: <TAB>  <TAB> self.querylist = querylist <TAB>  <TAB> for query in self.querylist: <TAB>  <TAB>  <TAB> if self.query_id == -1: <TAB>  <TAB>  <TAB>  <TAB> self.query_id = query.query_id <TAB>  <TAB>  <TAB> else: <MASK> raise ValueError(""query in list must be same query_id"")",if self . query_id != query . query_id :,137
272,"def candidates() -> Generator[""Symbol"", None, None]: <TAB> s = self <TAB> if Symbol.debug_lookup: <TAB>  <TAB> Symbol.debug_print(""searching in self:"") <TAB>  <TAB> print(s.to_string(Symbol.debug_indent + 1), end="""") <TAB> while True: <TAB>  <TAB> if matchSelf: <TAB>  <TAB>  <TAB> yield s <MASK> yield from s.children_recurse_anon <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield from s._children <TAB>  <TAB> if s.siblingAbove is None: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> s = s.siblingAbove <TAB>  <TAB> if Symbol.debug_lookup: <TAB>  <TAB>  <TAB> Symbol.debug_print(""searching in sibling:"") <TAB>  <TAB>  <TAB> print(s.to_string(Symbol.debug_indent + 1), end="""")",if recurseInAnon :,190
273,"def get_default_params(problem_type: str, penalty: str): <TAB> # TODO: get seed from seeds provider <TAB> if problem_type == REGRESSION: <TAB>  <TAB> default_params = {""C"": None, ""random_state"": 0, ""fit_intercept"": True} <MASK> default_params[""solver""] = ""auto"" <TAB> else: <TAB>  <TAB> default_params = { <TAB>  <TAB>  <TAB> ""C"": None, <TAB>  <TAB>  <TAB> ""random_state"": 0, <TAB>  <TAB>  <TAB> ""solver"": _get_solver(problem_type), <TAB>  <TAB>  <TAB> ""n_jobs"": -1, <TAB>  <TAB>  <TAB> ""fit_intercept"": True, <TAB>  <TAB> } <TAB> model_params = list(default_params.keys()) <TAB> return model_params, default_params",if penalty == L2 :,187
274,"def _UploadDirectory(local_dir: str, gcs_bucket: storage.Bucket, gcs_dir: str): <TAB> """"""Upload the contents of a local directory to a GCS Bucket."""""" <TAB> for file_name in os.listdir(local_dir): <TAB>  <TAB> path = os.path.join(local_dir, file_name) <MASK> logging.info(""Skipping %s as it's not a file."", path) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> logging.info(""Uploading: %s"", path) <TAB>  <TAB> gcs_blob = gcs_bucket.blob(f""{gcs_dir}/{file_name}"") <TAB>  <TAB> gcs_blob.upload_from_filename(path)",if not os . path . isfile ( path ) :,173
275,"def decode_query_ids(self, trans, conditional): <TAB> if conditional.operator == ""and"": <TAB>  <TAB> self.decode_query_ids(trans, conditional.left) <TAB>  <TAB> self.decode_query_ids(trans, conditional.right) <TAB> else: <TAB>  <TAB> left_base = conditional.left.split(""."")[0] <TAB>  <TAB> if left_base in self.FIELDS: <TAB>  <TAB>  <TAB> field = self.FIELDS[left_base] <MASK> conditional.right = trans.security.decode_id(conditional.right)",if field . id_decode :,135
276,"def data_dir(self) -> Path: <TAB> try: <TAB>  <TAB> from appdirs import user_data_dir <TAB> except ImportError: <TAB>  <TAB> # linux <TAB>  <TAB> path = Path.home() / "".local"" / ""share"" <MASK> return path / ""dephell"" <TAB>  <TAB> # mac os <TAB>  <TAB> path = Path.home() / ""Library"" / ""Application Support"" <TAB>  <TAB> if path.exists(): <TAB>  <TAB>  <TAB> return path / ""dephell"" <TAB>  <TAB> self.pip_main([""install"", ""appdirs""]) <TAB>  <TAB> from appdirs import user_data_dir <TAB> return Path(user_data_dir(""dephell""))",if path . exists ( ) :,157
277,"def setGameCard(self, isGameCard=False): <TAB> if isGameCard: <TAB>  <TAB> targetValue = 1 <TAB> else: <TAB>  <TAB> targetValue = 0 <TAB> for nca in self: <TAB>  <TAB> if isinstance(nca, Nca): <MASK> continue <TAB>  <TAB>  <TAB> Print.info(""writing isGameCard for %s, %d"" % (str(nca._path), targetValue)) <TAB>  <TAB>  <TAB> nca.header.setIsGameCard(targetValue)",if nca . header . getIsGameCard ( ) == targetValue :,132
278,"def check_apns_certificate(ss): <TAB> mode = ""start"" <TAB> for s in ss.split(""\n""): <TAB>  <TAB> if mode == ""start"": <TAB>  <TAB>  <TAB> if ""BEGIN RSA PRIVATE KEY"" in s or ""BEGIN PRIVATE KEY"" in s: <TAB>  <TAB>  <TAB>  <TAB> mode = ""key"" <MASK> if ""END RSA PRIVATE KEY"" in s or ""END PRIVATE KEY"" in s: <TAB>  <TAB>  <TAB>  <TAB> mode = ""end"" <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> elif s.startswith(""Proc-Type"") and ""ENCRYPTED"" in s: <TAB>  <TAB>  <TAB>  <TAB> raise ImproperlyConfigured( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Encrypted APNS private keys are not supported"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> if mode != ""end"": <TAB>  <TAB> raise ImproperlyConfigured(""The APNS certificate doesn't contain a private key"")","elif mode == ""key"" :",195
279,"def register_aggregate_groups(conn, *groups): <TAB> seen = set() <TAB> for group in groups: <TAB>  <TAB> klasses = AGGREGATE_COLLECTION[group] <TAB>  <TAB> for klass in klasses: <TAB>  <TAB>  <TAB> name = getattr(klass, ""name"", klass.__name__) <MASK> seen.add(name) <TAB>  <TAB>  <TAB>  <TAB> conn.create_aggregate(name, -1, klass)",if name not in seen :,106
280,"def _impl(inputs, input_types): <TAB> data = inputs[0] <TAB> axis = None <TAB> keepdims = False <TAB> if len(inputs) > 2:  # default, torch have only data, axis=None, keepdims=False <TAB>  <TAB> if isinstance(inputs[1], int): <TAB>  <TAB>  <TAB> axis = int(inputs[1]) <MASK> axis = inputs[1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> axis = list(_infer_shape(inputs[1])) <TAB>  <TAB> keepdims = bool(inputs[2]) <TAB> return get_relay_op(name)(data, axis=axis, keepdims=keepdims)",elif _is_int_seq ( inputs [ 1 ] ) :,158
281,"def walks_generator(): <TAB> if filelist is not None: <TAB>  <TAB> bucket = [] <TAB>  <TAB> for filename in filelist: <TAB>  <TAB>  <TAB> with io.open(filename) as inf: <TAB>  <TAB>  <TAB>  <TAB> for line in inf: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> walk = [int(x) for x in line.strip(""\n"").split("" "")] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> bucket.append(walk) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if len(bucket) == batch_size: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield bucket <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> bucket = [] <MASK> yield bucket <TAB> else: <TAB>  <TAB> for _ in range(epoch): <TAB>  <TAB>  <TAB> for nodes in graph.node_batch_iter(batch_size): <TAB>  <TAB>  <TAB>  <TAB> walks = graph.random_walk(nodes, walk_len) <TAB>  <TAB>  <TAB>  <TAB> yield walks",if len ( bucket ) :,198
282,"def _calculate_runtimes(states): <TAB> results = {""runtime"": 0.00, ""num_failed_states"": 0, ""num_passed_states"": 0} <TAB> for state, resultset in states.items(): <MASK> # Count the pass vs failures <TAB>  <TAB>  <TAB> if resultset[""result""]: <TAB>  <TAB>  <TAB>  <TAB> results[""num_passed_states""] += 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> results[""num_failed_states""] += 1 <TAB>  <TAB>  <TAB> # Count durations <TAB>  <TAB>  <TAB> results[""runtime""] += resultset[""duration""] <TAB> log.debug(""Parsed state metrics: {}"".format(results)) <TAB> return results","if isinstance ( resultset , dict ) and ""duration"" in resultset :",167
283,"def _replicator_primary_device() -> snt_replicator.Replicator: <TAB> # NOTE: The explicit device list is required since currently Replicator <TAB> # only considers CPU and GPU devices. This means on TPU by default we only <TAB> # mirror on the local CPU. <TAB> for device_type in (""TPU"", ""GPU"", ""CPU""): <TAB>  <TAB> devices = tf.config.experimental.list_logical_devices(device_type=device_type) <MASK> devices = [d.name for d in devices] <TAB>  <TAB>  <TAB> logging.info(""Replicating over %s"", devices) <TAB>  <TAB>  <TAB> return snt_replicator.Replicator(devices=devices) <TAB> assert False, ""No TPU/GPU or CPU found""",if devices :,180
284,"def get_tag_values(self, event): <TAB> http = event.interfaces.get(""sentry.interfaces.Http"") <TAB> if not http: <TAB>  <TAB> return [] <TAB> if not http.headers: <TAB>  <TAB> return [] <TAB> headers = http.headers <TAB> # XXX: transitional support for workers <TAB> if isinstance(headers, dict): <TAB>  <TAB> headers = headers.items() <TAB> output = [] <TAB> for key, value in headers: <MASK> continue <TAB>  <TAB> ua = Parse(value) <TAB>  <TAB> if not ua: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> result = self.get_tag_from_ua(ua) <TAB>  <TAB> if result: <TAB>  <TAB>  <TAB> output.append(result) <TAB> return output","if key != ""User-Agent"" :",176
285,"def general(metadata, value): <TAB> if metadata.get(""commands"") and value: <MASK> v = quote(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> v = value <TAB>  <TAB> return u""{0} {1}"".format(metadata[""commands""][0], v) <TAB> else: <TAB>  <TAB> if not value: <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> elif not metadata.get(""nargs""): <TAB>  <TAB>  <TAB> return quote(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return value","if not metadata . get ( ""nargs"" ) :",122
286,"def _actions_read(self, c): <TAB> self.action_input.handle_read(c) <TAB> if c in [curses.KEY_ENTER, util.KEY_ENTER2]: <TAB>  <TAB> # take action <TAB>  <TAB> if self.action_input.selected_index == 0:  # Cancel <TAB>  <TAB>  <TAB> self.back_to_parent() <TAB>  <TAB> elif self.action_input.selected_index == 1:  # Apply <TAB>  <TAB>  <TAB> self._apply_prefs() <TAB>  <TAB>  <TAB> client.core.get_config().addCallback(self._update_preferences) <MASK> # OK <TAB>  <TAB>  <TAB> self._apply_prefs() <TAB>  <TAB>  <TAB> self.back_to_parent()",elif self . action_input . selected_index == 2 :,174
287,def logic(): <TAB> if reset == 1: <TAB>  <TAB> lfsr.next = 1 <TAB> else: <MASK> # lfsr.next[24:1] = lfsr[23:0] <TAB>  <TAB>  <TAB> lfsr.next = lfsr << 1 <TAB>  <TAB>  <TAB> lfsr.next[0] = lfsr[23] ^ lfsr[22] ^ lfsr[21] ^ lfsr[16],if enable :,110
288,"def action_delete(self, request, attachments): <TAB> deleted_attachments = [] <TAB> desynced_posts = [] <TAB> for attachment in attachments: <MASK> deleted_attachments.append(attachment.pk) <TAB>  <TAB>  <TAB> desynced_posts.append(attachment.post_id) <TAB> if desynced_posts: <TAB>  <TAB> with transaction.atomic(): <TAB>  <TAB>  <TAB> for post in Post.objects.filter(id__in=desynced_posts): <TAB>  <TAB>  <TAB>  <TAB> self.delete_from_cache(post, deleted_attachments) <TAB> for attachment in attachments: <TAB>  <TAB> attachment.delete() <TAB> message = _(""Selected attachments have been deleted."") <TAB> messages.success(request, message)",if attachment . post :,165
289,"def __getitem__(self, index): <TAB> if self._check(): <TAB>  <TAB> if isinstance(index, int): <TAB>  <TAB>  <TAB> if index < 0 or index >= len(self.features): <TAB>  <TAB>  <TAB>  <TAB> raise IndexError(index) <TAB>  <TAB>  <TAB> if self.features[index] is None: <TAB>  <TAB>  <TAB>  <TAB> feature = self.device.feature_request(FEATURE.FEATURE_SET, 0x10, index) <TAB>  <TAB>  <TAB>  <TAB> if feature: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> (feature,) = _unpack(""!H"", feature[:2]) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.features[index] = FEATURE[feature] <TAB>  <TAB>  <TAB> return self.features[index] <MASK> indices = index.indices(len(self.features)) <TAB>  <TAB>  <TAB> return [self.__getitem__(i) for i in range(*indices)]","elif isinstance ( index , slice ) :",195
290,"def _skip_start(self): <TAB> start, stop = self.start, self.stop <TAB> for chunk in self.app_iter: <TAB>  <TAB> self._pos += len(chunk) <MASK> continue <TAB>  <TAB> elif self._pos == start: <TAB>  <TAB>  <TAB> return b"""" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> chunk = chunk[start - self._pos :] <TAB>  <TAB>  <TAB> if stop is not None and self._pos > stop: <TAB>  <TAB>  <TAB>  <TAB> chunk = chunk[: stop - self._pos] <TAB>  <TAB>  <TAB>  <TAB> assert len(chunk) == stop - start <TAB>  <TAB>  <TAB> return chunk <TAB> else: <TAB>  <TAB> raise StopIteration()",if self . _pos < start :,156
291,"def get_files(d): <TAB> f = [] <TAB> for root, dirs, files in os.walk(d): <TAB>  <TAB> for name in files: <MASK> continue <TAB>  <TAB>  <TAB> if ""qemux86copy-"" in root or ""qemux86-"" in root: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if ""do_build"" not in name and ""do_populate_sdk"" not in name: <TAB>  <TAB>  <TAB>  <TAB> f.append(os.path.join(root, name)) <TAB> return f","if ""meta-environment"" in root or ""cross-canadian"" in root :",143
292,"def _load_windows_store_certs(self, storename, purpose): <TAB> certs = bytearray() <TAB> try: <TAB>  <TAB> for cert, encoding, trust in enum_certificates(storename): <TAB>  <TAB>  <TAB> # CA certs are never PKCS#7 encoded <MASK> if trust is True or purpose.oid in trust: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> certs.extend(cert) <TAB> except PermissionError: <TAB>  <TAB> warnings.warn(""unable to enumerate Windows certificate store"") <TAB> if certs: <TAB>  <TAB> self.load_verify_locations(cadata=certs) <TAB> return certs","if encoding == ""x509_asn"" :",145
293,"def test_tokenizer_identifier_with_correct_config(self): <TAB> for tokenizer_class in [BertTokenizer, BertTokenizerFast, AutoTokenizer]: <TAB>  <TAB> tokenizer = tokenizer_class.from_pretrained(""wietsedv/bert-base-dutch-cased"") <TAB>  <TAB> self.assertIsInstance(tokenizer, (BertTokenizer, BertTokenizerFast)) <MASK> self.assertEqual(tokenizer.basic_tokenizer.do_lower_case, False) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertEqual(tokenizer.do_lower_case, False) <TAB>  <TAB> self.assertEqual(tokenizer.model_max_length, 512)","if isinstance ( tokenizer , BertTokenizer ) :",146
294,"def run(self): <TAB> global WAITING_BEFORE_START <TAB> time.sleep(WAITING_BEFORE_START) <TAB> while self.keep_alive: <TAB>  <TAB> path_id, module, resolve = self.queue_receive.get() <TAB>  <TAB> if path_id is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> self.lock.acquire() <TAB>  <TAB> self.modules[path_id] = module <TAB>  <TAB> self.lock.release() <MASK> resolution = self._resolve_with_other_modules(resolve) <TAB>  <TAB>  <TAB> self._relations[path_id] = [] <TAB>  <TAB>  <TAB> for package in resolution: <TAB>  <TAB>  <TAB>  <TAB> self._relations[path_id].append(resolution[package]) <TAB>  <TAB>  <TAB> self.queue_send.put((path_id, module, False, resolution))",if resolve :,190
295,"def __new__(mcs, name, bases, attrs): <TAB> include_profile = include_trace = include_garbage = True <TAB> bases = list(bases) <TAB> if name == ""SaltLoggingClass"": <TAB>  <TAB> for base in bases: <TAB>  <TAB>  <TAB> if hasattr(base, ""trace""): <TAB>  <TAB>  <TAB>  <TAB> include_trace = False <MASK> include_garbage = False <TAB> if include_profile: <TAB>  <TAB> bases.append(LoggingProfileMixin) <TAB> if include_trace: <TAB>  <TAB> bases.append(LoggingTraceMixin) <TAB> if include_garbage: <TAB>  <TAB> bases.append(LoggingGarbageMixin) <TAB> return super(LoggingMixinMeta, mcs).__new__(mcs, name, tuple(bases), attrs)","if hasattr ( base , ""garbage"" ) :",176
296,"def __str__(self, prefix="""", printElemNumber=0): <TAB> res = """" <TAB> if self.has_owner_: <TAB>  <TAB> res += prefix + (""owner: %s\n"" % self.DebugFormatString(self.owner_)) <TAB> cnt = 0 <TAB> for e in self.entries_: <TAB>  <TAB> elm = """" <MASK> elm = ""(%d)"" % cnt <TAB>  <TAB> res += prefix + (""entries%s <\n"" % elm) <TAB>  <TAB> res += e.__str__(prefix + ""  "", printElemNumber) <TAB>  <TAB> res += prefix + "">\n"" <TAB>  <TAB> cnt += 1 <TAB> return res",if printElemNumber :,154
297,"def parse_tag(self): <TAB> buf = [] <TAB> escaped = False <TAB> for c in self.get_next_chars(): <TAB>  <TAB> if escaped: <TAB>  <TAB>  <TAB> buf.append(c) <TAB>  <TAB> elif c == ""\\"": <TAB>  <TAB>  <TAB> escaped = True <MASK> return """".join(buf) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> buf.append(c) <TAB> raise Exception(""Unclosed tag "" + """".join(buf))","elif c == "">"" :",110
298,"def get_batches(train_nodes, train_labels, batch_size=64, shuffle=True): <TAB> if shuffle: <TAB>  <TAB> random.shuffle(train_nodes) <TAB> total = train_nodes.shape[0] <TAB> for i in range(0, total, batch_size): <MASK> cur_nodes = train_nodes[i : i + batch_size] <TAB>  <TAB>  <TAB> cur_labels = train_labels[cur_nodes] <TAB>  <TAB>  <TAB> yield cur_nodes, cur_labels",if i + batch_size <= total :,127
299,"def _get_all_info_lines(data): <TAB> infos = [] <TAB> for row in data: <TAB>  <TAB> splitrow = row.split() <TAB>  <TAB> if len(splitrow) > 0: <MASK> infos.append("" "".join(splitrow[1:])) <TAB> return infos","if splitrow [ 0 ] == ""INFO:"" :",82
300,"def _validate_client_public_key(self, username, key_data): <TAB> """"""Validate a client public key for the specified user"""""" <TAB> try: <TAB>  <TAB> key = decode_ssh_public_key(key_data) <TAB> except KeyImportError: <TAB>  <TAB> return None <TAB> options = None <TAB> if self._client_keys: <TAB>  <TAB> options = self._client_keys.validate(key, self._peer_addr) <TAB> if options is None: <TAB>  <TAB> result = self._owner.validate_public_key(username, key) <TAB>  <TAB> if asyncio.iscoroutine(result): <TAB>  <TAB>  <TAB> result = yield from result <MASK> return None <TAB>  <TAB> options = {} <TAB> self._key_options = options <TAB> return key",if not result :,177
301,"def attach_related_versions(addons, addon_dict=None): <TAB> if addon_dict is None: <TAB>  <TAB> addon_dict = {addon.id: addon for addon in addons} <TAB> all_ids = set(filter(None, (addon._current_version_id for addon in addons))) <TAB> versions = list(Version.objects.filter(id__in=all_ids).order_by()) <TAB> for version in versions: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> addon = addon_dict[version.addon_id] <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> log.info(""Version %s has an invalid add-on id."" % version.id) <TAB>  <TAB>  <TAB> continue <MASK> addon._current_version = version <TAB>  <TAB> version.addon = addon",if addon . _current_version_id == version . id :,200
302,"def move_view(obj, evt): <TAB> position = obj.GetCurrentCursorPosition() <TAB> for other_axis, axis_number in self._axis_names.iteritems(): <MASK> continue <TAB>  <TAB> ipw3d = getattr(self, ""ipw_3d_%s"" % other_axis) <TAB>  <TAB> ipw3d.ipw.slice_position = position[axis_number]",if other_axis == axis_name :,104
303,"def func_wrapper(*args, **kwargs): <TAB> warnings.simplefilter(""always"", DeprecationWarning)  # turn off filter <TAB> for old, new in arg_mapping.items(): <MASK> warnings.warn( <TAB>  <TAB>  <TAB>  <TAB> f""Keyword argument '{old}' has been "" <TAB>  <TAB>  <TAB>  <TAB> f""deprecated in favour of '{new}'. "" <TAB>  <TAB>  <TAB>  <TAB> f""'{old}' will be removed in a future version."", <TAB>  <TAB>  <TAB>  <TAB> category=DeprecationWarning, <TAB>  <TAB>  <TAB>  <TAB> stacklevel=2, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> val = kwargs.pop(old) <TAB>  <TAB>  <TAB> kwargs[new] = val <TAB> # reset filter <TAB> warnings.simplefilter(""default"", DeprecationWarning) <TAB> return func(*args, **kwargs)",if old in kwargs :,173
304,"def inner_connection_checker(self, *args, **kwargs): <TAB> LOG.debug(""in _connection_checker"") <TAB> for attempts in range(5): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return func(self, *args, **kwargs) <TAB>  <TAB> except exception.VolumeBackendAPIException as e: <TAB>  <TAB>  <TAB> pattern = re.compile(r"".*Session id expired$"") <TAB>  <TAB>  <TAB> matches = pattern.match(six.text_type(e)) <TAB>  <TAB>  <TAB> if matches: <MASK> LOG.debug(""Session might have expired."" "" Trying to relogin"") <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._login() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> LOG.error(""Re-throwing Exception %s"", e) <TAB>  <TAB>  <TAB> raise",if attempts < 4 :,182
305,"def set(self, pcount): <TAB> """"""Set channel prefetch_count setting."""""" <TAB> if pcount != self.prev: <TAB>  <TAB> new_value = pcount <MASK> logger.warning( <TAB>  <TAB>  <TAB>  <TAB> ""QoS: Disabled: prefetch_count exceeds %r"", PREFETCH_COUNT_MAX <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> new_value = 0 <TAB>  <TAB> logger.debug(""basic.qos: prefetch_count->%s"", new_value) <TAB>  <TAB> self.callback(prefetch_count=new_value) <TAB>  <TAB> self.prev = pcount <TAB> return pcount",if pcount > PREFETCH_COUNT_MAX :,146
306,"def _build_gcs_object_key(self, key): <TAB> if self.platform_specific_separator: <MASK> gcs_object_key = os.path.join( <TAB>  <TAB>  <TAB>  <TAB> self.prefix, self._convert_key_to_filepath(key) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> gcs_object_key = self._convert_key_to_filepath(key) <TAB> else: <TAB>  <TAB> if self.prefix: <TAB>  <TAB>  <TAB> gcs_object_key = ""/"".join((self.prefix, self._convert_key_to_filepath(key))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> gcs_object_key = self._convert_key_to_filepath(key) <TAB> return gcs_object_key",if self . prefix :,185
307,"def number_operators(self, a, b, skip=[]): <TAB> dict = {""a"": a, ""b"": b} <TAB> for name, expr in self.binops.items(): <MASK> name = ""__%s__"" % name <TAB>  <TAB>  <TAB> if hasattr(a, name): <TAB>  <TAB>  <TAB>  <TAB> res = eval(expr, dict) <TAB>  <TAB>  <TAB>  <TAB> self.binop_test(a, b, res, expr, name) <TAB> for name, expr in self.unops.items(): <TAB>  <TAB> if name not in skip: <TAB>  <TAB>  <TAB> name = ""__%s__"" % name <TAB>  <TAB>  <TAB> if hasattr(a, name): <TAB>  <TAB>  <TAB>  <TAB> res = eval(expr, dict) <TAB>  <TAB>  <TAB>  <TAB> self.unop_test(a, res, expr, name)",if name not in skip :,187
308,def isCurveMonotonic(set_): <TAB> for i in range(len(set_) - 1): <TAB>  <TAB> # ==== added by zli ======= <MASK> return False <TAB>  <TAB> # ==== added by zli ======= <TAB>  <TAB> # ==== added by zli ======= <TAB>  <TAB> # if set_[i][1] > set_[i + 1][1]: <TAB>  <TAB> if set_[i][1] >= set_[i + 1][1]: <TAB>  <TAB>  <TAB> # ==== added by zli ======= <TAB>  <TAB>  <TAB> return False <TAB> return True,if set_ [ i ] [ 0 ] >= set_ [ i + 1 ] [ 0 ] :,141
309,"def show_topics(): <TAB> """"""prints all available miscellaneous help topics."""""" <TAB> print(_stash.text_color(""Miscellaneous Topics:"", ""yellow"")) <TAB> for pp in PAGEPATHS: <MASK> continue <TAB>  <TAB> content = os.listdir(pp) <TAB>  <TAB> for pn in content: <TAB>  <TAB>  <TAB> if ""."" in pn: <TAB>  <TAB>  <TAB>  <TAB> name = pn[: pn.index(""."")] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> name = pn <TAB>  <TAB>  <TAB> print(name)",if not os . path . isdir ( pp ) :,125
310,"def test_send_error(self): <TAB> allow_transfer_encoding_codes = (205, 304) <TAB> for code in (101, 102, 204, 205, 304): <TAB>  <TAB> self.con.request(""SEND_ERROR"", ""/{}"".format(code)) <TAB>  <TAB> res = self.con.getresponse() <TAB>  <TAB> self.assertEqual(code, res.status) <TAB>  <TAB> self.assertEqual(None, res.getheader(""Content-Length"")) <TAB>  <TAB> self.assertEqual(None, res.getheader(""Content-Type"")) <MASK> self.assertEqual(None, res.getheader(""Transfer-Encoding"")) <TAB>  <TAB> data = res.read() <TAB>  <TAB> self.assertEqual(b"""", data)",if code not in allow_transfer_encoding_codes :,173
311,"def _length_hint(obj): <TAB> """"""Returns the length hint of an object."""""" <TAB> try: <TAB>  <TAB> return len(obj) <TAB> except (AttributeError, TypeError): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> get_hint = type(obj).__length_hint__ <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> hint = get_hint(obj) <TAB>  <TAB> except TypeError: <TAB>  <TAB>  <TAB> return None <MASK> return None <TAB>  <TAB> return hint","if hint is NotImplemented or not isinstance ( hint , int_types ) or hint < 0 :",135
312,"def _rmtree(self, path): <TAB> # Essentially a stripped down version of shutil.rmtree.  We can't <TAB> # use globals because they may be None'ed out at shutdown. <TAB> for name in self._listdir(path): <TAB>  <TAB> fullname = self._path_join(path, name) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> isdir = self._isdir(fullname) <TAB>  <TAB> except self._os_error: <TAB>  <TAB>  <TAB> isdir = False <MASK> self._rmtree(fullname) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> self._remove(fullname) <TAB>  <TAB>  <TAB> except self._os_error: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB> try: <TAB>  <TAB> self._rmdir(path) <TAB> except self._os_error: <TAB>  <TAB> pass",if isdir :,183
313,"def get_sources(self, sources=None): <TAB> """"""Returns all sources from this provider."""""" <TAB> self._load() <TAB> if sources is None: <TAB>  <TAB> sources = list(self.data.keys()) <TAB> elif not isinstance(sources, (list, tuple)): <TAB>  <TAB> sources = [sources] <TAB> for source in sources: <MASK> raise KeyError( <TAB>  <TAB>  <TAB>  <TAB> ""Invalid data key: {}. Valid keys are: {}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> source, "", "".join(str(k) for k in self.data) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> return {k: self.data[k] for k in sources}",if source not in self . data :,163
314,"def do_shorts( <TAB> opts: List[Tuple[str, str]], optstring: str, shortopts: str, args: List[str]) -> Tuple[List[Tuple[str, str]], List[str]]: <TAB> while optstring != """": <TAB>  <TAB> opt, optstring = optstring[0], optstring[1:] <TAB>  <TAB> if short_has_arg(opt, shortopts): <MASK> if not args: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise GetoptError(""option -%s requires argument"" % opt, opt) <TAB>  <TAB>  <TAB>  <TAB> optstring, args = args[0], args[1:] <TAB>  <TAB>  <TAB> optarg, optstring = optstring, """" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> optarg = """" <TAB>  <TAB> opts.append((""-"" + opt, optarg)) <TAB> return opts, args","if optstring == """" :",183
315,"def _sanitize_dict(self, config_dict, allow_val_change=None, ignore_keys: set = None): <TAB> sanitized = {} <TAB> for k, v in six.iteritems(config_dict): <MASK> continue <TAB>  <TAB> k, v = self._sanitize(k, v, allow_val_change) <TAB>  <TAB> sanitized[k] = v <TAB> return sanitized",if ignore_keys and k in ignore_keys :,104
316,def x(data): <TAB> count = 0 <TAB> while count < 10: <TAB>  <TAB> data.start_example(SOME_LABEL) <TAB>  <TAB> b = data.draw_bits(1) <MASK> count += 1 <TAB>  <TAB> data.stop_example(discard=not b) <TAB> data.mark_interesting(),if b :,79
317,"def prompt_for_resume(config): <TAB> logger = logging.getLogger(""changeme"") <TAB> logger.error( <TAB>  <TAB> ""A previous scan was interrupted. Type R to resume or F to start a fresh scan"" <TAB> ) <TAB> answer = """" <TAB> while not (answer == ""R"" or answer == ""F""): <TAB>  <TAB> prompt = ""(R/F)> "" <TAB>  <TAB> answer = """" <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> answer = raw_input(prompt) <TAB>  <TAB> except NameError: <TAB>  <TAB>  <TAB> answer = input(prompt) <TAB>  <TAB> if answer.upper() == ""F"": <TAB>  <TAB>  <TAB> logger.debug(""Forcing a fresh scan"") <MASK> logger.debug(""Resuming previous scan"") <TAB>  <TAB>  <TAB> config.resume = True <TAB> return config.resume","elif answer . upper ( ) == ""R"" :",189
318,"def _evaluate_local_single(self, iterator): <TAB> for batch in iterator: <TAB>  <TAB> in_arrays = convert._call_converter(self.converter, batch, self.device) <TAB>  <TAB> with function.no_backprop_mode(): <MASK> results = self.calc_local(*in_arrays) <TAB>  <TAB>  <TAB> elif isinstance(in_arrays, dict): <TAB>  <TAB>  <TAB>  <TAB> results = self.calc_local(**in_arrays) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> results = self.calc_local(in_arrays) <TAB>  <TAB> if self._progress_hook: <TAB>  <TAB>  <TAB> self._progress_hook(batch) <TAB>  <TAB> yield results","if isinstance ( in_arrays , tuple ) :",166
319,"def _send_until_done(self, data): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self.connection.send(data) <TAB>  <TAB> except OpenSSL.SSL.WantWriteError: <MASK> raise timeout() <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> except OpenSSL.SSL.SysCallError as e: <TAB>  <TAB>  <TAB> raise SocketError(str(e))","if not util . wait_for_write ( self . socket , self . socket . gettimeout ( ) ) :",112
320,"def _read_jtl_chunk(self, jtl): <TAB> data = jtl.read(1024 * 1024 * 10) <TAB> if data: <TAB>  <TAB> parts = data.rsplit(""\n"", 1) <MASK> ready_chunk = self.buffer + parts[0] + ""\n"" <TAB>  <TAB>  <TAB> self.buffer = parts[1] <TAB>  <TAB>  <TAB> df = string_to_df(ready_chunk) <TAB>  <TAB>  <TAB> self.stat_queue.put(df) <TAB>  <TAB>  <TAB> return df <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.buffer += parts[0] <TAB> else: <TAB>  <TAB> if self.jmeter_finished: <TAB>  <TAB>  <TAB> self.agg_finished = True <TAB>  <TAB> jtl.readline() <TAB> return None",if len ( parts ) > 1 :,182
321,"def __new__(mcl, classname, bases, dictionary): <TAB> slots = list(dictionary.get(""__slots__"", [])) <TAB> for getter_name in [key for key in dictionary if key.startswith(""get_"")]: <TAB>  <TAB> name = getter_name <TAB>  <TAB> slots.append(""__"" + name) <TAB>  <TAB> getter = dictionary.pop(getter_name) <TAB>  <TAB> setter = dictionary.get(setter_name, None) <MASK> del dictionary[setter_name] <TAB>  <TAB> dictionary[name] = property(getter.setter) <TAB>  <TAB> dictionary[""__slots__""] = tuple(slots) <TAB>  <TAB> return super().__new__(mcl, classname, bases, dictionary)","if setter is not None and isinstance ( setter , collections . Callable ) :",166
322,"def tex_coords(self): <TAB> """"""Array of texture coordinate data."""""" <TAB> if ""multi_tex_coords"" not in self.domain.attribute_names: <MASK> domain = self.domain <TAB>  <TAB>  <TAB> attribute = domain.attribute_names[""tex_coords""] <TAB>  <TAB>  <TAB> self._tex_coords_cache = attribute.get_region( <TAB>  <TAB>  <TAB>  <TAB> attribute.buffer, self.start, self.count <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self._tex_coords_cache_version = domain._version <TAB>  <TAB> region = self._tex_coords_cache <TAB>  <TAB> region.invalidate() <TAB>  <TAB> return region.array <TAB> else: <TAB>  <TAB> return None",if self . _tex_coords_cache_version != self . domain . _version :,173
323,"def index(self, sub, start=0): <TAB> """"""Returns the index of the closing bracket"""""" <TAB> br = ""([{<""["")]}>"".index(sub)] <TAB> count = 0 <TAB> for i in range(start, len(self.string)): <TAB>  <TAB> char = self.string[i] <MASK> count += 1 <TAB>  <TAB> elif char == sub: <TAB>  <TAB>  <TAB> if count > 0: <TAB>  <TAB>  <TAB>  <TAB> count -= 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return i <TAB> err = ""Closing bracket {!r} missing in string {!r}"".format( <TAB>  <TAB> sub, """".join(self.original) <TAB> ) <TAB> raise ParseError(err)",if char == br :,161
324,"def test_createFile(self): <TAB> text = ""This is a test!"" <TAB> path = tempfile.mktemp() <TAB> try: <TAB>  <TAB> koDoc = self._koDocFromPath(path, load=False) <TAB>  <TAB> koDoc.buffer = text <TAB>  <TAB> koDoc.save(0) <TAB>  <TAB> del koDoc <TAB>  <TAB> koDoc2 = self._koDocFromPath(path) <TAB>  <TAB> assert koDoc2.buffer == text <TAB> finally: <MASK> os.unlink(path)  # clean up",if os . path . exists ( path ) :,134
325,"def __editScopeHasEdit(self, attributeHistory): <TAB> with attributeHistory.context: <TAB>  <TAB> tweak = GafferScene.EditScopeAlgo.acquireParameterEdit( <TAB>  <TAB>  <TAB> attributeHistory.scene.node(), <TAB>  <TAB>  <TAB> attributeHistory.context[""scene:path""], <TAB>  <TAB>  <TAB> attributeHistory.attributeName, <TAB>  <TAB>  <TAB> IECoreScene.ShaderNetwork.Parameter("""", self.__parameter), <TAB>  <TAB>  <TAB> createIfNecessary=False, <TAB>  <TAB> ) <MASK> return False <TAB>  <TAB> return tweak[""enabled""].getValue()",if tweak is None :,139
326,"def mail_migrator(app, schema_editor): <TAB> Event_SettingsStore = app.get_model(""pretixbase"", ""Event_SettingsStore"") <TAB> for ss in Event_SettingsStore.objects.filter( <TAB>  <TAB> key__in=[ <TAB>  <TAB>  <TAB> ""mail_text_order_approved"", <TAB>  <TAB>  <TAB> ""mail_text_order_placed"", <TAB>  <TAB>  <TAB> ""mail_text_order_placed_require_approval"", <TAB>  <TAB> ] <TAB> ): <TAB>  <TAB> chgd = ss.value.replace(""{date}"", ""{expire_date}"") <MASK> ss.value = chgd <TAB>  <TAB>  <TAB> ss.save() <TAB>  <TAB>  <TAB> cache.delete(""hierarkey_{}_{}"".format(""event"", ss.object_id))",if chgd != ss . value :,179
327,"def __get_limits(self): <TAB> dimension = len(self.__tree.get_root().data) <TAB> nodes = self.__get_all_nodes() <TAB> max, min = [float(""-inf"")] * dimension, [float(""+inf"")] * dimension <TAB> for node in nodes: <TAB>  <TAB> for d in range(dimension): <TAB>  <TAB>  <TAB> if max[d] < node.data[d]: <TAB>  <TAB>  <TAB>  <TAB> max[d] = node.data[d] <MASK> min[d] = node.data[d] <TAB> return min, max",if min [ d ] > node . data [ d ] :,145
328,"def get_complete_position(self, context: UserContext) -> int: <TAB> # Check member prefix pattern. <TAB> for prefix_pattern in convert2list( <TAB>  <TAB> self.get_filetype_var(context[""filetype""], ""prefix_patterns"") <TAB> ): <TAB>  <TAB> m = re.search(self._object_pattern + prefix_pattern + r""\w*$"", context[""input""]) <MASK> continue <TAB>  <TAB> self._prefix = re.sub(r""\w*$"", """", m.group(0)) <TAB>  <TAB> m = re.search(r""\w*$"", context[""input""]) <TAB>  <TAB> if m: <TAB>  <TAB>  <TAB> return m.start() <TAB> return -1","if m is None or prefix_pattern == """" :",166
329,"def _stderr_supports_color(): <TAB> try: <TAB>  <TAB> if hasattr(sys.stderr, ""isatty"") and sys.stderr.isatty(): <TAB>  <TAB>  <TAB> if curses: <TAB>  <TAB>  <TAB>  <TAB> curses.setupterm() <TAB>  <TAB>  <TAB>  <TAB> if curses.tigetnum(""colors"") > 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <MASK> if sys.stderr is getattr( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> colorama.initialise, ""wrapped_stderr"", object() <TAB>  <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> except Exception: <TAB>  <TAB> # Very broad exception handling because it's always better to <TAB>  <TAB> # fall back to non-colored logs than to break at startup. <TAB>  <TAB> pass <TAB> return False",elif colorama :,170
330,"def setLabelColumnWidth(self, panel, width): <TAB> for child in panel.GetChildren(): <MASK> size = child.GetSize() <TAB>  <TAB>  <TAB> size[0] = width <TAB>  <TAB>  <TAB> child.SetBestSize(size)","if isinstance ( child , wx . lib . stattext . GenStaticText ) :",74
331,"def update(self, other): <TAB> if other.M is None: <MASK> self.items.update(other.items) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for i in other.items: <TAB>  <TAB>  <TAB>  <TAB> self.add(i) <TAB>  <TAB> return <TAB> if self.M is None: <TAB>  <TAB> self.convert() <TAB> self.M = array.array(""B"", list(map(max, list(zip(self.M, other.M)))))",if self . M is None :,119
332,"def on_end_epoch(self, state): <TAB> if self.write_epoch_metrics: <MASK> self.writer.add_text( <TAB>  <TAB>  <TAB>  <TAB> ""epoch"", <TAB>  <TAB>  <TAB>  <TAB> ""<h4>Epoch {}</h4>"".format(state[torchbearer.EPOCH]) <TAB>  <TAB>  <TAB>  <TAB> + self.table_formatter(str(state[torchbearer.METRICS])), <TAB>  <TAB>  <TAB>  <TAB> 1, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.writer.add_text( <TAB>  <TAB>  <TAB>  <TAB> ""epoch"", <TAB>  <TAB>  <TAB>  <TAB> self.table_formatter(str(state[torchbearer.METRICS])), <TAB>  <TAB>  <TAB>  <TAB> state[torchbearer.EPOCH], <TAB>  <TAB>  <TAB> )",if self . visdom :,174
333,"def is_listening_for_message(conversation_id: Text, endpoint: EndpointConfig) -> bool: <TAB> """"""Check if the conversation is in need for a user message."""""" <TAB> tracker = await retrieve_tracker(endpoint, conversation_id, EventVerbosity.APPLIED) <TAB> for i, e in enumerate(reversed(tracker.get(""events"", []))): <MASK> return False <TAB>  <TAB> elif e.get(""event"") == ActionExecuted.type_name: <TAB>  <TAB>  <TAB> return e.get(""name"") == ACTION_LISTEN_NAME <TAB> return False","if e . get ( ""event"" ) == UserUttered . type_name :",154
334,"def filter_ports(self, dpid, in_port, nw_id, allow_nw_id_external=None): <TAB> assert nw_id != self.nw_id_unknown <TAB> ret = [] <TAB> for port in self.get_ports(dpid): <TAB>  <TAB> nw_id_ = port.network_id <MASK> continue <TAB>  <TAB> if nw_id_ == nw_id: <TAB>  <TAB>  <TAB> ret.append(port.port_no) <TAB>  <TAB> elif allow_nw_id_external is not None and nw_id_ == allow_nw_id_external: <TAB>  <TAB>  <TAB> ret.append(port.port_no) <TAB> return ret",if port . port_no == in_port :,167
335,"def next_month(billing_cycle_anchor: datetime, dt: datetime) -> datetime: <TAB> estimated_months = round((dt - billing_cycle_anchor).days * 12.0 / 365) <TAB> for months in range(max(estimated_months - 1, 0), estimated_months + 2): <TAB>  <TAB> proposed_next_month = add_months(billing_cycle_anchor, months) <MASK> return proposed_next_month <TAB> raise AssertionError( <TAB>  <TAB> ""Something wrong in next_month calculation with "" <TAB>  <TAB> f""billing_cycle_anchor: {billing_cycle_anchor}, dt: {dt}"" <TAB> )",if 20 < ( proposed_next_month - dt ) . days < 40 :,165
336,"def wait_complete(self): <TAB> """"""Wait for futures complete done."""""" <TAB> for future in concurrent.futures.as_completed(self._futures.keys()): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> error = future.exception() <TAB>  <TAB> except concurrent.futures.CancelledError: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> name = self._futures[future] <MASK> err_msg = 'Extracting ""{0}"", got: {1}'.format(name, error) <TAB>  <TAB>  <TAB> logger.error(err_msg)",if error is not None :,124
337,"def _accept_with(cls, orm, target): <TAB> if target is orm.mapper: <TAB>  <TAB> return mapperlib.Mapper <TAB> elif isinstance(target, type): <TAB>  <TAB> if issubclass(target, mapperlib.Mapper): <TAB>  <TAB>  <TAB> return target <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> mapper = _mapper_or_none(target) <MASK> return mapper <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return _MapperEventsHold(target) <TAB> else: <TAB>  <TAB> return target",if mapper is not None :,123
338,"def gvariant_args(args: List[Any]) -> str: <TAB> """"""Convert args into gvariant."""""" <TAB> gvariant = """" <TAB> for arg in args: <MASK> gvariant += "" {}"".format(str(arg).lower()) <TAB>  <TAB> elif isinstance(arg, (int, float)): <TAB>  <TAB>  <TAB> gvariant += f"" {arg}"" <TAB>  <TAB> elif isinstance(arg, str): <TAB>  <TAB>  <TAB> gvariant += f' ""{arg}""' <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> gvariant += f"" {arg!s}"" <TAB> return gvariant.lstrip()","if isinstance ( arg , bool ) :",139
339,"def _list_cases(suite): <TAB> for test in suite: <TAB>  <TAB> if isinstance(test, unittest.TestSuite): <TAB>  <TAB>  <TAB> _list_cases(test) <MASK> if support.match_test(test): <TAB>  <TAB>  <TAB>  <TAB> print(test.id())","elif isinstance ( test , unittest . TestCase ) :",75
340,def get_and_set_all_disambiguation(self): <TAB> all_disambiguations = [] <TAB> for page in self.pages: <MASK> all_disambiguations.extend(page.relations.disambiguation_links_norm) <TAB>  <TAB> if page.relations.disambiguation_links is not None: <TAB>  <TAB>  <TAB> all_disambiguations.extend(page.relations.disambiguation_links) <TAB> return set(all_disambiguations),if page . relations . disambiguation_links_norm is not None :,113
341,"def test_decode_invalid(self): <TAB> testcases = [ <TAB>  <TAB> (b""xn--w&"", ""strict"", UnicodeError()), <TAB>  <TAB> (b""xn--w&"", ""ignore"", ""xn-""), <TAB> ] <TAB> for puny, errors, expected in testcases: <TAB>  <TAB> with self.subTest(puny=puny, errors=errors): <MASK> self.assertRaises(UnicodeError, puny.decode, ""punycode"", errors) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(puny.decode(""punycode"", errors), expected)","if isinstance ( expected , Exception ) :",144
342,"def find_globs(walker, patterns, matches): <TAB> for root, dirs, files in walker: <TAB>  <TAB> for d in dirs: <TAB>  <TAB>  <TAB> d = join(root, d) <TAB>  <TAB>  <TAB> for pattern in patterns: <TAB>  <TAB>  <TAB>  <TAB> for p in Path(d).glob(pattern): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> matches.add(str(p)) <TAB>  <TAB> sub_files = set() <TAB>  <TAB> for p in matches: <MASK> for f in files: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> sub_files.add(join(root, f)) <TAB>  <TAB> matches.update(sub_files)",if root . startswith ( p ) :,149
343,"def parse_stack_trace(self, it, line): <TAB> """"""Iterate over lines and parse stack traces."""""" <TAB> events = [] <TAB> stack_traces = [] <TAB> while self.stack_trace_re.match(line): <TAB>  <TAB> event = self.parse_stack_trace_line(line) <MASK> events.append(event) <TAB>  <TAB> stack_traces.append(line) <TAB>  <TAB> line = get_next(it) <TAB> events.reverse() <TAB> return stack_traces, events, line",if event :,123
344,"def process(self): <TAB> """"""Do processing necessary, storing result in feature."""""" <TAB> summation = 0  # count of all <TAB> histo = self.data[""flat.notes.quarterLengthHistogram""] <TAB> if not histo: <TAB>  <TAB> raise NativeFeatureException(""input lacks notes"") <TAB> maxKey = 0  # max found for any one key <TAB> for key in histo: <TAB>  <TAB> # all defined keys should be greater than zero, but just in case <TAB>  <TAB> if histo[key] > 0: <TAB>  <TAB>  <TAB> summation += histo[key] <MASK> maxKey = histo[key] <TAB> self.feature.vector[0] = maxKey / summation",if histo [ key ] >= maxKey :,169
345,"def load_resource(name): <TAB> """"""return file contents for files within the package root folder"""""" <TAB> try: <MASK> return sublime.load_resource(""Packages/Markdown Preview/{0}"".format(name)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> filename = os.path.join( <TAB>  <TAB>  <TAB>  <TAB> sublime.packages_path(), INSTALLED_DIRECTORY, os.path.normpath(name) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return load_utf8(filename) <TAB> except: <TAB>  <TAB> print(""Error while load_resource('%s')"" % name) <TAB>  <TAB> traceback.print_exc() <TAB>  <TAB> return """"",if is_ST3 ( ) :,154
346,"def get_password(self, service, repo_url): <TAB> if self.is_unlocked: <TAB>  <TAB> asyncio.set_event_loop(asyncio.new_event_loop()) <TAB>  <TAB> collection = secretstorage.get_default_collection(self.connection) <TAB>  <TAB> attributes = {""application"": ""Vorta"", ""service"": service, ""repo_url"": repo_url} <TAB>  <TAB> items = list(collection.search_items(attributes)) <TAB>  <TAB> logger.debug(""Found %i passwords matching repo URL."", len(items)) <MASK> return items[0].get_secret().decode(""utf-8"") <TAB> return None",if len ( items ) > 0 :,156
347,"def get_files(d): <TAB> res = [] <TAB> for p in glob.glob(os.path.join(d, ""*"")): <TAB>  <TAB> if not p: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> (pth, fname) = os.path.split(p) <TAB>  <TAB> if fname == ""output"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if fname == ""PureMVC_Python_1_0"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if fname[-4:] == "".pyc"":  # ehmm.. no. <TAB>  <TAB>  <TAB> continue <MASK> get_dir(p) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> res.append(p) <TAB> return res",if os . path . isdir ( p ) :,162
348,"def test_nic_names(self): <TAB> p = subprocess.Popen([""ipconfig"", ""/all""], stdout=subprocess.PIPE) <TAB> out = p.communicate()[0] <TAB> if PY3: <TAB>  <TAB> out = str(out, sys.stdout.encoding) <TAB> nics = psutil.net_io_counters(pernic=True).keys() <TAB> for nic in nics: <MASK> continue <TAB>  <TAB> if nic not in out: <TAB>  <TAB>  <TAB> self.fail(""%r nic wasn't found in 'ipconfig /all' output"" % nic)","if ""pseudo-interface"" in nic . replace ( "" "" , ""-"" ) . lower ( ) :",145
349,"def vexop_to_simop(op, extended=True, fp=True): <TAB> res = operations.get(op) <TAB> if res is None and extended: <TAB>  <TAB> attrs = op_attrs(op) <MASK> raise UnsupportedIROpError(""Operation not implemented"") <TAB>  <TAB> res = SimIROp(op, **attrs) <TAB> if res is None: <TAB>  <TAB> raise UnsupportedIROpError(""Operation not implemented"") <TAB> if res._float and not fp: <TAB>  <TAB> raise UnsupportedIROpError(""Floating point support disabled"") <TAB> return res",if attrs is None :,141
350,"def rule_builder_add_value(self, value, screenshot_name=None): <TAB> rule_builder = self.components.rule_builder <TAB> rule_builder.menu_button_column.wait_for_and_click() <TAB> with self.rule_builder_rule_editor(""add-column-value"") as editor_element: <TAB>  <TAB> filter_input = editor_element.find_element_by_css_selector(""input[type='text']"") <TAB>  <TAB> filter_input.clear() <TAB>  <TAB> filter_input.send_keys(value) <MASK> self.screenshot(screenshot_name)",if screenshot_name :,147
351,"def make_open_socket(self): <TAB> s = socket.socket() <TAB> try: <TAB>  <TAB> s.bind(DEFAULT_BIND_ADDR_TUPLE) <MASK> # Windows and linux (with psutil) doesn't show as open until <TAB>  <TAB>  <TAB> # we call listen (linux with lsof accepts either) <TAB>  <TAB>  <TAB> s.listen(1) <TAB>  <TAB> self.assert_open(s, s.fileno()) <TAB> except: <TAB>  <TAB> s.close() <TAB>  <TAB> s = None <TAB>  <TAB> raise <TAB> return s",if WIN or greentest . LINUX :,135
352,"def handle_ray_task_error(e): <TAB> for s in e.traceback_str.split(""\n"")[::-1]: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> raise getattr(builtins, s.split("":"")[0])("""".join(s.split("":"")[1:])) <TAB>  <TAB>  <TAB> except AttributeError as att_err: <TAB>  <TAB>  <TAB>  <TAB> if ""module"" in str(att_err) and builtins.__name__ in str(att_err): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise att_err <TAB> raise e","if ""Error"" in s or ""Exception"" in s :",144
353,"def compare_multiple_events(i, expected_results, actual_results): <TAB> events_in_a_row = [] <TAB> j = i <TAB> while j < len(expected_results) and isinstance( <TAB>  <TAB> actual_results[j], actual_results[i].__class__ <TAB> ): <TAB>  <TAB> events_in_a_row.append(actual_results[j]) <TAB>  <TAB> j += 1 <TAB> message = """" <TAB> for event in events_in_a_row: <TAB>  <TAB> for k in range(i, j): <TAB>  <TAB>  <TAB> passed, message = compare_events(expected_results[k], event) <MASK> expected_results[k] = None <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return i, False, message <TAB> return j, True, """"",if passed :,192
354,"def ListSubscriptions(self, params): <TAB> queryreturn = sqlQuery(""""""SELECT label, address, enabled FROM subscriptions"""""") <TAB> data = '{""subscriptions"":[' <TAB> for row in queryreturn: <TAB>  <TAB> label, address, enabled = row <TAB>  <TAB> label = shared.fixPotentiallyInvalidUTF8Data(label) <MASK> data += "","" <TAB>  <TAB> data += json.dumps( <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB> ""label"": label.encode(""base64""), <TAB>  <TAB>  <TAB>  <TAB> ""address"": address, <TAB>  <TAB>  <TAB>  <TAB> ""enabled"": enabled == 1, <TAB>  <TAB>  <TAB> }, <TAB>  <TAB>  <TAB> indent=4, <TAB>  <TAB>  <TAB> separators=("","", "": ""), <TAB>  <TAB> ) <TAB> data += ""]}"" <TAB> return data",if len ( data ) > 20 :,177
355,"def compile(self, args): <TAB> compiled_args = {} <TAB> for key, value in six.iteritems(args): <MASK> compiled_args[key] = str(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> compiled_args[key] = sjson_dumps(value) <TAB> return self._minified_code % compiled_args",if key in self . clean_args :,91
356,"def insert(self, pack_id, data): <TAB> if (pack_id not in self.queue) and pack_id > self.begin_id: <TAB>  <TAB> self.queue[pack_id] = PacketInfo(data) <TAB>  <TAB> if self.end_id == pack_id: <TAB>  <TAB>  <TAB> self.end_id = pack_id + 1 <MASK> eid = self.end_id <TAB>  <TAB>  <TAB> while eid < pack_id: <TAB>  <TAB>  <TAB>  <TAB> self.miss_queue.add(eid) <TAB>  <TAB>  <TAB>  <TAB> eid += 1 <TAB>  <TAB>  <TAB> self.end_id = pack_id + 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.miss_queue.remove(pack_id)",elif self . end_id < pack_id :,182
357,"def _target_generator(self): <TAB> # since we do not have predictions yet, so we ignore sampling here <TAB> if self._internal_target_generator is None: <MASK> return None <TAB>  <TAB> from ....model_zoo.ssd.target import SSDTargetGenerator <TAB>  <TAB> self._internal_target_generator = SSDTargetGenerator( <TAB>  <TAB>  <TAB> iou_thresh=self._iou_thresh, <TAB>  <TAB>  <TAB> stds=self._box_norm, <TAB>  <TAB>  <TAB> negative_mining_ratio=-1, <TAB>  <TAB>  <TAB> **self._kwargs <TAB>  <TAB> ) <TAB>  <TAB> return self._internal_target_generator <TAB> else: <TAB>  <TAB> return self._internal_target_generator",if self . _anchors_none :,166
358,"def test_heapsort(self): <TAB> # Exercise everything with repeated heapsort checks <TAB> for trial in range(100): <TAB>  <TAB> size = random.randrange(50) <TAB>  <TAB> data = [random.randrange(25) for i in range(size)] <MASK> # Half of the time, use heapify <TAB>  <TAB>  <TAB> heap = data[:] <TAB>  <TAB>  <TAB> self.module.heapify(heap) <TAB>  <TAB> else:  # The rest of the time, use heappush <TAB>  <TAB>  <TAB> heap = [] <TAB>  <TAB>  <TAB> for item in data: <TAB>  <TAB>  <TAB>  <TAB> self.module.heappush(heap, item) <TAB>  <TAB> heap_sorted = [self.module.heappop(heap) for i in range(size)] <TAB>  <TAB> self.assertEqual(heap_sorted, sorted(data))",if trial & 1 :,189
359,"def wait(self, timeout=None): <TAB> if self.returncode is None: <TAB>  <TAB> if timeout is None: <TAB>  <TAB>  <TAB> msecs = _subprocess.INFINITE <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> msecs = max(0, int(timeout * 1000 + 0.5)) <TAB>  <TAB> res = _subprocess.WaitForSingleObject(int(self._handle), msecs) <MASK> code = _subprocess.GetExitCodeProcess(self._handle) <TAB>  <TAB>  <TAB> if code == TERMINATE: <TAB>  <TAB>  <TAB>  <TAB> code = -signal.SIGTERM <TAB>  <TAB>  <TAB> self.returncode = code <TAB> return self.returncode",if res == _subprocess . WAIT_OBJECT_0 :,154
360,"def _on_change(self): <TAB> changed = False <TAB> self.save() <TAB> for key, value in self.data.items(): <TAB>  <TAB> if isinstance(value, bool): <TAB>  <TAB>  <TAB> if value: <TAB>  <TAB>  <TAB>  <TAB> changed = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if isinstance(value, int): <TAB>  <TAB>  <TAB> if value != 1: <TAB>  <TAB>  <TAB>  <TAB> changed = True <TAB>  <TAB>  <TAB>  <TAB> break <MASK> continue <TAB>  <TAB> elif len(value) != 0: <TAB>  <TAB>  <TAB> changed = True <TAB>  <TAB>  <TAB> break <TAB> self._reset_button.disabled = not changed",elif value is None :,145
361,"def isnotsurplus(self, item: T) -> bool: <TAB> if not self.matchers: <MASK> self.mismatch_description.append_text( <TAB>  <TAB>  <TAB>  <TAB> ""not matched: "" <TAB>  <TAB>  <TAB> ).append_description_of(item) <TAB>  <TAB> return False <TAB> return True",if self . mismatch_description :,80
362,"def resolve_env_secrets(config, environ): <TAB> """"""Create copy that recursively replaces {""$env"": ""NAME""} with values from environ"""""" <TAB> if isinstance(config, dict): <MASK> return environ.get(list(config.values())[0]) <TAB>  <TAB> elif list(config.keys()) == [""$file""]: <TAB>  <TAB>  <TAB> return open(list(config.values())[0]).read() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return { <TAB>  <TAB>  <TAB>  <TAB> key: resolve_env_secrets(value, environ) <TAB>  <TAB>  <TAB>  <TAB> for key, value in config.items() <TAB>  <TAB>  <TAB> } <TAB> elif isinstance(config, list): <TAB>  <TAB> return [resolve_env_secrets(value, environ) for value in config] <TAB> else: <TAB>  <TAB> return config","if list ( config . keys ( ) ) == [ ""$env"" ] :",190
363,"def __open__(filename, *args, **kwargs): <TAB> if os.path.isfile(filename): <TAB>  <TAB> return __realopen__(filename, *args, **kwargs) <TAB> if not os.path.isabs(filename): <TAB>  <TAB> datafilename = __papplet__.dataPath(filename) <MASK> return __realopen__(datafilename, *args, **kwargs) <TAB>  <TAB> sketchfilename = __papplet__.sketchPath(filename) <TAB> if os.path.isfile(sketchfilename): <TAB>  <TAB> return __realopen__(sketchfilename, *args, **kwargs) <TAB> # Fail naturally <TAB> return __realopen__(filename, *args, **kwargs)",if os . path . isfile ( datafilename ) :,172
364,def run(self): <TAB> while not self.completed: <MASK> time.sleep(self.period) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._completed.wait(self.period) <TAB>  <TAB> self.counter += 1 <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.callback(self.counter) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> self.stop() <TAB>  <TAB> if self.timeout is not None: <TAB>  <TAB>  <TAB> dt = time.time() - self._start_time <TAB>  <TAB>  <TAB> if dt > self.timeout: <TAB>  <TAB>  <TAB>  <TAB> self.stop() <TAB>  <TAB> if self.counter == self.count: <TAB>  <TAB>  <TAB> self.stop(),if self . block :,159
365,"def remove(self, path, config=None, error_on_path=False, defaults=None): <TAB> if not path: <MASK> raise NoSuchSettingsPath() <TAB>  <TAB> return <TAB> if config is not None or defaults is not None: <TAB>  <TAB> if config is None: <TAB>  <TAB>  <TAB> config = self._config <TAB>  <TAB> if defaults is None: <TAB>  <TAB>  <TAB> defaults = dict(self._map.parents) <TAB>  <TAB> chain = HierarchicalChainMap(config, defaults) <TAB> else: <TAB>  <TAB> chain = self._map <TAB> try: <TAB>  <TAB> chain.del_by_path(path) <TAB>  <TAB> self._mark_dirty() <TAB> except KeyError: <TAB>  <TAB> if error_on_path: <TAB>  <TAB>  <TAB> raise NoSuchSettingsPath() <TAB>  <TAB> pass",if error_on_path :,184
366,"def structured_dot_grad(sparse_A, dense_B, ga): <TAB> if sparse_A.type.format in (""csc"", ""csr""): <MASK> sdgcsx = sdg_csc <TAB>  <TAB>  <TAB> CSx = CSC <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sdgcsx = sdg_csr <TAB>  <TAB>  <TAB> CSx = CSR <TAB>  <TAB> g_A_data = sdgcsx(csm_indices(sparse_A), csm_indptr(sparse_A), dense_B, ga) <TAB>  <TAB> return CSx( <TAB>  <TAB>  <TAB> g_A_data, csm_indices(sparse_A), csm_indptr(sparse_A), csm_shape(sparse_A) <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> raise NotImplementedError()","if sparse_A . type . format == ""csc"" :",180
367,"def step_async(self, actions): <TAB> listify = True <TAB> try: <MASK> listify = False <TAB> except TypeError: <TAB>  <TAB> pass <TAB> if not listify: <TAB>  <TAB> self.actions = actions <TAB> else: <TAB>  <TAB> assert ( <TAB>  <TAB>  <TAB> self.num_envs == 1 <TAB>  <TAB> ), f""actions {actions} is either not a list or has a wrong size - cannot match to {self.num_envs} environments"" <TAB>  <TAB> self.actions = [actions]",if len ( actions ) == self . num_envs :,130
368,"def tempFailureRetry(func, *args, **kwargs): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return func(*args, **kwargs) <TAB>  <TAB> except (os.error, IOError) as ex: <MASK> continue <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise",if ex . errno == errno . EINTR :,83
369,"def test_learning_always_changes_generation(chars, order): <TAB> learner = LStar(lambda s: len(s) == 1 and s[0] in chars) <TAB> for c in order: <TAB>  <TAB> prev = learner.generation <TAB>  <TAB> s = bytes([c]) <MASK> learner.learn(s) <TAB>  <TAB>  <TAB> assert learner.generation > prev",if learner . dfa . matches ( s ) != learner . member ( s ) :,108
370,"def test_costs_5D_noisy_names(signal_bkps_5D_noisy, cost_name): <TAB> signal, bkps = signal_bkps_5D_noisy <TAB> cost = cost_factory(cost_name) <TAB> cost.fit(signal) <TAB> cost.error(0, 100) <TAB> cost.error(100, signal.shape[0]) <TAB> cost.error(10, 50) <TAB> cost.sum_of_costs(bkps) <TAB> with pytest.raises(NotEnoughPoints): <MASK> cost.min_size = 4 <TAB>  <TAB>  <TAB> cost.error(1, 2) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> cost.error(1, 2)","if cost_name == ""cosine"" :",174
371,"def remove_empty_dirs(dirname): <TAB> logger.debug(""remove_empty_dirs '%s'"" % (dirname)) <TAB> try: <MASK> dirname = dirname.encode(""utf-8"") <TAB>  <TAB> os.removedirs(dirname) <TAB>  <TAB> logger.debug(""remove_empty_dirs '%s' done"" % (dirname)) <TAB> except OSError as exc:  # Python >2.5 <TAB>  <TAB> if exc.errno == errno.ENOTEMPTY: <TAB>  <TAB>  <TAB> logger.debug(""remove_empty_dirs '%s' not empty"" % (dirname)) <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise <TAB> except Exception as e: <TAB>  <TAB> logger.exception(e) <TAB>  <TAB> logger.error(""remove_empty_dirs exception: "" + dirname) <TAB>  <TAB> raise e","if not isinstance ( dirname , str ) :",193
372,"def get_unique_attribute(self, name: str): <TAB> feat = None <TAB> for f in self.features: <MASK> if feat is not None: <TAB>  <TAB>  <TAB>  <TAB> raise RuntimeError(""The attribute was not unique."") <TAB>  <TAB>  <TAB> feat = f <TAB> if feat is None: <TAB>  <TAB> raise RuntimeError(""The attribute did not exist"") <TAB> return getattr(feat, name)","if self . _return_feature ( f ) and hasattr ( f , name ) :",106
373,"def get_allocated_address( <TAB> self, config: ActorPoolConfig, allocated: allocated_type) -> str: <TAB> addresses = config.get_external_addresses(label=self.label) <TAB> for addr in addresses: <TAB>  <TAB> occupied = False <TAB>  <TAB> for strategy, _ in allocated.get(addr, dict()).values(): <TAB>  <TAB>  <TAB> if strategy == self: <TAB>  <TAB>  <TAB>  <TAB> occupied = True <TAB>  <TAB>  <TAB>  <TAB> break <MASK> return addr <TAB> raise NoIdleSlot( <TAB>  <TAB> f""No idle slot for creating actor "" f""with label {self.label}, mark {self.mark}"" <TAB> )",if not occupied :,146
374,"def __deepcopy__(self, memo): <TAB> cls = self.__class__ <TAB> result = cls.__new__(cls) <TAB> memo[id(self)] = result <TAB> for key, value in self.__dict__.items(): <MASK> setattr(result, key, copy.copy(value)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> setattr(result, key, copy.deepcopy(value, memo)) <TAB> return result",if key in cls . dynamic_methods :,105
375,def restore_forward(model): <TAB> for child in model.children(): <TAB>  <TAB> # leaf node <MASK> child.forward = child.old_forward <TAB>  <TAB>  <TAB> child.old_forward = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> restore_forward(child),"if is_leaf ( child ) and hasattr ( child , ""old_forward"" ) :",82
376,"def add(self, obj, allow_duplicates=False): <TAB> if allow_duplicates or obj not in self._constants: <TAB>  <TAB> self._constant_pool.append(obj) <TAB>  <TAB> self._constants[obj] = len(self) <MASK> self._constant_pool.append(None)","if obj . __class__ in ( Double , Long ) :",83
377,"def find_file_copyright_notices(fname): <TAB> ret = set() <TAB> f = open(fname) <TAB> lines = f.readlines() <TAB> for l in lines[:80]:  # hmmm, assume copyright to be in first 80 lines <TAB>  <TAB> idx = l.lower().find(""copyright"") <TAB>  <TAB> if idx < 0: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> copyright = l[idx + 9 :].strip() <TAB>  <TAB> if not copyright: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> copyright = sanitise(copyright) <TAB>  <TAB> # hmm, do a quick check to see if there's a year, <TAB>  <TAB> # if not, skip it <MASK> continue <TAB>  <TAB> ret.add(copyright) <TAB> return ret","if not copyright . find ( ""200"" ) >= 0 and not copyright . find ( ""199"" ) >= 0 :",186
378,"def callback(lexer, match, context): <TAB> text = match.group() <TAB> extra = """" <TAB> if start: <TAB>  <TAB> context.next_indent = len(text) <TAB>  <TAB> if context.next_indent < context.indent: <TAB>  <TAB>  <TAB> while context.next_indent < context.indent: <TAB>  <TAB>  <TAB>  <TAB> context.indent = context.indent_stack.pop() <MASK> extra = text[context.indent :] <TAB>  <TAB>  <TAB>  <TAB> text = text[: context.indent] <TAB> else: <TAB>  <TAB> context.next_indent += len(text) <TAB> if text: <TAB>  <TAB> yield match.start(), TokenClass, text <TAB> if extra: <TAB>  <TAB> yield match.start() + len(text), TokenClass.Error, extra <TAB> context.pos = match.end()",if context . next_indent > context . indent :,196
379,"def queries(self): <TAB> if DEV: <TAB>  <TAB> cmd = ShellCommand(""docker"", ""ps"", ""-qf"", ""name=%s"" % self.path.k8s) <TAB>  <TAB> if not cmd.check(f""docker check for {self.path.k8s}""): <TAB>  <TAB>  <TAB> if not cmd.stdout.strip(): <TAB>  <TAB>  <TAB>  <TAB> log_cmd = ShellCommand( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""docker"", ""logs"", self.path.k8s, stderr=subprocess.STDOUT <TAB>  <TAB>  <TAB>  <TAB> ) <MASK> print(cmd.stdout) <TAB>  <TAB>  <TAB>  <TAB> pytest.exit(f""container failed to start for {self.path.k8s}"") <TAB> return ()","if log_cmd . check ( f""docker logs for {self.path.k8s}"" ) :",188
380,"def nodes(self): <TAB> if not self._nodes: <TAB>  <TAB> nodes = self.cluster_group.instances() <TAB>  <TAB> self._nodes = [] <TAB>  <TAB> master = self.master_node <TAB>  <TAB> nodeid = 1 <TAB>  <TAB> for node in nodes: <TAB>  <TAB>  <TAB> if node.state not in [""pending"", ""running""]: <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> self._nodes.insert(0, master) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> self._nodes.append(Node(node, self.key_location, ""node%.3d"" % nodeid)) <TAB>  <TAB>  <TAB> nodeid += 1 <TAB> else: <TAB>  <TAB> for node in self._nodes: <TAB>  <TAB>  <TAB> log.debug(""refreshing instance %s"" % node.id) <TAB>  <TAB>  <TAB> node.update() <TAB> return self._nodes",if node . id == master . id :,198
381,"def match(cls, agent_name, guid, uri, media=None): <TAB> # Retrieve `Agent` for provided `guid` <TAB> agent = Agents.get(agent_name) <TAB> if agent is None: <MASK> # First occurrence of unsupported agent <TAB>  <TAB>  <TAB> log.warn(""Unsupported metadata agent: %s"" % agent_name) <TAB>  <TAB>  <TAB> # Mark unsupported agent as ""seen"" <TAB>  <TAB>  <TAB> unsupported_agents[agent_name] = True <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> # Duplicate occurrence of unsupported agent <TAB>  <TAB> log.warn( <TAB>  <TAB>  <TAB> ""Unsupported metadata agent: %s"" % agent_name, extra={""duplicate"": True} <TAB>  <TAB> ) <TAB>  <TAB> return False <TAB> # Fill `guid` with details from agent <TAB> return agent.fill(guid, uri, media)",if agent_name not in unsupported_agents :,199
382,"def __createRandom(plug): <TAB> node = plug.node() <TAB> parentNode = node.ancestor(Gaffer.Node) <TAB> with Gaffer.UndoScope(node.scriptNode()): <TAB>  <TAB> randomNode = Gaffer.Random() <TAB>  <TAB> parentNode.addChild(randomNode) <TAB>  <TAB> if isinstance(plug, (Gaffer.FloatPlug, Gaffer.IntPlug)): <TAB>  <TAB>  <TAB> plug.setInput(randomNode[""outFloat""]) <MASK> plug.setInput(randomNode[""outColor""]) <TAB> GafferUI.NodeEditor.acquire(randomNode)","elif isinstance ( plug , Gaffer . Color3fPlug ) :",158
383,"def post_arrow(self, arr: pa.Table, graph_type: str, opts: str = """"): <TAB> dataset_id = self.dataset_id <TAB> tok = self.token <TAB> sub_path = f""api/v2/upload/datasets/{dataset_id}/{graph_type}/arrow"" <TAB> try: <TAB>  <TAB> resp = self.post_arrow_generic(sub_path, tok, arr, opts) <TAB>  <TAB> out = resp.json() <MASK> raise Exception(""No success indicator in server response"") <TAB>  <TAB> return out <TAB> except Exception as e: <TAB>  <TAB> logger.error(""Failed to post arrow to %s"", sub_path, exc_info=True) <TAB>  <TAB> raise e","if not ( ""success"" in out ) or not out [ ""success"" ] :",179
384,"def dict_to_XML(tag, dictionary, **kwargs): <TAB> """"""Return XML element converting dicts recursively."""""" <TAB> elem = Element(tag, **kwargs) <TAB> for key, val in dictionary.items(): <MASK> child = dict_to_XML(""layer"", val, name=key) <TAB>  <TAB> elif isinstance(val, MutableMapping): <TAB>  <TAB>  <TAB> child = dict_to_XML(key, val) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if tag == ""config"": <TAB>  <TAB>  <TAB>  <TAB> child = Element(""variable"", name=key) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> child = Element(key) <TAB>  <TAB>  <TAB> child.text = str(val) <TAB>  <TAB> elem.append(child) <TAB> return elem","if tag == ""layers"" :",175
385,"def apply_incpaths_ml(self): <TAB> inc_lst = self.includes.split() <TAB> lst = self.incpaths_lst <TAB> for dir in inc_lst: <TAB>  <TAB> node = self.path.find_dir(dir) <MASK> error(""node not found: "" + str(dir)) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if not node in lst: <TAB>  <TAB>  <TAB> lst.append(node) <TAB>  <TAB> self.bld_incpaths_lst.append(node)",if not node :,121
386,"def _table_reprfunc(self, row, col, val): <TAB> if self._table.column_names[col].endswith(""Size""): <TAB>  <TAB> if isinstance(val, compat.string_types): <TAB>  <TAB>  <TAB> return ""  %s"" % val <TAB>  <TAB> elif val < 1024 ** 2: <TAB>  <TAB>  <TAB> return ""  %.1f KB"" % (val / 1024.0 ** 1) <MASK> return ""  %.1f MB"" % (val / 1024.0 ** 2) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""  %.1f GB"" % (val / 1024.0 ** 3) <TAB> if col in (0, """"): <TAB>  <TAB> return str(val) <TAB> else: <TAB>  <TAB> return ""  %s"" % val",elif val < 1024 ** 3 :,182
387,"def _cache_mem(curr_out, prev_mem, mem_len, reuse_len=None): <TAB> """"""cache hidden states into memory."""""" <TAB> if mem_len is None or mem_len == 0: <TAB>  <TAB> return None <TAB> else: <MASK> curr_out = curr_out[:reuse_len] <TAB>  <TAB> if prev_mem is None: <TAB>  <TAB>  <TAB> new_mem = curr_out[-mem_len:] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_mem = tf.concat([prev_mem, curr_out], 0)[-mem_len:] <TAB> new_mem.stop_gradient = True <TAB> return new_mem",if reuse_len is not None and reuse_len > 0 :,165
388,"def GROUP_CONCAT(builder, distinct, expr, sep=None): <TAB> assert distinct in (None, True, False) <TAB> result = distinct and ""GROUP_CONCAT(DISTINCT "" or ""GROUP_CONCAT("", builder(expr) <TAB> if sep is not None: <MASK> result = result, "" SEPARATOR "", builder(sep) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result = result, "", "", builder(sep) <TAB> return result, "")""","if builder . provider . dialect == ""MySQL"" :",117
389,"def __init__(self, *args, **kwargs): <TAB> super().__init__(*args, **kwargs) <TAB> self.custom_fields = [] <TAB> self.obj_type = ContentType.objects.get_for_model(self.model) <TAB> # Add all applicable CustomFields to the form <TAB> custom_fields = CustomField.objects.filter(content_types=self.obj_type) <TAB> for cf in custom_fields: <TAB>  <TAB> # Annotate non-required custom fields as nullable <MASK> self.nullable_fields.append(cf.name) <TAB>  <TAB> self.fields[cf.name] = cf.to_form_field( <TAB>  <TAB>  <TAB> set_initial=False, enforce_required=False <TAB>  <TAB> ) <TAB>  <TAB> # Annotate this as a custom field <TAB>  <TAB> self.custom_fields.append(cf.name)",if not cf . required :,199
390,"def is_child_of(self, item_hash, possible_child_hash): <TAB> if self.get_last(item_hash) != self.get_last(possible_child_hash): <TAB>  <TAB> return None <TAB> while True: <MASK> return True <TAB>  <TAB> if possible_child_hash not in self.items: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> possible_child_hash = self.items[possible_child_hash].previous_hash",if possible_child_hash == item_hash :,119
391,"def validate(self): <TAB> self.assertEqual(len(self.inputs), len(self.outputs)) <TAB> for batch_in, batch_out in zip(self.inputs, self.outputs): <TAB>  <TAB> self.assertEqual(len(batch_in), len(batch_out)) <MASK> self.validate_unordered_batch(batch_in, batch_out) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for in_data, out_data in zip(batch_in, batch_out): <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(in_data.shape, out_data.shape) <TAB>  <TAB>  <TAB>  <TAB> if not self.use_parallel_executor: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.assertTrue((in_data == out_data).all())",if self . use_parallel_executor and not self . use_double_buffer :,189
392,"def add_cells(self, cells): <TAB> for cell in cells: <MASK> id = len(self.cell_id_map) <TAB>  <TAB>  <TAB> self.cell_id_map[cell] = id <TAB>  <TAB>  <TAB> self.id_cell_map[id] = cell",if cell not in self . cell_id_map :,80
393,"def _verify_out(marker="">>""): <TAB> if shared: <TAB>  <TAB> self.assertIn(""libapp_lib.dylib"", self.client.out) <TAB> else: <MASK> self.assertIn(""libapp_lib.a"", self.client.out) <TAB>  <TAB> else:  # Incremental build not the same msg <TAB>  <TAB>  <TAB> self.assertIn(""Built target app_lib"", self.client.out) <TAB> out = str(self.client.out).splitlines() <TAB> for k, v in vals.items(): <TAB>  <TAB> self.assertIn(""%s %s: %s"" % (marker, k, v), out)","if marker == "">>"" :",152
394,"def Visit_expr(self, node):  # pylint: disable=invalid-name <TAB> # expr ::= xor_expr ('|' xor_expr)* <TAB> for child in node.children: <TAB>  <TAB> self.Visit(child) <MASK> _AppendTokenSubtype(child, format_token.Subtype.BINARY_OPERATOR)","if isinstance ( child , pytree . Leaf ) and child . value == ""|"" :",92
395,"def fill_members(self): <TAB> if self._get_retrieve(): <TAB>  <TAB> after = self.after.id if self.after else None <TAB>  <TAB> data = await self.get_members(self.guild.id, self.retrieve, after) <TAB>  <TAB> if not data: <TAB>  <TAB>  <TAB> # no data, terminate <TAB>  <TAB>  <TAB> return <MASK> self.limit = 0  # terminate loop <TAB>  <TAB> self.after = Object(id=int(data[-1][""user""][""id""])) <TAB>  <TAB> for element in reversed(data): <TAB>  <TAB>  <TAB> await self.members.put(self.create_member(element))",if len ( data ) < 1000 :,153
396,"def assert_warns(expected): <TAB> with warnings.catch_warnings(record=True) as w: <TAB>  <TAB> warnings.simplefilter(""always"") <TAB>  <TAB> yield <TAB> # Python 2 does not raise warnings multiple times from the same stack <TAB> # frame. <TAB> if sys.version_info >= (3, 0): <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> exc_name = expected.__name__ <TAB>  <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB>  <TAB> exc_name = str(expected) <TAB>  <TAB>  <TAB> raise AssertionError(""%s not triggerred"" % exc_name)","if not any ( isinstance ( m . message , expected ) for m in w ) :",147
397,"def __init__(self, measures): <TAB> """"""Constructs a ContingencyMeasures given a NgramAssocMeasures class"""""" <TAB> self.__class__.__name__ = ""Contingency"" + measures.__class__.__name__ <TAB> for k in dir(measures): <MASK> continue <TAB>  <TAB> v = getattr(measures, k) <TAB>  <TAB> if not k.startswith(""_""): <TAB>  <TAB>  <TAB> v = self._make_contingency_fn(measures, v) <TAB>  <TAB> setattr(self, k, v)","if k . startswith ( ""__"" ) :",116
398,"def _omit_keywords(self, context): <TAB> omitted_kws = 0 <TAB> for event, elem in context: <TAB>  <TAB> # Teardowns aren't omitted to allow checking suite teardown status. <TAB>  <TAB> omit = elem.tag == ""kw"" and elem.get(""type"") != ""teardown"" <TAB>  <TAB> start = event == ""start"" <MASK> omitted_kws += 1 <TAB>  <TAB> if not omitted_kws: <TAB>  <TAB>  <TAB> yield event, elem <TAB>  <TAB> elif not start: <TAB>  <TAB>  <TAB> elem.clear() <TAB>  <TAB> if omit and not start: <TAB>  <TAB>  <TAB> omitted_kws -= 1",if omit and start :,144
399,"def read_block(buffer, i): <TAB> offset = i * BLOCK_LENGTH % config.CAPTURE_BUFFER <TAB> while True: <TAB>  <TAB> if buffer[offset] == BLOCK_MARKER.END: <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> while buffer[offset] == BLOCK_MARKER.WRITE: <TAB>  <TAB>  <TAB> time.sleep(SHORT_SENSOR_SLEEP_TIME) <TAB>  <TAB> buffer[offset] = BLOCK_MARKER.READ <TAB>  <TAB> buffer.seek(offset + 1) <TAB>  <TAB> length = struct.unpack(""=H"", buffer.read(2))[0] <TAB>  <TAB> retval = buffer.read(length) <MASK> break <TAB> buffer[offset] = BLOCK_MARKER.NOP <TAB> return retval",if buffer [ offset ] == BLOCK_MARKER . READ :,179
400,def _start(self): <TAB> try: <TAB>  <TAB> instance_info = self._get_instance_info() <MASK> self._multipass_cmd.start(instance_name=self.instance_name) <TAB> except errors.ProviderInfoError as instance_error: <TAB>  <TAB> # Until we have proper multipass error codes to know if this <TAB>  <TAB> # was a communication error we should keep this error tracking <TAB>  <TAB> # and generation here. <TAB>  <TAB> raise errors.ProviderInstanceNotFoundError( <TAB>  <TAB>  <TAB> instance_name=self.instance_name <TAB>  <TAB> ) from instance_error,if not instance_info . is_running ( ) :,145
401,"def _river_driver(self): <TAB> if self._cached_river_driver: <TAB>  <TAB> return self._cached_river_driver <TAB> else: <MASK> self._cached_river_driver = MsSqlDriver( <TAB>  <TAB>  <TAB>  <TAB> self.workflow, self.wokflow_object_class, self.field_name <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._cached_river_driver = OrmDriver( <TAB>  <TAB>  <TAB>  <TAB> self.workflow, self.wokflow_object_class, self.field_name <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return self._cached_river_driver",if app_config . IS_MSSQL :,156
402,"def __LazyMap__(self, attr): <TAB> try: <MASK> debug_attr_print( <TAB>  <TAB>  <TAB>  <TAB> ""%s.__LazyMap__(%s) added something"" % (self._username_, attr) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return 1 <TAB> except AttributeError: <TAB>  <TAB> return 0",if self . _LazyAddAttr_ ( attr ) :,80
403,"def prepare(self, data=None, user=None): <TAB> """"""Prepare activation for execution."""""" <TAB> super(ManagedStartViewActivation, self).prepare.original() <TAB> self.task.owner = user <TAB> management_form_class = self.get_management_form_class() <TAB> self.management_form = management_form_class(data=data, instance=self.task) <TAB> if data: <MASK> raise FlowRuntimeError( <TAB>  <TAB>  <TAB>  <TAB> ""Activation metadata is broken {}"".format(self.management_form.errors) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self.task = self.management_form.save(commit=False)",if not self . management_form . is_valid ( ) :,160
404,"def PreprocessConditionalStatement(self, IfList, ReplacedLine): <TAB> while self: <TAB>  <TAB> if self.__Token: <TAB>  <TAB>  <TAB> x = 1 <TAB>  <TAB> elif not IfList: <TAB>  <TAB>  <TAB> if self <= 2: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> RegionSizeGuid = 3 <MASK> RegionLayoutLine = 5 <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> RegionLayoutLine = self.CurrentLineNumber <TAB> return 1",if not RegionSizeGuid :,111
405,"def _get_completion(self, document): <TAB> try: <TAB>  <TAB> completion_header = document.xpath(""//div[@id='complete_day']"")[0] <TAB>  <TAB> completion_message = completion_header.getchildren()[0] <MASK> return False <TAB>  <TAB> elif ""day_complete_message"" in completion_message.classes: <TAB>  <TAB>  <TAB> return True <TAB> except IndexError: <TAB>  <TAB> return False  # Who knows, probably not my diary.","if ""day_incomplete_message"" in completion_message . classes :",123
406,"def run(self): <TAB> DISPATCH_SYNC = components.interfaces.nsIEventTarget.DISPATCH_SYNC <TAB> try: <MASK> return <TAB>  <TAB> for match in findlib2.find_all_matches(self.regex, self.text): <TAB>  <TAB>  <TAB> if self._stopped: <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> self.target.dispatch(lambda: self.callback(match), DISPATCH_SYNC) <TAB>  <TAB>  <TAB> if self._stopped: <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> self.target.dispatch(lambda: self.callback(None), DISPATCH_SYNC) <TAB> finally: <TAB>  <TAB> self.callback = None <TAB>  <TAB> self.target = None",if self . _stopped :,164
407,"def to_key(literal_or_identifier): <TAB> """"""returns string representation of this object"""""" <TAB> if literal_or_identifier[""type""] == ""Identifier"": <TAB>  <TAB> return literal_or_identifier[""name""] <TAB> elif literal_or_identifier[""type""] == ""Literal"": <TAB>  <TAB> k = literal_or_identifier[""value""] <TAB>  <TAB> if isinstance(k, float): <TAB>  <TAB>  <TAB> return unicode(float_repr(k)) <MASK> return compose_regex(k) <TAB>  <TAB> elif isinstance(k, bool): <TAB>  <TAB>  <TAB> return ""true"" if k else ""false"" <TAB>  <TAB> elif k is None: <TAB>  <TAB>  <TAB> return ""null"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return unicode(k)","elif ""regex"" in literal_or_identifier :",179
408,"def process_image_pre_creation(sender, instance: Image, **kwargs): <TAB> # FIXME(winkidney): May have issue on determining if it <TAB> #  is created or not <TAB> if instance.pk is not None: <TAB>  <TAB> return <TAB> for plugin in _plugin_instances: <TAB>  <TAB> process_fn = getattr(plugin, ""process_image_pre_creation"", None) <MASK> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> process_fn( <TAB>  <TAB>  <TAB>  <TAB> django_settings=settings, <TAB>  <TAB>  <TAB>  <TAB> image_instance=instance, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> logging.exception( <TAB>  <TAB>  <TAB>  <TAB> ""Error occurs while trying to access plugin's pin_pre_save "" <TAB>  <TAB>  <TAB>  <TAB> ""for plugin %s"" % plugin <TAB>  <TAB>  <TAB> )",if process_fn is None :,197
409,"def check_screenshots(self): <TAB> # If we arrive here, there have not been any failures yet <TAB> if self.interactive: <TAB>  <TAB> self._commit_screenshots() <TAB> else: <MASK> self._validate_screenshots() <TAB>  <TAB>  <TAB> # Always commit the screenshots here. They can be used for the next test run. <TAB>  <TAB>  <TAB> # If reference screenshots were already present and there was a mismatch, it should <TAB>  <TAB>  <TAB> # have failed above. <TAB>  <TAB>  <TAB> self._commit_screenshots() <TAB>  <TAB> elif self.allow_missing_screenshots: <TAB>  <TAB>  <TAB> warnings.warn(""No committed reference screenshots available. Ignoring."") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.fail( <TAB>  <TAB>  <TAB>  <TAB> ""No committed reference screenshots available. Run interactive first."" <TAB>  <TAB>  <TAB> )",if self . _has_reference_screenshots ( ) :,190
410,"def on_task_abort(self, task, config): <TAB> if ""abort"" in config: <MASK> return <TAB>  <TAB> log.debug(""sending abort notification"") <TAB>  <TAB> self.send_notification( <TAB>  <TAB>  <TAB> config[""abort""][""title""], <TAB>  <TAB>  <TAB> config[""abort""][""message""], <TAB>  <TAB>  <TAB> config[""abort""][""via""], <TAB>  <TAB>  <TAB> template_renderer=task.render, <TAB>  <TAB> )",if task . silent_abort :,104
411,"def block_users(self, user_ids): <TAB> broken_items = [] <TAB> self.logger.info(""Going to block %d users."" % len(user_ids)) <TAB> for user_id in tqdm(user_ids): <MASK> self.error_delay() <TAB>  <TAB>  <TAB> broken_items = user_ids[user_ids.index(user_id) :] <TAB>  <TAB>  <TAB> break <TAB> self.logger.info(""DONE: Total blocked %d users."" % self.total[""blocks""]) <TAB> return broken_items",if not self . block ( user_id ) :,135
412,"def find_widget_by_id(self, id, parent=None): <TAB> """"""Recursively searches for widget with specified ID"""""" <TAB> if parent == None: <TAB>  <TAB> if id in self: <TAB>  <TAB>  <TAB> return self[id]  # Do things fast if possible <TAB>  <TAB> parent = self[""editor""] <TAB> for c in parent.get_children(): <TAB>  <TAB> if hasattr(c, ""get_id""): <TAB>  <TAB>  <TAB> if c.get_id() == id: <TAB>  <TAB>  <TAB>  <TAB> return c <TAB>  <TAB> if isinstance(c, Gtk.Container): <TAB>  <TAB>  <TAB> r = self.find_widget_by_id(id, c) <MASK> return r <TAB> return None",if not r is None :,167
413,"def addClasses(self, name): <TAB> # Result: void - None <TAB> # In: name: string <TAB> for n in name.split(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> k, method = n.split(""."") <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> k = n <TAB>  <TAB>  <TAB> method = None <TAB>  <TAB> self.classes[k] = 1 <MASK> self.methods.setdefault(k, {})[method] = 1",if method is not None :,109
414,"def Read(self, lex_mode): <TAB> while True: <TAB>  <TAB> t = self._Read(lex_mode) <TAB>  <TAB> self.was_line_cont = t.id == Id.Ignored_LineCont <TAB>  <TAB> # TODO: Change to ALL IGNORED types, once you have SPACE_TOK.  This means <TAB>  <TAB> # we don't have to handle them in the VS_1/VS_2/etc. states. <MASK> break <TAB> # log('Read() Returning %s', t) <TAB> return t",if t . id != Id . Ignored_LineCont :,137
415,"def _dir_guildfile(dir, ctx): <TAB> from guild import guildfile <TAB> try: <TAB>  <TAB> return guildfile.for_dir(dir) <TAB> except guildfile.NoModels: <MASK> help_suffix = "" or '%s' for help"" % click_util.cmd_help(ctx) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> help_suffix = """" <TAB>  <TAB> cli.error( <TAB>  <TAB>  <TAB> ""%s does not contain a Guild file (guild.yml)\n"" <TAB>  <TAB>  <TAB> ""Try specifying a project path or package name%s."" <TAB>  <TAB>  <TAB> % (cwd_desc(dir), help_suffix) <TAB>  <TAB> ) <TAB> except guildfile.GuildfileError as e: <TAB>  <TAB> cli.error(str(e))",if ctx :,186
416,"def check_response(self, response): <TAB> """"""Specialized version of check_response()."""""" <TAB> for line in response: <TAB>  <TAB> # Skip blank lines: <TAB>  <TAB> if not line.strip(): <TAB>  <TAB>  <TAB> continue <MASK> return <TAB>  <TAB> elif line.startswith(b""Benutzer/Passwort Fehler""): <TAB>  <TAB>  <TAB> raise BadLogin(line) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise FailedPost(""Server returned '%s'"" % six.ensure_text(line))","if line . startswith ( b""OK"" ) :",126
417,"def ParseResponses( <TAB> self, <TAB> knowledge_base: rdf_client.KnowledgeBase, <TAB> responses: Iterable[rdfvalue.RDFValue],) -> Iterator[rdf_client.User]: <TAB> for response in responses: <TAB>  <TAB> if not isinstance(response, rdf_client_fs.StatEntry): <TAB>  <TAB>  <TAB> raise TypeError(f""Unexpected response type: `{type(response)}`"") <TAB>  <TAB> # TODO: `st_mode` has to be an `int`, not `StatMode`. <MASK> homedir = response.pathspec.path <TAB>  <TAB>  <TAB> username = os.path.basename(homedir) <TAB>  <TAB>  <TAB> if username not in self._ignore_users: <TAB>  <TAB>  <TAB>  <TAB> yield rdf_client.User(username=username, homedir=homedir)",if stat . S_ISDIR ( int ( response . st_mode ) ) :,198
418,"def __call__(self, x, uttid=None): <TAB> if self.utt2spk is not None: <TAB>  <TAB> spk = self.utt2spk[uttid] <TAB> else: <TAB>  <TAB> spk = uttid <TAB> if not self.reverse: <MASK> x = np.add(x, self.bias[spk]) <TAB>  <TAB> if self.norm_vars: <TAB>  <TAB>  <TAB> x = np.multiply(x, self.scale[spk]) <TAB> else: <TAB>  <TAB> if self.norm_vars: <TAB>  <TAB>  <TAB> x = np.divide(x, self.scale[spk]) <TAB>  <TAB> if self.norm_means: <TAB>  <TAB>  <TAB> x = np.subtract(x, self.bias[spk]) <TAB> return x",if self . norm_means :,189
419,"def hasFixtures(self, ctx_callback=None): <TAB> context = self.context <TAB> if context is None: <TAB>  <TAB> return False <TAB> if self.implementsAnyFixture(context, ctx_callback=ctx_callback): <TAB>  <TAB> return True <TAB> # My context doesn't have any, but its ancestors might <TAB> factory = self.factory <TAB> if factory: <TAB>  <TAB> ancestors = factory.context.get(self, []) <TAB>  <TAB> for ancestor in ancestors: <MASK> return True <TAB> return False","if self . implementsAnyFixture ( ancestor , ctx_callback = ctx_callback ) :",137
420,def UpdateControlState(self): <TAB> active = self.demoModules.GetActiveID() <TAB> # Update the radio/restore buttons <TAB> for moduleID in self.radioButtons: <TAB>  <TAB> btn = self.radioButtons[moduleID] <TAB>  <TAB> if moduleID == active: <TAB>  <TAB>  <TAB> btn.SetValue(True) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> btn.SetValue(False) <TAB>  <TAB> if self.demoModules.Exists(moduleID): <TAB>  <TAB>  <TAB> btn.Enable(True) <MASK> self.btnRestore.Enable(True) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> btn.Enable(False) <TAB>  <TAB>  <TAB> if moduleID == modModified: <TAB>  <TAB>  <TAB>  <TAB> self.btnRestore.Enable(False),if moduleID == modModified :,177
421,"def ignore_proxy_host(self): <TAB> """"""Check if self.host is in the $no_proxy ignore list."""""" <TAB> if urllib.proxy_bypass(self.host): <TAB>  <TAB> return True <TAB> no_proxy = os.environ.get(""no_proxy"") <TAB> if no_proxy: <TAB>  <TAB> entries = [parse_host_port(x) for x in no_proxy.split("","")] <TAB>  <TAB> for host, port in entries: <MASK> return True <TAB> return False",if host . lower ( ) == self . host and port == self . port :,133
422,"def run(self, _): <TAB> view = self.view <TAB> if not view.settings().get(""terminus_view""): <TAB>  <TAB> return <TAB> terminal = Terminal.from_id(view.id()) <TAB> if terminal: <TAB>  <TAB> terminal.close() <TAB>  <TAB> panel_name = terminal.panel_name <MASK> window = panel_window(view) <TAB>  <TAB>  <TAB> if window: <TAB>  <TAB>  <TAB>  <TAB> window.destroy_output_panel(panel_name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> view.close()",if panel_name :,128
423,"def get_docname_for_node(self, node: Node) -> str: <TAB> while node: <MASK> return self.env.path2doc(node[""source""]) <TAB>  <TAB> elif isinstance(node, addnodes.start_of_file): <TAB>  <TAB>  <TAB> return node[""docname""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> node = node.parent <TAB> return None  # never reached here. only for type hinting","if isinstance ( node , nodes . document ) :",110
424,"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.add_version(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,90
425,"def _maybe_female(self, path_elements, female, strict): <TAB> if female: <TAB>  <TAB> if self.has_gender_differences: <TAB>  <TAB>  <TAB> elements = path_elements + [""female""] <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> return self._get_file(elements, "".png"", strict=strict) <TAB>  <TAB>  <TAB> except ValueError: <MASK> raise <TAB>  <TAB> elif strict: <TAB>  <TAB>  <TAB> raise ValueError(""Pokemon %s has no gender differences"" % self.species_id) <TAB> return self._get_file(path_elements, "".png"", strict=strict)",if strict :,146
426,"def OnKeyUp(self, event): <TAB> if self._properties.modifiable: <TAB>  <TAB> if event.GetKeyCode() == wx.WXK_ESCAPE: <TAB>  <TAB>  <TAB> self._cancel_editing() <TAB>  <TAB> elif event.GetKeyCode() == wx.WXK_RETURN: <TAB>  <TAB>  <TAB> self._update_value() <MASK> self.SetValue("""") <TAB> if event.GetKeyCode() != wx.WXK_RETURN: <TAB>  <TAB> # Don't send skip event if enter key is pressed <TAB>  <TAB> # On some platforms this event is sent too late and causes crash <TAB>  <TAB> event.Skip()",elif event . GetKeyCode ( ) == wx . WXK_DELETE :,145
427,"def sync_up_to_new_location(self, worker_ip): <TAB> if worker_ip != self.worker_ip: <TAB>  <TAB> logger.debug(""Setting new worker IP to %s"", worker_ip) <TAB>  <TAB> self.set_worker_ip(worker_ip) <TAB>  <TAB> self.reset() <MASK> logger.warning(""Sync up to new location skipped. This should not occur."") <TAB> else: <TAB>  <TAB> logger.warning(""Sync attempted to same IP %s."", worker_ip)",if not self . sync_up ( ) :,126
428,"def _get_download_link(self, url, download_type=""torrent""): <TAB> links = { <TAB>  <TAB> ""torrent"": """", <TAB>  <TAB> ""magnet"": """", <TAB> } <TAB> try: <TAB>  <TAB> data = self.session.get(url).text <TAB>  <TAB> with bs4_parser(data) as html: <TAB>  <TAB>  <TAB> downloads = html.find(""div"", {""class"": ""download""}) <MASK> for download in downloads.findAll(""a""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> link = download[""href""] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if link.startswith(""magnet""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> links[""magnet""] = link <TAB>  <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> links[""torrent""] = urljoin(self.urls[""base_url""], link) <TAB> except Exception: <TAB>  <TAB> pass <TAB> return links[download_type]",if downloads :,200
429,"def force_ipv4(self, *args): <TAB> """"""only ipv4 localhost in /etc/hosts"""""" <TAB> logg.debug(""checking /etc/hosts for '::1 localhost'"") <TAB> lines = [] <TAB> for line in open(self.etc_hosts()): <TAB>  <TAB> if ""::1"" in line: <TAB>  <TAB>  <TAB> newline = re.sub(""\\slocalhost\\s"", "" "", line) <MASK> logg.info(""/etc/hosts: '%s' => '%s'"", line.rstrip(), newline.rstrip()) <TAB>  <TAB>  <TAB>  <TAB> line = newline <TAB>  <TAB> lines.append(line) <TAB> f = open(self.etc_hosts(), ""w"") <TAB> for line in lines: <TAB>  <TAB> f.write(line) <TAB> f.close()",if line != newline :,182
430,"def prepare(self): <TAB> # Maybe the brok is a old daemon one or was already prepared <TAB> # if so, the data is already ok <TAB> if hasattr(self, ""prepared"") and not self.prepared: <TAB>  <TAB> self.data = SafeUnpickler.loads(self.data) <MASK> self.data[""instance_id""] = self.instance_id <TAB> self.prepared = True","if hasattr ( self , ""instance_id"" ) :",104
431,"def _test_compute_q0(self): <TAB> # Stub code to search a logq space and figure out logq0 by eyeballing <TAB> # results. This code does not run with the tests. Remove underscore to run. <TAB> sigma = 15 <TAB> order = 250 <TAB> logqs = np.arange(-290, -270, 1) <TAB> count = 0 <TAB> for logq in logqs: <TAB>  <TAB> count += 1 <TAB>  <TAB> sys.stdout.write( <TAB>  <TAB>  <TAB> ""\t%0.5g: %0.10g"" % (logq, pate.rdp_gaussian(logq, sigma, order)) <TAB>  <TAB> ) <TAB>  <TAB> sys.stdout.flush() <MASK> print("""")",if count % 5 == 0 :,175
432,"def valid_fieldnames(fieldnames): <TAB> """"""check if fieldnames are valid"""""" <TAB> for fieldname in fieldnames: <MASK> return True <TAB>  <TAB> elif fieldname in fieldname_map and fieldname_map[fieldname] == ""source"": <TAB>  <TAB>  <TAB> return True <TAB> return False","if fieldname in canonical_field_names and fieldname == ""source"" :",81
433,"def ns_provide(self, id_): <TAB> global controllers, layouts <TAB> if id_ == ""_leo_viewrendered"": <TAB>  <TAB> c = self.c <TAB>  <TAB> vr = controllers.get(c.hash()) or ViewRenderedController(c) <TAB>  <TAB> h = c.hash() <TAB>  <TAB> controllers[h] = vr <MASK> layouts[h] = c.db.get(""viewrendered_default_layouts"", (None, None)) <TAB>  <TAB> # return ViewRenderedController(self.c) <TAB>  <TAB> return vr",if not layouts . get ( h ) :,143
434,"def remove(self, path, config=None, error_on_path=False, defaults=None): <TAB> if not path: <TAB>  <TAB> if error_on_path: <TAB>  <TAB>  <TAB> raise NoSuchSettingsPath() <TAB>  <TAB> return <TAB> if config is not None or defaults is not None: <TAB>  <TAB> if config is None: <TAB>  <TAB>  <TAB> config = self._config <MASK> defaults = dict(self._map.parents) <TAB>  <TAB> chain = HierarchicalChainMap(config, defaults) <TAB> else: <TAB>  <TAB> chain = self._map <TAB> try: <TAB>  <TAB> chain.del_by_path(path) <TAB>  <TAB> self._mark_dirty() <TAB> except KeyError: <TAB>  <TAB> if error_on_path: <TAB>  <TAB>  <TAB> raise NoSuchSettingsPath() <TAB>  <TAB> pass",if defaults is None :,184
435,"def _mongo_query_and(self, queries): <TAB> if len(queries) == 1: <TAB>  <TAB> return queries[0] <TAB> query = {} <TAB> for q in queries: <TAB>  <TAB> for k, v in q.items(): <TAB>  <TAB>  <TAB> if k not in query: <TAB>  <TAB>  <TAB>  <TAB> query[k] = {} <MASK> # TODO check exists of k in query, may be it should be update <TAB>  <TAB>  <TAB>  <TAB> query[k] = v <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> query[k].update(v) <TAB> return query","if isinstance ( v , list ) :",141
436,"def write(self, data): <TAB> self.size -= len(data) <TAB> passon = None <TAB> if self.size > 0: <TAB>  <TAB> self.data.append(data) <TAB> else: <MASK> data, passon = data[: self.size], data[self.size :] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> passon = b"""" <TAB>  <TAB> if data: <TAB>  <TAB>  <TAB> self.data.append(data) <TAB> return passon",if self . size :,114
437,"def updateVar(name, data, mode=None): <TAB> if mode: <TAB>  <TAB> if mode == ""append"": <TAB>  <TAB>  <TAB> core.config.globalVariables[name].append(data) <MASK> core.config.globalVariables[name].add(data) <TAB> else: <TAB>  <TAB> core.config.globalVariables[name] = data","elif mode == ""add"" :",91
438,"def vi_pos_back_short(line, index=0, count=1): <TAB> line = vi_list(line) <TAB> try: <TAB>  <TAB> for i in range(count): <TAB>  <TAB>  <TAB> index -= 1 <TAB>  <TAB>  <TAB> while vi_is_space(line[index]): <TAB>  <TAB>  <TAB>  <TAB> index -= 1 <TAB>  <TAB>  <TAB> in_word = vi_is_word(line[index]) <MASK> while vi_is_word(line[index]): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> index -= 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> while not vi_is_word_or_space(line[index]): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> index -= 1 <TAB>  <TAB> return index + 1 <TAB> except IndexError: <TAB>  <TAB> return 0",if in_word :,179
439,"def _truncate_to_length(generator, len_map=None): <TAB> for example in generator: <TAB>  <TAB> example = list(example) <MASK> for key, max_len in len_map.items(): <TAB>  <TAB>  <TAB>  <TAB> example_len = example[key].shape <TAB>  <TAB>  <TAB>  <TAB> if example_len > max_len: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> example[key] = np.resize(example[key], max_len) <TAB>  <TAB> yield tuple(example)",if len_map is not None :,120
440,"def decorate(f): <TAB> # call-signature of f is exposed via __wrapped__. <TAB> # we want it to mimic Obj.__init__ <TAB> f.__wrapped__ = Obj.__init__ <TAB> f._uses_signature = Obj <TAB> # Supplement the docstring of f with information from Obj <TAB> if Obj.__doc__: <TAB>  <TAB> doclines = Obj.__doc__.splitlines() <MASK> doc = f.__doc__ + ""\n"".join(doclines[1:]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> doc = ""\n"".join(doclines) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> f.__doc__ = doc <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB> # __doc__ is not modifiable for classes in Python < 3.3 <TAB>  <TAB>  <TAB> pass <TAB> return f",if f . __doc__ :,192
441,"def IncrementErrorCount(self, category): <TAB> """"""Bumps the module's error statistic."""""" <TAB> self.error_count += 1 <TAB> if self.counting in (""toplevel"", ""detailed""): <TAB>  <TAB> if self.counting != ""detailed"": <TAB>  <TAB>  <TAB> category = category.split(""/"")[0] <MASK> self.errors_by_category[category] = 0 <TAB>  <TAB> self.errors_by_category[category] += 1",if category not in self . errors_by_category :,115
442,"def _delete_fields(self, data): <TAB> data = self._del( <TAB>  <TAB> data, [""speaker_ids"", ""track_id"", ""microlocation_id"", ""session_type_id""] <TAB> ) <TAB> # convert datetime fields <TAB> for _ in [""start_time_tz"", ""end_time_tz""]: <MASK> data[_] = SESSION_POST[_[0:-3]].from_str(data[_]) <TAB>  <TAB>  <TAB> data[_[0:-3]] = data.pop(_) <TAB> return data",if _ in data :,128
443,"def get_strings_of_set(word, char_set, threshold=20): <TAB> count = 0 <TAB> letters = """" <TAB> strings = [] <TAB> for char in word: <TAB>  <TAB> if char in char_set: <TAB>  <TAB>  <TAB> letters += char <TAB>  <TAB>  <TAB> count += 1 <TAB>  <TAB> else: <MASK> strings.append(letters) <TAB>  <TAB>  <TAB> letters = """" <TAB>  <TAB>  <TAB> count = 0 <TAB> if count > threshold: <TAB>  <TAB> strings.append(letters) <TAB> return strings",if count > threshold :,125
444,"def _ArgumentListHasDictionaryEntry(self, token): <TAB> """"""Check if the function argument list has a dictionary as an arg."""""" <TAB> if _IsArgumentToFunction(token): <TAB>  <TAB> while token: <TAB>  <TAB>  <TAB> if token.value == ""{"": <TAB>  <TAB>  <TAB>  <TAB> length = token.matching_bracket.total_length - token.total_length <TAB>  <TAB>  <TAB>  <TAB> return length + self.stack[-2].indent > self.column_limit <MASK> break <TAB>  <TAB>  <TAB> if token.OpensScope(): <TAB>  <TAB>  <TAB>  <TAB> token = token.matching_bracket <TAB>  <TAB>  <TAB> token = token.next_token <TAB> return False",if token . ClosesScope ( ) :,153
445,"def check_apns_certificate(ss): <TAB> mode = ""start"" <TAB> for s in ss.split(""\n""): <TAB>  <TAB> if mode == ""start"": <TAB>  <TAB>  <TAB> if ""BEGIN RSA PRIVATE KEY"" in s or ""BEGIN PRIVATE KEY"" in s: <TAB>  <TAB>  <TAB>  <TAB> mode = ""key"" <TAB>  <TAB> elif mode == ""key"": <TAB>  <TAB>  <TAB> if ""END RSA PRIVATE KEY"" in s or ""END PRIVATE KEY"" in s: <TAB>  <TAB>  <TAB>  <TAB> mode = ""end"" <TAB>  <TAB>  <TAB>  <TAB> break <MASK> raise ImproperlyConfigured( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Encrypted APNS private keys are not supported"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> if mode != ""end"": <TAB>  <TAB> raise ImproperlyConfigured(""The APNS certificate doesn't contain a private key"")","elif s . startswith ( ""Proc-Type"" ) and ""ENCRYPTED"" in s :",195
446,"def main(self): <TAB> self.model.clear() <TAB> self.callman.unregister_all() <TAB> active_handle = self.get_active(""Person"") <TAB> if active_handle: <TAB>  <TAB> active = self.dbstate.db.get_person_from_handle(active_handle) <MASK> self.callman.register_obj(active) <TAB>  <TAB>  <TAB> self.display_citations(active) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.set_has_data(False) <TAB> else: <TAB>  <TAB> self.set_has_data(False)",if active :,141
447,"def _validate(self) -> None: <TAB> # Paren validation and such <TAB> super(Tuple, self)._validate() <TAB> if len(self.elements) == 0: <MASK> # assumes len(lpar) == len(rpar), via superclass <TAB>  <TAB>  <TAB> raise CSTValidationError( <TAB>  <TAB>  <TAB>  <TAB> ""A zero-length tuple must be wrapped in parentheses."" <TAB>  <TAB>  <TAB> )",if len ( self . lpar ) == 0 :,101
448,"def _session_from_arg(self, session_obj, lock_type=None): <TAB> if not isinstance(session_obj, self.ISession): <TAB>  <TAB> vm = self._machine_from_arg(session_obj) <TAB>  <TAB> lock_type = lock_type or self.LockType.null <MASK> return vm.create_session(lock_type) <TAB>  <TAB> return None <TAB> return session_obj",if vm :,102
449,"def _decorator(cls): <TAB> for name, meth in inspect.getmembers(cls, inspect.isroutine): <TAB>  <TAB> if name not in cls.__dict__: <TAB>  <TAB>  <TAB> continue <MASK> if not private and name.startswith(""_""): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if name in butnot: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> setattr(cls, name, decorator(meth)) <TAB> return cls","if name != ""__init__"" :",99
450,"def pdb(message=""""): <TAB> """"""Fall into pdb."""""" <TAB> import pdb  # Required: we have just defined pdb as a function! <TAB> if app and not app.useIpython: <TAB>  <TAB> # from leo.core.leoQt import QtCore <TAB>  <TAB> # This is more portable. <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> import PyQt5.QtCore as QtCore <TAB>  <TAB> except ImportError: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> import PyQt4.QtCore as QtCore <TAB>  <TAB>  <TAB> except ImportError: <TAB>  <TAB>  <TAB>  <TAB> QtCore = None <MASK> # pylint: disable=no-member <TAB>  <TAB>  <TAB> QtCore.pyqtRemoveInputHook() <TAB> if message: <TAB>  <TAB> print(message) <TAB> pdb.set_trace()",if QtCore :,183
451,"def get_s3_bucket_locations(buckets, self_log=False): <TAB> """"""return (bucket_name, prefix) for all s3 logging targets"""""" <TAB> for b in buckets: <TAB>  <TAB> if b.get(""Logging""): <MASK> if b[""Name""] != b[""Logging""][""TargetBucket""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> yield (b[""Logging""][""TargetBucket""], b[""Logging""][""TargetPrefix""]) <TAB>  <TAB> if not self_log and b[""Name""].startswith(""cf-templates-""): <TAB>  <TAB>  <TAB> yield (b[""Name""], """")",if self_log :,138
452,"def prepare_fields(self): <TAB> # See clean() <TAB> for k, v in self.fields.items(): <TAB>  <TAB> v._required = v.required <TAB>  <TAB> v.required = False <TAB>  <TAB> v.widget.is_required = False <MASK> v._required = v.one_required <TAB>  <TAB>  <TAB> v.one_required = False <TAB>  <TAB>  <TAB> v.widget.enabled_locales = self.locales","if isinstance ( v , I18nFormField ) :",110
453,"def __pack__(self): <TAB> new_values = [] <TAB> for i in xrange(len(self.__unpacked_data_elms__)): <TAB>  <TAB> for key in self.__keys__[i]: <TAB>  <TAB>  <TAB> new_val = getattr(self, key) <TAB>  <TAB>  <TAB> old_val = self.__unpacked_data_elms__[i] <TAB>  <TAB>  <TAB> # In the case of Unions, when the first changed value <TAB>  <TAB>  <TAB> # is picked the loop is exited <MASK> break <TAB>  <TAB> new_values.append(new_val) <TAB> return struct.pack(self.__format__, *new_values)",if new_val != old_val :,153
454,"def run(self): <TAB> pwd_found = [] <TAB> if constant.user_dpapi and constant.user_dpapi.unlocked: <TAB>  <TAB> main_vault_directory = os.path.join( <TAB>  <TAB>  <TAB> constant.profile[""APPDATA""], u"".."", u""Local"", u""Microsoft"", u""Vault"" <TAB>  <TAB> ) <MASK> for vault_directory in os.listdir(main_vault_directory): <TAB>  <TAB>  <TAB>  <TAB> cred = constant.user_dpapi.decrypt_vault( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> os.path.join(main_vault_directory, vault_directory) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> if cred: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pwd_found.append(cred) <TAB> return pwd_found",if os . path . exists ( main_vault_directory ) :,197
455,"def on_revision_plugin_revision_pre_save(**kwargs): <TAB> instance = kwargs[""instance""] <TAB> if kwargs.get(""created"", False): <TAB>  <TAB> update_previous_revision = ( <TAB>  <TAB>  <TAB> not instance.previous_revision <TAB>  <TAB>  <TAB> and instance.plugin <TAB>  <TAB>  <TAB> and instance.plugin.current_revision <TAB>  <TAB>  <TAB> and instance.plugin.current_revision != instance <TAB>  <TAB> ) <MASK> instance.previous_revision = instance.plugin.current_revision <TAB> if not instance.revision_number: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> previous_revision = instance.plugin.revision_set.latest() <TAB>  <TAB>  <TAB> instance.revision_number = previous_revision.revision_number + 1 <TAB>  <TAB> except RevisionPluginRevision.DoesNotExist: <TAB>  <TAB>  <TAB> instance.revision_number = 1",if update_previous_revision :,194
456,"def __setattr__(self, name, value): <TAB> super().__setattr__(name, value) <TAB> field = self._fields.get(name) <TAB> if field: <TAB>  <TAB> self.check_field_type(field, value) <MASK> raise TypeError(f""cannot set immutable {name} on {self!r}"")",if name in self . __ast_frozen_fields__ :,88
457,"def _check_for_req_data(data): <TAB> required_args = [""columns""] <TAB> for arg in required_args: <MASK> return True, make_json_response( <TAB>  <TAB>  <TAB>  <TAB> status=400, <TAB>  <TAB>  <TAB>  <TAB> success=0, <TAB>  <TAB>  <TAB>  <TAB> errormsg=gettext(""Could not find required parameter ({})."").format(arg), <TAB>  <TAB>  <TAB> ) <TAB> return False, """"","if arg not in data or ( isinstance ( data [ arg ] , list ) and len ( data [ arg ] ) < 1 ) :",123
458,"def train_dict(self, triples): <TAB> """"""Train a dict lemmatizer given training (word, pos, lemma) triples."""""" <TAB> # accumulate counter <TAB> ctr = Counter() <TAB> ctr.update([(p[0], p[1], p[2]) for p in triples]) <TAB> # find the most frequent mappings <TAB> for p, _ in ctr.most_common(): <TAB>  <TAB> w, pos, l = p <MASK> self.composite_dict[(w, pos)] = l <TAB>  <TAB> if w not in self.word_dict: <TAB>  <TAB>  <TAB> self.word_dict[w] = l <TAB> return","if ( w , pos ) not in self . composite_dict :",158
459,"def render(type_, obj, context): <TAB> if type_ == ""foreign_key"": <TAB>  <TAB> return None <TAB> if type_ == ""column"": <TAB>  <TAB> if obj.name == ""y"": <TAB>  <TAB>  <TAB> return None <MASK> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""col(%s)"" % obj.name <TAB> if type_ == ""type"" and isinstance(obj, MySpecialType): <TAB>  <TAB> context.imports.add(""from mypackage import MySpecialType"") <TAB>  <TAB> return ""MySpecialType()"" <TAB> return ""render:%s"" % type_","elif obj . name == ""q"" :",144
460,"def test_knows_when_stepping_back_possible(self): <TAB> iterator = bidirectional_iterator.BidirectionalIterator([0, 1, 2, 3]) <TAB> commands = [0, 1, 0, 0, 1, 1, 0, 0, 0, 0] <TAB> command_count = 0 <TAB> results = [] <TAB> for _ in iterator: <MASK> iterator.step_back_on_next_iteration() <TAB>  <TAB> results.append(iterator.can_step_back()) <TAB>  <TAB> command_count += 1 <TAB> assert results == [False, True, False, True, True, True, False, True, True, True]",if commands [ command_count ] :,157
461,"def flask_debug_true(context): <TAB> if context.is_module_imported_like(""flask""): <TAB>  <TAB> if context.call_function_name_qual.endswith("".run""): <MASK> return bandit.Issue( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> severity=bandit.HIGH, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> confidence=bandit.MEDIUM, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> text=""A Flask app appears to be run with debug=True, "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""which exposes the Werkzeug debugger and allows "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""the execution of arbitrary code."", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> lineno=context.get_lineno_for_call_arg(""debug""), <TAB>  <TAB>  <TAB>  <TAB> )","if context . check_call_arg_value ( ""debug"" , ""True"" ) :",181
462,"def __exit__(self, exc_type, exc_val, exc_tb): <TAB> if self._should_meta_profile: <TAB>  <TAB> end_time = timezone.now() <TAB>  <TAB> exception_raised = exc_type is not None <TAB>  <TAB> if exception_raised: <TAB>  <TAB>  <TAB> Logger.error( <TAB>  <TAB>  <TAB>  <TAB> ""Exception when performing meta profiling, dumping trace below"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> traceback.print_exception(exc_type, exc_val, exc_tb) <TAB>  <TAB> request = getattr(DataCollector().local, ""request"", None) <MASK> curr = request.meta_time or 0 <TAB>  <TAB>  <TAB> request.meta_time = curr + _time_taken(self.start_time, end_time)",if request :,176
463,"def get_job_offer(ja_list): <TAB> ja_joff_map = {} <TAB> offers = frappe.get_all( <TAB>  <TAB> ""Job Offer"", <TAB>  <TAB> filters=[[""job_applicant"", ""IN"", ja_list]], <TAB>  <TAB> fields=[""name"", ""job_applicant"", ""status"", ""offer_date"", ""designation""], <TAB> ) <TAB> for offer in offers: <MASK> ja_joff_map[offer.job_applicant] = [offer] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ja_joff_map[offer.job_applicant].append(offer) <TAB> return ja_joff_map",if offer . job_applicant not in ja_joff_map . keys ( ) :,176
464,"def _get_deepest(self, t): <TAB> if isinstance(t, list): <MASK> return t[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for part in t: <TAB>  <TAB>  <TAB>  <TAB> res = self._get_deepest(part) <TAB>  <TAB>  <TAB>  <TAB> if res: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return res <TAB>  <TAB>  <TAB> return None <TAB> return None",if len ( t ) == 1 :,95
465,"def test_main(self): <TAB> root = os.path.dirname(mutagen.__path__[0]) <TAB> skip = [os.path.join(root, ""docs""), os.path.join(root, ""venv"")] <TAB> for dirpath, dirnames, filenames in os.walk(root): <MASK> continue <TAB>  <TAB> for filename in filenames: <TAB>  <TAB>  <TAB> if filename.endswith("".py""): <TAB>  <TAB>  <TAB>  <TAB> path = os.path.join(dirpath, filename) <TAB>  <TAB>  <TAB>  <TAB> self._check_encoding(path)",if any ( ( dirpath . startswith ( s + os . sep ) or s == dirpath ) for s in skip ) :,146
466,"def xview(self, mode=None, value=None, units=None): <TAB> if type(value) == str: <TAB>  <TAB> value = float(value) <TAB> if mode is None: <TAB>  <TAB> return self.hsb.get() <TAB> elif mode == ""moveto"": <TAB>  <TAB> frameWidth = self.innerframe.winfo_reqwidth() <TAB>  <TAB> self._startX = value * float(frameWidth) <TAB> else:  # mode == 'scroll' <TAB>  <TAB> clipperWidth = self._clipper.winfo_width() <MASK> jump = int(clipperWidth * self._jfraction) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> jump = clipperWidth <TAB>  <TAB> self._startX = self._startX + value * jump <TAB> self.reposition()","if units == ""units"" :",181
467,"def test_training_script_with_max_history_set(tmpdir): <TAB> train_dialogue_model( <TAB>  <TAB> DEFAULT_DOMAIN_PATH, <TAB>  <TAB> DEFAULT_STORIES_FILE, <TAB>  <TAB> tmpdir.strpath, <TAB>  <TAB> interpreter=RegexInterpreter(), <TAB>  <TAB> policy_config=""data/test_config/max_hist_config.yml"", <TAB>  <TAB> kwargs={}, <TAB> ) <TAB> agent = Agent.load(tmpdir.strpath) <TAB> for policy in agent.policy_ensemble.policies: <MASK> if type(policy) == FormPolicy: <TAB>  <TAB>  <TAB>  <TAB> assert policy.featurizer.max_history == 2 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> assert policy.featurizer.max_history == 5","if hasattr ( policy . featurizer , ""max_history"" ) :",191
468,"def generate_auto_complete(self, base, iterable_var): <TAB> sugg = [] <TAB> for entry in iterable_var: <TAB>  <TAB> compare_entry = entry <TAB>  <TAB> compare_base = base <MASK> compare_entry = compare_entry.lower() <TAB>  <TAB>  <TAB> compare_base = compare_base.lower() <TAB>  <TAB> if self.compare_entries(compare_entry, compare_base): <TAB>  <TAB>  <TAB> if entry not in sugg: <TAB>  <TAB>  <TAB>  <TAB> sugg.append(entry) <TAB> return sugg",if self . settings . get ( IGNORE_CASE_SETTING ) :,137
469,"def marker_expr(remaining): <TAB> if remaining and remaining[0] == ""("": <TAB>  <TAB> result, remaining = marker(remaining[1:].lstrip()) <MASK> raise SyntaxError(""unterminated parenthesis: %s"" % remaining) <TAB>  <TAB> remaining = remaining[1:].lstrip() <TAB> else: <TAB>  <TAB> lhs, remaining = marker_var(remaining) <TAB>  <TAB> while remaining: <TAB>  <TAB>  <TAB> m = MARKER_OP.match(remaining) <TAB>  <TAB>  <TAB> if not m: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> op = m.groups()[0] <TAB>  <TAB>  <TAB> remaining = remaining[m.end() :] <TAB>  <TAB>  <TAB> rhs, remaining = marker_var(remaining) <TAB>  <TAB>  <TAB> lhs = {""op"": op, ""lhs"": lhs, ""rhs"": rhs} <TAB>  <TAB> result = lhs <TAB> return result, remaining","if remaining [ 0 ] != "")"" :",196
470,"def __repr__(self): <TAB> """"""Dump the class data in the format of a .netrc file."""""" <TAB> rep = """" <TAB> for host in self.hosts.keys(): <TAB>  <TAB> attrs = self.hosts[host] <TAB>  <TAB> rep = rep + ""machine "" + host + ""\n\tlogin "" + repr(attrs[0]) + ""\n"" <MASK> rep = rep + ""account "" + repr(attrs[1]) <TAB>  <TAB> rep = rep + ""\tpassword "" + repr(attrs[2]) + ""\n"" <TAB> for macro in self.macros.keys(): <TAB>  <TAB> rep = rep + ""macdef "" + macro + ""\n"" <TAB>  <TAB> for line in self.macros[macro]: <TAB>  <TAB>  <TAB> rep = rep + line <TAB>  <TAB> rep = rep + ""\n"" <TAB> return rep",if attrs [ 1 ] :,192
471,"def _parse_policies(self, policies_yaml): <TAB> for item in policies_yaml: <TAB>  <TAB> id_ = required_key(item, ""id"") <TAB>  <TAB> controls_ids = required_key(item, ""controls"") <MASK> if controls_ids != ""all"": <TAB>  <TAB>  <TAB>  <TAB> msg = ""Policy {id_} contains invalid controls list {controls}."".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> id_=id_, controls=str(controls_ids) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(msg) <TAB>  <TAB> self.policies[id_] = controls_ids","if not isinstance ( controls_ids , list ) :",155
472,"def __set__(self, obj, value):  # noqa <TAB> if ( <TAB>  <TAB> value is not None <TAB>  <TAB> and self.field._currency_field.null <TAB>  <TAB> and not isinstance(value, MONEY_CLASSES + (Decimal,)) <TAB> ): <TAB>  <TAB> # For nullable fields we need either both NULL amount and currency or both NOT NULL <TAB>  <TAB> raise ValueError(""Missing currency value"") <TAB> if isinstance(value, BaseExpression): <MASK> value = self.prepare_value(obj, value.value) <TAB>  <TAB> elif not isinstance(value, Func): <TAB>  <TAB>  <TAB> validate_money_expression(obj, value) <TAB>  <TAB>  <TAB> prepare_expression(value) <TAB> else: <TAB>  <TAB> value = self.prepare_value(obj, value) <TAB> obj.__dict__[self.field.name] = value","if isinstance ( value , Value ) :",193
473,"def Children(self): <TAB> """"""Returns a list of all of this object's owned (strong) children."""""" <TAB> children = [] <TAB> for property, attributes in self._schema.iteritems(): <TAB>  <TAB> (is_list, property_type, is_strong) = attributes[0:3] <MASK> if not is_list: <TAB>  <TAB>  <TAB>  <TAB> children.append(self._properties[property]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> children.extend(self._properties[property]) <TAB> return children",if is_strong and property in self . _properties :,130
474,"def next_item(self, direction): <TAB> """"""Selects next menu item, based on self._direction"""""" <TAB> start, i = -1, 0 <TAB> try: <TAB>  <TAB> start = self.items.index(self._selected) <TAB>  <TAB> i = start + direction <TAB> except: <TAB>  <TAB> pass <TAB> while True: <TAB>  <TAB> if i == start: <TAB>  <TAB>  <TAB> # Cannot find valid menu item <TAB>  <TAB>  <TAB> self.select(start) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if i >= len(self.items): <TAB>  <TAB>  <TAB> i = 0 <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if i < 0: <TAB>  <TAB>  <TAB> i = len(self.items) - 1 <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if self.select(i): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> i += direction <MASK> start = 0",if start < 0 :,194
475,"def setup_displace(self): <TAB> self.displace_mod = None <TAB> self.displace_strength = 0.020 <TAB> for mod in self.obj.modifiers: <MASK> self.displace_mod = mod <TAB>  <TAB>  <TAB> self.displace_strength = mod.strength <TAB> if not self.displace_mod: <TAB>  <TAB> bpy.ops.object.modifier_add(type=""DISPLACE"") <TAB>  <TAB> self.displace_mod = self.obj.modifiers[-1] <TAB>  <TAB> self.displace_mod.show_expanded = False <TAB>  <TAB> self.displace_mod.strength = self.displace_strength <TAB>  <TAB> self.displace_mod.show_render = False <TAB>  <TAB> self.displace_mod.show_viewport = False","if mod . type == ""DISPLACE"" :",195
476,"def set_json_body(cls, request_builder): <TAB> old_body = request_builder.info.pop(""data"", {}) <TAB> if isinstance(old_body, abc.Mapping): <TAB>  <TAB> body = request_builder.info.setdefault(""json"", {}) <TAB>  <TAB> for path in old_body: <MASK> cls._sequence_path_resolver(path, old_body[path], body) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> body[path] = old_body[path] <TAB> else: <TAB>  <TAB> request_builder.info.setdefault(""json"", old_body)","if isinstance ( path , tuple ) :",147
477,"def build(opt): <TAB> dpath = os.path.join(opt[""datapath""], ""DBLL"") <TAB> version = None <TAB> if not build_data.built(dpath, version_string=version): <TAB>  <TAB> print(""[building data: "" + dpath + ""]"") <MASK> # An older version exists, so remove these outdated files. <TAB>  <TAB>  <TAB> build_data.remove_dir(dpath) <TAB>  <TAB> build_data.make_dir(dpath) <TAB>  <TAB> # Download the data. <TAB>  <TAB> for downloadable_file in RESOURCES: <TAB>  <TAB>  <TAB> downloadable_file.download_file(dpath) <TAB>  <TAB> # Mark the data as built. <TAB>  <TAB> build_data.mark_done(dpath, version_string=version)",if build_data . built ( dpath ) :,181
478,"def test_prefix_lm(self): <TAB> num_tries = 100 <TAB> original = ""This is a long test with lots of words to see if it works ok."" <TAB> dataset = tf.data.Dataset.from_tensor_slices({""text"": [original] * num_tries}) <TAB> dataset = prep.prefix_lm(dataset) <TAB> for data in test_utils.dataset_as_text(dataset): <TAB>  <TAB> inputs = data[""inputs""].replace(""prefix: "", """") <TAB>  <TAB> targets = data[""targets""] <TAB>  <TAB> reconstructed = """".join(inputs) <MASK> reconstructed += "" "" <TAB>  <TAB> reconstructed += """".join(targets) <TAB>  <TAB> self.assertEqual(reconstructed, original)",if inputs :,162
479,"def leading_whitespace(self, inputstring): <TAB> """"""Get leading whitespace."""""" <TAB> leading_ws = [] <TAB> for i, c in enumerate(inputstring): <TAB>  <TAB> if c in legal_indent_chars: <TAB>  <TAB>  <TAB> leading_ws.append(c) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <MASK> self.indchar = c <TAB>  <TAB> elif c != self.indchar: <TAB>  <TAB>  <TAB> self.strict_err_or_warn(""found mixing of tabs and spaces"", inputstring, i) <TAB> return """".join(leading_ws)",if self . indchar is None :,139
480,"def __init__(self, text): <TAB> self.mappings = {} <TAB> self.attributes = collections.defaultdict(set) <TAB> for stanza in _ParseTextProperties(text): <TAB>  <TAB> processor_id, single_values, multiple_values = self._ParseStanza(stanza) <TAB>  <TAB> if processor_id is None:  # can be 0 <TAB>  <TAB>  <TAB> continue <MASK> logging.warn(""Processor id %s seen twice in %s"", processor_id, text) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> self.mappings[processor_id] = single_values <TAB>  <TAB> for key, value in multiple_values.items(): <TAB>  <TAB>  <TAB> self.attributes[key].add(value)",if processor_id in self . mappings :,172
481,"def __iter__(self): <TAB> for chunk in self.source: <MASK> self.wait_counter = 0 <TAB>  <TAB>  <TAB> yield chunk <TAB>  <TAB> elif self.wait_counter < self.wait_cntr_max: <TAB>  <TAB>  <TAB> self.wait_counter += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logger.warning( <TAB>  <TAB>  <TAB>  <TAB> ""Data poller has been receiving no data for {} seconds.\n"" <TAB>  <TAB>  <TAB>  <TAB> ""Closing data poller"".format(self.wait_cntr_max * self.poll_period) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> time.sleep(self.poll_period)",if chunk is not None :,156
482,"def download(self, prefetch=False): <TAB> while self.running: <TAB>  <TAB> try: <MASK> (path, start, end) = self.prefetch_queue.get( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> True, 1 <TAB>  <TAB>  <TAB>  <TAB> )  # 1 second time-out <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> (path, start, end) = self.download_queue.get( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> True, 1 <TAB>  <TAB>  <TAB>  <TAB> )  # 1 second time-out <TAB>  <TAB>  <TAB> self.download_data(path, start, end) <TAB>  <TAB>  <TAB> if prefetch: <TAB>  <TAB>  <TAB>  <TAB> self.prefetch_queue.task_done() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.download_queue.task_done() <TAB>  <TAB> except Queue.Empty: <TAB>  <TAB>  <TAB> pass",if prefetch :,193
483,"def process_messages(self, found_files, messages): <TAB> for message in messages: <MASK> message.to_absolute_path(self.config.workdir) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> message.to_relative_path(self.config.workdir) <TAB> if self.config.blending: <TAB>  <TAB> messages = blender.blend(messages) <TAB> filepaths = found_files.iter_module_paths(abspath=False) <TAB> return postfilter.filter_messages(filepaths, self.config.workdir, messages)",if self . config . absolute_paths :,139
484,"def set_indentation_params(self, ispythonsource, guess=1): <TAB> if guess and ispythonsource: <TAB>  <TAB> i = self.guess_indent() <MASK> self.indentwidth = i <TAB>  <TAB> if self.indentwidth != self.tabwidth: <TAB>  <TAB>  <TAB> self.usetabs = 0 <TAB> self.editwin.set_tabwidth(self.tabwidth)",if 2 <= i <= 8 :,100
485,"def to_tree(self, tagname=None, value=None, namespace=None): <TAB> namespace = getattr(self, ""namespace"", namespace) <TAB> if value is not None: <MASK> tagname = ""{%s}%s"" % (namespace, tagname) <TAB>  <TAB> el = Element(tagname) <TAB>  <TAB> el.text = safe_string(value) <TAB>  <TAB> return el",if namespace is not None :,96
486,"def execute(self, argv: List) -> bool: <TAB> if not argv: <TAB>  <TAB> print(""ERROR: You must give at least one module to download."") <TAB>  <TAB> return False <TAB> for _arg in argv: <TAB>  <TAB> result = module_server.search_module(_arg) <TAB>  <TAB> CacheUpdater(""hub_download"", _arg).start() <MASK> url = result[0][""url""] <TAB>  <TAB>  <TAB> with log.ProgressBar(""Download {}"".format(url)) as bar: <TAB>  <TAB>  <TAB>  <TAB> for file, ds, ts in utils.download_with_progress(url): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> bar.update(float(ds) / ts) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""ERROR: Could not find a HubModule named {}"".format(_arg)) <TAB> return True",if result :,185
487,"def visit_type_type(self, t: TypeType) -> ProperType: <TAB> if isinstance(self.s, TypeType): <TAB>  <TAB> typ = self.meet(t.item, self.s.item) <MASK> typ = TypeType.make_normalized(typ, line=t.line) <TAB>  <TAB> return typ <TAB> elif isinstance(self.s, Instance) and self.s.type.fullname == ""builtins.type"": <TAB>  <TAB> return t <TAB> elif isinstance(self.s, CallableType): <TAB>  <TAB> return self.meet(t, self.s) <TAB> else: <TAB>  <TAB> return self.default(self.s)","if not isinstance ( typ , NoneType ) :",154
488,"def run(self, paths=[]): <TAB> items = [] <TAB> for item in SideBarSelection(paths).getSelectedItems(): <TAB>  <TAB> items.append(item.name()) <TAB> if len(items) > 0: <TAB>  <TAB> sublime.set_clipboard(""\n"".join(items)) <MASK> sublime.status_message(""Items copied"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sublime.status_message(""Item copied"")",if len ( items ) > 1 :,113
489,"def get_icon(self): <TAB> if self.icon is not None: <TAB>  <TAB> # Load it from an absolute filename <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> return GdkPixbuf.Pixbuf.new_from_file_at_size(self.icon, 24, 24) <TAB>  <TAB>  <TAB> except GObject.GError as ge: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> # Load it from the current icon theme <TAB>  <TAB> (icon_name, extension) = os.path.splitext(os.path.basename(self.icon)) <TAB>  <TAB> theme = Gtk.IconTheme() <TAB>  <TAB> if theme.has_icon(icon_name): <TAB>  <TAB>  <TAB> return theme.load_icon(icon_name, 24, 0)",if os . path . exists ( self . icon ) :,174
490,"def setup_logger(): <TAB> """"""Set up logger and add stdout handler"""""" <TAB> logging.setLoggerClass(IPDLogger) <TAB> logger = logging.getLogger(""icloudpd"") <TAB> has_stdout_handler = False <TAB> for handler in logger.handlers: <MASK> has_stdout_handler = True <TAB> if not has_stdout_handler: <TAB>  <TAB> formatter = logging.Formatter( <TAB>  <TAB>  <TAB> fmt=""%(asctime)s %(levelname)-8s %(message)s"", datefmt=""%Y-%m-%d %H:%M:%S"" <TAB>  <TAB> ) <TAB>  <TAB> stdout_handler = logging.StreamHandler(stream=sys.stdout) <TAB>  <TAB> stdout_handler.setFormatter(formatter) <TAB>  <TAB> stdout_handler.name = ""stdoutLogger"" <TAB>  <TAB> logger.addHandler(stdout_handler) <TAB> return logger","if handler . name == ""stdoutLogger"" :",195
491,"def process_extra_fields(self): <TAB> if self.instance.pk is not None: <TAB>  <TAB> if self.cleaned_data.get(""initialize"", None): <TAB>  <TAB>  <TAB> self.instance.initialize() <MASK> self.instance.update_from_templates()","if self . cleaned_data . get ( ""update"" , None ) or not self . instance . stores . count ( ) :",88
492,"def testFunctions(self): <TAB> from zim.formats.wiki import match_url, is_url <TAB> for input, input_is_url, tail in self.examples: <TAB>  <TAB> if input_is_url: <MASK> self.assertEqual(match_url(input), input[: -len(tail)]) <TAB>  <TAB>  <TAB>  <TAB> self.assertFalse(is_url(input)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(match_url(input), input) <TAB>  <TAB>  <TAB>  <TAB> self.assertTrue(is_url(input)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertEqual(match_url(input), None) <TAB>  <TAB>  <TAB> self.assertFalse(is_url(input))",if tail :,168
493,"def _SetUser(self, users): <TAB> for user in users.items(): <TAB>  <TAB> username = user[0] <TAB>  <TAB> settings = user[1] <TAB>  <TAB> room = settings[""room""][""name""] if ""room"" in settings else None <TAB>  <TAB> file_ = settings[""file""] if ""file"" in settings else None <MASK> if ""joined"" in settings[""event""]: <TAB>  <TAB>  <TAB>  <TAB> self._client.userlist.addUser(username, room, file_) <TAB>  <TAB>  <TAB> elif ""left"" in settings[""event""]: <TAB>  <TAB>  <TAB>  <TAB> self._client.removeUser(username) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._client.userlist.modUser(username, room, file_)","if ""event"" in settings :",170
494,"def restoreTerminals(self, state): <TAB> for name in list(self.terminals.keys()): <MASK> self.removeTerminal(name) <TAB> for name, opts in state.items(): <TAB>  <TAB> if name in self.terminals: <TAB>  <TAB>  <TAB> term = self[name] <TAB>  <TAB>  <TAB> term.setOpts(**opts) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> opts = strDict(opts) <TAB>  <TAB>  <TAB> self.addTerminal(name, **opts) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> printExc(""Error restoring terminal %s (%s):"" % (str(name), str(opts)))",if name not in state :,150
495,"def htmlify(path, text): <TAB> fname = os.path.basename(path) <TAB> if any((fnmatch.fnmatchcase(fname, p) for p in _patterns)): <TAB>  <TAB> # Get file_id, skip if not in database <TAB>  <TAB> sql = ""SELECT files.id FROM files WHERE path = ? LIMIT 1"" <TAB>  <TAB> row = _conn.execute(sql, (path,)).fetchone() <MASK> return ClangHtmlifier(_tree, _conn, path, text, row[0]) <TAB> return None",if row :,127
496,"def autoformat_filter_conv2d(fsize, in_depth, out_depth): <TAB> if isinstance(fsize, int): <TAB>  <TAB> return [fsize, fsize, in_depth, out_depth] <TAB> elif isinstance(fsize, (tuple, list, tf.TensorShape)): <MASK> return [fsize[0], fsize[1], in_depth, out_depth] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> ""filter length error: "" <TAB>  <TAB>  <TAB>  <TAB> + str(len(fsize)) <TAB>  <TAB>  <TAB>  <TAB> + "", only a length of 2 is supported."" <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> raise Exception(""filter format error: "" + str(type(fsize)))",if len ( fsize ) == 2 :,172
497,"def _rle_encode(string): <TAB> new = b"""" <TAB> count = 0 <TAB> for cur in string: <MASK> count += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if count: <TAB>  <TAB>  <TAB>  <TAB> new += b""\0"" + bytes([count]) <TAB>  <TAB>  <TAB>  <TAB> count = 0 <TAB>  <TAB>  <TAB> new += bytes([cur]) <TAB> return new",if not cur :,92
498,"def is_clean(self): <TAB> acceptable_statuses = {""external"", ""unversioned""} <TAB> root = self._capture_output(""status"", ""--quiet"") <TAB> for elem in root.findall(""./target/entry""): <TAB>  <TAB> status = elem.find(""./wc-status"") <MASK> continue <TAB>  <TAB> log.debug(""Path %s is %s"", elem.get(""path""), status.get(""item"")) <TAB>  <TAB> return False <TAB> return True","if status . get ( ""item"" , None ) in acceptable_statuses :",119
499,"def process(self, body, message): <TAB> try: <MASK> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> 'Received an unexpected type ""%s"" for payload.' % type(body) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> response = self._handler.pre_ack_process(body) <TAB>  <TAB> self._dispatcher.dispatch(self._process_message, response) <TAB> except: <TAB>  <TAB> LOG.exception(""%s failed to process message: %s"", self.__class__.__name__, body) <TAB> finally: <TAB>  <TAB> # At this point we will always ack a message. <TAB>  <TAB> message.ack()","if not isinstance ( body , self . _handler . message_type ) :",152
500,"def page_file(self, page): <TAB> try: <TAB>  <TAB> page = self.notebook.get_page(page) <MASK> return page.source <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return None <TAB> except PageNotFoundError: <TAB>  <TAB> return None","if hasattr ( page , ""source"" ) and isinstance ( page . source , File ) :",79
501,"def _optimize(self, solutions): <TAB> best_a = None <TAB> best_silhouette = None <TAB> best_k = None <TAB> for a, silhouette, k in solutions(): <MASK> pass <TAB>  <TAB> elif silhouette <= best_silhouette: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> best_silhouette = silhouette <TAB>  <TAB> best_a = a <TAB>  <TAB> best_k = k <TAB> return best_a, best_silhouette, best_k",if best_silhouette is None :,109
502,"def _cancel_tasks_for_partitions(self, to_cancel_partitions): <TAB> # type: (Iterable[str]) -> None <TAB> with self._lock: <TAB>  <TAB> _LOGGER.debug( <TAB>  <TAB>  <TAB> ""EventProcessor %r tries to cancel partitions %r"", <TAB>  <TAB>  <TAB> self._id, <TAB>  <TAB>  <TAB> to_cancel_partitions, <TAB>  <TAB> ) <TAB>  <TAB> for partition_id in to_cancel_partitions: <MASK> self._consumers[partition_id].stop = True <TAB>  <TAB>  <TAB>  <TAB> _LOGGER.info( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""EventProcessor %r has cancelled partition %r"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._id, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> partition_id, <TAB>  <TAB>  <TAB>  <TAB> )",if partition_id in self . _consumers :,184
503,"def get_intersect_all(self, refine=False): <TAB> result = None <TAB> for source, parts in self._per_source.items(): <MASK> result = parts <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result.intersection_update(parts) <TAB> if not result: <TAB>  <TAB> return None <TAB> elif len(result) == 1: <TAB>  <TAB> return list(result)[0].item <TAB> else: <TAB>  <TAB> solids = [p.item for p in result] <TAB>  <TAB> solid = solids[0].fuse(solids[1:]) <TAB>  <TAB> if refine: <TAB>  <TAB>  <TAB> solid = solid.removeSplitter() <TAB>  <TAB> return solid",if result is None :,159
504,"def geli_detach(self, pool, clear=False): <TAB> failed = 0 <TAB> for ed in self.middleware.call_sync( <TAB>  <TAB> ""datastore.query"", <TAB>  <TAB> ""storage.encrypteddisk"", <TAB>  <TAB> [(""encrypted_volume"", ""="", pool[""id""])], <TAB> ): <TAB>  <TAB> dev = ed[""encrypted_provider""] <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.geli_detach_single(dev) <TAB>  <TAB> except Exception as ee: <TAB>  <TAB>  <TAB> self.logger.warn(str(ee)) <TAB>  <TAB>  <TAB> failed += 1 <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> self.geli_clear(dev) <TAB>  <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB>  <TAB> self.logger.warn(""Failed to clear %s: %s"", dev, e) <TAB> return failed",if clear :,191
505,def compute_lengths(batch_sizes): <TAB> tmp_batch_sizes = np.copy(batch_sizes) <TAB> lengths = [] <TAB> while True: <TAB>  <TAB> c = np.count_nonzero(tmp_batch_sizes > 0) <MASK> break <TAB>  <TAB> lengths.append(c) <TAB>  <TAB> tmp_batch_sizes = np.array([b - 1 for b in tmp_batch_sizes]) <TAB> return np.array(lengths),if c == 0 :,111
506,"def _render_raw_list(bytes_items): <TAB> flatten_items = [] <TAB> for item in bytes_items: <MASK> flatten_items.append(b"""") <TAB>  <TAB> elif isinstance(item, bytes): <TAB>  <TAB>  <TAB> flatten_items.append(item) <TAB>  <TAB> elif isinstance(item, int): <TAB>  <TAB>  <TAB> flatten_items.append(str(item).encode()) <TAB>  <TAB> elif isinstance(item, list): <TAB>  <TAB>  <TAB> flatten_items.append(_render_raw_list(item)) <TAB> return b""\n"".join(flatten_items)",if item is None :,138
507,"def update(self, new_config): <TAB> jsonschema.validate(new_config, self.schema) <TAB> config = {} <TAB> for k, v in new_config.items(): <MASK> config[k] = self[k] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> config[k] = v <TAB> self._config = config <TAB> self.changed()","if k in self . schema . get ( ""secret"" , [ ] ) and v == SECRET_PLACEHOLDER :",108
508,"def _encode_numpy(values, uniques=None, encode=False, check_unknown=True): <TAB> # only used in _encode below, see docstring there for details <TAB> if uniques is None: <TAB>  <TAB> if encode: <TAB>  <TAB>  <TAB> uniques, encoded = np.unique(values, return_inverse=True) <TAB>  <TAB>  <TAB> return uniques, encoded <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # unique sorts <TAB>  <TAB>  <TAB> return np.unique(values) <TAB> if encode: <MASK> diff = _encode_check_unknown(values, uniques) <TAB>  <TAB>  <TAB> if diff: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""y contains previously unseen labels: %s"" % str(diff)) <TAB>  <TAB> encoded = np.searchsorted(uniques, values) <TAB>  <TAB> return uniques, encoded <TAB> else: <TAB>  <TAB> return uniques",if check_unknown :,190
509,"def restore_dtype_and_merge(arr, input_dtype): <TAB> if isinstance(arr, list): <TAB>  <TAB> arr = [restore_dtype_and_merge(arr_i, input_dtype) for arr_i in arr] <TAB>  <TAB> shapes = [arr_i.shape for arr_i in arr] <MASK> arr = np.array(arr) <TAB> if ia.is_np_array(arr): <TAB>  <TAB> arr = iadt.restore_dtypes_(arr, input_dtype) <TAB> return arr",if len ( set ( shapes ) ) == 1 :,131
510,"def proc_minute(d): <TAB> if expanded[0][0] != ""*"": <TAB>  <TAB> diff_min = nearest_diff_method(d.minute, expanded[0], 60) <TAB>  <TAB> if diff_min is not None and diff_min != 0: <MASK> d += relativedelta(minutes=diff_min, second=59) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> d += relativedelta(minutes=diff_min, second=0) <TAB>  <TAB>  <TAB> return True, d <TAB> return False, d",if is_prev :,128
511,"def _populate_tree(self, element, d): <TAB> """"""Populates an etree with attributes & elements, given a dict."""""" <TAB> for k, v in d.iteritems(): <MASK> self._populate_dict(element, k, v) <TAB>  <TAB> elif isinstance(v, list): <TAB>  <TAB>  <TAB> self._populate_list(element, k, v) <TAB>  <TAB> elif isinstance(v, bool): <TAB>  <TAB>  <TAB> self._populate_bool(element, k, v) <TAB>  <TAB> elif isinstance(v, basestring): <TAB>  <TAB>  <TAB> self._populate_str(element, k, v) <TAB>  <TAB> elif type(v) in [int, float, long, complex]: <TAB>  <TAB>  <TAB> self._populate_number(element, k, v)","if isinstance ( v , dict ) :",178
512,"def __createItemAttribute(self, item, function, preload): <TAB> """"""Create the new widget, add it, and remove the old one"""""" <TAB> try: <TAB>  <TAB> self.__stack.addWidget(function(item, preload)) <TAB>  <TAB> # Remove the widget <MASK> oldWidget = self.__stack.widget(0) <TAB>  <TAB>  <TAB> self.__stack.removeWidget(oldWidget) <TAB>  <TAB>  <TAB> oldWidget.setParent(QtWidgets.QWidget()) <TAB> except Exception as e: <TAB>  <TAB> list(map(logger.warning, cuegui.Utils.exceptionOutput(e)))",if self . __stack . count ( ) > 1 :,145
513,"def download_main( <TAB> download, download_playlist, urls, playlist, output_dir, merge, info_only): <TAB> for url in urls: <MASK> url = url[8:] <TAB>  <TAB> if not url.startswith(""http://""): <TAB>  <TAB>  <TAB> url = ""http://"" + url <TAB>  <TAB> if playlist: <TAB>  <TAB>  <TAB> download_playlist( <TAB>  <TAB>  <TAB>  <TAB> url, output_dir=output_dir, merge=merge, info_only=info_only <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> download(url, output_dir=output_dir, merge=merge, info_only=info_only)","if url . startswith ( ""https://"" ) :",155
514,"def add_enc_zero(obj, enc_zero): <TAB> if isinstance(obj, np.ndarray): <TAB>  <TAB> return obj + enc_zero <TAB> elif isinstance(obj, Iterable): <TAB>  <TAB> return type(obj)( <TAB>  <TAB>  <TAB> EncryptModeCalculator.add_enc_zero(o, enc_zero) <MASK> else o + enc_zero <TAB>  <TAB>  <TAB> for o in obj <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> return obj + enc_zero","if isinstance ( o , Iterable )",118
515,"def ensemble(self, pairs, other_preds): <TAB> """"""Ensemble the dict with statistical model predictions."""""" <TAB> lemmas = [] <TAB> assert len(pairs) == len(other_preds) <TAB> for p, pred in zip(pairs, other_preds): <TAB>  <TAB> w, pos = p <TAB>  <TAB> if (w, pos) in self.composite_dict: <TAB>  <TAB>  <TAB> lemma = self.composite_dict[(w, pos)] <TAB>  <TAB> elif w in self.word_dict: <TAB>  <TAB>  <TAB> lemma = self.word_dict[w] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lemma = pred <MASK> lemma = w <TAB>  <TAB> lemmas.append(lemma) <TAB> return lemmas",if lemma is None :,164
516,"def replace_to_6hex(color): <TAB> """"""Validate and replace 3hex colors to 6hex ones."""""" <TAB> if match(r""^#(?:[0-9a-fA-F]{3}){1,2}$"", color): <MASK> color = ""#{0}{0}{1}{1}{2}{2}"".format(color[1], color[2], color[3]) <TAB>  <TAB> return color <TAB> else: <TAB>  <TAB> exit(_(""Invalid color {}"").format(color))",if len ( color ) == 4 :,120
517,"def computeMachineName(self): <TAB> """"""Return the name of the current machine, i.e, HOSTNAME."""""" <TAB> # This is prepended to leoSettings.leo or myLeoSettings.leo <TAB> # to give the machine-specific setting name. <TAB> # How can this be worth doing?? <TAB> try: <TAB>  <TAB> import os <TAB>  <TAB> name = os.getenv(""HOSTNAME"") <MASK> name = os.getenv(""COMPUTERNAME"") <TAB>  <TAB> if not name: <TAB>  <TAB>  <TAB> import socket <TAB>  <TAB>  <TAB> name = socket.gethostname() <TAB> except Exception: <TAB>  <TAB> name = """" <TAB> return name",if not name :,151
518,"def _git_dirty_working_directory(q, include_untracked): <TAB> try: <TAB>  <TAB> cmd = [""git"", ""status"", ""--porcelain""] <TAB>  <TAB> if include_untracked: <TAB>  <TAB>  <TAB> cmd += [""--untracked-files=normal""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> cmd += [""--untracked-files=no""] <TAB>  <TAB> status = _run_git_cmd(cmd) <MASK> q.put(bool(status)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> q.put(None) <TAB> except (subprocess.CalledProcessError, OSError, FileNotFoundError): <TAB>  <TAB> q.put(None)",if status is not None :,156
519,"def runAndWaitWork(server, work): <TAB> work.touch() <TAB> thr = threading.Thread(target=workThread, args=(server, work)) <TAB> thr.setDaemon(True) <TAB> thr.start() <TAB> # Wait around for done or timeout <TAB> while True: <TAB>  <TAB> if work.isTimedOut(): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> # If the thread is done, lets get out. <TAB>  <TAB> if not thr.isAlive(): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> # If our parent, or some thread closes stdin, <TAB>  <TAB> # time to pack up and go. <MASK> break <TAB>  <TAB> time.sleep(2)",if sys . stdin . closed :,160
520,"def read(self, count=True, timeout=None, ignore_non_errors=True, ignore_timeouts=True): <TAB> try: <TAB>  <TAB> return self._read(count, timeout) <TAB> except usb.USBError as e: <TAB>  <TAB> if DEBUG_COMM: <TAB>  <TAB>  <TAB> log.info( <TAB>  <TAB>  <TAB>  <TAB> ""read: e.errno=%s e.strerror=%s e.message=%s repr=%s"" <TAB>  <TAB>  <TAB>  <TAB> % (e.errno, e.strerror, e.message, repr(e)) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if ignore_timeouts and is_timeout(e): <TAB>  <TAB>  <TAB> return [] <MASK> return [] <TAB>  <TAB> raise",if ignore_non_errors and is_noerr ( e ) :,174
521,"def PrintHeader(self):  # print the header array <TAB> if self.draw == False: <TAB>  <TAB> return <TAB> for val in self.parent.header: <TAB>  <TAB> self.SetPrintFont(val[""Font""]) <TAB>  <TAB> header_indent = val[""Indent""] * self.pwidth <TAB>  <TAB> text = val[""Text""] <TAB>  <TAB> htype = val[""Type""] <MASK> addtext = self.GetDate() <TAB>  <TAB> elif htype == ""Date & Time"": <TAB>  <TAB>  <TAB> addtext = self.GetDateTime() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> addtext = """" <TAB>  <TAB> self.OutTextPageWidth( <TAB>  <TAB>  <TAB> text + addtext, self.pheader_margin, val[""Align""], header_indent, True <TAB>  <TAB> )","if htype == ""Date"" :",184
522,"def get_intersect_all(self, refine=False): <TAB> result = None <TAB> for source, parts in self._per_source.items(): <TAB>  <TAB> if result is None: <TAB>  <TAB>  <TAB> result = parts <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result.intersection_update(parts) <TAB> if not result: <TAB>  <TAB> return None <TAB> elif len(result) == 1: <TAB>  <TAB> return list(result)[0].item <TAB> else: <TAB>  <TAB> solids = [p.item for p in result] <TAB>  <TAB> solid = solids[0].fuse(solids[1:]) <MASK> solid = solid.removeSplitter() <TAB>  <TAB> return solid",if refine :,159
523,"def captured_updateNode(self, context): <TAB> if not self.updating_name_from_pointer: <TAB>  <TAB> font_datablock = self.get_bpy_data_from_name(self.fontname, bpy.data.fonts) <MASK> self.font_pointer = font_datablock <TAB>  <TAB>  <TAB> updateNode(self, context)",if font_datablock :,91
524,"def __add__(self, other): <TAB> if isinstance(other, Vector2): <TAB>  <TAB> # Vector + Vector -> Vector <TAB>  <TAB> # Vector + Point -> Point <TAB>  <TAB> # Point + Point -> Vector <MASK> _class = Vector2 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _class = Point2 <TAB>  <TAB> return _class(self.x + other.x, self.y + other.y) <TAB> else: <TAB>  <TAB> assert hasattr(other, ""__len__"") and len(other) == 2 <TAB>  <TAB> return Vector2(self.x + other[0], self.y + other[1])",if self . __class__ is other . __class__ :,150
525,"def _flatten_settings_from_form(self, settings, form, form_values): <TAB> """"""Take a nested dict and return a flat dict of setting values."""""" <TAB> setting_values = {} <TAB> for field in form.c: <MASK> setting_values.update( <TAB>  <TAB>  <TAB>  <TAB> self._flatten_settings_from_form( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> settings, field, form_values[field._name] <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> elif field._name in settings: <TAB>  <TAB>  <TAB> setting_values[field._name] = form_values[field._name] <TAB> return setting_values","if isinstance ( field , _ContainerMixin ) :",156
526,"def add_include_dirs(self, args): <TAB> ids = [] <TAB> for a in args: <TAB>  <TAB> # FIXME same hack, forcibly unpack from holder. <TAB>  <TAB> if hasattr(a, ""includedirs""): <TAB>  <TAB>  <TAB> a = a.includedirs <MASK> raise InvalidArguments( <TAB>  <TAB>  <TAB>  <TAB> ""Include directory to be added is not an include directory object."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ids.append(a) <TAB> self.include_dirs += ids","if not isinstance ( a , IncludeDirs ) :",120
527,"def _clip_array(array, config): <TAB> if ""threshold"" in config.keys(): <TAB>  <TAB> threshold = config[""threshold""] <TAB> else: <TAB>  <TAB> abs_array = np.max(np.abs(array)) <MASK> return array <TAB>  <TAB> threshold = np.percentile(np.abs(array), 99.99) <TAB> return np.clip(array, -threshold, threshold)",if abs_array < 1.0 :,103
528,def dfs(v: str) -> Iterator[Set[str]]: <TAB> index[v] = len(stack) <TAB> stack.append(v) <TAB> boundaries.append(index[v]) <TAB> for w in edges[v]: <MASK> yield from dfs(w) <TAB>  <TAB> elif w not in identified: <TAB>  <TAB>  <TAB> while index[w] < boundaries[-1]: <TAB>  <TAB>  <TAB>  <TAB> boundaries.pop() <TAB> if boundaries[-1] == index[v]: <TAB>  <TAB> boundaries.pop() <TAB>  <TAB> scc = set(stack[index[v] :]) <TAB>  <TAB> del stack[index[v] :] <TAB>  <TAB> identified.update(scc) <TAB>  <TAB> yield scc,if w not in index :,162
529,"def create_balancer( <TAB> self, name, members, protocol=""http"", port=80, algorithm=DEFAULT_ALGORITHM): <TAB> balancer = self.ex_create_balancer_nowait(name, members, protocol, port, algorithm) <TAB> timeout = 60 * 20 <TAB> waittime = 0 <TAB> interval = 2 * 15 <TAB> if balancer.id is not None: <TAB>  <TAB> return balancer <TAB> else: <TAB>  <TAB> while waittime < timeout: <TAB>  <TAB>  <TAB> balancers = self.list_balancers() <TAB>  <TAB>  <TAB> for i in balancers: <MASK> return i <TAB>  <TAB>  <TAB> waittime += interval <TAB>  <TAB>  <TAB> time.sleep(interval) <TAB> raise Exception(""Failed to get id"")",if i . name == balancer . name and i . id is not None :,190
530,"def handle(self, scope: Scope, receive: Receive, send: Send) -> None: <TAB> if self.methods and scope[""method""] not in self.methods: <MASK> raise HTTPException(status_code=405) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> response = PlainTextResponse(""Method Not Allowed"", status_code=405) <TAB>  <TAB> await response(scope, receive, send) <TAB> else: <TAB>  <TAB> await self.app(scope, receive, send)","if ""app"" in scope :",116
531,"def convert(data): <TAB> result = [] <TAB> for d in data: <TAB>  <TAB> # noinspection PyCompatibility <TAB>  <TAB> if isinstance(d, tuple) and len(d) == 2: <TAB>  <TAB>  <TAB> result.append((d[0], None, d[1])) <MASK> result.append(d) <TAB> return result","elif isinstance ( d , basestring ) :",86
532,"def register_adapters(): <TAB> global adapters_registered <TAB> if adapters_registered is True: <TAB>  <TAB> return <TAB> try: <TAB>  <TAB> import pkg_resources <TAB>  <TAB> packageDir = pkg_resources.resource_filename(""pyamf"", ""adapters"") <TAB> except: <TAB>  <TAB> packageDir = os.path.dirname(__file__) <TAB> for f in glob.glob(os.path.join(packageDir, ""*.py"")): <TAB>  <TAB> mod = os.path.basename(f).split(os.path.extsep, 1)[0] <MASK> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> register_adapter(mod[1:].replace(""_"", "".""), PackageImporter(mod)) <TAB>  <TAB> except ImportError: <TAB>  <TAB>  <TAB> pass <TAB> adapters_registered = True","if mod == ""__init__"" or not mod . startswith ( ""_"" ) :",188
533,"def load_modules( <TAB> to_load, load, attr, modules_dict, excluded_aliases, loading_message=None): <TAB> if loading_message: <TAB>  <TAB> print(loading_message) <TAB> for name in to_load: <TAB>  <TAB> module = load(name) <TAB>  <TAB> if module is None or not hasattr(module, attr): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> cls = getattr(module, attr) <TAB>  <TAB> if hasattr(cls, ""initialize"") and not cls.initialize(): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if hasattr(module, ""aliases""): <TAB>  <TAB>  <TAB> for alias in module.aliases(): <MASK> modules_dict[alias] = module <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> modules_dict[name] = module <TAB> if loading_message: <TAB>  <TAB> print()",if alias not in excluded_aliases :,195
534,"def clean_items(event, items, variations): <TAB> for item in items: <MASK> raise ValidationError(_(""One or more items do not belong to this event."")) <TAB>  <TAB> if item.has_variations: <TAB>  <TAB>  <TAB> if not any(var.item == item for var in variations): <TAB>  <TAB>  <TAB>  <TAB> raise ValidationError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""One or more items has variations but none of these are in the variations list."" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> )",if event != item . event :,127
535,"def __get_file_by_num(self, num, file_list, idx=0): <TAB> for element in file_list: <MASK> return element <TAB>  <TAB> if element[3] and element[4]: <TAB>  <TAB>  <TAB> i = self.__get_file_by_num(num, element[3], idx + 1) <TAB>  <TAB>  <TAB> if not isinstance(i, int): <TAB>  <TAB>  <TAB>  <TAB> return i <TAB>  <TAB>  <TAB> idx = i <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> idx += 1 <TAB> return idx",if idx == num :,127
536,"def check(chip, xeddb, chipdb): <TAB> all_inst = [] <TAB> undoc = [] <TAB> for inst in xeddb.recs: <MASK> if inst.undocumented: <TAB>  <TAB>  <TAB>  <TAB> undoc.append(inst) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> all_inst.append(inst) <TAB> return (all_inst, undoc)",if inst . isa_set in chipdb [ chip ] :,108
537,"def get_all_topic_src_files(self): <TAB> """"""Retrieves the file paths of all the topics in directory"""""" <TAB> topic_full_paths = [] <TAB> topic_names = os.listdir(self.topic_dir) <TAB> for topic_name in topic_names: <TAB>  <TAB> # Do not try to load hidden files. <MASK> topic_full_path = os.path.join(self.topic_dir, topic_name) <TAB>  <TAB>  <TAB> # Ignore the JSON Index as it is stored with topic files. <TAB>  <TAB>  <TAB> if topic_full_path != self.index_file: <TAB>  <TAB>  <TAB>  <TAB> topic_full_paths.append(topic_full_path) <TAB> return topic_full_paths","if not topic_name . startswith ( ""."" ) :",174
538,"def _get_element(dom_msi, tag_name, name=None, id_=None): <TAB> """"""Get a xml element defined on Product."""""" <TAB> product = dom_msi.getElementsByTagName(""Product"")[0] <TAB> elements = product.getElementsByTagName(tag_name) <TAB> for element in elements: <MASK> if ( <TAB>  <TAB>  <TAB>  <TAB> element.getAttribute(""Name"") == name <TAB>  <TAB>  <TAB>  <TAB> and element.getAttribute(""Id"") == id_ <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> return element <TAB>  <TAB> elif id_: <TAB>  <TAB>  <TAB> if element.getAttribute(""Id"") == id_: <TAB>  <TAB>  <TAB>  <TAB> return element",if name and id_ :,153
539,"def __init__(self, *models): <TAB> super().__init__() <TAB> self.models = ModuleList(models) <TAB> for m in models: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""IndependentModelList currently only supports models that have a likelihood (e.g. ExactGPs)"" <TAB>  <TAB>  <TAB> ) <TAB> self.likelihood = LikelihoodList(*[m.likelihood for m in models])","if not hasattr ( m , ""likelihood"" ) :",101
540,"def _sniff(filename, oxlitype): <TAB> try: <TAB>  <TAB> with open(filename, ""rb"") as fileobj: <TAB>  <TAB>  <TAB> header = fileobj.read(4) <MASK> fileobj.read(1)  # skip the version number <TAB>  <TAB>  <TAB>  <TAB> ftype = fileobj.read(1) <TAB>  <TAB>  <TAB>  <TAB> if binascii.hexlify(ftype) == oxlitype: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> return False <TAB> except OSError: <TAB>  <TAB> return False","if header == b""OXLI"" :",126
541,"def convert_port_bindings(port_bindings): <TAB> result = {} <TAB> for k, v in six.iteritems(port_bindings): <TAB>  <TAB> key = str(k) <TAB>  <TAB> if ""/"" not in key: <TAB>  <TAB>  <TAB> key += ""/tcp"" <MASK> result[key] = [_convert_port_binding(binding) for binding in v] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result[key] = [_convert_port_binding(v)] <TAB> return result","if isinstance ( v , list ) :",119
542,"def input_data(self): <TAB> gen = self.config.generator <TAB> # don't try running the generator if we specify an output file explicitly, <TAB> # otherwise generator may segfault and we end up returning the output file anyway <TAB> if gen and (not self.config[""out""] or not self.config[""in""]): <MASK> self._run_generator(gen, args=self.config.generator_args) <TAB>  <TAB> if self._generated[0]: <TAB>  <TAB>  <TAB> return self._generated[0] <TAB> # in file is optional <TAB> return ( <TAB>  <TAB> self._normalize(self.problem.problem_data[self.config[""in""]]) <TAB>  <TAB> if self.config[""in""] <TAB>  <TAB> else b"""" <TAB> )",if self . _generated is None :,175
543,"def __new__(cls, *tasks, **kwargs): <TAB> # This forces `chain(X, Y, Z)` to work the same way as `X | Y | Z` <TAB> if not kwargs and tasks: <MASK> tasks = tasks[0] if len(tasks) == 1 else tasks <TAB>  <TAB>  <TAB> return reduce(operator.or_, tasks) <TAB> return super(chain, cls).__new__(cls, *tasks, **kwargs)",if len ( tasks ) != 1 or is_list ( tasks [ 0 ] ) :,118
544,"def get_file_sources(): <TAB> global _file_sources <TAB> if _file_sources is None: <TAB>  <TAB> from galaxy.files import ConfiguredFileSources <TAB>  <TAB> file_sources = None <TAB>  <TAB> if os.path.exists(""file_sources.json""): <TAB>  <TAB>  <TAB> file_sources_as_dict = None <TAB>  <TAB>  <TAB> with open(""file_sources.json"", ""r"") as f: <TAB>  <TAB>  <TAB>  <TAB> file_sources_as_dict = json.load(f) <TAB>  <TAB>  <TAB> if file_sources_as_dict is not None: <TAB>  <TAB>  <TAB>  <TAB> file_sources = ConfiguredFileSources.from_dict(file_sources_as_dict) <MASK> ConfiguredFileSources.from_dict([]) <TAB>  <TAB> _file_sources = file_sources <TAB> return _file_sources",if file_sources is None :,196
545,"def InitializeColours(self): <TAB> """"""Initializes the 16 custom colours in :class:`CustomPanel`."""""" <TAB> curr = self._colourData.GetColour() <TAB> self._colourSelection = -1 <TAB> for i in range(16): <TAB>  <TAB> c = self._colourData.GetCustomColour(i) <MASK> self._customColours[i] = self._colourData.GetCustomColour(i) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._customColours[i] = wx.WHITE <TAB>  <TAB> if c == curr: <TAB>  <TAB>  <TAB> self._colourSelection = i",if c . IsOk ( ) :,147
546,"def convert_obj_into_marshallable(self, obj): <TAB> if isinstance(obj, self.marshalable_types): <TAB>  <TAB> return obj <TAB> if isinstance(obj, array.array): <TAB>  <TAB> if obj.typecode == ""c"": <TAB>  <TAB>  <TAB> return obj.tostring() <MASK> return obj.tounicode() <TAB>  <TAB> return obj.tolist() <TAB> return self.class_to_dict(obj)","if obj . typecode == ""u"" :",113
547,"def run(self): <TAB> self.run_command(""egg_info"") <TAB> from glob import glob <TAB> for pattern in self.match: <TAB>  <TAB> pattern = self.distribution.get_name() + ""*"" + pattern <TAB>  <TAB> files = glob(os.path.join(self.dist_dir, pattern)) <TAB>  <TAB> files = [(os.path.getmtime(f), f) for f in files] <TAB>  <TAB> files.sort() <TAB>  <TAB> files.reverse() <TAB>  <TAB> log.info(""%d file(s) matching %s"", len(files), pattern) <TAB>  <TAB> files = files[self.keep :] <TAB>  <TAB> for (t, f) in files: <TAB>  <TAB>  <TAB> log.info(""Deleting %s"", f) <MASK> os.unlink(f)",if not self . dry_run :,188
548,"def render_token_list(self, tokens): <TAB> result = [] <TAB> vars = [] <TAB> for token in tokens: <TAB>  <TAB> if token.token_type == TOKEN_TEXT: <TAB>  <TAB>  <TAB> result.append(token.contents.replace(""%"", ""%%"")) <MASK> result.append(""%%(%s)s"" % token.contents) <TAB>  <TAB>  <TAB> vars.append(token.contents) <TAB> return """".join(result), vars",elif token . token_type == TOKEN_VAR :,113
549,"def _handle_raise(self, values, is_NAs, origins): <TAB> for is_NA, origin in zip(is_NAs, origins): <MASK> msg = ( <TAB>  <TAB>  <TAB>  <TAB> ""Missing values detected. If you want rows with missing "" <TAB>  <TAB>  <TAB>  <TAB> ""values to be automatically deleted in a list-wise "" <TAB>  <TAB>  <TAB>  <TAB> ""manner (not recommended), please set dropna=True in "" <TAB>  <TAB>  <TAB>  <TAB> ""the Bambi Model initialization."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> raise PatsyError(msg, origin) <TAB> return values",if np . any ( is_NA ) :,145
550,"def add_node_data(node_array, ntwk): <TAB> node_ntwk = nx.Graph() <TAB> newdata = {} <TAB> for idx, data in ntwk.nodes(data=True): <MASK> newdata[""value""] = node_array[int(idx) - 1] <TAB>  <TAB>  <TAB> data.update(newdata) <TAB>  <TAB>  <TAB> node_ntwk.add_node(int(idx), **data) <TAB> return node_ntwk",if not int ( idx ) == 0 :,119
551,"def safe_parse_date(date_hdr): <TAB> """"""Parse a Date: or Received: header into a unix timestamp."""""" <TAB> try: <TAB>  <TAB> if "";"" in date_hdr: <TAB>  <TAB>  <TAB> date_hdr = date_hdr.split("";"")[-1].strip() <TAB>  <TAB> msg_ts = long(rfc822.mktime_tz(rfc822.parsedate_tz(date_hdr))) <MASK> return None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return msg_ts <TAB> except (ValueError, TypeError, OverflowError): <TAB>  <TAB> return None",if ( msg_ts > ( time . time ( ) + 24 * 3600 ) ) or ( msg_ts < 1 ) :,150
552,"def _route_db(self, model, **hints): <TAB> chosen_db = None <TAB> for router in self.routers: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> method = getattr(router, action) <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB> # If the router doesn't have a method, skip to the next one. <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> chosen_db = method(model, **hints) <MASK> return chosen_db <TAB> try: <TAB>  <TAB> return hints[""instance""]._state.db or DEFAULT_DB_ALIAS <TAB> except KeyError: <TAB>  <TAB> return DEFAULT_DB_ALIAS",if chosen_db :,154
553,"def get_keys(struct, ignore_first_level=False): <TAB> res = [] <TAB> if isinstance(struct, dict): <TAB>  <TAB> if not ignore_first_level: <TAB>  <TAB>  <TAB> keys = [x.split(""("")[0] for x in struct.keys()] <TAB>  <TAB>  <TAB> res.extend(keys) <TAB>  <TAB> for key in struct: <MASK> logging.debug(""Ignored: %s: %s"", key, struct[key]) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> res.extend(get_keys(struct[key], key in IGNORED_FIRST_LEVEL)) <TAB> elif isinstance(struct, list): <TAB>  <TAB> for item in struct: <TAB>  <TAB>  <TAB> res.extend(get_keys(item)) <TAB> return res",if key in IGNORED_KEYS :,178
554,"def launch_app(self, fs_id): <TAB> if fs_id in self.app_infos: <TAB>  <TAB> row = self.get_row_by_fsid(fs_id) <MASK> return <TAB>  <TAB> app_info = self.app_infos[fs_id] <TAB>  <TAB> filepath = os.path.join(row[SAVEDIR_COL], row[SAVENAME_COL]) <TAB>  <TAB> gfile = Gio.File.new_for_path(filepath) <TAB>  <TAB> app_info.launch( <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB> gfile, <TAB>  <TAB>  <TAB> ], <TAB>  <TAB>  <TAB> None, <TAB>  <TAB> ) <TAB>  <TAB> self.app_infos.pop(fs_id, None)",if not row :,166
555,"def create_skipfile(files_changed, skipfile): <TAB> # File is likely to contain some garbage values at start, <TAB> # only the corresponding json should be parsed. <TAB> json_pattern = re.compile(r""^\{.*\}"") <TAB> for line in files_changed.readlines(): <MASK> for filename in json.loads(line): <TAB>  <TAB>  <TAB>  <TAB> if ""/COMMIT_MSG"" in filename: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB>  <TAB> skipfile.write(""+*/%s\n"" % filename) <TAB> skipfile.write(""-*\n"")","if re . match ( json_pattern , line ) :",142
556,"def zscore(self, client, request, N): <TAB> check_input(request, N != 2) <TAB> key = request[1] <TAB> db = client.db <TAB> value = db.get(key) <TAB> if value is None: <TAB>  <TAB> client.reply_bulk(None) <TAB> elif not isinstance(value, self.zset_type): <TAB>  <TAB> client.reply_wrongtype() <TAB> else: <TAB>  <TAB> score = value.score(request[2], None) <MASK> score = str(score).encode(""utf-8"") <TAB>  <TAB> client.reply_bulk(score)",if score is not None :,148
557,"def _list_cases(suite): <TAB> for test in suite: <TAB>  <TAB> if isinstance(test, unittest.TestSuite): <TAB>  <TAB>  <TAB> _list_cases(test) <TAB>  <TAB> elif isinstance(test, unittest.TestCase): <MASK> print(test.id())",if support . match_test ( test ) :,75
558,"def Run(self): <TAB> """"""The main run method of the client."""""" <TAB> for thread in self._threads.values(): <TAB>  <TAB> thread.start() <TAB> logging.info(START_STRING) <TAB> while True: <TAB>  <TAB> dead_threads = [tn for (tn, t) in self._threads.items() if not t.isAlive()] <MASK> raise FatalError( <TAB>  <TAB>  <TAB>  <TAB> ""These threads are dead: %r. Shutting down..."" % dead_threads <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> time.sleep(10)",if dead_threads :,130
559,"def _slice_queryset(queryset, order_by, per_page, start): <TAB> page_len = int(per_page) + 1 <TAB> if start: <MASK> filter_name = ""%s__lte"" % order_by[1:] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> filter_name = ""%s__gte"" % order_by <TAB>  <TAB> return queryset.filter(**{filter_name: start})[:page_len] <TAB> return queryset[:page_len]","if order_by . startswith ( ""-"" ) :",118
560,"def compute_timer_precision(timer): <TAB> precision = None <TAB> points = 0 <TAB> timeout = timeout_timer() + 1.0 <TAB> previous = timer() <TAB> while timeout_timer() < timeout or points < 5: <TAB>  <TAB> for _ in XRANGE(10): <TAB>  <TAB>  <TAB> t1 = timer() <TAB>  <TAB>  <TAB> t2 = timer() <TAB>  <TAB>  <TAB> dt = t2 - t1 <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> dt = t2 - previous <TAB>  <TAB>  <TAB> if dt <= 0.0: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if precision is not None: <TAB>  <TAB>  <TAB> precision = min(precision, dt) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> precision = dt <TAB>  <TAB> points += 1 <TAB>  <TAB> previous = timer() <TAB> return precision",if 0 < dt :,189
561,"def findWorkingDir(): <TAB> frozen = getattr(sys, ""frozen"", """") <TAB> if not frozen: <TAB>  <TAB> path = os.path.dirname(__file__) <TAB> elif frozen in (""dll"", ""console_exe"", ""windows_exe"", ""macosx_app""): <TAB>  <TAB> path = os.path.dirname( <TAB>  <TAB>  <TAB> os.path.dirname(os.path.dirname(os.path.dirname(__file__))) <TAB>  <TAB> ) <TAB> elif frozen:  # needed for PyInstaller <MASK> path = getattr(sys, ""_MEIPASS"", """")  # --onefile <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> path = os.path.dirname(sys.executable)  # --onedir <TAB> else: <TAB>  <TAB> path = """" <TAB> return path","if getattr ( sys , ""_MEIPASS"" , """" ) is not None :",192
562,"def CreateDataType(vmodlName, wsdlName, parent, version, props): <TAB> with _lazyLock: <TAB>  <TAB> dic = [vmodlName, wsdlName, parent, version, props] <TAB>  <TAB> names = vmodlName.split(""."") <MASK> vmodlName = ""."".join(name[0].lower() + name[1:] for name in names) <TAB>  <TAB> _AddToDependencyMap(names) <TAB>  <TAB> typeNs = GetWsdlNamespace(version) <TAB>  <TAB> _dataDefMap[vmodlName] = dic <TAB>  <TAB> _wsdlDefMap[(typeNs, wsdlName)] = dic <TAB>  <TAB> _wsdlTypeMapNSs.add(typeNs)",if _allowCapitalizedNames :,170
563,"def ParseResponses( <TAB> self, <TAB> knowledge_base: rdf_client.KnowledgeBase, <TAB> responses: Iterable[rdfvalue.RDFValue],) -> Iterator[rdf_client.User]: <TAB> for response in responses: <TAB>  <TAB> if not isinstance(response, rdf_client_fs.StatEntry): <TAB>  <TAB>  <TAB> raise TypeError(f""Unexpected response type: `{type(response)}`"") <TAB>  <TAB> # TODO: `st_mode` has to be an `int`, not `StatMode`. <TAB>  <TAB> if stat.S_ISDIR(int(response.st_mode)): <TAB>  <TAB>  <TAB> homedir = response.pathspec.path <TAB>  <TAB>  <TAB> username = os.path.basename(homedir) <MASK> yield rdf_client.User(username=username, homedir=homedir)",if username not in self . _ignore_users :,198
564,"def process_question(qtxt): <TAB> question = """" <TAB> skip = False <TAB> for letter in qtxt: <TAB>  <TAB> if letter == ""<"": <TAB>  <TAB>  <TAB> skip = True <TAB>  <TAB> if letter == "">"": <TAB>  <TAB>  <TAB> skip = False <TAB>  <TAB> if skip: <TAB>  <TAB>  <TAB> continue <MASK> if letter == "" "": <TAB>  <TAB>  <TAB>  <TAB> letter = ""_"" <TAB>  <TAB>  <TAB> question += letter.lower() <TAB> return question","if letter . isalnum ( ) or letter == "" "" :",110
565,"def process_all(self, lines, times=1): <TAB> gap = False <TAB> for _ in range(times): <TAB>  <TAB> for line in lines: <TAB>  <TAB>  <TAB> if gap: <TAB>  <TAB>  <TAB>  <TAB> self.write("""") <TAB>  <TAB>  <TAB> self.process(line) <MASK> gap = True <TAB> return 0",if not is_command ( line ) :,86
566,"def _get(self, domain): <TAB> with self.lock: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> record = self.cache[domain] <TAB>  <TAB>  <TAB> time_now = time.time() <TAB>  <TAB>  <TAB> if time_now - record[""update""] > self.ttl: <TAB>  <TAB>  <TAB>  <TAB> record = None <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> record = None <MASK> record = {""r"": ""unknown"", ""dns"": {}, ""g"": 1, ""query_count"": 0} <TAB>  <TAB> # self.cache[domain] = record <TAB>  <TAB> return record",if not record :,137
567,"def gen_constant_folding(cw): <TAB> types = [""Int32"", ""Double"", ""BigInteger"", ""Complex""] <TAB> for cur_type in types: <TAB>  <TAB> cw.enter_block(""if (constLeft.Value.GetType() == typeof(%s))"" % (cur_type,)) <TAB>  <TAB> cw.enter_block(""switch (_op)"") <TAB>  <TAB> for op in ops: <TAB>  <TAB>  <TAB> gen = getattr(op, ""genConstantFolding"", None) <MASK> gen(cw, cur_type) <TAB>  <TAB> cw.exit_block() <TAB>  <TAB> cw.exit_block()",if gen is not None :,147
568,"def unreferenced_dummy(self): <TAB> for g, base in zip(self.evgroups, self.evbases): <TAB>  <TAB> for ind, j in enumerate(g): <MASK> debug_print( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""replacing unreferenced %d %s with dummy"" % ((base + ind), g[ind]) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> g[ind] = ""dummy"" <TAB>  <TAB>  <TAB>  <TAB> self.evnum[base + ind] = ""dummy""",if not self . indexobj [ base + ind ] :,127
569,"def handle_signature(self, sig: str, signode: desc_signature) -> Tuple[str, str]: <TAB> for cls in self.__class__.__mro__: <MASK> warnings.warn( <TAB>  <TAB>  <TAB>  <TAB> ""PyDecoratorMixin is deprecated. "" <TAB>  <TAB>  <TAB>  <TAB> ""Please check the implementation of %s"" % cls, <TAB>  <TAB>  <TAB>  <TAB> RemovedInSphinx50Warning, <TAB>  <TAB>  <TAB>  <TAB> stacklevel=2, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> warnings.warn( <TAB>  <TAB>  <TAB> ""PyDecoratorMixin is deprecated"", RemovedInSphinx50Warning, stacklevel=2 <TAB>  <TAB> ) <TAB> ret = super().handle_signature(sig, signode)  # type: ignore <TAB> signode.insert(0, addnodes.desc_addname(""@"", ""@"")) <TAB> return ret","if cls . __name__ != ""DirectiveAdapter"" :",199
570,"def _iter_lines(path=path, response=response, max_next=options.http_max_next): <TAB> path.responses = [] <TAB> n = 0 <TAB> while response: <TAB>  <TAB> path.responses.append(response) <TAB>  <TAB> yield from response.iter_lines(decode_unicode=True) <TAB>  <TAB> src = response.links.get(""next"", {}).get(""url"", None) <MASK> break <TAB>  <TAB> n += 1 <TAB>  <TAB> if n > max_next: <TAB>  <TAB>  <TAB> vd.warning(f""stopping at max {max_next} pages"") <TAB>  <TAB>  <TAB> break <TAB>  <TAB> vd.status(f""fetching next page from {src}"") <TAB>  <TAB> response = requests.get(src, stream=True)",if not src :,179
571,"def ordered_indices(self): <TAB> with data_utils.numpy_seed(self.seed, self.epoch): <TAB>  <TAB> # Used to store the order of indices of each dataset to use <TAB>  <TAB> indices = [ <TAB>  <TAB>  <TAB> np.random.permutation(len(dataset)) for dataset in self.datasets.values() <TAB>  <TAB> ] <TAB>  <TAB> # Keep track of which samples we've  used for each dataset <TAB>  <TAB> counters = [0 for _ in self.datasets] <TAB>  <TAB> sampled_indices = [ <TAB>  <TAB>  <TAB> self._sample(indices, counters) for _ in range(self.total_num_instances) <TAB>  <TAB> ] <MASK> sampled_indices.sort(key=lambda i: self.num_tokens(i)) <TAB>  <TAB> return np.array(sampled_indices, dtype=np.int64)",if self . sort_indices :,195
572,"def _build_columns(self): <TAB> self.columns = [Column() for col in self.keys] <TAB> for row in self: <TAB>  <TAB> for (col_idx, col_val) in enumerate(row): <TAB>  <TAB>  <TAB> col = self.columns[col_idx] <TAB>  <TAB>  <TAB> col.append(col_val) <MASK> col.is_quantity = False <TAB> for (idx, key_name) in enumerate(self.keys): <TAB>  <TAB> self.columns[idx].name = key_name <TAB> self.x = Column() <TAB> self.ys = []",if ( col_val is not None ) and ( not is_quantity ( col_val ) ) :,158
573,"def tearDown(self): <TAB> subprocess_list = self.subprocess_list <TAB> processes = subprocess_list.processes <TAB> self.schedule.reset() <TAB> del self.schedule <TAB> for proc in processes: <MASK> terminate_process(proc.pid, kill_children=True, slow_stop=True) <TAB> subprocess_list.cleanup() <TAB> processes = subprocess_list.processes <TAB> if processes: <TAB>  <TAB> for proc in processes: <TAB>  <TAB>  <TAB> if proc.is_alive(): <TAB>  <TAB>  <TAB>  <TAB> terminate_process(proc.pid, kill_children=True, slow_stop=False) <TAB>  <TAB> subprocess_list.cleanup() <TAB> processes = subprocess_list.processes <TAB> if processes: <TAB>  <TAB> log.warning(""Processes left running: %s"", processes)",if proc . is_alive ( ) :,187
574,"def colorNetwork(cls, network, nodesInNetwork, nodeByID=None): <TAB> for node in nodesInNetwork: <TAB>  <TAB> node.use_custom_color = True <TAB>  <TAB> neededCopies = sum(socket.execution.neededCopies for socket in node.outputs) <MASK> color = (0.7, 0.9, 0.7) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> color = (1.0, 0.3, 0.3) <TAB>  <TAB> node.color = color",if neededCopies == 0 :,121
575,"def _init_warmup_scheduler(self, optimizer, states): <TAB> updates_so_far = states.get(""number_training_updates"", 0) <TAB> if self.warmup_updates > 0 and ( <TAB>  <TAB> updates_so_far <= self.warmup_updates or self.hard_reset <TAB> ): <TAB>  <TAB> self.warmup_scheduler = optim.lr_scheduler.LambdaLR(optimizer, self._warmup_lr) <MASK> self.warmup_scheduler.load_state_dict(states[""warmup_scheduler""]) <TAB> else: <TAB>  <TAB> self.warmup_scheduler = None","if states . get ( ""warmup_scheduler"" ) :",144
576,"def inner(self, *iargs, **ikwargs): <TAB> try: <TAB>  <TAB> return getattr(super(VEXResilienceMixin, self), func)(*iargs, **ikwargs) <TAB> except excs as e: <TAB>  <TAB> for exc, handler in zip(excs, handlers): <TAB>  <TAB>  <TAB> if isinstance(e, exc): <TAB>  <TAB>  <TAB>  <TAB> v = getattr(self, handler)(*iargs, **ikwargs) <MASK> raise <TAB>  <TAB>  <TAB>  <TAB> return v <TAB>  <TAB> assert False, ""this should be unreachable if Python is working correctly""",if v is raiseme :,140
577,"def unwrap_envelope(self, data, many): <TAB> if many: <TAB>  <TAB> if data[""items""]: <MASK> self.context[""total""] = len(data) <TAB>  <TAB>  <TAB>  <TAB> return data <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.context[""total""] = data[""total""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.context[""total""] = 0 <TAB>  <TAB>  <TAB> data = {""items"": []} <TAB>  <TAB> return data[""items""] <TAB> return data","if isinstance ( data , InstrumentedList ) or isinstance ( data , list ) :",130
578,"def __subclasscheck__(self, cls): <TAB> if self.__origin__ is not None: <MASK> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""Parameterized generics cannot be used with class "" ""or instance checks"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return False <TAB> if self is Generic: <TAB>  <TAB> raise TypeError( <TAB>  <TAB>  <TAB> ""Class %r cannot be used with class "" ""or instance checks"" % self <TAB>  <TAB> ) <TAB> return super().__subclasscheck__(cls)","if sys . _getframe ( 1 ) . f_globals [ ""__name__"" ] not in [ ""abc"" , ""functools"" ] :",130
579,"def __init__(self, pyversions, coverage_service): <TAB> build_matrix = """" <TAB> for version in pyversions: <TAB>  <TAB> build_matrix += ""\n <TAB> {},"".format( <TAB>  <TAB>  <TAB> version <MASK> else ""py{}"".format("""".join(version.split("".""))) <TAB>  <TAB> ) <TAB> coverage_package = """" <TAB> if coverage_service: <TAB>  <TAB> coverage_package += ""\n <TAB> {}"".format(coverage_service.package) <TAB> coverage_package += ""\n"" <TAB> super(Tox, self).__init__( <TAB>  <TAB> ""tox.ini"", <TAB>  <TAB> TEMPLATE.format(build_matrix=build_matrix, coverage_package=coverage_package), <TAB> )","if version . startswith ( ""pypy"" )",172
580,"def _get_app(self, body=None): <TAB> app = self._app <TAB> if app is None: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> tasks = self.tasks.tasks  # is a group <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB> tasks = self.tasks <TAB>  <TAB> if len(tasks): <TAB>  <TAB>  <TAB> app = tasks[0]._app <MASK> app = body._app <TAB> return app if app is not None else current_app",if app is None and body is not None :,117
581,"def logic(): <TAB> for v in [True, False, None, 0, True, None, None, 1]: <TAB>  <TAB> yield clk.posedge <TAB>  <TAB> xd.next = v <MASK> yd.next = zd.next = None <TAB>  <TAB> elif v: <TAB>  <TAB>  <TAB> yd.next = zd.next = 11 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yd.next = zd.next = 0",if v is None :,104
582,"def run(self): <TAB> eid = self.start_episode() <TAB> obs = self.env.reset() <TAB> while True: <MASK> action = self.env.action_space.sample() <TAB>  <TAB>  <TAB> self.log_action(eid, obs, action) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> action = self.get_action(eid, obs) <TAB>  <TAB> obs, reward, done, info = self.env.step(action) <TAB>  <TAB> self.log_returns(eid, reward, info=info) <TAB>  <TAB> if done: <TAB>  <TAB>  <TAB> self.end_episode(eid, obs) <TAB>  <TAB>  <TAB> obs = self.env.reset() <TAB>  <TAB>  <TAB> eid = self.start_episode()",if random . random ( ) < self . off_pol_frac :,187
583,"def tearDown(self): <TAB> os.chdir(self.orig_working_dir) <TAB> sys.argv = self.orig_argv <TAB> sys.stdout = self.orig_stdout <TAB> sys.stderr = self.orig_stderr <TAB> for dirname in [""lv_LV"", ""ja_JP""]: <TAB>  <TAB> locale_dir = os.path.join(self.datadir, ""project"", ""i18n"", dirname) <MASK> shutil.rmtree(locale_dir)",if os . path . isdir ( locale_dir ) :,122
584,"def sentry_set_scope(process_context, entity, project, email=None, url=None): <TAB> # Using GLOBAL_HUB means these tags will persist between threads. <TAB> # Normally there is one hub per thread. <TAB> with sentry_sdk.hub.GLOBAL_HUB.configure_scope() as scope: <TAB>  <TAB> scope.set_tag(""process_context"", process_context) <TAB>  <TAB> scope.set_tag(""entity"", entity) <TAB>  <TAB> scope.set_tag(""project"", project) <MASK> scope.user = {""email"": email} <TAB>  <TAB> if url: <TAB>  <TAB>  <TAB> scope.set_tag(""url"", url)",if email :,157
585,"def getDataMax(self): <TAB> result = -Double.MAX_VALUE <TAB> nCurves = self.chart.getNCurves() <TAB> for i in range(nCurves): <TAB>  <TAB> c = self.getSystemCurve(i) <MASK> continue <TAB>  <TAB> if c.getYAxis() == Y_AXIS: <TAB>  <TAB>  <TAB> nPoints = c.getNPoints() <TAB>  <TAB>  <TAB> for j in range(nPoints): <TAB>  <TAB>  <TAB>  <TAB> result = self.maxIgnoreNaNAndMaxValue(result, c.getPoint(j).getY()) <TAB> if result == -Double.MAX_VALUE: <TAB>  <TAB> return Double.NaN <TAB> return result",if not c . isVisible ( ) :,163
586,"def handle_starttag(self, tag, attrs): <TAB> if tag == ""link"" and (""rel"", ""icon"") in attrs or (""rel"", ""shortcut icon"") in attrs: <TAB>  <TAB> href = None <TAB>  <TAB> icon_type = None <TAB>  <TAB> for attr, value in attrs: <TAB>  <TAB>  <TAB> if attr == ""href"": <TAB>  <TAB>  <TAB>  <TAB> href = value <TAB>  <TAB>  <TAB> elif attr == ""type"": <TAB>  <TAB>  <TAB>  <TAB> icon_type = value <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> mimetype = extension_to_mimetype(href.rpartition(""."")[2]) <TAB>  <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> icon_type = mimetype <TAB>  <TAB>  <TAB> if icon_type: <TAB>  <TAB>  <TAB>  <TAB> self.icons.append((href, icon_type))",if href :,188
587,"def get_version(version_file=STATIC_VERSION_FILE): <TAB> version_info = get_static_version_info(version_file) <TAB> version = version_info[""version""] <TAB> if version == ""__use_git__"": <TAB>  <TAB> version = get_version_from_git() <MASK> version = get_version_from_git_archive(version_info) <TAB>  <TAB> if not version: <TAB>  <TAB>  <TAB> version = Version(""unknown"", None, None) <TAB>  <TAB> return pep440_format(version) <TAB> else: <TAB>  <TAB> return version",if not version :,137
588,"def _Sleep(self, seconds): <TAB> if threading.current_thread() is not self._worker_thread: <TAB>  <TAB> return self._original_sleep(seconds) <TAB> self._time += seconds <TAB> self._budget -= seconds <TAB> while self._budget < 0: <TAB>  <TAB> self._worker_thread_turn.clear() <TAB>  <TAB> self._owner_thread_turn.set() <TAB>  <TAB> self._worker_thread_turn.wait() <MASK> raise FakeTimeline._WorkerThreadExit()",if self . _worker_thread_done :,127
589,"def validate_attributes(self): <TAB> if not (self.has_variants or self.variant_of): <TAB>  <TAB> return <TAB> if not self.variant_based_on: <TAB>  <TAB> self.variant_based_on = ""Item Attribute"" <TAB> if self.variant_based_on == ""Item Attribute"": <TAB>  <TAB> attributes = [] <MASK> frappe.throw(_(""Attribute table is mandatory"")) <TAB>  <TAB> for d in self.attributes: <TAB>  <TAB>  <TAB> if d.attribute in attributes: <TAB>  <TAB>  <TAB>  <TAB> frappe.throw( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Attribute {0} selected multiple times in Attributes Table"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ).format(d.attribute) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> attributes.append(d.attribute)",if not self . attributes :,197
590,"def check_digest_auth(user, passwd): <TAB> """"""Check user authentication using HTTP Digest auth"""""" <TAB> if request.headers.get(""Authorization""): <TAB>  <TAB> credentails = parse_authorization_header(request.headers.get(""Authorization"")) <TAB>  <TAB> if not credentails: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> response_hash = response( <TAB>  <TAB>  <TAB> credentails, <TAB>  <TAB>  <TAB> passwd, <TAB>  <TAB>  <TAB> dict( <TAB>  <TAB>  <TAB>  <TAB> uri=request.script_root + request.path, <TAB>  <TAB>  <TAB>  <TAB> body=request.data, <TAB>  <TAB>  <TAB>  <TAB> method=request.method, <TAB>  <TAB>  <TAB> ), <TAB>  <TAB> ) <MASK> return True <TAB> return False","if credentails . get ( ""response"" ) == response_hash :",165
591,"def _get_index_type(return_index_type, ctx): <TAB> if return_index_type is None:  # pragma: no cover <TAB>  <TAB> if ctx.running_mode == RunningMode.local: <TAB>  <TAB>  <TAB> return_index_type = ""object"" <MASK> return_index_type = ""filename"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return_index_type = ""bytes"" <TAB> return return_index_type",elif ctx . running_mode == RunningMode . local_cluster :,116
592,"def iter_event_handlers( <TAB> self, <TAB> resource: resources_.Resource, <TAB> event: bodies.RawEvent,) -> Iterator[handlers.ResourceWatchingHandler]: <TAB> warnings.warn( <TAB>  <TAB> ""SimpleRegistry.iter_event_handlers() is deprecated; use "" <TAB>  <TAB> ""ResourceWatchingRegistry.iter_handlers()."", <TAB>  <TAB> DeprecationWarning, <TAB> ) <TAB> cause = _create_watching_cause(resource, event) <TAB> for handler in self._handlers: <TAB>  <TAB> if not isinstance(handler, handlers.ResourceWatchingHandler): <TAB>  <TAB>  <TAB> pass <MASK> yield handler","elif registries . match ( handler = handler , cause = cause , ignore_fields = True ) :",160
593,"def subprocess_post_check( <TAB> completed_process: subprocess.CompletedProcess, raise_error: bool = True) -> None: <TAB> if completed_process.returncode: <MASK> print(completed_process.stdout, file=sys.stdout, end="""") <TAB>  <TAB> if completed_process.stderr is not None: <TAB>  <TAB>  <TAB> print(completed_process.stderr, file=sys.stderr, end="""") <TAB>  <TAB> if raise_error: <TAB>  <TAB>  <TAB> raise PipxError( <TAB>  <TAB>  <TAB>  <TAB> f""{' '.join([str(x) for x in completed_process.args])!r} failed"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logger.info(f""{' '.join(completed_process.args)!r} failed"")",if completed_process . stdout is not None :,185
594,"def __pow__(self, power): <TAB> if power == 1: <TAB>  <TAB> return self <TAB> if power == -1: <TAB>  <TAB> # HACK: break cycle <TAB>  <TAB> from cirq.devices import line_qubit <TAB>  <TAB> decomposed = protocols.decompose_once_with_qubits( <TAB>  <TAB>  <TAB> self, qubits=line_qubit.LineQid.for_gate(self), default=None <TAB>  <TAB> ) <MASK> return NotImplemented <TAB>  <TAB> inverse_decomposed = protocols.inverse(decomposed, None) <TAB>  <TAB> if inverse_decomposed is None: <TAB>  <TAB>  <TAB> return NotImplemented <TAB>  <TAB> return _InverseCompositeGate(self) <TAB> return NotImplemented",if decomposed is None :,164
595,"def tearDown(self): <TAB> """"""Close the application after tests"""""" <TAB> # set it back to it's old position so not to annoy users :-) <TAB> self.old_pos = self.dlg.rectangle <TAB> # close the application <TAB> self.dlg.menu_select(""File->Exit"") <TAB> try: <MASK> self.app.UntitledNotepad[""Do&n't Save""].click() <TAB>  <TAB>  <TAB> self.app.UntitledNotepad.wait_not(""visible"") <TAB> except Exception: <TAB>  <TAB> pass <TAB> finally: <TAB>  <TAB> self.app.kill()","if self . app . UntitledNotepad [ ""Do&n't Save"" ] . exists ( ) :",160
596,"def terminate_subprocess(proc, timeout=0.1, log=None): <MASK> if log: <TAB>  <TAB>  <TAB> log.info(""Sending SIGTERM to %r"", proc) <TAB>  <TAB> proc.terminate() <TAB>  <TAB> timeout_time = time.time() + timeout <TAB>  <TAB> while proc.poll() is None and time.time() < timeout_time: <TAB>  <TAB>  <TAB> time.sleep(0.02) <TAB>  <TAB> if proc.poll() is None: <TAB>  <TAB>  <TAB> if log: <TAB>  <TAB>  <TAB>  <TAB> log.info(""Sending SIGKILL to %r"", proc) <TAB>  <TAB>  <TAB> proc.kill() <TAB> return proc.returncode",if proc . poll ( ) is None :,152
597,"def validate(self, detection, expectation): <TAB> config = SigmaConfiguration() <TAB> self.basic_rule[""detection""] = detection <TAB> with patch(""yaml.safe_load_all"", return_value=[self.basic_rule]): <TAB>  <TAB> parser = SigmaCollectionParser(""any sigma io"", config, None) <TAB>  <TAB> backend = SQLiteBackend(config, self.table) <TAB>  <TAB> assert len(parser.parsers) == 1 <TAB>  <TAB> for p in parser.parsers: <MASK> self.assertEqual(expectation, backend.generate(p)) <TAB>  <TAB>  <TAB> elif isinstance(expectation, Exception): <TAB>  <TAB>  <TAB>  <TAB> self.assertRaises(type(expectation), backend.generate, p)","if isinstance ( expectation , str ) :",167
598,"def makelist(d): <TAB> """"""Convert d into a list if all the keys of d are integers."""""" <TAB> if isinstance(d, dict): <MASK> return [makelist(d[k]) for k in sorted(d, key=int)] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return web.storage((k, makelist(v)) for k, v in d.items()) <TAB> else: <TAB>  <TAB> return d",if all ( isint ( k ) for k in d ) :,112
599,"def __share_local_dir(self, lpath, rpath, fast): <TAB> result = const.ENoError <TAB> for walk in self.__walk_normal_file(lpath): <TAB>  <TAB> (dirpath, dirnames, filenames) = walk <TAB>  <TAB> for filename in filenames: <TAB>  <TAB>  <TAB> rpart = os.path.relpath(dirpath, lpath) <TAB>  <TAB>  <TAB> if rpart == ""."": <TAB>  <TAB>  <TAB>  <TAB> rpart = """" <TAB>  <TAB>  <TAB> subr = self.__share_local_file( <TAB>  <TAB>  <TAB>  <TAB> joinpath(dirpath, filename), <TAB>  <TAB>  <TAB>  <TAB> posixpath.join(rpath, rpart, filename), <TAB>  <TAB>  <TAB>  <TAB> fast, <TAB>  <TAB>  <TAB> ) <MASK> result = subr <TAB> return result",if subr != const . ENoError :,183
600,"def _targets(self, sigmaparser): <TAB> # build list of matching target mappings <TAB> targets = set() <TAB> for condfield in self.conditions: <MASK> rulefieldvalues = sigmaparser.values[condfield] <TAB>  <TAB>  <TAB> for condvalue in self.conditions[condfield]: <TAB>  <TAB>  <TAB>  <TAB> if condvalue in rulefieldvalues: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> targets.update(self.conditions[condfield][condvalue]) <TAB> return targets",if condfield in sigmaparser . values :,115
601,"def _wrapped_view(request, *args, **kwargs): <TAB> # based on authority/decorators.py <TAB> user = request.user <TAB> if user.is_authenticated(): <TAB>  <TAB> obj = _resolve_lookup(obj_lookup, kwargs) <TAB>  <TAB> perm_obj = _resolve_lookup(perm_obj_lookup, kwargs) <TAB>  <TAB> granted = access.has_perm_or_owns(user, perm, obj, perm_obj, owner_attr) <MASK> return view_func(request, *args, **kwargs) <TAB> # In all other cases, permission denied <TAB> return HttpResponseForbidden()",if granted or user . has_perm ( perm ) :,157
602,"def assert_parts_cleaned(self, earlier_parts, current_parts, expected_parts, hint): <TAB> cleaned_parts = [] <TAB> for earlier in earlier_parts: <TAB>  <TAB> earlier_part = earlier[""part""] <TAB>  <TAB> earlier_step = earlier[""step""] <TAB>  <TAB> found = False <TAB>  <TAB> for current in current_parts: <MASK> found = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if not found: <TAB>  <TAB>  <TAB> cleaned_parts.append(dict(part=earlier_part, step=earlier_step)) <TAB> self.assertThat(cleaned_parts, HasLength(len(expected_parts)), hint) <TAB> for expected in expected_parts: <TAB>  <TAB> self.assertThat(cleaned_parts, Contains(expected), hint)","if earlier_part == current [ ""part"" ] and earlier_step == current [ ""step"" ] :",194
603,"def show_image(self, wnd_name, img): <TAB> if wnd_name in self.named_windows: <TAB>  <TAB> if self.named_windows[wnd_name] == 0: <TAB>  <TAB>  <TAB> self.named_windows[wnd_name] = 1 <TAB>  <TAB>  <TAB> self.on_create_window(wnd_name) <MASK> self.capture_mouse(wnd_name) <TAB>  <TAB> self.on_show_image(wnd_name, img) <TAB> else: <TAB>  <TAB> print(""show_image: named_window "", wnd_name, "" not found."")",if wnd_name in self . capture_mouse_windows :,159
604,"def readlines(self, hint=None): <TAB> # Again, allow hint but ignore <TAB> body = self._get_body() <TAB> rest = body[self.position :] <TAB> self.position = len(body) <TAB> result = [] <TAB> while 1: <TAB>  <TAB> next = rest.find(""\r\n"") <MASK> result.append(rest) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> result.append(rest[: next + 2]) <TAB>  <TAB> rest = rest[next + 2 :] <TAB> return result",if next == - 1 :,125
605,"def __lt__(self, other): <TAB> olen = len(other) <TAB> for i in range(olen): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> c = self[i] < other[i] <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB> # self must be shorter <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> if c: <TAB>  <TAB>  <TAB> return c <MASK> return False <TAB> return len(self) < olen",elif other [ i ] < self [ i ] :,108
606,"def social_user(backend, uid, user=None, *args, **kwargs): <TAB> provider = backend.name <TAB> social = backend.strategy.storage.user.get_social_auth(provider, uid) <TAB> if social: <TAB>  <TAB> if user and social.user != user: <TAB>  <TAB>  <TAB> msg = ""This account is already in use."" <TAB>  <TAB>  <TAB> raise AuthAlreadyAssociated(backend, msg) <MASK> user = social.user <TAB> return { <TAB>  <TAB> ""social"": social, <TAB>  <TAB> ""user"": user, <TAB>  <TAB> ""is_new"": user is None, <TAB>  <TAB> ""new_association"": social is None, <TAB> }",elif not user :,170
607,"def markUVs(self, indices=None): <TAB> if isinstance(indices, tuple): <TAB>  <TAB> indices = indices[0] <TAB> ntexco = len(self.texco) <TAB> if indices is None: <TAB>  <TAB> self.utexc = True <TAB> else: <TAB>  <TAB> if self.utexc is False: <TAB>  <TAB>  <TAB> self.utexc = np.zeros(ntexco, dtype=bool) <MASK> self.utexc[indices] = True",if self . utexc is not True :,120
608,"def destination(self, type, name, arglist): <TAB> classname = ""ResFunction"" <TAB> listname = ""functions"" <TAB> if arglist: <TAB>  <TAB> t, n, m = arglist[0] <MASK> classname = ""ResMethod"" <TAB>  <TAB>  <TAB> listname = ""resmethods"" <TAB> return classname, listname","if t == ""Handle"" and m == ""InMode"" :",90
609,"def select(self, regions, register): <TAB> self.view.sel().clear() <TAB> to_store = [] <TAB> for r in regions: <TAB>  <TAB> self.view.sel().add(r) <TAB>  <TAB> if register: <TAB>  <TAB>  <TAB> to_store.append(self.view.substr(self.view.full_line(r))) <TAB> if register: <TAB>  <TAB> text = """".join(to_store) <MASK> text = text + ""\n"" <TAB>  <TAB> state = State(self.view) <TAB>  <TAB> state.registers[register] = [text]","if not text . endswith ( ""\n"" ) :",142
610,"def _skip_start(self): <TAB> start, stop = self.start, self.stop <TAB> for chunk in self.app_iter: <TAB>  <TAB> self._pos += len(chunk) <TAB>  <TAB> if self._pos < start: <TAB>  <TAB>  <TAB> continue <MASK> return b"""" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> chunk = chunk[start - self._pos :] <TAB>  <TAB>  <TAB> if stop is not None and self._pos > stop: <TAB>  <TAB>  <TAB>  <TAB> chunk = chunk[: stop - self._pos] <TAB>  <TAB>  <TAB>  <TAB> assert len(chunk) == stop - start <TAB>  <TAB>  <TAB> return chunk <TAB> else: <TAB>  <TAB> raise StopIteration()",elif self . _pos == start :,156
611,"def start(self): <TAB> self.on_config_change() <TAB> self.start_config_watch() <TAB> try: <TAB>  <TAB> if self.config[""MITMf""][""DNS""][""tcp""].lower() == ""on"": <TAB>  <TAB>  <TAB> self.startTCP() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.startUDP() <TAB> except socket.error as e: <MASK> shutdown( <TAB>  <TAB>  <TAB>  <TAB> ""\n[DNS] Unable to start DNS server on port {}: port already in use"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.config[""MITMf""][""DNS""][""port""] <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> )","if ""Address already in use"" in e :",158
612,"def ignore(self, other): <TAB> if isinstance(other, Suppress): <TAB>  <TAB> if other not in self.ignoreExprs: <TAB>  <TAB>  <TAB> super(ParseElementEnhance, self).ignore(other) <MASK> self.expr.ignore(self.ignoreExprs[-1]) <TAB> else: <TAB>  <TAB> super(ParseElementEnhance, self).ignore(other) <TAB>  <TAB> if self.expr is not None: <TAB>  <TAB>  <TAB> self.expr.ignore(self.ignoreExprs[-1]) <TAB> return self",if self . expr is not None :,129
613,"def test_relative_deploy_path_override(): <TAB> s = Site(TEST_SITE_ROOT) <TAB> s.load() <TAB> res = s.content.resource_from_relative_path( <TAB>  <TAB> ""blog/2010/december/merry-christmas.html"" <TAB> ) <TAB> res.relative_deploy_path = ""blog/2010/december/happy-holidays.html"" <TAB> for page in s.content.walk_resources(): <MASK> assert page.relative_deploy_path == ""blog/2010/december/happy-holidays.html"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert page.relative_deploy_path == Folder(page.relative_path)",if res . source_file == page . source_file :,177
614,"def _parser(cls, buf): <TAB> tlvs = [] <TAB> while buf: <TAB>  <TAB> tlv_type = LLDPBasicTLV.get_type(buf) <TAB>  <TAB> tlv = cls._tlv_parsers[tlv_type](buf) <TAB>  <TAB> tlvs.append(tlv) <TAB>  <TAB> offset = LLDP_TLV_SIZE + tlv.len <TAB>  <TAB> buf = buf[offset:] <MASK> break <TAB>  <TAB> assert len(buf) > 0 <TAB> lldp_pkt = cls(tlvs) <TAB> assert lldp_pkt._tlvs_len_valid() <TAB> assert lldp_pkt._tlvs_valid() <TAB> return lldp_pkt, None, buf",if tlv . tlv_type == LLDP_TLV_END :,192
615,"def _do_pull(self, repo, pull_kwargs, silent, ignore_pull_failures): <TAB> try: <TAB>  <TAB> output = self.client.pull(repo, **pull_kwargs) <TAB>  <TAB> if silent: <TAB>  <TAB>  <TAB> with open(os.devnull, ""w"") as devnull: <TAB>  <TAB>  <TAB>  <TAB> yield from stream_output(output, devnull) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield from stream_output(output, sys.stdout) <TAB> except (StreamOutputError, NotFound) as e: <MASK> raise <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.error(str(e))",if not ignore_pull_failures :,151
616,def _collect_bytecode(ordered_code): <TAB> bytecode_blocks = [] <TAB> stack = [ordered_code] <TAB> while stack: <TAB>  <TAB> code = stack.pop() <TAB>  <TAB> bytecode_blocks.append(code.co_code) <TAB>  <TAB> for const in code.co_consts: <MASK> stack.append(const) <TAB> return bytecode_blocks,"if isinstance ( const , blocks . OrderedCode ) :",99
617,"def displayhook(value): <TAB> if value is None: <TAB>  <TAB> return <TAB> builtins = modules[""builtins""] <TAB> # Set '_' to None to avoid recursion <TAB> builtins._ = None <TAB> text = repr(value) <TAB> try: <TAB>  <TAB> local_stdout = stdout <TAB> except NameError as e: <TAB>  <TAB> raise RuntimeError(""lost sys.stdout"") from e <TAB> try: <TAB>  <TAB> local_stdout.write(text) <TAB> except UnicodeEncodeError: <TAB>  <TAB> bytes = text.encode(local_stdout.encoding, ""backslashreplace"") <MASK> local_stdout.buffer.write(bytes) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> text = bytes.decode(local_stdout.encoding, ""strict"") <TAB>  <TAB>  <TAB> local_stdout.write(text) <TAB> local_stdout.write(""\n"") <TAB> builtins._ = value","if hasattr ( local_stdout , ""buffer"" ) :",200
618,"def _analyze(self): <TAB> lines = open(self.log_path, ""r"").readlines() <TAB> prev_line = None <TAB> for line in lines: <TAB>  <TAB> if line.startswith(""ERROR:"") and prev_line and prev_line.startswith(""=""): <TAB>  <TAB>  <TAB> self.errors.append(line[len(""ERROR:"") :].strip()) <MASK> self.failures.append(line[len(""FAIL:"") :].strip()) <TAB>  <TAB> prev_line = line","elif line . startswith ( ""FAIL:"" ) and prev_line and prev_line . startswith ( ""="" ) :",128
619,"def _flush(self): <TAB> if self._data: <TAB>  <TAB> if self._last is not None: <TAB>  <TAB>  <TAB> text = """".join(self._data) <MASK> assert self._last.tail is None, ""internal error (tail)"" <TAB>  <TAB>  <TAB>  <TAB> self._last.tail = text <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> assert self._last.text is None, ""internal error (text)"" <TAB>  <TAB>  <TAB>  <TAB> self._last.text = text <TAB>  <TAB> self._data = []",if self . _tail :,125
620,"def write(self, chunk): <TAB> consumer = self._current_consumer <TAB> server_side = consumer.server_side <TAB> if server_side: <TAB>  <TAB> server_side.data_received(chunk) <TAB> else: <TAB>  <TAB> consumer.message += chunk <TAB>  <TAB> assert consumer.in_parser.execute(chunk, len(chunk)) == len(chunk) <MASK> consumer.finished()",if consumer . in_parser . is_message_complete ( ) :,114
621,"def _api_change_cat(name, output, kwargs): <TAB> """"""API: accepts output, value(=nzo_id), value2(=category)"""""" <TAB> value = kwargs.get(""value"") <TAB> value2 = kwargs.get(""value2"") <TAB> if value and value2: <TAB>  <TAB> nzo_id = value <TAB>  <TAB> cat = value2 <MASK> cat = None <TAB>  <TAB> result = sabnzbd.NzbQueue.change_cat(nzo_id, cat) <TAB>  <TAB> return report(output, keyword=""status"", data=bool(result > 0)) <TAB> else: <TAB>  <TAB> return report(output, _MSG_NO_VALUE)","if cat == ""None"" :",164
622,"def get_allocated_address( <TAB> self, config: ActorPoolConfig, allocated: allocated_type) -> str: <TAB> addresses = config.get_external_addresses(label=self.label) <TAB> for addr in addresses: <TAB>  <TAB> occupied = False <TAB>  <TAB> for strategy, _ in allocated.get(addr, dict()).values(): <MASK> occupied = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if not occupied: <TAB>  <TAB>  <TAB> return addr <TAB> raise NoIdleSlot( <TAB>  <TAB> f""No idle slot for creating actor "" f""with label {self.label}, mark {self.mark}"" <TAB> )",if strategy == self :,146
623,"def schedule_logger(job_id=None, delete=False): <TAB> if not job_id: <TAB>  <TAB> return getLogger(""fate_flow_schedule"") <TAB> else: <MASK> with LoggerFactory.lock: <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for key in LoggerFactory.schedule_logger_dict.keys(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if job_id in key: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> del LoggerFactory.schedule_logger_dict[key] <TAB>  <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> key = job_id + ""schedule"" <TAB>  <TAB> if key in LoggerFactory.schedule_logger_dict: <TAB>  <TAB>  <TAB> return LoggerFactory.schedule_logger_dict[key] <TAB>  <TAB> return LoggerFactory.get_schedule_logger(job_id)",if delete :,198
624,"def quick_load(tool_file, async_load=True): <TAB> try: <TAB>  <TAB> tool = self.load_tool(tool_file, tool_cache_data_dir) <TAB>  <TAB> self.__add_tool(tool, load_panel_dict, elems) <TAB>  <TAB> # Always load the tool into the integrated_panel_dict, or it will not be included in the integrated_tool_panel.xml file. <TAB>  <TAB> key = ""tool_%s"" % str(tool.id) <TAB>  <TAB> integrated_elems[key] = tool <MASK> self._load_tool_panel() <TAB>  <TAB>  <TAB> self._save_integrated_tool_panel() <TAB>  <TAB> return tool.id <TAB> except Exception: <TAB>  <TAB> log.exception(""Failed to load potential tool %s."", tool_file) <TAB>  <TAB> return None",if async_load :,195
625,"def _get_default_ordering(self): <TAB> try: <TAB>  <TAB> ordering = super(DocumentChangeList, self)._get_default_ordering() <TAB> except AttributeError: <TAB>  <TAB> ordering = [] <TAB>  <TAB> if self.model_admin.ordering: <TAB>  <TAB>  <TAB> ordering = self.model_admin.ordering <MASK> ordering = self.lookup_opts.ordering <TAB> return ordering",elif self . lookup_opts . ordering :,99
626,"def names(self, persistent=None): <TAB> u = set() <TAB> result = [] <TAB> for s in [ <TAB>  <TAB> self.__storage(None), <TAB>  <TAB> self.__storage(self.__category), <TAB> ]: <TAB>  <TAB> for b in s: <MASK> continue <TAB>  <TAB>  <TAB> if b.name.startswith(""__""): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if b.name not in u: <TAB>  <TAB>  <TAB>  <TAB> result.append(b.name) <TAB>  <TAB>  <TAB>  <TAB> u.add(b.name) <TAB> return result",if persistent is not None and b . persistent != persistent :,139
627,"def common_check_get_messages_query( <TAB> self, query_params: Dict[str, object], expected: str) -> None: <TAB> user_profile = self.example_user(""hamlet"") <TAB> request = POSTRequestMock(query_params, user_profile) <TAB> with queries_captured() as queries: <TAB>  <TAB> get_messages_backend(request, user_profile) <TAB> for query in queries: <MASK> sql = str(query[""sql""]).replace("" /* get_messages */"", """") <TAB>  <TAB>  <TAB> self.assertEqual(sql, expected) <TAB>  <TAB>  <TAB> return <TAB> raise AssertionError(""get_messages query not found"")","if ""/* get_messages */"" in query [ ""sql"" ] :",161
628,"def _activate_only_current_top_active(): <TAB> for i in range(0, len(current_sequence().tracks) - 1): <MASK> current_sequence().tracks[i].active = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> current_sequence().tracks[i].active = False <TAB> gui.tline_column.widget.queue_draw()",if i == current_sequence ( ) . get_first_active_track ( ) . id :,103
629,"def http_wrapper(self, url, postdata={}): <TAB> try: <TAB>  <TAB> if postdata != {}: <TAB>  <TAB>  <TAB> f = urllib.urlopen(url, postdata) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> f = urllib.urlopen(url) <TAB>  <TAB> response = f.read() <TAB> except: <TAB>  <TAB> import traceback <TAB>  <TAB> import logging, sys <TAB>  <TAB> cla, exc, tb = sys.exc_info() <TAB>  <TAB> logging.error(url) <MASK> logging.error(""with post data"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logging.error(""without post data"") <TAB>  <TAB> logging.error(exc.args) <TAB>  <TAB> logging.error(traceback.format_tb(tb)) <TAB>  <TAB> response = """" <TAB> return response",if postdata :,178
630,"def frequent_thread_switches(): <TAB> """"""Make concurrency bugs more likely to manifest."""""" <TAB> interval = None <MASK> if hasattr(sys, ""getswitchinterval""): <TAB>  <TAB>  <TAB> interval = sys.getswitchinterval() <TAB>  <TAB>  <TAB> sys.setswitchinterval(1e-6) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> interval = sys.getcheckinterval() <TAB>  <TAB>  <TAB> sys.setcheckinterval(1) <TAB> try: <TAB>  <TAB> yield <TAB> finally: <TAB>  <TAB> if not sys.platform.startswith(""java""): <TAB>  <TAB>  <TAB> if hasattr(sys, ""setswitchinterval""): <TAB>  <TAB>  <TAB>  <TAB> sys.setswitchinterval(interval) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> sys.setcheckinterval(interval)","if not sys . platform . startswith ( ""java"" ) :",177
631,"def iter_filters(filters, block_end=False): <TAB> queue = deque(filters) <TAB> while queue: <TAB>  <TAB> f = queue.popleft() <MASK> if block_end: <TAB>  <TAB>  <TAB>  <TAB> queue.appendleft(None) <TAB>  <TAB>  <TAB> for gf in f.filters: <TAB>  <TAB>  <TAB>  <TAB> queue.appendleft(gf) <TAB>  <TAB> yield f","if f is not None and f . type in ( ""or"" , ""and"" , ""not"" ) :",105
632,"def smartsplit(code): <TAB> """"""Split `code` at "" symbol, only if it is not escaped."""""" <TAB> strings = [] <TAB> pos = 0 <TAB> while pos < len(code): <MASK> word = """"  # new word <TAB>  <TAB>  <TAB> pos += 1 <TAB>  <TAB>  <TAB> while pos < len(code): <TAB>  <TAB>  <TAB>  <TAB> if code[pos] == '""': <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB>  <TAB> if code[pos] == ""\\"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> word += ""\\"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pos += 1 <TAB>  <TAB>  <TAB>  <TAB> word += code[pos] <TAB>  <TAB>  <TAB>  <TAB> pos += 1 <TAB>  <TAB>  <TAB> strings.append('""%s""' % word) <TAB>  <TAB> pos += 1 <TAB> return strings","if code [ pos ] == '""' :",174
633,"def get_folder_content(cls, name): <TAB> """"""Return (folders, files) for the given folder in the root dir."""""" <TAB> folders = set() <TAB> files = set() <TAB> for path in cls.LAYOUT: <MASK> continue <TAB>  <TAB> parts = path.split(""/"") <TAB>  <TAB> if len(parts) == 2: <TAB>  <TAB>  <TAB> files.add(parts[1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> folders.add(parts[1]) <TAB> folders = list(folders) <TAB> folders.sort() <TAB> files = list(files) <TAB> files.sort() <TAB> return (folders, files)","if not path . startswith ( name + ""/"" ) :",155
634,"def array_for(self, i): <TAB> if 0 <= i < self._cnt: <MASK> return self._tail <TAB>  <TAB> node = self._root <TAB>  <TAB> level = self._shift <TAB>  <TAB> while level > 0: <TAB>  <TAB>  <TAB> assert isinstance(node, Node) <TAB>  <TAB>  <TAB> node = node._array[(i >> level) & 0x01F] <TAB>  <TAB>  <TAB> level -= 5 <TAB>  <TAB> assert isinstance(node, Node) <TAB>  <TAB> return node._array <TAB> affirm(False, u""Index out of Range"")",if i >= self . tailoff ( ) :,135
635,"def __or__(self, other) -> ""MultiVector"": <TAB> r""""""``self | other``, the inner product :math:`M \cdot N`"""""" <TAB> other, mv = self._checkOther(other) <TAB> if mv: <TAB>  <TAB> newValue = self.layout.imt_func(self.value, other.value) <TAB> else: <MASK> obj = self.__array__() <TAB>  <TAB>  <TAB> return obj | other <TAB>  <TAB> # l * M = M * l = 0 for scalar l <TAB>  <TAB> return self._newMV(dtype=np.result_type(self.value.dtype, other)) <TAB> return self._newMV(newValue)","if isinstance ( other , np . ndarray ) :",163
636,"def parse_bzr_stats(status): <TAB> stats = RepoStats() <TAB> statustype = ""changed"" <TAB> for statusline in status: <TAB>  <TAB> if statusline[:2] == ""  "": <TAB>  <TAB>  <TAB> setattr(stats, statustype, getattr(stats, statustype) + 1) <MASK> statustype = ""staged"" <TAB>  <TAB> elif statusline == ""unknown:"": <TAB>  <TAB>  <TAB> statustype = ""new"" <TAB>  <TAB> else:  # removed, missing, renamed, modified or kind changed <TAB>  <TAB>  <TAB> statustype = ""changed"" <TAB> return stats","elif statusline == ""added:"" :",146
637,"def write(self, timestamps, actualValues, predictedValues, predictionStep=1): <TAB> assert len(timestamps) == len(actualValues) == len(predictedValues) <TAB> for index in range(len(self.names)): <TAB>  <TAB> timestamp = timestamps[index] <TAB>  <TAB> actual = actualValues[index] <TAB>  <TAB> prediction = predictedValues[index] <TAB>  <TAB> writer = self.outputWriters[index] <MASK> outputRow = [timestamp, actual, prediction] <TAB>  <TAB>  <TAB> writer.writerow(outputRow) <TAB>  <TAB>  <TAB> self.lineCounts[index] += 1",if timestamp is not None :,142
638,"def clean(self): <TAB> """"""Delete old files in ""tmp""."""""" <TAB> now = time.time() <TAB> for entry in os.listdir(os.path.join(self._path, ""tmp"")): <TAB>  <TAB> path = os.path.join(self._path, ""tmp"", entry) <MASK> # 60 * 60 * 36 <TAB>  <TAB>  <TAB> os.remove(path)",if now - os . path . getatime ( path ) > 129600 :,101
639,"def _get_info(self, path): <TAB> info = OrderedDict() <TAB> if not self._is_mac() or self._has_xcode_tools(): <TAB>  <TAB> stdout = None <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> stdout, stderr = Popen( <TAB>  <TAB>  <TAB>  <TAB> [self._find_binary(), ""info"", os.path.realpath(path)], <TAB>  <TAB>  <TAB>  <TAB> stdout=PIPE, <TAB>  <TAB>  <TAB>  <TAB> stderr=PIPE, <TAB>  <TAB>  <TAB> ).communicate() <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <MASK> for line in stdout.splitlines(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> line = u(line).split("": "", 1) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if len(line) == 2: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> info[line[0]] = line[1] <TAB> return info",if stdout :,194
640,"def add(meta_list, info_list=None): <TAB> if not info_list: <TAB>  <TAB> info_list = meta_list <TAB> if not isinstance(meta_list, (list, tuple)): <TAB>  <TAB> meta_list = (meta_list,) <TAB> if not isinstance(info_list, (list, tuple)): <TAB>  <TAB> info_list = (info_list,) <TAB> for info_f in info_list: <MASK> for meta_f in meta_list: <TAB>  <TAB>  <TAB>  <TAB> metadata[meta_f] = info[info_f] <TAB>  <TAB>  <TAB> break",if info . get ( info_f ) is not None :,149
641,"def _compute_log_r(model_trace, guide_trace): <TAB> log_r = MultiFrameTensor() <TAB> stacks = get_plate_stacks(model_trace) <TAB> for name, model_site in model_trace.nodes.items(): <MASK> log_r_term = model_site[""log_prob""] <TAB>  <TAB>  <TAB> if not model_site[""is_observed""]: <TAB>  <TAB>  <TAB>  <TAB> log_r_term = log_r_term - guide_trace.nodes[name][""log_prob""] <TAB>  <TAB>  <TAB> log_r.add((stacks[name], log_r_term.detach())) <TAB> return log_r","if model_site [ ""type"" ] == ""sample"" :",162
642,"def pickline(file, key, casefold=1): <TAB> try: <TAB>  <TAB> f = open(file, ""r"") <TAB> except IOError: <TAB>  <TAB> return None <TAB> pat = re.escape(key) + "":"" <TAB> prog = re.compile(pat, casefold and re.IGNORECASE) <TAB> while 1: <TAB>  <TAB> line = f.readline() <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if prog.match(line): <TAB>  <TAB>  <TAB> text = line[len(key) + 1 :] <TAB>  <TAB>  <TAB> while 1: <TAB>  <TAB>  <TAB>  <TAB> line = f.readline() <MASK> break <TAB>  <TAB>  <TAB>  <TAB> text = text + line <TAB>  <TAB>  <TAB> return text.strip() <TAB> return None",if not line or not line [ 0 ] . isspace ( ) :,182
643,"def build_iterator(data, infinite=True): <TAB> """"""Build the iterator for inputs."""""" <TAB> index = 0 <TAB> size = len(data[0]) <TAB> while True: <TAB>  <TAB> if index + batch_size > size: <MASK> index = 0 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> yield data[0][index : index + batch_size], data[1][index : index + batch_size] <TAB>  <TAB> index += batch_size",if infinite :,116
644,"def checkall(g, bg, dst_nodes, include_dst_in_src=True): <TAB> for etype in g.etypes: <TAB>  <TAB> ntype = g.to_canonical_etype(etype)[2] <MASK> check(g, bg, ntype, etype, dst_nodes[ntype], include_dst_in_src) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> check(g, bg, ntype, etype, None, include_dst_in_src)",if dst_nodes is not None and ntype in dst_nodes :,124
645,"def minimalBases(classes): <TAB> """"""Reduce a list of base classes to its ordered minimum equivalent"""""" <TAB> if not __python3:  # pragma: no cover <TAB>  <TAB> classes = [c for c in classes if c is not ClassType] <TAB> candidates = [] <TAB> for m in classes: <TAB>  <TAB> for n in classes: <TAB>  <TAB>  <TAB> if issubclass(n, m) and m is not n: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # m has no subclasses in 'classes' <MASK> candidates.remove(m)  # ensure that we're later in the list <TAB>  <TAB>  <TAB> candidates.append(m) <TAB> return candidates",if m in candidates :,160
646,"def __keep_songs_enable(self, enabled): <TAB> config.set(""memory"", ""queue_keep_songs"", enabled) <TAB> if enabled: <TAB>  <TAB> self.queue.set_first_column_type(CurrentColumn) <TAB> else: <TAB>  <TAB> for col in self.queue.get_columns(): <TAB>  <TAB>  <TAB> # Remove the CurrentColum if it exists <MASK> self.queue.set_first_column_type(None) <TAB>  <TAB>  <TAB>  <TAB> break","if isinstance ( col , CurrentColumn ) :",121
647,"def outlineView_heightOfRowByItem_(self, tree, item) -> float: <TAB> default_row_height = self.rowHeight <TAB> if item is self: <TAB>  <TAB> return default_row_height <TAB> heights = [default_row_height] <TAB> for column in self.tableColumns: <TAB>  <TAB> value = getattr(item.attrs[""node""], str(column.identifier)) <MASK> # if the cell value is a widget, use its height <TAB>  <TAB>  <TAB> heights.append(value._impl.native.intrinsicContentSize().height) <TAB> return max(heights)","if isinstance ( value , toga . Widget ) :",146
648,"def condition(self): <TAB> if self.__condition is None: <MASK> # Avoid an extra indirection in the common case of only one condition. <TAB>  <TAB>  <TAB> self.__condition = self.flat_conditions[0] <TAB>  <TAB> elif len(self.flat_conditions) == 0: <TAB>  <TAB>  <TAB> # Possible, if unlikely, due to filter predicate rewriting <TAB>  <TAB>  <TAB> self.__condition = lambda _: True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.__condition = lambda x: all(cond(x) for cond in self.flat_conditions) <TAB> return self.__condition",if len ( self . flat_conditions ) == 1 :,143
649,"def _find_delimiter(f, block_size=2 ** 16): <TAB> delimiter = b""\n"" <TAB> if f.tell() == 0: <TAB>  <TAB> return 0 <TAB> while True: <TAB>  <TAB> b = f.read(block_size) <TAB>  <TAB> if not b: <TAB>  <TAB>  <TAB> return f.tell() <MASK> return f.tell() - len(b) + b.index(delimiter) + 1",elif delimiter in b :,105
650,"def serialize(self, name=None): <TAB> data = super(SimpleText, self).serialize(name) <TAB> data[""contentType""] = self.contentType <TAB> data[""content""] = self.content <TAB> if self.width: <MASK> raise InvalidWidthException(self.width) <TAB>  <TAB> data[""inputOptions""] = {} <TAB>  <TAB> data[""width""] = self.width <TAB> return data","if self . width not in [ 100 , 50 , 33 , 25 ] :",108
651,"def inference(self): <TAB> self.attention_weight_dim = self.input_dims[0][-1] <TAB> if self.keep_dim: <TAB>  <TAB> self.output_dim = copy.deepcopy(self.input_dims[0]) <TAB> else: <TAB>  <TAB> self.output_dim = [] <TAB>  <TAB> for idx, dim in enumerate(self.input_dims[0]): <MASK> self.output_dim.append(dim) <TAB> super( <TAB>  <TAB> LinearAttentionConf, self <TAB> ).inference()  # PUT THIS LINE AT THE END OF inference()",if idx != len ( self . input_dims [ 0 ] ) - 2 :,152
652,"def __delete_hook(self, rpc): <TAB> try: <TAB>  <TAB> rpc.check_success() <TAB> except apiproxy_errors.Error: <TAB>  <TAB> return None <TAB> result = [] <TAB> for status in rpc.response.delete_status_list(): <TAB>  <TAB> if status == MemcacheDeleteResponse.DELETED: <TAB>  <TAB>  <TAB> result.append(DELETE_SUCCESSFUL) <MASK> result.append(DELETE_ITEM_MISSING) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result.append(DELETE_NETWORK_FAILURE) <TAB> return result",elif status == MemcacheDeleteResponse . NOT_FOUND :,139
653,def identify_page_at_cursor(self): <TAB> for region in self.view.sel(): <TAB>  <TAB> text_on_cursor = None <TAB>  <TAB> pos = region.begin() <TAB>  <TAB> scope_region = self.view.extract_scope(pos) <MASK> text_on_cursor = self.view.substr(scope_region) <TAB>  <TAB>  <TAB> return text_on_cursor.strip(string.punctuation) <TAB> return None,if not scope_region . empty ( ) :,111
654,"def from_elem(cls, parent, when_elem): <TAB> """"""Loads the proper when by attributes of elem"""""" <TAB> when_value = when_elem.get(""value"", None) <MASK> return ValueToolOutputActionConditionalWhen(parent, when_elem, when_value) <TAB> else: <TAB>  <TAB> when_value = when_elem.get(""datatype_isinstance"", None) <TAB>  <TAB> if when_value is not None: <TAB>  <TAB>  <TAB> return DatatypeIsInstanceToolOutputActionConditionalWhen( <TAB>  <TAB>  <TAB>  <TAB> parent, when_elem, when_value <TAB>  <TAB>  <TAB> ) <TAB> raise TypeError(""When type not implemented"")",if when_value is not None :,151
655,"def test_insert_entity_empty_string_rk( <TAB> self, tables_cosmos_account_name, tables_primary_cosmos_account_key): <TAB> # Arrange <TAB> await self._set_up(tables_cosmos_account_name, tables_primary_cosmos_account_key) <TAB> try: <TAB>  <TAB> entity = {""PartitionKey"": ""pk"", ""RowKey"": """"} <TAB>  <TAB> # Act <TAB>  <TAB> with pytest.raises(HttpResponseError): <TAB>  <TAB>  <TAB> await self.table.create_entity(entity=entity) <TAB>  <TAB>  <TAB> # Assert <TAB>  <TAB> #  assert resp is None <TAB> finally: <TAB>  <TAB> await self._tear_down() <MASK> sleep(SLEEP_DELAY)",if self . is_live :,179
656,"def provider_uris(self): <TAB> login_urls = {} <TAB> continue_url = self.request.get(""continue_url"") <TAB> for provider in self.provider_info: <MASK> login_url = self.uri_for( <TAB>  <TAB>  <TAB>  <TAB> ""social-login"", provider_name=provider, continue_url=continue_url <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> login_url = self.uri_for(""social-login"", provider_name=provider) <TAB>  <TAB> login_urls[provider] = login_url <TAB> return login_urls",if continue_url :,140
657,"def expand_extensions(existing): <TAB> for name in extension_names: <TAB>  <TAB> ext = ( <TAB>  <TAB>  <TAB> im(""lizard_ext.lizard"" + name.lower()).LizardExtension() <MASK> else name <TAB>  <TAB> ) <TAB>  <TAB> existing.insert( <TAB>  <TAB>  <TAB> len(existing) if not hasattr(ext, ""ordering_index"") else ext.ordering_index, <TAB>  <TAB>  <TAB> ext, <TAB>  <TAB> ) <TAB> return existing","if isinstance ( name , str )",116
658,"def wrapper(self, *args, **kwargs): <TAB> if not self.request.path.endswith(""/""): <TAB>  <TAB> if self.request.method in (""GET"", ""HEAD""): <TAB>  <TAB>  <TAB> uri = self.request.path + ""/"" <MASK> uri += ""?"" + self.request.query <TAB>  <TAB>  <TAB> self.redirect(uri, permanent=True) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> raise HTTPError(404) <TAB> return method(self, *args, **kwargs)",if self . request . query :,118
659,"def subword_map_by_joiner(subwords, marker=SubwordMarker.JOINER): <TAB> """"""Return word id for each subword token (annotate by joiner)."""""" <TAB> flags = [0] * len(subwords) <TAB> for i, tok in enumerate(subwords): <MASK> flags[i] = 1 <TAB>  <TAB> if tok.startswith(marker): <TAB>  <TAB>  <TAB> assert i >= 1 and flags[i - 1] != 1, ""Sentence `{}` not correct!"".format( <TAB>  <TAB>  <TAB>  <TAB> "" "".join(subwords) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> flags[i - 1] = 1 <TAB> marker_acc = list(accumulate([0] + flags[:-1])) <TAB> word_group = [(i - maker_sofar) for i, maker_sofar in enumerate(marker_acc)] <TAB> return word_group",if tok . endswith ( marker ) :,193
660,"def next_item(self, direction): <TAB> """"""Selects next menu item, based on self._direction"""""" <TAB> start, i = -1, 0 <TAB> try: <TAB>  <TAB> start = self.items.index(self._selected) <TAB>  <TAB> i = start + direction <TAB> except: <TAB>  <TAB> pass <TAB> while True: <TAB>  <TAB> if i == start: <TAB>  <TAB>  <TAB> # Cannot find valid menu item <TAB>  <TAB>  <TAB> self.select(start) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if i >= len(self.items): <TAB>  <TAB>  <TAB> i = 0 <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if i < 0: <TAB>  <TAB>  <TAB> i = len(self.items) - 1 <TAB>  <TAB>  <TAB> continue <MASK> break <TAB>  <TAB> i += direction <TAB>  <TAB> if start < 0: <TAB>  <TAB>  <TAB> start = 0",if self . select ( i ) :,194
661,"def get_config(cls): <TAB> # FIXME: Replace this as soon as we have a config module <TAB> config = {} <TAB> # Try to get iflytek_yuyin config from config <TAB> profile_path = dingdangpath.config(""profile.yml"") <TAB> if os.path.exists(profile_path): <TAB>  <TAB> with open(profile_path, ""r"") as f: <TAB>  <TAB>  <TAB> profile = yaml.safe_load(f) <MASK> if ""vid"" in profile[""iflytek_yuyin""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> config[""vid""] = profile[""iflytek_yuyin""][""vid""] <TAB> return config","if ""iflytek_yuyin"" in profile :",169
662,"def get_signed_in_user(test_case): <TAB> playback = not (test_case.is_live or test_case.in_recording) <TAB> if playback: <TAB>  <TAB> return MOCKED_USER_NAME <TAB> else: <TAB>  <TAB> account_info = test_case.cmd(""account show"").get_output_in_json() <MASK> return account_info[""user""][""name""] <TAB> return None","if account_info [ ""user"" ] [ ""type"" ] != ""servicePrincipal"" :",115
663,"def rename_project(self, project, new_name): <TAB> """"""Rename project, update the related projects if necessary"""""" <TAB> old_name = project.name <TAB> for proj in self.projects: <TAB>  <TAB> relproj = proj.get_related_projects() <MASK> relproj[relproj.index(old_name)] = new_name <TAB>  <TAB>  <TAB> proj.set_related_projects(relproj) <TAB> project.rename(new_name) <TAB> self.save()",if old_name in relproj :,121
664,"def test_call_extern_c_fn(self): <TAB> global memcmp <TAB> memcmp = cffi_support.ExternCFunction( <TAB>  <TAB> ""memcmp"", <TAB>  <TAB> (""int memcmp ( const uint8_t * ptr1, "" ""const uint8_t * ptr2, size_t num )""), <TAB> ) <TAB> @udf(BooleanVal(FunctionContext, StringVal, StringVal)) <TAB> def fn(context, a, b): <TAB>  <TAB> if a.is_null != b.is_null: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> if a is None: <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> if len(a) != b.len: <TAB>  <TAB>  <TAB> return False <MASK> return True <TAB>  <TAB> return memcmp(a.ptr, b.ptr, a.len) == 0",if a . ptr == b . ptr :,199
665,"def parse_variable(self): <TAB> begin = self._pos <TAB> while True: <TAB>  <TAB> ch = self.read() <MASK> return ScriptVariable(self._text[begin : self._pos - 1]) <TAB>  <TAB> elif ch is None: <TAB>  <TAB>  <TAB> self.__raise_eof() <TAB>  <TAB> elif not isidentif(ch) and ch != "":"": <TAB>  <TAB>  <TAB> self.__raise_char(ch)","if ch == ""%"" :",101
666,"def h_file(self): <TAB> filename = self.abspath() <TAB> st = os.stat(filename) <TAB> cache = self.ctx.hashes_md5_tstamp <TAB> if filename in cache and cache[filename][0] == st.st_mtime: <TAB>  <TAB> return cache[filename][1] <TAB> if STRONGEST: <TAB>  <TAB> ret = Utils.h_file(filename) <TAB> else: <MASK> raise IOError(""Not a file"") <TAB>  <TAB> ret = Utils.md5(str((st.st_mtime, st.st_size)).encode()).digest() <TAB> cache[filename] = (st.st_mtime, ret) <TAB> return ret",if stat . S_ISDIR ( st [ stat . ST_MODE ] ) :,172
667,"def add_widgets(self, *widgets_or_spacings): <TAB> """"""Add widgets/spacing to dialog vertical layout"""""" <TAB> layout = self.layout() <TAB> for widget_or_spacing in widgets_or_spacings: <MASK> layout.addSpacing(widget_or_spacing) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> layout.addWidget(widget_or_spacing)","if isinstance ( widget_or_spacing , int ) :",103
668,"def _str_index(self): <TAB> idx = self[""index""] <TAB> out = [] <TAB> if len(idx) == 0: <TAB>  <TAB> return out <TAB> out += ["".. index:: %s"" % idx.get(""default"", """")] <TAB> for section, references in idx.iteritems(): <MASK> continue <TAB>  <TAB> elif section == ""refguide"": <TAB>  <TAB>  <TAB> out += [""   single: %s"" % ("", "".join(references))] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> out += [""   %s: %s"" % (section, "","".join(references))] <TAB> return out","if section == ""default"" :",145
669,"def dictify_CPPDEFINES(env): <TAB> cppdefines = env.get(""CPPDEFINES"", {}) <TAB> if cppdefines is None: <TAB>  <TAB> return {} <TAB> if SCons.Util.is_Sequence(cppdefines): <TAB>  <TAB> result = {} <TAB>  <TAB> for c in cppdefines: <MASK> result[c[0]] = c[1] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> result[c] = None <TAB>  <TAB> return result <TAB> if not SCons.Util.is_Dict(cppdefines): <TAB>  <TAB> return {cppdefines: None} <TAB> return cppdefines",if SCons . Util . is_Sequence ( c ) :,155
670,"def decoder(s): <TAB> r = [] <TAB> decode = [] <TAB> for c in s: <TAB>  <TAB> if c == ""&"" and not decode: <TAB>  <TAB>  <TAB> decode.append(""&"") <TAB>  <TAB> elif c == ""-"" and decode: <TAB>  <TAB>  <TAB> if len(decode) == 1: <TAB>  <TAB>  <TAB>  <TAB> r.append(""&"") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> r.append(modified_unbase64("""".join(decode[1:]))) <TAB>  <TAB>  <TAB> decode = [] <MASK> decode.append(c) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> r.append(c) <TAB> if decode: <TAB>  <TAB> r.append(modified_unbase64("""".join(decode[1:]))) <TAB> bin_str = """".join(r) <TAB> return (bin_str, len(s))",elif decode :,188
671,"def optimize(self, graph: Graph): <TAB> MAX_TEXTURE_SIZE = config.WEBGL_MAX_TEXTURE_SIZE <TAB> flag_changed = False <TAB> for v in traverse.listup_variables(graph): <MASK> continue <TAB>  <TAB> height, width = TextureShape.get(v) <TAB>  <TAB> if height <= MAX_TEXTURE_SIZE and width <= MAX_TEXTURE_SIZE: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if not v.has_attribute(SplitTarget): <TAB>  <TAB>  <TAB> flag_changed = True <TAB>  <TAB>  <TAB> v.attributes.add(SplitTarget()) <TAB> return graph, flag_changed",if not Placeholder . check_resolved ( v . size ) :,157
672,"def one_gpr_reg_one_mem_scalable(ii): <TAB> n, r = 0, 0 <TAB> for op in _gen_opnds(ii): <TAB>  <TAB> if op_agen(op) or (op_mem(op) and op.oc2 in [""v""]): <TAB>  <TAB>  <TAB> n += 1 <MASK> r += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> return n == 1 and r == 1",elif op_gprv ( op ) :,113
673,"def get_genome_dir(gid, galaxy_dir, data): <TAB> """"""Return standard location of genome directories."""""" <TAB> if galaxy_dir: <TAB>  <TAB> refs = genome.get_refs(gid, None, galaxy_dir, data) <TAB>  <TAB> seq_file = tz.get_in([""fasta"", ""base""], refs) <TAB>  <TAB> if seq_file and os.path.exists(seq_file): <TAB>  <TAB>  <TAB> return os.path.dirname(os.path.dirname(seq_file)) <TAB> else: <TAB>  <TAB> gdirs = glob.glob(os.path.join(_get_data_dir(), ""genomes"", ""*"", gid)) <MASK> return gdirs[0]",if len ( gdirs ) == 1 and os . path . exists ( gdirs [ 0 ] ) :,190
674,"def __modules(self): <TAB> raw_output = self.__module_avail_output().decode(""utf-8"") <TAB> for line in StringIO(raw_output): <TAB>  <TAB> line = line and line.strip() <TAB>  <TAB> if not line or line.startswith(""-""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> line_modules = line.split() <TAB>  <TAB> for module in line_modules: <MASK> module = module[0 : -len(self.default_indicator)].strip() <TAB>  <TAB>  <TAB> module_parts = module.split(""/"") <TAB>  <TAB>  <TAB> module_version = None <TAB>  <TAB>  <TAB> if len(module_parts) == 2: <TAB>  <TAB>  <TAB>  <TAB> module_version = module_parts[1] <TAB>  <TAB>  <TAB> module_name = module_parts[0] <TAB>  <TAB>  <TAB> yield module_name, module_version",if module . endswith ( self . default_indicator ) :,199
675,"def save(self): <TAB> updates = self.cinder_obj_get_changes() <TAB> if updates: <MASK> metadata = updates.pop(""metadata"", None) <TAB>  <TAB>  <TAB> self.metadata = db.backup_metadata_update( <TAB>  <TAB>  <TAB>  <TAB> self._context, self.id, metadata, True <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> updates.pop(""parent"", None) <TAB>  <TAB> db.backup_update(self._context, self.id, updates) <TAB> self.obj_reset_changes()","if ""metadata"" in updates :",127
676,"def test_set_tag(association_obj, sagemaker_session): <TAB> tag = {""Key"": ""foo"", ""Value"": ""bar""} <TAB> association_obj.set_tag(tag) <TAB> while True: <TAB>  <TAB> actual_tags = sagemaker_session.sagemaker_client.list_tags( <TAB>  <TAB>  <TAB> ResourceArn=association_obj.source_arn <TAB>  <TAB> )[""Tags""] <MASK> break <TAB>  <TAB> time.sleep(5) <TAB> # When sagemaker-client-config endpoint-url is passed as argument to hit some endpoints, <TAB> # length of actual tags will be greater than 1 <TAB> assert len(actual_tags) > 0 <TAB> assert actual_tags[0] == tag",if actual_tags :,175
677,"def test_error_stream(environ, start_response): <TAB> writer = start_response(""200 OK"", []) <TAB> wsgi_errors = environ[""wsgi.errors""] <TAB> error_msg = None <TAB> for method in [ <TAB>  <TAB> ""flush"", <TAB>  <TAB> ""write"", <TAB>  <TAB> ""writelines"", <TAB> ]: <TAB>  <TAB> if not hasattr(wsgi_errors, method): <TAB>  <TAB>  <TAB> error_msg = ""wsgi.errors has no '%s' attr"" % method <MASK> error_msg = ""wsgi.errors.%s attr is not callable"" % method <TAB>  <TAB> if error_msg: <TAB>  <TAB>  <TAB> break <TAB> return_msg = error_msg or ""success"" <TAB> writer(return_msg) <TAB> return []","if not error_msg and not callable ( getattr ( wsgi_errors , method ) ) :",185
678,"def current_dict(cursor_offset, line): <TAB> """"""If in dictionary completion, return the dict that should be used"""""" <TAB> for m in current_dict_re.finditer(line): <MASK> return LinePart(m.start(1), m.end(1), m.group(1)) <TAB> return None",if m . start ( 2 ) <= cursor_offset and m . end ( 2 ) >= cursor_offset :,99
679,"def show_file_browser(self): <TAB> """"""Show/hide the file browser."""""" <TAB> if self.show_file_browser_action.isChecked(): <TAB>  <TAB> sizes = self.panel.sizes() <MASK> sizes[0] = sum(sizes) // 4 <TAB>  <TAB>  <TAB> self.panel.setSizes(sizes) <TAB>  <TAB> self.file_browser.show() <TAB> else: <TAB>  <TAB> self.file_browser.hide()",if sizes [ 0 ] == 0 :,112
680,"def run(self, paths=[]): <TAB> items = [] <TAB> for item in SideBarSelection(paths).getSelectedItems(): <TAB>  <TAB> items.append(item.nameEncoded()) <TAB> if len(items) > 0: <TAB>  <TAB> sublime.set_clipboard(""\n"".join(items)) <MASK> sublime.status_message(""Items copied"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sublime.status_message(""Item copied"")",if len ( items ) > 1 :,114
681,"def prepend(self, value): <TAB> """"""prepend value to nodes"""""" <TAB> root, root_text = self._get_root(value) <TAB> for i, tag in enumerate(self): <MASK> tag.text = """" <TAB>  <TAB> if len(root) > 0: <TAB>  <TAB>  <TAB> root[-1].tail = tag.text <TAB>  <TAB>  <TAB> tag.text = root_text <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tag.text = root_text + tag.text <TAB>  <TAB> if i > 0: <TAB>  <TAB>  <TAB> root = deepcopy(list(root)) <TAB>  <TAB> tag[:0] = root <TAB>  <TAB> root = tag[: len(root)] <TAB> return self",if not tag . text :,160
682,"def getLabel(self, address=None): <TAB> if address is None: <TAB>  <TAB> address = self.address <TAB> label = address <TAB> if shared.config.has_section(address): <TAB>  <TAB> label = shared.config.get(address, ""label"") <TAB> queryreturn = sqlQuery(""""""select label from addressbook where address=?"""""", address) <MASK> for row in queryreturn: <TAB>  <TAB>  <TAB> (label,) = row <TAB> else: <TAB>  <TAB> queryreturn = sqlQuery( <TAB>  <TAB>  <TAB> """"""select label from subscriptions where address=?"""""", address <TAB>  <TAB> ) <TAB>  <TAB> if queryreturn != []: <TAB>  <TAB>  <TAB> for row in queryreturn: <TAB>  <TAB>  <TAB>  <TAB> (label,) = row <TAB> return label",if queryreturn != [ ] :,168
683,"def _parse(self, engine): <TAB> """"""Parse the layer."""""" <TAB> if isinstance(self.args, dict): <TAB>  <TAB> if ""axis"" in self.args: <TAB>  <TAB>  <TAB> self.axis = engine.evaluate(self.args[""axis""], recursive=True) <TAB>  <TAB>  <TAB> if not isinstance(self.axis, int): <TAB>  <TAB>  <TAB>  <TAB> raise ParsingError('""axis"" must be an integer.') <MASK> self.momentum = engine.evaluate(self.args[""momentum""], recursive=True) <TAB>  <TAB>  <TAB> if not isinstance(self.momentum, (int, float)): <TAB>  <TAB>  <TAB>  <TAB> raise ParsingError('""momentum"" must be numeric.')","if ""momentum"" in self . args :",157
684,"def urlquote(*args, **kwargs): <TAB> new_kwargs = dict(kwargs) <TAB> if not PY3: <TAB>  <TAB> new_kwargs = dict(kwargs) <TAB>  <TAB> if ""encoding"" in new_kwargs: <TAB>  <TAB>  <TAB> del new_kwargs[""encoding""] <MASK> del new_kwargs[""errors""] <TAB> return quote(*args, **new_kwargs)","if ""errors"" in kwargs :",93
685,"def setNextFormPrevious(self, backup=STARTING_FORM): <TAB> try: <TAB>  <TAB> if self._THISFORM.FORM_NAME == self._FORM_VISIT_LIST[-1]: <TAB>  <TAB>  <TAB> self._FORM_VISIT_LIST.pop()  # Remove the current form. if it is at the end of the list <MASK> # take no action if it looks as if someone has already set the next form. <TAB>  <TAB>  <TAB> self.setNextForm( <TAB>  <TAB>  <TAB>  <TAB> self._FORM_VISIT_LIST.pop() <TAB>  <TAB>  <TAB> )  # Switch to the previous form if one exists <TAB> except IndexError: <TAB>  <TAB> self.setNextForm(backup)",if self . _THISFORM . FORM_NAME == self . NEXT_ACTIVE_FORM :,178
686,"def iter_chars_to_words(self, chars): <TAB> current_word = [] <TAB> for char in chars: <TAB>  <TAB> if not self.keep_blank_chars and char[""text""].isspace(): <TAB>  <TAB>  <TAB> if current_word: <TAB>  <TAB>  <TAB>  <TAB> yield current_word <TAB>  <TAB>  <TAB>  <TAB> current_word = [] <MASK> yield current_word <TAB>  <TAB>  <TAB> current_word = [char] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> current_word.append(char) <TAB> if current_word: <TAB>  <TAB> yield current_word","elif current_word and self . char_begins_new_word ( current_word , char ) :",150
687,"def get(self): <TAB> """"""return a secret by name"""""" <TAB> results = self._get(""secrets"", self.name) <TAB> results[""decoded""] = {} <TAB> results[""exists""] = False <TAB> if results[""returncode""] == 0 and results[""results""][0]: <TAB>  <TAB> results[""exists""] = True <MASK> if ""data"" in results[""results""][0]: <TAB>  <TAB>  <TAB>  <TAB> for sname, value in results[""results""][0][""data""].items(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> results[""decoded""][sname] = base64.b64decode(value) <TAB> if results[""returncode""] != 0 and '""%s"" not found' % self.name in results[""stderr""]: <TAB>  <TAB> results[""returncode""] = 0 <TAB> return results",if self . decode :,173
688,"def insert_use(self, edit): <TAB> if self.is_first_use(): <TAB>  <TAB> for location in [r""^\s*namespace\s+[\w\\]+[;{]"", r""<\?php""]: <TAB>  <TAB>  <TAB> inserted = self.insert_first_use(location, edit) <MASK> break <TAB> else: <TAB>  <TAB> self.insert_use_among_others(edit)",if inserted :,99
689,"def _new_rsa_key(spec): <TAB> if ""name"" not in spec: <MASK> (head, tail) = os.path.split(spec[""key""]) <TAB>  <TAB>  <TAB> spec[""path""] = head <TAB>  <TAB>  <TAB> spec[""name""] = tail <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> spec[""name""] = spec[""key""] <TAB> return rsa_init(spec)","if ""/"" in spec [ ""key"" ] :",98
690,"def mimeData(self, indexes): <TAB> if len(indexes) == 1: <TAB>  <TAB> index = indexes[0] <TAB>  <TAB> model = song = index.data(Qt.UserRole) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> model = song.album <TAB>  <TAB>  <TAB> except (ProviderIOError, Exception): <TAB>  <TAB>  <TAB>  <TAB> model = None <TAB>  <TAB> return ModelMimeData(model)",if index . column ( ) == Column . album :,103
691,"def get(self, url, **kwargs): <TAB> app, url = self._prepare_call(url, kwargs) <TAB> if app: <TAB>  <TAB> if url.endswith(""ping"") and self._first_ping: <TAB>  <TAB>  <TAB> self._first_ping = False <TAB>  <TAB>  <TAB> return EmptyCapabilitiesResponse() <MASK> return ErrorApiResponse() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> response = app.get(url, **kwargs) <TAB>  <TAB>  <TAB> return TestingResponse(response) <TAB> else: <TAB>  <TAB> return requests.get(url, **kwargs)","elif ""Hello0"" in url and ""1.2.1"" in url and ""v1"" in url :",153
692,"def handle_noargs(self, **options): <TAB> self.style = color_style() <TAB> print(""Running Django's own validation:"") <TAB> self.validate(display_num_errors=True) <TAB> for model in loading.get_models(): <TAB>  <TAB> if hasattr(model, ""_create_content_base""): <TAB>  <TAB>  <TAB> self.validate_base_model(model) <MASK> self.validate_content_type(model)","if hasattr ( model , ""_feincms_content_models"" ) :",117
693,"def test_rules_widget(self): <TAB> subreddit = self.reddit.subreddit(pytest.placeholders.test_subreddit) <TAB> widgets = subreddit.widgets <TAB> with self.use_cassette(""TestSubredditWidgets.fetch_widgets""): <TAB>  <TAB> rules = None <TAB>  <TAB> for widget in widgets.sidebar: <MASK> rules = widget <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> assert isinstance(rules, RulesWidget) <TAB>  <TAB> assert rules == rules <TAB>  <TAB> assert rules.id == rules <TAB>  <TAB> assert rules.display <TAB>  <TAB> assert len(rules) > 0 <TAB>  <TAB> assert subreddit == rules.subreddit","if isinstance ( widget , RulesWidget ) :",173
694,"def __init__(self, exception): <TAB> message = str(exception) <TAB> with contextlib.suppress(IndexError): <TAB>  <TAB> underlying_exception = exception.args[0] <MASK> message = ( <TAB>  <TAB>  <TAB>  <TAB> ""maximum retries exceeded trying to reach the store.\n"" <TAB>  <TAB>  <TAB>  <TAB> ""Check your network connection, and check the store "" <TAB>  <TAB>  <TAB>  <TAB> ""status at {}"".format(_STORE_STATUS_URL) <TAB>  <TAB>  <TAB> ) <TAB> super().__init__(message=message)","if isinstance ( underlying_exception , urllib3 . exceptions . MaxRetryError ) :",130
695,"def wrapped(self, request): <TAB> try: <TAB>  <TAB> return self._finished <TAB> except AttributeError: <TAB>  <TAB> if self.node_ids: <MASK> log.debug( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""%s is still going to be used, not terminating it. "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Still in use on:\n%s"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pprint.pformat(list(self.node_ids)), <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> log.debug(""Finish called on %s"", self) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return func(request) <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self._finished = True",if not request . session . shouldfail and not request . session . shouldstop :,185
696,"def get_min_vertical_scroll() -> int: <TAB> # Make sure that the cursor line is not below the bottom. <TAB> # (Calculate how many lines can be shown between the cursor and the .) <TAB> used_height = 0 <TAB> prev_lineno = ui_content.cursor_position.y <TAB> for lineno in range(ui_content.cursor_position.y, -1, -1): <TAB>  <TAB> used_height += get_line_height(lineno) <MASK> return prev_lineno <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> prev_lineno = lineno <TAB> return 0",if used_height > height - scroll_offsets_bottom :,148
697,"def cookies(self): <TAB> # strip cookie_suffix from all cookies in the request, return result <TAB> cookies = flask.Request.cookies.__get__(self) <TAB> result = {} <TAB> desuffixed = {} <TAB> for key, value in cookies.items(): <MASK> desuffixed[key[: -len(self.cookie_suffix)]] = value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result[key] = value <TAB> result.update(desuffixed) <TAB> return result",if key . endswith ( self . cookie_suffix ) :,123
698,"def update_vars(state1, state2): <TAB> ops = [] <TAB> for name in state1._fields: <TAB>  <TAB> state1_vs = getattr(state1, name) <MASK> ops += [ <TAB>  <TAB>  <TAB>  <TAB> tf.assign(_v1, _v2) <TAB>  <TAB>  <TAB>  <TAB> for _v1, _v2 in zip(state1_vs, getattr(state2, name)) <TAB>  <TAB>  <TAB> ] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ops += [tf.assign(state1_vs, getattr(state2, name))] <TAB> return tf.group(*ops)","if isinstance ( state1_vs , list ) :",148
699,"def manifest(self): <TAB> """"""The current manifest dictionary."""""" <TAB> if self.reload: <MASK> return {} <TAB>  <TAB> mtime = self.getmtime(self.manifest_path) <TAB>  <TAB> if self._mtime is None or mtime > self._mtime: <TAB>  <TAB>  <TAB> self._manifest = self.get_manifest() <TAB>  <TAB>  <TAB> self._mtime = mtime <TAB> return self._manifest",if not self . exists ( self . manifest_path ) :,102
700,"def csvtitle(self): <TAB> if isinstance(self.name, six.string_types): <TAB>  <TAB> return '""' + self.name + '""' + char[""sep""] * (len(self.nick) - 1) <TAB> else: <TAB>  <TAB> ret = """" <TAB>  <TAB> for i, name in enumerate(self.name): <TAB>  <TAB>  <TAB> ret = ret + '""' + name + '""' + char[""sep""] * (len(self.nick) - 1) <MASK> ret = ret + char[""sep""] <TAB>  <TAB> return ret",if i + 1 != len ( self . name ) :,135
701,"def cache_dst(self): <TAB> final_dst = None <TAB> final_linenb = None <TAB> for linenb, assignblk in enumerate(self): <TAB>  <TAB> for dst, src in viewitems(assignblk): <MASK> if final_dst is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""Multiple destinations!"") <TAB>  <TAB>  <TAB>  <TAB> final_dst = src <TAB>  <TAB>  <TAB>  <TAB> final_linenb = linenb <TAB> self._dst = final_dst <TAB> self._dst_linenb = final_linenb <TAB> return final_dst","if dst . is_id ( ""IRDst"" ) :",144
702,"def _ProcessName(self, name, dependencies): <TAB> """"""Retrieve a module name from a node name."""""" <TAB> module_name, dot, base_name = name.rpartition(""."") <TAB> if dot: <MASK> if module_name in dependencies: <TAB>  <TAB>  <TAB>  <TAB> dependencies[module_name].add(base_name) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> dependencies[module_name] = {base_name} <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # If we have a relative import that did not get qualified (usually due <TAB>  <TAB>  <TAB> # to an empty package_name), don't insert module_name='' into the <TAB>  <TAB>  <TAB> # dependencies; we get a better error message if we filter it out here <TAB>  <TAB>  <TAB> # and fail later on. <TAB>  <TAB>  <TAB> logging.warning(""Empty package name: %s"", name)",if module_name :,196
703,"def get_aa_from_codonre(re_aa): <TAB> aas = [] <TAB> m = 0 <TAB> for i in re_aa: <TAB>  <TAB> if i == ""["": <TAB>  <TAB>  <TAB> m = -1 <TAB>  <TAB>  <TAB> aas.append("""") <TAB>  <TAB> elif i == ""]"": <TAB>  <TAB>  <TAB> m = 0 <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif m == -1: <TAB>  <TAB>  <TAB> aas[-1] = aas[-1] + i <MASK> aas.append(i) <TAB> return aas",elif m == 0 :,129
704,"def logic(): <TAB> count = intbv(0, min=0, max=MAXVAL + 1) <TAB> while True: <TAB>  <TAB> yield clock.posedge, reset.posedge <TAB>  <TAB> if reset == 1: <TAB>  <TAB>  <TAB> count[:] = 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> flag.next = 0 <MASK> flag.next = 1 <TAB>  <TAB>  <TAB>  <TAB> count[:] = 0 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> count += 1",if count == MAXVAL :,115
705,"def _history_define_metric( <TAB> self, hkey: str) -> Optional[wandb_internal_pb2.MetricRecord]: <TAB> """"""check for hkey match in glob metrics, return defined metric."""""" <TAB> # Dont define metric for internal metrics <TAB> if hkey.startswith(""_""): <TAB>  <TAB> return None <TAB> for k, mglob in six.iteritems(self._metric_globs): <TAB>  <TAB> if k.endswith(""*""): <MASK> m = wandb_internal_pb2.MetricRecord() <TAB>  <TAB>  <TAB>  <TAB> m.CopyFrom(mglob) <TAB>  <TAB>  <TAB>  <TAB> m.ClearField(""glob_name"") <TAB>  <TAB>  <TAB>  <TAB> m.name = hkey <TAB>  <TAB>  <TAB>  <TAB> return m <TAB> return None",if hkey . startswith ( k [ : - 1 ] ) :,180
706,"def optimize_models(args, use_cuda, models): <TAB> """"""Optimize ensemble for generation"""""" <TAB> for model in models: <TAB>  <TAB> model.make_generation_fast_( <TAB>  <TAB>  <TAB> beamable_mm_beam_size=None if args.no_beamable_mm else args.beam, <TAB>  <TAB>  <TAB> need_attn=args.print_alignment, <TAB>  <TAB> ) <MASK> model.half() <TAB>  <TAB> if use_cuda: <TAB>  <TAB>  <TAB> model.cuda()",if args . fp16 :,122
707,"def _Dynamic_Rollback(self, transaction, transaction_response): <TAB> txid = transaction.handle() <TAB> self.__local_tx_lock.acquire() <TAB> try: <MASK> raise apiproxy_errors.ApplicationError( <TAB>  <TAB>  <TAB>  <TAB> datastore_pb.Error.BAD_REQUEST, ""Transaction %d not found."" % (txid,) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> txdata = self.__transactions[txid] <TAB>  <TAB> assert ( <TAB>  <TAB>  <TAB> txdata.thread_id == thread.get_ident() <TAB>  <TAB> ), ""Transactions are single-threaded."" <TAB>  <TAB> del self.__transactions[txid] <TAB> finally: <TAB>  <TAB> self.__local_tx_lock.release()",if txid not in self . __transactions :,174
708,"def get_job_dirs(path): <TAB> regex = re.compile(""[1-9][0-9]*-"") <TAB> jobdirs = [] <TAB> for d in os.listdir(path): <TAB>  <TAB> # skip directories not matching the job result dir pattern <MASK> continue <TAB>  <TAB> d = os.path.join(options.resultsdir, d) <TAB>  <TAB> if os.path.isdir(d) and not os.path.exists(os.path.join(d, PUBLISH_FLAGFILE)): <TAB>  <TAB>  <TAB> jobdirs.append(d) <TAB> return jobdirs",if not regex . match ( d ) :,141
709,"def traverse(node, functions=[]): <TAB> if hasattr(node, ""grad_fn""): <TAB>  <TAB> node = node.grad_fn <TAB> if hasattr(node, ""variable""): <TAB>  <TAB> node = graph.nodes_by_id.get(id(node.variable)) <TAB>  <TAB> if node: <TAB>  <TAB>  <TAB> node.functions = list(functions) <TAB>  <TAB>  <TAB> del functions[:] <TAB> if hasattr(node, ""next_functions""): <TAB>  <TAB> functions.append(type(node).__name__) <TAB>  <TAB> for f in node.next_functions: <MASK> functions.append(type(f[0]).__name__) <TAB>  <TAB>  <TAB>  <TAB> traverse(f[0], functions) <TAB> if hasattr(node, ""saved_tensors""): <TAB>  <TAB> for t in node.saved_tensors: <TAB>  <TAB>  <TAB> traverse(t)",if f [ 0 ] :,195
710,"def get_all_snap_points(self, forts): <TAB> points = [] <TAB> radius = Constants.MAX_DISTANCE_FORT_IS_REACHABLE <TAB> for i in range(0, len(forts)): <TAB>  <TAB> for j in range(i + 1, len(forts)): <TAB>  <TAB>  <TAB> c1, c2 = self.get_enclosing_circles(forts[i], forts[j], radius) <MASK> points.append((c1, c2, forts[i], forts[j])) <TAB> return points",if c1 and c2 :,142
711,"def doDir(elem): <TAB> for child in elem.childNodes: <TAB>  <TAB> if not isinstance(child, minidom.Element): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if child.tagName == ""Directory"": <TAB>  <TAB>  <TAB> doDir(child) <TAB>  <TAB> elif child.tagName == ""Component"": <TAB>  <TAB>  <TAB> for grandchild in child.childNodes: <MASK> continue <TAB>  <TAB>  <TAB>  <TAB> if grandchild.tagName != ""File"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB>  <TAB> files.add(grandchild.getAttribute(""Source"").replace(os.sep, ""/""))","if not isinstance ( grandchild , minidom . Element ) :",152
712,"def computeLeadingWhitespaceWidth(s, tab_width): <TAB> w = 0 <TAB> for ch in s: <TAB>  <TAB> if ch == "" "": <TAB>  <TAB>  <TAB> w += 1 <MASK> w += abs(tab_width) - (w % abs(tab_width)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> return w","elif ch == ""\t"" :",87
713,"def test_avg_group_by(self): <TAB> ret = ( <TAB>  <TAB> await Book.annotate(avg=Avg(""rating"")) <TAB>  <TAB> .group_by(""author_id"") <TAB>  <TAB> .values(""author_id"", ""avg"") <TAB> ) <TAB> for item in ret: <TAB>  <TAB> author_id = item.get(""author_id"") <TAB>  <TAB> avg = item.get(""avg"") <MASK> self.assertEqual(avg, 4.5) <TAB>  <TAB> elif author_id == self.a2.pk: <TAB>  <TAB>  <TAB> self.assertEqual(avg, 2.0)",if author_id == self . a1 . pk :,150
714,"def open_session(self, app, request): <TAB> sid = request.cookies.get(app.session_cookie_name) <TAB> if sid: <TAB>  <TAB> stored_session = self.cls.objects(sid=sid).first() <MASK> expiration = stored_session.expiration <TAB>  <TAB>  <TAB> if not expiration.tzinfo: <TAB>  <TAB>  <TAB>  <TAB> expiration = expiration.replace(tzinfo=utc) <TAB>  <TAB>  <TAB> if expiration > datetime.datetime.utcnow().replace(tzinfo=utc): <TAB>  <TAB>  <TAB>  <TAB> return MongoEngineSession( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> initial=stored_session.data, sid=stored_session.sid <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return MongoEngineSession(sid=str(uuid.uuid4()))",if stored_session :,174
715,"def one_line_description(self): <TAB> MAX_LINE_LENGTH = 120 <TAB> desc = util.remove_html_tags(self.description or """") <TAB> desc = re.sub(""\s+"", "" "", desc).strip() <TAB> if not desc: <TAB>  <TAB> return _(""No description available"") <TAB> else: <TAB>  <TAB> # Decode the description to avoid gPodder bug 1277 <TAB>  <TAB> desc = util.convert_bytes(desc).strip() <MASK> return desc[:MAX_LINE_LENGTH] + ""..."" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return desc",if len ( desc ) > MAX_LINE_LENGTH :,142
716,"def setInnerHTML(self, html): <TAB> log.HTMLClassifier.classify( <TAB>  <TAB> log.ThugLogging.url if log.ThugOpts.local else log.last_url, html <TAB> ) <TAB> self.tag.clear() <TAB> for node in bs4.BeautifulSoup(html, ""html.parser"").contents: <TAB>  <TAB> self.tag.append(node) <TAB>  <TAB> name = getattr(node, ""name"", None) <TAB>  <TAB> if name is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> handler = getattr(log.DFT, ""handle_%s"" % (name,), None) <MASK> handler(node)",if handler :,151
717,def get_supported_period_type_map(cls): <TAB> if cls.supported_period_map is None: <TAB>  <TAB> cls.supported_period_map = {} <TAB>  <TAB> cls.supported_period_map.update(cls.period_type_map) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> from dateutil import relativedelta <MASK> cls.supported_period_map.update(cls.optional_period_type_map) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> pass <TAB> return cls.supported_period_map,if relativedelta is not None :,131
718,"def _compare_single_run(self, compares_done): <TAB> try: <TAB>  <TAB> compare_id, redo = self.in_queue.get( <TAB>  <TAB>  <TAB> timeout=float(self.config[""ExpertSettings""][""block_delay""]) <TAB>  <TAB> ) <TAB> except Empty: <TAB>  <TAB> pass <TAB> else: <MASK> if redo: <TAB>  <TAB>  <TAB>  <TAB> self.db_interface.delete_old_compare_result(compare_id) <TAB>  <TAB>  <TAB> compares_done.add(compare_id) <TAB>  <TAB>  <TAB> self._process_compare(compare_id) <TAB>  <TAB>  <TAB> if self.callback: <TAB>  <TAB>  <TAB>  <TAB> self.callback()","if self . _decide_whether_to_process ( compare_id , redo , compares_done ) :",177
719,"def _get_field_actual(cant_be_number, raw_string, field_names): <TAB> for line in raw_string.splitlines(): <TAB>  <TAB> for field_name in field_names: <TAB>  <TAB>  <TAB> field_name = field_name.lower() <TAB>  <TAB>  <TAB> if "":"" in line: <TAB>  <TAB>  <TAB>  <TAB> left, right = line.split("":"", 1) <TAB>  <TAB>  <TAB>  <TAB> left = left.strip().lower() <TAB>  <TAB>  <TAB>  <TAB> right = right.strip() <TAB>  <TAB>  <TAB>  <TAB> if left == field_name and len(right) > 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if cant_be_number: <MASK> return right <TAB>  <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return right <TAB> return None",if not right . isdigit ( ) :,184
720,"def _p_basicstr_content(s, content=_basicstr_re): <TAB> res = [] <TAB> while True: <TAB>  <TAB> res.append(s.expect_re(content).group(0)) <TAB>  <TAB> if not s.consume(""\\""): <TAB>  <TAB>  <TAB> break <MASK> pass <TAB>  <TAB> elif s.consume_re(_short_uni_re) or s.consume_re(_long_uni_re): <TAB>  <TAB>  <TAB> res.append(_chr(int(s.last().group(1), 16))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> s.expect_re(_escapes_re) <TAB>  <TAB>  <TAB> res.append(_escapes[s.last().group(0)]) <TAB> return """".join(res)",if s . consume_re ( _newline_esc_re ) :,179
721,"def removedir(self, path): <TAB> # type: (Text) -> None <TAB> _path = self.validatepath(path) <TAB> if _path == ""/"": <TAB>  <TAB> raise errors.RemoveRootError() <TAB> with ftp_errors(self, path): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.ftp.rmd(_encode(_path, self.ftp.encoding)) <TAB>  <TAB> except error_perm as error: <TAB>  <TAB>  <TAB> code, _ = _parse_ftp_error(error) <TAB>  <TAB>  <TAB> if code == ""550"": <TAB>  <TAB>  <TAB>  <TAB> if self.isfile(path): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise errors.DirectoryExpected(path) <MASK> raise errors.DirectoryNotEmpty(path) <TAB>  <TAB>  <TAB> raise  # pragma: no cover",if not self . isempty ( path ) :,189
722,"def _normalize_store_path(self, resource_store): <TAB> if resource_store[""type""] == ""filesystem"": <MASK> resource_store[""base_directory""] = os.path.join( <TAB>  <TAB>  <TAB>  <TAB> self.root_directory, resource_store[""base_directory""] <TAB>  <TAB>  <TAB> ) <TAB> return resource_store","if not os . path . isabs ( resource_store [ ""base_directory"" ] ) :",96
723,"def _apply_nested(name, val, nested): <TAB> parts = name.split(""."") <TAB> cur = nested <TAB> for i in range(0, len(parts) - 1): <TAB>  <TAB> cur = cur.setdefault(parts[i], {}) <MASK> conflicts_with = ""."".join(parts[0 : i + 1]) <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""%r cannot be nested: conflicts with {%r: %s}"" <TAB>  <TAB>  <TAB>  <TAB> % (name, conflicts_with, cur) <TAB>  <TAB>  <TAB> ) <TAB> cur[parts[-1]] = val","if not isinstance ( cur , dict ) :",142
724,"def build_packages(targeted_packages, distribution_directory, is_dev_build=False): <TAB> # run the build and distribution <TAB> for package_root in targeted_packages: <TAB>  <TAB> service_hierarchy = os.path.join(os.path.basename(package_root)) <MASK> verify_update_package_requirement(package_root) <TAB>  <TAB> print(""Generating Package Using Python {}"".format(sys.version)) <TAB>  <TAB> run_check_call( <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB> sys.executable, <TAB>  <TAB>  <TAB>  <TAB> build_packing_script_location, <TAB>  <TAB>  <TAB>  <TAB> ""--dest"", <TAB>  <TAB>  <TAB>  <TAB> os.path.join(distribution_directory, service_hierarchy), <TAB>  <TAB>  <TAB>  <TAB> package_root, <TAB>  <TAB>  <TAB> ], <TAB>  <TAB>  <TAB> root_dir, <TAB>  <TAB> )",if is_dev_build :,199
725,"def resolve_root_node_address(self, root_node): <TAB> if ""["" in root_node: <TAB>  <TAB> name, numbers = root_node.split(""["", maxsplit=1) <TAB>  <TAB> number = numbers.split("","", maxsplit=1)[0] <MASK> number = number.split(""-"")[0] <TAB>  <TAB> number = re.sub(""[^0-9]"", """", number) <TAB>  <TAB> root_node = name + number <TAB> return root_node","if ""-"" in number :",109
726,"def _map_args(maps: dict, **kwargs): <TAB> # maps: key=old name, value= new name <TAB> output = {} <TAB> for name, val in kwargs.items(): <TAB>  <TAB> if name in maps: <TAB>  <TAB>  <TAB> assert isinstance(maps[name], str) <TAB>  <TAB>  <TAB> output.update({maps[name]: val}) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> output.update({name: val}) <TAB> for keys in maps.keys(): <MASK> pass <TAB> return output",if keys not in output . keys ( ) :,125
727,"def next_item(self, direction): <TAB> """"""Selects next menu item, based on self._direction"""""" <TAB> start, i = -1, 0 <TAB> try: <TAB>  <TAB> start = self.items.index(self._selected) <TAB>  <TAB> i = start + direction <TAB> except: <TAB>  <TAB> pass <TAB> while True: <TAB>  <TAB> if i == start: <TAB>  <TAB>  <TAB> # Cannot find valid menu item <TAB>  <TAB>  <TAB> self.select(start) <TAB>  <TAB>  <TAB> break <MASK> i = 0 <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if i < 0: <TAB>  <TAB>  <TAB> i = len(self.items) - 1 <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if self.select(i): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> i += direction <TAB>  <TAB> if start < 0: <TAB>  <TAB>  <TAB> start = 0",if i >= len ( self . items ) :,194
728,"def detect_reentrancy(self, contract): <TAB> for function in contract.functions_and_modifiers_declared: <MASK> if self.KEY in function.context: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> self._explore(function.entry_point, []) <TAB>  <TAB>  <TAB> function.context[self.KEY] = True",if function . is_implemented :,87
729,"def load_model(self): <TAB> if not os.path.exists(self.get_filename(absolute=True)): <MASK> return {}, {} <TAB>  <TAB> error( <TAB>  <TAB>  <TAB> ""Model file with pre-trained convolution layers not found. Download it here..."", <TAB>  <TAB>  <TAB> ""https://github.com/alexjc/neural-enhance/releases/download/v%s/%s"" <TAB>  <TAB>  <TAB> % (__version__, self.get_filename()), <TAB>  <TAB> ) <TAB> print(""  - Loaded file `{}` with trained model."".format(self.get_filename())) <TAB> return pickle.load(bz2.open(self.get_filename(), ""rb""))",if args . train :,158
730,"def get_nonexisting_check_definition_extends(definition, indexed_oval_defs): <TAB> # TODO: handle multiple levels of referrals. <TAB> # OVAL checks that go beyond one level of extend_definition won't be properly identified <TAB> for extdefinition in definition.findall("".//{%s}extend_definition"" % oval_ns): <TAB>  <TAB> # Verify each extend_definition in the definition <TAB>  <TAB> extdefinitionref = extdefinition.get(""definition_ref"") <TAB>  <TAB> # Search the OVAL tree for a definition with the referred ID <TAB>  <TAB> referreddefinition = indexed_oval_defs.get(extdefinitionref) <MASK> # There is no oval satisfying the extend_definition referal <TAB>  <TAB>  <TAB> return extdefinitionref <TAB> return None",if referreddefinition is None :,177
731,"def pause(self): <TAB> if self.is_playing: <TAB>  <TAB> self.state = MusicPlayerState.PAUSED <MASK> self._current_player.pause() <TAB>  <TAB> self.emit(""pause"", player=self, entry=self.current_entry) <TAB>  <TAB> return <TAB> elif self.is_paused: <TAB>  <TAB> return <TAB> raise ValueError(""Cannot pause a MusicPlayer in state %s"" % self.state)",if self . _current_player :,107
732,"def setNextFormPrevious(self, backup=STARTING_FORM): <TAB> try: <MASK> self._FORM_VISIT_LIST.pop()  # Remove the current form. if it is at the end of the list <TAB>  <TAB> if self._THISFORM.FORM_NAME == self.NEXT_ACTIVE_FORM: <TAB>  <TAB>  <TAB> # take no action if it looks as if someone has already set the next form. <TAB>  <TAB>  <TAB> self.setNextForm( <TAB>  <TAB>  <TAB>  <TAB> self._FORM_VISIT_LIST.pop() <TAB>  <TAB>  <TAB> )  # Switch to the previous form if one exists <TAB> except IndexError: <TAB>  <TAB> self.setNextForm(backup)",if self . _THISFORM . FORM_NAME == self . _FORM_VISIT_LIST [ - 1 ] :,178
733,"def get_expr_referrers(schema: s_schema.Schema, obj: so.Object) -> Dict[so.Object, str]: <TAB> """"""Return schema referrers with refs in expressions."""""" <TAB> refs = schema.get_referrers_ex(obj) <TAB> result = {} <TAB> for (mcls, fn), referrers in refs.items(): <TAB>  <TAB> field = mcls.get_field(fn) <MASK> result.update({ref: fn for ref in referrers}) <TAB> return result","if issubclass ( field . type , ( Expression , ExpressionList ) ) :",136
734,"def _fields_to_index(cls): <TAB> fields = [] <TAB> for field in cls._meta.sorted_fields: <MASK> continue <TAB>  <TAB> requires_index = any( <TAB>  <TAB>  <TAB> (field.index, field.unique, isinstance(field, ForeignKeyField)) <TAB>  <TAB> ) <TAB>  <TAB> if requires_index: <TAB>  <TAB>  <TAB> fields.append(field) <TAB> return fields",if field . primary_key :,99
735,"def ident_values(self): <TAB> value = self._ident_values <TAB> if value is False: <TAB>  <TAB> value = None <TAB>  <TAB> # XXX: how will this interact with orig_prefix ? <TAB>  <TAB> # <TAB>   not exposing attrs for now if orig_prefix is set. <TAB>  <TAB> if not self.orig_prefix: <TAB>  <TAB>  <TAB> wrapped = self.wrapped <TAB>  <TAB>  <TAB> idents = getattr(wrapped, ""ident_values"", None) <MASK> value = [self._wrap_hash(ident) for ident in idents] <TAB>  <TAB>  <TAB> ##else: <TAB>  <TAB>  <TAB> ## <TAB> ident = self.ident <TAB>  <TAB>  <TAB> ## <TAB> if ident is not None: <TAB>  <TAB>  <TAB> ## <TAB>  <TAB> value = [ident] <TAB>  <TAB> self._ident_values = value <TAB> return value",if idents :,200
736,"def apply_incpaths_ml(self): <TAB> inc_lst = self.includes.split() <TAB> lst = self.incpaths_lst <TAB> for dir in inc_lst: <TAB>  <TAB> node = self.path.find_dir(dir) <TAB>  <TAB> if not node: <TAB>  <TAB>  <TAB> error(""node not found: "" + str(dir)) <TAB>  <TAB>  <TAB> continue <MASK> lst.append(node) <TAB>  <TAB> self.bld_incpaths_lst.append(node)",if not node in lst :,121
737,"def application_openFiles_(self, nsapp, filenames): <TAB> # logging.info('[osx] file open') <TAB> # logging.info('[osx] file : %s' % (filenames)) <TAB> for filename in filenames: <TAB>  <TAB> logging.info(""[osx] receiving from macOS : %s"", filename) <TAB>  <TAB> if os.path.exists(filename): <MASK> sabnzbd.add_nzbfile(filename, keep=True)",if sabnzbd . filesystem . get_ext ( filename ) in VALID_ARCHIVES + VALID_NZB_FILES :,136
738,"def check(self, xp, nout): <TAB> input = xp.asarray(self.x).astype(numpy.float32) <TAB> with warnings.catch_warnings(): <TAB>  <TAB> if self.ignore_warning: <TAB>  <TAB>  <TAB> warnings.simplefilter(""ignore"", self.ignore_warning) <MASK> self.check_positive(xp, self.func, input, self.eps, nout) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.check_negative(xp, self.func, input, self.eps, nout)",if self . result :,125
739,"def _set_scheme(url, newscheme): <TAB> scheme = _get_scheme(url) <TAB> newscheme = newscheme or """" <TAB> newseparator = "":"" if newscheme in COLON_SEPARATED_SCHEMES else ""://"" <TAB> if scheme == """":  # Protocol relative URL. <TAB>  <TAB> url = ""%s:%s"" % (newscheme, url) <TAB> elif scheme is None and url:  # No scheme. <TAB>  <TAB> url = """".join([newscheme, newseparator, url]) <TAB> elif scheme:  # Existing scheme. <TAB>  <TAB> remainder = url[len(scheme) :] <MASK> remainder = remainder[3:] <TAB>  <TAB> elif remainder.startswith("":""): <TAB>  <TAB>  <TAB> remainder = remainder[1:] <TAB>  <TAB> url = """".join([newscheme, newseparator, remainder]) <TAB> return url","if remainder . startswith ( ""://"" ) :",191
740,"def parquet(tables, data_directory, ignore_missing_dependency, **params): <TAB> try: <TAB>  <TAB> import pyarrow as pa  # noqa: F401 <TAB>  <TAB> import pyarrow.parquet as pq  # noqa: F401 <TAB> except ImportError: <TAB>  <TAB> msg = ""PyArrow dependency is missing"" <MASK> logger.warning(""Ignored: %s"", msg) <TAB>  <TAB>  <TAB> return 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise click.ClickException(msg) <TAB> data_directory = Path(data_directory) <TAB> for table, df in read_tables(tables, data_directory): <TAB>  <TAB> arrow_table = pa.Table.from_pandas(df) <TAB>  <TAB> target_path = data_directory / ""{}.parquet"".format(table) <TAB>  <TAB> pq.write_table(arrow_table, str(target_path))",if ignore_missing_dependency :,199
741,"def h2i(self, pkt, s): <TAB> t = () <TAB> if type(s) is str: <TAB>  <TAB> t = time.strptime(s) <TAB>  <TAB> t = t[:2] + t[2:-3] <TAB> else: <MASK> y, m, d, h, min, sec, rest, rest, rest = time.gmtime(time.time()) <TAB>  <TAB>  <TAB> t = (y, m, d, h, min, sec) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> t = s <TAB> return t",if not s :,130
742,"def filter_episodes(self, batch, cross_entropy): <TAB> """"""Filter the episodes for the cross_entropy method"""""" <TAB> accumulated_reward = [sum(rewards) for rewards in batch[""rewards""]] <TAB> percentile = cross_entropy * 100 <TAB> reward_bound = np.percentile(accumulated_reward, percentile) <TAB> # we save the batch with reward above the bound <TAB> result = {k: [] for k in self.data_keys} <TAB> episode_kept = 0 <TAB> for i in range(len(accumulated_reward)): <MASK> for k in self.data_keys: <TAB>  <TAB>  <TAB>  <TAB> result[k].append(batch[k][i]) <TAB>  <TAB>  <TAB> episode_kept += 1 <TAB> return result",if accumulated_reward [ i ] >= reward_bound :,181
743,"def _readenv(var, msg): <TAB> match = _ENV_VAR_PAT.match(var) <TAB> if match and match.groups(): <TAB>  <TAB> envvar = match.groups()[0] <TAB>  <TAB> if envvar in os.environ: <TAB>  <TAB>  <TAB> value = os.environ[envvar] <MASK> value = value.decode(""utf8"") <TAB>  <TAB>  <TAB> return value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise InvalidConfigException( <TAB>  <TAB>  <TAB>  <TAB> ""{} - environment variable '{}' not set"".format(msg, var) <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> raise InvalidConfigException( <TAB>  <TAB>  <TAB> ""{} - environment variable name '{}' does not match pattern '{}'"".format( <TAB>  <TAB>  <TAB>  <TAB> msg, var, _ENV_VAR_PAT_STR <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> )",if six . PY2 :,190
744,"def _allocate_nbd(self): <TAB> if not os.path.exists(""/sys/block/nbd0""): <TAB>  <TAB> self.error = _(""nbd unavailable: module not loaded"") <TAB>  <TAB> return None <TAB> while True: <TAB>  <TAB> if not self._DEVICES: <TAB>  <TAB>  <TAB> # really want to log this info, not raise <TAB>  <TAB>  <TAB> self.error = _(""No free nbd devices"") <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> device = self._DEVICES.pop() <MASK> break <TAB> return device","if not os . path . exists ( ""/sys/block/%s/pid"" % os . path . basename ( device ) ) :",146
745,"def _expand_deps_java_generation(self): <TAB> """"""Ensure that all multilingual dependencies such as proto_library generate java code."""""" <TAB> queue = collections.deque(self.deps) <TAB> keys = set() <TAB> while queue: <TAB>  <TAB> k = queue.popleft() <MASK> keys.add(k) <TAB>  <TAB>  <TAB> dep = self.target_database[k] <TAB>  <TAB>  <TAB> if ""generate_java"" in dep.attr:  # Has this attribute <TAB>  <TAB>  <TAB>  <TAB> dep.attr[""generate_java""] = True <TAB>  <TAB>  <TAB>  <TAB> queue.extend(dep.deps)",if k not in keys :,144
746,"def load_syntax(syntax): <TAB> context = _create_scheme() or {} <TAB> partition_scanner = PartitionScanner(syntax.get(""partitions"", [])) <TAB> scanners = {} <TAB> for part_name, part_scanner in list(syntax.get(""scanner"", {}).items()): <TAB>  <TAB> scanners[part_name] = Scanner(part_scanner) <TAB> formats = [] <TAB> for fname, fstyle in list(syntax.get(""formats"", {}).items()): <TAB>  <TAB> if isinstance(fstyle, basestring): <MASK> key = fstyle[2:-2] <TAB>  <TAB>  <TAB>  <TAB> fstyle = context[key] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> fstyle = fstyle % context <TAB>  <TAB> formats.append((fname, fstyle)) <TAB> return partition_scanner, scanners, formats","if fstyle . startswith ( ""%("" ) and fstyle . endswith ( "")s"" ) :",199
747,"def rollback(self): <TAB> for operation, values in self.current_transaction_state[::-1]: <MASK> values.remove() <TAB>  <TAB> elif operation == ""update"": <TAB>  <TAB>  <TAB> old_value, new_value = values <TAB>  <TAB>  <TAB> if new_value.full_filename != old_value.full_filename: <TAB>  <TAB>  <TAB>  <TAB> os.unlink(new_value.full_filename) <TAB>  <TAB>  <TAB> old_value.write() <TAB> self._post_xact_cleanup()","if operation == ""insert"" :",121
748,"def _buildOffsets(offsetDict, localeData, indexStart): <TAB> o = indexStart <TAB> for key in localeData: <MASK> for k in key.split(""|""): <TAB>  <TAB>  <TAB>  <TAB> offsetDict[k] = o <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> offsetDict[key] = o <TAB>  <TAB> o += 1","if ""|"" in key :",83
749,"def _check_start_pipeline_execution_errors( <TAB> graphene_info, execution_params, execution_plan): <TAB> if execution_params.step_keys: <TAB>  <TAB> for step_key in execution_params.step_keys: <MASK> raise UserFacingGraphQLError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> graphene_info.schema.type_named(""InvalidStepError"")( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> invalid_step_key=step_key <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> )",if not execution_plan . has_step ( step_key ) :,132
750,"def __setattr__(self, option_name, option_value): <TAB> if option_name in self._options: <TAB>  <TAB> # type checking <TAB>  <TAB> sort = self.OPTIONS[self.arch.name][option_name][0] <MASK> self._options[option_name] = option_value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> 'Value for option ""%s"" must be of type %s' % (option_name, sort) <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> super(CFGArchOptions, self).__setattr__(option_name, option_value)","if sort is None or isinstance ( option_value , sort ) :",155
751,"def value(self): <TAB> quote = False <TAB> if self.defects: <TAB>  <TAB> quote = True <TAB> else: <TAB>  <TAB> for x in self: <MASK> quote = True <TAB> if quote: <TAB>  <TAB> pre = post = """" <TAB>  <TAB> if self[0].token_type == ""cfws"" or self[0][0].token_type == ""cfws"": <TAB>  <TAB>  <TAB> pre = "" "" <TAB>  <TAB> if self[-1].token_type == ""cfws"" or self[-1][-1].token_type == ""cfws"": <TAB>  <TAB>  <TAB> post = "" "" <TAB>  <TAB> return pre + quote_string(self.display_name) + post <TAB> else: <TAB>  <TAB> return super(DisplayName, self).value","if x . token_type == ""quoted-string"" :",186
752,"def __init__(self, patch_files, patch_directories): <TAB> files = [] <TAB> files_data = {} <TAB> for filename_data in patch_files: <MASK> filename, data = filename_data <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> filename = filename_data <TAB>  <TAB>  <TAB> data = None <TAB>  <TAB> if not filename.startswith(os.sep): <TAB>  <TAB>  <TAB> filename = ""{0}{1}"".format(FakeState.deploy_dir, filename) <TAB>  <TAB> files.append(filename) <TAB>  <TAB> if data: <TAB>  <TAB>  <TAB> files_data[filename] = data <TAB> self.files = files <TAB> self.files_data = files_data <TAB> self.directories = patch_directories","if isinstance ( filename_data , list ) :",171
753,"def _evaluateStack(s): <TAB> op = s.pop() <TAB> if op in ""+-*/@^"": <TAB>  <TAB> op2 = _evaluateStack(s) <TAB>  <TAB> op1 = _evaluateStack(s) <TAB>  <TAB> result = opn[op](op1, op2) <MASK> print(result) <TAB>  <TAB> return result <TAB> else: <TAB>  <TAB> return op",if debug_flag :,97
754,"def reconnect_user(self, user_id, host_id, server_id): <TAB> if host_id == settings.local.host_id: <TAB>  <TAB> return <TAB> if server_id and self.server.id != server_id: <TAB>  <TAB> return <TAB> for client in self.clients.find({""user_id"": user_id}): <TAB>  <TAB> self.clients.update_id( <TAB>  <TAB>  <TAB> client[""id""], <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB> ""ignore_routes"": True, <TAB>  <TAB>  <TAB> }, <TAB>  <TAB> ) <MASK> self.instance.disconnect_wg(client[""id""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.instance_com.client_kill(client[""id""])","if len ( client [ ""id"" ] ) > 32 :",176
755,"def _get_library(self, name, args): <TAB> library_database = self._library_manager.get_new_connection_to_library_database() <TAB> try: <TAB>  <TAB> last_updated = library_database.get_library_last_updated(name, args) <TAB>  <TAB> if last_updated: <MASK> self._library_manager.fetch_keywords( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> name, args, self._libraries_need_refresh_listener <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return library_database.fetch_library_keywords(name, args) <TAB>  <TAB> return self._library_manager.get_and_insert_keywords(name, args) <TAB> finally: <TAB>  <TAB> library_database.close()",if time . time ( ) - last_updated > 10.0 :,184
756,"def get_paths(self, path, commit): <TAB> """"""Return a generator of all filepaths under path at commit."""""" <TAB> _check_path_is_repo_relative(path) <TAB> git_path = _get_git_path(path) <TAB> tree = self.gl_repo.git_repo[commit.tree[git_path].id] <TAB> assert tree.type == pygit2.GIT_OBJ_TREE <TAB> for tree_entry in tree: <TAB>  <TAB> tree_entry_path = os.path.join(path, tree_entry.name) <MASK> for fp in self.get_paths(tree_entry_path, commit): <TAB>  <TAB>  <TAB>  <TAB> yield fp <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield tree_entry_path","if tree_entry . type == ""tree"" :",185
757,"def scan_resource_conf(self, conf): <TAB> if ""properties"" in conf: <TAB>  <TAB> if ""attributes"" in conf[""properties""]: <MASK> if conf[""properties""][""attributes""][""exp""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return CheckResult.PASSED <TAB> return CheckResult.FAILED","if ""exp"" in conf [ ""properties"" ] [ ""attributes"" ] :",82
758,"def _set_parse_context(self, tag, tag_attrs): <TAB> # special case: script or style parse context <TAB> if not self._wb_parse_context: <TAB>  <TAB> if tag == ""style"": <TAB>  <TAB>  <TAB> self._wb_parse_context = ""style"" <TAB>  <TAB> elif tag == ""script"": <MASK> self._wb_parse_context = ""script""",if self . _allow_js_type ( tag_attrs ) :,106
759,"def modified(self): <TAB> paths = set() <TAB> dictionary_list = [] <TAB> for op_list in self._operations: <TAB>  <TAB> if not isinstance(op_list, list): <TAB>  <TAB>  <TAB> op_list = (op_list,) <TAB>  <TAB> for item in chain(*op_list): <MASK> continue <TAB>  <TAB>  <TAB> dictionary = item.dictionary <TAB>  <TAB>  <TAB> if dictionary.path in paths: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> paths.add(dictionary.path) <TAB>  <TAB>  <TAB> dictionary_list.append(dictionary) <TAB> return dictionary_list",if item is None :,139
760,def preorder(root): <TAB> res = [] <TAB> if not root: <TAB>  <TAB> return res <TAB> stack = [] <TAB> stack.append(root) <TAB> while stack: <TAB>  <TAB> root = stack.pop() <TAB>  <TAB> res.append(root.val) <MASK> stack.append(root.right) <TAB>  <TAB> if root.left: <TAB>  <TAB>  <TAB> stack.append(root.left) <TAB> return res,if root . right :,105
761,"def create(exported_python_target): <TAB> if exported_python_target not in created: <TAB>  <TAB> self.context.log.info( <TAB>  <TAB>  <TAB> ""Creating setup.py project for {}"".format(exported_python_target) <TAB>  <TAB> ) <TAB>  <TAB> subject = self.derived_by_original.get( <TAB>  <TAB>  <TAB> exported_python_target, exported_python_target <TAB>  <TAB> ) <TAB>  <TAB> setup_dir, dependencies = self.create_setup_py(subject, dist_dir) <TAB>  <TAB> created[exported_python_target] = setup_dir <TAB>  <TAB> if self._recursive: <TAB>  <TAB>  <TAB> for dep in dependencies: <MASK> create(dep)",if is_exported_python_target ( dep ) :,172
762,"def test_array_interface(self, data): <TAB> result = np.array(data) <TAB> np.testing.assert_array_equal(result[0], data[0]) <TAB> result = np.array(data, dtype=object) <TAB> expected = np.array(list(data), dtype=object) <TAB> for a1, a2 in zip(result, expected): <MASK> assert np.isnan(a1) and np.isnan(a2) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tm.assert_numpy_array_equal(a2, a1)",if np . isscalar ( a1 ) :,143
763,"def valueChanged(plug): <TAB> changed = plug.getInput() is not None <TAB> if not changed and isinstance(plug, Gaffer.ValuePlug): <MASK> changed = not Gaffer.NodeAlgo.isSetToUserDefault(plug) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> changed = not plug.isSetToDefault() <TAB> return changed",if Gaffer . NodeAlgo . hasUserDefault ( plug ) :,101
764,"def process_tag(hive_name, company, company_key, tag, default_arch): <TAB> with winreg.OpenKeyEx(company_key, tag) as tag_key: <TAB>  <TAB> version = load_version_data(hive_name, company, tag, tag_key) <MASK> # if failed to get version bail <TAB>  <TAB>  <TAB> major, minor, _ = version <TAB>  <TAB>  <TAB> arch = load_arch_data(hive_name, company, tag, tag_key, default_arch) <TAB>  <TAB>  <TAB> if arch is not None: <TAB>  <TAB>  <TAB>  <TAB> exe_data = load_exe(hive_name, company, company_key, tag) <TAB>  <TAB>  <TAB>  <TAB> if exe_data is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> exe, args = exe_data <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return company, major, minor, arch, exe, args",if version is not None :,199
765,"def __iter__(self): <TAB> for name, value in self.__class__.__dict__.items(): <TAB>  <TAB> if isinstance(value, alias_flag_value): <TAB>  <TAB>  <TAB> continue <MASK> yield (name, self._has_flag(value.flag))","if isinstance ( value , flag_value ) :",71
766,"def connect(self): <TAB> self.sock = sockssocket() <TAB> self.sock.setproxy(*proxy_args) <TAB> if type(self.timeout) in (int, float): <TAB>  <TAB> self.sock.settimeout(self.timeout) <TAB> self.sock.connect((self.host, self.port)) <TAB> if isinstance(self, compat_http_client.HTTPSConnection): <MASK> # Python > 2.6 <TAB>  <TAB>  <TAB> self.sock = self._context.wrap_socket(self.sock, server_hostname=self.host) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.sock = ssl.wrap_socket(self.sock)","if hasattr ( self , ""_context"" ) :",158
767,"def frequent_thread_switches(): <TAB> """"""Make concurrency bugs more likely to manifest."""""" <TAB> interval = None <TAB> if not sys.platform.startswith(""java""): <TAB>  <TAB> if hasattr(sys, ""getswitchinterval""): <TAB>  <TAB>  <TAB> interval = sys.getswitchinterval() <TAB>  <TAB>  <TAB> sys.setswitchinterval(1e-6) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> interval = sys.getcheckinterval() <TAB>  <TAB>  <TAB> sys.setcheckinterval(1) <TAB> try: <TAB>  <TAB> yield <TAB> finally: <TAB>  <TAB> if not sys.platform.startswith(""java""): <MASK> sys.setswitchinterval(interval) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> sys.setcheckinterval(interval)","if hasattr ( sys , ""setswitchinterval"" ) :",177
768,"def vars(self): <TAB> ret = [] <TAB> if op.intlist: <TAB>  <TAB> varlist = op.intlist <TAB> else: <TAB>  <TAB> varlist = self.discover <TAB>  <TAB> for name in varlist: <TAB>  <TAB>  <TAB> if name in (""0"", ""1"", ""2"", ""8"", ""CPU0"", ""ERR"", ""LOC"", ""MIS"", ""NMI""): <TAB>  <TAB>  <TAB>  <TAB> varlist.remove(name) <TAB>  <TAB> if not op.full and len(varlist) > 3: <TAB>  <TAB>  <TAB> varlist = varlist[-3:] <TAB> for name in varlist: <TAB>  <TAB> if name in self.discover: <TAB>  <TAB>  <TAB> ret.append(name) <MASK> ret.append(self.intmap[name.lower()]) <TAB> return ret",elif name . lower ( ) in self . intmap :,191
769,"def deleteDuplicates(gadgets, callback=None): <TAB> toReturn = [] <TAB> inst = set() <TAB> count = 0 <TAB> added = False <TAB> len_gadgets = len(gadgets) <TAB> for i, gadget in enumerate(gadgets): <TAB>  <TAB> inst.add(gadget._gadget) <MASK> count = len(inst) <TAB>  <TAB>  <TAB> toReturn.append(gadget) <TAB>  <TAB>  <TAB> added = True <TAB>  <TAB> if callback: <TAB>  <TAB>  <TAB> callback(gadget, added, float(i + 1) / (len_gadgets)) <TAB>  <TAB>  <TAB> added = False <TAB> return toReturn",if len ( inst ) > count :,164
770,"def ident(self): <TAB> value = self._ident <TAB> if value is False: <TAB>  <TAB> value = None <TAB>  <TAB> # XXX: how will this interact with orig_prefix ? <TAB>  <TAB> # <TAB>   not exposing attrs for now if orig_prefix is set. <TAB>  <TAB> if not self.orig_prefix: <TAB>  <TAB>  <TAB> wrapped = self.wrapped <TAB>  <TAB>  <TAB> ident = getattr(wrapped, ""ident"", None) <MASK> value = self._wrap_hash(ident) <TAB>  <TAB> self._ident = value <TAB> return value",if ident is not None :,135
771,"def _flatten_settings_from_form(self, settings, form, form_values): <TAB> """"""Take a nested dict and return a flat dict of setting values."""""" <TAB> setting_values = {} <TAB> for field in form.c: <TAB>  <TAB> if isinstance(field, _ContainerMixin): <TAB>  <TAB>  <TAB> setting_values.update( <TAB>  <TAB>  <TAB>  <TAB> self._flatten_settings_from_form( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> settings, field, form_values[field._name] <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <MASK> setting_values[field._name] = form_values[field._name] <TAB> return setting_values",elif field . _name in settings :,156
772,"def _decorator(cls): <TAB> for name, meth in inspect.getmembers(cls, inspect.isroutine): <TAB>  <TAB> if name not in cls.__dict__: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if name != ""__init__"": <MASK> continue <TAB>  <TAB> if name in butnot: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> setattr(cls, name, decorator(meth)) <TAB> return cls","if not private and name . startswith ( ""_"" ) :",99
773,"def _do_cmp(f1, f2): <TAB> bufsize = BUFSIZE <TAB> with open(f1, ""rb"") as fp1, open(f2, ""rb"") as fp2: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> b1 = fp1.read(bufsize) <TAB>  <TAB>  <TAB> b2 = fp2.read(bufsize) <MASK> return False <TAB>  <TAB>  <TAB> if not b1: <TAB>  <TAB>  <TAB>  <TAB> return True",if b1 != b2 :,118
774,"def _memoized(*args): <TAB> now = time.time() <TAB> try: <TAB>  <TAB> value, last_update = self.cache[args] <TAB>  <TAB> age = now - last_update <TAB>  <TAB> if self._call_count > self.ctl or age > self.ttl: <TAB>  <TAB>  <TAB> self._call_count = 0 <TAB>  <TAB>  <TAB> raise AttributeError <MASK> self._call_count += 1 <TAB>  <TAB> return value <TAB> except (KeyError, AttributeError): <TAB>  <TAB> value = func(*args) <TAB>  <TAB> if value: <TAB>  <TAB>  <TAB> self.cache[args] = (value, now) <TAB>  <TAB> return value <TAB> except TypeError: <TAB>  <TAB> return func(*args)",if self . ctl :,164
775,"def check(self, hyperlinks: Dict[str, Hyperlink]) -> Generator[CheckResult, None, None]: <TAB> self.invoke_threads() <TAB> total_links = 0 <TAB> for hyperlink in hyperlinks.values(): <MASK> yield CheckResult( <TAB>  <TAB>  <TAB>  <TAB> hyperlink.uri, hyperlink.docname, hyperlink.lineno, ""ignored"", """", 0 <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.wqueue.put(CheckRequest(CHECK_IMMEDIATELY, hyperlink), False) <TAB>  <TAB>  <TAB> total_links += 1 <TAB> done = 0 <TAB> while done < total_links: <TAB>  <TAB> yield self.rqueue.get() <TAB>  <TAB> done += 1 <TAB> self.shutdown_threads()",if self . is_ignored_uri ( hyperlink . uri ) :,188
776,"def remove_subscriber(self, topic, subscriber): <TAB> if subscriber in self.subscribers[topic]: <MASK> subscriber._pyroRelease() <TAB>  <TAB> if hasattr(subscriber, ""_pyroUri""): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> proxy = self.proxy_cache[subscriber._pyroUri] <TAB>  <TAB>  <TAB>  <TAB> proxy._pyroRelease() <TAB>  <TAB>  <TAB>  <TAB> del self.proxy_cache[subscriber._pyroUri] <TAB>  <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> self.subscribers[topic].discard(subscriber)","if hasattr ( subscriber , ""_pyroRelease"" ) :",139
777,"def delete_arc(collection, document, origin, target, type): <TAB> directory = collection <TAB> real_dir = real_directory(directory) <TAB> mods = ModificationTracker() <TAB> projectconf = ProjectConfiguration(real_dir) <TAB> document = path_join(real_dir, document) <TAB> with TextAnnotations(document) as ann_obj: <TAB>  <TAB> # bail as quick as possible if read-only <MASK> raise AnnotationsIsReadOnlyError(ann_obj.get_document()) <TAB>  <TAB> _delete_arc_with_ann(origin, target, type, mods, ann_obj, projectconf) <TAB>  <TAB> mods_json = mods.json_response() <TAB>  <TAB> mods_json[""annotations""] = _json_from_ann(ann_obj) <TAB>  <TAB> return mods_json",if ann_obj . _read_only :,193
778,"def _select_from(self, parent_path, is_dir, exists, listdir): <TAB> if not is_dir(parent_path): <TAB>  <TAB> return <TAB> with _cached(listdir) as listdir: <TAB>  <TAB> yielded = set() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> successor_select = self.successor._select_from <TAB>  <TAB>  <TAB> for starting_point in self._iterate_directories( <TAB>  <TAB>  <TAB>  <TAB> parent_path, is_dir, listdir <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> for p in successor_select(starting_point, is_dir, exists, listdir): <MASK> yield p <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yielded.add(p) <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> yielded.clear()",if p not in yielded :,183
779,"def _fractional_part(self, n, expr, evaluation): <TAB> n_sympy = n.to_sympy() <TAB> if n_sympy.is_constant(): <MASK> positive_integer_part = ( <TAB>  <TAB>  <TAB>  <TAB> Expression(""Floor"", n).evaluate(evaluation).to_python() <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> result = n - positive_integer_part <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> negative_integer_part = ( <TAB>  <TAB>  <TAB>  <TAB> Expression(""Ceiling"", n).evaluate(evaluation).to_python() <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> result = n - negative_integer_part <TAB> else: <TAB>  <TAB> return expr <TAB> return from_python(result)",if n_sympy >= 0 :,169
780,"def check_bounds(geometry): <TAB> if isinstance(geometry[0], (list, tuple)): <TAB>  <TAB> return list(map(check_bounds, geometry)) <TAB> else: <TAB>  <TAB> if geometry[0] > 180 or geometry[0] < -180: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Longitude is out of bounds, check your JSON format or data"" <TAB>  <TAB>  <TAB> ) <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Latitude is out of bounds, check your JSON format or data"" <TAB>  <TAB>  <TAB> )",if geometry [ 1 ] > 90 or geometry [ 1 ] < - 90 :,143
781,"def get_absolute_path(self, root, path): <TAB> # find the first absolute path that exists <TAB> self.root = self.roots[0] <TAB> for root in self.roots: <TAB>  <TAB> abspath = os.path.abspath(os.path.join(root, path)) <MASK> self.root = root  # make sure all the other methods in the base class know how to find the file <TAB>  <TAB>  <TAB> break <TAB> return abspath",if os . path . exists ( abspath ) :,114
782,"def do_setflow(self, l=""""): <TAB> try: <MASK> l = str(self.flow_slider.GetValue()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> l = l.lower() <TAB>  <TAB> flow = int(l) <TAB>  <TAB> if self.p.online: <TAB>  <TAB>  <TAB> self.p.send_now(""M221 S"" + l) <TAB>  <TAB>  <TAB> self.log(_(""Setting print flow factor to %d%%."") % flow) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.logError(_(""Printer is not online."")) <TAB> except Exception as x: <TAB>  <TAB> self.logError(_(""You must enter a flow. (%s)"") % (repr(x),))","if not isinstance ( l , str ) or not len ( l ) :",170
783,"def sources(): <TAB> for d in os.listdir(base): <TAB>  <TAB> # <TAB>  <TAB> if d.startswith('talis'): <TAB>  <TAB> # <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> if d == ""indcat"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if not os.path.isdir(base + d): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> yield d","if d . endswith ( ""old"" ) :",105
784,"def create_accumulator(self) -> tf_metric_accumulators.TFCompilableMetricsAccumulator: <TAB> configs = zip(self._metric_configs, self._loss_configs) <TAB> padding_options = None <TAB> if self._eval_config is not None: <TAB>  <TAB> model_spec = model_util.get_model_spec(self._eval_config, self._model_name) <MASK> padding_options = model_spec.padding_options <TAB> return tf_metric_accumulators.TFCompilableMetricsAccumulator( <TAB>  <TAB> padding_options, <TAB>  <TAB> [len(m) + len(l) for m, l in configs], <TAB>  <TAB> desired_batch_size=self._desired_batch_size, <TAB> )","if model_spec is not None and model_spec . HasField ( ""padding_options"" ) :",196
785,"def parseImpl(self, instring, loc, doActions=True): <TAB> try: <TAB>  <TAB> loc, tokens = self.expr._parse(instring, loc, doActions, callPreParse=False) <TAB> except (ParseException, IndexError): <MASK> if self.expr.resultsName: <TAB>  <TAB>  <TAB>  <TAB> tokens = ParseResults([self.defaultValue]) <TAB>  <TAB>  <TAB>  <TAB> tokens[self.expr.resultsName] = self.defaultValue <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> tokens = [self.defaultValue] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tokens = [] <TAB> return loc, tokens",if self . defaultValue is not self . __optionalNotMatched :,157
786,"def handleConnection(self): <TAB> # connection handshake <TAB> try: <MASK> return True <TAB>  <TAB> self.csock.close() <TAB> except: <TAB>  <TAB> ex_t, ex_v, ex_tb = sys.exc_info() <TAB>  <TAB> tb = util.formatTraceback(ex_t, ex_v, ex_tb) <TAB>  <TAB> log.warning(""error during connect/handshake: %s; %s"", ex_v, ""\n"".join(tb)) <TAB>  <TAB> self.csock.close() <TAB> return False",if self . daemon . _handshake ( self . csock ) :,138
787,"def getProc(su, innerTarget): <TAB> if len(su) == 1:  # have a one element wedge <TAB>  <TAB> proc = (""first"", ""last"") <TAB> else: <MASK> proc = (""first"", ""last"")  # same element can be first and last <TAB>  <TAB> elif su.isFirst(innerTarget): <TAB>  <TAB>  <TAB> proc = (""first"",) <TAB>  <TAB> elif su.isLast(innerTarget): <TAB>  <TAB>  <TAB> proc = (""last"",) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> proc = () <TAB> return proc",if su . isFirst ( innerTarget ) and su . isLast ( innerTarget ) :,143
788,"def get_color_dtype(data, column_names): <TAB> has_color = all(column in data[""points""] for column in column_names) <TAB> if has_color: <TAB>  <TAB> color_data_types = [ <TAB>  <TAB>  <TAB> data[""points""][column_name].dtype for column_name in column_names <TAB>  <TAB> ] <MASK> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> f""Data types of color values are inconsistent: got {color_data_types}"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> color_data_type = color_data_types[0] <TAB> else: <TAB>  <TAB> color_data_type = None <TAB> return color_data_type",if len ( set ( color_data_types ) ) > 1 :,168
789,"def close(self): <TAB> children = [] <TAB> for children_part, line_offset, last_line_offset_leaf in self.children_groups: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> _update_positions(children_part, line_offset, last_line_offset_leaf) <TAB>  <TAB>  <TAB> except _PositionUpdatingFinished: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> children += children_part <TAB> self.tree_node.children = children <TAB> # Reset the parents <TAB> for node in children: <TAB>  <TAB> node.parent = self.tree_node",if line_offset != 0 :,138
790,"def get_multi(self, keys, index=None): <TAB> with self._lmdb.begin() as txn: <TAB>  <TAB> result = [] <TAB>  <TAB> for key in keys: <TAB>  <TAB>  <TAB> packed = txn.get(key.encode()) <MASK> result.append((key, cbor.loads(packed))) <TAB> return result",if packed is not None :,86
791,"def get_directory_info(prefix, pth, recursive): <TAB> res = [] <TAB> directory = os.listdir(pth) <TAB> directory.sort() <TAB> for p in directory: <TAB>  <TAB> if p[0] != ""."": <TAB>  <TAB>  <TAB> subp = os.path.join(pth, p) <TAB>  <TAB>  <TAB> p = os.path.join(prefix, p) <MASK> res.append([p, get_directory_info(prefix, subp, 1)]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> res.append([p, None]) <TAB> return res",if recursive and os . path . isdir ( subp ) :,148
792,"def __schedule(self, workflow_scheduler_id, workflow_scheduler): <TAB> invocation_ids = self.__active_invocation_ids(workflow_scheduler_id) <TAB> for invocation_id in invocation_ids: <TAB>  <TAB> log.debug(""Attempting to schedule workflow invocation [%s]"", invocation_id) <TAB>  <TAB> self.__attempt_schedule(invocation_id, workflow_scheduler) <MASK> return",if not self . monitor_running :,103
793,"def write(self, data): <TAB> self.size -= len(data) <TAB> passon = None <TAB> if self.size > 0: <TAB>  <TAB> self.data.append(data) <TAB> else: <TAB>  <TAB> if self.size: <TAB>  <TAB>  <TAB> data, passon = data[: self.size], data[self.size :] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> passon = b"""" <MASK> self.data.append(data) <TAB> return passon",if data :,114
794,"def __getstate__(self): <TAB> try: <TAB>  <TAB> store_func, load_func = self.store_function, self.load_function <TAB>  <TAB> self.store_function, self.load_function = None, None <TAB>  <TAB> # ignore analyses. we re-initialize analyses when restoring from pickling so that we do not lose any newly <TAB>  <TAB> # added analyses classes <TAB>  <TAB> d = dict( <TAB>  <TAB>  <TAB> (k, v) <TAB>  <TAB>  <TAB> for k, v in self.__dict__.items() <MASK> not in { <TAB>  <TAB>  <TAB>  <TAB> ""analyses"", <TAB>  <TAB>  <TAB> } <TAB>  <TAB> ) <TAB>  <TAB> return d <TAB> finally: <TAB>  <TAB> self.store_function, self.load_function = store_func, load_func",if k,175
795,"def mouse_down(self, event): <TAB> if event.button == 1: <TAB>  <TAB> if self.scrolling: <TAB>  <TAB>  <TAB> p = event.local <MASK> self.scroll_up() <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> elif self.scroll_down_rect().collidepoint(p): <TAB>  <TAB>  <TAB>  <TAB> self.scroll_down() <TAB>  <TAB>  <TAB>  <TAB> return <TAB> if event.button == 4: <TAB>  <TAB> self.scroll_up() <TAB> if event.button == 5: <TAB>  <TAB> self.scroll_down() <TAB> GridView.mouse_down(self, event)",if self . scroll_up_rect ( ) . collidepoint ( p ) :,160
796,"def on_api_command(self, command, data): <TAB> if command == ""select"": <TAB>  <TAB> if not Permissions.PLUGIN_ACTION_COMMAND_PROMPT_INTERACT.can(): <TAB>  <TAB>  <TAB> return flask.abort(403, ""Insufficient permissions"") <TAB>  <TAB> if self._prompt is None: <TAB>  <TAB>  <TAB> return flask.abort(409, ""No active prompt"") <TAB>  <TAB> choice = data[""choice""] <MASK> return flask.abort( <TAB>  <TAB>  <TAB>  <TAB> 400, ""{!r} is not a valid value for choice"".format(choice) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self._answer_prompt(choice)","if not isinstance ( choice , int ) or not self . _prompt . validate_choice ( choice ) :",164
797,"def register_predictors(self, model_data_arr): <TAB> for integration in self._get_integrations(): <MASK> integration.register_predictors(model_data_arr) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logger.warning( <TAB>  <TAB>  <TAB>  <TAB> f""There is no connection to {integration.name}. predictor wouldn't be registred."" <TAB>  <TAB>  <TAB> )",if integration . check_connection ( ) :,98
798,"def _pack_shears(shearData): <TAB> shears = list() <TAB> vidxs = list() <TAB> for e_idx, entry in enumerate(shearData): <TAB>  <TAB> # Should be 3 entries <MASK> shears.extend([float(""nan""), float(""nan"")]) <TAB>  <TAB>  <TAB> vidxs.extend([0, 0]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> vidx1, vidx2, shear1, shear2 = entry <TAB>  <TAB>  <TAB> shears.extend([shear1, shear2]) <TAB>  <TAB>  <TAB> vidxs.extend([vidx1, vidx2]) <TAB> return (np.asarray(shears, dtype=np.float32), np.asarray(vidxs, dtype=np.uint32))",if entry is None :,173
799,"def aiter_cogs(cls) -> AsyncIterator[Tuple[str, str]]: <TAB> yield ""Core"", ""0"" <TAB> for _dir in data_manager.cog_data_path().iterdir(): <TAB>  <TAB> fpath = _dir / ""settings.json"" <TAB>  <TAB> if not fpath.exists(): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> with fpath.open() as f: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> data = json.load(f) <TAB>  <TAB>  <TAB> except json.JSONDecodeError: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if not isinstance(data, dict): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> cog_name = _dir.stem <TAB>  <TAB> for cog_id, inner in data.items(): <MASK> continue <TAB>  <TAB>  <TAB> yield cog_name, cog_id","if not isinstance ( inner , dict ) :",192
800,"def subFeaName(m, newNames, state): <TAB> try: <TAB>  <TAB> int(m[3], 16) <TAB> except: <TAB>  <TAB> return m[0] <TAB> name = m[2] <TAB> if name in newNames: <TAB>  <TAB> # print('sub %r => %r' % (m[0], m[1] + newNames[name] + m[4])) <MASK> print(""sub %r => %r"" % (m[0], m[1] + newNames[name] + m[4])) <TAB>  <TAB> state[""didChange""] = True <TAB>  <TAB> return m[1] + newNames[name] + m[4] <TAB> return m[0]","if name == ""uni0402"" :",172
801,"def log_graph(self, model: LightningModule, input_array=None): <TAB> if self._log_graph: <TAB>  <TAB> if input_array is None: <TAB>  <TAB>  <TAB> input_array = model.example_input_array <MASK> input_array = model._apply_batch_transfer_handler(input_array) <TAB>  <TAB>  <TAB> self.experiment.add_graph(model, input_array) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> rank_zero_warn( <TAB>  <TAB>  <TAB>  <TAB> ""Could not log computational graph since the"" <TAB>  <TAB>  <TAB>  <TAB> "" `model.example_input_array` attribute is not set"" <TAB>  <TAB>  <TAB>  <TAB> "" or `input_array` was not given"", <TAB>  <TAB>  <TAB>  <TAB> UserWarning, <TAB>  <TAB>  <TAB> )",if input_array is not None :,182
802,"def apply(self, db, person): <TAB> for family_handle in person.get_family_handle_list(): <TAB>  <TAB> family = db.get_family_from_handle(family_handle) <TAB>  <TAB> if family: <TAB>  <TAB>  <TAB> for event_ref in family.get_event_ref_list(): <TAB>  <TAB>  <TAB>  <TAB> if event_ref: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> event = db.get_event_from_handle(event_ref.ref) <MASK> return True <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if not event.get_date_object(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if not event . get_place_handle ( ) :,159
803,"def format(m): <TAB> if m > 1000: <MASK> return (str(int(m / 1000)), ""km"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return (str(round(m / 1000, 1)), ""km"") <TAB> return (str(m), ""m"")",if m % 1000 == 0 :,75
804,"def previous(self): <TAB> try: <TAB>  <TAB> idx = _jump_list_index <TAB>  <TAB> next_index = idx + 1 <MASK> next_index = 100 <TAB>  <TAB> next_index = min(len(_jump_list) - 1, next_index) <TAB>  <TAB> _jump_list_index = next_index <TAB>  <TAB> return _jump_list[next_index] <TAB> except (IndexError, KeyError) as e: <TAB>  <TAB> return None",if next_index > 100 :,114
805,"def _validate_and_set_default_hyperparameters(self): <TAB> """"""Placeholder docstring"""""" <TAB> # Check if all the required hyperparameters are set. If there is a default value <TAB> # for one, set it. <TAB> for name, definition in self.hyperparameter_definitions.items(): <TAB>  <TAB> if name not in self.hyperparam_dict: <TAB>  <TAB>  <TAB> spec = definition[""spec""] <MASK> self.hyperparam_dict[name] = spec[""DefaultValue""] <TAB>  <TAB>  <TAB> elif ""IsRequired"" in spec and spec[""IsRequired""]: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""Required hyperparameter: %s is not set"" % name)","if ""DefaultValue"" in spec :",158
806,"def _actions_read(self, c): <TAB> self.action_input.handle_read(c) <TAB> if c in [curses.KEY_ENTER, util.KEY_ENTER2]: <TAB>  <TAB> # take action <TAB>  <TAB> if self.action_input.selected_index == 0:  # Cancel <TAB>  <TAB>  <TAB> self.back_to_parent() <MASK> # Apply <TAB>  <TAB>  <TAB> self._apply_prefs() <TAB>  <TAB>  <TAB> client.core.get_config().addCallback(self._update_preferences) <TAB>  <TAB> elif self.action_input.selected_index == 2:  # OK <TAB>  <TAB>  <TAB> self._apply_prefs() <TAB>  <TAB>  <TAB> self.back_to_parent()",elif self . action_input . selected_index == 1 :,174
807,"def _split_anonymous_function(s): <TAB> # Regex is not sufficient to handle differences between anonymous <TAB> # functions and YAML encoded lists. We perform a sniff test to see <TAB> # if it might be an anonymous function and then confirm by <TAB> # decoding it as YAML and testing the result. <TAB> if s[:1] == ""["" and s[-1:] == ""]"" and "":"" in s: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> l = yaml_util.decode_yaml(s) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> return None, s[1:-1] <TAB>  <TAB> else: <MASK> return None, s[1:-1] <TAB> return None","if len ( l ) == 1 and isinstance ( l [ 0 ] , ( six . string_types , int ) ) :",177
808,"def test_source_address(self): <TAB> for addr, is_ipv6 in VALID_SOURCE_ADDRESSES: <MASK> warnings.warn(""No IPv6 support: skipping."", NoIPv6Warning) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> pool = HTTPConnectionPool( <TAB>  <TAB>  <TAB> self.host, self.port, source_address=addr, retries=False <TAB>  <TAB> ) <TAB>  <TAB> self.addCleanup(pool.close) <TAB>  <TAB> r = pool.request(""GET"", ""/source_address"") <TAB>  <TAB> self.assertEqual(r.data, b(addr[0]))",if is_ipv6 and not HAS_IPV6_AND_DNS :,150
809,"def vim_G(self): <TAB> """"""Put the cursor on the last character of the file."""""" <TAB> if self.is_text_wrapper(self.w): <MASK> self.do(""end-of-buffer-extend-selection"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.do(""end-of-buffer"") <TAB>  <TAB> self.done() <TAB> else: <TAB>  <TAB> self.quit()","if self . state == ""visual"" :",103
810,"def backend_supported(module, manager, **kwargs): <TAB> if CollectionNodeModule.backend_supported(module, manager, **kwargs): <TAB>  <TAB> if ""tid"" not in kwargs: <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> conn = manager.connection(did=kwargs[""did""]) <TAB>  <TAB> template_path = ""partitions/sql/{0}/#{0}#{1}#"".format( <TAB>  <TAB>  <TAB> manager.server_type, manager.version <TAB>  <TAB> ) <TAB>  <TAB> SQL = render_template( <TAB>  <TAB>  <TAB> ""/"".join([template_path, ""backend_support.sql""]), tid=kwargs[""tid""] <TAB>  <TAB> ) <TAB>  <TAB> status, res = conn.execute_scalar(SQL) <TAB>  <TAB> # check if any errors <MASK> return internal_server_error(errormsg=res) <TAB>  <TAB> return res",if not status :,195
811,"def _get_regex_config(self, data_asset_name: Optional[str] = None) -> dict: <TAB> regex_config: dict = copy.deepcopy(self._default_regex) <TAB> asset: Optional[Asset] = None <TAB> if data_asset_name: <TAB>  <TAB> asset = self._get_asset(data_asset_name=data_asset_name) <TAB> if asset is not None: <TAB>  <TAB> # Override the defaults <MASK> regex_config[""pattern""] = asset.pattern <TAB>  <TAB> if asset.group_names: <TAB>  <TAB>  <TAB> regex_config[""group_names""] = asset.group_names <TAB> return regex_config",if asset . pattern :,159
812,"def resolve(self, other): <TAB> if other == ANY_TYPE: <TAB>  <TAB> return self <TAB> elif isinstance(other, ComplexType): <TAB>  <TAB> f = self.first.resolve(other.first) <TAB>  <TAB> s = self.second.resolve(other.second) <MASK> return ComplexType(f, s) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return None <TAB> elif self == ANY_TYPE: <TAB>  <TAB> return other <TAB> else: <TAB>  <TAB> return None",if f and s :,114
813,"def collect_pages(app): <TAB> new_images = {} <TAB> for full_path, basename in app.builder.images.iteritems(): <TAB>  <TAB> base, ext = os.path.splitext(full_path) <TAB>  <TAB> retina_path = base + ""@2x"" + ext <MASK> new_images[retina_path] = app.env.images[retina_path][1] <TAB> app.builder.images.update(new_images) <TAB> return []",if retina_path in app . env . images :,129
814,"def has_bad_headers(self): <TAB> headers = [self.sender, self.reply_to] + self.recipients <TAB> for header in headers: <TAB>  <TAB> if _has_newline(header): <TAB>  <TAB>  <TAB> return True <TAB> if self.subject: <TAB>  <TAB> if _has_newline(self.subject): <TAB>  <TAB>  <TAB> for linenum, line in enumerate(self.subject.split(""\r\n"")): <MASK> return True <TAB>  <TAB>  <TAB>  <TAB> if linenum > 0 and line[0] not in ""\t "": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB>  <TAB> if _has_newline(line): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB>  <TAB> if len(line.strip()) == 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if not line :,186
815,"def reader(): <TAB> try: <TAB>  <TAB> imgs = mp4_loader(video_path, seg_num, seglen, mode) <MASK> logger.error( <TAB>  <TAB>  <TAB>  <TAB> ""{} frame length {} less than 1."".format(video_path, len(imgs)) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> yield None, None <TAB> except: <TAB>  <TAB> logger.error(""Error when loading {}"".format(mp4_path)) <TAB>  <TAB> yield None, None <TAB> imgs_ret = imgs_transform( <TAB>  <TAB> imgs, mode, seg_num, seglen, short_size, target_size, img_mean, img_std <TAB> ) <TAB> label_ret = video_path <TAB> yield imgs_ret, label_ret",if len ( imgs ) < 1 :,176
816,"def translate_from_sortname(name, sortname): <TAB> """"""'Translate' the artist name by reversing the sortname."""""" <TAB> for c in name: <TAB>  <TAB> ctg = unicodedata.category(c) <MASK> for separator in ("" & "", ""; "", "" and "", "" vs. "", "" with "", "" y ""): <TAB>  <TAB>  <TAB>  <TAB> if separator in sortname: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> parts = sortname.split(separator) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> parts = [sortname] <TAB>  <TAB>  <TAB>  <TAB> separator = """" <TAB>  <TAB>  <TAB> return separator.join(map(_reverse_sortname, parts)) <TAB> return name","if ctg [ 0 ] == ""L"" and unicodedata . name ( c ) . find ( ""LATIN"" ) == - 1 :",181
817,"def _to_local_path(path): <TAB> """"""Convert local path to SFTP path"""""" <TAB> if sys.platform == ""win32"":  # pragma: no cover <TAB>  <TAB> path = os.fsdecode(path) <MASK> path = path[1:] <TAB>  <TAB> path = path.replace(""/"", ""\\"") <TAB> return path","if path [ : 1 ] == ""/"" and path [ 2 : 3 ] == "":"" :",95
818,"def __call__(self, text: str) -> str: <TAB> for t in self.cleaner_types: <TAB>  <TAB> if t == ""tacotron"": <TAB>  <TAB>  <TAB> text = tacotron_cleaner.cleaners.custom_english_cleaners(text) <MASK> text = jaconv.normalize(text) <TAB>  <TAB> elif t == ""vietnamese"": <TAB>  <TAB>  <TAB> if vietnamese_cleaners is None: <TAB>  <TAB>  <TAB>  <TAB> raise RuntimeError(""Please install underthesea"") <TAB>  <TAB>  <TAB> text = vietnamese_cleaners.vietnamese_cleaner(text) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise RuntimeError(f""Not supported: type={t}"") <TAB> return text","elif t == ""jaconv"" :",174
819,"def cb_syncthing_system_data(self, daemon, mem, cpu, d_failed, d_total): <TAB> if self.daemon.get_my_id() in self.devices: <TAB>  <TAB> # Update my device display <TAB>  <TAB> device = self.devices[self.daemon.get_my_id()] <TAB>  <TAB> device[""ram""] = sizeof_fmt(mem) <TAB>  <TAB> device[""cpu""] = ""%3.2f%%"" % (cpu) <MASK> device[""announce""] = _(""disabled"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> device[""announce""] = ""%s/%s"" % (d_total - d_failed, d_total)",if d_total == 0 :,162
820,"def update_kls(self, sampled_kls): <TAB> for i, kl in enumerate(sampled_kls): <MASK> self.kl_coeff_val[i] *= 0.5 <TAB>  <TAB> elif kl > 1.5 * self.kl_target: <TAB>  <TAB>  <TAB> self.kl_coeff_val[i] *= 2.0 <TAB> return self.kl_coeff_val",if kl < self . kl_target / 1.5 :,106
821,"def DeleteEmptyCols(self): <TAB> cols2delete = [] <TAB> for c in range(0, self.GetCols()): <TAB>  <TAB> f = True <TAB>  <TAB> for r in range(0, self.GetRows()): <TAB>  <TAB>  <TAB> if self.FindItemAtPosition((r, c)) is not None: <TAB>  <TAB>  <TAB>  <TAB> f = False <MASK> cols2delete.append(c) <TAB> for i in range(0, len(cols2delete)): <TAB>  <TAB> self.ShiftColsLeft(cols2delete[i] + 1) <TAB>  <TAB> cols2delete = [x - 1 for x in cols2delete]",if f :,150
822,"def get_session(self): <TAB> if self._session is None: <TAB>  <TAB> session = super(ChildResourceManager, self).get_session() <MASK> session = session.get_session_for_resource(self.resource_type.resource) <TAB>  <TAB> self._session = session <TAB> return self._session",if self . resource_type . resource != constants . RESOURCE_ACTIVE_DIRECTORY :,92
823,"def _get_master_authorized_networks_config(self, raw_cluster): <TAB> if raw_cluster.get(""masterAuthorizedNetworksConfig""): <TAB>  <TAB> config = raw_cluster.get(""masterAuthorizedNetworksConfig"") <TAB>  <TAB> config[""includes_public_cidr""] = False <TAB>  <TAB> for block in config[""cidrBlocks""]: <MASK> config[""includes_public_cidr""] = True <TAB>  <TAB> return config <TAB> else: <TAB>  <TAB> return {""enabled"": False, ""cidrBlocks"": [], ""includes_public_cidr"": False}","if block [ ""cidrBlock"" ] == ""0.0.0.0/0"" :",146
824,"def scan_folder(folder): <TAB> scanned_files = [] <TAB> for root, dirs, files in os.walk(folder): <TAB>  <TAB> dirs[:] = [d for d in dirs if d != ""__pycache__""] <TAB>  <TAB> relative_path = os.path.relpath(root, folder) <TAB>  <TAB> for f in files: <MASK> continue <TAB>  <TAB>  <TAB> relative_name = os.path.normpath(os.path.join(relative_path, f)).replace( <TAB>  <TAB>  <TAB>  <TAB> ""\\"", ""/"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> scanned_files.append(relative_name) <TAB> return sorted(scanned_files)","if f . endswith ( "".pyc"" ) :",154
825,"def read_progress(self): <TAB> while True: <TAB>  <TAB> processed_file = self.queue.get() <TAB>  <TAB> self.threading_completed.append(processed_file) <TAB>  <TAB> total_number = len(self.file_list) <TAB>  <TAB> completed_number = len(self.threading_completed) <TAB>  <TAB> # Just for the record, this slows down book searching by about 20% <TAB>  <TAB> if _progress_emitter:  # Skip update in reading mode <TAB>  <TAB>  <TAB> _progress_emitter.update_progress(completed_number * 100 // total_number) <MASK> break",if total_number == completed_number :,145
826,"def next_instruction_is_function_or_class(lines): <TAB> """"""Is the first non-empty, non-commented line of the cell either a function or a class?"""""" <TAB> parser = StringParser(""python"") <TAB> for i, line in enumerate(lines): <TAB>  <TAB> if parser.is_quoted(): <TAB>  <TAB>  <TAB> parser.read_line(line) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> parser.read_line(line) <TAB>  <TAB> if not line.strip():  # empty line <MASK> return False <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if line.startswith(""def "") or line.startswith(""class ""): <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> if line.startswith((""#"", ""@"", "" "", "")"")): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> return False <TAB> return False",if i > 0 and not lines [ i - 1 ] . strip ( ) :,194
827,def __next__(self): <TAB> try: <TAB>  <TAB> data = next(self.iter_loader) <TAB> except StopIteration: <TAB>  <TAB> self._epoch += 1 <MASK> self._dataloader.sampler.set_epoch(self._epoch) <TAB>  <TAB> self.iter_loader = iter(self._dataloader) <TAB>  <TAB> data = next(self.iter_loader) <TAB> return data,"if hasattr ( self . _dataloader . sampler , ""set_epoch"" ) :",104
828,"def dgl_mp_batchify_fn(data): <TAB> if isinstance(data[0], tuple): <TAB>  <TAB> data = zip(*data) <TAB>  <TAB> return [dgl_mp_batchify_fn(i) for i in data] <TAB> for dt in data: <TAB>  <TAB> if dt is not None: <MASK> return [d for d in data if isinstance(d, dgl.DGLGraph)] <TAB>  <TAB>  <TAB> elif isinstance(dt, nd.NDArray): <TAB>  <TAB>  <TAB>  <TAB> pad = Pad(axis=(1, 2), num_shards=1, ret_length=False) <TAB>  <TAB>  <TAB>  <TAB> data_list = [dt for dt in data if dt is not None] <TAB>  <TAB>  <TAB>  <TAB> return pad(data_list)","if isinstance ( dt , dgl . DGLGraph ) :",183
829,"def f(self, info): <TAB> for k in keys: <MASK> for k2 in list(info.keys()): <TAB>  <TAB>  <TAB>  <TAB> if k(k2): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> info.pop(k2) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> info.pop(k, None)",if callable ( k ) :,78
830,"def create(path, binary=False): <TAB> for i in range(10): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> os.makedirs(os.path.dirname(path), exist_ok=True) <MASK> return open(path, ""wb"") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return open(path, ""w"", encoding=""utf-8"") <TAB>  <TAB>  <TAB> if i > 0: <TAB>  <TAB>  <TAB>  <TAB> log(True, f""Created {path} at attempt {i + 1}"") <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> time.sleep(0.5) <TAB> else: <TAB>  <TAB> raise Error(f""Failed to create {path}"")",if binary :,157
831,"def validate_update(self, update_query): <TAB> structure = DotCollapsedDict(self.doc_class.structure) <TAB> for op, fields in update_query.iteritems(): <TAB>  <TAB> for field in fields: <TAB>  <TAB>  <TAB> if op != ""$unset"" and op != ""$rename"": <MASK> raise UpdateQueryError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""'%s' not found in %s's structure"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> % (field, self.doc_class.__name__) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> )",if field not in structure :,133
832,"def check_enums_ATLAS_ISAEXT(lines): <TAB> for i, isaext in enumerate(ATLAS_ISAEXT): <TAB>  <TAB> got = lines.pop(0).strip() <MASK> expect = ""none: 1"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> expect = ""{0}: {1}"".format(isaext, 1 << i) <TAB>  <TAB> if got != expect: <TAB>  <TAB>  <TAB> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB> ""ATLAS_ISAEXT mismatch at position "" <TAB>  <TAB>  <TAB>  <TAB> + str(i) <TAB>  <TAB>  <TAB>  <TAB> + "": got >>"" <TAB>  <TAB>  <TAB>  <TAB> + got <TAB>  <TAB>  <TAB>  <TAB> + ""<<, expected >>"" <TAB>  <TAB>  <TAB>  <TAB> + expect <TAB>  <TAB>  <TAB>  <TAB> + ""<<"" <TAB>  <TAB>  <TAB> )",if i == 0 :,180
833,"def _test_export_session_csv(self, test_session=None): <TAB> with self.app.test_request_context(): <MASK> test_session = SessionFactory() <TAB>  <TAB> field_data = export_sessions_csv([test_session]) <TAB>  <TAB> session_row = field_data[1] <TAB>  <TAB> self.assertEqual(session_row[0], ""example (accepted)"") <TAB>  <TAB> self.assertEqual(session_row[9], ""accepted"")",if not test_session :,116
834,"def get_report_to_platform(self, args, scan_reports): <TAB> if self.bc_api_key: <MASK> repo_id = self.get_repository(args) <TAB>  <TAB>  <TAB> self.setup_bridgecrew_credentials( <TAB>  <TAB>  <TAB>  <TAB> bc_api_key=self.bc_api_key, repo_id=repo_id <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if self.is_integration_configured(): <TAB>  <TAB>  <TAB> self._upload_run(args, scan_reports)",if args . directory :,126
835,"def test_fvalue(self): <TAB> if not getattr(self, ""skip_f"", False): <TAB>  <TAB> rtol = getattr(self, ""rtol"", 1e-10) <TAB>  <TAB> assert_allclose(self.res1.fvalue, self.res2.F, rtol=rtol) <MASK> # only available with ivreg2 <TAB>  <TAB>  <TAB> assert_allclose(self.res1.f_pvalue, self.res2.Fp, rtol=rtol) <TAB> else: <TAB>  <TAB> raise pytest.skip(""TODO: document why this test is skipped"")","if hasattr ( self . res2 , ""Fp"" ) :",143
836,"def fix_repeating_arguments(self): <TAB> """"""Fix elements that should accumulate/increment values."""""" <TAB> either = [list(child.children) for child in transform(self).children] <TAB> for case in either: <TAB>  <TAB> for e in [child for child in case if case.count(child) > 1]: <TAB>  <TAB>  <TAB> if type(e) is Argument or type(e) is Option and e.argcount: <TAB>  <TAB>  <TAB>  <TAB> if e.value is None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> e.value = [] <MASK> e.value = e.value.split() <TAB>  <TAB>  <TAB> if type(e) is Command or type(e) is Option and e.argcount == 0: <TAB>  <TAB>  <TAB>  <TAB> e.value = 0 <TAB> return self",elif type ( e . value ) is not list :,190
837,"def touch(self): <TAB> if not self.exists(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.parent().touch() <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> node = self._fs.touch(self.pathnames, {}) <TAB>  <TAB> if not node.isdir: <TAB>  <TAB>  <TAB> raise AssertionError(""Not a folder: %s"" % self.path) <MASK> self.watcher.emit(""created"", self)",if self . watcher :,107
838,"def __init__(self, _inf=None, _tzinfos=None): <TAB> if _inf: <TAB>  <TAB> self._tzinfos = _tzinfos <TAB>  <TAB> self._utcoffset, self._dst, self._tzname = _inf <TAB> else: <TAB>  <TAB> _tzinfos = {} <TAB>  <TAB> self._tzinfos = _tzinfos <TAB>  <TAB> self._utcoffset, self._dst, self._tzname = self._transition_info[0] <TAB>  <TAB> _tzinfos[self._transition_info[0]] = self <TAB>  <TAB> for inf in self._transition_info[1:]: <MASK> _tzinfos[inf] = self.__class__(inf, _tzinfos)",if not _tzinfos . has_key ( inf ) :,173
839,"def test_sample_output(): <TAB> comment = ""SAMPLE OUTPUT"" <TAB> skip_files = [""__init__.py""] <TAB> errors = [] <TAB> for _file in sorted(MODULE_PATH.iterdir()): <MASK> with _file.open() as f: <TAB>  <TAB>  <TAB>  <TAB> if comment not in f.read(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> errors.append((comment, _file)) <TAB> if errors: <TAB>  <TAB> line = ""Missing sample error(s) detected!\n\n"" <TAB>  <TAB> for error in errors: <TAB>  <TAB>  <TAB> line += ""`{}` is not in module `{}`\n"".format(*error) <TAB>  <TAB> print(line[:-1]) <TAB>  <TAB> assert False","if _file . suffix == "".py"" and _file . name not in skip_files :",174
840,"def http_get(url, target): <TAB> req = requests.get(url, stream=True) <TAB> content_length = req.headers.get(""Content-Length"") <TAB> total = int(content_length) if content_length is not None else None <TAB> progress = tqdm(unit=""B"", total=total) <TAB> with open(target, ""wb"") as target_file: <TAB>  <TAB> for chunk in req.iter_content(chunk_size=1024): <MASK> # filter out keep-alive new chunks <TAB>  <TAB>  <TAB>  <TAB> progress.update(len(chunk)) <TAB>  <TAB>  <TAB>  <TAB> target_file.write(chunk) <TAB> progress.close()",if chunk :,154
841,"def _elements_to_datasets(self, elements, level=0): <TAB> for element in elements: <TAB>  <TAB> extra_kwds = {""identifier_%d"" % level: element[""name""]} <MASK> for inner_element in self._elements_to_datasets( <TAB>  <TAB>  <TAB>  <TAB> element[""elements""], level=level + 1 <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> dataset = extra_kwds.copy() <TAB>  <TAB>  <TAB>  <TAB> dataset.update(inner_element) <TAB>  <TAB>  <TAB>  <TAB> yield dataset <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> dataset = extra_kwds <TAB>  <TAB>  <TAB> extra_kwds.update(element) <TAB>  <TAB>  <TAB> yield extra_kwds","if ""elements"" in element :",156
842,"def update_dict(a, b): <TAB> for key, value in b.items(): <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB> continue <MASK> a[key] = value <TAB>  <TAB> elif isinstance(a[key], dict) and isinstance(value, dict): <TAB>  <TAB>  <TAB> update_dict(a[key], value) <TAB>  <TAB> elif isinstance(a[key], list): <TAB>  <TAB>  <TAB> a[key].append(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> a[key] = [a[key], value]",if key not in a :,131
843,"def scan(self, targets): <TAB> for target in targets: <TAB>  <TAB> target.print_infos() <TAB>  <TAB> if self.is_interesting(target): <TAB>  <TAB>  <TAB> self.target[""other""].append(target) <MASK> return target <TAB> return None",if self . match ( target ) :,72
844,"def printConnections(switches): <TAB> ""Compactly print connected nodes to each switch"" <TAB> for sw in switches: <TAB>  <TAB> output(""%s: "" % sw) <TAB>  <TAB> for intf in sw.intfList(): <TAB>  <TAB>  <TAB> link = intf.link <MASK> intf1, intf2 = link.intf1, link.intf2 <TAB>  <TAB>  <TAB>  <TAB> remote = intf1 if intf1.node != sw else intf2 <TAB>  <TAB>  <TAB>  <TAB> output(""%s(%s) "" % (remote.node, sw.ports[intf])) <TAB>  <TAB> output(""\n"")",if link :,147
845,"def __cut(sentence): <TAB> global emit_P <TAB> prob, pos_list = viterbi(sentence, ""BMES"", start_P, trans_P, emit_P) <TAB> begin, nexti = 0, 0 <TAB> # print pos_list, sentence <TAB> for i, char in enumerate(sentence): <TAB>  <TAB> pos = pos_list[i] <TAB>  <TAB> if pos == ""B"": <TAB>  <TAB>  <TAB> begin = i <MASK> yield sentence[begin : i + 1] <TAB>  <TAB>  <TAB> nexti = i + 1 <TAB>  <TAB> elif pos == ""S"": <TAB>  <TAB>  <TAB> yield char <TAB>  <TAB>  <TAB> nexti = i + 1 <TAB> if nexti < len(sentence): <TAB>  <TAB> yield sentence[nexti:]","elif pos == ""E"" :",174
846,"def check_files(self, paths=None): <TAB> """"""Run all checks on the paths."""""" <TAB> if paths is None: <TAB>  <TAB> paths = self.paths <TAB> report = self.options.report <TAB> runner = self.runner <TAB> report.start() <TAB> try: <TAB>  <TAB> for path in paths: <MASK> self.input_dir(path) <TAB>  <TAB>  <TAB> elif not self.excluded(path): <TAB>  <TAB>  <TAB>  <TAB> runner(path) <TAB> except KeyboardInterrupt: <TAB>  <TAB> print(""... stopped"") <TAB> report.stop() <TAB> return report",if os . path . isdir ( path ) :,140
847,"def verts_of_loop(edge_loop): <TAB> verts = [] <TAB> for e0, e1 in iter_pairs(edge_loop, False): <MASK> v0 = e0.shared_vert(e1) <TAB>  <TAB>  <TAB> verts += [e0.other_vert(v0), v0] <TAB>  <TAB> verts += [e1.other_vert(verts[-1])] <TAB> if len(verts) > 1 and verts[0] == verts[-1]: <TAB>  <TAB> return verts[:-1] <TAB> return verts",if not verts :,134
848,"def generator(self, data): <TAB> for task in data: <TAB>  <TAB> # Do we scan everything or just /bin/bash instances? <MASK> continue <TAB>  <TAB> for bucket in task.bash_hash_entries(): <TAB>  <TAB>  <TAB> yield ( <TAB>  <TAB>  <TAB>  <TAB> 0, <TAB>  <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> int(task.p_pid), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> str(task.p_comm), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> int(bucket.times_found), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> str(bucket.key), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> str(bucket.data.path), <TAB>  <TAB>  <TAB>  <TAB> ], <TAB>  <TAB>  <TAB> )","if not ( self . _config . SCAN_ALL or str ( task . p_comm ) == ""bash"" ) :",174
849,"def __get_ratio(self): <TAB> """"""Return splitter ratio of the main splitter."""""" <TAB> c = self.c <TAB> free_layout = c.free_layout <TAB> if free_layout: <TAB>  <TAB> w = free_layout.get_main_splitter() <TAB>  <TAB> if w: <TAB>  <TAB>  <TAB> aList = w.sizes() <MASK> n1, n2 = aList <TAB>  <TAB>  <TAB>  <TAB> # 2017/06/07: guard against division by zero. <TAB>  <TAB>  <TAB>  <TAB> ratio = 0.5 if n1 + n2 == 0 else float(n1) / float(n1 + n2) <TAB>  <TAB>  <TAB>  <TAB> return ratio <TAB> return 0.5",if len ( aList ) == 2 :,170
850,"def geterrors(self): <TAB> """"""Get all error messages."""""" <TAB> notes = self.getnotes(origin=""translator"").split(""\n"") <TAB> errordict = {} <TAB> for note in notes: <MASK> error = note.replace(""(pofilter) "", """") <TAB>  <TAB>  <TAB> errorname, errortext = error.split("": "", 1) <TAB>  <TAB>  <TAB> errordict[errorname] = errortext <TAB> return errordict","if ""(pofilter) "" in note :",107
851,"def rename_path(self, path, new_path): <TAB> logger.debug(""rename_path '%s' -> '%s'"" % (path, new_path)) <TAB> dirs = self.readdir(path) <TAB> for d in dirs: <TAB>  <TAB> if d in [""."", ""..""]: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> d_path = """".join([path, ""/"", d]) <TAB>  <TAB> d_new_path = """".join([new_path, ""/"", d]) <TAB>  <TAB> attr = self.getattr(d_path) <MASK> self.rename_path(d_path, d_new_path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.rename_item(d_path, d_new_path) <TAB> self.rename_item(path, new_path, dir=True)","if stat . S_ISDIR ( attr [ ""st_mode"" ] ) :",196
852,"def index(self, url_id: int) -> FlaskResponse:  # pylint: disable=no-self-use <TAB> url = db.session.query(models.Url).get(url_id) <TAB> if url and url.url: <TAB>  <TAB> explore_url = ""//superset/explore/?"" <MASK> explore_url += f""r={url_id}"" <TAB>  <TAB>  <TAB> return redirect(explore_url[1:]) <TAB>  <TAB> return redirect(url.url[1:]) <TAB> flash(""URL to nowhere..."", ""danger"") <TAB> return redirect(""/"")",if url . url . startswith ( explore_url ) :,142
853,"def testShortCircuit(self): <TAB> """"""Test that creation short-circuits to reuse existing references"""""" <TAB> sd = {} <TAB> for s in self.ss: <TAB>  <TAB> sd[s] = 1 <TAB> for t in self.ts: <MASK> self.assertTrue(sd.has_key(safeRef(t.x))) <TAB>  <TAB>  <TAB> self.assertTrue(safeRef(t.x) in sd) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertTrue(sd.has_key(safeRef(t))) <TAB>  <TAB>  <TAB> self.assertTrue(safeRef(t) in sd)","if hasattr ( t , ""x"" ) :",146
854,"def wrapped(request, *args, **kwargs): <TAB> if not request.user.is_authenticated(): <TAB>  <TAB> request.session[""_next""] = request.get_full_path() <MASK> redirect_uri = reverse( <TAB>  <TAB>  <TAB>  <TAB> ""sentry-auth-organization"", args=[kwargs[""organization_slug""]] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> redirect_uri = get_login_url() <TAB>  <TAB> return HttpResponseRedirect(redirect_uri) <TAB> return func(request, *args, **kwargs)","if ""organization_slug"" in kwargs :",132
855,"def read_info(reader, dump=None): <TAB> line_number_table_length = reader.read_u2() <MASK> reader.debug( <TAB>  <TAB>  <TAB> "" <TAB> "" * dump, ""Line numbers (%s total):"" % line_number_table_length <TAB>  <TAB> ) <TAB> line_numbers = [] <TAB> for i in range(0, line_number_table_length): <TAB>  <TAB> start_pc = reader.read_u2() <TAB>  <TAB> line_number = reader.read_u2() <TAB>  <TAB> if dump is not None: <TAB>  <TAB>  <TAB> reader.debug("" <TAB> "" * (dump + 1), ""%s: %s"" % (start_pc, line_number)) <TAB>  <TAB> line_numbers.append((start_pc, line_number)) <TAB> return LineNumberTable(line_numbers)",if dump is not None :,198
856,"def compute_timer_precision(timer): <TAB> precision = None <TAB> points = 0 <TAB> timeout = timeout_timer() + 1.0 <TAB> previous = timer() <TAB> while timeout_timer() < timeout or points < 5: <TAB>  <TAB> for _ in XRANGE(10): <TAB>  <TAB>  <TAB> t1 = timer() <TAB>  <TAB>  <TAB> t2 = timer() <TAB>  <TAB>  <TAB> dt = t2 - t1 <TAB>  <TAB>  <TAB> if 0 < dt: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> dt = t2 - previous <TAB>  <TAB>  <TAB> if dt <= 0.0: <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> precision = min(precision, dt) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> precision = dt <TAB>  <TAB> points += 1 <TAB>  <TAB> previous = timer() <TAB> return precision",if precision is not None :,189
857,def get_hi_lineno(self): <TAB> lineno = Node.get_hi_lineno(self) <TAB> if self.expr1 is None: <TAB>  <TAB> pass <TAB> else: <TAB>  <TAB> lineno = self.expr1.get_hi_lineno() <MASK> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lineno = self.expr2.get_hi_lineno() <TAB>  <TAB>  <TAB> if self.expr3 is None: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> lineno = self.expr3.get_hi_lineno() <TAB> return lineno,if self . expr2 is None :,142
858,"def validate_cluster_resource_group(cmd, namespace): <TAB> if namespace.cluster_resource_group is not None: <TAB>  <TAB> client = get_mgmt_service_client( <TAB>  <TAB>  <TAB> cmd.cli_ctx, ResourceType.MGMT_RESOURCE_RESOURCES <TAB>  <TAB> ) <MASK> raise InvalidArgumentValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Invalid --cluster-resource-group '%s': resource group must not exist."" <TAB>  <TAB>  <TAB>  <TAB> % namespace.cluster_resource_group <TAB>  <TAB>  <TAB> )",if client . resource_groups . check_existence ( namespace . cluster_resource_group ) :,137
859,"def find_word_bounds(self, text, index, allowed_chars): <TAB> right = left = index <TAB> done = False <TAB> while not done: <MASK> done = True <TAB>  <TAB> elif not self.word_boundary_char(text[left - 1]): <TAB>  <TAB>  <TAB> left -= 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> done = True <TAB> done = False <TAB> while not done: <TAB>  <TAB> if right == len(text): <TAB>  <TAB>  <TAB> done = True <TAB>  <TAB> elif not self.word_boundary_char(text[right]): <TAB>  <TAB>  <TAB> right += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> done = True <TAB> return left, right",if left == 0 :,159
860,"def _check_good_input(self, X, y=None): <TAB> if isinstance(X, dict): <TAB>  <TAB> lengths = [len(X1) for X1 in X.values()] <TAB>  <TAB> if len(set(lengths)) > 1: <TAB>  <TAB>  <TAB> raise ValueError(""Not all values of X are of equal length."") <TAB>  <TAB> x_len = lengths[0] <TAB> else: <TAB>  <TAB> x_len = len(X) <TAB> if y is not None: <MASK> raise ValueError(""X and y are not of equal length."") <TAB> if self.regression and y is not None and y.ndim == 1: <TAB>  <TAB> y = y.reshape(-1, 1) <TAB> return X, y",if len ( y ) != x_len :,175
861,"def _get_text_nodes(nodes, html_body): <TAB> text = [] <TAB> open_tags = 0 <TAB> for node in nodes: <TAB>  <TAB> if isinstance(node, HtmlTag): <TAB>  <TAB>  <TAB> if node.tag_type == OPEN_TAG: <TAB>  <TAB>  <TAB>  <TAB> open_tags += 1 <MASK> open_tags -= 1 <TAB>  <TAB> elif ( <TAB>  <TAB>  <TAB> isinstance(node, HtmlDataFragment) <TAB>  <TAB>  <TAB> and node.is_text_content <TAB>  <TAB>  <TAB> and open_tags == 0 <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> text.append(html_body[node.start : node.end]) <TAB> return text",elif node . tag_type == CLOSE_TAG :,165
862,"def _get_spyne_type(cls_name, k, v): <TAB> try: <TAB>  <TAB> v = NATIVE_MAP.get(v, v) <TAB> except TypeError: <TAB>  <TAB> return <TAB> try: <TAB>  <TAB> subc = issubclass(v, ModelBase) or issubclass(v, SelfReference) <TAB> except: <TAB>  <TAB> subc = False <TAB> if subc: <TAB>  <TAB> if issubclass(v, Array) and len(v._type_info) != 1: <TAB>  <TAB>  <TAB> raise Exception(""Invalid Array definition in %s.%s."" % (cls_name, k)) <MASK> raise Exception(""Please specify the number of dimensions"") <TAB>  <TAB> return v","elif issubclass ( v , Point ) and v . Attributes . dim is None :",171
863,"def customize(cls, **kwargs): <TAB> """"""return a class with some existing attributes customized"""""" <TAB> for name, value in kwargs.iteritems(): <MASK> raise TransportError( <TAB>  <TAB>  <TAB>  <TAB> ""you cannot customize the protected attribute %s"" % name <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if not hasattr(cls, name): <TAB>  <TAB>  <TAB> raise TransportError(""Transport has no attribute %s"" % name) <TAB> NewSubClass = type(""Customized_{}"".format(cls.__name__), (cls,), kwargs) <TAB> return NewSubClass","if name in [ ""cookie"" , ""circuit"" , ""upstream"" , ""downstream"" , ""stream"" ] :",144
864,"def test_UNrelativize(self): <TAB> import URIlib <TAB> relative = self.relative + self.full_relativize <TAB> for base, rel, fullpath, common in relative: <TAB>  <TAB> URI = uriparse.UnRelativizeURL(base, rel) <TAB>  <TAB> fullURI = URIlib.URIParser(URI) <TAB>  <TAB> # We need to canonicalize the result from unrelativize <TAB>  <TAB> # compared to the original full path we expect to see. <MASK> fullpath = fullpath[:-1] <TAB>  <TAB> self.failUnlessSamePath( <TAB>  <TAB>  <TAB> os.path.normcase(fullURI.path), os.path.normcase(fullpath) <TAB>  <TAB> )","if fullpath [ - 1 ] in ( ""/"" , ""\\"" ) :",170
865,"def get_release_info(file_path=RELEASE_FILE): <TAB> RELEASE_TYPE_REGEX = re.compile(r""^[Rr]elease [Tt]ype: (major|minor|patch)$"") <TAB> with open(file_path, ""r"") as f: <TAB>  <TAB> line = f.readline() <TAB>  <TAB> match = RELEASE_TYPE_REGEX.match(line) <MASK> print( <TAB>  <TAB>  <TAB>  <TAB> ""The file RELEASE.md should start with `Release type` "" <TAB>  <TAB>  <TAB>  <TAB> ""and specify one of the following values: major, minor or patch."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> sys.exit(1) <TAB>  <TAB> type_ = match.group(1) <TAB>  <TAB> changelog = """".join([line for line in f.readlines()]).strip() <TAB> return type_, changelog",if not match :,190
866,"def _get_next_history_entry(self): <TAB> if self._history: <TAB>  <TAB> hist_len = len(self._history) - 1 <TAB>  <TAB> self.history_index = min(hist_len, self.history_index + 1) <TAB>  <TAB> index = self.history_index <MASK> self.history_index += 1 <TAB>  <TAB> return self._history[index] <TAB> return """"",if self . history_index == hist_len :,107
867,"def star_op(self): <TAB> """"""Put a '*' op, with special cases for *args."""""" <TAB> val = ""*"" <TAB> if self.paren_level: <TAB>  <TAB> i = len(self.code_list) - 1 <TAB>  <TAB> if self.code_list[i].kind == ""blank"": <TAB>  <TAB>  <TAB> i -= 1 <TAB>  <TAB> token = self.code_list[i] <MASK> self.op_no_blanks(val) <TAB>  <TAB> elif token.value == "","": <TAB>  <TAB>  <TAB> self.blank() <TAB>  <TAB>  <TAB> self.add_token(""op-no-blanks"", val) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.op(val) <TAB> else: <TAB>  <TAB> self.op(val)","if token . kind == ""lt"" :",177
868,"def get_safe_settings(): <TAB> ""Returns a dictionary of the settings module, with sensitive settings blurred out."" <TAB> settings_dict = {} <TAB> for k in dir(settings): <MASK> if HIDDEN_SETTINGS.search(k): <TAB>  <TAB>  <TAB>  <TAB> settings_dict[k] = ""********************"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> settings_dict[k] = getattr(settings, k) <TAB> return settings_dict",if k . isupper ( ) :,109
869,"def nextEditable(self): <TAB> """"""Moves focus of the cursor to the next editable window"""""" <TAB> if self.currentEditable is None: <TAB>  <TAB> if len(self._editableChildren): <TAB>  <TAB>  <TAB> self._currentEditableRef = self._editableChildren[0] <TAB> else: <TAB>  <TAB> for ref in weakref.getweakrefs(self.currentEditable): <MASK> cei = self._editableChildren.index(ref) <TAB>  <TAB>  <TAB>  <TAB> nei = cei + 1 <TAB>  <TAB>  <TAB>  <TAB> if nei >= len(self._editableChildren): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> nei = 0 <TAB>  <TAB>  <TAB>  <TAB> self._currentEditableRef = self._editableChildren[nei] <TAB> return self.currentEditable",if ref in self . _editableChildren :,179
870,"def _handle_dependents_type(types, type_str, type_name, rel_name, row): <TAB> if types[type_str[0]] is None: <MASK> type_name = ""index"" <TAB>  <TAB>  <TAB> rel_name = row[""indname""] + "" ON "" + rel_name <TAB>  <TAB> elif type_str[0] == ""o"": <TAB>  <TAB>  <TAB> type_name = ""operator"" <TAB>  <TAB>  <TAB> rel_name = row[""relname""] <TAB> else: <TAB>  <TAB> type_name = types[type_str[0]] <TAB> return type_name, rel_name","if type_str [ 0 ] == ""i"" :",152
871,"def streamErrorHandler(self, conn, error): <TAB> name, text = ""error"", error.getData() <TAB> for tag in error.getChildren(): <MASK> if tag.getName() == ""text"": <TAB>  <TAB>  <TAB>  <TAB> text = tag.getData() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> name = tag.getName() <TAB> if name in stream_exceptions.keys(): <TAB>  <TAB> exc = stream_exceptions[name] <TAB> else: <TAB>  <TAB> exc = StreamError <TAB> raise exc((name, text))",if tag . getNamespace ( ) == NS_XMPP_STREAMS :,138
872,"def _validate_names(self, settings: _SettingsType) -> None: <TAB> """"""Make sure all settings exist."""""" <TAB> unknown = [] <TAB> for name in settings: <MASK> unknown.append(name) <TAB> if unknown: <TAB>  <TAB> errors = [ <TAB>  <TAB>  <TAB> configexc.ConfigErrorDesc( <TAB>  <TAB>  <TAB>  <TAB> ""While loading options"", ""Unknown option {}"".format(e) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> for e in sorted(unknown) <TAB>  <TAB> ] <TAB>  <TAB> raise configexc.ConfigFileErrors(""autoconfig.yml"", errors)",if name not in configdata . DATA :,139
873,"def can_haz(self, target, credentials): <TAB> """"""Check whether key-values in target are present in credentials."""""" <TAB> # TODO(termie): handle ANDs, probably by providing a tuple instead of a <TAB> # <TAB>  <TAB>  <TAB>    string <TAB> for requirement in target: <TAB>  <TAB> key, match = requirement.split("":"", 1) <TAB>  <TAB> check = credentials.get(key) <MASK> check = [check] <TAB>  <TAB> if match in check: <TAB>  <TAB>  <TAB> return True","if check is None or isinstance ( check , basestring ) :",135
874,"def _recursive_fx_apply(input: dict, fx): <TAB> for k, v in input.items(): <MASK> v = torch.tensor(v) <TAB>  <TAB> if isinstance(v, torch.Tensor): <TAB>  <TAB>  <TAB> v = fx(v.float()) <TAB>  <TAB>  <TAB> input[k] = v <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _recursive_fx_apply(v, fx)","if isinstance ( v , list ) :",102
875,"def get(self, url, **kwargs): <TAB> app, url = self._prepare_call(url, kwargs) <TAB> if app: <MASK> self._first_ping = False <TAB>  <TAB>  <TAB> return EmptyCapabilitiesResponse() <TAB>  <TAB> elif ""Hello0"" in url and ""1.2.1"" in url and ""v1"" in url: <TAB>  <TAB>  <TAB> return ErrorApiResponse() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> response = app.get(url, **kwargs) <TAB>  <TAB>  <TAB> return TestingResponse(response) <TAB> else: <TAB>  <TAB> return requests.get(url, **kwargs)","if url . endswith ( ""ping"" ) and self . _first_ping :",153
876,"def server_thread_fn(): <TAB> server_ctx = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH) <TAB> server_ctx.load_cert_chain(""trio-test-1.pem"") <TAB> server = server_ctx.wrap_socket( <TAB>  <TAB> server_sock, <TAB>  <TAB> server_side=True, <TAB>  <TAB> suppress_ragged_eofs=False, <TAB> ) <TAB> while True: <TAB>  <TAB> data = server.recv(4096) <TAB>  <TAB> print(""server got:"", data) <MASK> print(""server waiting for client to finish everything"") <TAB>  <TAB>  <TAB> client_done.wait() <TAB>  <TAB>  <TAB> print(""server attempting to send back close-notify"") <TAB>  <TAB>  <TAB> server.unwrap() <TAB>  <TAB>  <TAB> print(""server ok"") <TAB>  <TAB>  <TAB> break <TAB>  <TAB> server.sendall(data)",if not data :,198
877,"def find_hostnames(data): <TAB> # sends back an array of hostnames <TAB> hostnames = [] <TAB> for i in re.finditer(hostname_regex, data): <TAB>  <TAB> h = string.lower(i.group(1)) <TAB>  <TAB> tld = h.split(""."")[-1:][0] <MASK> hostnames.append(h) <TAB> return hostnames",if tld in tlds :,91
878,"def Validate(self, win): <TAB> textCtrl = self.GetWindow() <TAB> text = textCtrl.GetValue().strip() <TAB> sChar = Character.getInstance() <TAB> try: <MASK> raise ValueError(_t(""You must supply a name for the Character!"")) <TAB>  <TAB> elif text in [x.name for x in sChar.getCharacterList()]: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> _t(""Character name already in use, please choose another."") <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return True <TAB> except ValueError as e: <TAB>  <TAB> pyfalog.error(e) <TAB>  <TAB> wx.MessageBox(""{}"".format(e), _t(""Error"")) <TAB>  <TAB> textCtrl.SetFocus() <TAB>  <TAB> return False",if len ( text ) == 0 :,177
879,def get_random_user_agent(agent_list=UA_CACHE): <TAB> if not len(agent_list): <TAB>  <TAB> ua_file = file(UA_FILE) <TAB>  <TAB> for line in ua_file: <TAB>  <TAB>  <TAB> line = line.strip() <MASK> agent_list.append(line) <TAB> ua = random.choice(UA_CACHE) <TAB> return ua,if line :,100
880,"def _validate_action_like_for_prefixes(self, key): <TAB> for statement in self._statements: <MASK> if isinstance(statement[key], string_types): <TAB>  <TAB>  <TAB>  <TAB> self._validate_action_prefix(statement[key]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> for action in statement[key]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._validate_action_prefix(action)",if key in statement :,100
881,"def predict(self, X): <TAB> if self.regression: <TAB>  <TAB> return self.predict_proba(X) <TAB> else: <TAB>  <TAB> y_pred = np.argmax(self.predict_proba(X), axis=1) <MASK> y_pred = self.enc_.inverse_transform(y_pred) <TAB>  <TAB> return y_pred",if self . use_label_encoder :,93
882,"def _threaded_request_tracker(self, builder): <TAB> while True: <TAB>  <TAB> event_type = self._read_q.get() <MASK> return <TAB>  <TAB> payload = {""body"": b""""} <TAB>  <TAB> request_id = builder.build_record(event_type, payload, """") <TAB>  <TAB> self._write_q.put_nowait(request_id)",if event_type is False :,96
883,"def __call__(self, value): <TAB> try: <TAB>  <TAB> super(EmailValidator, self).__call__(value) <TAB> except ValidationError as e: <TAB>  <TAB> # Trivial case failed. Try for possible IDN domain-part <MASK> parts = value.split(""@"") <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> parts[-1] = parts[-1].encode(""idna"").decode(""ascii"") <TAB>  <TAB>  <TAB> except UnicodeError: <TAB>  <TAB>  <TAB>  <TAB> raise e <TAB>  <TAB>  <TAB> super(EmailValidator, self).__call__(""@"".join(parts)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise","if value and ""@"" in value :",143
884,"def PreprocessConditionalStatement(self, IfList, ReplacedLine): <TAB> while self: <TAB>  <TAB> if self.__Token: <TAB>  <TAB>  <TAB> x = 1 <MASK> if self <= 2: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> RegionSizeGuid = 3 <TAB>  <TAB>  <TAB> if not RegionSizeGuid: <TAB>  <TAB>  <TAB>  <TAB> RegionLayoutLine = 5 <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> RegionLayoutLine = self.CurrentLineNumber <TAB> return 1",elif not IfList :,111
885,"def _arg_with_type(self): <TAB> for t in self.d[""Args""]: <TAB>  <TAB> m = re.search(""([A-Za-z0-9_-]+)\s{0,4}(\(.+\))\s{0,4}:"", t) <MASK> self.args[m.group(1)] = m.group(2) <TAB> return self.args",if m :,95
886,"def get_palette_for_custom_classes(self, class_names, palette=None): <TAB> if self.label_map is not None: <TAB>  <TAB> # return subset of palette <TAB>  <TAB> palette = [] <TAB>  <TAB> for old_id, new_id in sorted(self.label_map.items(), key=lambda x: x[1]): <TAB>  <TAB>  <TAB> if new_id != -1: <TAB>  <TAB>  <TAB>  <TAB> palette.append(self.PALETTE[old_id]) <TAB>  <TAB> palette = type(self.PALETTE)(palette) <TAB> elif palette is None: <MASK> palette = np.random.randint(0, 255, size=(len(class_names), 3)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> palette = self.PALETTE <TAB> return palette",if self . PALETTE is None :,194
887,"def Visit_star_expr(self, node):  # pylint: disable=invalid-name <TAB> # star_expr ::= '*' expr <TAB> for child in node.children: <TAB>  <TAB> self.Visit(child) <MASK> _AppendTokenSubtype(child, format_token.Subtype.UNARY_OPERATOR) <TAB>  <TAB>  <TAB> _AppendTokenSubtype(child, format_token.Subtype.VARARGS_STAR)","if isinstance ( child , pytree . Leaf ) and child . value == ""*"" :",110
888,"def create_if_compatible(cls, typ: Type, *, root: ""RootNode"") -> Optional[""Node""]: <TAB> if cls.compatible_types: <TAB>  <TAB> target_type: Type = typ <MASK> target_type = getattr(typ, ""__origin__"", None) or typ <TAB>  <TAB> if cls._issubclass(target_type, cls.compatible_types): <TAB>  <TAB>  <TAB> return cls(typ, root=root) <TAB> return None",if cls . use_origin :,109
889,"def grep_full_py_identifiers(tokens): <TAB> global pykeywords <TAB> tokens = list(tokens) <TAB> i = 0 <TAB> while i < len(tokens): <TAB>  <TAB> tokentype, token = tokens[i] <TAB>  <TAB> i += 1 <TAB>  <TAB> if tokentype != ""id"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> while ( <TAB>  <TAB>  <TAB> i + 1 < len(tokens) <TAB>  <TAB>  <TAB> and tokens[i] == (""op"", ""."") <TAB>  <TAB>  <TAB> and tokens[i + 1][0] == ""id"" <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> token += ""."" + tokens[i + 1][1] <TAB>  <TAB>  <TAB> i += 2 <MASK> continue <TAB>  <TAB> if token in pykeywords: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if token[0] in "".0123456789"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> yield token","if token == """" :",194
890,"def create_config_filepath(cls, visibility=None): <TAB> if cls.is_local(visibility): <TAB>  <TAB> # Local to this directory <TAB>  <TAB> base_path = os.path.join(""."") <MASK> # Add it to the current ""./.polyaxon"" <TAB>  <TAB>  <TAB> base_path = os.path.join(base_path, "".polyaxon"") <TAB>  <TAB>  <TAB> cls._create_dir(base_path) <TAB> elif cls.CONFIG_PATH:  # Custom path <TAB>  <TAB> pass <TAB> else:  # Handle both global and all cases <TAB>  <TAB> base_path = polyaxon_user_path() <TAB>  <TAB> cls._create_dir(base_path)",if cls . IS_POLYAXON_DIR :,170
891,"def test_len(self): <TAB> eq = self.assertEqual <TAB> eq(base64MIME.base64_len(""hello""), len(base64MIME.encode(""hello"", eol=""""))) <TAB> for size in range(15): <TAB>  <TAB> if size == 0: <TAB>  <TAB>  <TAB> bsize = 0 <MASK> bsize = 4 <TAB>  <TAB> elif size <= 6: <TAB>  <TAB>  <TAB> bsize = 8 <TAB>  <TAB> elif size <= 9: <TAB>  <TAB>  <TAB> bsize = 12 <TAB>  <TAB> elif size <= 12: <TAB>  <TAB>  <TAB> bsize = 16 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> bsize = 20 <TAB>  <TAB> eq(base64MIME.base64_len(""x"" * size), bsize)",elif size <= 3 :,160
892,"def as_dict(path="""", version=""latest"", section=""meta-data""): <TAB> result = {} <TAB> dirs = dir(path, version, section) <TAB> if not dirs: <TAB>  <TAB> return None <TAB> for item in dirs: <MASK> records = as_dict(path + item, version, section) <TAB>  <TAB>  <TAB> if records: <TAB>  <TAB>  <TAB>  <TAB> result[item[:-1]] = records <TAB>  <TAB> elif is_dict.match(item): <TAB>  <TAB>  <TAB> idx, name = is_dict.match(item).groups() <TAB>  <TAB>  <TAB> records = as_dict(path + idx + ""/"", version, section) <TAB>  <TAB>  <TAB> if records: <TAB>  <TAB>  <TAB>  <TAB> result[name] = records <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result[item] = valueconv(get(path + item, version, section)) <TAB> return result","if item . endswith ( ""/"" ) :",197
893,"def api_read(self): <TAB> result = {} <TAB> files = [""my.cnf"", ""debian.cnf""] <TAB> directory_list = self.exec_payload(""mysql_config_directory"")[""directory""] <TAB> for _file in files: <TAB>  <TAB> for directory in directory_list: <TAB>  <TAB>  <TAB> mysql_conf = directory + _file <TAB>  <TAB>  <TAB> content = self.shell.read(mysql_conf) <MASK> result[mysql_conf] = content <TAB> return result",if content :,118
894,"def generate(self, count=100): <TAB> self.pre_generate() <TAB> counter = iter(range(count)) <TAB> created = 0 <TAB> while True: <TAB>  <TAB> batch = list(islice(counter, self.batch_size)) <MASK> break <TAB>  <TAB> self.do_generate(batch, self.batch_size) <TAB>  <TAB> from_size = created <TAB>  <TAB> created += len(batch) <TAB>  <TAB> print(""Generate %s: %s-%s"" % (self.resource, from_size, created)) <TAB> self.after_generate()",if not batch :,135
895,"def _normalize_fields(self, document, loader): <TAB> # type: (Dict[Text, Text], Loader) -> None <TAB> # Normalize fields which are prefixed or full URIn to vocabulary terms <TAB> for d in list(document.keys()): <TAB>  <TAB> d2 = loader.expand_url(d, u"""", scoped_id=False, vocab_term=True) <MASK> document[d2] = document[d] <TAB>  <TAB>  <TAB> del document[d]",if d != d2 :,115
896,"def load_cache(filename, get_key=mangle_key): <TAB> cache = {} <TAB> if not os.path.exists(filename): <TAB>  <TAB> return cache <TAB> f = open(filename, ""rb"") <TAB> l = 0 <TAB> for line in f.readlines(): <TAB>  <TAB> l += 1 <TAB>  <TAB> fields = line.split(b"" "") <MASK> sys.stderr.write(""Invalid file format in [%s], line %d\n"" % (filename, l)) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # put key:value in cache, key without ^: <TAB>  <TAB> cache[get_key(fields[0][1:])] = fields[1].split(b""\n"")[0] <TAB> f.close() <TAB> return cache","if fields == None or not len ( fields ) == 2 or fields [ 0 ] [ 0 : 1 ] != b"":"" :",197
897,"def __lshift__(self, other): <TAB> if not self.symbolic and type(other) is int: <TAB>  <TAB> return RegisterOffset( <TAB>  <TAB>  <TAB> self._bits, self.reg, self._to_signed(self.offset << other) <TAB>  <TAB> ) <TAB> else: <MASK> return RegisterOffset(self._bits, self.reg, self.offset << other) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return RegisterOffset( <TAB>  <TAB>  <TAB>  <TAB> self._bits, <TAB>  <TAB>  <TAB>  <TAB> self.reg, <TAB>  <TAB>  <TAB>  <TAB> ArithmeticExpression( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ArithmeticExpression.LShift, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.offset, <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> other, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB> )",if self . symbolic :,192
898,"def SaveSettings(self, force=False): <TAB> if self.config is not None: <TAB>  <TAB> frame.ShellFrameMixin.SaveSettings(self) <MASK> frame.Frame.SaveSettings(self, self.config) <TAB>  <TAB>  <TAB> self.shell.SaveSettings(self.config)",if self . autoSaveSettings or force :,79
899,"def _parse_gene(element): <TAB> for genename_element in element: <TAB>  <TAB> if ""type"" in genename_element.attrib: <TAB>  <TAB>  <TAB> ann_key = ""gene_%s_%s"" % ( <TAB>  <TAB>  <TAB>  <TAB> genename_element.tag.replace(NS, """"), <TAB>  <TAB>  <TAB>  <TAB> genename_element.attrib[""type""], <TAB>  <TAB>  <TAB> ) <MASK> self.ParsedSeqRecord.annotations[ann_key] = genename_element.text <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> append_to_annotations(ann_key, genename_element.text)","if genename_element . attrib [ ""type"" ] == ""primary"" :",157
900,"def _write_pkg_file(self, file): <TAB> with TemporaryFile(mode=""w+"") as tmpfd: <TAB>  <TAB> _write_pkg_file_orig(self, tmpfd) <TAB>  <TAB> tmpfd.seek(0) <TAB>  <TAB> for line in tmpfd: <MASK> file.write(""Metadata-Version: 2.1\n"") <TAB>  <TAB>  <TAB> elif line.startswith(""Description: ""): <TAB>  <TAB>  <TAB>  <TAB> file.write( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Description-Content-Type: %s; charset=UTF-8\n"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> % long_description_content_type <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> file.write(line) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> file.write(line)","if line . startswith ( ""Metadata-Version: "" ) :",188
901,"def get(self): <TAB> """"""If a value/an exception is stored, return/raise it. Otherwise until switch() or throw() is called."""""" <TAB> if self._exception is not _NONE: <MASK> return self.value <TAB>  <TAB> getcurrent().throw(*self._exception)  # pylint:disable=undefined-variable <TAB> else: <TAB>  <TAB> if self.greenlet is not None: <TAB>  <TAB>  <TAB> raise ConcurrentObjectUseError( <TAB>  <TAB>  <TAB>  <TAB> ""This Waiter is already used by %r"" % (self.greenlet,) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self.greenlet = getcurrent()  # pylint:disable=undefined-variable <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self.hub.switch() <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self.greenlet = None",if self . _exception is None :,188
902,"def connect(self, *args): <TAB> """"""connects to the dropbox. args[0] is the username."""""" <TAB> if len(args) != 1: <TAB>  <TAB> return ""expected one argument!"" <TAB> try: <TAB>  <TAB> dbci = get_dropbox_client(args[0], False, None, None) <TAB> except Exception as e: <TAB>  <TAB> return e.message <TAB> else: <MASK> return ""No Dropbox configured for '{u}'."".format(u=args[0]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.client = dbci <TAB>  <TAB> return True",if dbci is None :,142
903,"def escape(text, newline=False): <TAB> """"""Escape special html characters."""""" <TAB> if isinstance(text, str): <TAB>  <TAB> if ""&"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""&"", ""&amp;"") <TAB>  <TAB> if "">"" in text: <TAB>  <TAB>  <TAB> text = text.replace("">"", ""&gt;"") <TAB>  <TAB> if ""<"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""<"", ""&lt;"") <TAB>  <TAB> if '""' in text: <TAB>  <TAB>  <TAB> text = text.replace('""', ""&quot;"") <TAB>  <TAB> if ""'"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""'"", ""&quot;"") <TAB>  <TAB> if newline: <MASK> text = text.replace(""\n"", ""<br>"") <TAB> return text","if ""\n"" in text :",170
904,def t(ret): <TAB> with IPDB() as ipdb: <TAB>  <TAB> with ipdb.eventqueue() as evq: <TAB>  <TAB>  <TAB> for msg in evq: <MASK> ret.append(msg) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return,"if msg . get_attr ( ""IFLA_IFNAME"" ) == ""test1984"" :",83
905,"def check_stmt(self, stmt): <TAB> if is_future(stmt): <TAB>  <TAB> for name, asname in stmt.names: <MASK> self.found[name] = 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise SyntaxError(""future feature %s is not defined"" % name) <TAB>  <TAB> stmt.valid_future = 1 <TAB>  <TAB> return 1 <TAB> return 0",if name in self . features :,99
906,"def process_pypi_option(option, option_str, option_value, parser): <TAB> if option_str.startswith(""--no""): <TAB>  <TAB> setattr(parser.values, option.dest, []) <TAB> else: <TAB>  <TAB> indexes = getattr(parser.values, option.dest, []) <MASK> indexes.append(_PYPI) <TAB>  <TAB> setattr(parser.values, option.dest, indexes)",if _PYPI not in indexes :,102
907,"def modify_address(self, name, address, domain): <TAB> if not self.get_entries_by_name(name, domain): <TAB>  <TAB> raise exception.NotFound <TAB> infile = open(self.filename, ""r"") <TAB> outfile = tempfile.NamedTemporaryFile(""w"", delete=False) <TAB> for line in infile: <TAB>  <TAB> entry = self.parse_line(line) <MASK> outfile.write( <TAB>  <TAB>  <TAB>  <TAB> ""%s   %s   %s\n"" % (address, self.qualify(name, domain), entry[""type""]) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> outfile.write(line) <TAB> infile.close() <TAB> outfile.close() <TAB> shutil.move(outfile.name, self.filename)","if entry and entry [ ""name"" ] . lower ( ) == self . qualify ( name , domain ) . lower ( ) :",197
908,"def tms_to_quadkey(self, tms, google=False): <TAB> quadKey = """" <TAB> x, y, z = tms <TAB> # this algorithm works with google tiles, rather than tms, so convert <TAB> # to those first. <TAB> if not google: <TAB>  <TAB> y = (2 ** z - 1) - y <TAB> for i in range(z, 0, -1): <TAB>  <TAB> digit = 0 <TAB>  <TAB> mask = 1 << (i - 1) <TAB>  <TAB> if (x & mask) != 0: <TAB>  <TAB>  <TAB> digit += 1 <MASK> digit += 2 <TAB>  <TAB> quadKey += str(digit) <TAB> return quadKey",if ( y & mask ) != 0 :,164
909,"def add_if_unique(self, issuer, use, keys): <TAB> if use in self.issuer_keys[issuer] and self.issuer_keys[issuer][use]: <TAB>  <TAB> for typ, key in keys: <TAB>  <TAB>  <TAB> flag = 1 <TAB>  <TAB>  <TAB> for _typ, _key in self.issuer_keys[issuer][use]: <TAB>  <TAB>  <TAB>  <TAB> if _typ == typ and key is _key: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> flag = 0 <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <MASK> self.issuer_keys[issuer][use].append((typ, key)) <TAB> else: <TAB>  <TAB> self.issuer_keys[issuer][use] = keys",if flag :,158
910,"def scan_error(self): <TAB> ""A string describing why the last scan failed, or None if it didn't."" <TAB> self.acquire_lock() <TAB> try: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> self._load_buf_data_once() <TAB>  <TAB>  <TAB> except NotFoundInDatabase: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> return self._scan_error_cache <TAB> finally: <TAB>  <TAB> self.release_lock()",if self . _scan_error_cache is None :,114
911,"def _query(self): <TAB> if self._mongo_query is None: <TAB>  <TAB> self._mongo_query = self._query_obj.to_query(self._document) <MASK> if ""_cls"" in self._mongo_query: <TAB>  <TAB>  <TAB>  <TAB> self._mongo_query = {""$and"": [self._cls_query, self._mongo_query]} <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._mongo_query.update(self._cls_query) <TAB> return self._mongo_query",if self . _cls_query :,127
912,"def CountButtons(self): <TAB> """"""Returns the number of visible buttons in the docked pane."""""" <TAB> n = 0 <TAB> if self.HasCaption() or self.HasCaptionLeft(): <TAB>  <TAB> if isinstance(wx.GetTopLevelParent(self.window), AuiFloatingFrame): <TAB>  <TAB>  <TAB> return 1 <TAB>  <TAB> if self.HasCloseButton(): <TAB>  <TAB>  <TAB> n += 1 <TAB>  <TAB> if self.HasMaximizeButton(): <TAB>  <TAB>  <TAB> n += 1 <TAB>  <TAB> if self.HasMinimizeButton(): <TAB>  <TAB>  <TAB> n += 1 <MASK> n += 1 <TAB> return n",if self . HasPinButton ( ) :,149
913,"def testBind(self): <TAB> try: <TAB>  <TAB> with socket.socket(socket.PF_CAN, socket.SOCK_DGRAM, socket.CAN_J1939) as s: <TAB>  <TAB>  <TAB> addr = ( <TAB>  <TAB>  <TAB>  <TAB> self.interface, <TAB>  <TAB>  <TAB>  <TAB> socket.J1939_NO_NAME, <TAB>  <TAB>  <TAB>  <TAB> socket.J1939_NO_PGN, <TAB>  <TAB>  <TAB>  <TAB> socket.J1939_NO_ADDR, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> s.bind(addr) <TAB>  <TAB>  <TAB> self.assertEqual(s.getsockname(), addr) <TAB> except OSError as e: <MASK> self.skipTest(""network interface `%s` does not exist"" % self.interface) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise",if e . errno == errno . ENODEV :,189
914,"def createFields(self): <TAB> while self.current_size < self.size: <TAB>  <TAB> pos = self.stream.searchBytes( <TAB>  <TAB>  <TAB> ""\0\0\1"", self.current_size, self.current_size + 1024 * 1024 * 8 <TAB>  <TAB> )  # seek forward by at most 1MB <TAB>  <TAB> if pos is not None: <TAB>  <TAB>  <TAB> padsize = pos - self.current_size <MASK> yield PaddingBytes(self, ""pad[]"", padsize // 8) <TAB>  <TAB> chunk = Chunk(self, ""chunk[]"") <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> # force chunk to be processed, so that CustomFragments are complete <TAB>  <TAB>  <TAB> chunk[""content/data""] <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> yield chunk",if padsize :,184
915,"def index_modulemd_files(repo_path): <TAB> merger = Modulemd.ModuleIndexMerger() <TAB> for fn in sorted(os.listdir(repo_path)): <MASK> continue <TAB>  <TAB> yaml_path = os.path.join(repo_path, fn) <TAB>  <TAB> mmd = Modulemd.ModuleIndex() <TAB>  <TAB> mmd.update_from_file(yaml_path, strict=True) <TAB>  <TAB> merger.associate_index(mmd, 0) <TAB> return merger.resolve()","if not fn . endswith ( "".yaml"" ) :",129
916,"def set_visible(self, visible=True): <TAB> self._visible = visible <TAB> if self._nswindow is not None: <MASK> # Not really sure why on_resize needs to be here, <TAB>  <TAB>  <TAB> # but it's what pyglet wants. <TAB>  <TAB>  <TAB> self.dispatch_event(""on_resize"", self._width, self._height) <TAB>  <TAB>  <TAB> self.dispatch_event(""on_show"") <TAB>  <TAB>  <TAB> self.dispatch_event(""on_expose"") <TAB>  <TAB>  <TAB> self._nswindow.makeKeyAndOrderFront_(None) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._nswindow.orderOut_(None)",if visible :,153
917,"def __repr__(self): <TAB> if self._in_repr: <TAB>  <TAB> return ""<recursion>"" <TAB> try: <TAB>  <TAB> self._in_repr = True <TAB>  <TAB> if self.is_computed(): <TAB>  <TAB>  <TAB> status = ""computed, "" <TAB>  <TAB>  <TAB> if self.error() is None: <MASK> status += ""= self"" <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> status += ""= "" + repr(self.value()) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> status += ""error = "" + repr(self.error()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> status = ""isn't computed"" <TAB>  <TAB> return ""%s (%s)"" % (type(self), status) <TAB> finally: <TAB>  <TAB> self._in_repr = False",if self . value ( ) is self :,189
918,"def _individual_get(self, segment, index_type, index, strictdoc): <TAB> if index_type == ""val"": <TAB>  <TAB> for key, value in segment.items(): <TAB>  <TAB>  <TAB> if key == index[0]: <TAB>  <TAB>  <TAB>  <TAB> return value <MASK> if key.text == index[0]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return value <TAB>  <TAB> raise Exception(""Invalid state"") <TAB> elif index_type == ""index"": <TAB>  <TAB> return segment[index] <TAB> elif index_type == ""textslice"": <TAB>  <TAB> return segment[index[0] : index[1]] <TAB> elif index_type == ""key"": <TAB>  <TAB> return index[1] if strictdoc else index[0] <TAB> else: <TAB>  <TAB> raise Exception(""Invalid state"")","if hasattr ( key , ""text"" ) :",186
919,"def _makeSafeAbsoluteURI(base, rel=None): <TAB> # bail if ACCEPTABLE_URI_SCHEMES is empty <TAB> if not ACCEPTABLE_URI_SCHEMES: <TAB>  <TAB> return _urljoin(base, rel or u"""") <TAB> if not base: <TAB>  <TAB> return rel or u"""" <TAB> if not rel: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> scheme = urlparse.urlparse(base)[0] <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> return u"""" <MASK> return base <TAB>  <TAB> return u"""" <TAB> uri = _urljoin(base, rel) <TAB> if uri.strip().split("":"", 1)[0] not in ACCEPTABLE_URI_SCHEMES: <TAB>  <TAB> return u"""" <TAB> return uri",if not scheme or scheme in ACCEPTABLE_URI_SCHEMES :,186
920,"def _write_packet(self, packet): <TAB> # Immediately writes the given packet to the network. The caller must <TAB> # have the write lock acquired before calling this method. <TAB> try: <TAB>  <TAB> for listener in self.early_outgoing_packet_listeners: <TAB>  <TAB>  <TAB> listener.call_packet(packet) <MASK> packet.write(self.socket, self.options.compression_threshold) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> packet.write(self.socket) <TAB>  <TAB> for listener in self.outgoing_packet_listeners: <TAB>  <TAB>  <TAB> listener.call_packet(packet) <TAB> except IgnorePacket: <TAB>  <TAB> pass",if self . options . compression_enabled :,160
921,"def rangelist_to_set(rangelist): <TAB> result = set() <TAB> if not rangelist: <TAB>  <TAB> return result <TAB> for x in rangelist.split("",""): <MASK> result.add(int(x)) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> m = re.match(r""^(\d+)-(\d+)$"", x) <TAB>  <TAB> if m: <TAB>  <TAB>  <TAB> start = int(m.group(1)) <TAB>  <TAB>  <TAB> end = int(m.group(2)) <TAB>  <TAB>  <TAB> result.update(set(range(start, end + 1))) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> msg = ""Cannot understand data input: %s %s"" % (x, rangelist) <TAB>  <TAB> raise ValueError(msg) <TAB> return result","if re . match ( r""^(\d+)$"" , x ) :",181
922,"def test_device_property_logfile_isinstance(self): <TAB> mock = MagicMock() <TAB> with patch(builtin_string + "".open"", mock): <MASK> builtin_file = ""io.TextIOWrapper"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> builtin_file = builtin_string + "".file"" <TAB>  <TAB> with patch(builtin_file, MagicMock): <TAB>  <TAB>  <TAB> handle = open(""filename"", ""r"") <TAB>  <TAB>  <TAB> self.dev.logfile = handle <TAB>  <TAB>  <TAB> self.assertEqual(self.dev.logfile, handle)","if sys . version > ""3"" :",130
923,"def _line_ranges(statements, lines): <TAB> """"""Produce a list of ranges for `format_lines`."""""" <TAB> statements = sorted(statements) <TAB> lines = sorted(lines) <TAB> pairs = [] <TAB> start = None <TAB> lidx = 0 <TAB> for stmt in statements: <TAB>  <TAB> if lidx >= len(lines): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if stmt == lines[lidx]: <TAB>  <TAB>  <TAB> lidx += 1 <TAB>  <TAB>  <TAB> if not start: <TAB>  <TAB>  <TAB>  <TAB> start = stmt <TAB>  <TAB>  <TAB> end = stmt <MASK> pairs.append((start, end)) <TAB>  <TAB>  <TAB> start = None <TAB> if start: <TAB>  <TAB> pairs.append((start, end)) <TAB> return pairs",elif start :,167
924,"def reset_parameters(self): <TAB> initialize = layers.get_initializer(self._hparams.initializer) <TAB> if initialize is not None: <TAB>  <TAB> # Do not re-initialize LayerNorm modules. <TAB>  <TAB> for name, param in self.named_parameters(): <MASK> initialize(param)","if name . split ( ""."" ) [ - 1 ] == ""weight"" and ""layer_norm"" not in name :",93
925,"def billing_invoice_show_validator(namespace): <TAB> from azure.cli.core.azclierror import ( <TAB>  <TAB> RequiredArgumentMissingError, <TAB>  <TAB> MutuallyExclusiveArgumentError, <TAB> ) <TAB> valid_combs = ( <TAB>  <TAB> ""only --account-name, --name / --name / --name, --by-subscription is valid"" <TAB> ) <TAB> if namespace.account_name is not None: <TAB>  <TAB> if namespace.by_subscription is not None: <TAB>  <TAB>  <TAB> raise MutuallyExclusiveArgumentError(valid_combs) <MASK> raise RequiredArgumentMissingError(""--name is also required"") <TAB> if namespace.by_subscription is not None: <TAB>  <TAB> if namespace.name is None: <TAB>  <TAB>  <TAB> raise RequiredArgumentMissingError(""--name is also required"")",if namespace . name is None :,188
926,"def DeleteDocuments(self, document_ids, response): <TAB> """"""Deletes documents for the given document_ids."""""" <TAB> for document_id in document_ids: <MASK> document = self._documents[document_id] <TAB>  <TAB>  <TAB> self._inverted_index.RemoveDocument(document) <TAB>  <TAB>  <TAB> del self._documents[document_id] <TAB>  <TAB> delete_status = response.add_status() <TAB>  <TAB> delete_status.set_code(search_service_pb.SearchServiceError.OK)",if document_id in self . _documents :,125
927,"def generate_new_element(items, prefix, numeric=False): <TAB> """"""Creates a random string with prefix, that is not in 'items' list."""""" <TAB> while True: <MASK> candidate = prefix + generate_random_numeric(8) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> candidate = prefix + generate_random_alphanumeric(8) <TAB>  <TAB> if not candidate in items: <TAB>  <TAB>  <TAB> return candidate <TAB>  <TAB> LOG.debug(""Random collision on %s"" % candidate)",if numeric :,115
928,"def generate_text_for_vocab(self, data_dir, tmp_dir): <TAB> for i, sample in enumerate( <TAB>  <TAB> self.generate_samples(data_dir, tmp_dir, problem.DatasetSplit.TRAIN) <TAB> ): <TAB>  <TAB> if self.has_inputs: <TAB>  <TAB>  <TAB> yield sample[""inputs""] <TAB>  <TAB> yield sample[""targets""] <MASK> break",if self . max_samples_for_vocab and ( i + 1 ) >= self . max_samples_for_vocab :,118
929,"def _get_ccp(config=None, config_path=None, saltenv=""base""): <TAB> """""" """""" <TAB> if config_path: <TAB>  <TAB> config = __salt__[""cp.get_file_str""](config_path, saltenv=saltenv) <MASK> raise SaltException(""{} is not available"".format(config_path)) <TAB> if isinstance(config, six.string_types): <TAB>  <TAB> config = config.splitlines() <TAB> ccp = ciscoconfparse.CiscoConfParse(config) <TAB> return ccp",if config is False :,135
930,"def rpush(key, *vals, **kwargs): <TAB> ttl = kwargs.get(""ttl"") <TAB> cap = kwargs.get(""cap"") <TAB> if not ttl and not cap: <TAB>  <TAB> _client.rpush(key, *vals) <TAB> else: <TAB>  <TAB> pipe = _client.pipeline() <TAB>  <TAB> pipe.rpush(key, *vals) <MASK> pipe.ltrim(key, 0, cap) <TAB>  <TAB> if ttl: <TAB>  <TAB>  <TAB> pipe.expire(key, ttl) <TAB>  <TAB> pipe.execute()",if cap :,131
931,"def check_apns_certificate(ss): <TAB> mode = ""start"" <TAB> for s in ss.split(""\n""): <MASK> if ""BEGIN RSA PRIVATE KEY"" in s or ""BEGIN PRIVATE KEY"" in s: <TAB>  <TAB>  <TAB>  <TAB> mode = ""key"" <TAB>  <TAB> elif mode == ""key"": <TAB>  <TAB>  <TAB> if ""END RSA PRIVATE KEY"" in s or ""END PRIVATE KEY"" in s: <TAB>  <TAB>  <TAB>  <TAB> mode = ""end"" <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> elif s.startswith(""Proc-Type"") and ""ENCRYPTED"" in s: <TAB>  <TAB>  <TAB>  <TAB> raise ImproperlyConfigured( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Encrypted APNS private keys are not supported"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> if mode != ""end"": <TAB>  <TAB> raise ImproperlyConfigured(""The APNS certificate doesn't contain a private key"")","if mode == ""start"" :",195
932,"def _add_communication_type(apps, schema_editor, communication_type): <TAB> Worker = apps.get_model(""orchestra"", ""Worker"") <TAB> CommunicationPreference = apps.get_model(""orchestra"", ""CommunicationPreference"") <TAB> for worker in Worker.objects.all(): <TAB>  <TAB> ( <TAB>  <TAB>  <TAB> communication_preference, <TAB>  <TAB>  <TAB> created, <TAB>  <TAB> ) = CommunicationPreference.objects.get_or_create( <TAB>  <TAB>  <TAB> worker=worker, communication_type=communication_type <TAB>  <TAB> ) <TAB>  <TAB> # By default set both Slack and Email notifications to True <MASK> communication_preference.methods.slack = True <TAB>  <TAB>  <TAB> communication_preference.methods.email = True <TAB>  <TAB> communication_preference.save()",if created :,183
933,"def get_postgresql_driver_name(): <TAB> # pylint: disable=unused-variable <TAB> try: <TAB>  <TAB> driver = os.getenv(""CODECHECKER_DB_DRIVER"") <MASK> return driver <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> # pylint: disable=W0611 <TAB>  <TAB>  <TAB> import psycopg2 <TAB>  <TAB>  <TAB> return ""psycopg2"" <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> # pylint: disable=W0611 <TAB>  <TAB>  <TAB> import pg8000 <TAB>  <TAB>  <TAB> return ""pg8000"" <TAB> except Exception as ex: <TAB>  <TAB> LOG.error(str(ex)) <TAB>  <TAB> LOG.error(""Failed to import psycopg2 or pg8000 module."") <TAB>  <TAB> raise",if driver :,157
934,"def env_purge_doc(app: Sphinx, env: BuildEnvironment, docname: str) -> None: <TAB> modules = getattr(env, ""_viewcode_modules"", {}) <TAB> for modname, entry in list(modules.items()): <TAB>  <TAB> if entry is False: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> code, tags, used, refname = entry <TAB>  <TAB> for fullname in list(used): <TAB>  <TAB>  <TAB> if used[fullname] == docname: <TAB>  <TAB>  <TAB>  <TAB> used.pop(fullname) <MASK> modules.pop(modname)",if len ( used ) == 0 :,133
935,"def do_query(data, q): <TAB> ret = [] <TAB> if not q: <TAB>  <TAB> return ret <TAB> qkey = q[0] <TAB> for key, value in iterate(data): <TAB>  <TAB> if len(q) == 1: <TAB>  <TAB>  <TAB> if key == qkey: <TAB>  <TAB>  <TAB>  <TAB> ret.append(value) <TAB>  <TAB>  <TAB> elif is_iterable(value): <TAB>  <TAB>  <TAB>  <TAB> ret.extend(do_query(value, q)) <TAB>  <TAB> else: <MASK> continue <TAB>  <TAB>  <TAB> if key == qkey: <TAB>  <TAB>  <TAB>  <TAB> ret.extend(do_query(value, q[1:])) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> ret.extend(do_query(value, q)) <TAB> return ret",if not is_iterable ( value ) :,185
936,"def _get_bucket_for_key(self, key: bytes) -> Optional[_DBValueTuple]: <TAB> dbs: Iterable[PartitionDB] <TAB> try: <TAB>  <TAB> partition = self._key_index[key] <TAB>  <TAB> dbs = [PartitionDB(partition, self._dbs[partition])] <TAB> except KeyError: <TAB>  <TAB> dbs = cast(Iterable[PartitionDB], self._dbs.items()) <TAB> for partition, db in dbs: <TAB>  <TAB> if db.key_may_exist(key)[0]: <TAB>  <TAB>  <TAB> value = db.get(key) <MASK> self._key_index[key] = partition <TAB>  <TAB>  <TAB>  <TAB> return _DBValueTuple(db, value) <TAB> return None",if value is not None :,177
937,"def _clean(self): <TAB> logger.info(""Cleaning up..."") <TAB> if self._process is not None: <TAB>  <TAB> if self._process.poll() is None: <TAB>  <TAB>  <TAB> for _ in range(3): <TAB>  <TAB>  <TAB>  <TAB> self._process.terminate() <TAB>  <TAB>  <TAB>  <TAB> time.sleep(0.5) <MASK> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._process.kill() <TAB>  <TAB>  <TAB>  <TAB> self._process.wait() <TAB>  <TAB>  <TAB>  <TAB> logger.error(""KILLED"") <TAB> if os.path.exists(self._tmp_dir): <TAB>  <TAB> shutil.rmtree(self._tmp_dir) <TAB> self._process = None <TAB> self._ws = None <TAB> logger.info(""Cleanup complete"")",if self . _process . poll ( ) is not None :,189
938,"def _calculate_runtimes(states): <TAB> results = {""runtime"": 0.00, ""num_failed_states"": 0, ""num_passed_states"": 0} <TAB> for state, resultset in states.items(): <TAB>  <TAB> if isinstance(resultset, dict) and ""duration"" in resultset: <TAB>  <TAB>  <TAB> # Count the pass vs failures <MASK> results[""num_passed_states""] += 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> results[""num_failed_states""] += 1 <TAB>  <TAB>  <TAB> # Count durations <TAB>  <TAB>  <TAB> results[""runtime""] += resultset[""duration""] <TAB> log.debug(""Parsed state metrics: {}"".format(results)) <TAB> return results","if resultset [ ""result"" ] :",167
939,"def spaces_after(token, prev, next, min=-1, max=-1, min_desc=None, max_desc=None): <TAB> if next is not None and token.end_mark.line == next.start_mark.line: <TAB>  <TAB> spaces = next.start_mark.pointer - token.end_mark.pointer <TAB>  <TAB> if max != -1 and spaces > max: <TAB>  <TAB>  <TAB> return LintProblem( <TAB>  <TAB>  <TAB>  <TAB> token.start_mark.line + 1, next.start_mark.column, max_desc <TAB>  <TAB>  <TAB> ) <MASK> return LintProblem( <TAB>  <TAB>  <TAB>  <TAB> token.start_mark.line + 1, next.start_mark.column + 1, min_desc <TAB>  <TAB>  <TAB> )",elif min != - 1 and spaces < min :,184
940,"def getfileinfo(name): <TAB> finfo = FInfo() <TAB> with io.open(name, ""rb"") as fp: <TAB>  <TAB> # Quick check for textfile <TAB>  <TAB> data = fp.read(512) <MASK> finfo.Type = ""TEXT"" <TAB>  <TAB> fp.seek(0, 2) <TAB>  <TAB> dsize = fp.tell() <TAB> dir, file = os.path.split(name) <TAB> file = file.replace("":"", ""-"", 1) <TAB> return file, finfo, dsize, 0",if 0 not in data :,124
941,"def dict_to_XML(tag, dictionary, **kwargs): <TAB> """"""Return XML element converting dicts recursively."""""" <TAB> elem = Element(tag, **kwargs) <TAB> for key, val in dictionary.items(): <TAB>  <TAB> if tag == ""layers"": <TAB>  <TAB>  <TAB> child = dict_to_XML(""layer"", val, name=key) <MASK> child = dict_to_XML(key, val) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if tag == ""config"": <TAB>  <TAB>  <TAB>  <TAB> child = Element(""variable"", name=key) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> child = Element(key) <TAB>  <TAB>  <TAB> child.text = str(val) <TAB>  <TAB> elem.append(child) <TAB> return elem","elif isinstance ( val , MutableMapping ) :",175
942,"def _read_bytes(self, length): <TAB> buffer = b"""" <TAB> while length: <TAB>  <TAB> chunk = self.request.recv(length) <MASK> log.debug(""Connection closed"") <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> length -= len(chunk) <TAB>  <TAB> buffer += chunk <TAB> return buffer","if chunk == b"""" :",79
943,"def rec_deps(services, container_by_name, cnt, init_service): <TAB> deps = cnt[""_deps""] <TAB> for dep in deps.copy(): <TAB>  <TAB> dep_cnts = services.get(dep) <MASK> continue <TAB>  <TAB> dep_cnt = container_by_name.get(dep_cnts[0]) <TAB>  <TAB> if dep_cnt: <TAB>  <TAB>  <TAB> # TODO: avoid creating loops, A->B->A <TAB>  <TAB>  <TAB> if init_service and init_service in dep_cnt[""_deps""]: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> new_deps = rec_deps(services, container_by_name, dep_cnt, init_service) <TAB>  <TAB>  <TAB> deps.update(new_deps) <TAB> return deps",if not dep_cnts :,181
944,"def fix_repeating_arguments(self): <TAB> """"""Fix elements that should accumulate/increment values."""""" <TAB> either = [list(child.children) for child in transform(self).children] <TAB> for case in either: <TAB>  <TAB> for e in [child for child in case if case.count(child) > 1]: <MASK> if e.value is None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> e.value = [] <TAB>  <TAB>  <TAB>  <TAB> elif type(e.value) is not list: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> e.value = e.value.split() <TAB>  <TAB>  <TAB> if type(e) is Command or type(e) is Option and e.argcount == 0: <TAB>  <TAB>  <TAB>  <TAB> e.value = 0 <TAB> return self",if type ( e ) is Argument or type ( e ) is Option and e . argcount :,190
945,"def do_cli(manager, options): <TAB> header = [""Name"", ""Description""] <TAB> table_data = [header] <TAB> for filter_name, filter in get_filters(): <MASK> continue <TAB>  <TAB> filter_doc = inspect.getdoc(filter) or """" <TAB>  <TAB> table_data.append([filter_name, filter_doc]) <TAB> try: <TAB>  <TAB> table = TerminalTable(options.table_type, table_data) <TAB> except TerminalTableError as e: <TAB>  <TAB> console(""ERROR: %s"" % str(e)) <TAB> else: <TAB>  <TAB> console(table.output)",if options . name and not options . name in filter_name :,155
946,"def _do_cmp(f1, f2): <TAB> bufsize = BUFSIZE <TAB> with open(f1, ""rb"") as fp1, open(f2, ""rb"") as fp2: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> b1 = fp1.read(bufsize) <TAB>  <TAB>  <TAB> b2 = fp2.read(bufsize) <TAB>  <TAB>  <TAB> if b1 != b2: <TAB>  <TAB>  <TAB>  <TAB> return False <MASK> return True",if not b1 :,118
947,"def apply(self, db, person): <TAB> families = person.get_parent_family_handle_list() <TAB> if families == []: <TAB>  <TAB> return True <TAB> for family_handle in person.get_parent_family_handle_list(): <TAB>  <TAB> family = db.get_family_from_handle(family_handle) <TAB>  <TAB> if family: <TAB>  <TAB>  <TAB> father_handle = family.get_father_handle() <TAB>  <TAB>  <TAB> mother_handle = family.get_mother_handle() <MASK> return True <TAB>  <TAB>  <TAB> if not mother_handle: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if not father_handle :,157
948,"def caesar_cipher(s, k): <TAB> result = """" <TAB> for char in s: <TAB>  <TAB> n = ord(char) <TAB>  <TAB> if 64 < n < 91: <TAB>  <TAB>  <TAB> n = ((n - 65 + k) % 26) + 65 <MASK> n = ((n - 97 + k) % 26) + 97 <TAB>  <TAB> result = result + chr(n) <TAB> return result",if 96 < n < 123 :,104
949,"def title_by_index(self, trans, index, context): <TAB> d_type = self.get_datatype(trans, context) <TAB> for i, (composite_name, composite_file) in enumerate(d_type.writable_files.items()): <TAB>  <TAB> if i == index: <TAB>  <TAB>  <TAB> rval = composite_name <TAB>  <TAB>  <TAB> if composite_file.description: <TAB>  <TAB>  <TAB>  <TAB> rval = ""{} ({})"".format(rval, composite_file.description) <MASK> rval = ""%s [optional]"" % rval <TAB>  <TAB>  <TAB> return rval <TAB> if index < self.get_file_count(trans, context): <TAB>  <TAB> return ""Extra primary file"" <TAB> return None",if composite_file . optional :,167
950,"def __str__(self): <TAB> t = "" <TAB> "" <TAB> if self._name != ""root"": <TAB>  <TAB> r = f""{t * (self._level-1)}{self._name}:\n"" <TAB> else: <TAB>  <TAB> r = """" <TAB> level = self._level <TAB> for i, (k, v) in enumerate(self._pointer.items()): <MASK> r += f""{t * (self._level)}{v}\n"" <TAB>  <TAB>  <TAB> self._level += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> r += f""{t * (self._level)}{k}: {v} ({type(v).__name__})\n"" <TAB>  <TAB> self._level = level <TAB> return r[:-1]","if isinstance ( v , Config ) :",176
951,"def __get_securitygroups(vm_): <TAB> vm_securitygroups = config.get_cloud_config_value( <TAB>  <TAB> ""securitygroups"", vm_, __opts__, search_global=False <TAB> ) <TAB> if not vm_securitygroups: <TAB>  <TAB> return [] <TAB> securitygroups = list_securitygroups() <TAB> for i in range(len(vm_securitygroups)): <TAB>  <TAB> vm_securitygroups[i] = six.text_type(vm_securitygroups[i]) <MASK> raise SaltCloudNotFound( <TAB>  <TAB>  <TAB>  <TAB> ""The specified securitygroups '{0}' could not be found."".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> vm_securitygroups[i] <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> return vm_securitygroups",if vm_securitygroups [ i ] not in securitygroups :,186
952,"def assert_walk_snapshot( <TAB> self, field, filespecs_or_globs, paths, ignore_patterns=None, prepare=None): <TAB> with self.mk_project_tree(ignore_patterns=ignore_patterns) as project_tree: <TAB>  <TAB> scheduler = self.mk_scheduler( <TAB>  <TAB>  <TAB> rules=create_fs_rules(), project_tree=project_tree <TAB>  <TAB> ) <MASK> prepare(project_tree) <TAB>  <TAB> result = self.execute(scheduler, Snapshot, self.specs(filespecs_or_globs))[0] <TAB>  <TAB> self.assertEqual(sorted(getattr(result, field)), sorted(paths))",if prepare :,152
953,"def _parse_rowids(self, rowids): <TAB> xploded = [] <TAB> rowids = [x.strip() for x in rowids.split("","")] <TAB> for rowid in rowids: <TAB>  <TAB> try: <MASK> start = int(rowid.split(""-"")[0].strip()) <TAB>  <TAB>  <TAB>  <TAB> end = int(rowid.split(""-"")[-1].strip()) <TAB>  <TAB>  <TAB>  <TAB> xploded += range(start, end + 1) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> xploded.append(int(rowid)) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> continue <TAB> return sorted(list(set(xploded)))","if ""-"" in rowid :",156
954,"def ensemble(self, pairs, other_preds): <TAB> """"""Ensemble the dict with statistical model predictions."""""" <TAB> lemmas = [] <TAB> assert len(pairs) == len(other_preds) <TAB> for p, pred in zip(pairs, other_preds): <TAB>  <TAB> w, pos = p <MASK> lemma = self.composite_dict[(w, pos)] <TAB>  <TAB> elif w in self.word_dict: <TAB>  <TAB>  <TAB> lemma = self.word_dict[w] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lemma = pred <TAB>  <TAB> if lemma is None: <TAB>  <TAB>  <TAB> lemma = w <TAB>  <TAB> lemmas.append(lemma) <TAB> return lemmas","if ( w , pos ) in self . composite_dict :",164
955,"def selectionToChunks(self, remove=False, add=False): <TAB> box = self.selectionBox() <TAB> if box: <MASK> self.selectedChunks = set(self.level.allChunks) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> selectedChunks = self.selectedChunks <TAB>  <TAB> boxedChunks = set(box.chunkPositions) <TAB>  <TAB> if boxedChunks.issubset(selectedChunks): <TAB>  <TAB>  <TAB> remove = True <TAB>  <TAB> if remove and not add: <TAB>  <TAB>  <TAB> selectedChunks.difference_update(boxedChunks) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> selectedChunks.update(boxedChunks) <TAB> self.selectionTool.selectNone()",if box == self . level . bounds :,158
956,"def _ensure_max_size(cls, image, max_size, interpolation): <TAB> if max_size is not None: <TAB>  <TAB> size = max(image.shape[0], image.shape[1]) <MASK> resize_factor = max_size / size <TAB>  <TAB>  <TAB> new_height = int(image.shape[0] * resize_factor) <TAB>  <TAB>  <TAB> new_width = int(image.shape[1] * resize_factor) <TAB>  <TAB>  <TAB> image = ia.imresize_single_image( <TAB>  <TAB>  <TAB>  <TAB> image, (new_height, new_width), interpolation=interpolation <TAB>  <TAB>  <TAB> ) <TAB> return image",if size > max_size :,155
957,"def _1_0_cloud_ips(self, method, url, body, headers): <TAB> if method == ""GET"": <TAB>  <TAB> return self.test_response(httplib.OK, self.fixtures.load(""list_cloud_ips.json"")) <TAB> elif method == ""POST"": <MASK> body = json.loads(body) <TAB>  <TAB> node = json.loads(self.fixtures.load(""create_cloud_ip.json"")) <TAB>  <TAB> if ""reverse_dns"" in body: <TAB>  <TAB>  <TAB> node[""reverse_dns""] = body[""reverse_dns""] <TAB>  <TAB> return self.test_response(httplib.ACCEPTED, json.dumps(node))",if body :,159
958,"def get_formatted_stats(self): <TAB> """"""Get percentage or number of rar's done"""""" <TAB> if self.cur_setname and self.cur_setname in self.total_volumes: <TAB>  <TAB> # This won't work on obfuscated posts <MASK> return ""%02d/%02d"" % (self.cur_volume, self.total_volumes[self.cur_setname]) <TAB> return self.cur_volume",if self . total_volumes [ self . cur_setname ] >= self . cur_volume and self . cur_volume :,128
959,"def wdayset(self, year, month, day): <TAB> # We need to handle cross-year weeks here. <TAB> dset = [None] * (self.yearlen + 7) <TAB> i = datetime.date(year, month, day).toordinal() - self.yearordinal <TAB> start = i <TAB> for j in range(7): <TAB>  <TAB> dset[i] = i <TAB>  <TAB> i += 1 <TAB>  <TAB> # if (not (0 <= i < self.yearlen) or <TAB>  <TAB> # <TAB> self.wdaymask[i] == self.rrule._wkst): <TAB>  <TAB> # This will cross the year boundary, if necessary. <MASK> break <TAB> return dset, start, i",if self . wdaymask [ i ] == self . rrule . _wkst :,184
960,"def do_acquire_read_lock(self, wait=True): <TAB> self.condition.acquire() <TAB> try: <TAB>  <TAB> # see if a synchronous operation is waiting to start <TAB>  <TAB> # or is already running, in which case we wait (or just <TAB>  <TAB> # give up and return) <MASK> while self.current_sync_operation is not None: <TAB>  <TAB>  <TAB>  <TAB> self.condition.wait() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if self.current_sync_operation is not None: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> self.asynch += 1 <TAB> finally: <TAB>  <TAB> self.condition.release() <TAB> if not wait: <TAB>  <TAB> return True",if wait :,162
961,"def _blend(x, y):  # pylint: disable=invalid-name <TAB> """"""Implements the ""blend"" strategy for `deep_merge`."""""" <TAB> if isinstance(x, (dict, OrderedDict)): <MASK> return y <TAB>  <TAB> return _merge(x, y, recursion_func=_blend) <TAB> if isinstance(x, (list, tuple)): <TAB>  <TAB> if not isinstance(y, (list, tuple)): <TAB>  <TAB>  <TAB> return y <TAB>  <TAB> result = [_blend(*i) for i in zip(x, y)] <TAB>  <TAB> if len(x) > len(y): <TAB>  <TAB>  <TAB> result += x[len(y) :] <TAB>  <TAB> elif len(x) < len(y): <TAB>  <TAB>  <TAB> result += y[len(x) :] <TAB>  <TAB> return result <TAB> return y","if not isinstance ( y , ( dict , OrderedDict ) ) :",194
962,"def update_forum_nums_topic_post(modeladmin, request, queryset): <TAB> for forum in queryset: <TAB>  <TAB> forum.num_topics = forum.count_nums_topic() <TAB>  <TAB> forum.num_posts = forum.count_nums_post() <MASK> forum.last_post = forum.topic_set.order_by(""-last_reply_on"")[0].last_post <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> forum.last_post = """" <TAB>  <TAB> forum.save()",if forum . num_topics :,123
963,"def get_docname_for_node(self, node: Node) -> str: <TAB> while node: <TAB>  <TAB> if isinstance(node, nodes.document): <TAB>  <TAB>  <TAB> return self.env.path2doc(node[""source""]) <MASK> return node[""docname""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> node = node.parent <TAB> return None  # never reached here. only for type hinting","elif isinstance ( node , addnodes . start_of_file ) :",110
964,"def _selected_machines(self, virtual_machines): <TAB> selected_machines = [] <TAB> for machine in virtual_machines: <TAB>  <TAB> if self._args.host and self._args.host == machine.name: <TAB>  <TAB>  <TAB> selected_machines.append(machine) <TAB>  <TAB> if self.tags and self._tags_match(machine.tags, self.tags): <TAB>  <TAB>  <TAB> selected_machines.append(machine) <MASK> selected_machines.append(machine) <TAB> return selected_machines",if self . locations and machine . location in self . locations :,129
965,"def transform_kwarg(self, name, value, split_single_char_options): <TAB> if len(name) == 1: <TAB>  <TAB> if value is True: <TAB>  <TAB>  <TAB> return [""-%s"" % name] <MASK> if split_single_char_options: <TAB>  <TAB>  <TAB>  <TAB> return [""-%s"" % name, ""%s"" % value] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return [""-%s%s"" % (name, value)] <TAB> else: <TAB>  <TAB> if value is True: <TAB>  <TAB>  <TAB> return [""--%s"" % dashify(name)] <TAB>  <TAB> elif value is not False and value is not None: <TAB>  <TAB>  <TAB> return [""--%s=%s"" % (dashify(name), value)] <TAB> return []","elif value not in ( False , None ) :",183
966,"def indent(elem, level=0): <TAB> i = ""\n"" + level * ""  "" <TAB> if len(elem): <TAB>  <TAB> if not elem.text or not elem.text.strip(): <TAB>  <TAB>  <TAB> elem.text = i + ""  "" <TAB>  <TAB> if not elem.tail or not elem.tail.strip(): <TAB>  <TAB>  <TAB> elem.tail = i <TAB>  <TAB> for elem in elem: <TAB>  <TAB>  <TAB> indent(elem, level + 1) <TAB>  <TAB> if not elem.tail or not elem.tail.strip(): <TAB>  <TAB>  <TAB> elem.tail = i <TAB> else: <MASK> elem.tail = i",if level and ( not elem . tail or not elem . tail . strip ( ) ) :,161
967,"def _run_instances_op(self, op, instance_ids, **kwargs): <TAB> while instance_ids: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self.manager.retry(op, InstanceIds=instance_ids, **kwargs) <TAB>  <TAB> except ClientError as e: <MASK> instance_ids.remove(extract_instance_id(e)) <TAB>  <TAB>  <TAB> raise","if e . response [ ""Error"" ] [ ""Code"" ] == ""IncorrectInstanceState"" :",105
968,"def runTest(self): <TAB> self.poco(text=""wait UI"").click() <TAB> bomb_count = 0 <TAB> while True: <TAB>  <TAB> blue_fish = self.poco(""fish_emitter"").child(""blue"") <TAB>  <TAB> yellow_fish = self.poco(""fish_emitter"").child(""yellow"") <TAB>  <TAB> bomb = self.poco(""fish_emitter"").child(""bomb"") <TAB>  <TAB> fish = self.poco.wait_for_any([blue_fish, yellow_fish, bomb]) <MASK> bomb_count += 1 <TAB>  <TAB>  <TAB> if bomb_count > 3: <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> fish.click() <TAB>  <TAB> time.sleep(2.5)",if fish is bomb :,192
969,"def lineWidth(self, lw=None): <TAB> """"""Set/get width of mesh edges. Same as `lw()`."""""" <TAB> if lw is not None: <MASK> self.GetProperty().EdgeVisibilityOff() <TAB>  <TAB>  <TAB> self.GetProperty().SetRepresentationToSurface() <TAB>  <TAB>  <TAB> return self <TAB>  <TAB> self.GetProperty().EdgeVisibilityOn() <TAB>  <TAB> self.GetProperty().SetLineWidth(lw) <TAB> else: <TAB>  <TAB> return self.GetProperty().GetLineWidth() <TAB> return self",if lw == 0 :,130
970,"def _current_date_updater(doc, field_name, value): <TAB> if isinstance(doc, dict): <MASK> # TODO(juannyg): get_current_timestamp should also be using helpers utcnow, <TAB>  <TAB>  <TAB> # as it currently using time.time internally <TAB>  <TAB>  <TAB> doc[field_name] = helpers.get_current_timestamp() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> doc[field_name] = mongomock.utcnow()","if value == { ""$type"" : ""timestamp"" } :",118
971,"def fill_members(self): <TAB> if self._get_retrieve(): <TAB>  <TAB> after = self.after.id if self.after else None <TAB>  <TAB> data = await self.get_members(self.guild.id, self.retrieve, after) <MASK> # no data, terminate <TAB>  <TAB>  <TAB> return <TAB>  <TAB> if len(data) < 1000: <TAB>  <TAB>  <TAB> self.limit = 0  # terminate loop <TAB>  <TAB> self.after = Object(id=int(data[-1][""user""][""id""])) <TAB>  <TAB> for element in reversed(data): <TAB>  <TAB>  <TAB> await self.members.put(self.create_member(element))",if not data :,153
972,"def extract(self, page, start_index=0, end_index=None): <TAB> items = [] <TAB> for extractor in self.extractors: <TAB>  <TAB> extracted = extractor.extract( <TAB>  <TAB>  <TAB> page, start_index, end_index, self.template.ignored_regions <TAB>  <TAB> ) <TAB>  <TAB> for item in arg_to_iter(extracted): <TAB>  <TAB>  <TAB> if item: <MASK> item[u""_template""] = self.template.id <TAB>  <TAB>  <TAB>  <TAB> items.append(item) <TAB> return items","if isinstance ( item , ( ItemProcessor , dict ) ) :",141
973,"def _get_node_type_specific_fields(self, node_id: str, fields_key: str) -> Any: <TAB> fields = self.config[fields_key] <TAB> node_tags = self.provider.node_tags(node_id) <TAB> if TAG_RAY_USER_NODE_TYPE in node_tags: <TAB>  <TAB> node_type = node_tags[TAG_RAY_USER_NODE_TYPE] <TAB>  <TAB> if node_type not in self.available_node_types: <TAB>  <TAB>  <TAB> raise ValueError(f""Unknown node type tag: {node_type}."") <TAB>  <TAB> node_specific_config = self.available_node_types[node_type] <MASK> fields = node_specific_config[fields_key] <TAB> return fields",if fields_key in node_specific_config :,189
974,"def _write_all(self, writer): <TAB> """"""Writes messages and insert comments here and there."""""" <TAB> # Note: we make no assumptions about the length of original_messages and original_comments <TAB> for msg, comment in zip_longest( <TAB>  <TAB> self.original_messages, self.original_comments, fillvalue=None <TAB> ): <TAB>  <TAB> # msg and comment might be None <MASK> print(""writing comment: "", comment) <TAB>  <TAB>  <TAB> writer.log_event(comment)  # we already know that this method exists <TAB>  <TAB> if msg is not None: <TAB>  <TAB>  <TAB> print(""writing message: "", msg) <TAB>  <TAB>  <TAB> writer(msg)",if comment is not None :,157
975,"def run_tests(): <TAB> # type: () -> None <TAB> x = 5 <TAB> with switch(x) as case: <MASK> print(""zero"") <TAB>  <TAB>  <TAB> print(""zero"") <TAB>  <TAB> elif case(1, 2): <TAB>  <TAB>  <TAB> print(""one or two"") <TAB>  <TAB> elif case(3, 4): <TAB>  <TAB>  <TAB> print(""three or four"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""default"") <TAB>  <TAB>  <TAB> print(""another"")",if case ( 0 ) :,114
976,"def date_to_format(value, target_format): <TAB> """"""Convert date to specified format"""""" <TAB> if target_format == str: <TAB>  <TAB> if isinstance(value, datetime.date): <TAB>  <TAB>  <TAB> ret = value.strftime(""%d/%m/%y"") <MASK> ret = value.strftime(""%d/%m/%y"") <TAB>  <TAB> elif isinstance(value, datetime.time): <TAB>  <TAB>  <TAB> ret = value.strftime(""%H:%M:%S"") <TAB> else: <TAB>  <TAB> ret = value <TAB> return ret","elif isinstance ( value , datetime . datetime ) :",130
977,"def database_app(request): <TAB> if request.param == ""postgres_app"": <TAB>  <TAB> if not which(""initdb""): <TAB>  <TAB>  <TAB> pytest.skip(""initdb must be on PATH for postgresql fixture"") <MASK> pytest.skip(""psycopg2 must be installed for postgresql fixture"") <TAB> if request.param == ""sqlite_rabbitmq_app"": <TAB>  <TAB> if not os.environ.get(""GALAXY_TEST_AMQP_INTERNAL_CONNECTION""): <TAB>  <TAB>  <TAB> pytest.skip( <TAB>  <TAB>  <TAB>  <TAB> ""rabbitmq tests will be skipped if GALAXY_TEST_AMQP_INTERNAL_CONNECTION env var is unset"" <TAB>  <TAB>  <TAB> ) <TAB> return request.getfixturevalue(request.param)",if not psycopg2 :,174
978,"def poll_ms(self, timeout=-1): <TAB> s = bytearray(self.evbuf) <MASK> deadline = utime.ticks_add(utime.ticks_ms(), timeout) <TAB> while True: <TAB>  <TAB> n = epoll_wait(self.epfd, s, 1, timeout) <TAB>  <TAB> if not os.check_error(n): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if timeout >= 0: <TAB>  <TAB>  <TAB> timeout = utime.ticks_diff(deadline, utime.ticks_ms()) <TAB>  <TAB>  <TAB> if timeout < 0: <TAB>  <TAB>  <TAB>  <TAB> n = 0 <TAB>  <TAB>  <TAB>  <TAB> break <TAB> res = [] <TAB> if n > 0: <TAB>  <TAB> vals = struct.unpack(epoll_event, s) <TAB>  <TAB> res.append((vals[1], vals[0])) <TAB> return res",if timeout >= 0 :,192
979,"def get_all_active_plugins(self) -> List[BotPlugin]: <TAB> """"""This returns the list of plugins in the callback ordered defined from the config."""""" <TAB> all_plugins = [] <TAB> for name in self.plugins_callback_order: <TAB>  <TAB> # None is a placeholder for any plugin not having a defined order <TAB>  <TAB> if name is None: <TAB>  <TAB>  <TAB> all_plugins += [ <TAB>  <TAB>  <TAB>  <TAB> plugin <TAB>  <TAB>  <TAB>  <TAB> for name, plugin in self.plugins.items() <TAB>  <TAB>  <TAB>  <TAB> if name not in self.plugins_callback_order and plugin.is_activated <TAB>  <TAB>  <TAB> ] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> plugin = self.plugins[name] <MASK> all_plugins.append(plugin) <TAB> return all_plugins",if plugin . is_activated :,186
980,"def get_expected_sql(self): <TAB> sql_base_path = path.join(path.dirname(path.realpath(__file__)), ""sql"") <TAB> # Iterate the version mapping directories. <TAB> for version_mapping in get_version_mapping_directories(self.server[""type""]): <MASK> continue <TAB>  <TAB> complete_path = path.join(sql_base_path, version_mapping[""name""]) <TAB>  <TAB> if not path.exists(complete_path): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> break <TAB> data_sql = """" <TAB> with open(path.join(complete_path, ""test_sql_output.sql"")) as fp: <TAB>  <TAB> data_sql = fp.read() <TAB> return data_sql","if version_mapping [ ""number"" ] > self . server_information [ ""server_version"" ] :",185
981,"def _validate_headers(self, headers): <TAB> if headers is None: <TAB>  <TAB> return headers <TAB> res = {} <TAB> for key, value in headers.items(): <TAB>  <TAB> if isinstance(value, (int, float)): <TAB>  <TAB>  <TAB> value = str(value) <MASK> raise ScriptError( <TAB>  <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""message"": ""headers must be a table"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> "" with strings as keys and values."" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Header: `{!r}:{!r}` is not valid"".format(key, value) <TAB>  <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> res[key] = value <TAB> return res","if not isinstance ( key , ( bytes , str ) ) or not isinstance ( value , ( bytes , str ) ) :",181
982,"def _get_literal_value(self, pyval): <TAB> if pyval == self.vm.lookup_builtin(""builtins.True""): <TAB>  <TAB> return True <TAB> elif pyval == self.vm.lookup_builtin(""builtins.False""): <TAB>  <TAB> return False <TAB> elif isinstance(pyval, str): <TAB>  <TAB> prefix, value = parser_constants.STRING_RE.match(pyval).groups()[:2] <TAB>  <TAB> value = value[1:-1]  # remove quotation marks <MASK> value = compat.bytestring(value) <TAB>  <TAB> elif ""u"" in prefix and self.vm.PY2: <TAB>  <TAB>  <TAB> value = compat.UnicodeType(value) <TAB>  <TAB> return value <TAB> else: <TAB>  <TAB> return pyval","if ""b"" in prefix and not self . vm . PY2 :",183
983,"def decode_query_ids(self, trans, conditional): <TAB> if conditional.operator == ""and"": <TAB>  <TAB> self.decode_query_ids(trans, conditional.left) <TAB>  <TAB> self.decode_query_ids(trans, conditional.right) <TAB> else: <TAB>  <TAB> left_base = conditional.left.split(""."")[0] <MASK> field = self.FIELDS[left_base] <TAB>  <TAB>  <TAB> if field.id_decode: <TAB>  <TAB>  <TAB>  <TAB> conditional.right = trans.security.decode_id(conditional.right)",if left_base in self . FIELDS :,135
984,"def testLastPhrases(self): <TAB> for day in (11, 12, 13, 14, 15, 16, 17): <TAB>  <TAB> start = datetime.datetime(2012, 11, day, 9, 0, 0) <TAB>  <TAB> (yr, mth, dy, _, _, _, wd, yd, isdst) = start.timetuple() <TAB>  <TAB> n = 4 - wd <MASK> n -= 7 <TAB>  <TAB> target = start + datetime.timedelta(days=n) <TAB>  <TAB> self.assertExpectedResult( <TAB>  <TAB>  <TAB> self.cal.parse(""last friday"", start.timetuple()), <TAB>  <TAB>  <TAB> (target.timetuple(), 1), <TAB>  <TAB>  <TAB> dateOnly=True, <TAB>  <TAB> )",if n >= 0 :,168
985,"def _convertNbCharsInNbBits(self, nbChars): <TAB> nbMinBit = None <TAB> nbMaxBit = None <TAB> if nbChars is not None: <TAB>  <TAB> if isinstance(nbChars, int): <TAB>  <TAB>  <TAB> nbMinBit = nbChars * 8 <TAB>  <TAB>  <TAB> nbMaxBit = nbMinBit <TAB>  <TAB> else: <MASK> nbMinBit = nbChars[0] * 8 <TAB>  <TAB>  <TAB> if nbChars[1] is not None: <TAB>  <TAB>  <TAB>  <TAB> nbMaxBit = nbChars[1] * 8 <TAB> return (nbMinBit, nbMaxBit)",if nbChars [ 0 ] is not None :,158
986,"def getpystone(): <TAB> # Start calculation <TAB> maxpystone = 0 <TAB> # Start with a short run, find the the pystone, and increase runtime until duration took > 0.1 second <TAB> for pyseed in [1000, 2000, 5000, 10000, 20000, 50000, 100000, 200000]: <TAB>  <TAB> duration, pystonefloat = pystones(pyseed) <TAB>  <TAB> maxpystone = max(maxpystone, int(pystonefloat)) <TAB>  <TAB> # Stop when pystone() has been running for at least 0.1 second <MASK> break <TAB> return maxpystone",if duration > 0.1 :,144
987,"def _append_to_io_queue(self, data, stream_name): <TAB> # Make sure ANSI CSI codes and object links are stored as separate events <TAB> # TODO: try to complete previously submitted incomplete code <TAB> parts = re.split(OUTPUT_SPLIT_REGEX, data) <TAB> for part in parts: <MASK> # split may produce empty string in the beginning or start <TAB>  <TAB>  <TAB> # split the data so that very long lines separated <TAB>  <TAB>  <TAB> for block in re.split( <TAB>  <TAB>  <TAB>  <TAB> ""(.{%d,})"" % (self._get_squeeze_threshold() + 1), part <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> if block: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._queued_io_events.append((block, stream_name))",if part :,174
988,"def qtTypeIdent(conn, *args): <TAB> # We're not using the conn object at the moment, but - we will <TAB> # modify the <TAB> # logic to use the server version specific keywords later. <TAB> res = None <TAB> value = None <TAB> for val in args: <TAB>  <TAB> # DataType doesn't have len function then convert it to string <MASK> val = str(val) <TAB>  <TAB> if len(val) == 0: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> value = val <TAB>  <TAB> if Driver.needsQuoting(val, True): <TAB>  <TAB>  <TAB> value = value.replace('""', '""""') <TAB>  <TAB>  <TAB> value = '""' + value + '""' <TAB>  <TAB> res = ((res and res + ""."") or """") + value <TAB> return res","if not hasattr ( val , ""__len__"" ) :",181
989,"def SetVerbose(self, level): <TAB> """"""Sets the verbose level."""""" <TAB> try: <MASK> level = int(level) <TAB>  <TAB> if (level >= 0) and (level <= 3): <TAB>  <TAB>  <TAB> self._verbose = level <TAB>  <TAB>  <TAB> return <TAB> except ValueError: <TAB>  <TAB> pass <TAB> self.Error(""Verbose level (%s) must be between 0 and 3 inclusive."" % level)",if type ( level ) != types . IntType :,105
990,"def step(self) -> None: <TAB> """"""Performs a single optimization step."""""" <TAB> for group in self.param_groups: <TAB>  <TAB> for p in group[""params""]: <MASK> continue <TAB>  <TAB>  <TAB> p.add_(p.grad, alpha=(-group[""lr""] * self.num_data)) <TAB> return None",if p . grad is None :,85
991,"def fill(self, values): <TAB> if lupa.lua_type(values) != ""table"": <TAB>  <TAB> raise ScriptError( <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB> ""argument"": ""values"", <TAB>  <TAB>  <TAB>  <TAB> ""message"": ""element:fill values is not a table"", <TAB>  <TAB>  <TAB>  <TAB> ""splash_method"": ""fill"", <TAB>  <TAB>  <TAB> } <TAB>  <TAB> ) <TAB> # marking all tables as arrays by default <TAB> for key, value in values.items(): <MASK> _mark_table_as_array(self.lua, value) <TAB> values = self.lua.lua2python(values) <TAB> return self.element.fill(values)","if lupa . lua_type ( value ) == ""table"" :",177
992,"def _gen_repr(self, buf): <TAB> print >> buf, "" <TAB> def __repr__(self):"" <TAB> if self.argnames: <TAB>  <TAB> fmt = COMMA.join([""%s""] * self.nargs) <MASK> fmt = ""(%s)"" % fmt <TAB>  <TAB> vals = [""repr(self.%s)"" % name for name in self.argnames] <TAB>  <TAB> vals = COMMA.join(vals) <TAB>  <TAB> if self.nargs == 1: <TAB>  <TAB>  <TAB> vals = vals + "","" <TAB>  <TAB> print >> buf, ' <TAB>  <TAB> return ""%s(%s)"" %% (%s)' % (self.name, fmt, vals) <TAB> else: <TAB>  <TAB> print >> buf, ' <TAB>  <TAB> return ""%s()""' % self.name","if ""("" in self . args :",189
993,"def render_observation(self): <TAB> x = self.read_head_position <TAB> label = ""Observation Grid <TAB> : "" <TAB> x_str = """" <TAB> for j in range(-1, self.rows + 1): <MASK> x_str += "" "" * len(label) <TAB>  <TAB> for i in range(-2, self.input_width + 2): <TAB>  <TAB>  <TAB> if i == x[0] and j == x[1]: <TAB>  <TAB>  <TAB>  <TAB> x_str += colorize(self._get_str_obs((i, j)), ""green"", highlight=True) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> x_str += self._get_str_obs((i, j)) <TAB>  <TAB> x_str += ""\n"" <TAB> x_str = label + x_str <TAB> return x_str",if j != - 1 :,200
994,"def get_module_comment(self, attrname: str) -> Optional[List[str]]: <TAB> try: <TAB>  <TAB> analyzer = ModuleAnalyzer.for_module(self.modname) <TAB>  <TAB> analyzer.analyze() <TAB>  <TAB> key = ("""", attrname) <MASK> return list(analyzer.attr_docs[key]) <TAB> except PycodeError: <TAB>  <TAB> pass <TAB> return None",if key in analyzer . attr_docs :,99
995,"def tms_to_quadkey(self, tms, google=False): <TAB> quadKey = """" <TAB> x, y, z = tms <TAB> # this algorithm works with google tiles, rather than tms, so convert <TAB> # to those first. <TAB> if not google: <TAB>  <TAB> y = (2 ** z - 1) - y <TAB> for i in range(z, 0, -1): <TAB>  <TAB> digit = 0 <TAB>  <TAB> mask = 1 << (i - 1) <MASK> digit += 1 <TAB>  <TAB> if (y & mask) != 0: <TAB>  <TAB>  <TAB> digit += 2 <TAB>  <TAB> quadKey += str(digit) <TAB> return quadKey",if ( x & mask ) != 0 :,164
996,"def test_enumerate(app): <TAB> async with new_stream(app) as stream: <TAB>  <TAB> for i in range(100): <TAB>  <TAB>  <TAB> await stream.channel.deliver(message(key=i, value=i * 4)) <TAB>  <TAB> async for i, value in stream.enumerate(): <TAB>  <TAB>  <TAB> current_event = stream.current_event <TAB>  <TAB>  <TAB> assert i == current_event.key <TAB>  <TAB>  <TAB> assert value == i * 4 <MASK> break <TAB>  <TAB> assert await channel_empty(stream.channel)",if i >= 99 :,131
997,"def print_messages(self): <TAB> output_reports = self.config.get_output_report() <TAB> for report in output_reports: <TAB>  <TAB> output_format, output_files = report <TAB>  <TAB> self.summary[""formatter""] = output_format <TAB>  <TAB> formatter = FORMATTERS[output_format]( <TAB>  <TAB>  <TAB> self.summary, self.messages, self.config.profile <TAB>  <TAB> ) <MASK> self.write_to(formatter, sys.stdout) <TAB>  <TAB> for output_file in output_files: <TAB>  <TAB>  <TAB> with open(output_file, ""w+"") as target: <TAB>  <TAB>  <TAB>  <TAB> self.write_to(formatter, target)",if not output_files :,160
998,"def eval_metrics(self): <TAB> for task in self.task_list: <MASK> return [ <TAB>  <TAB>  <TAB>  <TAB> metrics.Metrics.ACC, <TAB>  <TAB>  <TAB>  <TAB> metrics.Metrics.NEG_LOG_PERPLEXITY, <TAB>  <TAB>  <TAB>  <TAB> metrics.Metrics.ROUGE_2_F, <TAB>  <TAB>  <TAB>  <TAB> metrics.Metrics.ROUGE_L_F, <TAB>  <TAB>  <TAB> ] <TAB> return [ <TAB>  <TAB> metrics.Metrics.ACC, <TAB>  <TAB> metrics.Metrics.NEG_LOG_PERPLEXITY, <TAB> ]","if ""summarize"" in task . name :",137
999,"def _getBuildRequestForBrdict(self, brdict): <TAB> # Turn a brdict into a BuildRequest into a brdict. This is useful <TAB> # for API like 'nextBuild', which operate on BuildRequest objects. <TAB> breq = self.breqCache.get(brdict[""buildrequestid""]) <TAB> if not breq: <TAB>  <TAB> breq = yield BuildRequest.fromBrdict(self.master, brdict) <MASK> self.breqCache[brdict[""buildrequestid""]] = breq <TAB> defer.returnValue(breq)",if breq :,136
1000,"def _stash_splitter(states): <TAB> keep, split = [], [] <TAB> if state_func is not None: <TAB>  <TAB> for s in states: <TAB>  <TAB>  <TAB> ns = state_func(s) <MASK> split.append(ns) <TAB>  <TAB>  <TAB> elif isinstance(ns, (list, tuple, set)): <TAB>  <TAB>  <TAB>  <TAB> split.extend(ns) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> split.append(s) <TAB> if stash_func is not None: <TAB>  <TAB> split = stash_func(states) <TAB> if to_stash is not stash: <TAB>  <TAB> keep = states <TAB> return keep, split","if isinstance ( ns , SimState ) :",163
1001,"def sequence_to_text(sequence): <TAB> """"""Converts a sequence of IDs back to a string"""""" <TAB> result = """" <TAB> for symbol_id in sequence: <MASK> s = _id_to_symbol[symbol_id] <TAB>  <TAB>  <TAB> # Enclose ARPAbet back in curly braces: <TAB>  <TAB>  <TAB> if len(s) > 1 and s[0] == ""@"": <TAB>  <TAB>  <TAB>  <TAB> s = ""{%s}"" % s[1:] <TAB>  <TAB>  <TAB> result += s <TAB> return result.replace(""}{"", "" "")",if symbol_id in _id_to_symbol :,137
1002,"def get_code(self, fullname=None): <TAB> fullname = self._fix_name(fullname) <TAB> if self.code is None: <TAB>  <TAB> mod_type = self.etc[2] <MASK> source = self.get_source(fullname) <TAB>  <TAB>  <TAB> self.code = compile(source, self.filename, ""exec"") <TAB>  <TAB> elif mod_type == imp.PY_COMPILED: <TAB>  <TAB>  <TAB> self._reopen() <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> self.code = read_code(self.file) <TAB>  <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB>  <TAB> self.file.close() <TAB>  <TAB> elif mod_type == imp.PKG_DIRECTORY: <TAB>  <TAB>  <TAB> self.code = self._get_delegate().get_code() <TAB> return self.code",if mod_type == imp . PY_SOURCE :,196
1003,"def identwaf(self, findall=False): <TAB> detected = list() <TAB> try: <TAB>  <TAB> self.attackres = self.performCheck(self.centralAttack) <TAB> except RequestBlocked: <TAB>  <TAB> return detected <TAB> for wafvendor in self.checklist: <TAB>  <TAB> self.log.info(""Checking for %s"" % wafvendor) <TAB>  <TAB> if self.wafdetections[wafvendor](self): <TAB>  <TAB>  <TAB> detected.append(wafvendor) <MASK> break <TAB> self.knowledge[""wafname""] = detected <TAB> return detected",if not findall :,143
1004,"def SessionId(self): <TAB> """"""Returns the Session ID of the process"""""" <TAB> if self.Session.is_valid(): <TAB>  <TAB> process_space = self.get_process_address_space() <MASK> return obj.Object( <TAB>  <TAB>  <TAB>  <TAB> ""_MM_SESSION_SPACE"", offset=self.Session, vm=process_space <TAB>  <TAB>  <TAB> ).SessionId <TAB> return obj.NoneObject(""Cannot find process session"")",if process_space :,105
1005,"def _convert_java_pattern_to_python(pattern): <TAB> """"""Convert a replacement pattern from the Java-style `$5` to the Python-style `\\5`."""""" <TAB> s = list(pattern) <TAB> i = 0 <TAB> while i < len(s) - 1: <TAB>  <TAB> c = s[i] <TAB>  <TAB> if c == ""$"" and s[i + 1] in ""0123456789"": <TAB>  <TAB>  <TAB> s[i] = ""\\"" <MASK> s[i] = """" <TAB>  <TAB>  <TAB> i += 1 <TAB>  <TAB> i += 1 <TAB> return pattern[:0].join(s)","elif c == ""\\"" and s [ i + 1 ] == ""$"" :",152
1006,"def __init__(self, coverage): <TAB> self.coverage = coverage <TAB> self.config = self.coverage.config <TAB> self.source_paths = set() <TAB> if self.config.source: <TAB>  <TAB> for src in self.config.source: <MASK> if not self.config.relative_files: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> src = files.canonical_filename(src) <TAB>  <TAB>  <TAB>  <TAB> self.source_paths.add(src) <TAB> self.packages = {} <TAB> self.xml_out = None",if os . path . exists ( src ) :,133
1007,"def populate_vol_format(self): <TAB> rhel6_file_whitelist = [""raw"", ""qcow2"", ""qed""] <TAB> model = self.widget(""vol-format"").get_model() <TAB> model.clear() <TAB> formats = self.vol_class.formats <TAB> if hasattr(self.vol_class, ""create_formats""): <TAB>  <TAB> formats = getattr(self.vol_class, ""create_formats"") <TAB> if self.vol_class == Storage.FileVolume and not self.conn.rhel6_defaults_caps(): <TAB>  <TAB> newfmts = [] <TAB>  <TAB> for f in rhel6_file_whitelist: <MASK> newfmts.append(f) <TAB>  <TAB> formats = newfmts <TAB> for f in formats: <TAB>  <TAB> model.append([f, f])",if f in formats :,196
1008,"def get_file_sources(): <TAB> global _file_sources <TAB> if _file_sources is None: <TAB>  <TAB> from galaxy.files import ConfiguredFileSources <TAB>  <TAB> file_sources = None <MASK> file_sources_as_dict = None <TAB>  <TAB>  <TAB> with open(""file_sources.json"", ""r"") as f: <TAB>  <TAB>  <TAB>  <TAB> file_sources_as_dict = json.load(f) <TAB>  <TAB>  <TAB> if file_sources_as_dict is not None: <TAB>  <TAB>  <TAB>  <TAB> file_sources = ConfiguredFileSources.from_dict(file_sources_as_dict) <TAB>  <TAB> if file_sources is None: <TAB>  <TAB>  <TAB> ConfiguredFileSources.from_dict([]) <TAB>  <TAB> _file_sources = file_sources <TAB> return _file_sources","if os . path . exists ( ""file_sources.json"" ) :",196
1009,"def _blend(x, y):  # pylint: disable=invalid-name <TAB> """"""Implements the ""blend"" strategy for `deep_merge`."""""" <TAB> if isinstance(x, (dict, OrderedDict)): <TAB>  <TAB> if not isinstance(y, (dict, OrderedDict)): <TAB>  <TAB>  <TAB> return y <TAB>  <TAB> return _merge(x, y, recursion_func=_blend) <TAB> if isinstance(x, (list, tuple)): <TAB>  <TAB> if not isinstance(y, (list, tuple)): <TAB>  <TAB>  <TAB> return y <TAB>  <TAB> result = [_blend(*i) for i in zip(x, y)] <MASK> result += x[len(y) :] <TAB>  <TAB> elif len(x) < len(y): <TAB>  <TAB>  <TAB> result += y[len(x) :] <TAB>  <TAB> return result <TAB> return y",if len ( x ) > len ( y ) :,194
1010,"def copy_dicts(dct): <TAB> if ""_remote_data"" in dct: <TAB>  <TAB> dsindex = dct[""_remote_data""][""_content""].dsindex <TAB>  <TAB> newdct = dct.copy() <TAB>  <TAB> newdct[""_remote_data""] = {""_content"": dsindex} <TAB>  <TAB> return list(newdct.items()) <TAB> elif ""_data"" in dct: <TAB>  <TAB> newdct = dct.copy() <TAB>  <TAB> newdata = copy_dicts(dct[""_data""]) <MASK> newdct[""_data""] = newdata <TAB>  <TAB> return list(newdct.items()) <TAB> return None",if newdata :,139
1011,"def _import_epic_activity(self, project_data, taiga_epic, epic, options): <TAB> offset = 0 <TAB> while True: <TAB>  <TAB> activities = self._client.get( <TAB>  <TAB>  <TAB> ""/projects/{}/epics/{}/activity"".format( <TAB>  <TAB>  <TAB>  <TAB> project_data[""id""], <TAB>  <TAB>  <TAB>  <TAB> epic[""id""], <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB> {""envelope"": ""true"", ""limit"": 300, ""offset"": offset}, <TAB>  <TAB> ) <TAB>  <TAB> offset += 300 <TAB>  <TAB> for activity in activities[""data""]: <TAB>  <TAB>  <TAB> self._import_activity(taiga_epic, activity, options) <MASK> break","if len ( activities [ ""data"" ] ) < 300 :",173
1012,"def __get__(self, instance, instance_type=None): <TAB> if instance: <MASK> rel_obj = self.get_obj(instance) <TAB>  <TAB>  <TAB> if rel_obj: <TAB>  <TAB>  <TAB>  <TAB> instance._obj_cache[self.att_name] = rel_obj <TAB>  <TAB> return instance._obj_cache.get(self.att_name) <TAB> return self",if self . att_name not in instance . _obj_cache :,105
1013,"def download_main( <TAB> download, download_playlist, urls, playlist, output_dir, merge, info_only): <TAB> for url in urls: <TAB>  <TAB> if url.startswith(""https://""): <TAB>  <TAB>  <TAB> url = url[8:] <TAB>  <TAB> if not url.startswith(""http://""): <TAB>  <TAB>  <TAB> url = ""http://"" + url <MASK> download_playlist( <TAB>  <TAB>  <TAB>  <TAB> url, output_dir=output_dir, merge=merge, info_only=info_only <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> download(url, output_dir=output_dir, merge=merge, info_only=info_only)",if playlist :,155
1014,"def _mksubs(self): <TAB> self._subs = {} <TAB> commit_dir = CommitDir(self, "".commit"") <TAB> self._subs["".commit""] = commit_dir <TAB> tag_dir = TagDir(self, "".tag"") <TAB> self._subs["".tag""] = tag_dir <TAB> for (name, sha) in git.list_refs(): <MASK> name = name[11:] <TAB>  <TAB>  <TAB> date = git.rev_get_date(sha.encode(""hex"")) <TAB>  <TAB>  <TAB> n1 = BranchList(self, name, sha) <TAB>  <TAB>  <TAB> n1.ctime = n1.mtime = date <TAB>  <TAB>  <TAB> self._subs[name] = n1","if name . startswith ( ""refs/heads/"" ) :",168
1015,"def readAtOffset(self, offset, size, shortok=False): <TAB> ret = b"""" <TAB> self.fd.seek(offset) <TAB> while len(ret) != size: <TAB>  <TAB> rlen = size - len(ret) <TAB>  <TAB> x = self.fd.read(rlen) <MASK> if not shortok: <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB>  <TAB> return ret <TAB>  <TAB> ret += x <TAB> return ret","if x == b"""" :",111
1016,"def remove_indent(self): <TAB> """"""Remove one tab-width of blanks from the previous token."""""" <TAB> w = abs(self.tab_width) <TAB> if self.result: <TAB>  <TAB> s = self.result[-1] <MASK> self.result.pop() <TAB>  <TAB>  <TAB> s = s.replace(""\t"", "" "" * w) <TAB>  <TAB>  <TAB> if s.startswith(""\n""): <TAB>  <TAB>  <TAB>  <TAB> s2 = s[1:] <TAB>  <TAB>  <TAB>  <TAB> self.result.append(""\n"" + s2[:-w]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.result.append(s[:-w])",if s . isspace ( ) :,151
1017,"def flush(self, *args, **kwargs): <TAB> with self._lock: <TAB>  <TAB> self._last_updated = time.time() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if kwargs.get(""in_place"", False): <TAB>  <TAB>  <TAB>  <TAB> self._locked_flush_without_tempfile() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> mailbox.mbox.flush(self, *args, **kwargs) <TAB>  <TAB> except OSError: <MASK> self._locked_flush_without_tempfile() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> self._last_updated = time.time()","if ""_create_temporary"" in traceback . format_exc ( ) :",157
1018,"def _collect_manual_intervention_nodes(pipeline_tree): <TAB> for act in pipeline_tree[""activities""].values(): <MASK> _collect_manual_intervention_nodes(act[""pipeline""]) <TAB>  <TAB> elif act[""component""][""code""] in MANUAL_INTERVENTION_COMP_CODES: <TAB>  <TAB>  <TAB> manual_intervention_nodes.add(act[""id""])","if act [ ""type"" ] == ""SubProcess"" :",105
1019,"def banned(): <TAB> if request.endpoint == ""views.themes"": <TAB>  <TAB> return <TAB> if authed(): <TAB>  <TAB> user = get_current_user_attrs() <TAB>  <TAB> team = get_current_team_attrs() <MASK> return ( <TAB>  <TAB>  <TAB>  <TAB> render_template( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""errors/403.html"", error=""You have been banned from this CTF"" <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB>  <TAB> 403, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if team and team.banned: <TAB>  <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB>  <TAB> render_template( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""errors/403.html"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> error=""Your team has been banned from this CTF"", <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB>  <TAB> 403, <TAB>  <TAB>  <TAB> )",if user and user . banned :,193
1020,"def remove(self, values): <TAB> if not isinstance(values, (list, tuple, set)): <TAB>  <TAB> values = [values] <TAB> for v in values: <TAB>  <TAB> v = str(v) <TAB>  <TAB> if isinstance(self._definition, dict): <TAB>  <TAB>  <TAB> self._definition.pop(v, None) <TAB>  <TAB> elif self._definition == ""ANY"": <TAB>  <TAB>  <TAB> if v == ""ANY"": <TAB>  <TAB>  <TAB>  <TAB> self._definition = [] <MASK> self._definition.remove(v) <TAB> if ( <TAB>  <TAB> self._value is not None <TAB>  <TAB> and self._value not in self._definition <TAB>  <TAB> and self._not_any() <TAB> ): <TAB>  <TAB> raise ConanException(bad_value_msg(self._name, self._value, self.values_range))",elif v in self . _definition :,192
1021,"def save(self, learner, file_name): <TAB> """"""Save the model to location specified in file_name."""""" <TAB> with open(file_name, ""wb"") as f: <MASK> # don't store the large inference cache! <TAB>  <TAB>  <TAB> learner.inference_cache_, tmp = (None, learner.inference_cache_) <TAB>  <TAB>  <TAB> pickle.dump(learner, f, -1) <TAB>  <TAB>  <TAB> learner.inference_cache_ = tmp <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pickle.dump(learner, f, -1)","if hasattr ( learner , ""inference_cache_"" ) :",137
1022,"def __init__(self, exprs, savelist=False): <TAB> super(ParseExpression, self).__init__(savelist) <TAB> if isinstance(exprs, _generatorType): <TAB>  <TAB> exprs = list(exprs) <TAB> if isinstance(exprs, basestring): <TAB>  <TAB> self.exprs = [ParserElement._literalStringClass(exprs)] <TAB> elif isinstance(exprs, collections.Iterable): <TAB>  <TAB> exprs = list(exprs) <TAB>  <TAB> # if sequence of strings provided, wrap with Literal <MASK> exprs = map(ParserElement._literalStringClass, exprs) <TAB>  <TAB> self.exprs = list(exprs) <TAB> else: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.exprs = list(exprs) <TAB>  <TAB> except TypeError: <TAB>  <TAB>  <TAB> self.exprs = [exprs] <TAB> self.callPreparse = False","if all ( isinstance ( expr , basestring ) for expr in exprs ) :",199
1023,"def find(self, back=False): <TAB> flags = 0 <MASK> flags = QTextDocument.FindBackward <TAB> if self.csBox.isChecked(): <TAB>  <TAB> flags = flags | QTextDocument.FindCaseSensitively <TAB> text = self.searchEdit.text() <TAB> if not self.findMain(text, flags): <TAB>  <TAB> if text in self.editBoxes[self.ind].toPlainText(): <TAB>  <TAB>  <TAB> cursor = self.editBoxes[self.ind].textCursor() <TAB>  <TAB>  <TAB> if back: <TAB>  <TAB>  <TAB>  <TAB> cursor.movePosition(QTextCursor.End) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> cursor.movePosition(QTextCursor.Start) <TAB>  <TAB>  <TAB> self.editBoxes[self.ind].setTextCursor(cursor) <TAB>  <TAB>  <TAB> self.findMain(text, flags)",if back :,195
1024,"def _load_storage(self): <TAB> self._storage = {} <TAB> for row in self(""SELECT object, resource, amount FROM storage""): <TAB>  <TAB> ownerid = int(row[0]) <MASK> self._storage[ownerid].append(row[1:]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._storage[ownerid] = [row[1:]]",if ownerid in self . _storage :,94
1025,"def parse_chunked(self, unreader): <TAB> (size, rest) = self.parse_chunk_size(unreader) <TAB> while size > 0: <TAB>  <TAB> while size > len(rest): <TAB>  <TAB>  <TAB> size -= len(rest) <TAB>  <TAB>  <TAB> yield rest <TAB>  <TAB>  <TAB> rest = unreader.read() <MASK> raise NoMoreData() <TAB>  <TAB> yield rest[:size] <TAB>  <TAB> # Remove \r\n after chunk <TAB>  <TAB> rest = rest[size:] <TAB>  <TAB> while len(rest) < 2: <TAB>  <TAB>  <TAB> rest += unreader.read() <TAB>  <TAB> if rest[:2] != b""\r\n"": <TAB>  <TAB>  <TAB> raise ChunkMissingTerminator(rest[:2]) <TAB>  <TAB> (size, rest) = self.parse_chunk_size(unreader, data=rest[2:])",if not rest :,197
1026,"def _augment_batch_(self, batch, random_state, parents, hooks): <TAB> for column in batch.columns: <MASK> for i, cbaoi in enumerate(column.value): <TAB>  <TAB>  <TAB>  <TAB> column.value[i] = cbaoi.clip_out_of_image_() <TAB> return batch","if column . name in [ ""keypoints"" , ""bounding_boxes"" , ""polygons"" , ""line_strings"" ] :",93
1027,"def to_nim(self): <TAB> if self.is_pointer == 2: <TAB>  <TAB> s = ""cstringArray"" if self.type == ""GLchar"" else ""ptr pointer"" <TAB> else: <TAB>  <TAB> s = self.type <MASK> default = ""ptr "" + s <TAB>  <TAB>  <TAB> s = self.NIM_POINTER_MAP.get(s, default) <TAB> return s",if self . is_pointer == 1 :,105
1028,"def find(self, path): <TAB> if os.path.isfile(path) or os.path.islink(path): <TAB>  <TAB> self.num_files = self.num_files + 1 <TAB>  <TAB> if self.match_function(path): <TAB>  <TAB>  <TAB> self.files.append(path) <TAB> elif os.path.isdir(path): <TAB>  <TAB> for content in os.listdir(path): <TAB>  <TAB>  <TAB> file = os.path.join(path, content) <MASK> self.num_files = self.num_files + 1 <TAB>  <TAB>  <TAB>  <TAB> if self.match_function(file): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.files.append(file) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.find(file)",if os . path . isfile ( file ) or os . path . islink ( file ) :,192
1029,"def remove(self, event): <TAB> try: <TAB>  <TAB> self._events_current_sweep.remove(event) <MASK> assert event.in_sweep == True <TAB>  <TAB>  <TAB> assert event.other.in_sweep == True <TAB>  <TAB>  <TAB> event.in_sweep = False <TAB>  <TAB>  <TAB> event.other.in_sweep = False <TAB>  <TAB> return True <TAB> except KeyError: <TAB>  <TAB> if USE_DEBUG: <TAB>  <TAB>  <TAB> assert event.in_sweep == False <TAB>  <TAB>  <TAB> assert event.other.in_sweep == False <TAB>  <TAB> return False",if USE_DEBUG :,134
1030,"def update_metadata(self): <TAB> for attrname in dir(self): <TAB>  <TAB> if attrname.startswith(""__""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> attrvalue = getattr(self, attrname, None) <TAB>  <TAB> if attrvalue == 0: <TAB>  <TAB>  <TAB> continue <MASK> attrname = ""version"" <TAB>  <TAB> if hasattr(self.metadata, ""set_{0}"".format(attrname)): <TAB>  <TAB>  <TAB> getattr(self.metadata, ""set_{0}"".format(attrname))(attrvalue) <TAB>  <TAB> elif hasattr(self.metadata, attrname): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> setattr(self.metadata, attrname, attrvalue) <TAB>  <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB>  <TAB> pass","if attrname == ""salt_version"" :",173
1031,"def _init_auxiliary_head(self, auxiliary_head): <TAB> """"""Initialize ``auxiliary_head``"""""" <TAB> if auxiliary_head is not None: <MASK> self.auxiliary_head = nn.ModuleList() <TAB>  <TAB>  <TAB> for head_cfg in auxiliary_head: <TAB>  <TAB>  <TAB>  <TAB> self.auxiliary_head.append(builder.build_head(head_cfg)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.auxiliary_head = builder.build_head(auxiliary_head)","if isinstance ( auxiliary_head , list ) :",121
1032,"def _str_param_list(self, name): <TAB> out = [] <TAB> if self[name]: <TAB>  <TAB> out += self._str_header(name) <TAB>  <TAB> for param in self[name]: <TAB>  <TAB>  <TAB> parts = [] <TAB>  <TAB>  <TAB> if param.name: <TAB>  <TAB>  <TAB>  <TAB> parts.append(param.name) <MASK> parts.append(param.type) <TAB>  <TAB>  <TAB> out += ["" : "".join(parts)] <TAB>  <TAB>  <TAB> if param.desc and """".join(param.desc).strip(): <TAB>  <TAB>  <TAB>  <TAB> out += self._str_indent(param.desc) <TAB>  <TAB> out += [""""] <TAB> return out",if param . type :,157
1033,"def _set_handler( <TAB> self, name, handle=None, obj=None, constructor_args=(), constructor_kwds={}): <TAB> if handle is None: <TAB>  <TAB> handle = obj is not None <TAB> if handle: <TAB>  <TAB> handler_class = self.handler_classes[name] <MASK> newhandler = handler_class(obj) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> newhandler = handler_class(*constructor_args, **constructor_kwds) <TAB> else: <TAB>  <TAB> newhandler = None <TAB> self._replace_handler(name, newhandler)",if obj is not None :,137
1034,"def _extract_subtitles(src): <TAB> subtitles = {} <TAB> for caption in try_get(src, lambda x: x[""captions""], list) or []: <TAB>  <TAB> subtitle_url = url_or_none(caption.get(""uri"")) <MASK> lang = caption.get(""language"", ""deu"") <TAB>  <TAB>  <TAB> subtitles.setdefault(lang, []).append( <TAB>  <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""url"": subtitle_url, <TAB>  <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB> ) <TAB> return subtitles",if subtitle_url :,131
1035,"def get_keys(struct, ignore_first_level=False): <TAB> res = [] <TAB> if isinstance(struct, dict): <MASK> keys = [x.split(""("")[0] for x in struct.keys()] <TAB>  <TAB>  <TAB> res.extend(keys) <TAB>  <TAB> for key in struct: <TAB>  <TAB>  <TAB> if key in IGNORED_KEYS: <TAB>  <TAB>  <TAB>  <TAB> logging.debug(""Ignored: %s: %s"", key, struct[key]) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> res.extend(get_keys(struct[key], key in IGNORED_FIRST_LEVEL)) <TAB> elif isinstance(struct, list): <TAB>  <TAB> for item in struct: <TAB>  <TAB>  <TAB> res.extend(get_keys(item)) <TAB> return res",if not ignore_first_level :,178
1036,"def create_dir(path): <TAB> curr_path = None <TAB> for p in path: <TAB>  <TAB> if curr_path is None: <TAB>  <TAB>  <TAB> curr_path = os.path.abspath(p) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> curr_path = os.path.join(curr_path, p) <MASK> os.mkdir(curr_path)",if not os . path . exists ( curr_path ) :,100
1037,"def dataToDumpFile(dumpFile, data): <TAB> try: <TAB>  <TAB> dumpFile.write(data) <TAB>  <TAB> dumpFile.flush() <TAB> except IOError as ex: <TAB>  <TAB> if ""No space left"" in getUnicode(ex): <TAB>  <TAB>  <TAB> errMsg = ""no space left on output device"" <TAB>  <TAB>  <TAB> logger.error(errMsg) <MASK> errMsg = ""permission denied when flushing dump data"" <TAB>  <TAB>  <TAB> logger.error(errMsg) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> errMsg = ( <TAB>  <TAB>  <TAB>  <TAB> ""error occurred when writing dump data to file ('%s')"" % getUnicode(ex) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> logger.error(errMsg)","elif ""Permission denied"" in getUnicode ( ex ) :",176
1038,"def elements(self, top): <TAB> res = [] <TAB> # try: <TAB> # <TAB>  string = ""== %s (%s)"" % (self.name,self.__class__) <TAB> # except AttributeError: <TAB> # <TAB>  string = ""== (%s)"" % (self.__class__,) <TAB> # print(string) <TAB> for part in self.parts: <MASK> res.append(name_or_ref(part, top)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if isinstance(part, Extension): <TAB>  <TAB>  <TAB>  <TAB> res.append(part.base) <TAB>  <TAB>  <TAB> res.extend(part.elements(top)) <TAB> return res","if isinstance ( part , Element ) :",159
1039,"def _parse_param_value(name, datatype, default): <TAB> if datatype == ""bool"": <TAB>  <TAB> if default.lower() == ""true"": <TAB>  <TAB>  <TAB> return True <MASK> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _s = ""{}: Invalid default value '{}' for bool parameter {}"" <TAB>  <TAB>  <TAB> raise SyntaxError(_s.format(self.name, default, p)) <TAB> elif datatype == ""int"": <TAB>  <TAB> if type(default) == int: <TAB>  <TAB>  <TAB> return default <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return int(default, 0) <TAB> elif datatype == ""real"": <TAB>  <TAB> if type(default) == float: <TAB>  <TAB>  <TAB> return default <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return float(default) <TAB> else: <TAB>  <TAB> return str(default)","elif default . lower ( ) == ""false"" :",191
1040,"def dvmethod(c, dx, doAST=False): <TAB> for m in c.get_methods(): <TAB>  <TAB> mx = dx.get_method(m) <TAB>  <TAB> ms = DvMethod(mx) <TAB>  <TAB> ms.process(doAST=doAST) <MASK> assert ms.get_ast() is not None <TAB>  <TAB>  <TAB> assert isinstance(ms.get_ast(), dict) <TAB>  <TAB>  <TAB> assert ""body"" in ms.get_ast() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert ms.get_source() is not None",if doAST :,132
1041,"def _repr_pretty_(self, p, cycle): <TAB> if cycle: <TAB>  <TAB> return ""{{...}"" <TAB> with p.group(2, ""{"", ""}""): <TAB>  <TAB> p.breakable("""") <TAB>  <TAB> for idx, key in enumerate(self._items): <MASK> p.text("","") <TAB>  <TAB>  <TAB>  <TAB> p.breakable() <TAB>  <TAB>  <TAB> value = self._items[key] <TAB>  <TAB>  <TAB> p.pretty(key) <TAB>  <TAB>  <TAB> p.text("": "") <TAB>  <TAB>  <TAB> if isinstance(value, bytes): <TAB>  <TAB>  <TAB>  <TAB> value = trimmed_repr(value) <TAB>  <TAB>  <TAB> p.pretty(value) <TAB>  <TAB> p.breakable("""")",if idx :,159
1042,"def remove_rating(self, songs, librarian): <TAB> count = len(songs) <TAB> if count > 1 and config.getboolean(""browsers"", ""rating_confirm_multiple""): <TAB>  <TAB> parent = qltk.get_menu_item_top_parent(self) <TAB>  <TAB> dialog = ConfirmRateMultipleDialog(parent, _(""_Remove Rating""), count, None) <MASK> return <TAB> reset = [] <TAB> for song in songs: <TAB>  <TAB> if ""~#rating"" in song: <TAB>  <TAB>  <TAB> del song[""~#rating""] <TAB>  <TAB>  <TAB> reset.append(song) <TAB> librarian.changed(reset)",if dialog . run ( ) != Gtk . ResponseType . YES :,159
1043,"def get_or_create_place(self, place_name): <TAB> ""Return the requested place object tuple-packed with a new indicator."" <TAB> LOG.debug(""get_or_create_place: looking for: %s"", place_name) <TAB> for place_handle in self.db.iter_place_handles(): <TAB>  <TAB> place = self.db.get_place_from_handle(place_handle) <TAB>  <TAB> place_title = place_displayer.display(self.db, place) <MASK> return (0, place) <TAB> place = Place() <TAB> place.set_title(place_name) <TAB> place.name = PlaceName(value=place_name) <TAB> self.db.add_place(place, self.trans) <TAB> return (1, place)",if place_title == place_name :,193
1044,def _skip_trivial(constraint_data): <TAB> if skip_trivial_constraints: <MASK> if constraint_data.variables is None: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if constraint_data.body.polynomial_degree() == 0: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False,"if isinstance ( constraint_data , LinearCanonicalRepn ) :",90
1045,"def get_other(self, data, items): <TAB> is_tuple = False <TAB> if type(data) == tuple: <TAB>  <TAB> data = list(data) <TAB>  <TAB> is_tuple = True <TAB> if type(data) == list: <TAB>  <TAB> m_items = items.copy() <TAB>  <TAB> for idx, item in enumerate(items): <TAB>  <TAB>  <TAB> if item < 0: <TAB>  <TAB>  <TAB>  <TAB> m_items[idx] = len(data) - abs(item) <TAB>  <TAB> for i in sorted(set(m_items), reverse=True): <MASK> del data[i] <TAB>  <TAB> if is_tuple: <TAB>  <TAB>  <TAB> return tuple(data) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return data <TAB> else: <TAB>  <TAB> return None",if i < len ( data ) and i > - 1 :,191
1046,"def test_case_insensitivity(self): <TAB> with support.EnvironmentVarGuard() as env: <TAB>  <TAB> env.set(""PYTHONCASEOK"", ""1"") <MASK> self.skipTest(""os.environ changes not reflected in "" ""_os.environ"") <TAB>  <TAB> loader = self.find_module() <TAB>  <TAB> self.assertTrue(hasattr(loader, ""load_module""))","if b""PYTHONCASEOK"" not in _bootstrap . _os . environ :",103
1047,def field_spec(self): <MASK> self.lazy_init_lock_.acquire() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if self.field_spec_ is None: <TAB>  <TAB>  <TAB>  <TAB> self.field_spec_ = FieldSpec() <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self.lazy_init_lock_.release() <TAB> return self.field_spec_,if self . field_spec_ is None :,95
1048,"def reduce(self, f, init): <TAB> for x in range(self._idx, rt.count(self._w_array)): <MASK> return rt.deref(init) <TAB>  <TAB> init = f.invoke([init, rt.nth(self._w_array, rt.wrap(x))]) <TAB> return init",if rt . reduced_QMARK_ ( init ) :,86
1049,"def _find(event: E) -> None: <TAB> # We first check values after the selected value, then all values. <TAB> values = list(self.values) <TAB> for value in values[self._selected_index + 1 :] + values: <TAB>  <TAB> text = fragment_list_to_text(to_formatted_text(value[1])).lower() <MASK> self._selected_index = self.values.index(value) <TAB>  <TAB>  <TAB> return",if text . startswith ( event . data . lower ( ) ) :,118
1050,"def check_permissions(): <TAB> if platform_os() != ""Windows"": <MASK> print(localization.lang_check_permissions[""permissions_granted""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(localization.lang_check_permissions[""permissions_denied""]) <TAB>  <TAB>  <TAB> exit() <TAB> else: <TAB>  <TAB> print(localization.lang_check_permissions[""windows_warning""]) <TAB>  <TAB> exit()",if getuid ( ) == 0 :,101
1051,"def _ProcessName(self, name, dependencies): <TAB> """"""Retrieve a module name from a node name."""""" <TAB> module_name, dot, base_name = name.rpartition(""."") <TAB> if dot: <TAB>  <TAB> if module_name: <MASK> dependencies[module_name].add(base_name) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> dependencies[module_name] = {base_name} <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # If we have a relative import that did not get qualified (usually due <TAB>  <TAB>  <TAB> # to an empty package_name), don't insert module_name='' into the <TAB>  <TAB>  <TAB> # dependencies; we get a better error message if we filter it out here <TAB>  <TAB>  <TAB> # and fail later on. <TAB>  <TAB>  <TAB> logging.warning(""Empty package name: %s"", name)",if module_name in dependencies :,196
1052,"def _load_db(self): <TAB> try: <TAB>  <TAB> with open(self.db) as db: <TAB>  <TAB>  <TAB> content = db.read(8) <TAB>  <TAB>  <TAB> db.seek(0) <TAB>  <TAB>  <TAB> if content == (""Salted__""): <TAB>  <TAB>  <TAB>  <TAB> data = StringIO() <MASK> self.encryptor.decrypt(db, data) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise EncryptionError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Encrpyted credential storage: {}"".format(self.db) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> return json.loads(data.getvalue()) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return json.load(db) <TAB> except: <TAB>  <TAB> return {""creds"": []}",if self . encryptor :,187
1053,"def _parse(self, stream, context): <TAB> obj = [] <TAB> try: <TAB>  <TAB> context_for_subcon = context <TAB>  <TAB> if self.subcon.conflags & self.FLAG_COPY_CONTEXT: <TAB>  <TAB>  <TAB> context_for_subcon = context.__copy__() <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> subobj = self.subcon._parse(stream, context_for_subcon) <MASK> break <TAB>  <TAB>  <TAB> obj.append(subobj) <TAB> except ConstructError as ex: <TAB>  <TAB> raise ArrayError(""missing terminator"", ex) <TAB> return obj","if self . predicate ( subobj , context ) :",150
1054,"def is_active_for_user(self, user): <TAB> is_active = super(AbstractUserFlag, self).is_active_for_user(user) <TAB> if is_active: <TAB>  <TAB> return is_active <TAB> user_ids = self._get_user_ids() <TAB> if hasattr(user, ""pk"") and user.pk in user_ids: <TAB>  <TAB> return True <TAB> if hasattr(user, ""groups""): <TAB>  <TAB> group_ids = self._get_group_ids() <TAB>  <TAB> if group_ids: <TAB>  <TAB>  <TAB> user_groups = set(user.groups.all().values_list(""pk"", flat=True)) <MASK> return True <TAB> return None",if group_ids . intersection ( user_groups ) :,175
1055,"def lookup_member(self, member_name): <TAB> document_choices = self.choices or [] <TAB> for document_choice in document_choices: <TAB>  <TAB> doc_and_subclasses = [document_choice] + document_choice.__subclasses__() <TAB>  <TAB> for doc_type in doc_and_subclasses: <TAB>  <TAB>  <TAB> field = doc_type._fields.get(member_name) <MASK> return field",if field :,101
1056,"def apply(self, db, person): <TAB> families = person.get_parent_family_handle_list() <TAB> if families == []: <TAB>  <TAB> return True <TAB> for family_handle in person.get_parent_family_handle_list(): <TAB>  <TAB> family = db.get_family_from_handle(family_handle) <TAB>  <TAB> if family: <TAB>  <TAB>  <TAB> father_handle = family.get_father_handle() <TAB>  <TAB>  <TAB> mother_handle = family.get_mother_handle() <TAB>  <TAB>  <TAB> if not father_handle: <TAB>  <TAB>  <TAB>  <TAB> return True <MASK> return True <TAB> return False",if not mother_handle :,157
1057,"def init_weights(self): <TAB> for m in self.modules(): <TAB>  <TAB> if isinstance(m, nn.Linear): <TAB>  <TAB>  <TAB> normal_init(m, std=0.01) <TAB>  <TAB> if isinstance(m, nn.Conv3d): <TAB>  <TAB>  <TAB> xavier_init(m, distribution=""uniform"") <MASK> constant_init(m, 1)","if isinstance ( m , nn . BatchNorm3d ) :",99
1058,"def _update_learning_params(self): <TAB> model = self.model <TAB> hparams = self.hparams <TAB> fd = self.runner.feed_dict <TAB> step_num = self.step_num <TAB> if hparams.model_type == ""resnet_tf"": <MASK> lrn_rate = hparams.mom_lrn <TAB>  <TAB> elif step_num < 30000: <TAB>  <TAB>  <TAB> lrn_rate = hparams.mom_lrn / 10 <TAB>  <TAB> elif step_num < 35000: <TAB>  <TAB>  <TAB> lrn_rate = hparams.mom_lrn / 100 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lrn_rate = hparams.mom_lrn / 1000 <TAB>  <TAB> fd[model.lrn_rate] = lrn_rate",if step_num < hparams . lrn_step :,190
1059,"def token_producer(source): <TAB> token = source.read_uint8() <TAB> while token is not None: <TAB>  <TAB> if is_push_data_token(token): <TAB>  <TAB>  <TAB> yield DataToken(read_data(token, source)) <MASK> yield SmallIntegerToken(read_small_integer(token)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield Token(token) <TAB>  <TAB> token = source.read_uint8()",elif is_small_integer ( token ) :,113
1060,"def user_info(oicsrv, userdb, sub, client_id="""", user_info_claims=None): <TAB> identity = userdb[sub] <TAB> if user_info_claims: <TAB>  <TAB> result = {} <TAB>  <TAB> for key, restr in user_info_claims[""claims""].items(): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> result[key] = identity[key] <TAB>  <TAB>  <TAB> except KeyError: <MASK> raise Exception(""Missing property '%s'"" % key) <TAB> else: <TAB>  <TAB> result = identity <TAB> return OpenIDSchema(**result)","if restr == { ""essential"" : True } :",147
1061,"def _helpSlot(self, *args): <TAB> help_text = ""Filters are applied to packets in both direction.\n\n"" <TAB> filter_nb = 0 <TAB> for filter in self._filters: <TAB>  <TAB> help_text += ""{}: {}"".format(filter[""name""], filter[""description""]) <TAB>  <TAB> filter_nb += 1 <MASK> help_text += ""\n\n"" <TAB> QtWidgets.QMessageBox.information(self, ""Help for filters"", help_text)",if len ( self . _filters ) != filter_nb :,124
1062,"def find_user_theme(self, name: str) -> Theme: <TAB> """"""Find a theme named as *name* from latex_theme_path."""""" <TAB> for theme_path in self.theme_paths: <TAB>  <TAB> config_path = path.join(theme_path, name, ""theme.conf"") <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> return UserTheme(name, config_path) <TAB>  <TAB>  <TAB> except ThemeError as exc: <TAB>  <TAB>  <TAB>  <TAB> logger.warning(exc) <TAB> return None",if path . isfile ( config_path ) :,128
1063,"def decompress(self, value): <TAB> if value: <MASK> if value.country_code and value.national_number: <TAB>  <TAB>  <TAB>  <TAB> return [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""+%d"" % value.country_code, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> national_significant_number(value), <TAB>  <TAB>  <TAB>  <TAB> ] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return value.split(""."") <TAB> return [None, """"]",if type ( value ) == PhoneNumber :,111
1064,"def update_prevdoc_status(self, flag): <TAB> for quotation in list(set([d.prevdoc_docname for d in self.get(""items"")])): <MASK> doc = frappe.get_doc(""Quotation"", quotation) <TAB>  <TAB>  <TAB> if doc.docstatus == 2: <TAB>  <TAB>  <TAB>  <TAB> frappe.throw(_(""Quotation {0} is cancelled"").format(quotation)) <TAB>  <TAB>  <TAB> doc.set_status(update=True) <TAB>  <TAB>  <TAB> doc.update_opportunity()",if quotation :,127
1065,"def map(item): <TAB> if item.deleted: <TAB>  <TAB> return <TAB> exploration = exp_fetchers.get_exploration_from_model(item) <TAB> for state_name, state in exploration.states.items(): <TAB>  <TAB> hints_length = len(state.interaction.hints) <MASK> exp_and_state_key = ""%s %s"" % (item.id, state_name.encode(""utf-8"")) <TAB>  <TAB>  <TAB> yield (python_utils.UNICODE(hints_length), exp_and_state_key)",if hints_length > 0 :,136
1066,"def _selected_machines(self, virtual_machines): <TAB> selected_machines = [] <TAB> for machine in virtual_machines: <TAB>  <TAB> if self._args.host and self._args.host == machine.name: <TAB>  <TAB>  <TAB> selected_machines.append(machine) <MASK> selected_machines.append(machine) <TAB>  <TAB> if self.locations and machine.location in self.locations: <TAB>  <TAB>  <TAB> selected_machines.append(machine) <TAB> return selected_machines","if self . tags and self . _tags_match ( machine . tags , self . tags ) :",129
1067,"def _ripple_trim_compositors_move(self, delta): <TAB> comp_ids = self.multi_data.moved_compositors_destroy_ids <TAB> tracks_compositors = _get_tracks_compositors_list() <TAB> track_moved = self.multi_data.track_affected <TAB> for i in range(1, len(current_sequence().tracks) - 1): <TAB>  <TAB> if not track_moved[i - 1]: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> track_comps = tracks_compositors[i - 1] <TAB>  <TAB> for comp in track_comps: <MASK> comp.move(delta)",if comp . destroy_id in comp_ids :,158
1068,"def stream_docker_log(log_stream): <TAB> async for line in log_stream: <TAB>  <TAB> if ""stream"" in line and line[""stream""].strip(): <TAB>  <TAB>  <TAB> logger.debug(line[""stream""].strip()) <MASK> logger.debug(line[""status""].strip()) <TAB>  <TAB> elif ""error"" in line: <TAB>  <TAB>  <TAB> logger.error(line[""error""].strip()) <TAB>  <TAB>  <TAB> raise DockerBuildError","elif ""status"" in line :",108
1069,"def create_keyfile(self, keyfile, size=64, force=False): <TAB> if force or not os.path.exists(keyfile): <TAB>  <TAB> keypath = os.path.dirname(keyfile) <MASK> os.makedirs(keypath) <TAB>  <TAB> subprocess.run( <TAB>  <TAB>  <TAB> [""dd"", ""if=/dev/random"", f""of={keyfile}"", f""bs={size}"", ""count=1""], <TAB>  <TAB>  <TAB> check=True, <TAB>  <TAB>  <TAB> stdout=subprocess.DEVNULL, <TAB>  <TAB>  <TAB> stderr=subprocess.DEVNULL, <TAB>  <TAB> )",if not os . path . exists ( keypath ) :,138
1070,"def calc(self, arg): <TAB> op = arg[""op""] <TAB> if op == ""C"": <TAB>  <TAB> self.clear() <TAB>  <TAB> return str(self.current) <TAB> num = decimal.Decimal(arg[""num""]) <TAB> if self.op: <TAB>  <TAB> if self.op == ""+"": <TAB>  <TAB>  <TAB> self.current += num <TAB>  <TAB> elif self.op == ""-"": <TAB>  <TAB>  <TAB> self.current -= num <MASK> self.current *= num <TAB>  <TAB> elif self.op == ""/"": <TAB>  <TAB>  <TAB> self.current /= num <TAB>  <TAB> self.op = op <TAB> else: <TAB>  <TAB> self.op = op <TAB>  <TAB> self.current = num <TAB> res = str(self.current) <TAB> if op == ""="": <TAB>  <TAB> self.clear() <TAB> return res","elif self . op == ""*"" :",187
1071,"def chop(expr, delta=10.0 ** (-10.0)): <TAB> if isinstance(expr, Real): <TAB>  <TAB> if -delta < expr.get_float_value() < delta: <TAB>  <TAB>  <TAB> return Integer(0) <TAB> elif isinstance(expr, Complex) and expr.is_inexact(): <TAB>  <TAB> real, imag = expr.real, expr.imag <MASK> real = Integer(0) <TAB>  <TAB> if -delta < imag.get_float_value() < delta: <TAB>  <TAB>  <TAB> imag = Integer(0) <TAB>  <TAB> return Complex(real, imag) <TAB> elif isinstance(expr, Expression): <TAB>  <TAB> return Expression(chop(expr.head), *[chop(leaf) for leaf in expr.leaves]) <TAB> return expr",if - delta < real . get_float_value ( ) < delta :,186
1072,"def get_file_sources(): <TAB> global _file_sources <TAB> if _file_sources is None: <TAB>  <TAB> from galaxy.files import ConfiguredFileSources <TAB>  <TAB> file_sources = None <TAB>  <TAB> if os.path.exists(""file_sources.json""): <TAB>  <TAB>  <TAB> file_sources_as_dict = None <TAB>  <TAB>  <TAB> with open(""file_sources.json"", ""r"") as f: <TAB>  <TAB>  <TAB>  <TAB> file_sources_as_dict = json.load(f) <MASK> file_sources = ConfiguredFileSources.from_dict(file_sources_as_dict) <TAB>  <TAB> if file_sources is None: <TAB>  <TAB>  <TAB> ConfiguredFileSources.from_dict([]) <TAB>  <TAB> _file_sources = file_sources <TAB> return _file_sources",if file_sources_as_dict is not None :,196
1073,"def _get_sort_map(tags): <TAB> """"""See TAG_TO_SORT"""""" <TAB> tts = {} <TAB> for name, tag in tags.items(): <MASK> if tag.user: <TAB>  <TAB>  <TAB>  <TAB> tts[name] = ""%ssort"" % name <TAB>  <TAB>  <TAB> if tag.internal: <TAB>  <TAB>  <TAB>  <TAB> tts[""~%s"" % name] = ""~%ssort"" % name <TAB> return tts",if tag . has_sort :,111
1074,"def __init__(self, **kwargs): <TAB> if self.name is None: <TAB>  <TAB> raise RuntimeError(""RenderPrimitive cannot be used directly"") <TAB> self.option_values = {} <TAB> for key, val in kwargs.items(): <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""primitive `{0}' has no option `{1}'"".format(self.name, key) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self.option_values[key] = val <TAB> # set up defaults <TAB> for name, (description, default) in self.options.items(): <TAB>  <TAB> if not name in self.option_values: <TAB>  <TAB>  <TAB> self.option_values[name] = default",if not key in self . options :,162
1075,"def modify_bottle_params(self, output_stride=None): <TAB> if output_stride is not None and output_stride % 2 != 0: <TAB>  <TAB> raise Exception(""output stride must to be even number"") <TAB> if output_stride is None: <TAB>  <TAB> return <TAB> else: <TAB>  <TAB> stride = 2 <TAB>  <TAB> for i, _cfg in enumerate(self.cfg): <TAB>  <TAB>  <TAB> stride = stride * _cfg[-1] <MASK> s = 1 <TAB>  <TAB>  <TAB>  <TAB> self.cfg[i][-1] = s",if stride > output_stride :,134
1076,"def do_query(data, q): <TAB> ret = [] <TAB> if not q: <TAB>  <TAB> return ret <TAB> qkey = q[0] <TAB> for key, value in iterate(data): <TAB>  <TAB> if len(q) == 1: <TAB>  <TAB>  <TAB> if key == qkey: <TAB>  <TAB>  <TAB>  <TAB> ret.append(value) <MASK> ret.extend(do_query(value, q)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if not is_iterable(value): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if key == qkey: <TAB>  <TAB>  <TAB>  <TAB> ret.extend(do_query(value, q[1:])) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> ret.extend(do_query(value, q)) <TAB> return ret",elif is_iterable ( value ) :,185
1077,"def make_shares(self, plaintext): <TAB> share_arrays = [] <TAB> for i, p in enumerate(plaintext): <TAB>  <TAB> share_array = self.make_byte_shares(p) <TAB>  <TAB> for sa in share_array: <MASK> share_arrays.append(array.array(""H"")) <TAB>  <TAB>  <TAB> current_share_array = sa <TAB>  <TAB>  <TAB> current_share_array.append(sa) <TAB> return share_arrays",if i == 0 :,112
1078,"def populate(self, item): <TAB> # log.message('populate: %s', item) <TAB> path = self.getItemPath(item) <TAB> # log.message('populate: path=%s', path) <TAB> value = self.getValue(path) <TAB> for name in sorted(value.__dict__.keys()): <MASK> continue <TAB>  <TAB> child = getattr(value, name, None) <TAB>  <TAB> if hasattr(child, ""__dict__""): <TAB>  <TAB>  <TAB> item.addChild(name, True) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> item.addChild(name, False)","if name [ : 2 ] == ""__"" and name [ - 2 : ] == ""__"" :",151
1079,"def __repr__(self): <TAB> try: <TAB>  <TAB> if self._semlock._is_mine(): <TAB>  <TAB>  <TAB> name = current_process().name <MASK> name += ""|"" + threading.current_thread().name <TAB>  <TAB> elif self._semlock._get_value() == 1: <TAB>  <TAB>  <TAB> name = ""None"" <TAB>  <TAB> elif self._semlock._count() > 0: <TAB>  <TAB>  <TAB> name = ""SomeOtherThread"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = ""SomeOtherProcess"" <TAB> except Exception: <TAB>  <TAB> name = ""unknown"" <TAB> return ""<Lock(owner=%s)>"" % name","if threading . current_thread ( ) . name != ""MainThread"" :",160
1080,"def buffer(self, lines, scroll_end=True, scroll_if_editing=False): <TAB> ""Add data to be displayed in the buffer."" <TAB> self.values.extend(lines) <TAB> if scroll_end: <MASK> self.start_display_at = len(self.values) - len(self._my_widgets) <TAB>  <TAB> elif scroll_if_editing: <TAB>  <TAB>  <TAB> self.start_display_at = len(self.values) - len(self._my_widgets)",if not self . editing :,124
1081,"def warehouses(self) -> tuple: <TAB> from ..repositories import WarehouseBaseRepo <TAB> repos = dict() <TAB> for dep in chain(self.dependencies, [self]): <TAB>  <TAB> if dep.repo is None: <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> for repo in dep.repo.repos: <TAB>  <TAB>  <TAB> if repo.from_config: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> repos[repo.name] = repo <TAB> return tuple(repos.values())","if not isinstance ( dep . repo , WarehouseBaseRepo ) :",124
1082,"def _apply_flag_attrs(src_flag, dest_flag): <TAB> # Use a baseline flag def to get default values for empty data. <TAB> baseline_flag = FlagDef("""", {}, None) <TAB> for name in dir(src_flag): <MASK> continue <TAB>  <TAB> dest_val = getattr(dest_flag, name, None) <TAB>  <TAB> baseline_val = getattr(baseline_flag, name, None) <TAB>  <TAB> if dest_val == baseline_val: <TAB>  <TAB>  <TAB> setattr(dest_flag, name, getattr(src_flag, name))","if name [ : 1 ] == ""_"" :",137
1083,"def out(parent, attr, indent=0): <TAB> val = getattr(parent, attr) <TAB> prefix = ""%s%s:"" % ("" "" * indent, attr.replace(""_"", ""-"")) <TAB> if val is None: <TAB>  <TAB> cli.out(prefix) <TAB> else: <MASK> val = [flag_util.encode_flag_val(c.value) for c in val] <TAB>  <TAB> cli.out(""%s %s"" % (prefix, flag_util.encode_flag_val(val)))","if attr == ""choices"" :",125
1084,"def add_cand_to_check(cands): <TAB> for cand in cands: <TAB>  <TAB> x = cand.creator <TAB>  <TAB> if x is None: <TAB>  <TAB>  <TAB> continue <MASK> # `len(fan_out)` is in order to avoid comparing `x` <TAB>  <TAB>  <TAB> heapq.heappush(cand_funcs, (-x.rank, len(fan_out), x)) <TAB>  <TAB> fan_out[x] += 1",if x not in fan_out :,111
1085,"def task_tree_lines(task=None): <TAB> if task is None: <TAB>  <TAB> task = current_root_task() <TAB> rendered_children = [] <TAB> nurseries = list(task.child_nurseries) <TAB> while nurseries: <TAB>  <TAB> nursery = nurseries.pop() <TAB>  <TAB> nursery_children = _rendered_nursery_children(nursery) <MASK> nested = _render_subtree(""(nested nursery)"", rendered_children) <TAB>  <TAB>  <TAB> nursery_children.append(nested) <TAB>  <TAB> rendered_children = nursery_children <TAB> return _render_subtree(task.name, rendered_children)",if rendered_children :,172
1086,"def lock_workspace(build_dir): <TAB> _BUILDING_LOCK_FILE = "".blade.building.lock"" <TAB> lock_file_fd, ret_code = lock_file(os.path.join(build_dir, _BUILDING_LOCK_FILE)) <TAB> if lock_file_fd == -1: <MASK> console.fatal(""There is already an active building in current workspace."") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> console.fatal(""Lock exception, please try it later."") <TAB> return lock_file_fd",if ret_code == errno . EAGAIN :,136
1087,"def test_list(self): <TAB> self._create_locations() <TAB> response = self.client.get(self.geojson_boxedlocation_list_url) <TAB> self.assertEqual(response.status_code, 200) <TAB> self.assertEqual(len(response.data[""features""]), 2) <TAB> for feature in response.data[""features""]: <TAB>  <TAB> self.assertIn(""bbox"", feature) <TAB>  <TAB> fid = feature[""id""] <TAB>  <TAB> if fid == 1: <TAB>  <TAB>  <TAB> self.assertEqual(feature[""bbox""], self.bl1.bbox_geometry.extent) <MASK> self.assertEqual(feature[""bbox""], self.bl2.bbox_geometry.extent) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.fail(""Unexpected id: {0}"".format(fid)) <TAB> BoxedLocation.objects.all().delete()",elif fid == 2 :,196
1088,"def result(): <TAB> # ""global"" does not work here... <TAB> R, V = rays, virtual_rays <TAB> if V is not None: <TAB>  <TAB> if normalize: <TAB>  <TAB>  <TAB> V = normalize_rays(V, lattice) <TAB>  <TAB> if check: <TAB>  <TAB>  <TAB> R = PointCollection(V, lattice) <TAB>  <TAB>  <TAB> V = PointCollection(V, lattice) <TAB>  <TAB>  <TAB> d = lattice.dimension() <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""virtual rays must be linearly "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""independent and with other rays span the ambient space."" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return RationalPolyhedralFan(cones, R, lattice, is_complete, V)",if len ( V ) != d - R . dim ( ) or ( R + V ) . dim ( ) != d :,194
1089,"def search_host(self, search_string): <TAB> results = [] <TAB> for host_entry in self.config_data: <TAB>  <TAB> if host_entry.get(""type"") != ""entry"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if host_entry.get(""host"") == ""*"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> searchable_information = host_entry.get(""host"") <TAB>  <TAB> for key, value in six.iteritems(host_entry.get(""options"")): <MASK> value = "" "".join(value) <TAB>  <TAB>  <TAB> if isinstance(value, int): <TAB>  <TAB>  <TAB>  <TAB> value = str(value) <TAB>  <TAB>  <TAB> searchable_information += "" "" + value <TAB>  <TAB> if search_string in searchable_information: <TAB>  <TAB>  <TAB> results.append(host_entry) <TAB> return results","if isinstance ( value , list ) :",191
1090,"def test_async_iterator(app): <TAB> async with new_stream(app) as stream: <TAB>  <TAB> for i in range(100): <TAB>  <TAB>  <TAB> await stream.channel.deliver(message(key=i, value=i)) <TAB>  <TAB> received = 0 <TAB>  <TAB> async for value in stream: <TAB>  <TAB>  <TAB> assert value == received <TAB>  <TAB>  <TAB> received += 1 <MASK> break <TAB>  <TAB> assert await channel_empty(stream.channel)",if received >= 100 :,113
1091,"def has_google_credentials(): <TAB> global _HAS_GOOGLE_CREDENTIALS <TAB> if _HAS_GOOGLE_CREDENTIALS is None: <TAB>  <TAB> provider = Provider(""google"") <MASK> _HAS_GOOGLE_CREDENTIALS = False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _HAS_GOOGLE_CREDENTIALS = True <TAB> return _HAS_GOOGLE_CREDENTIALS",if provider . get_access_key ( ) is None or provider . get_secret_key ( ) is None :,102
1092,"def __cmp__(self, other): <TAB> if isinstance(other, date) or isinstance(other, datetime): <TAB>  <TAB> a = self._d.getTime() <TAB>  <TAB> b = other._d.getTime() <TAB>  <TAB> if a < b: <TAB>  <TAB>  <TAB> return -1 <MASK> return 0 <TAB> else: <TAB>  <TAB> raise TypeError(""expected date or datetime object"") <TAB> return 1",elif a == b :,98
1093,"def validate_weight(self, weight): <TAB> try: <TAB>  <TAB> add_acl_to_obj(self.context[""user_acl""], self.category) <TAB> except AttributeError: <TAB>  <TAB> return weight  # don't validate weight further if category failed <TAB> if weight > self.category.acl.get(""can_pin_threads"", 0): <MASK> raise ValidationError( <TAB>  <TAB>  <TAB>  <TAB> _( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""You don't have permission to pin threads globally "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""in this category."" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValidationError( <TAB>  <TAB>  <TAB>  <TAB> _(""You don't have permission to pin threads in this category."") <TAB>  <TAB>  <TAB> ) <TAB> return weight",if weight == 2 :,177
1094,"def effective(line): <TAB> for b in line: <TAB>  <TAB> if not b.cond: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> val = 5 <MASK> if b.ignore: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> b.ignore -= 1 <TAB>  <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return (b, True) <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> return (b, False) <TAB> return",if val :,118
1095,"def wheelEvent(self, event): <TAB> """"""Handle a wheel event."""""" <TAB> if QtCore.Qt.ControlModifier & event.modifiers(): <TAB>  <TAB> d = {""c"": self.leo_c} <TAB>  <TAB> if isQt5: <TAB>  <TAB>  <TAB> point = event.angleDelta() <TAB>  <TAB>  <TAB> delta = point.y() or point.x() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> delta = event.delta() <MASK> zoom_out(d) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> zoom_in(d) <TAB>  <TAB> event.accept() <TAB>  <TAB> return <TAB> QtWidgets.QTextBrowser.wheelEvent(self, event)",if delta < 0 :,160
1096,"def test_evname_in_mp_events_testcases(): <TAB> ok = True <TAB> for evname in ins.mp_events: <TAB>  <TAB> if evname == ""version"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for i, args in enumerate(ins.mp_events[evname][""test_cases""]): <MASK> msg = ""Error, for evname %s the testase #%d does not match evname"" <TAB>  <TAB>  <TAB>  <TAB> print(msg % (evname, i)) <TAB>  <TAB>  <TAB>  <TAB> ok = False <TAB> if ok: <TAB>  <TAB> print(""test_evname_in_mp_events_testcases: passed"")",if evname != args [ 0 ] :,156
1097,"def check_database(): <TAB> if len(EmailAddress.objects.all()) > 0: <TAB>  <TAB> print( <TAB>  <TAB>  <TAB> ""Are you sure you want to wipe the existing development database and reseed it? (Y/N)"" <TAB>  <TAB> ) <MASK> destroy_database() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> else: <TAB>  <TAB> return True","if raw_input ( ) . lower ( ) == ""y"" :",97
1098,"def _get_requested_databases(self): <TAB> """"""Returns a list of databases requested, not including ignored dbs"""""" <TAB> requested_databases = [] <TAB> if (self._requested_namespaces is not None) and (self._requested_namespaces != []): <TAB>  <TAB> for requested_namespace in self._requested_namespaces: <TAB>  <TAB>  <TAB> if requested_namespace[0] is ""*"": <TAB>  <TAB>  <TAB>  <TAB> return [] <MASK> requested_databases.append(requested_namespace[0]) <TAB> return requested_databases",elif requested_namespace [ 0 ] not in IGNORE_DBS :,131
1099,"def decorated(self, *args, **kwargs): <TAB> start_time = time.perf_counter() <TAB> stderr = """" <TAB> saved_exception = None <TAB> try: <TAB>  <TAB> yield from fn(self, *args, **kwargs) <TAB> except GitSavvyError as e: <TAB>  <TAB> stderr = e.stderr <TAB>  <TAB> saved_exception = e <TAB> finally: <TAB>  <TAB> end_time = time.perf_counter() <TAB>  <TAB> util.debug.log_git(args, None, ""<SNIP>"", stderr, end_time - start_time) <MASK> raise saved_exception from None",if saved_exception :,146
1100,"def is_suppressed_warning( <TAB> type: str, subtype: str, suppress_warnings: List[str]) -> bool: <TAB> """"""Check the warning is suppressed or not."""""" <TAB> if type is None: <TAB>  <TAB> return False <TAB> for warning_type in suppress_warnings: <TAB>  <TAB> if ""."" in warning_type: <TAB>  <TAB>  <TAB> target, subtarget = warning_type.split(""."", 1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> target, subtarget = warning_type, None <MASK> if ( <TAB>  <TAB>  <TAB>  <TAB> subtype is None <TAB>  <TAB>  <TAB>  <TAB> or subtarget is None <TAB>  <TAB>  <TAB>  <TAB> or subtarget == subtype <TAB>  <TAB>  <TAB>  <TAB> or subtarget == ""*"" <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if target == type :,178
1101,"def talk(self, words): <TAB> if self.writeSentence(words) == 0: <TAB>  <TAB> return <TAB> r = [] <TAB> while 1: <TAB>  <TAB> i = self.readSentence() <TAB>  <TAB> if len(i) == 0: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> reply = i[0] <TAB>  <TAB> attrs = {} <TAB>  <TAB> for w in i[1:]: <TAB>  <TAB>  <TAB> j = w.find(""="", 1) <TAB>  <TAB>  <TAB> if j == -1: <TAB>  <TAB>  <TAB>  <TAB> attrs[w] = """" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> attrs[w[:j]] = w[j + 1 :] <TAB>  <TAB> r.append((reply, attrs)) <MASK> return r","if reply == ""!done"" :",169
1102,"def encrypt(self, plaintext): <TAB> encrypted = [] <TAB> for p in _string_to_bytes(plaintext): <MASK> self._remaining_block = self._aes.encrypt(self._last_precipherblock) <TAB>  <TAB>  <TAB> self._last_precipherblock = [] <TAB>  <TAB> precipherbyte = self._remaining_block.pop(0) <TAB>  <TAB> self._last_precipherblock.append(precipherbyte) <TAB>  <TAB> cipherbyte = p ^ precipherbyte <TAB>  <TAB> encrypted.append(cipherbyte) <TAB> return _bytes_to_string(encrypted)",if len ( self . _remaining_block ) == 0 :,146
1103,"def find_symbol(self, r, globally=False): <TAB> query = self.view.substr(self.view.word(r)) <TAB> fname = self.view.file_name().replace(""\\"", ""/"") <TAB> locations = self.view.window().lookup_symbol_in_index(query) <TAB> if not locations: <TAB>  <TAB> return <TAB> try: <MASK> location = [hit[2] for hit in locations if fname.endswith(hit[1])][0] <TAB>  <TAB>  <TAB> return location[0] - 1, location[1] - 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # TODO: There might be many symbols with the same name. <TAB>  <TAB>  <TAB> return locations[0] <TAB> except IndexError: <TAB>  <TAB> return",if not globally :,172
1104,"def __getslice__(self, i, j): <TAB> try: <MASK> # handle the case where the right bound is unspecified <TAB>  <TAB>  <TAB> j = len(self) <TAB>  <TAB> if i < 0 or j < 0: <TAB>  <TAB>  <TAB> raise dns.exception.FormError <TAB>  <TAB> # If it's not an empty slice, access left and right bounds <TAB>  <TAB> # to make sure they're valid <TAB>  <TAB> if i != j: <TAB>  <TAB>  <TAB> super(WireData, self).__getitem__(i) <TAB>  <TAB>  <TAB> super(WireData, self).__getitem__(j - 1) <TAB>  <TAB> return WireData(super(WireData, self).__getslice__(i, j)) <TAB> except IndexError: <TAB>  <TAB> raise dns.exception.FormError",if j == sys . maxint :,181
1105,"def main(): <TAB> r = redis.StrictRedis() <TAB> curr_memory = prev_memory = r.info()[""used_memory""] <TAB> while True: <MASK> print( <TAB>  <TAB>  <TAB>  <TAB> ""Delta Memory : %d, Total Memory : %d"" <TAB>  <TAB>  <TAB>  <TAB> % ((curr_memory - prev_memory), curr_memory) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> time.sleep(1) <TAB>  <TAB> prev_memory = curr_memory <TAB>  <TAB> curr_memory = r.info()[""used_memory""]",if prev_memory != curr_memory :,130
1106,"def _visit(self, func): <TAB> fname = func[0] <TAB> if fname in self._flags: <TAB>  <TAB> if self._flags[fname] == 1: <TAB>  <TAB>  <TAB> logger.critical(""Fatal error! network ins not Dag."") <TAB>  <TAB>  <TAB> import sys <TAB>  <TAB>  <TAB> sys.exit(-1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return <TAB> else: <MASK> self._flags[fname] = 1 <TAB>  <TAB> for output in func[3]: <TAB>  <TAB>  <TAB> for f in self._orig: <TAB>  <TAB>  <TAB>  <TAB> for input in f[2]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if output == input: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._visit(f) <TAB> self._flags[fname] = 2 <TAB> self._sorted.insert(0, func)",if fname not in self . _flags :,188
1107,"def urls(self, version=None): <TAB> """"""Returns all URLS that are mapped to this interface"""""" <TAB> urls = [] <TAB> for _base_url, routes in self.api.http.routes.items(): <TAB>  <TAB> for url, methods in routes.items(): <TAB>  <TAB>  <TAB> for _method, versions in methods.items(): <TAB>  <TAB>  <TAB>  <TAB> for interface_version, interface in versions.items(): <MASK> if not url in urls: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> urls.append( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> (""/v{0}"".format(version) if version else """") + url <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return urls",if interface_version == version and interface == self :,169
1108,"def _handle_data(self, text): <TAB> if self._translate: <MASK> self._data.append(text) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._translate = False <TAB>  <TAB>  <TAB> self._data = [] <TAB>  <TAB>  <TAB> self._comments = []","if not text . startswith ( ""gtk-"" ) :",74
1109,"def set_dir_modes(self, dirname, mode): <TAB> if not self.is_chmod_supported(): <TAB>  <TAB> return <TAB> for dirpath, dirnames, fnames in os.walk(dirname): <MASK> continue <TAB>  <TAB> log.info(""changing mode of %s to %o"", dirpath, mode) <TAB>  <TAB> if not self.dry_run: <TAB>  <TAB>  <TAB> os.chmod(dirpath, mode)",if os . path . islink ( dirpath ) :,105
1110,"def language(self): <TAB> if self.lang_data: <TAB>  <TAB> lang_data = [s if s != ""None"" else None for s in self.lang_data] <MASK> return Language(lang_data[0], country=lang_data[1], script=lang_data[2])",if lang_data [ 0 ] :,80
1111,"def _addItemToLayout(self, sample, label): <TAB> col = self.layout.columnCount() <TAB> row = self.layout.rowCount() <TAB> if row: <TAB>  <TAB> row -= 1 <TAB> nCol = self.columnCount * 2 <TAB> # FIRST ROW FULL <TAB> if col == nCol: <TAB>  <TAB> for col in range(0, nCol, 2): <TAB>  <TAB>  <TAB> # FIND RIGHT COLUMN <MASK> break <TAB>  <TAB> if col + 2 == nCol: <TAB>  <TAB>  <TAB> # MAKE NEW ROW <TAB>  <TAB>  <TAB> col = 0 <TAB>  <TAB>  <TAB> row += 1 <TAB> self.layout.addItem(sample, row, col) <TAB> self.layout.addItem(label, row, col + 1)","if not self . layout . itemAt ( row , col ) :",185
1112,"def align_comments(tlist): <TAB> tidx, token = tlist.token_next_by(i=sql.Comment) <TAB> while token: <TAB>  <TAB> pidx, prev_ = tlist.token_prev(tidx) <MASK> tlist.group_tokens(sql.TokenList, pidx, tidx, extend=True) <TAB>  <TAB>  <TAB> tidx = pidx <TAB>  <TAB> tidx, token = tlist.token_next_by(i=sql.Comment, idx=tidx)","if isinstance ( prev_ , sql . TokenList ) :",130
1113,"def hook_GetVariable(ql, address, params): <TAB> if params[""VariableName""] in ql.env: <TAB>  <TAB> var = ql.env[params[""VariableName""]] <TAB>  <TAB> read_len = read_int64(ql, params[""DataSize""]) <TAB>  <TAB> if params[""Attributes""] != 0: <TAB>  <TAB>  <TAB> write_int64(ql, params[""Attributes""], 0) <TAB>  <TAB> write_int64(ql, params[""DataSize""], len(var)) <MASK> return EFI_BUFFER_TOO_SMALL <TAB>  <TAB> if params[""Data""] != 0: <TAB>  <TAB>  <TAB> ql.mem.write(params[""Data""], var) <TAB>  <TAB> return EFI_SUCCESS <TAB> return EFI_NOT_FOUND",if read_len < len ( var ) :,177
1114,"def _PromptMySQL(self, config): <TAB> """"""Prompts the MySQL configuration, retrying if the configuration is invalid."""""" <TAB> while True: <TAB>  <TAB> self._PromptMySQLOnce(config) <TAB>  <TAB> if self._CheckMySQLConnection(): <TAB>  <TAB>  <TAB> print(""Successfully connected to MySQL with the given configuration."") <TAB>  <TAB>  <TAB> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""Error: Could not connect to MySQL with the given configuration."") <TAB>  <TAB>  <TAB> retry = RetryBoolQuestion(""Do you want to retry MySQL configuration?"", True) <MASK> raise ConfigInitError()",if not retry :,136
1115,"def split_long_line_with_indent(line, max_per_line, indent): <TAB> """"""Split the `line` so that it doesn't go over `max_per_line` and adds `indent` to new lines."""""" <TAB> words = line.split("" "") <TAB> lines = [] <TAB> current_line = words[0] <TAB> for word in words[1:]: <MASK> lines.append(current_line) <TAB>  <TAB>  <TAB> current_line = "" "" * indent + word <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> current_line = f""{current_line} {word}"" <TAB> lines.append(current_line) <TAB> return ""\n"".join(lines)","if len ( f""{current_line} {word}"" ) > max_per_line :",176
1116,"def gen_cli(docs_dir): <TAB> with open(os.path.join(docs_dir, ""CLI_template.md""), ""r"") as cli_temp_file: <TAB>  <TAB> temp_lines = cli_temp_file.readlines() <TAB> lines = [] <TAB> for line in temp_lines: <TAB>  <TAB> matched = re.match(r""{onnx-tf.*}"", line) <MASK> command = matched.string.strip()[1:-1] <TAB>  <TAB>  <TAB> output = subprocess.check_output(command.split("" "")).decode(""UTF-8"") <TAB>  <TAB>  <TAB> lines.append(output) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lines.append(line) <TAB> with open(os.path.join(docs_dir, ""CLI.md""), ""w"") as cli_file: <TAB>  <TAB> cli_file.writelines(lines)",if matched :,200
1117,"def read(self, size=None): <TAB> if size == 0: <TAB>  <TAB> return """" <TAB> data = list() <TAB> while size is None or size > 0: <TAB>  <TAB> line = self.readline(size or -1) <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB> break <MASK> size -= len(line) <TAB>  <TAB> data.append(line) <TAB> return """".join(data)",if size is not None :,101
1118,"def _get_format_and_pattern(file_path): <TAB> file_path = Path(file_path) <TAB> with file_path.open() as f: <TAB>  <TAB> first_line = f.readline().strip() <TAB>  <TAB> match = re.match(r""format *: *(.+)"", first_line) <MASK> return ""gztar"", first_line, 1 <TAB>  <TAB> return match.group(1), f.readline().strip(), 2",if match is None :,111
1119,"def remove_old_snapshot(install_dir): <TAB> logging.info(""Removing any old files in {}"".format(install_dir)) <TAB> for file in glob.glob(""{}/*"".format(install_dir)): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if os.path.isfile(file): <TAB>  <TAB>  <TAB>  <TAB> os.unlink(file) <MASK> shutil.rmtree(file) <TAB>  <TAB> except Exception as error: <TAB>  <TAB>  <TAB> logging.error(""Error: {}"".format(error)) <TAB>  <TAB>  <TAB> sys.exit(1)",elif os . path . isdir ( file ) :,133
1120,"def _test_forever(self, tests): <TAB> while True: <TAB>  <TAB> for test_name in tests: <TAB>  <TAB>  <TAB> yield test_name <TAB>  <TAB>  <TAB> if self.bad: <TAB>  <TAB>  <TAB>  <TAB> return <MASK> return",if self . ns . fail_env_changed and self . environment_changed :,76
1121,"def _swig_extract_dependency_files(self, src): <TAB> dep = [] <TAB> for line in open(src): <TAB>  <TAB> if line.startswith(""#include"") or line.startswith(""%include""): <TAB>  <TAB>  <TAB> line = line.split("" "")[1].strip(""""""'""\r\n"""""") <MASK> dep.append(line) <TAB> return [i for i in dep if os.path.exists(i)]","if not ( ""<"" in line or line in dep ) :",111
1122,"def update_service_key(kid, name=None, metadata=None): <TAB> try: <TAB>  <TAB> with db_transaction(): <TAB>  <TAB>  <TAB> key = db_for_update(ServiceKey.select().where(ServiceKey.kid == kid)).get() <MASK> key.name = name <TAB>  <TAB>  <TAB> if metadata is not None: <TAB>  <TAB>  <TAB>  <TAB> key.metadata.update(metadata) <TAB>  <TAB>  <TAB> key.save() <TAB> except ServiceKey.DoesNotExist: <TAB>  <TAB> raise ServiceKeyDoesNotExist",if name is not None :,127
1123,"def range(self, dimension, data_range=True, dimension_range=True): <TAB> if self.nodes and dimension in self.nodes.dimensions(): <TAB>  <TAB> node_range = self.nodes.range(dimension, data_range, dimension_range) <MASK> path_range = self._edgepaths.range(dimension, data_range, dimension_range) <TAB>  <TAB>  <TAB> return max_range([node_range, path_range]) <TAB>  <TAB> return node_range <TAB> return super(Graph, self).range(dimension, data_range, dimension_range)",if self . _edgepaths :,137
1124,"def handler(chan, host, port): <TAB> sock = socket() <TAB> try: <TAB>  <TAB> sock.connect((host, port)) <TAB> except Exception as e: <TAB>  <TAB> if verbose == True: <TAB>  <TAB>  <TAB> print(e) <TAB>  <TAB> return <TAB> while True: <TAB>  <TAB> r, w, x = select.select([sock, chan], [], []) <TAB>  <TAB> if sock in r: <TAB>  <TAB>  <TAB> data = sock.recv(1024) <MASK> break <TAB>  <TAB>  <TAB> chan.send(data) <TAB>  <TAB> if chan in r: <TAB>  <TAB>  <TAB> data = chan.recv(1024) <TAB>  <TAB>  <TAB> if len(data) == 0: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> sock.send(data) <TAB> chan.close() <TAB> sock.close()",if len ( data ) == 0 :,190
1125,"def output_layer(self, features, **kwargs): <TAB> """"""Project features to the vocabulary size."""""" <TAB> if self.adaptive_softmax is None: <TAB>  <TAB> # project back to size of vocabulary <MASK> return F.linear(features, self.embed_tokens.weight) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return F.linear(features, self.embed_out) <TAB> else: <TAB>  <TAB> return features",if self . share_input_output_embed :,108
1126,"def generate(self, dest, vars): <TAB> util.ensure_dir(dest) <TAB> for relpath, src, template in self._file_templates: <TAB>  <TAB> file_dest = os.path.join(dest, relpath) <TAB>  <TAB> util.ensure_dir(os.path.dirname(file_dest)) <MASK> shutil.copyfile(src, file_dest) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _render_template(template, vars, file_dest)",if template is None :,115
1127,"def _py_matching_callback(self, context, result, sender, device): <TAB> d = HIDDevice.get_device(c_void_p(device)) <TAB> if d not in self.devices: <TAB>  <TAB> self.devices.add(d) <TAB>  <TAB> for x in self.matching_observers: <MASK> x.device_discovered(d)","if hasattr ( x , ""device_discovered"" ) :",102
1128,"def urlquote(*args, **kwargs): <TAB> new_kwargs = dict(kwargs) <TAB> if not PY3: <TAB>  <TAB> new_kwargs = dict(kwargs) <MASK> del new_kwargs[""encoding""] <TAB>  <TAB> if ""errors"" in kwargs: <TAB>  <TAB>  <TAB> del new_kwargs[""errors""] <TAB> return quote(*args, **new_kwargs)","if ""encoding"" in new_kwargs :",93
1129,"def Set(self, attr, value): <TAB> hook = getattr(self, ""_set_%s"" % attr, None) <TAB> if hook: <TAB>  <TAB> # If there is a set hook we must use the context manager. <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Can only update attribute %s using the context manager."" % attr <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if attr not in self._pending_hooks: <TAB>  <TAB>  <TAB> self._pending_hooks.append(attr) <TAB>  <TAB> self._pending_parameters[attr] = value <TAB> else: <TAB>  <TAB> super(Configuration, self).Set(attr, value)",if self . _lock > 0 :,150
1130,"def on_profiles_loaded(self, profiles): <TAB> cb = self.builder.get_object(""cbProfile"") <TAB> model = cb.get_model() <TAB> model.clear() <TAB> for f in profiles: <TAB>  <TAB> name = f.get_basename() <TAB>  <TAB> if name.endswith("".mod""): <TAB>  <TAB>  <TAB> continue <MASK> name = name[0:-11] <TAB>  <TAB> model.append((name, f, None)) <TAB> cb.set_active(0)","if name . endswith ( "".sccprofile"" ) :",122
1131,"def get_eval_task(self, worker_id): <TAB> """"""Return next evaluation (task_id, Task) tuple"""""" <TAB> with self._lock: <MASK> return -1, None <TAB>  <TAB> self._task_id += 1 <TAB>  <TAB> task = self._eval_todo.pop() <TAB>  <TAB> self._doing[self._task_id] = (worker_id, task, time.time()) <TAB>  <TAB> return self._task_id, task",if not self . _eval_todo :,115
1132,"def queries(self): <TAB> if DEV: <TAB>  <TAB> cmd = ShellCommand(""docker"", ""ps"", ""-qf"", ""name=%s"" % self.path.k8s) <MASK> if not cmd.stdout.strip(): <TAB>  <TAB>  <TAB>  <TAB> log_cmd = ShellCommand( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""docker"", ""logs"", self.path.k8s, stderr=subprocess.STDOUT <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> if log_cmd.check(f""docker logs for {self.path.k8s}""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> print(cmd.stdout) <TAB>  <TAB>  <TAB>  <TAB> pytest.exit(f""container failed to start for {self.path.k8s}"") <TAB> return ()","if not cmd . check ( f""docker check for {self.path.k8s}"" ) :",188
1133,"def disjoined(data): <TAB> # create marginalized distributions and multiple them together <TAB> data_disjoined = None <TAB> dim = len(data.shape) <TAB> for d in range(dim): <TAB>  <TAB> axes = list(range(dim)) <TAB>  <TAB> axes.remove(d) <TAB>  <TAB> data1d = multisum(data, axes) <TAB>  <TAB> shape = [1 for k in range(dim)] <TAB>  <TAB> shape[d] = len(data1d) <TAB>  <TAB> data1d = data1d.reshape(tuple(shape)) <MASK> data_disjoined = data1d <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> data_disjoined = data_disjoined * data1d <TAB> return data_disjoined",if d == 0 :,176
1134,"def safe_repr(val): <TAB> try: <MASK> # We special case dicts to have a sorted repr. This makes testing <TAB>  <TAB>  <TAB> # significantly easier <TAB>  <TAB>  <TAB> val = _obj_with_safe_repr(val) <TAB>  <TAB> ret = repr(val) <TAB>  <TAB> if six.PY2: <TAB>  <TAB>  <TAB> ret = ret.decode(""utf-8"") <TAB> except UnicodeEncodeError: <TAB>  <TAB> ret = red(""a %r that cannot be represented"" % type(val)) <TAB> else: <TAB>  <TAB> ret = green(ret) <TAB> return ret","if isinstance ( val , dict ) :",138
1135,"def wrapper(*args, **kwargs): <TAB> resp = view_func(*args, **kwargs) <TAB> if isinstance(resp, dict): <TAB>  <TAB> ctx_params = request.environ.get(""webrec.template_params"") <MASK> resp.update(ctx_params) <TAB>  <TAB> template = self.jinja_env.jinja_env.get_or_select_template(template_name) <TAB>  <TAB> return template.render(**resp) <TAB> else: <TAB>  <TAB> return resp",if ctx_params :,117
1136,"def post(self, request, *args, **kwargs): <TAB> contact_id = kwargs.get(""pk"") <TAB> self.object = get_object_or_404(Contact, id=contact_id) <TAB> if ( <TAB>  <TAB> self.request.user.role != ""ADMIN"" <TAB>  <TAB> and not self.request.user.is_superuser <TAB>  <TAB> and self.request.user != self.object.created_by <TAB> ) or self.object.company != self.request.company: <TAB>  <TAB> raise PermissionDenied <TAB> else: <TAB>  <TAB> if self.object.address_id: <TAB>  <TAB>  <TAB> self.object.address.delete() <TAB>  <TAB> self.object.delete() <MASK> return JsonResponse({""error"": False}) <TAB>  <TAB> return redirect(""contacts:list"")",if self . request . is_ajax ( ) :,189
1137,"def escape(text, newline=False): <TAB> """"""Escape special html characters."""""" <TAB> if isinstance(text, str): <TAB>  <TAB> if ""&"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""&"", ""&amp;"") <TAB>  <TAB> if "">"" in text: <TAB>  <TAB>  <TAB> text = text.replace("">"", ""&gt;"") <MASK> text = text.replace(""<"", ""&lt;"") <TAB>  <TAB> if '""' in text: <TAB>  <TAB>  <TAB> text = text.replace('""', ""&quot;"") <TAB>  <TAB> if ""'"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""'"", ""&quot;"") <TAB>  <TAB> if newline: <TAB>  <TAB>  <TAB> if ""\n"" in text: <TAB>  <TAB>  <TAB>  <TAB> text = text.replace(""\n"", ""<br>"") <TAB> return text","if ""<"" in text :",170
1138,"def everythingIsUnicode(d): <TAB> """"""Takes a dictionary, recursively verifies that every value is unicode"""""" <TAB> for k, v in d.iteritems(): <TAB>  <TAB> if isinstance(v, dict) and k != ""headers"": <MASK> return False <TAB>  <TAB> elif isinstance(v, list): <TAB>  <TAB>  <TAB> for i in v: <TAB>  <TAB>  <TAB>  <TAB> if isinstance(i, dict) and not everythingIsUnicode(i): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB>  <TAB> elif isinstance(i, _bytes): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> elif isinstance(v, _bytes): <TAB>  <TAB>  <TAB> return False <TAB> return True",if not everythingIsUnicode ( v ) :,158
1139,"def fill(self): <TAB> try: <TAB>  <TAB> while ( <TAB>  <TAB>  <TAB> not self.stopping.wait(self.sample_wait) <TAB>  <TAB>  <TAB> and len(self.queue) < self.queue.maxlen <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> self.queue.append(self.parent._read()) <MASK> self.parent._fire_events() <TAB>  <TAB> self.full.set() <TAB>  <TAB> while not self.stopping.wait(self.sample_wait): <TAB>  <TAB>  <TAB> self.queue.append(self.parent._read()) <TAB>  <TAB>  <TAB> if isinstance(self.parent, EventsMixin): <TAB>  <TAB>  <TAB>  <TAB> self.parent._fire_events() <TAB> except ReferenceError: <TAB>  <TAB> # Parent is dead; time to die! <TAB>  <TAB> pass","if self . partial and isinstance ( self . parent , EventsMixin ) :",190
1140,"def _SetListviewTextItems(self, items): <TAB> self.listview.DeleteAllItems() <TAB> index = -1 <TAB> for item in items: <TAB>  <TAB> index = self.listview.InsertItem(index + 1, item[0]) <TAB>  <TAB> data = item[1] <MASK> data = """" <TAB>  <TAB> self.listview.SetItemText(index, 1, data)",if data is None :,99
1141,"def process_request(self, request): <TAB> for old, new in self.names_name: <TAB>  <TAB> request.uri = request.uri.replace(old, new) <TAB>  <TAB> if is_text_payload(request) and request.body: <TAB>  <TAB>  <TAB> body = six.ensure_str(request.body) <MASK> request.body = body.replace(old, new) <TAB> return request",if old in body :,103
1142,"def serialize(cls, value, *args, **kwargs): <TAB> if value is None: <TAB>  <TAB> return """" <TAB> value_as_string = six.text_type(value) <TAB> if SHOULD_NOT_USE_LOCALE: <TAB>  <TAB> return value_as_string <TAB> else: <TAB>  <TAB> grouping = kwargs.get(""grouping"", None) <TAB>  <TAB> has_decimal_places = value_as_string.find(""."") != -1 <MASK> string_format = ""%d"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> decimal_places = len(value_as_string.split(""."")[1]) <TAB>  <TAB>  <TAB> string_format = ""%.{}f"".format(decimal_places) <TAB>  <TAB> return locale.format(string_format, value, grouping=grouping)",if not has_decimal_places :,185
1143,"def review_link(request, path_obj): <TAB> try: <MASK> if check_permission(""translate"", request): <TAB>  <TAB>  <TAB>  <TAB> text = _(""Review Suggestions"") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> text = _(""View Suggestions"") <TAB>  <TAB>  <TAB> return { <TAB>  <TAB>  <TAB>  <TAB> ""href"": dispatch.translate( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> request, path_obj.pootle_path, matchnames=[""hassuggestion""] <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB>  <TAB> ""text"": text, <TAB>  <TAB>  <TAB> } <TAB> except IOError: <TAB>  <TAB> pass",if path_obj . has_suggestions ( ) :,146
1144,"def _migrate_key(self, key): <TAB> """"""migrate key from old .dat file"""""" <TAB> key_path = os.path.join(self.home_path, ""keys.dat"") <TAB> if os.path.exists(key_path): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> key_data = json.loads(open(key_path, ""rb"").read()) <MASK> self.add_key(key, key_data.get(key)) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> self.error(f""Corrupt key file. Manual migration of '{key}' required."")",if key_data . get ( key ) :,148
1145,"def gather_callback_args(self, obj, callbacks): <TAB> session = sa.orm.object_session(obj) <TAB> for callback in callbacks: <TAB>  <TAB> backref = callback.backref <TAB>  <TAB> root_objs = getdotattr(obj, backref) if backref else obj <TAB>  <TAB> if root_objs: <MASK> root_objs = [root_objs] <TAB>  <TAB>  <TAB> with session.no_autoflush: <TAB>  <TAB>  <TAB>  <TAB> for root_obj in root_objs: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if root_obj: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> args = self.get_callback_args(root_obj, callback) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if args: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield args","if not isinstance ( root_objs , Iterable ) :",182
1146,"def GetDefFile(self, gyp_to_build_path): <TAB> """"""Returns the .def file from sources, if any.  Otherwise returns None."""""" <TAB> spec = self.spec <TAB> if spec[""type""] in (""shared_library"", ""loadable_module"", ""executable""): <TAB>  <TAB> def_files = [s for s in spec.get(""sources"", []) if s.endswith("".def"")] <MASK> return gyp_to_build_path(def_files[0]) <TAB>  <TAB> elif len(def_files) > 1: <TAB>  <TAB>  <TAB> raise Exception(""Multiple .def files"") <TAB> return None",if len ( def_files ) == 1 :,153
1147,"def _validate_gallery(images): <TAB> for image in images: <TAB>  <TAB> image_path = image.get(""image_path"", """") <TAB>  <TAB> if image_path: <TAB>  <TAB>  <TAB> if not isfile(image_path): <TAB>  <TAB>  <TAB>  <TAB> raise TypeError(f""{image_path!r} is not a valid image path."") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise TypeError(""'image_path' is required."") <MASK> raise TypeError(""Caption must be 180 characters or less."")","if not len ( image . get ( ""caption"" , """" ) ) <= 180 :",130
1148,"def VType(self): <TAB> if ""DW_AT_type"" in self.attributes: <TAB>  <TAB> target = self.types[self.type_id] <TAB>  <TAB> target_type = target.VType() <MASK> target_type = [target_type, None] <TAB>  <TAB> return [""Pointer"", dict(target=target_type[0], target_args=target_type[1])] <TAB> return [""Pointer"", dict(target=""Void"")]","if not isinstance ( target_type , list ) :",117
1149,"def addInPlace(self, value1, value2): <TAB> for group in value2: <TAB>  <TAB> for key in value2[group]: <MASK> value1[group][key] = value2[group][key] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> value1[group][key] += value2[group][key] <TAB> return value1",if key not in value1 [ group ] :,97
1150,"def _mongo_query_and(self, queries): <TAB> if len(queries) == 1: <TAB>  <TAB> return queries[0] <TAB> query = {} <TAB> for q in queries: <TAB>  <TAB> for k, v in q.items(): <MASK> query[k] = {} <TAB>  <TAB>  <TAB> if isinstance(v, list): <TAB>  <TAB>  <TAB>  <TAB> # TODO check exists of k in query, may be it should be update <TAB>  <TAB>  <TAB>  <TAB> query[k] = v <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> query[k].update(v) <TAB> return query",if k not in query :,141
1151,"def _handled_eventtype(self, eventtype, handler): <TAB> if eventtype not in known_events: <TAB>  <TAB> log.error('The event ""%s"" is not known', eventtype) <TAB>  <TAB> return False <TAB> if known_events[eventtype].__module__.startswith(""deluge.event""): <MASK> return True <TAB>  <TAB> log.error( <TAB>  <TAB>  <TAB> ""You cannot register custom notification providers "" <TAB>  <TAB>  <TAB> ""for built-in event types."" <TAB>  <TAB> ) <TAB>  <TAB> return False <TAB> return True",if handler . __self__ is self :,130
1152,"def get_ax_arg(uri): <TAB> if not ax_ns: <TAB>  <TAB> return u"""" <TAB> prefix = ""openid."" + ax_ns + "".type."" <TAB> ax_name = None <TAB> for name, values in self.request.arguments.iteritems(): <MASK> part = name[len(prefix) :] <TAB>  <TAB>  <TAB> ax_name = ""openid."" + ax_ns + "".value."" + part <TAB>  <TAB>  <TAB> break <TAB> if not ax_name: <TAB>  <TAB> return u"""" <TAB> return self.get_argument(ax_name, u"""")",if values [ - 1 ] == uri and name . startswith ( prefix ) :,148
1153,"def handle_starttag(self, tag, attrs): <TAB> if tag == ""base"": <TAB>  <TAB> self.base_url = dict(attrs).get(""href"") <TAB> if self.scan_tag(tag): <TAB>  <TAB> for attr, value in attrs: <MASK> if self.strip: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value = strip_html5_whitespace(value) <TAB>  <TAB>  <TAB>  <TAB> url = self.process_attr(value) <TAB>  <TAB>  <TAB>  <TAB> link = Link(url=url) <TAB>  <TAB>  <TAB>  <TAB> self.links.append(link) <TAB>  <TAB>  <TAB>  <TAB> self.current_link = link",if self . scan_attr ( attr ) :,151
1154,"def test_long_steadystate_queue_popright(self): <TAB> for size in (0, 1, 2, 100, 1000): <TAB>  <TAB> d = deque(reversed(range(size))) <TAB>  <TAB> append, pop = d.appendleft, d.pop <TAB>  <TAB> for i in range(size, BIG): <TAB>  <TAB>  <TAB> append(i) <TAB>  <TAB>  <TAB> x = pop() <MASK> self.assertEqual(x, i - size) <TAB>  <TAB> self.assertEqual(list(reversed(list(d))), list(range(BIG - size, BIG)))",if x != i - size :,143
1155,"def _update_read(self): <TAB> """"""Update state when there is read event"""""" <TAB> try: <TAB>  <TAB> msg = bytes(self._sock.recv(4096)) <MASK> self.on_message(msg) <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> # normal close, remote is closed <TAB>  <TAB> self.close() <TAB> except socket.error as err: <TAB>  <TAB> if err.args[0] in (errno.EAGAIN, errno.EWOULDBLOCK): <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.on_error(err) <TAB> return False",if msg :,142
1156,"def prepend(self, value): <TAB> """"""prepend value to nodes"""""" <TAB> root, root_text = self._get_root(value) <TAB> for i, tag in enumerate(self): <TAB>  <TAB> if not tag.text: <TAB>  <TAB>  <TAB> tag.text = """" <MASK> root[-1].tail = tag.text <TAB>  <TAB>  <TAB> tag.text = root_text <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tag.text = root_text + tag.text <TAB>  <TAB> if i > 0: <TAB>  <TAB>  <TAB> root = deepcopy(list(root)) <TAB>  <TAB> tag[:0] = root <TAB>  <TAB> root = tag[: len(root)] <TAB> return self",if len ( root ) > 0 :,160
1157,"def cmp(self, other): <TAB> v_is_ptr = not isinstance(self, CTypesGenericPrimitive) <TAB> w_is_ptr = isinstance(other, CTypesData) and not isinstance( <TAB>  <TAB> other, CTypesGenericPrimitive <TAB> ) <TAB> if v_is_ptr and w_is_ptr: <TAB>  <TAB> return cmpfunc(self._convert_to_address(None), other._convert_to_address(None)) <TAB> elif v_is_ptr or w_is_ptr: <TAB>  <TAB> return NotImplemented <TAB> else: <TAB>  <TAB> if isinstance(self, CTypesGenericPrimitive): <TAB>  <TAB>  <TAB> self = self._value <MASK> other = other._value <TAB>  <TAB> return cmpfunc(self, other)","if isinstance ( other , CTypesGenericPrimitive ) :",179
1158,"def get_external_addresses(self, label=None) -> List[str]: <TAB> result = [] <TAB> for c in self._conf[""pools""].values(): <MASK> if label == c[""label""]: <TAB>  <TAB>  <TAB>  <TAB> result.append(c[""external_address""][0]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result.append(c[""external_address""][0]) <TAB> return result",if label is not None :,99
1159,"def coerce_text(v): <TAB> if not isinstance(v, basestring_): <MASK> attr = ""__unicode__"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> attr = ""__str__"" <TAB>  <TAB> if hasattr(v, attr): <TAB>  <TAB>  <TAB> return unicode(v) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return bytes(v) <TAB> return v",if sys . version_info [ 0 ] < 3 :,93
1160,"def check_localhost(self): <TAB> """"""Warn if any socket_host is 'localhost'. See #711."""""" <TAB> for k, v in cherrypy.config.items(): <MASK> warnings.warn( <TAB>  <TAB>  <TAB>  <TAB> ""The use of 'localhost' as a socket host can "" <TAB>  <TAB>  <TAB>  <TAB> ""cause problems on newer systems, since "" <TAB>  <TAB>  <TAB>  <TAB> ""'localhost' can map to either an IPv4 or an "" <TAB>  <TAB>  <TAB>  <TAB> ""IPv6 address. You should use '127.0.0.1' "" <TAB>  <TAB>  <TAB>  <TAB> ""or '[::1]' instead."" <TAB>  <TAB>  <TAB> )","if k == ""server.socket_host"" and v == ""localhost"" :",160
1161,"def add_songs(self, filenames, library): <TAB> changed = [] <TAB> for i in range(len(self)): <MASK> song = library[self._list[i]] <TAB>  <TAB>  <TAB> self._list[i] = song <TAB>  <TAB>  <TAB> changed.append(song) <TAB> if changed: <TAB>  <TAB> self._emit_changed(changed, msg=""add"") <TAB> return bool(changed)","if isinstance ( self [ i ] , str ) and self . _list [ i ] in filenames :",113
1162,"def _expand_deps_java_generation(self): <TAB> """"""Ensure that all multilingual dependencies such as proto_library generate java code."""""" <TAB> queue = collections.deque(self.deps) <TAB> keys = set() <TAB> while queue: <TAB>  <TAB> k = queue.popleft() <TAB>  <TAB> if k not in keys: <TAB>  <TAB>  <TAB> keys.add(k) <TAB>  <TAB>  <TAB> dep = self.target_database[k] <MASK> # Has this attribute <TAB>  <TAB>  <TAB>  <TAB> dep.attr[""generate_java""] = True <TAB>  <TAB>  <TAB>  <TAB> queue.extend(dep.deps)","if ""generate_java"" in dep . attr :",144
1163,"def get(self): <TAB> name = request.args.get(""filename"") <TAB> if name is not None: <TAB>  <TAB> opts = dict() <TAB>  <TAB> opts[""type""] = ""episode"" <TAB>  <TAB> result = guessit(name, options=opts) <TAB>  <TAB> res = dict() <MASK> res[""episode""] = result[""episode""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> res[""episode""] = 0 <TAB>  <TAB> if ""season"" in result: <TAB>  <TAB>  <TAB> res[""season""] = result[""season""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> res[""season""] = 0 <TAB>  <TAB> if ""subtitle_language"" in result: <TAB>  <TAB>  <TAB> res[""subtitle_language""] = str(result[""subtitle_language""]) <TAB>  <TAB> return jsonify(data=res) <TAB> else: <TAB>  <TAB> return """", 400","if ""episode"" in result :",196
1164,def _get_error_file(self) -> Optional[str]: <TAB> error_file = None <TAB> min_timestamp = sys.maxsize <TAB> for replicas in self.role_replicas.values(): <TAB>  <TAB> for replica in replicas: <MASK> continue <TAB>  <TAB>  <TAB> mtime = os.path.getmtime(replica.error_file) <TAB>  <TAB>  <TAB> if mtime < min_timestamp: <TAB>  <TAB>  <TAB>  <TAB> min_timestamp = mtime <TAB>  <TAB>  <TAB>  <TAB> error_file = replica.error_file <TAB> return error_file,if not os . path . exists ( replica . error_file ) :,138
1165,"def findChapterNameForPosition(self, p): <TAB> """"""Return the name of a chapter containing p or None if p does not exist."""""" <TAB> cc, c = self, self.c <TAB> if not p or not c.positionExists(p): <TAB>  <TAB> return None <TAB> for name in cc.chaptersDict: <MASK> theChapter = cc.chaptersDict.get(name) <TAB>  <TAB>  <TAB> if theChapter.positionIsInChapter(p): <TAB>  <TAB>  <TAB>  <TAB> return name <TAB> return ""main""","if name != ""main"" :",128
1166,"def remove_files(folder, file_extensions): <TAB> for f in os.listdir(folder): <TAB>  <TAB> f_path = os.path.join(folder, f) <TAB>  <TAB> if os.path.isfile(f_path): <TAB>  <TAB>  <TAB> extension = os.path.splitext(f_path)[1] <MASK> os.remove(f_path)",if extension in file_extensions :,96
1167,"def execute_uncomment(self, event): <TAB> cursor = self._editor.GetCurrentPos() <TAB> line, pos = self._editor.GetCurLine() <TAB> spaces = "" "" * self._tab_size <TAB> comment = ""Comment"" + spaces <TAB> cpos = cursor - len(comment) <TAB> lenline = len(line) <TAB> if lenline > 0: <TAB>  <TAB> idx = 0 <TAB>  <TAB> while idx < lenline and line[idx] == "" "": <TAB>  <TAB>  <TAB> idx += 1 <MASK> self._editor.DeleteRange(cursor - pos + idx, len(comment)) <TAB>  <TAB>  <TAB> self._editor.SetCurrentPos(cpos) <TAB>  <TAB>  <TAB> self._editor.SetSelection(cpos, cpos) <TAB>  <TAB>  <TAB> self.store_position()",if ( line [ idx : len ( comment ) + idx ] ) . lower ( ) == comment . lower ( ) :,197
1168,"def test_batch_kwarg_path_relative_dot_slash_is_modified_and_found_in_a_code_cell( <TAB> critical_suite_with_citations, empty_data_context): <TAB> obs = SuiteEditNotebookRenderer.from_data_context(empty_data_context).render( <TAB>  <TAB> critical_suite_with_citations, {""path"": ""./foo/data""} <TAB> ) <TAB> assert isinstance(obs, dict) <TAB> found_expected = False <TAB> for cell in obs[""cells""]: <MASK> source_code = cell[""source""] <TAB>  <TAB>  <TAB> if 'batch_kwargs = {""path"": ""../.././foo/data""}' in source_code: <TAB>  <TAB>  <TAB>  <TAB> found_expected = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB> assert found_expected","if cell [ ""cell_type"" ] == ""code"" :",196
1169,"def _get_file(self): <TAB> if self._file is None: <TAB>  <TAB> self._file = SpooledTemporaryFile( <TAB>  <TAB>  <TAB> max_size=self._storage.max_memory_size, <TAB>  <TAB>  <TAB> suffix="".S3Boto3StorageFile"", <TAB>  <TAB>  <TAB> dir=setting(""FILE_UPLOAD_TEMP_DIR""), <TAB>  <TAB> ) <TAB>  <TAB> if ""r"" in self._mode: <TAB>  <TAB>  <TAB> self._is_dirty = False <TAB>  <TAB>  <TAB> self.obj.download_fileobj(self._file) <TAB>  <TAB>  <TAB> self._file.seek(0) <MASK> self._file = GzipFile(mode=self._mode, fileobj=self._file, mtime=0.0) <TAB> return self._file","if self . _storage . gzip and self . obj . content_encoding == ""gzip"" :",184
1170,"def _parse_filters(f_strs): <TAB> filters = [] <TAB> if not f_strs: <TAB>  <TAB> return filters <TAB> for f_str in f_strs: <MASK> fname, fopts = f_str.split("":"", 1) <TAB>  <TAB>  <TAB> filters.append((fname, _parse_options([fopts]))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> filters.append((f_str, {})) <TAB> return filters","if "":"" in f_str :",107
1171,"def update_completion(self): <TAB> """"""Update completion model with exist tags"""""" <TAB> orig_text = self.widget.text() <TAB> text = "", "".join(orig_text.replace("", "", "","").split("","")[:-1]) <TAB> tags = [] <TAB> for tag in self.tags_list: <MASK> if orig_text[-1] not in ("","", "" ""): <TAB>  <TAB>  <TAB>  <TAB> tags.append(""%s,%s"" % (text, tag)) <TAB>  <TAB>  <TAB> tags.append(""%s, %s"" % (text, tag)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tags.append(tag) <TAB> if tags != self.completer_model.stringList(): <TAB>  <TAB> self.completer_model.setStringList(tags)","if "","" in orig_text :",177
1172,"def _get_startup_packages(lib_path: Path, packages) -> Set[str]: <TAB> names = set() <TAB> for path in lib_path.iterdir(): <TAB>  <TAB> name = path.name <TAB>  <TAB> if name == ""__pycache__"": <TAB>  <TAB>  <TAB> continue <MASK> names.add(name.split(""."")[0]) <TAB>  <TAB> elif path.is_dir() and ""."" not in name: <TAB>  <TAB>  <TAB> names.add(name) <TAB> if packages: <TAB>  <TAB> packages = {package.lower().replace(""-"", ""_"") for package in packages} <TAB>  <TAB> if len(names & packages) == len(packages): <TAB>  <TAB>  <TAB> return packages <TAB> return names","if name . endswith ( "".py"" ) :",159
1173,"def get_cloud_credential(self): <TAB> """"""Return the credential which is directly tied to the inventory source type."""""" <TAB> credential = None <TAB> for cred in self.credentials.all(): <MASK> if cred.kind == self.source.replace(""ec2"", ""aws""): <TAB>  <TAB>  <TAB>  <TAB> credential = cred <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # these need to be returned in the API credential field <TAB>  <TAB>  <TAB> if cred.credential_type.kind != ""vault"": <TAB>  <TAB>  <TAB>  <TAB> credential = cred <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return credential",if self . source in CLOUD_PROVIDERS :,149
1174,"def newickize(clade): <TAB> """"""Convert a node tree to a Newick tree string, recursively."""""" <TAB> label = clade.name or """" <TAB> if label: <TAB>  <TAB> unquoted_label = re.match(token_dict[""unquoted node label""], label) <MASK> label = ""'%s'"" % label.replace(""\\"", ""\\\\"").replace(""'"", ""\\'"") <TAB> if clade.is_terminal():  # terminal <TAB>  <TAB> return label + make_info_string(clade, terminal=True) <TAB> else: <TAB>  <TAB> subtrees = (newickize(sub) for sub in clade) <TAB>  <TAB> return ""(%s)%s"" % ("","".join(subtrees), label + make_info_string(clade))",if ( not unquoted_label ) or ( unquoted_label . end ( ) < len ( label ) ) :,184
1175,"def __iter__(self): <TAB> for name, value in self._vars.store.data.items(): <TAB>  <TAB> source = self._sources[name] <TAB>  <TAB> prefix = self._get_prefix(value) <TAB>  <TAB> name = u""{0}{{{1}}}"".format(prefix, name) <MASK> yield ArgumentInfo(name, value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield VariableInfo(name, value, source)",if source == self . ARGUMENT_SOURCE :,110
1176,"def filepath_enumerate(paths): <TAB> """"""Enumerate the file paths of all subfiles of the list of paths"""""" <TAB> out = [] <TAB> for path in paths: <MASK> out.append(path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for root, dirs, files in os.walk(path): <TAB>  <TAB>  <TAB>  <TAB> for name in files: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> out.append(os.path.normpath(os.path.join(root, name))) <TAB> return out",if os . path . isfile ( path ) :,122
1177,"def del_(self, key): <TAB> hash_ = self.hash(key) <TAB> node_ = self._table[hash_] <TAB> pre_node = None <TAB> while node_ is not None: <MASK> if pre_node is None: <TAB>  <TAB>  <TAB>  <TAB> self._table[hash_] = node_.next <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> pre_node.next = node_.next <TAB>  <TAB>  <TAB> self._len -= 1 <TAB>  <TAB> pre_node = node_ <TAB>  <TAB> node_ = node_.next",if node_ . key == key :,129
1178,"def _recurse(self, base_path, rel_source, rel_zip): <TAB> submodules_path = Path(base_path) / ""submodules"" <TAB> if not submodules_path.is_dir(): <TAB>  <TAB> return <TAB> for submodule in submodules_path.iterdir(): <TAB>  <TAB> source_path = submodule / rel_source <MASK> continue <TAB>  <TAB> output_path = submodule / rel_zip <TAB>  <TAB> self._build_lambdas(source_path, output_path) <TAB>  <TAB> self._recurse(submodule, rel_source, rel_zip)",if not source_path . is_dir ( ) :,139
1179,"def find_test_functions(collections): <TAB> if not isinstance(collections, list): <TAB>  <TAB> collections = [collections] <TAB> functions = [] <TAB> for collection in collections: <TAB>  <TAB> if not isinstance(collection, dict): <TAB>  <TAB>  <TAB> collection = vars(collection) <TAB>  <TAB> keys = collection.keys() <TAB>  <TAB> keys.sort() <TAB>  <TAB> for key in keys: <TAB>  <TAB>  <TAB> value = collection[key] <MASK> functions.append(value) <TAB> return functions","if isinstance ( value , types . FunctionType ) and hasattr ( value , ""unittest"" ) :",131
1180,"def __init__( <TAB> self, <TAB> classifier, <TAB> layer_name=None, <TAB> transpose=None, <TAB> distance=None, <TAB> copy_weights=True,): <TAB> super().__init__() <TAB> self.copy_weights = copy_weights <TAB> ### set layer weights ### <TAB> if layer_name is not None: <TAB>  <TAB> self.set_weights(getattr(classifier, layer_name)) <TAB> else: <TAB>  <TAB> for x in self.possible_layer_names: <TAB>  <TAB>  <TAB> layer = getattr(classifier, x, None) <MASK> self.set_weights(layer) <TAB>  <TAB>  <TAB>  <TAB> break <TAB> ### set distance measure ### <TAB> self.distance = classifier.distance if distance is None else distance <TAB> self.transpose = transpose",if layer is not None :,183
1181,def multi_dev_generator(self): <TAB> for data in self._data_loader(): <TAB>  <TAB> if len(self._tail_data) < self._base_number: <TAB>  <TAB>  <TAB> self._tail_data += data <MASK> yield self._tail_data <TAB>  <TAB>  <TAB> self._tail_data = [],if len ( self . _tail_data ) == self . _base_number :,91
1182,"def Resolve(self, updater=None): <TAB> if len(self.Conflicts): <TAB>  <TAB> for setting, edge in self.Conflicts: <TAB>  <TAB>  <TAB> answer = self.AskUser(self.Setting, setting) <TAB>  <TAB>  <TAB> if answer == Gtk.ResponseType.YES: <TAB>  <TAB>  <TAB>  <TAB> value = setting.Value.split(""|"") <TAB>  <TAB>  <TAB>  <TAB> value.remove(edge) <TAB>  <TAB>  <TAB>  <TAB> setting.Value = ""|"".join(value) <TAB>  <TAB>  <TAB>  <TAB> if updater: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> updater.UpdateSetting(setting) <MASK> return False <TAB> return True",if answer == Gtk . ResponseType . NO :,146
1183,"def _post_process_ttl(zone): <TAB> for name in zone: <TAB>  <TAB> for record_type in zone[name]: <TAB>  <TAB>  <TAB> records = zone[name][record_type] <TAB>  <TAB>  <TAB> if isinstance(records, list): <TAB>  <TAB>  <TAB>  <TAB> ttl = min([x[""ttl""] for x in records]) <TAB>  <TAB>  <TAB>  <TAB> for record in records: <MASK> logger.warning( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Using lowest TTL {} for the record set. Ignoring value {}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ttl, record[""ttl""] <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> record[""ttl""] = ttl","if record [ ""ttl"" ] != ttl :",183
1184,"def __init__(self, cmds, env, cleanup=[]): <TAB> self.handle = None <TAB> self.cmds = cmds <TAB> self.env = env <TAB> if cleanup: <MASK> cleanup = [cleanup] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> cleanup = [c for c in cleanup if callable(c)] <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> cleanup = [] <TAB> self.cleanup = cleanup",if callable ( cleanup ) :,106
1185,"def _parse_data_of_birth(cls, data_of_birth_string): <TAB> if data_of_birth_string: <TAB>  <TAB> format = ""%m/%d/%Y"" <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> parsed_date = datetime.datetime.strptime(data_of_birth_string, format) <TAB>  <TAB>  <TAB> return parsed_date <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> # Facebook sometimes provides a partial date format <TAB>  <TAB>  <TAB> # ie 04/07 (ignore those) <MASK> raise","if data_of_birth_string . count ( ""/"" ) != 1 :",138
1186,"def process_lib(vars_, coreval): <TAB> for d in vars_: <TAB>  <TAB> var = d.upper() <TAB>  <TAB> if var == ""QTCORE"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> value = env[""LIBPATH_"" + var] <TAB>  <TAB> if value: <TAB>  <TAB>  <TAB> core = env[coreval] <TAB>  <TAB>  <TAB> accu = [] <TAB>  <TAB>  <TAB> for lib in value: <MASK> continue <TAB>  <TAB>  <TAB>  <TAB> accu.append(lib) <TAB>  <TAB>  <TAB> env[""LIBPATH_"" + var] = accu",if lib in core :,133
1187,"def throttle_status(server=None): <TAB> result = AmonStruct() <TAB> result.allow = False <TAB> last_check = server.get(""last_check"") <TAB> server_check_period = server.get(""check_every"", 60) <TAB> if last_check: <TAB>  <TAB> period_since_last_check = unix_utc_now() - last_check <TAB>  <TAB> # Add 15 seconds buffer, for statsd <TAB>  <TAB> period_since_last_check = period_since_last_check + 15 <MASK> result.allow = True <TAB> else: <TAB>  <TAB> result.allow = True  # Never checked <TAB> return result",if period_since_last_check >= server_check_period :,164
1188,"def fetch_scatter_outputs(self, task): <TAB> scatteroutputs = [] <TAB> for var in task[""body""]: <TAB>  <TAB> # TODO variable support <TAB>  <TAB> if var.startswith(""call""): <MASK> for output in self.tasks_dictionary[task[""body""][var][""task""]][ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""outputs"" <TAB>  <TAB>  <TAB>  <TAB> ]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> scatteroutputs.append( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> {""task"": task[""body""][var][""alias""], ""output"": output[0]} <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return scatteroutputs","if ""outputs"" in self . tasks_dictionary [ task [ ""body"" ] [ var ] [ ""task"" ] ] :",152
1189,"def _add_constant_node(self, source_node): <TAB> parent_ids = range(len(source_node.in_edges)) <TAB> for idx in parent_ids: <TAB>  <TAB> parent_node = self.tf_graph.get_node(source_node.in_edges[idx]) <MASK> self._rename_Const(parent_node)","if parent_node . type == ""Const"" :",96
1190,"def enableCtrls(self): <TAB> # Check if each ctrl has a requirement or an incompatibility, <TAB> # look it up, and enable/disable if so <TAB> for data in self.storySettingsData: <TAB>  <TAB> name = data[""name""] <TAB>  <TAB> if name in self.ctrls: <MASK> set = self.getSetting(data[""requires""]) <TAB>  <TAB>  <TAB>  <TAB> for i in self.ctrls[name]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> i.Enable(set not in [""off"", ""false"", ""0""])","if ""requires"" in data :",133
1191,"def update_realtime(self, stdout="""", stderr="""", delete=False): <TAB> wooey_cache = wooey_settings.WOOEY_REALTIME_CACHE <TAB> if delete == False and wooey_cache is None: <TAB>  <TAB> self.stdout = stdout <TAB>  <TAB> self.stderr = stderr <TAB>  <TAB> self.save() <TAB> elif wooey_cache is not None: <TAB>  <TAB> cache = django_cache[wooey_cache] <MASK> cache.delete(self.get_realtime_key()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> cache.set( <TAB>  <TAB>  <TAB>  <TAB> self.get_realtime_key(), <TAB>  <TAB>  <TAB>  <TAB> json.dumps({""stdout"": stdout, ""stderr"": stderr}), <TAB>  <TAB>  <TAB> )",if delete :,177
1192,"def _check_for_batch_clashes(xs): <TAB> """"""Check that batch names do not overlap with sample names."""""" <TAB> names = set([x[""description""] for x in xs]) <TAB> dups = set([]) <TAB> for x in xs: <TAB>  <TAB> batches = tz.get_in((""metadata"", ""batch""), x) <TAB>  <TAB> if batches: <TAB>  <TAB>  <TAB> if not isinstance(batches, (list, tuple)): <TAB>  <TAB>  <TAB>  <TAB> batches = [batches] <TAB>  <TAB>  <TAB> for batch in batches: <MASK> dups.add(batch) <TAB> if len(dups) > 0: <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> ""Batch names must be unique from sample descriptions.\n"" <TAB>  <TAB>  <TAB> ""Clashing batch names: %s"" % sorted(list(dups)) <TAB>  <TAB> )",if batch in names :,192
1193,"def toggle(self, event=None): <TAB> if self.absolute: <TAB>  <TAB> if self.save == self.split: <TAB>  <TAB>  <TAB> self.save = 100 <TAB>  <TAB> if self.split > 20: <TAB>  <TAB>  <TAB> self.save = self.split <TAB>  <TAB>  <TAB> self.split = 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.split = self.save <TAB> else: <TAB>  <TAB> if self.save == self.split: <TAB>  <TAB>  <TAB> self.save = 0.3 <MASK> self.split = self.save <TAB>  <TAB> elif self.split < 0.5: <TAB>  <TAB>  <TAB> self.split = self.min <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.split = self.max <TAB> self.placeChilds()",if self . split <= self . min or self . split >= self . max :,189
1194,"def can_read(self): <TAB> if hasattr(self.file, ""__iter__""): <TAB>  <TAB> iterator = iter(self.file) <TAB>  <TAB> head = next(iterator, None) <MASK> self.repaired = [] <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> if isinstance(head, str): <TAB>  <TAB>  <TAB> self.repaired = itertools.chain([head], iterator) <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # We may have mangled a generator at this point, so just abort <TAB>  <TAB>  <TAB> raise IOSourceError( <TAB>  <TAB>  <TAB>  <TAB> ""Could not open source: %r (mode: %r)"" <TAB>  <TAB>  <TAB>  <TAB> % (self.file, self.options[""mode""]) <TAB>  <TAB>  <TAB> ) <TAB> return False",if head is None :,176
1195,"def _print_message_content(self, peer, data): <TAB> inheaders = 1 <TAB> lines = data.splitlines() <TAB> for line in lines: <TAB>  <TAB> # headers first <TAB>  <TAB> if inheaders and not line: <TAB>  <TAB>  <TAB> peerheader = ""X-Peer: "" + peer[0] <MASK> # decoded_data=false; make header match other binary output <TAB>  <TAB>  <TAB>  <TAB> peerheader = repr(peerheader.encode(""utf-8"")) <TAB>  <TAB>  <TAB> print(peerheader) <TAB>  <TAB>  <TAB> inheaders = 0 <TAB>  <TAB> if not isinstance(data, str): <TAB>  <TAB>  <TAB> # Avoid spurious 'str on bytes instance' warning. <TAB>  <TAB>  <TAB> line = repr(line) <TAB>  <TAB> print(line)","if not isinstance ( data , str ) :",180
1196,"def connect(self): <TAB> # Makes connection with MySQL server <TAB> try: <MASK> connection = pymysql.connect(read_default_file=""/etc/mysql/conf.d/my.cnf"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> connection = pymysql.connect(read_default_file=""~/.my.cnf"") <TAB>  <TAB> return connection <TAB> except ValueError as e: <TAB>  <TAB> Log.debug(self, str(e)) <TAB>  <TAB> raise MySQLConnectionError <TAB> except pymysql.err.InternalError as e: <TAB>  <TAB> Log.debug(self, str(e)) <TAB>  <TAB> raise MySQLConnectionError","if os . path . exists ( ""/etc/mysql/conf.d/my.cnf"" ) :",156
1197,"def _copy_package_apps( <TAB> local_bin_dir: Path, app_paths: List[Path], suffix: str = """") -> None: <TAB> for src_unresolved in app_paths: <TAB>  <TAB> src = src_unresolved.resolve() <TAB>  <TAB> app = src.name <TAB>  <TAB> dest = Path(local_bin_dir / add_suffix(app, suffix)) <TAB>  <TAB> if not dest.parent.is_dir(): <TAB>  <TAB>  <TAB> mkdir(dest.parent) <TAB>  <TAB> if dest.exists(): <TAB>  <TAB>  <TAB> logger.warning(f""{hazard}  Overwriting file {str(dest)} with {str(src)}"") <TAB>  <TAB>  <TAB> dest.unlink() <MASK> shutil.copy(src, dest)",if src . exists ( ) :,177
1198,"def update(self, x, who=None, metadata=None): <TAB> self._retain_refs(metadata) <TAB> y = self._get_key(x) <TAB> if self.keep == ""last"": <TAB>  <TAB> # remove key if already present so that emitted value <TAB>  <TAB> # will reflect elements' actual relative ordering <TAB>  <TAB> self._buffer.pop(y, None) <TAB>  <TAB> self._metadata_buffer.pop(y, None) <TAB>  <TAB> self._buffer[y] = x <TAB>  <TAB> self._metadata_buffer[y] = metadata <TAB> else:  # self.keep == ""first"" <MASK> self._buffer[y] = x <TAB>  <TAB>  <TAB> self._metadata_buffer[y] = metadata <TAB> return self.last",if y not in self . _buffer :,180
1199,"def resolve_credential_keys(m_keys, keys): <TAB> res = [] <TAB> for k in m_keys: <TAB>  <TAB> if k[""c7n:match-type""] == ""credential"": <TAB>  <TAB>  <TAB> c_date = parse_date(k[""last_rotated""]) <TAB>  <TAB>  <TAB> for ak in keys: <TAB>  <TAB>  <TAB>  <TAB> if c_date == ak[""CreateDate""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ak = dict(ak) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ak[""c7n:match-type""] = ""access"" <MASK> res.append(ak) <TAB>  <TAB> elif k not in res: <TAB>  <TAB>  <TAB> res.append(k) <TAB> return res",if ak not in res :,169
1200,"def _apply_flag_attrs(src_flag, dest_flag): <TAB> # Use a baseline flag def to get default values for empty data. <TAB> baseline_flag = FlagDef("""", {}, None) <TAB> for name in dir(src_flag): <TAB>  <TAB> if name[:1] == ""_"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> dest_val = getattr(dest_flag, name, None) <TAB>  <TAB> baseline_val = getattr(baseline_flag, name, None) <MASK> setattr(dest_flag, name, getattr(src_flag, name))",if dest_val == baseline_val :,137
1201,"def _ws_keep_reading(self): <TAB> import websockets.exceptions <TAB> while not self._reader_stopped: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> data = await self._ws.recv() <MASK> data = data.encode(""UTF-8"") <TAB>  <TAB>  <TAB> if len(data) == 0: <TAB>  <TAB>  <TAB>  <TAB> self._error = ""EOF"" <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> except websockets.exceptions.ConnectionClosedError: <TAB>  <TAB>  <TAB> # TODO: try to reconnect in case of Ctrl+D <TAB>  <TAB>  <TAB> self._error = ""EOF"" <TAB>  <TAB>  <TAB> break <TAB>  <TAB> self.num_bytes_received += len(data) <TAB>  <TAB> self._make_output_available(data, block=False)","if isinstance ( data , str ) :",180
1202,"def to_dict(self) -> Dict[str, Any]: <TAB> result = {} <TAB> for field_name in self.API_FIELDS: <MASK> result[""stream_id""] = self.id <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif field_name == ""date_created"": <TAB>  <TAB>  <TAB> result[""date_created""] = datetime_to_timestamp(self.date_created) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> result[field_name] = getattr(self, field_name) <TAB> result[""is_announcement_only""] = ( <TAB>  <TAB> self.stream_post_policy == Stream.STREAM_POST_POLICY_ADMINS <TAB> ) <TAB> return result","if field_name == ""id"" :",164
1203,"def all_masks( <TAB> cls, <TAB> images, <TAB> run, <TAB> run_key, <TAB> step,): <TAB> all_mask_groups = [] <TAB> for image in images: <MASK> mask_group = {} <TAB>  <TAB>  <TAB> for k in image._masks: <TAB>  <TAB>  <TAB>  <TAB> mask = image._masks[k] <TAB>  <TAB>  <TAB>  <TAB> mask_group[k] = mask.to_json(run) <TAB>  <TAB>  <TAB> all_mask_groups.append(mask_group) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> all_mask_groups.append(None) <TAB> if all_mask_groups and not all(x is None for x in all_mask_groups): <TAB>  <TAB> return all_mask_groups <TAB> else: <TAB>  <TAB> return False",if image . _masks :,183
1204,"def disconnect_all(listener): <TAB> """"""Disconnect from all signals"""""" <TAB> for emitter in listener._signal_data.emitters: <TAB>  <TAB> for signal in emitter._signal_data.listeners: <TAB>  <TAB>  <TAB> emitter._signal_data.listeners[signal] = [ <TAB>  <TAB>  <TAB>  <TAB> i <TAB>  <TAB>  <TAB>  <TAB> for i in emitter._signal_data.listeners[signal] <MASK> ]","if getattr ( i , ""__self__"" , None ) != listener",108
1205,"def wait(self, timeout=None): <TAB> if self.returncode is None: <TAB>  <TAB> if timeout is None: <TAB>  <TAB>  <TAB> msecs = _subprocess.INFINITE <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> msecs = max(0, int(timeout * 1000 + 0.5)) <TAB>  <TAB> res = _subprocess.WaitForSingleObject(int(self._handle), msecs) <TAB>  <TAB> if res == _subprocess.WAIT_OBJECT_0: <TAB>  <TAB>  <TAB> code = _subprocess.GetExitCodeProcess(self._handle) <MASK> code = -signal.SIGTERM <TAB>  <TAB>  <TAB> self.returncode = code <TAB> return self.returncode",if code == TERMINATE :,154
1206,"def set_pbar_fraction(self, frac, progress, stage=None): <TAB> gtk.gdk.threads_enter() <TAB> try: <TAB>  <TAB> self.is_pulsing = False <TAB>  <TAB> self.set_stage_text(stage or _(""Processing..."")) <TAB>  <TAB> self.pbar.set_text(progress) <MASK> frac = 1.0 <TAB>  <TAB> if frac < 0: <TAB>  <TAB>  <TAB> frac = 0 <TAB>  <TAB> self.pbar.set_fraction(frac) <TAB> finally: <TAB>  <TAB> gtk.gdk.threads_leave()",if frac > 1 :,135
1207,"def get_aa_from_codonre(re_aa): <TAB> aas = [] <TAB> m = 0 <TAB> for i in re_aa: <TAB>  <TAB> if i == ""["": <TAB>  <TAB>  <TAB> m = -1 <TAB>  <TAB>  <TAB> aas.append("""") <MASK> m = 0 <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif m == -1: <TAB>  <TAB>  <TAB> aas[-1] = aas[-1] + i <TAB>  <TAB> elif m == 0: <TAB>  <TAB>  <TAB> aas.append(i) <TAB> return aas","elif i == ""]"" :",129
1208,"def link(token, base_url): <TAB> """"""Validation for ``link``."""""" <TAB> if get_keyword(token) == ""none"": <TAB>  <TAB> return ""none"" <TAB> parsed_url = get_url(token, base_url) <TAB> if parsed_url: <TAB>  <TAB> return parsed_url <TAB> function = parse_function(token) <TAB> if function: <TAB>  <TAB> name, args = function <TAB>  <TAB> prototype = (name, [a.type for a in args]) <TAB>  <TAB> args = [getattr(a, ""value"", a) for a in args] <MASK> return (""attr()"", args[0])","if prototype == ( ""attr"" , [ ""ident"" ] ) :",153
1209,"def on_bt_search_clicked(self, widget): <TAB> if self.current_provider is None: <TAB>  <TAB> return <TAB> query = self.en_query.get_text() <TAB> @self.obtain_podcasts_with <TAB> def load_data(): <TAB>  <TAB> if self.current_provider.kind == directory.Provider.PROVIDER_SEARCH: <TAB>  <TAB>  <TAB> return self.current_provider.on_search(query) <MASK> return self.current_provider.on_url(query) <TAB>  <TAB> elif self.current_provider.kind == directory.Provider.PROVIDER_FILE: <TAB>  <TAB>  <TAB> return self.current_provider.on_file(query)",elif self . current_provider . kind == directory . Provider . PROVIDER_URL :,172
1210,"def test_handle_single(self): <TAB> self.skipTest( <TAB>  <TAB> ""Pops up windows and needs user input.. so disabled."" <TAB>  <TAB> ""Still worth keeping whilst we don't have unit tests "" <TAB>  <TAB> ""for all plugins."" <TAB> ) <TAB> # Ignored... <TAB> for id_, plugin in self.plugins.items(): <MASK> self.h.plugin_enable(plugin, None) <TAB>  <TAB>  <TAB> self.h.handle(id_, self.lib, self.parent, SONGS) <TAB>  <TAB>  <TAB> self.h.plugin_disable(plugin)",if self . h . plugin_handle ( plugin ) :,144
1211,"def __repr__(self): <TAB> attrs = [] <TAB> for k in self._keydata: <MASK> attrs.append(""p(%d)"" % (self.size() + 1,)) <TAB>  <TAB> elif hasattr(self, k): <TAB>  <TAB>  <TAB> attrs.append(k) <TAB> if self.has_private(): <TAB>  <TAB> attrs.append(""private"") <TAB> # PY3K: This is meant to be text, do not change to bytes (data) <TAB> return ""<%s @0x%x %s>"" % (self.__class__.__name__, id(self), "","".join(attrs))","if k == ""p"" :",142
1212,"def apply(self, node, code, required): <TAB> yield ""try:"" <TAB> yield from self.iterIndented(code) <TAB> yield "" <TAB> pass"" <TAB> yield ""except {}:"".format(self.exceptionString) <TAB> outputVariables = node.getOutputSocketVariables() <TAB> for i, s in enumerate(node.outputs): <MASK> if hasattr(s, ""getDefaultValueCode""): <TAB>  <TAB>  <TAB>  <TAB> yield f"" <TAB> {outputVariables[s.identifier]} = {s.getDefaultValueCode()}"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield f"" <TAB> {outputVariables[s.identifier]} = self.outputs[{i}].getDefaultValue()"" <TAB> yield "" <TAB> pass""",if s . identifier in required :,181
1213,"def __import__(name, globals=None, locals=None, fromlist=(), level=0): <TAB> module = orig___import__(name, globals, locals, fromlist, level) <TAB> if fromlist and module.__name__ in modules: <TAB>  <TAB> if ""*"" in fromlist: <TAB>  <TAB>  <TAB> fromlist = list(fromlist) <TAB>  <TAB>  <TAB> fromlist.remove(""*"") <TAB>  <TAB>  <TAB> fromlist.extend(getattr(module, ""__all__"", [])) <TAB>  <TAB> for x in fromlist: <MASK> from_name = ""{}.{}"".format(module.__name__, x) <TAB>  <TAB>  <TAB>  <TAB> if from_name in modules: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> importlib.import_module(from_name) <TAB> return module","if isinstance ( getattr ( module , x , None ) , types . ModuleType ) :",175
1214,"def _consume_msg(self): <TAB> ws = self._ws <TAB> try: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> r = await ws.recv() <MASK> r = r.decode(""utf-8"") <TAB>  <TAB>  <TAB> msg = json.loads(r) <TAB>  <TAB>  <TAB> stream = msg.get(""stream"") <TAB>  <TAB>  <TAB> if stream is not None: <TAB>  <TAB>  <TAB>  <TAB> await self._dispatch(stream, msg) <TAB> except websockets.WebSocketException as wse: <TAB>  <TAB> logging.warn(wse) <TAB>  <TAB> await self.close() <TAB>  <TAB> asyncio.ensure_future(self._ensure_ws())","if isinstance ( r , bytes ) :",158
1215,"def add_source(self, source, name=None): <TAB> """"""Adds a new data source to an existing provider."""""" <TAB> if self.randomize: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Cannot add a non-shuffleable source to an "" <TAB>  <TAB>  <TAB>  <TAB> ""already shuffled provider."" <TAB>  <TAB>  <TAB> ) <TAB> super().add_source(source, name=name) <TAB> if self.randomize is True: <TAB>  <TAB> self._shuffle_len = self.entries",if not source . can_shuffle ( ) :,121
1216,"def __str__(self): <TAB> buf = [""""] <TAB> if self.fileName: <TAB>  <TAB> buf.append(self.fileName + "":"") <TAB> if self.line != -1: <TAB>  <TAB> if not self.fileName: <TAB>  <TAB>  <TAB> buf.append(""line "") <TAB>  <TAB> buf.append(str(self.line)) <MASK> buf.append("":"" + str(self.column)) <TAB>  <TAB> buf.append("":"") <TAB> buf.append("" "") <TAB> return str("""").join(buf)",if self . column != - 1 :,124
1217,"def has_bad_headers(self): <TAB> headers = [self.sender, self.reply_to] + self.recipients <TAB> for header in headers: <TAB>  <TAB> if _has_newline(header): <TAB>  <TAB>  <TAB> return True <TAB> if self.subject: <TAB>  <TAB> if _has_newline(self.subject): <TAB>  <TAB>  <TAB> for linenum, line in enumerate(self.subject.split(""\r\n"")): <TAB>  <TAB>  <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB>  <TAB> if linenum > 0 and line[0] not in ""\t "": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB>  <TAB> if _has_newline(line): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <MASK> return True <TAB> return False",if len ( line . strip ( ) ) == 0 :,186
1218,"def scanHexEscape(self, prefix): <TAB> code = 0 <TAB> leng = 4 if (prefix == ""u"") else 2 <TAB> for i in xrange(leng): <MASK> ch = self.source[self.index] <TAB>  <TAB>  <TAB> self.index += 1 <TAB>  <TAB>  <TAB> code = code * 16 + HEX_CONV[ch] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return """" <TAB> return unichr(code)",if self . index < self . length and isHexDigit ( self . source [ self . index ] ) :,119
1219,"def _get_table_info(self, table_name): <TAB> table_addr = self.addr_space.profile.get_symbol(table_name) <TAB> table_size = self._get_table_info_distorm() <MASK> table_size = self._get_table_info_other(table_addr, table_name) <TAB>  <TAB> if table_size == 0: <TAB>  <TAB>  <TAB> debug.error(""Unable to get system call table size"") <TAB> return [table_addr, table_size]",if table_size == 0 :,126
1220,"def format_file_path(filepath): <TAB> """"""Formats a path as absolute and with the correct platform separator."""""" <TAB> try: <TAB>  <TAB> is_windows_network_mount = WINDOWS_NETWORK_MOUNT_PATTERN.match(filepath) <TAB>  <TAB> filepath = os.path.realpath(os.path.abspath(filepath)) <TAB>  <TAB> filepath = re.sub(BACKSLASH_REPLACE_PATTERN, ""/"", filepath) <TAB>  <TAB> is_windows_drive = WINDOWS_DRIVE_PATTERN.match(filepath) <MASK> filepath = filepath.capitalize() <TAB>  <TAB> if is_windows_network_mount: <TAB>  <TAB>  <TAB> # Add back a / to the front, since the previous modifications <TAB>  <TAB>  <TAB> # will have replaced any double slashes with single <TAB>  <TAB>  <TAB> filepath = ""/"" + filepath <TAB> except: <TAB>  <TAB> pass <TAB> return filepath",if is_windows_drive :,194
1221,"def _match(self, cre, s): <TAB> # Run compiled regular expression match method on 's'. <TAB> # Save result, return success. <TAB> self.mo = cre.match(s) <TAB> if __debug__: <MASK> self._mesg(""\tmatched r'%r' => %r"" % (cre.pattern, self.mo.groups())) <TAB> return self.mo is not None",if self . mo is not None and self . debug >= 5 :,108
1222,"def reload_sanitize_allowlist(self, explicit=True): <TAB> self.sanitize_allowlist = [] <TAB> try: <TAB>  <TAB> with open(self.sanitize_allowlist_file) as f: <TAB>  <TAB>  <TAB> for line in f.readlines(): <TAB>  <TAB>  <TAB>  <TAB> if not line.startswith(""#""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.sanitize_allowlist.append(line.strip()) <TAB> except OSError: <MASK> log.warning( <TAB>  <TAB>  <TAB>  <TAB> ""Sanitize log file explicitly specified as '%s' but does not exist, continuing with no tools allowlisted."", <TAB>  <TAB>  <TAB>  <TAB> self.sanitize_allowlist_file, <TAB>  <TAB>  <TAB> )",if explicit :,149
1223,"def conj(self): <TAB> dtype = self.dtype <TAB> if issubclass(self.dtype.type, np.complexfloating): <TAB>  <TAB> if not self.flags.forc: <TAB>  <TAB>  <TAB> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB> ""only contiguous arrays may "" ""be used as arguments to this operation"" <TAB>  <TAB>  <TAB> ) <MASK> order = ""F"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> order = ""C"" <TAB>  <TAB> result = self._new_like_me(order=order) <TAB>  <TAB> func = elementwise.get_conj_kernel(dtype) <TAB>  <TAB> func.prepared_async_call( <TAB>  <TAB>  <TAB> self._grid, self._block, None, self.gpudata, result.gpudata, self.mem_size <TAB>  <TAB> ) <TAB>  <TAB> return result <TAB> else: <TAB>  <TAB> return self",if self . flags . f_contiguous :,198
1224,"def scan_spec_conf(self, conf): <TAB> if ""metadata"" in conf: <TAB>  <TAB> if ""annotations"" in conf[""metadata""] and conf[""metadata""].get(""annotations""): <TAB>  <TAB>  <TAB> for annotation in conf[""metadata""][""annotations""]: <TAB>  <TAB>  <TAB>  <TAB> for key in annotation: <MASK> if ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""docker/default"" in annotation[key] <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> or ""runtime/default"" in annotation[key] <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return CheckResult.PASSED <TAB> return CheckResult.FAILED","if ""seccomp.security.alpha.kubernetes.io/defaultProfileName"" in key :",167
1225,"def test_error_through_destructor(self): <TAB> # Test that the exception state is not modified by a destructor, <TAB> # even if close() fails. <TAB> rawio = self.CloseFailureIO() <TAB> with support.catch_unraisable_exception() as cm: <TAB>  <TAB> with self.assertRaises(AttributeError): <TAB>  <TAB>  <TAB> self.tp(rawio).xyzzy <TAB>  <TAB> if not IOBASE_EMITS_UNRAISABLE: <TAB>  <TAB>  <TAB> self.assertIsNone(cm.unraisable) <MASK> self.assertEqual(cm.unraisable.exc_type, OSError)",elif cm . unraisable is not None :,157
1226,"def _dumpf(frame): <TAB> if frame is None: <TAB>  <TAB> return ""<None>"" <TAB> else: <TAB>  <TAB> addn = ""(with trace!)"" <MASK> addn = "" **No Trace Set **"" <TAB>  <TAB> return ""Frame at %d, file %s, line: %d%s"" % ( <TAB>  <TAB>  <TAB> id(frame), <TAB>  <TAB>  <TAB> frame.f_code.co_filename, <TAB>  <TAB>  <TAB> frame.f_lineno, <TAB>  <TAB>  <TAB> addn, <TAB>  <TAB> )",if frame . f_trace is None :,128
1227,"def containsBadbytes(self, value, bytecount=4): <TAB> for b in self.badbytes: <TAB>  <TAB> tmp = value <MASK> b = ord(b) <TAB>  <TAB> for i in range(bytecount): <TAB>  <TAB>  <TAB> if (tmp & 0xFF) == b: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB> tmp >>= 8 <TAB> return False",if type ( b ) == str :,95
1228,"def _set_peer_statuses(self): <TAB> """"""Set peer statuses."""""" <TAB> cutoff = time.time() - STALE_SECS <TAB> for peer in self.peers: <MASK> peer.status = PEER_BAD <TAB>  <TAB> elif peer.last_good > cutoff: <TAB>  <TAB>  <TAB> peer.status = PEER_GOOD <TAB>  <TAB> elif peer.last_good: <TAB>  <TAB>  <TAB> peer.status = PEER_STALE <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> peer.status = PEER_NEVER",if peer . bad :,128
1229,"def afterTest(self, test): <TAB> try: <TAB>  <TAB> # If the browser window is still open, close it now. <TAB>  <TAB> self.driver.quit() <TAB> except AttributeError: <TAB>  <TAB> pass <TAB> except Exception: <TAB>  <TAB> pass <TAB> if self.options.headless: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> self.display.stop() <TAB>  <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> pass",if self . headless_active :,117
1230,"def _written_variables_in_proxy(self, contract): <TAB> variables = [] <TAB> if contract.is_upgradeable: <TAB>  <TAB> variables_name_written_in_proxy = self._variable_written_in_proxy() <MASK> variables_in_contract = [ <TAB>  <TAB>  <TAB>  <TAB> contract.get_state_variable_from_name(v) <TAB>  <TAB>  <TAB>  <TAB> for v in variables_name_written_in_proxy <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB> variables_in_contract = [v for v in variables_in_contract if v] <TAB>  <TAB>  <TAB> variables += variables_in_contract <TAB> return list(set(variables))",if variables_name_written_in_proxy :,162
1231,"def _available_symbols(self, scoperef, expr): <TAB> cplns = [] <TAB> found_names = set() <TAB> while scoperef: <TAB>  <TAB> elem = self._elem_from_scoperef(scoperef) <TAB>  <TAB> for child in elem: <TAB>  <TAB>  <TAB> name = child.get(""name"", """") <TAB>  <TAB>  <TAB> if name.startswith(expr): <MASK> found_names.add(name) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ilk = child.get(""ilk"") or child.tag <TAB>  <TAB>  <TAB>  <TAB>  <TAB> cplns.append((ilk, name)) <TAB>  <TAB> scoperef = self.parent_scoperef_from_scoperef(scoperef) <TAB>  <TAB> if not scoperef: <TAB>  <TAB>  <TAB> break <TAB> return sorted(cplns, key=operator.itemgetter(1))",if name not in found_names :,196
1232,"def get_resource_public_actions(resource_class): <TAB> resource_class_members = inspect.getmembers(resource_class) <TAB> resource_methods = {} <TAB> for name, member in resource_class_members: <TAB>  <TAB> if not name.startswith(""_""): <MASK> if not name.startswith(""wait_until""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if is_resource_action(member): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> resource_methods[name] = member <TAB> return resource_methods",if not name [ 0 ] . isupper ( ) :,122
1233,def UpdateControlState(self): <TAB> active = self.demoModules.GetActiveID() <TAB> # Update the radio/restore buttons <TAB> for moduleID in self.radioButtons: <TAB>  <TAB> btn = self.radioButtons[moduleID] <MASK> btn.SetValue(True) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> btn.SetValue(False) <TAB>  <TAB> if self.demoModules.Exists(moduleID): <TAB>  <TAB>  <TAB> btn.Enable(True) <TAB>  <TAB>  <TAB> if moduleID == modModified: <TAB>  <TAB>  <TAB>  <TAB> self.btnRestore.Enable(True) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> btn.Enable(False) <TAB>  <TAB>  <TAB> if moduleID == modModified: <TAB>  <TAB>  <TAB>  <TAB> self.btnRestore.Enable(False),if moduleID == active :,177
1234,"def test_controlcharacters(self): <TAB> for i in range(128): <TAB>  <TAB> c = chr(i) <TAB>  <TAB> testString = ""string containing %s"" % c <TAB>  <TAB> if i >= 32 or c in ""\r\n\t"": <TAB>  <TAB>  <TAB> # \r, \n and \t are the only legal control chars in XML <TAB>  <TAB>  <TAB> data = plistlib.dumps(testString, fmt=plistlib.FMT_XML) <MASK> self.assertEqual(plistlib.loads(data), testString) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> with self.assertRaises(ValueError): <TAB>  <TAB>  <TAB>  <TAB> plistlib.dumps(testString, fmt=plistlib.FMT_XML) <TAB>  <TAB> plistlib.dumps(testString, fmt=plistlib.FMT_BINARY)","if c != ""\r"" :",188
1235,"def remove_usernames(self, username: SLT[str]) -> None: <TAB> with self.__lock: <MASK> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB> f""Can't set {self.username_name} in conjunction with (already set) "" <TAB>  <TAB>  <TAB>  <TAB> f""{self.chat_id_name}s."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> parsed_username = self._parse_username(username) <TAB>  <TAB> self._usernames -= parsed_username",if self . _chat_ids :,116
1236,"def get_size(self, shape_info): <TAB> # The size is the data, that have constant size. <TAB> state = np.random.RandomState().get_state() <TAB> size = 0 <TAB> for elem in state: <TAB>  <TAB> if isinstance(elem, str): <TAB>  <TAB>  <TAB> size += len(elem) <TAB>  <TAB> elif isinstance(elem, np.ndarray): <TAB>  <TAB>  <TAB> size += elem.size * elem.itemsize <MASK> size += np.dtype(""int"").itemsize <TAB>  <TAB> elif isinstance(elem, float): <TAB>  <TAB>  <TAB> size += np.dtype(""float"").itemsize <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise NotImplementedError() <TAB> return size","elif isinstance ( elem , int ) :",159
1237,"def before_step(self, step, feed_dict): <TAB> if step == 0: <TAB>  <TAB> for _type, mem in self.memories.items(): <MASK> self.gan.session.run(tf.assign(mem[""var""], mem[""source""]))","if ""var"" in mem and ""source"" in mem :",79
1238,"def write(self, *bits): <TAB> for bit in bits: <TAB>  <TAB> if not self.bytestream: <TAB>  <TAB>  <TAB> self.bytestream.append(0) <TAB>  <TAB> byte = self.bytestream[self.bytenum] <MASK> if self.bytenum == len(self.bytestream) - 1: <TAB>  <TAB>  <TAB>  <TAB> byte = 0 <TAB>  <TAB>  <TAB>  <TAB> self.bytestream += bytes([byte]) <TAB>  <TAB>  <TAB> self.bytenum += 1 <TAB>  <TAB>  <TAB> self.bitnum = 0 <TAB>  <TAB> mask = 2 ** self.bitnum <TAB>  <TAB> if bit: <TAB>  <TAB>  <TAB> byte |= mask <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> byte &= ~mask <TAB>  <TAB> self.bytestream[self.bytenum] = byte <TAB>  <TAB> self.bitnum += 1",if self . bitnum == 8 :,186
1239,"def _validate_parameter_range(self, value_hp, parameter_range): <TAB> """"""Placeholder docstring"""""" <TAB> for ( <TAB>  <TAB> parameter_range_key, <TAB>  <TAB> parameter_range_value, <TAB> ) in parameter_range.__dict__.items(): <TAB>  <TAB> if parameter_range_key == ""scaling_type"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # Categorical ranges <MASK> for categorical_value in parameter_range_value: <TAB>  <TAB>  <TAB>  <TAB> value_hp.validate(categorical_value) <TAB>  <TAB> # Continuous, Integer ranges <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value_hp.validate(parameter_range_value)","if isinstance ( parameter_range_value , list ) :",159
1240,"def _trackA(self, tracks): <TAB> try: <TAB>  <TAB> track, start, end = self.featureA <TAB>  <TAB> assert track in tracks <TAB>  <TAB> return track <TAB> except TypeError: <TAB>  <TAB> for track in tracks: <TAB>  <TAB>  <TAB> for feature_set in track.get_sets(): <TAB>  <TAB>  <TAB>  <TAB> if hasattr(feature_set, ""features""): <MASK> return track <TAB>  <TAB> return None",if self . featureA in feature_set . features . values ( ) :,116
1241,"def walk(directory, path_so_far): <TAB> for name in sorted(os.listdir(directory)): <TAB>  <TAB> if any(fnmatch(name, pattern) for pattern in basename_ignore): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> path = path_so_far + ""/"" + name if path_so_far else name <TAB>  <TAB> if any(fnmatch(path, pattern) for pattern in path_ignore): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> full_name = os.path.join(directory, name) <MASK> for file_path in walk(full_name, path): <TAB>  <TAB>  <TAB>  <TAB> yield file_path <TAB>  <TAB> elif os.path.isfile(full_name): <TAB>  <TAB>  <TAB> yield path",if os . path . isdir ( full_name ) :,172
1242,"def _poll_ipc_requests(self) -> None: <TAB> try: <MASK> return <TAB>  <TAB> while not self._ipc_requests.empty(): <TAB>  <TAB>  <TAB> args = self._ipc_requests.get() <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> for filename in args: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if os.path.isfile(filename): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.get_editor_notebook().show_file(filename) <TAB>  <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB>  <TAB> logger.exception(""Problem processing ipc request"", exc_info=e) <TAB>  <TAB> self.become_active_window() <TAB> finally: <TAB>  <TAB> self.after(50, self._poll_ipc_requests)",if self . _ipc_requests . empty ( ) :,180
1243,"def test_read1(self): <TAB> self.test_write() <TAB> blocks = [] <TAB> nread = 0 <TAB> with gzip.GzipFile(self.filename, ""r"") as f: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> d = f.read1() <MASK> break <TAB>  <TAB>  <TAB> blocks.append(d) <TAB>  <TAB>  <TAB> nread += len(d) <TAB>  <TAB>  <TAB> # Check that position was updated correctly (see issue10791). <TAB>  <TAB>  <TAB> self.assertEqual(f.tell(), nread) <TAB> self.assertEqual(b"""".join(blocks), data1 * 50)",if not d :,146
1244,"def _target_generator(self): <TAB> if self._internal_target_generator is None: <MASK> return None <TAB>  <TAB> from ....model_zoo.rcnn.rpn.rpn_target import RPNTargetGenerator <TAB>  <TAB> self._internal_target_generator = RPNTargetGenerator( <TAB>  <TAB>  <TAB> num_sample=self._num_sample, <TAB>  <TAB>  <TAB> pos_iou_thresh=self._pos_iou_thresh, <TAB>  <TAB>  <TAB> neg_iou_thresh=self._neg_iou_thresh, <TAB>  <TAB>  <TAB> pos_ratio=self._pos_ratio, <TAB>  <TAB>  <TAB> stds=self._box_norm, <TAB>  <TAB>  <TAB> **self._kwargs <TAB>  <TAB> ) <TAB>  <TAB> return self._internal_target_generator <TAB> else: <TAB>  <TAB> return self._internal_target_generator",if self . _net_none :,191
1245,"def time_left(self): <TAB> """"""Return how many seconds are left until the timeout expires"""""" <TAB> if self.is_non_blocking: <TAB>  <TAB> return 0 <TAB> elif self.is_infinite: <TAB>  <TAB> return None <TAB> else: <TAB>  <TAB> delta = self.target_time - self.TIME() <MASK> # clock jumped, recalculate <TAB>  <TAB>  <TAB> self.target_time = self.TIME() + self.duration <TAB>  <TAB>  <TAB> return self.duration <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return max(0, delta)",if delta > self . duration :,132
1246,"def _decorator(cls): <TAB> for name, meth in inspect.getmembers(cls, inspect.isroutine): <TAB>  <TAB> if name not in cls.__dict__: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if name != ""__init__"": <TAB>  <TAB>  <TAB> if not private and name.startswith(""_""): <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> setattr(cls, name, decorator(meth)) <TAB> return cls",if name in butnot :,99
1247,"def load_vocab(vocab_file: str) -> List: <TAB> """"""Loads a vocabulary file into a dictionary."""""" <TAB> vocab = collections.OrderedDict() <TAB> with io.open(vocab_file, ""r"", encoding=""UTF-8"") as file: <TAB>  <TAB> for num, line in enumerate(file): <TAB>  <TAB>  <TAB> items = convert_to_unicode(line.strip()).split(""\t"") <MASK> break <TAB>  <TAB>  <TAB> token = items[0] <TAB>  <TAB>  <TAB> index = items[1] if len(items) == 2 else num <TAB>  <TAB>  <TAB> token = token.strip() <TAB>  <TAB>  <TAB> vocab[token] = int(index) <TAB>  <TAB> return vocab",if len ( items ) > 2 :,164
1248,"def slice_fill(self, slice_): <TAB> ""Fills the slice with zeroes for the dimensions that have single elements and squeeze_dims true"" <TAB> if isinstance(self.indexes, int): <TAB>  <TAB> new_slice_ = [0] <TAB>  <TAB> offset = 0 <TAB> else: <TAB>  <TAB> new_slice_ = [slice_[0]] <TAB>  <TAB> offset = 1 <TAB> for i in range(1, len(self.nums)): <MASK> new_slice_.append(0) <TAB>  <TAB> elif offset < len(slice_): <TAB>  <TAB>  <TAB> new_slice_.append(slice_[offset]) <TAB>  <TAB>  <TAB> offset += 1 <TAB> new_slice_ += slice_[offset:] <TAB> return new_slice_",if self . squeeze_dims [ i ] :,171
1249,"def check_update_function(url, folder, update_setter, version_setter, auto): <TAB> remote_version = urllib.urlopen(url).read() <TAB> if remote_version.isdigit(): <TAB>  <TAB> local_version = get_local_timestamp(folder) <TAB>  <TAB> if remote_version > local_version: <MASK> update_setter.set_value(True) <TAB>  <TAB>  <TAB> version_setter.set_value(remote_version) <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> else: <TAB>  <TAB> return False",if auto :,136
1250,"def iter_content(self, chunk_size_bytes): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> data = self._fp.read(chunk_size_bytes) <TAB>  <TAB> except IOError as e: <TAB>  <TAB>  <TAB> raise Fetcher.PermanentError( <TAB>  <TAB>  <TAB>  <TAB> ""Problem reading chunk from {}: {}"".format(self._fp.name, e) <TAB>  <TAB>  <TAB> ) <MASK> break <TAB>  <TAB> yield data",if not data :,105
1251,"def gvariant_args(args: List[Any]) -> str: <TAB> """"""Convert args into gvariant."""""" <TAB> gvariant = """" <TAB> for arg in args: <TAB>  <TAB> if isinstance(arg, bool): <TAB>  <TAB>  <TAB> gvariant += "" {}"".format(str(arg).lower()) <TAB>  <TAB> elif isinstance(arg, (int, float)): <TAB>  <TAB>  <TAB> gvariant += f"" {arg}"" <MASK> gvariant += f' ""{arg}""' <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> gvariant += f"" {arg!s}"" <TAB> return gvariant.lstrip()","elif isinstance ( arg , str ) :",139
1252,"def _element_keywords(cls, backend, elements=None): <TAB> ""Returns a dictionary of element names to allowed keywords"" <TAB> if backend not in Store.loaded_backends(): <TAB>  <TAB> return {} <TAB> mapping = {} <TAB> backend_options = Store.options(backend) <TAB> elements = elements if elements is not None else backend_options.keys() <TAB> for element in elements: <MASK> continue <TAB>  <TAB> element = element if isinstance(element, tuple) else (element,) <TAB>  <TAB> element_keywords = [] <TAB>  <TAB> options = backend_options[""."".join(element)] <TAB>  <TAB> for group in Options._option_groups: <TAB>  <TAB>  <TAB> element_keywords.extend(options[group].allowed_keywords) <TAB>  <TAB> mapping[element[0]] = element_keywords <TAB> return mapping","if ""."" in element :",185
1253,"def setup_parameter_node(self, param_node): <TAB> if param_node.bl_idname == ""SvNumberNode"": <TAB>  <TAB> if self.use_prop or self.get_prop_name(): <TAB>  <TAB>  <TAB> value = self.sv_get()[0][0] <TAB>  <TAB>  <TAB> print(""V"", value) <MASK> param_node.selected_mode = ""int"" <TAB>  <TAB>  <TAB>  <TAB> param_node.int_ = value <TAB>  <TAB>  <TAB> elif isinstance(value, float): <TAB>  <TAB>  <TAB>  <TAB> param_node.selected_mode = ""float"" <TAB>  <TAB>  <TAB>  <TAB> param_node.float_ = value","if isinstance ( value , int ) :",156
1254,"def _get_oshape(indices_shape, depth, axis): <TAB> oshape = [] <TAB> true_axis = len(indices_shape) if axis == -1 else axis <TAB> ndim = len(indices_shape) + 1 <TAB> indices_index = 0 <TAB> for i in range(0, ndim): <MASK> oshape.append(depth) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> oshape.append(indices_shape[indices_index]) <TAB>  <TAB>  <TAB> indices_index += 1 <TAB> return oshape",if i == true_axis :,123
1255,"def check(self, value): <TAB> value = String.check(self, value) <TAB> if isinstance(value, str): <TAB>  <TAB> value = value.upper() <TAB>  <TAB> for prefix in (self.prefix, self.prefix.split(""_"", 1)[1]): <TAB>  <TAB>  <TAB> # e.g. PANGO_WEIGHT_BOLD --> BOLD but also WEIGHT_BOLD --> BOLD <MASK> value = value[len(prefix) :] <TAB>  <TAB>  <TAB> value = value.lstrip(""_"") <TAB>  <TAB> if hasattr(self.group, value): <TAB>  <TAB>  <TAB> return getattr(self.group, value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""No such constant: %s_%s"" % (self.prefix, value)) <TAB> else: <TAB>  <TAB> return value",if value . startswith ( prefix ) :,182
1256,"def shuffle_unison_inplace(list_of_lists, random_state=None): <TAB> if list_of_lists: <TAB>  <TAB> assert all(len(l) == len(list_of_lists[0]) for l in list_of_lists) <MASK> random_state.permutation(len(list_of_lists[0])) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> p = np.random.permutation(len(list_of_lists[0])) <TAB>  <TAB> return [l[p] for l in list_of_lists] <TAB> return None",if random_state is not None :,139
1257,"def _load_module(self): <TAB> spec = self.default_module_spec <TAB> module_identifier = self.module_identifier <TAB> if module_identifier: <TAB>  <TAB> impls = self.get_module_implementation_map() <MASK> raise ModuleNotFound( <TAB>  <TAB>  <TAB>  <TAB> ""Invalid module identifier %r in %s"" <TAB>  <TAB>  <TAB>  <TAB> % (module_identifier, force_ascii(repr(self))) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> spec = impls[module_identifier] <TAB> cls = load( <TAB>  <TAB> spec, context_explanation=""Loading module for %s"" % force_ascii(repr(self)) <TAB> ) <TAB> options = getattr(self, self.module_options_field, None) or {} <TAB> return cls(self, options)",if module_identifier not in impls :,185
1258,"def get_data(self, state=None, request=None): <TAB> if self.load_in_memory: <TAB>  <TAB> data, shapes = self._in_memory_get_data(state, request) <TAB> else: <TAB>  <TAB> data, shapes = self._out_of_memory_get_data(state, request) <TAB> for i in range(len(data)): <MASK> if isinstance(request, numbers.Integral): <TAB>  <TAB>  <TAB>  <TAB> data[i] = data[i].reshape(shapes[i]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> for j in range(len(data[i])): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> data[i][j] = data[i][j].reshape(shapes[i][j]) <TAB> return tuple(data)",if shapes [ i ] is not None :,187
1259,"def resolve_credential_keys(m_keys, keys): <TAB> res = [] <TAB> for k in m_keys: <TAB>  <TAB> if k[""c7n:match-type""] == ""credential"": <TAB>  <TAB>  <TAB> c_date = parse_date(k[""last_rotated""]) <TAB>  <TAB>  <TAB> for ak in keys: <MASK> ak = dict(ak) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ak[""c7n:match-type""] = ""access"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if ak not in res: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> res.append(ak) <TAB>  <TAB> elif k not in res: <TAB>  <TAB>  <TAB> res.append(k) <TAB> return res","if c_date == ak [ ""CreateDate"" ] :",169
1260,"def _is_legacy_mode(self, node): <TAB> """"""Checks if the ``ast.Call`` node's keywords signal using legacy mode."""""" <TAB> script_mode = False <TAB> py_version = ""py2"" <TAB> for kw in node.keywords: <MASK> script_mode = ( <TAB>  <TAB>  <TAB>  <TAB> bool(kw.value.value) if isinstance(kw.value, ast.NameConstant) else True <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if kw.arg == ""py_version"": <TAB>  <TAB>  <TAB> py_version = kw.value.s if isinstance(kw.value, ast.Str) else ""py3"" <TAB> return not (py_version.startswith(""py3"") or script_mode)","if kw . arg == ""script_mode"" :",173
1261,"def get_upstream_statuses_events(self, upstream: Set) -> Dict[str, V1Statuses]: <TAB> statuses_by_refs = {u: [] for u in upstream} <TAB> events = self.events or []  # type: List[V1EventTrigger] <TAB> for e in events: <TAB>  <TAB> entity_ref = contexts_refs.get_entity_ref(e.ref) <TAB>  <TAB> if not entity_ref: <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> for kind in e.kinds: <TAB>  <TAB>  <TAB> status = V1EventKind.events_statuses_mapping.get(kind) <TAB>  <TAB>  <TAB> if status: <TAB>  <TAB>  <TAB>  <TAB> statuses_by_refs[entity_ref].append(status) <TAB> return statuses_by_refs",if entity_ref not in statuses_by_refs :,191
1262,"def items(self): <TAB> dict = {} <TAB> for userdir in self.XDG_DIRS.keys(): <TAB>  <TAB> prefix = self.get(userdir).strip('""').split(""/"")[0] <MASK> path = ( <TAB>  <TAB>  <TAB>  <TAB> os.getenv(""HOME"") <TAB>  <TAB>  <TAB>  <TAB> + ""/"" <TAB>  <TAB>  <TAB>  <TAB> + ""/"".join(self.get(userdir).strip('""').split(""/"")[1:]) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> path = self.get(userdir).strip('""') <TAB>  <TAB> dict[userdir] = path <TAB> return dict.items()",if prefix :,140
1263,"def clean_objects(string, common_attributes): <TAB> """"""Return object and attribute lists"""""" <TAB> string = clean_string(string) <TAB> words = string.split() <TAB> if len(words) > 1: <TAB>  <TAB> prefix_words_are_adj = True <TAB>  <TAB> for att in words[:-1]: <MASK> prefix_words_are_adj = False <TAB>  <TAB> if prefix_words_are_adj: <TAB>  <TAB>  <TAB> return words[-1:], words[:-1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return [string], [] <TAB> else: <TAB>  <TAB> return [string], []",if att not in common_attributes :,148
1264,"def extract_custom(extractor, *args, **kw): <TAB> for match in extractor(*args, **kw): <TAB>  <TAB> msg = match[2] <MASK> unused = ( <TAB>  <TAB>  <TAB>  <TAB> ""<unused singular (hash=%s)>"" % md5(msg[1].encode(""utf8"")).hexdigest() <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> msg = (unused, msg[1], msg[2]) <TAB>  <TAB>  <TAB> match = (match[0], match[1], msg, match[3]) <TAB>  <TAB> yield match","if isinstance ( msg , tuple ) and msg [ 0 ] == """" :",136
1265,"def test_convex_decomposition(self): <TAB> mesh = g.get_mesh(""quadknot.obj"") <TAB> engines = [(""vhacd"", g.trimesh.interfaces.vhacd.exists)] <TAB> for engine, exists in engines: <MASK> g.log.warning(""skipping convex decomposition engine %s"", engine) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> g.log.info(""Testing convex decomposition with engine %s"", engine) <TAB>  <TAB> meshes = mesh.convex_decomposition(engine=engine) <TAB>  <TAB> self.assertTrue(len(meshes) > 1) <TAB>  <TAB> for m in meshes: <TAB>  <TAB>  <TAB> self.assertTrue(m.is_watertight) <TAB>  <TAB> g.log.info(""convex decomposition succeeded with %s"", engine)",if not exists :,183
1266,"def _to_string_infix(self, ostream, idx, verbose): <TAB> if verbose: <TAB>  <TAB> ostream.write("" , "") <TAB> else: <TAB>  <TAB> hasConst = not ( <TAB>  <TAB>  <TAB> self._const.__class__ in native_numeric_types and self._const == 0 <TAB>  <TAB> ) <TAB>  <TAB> if hasConst: <TAB>  <TAB>  <TAB> idx -= 1 <TAB>  <TAB> _l = self._coef[id(self._args[idx])] <TAB>  <TAB> _lt = _l.__class__ <MASK> ostream.write("" - "") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ostream.write("" + "")",if _lt is _NegationExpression or ( _lt in native_numeric_types and _l < 0 ) :,169
1267,"def get_other(self, data, items): <TAB> is_tuple = False <TAB> if type(data) == tuple: <TAB>  <TAB> data = list(data) <TAB>  <TAB> is_tuple = True <TAB> if type(data) == list: <TAB>  <TAB> m_items = items.copy() <TAB>  <TAB> for idx, item in enumerate(items): <TAB>  <TAB>  <TAB> if item < 0: <TAB>  <TAB>  <TAB>  <TAB> m_items[idx] = len(data) - abs(item) <TAB>  <TAB> for i in sorted(set(m_items), reverse=True): <TAB>  <TAB>  <TAB> if i < len(data) and i > -1: <TAB>  <TAB>  <TAB>  <TAB> del data[i] <MASK> return tuple(data) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return data <TAB> else: <TAB>  <TAB> return None",if is_tuple :,191
1268,"def process_error(self, data): <TAB> if data.get(""error""): <MASK> raise AuthCanceled(self, data.get(""error_description"", """")) <TAB>  <TAB> raise AuthFailed(self, data.get(""error_description"") or data[""error""]) <TAB> elif ""denied"" in data: <TAB>  <TAB> raise AuthCanceled(self, data[""denied""])","if ""denied"" in data [ ""error"" ] or ""cancelled"" in data [ ""error"" ] :",103
1269,"def tamper(payload, **kwargs): <TAB> junk_chars = ""!#$%&()*~+-_.,:;?@[/|\]^`"" <TAB> retval = """" <TAB> for i, char in enumerate(payload, start=1): <TAB>  <TAB> amount = random.randint(10, 15) <TAB>  <TAB> if char == "">"": <TAB>  <TAB>  <TAB> retval += "">"" <TAB>  <TAB>  <TAB> for _ in range(amount): <TAB>  <TAB>  <TAB>  <TAB> retval += random.choice(junk_chars) <TAB>  <TAB> elif char == ""<"": <TAB>  <TAB>  <TAB> retval += ""<"" <TAB>  <TAB>  <TAB> for _ in range(amount): <TAB>  <TAB>  <TAB>  <TAB> retval += random.choice(junk_chars) <MASK> for _ in range(amount): <TAB>  <TAB>  <TAB>  <TAB> retval += random.choice(junk_chars) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> retval += char <TAB> return retval","elif char == "" "" :",200
1270,"def retry_http_digest_auth(self, req, auth): <TAB> token, challenge = auth.split("" "", 1) <TAB> chal = parse_keqv_list(parse_http_list(challenge)) <TAB> auth = self.get_authorization(req, chal) <TAB> if auth: <TAB>  <TAB> auth_val = ""Digest %s"" % auth <MASK> return None <TAB>  <TAB> req.add_unredirected_header(self.auth_header, auth_val) <TAB>  <TAB> resp = self.parent.open(req) <TAB>  <TAB> return resp","if req . headers . get ( self . auth_header , None ) == auth_val :",154
1271,"def close(self): <TAB> self.selector.close() <TAB> if self.sock: <TAB>  <TAB> sockname = None <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> sockname = self.sock.getsockname() <TAB>  <TAB> except (socket.error, OSError): <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> self.sock.close() <TAB>  <TAB> if type(sockname) is str: <TAB>  <TAB>  <TAB> # it was a Unix domain socket, remove it from the filesystem <MASK> os.remove(sockname) <TAB> self.sock = None",if os . path . exists ( sockname ) :,128
1272,"def to_nurbs(self, curves): <TAB> result = [] <TAB> for i, c in enumerate(curves): <TAB>  <TAB> nurbs = SvNurbsCurve.to_nurbs(c) <MASK> raise Exception(f""Curve #{i} - {c} - can not be converted to NURBS!"") <TAB>  <TAB> result.append(nurbs) <TAB> return result",if nurbs is None :,102
1273,"def handle_1_roomid_raffle(self, i): <TAB> if i[1] in [""handle_1_room_TV"", ""handle_1_room_captain""]: <MASK> await self.notify(""post_watching_history"", i[0]) <TAB>  <TAB>  <TAB> await self.notify(i[1], i[0], i[2]) <TAB> else: <TAB>  <TAB> print(""hhjjkskddrsfvsfdfvdfvvfdvdvdfdfffdfsvh"", i)","if await self . notify ( ""check_if_normal_room"" , i [ 0 ] , - 1 ) :",144
1274,"def init_ps_var_partition(self): <TAB> ps_vars = {} <TAB> for v in self._non_embed_vars.values(): <TAB>  <TAB> if v.name not in self._var_to_ps: <TAB>  <TAB>  <TAB> self._var_to_ps[v.name] = string_to_id(v.name, self._ps_num) <TAB>  <TAB> ps_id = self._var_to_ps[v.name] <MASK> ps_vars[ps_id] = [v] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ps_vars[ps_id].append(v) <TAB> self._ps_vars = ps_vars",if ps_id not in ps_vars :,164
1275,"def get_files(d): <TAB> f = [] <TAB> for root, dirs, files in os.walk(d): <TAB>  <TAB> for name in files: <TAB>  <TAB>  <TAB> if ""meta-environment"" in root or ""cross-canadian"" in root: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if ""qemux86copy-"" in root or ""qemux86-"" in root: <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> f.append(os.path.join(root, name)) <TAB> return f","if ""do_build"" not in name and ""do_populate_sdk"" not in name :",143
1276,"def setSelectedLabelState(self, p):  # selected, disabled <TAB> c = self.c <TAB> # g.trace(p,c.edit_widget(p)) <TAB> if p and c.edit_widget(p): <MASK> g.trace(self.trace_n, c.edit_widget(p), p) <TAB>  <TAB>  <TAB> # g.trace(g.callers(6)) <TAB>  <TAB>  <TAB> self.trace_n += 1 <TAB>  <TAB> self.setDisabledHeadlineColors(p)",if 0 :,122
1277,"def filter_tasks(self, task_types=None, task_states=None, task_text=None): <TAB> tasks = self.api.tasks(self.id).get(""tasks"", {}) <TAB> if tasks and tasks.get(""task""): <TAB>  <TAB> return [ <TAB>  <TAB>  <TAB> Task(self, task) <TAB>  <TAB>  <TAB> for task in tasks.get(""task"", []) <MASK> and (not task_states or task[""state""].lower() in task_states) <TAB>  <TAB>  <TAB> and (not task_text or task_text.lower() in str(task).lower()) <TAB>  <TAB> ] <TAB> else: <TAB>  <TAB> return []","if ( not task_types or task [ ""type"" ] . lower ( ) in task_types )",166
1278,"def GenerateVector(self, hits, vector, level): <TAB> """"""Generate possible hit vectors which match the rules."""""" <TAB> for item in hits.get(level, []): <MASK> if item < vector[-1]: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if item > self.max_separation + vector[-1]: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> new_vector = vector + [item] <TAB>  <TAB> if level + 1 == len(hits): <TAB>  <TAB>  <TAB> yield new_vector <TAB>  <TAB> elif level + 1 < len(hits): <TAB>  <TAB>  <TAB> for result in self.GenerateVector(hits, new_vector, level + 1): <TAB>  <TAB>  <TAB>  <TAB> yield result",if vector :,157
1279,def _transmit_from_storage(self) -> None: <TAB> for blob in self.storage.gets(): <TAB>  <TAB> # give a few more seconds for blob lease operation <TAB>  <TAB> # to reduce the chance of race (for perf consideration) <TAB>  <TAB> if blob.lease(self._timeout + 5): <TAB>  <TAB>  <TAB> envelopes = [TelemetryItem(**x) for x in blob.get()] <TAB>  <TAB>  <TAB> result = self._transmit(list(envelopes)) <MASK> blob.lease(1) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> blob.delete(),if result == ExportResult . FAILED_RETRYABLE :,147
1280,"def load_dictionary(file): <TAB> oui = {} <TAB> with open(file, ""r"") as f: <TAB>  <TAB> for line in f: <MASK> data = line.split(""(hex)"") <TAB>  <TAB>  <TAB>  <TAB> key = data[0].replace(""-"", "":"").lower().strip() <TAB>  <TAB>  <TAB>  <TAB> company = data[1].strip() <TAB>  <TAB>  <TAB>  <TAB> oui[key] = company <TAB> return oui","if ""(hex)"" in line :",108
1281,"def _yield_minibatches_idx(self, rgen, n_batches, data_ary, shuffle=True): <TAB> indices = np.arange(data_ary.shape[0]) <TAB> if shuffle: <TAB>  <TAB> indices = rgen.permutation(indices) <TAB> if n_batches > 1: <TAB>  <TAB> remainder = data_ary.shape[0] % n_batches <MASK> minis = np.array_split(indices[:-remainder], n_batches) <TAB>  <TAB>  <TAB> minis[-1] = np.concatenate((minis[-1], indices[-remainder:]), axis=0) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> minis = np.array_split(indices, n_batches) <TAB> else: <TAB>  <TAB> minis = (indices,) <TAB> for idx_batch in minis: <TAB>  <TAB> yield idx_batch",if remainder :,194
1282,"def canonical_custom_headers(self, headers): <TAB> hoi = [] <TAB> custom_headers = {} <TAB> for key in headers: <TAB>  <TAB> lk = key.lower() <TAB>  <TAB> if headers[key] is not None: <MASK> custom_headers[lk] = "","".join(v.strip() for v in headers.get_all(key)) <TAB> sorted_header_keys = sorted(custom_headers.keys()) <TAB> for key in sorted_header_keys: <TAB>  <TAB> hoi.append(""%s:%s"" % (key, custom_headers[key])) <TAB> return ""\n"".join(hoi)","if lk . startswith ( ""x-amz-"" ) :",158
1283,"def validate(self, data): <TAB> if not data.get(""reason""): <TAB>  <TAB> # If reason is not provided, message is required and can not be <TAB>  <TAB> # null or blank. <TAB>  <TAB> message = data.get(""message"") <TAB>  <TAB> if not message: <TAB>  <TAB>  <TAB> if ""message"" not in data: <TAB>  <TAB>  <TAB>  <TAB> msg = serializers.Field.default_error_messages[""required""] <MASK> msg = serializers.Field.default_error_messages[""null""] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> msg = serializers.CharField.default_error_messages[""blank""] <TAB>  <TAB>  <TAB> raise serializers.ValidationError({""message"": [msg]}) <TAB> return data",elif message is None :,167
1284,def tearDown(self): <TAB> try: <TAB>  <TAB> os.chdir(self.cwd) <MASK> os.remove(self.pythonexe) <TAB>  <TAB> test_support.rmtree(self.parent_dir) <TAB> finally: <TAB>  <TAB> BaseTestCase.tearDown(self),if self . pythonexe != sys . executable :,77
1285,"def update(self, value, label): <TAB> if self._disabled: <TAB>  <TAB> return <TAB> try: <TAB>  <TAB> self._progress.value = value <TAB>  <TAB> self._label.value = label <MASK> self._displayed = True <TAB>  <TAB>  <TAB> display_widget(self._widget) <TAB> except Exception as e: <TAB>  <TAB> self._disabled = True <TAB>  <TAB> logger.exception(e) <TAB>  <TAB> wandb.termwarn(""Unable to render progress bar, see the user log for details"")",if not self . _displayed :,122
1286,"def GetBinaryOperationBinder(self, op): <TAB> with self._lock: <MASK> return self._binaryOperationBinders[op] <TAB>  <TAB> b = runtime.SymplBinaryOperationBinder(op) <TAB>  <TAB> self._binaryOperationBinders[op] = b <TAB> return b",if self . _binaryOperationBinders . ContainsKey ( op ) :,83
1287,"def apply(self, l, b, evaluation): <TAB> ""FromDigits[l_, b_]"" <TAB> if l.get_head_name() == ""System`List"": <TAB>  <TAB> value = Integer(0) <TAB>  <TAB> for leaf in l.leaves: <TAB>  <TAB>  <TAB> value = Expression(""Plus"", Expression(""Times"", value, b), leaf) <TAB>  <TAB> return value <TAB> elif isinstance(l, String): <TAB>  <TAB> value = FromDigits._parse_string(l.get_string_value(), b) <MASK> evaluation.message(""FromDigits"", ""nlst"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return value <TAB> else: <TAB>  <TAB> evaluation.message(""FromDigits"", ""nlst"")",if value is None :,163
1288,"def hsconn_sender(self): <TAB> while not self.stop_event.is_set(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> # Block, but timeout, so that we can exit the loop gracefully <TAB>  <TAB>  <TAB> request = self.send_queue.get(True, 6.0) <TAB>  <TAB>  <TAB> if self.socket is not None: <TAB>  <TAB>  <TAB>  <TAB> # Socket got closed and set to None in another thread... <TAB>  <TAB>  <TAB>  <TAB> self.socket.sendall(request) <MASK> self.send_queue.task_done() <TAB>  <TAB> except queue.Empty: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> self.stop_event.set()",if self . send_queue is not None :,168
1289,"def check_expected(result, expected, contains=False): <TAB> if sys.version_info[0] >= 3: <TAB>  <TAB> if isinstance(result, str): <TAB>  <TAB>  <TAB> result = result.encode(""ascii"") <TAB>  <TAB> if isinstance(expected, str): <TAB>  <TAB>  <TAB> expected = expected.encode(""ascii"") <TAB> resultlines = result.splitlines() <TAB> expectedlines = expected.splitlines() <TAB> if len(resultlines) != len(expectedlines): <TAB>  <TAB> return False <TAB> for rline, eline in zip(resultlines, expectedlines): <TAB>  <TAB> if contains: <MASK> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if not rline.endswith(eline): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return True",if eline not in rline :,181
1290,"def init_weights(self): <TAB> """"""Initialize model weights."""""" <TAB> for _, m in self.multi_deconv_layers.named_modules(): <MASK> normal_init(m, std=0.001) <TAB>  <TAB> elif isinstance(m, nn.BatchNorm2d): <TAB>  <TAB>  <TAB> constant_init(m, 1) <TAB> for m in self.multi_final_layers.modules(): <TAB>  <TAB> if isinstance(m, nn.Conv2d): <TAB>  <TAB>  <TAB> normal_init(m, std=0.001, bias=0)","if isinstance ( m , nn . ConvTranspose2d ) :",139
1291,"def filter_rel_attrs(field_name, **rel_attrs): <TAB> clean_dict = {} <TAB> for k, v in rel_attrs.items(): <MASK> splitted_key = k.split(""__"") <TAB>  <TAB>  <TAB> key = ""__"".join(splitted_key[1:]) <TAB>  <TAB>  <TAB> clean_dict[key] = v <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> clean_dict[k] = v <TAB> return clean_dict","if k . startswith ( field_name + ""__"" ) :",114
1292,"def cancel(self): <TAB> with self._condition: <MASK> self._squash( <TAB>  <TAB>  <TAB>  <TAB> state_root=self._previous_state_hash, <TAB>  <TAB>  <TAB>  <TAB> context_ids=[self._previous_context_id], <TAB>  <TAB>  <TAB>  <TAB> persist=False, <TAB>  <TAB>  <TAB>  <TAB> clean_up=True, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self._cancelled = True <TAB>  <TAB> self._condition.notify_all()",if not self . _cancelled and not self . _final and self . _previous_context_id :,121
1293,"def _get_level(levels, level_ref): <TAB> if level_ref in levels: <TAB>  <TAB> return levels.index(level_ref) <TAB> if isinstance(level_ref, six.integer_types): <MASK> level_ref += len(levels) <TAB>  <TAB> if not (0 <= level_ref < len(levels)): <TAB>  <TAB>  <TAB> raise PatsyError(""specified level %r is out of range"" % (level_ref,)) <TAB>  <TAB> return level_ref <TAB> raise PatsyError(""specified level %r not found"" % (level_ref,))",if level_ref < 0 :,138
1294,"def parse_node(self, node, alias_map=None, conv=None): <TAB> sql, params, unknown = self._parse(node, alias_map, conv) <TAB> if unknown and conv and params: <TAB>  <TAB> params = [conv.db_value(i) for i in params] <TAB> if isinstance(node, Node): <TAB>  <TAB> if node._negated: <TAB>  <TAB>  <TAB> sql = ""NOT %s"" % sql <MASK> sql = "" "".join((sql, ""AS"", node._alias)) <TAB>  <TAB> if node._ordering: <TAB>  <TAB>  <TAB> sql = "" "".join((sql, node._ordering)) <TAB> return sql, params",if node . _alias :,155
1295,"def parse_object_id(_, values): <TAB> if values: <TAB>  <TAB> for key in values: <MASK> val = values[key] <TAB>  <TAB>  <TAB>  <TAB> if len(val) > 10: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> values[key] = utils.ObjectIdSilent(val) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> values[key] = None","if key . endswith ( ""_id"" ) :",108
1296,"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_app_id(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 16: <TAB>  <TAB>  <TAB> self.set_max_rows(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,124
1297,"def has_invalid_cce(yaml_file, product_yaml=None): <TAB> rule = yaml.open_and_macro_expand(yaml_file, product_yaml) <TAB> if ""identifiers"" in rule and rule[""identifiers""] is not None: <TAB>  <TAB> for i_type, i_value in rule[""identifiers""].items(): <MASK> if not checks.is_cce_value_valid(""CCE-"" + str(i_value)): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False","if i_type [ 0 : 3 ] == ""cce"" :",134
1298,"def _generate_table(self, fromdesc, todesc, diffs): <TAB> if fromdesc or todesc: <TAB>  <TAB> yield ( <TAB>  <TAB>  <TAB> simple_colorize(fromdesc, ""description""), <TAB>  <TAB>  <TAB> simple_colorize(todesc, ""description""), <TAB>  <TAB> ) <TAB> for i, line in enumerate(diffs): <TAB>  <TAB> if line is None: <TAB>  <TAB>  <TAB> # mdiff yields None on separator lines; skip the bogus ones <TAB>  <TAB>  <TAB> # generated for the first line <MASK> yield ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> simple_colorize(""---"", ""separator""), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> simple_colorize(""---"", ""separator""), <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield line",if i > 0 :,170
1299,"def _getPatternTemplate(pattern, key=None): <TAB> if key is None: <TAB>  <TAB> key = pattern <TAB>  <TAB> if ""%"" not in pattern: <TAB>  <TAB>  <TAB> key = pattern.upper() <TAB> template = DD_patternCache.get(key) <TAB> if not template: <TAB>  <TAB> if key in (""EPOCH"", ""{^LN-BEG}EPOCH"", ""^EPOCH""): <TAB>  <TAB>  <TAB> template = DateEpoch(lineBeginOnly=(key != ""EPOCH"")) <MASK> template = DateTai64n(wordBegin=(""start"" if key != ""TAI64N"" else False)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> template = DatePatternRegex(pattern) <TAB> DD_patternCache.set(key, template) <TAB> return template","elif key in ( ""TAI64N"" , ""{^LN-BEG}TAI64N"" , ""^TAI64N"" ) :",195
1300,"def ref_max_pooling_2d(x, kernel, stride, ignore_border, pad): <TAB> y = [] <TAB> for xx in x.reshape((-1,) + x.shape[-3:]): <MASK> xx = xx[np.newaxis] <TAB>  <TAB> y += [ <TAB>  <TAB>  <TAB> refs.pooling_2d(xx, ""max"", kernel, stride, pad, ignore_border)[np.newaxis] <TAB>  <TAB> ] <TAB> y = np.vstack(y) <TAB> if x.ndim == 2: <TAB>  <TAB> y = np.squeeze(y, 1) <TAB> return y.reshape(x.shape[:-3] + y.shape[1:])",if xx . ndim == 2 :,160
1301,"def show_topics(): <TAB> """"""prints all available miscellaneous help topics."""""" <TAB> print(_stash.text_color(""Miscellaneous Topics:"", ""yellow"")) <TAB> for pp in PAGEPATHS: <TAB>  <TAB> if not os.path.isdir(pp): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> content = os.listdir(pp) <TAB>  <TAB> for pn in content: <MASK> name = pn[: pn.index(""."")] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> name = pn <TAB>  <TAB>  <TAB> print(name)","if ""."" in pn :",125
1302,"def justify_toggle_auto(self, event=None): <TAB> c = self <TAB> if c.editCommands.autojustify == 0: <TAB>  <TAB> c.editCommands.autojustify = abs(c.config.getInt(""autojustify"") or 0) <MASK> g.es(""Autojustify on, @int autojustify == %s"" % c.editCommands.autojustify) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> g.es(""Set @int autojustify in @settings"") <TAB> else: <TAB>  <TAB> c.editCommands.autojustify = 0 <TAB>  <TAB> g.es(""Autojustify off"")",if c . editCommands . autojustify :,153
1303,"def render_token_list(self, tokens): <TAB> result = [] <TAB> vars = [] <TAB> for token in tokens: <MASK> result.append(token.contents.replace(""%"", ""%%"")) <TAB>  <TAB> elif token.token_type == TOKEN_VAR: <TAB>  <TAB>  <TAB> result.append(""%%(%s)s"" % token.contents) <TAB>  <TAB>  <TAB> vars.append(token.contents) <TAB> return """".join(result), vars",if token . token_type == TOKEN_TEXT :,113
1304,"def get_target_dimensions(self): <TAB> width, height = self.engine.size <TAB> for operation in self.operations: <TAB>  <TAB> if operation[""type""] == ""crop"": <TAB>  <TAB>  <TAB> width = operation[""right""] - operation[""left""] <TAB>  <TAB>  <TAB> height = operation[""bottom""] - operation[""top""] <MASK> width = operation[""width""] <TAB>  <TAB>  <TAB> height = operation[""height""] <TAB> return (width, height)","if operation [ ""type"" ] == ""resize"" :",112
1305,"def get_eval_matcher(self): <TAB> if isinstance(self.data[""match""], str): <MASK> values = [""explicitDeny"", ""implicitDeny""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> values = [""allowed""] <TAB>  <TAB> vf = ValueFilter( <TAB>  <TAB>  <TAB> {""type"": ""value"", ""key"": ""EvalDecision"", ""value"": values, ""op"": ""in""} <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> vf = ValueFilter(self.data[""match""]) <TAB> vf.annotate = False <TAB> return vf","if self . data [ ""match"" ] == ""denied"" :",140
1306,"def test_training(self): <TAB> if not self.model_tester.is_training: <TAB>  <TAB> return <TAB> config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common() <TAB> config.return_dict = True <TAB> for model_class in self.all_model_classes: <MASK> continue <TAB>  <TAB> model = model_class(config) <TAB>  <TAB> model.to(torch_device) <TAB>  <TAB> model.train() <TAB>  <TAB> inputs = self._prepare_for_class(inputs_dict, model_class, return_labels=True) <TAB>  <TAB> loss = model(**inputs).loss <TAB>  <TAB> loss.backward()",if model_class in MODEL_MAPPING . values ( ) :,168
1307,"def prehook(self, emu, op, eip): <TAB> if op in self.badops: <TAB>  <TAB> emu.stopEmu() <TAB>  <TAB> raise v_exc.BadOpBytes(op.va) <TAB> if op.mnem in STOS: <MASK> reg = emu.getRegister(envi.archs.i386.REG_EDI) <TAB>  <TAB> elif self.arch == ""amd64"": <TAB>  <TAB>  <TAB> reg = emu.getRegister(envi.archs.amd64.REG_RDI) <TAB>  <TAB> if self.vw.isValidPointer(reg) and self.vw.getLocation(reg) is None: <TAB>  <TAB>  <TAB> self.vw.makePointer(reg, follow=True)","if self . arch == ""i386"" :",186
1308,"def test_len(self): <TAB> eq = self.assertEqual <TAB> eq(base64mime.base64_len(""hello""), len(base64mime.encode(""hello"", eol=""""))) <TAB> for size in range(15): <MASK> bsize = 0 <TAB>  <TAB> elif size <= 3: <TAB>  <TAB>  <TAB> bsize = 4 <TAB>  <TAB> elif size <= 6: <TAB>  <TAB>  <TAB> bsize = 8 <TAB>  <TAB> elif size <= 9: <TAB>  <TAB>  <TAB> bsize = 12 <TAB>  <TAB> elif size <= 12: <TAB>  <TAB>  <TAB> bsize = 16 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> bsize = 20 <TAB>  <TAB> eq(base64mime.base64_len(""x"" * size), bsize)",if size == 0 :,160
1309,"def __new__(cls, dependencies): <TAB> deps = check.list_param(dependencies, ""dependencies"", of_type=DependencyDefinition) <TAB> seen = {} <TAB> for dep in deps: <TAB>  <TAB> key = dep.solid + "":"" + dep.output <MASK> raise DagsterInvalidDefinitionError( <TAB>  <TAB>  <TAB>  <TAB> 'Duplicate dependencies on solid ""{dep.solid}"" output ""{dep.output}"" ' <TAB>  <TAB>  <TAB>  <TAB> ""used in the same MultiDependencyDefinition."".format(dep=dep) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> seen[key] = True <TAB> return super(MultiDependencyDefinition, cls).__new__(cls, deps)",if key in seen :,149
1310,"def get_explanation(self, spec): <TAB> """"""Expand an explanation."""""" <TAB> if spec: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> a = self.dns_txt(spec) <TAB>  <TAB>  <TAB> if len(a) == 1: <TAB>  <TAB>  <TAB>  <TAB> return str(self.expand(to_ascii(a[0]), stripdot=False)) <TAB>  <TAB> except PermError: <TAB>  <TAB>  <TAB> # RFC4408 6.2/4 syntax errors cause exp= to be ignored <MASK> raise  # but report in harsh mode for record checking tools <TAB>  <TAB>  <TAB> pass <TAB> elif self.strict > 1: <TAB>  <TAB> raise PermError(""Empty domain-spec on exp="") <TAB> # RFC4408 6.2/4 empty domain spec is ignored <TAB> # (unless you give precedence to the grammar). <TAB> return None",if self . strict > 1 :,200
1311,"def build(self): <TAB> if self.args.get(""sle_id""): <TAB>  <TAB> self.process_sle_against_current_voucher() <TAB> else: <TAB>  <TAB> entries_to_fix = self.get_future_entries_to_fix() <TAB>  <TAB> i = 0 <TAB>  <TAB> while i < len(entries_to_fix): <TAB>  <TAB>  <TAB> sle = entries_to_fix[i] <TAB>  <TAB>  <TAB> i += 1 <TAB>  <TAB>  <TAB> self.process_sle(sle) <MASK> self.get_dependent_entries_to_fix(entries_to_fix, sle) <TAB> if self.exceptions: <TAB>  <TAB> self.raise_exceptions() <TAB> self.update_bin()",if sle . dependant_sle_voucher_detail_no :,187
1312,"def ValidateStopLatitude(self, problems): <TAB> if self.stop_lat is not None: <TAB>  <TAB> value = self.stop_lat <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if not isinstance(value, (float, int)): <TAB>  <TAB>  <TAB>  <TAB> self.stop_lat = util.FloatStringToFloat(value, problems) <TAB>  <TAB> except (ValueError, TypeError): <TAB>  <TAB>  <TAB> problems.InvalidValue(""stop_lat"", value) <TAB>  <TAB>  <TAB> del self.stop_lat <TAB>  <TAB> else: <MASK> problems.InvalidValue(""stop_lat"", value)",if self . stop_lat > 90 or self . stop_lat < - 90 :,153
1313,"def set(self, obj, **kwargs): <TAB> """"""Check for missing event functions and substitute these with"""""" <TAB> """"""the ignore method"""""" <TAB> ignore = getattr(self, ""ignore"") <TAB> for k, v in kwargs.iteritems(): <TAB>  <TAB> setattr(self, k, getattr(obj, v)) <MASK> for k1 in self.combinations[k]: <TAB>  <TAB>  <TAB>  <TAB> if not hasattr(self, k1): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> setattr(self, k1, ignore)",if k in self . combinations :,121
1314,"def split(self, duration, include_remainder=True): <TAB> # Convert seconds to timedelta, if appropriate. <TAB> duration = _seconds_or_timedelta(duration) <TAB> if duration <= timedelta(seconds=0): <TAB>  <TAB> raise ValueError(""cannot call split with a non-positive timedelta"") <TAB> start = self.start <TAB> while start < self.end: <TAB>  <TAB> if start + duration <= self.end: <TAB>  <TAB>  <TAB> yield MayaInterval(start, start + duration) <MASK> yield MayaInterval(start, self.end) <TAB>  <TAB> start += duration",elif include_remainder :,137
1315,"def get_first_field(layout, clz): <TAB> for layout_object in layout.fields: <TAB>  <TAB> if issubclass(layout_object.__class__, clz): <TAB>  <TAB>  <TAB> return layout_object <MASK> gf = get_first_field(layout_object, clz) <TAB>  <TAB>  <TAB> if gf: <TAB>  <TAB>  <TAB>  <TAB> return gf","elif hasattr ( layout_object , ""get_field_names"" ) :",94
1316,"def _getPatternTemplate(pattern, key=None): <TAB> if key is None: <TAB>  <TAB> key = pattern <TAB>  <TAB> if ""%"" not in pattern: <TAB>  <TAB>  <TAB> key = pattern.upper() <TAB> template = DD_patternCache.get(key) <TAB> if not template: <MASK> template = DateEpoch(lineBeginOnly=(key != ""EPOCH"")) <TAB>  <TAB> elif key in (""TAI64N"", ""{^LN-BEG}TAI64N"", ""^TAI64N""): <TAB>  <TAB>  <TAB> template = DateTai64n(wordBegin=(""start"" if key != ""TAI64N"" else False)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> template = DatePatternRegex(pattern) <TAB> DD_patternCache.set(key, template) <TAB> return template","if key in ( ""EPOCH"" , ""{^LN-BEG}EPOCH"" , ""^EPOCH"" ) :",195
1317,"def findOwningViewController(self, object): <TAB> while object: <MASK> description = fb.evaluateExpressionValue(object).GetObjectDescription() <TAB>  <TAB>  <TAB> print(""Found the owning view controller.\n{}"".format(description)) <TAB>  <TAB>  <TAB> cmd = 'echo {} | tr -d ""\n"" | pbcopy'.format(object) <TAB>  <TAB>  <TAB> os.system(cmd) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> object = self.nextResponder(object) <TAB> print(""Could not find an owning view controller"")",if self . isViewController ( object ) :,141
1318,"def __get_file_by_num(self, num, file_list, idx=0): <TAB> for element in file_list: <TAB>  <TAB> if idx == num: <TAB>  <TAB>  <TAB> return element <TAB>  <TAB> if element[3] and element[4]: <TAB>  <TAB>  <TAB> i = self.__get_file_by_num(num, element[3], idx + 1) <MASK> return i <TAB>  <TAB>  <TAB> idx = i <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> idx += 1 <TAB> return idx","if not isinstance ( i , int ) :",127
1319,"def promtool(**kwargs): <TAB> key = ""prometheus:promtool"" <TAB> try: <TAB>  <TAB> path = pathlib.Path(util.setting(key)) <TAB> except TypeError: <TAB>  <TAB> yield checks.Warning( <TAB>  <TAB>  <TAB> ""Missing setting for %s in %s "" % (key, settings.PROMGEN_CONFIG_FILE), <TAB>  <TAB>  <TAB> id=""promgen.W001"", <TAB>  <TAB> ) <TAB> else: <MASK> yield checks.Warning(""Unable to execute file %s"" % path, id=""promgen.W003"")","if not os . access ( path , os . X_OK ) :",141
1320,"def parse_config(schema, config): <TAB> schemaparser = ConfigParser() <TAB> schemaparser.readfp(StringIO(schema)) <TAB> cfgparser = ConfigParser() <TAB> cfgparser.readfp(StringIO(config)) <TAB> result = {} <TAB> for section in cfgparser.sections(): <TAB>  <TAB> result_section = {} <TAB>  <TAB> schema = {} <MASK> schema = dict(schemaparser.items(section)) <TAB>  <TAB> for key, value in cfgparser.items(section): <TAB>  <TAB>  <TAB> converter = converters[schema.get(key, ""string"")] <TAB>  <TAB>  <TAB> result_section[key] = converter(value) <TAB>  <TAB> result[section] = result_section <TAB> return result",if section in schemaparser . sections ( ) :,165
1321,"def validate_arguments(args): <TAB> if args.num_pss < 1: <TAB>  <TAB> print(""Value error: must have ore than one parameter servers."") <TAB>  <TAB> exit(1) <TAB> if not GPU_IDS: <TAB>  <TAB> num_cpus = multiprocessing.cpu_count() <MASK> print( <TAB>  <TAB>  <TAB>  <TAB> ""Value error: there are %s available CPUs but you are requiring %s."" <TAB>  <TAB>  <TAB>  <TAB> % (num_cpus, args.cpu_trainers) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> exit(1) <TAB> if not os.path.isfile(args.file): <TAB>  <TAB> print(""Value error: model trainning file does not exist"") <TAB>  <TAB> exit(1)",if args . cpu_trainers > num_cpus :,177
1322,"def infer_dataset_impl(path): <TAB> if IndexedRawTextDataset.exists(path): <TAB>  <TAB> return ""raw"" <TAB> elif IndexedDataset.exists(path): <TAB>  <TAB> with open(index_file_path(path), ""rb"") as f: <TAB>  <TAB>  <TAB> magic = f.read(8) <TAB>  <TAB>  <TAB> if magic == IndexedDataset._HDR_MAGIC: <TAB>  <TAB>  <TAB>  <TAB> return ""cached"" <MASK> return ""mmap"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return None <TAB> elif FastaDataset.exists(path): <TAB>  <TAB> return ""fasta"" <TAB> else: <TAB>  <TAB> return None",elif magic == MMapIndexedDataset . Index . _HDR_MAGIC [ : 8 ] :,167
1323,"def _add_resource_group(obj): <TAB> if isinstance(obj, list): <TAB>  <TAB> for array_item in obj: <TAB>  <TAB>  <TAB> _add_resource_group(array_item) <TAB> elif isinstance(obj, dict): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if ""resourcegroup"" not in [x.lower() for x in obj.keys()]: <MASK> obj[""resourceGroup""] = _parse_id(obj[""id""])[""resource-group""] <TAB>  <TAB> except (KeyError, IndexError, TypeError): <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> for item_key in obj: <TAB>  <TAB>  <TAB> if item_key != ""sourceVault"": <TAB>  <TAB>  <TAB>  <TAB> _add_resource_group(obj[item_key])","if obj [ ""id"" ] :",175
1324,"def reformatBody(self, event=None): <TAB> """"""Reformat all paragraphs in the body."""""" <TAB> c, p = self, self.p <TAB> undoType = ""reformat-body"" <TAB> w = c.frame.body.wrapper <TAB> c.undoer.beforeChangeGroup(p, undoType) <TAB> w.setInsertPoint(0) <TAB> while 1: <TAB>  <TAB> progress = w.getInsertPoint() <TAB>  <TAB> c.reformatParagraph(event, undoType=undoType) <TAB>  <TAB> ins = w.getInsertPoint() <TAB>  <TAB> s = w.getAllText() <TAB>  <TAB> w.setInsertPoint(ins) <MASK> break <TAB> c.undoer.afterChangeGroup(p, undoType)",if ins <= progress or ins >= len ( s ) :,181
1325,"def make_sources(project: RootDependency) -> str: <TAB> content = [] <TAB> if project.readme: <TAB>  <TAB> content.append(project.readme.path.name) <MASK> content.append(project.readme.to_rst().path.name) <TAB> path = project.package.path <TAB> for fname in (""setup.cfg"", ""setup.py""): <TAB>  <TAB> if (path / fname).exists(): <TAB>  <TAB>  <TAB> content.append(fname) <TAB> for package in chain(project.package.packages, project.package.data): <TAB>  <TAB> for fpath in package: <TAB>  <TAB>  <TAB> fpath = fpath.relative_to(project.package.path) <TAB>  <TAB>  <TAB> content.append(""/"".join(fpath.parts)) <TAB> return ""\n"".join(content)","if project . readme . markup != ""rst"" :",193
1326,"def __init__(self, response): <TAB> error = ""{} {}"".format(response.status_code, response.reason) <TAB> extra = [] <TAB> try: <TAB>  <TAB> response_json = response.json() <MASK> error = "" "".join(error[""message""] for error in response_json[""error_list""]) <TAB>  <TAB>  <TAB> extra = [ <TAB>  <TAB>  <TAB>  <TAB> error[""extra""] <TAB>  <TAB>  <TAB>  <TAB> for error in response_json[""error_list""] <TAB>  <TAB>  <TAB>  <TAB> if ""extra"" in error <TAB>  <TAB>  <TAB> ] <TAB> except JSONDecodeError: <TAB>  <TAB> pass <TAB> super().__init__(response=response, error=error, extra=extra)","if ""error_list"" in response_json :",161
1327,"def handle_event(self, fileno=None, events=None): <TAB> if self._state == RUN: <MASK> self._it = self._process_result(0)  # non-blocking <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> next(self._it) <TAB>  <TAB> except (StopIteration, CoroStop): <TAB>  <TAB>  <TAB> self._it = None",if self . _it is None :,92
1328,"def find_query(self, needle, haystack): <TAB> try: <TAB>  <TAB> import pinyin <TAB>  <TAB> haystack_py = pinyin.get_initial(haystack, """") <TAB>  <TAB> needle_len = len(needle) <TAB>  <TAB> start = 0 <TAB>  <TAB> result = [] <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> found = haystack_py.find(needle, start) <MASK> break <TAB>  <TAB>  <TAB> result.append((found, needle_len)) <TAB>  <TAB>  <TAB> start = found + needle_len <TAB>  <TAB> return result <TAB> except: <TAB>  <TAB> return None",if found < 0 :,136
1329,"def decorated_function(*args, **kwargs): <TAB> rv = f(*args, **kwargs) <TAB> if ""Last-Modified"" not in rv.headers: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> result = date <TAB>  <TAB>  <TAB> if callable(result): <TAB>  <TAB>  <TAB>  <TAB> result = result(rv) <TAB>  <TAB>  <TAB> if not isinstance(result, basestring): <TAB>  <TAB>  <TAB>  <TAB> from werkzeug.http import http_date <TAB>  <TAB>  <TAB>  <TAB> result = http_date(result) <MASK> rv.headers[""Last-Modified""] = result <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> logging.getLogger(__name__).exception( <TAB>  <TAB>  <TAB>  <TAB> ""Error while calculating the lastmodified value for response {!r}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> rv <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> return rv",if result :,189
1330,"def check_require(require_modules, require_lines): <TAB> for require_module in require_modules: <TAB>  <TAB> st = try_import(require_module) <TAB>  <TAB> if st == 0: <TAB>  <TAB>  <TAB> continue <MASK> print( <TAB>  <TAB>  <TAB>  <TAB> ""installed {}: {}\n"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> require_module, require_lines[require_module] <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> elif st == 2: <TAB>  <TAB>  <TAB> print( <TAB>  <TAB>  <TAB>  <TAB> ""failed installed {}: {}\n"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> require_module, require_lines[require_module] <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> )",elif st == 1 :,164
1331,"def bundle_directory(self, dirpath): <TAB> """"""Bundle all modules/packages in the given directory."""""" <TAB> dirpath = os.path.abspath(dirpath) <TAB> for nm in os.listdir(dirpath): <TAB>  <TAB> nm = _u(nm) <TAB>  <TAB> if nm.startswith("".""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> itempath = os.path.join(dirpath, nm) <TAB>  <TAB> if os.path.isdir(itempath): <TAB>  <TAB>  <TAB> if os.path.exists(os.path.join(itempath, ""__init__.py"")): <TAB>  <TAB>  <TAB>  <TAB> self.bundle_package(itempath) <MASK> self.bundle_module(itempath)","elif nm . endswith ( "".py"" ) :",160
1332,"def _find_root(): <TAB> test_dirs = [""Src"", ""Build"", ""Package"", ""Tests"", ""Util""] <TAB> root = os.getcwd() <TAB> test = all([os.path.exists(os.path.join(root, x)) for x in test_dirs]) <TAB> while not test: <TAB>  <TAB> last_root = root <TAB>  <TAB> root = os.path.dirname(root) <MASK> raise Exception(""Root not found"") <TAB>  <TAB> test = all([os.path.exists(os.path.join(root, x)) for x in test_dirs]) <TAB> return root",if root == last_root :,148
1333,"def findMarkForUnitTestNodes(self): <TAB> """"""return the position of *all* non-ignored @mark-for-unit-test nodes."""""" <TAB> c = self.c <TAB> p, result, seen = c.rootPosition(), [], [] <TAB> while p: <TAB>  <TAB> if p.v in seen: <TAB>  <TAB>  <TAB> p.moveToNodeAfterTree() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> seen.append(p.v) <TAB>  <TAB>  <TAB> if g.match_word(p.h, 0, ""@ignore""): <TAB>  <TAB>  <TAB>  <TAB> p.moveToNodeAfterTree() <MASK> result.append(p.copy()) <TAB>  <TAB>  <TAB>  <TAB> p.moveToNodeAfterTree() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> p.moveToThreadNext() <TAB> return result","elif p . h . startswith ( ""@mark-for-unit-tests"" ) :",200
1334,"def startTagFrameset(self, token): <TAB> self.parser.parseError(""unexpected-start-tag"", {""name"": ""frameset""}) <TAB> if len(self.tree.openElements) == 1 or self.tree.openElements[1].name != ""body"": <TAB>  <TAB> assert self.parser.innerHTML <TAB> elif not self.parser.framesetOK: <TAB>  <TAB> pass <TAB> else: <MASK> self.tree.openElements[1].parent.removeChild(self.tree.openElements[1]) <TAB>  <TAB> while self.tree.openElements[-1].name != ""html"": <TAB>  <TAB>  <TAB> self.tree.openElements.pop() <TAB>  <TAB> self.tree.insertElement(token) <TAB>  <TAB> self.parser.phase = self.parser.phases[""inFrameset""]",if self . tree . openElements [ 1 ] . parent :,193
1335,"def try_split(self, split_text: List[str]): <TAB> ret = [] <TAB> for i in split_text: <MASK> continue <TAB>  <TAB> val = int(i, 2) <TAB>  <TAB> if val > 255 or val < 0: <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> ret.append(val) <TAB> if len(ret) != 0: <TAB>  <TAB> ret = bytes(ret) <TAB>  <TAB> logger.debug(f""binary successful, returning {ret.__repr__()}"") <TAB>  <TAB> return ret",if len ( i ) == 0 :,127
1336,"def generator(self, data): <TAB> for sock in data: <MASK> offset = sock.obj_offset <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> offset = sock.obj_vm.vtop(sock.obj_offset) <TAB>  <TAB> yield ( <TAB>  <TAB>  <TAB> 0, <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB> Address(offset), <TAB>  <TAB>  <TAB>  <TAB> int(sock.Pid), <TAB>  <TAB>  <TAB>  <TAB> int(sock.LocalPort), <TAB>  <TAB>  <TAB>  <TAB> int(sock.Protocol), <TAB>  <TAB>  <TAB>  <TAB> str(protos.protos.get(sock.Protocol.v(), ""-"")), <TAB>  <TAB>  <TAB>  <TAB> str(sock.LocalIpAddress), <TAB>  <TAB>  <TAB>  <TAB> str(sock.CreateTime), <TAB>  <TAB>  <TAB> ], <TAB>  <TAB> )",if not self . _config . PHYSICAL_OFFSET :,181
1337,"def __init__(self, num_bits=4, always_apply=False, p=0.5): <TAB> super(Posterize, self).__init__(always_apply, p) <TAB> if isinstance(num_bits, (list, tuple)): <MASK> self.num_bits = [to_tuple(i, 0) for i in num_bits] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.num_bits = to_tuple(num_bits, 0) <TAB> else: <TAB>  <TAB> self.num_bits = to_tuple(num_bits, num_bits)",if len ( num_bits ) == 3 :,146
1338,"def tearDown(self): <TAB> """"""Just in case yn00 creates some junk files, do a clean-up."""""" <TAB> del_files = [self.out_file, ""2YN.dN"", ""2YN.dS"", ""2YN.t"", ""rst"", ""rst1"", ""rub""] <TAB> for filename in del_files: <MASK> os.remove(filename) <TAB> if os.path.exists(self.working_dir): <TAB>  <TAB> for filename in os.listdir(self.working_dir): <TAB>  <TAB>  <TAB> filepath = os.path.join(self.working_dir, filename) <TAB>  <TAB>  <TAB> os.remove(filepath) <TAB>  <TAB> os.rmdir(self.working_dir)",if os . path . exists ( filename ) :,179
1339,"def reverse_search_history(self, searchfor, startpos=None): <TAB> if startpos is None: <TAB>  <TAB> startpos = self.history_cursor <TAB> if _ignore_leading_spaces: <TAB>  <TAB> res = [ <TAB>  <TAB>  <TAB> (idx, line.lstrip()) <TAB>  <TAB>  <TAB> for idx, line in enumerate(self.history[startpos:0:-1]) <MASK> ] <TAB> else: <TAB>  <TAB> res = [ <TAB>  <TAB>  <TAB> (idx, line) <TAB>  <TAB>  <TAB> for idx, line in enumerate(self.history[startpos:0:-1]) <TAB>  <TAB>  <TAB> if line.startswith(searchfor) <TAB>  <TAB> ] <TAB> if res: <TAB>  <TAB> self.history_cursor -= res[0][0] <TAB>  <TAB> return res[0][1].get_line_text() <TAB> return """"",if line . lstrip ( ) . startswith ( searchfor . lstrip ( ) ),198
1340,"def ComboBoxDroppedHeightTest(windows): <TAB> ""Check if each combobox height is the same as the reference"" <TAB> bugs = [] <TAB> for win in windows: <TAB>  <TAB> if not win.ref: <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> if win.DroppedRect().height() != win.ref.DroppedRect().height(): <TAB>  <TAB>  <TAB> bugs.append( <TAB>  <TAB>  <TAB>  <TAB> ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> win, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ], <TAB>  <TAB>  <TAB>  <TAB>  <TAB> {}, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> testname, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> 0, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> return bugs","if win . Class ( ) != ""ComboBox"" or win . ref . Class ( ) != ""ComboBox"" :",181
1341,"def get_changed(self): <TAB> if self._is_expression(): <TAB>  <TAB> result = self._get_node_text(self.ast) <TAB>  <TAB> if result == self.source: <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> return result <TAB> else: <TAB>  <TAB> collector = codeanalyze.ChangeCollector(self.source) <TAB>  <TAB> last_end = -1 <TAB>  <TAB> for match in self.matches: <TAB>  <TAB>  <TAB> start, end = match.get_region() <MASK> if not self._is_expression(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> last_end = end <TAB>  <TAB>  <TAB> replacement = self._get_matched_text(match) <TAB>  <TAB>  <TAB> collector.add_change(start, end, replacement) <TAB>  <TAB> return collector.get_changed()",if start < last_end :,189
1342,"def unpickle_from_file(file_path, gzip=False): <TAB> """"""Unpickle obj from file_path with gzipping."""""" <TAB> with tf.io.gfile.GFile(file_path, ""rb"") as f: <MASK> obj = pickle.load(f) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> with gzip_lib.GzipFile(fileobj=f, compresslevel=2) as gzipf: <TAB>  <TAB>  <TAB>  <TAB> obj = pickle.load(gzipf) <TAB> return obj",if not gzip :,116
1343,"def get_user_context(request, escape=False): <TAB> if isinstance(request, HttpRequest): <TAB>  <TAB> user = getattr(request, ""user"", None) <TAB>  <TAB> result = {""ip_address"": request.META[""REMOTE_ADDR""]} <TAB>  <TAB> if user and user.is_authenticated(): <TAB>  <TAB>  <TAB> result.update( <TAB>  <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""email"": user.email, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""id"": user.id, <TAB>  <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB> ) <MASK> result[""name""] = user.name <TAB> else: <TAB>  <TAB> result = {} <TAB> return mark_safe(json.dumps(result))",if user . name :,163
1344,"def get_item_address(self, item): <TAB> """"""Get an item's address as a collection of names"""""" <TAB> result = [] <TAB> while True: <TAB>  <TAB> name = self.tree_ctrl.GetItemPyData(item) <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result.insert(0, name) <TAB>  <TAB>  <TAB> item = self.tree_ctrl.GetItemParent(item) <TAB> return result",if name is None :,104
1345,"def closest_unseen(self, row1, col1, filter=None): <TAB> # find the closest unseen from this row/col <TAB> min_dist = maxint <TAB> closest_unseen = None <TAB> for row in range(self.height): <TAB>  <TAB> for col in range(self.width): <TAB>  <TAB>  <TAB> if filter is None or (row, col) not in filter: <MASK> dist = self.distance(row1, col1, row, col) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if dist < min_dist: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> min_dist = dist <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> closest_unseen = (row, col) <TAB> return closest_unseen",if self . map [ row ] [ col ] == UNSEEN :,174
1346,"def log_graph(self, model: LightningModule, input_array=None): <TAB> if self._log_graph: <MASK> input_array = model.example_input_array <TAB>  <TAB> if input_array is not None: <TAB>  <TAB>  <TAB> input_array = model._apply_batch_transfer_handler(input_array) <TAB>  <TAB>  <TAB> self.experiment.add_graph(model, input_array) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> rank_zero_warn( <TAB>  <TAB>  <TAB>  <TAB> ""Could not log computational graph since the"" <TAB>  <TAB>  <TAB>  <TAB> "" `model.example_input_array` attribute is not set"" <TAB>  <TAB>  <TAB>  <TAB> "" or `input_array` was not given"", <TAB>  <TAB>  <TAB>  <TAB> UserWarning, <TAB>  <TAB>  <TAB> )",if input_array is None :,182
1347,"def get_scene_exceptions_by_season(self, season=-1): <TAB> scene_exceptions = [] <TAB> for scene_exception in self.scene_exceptions: <TAB>  <TAB> if not len(scene_exception) == 2: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> scene_name, scene_season = scene_exception.split(""|"") <MASK> scene_exceptions.append(scene_name) <TAB> return scene_exceptions",if season == scene_season :,121
1348,def _clean_temp_files(): <TAB> for pattern in _temp_files: <TAB>  <TAB> for path in glob.glob(pattern): <MASK> os.remove(path) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> shutil.rmtree(path),if os . path . islink ( path ) or os . path . isfile ( path ) :,81
1349,"def wait_for_completion(self, job_id, offset, max_results, start_time, timeout): <TAB> """"""Wait for job completion and return the first page."""""" <TAB> while True: <TAB>  <TAB> result = self.get_query_results( <TAB>  <TAB>  <TAB> job_id=job_id, page_token=None, start_index=offset, max_results=max_results <TAB>  <TAB> ) <MASK> return result <TAB>  <TAB> if (time.time() - start_time) > timeout: <TAB>  <TAB>  <TAB> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> ""Timeout: the query doesn't finish within %d seconds."" % timeout <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> time.sleep(1)","if result [ ""jobComplete"" ] :",165
1350,"def get_data(self, element, ranges, style): <MASK> groups = element.groupby(element.kdims).items() <TAB> else: <TAB>  <TAB> groups = [(element.label, element)] <TAB> plots = [] <TAB> axis = ""x"" if self.invert_axes else ""y"" <TAB> for key, group in groups: <TAB>  <TAB> if element.kdims: <TAB>  <TAB>  <TAB> label = "","".join([d.pprint_value(v) for d, v in zip(element.kdims, key)]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> label = key <TAB>  <TAB> data = {axis: group.dimension_values(group.vdims[0]), ""name"": label} <TAB>  <TAB> plots.append(data) <TAB> return plots",if element . kdims :,176
1351,"def get_files(self, dirname): <TAB> if not self._data.has_key(dirname): <TAB>  <TAB> self._create(dirname) <TAB> else: <TAB>  <TAB> new_time = self._changed(dirname) <MASK> self._update(dirname, new_time) <TAB>  <TAB>  <TAB> dcLog.debug(""==> "" + ""\t\n"".join(self._data[dirname][""flist""])) <TAB> return self._data[dirname][""flist""]",if new_time :,112
1352,"def __init__(self, dir): <TAB> self.module_names = set() <TAB> for name in os.listdir(dir): <MASK> self.module_names.add(name[:-3]) <TAB>  <TAB> elif ""."" not in name: <TAB>  <TAB>  <TAB> self.module_names.add(name)","if name . endswith ( "".py"" ) :",79
1353,"def logic(): <TAB> for i in range(100): <TAB>  <TAB> yield clock.posedge, reset.negedge <MASK> count.next = 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if enable: <TAB>  <TAB>  <TAB>  <TAB> count.next = (count + 1) % n <TAB> raise StopSimulation",if reset == ACTIVE_LOW :,81
1354,"def sortkeypicker(keynames): <TAB> negate = set() <TAB> for i, k in enumerate(keynames): <TAB>  <TAB> if k[:1] == ""-"": <TAB>  <TAB>  <TAB> keynames[i] = k[1:] <TAB>  <TAB>  <TAB> negate.add(k[1:]) <TAB> def getit(adict): <TAB>  <TAB> composite = [adict[k] for k in keynames] <TAB>  <TAB> for i, (k, v) in enumerate(zip(keynames, composite)): <MASK> composite[i] = -v <TAB>  <TAB> return composite <TAB> return getit",if k in negate :,140
1355,"def show_image(self, wnd_name, img): <TAB> if wnd_name in self.named_windows: <MASK> self.named_windows[wnd_name] = 1 <TAB>  <TAB>  <TAB> self.on_create_window(wnd_name) <TAB>  <TAB>  <TAB> if wnd_name in self.capture_mouse_windows: <TAB>  <TAB>  <TAB>  <TAB> self.capture_mouse(wnd_name) <TAB>  <TAB> self.on_show_image(wnd_name, img) <TAB> else: <TAB>  <TAB> print(""show_image: named_window "", wnd_name, "" not found."")",if self . named_windows [ wnd_name ] == 0 :,159
1356,"def check_action_permitted(self): <TAB> if ( <TAB>  <TAB> self._action == ""sts:GetCallerIdentity"" <TAB> ):  # always allowed, even if there's an explicit Deny for it <TAB>  <TAB> return True <TAB> policies = self._access_key.collect_policies() <TAB> permitted = False <TAB> for policy in policies: <TAB>  <TAB> iam_policy = IAMPolicy(policy) <TAB>  <TAB> permission_result = iam_policy.is_action_permitted(self._action) <TAB>  <TAB> if permission_result == PermissionResult.DENIED: <TAB>  <TAB>  <TAB> self._raise_access_denied() <MASK> permitted = True <TAB> if not permitted: <TAB>  <TAB> self._raise_access_denied()",elif permission_result == PermissionResult . PERMITTED :,184
1357,"def _limit_value(key, value, config): <TAB> if config[key].get(""upper_limit""): <TAB>  <TAB> limit = config[key][""upper_limit""] <TAB>  <TAB> # auto handle datetime <TAB>  <TAB> if isinstance(value, datetime) and isinstance(limit, timedelta): <TAB>  <TAB>  <TAB> if config[key][""inverse""] is True: <MASK> value = datetime.now() - limit <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> if (datetime.now() + limit) < value: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value = datetime.now() + limit <TAB>  <TAB> elif value > limit: <TAB>  <TAB>  <TAB> value = limit <TAB> return value",if ( datetime . now ( ) - limit ) > value :,164
1358,"def replace_dataset_ids(path, key, value): <TAB> """"""Exchanges dataset_ids (HDA, LDA, HDCA, not Dataset) in input_values with dataset ids used in job."""""" <TAB> current_case = input_values <TAB> if key == ""id"": <TAB>  <TAB> for i, p in enumerate(path): <TAB>  <TAB>  <TAB> if isinstance(current_case, (list, dict)): <TAB>  <TAB>  <TAB>  <TAB> current_case = current_case[p] <MASK> return key, translate_values.get(current_case[""id""], value) <TAB> return key, value","if src == current_case . get ( ""src"" ) :",148
1359,"def load_ext(name, funcs): <TAB> ExtModule = namedtuple(""ExtModule"", funcs) <TAB> ext_list = [] <TAB> lib_root = os.path.dirname(os.path.dirname(os.path.realpath(__file__))) <TAB> for fun in funcs: <MASK> ext_list.append(extension.load(fun, name, lib_dir=lib_root).op) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ext_list.append(extension.load(fun, name, lib_dir=lib_root).op_) <TAB> return ExtModule(*ext_list)","if fun in [ ""nms"" , ""softnms"" ] :",146
1360,"def execute_action(self): <TAB> selected_actions = self.model_action.get_selected_results_with_index() <TAB> if selected_actions and self.args_for_action: <TAB>  <TAB> for name, _, act_idx in selected_actions: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> action = self.actions[act_idx] <MASK> action.act([arg for arg, _, _ in self.args_for_action], self) <TAB>  <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB>  <TAB> debug.log(""execute_action"", e)",if action :,140
1361,"def __getattr__(self, attr): <TAB> proxy = self.__proxy <TAB> if proxy and hasattr(proxy, attr): <TAB>  <TAB> return getattr(proxy, attr) <TAB> attrmap = self.__attrmap <TAB> if attr in attrmap: <TAB>  <TAB> source = attrmap[attr] <MASK> value = source() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = _import_object(source) <TAB>  <TAB> setattr(self, attr, value) <TAB>  <TAB> self.__log.debug(""loaded lazy attr %r: %r"", attr, value) <TAB>  <TAB> return value <TAB> raise AttributeError(""'module' object has no attribute '%s'"" % (attr,))",if callable ( source ) :,154
1362,"def forward(self, x): <TAB> # BxT -> BxCxT <TAB> x = x.unsqueeze(1) <TAB> for conv in self.conv_layers: <TAB>  <TAB> residual = x <TAB>  <TAB> x = conv(x) <MASK> tsz = x.size(2) <TAB>  <TAB>  <TAB> r_tsz = residual.size(2) <TAB>  <TAB>  <TAB> residual = residual[..., :: r_tsz // tsz][..., :tsz] <TAB>  <TAB>  <TAB> x = (x + residual) * self.residual_scale <TAB> if self.log_compression: <TAB>  <TAB> x = x.abs() <TAB>  <TAB> x = x + 1 <TAB>  <TAB> x = x.log() <TAB> return x",if self . skip_connections and x . size ( 1 ) == residual . size ( 1 ) :,186
1363,"def __Prefix_Step2a(self, token): <TAB> for prefix in self.__prefix_step2a: <MASK> token = token[len(prefix) :] <TAB>  <TAB>  <TAB> self.prefix_step2a_success = True <TAB>  <TAB>  <TAB> break <TAB> return token",if token . startswith ( prefix ) and len ( token ) > 5 :,81
1364,"def is_valid(sample): <TAB> if sample is None: <TAB>  <TAB> return False <TAB> if isinstance(sample, tuple): <TAB>  <TAB> for s in sample: <TAB>  <TAB>  <TAB> if s is None: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> elif isinstance(s, np.ndarray) and s.size == 0: <TAB>  <TAB>  <TAB>  <TAB> return False <MASK> return False <TAB> return True","elif isinstance ( s , collections . abc . Sequence ) and len ( s ) == 0 :",114
1365,"def get_all_comments(self, gallery_id, post_no, comment_cnt): <TAB> comment_page_cnt = (comment_cnt - 1) // self.options.comments_per_page + 1 <TAB> comments = [] <TAB> headers = {""X-Requested-With"": ""XMLHttpRequest""} <TAB> data = {""ci_t"": self._session.cookies[""ci_c""], ""id"": gallery_id, ""no"": post_no} <TAB> for i in range(comment_page_cnt): <TAB>  <TAB> data[""comment_page""] = i + 1 <TAB>  <TAB> response = self.request_comment(headers, data) <TAB>  <TAB> batch = self.parse_comments(response.text) <MASK> break <TAB>  <TAB> comments = batch + comments <TAB> return comments",if not batch :,187
1366,def run_on_module(self): <TAB> try: <TAB>  <TAB> self.module_base.disable(self.opts.module_spec) <TAB> except dnf.exceptions.MarkingErrors as e: <MASK> if e.no_match_group_specs or e.error_group_specs: <TAB>  <TAB>  <TAB>  <TAB> raise e <TAB>  <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB>  <TAB> e.module_depsolv_errors <TAB>  <TAB>  <TAB>  <TAB> and e.module_depsolv_errors[1] <TAB>  <TAB>  <TAB>  <TAB> != libdnf.module.ModulePackageContainer.ModuleErrorType_ERROR_IN_DEFAULTS <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> raise e <TAB>  <TAB> logger.error(str(e)),if self . base . conf . strict :,174
1367,"def find_field_notnull_differ(self, meta, table_description, table_name): <TAB> if not self.can_detect_notnull_differ: <TAB>  <TAB> return <TAB> for field in all_local_fields(meta): <TAB>  <TAB> attname = field.db_column or field.attname <MASK> continue <TAB>  <TAB> null = self.get_field_db_nullable(field, table_name) <TAB>  <TAB> if field.null != null: <TAB>  <TAB>  <TAB> action = field.null and ""DROP"" or ""SET"" <TAB>  <TAB>  <TAB> self.add_difference(""notnull-differ"", table_name, attname, action)","if ( table_name , attname ) in self . new_db_fields :",167
1368,"def _change_moving_module(self, changes, dest): <TAB> if not self.source.is_folder(): <TAB>  <TAB> pymodule = self.pycore.resource_to_pyobject(self.source) <TAB>  <TAB> source = self.import_tools.relatives_to_absolutes(pymodule) <TAB>  <TAB> pymodule = self.tools.new_pymodule(pymodule, source) <TAB>  <TAB> source = self._change_occurrences_in_module(dest, pymodule) <TAB>  <TAB> source = self.tools.new_source(pymodule, source) <MASK> changes.add_change(ChangeContents(self.source, source))",if source != self . source . read ( ) :,155
1369,"def get(quality_name): <TAB> """"""Returns a quality object based on canonical quality name."""""" <TAB> found_components = {} <TAB> for part in quality_name.lower().split(): <TAB>  <TAB> component = _registry.get(part) <MASK> raise ValueError(""`%s` is not a valid quality string"" % part) <TAB>  <TAB> if component.type in found_components: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""`%s` cannot be defined twice in a quality"" % component.type <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> found_components[component.type] = component <TAB> if not found_components: <TAB>  <TAB> raise ValueError(""No quality specified"") <TAB> result = Quality() <TAB> for type, component in found_components.items(): <TAB>  <TAB> setattr(result, type, component) <TAB> return result",if not component :,191
1370,def _unselected(self): <TAB> selected = self._selected <TAB> k = 0 <TAB> z = selected[k] <TAB> k += 1 <TAB> for i in range(self._n): <TAB>  <TAB> if i == z: <MASK> z = selected[k] <TAB>  <TAB>  <TAB>  <TAB> k += 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> z = -1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield i,if k < len ( selected ) :,107
1371,"def render_headers(self) -> bytes: <TAB> if not hasattr(self, ""_headers""): <TAB>  <TAB> parts = [ <TAB>  <TAB>  <TAB> b""Content-Disposition: form-data; "", <TAB>  <TAB>  <TAB> format_form_param(""name"", self.name), <TAB>  <TAB> ] <MASK> filename = format_form_param(""filename"", self.filename) <TAB>  <TAB>  <TAB> parts.extend([b""; "", filename]) <TAB>  <TAB> if self.content_type is not None: <TAB>  <TAB>  <TAB> content_type = self.content_type.encode() <TAB>  <TAB>  <TAB> parts.extend([b""\r\nContent-Type: "", content_type]) <TAB>  <TAB> parts.append(b""\r\n\r\n"") <TAB>  <TAB> self._headers = b"""".join(parts) <TAB> return self._headers",if self . filename :,189
1372,"def app_middleware(next, root, info, **kwargs): <TAB> app_auth_header = ""HTTP_AUTHORIZATION"" <TAB> prefix = ""bearer"" <TAB> request = info.context <TAB> if request.path == API_PATH: <TAB>  <TAB> if not hasattr(request, ""app""): <TAB>  <TAB>  <TAB> request.app = None <TAB>  <TAB>  <TAB> auth = request.META.get(app_auth_header, """").split() <MASK> auth_prefix, auth_token = auth <TAB>  <TAB>  <TAB>  <TAB> if auth_prefix.lower() == prefix: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> request.app = SimpleLazyObject(lambda: get_app(auth_token)) <TAB> return next(root, info, **kwargs)",if len ( auth ) == 2 :,171
1373,"def _shortest_hypernym_paths(self, simulate_root): <TAB> if self.offset == ""00000000"": <TAB>  <TAB> return {self: 0} <TAB> queue = deque([(self, 0)]) <TAB> path = {} <TAB> while queue: <TAB>  <TAB> s, depth = queue.popleft() <MASK> continue <TAB>  <TAB> path[s] = depth <TAB>  <TAB> depth += 1 <TAB>  <TAB> queue.extend((hyp, depth) for hyp in s._hypernyms()) <TAB> if simulate_root: <TAB>  <TAB> root = Synset(self._wordnet_corpus_reader, None, self.pos(), ""00000000"", """") <TAB>  <TAB> path[root] = max(path.values()) + 1 <TAB> return path",if s in path :,163
1374,"def _populate_class_variables(): <TAB> lookup = {} <TAB> reverse_lookup = {} <TAB> characters_for_re = [] <TAB> for codepoint, name in list(codepoint2name.items()): <TAB>  <TAB> character = chr(codepoint) <MASK> # There's no point in turning the quotation mark into <TAB>  <TAB>  <TAB> # &quot;, unless it happens within an attribute value, which <TAB>  <TAB>  <TAB> # is handled elsewhere. <TAB>  <TAB>  <TAB> characters_for_re.append(character) <TAB>  <TAB>  <TAB> lookup[character] = name <TAB>  <TAB> # But we do want to turn &quot; into the quotation mark. <TAB>  <TAB> reverse_lookup[name] = character <TAB> re_definition = ""[%s]"" % """".join(characters_for_re) <TAB> return lookup, reverse_lookup, re.compile(re_definition)",if codepoint != 34 :,193
1375,"def prepare_data_status(self, view: sublime.View, data: Dict[str, Any]) -> Any: <TAB> """"""Prepare the returned data for status"""""" <TAB> if ( <TAB>  <TAB> data[""success""] <TAB>  <TAB> and ""No docstring"" not in data[""doc""] <TAB>  <TAB> and data[""doc""] != ""list\n"" <TAB> ): <TAB>  <TAB> self.signature = data[""doc""] <MASK> return <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.signature = self.signature.splitlines()[2] <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> return self._show_status(view)",if self . _signature_excluded ( self . signature ) :,155
1376,"def _setup_once_tables(cls): <TAB> if cls.run_define_tables == ""once"": <TAB>  <TAB> cls.define_tables(cls.metadata) <MASK> cls.metadata.create_all(cls.bind) <TAB>  <TAB> cls.tables.update(cls.metadata.tables)","if cls . run_create_tables == ""once"" :",84
1377,"def _send_recursive(self, files): <TAB> for base in files: <MASK> # filename mixed into the bunch <TAB>  <TAB>  <TAB> self._send_files([base]) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> last_dir = asbytes(base) <TAB>  <TAB> for root, dirs, fls in os.walk(base): <TAB>  <TAB>  <TAB> self._chdir(last_dir, asbytes(root)) <TAB>  <TAB>  <TAB> self._send_files([os.path.join(root, f) for f in fls]) <TAB>  <TAB>  <TAB> last_dir = asbytes(root) <TAB>  <TAB> # back out of the directory <TAB>  <TAB> for i in range(len(os.path.split(last_dir))): <TAB>  <TAB>  <TAB> self._send_popd()",if not os . path . isdir ( base ) :,183
1378,"def __init__(self, *args, **kwargs): <TAB> super().__init__(*args, **kwargs) <TAB> # Automatically register models if required. <TAB> if not is_registered(self.model): <TAB>  <TAB> inline_fields = () <TAB>  <TAB> for inline in self.inlines: <TAB>  <TAB>  <TAB> inline_model, follow_field = self._reversion_introspect_inline_admin(inline) <TAB>  <TAB>  <TAB> if inline_model: <TAB>  <TAB>  <TAB>  <TAB> self._reversion_autoregister(inline_model, ()) <MASK> inline_fields += (follow_field,) <TAB>  <TAB> self._reversion_autoregister(self.model, inline_fields)",if follow_field :,161
1379,"def dispatch_hook(key, hooks, hook_data, **kwargs): <TAB> """"""Dispatches a hook dictionary on a given piece of data."""""" <TAB> hooks = hooks or dict() <TAB> hooks = hooks.get(key) <TAB> if hooks: <TAB>  <TAB> if hasattr(hooks, ""__call__""): <TAB>  <TAB>  <TAB> hooks = [hooks] <TAB>  <TAB> for hook in hooks: <TAB>  <TAB>  <TAB> _hook_data = hook(hook_data, **kwargs) <MASK> hook_data = _hook_data <TAB> return hook_data",if _hook_data is not None :,133
1380,"def __call__(self, image, crop=True): <TAB> if isinstance(image, PTensor): <TAB>  <TAB> return self.crop_to_output( <TAB>  <TAB>  <TAB> numpy_to_paddle(self(paddle_to_numpy(image), crop=False)) <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> warp = cv.warpAffine( <TAB>  <TAB>  <TAB> image, <TAB>  <TAB>  <TAB> self.transform_matrix, <TAB>  <TAB>  <TAB> image.shape[1::-1], <TAB>  <TAB>  <TAB> borderMode=cv.BORDER_REPLICATE, <TAB>  <TAB> ) <MASK> return self.crop_to_output(warp) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return warp",if crop :,157
1381,"def _analyze(self): <TAB> lines = open(self.log_path, ""r"").readlines() <TAB> prev_line = None <TAB> for line in lines: <MASK> self.errors.append(line[len(""ERROR:"") :].strip()) <TAB>  <TAB> elif line.startswith(""FAIL:"") and prev_line and prev_line.startswith(""=""): <TAB>  <TAB>  <TAB> self.failures.append(line[len(""FAIL:"") :].strip()) <TAB>  <TAB> prev_line = line","if line . startswith ( ""ERROR:"" ) and prev_line and prev_line . startswith ( ""="" ) :",128
1382,"def end(self, name): <TAB> self.soup.endData() <TAB> completed_tag = self.soup.tagStack[-1] <TAB> namespace, name = self._getNsTag(name) <TAB> nsprefix = None <TAB> if namespace is not None: <TAB>  <TAB> for inverted_nsmap in reversed(self.nsmaps): <MASK> nsprefix = inverted_nsmap[namespace] <TAB>  <TAB>  <TAB>  <TAB> break <TAB> self.soup.handle_endtag(name, nsprefix) <TAB> if len(self.nsmaps) > 1: <TAB>  <TAB> # This tag, or one of its parents, introduced a namespace <TAB>  <TAB> # mapping, so pop it off the stack. <TAB>  <TAB> self.nsmaps.pop()",if inverted_nsmap is not None and namespace in inverted_nsmap :,184
1383,"def _bind_parameters(operation, parameters): <TAB> # inspired by MySQL Python Connector (conversion.py) <TAB> string_parameters = {} <TAB> for (name, value) in parameters.iteritems(): <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB> string_parameters[name] = ""NULL"" <MASK> string_parameters[name] = ""'"" + _escape(value) + ""'"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> string_parameters[name] = str(value) <TAB> return operation % string_parameters","elif isinstance ( value , basestring ) :",126
1384,"def plugin_on_song_ended(self, song, skipped): <TAB> if song is not None: <TAB>  <TAB> rating = song(""~#rating"") <TAB>  <TAB> invrating = 1.0 - rating <TAB>  <TAB> delta = min(rating, invrating) / 2.0 <MASK> rating -= delta <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> rating += delta <TAB>  <TAB> song[""~#rating""] = rating",if skipped :,97
1385,"def on_activated_async(self, view): <TAB> if settings[""modified_lines_only""]: <TAB>  <TAB> self.freeze_last_version(view) <TAB> if settings[""enabled""]: <TAB>  <TAB> match_trailing_spaces(view) <TAB>  <TAB> # continuously watch view for changes to the visible region <MASK> # track <TAB>  <TAB>  <TAB> active_views[view.id()] = view.visible_region() <TAB>  <TAB>  <TAB> self.update_on_region_change(view)",if not view . id ( ) in active_views :,123
1386,"def _notin_text(term, text, verbose=False): <TAB> index = text.find(term) <TAB> head = text[:index] <TAB> tail = text[index + len(term) :] <TAB> correct_text = head + tail <TAB> diff = _diff_text(correct_text, text, verbose) <TAB> newdiff = [u(""%s is contained here:"") % py.io.saferepr(term, maxsize=42)] <TAB> for line in diff: <MASK> continue <TAB>  <TAB> if line.startswith(u(""- "")): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if line.startswith(u(""+ "")): <TAB>  <TAB>  <TAB> newdiff.append(u(""  "") + line[2:]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> newdiff.append(line) <TAB> return newdiff","if line . startswith ( u ( ""Skipping"" ) ) :",192
1387,"def delete_all(path): <TAB> ppath = os.getcwd() <TAB> os.chdir(path) <TAB> for fn in glob.glob(""*""): <TAB>  <TAB> fn_full = os.path.join(path, fn) <TAB>  <TAB> if os.path.isdir(fn): <TAB>  <TAB>  <TAB> delete_all(fn_full) <TAB>  <TAB> elif fn.endswith("".png""): <TAB>  <TAB>  <TAB> os.remove(fn_full) <MASK> os.remove(fn_full) <TAB>  <TAB> elif DELETE_ALL_OLD: <TAB>  <TAB>  <TAB> os.remove(fn_full) <TAB> os.chdir(ppath) <TAB> os.rmdir(path)","elif fn . endswith ( "".md"" ) :",158
1388,"def reward(self): <TAB> """"""Returns a tuple of sum of raw and processed rewards."""""" <TAB> raw_rewards, processed_rewards = 0, 0 <TAB> for ts in self.time_steps: <TAB>  <TAB> # NOTE: raw_reward and processed_reward are None for the first time-step. <TAB>  <TAB> if ts.raw_reward is not None: <TAB>  <TAB>  <TAB> raw_rewards += ts.raw_reward <MASK> processed_rewards += ts.processed_reward <TAB> return raw_rewards, processed_rewards",if ts . processed_reward is not None :,134
1389,"def formatmonthname(self, theyear, themonth, withyear=True): <TAB> with TimeEncoding(self.locale) as encoding: <TAB>  <TAB> s = month_name[themonth] <MASK> s = s.decode(encoding) <TAB>  <TAB> if withyear: <TAB>  <TAB>  <TAB> s = ""%s %s"" % (s, theyear) <TAB>  <TAB> return '<tr><th colspan=""7"" class=""month"">%s</th></tr>' % s",if encoding is not None :,115
1390,"def check_digest_auth(user, passwd): <TAB> """"""Check user authentication using HTTP Digest auth"""""" <TAB> if request.headers.get(""Authorization""): <TAB>  <TAB> credentails = parse_authorization_header(request.headers.get(""Authorization"")) <MASK> return <TAB>  <TAB> response_hash = response( <TAB>  <TAB>  <TAB> credentails, <TAB>  <TAB>  <TAB> passwd, <TAB>  <TAB>  <TAB> dict( <TAB>  <TAB>  <TAB>  <TAB> uri=request.script_root + request.path, <TAB>  <TAB>  <TAB>  <TAB> body=request.data, <TAB>  <TAB>  <TAB>  <TAB> method=request.method, <TAB>  <TAB>  <TAB> ), <TAB>  <TAB> ) <TAB>  <TAB> if credentails.get(""response"") == response_hash: <TAB>  <TAB>  <TAB> return True <TAB> return False",if not credentails :,165
1391,"def wrapped(self, request): <TAB> try: <TAB>  <TAB> return self._finished <TAB> except AttributeError: <MASK> if not request.session.shouldfail and not request.session.shouldstop: <TAB>  <TAB>  <TAB>  <TAB> log.debug( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""%s is still going to be used, not terminating it. "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Still in use on:\n%s"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pprint.pformat(list(self.node_ids)), <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> log.debug(""Finish called on %s"", self) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return func(request) <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self._finished = True",if self . node_ids :,185
1392,"def run_tests(): <TAB> # type: () -> None <TAB> x = 5 <TAB> with switch(x) as case: <TAB>  <TAB> if case(0): <TAB>  <TAB>  <TAB> print(""zero"") <TAB>  <TAB>  <TAB> print(""zero"") <TAB>  <TAB> elif case(1, 2): <TAB>  <TAB>  <TAB> print(""one or two"") <MASK> print(""three or four"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""default"") <TAB>  <TAB>  <TAB> print(""another"")","elif case ( 3 , 4 ) :",114
1393,"def task_done(self): <TAB> with self._cond: <MASK> raise ValueError(""task_done() called too many times"") <TAB>  <TAB> if self._unfinished_tasks._semlock._is_zero(): <TAB>  <TAB>  <TAB> self._cond.notify_all()",if not self . _unfinished_tasks . acquire ( False ) :,75
1394,"def _set_uid(self, val): <TAB> if val is not None: <MASK> self.bus.log(""pwd module not available; ignoring uid."", level=30) <TAB>  <TAB>  <TAB> val = None <TAB>  <TAB> elif isinstance(val, text_or_bytes): <TAB>  <TAB>  <TAB> val = pwd.getpwnam(val)[2] <TAB> self._uid = val",if pwd is None :,92
1395,"def process_tag(hive_name, company, company_key, tag, default_arch): <TAB> with winreg.OpenKeyEx(company_key, tag) as tag_key: <TAB>  <TAB> version = load_version_data(hive_name, company, tag, tag_key) <TAB>  <TAB> if version is not None:  # if failed to get version bail <TAB>  <TAB>  <TAB> major, minor, _ = version <TAB>  <TAB>  <TAB> arch = load_arch_data(hive_name, company, tag, tag_key, default_arch) <TAB>  <TAB>  <TAB> if arch is not None: <TAB>  <TAB>  <TAB>  <TAB> exe_data = load_exe(hive_name, company, company_key, tag) <MASK> exe, args = exe_data <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return company, major, minor, arch, exe, args",if exe_data is not None :,199
1396,"def run(algs): <TAB> for alg in algs: <TAB>  <TAB> vcs = alg.get(""variantcaller"") <TAB>  <TAB> if vcs: <TAB>  <TAB>  <TAB> if isinstance(vcs, dict): <TAB>  <TAB>  <TAB>  <TAB> vcs = reduce(operator.add, vcs.values()) <MASK> vcs = [vcs] <TAB>  <TAB>  <TAB> return any(vc.startswith(prefix) for vc in vcs if vc)","if not isinstance ( vcs , ( list , tuple ) ) :",117
1397,"def wrapper(self, *args, **kwargs): <TAB> if not self.request.path.endswith(""/""): <MASK> uri = self.request.path + ""/"" <TAB>  <TAB>  <TAB> if self.request.query: <TAB>  <TAB>  <TAB>  <TAB> uri += ""?"" + self.request.query <TAB>  <TAB>  <TAB> self.redirect(uri, permanent=True) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> raise HTTPError(404) <TAB> return method(self, *args, **kwargs)","if self . request . method in ( ""GET"" , ""HEAD"" ) :",118
1398,"def check_response(self, response): <TAB> """"""Specialized version of check_response()."""""" <TAB> for line in response: <TAB>  <TAB> # Skip blank lines: <MASK> continue <TAB>  <TAB> if line.startswith(b""OK""): <TAB>  <TAB>  <TAB> return <TAB>  <TAB> elif line.startswith(b""Benutzer/Passwort Fehler""): <TAB>  <TAB>  <TAB> raise BadLogin(line) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise FailedPost(""Server returned '%s'"" % six.ensure_text(line))",if not line . strip ( ) :,126
1399,"def Walk(self, hMenu=None): <TAB> if not hMenu: <TAB>  <TAB> hMenu = self.handle <TAB> n = user32.GetMenuItemCount(hMenu) <TAB> mi = MENUITEMINFO() <TAB> for i in range(n): <TAB>  <TAB> mi.fMask = 2  #  MIIM_ID <TAB>  <TAB> user32.GetMenuItemInfoA(hMenu, i, 1, byref(mi)) <TAB>  <TAB> handle = user32.GetSubMenu(hMenu, i) <MASK> yield handle, self.ListItems(handle) <TAB>  <TAB>  <TAB> for i in self.Walk(handle): <TAB>  <TAB>  <TAB>  <TAB> yield i",if handle :,157
1400,"def setSelection(self, labels): <TAB> input = self.__validateInput(labels) <TAB> if len(input) == 0 and not self.__allowEmptySelection: <TAB>  <TAB> return <TAB> if self.__allowMultipleSelection: <TAB>  <TAB> self.__selectedLabels[:] = input <TAB>  <TAB> self.__selectionChanged() <TAB> else: <MASK> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB> ""Parameter must be single item or a list with one element."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.__selectedLabels[:] = input <TAB>  <TAB>  <TAB> self.__selectionChanged() <TAB> # Remove all selected labels that are not in the menu, emit signals if necessary and update the button. <TAB> self.__validateState()",if len ( input ) > 1 :,168
1401,"def _parse(self, engine): <TAB> """"""Parse the layer."""""" <TAB> if isinstance(self.args, dict): <TAB>  <TAB> if ""axis"" in self.args: <TAB>  <TAB>  <TAB> self.axis = engine.evaluate(self.args[""axis""], recursive=True) <TAB>  <TAB>  <TAB> if not isinstance(self.axis, int): <TAB>  <TAB>  <TAB>  <TAB> raise ParsingError('""axis"" must be an integer.') <TAB>  <TAB> if ""momentum"" in self.args: <TAB>  <TAB>  <TAB> self.momentum = engine.evaluate(self.args[""momentum""], recursive=True) <MASK> raise ParsingError('""momentum"" must be numeric.')","if not isinstance ( self . momentum , ( int , float ) ) :",157
1402,"def get_order(self, aBuf): <TAB> if not aBuf: <TAB>  <TAB> return -1, 1 <TAB> # find out current char's byte length <TAB> first_char = wrap_ord(aBuf[0]) <TAB> if (0x81 <= first_char <= 0x9F) or (0xE0 <= first_char <= 0xFC): <TAB>  <TAB> charLen = 2 <TAB> else: <TAB>  <TAB> charLen = 1 <TAB> # return its order if it is hiragana <TAB> if len(aBuf) > 1: <TAB>  <TAB> second_char = wrap_ord(aBuf[1]) <MASK> return second_char - 0x9F, charLen <TAB> return -1, charLen",if ( first_char == 202 ) and ( 0x9F <= second_char <= 0xF1 ) :,194
1403,"def saveSpecial(self, **kwargs): <TAB> for kw in SPECIAL_BOOL_LIST + SPECIAL_VALUE_LIST + SPECIAL_LIST_LIST: <TAB>  <TAB> item = config.get_config(""misc"", kw) <TAB>  <TAB> value = kwargs.get(kw) <TAB>  <TAB> msg = item.set(value) <MASK> return badParameterResponse(msg) <TAB> config.save_config() <TAB> raise Raiser(self.__root)",if msg :,105
1404,"def sanitize_event_keys(kwargs, valid_keys): <TAB> # Sanity check: Don't honor keys that we don't recognize. <TAB> for key in list(kwargs.keys()): <MASK> kwargs.pop(key) <TAB> # Truncate certain values over 1k <TAB> for key in [""play"", ""role"", ""task"", ""playbook""]: <TAB>  <TAB> if isinstance(kwargs.get(""event_data"", {}).get(key), str): <TAB>  <TAB>  <TAB> if len(kwargs[""event_data""][key]) > 1024: <TAB>  <TAB>  <TAB>  <TAB> kwargs[""event_data""][key] = Truncator(kwargs[""event_data""][key]).chars( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> 1024 <TAB>  <TAB>  <TAB>  <TAB> )",if key not in valid_keys :,168
1405,"def toggleFactorReload(self, value=None): <TAB> self.serviceFittingOptions[""useGlobalForceReload""] = ( <TAB>  <TAB> value <TAB>  <TAB> if value is not None <TAB>  <TAB> else not self.serviceFittingOptions[""useGlobalForceReload""] <TAB> ) <TAB> fitIDs = set() <TAB> for fit in set(self._loadedFits): <MASK> continue <TAB>  <TAB> if fit.calculated: <TAB>  <TAB>  <TAB> fit.factorReload = self.serviceFittingOptions[""useGlobalForceReload""] <TAB>  <TAB>  <TAB> fit.clearFactorReloadDependentData() <TAB>  <TAB>  <TAB> fitIDs.add(fit.ID) <TAB> return fitIDs",if fit is None :,149
1406,"def closest_unseen(self, row1, col1, filter=None): <TAB> # find the closest unseen from this row/col <TAB> min_dist = maxint <TAB> closest_unseen = None <TAB> for row in range(self.height): <TAB>  <TAB> for col in range(self.width): <MASK> if self.map[row][col] == UNSEEN: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> dist = self.distance(row1, col1, row, col) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if dist < min_dist: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> min_dist = dist <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> closest_unseen = (row, col) <TAB> return closest_unseen","if filter is None or ( row , col ) not in filter :",174
1407,"def getAlphaClone(lookfor, eager=None): <TAB> if isinstance(lookfor, int): <MASK> item = get_gamedata_session().query(AlphaClone).get(lookfor) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> item = ( <TAB>  <TAB>  <TAB>  <TAB> get_gamedata_session() <TAB>  <TAB>  <TAB>  <TAB> .query(AlphaClone) <TAB>  <TAB>  <TAB>  <TAB> .options(*processEager(eager)) <TAB>  <TAB>  <TAB>  <TAB> .filter(AlphaClone.ID == lookfor) <TAB>  <TAB>  <TAB>  <TAB> .first() <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> raise TypeError(""Need integer as argument"") <TAB> return item",if eager is None :,150
1408,"def _rle_encode(string): <TAB> new = b"""" <TAB> count = 0 <TAB> for cur in string: <TAB>  <TAB> if not cur: <TAB>  <TAB>  <TAB> count += 1 <TAB>  <TAB> else: <MASK> new += b""\0"" + bytes([count]) <TAB>  <TAB>  <TAB>  <TAB> count = 0 <TAB>  <TAB>  <TAB> new += bytes([cur]) <TAB> return new",if count :,92
1409,def result_iterator(): <TAB> try: <TAB>  <TAB> for future in fs: <MASK> yield future.result() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield future.result(end_time - time.time()) <TAB> finally: <TAB>  <TAB> for future in fs: <TAB>  <TAB>  <TAB> future.cancel(),if timeout is None :,81
1410,"def _individual_get(self, segment, index_type, index, strictdoc): <TAB> if index_type == ""val"": <TAB>  <TAB> for key, value in segment.items(): <MASK> return value <TAB>  <TAB>  <TAB> if hasattr(key, ""text""): <TAB>  <TAB>  <TAB>  <TAB> if key.text == index[0]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return value <TAB>  <TAB> raise Exception(""Invalid state"") <TAB> elif index_type == ""index"": <TAB>  <TAB> return segment[index] <TAB> elif index_type == ""textslice"": <TAB>  <TAB> return segment[index[0] : index[1]] <TAB> elif index_type == ""key"": <TAB>  <TAB> return index[1] if strictdoc else index[0] <TAB> else: <TAB>  <TAB> raise Exception(""Invalid state"")",if key == index [ 0 ] :,186
1411,"def _reset_sequences(self, db_name): <TAB> conn = connections[db_name] <TAB> if conn.features.supports_sequence_reset: <TAB>  <TAB> sql_list = conn.ops.sequence_reset_by_name_sql( <TAB>  <TAB>  <TAB> no_style(), conn.introspection.sequence_list() <TAB>  <TAB> ) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> cursor = conn.cursor() <TAB>  <TAB>  <TAB>  <TAB> for sql in sql_list: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> cursor.execute(sql) <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> transaction.rollback_unless_managed(using=db_name) <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB>  <TAB> transaction.commit_unless_managed(using=db_name)",if sql_list :,177
1412,"def translate_to_statements(self, statements, conditional_write_vars): <TAB> lines = [] <TAB> for stmt in statements: <MASK> self.temporary_vars.add((stmt.var, stmt.dtype)) <TAB>  <TAB> line = self.translate_statement(stmt) <TAB>  <TAB> if stmt.var in conditional_write_vars: <TAB>  <TAB>  <TAB> subs = {} <TAB>  <TAB>  <TAB> condvar = conditional_write_vars[stmt.var] <TAB>  <TAB>  <TAB> lines.append(""if %s:"" % condvar) <TAB>  <TAB>  <TAB> lines.append(indent(line)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lines.append(line) <TAB> return lines","if stmt . op == "":="" and not stmt . var in self . variables :",168
1413,"def _bytecode_filenames(self, py_filenames): <TAB> bytecode_files = [] <TAB> for py_file in py_filenames: <TAB>  <TAB> # Since build_py handles package data installation, the <TAB>  <TAB> # list of outputs can contain more than just .py files. <TAB>  <TAB> # Make sure we only report bytecode for the .py files. <TAB>  <TAB> ext = os.path.splitext(os.path.normcase(py_file))[1] <TAB>  <TAB> if ext != PYTHON_SOURCE_EXTENSION: <TAB>  <TAB>  <TAB> continue <MASK> bytecode_files.append(py_file + ""c"") <TAB>  <TAB> if self.optimize > 0: <TAB>  <TAB>  <TAB> bytecode_files.append(py_file + ""o"") <TAB> return bytecode_files",if self . compile :,175
1414,"def logic(): <TAB> for i in range(100): <TAB>  <TAB> yield clock.posedge, reset.negedge <TAB>  <TAB> if reset == ACTIVE_LOW: <TAB>  <TAB>  <TAB> count.next = 0 <TAB>  <TAB> else: <MASK> count.next = (count + 1) % n <TAB> raise StopSimulation",if enable :,81
1415,"def _is_subnet_of(a, b): <TAB> try: <TAB>  <TAB> # Always false if one is v4 and the other is v6. <MASK> raise TypeError(""%s and %s are not of the same version"" % (a, b)) <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB> b.network_address <= a.network_address <TAB>  <TAB>  <TAB> and b.broadcast_address >= a.broadcast_address <TAB>  <TAB> ) <TAB> except AttributeError: <TAB>  <TAB> raise TypeError( <TAB>  <TAB>  <TAB> ""Unable to test subnet containment "" ""between %s and %s"" % (a, b) <TAB>  <TAB> )",if a . _version != b . _version :,153
1416,"def _filter_paths(basename, path, is_dir, exclude): <TAB> """""".gitignore style file filtering."""""" <TAB> for item in exclude: <TAB>  <TAB> # Items ending in '/' apply only to directories. <TAB>  <TAB> if item.endswith(""/"") and not is_dir: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # Items starting with '/' apply to the whole path. <TAB>  <TAB> # In any other cases just the basename is used. <TAB>  <TAB> match = path if item.startswith(""/"") else basename <MASK> return True <TAB> return False","if fnmatch . fnmatch ( match , item . strip ( ""/"" ) ) :",130
1417,"def __recv_null(self): <TAB> """"""Receive a null byte."""""" <TAB> while 1: <TAB>  <TAB> c = self.sock.recv(1) <TAB>  <TAB> if c == """": <TAB>  <TAB>  <TAB> self.close() <TAB>  <TAB>  <TAB> raise EOFError(""Socket Closed"") <MASK> return","if c == ""\0"" :",74
1418,"def onMessage(self, payload, isBinary): <TAB> if isBinary: <TAB>  <TAB> self.result = ""Expected text message with payload, but got binary."" <TAB> else: <MASK> self.result = ( <TAB>  <TAB>  <TAB>  <TAB> ""Expected text message with payload of length %d, but got %d."" <TAB>  <TAB>  <TAB>  <TAB> % (self.DATALEN, len(payload)) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ## FIXME : check actual content <TAB>  <TAB>  <TAB> ## <TAB>  <TAB>  <TAB> self.behavior = Case.OK <TAB>  <TAB>  <TAB> self.result = ""Received text message of length %d."" % len(payload) <TAB> self.p.createWirelog = True <TAB> self.p.sendClose(self.p.CLOSE_STATUS_CODE_NORMAL)",if len ( payload ) != self . DATALEN :,191
1419,"def rename_path(self, path, new_path): <TAB> logger.debug(""rename_path '%s' -> '%s'"" % (path, new_path)) <TAB> dirs = self.readdir(path) <TAB> for d in dirs: <MASK> continue <TAB>  <TAB> d_path = """".join([path, ""/"", d]) <TAB>  <TAB> d_new_path = """".join([new_path, ""/"", d]) <TAB>  <TAB> attr = self.getattr(d_path) <TAB>  <TAB> if stat.S_ISDIR(attr[""st_mode""]): <TAB>  <TAB>  <TAB> self.rename_path(d_path, d_new_path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.rename_item(d_path, d_new_path) <TAB> self.rename_item(path, new_path, dir=True)","if d in [ ""."" , "".."" ] :",196
1420,"def dir_box_click(self, double): <TAB> if double: <TAB>  <TAB> name = self.list_box.get_selected_name() <TAB>  <TAB> path = os.path.join(self.directory, name) <TAB>  <TAB> suffix = os.path.splitext(name)[1] <MASK> self.directory = path <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.double_click_file(name) <TAB> self.update()",if suffix not in self . suffixes and os . path . isdir ( path ) :,119
1421,"def __getattr__(self, key): <TAB> try: <TAB>  <TAB> value = self.__parent.contents[key] <TAB> except KeyError: <TAB>  <TAB> pass <TAB> else: <TAB>  <TAB> if value is not None: <MASK> return value.mod_ns <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> assert isinstance(value, _MultipleClassMarker) <TAB>  <TAB>  <TAB>  <TAB> return value.attempt_get(self.__parent.path, key) <TAB> raise AttributeError( <TAB>  <TAB> ""Module %r has no mapped classes "" <TAB>  <TAB> ""registered under the name %r"" % (self.__parent.name, key) <TAB> )","if isinstance ( value , _ModuleMarker ) :",154
1422,"def poll_thread(): <TAB> time.sleep(0.5) <TAB> if process.wait() and process_state: <TAB>  <TAB> time.sleep(0.25) <MASK> stdout, stderr = process._communicate(None) <TAB>  <TAB>  <TAB> logger.error( <TAB>  <TAB>  <TAB>  <TAB> ""Web server process exited unexpectedly"", <TAB>  <TAB>  <TAB>  <TAB> ""app"", <TAB>  <TAB>  <TAB>  <TAB> stdout=stdout, <TAB>  <TAB>  <TAB>  <TAB> stderr=stderr, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> time.sleep(1) <TAB>  <TAB>  <TAB> restart_server(1)",if not check_global_interrupt ( ) :,135
1423,"def apply_dateparser_timezone(utc_datetime, offset_or_timezone_abb): <TAB> for name, info in _tz_offsets: <MASK> tz = StaticTzInfo(name, info[""offset""]) <TAB>  <TAB>  <TAB> return utc_datetime.astimezone(tz)","if info [ ""regex"" ] . search ( "" %s"" % offset_or_timezone_abb ) :",87
1424,"def _load_wordlist(filename): <TAB> if filename is None: <TAB>  <TAB> return {} <TAB> path = None <TAB> for dir in (CONFIG_DIR, ASSETS_DIR): <TAB>  <TAB> path = os.path.realpath(os.path.join(dir, filename)) <MASK> break <TAB> words = {} <TAB> with open(path, encoding=""utf-8"") as f: <TAB>  <TAB> pairs = [word.strip().rsplit("" "", 1) for word in f] <TAB>  <TAB> pairs.sort(reverse=True, key=lambda x: int(x[1])) <TAB>  <TAB> words = {p[0]: int(p[1]) for p in pairs} <TAB> return words",if os . path . exists ( path ) :,168
1425,"def terminate_processes_matching_names(match_strings, kill=False): <TAB> """"""Terminates processes matching particular names (case sensitive)."""""" <TAB> if isinstance(match_strings, str): <TAB>  <TAB> match_strings = [match_strings] <TAB> for process in psutil.process_iter(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> process_info = process.as_dict(attrs=[""name"", ""pid""]) <TAB>  <TAB>  <TAB> process_name = process_info[""name""] <TAB>  <TAB> except (psutil.AccessDenied, psutil.NoSuchProcess, OSError): <TAB>  <TAB>  <TAB> continue <MASK> terminate_process(process_info[""pid""], kill)",if any ( x == process_name for x in match_strings ) :,159
1426,"def has_scheme(self, inp): <TAB> if ""://"" in inp: <TAB>  <TAB> return True <TAB> else: <TAB>  <TAB> authority = inp.replace(""/"", ""#"").replace(""?"", ""#"").split(""#"")[0] <MASK> _, host_or_port = authority.split("":"", 1) <TAB>  <TAB>  <TAB> # Assert it's not a port number <TAB>  <TAB>  <TAB> if re.match(r""^\d+$"", host_or_port): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> return True","if "":"" in authority :",126
1427,"def close(self): <TAB> with BrowserContext._BROWSER_LOCK: <TAB>  <TAB> BrowserContext._BROWSER_REFCNT -= 1 <MASK> logger.info(""Destroying browser main loop"") <TAB>  <TAB>  <TAB> BrowserContext._BROWSER_LOOP.destroy() <TAB>  <TAB>  <TAB> BrowserContext._BROWSER_LOOP = None",if BrowserContext . _BROWSER_REFCNT == 0 :,77
1428,"def _mock_get_merge_ticks(self, order_book_id_list, trading_date, last_dt=None): <TAB> for tick in self._ticks: <MASK> continue <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB> self.env.data_proxy.get_future_trading_date(tick.datetime).date() <TAB>  <TAB>  <TAB> != trading_date.date() <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if last_dt and tick.datetime <= last_dt: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> yield tick",if tick . order_book_id not in order_book_id_list :,146
1429,"def messageSourceStamps(self, source_stamps): <TAB> text = """" <TAB> for ss in source_stamps: <TAB>  <TAB> source = """" <MASK> source += ""[branch %s] "" % ss[""branch""] <TAB>  <TAB> if ss[""revision""]: <TAB>  <TAB>  <TAB> source += str(ss[""revision""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> source += ""HEAD"" <TAB>  <TAB> if ss[""patch""] is not None: <TAB>  <TAB>  <TAB> source += "" (plus patch)"" <TAB>  <TAB> discriminator = """" <TAB>  <TAB> if ss[""codebase""]: <TAB>  <TAB>  <TAB> discriminator = "" '%s'"" % ss[""codebase""] <TAB>  <TAB> text += ""Build Source Stamp%s: %s\n"" % (discriminator, source) <TAB> return text","if ss [ ""branch"" ] :",176
1430,"def test_open_read_bytes(self, sftp): <TAB> """"""Test reading bytes from a file"""""" <TAB> f = None <TAB> try: <TAB>  <TAB> self._create_file(""file"", ""xxx"") <TAB>  <TAB> f = yield from sftp.open(""file"", ""rb"") <TAB>  <TAB> self.assertEqual((yield from f.read()), b""xxx"") <TAB> finally: <MASK> # pragma: no branch <TAB>  <TAB>  <TAB> yield from f.close() <TAB>  <TAB> remove(""file"")",if f :,115
1431,"def handler(chan, host, port): <TAB> sock = socket() <TAB> try: <TAB>  <TAB> sock.connect((host, port)) <TAB> except Exception as e: <TAB>  <TAB> if verbose == True: <TAB>  <TAB>  <TAB> print(e) <TAB>  <TAB> return <TAB> while True: <TAB>  <TAB> r, w, x = select.select([sock, chan], [], []) <TAB>  <TAB> if sock in r: <TAB>  <TAB>  <TAB> data = sock.recv(1024) <TAB>  <TAB>  <TAB> if len(data) == 0: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> chan.send(data) <MASK> data = chan.recv(1024) <TAB>  <TAB>  <TAB> if len(data) == 0: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> sock.send(data) <TAB> chan.close() <TAB> sock.close()",if chan in r :,190
1432,"def detect(get_page): <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS: <TAB>  <TAB> page, headers, code = get_page(get=vector) <TAB>  <TAB> retval = re.search(r""url\('/ks-waf-error\.png'\)"", page, re.I) is not None <MASK> break <TAB> return retval",if retval :,94
1433,"def __init__(self, raw): <TAB> ticker_ticks = {} <TAB> for tick in raw[""results""]: <MASK> ticker_ticks[tick[""T""]].append(tick) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ticker_ticks[tick[""T""]] = [tick] <TAB> super().__init__( <TAB>  <TAB> {ticker: Aggsv2({""results"": ticks}) for ticker, ticks in ticker_ticks.items()} <TAB> )","if ticker_ticks . get ( tick [ ""T"" ] ) :",114
1434,"def _makefiles(self, f): <TAB> if isinstance(f, dict): <TAB>  <TAB> for k, v in list(f.items()): <MASK> self.makedir(dirname=k, content=v) <TAB>  <TAB>  <TAB> elif isinstance(v, str): <TAB>  <TAB>  <TAB>  <TAB> self.make_file(filename=k, content=v) <TAB>  <TAB>  <TAB> else:  # pragma: nocover <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""Unexpected:"", k, v) <TAB> elif isinstance(f, str): <TAB>  <TAB> self._make_empty_file(f) <TAB> elif isinstance(f, list): <TAB>  <TAB> self.make_list(f) <TAB> else:  # pragma: nocover <TAB>  <TAB> raise ValueError(""Unknown type:"", f)","if isinstance ( v , list ) :",182
1435,"def migrate_command_storage(apps, schema_editor): <TAB> model = apps.get_model(""terminal"", ""CommandStorage"") <TAB> init_storage_data(model) <TAB> setting = get_setting(apps, schema_editor, ""TERMINAL_COMMAND_STORAGE"") <TAB> if not setting: <TAB>  <TAB> return <TAB> values = get_storage_data(setting) <TAB> for name, meta in values.items(): <TAB>  <TAB> tp = meta.pop(""TYPE"") <MASK> continue <TAB>  <TAB> model.objects.create(name=name, type=tp, meta=meta)","if not tp or name in [ ""default"" , ""null"" ] :",146
1436,"def build_vertices(self, ulines): <TAB> vertex_idx = 0 <TAB> vertices = collections.OrderedDict() <TAB> for line in ulines: <TAB>  <TAB> for vt in line: <MASK> continue <TAB>  <TAB>  <TAB> new_vertex = (vt.u, vt.v, 0.0) <TAB>  <TAB>  <TAB> if new_vertex in vertices: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> vt.index = vertex_idx <TAB>  <TAB>  <TAB> vertex_idx += 1 <TAB>  <TAB>  <TAB> vertices[new_vertex] = 1 <TAB> return vertex_idx, list(vertices.keys())",if vt . replacement is not None :,145
1437,"def get_quarantine_count(self): <TAB> """"""get obj/container/account quarantine counts"""""" <TAB> qcounts = {""objects"": 0, ""containers"": 0, ""accounts"": 0} <TAB> qdir = ""quarantined"" <TAB> for device in os.listdir(self.devices): <TAB>  <TAB> for qtype in qcounts: <TAB>  <TAB>  <TAB> qtgt = os.path.join(self.devices, device, qdir, qtype) <TAB>  <TAB>  <TAB> if os.path.exists(qtgt): <TAB>  <TAB>  <TAB>  <TAB> linkcount = os.lstat(qtgt).st_nlink <MASK> qcounts[qtype] += linkcount - 2 <TAB> return qcounts",if linkcount > 2 :,171
1438,"def _format_arg(self, name, trait_spec, value): <TAB> if name == ""mask_file"": <TAB>  <TAB> return """" <TAB> if name == ""op_string"": <MASK> if isdefined(self.inputs.mask_file): <TAB>  <TAB>  <TAB>  <TAB> return self.inputs.op_string % self.inputs.mask_file <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""-k %s option in op_string requires mask_file"") <TAB> return super(ImageStats, self)._format_arg(name, trait_spec, value)","if ""-k %s"" in self . inputs . op_string :",146
1439,"def _update_theme_style(self, *args): <TAB> self.line_color_normal = self.theme_cls.divider_color <TAB> if not any([self.error, self._text_len_error]): <TAB>  <TAB> if not self.focus: <TAB>  <TAB>  <TAB> self._current_hint_text_color = self.theme_cls.disabled_hint_text_color <TAB>  <TAB>  <TAB> self._current_right_lbl_color = self.theme_cls.disabled_hint_text_color <MASK> self._current_error_color = self.theme_cls.disabled_hint_text_color","if self . helper_text_mode == ""persistent"" :",158
1440,"def createFields(self): <TAB> for item in self.format: <MASK> yield item[0](self, *item[1:-1], **item[-1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield item[0](self, *item[1:])","if isinstance ( item [ - 1 ] , dict ) :",72
1441,"def execute(self, statement, arguments=None): <TAB> while True: <TAB>  <TAB> try: <MASK> self.cursor.execute(statement, arguments) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.cursor.execute(statement) <TAB>  <TAB> except sqlite3.OperationalError as ex: <TAB>  <TAB>  <TAB> if ""locked"" not in getSafeExString(ex): <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> if statement.lstrip().upper().startswith(""SELECT""): <TAB>  <TAB> return self.cursor.fetchall()",if arguments :,130
1442,"def set_income_account_for_fixed_assets(self): <TAB> disposal_account = depreciation_cost_center = None <TAB> for d in self.get(""items""): <MASK> if not disposal_account: <TAB>  <TAB>  <TAB>  <TAB> ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> disposal_account, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> depreciation_cost_center, <TAB>  <TAB>  <TAB>  <TAB> ) = get_disposal_account_and_cost_center(self.company) <TAB>  <TAB>  <TAB> d.income_account = disposal_account <TAB>  <TAB>  <TAB> if not d.cost_center: <TAB>  <TAB>  <TAB>  <TAB> d.cost_center = depreciation_cost_center",if d . is_fixed_asset :,170
1443,"def _convertNbCharsInNbBits(self, nbChars): <TAB> nbMinBit = None <TAB> nbMaxBit = None <TAB> if nbChars is not None: <TAB>  <TAB> if isinstance(nbChars, int): <TAB>  <TAB>  <TAB> nbMinBit = nbChars * 8 <TAB>  <TAB>  <TAB> nbMaxBit = nbMinBit <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if nbChars[0] is not None: <TAB>  <TAB>  <TAB>  <TAB> nbMinBit = nbChars[0] * 8 <MASK> nbMaxBit = nbChars[1] * 8 <TAB> return (nbMinBit, nbMaxBit)",if nbChars [ 1 ] is not None :,158
1444,"def _get_service_full_name(self, name, help_command_table): <TAB> if help_command_table and name not in self._NON_SERVICE_COMMANDS: <MASK> return self._HIGH_LEVEL_SERVICE_FULL_NAMES[name] <TAB>  <TAB> service = help_command_table.get(name) <TAB>  <TAB> if service: <TAB>  <TAB>  <TAB> return service.service_model.metadata[""serviceFullName""]",if name in self . _HIGH_LEVEL_SERVICE_FULL_NAMES :,116
1445,"def print_addresses(self): <TAB> p = 3 <TAB> tmp_str = ""["" <TAB> if self.get_len() >= 7:  # at least one complete IP address <TAB>  <TAB> while 1: <MASK> tmp_str += ""#"" <TAB>  <TAB>  <TAB> tmp_str += self.get_ip_address(p) <TAB>  <TAB>  <TAB> p += 4 <TAB>  <TAB>  <TAB> if p >= self.get_len(): <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> tmp_str += "", "" <TAB> tmp_str += ""] "" <TAB> if self.get_ptr() % 4:  # ptr field should be a multiple of 4 <TAB>  <TAB> tmp_str += ""nonsense ptr field: %d "" % self.get_ptr() <TAB> return tmp_str",if p + 1 == self . get_ptr ( ) :,191
1446,"def run(self): <TAB> for _ in range(self.n): <TAB>  <TAB> error = True <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.collection.insert_one({""test"": ""insert""}) <TAB>  <TAB>  <TAB> error = False <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> if not self.expect_exception: <TAB>  <TAB>  <TAB>  <TAB> raise <MASK> assert error",if self . expect_exception :,91
1447,"def create_composite_mounter_by_args(args): <TAB> """"""Creates a CompositeMounter by the images in given args."""""" <TAB> logging.info(""Mount images..."") <TAB> mounter = composite_mounter.CompositeMounter() <TAB> for partition in composite_mounter.SUPPORTED_PARTITIONS: <TAB>  <TAB> image_source = vars(args)[partition] <MASK> logging.info(""  %s=%s"", partition, image_source) <TAB>  <TAB>  <TAB> mounter.add_by_mount_target(partition, image_source) <TAB> if mounter.is_empty(): <TAB>  <TAB> raise RuntimeError(""Must give at least one image source."") <TAB> return mounter",if image_source :,162
1448,"def _get_containing_class(self, pyname): <TAB> if isinstance(pyname, pynames.DefinedName): <TAB>  <TAB> scope = pyname.get_object().get_scope() <TAB>  <TAB> parent = scope.parent <MASK> return parent.pyobject","if parent is not None and parent . get_kind ( ) == ""Class"" :",80
1449,"def test_chunkcoding(self): <TAB> tstring_lines = [] <TAB> for b in self.tstring: <TAB>  <TAB> lines = b.split(b""\n"") <TAB>  <TAB> last = lines.pop() <TAB>  <TAB> assert last == b"""" <TAB>  <TAB> lines = [line + b""\n"" for line in lines] <TAB>  <TAB> tstring_lines.append(lines) <TAB> for native, utf8 in zip(*tstring_lines): <TAB>  <TAB> u = self.decode(native)[0] <TAB>  <TAB> self.assertEqual(u, utf8.decode(""utf-8"")) <MASK> self.assertEqual(native, self.encode(u)[0])",if self . roundtriptest :,161
1450,"def set_default_variants(apps, schema_editor): <TAB> Product = apps.get_model(""product"", ""Product"") <TAB> for product in Product.objects.iterator(): <TAB>  <TAB> first_variant = product.variants.first() <MASK> product.default_variant = first_variant <TAB>  <TAB>  <TAB> product.save(update_fields=[""default_variant"", ""updated_at""])",if first_variant :,95
1451,"def json(self): <TAB> try: <TAB>  <TAB> if self.is_json(): <TAB>  <TAB>  <TAB> raw_data = self.raw_data() <MASK> raw_data = raw_data.decode(""utf-8"") <TAB>  <TAB>  <TAB> return json.loads(raw_data) <TAB> except ValueError: <TAB>  <TAB> pass","if not isinstance ( raw_data , text_type ) :",91
1452,"def clear_react(self, message: discord.Message, emoji: MutableMapping = None) -> None: <TAB> try: <TAB>  <TAB> await message.clear_reactions() <TAB> except discord.Forbidden: <MASK> return <TAB>  <TAB> with contextlib.suppress(discord.HTTPException): <TAB>  <TAB>  <TAB> async for key in AsyncIter(emoji.values(), delay=0.2): <TAB>  <TAB>  <TAB>  <TAB> await message.remove_reaction(key, self.bot.user) <TAB> except discord.HTTPException: <TAB>  <TAB> return",if not emoji :,134
1453,"def check(self, value): <TAB> value = String.check(self, value) <TAB> if isinstance(value, str): <TAB>  <TAB> value = value.upper() <TAB>  <TAB> for prefix in (self.prefix, self.prefix.split(""_"", 1)[1]): <TAB>  <TAB>  <TAB> # e.g. PANGO_WEIGHT_BOLD --> BOLD but also WEIGHT_BOLD --> BOLD <TAB>  <TAB>  <TAB> if value.startswith(prefix): <TAB>  <TAB>  <TAB>  <TAB> value = value[len(prefix) :] <TAB>  <TAB>  <TAB> value = value.lstrip(""_"") <MASK> return getattr(self.group, value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""No such constant: %s_%s"" % (self.prefix, value)) <TAB> else: <TAB>  <TAB> return value","if hasattr ( self . group , value ) :",182
1454,"def value(self): <TAB> quote = False <TAB> if self.defects: <TAB>  <TAB> quote = True <TAB> else: <TAB>  <TAB> for x in self: <TAB>  <TAB>  <TAB> if x.token_type == ""quoted-string"": <TAB>  <TAB>  <TAB>  <TAB> quote = True <TAB> if quote: <TAB>  <TAB> pre = post = """" <TAB>  <TAB> if self[0].token_type == ""cfws"" or self[0][0].token_type == ""cfws"": <TAB>  <TAB>  <TAB> pre = "" "" <MASK> post = "" "" <TAB>  <TAB> return pre + quote_string(self.display_name) + post <TAB> else: <TAB>  <TAB> return super(DisplayName, self).value","if self [ - 1 ] . token_type == ""cfws"" or self [ - 1 ] [ - 1 ] . token_type == ""cfws"" :",186
1455,"def get_drive(self, root_path="""", volume_guid_path=""""): <TAB> for drive in self.drives: <TAB>  <TAB> if root_path: <TAB>  <TAB>  <TAB> config_root_path = drive.get(""root_path"") <TAB>  <TAB>  <TAB> if config_root_path and root_path == config_root_path: <TAB>  <TAB>  <TAB>  <TAB> return drive <MASK> config_volume_guid_path = drive.get(""volume_guid_path"") <TAB>  <TAB>  <TAB> if config_volume_guid_path and config_volume_guid_path == volume_guid_path: <TAB>  <TAB>  <TAB>  <TAB> return drive",elif volume_guid_path :,148
1456,"def parse_edges(self, pcb): <TAB> edges = [] <TAB> drawings = list(pcb.GetDrawings()) <TAB> bbox = None <TAB> for m in pcb.GetModules(): <TAB>  <TAB> for g in m.GraphicalItems(): <TAB>  <TAB>  <TAB> drawings.append(g) <TAB> for d in drawings: <TAB>  <TAB> if d.GetLayer() == pcbnew.Edge_Cuts: <TAB>  <TAB>  <TAB> parsed_drawing = self.parse_drawing(d) <MASK> edges.append(parsed_drawing) <TAB>  <TAB>  <TAB>  <TAB> if bbox is None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> bbox = d.GetBoundingBox() <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> bbox.Merge(d.GetBoundingBox()) <TAB> if bbox: <TAB>  <TAB> bbox.Normalize() <TAB> return edges, bbox",if parsed_drawing :,197
1457,"def to_key(literal_or_identifier): <TAB> """"""returns string representation of this object"""""" <TAB> if literal_or_identifier[""type""] == ""Identifier"": <TAB>  <TAB> return literal_or_identifier[""name""] <TAB> elif literal_or_identifier[""type""] == ""Literal"": <TAB>  <TAB> k = literal_or_identifier[""value""] <TAB>  <TAB> if isinstance(k, float): <TAB>  <TAB>  <TAB> return unicode(float_repr(k)) <TAB>  <TAB> elif ""regex"" in literal_or_identifier: <TAB>  <TAB>  <TAB> return compose_regex(k) <TAB>  <TAB> elif isinstance(k, bool): <TAB>  <TAB>  <TAB> return ""true"" if k else ""false"" <MASK> return ""null"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return unicode(k)",elif k is None :,179
1458,"def find_multiple_stats(stats, name, _found=None, _on_found=None): <TAB> if _found is None: <TAB>  <TAB> _found = [] <TAB> for child_stats in stats: <TAB>  <TAB> if child_stats.name == name: <TAB>  <TAB>  <TAB> _found.append(child_stats) <MASK> _on_found(_found) <TAB>  <TAB> find_multiple_stats(child_stats, name, _found) <TAB> return _found",if callable ( _on_found ) :,119
1459,"def _run_generated_code( <TAB> self, <TAB> code, <TAB> globs, <TAB> locs, <TAB> fails_under_py3k=True,): <TAB> import warnings <TAB> from zope.interface._compat import PYTHON3 <TAB> with warnings.catch_warnings(record=True) as log: <TAB>  <TAB> warnings.resetwarnings() <MASK> exec(code, globs, locs) <TAB>  <TAB>  <TAB> self.assertEqual(len(log), 0)  # no longer warn <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> exec(code, globs, locs) <TAB>  <TAB>  <TAB> except TypeError: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> if fails_under_py3k: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.fail(""Didn't raise TypeError"")",if not PYTHON3 :,195
1460,"def _get_node(self, node_id): <TAB> self.non_terminated_nodes({})  # Side effect: updates cache <TAB> with self.lock: <MASK> return self.cached_nodes[node_id] <TAB>  <TAB> instance = ( <TAB>  <TAB>  <TAB> self.compute.instances() <TAB>  <TAB>  <TAB> .get( <TAB>  <TAB>  <TAB>  <TAB> project=self.provider_config[""project_id""], <TAB>  <TAB>  <TAB>  <TAB> zone=self.provider_config[""availability_zone""], <TAB>  <TAB>  <TAB>  <TAB> instance=node_id, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> .execute() <TAB>  <TAB> ) <TAB>  <TAB> return instance",if node_id in self . cached_nodes :,156
1461,"def skip_to_close_match(self): <TAB> nestedCount = 1 <TAB> while 1: <TAB>  <TAB> tok = self.tokenizer.get_next_token() <TAB>  <TAB> ttype = tok[""style""] <TAB>  <TAB> if ttype == SCE_PL_UNUSED: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> elif self.classifier.is_index_op(tok): <TAB>  <TAB>  <TAB> tval = tok[""text""] <MASK> if self.opHash[tval][1] == 1: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> nestedCount += 1 <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> nestedCount -= 1 <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if nestedCount <= 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break",if self . opHash . has_key ( tval ) :,176
1462,"def _create_or_get_helper(self, infer_mode: Optional[bool] = None, **kwargs) -> Helper: <TAB> # Prefer creating a new helper when at least one kwarg is specified. <TAB> prefer_new = len(kwargs) > 0 <TAB> kwargs.update(infer_mode=infer_mode) <TAB> is_training = not infer_mode if infer_mode is not None else self.training <TAB> helper = self._train_helper if is_training else self._infer_helper <TAB> if prefer_new or helper is None: <TAB>  <TAB> helper = self.create_helper(**kwargs) <TAB>  <TAB> if is_training and self._train_helper is None: <TAB>  <TAB>  <TAB> self._train_helper = helper <MASK> self._infer_helper = helper <TAB> return helper",elif not is_training and self . _infer_helper is None :,195
1463,"def get_ldset(self, ldsets): <TAB> ldset = None <TAB> if self._properties[""ldset_name""] == """": <TAB>  <TAB> nldset = len(ldsets) <TAB>  <TAB> if nldset == 0: <TAB>  <TAB>  <TAB> msg = _(""Logical Disk Set could not be found."") <TAB>  <TAB>  <TAB> raise exception.NotFound(msg) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ldset = None <TAB> else: <MASK> msg = ( <TAB>  <TAB>  <TAB>  <TAB> _(""Logical Disk Set `%s` could not be found."") <TAB>  <TAB>  <TAB>  <TAB> % self._properties[""ldset_name""] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> raise exception.NotFound(msg) <TAB>  <TAB> ldset = ldsets[self._properties[""ldset_name""]] <TAB> return ldset","if self . _properties [ ""ldset_name"" ] not in ldsets :",195
1464,"def calc_fractal_serial(q, maxiter): <TAB> # calculate z using pure python on a numpy array <TAB> # note that, unlike the other two implementations, <TAB> # the number of iterations per point is NOT constant <TAB> z = np.zeros(q.shape, complex) <TAB> output = np.resize( <TAB>  <TAB> np.array( <TAB>  <TAB>  <TAB> 0, <TAB>  <TAB> ), <TAB>  <TAB> q.shape, <TAB> ) <TAB> for i in range(len(q)): <TAB>  <TAB> for iter in range(maxiter): <TAB>  <TAB>  <TAB> z[i] = z[i] * z[i] + q[i] <MASK> output[i] = iter <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return output",if abs ( z [ i ] ) > 2.0 :,180
1465,"def _verifySubs(self): <TAB> for inst in self.subs: <TAB>  <TAB> if not isinstance(inst, (_Block, _Instantiator, Cosimulation)): <TAB>  <TAB>  <TAB> raise BlockError(_error.ArgType % (self.name,)) <MASK> if not inst.modctxt: <TAB>  <TAB>  <TAB>  <TAB> raise BlockError(_error.InstanceError % (self.name, inst.callername))","if isinstance ( inst , ( _Block , _Instantiator ) ) :",110
1466,"def walks_generator(): <TAB> if filelist is not None: <TAB>  <TAB> bucket = [] <TAB>  <TAB> for filename in filelist: <TAB>  <TAB>  <TAB> with io.open(filename) as inf: <TAB>  <TAB>  <TAB>  <TAB> for line in inf: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> walk = [int(x) for x in line.strip(""\n"").split("" "")] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> bucket.append(walk) <MASK> yield bucket <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> bucket = [] <TAB>  <TAB> if len(bucket): <TAB>  <TAB>  <TAB> yield bucket <TAB> else: <TAB>  <TAB> for _ in range(epoch): <TAB>  <TAB>  <TAB> for nodes in graph.node_batch_iter(batch_size): <TAB>  <TAB>  <TAB>  <TAB> walks = graph.random_walk(nodes, walk_len) <TAB>  <TAB>  <TAB>  <TAB> yield walks",if len ( bucket ) == batch_size :,198
1467,def _traverse(op): <TAB> if op in visited: <TAB>  <TAB> return <TAB> visited.add(op) <TAB> if tag.is_injective(op.tag): <TAB>  <TAB> if op not in s.outputs: <TAB>  <TAB>  <TAB> s[op].compute_inline() <TAB>  <TAB> for tensor in op.input_tensors: <MASK> _traverse(tensor.op) <TAB> callback(op),"if isinstance ( tensor . op , tvm . te . ComputeOp ) :",112
1468,"def unwatch_run(self, run_id, handler): <TAB> with self._dict_lock: <MASK> self._handlers_dict[run_id] = [ <TAB>  <TAB>  <TAB>  <TAB> (start_cursor, callback) <TAB>  <TAB>  <TAB>  <TAB> for (start_cursor, callback) in self._handlers_dict[run_id] <TAB>  <TAB>  <TAB>  <TAB> if callback != handler <TAB>  <TAB>  <TAB> ] <TAB>  <TAB> if not self._handlers_dict[run_id]: <TAB>  <TAB>  <TAB> del self._handlers_dict[run_id] <TAB>  <TAB>  <TAB> run_id_dict = self._run_id_dict <TAB>  <TAB>  <TAB> del run_id_dict[run_id] <TAB>  <TAB>  <TAB> self._run_id_dict = run_id_dict",if run_id in self . _run_id_dict :,185
1469,"def _PromptMySQL(self, config): <TAB> """"""Prompts the MySQL configuration, retrying if the configuration is invalid."""""" <TAB> while True: <TAB>  <TAB> self._PromptMySQLOnce(config) <MASK> print(""Successfully connected to MySQL with the given configuration."") <TAB>  <TAB>  <TAB> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""Error: Could not connect to MySQL with the given configuration."") <TAB>  <TAB>  <TAB> retry = RetryBoolQuestion(""Do you want to retry MySQL configuration?"", True) <TAB>  <TAB>  <TAB> if not retry: <TAB>  <TAB>  <TAB>  <TAB> raise ConfigInitError()",if self . _CheckMySQLConnection ( ) :,136
1470,"def get_courses_without_topic(topic): <TAB> data = [] <TAB> for entry in frappe.db.get_all(""Course""): <TAB>  <TAB> course = frappe.get_doc(""Course"", entry.name) <TAB>  <TAB> topics = [t.topic for t in course.topics] <MASK> data.append(course.name) <TAB> return data",if not topics or topic not in topics :,103
1471,"def _error_handler(action, **keywords): <TAB> if keywords: <TAB>  <TAB> file_type = keywords.get(""file_type"", None) <TAB>  <TAB> if file_type: <TAB>  <TAB>  <TAB> raise exceptions.FileTypeNotSupported( <TAB>  <TAB>  <TAB>  <TAB> constants.FILE_TYPE_NOT_SUPPORTED_FMT % (file_type, action) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <MASK> keywords.pop(""on_demand"") <TAB>  <TAB>  <TAB> msg = ""Please check if there were typos in "" <TAB>  <TAB>  <TAB> msg += ""function parameters: %s. Otherwise "" <TAB>  <TAB>  <TAB> msg += ""unrecognized parameters were given."" <TAB>  <TAB>  <TAB> raise exceptions.UnknownParameters(msg % keywords) <TAB> else: <TAB>  <TAB> raise exceptions.UnknownParameters(""No parameters found!"")","if ""on_demand"" in keywords :",186
1472,"def select(self, regions, register): <TAB> self.view.sel().clear() <TAB> to_store = [] <TAB> for r in regions: <TAB>  <TAB> self.view.sel().add(r) <MASK> to_store.append(self.view.substr(self.view.full_line(r))) <TAB> if register: <TAB>  <TAB> text = """".join(to_store) <TAB>  <TAB> if not text.endswith(""\n""): <TAB>  <TAB>  <TAB> text = text + ""\n"" <TAB>  <TAB> state = State(self.view) <TAB>  <TAB> state.registers[register] = [text]",if register :,142
1473,"def has_actor(self, message: HasActorMessage) -> ResultMessage: <TAB> actor_ref = message.actor_ref <TAB> # lookup allocated <TAB> for address, item in self._allocated_actors.items(): <TAB>  <TAB> ref = create_actor_ref(address, actor_ref.uid) <MASK> return ResultMessage(message.message_id, True, protocol=message.protocol) <TAB> return ResultMessage(message.message_id, False, protocol=message.protocol)",if ref in item :,113
1474,"def toggleMetaButton(self, event): <TAB> """"""Process clicks on toggle buttons"""""" <TAB> clickedBtn = event.EventObject <TAB> if wx.GetMouseState().GetModifiers() == wx.MOD_CONTROL: <TAB>  <TAB> activeBtns = [btn for btn in self.metaButtons if btn.GetValue()] <MASK> clickedBtn.setUserSelection(clickedBtn.GetValue()) <TAB>  <TAB>  <TAB> self.itemView.filterItemStore() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Do 'nothing' if we're trying to turn last active button off <TAB>  <TAB>  <TAB> # Keep button in the same state <TAB>  <TAB>  <TAB> clickedBtn.setUserSelection(True) <TAB> else: <TAB>  <TAB> for btn in self.metaButtons: <TAB>  <TAB>  <TAB> btn.setUserSelection(btn == clickedBtn) <TAB>  <TAB> self.itemView.filterItemStore()",if activeBtns :,198
1475,"def __init__(self, hub=None):  # pylint: disable=unused-argument <TAB> if resolver._resolver is None: <TAB>  <TAB> _resolver = resolver._resolver = _DualResolver() <TAB>  <TAB> if config.resolver_nameservers: <TAB>  <TAB>  <TAB> _resolver.network_resolver.nameservers[:] = config.resolver_nameservers <MASK> _resolver.network_resolver.lifetime = config.resolver_timeout <TAB> # Different hubs in different threads could be sharing the same <TAB> # resolver. <TAB> assert isinstance(resolver._resolver, _DualResolver) <TAB> self._resolver = resolver._resolver",if config . resolver_timeout :,147
1476,"def sub_paragraph(self, li): <TAB> """"""Search for checkbox in sub-paragraph."""""" <TAB> found = False <TAB> if len(li): <TAB>  <TAB> first = list(li)[0] <MASK> m = RE_CHECKBOX.match(first.text) <TAB>  <TAB>  <TAB> if m is not None: <TAB>  <TAB>  <TAB>  <TAB> first.text = self.markdown.htmlStash.store( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> get_checkbox(m.group(""state"")), safe=True <TAB>  <TAB>  <TAB>  <TAB> ) + m.group(""line"") <TAB>  <TAB>  <TAB>  <TAB> found = True <TAB> return found","if first . tag == ""p"" and first . text is not None :",152
1477,"def _check_mswin_locale(locale): <TAB> msloc = None <TAB> try: <TAB>  <TAB> msloc = _LOCALE_NAMES[locale[:5]][:2] <TAB>  <TAB> locale = locale[:5] <TAB> except KeyError: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> msloc = _LOCALE_NAMES[locale[:2]][:2] <TAB>  <TAB>  <TAB> locale = locale[:2] <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> # US English is the outlier, all other English locales want <TAB>  <TAB>  <TAB> # real English: <MASK> return (""en_GB"", ""1252"") <TAB>  <TAB>  <TAB> return (None, None) <TAB> return (locale, msloc)","if locale [ : 2 ] == ( ""en"" ) and locale [ : 5 ] != ""en_US"" :",176
1478,"def setLabel(self, s, protect=False): <TAB> """"""Set the label of the minibuffer."""""" <TAB> c, k, w = self.c, self, self.w <TAB> if w: <TAB>  <TAB> # Support for the curses gui. <MASK> g.app.gui.set_minibuffer_label(c, s) <TAB>  <TAB> w.setAllText(s) <TAB>  <TAB> n = len(s) <TAB>  <TAB> w.setSelectionRange(n, n, insert=n) <TAB>  <TAB> if protect: <TAB>  <TAB>  <TAB> k.mb_prefix = s","if hasattr ( g . app . gui , ""set_minibuffer_label"" ) :",151
1479,"def getProc(su, innerTarget): <TAB> if len(su) == 1:  # have a one element wedge <TAB>  <TAB> proc = (""first"", ""last"") <TAB> else: <TAB>  <TAB> if su.isFirst(innerTarget) and su.isLast(innerTarget): <TAB>  <TAB>  <TAB> proc = (""first"", ""last"")  # same element can be first and last <MASK> proc = (""first"",) <TAB>  <TAB> elif su.isLast(innerTarget): <TAB>  <TAB>  <TAB> proc = (""last"",) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> proc = () <TAB> return proc",elif su . isFirst ( innerTarget ) :,143
1480,"def await_test_end(self): <TAB> iterations = 0 <TAB> while True: <TAB>  <TAB> if iterations > 100: <TAB>  <TAB>  <TAB> self.log.debug(""Await: iteration limit reached"") <TAB>  <TAB>  <TAB> return <TAB>  <TAB> status = self.master.get_status() <MASK> return <TAB>  <TAB> iterations += 1 <TAB>  <TAB> time.sleep(1.0)","if status . get ( ""status"" ) == ""ENDED"" :",100
1481,"def _handle_autocomplete_request_for_text(text): <TAB> if not hasattr(text, ""autocompleter""): <TAB>  <TAB> if isinstance(text, (CodeViewText, ShellText)) and text.is_python_text(): <MASK> text.autocompleter = Completer(text) <TAB>  <TAB>  <TAB> elif isinstance(text, ShellText): <TAB>  <TAB>  <TAB>  <TAB> text.autocompleter = ShellCompleter(text) <TAB>  <TAB>  <TAB> text.bind(""<1>"", text.autocompleter.on_text_click) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return <TAB> text.autocompleter.handle_autocomplete_request()","if isinstance ( text , CodeViewText ) :",151
1482,"def validate_party_details(self): <TAB> if self.party: <MASK> frappe.throw(_(""Invalid {0}: {1}"").format(self.party_type, self.party)) <TAB>  <TAB> if self.party_account and self.party_type in (""Customer"", ""Supplier""): <TAB>  <TAB>  <TAB> self.validate_account_type( <TAB>  <TAB>  <TAB>  <TAB> self.party_account, [erpnext.get_party_account_type(self.party_type)] <TAB>  <TAB>  <TAB> )","if not frappe . db . exists ( self . party_type , self . party ) :",140
1483,"def format(self, formatstr): <TAB> pieces = [] <TAB> for i, piece in enumerate(re_formatchars.split(force_text(formatstr))): <MASK> pieces.append(force_text(getattr(self, piece)())) <TAB>  <TAB> elif piece: <TAB>  <TAB>  <TAB> pieces.append(re_escaped.sub(r""\1"", piece)) <TAB> return """".join(pieces)",if i % 2 :,99
1484,"def _convert_java_pattern_to_python(pattern): <TAB> """"""Convert a replacement pattern from the Java-style `$5` to the Python-style `\\5`."""""" <TAB> s = list(pattern) <TAB> i = 0 <TAB> while i < len(s) - 1: <TAB>  <TAB> c = s[i] <MASK> s[i] = ""\\"" <TAB>  <TAB> elif c == ""\\"" and s[i + 1] == ""$"": <TAB>  <TAB>  <TAB> s[i] = """" <TAB>  <TAB>  <TAB> i += 1 <TAB>  <TAB> i += 1 <TAB> return pattern[:0].join(s)","if c == ""$"" and s [ i + 1 ] in ""0123456789"" :",152
1485,"def download(self, url, filename, **kwargs): <TAB> try: <TAB>  <TAB> r = self.get(url, timeout=10, stream=True, **kwargs) <MASK> return False <TAB>  <TAB> with open(filename, ""wb"") as f: <TAB>  <TAB>  <TAB> for chunk in r.iter_content(chunk_size=1024): <TAB>  <TAB>  <TAB>  <TAB> if chunk: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f.write(chunk) <TAB>  <TAB> helpers.chmod_as_parent(filename) <TAB> except Exception as e: <TAB>  <TAB> sickrage.app.log.debug( <TAB>  <TAB>  <TAB> ""Failed to download file from {} - ERROR: {}"".format(url, e) <TAB>  <TAB> ) <TAB>  <TAB> if os.path.exists(filename): <TAB>  <TAB>  <TAB> os.remove(filename) <TAB>  <TAB> return False <TAB> return True",if r . status_code >= 400 :,200
1486,"def run(self, paths=[]): <TAB> items = [] <TAB> for item in SideBarSelection(paths).getSelectedFilesWithExtension(""js""): <TAB>  <TAB> items.append( <TAB>  <TAB>  <TAB> '<script type=""text/javascript"" src=""' <TAB>  <TAB>  <TAB> + item.pathAbsoluteFromProjectEncoded() <TAB>  <TAB>  <TAB> + '""></script>' <TAB>  <TAB> ) <TAB> if len(items) > 0: <TAB>  <TAB> sublime.set_clipboard(""\n"".join(items)) <MASK> sublime.status_message(""Items copied"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sublime.status_message(""Item copied"")",if len ( items ) > 1 :,153
1487,"def work(self): <TAB> while True: <TAB>  <TAB> timeout = self.timeout <TAB>  <TAB> if idle.is_set(): <TAB>  <TAB>  <TAB> timeout = self.idle_timeout <TAB>  <TAB> log.debug(""Wait for {}"".format(timeout)) <TAB>  <TAB> fetch.wait(timeout) <MASK> log.info(""Stop fetch worker"") <TAB>  <TAB>  <TAB> break <TAB>  <TAB> self.fetch()",if shutting_down . is_set ( ) :,99
1488,"def check_apns_certificate(ss): <TAB> mode = ""start"" <TAB> for s in ss.split(""\n""): <TAB>  <TAB> if mode == ""start"": <MASK> mode = ""key"" <TAB>  <TAB> elif mode == ""key"": <TAB>  <TAB>  <TAB> if ""END RSA PRIVATE KEY"" in s or ""END PRIVATE KEY"" in s: <TAB>  <TAB>  <TAB>  <TAB> mode = ""end"" <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> elif s.startswith(""Proc-Type"") and ""ENCRYPTED"" in s: <TAB>  <TAB>  <TAB>  <TAB> raise ImproperlyConfigured( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Encrypted APNS private keys are not supported"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> if mode != ""end"": <TAB>  <TAB> raise ImproperlyConfigured(""The APNS certificate doesn't contain a private key"")","if ""BEGIN RSA PRIVATE KEY"" in s or ""BEGIN PRIVATE KEY"" in s :",195
1489,"def compare_lists(self, l1, l2, key): <TAB> l2_lookup = {o.get(key): o for o in l2} <TAB> for obj1 in l1: <TAB>  <TAB> obj2 = l2_lookup.get(obj1.get(key)) <TAB>  <TAB> for k in obj1: <MASK> self.assertEqual(obj1.get(k), obj2.get(k))","if k not in ""id"" and obj1 . get ( k ) :",117
1490,"def before_get_object(self, view_kwargs): <TAB> if view_kwargs.get(""id"") is not None: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> user_favourite_event = find_user_favourite_event_by_id( <TAB>  <TAB>  <TAB>  <TAB> event_id=view_kwargs[""id""] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> except NoResultFound: <TAB>  <TAB>  <TAB> raise ObjectNotFound( <TAB>  <TAB>  <TAB>  <TAB> {""source"": ""/data/relationships/event""}, ""Object: not found"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <MASK> view_kwargs[""id""] = user_favourite_event.id <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> view_kwargs[""id""] = None",if user_favourite_event is not None :,182
1491,"def close(self): <TAB> super().close() <TAB> if not sys.is_finalizing(): <TAB>  <TAB> for sig in list(self._signal_handlers): <TAB>  <TAB>  <TAB> self.remove_signal_handler(sig) <TAB> else: <MASK> warnings.warn( <TAB>  <TAB>  <TAB>  <TAB> f""Closing the loop {self!r} "" <TAB>  <TAB>  <TAB>  <TAB> f""on interpreter shutdown "" <TAB>  <TAB>  <TAB>  <TAB> f""stage, skipping signal handlers removal"", <TAB>  <TAB>  <TAB>  <TAB> ResourceWarning, <TAB>  <TAB>  <TAB>  <TAB> source=self, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self._signal_handlers.clear()",if self . _signal_handlers :,148
1492,"def install_script(self, script, install_options=None): <TAB> try: <TAB>  <TAB> fname = utils.do_script( <TAB>  <TAB>  <TAB> script, <TAB>  <TAB>  <TAB> python_exe=osp.join(self.target, ""python.exe""), <TAB>  <TAB>  <TAB> architecture=self.architecture, <TAB>  <TAB>  <TAB> verbose=self.verbose, <TAB>  <TAB>  <TAB> install_options=install_options, <TAB>  <TAB> ) <TAB> except RuntimeError: <MASK> print(""Failed!"") <TAB>  <TAB>  <TAB> raise",if not self . verbose :,123
1493,"def GetRouterForUser(self, username): <TAB> """"""Returns a router corresponding to a given username."""""" <TAB> for index, router in enumerate(self.routers): <TAB>  <TAB> router_id = str(index) <MASK> logging.debug( <TAB>  <TAB>  <TAB>  <TAB> ""Matched router %s to user %s"", router.__class__.__name__, username <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return router <TAB> logging.debug( <TAB>  <TAB> ""No router ACL rule match for user %s. Using default "" ""router %s"", <TAB>  <TAB> username, <TAB>  <TAB> self.default_router.__class__.__name__, <TAB> ) <TAB> return self.default_router","if self . auth_manager . CheckPermissions ( username , router_id ) :",168
1494,"def charset(self): <TAB> """"""The charset from the content type."""""" <TAB> header = self.environ.get(""CONTENT_TYPE"") <TAB> if header: <TAB>  <TAB> ct, options = parse_options_header(header) <TAB>  <TAB> charset = options.get(""charset"") <MASK> if is_known_charset(charset): <TAB>  <TAB>  <TAB>  <TAB> return charset <TAB>  <TAB>  <TAB> return self.unknown_charset(charset) <TAB> return self.default_charset",if charset :,108
1495,def isFinished(self): <TAB> # returns true if episode timesteps has reached episode length and resets the task <TAB> if self.count > self.epiLen: <TAB>  <TAB> self.res() <TAB>  <TAB> return True <TAB> else: <TAB>  <TAB> if self.count == 1: <TAB>  <TAB>  <TAB> self.pertGlasPos(0) <MASK> self.env.reset() <TAB>  <TAB>  <TAB> self.pertGlasPos(1) <TAB>  <TAB> self.count += 1 <TAB>  <TAB> return False,if self . count == self . epiLen / 2 + 1 :,132
1496,"def mtimes_of_files(dirnames: List[str], suffix: str) -> Iterator[float]: <TAB> for dirname in dirnames: <TAB>  <TAB> for root, dirs, files in os.walk(dirname): <TAB>  <TAB>  <TAB> for sfile in files: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield path.getmtime(path.join(root, sfile)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass",if sfile . endswith ( suffix ) :,113
1497,"def get_all_hashes(self): <TAB> event_hashes = [] <TAB> sample_hashes = [] <TAB> for a in self.event.attributes: <TAB>  <TAB> h = None <TAB>  <TAB> if a.type in (""md5"", ""sha1"", ""sha256""): <TAB>  <TAB>  <TAB> h = a.value <TAB>  <TAB>  <TAB> event_hashes.append(h) <TAB>  <TAB> elif a.type in (""filename|md5"", ""filename|sha1"", ""filename|sha256""): <TAB>  <TAB>  <TAB> h = a.value.split(""|"")[1] <TAB>  <TAB>  <TAB> event_hashes.append(h) <MASK> h = a.value.split(""|"")[1] <TAB>  <TAB>  <TAB> sample_hashes.append(h) <TAB> return event_hashes, sample_hashes","elif a . type == ""malware-sample"" :",184
1498,"def _validate(self, event): <TAB> if self.type is None: <TAB>  <TAB> return <TAB> new = self.value <TAB> if not isinstance(new, self.type) and new is not None: <MASK> self.value = event.old <TAB>  <TAB> types = repr(self.type) if isinstance(self.type, tuple) else self.type.__name__ <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> ""LiteralInput expected %s type but value %s "" <TAB>  <TAB>  <TAB> ""is of type %s."" % (types, new, type(new).__name__) <TAB>  <TAB> )",if event :,140
1499,"def update_dict(a, b): <TAB> for key, value in b.items(): <MASK> continue <TAB>  <TAB> if key not in a: <TAB>  <TAB>  <TAB> a[key] = value <TAB>  <TAB> elif isinstance(a[key], dict) and isinstance(value, dict): <TAB>  <TAB>  <TAB> update_dict(a[key], value) <TAB>  <TAB> elif isinstance(a[key], list): <TAB>  <TAB>  <TAB> a[key].append(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> a[key] = [a[key], value]",if value is None :,131
1500,"def on_pre_save(self, view): <TAB> extOrClause = ""|"".join(s.get(""format_on_save_extensions"")) <TAB> extRegex = ""\\.("" + extOrClause + "")$"" <TAB> if s.get(""format_on_save"") and re.search(extRegex, view.file_name()): <TAB>  <TAB> # only auto-format on save if there are no ""lint errors"" <TAB>  <TAB> # here are some named regions from sublimelint see https://github.com/lunixbochs/sublimelint/tree/st3 <TAB>  <TAB> lints_regions = [""lint-keyword-underline"", ""lint-keyword-outline""] <TAB>  <TAB> for linter in lints_regions: <MASK> return <TAB>  <TAB> view.run_command(""js_format"")",if len ( view . get_regions ( linter ) ) :,198
1501,"def readMemory(self, va, size): <TAB> for mva, mmaxva, mmap, mbytes in self._map_defs: <TAB>  <TAB> if mva <= va < mmaxva: <TAB>  <TAB>  <TAB> mva, msize, mperms, mfname = mmap <MASK> raise envi.SegmentationViolation(va) <TAB>  <TAB>  <TAB> offset = va - mva <TAB>  <TAB>  <TAB> return mbytes[offset : offset + size] <TAB> raise envi.SegmentationViolation(va)",if not mperms & MM_READ :,127
1502,"def assertFilepathsEqual(self, p1, p2): <TAB> if sys.platform == ""win32"": <MASK> p1 = [normcase(normpath(x)) for x in p1] <TAB>  <TAB>  <TAB> p2 = [normcase(normpath(x)) for x in p2] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert isinstance(p1, (str, unicode)) <TAB>  <TAB>  <TAB> p1 = normcase(normpath(p1)) <TAB>  <TAB>  <TAB> p2 = normcase(normpath(p2)) <TAB> self.assertEqual(p1, p2)","if isinstance ( p1 , ( list , tuple ) ) :",140
1503,"def add_directory_csv_files(dir_path, paths=None): <TAB> if not paths: <TAB>  <TAB> paths = [] <TAB> for p in listdir(dir_path): <TAB>  <TAB> path = join(dir_path, p) <TAB>  <TAB> if isdir(path): <TAB>  <TAB>  <TAB> # call recursively for each dir <TAB>  <TAB>  <TAB> paths = add_directory_csv_files(path, paths) <MASK> # add every file to the list <TAB>  <TAB>  <TAB> paths.append(path) <TAB> return paths","elif isfile ( path ) and path . endswith ( "".csv"" ) :",130
1504,"def _verifySubs(self): <TAB> for inst in self.subs: <MASK> raise BlockError(_error.ArgType % (self.name,)) <TAB>  <TAB> if isinstance(inst, (_Block, _Instantiator)): <TAB>  <TAB>  <TAB> if not inst.modctxt: <TAB>  <TAB>  <TAB>  <TAB> raise BlockError(_error.InstanceError % (self.name, inst.callername))","if not isinstance ( inst , ( _Block , _Instantiator , Cosimulation ) ) :",110
1505,"def __annotations_bytes(self): <TAB> if self.annotations: <TAB>  <TAB> a = [] <TAB>  <TAB> for k, v in self.annotations.items(): <TAB>  <TAB>  <TAB> if len(k) != 4: <TAB>  <TAB>  <TAB>  <TAB> raise errors.ProtocolError(""annotation key must be of length 4"") <MASK> k = k.encode(""ASCII"") <TAB>  <TAB>  <TAB> a.append(struct.pack(""!4sH"", k, len(v))) <TAB>  <TAB>  <TAB> a.append(v) <TAB>  <TAB> return b"""".join(a) <TAB> return b""""","if sys . version_info >= ( 3 , 0 ) :",143
1506,"def session(self, profile: str = ""default"", region: str = None) -> boto3.Session: <TAB> region = self._get_region(region, profile) <TAB> try: <TAB>  <TAB> session = self._cache_lookup( <TAB>  <TAB>  <TAB> self._session_cache, <TAB>  <TAB>  <TAB> [profile, region], <TAB>  <TAB>  <TAB> self._boto3.Session, <TAB>  <TAB>  <TAB> [], <TAB>  <TAB>  <TAB> {""region_name"": region, ""profile_name"": profile}, <TAB>  <TAB> ) <TAB> except ProfileNotFound: <MASK> raise <TAB>  <TAB> session = self._boto3.Session(region_name=region) <TAB>  <TAB> self._cache_set(self._session_cache, [profile, region], session) <TAB> return session","if profile != ""default"" :",174
1507,"def spans_score(gold_spans, system_spans): <TAB> correct, gi, si = 0, 0, 0 <TAB> while gi < len(gold_spans) and si < len(system_spans): <TAB>  <TAB> if system_spans[si].start < gold_spans[gi].start: <TAB>  <TAB>  <TAB> si += 1 <MASK> gi += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> correct += gold_spans[gi].end == system_spans[si].end <TAB>  <TAB>  <TAB> si += 1 <TAB>  <TAB>  <TAB> gi += 1 <TAB> return Score(len(gold_spans), len(system_spans), correct)",elif gold_spans [ gi ] . start < system_spans [ si ] . start :,160
1508,"def to_api(tag, raw_value): <TAB> try: <TAB>  <TAB> api_tag, converter = _QL_TO_SC[tag] if tag else (""q"", None) <TAB> except KeyError: <MASK> raise self.error( <TAB>  <TAB>  <TAB>  <TAB> ""Unsupported '%s' tag. Try: %s"" % (tag, "", "".join(SUPPORTED)) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return None, None <TAB> else: <TAB>  <TAB> value = str(converter(raw_value) if converter else raw_value) <TAB>  <TAB> return api_tag, value",if tag not in SUPPORTED :,137
1509,"def unpack(self, buf): <TAB> dpkt.Packet.unpack(self, buf) <TAB> buf = buf[self.__hdr_len__ :] <TAB> # single-byte IE <TAB> if self.type & 0x80: <TAB>  <TAB> self.len = 0 <TAB>  <TAB> self.data = b"""" <TAB> # multi-byte IE <TAB> else: <TAB>  <TAB> # special PER-encoded UUIE <MASK> self.len = struct.unpack("">H"", buf[:2])[0] <TAB>  <TAB>  <TAB> buf = buf[2:] <TAB>  <TAB> # normal TLV-like IE <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.len = struct.unpack(""B"", buf[:1])[0] <TAB>  <TAB>  <TAB> buf = buf[1:] <TAB>  <TAB> self.data = buf[: self.len]",if self . type == USER_TO_USER :,195
1510,"def on_bt_search_clicked(self, widget): <TAB> if self.current_provider is None: <TAB>  <TAB> return <TAB> query = self.en_query.get_text() <TAB> @self.obtain_podcasts_with <TAB> def load_data(): <MASK> return self.current_provider.on_search(query) <TAB>  <TAB> elif self.current_provider.kind == directory.Provider.PROVIDER_URL: <TAB>  <TAB>  <TAB> return self.current_provider.on_url(query) <TAB>  <TAB> elif self.current_provider.kind == directory.Provider.PROVIDER_FILE: <TAB>  <TAB>  <TAB> return self.current_provider.on_file(query)",if self . current_provider . kind == directory . Provider . PROVIDER_SEARCH :,172
1511,"def _text(bitlist): <TAB> out = """" <TAB> for typ, text in bitlist: <TAB>  <TAB> if not typ: <TAB>  <TAB>  <TAB> out += text <MASK> out += ""\\fI%s\\fR"" % text <TAB>  <TAB> elif typ in [""strong"", ""code""]: <TAB>  <TAB>  <TAB> out += ""\\fB%s\\fR"" % text <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""unexpected tag %r inside text"" % (typ,)) <TAB> out = out.strip() <TAB> out = re.sub(re.compile(r""^\s+"", re.M), """", out) <TAB> return out","elif typ == ""em"" :",150
1512,"def process(self, buckets): <TAB> with self.executor_factory(max_workers=3) as w: <TAB>  <TAB> futures = {} <TAB>  <TAB> results = [] <TAB>  <TAB> for b in buckets: <TAB>  <TAB>  <TAB> futures[w.submit(self.process_bucket, b)] = b <TAB>  <TAB> for f in as_completed(futures): <MASK> b = futures[f] <TAB>  <TAB>  <TAB>  <TAB> self.log.error( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""error modifying bucket:%s\n%s"", b[""Name""], f.exception() <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> results += filter(None, [f.result()]) <TAB>  <TAB> return results",if f . exception ( ) :,160
1513,"def check_settings(self): <TAB> if self.settings_dict[""TIME_ZONE""] is not None: <MASK> raise ImproperlyConfigured( <TAB>  <TAB>  <TAB>  <TAB> ""Connection '%s' cannot set TIME_ZONE because USE_TZ is "" <TAB>  <TAB>  <TAB>  <TAB> ""False."" % self.alias <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> elif self.features.supports_timezones: <TAB>  <TAB>  <TAB> raise ImproperlyConfigured( <TAB>  <TAB>  <TAB>  <TAB> ""Connection '%s' cannot set TIME_ZONE because its engine "" <TAB>  <TAB>  <TAB>  <TAB> ""handles time zones conversions natively."" % self.alias <TAB>  <TAB>  <TAB> )",if not settings . USE_TZ :,140
1514,"def process_webhook_prop(namespace): <TAB> if not isinstance(namespace.webhook_properties, list): <TAB>  <TAB> return <TAB> result = {} <TAB> for each in namespace.webhook_properties: <TAB>  <TAB> if each: <MASK> key, value = each.split(""="", 1) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> key, value = each, """" <TAB>  <TAB>  <TAB> result[key] = value <TAB> namespace.webhook_properties = result","if ""="" in each :",111
1515,"def _expand_query_values(original_query_list): <TAB> query_list = [] <TAB> for key, value in original_query_list: <MASK> query_list.append((key, value)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> key_fmt = key + ""[%s]"" <TAB>  <TAB>  <TAB> value_list = _to_kv_list(value) <TAB>  <TAB>  <TAB> query_list.extend((key_fmt % k, v) for k, v in value_list) <TAB> return query_list","if isinstance ( value , basestring ) :",127
1516,"def tags(): <TAB> """"""Return a dictionary of all tags in the form {hash: [tag_names, ...]}."""""" <TAB> tags = {} <TAB> for (n, c) in list_refs(): <TAB>  <TAB> if n.startswith(""refs/tags/""): <TAB>  <TAB>  <TAB> name = n[10:] <MASK> tags[c] = [] <TAB>  <TAB>  <TAB> tags[c].append(name)  # more than one tag can point at 'c' <TAB> return tags",if not c in tags :,116
1517,"def test_colorspiral(self): <TAB> """"""Set of 625 colours, with jitter, using get_colors()."""""" <TAB> boxedge = 20 <TAB> boxes_per_row = 25 <TAB> rows = 0 <TAB> for i, c in enumerate(get_colors(625)): <TAB>  <TAB> self.c.setFillColor(c) <TAB>  <TAB> x1 = boxedge * (i % boxes_per_row) <TAB>  <TAB> y1 = rows * boxedge <TAB>  <TAB> self.c.rect(x1, y1, boxedge, boxedge, fill=1, stroke=0) <MASK> rows += 1 <TAB> self.finish()",if not ( i + 1 ) % boxes_per_row :,164
1518,"def oldest_pending_update_in_days(): <TAB> """"""Return the datestamp of the oldest pending update"""""" <TAB> pendingupdatespath = os.path.join( <TAB>  <TAB> prefs.pref(""ManagedInstallDir""), ""UpdateNotificationTracking.plist"" <TAB> ) <TAB> try: <TAB>  <TAB> pending_updates = FoundationPlist.readPlist(pendingupdatespath) <TAB> except FoundationPlist.NSPropertyListSerializationException: <TAB>  <TAB> return 0 <TAB> oldest_date = now = NSDate.date() <TAB> for category in pending_updates: <TAB>  <TAB> for name in pending_updates[category]: <TAB>  <TAB>  <TAB> this_date = pending_updates[category][name] <MASK> oldest_date = this_date <TAB> return now.timeIntervalSinceDate_(oldest_date) / (24 * 60 * 60)",if this_date < oldest_date :,199
1519,"def _try_read_gpg(path): <TAB> path = os.path.expanduser(path) <TAB> cmd = _gpg_cmd() + [path] <TAB> log.debug(""gpg cmd: %s"", cmd) <TAB> try: <TAB>  <TAB> p = subprocess.Popen( <TAB>  <TAB>  <TAB> cmd, env=os.environ, stdout=subprocess.PIPE, stderr=subprocess.PIPE <TAB>  <TAB> ) <TAB> except OSError as e: <TAB>  <TAB> log.error(""cannot decode %s with command '%s' (%s)"", path, "" "".join(cmd), e) <TAB> else: <TAB>  <TAB> out, err = p.communicate() <MASK> log.error(err.decode(errors=""replace"").strip()) <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> return out.decode(errors=""replace"")",if p . returncode != 0 :,190
1520,"def sort_nested_dictionary_lists(d): <TAB> for k, v in d.items(): <MASK> for i in range(0, len(v)): <TAB>  <TAB>  <TAB>  <TAB> if isinstance(v[i], dict): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> v[i] = await sort_nested_dictionary_lists(v[i]) <TAB>  <TAB>  <TAB>  <TAB> d[k] = sorted(v) <TAB>  <TAB> if isinstance(v, dict): <TAB>  <TAB>  <TAB> d[k] = await sort_nested_dictionary_lists(v) <TAB> return d","if isinstance ( v , list ) :",134
1521,"def _the_callback(widget, event_id): <TAB> point = widget.GetCenter() <TAB> index = widget.WIDGET_INDEX <TAB> if hasattr(callback, ""__call__""): <MASK> args = [point, index] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> args = [point] <TAB>  <TAB> if pass_widget: <TAB>  <TAB>  <TAB> args.append(widget) <TAB>  <TAB> try_callback(callback, *args) <TAB> return",if num > 1 :,109
1522,"def _add_cs(master_cs, sub_cs, prefix, delimiter=""."", parent_hp=None): <TAB> new_parameters = [] <TAB> for hp in sub_cs.get_hyperparameters(): <TAB>  <TAB> new_parameter = copy.deepcopy(hp) <TAB>  <TAB> # Allow for an empty top-level parameter <MASK> new_parameter.name = prefix <TAB>  <TAB> elif not prefix == """": <TAB>  <TAB>  <TAB> new_parameter.name = ""{}{}{}"".format(prefix, SPLITTER, new_parameter.name) <TAB>  <TAB> new_parameters.append(new_parameter) <TAB> for hp in new_parameters: <TAB>  <TAB> _add_hp(master_cs, hp)","if new_parameter . name == """" :",162
1523,"def tearDown(self): <TAB> """"""Shutdown the server."""""" <TAB> try: <MASK> self.server.stop() <TAB>  <TAB> if self.sl_hdlr: <TAB>  <TAB>  <TAB> self.root_logger.removeHandler(self.sl_hdlr) <TAB>  <TAB>  <TAB> self.sl_hdlr.close() <TAB> finally: <TAB>  <TAB> BaseTest.tearDown(self)",if self . server :,92
1524,"def app_uninstall_all(self, excludes=[], verbose=False): <TAB> """"""Uninstall all apps"""""" <TAB> our_apps = [""com.github.uiautomator"", ""com.github.uiautomator.test""] <TAB> output, _ = self.shell([""pm"", ""list"", ""packages"", ""-3""]) <TAB> pkgs = re.findall(r""package:([^\s]+)"", output) <TAB> pkgs = set(pkgs).difference(our_apps + excludes) <TAB> pkgs = list(pkgs) <TAB> for pkg_name in pkgs: <MASK> print(""uninstalling"", pkg_name, "" "", end="""", flush=True) <TAB>  <TAB> ok = self.app_uninstall(pkg_name) <TAB>  <TAB> if verbose: <TAB>  <TAB>  <TAB> print(""OK"" if ok else ""FAIL"") <TAB> return pkgs",if verbose :,188
1525,"def httpapi(self, arg, opts): <TAB> sc = HttpAPIStatsCollector() <TAB> headers = [""#Item"", ""Value""] <TAB> table = [] <TAB> for k, v in sc.get().getStats().items(): <TAB>  <TAB> if isinstance(v, dict): <TAB>  <TAB>  <TAB> v = json.dumps(v) <TAB>  <TAB> row = [] <TAB>  <TAB> row.append(""#%s"" % k) <MASK> row.append(formatDateTime(v)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> row.append(v) <TAB>  <TAB> table.append(row) <TAB> self.protocol.sendData( <TAB>  <TAB> tabulate(table, headers, tablefmt=""plain"", numalign=""left"").encode(""ascii"") <TAB> )","if k [ - 3 : ] == ""_at"" :",178
1526,"def Get_Gene(self, id): <TAB> """"""Retreive the gene name (GN)."""""" <TAB> entry = self.Get(id) <TAB> if not entry: <TAB>  <TAB> return None <TAB> GN = """" <TAB> for line in string.split(entry, ""\n""): <MASK> GN = string.strip(line[5:]) <TAB>  <TAB>  <TAB> if GN[-1] == ""."": <TAB>  <TAB>  <TAB>  <TAB> GN = GN[0:-1] <TAB>  <TAB>  <TAB> return GN <TAB>  <TAB> if line[0:2] == ""//"": <TAB>  <TAB>  <TAB> break <TAB> return GN","if line [ 0 : 5 ] == ""GN   "" :",150
1527,"def replace_dir_vars(path, d): <TAB> """"""Replace common directory paths with appropriate variable references (e.g. /etc becomes ${sysconfdir})"""""" <TAB> dirvars = {} <TAB> # Sort by length so we get the variables we're interested in first <TAB> for var in sorted(list(d.keys()), key=len): <TAB>  <TAB> if var.endswith(""dir"") and var.lower() == var: <TAB>  <TAB>  <TAB> value = d.getVar(var) <MASK> dirvars[value] = var <TAB> for dirpath in sorted(list(dirvars.keys()), reverse=True): <TAB>  <TAB> path = path.replace(dirpath, ""${%s}"" % dirvars[dirpath]) <TAB> return path","if value . startswith ( ""/"" ) and not ""\n"" in value and value not in dirvars :",184
1528,"def _scrub_generated_timestamps(self, target_workdir): <TAB> """"""Remove the first line of comment from each file if it contains a timestamp."""""" <TAB> for root, _, filenames in safe_walk(target_workdir): <TAB>  <TAB> for filename in filenames: <TAB>  <TAB>  <TAB> source = os.path.join(root, filename) <TAB>  <TAB>  <TAB> with open(source, ""r"") as f: <TAB>  <TAB>  <TAB>  <TAB> lines = f.readlines() <TAB>  <TAB>  <TAB> if len(lines) < 1: <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> with open(source, ""w"") as f: <MASK> f.write(lines[0]) <TAB>  <TAB>  <TAB>  <TAB> for line in lines[1:]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f.write(line)",if not self . _COMMENT_WITH_TIMESTAMP_RE . match ( lines [ 0 ] ) :,196
1529,"def get_all_active_plugins(self) -> List[BotPlugin]: <TAB> """"""This returns the list of plugins in the callback ordered defined from the config."""""" <TAB> all_plugins = [] <TAB> for name in self.plugins_callback_order: <TAB>  <TAB> # None is a placeholder for any plugin not having a defined order <MASK> all_plugins += [ <TAB>  <TAB>  <TAB>  <TAB> plugin <TAB>  <TAB>  <TAB>  <TAB> for name, plugin in self.plugins.items() <TAB>  <TAB>  <TAB>  <TAB> if name not in self.plugins_callback_order and plugin.is_activated <TAB>  <TAB>  <TAB> ] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> plugin = self.plugins[name] <TAB>  <TAB>  <TAB> if plugin.is_activated: <TAB>  <TAB>  <TAB>  <TAB> all_plugins.append(plugin) <TAB> return all_plugins",if name is None :,186
1530,"def test_query_level(self): <TAB> ""Tests querying at a level other than max"" <TAB> # level 2 <TAB> l2 = set() <TAB> for p in self.tile_paths: <TAB>  <TAB> l2.add(p[0:2]) <TAB> for path in iterate_base4(2): <MASK> self.assertTrue(self.tree.query_path(path)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertFalse(self.tree.query_path(path)) <TAB> # level 1: <TAB> self.assertTrue(self.tree.query_path((0,))) <TAB> self.assertTrue(self.tree.query_path((1,))) <TAB> self.assertTrue(self.tree.query_path((2,))) <TAB> self.assertFalse(self.tree.query_path((3,)))",if path in l2 :,191
1531,"def program_exists(name): <TAB> paths = (os.getenv(""PATH"") or os.defpath).split(os.pathsep) <TAB> for p in paths: <TAB>  <TAB> fn = ""%s/%s"" % (p, name) <MASK> return not os.path.isdir(fn) and os.access(fn, os.X_OK)",if os . path . exists ( fn ) :,93
1532,"def decoration_helper(self, patched, args, keywargs): <TAB> extra_args = [] <TAB> with contextlib.ExitStack() as exit_stack: <TAB>  <TAB> for patching in patched.patchings: <TAB>  <TAB>  <TAB> arg = exit_stack.enter_context(patching) <MASK> keywargs.update(arg) <TAB>  <TAB>  <TAB> elif patching.new is DEFAULT: <TAB>  <TAB>  <TAB>  <TAB> extra_args.append(arg) <TAB>  <TAB> args += tuple(extra_args) <TAB>  <TAB> yield (args, keywargs)",if patching . attribute_name is not None :,134
1533,"def update_neighbor(neigh_ip_address, changes): <TAB> rets = [] <TAB> for k, v in changes.items(): <TAB>  <TAB> if k == neighbors.MULTI_EXIT_DISC: <TAB>  <TAB>  <TAB> rets.append(_update_med(neigh_ip_address, v)) <MASK> rets.append(update_neighbor_enabled(neigh_ip_address, v)) <TAB>  <TAB> if k == neighbors.CONNECT_MODE: <TAB>  <TAB>  <TAB> rets.append(_update_connect_mode(neigh_ip_address, v)) <TAB> return all(rets)",if k == neighbors . ENABLED :,138
1534,"def calcUniqueStates(self): <TAB> # Here we show which colors can be relied on to map to an <TAB> # internal state.  The current position will be at the first <TAB> # character in the buffer styled that color, so this might not <TAB> # work in all cases. <TAB> self.uniqueStates = {} <TAB> for k in self.holdUniqueStates.keys(): <TAB>  <TAB> v = self.holdUniqueStates[k] <MASK> self.uniqueStates[k] = v.keys()[0] <TAB>  <TAB>  <TAB> log.debug(""Map style [%s] to state [%s]"", k, v.keys()[0]) <TAB>  <TAB> log.debug(""Style [%s] maps to states [%s]"", k, "", "".join(v.keys())) <TAB> self.holdUniqueStates = None",if len ( v . keys ( ) ) == 1 :,191
1535,"def init_logger(): <TAB> configured_loggers = [log_config.get(""root"", {})] + [ <TAB>  <TAB> logger for logger in log_config.get(""loggers"", {}).values() <TAB> ] <TAB> used_handlers = { <TAB>  <TAB> handler for log in configured_loggers for handler in log.get(""handlers"", []) <TAB> } <TAB> for handler_id, handler in list(log_config[""handlers""].items()): <MASK> del log_config[""handlers""][handler_id] <TAB>  <TAB> elif ""filename"" in handler.keys(): <TAB>  <TAB>  <TAB> filename = handler[""filename""] <TAB>  <TAB>  <TAB> logfile_path = Path(filename).expanduser().resolve() <TAB>  <TAB>  <TAB> handler[""filename""] = str(logfile_path) <TAB> logging.config.dictConfig(log_config)",if handler_id not in used_handlers :,192
1536,"def _selected_machines(self, virtual_machines): <TAB> selected_machines = [] <TAB> for machine in virtual_machines: <MASK> selected_machines.append(machine) <TAB>  <TAB> if self.tags and self._tags_match(machine.tags, self.tags): <TAB>  <TAB>  <TAB> selected_machines.append(machine) <TAB>  <TAB> if self.locations and machine.location in self.locations: <TAB>  <TAB>  <TAB> selected_machines.append(machine) <TAB> return selected_machines",if self . _args . host and self . _args . host == machine . name :,129
1537,"def init(self): <TAB> r = self.get_redis() <TAB> if r: <TAB>  <TAB> key = ""pocsuite_target"" <TAB>  <TAB> info_msg = ""[PLUGIN] try fetch targets from redis..."" <TAB>  <TAB> logger.info(info_msg) <TAB>  <TAB> targets = r.get(key) <TAB>  <TAB> count = 0 <TAB>  <TAB> if targets: <TAB>  <TAB>  <TAB> for target in targets: <MASK> count += 1 <TAB>  <TAB> info_msg = ""[PLUGIN] get {0} target(s) from redis"".format(count) <TAB>  <TAB> logger.info(info_msg)",if self . add_target ( target ) :,151
1538,"def tearDown(self): <TAB> suffix = str(os.getgid()) <TAB> cli = monitoring_v3.MetricServiceClient() <TAB> for md in cli.list_metric_descriptors(""projects/{}"".format(PROJECT)): <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> cli.delete_metric_descriptor(md.name) <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> pass","if ""OpenCensus"" in md . name and suffix in md . name :",106
1539,"def InitializeColours(self): <TAB> """"""Initializes the 16 custom colours in :class:`CustomPanel`."""""" <TAB> curr = self._colourData.GetColour() <TAB> self._colourSelection = -1 <TAB> for i in range(16): <TAB>  <TAB> c = self._colourData.GetCustomColour(i) <TAB>  <TAB> if c.IsOk(): <TAB>  <TAB>  <TAB> self._customColours[i] = self._colourData.GetCustomColour(i) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._customColours[i] = wx.WHITE <MASK> self._colourSelection = i",if c == curr :,147
1540,"def __getitem__(self, index): <TAB> if self._check(): <TAB>  <TAB> if isinstance(index, int): <TAB>  <TAB>  <TAB> if index < 0 or index >= len(self.features): <TAB>  <TAB>  <TAB>  <TAB> raise IndexError(index) <TAB>  <TAB>  <TAB> if self.features[index] is None: <TAB>  <TAB>  <TAB>  <TAB> feature = self.device.feature_request(FEATURE.FEATURE_SET, 0x10, index) <MASK> (feature,) = _unpack(""!H"", feature[:2]) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.features[index] = FEATURE[feature] <TAB>  <TAB>  <TAB> return self.features[index] <TAB>  <TAB> elif isinstance(index, slice): <TAB>  <TAB>  <TAB> indices = index.indices(len(self.features)) <TAB>  <TAB>  <TAB> return [self.__getitem__(i) for i in range(*indices)]",if feature :,195
1541,"def _get_data_from_buffer(obj): <TAB> try: <TAB>  <TAB> view = memoryview(obj) <TAB> except TypeError: <TAB>  <TAB> # try to use legacy buffer protocol if 2.7, otherwise re-raise <MASK> view = memoryview(buffer(obj)) <TAB>  <TAB>  <TAB> warnings.warn( <TAB>  <TAB>  <TAB>  <TAB> ""using old buffer interface to unpack %s; "" <TAB>  <TAB>  <TAB>  <TAB> ""this leads to unpacking errors if slicing is used and "" <TAB>  <TAB>  <TAB>  <TAB> ""will be removed in a future version"" % type(obj), <TAB>  <TAB>  <TAB>  <TAB> RuntimeWarning, <TAB>  <TAB>  <TAB>  <TAB> stacklevel=3, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise <TAB> if view.itemsize != 1: <TAB>  <TAB> raise ValueError(""cannot unpack from multi-byte object"") <TAB> return view",if PY2 :,188
1542,"def import_modules(modules, safe=True): <TAB> """"""Safely import a list of *modules*"""""" <TAB> all = [] <TAB> for mname in modules: <TAB>  <TAB> if mname.endswith("".*""): <TAB>  <TAB>  <TAB> to_load = expand_star(mname) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> to_load = [mname] <TAB>  <TAB> for module in to_load: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> all.append(import_module(module)) <TAB>  <TAB>  <TAB> except ImportError: <MASK> raise <TAB> return all",if not safe :,139
1543,"def pack(types, *args): <TAB> if len(types) != len(args): <TAB>  <TAB> raise Exception(""number of arguments does not match format string"") <TAB> port = StringIO() <TAB> for (type, value) in zip(types, args): <TAB>  <TAB> if type == ""V"": <TAB>  <TAB>  <TAB> write_vuint(port, value) <MASK> write_vint(port, value) <TAB>  <TAB> elif type == ""s"": <TAB>  <TAB>  <TAB> write_bvec(port, value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception('unknown xpack format string item ""' + type + '""') <TAB> return port.getvalue()","elif type == ""v"" :",153
1544,"def create_local_app_folder(local_app_path): <TAB> if exists(local_app_path): <TAB>  <TAB> raise ValueError(""There is already a '%s' folder! Aborting!"" % local_app_path) <TAB> for folder in subfolders(local_app_path): <MASK> os.mkdir(folder) <TAB>  <TAB>  <TAB> init_path = join(folder, ""__init__.py"") <TAB>  <TAB>  <TAB> if not exists(init_path): <TAB>  <TAB>  <TAB>  <TAB> create_file(init_path)",if not exists ( folder ) :,126
1545,"def _get_node_type_specific_fields(self, node_id: str, fields_key: str) -> Any: <TAB> fields = self.config[fields_key] <TAB> node_tags = self.provider.node_tags(node_id) <TAB> if TAG_RAY_USER_NODE_TYPE in node_tags: <TAB>  <TAB> node_type = node_tags[TAG_RAY_USER_NODE_TYPE] <MASK> raise ValueError(f""Unknown node type tag: {node_type}."") <TAB>  <TAB> node_specific_config = self.available_node_types[node_type] <TAB>  <TAB> if fields_key in node_specific_config: <TAB>  <TAB>  <TAB> fields = node_specific_config[fields_key] <TAB> return fields",if node_type not in self . available_node_types :,189
1546,"def _maybe_fix_sequence_in_union( <TAB> aliases: List[Alias], typecst: cst.SubscriptElement) -> cst.SubscriptElement: <TAB> slc = typecst.slice <TAB> if isinstance(slc, cst.Index): <TAB>  <TAB> val = slc.value <MASK> return cst.ensure_type( <TAB>  <TAB>  <TAB>  <TAB> typecst.deep_replace(val, _get_clean_type_from_subscript(aliases, val)), <TAB>  <TAB>  <TAB>  <TAB> cst.SubscriptElement, <TAB>  <TAB>  <TAB> ) <TAB> return typecst","if isinstance ( val , cst . Subscript ) :",144
1547,"def cancel_download(self, downloads): <TAB> # Make sure we're always dealing with a list <TAB> if isinstance(downloads, Download): <TAB>  <TAB> downloads = [downloads] <TAB> for download in downloads: <MASK> self.cancel_current_download() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.__paused = True <TAB>  <TAB>  <TAB> new_queue = queue.Queue() <TAB>  <TAB>  <TAB> while not self.__queue.empty(): <TAB>  <TAB>  <TAB>  <TAB> queued_download = self.__queue.get() <TAB>  <TAB>  <TAB>  <TAB> if download == queued_download: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> download.cancel() <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> new_queue.put(queued_download) <TAB>  <TAB>  <TAB> self.__queue = new_queue <TAB>  <TAB>  <TAB> self.__paused = False",if download == self . __current_download :,188
1548,"def migrate_account_metadata(account_id): <TAB> from inbox.models.session import session_scope <TAB> from inbox.models import Account <TAB> with session_scope(versioned=False) as db_session: <TAB>  <TAB> account = db_session.query(Account).get(account_id) <TAB>  <TAB> if account.discriminator == ""easaccount"": <TAB>  <TAB>  <TAB> create_categories_for_easfoldersyncstatuses(account, db_session) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> create_categories_for_folders(account, db_session) <MASK> set_labels_for_imapuids(account, db_session) <TAB>  <TAB> db_session.commit()","if account . discriminator == ""gmailaccount"" :",168
1549,"def __init__(self, fmt=None, *args): <TAB> if not isinstance(fmt, BaseException): <TAB>  <TAB> Error.__init__(self, fmt, *args) <TAB> else: <TAB>  <TAB> e = fmt <TAB>  <TAB> cls = e.__class__ <TAB>  <TAB> fmt = ""%s.%s: %s"" % (cls.__module__, cls.__name__, e) <TAB>  <TAB> tb = sys.exc_info()[2] <MASK> fmt += ""\n"" <TAB>  <TAB>  <TAB> fmt += """".join(traceback.format_tb(tb)) <TAB>  <TAB> Error.__init__(self, fmt)",if tb :,138
1550,"def setLabel(self, label): <TAB> if label is None: <MASK> self.label.scene().removeItem(self.label) <TAB>  <TAB>  <TAB> self.label = None <TAB> else: <TAB>  <TAB> if self.label is None: <TAB>  <TAB>  <TAB> self.label = TextItem() <TAB>  <TAB>  <TAB> self.label.setParentItem(self) <TAB>  <TAB> self.label.setText(label) <TAB>  <TAB> self._updateLabel()",if self . label is not None :,112
1551,"def serve_until_stopped(self) -> None: <TAB> while True: <TAB>  <TAB> rd, wr, ex = select.select([self.socket.fileno()], [], [], self.timeout) <MASK> self.handle_request() <TAB>  <TAB> if self.event is not None and self.event.is_set(): <TAB>  <TAB>  <TAB> break",if rd :,83
1552,"def generateCompressedFile(inputfile, outputfile, formatstring): <TAB> try: <MASK> in_file = open(inputfile, ""rb"") <TAB>  <TAB>  <TAB> in_data = in_file.read() <TAB>  <TAB>  <TAB> out_file = open(inputfile + "".xz"", ""wb"") <TAB>  <TAB>  <TAB> out_file.write(xz.compress(in_data)) <TAB>  <TAB>  <TAB> in_file.close() <TAB>  <TAB>  <TAB> out_file.close() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tarout = tarfile.open(outputfile, formatstring) <TAB>  <TAB>  <TAB> tarout.add(inputfile, arcname=os.path.basename(inputfile)) <TAB>  <TAB>  <TAB> tarout.close() <TAB> except Exception as e: <TAB>  <TAB> print(e) <TAB>  <TAB> return False <TAB> return True","if formatstring == ""w:xz"" :",191
1553,"def _datastore_get_handler(signal, sender, keys, **kwargs): <TAB> txn = current_transaction() <TAB> if txn: <TAB>  <TAB> for key in keys: <MASK> raise PreventedReadError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Attempted to read key (%s:%s) inside a transaction "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""where it was marked protected"" % (key.kind(), key.id_or_name()) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> txn._fetched_keys.update(set(keys))",if key in txn . _protected_keys :,130
1554,"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.set_access_token(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 16: <TAB>  <TAB>  <TAB> self.set_expiration_time(d.getVarInt64()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 10 :,124
1555,"def write_vuint(port, x): <TAB> if x < 0: <TAB>  <TAB> raise Exception(""vuints must not be negative"") <TAB> elif x == 0: <TAB>  <TAB> port.write(""\0"") <TAB> else: <TAB>  <TAB> while x: <TAB>  <TAB>  <TAB> seven_bits = x & 0x7F <TAB>  <TAB>  <TAB> x >>= 7 <MASK> port.write(chr(0x80 | seven_bits)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> port.write(chr(seven_bits))",if x :,129
1556,"def _expand_srcs(self): <TAB> """"""Expand src to [(src, full_path)]"""""" <TAB> result = [] <TAB> for src in self.srcs: <TAB>  <TAB> full_path = self._source_file_path(src) <MASK> # Assume generated <TAB>  <TAB>  <TAB> full_path = self._target_file_path(src) <TAB>  <TAB> result.append((src, full_path)) <TAB> return result",if not os . path . exists ( full_path ) :,113
1557,"def pytest_collection_modifyitems(items): <TAB> for item in items: <TAB>  <TAB> if item.nodeid.startswith(""tests/ops""): <TAB>  <TAB>  <TAB> if ""stage"" not in item.keywords: <TAB>  <TAB>  <TAB>  <TAB> item.add_marker(pytest.mark.stage(""unit"")) <MASK> item.add_marker(pytest.mark.init(rng_seed=123))","if ""init"" not in item . keywords :",102
1558,"def set_shape(self, shape): <TAB> """"""Sets a shape."""""" <TAB> if self._shape is not None: <TAB>  <TAB> logger.warning('Modifying the shape of Placeholder ""%s"".', self.name) <TAB> if not isinstance(shape, (list, tuple)): <TAB>  <TAB> shape = (shape,) <TAB> shape = tuple(x if x != ""None"" else None for x in shape) <TAB> for x in shape: <MASK> raise ParsingError( <TAB>  <TAB>  <TAB>  <TAB> 'All entries in ""shape"" must be integers, or in special ' <TAB>  <TAB>  <TAB>  <TAB> ""cases None. Shape is: {}"".format(shape) <TAB>  <TAB>  <TAB> ) <TAB> self._shape = shape","if not isinstance ( x , ( int , type ( None ) ) ) :",169
1559,"def _get_field_actual(cant_be_number, raw_string, field_names): <TAB> for line in raw_string.splitlines(): <TAB>  <TAB> for field_name in field_names: <TAB>  <TAB>  <TAB> field_name = field_name.lower() <TAB>  <TAB>  <TAB> if "":"" in line: <TAB>  <TAB>  <TAB>  <TAB> left, right = line.split("":"", 1) <TAB>  <TAB>  <TAB>  <TAB> left = left.strip().lower() <TAB>  <TAB>  <TAB>  <TAB> right = right.strip() <MASK> if cant_be_number: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if not right.isdigit(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return right <TAB>  <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return right <TAB> return None",if left == field_name and len ( right ) > 0 :,184
1560,"def validate_attributes(self): <TAB> for attribute in self.get_all_attributes(): <TAB>  <TAB> value = getattr(self, attribute.code, None) <TAB>  <TAB> if value is None: <MASK> raise ValidationError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _(""%(attr)s attribute cannot be blank"") % {""attr"": attribute.code} <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> attribute.validate_value(value) <TAB>  <TAB>  <TAB> except ValidationError as e: <TAB>  <TAB>  <TAB>  <TAB> raise ValidationError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _(""%(attr)s attribute %(err)s"") % {""attr"": attribute.code, ""err"": e} <TAB>  <TAB>  <TAB>  <TAB> )",if attribute . required :,168
1561,"def append(self, s): <TAB> buf = self.buf <TAB> if buf is None: <TAB>  <TAB> strbuf = self.strbuf <MASK> self.strbuf = strbuf + s <TAB>  <TAB>  <TAB> return <TAB>  <TAB> buf = self._create_buffer() <TAB> buf.append(s) <TAB> # use buf.__len__ rather than len(buf) FBO of not getting <TAB> # OverflowError on Python 2 <TAB> sz = buf.__len__() <TAB> if not self.overflowed: <TAB>  <TAB> if sz >= self.overflow: <TAB>  <TAB>  <TAB> self._set_large_buffer()",if len ( strbuf ) + len ( s ) < STRBUF_LIMIT :,154
1562,"def billing_invoice_show_validator(namespace): <TAB> from azure.cli.core.azclierror import ( <TAB>  <TAB> RequiredArgumentMissingError, <TAB>  <TAB> MutuallyExclusiveArgumentError, <TAB> ) <TAB> valid_combs = ( <TAB>  <TAB> ""only --account-name, --name / --name / --name, --by-subscription is valid"" <TAB> ) <TAB> if namespace.account_name is not None: <MASK> raise MutuallyExclusiveArgumentError(valid_combs) <TAB>  <TAB> if namespace.name is None: <TAB>  <TAB>  <TAB> raise RequiredArgumentMissingError(""--name is also required"") <TAB> if namespace.by_subscription is not None: <TAB>  <TAB> if namespace.name is None: <TAB>  <TAB>  <TAB> raise RequiredArgumentMissingError(""--name is also required"")",if namespace . by_subscription is not None :,188
1563,"def Handle(self, args, context=None): <TAB> for client_id in args.client_ids: <TAB>  <TAB> cid = str(client_id) <TAB>  <TAB> data_store.REL_DB.RemoveClientLabels(cid, context.username, args.labels) <TAB>  <TAB> labels_to_remove = set(args.labels) <TAB>  <TAB> existing_labels = data_store.REL_DB.ReadClientLabels(cid) <TAB>  <TAB> for label in existing_labels: <TAB>  <TAB>  <TAB> labels_to_remove.discard(label.name) <MASK> idx = client_index.ClientIndex() <TAB>  <TAB>  <TAB> idx.RemoveClientLabels(cid, labels_to_remove)",if labels_to_remove :,164
1564,"def delete_snapshot(self, snapshot): <TAB> snap_name = self._get_snap_name(snapshot[""id""]) <TAB> LOG.debug(""Deleting snapshot (%s)"", snapshot[""id""]) <TAB> self.client_login() <TAB> try: <TAB>  <TAB> self.client.delete_snapshot(snap_name, self.backend_type) <TAB> except exception.DotHillRequestError as ex: <TAB>  <TAB> # if the volume wasn't found, ignore the error <MASK> return <TAB>  <TAB> LOG.exception(""Deleting snapshot %s failed"", snapshot[""id""]) <TAB>  <TAB> raise exception.Invalid(ex) <TAB> finally: <TAB>  <TAB> self.client_logout()","if ""The volume was not found on this system."" in ex . args :",165
1565,"def jobs(self): <TAB> # How many jobs have we done? <TAB> total_processed = 0 <TAB> for jobEntity in self.jobItems.query_entities(): <TAB>  <TAB> # Process the items in the page <TAB>  <TAB> yield AzureJob.fromEntity(jobEntity) <TAB>  <TAB> total_processed += 1 <MASK> # Produce some feedback for the user, because this can take <TAB>  <TAB>  <TAB> # a long time on, for example, Azure <TAB>  <TAB>  <TAB> logger.debug(""Processed %d total jobs"" % total_processed) <TAB> logger.debug(""Processed %d total jobs"" % total_processed)",if total_processed % 1000 == 0 :,153
1566,def run(self): <TAB> while not self.completed: <TAB>  <TAB> if self.block: <TAB>  <TAB>  <TAB> time.sleep(self.period) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._completed.wait(self.period) <TAB>  <TAB> self.counter += 1 <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.callback(self.counter) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> self.stop() <TAB>  <TAB> if self.timeout is not None: <TAB>  <TAB>  <TAB> dt = time.time() - self._start_time <TAB>  <TAB>  <TAB> if dt > self.timeout: <TAB>  <TAB>  <TAB>  <TAB> self.stop() <MASK> self.stop(),if self . counter == self . count :,159
1567,"def get_instance(cls, pool_size=None): <TAB> if cls._instance is not None: <TAB>  <TAB> return cls._instance <TAB> # Lazy init <TAB> with cls._SINGLETON_LOCK: <MASK> cls._instance = cls( <TAB>  <TAB>  <TAB>  <TAB> ARCTIC_ASYNC_NWORKERS if pool_size is None else pool_size <TAB>  <TAB>  <TAB> ) <TAB> return cls._instance",if cls . _instance is None :,102
1568,"def set_state(self, state): <TAB> if self._inhibit_play: <TAB>  <TAB> # PLAYING, PAUSED change the state for after buffering is finished, <TAB>  <TAB> # everything else aborts buffering <MASK> # abort <TAB>  <TAB>  <TAB> self.__set_inhibit_play(False) <TAB>  <TAB>  <TAB> self.bin.set_state(state) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> self._wanted_state = state <TAB> else: <TAB>  <TAB> self.bin.set_state(state)","if state not in ( Gst . State . PLAYING , Gst . State . PAUSED ) :",136
1569,"def seen_add(options): <TAB> seen_name = options.add_value <TAB> if is_imdb_url(seen_name): <TAB>  <TAB> console(""IMDB url detected, try to parse ID"") <TAB>  <TAB> imdb_id = extract_id(seen_name) <MASK> seen_name = imdb_id <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> console(""Could not parse IMDB ID"") <TAB> db.add(seen_name, ""cli_add"", {""cli_add"": seen_name}) <TAB> console(""Added %s as seen. This will affect all tasks."" % seen_name)",if imdb_id :,144
1570,"def test_204_invalid_content_length(self): <TAB> # 204 status with non-zero content length is malformed <TAB> with ExpectLog(gen_log, "".*Response with code 204 should not have body""): <TAB>  <TAB> response = self.fetch(""/?error=1"") <TAB>  <TAB> if not self.http1: <TAB>  <TAB>  <TAB> self.skipTest(""requires HTTP/1.x"") <MASK> self.skipTest(""curl client accepts invalid headers"") <TAB>  <TAB> self.assertEqual(response.code, 599)",if self . http_client . configured_class != SimpleAsyncHTTPClient :,136
1571,"def set_related_perm(_mapper: Mapper, _connection: Connection, target: Slice) -> None: <TAB> src_class = target.cls_model <TAB> id_ = target.datasource_id <TAB> if id_: <TAB>  <TAB> ds = db.session.query(src_class).filter_by(id=int(id_)).first() <MASK> target.perm = ds.perm <TAB>  <TAB>  <TAB> target.schema_perm = ds.schema_perm",if ds :,110
1572,"def on_modified_async(self, view): <TAB> if self.is_command_line(view): <MASK> view.run_command(""text_pastry_selection_preview"")","if view . size ( ) > 6 and view . substr ( sublime . Region ( 0 , 6 ) ) . lower ( ) == ""search"" :",76
1573,"def _improve_answer_span( <TAB> doc_tokens, input_start, input_end, tokenizer, orig_answer_text): <TAB> """"""Returns tokenized answer spans that better match the annotated answer."""""" <TAB> tok_answer_text = "" "".join(tokenizer.tokenize(orig_answer_text)) <TAB> for new_start in range(input_start, input_end + 1): <TAB>  <TAB> for new_end in range(input_end, new_start - 1, -1): <TAB>  <TAB>  <TAB> text_span = "" "".join(doc_tokens[new_start : (new_end + 1)]) <MASK> return new_start, new_end <TAB> return input_start, input_end",if text_span == tok_answer_text :,174
1574,"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.set_url(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 18: <TAB>  <TAB>  <TAB> self.set_app_version_id(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 26: <TAB>  <TAB>  <TAB> self.set_method(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 34: <TAB>  <TAB>  <TAB> self.set_queue(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 10 :,184
1575,"def _add_resource_group(obj): <TAB> if isinstance(obj, list): <TAB>  <TAB> for array_item in obj: <TAB>  <TAB>  <TAB> _add_resource_group(array_item) <TAB> elif isinstance(obj, dict): <TAB>  <TAB> try: <MASK> if obj[""id""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> obj[""resourceGroup""] = _parse_id(obj[""id""])[""resource-group""] <TAB>  <TAB> except (KeyError, IndexError, TypeError): <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> for item_key in obj: <TAB>  <TAB>  <TAB> if item_key != ""sourceVault"": <TAB>  <TAB>  <TAB>  <TAB> _add_resource_group(obj[item_key])","if ""resourcegroup"" not in [ x . lower ( ) for x in obj . keys ( ) ] :",175
1576,"def build(opt): <TAB> dpath = os.path.join(opt[""datapath""], DECODE) <TAB> version = DECODE_VERSION <TAB> if not build_data.built(dpath, version_string=version): <TAB>  <TAB> print(""[building data: "" + dpath + ""]"") <MASK> # An older version exists, so remove these outdated files. <TAB>  <TAB>  <TAB> build_data.remove_dir(dpath) <TAB>  <TAB> build_data.make_dir(dpath) <TAB>  <TAB> # Download the data. <TAB>  <TAB> for downloadable_file in RESOURCES: <TAB>  <TAB>  <TAB> downloadable_file.download_file(dpath) <TAB>  <TAB> # Mark the data as built. <TAB>  <TAB> build_data.mark_done(dpath, version_string=version)",if build_data . built ( dpath ) :,183
1577,"def toterminal(self, tw): <TAB> # the entries might have different styles <TAB> last_style = None <TAB> for i, entry in enumerate(self.reprentries): <MASK> tw.line("""") <TAB>  <TAB> entry.toterminal(tw) <TAB>  <TAB> if i < len(self.reprentries) - 1: <TAB>  <TAB>  <TAB> next_entry = self.reprentries[i + 1] <TAB>  <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB>  <TAB> entry.style == ""long"" <TAB>  <TAB>  <TAB>  <TAB> or entry.style == ""short"" <TAB>  <TAB>  <TAB>  <TAB> and next_entry.style == ""long"" <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> tw.sep(self.entrysep) <TAB> if self.extraline: <TAB>  <TAB> tw.line(self.extraline)","if entry . style == ""long"" :",198
1578,"def reposition_division(f1): <TAB> lines = f1.splitlines() <TAB> if lines[2] == division: <TAB>  <TAB> lines.pop(2) <TAB> found = 0 <TAB> for i, line in enumerate(lines): <MASK> found += 1 <TAB>  <TAB>  <TAB> if found == 2: <TAB>  <TAB>  <TAB>  <TAB> if division in ""\n"".join(lines): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break  # already in the right place <TAB>  <TAB>  <TAB>  <TAB> lines.insert(i + 1, """") <TAB>  <TAB>  <TAB>  <TAB> lines.insert(i + 2, division) <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return ""\n"".join(lines)","if line . startswith ( '""""""' ) :",153
1579,def run_on_module(self): <TAB> try: <TAB>  <TAB> self.module_base.disable(self.opts.module_spec) <TAB> except dnf.exceptions.MarkingErrors as e: <TAB>  <TAB> if self.base.conf.strict: <MASK> raise e <TAB>  <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB>  <TAB> e.module_depsolv_errors <TAB>  <TAB>  <TAB>  <TAB> and e.module_depsolv_errors[1] <TAB>  <TAB>  <TAB>  <TAB> != libdnf.module.ModulePackageContainer.ModuleErrorType_ERROR_IN_DEFAULTS <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> raise e <TAB>  <TAB> logger.error(str(e)),if e . no_match_group_specs or e . error_group_specs :,174
1580,"def test_len(self): <TAB> eq = self.assertEqual <TAB> eq(base64mime.base64_len(""hello""), len(base64mime.encode(""hello"", eol=""""))) <TAB> for size in range(15): <TAB>  <TAB> if size == 0: <TAB>  <TAB>  <TAB> bsize = 0 <TAB>  <TAB> elif size <= 3: <TAB>  <TAB>  <TAB> bsize = 4 <TAB>  <TAB> elif size <= 6: <TAB>  <TAB>  <TAB> bsize = 8 <MASK> bsize = 12 <TAB>  <TAB> elif size <= 12: <TAB>  <TAB>  <TAB> bsize = 16 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> bsize = 20 <TAB>  <TAB> eq(base64mime.base64_len(""x"" * size), bsize)",elif size <= 9 :,160
1581,"def is_valid(self): <TAB> """"""Determines whether file is valid for this reader"""""" <TAB> blocklist = self.open() <TAB> valid = True <TAB> for line in blocklist: <TAB>  <TAB> line = decode_bytes(line) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> (start, end) = self.parse(line) <TAB>  <TAB>  <TAB>  <TAB> if not re.match(r""^(\d{1,3}\.){4}$"", start + ""."") or not re.match( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> r""^(\d{1,3}\.){4}$"", end + ""."" <TAB>  <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> valid = False <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> valid = False <TAB>  <TAB>  <TAB> break <TAB> blocklist.close() <TAB> return valid",if not self . is_ignored ( line ) :,188
1582,"def next(self): <TAB> while self.index < len(self.data): <TAB>  <TAB> uid = self._read_next_word() <TAB>  <TAB> dont_care = self._read_next_word() <TAB>  <TAB> entry = self._read_next_string() <TAB>  <TAB> total_size = int(4 + 4 + len(entry)) <TAB>  <TAB> count = int(total_size / self.SIZE) <TAB>  <TAB> if count == 0: <TAB>  <TAB>  <TAB> mod = self.SIZE - total_size <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> mod = self.SIZE - int(total_size - (count * self.SIZE)) <MASK> remainder = self._read_next_block(mod) <TAB>  <TAB> yield (uid, entry)",if mod > 0 :,175
1583,"def _str_param_list(self, name): <TAB> out = [] <TAB> if self[name]: <TAB>  <TAB> out += self._str_header(name) <TAB>  <TAB> for param in self[name]: <TAB>  <TAB>  <TAB> parts = [] <TAB>  <TAB>  <TAB> if param.name: <TAB>  <TAB>  <TAB>  <TAB> parts.append(param.name) <TAB>  <TAB>  <TAB> if param.type: <TAB>  <TAB>  <TAB>  <TAB> parts.append(param.type) <TAB>  <TAB>  <TAB> out += ["" : "".join(parts)] <MASK> out += self._str_indent(param.desc) <TAB>  <TAB> out += [""""] <TAB> return out","if param . desc and """" . join ( param . desc ) . strip ( ) :",157
1584,"def assert_backend(self, expected_translated, language=""cs""): <TAB> """"""Check that backend has correct data."""""" <TAB> translation = self.get_translation(language) <TAB> translation.commit_pending(""test"", None) <TAB> store = translation.component.file_format_cls(translation.get_filename(), None) <TAB> messages = set() <TAB> translated = 0 <TAB> for unit in store.content_units: <TAB>  <TAB> id_hash = unit.id_hash <TAB>  <TAB> self.assertFalse(id_hash in messages, ""Duplicate string in in backend file!"") <MASK> translated += 1 <TAB> self.assertEqual( <TAB>  <TAB> translated, <TAB>  <TAB> expected_translated, <TAB>  <TAB> ""Did not found expected number of translations ({} != {})."".format( <TAB>  <TAB>  <TAB> translated, expected_translated <TAB>  <TAB> ), <TAB> )",if unit . is_translated ( ) :,195
1585,"def status(self, name, error=""No matching script logs found""): <TAB> with self.script_lock: <MASK> return self.script_running[1:] <TAB>  <TAB> elif self.script_last and self.script_last[1] == name: <TAB>  <TAB>  <TAB> return self.script_last[1:] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(error)",if self . script_running and self . script_running [ 1 ] == name :,107
1586,"def dict_no_value_from_proto_list(obj_list): <TAB> d = dict() <TAB> for item in obj_list: <TAB>  <TAB> possible_dict = json.loads(item.value_json) <MASK> # (tss) TODO: This is protecting against legacy 'wandb_version' field. <TAB>  <TAB>  <TAB> # Should investigate why the config payload even has 'wandb_version'. <TAB>  <TAB>  <TAB> logger.warning(""key '{}' has no 'value' attribute"".format(item.key)) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> d[item.key] = possible_dict[""value""] <TAB> return d","if not isinstance ( possible_dict , dict ) or ""value"" not in possible_dict :",167
1587,"def visit(self, node): <TAB> """"""dispatcher on node's class/bases name."""""" <TAB> cls = node.__class__ <TAB> try: <TAB>  <TAB> visitmethod = self.cache[cls] <TAB> except KeyError: <TAB>  <TAB> for subclass in cls.__mro__: <TAB>  <TAB>  <TAB> visitmethod = getattr(self, subclass.__name__, None) <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> visitmethod = self.__object <TAB>  <TAB> self.cache[cls] = visitmethod <TAB> visitmethod(node)",if visitmethod is not None :,127
1588,"def _get_adapter( <TAB> mcls, <TAB> reversed_mro: Tuple[type, ...], <TAB> collection: Dict[Any, Dict[type, Adapter]], <TAB> kwargs: Dict[str, Any],) -> Optional[Adapter]: <TAB> registry_key = mcls.get_registry_key(kwargs) <TAB> adapters = collection.get(registry_key) <TAB> if adapters is None: <TAB>  <TAB> return None <TAB> result = None <TAB> seen: Set[Adapter] = set() <TAB> for base in reversed_mro: <TAB>  <TAB> for adaptee, adapter in adapters.items(): <TAB>  <TAB>  <TAB> found = mcls._match_adapter(base, adaptee, adapter) <MASK> result = found <TAB>  <TAB>  <TAB>  <TAB> seen.add(found) <TAB> return result",if found and found not in seen :,190
1589,"def test_pt_BR_rg(self): <TAB> for _ in range(100): <TAB>  <TAB> to_test = self.fake.rg() <MASK> assert re.search(r""^\d{8}X"", to_test) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert re.search(r""^\d{9}$"", to_test)","if ""X"" in to_test :",91
1590,"def get_user_extra_data_by_client_id(self, client_id, username): <TAB> extra_data = {} <TAB> current_client = self.clients.get(client_id, None) <TAB> if current_client: <TAB>  <TAB> for readable_field in current_client.get_readable_fields(): <TAB>  <TAB>  <TAB> attribute = list( <TAB>  <TAB>  <TAB>  <TAB> filter( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> lambda f: f[""Name""] == readable_field, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.users.get(username).attributes, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <MASK> extra_data.update({attribute[0][""Name""]: attribute[0][""Value""]}) <TAB> return extra_data",if len ( attribute ) > 0 :,176
1591,"def augment(self, resources): <TAB> super().augment(resources) <TAB> for r in resources: <TAB>  <TAB> md = r.get(""SAMLMetadataDocument"") <MASK> continue <TAB>  <TAB> root = sso_metadata(md) <TAB>  <TAB> r[""IDPSSODescriptor""] = root[""IDPSSODescriptor""] <TAB> return resources",if not md :,82
1592,"def __init__(self, mode=0, decode=None): <TAB> self.regex = self.REGEX[mode] <TAB> self.decode = decode <TAB> if decode: <TAB>  <TAB> self.header = _( <TAB>  <TAB>  <TAB> ""### This log has been decoded with automatic search pattern\n"" <TAB>  <TAB>  <TAB> ""### If some paths are not decoded you can manually decode them with:\n"" <TAB>  <TAB> ) <TAB>  <TAB> self.header += ""### 'backintime --quiet "" <MASK> self.header += '--profile ""%s"" ' % decode.config.profileName() <TAB>  <TAB> self.header += ""--decode <path>'\n\n"" <TAB> else: <TAB>  <TAB> self.header = """"",if int ( decode . config . currentProfile ( ) ) > 1 :,173
1593,"def _get_dynamic_attr(self, attname, obj, default=None): <TAB> try: <TAB>  <TAB> attr = getattr(self, attname) <TAB> except AttributeError: <TAB>  <TAB> return default <TAB> if callable(attr): <TAB>  <TAB> # Check co_argcount rather than try/excepting the function and <TAB>  <TAB> # catching the TypeError, because something inside the function <TAB>  <TAB> # may raise the TypeError. This technique is more accurate. <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> code = six.get_function_code(attr) <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB> code = six.get_function_code(attr.__call__) <MASK> # one argument is 'self' <TAB>  <TAB>  <TAB> return attr(obj) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return attr() <TAB> return attr",if code . co_argcount == 2 :,190
1594,"def grep_full_py_identifiers(tokens): <TAB> global pykeywords <TAB> tokens = list(tokens) <TAB> i = 0 <TAB> while i < len(tokens): <TAB>  <TAB> tokentype, token = tokens[i] <TAB>  <TAB> i += 1 <MASK> continue <TAB>  <TAB> while ( <TAB>  <TAB>  <TAB> i + 1 < len(tokens) <TAB>  <TAB>  <TAB> and tokens[i] == (""op"", ""."") <TAB>  <TAB>  <TAB> and tokens[i + 1][0] == ""id"" <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> token += ""."" + tokens[i + 1][1] <TAB>  <TAB>  <TAB> i += 2 <TAB>  <TAB> if token == """": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if token in pykeywords: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if token[0] in "".0123456789"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> yield token","if tokentype != ""id"" :",194
1595,"def _add_disk_config(self, context, images): <TAB> for image in images: <TAB>  <TAB> metadata = image[""metadata""] <MASK> raw_value = metadata[INTERNAL_DISK_CONFIG] <TAB>  <TAB>  <TAB> value = utils.bool_from_str(raw_value) <TAB>  <TAB>  <TAB> image[API_DISK_CONFIG] = disk_config_to_api(value)",if INTERNAL_DISK_CONFIG in metadata :,101
1596,"def test_edgeql_expr_valid_setop_07(self): <TAB> expected_error_msg = ""cannot be applied to operands"" <TAB> # IF ELSE with every scalar as the condition <TAB> for val in get_test_values(): <TAB>  <TAB> query = f""""""SELECT 1 IF {val} ELSE 2;"""""" <MASK> await self.assert_query_result(query, [1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # every other combination must produce an error <TAB>  <TAB>  <TAB> with self.assertRaisesRegex( <TAB>  <TAB>  <TAB>  <TAB> edgedb.QueryError, expected_error_msg, msg=query <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> async with self.con.transaction(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> await self.con.execute(query)","if val == ""<bool>True"" :",179
1597,"def get_all_url_infos() -> Dict[str, UrlInfo]: <TAB> """"""Returns dict associating URL to UrlInfo."""""" <TAB> url_infos = {} <TAB> for path in _checksum_paths().values(): <TAB>  <TAB> dataset_url_infos = load_url_infos(path) <TAB>  <TAB> for url, url_info in dataset_url_infos.items(): <MASK> raise AssertionError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""URL {} is registered with 2+ distinct size/checksum tuples. "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""{} vs {}"".format(url, url_info, url_infos[url]) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> url_infos.update(dataset_url_infos) <TAB> return url_infos","if url_infos . get ( url , url_info ) != url_info :",185
1598,"def global_fixes(): <TAB> """"""Yield multiple (code, function) tuples."""""" <TAB> for function in list(globals().values()): <MASK> arguments = _get_parameters(function) <TAB>  <TAB>  <TAB> if arguments[:1] != [""source""]: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> code = extract_code_from_function(function) <TAB>  <TAB>  <TAB> if code: <TAB>  <TAB>  <TAB>  <TAB> yield (code, function)",if inspect . isfunction ( function ) :,106
1599,"def createSocket(self): <TAB> skt = Port.createSocket(self) <TAB> if self.listenMultiple: <TAB>  <TAB> skt.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) <MASK> skt.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1) <TAB> return skt","if hasattr ( socket , ""SO_REUSEPORT"" ) :",90
1600,"def _asStringList(self, sep=""""): <TAB> out = [] <TAB> for item in self._toklist: <TAB>  <TAB> if out and sep: <TAB>  <TAB>  <TAB> out.append(sep) <MASK> out += item._asStringList() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> out.append(str(item)) <TAB> return out","if isinstance ( item , ParseResults ) :",88
1601,"def parse_c_comments(lexer, tok, ntok): <TAB> if tok != ""/"" or ntok != ""*"": <TAB>  <TAB> return False <TAB> quotes = lexer.quotes <TAB> lexer.quotes = """" <TAB> while True: <TAB>  <TAB> tok = lexer.get_token() <TAB>  <TAB> ntok = lexer.get_token() <MASK> lexer.quotes = quotes <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lexer.push_token(ntok) <TAB> return True","if tok == ""*"" and ntok == ""/"" :",121
1602,"def doWorkForFindAll(self, v, target, partialMatch): <TAB> sibling = self <TAB> while sibling: <TAB>  <TAB> c1 = partialMatch and sibling.equalsTreePartial(target) <TAB>  <TAB> if c1: <TAB>  <TAB>  <TAB> v.append(sibling) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> c2 = not partialMatch and sibling.equalsTree(target) <MASK> v.append(sibling) <TAB>  <TAB> ### regardless of match or not, check any children for matches <TAB>  <TAB> if sibling.getFirstChild(): <TAB>  <TAB>  <TAB> sibling.getFirstChild().doWorkForFindAll(v, target, partialMatch) <TAB>  <TAB> sibling = sibling.getNextSibling()",if c2 :,163
1603,"def __view_beside(self, onsideof, **kwargs): <TAB> bounds = self.info[""bounds""] <TAB> min_dist, found = -1, None <TAB> for ui in UiObject(self.session, Selector(**kwargs)): <TAB>  <TAB> dist = onsideof(bounds, ui.info[""bounds""]) <MASK> min_dist, found = dist, ui <TAB> return found",if dist >= 0 and ( min_dist < 0 or dist < min_dist ) :,112
1604,"def __eq__(self, other): <TAB> if isinstance(other, numeric_range): <TAB>  <TAB> empty_self = not bool(self) <TAB>  <TAB> empty_other = not bool(other) <MASK> return empty_self and empty_other  # True if both empty <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB>  <TAB> self._start == other._start <TAB>  <TAB>  <TAB>  <TAB> and self._step == other._step <TAB>  <TAB>  <TAB>  <TAB> and self._get_by_index(-1) == other._get_by_index(-1) <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> return False",if empty_self or empty_other :,151
1605,"def _buffered_generator(self, size): <TAB> buf = [] <TAB> c_size = 0 <TAB> push = buf.append <TAB> while 1: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> while c_size < size: <TAB>  <TAB>  <TAB>  <TAB> c = next(self._gen) <TAB>  <TAB>  <TAB>  <TAB> push(c) <TAB>  <TAB>  <TAB>  <TAB> if c: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> c_size += 1 <TAB>  <TAB> except StopIteration: <MASK> return <TAB>  <TAB> yield concat(buf) <TAB>  <TAB> del buf[:] <TAB>  <TAB> c_size = 0",if not c_size :,137
1606,"def connect(self): <TAB> with self._conn_lock: <MASK> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> ""Error, database not properly initialized "" ""before opening connection"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> with self.exception_wrapper(): <TAB>  <TAB>  <TAB> self.__local.conn = self._connect(self.database, **self.connect_kwargs) <TAB>  <TAB>  <TAB> self.__local.closed = False <TAB>  <TAB>  <TAB> self.initialize_connection(self.__local.conn)",if self . deferred :,115
1607,"def _merge_substs(self, subst, new_substs): <TAB> subst = subst.copy() <TAB> for new_subst in new_substs: <TAB>  <TAB> for name, var in new_subst.items(): <MASK> subst[name] = var <TAB>  <TAB>  <TAB> elif subst[name] is not var: <TAB>  <TAB>  <TAB>  <TAB> subst[name].PasteVariable(var) <TAB> return subst",if name not in subst :,109
1608,"def remove(self, tag): <TAB> """"""Removes a tag recursively from all containers."""""" <TAB> new_contents = [] <TAB> self.content_size = 0 <TAB> for element in self.contents: <TAB>  <TAB> if element.name != tag: <TAB>  <TAB>  <TAB> new_contents.append(element) <MASK> element.remove(tag) <TAB>  <TAB>  <TAB> self.content_size += element.size() <TAB> self.contents = new_contents","if isinstance ( element , Container ) :",111
1609,"def _create_object(self, obj_body): <TAB> props = obj_body[SYMBOL_PROPERTIES] <TAB> for prop_name, prop_value in props.items(): <TAB>  <TAB> if isinstance(prop_value, dict) and prop_value: <TAB>  <TAB>  <TAB> # get the first key as the convert function <TAB>  <TAB>  <TAB> func_name = list(prop_value.keys())[0] <MASK> func = getattr(self, func_name) <TAB>  <TAB>  <TAB>  <TAB> props[prop_name] = func(prop_value[func_name]) <TAB> if SYMBOL_TYPE in obj_body and obj_body[SYMBOL_TYPE] in self.fake_func_mapping: <TAB>  <TAB> return self.fake_func_mapping[obj_body[SYMBOL_TYPE]](**props) <TAB> else: <TAB>  <TAB> return props","if func_name . startswith ( ""_"" ) :",199
1610,"def visit_try_stmt(self, o: ""mypy.nodes.TryStmt"") -> str: <TAB> a = [o.body]  # type: List[Any] <TAB> for i in range(len(o.vars)): <TAB>  <TAB> a.append(o.types[i]) <MASK> a.append(o.vars[i]) <TAB>  <TAB> a.append(o.handlers[i]) <TAB> if o.else_body: <TAB>  <TAB> a.append((""Else"", o.else_body.body)) <TAB> if o.finally_body: <TAB>  <TAB> a.append((""Finally"", o.finally_body.body)) <TAB> return self.dump(a, o)",if o . vars [ i ] :,166
1611,"def everythingIsUnicode(d): <TAB> """"""Takes a dictionary, recursively verifies that every value is unicode"""""" <TAB> for k, v in d.iteritems(): <TAB>  <TAB> if isinstance(v, dict) and k != ""headers"": <TAB>  <TAB>  <TAB> if not everythingIsUnicode(v): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> elif isinstance(v, list): <TAB>  <TAB>  <TAB> for i in v: <TAB>  <TAB>  <TAB>  <TAB> if isinstance(i, dict) and not everythingIsUnicode(i): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <MASK> return False <TAB>  <TAB> elif isinstance(v, _bytes): <TAB>  <TAB>  <TAB> return False <TAB> return True","elif isinstance ( i , _bytes ) :",158
1612,"def msg_ser(inst, sformat, lev=0): <TAB> if sformat in [""urlencoded"", ""json""]: <TAB>  <TAB> if isinstance(inst, Message): <TAB>  <TAB>  <TAB> res = inst.serialize(sformat, lev) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> res = inst <TAB> elif sformat == ""dict"": <TAB>  <TAB> if isinstance(inst, Message): <TAB>  <TAB>  <TAB> res = inst.serialize(sformat, lev) <MASK> res = inst <TAB>  <TAB> elif isinstance(inst, str):  # Iff ID Token <TAB>  <TAB>  <TAB> res = inst <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise MessageException(""Wrong type: %s"" % type(inst)) <TAB> else: <TAB>  <TAB> raise PyoidcError(""Unknown sformat"", inst) <TAB> return res","elif isinstance ( inst , dict ) :",182
1613,"def start_container_if_stopped(self, container, attach_logs=False, quiet=False): <TAB> if not container.is_running: <MASK> log.info(""Starting %s"" % container.name) <TAB>  <TAB> if attach_logs: <TAB>  <TAB>  <TAB> container.attach_log_stream() <TAB>  <TAB> return self.start_container(container)",if not quiet :,90
1614,"def layer_op(self, input_image, mask=None): <TAB> if not isinstance(input_image, dict): <TAB>  <TAB> self._set_full_border(input_image) <TAB>  <TAB> input_image = np.pad(input_image, self.full_border, mode=self.mode) <TAB>  <TAB> return input_image, mask <TAB> for name, image in input_image.items(): <TAB>  <TAB> self._set_full_border(image) <MASK> tf.logging.warning( <TAB>  <TAB>  <TAB>  <TAB> ""could not pad, dict name %s not in %s"", name, self.image_name <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> input_image[name] = np.pad(image, self.full_border, mode=self.mode) <TAB> return input_image, mask",if name not in self . image_name :,200
1615,"def __Suffix_Noun_Step2b(self, token): <TAB> for suffix in self.__suffix_noun_step2b: <MASK> token = token[:-2] <TAB>  <TAB>  <TAB> self.suffix_noun_step2b_success = True <TAB>  <TAB>  <TAB> break <TAB> return token",if token . endswith ( suffix ) and len ( token ) >= 5 :,86
1616,"def replace_header_items(ps, replacments): <TAB> match = read_while(ps, header_item_or_end_re.match, lambda match: match is None) <TAB> while not ps.current_line.startswith(""*/""): <TAB>  <TAB> match = header_item_re.match(ps.current_line) <MASK> key = match.groupdict()[""key""] <TAB>  <TAB>  <TAB> if key in replacments: <TAB>  <TAB>  <TAB>  <TAB> ps.current_line = match.expand( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""\g<key>\g<space>%s\n"" % replacments[key] <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ps.read_line()",if match is not None :,163
1617,"def __projectBookmark(widget, location): <TAB> script = None <TAB> while widget is not None: <MASK> script = widget.scriptNode() <TAB>  <TAB>  <TAB> if isinstance(script, Gaffer.ScriptNode): <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> widget = widget.parent() <TAB> if script is not None: <TAB>  <TAB> p = script.context().substitute(location) <TAB>  <TAB> if not os.path.exists(p): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> os.makedirs(p) <TAB>  <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> return p <TAB> else: <TAB>  <TAB> return os.getcwd()","if hasattr ( widget , ""scriptNode"" ) :",159
1618,"def events_to_str(event_field, all_events): <TAB> result = [] <TAB> for (flag, string) in all_events: <TAB>  <TAB> c_flag = flag <TAB>  <TAB> if event_field & c_flag: <TAB>  <TAB>  <TAB> result.append(string) <TAB>  <TAB>  <TAB> event_field = event_field & (~c_flag) <MASK> break <TAB> if event_field: <TAB>  <TAB> result.append(hex(event_field)) <TAB> return ""|"".join(result)",if not event_field :,123
1619,"def get_s3_bucket_locations(buckets, self_log=False): <TAB> """"""return (bucket_name, prefix) for all s3 logging targets"""""" <TAB> for b in buckets: <TAB>  <TAB> if b.get(""Logging""): <TAB>  <TAB>  <TAB> if self_log: <TAB>  <TAB>  <TAB>  <TAB> if b[""Name""] != b[""Logging""][""TargetBucket""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> yield (b[""Logging""][""TargetBucket""], b[""Logging""][""TargetPrefix""]) <MASK> yield (b[""Name""], """")","if not self_log and b [ ""Name"" ] . startswith ( ""cf-templates-"" ) :",138
1620,"def extract_file(tgz, tarinfo, dst_path, buffer_size=10 << 20, log_function=None): <TAB> """"""Extracts 'tarinfo' from 'tgz' and writes to 'dst_path'."""""" <TAB> src = tgz.extractfile(tarinfo) <TAB> if src is None: <TAB>  <TAB> return <TAB> dst = tf.compat.v1.gfile.GFile(dst_path, ""wb"") <TAB> while 1: <TAB>  <TAB> buf = src.read(buffer_size) <TAB>  <TAB> if not buf: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> dst.write(buf) <MASK> log_function(len(buf)) <TAB> dst.close() <TAB> src.close()",if log_function is not None :,165
1621,"def make_index_fields(rec): <TAB> fields = {} <TAB> for k, v in rec.iteritems(): <TAB>  <TAB> if k in (""lccn"", ""oclc"", ""isbn""): <TAB>  <TAB>  <TAB> fields[k] = v <TAB>  <TAB>  <TAB> continue <MASK> fields[""title""] = [read_short_title(v)] <TAB> return fields","if k == ""full_title"" :",93
1622,"def disconnect_application(self): <TAB> if not self.is_app_running(self.APP_BACKDROP): <TAB>  <TAB> self.socket.send(commands.CloseCommand(destination_id=False)) <TAB>  <TAB> start_time = time.time() <TAB>  <TAB> while not self.is_app_running(None): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> self.socket.send_and_wait(commands.StatusCommand()) <TAB>  <TAB>  <TAB> except cast_socket.ConnectionTerminatedException: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> current_time = time.time() <MASK> raise TimeoutException() <TAB>  <TAB>  <TAB> time.sleep(self.WAIT_INTERVAL) <TAB> else: <TAB>  <TAB> logger.debug(""Closing not necessary. Backdrop is running ..."")",if current_time - start_time > self . timeout :,190
1623,"def matches(self, cursor_offset, line, **kwargs): <TAB> cs = lineparts.current_string(cursor_offset, line) <TAB> if cs is None: <TAB>  <TAB> return None <TAB> matches = set() <TAB> username = cs.word.split(os.path.sep, 1)[0] <TAB> user_dir = os.path.expanduser(username) <TAB> for filename in self.safe_glob(os.path.expanduser(cs.word)): <TAB>  <TAB> if os.path.isdir(filename): <TAB>  <TAB>  <TAB> filename += os.path.sep <MASK> filename = username + filename[len(user_dir) :] <TAB>  <TAB> matches.add(filename) <TAB> return matches","if cs . word . startswith ( ""~"" ) :",169
1624,"def eventFilter(self, obj, event): <TAB> if event.type() == QEvent.MouseButtonPress: <TAB>  <TAB> button = event.button() <MASK> self._app.browser.back() <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> elif button == Qt.ForwardButton: <TAB>  <TAB>  <TAB> self._app.browser.forward() <TAB>  <TAB>  <TAB> return True <TAB> return False",if button == Qt . BackButton :,96
1625,"def reset_parameters(self): <TAB> for m in self.modules(): <TAB>  <TAB> if isinstance(m, nn.Embedding): <TAB>  <TAB>  <TAB> continue <MASK> nn.init.constant_(m.weight, 0.1) <TAB>  <TAB>  <TAB> nn.init.constant_(m.bias, 0) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for p in m.parameters(): <TAB>  <TAB>  <TAB>  <TAB> nn.init.normal_(p, 0, 0.1)","elif isinstance ( m , nn . LayerNorm ) :",115
1626,"def get_scalding_core(self): <TAB> lib_dir = os.path.join(self.scalding_home, ""lib"") <TAB> for j in os.listdir(lib_dir): <MASK> p = os.path.join(lib_dir, j) <TAB>  <TAB>  <TAB> logger.debug(""Found scalding-core: %s"", p) <TAB>  <TAB>  <TAB> return p <TAB> raise luigi.contrib.hadoop.HadoopJobError(""Could not find scalding-core."")","if j . startswith ( ""scalding-core-"" ) :",126
1627,"def save(self): <TAB> """"""Saves a new set of golden output frames to disk."""""" <TAB> for pixels, (relative_to_assets, filename) in zip( <TAB>  <TAB> self.iter_render(), self._iter_paths() <TAB> ): <TAB>  <TAB> full_directory_path = os.path.join(self._ASSETS_DIR, relative_to_assets) <MASK> os.makedirs(full_directory_path) <TAB>  <TAB> path = os.path.join(full_directory_path, filename) <TAB>  <TAB> _save_pixels(pixels, path)",if not os . path . exists ( full_directory_path ) :,147
1628,"def _fix_var_naming(operators, names, mod=""input""): <TAB> new_names = [] <TAB> map = {} <TAB> for op in operators: <MASK> iter = op.inputs <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> iter = op.outputs <TAB>  <TAB> for i in iter: <TAB>  <TAB>  <TAB> for name in names: <TAB>  <TAB>  <TAB>  <TAB> if i.raw_name == name and name not in map: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> map[i.raw_name] = i.full_name <TAB>  <TAB> if len(map) == len(names): <TAB>  <TAB>  <TAB> break <TAB> for name in names: <TAB>  <TAB> new_names.append(map[name]) <TAB> return new_names","if mod == ""input"" :",168
1629,"def Tokenize(s): <TAB> # type: (str) -> Iterator[Token] <TAB> for item in TOKEN_RE.findall(s): <TAB>  <TAB> # The type checker can't know the true type of item! <TAB>  <TAB> item = cast(TupleStr4, item) <TAB>  <TAB> if item[0]: <TAB>  <TAB>  <TAB> typ = ""number"" <TAB>  <TAB>  <TAB> val = item[0] <MASK> typ = ""name"" <TAB>  <TAB>  <TAB> val = item[1] <TAB>  <TAB> elif item[2]: <TAB>  <TAB>  <TAB> typ = item[2] <TAB>  <TAB>  <TAB> val = item[2] <TAB>  <TAB> elif item[3]: <TAB>  <TAB>  <TAB> typ = item[3] <TAB>  <TAB>  <TAB> val = item[3] <TAB>  <TAB> yield Token(typ, val)",elif item [ 1 ] :,181
1630,"def init_errorhandler(): <TAB> # http error handling <TAB> for ex in default_exceptions: <TAB>  <TAB> if ex < 500: <TAB>  <TAB>  <TAB> app.register_error_handler(ex, error_http) <MASK> app.register_error_handler(ex, internal_error) <TAB> if services.ldap: <TAB>  <TAB> # Only way of catching the LDAPException upon logging in with LDAP server down <TAB>  <TAB> @app.errorhandler(services.ldap.LDAPException) <TAB>  <TAB> def handle_exception(e): <TAB>  <TAB>  <TAB> log.debug(""LDAP server not accessible while trying to login to opds feed"") <TAB>  <TAB>  <TAB> return error_http(FailedDependency())",elif ex == 500 :,168
1631,"def decode(self, ids): <TAB> ids = pad_decr(ids) <TAB> tokens = [] <TAB> for int_id in ids: <MASK> tokens.append(self._vocab_list[int_id]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tokens.append(self._oov_token) <TAB> return self._decode_token_separator.join(tokens)",if int_id < len ( self . _vocab_list ) :,101
1632,"def remove_contest(contest_id): <TAB> with SessionGen() as session: <TAB>  <TAB> contest = session.query(Contest).filter(Contest.id == contest_id).first() <TAB>  <TAB> if not contest: <TAB>  <TAB>  <TAB> print(""No contest with id %s found."" % contest_id) <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> contest_name = contest.name <MASK> print(""Not removing contest `%s'."" % contest_name) <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> session.delete(contest) <TAB>  <TAB> session.commit() <TAB>  <TAB> print(""Contest `%s' removed."" % contest_name) <TAB> return True",if not ask ( contest ) :,169
1633,def get_hi_lineno(self): <TAB> lineno = Node.get_hi_lineno(self) <TAB> if self.expr1 is None: <TAB>  <TAB> pass <TAB> else: <TAB>  <TAB> lineno = self.expr1.get_hi_lineno() <TAB>  <TAB> if self.expr2 is None: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lineno = self.expr2.get_hi_lineno() <MASK> pass <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> lineno = self.expr3.get_hi_lineno() <TAB> return lineno,if self . expr3 is None :,142
1634,"def _send_internal(self, bytes_): <TAB> # buffering <TAB> if self.pendings: <TAB>  <TAB> self.pendings += bytes_ <TAB>  <TAB> bytes_ = self.pendings <TAB> try: <TAB>  <TAB> # reconnect if possible <TAB>  <TAB> self._reconnect() <TAB>  <TAB> # send message <TAB>  <TAB> self.socket.sendall(bytes_) <TAB>  <TAB> # send finished <TAB>  <TAB> self.pendings = None <TAB> except Exception:  # pylint: disable=broad-except <TAB>  <TAB> # close socket <TAB>  <TAB> self._close() <TAB>  <TAB> # clear buffer if it exceeds max bufer size <MASK> # TODO: add callback handler here <TAB>  <TAB>  <TAB> self.pendings = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.pendings = bytes_",if self . pendings and ( len ( self . pendings ) > self . bufmax ) :,194
1635,"def _unpack(self, fmt, byt): <TAB> d = unpack(self._header[""byteorder""] + fmt, byt)[0] <TAB> if fmt[-1] in self.MISSING_VALUES: <TAB>  <TAB> nmin, nmax = self.MISSING_VALUES[fmt[-1]] <TAB>  <TAB> if d < nmin or d > nmax: <MASK> return StataMissingValue(nmax, d) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return None <TAB> return d",if self . _missing_values :,121
1636,"def tuple_iter(self): <TAB> for x in range( <TAB>  <TAB> self.center.x - self.max_radius, self.center.x + self.max_radius + 1 <TAB> ): <TAB>  <TAB> for y in range( <TAB>  <TAB>  <TAB> self.center.y - self.max_radius, self.center.y + self.max_radius + 1 <TAB>  <TAB> ): <MASK> yield (x, y)","if self . min_radius <= self . center . distance ( ( x , y ) ) <= self . max_radius :",126
1637,"def _parse_gene(element): <TAB> for genename_element in element: <MASK> ann_key = ""gene_%s_%s"" % ( <TAB>  <TAB>  <TAB>  <TAB> genename_element.tag.replace(NS, """"), <TAB>  <TAB>  <TAB>  <TAB> genename_element.attrib[""type""], <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> if genename_element.attrib[""type""] == ""primary"": <TAB>  <TAB>  <TAB>  <TAB> self.ParsedSeqRecord.annotations[ann_key] = genename_element.text <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> append_to_annotations(ann_key, genename_element.text)","if ""type"" in genename_element . attrib :",157
1638,"def invalidateDependentSlices(self, iFirstCurve): <TAB> # only user defined curve can have slice dependency relationships <TAB> if self.isSystemCurveIndex(iFirstCurve): <TAB>  <TAB> return <TAB> nCurves = self.getNCurves() <TAB> for i in range(iFirstCurve, nCurves): <TAB>  <TAB> c = self.getSystemCurve(i) <TAB>  <TAB> if isinstance(c.getSymbol().getSymbolType(), SymbolType.PieSliceSymbolType): <TAB>  <TAB>  <TAB> c.invalidate() <MASK> # if first curve isn't a slice, <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> # there are no dependent slices",elif i == iFirstCurve :,154
1639,"def gen_app_versions(self): <TAB> for app_config in apps.get_app_configs(): <TAB>  <TAB> name = app_config.verbose_name <TAB>  <TAB> app = app_config.module <TAB>  <TAB> version = self.get_app_version(app) <MASK> yield app.__name__, name, version",if version :,80
1640,"def verify_relative_valid_path(root, path): <TAB> if len(path) < 1: <TAB>  <TAB> raise PackagerError(""Empty chown path"") <TAB> checkpath = root <TAB> parts = path.split(os.sep) <TAB> for part in parts: <TAB>  <TAB> if part in (""."", ""..""): <TAB>  <TAB>  <TAB> raise PackagerError("". and .. is not allowed in chown path"") <TAB>  <TAB> checkpath = os.path.join(checkpath, part) <TAB>  <TAB> relpath = checkpath[len(root) + 1 :] <MASK> raise PackagerError(f""chown path {relpath} does not exist"") <TAB>  <TAB> if os.path.islink(checkpath): <TAB>  <TAB>  <TAB> raise PackagerError(f""chown path {relpath} is a soft link"")",if not os . path . exists ( checkpath ) :,191
1641,"def create_or_update_tag_at_scope(cmd, resource_id=None, tags=None, tag_name=None): <TAB> rcf = _resource_client_factory(cmd.cli_ctx) <TAB> if resource_id is not None: <MASK> raise IncorrectUsageError(""Tags could not be empty."") <TAB>  <TAB> Tags = cmd.get_models(""Tags"") <TAB>  <TAB> tag_obj = Tags(tags=tags) <TAB>  <TAB> return rcf.tags.create_or_update_at_scope(scope=resource_id, properties=tag_obj) <TAB> return rcf.tags.create_or_update(tag_name=tag_name)",if not tags :,160
1642,"def generate_auto_complete(self, base, iterable_var): <TAB> sugg = [] <TAB> for entry in iterable_var: <TAB>  <TAB> compare_entry = entry <TAB>  <TAB> compare_base = base <TAB>  <TAB> if self.settings.get(IGNORE_CASE_SETTING): <TAB>  <TAB>  <TAB> compare_entry = compare_entry.lower() <TAB>  <TAB>  <TAB> compare_base = compare_base.lower() <MASK> if entry not in sugg: <TAB>  <TAB>  <TAB>  <TAB> sugg.append(entry) <TAB> return sugg","if self . compare_entries ( compare_entry , compare_base ) :",137
1643,"def createFields(self): <TAB> yield String(self, ""dict_start"", 2) <TAB> while not self.eof: <TAB>  <TAB> addr = self.absolute_address + self.current_size <MASK> for field in parsePDFType(self): <TAB>  <TAB>  <TAB>  <TAB> yield field <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> yield String(self, ""dict_end"", 2)","if self . stream . readBytes ( addr , 2 ) != "">>"" :",107
1644,"def Visit_and_test(self, node):  # pylint: disable=invalid-name <TAB> # and_test ::= not_test ('and' not_test)* <TAB> for child in node.children: <TAB>  <TAB> self.Visit(child) <MASK> _AppendTokenSubtype(child, format_token.Subtype.BINARY_OPERATOR)","if isinstance ( child , pytree . Leaf ) and child . value == ""and"" :",99
1645,"def getfiledata(directories): <TAB> columns = None <TAB> data = [] <TAB> counter = 1 <TAB> for directory in directories: <TAB>  <TAB> for f in os.listdir(directory): <TAB>  <TAB>  <TAB> if not os.path.isfile(os.path.join(directory, f)): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> counter += 1 <TAB>  <TAB>  <TAB> st = os.stat(os.path.join(directory, f)) <MASK> columns = [""rowid"", ""name"", ""directory""] + [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> x for x in dir(st) if x.startswith(""st_"") <TAB>  <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB> data.append([counter, f, directory] + [getattr(st, x) for x in columns[3:]]) <TAB> return columns, data",if columns is None :,185
1646,"def copy_attributes(info_add, obj, name_fmt, attributes, formatter=None): <TAB> for attr in attributes: <TAB>  <TAB> value = getattr(obj, attr, None) <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> name = name_fmt % attr <MASK> value = formatter(attr, value) <TAB>  <TAB> info_add(name, value)",if formatter is not None :,97
1647,"def main(args): <TAB> ap = argparse.ArgumentParser() <TAB> ap.add_argument(""job_ids"", nargs=""+"", type=int, help=""ID of a running job"") <TAB> ns = ap.parse_args(args) <TAB> _stash = globals()[""_stash""] <TAB> """""":type : StaSh"""""" <TAB> for job_id in ns.job_ids: <MASK> print(""killing job {} ..."".format(job_id)) <TAB>  <TAB>  <TAB> worker = _stash.runtime.worker_registry.get_worker(job_id) <TAB>  <TAB>  <TAB> worker.kill() <TAB>  <TAB>  <TAB> time.sleep(1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""error: no such job with id: {}"".format(job_id)) <TAB>  <TAB>  <TAB> break",if job_id in _stash . runtime . worker_registry :,195
1648,"def _check_choice(self): <TAB> if self.type == ""choice"": <TAB>  <TAB> if self.choices is None: <TAB>  <TAB>  <TAB> raise OptionError(""must supply a list of choices for type 'choice'"", self) <MASK> raise OptionError( <TAB>  <TAB>  <TAB>  <TAB> ""choices must be a list of strings ('%s' supplied)"" <TAB>  <TAB>  <TAB>  <TAB> % str(type(self.choices)).split(""'"")[1], <TAB>  <TAB>  <TAB>  <TAB> self, <TAB>  <TAB>  <TAB> ) <TAB> elif self.choices is not None: <TAB>  <TAB> raise OptionError(""must not supply choices for type %r"" % self.type, self)","elif type ( self . choices ) not in ( types . TupleType , types . ListType ) :",162
1649,"def add_file(pipe, srcpath, tgtpath): <TAB> with open(srcpath, ""rb"") as handle: <MASK> write(pipe, enc(""M 100755 inline %s\n"" % tgtpath)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> write(pipe, enc(""M 100644 inline %s\n"" % tgtpath)) <TAB>  <TAB> data = handle.read() <TAB>  <TAB> write(pipe, enc(""data %d\n"" % len(data))) <TAB>  <TAB> write(pipe, enc(data)) <TAB>  <TAB> write(pipe, enc(""\n""))","if os . access ( srcpath , os . X_OK ) :",148
1650,"def cdf(self, x): <TAB> if x == numpy.inf: <TAB>  <TAB> return 1.0 <TAB> else:  # Inefficient sum. <MASK> raise RuntimeError(""Invalid value."") <TAB>  <TAB> c = 0.0 <TAB>  <TAB> for i in xrange(x + 1): <TAB>  <TAB>  <TAB> c += self.probability(i) <TAB>  <TAB> return c",if x != int ( x ) :,91
1651,"def convert_to_strings(self, out, seq_len): <TAB> results = [] <TAB> for b, batch in enumerate(out): <TAB>  <TAB> utterances = [] <TAB>  <TAB> for p, utt in enumerate(batch): <TAB>  <TAB>  <TAB> size = seq_len[b][p] <MASK> transcript = """".join( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> map(lambda x: self.int_to_char[x.item()], utt[0:size]) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> transcript = """" <TAB>  <TAB>  <TAB> utterances.append(transcript) <TAB>  <TAB> results.append(utterances) <TAB> return results",if size > 0 :,158
1652,"def get_date_range(self): <TAB> if not hasattr(self, ""start"") or not hasattr(self, ""end""): <TAB>  <TAB> args = (self.today.year, self.today.month) <TAB>  <TAB> form = self.get_form() <MASK> args = (int(form.cleaned_data[""year""]), int(form.cleaned_data[""month""])) <TAB>  <TAB> self.start = self.get_start(*args) <TAB>  <TAB> self.end = self.get_end(*args) <TAB> return self.start, self.end",if form . is_valid ( ) :,136
1653,"def save_stats(self): <TAB> LOGGER.info(""Saving task-level statistics."") <TAB> has_headers = os.path.isfile(paths.TABLE_COUNT_PATH) <TAB> with open(paths.TABLE_COUNT_PATH, ""a"") as csvfile: <TAB>  <TAB> headers = [""start_time"", ""database_name"", ""number_tables""] <TAB>  <TAB> writer = csv.DictWriter( <TAB>  <TAB>  <TAB> csvfile, delimiter="","", lineterminator=""\n"", fieldnames=headers <TAB>  <TAB> ) <MASK> writer.writeheader() <TAB>  <TAB> writer.writerow( <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB> ""start_time"": self.start_time, <TAB>  <TAB>  <TAB>  <TAB> ""database_name"": self.database_name, <TAB>  <TAB>  <TAB>  <TAB> ""number_tables"": self.count, <TAB>  <TAB>  <TAB> } <TAB>  <TAB> )",if not has_headers :,199
1654,"def _CheckCanaryCommand(self): <MASK> # fast path <TAB>  <TAB> return <TAB> with self._lock: <TAB>  <TAB> if OpenStackVirtualMachine.command_works: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> logging.info(""Testing OpenStack CLI command is installed and working"") <TAB>  <TAB> cmd = os_utils.OpenStackCLICommand(self, ""image"", ""list"") <TAB>  <TAB> stdout, stderr, _ = cmd.Issue() <TAB>  <TAB> if stderr: <TAB>  <TAB>  <TAB> raise errors.Config.InvalidValue( <TAB>  <TAB>  <TAB>  <TAB> ""OpenStack CLI test command failed. Please make sure the OpenStack "" <TAB>  <TAB>  <TAB>  <TAB> ""CLI client is installed and properly configured"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> OpenStackVirtualMachine.command_works = True",if OpenStackVirtualMachine . command_works :,176
1655,"def test_windows_hidden(self): <TAB> if not sys.platform == ""win32"": <TAB>  <TAB> self.skipTest(""sys.platform is not windows"") <TAB>  <TAB> return <TAB> # FILE_ATTRIBUTE_HIDDEN = 2 (0x2) from GetFileAttributes documentation. <TAB> hidden_mask = 2 <TAB> with tempfile.NamedTemporaryFile() as f: <TAB>  <TAB> # Hide the file using <TAB>  <TAB> success = ctypes.windll.kernel32.SetFileAttributesW(f.name, hidden_mask) <MASK> self.skipTest(""unable to set file attributes"") <TAB>  <TAB> self.assertTrue(hidden.is_hidden(f.name))",if not success :,147
1656,"def recv_some(p, t=0.1, e=1, tr=5, stderr=0): <TAB> if tr < 1: <TAB>  <TAB> tr = 1 <TAB> x = time.time() + t <TAB> y = [] <TAB> r = """" <TAB> if stderr: <TAB>  <TAB> pr = p.recv_err <TAB> else: <TAB>  <TAB> pr = p.recv <TAB> while time.time() < x or r: <TAB>  <TAB> r = pr() <TAB>  <TAB> if r is None: <TAB>  <TAB>  <TAB> break <MASK> y.append(r) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> time.sleep(max((x - time.time()) / tr, 0)) <TAB> return b"""".join(y)",elif r :,169
1657,"def _is_xml(accepts): <TAB> if accepts.startswith(b""application/""): <TAB>  <TAB> has_xml = accepts.find(b""xml"") <MASK> semicolon = accepts.find(b"";"") <TAB>  <TAB>  <TAB> if semicolon < 0 or has_xml < semicolon: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if has_xml > 0 :,86
1658,"def times(self, value: int): <TAB> if value is None: <TAB>  <TAB> self._times = None <TAB> else: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> candidate = int(value) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> # pylint: disable:raise-missing-from <TAB>  <TAB>  <TAB> raise BarException(f""cannot set repeat times to: {value!r}"") <TAB>  <TAB> if candidate < 0: <TAB>  <TAB>  <TAB> raise BarException( <TAB>  <TAB>  <TAB>  <TAB> f""cannot set repeat times to a value less than zero: {value}"" <TAB>  <TAB>  <TAB> ) <MASK> raise BarException(""cannot set repeat times on a start Repeat"") <TAB>  <TAB> self._times = candidate","if self . direction == ""start"" :",163
1659,"def __call__(self, *args, **kwargs): <TAB> if not NET_INITTED: <TAB>  <TAB> return self.raw(*args, **kwargs) <TAB> for stack in traceback.walk_stack(None): <TAB>  <TAB> if ""self"" in stack[0].f_locals: <TAB>  <TAB>  <TAB> layer = stack[0].f_locals[""self""] <MASK> log.pytorch_layer_name = layer_names[layer] <TAB>  <TAB>  <TAB>  <TAB> print(layer_names[layer]) <TAB>  <TAB>  <TAB>  <TAB> break <TAB> out = self.obj(self.raw, *args, **kwargs) <TAB> # if isinstance(out,Variable): <TAB> # <TAB>  out=[out] <TAB> return out",if layer in layer_names :,173
1660,"def do_begin(self, byte): <TAB> if byte.isspace(): <TAB>  <TAB> return <TAB> if byte != ""<"": <MASK> self._leadingBodyData = byte <TAB>  <TAB>  <TAB> return ""bodydata"" <TAB>  <TAB> self._parseError(""First char of document [{!r}] wasn't <"".format(byte)) <TAB> return ""tagstart""",if self . beExtremelyLenient :,91
1661,"def pretty(self, n, comment=True): <TAB> if isinstance(n, (str, bytes, list, tuple, dict)): <TAB>  <TAB> r = repr(n) <MASK> # then it can be inside a comment! <TAB>  <TAB>  <TAB> r = r.replace(""*/"", r""\x2a/"") <TAB>  <TAB> return r <TAB> if not isinstance(n, six.integer_types): <TAB>  <TAB> return n <TAB> if isinstance(n, constants.Constant): <TAB>  <TAB> if comment: <TAB>  <TAB>  <TAB> return ""%s /* %s */"" % (n, self.pretty(int(n))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""%s (%s)"" % (n, self.pretty(int(n))) <TAB> elif abs(n) < 10: <TAB>  <TAB> return str(n) <TAB> else: <TAB>  <TAB> return hex(n)",if not comment :,194
1662,"def test_training_script_with_max_history_set(tmpdir): <TAB> train_dialogue_model( <TAB>  <TAB> DEFAULT_DOMAIN_PATH, <TAB>  <TAB> DEFAULT_STORIES_FILE, <TAB>  <TAB> tmpdir.strpath, <TAB>  <TAB> interpreter=RegexInterpreter(), <TAB>  <TAB> policy_config=""data/test_config/max_hist_config.yml"", <TAB>  <TAB> kwargs={}, <TAB> ) <TAB> agent = Agent.load(tmpdir.strpath) <TAB> for policy in agent.policy_ensemble.policies: <TAB>  <TAB> if hasattr(policy.featurizer, ""max_history""): <MASK> assert policy.featurizer.max_history == 2 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> assert policy.featurizer.max_history == 5",if type ( policy ) == FormPolicy :,191
1663,"def cli_uninstall_distro(): <TAB> distro_list = install_distro_list() <TAB> if distro_list is not None: <TAB>  <TAB> for index, _distro_dir in enumerate(distro_list): <TAB>  <TAB>  <TAB> log(str(index) + ""  --->>  "" + _distro_dir) <TAB>  <TAB> user_input = read_input_uninstall() <MASK> for index, _distro_dir in enumerate(distro_list): <TAB>  <TAB>  <TAB>  <TAB> if index == user_input: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> config.uninstall_distro_dir_name = _distro_dir <TAB>  <TAB>  <TAB>  <TAB>  <TAB> unin_distro() <TAB> else: <TAB>  <TAB> log(""No distro installed on "" + config.usb_disk)",if user_input is not False :,189
1664,"def set_random_avatar(user): <TAB> galleries = get_available_galleries(include_default=True) <TAB> if not galleries: <TAB>  <TAB> raise RuntimeError(""no avatar galleries are set"") <TAB> avatars_list = [] <TAB> for gallery in galleries: <MASK> avatars_list = gallery[""images""] <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> avatars_list += gallery[""images""] <TAB> random_avatar = random.choice(avatars_list) <TAB> store.store_new_avatar(user, Image.open(random_avatar.image))","if gallery [ ""name"" ] == DEFAULT_GALLERY :",169
1665,"def make_query(self, key, filters): <TAB> meta = self.get_meta(key) <TAB> q = {meta.facet_key: self.normalize_key(meta.path)} <TAB> if filters: <TAB>  <TAB> if filters.get(""has_fulltext"") == ""true"": <TAB>  <TAB>  <TAB> q[""has_fulltext""] = ""true"" <MASK> q[""publish_year""] = filters[""publish_year""] <TAB> return q","if filters . get ( ""publish_year"" ) :",113
1666,"def test_named_parameters_and_constraints(self): <TAB> likelihood = gpytorch.likelihoods.GaussianLikelihood() <TAB> model = ExactGPModel(None, None, likelihood) <TAB> for name, _param, constraint in model.named_parameters_and_constraints(): <TAB>  <TAB> if name == ""likelihood.noise_covar.raw_noise"": <TAB>  <TAB>  <TAB> self.assertIsInstance(constraint, gpytorch.constraints.GreaterThan) <MASK> self.assertIsNone(constraint) <TAB>  <TAB> elif name == ""covar_module.raw_outputscale"": <TAB>  <TAB>  <TAB> self.assertIsInstance(constraint, gpytorch.constraints.Positive) <TAB>  <TAB> elif name == ""covar_module.base_kernel.raw_lengthscale"": <TAB>  <TAB>  <TAB> self.assertIsInstance(constraint, gpytorch.constraints.Positive)","elif name == ""mean_module.constant"" :",192
1667,"def _test_pooling(input_shape, **kwargs): <TAB> _test_pooling_iteration(input_shape, **kwargs) <TAB> if is_gpu_available(): <MASK> input_shape = [input_shape[ii] for ii in (0, 3, 1, 2)] <TAB>  <TAB>  <TAB> kwargs[""data_format""] = ""NCHW"" <TAB>  <TAB>  <TAB> _test_pooling_iteration(input_shape, **kwargs)",if len ( input_shape ) == 4 :,111
1668,"def init(self): <TAB> r = self.get_redis() <TAB> if r: <TAB>  <TAB> key = ""pocsuite_target"" <TAB>  <TAB> info_msg = ""[PLUGIN] try fetch targets from redis..."" <TAB>  <TAB> logger.info(info_msg) <TAB>  <TAB> targets = r.get(key) <TAB>  <TAB> count = 0 <MASK> for target in targets: <TAB>  <TAB>  <TAB>  <TAB> if self.add_target(target): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> count += 1 <TAB>  <TAB> info_msg = ""[PLUGIN] get {0} target(s) from redis"".format(count) <TAB>  <TAB> logger.info(info_msg)",if targets :,151
1669,"def reload_json_api_settings(*args, **kwargs): <TAB> django_setting = kwargs[""setting""] <TAB> setting = django_setting.replace(JSON_API_SETTINGS_PREFIX, """") <TAB> value = kwargs[""value""] <TAB> if setting in DEFAULTS.keys(): <TAB>  <TAB> if value is not None: <TAB>  <TAB>  <TAB> setattr(json_api_settings, setting, value) <MASK> delattr(json_api_settings, setting)","elif hasattr ( json_api_settings , setting ) :",115
1670,"def update_metadata(self): <TAB> for attrname in dir(self): <TAB>  <TAB> if attrname.startswith(""__""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> attrvalue = getattr(self, attrname, None) <TAB>  <TAB> if attrvalue == 0: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if attrname == ""salt_version"": <TAB>  <TAB>  <TAB> attrname = ""version"" <TAB>  <TAB> if hasattr(self.metadata, ""set_{0}"".format(attrname)): <TAB>  <TAB>  <TAB> getattr(self.metadata, ""set_{0}"".format(attrname))(attrvalue) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> setattr(self.metadata, attrname, attrvalue) <TAB>  <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB>  <TAB> pass","elif hasattr ( self . metadata , attrname ) :",173
1671,"def test_02_looking_at_listdir_path_(name): <TAB> for dline in listdir.json(): <MASK> assert dline[""type""] in (""DIRECTORY"", ""FILE""), listdir.text <TAB>  <TAB>  <TAB> assert dline[""uid""] == 0, listdir.text <TAB>  <TAB>  <TAB> assert dline[""gid""] == 0, listdir.text <TAB>  <TAB>  <TAB> assert dline[""name""] == name, listdir.text <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> raise AssertionError(f""/{path}/{name} not found"")","if dline [ ""path"" ] == f""{path}/{name}"" :",136
1672,"def DeletePlugin(): <TAB> oid = request.form.get(""oid"", """") <TAB> if oid: <TAB>  <TAB> result = Mongo.coll[""Plugin""].find_one_and_delete( <TAB>  <TAB>  <TAB> {""_id"": ObjectId(oid)}, remove=True <TAB>  <TAB> ) <MASK> result[""filename""] = result[""filename""] + "".py"" <TAB>  <TAB> if os.path.exists(file_path + result[""filename""]): <TAB>  <TAB>  <TAB> os.remove(file_path + result[""filename""]) <TAB>  <TAB>  <TAB> return ""success"" <TAB> return ""fail""","if not result [ ""filename"" ] . find ( ""."" ) > - 1 :",144
1673,"def iterparent(self, node): <TAB> """"""Iterator wrapper to get allowed parent and child all at once."""""" <TAB> # We do not allow the marker inside a header as that <TAB> # would causes an enless loop of placing a new TOC <TAB> # inside previously generated TOC. <TAB> for child in node: <MASK> yield node, child <TAB>  <TAB>  <TAB> yield from self.iterparent(child)","if not self . header_rgx . match ( child . tag ) and child . tag not in [ ""pre"" , ""code"" ] :",120
1674,"def _get_matched_layout(command): <TAB> # don't use command.split_script here because a layout mismatch will likely <TAB> # result in a non-splitable script as per shlex <TAB> cmd = command.script.split("" "") <TAB> for source_layout in source_layouts: <TAB>  <TAB> is_all_match = True <TAB>  <TAB> for cmd_part in cmd: <TAB>  <TAB>  <TAB> if not all([ch in source_layout or ch in ""-_"" for ch in cmd_part]): <TAB>  <TAB>  <TAB>  <TAB> is_all_match = False <TAB>  <TAB>  <TAB>  <TAB> break <MASK> return source_layout",if is_all_match :,147
1675,"def _update_tileable_and_chunk_shape(self, tileable_graph, chunk_result, failed_ops): <TAB> for n in tileable_graph: <TAB>  <TAB> if n.op in failed_ops: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> tiled_n = get_tiled(n) <TAB>  <TAB> if has_unknown_shape(tiled_n): <MASK> # some of the chunks has been fused <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> new_nsplits = self.get_tileable_nsplits(n, chunk_result=chunk_result) <TAB>  <TAB>  <TAB> for node in (n, tiled_n): <TAB>  <TAB>  <TAB>  <TAB> node._update_shape(tuple(sum(nsplit) for nsplit in new_nsplits)) <TAB>  <TAB>  <TAB> tiled_n._nsplits = new_nsplits",if any ( c . key not in chunk_result for c in tiled_n . chunks ) :,200
1676,"def _get_items(self, name, target=1): <TAB> all_items = self.get_items(name) <TAB> items = [o for o in all_items if not o.disabled] <TAB> if len(items) < target: <TAB>  <TAB> if len(all_items) < target: <TAB>  <TAB>  <TAB> raise ItemNotFoundError(""insufficient items with name %r"" % name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise AttributeError(""insufficient non-disabled items with name %s"" % name) <TAB> on = [] <TAB> off = [] <TAB> for o in items: <MASK> on.append(o) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> off.append(o) <TAB> return on, off",if o . selected :,169
1677,def parse_flow_sequence_entry_mapping_value(self): <TAB> if self.check_token(ValueToken): <TAB>  <TAB> token = self.get_token() <MASK> self.states.append(self.parse_flow_sequence_entry_mapping_end) <TAB>  <TAB>  <TAB> return self.parse_flow_node() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.state = self.parse_flow_sequence_entry_mapping_end <TAB>  <TAB>  <TAB> return self.process_empty_scalar(token.end_mark) <TAB> else: <TAB>  <TAB> self.state = self.parse_flow_sequence_entry_mapping_end <TAB>  <TAB> token = self.peek_token() <TAB>  <TAB> return self.process_empty_scalar(token.start_mark),"if not self . check_token ( FlowEntryToken , FlowSequenceEndToken ) :",194
1678,"def serialize_config(self, session, key, tid, language): <TAB> cache_key = gen_cache_key(key, tid, language) <TAB> cache_obj = None <TAB> if cache_key not in self.cache: <MASK> cache_obj = db_admin_serialize_node(session, tid, language) <TAB>  <TAB> elif key == ""notification"": <TAB>  <TAB>  <TAB> cache_obj = db_get_notification(session, tid, language) <TAB>  <TAB> self.cache[cache_key] = cache_obj <TAB> return self.cache[cache_key]","if key == ""node"" :",139
1679,"def get_lldp_neighbors(self): <TAB> commands = [""show lldp neighbors""] <TAB> output = self.device.run_commands(commands)[0][""lldpNeighbors""] <TAB> lldp = {} <TAB> for n in output: <MASK> lldp[n[""port""]] = [] <TAB>  <TAB> lldp[n[""port""]].append( <TAB>  <TAB>  <TAB> {""hostname"": n[""neighborDevice""], ""port"": n[""neighborPort""]} <TAB>  <TAB> ) <TAB> return lldp","if n [ ""port"" ] not in lldp . keys ( ) :",126
1680,"def handle(self): <TAB> from poetry.utils.env import EnvManager <TAB> manager = EnvManager(self.poetry) <TAB> current_env = manager.get() <TAB> for venv in manager.list(): <TAB>  <TAB> name = venv.path.name <TAB>  <TAB> if self.option(""full-path""): <TAB>  <TAB>  <TAB> name = str(venv.path) <MASK> self.line(""<info>{} (Activated)</info>"".format(name)) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> self.line(name)",if venv == current_env :,129
1681,"def resolve_env_secrets(config, environ): <TAB> """"""Create copy that recursively replaces {""$env"": ""NAME""} with values from environ"""""" <TAB> if isinstance(config, dict): <TAB>  <TAB> if list(config.keys()) == [""$env""]: <TAB>  <TAB>  <TAB> return environ.get(list(config.values())[0]) <MASK> return open(list(config.values())[0]).read() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return { <TAB>  <TAB>  <TAB>  <TAB> key: resolve_env_secrets(value, environ) <TAB>  <TAB>  <TAB>  <TAB> for key, value in config.items() <TAB>  <TAB>  <TAB> } <TAB> elif isinstance(config, list): <TAB>  <TAB> return [resolve_env_secrets(value, environ) for value in config] <TAB> else: <TAB>  <TAB> return config","elif list ( config . keys ( ) ) == [ ""$file"" ] :",190
1682,"def _is_valid_16bit_as_path(cls, buf): <TAB> two_byte_as_size = struct.calcsize(""!H"") <TAB> while buf: <TAB>  <TAB> (type_, num_as) = struct.unpack_from( <TAB>  <TAB>  <TAB> cls._SEG_HDR_PACK_STR, six.binary_type(buf) <TAB>  <TAB> ) <TAB>  <TAB> if type_ is not cls._AS_SET and type_ is not cls._AS_SEQUENCE: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> buf = buf[struct.calcsize(cls._SEG_HDR_PACK_STR) :] <MASK> return False <TAB>  <TAB> buf = buf[num_as * two_byte_as_size :] <TAB> return True",if len ( buf ) < num_as * two_byte_as_size :,190
1683,"def reparentChildren(self, newParent): <TAB> if newParent.childNodes: <TAB>  <TAB> newParent.childNodes[-1]._element.tail += self._element.text <TAB> else: <MASK> newParent._element.text = """" <TAB>  <TAB> if self._element.text is not None: <TAB>  <TAB>  <TAB> newParent._element.text += self._element.text <TAB> self._element.text = """" <TAB> base.Node.reparentChildren(self, newParent)",if not newParent . _element . text :,121
1684,"def get_operation_ast(document_ast, operation_name=None): <TAB> operation = None <TAB> for definition in document_ast.definitions: <TAB>  <TAB> if isinstance(definition, ast.OperationDefinition): <TAB>  <TAB>  <TAB> if not operation_name: <TAB>  <TAB>  <TAB>  <TAB> # If no operation name is provided, only return an Operation if it is the only one present in the <TAB>  <TAB>  <TAB>  <TAB> # document. This means that if we've encountered a second operation as we were iterating over the <TAB>  <TAB>  <TAB>  <TAB> # definitions in the document, there are more than one Operation defined, and we should return None. <TAB>  <TAB>  <TAB>  <TAB> if operation: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB>  <TAB>  <TAB> operation = definition <MASK> return definition <TAB> return operation",elif definition . name and definition . name . value == operation_name :,186
1685,"def reprSmart(vw, item): <TAB> ptype = type(item) <TAB> if ptype is int: <MASK> return str(item) <TAB>  <TAB> elif vw.isValidPointer(item): <TAB>  <TAB>  <TAB> return vw.reprPointer(item) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return hex(item) <TAB> elif ptype in (list, tuple): <TAB>  <TAB> return reprComplex(vw, item)  # recurse <TAB> elif ptype is dict: <TAB>  <TAB> return ""{%s}"" % "","".join( <TAB>  <TAB>  <TAB> [""%s:%s"" % (reprSmart(vw, k), reprSmart(vw, v)) for k, v in item.items()] <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> return repr(item)",if - 1024 < item < 1024 :,183
1686,"def cleanDataCmd(cmd): <TAB> newcmd = ""AbracadabrA ** <?php "" <TAB> if cmd[:6] != ""php://"": <MASK> cmds = cmd.split(""&"") <TAB>  <TAB>  <TAB> for c in cmds: <TAB>  <TAB>  <TAB>  <TAB> if len(c) > 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> newcmd += ""system('%s');"" % c <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> b64cmd = base64.b64encode(cmd) <TAB>  <TAB>  <TAB> newcmd += ""system(base64_decode('%s'));"" % b64cmd <TAB> else: <TAB>  <TAB> newcmd += cmd[6:] <TAB> newcmd += ""?> **"" <TAB> return newcmd",if reverseConn not in cmd :,170
1687,"def render_tasks(self) -> List: <TAB> results = [] <TAB> for task in self.tasks.values(): <TAB>  <TAB> job_entry = self.jobs.get(task.job_id) <MASK> if not self.should_render_job(job_entry): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> files = self.get_file_counts([task]) <TAB>  <TAB> entry = ( <TAB>  <TAB>  <TAB> task.job_id, <TAB>  <TAB>  <TAB> task.task_id, <TAB>  <TAB>  <TAB> task.state, <TAB>  <TAB>  <TAB> task.type.name, <TAB>  <TAB>  <TAB> task.target, <TAB>  <TAB>  <TAB> files, <TAB>  <TAB>  <TAB> task.pool, <TAB>  <TAB>  <TAB> task.end_time, <TAB>  <TAB> ) <TAB>  <TAB> results.append(entry) <TAB> return results",if job_entry :,186
1688,"def __call__(self, environ, start_response): <TAB> for key in ""REQUEST_URL"", ""REQUEST_URI"", ""UNENCODED_URL"": <TAB>  <TAB> if key not in environ: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> request_uri = unquote(environ[key]) <TAB>  <TAB> script_name = unquote(environ.get(""SCRIPT_NAME"", """")) <MASK> environ[""PATH_INFO""] = request_uri[len(script_name) :].split(""?"", 1)[0] <TAB>  <TAB>  <TAB> break <TAB> return self.app(environ, start_response)",if request_uri . startswith ( script_name ) :,140
1689,"def _add_role_information(self, function_dict, role_id): <TAB> # Make it easier to build rules based on policies attached to execution roles <TAB> function_dict[""role_arn""] = role_id <TAB> role_name = role_id.split(""/"")[-1] <TAB> function_dict[ <TAB>  <TAB> ""execution_role"" <TAB> ] = await self.facade.awslambda.get_role_with_managed_policies(role_name) <TAB> if function_dict.get(""execution_role""): <TAB>  <TAB> statements = [] <TAB>  <TAB> for policy in function_dict[""execution_role""].get(""policies""): <MASK> statements += policy[""Document""][""Statement""] <TAB>  <TAB> function_dict[""execution_role""][""policy_statements""] = statements","if ""Document"" in policy and ""Statement"" in policy [ ""Document"" ] :",196
1690,"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 8: <TAB>  <TAB>  <TAB> self.set_ts(d.getVarInt64()) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,90
1691,"def format_counts(results, json_output=False, human_readable=False): <TAB> if json_output: <TAB>  <TAB> for result in results: <TAB>  <TAB>  <TAB> yield json.dumps(result) <TAB> else: <TAB>  <TAB> for result in results: <TAB>  <TAB>  <TAB> space_consumed = result.get(""spaceConsumed"") <MASK> space_consumed = _sizeof_fmt(int(result.get(""spaceConsumed""))) <TAB>  <TAB>  <TAB> yield ""%12s %12s %18s %s"" % ( <TAB>  <TAB>  <TAB>  <TAB> result.get(""directoryCount""), <TAB>  <TAB>  <TAB>  <TAB> result.get(""fileCount""), <TAB>  <TAB>  <TAB>  <TAB> space_consumed, <TAB>  <TAB>  <TAB>  <TAB> result.get(""path""), <TAB>  <TAB>  <TAB> )",if human_readable :,175
1692,"def parse_edges(self, pcb): <TAB> edges = [] <TAB> drawings = list(pcb.GetDrawings()) <TAB> bbox = None <TAB> for m in pcb.GetModules(): <TAB>  <TAB> for g in m.GraphicalItems(): <TAB>  <TAB>  <TAB> drawings.append(g) <TAB> for d in drawings: <TAB>  <TAB> if d.GetLayer() == pcbnew.Edge_Cuts: <TAB>  <TAB>  <TAB> parsed_drawing = self.parse_drawing(d) <TAB>  <TAB>  <TAB> if parsed_drawing: <TAB>  <TAB>  <TAB>  <TAB> edges.append(parsed_drawing) <MASK> bbox = d.GetBoundingBox() <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> bbox.Merge(d.GetBoundingBox()) <TAB> if bbox: <TAB>  <TAB> bbox.Normalize() <TAB> return edges, bbox",if bbox is None :,197
1693,"def __getitem__(self, k) -> ""SimMemView"": <TAB> if isinstance(k, slice): <TAB>  <TAB> if k.step is not None: <TAB>  <TAB>  <TAB> raise ValueError(""Slices with strides are not supported"") <MASK> raise ValueError(""Must specify start index"") <TAB>  <TAB> elif k.stop is not None: <TAB>  <TAB>  <TAB> raise ValueError(""Slices with stop index are not supported"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> addr = k.start <TAB> elif self._type is not None and self._type._can_refine_int: <TAB>  <TAB> return self._type._refine(self, k) <TAB> else: <TAB>  <TAB> addr = k <TAB> return self._deeper(addr=addr)",elif k . start is None :,169
1694,"def _parse(self, stream, context): <TAB> obj = [] <TAB> try: <TAB>  <TAB> if self.subcon.conflags & self.FLAG_COPY_CONTEXT: <TAB>  <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB>  <TAB> subobj = self.subcon._parse(stream, context.__copy__()) <TAB>  <TAB>  <TAB>  <TAB> obj.append(subobj) <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB>  <TAB> subobj = self.subcon._parse(stream, context) <TAB>  <TAB>  <TAB>  <TAB> obj.append(subobj) <TAB>  <TAB>  <TAB>  <TAB> if self.predicate(subobj, context): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB> except ConstructError as ex: <TAB>  <TAB> raise ArrayError(""missing terminator"", ex) <TAB> return obj","if self . predicate ( subobj , context ) :",191
1695,"def before_run(self, run_context): <TAB> if ""featurizer"" in self.model_portion and ( <TAB>  <TAB> self.need_to_refresh or self.refresh_base_model <TAB> ): <MASK> self.refresh_base_model = True <TAB>  <TAB> self.init_fn( <TAB>  <TAB>  <TAB> None, run_context.session, self.model_portion, self.refresh_base_model <TAB>  <TAB> ) <TAB>  <TAB> self.need_to_refresh = False <TAB>  <TAB> self.refresh_base_model = False","if self . model_portion == ""whole_featurizer"" :",141
1696,"def run(self): <TAB> while True: <TAB>  <TAB> task = self.requestQueue.get() <TAB>  <TAB> if task is None: <TAB>  <TAB>  <TAB> # The ""None"" value is used as a sentinel by <TAB>  <TAB>  <TAB> # ThreadPool.cleanup().  This indicates that there <TAB>  <TAB>  <TAB> # are no more tasks, so we should quit. <TAB>  <TAB>  <TAB> break <TAB>  <TAB> try: <MASK> raise SCons.Errors.BuildError(task.targets[0], errstr=interrupt_msg) <TAB>  <TAB>  <TAB> task.execute() <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> task.exception_set() <TAB>  <TAB>  <TAB> ok = False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ok = True <TAB>  <TAB> self.resultsQueue.put((task, ok))",if self . interrupted ( ) :,178
1697,"def get_overdue_evergreen_documents(*, db_session) -> List[Optional[Document]]: <TAB> """"""Returns all documents that have need had a recent evergreen notification."""""" <TAB> documents = ( <TAB>  <TAB> db_session.query(Document).filter(Document.evergreen == True) <TAB> ).all()  # noqa <TAB> overdue_documents = [] <TAB> now = datetime.utcnow() <TAB> for d in documents: <TAB>  <TAB> next_reminder = d.evergreen_last_reminder_at + timedelta( <TAB>  <TAB>  <TAB> days=d.evergreen_reminder_interval <TAB>  <TAB> ) <MASK> overdue_documents.append(d) <TAB> return overdue_documents",if now > next_reminder :,163
1698,"def create_local_app_folder(local_app_path): <TAB> if exists(local_app_path): <TAB>  <TAB> raise ValueError(""There is already a '%s' folder! Aborting!"" % local_app_path) <TAB> for folder in subfolders(local_app_path): <TAB>  <TAB> if not exists(folder): <TAB>  <TAB>  <TAB> os.mkdir(folder) <TAB>  <TAB>  <TAB> init_path = join(folder, ""__init__.py"") <MASK> create_file(init_path)",if not exists ( init_path ) :,126
1699,"def generate(): <TAB> for leaf in u.leaves: <MASK> val = leaf.get_int_value() <TAB>  <TAB>  <TAB> if val in (0, 1): <TAB>  <TAB>  <TAB>  <TAB> yield val <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise _NoBoolVector <TAB>  <TAB> elif isinstance(leaf, Symbol): <TAB>  <TAB>  <TAB> if leaf == SymbolTrue: <TAB>  <TAB>  <TAB>  <TAB> yield 1 <TAB>  <TAB>  <TAB> elif leaf == SymbolFalse: <TAB>  <TAB>  <TAB>  <TAB> yield 0 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise _NoBoolVector <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise _NoBoolVector","if isinstance ( leaf , Integer ) :",138
1700,"def replace(self, old, new): <TAB> v_m = self.var_map <TAB> size = v_m[self.size] <TAB> if not (size.is_const() or size.is_ident()): <TAB>  <TAB> size.replace(old, new) <TAB> else: <MASK> v_m[new.value()] = new <TAB>  <TAB>  <TAB> self.size = new.value() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> v_m[old] = new",if new . is_ident ( ) :,119
1701,"def method_for_doctype(doctype): <TAB> method = ""xhtml"" <TAB> if doctype: <TAB>  <TAB> if doctype.startswith(""html""): <TAB>  <TAB>  <TAB> method = ""html"" <MASK> method = ""xhtml"" <TAB>  <TAB> elif doctype.startswith(""svg""): <TAB>  <TAB>  <TAB> method = ""xml"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> method = ""xhtml"" <TAB> return method","elif doctype . startswith ( ""xhtml"" ) :",101
1702,"def delete(self, trans, **kwd): <TAB> idnum = kwd[self.tagged_item_id] <TAB> item = self._get_item_from_id(trans, idnum, check_writable=True) <TAB> if item is not None: <TAB>  <TAB> ex_obj = self.get_item_extended_metadata_obj(trans, item) <MASK> self.unset_item_extended_metadata_obj(trans, item) <TAB>  <TAB>  <TAB> self.delete_extended_metadata(trans, ex_obj)",if ex_obj is not None :,131
1703,"def check_testv(self, testv): <TAB> test_good = True <TAB> f = open(self.home, ""rb+"") <TAB> for (offset, length, operator, specimen) in testv: <TAB>  <TAB> data = self._read_share_data(f, offset, length) <MASK> test_good = False <TAB>  <TAB>  <TAB> break <TAB> f.close() <TAB> return test_good","if not testv_compare ( data , operator , specimen ) :",113
1704,"def get_history_user(self, instance): <TAB> """"""Get the modifying user from instance or middleware."""""" <TAB> try: <TAB>  <TAB> return instance._history_user <TAB> except AttributeError: <TAB>  <TAB> request = None <TAB>  <TAB> try: <MASK> request = self.thread.request <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB> pass <TAB> return self.get_user(instance=instance, request=request)",if self . thread . request . user . is_authenticated :,110
1705,"def _check(self, name, size=None, *extra): <TAB> func = getattr(imageop, name) <TAB> for height in VALUES: <TAB>  <TAB> for width in VALUES: <TAB>  <TAB>  <TAB> strlen = abs(width * height) <MASK> strlen *= size <TAB>  <TAB>  <TAB> if strlen < MAX_LEN: <TAB>  <TAB>  <TAB>  <TAB> data = ""A"" * strlen <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> data = AAAAA <TAB>  <TAB>  <TAB> if size: <TAB>  <TAB>  <TAB>  <TAB> arguments = (data, size, width, height) + extra <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> arguments = (data, width, height) + extra <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> func(*arguments) <TAB>  <TAB>  <TAB> except (ValueError, imageop.error): <TAB>  <TAB>  <TAB>  <TAB> pass",if size :,188
1706,"def __setattr__(self, name, value): <TAB> if name == ""path"": <TAB>  <TAB> if value and value != """": <TAB>  <TAB>  <TAB> if value[0] != ""/"": <TAB>  <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> 'The page path should always start with a slash (""/"").' <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> elif name == ""load_time"": <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Page load time must be specified in integer milliseconds."" <TAB>  <TAB>  <TAB> ) <TAB> object.__setattr__(self, name, value)","if value and not isinstance ( value , int ) :",136
1707,"def __repr__(self): <TAB> if self._in_repr: <TAB>  <TAB> return ""<recursion>"" <TAB> try: <TAB>  <TAB> self._in_repr = True <TAB>  <TAB> if self.is_computed(): <TAB>  <TAB>  <TAB> status = ""computed, "" <MASK> if self.value() is self: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> status += ""= self"" <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> status += ""= "" + repr(self.value()) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> status += ""error = "" + repr(self.error()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> status = ""isn't computed"" <TAB>  <TAB> return ""%s (%s)"" % (type(self), status) <TAB> finally: <TAB>  <TAB> self._in_repr = False",if self . error ( ) is None :,189
1708,"def _exclude_node(self, name): <TAB> if ""exclude_nodes"" in self.node_filters: <MASK> self.loggit.info('Excluding node ""{0}"" due to node_filters'.format(name)) <TAB>  <TAB>  <TAB> return True <TAB> return False","if name in self . node_filters [ ""exclude_nodes"" ] :",79
1709,"def enumerate_projects(): <TAB> """"""List projects in _DEFAULT_APP_DIR."""""" <TAB> src_path = os.path.join(_DEFAULT_APP_DIR, ""src"") <TAB> projects = {} <TAB> for project in os.listdir(src_path): <TAB>  <TAB> projects[project] = [] <TAB>  <TAB> project_path = os.path.join(src_path, project) <TAB>  <TAB> for file in os.listdir(project_path): <MASK> projects[project].append(file[:-8]) <TAB> return projects","if file . endswith ( "".gwt.xml"" ) :",133
1710,"def zip_readline_read_test(self, f, compression): <TAB> self.make_test_archive(f, compression) <TAB> # Read the ZIP archive <TAB> with zipfile.ZipFile(f, ""r"") as zipfp, zipfp.open(TESTFN) as zipopen: <TAB>  <TAB> data = b"""" <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> read = zipopen.readline() <MASK> break <TAB>  <TAB>  <TAB> data += read <TAB>  <TAB>  <TAB> read = zipopen.read(100) <TAB>  <TAB>  <TAB> if not read: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> data += read <TAB> self.assertEqual(data, self.data)",if not read :,155
1711,"def f(view, s): <TAB> if mode == modes.NORMAL: <TAB>  <TAB> return sublime.Region(0) <TAB> elif mode == modes.VISUAL: <MASK> return sublime.Region(s.a + 1, 0) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return sublime.Region(s.a, 0) <TAB> elif mode == modes.INTERNAL_NORMAL: <TAB>  <TAB> return sublime.Region(view.full_line(s.b).b, 0) <TAB> elif mode == modes.VISUAL_LINE: <TAB>  <TAB> if s.a < s.b: <TAB>  <TAB>  <TAB> return sublime.Region(0, s.b) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return sublime.Region(0, s.a) <TAB> return s",if s . a < s . b :,192
1712,def response(self): <TAB> try: <TAB>  <TAB> response = requests.get(str(self)) <TAB>  <TAB> rjson = response.json() <MASK> raise Exception(response.text) <TAB>  <TAB> return rjson <TAB> except Exception as e: <TAB>  <TAB> raise ResponseFanartError(str(e)),"if not isinstance ( rjson , dict ) :",82
1713,"def __get_type(self, cexpr): <TAB> """"""Returns one of the following types: 'R' - read value, 'W' - write value, 'A' - function argument"""""" <TAB> child = cexpr <TAB> for p in reversed(self.parents): <TAB>  <TAB> assert p, ""Failed to get type at "" + helper.to_hex(self.__function_address) <TAB>  <TAB> if p.cexpr.op == idaapi.cot_call: <TAB>  <TAB>  <TAB> return ""Arg"" <TAB>  <TAB> if not p.is_expr(): <TAB>  <TAB>  <TAB> return ""R"" <TAB>  <TAB> if p.cexpr.op == idaapi.cot_asg: <MASK> return ""W"" <TAB>  <TAB>  <TAB> return ""R"" <TAB>  <TAB> child = p.cexpr",if p . cexpr . x == child :,192
1714,"def _extract_lemma(self, parse: Parse) -> str: <TAB> special_feats = [x for x in self.SPECIAL_FEATURES if x in parse.tag] <TAB> if len(special_feats) == 0: <TAB>  <TAB> return parse.normal_form <TAB> # here we process surnames and patronyms since PyMorphy lemmatizes them incorrectly <TAB> for other in parse.lexeme: <TAB>  <TAB> tag = other.tag <MASK> continue <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB> tag.case == ""nomn"" <TAB>  <TAB>  <TAB> and tag.gender == parse.tag.gender <TAB>  <TAB>  <TAB> and tag.number == ""sing"" <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> return other.word <TAB> return parse.normal_form",if any ( x not in tag for x in special_feats ) :,185
1715,"def evaluateWord(self, argument): <TAB> wildcard_count = argument[0].count(""*"") <TAB> if wildcard_count > 0: <TAB>  <TAB> if wildcard_count == 1 and argument[0].startswith(""*""): <TAB>  <TAB>  <TAB> return self.GetWordWildcard(argument[0][1:], method=""endswith"") <MASK> return self.GetWordWildcard(argument[0][:-1], method=""startswith"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _regex = argument[0].replace(""*"", "".+"") <TAB>  <TAB>  <TAB> matched = False <TAB>  <TAB>  <TAB> for w in self.words: <TAB>  <TAB>  <TAB>  <TAB> matched = bool(re.search(_regex, w)) <TAB>  <TAB>  <TAB>  <TAB> if matched: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> return matched <TAB> return self.GetWord(argument[0])","if wildcard_count == 1 and argument [ 0 ] . endswith ( ""*"" ) :",194
1716,def getAllEntries(self): <TAB> entries = [] <TAB> for bucket in self.buckets: <TAB>  <TAB> last = None <TAB>  <TAB> for entry in bucket.entries: <TAB>  <TAB>  <TAB> if last is not None: <TAB>  <TAB>  <TAB>  <TAB> last.size = entry.virtualOffset - last.virtualOffset <TAB>  <TAB>  <TAB> last = entry <TAB>  <TAB>  <TAB> entries.append(entry) <MASK> entries[-1].size = bucket.endOffset - entries[-1].virtualOffset <TAB> return entries,if len ( entries ) != 0 :,119
1717,def clean(self): <TAB> if self._ctx: <MASK> libcrypto.EVP_CIPHER_CTX_cleanup(self._ctx) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> libcrypto.EVP_CIPHER_CTX_reset(self._ctx) <TAB>  <TAB> libcrypto.EVP_CIPHER_CTX_free(self._ctx),"if hasattr ( libcrypto , ""EVP_CIPHER_CTX_cleanup"" ) :",96
1718,"def _addTab(self, name, label, idx=None): <TAB> label = getLanguageString(label) <TAB> tab = Tab(self, name, label) <TAB> tab.idx = self._makeTab(tab, idx) <TAB> if idx != None: <TAB>  <TAB> # Update index list when inserting tabs at arbitrary positions <TAB>  <TAB> newIdxList = {} <TAB>  <TAB> for tIdx, t in list(self._tabs_by_idx.items()): <MASK> t.idx += 1 <TAB>  <TAB>  <TAB> newIdxList[t.idx] = t <TAB>  <TAB> self._tabs_by_idx = newIdxList <TAB> self._tabs_by_idx[tab.idx] = tab <TAB> self._tabs_by_name[tab.name] = tab <TAB> return tab",if int ( tIdx ) >= idx :,189
1719,"def set(self, _key, _new_login=True): <TAB> with self.lock: <TAB>  <TAB> user = self.users.get(current_user.id, None) <MASK> self.users[current_user.id] = dict(session_count=1, key=_key) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if _new_login: <TAB>  <TAB>  <TAB>  <TAB> user[""session_count""] += 1 <TAB>  <TAB>  <TAB> user[""key""] = _key",if user is None :,116
1720,"def stop(self): <TAB> # Try to shut the connection down, but if we get any sort of <TAB> # errors, go ahead and ignore them.. as we're shutting down anyway <TAB> try: <TAB>  <TAB> self.rpcserver.stop() <MASK> self.backend_rpcserver.stop() <TAB>  <TAB> if self.cluster_rpcserver: <TAB>  <TAB>  <TAB> self.cluster_rpcserver.stop() <TAB> except Exception: <TAB>  <TAB> pass <TAB> if self.coordination: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> coordination.COORDINATOR.stop() <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> pass <TAB> super(Service, self).stop(graceful=True)",if self . backend_rpcserver :,171
1721,"def __genmenuOnlyAllocated(menu): <TAB> for submenu in menu.Submenus: <TAB>  <TAB> __genmenuOnlyAllocated(submenu) <TAB> if menu.OnlyUnallocated == True: <TAB>  <TAB> tmp[""cache""].addMenuEntries(menu.AppDirs) <TAB>  <TAB> menuentries = [] <TAB>  <TAB> for rule in menu.Rules: <TAB>  <TAB>  <TAB> menuentries = rule.do( <TAB>  <TAB>  <TAB>  <TAB> tmp[""cache""].getMenuEntries(menu.AppDirs), rule.Type, 2 <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> for menuentry in menuentries: <MASK> menuentry.Parents.append(menu) <TAB>  <TAB>  <TAB>  <TAB> #   menuentry.Add = False <TAB>  <TAB>  <TAB>  <TAB> #   menuentry.Allocated = True <TAB>  <TAB>  <TAB>  <TAB> menu.MenuEntries.append(menuentry)",if menuentry . Add == True :,198
1722,"def __init__(self, **options): <TAB> self.func_name_highlighting = get_bool_opt(options, ""func_name_highlighting"", True) <TAB> self.disabled_modules = get_list_opt(options, ""disabled_modules"", []) <TAB> self._functions = set() <TAB> if self.func_name_highlighting: <TAB>  <TAB> from pygments.lexers._lua_builtins import MODULES <TAB>  <TAB> for mod, func in iteritems(MODULES): <MASK> self._functions.update(func) <TAB> RegexLexer.__init__(self, **options)",if mod not in self . disabled_modules :,150
1723,"def recv_some(p, t=0.1, e=1, tr=5, stderr=0): <TAB> if tr < 1: <TAB>  <TAB> tr = 1 <TAB> x = time.time() + t <TAB> y = [] <TAB> r = """" <TAB> if stderr: <TAB>  <TAB> pr = p.recv_err <TAB> else: <TAB>  <TAB> pr = p.recv <TAB> while time.time() < x or r: <TAB>  <TAB> r = pr() <MASK> break <TAB>  <TAB> elif r: <TAB>  <TAB>  <TAB> y.append(r) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> time.sleep(max((x - time.time()) / tr, 0)) <TAB> return """".join(y)",if r is None :,168
1724,"def get_menu_items(node): <TAB> aList = [] <TAB> for child in node.children: <TAB>  <TAB> for tag in (""@menu"", ""@item""): <TAB>  <TAB>  <TAB> if child.h.startswith(tag): <TAB>  <TAB>  <TAB>  <TAB> name = child.h[len(tag) + 1 :].strip() <MASK> aList.append((""%s %s"" % (tag, name), get_menu_items(child), None)) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> b = g.splitLines("""".join(child.b)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> aList.append((tag, name, b[0] if b else """")) <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return aList","if tag == ""@menu"" :",173
1725,"def import_suffix_generator(a_block, datatype=False): <TAB> if datatype is False: <TAB>  <TAB> for name, suffix in iteritems(a_block.component_map(Suffix)): <MASK> yield name, suffix <TAB> else: <TAB>  <TAB> for name, suffix in iteritems(a_block.component_map(Suffix)): <TAB>  <TAB>  <TAB> if (suffix.import_enabled() is True) and ( <TAB>  <TAB>  <TAB>  <TAB> suffix.get_datatype() is datatype <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> yield name, suffix",if suffix . import_enabled ( ) is True :,136
1726,"def verify_relative_valid_path(root, path): <TAB> if len(path) < 1: <TAB>  <TAB> raise PackagerError(""Empty chown path"") <TAB> checkpath = root <TAB> parts = path.split(os.sep) <TAB> for part in parts: <TAB>  <TAB> if part in (""."", ""..""): <TAB>  <TAB>  <TAB> raise PackagerError("". and .. is not allowed in chown path"") <TAB>  <TAB> checkpath = os.path.join(checkpath, part) <TAB>  <TAB> relpath = checkpath[len(root) + 1 :] <TAB>  <TAB> if not os.path.exists(checkpath): <TAB>  <TAB>  <TAB> raise PackagerError(f""chown path {relpath} does not exist"") <MASK> raise PackagerError(f""chown path {relpath} is a soft link"")",if os . path . islink ( checkpath ) :,191
1727,"def load_syntax(syntax): <TAB> context = _create_scheme() or {} <TAB> partition_scanner = PartitionScanner(syntax.get(""partitions"", [])) <TAB> scanners = {} <TAB> for part_name, part_scanner in list(syntax.get(""scanner"", {}).items()): <TAB>  <TAB> scanners[part_name] = Scanner(part_scanner) <TAB> formats = [] <TAB> for fname, fstyle in list(syntax.get(""formats"", {}).items()): <MASK> if fstyle.startswith(""%("") and fstyle.endswith("")s""): <TAB>  <TAB>  <TAB>  <TAB> key = fstyle[2:-2] <TAB>  <TAB>  <TAB>  <TAB> fstyle = context[key] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> fstyle = fstyle % context <TAB>  <TAB> formats.append((fname, fstyle)) <TAB> return partition_scanner, scanners, formats","if isinstance ( fstyle , basestring ) :",199
1728,"def should_keep_alive(commit_msg): <TAB> result = False <TAB> ci = get_current_ci() or """" <TAB> for line in commit_msg.splitlines(): <TAB>  <TAB> parts = line.strip(""# "").split("":"", 1) <TAB>  <TAB> (key, val) = parts if len(parts) > 1 else (parts[0], """") <MASK> ci_names = val.replace("","", "" "").lower().split() if val else [] <TAB>  <TAB>  <TAB> if len(ci_names) == 0 or ci.lower() in ci_names: <TAB>  <TAB>  <TAB>  <TAB> result = True <TAB> return result","if key == ""CI_KEEP_ALIVE"" :",150
1729,"def get_note_title_file(note): <TAB> mo = note_title_re.match(note.get(""content"", """")) <TAB> if mo: <TAB>  <TAB> fn = mo.groups()[0] <TAB>  <TAB> fn = fn.replace("" "", ""_"") <TAB>  <TAB> fn = fn.replace(""/"", ""_"") <TAB>  <TAB> if not fn: <TAB>  <TAB>  <TAB> return """" <MASK> fn = unicode(fn, ""utf-8"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> fn = unicode(fn) <TAB>  <TAB> if note_markdown(note): <TAB>  <TAB>  <TAB> fn += "".mkdn"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> fn += "".txt"" <TAB>  <TAB> return fn <TAB> else: <TAB>  <TAB> return """"","if isinstance ( fn , str ) :",169
1730,"def post(self, orgname, teamname): <TAB> if _syncing_setup_allowed(orgname): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> team = model.team.get_organization_team(orgname, teamname) <TAB>  <TAB> except model.InvalidTeamException: <TAB>  <TAB>  <TAB> raise NotFound() <TAB>  <TAB> config = request.get_json() <TAB>  <TAB> # Ensure that the specified config points to a valid group. <TAB>  <TAB> status, err = authentication.check_group_lookup_args(config) <MASK> raise InvalidRequest(""Could not sync to group: %s"" % err) <TAB>  <TAB> # Set the team's syncing config. <TAB>  <TAB> model.team.set_team_syncing(team, authentication.federated_service, config) <TAB>  <TAB> return team_view(orgname, team) <TAB> raise Unauthorized()",if not status :,199
1731,"def _marshalData(self): <TAB> if self._cache == None: <TAB>  <TAB> d = self._data <TAB>  <TAB> s = """" <TAB>  <TAB> s = time.strftime(""%H:%M:%S"", (0, 0, 0) + d + (0, 0, -1)) <TAB>  <TAB> f = d[2] - int(d[2]) <MASK> s += (""%g"" % f)[1:] <TAB>  <TAB> s += ""Z"" <TAB>  <TAB> self._cache = s <TAB> return self._cache",if f != 0 :,126
1732,"def _get_level(levels, level_ref): <TAB> if level_ref in levels: <TAB>  <TAB> return levels.index(level_ref) <TAB> if isinstance(level_ref, six.integer_types): <TAB>  <TAB> if level_ref < 0: <TAB>  <TAB>  <TAB> level_ref += len(levels) <MASK> raise PatsyError(""specified level %r is out of range"" % (level_ref,)) <TAB>  <TAB> return level_ref <TAB> raise PatsyError(""specified level %r not found"" % (level_ref,))",if not ( 0 <= level_ref < len ( levels ) ) :,138
1733,"def iterfieldselect(source, field, where, complement, missing): <TAB> it = iter(source) <TAB> hdr = next(it) <TAB> yield tuple(hdr) <TAB> indices = asindices(hdr, field) <TAB> getv = operator.itemgetter(*indices) <TAB> for row in it: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> v = getv(row) <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB> v = missing <MASK> # XOR <TAB>  <TAB>  <TAB> yield tuple(row)",if bool ( where ( v ) ) != complement :,122
1734,"def _test_wait_read_invalid_switch(self, sleep): <TAB> sock1, sock2 = socket.socketpair() <TAB> try: <TAB>  <TAB> p = gevent.spawn( <TAB>  <TAB>  <TAB> util.wrap_errors( <TAB>  <TAB>  <TAB>  <TAB> AssertionError, socket.wait_read <TAB>  <TAB>  <TAB> ),  # pylint:disable=no-member <TAB>  <TAB>  <TAB> sock1.fileno(), <TAB>  <TAB> ) <TAB>  <TAB> gevent.get_hub().loop.run_callback(switch_None, p) <MASK> gevent.sleep(sleep) <TAB>  <TAB> result = p.get() <TAB>  <TAB> assert isinstance(result, AssertionError), result <TAB>  <TAB> assert ""Invalid switch"" in str(result), repr(str(result)) <TAB> finally: <TAB>  <TAB> sock1.close() <TAB>  <TAB> sock2.close()",if sleep is not None :,190
1735,"def train(config, args): <TAB> gan = setup_gan(config, inputs, args) <TAB> test_batches = [] <TAB> for i in range(args.steps): <TAB>  <TAB> gan.step() <MASK> correct_prediction = 0 <TAB>  <TAB>  <TAB> total = 0 <TAB>  <TAB>  <TAB> for (x, y) in gan.inputs.testdata(): <TAB>  <TAB>  <TAB>  <TAB> prediction = gan.generator(x) <TAB>  <TAB>  <TAB>  <TAB> correct_prediction += ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> torch.argmax(prediction, 1) == torch.argmax(y, 1) <TAB>  <TAB>  <TAB>  <TAB> ).sum() <TAB>  <TAB>  <TAB>  <TAB> total += y.shape[0] <TAB>  <TAB>  <TAB> accuracy = (float(correct_prediction) / total) * 100 <TAB>  <TAB>  <TAB> print(""accuracy: "", accuracy) <TAB> return sum_metrics",if i % args . sample_every == 0 and i > 0 :,200
1736,"def process_response(self, request, response, spider): <TAB> if not response.body: <TAB>  <TAB> return response <TAB> for fmt, func in six.iteritems(self._formats): <TAB>  <TAB> new_response = func(response) <MASK> logger.debug( <TAB>  <TAB>  <TAB>  <TAB> ""Decompressed response with format: %(responsefmt)s"", <TAB>  <TAB>  <TAB>  <TAB> {""responsefmt"": fmt}, <TAB>  <TAB>  <TAB>  <TAB> extra={""spider"": spider}, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return new_response <TAB> return response",if new_response :,126
1737,"def detect_ssl_option(self): <TAB> for option in self.ssl_options(): <MASK> for other_option in self.ssl_options(): <TAB>  <TAB>  <TAB>  <TAB> if option != other_option: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if scan_argv(self.argv, other_option) is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise ConfigurationError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Cannot give both %s and %s"" % (option, other_option) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return option","if scan_argv ( self . argv , option ) is not None :",140
1738,"def load(cls, storefile, template_store): <TAB> # Did we get file or filename? <TAB> if not hasattr(storefile, ""read""): <TAB>  <TAB> storefile = open(storefile, ""rb"") <TAB> # Adjust store to have translations <TAB> store = cls.convertfile(storefile, template_store) <TAB> for unit in store.units: <MASK> continue <TAB>  <TAB> # HTML does this properly on loading, others need it <TAB>  <TAB> if cls.needs_target_sync: <TAB>  <TAB>  <TAB> unit.target = unit.source <TAB>  <TAB>  <TAB> unit.rich_target = unit.rich_source <TAB> return store",if unit . isheader ( ) :,152
1739,"def _pre_get_table(self, _ctx, table_name): <TAB> vsctl_table = self._get_table(table_name) <TAB> schema_helper = self.schema_helper <TAB> schema_helper.register_table(vsctl_table.table_name) <TAB> for row_id in vsctl_table.row_ids: <MASK> schema_helper.register_table(row_id.table) <TAB>  <TAB> if row_id.name_column: <TAB>  <TAB>  <TAB> schema_helper.register_columns(row_id.table, [row_id.name_column]) <TAB>  <TAB> if row_id.uuid_column: <TAB>  <TAB>  <TAB> schema_helper.register_columns(row_id.table, [row_id.uuid_column]) <TAB> return vsctl_table",if row_id . table :,194
1740,"def __init__(self, pin=None, pull_up=False): <TAB> super(InputDevice, self).__init__(pin) <TAB> try: <TAB>  <TAB> self.pin.function = ""input"" <TAB>  <TAB> pull = ""up"" if pull_up else ""down"" <MASK> self.pin.pull = pull <TAB> except: <TAB>  <TAB> self.close() <TAB>  <TAB> raise <TAB> self._active_state = False if pull_up else True <TAB> self._inactive_state = True if pull_up else False",if self . pin . pull != pull :,130
1741,"def _increment_operations_count(self, operation, executed): <TAB> with self._lock: <MASK> self._executed_operations += 1 <TAB>  <TAB>  <TAB> self._executed[operation.job_type] += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._skipped[operation.job_type] += 1",if executed :,76
1742,"def emit(self, type, info=None): <TAB> # Overload emit() to send events to the proxy object at the other end <TAB> ev = super().emit(type, info) <TAB> if self._has_proxy is True and self._session.status > 0: <TAB>  <TAB> # implicit: and self._disposed is False: <MASK> self._session.send_command(""INVOKE"", self._id, ""_emit_at_proxy"", [ev]) <TAB>  <TAB> elif type in self.__event_types_at_proxy: <TAB>  <TAB>  <TAB> self._session.send_command(""INVOKE"", self._id, ""_emit_at_proxy"", [ev])",if type in self . __proxy_properties__ :,161
1743,"def validate_pull_secret(namespace): <TAB> if namespace.pull_secret is None: <TAB>  <TAB> # TODO: add aka.ms link here <TAB>  <TAB> warning = ( <TAB>  <TAB>  <TAB> ""No --pull-secret provided: cluster will not include samples or operators from "" <TAB>  <TAB>  <TAB> + ""Red Hat or from certified partners."" <TAB>  <TAB> ) <TAB>  <TAB> logger.warning(warning) <TAB> else: <TAB>  <TAB> try: <MASK> raise Exception() <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> raise InvalidArgumentValueError(""Invalid --pull-secret."")","if not isinstance ( json . loads ( namespace . pull_secret ) , dict ) :",145
1744,"def pack(types, *args): <TAB> if len(types) != len(args): <TAB>  <TAB> raise Exception(""number of arguments does not match format string"") <TAB> port = StringIO() <TAB> for (type, value) in zip(types, args): <TAB>  <TAB> if type == ""V"": <TAB>  <TAB>  <TAB> write_vuint(port, value) <TAB>  <TAB> elif type == ""v"": <TAB>  <TAB>  <TAB> write_vint(port, value) <MASK> write_bvec(port, value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception('unknown xpack format string item ""' + type + '""') <TAB> return port.getvalue()","elif type == ""s"" :",153
1745,"def data(self): <TAB> if self._data is not None: <TAB>  <TAB> return self._data <TAB> else: <MASK> with open(self.path, ""rb"") as jsonfile: <TAB>  <TAB>  <TAB>  <TAB> data = jsonfile.read().decode(""utf8"") <TAB>  <TAB>  <TAB>  <TAB> data = json.loads(data) <TAB>  <TAB>  <TAB>  <TAB> self._data = data <TAB>  <TAB>  <TAB>  <TAB> return self._data <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return dict()",if os . path . exists ( self . path ) :,120
1746,"def interact(self): <TAB> self.output.write(""\n"") <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> request = self.getline(""help> "") <MASK> break <TAB>  <TAB> except (KeyboardInterrupt, EOFError): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> request = strip(request) <TAB>  <TAB> # Make sure significant trailing quotation marks of literals don't <TAB>  <TAB> # get deleted while cleaning input <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB> len(request) > 2 <TAB>  <TAB>  <TAB> and request[0] == request[-1] in (""'"", '""') <TAB>  <TAB>  <TAB> and request[0] not in request[1:-1] <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> request = request[1:-1] <TAB>  <TAB> if lower(request) in (""q"", ""quit""): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> self.help(request)",if not request :,195
1747,"def api_attachment_metadata(self): <TAB> resp = [] <TAB> for part in self.parts: <MASK> continue <TAB>  <TAB> k = { <TAB>  <TAB>  <TAB> ""content_type"": part.block.content_type, <TAB>  <TAB>  <TAB> ""size"": part.block.size, <TAB>  <TAB>  <TAB> ""filename"": part.block.filename, <TAB>  <TAB>  <TAB> ""id"": part.block.public_id, <TAB>  <TAB> } <TAB>  <TAB> content_id = part.content_id <TAB>  <TAB> if content_id: <TAB>  <TAB>  <TAB> if content_id[0] == ""<"" and content_id[-1] == "">"": <TAB>  <TAB>  <TAB>  <TAB> content_id = content_id[1:-1] <TAB>  <TAB>  <TAB> k[""content_id""] = content_id <TAB>  <TAB> resp.append(k) <TAB> return resp",if not part . is_attachment :,194
1748,"def _notin_text(term, text, verbose=False): <TAB> index = text.find(term) <TAB> head = text[:index] <TAB> tail = text[index + len(term) :] <TAB> correct_text = head + tail <TAB> diff = _diff_text(correct_text, text, verbose) <TAB> newdiff = [u(""%s is contained here:"") % py.io.saferepr(term, maxsize=42)] <TAB> for line in diff: <TAB>  <TAB> if line.startswith(u(""Skipping"")): <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> if line.startswith(u(""+ "")): <TAB>  <TAB>  <TAB> newdiff.append(u(""  "") + line[2:]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> newdiff.append(line) <TAB> return newdiff","if line . startswith ( u ( ""- "" ) ) :",192
1749,"def get_api(user, url): <TAB> global API_CACHE <TAB> if API_CACHE is None or API_CACHE.get(url) is None: <TAB>  <TAB> API_CACHE_LOCK.acquire() <TAB>  <TAB> try: <MASK> API_CACHE = {} <TAB>  <TAB>  <TAB> if API_CACHE.get(url) is None: <TAB>  <TAB>  <TAB>  <TAB> API_CACHE[url] = ImpalaDaemonApi(url) <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> API_CACHE_LOCK.release() <TAB> api = API_CACHE[url] <TAB> api.set_user(user) <TAB> return api",if API_CACHE is None :,148
1750,"def __str__(self, prefix="""", printElemNumber=0): <TAB> res = """" <TAB> if self.has_index_name_: <TAB>  <TAB> res += prefix + (""index_name: %s\n"" % self.DebugFormatString(self.index_name_)) <TAB> cnt = 0 <TAB> for e in self.prefix_value_: <TAB>  <TAB> elm = """" <MASK> elm = ""(%d)"" % cnt <TAB>  <TAB> res += prefix + (""prefix_value%s: %s\n"" % (elm, self.DebugFormatString(e))) <TAB>  <TAB> cnt += 1 <TAB> if self.has_value_prefix_: <TAB>  <TAB> res += prefix + ( <TAB>  <TAB>  <TAB> ""value_prefix: %s\n"" % self.DebugFormatBool(self.value_prefix_) <TAB>  <TAB> ) <TAB> return res",if printElemNumber :,195
1751,"def add_group(x, nl, in_group, mw): <TAB> if len(x) == 0: <TAB>  <TAB> return x <TAB> if len(x) > 1 and not in_group: <MASK> return [""[[""] + x + [""]]""] <TAB>  <TAB> mw.warn( <TAB>  <TAB>  <TAB> ""Equation will multiplex and may produce inaccurate results (see manual)"" <TAB>  <TAB> ) <TAB> return [""[""] + x + [""]""]","if supports_group ( x , nl ) :",114
1752,"def unfulfilled_items(self): <TAB> unfulfilled_items = 0 <TAB> for order_item in self.items.all(): <MASK> aggr = order_item.deliver_item.aggregate(delivered=Sum(""quantity"")) <TAB>  <TAB>  <TAB> unfulfilled_items += order_item.quantity - (aggr[""delivered""] or 0) <TAB> return unfulfilled_items",if not order_item . canceled :,94
1753,"def _get_pattern(self, pattern_id): <TAB> """"""Get pattern item by id."""""" <TAB> for key in (Tag.PATTERNS1, Tag.PATTERNS2, Tag.PATTERNS3): <MASK> data = self.tagged_blocks.get_data(key) <TAB>  <TAB>  <TAB> for pattern in data: <TAB>  <TAB>  <TAB>  <TAB> if pattern.pattern_id == pattern_id: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return pattern <TAB> return None",if key in self . tagged_blocks :,110
1754,"def query_lister(domain, query="""", max_items=None, attr_names=None): <TAB> more_results = True <TAB> num_results = 0 <TAB> next_token = None <TAB> while more_results: <TAB>  <TAB> rs = domain.connection.query_with_attributes( <TAB>  <TAB>  <TAB> domain, query, attr_names, next_token=next_token <TAB>  <TAB> ) <TAB>  <TAB> for item in rs: <TAB>  <TAB>  <TAB> if max_items: <MASK> raise StopIteration <TAB>  <TAB>  <TAB> yield item <TAB>  <TAB>  <TAB> num_results += 1 <TAB>  <TAB> next_token = rs.next_token <TAB>  <TAB> more_results = next_token != None",if num_results == max_items :,166
1755,"def find_deprecated_settings(source):  # pragma: no cover <TAB> from celery.utils import deprecated <TAB> for name, opt in flatten(NAMESPACES): <MASK> deprecated.warn( <TAB>  <TAB>  <TAB>  <TAB> description=""The {0!r} setting"".format(name), <TAB>  <TAB>  <TAB>  <TAB> deprecation=opt.deprecate_by, <TAB>  <TAB>  <TAB>  <TAB> removal=opt.remove_by, <TAB>  <TAB>  <TAB>  <TAB> alternative=""Use the {0.alt} instead"".format(opt), <TAB>  <TAB>  <TAB> ) <TAB> return source","if ( opt . deprecate_by or opt . remove_by ) and getattr ( source , name , None ) :",150
1756,"def tearDown(self): <TAB> """"""Shutdown the server."""""" <TAB> try: <MASK> self.server.stop(2.0) <TAB>  <TAB> if self.sl_hdlr: <TAB>  <TAB>  <TAB> self.root_logger.removeHandler(self.sl_hdlr) <TAB>  <TAB>  <TAB> self.sl_hdlr.close() <TAB> finally: <TAB>  <TAB> BaseTest.tearDown(self)",if self . server :,96
1757,"def broadcast_events(self, events): <TAB> LOGGER.debug(""Broadcasting events: %s"", events) <TAB> with self._subscribers_cv: <TAB>  <TAB> # Copy the subscribers <TAB>  <TAB> subscribers = {conn: sub.copy() for conn, sub in self._subscribers.items()} <TAB> if subscribers: <TAB>  <TAB> for connection_id, subscriber in subscribers.items(): <MASK> subscriber_events = [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> event for event in events if subscriber.is_subscribed(event) <TAB>  <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB>  <TAB> event_list = EventList(events=subscriber_events) <TAB>  <TAB>  <TAB>  <TAB> self._send(connection_id, event_list.SerializeToString())",if subscriber . is_listening ( ) :,173
1758,"def _get_info(self, path): <TAB> info = OrderedDict() <TAB> if not self._is_mac() or self._has_xcode_tools(): <TAB>  <TAB> stdout = None <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> stdout, stderr = Popen( <TAB>  <TAB>  <TAB>  <TAB> [self._find_binary(), ""info"", os.path.realpath(path)], <TAB>  <TAB>  <TAB>  <TAB> stdout=PIPE, <TAB>  <TAB>  <TAB>  <TAB> stderr=PIPE, <TAB>  <TAB>  <TAB> ).communicate() <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if stdout: <TAB>  <TAB>  <TAB>  <TAB> for line in stdout.splitlines(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> line = u(line).split("": "", 1) <MASK> info[line[0]] = line[1] <TAB> return info",if len ( line ) == 2 :,194
1759,"def test_call_extern_c_fn(self): <TAB> global memcmp <TAB> memcmp = cffi_support.ExternCFunction( <TAB>  <TAB> ""memcmp"", <TAB>  <TAB> (""int memcmp ( const uint8_t * ptr1, "" ""const uint8_t * ptr2, size_t num )""), <TAB> ) <TAB> @udf(BooleanVal(FunctionContext, StringVal, StringVal)) <TAB> def fn(context, a, b): <TAB>  <TAB> if a.is_null != b.is_null: <TAB>  <TAB>  <TAB> return False <MASK> return True <TAB>  <TAB> if len(a) != b.len: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> if a.ptr == b.ptr: <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> return memcmp(a.ptr, b.ptr, a.len) == 0",if a is None :,199
1760,"def _flatten(*args): <TAB> ahs = set() <TAB> if len(args) > 0: <TAB>  <TAB> for item in args: <TAB>  <TAB>  <TAB> if type(item) is ActionHandle: <TAB>  <TAB>  <TAB>  <TAB> ahs.add(item) <TAB>  <TAB>  <TAB> elif type(item) in (list, tuple, dict, set): <TAB>  <TAB>  <TAB>  <TAB> for ah in item: <MASK> # pragma:nocover <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise ActionManagerError(""Bad argument type %s"" % str(ah)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ahs.add(ah) <TAB>  <TAB>  <TAB> else:  # pragma:nocover <TAB>  <TAB>  <TAB>  <TAB> raise ActionManagerError(""Bad argument type %s"" % str(item)) <TAB> return ahs",if type ( ah ) is not ActionHandle :,183
1761,"def startElement(self, name, attrs, connection): <TAB> if name == ""Parameter"": <MASK> self[self._current_param.name] = self._current_param <TAB>  <TAB> self._current_param = Parameter(self) <TAB>  <TAB> return self._current_param",if self . _current_param :,73
1762,"def _find_class_in_descendants(self, search_key): <TAB> for cls in self.primitive_classes: <TAB>  <TAB> cls_key = (cls.__name__, cls.__module__) <TAB>  <TAB> self.class_cache[cls_key] = cls <MASK> return cls",if cls_key == search_key :,77
1763,"def doWorkForFindAll(self, v, target, partialMatch): <TAB> sibling = self <TAB> while sibling: <TAB>  <TAB> c1 = partialMatch and sibling.equalsTreePartial(target) <TAB>  <TAB> if c1: <TAB>  <TAB>  <TAB> v.append(sibling) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> c2 = not partialMatch and sibling.equalsTree(target) <TAB>  <TAB>  <TAB> if c2: <TAB>  <TAB>  <TAB>  <TAB> v.append(sibling) <TAB>  <TAB> ### regardless of match or not, check any children for matches <MASK> sibling.getFirstChild().doWorkForFindAll(v, target, partialMatch) <TAB>  <TAB> sibling = sibling.getNextSibling()",if sibling . getFirstChild ( ) :,163
1764,"def forward(self, inputs: paddle.Tensor): <TAB> outputs = [] <TAB> blocks = self.block(inputs) <TAB> route = None <TAB> for i, block in enumerate(blocks): <TAB>  <TAB> if i > 0: <TAB>  <TAB>  <TAB> block = paddle.concat([route, block], axis=1) <TAB>  <TAB> route, tip = self.yolo_blocks[i](block) <TAB>  <TAB> block_out = self.block_outputs[i](tip) <TAB>  <TAB> outputs.append(block_out) <MASK> route = self.route_blocks_2[i](route) <TAB>  <TAB>  <TAB> route = self.upsample(route) <TAB> return outputs",if i < 2 :,163
1765,"def _filter_paths(basename, path, is_dir, exclude): <TAB> """""".gitignore style file filtering."""""" <TAB> for item in exclude: <TAB>  <TAB> # Items ending in '/' apply only to directories. <MASK> continue <TAB>  <TAB> # Items starting with '/' apply to the whole path. <TAB>  <TAB> # In any other cases just the basename is used. <TAB>  <TAB> match = path if item.startswith(""/"") else basename <TAB>  <TAB> if fnmatch.fnmatch(match, item.strip(""/"")): <TAB>  <TAB>  <TAB> return True <TAB> return False","if item . endswith ( ""/"" ) and not is_dir :",130
1766,"def reposition_division(f1): <TAB> lines = f1.splitlines() <TAB> if lines[2] == division: <TAB>  <TAB> lines.pop(2) <TAB> found = 0 <TAB> for i, line in enumerate(lines): <TAB>  <TAB> if line.startswith('""""""'): <TAB>  <TAB>  <TAB> found += 1 <TAB>  <TAB>  <TAB> if found == 2: <MASK> break  # already in the right place <TAB>  <TAB>  <TAB>  <TAB> lines.insert(i + 1, """") <TAB>  <TAB>  <TAB>  <TAB> lines.insert(i + 2, division) <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return ""\n"".join(lines)","if division in ""\n"" . join ( lines ) :",153
1767,"def buildImage(opt): <TAB> dpath = os.path.join(opt[""datapath""], ""COCO-IMG-2015"") <TAB> version = ""1"" <TAB> if not build_data.built(dpath, version_string=version): <TAB>  <TAB> print(""[building image data: "" + dpath + ""]"") <MASK> # An older version exists, so remove these outdated files. <TAB>  <TAB>  <TAB> build_data.remove_dir(dpath) <TAB>  <TAB> build_data.make_dir(dpath) <TAB>  <TAB> # Download the data. <TAB>  <TAB> for downloadable_file in RESOURCES[:1]: <TAB>  <TAB>  <TAB> downloadable_file.download_file(dpath) <TAB>  <TAB> # Mark the data as built. <TAB>  <TAB> build_data.mark_done(dpath, version_string=version)",if build_data . built ( dpath ) :,191
1768,"def colorformat(text): <TAB> if text[0:1] == ""#"": <TAB>  <TAB> col = text[1:] <MASK> return col <TAB>  <TAB> elif len(col) == 3: <TAB>  <TAB>  <TAB> return col[0] * 2 + col[1] * 2 + col[2] * 2 <TAB> elif text == """": <TAB>  <TAB> return """" <TAB> assert False, ""wrong color format %r"" % text",if len ( col ) == 6 :,105
1769,"def tree_print(tree): <TAB> for key in tree: <TAB>  <TAB> print(key, end="" "")  # end=' ' prevents a newline character <TAB>  <TAB> tree_element = tree[key]  # multiple lookups is expensive, even amortized O(1)! <TAB>  <TAB> for subElem in tree_element: <TAB>  <TAB>  <TAB> print("" -> "", subElem, end="" "") <MASK> # OP wants indenting after digits <TAB>  <TAB>  <TAB>  <TAB> print(""\n "")  # newline and a space to match indenting <TAB>  <TAB> print()  # forces a newline",if type ( subElem ) != str :,138
1770,"def is_dse_cluster(path): <TAB> try: <TAB>  <TAB> with open(os.path.join(path, ""CURRENT""), ""r"") as f: <TAB>  <TAB>  <TAB> name = f.readline().strip() <TAB>  <TAB>  <TAB> cluster_path = os.path.join(path, name) <TAB>  <TAB>  <TAB> filename = os.path.join(cluster_path, ""cluster.conf"") <TAB>  <TAB>  <TAB> with open(filename, ""r"") as f: <TAB>  <TAB>  <TAB>  <TAB> data = yaml.load(f) <MASK> return True <TAB> except IOError: <TAB>  <TAB> return False","if ""dse_dir"" in data :",148
1771,"def delete_old_target_output_files(classpath_prefix): <TAB> """"""Delete existing output files or symlinks for target."""""" <TAB> directory, basename = os.path.split(classpath_prefix) <TAB> pattern = re.compile( <TAB>  <TAB> r""^{basename}(([0-9]+)(\.jar)?|classpath\.txt)$"".format( <TAB>  <TAB>  <TAB> basename=re.escape(basename) <TAB>  <TAB> ) <TAB> ) <TAB> files = [filename for filename in os.listdir(directory) if pattern.match(filename)] <TAB> for rel_path in files: <TAB>  <TAB> path = os.path.join(directory, rel_path) <MASK> safe_delete(path)",if os . path . islink ( path ) or os . path . isfile ( path ) :,175
1772,"def test_files(self): <TAB> # get names of files to test <TAB> dist_dir = os.path.join(os.path.dirname(__file__), os.pardir, os.pardir) <TAB> names = [] <TAB> for d in self.test_directories: <TAB>  <TAB> test_dir = os.path.join(dist_dir, d) <TAB>  <TAB> for n in os.listdir(test_dir): <TAB>  <TAB>  <TAB> if n.endswith("".py"") and not n.startswith(""bad""): <TAB>  <TAB>  <TAB>  <TAB> names.append(os.path.join(test_dir, n)) <TAB> for filename in names: <MASK> print(""Testing %s"" % filename) <TAB>  <TAB> source = read_pyfile(filename) <TAB>  <TAB> self.check_roundtrip(source)",if test_support . verbose :,186
1773,"def __str__(self): <TAB> if self.HasError(): <TAB>  <TAB> return self.ErrorAsStr() <TAB> else: <TAB>  <TAB> # Format is: {action} ""{target}"" ({filename}:{lineno}) <TAB>  <TAB> string = self._action <TAB>  <TAB> if self._target is not None: <TAB>  <TAB>  <TAB> string += ' ""{target}""'.format(target=self._target) <MASK> path = self._filename <TAB>  <TAB>  <TAB> if self._lineno is not None: <TAB>  <TAB>  <TAB>  <TAB> path += "":{lineno}"".format(lineno=self._lineno) <TAB>  <TAB>  <TAB> string += "" ({path})"".format(path=path) <TAB>  <TAB> return string",if self . _filename is not None :,156
1774,"def extra_action_out(self, input_dict, state_batches, model, action_dist): <TAB> with self._no_grad_context(): <MASK> stats_dict = extra_action_out_fn( <TAB>  <TAB>  <TAB>  <TAB> self, input_dict, state_batches, model, action_dist <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> stats_dict = parent_cls.extra_action_out( <TAB>  <TAB>  <TAB>  <TAB> self, input_dict, state_batches, model, action_dist <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return self._convert_to_non_torch_type(stats_dict)",if extra_action_out_fn :,156
1775,"def _retract_bindings(fstruct, inv_bindings, fs_class, visited): <TAB> # Visit each node only once: <TAB> if id(fstruct) in visited: <TAB>  <TAB> return <TAB> visited.add(id(fstruct)) <TAB> if _is_mapping(fstruct): <TAB>  <TAB> items = fstruct.items() <TAB> elif _is_sequence(fstruct): <TAB>  <TAB> items = enumerate(fstruct) <TAB> else: <TAB>  <TAB> raise ValueError(""Expected mapping or sequence"") <TAB> for (fname, fval) in items: <TAB>  <TAB> if isinstance(fval, fs_class): <MASK> fstruct[fname] = inv_bindings[id(fval)] <TAB>  <TAB>  <TAB> _retract_bindings(fval, inv_bindings, fs_class, visited)",if id ( fval ) in inv_bindings :,181
1776,"def warehouses(self) -> tuple: <TAB> from ..repositories import WarehouseBaseRepo <TAB> repos = dict() <TAB> for dep in chain(self.dependencies, [self]): <MASK> continue <TAB>  <TAB> if not isinstance(dep.repo, WarehouseBaseRepo): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for repo in dep.repo.repos: <TAB>  <TAB>  <TAB> if repo.from_config: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> repos[repo.name] = repo <TAB> return tuple(repos.values())",if dep . repo is None :,124
1777,"def detype(self): <TAB> if self._detyped is not None: <TAB>  <TAB> return self._detyped <TAB> ctx = {} <TAB> for key, val in self._d.items(): <TAB>  <TAB> if not isinstance(key, str): <TAB>  <TAB>  <TAB> key = str(key) <TAB>  <TAB> detyper = self.get_detyper(key) <MASK> # cannot be detyped <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> deval = detyper(val) <TAB>  <TAB> if deval is None: <TAB>  <TAB>  <TAB> # cannot be detyped <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> ctx[key] = deval <TAB> self._detyped = ctx <TAB> return ctx",if detyper is None :,163
1778,"def populate_obj(self, obj, name): <TAB> field = getattr(obj, name, None) <TAB> if field is not None: <TAB>  <TAB> # If field should be deleted, clean it up <MASK> field.delete() <TAB>  <TAB>  <TAB> return <TAB>  <TAB> if isinstance(self.data, FileStorage) and not is_empty(self.data.stream): <TAB>  <TAB>  <TAB> if not field.grid_id: <TAB>  <TAB>  <TAB>  <TAB> func = field.put <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> func = field.replace <TAB>  <TAB>  <TAB> func( <TAB>  <TAB>  <TAB>  <TAB> self.data.stream, <TAB>  <TAB>  <TAB>  <TAB> filename=self.data.filename, <TAB>  <TAB>  <TAB>  <TAB> content_type=self.data.content_type, <TAB>  <TAB>  <TAB> )",if self . _should_delete :,182
1779,"def _load(container): <TAB> if isinstance(container, str): <TAB>  <TAB> # If container is a filename. <MASK> with open(container, ""rb"") as f: <TAB>  <TAB>  <TAB>  <TAB> return pickle.load(f) <TAB>  <TAB> # If container is a pickle string. <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return pickle.loads(container) <TAB> # If container is an open file <TAB> elif isinstance(container, IOBase): <TAB>  <TAB> return pickle.load(container) <TAB> # What else could it be? <TAB> else: <TAB>  <TAB> l.error(""Cannot unpickle container of type %s"", type(container)) <TAB>  <TAB> return None",if all ( c in string . printable for c in container ) and os . path . exists ( container ) :,171
1780,"def append_row(self, row): <TAB> self.allocate_future_payments(row) <TAB> self.set_invoice_details(row) <TAB> self.set_party_details(row) <TAB> self.set_ageing(row) <TAB> if self.filters.get(""group_by_party""): <TAB>  <TAB> self.update_sub_total_row(row, row.party) <MASK> self.append_subtotal_row(self.previous_party) <TAB>  <TAB> self.previous_party = row.party <TAB> self.data.append(row)",if self . previous_party and ( self . previous_party != row . party ) :,152
1781,"def gg1(): <TAB> while 1: <TAB>  <TAB> tt = 3 <TAB>  <TAB> while tt > 0: <TAB>  <TAB>  <TAB> trace.append(tt) <TAB>  <TAB>  <TAB> val = yield <MASK> tt = 10  # <= uncomment this line <TAB>  <TAB>  <TAB>  <TAB> trace.append(""breaking early..."") <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> tt -= 1 <TAB>  <TAB> trace.append(""try!"")",if val is not None :,101
1782,"def migrate_common_facts(facts): <TAB> """"""Migrate facts from various roles into common"""""" <TAB> params = {""node"": (""portal_net""), ""master"": (""portal_net"")} <TAB> if ""common"" not in facts: <TAB>  <TAB> facts[""common""] = {} <TAB> # pylint: disable=consider-iterating-dictionary <TAB> for role in params.keys(): <TAB>  <TAB> if role in facts: <TAB>  <TAB>  <TAB> for param in params[role]: <MASK> facts[""common""][param] = facts[role].pop(param) <TAB> return facts",if param in facts [ role ] :,137
1783,"def get_measurements(self, pipeline, object_name, category): <TAB> if self.get_categories(pipeline, object_name) == [category]: <TAB>  <TAB> results = [] <MASK> if object_name == ""Image"": <TAB>  <TAB>  <TAB>  <TAB> results += [""Correlation"", ""Slope""] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> results += [""Correlation""] <TAB>  <TAB> if self.do_overlap: <TAB>  <TAB>  <TAB> results += [""Overlap"", ""K""] <TAB>  <TAB> if self.do_manders: <TAB>  <TAB>  <TAB> results += [""Manders""] <TAB>  <TAB> if self.do_rwc: <TAB>  <TAB>  <TAB> results += [""RWC""] <TAB>  <TAB> if self.do_costes: <TAB>  <TAB>  <TAB> results += [""Costes""] <TAB>  <TAB> return results <TAB> return []",if self . do_corr_and_slope :,195
1784,"def access_modes(self): <TAB> """"""access_modes property"""""" <TAB> if self._access_modes is None: <TAB>  <TAB> self._access_modes = self.get_access_modes() <MASK> self._access_modes = list(self._access_modes) <TAB> return self._access_modes","if not isinstance ( self . _access_modes , list ) :",85
1785,"def unwrap_envelope(self, data, many): <TAB> if many: <MASK> if isinstance(data, InstrumentedList) or isinstance(data, list): <TAB>  <TAB>  <TAB>  <TAB> self.context[""total""] = len(data) <TAB>  <TAB>  <TAB>  <TAB> return data <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.context[""total""] = data[""total""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.context[""total""] = 0 <TAB>  <TAB>  <TAB> data = {""items"": []} <TAB>  <TAB> return data[""items""] <TAB> return data","if data [ ""items"" ] :",130
1786,"def to_string(self, fmt=""{:.4f}""): <TAB> result_str = """" <TAB> for key in self.measures: <TAB>  <TAB> result = self.m_dict[key][0]() <TAB>  <TAB> result_str += ( <TAB>  <TAB>  <TAB> "","".join(fmt.format(x) for x in result) <MASK> else fmt.format(result) <TAB>  <TAB> ) <TAB>  <TAB> result_str += "","" <TAB> return result_str[:-1]  # trim the last comma","if isinstance ( result , tuple )",121
1787,"def on_torrent_created(self, result): <TAB> if not result: <TAB>  <TAB> return <TAB> self.dialog_widget.btn_create.setEnabled(True) <TAB> self.dialog_widget.edit_channel_create_torrent_progress_label.setText( <TAB>  <TAB> ""Created torrent"" <TAB> ) <TAB> if ""torrent"" in result: <TAB>  <TAB> self.create_torrent_notification.emit({""msg"": ""Torrent successfully created""}) <MASK> self.add_torrent_to_channel(result[""torrent""]) <TAB>  <TAB> self.close_dialog()",if self . dialog_widget . add_to_channel_checkbox . isChecked ( ) :,151
1788,"def save(self): <TAB> for var_name in self.default_config: <MASK> if var_name in self.file_config: <TAB>  <TAB>  <TAB>  <TAB> del self.file_config[var_name] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.file_config[var_name] = getattr(self, var_name) <TAB> with open(self.config_path, ""w"") as f: <TAB>  <TAB> f.write(json.dumps(self.file_config, indent=2))","if getattr ( self , var_name , None ) == self . default_config [ var_name ] :",141
1789,"def get_class_parameters(kwarg): <TAB> ret = {""attrs"": []} <TAB> for key in (""rsc"", ""fsc"", ""usc""): <MASK> ret[""attrs""].append( <TAB>  <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""TCA_HFSC_%s"" % key.upper(), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""m1"": get_rate(kwarg[key].get(""m1"", 0)), <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""d"": get_time(kwarg[key].get(""d"", 0)), <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""m2"": get_rate(kwarg[key].get(""m2"", 0)), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> }, <TAB>  <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB> ) <TAB> return ret",if key in kwarg :,184
1790,"def forward(self, x): <TAB> f_x = x <TAB> if self.exp: <TAB>  <TAB> f_x = self.exp_swish(self.exp_bn(self.exp(f_x))) <TAB> f_x = self.dwise_swish(self.dwise_bn(self.dwise(f_x))) <TAB> f_x = self.se(f_x) <TAB> f_x = self.lin_proj_bn(self.lin_proj(f_x)) <TAB> if self.has_skip: <MASK> f_x = drop_connect(f_x, effnet_cfg.EN.DC_RATIO) <TAB>  <TAB> f_x = x + f_x <TAB> return f_x",if self . training and effnet_cfg . EN . DC_RATIO > 0.0 :,193
1791,"def cli_uninstall_distro(): <TAB> distro_list = install_distro_list() <TAB> if distro_list is not None: <TAB>  <TAB> for index, _distro_dir in enumerate(distro_list): <TAB>  <TAB>  <TAB> log(str(index) + ""  --->>  "" + _distro_dir) <TAB>  <TAB> user_input = read_input_uninstall() <TAB>  <TAB> if user_input is not False: <TAB>  <TAB>  <TAB> for index, _distro_dir in enumerate(distro_list): <MASK> config.uninstall_distro_dir_name = _distro_dir <TAB>  <TAB>  <TAB>  <TAB>  <TAB> unin_distro() <TAB> else: <TAB>  <TAB> log(""No distro installed on "" + config.usb_disk)",if index == user_input :,189
1792,"def IMPORTFROM(self, node): <TAB> if node.module == ""__future__"": <MASK> self.report(messages.LateFutureImport, node, [n.name for n in node.names]) <TAB> else: <TAB>  <TAB> self.futuresAllowed = False <TAB> for alias in node.names: <TAB>  <TAB> if alias.name == ""*"": <TAB>  <TAB>  <TAB> self.scope.importStarred = True <TAB>  <TAB>  <TAB> self.report(messages.ImportStarUsed, node, node.module) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> name = alias.asname or alias.name <TAB>  <TAB> importation = Importation(name, node) <TAB>  <TAB> if node.module == ""__future__"": <TAB>  <TAB>  <TAB> importation.used = (self.scope, node) <TAB>  <TAB> self.addBinding(node, importation)",if not self . futuresAllowed :,190
1793,"def _split_and_load(batch, ctx_list): <TAB> """"""Split data to 1 batch each device."""""" <TAB> new_batch = [] <TAB> for _, data in enumerate(batch): <MASK> new_data = [x.as_in_context(ctx) for x, ctx in zip(data, ctx_list)] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_data = [data.as_in_context(ctx_list[0])] <TAB>  <TAB> new_batch.append(new_data) <TAB> return new_batch","if isinstance ( data , ( list , tuple ) ) :",135
1794,"def wait_success(self, timeout=60 * 10): <TAB> for i in range(timeout // 10): <TAB>  <TAB> time.sleep(10) <TAB>  <TAB> status = self.query_job() <TAB>  <TAB> print(""job {} status is {}"".format(self.job_id, status)) <MASK> return True <TAB>  <TAB> if status and status in [ <TAB>  <TAB>  <TAB> StatusSet.CANCELED, <TAB>  <TAB>  <TAB> StatusSet.TIMEOUT, <TAB>  <TAB>  <TAB> StatusSet.FAILED, <TAB>  <TAB> ]: <TAB>  <TAB>  <TAB> return False <TAB> return False",if status and status == StatusSet . SUCCESS :,134
1795,"def copy_tree(self, src_dir, dst_dir, skip_variables=False): <TAB> for src_root, _, files in os.walk(src_dir): <MASK> rel_root = os.path.relpath(src_root, src_dir) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> rel_root = """" <TAB>  <TAB> if skip_variables and rel_root.startswith(""variables""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> dst_root = os.path.join(dst_dir, rel_root) <TAB>  <TAB> if not os.path.exists(dst_root): <TAB>  <TAB>  <TAB> os.makedirs(dst_root) <TAB>  <TAB> for f in files: <TAB>  <TAB>  <TAB> shutil.copy(os.path.join(src_root, f), os.path.join(dst_root, f))",if src_root != src_dir :,197
1796,"def _make_padded_shapes(self, dataset, decoders): <TAB> padded_shapes = dataset.output_shapes <TAB> for i, hparams_i in enumerate(self._hparams.datasets): <MASK> continue <TAB>  <TAB> if not hparams_i[""pad_to_max_seq_length""]: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> text_and_id_shapes = MonoTextData._make_padded_text_and_id_shapes( <TAB>  <TAB>  <TAB> dataset, hparams_i, decoders[i], self.text_name(i), self.text_id_name(i) <TAB>  <TAB> ) <TAB>  <TAB> padded_shapes.update(text_and_id_shapes) <TAB> return padded_shapes","if not _is_text_data ( hparams_i [ ""data_type"" ] ) :",179
1797,"def format_errors(messages): <TAB> errors = {} <TAB> for k, v in messages.items(): <TAB>  <TAB> key = camelize(k, uppercase_first_letter=False) <MASK> errors[key] = format_errors(v) <TAB>  <TAB> elif isinstance(v, list): <TAB>  <TAB>  <TAB> errors[key] = v[0] <TAB> return errors","if isinstance ( v , dict ) :",94
1798,"def generic_visit(self, node, parents=None): <TAB> parents = (parents or []) + [node] <TAB> for field, value in iter_fields(node): <MASK> for item in value: <TAB>  <TAB>  <TAB>  <TAB> if isinstance(item, AST): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.visit(item, parents) <TAB>  <TAB> elif isinstance(value, AST): <TAB>  <TAB>  <TAB> self.visit(value, parents)","if isinstance ( value , list ) :",106
1799,"def get_override_css(self): <TAB> """"""handls allow_css_overrides setting."""""" <TAB> if self.settings.get(""allow_css_overrides""): <TAB>  <TAB> filename = self.view.file_name() <TAB>  <TAB> filetypes = self.settings.get(""markdown_filetypes"") <TAB>  <TAB> if filename and filetypes: <TAB>  <TAB>  <TAB> for filetype in filetypes: <MASK> css_filename = filename.rpartition(filetype)[0] + "".css"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if os.path.isfile(css_filename): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return u""<style>%s</style>"" % load_utf8(css_filename) <TAB> return """"",if filename . endswith ( filetype ) :,165
1800,"def clean(self): <TAB> super().clean() <TAB> # If the Cluster is assigned to a Site, all Devices must be assigned to that Site. <TAB> if self.cluster.site is not None: <TAB>  <TAB> for device in self.cleaned_data.get(""devices"", []): <MASK> raise ValidationError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""devices"": ""{} belongs to a different site ({}) than the cluster ({})"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> device, device.site, self.cluster.site <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB>  <TAB> )",if device . site != self . cluster . site :,156
1801,"def _setProcessPriority(process, nice_val, disable_gc): <TAB> org_nice_val = Computer._process_original_nice_value <TAB> try: <TAB>  <TAB> process.nice(nice_val) <TAB>  <TAB> Computer.in_high_priority_mode = nice_val != org_nice_val <MASK> gc.disable() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> gc.enable() <TAB>  <TAB> return True <TAB> except psutil.AccessDenied: <TAB>  <TAB> print2err( <TAB>  <TAB>  <TAB> ""WARNING: Could not set process {} priority "" <TAB>  <TAB>  <TAB> ""to {}"".format(process.pid, nice_val) <TAB>  <TAB> ) <TAB>  <TAB> return False",if disable_gc :,161
1802,"def _setResultsName(self, name, listAllMatches=False): <TAB> if __diag__.warn_multiple_tokens_in_named_alternation: <MASK> warnings.warn( <TAB>  <TAB>  <TAB>  <TAB> ""{}: setting results name {!r} on {} expression "" <TAB>  <TAB>  <TAB>  <TAB> ""may only return a single token for an And alternative, "" <TAB>  <TAB>  <TAB>  <TAB> ""in future will return the full list of tokens"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""warn_multiple_tokens_in_named_alternation"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> name, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> type(self).__name__, <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB>  <TAB> stacklevel=3, <TAB>  <TAB>  <TAB> ) <TAB> return super()._setResultsName(name, listAllMatches)","if any ( isinstance ( e , And ) for e in self . exprs ) :",193
1803,"def make_sources(project: RootDependency) -> str: <TAB> content = [] <TAB> if project.readme: <TAB>  <TAB> content.append(project.readme.path.name) <TAB>  <TAB> if project.readme.markup != ""rst"": <TAB>  <TAB>  <TAB> content.append(project.readme.to_rst().path.name) <TAB> path = project.package.path <TAB> for fname in (""setup.cfg"", ""setup.py""): <MASK> content.append(fname) <TAB> for package in chain(project.package.packages, project.package.data): <TAB>  <TAB> for fpath in package: <TAB>  <TAB>  <TAB> fpath = fpath.relative_to(project.package.path) <TAB>  <TAB>  <TAB> content.append(""/"".join(fpath.parts)) <TAB> return ""\n"".join(content)",if ( path / fname ) . exists ( ) :,193
1804,"def findControlPointsInMesh(glyph, va, subsegments): <TAB> controlPointIndices = np.zeros((len(va), 1)) <TAB> index = 0 <TAB> for i, c in enumerate(subsegments): <TAB>  <TAB> segmentCount = len(glyph.contours[i].segments) - 1 <TAB>  <TAB> for j, s in enumerate(c): <TAB>  <TAB>  <TAB> if j < segmentCount: <MASK> controlPointIndices[index] = 1 <TAB>  <TAB>  <TAB> index += s[1] <TAB> return controlPointIndices","if glyph . contours [ i ] . segments [ j ] . type == ""line"" :",143
1805,"def MergeFrom(self, other): <TAB> if self.message_class is not None: <TAB>  <TAB> if other.Parse(self.message_class): <TAB>  <TAB>  <TAB> self.message.MergeFrom(other.message) <TAB> elif other.message_class is not None: <MASK> self.message = other.message_class() <TAB>  <TAB>  <TAB> self.message_class = other.message_class <TAB>  <TAB> self.message.MergeFrom(other.message) <TAB> else: <TAB>  <TAB> self.message += other.message",if not self . Parse ( other . message_class ) :,134
1806,"def remove_old_snapshot(install_dir): <TAB> logging.info(""Removing any old files in {}"".format(install_dir)) <TAB> for file in glob.glob(""{}/*"".format(install_dir)): <TAB>  <TAB> try: <MASK> os.unlink(file) <TAB>  <TAB>  <TAB> elif os.path.isdir(file): <TAB>  <TAB>  <TAB>  <TAB> shutil.rmtree(file) <TAB>  <TAB> except Exception as error: <TAB>  <TAB>  <TAB> logging.error(""Error: {}"".format(error)) <TAB>  <TAB>  <TAB> sys.exit(1)",if os . path . isfile ( file ) :,133
1807,"def writexml( <TAB> self, <TAB> stream, <TAB> indent="""", <TAB> addindent="""", <TAB> newl="""", <TAB> strip=0, <TAB> nsprefixes={}, <TAB> namespace="""",): <TAB> w = _streamWriteWrapper(stream) <TAB> if self.raw: <TAB>  <TAB> val = self.nodeValue <TAB>  <TAB> if not isinstance(val, str): <TAB>  <TAB>  <TAB> val = str(self.nodeValue) <TAB> else: <TAB>  <TAB> v = self.nodeValue <TAB>  <TAB> if not isinstance(v, str): <TAB>  <TAB>  <TAB> v = str(v) <MASK> v = "" "".join(v.split()) <TAB>  <TAB> val = escape(v) <TAB> w(val)",if strip :,164
1808,"def validate_attributes(self): <TAB> for attribute in self.get_all_attributes(): <TAB>  <TAB> value = getattr(self, attribute.code, None) <MASK> if attribute.required: <TAB>  <TAB>  <TAB>  <TAB> raise ValidationError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _(""%(attr)s attribute cannot be blank"") % {""attr"": attribute.code} <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> attribute.validate_value(value) <TAB>  <TAB>  <TAB> except ValidationError as e: <TAB>  <TAB>  <TAB>  <TAB> raise ValidationError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _(""%(attr)s attribute %(err)s"") % {""attr"": attribute.code, ""err"": e} <TAB>  <TAB>  <TAB>  <TAB> )",if value is None :,168
1809,"def PyJsHoisted_BinaryExpression_(node, parent, this, arguments, var=var): <TAB> var = Scope( <TAB>  <TAB> {u""node"": node, u""this"": this, u""arguments"": arguments, u""parent"": parent}, var <TAB> ) <TAB> var.registers([u""node"", u""parent""]) <TAB> if PyJsStrictEq(var.get(u""node"").get(u""operator""), Js(u""in"")): <MASK> return var.get(u""true"") <TAB>  <TAB> if var.get(u""t"").callprop(u""isFor"", var.get(u""parent"")): <TAB>  <TAB>  <TAB> return var.get(u""true"") <TAB> return Js(False)","if var . get ( u""t"" ) . callprop ( u""isVariableDeclarator"" , var . get ( u""parent"" ) ) :",196
1810,"def distinct(expr, *on): <TAB> fields = frozenset(expr.fields) <TAB> _on = [] <TAB> append = _on.append <TAB> for n in on: <TAB>  <TAB> if isinstance(n, Field): <TAB>  <TAB>  <TAB> if n._child.isidentical(expr): <TAB>  <TAB>  <TAB>  <TAB> n = n._name <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""{0} is not a field of {1}"".format(n, expr)) <MASK> raise TypeError(""on must be a name or field, not: {0}"".format(n)) <TAB>  <TAB> elif n not in fields: <TAB>  <TAB>  <TAB> raise ValueError(""{0} is not a field of {1}"".format(n, expr)) <TAB>  <TAB> append(n) <TAB> return Distinct(expr, tuple(_on))","if not isinstance ( n , _strtypes ) :",192
1811,"def encode(self, msg): <TAB> """"""Encodes the message to the stream encoding."""""" <TAB> stream = self.stream <TAB> rv = msg + ""\n"" <TAB> if (PY2 and is_unicode(rv)) or not ( <TAB>  <TAB> PY2 or is_unicode(rv) or _is_text_stream(stream) <TAB> ): <TAB>  <TAB> enc = self.encoding <MASK> enc = getattr(stream, ""encoding"", None) or ""utf-8"" <TAB>  <TAB> rv = rv.encode(enc, ""replace"") <TAB> return rv",if enc is None :,131
1812,"def color_convert(self, to_color_space, preserve_alpha=True): <TAB> if to_color_space == self.color_space and preserve_alpha: <TAB>  <TAB> return self <TAB> else: <TAB>  <TAB> pixels = pixels_as_float(self.pixels) <TAB>  <TAB> converted = convert_color( <TAB>  <TAB>  <TAB> pixels, self.color_space, to_color_space, preserve_alpha <TAB>  <TAB> ) <MASK> return None <TAB>  <TAB> return Image(converted, to_color_space)",if converted is None :,125
1813,"def seek(self, pos): <TAB> if self.closed: <TAB>  <TAB> raise IOError(""Cannot seek on a closed file"") <TAB> for n, idx in enumerate(self._indexes[::-1]): <TAB>  <TAB> if idx.offset <= pos: <MASK> self._idxiter = iter(self._indexes[-(n + 1) :]) <TAB>  <TAB>  <TAB>  <TAB> self._nextidx() <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> raise Exception(""Cannot seek to pos"") <TAB> self._curfile.seek(pos - self._curidx.offset)",if idx != self . _curidx :,135
1814,"def load_from_json(self, node_data: dict, import_version: float): <TAB> if import_version <= 0.08: <TAB>  <TAB> self.image_pointer = unpack_pointer_property_name( <TAB>  <TAB>  <TAB> bpy.data.images, node_data, ""image_name"" <TAB>  <TAB> ) <MASK> proposed_name = node_data.get(""image_name"") <TAB>  <TAB>  <TAB> self.info(f""image data not found in current {proposed_name}"")",if not self . image_pointer :,126
1815,"def __init__(self, execution_context, aggregate_operators): <TAB> super(_QueryExecutionAggregateEndpointComponent, self).__init__(execution_context) <TAB> self._local_aggregators = [] <TAB> self._results = None <TAB> self._result_index = 0 <TAB> for operator in aggregate_operators: <TAB>  <TAB> if operator == ""Average"": <TAB>  <TAB>  <TAB> self._local_aggregators.append(_AverageAggregator()) <MASK> self._local_aggregators.append(_CountAggregator()) <TAB>  <TAB> elif operator == ""Max"": <TAB>  <TAB>  <TAB> self._local_aggregators.append(_MaxAggregator()) <TAB>  <TAB> elif operator == ""Min"": <TAB>  <TAB>  <TAB> self._local_aggregators.append(_MinAggregator()) <TAB>  <TAB> elif operator == ""Sum"": <TAB>  <TAB>  <TAB> self._local_aggregators.append(_SumAggregator())","elif operator == ""Count"" :",192
1816,"def attrgetter(item): <TAB> items = [None] * len(attribute) <TAB> for i, attribute_part in enumerate(attribute): <TAB>  <TAB> item_i = item <TAB>  <TAB> for part in attribute_part: <TAB>  <TAB>  <TAB> item_i = environment.getitem(item_i, part) <MASK> item_i = postprocess(item_i) <TAB>  <TAB> items[i] = item_i <TAB> return items",if postprocess is not None :,105
1817,"def work(self): <TAB> while True: <TAB>  <TAB> timeout = self.timeout <MASK> timeout = self.idle_timeout <TAB>  <TAB> log.debug(""Wait for {}"".format(timeout)) <TAB>  <TAB> fetch.wait(timeout) <TAB>  <TAB> if shutting_down.is_set(): <TAB>  <TAB>  <TAB> log.info(""Stop fetch worker"") <TAB>  <TAB>  <TAB> break <TAB>  <TAB> self.fetch()",if idle . is_set ( ) :,99
1818,"def testCoreInterfaceIntInputData(): <TAB> result_testing = False <TAB> for _ in range(10): <TAB>  <TAB> hsyncnet_instance = hsyncnet( <TAB>  <TAB>  <TAB> [[1], [2], [3], [20], [21], [22]], 2, initial_type.EQUIPARTITION, ccore=True <TAB>  <TAB> ) <TAB>  <TAB> analyser = hsyncnet_instance.process() <MASK> result_testing = True <TAB>  <TAB>  <TAB> break <TAB> assert result_testing",if len ( analyser . allocate_clusters ( 0.1 ) ) == 2 :,132
1819,"def _gen(): <TAB> buf = [] <TAB> iterable = dataset() <TAB> try: <TAB>  <TAB> while len(buf) < buffer_size: <TAB>  <TAB>  <TAB> buf.append(next(iterable)) <TAB>  <TAB> while 1: <TAB>  <TAB>  <TAB> i = random.randint(0, buffer_size - 1) <TAB>  <TAB>  <TAB> n = next(iterable) <TAB>  <TAB>  <TAB> yield buf[i] <TAB>  <TAB>  <TAB> buf[i] = n <TAB> except StopIteration: <MASK> random.shuffle(buf) <TAB>  <TAB>  <TAB> for i in buf: <TAB>  <TAB>  <TAB>  <TAB> yield i",if len ( buf ) :,137
1820,"def debug_tree(tree): <TAB> l = [] <TAB> for elt in tree: <TAB>  <TAB> if isinstance(elt, (int, long)): <TAB>  <TAB>  <TAB> l.append(_names.get(elt, elt)) <MASK> l.append(elt) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> l.append(debug_tree(elt)) <TAB> return l","elif isinstance ( elt , str ) :",92
1821,"def reverse_code(apps: StateApps, schema_editor: DatabaseSchemaEditor) -> None: <TAB> PreregistrationUser = apps.get_model(""zerver"", ""PreregistrationUser"") <TAB> for user in PreregistrationUser.objects.all(): <MASK> # PreregistrationUser.INVITE_AS['REALM_ADMIN'] <TAB>  <TAB>  <TAB> user.invited_as_admin = True <TAB>  <TAB> else:  # PreregistrationUser.INVITE_AS['MEMBER'] <TAB>  <TAB>  <TAB> user.invited_as_admin = False <TAB>  <TAB> user.save(update_fields=[""invited_as_admin""])",if user . invited_as == 2 :,151
1822,"def _fastqc_data_section(self, section_name): <TAB> out = [] <TAB> in_section = False <TAB> data_file = os.path.join(self._dir, ""fastqc_data.txt"") <TAB> if os.path.exists(data_file): <TAB>  <TAB> with open(data_file) as in_handle: <TAB>  <TAB>  <TAB> for line in in_handle: <TAB>  <TAB>  <TAB>  <TAB> if line.startswith("">>%s"" % section_name): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> in_section = True <TAB>  <TAB>  <TAB>  <TAB> elif in_section: <MASK> break <TAB>  <TAB>  <TAB>  <TAB>  <TAB> out.append(line.rstrip(""\r\n"")) <TAB> return out","if line . startswith ( "">>END"" ) :",173
1823,"def determine_block_hints(self, text): <TAB> hints = """" <TAB> if text: <TAB>  <TAB> if text[0] in "" \n\x85\u2028\u2029"": <TAB>  <TAB>  <TAB> hints += str(self.best_indent) <MASK> hints += ""-"" <TAB>  <TAB> elif len(text) == 1 or text[-2] in ""\n\x85\u2028\u2029"": <TAB>  <TAB>  <TAB> hints += ""+"" <TAB> return hints","if text [ - 1 ] not in ""\n\x85\u2028\u2029"" :",132
1824,"def database_app(request): <TAB> if request.param == ""postgres_app"": <TAB>  <TAB> if not which(""initdb""): <TAB>  <TAB>  <TAB> pytest.skip(""initdb must be on PATH for postgresql fixture"") <TAB>  <TAB> if not psycopg2: <TAB>  <TAB>  <TAB> pytest.skip(""psycopg2 must be installed for postgresql fixture"") <TAB> if request.param == ""sqlite_rabbitmq_app"": <MASK> pytest.skip( <TAB>  <TAB>  <TAB>  <TAB> ""rabbitmq tests will be skipped if GALAXY_TEST_AMQP_INTERNAL_CONNECTION env var is unset"" <TAB>  <TAB>  <TAB> ) <TAB> return request.getfixturevalue(request.param)","if not os . environ . get ( ""GALAXY_TEST_AMQP_INTERNAL_CONNECTION"" ) :",174
1825,"def do_rollout(agent, env, num_steps, render=False): <TAB> total_rew = 0 <TAB> ob = env.reset() <TAB> for t in range(num_steps): <TAB>  <TAB> a = agent.act(ob) <TAB>  <TAB> (ob, reward, done, _info) = env.step(a) <TAB>  <TAB> total_rew += reward <MASK> env.render() <TAB>  <TAB> if done: <TAB>  <TAB>  <TAB> break <TAB> return total_rew, t + 1",if render and t % 3 == 0 :,126
1826,"def _handle_subrepos(self, ctx, dirty_trees): <TAB> substate = util.parse_hgsubstate(ctx["".hgsubstate""].data().splitlines()) <TAB> sub = util.OrderedDict() <TAB> if "".hgsub"" in ctx: <TAB>  <TAB> sub = util.parse_hgsub(ctx["".hgsub""].data().splitlines()) <TAB> for path, sha in substate.iteritems(): <TAB>  <TAB> # Ignore non-Git repositories keeping state in .hgsubstate. <MASK> continue <TAB>  <TAB> d = os.path.dirname(path) <TAB>  <TAB> dirty_trees.add(d) <TAB>  <TAB> tree = self._dirs.setdefault(d, dulobjs.Tree()) <TAB>  <TAB> tree.add(os.path.basename(path), dulobjs.S_IFGITLINK, sha)","if path in sub and not sub [ path ] . startswith ( ""[git]"" ) :",197
1827,"def get_property_file_image_choices(self, pipeline): <TAB> columns = pipeline.get_measurement_columns() <TAB> image_names = [] <TAB> for column in columns: <TAB>  <TAB> object_name, feature, coltype = column[:3] <TAB>  <TAB> choice = feature[(len(C_FILE_NAME) + 1) :] <MASK> image_names.append(choice) <TAB> return image_names","if object_name == ""Image"" and ( feature . startswith ( C_FILE_NAME ) ) :",118
1828,"def check_all_decorator_order(): <TAB> """"""Check that in all test files, the slow decorator is always last."""""" <TAB> errors = [] <TAB> for fname in os.listdir(PATH_TO_TESTS): <MASK> filename = os.path.join(PATH_TO_TESTS, fname) <TAB>  <TAB>  <TAB> new_errors = check_decorator_order(filename) <TAB>  <TAB>  <TAB> errors += [f""- {filename}, line {i}"" for i in new_errors] <TAB> if len(errors) > 0: <TAB>  <TAB> msg = ""\n"".join(errors) <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> f""The parameterized decorator (and its variants) should always be first, but this is not the case in the following files:\n{msg}"" <TAB>  <TAB> )","if fname . endswith ( "".py"" ) :",182
1829,"def on_edit_button_clicked(self, event=None, a=None, col=None): <TAB> tree, tree_id = self.treeView.get_selection().get_selected() <TAB> watchdir_id = str(self.store.get_value(tree_id, 0)) <TAB> if watchdir_id: <TAB>  <TAB> if col and col.get_title() == _(""Active""): <MASK> client.autoadd.disable_watchdir(watchdir_id) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> client.autoadd.enable_watchdir(watchdir_id) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.opts_dialog.show(self.watchdirs[watchdir_id], watchdir_id)","if self . watchdirs [ watchdir_id ] [ ""enabled"" ] :",187
1830,"def get_conv_output_size(input_size, kernel_size, stride, padding, dilation): <TAB> ndim = len(input_size) <TAB> output_size = [] <TAB> for i in range(ndim): <TAB>  <TAB> size = ( <TAB>  <TAB>  <TAB> input_size[i] + 2 * padding[i] - dilation[i] * (kernel_size[i] - 1) - 1 <TAB>  <TAB> ) // stride[i] + 1 <MASK> output_size.append(1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> output_size.append(size) <TAB> return output_size",if kernel_size [ i ] == - 1 :,151
1831,"def from_location(cls, location, basename, metadata=None, **kw): <TAB> project_name, version, py_version, platform = [None] * 4 <TAB> basename, ext = os.path.splitext(basename) <TAB> if ext.lower() in ("".egg"", "".egg-info""): <TAB>  <TAB> match = EGG_NAME(basename) <MASK> project_name, version, py_version, platform = match.group( <TAB>  <TAB>  <TAB>  <TAB> ""name"", ""ver"", ""pyver"", ""plat"" <TAB>  <TAB>  <TAB> ) <TAB> return cls( <TAB>  <TAB> location, <TAB>  <TAB> metadata, <TAB>  <TAB> project_name=project_name, <TAB>  <TAB> version=version, <TAB>  <TAB> py_version=py_version, <TAB>  <TAB> platform=platform, <TAB>  <TAB> **kw <TAB> )",if match :,187
1832,"def __new__(metacls, typename, bases, namespace): <TAB> annotations = namespace.get(""__annotations__"", {}) <TAB> for t in annotations.values(): <MASK> for ut in t.__args__: <TAB>  <TAB>  <TAB>  <TAB> _assert_tensorizer_type(ut) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _assert_tensorizer_type(t) <TAB> return super().__new__(metacls, typename, bases, namespace)","if getattr ( t , ""__origin__"" , """" ) is Union :",110
1833,"def decode_content(self): <TAB> """"""Return the best possible representation of the response body."""""" <TAB> ct = self.headers.get(""content-type"") <TAB> if ct: <TAB>  <TAB> ct, options = parse_options_header(ct) <TAB>  <TAB> charset = options.get(""charset"") <MASK> return self.json(charset) <TAB>  <TAB> elif ct.startswith(""text/""): <TAB>  <TAB>  <TAB> return self.text(charset) <TAB>  <TAB> elif ct == FORM_URL_ENCODED: <TAB>  <TAB>  <TAB> return parse_qsl(self.content.decode(charset), keep_blank_values=True) <TAB> return self.content",if ct in JSON_CONTENT_TYPES :,156
1834,"def get_full_path(path): <TAB> if ""://"" not in path: <TAB>  <TAB> path = os.path.join(self.AUTO_COLL_TEMPL, path, """") <MASK> path = os.path.join(abs_path, path) <TAB> return path",if abs_path :,71
1835,"def __getitem__(self, name_or_path): <TAB> if isinstance(name_or_path, integer_types): <TAB>  <TAB> return list.__getitem__(self, name_or_path) <TAB> elif isinstance(name_or_path, tuple): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> val = self <TAB>  <TAB>  <TAB> for fid in name_or_path: <MASK> raise KeyError  # path contains base value <TAB>  <TAB>  <TAB>  <TAB> val = val[fid] <TAB>  <TAB>  <TAB> return val <TAB>  <TAB> except (KeyError, IndexError): <TAB>  <TAB>  <TAB> raise KeyError(name_or_path) <TAB> else: <TAB>  <TAB> raise TypeError(self._INDEX_ERROR % name_or_path)","if not isinstance ( val , FeatStruct ) :",170
1836,"def scan(scope): <TAB> for s in scope.children: <TAB>  <TAB> if s.start_pos <= position <= s.end_pos: <TAB>  <TAB>  <TAB> if isinstance(s, (tree.Scope, tree.Flow)): <TAB>  <TAB>  <TAB>  <TAB> return scan(s) or s <MASK> return scan(s) <TAB> return None","elif s . type in ( ""suite"" , ""decorated"" ) :",92
1837,"def _get_key(self): <TAB> if not self.key: <TAB>  <TAB> self._channel.send(u""pake"", self.msg1) <TAB>  <TAB> pake_msg = self._channel.get(u""pake"") <TAB>  <TAB> self.key = self.sp.finish(pake_msg) <TAB>  <TAB> self.verifier = self.derive_key(u""wormhole:verifier"") <MASK> return <TAB>  <TAB> confkey = self.derive_key(u""wormhole:confirmation"") <TAB>  <TAB> nonce = os.urandom(CONFMSG_NONCE_LENGTH) <TAB>  <TAB> confmsg = make_confmsg(confkey, nonce) <TAB>  <TAB> self._channel.send(u""_confirm"", confmsg)",if not self . _send_confirm :,181
1838,"def executeScript(self, script): <TAB> if len(script) > 0: <TAB>  <TAB> commands = [] <TAB>  <TAB> for l in script: <TAB>  <TAB>  <TAB> extracted = self.extract_command(l) <MASK> commands.append(extracted) <TAB>  <TAB> for command in commands: <TAB>  <TAB>  <TAB> cmd, argv = command <TAB>  <TAB>  <TAB> self.dispatch_command(cmd, argv)",if extracted :,98
1839,"def create_path(n, fullname, meta): <TAB> if meta: <TAB>  <TAB> meta.create_path(fullname) <TAB> else: <TAB>  <TAB> # These fallbacks are important -- meta could be null if, for <TAB>  <TAB> # example, save created a ""fake"" item, i.e. a new strip/graft <TAB>  <TAB> # path element, etc.  You can find cases like that by <TAB>  <TAB> # searching for ""Metadata()"". <TAB>  <TAB> unlink(fullname) <TAB>  <TAB> if stat.S_ISDIR(n.mode): <TAB>  <TAB>  <TAB> mkdirp(fullname) <MASK> os.symlink(n.readlink(), fullname)",elif stat . S_ISLNK ( n . mode ) :,158
1840,def get_cycle(self): <TAB> if self.has_cycle(): <TAB>  <TAB> cross_node = self.path[-1] <MASK> return self.path[self.path.index(cross_node) :] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.path <TAB> return [],if self . path . count ( cross_node ) > 1 :,84
1841,"def _select_block(str_in, start_tag, end_tag): <TAB> """"""Select first block delimited by start_tag and end_tag"""""" <TAB> start_pos = str_in.find(start_tag) <TAB> if start_pos < 0: <TAB>  <TAB> raise ValueError(""start_tag not found"") <TAB> depth = 0 <TAB> for pos in range(start_pos, len(str_in)): <MASK> depth += 1 <TAB>  <TAB> elif str_in[pos] == end_tag: <TAB>  <TAB>  <TAB> depth -= 1 <TAB>  <TAB> if depth == 0: <TAB>  <TAB>  <TAB> break <TAB> sel = str_in[start_pos + 1 : pos] <TAB> return sel",if str_in [ pos ] == start_tag :,171
1842,"def device(self): <TAB> """"""Device on which the data array of this variable reside."""""" <TAB> # lazy initialization for performance <TAB> if self._device is None: <MASK> self._device = backend.CpuDevice() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._device = backend.get_device_from_array(self._data[0]) <TAB> return self._device",if self . _data [ 0 ] is None :,98
1843,"def function_out(*args, **kwargs): <TAB> try: <TAB>  <TAB> return function_in(*args, **kwargs) <TAB> except dbus.exceptions.DBusException as e: <TAB>  <TAB> if e.get_dbus_name() == DBUS_UNKNOWN_METHOD: <TAB>  <TAB>  <TAB> raise ItemNotFoundException(""Item does not exist!"") <MASK> raise ItemNotFoundException(e.get_dbus_message()) <TAB>  <TAB> if e.get_dbus_name() in (DBUS_NO_REPLY, DBUS_NOT_SUPPORTED): <TAB>  <TAB>  <TAB> raise SecretServiceNotAvailableException(e.get_dbus_message()) <TAB>  <TAB> raise",if e . get_dbus_name ( ) == DBUS_NO_SUCH_OBJECT :,162
1844,"def run(self): <TAB> """"""Continual loop evaluating when_statements"""""" <TAB> while len(self.library) > 0: <TAB>  <TAB> for name, expression in self.library.items(): <MASK> del self.library[name] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> expression.evaluate() <TAB>  <TAB> sleep(0.01) <TAB> return",if expression . remove_me == True :,96
1845,"def tamper(payload, **kwargs): <TAB> junk_chars = ""!#$%&()*~+-_.,:;?@[/|\]^`"" <TAB> retval = """" <TAB> for i, char in enumerate(payload, start=1): <TAB>  <TAB> amount = random.randint(10, 15) <MASK> retval += "">"" <TAB>  <TAB>  <TAB> for _ in range(amount): <TAB>  <TAB>  <TAB>  <TAB> retval += random.choice(junk_chars) <TAB>  <TAB> elif char == ""<"": <TAB>  <TAB>  <TAB> retval += ""<"" <TAB>  <TAB>  <TAB> for _ in range(amount): <TAB>  <TAB>  <TAB>  <TAB> retval += random.choice(junk_chars) <TAB>  <TAB> elif char == "" "": <TAB>  <TAB>  <TAB> for _ in range(amount): <TAB>  <TAB>  <TAB>  <TAB> retval += random.choice(junk_chars) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> retval += char <TAB> return retval","if char == "">"" :",200
1846,"def _source_target_path(source, source_path, source_location): <TAB> target_path_attr = source.target_path or source.resdef.target_path <TAB> if source.preserve_path: <MASK> log.warning( <TAB>  <TAB>  <TAB>  <TAB> ""target-path '%s' specified with preserve-path - ignoring"", <TAB>  <TAB>  <TAB>  <TAB> target_path_attr, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return os.path.relpath(os.path.dirname(source_path), source_location) <TAB> else: <TAB>  <TAB> return target_path_attr or source.resdef.target_path or """"",if target_path_attr :,152
1847,"def _load_user_from_header(self, header): <TAB> if self._header_callback: <TAB>  <TAB> user = self._header_callback(header) <MASK> app = current_app._get_current_object() <TAB>  <TAB>  <TAB> user_loaded_from_header.send(app, user=user) <TAB>  <TAB>  <TAB> return user <TAB> return None",if user is not None :,92
1848,"def setup(cls): <TAB> ""Check dependencies and warn about firewalling"" <TAB> pathCheck(""brctl"", moduleName=""bridge-utils"") <TAB> # Disable Linux bridge firewalling so that traffic can flow! <TAB> for table in ""arp"", ""ip"", ""ip6"": <TAB>  <TAB> cmd = ""sysctl net.bridge.bridge-nf-call-%stables"" % table <TAB>  <TAB> out = quietRun(cmd).strip() <MASK> warn(""Warning: Linux bridge may not work with"", out, ""\n"")","if out . endswith ( ""1"" ) :",128
1849,"def _browse_your_music(web_client, variant): <TAB> if not web_client.logged_in: <TAB>  <TAB> return [] <TAB> if variant in (""tracks"", ""albums""): <TAB>  <TAB> items = flatten( <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB> page.get(""items"", []) <TAB>  <TAB>  <TAB>  <TAB> for page in web_client.get_all( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f""me/{variant}"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> params={""market"": ""from_token"", ""limit"": 50}, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> if page <TAB>  <TAB>  <TAB> ] <TAB>  <TAB> ) <MASK> return list(translator.web_to_track_refs(items)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return list(translator.web_to_album_refs(items)) <TAB> else: <TAB>  <TAB> return []","if variant == ""tracks"" :",198
1850,"def reset_styling(self): <TAB> for edge in self.fsm_graph.edges_iter(): <TAB>  <TAB> style_attr = self.fsm_graph.style_attributes.get(""edge"", {}).get(""default"") <TAB>  <TAB> edge.attr.update(style_attr) <TAB> for node in self.fsm_graph.nodes_iter(): <MASK> style_attr = self.fsm_graph.style_attributes.get(""node"", {}).get(""inactive"") <TAB>  <TAB>  <TAB> node.attr.update(style_attr) <TAB> for sub_graph in self.fsm_graph.subgraphs_iter(): <TAB>  <TAB> style_attr = self.fsm_graph.style_attributes.get(""graph"", {}).get(""default"") <TAB>  <TAB> sub_graph.graph_attr.update(style_attr)","if ""point"" not in node . attr [ ""shape"" ] :",200
1851,"def set_message_type_visibility(self, message_type: MessageType): <TAB> try: <TAB>  <TAB> rows = { <TAB>  <TAB>  <TAB> i <TAB>  <TAB>  <TAB> for i, msg in enumerate(self.proto_analyzer.messages) <MASK> } <TAB>  <TAB> if message_type.show: <TAB>  <TAB>  <TAB> self.ui.tblViewProtocol.show_rows(rows) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.ui.tblViewProtocol.hide_rows(rows) <TAB> except Exception as e: <TAB>  <TAB> logger.exception(e)",if msg . message_type == message_type,138
1852,"def POP(cpu, *regs): <TAB> for reg in regs: <TAB>  <TAB> val = cpu.stack_pop(cpu.address_bit_size // 8) <MASK> cpu._set_mode_by_val(val) <TAB>  <TAB>  <TAB> val = val & ~0x1 <TAB>  <TAB> reg.write(val)","if reg . reg in ( ""PC"" , ""R15"" ) :",89
1853,"def processMovie(self, atom): <TAB> for field in atom: <TAB>  <TAB> if ""track"" in field: <TAB>  <TAB>  <TAB> self.processTrack(field[""track""]) <MASK> self.processMovieHeader(field[""movie_hdr""])","if ""movie_hdr"" in field :",69
1854,"def check_update_function(url, folder, update_setter, version_setter, auto): <TAB> remote_version = urllib.urlopen(url).read() <TAB> if remote_version.isdigit(): <TAB>  <TAB> local_version = get_local_timestamp(folder) <MASK> if auto: <TAB>  <TAB>  <TAB>  <TAB> update_setter.set_value(True) <TAB>  <TAB>  <TAB> version_setter.set_value(remote_version) <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> else: <TAB>  <TAB> return False",if remote_version > local_version :,136
1855,"def init(self, view, items=None): <TAB> selections = [] <TAB> if view.sel(): <TAB>  <TAB> for region in view.sel(): <TAB>  <TAB>  <TAB> selections.append(view.substr(region)) <TAB> values = [] <TAB> for idx, index in enumerate(map(int, items)): <TAB>  <TAB> if idx >= len(selections): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> i = index - 1 <MASK> values.append(selections[i]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> values.append(None) <TAB> # fill up <TAB> for idx, value in enumerate(selections): <TAB>  <TAB> if len(values) + 1 < idx: <TAB>  <TAB>  <TAB> values.append(value) <TAB> self.stack = values",if i >= 0 and i < len ( selections ) :,178
1856,"def find_int_identifiers(directory): <TAB> results = find_rules(directory, has_int_identifier) <TAB> print(""Number of rules with integer identifiers: %d"" % len(results)) <TAB> for result in results: <TAB>  <TAB> rule_path = result[0] <TAB>  <TAB> product_yaml_path = result[1] <TAB>  <TAB> product_yaml = None <MASK> product_yaml = yaml.open_raw(product_yaml_path) <TAB>  <TAB> fix_file(rule_path, product_yaml, fix_int_identifier)",if product_yaml_path is not None :,138
1857,"def condition(self): <TAB> if self.__condition is None: <TAB>  <TAB> if len(self.flat_conditions) == 1: <TAB>  <TAB>  <TAB> # Avoid an extra indirection in the common case of only one condition. <TAB>  <TAB>  <TAB> self.__condition = self.flat_conditions[0] <MASK> # Possible, if unlikely, due to filter predicate rewriting <TAB>  <TAB>  <TAB> self.__condition = lambda _: True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.__condition = lambda x: all(cond(x) for cond in self.flat_conditions) <TAB> return self.__condition",elif len ( self . flat_conditions ) == 0 :,143
1858,"def get_scene_exceptions_by_season(self, season=-1): <TAB> scene_exceptions = [] <TAB> for scene_exception in self.scene_exceptions: <MASK> continue <TAB>  <TAB> scene_name, scene_season = scene_exception.split(""|"") <TAB>  <TAB> if season == scene_season: <TAB>  <TAB>  <TAB> scene_exceptions.append(scene_name) <TAB> return scene_exceptions",if not len ( scene_exception ) == 2 :,121
1859,"def init(self, view, items=None): <TAB> selections = [] <TAB> if view.sel(): <TAB>  <TAB> for region in view.sel(): <TAB>  <TAB>  <TAB> selections.append(view.substr(region)) <TAB> values = [] <TAB> for idx, index in enumerate(map(int, items)): <MASK> break <TAB>  <TAB> i = index - 1 <TAB>  <TAB> if i >= 0 and i < len(selections): <TAB>  <TAB>  <TAB> values.append(selections[i]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> values.append(None) <TAB> # fill up <TAB> for idx, value in enumerate(selections): <TAB>  <TAB> if len(values) + 1 < idx: <TAB>  <TAB>  <TAB> values.append(value) <TAB> self.stack = values",if idx >= len ( selections ) :,178
1860,"def to_tool_path(self, path_or_uri_like, **kwds): <TAB> if ""://"" not in path_or_uri_like: <TAB>  <TAB> path = path_or_uri_like <TAB> else: <TAB>  <TAB> uri_like = path_or_uri_like <MASK> raise Exception(""Invalid URI passed to get_tool_source"") <TAB>  <TAB> scheme, rest = uri_like.split("":"", 2) <TAB>  <TAB> if scheme not in self.resolver_classes: <TAB>  <TAB>  <TAB> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> ""Unknown tool scheme [{}] for URI [{}]"".format(scheme, uri_like) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> path = self.resolver_classes[scheme]().get_tool_source_path(uri_like) <TAB> return path","if "":"" not in path_or_uri_like :",188
1861,def mainWindow(): <TAB> global MW <TAB> if not MW: <TAB>  <TAB> for i in qApp.topLevelWidgets(): <MASK> MW = i <TAB>  <TAB>  <TAB>  <TAB> return MW <TAB>  <TAB> return None <TAB> else: <TAB>  <TAB> return MW,"if i . objectName ( ) == ""MainWindow"" :",78
1862,"def async_get_service(hass, config, discovery_info=None): <TAB> # pylint: disable=unused-argument <TAB> """"""Get the demo notification service."""""" <TAB> for account, account_dict in hass.data[DATA_ALEXAMEDIA][""accounts""].items(): <TAB>  <TAB> for key, _ in account_dict[""devices""][""media_player""].items(): <MASK> _LOGGER.debug( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""%s: Media player %s not loaded yet; delaying load"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> hide_email(account), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> hide_serial(key), <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return AlexaNotificationService(hass)","if key not in account_dict [ ""entities"" ] [ ""media_player"" ] :",182
1863,"def _migrate_bool(self, name: str, true_value: str, false_value: str) -> None: <TAB> if name not in self._settings: <TAB>  <TAB> return <TAB> values = self._settings[name] <TAB> if not isinstance(values, dict): <TAB>  <TAB> return <TAB> for scope, val in values.items(): <MASK> new_value = true_value if val else false_value <TAB>  <TAB>  <TAB> self._settings[name][scope] = new_value <TAB>  <TAB>  <TAB> self.changed.emit()","if isinstance ( val , bool ) :",130
1864,"def send(self, data, flags=0): <TAB> self._checkClosed() <TAB> if self._sslobj: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""non-zero flags not allowed in calls to send() on %s"" % self.__class__ <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return self._sslobj.write(data) <TAB> else: <TAB>  <TAB> return socket.send(self, data, flags)",if flags != 0 :,106
1865,"def rec_deps(services, container_by_name, cnt, init_service): <TAB> deps = cnt[""_deps""] <TAB> for dep in deps.copy(): <TAB>  <TAB> dep_cnts = services.get(dep) <TAB>  <TAB> if not dep_cnts: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> dep_cnt = container_by_name.get(dep_cnts[0]) <MASK> # TODO: avoid creating loops, A->B->A <TAB>  <TAB>  <TAB> if init_service and init_service in dep_cnt[""_deps""]: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> new_deps = rec_deps(services, container_by_name, dep_cnt, init_service) <TAB>  <TAB>  <TAB> deps.update(new_deps) <TAB> return deps",if dep_cnt :,181
1866,"def as_dict(path="""", version=""latest"", section=""meta-data""): <TAB> result = {} <TAB> dirs = dir(path, version, section) <TAB> if not dirs: <TAB>  <TAB> return None <TAB> for item in dirs: <TAB>  <TAB> if item.endswith(""/""): <TAB>  <TAB>  <TAB> records = as_dict(path + item, version, section) <TAB>  <TAB>  <TAB> if records: <TAB>  <TAB>  <TAB>  <TAB> result[item[:-1]] = records <MASK> idx, name = is_dict.match(item).groups() <TAB>  <TAB>  <TAB> records = as_dict(path + idx + ""/"", version, section) <TAB>  <TAB>  <TAB> if records: <TAB>  <TAB>  <TAB>  <TAB> result[name] = records <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result[item] = valueconv(get(path + item, version, section)) <TAB> return result",elif is_dict . match ( item ) :,197
1867,"def PrintColGroup(col_names, schema): <TAB> """"""Print HTML colgroup element, used for JavaScript sorting."""""" <TAB> print(""  <colgroup>"") <TAB> for i, col in enumerate(col_names): <TAB>  <TAB> if col.endswith(""_HREF""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # CSS class is used for sorting <MASK> css_class = ""number"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> css_class = ""case-insensitive"" <TAB>  <TAB> # NOTE: id is a comment only; not used <TAB>  <TAB> print(' <TAB> <col id=""{}"" type=""{}"" />'.format(col, css_class)) <TAB> print(""  </colgroup>"")",if schema . IsNumeric ( col ) :,161
1868,"def check_region(self, region): <TAB> for other in self.regions: <MASK> continue <TAB>  <TAB> if (other.start < region.start < other.end) or ( <TAB>  <TAB>  <TAB> other.start < region.end < other.end <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> raise Exception(""%r overlaps with %r"" % (region, other))",if other is region :,89
1869,"def _write_value(self, rng, value, scalar): <TAB> if rng.api and value: <TAB>  <TAB> # it is assumed by this stage that value is a list of lists <MASK> value = value[0][0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> rng = rng.resize(len(value), len(value[0])) <TAB>  <TAB> rng.raw_value = value",if scalar :,94
1870,"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> length = d.getVarInt32() <TAB>  <TAB>  <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB>  <TAB>  <TAB> d.skip(length) <TAB>  <TAB>  <TAB> self.mutable_cost().TryMerge(tmp) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 24: <TAB>  <TAB>  <TAB> self.add_version(d.getVarInt64()) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,167
1871,"def generate_sv_faces(dcel_mesh, point_index, only_select=False, del_flag=None): <TAB> # This part of function creates faces in SV format <TAB> # It ignores  boundless super face <TAB> sv_faces = [] <TAB> for i, face in enumerate(dcel_mesh.faces): <MASK> ""Face ({}) has inner components! Sverchok cant show polygons with holes."".format( <TAB>  <TAB>  <TAB>  <TAB> i <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if not face.outer or del_flag in face.flags: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if only_select and not face.select: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> sv_faces.append([point_index[hedge.origin] for hedge in face.outer.loop_hedges]) <TAB> return sv_faces",if face . inners and face . outer :,198
1872,"def _get_x_for_y(self, xValue, x, y): <TAB> # print(""searching ""+x+"" with the value ""+str(xValue)+"" and want to give back ""+y) <TAB> x_value = str(xValue) <TAB> for anime in self.xmlMap.findall(""anime""): <TAB>  <TAB> try: <MASK> return int(anime.get(y, 0)) <TAB>  <TAB> except ValueError as e: <TAB>  <TAB>  <TAB> continue <TAB> return 0","if anime . get ( x , False ) == x_value :",131
1873,"def dir_copy(src_dir, dest_dir, merge_if_exists=True): <TAB> try: <TAB>  <TAB> if not os.path.exists(dest_dir): <TAB>  <TAB>  <TAB> shutil.copytree(src_dir, dest_dir) <MASK> merge_dir(src_dir, dest_dir) <TAB> except OSError as e: <TAB>  <TAB> # If source is not a directory, copy with shutil.copy <TAB>  <TAB> if e.errno == errno.ENOTDIR: <TAB>  <TAB>  <TAB> shutil.copy(src_dir, dest_dir) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logging.error(""Could not copy %s to %s"", src_dir, dest_dir)",elif merge_if_exists :,166
1874,"def mapping(self): <TAB> m = {} <TAB> if getGdriveCredentialsFile() is not None: <TAB>  <TAB> m[""gdrive""] = """" <TAB> unknown = 0 <TAB> for f in self.scan: <TAB>  <TAB> bits = f.split(""#"", 2) <TAB>  <TAB> if len(bits) == 1: <TAB>  <TAB>  <TAB> label = os.path.basename(f) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> label = bits[1] <MASK> label = ""L"" + str(unknown) <TAB>  <TAB>  <TAB> unknown += 1 <TAB>  <TAB> m[label] = bits[0] <TAB> return m","if not label or len ( label ) == 0 or label == """" :",153
1875,"def get_tag_values(self, event): <TAB> http = event.interfaces.get(""sentry.interfaces.Http"") <TAB> if not http: <TAB>  <TAB> return [] <TAB> if not http.headers: <TAB>  <TAB> return [] <TAB> headers = http.headers <TAB> # XXX: transitional support for workers <TAB> if isinstance(headers, dict): <TAB>  <TAB> headers = headers.items() <TAB> output = [] <TAB> for key, value in headers: <TAB>  <TAB> if key != ""User-Agent"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> ua = Parse(value) <MASK> continue <TAB>  <TAB> result = self.get_tag_from_ua(ua) <TAB>  <TAB> if result: <TAB>  <TAB>  <TAB> output.append(result) <TAB> return output",if not ua :,176
1876,"def __iter__(self): <TAB> it = DiskHashMerger.__iter__(self) <TAB> direct_upstreams = self.direct_upstreams <TAB> for k, groups in it: <TAB>  <TAB> t = list([[] for _ in range(self.size)]) <TAB>  <TAB> for i, g in enumerate(groups): <TAB>  <TAB>  <TAB> if g: <MASK> t[i] = g <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> g.sort(key=itemgetter(0)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> g1 = [] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for _, vs in g: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> g1.extend(vs) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> t[i] = g1 <TAB>  <TAB> yield k, tuple(t)",if i in direct_upstreams :,185
1877,"def process_question(qtxt): <TAB> question = """" <TAB> skip = False <TAB> for letter in qtxt: <MASK> skip = True <TAB>  <TAB> if letter == "">"": <TAB>  <TAB>  <TAB> skip = False <TAB>  <TAB> if skip: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if letter.isalnum() or letter == "" "": <TAB>  <TAB>  <TAB> if letter == "" "": <TAB>  <TAB>  <TAB>  <TAB> letter = ""_"" <TAB>  <TAB>  <TAB> question += letter.lower() <TAB> return question","if letter == ""<"" :",110
1878,"def _module_repr_from_spec(spec): <TAB> """"""Return the repr to use for the module."""""" <TAB> # We mostly replicate _module_repr() using the spec attributes. <TAB> name = ""?"" if spec.name is None else spec.name <TAB> if spec.origin is None: <TAB>  <TAB> if spec.loader is None: <TAB>  <TAB>  <TAB> return ""<module {!r}>"".format(name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""<module {!r} ({!r})>"".format(name, spec.loader) <TAB> else: <MASK> return ""<module {!r} from {!r}>"".format(name, spec.origin) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""<module {!r} ({})>"".format(spec.name, spec.origin)",if spec . has_location :,180
1879,"def test_row(self, row): <TAB> for idx, test in self.patterns.items(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> value = row[idx] <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB> value = """" <TAB>  <TAB> result = test(value) <TAB>  <TAB> if self.any_match: <TAB>  <TAB>  <TAB> if result: <TAB>  <TAB>  <TAB>  <TAB> return not self.inverse  # True <TAB>  <TAB> else: <MASK> return self.inverse  # False <TAB> if self.any_match: <TAB>  <TAB> return self.inverse  # False <TAB> else: <TAB>  <TAB> return not self.inverse  # True",if not result :,149
1880,"def frequent_thread_switches(): <TAB> """"""Make concurrency bugs more likely to manifest."""""" <TAB> interval = None <TAB> if not sys.platform.startswith(""java""): <MASK> interval = sys.getswitchinterval() <TAB>  <TAB>  <TAB> sys.setswitchinterval(1e-6) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> interval = sys.getcheckinterval() <TAB>  <TAB>  <TAB> sys.setcheckinterval(1) <TAB> try: <TAB>  <TAB> yield <TAB> finally: <TAB>  <TAB> if not sys.platform.startswith(""java""): <TAB>  <TAB>  <TAB> if hasattr(sys, ""setswitchinterval""): <TAB>  <TAB>  <TAB>  <TAB> sys.setswitchinterval(interval) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> sys.setcheckinterval(interval)","if hasattr ( sys , ""getswitchinterval"" ) :",177
1881,"def record_expected_exportable_production(self, ticks): <TAB> """"""Record the amount of production that should be transferred to other islands."""""" <TAB> for (quota_holder, resource_id), amount in self._low_priority_requests.items(): <MASK> self._settlement_manager_id[quota_holder] = WorldObject.get_object_by_id( <TAB>  <TAB>  <TAB>  <TAB> int(quota_holder[1:].split("","")[0]) <TAB>  <TAB>  <TAB> ).settlement_manager.worldid <TAB>  <TAB> self.trade_storage[self._settlement_manager_id[quota_holder]][resource_id] += ( <TAB>  <TAB>  <TAB> ticks * amount <TAB>  <TAB> )",if quota_holder not in self . _settlement_manager_id :,168
1882,"def _method_events_callback(self, values): <TAB> try: <TAB>  <TAB> previous_echoed = ( <TAB>  <TAB>  <TAB> values[""child_result_list""][-1].decode().split(""\n"")[-2].strip() <TAB>  <TAB> ) <MASK> return ""echo foo2\n"" <TAB>  <TAB> elif previous_echoed.endswith(""foo2""): <TAB>  <TAB>  <TAB> return ""echo foo3\n"" <TAB>  <TAB> elif previous_echoed.endswith(""foo3""): <TAB>  <TAB>  <TAB> return ""exit\n"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception(""Unexpected output {0!r}"".format(previous_echoed)) <TAB> except IndexError: <TAB>  <TAB> return ""echo foo1\n""","if previous_echoed . endswith ( ""foo1"" ) :",172
1883,"def describe_cluster_snapshots(self, cluster_identifier=None, snapshot_identifier=None): <TAB> if cluster_identifier: <TAB>  <TAB> cluster_snapshots = [] <TAB>  <TAB> for snapshot in self.snapshots.values(): <MASK> cluster_snapshots.append(snapshot) <TAB>  <TAB> if cluster_snapshots: <TAB>  <TAB>  <TAB> return cluster_snapshots <TAB> if snapshot_identifier: <TAB>  <TAB> if snapshot_identifier in self.snapshots: <TAB>  <TAB>  <TAB> return [self.snapshots[snapshot_identifier]] <TAB>  <TAB> raise ClusterSnapshotNotFoundError(snapshot_identifier) <TAB> return self.snapshots.values()",if snapshot . cluster . cluster_identifier == cluster_identifier :,149
1884,def get_snippet_edit_handler(model): <TAB> if model not in SNIPPET_EDIT_HANDLERS: <MASK> # use the edit handler specified on the page class <TAB>  <TAB>  <TAB> edit_handler = model.edit_handler <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> panels = extract_panel_definitions_from_model_class(model) <TAB>  <TAB>  <TAB> edit_handler = ObjectList(panels) <TAB>  <TAB> SNIPPET_EDIT_HANDLERS[model] = edit_handler.bind_to(model=model) <TAB> return SNIPPET_EDIT_HANDLERS[model],"if hasattr ( model , ""edit_handler"" ) :",137
1885,"def start(): <TAB> if os.environ.get(""RUN_MAIN"") != ""true"": <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> exit_code = restart_with_reloader() <MASK> os.kill(os.getpid(), -exit_code) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> sys.exit(exit_code) <TAB>  <TAB> except KeyboardInterrupt: <TAB>  <TAB>  <TAB> pass",if exit_code < 0 :,100
1886,"def discover(self, *objlist): <TAB> ret = [] <TAB> for l in self.splitlines(): <TAB>  <TAB> if len(l) < 5: <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> int(l[2]) <TAB>  <TAB>  <TAB> int(l[3]) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # <TAB>  <TAB>    ret.append(improve(l[0])) <TAB>  <TAB> ret.append(l[0]) <TAB> ret.sort() <TAB> for item in objlist: <TAB>  <TAB> ret.append(item) <TAB> return ret","if l [ 0 ] == ""Filename"" :",154
1887,"def ipfs_publish(self, lib): <TAB> with tempfile.NamedTemporaryFile() as tmp: <TAB>  <TAB> self.ipfs_added_albums(lib, tmp.name) <TAB>  <TAB> try: <MASK> cmd = ""ipfs add --nocopy -q "".split() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> cmd = ""ipfs add -q "".split() <TAB>  <TAB>  <TAB> cmd.append(tmp.name) <TAB>  <TAB>  <TAB> output = util.command_output(cmd) <TAB>  <TAB> except (OSError, subprocess.CalledProcessError) as err: <TAB>  <TAB>  <TAB> msg = ""Failed to publish library. Error: {0}"".format(err) <TAB>  <TAB>  <TAB> self._log.error(msg) <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> self._log.info(""hash of library: {0}"", output)","if self . config [ ""nocopy"" ] :",188
1888,"def spends(self): <TAB> # Return spends indexed by hashX <TAB> spends = defaultdict(list) <TAB> utxos = self.mempool_utxos() <TAB> for tx_hash, tx in self.txs.items(): <TAB>  <TAB> for n, input in enumerate(tx.inputs): <TAB>  <TAB>  <TAB> if input.is_generation(): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> prevout = (input.prev_hash, input.prev_idx) <MASK> hashX, value = utxos.pop(prevout) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> hashX, value = self.db_utxos[prevout] <TAB>  <TAB>  <TAB> spends[hashX].append(prevout) <TAB> return spends",if prevout in utxos :,188
1889,"def terminate(self): <TAB> if self.returncode is None: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> os.kill(self.pid, TERM_SIGNAL) <TAB>  <TAB> except OSError as exc: <TAB>  <TAB>  <TAB> if getattr(exc, ""errno"", None) != errno.ESRCH: <MASK> raise",if self . wait ( timeout = 0.1 ) is None :,92
1890,"def _getVolumeScalar(self): <TAB> if self._volumeScalar is not None: <TAB>  <TAB> return self._volumeScalar <TAB> # use default <TAB> elif self._value in dynamicStrToScalar: <TAB>  <TAB> return dynamicStrToScalar[self._value] <TAB> else: <TAB>  <TAB> thisDynamic = self._value <TAB>  <TAB> # ignore leading s like in sf <MASK> thisDynamic = thisDynamic[1:] <TAB>  <TAB> # ignore closing z like in fz <TAB>  <TAB> if thisDynamic[-1] == ""z"": <TAB>  <TAB>  <TAB> thisDynamic = thisDynamic[:-1] <TAB>  <TAB> if thisDynamic in dynamicStrToScalar: <TAB>  <TAB>  <TAB> return dynamicStrToScalar[thisDynamic] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return dynamicStrToScalar[None]","if ""s"" in thisDynamic :",183
1891,"def init_values(self): <TAB> config = self._raw_config <TAB> for valname, value in self.overrides.iteritems(): <TAB>  <TAB> if ""."" in valname: <TAB>  <TAB>  <TAB> realvalname, key = valname.split(""."", 1) <TAB>  <TAB>  <TAB> config.setdefault(realvalname, {})[key] = value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> config[valname] = value <TAB> for name in config: <MASK> self.__dict__[name] = config[name] <TAB> del self._raw_config",if name in self . values :,131
1892,"def modified(self): <TAB> paths = set() <TAB> dictionary_list = [] <TAB> for op_list in self._operations: <TAB>  <TAB> if not isinstance(op_list, list): <TAB>  <TAB>  <TAB> op_list = (op_list,) <TAB>  <TAB> for item in chain(*op_list): <TAB>  <TAB>  <TAB> if item is None: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> dictionary = item.dictionary <MASK> continue <TAB>  <TAB>  <TAB> paths.add(dictionary.path) <TAB>  <TAB>  <TAB> dictionary_list.append(dictionary) <TAB> return dictionary_list",if dictionary . path in paths :,139
1893,"def __getitem__(self, key, _get_mode=False): <TAB> if not _get_mode: <MASK> return self._list[key] <TAB>  <TAB> elif isinstance(key, slice): <TAB>  <TAB>  <TAB> return self.__class__(self._list[key]) <TAB> ikey = key.lower() <TAB> for k, v in self._list: <TAB>  <TAB> if k.lower() == ikey: <TAB>  <TAB>  <TAB> return v <TAB> # micro optimization: if we are in get mode we will catch that <TAB> # exception one stack level down so we can raise a standard <TAB> # key error instead of our special one. <TAB> if _get_mode: <TAB>  <TAB> raise KeyError() <TAB> raise BadRequestKeyError(key)","if isinstance ( key , ( int , long ) ) :",176
1894,"def _get_items(self, name, target=1): <TAB> all_items = self.get_items(name) <TAB> items = [o for o in all_items if not o.disabled] <TAB> if len(items) < target: <MASK> raise ItemNotFoundError(""insufficient items with name %r"" % name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise AttributeError(""insufficient non-disabled items with name %s"" % name) <TAB> on = [] <TAB> off = [] <TAB> for o in items: <TAB>  <TAB> if o.selected: <TAB>  <TAB>  <TAB> on.append(o) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> off.append(o) <TAB> return on, off",if len ( all_items ) < target :,169
1895,"def get_genome_dir(gid, galaxy_dir, data): <TAB> """"""Return standard location of genome directories."""""" <TAB> if galaxy_dir: <TAB>  <TAB> refs = genome.get_refs(gid, None, galaxy_dir, data) <TAB>  <TAB> seq_file = tz.get_in([""fasta"", ""base""], refs) <MASK> return os.path.dirname(os.path.dirname(seq_file)) <TAB> else: <TAB>  <TAB> gdirs = glob.glob(os.path.join(_get_data_dir(), ""genomes"", ""*"", gid)) <TAB>  <TAB> if len(gdirs) == 1 and os.path.exists(gdirs[0]): <TAB>  <TAB>  <TAB> return gdirs[0]",if seq_file and os . path . exists ( seq_file ) :,190
1896,"def _PrintFuncs(self, names): <TAB> # type: (List[str]) -> int <TAB> status = 0 <TAB> for name in names: <MASK> print(name) <TAB>  <TAB>  <TAB> # TODO: Could print LST for -f, or render LST.  Bash does this.  'trap' <TAB>  <TAB>  <TAB> # could use that too. <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> status = 1 <TAB> return status",if name in self . funcs :,110
1897,"def package_files(self): <TAB> seen_package_directories = () <TAB> directories = self.distribution.package_dir or {} <TAB> empty_directory_exists = """" in directories <TAB> packages = self.distribution.packages or [] <TAB> for package in packages: <TAB>  <TAB> if package in directories: <TAB>  <TAB>  <TAB> package_directory = directories[package] <TAB>  <TAB> elif empty_directory_exists: <TAB>  <TAB>  <TAB> package_directory = os.path.join(directories[""""], package) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> package_directory = package <MASK> seen_package_directories += (package_directory + ""."",) <TAB>  <TAB>  <TAB> yield package_directory",if not package_directory . startswith ( seen_package_directories ) :,164
1898,"def apply_conf_file(fn, conf_filename): <TAB> for env in LSF_CONF_ENV: <TAB>  <TAB> conf_file = get_conf_file(conf_filename, env) <MASK> with open(conf_file) as conf_handle: <TAB>  <TAB>  <TAB>  <TAB> value = fn(conf_handle) <TAB>  <TAB>  <TAB> if value: <TAB>  <TAB>  <TAB>  <TAB> return value <TAB> return None",if conf_file :,101
1899,"def on_text(self, text): <TAB> if text != self.chosen_text: <TAB>  <TAB> self.fail_test('Expected ""{}"", received ""{}""'.format(self.chosen_text, text)) <TAB> else: <TAB>  <TAB> self.checks_passed += 1 <MASK> self.pass_test() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._select_next_text()",if self . checks_passed >= self . number_of_checks :,103
1900,"def test_field_attr_existence(self): <TAB> for name, item in ast.__dict__.items(): <TAB>  <TAB> if self._is_ast_node(name, item): <MASK> # Index(value) just returns value now. <TAB>  <TAB>  <TAB>  <TAB> # The argument is required. <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> x = item() <TAB>  <TAB>  <TAB> if isinstance(x, ast.AST): <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(type(x._fields), tuple)","if name == ""Index"" :",122
1901,"def apply(self, response): <TAB> updated_headers = self.update_headers(response) <TAB> if updated_headers: <TAB>  <TAB> response.headers.update(updated_headers) <TAB>  <TAB> warning_header_value = self.warning(response) <MASK> response.headers.update({""Warning"": warning_header_value}) <TAB> return response",if warning_header_value is not None :,92
1902,"def validate(self): <TAB> self.assertEqual(len(self.inputs), len(self.outputs)) <TAB> for batch_in, batch_out in zip(self.inputs, self.outputs): <TAB>  <TAB> self.assertEqual(len(batch_in), len(batch_out)) <TAB>  <TAB> if self.use_parallel_executor and not self.use_double_buffer: <TAB>  <TAB>  <TAB> self.validate_unordered_batch(batch_in, batch_out) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for in_data, out_data in zip(batch_in, batch_out): <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(in_data.shape, out_data.shape) <MASK> self.assertTrue((in_data == out_data).all())",if not self . use_parallel_executor :,189
1903,def finalize(self): <TAB> if self._started: <MASK> self._queue.put(None) <TAB>  <TAB>  <TAB> self._queue.join() <TAB>  <TAB>  <TAB> self._consumer.join() <TAB>  <TAB> self._started = False <TAB> self._finalized = True,if not self . _finalized :,70
1904,"def _get_ilo_version(self): <TAB> try: <TAB>  <TAB> self._get_ilo2('<?xml version=""1.0""?><RIBCL VERSION=""2.0""></RIBCL>') <TAB> except ResponseError as e: <MASK> if e.code == 405: <TAB>  <TAB>  <TAB>  <TAB> return 3 <TAB>  <TAB>  <TAB> if e.code == 501: <TAB>  <TAB>  <TAB>  <TAB> return 1 <TAB>  <TAB> raise <TAB> return 2","if hasattr ( e , ""code"" ) :",113
1905,"def _check_data(self, source, expected_bytes, expected_duration): <TAB> received_bytes = 0 <TAB> received_seconds = 0.0 <TAB> bytes_to_read = 1024 <TAB> while True: <TAB>  <TAB> data = source.get_audio_data(bytes_to_read) <MASK> break <TAB>  <TAB> received_bytes += data.length <TAB>  <TAB> received_seconds += data.duration <TAB>  <TAB> self.assertEqual(data.length, len(data.data)) <TAB> self.assertAlmostEqual(expected_duration, received_seconds, places=1) <TAB> self.assertAlmostEqual(expected_bytes, received_bytes, delta=5)",if data is None :,154
1906,"def __randomize_interval_task(self): <TAB> for job in self.aps_scheduler.get_jobs(): <MASK> self.aps_scheduler.modify_job( <TAB>  <TAB>  <TAB>  <TAB> job.id, <TAB>  <TAB>  <TAB>  <TAB> next_run_time=datetime.now() <TAB>  <TAB>  <TAB>  <TAB> + timedelta( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> seconds=randrange( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> job.trigger.interval.total_seconds() * 0.75, <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> job.trigger.interval.total_seconds(), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB> )","if isinstance ( job . trigger , IntervalTrigger ) :",153
1907,"def find_approximant(x): <TAB> c = 1e-4 <TAB> it = sympy.ntheory.continued_fraction_convergents( <TAB>  <TAB> sympy.ntheory.continued_fraction_iterator(x) <TAB> ) <TAB> for i in it: <TAB>  <TAB> p, q = i.as_numer_denom() <TAB>  <TAB> tol = c / q ** 2 <MASK> return i <TAB>  <TAB> if tol < machine_epsilon: <TAB>  <TAB>  <TAB> break <TAB> return x",if abs ( i - x ) <= tol :,122
1908,"def fix_newlines(lines): <TAB> """"""Convert newlines to unix."""""" <TAB> for i, line in enumerate(lines): <TAB>  <TAB> if line.endswith(""\r\n""): <TAB>  <TAB>  <TAB> lines[i] = line[:-2] + ""\n"" <MASK> lines[i] = line[:-1] + ""\n""","elif line . endswith ( ""\r"" ) :",83
1909,"def payment_control_render(self, request: HttpRequest, payment: OrderPayment): <TAB> template = get_template(""pretixplugins/paypal/control.html"") <TAB> sale_id = None <TAB> for trans in payment.info_data.get(""transactions"", []): <TAB>  <TAB> for res in trans.get(""related_resources"", []): <MASK> sale_id = res[""sale""][""id""] <TAB> ctx = { <TAB>  <TAB> ""request"": request, <TAB>  <TAB> ""event"": self.event, <TAB>  <TAB> ""settings"": self.settings, <TAB>  <TAB> ""payment_info"": payment.info_data, <TAB>  <TAB> ""order"": payment.order, <TAB>  <TAB> ""sale_id"": sale_id, <TAB> } <TAB> return template.render(ctx)","if ""sale"" in res and ""id"" in res [ ""sale"" ] :",192
1910,"def for_name(self, name): <TAB> try: <TAB>  <TAB> name_resources = self._resources[name] <TAB> except KeyError: <TAB>  <TAB> raise LookupError(name) <TAB> else: <TAB>  <TAB> for res in name_resources: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> inst = res.inst() <TAB>  <TAB>  <TAB> except Exception as e: <MASK> log.exception(""error initializing %s"", res) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> log.error(""error initializing %s: %s"", res, e) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield inst",if log . getEffectiveLevel ( ) <= logging . DEBUG :,154
1911,"def describe(self, done=False): <TAB> description = ShellCommand.describe(self, done) <TAB> if done: <MASK> description = [""compile""] <TAB>  <TAB> description.append(""%d projects"" % self.getStatistic(""projects"", 0)) <TAB>  <TAB> description.append(""%d files"" % self.getStatistic(""files"", 0)) <TAB>  <TAB> warnings = self.getStatistic(""warnings"", 0) <TAB>  <TAB> if warnings > 0: <TAB>  <TAB>  <TAB> description.append(""%d warnings"" % warnings) <TAB>  <TAB> errors = self.getStatistic(""errors"", 0) <TAB>  <TAB> if errors > 0: <TAB>  <TAB>  <TAB> description.append(""%d errors"" % errors) <TAB> return description",if not description :,164
1912,"def parse_list(tl): <TAB> ls = [] <TAB> nm = [] <TAB> while True: <TAB>  <TAB> term, nmt, tl = parse_term(tl) <TAB>  <TAB> ls.append(term) <MASK> nm.append(nmt) <TAB>  <TAB> if tl[0] != "","": <TAB>  <TAB>  <TAB> break <TAB>  <TAB> tl = tl[1:] <TAB> return ls, nm, tl",if nmt is not None :,101
1913,"def infer_dataset_impl(path): <TAB> if IndexedRawTextDataset.exists(path): <TAB>  <TAB> return ""raw"" <TAB> elif IndexedDataset.exists(path): <TAB>  <TAB> with open(index_file_path(path), ""rb"") as f: <TAB>  <TAB>  <TAB> magic = f.read(8) <MASK> return ""cached"" <TAB>  <TAB>  <TAB> elif magic == MMapIndexedDataset.Index._HDR_MAGIC[:8]: <TAB>  <TAB>  <TAB>  <TAB> return ""mmap"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return None <TAB> elif FastaDataset.exists(path): <TAB>  <TAB> return ""fasta"" <TAB> else: <TAB>  <TAB> return None",if magic == IndexedDataset . _HDR_MAGIC :,167
1914,"def _get(self): <TAB> fut = item = None <TAB> with self._mutex: <TAB>  <TAB> # Critical section never blocks. <MASK> fut = Future() <TAB>  <TAB>  <TAB> fut.add_done_callback( <TAB>  <TAB>  <TAB>  <TAB> lambda f: self._get_complete() if not f.cancelled() else None <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self._getters.append(fut) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> item = self._get_item() <TAB>  <TAB>  <TAB> self._get_complete() <TAB> return item, fut",if not self . _queue or self . _getters :,142
1915,"def validate(self): <TAB> dates = [] <TAB> for d in self.get(""leave_block_list_dates""): <TAB>  <TAB> # date is not repeated <MASK> frappe.msgprint( <TAB>  <TAB>  <TAB>  <TAB> _(""Date is repeated"") + "":"" + d.block_date, raise_exception=1 <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> dates.append(d.block_date)",if d . block_date in dates :,101
1916,"def on_choose_watch_dir_clicked(self): <TAB> if self.window().watchfolder_enabled_checkbox.isChecked(): <TAB>  <TAB> previous_watch_dir = self.window().watchfolder_location_input.text() or """" <TAB>  <TAB> watch_dir = QFileDialog.getExistingDirectory( <TAB>  <TAB>  <TAB> self.window(), <TAB>  <TAB>  <TAB> ""Please select the watch folder"", <TAB>  <TAB>  <TAB> previous_watch_dir, <TAB>  <TAB>  <TAB> QFileDialog.ShowDirsOnly, <TAB>  <TAB> ) <MASK> return <TAB>  <TAB> self.window().watchfolder_location_input.setText(watch_dir)",if not watch_dir :,147
1917,"def log_generator(self, limit=6000, **kwargs): <TAB> # Generator for show_log_panel <TAB> skip = 0 <TAB> while True: <TAB>  <TAB> logs = self.log(limit=limit, skip=skip, **kwargs) <TAB>  <TAB> if not logs: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> for entry in logs: <TAB>  <TAB>  <TAB> yield entry <MASK> break <TAB>  <TAB> skip = skip + limit",if len ( logs ) < limit :,106
1918,"def _setUpClass(cls): <TAB> global solver <TAB> import pyomo.environ <TAB> from pyomo.solvers.tests.io.writer_test_cases import testCases <TAB> for test_case in testCases: <MASK> solver[(test_case.name, test_case.io)] = True","if ( ( test_case . name , test_case . io ) in solver ) and ( test_case . available ) :",101
1919,"def _get_file_data(self, normpath, normrev): <TAB> data = self.client.cat(normpath, normrev) <TAB> if has_expanded_svn_keywords(data): <TAB>  <TAB> # Find out if this file has any keyword expansion set. <TAB>  <TAB> # If it does, collapse these keywords. This is because SVN <TAB>  <TAB> # will return the file expanded to us, which would break patching. <TAB>  <TAB> keywords = self.client.propget(""svn:keywords"", normpath, normrev, recurse=True) <MASK> data = collapse_svn_keywords(data, force_bytes(keywords[normpath])) <TAB> return data",if normpath in keywords :,152
1920,"def add_controller_list(path): <TAB> if not os.path.exists(os.path.join(path, ""__init__.py"")): <TAB>  <TAB> bb.fatal(""Controllers directory %s exists but is missing __init__.py"" % path) <TAB> files = sorted( <TAB>  <TAB> [f for f in os.listdir(path) if f.endswith("".py"") and not f.startswith(""_"")] <TAB> ) <TAB> for f in files: <TAB>  <TAB> module = ""oeqa.controllers."" + f[:-3] <MASK> controllerslist.append(module) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> bb.warn( <TAB>  <TAB>  <TAB>  <TAB> ""Duplicate controller module found for %s, only one added. Layers should create unique controller module names"" <TAB>  <TAB>  <TAB>  <TAB> % module <TAB>  <TAB>  <TAB> )",if module not in controllerslist :,197
1921,"def on_session2(event): <TAB> new_xmpp.get_roster() <TAB> new_xmpp.send_presence() <TAB> logging.info(roster[0]) <TAB> data = roster[0][""roster""][""items""] <TAB> logging.info(data) <TAB> for jid, item in data.items(): <MASK> new_xmpp.send_presence(ptype=""subscribe"", pto=jid) <TAB>  <TAB> new_xmpp.update_roster(jid, name=item[""name""], groups=item[""groups""]) <TAB> new_xmpp.disconnect()","if item [ ""subscription"" ] != ""none"" :",145
1922,"def _parse_class_simplified(symbol): <TAB> results = {} <TAB> name = symbol.name + ""("" <TAB> name += "", "".join([analyzer.expand_attribute(base) for base in symbol.bases]) <TAB> name += "")"" <TAB> for sym in symbol.body: <MASK> result = _parse_function_simplified(sym, symbol.name) <TAB>  <TAB>  <TAB> results.update(result) <TAB>  <TAB> elif isinstance(sym, ast.ClassDef): <TAB>  <TAB>  <TAB> result = _parse_class_simplified(sym) <TAB>  <TAB>  <TAB> results.update(result) <TAB> lineno = symbol.lineno <TAB> for decorator in symbol.decorator_list: <TAB>  <TAB> lineno += 1 <TAB> results[lineno] = (name, ""c"") <TAB> return results","if isinstance ( sym , ast . FunctionDef ) :",181
1923,"def check_args(args): <TAB> """"""Checks that the args are coherent."""""" <TAB> check_args_has_attributes(args) <TAB> if args.v: <TAB>  <TAB> non_version_attrs = [v for k, v in args.__dict__.items() if k != ""v""] <TAB>  <TAB> print(""non_version_attrs"", non_version_attrs) <MASK> fail(""Cannot show the version number with another command."") <TAB>  <TAB> return <TAB> if args.i is None: <TAB>  <TAB> fail(""Cannot draw ER diagram of no database."") <TAB> if args.o is None: <TAB>  <TAB> fail(""Cannot draw ER diagram with no output file."")",if len ( [ v for v in non_version_attrs if v is not None ] ) != 0 :,176
1924,"def handle(self, *args, **options): <TAB> if not settings.ST_BASE_DIR.endswith(""spirit""): <TAB>  <TAB> raise CommandError( <TAB>  <TAB>  <TAB> ""settings.ST_BASE_DIR is not the spirit root folder, are you overriding it?"" <TAB>  <TAB> ) <TAB> for root, dirs, files in os.walk(settings.ST_BASE_DIR): <MASK> continue <TAB>  <TAB> with utils.pushd(root): <TAB>  <TAB>  <TAB> call_command( <TAB>  <TAB>  <TAB>  <TAB> ""makemessages"", stdout=self.stdout, stderr=self.stderr, **options <TAB>  <TAB>  <TAB> ) <TAB> self.stdout.write(""ok"")","if ""locale"" not in dirs :",160
1925,"def scan(scope): <TAB> for s in scope.children: <TAB>  <TAB> if s.start_pos <= position <= s.end_pos: <MASK> return scan(s) or s <TAB>  <TAB>  <TAB> elif s.type in (""suite"", ""decorated""): <TAB>  <TAB>  <TAB>  <TAB> return scan(s) <TAB> return None","if isinstance ( s , ( tree . Scope , tree . Flow ) ) :",92
1926,def run_sync(self): <TAB> count = 0 <TAB> while count < self.args.num_messages: <TAB>  <TAB> batch = self.receiver.fetch_next(max_batch_size=self.args.num_messages - count) <MASK> for msg in batch: <TAB>  <TAB>  <TAB>  <TAB> msg.complete() <TAB>  <TAB> count += len(batch),if self . args . peeklock :,93
1927,"def __getitem__(self, item): <TAB> if self._datas is not None: <TAB>  <TAB> ret = [] <TAB>  <TAB> for data in self._datas: <MASK> ret.append(data[self._offset]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> ret.append(data.iloc[self._offset]) <TAB>  <TAB> self._offset += 1 <TAB>  <TAB> return ret <TAB> else: <TAB>  <TAB> return self._get_data(item)","if isinstance ( data , np . ndarray ) :",115
1928,"def removedir(self, path): <TAB> # type: (Text) -> None <TAB> _path = self.validatepath(path) <TAB> if _path == ""/"": <TAB>  <TAB> raise errors.RemoveRootError() <TAB> with ftp_errors(self, path): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.ftp.rmd(_encode(_path, self.ftp.encoding)) <TAB>  <TAB> except error_perm as error: <TAB>  <TAB>  <TAB> code, _ = _parse_ftp_error(error) <TAB>  <TAB>  <TAB> if code == ""550"": <MASK> raise errors.DirectoryExpected(path) <TAB>  <TAB>  <TAB>  <TAB> if not self.isempty(path): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise errors.DirectoryNotEmpty(path) <TAB>  <TAB>  <TAB> raise  # pragma: no cover",if self . isfile ( path ) :,189
1929,"def replaces_in_file(file, replacement_list): <TAB> rs = [(re.compile(regexp), repl) for (regexp, repl) in replacement_list] <TAB> file_tmp = file + ""."" + str(os.getpid()) + "".tmp"" <TAB> with open(file, ""r"") as f: <TAB>  <TAB> with open(file_tmp, ""w"") as f_tmp: <TAB>  <TAB>  <TAB> for line in f: <TAB>  <TAB>  <TAB>  <TAB> for r, replace in rs: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> match = r.search(line) <MASK> line = replace + ""\n"" <TAB>  <TAB>  <TAB>  <TAB> f_tmp.write(line) <TAB> shutil.move(file_tmp, file)",if match :,172
1930,"def _get_path_check_mem(self, i, size): <TAB> if size > 0: <MASK> p = self._get_path(i, -1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> p = self._get_path(i, size) <TAB>  <TAB>  <TAB> if p.startswith(""/dev/shm""): <TAB>  <TAB>  <TAB>  <TAB> env.meminfo.add(size) <TAB> else: <TAB>  <TAB> p = self._get_path(i, size) <TAB> return p",if env . meminfo . rss + size > env . meminfo . mem_limit_soft :,136
1931,"def find_widget_by_id(self, id, parent=None): <TAB> """"""Recursively searches for widget with specified ID"""""" <TAB> if parent == None: <TAB>  <TAB> if id in self: <TAB>  <TAB>  <TAB> return self[id]  # Do things fast if possible <TAB>  <TAB> parent = self[""editor""] <TAB> for c in parent.get_children(): <MASK> if c.get_id() == id: <TAB>  <TAB>  <TAB>  <TAB> return c <TAB>  <TAB> if isinstance(c, Gtk.Container): <TAB>  <TAB>  <TAB> r = self.find_widget_by_id(id, c) <TAB>  <TAB>  <TAB> if not r is None: <TAB>  <TAB>  <TAB>  <TAB> return r <TAB> return None","if hasattr ( c , ""get_id"" ) :",167
1932,"def _deserialize(cls, io): <TAB> flags = VideoFlags() <TAB> flags.byte = U8.read(io) <TAB> if flags.bit.type == VIDEO_FRAME_TYPE_COMMAND_FRAME: <TAB>  <TAB> data = VideoCommandFrame.deserialize(io) <TAB> else: <MASK> data = AVCVideoData.deserialize(io) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> data = io.read() <TAB> return cls(flags.bit.type, flags.bit.codec, data)",if flags . bit . codec == VIDEO_CODEC_ID_AVC :,134
1933,"def asciiLogData(data, maxlen=64, replace=False): <TAB> ellipses = "" ..."" <TAB> try: <MASK> dd = data[:maxlen] + ellipses <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> dd = data <TAB>  <TAB> return dd.decode(""utf8"", errors=""replace"" if replace else ""strict"") <TAB> except: <TAB>  <TAB> return ""0x"" + binLogData(data, maxlen)",if len ( data ) > maxlen - len ( ellipses ) :,112
1934,"def _check_units(self, new_unit_system): <TAB> # If no unit system has been specified for me yet, adopt the incoming <TAB> # system <TAB> if self.unit_system is None: <TAB>  <TAB> self.unit_system = new_unit_system <TAB> else: <TAB>  <TAB> # Otherwise, make sure they match <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Unit system mismatch %d v. %d"" % (self.unit_system, new_unit_system) <TAB>  <TAB>  <TAB> )",if self . unit_system != new_unit_system :,133
1935,"def command(filenames, dirnames, fix): <TAB> for filename in gather_files(dirnames, filenames): <TAB>  <TAB> visitor = process_file(filename) <MASK> print(""%s: %s"" % (filename, visitor.get_stats())) <TAB>  <TAB>  <TAB> if fix: <TAB>  <TAB>  <TAB>  <TAB> print(""Fixing: %s"" % filename) <TAB>  <TAB>  <TAB>  <TAB> fix_file(filename)",if visitor . needs_fix ( ) :,100
1936,"def assign_attributes_to_variants(variant_attributes): <TAB> for value in variant_attributes: <TAB>  <TAB> pk = value[""pk""] <TAB>  <TAB> defaults = value[""fields""] <TAB>  <TAB> defaults[""variant_id""] = defaults.pop(""variant"") <TAB>  <TAB> defaults[""assignment_id""] = defaults.pop(""assignment"") <TAB>  <TAB> assigned_values = defaults.pop(""values"") <TAB>  <TAB> assoc, created = AssignedVariantAttribute.objects.update_or_create( <TAB>  <TAB>  <TAB> pk=pk, defaults=defaults <TAB>  <TAB> ) <MASK> assoc.values.set(AttributeValue.objects.filter(pk__in=assigned_values))",if created :,148
1937,"def _info(self, userlist): <TAB> for strng in userlist: <TAB>  <TAB> group_matched = False <TAB>  <TAB> for env in self.base.comps.environments_by_pattern(strng): <TAB>  <TAB>  <TAB> self.output.display_groups_in_environment(env) <TAB>  <TAB>  <TAB> group_matched = True <TAB>  <TAB> for group in self.base.comps.groups_by_pattern(strng): <TAB>  <TAB>  <TAB> self.output.display_pkgs_in_groups(group) <TAB>  <TAB>  <TAB> group_matched = True <MASK> logger.error(_(""Warning: Group %s does not exist.""), strng) <TAB> return 0, []",if not group_matched :,159
1938,"def parse_implements_interfaces(parser): <TAB> types = [] <TAB> if parser.token.value == ""implements"": <TAB>  <TAB> advance(parser) <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> types.append(parse_named_type(parser)) <MASK> break <TAB> return types","if not peek ( parser , TokenKind . NAME ) :",81
1939,"def generate(): <TAB> for leaf in u.leaves: <TAB>  <TAB> if isinstance(leaf, Integer): <TAB>  <TAB>  <TAB> val = leaf.get_int_value() <TAB>  <TAB>  <TAB> if val in (0, 1): <TAB>  <TAB>  <TAB>  <TAB> yield val <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise _NoBoolVector <TAB>  <TAB> elif isinstance(leaf, Symbol): <TAB>  <TAB>  <TAB> if leaf == SymbolTrue: <TAB>  <TAB>  <TAB>  <TAB> yield 1 <MASK> yield 0 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise _NoBoolVector <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise _NoBoolVector",elif leaf == SymbolFalse :,138
1940,"def update_gstin(context): <TAB> dirty = False <TAB> for key, value in iteritems(frappe.form_dict): <TAB>  <TAB> if key != ""party"": <TAB>  <TAB>  <TAB> address_name = frappe.get_value(""Address"", key) <MASK> address = frappe.get_doc(""Address"", address_name) <TAB>  <TAB>  <TAB>  <TAB> address.gstin = value.upper() <TAB>  <TAB>  <TAB>  <TAB> address.save(ignore_permissions=True) <TAB>  <TAB>  <TAB>  <TAB> dirty = True <TAB> if dirty: <TAB>  <TAB> frappe.db.commit() <TAB>  <TAB> context.updated = True",if address_name :,151
1941,"def everythingIsUnicode(d): <TAB> """"""Takes a dictionary, recursively verifies that every value is unicode"""""" <TAB> for k, v in d.iteritems(): <MASK> if not everythingIsUnicode(v): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> elif isinstance(v, list): <TAB>  <TAB>  <TAB> for i in v: <TAB>  <TAB>  <TAB>  <TAB> if isinstance(i, dict) and not everythingIsUnicode(i): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB>  <TAB> elif isinstance(i, _bytes): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> elif isinstance(v, _bytes): <TAB>  <TAB>  <TAB> return False <TAB> return True","if isinstance ( v , dict ) and k != ""headers"" :",158
1942,"def check_graph(graph):  # pragma: no cover <TAB> for c in graph: <MASK> raise RuntimeError(""cannot have fuse"") <TAB>  <TAB> for inp in c.inputs: <TAB>  <TAB>  <TAB> if isinstance(inp.op, Fuse): <TAB>  <TAB>  <TAB>  <TAB> raise RuntimeError(""cannot have fuse"")","if isinstance ( c . op , Fuse ) :",79
1943,"def __getattr__(self, key): <TAB> try: <TAB>  <TAB> value = self.__parent.contents[key] <TAB> except KeyError: <TAB>  <TAB> pass <TAB> else: <MASK> if isinstance(value, _ModuleMarker): <TAB>  <TAB>  <TAB>  <TAB> return value.mod_ns <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> assert isinstance(value, _MultipleClassMarker) <TAB>  <TAB>  <TAB>  <TAB> return value.attempt_get(self.__parent.path, key) <TAB> raise AttributeError( <TAB>  <TAB> ""Module %r has no mapped classes "" <TAB>  <TAB> ""registered under the name %r"" % (self.__parent.name, key) <TAB> )",if value is not None :,154
1944,"def filter_ports(self, dpid, in_port, nw_id, allow_nw_id_external=None): <TAB> assert nw_id != self.nw_id_unknown <TAB> ret = [] <TAB> for port in self.get_ports(dpid): <TAB>  <TAB> nw_id_ = port.network_id <TAB>  <TAB> if port.port_no == in_port: <TAB>  <TAB>  <TAB> continue <MASK> ret.append(port.port_no) <TAB>  <TAB> elif allow_nw_id_external is not None and nw_id_ == allow_nw_id_external: <TAB>  <TAB>  <TAB> ret.append(port.port_no) <TAB> return ret",if nw_id_ == nw_id :,167
1945,"def _parse(self, contents): <TAB> entries = [] <TAB> for line in contents.splitlines(): <TAB>  <TAB> if not len(line.strip()): <TAB>  <TAB>  <TAB> entries.append((""blank"", [line])) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> (head, tail) = chop_comment(line.strip(), ""#"") <MASK> entries.append((""all_comment"", [line])) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> entries.append((""option"", [head.split(None), tail])) <TAB> return entries",if not len ( head ) :,121
1946,"def _get_documented_completions(self, table, startswith=None): <TAB> names = [] <TAB> for key, command in table.items(): <TAB>  <TAB> if getattr(command, ""_UNDOCUMENTED"", False): <TAB>  <TAB>  <TAB> # Don't tab complete undocumented commands/params <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> if getattr(command, ""positional_arg"", False): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> names.append(key) <TAB> return names",if startswith is not None and not key . startswith ( startswith ) :,118
1947,"def _convert_example(example, use_bfloat16): <TAB> """"""Cast int64 into int32 and float32 to bfloat16 if use_bfloat16."""""" <TAB> for key in list(example.keys()): <TAB>  <TAB> val = example[key] <MASK> val = tf.sparse.to_dense(val) <TAB>  <TAB> if val.dtype == tf.int64: <TAB>  <TAB>  <TAB> val = tf.cast(val, tf.int32) <TAB>  <TAB> if use_bfloat16 and val.dtype == tf.float32: <TAB>  <TAB>  <TAB> val = tf.cast(val, tf.bfloat16) <TAB>  <TAB> example[key] = val",if tf . keras . backend . is_sparse ( val ) :,166
1948,"def _get_lang_zone(self, lang): <TAB> if lang not in self._lang_zone_from_lang: <MASK> self._lang_zone_from_lang[lang] = MultiLangZone(self.mgr, lang) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._lang_zone_from_lang[lang] = LangZone(self.mgr, lang) <TAB> return self._lang_zone_from_lang[lang]",if self . mgr . is_multilang ( lang ) :,119
1949,"def dispatch(self, request, *args, **kwargs): <TAB> try: <TAB>  <TAB> return super(Handler, self).dispatch(request, *args, **kwargs) <TAB> except Http404 as e: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> request.original_path_info = request.path_info <TAB>  <TAB>  <TAB>  <TAB> request.path_info = settings.FEINCMS_CMS_404_PAGE <TAB>  <TAB>  <TAB>  <TAB> response = super(Handler, self).dispatch(request, *args, **kwargs) <TAB>  <TAB>  <TAB>  <TAB> response.status_code = 404 <TAB>  <TAB>  <TAB>  <TAB> return response <TAB>  <TAB>  <TAB> except Http404: <TAB>  <TAB>  <TAB>  <TAB> raise e <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise",if settings . FEINCMS_CMS_404_PAGE :,179
1950,"def _maybe_update_dropout(self, step): <TAB> for i in range(len(self.dropout_steps)): <MASK> self.model.update_dropout(self.dropout[i]) <TAB>  <TAB>  <TAB> logger.info(""Updated dropout to %f from step %d"" % (self.dropout[i], step))",if step > 1 and step == self . dropout_steps [ i ] + 1 :,95
1951,"def bulk_move(*args, **kwargs): <TAB> for arg in args: <MASK> raise PopupException(_(""Source path and destination path cannot be same"")) <TAB>  <TAB> request.fs.rename( <TAB>  <TAB>  <TAB> urllib.unquote(arg[""src_path""]), urllib.unquote(arg[""dest_path""]) <TAB>  <TAB> )","if arg [ ""src_path"" ] == arg [ ""dest_path"" ] :",90
1952,"def asisWrite(self, root): <TAB> at, c = self, self.c <TAB> try: <TAB>  <TAB> c.endEditing() <TAB>  <TAB> c.init_error_dialogs() <TAB>  <TAB> fileName = at.initWriteIvars(root, root.atAsisFileNodeName()) <MASK> at.addToOrphanList(root) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> at.openOutputStream() <TAB>  <TAB> for p in root.self_and_subtree(copy=False): <TAB>  <TAB>  <TAB> at.writeAsisNode(p) <TAB>  <TAB> contents = at.closeOutputStream() <TAB>  <TAB> at.replaceFile(contents, at.encoding, fileName, root) <TAB> except Exception: <TAB>  <TAB> at.writeException(fileName, root)","if not at . precheck ( fileName , root ) :",187
1953,"def next_event(it): <TAB> """"""read an event from an eventstream"""""" <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> line = next(it) <TAB>  <TAB> except StopIteration: <TAB>  <TAB>  <TAB> return <MASK> return json.loads(line.split("":"", 1)[1])","if line . startswith ( ""data:"" ) :",77
1954,"def process_formdata(self, valuelist): <TAB> if valuelist: <TAB>  <TAB> if valuelist[0] == ""__None"": <TAB>  <TAB>  <TAB> self.data = None <TAB>  <TAB> else: <MASK> self.data = None <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> obj = self.queryset.get(pk=valuelist[0]) <TAB>  <TAB>  <TAB>  <TAB> self.data = obj <TAB>  <TAB>  <TAB> except DoesNotExist: <TAB>  <TAB>  <TAB>  <TAB> self.data = None",if self . queryset is None :,122
1955,"def _setResultsName(self, name, listAllMatches=False): <TAB> if __diag__.warn_multiple_tokens_in_named_alternation: <MASK> warnings.warn( <TAB>  <TAB>  <TAB>  <TAB> ""{}: setting results name {!r} on {} expression "" <TAB>  <TAB>  <TAB>  <TAB> ""will return a list of all parsed tokens in an And alternative, "" <TAB>  <TAB>  <TAB>  <TAB> ""in prior versions only the first token was returned"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""warn_multiple_tokens_in_named_alternation"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> name, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> type(self).__name__, <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB>  <TAB> stacklevel=3, <TAB>  <TAB>  <TAB> ) <TAB> return super()._setResultsName(name, listAllMatches)","if any ( isinstance ( e , And ) for e in self . exprs ) :",195
1956,"def add(request): <TAB> form_type = ""servers"" <TAB> if request.method == ""POST"": <TAB>  <TAB> form = BookMarkForm(request.POST) <TAB>  <TAB> if form.is_valid(): <TAB>  <TAB>  <TAB> form_type = form.save() <TAB>  <TAB>  <TAB> messages.add_message(request, messages.INFO, ""Bookmark created"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> messages.add_message(request, messages.INFO, form.errors) <MASK> url = reverse(""servers"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> url = reverse(""metrics"") <TAB>  <TAB> return redirect(url) <TAB> else: <TAB>  <TAB> return redirect(reverse(""servers""))","if form_type == ""server"" :",164
1957,"def __init__(self, post_id, artist, page, tzInfo=None, dateFormat=None): <TAB> self.imageUrls = list() <TAB> self.imageResizedUrls = list() <TAB> self.imageId = int(post_id) <TAB> self._tzInfo = tzInfo <TAB> self.dateFormat = dateFormat <TAB> if page is not None: <TAB>  <TAB> post_json = demjson.decode(page) <MASK> artist_id = post_json[""data""][""item""][""user""][""id""] <TAB>  <TAB>  <TAB> self.artist = SketchArtist(artist_id, page, tzInfo, dateFormat) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.artist = artist <TAB>  <TAB> self.parse_post(post_json[""data""][""item""])",if artist is None :,182
1958,"def _create_batch_iterator( <TAB> self, <TAB> mark_as_delete: Callable[[Any], None], <TAB> to_key: Callable[[Any], Any], <TAB> to_value: Callable[[Any], Any], <TAB> batch: Iterable[EventT],) -> Iterable[Tuple[Any, Any]]: <TAB> for event in batch: <TAB>  <TAB> key = to_key(event.key) <TAB>  <TAB> # to delete keys in the table we set the raw value to None <MASK> mark_as_delete(key) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> yield key, to_value(event.value)",if event . message . value is None :,150
1959,"def test_lc_numeric_nl_langinfo(self): <TAB> # Test nl_langinfo against known values <TAB> tested = False <TAB> for loc in candidate_locales: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> setlocale(LC_NUMERIC, loc) <TAB>  <TAB>  <TAB> setlocale(LC_CTYPE, loc) <TAB>  <TAB> except Error: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for li, lc in ((RADIXCHAR, ""decimal_point""), (THOUSEP, ""thousands_sep"")): <MASK> tested = True <TAB> if not tested: <TAB>  <TAB> self.skipTest(""no suitable locales"")","if self . numeric_tester ( ""nl_langinfo"" , nl_langinfo ( li ) , lc , loc ) :",163
1960,"def _level_up_logging(self): <TAB> for handler in self.log.handlers: <MASK> if handler.level != logging.DEBUG: <TAB>  <TAB>  <TAB>  <TAB> handler.setLevel(logging.DEBUG) <TAB>  <TAB>  <TAB>  <TAB> self.log.debug(""Leveled up log file verbosity"")","if issubclass ( handler . __class__ , logging . FileHandler ) :",80
1961,def _show_axes_changed(self): <TAB> marker = self.marker <TAB> if (self._vtk_control is not None) and (marker is not None): <MASK> marker.interactor = None <TAB>  <TAB>  <TAB> marker.enabled = False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> marker.interactor = self.interactor <TAB>  <TAB>  <TAB> marker.enabled = True <TAB>  <TAB> self.render(),if not self . show_axes :,103
1962,"def handle_keypress(self, rawKey, modifiers, key, *args): <TAB> if self.recordKeyboard and self.__delayPassed(): <MASK> self.insideKeys = True <TAB>  <TAB>  <TAB> self.targetParent.start_key_sequence() <TAB>  <TAB> modifierCount = len(modifiers) <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB> modifierCount > 1 <TAB>  <TAB>  <TAB> or (modifierCount == 1 and Key.SHIFT not in modifiers) <TAB>  <TAB>  <TAB> or (Key.SHIFT in modifiers and len(rawKey) > 1) <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> self.targetParent.append_hotkey(rawKey, modifiers) <TAB>  <TAB> elif key not in MODIFIERS: <TAB>  <TAB>  <TAB> self.targetParent.append_key(key)",if not self . insideKeys :,178
1963,"def transform(self, data): <TAB> with timer(""transform %s"" % self.name, logging.DEBUG): <TAB>  <TAB> if self.operator in {""lat"", ""latitude""}: <TAB>  <TAB>  <TAB> return self.series(data).apply(GeoIP.get_latitude) <MASK> return self.series(data).apply(GeoIP.get_longitude) <TAB>  <TAB> elif self.operator in {""acc"", ""accuracy""}: <TAB>  <TAB>  <TAB> return self.series(data).apply(GeoIP.get_accuracy) <TAB>  <TAB> raise NameError(""Unknown GeoIP operator [lat, lon, acc]: %s"" % self.operator)","elif self . operator in { ""lon"" , ""longitude"" } :",161
1964,"def _get_sidebar_selected(self): <TAB> sidebar_selected = None <TAB> if self.businessline_id: <TAB>  <TAB> sidebar_selected = ""bl_%s"" % self.businessline_id <MASK> sidebar_selected += ""_s_%s"" % self.service_id <TAB>  <TAB>  <TAB> if self.environment_id: <TAB>  <TAB>  <TAB>  <TAB> sidebar_selected += ""_env_%s"" % self.environment_id <TAB> return sidebar_selected",if self . service_id :,113
1965,"def _run_response_middleware(self, request, response, request_name=None): <TAB> named_middleware = self.named_response_middleware.get(request_name, deque()) <TAB> applicable_middleware = self.response_middleware + named_middleware <TAB> if applicable_middleware: <TAB>  <TAB> for middleware in applicable_middleware: <TAB>  <TAB>  <TAB> _response = middleware(request, response) <MASK> _response = await _response <TAB>  <TAB>  <TAB> if _response: <TAB>  <TAB>  <TAB>  <TAB> response = _response <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return response",if isawaitable ( _response ) :,136
1966,"def populate_obj(self, obj, name): <TAB> field = getattr(obj, name, None) <TAB> if field is not None: <TAB>  <TAB> # If field should be deleted, clean it up <TAB>  <TAB> if self._should_delete: <TAB>  <TAB>  <TAB> field.delete() <TAB>  <TAB>  <TAB> return <MASK> if not field.grid_id: <TAB>  <TAB>  <TAB>  <TAB> func = field.put <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> func = field.replace <TAB>  <TAB>  <TAB> func( <TAB>  <TAB>  <TAB>  <TAB> self.data.stream, <TAB>  <TAB>  <TAB>  <TAB> filename=self.data.filename, <TAB>  <TAB>  <TAB>  <TAB> content_type=self.data.content_type, <TAB>  <TAB>  <TAB> )","if isinstance ( self . data , FileStorage ) and not is_empty ( self . data . stream ) :",182
1967,"def _import_hash(self, operator): <TAB> # Import required modules into local namespace so that pipelines <TAB> # may be evaluated directly <TAB> for key in sorted(operator.import_hash.keys()): <TAB>  <TAB> module_list = "", "".join(sorted(operator.import_hash[key])) <MASK> exec(""from {} import {}"".format(key[4:], module_list)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> exec(""from {} import {}"".format(key, module_list)) <TAB>  <TAB> for var in operator.import_hash[key]: <TAB>  <TAB>  <TAB> self.operators_context[var] = eval(var)","if key . startswith ( ""tpot."" ) :",152
1968,"def remove_files(folder, file_extensions): <TAB> for f in os.listdir(folder): <TAB>  <TAB> f_path = os.path.join(folder, f) <MASK> extension = os.path.splitext(f_path)[1] <TAB>  <TAB>  <TAB> if extension in file_extensions: <TAB>  <TAB>  <TAB>  <TAB> os.remove(f_path)",if os . path . isfile ( f_path ) :,96
1969,"def clearBuffer(self): <TAB> if self.shouldLose == -1: <TAB>  <TAB> return <TAB> if self.producer: <TAB>  <TAB> self.producer.resumeProducing() <TAB> if self.buffer: <MASK> self.logFile.write(""loopback receiving %s\n"" % repr(self.buffer)) <TAB>  <TAB> buffer = self.buffer <TAB>  <TAB> self.buffer = b"""" <TAB>  <TAB> self.target.dataReceived(buffer) <TAB> if self.shouldLose == 1: <TAB>  <TAB> self.shouldLose = -1 <TAB>  <TAB> self.target.connectionLost(failure.Failure(main.CONNECTION_DONE))",if self . logFile :,156
1970,"def write(self, data): <TAB> if mock_target._mirror_on_stderr: <TAB>  <TAB> if self._write_line: <TAB>  <TAB>  <TAB> sys.stderr.write(fn + "": "") <TAB>  <TAB> if bytes: <TAB>  <TAB>  <TAB> sys.stderr.write(data.decode(""utf8"")) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sys.stderr.write(data) <MASK> self._write_line = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._write_line = False <TAB> super(Buffer, self).write(data)","if ( data [ - 1 ] ) == ""\n"" :",137
1971,def stop(self): <TAB> self.queue_com.state_lock.acquire() <TAB> try: <MASK> self.queue_com.state = STOPPED <TAB>  <TAB>  <TAB> self.remove() <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> return False <TAB> finally: <TAB>  <TAB> self.queue_com.state_lock.release(),if self . queue_com . state == RUNNING and self . stop_task ( ) :,97
1972,"def _handle_special_args(self, pyobjects): <TAB> if len(pyobjects) == len(self.arguments.args): <TAB>  <TAB> if self.arguments.vararg: <TAB>  <TAB>  <TAB> pyobjects.append(rope.base.builtins.get_list()) <MASK> pyobjects.append(rope.base.builtins.get_dict())",if self . arguments . kwarg :,91
1973,"def go_to_last_edit_location(self): <TAB> if self.last_edit_cursor_pos is not None: <TAB>  <TAB> filename, position = self.last_edit_cursor_pos <TAB>  <TAB> if not osp.isfile(filename): <TAB>  <TAB>  <TAB> self.last_edit_cursor_pos = None <TAB>  <TAB>  <TAB> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.load(filename) <TAB>  <TAB>  <TAB> editor = self.get_current_editor() <MASK> editor.set_cursor_position(position)",if position < editor . document ( ) . characterCount ( ) :,135
1974,"def _create_sentence_objects(self): <TAB> """"""Returns a list of Sentence objects from the raw text."""""" <TAB> sentence_objects = [] <TAB> sent_tokenizer = SentenceTokenizer(locale=self.language.code) <TAB> seq = Sequence(self.raw) <TAB> seq = sent_tokenizer.transform(seq) <TAB> for start_index, end_index in zip(seq.idx[:-1], seq.idx[1:]): <TAB>  <TAB> # Sentences share the same models as their parent blob <TAB>  <TAB> sent = seq.text[start_index:end_index].strip() <MASK> continue <TAB>  <TAB> s = Sentence(sent, start_index=start_index, end_index=end_index) <TAB>  <TAB> s.detected_languages = self.detected_languages <TAB>  <TAB> sentence_objects.append(s) <TAB> return sentence_objects",if not sent :,196
1975,"def to_json_schema(self, parent=None): <TAB> schema = {} <TAB> if not parent: <TAB>  <TAB> schema[""title""] = self.title <MASK> schema[""description""] = self.description <TAB>  <TAB> if self.has_default: <TAB>  <TAB>  <TAB> schema[""default""] = self.default <TAB>  <TAB> schema[""_required_""] = self.required <TAB> if self.null: <TAB>  <TAB> schema[""type""] = [""string"", ""null""] <TAB> else: <TAB>  <TAB> schema[""type""] = ""string"" <TAB> if self.enum is not None: <TAB>  <TAB> schema[""enum""] = self.enum <TAB> return schema",if self . description :,150
1976,def rmdir(dirname): <TAB> if dirname[-1] == os.sep: <TAB>  <TAB> dirname = dirname[:-1] <TAB> if os.path.islink(dirname): <TAB>  <TAB> return  # do not clear link - we can get out of dir <TAB> for f in os.listdir(dirname): <MASK> continue <TAB>  <TAB> path = dirname + os.sep + f <TAB>  <TAB> if os.path.isdir(path): <TAB>  <TAB>  <TAB> rmdir(path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> os.unlink(path) <TAB> os.rmdir(dirname),"if f in ( ""."" , "".."" ) :",137
1977,"def convert_whole_dir(path=Path(""marian_ckpt/"")): <TAB> for subdir in tqdm(list(path.ls())): <TAB>  <TAB> dest_dir = f""marian_converted/{subdir.name}"" <MASK> continue <TAB>  <TAB> convert(source_dir, dest_dir)","if ( dest_dir / ""pytorch_model.bin"" ) . exists ( ) :",85
1978,"def colorformat(text): <TAB> if text[0:1] == ""#"": <TAB>  <TAB> col = text[1:] <TAB>  <TAB> if len(col) == 6: <TAB>  <TAB>  <TAB> return col <MASK> return col[0] * 2 + col[1] * 2 + col[2] * 2 <TAB> elif text == """": <TAB>  <TAB> return """" <TAB> assert False, ""wrong color format %r"" % text",elif len ( col ) == 3 :,105
1979,"def _init_rel_seek(self): <TAB> ""Sets the file object's position to the relative location set above."" <TAB> rs, fo = self._rel_seek, self._file_obj <TAB> if rs == 0.0: <TAB>  <TAB> fo.seek(0, os.SEEK_SET) <TAB> else: <TAB>  <TAB> fo.seek(0, os.SEEK_END) <TAB>  <TAB> size = fo.tell() <MASK> self._cur_pos = size <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> target = int(size * rs) <TAB>  <TAB>  <TAB> fo.seek(target, os.SEEK_SET) <TAB>  <TAB>  <TAB> self._align_to_newline() <TAB>  <TAB>  <TAB> self._cur_pos = fo.tell()",if rs == 1.0 :,176
1980,"def parse_command_line(self, argv=None): <TAB> """"""Parse the command line"""""" <TAB> if self.config: <TAB>  <TAB> parser = argparse.ArgumentParser(add_help=False) <TAB>  <TAB> self.settings[""config""].add_argument(parser) <TAB>  <TAB> opts, _ = parser.parse_known_args(argv) <TAB>  <TAB> if opts.config is not None: <TAB>  <TAB>  <TAB> self.set(""config"", opts.config) <TAB>  <TAB> self.params.update(self.import_from_module()) <TAB> parser = self.parser() <TAB> opts = parser.parse_args(argv) <TAB> for k, v in opts.__dict__.items(): <MASK> continue <TAB>  <TAB> self.set(k.lower(), v)",if v is None :,177
1981,"def process(self, resources, event=None): <TAB> client = local_session(self.manager.session_factory).client( <TAB>  <TAB> ""shield"", region_name=""us-east-1"" <TAB> ) <TAB> protections = get_type_protections(client, self.manager.get_model()) <TAB> protected_resources = {p[""ResourceArn""] for p in protections} <TAB> state = self.data.get(""state"", False) <TAB> results = [] <TAB> for arn, r in zip(self.manager.get_arns(resources), resources): <TAB>  <TAB> r[""c7n:ShieldProtected""] = shielded = arn in protected_resources <MASK> results.append(r) <TAB>  <TAB> elif not shielded and not state: <TAB>  <TAB>  <TAB> results.append(r) <TAB> return results",if shielded and state :,199
1982,"def removeTrailingWs(self, aList): <TAB> i = 0 <TAB> while i < len(aList): <MASK> j = i <TAB>  <TAB>  <TAB> i = self.skip_ws(aList, i) <TAB>  <TAB>  <TAB> assert j < i <TAB>  <TAB>  <TAB> if i >= len(aList) or aList[i] == ""\n"": <TAB>  <TAB>  <TAB>  <TAB> # print ""removing trailing ws:"", `i-j` <TAB>  <TAB>  <TAB>  <TAB> del aList[j:i] <TAB>  <TAB>  <TAB>  <TAB> i = j <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> i += 1",if self . is_ws ( aList [ i ] ) :,147
1983,"def predict(request: Request): <TAB> form = await request.form() <TAB> files, entry = convert_input(form) <TAB> try: <MASK> return JSONResponse(ALL_FEATURES_PRESENT_ERROR, status_code=400) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> resp = model.predict(data_dict=[entry]).to_dict(""records"")[0] <TAB>  <TAB>  <TAB> return JSONResponse(resp) <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> logger.error(""Error: {}"".format(str(e))) <TAB>  <TAB>  <TAB> return JSONResponse(COULD_NOT_RUN_INFERENCE_ERROR, status_code=500) <TAB> finally: <TAB>  <TAB> for f in files: <TAB>  <TAB>  <TAB> os.remove(f.name)",if ( entry . keys ( ) & input_features ) != input_features :,192
1984,"def reset(self): <TAB> logger.debug(""Arctic.reset()"") <TAB> with self._lock: <MASK> self.__conn.close() <TAB>  <TAB>  <TAB> self.__conn = None <TAB>  <TAB> for _, l in self._library_cache.items(): <TAB>  <TAB>  <TAB> if hasattr(l, ""_reset"") and callable(l._reset): <TAB>  <TAB>  <TAB>  <TAB> logger.debug(""Library reset() %s"" % l) <TAB>  <TAB>  <TAB>  <TAB> l._reset()  # the existence of _reset() is not guaranteed/enforced, it also triggers re-auth",if self . __conn is not None :,137
1985,"def read(self): <TAB> if op.isfile(self.fileName): <TAB>  <TAB> with textfile_open(self.fileName, ""rt"") as fid: <TAB>  <TAB>  <TAB> items = json.load(fid) <TAB>  <TAB>  <TAB> # TODO: catch JSON exception... <MASK> items = dict() <TAB> else: <TAB>  <TAB> items = dict() <TAB> self._items.clear() <TAB> self._items.update(items) <TAB> self._haveReadData = True",if items is None :,115
1986,"def get_django_comment(text: str, i: int) -> str: <TAB> end = i + 4 <TAB> unclosed_end = 0 <TAB> while end <= len(text): <TAB>  <TAB> if text[end - 2 : end] == ""#}"": <TAB>  <TAB>  <TAB> return text[i:end] <MASK> unclosed_end = end <TAB>  <TAB> end += 1 <TAB> raise TokenizationException(""Unclosed comment"", text[i:unclosed_end])","if not unclosed_end and text [ end ] == ""<"" :",126
1987,"def _wrap_forwarded(self, key, value): <TAB> if isinstance(value, SourceCode) and value.late_binding: <TAB>  <TAB> # get cached return value if present <TAB>  <TAB> value_ = self._late_binding_returnvalues.get(key, KeyError) <MASK> # evaluate the late-bound function <TAB>  <TAB>  <TAB> value_ = self._eval_late_binding(value) <TAB>  <TAB>  <TAB> schema = self.late_bind_schemas.get(key) <TAB>  <TAB>  <TAB> if schema is not None: <TAB>  <TAB>  <TAB>  <TAB> value_ = schema.validate(value_) <TAB>  <TAB>  <TAB> # cache result of late bound func <TAB>  <TAB>  <TAB> self._late_binding_returnvalues[key] = value_ <TAB>  <TAB> return value_ <TAB> else: <TAB>  <TAB> return value",if value_ is KeyError :,187
1988,"def connect(*args, **ckwargs): <TAB> if ""give_content_type"" in kwargs: <MASK> kwargs[""give_content_type""](args[6][""content-type""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> kwargs[""give_content_type""]("""") <TAB> if ""give_connect"" in kwargs: <TAB>  <TAB> kwargs[""give_connect""](*args, **ckwargs) <TAB> status = code_iter.next() <TAB> etag = etag_iter.next() <TAB> timestamp = timestamps_iter.next() <TAB> if status == -1: <TAB>  <TAB> raise HTTPException() <TAB> return FakeConn(status, etag, body=kwargs.get(""body"", """"), timestamp=timestamp)","if len ( args ) >= 7 and ""content_type"" in args [ 6 ] :",178
1989,"def _reset(self): <TAB> self._handle_connect() <TAB> if self.rewarder_session: <MASK> env_id = random.choice(self._sample_env_ids) <TAB>  <TAB>  <TAB> logger.info(""Randomly sampled env_id={}"".format(env_id)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> env_id = None <TAB>  <TAB> self.rewarder_session.reset(env_id=env_id) <TAB> else: <TAB>  <TAB> logger.info( <TAB>  <TAB>  <TAB> ""No rewarder session exists, so cannot send a reset via the rewarder channel"" <TAB>  <TAB> ) <TAB> self._reset_mask() <TAB> return [None] * self.n",if self . _sample_env_ids :,171
1990,"def _create_architecture_list(architectures, current_arch): <TAB> if not architectures: <TAB>  <TAB> return [_Architecture(build_on=[current_arch])] <TAB> build_architectures: List[str] = [] <TAB> architecture_list: List[_Architecture] = [] <TAB> for item in architectures: <TAB>  <TAB> if isinstance(item, str): <TAB>  <TAB>  <TAB> build_architectures.append(item) <MASK> architecture_list.append( <TAB>  <TAB>  <TAB>  <TAB> _Architecture(build_on=item.get(""build-on""), run_on=item.get(""run-on"")) <TAB>  <TAB>  <TAB> ) <TAB> if build_architectures: <TAB>  <TAB> architecture_list.append(_Architecture(build_on=build_architectures)) <TAB> return architecture_list","if isinstance ( item , dict ) :",196
1991,"def inspect(self, pokemon): <TAB> # Make sure it was not caught! <TAB> for caught_pokemon in self.cache: <TAB>  <TAB> same_latitude = ""{0:.4f}"".format(pokemon[""latitude""]) == ""{0:.4f}"".format( <TAB>  <TAB>  <TAB> caught_pokemon[""latitude""] <TAB>  <TAB> ) <TAB>  <TAB> same_longitude = ""{0:.4f}"".format(pokemon[""longitude""]) == ""{0:.4f}"".format( <TAB>  <TAB>  <TAB> caught_pokemon[""longitude""] <TAB>  <TAB> ) <MASK> return <TAB> if len(self.cache) >= 200: <TAB>  <TAB> self.cache.pop(0) <TAB> self.cache.append(pokemon)",if same_latitude and same_longitude :,185
1992,"def parley(self): <TAB> for x in [0, 1]: <TAB>  <TAB> a = self.agents[x].act() <MASK> if ""[DONE]"" in a[""text""]: <TAB>  <TAB>  <TAB>  <TAB> self.agents[x - 1].observe( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> {""id"": ""World"", ""text"": ""The other agent has ended the chat.""} <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> self.episodeDone = True <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.agents[x - 1].observe(a)",if a is not None :,134
1993,"def _prepare_subset( <TAB> full_data: torch.Tensor, <TAB> full_targets: torch.Tensor, <TAB> num_samples: int, <TAB> digits: Sequence,): <TAB> classes = {d: 0 for d in digits} <TAB> indexes = [] <TAB> for idx, target in enumerate(full_targets): <TAB>  <TAB> label = target.item() <TAB>  <TAB> if classes.get(label, float(""inf"")) >= num_samples: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> indexes.append(idx) <TAB>  <TAB> classes[label] += 1 <MASK> break <TAB> data = full_data[indexes] <TAB> targets = full_targets[indexes] <TAB> return data, targets",if all ( classes [ k ] >= num_samples for k in classes ) :,174
1994,"def get_work_root(self, flags): <TAB> _flags = flags.copy() <TAB> _flags[""is_toplevel""] = True <TAB> target = self._get_target(_flags) <TAB> if target: <TAB>  <TAB> _flags[""target""] = target.name <TAB>  <TAB> tool = self.get_tool(_flags) <MASK> return target.name + ""-"" + tool <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise SyntaxError( <TAB>  <TAB>  <TAB>  <TAB> ""Failed to determine work root. Could not resolve tool for target "" <TAB>  <TAB>  <TAB>  <TAB> + target.name <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> raise SyntaxError(""Failed to determine work root. Could not resolve target"")",if tool :,158
1995,"def run_command(self, data): <TAB> """"""Run editor commands."""""" <TAB> parts = data.split("" "") <TAB> cmd = parts[0].lower() <TAB> if cmd in self.operations.keys(): <TAB>  <TAB> return self.run_operation(cmd) <TAB> args = "" "".join(parts[1:]) <TAB> self.logger.debug(""Looking for command '{0}'"".format(cmd)) <TAB> if cmd in self.modules.modules.keys(): <TAB>  <TAB> self.logger.debug(""Trying to run command '{0}'"".format(cmd)) <TAB>  <TAB> self.get_editor().store_action_state(cmd) <MASK> return False <TAB> else: <TAB>  <TAB> self.set_status(""Command '{0}' not found."".format(cmd)) <TAB>  <TAB> return False <TAB> return True","if not self . run_module ( cmd , args ) :",193
1996,"def get_main_chain_layers(self): <TAB> """"""Return a list of layer IDs in the main chain."""""" <TAB> main_chain = self.get_main_chain() <TAB> ret = [] <TAB> for u in main_chain: <TAB>  <TAB> for v, layer_id in self.adj_list[u]: <MASK> ret.append(layer_id) <TAB> return ret",if v in main_chain and u in main_chain :,106
1997,"def hash(self, context): <TAB> with context: <MASK> return IECore.MurmurHash() <TAB>  <TAB> h = GafferDispatch.TaskNode.hash(self, context) <TAB>  <TAB> h.append(self[""fileName""].hash()) <TAB>  <TAB> h.append(self[""in""].hash()) <TAB>  <TAB> h.append(self.__parameterHandler.hash()) <TAB>  <TAB> return h","if not self [ ""fileName"" ] . getValue ( ) or self [ ""in"" ] . source ( ) == self [ ""in"" ] :",116
1998,"def consume_buf(): <TAB> ty = state[""ty""] - 1 <TAB> for i in xrange(state[""buf""].shape[1] // N): <TAB>  <TAB> tx = x // N + i <TAB>  <TAB> src = state[""buf""][:, i * N : (i + 1) * N, :] <MASK> with self.tile_request(tx, ty, readonly=False) as dst: <TAB>  <TAB>  <TAB>  <TAB> mypaintlib.tile_convert_rgba8_to_rgba16(src, dst, self.EOTF) <TAB> if state[""progress""]: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> state[""progress""].completed(ty - ty0) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> logger.exception(""Progress.completed() failed"") <TAB>  <TAB>  <TAB> state[""progress""] = None","if src [ : , : , 3 ] . any ( ) :",188
1999,"def check_permissions(self, obj): <TAB> request = self.context.get(""request"") <TAB> for Perm in permissions: <TAB>  <TAB> perm = Perm() <TAB>  <TAB> if not perm.has_permission(request, self): <TAB>  <TAB>  <TAB> return False <MASK> return False <TAB> return True","if not perm . has_object_permission ( request , self , obj ) :",88
2000,"def _post_order(op): <TAB> if isinstance(op, tvm.tir.Allocate): <TAB>  <TAB> lift_stmt[-1].append(op) <TAB>  <TAB> return op.body <TAB> if isinstance(op, tvm.tir.AttrStmt): <TAB>  <TAB> if op.attr_key == ""storage_scope"": <TAB>  <TAB>  <TAB> lift_stmt[-1].append(op) <TAB>  <TAB>  <TAB> return op.body <MASK> return _merge_block(lift_stmt.pop() + [op], op.body) <TAB>  <TAB> return op <TAB> if isinstance(op, tvm.tir.For): <TAB>  <TAB> return _merge_block(lift_stmt.pop() + [op], op.body) <TAB> raise RuntimeError(""not reached"")","if op . attr_key == ""virtual_thread"" :",188
2001,"def task_done(self): <TAB> with self._cond: <TAB>  <TAB> if not self._unfinished_tasks.acquire(False): <TAB>  <TAB>  <TAB> raise ValueError(""task_done() called too many times"") <MASK> self._cond.notify_all()",if self . _unfinished_tasks . _semlock . _is_zero ( ) :,75
2002,"def get_json(self): <TAB> if not hasattr(self, ""_json""): <TAB>  <TAB> self._json = None <MASK> self._json = json.loads(self.request.body) <TAB> return self._json","if self . request . headers . get ( ""Content-Type"" , """" ) . startswith ( ""application/json"" ) :",74
2003,"def userfullname(): <TAB> """"""Get the user's full name."""""" <TAB> global _userfullname <MASK> uid = os.getuid() <TAB>  <TAB> entry = pwd_from_uid(uid) <TAB>  <TAB> if entry: <TAB>  <TAB>  <TAB> _userfullname = entry[4].split("","")[0] or entry[0] <TAB>  <TAB> if not _userfullname: <TAB>  <TAB>  <TAB> _userfullname = ""user%d"" % uid <TAB> return _userfullname",if not _userfullname :,108
2004,"def test_scatter(self): <TAB> for rank in range(self.world_size): <TAB>  <TAB> tensor = [] <MASK> tensor = [torch.tensor(i) for i in range(self.world_size)] <TAB>  <TAB> result = comm.get().scatter(tensor, rank, size=()) <TAB>  <TAB> self.assertTrue(torch.is_tensor(result)) <TAB>  <TAB> self.assertEqual(result.item(), self.rank)",if self . rank == rank :,109
2005,"def decompile(decompiler): <TAB> for pos, next_pos, opname, arg in decompiler.instructions: <TAB>  <TAB> if pos in decompiler.targets: <TAB>  <TAB>  <TAB> decompiler.process_target(pos) <TAB>  <TAB> method = getattr(decompiler, opname, None) <TAB>  <TAB> if method is None: <TAB>  <TAB>  <TAB> throw(DecompileError(""Unsupported operation: %s"" % opname)) <TAB>  <TAB> decompiler.pos = pos <TAB>  <TAB> decompiler.next_pos = next_pos <TAB>  <TAB> x = method(*arg) <MASK> decompiler.stack.append(x)",if x is not None :,143
2006,"def print_scenario_ran(self, scenario): <TAB> if scenario.passed: <TAB>  <TAB> self.wrt(""OK"") <TAB> elif scenario.failed: <TAB>  <TAB> reason = self.scenarios_and_its_fails[scenario] <MASK> self.wrt(""FAILED"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.wrt(""ERROR"") <TAB> self.wrt(""\n"")","if isinstance ( reason . exception , AssertionError ) :",102
2007,"def detect_ssl_option(self): <TAB> for option in self.ssl_options(): <TAB>  <TAB> if scan_argv(self.argv, option) is not None: <TAB>  <TAB>  <TAB> for other_option in self.ssl_options(): <TAB>  <TAB>  <TAB>  <TAB> if option != other_option: <MASK> raise ConfigurationError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Cannot give both %s and %s"" % (option, other_option) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return option","if scan_argv ( self . argv , other_option ) is not None :",140
2008,"def print_po_snippet(en_loc_old_lists, context): <TAB> for m, localized, old in zip(*en_loc_old_lists): <TAB>  <TAB> if m == """": <TAB>  <TAB>  <TAB> continue <MASK> localized = old <TAB>  <TAB> print( <TAB>  <TAB>  <TAB> ""#: {file}:{line}\n"" <TAB>  <TAB>  <TAB> 'msgid ""{context}{en_month}""\n' <TAB>  <TAB>  <TAB> 'msgstr ""{localized_month}""\n'.format( <TAB>  <TAB>  <TAB>  <TAB> context=context, <TAB>  <TAB>  <TAB>  <TAB> file=filename, <TAB>  <TAB>  <TAB>  <TAB> line=print_po_snippet.line, <TAB>  <TAB>  <TAB>  <TAB> en_month=m, <TAB>  <TAB>  <TAB>  <TAB> localized_month=localized, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB>  <TAB> print_po_snippet.line += 1",if m == localized :,190
2009,"def set_status(self, dict_new): <TAB> for i, value in dict_new.items(): <TAB>  <TAB> self.dict_bili[i] = value <MASK> self.dict_bili[""pcheaders""][""cookie""] = value <TAB>  <TAB>  <TAB> self.dict_bili[""appheaders""][""cookie""] = value","if i == ""cookie"" :",85
2010,"def makeSomeFiles(pathobj, dirdict): <TAB> pathdict = {} <TAB> for (key, value) in dirdict.items(): <TAB>  <TAB> child = pathobj.child(key) <MASK> pathdict[key] = child <TAB>  <TAB>  <TAB> child.setContent(value) <TAB>  <TAB> elif isinstance(value, dict): <TAB>  <TAB>  <TAB> child.createDirectory() <TAB>  <TAB>  <TAB> pathdict[key] = makeSomeFiles(child, value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""only strings and dicts allowed as values"") <TAB> return pathdict","if isinstance ( value , bytes ) :",138
2011,"def _truncate_to_length(generator, len_map=None): <TAB> for example in generator: <TAB>  <TAB> example = list(example) <TAB>  <TAB> if len_map is not None: <TAB>  <TAB>  <TAB> for key, max_len in len_map.items(): <TAB>  <TAB>  <TAB>  <TAB> example_len = example[key].shape <MASK> example[key] = np.resize(example[key], max_len) <TAB>  <TAB> yield tuple(example)",if example_len > max_len :,120
2012,"def check(self, **kw): <TAB> if not kw: <TAB>  <TAB> return exists(self.strpath) <TAB> if len(kw) == 1: <TAB>  <TAB> if ""dir"" in kw: <TAB>  <TAB>  <TAB> return not kw[""dir""] ^ isdir(self.strpath) <MASK> return not kw[""file""] ^ isfile(self.strpath) <TAB> return super(LocalPath, self).check(**kw)","if ""file"" in kw :",106
2013,"def next_instruction_is_function_or_class(lines): <TAB> """"""Is the first non-empty, non-commented line of the cell either a function or a class?"""""" <TAB> parser = StringParser(""python"") <TAB> for i, line in enumerate(lines): <TAB>  <TAB> if parser.is_quoted(): <TAB>  <TAB>  <TAB> parser.read_line(line) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> parser.read_line(line) <TAB>  <TAB> if not line.strip():  # empty line <TAB>  <TAB>  <TAB> if i > 0 and not lines[i - 1].strip(): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if line.startswith(""def "") or line.startswith(""class ""): <TAB>  <TAB>  <TAB> return True <MASK> continue <TAB>  <TAB> return False <TAB> return False","if line . startswith ( ( ""#"" , ""@"" , "" "" , "")"" ) ) :",194
2014,"def askCheckReadFile(self, localFile, remoteFile): <TAB> if not kb.bruteMode: <TAB>  <TAB> message = ""do you want confirmation that the remote file '%s' "" % remoteFile <TAB>  <TAB> message += ""has been successfully downloaded from the back-end "" <TAB>  <TAB> message += ""DBMS file system? [Y/n] "" <MASK> return self._checkFileLength(localFile, remoteFile, True) <TAB> return None","if readInput ( message , default = ""Y"" , boolean = True ) :",118
2015,"def process_tag(hive_name, company, company_key, tag, default_arch): <TAB> with winreg.OpenKeyEx(company_key, tag) as tag_key: <TAB>  <TAB> version = load_version_data(hive_name, company, tag, tag_key) <TAB>  <TAB> if version is not None:  # if failed to get version bail <TAB>  <TAB>  <TAB> major, minor, _ = version <TAB>  <TAB>  <TAB> arch = load_arch_data(hive_name, company, tag, tag_key, default_arch) <MASK> exe_data = load_exe(hive_name, company, company_key, tag) <TAB>  <TAB>  <TAB>  <TAB> if exe_data is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> exe, args = exe_data <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return company, major, minor, arch, exe, args",if arch is not None :,199
2016,"def _get_matching_bracket(self, s, pos): <TAB> if s[pos] != ""{"": <TAB>  <TAB> return None <TAB> end = len(s) <TAB> depth = 1 <TAB> pos += 1 <TAB> while pos != end: <TAB>  <TAB> c = s[pos] <TAB>  <TAB> if c == ""{"": <TAB>  <TAB>  <TAB> depth += 1 <MASK> depth -= 1 <TAB>  <TAB> if depth == 0: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> pos += 1 <TAB> if pos < end and s[pos] == ""}"": <TAB>  <TAB> return pos <TAB> return None","elif c == ""}"" :",132
2017,"def pred(field, value, item): <TAB> for suffix, p in _BUILTIN_PREDS.iteritems(): <TAB>  <TAB> if field.endswith(suffix): <TAB>  <TAB>  <TAB> f = field[: field.index(suffix)] <MASK> return False <TAB>  <TAB>  <TAB> return p(getattr(item, f), value) <TAB> if not hasattr(item, field) or getattr(item, field) is None: <TAB>  <TAB> return False <TAB> if isinstance(value, type(lambda x: x)): <TAB>  <TAB> return value(getattr(item, field)) <TAB> return getattr(item, field) == value","if not hasattr ( item , f ) or getattr ( item , f ) is None :",155
2018,"def init_weights(self): <TAB> """"""Initialize model weights."""""" <TAB> for _, m in self.multi_deconv_layers.named_modules(): <TAB>  <TAB> if isinstance(m, nn.ConvTranspose2d): <TAB>  <TAB>  <TAB> normal_init(m, std=0.001) <TAB>  <TAB> elif isinstance(m, nn.BatchNorm2d): <TAB>  <TAB>  <TAB> constant_init(m, 1) <TAB> for m in self.multi_final_layers.modules(): <MASK> normal_init(m, std=0.001, bias=0)","if isinstance ( m , nn . Conv2d ) :",139
2019,"def test_byteswap(self): <TAB> if self.typecode == ""u"": <TAB>  <TAB> example = ""\U00100100"" <TAB> else: <TAB>  <TAB> example = self.example <TAB> a = array.array(self.typecode, example) <TAB> self.assertRaises(TypeError, a.byteswap, 42) <TAB> if a.itemsize in (1, 2, 4, 8): <TAB>  <TAB> b = array.array(self.typecode, example) <TAB>  <TAB> b.byteswap() <MASK> self.assertEqual(a, b) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertNotEqual(a, b) <TAB>  <TAB> b.byteswap() <TAB>  <TAB> self.assertEqual(a, b)",if a . itemsize == 1 :,171
2020,"def _remove_blocks_from_variables(variables): <TAB> new_variables = [] <TAB> for name, variable in variables: <MASK> new_variables.extend(variable.locals) <TAB>  <TAB>  <TAB> new_variables.append((name, variable.result)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_variables.append((name, variable)) <TAB> return new_variables",if variable . is_block ( ) :,94
2021,def scope(self): <MASK> self.lazy_init_lock_.acquire() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if self.scope_ is None: <TAB>  <TAB>  <TAB>  <TAB> self.scope_ = Scope() <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self.lazy_init_lock_.release() <TAB> return self.scope_,if self . scope_ is None :,84
2022,"def translate(): <TAB> assert Lex.next() is AttributeList <TAB> reader.read()  # Discard attribute list from reader. <TAB> attrs = {} <TAB> d = AttributeList.match.groupdict() <TAB> for k, v in d.items(): <TAB>  <TAB> if v is not None: <TAB>  <TAB>  <TAB> if k == ""attrlist"": <TAB>  <TAB>  <TAB>  <TAB> v = subs_attrs(v) <MASK> parse_attributes(v, attrs) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> AttributeList.attrs[k] = v <TAB> AttributeList.subs(attrs) <TAB> AttributeList.attrs.update(attrs)",if v :,150
2023,"def parse(self, response): <TAB> try: <TAB>  <TAB> content = response.content.decode(""utf-8"", ""ignore"") <TAB>  <TAB> content = json.loads(content, strict=False) <TAB> except: <TAB>  <TAB> self.logger.error(""Fail to parse the response in json format"") <TAB>  <TAB> return <TAB> for item in content[""data""]: <MASK> img_url = self._decode_url(item[""objURL""]) <TAB>  <TAB> elif ""hoverURL"" in item: <TAB>  <TAB>  <TAB> img_url = item[""hoverURL""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> yield dict(file_url=img_url)","if ""objURL"" in item :",158
2024,"def canonicalize_instruction_name(instr): <TAB> name = instr.insn_name().upper() <TAB> # XXX bypass a capstone bug that incorrectly labels some insns as mov <TAB> if name == ""MOV"": <TAB>  <TAB> if instr.mnemonic.startswith(""lsr""): <TAB>  <TAB>  <TAB> return ""LSR"" <TAB>  <TAB> elif instr.mnemonic.startswith(""lsl""): <TAB>  <TAB>  <TAB> return ""LSL"" <MASK> return ""ASR"" <TAB> return OP_NAME_MAP.get(name, name)","elif instr . mnemonic . startswith ( ""asr"" ) :",135
2025,"def _clean_regions(items, region): <TAB> """"""Intersect region with target file if it exists"""""" <TAB> variant_regions = bedutils.population_variant_regions(items, merged=True) <TAB> with utils.tmpfile() as tx_out_file: <TAB>  <TAB> target = subset_variant_regions(variant_regions, region, tx_out_file, items) <MASK> if isinstance(target, six.string_types) and os.path.isfile(target): <TAB>  <TAB>  <TAB>  <TAB> target = _load_regions(target) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> target = [target] <TAB>  <TAB>  <TAB> return target",if target :,151
2026,def reader_leaves(self): <TAB> self.mutex.acquire() <TAB> try: <TAB>  <TAB> self.active_readers -= 1 <MASK> self.active_writers += 1 <TAB>  <TAB>  <TAB> self.waiting_writers -= 1 <TAB>  <TAB>  <TAB> self.can_write.release() <TAB> finally: <TAB>  <TAB> self.mutex.release(),if self . active_readers == 0 and self . waiting_writers != 0 :,101
2027,"def _bpe_to_words(sentence, delimiter=""@@""): <TAB> """"""Convert a sequence of bpe words into sentence."""""" <TAB> words = [] <TAB> word = """" <TAB> delimiter_len = len(delimiter) <TAB> for subwords in sentence: <MASK> word += subwords[:-delimiter_len] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> word += subwords <TAB>  <TAB>  <TAB> words.append(word) <TAB>  <TAB>  <TAB> word = """" <TAB> return words",if len ( subwords ) >= delimiter_len and subwords [ - delimiter_len : ] == delimiter :,121
2028,"def _make_var_names(exog): <TAB> if hasattr(exog, ""name""): <TAB>  <TAB> var_names = exog.name <TAB> elif hasattr(exog, ""columns""): <TAB>  <TAB> var_names = exog.columns <TAB> else: <TAB>  <TAB> raise ValueError(""exog is not a Series or DataFrame or is unnamed."") <TAB> try: <TAB>  <TAB> var_names = "" "".join(var_names) <TAB> except TypeError:  # cannot have names that are numbers, pandas default <TAB>  <TAB> from statsmodels.base.data import _make_exog_names <MASK> var_names = ""x1"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> var_names = "" "".join(_make_exog_names(exog)) <TAB> return var_names",if exog . ndim == 1 :,177
2029,"def __start_element_handler(self, name, attrs): <TAB> if name == ""mime-type"": <MASK> for extension in self.extensions: <TAB>  <TAB>  <TAB>  <TAB> self[extension] = self.type <TAB>  <TAB> self.type = attrs[""type""].lower() <TAB>  <TAB> self.extensions = [] <TAB> elif name == ""glob"": <TAB>  <TAB> pattern = attrs[""pattern""] <TAB>  <TAB> if pattern.startswith(""*.""): <TAB>  <TAB>  <TAB> self.extensions.append(pattern[1:].lower())",if self . type :,120
2030,"def nodes(self, id=None, name=None): <TAB> for node_dict in self.node_ls(id=id, name=name): <TAB>  <TAB> node_id = node_dict[""ID""] <TAB>  <TAB> node = DockerNode(self, node_id, inspect=node_dict) <MASK> continue <TAB>  <TAB> yield node",if self . _node_prefix and not node . name . startswith ( self . _node_prefix ) :,101
2031,"def fix_repeating_arguments(self): <TAB> """"""Fix elements that should accumulate/increment values."""""" <TAB> either = [list(child.children) for child in transform(self).children] <TAB> for case in either: <TAB>  <TAB> for e in [child for child in case if case.count(child) > 1]: <TAB>  <TAB>  <TAB> if type(e) is Argument or type(e) is Option and e.argcount: <TAB>  <TAB>  <TAB>  <TAB> if e.value is None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> e.value = [] <TAB>  <TAB>  <TAB>  <TAB> elif type(e.value) is not list: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> e.value = e.value.split() <MASK> e.value = 0 <TAB> return self",if type ( e ) is Command or type ( e ) is Option and e . argcount == 0 :,190
2032,"def vi_search(self, rng): <TAB> for i in rng: <TAB>  <TAB> line_history = self._history.history[i] <TAB>  <TAB> pos = line_history.get_line_text().find(self._vi_search_text) <MASK> self._history.history_cursor = i <TAB>  <TAB>  <TAB> self.l_buffer.line_buffer = list(line_history.line_buffer) <TAB>  <TAB>  <TAB> self.l_buffer.point = pos <TAB>  <TAB>  <TAB> self.vi_undo_restart() <TAB>  <TAB>  <TAB> return True <TAB> self._bell() <TAB> return False",if pos >= 0 :,144
2033,"def visitIf(self, node, scope): <TAB> for test, body in node.tests: <MASK> if type(test.value) in self._const_types: <TAB>  <TAB>  <TAB>  <TAB> if not test.value: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> self.visit(test, scope) <TAB>  <TAB> self.visit(body, scope) <TAB> if node.else_: <TAB>  <TAB> self.visit(node.else_, scope)","if isinstance ( test , ast . Const ) :",112
2034,"def collect(self): <TAB> for nickname in self.squid_hosts.keys(): <TAB>  <TAB> squid_host = self.squid_hosts[nickname] <TAB>  <TAB> fulldata = self._getData(squid_host[""host""], squid_host[""port""]) <MASK> fulldata = fulldata.splitlines() <TAB>  <TAB>  <TAB> for data in fulldata: <TAB>  <TAB>  <TAB>  <TAB> matches = self.stat_pattern.match(data) <TAB>  <TAB>  <TAB>  <TAB> if matches: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.publish_counter( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""%s.%s"" % (nickname, matches.group(1)), float(matches.group(2)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> )",if fulldata is not None :,166
2035,"def convert(x, base, exponents): <TAB> out = [] <TAB> for e in exponents: <TAB>  <TAB> d = int(x / (base ** e)) <TAB>  <TAB> x -= d * (base ** e) <TAB>  <TAB> out.append(digits[d]) <MASK> break <TAB> return out",if x == 0 and e < 0 :,80
2036,"def print_doc(manager, options): <TAB> plugin_name = options.doc <TAB> plugin = plugins.get(plugin_name, None) <TAB> if plugin: <MASK> console(""Plugin %s does not have documentation"" % plugin_name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> console("""") <TAB>  <TAB>  <TAB> console(trim(plugin.instance.__doc__)) <TAB>  <TAB>  <TAB> console("""") <TAB> else: <TAB>  <TAB> console(""Could not find plugin %s"" % plugin_name)",if not plugin . instance . __doc__ :,120
2037,"def _set_attrs(self, attrs): <TAB> for attr in self.ATTRS: <TAB>  <TAB> if attr in attrs: <TAB>  <TAB>  <TAB> setattr(self, attr, attrs[attr]) <TAB>  <TAB>  <TAB> del attrs[attr] <TAB>  <TAB> else: <MASK> setattr(self, attr, NO_DEFAULT) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> setattr(self, attr, None) <TAB> if attrs: <TAB>  <TAB> attrs = sorted(attrs.keys()) <TAB>  <TAB> raise OptionError(""invalid keyword arguments: %s"" % "", "".join(attrs), self)","if attr == ""default"" :",139
2038,"def _get_set_scope( <TAB> ir_set: irast.Set, scope_tree: irast.ScopeTreeNode) -> irast.ScopeTreeNode: <TAB> if ir_set.path_scope_id: <TAB>  <TAB> new_scope = scope_tree.root.find_by_unique_id(ir_set.path_scope_id) <MASK> raise errors.InternalServerError( <TAB>  <TAB>  <TAB>  <TAB> f""dangling scope pointer to node with uid"" <TAB>  <TAB>  <TAB>  <TAB> f"":{ir_set.path_scope_id} in {ir_set!r}"" <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> new_scope = scope_tree <TAB> return new_scope",if new_scope is None :,172
2039,"def test_leave_one_out(self): <TAB> correct = 0 <TAB> k = 3 <TAB> model = kNN.train(xs, ys, k) <TAB> predictions = [1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1] <TAB> for i in range(len(predictions)): <TAB>  <TAB> model = kNN.train(xs[:i] + xs[i + 1 :], ys[:i] + ys[i + 1 :], k) <TAB>  <TAB> prediction = kNN.classify(model, xs[i]) <TAB>  <TAB> self.assertEqual(prediction, predictions[i]) <MASK> correct += 1 <TAB> self.assertEqual(correct, 13)",if prediction == ys [ i ] :,177
2040,"def import_files(self, files): <TAB> """"""Import a list of MORE (.csv) files."""""" <TAB> c = self.c <TAB> if files: <TAB>  <TAB> changed = False <TAB>  <TAB> self.tab_width = c.getTabWidth(c.p) <TAB>  <TAB> for fileName in files: <TAB>  <TAB>  <TAB> g.setGlobalOpenDir(fileName) <TAB>  <TAB>  <TAB> p = self.import_file(fileName) <MASK> p.contract() <TAB>  <TAB>  <TAB>  <TAB> p.setDirty() <TAB>  <TAB>  <TAB>  <TAB> c.setChanged(True) <TAB>  <TAB>  <TAB>  <TAB> changed = True <TAB>  <TAB> if changed: <TAB>  <TAB>  <TAB> c.redraw(p)",if p :,160
2041,"def getPageTemplate(payload, place): <TAB> retVal = (kb.originalPage, kb.errorIsNone) <TAB> if payload and place: <MASK> page, _, _ = Request.queryPage(payload, place, content=True, raise404=False) <TAB>  <TAB>  <TAB> kb.pageTemplates[(payload, place)] = (page, kb.lastParserStatus is None) <TAB>  <TAB> retVal = kb.pageTemplates[(payload, place)] <TAB> return retVal","if ( payload , place ) not in kb . pageTemplates :",125
2042,"def _skip_trivial(constraint_data): <TAB> if skip_trivial_constraints: <TAB>  <TAB> if isinstance(constraint_data, LinearCanonicalRepn): <TAB>  <TAB>  <TAB> if constraint_data.variables is None: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <MASK> return True <TAB> return False",if constraint_data . body . polynomial_degree ( ) == 0 :,90
2043,"def get_unique_attribute(self, name: str): <TAB> feat = None <TAB> for f in self.features: <TAB>  <TAB> if self._return_feature(f) and hasattr(f, name): <MASK> raise RuntimeError(""The attribute was not unique."") <TAB>  <TAB>  <TAB> feat = f <TAB> if feat is None: <TAB>  <TAB> raise RuntimeError(""The attribute did not exist"") <TAB> return getattr(feat, name)",if feat is not None :,106
2044,"def hideEvent(self, event): <TAB> """"""Reimplement Qt method"""""" <TAB> if not self.light: <TAB>  <TAB> for plugin in self.widgetlist: <MASK> plugin.visibility_changed(True) <TAB> QMainWindow.hideEvent(self, event)",if plugin . isAncestorOf ( self . last_focused_widget ) :,87
2045,"def move_stdout_to_stderr(self): <TAB> to_remove = [] <TAB> to_add = [] <TAB> for consumer_level, consumer in self.consumers: <MASK> to_remove.append((consumer_level, consumer)) <TAB>  <TAB>  <TAB> to_add.append((consumer_level, sys.stderr)) <TAB> for item in to_remove: <TAB>  <TAB> self.consumers.remove(item) <TAB> self.consumers.extend(to_add)",if consumer == sys . stdout :,124
2046,"def create(exported_python_target): <TAB> if exported_python_target not in created: <TAB>  <TAB> self.context.log.info( <TAB>  <TAB>  <TAB> ""Creating setup.py project for {}"".format(exported_python_target) <TAB>  <TAB> ) <TAB>  <TAB> subject = self.derived_by_original.get( <TAB>  <TAB>  <TAB> exported_python_target, exported_python_target <TAB>  <TAB> ) <TAB>  <TAB> setup_dir, dependencies = self.create_setup_py(subject, dist_dir) <TAB>  <TAB> created[exported_python_target] = setup_dir <MASK> for dep in dependencies: <TAB>  <TAB>  <TAB>  <TAB> if is_exported_python_target(dep): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> create(dep)",if self . _recursive :,172
2047,"def __add__(self, other): <TAB> other = ArithmeticExpression.try_unpack_const(other) <TAB> if not self.symbolic and type(other) is int: <TAB>  <TAB> return SpOffset(self._bits, self._to_signed(self.offset + other)) <TAB> else: <MASK> return SpOffset(self._bits, self.offset + other) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return SpOffset( <TAB>  <TAB>  <TAB>  <TAB> self._bits, <TAB>  <TAB>  <TAB>  <TAB> ArithmeticExpression( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ArithmeticExpression.Add, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.offset, <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> other, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB> )",if self . symbolic :,180
2048,"def check_connection(conn): <TAB> tables = [ <TAB>  <TAB> r[0] <TAB>  <TAB> for r in conn.execute( <TAB>  <TAB>  <TAB> ""select name from sqlite_master where type='table'"" <TAB>  <TAB> ).fetchall() <TAB> ] <TAB> for table in tables: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> conn.execute( <TAB>  <TAB>  <TAB>  <TAB> f""PRAGMA table_info({escape_sqlite(table)});"", <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> except sqlite3.OperationalError as e: <MASK> raise SpatialiteConnectionProblem(e) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise ConnectionProblem(e)","if e . args [ 0 ] == ""no such module: VirtualSpatialIndex"" :",161
2049,"def _get_github_client(self) -> ""Github"": <TAB> from github import Github <TAB> if self.access_token_secret is not None: <TAB>  <TAB> # If access token secret specified, load it <TAB>  <TAB> access_token = Secret(self.access_token_secret).get() <TAB> else: <TAB>  <TAB> # Otherwise, fallback to loading from local secret or environment variable <TAB>  <TAB> access_token = prefect.context.get(""secrets"", {}).get(""GITHUB_ACCESS_TOKEN"") <MASK> access_token = os.getenv(""GITHUB_ACCESS_TOKEN"") <TAB> return Github(access_token)",if access_token is None :,149
2050,"def make_tab(lists): <TAB> if hasattr(lists, ""tolist""): <TAB>  <TAB> lists = lists.tolist() <TAB> ut = [] <TAB> for rad in lists: <MASK> ut.append(""\t"".join([""%s"" % x for x in rad])) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ut.append(""%s"" % rad) <TAB> return ""\n"".join(ut)","if type ( rad ) in [ list , tuple ] :",102
2051,"def _ensure_ffi_initialized(cls): <TAB> with cls._init_lock: <MASK> cls.lib = build_conditional_library(lib, CONDITIONAL_NAMES) <TAB>  <TAB>  <TAB> cls._lib_loaded = True <TAB>  <TAB>  <TAB> # initialize the SSL library <TAB>  <TAB>  <TAB> cls.lib.SSL_library_init() <TAB>  <TAB>  <TAB> # adds all ciphers/digests for EVP <TAB>  <TAB>  <TAB> cls.lib.OpenSSL_add_all_algorithms() <TAB>  <TAB>  <TAB> # loads error strings for libcrypto and libssl functions <TAB>  <TAB>  <TAB> cls.lib.SSL_load_error_strings() <TAB>  <TAB>  <TAB> cls._register_osrandom_engine()",if not cls . _lib_loaded :,162
2052,def writer_leaves(self): <TAB> self.mutex.acquire() <TAB> try: <TAB>  <TAB> self.active_writers -= 1 <TAB>  <TAB> if self.waiting_writers != 0: <TAB>  <TAB>  <TAB> self.active_writers += 1 <TAB>  <TAB>  <TAB> self.waiting_writers -= 1 <TAB>  <TAB>  <TAB> self.can_write.release() <MASK> t = self.waiting_readers <TAB>  <TAB>  <TAB> self.waiting_readers = 0 <TAB>  <TAB>  <TAB> self.active_readers += t <TAB>  <TAB>  <TAB> while t > 0: <TAB>  <TAB>  <TAB>  <TAB> self.can_read.release() <TAB>  <TAB>  <TAB>  <TAB> t -= 1 <TAB> finally: <TAB>  <TAB> self.mutex.release(),elif self . waiting_readers != 0 :,171
2053,"def _spans(self, operands): <TAB> spans = {} <TAB> k = 0 <TAB> j = 0 <TAB> for mode in (self.FLOAT, self.MPMATH): <TAB>  <TAB> for i, operand in enumerate(operands[k:]): <TAB>  <TAB>  <TAB> if operand[0] > mode: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> j = i + k + 1 <MASK> # only init state? then ignore. <TAB>  <TAB>  <TAB> j = 0 <TAB>  <TAB> spans[mode] = slice(k, j) <TAB>  <TAB> k = j <TAB> spans[self.SYMBOLIC] = slice(k, len(operands)) <TAB> return spans",if k == 0 and j == 1 :,152
2054,"def _report_error(self, completion_routine, response=None, message=None): <TAB> if response: <TAB>  <TAB> # Only include the text in case of error. <MASK> status = location.Status(response.status_code, response.text) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> status = location.Status(response.status_code) <TAB> else: <TAB>  <TAB> status = location.Status(500, message) <TAB> if response is None or not response.ok: <TAB>  <TAB> if completion_routine: <TAB>  <TAB>  <TAB> return completion_routine(status) <TAB>  <TAB> raise IOError(response.text) <TAB> else: <TAB>  <TAB> if completion_routine: <TAB>  <TAB>  <TAB> completion_routine(status) <TAB> return location.Status(200, response.content)",if not response . ok :,182
2055,"def readinto(self, buf): <TAB> if self.current_frame: <TAB>  <TAB> n = self.current_frame.readinto(buf) <TAB>  <TAB> if n == 0 and len(buf) != 0: <TAB>  <TAB>  <TAB> self.current_frame = None <TAB>  <TAB>  <TAB> n = len(buf) <TAB>  <TAB>  <TAB> buf[:] = self.file_read(n) <TAB>  <TAB>  <TAB> return n <MASK> raise UnpicklingError(""pickle exhausted before end of frame"") <TAB>  <TAB> return n <TAB> else: <TAB>  <TAB> n = len(buf) <TAB>  <TAB> buf[:] = self.file_read(n) <TAB>  <TAB> return n",if n < len ( buf ) :,154
2056,"def __getitem__(self, name, set=set, getattr=getattr, id=id): <TAB> visited = set() <TAB> mydict = self.basedict <TAB> while 1: <TAB>  <TAB> value = mydict[name] <MASK> return value <TAB>  <TAB> myid = id(mydict) <TAB>  <TAB> assert myid not in visited <TAB>  <TAB> visited.add(myid) <TAB>  <TAB> mydict = mydict.Parent <TAB>  <TAB> if mydict is None: <TAB>  <TAB>  <TAB> return",if value is not None :,120
2057,"def _handle_Mul(self, expr): <TAB> arg0, arg1 = expr.args <TAB> expr_0 = self._expr(arg0) <TAB> if expr_0 is None: <TAB>  <TAB> return None <TAB> expr_1 = self._expr(arg1) <TAB> if expr_1 is None: <TAB>  <TAB> return None <TAB> try: <MASK> # self.tyenv is not used <TAB>  <TAB>  <TAB> mask = (1 << expr.result_size(self.tyenv)) - 1 <TAB>  <TAB>  <TAB> return (expr_0 * expr_1) & mask <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return expr_0 * expr_1 <TAB> except TypeError as e: <TAB>  <TAB> self.l.warning(e) <TAB>  <TAB> return None","if isinstance ( expr_0 , int ) and isinstance ( expr_1 , int ) :",191
2058,"def end_request(self, request_id): <TAB> """"""Removes the information associated with given request_id."""""" <TAB> with self._lock: <TAB>  <TAB> del self._request_wsgi_environ[request_id] <TAB>  <TAB> del self._request_id_to_server_configuration[request_id] <MASK> del self._request_id_to_instance[request_id]",if request_id in self . _request_id_to_instance :,105
2059,def generate(): <MASK> decoder = zlib.decompressobj(16 + zlib.MAX_WBITS) <TAB> while True: <TAB>  <TAB> chunk = self.raw.read(chunk_size) <TAB>  <TAB> if not chunk: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if self._gzipped: <TAB>  <TAB>  <TAB> chunk = decoder.decompress(chunk) <TAB>  <TAB> yield chunk,if self . _gzipped :,87
2060,"def handle(self): <TAB> from poetry.utils.env import EnvManager <TAB> manager = EnvManager(self.poetry) <TAB> current_env = manager.get() <TAB> for venv in manager.list(): <TAB>  <TAB> name = venv.path.name <MASK> name = str(venv.path) <TAB>  <TAB> if venv == current_env: <TAB>  <TAB>  <TAB> self.line(""<info>{} (Activated)</info>"".format(name)) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> self.line(name)","if self . option ( ""full-path"" ) :",129
2061,"def addAggregators(sheet, cols, aggrnames): <TAB> ""Add each aggregator in list of *aggrnames* to each of *cols*."" <TAB> for aggrname in aggrnames: <TAB>  <TAB> aggrs = vd.aggregators.get(aggrname) <TAB>  <TAB> aggrs = aggrs if isinstance(aggrs, list) else [aggrs] <TAB>  <TAB> for aggr in aggrs: <TAB>  <TAB>  <TAB> for c in cols: <MASK> c.aggregators = [] <TAB>  <TAB>  <TAB>  <TAB> if aggr and aggr not in c.aggregators: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> c.aggregators += [aggr]","if not hasattr ( c , ""aggregators"" ) :",149
2062,"def on_pre_output_coercion( <TAB> directive_args: Dict[str, Any], <TAB> next_directive: Callable, <TAB> value: Any, <TAB> ctx: Optional[Any], <TAB> info: ""ResolveInfo"",): <TAB> value = await next_directive(value, ctx, info) <TAB> if value is None: <TAB>  <TAB> return value <TAB> try: <TAB>  <TAB> py_enum = _ENUM_MAP[directive_args[""name""]] <MASK> return [None if item is None else py_enum(item).name for item in value] <TAB>  <TAB> return py_enum(value).name <TAB> except Exception: <TAB>  <TAB> pass <TAB> return value","if isinstance ( value , list ) :",163
2063,def cut(sentence): <TAB> sentence = strdecode(sentence) <TAB> blocks = re_han.split(sentence) <TAB> for blk in blocks: <MASK> for word in __cut(blk): <TAB>  <TAB>  <TAB>  <TAB> if word not in Force_Split_Words: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield word <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for c in word: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield c <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tmp = re_skip.split(blk) <TAB>  <TAB>  <TAB> for x in tmp: <TAB>  <TAB>  <TAB>  <TAB> if x: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield x,if re_han . match ( blk ) :,156
2064,"def refresh_archive_action(self): <TAB> archive_name = self.selected_archive_name() <TAB> if archive_name is not None: <TAB>  <TAB> params = BorgInfoArchiveThread.prepare(self.profile(), archive_name) <MASK> thread = BorgInfoArchiveThread(params[""cmd""], params, parent=self.app) <TAB>  <TAB>  <TAB> thread.updated.connect(self._set_status) <TAB>  <TAB>  <TAB> thread.result.connect(self.refresh_archive_result) <TAB>  <TAB>  <TAB> self._toggle_all_buttons(False) <TAB>  <TAB>  <TAB> thread.start()","if params [ ""ok"" ] :",143
2065,"def get_resource_public_actions(resource_class): <TAB> resource_class_members = inspect.getmembers(resource_class) <TAB> resource_methods = {} <TAB> for name, member in resource_class_members: <TAB>  <TAB> if not name.startswith(""_""): <TAB>  <TAB>  <TAB> if not name[0].isupper(): <TAB>  <TAB>  <TAB>  <TAB> if not name.startswith(""wait_until""): <MASK> resource_methods[name] = member <TAB> return resource_methods",if is_resource_action ( member ) :,122
2066,"def _get_compressor(compress_type, compresslevel=None): <TAB> if compress_type == ZIP_DEFLATED: <MASK> return zlib.compressobj(compresslevel, zlib.DEFLATED, -15) <TAB>  <TAB> return zlib.compressobj(zlib.Z_DEFAULT_COMPRESSION, zlib.DEFLATED, -15) <TAB> elif compress_type == ZIP_BZIP2: <TAB>  <TAB> if compresslevel is not None: <TAB>  <TAB>  <TAB> return bz2.BZ2Compressor(compresslevel) <TAB>  <TAB> return bz2.BZ2Compressor() <TAB> # compresslevel is ignored for ZIP_LZMA <TAB> elif compress_type == ZIP_LZMA: <TAB>  <TAB> return LZMACompressor() <TAB> else: <TAB>  <TAB> return None",if compresslevel is not None :,169
2067,"def parse_header(plyfile, ext): <TAB> # Variables <TAB> line = [] <TAB> properties = [] <TAB> num_points = None <TAB> while b""end_header"" not in line and line != b"""": <TAB>  <TAB> line = plyfile.readline() <TAB>  <TAB> if b""element"" in line: <TAB>  <TAB>  <TAB> line = line.split() <TAB>  <TAB>  <TAB> num_points = int(line[2]) <MASK> line = line.split() <TAB>  <TAB>  <TAB> properties.append((line[2].decode(), ext + ply_dtypes[line[1]])) <TAB> return num_points, properties","elif b""property"" in line :",149
2068,"def download_release_artifacts(self, version): <TAB> try: <TAB>  <TAB> os.mkdir(self.artifacts_dir) <TAB> except FileExistsError: <TAB>  <TAB> pass <TAB> for job_name in self.build_ids: <TAB>  <TAB> build_number = self.build_ids.get(job_name) <TAB>  <TAB> build_status = self._get_build_status(job_name, build_number) <MASK> self._download_job_artifact(job_name, build_number, version) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""Build for {} is not fininished"".format(job_name)) <TAB>  <TAB>  <TAB> print(""\tRun 'build' action to check status of {}"".format(job_name))","if build_status == ""built"" :",175
2069,"def update_metadata(self): <TAB> for attrname in dir(self): <MASK> continue <TAB>  <TAB> attrvalue = getattr(self, attrname, None) <TAB>  <TAB> if attrvalue == 0: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if attrname == ""salt_version"": <TAB>  <TAB>  <TAB> attrname = ""version"" <TAB>  <TAB> if hasattr(self.metadata, ""set_{0}"".format(attrname)): <TAB>  <TAB>  <TAB> getattr(self.metadata, ""set_{0}"".format(attrname))(attrvalue) <TAB>  <TAB> elif hasattr(self.metadata, attrname): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> setattr(self.metadata, attrname, attrvalue) <TAB>  <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB>  <TAB> pass","if attrname . startswith ( ""__"" ) :",173
2070,"def check_heuristic_in_sql(): <TAB> heurs = set() <TAB> excluded = [""Equal assembly or pseudo-code"", ""All or most attributes""] <TAB> for heur in HEURISTICS: <TAB>  <TAB> name = heur[""name""] <TAB>  <TAB> if name in excluded: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> sql = heur[""sql""] <MASK> print((""SQL command not correctly associated to %s"" % repr(name))) <TAB>  <TAB>  <TAB> print(sql) <TAB>  <TAB>  <TAB> assert sql.find(name) != -1 <TAB>  <TAB> heurs.add(name) <TAB> print(""Heuristics:"") <TAB> import pprint <TAB> pprint.pprint(heurs)",if sql . lower ( ) . find ( name . lower ( ) ) == - 1 :,171
2071,def gettext(rv): <TAB> for child in rv.childNodes: <MASK> yield child.nodeValue <TAB>  <TAB> if child.nodeType == child.ELEMENT_NODE: <TAB>  <TAB>  <TAB> for item in gettext(child): <TAB>  <TAB>  <TAB>  <TAB> yield item,if child . nodeType == child . TEXT_NODE :,73
2072,"def update(self): <TAB> """"""Update properties over dbus."""""" <TAB> self._check_dbus() <TAB> _LOGGER.info(""Updating service information"") <TAB> self._services.clear() <TAB> try: <TAB>  <TAB> systemd_units = await self.sys_dbus.systemd.list_units() <TAB>  <TAB> for service_data in systemd_units[0]: <MASK> continue <TAB>  <TAB>  <TAB> self._services.add(ServiceInfo.read_from(service_data)) <TAB> except (HassioError, IndexError): <TAB>  <TAB> _LOGGER.warning(""Can't update host service information!"")","if not service_data [ 0 ] . endswith ( "".service"" ) or service_data [ 2 ] != ""loaded"" :",161
2073,"def filtercomments(source): <TAB> """"""NOT USED: strips trailing comments and put them at the top."""""" <TAB> trailing_comments = [] <TAB> comment = True <TAB> while comment: <MASK> comment = source[0, source.index(""*/"") + 2] <TAB>  <TAB> elif re.search(r""^\s*\/\/"", source): <TAB>  <TAB>  <TAB> comment = re.search(r""^\s*\/\/"", source).group(0) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> comment = None <TAB>  <TAB> if comment: <TAB>  <TAB>  <TAB> source = re.sub(r""^\s+"", """", source[len(comment) :]) <TAB>  <TAB>  <TAB> trailing_comments.append(comment) <TAB> return ""\n"".join(trailing_comments) + source","if re . search ( r""^\s*\/\*"" , source ) :",179
2074,"def _getSourceStamp_sync(self, ssid): <TAB> if ssid in self.sourcestamps: <TAB>  <TAB> ssdict = self.sourcestamps[ssid].copy() <TAB>  <TAB> ssdict[""ssid""] = ssid <TAB>  <TAB> patchid = ssdict[""patchid""] <MASK> ssdict.update(self.patches[patchid]) <TAB>  <TAB>  <TAB> ssdict[""patchid""] = patchid <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ssdict[""patch_body""] = None <TAB>  <TAB>  <TAB> ssdict[""patch_level""] = None <TAB>  <TAB>  <TAB> ssdict[""patch_subdir""] = None <TAB>  <TAB>  <TAB> ssdict[""patch_author""] = None <TAB>  <TAB>  <TAB> ssdict[""patch_comment""] = None <TAB>  <TAB> return ssdict <TAB> else: <TAB>  <TAB> return None",if patchid :,184
2075,"def parseImpl(self, instring, loc, doActions=True): <TAB> try: <TAB>  <TAB> loc, tokens = self.expr._parse(instring, loc, doActions, callPreParse=False) <TAB> except (ParseException, IndexError): <TAB>  <TAB> if self.defaultValue is not self.__optionalNotMatched: <MASK> tokens = ParseResults([self.defaultValue]) <TAB>  <TAB>  <TAB>  <TAB> tokens[self.expr.resultsName] = self.defaultValue <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> tokens = [self.defaultValue] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tokens = [] <TAB> return loc, tokens",if self . expr . resultsName :,157
2076,"def _find_exceptions(): <TAB> for _name, obj in iteritems(globals()): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> is_http_exception = issubclass(obj, HTTPException) <TAB>  <TAB> except TypeError: <TAB>  <TAB>  <TAB> is_http_exception = False <TAB>  <TAB> if not is_http_exception or obj.code is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> __all__.append(obj.__name__) <TAB>  <TAB> old_obj = default_exceptions.get(obj.code, None) <MASK> continue <TAB>  <TAB> default_exceptions[obj.code] = obj","if old_obj is not None and issubclass ( obj , old_obj ) :",148
2077,"def generator(self, data): <TAB> for (proc_as, key_buf_ptr) in data: <TAB>  <TAB> key_buf = proc_as.read(key_buf_ptr, 24) <MASK> continue <TAB>  <TAB> key = """".join(""%02X"" % ord(k) for k in key_buf) <TAB>  <TAB> yield ( <TAB>  <TAB>  <TAB> 0, <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB> str(key), <TAB>  <TAB>  <TAB> ], <TAB>  <TAB> )",if not key_buf :,117
2078,"def calculateEnableMargins(self): <TAB> self.cnc.resetEnableMargins() <TAB> for block in self.blocks: <MASK> CNC.vars[""xmin""] = min(CNC.vars[""xmin""], block.xmin) <TAB>  <TAB>  <TAB> CNC.vars[""ymin""] = min(CNC.vars[""ymin""], block.ymin) <TAB>  <TAB>  <TAB> CNC.vars[""zmin""] = min(CNC.vars[""zmin""], block.zmin) <TAB>  <TAB>  <TAB> CNC.vars[""xmax""] = max(CNC.vars[""xmax""], block.xmax) <TAB>  <TAB>  <TAB> CNC.vars[""ymax""] = max(CNC.vars[""ymax""], block.ymax) <TAB>  <TAB>  <TAB> CNC.vars[""zmax""] = max(CNC.vars[""zmax""], block.zmax)",if block . enable :,191
2079,"def __init__(self, client, job_id, callback=None): <TAB> self.client = client <TAB> self.job_id = job_id <TAB> # If a job event has been received already then we must set an Event <TAB> # to wait for this job to finish. <TAB> # Otherwise we create a new stub for the job with the Event for when <TAB> # the job event arrives to use existing event. <TAB> with client._jobs_lock: <TAB>  <TAB> job = client._jobs.get(job_id) <TAB>  <TAB> self.event = None <MASK> self.event = job.get(""__ready"") <TAB>  <TAB> if self.event is None: <TAB>  <TAB>  <TAB> self.event = job[""__ready""] = Event() <TAB>  <TAB> job[""__callback""] = callback",if job :,180
2080,"def asset(*paths): <TAB> for path in paths: <TAB>  <TAB> fspath = www_root + ""/assets/"" + path <TAB>  <TAB> etag = """" <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if env.cache_static: <TAB>  <TAB>  <TAB>  <TAB> etag = asset_etag(fspath) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> os.stat(fspath) <TAB>  <TAB> except FileNotFoundError as e: <TAB>  <TAB>  <TAB> if path == paths[-1]: <MASK> tell_sentry(e, {}) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> tell_sentry(e, {}) <TAB>  <TAB> return asset_url + path + (etag and ""?etag="" + etag)","if not os . path . exists ( fspath + "".spt"" ) :",182
2081,"def set_conf(): <TAB> """"""Collapse all object_trail config into cherrypy.request.config."""""" <TAB> base = cherrypy.config.copy() <TAB> # Note that we merge the config from each node <TAB> # even if that node was None. <TAB> for name, obj, conf, segleft in object_trail: <TAB>  <TAB> base.update(conf) <MASK> base[""tools.staticdir.section""] = ""/"" + ""/"".join( <TAB>  <TAB>  <TAB>  <TAB> fullpath[0 : fullpath_len - segleft] <TAB>  <TAB>  <TAB> ) <TAB> return base","if ""tools.staticdir.dir"" in conf :",145
2082,"def __init__(self): <TAB> self.setLayers(None, None) <TAB> self.interface = None <TAB> self.event_callbacks = {} <TAB> self.__stack = None <TAB> self.lock = threading.Lock() <TAB> members = inspect.getmembers(self, predicate=inspect.ismethod) <TAB> for m in members: <MASK> fname = m[0] <TAB>  <TAB>  <TAB> fn = m[1] <TAB>  <TAB>  <TAB> self.event_callbacks[fn.event_callback] = getattr(self, fname)","if hasattr ( m [ 1 ] , ""event_callback"" ) :",133
2083,def multi_dev_generator(self): <TAB> for data in self._data_loader(): <MASK> self._tail_data += data <TAB>  <TAB> if len(self._tail_data) == self._base_number: <TAB>  <TAB>  <TAB> yield self._tail_data <TAB>  <TAB>  <TAB> self._tail_data = [],if len ( self . _tail_data ) < self . _base_number :,91
2084,"def replace_field_to_value(layout, cb): <TAB> for i, lo in enumerate(layout.fields): <TAB>  <TAB> if isinstance(lo, Field) or issubclass(lo.__class__, Field): <TAB>  <TAB>  <TAB> layout.fields[i] = ShowField( <TAB>  <TAB>  <TAB>  <TAB> cb, *lo.fields, attrs=lo.attrs, wrapper_class=lo.wrapper_class <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> elif isinstance(lo, basestring): <TAB>  <TAB>  <TAB> layout.fields[i] = ShowField(cb, lo) <MASK> replace_field_to_value(lo, cb)","elif hasattr ( lo , ""get_field_names"" ) :",151
2085,"def function_out(*args, **kwargs): <TAB> try: <TAB>  <TAB> return function_in(*args, **kwargs) <TAB> except dbus.exceptions.DBusException as e: <TAB>  <TAB> if e.get_dbus_name() == DBUS_UNKNOWN_METHOD: <TAB>  <TAB>  <TAB> raise ItemNotFoundException(""Item does not exist!"") <TAB>  <TAB> if e.get_dbus_name() == DBUS_NO_SUCH_OBJECT: <TAB>  <TAB>  <TAB> raise ItemNotFoundException(e.get_dbus_message()) <MASK> raise SecretServiceNotAvailableException(e.get_dbus_message()) <TAB>  <TAB> raise","if e . get_dbus_name ( ) in ( DBUS_NO_REPLY , DBUS_NOT_SUPPORTED ) :",162
2086,"def results_iter(self): <TAB> if self.connection.ops.oracle: <TAB>  <TAB> from django.db.models.fields import DateTimeField <TAB>  <TAB> fields = [DateTimeField()] <TAB> else: <TAB>  <TAB> needs_string_cast = self.connection.features.needs_datetime_string_cast <TAB> offset = len(self.query.extra_select) <TAB> for rows in self.execute_sql(MULTI): <TAB>  <TAB> for row in rows: <TAB>  <TAB>  <TAB> date = row[offset] <TAB>  <TAB>  <TAB> if self.connection.ops.oracle: <TAB>  <TAB>  <TAB>  <TAB> date = self.resolve_columns(row, fields)[offset] <MASK> date = typecast_timestamp(str(date)) <TAB>  <TAB>  <TAB> yield date",elif needs_string_cast :,182
2087,"def handle_label(self, path, **options): <TAB> verbosity = int(options.get(""verbosity"", 1)) <TAB> result = finders.find(path, all=options[""all""]) <TAB> path = smart_unicode(path) <TAB> if result: <TAB>  <TAB> if not isinstance(result, (list, tuple)): <TAB>  <TAB>  <TAB> result = [result] <TAB>  <TAB> output = u""\n  "".join( <TAB>  <TAB>  <TAB> (smart_unicode(os.path.realpath(path)) for path in result) <TAB>  <TAB> ) <TAB>  <TAB> self.stdout.write(smart_str(u""Found '%s' here:\n  %s\n"" % (path, output))) <TAB> else: <MASK> self.stderr.write(smart_str(""No matching file found for '%s'.\n"" % path))",if verbosity >= 1 :,193
2088,"def name(self): <TAB> """"""Get the enumeration name of this storage class."""""" <TAB> if self._name_map is None: <TAB>  <TAB> self._name_map = {} <TAB>  <TAB> for key, value in list(StorageClass.__dict__.items()): <MASK> self._name_map[value] = key <TAB> return self._name_map[self]","if isinstance ( value , StorageClass ) :",94
2089,"def index(self, value): <TAB> if self._growing: <TAB>  <TAB> if self._start <= value < self._stop: <TAB>  <TAB>  <TAB> q, r = divmod(value - self._start, self._step) <TAB>  <TAB>  <TAB> if r == self._zero: <TAB>  <TAB>  <TAB>  <TAB> return int(q) <TAB> else: <MASK> q, r = divmod(self._start - value, -self._step) <TAB>  <TAB>  <TAB> if r == self._zero: <TAB>  <TAB>  <TAB>  <TAB> return int(q) <TAB> raise ValueError(""{} is not in numeric range"".format(value))",if self . _start >= value > self . _stop :,146
2090,"def extract_cookie(cookie_header, cookie_name): <TAB> inx = cookie_header.find(cookie_name) <TAB> if inx >= 0: <TAB>  <TAB> end_inx = cookie_header.find("";"", inx) <MASK> value = cookie_header[inx:end_inx] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = cookie_header[inx:] <TAB>  <TAB> return value <TAB> return """"",if end_inx > 0 :,104
2091,"def get_size(self, shape_info): <TAB> # The size is the data, that have constant size. <TAB> state = np.random.RandomState().get_state() <TAB> size = 0 <TAB> for elem in state: <TAB>  <TAB> if isinstance(elem, str): <TAB>  <TAB>  <TAB> size += len(elem) <MASK> size += elem.size * elem.itemsize <TAB>  <TAB> elif isinstance(elem, int): <TAB>  <TAB>  <TAB> size += np.dtype(""int"").itemsize <TAB>  <TAB> elif isinstance(elem, float): <TAB>  <TAB>  <TAB> size += np.dtype(""float"").itemsize <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise NotImplementedError() <TAB> return size","elif isinstance ( elem , np . ndarray ) :",159
2092,"def createFields(self): <TAB> size = self.size / 8 <TAB> if size > 2: <MASK> yield UInt8(self, ""cs"", ""10ms units, values from 0 to 199"") <TAB>  <TAB> yield Bits(self, ""2sec"", 5, ""seconds/2"") <TAB>  <TAB> yield Bits(self, ""min"", 6, ""minutes"") <TAB>  <TAB> yield Bits(self, ""hour"", 5, ""hours"") <TAB> yield Bits(self, ""day"", 5, ""(1-31)"") <TAB> yield Bits(self, ""month"", 4, ""(1-12)"") <TAB> yield Bits(self, ""year"", 7, ""(0 = 1980, 127 = 2107)"")",if size > 4 :,169
2093,"def detect(get_page): <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS: <TAB>  <TAB> page, headers, code = get_page(get=vector) <TAB>  <TAB> retval = ( <TAB>  <TAB>  <TAB> re.search( <TAB>  <TAB>  <TAB>  <TAB> r""incap_ses|visid_incap"", headers.get(HTTP_HEADER.SET_COOKIE, """"), re.I <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> is not None <TAB>  <TAB> ) <TAB>  <TAB> retval |= re.search(r""Incapsula"", headers.get(""X-CDN"", """"), re.I) is not None <MASK> break <TAB> return retval",if retval :,157
2094,"def _get_order_information(self, node_id, timeout=1200, check_interval=5): <TAB> mask = { <TAB>  <TAB> ""billingItem"": """", <TAB>  <TAB> ""powerState"": """", <TAB>  <TAB> ""operatingSystem"": {""passwords"": """"}, <TAB>  <TAB> ""provisionDate"": """", <TAB> } <TAB> for i in range(0, timeout, check_interval): <TAB>  <TAB> res = self.connection.request( <TAB>  <TAB>  <TAB> ""SoftLayer_Virtual_Guest"", ""getObject"", id=node_id, object_mask=mask <TAB>  <TAB> ).object <MASK> return res <TAB>  <TAB> time.sleep(check_interval) <TAB> raise SoftLayerException(""Timeout on getting node details"")","if res . get ( ""provisionDate"" , None ) :",170
2095,"def _process_param_change(self, msg): <TAB> msg = super(Select, self)._process_param_change(msg) <TAB> labels, values = self.labels, self.values <TAB> if ""value"" in msg: <TAB>  <TAB> msg[""value""] = [ <TAB>  <TAB>  <TAB> labels[indexOf(v, values)] for v in msg[""value""] if isIn(v, values) <TAB>  <TAB> ] <TAB> if ""options"" in msg: <TAB>  <TAB> msg[""options""] = labels <MASK> self.value = [v for v in self.value if isIn(v, values)] <TAB> return msg","if any ( not isIn ( v , values ) for v in self . value ) :",161
2096,"def get_object_from_name(self, name, check_symlinks=True): <TAB> if not name: <TAB>  <TAB> return None <TAB> name = name.rstrip(""\\"") <TAB> for a, o in self.objects.items(): <TAB>  <TAB> if not o.name: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if o.name.lower() == name.lower(): <TAB>  <TAB>  <TAB> return o <TAB> if check_symlinks: <TAB>  <TAB> m = [sl[1] for sl in self.symlinks if name.lower() == sl[0].lower()] <MASK> name = m[0] <TAB>  <TAB> return self.get_object_from_name(name, False)",if m :,156
2097,"def run(self): <TAB> for k, v in iteritems(self.objs): <MASK> continue <TAB>  <TAB> if v[""_class""] == ""User"": <TAB>  <TAB>  <TAB> if v[""email""] == """": <TAB>  <TAB>  <TAB>  <TAB> v[""email""] = None <TAB>  <TAB>  <TAB> if v[""ip""] == ""0.0.0.0"": <TAB>  <TAB>  <TAB>  <TAB> v[""ip""] = None <TAB> return self.objs","if k . startswith ( ""_"" ) :",102
2098,"def _providers(self, descriptor): <TAB> res = [] <TAB> for _md in self.metadata.values(): <TAB>  <TAB> for ent_id, ent_desc in _md.items(): <TAB>  <TAB>  <TAB> if descriptor in ent_desc: <MASK> # print(""duplicated entity_id: %s"" % res) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> res.append(ent_id) <TAB> return res",if ent_id in res :,118
2099,"def test_add_participant(self): <TAB> async with self.chat_client: <TAB>  <TAB> await self._create_thread() <TAB>  <TAB> async with self.chat_thread_client: <TAB>  <TAB>  <TAB> share_history_time = datetime.utcnow() <TAB>  <TAB>  <TAB> share_history_time = share_history_time.replace(tzinfo=TZ_UTC) <TAB>  <TAB>  <TAB> new_participant = ChatThreadParticipant( <TAB>  <TAB>  <TAB>  <TAB> user=self.new_user, <TAB>  <TAB>  <TAB>  <TAB> display_name=""name"", <TAB>  <TAB>  <TAB>  <TAB> share_history_time=share_history_time, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> await self.chat_thread_client.add_participant(new_participant) <MASK> await self.chat_client.delete_chat_thread(self.thread_id)",if not self . is_playback ( ) :,197
2100,"def url(regex, view, kwargs=None, name=None, prefix=""""): <TAB> if isinstance(view, (list, tuple)): <TAB>  <TAB> # For include(...) processing. <TAB>  <TAB> urlconf_module, app_name, namespace = view <TAB>  <TAB> return RegexURLResolver( <TAB>  <TAB>  <TAB> regex, urlconf_module, kwargs, app_name=app_name, namespace=namespace <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> if isinstance(view, basestring): <TAB>  <TAB>  <TAB> if not view: <TAB>  <TAB>  <TAB>  <TAB> raise ImproperlyConfigured( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Empty URL pattern view name not permitted (for pattern %r)"" % regex <TAB>  <TAB>  <TAB>  <TAB> ) <MASK> view = prefix + ""."" + view <TAB>  <TAB> return RegexURLPattern(regex, view, kwargs, name)",if prefix :,183
2101,"def tx(): <TAB> # Sync receiver ready to avoid loss of first packets <TAB> while not sub_ready.ready(): <TAB>  <TAB> pub.send(b""test BEGIN"") <TAB>  <TAB> eventlet.sleep(0.005) <TAB> for i in range(1, 101): <TAB>  <TAB> msg = ""test {0}"".format(i).encode() <MASK> pub.send(msg) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pub.send(b""test LAST"") <TAB>  <TAB>  <TAB> sub_last.wait() <TAB>  <TAB> # XXX: putting a real delay of 1ms here fixes sporadic failures on Travis <TAB>  <TAB> # just yield eventlet.sleep(0) doesn't cut it <TAB>  <TAB> eventlet.sleep(0.001) <TAB> pub.send(b""done DONE"")",if i != 50 :,185
2102,"def remove_tmp_snapshot_file(self, files): <TAB> for filepath in files: <TAB>  <TAB> path = Path(filepath) <TAB>  <TAB> if path.is_dir() and path.exists(): <TAB>  <TAB>  <TAB> shutil.rmtree(path) <MASK> path.unlink()",elif path . is_file ( ) and path . exists ( ) :,78
2103,"def f(view, s): <TAB> if mode == modes.INTERNAL_NORMAL: <TAB>  <TAB> if count == 1: <MASK> eol = view.line(s.b).b <TAB>  <TAB>  <TAB>  <TAB> return R(s.b, eol) <TAB>  <TAB>  <TAB> return s <TAB> return s",if view . line ( s . b ) . size ( ) > 0 :,85
2104,"def get_ids(self, **kwargs): <TAB> id = [] <TAB> if ""id"" in kwargs: <TAB>  <TAB> id = kwargs[""id""] <TAB>  <TAB> # Coerce ids to list <MASK> id = id.split("","") <TAB>  <TAB> # Ensure ids are integers <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> id = list(map(int, id)) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> decorators.error(""Invalid id"") <TAB> return id","if not isinstance ( id , list ) :",111
2105,"def param_value(self): <TAB> # This is part of the ""handle quoted extended parameters"" hack. <TAB> for token in self: <MASK> return token.stripped_value <TAB>  <TAB> if token.token_type == ""quoted-string"": <TAB>  <TAB>  <TAB> for token in token: <TAB>  <TAB>  <TAB>  <TAB> if token.token_type == ""bare-quoted-string"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for token in token: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if token.token_type == ""value"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return token.stripped_value <TAB> return """"","if token . token_type == ""value"" :",143
2106,"def get_all_start_methods(self): <TAB> if sys.platform == ""win32"": <TAB>  <TAB> return [""spawn""] <TAB> else: <TAB>  <TAB> methods = [""spawn"", ""fork""] if sys.platform == ""darwin"" else [""fork"", ""spawn""] <MASK> methods.append(""forkserver"") <TAB>  <TAB> return methods",if reduction . HAVE_SEND_HANDLE :,88
2107,"def _process_watch(self, watched_event): <TAB> logger.debug(""process_watch: %r"", watched_event) <TAB> with handle_exception(self._tree._error_listeners): <MASK> assert self._parent is None, ""unexpected CREATED on non-root"" <TAB>  <TAB>  <TAB> self.on_created() <TAB>  <TAB> elif watched_event.type == EventType.DELETED: <TAB>  <TAB>  <TAB> self.on_deleted() <TAB>  <TAB> elif watched_event.type == EventType.CHANGED: <TAB>  <TAB>  <TAB> self._refresh_data() <TAB>  <TAB> elif watched_event.type == EventType.CHILD: <TAB>  <TAB>  <TAB> self._refresh_children()",if watched_event . type == EventType . CREATED :,172
2108,"def assert_open(self, sock, *rest): <TAB> if isinstance(sock, fd_types): <TAB>  <TAB> self.__assert_fd_open(sock) <TAB> else: <TAB>  <TAB> fileno = sock.fileno() <TAB>  <TAB> assert isinstance(fileno, fd_types), fileno <TAB>  <TAB> sockname = sock.getsockname() <TAB>  <TAB> assert isinstance(sockname, tuple), sockname <MASK> self.__assert_fd_open(fileno) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._assert_sock_open(sock) <TAB> if rest: <TAB>  <TAB> self.assert_open(rest[0], *rest[1:])",if not WIN :,148
2109,"def detype(self): <TAB> """"""De-types the instance, allowing it to be exported to the environment."""""" <TAB> style = self.style <TAB> if self._detyped is None: <TAB>  <TAB> self._detyped = "":"".join( <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB> key <TAB>  <TAB>  <TAB>  <TAB> + ""="" <TAB>  <TAB>  <TAB>  <TAB> + "";"".join( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> LsColors.target_value <MASK> else ansi_color_name_to_escape_code(v, cmap=style) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for v in val <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> for key, val in sorted(self._d.items()) <TAB>  <TAB>  <TAB> ] <TAB>  <TAB> ) <TAB> return self._detyped",if key in self . _targets,198
2110,"def gather_metrics(dry_run=False): <TAB> today = datetime.date.today() <TAB> first = today.replace(day=1) <TAB> last_month = first - datetime.timedelta(days=1) <TAB> filename = ""form_types_{}.csv"".format(last_month.strftime(""%Y-%m"")) <TAB> with connection.cursor() as cursor: <TAB>  <TAB> cursor.execute(REGISTRATION_METRICS_SQL) <MASK> for row in cursor.fetchall(): <TAB>  <TAB>  <TAB>  <TAB> logger.info(encode_row(row)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> write_raw_data(cursor=cursor, filename=filename)",if dry_run :,154
2111,"def cat(tensors, dim=0): <TAB> assert isinstance(tensors, list), ""input to cat must be a list"" <TAB> if len(tensors) == 1: <TAB>  <TAB> return tensors[0] <TAB> from .autograd_cryptensor import AutogradCrypTensor <TAB> if any(isinstance(t, AutogradCrypTensor) for t in tensors): <MASK> tensors[0] = AutogradCrypTensor(tensors[0], requires_grad=False) <TAB>  <TAB> return tensors[0].cat(*tensors[1:], dim=dim) <TAB> else: <TAB>  <TAB> return get_default_backend().cat(tensors, dim=dim)","if not isinstance ( tensors [ 0 ] , AutogradCrypTensor ) :",166
2112,"def is_installed(self, dlc_title="""") -> bool: <TAB> installed = False <TAB> if dlc_title: <TAB>  <TAB> dlc_version = self.get_dlc_info(""version"", dlc_title) <TAB>  <TAB> installed = True if dlc_version else False <TAB>  <TAB> # Start: Code for compatibility with minigalaxy 1.0 <TAB>  <TAB> if not installed: <TAB>  <TAB>  <TAB> status = self.legacy_get_dlc_status(dlc_title) <TAB>  <TAB>  <TAB> installed = True if status in [""installed"", ""updatable""] else False <TAB>  <TAB> # End: Code for compatibility with minigalaxy 1.0 <TAB> else: <MASK> installed = True <TAB> return installed",if self . install_dir and os . path . exists ( self . install_dir ) :,178
2113,"def on_copy(self): <TAB> source_objects = self.__getSelection() <TAB> for source in source_objects: <MASK> new_obj = model.Phrase("""", """") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_obj = model.Script("""", """") <TAB>  <TAB> new_obj.copy(source) <TAB>  <TAB> self.cutCopiedItems.append(new_obj)","if isinstance ( source , model . Phrase ) :",100
2114,"def FetchFn(type_name): <TAB> """"""Fetches all hunt results of a given type."""""" <TAB> offset = 0 <TAB> while True: <TAB>  <TAB> results = data_store.REL_DB.ReadHuntResults( <TAB>  <TAB>  <TAB> hunt_id, offset=offset, count=self._RESULTS_PAGE_SIZE, with_type=type_name <TAB>  <TAB> ) <MASK> break <TAB>  <TAB> for r in results: <TAB>  <TAB>  <TAB> msg = r.AsLegacyGrrMessage() <TAB>  <TAB>  <TAB> msg.source_urn = source_urn <TAB>  <TAB>  <TAB> yield msg <TAB>  <TAB> offset += self._RESULTS_PAGE_SIZE",if not results :,149
2115,"def get_blob_type_declaration_sql(self, column): <TAB> length = column.get(""length"") <TAB> if length: <MASK> return ""TINYBLOB"" <TAB>  <TAB> if length <= self.LENGTH_LIMIT_BLOB: <TAB>  <TAB>  <TAB> return ""BLOB"" <TAB>  <TAB> if length <= self.LENGTH_LIMIT_MEDIUMBLOB: <TAB>  <TAB>  <TAB> return ""MEDIUMBLOB"" <TAB> return ""LONGBLOB""",if length <= self . LENGTH_LIMIT_TINYBLOB :,115
2116,"def decode(cls, data): <TAB> while data: <TAB>  <TAB> ( <TAB>  <TAB>  <TAB> length, <TAB>  <TAB>  <TAB> atype, <TAB>  <TAB> ) = unpack(cls.Header.PACK, data[: cls.Header.LEN]) <MASK> raise AttributesError(""Buffer underrun %d < %d"" % (len(data), length)) <TAB>  <TAB> payload = data[cls.Header.LEN : length] <TAB>  <TAB> yield atype, payload <TAB>  <TAB> data = data[int((length + 3) / 4) * 4 :]",if len ( data ) < length :,128
2117,"def test_join_diffs(db, series_of_diffs, expected): <TAB> diffs = [] <TAB> for changes in series_of_diffs: <TAB>  <TAB> tracker = DBDiffTracker() <TAB>  <TAB> for key, val in changes.items(): <MASK> del tracker[key] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> tracker[key] = val <TAB>  <TAB> diffs.append(tracker.diff()) <TAB> DBDiff.join(diffs).apply_to(db) <TAB> assert db == expected",if val is None :,123
2118,"def ant_map(m): <TAB> tmp = ""rows %s\ncols %s\n"" % (len(m), len(m[0])) <TAB> players = {} <TAB> for row in m: <TAB>  <TAB> tmp += ""m "" <TAB>  <TAB> for col in row: <TAB>  <TAB>  <TAB> if col == LAND: <TAB>  <TAB>  <TAB>  <TAB> tmp += ""."" <TAB>  <TAB>  <TAB> elif col == BARRIER: <TAB>  <TAB>  <TAB>  <TAB> tmp += ""%"" <TAB>  <TAB>  <TAB> elif col == FOOD: <TAB>  <TAB>  <TAB>  <TAB> tmp += ""*"" <MASK> tmp += ""?"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> players[col] = True <TAB>  <TAB>  <TAB>  <TAB> tmp += chr(col + 97) <TAB>  <TAB> tmp += ""\n"" <TAB> tmp = (""players %s\n"" % len(players)) + tmp <TAB> return tmp",elif col == UNSEEN :,199
2119,"def _report_error(self, completion_routine, response=None, message=None): <TAB> if response: <TAB>  <TAB> # Only include the text in case of error. <TAB>  <TAB> if not response.ok: <TAB>  <TAB>  <TAB> status = location.Status(response.status_code, response.text) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> status = location.Status(response.status_code) <TAB> else: <TAB>  <TAB> status = location.Status(500, message) <TAB> if response is None or not response.ok: <MASK> return completion_routine(status) <TAB>  <TAB> raise IOError(response.text) <TAB> else: <TAB>  <TAB> if completion_routine: <TAB>  <TAB>  <TAB> completion_routine(status) <TAB> return location.Status(200, response.content)",if completion_routine :,182
2120,"def _generate_examples(self, src_path=None, tgt_path=None, replace_unk=None): <TAB> """"""Yields examples."""""" <TAB> with tf.io.gfile.GFile(src_path) as f_d, tf.io.gfile.GFile(tgt_path) as f_s: <TAB>  <TAB> for i, (doc_text, sum_text) in enumerate(zip(f_d, f_s)): <MASK> yield i, { <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _DOCUMENT: doc_text.strip().replace(""<unk>"", ""UNK""), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _SUMMARY: sum_text.strip().replace(""<unk>"", ""UNK""), <TAB>  <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield i, {_DOCUMENT: doc_text.strip(), _SUMMARY: sum_text.strip()}",if replace_unk :,198
2121,"def escape(text, newline=False): <TAB> """"""Escape special html characters."""""" <TAB> if isinstance(text, str): <TAB>  <TAB> if ""&"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""&"", ""&amp;"") <TAB>  <TAB> if "">"" in text: <TAB>  <TAB>  <TAB> text = text.replace("">"", ""&gt;"") <TAB>  <TAB> if ""<"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""<"", ""&lt;"") <TAB>  <TAB> if '""' in text: <TAB>  <TAB>  <TAB> text = text.replace('""', ""&quot;"") <TAB>  <TAB> if ""'"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""'"", ""&quot;"") <MASK> if ""\n"" in text: <TAB>  <TAB>  <TAB>  <TAB> text = text.replace(""\n"", ""<br>"") <TAB> return text",if newline :,170
2122,"def _handle_url_click(self, event): <TAB> url = _extract_click_text(self.info_text, event, ""url"") <TAB> if url is not None: <MASK> import webbrowser <TAB>  <TAB>  <TAB> webbrowser.open(url) <TAB>  <TAB> elif os.path.sep in url: <TAB>  <TAB>  <TAB> os.makedirs(url, exist_ok=True) <TAB>  <TAB>  <TAB> open_path_in_system_file_manager(url) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._start_show_package_info(url)","if url . startswith ( ""http:"" ) or url . startswith ( ""https:"" ) :",144
2123,"def SConsignFile(self, name="".sconsign"", dbm_module=None): <TAB> if name is not None: <TAB>  <TAB> name = self.subst(name) <MASK> name = os.path.join(str(self.fs.SConstruct_dir), name) <TAB> if name: <TAB>  <TAB> name = os.path.normpath(name) <TAB>  <TAB> sconsign_dir = os.path.dirname(name) <TAB>  <TAB> if sconsign_dir and not os.path.exists(sconsign_dir): <TAB>  <TAB>  <TAB> self.Execute(SCons.Defaults.Mkdir(sconsign_dir)) <TAB> SCons.SConsign.File(name, dbm_module)",if not os . path . isabs ( name ) :,178
2124,"def on_train_start(self, trainer: Trainer, pl_module: LightningModule) -> None: <TAB> super().on_train_start(trainer, pl_module) <TAB> submodule_dict = dict(pl_module.named_modules()) <TAB> self._hook_handles = [] <TAB> for name in self._get_submodule_names(pl_module): <MASK> rank_zero_warn( <TAB>  <TAB>  <TAB>  <TAB> f""{name} is not a valid identifier for a submodule in {pl_module.__class__.__name__},"" <TAB>  <TAB>  <TAB>  <TAB> "" skipping this key."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> handle = self._register_hook(name, submodule_dict[name]) <TAB>  <TAB> self._hook_handles.append(handle)",if name not in submodule_dict :,184
2125,"def validate_configuration(self, configuration: Optional[ExpectationConfiguration]): <TAB> super().validate_configuration(configuration) <TAB> if configuration is None: <TAB>  <TAB> configuration = self.configuration <TAB> try: <TAB>  <TAB> assert ""value_set"" in configuration.kwargs, ""value_set is required"" <TAB>  <TAB> assert isinstance( <TAB>  <TAB>  <TAB> configuration.kwargs[""value_set""], (list, set, dict) <TAB>  <TAB> ), ""value_set must be a list or a set"" <MASK> assert ( <TAB>  <TAB>  <TAB>  <TAB> ""$PARAMETER"" in configuration.kwargs[""value_set""] <TAB>  <TAB>  <TAB> ), 'Evaluation Parameter dict for value_set kwarg must have ""$PARAMETER"" key.' <TAB> except AssertionError as e: <TAB>  <TAB> raise InvalidExpectationConfigurationError(str(e)) <TAB> return True","if isinstance ( configuration . kwargs [ ""value_set"" ] , dict ) :",191
2126,"def check_refcounts(expected, timeout=10): <TAB> start = time.time() <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> _check_refcounts(expected) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> except AssertionError as e: <MASK> raise e <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> time.sleep(0.1)",if time . time ( ) - start > timeout :,96
2127,"def pickline(file, key, casefold=1): <TAB> try: <TAB>  <TAB> f = open(file, ""r"") <TAB> except IOError: <TAB>  <TAB> return None <TAB> pat = re.escape(key) + "":"" <TAB> prog = re.compile(pat, casefold and re.IGNORECASE) <TAB> while 1: <TAB>  <TAB> line = f.readline() <MASK> break <TAB>  <TAB> if prog.match(line): <TAB>  <TAB>  <TAB> text = line[len(key) + 1 :] <TAB>  <TAB>  <TAB> while 1: <TAB>  <TAB>  <TAB>  <TAB> line = f.readline() <TAB>  <TAB>  <TAB>  <TAB> if not line or not line[0].isspace(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB>  <TAB> text = text + line <TAB>  <TAB>  <TAB> return text.strip() <TAB> return None",if not line :,182
2128,def _is_perf_file(file_path): <TAB> f = get_file(file_path) <TAB> for line in f: <MASK> continue <TAB>  <TAB> r = event_regexp.search(line) <TAB>  <TAB> if r: <TAB>  <TAB>  <TAB> f.close() <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> f.close() <TAB>  <TAB> return False,"if line [ 0 ] == ""#"" :",92
2129,"def link_pantsrefs(soups, precomputed): <TAB> """"""Transorm soups: <a pantsref=""foo""> becomes <a href=""../foo_page.html#foo"">"""""" <TAB> for (page, soup) in soups.items(): <TAB>  <TAB> for a in soup.find_all(""a""): <MASK> continue <TAB>  <TAB>  <TAB> pantsref = a[""pantsref""] <TAB>  <TAB>  <TAB> if pantsref not in precomputed.pantsref: <TAB>  <TAB>  <TAB>  <TAB> raise TaskError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f'Page {page} has pantsref ""{pantsref}"" and I cannot find pantsmark for it' <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> a[""href""] = rel_href(page, precomputed.pantsref[pantsref])","if not a . has_attr ( ""pantsref"" ) :",194
2130,"def __init__(self, querylist=None): <TAB> self.query_id = -1 <TAB> if querylist is None: <TAB>  <TAB> self.querylist = [] <TAB> else: <TAB>  <TAB> self.querylist = querylist <TAB>  <TAB> for query in self.querylist: <MASK> self.query_id = query.query_id <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> if self.query_id != query.query_id: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""query in list must be same query_id"")",if self . query_id == - 1 :,137
2131,"def _draw_number( <TAB> screen, x_offset, y_offset, number, token=Token.Clock, transparent=False): <TAB> ""Write number at position."" <TAB> fg = Char("" "", token) <TAB> bg = Char("" "", Token) <TAB> for y, row in enumerate(_numbers[number]): <TAB>  <TAB> screen_row = screen.data_buffer[y + y_offset] <TAB>  <TAB> for x, n in enumerate(row): <MASK> screen_row[x + x_offset] = fg <TAB>  <TAB>  <TAB> elif not transparent: <TAB>  <TAB>  <TAB>  <TAB> screen_row[x + x_offset] = bg","if n == ""#"" :",154
2132,"def init(self): <TAB> self.sock.setblocking(True) <TAB> if self.parser is None: <TAB>  <TAB> # wrap the socket if needed <MASK> self.sock = ssl.wrap_socket( <TAB>  <TAB>  <TAB>  <TAB> self.sock, server_side=True, **self.cfg.ssl_options <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> # initialize the parser <TAB>  <TAB> self.parser = http.RequestParser(self.cfg, self.sock)",if self . cfg . is_ssl :,116
2133,"def intersect_face(pt): <TAB> # todo: rewrite! inefficient! <TAB> nonlocal vis_faces2D <TAB> for f, vs in vis_faces2D: <TAB>  <TAB> v0 = vs[0] <TAB>  <TAB> for v1, v2 in iter_pairs(vs[1:], False): <MASK> return f <TAB> return None","if intersect_point_tri_2d ( pt , v0 , v1 , v2 ) :",104
2134,"def IMPORTFROM(self, node): <TAB> if node.module == ""__future__"": <TAB>  <TAB> if not self.futuresAllowed: <TAB>  <TAB>  <TAB> self.report(messages.LateFutureImport, node, [n.name for n in node.names]) <TAB> else: <TAB>  <TAB> self.futuresAllowed = False <TAB> for alias in node.names: <MASK> self.scope.importStarred = True <TAB>  <TAB>  <TAB> self.report(messages.ImportStarUsed, node, node.module) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> name = alias.asname or alias.name <TAB>  <TAB> importation = Importation(name, node) <TAB>  <TAB> if node.module == ""__future__"": <TAB>  <TAB>  <TAB> importation.used = (self.scope, node) <TAB>  <TAB> self.addBinding(node, importation)","if alias . name == ""*"" :",190
2135,"def PyObject_Bytes(obj): <TAB> if type(obj) == bytes: <TAB>  <TAB> return obj <TAB> if hasattr(obj, ""__bytes__""): <TAB>  <TAB> res = obj.__bytes__() <MASK> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""__bytes__ returned non-bytes (type %s)"" % type(res).__name__ <TAB>  <TAB>  <TAB> ) <TAB> return PyBytes_FromObject(obj)","if not isinstance ( res , bytes ) :",99
2136,"def on_bt_search_clicked(self, widget): <TAB> if self.current_provider is None: <TAB>  <TAB> return <TAB> query = self.en_query.get_text() <TAB> @self.obtain_podcasts_with <TAB> def load_data(): <TAB>  <TAB> if self.current_provider.kind == directory.Provider.PROVIDER_SEARCH: <TAB>  <TAB>  <TAB> return self.current_provider.on_search(query) <TAB>  <TAB> elif self.current_provider.kind == directory.Provider.PROVIDER_URL: <TAB>  <TAB>  <TAB> return self.current_provider.on_url(query) <MASK> return self.current_provider.on_file(query)",elif self . current_provider . kind == directory . Provider . PROVIDER_FILE :,172
2137,"def remove(self, name): <TAB> for s in [self.__storage(self.__category), self.__storage(None)]: <TAB>  <TAB> for i, b in enumerate(s): <MASK> del s[i] <TAB>  <TAB>  <TAB>  <TAB> if b.persistent: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.__save() <TAB>  <TAB>  <TAB>  <TAB> return <TAB> raise KeyError(name)",if b . name == name :,94
2138,"def _wrapper(data, axis=None, keepdims=False): <TAB> if not keepdims: <TAB>  <TAB> return func(data, axis=axis) <TAB> else: <MASK> axis = axis if isinstance(axis, int) else axis[0] <TAB>  <TAB>  <TAB> out_shape = list(data.shape) <TAB>  <TAB>  <TAB> out_shape[axis] = 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> out_shape = [1 for _ in range(len(data.shape))] <TAB>  <TAB> return func(data, axis=axis).reshape(out_shape)",if axis is not None :,135
2139,"def authn_info(self): <TAB> res = [] <TAB> for astat in self.assertion.authn_statement: <TAB>  <TAB> context = astat.authn_context <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> authn_instant = astat.authn_instant <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB> authn_instant = """" <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> aclass = context.authn_context_class_ref.text <TAB>  <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB>  <TAB> aclass = """" <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> authn_auth = [a.text for a in context.authenticating_authority] <TAB>  <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB>  <TAB> authn_auth = [] <TAB>  <TAB>  <TAB> res.append((aclass, authn_auth, authn_instant)) <TAB> return res",if context :,199
2140,"def _persist_metadata(self, dirname, filename): <TAB> metadata_path = ""{0}/{1}.json"".format(dirname, filename) <TAB> if self.media_metadata or self.comments or self.include_location: <TAB>  <TAB> if self.posts: <MASK> self.merge_json({""GraphImages"": self.posts}, metadata_path) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.save_json({""GraphImages"": self.posts}, metadata_path) <TAB>  <TAB> if self.stories: <TAB>  <TAB>  <TAB> if self.latest: <TAB>  <TAB>  <TAB>  <TAB> self.merge_json({""GraphStories"": self.stories}, metadata_path) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.save_json({""GraphStories"": self.stories}, metadata_path)",if self . latest :,190
2141,"def update_record_image_detail(input_image_record, updated_image_detail, session=None): <TAB> if not session: <TAB>  <TAB> session = db.Session <TAB> image_record = {} <TAB> image_record.update(input_image_record) <TAB> image_record.pop(""created_at"", None) <TAB> image_record.pop(""last_updated"", None) <TAB> if image_record[""image_type""] == ""docker"": <TAB>  <TAB> for tag_record in updated_image_detail: <MASK> image_record[""image_detail""].append(tag_record) <TAB>  <TAB>  <TAB>  <TAB> return update_record(image_record, session=session) <TAB> return image_record","if tag_record not in image_record [ ""image_detail"" ] :",179
2142,"def backup(self): <TAB> for ds in [(""activedirectory"", ""AD""), (""ldap"", ""LDAP""), (""nis"", ""NIS"")]: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> ds_cache = self.middleware.call_sync(""cache.get"", f""{ds[1]}_cache"") <TAB>  <TAB>  <TAB>  <TAB> with open(f""/var/db/system/.{ds[1]}_cache_backup"", ""wb"") as f: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pickle.dump(ds_cache, f) <TAB>  <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB>  <TAB> self.logger.debug(""No cache exists for directory service [%s]."", ds[0])","if ( self . middleware . call_sync ( f""{ds[0]}.config"" ) ) [ ""enable"" ] :",175
2143,"def parse_setup_cfg(self): <TAB> # type: () -> Dict[STRING_TYPE, Any] <TAB> if self.setup_cfg is not None and self.setup_cfg.exists(): <TAB>  <TAB> contents = self.setup_cfg.read_text() <TAB>  <TAB> base_dir = self.setup_cfg.absolute().parent.as_posix() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> parsed = setuptools_parse_setup_cfg(self.setup_cfg.as_posix()) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> if six.PY2: <TAB>  <TAB>  <TAB>  <TAB> contents = self.setup_cfg.read_bytes() <TAB>  <TAB>  <TAB> parsed = parse_setup_cfg(contents, base_dir) <MASK> return {} <TAB>  <TAB> return parsed <TAB> return {}",if not parsed :,183
2144,"def parts(): <TAB> for l in lists.leaves: <TAB>  <TAB> head_name = l.get_head_name() <MASK> yield l.leaves <TAB>  <TAB> elif head_name != ""System`Missing"": <TAB>  <TAB>  <TAB> raise MessageException(""Catenate"", ""invrp"", l)","if head_name == ""System`List"" :",78
2145,"def _get_callback_and_order(self, hook): <TAB> if callable(hook): <TAB>  <TAB> return hook, None <TAB> elif isinstance(hook, tuple) and len(hook) == 2: <TAB>  <TAB> callback, order = hook <TAB>  <TAB> # test that callback is a callable <MASK> raise ValueError(""Hook callback is not a callable"") <TAB>  <TAB> # test that number is an int <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> int(order) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> raise ValueError(""Hook order is not a number"") <TAB>  <TAB> return callback, order <TAB> else: <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> ""Invalid hook definition, neither a callable nor a 2-tuple (callback, order): {!r}"".format( <TAB>  <TAB>  <TAB>  <TAB> hook <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> )",if not callable ( callback ) :,189
2146,"def _resize_masks(self, results): <TAB> """"""Resize masks with ``results['scale']``"""""" <TAB> for key in results.get(""mask_fields"", []): <TAB>  <TAB> if results[key] is None: <TAB>  <TAB>  <TAB> continue <MASK> results[key] = results[key].rescale(results[""scale""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> results[key] = results[key].resize(results[""img_shape""][:2])",if self . keep_ratio :,110
2147,"def getDataMax(self): <TAB> result = -Double.MAX_VALUE <TAB> nCurves = self.chart.getNCurves() <TAB> for i in range(nCurves): <TAB>  <TAB> c = self.getSystemCurve(i) <TAB>  <TAB> if not c.isVisible(): <TAB>  <TAB>  <TAB> continue <MASK> nPoints = c.getNPoints() <TAB>  <TAB>  <TAB> for j in range(nPoints): <TAB>  <TAB>  <TAB>  <TAB> result = self.maxIgnoreNaNAndMaxValue(result, c.getPoint(j).getY()) <TAB> if result == -Double.MAX_VALUE: <TAB>  <TAB> return Double.NaN <TAB> return result",if c . getYAxis ( ) == Y_AXIS :,163
2148,"def _check_token(self): <TAB> if settings.app.sso_client_cache and self.server_auth_token: <TAB>  <TAB> doc = self.sso_client_cache_collection.find_one( <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB> ""user_id"": self.user.id, <TAB>  <TAB>  <TAB>  <TAB> ""server_id"": self.server.id, <TAB>  <TAB>  <TAB>  <TAB> ""device_id"": self.device_id, <TAB>  <TAB>  <TAB>  <TAB> ""device_name"": self.device_name, <TAB>  <TAB>  <TAB>  <TAB> ""auth_token"": self.server_auth_token, <TAB>  <TAB>  <TAB> } <TAB>  <TAB> ) <MASK> self.has_token = True",if doc :,162
2149,"def parse_header(plyfile, ext): <TAB> # Variables <TAB> line = [] <TAB> properties = [] <TAB> num_points = None <TAB> while b""end_header"" not in line and line != b"""": <TAB>  <TAB> line = plyfile.readline() <MASK> line = line.split() <TAB>  <TAB>  <TAB> num_points = int(line[2]) <TAB>  <TAB> elif b""property"" in line: <TAB>  <TAB>  <TAB> line = line.split() <TAB>  <TAB>  <TAB> properties.append((line[2].decode(), ext + ply_dtypes[line[1]])) <TAB> return num_points, properties","if b""element"" in line :",149
2150,"def __codeanalysis_settings_changed(self, current_finfo): <TAB> if self.data: <TAB>  <TAB> run_pyflakes, run_pep8 = self.pyflakes_enabled, self.pep8_enabled <TAB>  <TAB> for finfo in self.data: <TAB>  <TAB>  <TAB> self.__update_editor_margins(finfo.editor) <TAB>  <TAB>  <TAB> finfo.cleanup_analysis_results() <MASK> if current_finfo is not finfo: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> finfo.run_code_analysis(run_pyflakes, run_pep8)",if ( run_pyflakes or run_pep8 ) and current_finfo is not None :,148
2151,"def __modules(self): <TAB> raw_output = self.__module_avail_output().decode(""utf-8"") <TAB> for line in StringIO(raw_output): <TAB>  <TAB> line = line and line.strip() <MASK> continue <TAB>  <TAB> line_modules = line.split() <TAB>  <TAB> for module in line_modules: <TAB>  <TAB>  <TAB> if module.endswith(self.default_indicator): <TAB>  <TAB>  <TAB>  <TAB> module = module[0 : -len(self.default_indicator)].strip() <TAB>  <TAB>  <TAB> module_parts = module.split(""/"") <TAB>  <TAB>  <TAB> module_version = None <TAB>  <TAB>  <TAB> if len(module_parts) == 2: <TAB>  <TAB>  <TAB>  <TAB> module_version = module_parts[1] <TAB>  <TAB>  <TAB> module_name = module_parts[0] <TAB>  <TAB>  <TAB> yield module_name, module_version","if not line or line . startswith ( ""-"" ) :",199
2152,"def _set_trailing_size(self, size): <TAB> if self.is_free(): <TAB>  <TAB> next_chunk = self.next_chunk() <MASK> self.state.memory.store(next_chunk.base, size, self.state.arch.bytes)",if next_chunk is not None :,74
2153,"def _execute_for_all_tables(self, app, bind, operation, skip_tables=False): <TAB> app = self.get_app(app) <TAB> if bind == ""__all__"": <TAB>  <TAB> binds = [None] + list(app.config.get(""SQLALCHEMY_BINDS"") or ()) <TAB> elif isinstance(bind, string_types) or bind is None: <TAB>  <TAB> binds = [bind] <TAB> else: <TAB>  <TAB> binds = bind <TAB> for bind in binds: <TAB>  <TAB> extra = {} <MASK> tables = self.get_tables_for_bind(bind) <TAB>  <TAB>  <TAB> extra[""tables""] = tables <TAB>  <TAB> op = getattr(self.Model.metadata, operation) <TAB>  <TAB> op(bind=self.get_engine(app, bind), **extra)",if not skip_tables :,191
2154,"def getFileName(): <TAB> extension = "".json"" <TAB> file = ""%s-stats"" % self.clusterName <TAB> counter = 0 <TAB> while True: <TAB>  <TAB> suffix = str(counter).zfill(3) + extension <TAB>  <TAB> fullName = os.path.join(self.statsPath, file + suffix) <MASK> return fullName <TAB>  <TAB> counter += 1",if not os . path . exists ( fullName ) :,98
2155,def logic(): <TAB> # direction <TAB> if goRight == ACTIVE: <TAB>  <TAB> dir.next = DirType.RIGHT <TAB>  <TAB> run.next = True <TAB> elif goLeft == ACTIVE: <TAB>  <TAB> dir.next = DirType.LEFT <TAB>  <TAB> run.next = True <TAB> # stop <TAB> if stop == ACTIVE: <TAB>  <TAB> run.next = False <TAB> # counter action <TAB> if run: <MASK> q.next[4:1] = q[3:] <TAB>  <TAB>  <TAB> q.next[0] = not q[3] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> q.next[3:] = q[4:1] <TAB>  <TAB>  <TAB> q.next[3] = not q[0],if dir == DirType . LEFT :,176
2156,"def test_broadcast(self): <TAB> """"""Test example broadcast functionality."""""" <TAB> self.create_lang_connection(""1000000000"", ""en"") <TAB> self.create_lang_connection(""1000000001"", ""en"") <TAB> self.create_lang_connection(""1000000002"", ""en"") <TAB> self.create_lang_connection(""1000000003"", ""es"") <TAB> self.create_lang_connection(""1000000004"", ""es"") <TAB> app.lang_broadcast() <TAB> self.assertEqual(2, len(self.outbound)) <TAB> for message in self.outbound: <TAB>  <TAB> if message.text == ""hello"": <TAB>  <TAB>  <TAB> self.assertEqual(3, len(message.connections)) <MASK> self.assertEqual(2, len(message.connections))","elif message . text == ""hola"" :",187
2157,"def get_ovf_env(dirname): <TAB> env_names = (""ovf-env.xml"", ""ovf_env.xml"", ""OVF_ENV.XML"", ""OVF-ENV.XML"") <TAB> for fname in env_names: <TAB>  <TAB> full_fn = os.path.join(dirname, fname) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> contents = util.load_file(full_fn) <TAB>  <TAB>  <TAB>  <TAB> return (fname, contents) <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> util.logexc(LOG, ""Failed loading ovf file %s"", full_fn) <TAB> return (None, False)",if os . path . isfile ( full_fn ) :,164
2158,"def _calc_offsets_children(self, offset, is_last): <TAB> if self.elems: <TAB>  <TAB> elem_last = self.elems[-1] <TAB>  <TAB> for elem in self.elems: <TAB>  <TAB>  <TAB> offset = elem._calc_offsets(offset, (elem is elem_last)) <TAB>  <TAB> offset += _BLOCK_SENTINEL_LENGTH <TAB> elif not self.props or self.id in _ELEMS_ID_ALWAYS_BLOCK_SENTINEL: <MASK> offset += _BLOCK_SENTINEL_LENGTH <TAB> return offset",if not is_last :,134
2159,"def publish_state(cls, payload, state): <TAB> try: <MASK> if state == action_constants.LIVEACTION_STATUS_REQUESTED: <TAB>  <TAB>  <TAB>  <TAB> cls.process(payload) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> worker.get_worker().process(payload) <TAB> except Exception: <TAB>  <TAB> traceback.print_exc() <TAB>  <TAB> print(payload)","if isinstance ( payload , LiveActionDB ) :",99
2160,"def log_predictive_density(self, x_test, y_test, Y_metadata=None): <TAB> if isinstance(x_test, list): <TAB>  <TAB> x_test, y_test, ind = util.multioutput.build_XY(x_test, y_test) <MASK> Y_metadata = {""output_index"": ind, ""trials"": np.ones(ind.shape)} <TAB> return super(MultioutputGP, self).log_predictive_density(x_test, y_test, Y_metadata)",if Y_metadata is None :,131
2161,"def minimalBases(classes): <TAB> """"""Reduce a list of base classes to its ordered minimum equivalent"""""" <TAB> if not __python3:  # pragma: no cover <TAB>  <TAB> classes = [c for c in classes if c is not ClassType] <TAB> candidates = [] <TAB> for m in classes: <TAB>  <TAB> for n in classes: <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # m has no subclasses in 'classes' <TAB>  <TAB>  <TAB> if m in candidates: <TAB>  <TAB>  <TAB>  <TAB> candidates.remove(m)  # ensure that we're later in the list <TAB>  <TAB>  <TAB> candidates.append(m) <TAB> return candidates","if issubclass ( n , m ) and m is not n :",160
2162,"def apply(self, operations, rotations=None, **kwargs): <TAB> rotations = rotations or [] <TAB> # apply the circuit operations <TAB> for i, operation in enumerate(operations): <MASK> raise DeviceError( <TAB>  <TAB>  <TAB>  <TAB> ""Operation {} cannot be used after other Operations have already been applied "" <TAB>  <TAB>  <TAB>  <TAB> ""on a {} device."".format(operation.name, self.short_name) <TAB>  <TAB>  <TAB> ) <TAB> for operation in operations: <TAB>  <TAB> self._apply_operation(operation) <TAB> # store the pre-rotated state <TAB> self._pre_rotated_state = self._state <TAB> # apply the circuit rotations <TAB> for operation in rotations: <TAB>  <TAB> self._apply_operation(operation)","if i > 0 and isinstance ( operation , ( QubitStateVector , BasisState ) ) :",186
2163,"def __str__(self): <TAB> txt = str(self._called) <TAB> if self.call_gas or self.call_value: <TAB>  <TAB> gas = f""gas: {self.call_gas}"" if self.call_gas else """" <TAB>  <TAB> value = f""value: {self.call_value}"" if self.call_value else """" <TAB>  <TAB> salt = f""salt: {self.call_salt}"" if self.call_salt else """" <MASK> options = [gas, value, salt] <TAB>  <TAB>  <TAB> txt += ""{"" + "","".join([o for o in options if o != """"]) + ""}"" <TAB> return txt + ""("" + "","".join([str(a) for a in self._arguments]) + "")""",if gas or value or salt :,183
2164,"def pop(self): <TAB> """"""Pop a nonterminal.  (Internal)"""""" <TAB> popdfa, popstate, popnode = self.stack.pop() <TAB> newnode = self.convert(self.grammar, popnode) <TAB> if newnode is not None: <MASK> dfa, state, node = self.stack[-1] <TAB>  <TAB>  <TAB> node.children.append(newnode) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.rootnode = newnode",if self . stack :,112
2165,"def pollpacket(self, wait): <TAB> self._stage0() <TAB> if len(self.buffer) < self.bufneed: <TAB>  <TAB> r, w, x = select.select([self.sock.fileno()], [], [], wait) <MASK> return None <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> s = self.sock.recv(BUFSIZE) <TAB>  <TAB> except socket.error: <TAB>  <TAB>  <TAB> raise EOFError <TAB>  <TAB> if len(s) == 0: <TAB>  <TAB>  <TAB> raise EOFError <TAB>  <TAB> self.buffer += s <TAB>  <TAB> self._stage0() <TAB> return self._stage1()",if len ( r ) == 0 :,148
2166,"def increaseToolReach(self): <TAB> if self.draggingFace is not None: <TAB>  <TAB> d = (1, -1)[self.draggingFace & 1] <MASK> # xxxxx y <TAB>  <TAB>  <TAB> d = -d <TAB>  <TAB> self.draggingY += d <TAB>  <TAB> x, y, z = self.editor.mainViewport.cameraPosition <TAB>  <TAB> pos = [x, y, z] <TAB>  <TAB> pos[self.draggingFace >> 1] += d <TAB>  <TAB> self.editor.mainViewport.cameraPosition = tuple(pos) <TAB> else: <TAB>  <TAB> self.cloneCameraDistance = self.editor._incrementReach(self.cloneCameraDistance) <TAB> return True",if self . draggingFace >> 1 != 1 :,172
2167,"def selectionToChunks(self, remove=False, add=False): <TAB> box = self.selectionBox() <TAB> if box: <TAB>  <TAB> if box == self.level.bounds: <TAB>  <TAB>  <TAB> self.selectedChunks = set(self.level.allChunks) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> selectedChunks = self.selectedChunks <TAB>  <TAB> boxedChunks = set(box.chunkPositions) <TAB>  <TAB> if boxedChunks.issubset(selectedChunks): <TAB>  <TAB>  <TAB> remove = True <MASK> selectedChunks.difference_update(boxedChunks) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> selectedChunks.update(boxedChunks) <TAB> self.selectionTool.selectNone()",if remove and not add :,158
2168,"def __init__(self, *args, **kwargs): <TAB> super(ProjectForm, self).__init__(*args, **kwargs) <TAB> if self.instance.id: <MASK> self.fields[""localfiletype""].widget.attrs[""disabled""] = True <TAB>  <TAB>  <TAB> self.fields[""localfiletype""].required = False <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB> self.instance.treestyle != ""auto"" <TAB>  <TAB>  <TAB> and self.instance.translationproject_set.count() <TAB>  <TAB>  <TAB> and self.instance.treestyle == self.instance._detect_treestyle() <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> self.fields[""treestyle""].widget.attrs[""disabled""] = True <TAB>  <TAB>  <TAB> self.fields[""treestyle""].required = False",if Store . objects . filter ( translation_project__project = self . instance ) . count ( ) :,193
2169,"def _infer_return_type(*args): <TAB> """"""Look at the type of all args and divine their implied return type."""""" <TAB> return_type = None <TAB> for arg in args: <TAB>  <TAB> if arg is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if isinstance(arg, bytes): <MASK> raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."") <TAB>  <TAB>  <TAB> return_type = bytes <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if return_type is bytes: <TAB>  <TAB>  <TAB>  <TAB> raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."") <TAB>  <TAB>  <TAB> return_type = str <TAB> if return_type is None: <TAB>  <TAB> return str  # tempfile APIs return a str by default. <TAB> return return_type",if return_type is str :,186
2170,"def deleteDuplicates(gadgets, callback=None): <TAB> toReturn = [] <TAB> inst = set() <TAB> count = 0 <TAB> added = False <TAB> len_gadgets = len(gadgets) <TAB> for i, gadget in enumerate(gadgets): <TAB>  <TAB> inst.add(gadget._gadget) <TAB>  <TAB> if len(inst) > count: <TAB>  <TAB>  <TAB> count = len(inst) <TAB>  <TAB>  <TAB> toReturn.append(gadget) <TAB>  <TAB>  <TAB> added = True <MASK> callback(gadget, added, float(i + 1) / (len_gadgets)) <TAB>  <TAB>  <TAB> added = False <TAB> return toReturn",if callback :,164
2171,"def send_all(self, data: bytes): <TAB> with self._conflict_detector: <MASK> raise _core.ClosedResourceError(""this pipe is already closed"") <TAB>  <TAB> if not data: <TAB>  <TAB>  <TAB> await _core.checkpoint() <TAB>  <TAB>  <TAB> return <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> written = await _core.write_overlapped(self._handle_holder.handle, data) <TAB>  <TAB> except BrokenPipeError as ex: <TAB>  <TAB>  <TAB> raise _core.BrokenResourceError from ex <TAB>  <TAB> # By my reading of MSDN, this assert is guaranteed to pass so long <TAB>  <TAB> # as the pipe isn't in nonblocking mode, but... let's just <TAB>  <TAB> # double-check. <TAB>  <TAB> assert written == len(data)",if self . _handle_holder . closed :,181
2172,"def setup_parameter_node(self, param_node): <TAB> if param_node.bl_idname == ""SvNumberNode"": <MASK> value = self.sv_get()[0][0] <TAB>  <TAB>  <TAB> print(""V"", value) <TAB>  <TAB>  <TAB> if isinstance(value, int): <TAB>  <TAB>  <TAB>  <TAB> param_node.selected_mode = ""int"" <TAB>  <TAB>  <TAB>  <TAB> param_node.int_ = value <TAB>  <TAB>  <TAB> elif isinstance(value, float): <TAB>  <TAB>  <TAB>  <TAB> param_node.selected_mode = ""float"" <TAB>  <TAB>  <TAB>  <TAB> param_node.float_ = value",if self . use_prop or self . get_prop_name ( ) :,156
2173,"def collect_active_inst_idx_list(inst_beams, word_prob, inst_idx_to_position_map): <TAB> active_inst_idx_list = [] <TAB> for inst_idx, inst_position in inst_idx_to_position_map.items(): <TAB>  <TAB> is_inst_complete = inst_beams[inst_idx].advance(word_prob[inst_position]) <MASK> active_inst_idx_list += [inst_idx] <TAB> return active_inst_idx_list",if not is_inst_complete :,129
2174,"def compare_member_req_resp_without_key(self, request, response): <TAB> for user_response in resp_json(response)[""data""]: <TAB>  <TAB> for user_request in request: <MASK> assert user_request[""role""] == user_response[""role""]","if user_request [ ""user_id"" ] == user_response [ ""user_id"" ] :",86
2175,"def __init__(self, dir): <TAB> self.module_names = set() <TAB> for name in os.listdir(dir): <TAB>  <TAB> if name.endswith("".py""): <TAB>  <TAB>  <TAB> self.module_names.add(name[:-3]) <MASK> self.module_names.add(name)","elif ""."" not in name :",79
2176,"def _read_filter(self, data): <TAB> if data: <TAB>  <TAB> if self.expected_inner_sha256: <TAB>  <TAB>  <TAB> self.inner_sha.update(data) <MASK> self.inner_md5.update(data) <TAB> return data",if self . expected_inner_md5sum :,76
2177,"def _p_basicstr_content(s, content=_basicstr_re): <TAB> res = [] <TAB> while True: <TAB>  <TAB> res.append(s.expect_re(content).group(0)) <MASK> break <TAB>  <TAB> if s.consume_re(_newline_esc_re): <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> elif s.consume_re(_short_uni_re) or s.consume_re(_long_uni_re): <TAB>  <TAB>  <TAB> res.append(_chr(int(s.last().group(1), 16))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> s.expect_re(_escapes_re) <TAB>  <TAB>  <TAB> res.append(_escapes[s.last().group(0)]) <TAB> return """".join(res)","if not s . consume ( ""\\"" ) :",179
2178,"def process_response(self, request, response): <TAB> if ( <TAB>  <TAB> response.status_code == 404 <TAB>  <TAB> and request.path_info.endswith(""/"") <TAB>  <TAB> and not is_valid_path(request.path_info) <TAB>  <TAB> and is_valid_path(request.path_info[:-1]) <TAB> ): <TAB>  <TAB> # Use request.path because we munged app/locale in path_info. <TAB>  <TAB> newurl = request.path[:-1] <MASK> with safe_query_string(request): <TAB>  <TAB>  <TAB>  <TAB> newurl += ""?"" + request.META.get(""QUERY_STRING"", """") <TAB>  <TAB> return HttpResponsePermanentRedirect(newurl) <TAB> else: <TAB>  <TAB> return response",if request . GET :,171
2179,"def convertDict(obj): <TAB> obj = dict(obj) <TAB> for k, v in obj.items(): <TAB>  <TAB> del obj[k] <MASK> k = dumps(k) <TAB>  <TAB>  <TAB> # Keep track of which keys need to be decoded when loading. <TAB>  <TAB>  <TAB> if Types.KEYS not in obj: <TAB>  <TAB>  <TAB>  <TAB> obj[Types.KEYS] = [] <TAB>  <TAB>  <TAB> obj[Types.KEYS].append(k) <TAB>  <TAB> obj[k] = convertObjects(v) <TAB> return obj","if not ( isinstance ( k , str ) or isinstance ( k , unicode ) ) :",137
2180,"def __repr__(self): <TAB> if self._in_repr: <TAB>  <TAB> return ""<recursion>"" <TAB> try: <TAB>  <TAB> self._in_repr = True <MASK> status = ""computed, "" <TAB>  <TAB>  <TAB> if self.error() is None: <TAB>  <TAB>  <TAB>  <TAB> if self.value() is self: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> status += ""= self"" <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> status += ""= "" + repr(self.value()) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> status += ""error = "" + repr(self.error()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> status = ""isn't computed"" <TAB>  <TAB> return ""%s (%s)"" % (type(self), status) <TAB> finally: <TAB>  <TAB> self._in_repr = False",if self . is_computed ( ) :,189
2181,"def allocate_network(ipv=""ipv4""): <TAB> global dtcd_uuid <TAB> global network_pool <TAB> global allocations <TAB> network = None <TAB> try: <TAB>  <TAB> cx = httplib.HTTPConnection(""localhost:7623"") <TAB>  <TAB> cx.request(""POST"", ""/v1/network/%s/"" % ipv, body=dtcd_uuid) <TAB>  <TAB> resp = cx.getresponse() <MASK> network = netaddr.IPNetwork(resp.read().decode(""utf-8"")) <TAB>  <TAB> cx.close() <TAB> except Exception: <TAB>  <TAB> pass <TAB> if network is None: <TAB>  <TAB> network = network_pool[ipv].pop() <TAB>  <TAB> allocations[network] = True <TAB> return network",if resp . status == 200 :,170
2182,"def change_args_to_dict(string): <TAB> if string is None: <TAB>  <TAB> return None <TAB> ans = [] <TAB> strings = string.split(""\n"") <TAB> ind = 1 <TAB> start = 0 <TAB> while ind <= len(strings): <TAB>  <TAB> if ind < len(strings) and strings[ind].startswith("" ""): <TAB>  <TAB>  <TAB> ind += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if start < ind: <TAB>  <TAB>  <TAB>  <TAB> ans.append(""\n"".join(strings[start:ind])) <TAB>  <TAB>  <TAB> start = ind <TAB>  <TAB>  <TAB> ind += 1 <TAB> d = {} <TAB> for line in ans: <MASK> lines = line.split("":"") <TAB>  <TAB>  <TAB> d[lines[0]] = lines[1].strip() <TAB> return d","if "":"" in line and len ( line ) > 0 :",188
2183,"def kill_members(members, sig, hosts=nodes): <TAB> for member in sorted(members): <TAB>  <TAB> try: <MASK> print(""killing %s"" % member) <TAB>  <TAB>  <TAB> proc = hosts[member][""proc""] <TAB>  <TAB>  <TAB> # Not sure if cygwin makes sense here... <TAB>  <TAB>  <TAB> if sys.platform in (""win32"", ""cygwin""): <TAB>  <TAB>  <TAB>  <TAB> os.kill(proc.pid, signal.CTRL_C_EVENT) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> os.kill(proc.pid, sig) <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> if ha_tools_debug: <TAB>  <TAB>  <TAB>  <TAB> print(""%s already dead?"" % member)",if ha_tools_debug :,172
2184,"def check(self): <TAB> for path in self.paths: <TAB>  <TAB> response = self.http_request( <TAB>  <TAB>  <TAB> method=""GET"", <TAB>  <TAB>  <TAB> path=path, <TAB>  <TAB> ) <MASK> continue <TAB>  <TAB> if any( <TAB>  <TAB>  <TAB> map( <TAB>  <TAB>  <TAB>  <TAB> lambda x: x in response.text, <TAB>  <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""report.db.server.name"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""report.db.server.sa.pass"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""report.db.server.user.pass"", <TAB>  <TAB>  <TAB>  <TAB> ], <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> self.valid = path <TAB>  <TAB>  <TAB> return True  # target is vulnerable <TAB> return False  # target not vulnerable",if response is None :,184
2185,"def get_to_download_runs_ids(session, headers): <TAB> last_date = 0 <TAB> result = [] <TAB> while 1: <TAB>  <TAB> r = session.get(RUN_DATA_API.format(last_date=last_date), headers=headers) <TAB>  <TAB> if r.ok: <TAB>  <TAB>  <TAB> run_logs = r.json()[""data""][""records""] <TAB>  <TAB>  <TAB> result.extend([i[""logs""][0][""stats""][""id""] for i in run_logs]) <TAB>  <TAB>  <TAB> last_date = r.json()[""data""][""lastTimestamp""] <TAB>  <TAB>  <TAB> since_time = datetime.utcfromtimestamp(last_date / 1000) <TAB>  <TAB>  <TAB> print(f""pares keep ids data since {since_time}"") <TAB>  <TAB>  <TAB> time.sleep(1)  # spider rule <MASK> break <TAB> return result",if not last_date :,199
2186,"def button_press_cb(self, tdw, event): <TAB> self._update_zone_and_cursors(tdw, event.x, event.y) <TAB> if self._zone in (_EditZone.CREATE_FRAME, _EditZone.REMOVE_FRAME): <TAB>  <TAB> button = event.button <MASK> self._click_info = (button, self._zone) <TAB>  <TAB>  <TAB> return False <TAB> return super(FrameEditMode, self).button_press_cb(tdw, event)",if button == 1 and event . type == Gdk . EventType . BUTTON_PRESS :,135
2187,"def first_timestep(): <TAB> assignment = self.has_previous.assign( <TAB>  <TAB> value=tf_util.constant(value=True, dtype=""bool""), read_value=False <TAB> ) <TAB> with tf.control_dependencies(control_inputs=(assignment,)): <MASK> current = x <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> current = tf.expand_dims(input=x, axis=(self.axis + 1)) <TAB>  <TAB> multiples = tuple( <TAB>  <TAB>  <TAB> self.length if dims == self.axis + 1 else 1 <TAB>  <TAB>  <TAB> for dims in range(self.output_spec().rank + 1) <TAB>  <TAB> ) <TAB>  <TAB> return tf.tile(input=current, multiples=multiples)",if self . concatenate :,167
2188,"def main() -> None: <TAB> onefuzz = Onefuzz() <TAB> jobs = onefuzz.jobs.list() <TAB> for job in jobs: <TAB>  <TAB> print( <TAB>  <TAB>  <TAB> ""job:"", <TAB>  <TAB>  <TAB> str(job.job_id)[:8], <TAB>  <TAB>  <TAB> "":"".join([job.config.project, job.config.name, job.config.build]), <TAB>  <TAB> ) <TAB>  <TAB> for task in onefuzz.tasks.list(job_id=job.job_id): <MASK> continue <TAB>  <TAB>  <TAB> print( <TAB>  <TAB>  <TAB>  <TAB> "" <TAB> "", <TAB>  <TAB>  <TAB>  <TAB> str(task.task_id)[:8], <TAB>  <TAB>  <TAB>  <TAB> task.config.task.type, <TAB>  <TAB>  <TAB>  <TAB> task.config.task.target_exe, <TAB>  <TAB>  <TAB> )","if task . state in [ ""stopped"" , ""stopping"" ] :",200
2189,"def update_stack(self, full_name, template_url, parameters, tags): <TAB> """"""Updates an existing stack in CloudFormation."""""" <TAB> try: <TAB>  <TAB> logger.info(""Attempting to update stack %s."", full_name) <TAB>  <TAB> self.conn.cloudformation.update_stack( <TAB>  <TAB>  <TAB> full_name, <TAB>  <TAB>  <TAB> template_url=template_url, <TAB>  <TAB>  <TAB> parameters=parameters, <TAB>  <TAB>  <TAB> tags=tags, <TAB>  <TAB>  <TAB> capabilities=[""CAPABILITY_IAM""], <TAB>  <TAB> ) <TAB>  <TAB> return SUBMITTED <TAB> except BotoServerError as e: <MASK> logger.info(""Stack %s did not change, not updating."", full_name) <TAB>  <TAB>  <TAB> return SKIPPED <TAB>  <TAB> raise","if ""No updates are to be performed."" in e . message :",183
2190,"def header_tag_files(env, files, legal_header, script_files=False): <TAB> """"""Apply the legal_header to the list of files"""""" <TAB> try: <TAB>  <TAB> import apply_legal_header <TAB> except: <TAB>  <TAB> xbc.cdie(""XED ERROR: mfile.py could not find scripts directory"") <TAB> for g in files: <TAB>  <TAB> print(""G: "", g) <TAB>  <TAB> for f in mbuild.glob(g): <TAB>  <TAB>  <TAB> print(""F: "", f) <MASK> apply_legal_header.apply_header_to_data_file(legal_header, f) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> apply_legal_header.apply_header_to_source_file(legal_header, f)",if script_files :,186
2191,"def cleanDataCmd(cmd): <TAB> newcmd = ""AbracadabrA ** <?php "" <TAB> if cmd[:6] != ""php://"": <TAB>  <TAB> if reverseConn not in cmd: <TAB>  <TAB>  <TAB> cmds = cmd.split(""&"") <TAB>  <TAB>  <TAB> for c in cmds: <MASK> newcmd += ""system('%s');"" % c <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> b64cmd = base64.b64encode(cmd) <TAB>  <TAB>  <TAB> newcmd += ""system(base64_decode('%s'));"" % b64cmd <TAB> else: <TAB>  <TAB> newcmd += cmd[6:] <TAB> newcmd += ""?> **"" <TAB> return newcmd",if len ( c ) > 0 :,170
2192,"def test_form(self): <TAB> n_qubits = 6 <TAB> random_operator = get_fermion_operator(random_interaction_operator(n_qubits)) <TAB> chemist_operator = chemist_ordered(random_operator) <TAB> for term, _ in chemist_operator.terms.items(): <MASK> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertTrue(term[0][1]) <TAB>  <TAB>  <TAB> self.assertTrue(term[2][1]) <TAB>  <TAB>  <TAB> self.assertFalse(term[1][1]) <TAB>  <TAB>  <TAB> self.assertFalse(term[3][1]) <TAB>  <TAB>  <TAB> self.assertTrue(term[0][0] > term[2][0]) <TAB>  <TAB>  <TAB> self.assertTrue(term[1][0] > term[3][0])",if len ( term ) == 2 or not len ( term ) :,199
2193,"def do(server, handler, config, modargs): <TAB> data = [] <TAB> clients = server.get_clients(handler.default_filter) <TAB> if not clients: <TAB>  <TAB> return <TAB> for client in clients: <TAB>  <TAB> tags = config.tags(client.node()) <MASK> tags.remove(*modargs.remove) <TAB>  <TAB> if modargs.add: <TAB>  <TAB>  <TAB> tags.add(*modargs.add) <TAB>  <TAB> data.append({""ID"": client.node(), ""TAGS"": tags}) <TAB> config.save(project=modargs.write_project, user=modargs.write_user) <TAB> handler.display(Table(data))",if modargs . remove :,160
2194,"def validate(self): <TAB> if self.data.get(""state"") == ""enabled"": <MASK> raise PolicyValidationError( <TAB>  <TAB>  <TAB>  <TAB> ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""redshift logging enablement requires `bucket` "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""and `prefix` specification on %s"" % (self.manager.data,) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> return self","if ""bucket"" not in self . data :",104
2195,"def renumber(self, x1, y1, x2, y2, dx, dy): <TAB> out = [] <TAB> for part in re.split(""(\w+)"", self.formula): <TAB>  <TAB> m = re.match(""^([A-Z]+)([1-9][0-9]*)$"", part) <MASK> sx, sy = m.groups() <TAB>  <TAB>  <TAB> x = colname2num(sx) <TAB>  <TAB>  <TAB> y = int(sy) <TAB>  <TAB>  <TAB> if x1 <= x <= x2 and y1 <= y <= y2: <TAB>  <TAB>  <TAB>  <TAB> part = cellname(x + dx, y + dy) <TAB>  <TAB> out.append(part) <TAB> return FormulaCell("""".join(out), self.fmt, self.alignment)",if m is not None :,179
2196,"def update_sysconfig_file(fn, adjustments, allow_empty=False): <TAB> if not adjustments: <TAB>  <TAB> return <TAB> (exists, contents) = read_sysconfig_file(fn) <TAB> updated_am = 0 <TAB> for (k, v) in adjustments.items(): <TAB>  <TAB> if v is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> v = str(v) <TAB>  <TAB> if len(v) == 0 and not allow_empty: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> contents[k] = v <TAB>  <TAB> updated_am += 1 <TAB> if updated_am: <TAB>  <TAB> lines = [ <TAB>  <TAB>  <TAB> str(contents), <TAB>  <TAB> ] <MASK> lines.insert(0, util.make_header()) <TAB>  <TAB> util.write_file(fn, ""\n"".join(lines) + ""\n"", 0o644)",if not exists :,198
2197,"def getElement(self, aboutUri, namespace, name): <TAB> for desc in self.rdfRoot.getElementsByTagNameNS(RDF_NAMESPACE, ""Description""): <TAB>  <TAB> if desc.getAttributeNS(RDF_NAMESPACE, ""about"") == aboutUri: <TAB>  <TAB>  <TAB> attr = desc.getAttributeNodeNS(namespace, name) <MASK> yield attr <TAB>  <TAB>  <TAB> for element in desc.getElementsByTagNameNS(namespace, name): <TAB>  <TAB>  <TAB>  <TAB> yield element",if attr != None :,113
2198,"def get_store_name_from_connection_string(connection_string): <TAB> if is_valid_connection_string(connection_string): <TAB>  <TAB> segments = dict(seg.split(""="", 1) for seg in connection_string.split("";"")) <TAB>  <TAB> endpoint = segments.get(""Endpoint"") <MASK> return endpoint.split(""//"")[1].split(""."")[0] <TAB> return None",if endpoint :,93
2199,"def insertLoopTemplate(self, layout): <TAB> col = layout.column(align=True) <TAB> for socket in self.activeNode.outputs: <MASK> props = col.operator( <TAB>  <TAB>  <TAB>  <TAB> ""an.insert_loop_for_iterator"", <TAB>  <TAB>  <TAB>  <TAB> text=""Loop through {}"".format(repr(socket.getDisplayedName())), <TAB>  <TAB>  <TAB>  <TAB> icon=""MOD_ARRAY"", <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> props.nodeIdentifier = self.activeNode.identifier <TAB>  <TAB>  <TAB> props.socketIndex = socket.getIndex()",if not socket . hide and isList ( socket . bl_idname ) :,145
2200,"def do_task(self, task): <TAB> self.running_task += 1 <TAB> result = yield gen.Task(self.fetcher.fetch, task) <TAB> type, task, response = result.args <TAB> self.processor.on_task(task, response) <TAB> # do with message <TAB> while not self.processor.inqueue.empty(): <TAB>  <TAB> _task, _response = self.processor.inqueue.get() <TAB>  <TAB> self.processor.on_task(_task, _response) <TAB> # do with results <TAB> while not self.processor.result_queue.empty(): <TAB>  <TAB> _task, _result = self.processor.result_queue.get() <MASK> self.result_worker.on_result(_task, _result) <TAB> self.running_task -= 1",if self . result_worker :,191
2201,"def _parse_config_result(data): <TAB> command_list = "" ; "".join([x.strip() for x in data[0]]) <TAB> config_result = data[1] <TAB> if isinstance(config_result, list): <TAB>  <TAB> result = """" <MASK> for key in config_result[0]: <TAB>  <TAB>  <TAB>  <TAB> result += config_result[0][key] <TAB>  <TAB>  <TAB> config_result = result <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> config_result = config_result[0] <TAB> return [command_list, config_result]","if isinstance ( config_result [ 0 ] , dict ) :",142
2202,"def load_api_handler(self, mod_name): <TAB> for name, hdl in API_HANDLERS: <TAB>  <TAB> name = name.lower() <MASK> handler = self.mods.get(name) <TAB>  <TAB>  <TAB> if not handler: <TAB>  <TAB>  <TAB>  <TAB> handler = hdl(self.emu) <TAB>  <TAB>  <TAB>  <TAB> self.mods.update({name: handler}) <TAB>  <TAB>  <TAB> return handler <TAB> return None",if mod_name and name == mod_name . lower ( ) :,113
2203,def heal(self): <TAB> if not self.doctors: <TAB>  <TAB> return <TAB> proc_ids = self._get_process_ids() <TAB> for proc_id in proc_ids: <TAB>  <TAB> # get proc every time for latest state <TAB>  <TAB> proc = PipelineProcess.objects.get(id=proc_id) <TAB>  <TAB> if not proc.is_alive or proc.is_frozen: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for dr in self.doctors: <MASK> dr.cure(proc) <TAB>  <TAB>  <TAB>  <TAB> break,if dr . confirm ( proc ) :,138
2204,"def __new__(cls, *args, **kwargs): <TAB> if len(args) == 1: <TAB>  <TAB> if len(kwargs): <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""You can either use {} with one positional argument or with keyword arguments, not both."".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> cls.__name__ <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <MASK> return super().__new__(cls) <TAB>  <TAB> if isinstance(args[0], cls): <TAB>  <TAB>  <TAB> return cls <TAB> return super().__new__(cls, *args, **kwargs)",if not args [ 0 ] :,137
2205,"def __lt__(self, other): <TAB> # 0: clock 1: timestamp 3: process id <TAB> try: <TAB>  <TAB> A, B = self[0], other[0] <TAB>  <TAB> # uses logical clock value first <MASK> # use logical clock if available <TAB>  <TAB>  <TAB> if A == B:  # equal clocks use lower process id <TAB>  <TAB>  <TAB>  <TAB> return self[2] < other[2] <TAB>  <TAB>  <TAB> return A < B <TAB>  <TAB> return self[1] < other[1]  # ... or use timestamp <TAB> except IndexError: <TAB>  <TAB> return NotImplemented",if A and B :,135
2206,"def _get_client(rp_mapping, resource_provider): <TAB> for key, value in rp_mapping.items(): <TAB>  <TAB> if str.lower(key) == str.lower(resource_provider): <MASK> return GeneralPrivateEndpointClient( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> key, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value[""api_version""], <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value[""support_list_or_not""], <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value[""resource_get_api_version""], <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return value() <TAB> raise CLIError( <TAB>  <TAB> ""Resource type must be one of {}"".format("", "".join(rp_mapping.keys())) <TAB> )","if isinstance ( value , dict ) :",165
2207,"def test_progressbar_format_pos(runner, pos, length): <TAB> with _create_progress(length, length_known=length != 0, pos=pos) as progress: <TAB>  <TAB> result = progress.format_pos() <MASK> assert result == f""{pos}/{length}"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert result == str(pos)",if progress . length_known :,91
2208,"def optimize(self, graph: Graph): <TAB> MAX_TEXTURE_SIZE = config.WEBGL_MAX_TEXTURE_SIZE <TAB> flag_changed = False <TAB> for v in traverse.listup_variables(graph): <TAB>  <TAB> if not Placeholder.check_resolved(v.size): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> height, width = TextureShape.get(v) <TAB>  <TAB> if height <= MAX_TEXTURE_SIZE and width <= MAX_TEXTURE_SIZE: <TAB>  <TAB>  <TAB> continue <MASK> flag_changed = True <TAB>  <TAB>  <TAB> v.attributes.add(SplitTarget()) <TAB> return graph, flag_changed",if not v . has_attribute ( SplitTarget ) :,157
2209,"def ant_map(m): <TAB> tmp = ""rows %s\ncols %s\n"" % (len(m), len(m[0])) <TAB> players = {} <TAB> for row in m: <TAB>  <TAB> tmp += ""m "" <TAB>  <TAB> for col in row: <MASK> tmp += ""."" <TAB>  <TAB>  <TAB> elif col == BARRIER: <TAB>  <TAB>  <TAB>  <TAB> tmp += ""%"" <TAB>  <TAB>  <TAB> elif col == FOOD: <TAB>  <TAB>  <TAB>  <TAB> tmp += ""*"" <TAB>  <TAB>  <TAB> elif col == UNSEEN: <TAB>  <TAB>  <TAB>  <TAB> tmp += ""?"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> players[col] = True <TAB>  <TAB>  <TAB>  <TAB> tmp += chr(col + 97) <TAB>  <TAB> tmp += ""\n"" <TAB> tmp = (""players %s\n"" % len(players)) + tmp <TAB> return tmp",if col == LAND :,199
2210,"def reset(self): <TAB> logger.debug(""Arctic.reset()"") <TAB> with self._lock: <TAB>  <TAB> if self.__conn is not None: <TAB>  <TAB>  <TAB> self.__conn.close() <TAB>  <TAB>  <TAB> self.__conn = None <TAB>  <TAB> for _, l in self._library_cache.items(): <MASK> logger.debug(""Library reset() %s"" % l) <TAB>  <TAB>  <TAB>  <TAB> l._reset()  # the existence of _reset() is not guaranteed/enforced, it also triggers re-auth","if hasattr ( l , ""_reset"" ) and callable ( l . _reset ) :",137
2211,"def add_cand_to_check(cands): <TAB> for cand in cands: <TAB>  <TAB> x = cand.creator <MASK> continue <TAB>  <TAB> if x not in fan_out: <TAB>  <TAB>  <TAB> # `len(fan_out)` is in order to avoid comparing `x` <TAB>  <TAB>  <TAB> heapq.heappush(cand_funcs, (-x.rank, len(fan_out), x)) <TAB>  <TAB> fan_out[x] += 1",if x is None :,111
2212,"def on_task_modify(self, task, config): <TAB> for entry in task.entries: <MASK> size = entry[""torrent""].size / 1024 / 1024 <TAB>  <TAB>  <TAB> log.debug(""%s size: %s MB"" % (entry[""title""], size)) <TAB>  <TAB>  <TAB> entry[""content_size""] = size","if ""torrent"" in entry :",83
2213,"def get_measurements(self, pipeline, object_name, category): <TAB> if self.get_categories(pipeline, object_name) == [category]: <TAB>  <TAB> results = [] <TAB>  <TAB> if self.do_corr_and_slope: <TAB>  <TAB>  <TAB> if object_name == ""Image"": <TAB>  <TAB>  <TAB>  <TAB> results += [""Correlation"", ""Slope""] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> results += [""Correlation""] <TAB>  <TAB> if self.do_overlap: <TAB>  <TAB>  <TAB> results += [""Overlap"", ""K""] <TAB>  <TAB> if self.do_manders: <TAB>  <TAB>  <TAB> results += [""Manders""] <TAB>  <TAB> if self.do_rwc: <TAB>  <TAB>  <TAB> results += [""RWC""] <MASK> results += [""Costes""] <TAB>  <TAB> return results <TAB> return []",if self . do_costes :,195
2214,"def create_root(cls, site=None, title=""Root"", request=None, **kwargs): <TAB> if not site: <TAB>  <TAB> site = Site.objects.get_current() <TAB> root_nodes = cls.objects.root_nodes().filter(site=site) <TAB> if not root_nodes: <TAB>  <TAB> article = Article() <TAB>  <TAB> revision = ArticleRevision(title=title, **kwargs) <MASK> revision.set_from_request(request) <TAB>  <TAB> article.add_revision(revision, save=True) <TAB>  <TAB> article.save() <TAB>  <TAB> root = cls.objects.create(site=site, article=article) <TAB>  <TAB> article.add_object_relation(root) <TAB> else: <TAB>  <TAB> root = root_nodes[0] <TAB> return root",if request :,185
2215,"def get(self, key): <TAB> filename = self._get_filename(key) <TAB> try: <TAB>  <TAB> with open(filename, ""rb"") as f: <TAB>  <TAB>  <TAB> pickle_time = pickle.load(f) <MASK> return pickle.load(f) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> os.remove(filename) <TAB>  <TAB>  <TAB>  <TAB> return None <TAB> except (IOError, OSError, pickle.PickleError): <TAB>  <TAB> return None",if pickle_time == 0 or pickle_time >= time ( ) :,122
2216,"def build_message(self, options, target): <TAB> message = multipart.MIMEMultipart() <TAB> for name, value in list(options.items()): <MASK> self.add_body(message, value) <TAB>  <TAB> elif name == ""EMAIL_ATTACHMENT"": <TAB>  <TAB>  <TAB> self.add_attachment(message, value) <TAB>  <TAB> else:  # From, To, Subject, etc. <TAB>  <TAB>  <TAB> self.set_option(message, name, value, target) <TAB> return message","if name == ""EMAIL_BODY"" :",126
2217,"def updateVar(name, data, mode=None): <TAB> if mode: <MASK> core.config.globalVariables[name].append(data) <TAB>  <TAB> elif mode == ""add"": <TAB>  <TAB>  <TAB> core.config.globalVariables[name].add(data) <TAB> else: <TAB>  <TAB> core.config.globalVariables[name] = data","if mode == ""append"" :",91
2218,"def insert_errors( <TAB> el, <TAB> errors, <TAB> form_id=None, <TAB> form_index=None, <TAB> error_class=""error"", <TAB> error_creator=default_error_creator,): <TAB> el = _find_form(el, form_id=form_id, form_index=form_index) <TAB> for name, error in errors.items(): <MASK> continue <TAB>  <TAB> for error_el, message in _find_elements_for_name(el, name, error): <TAB>  <TAB>  <TAB> assert isinstance(message, (basestring, type(None), ElementBase)), ( <TAB>  <TAB>  <TAB>  <TAB> ""Bad message: %r"" % message <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> _insert_error(error_el, message, error_class, error_creator)",if error is None :,190
2219,"def read(self, item, recursive=False, sort=False): <TAB> item = _normalize_path(item) <TAB> if item in self._store: <MASK> del self._store[item] <TAB>  <TAB>  <TAB> raise KeyError(item) <TAB>  <TAB> return PathResult(item, value=self._store[item]) <TAB> else: <TAB>  <TAB> return self._read_dir(item, recursive=recursive, sort=sort)",if item in self . _expire_time and self . _expire_time [ item ] < datetime . now ( ) :,121
2220,"def _stash_splitter(states): <TAB> keep, split = [], [] <TAB> if state_func is not None: <TAB>  <TAB> for s in states: <TAB>  <TAB>  <TAB> ns = state_func(s) <TAB>  <TAB>  <TAB> if isinstance(ns, SimState): <TAB>  <TAB>  <TAB>  <TAB> split.append(ns) <MASK> split.extend(ns) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> split.append(s) <TAB> if stash_func is not None: <TAB>  <TAB> split = stash_func(states) <TAB> if to_stash is not stash: <TAB>  <TAB> keep = states <TAB> return keep, split","elif isinstance ( ns , ( list , tuple , set ) ) :",163
2221,"def run(self): <TAB> while self.runflag: <MASK> with self.lock: <TAB>  <TAB>  <TAB>  <TAB> tasks = list(self.queue) <TAB>  <TAB>  <TAB>  <TAB> self.queue.clear() <TAB>  <TAB>  <TAB> while len(tasks) > 0: <TAB>  <TAB>  <TAB>  <TAB> pathname, remotepath = tasks.pop(0) <TAB>  <TAB>  <TAB>  <TAB> self.bcloud_app.upload_page.add_bg_task(pathname, remotepath) <TAB>  <TAB>  <TAB> self.last = time() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sleep(1)",if time ( ) - self . last > 5 and self . qsize ( ) > 0 :,142
2222,"def _append_patch(self, patch_dir, patch_files): <TAB> for patch in patch_files: <MASK> tmp = patch <TAB>  <TAB>  <TAB> patch = {} <TAB>  <TAB>  <TAB> for key in tmp.keys(): <TAB>  <TAB>  <TAB>  <TAB> patch[os.path.join(patch_dir, key)] = tmp[key] <TAB>  <TAB>  <TAB> self.patches.append(patch) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.patches.append(os.path.join(patch_dir, patch))",if type ( patch ) is dict :,125
2223,"def __remote_port(self): <TAB> port = 22 <TAB> if self.git_has_remote: <TAB>  <TAB> m = re.match(r""^(.*?)?@([^/:]*):?([0-9]+)?"", self.git_remote.url) <TAB>  <TAB> if m: <MASK> port = m.group(3) <TAB> return int(port)",if m . group ( 3 ) :,94
2224,"def _create_or_get_helper(self, infer_mode: Optional[bool] = None, **kwargs) -> Helper: <TAB> # Prefer creating a new helper when at least one kwarg is specified. <TAB> prefer_new = len(kwargs) > 0 <TAB> kwargs.update(infer_mode=infer_mode) <TAB> is_training = not infer_mode if infer_mode is not None else self.training <TAB> helper = self._train_helper if is_training else self._infer_helper <TAB> if prefer_new or helper is None: <TAB>  <TAB> helper = self.create_helper(**kwargs) <MASK> self._train_helper = helper <TAB>  <TAB> elif not is_training and self._infer_helper is None: <TAB>  <TAB>  <TAB> self._infer_helper = helper <TAB> return helper",if is_training and self . _train_helper is None :,195
2225,"def flushChangeClassifications(self, schedulerid, less_than=None): <TAB> if less_than is not None: <TAB>  <TAB> classifications = self.classifications.setdefault(schedulerid, {}) <TAB>  <TAB> for changeid in list(classifications): <MASK> del classifications[changeid] <TAB> else: <TAB>  <TAB> self.classifications[schedulerid] = {} <TAB> return defer.succeed(None)",if changeid < less_than :,107
2226,"def pid_from_name(name): <TAB> processes = [] <TAB> for pid in os.listdir(""/proc""): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> pid = int(pid) <TAB>  <TAB>  <TAB> pname, cmdline = SunProcess._name_args(pid) <TAB>  <TAB>  <TAB> if name in pname: <TAB>  <TAB>  <TAB>  <TAB> return pid <MASK> return pid <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> pass <TAB> raise ProcessException(""No process with such name: %s"" % name)","if name in cmdline . split ( "" "" , 1 ) [ 0 ] :",126
2227,"def spew(): <TAB> seenUID = False <TAB> start() <TAB> for part in query: <MASK> seenUID = True <TAB>  <TAB> if part.type == ""body"": <TAB>  <TAB>  <TAB> yield self.spew_body(part, id, msg, write, flush) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> f = getattr(self, ""spew_"" + part.type) <TAB>  <TAB>  <TAB> yield f(id, msg, write, flush) <TAB>  <TAB> if part is not query[-1]: <TAB>  <TAB>  <TAB> space() <TAB> if uid and not seenUID: <TAB>  <TAB> space() <TAB>  <TAB> yield self.spew_uid(id, msg, write, flush) <TAB> finish() <TAB> flush()","if part . type == ""uid"" :",174
2228,"def rx(): <TAB> while True: <TAB>  <TAB> rx_i = rep.recv() <MASK> rep.send(b""done"") <TAB>  <TAB>  <TAB> break <TAB>  <TAB> rep.send(b""i"")","if rx_i == b""1000"" :",60
2229,"def test_search_incorrect_base_exception_1(self): <TAB> self.connection_1c.bind() <TAB> try: <TAB>  <TAB> result = self.connection_1c.search( <TAB>  <TAB>  <TAB> ""o=nonexistant"", ""(cn=*)"", search_scope=SUBTREE, attributes=[""cn"", ""sn""] <TAB>  <TAB> ) <MASK> _, result = self.connection_1c.get_response(result) <TAB>  <TAB> self.fail(""exception not raised"") <TAB> except LDAPNoSuchObjectResult: <TAB>  <TAB> pass",if not self . connection_1c . strategy . sync :,138
2230,"def value_from_datadict(self, data, files, prefix): <TAB> count = int(data[""%s-count"" % prefix]) <TAB> values_with_indexes = [] <TAB> for i in range(0, count): <MASK> continue <TAB>  <TAB> values_with_indexes.append( <TAB>  <TAB>  <TAB> ( <TAB>  <TAB>  <TAB>  <TAB> int(data[""%s-%d-order"" % (prefix, i)]), <TAB>  <TAB>  <TAB>  <TAB> self.child_block.value_from_datadict( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> data, files, ""%s-%d-value"" % (prefix, i) <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB> values_with_indexes.sort() <TAB> return [v for (i, v) in values_with_indexes]","if data [ ""%s-%d-deleted"" % ( prefix , i ) ] :",194
2231,"def _ensure_header_written(self, datasize): <TAB> if not self._headerwritten: <TAB>  <TAB> if not self._nchannels: <TAB>  <TAB>  <TAB> raise Error(""# channels not specified"") <TAB>  <TAB> if not self._sampwidth: <TAB>  <TAB>  <TAB> raise Error(""sample width not specified"") <MASK> raise Error(""sampling rate not specified"") <TAB>  <TAB> self._write_header(datasize)",if not self . _framerate :,99
2232,def wait_til_ready(cls): <TAB> while True: <TAB>  <TAB> now = time.time() <TAB>  <TAB> next_iteration = now // 1.0 + 1 <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> await cls._clock.run_til(next_iteration) <TAB>  <TAB> await asyncio.sleep(1.0),if cls . connector . ready :,89
2233,"def lookup_actions(self, resp): <TAB> actions = {} <TAB> for action, conditions in self.actions.items(): <TAB>  <TAB> for condition, opts in conditions: <TAB>  <TAB>  <TAB> for key, val in condition: <MASK> if resp.match(key[:-1], val): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if not resp.match(key, val): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> actions[action] = opts <TAB> return actions","if key [ - 1 ] == ""!"" :",138
2234,"def close(self, wait=True, abort=False): <TAB> """"""Close the socket connection."""""" <TAB> if not self.closed and not self.closing: <TAB>  <TAB> self.closing = True <TAB>  <TAB> self.server._trigger_event(""disconnect"", self.sid, run_async=False) <TAB>  <TAB> if not abort: <TAB>  <TAB>  <TAB> self.send(packet.Packet(packet.CLOSE)) <TAB>  <TAB> self.closed = True <TAB>  <TAB> self.queue.put(None) <MASK> self.queue.join()",if wait :,125
2235,"def model_parse(self): <TAB> for name, submodel in self.model.named_modules(): <TAB>  <TAB> for op_type in SUPPORTED_OP_TYPE: <MASK> self.target_layer[name] = submodel <TAB>  <TAB>  <TAB>  <TAB> self.already_pruned[name] = 0","if isinstance ( submodel , op_type ) :",83
2236,"def pack_identifier(self): <TAB> """"""Return a combined identifier for the whole pack if this has more than one episode."""""" <TAB> # Currently only supports ep mode <TAB> if self.id_type == ""ep"": <MASK> return ""S%02dE%02d-E%02d"" % ( <TAB>  <TAB>  <TAB>  <TAB> self.season, <TAB>  <TAB>  <TAB>  <TAB> self.episode, <TAB>  <TAB>  <TAB>  <TAB> self.episode + self.episodes - 1, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.identifier <TAB> else: <TAB>  <TAB> return self.identifier",if self . episodes > 1 :,143
2237,"def on_data(res): <TAB> if terminate.is_set(): <TAB>  <TAB> return <TAB> if args.strings and not args.no_content: <TAB>  <TAB> if type(res) == tuple: <TAB>  <TAB>  <TAB> f, v = res <TAB>  <TAB>  <TAB> if type(f) == unicode: <TAB>  <TAB>  <TAB>  <TAB> f = f.encode(""utf-8"") <MASK> v = v.encode(""utf-8"") <TAB>  <TAB>  <TAB> self.success(""{}: {}"".format(f, v)) <TAB>  <TAB> elif not args.content_only: <TAB>  <TAB>  <TAB> self.success(res) <TAB> else: <TAB>  <TAB> self.success(res)",if type ( v ) == unicode :,158
2238,"def _enable_contours_changed(self, value): <TAB> """"""Turns on and off the contours."""""" <TAB> if self.module_manager is None: <TAB>  <TAB> return <TAB> if value: <TAB>  <TAB> self.actor.inputs = [self.contour] <MASK> self.actor.mapper.scalar_mode = ""use_cell_data"" <TAB> else: <TAB>  <TAB> self.actor.inputs = [self.grid_plane] <TAB>  <TAB> self.actor.mapper.scalar_mode = ""default"" <TAB> self.render()",if self . contour . filled_contours :,139
2239,"def _apply_abs_paths(data, script_dir): <TAB> for flag_data in data.values(): <MASK> continue <TAB>  <TAB> default = flag_data.get(""default"") <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB> not default <TAB>  <TAB>  <TAB> or not isinstance(default, six.string_types) <TAB>  <TAB>  <TAB> or os.path.sep not in default <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> abs_path = os.path.join(script_dir, default) <TAB>  <TAB> if os.path.exists(abs_path): <TAB>  <TAB>  <TAB> flag_data[""default""] = abs_path","if not isinstance ( flag_data , dict ) :",153
2240,"def button_release(self, mapper): <TAB> self.pressed = False <TAB> if self.waiting_task and self.active is None and not self.action: <TAB>  <TAB> # In HoldModifier, button released before timeout <TAB>  <TAB> mapper.cancel_task(self.waiting_task) <TAB>  <TAB> self.waiting_task = None <MASK> self.normalaction.button_press(mapper) <TAB>  <TAB>  <TAB> mapper.schedule(0.02, self.normalaction.button_release) <TAB> elif self.active: <TAB>  <TAB> # Released held button <TAB>  <TAB> self.active.button_release(mapper) <TAB>  <TAB> self.active = None",if self . normalaction :,160
2241,"def goToPrevMarkedHeadline(self, event=None): <TAB> """"""Select the next marked node."""""" <TAB> c = self <TAB> p = c.p <TAB> if not p: <TAB>  <TAB> return <TAB> p.moveToThreadBack() <TAB> wrapped = False <TAB> while 1: <TAB>  <TAB> if p and p.isMarked(): <TAB>  <TAB>  <TAB> break <MASK> p.moveToThreadBack() <TAB>  <TAB> elif wrapped: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> wrapped = True <TAB>  <TAB>  <TAB> p = c.rootPosition() <TAB> if not p: <TAB>  <TAB> g.blue(""done"") <TAB> c.treeSelectHelper(p)  # Sets focus.",elif p :,164
2242,"def status(self, name, error=""No matching script logs found""): <TAB> with self.script_lock: <TAB>  <TAB> if self.script_running and self.script_running[1] == name: <TAB>  <TAB>  <TAB> return self.script_running[1:] <MASK> return self.script_last[1:] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(error)",elif self . script_last and self . script_last [ 1 ] == name :,107
2243,"def _stderr_supports_color(): <TAB> try: <TAB>  <TAB> if hasattr(sys.stderr, ""isatty"") and sys.stderr.isatty(): <MASK> curses.setupterm() <TAB>  <TAB>  <TAB>  <TAB> if curses.tigetnum(""colors"") > 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB> elif colorama: <TAB>  <TAB>  <TAB>  <TAB> if sys.stderr is getattr( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> colorama.initialise, ""wrapped_stderr"", object() <TAB>  <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> except Exception: <TAB>  <TAB> # Very broad exception handling because it's always better to <TAB>  <TAB> # fall back to non-colored logs than to break at startup. <TAB>  <TAB> pass <TAB> return False",if curses :,170
2244,"def main(): <TAB> configFilename = ""twitterbot.ini"" <TAB> if sys.argv[1:]: <TAB>  <TAB> configFilename = sys.argv[1] <TAB> try: <MASK> raise Exception() <TAB>  <TAB> load_config(configFilename) <TAB> except Exception as e: <TAB>  <TAB> print(""Error while loading ini file %s"" % (configFilename), file=sys.stderr) <TAB>  <TAB> print(e, file=sys.stderr) <TAB>  <TAB> print(__doc__, file=sys.stderr) <TAB>  <TAB> sys.exit(1) <TAB> bot = TwitterBot(configFilename) <TAB> return bot.run()",if not os . path . exists ( configFilename ) :,156
2245,def safe_to_kill(request): <TAB> if os.path.exists(DRAIN_FILE): <TAB>  <TAB> with open(DRAIN_FILE) as f: <TAB>  <TAB>  <TAB> dt = datetime.datetime.fromtimestamp(float(f.read())) <TAB>  <TAB>  <TAB> delta = datetime.datetime.now() - dt <MASK> return Response(status_int=200) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return Response(status_int=400) <TAB> else: <TAB>  <TAB> return Response(status_int=400),if delta . seconds > 2 :,131
2246,"def get_class_name(item): <TAB> class_name, module_name = None, None <TAB> for parent in reversed(item.listchain()): <MASK> class_name = parent.name <TAB>  <TAB> elif isinstance(parent, pytest.Module): <TAB>  <TAB>  <TAB> module_name = parent.module.__name__ <TAB>  <TAB>  <TAB> break <TAB> # heuristic: <TAB> # - better to group gpu and task tests, since tests from those modules <TAB> #   are likely to share caching more <TAB> # - split up the rest by class name because slow tests tend to be in <TAB> #   the same module <TAB> if class_name and "".tasks."" not in module_name: <TAB>  <TAB> return ""{}.{}"".format(module_name, class_name) <TAB> else: <TAB>  <TAB> return module_name","if isinstance ( parent , pytest . Class ) :",190
2247,"def getAllFitsLite(): <TAB> fits = eos.db.getFitListLite() <TAB> shipMap = {f.shipID: None for f in fits} <TAB> for shipID in shipMap: <TAB>  <TAB> ship = eos.db.getItem(shipID) <MASK> shipMap[shipID] = (ship.name, ship.getShortName()) <TAB> fitsToPurge = set() <TAB> for fit in fits: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> fit.shipName, fit.shipNameShort = shipMap[fit.shipID] <TAB>  <TAB> except (KeyError, TypeError): <TAB>  <TAB>  <TAB> fitsToPurge.add(fit) <TAB> for fit in fitsToPurge: <TAB>  <TAB> fits.remove(fit) <TAB> return fits",if ship is not None :,185
2248,"def _process(self, event_data): <TAB> self.machine.callbacks(self.machine.prepare_event, event_data) <TAB> _LOGGER.debug( <TAB>  <TAB> ""%sExecuted machine preparation callbacks before conditions."", self.machine.name <TAB> ) <TAB> try: <TAB>  <TAB> for trans in self.transitions[event_data.state.name]: <TAB>  <TAB>  <TAB> event_data.transition = trans <MASK> event_data.result = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB> except Exception as err: <TAB>  <TAB> event_data.error = err <TAB>  <TAB> raise <TAB> finally: <TAB>  <TAB> self.machine.callbacks(self.machine.finalize_event, event_data) <TAB>  <TAB> _LOGGER.debug(""%sExecuted machine finalize callbacks"", self.machine.name) <TAB> return event_data.result",if trans . execute ( event_data ) :,200
2249,"def fetch_comments(self, force=False, limit=None): <TAB> comments = [] <TAB> if (force is True) or (self.badges[""comments""] > 0): <TAB>  <TAB> query_params = {""filter"": ""commentCard,copyCommentCard""} <MASK> query_params[""limit""] = limit <TAB>  <TAB> comments = self.client.fetch_json( <TAB>  <TAB>  <TAB> ""/cards/"" + self.id + ""/actions"", query_params=query_params <TAB>  <TAB> ) <TAB>  <TAB> return sorted(comments, key=lambda comment: comment[""date""]) <TAB> return comments",if limit is not None :,140
2250,"def get_changed(self): <TAB> if self._is_expression(): <TAB>  <TAB> result = self._get_node_text(self.ast) <TAB>  <TAB> if result == self.source: <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> return result <TAB> else: <TAB>  <TAB> collector = codeanalyze.ChangeCollector(self.source) <TAB>  <TAB> last_end = -1 <TAB>  <TAB> for match in self.matches: <TAB>  <TAB>  <TAB> start, end = match.get_region() <TAB>  <TAB>  <TAB> if start < last_end: <MASK> continue <TAB>  <TAB>  <TAB> last_end = end <TAB>  <TAB>  <TAB> replacement = self._get_matched_text(match) <TAB>  <TAB>  <TAB> collector.add_change(start, end, replacement) <TAB>  <TAB> return collector.get_changed()",if not self . _is_expression ( ) :,189
2251,"def _replace_home(x): <TAB> if xp.ON_WINDOWS: <TAB>  <TAB> home = ( <TAB>  <TAB>  <TAB> builtins.__xonsh__.env[""HOMEDRIVE""] + builtins.__xonsh__.env[""HOMEPATH""][0] <TAB>  <TAB> ) <MASK> x = x.replace(home, ""~"", 1) <TAB>  <TAB> if builtins.__xonsh__.env.get(""FORCE_POSIX_PATHS""): <TAB>  <TAB>  <TAB> x = x.replace(os.sep, os.altsep) <TAB>  <TAB> return x <TAB> else: <TAB>  <TAB> home = builtins.__xonsh__.env[""HOME""] <TAB>  <TAB> if x.startswith(home): <TAB>  <TAB>  <TAB> x = x.replace(home, ""~"", 1) <TAB>  <TAB> return x",if x . startswith ( home ) :,176
2252,"def project_review(plans): <TAB> for plan in plans: <TAB>  <TAB> print(""Inspecting {} plan"".format(plan)) <TAB>  <TAB> branches = get_branches_from_plan(plan) <TAB>  <TAB> for branch in branches: <TAB>  <TAB>  <TAB> build_results = get_results_from_branch(branch) <TAB>  <TAB>  <TAB> for build in build_results: <TAB>  <TAB>  <TAB>  <TAB> build_key = build.get(""buildResultKey"") or None <TAB>  <TAB>  <TAB>  <TAB> print(""Inspecting build - {}"".format(build_key)) <MASK> for status in STATUS_CLEANED_RESULTS: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> remove_build_result(build_key=build_key, status=status)",if build_key :,169
2253,"def _check_for_batch_clashes(xs): <TAB> """"""Check that batch names do not overlap with sample names."""""" <TAB> names = set([x[""description""] for x in xs]) <TAB> dups = set([]) <TAB> for x in xs: <TAB>  <TAB> batches = tz.get_in((""metadata"", ""batch""), x) <TAB>  <TAB> if batches: <MASK> batches = [batches] <TAB>  <TAB>  <TAB> for batch in batches: <TAB>  <TAB>  <TAB>  <TAB> if batch in names: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> dups.add(batch) <TAB> if len(dups) > 0: <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> ""Batch names must be unique from sample descriptions.\n"" <TAB>  <TAB>  <TAB> ""Clashing batch names: %s"" % sorted(list(dups)) <TAB>  <TAB> )","if not isinstance ( batches , ( list , tuple ) ) :",192
2254,"def _check_signal(self): <TAB> """"""Checks if a signal was received and issues a message."""""" <TAB> proc_signal = getattr(self.proc, ""signal"", None) <TAB> if proc_signal is None: <TAB>  <TAB> return <TAB> sig, core = proc_signal <TAB> sig_str = SIGNAL_MESSAGES.get(sig) <TAB> if sig_str: <TAB>  <TAB> if core: <TAB>  <TAB>  <TAB> sig_str += "" (core dumped)"" <TAB>  <TAB> print(sig_str, file=sys.stderr) <MASK> self.errors += sig_str + ""\n""",if self . errors is not None :,146
2255,"def loadLabelFile(self, labelpath): <TAB> labeldict = {} <TAB> if not os.path.exists(labelpath): <TAB>  <TAB> f = open(labelpath, ""w"", encoding=""utf-8"") <TAB> else: <TAB>  <TAB> with open(labelpath, ""r"", encoding=""utf-8"") as f: <TAB>  <TAB>  <TAB> data = f.readlines() <TAB>  <TAB>  <TAB> for each in data: <TAB>  <TAB>  <TAB>  <TAB> file, label = each.split(""\t"") <MASK> label = label.replace(""false"", ""False"") <TAB>  <TAB>  <TAB>  <TAB>  <TAB> label = label.replace(""true"", ""True"") <TAB>  <TAB>  <TAB>  <TAB>  <TAB> labeldict[file] = eval(label) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> labeldict[file] = [] <TAB> return labeldict",if label :,191
2256,"def exists_col_to_many(self, select_columns: List[str]) -> bool: <TAB> for column in select_columns: <MASK> root_relation = get_column_root_relation(column) <TAB>  <TAB>  <TAB> if self.is_relation_many_to_many( <TAB>  <TAB>  <TAB>  <TAB> root_relation <TAB>  <TAB>  <TAB> ) or self.is_relation_one_to_many(root_relation): <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if is_column_dotted ( column ) :,120
2257,"def check_sequence_matches(seq, template): <TAB> i = 0 <TAB> for pattern in template: <MASK> pattern = {pattern} <TAB>  <TAB> got = set(seq[i : i + len(pattern)]) <TAB>  <TAB> assert got == pattern <TAB>  <TAB> i += len(got)","if not isinstance ( pattern , set ) :",77
2258,"def load_modules( <TAB> to_load, load, attr, modules_dict, excluded_aliases, loading_message=None): <TAB> if loading_message: <TAB>  <TAB> print(loading_message) <TAB> for name in to_load: <TAB>  <TAB> module = load(name) <TAB>  <TAB> if module is None or not hasattr(module, attr): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> cls = getattr(module, attr) <TAB>  <TAB> if hasattr(cls, ""initialize"") and not cls.initialize(): <TAB>  <TAB>  <TAB> continue <MASK> for alias in module.aliases(): <TAB>  <TAB>  <TAB>  <TAB> if alias not in excluded_aliases: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> modules_dict[alias] = module <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> modules_dict[name] = module <TAB> if loading_message: <TAB>  <TAB> print()","if hasattr ( module , ""aliases"" ) :",195
2259,"def result(): <TAB> # ""global"" does not work here... <TAB> R, V = rays, virtual_rays <TAB> if V is not None: <MASK> V = normalize_rays(V, lattice) <TAB>  <TAB> if check: <TAB>  <TAB>  <TAB> R = PointCollection(V, lattice) <TAB>  <TAB>  <TAB> V = PointCollection(V, lattice) <TAB>  <TAB>  <TAB> d = lattice.dimension() <TAB>  <TAB>  <TAB> if len(V) != d - R.dim() or (R + V).dim() != d: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""virtual rays must be linearly "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""independent and with other rays span the ambient space."" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return RationalPolyhedralFan(cones, R, lattice, is_complete, V)",if normalize :,194
2260,"def communicate(self, _input=None, _timeout=None) -> Tuple[bytes, bytes]: <TAB> if parse_args().print_commands: <MASK> print_stderr( <TAB>  <TAB>  <TAB>  <TAB> color_line(""=> "", 14) + "" "".join(str(arg) for arg in self.args) <TAB>  <TAB>  <TAB> ) <TAB> stdout, stderr = super().communicate(_input, _timeout) <TAB> self.stdout_text = stdout.decode(""utf-8"") if stdout else None <TAB> self.stderr_text = stderr.decode(""utf-8"") if stderr else None <TAB> return stdout, stderr",if self . args != get_sudo_refresh_command ( ) :,154
2261,"def convert(data): <TAB> result = [] <TAB> for d in data: <TAB>  <TAB> # noinspection PyCompatibility <MASK> result.append((d[0], None, d[1])) <TAB>  <TAB> elif isinstance(d, basestring): <TAB>  <TAB>  <TAB> result.append(d) <TAB> return result","if isinstance ( d , tuple ) and len ( d ) == 2 :",86
2262,"def validate(self, value): <TAB> try: <TAB>  <TAB> value = [ <TAB>  <TAB>  <TAB> datetime.datetime.strptime(range, ""%Y-%m-%d %H:%M:%S"") <TAB>  <TAB>  <TAB> for range in value.split("" to "") <TAB>  <TAB> ] <MASK> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> except ValueError: <TAB>  <TAB> return False",if ( len ( value ) == 2 ) and ( value [ 0 ] <= value [ 1 ] ) :,110
2263,"def rmdir(dirname): <TAB> if dirname[-1] == os.sep: <TAB>  <TAB> dirname = dirname[:-1] <TAB> if os.path.islink(dirname): <TAB>  <TAB> return  # do not clear link - we can get out of dir <TAB> for f in os.listdir(dirname): <TAB>  <TAB> if f in (""."", ""..""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> path = dirname + os.sep + f <MASK> rmdir(path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> os.unlink(path) <TAB> os.rmdir(dirname)",if os . path . isdir ( path ) :,137
2264,"def onCompletion(self, text): <TAB> res = [] <TAB> for l in text.split(""\n""): <TAB>  <TAB> if not l: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> l = l.split("":"") <MASK> continue <TAB>  <TAB> res.append([l[0].strip(), l[1].strip()]) <TAB> self.panel.setSlides(res)",if len ( l ) != 2 :,93
2265,"def pytest_collection_modifyitems(items): <TAB> for item in items: <MASK> if ""stage"" not in item.keywords: <TAB>  <TAB>  <TAB>  <TAB> item.add_marker(pytest.mark.stage(""unit"")) <TAB>  <TAB>  <TAB> if ""init"" not in item.keywords: <TAB>  <TAB>  <TAB>  <TAB> item.add_marker(pytest.mark.init(rng_seed=123))","if item . nodeid . startswith ( ""tests/infer"" ) :",102
2266,"def build_message(self, options, target): <TAB> message = multipart.MIMEMultipart() <TAB> for name, value in list(options.items()): <TAB>  <TAB> if name == ""EMAIL_BODY"": <TAB>  <TAB>  <TAB> self.add_body(message, value) <MASK> self.add_attachment(message, value) <TAB>  <TAB> else:  # From, To, Subject, etc. <TAB>  <TAB>  <TAB> self.set_option(message, name, value, target) <TAB> return message","elif name == ""EMAIL_ATTACHMENT"" :",126
2267,def extend_with_zeroes(b): <TAB> try: <TAB>  <TAB> for x in b: <TAB>  <TAB>  <TAB> x = to_constant(x) <MASK> yield (x) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield (0) <TAB>  <TAB> for _ in range(32): <TAB>  <TAB>  <TAB> yield (0) <TAB> except Exception as e: <TAB>  <TAB> return,"if isinstance ( x , int ) :",99
2268,"def _start_cluster(*, cleanup_atexit=True): <TAB> global _default_cluster <TAB> if _default_cluster is None: <TAB>  <TAB> cluster_addr = os.environ.get(""EDGEDB_TEST_CLUSTER_ADDR"") <MASK> conn_spec = json.loads(cluster_addr) <TAB>  <TAB>  <TAB> _default_cluster = edgedb_cluster.RunningCluster(**conn_spec) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> data_dir = os.environ.get(""EDGEDB_TEST_DATA_DIR"") <TAB>  <TAB>  <TAB> _default_cluster = _init_cluster( <TAB>  <TAB>  <TAB>  <TAB> data_dir=data_dir, cleanup_atexit=cleanup_atexit <TAB>  <TAB>  <TAB> ) <TAB> return _default_cluster",if cluster_addr :,175
2269,"def preprocess_raw_enwik9(input_filename, output_filename): <TAB> with open(input_filename, ""r"") as f1: <TAB>  <TAB> with open(output_filename, ""w"") as f2: <TAB>  <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB>  <TAB> line = f1.readline() <MASK> break <TAB>  <TAB>  <TAB>  <TAB> line = list(enwik9_norm_transform([line]))[0] <TAB>  <TAB>  <TAB>  <TAB> if line != "" "" and line != """": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if line[0] == "" "": <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> line = line[1:] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f2.writelines(line + ""\n"")",if not line :,164
2270,"def is_entirely_italic(line): <TAB> style = subs.styles.get(line.style, SSAStyle.DEFAULT_STYLE) <TAB> for fragment, sty in parse_tags(line.text, style, subs.styles): <TAB>  <TAB> fragment = fragment.replace(r""\h"", "" "") <TAB>  <TAB> fragment = fragment.replace(r""\n"", ""\n"") <TAB>  <TAB> fragment = fragment.replace(r""\N"", ""\n"") <MASK> return False <TAB> return True",if not sty . italic and fragment and not fragment . isspace ( ) :,128
2271,def __get_all_nodes(self): <TAB> nodes = [] <TAB> next_level = [self.__tree.get_root()] <TAB> while len(next_level) != 0: <TAB>  <TAB> cur_level = next_level <TAB>  <TAB> nodes += next_level <TAB>  <TAB> next_level = [] <TAB>  <TAB> for cur_node in cur_level: <TAB>  <TAB>  <TAB> children = cur_node.get_children() <MASK> next_level += children <TAB> return nodes,if children is not None :,119
2272,"def _openvpn_stdout(self): <TAB> while True: <TAB>  <TAB> line = self.process.stdout.readline() <TAB>  <TAB> if not line: <MASK> return <TAB>  <TAB>  <TAB> time.sleep(0.05) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> yield <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.server.output.push_output(line) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> logger.exception( <TAB>  <TAB>  <TAB>  <TAB> ""Failed to push vpn output"", <TAB>  <TAB>  <TAB>  <TAB> ""server"", <TAB>  <TAB>  <TAB>  <TAB> server_id=self.server.id, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> yield",if self . process . poll ( ) is not None or self . is_interrupted ( ) :,163
2273,"def payment_received_handler(event): <TAB> if isinstance(event.message.action, types.MessageActionPaymentSentMe): <TAB>  <TAB> payment: types.MessageActionPaymentSentMe = event.message.action <TAB>  <TAB> # do something after payment was received <TAB>  <TAB> if payment.payload.decode(""UTF-8"") == ""product A"": <TAB>  <TAB>  <TAB> await bot.send_message( <TAB>  <TAB>  <TAB>  <TAB> event.message.from_id, ""Thank you for buying product A!"" <TAB>  <TAB>  <TAB> ) <MASK> await bot.send_message( <TAB>  <TAB>  <TAB>  <TAB> event.message.from_id, ""Thank you for buying product B!"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> raise events.StopPropagation","elif payment . payload . decode ( ""UTF-8"" ) == ""product B"" :",181
2274,"def spaces_after(token, prev, next, min=-1, max=-1, min_desc=None, max_desc=None): <TAB> if next is not None and token.end_mark.line == next.start_mark.line: <TAB>  <TAB> spaces = next.start_mark.pointer - token.end_mark.pointer <MASK> return LintProblem( <TAB>  <TAB>  <TAB>  <TAB> token.start_mark.line + 1, next.start_mark.column, max_desc <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> elif min != -1 and spaces < min: <TAB>  <TAB>  <TAB> return LintProblem( <TAB>  <TAB>  <TAB>  <TAB> token.start_mark.line + 1, next.start_mark.column + 1, min_desc <TAB>  <TAB>  <TAB> )",if max != - 1 and spaces > max :,184
2275,"def seek_to_block(self, pos): <TAB> baseofs = 0 <TAB> ofs = 0 <TAB> for b in self.blocks: <MASK> self.current_block = b <TAB>  <TAB>  <TAB> break <TAB>  <TAB> baseofs += b.compressed_size <TAB>  <TAB> ofs += b.uncompressed_size <TAB> else: <TAB>  <TAB> self.current_block = None <TAB>  <TAB> self.current_stream = BytesIO(b"""") <TAB>  <TAB> return <TAB> self.current_block_start = ofs <TAB> self.stream.seek(self.basepos + baseofs) <TAB> buf = BytesIO(self.stream.read(self.current_block.compressed_size)) <TAB> self.current_stream = self.current_block.decompress(buf)",if ofs + b . uncompressed_size > pos :,190
2276,"def rewrite_hunks(hunks): <TAB> # type: (List[Hunk]) -> Iterator[Hunk] <TAB> # Assumes `hunks` are sorted, and from the same file <TAB> deltas = (hunk.b_length - hunk.a_length for hunk in hunks) <TAB> offsets = accumulate(deltas, initial=0) <TAB> for hunk, offset in zip(hunks, offsets): <TAB>  <TAB> new_b = hunk.a_start + offset <TAB>  <TAB> if hunk_of_additions_only(hunk): <TAB>  <TAB>  <TAB> new_b += 1 <MASK> new_b -= 1 <TAB>  <TAB> yield hunk._replace(b_start=new_b)",elif hunk_of_removals_only ( hunk ) :,185
2277,"def do_query(data, q): <TAB> ret = [] <TAB> if not q: <TAB>  <TAB> return ret <TAB> qkey = q[0] <TAB> for key, value in iterate(data): <MASK> if key == qkey: <TAB>  <TAB>  <TAB>  <TAB> ret.append(value) <TAB>  <TAB>  <TAB> elif is_iterable(value): <TAB>  <TAB>  <TAB>  <TAB> ret.extend(do_query(value, q)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if not is_iterable(value): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if key == qkey: <TAB>  <TAB>  <TAB>  <TAB> ret.extend(do_query(value, q[1:])) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> ret.extend(do_query(value, q)) <TAB> return ret",if len ( q ) == 1 :,185
2278,"def get_url(token, base_url): <TAB> """"""Parse an <url> token."""""" <TAB> if token.type == ""url"": <TAB>  <TAB> return _get_url_tuple(token.value, base_url) <TAB> elif token.type == ""function"": <TAB>  <TAB> if token.name == ""attr"": <TAB>  <TAB>  <TAB> return check_attr_function(token, ""url"") <MASK> # Ignore url modifiers <TAB>  <TAB>  <TAB> # See https://drafts.csswg.org/css-values-3/#urls <TAB>  <TAB>  <TAB> return _get_url_tuple(token.arguments[0].value, base_url)","elif token . name == ""url"" and len ( token . arguments ) in ( 1 , 2 ) :",166
2279,"def read(self, count): <TAB> if self.closed: <TAB>  <TAB> return self.upstream.read(count) <TAB> try: <TAB>  <TAB> while len(self.upstream) < count: <MASK> with self.buf_in: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.transport.downstream_recv(self.buf_in) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> return self.upstream.read(count) <TAB> except: <TAB>  <TAB> logger.debug(traceback.format_exc())",if self . buf_in or self . _poll_read ( 10 ) :,140
2280,"def get_timestamp_for_block( <TAB> self, block_hash: HexBytes, max_tries: Optional[int] = 10) -> int: <TAB> counter = 0 <TAB> block: AttributeDict = None <TAB> if block_hash in self._block_cache.keys(): <TAB>  <TAB> block = self._block_cache.get(block_hash) <TAB> else: <TAB>  <TAB> while block is None: <MASK> raise ValueError(f""Block hash {block_hash.hex()} does not exist."") <TAB>  <TAB>  <TAB> counter += 1 <TAB>  <TAB>  <TAB> block = self._block_cache.get(block_hash) <TAB>  <TAB>  <TAB> await asyncio.sleep(0.5) <TAB> return block.get(""timestamp"")",if counter == max_tries :,172
2281,"def reader(): <TAB> batch_out = [] <TAB> for video_name in self.video_list: <TAB>  <TAB> video_idx = self.video_list.index(video_name) <TAB>  <TAB> video_feat = self.load_file(video_name) <TAB>  <TAB> batch_out.append((video_feat, video_idx)) <MASK> yield batch_out <TAB>  <TAB>  <TAB> batch_out = []",if len ( batch_out ) == self . batch_size :,111
2282,"def cleanup(): <TAB> gscript.message(_(""Erasing temporary files..."")) <TAB> for temp_map, maptype in temp_maps: <MASK> gscript.run_command( <TAB>  <TAB>  <TAB>  <TAB> ""g.remove"", flags=""f"", type=maptype, name=temp_map, quiet=True <TAB>  <TAB>  <TAB> )","if gscript . find_file ( temp_map , element = maptype ) [ ""name"" ] :",94
2283,"def run(self): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> with DelayedKeyboardInterrupt(): <TAB>  <TAB>  <TAB>  <TAB> raw_inputs = self._parent_task_queue.get() <MASK> self._rq.put(raw_inputs, block=True) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB>  <TAB> if self._flow_type == BATCH: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._rq.put(raw_inputs, block=True) <TAB>  <TAB>  <TAB>  <TAB> elif self._flow_type == REALTIME: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._rq.put(raw_inputs, block=False) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> except KeyboardInterrupt: <TAB>  <TAB>  <TAB> continue",if self . _has_stop_signal ( raw_inputs ) :,199
2284,"def handle_sent(self, elt): <TAB> sent = [] <TAB> for child in elt: <TAB>  <TAB> if child.tag in (""mw"", ""hi"", ""corr"", ""trunc""): <TAB>  <TAB>  <TAB> sent += [self.handle_word(w) for w in child] <MASK> sent.append(self.handle_word(child)) <TAB>  <TAB> elif child.tag not in self.tags_to_ignore: <TAB>  <TAB>  <TAB> raise ValueError(""Unexpected element %s"" % child.tag) <TAB> return BNCSentence(elt.attrib[""n""], sent)","elif child . tag in ( ""w"" , ""c"" ) :",141
2285,"def bind_subscribers_to_graphql_type(self, graphql_type): <TAB> for field, subscriber in self._subscribers.items(): <MASK> raise ValueError(""Field %s is not defined on type %s"" % (field, self.name)) <TAB>  <TAB> graphql_type.fields[field].subscribe = subscriber",if field not in graphql_type . fields :,84
2286,"def _get_from_json(self, *, name, version): <TAB> url = urljoin(self.url, posixpath.join(name, str(version), ""json"")) <TAB> async with aiohttp_session(auth=self.auth) as session: <TAB>  <TAB> async with session.get(url) as response: <MASK> raise PackageNotFoundError(package=name, url=url) <TAB>  <TAB>  <TAB> response.raise_for_status() <TAB>  <TAB>  <TAB> response = await response.json() <TAB> dist = response[""info""][""requires_dist""] or [] <TAB> if dist: <TAB>  <TAB> return dist <TAB> # If no requires_dist then package metadata can be broken. <TAB> # Let's check distribution files. <TAB> return await self._get_from_files(response[""urls""])",if response . status == 404 :,186
2287,"def is_active(self): <TAB> if not self.pk: <TAB>  <TAB> log_level = get_setting(""LOG_MISSING_SWITCHES"") <TAB>  <TAB> if log_level: <TAB>  <TAB>  <TAB> logger.log(log_level, ""Switch %s not found"", self.name) <MASK> switch, _created = Switch.objects.get_or_create( <TAB>  <TAB>  <TAB>  <TAB> name=self.name, defaults={""active"": get_setting(""SWITCH_DEFAULT"")} <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> cache = get_cache() <TAB>  <TAB>  <TAB> cache.set(self._cache_key(self.name), switch) <TAB>  <TAB> return get_setting(""SWITCH_DEFAULT"") <TAB> return self.active","if get_setting ( ""CREATE_MISSING_SWITCHES"" ) :",179
2288,"def add_requirements(self, requirements): <TAB> if self._legacy: <TAB>  <TAB> self._legacy.add_requirements(requirements) <TAB> else: <TAB>  <TAB> run_requires = self._data.setdefault(""run_requires"", []) <TAB>  <TAB> always = None <TAB>  <TAB> for entry in run_requires: <MASK> always = entry <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if always is None: <TAB>  <TAB>  <TAB> always = {""requires"": requirements} <TAB>  <TAB>  <TAB> run_requires.insert(0, always) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> rset = set(always[""requires""]) | set(requirements) <TAB>  <TAB>  <TAB> always[""requires""] = sorted(rset)","if ""environment"" not in entry and ""extra"" not in entry :",171
2289,"def display_failures_for_single_test(result: TestResult) -> None: <TAB> """"""Display a failure for a single method / endpoint."""""" <TAB> display_subsection(result) <TAB> checks = _get_unique_failures(result.checks) <TAB> for idx, check in enumerate(checks, 1): <TAB>  <TAB> message: Optional[str] <TAB>  <TAB> if check.message: <TAB>  <TAB>  <TAB> message = f""{idx}. {check.message}"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> message = None <TAB>  <TAB> example = cast(Case, check.example)  # filtered in `_get_unique_failures` <TAB>  <TAB> display_example(example, check.name, message, result.seed) <TAB>  <TAB> # Display every time except the last check <MASK> click.echo(""\n"")",if idx != len ( checks ) :,188
2290,"def __call__(self, frame: FrameType, event: str, arg: Any) -> ""CallTracer"": <TAB> code = frame.f_code <TAB> if ( <TAB>  <TAB> event not in SUPPORTED_EVENTS <TAB>  <TAB> or code.co_name == ""trace_types"" <TAB>  <TAB> or self.should_trace <TAB>  <TAB> and not self.should_trace(code) <TAB> ): <TAB>  <TAB> return self <TAB> try: <TAB>  <TAB> if event == EVENT_CALL: <TAB>  <TAB>  <TAB> self.handle_call(frame) <MASK> self.handle_return(frame, arg) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logger.error(""Cannot handle event %s"", event) <TAB> except Exception: <TAB>  <TAB> logger.exception(""Failed collecting trace"") <TAB> return self",elif event == EVENT_RETURN :,185
2291,"def get_maps(test): <TAB> pages = set() <TAB> for addr in test[""pre""][""memory""].keys(): <TAB>  <TAB> pages.add(addr >> 12) <TAB> for addr in test[""pos""][""memory""].keys(): <TAB>  <TAB> pages.add(addr >> 12) <TAB> maps = [] <TAB> for p in sorted(pages): <MASK> maps[-1] = (maps[-1][0], maps[-1][1] + 0x1000) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> maps.append((p << 12, 0x1000)) <TAB> return maps",if len ( maps ) > 0 and maps [ - 1 ] [ 0 ] + maps [ - 1 ] [ 1 ] == p << 12 :,157
2292,"def process_rotate_aes_key(self): <TAB> if hasattr(self.options, ""rotate_aes_key"") and isinstance( <TAB>  <TAB> self.options.rotate_aes_key, six.string_types <TAB> ): <MASK> self.options.rotate_aes_key = True <TAB>  <TAB> elif self.options.rotate_aes_key.lower() == ""false"": <TAB>  <TAB>  <TAB> self.options.rotate_aes_key = False","if self . options . rotate_aes_key . lower ( ) == ""true"" :",122
2293,"def apply_figure(self, figure): <TAB> super(legend_text_legend, self).apply_figure(figure) <TAB> properties = self.properties.copy() <TAB> with suppress(KeyError): <TAB>  <TAB> del properties[""margin""] <TAB> with suppress(KeyError): <TAB>  <TAB> texts = figure._themeable[""legend_text_legend""] <TAB>  <TAB> for text in texts: <MASK> # textarea <TAB>  <TAB>  <TAB>  <TAB> text = text._text <TAB>  <TAB>  <TAB> text.set(**properties)","if not hasattr ( text , ""_x"" ) :",121
2294,"def tearDown(self): <TAB> for i in range(len(self.tree) - 1, -1, -1): <TAB>  <TAB> s = os.path.join(self.root, self.tree[i]) <MASK> os.rmdir(s) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> os.remove(s) <TAB> os.rmdir(self.root)","if not ""."" in s :",93
2295,"def _get_id(self, type, id): <TAB> fields = id.split("":"") <TAB> if len(fields) >= 3: <TAB>  <TAB> if type != fields[-2]: <TAB>  <TAB>  <TAB> logger.warning( <TAB>  <TAB>  <TAB>  <TAB> ""Expected id of type %s but found type %s %s"", type, fields[-2], id <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return fields[-1] <TAB> fields = id.split(""/"") <TAB> if len(fields) >= 3: <TAB>  <TAB> itype = fields[-2] <MASK> logger.warning( <TAB>  <TAB>  <TAB>  <TAB> ""Expected id of type %s but found type %s %s"", type, itype, id <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return fields[-1].split(""?"")[0] <TAB> return id",if type != itype :,178
2296,"def candidates() -> Generator[""Symbol"", None, None]: <TAB> s = self <TAB> if Symbol.debug_lookup: <TAB>  <TAB> Symbol.debug_print(""searching in self:"") <TAB>  <TAB> print(s.to_string(Symbol.debug_indent + 1), end="""") <TAB> while True: <MASK> yield s <TAB>  <TAB> if recurseInAnon: <TAB>  <TAB>  <TAB> yield from s.children_recurse_anon <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield from s._children <TAB>  <TAB> if s.siblingAbove is None: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> s = s.siblingAbove <TAB>  <TAB> if Symbol.debug_lookup: <TAB>  <TAB>  <TAB> Symbol.debug_print(""searching in sibling:"") <TAB>  <TAB>  <TAB> print(s.to_string(Symbol.debug_indent + 1), end="""")",if matchSelf :,190
2297,"def records(account_id): <TAB> """"""Fetch locks data"""""" <TAB> s = boto3.Session() <TAB> table = s.resource(""dynamodb"").Table(""Sphere11.Dev.ResourceLocks"") <TAB> results = table.scan() <TAB> for r in results[""Items""]: <TAB>  <TAB> if ""LockDate"" in r: <TAB>  <TAB>  <TAB> r[""LockDate""] = datetime.fromtimestamp(r[""LockDate""]) <MASK> r[""RevisionDate""] = datetime.fromtimestamp(r[""RevisionDate""]) <TAB> print(tabulate.tabulate(results[""Items""], headers=""keys"", tablefmt=""fancy_grid""))","if ""RevisionDate"" in r :",149
2298,"def _handle_errors(errors): <TAB> """"""Log out and possibly reraise errors during import."""""" <TAB> if not errors: <TAB>  <TAB> return <TAB> log_all = True  # pylint: disable=unused-variable <TAB> err_msg = ""T2T: skipped importing {num_missing} data_generators modules."" <TAB> print(err_msg.format(num_missing=len(errors))) <TAB> for module, err in errors: <TAB>  <TAB> err_str = str(err) <TAB>  <TAB> if log_all: <TAB>  <TAB>  <TAB> print(""Did not import module: %s; Cause: %s"" % (module, err_str)) <MASK> print(""From module %s"" % module) <TAB>  <TAB>  <TAB> raise err","if not _is_import_err_msg ( err_str , module ) :",184
2299,"def find_needle(self, tree, focused=None): <TAB> if isinstance(tree, list): <TAB>  <TAB> for el in tree: <TAB>  <TAB>  <TAB> res = self.find_needle(el, focused) <MASK> return res <TAB> elif isinstance(tree, dict): <TAB>  <TAB> nodes = tree.get(""nodes"", []) + tree.get(""floating_nodes"", []) <TAB>  <TAB> if focused: <TAB>  <TAB>  <TAB> for node in nodes: <TAB>  <TAB>  <TAB>  <TAB> if node[""id""] == focused[""id""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return tree <TAB>  <TAB> elif tree[""focused""]: <TAB>  <TAB>  <TAB> return tree <TAB>  <TAB> return self.find_needle(nodes, focused) <TAB> return {}",if res :,169
2300,"def available_datasets(self): <TAB> """"""Automatically determine datasets provided by this file"""""" <TAB> res = self.resolution <TAB> coordinates = [""pixel_longitude"", ""pixel_latitude""] <TAB> for var_name, val in self.file_content.items(): <TAB>  <TAB> if isinstance(val, netCDF4.Variable): <TAB>  <TAB>  <TAB> ds_info = { <TAB>  <TAB>  <TAB>  <TAB> ""file_type"": self.filetype_info[""file_type""], <TAB>  <TAB>  <TAB>  <TAB> ""resolution"": res, <TAB>  <TAB>  <TAB> } <MASK> ds_info[""coordinates""] = coordinates <TAB>  <TAB>  <TAB> yield DatasetID(name=var_name, resolution=res), ds_info",if not self . is_geo :,165
2301,"def get_subkeys(self, key): <TAB> # TODO: once we revamp the registry emulation, <TAB> # make this better <TAB> parent_path = key.get_path() <TAB> subkeys = [] <TAB> for k in self.keys: <TAB>  <TAB> test_path = k.get_path() <MASK> sub = test_path[len(parent_path) :] <TAB>  <TAB>  <TAB> if sub.startswith(""\\""): <TAB>  <TAB>  <TAB>  <TAB> sub = sub[1:] <TAB>  <TAB>  <TAB> end_slash = sub.find(""\\"") <TAB>  <TAB>  <TAB> if end_slash >= 0: <TAB>  <TAB>  <TAB>  <TAB> sub = sub[:end_slash] <TAB>  <TAB>  <TAB> if not sub: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> subkeys.append(sub) <TAB> return subkeys",if test_path . lower ( ) . startswith ( parent_path . lower ( ) ) :,192
2302,"def default(self, o): <TAB> try: <TAB>  <TAB> if type(o) == datetime.datetime: <TAB>  <TAB>  <TAB> return str(o) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # remove unwanted attributes from the provider object during conversion to json <TAB>  <TAB>  <TAB> if hasattr(o, ""profile""): <TAB>  <TAB>  <TAB>  <TAB> del o.profile <MASK> del o.credentials <TAB>  <TAB>  <TAB> if hasattr(o, ""metadata_path""): <TAB>  <TAB>  <TAB>  <TAB> del o.metadata_path <TAB>  <TAB>  <TAB> if hasattr(o, ""services_config""): <TAB>  <TAB>  <TAB>  <TAB> del o.services_config <TAB>  <TAB>  <TAB> return vars(o) <TAB> except Exception as e: <TAB>  <TAB> return str(o)","if hasattr ( o , ""credentials"" ) :",172
2303,"def submit(self, fn, *args, **kwargs): <TAB> with self._shutdown_lock: <MASK> raise RuntimeError(""cannot schedule new futures after shutdown"") <TAB>  <TAB> f = _base.Future() <TAB>  <TAB> w = _WorkItem(f, fn, args, kwargs) <TAB>  <TAB> self._work_queue.put(w) <TAB>  <TAB> self._adjust_thread_count() <TAB>  <TAB> return f",if self . _shutdown :,101
2304,"def __viewerKeyPress(viewer, event): <TAB> view = viewer.view() <TAB> if not isinstance(view, GafferSceneUI.SceneView): <TAB>  <TAB> return False <TAB> if event == __editSourceKeyPress: <TAB>  <TAB> selectedPath = __sceneViewSelectedPath(view) <MASK> __editSourceNode(view.getContext(), view[""in""], selectedPath) <TAB>  <TAB> return True <TAB> elif event == __editTweaksKeyPress: <TAB>  <TAB> selectedPath = __sceneViewSelectedPath(view) <TAB>  <TAB> if selectedPath is not None: <TAB>  <TAB>  <TAB> __editTweaksNode(view.getContext(), view[""in""], selectedPath) <TAB>  <TAB> return True",if selectedPath is not None :,175
2305,"def _split_to_option_groups_and_paths(self, args): <TAB> opt_groups = [] <TAB> current = [] <TAB> for arg in args: <MASK> opts = self._arg_parser.parse_args(current)[0] <TAB>  <TAB>  <TAB> opt_groups.append(opts) <TAB>  <TAB>  <TAB> current = [] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> current.append(arg) <TAB> if opt_groups: <TAB>  <TAB> return opt_groups, current <TAB> raise ValueError(""Nothing to split"")","if arg . replace ( ""-"" , """" ) == """" and len ( arg ) >= 3 :",136
2306,"def _on_change(self): <TAB> changed = False <TAB> self.save() <TAB> for key, value in self.data.items(): <TAB>  <TAB> if isinstance(value, bool): <MASK> changed = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if isinstance(value, int): <TAB>  <TAB>  <TAB> if value != 1: <TAB>  <TAB>  <TAB>  <TAB> changed = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif value is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif len(value) != 0: <TAB>  <TAB>  <TAB> changed = True <TAB>  <TAB>  <TAB> break <TAB> self._reset_button.disabled = not changed",if value :,145
2307,"def wait_for_child(pid, timeout=1.0): <TAB> deadline = mitogen.core.now() + timeout <TAB> while timeout < mitogen.core.now(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> target_pid, status = os.waitpid(pid, os.WNOHANG) <TAB>  <TAB>  <TAB> if target_pid == pid: <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> e = sys.exc_info()[1] <MASK> return <TAB>  <TAB> time.sleep(0.05) <TAB> assert False, ""wait_for_child() timed out""",if e . args [ 0 ] == errno . ECHILD :,156
2308,"def _get_os_version_lsb_release(): <TAB> try: <TAB>  <TAB> output = subprocess.check_output(""lsb_release -sri"", shell=True) <TAB>  <TAB> lines = output.strip().split() <TAB>  <TAB> name, version = lines <MASK> version = """" <TAB>  <TAB> return name, version <TAB> except: <TAB>  <TAB> return _get_os_version_uname()","if version . lower ( ) == ""rolling"" :",101
2309,"def _check_snapshot_status_healthy(self, snapshot_uuid): <TAB> status = """" <TAB> try: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> status, locked = self._get_snapshot_status(snapshot_uuid) <MASK> break <TAB>  <TAB>  <TAB> eventlet.sleep(2) <TAB> except Exception: <TAB>  <TAB> with excutils.save_and_reraise_exception(): <TAB>  <TAB>  <TAB> LOG.exception(""Failed to get snapshot status. [%s]"", snapshot_uuid) <TAB> LOG.debug( <TAB>  <TAB> ""Lun [%(snapshot)s], status [%(status)s]."", <TAB>  <TAB> {""snapshot"": snapshot_uuid, ""status"": status}, <TAB> ) <TAB> return status == ""Healthy""",if not locked :,172
2310,"def CountButtons(self): <TAB> """"""Returns the number of visible buttons in the docked pane."""""" <TAB> n = 0 <TAB> if self.HasCaption() or self.HasCaptionLeft(): <TAB>  <TAB> if isinstance(wx.GetTopLevelParent(self.window), AuiFloatingFrame): <TAB>  <TAB>  <TAB> return 1 <MASK> n += 1 <TAB>  <TAB> if self.HasMaximizeButton(): <TAB>  <TAB>  <TAB> n += 1 <TAB>  <TAB> if self.HasMinimizeButton(): <TAB>  <TAB>  <TAB> n += 1 <TAB>  <TAB> if self.HasPinButton(): <TAB>  <TAB>  <TAB> n += 1 <TAB> return n",if self . HasCloseButton ( ) :,149
2311,"def _url_encode_impl(obj, charset, encode_keys, sort, key): <TAB> from .datastructures import iter_multi_items <TAB> iterable = iter_multi_items(obj) <TAB> if sort: <TAB>  <TAB> iterable = sorted(iterable, key=key) <TAB> for key, value in iterable: <MASK> continue <TAB>  <TAB> if not isinstance(key, bytes): <TAB>  <TAB>  <TAB> key = text_type(key).encode(charset) <TAB>  <TAB> if not isinstance(value, bytes): <TAB>  <TAB>  <TAB> value = text_type(value).encode(charset) <TAB>  <TAB> yield _fast_url_quote_plus(key) + ""="" + _fast_url_quote_plus(value)",if value is None :,168
2312,"def get_response(self, exc_fmt=None): <TAB> self.callback = None <TAB> if __debug__: <TAB>  <TAB> self.parent._log(3, ""%s:%s.ready.wait"" % (self.name, self.tag)) <TAB> self.ready.wait() <TAB> if self.aborted is not None: <TAB>  <TAB> typ, val = self.aborted <MASK> exc_fmt = ""%s - %%s"" % typ <TAB>  <TAB> raise typ(exc_fmt % str(val)) <TAB> return self.response",if exc_fmt is None :,131
2313,"def extract_items(self): <TAB> responses = self.fetch() <TAB> items = [] <TAB> for response in responses: <TAB>  <TAB> page_key = response.meta.get(""page_key"") or response.url <TAB>  <TAB> item = {""key"": page_key, ""items"": None, ""templates"": None} <TAB>  <TAB> extracted_items = [ <TAB>  <TAB>  <TAB> dict(i) for i in self.spider.parse(response) if not isinstance(i, Request) <TAB>  <TAB> ] <MASK> item[""items""] = extracted_items <TAB>  <TAB>  <TAB> item[""templates""] = [ <TAB>  <TAB>  <TAB>  <TAB> i[""_template""] for i in extracted_items if i.get(""_template"") <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB> items.append(item) <TAB> return items",if extracted_items :,182
2314,"def fit_one(self, x): <TAB> for i, xi in x.items(): <TAB>  <TAB> if self.with_centering: <TAB>  <TAB>  <TAB> self.median[i].update(xi) <MASK> self.iqr[i].update(xi) <TAB> return self",if self . with_scaling :,75
2315,"def find_word_bounds(self, text, index, allowed_chars): <TAB> right = left = index <TAB> done = False <TAB> while not done: <TAB>  <TAB> if left == 0: <TAB>  <TAB>  <TAB> done = True <MASK> left -= 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> done = True <TAB> done = False <TAB> while not done: <TAB>  <TAB> if right == len(text): <TAB>  <TAB>  <TAB> done = True <TAB>  <TAB> elif not self.word_boundary_char(text[right]): <TAB>  <TAB>  <TAB> right += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> done = True <TAB> return left, right",elif not self . word_boundary_char ( text [ left - 1 ] ) :,159
2316,"def _validate_duplicate_detection_history_time_window(namespace): <TAB> if namespace.duplicate_detection_history_time_window: <TAB>  <TAB> if iso8601pattern.match(namespace.duplicate_detection_history_time_window): <TAB>  <TAB>  <TAB> pass <MASK> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise CLIError( <TAB>  <TAB>  <TAB>  <TAB> ""--duplicate-detection-history-time-window Value Error : {0} value is not in ISO 8601 timespan / duration format. e.g. PT10M for duration of 10 min or 00:10:00 for duration of 10 min"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> namespace.duplicate_detection_history_time_window <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> )",elif timedeltapattern . match ( namespace . duplicate_detection_history_time_window ) :,187
2317,"def get_subkeys(self, key): <TAB> # TODO: once we revamp the registry emulation, <TAB> # make this better <TAB> parent_path = key.get_path() <TAB> subkeys = [] <TAB> for k in self.keys: <TAB>  <TAB> test_path = k.get_path() <TAB>  <TAB> if test_path.lower().startswith(parent_path.lower()): <TAB>  <TAB>  <TAB> sub = test_path[len(parent_path) :] <TAB>  <TAB>  <TAB> if sub.startswith(""\\""): <TAB>  <TAB>  <TAB>  <TAB> sub = sub[1:] <TAB>  <TAB>  <TAB> end_slash = sub.find(""\\"") <TAB>  <TAB>  <TAB> if end_slash >= 0: <TAB>  <TAB>  <TAB>  <TAB> sub = sub[:end_slash] <MASK> continue <TAB>  <TAB>  <TAB> subkeys.append(sub) <TAB> return subkeys",if not sub :,192
2318,"def generator(self, data): <MASK> silent_vars = self._get_silent_vars() <TAB> for task in data: <TAB>  <TAB> for var, val in task.environment_variables(): <TAB>  <TAB>  <TAB> if self._config.SILENT: <TAB>  <TAB>  <TAB>  <TAB> if var in silent_vars: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> yield ( <TAB>  <TAB>  <TAB>  <TAB> 0, <TAB>  <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> int(task.UniqueProcessId), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> str(task.ImageFileName), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> Address(task.Peb.ProcessParameters.Environment), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> str(var), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> str(val), <TAB>  <TAB>  <TAB>  <TAB> ], <TAB>  <TAB>  <TAB> )",if self . _config . SILENT :,182
2319,"def start_requests(self): <TAB> if self.fail_before_yield: <TAB>  <TAB> 1 / 0 <TAB> for s in range(100): <TAB>  <TAB> qargs = {""total"": 10, ""seed"": s} <TAB>  <TAB> url = self.mockserver.url(""/follow?%s"") % urlencode(qargs, doseq=1) <TAB>  <TAB> yield Request(url, meta={""seed"": s}) <MASK> 2 / 0 <TAB> assert self.seedsseen, ""All start requests consumed before any download happened""",if self . fail_yielding :,127
2320,"def populateGridlines(self): <TAB> cTicks = self.getSystemCurve(self.ticksId) <TAB> cGridlines = self.getSystemCurve(self.gridlinesId) <TAB> cGridlines.clearPoints() <TAB> nTicks = cTicks.getNPoints() <TAB> for iTick in range(nTicks): <MASK> p = cTicks.getPoint(iTick) <TAB>  <TAB>  <TAB> cGridlines.addPoint(p.getX(), p.getY())",if self . hasGridlines and ( iTick % self . ticksPerGridline ) == 0 :,139
2321,"def handle_before_events(request, event_list): <TAB> if not event_list: <TAB>  <TAB> return """" <TAB> if not hasattr(event_list, ""__iter__""): <TAB>  <TAB> project = event_list.project <TAB>  <TAB> event_list = [event_list] <TAB> else: <TAB>  <TAB> projects = set(e.project for e in event_list) <MASK> project = projects.pop() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> project = None <TAB> for plugin in plugins.for_project(project): <TAB>  <TAB> safe_execute(plugin.before_events, request, event_list) <TAB> return """"",if len ( projects ) == 1 :,152
2322,"def handle_parse_result(self, ctx, opts, args): <TAB> if self.name in opts: <MASK> self._raise_exclusive_error() <TAB>  <TAB> if self.multiple and len(set(opts[self.name])) > 1: <TAB>  <TAB>  <TAB> self._raise_exclusive_error() <TAB> return super(MutuallyExclusiveOption, self).handle_parse_result(ctx, opts, args)",if self . mutually_exclusive . intersection ( opts ) :,108
2323,"def current_word(cursor_offset, line): <TAB> """"""the object.attribute.attribute just before or under the cursor"""""" <TAB> pos = cursor_offset <TAB> start = pos <TAB> end = pos <TAB> word = None <TAB> for m in current_word_re.finditer(line): <MASK> start = m.start(1) <TAB>  <TAB>  <TAB> end = m.end(1) <TAB>  <TAB>  <TAB> word = m.group(1) <TAB> if word is None: <TAB>  <TAB> return None <TAB> return LinePart(start, end, word)",if m . start ( 1 ) < pos and m . end ( 1 ) >= pos :,147
2324,"def query_to_script_path(path, query): <TAB> if path != ""*"": <TAB>  <TAB> script = os.path.join(path, query.split("" "")[0]) <MASK> raise IOError(""Script '{}' not found in script directory"".format(query)) <TAB>  <TAB> return os.path.join(path, query).split("" "") <TAB> return query",if not os . path . exists ( script ) :,93
2325,"def expand(self, pbegin): <TAB> # TODO(b/151921205): we have to do an identity map for unmodified <TAB> # PCollections below because otherwise we get an error from beam. <TAB> identity_map = ""Identity"" >> beam.Map(lambda x: x) <TAB> if self._dataset_key.is_flattened_dataset_key(): <MASK> return self._flat_pcollection | identity_map <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return list( <TAB>  <TAB>  <TAB>  <TAB> self._pcollection_dict.values() <TAB>  <TAB>  <TAB> ) | ""FlattenAnalysisInputs"" >> beam.Flatten(pipeline=pbegin.pipeline) <TAB> else: <TAB>  <TAB> return self._pcollection_dict[self._dataset_key] | identity_map",if self . _flat_pcollection :,183
2326,"def processCoords(coords): <TAB> newcoords = deque() <TAB> for (x, y, z) in coords: <TAB>  <TAB> for _dir, offsets in faceDirections: <TAB>  <TAB>  <TAB> if _dir == FaceYIncreasing: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> dx, dy, dz = offsets <TAB>  <TAB>  <TAB> p = (x + dx, y + dy, z + dz) <TAB>  <TAB>  <TAB> if p not in box: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> nx, ny, nz = p <MASK> level.setBlockAt(nx, ny, nz, waterID) <TAB>  <TAB>  <TAB>  <TAB> newcoords.append(p) <TAB> return newcoords","if level . blockAt ( nx , ny , nz ) == 0 :",173
2327,"def delete_byfilter(userId, remove=True, session=None, **dbfilter): <TAB> if not session: <TAB>  <TAB> session = db.Session <TAB> ret = False <TAB> results = session.query(ObjectStorageMetadata).filter_by(**dbfilter) <TAB> if results: <TAB>  <TAB> for result in results: <MASK> session.delete(result) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> result.update( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""record_state_key"": ""to_delete"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""record_state_val"": str(time.time()), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ret = True <TAB> return ret",if remove :,176
2328,"def fields(self, fields): <TAB> fields_xml = """" <TAB> for field in fields: <TAB>  <TAB> field_dict = DEFAULT_FIELD.copy() <TAB>  <TAB> field_dict.update(field) <MASK> field_dict[""required""] = ""true"" <TAB>  <TAB> fields_xml += FIELD_XML_TEMPLATE % field_dict + ""\n"" <TAB> self.xml = force_unicode( <TAB>  <TAB> force_unicode(self.xml).replace( <TAB>  <TAB>  <TAB> u""<!-- REPLACE FIELDS -->"", force_unicode(fields_xml) <TAB>  <TAB> ) <TAB> )","if self . unique_key_field == field [ ""name"" ] :",146
2329,"def get_all_users(self, access_token, timeout=None): <TAB> if timeout is None: <TAB>  <TAB> timeout = DEFAULT_TIMEOUT <TAB> headers = self.retrieve_header(access_token) <TAB> try: <TAB>  <TAB> response = await self.standard_request( <TAB>  <TAB>  <TAB> ""get"", ""/walkoff/api/users"", timeout=DEFAULT_TIMEOUT, headers=headers <TAB>  <TAB> ) <MASK> resp = await response.json() <TAB>  <TAB>  <TAB> return resp, ""Success"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""Invalid Credentials"" <TAB> except asyncio.CancelledError: <TAB>  <TAB> return False, ""TimedOut""",if response . status == 200 :,156
2330,"def set_val(): <TAB> idx = 0 <TAB> for idx in range(0, len(model)): <TAB>  <TAB> row = model[idx] <TAB>  <TAB> if value and row[0] == value: <TAB>  <TAB>  <TAB> break <MASK> idx = -1 <TAB> os_widget.set_active(idx) <TAB> if idx == -1: <TAB>  <TAB> os_widget.set_active(0) <TAB> if idx >= 0: <TAB>  <TAB> return row[1] <TAB> if self.show_all_os: <TAB>  <TAB> return None",if idx == len ( os_widget . get_model ( ) ) - 1 :,142
2331,"def translate_module_name(module: str, relative: int) -> Tuple[str, int]: <TAB> for pkg in VENDOR_PACKAGES: <TAB>  <TAB> for alt in ""six.moves"", ""six"": <TAB>  <TAB>  <TAB> substr = ""{}.{}"".format(pkg, alt) <TAB>  <TAB>  <TAB> if module.endswith(""."" + substr) or (module == substr and relative): <TAB>  <TAB>  <TAB>  <TAB> return alt, 0 <MASK> return alt + ""."" + module.partition(""."" + substr + ""."")[2], 0 <TAB> return module, relative","if ""."" + substr + ""."" in module :",132
2332,"def escape(m): <TAB> all, tail = m.group(0, 1) <TAB> assert all.startswith(""\\"") <TAB> esc = simple_escapes.get(tail) <TAB> if esc is not None: <TAB>  <TAB> return esc <TAB> if tail.startswith(""x""): <TAB>  <TAB> hexes = tail[1:] <MASK> raise ValueError(""invalid hex string escape ('\\%s')"" % tail) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> i = int(hexes, 16) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> raise ValueError(""invalid hex string escape ('\\%s')"" % tail) <TAB> else: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> i = int(tail, 8) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> raise ValueError(""invalid octal string escape ('\\%s')"" % tail) <TAB> return chr(i)",if len ( hexes ) < 2 :,198
2333,"def __get_k8s_container_name(self, job_wrapper): <TAB> # These must follow a specific regex for Kubernetes. <TAB> raw_id = job_wrapper.job_destination.id <TAB> if isinstance(raw_id, str): <TAB>  <TAB> cleaned_id = re.sub(""[^-a-z0-9]"", ""-"", raw_id) <MASK> cleaned_id = ""x%sx"" % cleaned_id <TAB>  <TAB> return cleaned_id <TAB> return ""job-container""","if cleaned_id . startswith ( ""-"" ) or cleaned_id . endswith ( ""-"" ) :",131
2334,"def _power_exact(y, xc, yc, xe): <TAB> yc, ye = y.int, y.exp <TAB> while yc % 10 == 0: <TAB>  <TAB> yc //= 10 <TAB>  <TAB> ye += 1 <TAB> if xc == 1: <TAB>  <TAB> xe *= yc <TAB>  <TAB> while xe % 10 == 0: <TAB>  <TAB>  <TAB> xe //= 10 <TAB>  <TAB>  <TAB> ye += 1 <TAB>  <TAB> if ye < 0: <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> exponent = xe * 10 ** ye <MASK> xc = exponent <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> xc = 0 <TAB>  <TAB> return 5",if y and xe :,144
2335,"def lpush(key, *vals, **kwargs): <TAB> ttl = kwargs.get(""ttl"") <TAB> cap = kwargs.get(""cap"") <TAB> if not ttl and not cap: <TAB>  <TAB> _client.lpush(key, *vals) <TAB> else: <TAB>  <TAB> pipe = _client.pipeline() <TAB>  <TAB> pipe.lpush(key, *vals) <MASK> pipe.ltrim(key, 0, cap) <TAB>  <TAB> if ttl: <TAB>  <TAB>  <TAB> pipe.expire(key, ttl) <TAB>  <TAB> pipe.execute()",if cap :,131
2336,"def render_headers(self) -> bytes: <TAB> if not hasattr(self, ""_headers""): <TAB>  <TAB> parts = [ <TAB>  <TAB>  <TAB> b""Content-Disposition: form-data; "", <TAB>  <TAB>  <TAB> format_form_param(""name"", self.name), <TAB>  <TAB> ] <TAB>  <TAB> if self.filename: <TAB>  <TAB>  <TAB> filename = format_form_param(""filename"", self.filename) <TAB>  <TAB>  <TAB> parts.extend([b""; "", filename]) <MASK> content_type = self.content_type.encode() <TAB>  <TAB>  <TAB> parts.extend([b""\r\nContent-Type: "", content_type]) <TAB>  <TAB> parts.append(b""\r\n\r\n"") <TAB>  <TAB> self._headers = b"""".join(parts) <TAB> return self._headers",if self . content_type is not None :,189
2337,"def validate_custom_field_data(field_type: int, field_data: ProfileFieldData) -> None: <TAB> try: <MASK> # Choice type field must have at least have one choice <TAB>  <TAB>  <TAB> if len(field_data) < 1: <TAB>  <TAB>  <TAB>  <TAB> raise JsonableError(_(""Field must have at least one choice."")) <TAB>  <TAB>  <TAB> validate_choice_field_data(field_data) <TAB>  <TAB> elif field_type == CustomProfileField.EXTERNAL_ACCOUNT: <TAB>  <TAB>  <TAB> validate_external_account_field_data(field_data) <TAB> except ValidationError as error: <TAB>  <TAB> raise JsonableError(error.message)",if field_type == CustomProfileField . CHOICE :,160
2338,"def get_data(self, path): <TAB> """"""Gross hack to contort loader to deal w/ load_*()'s bad API."""""" <TAB> if self.file and path == self.path: <MASK> file = self.file <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.file = file = open(self.path, ""r"") <TAB>  <TAB> with file: <TAB>  <TAB>  <TAB> # Technically should be returning bytes, but <TAB>  <TAB>  <TAB> # SourceLoader.get_code() just passed what is returned to <TAB>  <TAB>  <TAB> # compile() which can handle str. And converting to bytes would <TAB>  <TAB>  <TAB> # require figuring out the encoding to decode to and <TAB>  <TAB>  <TAB> # tokenize.detect_encoding() only accepts bytes. <TAB>  <TAB>  <TAB> return file.read() <TAB> else: <TAB>  <TAB> return super().get_data(path)",if not self . file . closed :,195
2339,"def handle_read(self): <TAB> """"""Called when there is data waiting to be read."""""" <TAB> try: <TAB>  <TAB> chunk = self.recv(self.ac_in_buffer_size) <TAB> except RetryError: <TAB>  <TAB> pass <TAB> except socket.error: <TAB>  <TAB> self.handle_error() <TAB> else: <TAB>  <TAB> self.tot_bytes_received += len(chunk) <MASK> self.transfer_finished = True <TAB>  <TAB>  <TAB> # self.close()  # <-- asyncore.recv() already do that... <TAB>  <TAB>  <TAB> return <TAB>  <TAB> if self._data_wrapper is not None: <TAB>  <TAB>  <TAB> chunk = self._data_wrapper(chunk) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.file_obj.write(chunk) <TAB>  <TAB> except OSError as err: <TAB>  <TAB>  <TAB> raise _FileReadWriteError(err)",if not chunk :,200
2340,"def _swig_extract_dependency_files(self, src): <TAB> dep = [] <TAB> for line in open(src): <MASK> line = line.split("" "")[1].strip(""""""'""\r\n"""""") <TAB>  <TAB>  <TAB> if not (""<"" in line or line in dep): <TAB>  <TAB>  <TAB>  <TAB> dep.append(line) <TAB> return [i for i in dep if os.path.exists(i)]","if line . startswith ( ""#include"" ) or line . startswith ( ""%include"" ) :",111
2341,"def buffer(self, lines, scroll_end=True, scroll_if_editing=False): <TAB> ""Add data to be displayed in the buffer."" <TAB> self.values.extend(lines) <TAB> if scroll_end: <TAB>  <TAB> if not self.editing: <TAB>  <TAB>  <TAB> self.start_display_at = len(self.values) - len(self._my_widgets) <MASK> self.start_display_at = len(self.values) - len(self._my_widgets)",elif scroll_if_editing :,124
2342,"def test_getline(self): <TAB> with tokenize.open(self.file_name) as fp: <TAB>  <TAB> for index, line in enumerate(fp): <MASK> line += ""\n"" <TAB>  <TAB>  <TAB> cached_line = linecache.getline(self.file_name, index + 1) <TAB>  <TAB>  <TAB> self.assertEqual(line, cached_line)","if not line . endswith ( ""\n"" ) :",97
2343,"def selectRow(self, rowNumber, highlight=None): <TAB> if rowNumber == ""h"": <TAB>  <TAB> rowNumber = 0 <TAB> else: <TAB>  <TAB> rowNumber = int(rowNumber) + 1 <TAB> if 1 > rowNumber >= len(self.cells) + 1: <TAB>  <TAB> raise Exception(""Invalid row number."") <TAB> else: <TAB>  <TAB> selected = self.cells[rowNumber][0].selected <TAB>  <TAB> for cell in self.cells[rowNumber]: <MASK> if selected: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> cell.deselect() <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> cell.select() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> if highlight: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> cell.mouseEnter() <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> cell.mouseLeave()",if highlight is None :,193
2344,"def put(self, session): <TAB> with sess_lock: <TAB>  <TAB> self.parent.put(session) <TAB>  <TAB> # Do not store the session if skip paths <TAB>  <TAB> for sp in self.skip_paths: <TAB>  <TAB>  <TAB> if request.path.startswith(sp): <TAB>  <TAB>  <TAB>  <TAB> return <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> del self._cache[session.sid] <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> self._cache[session.sid] = session <TAB> self._normalize()",if session . sid in self . _cache :,133
2345,"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> length = d.getVarInt32() <TAB>  <TAB>  <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB>  <TAB>  <TAB> d.skip(length) <TAB>  <TAB>  <TAB> self.add_status().TryMerge(tmp) <TAB>  <TAB>  <TAB> continue <MASK> self.add_doc_id(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 18 :,169
2346,"def extract(self, zip): <TAB> max_nb = maxNbFile(self) <TAB> for index, field in enumerate(zip.array(""file"")): <MASK> self.warning( <TAB>  <TAB>  <TAB>  <TAB> ""ZIP archive contains many files, but only first %s files are processed"" <TAB>  <TAB>  <TAB>  <TAB> % max_nb <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> self.processFile(field)",if max_nb is not None and max_nb <= index :,110
2347,"def get_norm(norm, out_channels): <TAB> if isinstance(norm, str): <MASK> return None <TAB>  <TAB> norm = { <TAB>  <TAB>  <TAB> ""BN"": BatchNorm2d, <TAB>  <TAB>  <TAB> ""GN"": lambda channels: nn.GroupNorm(32, channels), <TAB>  <TAB>  <TAB> ""nnSyncBN"": nn.SyncBatchNorm,  # keep for debugging <TAB>  <TAB>  <TAB> """": lambda x: x, <TAB>  <TAB> }[norm] <TAB> return norm(out_channels)",if len ( norm ) == 0 :,118
2348,"def execute(self): <TAB> if self._dirty or not self._qr: <TAB>  <TAB> model_class = self.model_class <TAB>  <TAB> query_meta = self.get_query_meta() <TAB>  <TAB> if self._tuples: <TAB>  <TAB>  <TAB> ResultWrapper = TuplesQueryResultWrapper <TAB>  <TAB> elif self._dicts: <TAB>  <TAB>  <TAB> ResultWrapper = DictQueryResultWrapper <TAB>  <TAB> elif self._naive or not self._joins or self.verify_naive(): <TAB>  <TAB>  <TAB> ResultWrapper = NaiveQueryResultWrapper <MASK> ResultWrapper = AggregateQueryResultWrapper <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ResultWrapper = ModelQueryResultWrapper <TAB>  <TAB> self._qr = ResultWrapper(model_class, self._execute(), query_meta) <TAB>  <TAB> self._dirty = False <TAB>  <TAB> return self._qr <TAB> else: <TAB>  <TAB> return self._qr",elif self . _aggregate_rows :,198
2349,"def emitIpToDomainsData(self, data, event): <TAB> self.emitRawRirData(data, event) <TAB> domains = data.get(""domains"") <TAB> if isinstance(domains, list): <TAB>  <TAB> for domain in domains: <TAB>  <TAB>  <TAB> if self.checkForStop(): <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB>  <TAB> domain = domain.strip() <MASK> self.emitHostname(domain, event)",if domain :,105
2350,"def delete(self): <TAB> from weblate.trans.models import Change, Suggestion, Vote <TAB> fast_deletes = [] <TAB> for item in self.fast_deletes: <MASK> fast_deletes.append(Vote.objects.filter(suggestion__in=item)) <TAB>  <TAB>  <TAB> fast_deletes.append(Change.objects.filter(suggestion__in=item)) <TAB>  <TAB> fast_deletes.append(item) <TAB> self.fast_deletes = fast_deletes <TAB> return super().delete()",if item . model is Suggestion :,124
2351,"def token(self): <TAB> if not self._token: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> cookie_token = self.state[""request""].headers.cookie[CSRF_TOKEN].value <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> cookie_token = """" <MASK> self._token = cookie_token <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._token = get_random_string(TOKEN_LENGTH) <TAB> return self._token",if len ( cookie_token ) == TOKEN_LENGTH :,113
2352,"def get_logs(last_file=None, last_time=None): <TAB> try: <TAB>  <TAB> response = client.get_logs(last_file=last_file, last_time=last_time) <TAB>  <TAB> get_logs_streamer( <TAB>  <TAB>  <TAB> show_timestamp=not hide_time, <TAB>  <TAB>  <TAB> all_containers=all_containers, <TAB>  <TAB>  <TAB> all_info=all_info, <TAB>  <TAB> )(response) <TAB>  <TAB> return response <TAB> except (ApiException, HTTPError) as e: <MASK> handle_cli_error( <TAB>  <TAB>  <TAB>  <TAB> e, <TAB>  <TAB>  <TAB>  <TAB> message=""Could not get logs for run `{}`."".format(client.run_uuid), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> sys.exit(1)",if not follow :,179
2353,"def update(self, targets): <TAB> Section.update(self, targets) <TAB> outputNames = set() <TAB> for target in targets: <TAB>  <TAB> g = target.globals() <TAB>  <TAB> outputNames.update([k for k in g.keys() if k.startswith(""output:"")]) <TAB> rows = [] <TAB> outputNames = sorted(outputNames) <TAB> for outputName in outputNames: <TAB>  <TAB> row = self.__rows.get(outputName) <MASK> row = _OutputRow(outputName) <TAB>  <TAB>  <TAB> self.__rows[outputName] = row <TAB>  <TAB> row.update(targets) <TAB>  <TAB> row.setAlternate(len(rows) % 2) <TAB>  <TAB> rows.append(row) <TAB> self._mainColumn()[:] = rows",if row is None :,181
2354,"def getBranches(self): <TAB> returned = [] <TAB> for git_branch_line in self._executeGitCommandAssertSuccess(""branch"").stdout: <TAB>  <TAB> if git_branch_line.startswith(""*""): <TAB>  <TAB>  <TAB> git_branch_line = git_branch_line[1:] <TAB>  <TAB> git_branch_line = git_branch_line.strip() <MASK> alias_name, aliased = git_branch_line.split(BRANCH_ALIAS_MARKER) <TAB>  <TAB>  <TAB> returned.append(branch.LocalBranchAlias(self, alias_name, aliased)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> returned.append(branch.LocalBranch(self, git_branch_line)) <TAB> return returned",if BRANCH_ALIAS_MARKER in git_branch_line :,178
2355,"def has_bad_headers(self): <TAB> headers = [self.sender, self.reply_to] + self.recipients <TAB> for header in headers: <TAB>  <TAB> if _has_newline(header): <TAB>  <TAB>  <TAB> return True <TAB> if self.subject: <TAB>  <TAB> if _has_newline(self.subject): <TAB>  <TAB>  <TAB> for linenum, line in enumerate(self.subject.split(""\r\n"")): <TAB>  <TAB>  <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <MASK> return True <TAB>  <TAB>  <TAB>  <TAB> if _has_newline(line): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB>  <TAB> if len(line.strip()) == 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False","if linenum > 0 and line [ 0 ] not in ""\t "" :",186
2356,"def resolve_references(self, note, reflist): <TAB> assert len(note[""ids""]) == 1 <TAB> id = note[""ids""][0] <TAB> for ref in reflist: <MASK> continue <TAB>  <TAB> ref.delattr(""refname"") <TAB>  <TAB> ref[""refid""] = id <TAB>  <TAB> assert len(ref[""ids""]) == 1 <TAB>  <TAB> note.add_backref(ref[""ids""][0]) <TAB>  <TAB> ref.resolved = 1 <TAB> note.resolved = 1",if ref . resolved :,118
2357,"def pickPath(self, color): <TAB> self.path[color] = () <TAB> currentPos = self.starts[color] <TAB> while True: <TAB>  <TAB> minDist = None <TAB>  <TAB> minGuide = None <TAB>  <TAB> for guide in self.guides[color]: <TAB>  <TAB>  <TAB> guideDist = dist(currentPos, guide) <TAB>  <TAB>  <TAB> if minDist == None or guideDist < minDist: <TAB>  <TAB>  <TAB>  <TAB> minDist = guideDist <TAB>  <TAB>  <TAB>  <TAB> minGuide = guide <MASK> return <TAB>  <TAB> if minGuide == None: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> self.path[color] = self.path[color] + (minGuide,) <TAB>  <TAB> currentPos = minGuide <TAB>  <TAB> self.guides[color].remove(minGuide)","if dist ( currentPos , self . ends [ color ] ) == 1 :",192
2358,"def __hierarchyViewKeyPress(hierarchyView, event): <TAB> if event == __editSourceKeyPress: <TAB>  <TAB> selectedPath = __hierarchyViewSelectedPath(hierarchyView) <MASK> __editSourceNode( <TAB>  <TAB>  <TAB>  <TAB> hierarchyView.getContext(), hierarchyView.scene(), selectedPath <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return True <TAB> elif event == __editTweaksKeyPress: <TAB>  <TAB> selectedPath = __hierarchyViewSelectedPath(hierarchyView) <TAB>  <TAB> if selectedPath is not None: <TAB>  <TAB>  <TAB> __editTweaksNode( <TAB>  <TAB>  <TAB>  <TAB> hierarchyView.getContext(), hierarchyView.scene(), selectedPath <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return True",if selectedPath is not None :,173
2359,"def getSubsegments(self): <TAB> for num, localdata in self.lfh.LocalData: <TAB>  <TAB> for bucket, seginfo in localdata.SegmentInfo: <MASK> continue <TAB>  <TAB>  <TAB> yield Win32Subsegment(self.trace, self.heap, seginfo.ActiveSubsegment)",if seginfo . ActiveSubsegment == 0 :,84
2360,"def test_full_hd_bluray(self): <TAB> cur_test = ""full_hd_bluray"" <TAB> cur_qual = common.Quality.FULLHDBLURAY <TAB> for name, tests in iteritems(self.test_cases): <TAB>  <TAB> for test in tests: <MASK> self.assertEqual(cur_qual, common.Quality.name_quality(test)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.assertNotEqual(cur_qual, common.Quality.name_quality(test))",if name == cur_test :,135
2361,"def calc(self, arg): <TAB> op = arg[""op""] <TAB> if op == ""C"": <TAB>  <TAB> self.clear() <TAB>  <TAB> return str(self.current) <TAB> num = decimal.Decimal(arg[""num""]) <TAB> if self.op: <TAB>  <TAB> if self.op == ""+"": <TAB>  <TAB>  <TAB> self.current += num <TAB>  <TAB> elif self.op == ""-"": <TAB>  <TAB>  <TAB> self.current -= num <TAB>  <TAB> elif self.op == ""*"": <TAB>  <TAB>  <TAB> self.current *= num <MASK> self.current /= num <TAB>  <TAB> self.op = op <TAB> else: <TAB>  <TAB> self.op = op <TAB>  <TAB> self.current = num <TAB> res = str(self.current) <TAB> if op == ""="": <TAB>  <TAB> self.clear() <TAB> return res","elif self . op == ""/"" :",187
2362,"def strip_export_type(path): <TAB> matched = re.search(r""#([a-zA-Z0-9\-]+\\+[a-zA-Z0-9\-]+)?$"", path.encode(""utf-8"")) <TAB> mime_type = None <TAB> if matched: <TAB>  <TAB> fragment = matched.group(0) <TAB>  <TAB> mime_type = matched.group(1) <MASK> mime_type = mime_type.replace(""+"", ""/"") <TAB>  <TAB> path = path[: -len(fragment)] <TAB> return (path, mime_type)",if mime_type is not None :,137
2363,"def _save_as_module(file, data, binary=False): <TAB> if not data: <TAB>  <TAB> return <TAB> with open(file, ""w"") as f: <TAB>  <TAB> f.write(""DATA="") <MASK> f.write('""') <TAB>  <TAB>  <TAB> f.write(base64.b64encode(data).decode(""ascii"")) <TAB>  <TAB>  <TAB> f.write('""') <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> f.write(str(data).replace(""\\\\"", ""\\"")) <TAB>  <TAB> f.flush()",if binary :,120
2364,"def ProcessStringLiteral(self): <TAB> if self._lastToken == None or self._lastToken.type == self.OpenBrace: <TAB>  <TAB> text = super(JavaScriptBaseLexer, self).text <MASK> if len(self._scopeStrictModes) > 0: <TAB>  <TAB>  <TAB>  <TAB> self._scopeStrictModes.pop() <TAB>  <TAB>  <TAB> self._useStrictCurrent = True <TAB>  <TAB>  <TAB> self._scopeStrictModes.append(self._useStrictCurrent)","if text == '""use strict""' or text == ""'use strict'"" :",124
2365,"def run(self, ttl=None): <TAB> self.zeroconf = zeroconf.Zeroconf() <TAB> zeroconf.ServiceBrowser(self.zeroconf, self.domain, MDNSHandler(self)) <TAB> if ttl: <TAB>  <TAB> gobject.timeout_add(ttl * 1000, self.shutdown) <TAB> self.__running = True <TAB> self.__mainloop = gobject.MainLoop() <TAB> context = self.__mainloop.get_context() <TAB> while self.__running: <TAB>  <TAB> try: <MASK> context.iteration(True) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> time.sleep(0.1) <TAB>  <TAB> except KeyboardInterrupt: <TAB>  <TAB>  <TAB> break <TAB> self.zeroconf.close() <TAB> logger.debug(""MDNSListener.run() quit"")",if context . pending ( ) :,187
2366,"def topology_change_notify(self, port_state): <TAB> notice = False <TAB> if port_state is PORT_STATE_FORWARD: <TAB>  <TAB> for port in self.ports.values(): <TAB>  <TAB>  <TAB> if port.role is DESIGNATED_PORT: <TAB>  <TAB>  <TAB>  <TAB> notice = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> notice = True <TAB> if notice: <TAB>  <TAB> self.send_event(EventTopologyChange(self.dp)) <MASK> self._transmit_tc_bpdu() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._transmit_tcn_bpdu()",if self . is_root_bridge :,154
2367,def close_open_fds(keep=None):  # noqa <TAB> keep = [maybe_fileno(f) for f in (keep or []) if maybe_fileno(f) is not None] <TAB> for fd in reversed(range(get_fdmax(default=2048))): <TAB>  <TAB> if fd not in keep: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> os.close(fd) <TAB>  <TAB>  <TAB> except OSError as exc: <MASK> raise,if exc . errno != errno . EBADF :,120
2368,"def collect_attributes(options, node, master_list): <TAB> """"""Collect all attributes"""""" <TAB> for ii in node.instructions: <TAB>  <TAB> if field_check(ii, ""attributes""): <TAB>  <TAB>  <TAB> s = getattr(ii, ""attributes"") <TAB>  <TAB>  <TAB> if isinstance(s, list): <TAB>  <TAB>  <TAB>  <TAB> for x in s: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if x not in master_list: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> master_list.append(x) <MASK> master_list.append(s) <TAB> for nxt in node.next.values(): <TAB>  <TAB> collect_attributes(options, nxt, master_list)",elif s != None and s not in master_list :,161
2369,"def remove_test_run_directories(expiry_time: int = 60 * 60) -> int: <TAB> removed = 0 <TAB> directories = glob.glob(os.path.join(UUID_VAR_DIR, ""test-backend"", ""run_*"")) <TAB> for test_run in directories: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> shutil.rmtree(test_run) <TAB>  <TAB>  <TAB>  <TAB> removed += 1 <TAB>  <TAB>  <TAB> except FileNotFoundError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB> return removed",if round ( time . time ( ) ) - os . path . getmtime ( test_run ) > expiry_time :,136
2370,"def read_work_titles(fields): <TAB> found = [] <TAB> if ""240"" in fields: <TAB>  <TAB> for line in fields[""240""]: <TAB>  <TAB>  <TAB> title = join_subfield_values(line, [""a"", ""m"", ""n"", ""p"", ""r""]) <MASK> found.append(title) <TAB> if ""130"" in fields: <TAB>  <TAB> for line in fields[""130""]: <TAB>  <TAB>  <TAB> title = "" "".join(get_lower_subfields(line)) <TAB>  <TAB>  <TAB> if title not in found: <TAB>  <TAB>  <TAB>  <TAB> found.append(title) <TAB> return {""work_titles"": found} if found else {}",if title not in found :,157
2371,"def _process_v1_msg(prot, msg): <TAB> header = None <TAB> body = msg[1] <TAB> if not isinstance(body, (binary_type, mmap, memoryview)): <TAB>  <TAB> raise ValidationError(body, ""Body must be a bytestream."") <TAB> if len(msg) > 2: <TAB>  <TAB> header = msg[2] <MASK> raise ValidationError(header, ""Header must be a dict."") <TAB>  <TAB> for k, v in header.items(): <TAB>  <TAB>  <TAB> header[k] = msgpack.unpackb(v) <TAB> ctx = MessagePackMethodContext(prot, MessagePackMethodContext.SERVER) <TAB> ctx.in_string = [body] <TAB> ctx.transport.in_header = header <TAB> return ctx","if not isinstance ( header , dict ) :",177
2372,"def find(self, node): <TAB> typename = type(node).__name__ <TAB> method = getattr(self, ""find_{}"".format(typename), None) <TAB> if method is None: <TAB>  <TAB> fields = getattr(node, ""_fields"", None) <MASK> return <TAB>  <TAB> for field in fields: <TAB>  <TAB>  <TAB> value = getattr(node, field) <TAB>  <TAB>  <TAB> for result in self.find(value): <TAB>  <TAB>  <TAB>  <TAB> yield result <TAB> else: <TAB>  <TAB> for result in method(node): <TAB>  <TAB>  <TAB> yield result",if fields is None :,129
2373,"def _str_param_list(self, name): <TAB> out = [] <TAB> if self[name]: <TAB>  <TAB> out += self._str_header(name) <TAB>  <TAB> for param in self[name]: <TAB>  <TAB>  <TAB> parts = [] <MASK> parts.append(param.name) <TAB>  <TAB>  <TAB> if param.type: <TAB>  <TAB>  <TAB>  <TAB> parts.append(param.type) <TAB>  <TAB>  <TAB> out += ["" : "".join(parts)] <TAB>  <TAB>  <TAB> if param.desc and """".join(param.desc).strip(): <TAB>  <TAB>  <TAB>  <TAB> out += self._str_indent(param.desc) <TAB>  <TAB> out += [""""] <TAB> return out",if param . name :,157
2374,"def _get_image(self, image_list, source): <TAB> if source.startswith(""wx""): <TAB>  <TAB> img = wx.ArtProvider_GetBitmap(source, wx.ART_OTHER, _SIZE) <TAB> else: <TAB>  <TAB> path = os.path.join(_BASE, source) <MASK> img = wx.Image(path, wx.BITMAP_TYPE_GIF).ConvertToBitmap() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> img = wx.Image(path, wx.BITMAP_TYPE_PNG).ConvertToBitmap() <TAB> return image_list.Add(img)","if source . endswith ( ""gif"" ) :",144
2375,"def change_opacity_function(self, new_f): <TAB> self.opacity_function = new_f <TAB> dr = self.radius / self.num_levels <TAB> sectors = [] <TAB> for submob in self.submobjects: <MASK> sectors.append(submob) <TAB> for (r, submob) in zip(np.arange(0, self.radius, dr), sectors): <TAB>  <TAB> if type(submob) != AnnularSector: <TAB>  <TAB>  <TAB> # it's the shadow, don't dim it <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> alpha = self.opacity_function(r) <TAB>  <TAB> submob.set_fill(opacity=alpha)",if type ( submob ) == AnnularSector :,180
2376,"def _sqlite_post_configure_engine(url, engine, follower_ident): <TAB> from sqlalchemy import event <TAB> @event.listens_for(engine, ""connect"") <TAB> def connect(dbapi_connection, connection_record): <TAB>  <TAB> # use file DBs in all cases, memory acts kind of strangely <TAB>  <TAB> # as an attached <MASK> dbapi_connection.execute('ATTACH DATABASE ""test_schema.db"" AS test_schema') <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> dbapi_connection.execute( <TAB>  <TAB>  <TAB>  <TAB> 'ATTACH DATABASE ""%s_test_schema.db"" AS test_schema' % follower_ident <TAB>  <TAB>  <TAB> )",if not follower_ident :,164
2377,"def apply_conf_file(fn, conf_filename): <TAB> for env in LSF_CONF_ENV: <TAB>  <TAB> conf_file = get_conf_file(conf_filename, env) <TAB>  <TAB> if conf_file: <TAB>  <TAB>  <TAB> with open(conf_file) as conf_handle: <TAB>  <TAB>  <TAB>  <TAB> value = fn(conf_handle) <MASK> return value <TAB> return None",if value :,101
2378,"def test_call_extern_c_fn(self): <TAB> global memcmp <TAB> memcmp = cffi_support.ExternCFunction( <TAB>  <TAB> ""memcmp"", <TAB>  <TAB> (""int memcmp ( const uint8_t * ptr1, "" ""const uint8_t * ptr2, size_t num )""), <TAB> ) <TAB> @udf(BooleanVal(FunctionContext, StringVal, StringVal)) <TAB> def fn(context, a, b): <TAB>  <TAB> if a.is_null != b.is_null: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> if a is None: <TAB>  <TAB>  <TAB> return True <MASK> return False <TAB>  <TAB> if a.ptr == b.ptr: <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> return memcmp(a.ptr, b.ptr, a.len) == 0",if len ( a ) != b . len :,199
2379,"def _get_initialized_app(app): <TAB> """"""Returns a reference to an initialized App instance."""""" <TAB> if app is None: <TAB>  <TAB> return firebase_admin.get_app() <TAB> if isinstance(app, firebase_admin.App): <TAB>  <TAB> initialized_app = firebase_admin.get_app(app.name) <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Illegal app argument. App instance not "" <TAB>  <TAB>  <TAB>  <TAB> ""initialized via the firebase module."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return app <TAB> raise ValueError( <TAB>  <TAB> ""Illegal app argument. Argument must be of type "" <TAB>  <TAB> ' firebase_admin.App, but given ""{0}"".'.format(type(app)) <TAB> )",if app is not initialized_app :,177
2380,def compiled_query(self): <MASK> self.lazy_init_lock_.acquire() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if self.compiled_query_ is None: <TAB>  <TAB>  <TAB>  <TAB> self.compiled_query_ = CompiledQuery() <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self.lazy_init_lock_.release() <TAB> return self.compiled_query_,if self . compiled_query_ is None :,96
2381,"def clean_subevent(event, subevent): <TAB> if event.has_subevents: <MASK> raise ValidationError(_(""Subevent cannot be null for event series."")) <TAB>  <TAB> if event != subevent.event: <TAB>  <TAB>  <TAB> raise ValidationError(_(""The subevent does not belong to this event."")) <TAB> else: <TAB>  <TAB> if subevent: <TAB>  <TAB>  <TAB> raise ValidationError(_(""The subevent does not belong to this event.""))",if not subevent :,102
2382,"def get_blob_type_declaration_sql(self, column): <TAB> length = column.get(""length"") <TAB> if length: <TAB>  <TAB> if length <= self.LENGTH_LIMIT_TINYBLOB: <TAB>  <TAB>  <TAB> return ""TINYBLOB"" <TAB>  <TAB> if length <= self.LENGTH_LIMIT_BLOB: <TAB>  <TAB>  <TAB> return ""BLOB"" <MASK> return ""MEDIUMBLOB"" <TAB> return ""LONGBLOB""",if length <= self . LENGTH_LIMIT_MEDIUMBLOB :,115
2383,"def decompress(self, data): <TAB> if not data: <TAB>  <TAB> return data <TAB> if not self._first_try: <TAB>  <TAB> return self._obj.decompress(data) <TAB> self._data += data <TAB> try: <TAB>  <TAB> decompressed = self._obj.decompress(data) <MASK> self._first_try = False <TAB>  <TAB>  <TAB> self._data = None <TAB>  <TAB> return decompressed <TAB> except zlib.error: <TAB>  <TAB> self._first_try = False <TAB>  <TAB> self._obj = zlib.decompressobj(-zlib.MAX_WBITS) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self.decompress(self._data) <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self._data = None",if decompressed :,163
2384,"def _record_event(self, path, fsevent_handle, filename, events, error): <TAB> with self.lock: <TAB>  <TAB> self.events[path].append(events) <TAB>  <TAB> if events | pyuv.fs.UV_RENAME: <MASK> self.watches.pop(path).close()",if not os . path . exists ( path ) :,89
2385,"def __init__(self, duration, batch_shape, event_shape, validate_args=None): <TAB> if duration is None: <MASK> # Infer duration from event_shape. <TAB>  <TAB>  <TAB> duration = event_shape[0] <TAB> elif duration != event_shape[0]: <TAB>  <TAB> if event_shape[0] != 1: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""duration, event_shape mismatch: {} vs {}"".format(duration, event_shape) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> # Infer event_shape from duration. <TAB>  <TAB> event_shape = torch.Size((duration,) + event_shape[1:]) <TAB> self._duration = duration <TAB> super().__init__(batch_shape, event_shape, validate_args)",if event_shape [ 0 ] != 1 :,183
2386,"def _CheckPrerequisites(self): <TAB> """"""Exits if any of the prerequisites is not met."""""" <TAB> if not FLAGS.kubectl: <TAB>  <TAB> raise Exception( <TAB>  <TAB>  <TAB> ""Please provide path to kubectl tool using --kubectl "" ""flag. Exiting."" <TAB>  <TAB> ) <TAB> if not FLAGS.kubeconfig: <TAB>  <TAB> raise Exception( <TAB>  <TAB>  <TAB> ""Please provide path to kubeconfig using --kubeconfig "" ""flag. Exiting."" <TAB>  <TAB> ) <TAB> if self.disk_specs and self.disk_specs[0].disk_type == disk.STANDARD: <MASK> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> ""Please provide a list of Ceph Monitors using "" ""--ceph_monitors flag."" <TAB>  <TAB>  <TAB> )",if not FLAGS . ceph_monitors :,181
2387,"def invalidateDependentSlices(self, iFirstCurve): <TAB> # only user defined curve can have slice dependency relationships <TAB> if self.isSystemCurveIndex(iFirstCurve): <TAB>  <TAB> return <TAB> nCurves = self.getNCurves() <TAB> for i in range(iFirstCurve, nCurves): <TAB>  <TAB> c = self.getSystemCurve(i) <MASK> c.invalidate() <TAB>  <TAB> elif i == iFirstCurve: <TAB>  <TAB>  <TAB> # if first curve isn't a slice, <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> # there are no dependent slices","if isinstance ( c . getSymbol ( ) . getSymbolType ( ) , SymbolType . PieSliceSymbolType ) :",154
2388,"def find_backwards(self, offset): <TAB> try: <TAB>  <TAB> for _, token_type, token_value in reversed(self.tokens[self.offset : offset]): <TAB>  <TAB>  <TAB> if token_type in (""comment"", ""linecomment""): <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> prefix, comment = token_value.split(None, 1) <TAB>  <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> return [comment.rstrip()] <TAB>  <TAB> return [] <TAB> finally: <TAB>  <TAB> self.offset = offset",if prefix in self . comment_tags :,140
2389,"def parse_column_definitions(self, elem): <TAB> for column_elem in elem.findall(""column""): <TAB>  <TAB> name = column_elem.get(""name"", None) <TAB>  <TAB> assert name is not None, ""Required 'name' attribute missing from column def"" <TAB>  <TAB> index = column_elem.get(""index"", None) <TAB>  <TAB> assert index is not None, ""Required 'index' attribute missing from column def"" <TAB>  <TAB> index = int(index) <TAB>  <TAB> self.columns[name] = index <MASK> self.largest_index = index <TAB> assert ""value"" in self.columns, ""Required 'value' column missing from column def"" <TAB> if ""name"" not in self.columns: <TAB>  <TAB> self.columns[""name""] = self.columns[""value""]",if index > self . largest_index :,188
2390,"def __find_smallest(self): <TAB> """"""Find the smallest uncovered value in the matrix."""""" <TAB> minval = sys.maxsize <TAB> for i in range(self.n): <TAB>  <TAB> for j in range(self.n): <TAB>  <TAB>  <TAB> if (not self.row_covered[i]) and (not self.col_covered[j]): <MASK> minval = self.C[i][j] <TAB> return minval",if minval > self . C [ i ] [ j ] :,114
2391,"def includes_tools_for_display_in_tool_panel(self): <TAB> if self.includes_tools: <TAB>  <TAB> tool_dicts = self.metadata[""tools""] <TAB>  <TAB> for tool_dict in tool_dicts: <MASK> return True <TAB> return False","if tool_dict . get ( ""add_to_tool_panel"" , True ) :",84
2392,"def commit(self, notify=False): <TAB> if self.editing: <TAB>  <TAB> text = self._text <TAB>  <TAB> if text: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> value = self.type(text) <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> value = self.clamp_value(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = self.empty <TAB>  <TAB>  <TAB> if value is NotImplemented: <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> self.value = value <TAB>  <TAB> self.insertion_point = None <MASK> self.change_text(unicode(value)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._text = unicode(value) <TAB>  <TAB> self.editing = False <TAB> else: <TAB>  <TAB> self.insertion_point = None",if notify :,183
2393,"def GeneratePageMetatadata(self, task): <TAB> address_space = self.session.GetParameter(""default_address_space"") <TAB> for vma in task.mm.mmap.walk_list(""vm_next""): <TAB>  <TAB> start = vma.vm_start <TAB>  <TAB> end = vma.vm_end <TAB>  <TAB> # Skip the entire region. <TAB>  <TAB> if end < self.plugin_args.start: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # Done. <MASK> break <TAB>  <TAB> for vaddr in utils.xrange(start, end, 0x1000): <TAB>  <TAB>  <TAB> if self.plugin_args.start <= vaddr <= self.plugin_args.end: <TAB>  <TAB>  <TAB>  <TAB> yield vaddr, self._CreateMetadata(address_space.describe_vtop(vaddr))",if start > self . plugin_args . end :,195
2394,"def _check_for_duplicate_host_entries(self, task_entries): <TAB> non_host_statuses = ( <TAB>  <TAB> models.HostQueueEntry.Status.PARSING, <TAB>  <TAB> models.HostQueueEntry.Status.ARCHIVING, <TAB> ) <TAB> for task_entry in task_entries: <TAB>  <TAB> using_host = ( <TAB>  <TAB>  <TAB> task_entry.host is not None and task_entry.status not in non_host_statuses <TAB>  <TAB> ) <MASK> self._assert_host_has_no_agent(task_entry)",if using_host :,136
2395,"def get_biggest_wall_time(jsons): <TAB> lowest_wall = None <TAB> for j in jsons: <MASK> lowest_wall = j[""wall_time""] <TAB>  <TAB> if lowest_wall < j[""wall_time""]: <TAB>  <TAB>  <TAB> lowest_wall = j[""wall_time""] <TAB> return lowest_wall",if lowest_wall is None :,87
2396,"def log_change_report(self, old_value, new_value, include_details=False): <TAB> from octoprint.util import map_boolean <TAB> with self._check_mutex: <TAB>  <TAB> self._logger.info( <TAB>  <TAB>  <TAB> ""Connectivity changed from {} to {}"".format( <TAB>  <TAB>  <TAB>  <TAB> map_boolean(old_value, ""online"", ""offline""), <TAB>  <TAB>  <TAB>  <TAB> map_boolean(new_value, ""online"", ""offline""), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <MASK> self.log_details()",if include_details :,136
2397,"def _include_block(self, value, context=None): <TAB> if hasattr(value, ""render_as_block""): <MASK> new_context = context.get_all() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_context = {} <TAB>  <TAB> return jinja2.Markup(value.render_as_block(context=new_context)) <TAB> return jinja2.Markup(value)",if context :,96
2398,"def __lt__(self, other): <TAB> # 0: clock 1: timestamp 3: process id <TAB> try: <TAB>  <TAB> A, B = self[0], other[0] <TAB>  <TAB> # uses logical clock value first <TAB>  <TAB> if A and B:  # use logical clock if available <MASK> # equal clocks use lower process id <TAB>  <TAB>  <TAB>  <TAB> return self[2] < other[2] <TAB>  <TAB>  <TAB> return A < B <TAB>  <TAB> return self[1] < other[1]  # ... or use timestamp <TAB> except IndexError: <TAB>  <TAB> return NotImplemented",if A == B :,135
2399,"def _get_port(): <TAB> while True: <TAB>  <TAB> port = 20000 + random.randint(1, 9999) <TAB>  <TAB> for i in range(5): <TAB>  <TAB>  <TAB> sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) <TAB>  <TAB>  <TAB> result = sock.connect_ex((""127.0.0.1"", port)) <MASK> continue <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return port",if result == 0 :,107
2400,"def fetch_all(self, api_client, fetchstatuslogger, q, targets): <TAB> self.fetchstatuslogger = fetchstatuslogger <TAB> if targets != None: <TAB>  <TAB> # Ensure targets is a tuple <TAB>  <TAB> if type(targets) != list and type(targets) != tuple: <TAB>  <TAB>  <TAB> targets = tuple( <TAB>  <TAB>  <TAB>  <TAB> targets, <TAB>  <TAB>  <TAB> ) <MASK> targets = tuple(targets) <TAB> for target in targets: <TAB>  <TAB> self._fetch_targets(api_client, q, target)",elif type ( targets ) != tuple :,130
2401,"def migrate_node_facts(facts): <TAB> """"""Migrate facts from various roles into node"""""" <TAB> params = { <TAB>  <TAB> ""common"": (""dns_ip""), <TAB> } <TAB> if ""node"" not in facts: <TAB>  <TAB> facts[""node""] = {} <TAB> # pylint: disable=consider-iterating-dictionary <TAB> for role in params.keys(): <MASK> for param in params[role]: <TAB>  <TAB>  <TAB>  <TAB> if param in facts[role]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> facts[""node""][param] = facts[role].pop(param) <TAB> return facts",if role in facts :,136
2402,"def build_dimension_param(self, dimension, params): <TAB> prefix = ""Dimensions.member"" <TAB> i = 0 <TAB> for dim_name in dimension: <TAB>  <TAB> dim_value = dimension[dim_name] <MASK> if isinstance(dim_value, six.string_types): <TAB>  <TAB>  <TAB>  <TAB> dim_value = [dim_value] <TAB>  <TAB>  <TAB> for value in dim_value: <TAB>  <TAB>  <TAB>  <TAB> params[""%s.%d.Name"" % (prefix, i + 1)] = dim_name <TAB>  <TAB>  <TAB>  <TAB> params[""%s.%d.Value"" % (prefix, i + 1)] = value <TAB>  <TAB>  <TAB>  <TAB> i += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> params[""%s.%d.Name"" % (prefix, i + 1)] = dim_name <TAB>  <TAB>  <TAB> i += 1",if dim_value :,192
2403,"def add_if_unique(self, issuer, use, keys): <TAB> if use in self.issuer_keys[issuer] and self.issuer_keys[issuer][use]: <TAB>  <TAB> for typ, key in keys: <TAB>  <TAB>  <TAB> flag = 1 <TAB>  <TAB>  <TAB> for _typ, _key in self.issuer_keys[issuer][use]: <MASK> flag = 0 <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> if flag: <TAB>  <TAB>  <TAB>  <TAB> self.issuer_keys[issuer][use].append((typ, key)) <TAB> else: <TAB>  <TAB> self.issuer_keys[issuer][use] = keys",if _typ == typ and key is _key :,158
2404,"def run(self): <TAB> while True: <TAB>  <TAB> message = self.in_queue.get() <MASK> self.reset() <TAB>  <TAB> elif message == EXIT: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> index, transaction = message <TAB>  <TAB>  <TAB> self.results_queue.put((index, self.validate(transaction)))",if message == RESET :,89
2405,"def __run(self): <TAB> threads = self.parameters()[""threads""].getTypedValue() <TAB> with IECore.tbb_global_control( <TAB>  <TAB> IECore.tbb_global_control.parameter.max_allowed_parallelism, <TAB>  <TAB> IECore.hardwareConcurrency() if threads == 0 else threads, <TAB> ): <TAB>  <TAB> self._executeStartupFiles(self.root().getName()) <TAB>  <TAB> # Append DEBUG message with process information to all messages <TAB>  <TAB> defaultMessageHandler = IECore.MessageHandler.getDefaultHandler() <MASK> IECore.MessageHandler.setDefaultHandler( <TAB>  <TAB>  <TAB>  <TAB> Gaffer.ProcessMessageHandler(defaultMessageHandler) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return self._run(self.parameters().getValidatedValue())","if not isinstance ( defaultMessageHandler , Gaffer . ProcessMessageHandler ) :",194
2406,"def adjust_uri(self, uri, relativeto): <TAB> """"""Adjust the given ``uri`` based on the given relative URI."""""" <TAB> key = (uri, relativeto) <TAB> if key in self._uri_cache: <TAB>  <TAB> return self._uri_cache[key] <TAB> if uri[0] != ""/"": <MASK> v = self._uri_cache[key] = posixpath.join( <TAB>  <TAB>  <TAB>  <TAB> posixpath.dirname(relativeto), uri <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> v = self._uri_cache[key] = ""/"" + uri <TAB> else: <TAB>  <TAB> v = self._uri_cache[key] = uri <TAB> return v",if relativeto is not None :,164
2407,"def decoder(s): <TAB> r = [] <TAB> decode = [] <TAB> for c in s: <MASK> decode.append(""&"") <TAB>  <TAB> elif c == ""-"" and decode: <TAB>  <TAB>  <TAB> if len(decode) == 1: <TAB>  <TAB>  <TAB>  <TAB> r.append(""&"") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> r.append(modified_unbase64("""".join(decode[1:]))) <TAB>  <TAB>  <TAB> decode = [] <TAB>  <TAB> elif decode: <TAB>  <TAB>  <TAB> decode.append(c) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> r.append(c) <TAB> if decode: <TAB>  <TAB> r.append(modified_unbase64("""".join(decode[1:]))) <TAB> bin_str = """".join(r) <TAB> return (bin_str, len(s))","if c == ""&"" and not decode :",188
2408,"def _process_file(self, content): <TAB> args = [] <TAB> for line in content.splitlines(): <TAB>  <TAB> line = line.strip() <TAB>  <TAB> if line.startswith(""-""): <TAB>  <TAB>  <TAB> args.extend(self._split_option(line)) <MASK> args.append(line) <TAB> return args","elif line and not line . startswith ( ""#"" ) :",83
2409,"def _method_events_callback(self, values): <TAB> try: <TAB>  <TAB> previous_echoed = ( <TAB>  <TAB>  <TAB> values[""child_result_list""][-1].decode().split(""\n"")[-2].strip() <TAB>  <TAB> ) <TAB>  <TAB> if previous_echoed.endswith(""foo1""): <TAB>  <TAB>  <TAB> return ""echo foo2\n"" <TAB>  <TAB> elif previous_echoed.endswith(""foo2""): <TAB>  <TAB>  <TAB> return ""echo foo3\n"" <MASK> return ""exit\n"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception(""Unexpected output {0!r}"".format(previous_echoed)) <TAB> except IndexError: <TAB>  <TAB> return ""echo foo1\n""","elif previous_echoed . endswith ( ""foo3"" ) :",172
2410,"def __delete_hook(self, rpc): <TAB> try: <TAB>  <TAB> rpc.check_success() <TAB> except apiproxy_errors.Error: <TAB>  <TAB> return None <TAB> result = [] <TAB> for status in rpc.response.delete_status_list(): <MASK> result.append(DELETE_SUCCESSFUL) <TAB>  <TAB> elif status == MemcacheDeleteResponse.NOT_FOUND: <TAB>  <TAB>  <TAB> result.append(DELETE_ITEM_MISSING) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result.append(DELETE_NETWORK_FAILURE) <TAB> return result",if status == MemcacheDeleteResponse . DELETED :,139
2411,"def __createRandom(plug): <TAB> node = plug.node() <TAB> parentNode = node.ancestor(Gaffer.Node) <TAB> with Gaffer.UndoScope(node.scriptNode()): <TAB>  <TAB> randomNode = Gaffer.Random() <TAB>  <TAB> parentNode.addChild(randomNode) <MASK> plug.setInput(randomNode[""outFloat""]) <TAB>  <TAB> elif isinstance(plug, Gaffer.Color3fPlug): <TAB>  <TAB>  <TAB> plug.setInput(randomNode[""outColor""]) <TAB> GafferUI.NodeEditor.acquire(randomNode)","if isinstance ( plug , ( Gaffer . FloatPlug , Gaffer . IntPlug ) ) :",158
2412,"def escapeentities(self, line): <TAB> ""Escape all Unicode characters to HTML entities."" <TAB> result = """" <TAB> pos = TextPosition(line) <TAB> while not pos.finished(): <TAB>  <TAB> if ord(pos.current()) > 128: <TAB>  <TAB>  <TAB> codepoint = hex(ord(pos.current())) <MASK> codepoint = hex(ord(pos.next()) + 0xF800) <TAB>  <TAB>  <TAB> result += ""&#"" + codepoint[1:] + "";"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result += pos.current() <TAB>  <TAB> pos.skipcurrent() <TAB> return result","if codepoint == ""0xd835"" :",143
2413,def get_and_set_all_aliases(self): <TAB> all_aliases = [] <TAB> for page in self.pages: <MASK> all_aliases.extend(page.relations.aliases_norm) <TAB>  <TAB> if page.relations.aliases is not None: <TAB>  <TAB>  <TAB> all_aliases.extend(page.relations.aliases) <TAB> return set(all_aliases),if page . relations . aliases_norm is not None :,101
2414,"def _list_cases(suite): <TAB> for test in suite: <MASK> _list_cases(test) <TAB>  <TAB> elif isinstance(test, unittest.TestCase): <TAB>  <TAB>  <TAB> if support.match_test(test): <TAB>  <TAB>  <TAB>  <TAB> print(test.id())","if isinstance ( test , unittest . TestSuite ) :",75
2415,"def get_next_requests(self, max_n_requests, **kwargs): <TAB> next_pages = [] <TAB> partitions = set(kwargs.pop(""partitions"", [])) <TAB> for partition_id in range(0, self.queue_partitions): <MASK> continue <TAB>  <TAB> results = self.queue.get_next_requests(max_n_requests, partition_id) <TAB>  <TAB> next_pages.extend(results) <TAB>  <TAB> self.logger.debug( <TAB>  <TAB>  <TAB> ""Got %d requests for partition id %d"", len(results), partition_id <TAB>  <TAB> ) <TAB> return next_pages",if partition_id not in partitions :,149
2416,"def __iter__(self): <TAB> if (self.query is not None) and sqlite.is_read_only_query(self.query): <TAB>  <TAB> cur = self.connection.cursor() <TAB>  <TAB> results = cur.execute(self.query) <MASK> yield [col[0] for col in cur.description] <TAB>  <TAB> for i, row in enumerate(results): <TAB>  <TAB>  <TAB> if i >= self.limit: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> yield [val for val in row] <TAB> else: <TAB>  <TAB> yield",if self . headers :,131
2417,"def rollback(self): <TAB> for operation, values in self.current_transaction_state[::-1]: <TAB>  <TAB> if operation == ""insert"": <TAB>  <TAB>  <TAB> values.remove() <MASK> old_value, new_value = values <TAB>  <TAB>  <TAB> if new_value.full_filename != old_value.full_filename: <TAB>  <TAB>  <TAB>  <TAB> os.unlink(new_value.full_filename) <TAB>  <TAB>  <TAB> old_value.write() <TAB> self._post_xact_cleanup()","elif operation == ""update"" :",121
2418,"def index(self, value): <TAB> if self._growing: <TAB>  <TAB> if self._start <= value < self._stop: <TAB>  <TAB>  <TAB> q, r = divmod(value - self._start, self._step) <MASK> return int(q) <TAB> else: <TAB>  <TAB> if self._start >= value > self._stop: <TAB>  <TAB>  <TAB> q, r = divmod(self._start - value, -self._step) <TAB>  <TAB>  <TAB> if r == self._zero: <TAB>  <TAB>  <TAB>  <TAB> return int(q) <TAB> raise ValueError(""{} is not in numeric range"".format(value))",if r == self . _zero :,146
2419,"def validate_name_and_description(body, check_length=True): <TAB> for attribute in [""name"", ""description"", ""display_name"", ""display_description""]: <TAB>  <TAB> value = body.get(attribute) <MASK> if isinstance(value, six.string_types): <TAB>  <TAB>  <TAB>  <TAB> body[attribute] = value.strip() <TAB>  <TAB>  <TAB> if check_length: <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> utils.check_string_length( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> body[attribute], attribute, min_length=0, max_length=255 <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> except exception.InvalidInput as error: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise webob.exc.HTTPBadRequest(explanation=error.msg)",if value is not None :,184
2420,"def printWiki(): <TAB> firstHeading = False <TAB> for m in protocol: <TAB>  <TAB> if m[0] == """": <MASK> output(""|}"") <TAB>  <TAB>  <TAB> __printWikiHeader(m[1], m[2]) <TAB>  <TAB>  <TAB> firstHeading = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> output(""|-"") <TAB>  <TAB>  <TAB> output( <TAB>  <TAB>  <TAB>  <TAB> '| <span style=""white-space:nowrap;""><tt>' <TAB>  <TAB>  <TAB>  <TAB> + m[0] <TAB>  <TAB>  <TAB>  <TAB> + ""</tt></span> || || "" <TAB>  <TAB>  <TAB>  <TAB> + m[1] <TAB>  <TAB>  <TAB> ) <TAB> output(""|}"")",if firstHeading :,155
2421,"def _get_platforms(data): <TAB> platform_list = [] <TAB> for item in data: <TAB>  <TAB> if item.startswith(""PlatformEdit.html?""): <TAB>  <TAB>  <TAB> parameter_list = item.split(""PlatformEdit.html?"", 1)[1].split(""&"") <TAB>  <TAB>  <TAB> for parameter in parameter_list: <MASK> platform_list.append(parameter.split(""="")[1]) <TAB> return platform_list","if parameter . startswith ( ""platformName"" ) :",110
2422,"def find_scintilla_constants(f): <TAB> lexers = [] <TAB> states = [] <TAB> for name in f.order: <TAB>  <TAB> v = f.features[name] <TAB>  <TAB> if v[""Category""] != ""Deprecated"": <TAB>  <TAB>  <TAB> if v[""FeatureType""] == ""val"": <MASK> states.append((name, v[""Value""])) <TAB>  <TAB>  <TAB>  <TAB> elif name.startswith(""SCLEX_""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> lexers.append((name, v[""Value""])) <TAB> return (lexers, states)","if name . startswith ( ""SCE_"" ) :",137
2423,"def get_operation_ast(document_ast, operation_name=None): <TAB> operation = None <TAB> for definition in document_ast.definitions: <TAB>  <TAB> if isinstance(definition, ast.OperationDefinition): <MASK> # If no operation name is provided, only return an Operation if it is the only one present in the <TAB>  <TAB>  <TAB>  <TAB> # document. This means that if we've encountered a second operation as we were iterating over the <TAB>  <TAB>  <TAB>  <TAB> # definitions in the document, there are more than one Operation defined, and we should return None. <TAB>  <TAB>  <TAB>  <TAB> if operation: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB>  <TAB>  <TAB> operation = definition <TAB>  <TAB>  <TAB> elif definition.name and definition.name.value == operation_name: <TAB>  <TAB>  <TAB>  <TAB> return definition <TAB> return operation",if not operation_name :,186
2424,"def _insertNewItemAtParent(self, targetIndex): <TAB> if not self.isContainer(targetIndex): <TAB>  <TAB> return <TAB> elif not self.isContainerOpen(targetIndex): <TAB>  <TAB> uri = self._rows[targetIndex].uri <TAB>  <TAB> modelNode = self.getNodeForURI(uri) <MASK> modelNode.markForRefreshing() <TAB>  <TAB> return <TAB> self.refreshView(targetIndex)",if modelNode :,103
2425,"def _get_trace(self, model, guide, args, kwargs): <TAB> model_trace, guide_trace = super()._get_trace(model, guide, args, kwargs) <TAB> # Mark all sample sites with require_backward to gather enumerated <TAB> # sites and adjust cond_indep_stack of all sample sites. <TAB> for node in model_trace.nodes.values(): <MASK> log_prob = node[""packed""][""unscaled_log_prob""] <TAB>  <TAB>  <TAB> require_backward(log_prob) <TAB> self._saved_state = model, model_trace, guide_trace, args, kwargs <TAB> return model_trace, guide_trace","if node [ ""type"" ] == ""sample"" and not node [ ""is_observed"" ] :",166
2426,"def _url_encode_impl(obj, charset, encode_keys, sort, key): <TAB> from .datastructures import iter_multi_items <TAB> iterable = iter_multi_items(obj) <TAB> if sort: <TAB>  <TAB> iterable = sorted(iterable, key=key) <TAB> for key, value in iterable: <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if not isinstance(key, bytes): <TAB>  <TAB>  <TAB> key = text_type(key).encode(charset) <MASK> value = text_type(value).encode(charset) <TAB>  <TAB> yield _fast_url_quote_plus(key) + ""="" + _fast_url_quote_plus(value)","if not isinstance ( value , bytes ) :",168
2427,"def handle_parse_result(self, ctx, opts, args): <TAB> with augment_usage_errors(ctx, param=self): <TAB>  <TAB> value = self.consume_value(ctx, opts) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> value = self.full_process_value(ctx, value) <TAB>  <TAB> except Exception: <MASK> raise <TAB>  <TAB>  <TAB> value = None <TAB>  <TAB> if self.callback is not None: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> value = invoke_param_callback(self.callback, ctx, self, value) <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> if not ctx.resilient_parsing: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise <TAB> if self.expose_value: <TAB>  <TAB> ctx.params[self.name] = value <TAB> return value, args",if not ctx . resilient_parsing :,195
2428,"def word_pattern(pattern, str): <TAB> dict = {} <TAB> set_value = set() <TAB> list_str = str.split() <TAB> if len(list_str) != len(pattern): <TAB>  <TAB> return False <TAB> for i in range(len(pattern)): <TAB>  <TAB> if pattern[i] not in dict: <MASK> return False <TAB>  <TAB>  <TAB> dict[pattern[i]] = list_str[i] <TAB>  <TAB>  <TAB> set_value.add(list_str[i]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if dict[pattern[i]] != list_str[i]: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return True",if list_str [ i ] in set_value :,165
2429,"def create(self, path, wipe=False): <TAB> # type: (Text, bool) -> bool <TAB> _path = self.validatepath(path) <TAB> with ftp_errors(self, path): <MASK> empty_file = io.BytesIO() <TAB>  <TAB>  <TAB> self.ftp.storbinary( <TAB>  <TAB>  <TAB>  <TAB> str(""STOR "") + _encode(_path, self.ftp.encoding), empty_file <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return True <TAB> return False",if wipe or not self . isfile ( path ) :,124
2430,"def build_output_for_item(self, item): <TAB> output = [] <TAB> for field in self.fields: <TAB>  <TAB> values = self._get_item(item, field) <MASK> values = [values] <TAB>  <TAB> for value in values: <TAB>  <TAB>  <TAB> if value: <TAB>  <TAB>  <TAB>  <TAB> output.append(self.build_output_for_single_value(value)) <TAB> return """".join(output)","if not isinstance ( values , list ) :",109
2431,"def get_resource_public_actions(resource_class): <TAB> resource_class_members = inspect.getmembers(resource_class) <TAB> resource_methods = {} <TAB> for name, member in resource_class_members: <TAB>  <TAB> if not name.startswith(""_""): <TAB>  <TAB>  <TAB> if not name[0].isupper(): <MASK> if is_resource_action(member): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> resource_methods[name] = member <TAB> return resource_methods","if not name . startswith ( ""wait_until"" ) :",122
2432,"def get_command(cls): <TAB> ifconfig_cmd = ""ifconfig"" <TAB> for path in [""/sbin"", ""/usr/sbin"", ""/bin"", ""/usr/bin""]: <MASK> ifconfig_cmd = os.path.join(path, ifconfig_cmd) <TAB>  <TAB>  <TAB> break <TAB> ifconfig_cmd = ifconfig_cmd + "" -a"" <TAB> return ifconfig_cmd","if os . path . exists ( os . path . join ( path , ifconfig_cmd ) ) :",109
2433,"def main(): <TAB> base_dir = os.path.join(os.path.split(__file__)[0], "".."", "".."") <TAB> for path in PATHS: <TAB>  <TAB> path = os.path.join(base_dir, path) <TAB>  <TAB> for root, _, files in os.walk(path): <TAB>  <TAB>  <TAB> for file in files: <TAB>  <TAB>  <TAB>  <TAB> extension = os.path.splitext(file)[1] <MASK> path = os.path.join(root, file) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> validate_header(path)",if extension in EXTENSIONS :,137
2434,"def auth_login(request): <TAB> form = RegistrationForm(request.POST or None) <TAB> if form.is_valid(): <TAB>  <TAB> authed_user = authenticate( <TAB>  <TAB>  <TAB> username=form.cleaned_data[""username""], <TAB>  <TAB>  <TAB> password=form.cleaned_data[""password""], <TAB>  <TAB> ) <MASK> login(request, authed_user) <TAB>  <TAB>  <TAB> return HttpResponse(""Success"") <TAB> raise Http404",if authed_user :,110
2435,"def set(self, _key, _new_login=True): <TAB> with self.lock: <TAB>  <TAB> user = self.users.get(current_user.id, None) <TAB>  <TAB> if user is None: <TAB>  <TAB>  <TAB> self.users[current_user.id] = dict(session_count=1, key=_key) <TAB>  <TAB> else: <MASK> user[""session_count""] += 1 <TAB>  <TAB>  <TAB> user[""key""] = _key",if _new_login :,116
2436,"def fetch(self, fingerprints): <TAB> to_fetch = [f for f in fingerprints if f not in self._cache] <TAB> self._logger.debug(""cache size %s"" % len(self._cache)) <TAB> self._logger.debug(""to fetch %d from %d"" % (len(to_fetch), len(fingerprints))) <TAB> [self._redis_pipeline.hgetall(key) for key in to_fetch] <TAB> responses = self._redis_pipeline.execute() <TAB> for index, key in enumerate(to_fetch): <TAB>  <TAB> response = responses[index] <MASK> self._cache[key] = response[FIELD_STATE] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._cache[key] = self.NOT_CRAWLED",if len ( response ) > 0 and FIELD_STATE in response :,187
2437,"def _append_to_io_queue(self, data, stream_name): <TAB> # Make sure ANSI CSI codes and object links are stored as separate events <TAB> # TODO: try to complete previously submitted incomplete code <TAB> parts = re.split(OUTPUT_SPLIT_REGEX, data) <TAB> for part in parts: <TAB>  <TAB> if part:  # split may produce empty string in the beginning or start <TAB>  <TAB>  <TAB> # split the data so that very long lines separated <TAB>  <TAB>  <TAB> for block in re.split( <TAB>  <TAB>  <TAB>  <TAB> ""(.{%d,})"" % (self._get_squeeze_threshold() + 1), part <TAB>  <TAB>  <TAB> ): <MASK> self._queued_io_events.append((block, stream_name))",if block :,174
2438,"def find_file_at_path_with_indexes(self, path, url): <TAB> if url.endswith(""/""): <TAB>  <TAB> path = os.path.join(path, self.index_file) <TAB>  <TAB> return self.get_static_file(path, url) <TAB> elif url.endswith(""/"" + self.index_file): <MASK> return self.redirect(url, url[: -len(self.index_file)]) <TAB> else: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self.get_static_file(path, url) <TAB>  <TAB> except IsDirectoryError: <TAB>  <TAB>  <TAB> if os.path.isfile(os.path.join(path, self.index_file)): <TAB>  <TAB>  <TAB>  <TAB> return self.redirect(url, url + ""/"") <TAB> raise MissingFileError(path)",if os . path . isfile ( path ) :,193
2439,"def module_list(target, fast): <TAB> """"""Find the list of modules to be compiled"""""" <TAB> modules = [] <TAB> native = native_modules(target) <TAB> basedir = os.path.join(ouroboros_repo_folder(), ""ouroboros"") <TAB> for name in os.listdir(basedir): <TAB>  <TAB> module_name, ext = os.path.splitext(name) <TAB>  <TAB> if ext == "".py"" or ext == """" and os.path.isdir(os.path.join(basedir, name)): <TAB>  <TAB>  <TAB> if module_name not in IGNORE_MODULES and module_name not in native: <MASK> modules.append(module_name) <TAB> return set(modules)",if not ( fast and module_name in KNOWN_PROBLEM_MODULES ) :,185
2440,"def housenumber(self): <TAB> if self.address: <TAB>  <TAB> expression = r""\d+"" <TAB>  <TAB> pattern = re.compile(expression) <TAB>  <TAB> match = pattern.search(self.address) <MASK> return int(match.group(0))",if match :,67
2441,"def get_pip_version(import_path=BASE_IMPORT_PATH): <TAB> try: <TAB>  <TAB> pip = importlib.import_module(import_path) <TAB> except ImportError: <MASK> return get_pip_version(import_path=""pip"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> import subprocess <TAB>  <TAB>  <TAB> version = subprocess.check_output([""pip"", ""--version""]) <TAB>  <TAB>  <TAB> if version: <TAB>  <TAB>  <TAB>  <TAB> version = version.decode(""utf-8"").split()[1] <TAB>  <TAB>  <TAB>  <TAB> return version <TAB>  <TAB>  <TAB> return ""0.0.0"" <TAB> version = getattr(pip, ""__version__"", None) <TAB> return version","if import_path != ""pip"" :",160
2442,"def __animate_progress(self): <TAB> """"""Change the status message, mostly used to animate progress."""""" <TAB> while True: <TAB>  <TAB> sleep_time = ThreadPool.PROGRESS_IDLE_DELAY <TAB>  <TAB> with self.__progress_lock: <TAB>  <TAB>  <TAB> if not self.__progress_status: <TAB>  <TAB>  <TAB>  <TAB> sleep_time = ThreadPool.PROGRESS_IDLE_DELAY <MASK> self.__progress_status.update_progress(self.__current_operation_name) <TAB>  <TAB>  <TAB>  <TAB> sleep_time = ThreadPool.PROGRESS_UPDATE_DELAY <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.__progress_status.show_as_ready() <TAB>  <TAB>  <TAB>  <TAB> sleep_time = ThreadPool.PROGRESS_IDLE_DELAY <TAB>  <TAB> # Allow some time for progress status to be updated. <TAB>  <TAB> time.sleep(sleep_time)",elif self . __show_animation :,195
2443,"def range_key_names(self): <TAB> keys = [self.range_key_attr] <TAB> for index in self.global_indexes: <TAB>  <TAB> range_key = None <TAB>  <TAB> for key in index.schema: <MASK> range_key = keys.append(key[""AttributeName""]) <TAB>  <TAB> keys.append(range_key) <TAB> return keys","if key [ ""KeyType"" ] == ""RANGE"" :",99
2444,"def run(self): <TAB> dist = self.distribution <TAB> commands = dist.command_options.keys() <TAB> settings = {} <TAB> for cmd in commands: <TAB>  <TAB> if cmd == ""saveopts"": <TAB>  <TAB>  <TAB> continue  # don't save our own options! <TAB>  <TAB> for opt, (src, val) in dist.get_option_dict(cmd).items(): <MASK> settings.setdefault(cmd, {})[opt] = val <TAB> edit_config(self.filename, settings, self.dry_run)","if src == ""command line"" :",131
2445,"def parse_move(self, node): <TAB> old, new = """", """" <TAB> for child in node: <TAB>  <TAB> tag, text = child.tag, child.text <TAB>  <TAB> text = text.strip() if text else None <TAB>  <TAB> if tag == ""Old"" and text: <TAB>  <TAB>  <TAB> old = text <MASK> new = text <TAB> return Move(old, new)","elif tag == ""New"" and text :",99
2446,"def __codeanalysis_settings_changed(self, current_finfo): <TAB> if self.data: <TAB>  <TAB> run_pyflakes, run_pep8 = self.pyflakes_enabled, self.pep8_enabled <TAB>  <TAB> for finfo in self.data: <TAB>  <TAB>  <TAB> self.__update_editor_margins(finfo.editor) <TAB>  <TAB>  <TAB> finfo.cleanup_analysis_results() <TAB>  <TAB>  <TAB> if (run_pyflakes or run_pep8) and current_finfo is not None: <MASK> finfo.run_code_analysis(run_pyflakes, run_pep8)",if current_finfo is not finfo :,148
2447,"def tchg(var, width): <TAB> ""Convert time string to given length"" <TAB> ret = ""%2dh%02d"" % (var / 60, var % 60) <MASK> ret = ""%2dh"" % (var / 60) <TAB>  <TAB> if len(ret) > width: <TAB>  <TAB>  <TAB> ret = ""%2dd"" % (var / 60 / 24) <TAB>  <TAB>  <TAB> if len(ret) > width: <TAB>  <TAB>  <TAB>  <TAB> ret = ""%2dw"" % (var / 60 / 24 / 7) <TAB> return ret",if len ( ret ) > width :,132
2448,"def spider_log_activity(self, messages): <TAB> for i in range(0, messages): <MASK> self.sp_sl_p.send( <TAB>  <TAB>  <TAB>  <TAB> sha1(str(randint(1, 1000))), <TAB>  <TAB>  <TAB>  <TAB> b""http://helloworld.com/way/to/the/sun/"" + b""0"", <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.sp_sl_p.send( <TAB>  <TAB>  <TAB>  <TAB> sha1(str(randint(1, 1000))), b""http://way.to.the.sun"" + b""0"" <TAB>  <TAB>  <TAB> ) <TAB> self.sp_sl_p.flush()",if i % 2 == 0 :,165
2449,"def decode_serial(self, offset): <TAB> serialnum = ( <TAB>  <TAB> (self.cache[offset + 3] << 24) <TAB>  <TAB> + (self.cache[offset + 2] << 16) <TAB>  <TAB> + (self.cache[offset + 1] << 8) <TAB>  <TAB> + self.cache[offset] <TAB> ) <TAB> serialstr = """" <TAB> is_alnum = True <TAB> for i in range(4): <MASK> is_alnum = False <TAB>  <TAB>  <TAB> break <TAB>  <TAB> serialstr += chr(self.cache[offset + 3 - i]) <TAB> serial = serialstr if is_alnum else str(serialnum) <TAB> self.ann_field(offset, offset + 3, ""Serial "" + serial)",if not chr ( self . cache [ offset + 3 - i ] ) . isalnum ( ) :,182
2450,def gettext(rv): <TAB> for child in rv.childNodes: <TAB>  <TAB> if child.nodeType == child.TEXT_NODE: <TAB>  <TAB>  <TAB> yield child.nodeValue <MASK> for item in gettext(child): <TAB>  <TAB>  <TAB>  <TAB> yield item,if child . nodeType == child . ELEMENT_NODE :,73
2451,"def determine_block_hints(self, text): <TAB> hints = """" <TAB> if text: <TAB>  <TAB> if text[0] in "" \n\x85\u2028\u2029"": <TAB>  <TAB>  <TAB> hints += str(self.best_indent) <TAB>  <TAB> if text[-1] not in ""\n\x85\u2028\u2029"": <TAB>  <TAB>  <TAB> hints += ""-"" <MASK> hints += ""+"" <TAB> return hints","elif len ( text ) == 1 or text [ - 2 ] in ""\n\x85\u2028\u2029"" :",132
2452,"def _infer_return_type(*args): <TAB> """"""Look at the type of all args and divine their implied return type."""""" <TAB> return_type = None <TAB> for arg in args: <TAB>  <TAB> if arg is None: <TAB>  <TAB>  <TAB> continue <MASK> if return_type is str: <TAB>  <TAB>  <TAB>  <TAB> raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."") <TAB>  <TAB>  <TAB> return_type = bytes <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if return_type is bytes: <TAB>  <TAB>  <TAB>  <TAB> raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."") <TAB>  <TAB>  <TAB> return_type = str <TAB> if return_type is None: <TAB>  <TAB> return str  # tempfile APIs return a str by default. <TAB> return return_type","if isinstance ( arg , bytes ) :",186
2453,"def as_iconbitmap(cls, rkey): <TAB> """"""Get image path for use in iconbitmap property"""""" <TAB> img = None <TAB> if rkey in cls._stock: <TAB>  <TAB> data = cls._stock[rkey] <MASK> fpath = data[""filename""] <TAB>  <TAB>  <TAB> fname = os.path.basename(fpath) <TAB>  <TAB>  <TAB> name, file_ext = os.path.splitext(fname) <TAB>  <TAB>  <TAB> file_ext = str(file_ext).lower() <TAB>  <TAB>  <TAB> if file_ext in TK_BITMAP_FORMATS: <TAB>  <TAB>  <TAB>  <TAB> img = BITMAP_TEMPLATE.format(fpath) <TAB> return img","if data [ ""type"" ] not in ( ""stock"" , ""data"" , ""image"" ) :",167
2454,"def anonymize_ip(ip): <TAB> if ip: <TAB>  <TAB> match = RE_FIRST_THREE_OCTETS_OF_IP.findall(str(ip)) <MASK> return ""%s%s"" % (match[0][0], ""0"") <TAB> return """"",if match :,69
2455,"def serialize_tail(self): <TAB> msg = bytearray() <TAB> for v in self.info: <MASK> value = v[""value""].encode(""utf-8"") <TAB>  <TAB> elif v[""type""] == BMP_TERM_TYPE_REASON: <TAB>  <TAB>  <TAB> value = struct.pack(""!H"", v[""value""]) <TAB>  <TAB> v[""len""] = len(value) <TAB>  <TAB> msg += struct.pack(self._TLV_PACK_STR, v[""type""], v[""len""]) <TAB>  <TAB> msg += value <TAB> return msg","if v [ ""type"" ] == BMP_TERM_TYPE_STRING :",139
2456,"def get_django_comment(text: str, i: int) -> str: <TAB> end = i + 4 <TAB> unclosed_end = 0 <TAB> while end <= len(text): <MASK> return text[i:end] <TAB>  <TAB> if not unclosed_end and text[end] == ""<"": <TAB>  <TAB>  <TAB> unclosed_end = end <TAB>  <TAB> end += 1 <TAB> raise TokenizationException(""Unclosed comment"", text[i:unclosed_end])","if text [ end - 2 : end ] == ""#}"" :",126
2457,"def ComboBoxDroppedHeightTest(windows): <TAB> ""Check if each combobox height is the same as the reference"" <TAB> bugs = [] <TAB> for win in windows: <TAB>  <TAB> if not win.ref: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if win.Class() != ""ComboBox"" or win.ref.Class() != ""ComboBox"": <TAB>  <TAB>  <TAB> continue <MASK> bugs.append( <TAB>  <TAB>  <TAB>  <TAB> ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> win, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ], <TAB>  <TAB>  <TAB>  <TAB>  <TAB> {}, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> testname, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> 0, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> return bugs",if win . DroppedRect ( ) . height ( ) != win . ref . DroppedRect ( ) . height ( ) :,181
2458,"def testBadModeArgument(self): <TAB> # verify that we get a sensible error message for bad mode argument <TAB> bad_mode = ""qwerty"" <TAB> try: <TAB>  <TAB> f = self.open(TESTFN, bad_mode) <TAB> except ValueError as msg: <MASK> s = str(msg) <TAB>  <TAB>  <TAB> if TESTFN in s or bad_mode not in s: <TAB>  <TAB>  <TAB>  <TAB> self.fail(""bad error message for invalid mode: %s"" % s) <TAB>  <TAB> # if msg.args[0] == 0, we're probably on Windows where there may be <TAB>  <TAB> # no obvious way to discover why open() failed. <TAB> else: <TAB>  <TAB> f.close() <TAB>  <TAB> self.fail(""no error for invalid mode: %s"" % bad_mode)",if msg . args [ 0 ] != 0 :,191
2459,"def command_group_expired(self, command_group_name): <TAB> try: <TAB>  <TAB> deprecate_info = self._command_loader.command_group_table[ <TAB>  <TAB>  <TAB> command_group_name <TAB>  <TAB> ].group_kwargs.get(""deprecate_info"", None) <MASK> return deprecate_info.expired() <TAB> except AttributeError: <TAB>  <TAB> # Items with only token presence in the command table will not have any data. They can't be expired. <TAB>  <TAB> pass <TAB> return False",if deprecate_info :,129
2460,"def test_non_uniform_probabilities_over_elements(self): <TAB> param = iap.Choice([0, 1], p=[0.25, 0.75]) <TAB> samples = param.draw_samples((10000,)) <TAB> unique, counts = np.unique(samples, return_counts=True) <TAB> assert len(unique) == 2 <TAB> for val, count in zip(unique, counts): <TAB>  <TAB> if val == 0: <TAB>  <TAB>  <TAB> assert 2500 - 500 < count < 2500 + 500 <MASK> assert 7500 - 500 < count < 7500 + 500 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert False",elif val == 1 :,145
2461,"def get_labels(directory): <TAB> cache = get_labels.__cache <TAB> if directory not in cache: <TAB>  <TAB> l = {} <TAB>  <TAB> for t in get_visual_configs(directory)[0][LABEL_SECTION]: <MASK> Messager.warning( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""In configuration, labels for '%s' defined more than once. Only using the last set."" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> % t.storage_form(), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> -1, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> # first is storage for, rest are labels. <TAB>  <TAB>  <TAB> l[t.storage_form()] = t.terms[1:] <TAB>  <TAB> cache[directory] = l <TAB> return cache[directory]",if t . storage_form ( ) in l :,179
2462,"def try_split(self, split_text: List[str]): <TAB> ret = [] <TAB> for i in split_text: <TAB>  <TAB> if len(i) == 0: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> val = int(i, 2) <MASK> return None <TAB>  <TAB> ret.append(val) <TAB> if len(ret) != 0: <TAB>  <TAB> ret = bytes(ret) <TAB>  <TAB> logger.debug(f""binary successful, returning {ret.__repr__()}"") <TAB>  <TAB> return ret",if val > 255 or val < 0 :,127
2463,"def setCellValue(self, row_idx, col, value): <TAB> assert col.id == ""repls-marked"" <TAB> with self._lock: <TAB>  <TAB> rgroup = self.events[row_idx] <MASK> return <TAB>  <TAB> rgroup._marked = value == ""true"" and True or False <TAB> if self._tree: <TAB>  <TAB> self._tree.invalidateCell(row_idx, col)","if not isinstance ( rgroup , findlib2 . ReplaceHitGroup ) :",113
2464,"def create(cls, settlement_manager, resource_id): <TAB> """"""Create a production chain that can produce the given resource."""""" <TAB> resource_producer = {} <TAB> for abstract_building in AbstractBuilding.buildings.values(): <TAB>  <TAB> for resource, production_line in abstract_building.lines.items(): <MASK> resource_producer[resource] = [] <TAB>  <TAB>  <TAB> resource_producer[resource].append((production_line, abstract_building)) <TAB> return ProductionChain(settlement_manager, resource_id, resource_producer)",if resource not in resource_producer :,137
2465,def get_all_partition_sets(self): <TAB> partition_sets = [] <TAB> if self.partitions_handle: <TAB>  <TAB> partition_sets.extend(self.partitions_handle.get_partition_sets()) <TAB> if self.scheduler_handle: <TAB>  <TAB> partition_sets.extend( <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB> schedule_def.get_partition_set() <TAB>  <TAB>  <TAB>  <TAB> for schedule_def in self.scheduler_handle.all_schedule_defs() <MASK> ] <TAB>  <TAB> ) <TAB> return partition_sets,"if isinstance ( schedule_def , PartitionScheduleDefinition )",140
2466,"def _sendDatapointsNow(self, datapoints): <TAB> metrics = {} <TAB> payload_pb = Payload() <TAB> for metric, datapoint in datapoints: <MASK> metric_pb = payload_pb.metrics.add() <TAB>  <TAB>  <TAB> metric_pb.metric = metric <TAB>  <TAB>  <TAB> metrics[metric] = metric_pb <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> metric_pb = metrics[metric] <TAB>  <TAB> point_pb = metric_pb.points.add() <TAB>  <TAB> point_pb.timestamp = int(datapoint[0]) <TAB>  <TAB> point_pb.value = datapoint[1] <TAB> self.sendString(payload_pb.SerializeToString())",if metric not in metrics :,159
2467,"def execute(self): <TAB> if self._dirty or not self._qr: <TAB>  <TAB> model_class = self.model_class <TAB>  <TAB> query_meta = self.get_query_meta() <TAB>  <TAB> if self._tuples: <TAB>  <TAB>  <TAB> ResultWrapper = TuplesQueryResultWrapper <MASK> ResultWrapper = DictQueryResultWrapper <TAB>  <TAB> elif self._naive or not self._joins or self.verify_naive(): <TAB>  <TAB>  <TAB> ResultWrapper = NaiveQueryResultWrapper <TAB>  <TAB> elif self._aggregate_rows: <TAB>  <TAB>  <TAB> ResultWrapper = AggregateQueryResultWrapper <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ResultWrapper = ModelQueryResultWrapper <TAB>  <TAB> self._qr = ResultWrapper(model_class, self._execute(), query_meta) <TAB>  <TAB> self._dirty = False <TAB>  <TAB> return self._qr <TAB> else: <TAB>  <TAB> return self._qr",elif self . _dicts :,198
2468,"def get_metrics(): <TAB> classifier, feature_labels = load_classifier() <TAB> available_metrics = ImgageMetrics.get_metric_classes() <TAB> # todo review: DONE IN DOCS <TAB> #  effective_metrics isn't used after filling it with values <TAB> #  in the loops below <TAB> effective_metrics = [] <TAB> for metric in available_metrics: <TAB>  <TAB> for label in feature_labels: <TAB>  <TAB>  <TAB> for label_part in metric.get_labels(): <MASK> effective_metrics.append(metric) <TAB> return (classifier, feature_labels, available_metrics)",if label_part == label and metric not in effective_metrics :,156
2469,"def test_nic_names(self): <TAB> p = subprocess.Popen([""ipconfig"", ""/all""], stdout=subprocess.PIPE) <TAB> out = p.communicate()[0] <TAB> if PY3: <TAB>  <TAB> out = str(out, sys.stdout.encoding) <TAB> nics = psutil.net_io_counters(pernic=True).keys() <TAB> for nic in nics: <TAB>  <TAB> if ""pseudo-interface"" in nic.replace("" "", ""-"").lower(): <TAB>  <TAB>  <TAB> continue <MASK> self.fail(""%r nic wasn't found in 'ipconfig /all' output"" % nic)",if nic not in out :,145
2470,"def convert_with_key(self, key, value, replace=True): <TAB> result = self.configurator.convert(value) <TAB> # If the converted value is different, save for next time <TAB> if value is not result: <TAB>  <TAB> if replace: <TAB>  <TAB>  <TAB> self[key] = result <MASK> result.parent = self <TAB>  <TAB>  <TAB> result.key = key <TAB> return result","if type ( result ) in ( ConvertingDict , ConvertingList , ConvertingTuple ) :",111
2471,"def _EvaluateFile(self, test_list, file): <TAB> (name, ext) = os.path.splitext(file) <TAB> if ext == "".cc"" or ext == "".cpp"" or ext == "".c"": <MASK> logger.SilentLog(""Found native test file %s"" % file) <TAB>  <TAB>  <TAB> test_list.append(name)","if re . search ( ""_test$|_test_$|_unittest$|_unittest_$|^test_|Tests$"" , name ) :",112
2472,"def leading_whitespace(self, inputstring): <TAB> """"""Get leading whitespace."""""" <TAB> leading_ws = [] <TAB> for i, c in enumerate(inputstring): <MASK> leading_ws.append(c) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if self.indchar is None: <TAB>  <TAB>  <TAB> self.indchar = c <TAB>  <TAB> elif c != self.indchar: <TAB>  <TAB>  <TAB> self.strict_err_or_warn(""found mixing of tabs and spaces"", inputstring, i) <TAB> return """".join(leading_ws)",if c in legal_indent_chars :,139
2473,"def ident_values(self): <TAB> value = self._ident_values <TAB> if value is False: <TAB>  <TAB> value = None <TAB>  <TAB> # XXX: how will this interact with orig_prefix ? <TAB>  <TAB> # <TAB>   not exposing attrs for now if orig_prefix is set. <MASK> wrapped = self.wrapped <TAB>  <TAB>  <TAB> idents = getattr(wrapped, ""ident_values"", None) <TAB>  <TAB>  <TAB> if idents: <TAB>  <TAB>  <TAB>  <TAB> value = [self._wrap_hash(ident) for ident in idents] <TAB>  <TAB>  <TAB> ##else: <TAB>  <TAB>  <TAB> ## <TAB> ident = self.ident <TAB>  <TAB>  <TAB> ## <TAB> if ident is not None: <TAB>  <TAB>  <TAB> ## <TAB>  <TAB> value = [ident] <TAB>  <TAB> self._ident_values = value <TAB> return value",if not self . orig_prefix :,200
2474,"def _available_symbols(self, scoperef, expr): <TAB> cplns = [] <TAB> found_names = set() <TAB> while scoperef: <TAB>  <TAB> elem = self._elem_from_scoperef(scoperef) <TAB>  <TAB> for child in elem: <TAB>  <TAB>  <TAB> name = child.get(""name"", """") <MASK> if name not in found_names: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> found_names.add(name) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ilk = child.get(""ilk"") or child.tag <TAB>  <TAB>  <TAB>  <TAB>  <TAB> cplns.append((ilk, name)) <TAB>  <TAB> scoperef = self.parent_scoperef_from_scoperef(scoperef) <TAB>  <TAB> if not scoperef: <TAB>  <TAB>  <TAB> break <TAB> return sorted(cplns, key=operator.itemgetter(1))",if name . startswith ( expr ) :,196
2475,"def pid_from_name(name): <TAB> # quick and dirty, works with all linux not depending on ps output <TAB> for pid in os.listdir(""/proc""): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> int(pid) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> pname = """" <TAB>  <TAB> with open(""/proc/%s/cmdline"" % pid, ""r"") as f: <TAB>  <TAB>  <TAB> pname = f.read() <MASK> return int(pid) <TAB> raise ProcessException(""No process with such name: %s"" % name)",if name in pname :,134
2476,"def touch(self): <TAB> if not self.exists(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.parent().touch() <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> node = self._fs.touch(self.pathnames, {}) <MASK> raise AssertionError(""Not a folder: %s"" % self.path) <TAB>  <TAB> if self.watcher: <TAB>  <TAB>  <TAB> self.watcher.emit(""created"", self)",if not node . isdir :,107
2477,"def setUp(self): <TAB> BaseTestCase.setUp(self) <TAB> self.rawData = [] <TAB> self.dataByKey = {} <TAB> for i in range(1, 11): <TAB>  <TAB> stringCol = ""String %d"" % i <TAB>  <TAB> fixedCharCol = (""Fixed Char %d"" % i).ljust(40) <TAB>  <TAB> rawCol = ""Raw %d"" % i <MASK> nullableCol = ""Nullable %d"" % i <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> nullableCol = None <TAB>  <TAB> dataTuple = (i, stringCol, rawCol, fixedCharCol, nullableCol) <TAB>  <TAB> self.rawData.append(dataTuple) <TAB>  <TAB> self.dataByKey[i] = dataTuple",if i % 2 :,173
2478,"def GenerateVector(self, hits, vector, level): <TAB> """"""Generate possible hit vectors which match the rules."""""" <TAB> for item in hits.get(level, []): <TAB>  <TAB> if vector: <TAB>  <TAB>  <TAB> if item < vector[-1]: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if item > self.max_separation + vector[-1]: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> new_vector = vector + [item] <MASK> yield new_vector <TAB>  <TAB> elif level + 1 < len(hits): <TAB>  <TAB>  <TAB> for result in self.GenerateVector(hits, new_vector, level + 1): <TAB>  <TAB>  <TAB>  <TAB> yield result",if level + 1 == len ( hits ) :,157
2479,"def __repr__(self): <TAB> attrs = [] <TAB> for k in self.keydata: <MASK> attrs.append(""p(%d)"" % (self.size() + 1,)) <TAB>  <TAB> elif hasattr(self.key, k): <TAB>  <TAB>  <TAB> attrs.append(k) <TAB> if self.has_private(): <TAB>  <TAB> attrs.append(""private"") <TAB> return ""<%s @0x%x %s>"" % (self.__class__.__name__, id(self), "","".join(attrs))","if k == ""p"" :",122
2480,"def autoload(self): <TAB> if self._app.config.THEME == ""auto"": <MASK> if get_osx_theme() == 1: <TAB>  <TAB>  <TAB>  <TAB> theme = DARK <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> theme = LIGHT <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> theme = self.guess_system_theme() <TAB>  <TAB>  <TAB> if theme == Dark: <TAB>  <TAB>  <TAB>  <TAB> theme = MacOSDark <TAB> else:  # user settings have highest priority <TAB>  <TAB> theme = self._app.config.THEME <TAB> self.load_theme(theme)","if sys . platform == ""darwin"" :",141
2481,"def _get_matching_bracket(self, s, pos): <TAB> if s[pos] != ""{"": <TAB>  <TAB> return None <TAB> end = len(s) <TAB> depth = 1 <TAB> pos += 1 <TAB> while pos != end: <TAB>  <TAB> c = s[pos] <TAB>  <TAB> if c == ""{"": <TAB>  <TAB>  <TAB> depth += 1 <TAB>  <TAB> elif c == ""}"": <TAB>  <TAB>  <TAB> depth -= 1 <MASK> break <TAB>  <TAB> pos += 1 <TAB> if pos < end and s[pos] == ""}"": <TAB>  <TAB> return pos <TAB> return None",if depth == 0 :,132
2482,"def update_meter(self, output, target, meters={""accuracy""}): <TAB> output = self.__to_tensor(output) <TAB> target = self.__to_tensor(target) <TAB> for meter in meters: <MASK> self.__addmeter(meter) <TAB>  <TAB> if meter in [""ap"", ""map"", ""confusion""]: <TAB>  <TAB>  <TAB> target_th = self._ver2tensor(target) <TAB>  <TAB>  <TAB> self.meter[meter].add(output, target_th) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.meter[meter].add(output, target)",if meter not in self . meter . keys ( ) :,147
2483,"def _reinit_optimizers_with_oss(self): <TAB> optimizers = self.lightning_module.trainer.optimizers <TAB> for x, optimizer in enumerate(optimizers): <TAB>  <TAB> if is_lightning_optimizer(optimizer): <TAB>  <TAB>  <TAB> optimizer = optimizer._optimizer <MASK> optim_class = type(optimizer) <TAB>  <TAB>  <TAB> zero_optimizer = OSS( <TAB>  <TAB>  <TAB>  <TAB> params=optimizer.param_groups, optim=optim_class, **optimizer.defaults <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> optimizers[x] = zero_optimizer <TAB>  <TAB>  <TAB> del optimizer <TAB> trainer = self.lightning_module.trainer <TAB> trainer.optimizers = optimizers <TAB> trainer.convert_to_lightning_optimizers()","if not isinstance ( optimizer , OSS ) :",175
2484,"def OnSelChanged(self, event): <TAB> self.item = event.GetItem() <TAB> if self.item: <TAB>  <TAB> self.log.write(""OnSelChanged: %s"" % self.GetItemText(self.item)) <MASK> self.log.write( <TAB>  <TAB>  <TAB>  <TAB> "", BoundingRect: %s\n"" % self.GetBoundingRect(self.item, True) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.log.write(""\n"") <TAB> event.Skip()","if wx . Platform == ""__WXMSW__"" :",131
2485,"def parse_batch(args): <TAB> errmsg = ""Invalid batch definition: batch entry has to be defined as RULE=BATCH/BATCHES (with integers BATCH <= BATCHES, BATCH >= 1)."" <TAB> if args.batch is not None: <TAB>  <TAB> rule, batchdef = parse_key_value_arg(args.batch, errmsg=errmsg) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> batch, batches = batchdef.split(""/"") <TAB>  <TAB>  <TAB> batch = int(batch) <TAB>  <TAB>  <TAB> batches = int(batches) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> raise ValueError(errmsg) <MASK> raise ValueError(errmsg) <TAB>  <TAB> return Batch(rule, batch, batches) <TAB> return None",if batch > batches or batch < 1 :,167
2486,"def get_foreign_key_columns(self, engine, table_name): <TAB> foreign_keys = set() <TAB> table = db_utils.get_table(engine, table_name) <TAB> inspector = reflection.Inspector.from_engine(engine) <TAB> for column_dict in inspector.get_columns(table_name): <TAB>  <TAB> column_name = column_dict[""name""] <TAB>  <TAB> column = getattr(table.c, column_name) <MASK> foreign_keys.add(column_name) <TAB> return foreign_keys",if column . foreign_keys :,135
2487,"def update(self, t): <TAB> l = int(t * self.nr_of_tiles) <TAB> for i in range(self.nr_of_tiles): <TAB>  <TAB> t = self.tiles_order[i] <MASK> self.turn_off_tile(t) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.turn_on_tile(t)",if i < l :,93
2488,"def read(self, amt=None): <TAB> # the _rbuf test is only in this first if for speed.  It's not <TAB> # logically necessary <TAB> if self._rbuf and not amt is None: <TAB>  <TAB> L = len(self._rbuf) <MASK> amt -= L <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> s = self._rbuf[:amt] <TAB>  <TAB>  <TAB> self._rbuf = self._rbuf[amt:] <TAB>  <TAB>  <TAB> return s <TAB> s = self._rbuf + self._raw_read(amt) <TAB> self._rbuf = b"""" <TAB> return s",if amt > L :,153
2489,"def draw_menu_button(self, context, layout, node, text): <TAB> if ( <TAB>  <TAB> hasattr(node.id_data, ""sv_show_socket_menus"") <TAB>  <TAB> and node.id_data.sv_show_socket_menus <TAB> ): <MASK> layout.menu(""SV_MT_SocketOptionsMenu"", text="""", icon=""TRIA_DOWN"")",if self . is_output or self . is_linked or not self . use_prop :,110
2490,"def __enter__(self): <TAB> with DB.connection_context(): <TAB>  <TAB> session_record = SessionRecord() <TAB>  <TAB> session_record.f_session_id = self._session_id <TAB>  <TAB> session_record.f_engine_name = self._engine_name <TAB>  <TAB> session_record.f_engine_type = EngineType.STORAGE <TAB>  <TAB> # TODO: engine address <TAB>  <TAB> session_record.f_engine_address = {} <TAB>  <TAB> session_record.f_create_time = current_timestamp() <TAB>  <TAB> rows = session_record.save(force_insert=True) <MASK> raise Exception(f""create session record {self._session_id} failed"") <TAB>  <TAB> LOGGER.debug(f""save session {self._session_id} record"") <TAB> self.create() <TAB> return self",if rows != 1 :,195
2491,"def tearDown(self): <TAB> """"""Shutdown the server."""""" <TAB> try: <TAB>  <TAB> if self.server: <TAB>  <TAB>  <TAB> self.server.stop(2.0) <MASK> self.root_logger.removeHandler(self.sl_hdlr) <TAB>  <TAB>  <TAB> self.sl_hdlr.close() <TAB> finally: <TAB>  <TAB> BaseTest.tearDown(self)",if self . sl_hdlr :,96
2492,"def _dec_device(self, srcdev, dstdev): <TAB> if srcdev: <TAB>  <TAB> self.srcdevs[srcdev] -= 1 <MASK> del self.srcdevs[srcdev] <TAB>  <TAB> self._set_limits(""read"", self.srcdevs) <TAB> if dstdev: <TAB>  <TAB> self.dstdevs[dstdev] -= 1 <TAB>  <TAB> if self.dstdevs[dstdev] == 0: <TAB>  <TAB>  <TAB> del self.dstdevs[dstdev] <TAB>  <TAB> self._set_limits(""write"", self.dstdevs)",if self . srcdevs [ srcdev ] == 0 :,141
2493,"def array_for(self, i): <TAB> if 0 <= i < self._cnt: <MASK> return self._tail <TAB>  <TAB> node = self._root <TAB>  <TAB> level = self._shift <TAB>  <TAB> while level > 0: <TAB>  <TAB>  <TAB> assert isinstance(node, Node) <TAB>  <TAB>  <TAB> node = node._array[(i >> level) & 0x01F] <TAB>  <TAB>  <TAB> level -= 5 <TAB>  <TAB> return node._array <TAB> affirm(False, u""Index out of Range"")",if i >= self . tailoff ( ) :,125
2494,"def convert_tensor(self, offsets, sizes): <TAB> results = [] <TAB> for b, batch in enumerate(offsets): <TAB>  <TAB> utterances = [] <TAB>  <TAB> for p, utt in enumerate(batch): <TAB>  <TAB>  <TAB> size = sizes[b][p] <MASK> utterances.append(utt[0:size]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> utterances.append(torch.tensor([], dtype=torch.int)) <TAB>  <TAB> results.append(utterances) <TAB> return results",if sizes [ b ] [ p ] > 0 :,126
2495,"def _predict_proba(self, X, preprocess=True): <TAB> if preprocess: <TAB>  <TAB> X = self.preprocess(X) <TAB> if self.problem_type == REGRESSION: <TAB>  <TAB> return self.model.predict(X) <TAB> y_pred_proba = self.model.predict_proba(X) <TAB> if self.problem_type == BINARY: <TAB>  <TAB> if len(y_pred_proba.shape) == 1: <TAB>  <TAB>  <TAB> return y_pred_proba <MASK> return y_pred_proba[:, 1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return y_pred_proba <TAB> elif y_pred_proba.shape[1] > 2: <TAB>  <TAB> return y_pred_proba <TAB> else: <TAB>  <TAB> return y_pred_proba[:, 1]",elif y_pred_proba . shape [ 1 ] > 1 :,198
2496,def timeout(self): <TAB> now = ptime.time() <TAB> dt = now - self.lastPlayTime <TAB> if dt < 0: <TAB>  <TAB> return <TAB> n = int(self.playRate * dt) <TAB> if n != 0: <TAB>  <TAB> self.lastPlayTime += float(n) / self.playRate <MASK> self.play(0) <TAB>  <TAB> self.jumpFrames(n),"if self . currentIndex + n > self . image . shape [ self . axes [ ""t"" ] ] :",117
2497,"def __init__(self, data, weights=None, ddof=0): <TAB> self.data = np.asarray(data) <TAB> if weights is None: <TAB>  <TAB> self.weights = np.ones(self.data.shape[0]) <TAB> else: <TAB>  <TAB> self.weights = np.asarray(weights).astype(float) <TAB>  <TAB> # TODO: why squeeze? <MASK> self.weights = self.weights.squeeze() <TAB> self.ddof = ddof",if len ( self . weights . shape ) > 1 and len ( self . weights ) > 1 :,130
2498,"def writerow(self, row): <TAB> unicode_row = [] <TAB> for col in row: <MASK> unicode_row.append(col.encode(""utf-8"").strip()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> unicode_row.append(col) <TAB> self.writer.writerow(unicode_row) <TAB> # Fetch UTF-8 output from the queue ... <TAB> data = self.queue.getvalue() <TAB> data = data.decode(""utf-8"") <TAB> # ... and reencode it into the target encoding <TAB> data = self.encoder.encode(data) <TAB> # write to the target stream <TAB> self.stream.write(data) <TAB> # empty queue <TAB> self.queue.truncate(0)",if type ( col ) == str or type ( col ) == unicode :,182
2499,"def __init__(self, choices, allow_blank=False, **kwargs): <TAB> self.choiceset = choices <TAB> self.allow_blank = allow_blank <TAB> self._choices = dict() <TAB> # Unpack grouped choices <TAB> for k, v in choices: <MASK> for k2, v2 in v: <TAB>  <TAB>  <TAB>  <TAB> self._choices[k2] = v2 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._choices[k] = v <TAB> super().__init__(**kwargs)","if type ( v ) in [ list , tuple ] :",127
2500,"def simp_ext(_, expr): <TAB> if expr.op.startswith(""zeroExt_""): <TAB>  <TAB> arg = expr.args[0] <MASK> return arg <TAB>  <TAB> return ExprCompose(arg, ExprInt(0, expr.size - arg.size)) <TAB> if expr.op.startswith(""signExt_""): <TAB>  <TAB> arg = expr.args[0] <TAB>  <TAB> add_size = expr.size - arg.size <TAB>  <TAB> new_expr = ExprCompose( <TAB>  <TAB>  <TAB> arg, <TAB>  <TAB>  <TAB> ExprCond( <TAB>  <TAB>  <TAB>  <TAB> arg.msb(), ExprInt(size2mask(add_size), add_size), ExprInt(0, add_size) <TAB>  <TAB>  <TAB> ), <TAB>  <TAB> ) <TAB>  <TAB> return new_expr <TAB> return expr",if expr . size == arg . size :,191
2501,"def mark_differences(value: str, compare_against: str): <TAB> result = [] <TAB> for i, char in enumerate(value): <TAB>  <TAB> try: <MASK> result.append('<font color=""red"">{}</font>'.format(char)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> result.append(char) <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB> result.append(char) <TAB> return """".join(result)",if char != compare_against [ i ] :,111
2502,"def run_query(self, query, user): <TAB> url = ""%s%s"" % (self.base_url, ""&"".join(query.split(""\n""))) <TAB> error = None <TAB> data = None <TAB> try: <TAB>  <TAB> response = requests.get(url, auth=self.auth, verify=self.verify) <MASK> data = _transform_result(response) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> error = ""Failed getting results (%d)"" % response.status_code <TAB> except Exception as ex: <TAB>  <TAB> data = None <TAB>  <TAB> error = str(ex) <TAB> return data, error",if response . status_code == 200 :,153
2503,"def on_enter(self): <TAB> """"""Fired when mouse enter the bbox of the widget."""""" <TAB> if hasattr(self, ""md_bg_color"") and self.focus_behavior: <MASK> self.md_bg_color = self.theme_cls.bg_normal <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if not self.focus_color: <TAB>  <TAB>  <TAB>  <TAB> self.md_bg_color = App.get_running_app().theme_cls.bg_normal <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.md_bg_color = self.focus_color","if hasattr ( self , ""theme_cls"" ) and not self . focus_color :",154
2504,"def tearDown(self): <TAB> if not self.is_playback(): <TAB>  <TAB> try: <MASK> self.sms.delete_hosted_service(self.hosted_service_name) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if self.storage_account_name is not None: <TAB>  <TAB>  <TAB>  <TAB> self.sms.delete_storage_account(self.storage_account_name) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.sms.delete_affinity_group(self.affinity_group_name) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> pass <TAB> return super(LegacyMgmtAffinityGroupTest, self).tearDown()",if self . hosted_service_name is not None :,180
2505,"def name2cp(k): <TAB> if k == ""apos"": <TAB>  <TAB> return ord(""'"") <TAB> if hasattr(htmlentitydefs, ""name2codepoint""):  # requires Python 2.3 <TAB>  <TAB> return htmlentitydefs.name2codepoint[k] <TAB> else: <TAB>  <TAB> k = htmlentitydefs.entitydefs[k] <MASK> return int(k[2:-1])  # not in latin-1 <TAB>  <TAB> return ord(codecs.latin_1_decode(k)[0])","if k . startswith ( ""&#"" ) and k . endswith ( "";"" ) :",125
2506,"def _para_set(self, params, part): <TAB> if len(params) == 0: <TAB>  <TAB> result = suggest([i.get_name() for i in self._options], part) <TAB>  <TAB> return result <TAB> elif len(params) == 1: <TAB>  <TAB> paramName = params[0] <TAB>  <TAB> if paramName not in self._options: <TAB>  <TAB>  <TAB> return [] <TAB>  <TAB> opt = self._options[paramName] <TAB>  <TAB> paramType = opt.get_type() <MASK> values = [opt.get_default_value() == ""True"" and ""False"" or ""True""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> values = self._memory[paramName] <TAB>  <TAB> return suggest(values, part) <TAB> else: <TAB>  <TAB> return []","if paramType == ""boolean"" :",186
2507,"def hexcmp(x, y): <TAB> try: <TAB>  <TAB> a = int(x, 16) <TAB>  <TAB> b = int(y, 16) <MASK> return -1 <TAB>  <TAB> if a > b: <TAB>  <TAB>  <TAB> return 1 <TAB>  <TAB> return 0 <TAB> except: <TAB>  <TAB> return cmp(x, y)",if a < b :,83
2508,"def execute(self, statement, arguments=None): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if arguments: <TAB>  <TAB>  <TAB>  <TAB> self.cursor.execute(statement, arguments) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.cursor.execute(statement) <TAB>  <TAB> except sqlite3.OperationalError as ex: <MASK> raise <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> if statement.lstrip().upper().startswith(""SELECT""): <TAB>  <TAB> return self.cursor.fetchall()","if ""locked"" not in getSafeExString ( ex ) :",130
2509,"def _test_forever(self, tests): <TAB> while True: <TAB>  <TAB> for test_name in tests: <TAB>  <TAB>  <TAB> yield test_name <MASK> return <TAB>  <TAB>  <TAB> if self.ns.fail_env_changed and self.environment_changed: <TAB>  <TAB>  <TAB>  <TAB> return",if self . bad :,76
2510,"def removeUser(self, username): <TAB> hideFromOSD = not constants.SHOW_DIFFERENT_ROOM_OSD <TAB> if username in self._users: <TAB>  <TAB> user = self._users[username] <TAB>  <TAB> if user.room: <MASK> hideFromOSD = not constants.SHOW_SAME_ROOM_OSD <TAB> if username in self._users: <TAB>  <TAB> self._users.pop(username) <TAB>  <TAB> message = getMessage(""left-notification"").format(username) <TAB>  <TAB> self.ui.showMessage(message, hideFromOSD) <TAB>  <TAB> self._client.lastLeftTime = time.time() <TAB>  <TAB> self._client.lastLeftUser = username <TAB> self.userListChange()",if self . isRoomSame ( user . room ) :,184
2511,"def AutoTest(): <TAB> with open(sys.argv[1], ""rb"") as f: <TAB>  <TAB> for line in f.read().split(b""\n""): <TAB>  <TAB>  <TAB> line = BYTES2SYSTEMSTR(line.strip()) <TAB>  <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> elif line.startswith(""#""): <TAB>  <TAB>  <TAB>  <TAB> print(line) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> print("">>> "" + line) <TAB>  <TAB>  <TAB>  <TAB> os.system(line) <TAB>  <TAB>  <TAB>  <TAB> sys.stdout.write(""\npress enter to continue..."") <MASK> input() <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raw_input() <TAB>  <TAB>  <TAB>  <TAB> sys.stdout.write(""\n"")",if PY3 :,179
2512,"def get_first_field(layout, clz): <TAB> for layout_object in layout.fields: <MASK> return layout_object <TAB>  <TAB> elif hasattr(layout_object, ""get_field_names""): <TAB>  <TAB>  <TAB> gf = get_first_field(layout_object, clz) <TAB>  <TAB>  <TAB> if gf: <TAB>  <TAB>  <TAB>  <TAB> return gf","if issubclass ( layout_object . __class__ , clz ) :",94
2513,"def sanitize_event_keys(kwargs, valid_keys): <TAB> # Sanity check: Don't honor keys that we don't recognize. <TAB> for key in list(kwargs.keys()): <TAB>  <TAB> if key not in valid_keys: <TAB>  <TAB>  <TAB> kwargs.pop(key) <TAB> # Truncate certain values over 1k <TAB> for key in [""play"", ""role"", ""task"", ""playbook""]: <TAB>  <TAB> if isinstance(kwargs.get(""event_data"", {}).get(key), str): <MASK> kwargs[""event_data""][key] = Truncator(kwargs[""event_data""][key]).chars( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> 1024 <TAB>  <TAB>  <TAB>  <TAB> )","if len ( kwargs [ ""event_data"" ] [ key ] ) > 1024 :",168
2514,"def visit_productionlist(self, node): <TAB> self.new_state() <TAB> names = [] <TAB> for production in node: <TAB>  <TAB> names.append(production[""tokenname""]) <TAB> maxlen = max(len(name) for name in names) <TAB> for production in node: <MASK> self.add_text(production[""tokenname""].ljust(maxlen) + "" ::="") <TAB>  <TAB>  <TAB> lastname = production[""tokenname""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.add_text(""%s <TAB> "" % ("" "" * len(lastname))) <TAB>  <TAB> self.add_text(production.astext() + self.nl) <TAB> self.end_state(wrap=False) <TAB> raise nodes.SkipNode","if production [ ""tokenname"" ] :",168
2515,"def uuid(self): <TAB> if not getattr(self, ""_uuid"", None): <MASK> self._uuid = self.repository._kp_uuid( <TAB>  <TAB>  <TAB>  <TAB> self.path <TAB>  <TAB>  <TAB> )  # Use repository UUID (even if None) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._uuid = str(uuid.uuid4()) <TAB> return self._uuid",if self . repository is not None :,95
2516,"def remove(self, values): <TAB> if not isinstance(values, (list, tuple, set)): <TAB>  <TAB> values = [values] <TAB> for v in values: <TAB>  <TAB> v = str(v) <MASK> self._definition.pop(v, None) <TAB>  <TAB> elif self._definition == ""ANY"": <TAB>  <TAB>  <TAB> if v == ""ANY"": <TAB>  <TAB>  <TAB>  <TAB> self._definition = [] <TAB>  <TAB> elif v in self._definition: <TAB>  <TAB>  <TAB> self._definition.remove(v) <TAB> if ( <TAB>  <TAB> self._value is not None <TAB>  <TAB> and self._value not in self._definition <TAB>  <TAB> and self._not_any() <TAB> ): <TAB>  <TAB> raise ConanException(bad_value_msg(self._name, self._value, self.values_range))","if isinstance ( self . _definition , dict ) :",192
2517,"def make(self): <TAB> pygments_dir = join(self.dir, ""externals"", ""pygments"") <TAB> if exists(pygments_dir): <TAB>  <TAB> run_in_dir(""hg pull"", pygments_dir, self.log.info) <TAB>  <TAB> run_in_dir(""hg update"", pygments_dir, self.log.info) <TAB> else: <MASK> os.makedirs(dirname(pygments_dir)) <TAB>  <TAB> run_in_dir( <TAB>  <TAB>  <TAB> ""hg clone http://dev.pocoo.org/hg/pygments-main %s"" <TAB>  <TAB>  <TAB> % basename(pygments_dir), <TAB>  <TAB>  <TAB> dirname(pygments_dir), <TAB>  <TAB>  <TAB> self.log.info, <TAB>  <TAB> )",if not exists ( dirname ( pygments_dir ) ) :,177
2518,def set_field(self): <TAB> i = 0 <TAB> for string in self.display_string: <MASK> self.config[self.field + str(i)] = self.conversion_fn(self.str[i]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.config[self.field + str(i)] = self.str[i] <TAB>  <TAB> i = i + 1,if self . conversion_fn :,99
2519,"def cleanup(self): <TAB> with self.lock: <TAB>  <TAB> for proc in self.processes: <MASK> continue <TAB>  <TAB>  <TAB> proc.join() <TAB>  <TAB>  <TAB> self.processes.remove(proc) <TAB>  <TAB>  <TAB> log.debug(""Subprocess %s cleaned up"", proc.name)",if proc . is_alive ( ) :,79
2520,"def setup(self, gen): <TAB> Node.setup(self, gen) <TAB> for c in self.children: <TAB>  <TAB> c.setup(gen) <TAB> if not self.accepts_epsilon: <TAB>  <TAB> # If it's not already accepting epsilon, it might now do so. <TAB>  <TAB> for c in self.children: <TAB>  <TAB>  <TAB> # any non-epsilon means all is non-epsilon <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.accepts_epsilon = 1 <TAB>  <TAB>  <TAB> gen.changed()",if not c . accepts_epsilon :,135
2521,"def __call__(self, message): <TAB> with self._lock: <TAB>  <TAB> self._pending_ack += 1 <TAB>  <TAB> self.max_pending_ack = max(self.max_pending_ack, self._pending_ack) <TAB>  <TAB> self.seen_message_ids.append(int(message.attributes[""seq_num""])) <TAB> time.sleep(self._processing_time) <TAB> with self._lock: <TAB>  <TAB> self._pending_ack -= 1 <TAB>  <TAB> message.ack() <TAB>  <TAB> self.completed_calls += 1 <TAB>  <TAB> if self.completed_calls >= self._resolve_at_msg_count: <MASK> self.done_future.set_result(None)",if not self . done_future . done ( ) :,173
2522,"def build_canned_image_list(path): <TAB> layers_path = get_bitbake_var(""BBLAYERS"") <TAB> canned_wks_layer_dirs = [] <TAB> if layers_path is not None: <TAB>  <TAB> for layer_path in layers_path.split(): <TAB>  <TAB>  <TAB> for wks_path in (WIC_DIR, SCRIPTS_CANNED_IMAGE_DIR): <TAB>  <TAB>  <TAB>  <TAB> cpath = os.path.join(layer_path, wks_path) <MASK> canned_wks_layer_dirs.append(cpath) <TAB> cpath = os.path.join(path, CANNED_IMAGE_DIR) <TAB> canned_wks_layer_dirs.append(cpath) <TAB> return canned_wks_layer_dirs",if os . path . isdir ( cpath ) :,199
2523,"def _recv_loop(self) -> None: <TAB> async with self._ws as connection: <TAB>  <TAB> self._connected = True <TAB>  <TAB> self.connection = connection <TAB>  <TAB> while self._connected: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> resp = await self.connection.recv() <MASK> await self._on_message(resp) <TAB>  <TAB>  <TAB> except (websockets.ConnectionClosed, ConnectionResetError): <TAB>  <TAB>  <TAB>  <TAB> logger.info(""connection closed"") <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> await asyncio.sleep(0) <TAB> if self._connected: <TAB>  <TAB> self._loop.create_task(self.dispose())",if resp :,156
2524,"def _get_between(content, start, end=None): <TAB> should_yield = False <TAB> for line in content.split(""\n""): <TAB>  <TAB> if start in line: <TAB>  <TAB>  <TAB> should_yield = True <TAB>  <TAB>  <TAB> continue <MASK> return <TAB>  <TAB> if should_yield and line: <TAB>  <TAB>  <TAB> yield line.strip().split("" "")[0]",if end and end in line :,94
2525,"def handle_parse_result(self, ctx, opts, args): <TAB> if self.name in opts: <TAB>  <TAB> if self.mutually_exclusive.intersection(opts): <TAB>  <TAB>  <TAB> self._raise_exclusive_error() <MASK> self._raise_exclusive_error() <TAB> return super(MutuallyExclusiveOption, self).handle_parse_result(ctx, opts, args)",if self . multiple and len ( set ( opts [ self . name ] ) ) > 1 :,108
2526,"def write(self, s): <TAB> if self.interactive: <MASK> self.active_mode.write(s) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> component.get(""CmdLine"").add_line(s, False) <TAB>  <TAB>  <TAB> self.events.append(s) <TAB> else: <TAB>  <TAB> print(colors.strip_colors(s))","if isinstance ( self . active_mode , deluge . ui . console . modes . cmdline . CmdLine ) :",110
2527,"def findfiles(path): <TAB> files = [] <TAB> for name in os.listdir(path): <TAB>  <TAB> # ignore hidden files/dirs and other unwanted files <TAB>  <TAB> if name.startswith(""."") or name == ""lastsnap.jpg"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> pathname = os.path.join(path, name) <TAB>  <TAB> st = os.lstat(pathname) <TAB>  <TAB> mode = st.st_mode <MASK> files.extend(findfiles(pathname)) <TAB>  <TAB> elif stat.S_ISREG(mode): <TAB>  <TAB>  <TAB> files.append((pathname, name, st)) <TAB> return files",if stat . S_ISDIR ( mode ) :,150
2528,"def _get_documented_completions(self, table, startswith=None): <TAB> names = [] <TAB> for key, command in table.items(): <TAB>  <TAB> if getattr(command, ""_UNDOCUMENTED"", False): <TAB>  <TAB>  <TAB> # Don't tab complete undocumented commands/params <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if startswith is not None and not key.startswith(startswith): <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> names.append(key) <TAB> return names","if getattr ( command , ""positional_arg"" , False ) :",118
2529,"def fix_newlines(lines): <TAB> """"""Convert newlines to unix."""""" <TAB> for i, line in enumerate(lines): <MASK> lines[i] = line[:-2] + ""\n"" <TAB>  <TAB> elif line.endswith(""\r""): <TAB>  <TAB>  <TAB> lines[i] = line[:-1] + ""\n""","if line . endswith ( ""\r\n"" ) :",83
2530,"def GeneratePageMetatadata(self, task): <TAB> address_space = self.session.GetParameter(""default_address_space"") <TAB> for vma in task.mm.mmap.walk_list(""vm_next""): <TAB>  <TAB> start = vma.vm_start <TAB>  <TAB> end = vma.vm_end <TAB>  <TAB> # Skip the entire region. <TAB>  <TAB> if end < self.plugin_args.start: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # Done. <TAB>  <TAB> if start > self.plugin_args.end: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> for vaddr in utils.xrange(start, end, 0x1000): <MASK> yield vaddr, self._CreateMetadata(address_space.describe_vtop(vaddr))",if self . plugin_args . start <= vaddr <= self . plugin_args . end :,195
2531,"def get_shape_at_node(self, node, assumptions): <TAB> for k, v in assumptions.items(): <MASK> return v <TAB> if node.inputs: <TAB>  <TAB> return node.container.shape( <TAB>  <TAB>  <TAB> input_shapes=[ <TAB>  <TAB>  <TAB>  <TAB> self.get_shape_at_node(input_node, assumptions) <TAB>  <TAB>  <TAB>  <TAB> for input_node in node.inputs <TAB>  <TAB>  <TAB> ] <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> return node.container.shape(None)",if k in node . names :,127
2532,"def fix_doc(self, doc): <TAB> type = doc.get(""type"", {}).get(""key"") <TAB> if type == ""/type/work"": <MASK> # some record got empty author records because of an error <TAB>  <TAB>  <TAB> # temporary hack to fix <TAB>  <TAB>  <TAB> doc[""authors""] = [ <TAB>  <TAB>  <TAB>  <TAB> a for a in doc[""authors""] if ""author"" in a and ""key"" in a[""author""] <TAB>  <TAB>  <TAB> ] <TAB> elif type == ""/type/edition"": <TAB>  <TAB> # get rid of title_prefix. <TAB>  <TAB> if ""title_prefix"" in doc: <TAB>  <TAB>  <TAB> title = doc[""title_prefix""].strip() + "" "" + doc.get(""title"", """") <TAB>  <TAB>  <TAB> doc[""title""] = title.strip() <TAB>  <TAB>  <TAB> del doc[""title_prefix""] <TAB> return doc","if doc . get ( ""authors"" ) :",199
2533,"def modify_column(self, column: List[Optional[""Cell""]]): <TAB> for i in range(len(column)): <TAB>  <TAB> gate = column[i] <MASK> continue <TAB>  <TAB> elif isinstance(gate, ParityControlCell): <TAB>  <TAB>  <TAB> # The first parity control to modify the column must merge all <TAB>  <TAB>  <TAB> # of the other parity controls into itself. <TAB>  <TAB>  <TAB> column[i] = None <TAB>  <TAB>  <TAB> self._basis_change += gate._basis_change <TAB>  <TAB>  <TAB> self.qubits += gate.qubits <TAB>  <TAB> elif gate is not None: <TAB>  <TAB>  <TAB> column[i] = gate.controlled_by(self.qubits[0])",if gate is self :,164
2534,"def onSync(self, auto=False, reload=True): <TAB> if not auto or ( <TAB>  <TAB> self.pm.profile[""syncKey""] and self.pm.profile[""autoSync""] and not self.safeMode <TAB> ): <TAB>  <TAB> from aqt.sync import SyncManager <TAB>  <TAB> if not self.unloadCollection(): <TAB>  <TAB>  <TAB> return <TAB>  <TAB> # set a sync state so the refresh timer doesn't fire while deck <TAB>  <TAB> # unloaded <TAB>  <TAB> self.state = ""sync"" <TAB>  <TAB> self.syncer = SyncManager(self, self.pm) <TAB>  <TAB> self.syncer.sync() <TAB> if reload: <MASK> self.loadCollection()",if not self . col :,161
2535,"def _has_url_match(self, match, request_url): <TAB> url = match[""url""] <TAB> if _is_string(url): <MASK> return self._has_strict_url_match(url, request_url) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> url_without_qs = request_url.split(""?"", 1)[0] <TAB>  <TAB>  <TAB> return url == url_without_qs <TAB> elif isinstance(url, re._pattern_type) and url.match(request_url): <TAB>  <TAB> return True <TAB> else: <TAB>  <TAB> return False","if match [ ""match_querystring"" ] :",140
2536,"def pool_image(self, image): <TAB> if self.count < self.pool_size: <TAB>  <TAB> self.pool.append(image) <TAB>  <TAB> self.count += 1 <TAB>  <TAB> return image <TAB> else: <TAB>  <TAB> p = random.random() <MASK> random_id = random.randint(0, self.pool_size - 1) <TAB>  <TAB>  <TAB> temp = self.pool[random_id] <TAB>  <TAB>  <TAB> self.pool[random_id] = image <TAB>  <TAB>  <TAB> return temp <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return image",if p > 0.5 :,137
2537,"def get_target_dimensions(self): <TAB> width, height = self.engine.size <TAB> for operation in self.operations: <MASK> width = operation[""right""] - operation[""left""] <TAB>  <TAB>  <TAB> height = operation[""bottom""] - operation[""top""] <TAB>  <TAB> if operation[""type""] == ""resize"": <TAB>  <TAB>  <TAB> width = operation[""width""] <TAB>  <TAB>  <TAB> height = operation[""height""] <TAB> return (width, height)","if operation [ ""type"" ] == ""crop"" :",112
2538,"def validate_matrix(matrix): <TAB> if not matrix: <TAB>  <TAB> return None <TAB> for key, value in matrix.items(): <MASK> raise ValidationError( <TAB>  <TAB>  <TAB>  <TAB> ""`{}` defines a non uniform distribution, "" <TAB>  <TAB>  <TAB>  <TAB> ""and it cannot be used with bayesian optimization."".format(key) <TAB>  <TAB>  <TAB> ) <TAB> return matrix",if value . is_distribution and not value . is_uniform :,98
2539,"def scm_to_conandata(self): <TAB> try: <TAB>  <TAB> scm_to_conandata = get_env(""CONAN_SCM_TO_CONANDATA"") <MASK> scm_to_conandata = self.get_item(""general.scm_to_conandata"") <TAB>  <TAB> return scm_to_conandata.lower() in (""1"", ""true"") <TAB> except ConanException: <TAB>  <TAB> return False",if scm_to_conandata is None :,124
2540,"def _link_vrf_table(self, vrf_table, rt_list): <TAB> route_family = vrf_table.route_family <TAB> for rt in rt_list: <TAB>  <TAB> rt_rf_id = rt + "":"" + str(route_family) <TAB>  <TAB> table_set = self._tables_for_rt.get(rt_rf_id) <MASK> table_set = set() <TAB>  <TAB>  <TAB> self._tables_for_rt[rt_rf_id] = table_set <TAB>  <TAB> table_set.add(vrf_table) <TAB>  <TAB> LOG.debug(""Added VrfTable %s to import RT table list: %s"", vrf_table, rt)",if table_set is None :,172
2541,"def add_tags( <TAB> self, cve_results: Dict[str, Dict[str, Dict[str, str]]], file_object: FileObject): <TAB> # results structure: {'component': {'cve_id': {'score2': '6.4', 'score3': 'N/A'}}} <TAB> for component in cve_results: <TAB>  <TAB> for cve_id in cve_results[component]: <TAB>  <TAB>  <TAB> entry = cve_results[component][cve_id] <MASK> self.add_analysis_tag( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> file_object, ""CVE"", ""critical CVE"", TagColor.RED, True <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> return",if self . _entry_has_critical_rating ( entry ) :,180
2542,"def _validate(self): <TAB> try: <TAB>  <TAB> super(CustomClassifier, self)._validate() <TAB> except UnsupportedDataType: <TAB>  <TAB> if self.dtype in FACTOR_DTYPES: <TAB>  <TAB>  <TAB> raise UnsupportedDataType( <TAB>  <TAB>  <TAB>  <TAB> typename=type(self).__name__, <TAB>  <TAB>  <TAB>  <TAB> dtype=self.dtype, <TAB>  <TAB>  <TAB>  <TAB> hint=""Did you mean to create a CustomFactor?"", <TAB>  <TAB>  <TAB> ) <MASK> raise UnsupportedDataType( <TAB>  <TAB>  <TAB>  <TAB> typename=type(self).__name__, <TAB>  <TAB>  <TAB>  <TAB> dtype=self.dtype, <TAB>  <TAB>  <TAB>  <TAB> hint=""Did you mean to create a CustomFilter?"", <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> raise",elif self . dtype in FILTER_DTYPES :,167
2543,"def formatMessage(self, record): <TAB> recordcopy = copy(record) <TAB> levelname = recordcopy.levelname <TAB> seperator = "" "" * (8 - len(recordcopy.levelname)) <TAB> if self.use_colors: <TAB>  <TAB> levelname = self.color_level_name(levelname, recordcopy.levelno) <MASK> recordcopy.msg = recordcopy.__dict__[""color_message""] <TAB>  <TAB>  <TAB> recordcopy.__dict__[""message""] = recordcopy.getMessage() <TAB> recordcopy.__dict__[""levelprefix""] = levelname + "":"" + seperator <TAB> return super().formatMessage(recordcopy)","if ""color_message"" in recordcopy . __dict__ :",152
2544,"def dumpregs(self): <TAB> for reg in ( <TAB>  <TAB> list(self.regs.retaddr) <TAB>  <TAB> + list(self.regs.misc) <TAB>  <TAB> + list(self.regs.common) <TAB>  <TAB> + list(self.regs.flags) <TAB> ): <TAB>  <TAB> enum = self.get_reg_enum(reg) <MASK> debug(""# Could not dump register %r"" % reg) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> name = ""U.x86_const.UC_X86_REG_%s"" % reg.upper() <TAB>  <TAB> value = self.uc.reg_read(enum) <TAB>  <TAB> debug(""uc.reg_read(%(name)s) ==> %(value)x"" % locals())",if not reg or enum is None :,177
2545,"def filter(self, lexer, stream): <TAB> current_type = None <TAB> current_value = None <TAB> for ttype, value in stream: <TAB>  <TAB> if ttype is current_type: <TAB>  <TAB>  <TAB> current_value += value <TAB>  <TAB> else: <MASK> yield current_type, current_value <TAB>  <TAB>  <TAB> current_type = ttype <TAB>  <TAB>  <TAB> current_value = value <TAB> if current_type is not None: <TAB>  <TAB> yield current_type, current_value",if current_type is not None :,121
2546,"def _get_between(content, start, end=None): <TAB> should_yield = False <TAB> for line in content.split(""\n""): <MASK> should_yield = True <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if end and end in line: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> if should_yield and line: <TAB>  <TAB>  <TAB> yield line.strip().split("" "")[0]",if start in line :,94
2547,"def parse_git_config(path): <TAB> """"""Parse git config file."""""" <TAB> config = dict() <TAB> section = None <TAB> with open(os.path.join(path, ""config""), ""r"") as f: <TAB>  <TAB> for line in f: <TAB>  <TAB>  <TAB> line = line.strip() <TAB>  <TAB>  <TAB> if line.startswith(""[""): <TAB>  <TAB>  <TAB>  <TAB> section = line[1:-1].strip() <TAB>  <TAB>  <TAB>  <TAB> config[section] = dict() <MASK> key, value = line.replace("" "", """").split(""="") <TAB>  <TAB>  <TAB>  <TAB> config[section][key] = value <TAB> return config",elif section :,146
2548,"def test_has_arg(fn, name, accept_all, expected): <TAB> if isinstance(fn, str): <TAB>  <TAB> context = dict() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> exec(""def {}: pass"".format(fn), context) <TAB>  <TAB> except SyntaxError: <MASK> raise <TAB>  <TAB>  <TAB> pytest.skip(""Function is not compatible with Python 2"") <TAB>  <TAB> # Sometimes exec adds builtins to the context <TAB>  <TAB> context.pop(""__builtins__"", None) <TAB>  <TAB> (fn,) = context.values() <TAB> assert has_arg(fn, name, accept_all) is expected","if sys . version_info >= ( 3 , ) :",147
2549,"def ObjectExpression(self, properties, **kwargs): <TAB> data = [] <TAB> for prop in properties: <TAB>  <TAB> self.emit(prop[""value""]) <MASK> raise NotImplementedError( <TAB>  <TAB>  <TAB>  <TAB> ""ECMA 5.1 does not support computed object properties!"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> data.append((to_key(prop[""key""]), prop[""kind""][0])) <TAB> self.emit(""LOAD_OBJECT"", tuple(data))","if prop [ ""computed"" ] :",108
2550,"def run(self): <TAB> for domain, locale, po in self.locales: <MASK> path = os.path.join(""locale"", locale, ""LC_MESSAGES"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> path = os.path.join(self.build_dir, locale, ""LC_MESSAGES"") <TAB>  <TAB> mo = os.path.join(path, ""%s.mo"" % domain) <TAB>  <TAB> self.mkpath(path) <TAB>  <TAB> self.spawn([""msgfmt"", ""-o"", mo, po])",if self . inplace :,128
2551,"def _compute_map(self, first_byte, second_byte=None): <TAB> if first_byte != 0x0F: <TAB>  <TAB> return ""XED_ILD_MAP0"" <TAB> else: <TAB>  <TAB> if second_byte == None: <TAB>  <TAB>  <TAB> return ""XED_ILD_MAP1"" <TAB>  <TAB> if second_byte == 0x38: <TAB>  <TAB>  <TAB> return ""XED_ILD_MAP2"" <MASK> return ""XED_ILD_MAP3"" <TAB>  <TAB> if second_byte == 0x0F and self.amd_enabled: <TAB>  <TAB>  <TAB> return ""XED_ILD_MAPAMD"" <TAB> die(""Unhandled escape {} / map {} bytes"".format(first_byte, second_byte))",if second_byte == 0x3A :,181
2552,"def parse_tag(self): <TAB> buf = [] <TAB> escaped = False <TAB> for c in self.get_next_chars(): <MASK> buf.append(c) <TAB>  <TAB> elif c == ""\\"": <TAB>  <TAB>  <TAB> escaped = True <TAB>  <TAB> elif c == "">"": <TAB>  <TAB>  <TAB> return """".join(buf) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> buf.append(c) <TAB> raise Exception(""Unclosed tag "" + """".join(buf))",if escaped :,110
2553,"def print_pairs(attrs=None, offset_y=0): <TAB> fmt = "" ({0}:{1}) "" <TAB> fmt_len = len(fmt) <TAB> for bg, fg in get_fg_bg(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> color = curses.color_pair(pair_number(fg, bg)) <MASK> for attr in attrs: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> color |= attr <TAB>  <TAB>  <TAB> screen.addstr(offset_y + bg, fg * fmt_len, fmt.format(fg, bg), color) <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> except curses.error: <TAB>  <TAB>  <TAB> pass",if not attrs is None :,152
2554,"def _impl(inputs, input_types): <TAB> data = inputs[0] <TAB> axis = None <TAB> keepdims = False <TAB> if len(inputs) > 2:  # default, torch have only data, axis=None, keepdims=False <MASK> axis = int(inputs[1]) <TAB>  <TAB> elif _is_int_seq(inputs[1]): <TAB>  <TAB>  <TAB> axis = inputs[1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> axis = list(_infer_shape(inputs[1])) <TAB>  <TAB> keepdims = bool(inputs[2]) <TAB> return get_relay_op(name)(data, axis=axis, keepdims=keepdims)","if isinstance ( inputs [ 1 ] , int ) :",158
2555,"def run(self, args, **kwargs): <TAB> # Filtering options <TAB> if args.trace_tag: <TAB>  <TAB> kwargs[""trace_tag""] = args.trace_tag <TAB> if args.trigger_instance: <TAB>  <TAB> kwargs[""trigger_instance""] = args.trigger_instance <TAB> if args.execution: <TAB>  <TAB> kwargs[""execution""] = args.execution <TAB> if args.rule: <TAB>  <TAB> kwargs[""rule""] = args.rule <TAB> if args.sort_order: <MASK> kwargs[""sort_asc""] = True <TAB>  <TAB> elif args.sort_order in [""desc"", ""descending""]: <TAB>  <TAB>  <TAB> kwargs[""sort_desc""] = True <TAB> return self.manager.query_with_count(limit=args.last, **kwargs)","if args . sort_order in [ ""asc"" , ""ascending"" ] :",188
2556,def retaddr(): <TAB> sp = pwndbg.regs.sp <TAB> stack = pwndbg.vmmap.find(sp) <TAB> # Enumerate all return addresses <TAB> frame = gdb.newest_frame() <TAB> addresses = [] <TAB> while frame: <TAB>  <TAB> addresses.append(frame.pc()) <TAB>  <TAB> frame = frame.older() <TAB> # Find all of them on the stack <TAB> start = stack.vaddr <TAB> stop = start + stack.memsz <TAB> while addresses and start < sp < stop: <TAB>  <TAB> value = pwndbg.memory.u(sp) <MASK> index = addresses.index(value) <TAB>  <TAB>  <TAB> del addresses[:index] <TAB>  <TAB>  <TAB> print(pwndbg.chain.format(sp)) <TAB>  <TAB> sp += pwndbg.arch.ptrsize,if value in addresses :,193
2557,"def update_from_dictio(self, dictio_item): <TAB> for index, dictio_payload in enumerate(dictio_item, 1): <TAB>  <TAB> fuzz_payload = None <TAB>  <TAB> for fuzz_payload in self.payloads[index]: <TAB>  <TAB>  <TAB> fuzz_payload.content = dictio_payload.content <TAB>  <TAB>  <TAB> fuzz_payload.type = dictio_payload.type <TAB>  <TAB> # payload generated not used in seed but in filters <MASK> self.add( <TAB>  <TAB>  <TAB>  <TAB> {""full_marker"": None, ""word"": None, ""index"": index, ""field"": None}, <TAB>  <TAB>  <TAB>  <TAB> dictio_item[index - 1], <TAB>  <TAB>  <TAB> )",if fuzz_payload is None :,169
2558,"def check_expected(result, expected, contains=False): <TAB> if sys.version_info[0] >= 3: <MASK> result = result.encode(""ascii"") <TAB>  <TAB> if isinstance(expected, str): <TAB>  <TAB>  <TAB> expected = expected.encode(""ascii"") <TAB> resultlines = result.splitlines() <TAB> expectedlines = expected.splitlines() <TAB> if len(resultlines) != len(expectedlines): <TAB>  <TAB> return False <TAB> for rline, eline in zip(resultlines, expectedlines): <TAB>  <TAB> if contains: <TAB>  <TAB>  <TAB> if eline not in rline: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if not rline.endswith(eline): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return True","if isinstance ( result , str ) :",181
2559,"def execute_sql(self, sql, params=None, commit=True): <TAB> try: <TAB>  <TAB> cursor = super(RetryOperationalError, self).execute_sql(sql, params, commit) <TAB> except OperationalError: <TAB>  <TAB> if not self.is_closed(): <TAB>  <TAB>  <TAB> self.close() <TAB>  <TAB> with __exception_wrapper__: <TAB>  <TAB>  <TAB> cursor = self.cursor() <TAB>  <TAB>  <TAB> cursor.execute(sql, params or ()) <MASK> self.commit() <TAB> return cursor",if commit and not self . in_transaction ( ) :,127
2560,"def get_operation_ast(document_ast, operation_name=None): <TAB> operation = None <TAB> for definition in document_ast.definitions: <TAB>  <TAB> if isinstance(definition, ast.OperationDefinition): <TAB>  <TAB>  <TAB> if not operation_name: <TAB>  <TAB>  <TAB>  <TAB> # If no operation name is provided, only return an Operation if it is the only one present in the <TAB>  <TAB>  <TAB>  <TAB> # document. This means that if we've encountered a second operation as we were iterating over the <TAB>  <TAB>  <TAB>  <TAB> # definitions in the document, there are more than one Operation defined, and we should return None. <MASK> return None <TAB>  <TAB>  <TAB>  <TAB> operation = definition <TAB>  <TAB>  <TAB> elif definition.name and definition.name.value == operation_name: <TAB>  <TAB>  <TAB>  <TAB> return definition <TAB> return operation",if operation :,186
2561,"def removeTrailingWs(self, aList): <TAB> i = 0 <TAB> while i < len(aList): <TAB>  <TAB> if self.is_ws(aList[i]): <TAB>  <TAB>  <TAB> j = i <TAB>  <TAB>  <TAB> i = self.skip_ws(aList, i) <TAB>  <TAB>  <TAB> assert j < i <MASK> # print ""removing trailing ws:"", `i-j` <TAB>  <TAB>  <TAB>  <TAB> del aList[j:i] <TAB>  <TAB>  <TAB>  <TAB> i = j <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> i += 1","if i >= len ( aList ) or aList [ i ] == ""\n"" :",147
2562,"def _process_filter(self, query, host_state): <TAB> """"""Recursively parse the query structure."""""" <TAB> if not query: <TAB>  <TAB> return True <TAB> cmd = query[0] <TAB> method = self.commands[cmd] <TAB> cooked_args = [] <TAB> for arg in query[1:]: <MASK> arg = self._process_filter(arg, host_state) <TAB>  <TAB> elif isinstance(arg, basestring): <TAB>  <TAB>  <TAB> arg = self._parse_string(arg, host_state) <TAB>  <TAB> if arg is not None: <TAB>  <TAB>  <TAB> cooked_args.append(arg) <TAB> result = method(self, cooked_args) <TAB> return result","if isinstance ( arg , list ) :",163
2563,"def handle_sent(self, elt): <TAB> sent = [] <TAB> for child in elt: <TAB>  <TAB> if child.tag in (""mw"", ""hi"", ""corr"", ""trunc""): <TAB>  <TAB>  <TAB> sent += [self.handle_word(w) for w in child] <TAB>  <TAB> elif child.tag in (""w"", ""c""): <TAB>  <TAB>  <TAB> sent.append(self.handle_word(child)) <MASK> raise ValueError(""Unexpected element %s"" % child.tag) <TAB> return BNCSentence(elt.attrib[""n""], sent)",elif child . tag not in self . tags_to_ignore :,141
2564,"def get_display_price( <TAB> base: Union[TaxedMoney, TaxedMoneyRange], display_gross: bool = False) -> Money: <TAB> """"""Return the price amount that should be displayed based on settings."""""" <TAB> if not display_gross: <TAB>  <TAB> display_gross = display_gross_prices() <TAB> if isinstance(base, TaxedMoneyRange): <MASK> base = MoneyRange(start=base.start.gross, stop=base.stop.gross) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> base = MoneyRange(start=base.start.net, stop=base.stop.net) <TAB> if isinstance(base, TaxedMoney): <TAB>  <TAB> base = base.gross if display_gross else base.net <TAB> return base",if display_gross :,164
2565,"def check_classes(self, node): <TAB> if isinstance(node, nodes.Element): <TAB>  <TAB> for class_value in node[""classes""][:]: <TAB>  <TAB>  <TAB> if class_value in self.strip_classes: <TAB>  <TAB>  <TAB>  <TAB> node[""classes""].remove(class_value) <MASK> return 1",if class_value in self . strip_elements :,86
2566,"def validate(outfile=sys.stdout, silent_success=False): <TAB> ""Validates all installed models."" <TAB> try: <TAB>  <TAB> num_errors = get_validation_errors(outfile) <MASK> return <TAB>  <TAB> outfile.write( <TAB>  <TAB>  <TAB> ""%s error%s found.\n"" % (num_errors, num_errors != 1 and ""s"" or """") <TAB>  <TAB> ) <TAB> except ImproperlyConfigured: <TAB>  <TAB> outfile.write(""Skipping validation because things aren't configured properly."")",if silent_success and num_errors == 0 :,124
2567,"def check_basename_conflicts(self, targets): <TAB> """"""Apps' basenames are used as bundle directory names. Ensure they are all unique."""""" <TAB> basename_seen = {} <TAB> for target in targets: <MASK> raise self.BasenameConflictError( <TAB>  <TAB>  <TAB>  <TAB> ""Basename must be unique, found two targets use "" <TAB>  <TAB>  <TAB>  <TAB> ""the same basename: {}'\n\t{} and \n\t{}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> target.basename, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> basename_seen[target.basename].address.spec, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> target.address.spec, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> basename_seen[target.basename] = target",if target . basename in basename_seen :,176
2568,"def __init__(self, api_version_str): <TAB> try: <TAB>  <TAB> self.latest = self.preview = False <TAB>  <TAB> self.yyyy = self.mm = self.dd = None <MASK> self.latest = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if ""preview"" in api_version_str: <TAB>  <TAB>  <TAB>  <TAB> self.preview = True <TAB>  <TAB>  <TAB> parts = api_version_str.split(""-"") <TAB>  <TAB>  <TAB> self.yyyy = int(parts[0]) <TAB>  <TAB>  <TAB> self.mm = int(parts[1]) <TAB>  <TAB>  <TAB> self.dd = int(parts[2]) <TAB> except (ValueError, TypeError): <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> ""The API version {} is not in a "" ""supported format"".format(api_version_str) <TAB>  <TAB> )","if api_version_str == ""latest"" :",199
2569,"def _osp2ec(self, bytes): <TAB> compressed = self._from_bytes(bytes) <TAB> y = compressed >> self._bits <TAB> x = compressed & (1 << self._bits) - 1 <TAB> if x == 0: <TAB>  <TAB> y = self._curve.b <TAB> else: <TAB>  <TAB> result = self.sqrtp( <TAB>  <TAB>  <TAB> x ** 3 + self._curve.a * x + self._curve.b, self._curve.field.p <TAB>  <TAB> ) <MASK> y = result[0] <TAB>  <TAB> elif len(result) == 2: <TAB>  <TAB>  <TAB> y1, y2 = result <TAB>  <TAB>  <TAB> y = y1 if (y1 & 1 == y) else y2 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return None <TAB> return ec.Point(self._curve, x, y)",if len ( result ) == 1 :,200
2570,"def _visit_import_alike(self, node: Union[cst.Import, cst.ImportFrom]) -> bool: <TAB> names = node.names <TAB> if isinstance(names, cst.ImportStar): <TAB>  <TAB> return False <TAB> # make sure node.names is Sequence[ImportAlias] <TAB> for name in names: <TAB>  <TAB> self.provider.set_metadata(name, self.scope) <TAB>  <TAB> asname = name.asname <MASK> name_values = _gen_dotted_names(cst.ensure_type(asname.name, cst.Name)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name_values = _gen_dotted_names(name.name) <TAB>  <TAB> for name_value, _ in name_values: <TAB>  <TAB>  <TAB> self.scope.record_assignment(name_value, node) <TAB> return False",if asname is not None :,200
2571,"def test_sanity_no_unmatched_parentheses(CorpusType: Type[ColumnCorpus]): <TAB> corpus = CorpusType() <TAB> unbalanced_entities = [] <TAB> for sentence in corpus.get_all_sentences(): <TAB>  <TAB> entities = sentence.get_spans(""ner"") <TAB>  <TAB> for entity in entities: <TAB>  <TAB>  <TAB> entity_text = """".join(t.text for t in entity.tokens) <MASK> unbalanced_entities.append(entity_text) <TAB> assert unbalanced_entities == []",if not has_balanced_parantheses ( entity_text ) :,128
2572,"def _learn_rate_adjust(self): <TAB> if self.learn_rate_decays == 1.0: <TAB>  <TAB> return <TAB> learn_rate_decays = self._vp(self.learn_rate_decays) <TAB> learn_rate_minimums = self._vp(self.learn_rate_minimums) <TAB> for index, decay in enumerate(learn_rate_decays): <TAB>  <TAB> new_learn_rate = self.net_.learnRates[index] * decay <MASK> self.net_.learnRates[index] = new_learn_rate <TAB> if self.verbose >= 2: <TAB>  <TAB> print(""Learn rates: {}"".format(self.net_.learnRates))",if new_learn_rate >= learn_rate_minimums [ index ] :,176
2573,"def set_attr_from_xmp_tag(self, attr, xmp_tags, tags, cast=None): <TAB> v = self.get_xmp_tag(xmp_tags, tags) <TAB> if v is not None: <MASK> setattr(self, attr, v) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Handle fractions <TAB>  <TAB>  <TAB> if (cast == float or cast == int) and ""/"" in v: <TAB>  <TAB>  <TAB>  <TAB> v = self.try_parse_fraction(v) <TAB>  <TAB>  <TAB> setattr(self, attr, cast(v))",if cast is None :,139
2574,"def _merge_scientific_float_tokens(tokens: Iterable[str]) -> List[str]: <TAB> tokens = list(tokens) <TAB> i = 0 <TAB> while ""e"" in tokens[i + 1 :]: <TAB>  <TAB> i = tokens.index(""e"", i + 1) <TAB>  <TAB> s = i - 1 <TAB>  <TAB> e = i + 1 <MASK> continue <TAB>  <TAB> if re.match(""[+-]"", str(tokens[e])): <TAB>  <TAB>  <TAB> e += 1 <TAB>  <TAB> if re.match(""[0-9]"", str(tokens[e])): <TAB>  <TAB>  <TAB> e += 1 <TAB>  <TAB>  <TAB> tokens[s:e] = ["""".join(tokens[s:e])] <TAB>  <TAB>  <TAB> i -= 1 <TAB> return tokens","if not re . match ( ""[0-9]"" , str ( tokens [ s ] ) ) :",184
2575,"def anypython(request): <TAB> name = request.param <TAB> executable = getexecutable(name) <TAB> if executable is None: <MASK> executable = winpymap.get(name, None) <TAB>  <TAB>  <TAB> if executable: <TAB>  <TAB>  <TAB>  <TAB> executable = py.path.local(executable) <TAB>  <TAB>  <TAB>  <TAB> if executable.check(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return executable <TAB>  <TAB> pytest.skip(""no suitable %s found"" % (name,)) <TAB> return executable","if sys . platform == ""win32"" :",119
2576,"def set_meta(self, dataset, overwrite=True, **kwd): <TAB> super().set_meta(dataset, overwrite=overwrite, **kwd) <TAB> try: <MASK> with tarfile.open(dataset.file_name, ""r"") as temptar: <TAB>  <TAB>  <TAB>  <TAB> dataset.metadata.fast5_count = sum( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> 1 for f in temptar if f.name.endswith("".fast5"") <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> except Exception as e: <TAB>  <TAB> log.warning(""%s, set_meta Exception: %s"", self, e)",if dataset and tarfile . is_tarfile ( dataset . file_name ) :,150
2577,"def run(self): <TAB> for k in list(iterkeys(self.objs)): <MASK> continue <TAB>  <TAB> v = self.objs[k] <TAB>  <TAB> if v[""_class""] == ""User"": <TAB>  <TAB>  <TAB> self.split_user(k, v) <TAB>  <TAB> elif v[""_class""] in [ <TAB>  <TAB>  <TAB> ""Message"", <TAB>  <TAB>  <TAB> ""PrintJob"", <TAB>  <TAB>  <TAB> ""Question"", <TAB>  <TAB>  <TAB> ""Submission"", <TAB>  <TAB>  <TAB> ""UserTest"", <TAB>  <TAB> ]: <TAB>  <TAB>  <TAB> v[""participation""] = v[""user""] <TAB>  <TAB>  <TAB> del v[""user""] <TAB> return self.objs","if k . startswith ( ""_"" ) :",150
2578,"def _findInTree(t, n): <TAB> ret = [] <TAB> if type(t) is dict: <MASK> ret.append(t) <TAB>  <TAB> for k, v in t.items(): <TAB>  <TAB>  <TAB> ret += _findInTree(v, n) <TAB> if type(t) is list: <TAB>  <TAB> for v in t: <TAB>  <TAB>  <TAB> ret += _findInTree(v, n) <TAB> return ret","if ""_name"" in t and t [ ""_name"" ] == n :",117
2579,"def parseArrayPattern(self): <TAB> node = Node() <TAB> elements = [] <TAB> self.expect(""["") <TAB> while not self.match(""]""): <MASK> self.lex() <TAB>  <TAB>  <TAB> elements.append(null) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if self.match(""...""): <TAB>  <TAB>  <TAB>  <TAB> restNode = Node() <TAB>  <TAB>  <TAB>  <TAB> self.lex() <TAB>  <TAB>  <TAB>  <TAB> rest = self.parseVariableIdentifier() <TAB>  <TAB>  <TAB>  <TAB> elements.append(restNode.finishRestElement(rest)) <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> elements.append(self.parsePatternWithDefault()) <TAB>  <TAB>  <TAB> if not self.match(""]""): <TAB>  <TAB>  <TAB>  <TAB> self.expect("","") <TAB> self.expect(""]"") <TAB> return node.finishArrayPattern(elements)","if self . match ( "","" ) :",190
2580,"def _set_log_writer(self): <TAB> if self.config[""logging""]: <TAB>  <TAB> config = self.config[""log_writer_config""] <MASK> self.log_writer = LogWriter(**config) <TAB>  <TAB> elif config[""writer""] == ""tensorboard"": <TAB>  <TAB>  <TAB> self.log_writer = TensorBoardWriter(**config) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(f""Unrecognized writer option: {config['writer']}"") <TAB> else: <TAB>  <TAB> self.log_writer = None","if config [ ""writer"" ] == ""json"" :",127
2581,"def _parse(self, contents): <TAB> entries = [] <TAB> hostnames_found = set() <TAB> for line in contents.splitlines(): <MASK> entries.append((""blank"", [line])) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> (head, tail) = chop_comment(line.strip(), ""#"") <TAB>  <TAB> if not len(head): <TAB>  <TAB>  <TAB> entries.append((""all_comment"", [line])) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> entries.append((""hostname"", [head, tail])) <TAB>  <TAB> hostnames_found.add(head) <TAB> if len(hostnames_found) > 1: <TAB>  <TAB> raise IOError(""Multiple hostnames (%s) found!"" % (hostnames_found)) <TAB> return entries",if not len ( line . strip ( ) ) :,167
2582,"def get_all_values(self, project): <TAB> if isinstance(project, models.Model): <TAB>  <TAB> project_id = project.id <TAB> else: <TAB>  <TAB> project_id = project <TAB> if project_id not in self.__cache: <TAB>  <TAB> cache_key = self._make_key(project_id) <TAB>  <TAB> result = cache.get(cache_key) <MASK> result = self.reload_cache(project_id) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.__cache[project_id] = result <TAB> return self.__cache.get(project_id, {})",if result is None :,144
2583,"def needed_libraries(self): <TAB> for cmd in self.load_commands_of_type(0xC):  # LC_LOAD_DYLIB <TAB>  <TAB> tname = self._get_typename(""dylib_command"") <TAB>  <TAB> dylib_command = cmd.cast(tname) <TAB>  <TAB> name_addr = cmd.obj_offset + dylib_command.name <TAB>  <TAB> dylib_name = self.obj_vm.read(name_addr, 256) <MASK> idx = dylib_name.find(""\x00"") <TAB>  <TAB>  <TAB> if idx != -1: <TAB>  <TAB>  <TAB>  <TAB> dylib_name = dylib_name[:idx] <TAB>  <TAB>  <TAB> yield dylib_name",if dylib_name :,164
2584,"def compress(self, data_list): <TAB> warn_untested() <TAB> if data_list: <MASK> error = self.error_messages[""invalid_year""] <TAB>  <TAB>  <TAB> raise forms.ValidationError(error) <TAB>  <TAB> if data_list[0] in forms.fields.EMPTY_VALUES: <TAB>  <TAB>  <TAB> error = self.error_messages[""invalid_month""] <TAB>  <TAB>  <TAB> raise forms.ValidationError(error) <TAB>  <TAB> year = int(data_list[1]) <TAB>  <TAB> month = int(data_list[0]) <TAB>  <TAB> # find last day of the month <TAB>  <TAB> day = monthrange(year, month)[1] <TAB>  <TAB> return date(year, month, day) <TAB> return None",if data_list [ 1 ] in forms . fields . EMPTY_VALUES :,181
2585,"def put(self, obj, block=True, timeout=None): <TAB> assert not self._closed <TAB> if not self._sem.acquire(block, timeout): <TAB>  <TAB> raise Full <TAB> with self._notempty: <TAB>  <TAB> with self._cond: <MASK> self._start_thread() <TAB>  <TAB>  <TAB> self._buffer.append(obj) <TAB>  <TAB>  <TAB> self._unfinished_tasks.release() <TAB>  <TAB>  <TAB> self._notempty.notify()",if self . _thread is None :,115
2586,"def has_module(self, module, version): <TAB> has_module = False <TAB> for directory in self.directories: <TAB>  <TAB> module_directory = join(directory, module) <TAB>  <TAB> has_module_directory = isdir(module_directory) <TAB>  <TAB> if not version: <TAB>  <TAB>  <TAB> has_module = has_module_directory or exists( <TAB>  <TAB>  <TAB>  <TAB> module_directory <TAB>  <TAB>  <TAB> )  # could be a bare modulefile <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> modulefile = join(module_directory, version) <TAB>  <TAB>  <TAB> has_modulefile = exists(modulefile) <TAB>  <TAB>  <TAB> has_module = has_module_directory and has_modulefile <MASK> break <TAB> return has_module",if has_module :,171
2587,"def expanduser(path): <TAB> if path[:1] == ""~"": <TAB>  <TAB> c = path[1:2] <MASK> return gethome() <TAB>  <TAB> if c == os.sep: <TAB>  <TAB>  <TAB> return asPyString(File(gethome(), path[2:]).getPath()) <TAB> return path",if not c :,76
2588,"def mock_touch(self, bearer, version=None, revision=None, **kwargs): <TAB> if version: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> return self.versions[int(version) - 1] <TAB>  <TAB>  <TAB> except (IndexError, ValueError): <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return None <TAB> return file_models.FileVersion()",if self . versions :,95
2589,"def _get_field_value(self, test, key, match): <TAB> if test.ver == ofproto_v1_0.OFP_VERSION: <TAB>  <TAB> members = inspect.getmembers(match) <TAB>  <TAB> for member in members: <TAB>  <TAB>  <TAB> if member[0] == key: <TAB>  <TAB>  <TAB>  <TAB> field_value = member[1] <MASK> wildcards = member[1] <TAB>  <TAB> if key == ""nw_src"": <TAB>  <TAB>  <TAB> field_value = test.nw_src_to_str(wildcards, field_value) <TAB>  <TAB> elif key == ""nw_dst"": <TAB>  <TAB>  <TAB> field_value = test.nw_dst_to_str(wildcards, field_value) <TAB> else: <TAB>  <TAB> field_value = match[key] <TAB> return field_value","elif member [ 0 ] == ""wildcards"" :",200
2590,"def check_expected(result, expected, contains=False): <TAB> if sys.version_info[0] >= 3: <TAB>  <TAB> if isinstance(result, str): <TAB>  <TAB>  <TAB> result = result.encode(""ascii"") <TAB>  <TAB> if isinstance(expected, str): <TAB>  <TAB>  <TAB> expected = expected.encode(""ascii"") <TAB> resultlines = result.splitlines() <TAB> expectedlines = expected.splitlines() <TAB> if len(resultlines) != len(expectedlines): <TAB>  <TAB> return False <TAB> for rline, eline in zip(resultlines, expectedlines): <MASK> if eline not in rline: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if not rline.endswith(eline): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return True",if contains :,181
2591,"def OnKeyUp(self, event): <TAB> if self._properties.modifiable: <TAB>  <TAB> if event.GetKeyCode() == wx.WXK_ESCAPE: <TAB>  <TAB>  <TAB> self._cancel_editing() <MASK> self._update_value() <TAB>  <TAB> elif event.GetKeyCode() == wx.WXK_DELETE: <TAB>  <TAB>  <TAB> self.SetValue("""") <TAB> if event.GetKeyCode() != wx.WXK_RETURN: <TAB>  <TAB> # Don't send skip event if enter key is pressed <TAB>  <TAB> # On some platforms this event is sent too late and causes crash <TAB>  <TAB> event.Skip()",elif event . GetKeyCode ( ) == wx . WXK_RETURN :,145
2592,"def load_modules( <TAB> to_load, load, attr, modules_dict, excluded_aliases, loading_message=None): <TAB> if loading_message: <TAB>  <TAB> print(loading_message) <TAB> for name in to_load: <TAB>  <TAB> module = load(name) <MASK> continue <TAB>  <TAB> cls = getattr(module, attr) <TAB>  <TAB> if hasattr(cls, ""initialize"") and not cls.initialize(): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if hasattr(module, ""aliases""): <TAB>  <TAB>  <TAB> for alias in module.aliases(): <TAB>  <TAB>  <TAB>  <TAB> if alias not in excluded_aliases: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> modules_dict[alias] = module <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> modules_dict[name] = module <TAB> if loading_message: <TAB>  <TAB> print()","if module is None or not hasattr ( module , attr ) :",195
2593,def eventIterator(): <TAB> while True: <TAB>  <TAB> yield eventmodule.wait() <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> event = eventmodule.poll() <MASK> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield event,if event . type == NOEVENT :,67
2594,"def _get_state_without_padding(self, state_with_padding, padding): <TAB> lean_state = {} <TAB> for key, value in state_with_padding.items(): <MASK> lean_length = value.numel() - padding <TAB>  <TAB>  <TAB> lean_state[key] = value[:lean_length] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lean_state[key] = value <TAB> return lean_state",if torch . is_tensor ( value ) :,110
2595,"def _get_validate(data): <TAB> """"""Retrieve items to validate, from single samples or from combined joint calls."""""" <TAB> if data.get(""vrn_file"") and tz.get_in([""config"", ""algorithm"", ""validate""], data): <TAB>  <TAB> return utils.deepish_copy(data) <TAB> elif ""group_orig"" in data: <TAB>  <TAB> for sub in multi.get_orig_items(data): <MASK> sub_val = utils.deepish_copy(sub) <TAB>  <TAB>  <TAB>  <TAB> sub_val[""vrn_file""] = data[""vrn_file""] <TAB>  <TAB>  <TAB>  <TAB> return sub_val <TAB> return None","if ""validate"" in sub [ ""config"" ] [ ""algorithm"" ] :",163
2596,"def OnPopup(self, form, popup_handle): <TAB> for num, action_name, menu_name, shortcut in self.actions: <MASK> ida_kernwin.attach_action_to_popup(form, popup_handle, None) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> handler = command_handler_t(self, num, 2) <TAB>  <TAB>  <TAB> desc = ida_kernwin.action_desc_t(action_name, menu_name, handler, shortcut) <TAB>  <TAB>  <TAB> ida_kernwin.attach_dynamic_action_to_popup(form, popup_handle, desc)",if menu_name is None :,153
2597,"def show(self, indent=0): <TAB> """"""Pretty print this structure."""""" <TAB> if indent == 0: <TAB>  <TAB> print(""struct {}"".format(self.name)) <TAB> for field in self.fields: <MASK> offset = ""0x??"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> offset = ""0x{:02x}"".format(field.offset) <TAB>  <TAB> print(""{}+{} {} {}"".format("" "" * indent, offset, field.name, field.type)) <TAB>  <TAB> if isinstance(field.type, Structure): <TAB>  <TAB>  <TAB> field.type.show(indent + 1)",if field . offset is None :,143
2598,"def get_operation_ast(document_ast, operation_name=None): <TAB> operation = None <TAB> for definition in document_ast.definitions: <MASK> if not operation_name: <TAB>  <TAB>  <TAB>  <TAB> # If no operation name is provided, only return an Operation if it is the only one present in the <TAB>  <TAB>  <TAB>  <TAB> # document. This means that if we've encountered a second operation as we were iterating over the <TAB>  <TAB>  <TAB>  <TAB> # definitions in the document, there are more than one Operation defined, and we should return None. <TAB>  <TAB>  <TAB>  <TAB> if operation: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB>  <TAB>  <TAB> operation = definition <TAB>  <TAB>  <TAB> elif definition.name and definition.name.value == operation_name: <TAB>  <TAB>  <TAB>  <TAB> return definition <TAB> return operation","if isinstance ( definition , ast . OperationDefinition ) :",186
2599,"def getSubMenu(self, callingWindow, context, mainItem, selection, rootMenu, i, pitem): <TAB> msw = True if ""wxMSW"" in wx.PlatformInfo else False <TAB> self.context = context <TAB> self.abilityIds = {} <TAB> sub = wx.Menu() <TAB> for ability in self.fighter.abilities: <MASK> continue <TAB>  <TAB> menuItem = self.addAbility(rootMenu if msw else sub, ability) <TAB>  <TAB> sub.Append(menuItem) <TAB>  <TAB> menuItem.Check(ability.active) <TAB> return sub",if not ability . effect . isImplemented :,143
2600,"def consume(self, event: Dict[str, Any]) -> None: <TAB> with self.lock: <TAB>  <TAB> logging.debug(""Received missedmessage_emails event: %s"", event) <TAB>  <TAB> # When we process an event, just put it into the queue and ensure we have a timer going. <TAB>  <TAB> user_profile_id = event[""user_profile_id""] <MASK> self.batch_start_by_recipient[user_profile_id] = time.time() <TAB>  <TAB> self.events_by_recipient[user_profile_id].append(event) <TAB>  <TAB> self.ensure_timer()",if user_profile_id not in self . batch_start_by_recipient :,160
2601,"def __init__(self, start_enabled=False, use_hardware=True): <TAB> self._use_hardware = use_hardware <TAB> if use_hardware: <TAB>  <TAB> self._button = Button(BUTTON_GPIO_PIN) <TAB>  <TAB> self._enabled = start_enabled <MASK> self._button.when_pressed = self._enable",if not start_enabled :,87
2602,"def execute(cls, ctx, op: ""DataFrameGroupByAgg""): <TAB> try: <TAB>  <TAB> pd.set_option(""mode.use_inf_as_na"", op.use_inf_as_na) <MASK> cls._execute_map(ctx, op) <TAB>  <TAB> elif op.stage == OperandStage.combine: <TAB>  <TAB>  <TAB> cls._execute_combine(ctx, op) <TAB>  <TAB> elif op.stage == OperandStage.agg: <TAB>  <TAB>  <TAB> cls._execute_agg(ctx, op) <TAB>  <TAB> else:  # pragma: no cover <TAB>  <TAB>  <TAB> raise ValueError(""Aggregation operand not executable"") <TAB> finally: <TAB>  <TAB> pd.reset_option(""mode.use_inf_as_na"")",if op . stage == OperandStage . map :,171
2603,"def load_package(name, path): <TAB> if os.path.isdir(path): <TAB>  <TAB> extensions = machinery.SOURCE_SUFFIXES[:] + machinery.BYTECODE_SUFFIXES[:] <TAB>  <TAB> for extension in extensions: <TAB>  <TAB>  <TAB> init_path = os.path.join(path, ""__init__"" + extension) <MASK> path = init_path <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""{!r} is not a package"".format(path)) <TAB> spec = util.spec_from_file_location(name, path, submodule_search_locations=[]) <TAB> if name in sys.modules: <TAB>  <TAB> return _exec(spec, sys.modules[name]) <TAB> else: <TAB>  <TAB> return _load(spec)",if os . path . exists ( init_path ) :,187
2604,def setup(level=None): <TAB> from pipeline.logging import pipeline_logger as logger <TAB> from pipeline.log.handlers import EngineLogHandler <TAB> if level in set(logging._levelToName.values()): <TAB>  <TAB> logger.setLevel(level) <TAB> logging._acquireLock() <TAB> try: <TAB>  <TAB> for hdl in logger.handlers: <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> hdl = EngineLogHandler() <TAB>  <TAB>  <TAB> hdl.setLevel(logger.level) <TAB>  <TAB>  <TAB> logger.addHandler(hdl) <TAB> finally: <TAB>  <TAB> logging._releaseLock(),"if isinstance ( hdl , EngineLogHandler ) :",150
2605,"def find_approximant(x): <TAB> c = 1e-4 <TAB> it = sympy.ntheory.continued_fraction_convergents( <TAB>  <TAB> sympy.ntheory.continued_fraction_iterator(x) <TAB> ) <TAB> for i in it: <TAB>  <TAB> p, q = i.as_numer_denom() <TAB>  <TAB> tol = c / q ** 2 <TAB>  <TAB> if abs(i - x) <= tol: <TAB>  <TAB>  <TAB> return i <MASK> break <TAB> return x",if tol < machine_epsilon :,122
2606,"def resolve( <TAB> self, debug: bool = False, silent: bool = False, level: Optional[int] = None) -> bool: <TAB> if silent: <TAB>  <TAB> spinner = nullcontext(type(""Mock"", (), {})) <TAB> else: <TAB>  <TAB> spinner = yaspin(text=""resolving..."") <TAB> with spinner as spinner: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> resolved = self._resolve( <TAB>  <TAB>  <TAB>  <TAB> debug=debug, silent=silent, level=level, spinner=spinner <TAB>  <TAB>  <TAB> ) <MASK> continue <TAB>  <TAB>  <TAB> self.graph.clear()  # remove unused deps from graph <TAB>  <TAB>  <TAB> return resolved",if resolved is None :,158
2607,"def canonicalize_instruction_name(instr): <TAB> name = instr.insn_name().upper() <TAB> # XXX bypass a capstone bug that incorrectly labels some insns as mov <TAB> if name == ""MOV"": <MASK> return ""LSR"" <TAB>  <TAB> elif instr.mnemonic.startswith(""lsl""): <TAB>  <TAB>  <TAB> return ""LSL"" <TAB>  <TAB> elif instr.mnemonic.startswith(""asr""): <TAB>  <TAB>  <TAB> return ""ASR"" <TAB> return OP_NAME_MAP.get(name, name)","if instr . mnemonic . startswith ( ""lsr"" ) :",135
2608,"def run_all(rule_list, defined_variables, defined_actions, stop_on_first_trigger=False): <TAB> rule_was_triggered = False <TAB> for rule in rule_list: <TAB>  <TAB> result = run(rule, defined_variables, defined_actions) <TAB>  <TAB> if result: <TAB>  <TAB>  <TAB> rule_was_triggered = True <MASK> return True <TAB> return rule_was_triggered",if stop_on_first_trigger :,108
2609,"def get_filters(self, request): <TAB> filter_specs = [] <TAB> if self.lookup_opts.admin.list_filter and not self.opts.one_to_one_field: <TAB>  <TAB> filter_fields = [ <TAB>  <TAB>  <TAB> self.lookup_opts.get_field(field_name) <TAB>  <TAB>  <TAB> for field_name in self.lookup_opts.admin.list_filter <TAB>  <TAB> ] <TAB>  <TAB> for f in filter_fields: <TAB>  <TAB>  <TAB> spec = FilterSpec.create(f, request, self.params, self.model) <MASK> filter_specs.append(spec) <TAB> return filter_specs, bool(filter_specs)",if spec and spec . has_output ( ) :,167
2610,"def get_type(type_ref): <TAB> kind = type_ref.get(""kind"") <TAB> if kind == TypeKind.LIST: <TAB>  <TAB> item_ref = type_ref.get(""ofType"") <MASK> raise Exception(""Decorated type deeper than introspection query."") <TAB>  <TAB> return GraphQLList(get_type(item_ref)) <TAB> elif kind == TypeKind.NON_NULL: <TAB>  <TAB> nullable_ref = type_ref.get(""ofType"") <TAB>  <TAB> if not nullable_ref: <TAB>  <TAB>  <TAB> raise Exception(""Decorated type deeper than introspection query."") <TAB>  <TAB> return GraphQLNonNull(get_type(nullable_ref)) <TAB> return get_named_type(type_ref[""name""])",if not item_ref :,171
2611,"def _1_0_cloud_ips_cip_jsjc5_map(self, method, url, body, headers): <TAB> if method == ""POST"": <TAB>  <TAB> body = json.loads(body) <MASK> return self.test_response(httplib.ACCEPTED, """") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> data = '{""error_name"":""bad destination"", ""errors"": [""Bad destination""]}' <TAB>  <TAB>  <TAB> return self.test_response(httplib.BAD_REQUEST, data)","if ""destination"" in body :",126
2612,"def _get_prefixed_values(data, prefix): <TAB> """"""Collect lines which start with prefix; with trimming"""""" <TAB> matches = [] <TAB> for line in data.splitlines(): <TAB>  <TAB> line = line.strip() <MASK> match = line[len(prefix) :] <TAB>  <TAB>  <TAB> match = match.strip() <TAB>  <TAB>  <TAB> matches.append(match) <TAB> return matches",if line . startswith ( prefix ) :,97
2613,"def _power_exact(y, xc, yc, xe): <TAB> yc, ye = y.int, y.exp <TAB> while yc % 10 == 0: <TAB>  <TAB> yc //= 10 <TAB>  <TAB> ye += 1 <TAB> if xc == 1: <TAB>  <TAB> xe *= yc <TAB>  <TAB> while xe % 10 == 0: <TAB>  <TAB>  <TAB> xe //= 10 <TAB>  <TAB>  <TAB> ye += 1 <MASK> return None <TAB>  <TAB> exponent = xe * 10 ** ye <TAB>  <TAB> if y and xe: <TAB>  <TAB>  <TAB> xc = exponent <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> xc = 0 <TAB>  <TAB> return 5",if ye < 0 :,144
2614,"def init(self, view, items=None): <TAB> selections = [] <TAB> if view.sel(): <TAB>  <TAB> for region in view.sel(): <TAB>  <TAB>  <TAB> selections.append(view.substr(region)) <TAB> values = [] <TAB> for idx, index in enumerate(map(int, items)): <TAB>  <TAB> if idx >= len(selections): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> i = index - 1 <TAB>  <TAB> if i >= 0 and i < len(selections): <TAB>  <TAB>  <TAB> values.append(selections[i]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> values.append(None) <TAB> # fill up <TAB> for idx, value in enumerate(selections): <MASK> values.append(value) <TAB> self.stack = values",if len ( values ) + 1 < idx :,178
2615,"def toggleFactorReload(self, value=None): <TAB> self.serviceFittingOptions[""useGlobalForceReload""] = ( <TAB>  <TAB> value <TAB>  <TAB> if value is not None <TAB>  <TAB> else not self.serviceFittingOptions[""useGlobalForceReload""] <TAB> ) <TAB> fitIDs = set() <TAB> for fit in set(self._loadedFits): <TAB>  <TAB> if fit is None: <TAB>  <TAB>  <TAB> continue <MASK> fit.factorReload = self.serviceFittingOptions[""useGlobalForceReload""] <TAB>  <TAB>  <TAB> fit.clearFactorReloadDependentData() <TAB>  <TAB>  <TAB> fitIDs.add(fit.ID) <TAB> return fitIDs",if fit . calculated :,149
2616,"def init_weights(self): <TAB> """"""Initialize model weights."""""" <TAB> for m in self.predict_layers.modules(): <TAB>  <TAB> if isinstance(m, nn.Conv2d): <TAB>  <TAB>  <TAB> kaiming_init(m) <MASK> constant_init(m, 1) <TAB>  <TAB> elif isinstance(m, nn.Linear): <TAB>  <TAB>  <TAB> normal_init(m, std=0.01)","elif isinstance ( m , nn . BatchNorm2d ) :",107
2617,"def _unzip_file(self, filepath, ext): <TAB> try: <MASK> zf = zipfile.ZipFile(filepath) <TAB>  <TAB>  <TAB> zf.extractall(os.path.dirname(filepath)) <TAB>  <TAB>  <TAB> zf.close() <TAB>  <TAB> elif ext == "".tar"": <TAB>  <TAB>  <TAB> tf = tarfile.open(filepath) <TAB>  <TAB>  <TAB> tf.extractall(os.path.dirname(filepath)) <TAB>  <TAB>  <TAB> tf.close() <TAB> except Exception as e: <TAB>  <TAB> raise ValueError(""Error reading file %r!\n%s"" % (filepath, e))","if ext == "".zip"" :",136
2618,"def add_multiple_tasks(data, parent): <TAB> data = json.loads(data) <TAB> new_doc = { <TAB>  <TAB> ""doctype"": ""Task"", <TAB>  <TAB> ""parent_task"": parent if parent != ""All Tasks"" else """", <TAB> } <TAB> new_doc[""project""] = frappe.db.get_value(""Task"", {""name"": parent}, ""project"") or """" <TAB> for d in data: <MASK> continue <TAB>  <TAB> new_doc[""subject""] = d.get(""subject"") <TAB>  <TAB> new_task = frappe.get_doc(new_doc) <TAB>  <TAB> new_task.insert()","if not d . get ( ""subject"" ) :",158
2619,"def filterSimilarKeywords(keyword, kwdsIterator): <TAB> """"""Return a sorted list of keywords similar to the one given."""""" <TAB> seenDict = {} <TAB> kwdSndx = soundex(keyword.encode(""ascii"", ""ignore"")) <TAB> matches = [] <TAB> matchesappend = matches.append <TAB> checkContained = False <TAB> if len(keyword) > 4: <TAB>  <TAB> checkContained = True <TAB> for movieID, key in kwdsIterator: <MASK> continue <TAB>  <TAB> seenDict[key] = None <TAB>  <TAB> if checkContained and keyword in key: <TAB>  <TAB>  <TAB> matchesappend(key) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if kwdSndx == soundex(key.encode(""ascii"", ""ignore"")): <TAB>  <TAB>  <TAB> matchesappend(key) <TAB> return _sortKeywords(keyword, matches)",if key in seenDict :,193
2620,"def visit_If(self, node): <TAB> self.newline() <TAB> self.write(""if "") <TAB> self.visit(node.test) <TAB> self.write("":"") <TAB> self.body(node.body) <TAB> while True: <TAB>  <TAB> else_ = node.orelse <MASK> node = else_[0] <TAB>  <TAB>  <TAB> self.newline() <TAB>  <TAB>  <TAB> self.write(""elif "") <TAB>  <TAB>  <TAB> self.visit(node.test) <TAB>  <TAB>  <TAB> self.write("":"") <TAB>  <TAB>  <TAB> self.body(node.body) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.newline() <TAB>  <TAB>  <TAB> self.write(""else:"") <TAB>  <TAB>  <TAB> self.body(else_) <TAB>  <TAB>  <TAB> break","if len ( else_ ) == 1 and isinstance ( else_ [ 0 ] , If ) :",181
2621,"def _eyeLinkHardwareAndSoftwareVersion(self): <TAB> try: <TAB>  <TAB> tracker_software_ver = 0 <TAB>  <TAB> eyelink_ver = self._eyelink.getTrackerVersion() <MASK> tvstr = self._eyelink.getTrackerVersionString() <TAB>  <TAB>  <TAB> vindex = tvstr.find(""EYELINK CL"") <TAB>  <TAB>  <TAB> tracker_software_ver = int( <TAB>  <TAB>  <TAB>  <TAB> float(tvstr[(vindex + len(""EYELINK CL"")) :].strip()) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return eyelink_ver, tracker_software_ver <TAB> except Exception: <TAB>  <TAB> print2err(""EYELINK Error during _eyeLinkHardwareAndSoftwareVersion:"") <TAB>  <TAB> printExceptionDetailsToStdErr() <TAB>  <TAB> return EyeTrackerConstants.EYETRACKER_ERROR",if eyelink_ver == 3 :,200
2622,"def execute(self, context): <TAB> for monad in context.blend_data.node_groups: <TAB>  <TAB> if monad.bl_idname == ""SverchGroupTreeType"": <MASK> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> monad.update_cls() <TAB>  <TAB>  <TAB>  <TAB> except Exception as err: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> print(err) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> print(""{} group class could not be created"".format(monad.name)) <TAB> return {""FINISHED""}","if not getattr ( bpy . types , monad . cls_bl_idname , None ) :",137
2623,"def word_pattern(pattern, str): <TAB> dict = {} <TAB> set_value = set() <TAB> list_str = str.split() <TAB> if len(list_str) != len(pattern): <TAB>  <TAB> return False <TAB> for i in range(len(pattern)): <TAB>  <TAB> if pattern[i] not in dict: <TAB>  <TAB>  <TAB> if list_str[i] in set_value: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> dict[pattern[i]] = list_str[i] <TAB>  <TAB>  <TAB> set_value.add(list_str[i]) <TAB>  <TAB> else: <MASK> return False <TAB> return True",if dict [ pattern [ i ] ] != list_str [ i ] :,165
2624,"def decorator_handle(tokens): <TAB> """"""Process decorators."""""" <TAB> defs = [] <TAB> decorates = [] <TAB> for i, tok in enumerate(tokens): <TAB>  <TAB> if ""simple"" in tok and len(tok) == 1: <TAB>  <TAB>  <TAB> decorates.append(""@"" + tok[0]) <MASK> varname = decorator_var + ""_"" + str(i) <TAB>  <TAB>  <TAB> defs.append(varname + "" = "" + tok[0]) <TAB>  <TAB>  <TAB> decorates.append(""@"" + varname) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise CoconutInternalException(""invalid decorator tokens"", tok) <TAB> return ""\n"".join(defs + decorates) + ""\n""","elif ""test"" in tok and len ( tok ) == 1 :",171
2625,"def wait_impl(self, cpid): <TAB> for i in range(10): <TAB>  <TAB> # wait3() shouldn't hang, but some of the buildbots seem to hang <TAB>  <TAB> # in the forking tests.  This is an attempt to fix the problem. <TAB>  <TAB> spid, status, rusage = os.wait3(os.WNOHANG) <MASK> break <TAB>  <TAB> time.sleep(1.0) <TAB> self.assertEqual(spid, cpid) <TAB> self.assertEqual(status, 0, ""cause = %d, exit = %d"" % (status & 0xFF, status >> 8)) <TAB> self.assertTrue(rusage)",if spid == cpid :,163
2626,"def test_non_uniform_probabilities_over_elements(self): <TAB> param = iap.Choice([0, 1], p=[0.25, 0.75]) <TAB> samples = param.draw_samples((10000,)) <TAB> unique, counts = np.unique(samples, return_counts=True) <TAB> assert len(unique) == 2 <TAB> for val, count in zip(unique, counts): <MASK> assert 2500 - 500 < count < 2500 + 500 <TAB>  <TAB> elif val == 1: <TAB>  <TAB>  <TAB> assert 7500 - 500 < count < 7500 + 500 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert False",if val == 0 :,145
2627,"def dispatch_return(self, frame, arg): <TAB> if self.stop_here(frame) or frame == self.returnframe: <TAB>  <TAB> # Ignore return events in generator except when stepping. <TAB>  <TAB> if self.stopframe and frame.f_code.co_flags & CO_GENERATOR: <TAB>  <TAB>  <TAB> return self.trace_dispatch <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.frame_returning = frame <TAB>  <TAB>  <TAB> self.user_return(frame, arg) <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self.frame_returning = None <MASK> raise BdbQuit <TAB>  <TAB> # The user issued a 'next' or 'until' command. <TAB>  <TAB> if self.stopframe is frame and self.stoplineno != -1: <TAB>  <TAB>  <TAB> self._set_stopinfo(None, None) <TAB> return self.trace_dispatch",if self . quitting :,199
2628,"def mouse(self, button, mods, x, y): <TAB> if button == 1: <TAB>  <TAB> for i in range(4): <MASK> self.hit = i <TAB> elif button == -1: <TAB>  <TAB> self.hit = None <TAB> elif self.hit != None: <TAB>  <TAB> self.coords[self.hit] = (x, y) <TAB>  <TAB> self.view.dirty()","if hypot ( x - self . coords [ i ] [ 0 ] , y - self . coords [ i ] [ 1 ] ) < 4 :",123
2629,"def __init__(self, *commands): <TAB> self.all_cmds = list( <TAB>  <TAB> map(lambda cmd: cmd[0] if isinstance(cmd, list) else cmd, commands) <TAB> ) <TAB> for command in commands: <TAB>  <TAB> self.cmd = command if isinstance(command, list) else [command] <TAB>  <TAB> self.cmd_path = pwndbg.which.which(self.cmd[0]) <MASK> break",if self . cmd_path :,111
2630,"def _recv_obj(self, suppress_error=False): <TAB> """"""Receive a (picklable) object"""""" <TAB> if self.conn.closed: <TAB>  <TAB> raise OSError(""handle is closed"") <TAB> try: <TAB>  <TAB> buf = self.conn.recv_bytes() <TAB> except (ConnectionError, EOFError) as e: <MASK> return <TAB>  <TAB> logger.debug(""receive has failed"", exc_info=e) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self._set_remote_close_cause(e) <TAB>  <TAB>  <TAB> raise PipeShutdownError() <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self._close() <TAB> obj = RemoteObjectUnpickler.loads(buf, self) <TAB> logger.debug(""received %r"", obj) <TAB> return obj",if suppress_error :,177
2631,"def act(self, obs): <TAB> with chainer.no_backprop_mode(): <TAB>  <TAB> batch_obs = self.batch_states([obs], self.xp, self.phi) <TAB>  <TAB> action_distrib = self.model(batch_obs) <MASK> return chainer.cuda.to_cpu(action_distrib.most_probable.array)[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return chainer.cuda.to_cpu(action_distrib.sample().array)[0]",if self . act_deterministically :,126
2632,"def _classify(nodes_by_level): <TAB> missing, invalid, downloads = [], [], [] <TAB> for level in nodes_by_level: <TAB>  <TAB> for node in level: <TAB>  <TAB>  <TAB> if node.binary == BINARY_MISSING: <TAB>  <TAB>  <TAB>  <TAB> missing.append(node) <TAB>  <TAB>  <TAB> elif node.binary == BINARY_INVALID: <TAB>  <TAB>  <TAB>  <TAB> invalid.append(node) <MASK> downloads.append(node) <TAB> return missing, invalid, downloads","elif node . binary in ( BINARY_UPDATE , BINARY_DOWNLOAD ) :",126
2633,"def persist(self, *_): <TAB> for key, obj in self._objects.items(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> state = obj.get_state() <MASK> continue <TAB>  <TAB>  <TAB> md5 = hashlib.md5(state).hexdigest() <TAB>  <TAB>  <TAB> if self._last_state.get(key) == md5: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> self._persist_provider.store(key, state) <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> system_log.exception(""PersistHelper.persist fail"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._last_state[key] = md5",if not state :,153
2634,"def enter(self, doc, **kwds): <TAB> """"""Enters the mode, arranging for necessary grabs ASAP"""""" <TAB> super(ColorPickMode, self).enter(doc, **kwds) <TAB> if self._started_from_key_press: <TAB>  <TAB> # Pick now using the last recorded event position <TAB>  <TAB> doc = self.doc <TAB>  <TAB> tdw = self.doc.tdw <TAB>  <TAB> t, x, y = doc.get_last_event_info(tdw) <MASK> self._pick_color_mode(tdw, x, y, self._pickmode) <TAB>  <TAB> # Start the drag when possible <TAB>  <TAB> self._start_drag_on_next_motion_event = True <TAB>  <TAB> self._needs_drag_start = True","if None not in ( x , y ) :",187
2635,"def on_profiles_loaded(self, profiles): <TAB> cb = self.builder.get_object(""cbProfile"") <TAB> model = cb.get_model() <TAB> model.clear() <TAB> for f in profiles: <TAB>  <TAB> name = f.get_basename() <MASK> continue <TAB>  <TAB> if name.endswith("".sccprofile""): <TAB>  <TAB>  <TAB> name = name[0:-11] <TAB>  <TAB> model.append((name, f, None)) <TAB> cb.set_active(0)","if name . endswith ( "".mod"" ) :",122
2636,"def subprocess_post_check( <TAB> completed_process: subprocess.CompletedProcess, raise_error: bool = True) -> None: <TAB> if completed_process.returncode: <TAB>  <TAB> if completed_process.stdout is not None: <TAB>  <TAB>  <TAB> print(completed_process.stdout, file=sys.stdout, end="""") <MASK> print(completed_process.stderr, file=sys.stderr, end="""") <TAB>  <TAB> if raise_error: <TAB>  <TAB>  <TAB> raise PipxError( <TAB>  <TAB>  <TAB>  <TAB> f""{' '.join([str(x) for x in completed_process.args])!r} failed"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logger.info(f""{' '.join(completed_process.args)!r} failed"")",if completed_process . stderr is not None :,185
2637,"def test_connect( <TAB> ipaddr, port, device, partition, method, path, headers=None, query_string=None): <TAB> if path == ""/a"": <TAB>  <TAB> for k, v in headers.iteritems(): <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> test_errors.append(""%s: %s not in %s"" % (test_header, test_value, headers))",if k . lower ( ) == test_header . lower ( ) and v == test_value :,116
2638,"def test_stat_result_pickle(self): <TAB> result = os.stat(self.fname) <TAB> for proto in range(pickle.HIGHEST_PROTOCOL + 1): <TAB>  <TAB> p = pickle.dumps(result, proto) <TAB>  <TAB> self.assertIn(b""stat_result"", p) <MASK> self.assertIn(b""cos\nstat_result\n"", p) <TAB>  <TAB> unpickled = pickle.loads(p) <TAB>  <TAB> self.assertEqual(result, unpickled)",if proto < 4 :,118
2639,"def run_sql(sql): <TAB> table = sql.split("" "")[5] <TAB> logger.info(""Updating table {}"".format(table)) <TAB> with transaction.atomic(): <TAB>  <TAB> with connection.cursor() as cursor: <TAB>  <TAB>  <TAB> cursor.execute(sql) <TAB>  <TAB>  <TAB> rows = cursor.fetchall() <MASK> raise Exception(""Sentry notification that {} is migrated"".format(table))",if not rows :,98
2640,"def countbox(self): <TAB> self.box = [1000, 1000, -1000, -1000] <TAB> for x, y in self.body: <TAB>  <TAB> if x < self.box[0]: <TAB>  <TAB>  <TAB> self.box[0] = x <MASK> self.box[2] = x <TAB>  <TAB> if y < self.box[1]: <TAB>  <TAB>  <TAB> self.box[1] = y <TAB>  <TAB> if y > self.box[3]: <TAB>  <TAB>  <TAB> self.box[3] = y",if x > self . box [ 2 ] :,131
2641,"def _packageFocusOutViaKeyPress(self, row, column, txt): <TAB> if txt: <TAB>  <TAB> self._set_current_cell(row + 1, column) <TAB> else: <TAB>  <TAB> widget = self.cellWidget(row + 1, column) <MASK> self._delete_cell(row, column) <TAB>  <TAB> new_request = self.get_request() <TAB>  <TAB> self.context_model.set_request(new_request) <TAB>  <TAB> self._update_request_column(column, self.context_model)","if widget and isinstance ( widget , PackageSelectWidget ) :",140
2642,"def parse_bash_set_output(output): <TAB> """"""Parse Bash-like 'set' output"""""" <TAB> if not sys.platform.startswith(""win""): <TAB>  <TAB> # Replace ""\""-continued lines in *Linux* environment dumps. <TAB>  <TAB> # Cannot do this on Windows because a ""\"" at the end of the <TAB>  <TAB> # line does not imply a continuation. <TAB>  <TAB> output = output.replace(""\\\n"", """") <TAB> environ = {} <TAB> for line in output.splitlines(0): <TAB>  <TAB> line = line.rstrip() <MASK> continue  # skip black lines <TAB>  <TAB> item = _ParseBashEnvStr(line) <TAB>  <TAB> if item: <TAB>  <TAB>  <TAB> environ[item[0]] = item[1] <TAB> return environ",if not line :,177
2643,"def _get(self, domain): <TAB> with self.lock: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> record = self.cache[domain] <TAB>  <TAB>  <TAB> time_now = time.time() <MASK> record = None <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> record = None <TAB>  <TAB> if not record: <TAB>  <TAB>  <TAB> record = {""r"": ""unknown"", ""dns"": {}, ""g"": 1, ""query_count"": 0} <TAB>  <TAB> # self.cache[domain] = record <TAB>  <TAB> return record","if time_now - record [ ""update"" ] > self . ttl :",137
2644,"def test_filehash(self): <TAB> """"""tests the hashes of the files in data/"""""" <TAB> fp = self.get_data_path() <TAB> for fn in os.listdir(fp): <MASK> # file used for something else <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> expected_hash = fn <TAB>  <TAB> fullp = os.path.join(fp, fn) <TAB>  <TAB> output = self.run_command(""sha1sum "" + fullp, exitcode=0) <TAB>  <TAB> result = output.split("" "")[0] <TAB>  <TAB> self.assertEqual(result, expected_hash)","if ""."" in fn :",139
2645,"def test_new_vs_reference_code_stream_read_during_iter(read_idx, read_len, bytecode): <TAB> reference = SlowCodeStream(bytecode) <TAB> latest = CodeStream(bytecode) <TAB> for index, (actual, expected) in enumerate(zip(latest, reference)): <TAB>  <TAB> assert actual == expected <TAB>  <TAB> if index == read_idx: <TAB>  <TAB>  <TAB> readout_actual = latest.read(read_len) <TAB>  <TAB>  <TAB> readout_expected = reference.read(read_len) <TAB>  <TAB>  <TAB> assert readout_expected == readout_actual <MASK> assert latest.program_counter >= len(reference) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert latest.program_counter == reference.program_counter",if reference . program_counter >= len ( reference ) :,179
2646,"def setup_logging(): <TAB> try: <TAB>  <TAB> logconfig = config.get(""logging_config_file"") <MASK> logging.config.fileConfig(logconfig, disable_existing_loggers=False) <TAB>  <TAB> logger.info(""logging initialized"") <TAB>  <TAB> logger.debug(""debug"") <TAB> except Exception as e: <TAB>  <TAB> print(""Unable to set logging configuration:"", str(e), file=sys.stderr) <TAB>  <TAB> raise",if logconfig and os . path . exists ( logconfig ) :,116
2647,"def all_words(filename): <TAB> start_char = True <TAB> for c in characters(filename): <MASK> word = """" <TAB>  <TAB>  <TAB> if c.isalnum(): <TAB>  <TAB>  <TAB>  <TAB> # We found the start of a word <TAB>  <TAB>  <TAB>  <TAB> word = c.lower() <TAB>  <TAB>  <TAB>  <TAB> start_char = False <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if c.isalnum(): <TAB>  <TAB>  <TAB>  <TAB> word += c.lower() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> # We found end of word, emit it <TAB>  <TAB>  <TAB>  <TAB> start_char = True <TAB>  <TAB>  <TAB>  <TAB> yield word",if start_char == True :,158
2648,"def _get_nonce(self, url, new_nonce_url): <TAB> if not self._nonces: <TAB>  <TAB> logger.debug(""Requesting fresh nonce"") <MASK> response = self.head(url) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # request a new nonce from the acme newNonce endpoint <TAB>  <TAB>  <TAB> response = self._check_response(self.head(new_nonce_url), content_type=None) <TAB>  <TAB> self._add_nonce(response) <TAB> return self._nonces.pop()",if new_nonce_url is None :,131
2649,"def paragraph_is_fully_commented(lines, comment, main_language): <TAB> """"""Is the paragraph fully commented?"""""" <TAB> for i, line in enumerate(lines): <TAB>  <TAB> if line.startswith(comment): <MASK> continue <TAB>  <TAB>  <TAB> if is_magic(line, main_language): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> return i > 0 and _BLANK_LINE.match(line) <TAB> return True",if line [ len ( comment ) : ] . lstrip ( ) . startswith ( comment ) :,121
2650,"def gvariant_args(args: List[Any]) -> str: <TAB> """"""Convert args into gvariant."""""" <TAB> gvariant = """" <TAB> for arg in args: <TAB>  <TAB> if isinstance(arg, bool): <TAB>  <TAB>  <TAB> gvariant += "" {}"".format(str(arg).lower()) <MASK> gvariant += f"" {arg}"" <TAB>  <TAB> elif isinstance(arg, str): <TAB>  <TAB>  <TAB> gvariant += f' ""{arg}""' <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> gvariant += f"" {arg!s}"" <TAB> return gvariant.lstrip()","elif isinstance ( arg , ( int , float ) ) :",139
2651,"def _SkipGroup(buffer, pos, end): <TAB> """"""Skip sub-group.  Returns the new position."""""" <TAB> while 1: <TAB>  <TAB> (tag_bytes, pos) = ReadTag(buffer, pos) <TAB>  <TAB> new_pos = SkipField(buffer, pos, end, tag_bytes) <MASK> return pos <TAB>  <TAB> pos = new_pos",if new_pos == - 1 :,93
2652,"def update_participants(self, refresh=True): <TAB> for participant in list(self.participants_dict): <TAB>  <TAB> if participant is None or participant == self.simulator_config.broadcast_part: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> self.removeItem(self.participants_dict[participant]) <TAB>  <TAB> self.participant_items.remove(self.participants_dict[participant]) <TAB>  <TAB> del self.participants_dict[participant] <TAB> for participant in self.simulator_config.participants: <MASK> self.participants_dict[participant].refresh() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.insert_participant(participant) <TAB> if refresh: <TAB>  <TAB> self.update_view()",if participant in self . participants_dict :,182
2653,"def feature_reddit(layer_data, graph): <TAB> feature = {} <TAB> times = {} <TAB> indxs = {} <TAB> for _type in layer_data: <TAB>  <TAB> if len(layer_data[_type]) == 0: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> idxs = np.array(list(layer_data[_type].keys())) <TAB>  <TAB> tims = np.array(list(layer_data[_type].values()))[:, 1] <TAB>  <TAB> feature[_type] = np.array( <TAB>  <TAB>  <TAB> list(graph.node_feature[_type].loc[idxs, ""emb""]), dtype=np.float <TAB>  <TAB> ) <TAB>  <TAB> times[_type] = tims <TAB>  <TAB> indxs[_type] = idxs <MASK> attr = feature[_type] <TAB> return feature, times, indxs, attr","if _type == ""def"" :",195
2654,"def _get_sort_map(tags): <TAB> """"""See TAG_TO_SORT"""""" <TAB> tts = {} <TAB> for name, tag in tags.items(): <TAB>  <TAB> if tag.has_sort: <MASK> tts[name] = ""%ssort"" % name <TAB>  <TAB>  <TAB> if tag.internal: <TAB>  <TAB>  <TAB>  <TAB> tts[""~%s"" % name] = ""~%ssort"" % name <TAB> return tts",if tag . user :,111
2655,"def max_radius(iterator): <TAB> radius_result = dict() <TAB> for k, v in iterator: <TAB>  <TAB> if v[0] not in radius_result: <TAB>  <TAB>  <TAB> radius_result[v[0]] = v[1] <MASK> radius_result[v[0]] = v[1] <TAB> return radius_result",elif v [ 1 ] >= radius_result [ v [ 0 ] ] :,96
2656,"def run(self): <TAB> pwd_found = [] <TAB> if constant.user_dpapi and constant.user_dpapi.unlocked: <TAB>  <TAB> main_vault_directory = os.path.join( <TAB>  <TAB>  <TAB> constant.profile[""APPDATA""], u"".."", u""Local"", u""Microsoft"", u""Vault"" <TAB>  <TAB> ) <TAB>  <TAB> if os.path.exists(main_vault_directory): <TAB>  <TAB>  <TAB> for vault_directory in os.listdir(main_vault_directory): <TAB>  <TAB>  <TAB>  <TAB> cred = constant.user_dpapi.decrypt_vault( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> os.path.join(main_vault_directory, vault_directory) <TAB>  <TAB>  <TAB>  <TAB> ) <MASK> pwd_found.append(cred) <TAB> return pwd_found",if cred :,197
2657,"def disconnect_sync(self, connection, close_connection=False): <TAB> key = id(connection) <TAB> ts = self.in_use.pop(key) <TAB> if close_connection: <TAB>  <TAB> self.connections_map.pop(key) <TAB>  <TAB> self._connection_close_sync(connection) <TAB> else: <MASK> self.connections_map.pop(key) <TAB>  <TAB>  <TAB> self._connection_close_sync(connection) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> with self._lock_sync: <TAB>  <TAB>  <TAB>  <TAB> heapq.heappush(self.connections_sync, (ts, key))",if self . stale_timeout and self . is_stale ( ts ) :,159
2658,"def _populate_tree(self, element, d): <TAB> """"""Populates an etree with attributes & elements, given a dict."""""" <TAB> for k, v in d.iteritems(): <TAB>  <TAB> if isinstance(v, dict): <TAB>  <TAB>  <TAB> self._populate_dict(element, k, v) <TAB>  <TAB> elif isinstance(v, list): <TAB>  <TAB>  <TAB> self._populate_list(element, k, v) <TAB>  <TAB> elif isinstance(v, bool): <TAB>  <TAB>  <TAB> self._populate_bool(element, k, v) <TAB>  <TAB> elif isinstance(v, basestring): <TAB>  <TAB>  <TAB> self._populate_str(element, k, v) <MASK> self._populate_number(element, k, v)","elif type ( v ) in [ int , float , long , complex ] :",178
2659,"def readframes(self, nframes): <TAB> if self._ssnd_seek_needed: <TAB>  <TAB> self._ssnd_chunk.seek(0) <TAB>  <TAB> dummy = self._ssnd_chunk.read(8) <TAB>  <TAB> pos = self._soundpos * self._framesize <MASK> self._ssnd_chunk.seek(pos + 8) <TAB>  <TAB> self._ssnd_seek_needed = 0 <TAB> if nframes == 0: <TAB>  <TAB> return """" <TAB> data = self._ssnd_chunk.read(nframes * self._framesize) <TAB> if self._convert and data: <TAB>  <TAB> data = self._convert(data) <TAB> self._soundpos = self._soundpos + len(data) / (self._nchannels * self._sampwidth) <TAB> return data",if pos :,185
2660,"def target_glob(tgt, hosts): <TAB> ret = {} <TAB> for host in hosts: <MASK> ret[host] = copy.deepcopy(__opts__.get(""roster_defaults"", {})) <TAB>  <TAB>  <TAB> ret[host].update({""host"": host}) <TAB>  <TAB>  <TAB> if __opts__.get(""ssh_user""): <TAB>  <TAB>  <TAB>  <TAB> ret[host].update({""user"": __opts__[""ssh_user""]}) <TAB> return ret","if fnmatch . fnmatch ( tgt , host ) :",110
2661,"def get_attribute_value(self, nodeid, attr): <TAB> with self._lock: <TAB>  <TAB> self.logger.debug(""get attr val: %s %s"", nodeid, attr) <TAB>  <TAB> if nodeid not in self._nodes: <TAB>  <TAB>  <TAB> dv = ua.DataValue() <TAB>  <TAB>  <TAB> dv.StatusCode = ua.StatusCode(ua.StatusCodes.BadNodeIdUnknown) <TAB>  <TAB>  <TAB> return dv <TAB>  <TAB> node = self._nodes[nodeid] <TAB>  <TAB> if attr not in node.attributes: <TAB>  <TAB>  <TAB> dv = ua.DataValue() <TAB>  <TAB>  <TAB> dv.StatusCode = ua.StatusCode(ua.StatusCodes.BadAttributeIdInvalid) <TAB>  <TAB>  <TAB> return dv <TAB>  <TAB> attval = node.attributes[attr] <MASK> return attval.value_callback() <TAB>  <TAB> return attval.value",if attval . value_callback :,200
2662,"def remove_property(self, key):  # type: (str) -> None <TAB> with self.secure() as config: <TAB>  <TAB> keys = key.split(""."") <TAB>  <TAB> current_config = config <TAB>  <TAB> for i, key in enumerate(keys): <MASK> return <TAB>  <TAB>  <TAB> if i == len(keys) - 1: <TAB>  <TAB>  <TAB>  <TAB> del current_config[key] <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> current_config = current_config[key]",if key not in current_config :,122
2663,"def _class_browser(parent):  # Wrapper for htest <TAB> try: <TAB>  <TAB> file = __file__ <TAB> except NameError: <TAB>  <TAB> file = sys.argv[0] <MASK> file = sys.argv[1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> file = sys.argv[0] <TAB> dir, file = os.path.split(file) <TAB> name = os.path.splitext(file)[0] <TAB> flist = PyShell.PyShellFileList(parent) <TAB> global file_open <TAB> file_open = flist.open <TAB> ClassBrowser(flist, name, [dir], _htest=True)",if sys . argv [ 1 : ] :,161
2664,"def get_only_text_part(self, msg): <TAB> count = 0 <TAB> only_text_part = None <TAB> for part in msg.walk(): <TAB>  <TAB> if part.is_multipart(): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> count += 1 <TAB>  <TAB> mimetype = part.get_content_type() or ""text/plain"" <MASK> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> only_text_part = part <TAB> return only_text_part","if mimetype != ""text/plain"" or count != 1 :",123
2665,"def should_keep_alive(commit_msg): <TAB> result = False <TAB> ci = get_current_ci() or """" <TAB> for line in commit_msg.splitlines(): <TAB>  <TAB> parts = line.strip(""# "").split("":"", 1) <TAB>  <TAB> (key, val) = parts if len(parts) > 1 else (parts[0], """") <TAB>  <TAB> if key == ""CI_KEEP_ALIVE"": <TAB>  <TAB>  <TAB> ci_names = val.replace("","", "" "").lower().split() if val else [] <MASK> result = True <TAB> return result",if len ( ci_names ) == 0 or ci . lower ( ) in ci_names :,150
2666,"def _calc_block_io(self, blkio): <TAB> """"""Calculate block IO stats."""""" <TAB> for stats in blkio[""io_service_bytes_recursive""]: <TAB>  <TAB> if stats[""op""] == ""Read"": <TAB>  <TAB>  <TAB> self._blk_read += stats[""value""] <MASK> self._blk_write += stats[""value""]","elif stats [ ""op"" ] == ""Write"" :",92
2667,"def value_to_db_datetime(self, value): <TAB> if value is None: <TAB>  <TAB> return None <TAB> # Oracle doesn't support tz-aware datetimes <TAB> if timezone.is_aware(value): <MASK> value = value.astimezone(timezone.utc).replace(tzinfo=None) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Oracle backend does not support timezone-aware datetimes when USE_TZ is False."" <TAB>  <TAB>  <TAB> ) <TAB> return six.text_type(value)",if settings . USE_TZ :,134
2668,"def load_state_dict(self, state_dict): <TAB> for module_name, module_state_dict in state_dict.items(): <TAB>  <TAB> if module_name in self.module_pool: <MASK> self.module_pool[module_name].module.load_state_dict(module_state_dict) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.module_pool[module_name].load_state_dict(module_state_dict) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logging.info(f""Missing {module_name} in module_pool, skip it.."")","if self . config [ ""dataparallel"" ] :",150
2669,"def _unpack_scales(scales, vidxs): <TAB> scaleData = [None, None, None] <TAB> for i in range(3): <TAB>  <TAB> if i >= min(len(scales), len(vidxs) // 2): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> scale = scales[i] <MASK> vidx1, vidx2 = vidxs[i * 2], vidxs[i * 2 + 1] <TAB>  <TAB>  <TAB> scaleData[i] = (int(vidx1), int(vidx2), float(scale)) <TAB> return scaleData",if not math . isnan ( scale ) :,138
2670,"def __init__(self, factors, contrast_matrices, num_columns): <TAB> self.factors = tuple(factors) <TAB> factor_set = frozenset(factors) <TAB> if not isinstance(contrast_matrices, dict): <TAB>  <TAB> raise ValueError(""contrast_matrices must be dict"") <TAB> for factor, contrast_matrix in six.iteritems(contrast_matrices): <MASK> raise ValueError(""Unexpected factor in contrast_matrices dict"") <TAB>  <TAB> if not isinstance(contrast_matrix, ContrastMatrix): <TAB>  <TAB>  <TAB> raise ValueError(""Expected a ContrastMatrix, not %r"" % (contrast_matrix,)) <TAB> self.contrast_matrices = contrast_matrices <TAB> if not isinstance(num_columns, six.integer_types): <TAB>  <TAB> raise ValueError(""num_columns must be an integer"") <TAB> self.num_columns = num_columns",if factor not in factor_set :,193
2671,"def app(scope, receive, send): <TAB> while True: <TAB>  <TAB> message = await receive() <MASK> await send({""type"": ""websocket.accept""}) <TAB>  <TAB> elif message[""type""] == ""websocket.receive"": <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> elif message[""type""] == ""websocket.disconnect"": <TAB>  <TAB>  <TAB> break","if message [ ""type"" ] == ""websocket.connect"" :",93
2672,"def value__set(self, value): <TAB> for i, (option, checked) in enumerate(self.options): <MASK> self.selectedIndex = i <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> ""Option %r not found (from %s)"" <TAB>  <TAB>  <TAB> % (value, "", "".join([repr(o) for o, c in self.options])) <TAB>  <TAB> )",if option == str ( value ) :,106
2673,"def init_links(self): <TAB> links = LinkCallback.find_links(self) <TAB> callbacks = [] <TAB> for link, src_plot, tgt_plot in links: <TAB>  <TAB> cb = Link._callbacks[""bokeh""][type(link)] <MASK> continue <TAB>  <TAB> callbacks.append(cb(self.root, link, src_plot, tgt_plot)) <TAB> return callbacks",if src_plot is None or ( link . _requires_target and tgt_plot is None ) :,112
2674,"def _validate_scalar_extensions(self) -> List[str]: <TAB> errors = [] <TAB> for extension in [ <TAB>  <TAB> x for x in self.extensions if isinstance(x, GraphQLScalarTypeExtension) <TAB> ]: <TAB>  <TAB> extended = self.type_definitions.get(extension.name) <TAB>  <TAB> ext_errors = _validate_extension( <TAB>  <TAB>  <TAB> extended, extension.name, GraphQLScalarType, ""SCALAR"" <TAB>  <TAB> ) <TAB>  <TAB> errors.extend(ext_errors) <MASK> errors.extend(_validate_extension_directives(extension, extended, ""SCALAR"")) <TAB> return errors",if not ext_errors :,149
2675,"def copy_tcltk(src, dest, symlink): <TAB> """"""copy tcl/tk libraries on Windows (issue #93)"""""" <TAB> for libversion in ""8.5"", ""8.6"": <TAB>  <TAB> for libname in ""tcl"", ""tk"": <TAB>  <TAB>  <TAB> srcdir = join(src, ""tcl"", libname + libversion) <TAB>  <TAB>  <TAB> destdir = join(dest, ""tcl"", libname + libversion) <TAB>  <TAB>  <TAB> # Only copy the dirs from the above combinations that exist <MASK> copyfileordir(srcdir, destdir, symlink)",if os . path . exists ( srcdir ) and not os . path . exists ( destdir ) :,153
2676,"def parse(self, response): <TAB> try: <TAB>  <TAB> content = response.content.decode(""utf-8"", ""ignore"") <TAB>  <TAB> content = json.loads(content, strict=False) <TAB> except: <TAB>  <TAB> self.logger.error(""Fail to parse the response in json format"") <TAB>  <TAB> return <TAB> for item in content[""data""]: <TAB>  <TAB> if ""objURL"" in item: <TAB>  <TAB>  <TAB> img_url = self._decode_url(item[""objURL""]) <MASK> img_url = item[""hoverURL""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> yield dict(file_url=img_url)","elif ""hoverURL"" in item :",158
2677,"def check_and_reload(self): <TAB> # Check if tables have been modified, if so reload <TAB> for table_name, table_version in self._table_versions.items(): <TAB>  <TAB> table = self.app.tool_data_tables.get(table_name, None) <MASK> return self.reload_genomes()",if table is not None and not table . is_current_version ( table_version ) :,100
2678,"def _get_query_defaults(self, query_defns): <TAB> defaults = {} <TAB> for k, v in query_defns.items(): <TAB>  <TAB> try: <MASK> defaults[k] = self._get_default_obj(v[""schema""]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> defaults[k] = v[""schema""][""default""] <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> pass <TAB> return defaults","if v [ ""schema"" ] [ ""type"" ] == ""object"" :",114
2679,"def ftp_login(host, port, username=None, password=None, anonymous=False): <TAB> ret = False <TAB> try: <TAB>  <TAB> ftp = ftplib.FTP() <TAB>  <TAB> ftp.connect(host, port, timeout=6) <MASK> ftp.login() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ftp.login(username, password) <TAB>  <TAB> ret = True <TAB>  <TAB> ftp.quit() <TAB> except Exception: <TAB>  <TAB> pass <TAB> return ret",if anonymous :,116
2680,"def _getVolumeScalar(self): <TAB> if self._volumeScalar is not None: <TAB>  <TAB> return self._volumeScalar <TAB> # use default <TAB> elif self._value in dynamicStrToScalar: <TAB>  <TAB> return dynamicStrToScalar[self._value] <TAB> else: <TAB>  <TAB> thisDynamic = self._value <TAB>  <TAB> # ignore leading s like in sf <TAB>  <TAB> if ""s"" in thisDynamic: <TAB>  <TAB>  <TAB> thisDynamic = thisDynamic[1:] <TAB>  <TAB> # ignore closing z like in fz <TAB>  <TAB> if thisDynamic[-1] == ""z"": <TAB>  <TAB>  <TAB> thisDynamic = thisDynamic[:-1] <MASK> return dynamicStrToScalar[thisDynamic] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return dynamicStrToScalar[None]",if thisDynamic in dynamicStrToScalar :,183
2681,"def processCoords(coords): <TAB> newcoords = deque() <TAB> for (x, y, z) in coords: <TAB>  <TAB> for _dir, offsets in faceDirections: <TAB>  <TAB>  <TAB> if _dir == FaceYIncreasing: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> dx, dy, dz = offsets <TAB>  <TAB>  <TAB> p = (x + dx, y + dy, z + dz) <MASK> continue <TAB>  <TAB>  <TAB> nx, ny, nz = p <TAB>  <TAB>  <TAB> if level.blockAt(nx, ny, nz) == 0: <TAB>  <TAB>  <TAB>  <TAB> level.setBlockAt(nx, ny, nz, waterID) <TAB>  <TAB>  <TAB>  <TAB> newcoords.append(p) <TAB> return newcoords",if p not in box :,173
2682,"def _set_property(self, target_widget, pname, value): <TAB> if pname == ""text"": <TAB>  <TAB> wstate = str(target_widget[""state""]) <MASK> # change state temporarily <TAB>  <TAB>  <TAB> target_widget[""state""] = ""normal"" <TAB>  <TAB> target_widget.delete(""0"", tk.END) <TAB>  <TAB> target_widget.insert(""0"", value) <TAB>  <TAB> target_widget[""state""] = wstate <TAB> else: <TAB>  <TAB> super(EntryBaseBO, self)._set_property(target_widget, pname, value)","if wstate != ""normal"" :",138
2683,"def teardown(): <TAB> try: <TAB>  <TAB> time.sleep(1) <TAB> except KeyboardInterrupt: <TAB>  <TAB> return <TAB> while launchers: <TAB>  <TAB> p = launchers.pop() <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> p.stop() <TAB>  <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB>  <TAB> print(e) <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> if p.poll() is None: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> time.sleep(0.25) <TAB>  <TAB>  <TAB> except KeyboardInterrupt: <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> if p.poll() is None: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> print(""cleaning up test process..."") <TAB>  <TAB>  <TAB>  <TAB> p.signal(SIGKILL) <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> print(""couldn't shutdown process: "", p)",if p . poll ( ) is None :,198
2684,"def checkAndRemoveDuplicate(self, node): <TAB> for bucket in self.buckets: <TAB>  <TAB> for n in bucket.getNodes(): <MASK> self.removeContact(n)","if ( n . ip , n . port ) == ( node . ip , node . port ) and n . id != node . id :",77
2685,"def toString(): <TAB> flags = u"""" <TAB> try: <TAB>  <TAB> if this.glob: <TAB>  <TAB>  <TAB> flags += u""g"" <MASK> flags += u""i"" <TAB>  <TAB> if this.multiline: <TAB>  <TAB>  <TAB> flags += u""m"" <TAB> except: <TAB>  <TAB> pass <TAB> v = this.value if this.value else ""(?:)"" <TAB> return u""/%s/"" % v + flags",if this . ignore_case :,106
2686,"def import_submodules(package_name): <TAB> package = sys.modules[package_name] <TAB> results = {} <TAB> for loader, name, is_pkg in pkgutil.iter_modules(package.__path__): <TAB>  <TAB> full_name = package_name + ""."" + name <TAB>  <TAB> module = importlib.import_module(full_name) <TAB>  <TAB> setattr(sys.modules[__name__], name, module) <TAB>  <TAB> results[full_name] = module <TAB>  <TAB> if is_pkg: <TAB>  <TAB>  <TAB> valid_pkg = import_submodules(full_name) <MASK> results.update(valid_pkg) <TAB> return results",if valid_pkg :,153
2687,"def _call(self, cmd): <TAB> what = cmd[""command""] <TAB> if what == ""list"": <TAB>  <TAB> name = cmd[""properties""].get(""name"") <MASK> return {""watchers"": [""one"", ""two"", ""three""]} <TAB>  <TAB> return {""pids"": [123, 456]} <TAB> elif what == ""dstats"": <TAB>  <TAB> return {""info"": {""pid"": 789}} <TAB> elif what == ""listsockets"": <TAB>  <TAB> return { <TAB>  <TAB>  <TAB> ""status"": ""ok"", <TAB>  <TAB>  <TAB> ""sockets"": [{""path"": self._unix, ""fd"": 5, ""name"": ""XXXX"", ""backlog"": 2048}], <TAB>  <TAB>  <TAB> ""time"": 1369647058.967524, <TAB>  <TAB> } <TAB> raise NotImplementedError(cmd)",if name is None :,182
2688,"def select(self): <TAB> e = xlib.XEvent() <TAB> while xlib.XPending(self._display): <TAB>  <TAB> xlib.XNextEvent(self._display, e) <TAB>  <TAB> # Key events are filtered by the xlib window event <TAB>  <TAB> # handler so they get a shot at the prefiltered event. <TAB>  <TAB> if e.xany.type not in (xlib.KeyPress, xlib.KeyRelease): <MASK> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> dispatch = self._window_map[e.xany.window] <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> dispatch(e)","if xlib . XFilterEvent ( e , e . xany . window ) :",171
2689,"def translate(self, line): <TAB> parsed = self.RE_LINE_PARSER.match(line) <TAB> if parsed: <TAB>  <TAB> value = parsed.group(3) <TAB>  <TAB> stage = parsed.group(1) <MASK> # query string is rendered here <TAB>  <TAB>  <TAB> return ""\n# HTTP Request:\n"" + self.stripslashes(value) <TAB>  <TAB> elif stage == ""reply"": <TAB>  <TAB>  <TAB> return ""\n\n# HTTP Response:\n"" + self.stripslashes(value) <TAB>  <TAB> elif stage == ""header"": <TAB>  <TAB>  <TAB> return value + ""\n"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return value <TAB> return line","if stage == ""send"" :",156
2690,"def toString(): <TAB> flags = u"""" <TAB> try: <MASK> flags += u""g"" <TAB>  <TAB> if this.ignore_case: <TAB>  <TAB>  <TAB> flags += u""i"" <TAB>  <TAB> if this.multiline: <TAB>  <TAB>  <TAB> flags += u""m"" <TAB> except: <TAB>  <TAB> pass <TAB> v = this.value if this.value else ""(?:)"" <TAB> return u""/%s/"" % v + flags",if this . glob :,106
2691,"def __exit__(self, *exc_info): <TAB> super(WarningsChecker, self).__exit__(*exc_info) <TAB> # only check if we're not currently handling an exception <TAB> if all(a is None for a in exc_info): <TAB>  <TAB> if self.expected_warning is not None: <MASK> __tracebackhide__ = True <TAB>  <TAB>  <TAB>  <TAB> pytest.fail(""DID NOT WARN"")",if not any ( r . category in self . expected_warning for r in self ) :,115
2692,"def run(self): <TAB> for k, v in iteritems(self.objs): <TAB>  <TAB> if k.startswith(""_""): <TAB>  <TAB>  <TAB> continue <MASK> if v[""email""] == """": <TAB>  <TAB>  <TAB>  <TAB> v[""email""] = None <TAB>  <TAB>  <TAB> if v[""ip""] == ""0.0.0.0"": <TAB>  <TAB>  <TAB>  <TAB> v[""ip""] = None <TAB> return self.objs","if v [ ""_class"" ] == ""User"" :",102
2693,"def list_stuff(self, upto=10, start_after=-1): <TAB> for i in range(upto): <TAB>  <TAB> if i <= start_after: <TAB>  <TAB>  <TAB> continue <MASK> self.count += 1 <TAB>  <TAB>  <TAB> raise TemporaryProblem <TAB>  <TAB> if i == 7 and self.count < 4: <TAB>  <TAB>  <TAB> self.count += 1 <TAB>  <TAB>  <TAB> raise TemporaryProblem <TAB>  <TAB> yield i",if i == 2 and self . count < 1 :,110
2694,"def check(self): <TAB> tcp_client = self.tcp_create() <TAB> if tcp_client.connect(): <TAB>  <TAB> tcp_client.send(b""ABCDE"") <TAB>  <TAB> response = tcp_client.recv(5) <TAB>  <TAB> tcp_client.close() <TAB>  <TAB> if response: <MASK> self.endianness = "">""  # BE <TAB>  <TAB>  <TAB> elif response.startswith(b""ScMM""): <TAB>  <TAB>  <TAB>  <TAB> self.endianness = ""<""  # LE <TAB>  <TAB>  <TAB> return True  # target is vulnerable <TAB> return False  # target is not vulnerable","if response . startswith ( b""MMcS"" ) :",148
2695,"def copy_tree(self, src_dir, dst_dir, skip_variables=False): <TAB> for src_root, _, files in os.walk(src_dir): <TAB>  <TAB> if src_root != src_dir: <TAB>  <TAB>  <TAB> rel_root = os.path.relpath(src_root, src_dir) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> rel_root = """" <TAB>  <TAB> if skip_variables and rel_root.startswith(""variables""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> dst_root = os.path.join(dst_dir, rel_root) <MASK> os.makedirs(dst_root) <TAB>  <TAB> for f in files: <TAB>  <TAB>  <TAB> shutil.copy(os.path.join(src_root, f), os.path.join(dst_root, f))",if not os . path . exists ( dst_root ) :,197
2696,"def _set_hostport(self, host, port): <TAB> if port is None: <TAB>  <TAB> i = host.rfind("":"") <TAB>  <TAB> j = host.rfind(""]"")  # ipv6 addresses have [...] <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> port = int(host[i + 1 :]) <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> raise InvalidURL(""nonnumeric port: '%s'"" % host[i + 1 :]) <TAB>  <TAB>  <TAB> host = host[:i] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> port = self.default_port <TAB>  <TAB> if host and host[0] == ""["" and host[-1] == ""]"": <TAB>  <TAB>  <TAB> host = host[1:-1] <TAB> self.host = host <TAB> self.port = port",if i > j :,176
2697,"def _get_field_value(self, test, key, match): <TAB> if test.ver == ofproto_v1_0.OFP_VERSION: <TAB>  <TAB> members = inspect.getmembers(match) <TAB>  <TAB> for member in members: <TAB>  <TAB>  <TAB> if member[0] == key: <TAB>  <TAB>  <TAB>  <TAB> field_value = member[1] <TAB>  <TAB>  <TAB> elif member[0] == ""wildcards"": <TAB>  <TAB>  <TAB>  <TAB> wildcards = member[1] <MASK> field_value = test.nw_src_to_str(wildcards, field_value) <TAB>  <TAB> elif key == ""nw_dst"": <TAB>  <TAB>  <TAB> field_value = test.nw_dst_to_str(wildcards, field_value) <TAB> else: <TAB>  <TAB> field_value = match[key] <TAB> return field_value","if key == ""nw_src"" :",200
2698,"def _clear_storage(): <TAB> """"""Clear old files from storage."""""" <TAB> hacs = get_hacs() <TAB> storagefiles = [""hacs""] <TAB> for s_f in storagefiles: <TAB>  <TAB> path = f""{hacs.core.config_path}/.storage/{s_f}"" <MASK> hacs.log.info(f""Cleaning up old storage file {path}"") <TAB>  <TAB>  <TAB> os.remove(path)",if os . path . isfile ( path ) :,111
2699,"def action_delete(self, ids): <TAB> try: <TAB>  <TAB> count = 0 <TAB>  <TAB> # TODO: Optimize me <TAB>  <TAB> for pk in ids: <MASK> count += 1 <TAB>  <TAB> flash( <TAB>  <TAB>  <TAB> ngettext( <TAB>  <TAB>  <TAB>  <TAB> ""Record was successfully deleted."", <TAB>  <TAB>  <TAB>  <TAB> ""%(count)s records were successfully deleted."", <TAB>  <TAB>  <TAB>  <TAB> count, <TAB>  <TAB>  <TAB>  <TAB> count=count, <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB> ""success"", <TAB>  <TAB> ) <TAB> except Exception as ex: <TAB>  <TAB> flash(gettext(""Failed to delete records. %(error)s"", error=str(ex)), ""error"")",if self . delete_model ( self . get_one ( pk ) ) :,166
2700,"def test_inclusion(all_values): <TAB> for values in [{""guid_2"", ""guid_1""}, {""guid_5"", ""guid_XXX""}, {""guid_2""}]: <TAB>  <TAB> test_predicate = in_set(values, ""volume_guid"") <TAB>  <TAB> included_values = set() <TAB>  <TAB> for val in all_values: <MASK> included_values.add(val) <TAB>  <TAB> assert included_values == all_values.intersection(values)","if test_predicate . do_include ( { ""volume_guid"" : val } ) :",126
2701,"def _get_attr(sdk_path, mod_attr_path, checked=True): <TAB> try: <TAB>  <TAB> attr_mod, attr_path = ( <TAB>  <TAB>  <TAB> mod_attr_path.split(""#"") if ""#"" in mod_attr_path else (mod_attr_path, """") <TAB>  <TAB> ) <TAB>  <TAB> full_mod_path = ""{}.{}"".format(sdk_path, attr_mod) if attr_mod else sdk_path <TAB>  <TAB> op = import_module(full_mod_path) <TAB>  <TAB> if attr_path: <TAB>  <TAB>  <TAB> # Only load attributes if needed <TAB>  <TAB>  <TAB> for part in attr_path.split("".""): <TAB>  <TAB>  <TAB>  <TAB> op = getattr(op, part) <TAB>  <TAB> return op <TAB> except (ImportError, AttributeError) as ex: <MASK> return None <TAB>  <TAB> raise ex",if checked :,191
2702,"def __exit__(self, exc_type, exc_val, exc_tb): <TAB> if self.fusefat is not None: <TAB>  <TAB> self.fusefat.send_signal(signal.SIGINT) <TAB>  <TAB> # Allow 1s to return without sending terminate <TAB>  <TAB> for count in range(10): <TAB>  <TAB>  <TAB> time.sleep(0.1) <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.fusefat.terminate() <TAB>  <TAB> time.sleep(self.delay) <TAB>  <TAB> assert not os.path.exists(self.canary) <TAB> self.dev_null.close() <TAB> shutil.rmtree(self.tmpdir)",if self . fusefat . poll ( ) is not None :,165
2703,"def check_context_processors(output): <TAB> with output.section(""Context processors"") as section: <TAB>  <TAB> processors = list( <TAB>  <TAB>  <TAB> chain( <TAB>  <TAB>  <TAB>  <TAB> *[ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> template[""OPTIONS""].get(""context_processors"", []) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for template in settings.TEMPLATES <TAB>  <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB>  <TAB> required_processors = (""cms.context_processors.cms_settings"",) <TAB>  <TAB> for processor in required_processors: <MASK> section.error( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""%s context processor must be in TEMPLATES option context_processors"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> % processor <TAB>  <TAB>  <TAB>  <TAB> )",if processor not in processors :,171
2704,"def test_converters(self): <TAB> response = self._get(""datatypes/converters"") <TAB> self._assert_status_code_is(response, 200) <TAB> converters_list = response.json() <TAB> found_fasta_to_tabular = False <TAB> for converter in converters_list: <TAB>  <TAB> self._assert_has_key(converter, ""source"", ""target"", ""tool_id"") <MASK> found_fasta_to_tabular = True <TAB> assert found_fasta_to_tabular","if converter [ ""source"" ] == ""fasta"" and converter [ ""target"" ] == ""tabular"" :",138
2705,"def remove_pid(self, watcher, pid): <TAB> if pid in self._pids[watcher]: <TAB>  <TAB> logger.debug(""Removing %d from %s"" % (pid, watcher)) <TAB>  <TAB> self._pids[watcher].remove(pid) <MASK> logger.debug(""Stopping the periodic callback for {0}"".format(watcher)) <TAB>  <TAB>  <TAB> self._callbacks[watcher].stop()",if len ( self . _pids [ watcher ] ) == 0 :,104
2706,"def _fc_layer(self, sess, bottom, name, trainable=True, relu=True): <TAB> with tf.variable_scope(name) as scope: <TAB>  <TAB> shape = bottom.get_shape().as_list() <TAB>  <TAB> dim = 1 <TAB>  <TAB> for d in shape[1:]: <TAB>  <TAB>  <TAB> dim *= d <TAB>  <TAB> x = tf.reshape(bottom, [-1, dim]) <TAB>  <TAB> weight = self._get_fc_weight(sess, name, trainable=trainable) <TAB>  <TAB> bias = self._get_bias(sess, name, trainable=trainable) <TAB>  <TAB> fc = tf.nn.bias_add(tf.matmul(x, weight), bias) <MASK> fc = tf.nn.relu(fc) <TAB>  <TAB> return fc",if relu :,179
2707,"def get_drive(self, root_path="""", volume_guid_path=""""): <TAB> for drive in self.drives: <TAB>  <TAB> if root_path: <TAB>  <TAB>  <TAB> config_root_path = drive.get(""root_path"") <MASK> return drive <TAB>  <TAB> elif volume_guid_path: <TAB>  <TAB>  <TAB> config_volume_guid_path = drive.get(""volume_guid_path"") <TAB>  <TAB>  <TAB> if config_volume_guid_path and config_volume_guid_path == volume_guid_path: <TAB>  <TAB>  <TAB>  <TAB> return drive",if config_root_path and root_path == config_root_path :,148
2708,"def rewire_init(expr): <TAB> new_args = [] <TAB> if expr[0] == HySymbol(""setv""): <TAB>  <TAB> pairs = expr[1:] <TAB>  <TAB> while len(pairs) > 0: <TAB>  <TAB>  <TAB> k, v = (pairs.pop(0), pairs.pop(0)) <MASK> v.append(HySymbol(""None"")) <TAB>  <TAB>  <TAB> new_args.append(k) <TAB>  <TAB>  <TAB> new_args.append(v) <TAB>  <TAB> expr = HyExpression([HySymbol(""setv"")] + new_args).replace(expr) <TAB> return expr","if k == HySymbol ( ""__init__"" ) :",149
2709,"def doDir(elem): <TAB> for child in elem.childNodes: <TAB>  <TAB> if not isinstance(child, minidom.Element): <TAB>  <TAB>  <TAB> continue <MASK> doDir(child) <TAB>  <TAB> elif child.tagName == ""Component"": <TAB>  <TAB>  <TAB> for grandchild in child.childNodes: <TAB>  <TAB>  <TAB>  <TAB> if not isinstance(grandchild, minidom.Element): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB>  <TAB> if grandchild.tagName != ""File"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB>  <TAB> files.add(grandchild.getAttribute(""Source"").replace(os.sep, ""/""))","if child . tagName == ""Directory"" :",152
2710,"def _v2_common(self, cfg): <TAB> LOG.debug(""v2_common: handling config:\n%s"", cfg) <TAB> if ""nameservers"" in cfg: <TAB>  <TAB> search = cfg.get(""nameservers"").get(""search"", []) <TAB>  <TAB> dns = cfg.get(""nameservers"").get(""addresses"", []) <TAB>  <TAB> name_cmd = {""type"": ""nameserver""} <MASK> name_cmd.update({""search"": search}) <TAB>  <TAB> if len(dns) > 0: <TAB>  <TAB>  <TAB> name_cmd.update({""addresses"": dns}) <TAB>  <TAB> LOG.debug(""v2(nameserver) -> v1(nameserver):\n%s"", name_cmd) <TAB>  <TAB> self.handle_nameserver(name_cmd)",if len ( search ) > 0 :,178
2711,"def __start_element_handler(self, name, attrs): <TAB> if name == ""mime-type"": <TAB>  <TAB> if self.type: <TAB>  <TAB>  <TAB> for extension in self.extensions: <TAB>  <TAB>  <TAB>  <TAB> self[extension] = self.type <TAB>  <TAB> self.type = attrs[""type""].lower() <TAB>  <TAB> self.extensions = [] <TAB> elif name == ""glob"": <TAB>  <TAB> pattern = attrs[""pattern""] <MASK> self.extensions.append(pattern[1:].lower())","if pattern . startswith ( ""*."" ) :",120
2712,"def get_attr_by_data_model(self, dmodel, exclude_record=False): <TAB> if exclude_record: <TAB>  <TAB> return list( <TAB>  <TAB>  <TAB> filter( <TAB>  <TAB>  <TAB>  <TAB> lambda x: x.data_model == dmodel and x.value == """" <MASK> else False, <TAB>  <TAB>  <TAB>  <TAB> self._inferred_intent, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> return list( <TAB>  <TAB>  <TAB> filter( <TAB>  <TAB>  <TAB>  <TAB> lambda x: x.data_model == dmodel and x.value == """" <TAB>  <TAB>  <TAB>  <TAB> if hasattr(x, ""data_model"") <TAB>  <TAB>  <TAB>  <TAB> else False, <TAB>  <TAB>  <TAB>  <TAB> self._inferred_intent, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> )","if x . attribute != ""Record"" and hasattr ( x , ""data_model"" )",196
2713,"def general(metadata, value): <TAB> if metadata.get(""commands"") and value: <TAB>  <TAB> if not metadata.get(""nargs""): <TAB>  <TAB>  <TAB> v = quote(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> v = value <TAB>  <TAB> return u""{0} {1}"".format(metadata[""commands""][0], v) <TAB> else: <TAB>  <TAB> if not value: <TAB>  <TAB>  <TAB> return None <MASK> return quote(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return value","elif not metadata . get ( ""nargs"" ) :",122
2714,"def get_images(self): <TAB> images = [] <TAB> try: <TAB>  <TAB> tag = MP4(self[""~filename""]) <TAB> except Exception: <TAB>  <TAB> return [] <TAB> for cover in tag.get(""covr"", []): <MASK> mime = ""image/jpeg"" <TAB>  <TAB> elif cover.imageformat == MP4Cover.FORMAT_PNG: <TAB>  <TAB>  <TAB> mime = ""image/png"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> mime = ""image/"" <TAB>  <TAB> f = get_temp_cover_file(cover) <TAB>  <TAB> images.append(EmbeddedImage(f, mime)) <TAB> return images",if cover . imageformat == MP4Cover . FORMAT_JPEG :,157
2715,"def run_cmd(self, util, value): <TAB> state = util.state <TAB> if not state.argument_supplied: <TAB>  <TAB> state.argument_supplied = True <TAB>  <TAB> if value == ""by_four"": <TAB>  <TAB>  <TAB> state.argument_value = 4 <MASK> state.argument_negative = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> state.argument_value = value <TAB> elif value == ""by_four"": <TAB>  <TAB> state.argument_value *= 4 <TAB> elif isinstance(value, int): <TAB>  <TAB> state.argument_value *= 10 <TAB>  <TAB> state.argument_value += value <TAB> elif value == ""negative"": <TAB>  <TAB> state.argument_value = -state.argument_value","elif value == ""negative"" :",169
2716,"def finish_character_data(self): <TAB> if self.character_data: <MASK> line, column = self.character_pos <TAB>  <TAB>  <TAB> token = XmlToken( <TAB>  <TAB>  <TAB>  <TAB> XML_CHARACTER_DATA, self.character_data, None, line, column <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.tokens.append(token) <TAB>  <TAB> self.character_data = """"",if not self . skip_ws or not self . character_data . isspace ( ) :,109
2717,"def check_syntax(filename, raise_error=False): <TAB> """"""Return True if syntax is okay."""""" <TAB> with autopep8.open_with_encoding(filename) as input_file: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> compile(input_file.read(), ""<string>"", ""exec"", dont_inherit=True) <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> except (SyntaxError, TypeError, UnicodeDecodeError): <MASK> raise <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return False",if raise_error :,118
2718,"def write(self, file): <TAB> if not self._been_written: <TAB>  <TAB> self._been_written = True <TAB>  <TAB> for attribute, value in self.__dict__.items(): <MASK> self.write_recursive(value, file) <TAB>  <TAB> w = file.write <TAB>  <TAB> w(""\t%s = {\n"" % self._id) <TAB>  <TAB> w(""\t\tisa = %s;\n"" % self.__class__.__name__) <TAB>  <TAB> for attribute, value in self.__dict__.items(): <TAB>  <TAB>  <TAB> if attribute[0] != ""_"": <TAB>  <TAB>  <TAB>  <TAB> w(""\t\t%s = %s;\n"" % (attribute, self.tostring(value))) <TAB>  <TAB> w(""\t};\n\n"")","if attribute [ 0 ] != ""_"" :",181
2719,"def update_service_key(kid, name=None, metadata=None): <TAB> try: <TAB>  <TAB> with db_transaction(): <TAB>  <TAB>  <TAB> key = db_for_update(ServiceKey.select().where(ServiceKey.kid == kid)).get() <TAB>  <TAB>  <TAB> if name is not None: <TAB>  <TAB>  <TAB>  <TAB> key.name = name <MASK> key.metadata.update(metadata) <TAB>  <TAB>  <TAB> key.save() <TAB> except ServiceKey.DoesNotExist: <TAB>  <TAB> raise ServiceKeyDoesNotExist",if metadata is not None :,127
2720,"def fill_buf(self, db, len_=None): <TAB> with open(""/dev/urandom"", ""rb"") as rfh: <TAB>  <TAB> first = True <TAB>  <TAB> for (id_,) in db.query(""SELECT id FROM test""): <TAB>  <TAB>  <TAB> if len_ is None and first: <TAB>  <TAB>  <TAB>  <TAB> val = b""""  # We always want to check this case <TAB>  <TAB>  <TAB>  <TAB> first = False <MASK> val = rfh.read(random.randint(0, 140)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> val = rfh.read(len_) <TAB>  <TAB>  <TAB> db.execute(""UPDATE test SET buf=? WHERE id=?"", (val, id_))",elif len_ is None :,164
2721,"def load_category_from_parser(self, parser): <TAB> for cate in parser.keys(): <TAB>  <TAB> id = parser.get_id(cate) <MASK> self._data[""cates""][id] = 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._data[""cates""][id] = self.count_unread(id) <TAB> self._is_init = False <TAB> self.save()",if self . _is_init :,102
2722,"def after_insert(self): <TAB> if self.prescription: <TAB>  <TAB> frappe.db.set_value( <TAB>  <TAB>  <TAB> ""Lab Prescription"", self.prescription, ""lab_test_created"", 1 <TAB>  <TAB> ) <MASK> self.invoiced = True <TAB> if not self.lab_test_name and self.template: <TAB>  <TAB> self.load_test_from_template() <TAB>  <TAB> self.reload()","if frappe . db . get_value ( ""Lab Prescription"" , self . prescription , ""invoiced"" ) :",130
2723,"def sync_terminology(self): <TAB> if self.is_source: <TAB>  <TAB> return <TAB> store = self.store <TAB> missing = [] <TAB> for source in self.component.get_all_sources(): <MASK> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> _unit, add = store.find_unit(source.context, source.source) <TAB>  <TAB> except UnitNotFound: <TAB>  <TAB>  <TAB> add = True <TAB>  <TAB> # Unit is already present <TAB>  <TAB> if not add: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> missing.append((source.context, source.source, """")) <TAB> if missing: <TAB>  <TAB> self.add_units(None, missing)","if ""terminology"" not in source . all_flags :",166
2724,def refresh(self): <TAB> if self._obj: <TAB>  <TAB> base = self._db.get_media_from_handle(self._obj.get_reference_handle()) <MASK> self._title = base.get_description() <TAB>  <TAB>  <TAB> self._value = base.get_path(),if base :,74
2725,"def _set_parse_context(self, tag, tag_attrs): <TAB> # special case: script or style parse context <TAB> if not self._wb_parse_context: <TAB>  <TAB> if tag == ""style"": <TAB>  <TAB>  <TAB> self._wb_parse_context = ""style"" <MASK> if self._allow_js_type(tag_attrs): <TAB>  <TAB>  <TAB>  <TAB> self._wb_parse_context = ""script""","elif tag == ""script"" :",106
2726,"def can_read(self): <TAB> if hasattr(self.file, ""__iter__""): <TAB>  <TAB> iterator = iter(self.file) <TAB>  <TAB> head = next(iterator, None) <TAB>  <TAB> if head is None: <TAB>  <TAB>  <TAB> self.repaired = [] <TAB>  <TAB>  <TAB> return True <MASK> self.repaired = itertools.chain([head], iterator) <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # We may have mangled a generator at this point, so just abort <TAB>  <TAB>  <TAB> raise IOSourceError( <TAB>  <TAB>  <TAB>  <TAB> ""Could not open source: %r (mode: %r)"" <TAB>  <TAB>  <TAB>  <TAB> % (self.file, self.options[""mode""]) <TAB>  <TAB>  <TAB> ) <TAB> return False","if isinstance ( head , str ) :",176
2727,"def wrapped_request_method(*args, **kwargs): <TAB> """"""Modifies HTTP headers to include a specified user-agent."""""" <TAB> if kwargs.get(""headers"") is not None: <TAB>  <TAB> if kwargs[""headers""].get(""user-agent""): <MASK> # Save the existing user-agent header and tack on our own. <TAB>  <TAB>  <TAB>  <TAB> kwargs[""headers""][""user-agent""] = ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f""{user_agent} "" f'{kwargs[""headers""][""user-agent""]}' <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> kwargs[""headers""][""user-agent""] = user_agent <TAB> else: <TAB>  <TAB> kwargs[""headers""] = {""user-agent"": user_agent} <TAB> return request_method(*args, **kwargs)","if user_agent not in kwargs [ ""headers"" ] [ ""user-agent"" ] :",191
2728,"def execute(self): <TAB> if self._dirty or not self._qr: <TAB>  <TAB> model_class = self.model_class <TAB>  <TAB> query_meta = self.get_query_meta() <TAB>  <TAB> if self._tuples: <TAB>  <TAB>  <TAB> ResultWrapper = TuplesQueryResultWrapper <TAB>  <TAB> elif self._dicts: <TAB>  <TAB>  <TAB> ResultWrapper = DictQueryResultWrapper <MASK> ResultWrapper = NaiveQueryResultWrapper <TAB>  <TAB> elif self._aggregate_rows: <TAB>  <TAB>  <TAB> ResultWrapper = AggregateQueryResultWrapper <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ResultWrapper = ModelQueryResultWrapper <TAB>  <TAB> self._qr = ResultWrapper(model_class, self._execute(), query_meta) <TAB>  <TAB> self._dirty = False <TAB>  <TAB> return self._qr <TAB> else: <TAB>  <TAB> return self._qr",elif self . _naive or not self . _joins or self . verify_naive ( ) :,198
2729,"def populate_data(apps, schema_editor): <TAB> Menu = apps.get_model(""menu"", ""Menu"") <TAB> for menu in Menu.objects.all(): <MASK> json_str = menu.json_content <TAB>  <TAB>  <TAB> while isinstance(json_str, str): <TAB>  <TAB>  <TAB>  <TAB> json_str = json.loads(json_str) <TAB>  <TAB>  <TAB> menu.json_content_new = json_str <TAB>  <TAB>  <TAB> menu.save()","if isinstance ( menu . json_content , str ) :",118
2730,"def virtualenv_exists(self): <TAB> if os.path.exists(self.virtualenv_location): <MASK> extra = [""Scripts"", ""activate.bat""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> extra = [""bin"", ""activate""] <TAB>  <TAB> return os.path.isfile(os.sep.join([self.virtualenv_location] + extra)) <TAB> return False","if os . name == ""nt"" :",96
2731,"def get_minkowski_function(name, variable): <TAB> fn_name = name + get_postfix(variable) <TAB> if hasattr(MEB, fn_name): <TAB>  <TAB> return getattr(MEB, fn_name) <TAB> else: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> f""Function {fn_name} not available. Please compile MinkowskiEngine with `torch.cuda.is_available()` is `True`."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(f""Function {fn_name} not available."")",if variable . is_cuda :,134
2732,"def build_temp_workspace(files): <TAB> tempdir = tempfile.mkdtemp(prefix=""yamllint-tests-"") <TAB> for path, content in files.items(): <TAB>  <TAB> path = os.path.join(tempdir, path).encode(""utf-8"") <MASK> os.makedirs(os.path.dirname(path)) <TAB>  <TAB> if type(content) is list: <TAB>  <TAB>  <TAB> os.mkdir(path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> mode = ""wb"" if isinstance(content, bytes) else ""w"" <TAB>  <TAB>  <TAB> with open(path, mode) as f: <TAB>  <TAB>  <TAB>  <TAB> f.write(content) <TAB> return tempdir",if not os . path . exists ( os . path . dirname ( path ) ) :,169
2733,"def clean_form(self, request, user, form, cleaned_data): <TAB> for field in self.get_fields(): <MASK> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> cleaned_data[field.fieldname] = field.clean( <TAB>  <TAB>  <TAB>  <TAB> request, user, cleaned_data[field.fieldname] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> except ValidationError as e: <TAB>  <TAB>  <TAB> form.add_error(field.fieldname, e) <TAB> return cleaned_data",if field . fieldname not in cleaned_data :,121
2734,"def setUp(self): <TAB> self.realm = service.InMemoryWordsRealm(""realmname"") <TAB> self.checker = checkers.InMemoryUsernamePasswordDatabaseDontUse() <TAB> self.portal = portal.Portal(self.realm, [self.checker]) <TAB> self.factory = service.IRCFactory(self.realm, self.portal) <TAB> c = [] <TAB> for nick in self.STATIC_USERS: <MASK> nick = nick.decode(""utf-8"") <TAB>  <TAB> c.append(self.realm.createUser(nick)) <TAB>  <TAB> self.checker.addUser(nick, nick + ""_password"") <TAB> return DeferredList(c)","if isinstance ( nick , bytes ) :",165
2735,"def __call__(self, message): <TAB> with self._lock: <TAB>  <TAB> self._pending_ack += 1 <TAB>  <TAB> self.max_pending_ack = max(self.max_pending_ack, self._pending_ack) <TAB>  <TAB> self.seen_message_ids.append(int(message.attributes[""seq_num""])) <TAB> time.sleep(self._processing_time) <TAB> with self._lock: <TAB>  <TAB> self._pending_ack -= 1 <TAB>  <TAB> message.ack() <TAB>  <TAB> self.completed_calls += 1 <MASK> if not self.done_future.done(): <TAB>  <TAB>  <TAB>  <TAB> self.done_future.set_result(None)",if self . completed_calls >= self . _resolve_at_msg_count :,173
2736,"def fill_in_standard_formats(book): <TAB> for x in std_format_code_types.keys(): <MASK> ty = std_format_code_types[x] <TAB>  <TAB>  <TAB> # Note: many standard format codes (mostly CJK date formats) have <TAB>  <TAB>  <TAB> # format strings that vary by locale; xlrd does not (yet) <TAB>  <TAB>  <TAB> # handle those; the type (date or numeric) is recorded but the fmt_str will be None. <TAB>  <TAB>  <TAB> fmt_str = std_format_strings.get(x) <TAB>  <TAB>  <TAB> fmtobj = Format(x, ty, fmt_str) <TAB>  <TAB>  <TAB> book.format_map[x] = fmtobj",if x not in book . format_map :,171
2737,"def FetchFn(bigger_than_3_only=None, less_than_7_only=None, even_only=None): <TAB> result = [] <TAB> for i in range(10): <TAB>  <TAB> # This line introduces a bug. <TAB>  <TAB> if bigger_than_3_only and less_than_7_only and i == 4: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if bigger_than_3_only and i <= 3: <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> if even_only and i % 2 != 0: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> result.append(i) <TAB> return result",if less_than_7_only and i >= 7 :,158
2738,"def next_instruction_is_function_or_class(lines): <TAB> """"""Is the first non-empty, non-commented line of the cell either a function or a class?"""""" <TAB> parser = StringParser(""python"") <TAB> for i, line in enumerate(lines): <MASK> parser.read_line(line) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> parser.read_line(line) <TAB>  <TAB> if not line.strip():  # empty line <TAB>  <TAB>  <TAB> if i > 0 and not lines[i - 1].strip(): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if line.startswith(""def "") or line.startswith(""class ""): <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> if line.startswith((""#"", ""@"", "" "", "")"")): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> return False <TAB> return False",if parser . is_quoted ( ) :,194
2739,"def __getattr__(self, key): <TAB> for tag in self.tag.children: <TAB>  <TAB> if tag.name not in (""input"",): <TAB>  <TAB>  <TAB> continue <MASK> from thug.DOM.W3C.Core.DOMImplementation import DOMImplementation <TAB>  <TAB>  <TAB> return DOMImplementation.createHTMLElement(self.doc, tag) <TAB> raise AttributeError","if ""name"" in tag . attrs and tag . attrs [ ""name"" ] in ( key , ) :",104
2740,"def process_signature(app, what, name, obj, options, signature, return_annotation): <TAB> if signature: <TAB>  <TAB> # replace Mock function names <TAB>  <TAB> signature = re.sub(""<Mock name='([^']+)'.*>"", ""\g<1>"", signature) <TAB>  <TAB> signature = re.sub(""tensorflow"", ""tf"", signature) <TAB>  <TAB> # add scope name to layer signatures: <MASK> if obj.use_scope: <TAB>  <TAB>  <TAB>  <TAB> signature = signature[0] + ""variable_scope_name, "" + signature[1:] <TAB>  <TAB>  <TAB> elif obj.use_scope is None: <TAB>  <TAB>  <TAB>  <TAB> signature = signature[0] + ""[variable_scope_name,] "" + signature[1:] <TAB> # signature: arg list <TAB> return signature, return_annotation","if hasattr ( obj , ""use_scope"" ) :",188
2741,"def countbox(self): <TAB> self.box = [1000, 1000, -1000, -1000] <TAB> for x, y in self.body: <TAB>  <TAB> if x < self.box[0]: <TAB>  <TAB>  <TAB> self.box[0] = x <TAB>  <TAB> if x > self.box[2]: <TAB>  <TAB>  <TAB> self.box[2] = x <TAB>  <TAB> if y < self.box[1]: <TAB>  <TAB>  <TAB> self.box[1] = y <MASK> self.box[3] = y",if y > self . box [ 3 ] :,131
2742,"def find_shell(): <TAB> global DEFAULT_SHELL <TAB> if not DEFAULT_SHELL: <TAB>  <TAB> for shell in propose_shell(): <MASK> DEFAULT_SHELL = shell <TAB>  <TAB>  <TAB>  <TAB> break <TAB> if not DEFAULT_SHELL: <TAB>  <TAB> DEFAULT_SHELL = ""/bin/sh"" <TAB> return DEFAULT_SHELL","if os . path . isfile ( shell ) and os . access ( shell , os . X_OK ) :",110
2743,"def addAggregators(sheet, cols, aggrnames): <TAB> ""Add each aggregator in list of *aggrnames* to each of *cols*."" <TAB> for aggrname in aggrnames: <TAB>  <TAB> aggrs = vd.aggregators.get(aggrname) <TAB>  <TAB> aggrs = aggrs if isinstance(aggrs, list) else [aggrs] <TAB>  <TAB> for aggr in aggrs: <TAB>  <TAB>  <TAB> for c in cols: <TAB>  <TAB>  <TAB>  <TAB> if not hasattr(c, ""aggregators""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> c.aggregators = [] <MASK> c.aggregators += [aggr]",if aggr and aggr not in c . aggregators :,149
2744,"def run(self, paths=[]): <TAB> items = [] <TAB> for item in SideBarSelection(paths).getSelectedItems(): <TAB>  <TAB> items.append(item.pathAbsoluteFromProjectEncoded()) <TAB> if len(items) > 0: <TAB>  <TAB> sublime.set_clipboard(""\n"".join(items)) <MASK> sublime.status_message(""Items copied"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sublime.status_message(""Item copied"")",if len ( items ) > 1 :,117
2745,"def social_user(backend, uid, user=None, *args, **kwargs): <TAB> provider = backend.name <TAB> social = backend.strategy.storage.user.get_social_auth(provider, uid) <TAB> if social: <MASK> msg = ""This account is already in use."" <TAB>  <TAB>  <TAB> raise AuthAlreadyAssociated(backend, msg) <TAB>  <TAB> elif not user: <TAB>  <TAB>  <TAB> user = social.user <TAB> return { <TAB>  <TAB> ""social"": social, <TAB>  <TAB> ""user"": user, <TAB>  <TAB> ""is_new"": user is None, <TAB>  <TAB> ""new_association"": social is None, <TAB> }",if user and social . user != user :,170
2746,"def _text(bitlist): <TAB> out = """" <TAB> for typ, text in bitlist: <TAB>  <TAB> if not typ: <TAB>  <TAB>  <TAB> out += text <TAB>  <TAB> elif typ == ""em"": <TAB>  <TAB>  <TAB> out += ""\\fI%s\\fR"" % text <MASK> out += ""\\fB%s\\fR"" % text <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""unexpected tag %r inside text"" % (typ,)) <TAB> out = out.strip() <TAB> out = re.sub(re.compile(r""^\s+"", re.M), """", out) <TAB> return out","elif typ in [ ""strong"" , ""code"" ] :",150
2747,"def OnRadioSelect(self, event): <TAB> fitID = self.mainFrame.getActiveFit() <TAB> if fitID is not None: <TAB>  <TAB> self.mainFrame.command.Submit( <TAB>  <TAB>  <TAB> cmd.GuiChangeImplantLocationCommand( <TAB>  <TAB>  <TAB>  <TAB> fitID=fitID, <TAB>  <TAB>  <TAB>  <TAB> source=ImplantLocation.FIT <MASK> else ImplantLocation.CHARACTER, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> )",if self . rbFit . GetValue ( ),119
2748,"def hexdump(data): <TAB> """"""yield lines with hexdump of data"""""" <TAB> values = [] <TAB> ascii = [] <TAB> offset = 0 <TAB> for h, a in sixteen(data): <MASK> yield (offset, "" "".join(["""".join(values), """".join(ascii)])) <TAB>  <TAB>  <TAB> del values[:] <TAB>  <TAB>  <TAB> del ascii[:] <TAB>  <TAB>  <TAB> offset += 0x10 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> values.append(h) <TAB>  <TAB>  <TAB> ascii.append(a)",if h is None :,124
2749,"def submit(self): <TAB> bot_token = self.config[""bot_token""] <TAB> chat_ids = self.config[""chat_id""] <TAB> chat_ids = [chat_ids] if isinstance(chat_ids, str) else chat_ids <TAB> text = ""\n"".join(super().submit()) <TAB> if not text: <TAB>  <TAB> logger.debug(""Not calling telegram API (no changes)"") <TAB>  <TAB> return <TAB> result = None <TAB> for chunk in chunkstring(text, self.MAX_LENGTH, numbering=True): <TAB>  <TAB> for chat_id in chat_ids: <TAB>  <TAB>  <TAB> res = self.submitToTelegram(bot_token, chat_id, chunk) <MASK> result = res <TAB> return result",if res . status_code != requests . codes . ok or res is None :,187
2750,"def onMessage(self, payload, isBinary): <TAB> if not isBinary: <TAB>  <TAB> self.result = ""Expected binary message with payload, but got binary."" <TAB> else: <MASK> self.result = ( <TAB>  <TAB>  <TAB>  <TAB> ""Expected binary message with payload of length %d, but got %d."" <TAB>  <TAB>  <TAB>  <TAB> % (self.DATALEN, len(payload)) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ## FIXME : check actual content <TAB>  <TAB>  <TAB> ## <TAB>  <TAB>  <TAB> self.behavior = Case.OK <TAB>  <TAB>  <TAB> self.result = ""Received binary message of length %d."" % len(payload) <TAB> self.p.createWirelog = True <TAB> self.p.sendClose(self.p.CLOSE_STATUS_CODE_NORMAL)",if len ( payload ) != self . DATALEN :,192
2751,"def verify_output(actual, expected): <TAB> actual = _read_file(actual, ""Actual"") <TAB> expected = _read_file(join(CURDIR, expected), ""Expected"") <TAB> if len(expected) != len(actual): <TAB>  <TAB> raise AssertionError( <TAB>  <TAB>  <TAB> ""Lengths differ. Expected %d lines but got %d"" <TAB>  <TAB>  <TAB> % (len(expected), len(actual)) <TAB>  <TAB> ) <TAB> for exp, act in zip(expected, actual): <TAB>  <TAB> tester = fnmatchcase if ""*"" in exp else eq <MASK> raise AssertionError( <TAB>  <TAB>  <TAB>  <TAB> ""Lines differ.\nExpected: %s\nActual:   %s"" % (exp, act) <TAB>  <TAB>  <TAB> )","if not tester ( act . rstrip ( ) , exp . rstrip ( ) ) :",179
2752,"def _in_out_vector_helper(self, name1, name2, ceil): <TAB> vector = [] <TAB> stats = self.record <TAB> if ceil is None: <TAB>  <TAB> ceil = self._get_max_rate(name1, name2) <TAB> maxlen = self.config.get_stats_history_length() <TAB> for n in [name1, name2]: <TAB>  <TAB> for i in range(maxlen + 1): <MASK> vector.append(float(stats[i][n]) / ceil) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> vector.append(0.0) <TAB> return vector",if i < len ( stats ) :,153
2753,"def _init_param(param, mode): <TAB> if isinstance(param, str): <TAB>  <TAB> param = _resolve(param) <TAB> elif isinstance(param, (list, tuple)): <TAB>  <TAB> param = [_init_param(p, mode) for p in param] <TAB> elif isinstance(param, dict): <MASK> param = from_params(param, mode=mode) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> param = {k: _init_param(v, mode) for k, v in param.items()} <TAB> return param","if { ""ref"" , ""class_name"" , ""config_path"" } . intersection ( param . keys ( ) ) :",145
2754,"def link_pantsrefs(soups, precomputed): <TAB> """"""Transorm soups: <a pantsref=""foo""> becomes <a href=""../foo_page.html#foo"">"""""" <TAB> for (page, soup) in soups.items(): <TAB>  <TAB> for a in soup.find_all(""a""): <TAB>  <TAB>  <TAB> if not a.has_attr(""pantsref""): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> pantsref = a[""pantsref""] <MASK> raise TaskError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f'Page {page} has pantsref ""{pantsref}"" and I cannot find pantsmark for it' <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> a[""href""] = rel_href(page, precomputed.pantsref[pantsref])",if pantsref not in precomputed . pantsref :,194
2755,"def _gridconvvalue(self, value): <TAB> if isinstance(value, (str, _tkinter.Tcl_Obj)): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> svalue = str(value) <TAB>  <TAB>  <TAB> if not svalue: <TAB>  <TAB>  <TAB>  <TAB> return None <MASK> return getdouble(svalue) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return getint(svalue) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> pass <TAB> return value","elif ""."" in svalue :",116
2756,"def default(self, o): <TAB> try: <MASK> return str(o) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # remove unwanted attributes from the provider object during conversion to json <TAB>  <TAB>  <TAB> if hasattr(o, ""profile""): <TAB>  <TAB>  <TAB>  <TAB> del o.profile <TAB>  <TAB>  <TAB> if hasattr(o, ""credentials""): <TAB>  <TAB>  <TAB>  <TAB> del o.credentials <TAB>  <TAB>  <TAB> if hasattr(o, ""metadata_path""): <TAB>  <TAB>  <TAB>  <TAB> del o.metadata_path <TAB>  <TAB>  <TAB> if hasattr(o, ""services_config""): <TAB>  <TAB>  <TAB>  <TAB> del o.services_config <TAB>  <TAB>  <TAB> return vars(o) <TAB> except Exception as e: <TAB>  <TAB> return str(o)",if type ( o ) == datetime . datetime :,172
2757,"def transform_kwarg(self, name, value, split_single_char_options): <TAB> if len(name) == 1: <MASK> return [""-%s"" % name] <TAB>  <TAB> elif value not in (False, None): <TAB>  <TAB>  <TAB> if split_single_char_options: <TAB>  <TAB>  <TAB>  <TAB> return [""-%s"" % name, ""%s"" % value] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return [""-%s%s"" % (name, value)] <TAB> else: <TAB>  <TAB> if value is True: <TAB>  <TAB>  <TAB> return [""--%s"" % dashify(name)] <TAB>  <TAB> elif value is not False and value is not None: <TAB>  <TAB>  <TAB> return [""--%s=%s"" % (dashify(name), value)] <TAB> return []",if value is True :,183
2758,"def handle(self, context, sign, *args): <TAB> if context.rounding in (ROUND_HALF_UP, ROUND_HALF_EVEN, ROUND_HALF_DOWN, ROUND_UP): <TAB>  <TAB> return Infsign[sign] <TAB> if sign == 0: <MASK> return Infsign[sign] <TAB>  <TAB> return Decimal((sign, (9,) * context.prec, context.Emax - context.prec + 1)) <TAB> if sign == 1: <TAB>  <TAB> if context.rounding == ROUND_FLOOR: <TAB>  <TAB>  <TAB> return Infsign[sign] <TAB>  <TAB> return Decimal((sign, (9,) * context.prec, context.Emax - context.prec + 1))",if context . rounding == ROUND_CEILING :,184
2759,"def OnLeftUp(self, event): <TAB> # Stop Drawing <TAB> if self.Drawing: <TAB>  <TAB> self.Drawing = False <MASK> world_rect = ( <TAB>  <TAB>  <TAB>  <TAB> self.Canvas.PixelToWorld(self.RBRect[0]), <TAB>  <TAB>  <TAB>  <TAB> self.Canvas.ScalePixelToWorld(self.RBRect[1]), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> wx.CallAfter(self.CallBack, world_rect) <TAB> self.RBRect = None",if self . RBRect :,127
2760,"def _map_answers(answers): <TAB> result = [] <TAB> for a in answers.split(""|""): <TAB>  <TAB> user_answers = [] <TAB>  <TAB> result.append(dict(sourcerAnswers=user_answers)) <TAB>  <TAB> for r in a.split("",""): <MASK> user_answers.append(dict(noAnswer=True)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> start_, end_ = map(int, r.split("":"")) <TAB>  <TAB>  <TAB>  <TAB> user_answers.append(dict(s=start_, e=end_)) <TAB> return result","if r == ""None"" :",138
2761,"def parse_edges(self, pcb): <TAB> edges = [] <TAB> drawings = list(pcb.GetDrawings()) <TAB> bbox = None <TAB> for m in pcb.GetModules(): <TAB>  <TAB> for g in m.GraphicalItems(): <TAB>  <TAB>  <TAB> drawings.append(g) <TAB> for d in drawings: <MASK> parsed_drawing = self.parse_drawing(d) <TAB>  <TAB>  <TAB> if parsed_drawing: <TAB>  <TAB>  <TAB>  <TAB> edges.append(parsed_drawing) <TAB>  <TAB>  <TAB>  <TAB> if bbox is None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> bbox = d.GetBoundingBox() <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> bbox.Merge(d.GetBoundingBox()) <TAB> if bbox: <TAB>  <TAB> bbox.Normalize() <TAB> return edges, bbox",if d . GetLayer ( ) == pcbnew . Edge_Cuts :,197
2762,"def get_size(self): <TAB> size = self.start_size <TAB> for operation in self.ran_operations: <MASK> size = operation[1][0] <TAB>  <TAB> elif operation[0] == ""crop"": <TAB>  <TAB>  <TAB> crop = operation[1][0] <TAB>  <TAB>  <TAB> size = crop[2] - crop[0], crop[3] - crop[1] <TAB> return size","if operation [ 0 ] == ""resize"" :",104
2763,"def migrate_account_metadata(account_id): <TAB> from inbox.models.session import session_scope <TAB> from inbox.models import Account <TAB> with session_scope(versioned=False) as db_session: <TAB>  <TAB> account = db_session.query(Account).get(account_id) <MASK> create_categories_for_easfoldersyncstatuses(account, db_session) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> create_categories_for_folders(account, db_session) <TAB>  <TAB> if account.discriminator == ""gmailaccount"": <TAB>  <TAB>  <TAB> set_labels_for_imapuids(account, db_session) <TAB>  <TAB> db_session.commit()","if account . discriminator == ""easaccount"" :",168
2764,"def OnEndDrag(self, event): <TAB> self.StopDragging() <TAB> dropTarget = event.GetItem() <TAB> if not dropTarget: <TAB>  <TAB> dropTarget = self.GetRootItem() <TAB> if self.IsValidDropTarget(dropTarget): <TAB>  <TAB> self.UnselectAll() <MASK> self.SelectItem(dropTarget) <TAB>  <TAB> self.OnDrop(dropTarget, self._dragItem)",if dropTarget != self . GetRootItem ( ) :,109
2765,"def validate(self, frame, value): <TAB> if self.sep and isinstance(value, string_types): <TAB>  <TAB> value = value.split(self.sep) <TAB> if isinstance(value, list): <MASK> return [self.specs[0].validate(frame, v) for v in value] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return [ <TAB>  <TAB>  <TAB>  <TAB> [s.validate(frame, v) for (v, s) in izip(val, self.specs)] <TAB>  <TAB>  <TAB>  <TAB> for val in value <TAB>  <TAB>  <TAB> ] <TAB> raise ValueError(""Invalid MultiSpec data: %r"" % value)",if len ( self . specs ) == 1 :,153
2766,"def __init__(self, action_space=None, network=None, network_kwargs=None, hparams=None): <TAB> QNetBase.__init__(self, hparams=hparams) <TAB> with tf.variable_scope(self.variable_scope): <MASK> action_space = Space(low=0, high=self._hparams.action_space, dtype=np.int32) <TAB>  <TAB> self._action_space = action_space <TAB>  <TAB> self._append_output_layer()",if action_space is None :,120
2767,"def n_weights(self): <TAB> """"""Return the number of weights (parameters) in this network."""""" <TAB> n_weights = 0 <TAB> for i, w in enumerate(self.all_weights): <TAB>  <TAB> n = 1 <TAB>  <TAB> # for s in p.eval().shape: <TAB>  <TAB> for s in w.get_shape(): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> s = int(s) <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> s = 1 <MASK> n = n * s <TAB>  <TAB> n_weights = n_weights + n <TAB> # print(""num of weights (parameters) %d"" % n_weights) <TAB> return n_weights",if s :,161
2768,"def _arg_desc(name, ctx): <TAB> for param in ctx.command.params: <TAB>  <TAB> if param.name == name: <TAB>  <TAB>  <TAB> desc = param.opts[-1] <MASK> desc = param.human_readable_name <TAB>  <TAB>  <TAB> return desc <TAB> raise AssertionError(name)","if desc [ 0 ] != ""-"" :",82
2769,"def walk(directory, path_so_far): <TAB> for name in sorted(os.listdir(directory)): <TAB>  <TAB> if any(fnmatch(name, pattern) for pattern in basename_ignore): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> path = path_so_far + ""/"" + name if path_so_far else name <TAB>  <TAB> if any(fnmatch(path, pattern) for pattern in path_ignore): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> full_name = os.path.join(directory, name) <TAB>  <TAB> if os.path.isdir(full_name): <TAB>  <TAB>  <TAB> for file_path in walk(full_name, path): <TAB>  <TAB>  <TAB>  <TAB> yield file_path <MASK> yield path",elif os . path . isfile ( full_name ) :,172
2770,"def cache_dst(self): <TAB> final_dst = None <TAB> final_linenb = None <TAB> for linenb, assignblk in enumerate(self): <TAB>  <TAB> for dst, src in viewitems(assignblk): <TAB>  <TAB>  <TAB> if dst.is_id(""IRDst""): <MASK> raise ValueError(""Multiple destinations!"") <TAB>  <TAB>  <TAB>  <TAB> final_dst = src <TAB>  <TAB>  <TAB>  <TAB> final_linenb = linenb <TAB> self._dst = final_dst <TAB> self._dst_linenb = final_linenb <TAB> return final_dst",if final_dst is not None :,144
2771,"def run(self, args, **kwargs): <TAB> if args.resource_ref or args.policy_type: <TAB>  <TAB> filters = {} <MASK> filters[""resource_ref""] = args.resource_ref <TAB>  <TAB> if args.policy_type: <TAB>  <TAB>  <TAB> filters[""policy_type""] = args.policy_type <TAB>  <TAB> filters.update(**kwargs) <TAB>  <TAB> return self.manager.query(**filters) <TAB> else: <TAB>  <TAB> return self.manager.get_all(**kwargs)",if args . resource_ref :,123
2772,"def __init__(self, folders): <TAB> self.folders = folders <TAB> self.duplicates = {} <TAB> for folder, path in folders.items(): <TAB>  <TAB> duplicates = [] <TAB>  <TAB> for other_folder, other_path in folders.items(): <TAB>  <TAB>  <TAB> if other_folder == folder: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if other_path == path: <TAB>  <TAB>  <TAB>  <TAB> duplicates.append(other_folder) <MASK> self.duplicates[folder] = duplicates",if len ( duplicates ) :,117
2773,"def limit_clause(self, select, **kw): <TAB> text = """" <TAB> if select._limit_clause is not None: <TAB>  <TAB> text += ""\n LIMIT "" + self.process(select._limit_clause, **kw) <TAB> if select._offset_clause is not None: <MASK> text += ""\n LIMIT "" + self.process(sql.literal(-1)) <TAB>  <TAB> text += "" OFFSET "" + self.process(select._offset_clause, **kw) <TAB> else: <TAB>  <TAB> text += "" OFFSET "" + self.process(sql.literal(0), **kw) <TAB> return text",if select . _limit_clause is None :,150
2774,"def _get_activation(self, act): <TAB> """"""Get activation block based on the name."""""" <TAB> if isinstance(act, str): <TAB>  <TAB> if act.lower() == ""gelu"": <TAB>  <TAB>  <TAB> return GELU() <MASK> return GELU(approximate=True) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return gluon.nn.Activation(act) <TAB> assert isinstance(act, gluon.Block) <TAB> return act","elif act . lower ( ) == ""approx_gelu"" :",112
2775,"def __eq__(self, other): <TAB> try: <TAB>  <TAB> if self.type != other.type: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> if self.type == ""ASK"": <TAB>  <TAB>  <TAB> return self.askAnswer == other.askAnswer <MASK> return self.vars == other.vars and self.bindings == other.bindings <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.graph == other.graph <TAB> except: <TAB>  <TAB> return False","elif self . type == ""SELECT"" :",116
2776,"def _get_text_nodes(nodes, html_body): <TAB> text = [] <TAB> open_tags = 0 <TAB> for node in nodes: <TAB>  <TAB> if isinstance(node, HtmlTag): <MASK> open_tags += 1 <TAB>  <TAB>  <TAB> elif node.tag_type == CLOSE_TAG: <TAB>  <TAB>  <TAB>  <TAB> open_tags -= 1 <TAB>  <TAB> elif ( <TAB>  <TAB>  <TAB> isinstance(node, HtmlDataFragment) <TAB>  <TAB>  <TAB> and node.is_text_content <TAB>  <TAB>  <TAB> and open_tags == 0 <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> text.append(html_body[node.start : node.end]) <TAB> return text",if node . tag_type == OPEN_TAG :,165
2777,"def test_do_change(self): <TAB> """"""Test if VTK object changes when trait is changed."""""" <TAB> p = Prop() <TAB> p.edge_visibility = not p.edge_visibility <TAB> p.representation = ""p"" <TAB> p.opacity = 0.5 <TAB> p.color = (0, 1, 0) <TAB> p.diffuse_color = (1, 1, 1) <TAB> p.specular_color = (1, 1, 0) <TAB> for t, g in p._updateable_traits_: <TAB>  <TAB> val = getattr(p._vtk_obj, g)() <MASK> self.assertEqual(val, getattr(p, t + ""_"")) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertEqual(val, getattr(p, t))","if t == ""representation"" :",185
2778,"def update_item(source_doc, target_doc, source_parent): <TAB> target_doc.t_warehouse = """" <TAB> if source_doc.material_request_item and source_doc.material_request: <TAB>  <TAB> add_to_transit = frappe.db.get_value( <TAB>  <TAB>  <TAB> ""Stock Entry"", source_name, ""add_to_transit"" <TAB>  <TAB> ) <MASK> warehouse = frappe.get_value( <TAB>  <TAB>  <TAB>  <TAB> ""Material Request Item"", source_doc.material_request_item, ""warehouse"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> target_doc.t_warehouse = warehouse <TAB> target_doc.s_warehouse = source_doc.t_warehouse <TAB> target_doc.qty = source_doc.qty - source_doc.transferred_qty",if add_to_transit :,198
2779,"def get_drive(self, root_path="""", volume_guid_path=""""): <TAB> for drive in self.drives: <MASK> config_root_path = drive.get(""root_path"") <TAB>  <TAB>  <TAB> if config_root_path and root_path == config_root_path: <TAB>  <TAB>  <TAB>  <TAB> return drive <TAB>  <TAB> elif volume_guid_path: <TAB>  <TAB>  <TAB> config_volume_guid_path = drive.get(""volume_guid_path"") <TAB>  <TAB>  <TAB> if config_volume_guid_path and config_volume_guid_path == volume_guid_path: <TAB>  <TAB>  <TAB>  <TAB> return drive",if root_path :,148
2780,"def f_freeze(_): <TAB> repos = utils.get_repos() <TAB> for name, path in repos.items(): <TAB>  <TAB> url = """" <TAB>  <TAB> cp = subprocess.run([""git"", ""remote"", ""-v""], cwd=path, capture_output=True) <MASK> url = cp.stdout.decode(""utf-8"").split(""\n"")[0].split()[1] <TAB>  <TAB> print(f""{url},{name},{path}"")",if cp . returncode == 0 :,111
2781,"def conj(self): <TAB> dtype = self.dtype <TAB> if issubclass(self.dtype.type, np.complexfloating): <MASK> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB> ""only contiguous arrays may "" ""be used as arguments to this operation"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if self.flags.f_contiguous: <TAB>  <TAB>  <TAB> order = ""F"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> order = ""C"" <TAB>  <TAB> result = self._new_like_me(order=order) <TAB>  <TAB> func = elementwise.get_conj_kernel(dtype) <TAB>  <TAB> func.prepared_async_call( <TAB>  <TAB>  <TAB> self._grid, self._block, None, self.gpudata, result.gpudata, self.mem_size <TAB>  <TAB> ) <TAB>  <TAB> return result <TAB> else: <TAB>  <TAB> return self",if not self . flags . forc :,198
2782,"def detect_reentrancy(self, contract): <TAB> for function in contract.functions_and_modifiers_declared: <TAB>  <TAB> if function.is_implemented: <MASK> continue <TAB>  <TAB>  <TAB> self._explore(function.entry_point, []) <TAB>  <TAB>  <TAB> function.context[self.KEY] = True",if self . KEY in function . context :,87
2783,"def test_default_configuration_no_encoding(self): <TAB> transformations = [] <TAB> for i in range(2): <TAB>  <TAB> transformation, original = _test_preprocessing(NoEncoding) <TAB>  <TAB> self.assertEqual(transformation.shape, original.shape) <TAB>  <TAB> self.assertTrue((transformation == original).all()) <TAB>  <TAB> transformations.append(transformation) <MASK> self.assertTrue((transformations[-1] == transformations[-2]).all())",if len ( transformations ) > 1 :,114
2784,"def main(): <TAB> """"""main function"""""" <TAB> # todo: lookuo real description <TAB> parser = argparse.ArgumentParser(description=""Let a cow speak for you"") <TAB> parser.add_argument(""text"", nargs=""*"", default=None, help=""text to say"") <TAB> ns = parser.parse_args() <TAB> if (ns.text is None) or (len(ns.text) == 0): <TAB>  <TAB> text = """" <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> inp = sys.stdin.read(4096) <TAB>  <TAB>  <TAB> if inp.endswith(""\n""): <TAB>  <TAB>  <TAB>  <TAB> inp = inp[:-1] <MASK> break <TAB>  <TAB>  <TAB> text += inp <TAB> else: <TAB>  <TAB> text = "" "".join(ns.text) <TAB> cow = get_cow(text) <TAB> print(cow)",if not inp :,193
2785,"def prehook(self, emu, op, eip): <TAB> if op in self.badops: <TAB>  <TAB> emu.stopEmu() <TAB>  <TAB> raise v_exc.BadOpBytes(op.va) <TAB> if op.mnem in STOS: <TAB>  <TAB> if self.arch == ""i386"": <TAB>  <TAB>  <TAB> reg = emu.getRegister(envi.archs.i386.REG_EDI) <TAB>  <TAB> elif self.arch == ""amd64"": <TAB>  <TAB>  <TAB> reg = emu.getRegister(envi.archs.amd64.REG_RDI) <MASK> self.vw.makePointer(reg, follow=True)",if self . vw . isValidPointer ( reg ) and self . vw . getLocation ( reg ) is None :,186
2786,"def get_boarding_status(project): <TAB> status = ""Pending"" <TAB> if project: <TAB>  <TAB> doc = frappe.get_doc(""Project"", project) <TAB>  <TAB> if flt(doc.percent_complete) > 0.0 and flt(doc.percent_complete) < 100.0: <TAB>  <TAB>  <TAB> status = ""In Process"" <MASK> status = ""Completed"" <TAB>  <TAB> return status",elif flt ( doc . percent_complete ) == 100.0 :,116
2787,"def set_weights(self, new_weights): <TAB> weights = self.get_weights() <TAB> if len(weights) != len(new_weights): <TAB>  <TAB> raise ValueError(""len of lists mismatch"") <TAB> tuples = [] <TAB> for w, new_w in zip(weights, new_weights): <MASK> new_w = new_w.reshape(w.shape) <TAB>  <TAB> tuples.append((w, new_w)) <TAB> nn.batch_set_value(tuples)",if len ( w . shape ) != new_w . shape :,129
2788,"def reload_json_api_settings(*args, **kwargs): <TAB> django_setting = kwargs[""setting""] <TAB> setting = django_setting.replace(JSON_API_SETTINGS_PREFIX, """") <TAB> value = kwargs[""value""] <TAB> if setting in DEFAULTS.keys(): <MASK> setattr(json_api_settings, setting, value) <TAB>  <TAB> elif hasattr(json_api_settings, setting): <TAB>  <TAB>  <TAB> delattr(json_api_settings, setting)",if value is not None :,115
2789,"def knamn(self, sup, cdict): <TAB> cname = cdict[sup].class_name <TAB> if not cname: <TAB>  <TAB> (namesp, tag) = cdict[sup].name.split(""."") <MASK> ctag = self.root.modul[namesp].factory(tag).__class__.__name__ <TAB>  <TAB>  <TAB> cname = ""%s.%s"" % (namesp, ctag) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> cname = tag + ""_"" <TAB> return cname",if namesp :,117
2790,"def setdefault(self, key, default=None): <TAB> try: <TAB>  <TAB> o = self.data[key]() <TAB> except KeyError: <TAB>  <TAB> o = None <TAB> if o is None: <MASK> self._commit_removals() <TAB>  <TAB> self.data[key] = KeyedRef(default, self._remove, key) <TAB>  <TAB> return default <TAB> else: <TAB>  <TAB> return o",if self . _pending_removals :,104
2791,"def __on_item_activated(self, event): <TAB> if self.__module_view: <TAB>  <TAB> module = self.get_event_module(event) <TAB>  <TAB> self.__module_view.set_selection(module.module_num) <MASK> self.input_list_ctrl.deactivate_active_item() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.list_ctrl.deactivate_active_item() <TAB>  <TAB>  <TAB> for index in range(self.list_ctrl.GetItemCount()): <TAB>  <TAB>  <TAB>  <TAB> if self.list_ctrl.IsSelected(index): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.list_ctrl.Select(index, False) <TAB> self.__controller.enable_module_controls_panel_buttons()",if event . EventObject is self . list_ctrl :,181
2792,"def _create_valid_graph(graph): <TAB> nodes = graph.nodes() <TAB> for i in range(len(nodes)): <TAB>  <TAB> for j in range(len(nodes)): <TAB>  <TAB>  <TAB> if i == j: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> edge = (nodes[i], nodes[j]) <MASK> graph.del_edge(edge) <TAB>  <TAB>  <TAB> graph.add_edge(edge, 1)",if graph . has_edge ( edge ) :,112
2793,"def _parse_param_value(name, datatype, default): <TAB> if datatype == ""bool"": <MASK> return True <TAB>  <TAB> elif default.lower() == ""false"": <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _s = ""{}: Invalid default value '{}' for bool parameter {}"" <TAB>  <TAB>  <TAB> raise SyntaxError(_s.format(self.name, default, p)) <TAB> elif datatype == ""int"": <TAB>  <TAB> if type(default) == int: <TAB>  <TAB>  <TAB> return default <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return int(default, 0) <TAB> elif datatype == ""real"": <TAB>  <TAB> if type(default) == float: <TAB>  <TAB>  <TAB> return default <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return float(default) <TAB> else: <TAB>  <TAB> return str(default)","if default . lower ( ) == ""true"" :",191
2794,"def get_size(self, shape_info): <TAB> # The size is the data, that have constant size. <TAB> state = np.random.RandomState().get_state() <TAB> size = 0 <TAB> for elem in state: <MASK> size += len(elem) <TAB>  <TAB> elif isinstance(elem, np.ndarray): <TAB>  <TAB>  <TAB> size += elem.size * elem.itemsize <TAB>  <TAB> elif isinstance(elem, int): <TAB>  <TAB>  <TAB> size += np.dtype(""int"").itemsize <TAB>  <TAB> elif isinstance(elem, float): <TAB>  <TAB>  <TAB> size += np.dtype(""float"").itemsize <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise NotImplementedError() <TAB> return size","if isinstance ( elem , str ) :",159
2795,"def _merge_substs(self, subst, new_substs): <TAB> subst = subst.copy() <TAB> for new_subst in new_substs: <TAB>  <TAB> for name, var in new_subst.items(): <TAB>  <TAB>  <TAB> if name not in subst: <TAB>  <TAB>  <TAB>  <TAB> subst[name] = var <MASK> subst[name].PasteVariable(var) <TAB> return subst",elif subst [ name ] is not var :,109
2796,"def _load_weights_if_possible(self, model, init_weight_path=None): <TAB> """"""Loads model weights when it is provided."""""" <TAB> if init_weight_path: <TAB>  <TAB> logging.info(""Load weights: {}"".format(init_weight_path)) <MASK> checkpoint = tf.train.Checkpoint( <TAB>  <TAB>  <TAB>  <TAB> model=model, optimizer=self._create_optimizer() <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> checkpoint.restore(init_weight_path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> model.load_weights(init_weight_path) <TAB> else: <TAB>  <TAB> logging.info(""Weights not loaded from path:{}"".format(init_weight_path))",if self . use_tpu :,168
2797,"def _cleanup_inactive_receivexlogs(self, site): <TAB> if site in self.receivexlogs: <TAB>  <TAB> if not self.receivexlogs[site].running: <MASK> self.receivexlogs[site].join() <TAB>  <TAB>  <TAB> del self.receivexlogs[site]",if self . receivexlogs [ site ] . is_alive ( ) :,92
2798,"def get_asset(self, path): <TAB> """"""Loads an asset by path."""""" <TAB> clean_path = cleanup_path(path).strip(""/"") <TAB> nodes = [self.asset_root] + self.theme_asset_roots <TAB> for node in nodes: <TAB>  <TAB> for piece in clean_path.split(""/""): <TAB>  <TAB>  <TAB> node = node.get_child(piece) <MASK> break <TAB>  <TAB> if node is not None: <TAB>  <TAB>  <TAB> return node <TAB> return None",if node is None :,119
2799,"def palindromic_substrings(s): <TAB> if not s: <TAB>  <TAB> return [[]] <TAB> results = [] <TAB> for i in range(len(s), 0, -1): <TAB>  <TAB> sub = s[:i] <MASK> for rest in palindromic_substrings(s[i:]): <TAB>  <TAB>  <TAB>  <TAB> results.append([sub] + rest) <TAB> return results",if sub == sub [ : : - 1 ] :,102
2800,"def debug_tree(tree): <TAB> l = [] <TAB> for elt in tree: <MASK> l.append(_names.get(elt, elt)) <TAB>  <TAB> elif isinstance(elt, str): <TAB>  <TAB>  <TAB> l.append(elt) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> l.append(debug_tree(elt)) <TAB> return l","if isinstance ( elt , ( int , long ) ) :",92
2801,"def shared_username(account): <TAB> username = os.environ.get(""SHARED_USERNAME"", ""PKKid"") <TAB> for user in account.users(): <MASK> return username <TAB>  <TAB> elif ( <TAB>  <TAB>  <TAB> user.username <TAB>  <TAB>  <TAB> and user.email <TAB>  <TAB>  <TAB> and user.id <TAB>  <TAB>  <TAB> and username.lower() <TAB>  <TAB>  <TAB> in (user.username.lower(), user.email.lower(), str(user.id)) <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> return username <TAB> pytest.skip(""Shared user %s wasn`t found in your MyPlex account"" % username)",if user . title . lower ( ) == username . lower ( ) :,152
2802,"def process_schema_element(self, e): <TAB> if e.name is None: <TAB>  <TAB> return <TAB> self.debug1(""adding element: %s"", e.name) <TAB> t = self.get_type(e.type) <TAB> if t: <MASK> del self.pending_elements[e.name] <TAB>  <TAB> self.retval[self.tns].elements[e.name] = e <TAB> else: <TAB>  <TAB> self.pending_elements[e.name] = e",if e . name in self . pending_elements :,129
2803,"def __setitem__(self, key, value): <TAB> with self._lock: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> link = self._get_link_and_move_to_front_of_ll(key) <TAB>  <TAB> except KeyError: <MASK> self._set_key_and_add_to_front_of_ll(key, value) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> evicted = self._set_key_and_evict_last_in_ll(key, value) <TAB>  <TAB>  <TAB>  <TAB> super(LRI, self).__delitem__(evicted) <TAB>  <TAB>  <TAB> super(LRI, self).__setitem__(key, value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> link[VALUE] = value",if len ( self ) < self . max_size :,181
2804,"def __delattr__(self, name): <TAB> if name == ""__dict__"": <TAB>  <TAB> raise AttributeError( <TAB>  <TAB>  <TAB> ""%r object attribute '__dict__' is read-only"" % self.__class__.__name__ <TAB>  <TAB> ) <TAB> if name in self._local_type_vars: <MASK> # A data descriptor, like a property or a slot. <TAB>  <TAB>  <TAB> type_attr = getattr(self._local_type, name, _marker) <TAB>  <TAB>  <TAB> type(type_attr).__delete__(type_attr, self) <TAB>  <TAB>  <TAB> return <TAB> # Otherwise it goes directly in the dict <TAB> # Begin inlined function _get_dict() <TAB> dct = _local_get_dict(self) <TAB> try: <TAB>  <TAB> del dct[name] <TAB> except KeyError: <TAB>  <TAB> raise AttributeError(name)",if name in self . _local_type_del_descriptors :,199
2805,"def update_participants(self, refresh=True): <TAB> for participant in list(self.participants_dict): <MASK> continue <TAB>  <TAB> self.removeItem(self.participants_dict[participant]) <TAB>  <TAB> self.participant_items.remove(self.participants_dict[participant]) <TAB>  <TAB> del self.participants_dict[participant] <TAB> for participant in self.simulator_config.participants: <TAB>  <TAB> if participant in self.participants_dict: <TAB>  <TAB>  <TAB> self.participants_dict[participant].refresh() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.insert_participant(participant) <TAB> if refresh: <TAB>  <TAB> self.update_view()",if participant is None or participant == self . simulator_config . broadcast_part :,182
2806,"def insert_bigger_b_add(node): <TAB> if node.op == theano.tensor.add: <TAB>  <TAB> inputs = list(node.inputs) <MASK> inputs[-1] = theano.tensor.concatenate((inputs[-1], inputs[-1])) <TAB>  <TAB>  <TAB> return [node.op(*inputs)] <TAB> return False",if inputs [ - 1 ] . owner is None :,87
2807,"def _activate_cancel_status(self, cancel_status): <TAB> if self._cancel_status is not None: <TAB>  <TAB> self._cancel_status._tasks.remove(self) <TAB> self._cancel_status = cancel_status <TAB> if self._cancel_status is not None: <TAB>  <TAB> self._cancel_status._tasks.add(self) <MASK> self._attempt_delivery_of_any_pending_cancel()",if self . _cancel_status . effectively_cancelled :,113
2808,"def writeLibraryGeometry(fp, meshes, config, shapes=None): <TAB> progress = Progress(len(meshes), None) <TAB> fp.write(""\n  <library_geometries>\n"") <TAB> for mIdx, mesh in enumerate(meshes): <MASK> shape = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> shape = shapes[mIdx] <TAB>  <TAB> writeGeometry(fp, mesh, config, shape) <TAB>  <TAB> progress.step() <TAB> fp.write(""  </library_geometries>\n"")",if shapes is None :,128
2809,"def init_module_config(module_json, config, config_path=default_config_path): <TAB> if ""config"" in module_json[""meta""]: <TAB>  <TAB> if module_json[""meta""][""config""]: <TAB>  <TAB>  <TAB> if module_json[""name""] not in config: <TAB>  <TAB>  <TAB>  <TAB> config.add_section(module_json[""name""]) <TAB>  <TAB>  <TAB> for config_var in module_json[""meta""][""config""]: <MASK> config.set(module_json[""name""], config_var, """") <TAB> return config","if config_var not in config [ module_json [ ""name"" ] ] :",142
2810,"def get_const_defines(flags, prefix=""""): <TAB> defs = [] <TAB> for k, v in globals().items(): <TAB>  <TAB> if isinstance(v, int): <TAB>  <TAB>  <TAB> if v & flags: <MASK> if k.startswith(prefix): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> defs.append(k) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> defs.append(k) <TAB> return defs",if prefix :,104
2811,"def __init__(self, source, encoding=DEFAULT_ENCODING): <TAB> self.data = {} <TAB> with open(source, encoding=encoding) as file_: <TAB>  <TAB> for line in file_: <TAB>  <TAB>  <TAB> line = line.strip() <MASK> continue <TAB>  <TAB>  <TAB> k, v = line.split(""="", 1) <TAB>  <TAB>  <TAB> k = k.strip() <TAB>  <TAB>  <TAB> v = v.strip() <TAB>  <TAB>  <TAB> if len(v) >= 2 and ( <TAB>  <TAB>  <TAB>  <TAB> (v[0] == ""'"" and v[-1] == ""'"") or (v[0] == '""' and v[-1] == '""') <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> v = v.strip(""'\"""") <TAB>  <TAB>  <TAB> self.data[k] = v","if not line or line . startswith ( ""#"" ) or ""="" not in line :",189
2812,"def __detect_console_logger(self): <TAB> logger = self.log <TAB> while logger: <TAB>  <TAB> for handler in logger.handlers[:]: <MASK> if handler.stream in (sys.stdout, sys.stderr): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.logger_handlers.append(handler) <TAB>  <TAB> if logger.root == logger: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logger = logger.root","if isinstance ( handler , StreamHandler ) :",109
2813,"def check_heuristic_in_sql(): <TAB> heurs = set() <TAB> excluded = [""Equal assembly or pseudo-code"", ""All or most attributes""] <TAB> for heur in HEURISTICS: <TAB>  <TAB> name = heur[""name""] <MASK> continue <TAB>  <TAB> sql = heur[""sql""] <TAB>  <TAB> if sql.lower().find(name.lower()) == -1: <TAB>  <TAB>  <TAB> print((""SQL command not correctly associated to %s"" % repr(name))) <TAB>  <TAB>  <TAB> print(sql) <TAB>  <TAB>  <TAB> assert sql.find(name) != -1 <TAB>  <TAB> heurs.add(name) <TAB> print(""Heuristics:"") <TAB> import pprint <TAB> pprint.pprint(heurs)",if name in excluded :,171
2814,"def read(self, size=-1): <TAB> buf = bytearray() <TAB> while size != 0 and self.cursor < self.maxpos: <MASK> self.seek_to_block(self.cursor) <TAB>  <TAB> part = self.current_stream.read(size) <TAB>  <TAB> if size > 0: <TAB>  <TAB>  <TAB> if len(part) == 0: <TAB>  <TAB>  <TAB>  <TAB> raise EOFError() <TAB>  <TAB>  <TAB> size -= len(part) <TAB>  <TAB> self.cursor += len(part) <TAB>  <TAB> buf += part <TAB> return bytes(buf)",if not self . in_current_block ( self . cursor ) :,142
2815,"def get_project_dir(env): <TAB> project_file = workon_home / env / "".project"" <TAB> if project_file.exists(): <TAB>  <TAB> with project_file.open() as f: <TAB>  <TAB>  <TAB> project_dir = f.readline().strip() <MASK> return project_dir <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> err( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Corrupted or outdated:"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> project_file, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""\nDirectory"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> project_dir, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""doesn't exist."", <TAB>  <TAB>  <TAB>  <TAB> )",if os . path . exists ( project_dir ) :,158
2816,"def _cache_mem(curr_out, prev_mem, mem_len, reuse_len=None): <TAB> """"""cache hidden states into memory."""""" <TAB> if mem_len is None or mem_len == 0: <TAB>  <TAB> return None <TAB> else: <MASK> curr_out = curr_out[:reuse_len] <TAB>  <TAB> if prev_mem is None: <TAB>  <TAB>  <TAB> new_mem = curr_out[-mem_len:] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_mem = tf.concat([prev_mem, curr_out], 0)[-mem_len:] <TAB> return tf.keras.backend.stop_gradient(new_mem)",if reuse_len is not None and reuse_len > 0 :,165
2817,"def cleanup_channel(self, to_cleanup): <TAB> public_key, id_ = to_cleanup <TAB> # TODO: Maybe run it threaded? <TAB> try: <TAB>  <TAB> with db_session: <TAB>  <TAB>  <TAB> channel = self.session.mds.ChannelMetadata.get_for_update( <TAB>  <TAB>  <TAB>  <TAB> public_key=public_key, id_=id_ <TAB>  <TAB>  <TAB> ) <MASK> return <TAB>  <TAB>  <TAB> channel.local_version = 0 <TAB>  <TAB>  <TAB> channel.contents.delete(bulk=True) <TAB> except Exception as e: <TAB>  <TAB> self._logger.warning(""Exception while cleaning unsubscribed channel: %"", str(e))",if not channel :,159
2818,"def best_image(width, height): <TAB> # A heuristic for finding closest sized image to required size. <TAB> image = images[0] <TAB> for img in images: <TAB>  <TAB> if img.width == width and img.height == height: <TAB>  <TAB>  <TAB> # Exact match always used <TAB>  <TAB>  <TAB> return img <MASK> # At least wide enough, and largest area <TAB>  <TAB>  <TAB> image = img <TAB> return image",elif img . width >= width and img . width * img . height > image . width * image . height :,120
2819,"def add_peer_to_blob(self, contact: ""KademliaPeer"", key: bytes) -> None: <TAB> now = self.loop.time() <TAB> if key in self._data_store: <TAB>  <TAB> current = list(filter(lambda x: x[0] == contact, self._data_store[key])) <MASK> self._data_store[key][self._data_store[key].index(current[0])] = ( <TAB>  <TAB>  <TAB>  <TAB> contact, <TAB>  <TAB>  <TAB>  <TAB> now, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._data_store[key].append((contact, now)) <TAB> else: <TAB>  <TAB> self._data_store[key] = [(contact, now)]",if len ( current ) > 0 :,180
2820,"def dump(self): <TAB> self.ql.log.info(""[*] Dumping object: %s"" % (self.sf_name)) <TAB> for field in self._fields_: <TAB>  <TAB> if isinstance(getattr(self, field[0]), POINTER64): <TAB>  <TAB>  <TAB> self.ql.log.info(""%s: 0x%x"" % (field[0], getattr(self, field[0]).value)) <TAB>  <TAB> elif isinstance(getattr(self, field[0]), int): <TAB>  <TAB>  <TAB> self.ql.log.info(""%s: %d"" % (field[0], getattr(self, field[0]))) <MASK> self.ql.log.info(""%s: %s"" % (field[0], getattr(self, field[0]).decode()))","elif isinstance ( getattr ( self , field [ 0 ] ) , bytes ) :",188
2821,"def GeneratePageMetatadata(self, task): <TAB> address_space = self.session.GetParameter(""default_address_space"") <TAB> for vma in task.mm.mmap.walk_list(""vm_next""): <TAB>  <TAB> start = vma.vm_start <TAB>  <TAB> end = vma.vm_end <TAB>  <TAB> # Skip the entire region. <MASK> continue <TAB>  <TAB> # Done. <TAB>  <TAB> if start > self.plugin_args.end: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> for vaddr in utils.xrange(start, end, 0x1000): <TAB>  <TAB>  <TAB> if self.plugin_args.start <= vaddr <= self.plugin_args.end: <TAB>  <TAB>  <TAB>  <TAB> yield vaddr, self._CreateMetadata(address_space.describe_vtop(vaddr))",if end < self . plugin_args . start :,195
2822,"def _available_symbols(self, scoperef, expr): <TAB> cplns = [] <TAB> found_names = set() <TAB> while scoperef: <TAB>  <TAB> elem = self._elem_from_scoperef(scoperef) <TAB>  <TAB> for child in elem: <TAB>  <TAB>  <TAB> name = child.get(""name"", """") <TAB>  <TAB>  <TAB> if name.startswith(expr): <TAB>  <TAB>  <TAB>  <TAB> if name not in found_names: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> found_names.add(name) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ilk = child.get(""ilk"") or child.tag <TAB>  <TAB>  <TAB>  <TAB>  <TAB> cplns.append((ilk, name)) <TAB>  <TAB> scoperef = self.parent_scoperef_from_scoperef(scoperef) <MASK> break <TAB> return sorted(cplns, key=operator.itemgetter(1))",if not scoperef :,196
2823,"def get_xenapi_host(self): <TAB> """"""Return the xenapi host on which nova-compute runs on."""""" <TAB> with self._get_session() as session: <MASK> return session.xenapi.host.get_by_uuid(self.host_uuid) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return session.xenapi.session.get_this_host(session.handle)",if self . host_uuid :,105
2824,"def stream_docker_log(log_stream): <TAB> async for line in log_stream: <MASK> logger.debug(line[""stream""].strip()) <TAB>  <TAB> elif ""status"" in line: <TAB>  <TAB>  <TAB> logger.debug(line[""status""].strip()) <TAB>  <TAB> elif ""error"" in line: <TAB>  <TAB>  <TAB> logger.error(line[""error""].strip()) <TAB>  <TAB>  <TAB> raise DockerBuildError","if ""stream"" in line and line [ ""stream"" ] . strip ( ) :",108
2825,"def test_wildcard_import(): <TAB> bonobo = __import__(""bonobo"") <TAB> assert bonobo.__version__ <TAB> for name in dir(bonobo): <TAB>  <TAB> # ignore attributes starting by underscores <MASK> continue <TAB>  <TAB> attr = getattr(bonobo, name) <TAB>  <TAB> if inspect.ismodule(attr): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> assert name in bonobo.__all__","if name . startswith ( ""_"" ) :",97
2826,"def _coerce_to_bool(self, node, var, true_val=True): <TAB> """"""Coerce the values in a variable to bools."""""" <TAB> bool_var = self.program.NewVariable() <TAB> for b in var.bindings: <TAB>  <TAB> v = b.data <TAB>  <TAB> if isinstance(v, mixin.PythonConstant) and isinstance(v.pyval, bool): <TAB>  <TAB>  <TAB> const = v.pyval is true_val <MASK> const = not true_val <TAB>  <TAB> elif not compare.compatible_with(v, False): <TAB>  <TAB>  <TAB> const = true_val <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> const = None <TAB>  <TAB> bool_var.AddBinding(self.convert.bool_values[const], {b}, node) <TAB> return bool_var","elif not compare . compatible_with ( v , True ) :",192
2827,"def _parse_policies(self, policies_yaml): <TAB> for item in policies_yaml: <TAB>  <TAB> id_ = required_key(item, ""id"") <TAB>  <TAB> controls_ids = required_key(item, ""controls"") <TAB>  <TAB> if not isinstance(controls_ids, list): <MASK> msg = ""Policy {id_} contains invalid controls list {controls}."".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> id_=id_, controls=str(controls_ids) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(msg) <TAB>  <TAB> self.policies[id_] = controls_ids","if controls_ids != ""all"" :",155
2828,"def pong(self, payload: Union[str, bytes] = """") -> None: <TAB> if self.trace_enabled and self.ping_pong_trace_enabled: <MASK> payload = payload.decode(""utf-8"") <TAB>  <TAB> self.logger.debug( <TAB>  <TAB>  <TAB> ""Sending a pong data frame "" <TAB>  <TAB>  <TAB> f""(session id: {self.session_id}, payload: {payload})"" <TAB>  <TAB> ) <TAB> data = _build_data_frame_for_sending(payload, FrameHeader.OPCODE_PONG) <TAB> with self.sock_send_lock: <TAB>  <TAB> self.sock.send(data)","if isinstance ( payload , bytes ) :",158
2829,"def _extract_curve_feature_log(arg): <TAB> """"""extract sampled curve feature for log items"""""" <TAB> try: <TAB>  <TAB> inp, res = arg <TAB>  <TAB> config = inp.config <TAB>  <TAB> with inp.target: <TAB>  <TAB>  <TAB> sch, args = inp.task.instantiate(config) <TAB>  <TAB> fea = feature.get_buffer_curve_sample_flatten(sch, args, sample_n=20) <TAB>  <TAB> x = np.concatenate((fea, list(config.get_other_option().values()))) <MASK> y = inp.task.flop / np.mean(res.costs) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> y = 0.0 <TAB>  <TAB> return x, y <TAB> except Exception:  # pylint: disable=broad-except <TAB>  <TAB> return None",if res . error_no == 0 :,192
2830,"def messageSourceStamps(self, source_stamps): <TAB> text = """" <TAB> for ss in source_stamps: <TAB>  <TAB> source = """" <TAB>  <TAB> if ss[""branch""]: <TAB>  <TAB>  <TAB> source += ""[branch %s] "" % ss[""branch""] <MASK> source += str(ss[""revision""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> source += ""HEAD"" <TAB>  <TAB> if ss[""patch""] is not None: <TAB>  <TAB>  <TAB> source += "" (plus patch)"" <TAB>  <TAB> discriminator = """" <TAB>  <TAB> if ss[""codebase""]: <TAB>  <TAB>  <TAB> discriminator = "" '%s'"" % ss[""codebase""] <TAB>  <TAB> text += ""Build Source Stamp%s: %s\n"" % (discriminator, source) <TAB> return text","if ss [ ""revision"" ] :",176
2831,"def find_repository(): <TAB> orig_path = path = os.path.realpath(""."") <TAB> drive, path = os.path.splitdrive(path) <TAB> while path: <TAB>  <TAB> current_path = os.path.join(drive, path) <TAB>  <TAB> current_repo = LocalRepository(current_path) <TAB>  <TAB> if current_repo.isValid(): <TAB>  <TAB>  <TAB> return current_repo <TAB>  <TAB> path, path_tail = os.path.split(current_path) <MASK> raise CannotFindRepository(""Cannot find repository for %s"" % (orig_path,))",if not path_tail :,139
2832,"def compute_indices(text: str, tokens): <TAB> indices = [] <TAB> for i, token in enumerate(tokens): <MASK> current_index = indices[-1] + len(tokens[i - 1][0]) <TAB>  <TAB>  <TAB> indices.append(current_index + text[current_index:].find(token[0])) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> indices.append(text.find(token[0])) <TAB> return indices",if 1 <= i :,108
2833,"def _add_defaults_data_files(self): <TAB> # getting distribution.data_files <TAB> if self.distribution.has_data_files(): <TAB>  <TAB> for item in self.distribution.data_files: <TAB>  <TAB>  <TAB> if isinstance(item, str): <TAB>  <TAB>  <TAB>  <TAB> # plain file <TAB>  <TAB>  <TAB>  <TAB> item = convert_path(item) <MASK> self.filelist.append(item) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> # a (dirname, filenames) tuple <TAB>  <TAB>  <TAB>  <TAB> dirname, filenames = item <TAB>  <TAB>  <TAB>  <TAB> for f in filenames: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f = convert_path(f) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if os.path.isfile(f): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.filelist.append(f)",if os . path . isfile ( item ) :,192
2834,"def libcxx_define(settings): <TAB> compiler = _base_compiler(settings) <TAB> libcxx = settings.get_safe(""compiler.libcxx"") <TAB> if not compiler or not libcxx: <TAB>  <TAB> return """" <TAB> if str(compiler) in GCC_LIKE: <MASK> return ""_GLIBCXX_USE_CXX11_ABI=0"" <TAB>  <TAB> elif str(libcxx) == ""libstdc++11"": <TAB>  <TAB>  <TAB> return ""_GLIBCXX_USE_CXX11_ABI=1"" <TAB> return """"","if str ( libcxx ) == ""libstdc++"" :",146
2835,"def _populate_tree(self, element, d): <TAB> """"""Populates an etree with attributes & elements, given a dict."""""" <TAB> for k, v in d.iteritems(): <TAB>  <TAB> if isinstance(v, dict): <TAB>  <TAB>  <TAB> self._populate_dict(element, k, v) <TAB>  <TAB> elif isinstance(v, list): <TAB>  <TAB>  <TAB> self._populate_list(element, k, v) <TAB>  <TAB> elif isinstance(v, bool): <TAB>  <TAB>  <TAB> self._populate_bool(element, k, v) <MASK> self._populate_str(element, k, v) <TAB>  <TAB> elif type(v) in [int, float, long, complex]: <TAB>  <TAB>  <TAB> self._populate_number(element, k, v)","elif isinstance ( v , basestring ) :",178
2836,"def test_seek(self): <MASK> print(""create large file via seek (may be sparse file) ..."") <TAB> with self.open(TESTFN, ""wb"") as f: <TAB>  <TAB> f.write(b""z"") <TAB>  <TAB> f.seek(0) <TAB>  <TAB> f.seek(size) <TAB>  <TAB> f.write(b""a"") <TAB>  <TAB> f.flush() <TAB>  <TAB> if verbose: <TAB>  <TAB>  <TAB> print(""check file size with os.fstat"") <TAB>  <TAB> self.assertEqual(os.fstat(f.fileno())[stat.ST_SIZE], size + 1)",if verbose :,139
2837,"def serialize_review_url_field(self, obj, **kwargs): <TAB> if obj.review_ui: <TAB>  <TAB> review_request = obj.get_review_request() <MASK> local_site_name = review_request.local_site.name <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> local_site_name = None <TAB>  <TAB> return local_site_reverse( <TAB>  <TAB>  <TAB> ""file-attachment"", <TAB>  <TAB>  <TAB> local_site_name=local_site_name, <TAB>  <TAB>  <TAB> kwargs={ <TAB>  <TAB>  <TAB>  <TAB> ""review_request_id"": review_request.display_id, <TAB>  <TAB>  <TAB>  <TAB> ""file_attachment_id"": obj.pk, <TAB>  <TAB>  <TAB> }, <TAB>  <TAB> ) <TAB> return """"",if review_request . local_site_id :,180
2838,"def on_item_down_clicked(self, button): <TAB> model = self.treeview.get_model() <TAB> for s in self._get_selected(): <MASK> # XXX need model.swap <TAB>  <TAB>  <TAB> old = model.get_iter(s[0]) <TAB>  <TAB>  <TAB> iter = model.insert(s[0] + 2) <TAB>  <TAB>  <TAB> for i in range(3): <TAB>  <TAB>  <TAB>  <TAB> model.set_value(iter, i, model.get_value(old, i)) <TAB>  <TAB>  <TAB> model.remove(old) <TAB>  <TAB>  <TAB> self.treeview.get_selection().select_iter(iter) <TAB> self._update_filter_string()",if s [ 0 ] < len ( model ) - 1 :,167
2839,"def writer(self): <TAB> """"""loop forever and copy socket->serial"""""" <TAB> while self.alive: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> data = self.socket.recv(1024) <MASK> break <TAB>  <TAB>  <TAB> self.serial.write(b"""".join(self.rfc2217.filter(data))) <TAB>  <TAB> except socket.error as msg: <TAB>  <TAB>  <TAB> self.log.error(""{}"".format(msg)) <TAB>  <TAB>  <TAB> # probably got disconnected <TAB>  <TAB>  <TAB> break <TAB> self.stop()",if not data :,124
2840,"def __getitem__(self, key): <TAB> if key == 1: <TAB>  <TAB> return self.get_value() <TAB> elif key == 0: <TAB>  <TAB> return self.cell[0] <TAB> elif isinstance(key, slice): <TAB>  <TAB> s = list(self.cell.__getitem__(key)) <MASK> s[s.index(self.cell[1])] = self.get_value() <TAB>  <TAB> return s <TAB> else: <TAB>  <TAB> raise IndexError(key)",if self . cell [ 1 ] in s :,120
2841,"def test_error_stream(environ, start_response): <TAB> writer = start_response(""200 OK"", []) <TAB> wsgi_errors = environ[""wsgi.errors""] <TAB> error_msg = None <TAB> for method in [ <TAB>  <TAB> ""flush"", <TAB>  <TAB> ""write"", <TAB>  <TAB> ""writelines"", <TAB> ]: <MASK> error_msg = ""wsgi.errors has no '%s' attr"" % method <TAB>  <TAB> if not error_msg and not callable(getattr(wsgi_errors, method)): <TAB>  <TAB>  <TAB> error_msg = ""wsgi.errors.%s attr is not callable"" % method <TAB>  <TAB> if error_msg: <TAB>  <TAB>  <TAB> break <TAB> return_msg = error_msg or ""success"" <TAB> writer(return_msg) <TAB> return []","if not hasattr ( wsgi_errors , method ) :",185
2842,"def job_rule_modules(app): <TAB> rules_module_list = [] <TAB> for rules_module_name in __job_rule_module_names(app): <TAB>  <TAB> rules_module = sys.modules.get(rules_module_name, None) <MASK> # if using a non-default module, it's not imported until a JobRunnerMapper is instantiated when the first <TAB>  <TAB>  <TAB> # JobWrapper is created <TAB>  <TAB>  <TAB> rules_module = importlib.import_module(rules_module_name) <TAB>  <TAB> rules_module_list.append(rules_module) <TAB> return rules_module_list",if not rules_module :,148
2843,"def discover_hdfstore(f): <TAB> d = dict() <TAB> for key in f.keys(): <TAB>  <TAB> d2 = d <TAB>  <TAB> key2 = key.lstrip(""/"") <TAB>  <TAB> while ""/"" in key2: <TAB>  <TAB>  <TAB> group, key2 = key2.split(""/"", 1) <MASK> d2[group] = dict() <TAB>  <TAB>  <TAB> d2 = d2[group] <TAB>  <TAB> d2[key2] = f.get_storer(key) <TAB> return discover(d)",if group not in d2 :,128
2844,"def test_update_zone(self): <TAB> zone = self.driver.list_zones()[0] <TAB> updated_zone = self.driver.update_zone(zone=zone, domain="""", extra={""paused"": True}) <TAB> self.assertEqual(zone.id, updated_zone.id) <TAB> self.assertEqual(zone.domain, updated_zone.domain) <TAB> self.assertEqual(zone.type, updated_zone.type) <TAB> self.assertEqual(zone.ttl, updated_zone.ttl) <TAB> for key in set(zone.extra) | set(updated_zone.extra): <MASK> self.assertNotEqual(zone.extra[key], updated_zone.extra[key]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertEqual(zone.extra[key], updated_zone.extra[key])","if key in ( ""paused"" , ""modified_on"" ) :",199
2845,"def ESP(phrase): <TAB> for num, name in enumerate(devname): <MASK> dev = devid[num] <TAB>  <TAB>  <TAB> if custom_action_keyword[""Dict""][""On""] in phrase: <TAB>  <TAB>  <TAB>  <TAB> ctrl = ""=ON"" <TAB>  <TAB>  <TAB>  <TAB> say(""Turning On "" + name) <TAB>  <TAB>  <TAB> elif custom_action_keyword[""Dict""][""Off""] in phrase: <TAB>  <TAB>  <TAB>  <TAB> ctrl = ""=OFF"" <TAB>  <TAB>  <TAB>  <TAB> say(""Turning Off "" + name) <TAB>  <TAB>  <TAB> rq = requests.head(""https://"" + ip + dev + ctrl, verify=False)",if name . lower ( ) in phrase :,153
2846,"def filter_ports(self, dpid, in_port, nw_id, allow_nw_id_external=None): <TAB> assert nw_id != self.nw_id_unknown <TAB> ret = [] <TAB> for port in self.get_ports(dpid): <TAB>  <TAB> nw_id_ = port.network_id <TAB>  <TAB> if port.port_no == in_port: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if nw_id_ == nw_id: <TAB>  <TAB>  <TAB> ret.append(port.port_no) <MASK> ret.append(port.port_no) <TAB> return ret",elif allow_nw_id_external is not None and nw_id_ == allow_nw_id_external :,167
2847,"def tail(filename): <TAB> if os.path.isfile(filename): <TAB>  <TAB> file = open(filename, ""r"") <TAB>  <TAB> st_results = os.stat(filename) <TAB>  <TAB> st_size = st_results[6] <TAB>  <TAB> file.seek(st_size) <TAB>  <TAB> while 1: <TAB>  <TAB>  <TAB> where = file.tell() <TAB>  <TAB>  <TAB> line = file.readline() <MASK> time.sleep(1) <TAB>  <TAB>  <TAB>  <TAB> file.seek(where) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> print( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> line, <TAB>  <TAB>  <TAB>  <TAB> )  # already has newline <TAB> else: <TAB>  <TAB> print_error(""File not found, cannot tail."")",if not line :,172
2848,"def proc_day_of_week(d): <TAB> if expanded[4][0] != ""*"": <TAB>  <TAB> diff_day_of_week = nearest_diff_method(d.isoweekday() % 7, expanded[4], 7) <TAB>  <TAB> if diff_day_of_week is not None and diff_day_of_week != 0: <MASK> d += relativedelta(days=diff_day_of_week, hour=23, minute=59, second=59) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> d += relativedelta(days=diff_day_of_week, hour=0, minute=0, second=0) <TAB>  <TAB>  <TAB> return True, d <TAB> return False, d",if is_prev :,175
2849,"def __call__(self): <TAB> """"""Run all check_* methods."""""" <TAB> if self.on: <TAB>  <TAB> oldformatwarning = warnings.formatwarning <TAB>  <TAB> warnings.formatwarning = self.formatwarning <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> for name in dir(self): <TAB>  <TAB>  <TAB>  <TAB> if name.startswith(""check_""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> method = getattr(self, name) <MASK> method() <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> warnings.formatwarning = oldformatwarning",if method and callable ( method ) :,127
2850,"def get(self, request, *args, **kwargs): <TAB> if self.revision: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> return send_file( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> request, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.revision.file.path, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.revision.created, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.attachment.original_filename, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return HttpResponseRedirect(self.revision.file.url) <TAB> raise Http404",if settings . USE_LOCAL_PATH :,141
2851,"def _close(self): <TAB> super(Recording, self)._close() <TAB> if self._log_n is not None: <TAB>  <TAB> for i in range(self.n): <MASK> self._log_n[i].close() <TAB>  <TAB>  <TAB>  <TAB> self._log_n[i] = None",if self . _log_n [ i ] is not None :,88
2852,"def addTags(self, rpcObjects=None): <TAB> hosts = self._getOnlyHostObjects(rpcObjects) <TAB> if hosts: <TAB>  <TAB> title = ""Add Tags"" <TAB>  <TAB> body = ""What tags should be added?\n\nUse a comma or space between each"" <TAB>  <TAB> (tags, choice) = self.getText(title, body, """") <MASK> tags = str(tags).replace("" "", "","").split("","") <TAB>  <TAB>  <TAB> for host in hosts: <TAB>  <TAB>  <TAB>  <TAB> self.cuebotCall( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> host.addTags, ""Add Tags to %s Failed"" % host.data.name, tags <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self._update()",if choice :,167
2853,"def available_datasets(self): <TAB> """"""Automatically determine datasets provided by this file"""""" <TAB> res = self.resolution <TAB> coordinates = [""pixel_longitude"", ""pixel_latitude""] <TAB> for var_name, val in self.file_content.items(): <MASK> ds_info = { <TAB>  <TAB>  <TAB>  <TAB> ""file_type"": self.filetype_info[""file_type""], <TAB>  <TAB>  <TAB>  <TAB> ""resolution"": res, <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB> if not self.is_geo: <TAB>  <TAB>  <TAB>  <TAB> ds_info[""coordinates""] = coordinates <TAB>  <TAB>  <TAB> yield DatasetID(name=var_name, resolution=res), ds_info","if isinstance ( val , netCDF4 . Variable ) :",165
2854,"def extract_from_file(fname: PathIsh) -> Iterator[Extraction]: <TAB> path = Path(fname) <TAB> fallback_dt = file_mtime(path) <TAB> p = Parser(path) <TAB> for r in p.walk(): <MASK> yield r <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield Visit( <TAB>  <TAB>  <TAB>  <TAB> url=r.url, <TAB>  <TAB>  <TAB>  <TAB> dt=fallback_dt, <TAB>  <TAB>  <TAB>  <TAB> locator=Loc.file(fname),  # TODO line number <TAB>  <TAB>  <TAB>  <TAB> context=r.context, <TAB>  <TAB>  <TAB> )","if isinstance ( r , Exception ) :",141
2855,"def init_module_config(module_json, config, config_path=default_config_path): <TAB> if ""config"" in module_json[""meta""]: <TAB>  <TAB> if module_json[""meta""][""config""]: <MASK> config.add_section(module_json[""name""]) <TAB>  <TAB>  <TAB> for config_var in module_json[""meta""][""config""]: <TAB>  <TAB>  <TAB>  <TAB> if config_var not in config[module_json[""name""]]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> config.set(module_json[""name""], config_var, """") <TAB> return config","if module_json [ ""name"" ] not in config :",142
2856,"def _create_entities(parsed_entities, sidx, eidx): <TAB> entities = [] <TAB> for k, vs in parsed_entities.items(): <MASK> vs = [vs] <TAB>  <TAB> for value in vs: <TAB>  <TAB>  <TAB> entities.append( <TAB>  <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""entity"": k, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""start"": sidx, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""end"": eidx,  # can't be more specific <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""value"": value, <TAB>  <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB> ) <TAB> return entities","if not isinstance ( vs , list ) :",145
2857,"def _telegram_upload_stream(self, stream, **kwargs): <TAB> """"""Perform upload defined in a stream."""""" <TAB> msg = None <TAB> try: <TAB>  <TAB> stream.accept() <TAB>  <TAB> msg = self._telegram_special_message( <TAB>  <TAB>  <TAB> chat_id=stream.identifier.id, <TAB>  <TAB>  <TAB> content=stream.raw, <TAB>  <TAB>  <TAB> msg_type=stream.stream_type, <TAB>  <TAB>  <TAB> **kwargs, <TAB>  <TAB> ) <TAB> except Exception: <TAB>  <TAB> log.exception(f""Upload of {stream.name} to {stream.identifier} failed."") <TAB> else: <MASK> stream.error() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> stream.success()",if msg is None :,166
2858,"def readlines(self, size=-1): <TAB> if self._nbr == self._size: <TAB>  <TAB> return [] <TAB> # leave all additional logic to our readline method, we just check the size <TAB> out = [] <TAB> nbr = 0 <TAB> while True: <TAB>  <TAB> line = self.readline() <MASK> break <TAB>  <TAB> out.append(line) <TAB>  <TAB> if size > -1: <TAB>  <TAB>  <TAB> nbr += len(line) <TAB>  <TAB>  <TAB> if nbr > size: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> # END handle size constraint <TAB> # END readline loop <TAB> return out",if not line :,145
2859,"def clean_permissions( <TAB> cls, <TAB> requestor: ""User"", <TAB> group: auth_models.Group, <TAB> errors: Dict[Optional[str], List[ValidationError]], <TAB> cleaned_input: dict,): <TAB> field = ""add_permissions"" <TAB> permission_items = cleaned_input.get(field) <TAB> if permission_items: <TAB>  <TAB> cleaned_input[field] = get_permissions(permission_items) <MASK> cls.ensure_can_manage_permissions( <TAB>  <TAB>  <TAB>  <TAB> requestor, errors, field, permission_items <TAB>  <TAB>  <TAB> )",if not requestor . is_superuser :,142
2860,"def _bwd(subj=None, obj=None, seen=None): <TAB> seen.add(obj) <TAB> for s, o in evalPath(graph, (None, self.path, obj)): <MASK> yield s, o <TAB>  <TAB> if self.more: <TAB>  <TAB>  <TAB> if s in seen: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> for s2, o2 in _bwd(None, s, seen): <TAB>  <TAB>  <TAB>  <TAB> yield s2, o",if not subj or subj == s :,120
2861,"def generate_data(self, request): <TAB> """"""Generate data for the widget."""""" <TAB> uptime = {} <TAB> cache_stats = get_cache_stats() <TAB> if cache_stats: <TAB>  <TAB> for hosts, stats in cache_stats: <MASK> uptime[""value""] = stats[""uptime""] / 60 / 60 / 24 <TAB>  <TAB>  <TAB>  <TAB> uptime[""unit""] = _(""days"") <TAB>  <TAB>  <TAB> elif stats[""uptime""] > 3600: <TAB>  <TAB>  <TAB>  <TAB> uptime[""value""] = stats[""uptime""] / 60 / 60 <TAB>  <TAB>  <TAB>  <TAB> uptime[""unit""] = _(""hours"") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> uptime[""value""] = stats[""uptime""] / 60 <TAB>  <TAB>  <TAB>  <TAB> uptime[""unit""] = _(""minutes"") <TAB> return {""cache_stats"": cache_stats, ""uptime"": uptime}","if stats [ ""uptime"" ] > 86400 :",195
2862,def refresh(self): <TAB> if self._handle: <TAB>  <TAB> source = self._db.get_repository_from_handle(self._handle) <MASK> self._title = str(source.get_type()) <TAB>  <TAB>  <TAB> self._value = source.get_name(),if source :,70
2863,"def _gridconvvalue(self, value): <TAB> if isinstance(value, (str, _tkinter.Tcl_Obj)): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> svalue = str(value) <MASK> return None <TAB>  <TAB>  <TAB> elif ""."" in svalue: <TAB>  <TAB>  <TAB>  <TAB> return getdouble(svalue) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return getint(svalue) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> pass <TAB> return value",if not svalue :,116
2864,"def parseGrants(self, tree): <TAB> for grant in tree.findall("".//Grant""): <TAB>  <TAB> grantee = Grantee() <TAB>  <TAB> g = grant.find("".//Grantee"") <TAB>  <TAB> grantee.xsi_type = g.attrib[""{http://www.w3.org/2001/XMLSchema-instance}type""] <TAB>  <TAB> grantee.permission = grant.find(""Permission"").text <TAB>  <TAB> for el in g: <MASK> grantee.display_name = el.text <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> grantee.tag = el.tag <TAB>  <TAB>  <TAB>  <TAB> grantee.name = el.text <TAB>  <TAB> self.grantees.append(grantee)","if el . tag == ""DisplayName"" :",188
2865,"def __init__(self, name: Optional[str] = None, order: int = 0): <TAB> if name is None: <TAB>  <TAB> if order == 0: <TAB>  <TAB>  <TAB> name = ""std_dev"" <MASK> name = ""sample_std_dev"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = f""std_dev{order})"" <TAB> super().__init__(name=name, order=order) <TAB> self.order = order",elif order == 1 :,109
2866,"def _shouldRollover(self): <TAB> if self.maxBytes > 0:  # are we rolling over? <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.stream.seek(0, 2)  # due to non-posix-compliant Windows feature <TAB>  <TAB> except IOError: <TAB>  <TAB>  <TAB> return True <MASK> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._degrade(False, ""Rotation done or not needed at this time"") <TAB> return False",if self . stream . tell ( ) >= self . maxBytes :,124
2867,"def userfullname(): <TAB> """"""Get the user's full name."""""" <TAB> global _userfullname <TAB> if not _userfullname: <TAB>  <TAB> uid = os.getuid() <TAB>  <TAB> entry = pwd_from_uid(uid) <MASK> _userfullname = entry[4].split("","")[0] or entry[0] <TAB>  <TAB> if not _userfullname: <TAB>  <TAB>  <TAB> _userfullname = ""user%d"" % uid <TAB> return _userfullname",if entry :,108
2868,"def drop(self): <TAB> # mssql <TAB> sql = ""if object_id('%s') is not null drop table %s"" % (self.tname, self.tname) <TAB> try: <TAB>  <TAB> self.execute(sql) <TAB> except Exception as e: <TAB>  <TAB> self.conn.rollback() <MASK> raise <TAB>  <TAB> # sqlite <TAB>  <TAB> sql = ""drop table if exists %s"" % self.tname <TAB>  <TAB> self.execute(sql)","if ""syntax error"" not in str ( e ) :",124
2869,"def _find_delimiter(f, block_size=2 ** 16): <TAB> delimiter = b""\n"" <TAB> if f.tell() == 0: <TAB>  <TAB> return 0 <TAB> while True: <TAB>  <TAB> b = f.read(block_size) <MASK> return f.tell() <TAB>  <TAB> elif delimiter in b: <TAB>  <TAB>  <TAB> return f.tell() - len(b) + b.index(delimiter) + 1",if not b :,105
2870,"def _convert(container): <TAB> if _value_marker in container: <TAB>  <TAB> force_list = False <TAB>  <TAB> values = container.pop(_value_marker) <MASK> force_list = True <TAB>  <TAB>  <TAB> values.extend(_convert(x[1]) for x in sorted(container.items())) <TAB>  <TAB> if not force_list and len(values) == 1: <TAB>  <TAB>  <TAB> values = values[0] <TAB>  <TAB> if not container: <TAB>  <TAB>  <TAB> return values <TAB>  <TAB> return _convert(container) <TAB> elif container.pop(_list_marker, False): <TAB>  <TAB> return [_convert(x[1]) for x in sorted(container.items())] <TAB> return dict_cls((k, _convert(v)) for k, v in iteritems(container))","if container . pop ( _list_marker , False ) :",188
2871,"def fitting(self, value): <TAB> self._fitting = value <TAB> if self._fitting is not None: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> os.makedirs(dirname(self.checkpoint_path())) <TAB>  <TAB>  <TAB> except FileExistsError as ex: <TAB>  <TAB>  <TAB>  <TAB> pass  # race to create <TAB>  <TAB> if not os.path.exists(dirname(self.tensorboard_path())): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> os.makedirs(dirname(self.tensorboard_path())) <TAB>  <TAB>  <TAB> except FileExistsError as ex: <TAB>  <TAB>  <TAB>  <TAB> pass  # race to create",if not os . path . exists ( dirname ( self . checkpoint_path ( ) ) ) :,149
2872,"def _make_headers(self): <TAB> libraries = self._df.columns.to_list() <TAB> columns = [] <TAB> for library in libraries: <TAB>  <TAB> version = self._package_versions[library] <TAB>  <TAB> library_description = self._libraries_description.get(library) <MASK> library += "" {}"".format(library_description) <TAB>  <TAB> columns.append( <TAB>  <TAB>  <TAB> ""{library}<br><small>{version}</small>"".format( <TAB>  <TAB>  <TAB>  <TAB> library=library, version=version <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB> return [""""] + columns",if library_description :,138
2873,"def plugin_on_song_ended(self, song, stopped): <TAB> if song is not None: <TAB>  <TAB> poll = self.rating_box.poll_vote() <MASK> ups = int(song.get(""~#wins"") or 0) <TAB>  <TAB>  <TAB> downs = int(song.get(""~#losses"") or 0) <TAB>  <TAB>  <TAB> ups += poll[0] <TAB>  <TAB>  <TAB> downs += poll[1] <TAB>  <TAB>  <TAB> song[""~#wins""] = ups <TAB>  <TAB>  <TAB> song[""~#losses""] = downs <TAB>  <TAB>  <TAB> song[""~#rating""] = ups / max((ups + downs), 2) <TAB>  <TAB>  <TAB> # note: ^^^ Look into implementing w/ confidence intervals! <TAB>  <TAB>  <TAB> song[""~#score""] = ups - downs",if poll [ 0 ] >= 1 or poll [ 1 ] >= 1 :,196
2874,"def submit(self, pig_script, params): <TAB> workflow = None <TAB> try: <TAB>  <TAB> workflow = self._create_workflow(pig_script, params) <TAB>  <TAB> mapping = dict( <TAB>  <TAB>  <TAB> [(param[""name""], param[""value""]) for param in workflow.get_parameters()] <TAB>  <TAB> ) <TAB>  <TAB> oozie_wf = _submit_workflow(self.user, self.fs, self.jt, workflow, mapping) <TAB> finally: <MASK> workflow.delete(skip_trash=True) <TAB> return oozie_wf",if workflow :,131
2875,"def test_parse(self): <TAB> correct = 0 <TAB> for example in EXAMPLES: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> schema.parse(example.schema_string) <MASK> correct += 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.fail(""Invalid schema was parsed: "" + example.schema_string) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> if not example.valid: <TAB>  <TAB>  <TAB>  <TAB> correct += 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.fail(""Valid schema failed to parse: "" + example.schema_string) <TAB> fail_msg = ""Parse behavior correct on %d out of %d schemas."" % ( <TAB>  <TAB> correct, <TAB>  <TAB> len(EXAMPLES), <TAB> ) <TAB> self.assertEqual(correct, len(EXAMPLES), fail_msg)",if example . valid :,188
2876,"def handle_sent(self, elt): <TAB> sent = [] <TAB> for child in elt: <TAB>  <TAB> if child.tag in (""wf"", ""punc""): <TAB>  <TAB>  <TAB> itm = self.handle_word(child) <MASK> sent.extend(itm) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> sent.append(itm) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""Unexpected element %s"" % child.tag) <TAB> return SemcorSentence(elt.attrib[""snum""], sent)","if self . _unit == ""word"" :",126
2877,"def _set_property(self, target_widget, pname, value): <TAB> if pname == ""text"": <TAB>  <TAB> state = target_widget.cget(""state"") <MASK> target_widget.configure(state=tk.NORMAL) <TAB>  <TAB>  <TAB> target_widget.insert(""0.0"", value) <TAB>  <TAB>  <TAB> target_widget.configure(state=tk.DISABLED) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> target_widget.insert(""0.0"", value) <TAB> else: <TAB>  <TAB> super(TKText, self)._set_property(target_widget, pname, value)",if state == tk . DISABLED :,145
2878,"def get_vrf_tables(self, vrf_rf=None): <TAB> vrf_tables = {} <TAB> for (scope_id, table_id), table in self._tables.items(): <TAB>  <TAB> if scope_id is None: <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> vrf_tables[(scope_id, table_id)] = table <TAB> return vrf_tables",if vrf_rf is not None and table_id != vrf_rf :,112
2879,"def new_f(self, *args, **kwargs): <TAB> for obj in f(self, *args, **kwargs): <TAB>  <TAB> if self.protected == False: <TAB>  <TAB>  <TAB> if ""user"" in obj and obj[""user""][""protected""]: <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> yield obj","elif ""protected"" in obj and obj [ ""protected"" ] :",88
2880,"def draw(self, context): <TAB> col = self.layout.column() <TAB> col.operator(""node.sv_show_latest_commits"") <TAB> if context.scene.sv_new_version: <TAB>  <TAB> col_alert = self.layout.column() <TAB>  <TAB> col_alert.alert = True <TAB>  <TAB> col_alert.operator(""node.sverchok_update_addon"", text=""Upgrade Sverchok addon"") <TAB> else: <TAB>  <TAB> col.operator(""node.sverchok_check_for_upgrades_wsha"", text=""Check for updates"") <TAB> with sv_preferences() as prefs: <MASK> col.operator(""node.sv_run_pydoc"")",if prefs . developer_mode :,173
2881,"def generate_tag_1_data(ids): <TAB> if len(ids) != SAMPLE_NUM: <TAB>  <TAB> raise ValueError(""len ids should equal to sample number"") <TAB> counter = 0 <TAB> for sample_i in range(SAMPLE_NUM): <TAB>  <TAB> one_data = [ids[sample_i]] <TAB>  <TAB> valid_set = [x for x in range(TAG_INTERVAL[0], TAG_INTERVAL[1])] <TAB>  <TAB> features = np.random.choice(valid_set, FEATURE_NUM, replace=False) <TAB>  <TAB> one_data += ["":"".join([x, ""1.0""]) for x in features] <TAB>  <TAB> counter += 1 <MASK> print(""generate data {}"".format(counter)) <TAB>  <TAB> yield one_data",if counter % 10000 == 0 :,179
2882,"def handle_api_languages(self, http_context): <TAB> mgr = PluginManager.get(aj.context) <TAB> languages = set() <TAB> for id in mgr: <TAB>  <TAB> locale_dir = mgr.get_content_path(id, ""locale"") <MASK> for lang in os.listdir(locale_dir): <TAB>  <TAB>  <TAB>  <TAB> if lang != ""app.pot"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> languages.add(lang) <TAB> return sorted(list(languages))",if os . path . isdir ( locale_dir ) :,125
2883,"def update(self, t): <TAB> # direction right - up <TAB> for i in range(self.grid.x): <TAB>  <TAB> for j in range(self.grid.y): <TAB>  <TAB>  <TAB> distance = self.test_func(i, j, t) <MASK> self.turn_off_tile(i, j) <TAB>  <TAB>  <TAB> elif distance < 1: <TAB>  <TAB>  <TAB>  <TAB> self.transform_tile(i, j, distance) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.turn_on_tile(i, j)",if distance == 0 :,135
2884,"def _handle_autocomplete_request_for_text(text): <TAB> if not hasattr(text, ""autocompleter""): <TAB>  <TAB> if isinstance(text, (CodeViewText, ShellText)) and text.is_python_text(): <TAB>  <TAB>  <TAB> if isinstance(text, CodeViewText): <TAB>  <TAB>  <TAB>  <TAB> text.autocompleter = Completer(text) <MASK> text.autocompleter = ShellCompleter(text) <TAB>  <TAB>  <TAB> text.bind(""<1>"", text.autocompleter.on_text_click) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return <TAB> text.autocompleter.handle_autocomplete_request()","elif isinstance ( text , ShellText ) :",151
2885,"def test_create_repository(repo_name, expected_status, client): <TAB> with client_with_identity(""devtable"", client) as cl: <TAB>  <TAB> body = { <TAB>  <TAB>  <TAB> ""namespace"": ""devtable"", <TAB>  <TAB>  <TAB> ""repository"": repo_name, <TAB>  <TAB>  <TAB> ""visibility"": ""public"", <TAB>  <TAB>  <TAB> ""description"": ""foo"", <TAB>  <TAB> } <TAB>  <TAB> result = conduct_api_call( <TAB>  <TAB>  <TAB> client, RepositoryList, ""post"", None, body, expected_code=expected_status <TAB>  <TAB> ).json <MASK> assert result[""name""] == repo_name <TAB>  <TAB>  <TAB> assert ( <TAB>  <TAB>  <TAB>  <TAB> model.repository.get_repository(""devtable"", repo_name).name == repo_name <TAB>  <TAB>  <TAB> )",if expected_status == 201 :,186
2886,"def _apply_filter(filter_item, filter_list): <TAB> for filter_method in filter_list: <TAB>  <TAB> try: <MASK> return False <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> raise MessageException( <TAB>  <TAB>  <TAB>  <TAB> ""Toolbox filter exception from '{}': {}."".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> filter_method.__name__, unicodify(e) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> return True","if not filter_method ( context , filter_item ) :",116
2887,"def printsumfp(fp, filename, out=sys.stdout): <TAB> m = md5() <TAB> try: <TAB>  <TAB> while 1: <TAB>  <TAB>  <TAB> data = fp.read(bufsize) <TAB>  <TAB>  <TAB> if not data: <TAB>  <TAB>  <TAB>  <TAB> break <MASK> data = data.encode(fp.encoding) <TAB>  <TAB>  <TAB> m.update(data) <TAB> except IOError as msg: <TAB>  <TAB> sys.stderr.write(""%s: I/O error: %s\n"" % (filename, msg)) <TAB>  <TAB> return 1 <TAB> out.write(""%s %s\n"" % (m.hexdigest(), filename)) <TAB> return 0","if isinstance ( data , str ) :",159
2888,"def get_block_loc_keys(block): <TAB> """"""Extract loc_keys used by @block"""""" <TAB> symbols = set() <TAB> for instr in block.lines: <MASK> if isinstance(instr.raw, list): <TAB>  <TAB>  <TAB>  <TAB> for expr in instr.raw: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> symbols.update(get_expr_locs(expr)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for arg in instr.args: <TAB>  <TAB>  <TAB>  <TAB> symbols.update(get_expr_locs(arg)) <TAB> return symbols","if isinstance ( instr , AsmRaw ) :",131
2889,"def get_operations(cls, info, operations: List[ProductAttributeAssignInput]): <TAB> """"""Resolve all passed global ids into integer PKs of the Attribute type."""""" <TAB> product_attrs_pks = [] <TAB> variant_attrs_pks = [] <TAB> for operation in operations: <TAB>  <TAB> pk = from_global_id_strict_type( <TAB>  <TAB>  <TAB> operation.id, only_type=Attribute, field=""operations"" <TAB>  <TAB> ) <MASK> product_attrs_pks.append(pk) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> variant_attrs_pks.append(pk) <TAB> return product_attrs_pks, variant_attrs_pks",if operation . type == ProductAttributeType . PRODUCT :,156
2890,"def _collect_manual_intervention_nodes(pipeline_tree): <TAB> for act in pipeline_tree[""activities""].values(): <TAB>  <TAB> if act[""type""] == ""SubProcess"": <TAB>  <TAB>  <TAB> _collect_manual_intervention_nodes(act[""pipeline""]) <MASK> manual_intervention_nodes.add(act[""id""])","elif act [ ""component"" ] [ ""code"" ] in MANUAL_INTERVENTION_COMP_CODES :",105
2891,"def prompt_authorization(self, stacks: List[Stack]): <TAB> auth_required_per_resource = auth_per_resource(stacks) <TAB> for resource, authorization_required in auth_required_per_resource: <MASK> auth_confirm = confirm( <TAB>  <TAB>  <TAB>  <TAB> f""\t{self.start_bold}{resource} may not have authorization defined, Is this okay?{self.end_bold}"", <TAB>  <TAB>  <TAB>  <TAB> default=False, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> if not auth_confirm: <TAB>  <TAB>  <TAB>  <TAB> raise GuidedDeployFailedError(msg=""Security Constraints Not Satisfied!"")",if not authorization_required :,148
2892,"def get_cloud_credential(self): <TAB> """"""Return the credential which is directly tied to the inventory source type."""""" <TAB> credential = None <TAB> for cred in self.credentials.all(): <TAB>  <TAB> if self.source in CLOUD_PROVIDERS: <MASK> credential = cred <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # these need to be returned in the API credential field <TAB>  <TAB>  <TAB> if cred.credential_type.kind != ""vault"": <TAB>  <TAB>  <TAB>  <TAB> credential = cred <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return credential","if cred . kind == self . source . replace ( ""ec2"" , ""aws"" ) :",149
2893,"def validate_party_details(self): <TAB> if self.party: <TAB>  <TAB> if not frappe.db.exists(self.party_type, self.party): <TAB>  <TAB>  <TAB> frappe.throw(_(""Invalid {0}: {1}"").format(self.party_type, self.party)) <MASK> self.validate_account_type( <TAB>  <TAB>  <TAB>  <TAB> self.party_account, [erpnext.get_party_account_type(self.party_type)] <TAB>  <TAB>  <TAB> )","if self . party_account and self . party_type in ( ""Customer"" , ""Supplier"" ) :",140
2894,"def __iter__(self): <TAB> it = DiskHashMerger.__iter__(self) <TAB> direct_upstreams = self.direct_upstreams <TAB> for k, groups in it: <TAB>  <TAB> t = list([[] for _ in range(self.size)]) <TAB>  <TAB> for i, g in enumerate(groups): <MASK> if i in direct_upstreams: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> t[i] = g <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> g.sort(key=itemgetter(0)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> g1 = [] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for _, vs in g: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> g1.extend(vs) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> t[i] = g1 <TAB>  <TAB> yield k, tuple(t)",if g :,185
2895,"def _unpack_scales(scales, vidxs): <TAB> scaleData = [None, None, None] <TAB> for i in range(3): <MASK> break <TAB>  <TAB> scale = scales[i] <TAB>  <TAB> if not math.isnan(scale): <TAB>  <TAB>  <TAB> vidx1, vidx2 = vidxs[i * 2], vidxs[i * 2 + 1] <TAB>  <TAB>  <TAB> scaleData[i] = (int(vidx1), int(vidx2), float(scale)) <TAB> return scaleData","if i >= min ( len ( scales ) , len ( vidxs ) // 2 ) :",138
2896,"def _make_ext_obj(self, obj): <TAB> ext = self._get_ext_class(obj.objname)() <TAB> for name, val in obj.body: <MASK> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> ""Error val should be a list, this is a python-opcua bug"", <TAB>  <TAB>  <TAB>  <TAB> name, <TAB>  <TAB>  <TAB>  <TAB> type(val), <TAB>  <TAB>  <TAB>  <TAB> val, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for attname, v in val: <TAB>  <TAB>  <TAB>  <TAB> self._set_attr(ext, attname, v) <TAB> return ext","if not isinstance ( val , list ) :",148
2897,"def insertLine(self, refnum, linenum, line): <TAB> i = -1 <TAB> for i, row in enumerate(self.rows): <TAB>  <TAB> if row[0] == linenum: <TAB>  <TAB>  <TAB> if row[refnum + 1] is None: <TAB>  <TAB>  <TAB>  <TAB> row[refnum + 1] = line <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> # else keep looking <MASK> break <TAB> self.rows.insert(i, self.newRow(linenum, refnum, line))",elif row [ 0 ] > linenum :,125
2898,"def valid_localparts(strip_delimiters=False): <TAB> for line in ABRIDGED_LOCALPART_VALID_TESTS.split(""\n""): <TAB>  <TAB> # strip line, skip over empty lines <TAB>  <TAB> line = line.strip() <TAB>  <TAB> if line == """": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # skip over comments or empty lines <TAB>  <TAB> match = COMMENT.match(line) <TAB>  <TAB> if match: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # skip over localparts with delimiters <TAB>  <TAB> if strip_delimiters: <MASK> continue <TAB>  <TAB> yield line","if "","" in line or "";"" in line :",145
2899,"def encodingChanged(self, idx): <TAB> encoding = str(self.mode_combo.currentText()) <TAB> validator = None <TAB> if encoding == ""hex"": <TAB>  <TAB> # only clear the box if there are non-hex chars <TAB>  <TAB> # before setting the validator. <TAB>  <TAB> txt = str(self.data_edit.text()) <MASK> self.data_edit.setText("""") <TAB>  <TAB> regex = QtCore.QRegExp(""^[0-9A-Fa-f]+$"") <TAB>  <TAB> validator = QtGui.QRegExpValidator(regex) <TAB> self.data_edit.setValidator(validator) <TAB> self.renderMemory()",if not all ( c in string . hexdigits for c in txt ) :,164
2900,"def _compare_single_run(self, compares_done): <TAB> try: <TAB>  <TAB> compare_id, redo = self.in_queue.get( <TAB>  <TAB>  <TAB> timeout=float(self.config[""ExpertSettings""][""block_delay""]) <TAB>  <TAB> ) <TAB> except Empty: <TAB>  <TAB> pass <TAB> else: <TAB>  <TAB> if self._decide_whether_to_process(compare_id, redo, compares_done): <MASK> self.db_interface.delete_old_compare_result(compare_id) <TAB>  <TAB>  <TAB> compares_done.add(compare_id) <TAB>  <TAB>  <TAB> self._process_compare(compare_id) <TAB>  <TAB>  <TAB> if self.callback: <TAB>  <TAB>  <TAB>  <TAB> self.callback()",if redo :,177
2901,"def _transform_bin(self, X: DataFrame): <TAB> if self._bin_map: <MASK> X = X.copy(deep=True) <TAB>  <TAB> with pd.option_context(""mode.chained_assignment"", None): <TAB>  <TAB>  <TAB> # Pandas complains about SettingWithCopyWarning, but this should be valid. <TAB>  <TAB>  <TAB> for column in self._bin_map: <TAB>  <TAB>  <TAB>  <TAB> X[column] = binning.bin_column( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> series=X[column], <TAB>  <TAB>  <TAB>  <TAB>  <TAB> mapping=self._bin_map[column], <TAB>  <TAB>  <TAB>  <TAB>  <TAB> dtype=self._astype_map[column], <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return X",if not self . inplace :,166
2902,"def escape(text, newline=False): <TAB> """"""Escape special html characters."""""" <TAB> if isinstance(text, str): <TAB>  <TAB> if ""&"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""&"", ""&amp;"") <TAB>  <TAB> if "">"" in text: <TAB>  <TAB>  <TAB> text = text.replace("">"", ""&gt;"") <TAB>  <TAB> if ""<"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""<"", ""&lt;"") <TAB>  <TAB> if '""' in text: <TAB>  <TAB>  <TAB> text = text.replace('""', ""&quot;"") <MASK> text = text.replace(""'"", ""&quot;"") <TAB>  <TAB> if newline: <TAB>  <TAB>  <TAB> if ""\n"" in text: <TAB>  <TAB>  <TAB>  <TAB> text = text.replace(""\n"", ""<br>"") <TAB> return text","if ""'"" in text :",170
2903,"def read(self): <TAB> """"""Reads the robots.txt URL and feeds it to the parser."""""" <TAB> try: <TAB>  <TAB> f = urllib.request.urlopen(self.url) <TAB> except urllib.error.HTTPError as err: <MASK> self.disallow_all = True <TAB>  <TAB> elif err.code >= 400 and err.code < 500: <TAB>  <TAB>  <TAB> self.allow_all = True <TAB> else: <TAB>  <TAB> raw = f.read() <TAB>  <TAB> self.parse(raw.decode(""utf-8"").splitlines())","if err . code in ( 401 , 403 ) :",134
2904,"def post_create(self, user, billing=None): <TAB> from weblate.trans.models import Change <TAB> if billing: <TAB>  <TAB> billing.projects.add(self) <MASK> self.access_control = Project.ACCESS_PRIVATE <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.access_control = Project.ACCESS_PUBLIC <TAB>  <TAB> self.save() <TAB> if not user.is_superuser: <TAB>  <TAB> self.add_user(user, ""@Administration"") <TAB> Change.objects.create( <TAB>  <TAB> action=Change.ACTION_CREATE_PROJECT, project=self, user=user, author=user <TAB> )",if billing . plan . change_access_control :,158
2905,"def visitConst(self, node): <TAB> if self.documentable: <MASK> self.documentable.append(make_docstring(node.value, node.lineno)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.documentable = None","if type ( node . value ) in ( StringType , UnicodeType ) :",73
2906,"def requires(self): <TAB> requires = copy.deepcopy(self._requires) <TAB> # Auto add dependencies when parameters reference the Ouptuts of <TAB> # another stack. <TAB> parameters = self.parameters <TAB> for value in parameters.values(): <TAB>  <TAB> if isinstance(value, basestring) and ""::"" in value: <TAB>  <TAB>  <TAB> stack_name, _ = value.split(""::"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> continue <MASK> requires.add(stack_name) <TAB> return requires",if stack_name not in requires :,123
2907,"def __load_protos(): <TAB> g = globals() <TAB> for k, v in g.items(): <MASK> name = k[4:] <TAB>  <TAB>  <TAB> modname = name.lower() <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> mod = __import__(modname, g, level=1) <TAB>  <TAB>  <TAB>  <TAB> PPP.set_p(v, getattr(mod, name)) <TAB>  <TAB>  <TAB> except (ImportError, AttributeError): <TAB>  <TAB>  <TAB>  <TAB> continue","if k . startswith ( ""PPP_"" ) :",115
2908,"def init_weights(self): <TAB> """"""Initialize model weights."""""" <TAB> for m in self.predict_layers.modules(): <TAB>  <TAB> if isinstance(m, nn.Conv2d): <TAB>  <TAB>  <TAB> kaiming_init(m) <TAB>  <TAB> elif isinstance(m, nn.BatchNorm2d): <TAB>  <TAB>  <TAB> constant_init(m, 1) <MASK> normal_init(m, std=0.01)","elif isinstance ( m , nn . Linear ) :",107
2909,"def get_data(self): <TAB> """"""get all data from sockets"""""" <TAB> si = self.inputs <TAB> parameters = [] <TAB> for socket in si: <MASK> parameters.append(socket.sv_get()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> parameters.append(socket.sv_get(default=[[]])) <TAB> return match_long_repeat(parameters)",if len ( socket . prop_name ) > 0 :,98
2910,"def test_parse_query_params_comparable_field(self): <TAB> query_params = {""filter[int_field][gt]"": 42, ""filter[int_field][lte]"": 9000} <TAB> fields = self.view.parse_query_params(query_params) <TAB> for key, field_name in fields.items(): <TAB>  <TAB> if field_name[""int_field""][""op""] == ""gt"": <TAB>  <TAB>  <TAB> assert_equal(field_name[""int_field""][""value""], 42) <MASK> assert_equal(field_name[""int_field""][""value""], 9000) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.fail()","elif field_name [ ""int_field"" ] [ ""op"" ] == ""lte"" :",168
2911,"def _create_examples(self, lines, set_type): <TAB> """"""Creates examples for the training and dev sets."""""" <TAB> examples = [] <TAB> for (i, line) in enumerate(lines): <MASK> continue <TAB>  <TAB> guid = ""%s-%s"" % (set_type, i) <TAB>  <TAB> text = line[0] <TAB>  <TAB> bbox = line[1] <TAB>  <TAB> label = line[2] <TAB>  <TAB> examples.append( <TAB>  <TAB>  <TAB> DocExample(guid=guid, text_a=text, text_b=None, bbox=bbox, label=label) <TAB>  <TAB> ) <TAB> return examples",if i == 0 :,149
2912,"def _get_attr(sdk_path, mod_attr_path, checked=True): <TAB> try: <TAB>  <TAB> attr_mod, attr_path = ( <TAB>  <TAB>  <TAB> mod_attr_path.split(""#"") if ""#"" in mod_attr_path else (mod_attr_path, """") <TAB>  <TAB> ) <TAB>  <TAB> full_mod_path = ""{}.{}"".format(sdk_path, attr_mod) if attr_mod else sdk_path <TAB>  <TAB> op = import_module(full_mod_path) <MASK> # Only load attributes if needed <TAB>  <TAB>  <TAB> for part in attr_path.split("".""): <TAB>  <TAB>  <TAB>  <TAB> op = getattr(op, part) <TAB>  <TAB> return op <TAB> except (ImportError, AttributeError) as ex: <TAB>  <TAB> if checked: <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> raise ex",if attr_path :,191
2913,"def _load_ui_modules(self, modules: Any) -> None: <TAB> if isinstance(modules, types.ModuleType): <TAB>  <TAB> self._load_ui_modules(dict((n, getattr(modules, n)) for n in dir(modules))) <TAB> elif isinstance(modules, list): <TAB>  <TAB> for m in modules: <TAB>  <TAB>  <TAB> self._load_ui_modules(m) <TAB> else: <TAB>  <TAB> assert isinstance(modules, dict) <TAB>  <TAB> for name, cls in modules.items(): <TAB>  <TAB>  <TAB> try: <MASK> self.ui_modules[name] = cls <TAB>  <TAB>  <TAB> except TypeError: <TAB>  <TAB>  <TAB>  <TAB> pass","if issubclass ( cls , UIModule ) :",162
2914,"def _remove_obsolete_leafs(input_dict): <TAB> if not isinstance(input_dict, dict): <TAB>  <TAB> return <TAB> if input_dict[LEAF_MARKER]: <TAB>  <TAB> bottom_leafs = input_dict[LEAF_MARKER] <TAB>  <TAB> for leaf in bottom_leafs: <MASK> input_dict[LEAF_MARKER].remove(leaf) <TAB> for subtree in input_dict.keys(): <TAB>  <TAB> _remove_obsolete_leafs(input_dict[subtree])",if leaf in input_dict :,124
2915,"def decode(self, value, force=False): <TAB> ""Return a unicode string from the bytes-like representation"" <TAB> if self.decode_responses or force: <MASK> value = value.tobytes() <TAB>  <TAB> if isinstance(value, bytes): <TAB>  <TAB>  <TAB> value = value.decode(self.encoding, self.encoding_errors) <TAB> return value","if isinstance ( value , memoryview ) :",91
2916,"def audit(self, directive): <TAB> value = _get_value(directive) <TAB> if not value: <TAB>  <TAB> return <TAB> server_side = directive.name.startswith(""proxy_"") <TAB> for var in compile_script(value): <TAB>  <TAB> char = """" <MASK> char = ""\\n"" <TAB>  <TAB> elif not server_side and var.can_contain(""\r""): <TAB>  <TAB>  <TAB> char = ""\\r"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> reason = 'At least variable ""${var}"" can contain ""{char}""'.format( <TAB>  <TAB>  <TAB> var=var.name, char=char <TAB>  <TAB> ) <TAB>  <TAB> self.add_issue(directive=[directive] + var.providers, reason=reason)","if var . can_contain ( ""\n"" ) :",176
2917,"def checkFilename(filename):  # useful in case of drag and drop <TAB> while True: <TAB>  <TAB> if filename[0] == ""'"": <TAB>  <TAB>  <TAB> filename = filename[1:] <MASK> filename = filename[:-1] <TAB>  <TAB> if os.path.exists(filename): <TAB>  <TAB>  <TAB> return filename <TAB>  <TAB> filename = input( <TAB>  <TAB>  <TAB> ""[!] Cannot find '%s'.\n[*] Enter a valid name of the file containing the paths to test -> "" <TAB>  <TAB>  <TAB> % filename <TAB>  <TAB> )","if filename [ len ( filename ) - 1 ] == ""'"" :",130
2918,"def findfiles(self, dir, base, rec): <TAB> try: <TAB>  <TAB> names = os.listdir(dir or os.curdir) <TAB> except os.error as msg: <TAB>  <TAB> print(msg) <TAB>  <TAB> return [] <TAB> list = [] <TAB> subdirs = [] <TAB> for name in names: <TAB>  <TAB> fn = os.path.join(dir, name) <MASK> subdirs.append(fn) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if fnmatch.fnmatch(name, base): <TAB>  <TAB>  <TAB>  <TAB> list.append(fn) <TAB> if rec: <TAB>  <TAB> for subdir in subdirs: <TAB>  <TAB>  <TAB> list.extend(self.findfiles(subdir, base, rec)) <TAB> return list",if os . path . isdir ( fn ) :,174
2919,"def loop(handler, obj): <TAB> handler.response.write(""<table>"") <TAB> for k, v in obj.__dict__.items(): <MASK> style = ""color: red"" if not v else """" <TAB>  <TAB>  <TAB> handler.response.write( <TAB>  <TAB>  <TAB>  <TAB> '<tr style=""{}""><td>{}:</td><td>{}</td></tr>'.format(style, k, v) <TAB>  <TAB>  <TAB> ) <TAB> handler.response.write(""</table>"")","if not k in ( ""data"" , ""gae_user"" , ""credentials"" , ""content"" , ""config"" ) :",127
2920,"def anypython(request): <TAB> name = request.param <TAB> executable = getexecutable(name) <TAB> if executable is None: <TAB>  <TAB> if sys.platform == ""win32"": <TAB>  <TAB>  <TAB> executable = winpymap.get(name, None) <TAB>  <TAB>  <TAB> if executable: <TAB>  <TAB>  <TAB>  <TAB> executable = py.path.local(executable) <MASK> return executable <TAB>  <TAB> pytest.skip(""no suitable %s found"" % (name,)) <TAB> return executable",if executable . check ( ) :,119
2921,"def __init__(self, socketpath=None): <TAB> if socketpath is None: <MASK> socketpath = ""/var/run/usbmuxd"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> socketpath = ""/var/run/usbmuxd"" <TAB> self.socketpath = socketpath <TAB> self.listener = MuxConnection(socketpath, BinaryProtocol) <TAB> try: <TAB>  <TAB> self.listener.listen() <TAB>  <TAB> self.version = 0 <TAB>  <TAB> self.protoclass = BinaryProtocol <TAB> except MuxVersionError: <TAB>  <TAB> self.listener = MuxConnection(socketpath, PlistProtocol) <TAB>  <TAB> self.listener.listen() <TAB>  <TAB> self.protoclass = PlistProtocol <TAB>  <TAB> self.version = 1 <TAB> self.devices = self.listener.devices","if sys . platform == ""darwin"" :",194
2922,"def _validate_distinct_on_different_types_and_field_orders( <TAB> self, collection, query, expected_results, get_mock_result): <TAB> self.count = 0 <TAB> self.get_mock_result = get_mock_result <TAB> query_iterable = collection.query_items(query, enable_cross_partition_query=True) <TAB> results = list(query_iterable) <TAB> for i in range(len(expected_results)): <MASK> self.assertDictEqual(results[i], expected_results[i]) <TAB>  <TAB> elif isinstance(results[i], list): <TAB>  <TAB>  <TAB> self.assertListEqual(results[i], expected_results[i]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertEqual(results[i], expected_results[i]) <TAB> self.count = 0","if isinstance ( results [ i ] , dict ) :",196
2923,"def getRootId(self, id): <TAB> with self.connect() as cu: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> stmt = ""select parent_path_id from hierarchy where path_id = ?"" <TAB>  <TAB>  <TAB> cu.execute(stmt, (id,)) <TAB>  <TAB>  <TAB> parent_id = cu.fetchone()[0] <MASK> return id <TAB>  <TAB>  <TAB> id = parent_id",if parent_id is None or parent_id == id :,109
2924,"def add(self, path): <TAB> with self.get_lock(path): <MASK> self.entries[path] = {} <TAB>  <TAB>  <TAB> self.entries[path][""lock""] = self.new_locks[path] <TAB>  <TAB>  <TAB> del self.new_locks[path] <TAB>  <TAB>  <TAB> self.lru.append(path)",if not path in self . entries :,88
2925,"def _get_coordinates_for_dataset_key(self, dsid): <TAB> """"""Get the coordinate dataset keys for *dsid*."""""" <TAB> ds_info = self.ids[dsid] <TAB> cids = [] <TAB> for cinfo in ds_info.get(""coordinates"", []): <TAB>  <TAB> if not isinstance(cinfo, dict): <TAB>  <TAB>  <TAB> cinfo = {""name"": cinfo} <TAB>  <TAB> cinfo[""resolution""] = ds_info[""resolution""] <MASK> cinfo[""polarization""] = ds_info[""polarization""] <TAB>  <TAB> cid = DatasetID(**cinfo) <TAB>  <TAB> cids.append(self.get_dataset_key(cid)) <TAB> return cids","if ""polarization"" in ds_info :",170
2926,"def build_from_gdobj(cls, gdobj, steal=False): <TAB> # Avoid calling cls.__init__ by first instanciating a placeholder, then <TAB> # overloading it __class__ to turn it into an instance of the right class <TAB> ret = BuiltinInitPlaceholder() <TAB> if steal: <TAB>  <TAB> assert ffi.typeof(gdobj).kind == ""pointer"" <TAB>  <TAB> ret._gd_ptr = gdobj <TAB> else: <MASK> ret._gd_ptr = cls._copy_gdobj(gdobj) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret._gd_ptr = cls._copy_gdobj(ffi.addressof(gdobj)) <TAB> ret.__class__ = cls <TAB> return ret","if ffi . typeof ( gdobj ) . kind == ""pointer"" :",182
2927,"def _listen_output(self): <TAB> ""NB! works in background thread"" <TAB> try: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> chars = self._proc.read(1) <MASK> as_bytes = chars.encode(self.encoding) <TAB>  <TAB>  <TAB>  <TAB> self._make_output_available(as_bytes) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._error = ""EOF"" <TAB>  <TAB>  <TAB>  <TAB> break <TAB> except Exception as e: <TAB>  <TAB> self._error = str(e)",if len ( chars ) > 0 :,131
2928,"def result( <TAB> metrics: Dict[metric_types.MetricKey, Any]) -> Dict[metric_types.AttributionsKey, Dict[Text, Union[float, np.ndarray]]]: <TAB> """"""Returns mean attributions."""""" <TAB> total_attributions = metrics[total_attributions_key] <TAB> weighted_count = metrics[weighted_example_count_key] <TAB> attributions = {} <TAB> for k, v in total_attributions.items(): <MASK> attributions[k] = float(""nan"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> attributions[k] = v / weighted_count <TAB> return {key: attributions}","if np . isclose ( weighted_count , 0.0 ) :",162
2929,"def write_if_changed(path, data): <TAB> if isinstance(data, str): <TAB>  <TAB> data = data.encode() <TAB> changed = False <TAB> with open(os.open(path, os.O_CREAT | os.O_RDWR), ""wb+"") as f: <TAB>  <TAB> f.seek(0) <TAB>  <TAB> current = f.read() <MASK> changed = True <TAB>  <TAB>  <TAB> f.seek(0) <TAB>  <TAB>  <TAB> f.write(data) <TAB>  <TAB>  <TAB> f.truncate() <TAB>  <TAB> os.fsync(f) <TAB> return changed",if current != data :,138
2930,"def detect_ssl_option(self): <TAB> for option in self.ssl_options(): <TAB>  <TAB> if scan_argv(self.argv, option) is not None: <TAB>  <TAB>  <TAB> for other_option in self.ssl_options(): <MASK> if scan_argv(self.argv, other_option) is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise ConfigurationError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Cannot give both %s and %s"" % (option, other_option) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return option",if option != other_option :,140
2931,"def _infer_return_type(*args): <TAB> """"""Look at the type of all args and divine their implied return type."""""" <TAB> return_type = None <TAB> for arg in args: <MASK> continue <TAB>  <TAB> if isinstance(arg, bytes): <TAB>  <TAB>  <TAB> if return_type is str: <TAB>  <TAB>  <TAB>  <TAB> raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."") <TAB>  <TAB>  <TAB> return_type = bytes <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if return_type is bytes: <TAB>  <TAB>  <TAB>  <TAB> raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."") <TAB>  <TAB>  <TAB> return_type = str <TAB> if return_type is None: <TAB>  <TAB> return str  # tempfile APIs return a str by default. <TAB> return return_type",if arg is None :,186
2932,"def _get_app(self, body=None): <TAB> app = self._app <TAB> if app is None: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> tasks = self.tasks.tasks  # is a group <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB> tasks = self.tasks <MASK> app = tasks[0]._app <TAB>  <TAB> if app is None and body is not None: <TAB>  <TAB>  <TAB> app = body._app <TAB> return app if app is not None else current_app",if len ( tasks ) :,117
2933,"def add_field(self, field): <TAB> self.remove_field(field.name) <TAB> self.fields[field.name] = field <TAB> self.columns[field.db_column] = field <TAB> self._sorted_field_list.insert(field) <TAB> self._update_field_lists() <TAB> if field.default is not None: <TAB>  <TAB> self.defaults[field] = field.default <MASK> self._default_callables[field] = field.default <TAB>  <TAB>  <TAB> self._default_callable_list.append((field.name, field.default)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._default_dict[field] = field.default <TAB>  <TAB>  <TAB> self._default_by_name[field.name] = field.default",if callable ( field . default ) :,184
2934,"def _get_families(self): <TAB> families = [] <TAB> for name, ext in self._get_family_dirs(): <MASK> # is a directory <TAB>  <TAB>  <TAB> family = self.get_resource( <TAB>  <TAB>  <TAB>  <TAB> FileSystemPackageFamilyResource.key, location=self.location, name=name <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> family = self.get_resource( <TAB>  <TAB>  <TAB>  <TAB> FileSystemCombinedPackageFamilyResource.key, <TAB>  <TAB>  <TAB>  <TAB> location=self.location, <TAB>  <TAB>  <TAB>  <TAB> name=name, <TAB>  <TAB>  <TAB>  <TAB> ext=ext, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> families.append(family) <TAB> return families",if ext is None :,157
2935,"def test(model, data_loader, device=None): <TAB> device = device or torch.device(""cpu"") <TAB> model.eval() <TAB> correct = 0 <TAB> total = 0 <TAB> with torch.no_grad(): <TAB>  <TAB> for batch_idx, (data, target) in enumerate(data_loader): <MASK> break <TAB>  <TAB>  <TAB> data, target = data.to(device), target.to(device) <TAB>  <TAB>  <TAB> outputs = model(data) <TAB>  <TAB>  <TAB> _, predicted = torch.max(outputs.data, 1) <TAB>  <TAB>  <TAB> total += target.size(0) <TAB>  <TAB>  <TAB> correct += (predicted == target).sum().item() <TAB> return correct / total",if batch_idx * len ( data ) > TEST_SIZE :,175
2936,"def __animate_progress(self): <TAB> """"""Change the status message, mostly used to animate progress."""""" <TAB> while True: <TAB>  <TAB> sleep_time = ThreadPool.PROGRESS_IDLE_DELAY <TAB>  <TAB> with self.__progress_lock: <MASK> sleep_time = ThreadPool.PROGRESS_IDLE_DELAY <TAB>  <TAB>  <TAB> elif self.__show_animation: <TAB>  <TAB>  <TAB>  <TAB> self.__progress_status.update_progress(self.__current_operation_name) <TAB>  <TAB>  <TAB>  <TAB> sleep_time = ThreadPool.PROGRESS_UPDATE_DELAY <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.__progress_status.show_as_ready() <TAB>  <TAB>  <TAB>  <TAB> sleep_time = ThreadPool.PROGRESS_IDLE_DELAY <TAB>  <TAB> # Allow some time for progress status to be updated. <TAB>  <TAB> time.sleep(sleep_time)",if not self . __progress_status :,195
2937,"def _parse_subtitles(self, video_data, url_key): <TAB> subtitles = {} <TAB> for translation in video_data.get(""translations"", []): <TAB>  <TAB> vtt_path = translation.get(url_key) <MASK> continue <TAB>  <TAB> lang = translation.get(""language_w3c"") or ISO639Utils.long2short( <TAB>  <TAB>  <TAB> translation[""language_medium""] <TAB>  <TAB> ) <TAB>  <TAB> subtitles.setdefault(lang, []).append( <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB> ""ext"": ""vtt"", <TAB>  <TAB>  <TAB>  <TAB> ""url"": vtt_path, <TAB>  <TAB>  <TAB> } <TAB>  <TAB> ) <TAB> return subtitles",if not vtt_path :,164
2938,"def postprocess_message(self, msg): <TAB> if msg[""type""] == ""sample"" and msg[""value""] is not None: <TAB>  <TAB> fn, value = msg[""fn""], msg[""value""] <TAB>  <TAB> value_batch_ndims = jnp.ndim(value) - fn.event_dim <TAB>  <TAB> fn_batch_ndim = len(fn.batch_shape) <MASK> prepend_shapes = (1,) * (value_batch_ndims - fn_batch_ndim) <TAB>  <TAB>  <TAB> msg[""fn""] = tree_map( <TAB>  <TAB>  <TAB>  <TAB> lambda x: jnp.reshape(x, prepend_shapes + jnp.shape(x)), fn <TAB>  <TAB>  <TAB> )",if fn_batch_ndim < value_batch_ndims :,170
2939,"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.set_filename(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 10 :,90
2940,"def createError(self, line, pos, description): <TAB> global ENABLE_PYIMPORT <TAB> msg = ""Line "" + unicode(line) + "": "" + unicode(description) <TAB> if ENABLE_JS2PY_ERRORS: <MASK> import js2py.base <TAB>  <TAB>  <TAB> return js2py.base.MakeError(""SyntaxError"", msg) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ENABLE_JS2PY_ERRORS(msg) <TAB> else: <TAB>  <TAB> return JsSyntaxError(msg)","if isinstance ( ENABLE_JS2PY_ERRORS , bool ) :",129
2941,"def extract(self, page, start_index=0, end_index=None): <TAB> items = [] <TAB> for extractor in self.extractors: <TAB>  <TAB> extracted = extractor.extract( <TAB>  <TAB>  <TAB> page, start_index, end_index, self.template.ignored_regions <TAB>  <TAB> ) <TAB>  <TAB> for item in arg_to_iter(extracted): <MASK> if isinstance(item, (ItemProcessor, dict)): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> item[u""_template""] = self.template.id <TAB>  <TAB>  <TAB>  <TAB> items.append(item) <TAB> return items",if item :,141
2942,"def create_volume(self, volume): <TAB> """"""Create a volume."""""" <TAB> try: <TAB>  <TAB> cmd = [""volume"", ""create"", volume[""name""], ""%sG"" % (volume[""size""])] <MASK> cmd.append(""pool"") <TAB>  <TAB>  <TAB> cmd.append(self.configuration.eqlx_pool) <TAB>  <TAB> if self.configuration.san_thin_provision: <TAB>  <TAB>  <TAB> cmd.append(""thin-provision"") <TAB>  <TAB> out = self._eql_execute(*cmd) <TAB>  <TAB> self.add_multihost_access(volume) <TAB>  <TAB> return self._get_volume_data(out) <TAB> except Exception: <TAB>  <TAB> with excutils.save_and_reraise_exception(): <TAB>  <TAB>  <TAB> LOG.error('Failed to create volume ""%s"".', volume[""name""])","if self . configuration . eqlx_pool != ""default"" :",199
2943,"def clean(self): <TAB> # TODO: check for clashes if the random code is already taken <TAB> if not self.code: <TAB>  <TAB> self.code = u""static-%s"" % uuid.uuid4() <TAB> if not self.site: <TAB>  <TAB> placeholders = StaticPlaceholder.objects.filter( <TAB>  <TAB>  <TAB> code=self.code, site__isnull=True <TAB>  <TAB> ) <MASK> placeholders = placeholders.exclude(pk=self.pk) <TAB>  <TAB> if placeholders.exists(): <TAB>  <TAB>  <TAB> raise ValidationError( <TAB>  <TAB>  <TAB>  <TAB> _(""A static placeholder with the same site and code already exists"") <TAB>  <TAB>  <TAB> )",if self . pk :,149
2944,"def spawnMenu(self, event): <TAB> clickedPos = self.getRowByAbs(event.Position) <TAB> self.ensureSelection(clickedPos) <TAB> selection = self.getSelectedBoosters() <TAB> mainBooster = None <TAB> if clickedPos != -1: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> booster = self.boosters[clickedPos] <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <MASK> mainBooster = booster <TAB> itemContext = None if mainBooster is None else _t(""Booster"") <TAB> menu = ContextMenu.getMenu( <TAB>  <TAB> self, <TAB>  <TAB> mainBooster, <TAB>  <TAB> selection, <TAB>  <TAB> (""boosterItem"", itemContext), <TAB>  <TAB> (""boosterItemMisc"", itemContext), <TAB> ) <TAB> if menu: <TAB>  <TAB> self.PopupMenu(menu)",if booster in self . original :,199
2945,"def init_errorhandler(): <TAB> # http error handling <TAB> for ex in default_exceptions: <MASK> app.register_error_handler(ex, error_http) <TAB>  <TAB> elif ex == 500: <TAB>  <TAB>  <TAB> app.register_error_handler(ex, internal_error) <TAB> if services.ldap: <TAB>  <TAB> # Only way of catching the LDAPException upon logging in with LDAP server down <TAB>  <TAB> @app.errorhandler(services.ldap.LDAPException) <TAB>  <TAB> def handle_exception(e): <TAB>  <TAB>  <TAB> log.debug(""LDAP server not accessible while trying to login to opds feed"") <TAB>  <TAB>  <TAB> return error_http(FailedDependency())",if ex < 500 :,168
2946,"def reloadCols(self): <TAB> self.columns = [] <TAB> for i, (name, fmt, *shape) in enumerate(self.npy.dtype.descr): <MASK> t = anytype <TAB>  <TAB> elif ""M"" in fmt: <TAB>  <TAB>  <TAB> self.addColumn(Column(name, type=date, getter=lambda c, r, i=i: str(r[i]))) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif ""i"" in fmt: <TAB>  <TAB>  <TAB> t = int <TAB>  <TAB> elif ""f"" in fmt: <TAB>  <TAB>  <TAB> t = float <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> t = anytype <TAB>  <TAB> self.addColumn(ColumnItem(name, i, type=t))",if shape :,168
2947,"def Proc2(IntParIO): <TAB> IntLoc = IntParIO + 10 <TAB> while True: <TAB>  <TAB> if Char1Glob == ""A"": <TAB>  <TAB>  <TAB> IntLoc = IntLoc - 1 <TAB>  <TAB>  <TAB> IntParIO = IntLoc - IntGlob <TAB>  <TAB>  <TAB> EnumLoc = Ident1 <MASK> break <TAB> return IntParIO",if EnumLoc == Ident1 :,90
2948,"def opengroup(self, name=None): <TAB> gid = self.groups <TAB> self.groupwidths.append(None) <TAB> if self.groups > MAXGROUPS: <TAB>  <TAB> raise error(""too many groups"") <TAB> if name is not None: <TAB>  <TAB> ogid = self.groupdict.get(name, None) <MASK> raise error( <TAB>  <TAB>  <TAB>  <TAB> ""redefinition of group name %r as group %d; "" <TAB>  <TAB>  <TAB>  <TAB> ""was group %d"" % (name, gid, ogid) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self.groupdict[name] = gid <TAB> return gid",if ogid is not None :,148
2949,"def __setattr__(self, name: str, val: Any): <TAB> if name.startswith(""COMPUTED_""): <TAB>  <TAB> if name in self: <TAB>  <TAB>  <TAB> old_val = self[name] <MASK> return <TAB>  <TAB>  <TAB> raise KeyError( <TAB>  <TAB>  <TAB>  <TAB> ""Computed attributed '{}' already exists "" <TAB>  <TAB>  <TAB>  <TAB> ""with a different value! old={}, new={}."".format(name, old_val, val) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self[name] = val <TAB> else: <TAB>  <TAB> super().__setattr__(name, val)",if old_val == val :,137
2950,"def get_all_function_symbols(self, module=""kernel""): <TAB> """"""Gets all the function tuples for the given module"""""" <TAB> ret = [] <TAB> symtable = self.type_map <TAB> if module in symtable: <TAB>  <TAB> mod = symtable[module] <TAB>  <TAB> for (addr, (name, _sym_types)) in mod.items(): <MASK> addr = addr + self.shift_address <TAB>  <TAB>  <TAB> ret.append([name, addr]) <TAB> else: <TAB>  <TAB> debug.info(""All symbols requested for non-existent module %s"" % module) <TAB> return ret",if self . shift_address and addr :,147
2951,"def __call__(self, frame: FrameType, event: str, arg: Any) -> ""CallTracer"": <TAB> code = frame.f_code <TAB> if ( <TAB>  <TAB> event not in SUPPORTED_EVENTS <TAB>  <TAB> or code.co_name == ""trace_types"" <TAB>  <TAB> or self.should_trace <TAB>  <TAB> and not self.should_trace(code) <TAB> ): <TAB>  <TAB> return self <TAB> try: <MASK> self.handle_call(frame) <TAB>  <TAB> elif event == EVENT_RETURN: <TAB>  <TAB>  <TAB> self.handle_return(frame, arg) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logger.error(""Cannot handle event %s"", event) <TAB> except Exception: <TAB>  <TAB> logger.exception(""Failed collecting trace"") <TAB> return self",if event == EVENT_CALL :,185
2952,"def test_update_topic(self): <TAB> async with self.chat_client: <TAB>  <TAB> await self._create_thread() <TAB>  <TAB> topic = ""update topic"" <TAB>  <TAB> async with self.chat_thread_client: <TAB>  <TAB>  <TAB> await self.chat_thread_client.update_topic(topic=topic) <TAB>  <TAB> # delete chat threads <MASK> await self.chat_client.delete_chat_thread(self.thread_id)",if not self . is_playback ( ) :,114
2953,"def render_observation(self): <TAB> x = self.read_head_position <TAB> label = ""Observation Grid <TAB> : "" <TAB> x_str = """" <TAB> for j in range(-1, self.rows + 1): <TAB>  <TAB> if j != -1: <TAB>  <TAB>  <TAB> x_str += "" "" * len(label) <TAB>  <TAB> for i in range(-2, self.input_width + 2): <MASK> x_str += colorize(self._get_str_obs((i, j)), ""green"", highlight=True) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> x_str += self._get_str_obs((i, j)) <TAB>  <TAB> x_str += ""\n"" <TAB> x_str = label + x_str <TAB> return x_str",if i == x [ 0 ] and j == x [ 1 ] :,200
2954,"def build(opt): <TAB> dpath = os.path.join(opt[""datapath""], ""QA-ZRE"") <TAB> version = None <TAB> if not build_data.built(dpath, version_string=version): <TAB>  <TAB> print(""[building data: "" + dpath + ""]"") <MASK> # An older version exists, so remove these outdated files. <TAB>  <TAB>  <TAB> build_data.remove_dir(dpath) <TAB>  <TAB> build_data.make_dir(dpath) <TAB>  <TAB> # Download the data. <TAB>  <TAB> for downloadable_file in RESOURCES: <TAB>  <TAB>  <TAB> downloadable_file.download_file(dpath) <TAB>  <TAB> # Mark the data as built. <TAB>  <TAB> build_data.mark_done(dpath, version_string=version)",if build_data . built ( dpath ) :,183
2955,"def git_pull(args): <TAB> if len(args) <= 1: <TAB>  <TAB> repo = _get_repo() <TAB>  <TAB> _confirm_dangerous() <TAB>  <TAB> url = args[0] if len(args) == 1 else repo.remotes.get(""origin"", """") <MASK> origin = url <TAB>  <TAB>  <TAB> url = repo.remotes.get(origin) <TAB>  <TAB> if url: <TAB>  <TAB>  <TAB> repo.pull(origin_uri=url) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""No pull URL."") <TAB> else: <TAB>  <TAB> print(command_help[""git pull""])",if url in repo . remotes :,147
2956,"def FindAndDelete(script, sig): <TAB> """"""Consensus critical, see FindAndDelete() in Satoshi codebase"""""" <TAB> r = b"""" <TAB> last_sop_idx = sop_idx = 0 <TAB> skip = True <TAB> for (opcode, data, sop_idx) in script.raw_iter(): <MASK> r += script[last_sop_idx:sop_idx] <TAB>  <TAB> last_sop_idx = sop_idx <TAB>  <TAB> if script[sop_idx : sop_idx + len(sig)] == sig: <TAB>  <TAB>  <TAB> skip = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> skip = False <TAB> if not skip: <TAB>  <TAB> r += script[last_sop_idx:] <TAB> return CScript(r)",if not skip :,187
2957,"def get_ip_info(ipaddress): <TAB> """"""Returns device information by IP address"""""" <TAB> result = {} <TAB> try: <TAB>  <TAB> ip = IPAddress.objects.select_related().get(address=ipaddress) <TAB> except IPAddress.DoesNotExist: <TAB>  <TAB> pass <TAB> else: <TAB>  <TAB> if ip.venture is not None: <TAB>  <TAB>  <TAB> result[""venture_id""] = ip.venture.id <TAB>  <TAB> if ip.device is not None: <TAB>  <TAB>  <TAB> result[""device_id""] = ip.device.id <MASK> result[""venture_id""] = ip.device.venture.id <TAB> return result",if ip . device . venture is not None :,162
2958,"def restore(self, state): <TAB> """"""Restore the state of a mesh previously saved using save()"""""" <TAB> import pickle <TAB> state = pickle.loads(state) <TAB> for k in state: <TAB>  <TAB> if isinstance(state[k], list): <MASK> state[k] = [[v.x(), v.y(), v.z()] for v in state[k]] <TAB>  <TAB>  <TAB> state[k] = np.array(state[k]) <TAB>  <TAB> setattr(self, k, state[k])","if isinstance ( state [ k ] [ 0 ] , QtGui . QVector3D ) :",135
2959,"def get_extra_lines(tup): <TAB> ext_name, pyopencl_ver = tup <TAB> if ext_name is not None: <MASK> # capital letters -> CL version, not extension <TAB>  <TAB>  <TAB> yield """" <TAB>  <TAB>  <TAB> yield "" <TAB> Available with OpenCL %s."" % (ext_name[3:]) <TAB>  <TAB>  <TAB> yield """" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield """" <TAB>  <TAB>  <TAB> yield "" <TAB> Available with the ``%s`` extension."" % ext_name <TAB>  <TAB>  <TAB> yield """" <TAB> if pyopencl_ver is not None: <TAB>  <TAB> yield """" <TAB>  <TAB> yield "" <TAB> .. versionadded:: %s"" % pyopencl_ver <TAB>  <TAB> yield """"","if ext_name . startswith ( ""CL_"" ) :",174
2960,"def _gen_remote_uri( <TAB> fileobj: IO[bytes], <TAB> remote_uri: Optional[ParseResult], <TAB> remote_path_prefix: Optional[str], <TAB> remote_path_suffix: Optional[str], <TAB> sha256sum: Optional[str],) -> ParseResult: <TAB> if remote_uri is None: <TAB>  <TAB> assert remote_path_prefix is not None and remote_path_suffix is not None <MASK> sha256sum = _hash_fileobj(fileobj) <TAB>  <TAB> return urlparse( <TAB>  <TAB>  <TAB> os.path.join(remote_path_prefix, f""{sha256sum}{remote_path_suffix}"") <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> return remote_uri",if sha256sum is None :,171
2961,"def queries(self): <TAB> if DEV: <TAB>  <TAB> cmd = ShellCommand(""docker"", ""ps"", ""-qf"", ""name=%s"" % self.path.k8s) <TAB>  <TAB> if not cmd.check(f""docker check for {self.path.k8s}""): <MASK> log_cmd = ShellCommand( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""docker"", ""logs"", self.path.k8s, stderr=subprocess.STDOUT <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> if log_cmd.check(f""docker logs for {self.path.k8s}""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> print(cmd.stdout) <TAB>  <TAB>  <TAB>  <TAB> pytest.exit(f""container failed to start for {self.path.k8s}"") <TAB> return ()",if not cmd . stdout . strip ( ) :,188
2962,"def get_range(self): <TAB> present = self.xml.find(""{%s}range"" % self.namespace) <TAB> if present is not None: <TAB>  <TAB> attributes = present.attrib <TAB>  <TAB> return_value = dict() <MASK> return_value[""minimum""] = attributes[""min""] <TAB>  <TAB> if ""max"" in attributes: <TAB>  <TAB>  <TAB> return_value[""maximum""] = attributes[""max""] <TAB>  <TAB> return return_value <TAB> return False","if ""min"" in attributes :",113
2963,"def _configuredOn(self, workerid, builderid=None, masterid=None): <TAB> cfg = [] <TAB> for cs in itervalues(self.configured): <MASK> continue <TAB>  <TAB> bid, mid = self.db.builders.builder_masters[cs[""buildermasterid""]] <TAB>  <TAB> if builderid is not None and bid != builderid: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if masterid is not None and mid != masterid: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> cfg.append({""builderid"": bid, ""masterid"": mid}) <TAB> return cfg","if cs [ ""workerid"" ] != workerid :",143
2964,"def __exit__(self, type, value, traceback): <TAB> try: <TAB>  <TAB> if type is not None: <TAB>  <TAB>  <TAB> return self.exception_handler(type, value, traceback) <TAB> finally: <TAB>  <TAB> final_contexts = _state.contexts <TAB>  <TAB> _state.contexts = self.old_contexts <MASK> raise StackContextInconsistentError( <TAB>  <TAB>  <TAB>  <TAB> ""stack_context inconsistency (may be caused by yield "" <TAB>  <TAB>  <TAB>  <TAB> 'within a ""with StackContext"" block)' <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> # Break up a reference to itself to allow for faster GC on CPython. <TAB>  <TAB> self.new_contexts = None",if final_contexts is not self . new_contexts :,162
2965,"def del_(self, key): <TAB> initial_hash = hash_ = self.hash(key) <TAB> while True: <MASK> # That key was never assigned <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> elif self._keys[hash_] == key: <TAB>  <TAB>  <TAB> # key found, assign with deleted sentinel <TAB>  <TAB>  <TAB> self._keys[hash_] = self._deleted <TAB>  <TAB>  <TAB> self._values[hash_] = self._deleted <TAB>  <TAB>  <TAB> self._len -= 1 <TAB>  <TAB>  <TAB> return <TAB>  <TAB> hash_ = self._rehash(hash_) <TAB>  <TAB> if initial_hash == hash_: <TAB>  <TAB>  <TAB> # table is full and wrapped around <TAB>  <TAB>  <TAB> return None",if self . _keys [ hash_ ] is self . _empty :,166
2966,"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.set_logout_url(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 10 :,92
2967,"def data_generator(): <TAB> i = 0 <TAB> max_batch_index = len(X_train) // batch_size <TAB> tot = 0 <TAB> while 1: <MASK> yield ( <TAB>  <TAB>  <TAB>  <TAB> np.ones([batch_size, input_dim]) * np.nan, <TAB>  <TAB>  <TAB>  <TAB> np.ones([batch_size, num_classes]) * np.nan, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield ( <TAB>  <TAB>  <TAB>  <TAB> X_train[i * batch_size : (i + 1) * batch_size], <TAB>  <TAB>  <TAB>  <TAB> y_train[i * batch_size : (i + 1) * batch_size], <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> i += 1 <TAB>  <TAB> tot += 1 <TAB>  <TAB> i = i % max_batch_index",if tot > 3 * len ( X_train ) :,198
2968,"def title(self): <TAB> ret = theme[""title""] <TAB> if isinstance(self.name, six.string_types): <TAB>  <TAB> width = self.statwidth() <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB> ret + self.name[0:width].center(width).replace("" "", ""-"") + theme[""default""] <TAB>  <TAB> ) <TAB> for i, name in enumerate(self.name): <TAB>  <TAB> width = self.colwidth() <TAB>  <TAB> ret = ret + name[0:width].center(width).replace("" "", ""-"") <MASK> if op.color: <TAB>  <TAB>  <TAB>  <TAB> ret = ret + theme[""frame""] + char[""dash""] + theme[""title""] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> ret = ret + char[""space""] <TAB> return ret",if i + 1 != len ( self . vars ) :,188
2969,"def get_container_from_dport(dport, docker_client): <TAB> for container in docker_client.containers(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> ports = container[""Ports""] <TAB>  <TAB>  <TAB> for port in ports: <MASK> if port[""PublicPort""] == int(dport): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return container <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> print(ports) <TAB>  <TAB>  <TAB> pass","if ""PublicPort"" in port :",112
2970,"def _get_parents_data(self, data): <TAB> parents = 0 <TAB> if data[COLUMN_PARENT]: <TAB>  <TAB> family = self.db.get_family_from_handle(data[COLUMN_PARENT][0]) <TAB>  <TAB> if family.get_father_handle(): <TAB>  <TAB>  <TAB> parents += 1 <MASK> parents += 1 <TAB> return parents",if family . get_mother_handle ( ) :,98
2971,"def wrapper(filename): <TAB> mtime = getmtime(filename) <TAB> with lock: <TAB>  <TAB> if filename in cache: <TAB>  <TAB>  <TAB> old_mtime, result = cache.pop(filename) <TAB>  <TAB>  <TAB> if old_mtime == mtime: <TAB>  <TAB>  <TAB>  <TAB> # Move to the end <TAB>  <TAB>  <TAB>  <TAB> cache[filename] = old_mtime, result <TAB>  <TAB>  <TAB>  <TAB> return result <TAB> result = function(filename) <TAB> with lock: <TAB>  <TAB> cache[filename] = mtime, result  # at the end <MASK> cache.popitem(last=False) <TAB> return result",if len ( cache ) > max_size :,144
2972,"def execute(cls, ctx, op: ""DataFrameGroupByAgg""): <TAB> try: <TAB>  <TAB> pd.set_option(""mode.use_inf_as_na"", op.use_inf_as_na) <TAB>  <TAB> if op.stage == OperandStage.map: <TAB>  <TAB>  <TAB> cls._execute_map(ctx, op) <TAB>  <TAB> elif op.stage == OperandStage.combine: <TAB>  <TAB>  <TAB> cls._execute_combine(ctx, op) <MASK> cls._execute_agg(ctx, op) <TAB>  <TAB> else:  # pragma: no cover <TAB>  <TAB>  <TAB> raise ValueError(""Aggregation operand not executable"") <TAB> finally: <TAB>  <TAB> pd.reset_option(""mode.use_inf_as_na"")",elif op . stage == OperandStage . agg :,171
2973,"def FindAndDelete(script, sig): <TAB> """"""Consensus critical, see FindAndDelete() in Satoshi codebase"""""" <TAB> r = b"""" <TAB> last_sop_idx = sop_idx = 0 <TAB> skip = True <TAB> for (opcode, data, sop_idx) in script.raw_iter(): <TAB>  <TAB> if not skip: <TAB>  <TAB>  <TAB> r += script[last_sop_idx:sop_idx] <TAB>  <TAB> last_sop_idx = sop_idx <MASK> skip = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> skip = False <TAB> if not skip: <TAB>  <TAB> r += script[last_sop_idx:] <TAB> return CScript(r)",if script [ sop_idx : sop_idx + len ( sig ) ] == sig :,187
2974,"def extractall(zip: typing.Any, path: str) -> NoneType: <TAB> for name in zip.namelist(): <TAB>  <TAB> member = zip.getinfo(name) <TAB>  <TAB> extracted_path = zip._extract_member(member, path, None) <TAB>  <TAB> attr = member.external_attr >> 16 <MASK> os.chmod(extracted_path, attr)",if attr != 0 :,93
2975,"def find_all_gyptest_files(directory): <TAB> result = [] <TAB> for root, dirs, files in os.walk(directory): <MASK> dirs.remove("".svn"") <TAB>  <TAB> result.extend([os.path.join(root, f) for f in files if is_test_name(f)]) <TAB> result.sort() <TAB> return result","if "".svn"" in dirs :",94
2976,"def load(cls, storefile, template_store): <TAB> # Did we get file or filename? <TAB> if not hasattr(storefile, ""read""): <TAB>  <TAB> storefile = open(storefile, ""rb"") <TAB> # Adjust store to have translations <TAB> store = cls.convertfile(storefile, template_store) <TAB> for unit in store.units: <TAB>  <TAB> if unit.isheader(): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # HTML does this properly on loading, others need it <MASK> unit.target = unit.source <TAB>  <TAB>  <TAB> unit.rich_target = unit.rich_source <TAB> return store",if cls . needs_target_sync :,152
2977,"def postOptions(self): <TAB> _BasicOptions.postOptions(self) <TAB> if self[""jobs""]: <TAB>  <TAB> conflicts = [""debug"", ""profile"", ""debug-stacktraces"", ""exitfirst""] <TAB>  <TAB> for option in conflicts: <TAB>  <TAB>  <TAB> if self[option]: <TAB>  <TAB>  <TAB>  <TAB> raise usage.UsageError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""You can't specify --%s when using --jobs"" % option <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> if self[""nopm""]: <MASK> raise usage.UsageError(""You must specify --debug when using "" ""--nopm "") <TAB>  <TAB> failure.DO_POST_MORTEM = False","if not self [ ""debug"" ] :",151
2978,"def filterTokenLocation(): <TAB> i = None <TAB> entry = None <TAB> token = None <TAB> tokens = [] <TAB> i = 0 <TAB> while 1: <TAB>  <TAB> if not (i < len(extra.tokens)): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> entry = extra.tokens[i] <TAB>  <TAB> token = jsdict( <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB> ""type"": entry.type, <TAB>  <TAB>  <TAB>  <TAB> ""value"": entry.value, <TAB>  <TAB>  <TAB> } <TAB>  <TAB> ) <TAB>  <TAB> if extra.range: <TAB>  <TAB>  <TAB> token.range = entry.range <MASK> token.loc = entry.loc <TAB>  <TAB> tokens.append(token) <TAB>  <TAB> i += 1 <TAB> extra.tokens = tokens",if extra . loc :,172
2979,"def on_rebalance_end(self) -> None: <TAB> """"""Call when rebalancing is done."""""" <TAB> self.rebalancing = False <TAB> if self._rebalancing_span: <TAB>  <TAB> self._rebalancing_span.finish() <TAB> self._rebalancing_span = None <TAB> sensor_state = self._rebalancing_sensor_state <TAB> try: <MASK> self.log.warning( <TAB>  <TAB>  <TAB>  <TAB> ""Missing sensor state for rebalance #%s"", self.rebalancing_count <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.sensors.on_rebalance_end(self, sensor_state) <TAB> finally: <TAB>  <TAB> self._rebalancing_sensor_state = None",if not sensor_state :,184
2980,"def decorator(request, *args, **kwargs): <TAB> if CALENDAR_VIEW_PERM: <TAB>  <TAB> user = request.user <TAB>  <TAB> if not user: <TAB>  <TAB>  <TAB> return HttpResponseRedirect(settings.LOGIN_URL) <TAB>  <TAB> occurrence, event, calendar = get_objects(request, **kwargs) <TAB>  <TAB> if calendar: <TAB>  <TAB>  <TAB> allowed = CHECK_CALENDAR_PERM_FUNC(calendar, user) <MASK> return HttpResponseRedirect(settings.LOGIN_URL) <TAB>  <TAB>  <TAB> # all checks passed <TAB>  <TAB>  <TAB> return function(request, *args, **kwargs) <TAB>  <TAB> return HttpResponseNotFound(""<h1>Page not found</h1>"") <TAB> return function(request, *args, **kwargs)",if not allowed :,170
2981,"def reduce_arguments(self, args): <TAB> assert isinstance(args, nodes.Arguments) <TAB> if args.incorrect_order(): <TAB>  <TAB> raise InvalidArguments( <TAB>  <TAB>  <TAB> ""All keyword arguments must be after positional arguments."" <TAB>  <TAB> ) <TAB> reduced_pos = [self.reduce_single(arg) for arg in args.arguments] <TAB> reduced_kw = {} <TAB> for key in args.kwargs.keys(): <MASK> raise InvalidArguments(""Keyword argument name is not a string."") <TAB>  <TAB> a = args.kwargs[key] <TAB>  <TAB> reduced_kw[key] = self.reduce_single(a) <TAB> return (reduced_pos, reduced_kw)","if not isinstance ( key , str ) :",163
2982,"def _encode(n, nbytes, little_endian=False): <TAB> retval = [] <TAB> n = long(n) <TAB> for i in range(nbytes): <MASK> retval.append(chr(n & 0xFF)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> retval.insert(0, chr(n & 0xFF)) <TAB>  <TAB> n >>= 8 <TAB> return """".join(retval)",if little_endian :,96
2983,"def copy_shell(self): <TAB> cls = self.__class__ <TAB> old_id = cls.id <TAB> new_i = cls()  # create a new group <TAB> new_i.id = self.id  # with the same id <TAB> cls.id = old_id  # Reset the Class counter <TAB> # Copy all properties <TAB> for prop in cls.properties: <TAB>  <TAB> if prop is not ""members"": <MASK> val = getattr(self, prop) <TAB>  <TAB>  <TAB>  <TAB> setattr(new_i, prop, val) <TAB> # but no members <TAB> new_i.members = [] <TAB> return new_i",if self . has ( prop ) :,156
2984,"def dataspec(config): <TAB> master = yield fakemaster.make_master() <TAB> data = connector.DataConnector() <TAB> data.setServiceParent(master) <TAB> if config[""out""] != ""--"": <TAB>  <TAB> dirs = os.path.dirname(config[""out""]) <MASK> os.makedirs(dirs) <TAB>  <TAB> f = open(config[""out""], ""w"") <TAB> else: <TAB>  <TAB> f = sys.stdout <TAB> if config[""global""] is not None: <TAB>  <TAB> f.write(""window."" + config[""global""] + ""="") <TAB> f.write(json.dumps(data.allEndpoints(), indent=2)) <TAB> f.close() <TAB> defer.returnValue(0)",if dirs and not os . path . exists ( dirs ) :,176
2985,"def _parseSCDOCDC(self, src): <TAB> """"""[S|CDO|CDC]*"""""" <TAB> while 1: <TAB>  <TAB> src = src.lstrip() <MASK> src = src[4:] <TAB>  <TAB> elif src.startswith(""-->""): <TAB>  <TAB>  <TAB> src = src[3:] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> return src","if src . startswith ( ""<!--"" ) :",92
2986,"def command(filenames, dirnames, fix): <TAB> for filename in gather_files(dirnames, filenames): <TAB>  <TAB> visitor = process_file(filename) <TAB>  <TAB> if visitor.needs_fix(): <TAB>  <TAB>  <TAB> print(""%s: %s"" % (filename, visitor.get_stats())) <MASK> print(""Fixing: %s"" % filename) <TAB>  <TAB>  <TAB>  <TAB> fix_file(filename)",if fix :,100
2987,"def shutdown(self): <TAB> """"""Shutdown host system."""""" <TAB> self._check_dbus(MANAGER) <TAB> use_logind = self.sys_dbus.logind.is_connected <TAB> _LOGGER.info(""Initialize host power off %s"", ""logind"" if use_logind else ""systemd"") <TAB> try: <TAB>  <TAB> await self.sys_core.shutdown() <TAB> finally: <MASK> await self.sys_dbus.logind.power_off() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> await self.sys_dbus.systemd.power_off()",if use_logind :,140
2988,"def _run_split_on_punc(self, text, never_split=None): <TAB> """"""Splits punctuation on a piece of text."""""" <TAB> if never_split is not None and text in never_split: <TAB>  <TAB> return [text] <TAB> chars = list(text) <TAB> i = 0 <TAB> start_new_word = True <TAB> output = [] <TAB> while i < len(chars): <TAB>  <TAB> char = chars[i] <TAB>  <TAB> if _is_punctuation(char): <TAB>  <TAB>  <TAB> output.append([char]) <TAB>  <TAB>  <TAB> start_new_word = True <TAB>  <TAB> else: <MASK> output.append([]) <TAB>  <TAB>  <TAB> start_new_word = False <TAB>  <TAB>  <TAB> output[-1].append(char) <TAB>  <TAB> i += 1 <TAB> return ["""".join(x) for x in output]",if start_new_word :,199
2989,"def _terminal_messenger(tp=""write"", msg="""", out=sys.stdout): <TAB> try: <TAB>  <TAB> if tp == ""write"": <TAB>  <TAB>  <TAB> out.write(msg) <MASK> out.flush() <TAB>  <TAB> elif tp == ""write_flush"": <TAB>  <TAB>  <TAB> out.write(msg) <TAB>  <TAB>  <TAB> out.flush() <TAB>  <TAB> elif tp == ""print"": <TAB>  <TAB>  <TAB> print(msg, file=out) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""Unsupported type: "" + tp) <TAB> except IOError as e: <TAB>  <TAB> logger.critical(""{}: {}"".format(type(e).__name__, ucd(e))) <TAB>  <TAB> pass","elif tp == ""flush"" :",160
2990,"def checkClassDeclation(file): <TAB> localResult = [] <TAB> with open(file, ""rb"") as f: <TAB>  <TAB> lineNumber = 0 <TAB>  <TAB> for line in f: <TAB>  <TAB>  <TAB> m = re.search(""class\s+[^\(]*:"", line) <MASK> localResult.append( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Old class definition found on {0}"".format(m.group()) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return localResult",if m :,112
2991,"def _evaluate_local_single(self, iterator): <TAB> for batch in iterator: <TAB>  <TAB> in_arrays = convert._call_converter(self.converter, batch, self.device) <TAB>  <TAB> with function.no_backprop_mode(): <TAB>  <TAB>  <TAB> if isinstance(in_arrays, tuple): <TAB>  <TAB>  <TAB>  <TAB> results = self.calc_local(*in_arrays) <MASK> results = self.calc_local(**in_arrays) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> results = self.calc_local(in_arrays) <TAB>  <TAB> if self._progress_hook: <TAB>  <TAB>  <TAB> self._progress_hook(batch) <TAB>  <TAB> yield results","elif isinstance ( in_arrays , dict ) :",166
2992,"def check_billing_view(user, permission, obj): <TAB> if hasattr(obj, ""all_projects""): <MASK> return True <TAB>  <TAB> # This is a billing object <TAB>  <TAB> return any(check_permission(user, permission, prj) for prj in obj.all_projects) <TAB> return check_permission(user, permission, obj)",if user . is_superuser or obj . owners . filter ( pk = user . pk ) . exists ( ) :,106
2993,"def ensure_output_spaces_contain_the_same_data(self, y, y_ensured): <TAB> stride = y.shape[1] <TAB> self.assertEqual(y.shape[0] * y.shape[1], y_ensured.shape[0]) <TAB> self.assertEqual(len(y_ensured.shape), 1) <TAB> for row in range(y.shape[0]): <TAB>  <TAB> for column in range(y.shape[1]): <MASK> self.assertEqual(y[row, column], y_ensured[row * stride + column]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(y[row][column], y_ensured[row * stride + column])",if sp . issparse ( y ) :,176
2994,"def train( <TAB> self, <TAB> training_data: TrainingData, <TAB> config: Optional[RasaNLUModelConfig] = None, <TAB> **kwargs: Any,) -> None: <TAB> """"""Tokenize all training data."""""" <TAB> for example in training_data.training_examples: <TAB>  <TAB> for attribute in MESSAGE_ATTRIBUTES: <TAB>  <TAB>  <TAB> if example.get(attribute) is not None and not example.get(attribute) == """": <MASK> tokens = self._split_name(example, attribute) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> tokens = self.tokenize(example, attribute) <TAB>  <TAB>  <TAB>  <TAB> example.set(TOKENS_NAMES[attribute], tokens)","if attribute in [ INTENT , ACTION_NAME , INTENT_RESPONSE_KEY ] :",183
2995,"def refresh_token(self, strategy, *args, **kwargs): <TAB> token = self.extra_data.get(""refresh_token"") or self.extra_data.get(""access_token"") <TAB> backend = self.get_backend(strategy) <TAB> if token and backend and hasattr(backend, ""refresh_token""): <TAB>  <TAB> backend = backend(strategy=strategy) <TAB>  <TAB> response = backend.refresh_token(token, *args, **kwargs) <TAB>  <TAB> extra_data = backend.extra_data(self, self.uid, response, self.extra_data) <MASK> self.save()",if self . set_extra_data ( extra_data ) :,154
2996,"def _verify_environ(_collected_environ): <TAB> try: <TAB>  <TAB> yield <TAB> finally: <TAB>  <TAB> new_environ = dict(os.environ) <TAB>  <TAB> current_test = new_environ.pop(""PYTEST_CURRENT_TEST"", None) <TAB>  <TAB> old_environ = dict(_collected_environ) <TAB>  <TAB> old_environ.pop(""PYTEST_CURRENT_TEST"", None) <MASK> raise DirtyTest( <TAB>  <TAB>  <TAB>  <TAB> ""Left over environment variables"", <TAB>  <TAB>  <TAB>  <TAB> current_test, <TAB>  <TAB>  <TAB>  <TAB> _compare_eq_dict(new_environ, old_environ, verbose=2), <TAB>  <TAB>  <TAB> )",if new_environ != old_environ :,157
2997,"def clean_len(self, line): <TAB> """"""Calculate wisible length of string"""""" <TAB> if isinstance(line, basestring): <TAB>  <TAB> return len(self.screen.markup.clean_markup(line)) <TAB> elif isinstance(line, tuple) or isinstance(line, list): <TAB>  <TAB> markups = self.screen.markup.get_markup_vars() <TAB>  <TAB> length = 0 <TAB>  <TAB> for i in line: <MASK> length += len(i) <TAB>  <TAB> return length",if i not in markups :,123
2998,"def _build_merged_dataset_args(datasets): <TAB> merged_dataset_args = [] <TAB> for dataset in datasets: <TAB>  <TAB> dataset_code_column = _parse_dataset_code(dataset) <TAB>  <TAB> arg = dataset_code_column[""code""] <TAB>  <TAB> column_index = dataset_code_column[""column_index""] <MASK> arg = (dataset_code_column[""code""], {""column_index"": [column_index]}) <TAB>  <TAB> merged_dataset_args.append(arg) <TAB> return merged_dataset_args",if column_index is not None :,134
2999,"def update_watch_data_table_paths(self): <TAB> if hasattr(self.tool_data_watcher, ""monitored_dirs""): <TAB>  <TAB> for tool_data_table_path in self.tool_data_paths: <MASK> self.tool_data_watcher.watch_directory(tool_data_table_path)",if tool_data_table_path not in self . tool_data_watcher . monitored_dirs :,107
3000,"def getsource(obj): <TAB> """"""Wrapper around inspect.getsource"""""" <TAB> try: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> src = encoding.to_unicode(inspect.getsource(obj)) <TAB>  <TAB> except TypeError: <MASK> src = encoding.to_unicode(inspect.getsource(obj.__class__)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> # Bindings like VTK or ITK require this case <TAB>  <TAB>  <TAB>  <TAB> src = getdoc(obj) <TAB>  <TAB> return src <TAB> except (TypeError, IOError): <TAB>  <TAB> return","if hasattr ( obj , ""__class__"" ) :",134
3001,"def __iter__(self): <TAB> for model in self.app_config.get_models(): <TAB>  <TAB> admin_model = AdminModel(model, **self.options) <TAB>  <TAB> for model_re in self.model_res: <TAB>  <TAB>  <TAB> if model_re.search(admin_model.name): <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <MASK> continue <TAB>  <TAB> yield admin_model",if self . model_res :,105
3002,"def run(self): <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> with DelayedKeyboardInterrupt(): <TAB>  <TAB>  <TAB>  <TAB> raw_inputs = self._parent_task_queue.get() <TAB>  <TAB>  <TAB>  <TAB> if self._has_stop_signal(raw_inputs): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._rq.put(raw_inputs, block=True) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB>  <TAB> if self._flow_type == BATCH: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._rq.put(raw_inputs, block=True) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._rq.put(raw_inputs, block=False) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> except KeyboardInterrupt: <TAB>  <TAB>  <TAB> continue",elif self . _flow_type == REALTIME :,199
3003,"def dump(self): <TAB> self.ql.log.info(""[*] Dumping object: %s"" % (self.sf_name)) <TAB> for field in self._fields_: <MASK> self.ql.log.info(""%s: 0x%x"" % (field[0], getattr(self, field[0]).value)) <TAB>  <TAB> elif isinstance(getattr(self, field[0]), int): <TAB>  <TAB>  <TAB> self.ql.log.info(""%s: %d"" % (field[0], getattr(self, field[0]))) <TAB>  <TAB> elif isinstance(getattr(self, field[0]), bytes): <TAB>  <TAB>  <TAB> self.ql.log.info(""%s: %s"" % (field[0], getattr(self, field[0]).decode()))","if isinstance ( getattr ( self , field [ 0 ] ) , POINTER64 ) :",188
3004,"def validate_configuration(self, configuration: Optional[ExpectationConfiguration]): <TAB> """"""Validating that user has inputted a value set and that configuration has been initialized"""""" <TAB> super().validate_configuration(configuration) <TAB> try: <TAB>  <TAB> assert ""value_set"" in configuration.kwargs, ""value_set is required"" <TAB>  <TAB> assert isinstance( <TAB>  <TAB>  <TAB> configuration.kwargs[""value_set""], (list, set, dict) <TAB>  <TAB> ), ""value_set must be a list or a set"" <MASK> assert ( <TAB>  <TAB>  <TAB>  <TAB> ""$PARAMETER"" in configuration.kwargs[""value_set""] <TAB>  <TAB>  <TAB> ), 'Evaluation Parameter dict for value_set kwarg must have ""$PARAMETER"" key' <TAB> except AssertionError as e: <TAB>  <TAB> raise InvalidExpectationConfigurationError(str(e)) <TAB> return True","if isinstance ( configuration . kwargs [ ""value_set"" ] , dict ) :",196
3005,def test_one_dead_branch(): <TAB> with deterministic_PRNG(): <TAB>  <TAB> seen = set() <TAB>  <TAB> @run_to_buffer <TAB>  <TAB> def x(data): <TAB>  <TAB>  <TAB> i = data.draw_bytes(1)[0] <TAB>  <TAB>  <TAB> if i > 0: <TAB>  <TAB>  <TAB>  <TAB> data.mark_invalid() <TAB>  <TAB>  <TAB> i = data.draw_bytes(1)[0] <TAB>  <TAB>  <TAB> if len(seen) < 255: <TAB>  <TAB>  <TAB>  <TAB> seen.add(i) <MASK> data.mark_interesting(),elif i not in seen :,138
3006,"def __on_item_activated(self, event): <TAB> if self.__module_view: <TAB>  <TAB> module = self.get_event_module(event) <TAB>  <TAB> self.__module_view.set_selection(module.module_num) <TAB>  <TAB> if event.EventObject is self.list_ctrl: <TAB>  <TAB>  <TAB> self.input_list_ctrl.deactivate_active_item() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.list_ctrl.deactivate_active_item() <TAB>  <TAB>  <TAB> for index in range(self.list_ctrl.GetItemCount()): <MASK> self.list_ctrl.Select(index, False) <TAB> self.__controller.enable_module_controls_panel_buttons()",if self . list_ctrl . IsSelected ( index ) :,181
3007,"def prime(self, callback): <MASK> # import pdb <TAB>  <TAB> # pdb.set_trace() <TAB>  <TAB> self.cbhdl = simulator.register_rwsynch_callback(callback, self) <TAB>  <TAB> if self.cbhdl is None: <TAB>  <TAB>  <TAB> raise_error(self, ""Unable set up %s Trigger"" % (str(self))) <TAB> Trigger.prime(self)",if self . cbhdl is None :,102
3008,"def fstab_configuration(middleware): <TAB> for command in ( <TAB>  <TAB> [ <TAB>  <TAB>  <TAB> [""systemctl"", ""daemon-reload""], <TAB>  <TAB>  <TAB> [""systemctl"", ""restart"", ""local-fs.target""], <TAB>  <TAB> ] <TAB>  <TAB> if osc.IS_LINUX <TAB>  <TAB> else [[""mount"", ""-uw"", ""/""]] <TAB> ): <TAB>  <TAB> ret = subprocess.run(command, capture_output=True) <MASK> middleware.logger.debug( <TAB>  <TAB>  <TAB>  <TAB> f'Failed to execute ""{"" "".join(command)}"": {ret.stderr.decode()}' <TAB>  <TAB>  <TAB> )",if ret . returncode :,148
3009,"def _generate_table(self, fromdesc, todesc, diffs): <TAB> if fromdesc or todesc: <TAB>  <TAB> yield ( <TAB>  <TAB>  <TAB> simple_colorize(fromdesc, ""description""), <TAB>  <TAB>  <TAB> simple_colorize(todesc, ""description""), <TAB>  <TAB> ) <TAB> for i, line in enumerate(diffs): <MASK> # mdiff yields None on separator lines; skip the bogus ones <TAB>  <TAB>  <TAB> # generated for the first line <TAB>  <TAB>  <TAB> if i > 0: <TAB>  <TAB>  <TAB>  <TAB> yield ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> simple_colorize(""---"", ""separator""), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> simple_colorize(""---"", ""separator""), <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield line",if line is None :,170
3010,"def update_completion(self): <TAB> """"""Update completion model with exist tags"""""" <TAB> orig_text = self.widget.text() <TAB> text = "", "".join(orig_text.replace("", "", "","").split("","")[:-1]) <TAB> tags = [] <TAB> for tag in self.tags_list: <TAB>  <TAB> if "","" in orig_text: <MASK> tags.append(""%s,%s"" % (text, tag)) <TAB>  <TAB>  <TAB> tags.append(""%s, %s"" % (text, tag)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tags.append(tag) <TAB> if tags != self.completer_model.stringList(): <TAB>  <TAB> self.completer_model.setStringList(tags)","if orig_text [ - 1 ] not in ( "","" , "" "" ) :",177
3011,"def cart_number_checksum_validation(cls, number): <TAB> digits = [] <TAB> even = False <TAB> if not number.isdigit(): <TAB>  <TAB> return False <TAB> for digit in reversed(number): <TAB>  <TAB> digit = ord(digit) - ord(""0"") <MASK> digit *= 2 <TAB>  <TAB>  <TAB> if digit >= 10: <TAB>  <TAB>  <TAB>  <TAB> digit = digit % 10 + digit // 10 <TAB>  <TAB> digits.append(digit) <TAB>  <TAB> even = not even <TAB> return sum(digits) % 10 == 0 if digits else False",if even :,127
3012,"def __get_param_string__(params): <TAB> params_string = [] <TAB> for key in sorted(params.keys()): <MASK> return <TAB>  <TAB> value = params[key] <TAB>  <TAB> params_string.append("""" if value == ""null"" else str(value)) <TAB> return ""|"".join(params_string)","if ""REFUND"" in params [ key ] or ""|"" in params [ key ] :",93
3013,"def _map_handlers(self, session, event_class, mapfn): <TAB> for event in DOC_EVENTS: <TAB>  <TAB> event_handler_name = event.replace(""-"", ""_"") <MASK> event_handler = getattr(self, event_handler_name) <TAB>  <TAB>  <TAB> format_string = DOC_EVENTS[event] <TAB>  <TAB>  <TAB> num_args = len(format_string.split(""."")) - 2 <TAB>  <TAB>  <TAB> format_args = (event_class,) + (""*"",) * num_args <TAB>  <TAB>  <TAB> event_string = event + format_string % format_args <TAB>  <TAB>  <TAB> unique_id = event_class + event_handler_name <TAB>  <TAB>  <TAB> mapfn(event_string, event_handler, unique_id)","if hasattr ( self , event_handler_name ) :",180
3014,"def _create_param_lr(self, param_and_grad): <TAB> # create learning rate variable for every parameter <TAB> param = param_and_grad[0] <TAB> param_lr = param.optimize_attr[""learning_rate""] <TAB> if type(param_lr) == Variable: <TAB>  <TAB> return param_lr <TAB> else: <MASK> return self._global_learning_rate() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> with default_main_program()._lr_schedule_guard( <TAB>  <TAB>  <TAB>  <TAB> is_with_opt=True <TAB>  <TAB>  <TAB> ), framework.name_scope(""scale_with_param_lr""): <TAB>  <TAB>  <TAB>  <TAB> return self._global_learning_rate() * param_lr",if param_lr == 1.0 :,174
3015,"def __getitem__(self, key): <TAB> try: <TAB>  <TAB> return self._clsmap[key] <TAB> except KeyError as e: <MASK> self._mutex.acquire() <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> if not self.initialized: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._init() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.initialized = True <TAB>  <TAB>  <TAB>  <TAB> return self._clsmap[key] <TAB>  <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB>  <TAB> self._mutex.release() <TAB>  <TAB> raise e",if not self . initialized :,125
3016,"def save(self, force=False): <TAB> if not force: <MASK> return <TAB>  <TAB> if time.time() - self.last_save_time < 10: <TAB>  <TAB>  <TAB> return <TAB> with self.lock: <TAB>  <TAB> with open(self.file_path, ""w"") as fd: <TAB>  <TAB>  <TAB> for ip in self.cache: <TAB>  <TAB>  <TAB>  <TAB> record = self.cache[ip] <TAB>  <TAB>  <TAB>  <TAB> rule = record[""r""] <TAB>  <TAB>  <TAB>  <TAB> connect_time = record[""c""] <TAB>  <TAB>  <TAB>  <TAB> update_time = record[""update""] <TAB>  <TAB>  <TAB>  <TAB> fd.write(""%s %s %d %d\n"" % (ip, rule, connect_time, update_time)) <TAB> self.last_save_time = time.time() <TAB> self.need_save = False",if not self . need_save :,198
3017,"def pick(items, sel): <TAB> for x, s in zip(items, sel): <MASK> yield x <TAB>  <TAB> elif not x.is_atom() and not s.is_atom(): <TAB>  <TAB>  <TAB> yield x.restructure(x.head, pick(x.leaves, s.leaves), evaluation)",if match ( s ) :,79
3018,"def isValidFloat(config_param_name, value, constraints): <TAB> if isinstance(value, float): <TAB>  <TAB> constraints.setdefault(""min"", MIN_VALID_FLOAT_VALUE) <TAB>  <TAB> constraints.setdefault(""max"", MAX_VALID_FLOAT_VALUE) <TAB>  <TAB> minv = float(constraints.get(""min"")) <TAB>  <TAB> maxv = float(constraints.get(""max"")) <MASK> if value <= maxv: <TAB>  <TAB>  <TAB>  <TAB> return value <TAB> raise FloatValueError(config_param_name, value, constraints)",if value >= minv :,125
3019,"def get_files(d): <TAB> f = [] <TAB> for root, dirs, files in os.walk(d): <TAB>  <TAB> for name in files: <TAB>  <TAB>  <TAB> if ""meta-environment"" in root or ""cross-canadian"" in root: <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB>  <TAB> if ""do_build"" not in name and ""do_populate_sdk"" not in name: <TAB>  <TAB>  <TAB>  <TAB> f.append(os.path.join(root, name)) <TAB> return f","if ""qemux86copy-"" in root or ""qemux86-"" in root :",143
3020,"def __get_photo(self, person_or_marriage): <TAB> """"""returns the first photo in the media list or None"""""" <TAB> media_list = person_or_marriage.get_media_list() <TAB> for media_ref in media_list: <TAB>  <TAB> media_handle = media_ref.get_reference_handle() <TAB>  <TAB> media = self.database.get_media_from_handle(media_handle) <TAB>  <TAB> mime_type = media.get_mime_type() <MASK> return media <TAB> return None","if mime_type and mime_type . startswith ( ""image"" ) :",140
3021,"def filter(this, args): <TAB> array = to_object(this, args.space) <TAB> callbackfn = get_arg(args, 0) <TAB> arr_len = js_arr_length(array) <TAB> if not is_callable(callbackfn): <TAB>  <TAB> raise MakeError(""TypeError"", ""callbackfn must be a function"") <TAB> _this = get_arg(args, 1) <TAB> k = 0 <TAB> res = [] <TAB> while k < arr_len: <TAB>  <TAB> if array.has_property(unicode(k)): <TAB>  <TAB>  <TAB> kValue = array.get(unicode(k)) <MASK> res.append(kValue) <TAB>  <TAB> k += 1 <TAB> return args.space.ConstructArray(res)","if to_boolean ( callbackfn . call ( _this , ( kValue , float ( k ) , array ) ) ) :",194
3022,"def optimize(self, graph: Graph): <TAB> for v in graph.inputs: <TAB>  <TAB> if not v.has_attribute(SplitTarget): <TAB>  <TAB>  <TAB> continue <MASK> DumpGraph().optimize(graph) <TAB>  <TAB> raise NotImplementedError( <TAB>  <TAB>  <TAB> f""Input Variable {v} is too large to handle in WebGL backend"" <TAB>  <TAB> ) <TAB> return graph, False",if flags . DEBUG :,94
3023,"def detach_volume(self, volume): <TAB> # We need to find the node using this volume <TAB> for node in self.list_nodes(): <TAB>  <TAB> if type(node.image) is not list: <TAB>  <TAB>  <TAB> # This node has only one associated image. It is not the one we <TAB>  <TAB>  <TAB> # are after. <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for disk in node.image: <MASK> # Node found. We can now detach the volume <TAB>  <TAB>  <TAB>  <TAB> disk_id = disk.extra[""disk_id""] <TAB>  <TAB>  <TAB>  <TAB> return self._do_detach_volume(node.id, disk_id) <TAB> return False",if disk . id == volume . id :,160
3024,"def Yield(value, level=1): <TAB> g = greenlet.getcurrent() <TAB> while level != 0: <TAB>  <TAB> if not isinstance(g, genlet): <TAB>  <TAB>  <TAB> raise RuntimeError(""yield outside a genlet"") <MASK> g.parent.set_child(g) <TAB>  <TAB> g = g.parent <TAB>  <TAB> level -= 1 <TAB> g.switch(value)",if level > 1 :,96
3025,"def get_all_pipeline_nodes( <TAB> pipeline: pipeline_pb2.Pipeline,) -> List[pipeline_pb2.PipelineNode]: <TAB> """"""Returns all pipeline nodes in the given pipeline."""""" <TAB> result = [] <TAB> for pipeline_or_node in pipeline.nodes: <TAB>  <TAB> which = pipeline_or_node.WhichOneof(""node"") <TAB>  <TAB> # TODO(goutham): Handle sub-pipelines. <TAB>  <TAB> # TODO(goutham): Handle system nodes. <MASK> result.append(pipeline_or_node.pipeline_node) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise NotImplementedError(""Only pipeline nodes supported."") <TAB> return result","if which == ""pipeline_node"" :",160
3026,"def __init__(self, **settings): <TAB> default_settings = self.get_default_settings() <TAB> for name, value in default_settings.items(): <TAB>  <TAB> if not hasattr(self, name): <TAB>  <TAB>  <TAB> setattr(self, name, value) <TAB> for name, value in settings.items(): <MASK> raise ImproperlyConfigured( <TAB>  <TAB>  <TAB>  <TAB> ""Invalid setting '{}' for {}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> name, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.__class__.__name__, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> setattr(self, name, value)",if name not in default_settings :,144
3027,"def _check_choice(self): <TAB> if self.type == ""choice"": <MASK> raise OptionError(""must supply a list of choices for type 'choice'"", self) <TAB>  <TAB> elif type(self.choices) not in (types.TupleType, types.ListType): <TAB>  <TAB>  <TAB> raise OptionError( <TAB>  <TAB>  <TAB>  <TAB> ""choices must be a list of strings ('%s' supplied)"" <TAB>  <TAB>  <TAB>  <TAB> % str(type(self.choices)).split(""'"")[1], <TAB>  <TAB>  <TAB>  <TAB> self, <TAB>  <TAB>  <TAB> ) <TAB> elif self.choices is not None: <TAB>  <TAB> raise OptionError(""must not supply choices for type %r"" % self.type, self)",if self . choices is None :,162
3028,"def prepare(self, size=None): <TAB> if _is_seekable(self.file): <TAB>  <TAB> start_pos = self.file.tell() <TAB>  <TAB> self.file.seek(0, 2) <TAB>  <TAB> end_pos = self.file.tell() <TAB>  <TAB> self.file.seek(start_pos) <TAB>  <TAB> fsize = end_pos - start_pos <MASK> self.remain = fsize <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.remain = min(fsize, size) <TAB> return self.remain",if size is None :,128
3029,"def _setSitemapTargets(): <TAB> if not conf.sitemapUrl: <TAB>  <TAB> return <TAB> infoMsg = ""parsing sitemap '%s'"" % conf.sitemapUrl <TAB> logger.info(infoMsg) <TAB> found = False <TAB> for item in parseSitemap(conf.sitemapUrl): <MASK> found = True <TAB>  <TAB>  <TAB> kb.targets.add((item.strip(), None, None, None, None)) <TAB> if not found and not conf.forms and not conf.crawlDepth: <TAB>  <TAB> warnMsg = ""no usable links found (with GET parameters)"" <TAB>  <TAB> logger.warn(warnMsg)","if re . match ( r""[^ ]+\?(.+)"" , item , re . I ) :",159
3030,"def test_CY_decomposition(self, tol): <TAB> """"""Tests that the decomposition of the CY gate is correct"""""" <TAB> op = qml.CY(wires=[0, 1]) <TAB> res = op.decomposition(op.wires) <TAB> mats = [] <TAB> for i in reversed(res): <MASK> mats.append(np.kron(i.matrix, np.eye(2))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> mats.append(i.matrix) <TAB> decomposed_matrix = np.linalg.multi_dot(mats) <TAB> assert np.allclose(decomposed_matrix, op.matrix, atol=tol, rtol=0)",if len ( i . wires ) == 1 :,169
3031,"def _line_ranges(statements, lines): <TAB> """"""Produce a list of ranges for `format_lines`."""""" <TAB> statements = sorted(statements) <TAB> lines = sorted(lines) <TAB> pairs = [] <TAB> start = None <TAB> lidx = 0 <TAB> for stmt in statements: <TAB>  <TAB> if lidx >= len(lines): <TAB>  <TAB>  <TAB> break <MASK> lidx += 1 <TAB>  <TAB>  <TAB> if not start: <TAB>  <TAB>  <TAB>  <TAB> start = stmt <TAB>  <TAB>  <TAB> end = stmt <TAB>  <TAB> elif start: <TAB>  <TAB>  <TAB> pairs.append((start, end)) <TAB>  <TAB>  <TAB> start = None <TAB> if start: <TAB>  <TAB> pairs.append((start, end)) <TAB> return pairs",if stmt == lines [ lidx ] :,167
3032,"def init_params(net): <TAB> """"""Init layer parameters."""""" <TAB> for module in net.modules(): <TAB>  <TAB> if isinstance(module, nn.Conv2d): <TAB>  <TAB>  <TAB> init.kaiming_normal(module.weight, mode=""fan_out"") <MASK> init.constant(module.bias, 0) <TAB>  <TAB> elif isinstance(module, nn.BatchNorm2d): <TAB>  <TAB>  <TAB> init.constant(module.weight, 1) <TAB>  <TAB>  <TAB> init.constant(module.bias, 0) <TAB>  <TAB> elif isinstance(module, nn.Linear): <TAB>  <TAB>  <TAB> init.normal(module.weight, std=1e-3) <TAB>  <TAB>  <TAB> if module.bias: <TAB>  <TAB>  <TAB>  <TAB> init.constant(module.bias, 0)",if module . bias :,180
3033,"def _get_directory_size_in_bytes(directory): <TAB> total = 0 <TAB> try: <TAB>  <TAB> for entry in os.scandir(directory): <MASK> # if it's a file, use stat() function <TAB>  <TAB>  <TAB>  <TAB> total += entry.stat().st_size <TAB>  <TAB>  <TAB> elif entry.is_dir(): <TAB>  <TAB>  <TAB>  <TAB> # if it's a directory, recursively call this function <TAB>  <TAB>  <TAB>  <TAB> total += _get_directory_size_in_bytes(entry.path) <TAB> except NotADirectoryError: <TAB>  <TAB> # if `directory` isn't a directory, get the file size then <TAB>  <TAB> return os.path.getsize(directory) <TAB> except PermissionError: <TAB>  <TAB> # if for whatever reason we can't open the folder, return 0 <TAB>  <TAB> return 0 <TAB> return total",if entry . is_file ( ) :,193
3034,"def run_cmd(self, util, to, always_push_mark=False): <TAB> if to == ""bof"": <TAB>  <TAB> util.push_mark_and_goto_position(0) <TAB> elif to == ""eof"": <TAB>  <TAB> util.push_mark_and_goto_position(self.view.size()) <TAB> elif to in (""eow"", ""bow""): <TAB>  <TAB> visible = self.view.visible_region() <TAB>  <TAB> pos = visible.a if to == ""bow"" else visible.b <MASK> util.push_mark_and_goto_position(pos) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> util.set_cursors([sublime.Region(pos)])",if always_push_mark :,170
3035,"def parse_results(cwd): <TAB> optimal_dd = None <TAB> optimal_measure = numpy.inf <TAB> for tup in tools.find_conf_files(cwd): <TAB>  <TAB> dd = tup[1] <TAB>  <TAB> if ""results.train_y_misclass"" in dd: <TAB>  <TAB>  <TAB> if dd[""results.train_y_misclass""] < optimal_measure: <TAB>  <TAB>  <TAB>  <TAB> optimal_measure = dd[""results.train_y_misclass""] <TAB>  <TAB>  <TAB>  <TAB> optimal_dd = dd <TAB> print(""Optimal results.train_y_misclass:"", str(optimal_measure)) <TAB> for key, value in optimal_dd.items(): <MASK> print(key + "": "" + str(value))","if ""hyper_parameters"" in key :",177
3036,"def clean_vc_position(self): <TAB> vc_position = self.cleaned_data[""vc_position""] <TAB> if self.validate_vc_position: <TAB>  <TAB> conflicting_members = Device.objects.filter( <TAB>  <TAB>  <TAB> virtual_chassis=self.instance.virtual_chassis, vc_position=vc_position <TAB>  <TAB> ) <MASK> raise forms.ValidationError( <TAB>  <TAB>  <TAB>  <TAB> ""A virtual chassis member already exists in position {}."".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> vc_position <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> return vc_position",if conflicting_members . exists ( ) :,148
3037,"def cal_pads(auto_pad, pad_shape): <TAB> spatial_size = len(pad_shape) <TAB> pads = [0] * spatial_size * 2 <TAB> for i in range(spatial_size): <TAB>  <TAB> if auto_pad == ""SAME_LOWER"": <TAB>  <TAB>  <TAB> pads[i + spatial_size] = pad_shape[i] // 2 <TAB>  <TAB>  <TAB> pads[i] = pad_shape[i] - pads[i + spatial_size] <MASK> pads[i] = pad_shape[i] // 2 <TAB>  <TAB>  <TAB> pads[i + spatial_size] = pad_shape[i] - pads[i] <TAB> return pads","elif auto_pad == ""SAME_UPPER"" :",173
3038,"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> length = d.getVarInt32() <TAB>  <TAB>  <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB>  <TAB>  <TAB> d.skip(length) <TAB>  <TAB>  <TAB> self.add_presence_response().TryMerge(tmp) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 10 :,140
3039,"def test_cwl_rnaseq(self, install_test_files): <TAB> with install_cwl_test_files() as work_dir: <TAB>  <TAB> with utils.chdir(os.path.join(work_dir, ""rnaseq"")): <MASK> shutil.rmtree(""cromwell_work"") <TAB>  <TAB>  <TAB> subprocess.check_call( <TAB>  <TAB>  <TAB>  <TAB> [""bcbio_vm.py"", ""cwlrun"", ""cromwell"", ""rnaseq-workflow""] <TAB>  <TAB>  <TAB> )","if os . path . exists ( ""cromwell_work"" ) :",139
3040,"def files_per_version(self): <TAB> xpath = ""./files/file"" <TAB> files = self.root.findall(xpath) <TAB> versions = {} <TAB> for file in files: <TAB>  <TAB> vfile = file.findall(""version"") <TAB>  <TAB> for version in vfile: <TAB>  <TAB>  <TAB> nb = version.attrib[""nb""] <MASK> versions[nb] = [] <TAB>  <TAB>  <TAB> versions[nb].append(file.attrib[""url""]) <TAB> return versions",if not nb in versions :,117
3041,"def value_to_db_datetime(self, value): <TAB> if value is None: <TAB>  <TAB> return None <TAB> # SQLite doesn't support tz-aware datetimes <TAB> if timezone.is_aware(value): <MASK> value = value.astimezone(timezone.utc).replace(tzinfo=None) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""SQLite backend does not support timezone-aware datetimes when USE_TZ is False."" <TAB>  <TAB>  <TAB> ) <TAB> return six.text_type(value)",if settings . USE_TZ :,131
3042,"def _toplevelTryFunc(func, *args, status=status, **kwargs): <TAB> with ThreadProfiler(threading.current_thread()) as prof: <TAB>  <TAB> t = threading.current_thread() <TAB>  <TAB> t.name = func.__name__ <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> t.status = func(*args, **kwargs) <TAB>  <TAB> except EscapeException as e:  # user aborted <TAB>  <TAB>  <TAB> t.status = ""aborted by user"" <MASK> status(""%s aborted"" % t.name, priority=2) <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> t.exception = e <TAB>  <TAB>  <TAB> t.status = ""exception"" <TAB>  <TAB>  <TAB> vd.exceptionCaught(e) <TAB>  <TAB> if t.sheet: <TAB>  <TAB>  <TAB> t.sheet.currentThreads.remove(t)",if status :,193
3043,"def ESP(phrase): <TAB> for num, name in enumerate(devname): <TAB>  <TAB> if name.lower() in phrase: <TAB>  <TAB>  <TAB> dev = devid[num] <MASK> ctrl = ""=ON"" <TAB>  <TAB>  <TAB>  <TAB> say(""Turning On "" + name) <TAB>  <TAB>  <TAB> elif custom_action_keyword[""Dict""][""Off""] in phrase: <TAB>  <TAB>  <TAB>  <TAB> ctrl = ""=OFF"" <TAB>  <TAB>  <TAB>  <TAB> say(""Turning Off "" + name) <TAB>  <TAB>  <TAB> rq = requests.head(""https://"" + ip + dev + ctrl, verify=False)","if custom_action_keyword [ ""Dict"" ] [ ""On"" ] in phrase :",153
3044,"def _table_schema(self, table): <TAB> rows = self.db.execute_sql(""PRAGMA table_info('%s')"" % table).fetchall() <TAB> # Build list of fields from table information <TAB> result = {} <TAB> for _, name, data_type, not_null, _, primary_key in rows: <TAB>  <TAB> parts = [data_type] <MASK> parts.append(""PRIMARY KEY"") <TAB>  <TAB> if not_null: <TAB>  <TAB>  <TAB> parts.append(""NOT NULL"") <TAB>  <TAB> result[name] = "" "".join(parts) <TAB> return result",if primary_key :,137
3045,"def _validate_forward_input(x, n_in): <TAB> if n_in != 1: <TAB>  <TAB> if not isinstance(x, (tuple, list)): <TAB>  <TAB>  <TAB> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> f""Expected input to be a tuple or list; instead got {type(x)}."" <TAB>  <TAB>  <TAB> ) <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> f""Input tuple length ({len(x)}) does not equal required "" <TAB>  <TAB>  <TAB>  <TAB> f""number of inputs ({n_in})."" <TAB>  <TAB>  <TAB> )",if len ( x ) != n_in :,133
3046,"def _table_reprfunc(self, row, col, val): <TAB> if self._table.column_names[col].endswith(""Size""): <TAB>  <TAB> if isinstance(val, compat.string_types): <TAB>  <TAB>  <TAB> return ""  %s"" % val <MASK> return ""  %.1f KB"" % (val / 1024.0 ** 1) <TAB>  <TAB> elif val < 1024 ** 3: <TAB>  <TAB>  <TAB> return ""  %.1f MB"" % (val / 1024.0 ** 2) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""  %.1f GB"" % (val / 1024.0 ** 3) <TAB> if col in (0, """"): <TAB>  <TAB> return str(val) <TAB> else: <TAB>  <TAB> return ""  %s"" % val",elif val < 1024 ** 2 :,182
3047,"def get_path_name(self): <TAB> if self.is_root(): <TAB>  <TAB> return ""@"" + self.name <TAB> else: <TAB>  <TAB> parent_name = self.parent.get_path_name() <MASK> return ""/"".join([parent_name, ""@"" + self.name]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""@"" + self.name",if parent_name :,90
3048,"def parse(cls, api, json): <TAB> lst = List(api) <TAB> setattr(lst, ""_json"", json) <TAB> for k, v in json.items(): <MASK> setattr(lst, k, User.parse(api, v)) <TAB>  <TAB> elif k == ""created_at"": <TAB>  <TAB>  <TAB> setattr(lst, k, parse_datetime(v)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> setattr(lst, k, v) <TAB> return lst","if k == ""user"" :",115
3049,"def _bytecode_filenames(self, py_filenames): <TAB> bytecode_files = [] <TAB> for py_file in py_filenames: <TAB>  <TAB> if not py_file.endswith("".py""): <TAB>  <TAB>  <TAB> continue <MASK> bytecode_files.append(py_file + ""c"") <TAB>  <TAB> if self.optimize > 0: <TAB>  <TAB>  <TAB> bytecode_files.append(py_file + ""o"") <TAB> return bytecode_files",if self . compile :,107
3050,"def to_json_dict(self): <TAB> d = super().to_json_dict() <TAB> d[""bullet_list""] = RenderedContent.rendered_content_list_to_json(self.bullet_list) <TAB> if self.header is not None: <MASK> d[""header""] = self.header.to_json_dict() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> d[""header""] = self.header <TAB> if self.subheader is not None: <TAB>  <TAB> if isinstance(self.subheader, RenderedContent): <TAB>  <TAB>  <TAB> d[""subheader""] = self.subheader.to_json_dict() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> d[""subheader""] = self.subheader <TAB> return d","if isinstance ( self . header , RenderedContent ) :",172
3051,"def makeSomeFiles(pathobj, dirdict): <TAB> pathdict = {} <TAB> for (key, value) in dirdict.items(): <TAB>  <TAB> child = pathobj.child(key) <TAB>  <TAB> if isinstance(value, bytes): <TAB>  <TAB>  <TAB> pathdict[key] = child <TAB>  <TAB>  <TAB> child.setContent(value) <MASK> child.createDirectory() <TAB>  <TAB>  <TAB> pathdict[key] = makeSomeFiles(child, value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""only strings and dicts allowed as values"") <TAB> return pathdict","elif isinstance ( value , dict ) :",138
3052,"def Restore(self): <TAB> picker, obj = self._window, self._pObject <TAB> value = obj.RestoreValue(PERSIST_FILEDIRPICKER_PATH) <TAB> if value is not None: <MASK> if type(value) == list: <TAB>  <TAB>  <TAB>  <TAB> value = value[-1] <TAB>  <TAB> picker.SetPath(value) <TAB>  <TAB> return True <TAB> return False","if issubclass ( picker . __class__ , wx . FileDialog ) :",102
3053,"def recv(self, buffer_size): <TAB> try: <TAB>  <TAB> return super(SSLConnection, self).recv(buffer_size) <TAB> except ssl.SSLError as err: <MASK> return b"""" <TAB>  <TAB> if err.args[0] in (ssl.SSL_ERROR_EOF, ssl.SSL_ERROR_ZERO_RETURN): <TAB>  <TAB>  <TAB> self.handle_close() <TAB>  <TAB>  <TAB> return b"""" <TAB>  <TAB> raise","if err . args [ 0 ] in ( ssl . SSL_ERROR_WANT_READ , ssl . SSL_ERROR_WANT_WRITE ) :",133
3054,"def IncrementErrorCount(self, category): <TAB> """"""Bumps the module's error statistic."""""" <TAB> self.error_count += 1 <TAB> if self.counting in (""toplevel"", ""detailed""): <MASK> category = category.split(""/"")[0] <TAB>  <TAB> if category not in self.errors_by_category: <TAB>  <TAB>  <TAB> self.errors_by_category[category] = 0 <TAB>  <TAB> self.errors_by_category[category] += 1","if self . counting != ""detailed"" :",115
3055,"def _get_y(self, data_inst): <TAB> if self.stratified: <TAB>  <TAB> y = [v for i, v in data_inst.mapValues(lambda v: v.label).collect()] <MASK> y = self.transform_regression_label(data_inst) <TAB> else: <TAB>  <TAB> # make dummy y <TAB>  <TAB> y = [0] * (data_inst.count()) <TAB> return y",if self . need_transform :,109
3056,"def test_all_project_files(self): <TAB> if sys.platform.startswith(""win""): <TAB>  <TAB> # XXX something with newlines goes wrong on Windows. <TAB>  <TAB> return <TAB> for filepath in support.all_project_files(): <TAB>  <TAB> with open(filepath, ""rb"") as fp: <TAB>  <TAB>  <TAB> encoding = tokenize.detect_encoding(fp.readline)[0] <TAB>  <TAB> self.assertIsNotNone(encoding, ""can't detect encoding for %s"" % filepath) <TAB>  <TAB> with open(filepath, ""r"") as fp: <TAB>  <TAB>  <TAB> source = fp.read() <TAB>  <TAB>  <TAB> source = source.decode(encoding) <TAB>  <TAB> tree = driver.parse_string(source) <TAB>  <TAB> new = unicode(tree) <MASK> self.fail(""Idempotency failed: %s"" % filepath)","if diff ( filepath , new , encoding ) :",195
3057,"def test_resource_arn_override_generator(self): <TAB> overrides = set() <TAB> for k, v in manager.resources.items(): <TAB>  <TAB> arn_gen = bool(v.__dict__.get(""get_arns"") or v.__dict__.get(""generate_arn"")) <MASK> overrides.add(k) <TAB> overrides = overrides.difference( <TAB>  <TAB> { <TAB>  <TAB>  <TAB> ""account"", <TAB>  <TAB>  <TAB> ""s3"", <TAB>  <TAB>  <TAB> ""hostedzone"", <TAB>  <TAB>  <TAB> ""log-group"", <TAB>  <TAB>  <TAB> ""rest-api"", <TAB>  <TAB>  <TAB> ""redshift-snapshot"", <TAB>  <TAB>  <TAB> ""rest-stage"", <TAB>  <TAB> } <TAB> ) <TAB> if overrides: <TAB>  <TAB> raise ValueError(""unknown arn overrides in %s"" % ("", "".join(overrides)))",if arn_gen :,185
3058,"def _check_dsl_runner(self) -> None: <TAB> """"""Checks if runner in dsl is Kubeflow V2 runner."""""" <TAB> with open(self.flags_dict[labels.PIPELINE_DSL_PATH], ""r"") as f: <TAB>  <TAB> dsl_contents = f.read() <MASK> raise RuntimeError(""KubeflowV2DagRunner not found in dsl."")","if ""KubeflowV2DagRunner"" not in dsl_contents :",116
3059,"def create_warehouse(warehouse_name, properties=None, company=None): <TAB> if not company: <TAB>  <TAB> company = ""_Test Company"" <TAB> warehouse_id = erpnext.encode_company_abbr(warehouse_name, company) <TAB> if not frappe.db.exists(""Warehouse"", warehouse_id): <TAB>  <TAB> warehouse = frappe.new_doc(""Warehouse"") <TAB>  <TAB> warehouse.warehouse_name = warehouse_name <TAB>  <TAB> warehouse.parent_warehouse = ""All Warehouses - _TCUV"" <TAB>  <TAB> warehouse.company = company <TAB>  <TAB> warehouse.account = get_warehouse_account(warehouse_name, company) <MASK> warehouse.update(properties) <TAB>  <TAB> warehouse.save() <TAB>  <TAB> return warehouse.name <TAB> else: <TAB>  <TAB> return warehouse_id",if properties :,186
3060,"def _parse(self, contents): <TAB> entries = [] <TAB> hostnames_found = set() <TAB> for line in contents.splitlines(): <TAB>  <TAB> if not len(line.strip()): <TAB>  <TAB>  <TAB> entries.append((""blank"", [line])) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> (head, tail) = chop_comment(line.strip(), ""#"") <MASK> entries.append((""all_comment"", [line])) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> entries.append((""hostname"", [head, tail])) <TAB>  <TAB> hostnames_found.add(head) <TAB> if len(hostnames_found) > 1: <TAB>  <TAB> raise IOError(""Multiple hostnames (%s) found!"" % (hostnames_found)) <TAB> return entries",if not len ( head ) :,167
3061,"def _get_omega(self): <TAB> if self._omega is None: <TAB>  <TAB> n = self.get_drift_dim() // 2 <TAB>  <TAB> omg = sympl.calc_omega(n) <TAB>  <TAB> if self.oper_dtype == Qobj: <TAB>  <TAB>  <TAB> self._omega = Qobj(omg, dims=self.dyn_dims) <TAB>  <TAB>  <TAB> self._omega_qobj = self._omega <MASK> self._omega = sp.csr_matrix(omg) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._omega = omg <TAB> return self._omega",elif self . oper_dtype == sp . csr_matrix :,163
3062,"def get_in_inputs(key, data): <TAB> if isinstance(data, dict): <TAB>  <TAB> for k, v in data.items(): <TAB>  <TAB>  <TAB> if k == key: <TAB>  <TAB>  <TAB>  <TAB> return v <MASK> out = get_in_inputs(key, v) <TAB>  <TAB>  <TAB>  <TAB> if out: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return out <TAB> elif isinstance(data, (list, tuple)): <TAB>  <TAB> out = [get_in_inputs(key, x) for x in data] <TAB>  <TAB> out = [x for x in out if x] <TAB>  <TAB> if out: <TAB>  <TAB>  <TAB> return out[0]","elif isinstance ( v , ( list , tuple , dict ) ) :",160
3063,def visit_binary(binary): <TAB> if binary.operator == operators.eq: <TAB>  <TAB> cols = util.column_set(chain(*[c.proxy_set for c in columns.difference(omit)])) <MASK> for c in reversed(columns): <TAB>  <TAB>  <TAB>  <TAB> if c.shares_lineage(binary.right) and ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> not only_synonyms or c.name == binary.left.name <TAB>  <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> omit.add(c) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break,if binary . left in cols and binary . right in cols :,136
3064,"def wait_tasks_or_abort(futures, timeout=60, kill_switch_ev=None): <TAB> try: <TAB>  <TAB> LazySingletonTasksCoordinator.wait_tasks( <TAB>  <TAB>  <TAB> futures, return_when=FIRST_EXCEPTION, raise_exceptions=True <TAB>  <TAB> ) <TAB> except Exception as e: <MASK> # Used when we want to keep both raise the exception and wait for all tasks to finish <TAB>  <TAB>  <TAB> kill_switch_ev.set() <TAB>  <TAB>  <TAB> LazySingletonTasksCoordinator.wait_tasks( <TAB>  <TAB>  <TAB>  <TAB> futures, <TAB>  <TAB>  <TAB>  <TAB> return_when=ALL_COMPLETED, <TAB>  <TAB>  <TAB>  <TAB> raise_exceptions=False, <TAB>  <TAB>  <TAB>  <TAB> timeout=timeout, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> raise e",if kill_switch_ev is not None :,187
3065,"def is_valid(sample): <TAB> if sample is None: <TAB>  <TAB> return False <TAB> if isinstance(sample, tuple): <TAB>  <TAB> for s in sample: <MASK> return False <TAB>  <TAB>  <TAB> elif isinstance(s, np.ndarray) and s.size == 0: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> elif isinstance(s, collections.abc.Sequence) and len(s) == 0: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return True",if s is None :,114
3066,"def setVaName(self, va, parent=None): <TAB> if parent is None: <TAB>  <TAB> parent = self <TAB> curname = self.vw.getName(va) <TAB> if curname is None: <TAB>  <TAB> curname = """" <TAB> name, ok = QInputDialog.getText(parent, ""Enter..."", ""Name"", text=curname) <TAB> if ok: <TAB>  <TAB> name = str(name) <MASK> raise Exception(""Duplicate Name: %s"" % name) <TAB>  <TAB> self.vw.makeName(va, name)",if self . vw . vaByName ( name ) :,142
3067,"def generic_tag_compiler(params, defaults, name, node_class, parser, token): <TAB> ""Returns a template.Node subclass."" <TAB> bits = token.split_contents()[1:] <TAB> bmax = len(params) <TAB> def_len = defaults and len(defaults) or 0 <TAB> bmin = bmax - def_len <TAB> if len(bits) < bmin or len(bits) > bmax: <MASK> message = ""%s takes %s arguments"" % (name, bmin) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> message = ""%s takes between %s and %s arguments"" % (name, bmin, bmax) <TAB>  <TAB> raise TemplateSyntaxError(message) <TAB> return node_class(bits)",if bmin == bmax :,176
3068,"def extract_segmentation_mask(annotation): <TAB> poly_specs = annotation[DensePoseDataRelative.S_KEY] <TAB> if isinstance(poly_specs, torch.Tensor): <TAB>  <TAB> # data is already given as mask tensors, no need to decode <TAB>  <TAB> return poly_specs <TAB> import pycocotools.mask as mask_utils <TAB> segm = torch.zeros((DensePoseDataRelative.MASK_SIZE,) * 2, dtype=torch.float32) <TAB> for i in range(DensePoseDataRelative.N_BODY_PARTS): <TAB>  <TAB> poly_i = poly_specs[i] <MASK> mask_i = mask_utils.decode(poly_i) <TAB>  <TAB>  <TAB> segm[mask_i > 0] = i + 1 <TAB> return segm",if poly_i :,184
3069,"def module_list(target, fast): <TAB> """"""Find the list of modules to be compiled"""""" <TAB> modules = [] <TAB> native = native_modules(target) <TAB> basedir = os.path.join(ouroboros_repo_folder(), ""ouroboros"") <TAB> for name in os.listdir(basedir): <TAB>  <TAB> module_name, ext = os.path.splitext(name) <MASK> if module_name not in IGNORE_MODULES and module_name not in native: <TAB>  <TAB>  <TAB>  <TAB> if not (fast and module_name in KNOWN_PROBLEM_MODULES): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> modules.append(module_name) <TAB> return set(modules)","if ext == "".py"" or ext == """" and os . path . isdir ( os . path . join ( basedir , name ) ) :",185
3070,"def filelist_from_patterns(pats, rootdir=None): <TAB> if rootdir is None: <TAB>  <TAB> rootdir = ""."" <TAB> # filelist = [] <TAB> fileset = set([]) <TAB> lines = [line.strip() for line in pats] <TAB> for line in lines: <TAB>  <TAB> pat = line[2:] <TAB>  <TAB> newfiles = glob(osp.join(rootdir, pat)) <TAB>  <TAB> if line.startswith(""+""): <TAB>  <TAB>  <TAB> fileset.update(newfiles) <MASK> fileset.difference_update(newfiles) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""line must start with + or -"") <TAB> filelist = list(fileset) <TAB> return filelist","elif line . startswith ( ""-"" ) :",165
3071,"def get_upstream_statuses_events(self, upstream: Set) -> Dict[str, V1Statuses]: <TAB> statuses_by_refs = {u: [] for u in upstream} <TAB> events = self.events or []  # type: List[V1EventTrigger] <TAB> for e in events: <TAB>  <TAB> entity_ref = contexts_refs.get_entity_ref(e.ref) <TAB>  <TAB> if not entity_ref: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if entity_ref not in statuses_by_refs: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for kind in e.kinds: <TAB>  <TAB>  <TAB> status = V1EventKind.events_statuses_mapping.get(kind) <MASK> statuses_by_refs[entity_ref].append(status) <TAB> return statuses_by_refs",if status :,191
3072,"def __setitem__(self, key, value): <TAB> if isinstance(value, (tuple, list)): <TAB>  <TAB> info, reference = value <MASK> self._reverse_infos[info] = len(self._infos) <TAB>  <TAB>  <TAB> self._infos.append(info) <TAB>  <TAB> if reference not in self._reverse_references: <TAB>  <TAB>  <TAB> self._reverse_references[reference] = len(self._references) <TAB>  <TAB>  <TAB> self._references.append(reference) <TAB>  <TAB> self._trails[key] = ""%d,%d"" % ( <TAB>  <TAB>  <TAB> self._reverse_infos[info], <TAB>  <TAB>  <TAB> self._reverse_references[reference], <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> raise Exception(""unsupported type '%s'"" % type(value))",if info not in self . _reverse_infos :,184
3073,"def ChangeStyle(self, combos): <TAB> style = 0 <TAB> for combo in combos: <MASK> if combo.GetLabel() == ""TR_VIRTUAL"": <TAB>  <TAB>  <TAB>  <TAB> style = style | HTL.TR_VIRTUAL <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> style = style | eval(""wx."" + combo.GetLabel()) <TAB>  <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> style = style | eval(""HTL."" + combo.GetLabel()) <TAB> if self.GetAGWWindowStyleFlag() != style: <TAB>  <TAB> self.SetAGWWindowStyleFlag(style)",if combo . GetValue ( ) == 1 :,153
3074,"def _parse_csrf(self, response): <TAB> for d in response: <TAB>  <TAB> if d.startswith(""Set-Cookie:""): <TAB>  <TAB>  <TAB> for c in d.split("":"", 1)[1].split("";""): <MASK> self._CSRFtoken = c.strip("" \r\n"") <TAB>  <TAB>  <TAB>  <TAB>  <TAB> log.verbose(""Got new cookie: %s"", self._CSRFtoken) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> if self._CSRFtoken != None: <TAB>  <TAB>  <TAB>  <TAB> break","if c . strip ( ) . startswith ( ""CSRF-Token-"" ) :",135
3075,"def test_page_size_matching_max_returned_rows( <TAB> app_client_returned_rows_matches_page_size,): <TAB> fetched = [] <TAB> path = ""/fixtures/no_primary_key.json"" <TAB> while path: <TAB>  <TAB> response = app_client_returned_rows_matches_page_size.get(path) <TAB>  <TAB> fetched.extend(response.json[""rows""]) <TAB>  <TAB> assert len(response.json[""rows""]) in (1, 50) <TAB>  <TAB> path = response.json[""next_url""] <MASK> path = path.replace(""http://localhost"", """") <TAB> assert 201 == len(fetched)",if path :,155
3076,"def get_mapping_exception_message(mappings: List[Tuple[Text, Text]]): <TAB> """"""Return a message given a list of duplicates."""""" <TAB> message = """" <TAB> for name, action_name in mappings: <MASK> message += ""\n"" <TAB>  <TAB> message += ( <TAB>  <TAB>  <TAB> ""Intent '{}' is set to trigger action '{}', which is "" <TAB>  <TAB>  <TAB> ""not defined in the domain."".format(name, action_name) <TAB>  <TAB> ) <TAB> return message",if message :,113
3077,def cut(sentence): <TAB> sentence = strdecode(sentence) <TAB> blocks = re_han.split(sentence) <TAB> for blk in blocks: <TAB>  <TAB> if re_han.match(blk): <TAB>  <TAB>  <TAB> for word in __cut(blk): <TAB>  <TAB>  <TAB>  <TAB> if word not in Force_Split_Words: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield word <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for c in word: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield c <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tmp = re_skip.split(blk) <TAB>  <TAB>  <TAB> for x in tmp: <MASK> yield x,if x :,156
3078,"def chop(expr, delta=10.0 ** (-10.0)): <TAB> if isinstance(expr, Real): <TAB>  <TAB> if -delta < expr.get_float_value() < delta: <TAB>  <TAB>  <TAB> return Integer(0) <TAB> elif isinstance(expr, Complex) and expr.is_inexact(): <TAB>  <TAB> real, imag = expr.real, expr.imag <TAB>  <TAB> if -delta < real.get_float_value() < delta: <TAB>  <TAB>  <TAB> real = Integer(0) <MASK> imag = Integer(0) <TAB>  <TAB> return Complex(real, imag) <TAB> elif isinstance(expr, Expression): <TAB>  <TAB> return Expression(chop(expr.head), *[chop(leaf) for leaf in expr.leaves]) <TAB> return expr",if - delta < imag . get_float_value ( ) < delta :,186
3079,"def make_row(self): <TAB> res = [] <TAB> for i in range(self.num_cols): <TAB>  <TAB> t = sqlite3_column_type(self.stmnt, i) <TAB>  <TAB> # print(""type"", t) <TAB>  <TAB> if t == SQLITE_INTEGER: <TAB>  <TAB>  <TAB> res.append(sqlite3_column_int(self.stmnt, i)) <TAB>  <TAB> elif t == SQLITE_FLOAT: <TAB>  <TAB>  <TAB> res.append(sqlite3_column_double(self.stmnt, i)) <MASK> res.append(sqlite3_column_text(self.stmnt, i)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise NotImplementedError <TAB> return tuple(res)",elif t == SQLITE_TEXT :,172
3080,"def try_convert(self, string): <TAB> string = string.strip() <TAB> try: <TAB>  <TAB> return int(string) <TAB> except: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return float(string) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> if string == ""True"": <TAB>  <TAB>  <TAB>  <TAB> return True <MASK> return False <TAB>  <TAB>  <TAB> return string","if string == ""False"" :",93
3081,"def configure_create_table_epilogue(store): <TAB> for val in ["""", "" ENGINE=InnoDB""]: <TAB>  <TAB> store.config[""create_table_epilogue""] = val <TAB>  <TAB> store._set_sql_flavour() <MASK> store.log.info(""create_table_epilogue='%s'"", val) <TAB>  <TAB>  <TAB> return <TAB> raise Exception(""Can not create a transactional table."")",if store . _test_transaction ( ) :,104
3082,"def _check_rule(self, match, target_dict, cred_dict): <TAB> """"""Recursively checks credentials based on the brains rules."""""" <TAB> try: <TAB>  <TAB> new_match_list = self.rules[match] <TAB> except KeyError: <MASK> new_match_list = (""rule:%s"" % self.default_rule,) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> return self.check(new_match_list, target_dict, cred_dict)",if self . default_rule and match != self . default_rule :,129
3083,"def get_civil_names(self): <TAB> congresspeople_ids = self.get_all_congresspeople_ids() <TAB> for i, congress_id in enumerate(congresspeople_ids): <TAB>  <TAB> if not np.math.isnan(float(congress_id)): <TAB>  <TAB>  <TAB> percentage = i / self.total * 100 <TAB>  <TAB>  <TAB> msg = ""Processed {} out of {} ({:.2f}%)"" <TAB>  <TAB>  <TAB> print(msg.format(i, self.total, percentage), end=""\r"") <TAB>  <TAB>  <TAB> data = self.fetch_data_repository(congress_id) <MASK> yield dict(data)",if data is not None :,160
3084,"def parse_network_whitelist(self, network_whitelist_location): <TAB> networks = [] <TAB> with open(network_whitelist_location, ""r"") as text_file: <TAB>  <TAB> for line in text_file: <TAB>  <TAB>  <TAB> line = line.strip().strip(""'"").strip('""') <MASK> networks.append(line) <TAB> return networks",if isIPv4 ( line ) or isIPv6 ( line ) :,98
3085,"def _pick(self, cum): <TAB> if self._isleaf(): <TAB>  <TAB> return self.bd[0], self.s <TAB> else: <MASK> return self.left._pick(cum) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.right._pick(cum - self.left.s)",if cum < self . left . s :,83
3086,"def serialize_content_range(value): <TAB> if isinstance(value, (tuple, list)): <TAB>  <TAB> if len(value) not in (2, 3): <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""When setting content_range to a list/tuple, it must "" <TAB>  <TAB>  <TAB>  <TAB> ""be length 2 or 3 (not %r)"" % value <TAB>  <TAB>  <TAB> ) <MASK> begin, end = value <TAB>  <TAB>  <TAB> length = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> begin, end, length = value <TAB>  <TAB> value = ContentRange(begin, end, length) <TAB> value = str(value).strip() <TAB> if not value: <TAB>  <TAB> return None <TAB> return value",if len ( value ) == 2 :,169
3087,"def make_index_fields(rec): <TAB> fields = {} <TAB> for k, v in rec.iteritems(): <MASK> fields[k] = v <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if k == ""full_title"": <TAB>  <TAB>  <TAB> fields[""title""] = [read_short_title(v)] <TAB> return fields","if k in ( ""lccn"" , ""oclc"" , ""isbn"" ) :",93
3088,"def _sample_translation(reference, max_len): <TAB> translation = reference[:] <TAB> while np.random.uniform() < 0.8 and 1 < len(translation) < max_len: <TAB>  <TAB> trans_len = len(translation) <TAB>  <TAB> ind = np.random.randint(trans_len) <TAB>  <TAB> action = np.random.choice(actions) <TAB>  <TAB> if action == ""deletion"": <TAB>  <TAB>  <TAB> del translation[ind] <MASK> ind_rep = np.random.randint(trans_len) <TAB>  <TAB>  <TAB> translation[ind] = translation[ind_rep] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ind_insert = np.random.randint(trans_len) <TAB>  <TAB>  <TAB> translation.insert(ind, translation[ind_insert]) <TAB> return translation","elif action == ""replacement"" :",186
3089,"def __call__(self, text: str) -> str: <TAB> for t in self.cleaner_types: <TAB>  <TAB> if t == ""tacotron"": <TAB>  <TAB>  <TAB> text = tacotron_cleaner.cleaners.custom_english_cleaners(text) <TAB>  <TAB> elif t == ""jaconv"": <TAB>  <TAB>  <TAB> text = jaconv.normalize(text) <MASK> if vietnamese_cleaners is None: <TAB>  <TAB>  <TAB>  <TAB> raise RuntimeError(""Please install underthesea"") <TAB>  <TAB>  <TAB> text = vietnamese_cleaners.vietnamese_cleaner(text) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise RuntimeError(f""Not supported: type={t}"") <TAB> return text","elif t == ""vietnamese"" :",174
3090,"def hook_GetVariable(ql, address, params): <TAB> if params[""VariableName""] in ql.env: <TAB>  <TAB> var = ql.env[params[""VariableName""]] <TAB>  <TAB> read_len = read_int64(ql, params[""DataSize""]) <MASK> write_int64(ql, params[""Attributes""], 0) <TAB>  <TAB> write_int64(ql, params[""DataSize""], len(var)) <TAB>  <TAB> if read_len < len(var): <TAB>  <TAB>  <TAB> return EFI_BUFFER_TOO_SMALL <TAB>  <TAB> if params[""Data""] != 0: <TAB>  <TAB>  <TAB> ql.mem.write(params[""Data""], var) <TAB>  <TAB> return EFI_SUCCESS <TAB> return EFI_NOT_FOUND","if params [ ""Attributes"" ] != 0 :",177
3091,"def test_setupapp(self, overrideRootMenu): <TAB> ""Call setupApp with each possible graphics type."" <TAB> root = self.root <TAB> flist = FileList(root) <TAB> for tktype in alltypes: <TAB>  <TAB> with self.subTest(tktype=tktype): <TAB>  <TAB>  <TAB> macosx._tk_type = tktype <TAB>  <TAB>  <TAB> macosx.setupApp(root, flist) <MASK> self.assertTrue(overrideRootMenu.called) <TAB>  <TAB>  <TAB> overrideRootMenu.reset_mock()","if tktype in ( ""carbon"" , ""cocoa"" ) :",139
3092,"def names(self, persistent=None): <TAB> u = set() <TAB> result = [] <TAB> for s in [ <TAB>  <TAB> self.__storage(None), <TAB>  <TAB> self.__storage(self.__category), <TAB> ]: <TAB>  <TAB> for b in s: <TAB>  <TAB>  <TAB> if persistent is not None and b.persistent != persistent: <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB>  <TAB> if b.name not in u: <TAB>  <TAB>  <TAB>  <TAB> result.append(b.name) <TAB>  <TAB>  <TAB>  <TAB> u.add(b.name) <TAB> return result","if b . name . startswith ( ""__"" ) :",139
3093,"def _check_extra_specs(key, value=None): <TAB> extra_specs = diff.get(""extra_specs"") <TAB> specific_type = extra_specs.get(key) if extra_specs else None <TAB> old_type = None <TAB> new_type = None <TAB> if specific_type: <TAB>  <TAB> old_type, new_type = specific_type <MASK> old_type = True if old_type and old_type.upper() == value else False <TAB>  <TAB>  <TAB> new_type = True if new_type and new_type.upper() == value else False <TAB> return old_type, new_type",if value :,148
3094,"def _write_lock_file(self, repo, force=True):  # type: (Repository, bool) -> None <TAB> if force or (self._update and self._write_lock): <TAB>  <TAB> updated_lock = self._locker.set_lock_data(self._package, repo.packages) <MASK> self._io.write_line("""") <TAB>  <TAB>  <TAB> self._io.write_line(""<info>Writing lock file</>"")",if updated_lock :,109
3095,"def process_message(self, msg): <TAB> if msg[""type""] == ""sample"": <TAB>  <TAB> batch_shape = msg[""fn""].batch_shape <MASK> batch_shape = [1] * (-self.dim - len(batch_shape)) + list(batch_shape) <TAB>  <TAB>  <TAB> batch_shape[self.dim] = self.size <TAB>  <TAB>  <TAB> msg[""fn""] = msg[""fn""].expand(torch.Size(batch_shape))",if len ( batch_shape ) < - self . dim or batch_shape [ self . dim ] != self . size :,133
3096,"def _test_reducibility(self): <TAB> # make a copy of the graph <TAB> graph = networkx.DiGraph(self._graph) <TAB> # preprocess: make it a super graph <TAB> self._make_supergraph(graph) <TAB> while True: <TAB>  <TAB> changed = False <TAB>  <TAB> # find a node with a back-edge, remove the edge (deleting the loop), and replace it with a MultiNode <TAB>  <TAB> changed |= self._remove_self_loop(graph) <TAB>  <TAB> # find a node that has only one predecessor, and merge it with its predecessor (replace them with a <TAB>  <TAB> # MultiNode) <TAB>  <TAB> changed |= self._merge_single_entry_node(graph) <MASK> # a fixed-point is reached <TAB>  <TAB>  <TAB> break",if not changed :,178
3097,"def __init__(self, roberta, num_classes=2, dropout=0.0, prefix=None, params=None): <TAB> super(RoBERTaClassifier, self).__init__(prefix=prefix, params=params) <TAB> self.roberta = roberta <TAB> self._units = roberta._units <TAB> with self.name_scope(): <TAB>  <TAB> self.classifier = nn.HybridSequential(prefix=prefix) <MASK> self.classifier.add(nn.Dropout(rate=dropout)) <TAB>  <TAB> self.classifier.add(nn.Dense(units=self._units, activation=""tanh"")) <TAB>  <TAB> if dropout: <TAB>  <TAB>  <TAB> self.classifier.add(nn.Dropout(rate=dropout)) <TAB>  <TAB> self.classifier.add(nn.Dense(units=num_classes))",if dropout :,185
3098,"def get_object_from_name(self, name, check_symlinks=True): <TAB> if not name: <TAB>  <TAB> return None <TAB> name = name.rstrip(""\\"") <TAB> for a, o in self.objects.items(): <TAB>  <TAB> if not o.name: <TAB>  <TAB>  <TAB> continue <MASK> return o <TAB> if check_symlinks: <TAB>  <TAB> m = [sl[1] for sl in self.symlinks if name.lower() == sl[0].lower()] <TAB>  <TAB> if m: <TAB>  <TAB>  <TAB> name = m[0] <TAB>  <TAB> return self.get_object_from_name(name, False)",if o . name . lower ( ) == name . lower ( ) :,156
3099,"def __call__(self): <TAB> """"""Run all check_* methods."""""" <TAB> if self.on: <TAB>  <TAB> oldformatwarning = warnings.formatwarning <TAB>  <TAB> warnings.formatwarning = self.formatwarning <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> for name in dir(self): <MASK> method = getattr(self, name) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if method and callable(method): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> method() <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> warnings.formatwarning = oldformatwarning","if name . startswith ( ""check_"" ) :",127
3100,"def __print__(self, defaults=False): <TAB> if defaults: <TAB>  <TAB> print_func = str <TAB> else: <TAB>  <TAB> print_func = repr <TAB> pieces = [] <TAB> default_values = self.__defaults__ <TAB> for k in self.__fields__: <TAB>  <TAB> value = getattr(self, k) <TAB>  <TAB> if not defaults and value == default_values[k]: <TAB>  <TAB>  <TAB> continue <MASK> print_func = repr  # keep quotes around strings <TAB>  <TAB> pieces.append(""%s=%s"" % (k, print_func(value))) <TAB> if pieces or self.__base__: <TAB>  <TAB> return ""%s(%s)"" % (self.__class__.__name__, "", "".join(pieces)) <TAB> else: <TAB>  <TAB> return """"","if isinstance ( value , basestring ) :",178
3101,"def apply(self, **kwargs: Any) -> None: <TAB> for node in self.document.traverse(nodes.target): <MASK> continue <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB> ""ismod"" in node <TAB>  <TAB>  <TAB> and node.parent.__class__ is nodes.section <TAB>  <TAB>  <TAB> and <TAB>  <TAB>  <TAB> # index 0 is the section title node <TAB>  <TAB>  <TAB> node.parent.index(node) == 1 <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> node.parent[""ids""][0:0] = node[""ids""] <TAB>  <TAB>  <TAB> node.parent.remove(node)","if not node [ ""ids"" ] :",139
3102,"def add_special_token_2d( <TAB> values: List[List[int]], special_token: int = 0, use_first_value: bool = False) -> List[List[int]]: <TAB> results = torch.jit.annotate(List[List[int]], []) <TAB> for value in values: <TAB>  <TAB> result = torch.jit.annotate(List[int], []) <MASK> special_token = value[0] <TAB>  <TAB> result.append(special_token) <TAB>  <TAB> result.extend(value) <TAB>  <TAB> result.append(special_token) <TAB>  <TAB> results.append(result) <TAB> return results",if use_first_value and len ( value ) > 0 :,159
3103,"def test_import(self): <TAB> TIMEOUT = 5 <TAB> # Test for a deadlock when importing a module that runs the <TAB> # ThreadedResolver at import-time. See resolve_test.py for <TAB> # full explanation. <TAB> command = [sys.executable, ""-c"", ""import tornado.test.resolve_test_helper""] <TAB> start = time.time() <TAB> popen = Popen(command, preexec_fn=lambda: signal.alarm(TIMEOUT)) <TAB> while time.time() - start < TIMEOUT: <TAB>  <TAB> return_code = popen.poll() <MASK> self.assertEqual(0, return_code) <TAB>  <TAB>  <TAB> return  # Success. <TAB>  <TAB> time.sleep(0.05) <TAB> self.fail(""import timed out"")",if return_code is not None :,183
3104,"def find_item_for_key(self, e): <TAB> for item in self._items: <TAB>  <TAB> if item.keycode == e.key and item.shift == e.shift and item.alt == e.alt: <TAB>  <TAB>  <TAB> focus = get_focus() <MASK> return self._items.index(item) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return -1 <TAB> return -1","if self . command_is_enabled ( item , focus ) :",112
3105,"def check_app_config_brackets(self): <TAB> for sn, app in cherrypy.tree.apps.items(): <TAB>  <TAB> if not isinstance(app, cherrypy.Application): <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> for key in app.config.keys(): <TAB>  <TAB>  <TAB> if key.startswith(""["") or key.endswith(""]""): <TAB>  <TAB>  <TAB>  <TAB> warnings.warn( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""The application mounted at %r has config "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""section names with extraneous brackets: %r. "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Config *files* need brackets; config *dicts* "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""(e.g. passed to tree.mount) do not."" % (sn, key) <TAB>  <TAB>  <TAB>  <TAB> )",if not app . config :,186
3106,"def got_arbiter_module_type_defined(self, mod_type): <TAB> for a in self.arbiters: <TAB>  <TAB> # Do like the linkify will do after.... <TAB>  <TAB> for m in getattr(a, ""modules"", []): <TAB>  <TAB>  <TAB> # So look at what the arbiter try to call as module <TAB>  <TAB>  <TAB> m = m.strip() <TAB>  <TAB>  <TAB> # Ok, now look in modules... <TAB>  <TAB>  <TAB> for mod in self.modules: <TAB>  <TAB>  <TAB>  <TAB> # try to see if this module is the good type <MASK> # if so, the good name? <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if getattr(mod, ""module_name"", """").strip() == m: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False","if getattr ( mod , ""module_type"" , """" ) . strip ( ) == mod_type . strip ( ) :",199
3107,"def write_config_to_file(self, folder, filename, config): <TAB> do_not_write = [""hyperparameter_search_space_updates""] <TAB> with open(os.path.join(folder, filename), ""w"") as f: <TAB>  <TAB> f.write( <TAB>  <TAB>  <TAB> ""\n"".join( <TAB>  <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> (key + ""="" + str(value)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for (key, value) in sorted(config.items(), key=lambda x: x[0]) <MASK> ] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> )",if not key in do_not_write,152
3108,"def parsing(self, parsing):  # type: (bool) -> None <TAB> self._parsed = parsing <TAB> for k, v in self._body: <MASK> v.value.parsing(parsing) <TAB>  <TAB> elif isinstance(v, AoT): <TAB>  <TAB>  <TAB> for t in v.body: <TAB>  <TAB>  <TAB>  <TAB> t.value.parsing(parsing)","if isinstance ( v , Table ) :",93
3109,"def test_crashers_crash(self): <TAB> for fname in glob.glob(CRASHER_FILES): <MASK> continue <TAB>  <TAB> # Some ""crashers"" only trigger an exception rather than a <TAB>  <TAB> # segfault. Consider that an acceptable outcome. <TAB>  <TAB> if test.support.verbose: <TAB>  <TAB>  <TAB> print(""Checking crasher:"", fname) <TAB>  <TAB> assert_python_failure(fname)",if os . path . basename ( fname ) in infinite_loops :,110
3110,"def __getitem__(self, k) -> ""SimMemView"": <TAB> if isinstance(k, slice): <TAB>  <TAB> if k.step is not None: <TAB>  <TAB>  <TAB> raise ValueError(""Slices with strides are not supported"") <TAB>  <TAB> elif k.start is None: <TAB>  <TAB>  <TAB> raise ValueError(""Must specify start index"") <MASK> raise ValueError(""Slices with stop index are not supported"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> addr = k.start <TAB> elif self._type is not None and self._type._can_refine_int: <TAB>  <TAB> return self._type._refine(self, k) <TAB> else: <TAB>  <TAB> addr = k <TAB> return self._deeper(addr=addr)",elif k . stop is not None :,169
3111,"def get_lowest_wall_time(jsons): <TAB> lowest_wall = None <TAB> for j in jsons: <MASK> lowest_wall = j[""wall_time""] <TAB>  <TAB> if lowest_wall > j[""wall_time""]: <TAB>  <TAB>  <TAB> lowest_wall = j[""wall_time""] <TAB> return lowest_wall",if lowest_wall is None :,86
3112,"def extract_wav_headers(data): <TAB> # def search_subchunk(data, subchunk_id): <TAB> pos = 12  # The size of the RIFF chunk descriptor <TAB> subchunks = [] <TAB> while pos + 8 <= len(data) and len(subchunks) < 10: <TAB>  <TAB> subchunk_id = data[pos : pos + 4] <TAB>  <TAB> subchunk_size = struct.unpack_from(""<I"", data[pos + 4 : pos + 8])[0] <TAB>  <TAB> subchunks.append(WavSubChunk(subchunk_id, pos, subchunk_size)) <MASK> # 'data' is the last subchunk <TAB>  <TAB>  <TAB> break <TAB>  <TAB> pos += subchunk_size + 8 <TAB> return subchunks","if subchunk_id == b""data"" :",183
3113,"def _any_targets_have_native_sources(self, targets): <TAB> # TODO(#5949): convert this to checking if the closure of python requirements has any <TAB> # platform-specific packages (maybe find the platforms there too?). <TAB> for tgt in targets: <TAB>  <TAB> for type_constraint, target_predicate in self._native_target_matchers.items(): <MASK> return True <TAB> return False",if type_constraint . satisfied_by ( tgt ) and target_predicate ( tgt ) :,115
3114,"def validate_memory(self, value): <TAB> for k, v in value.viewitems(): <TAB>  <TAB> if v is None:  # use NoneType to unset a value <TAB>  <TAB>  <TAB> continue <MASK> raise serializers.ValidationError(""Process types can only contain [a-z]"") <TAB>  <TAB> if not re.match(MEMLIMIT_MATCH, str(v)): <TAB>  <TAB>  <TAB> raise serializers.ValidationError( <TAB>  <TAB>  <TAB>  <TAB> ""Limit format: <number><unit>, where unit = B, K, M or G"" <TAB>  <TAB>  <TAB> ) <TAB> return value","if not re . match ( PROCTYPE_MATCH , k ) :",141
3115,"def cart_number_checksum_validation(cls, number): <TAB> digits = [] <TAB> even = False <TAB> if not number.isdigit(): <TAB>  <TAB> return False <TAB> for digit in reversed(number): <TAB>  <TAB> digit = ord(digit) - ord(""0"") <TAB>  <TAB> if even: <TAB>  <TAB>  <TAB> digit *= 2 <MASK> digit = digit % 10 + digit // 10 <TAB>  <TAB> digits.append(digit) <TAB>  <TAB> even = not even <TAB> return sum(digits) % 10 == 0 if digits else False",if digit >= 10 :,127
3116,"def transform(a, cmds): <TAB> buf = a.split(""\n"") <TAB> for cmd in cmds: <TAB>  <TAB> ctype, line, col, char = cmd <TAB>  <TAB> if ctype == ""D"": <MASK> buf[line] = buf[line][:col] + buf[line][col + len(char) :] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> buf[line] = buf[line] + buf[line + 1] <TAB>  <TAB>  <TAB>  <TAB> del buf[line + 1] <TAB>  <TAB> elif ctype == ""I"": <TAB>  <TAB>  <TAB> buf[line] = buf[line][:col] + char + buf[line][col:] <TAB>  <TAB> buf = ""\n"".join(buf).split(""\n"") <TAB> return ""\n"".join(buf)","if char != ""\n"" :",182
3117,"def get_partners(self) -> Dict[AbstractNode, Set[int]]: <TAB> partners = {}  # type: Dict[AbstractNode, Set[int]] <TAB> for edge in self.edges: <TAB>  <TAB> if edge.is_dangling(): <TAB>  <TAB>  <TAB> raise ValueError(""Cannot contract copy tensor with dangling edges"") <TAB>  <TAB> if self._is_my_trace(edge): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> partner_node, shared_axis = self._get_partner(edge) <MASK> partners[partner_node] = set() <TAB>  <TAB> partners[partner_node].add(shared_axis) <TAB> return partners",if partner_node not in partners :,163
3118,"def _bind_interactive_rez(self): <TAB> if config.set_prompt and self.settings.prompt: <TAB>  <TAB> stored_prompt = os.getenv(""REZ_STORED_PROMPT_CMD"") <TAB>  <TAB> curr_prompt = stored_prompt or os.getenv(""PROMPT"", """") <MASK> self.setenv(""REZ_STORED_PROMPT_CMD"", curr_prompt) <TAB>  <TAB> new_prompt = ""%%REZ_ENV_PROMPT%%"" <TAB>  <TAB> new_prompt = ( <TAB>  <TAB>  <TAB> (new_prompt + "" %s"") if config.prefix_prompt else (""%s "" + new_prompt) <TAB>  <TAB> ) <TAB>  <TAB> new_prompt = new_prompt % curr_prompt <TAB>  <TAB> self._addline(""set PROMPT=%s"" % new_prompt)",if not stored_prompt :,182
3119,"def __listingColumns(self): <TAB> columns = [] <TAB> for name in self.__getColumns(): <TAB>  <TAB> definition = column(name) <TAB>  <TAB> if not definition: <TAB>  <TAB>  <TAB> IECore.msg( <TAB>  <TAB>  <TAB>  <TAB> IECore.Msg.Level.Error, <TAB>  <TAB>  <TAB>  <TAB> ""GafferImageUI.CatalogueUI"", <TAB>  <TAB>  <TAB>  <TAB> ""No column registered with name '%s'"" % name, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> continue <MASK> c = GafferUI.PathListingWidget.IconColumn(definition.title(), """", name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> c = GafferUI.PathListingWidget.StandardColumn(definition.title(), name) <TAB>  <TAB> columns.append(c) <TAB> return columns","if isinstance ( definition , IconColumn ) :",184
3120,"def _check_invalid_keys(self, section_name, section): <TAB> for key in section: <TAB>  <TAB> key_name = str(key) <TAB>  <TAB> valid_key_names = [s[0] for s in self.keys] <TAB>  <TAB> is_valid_key = key_name in valid_key_names <MASK> err_msg = ( <TAB>  <TAB>  <TAB>  <TAB> ""'{0}' is not a valid key name for '{1}'. Must "" ""be one of these: {2}"" <TAB>  <TAB>  <TAB> ).format(key_name, section_name, "", "".join(valid_key_names)) <TAB>  <TAB>  <TAB> raise InvalidConfig(err_msg)",if not is_valid_key :,160
3121,"def _get_startup_packages(lib_path: Path, packages) -> Set[str]: <TAB> names = set() <TAB> for path in lib_path.iterdir(): <TAB>  <TAB> name = path.name <TAB>  <TAB> if name == ""__pycache__"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if name.endswith("".py""): <TAB>  <TAB>  <TAB> names.add(name.split(""."")[0]) <MASK> names.add(name) <TAB> if packages: <TAB>  <TAB> packages = {package.lower().replace(""-"", ""_"") for package in packages} <TAB>  <TAB> if len(names & packages) == len(packages): <TAB>  <TAB>  <TAB> return packages <TAB> return names","elif path . is_dir ( ) and ""."" not in name :",159
3122,"def sortkeypicker(keynames): <TAB> negate = set() <TAB> for i, k in enumerate(keynames): <MASK> keynames[i] = k[1:] <TAB>  <TAB>  <TAB> negate.add(k[1:]) <TAB> def getit(adict): <TAB>  <TAB> composite = [adict[k] for k in keynames] <TAB>  <TAB> for i, (k, v) in enumerate(zip(keynames, composite)): <TAB>  <TAB>  <TAB> if k in negate: <TAB>  <TAB>  <TAB>  <TAB> composite[i] = -v <TAB>  <TAB> return composite <TAB> return getit","if k [ : 1 ] == ""-"" :",140
3123,"def iter_symbols(code): <TAB> """"""Yield names and strings used by `code` and its nested code objects"""""" <TAB> for name in code.co_names: <TAB>  <TAB> yield name <TAB> for const in code.co_consts: <TAB>  <TAB> if isinstance(const, six.string_types): <TAB>  <TAB>  <TAB> yield const <MASK> for name in iter_symbols(const): <TAB>  <TAB>  <TAB>  <TAB> yield name","elif isinstance ( const , CodeType ) :",104
3124,"def set_study_directions( <TAB> self, study_id: int, directions: Sequence[StudyDirection]) -> None: <TAB> with self._lock: <MASK> current_directions = self._studies[study_id].directions <TAB>  <TAB>  <TAB> if directions == current_directions: <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> elif ( <TAB>  <TAB>  <TAB>  <TAB> len(current_directions) == 1 <TAB>  <TAB>  <TAB>  <TAB> and current_directions[0] == StudyDirection.NOT_SET <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> self._studies[study_id].directions = list(directions) <TAB>  <TAB>  <TAB>  <TAB> self._backend.set_study_directions(study_id, directions) <TAB>  <TAB>  <TAB>  <TAB> return <TAB> self._backend.set_study_directions(study_id, directions)",if study_id in self . _studies :,198
3125,"def PreprocessConditionalStatement(self, IfList, ReplacedLine): <TAB> while self: <MASK> x = 1 <TAB>  <TAB> elif not IfList: <TAB>  <TAB>  <TAB> if self <= 2: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> RegionSizeGuid = 3 <TAB>  <TAB>  <TAB> if not RegionSizeGuid: <TAB>  <TAB>  <TAB>  <TAB> RegionLayoutLine = 5 <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> RegionLayoutLine = self.CurrentLineNumber <TAB> return 1",if self . __Token :,111
3126,"def _check_blocking(self, current_time): <TAB> if self._switch_flag is False: <TAB>  <TAB> active_greenlet = self._active_greenlet <MASK> self._notify_greenlet_blocked(active_greenlet, current_time) <TAB> self._switch_flag = False",if active_greenlet is not None and active_greenlet != self . _hub :,90
3127,"def detect(get_page): <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS: <TAB>  <TAB> page, headers, code = get_page(get=vector) <TAB>  <TAB> retval = ( <TAB>  <TAB>  <TAB> re.search(r""BlockDos\.net"", headers.get(HTTP_HEADER.SERVER, """"), re.I) <TAB>  <TAB>  <TAB> is not None <TAB>  <TAB> ) <MASK> break <TAB> return retval",if retval :,109
3128,"def _fastqc_data_section(self, section_name): <TAB> out = [] <TAB> in_section = False <TAB> data_file = os.path.join(self._dir, ""fastqc_data.txt"") <TAB> if os.path.exists(data_file): <TAB>  <TAB> with open(data_file) as in_handle: <TAB>  <TAB>  <TAB> for line in in_handle: <MASK> in_section = True <TAB>  <TAB>  <TAB>  <TAB> elif in_section: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if line.startswith("">>END""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB>  <TAB>  <TAB> out.append(line.rstrip(""\r\n"")) <TAB> return out","if line . startswith ( "">>%s"" % section_name ) :",173
3129,"def shortcut(self, input, ch_out, stride, is_first, name): <TAB> ch_in = input.shape[1] <TAB> if ch_in != ch_out or stride != 1: <MASK> return self.conv_bn_layer(input, ch_out, 1, stride, name=name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.conv_bn_layer_new(input, ch_out, 1, stride, name=name) <TAB> elif is_first: <TAB>  <TAB> return self.conv_bn_layer(input, ch_out, 1, stride, name=name) <TAB> else: <TAB>  <TAB> return input",if is_first or stride == 1 :,162
3130,"def get_value_from_string(self, string_value): <TAB> """"""Return internal representation starting from CFN/user-input value."""""" <TAB> param_value = self.get_default_value() <TAB> try: <TAB>  <TAB> if string_value is not None: <TAB>  <TAB>  <TAB> string_value = str(string_value).strip() <MASK> param_value = int(string_value) <TAB> except ValueError: <TAB>  <TAB> self.pcluster_config.warn( <TAB>  <TAB>  <TAB> ""Unable to convert the value '{0}' to an Integer. "" <TAB>  <TAB>  <TAB> ""Using default value for parameter '{1}'"".format(string_value, self.key) <TAB>  <TAB> ) <TAB> return param_value","if string_value != ""NONE"" :",172
3131,"def get_running(workers): <TAB> running = [] <TAB> for worker in workers: <TAB>  <TAB> current_test_name = worker.current_test_name <MASK> continue <TAB>  <TAB> dt = time.monotonic() - worker.start_time <TAB>  <TAB> if dt >= PROGRESS_MIN_TIME: <TAB>  <TAB>  <TAB> text = ""%s (%s)"" % (current_test_name, format_duration(dt)) <TAB>  <TAB>  <TAB> running.append(text) <TAB> return running",if not current_test_name :,120
3132,"def generate_data(self, request): <TAB> """"""Generate data for the widget."""""" <TAB> uptime = {} <TAB> cache_stats = get_cache_stats() <TAB> if cache_stats: <TAB>  <TAB> for hosts, stats in cache_stats: <TAB>  <TAB>  <TAB> if stats[""uptime""] > 86400: <TAB>  <TAB>  <TAB>  <TAB> uptime[""value""] = stats[""uptime""] / 60 / 60 / 24 <TAB>  <TAB>  <TAB>  <TAB> uptime[""unit""] = _(""days"") <MASK> uptime[""value""] = stats[""uptime""] / 60 / 60 <TAB>  <TAB>  <TAB>  <TAB> uptime[""unit""] = _(""hours"") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> uptime[""value""] = stats[""uptime""] / 60 <TAB>  <TAB>  <TAB>  <TAB> uptime[""unit""] = _(""minutes"") <TAB> return {""cache_stats"": cache_stats, ""uptime"": uptime}","elif stats [ ""uptime"" ] > 3600 :",195
3133,"def add_actors(self): <TAB> """"""Adds `self.actors` to the scene."""""" <TAB> if not self._actors_added: <TAB>  <TAB> self.reader.render_window = self.scene.render_window <TAB>  <TAB> self._update_reader() <TAB>  <TAB> self._actors_added = True <MASK> self._visible_changed(self.visible) <TAB>  <TAB> self.scene.render()",if not self . visible :,103
3134,"def _add_uniqu_suffix(self, titles): <TAB> counters = dict() <TAB> titles_with_suffix = [] <TAB> for title in titles: <TAB>  <TAB> counters[title] = counters[title] + 1 if title in counters else 1 <MASK> title = f""{title} ({counters[title]})"" <TAB>  <TAB> titles_with_suffix.append(title) <TAB> return titles_with_suffix",if counters [ title ] > 1 :,103
3135,"def _verify_udf_resources(self, job, config): <TAB> udf_resources = config.get(""userDefinedFunctionResources"", ()) <TAB> self.assertEqual(len(job.udf_resources), len(udf_resources)) <TAB> for found, expected in zip(job.udf_resources, udf_resources): <MASK> self.assertEqual(found.udf_type, ""resourceUri"") <TAB>  <TAB>  <TAB> self.assertEqual(found.value, expected[""resourceUri""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertEqual(found.udf_type, ""inlineCode"") <TAB>  <TAB>  <TAB> self.assertEqual(found.value, expected[""inlineCode""])","if ""resourceUri"" in expected :",157
3136,"def __init__( <TAB> self, layout, value=None, string=None, *, dtype: np.dtype = np.float64) -> None: <TAB> """"""Constructor."""""" <TAB> self.layout = layout <TAB> if value is None: <MASK> self.value = np.zeros((self.layout.gaDims,), dtype=dtype) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.value = layout.parse_multivector(string).value <TAB> else: <TAB>  <TAB> self.value = np.array(value) <TAB>  <TAB> if self.value.shape != (self.layout.gaDims,): <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""value must be a sequence of length %s"" % self.layout.gaDims <TAB>  <TAB>  <TAB> )",if string is None :,180
3137,"def read_file(filename, print_error=True): <TAB> """"""Returns the contents of a file."""""" <TAB> try: <TAB>  <TAB> for encoding in [""utf-8"", ""latin1""]: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> with io.open(filename, encoding=encoding) as fp: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return fp.read() <TAB>  <TAB>  <TAB> except UnicodeDecodeError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB> except IOError as exception: <MASK> print(exception, file=sys.stderr) <TAB>  <TAB> return None",if print_error :,126
3138,"def get_albums_for_iter(self, iter_): <TAB> obj = self.get_value(iter_) <TAB> if isinstance(obj, AlbumNode): <TAB>  <TAB> return {obj.album} <TAB> albums = set() <TAB> for child_iter, value in self.iterrows(iter_): <MASK> albums.add(value.album) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> albums.update(self.get_albums_for_iter(child_iter)) <TAB> return albums","if isinstance ( value , AlbumNode ) :",120
3139,"def wait_til_ready(cls, connector=None): <TAB> if connector is None: <TAB>  <TAB> connector = cls.connector <TAB> while True: <TAB>  <TAB> now = time.time() <TAB>  <TAB> next_iteration = now // 1.0 + 1 <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> await cls._clock.run_til(next_iteration) <TAB>  <TAB> await asyncio.sleep(1.0)",if connector . ready :,106
3140,"def remove_property(self, key):  # type: (str) -> None <TAB> with self.secure() as config: <TAB>  <TAB> keys = key.split(""."") <TAB>  <TAB> current_config = config <TAB>  <TAB> for i, key in enumerate(keys): <TAB>  <TAB>  <TAB> if key not in current_config: <TAB>  <TAB>  <TAB>  <TAB> return <MASK> del current_config[key] <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> current_config = current_config[key]",if i == len ( keys ) - 1 :,122
3141,"def get(self, hash160, default=None): <TAB> v = self.p2s_for_hash(hash160) <MASK> return v <TAB> if hash160 not in self._secret_exponent_cache: <TAB>  <TAB> v = self.path_for_hash160(hash160) <TAB>  <TAB> if v: <TAB>  <TAB>  <TAB> fingerprint, path = v <TAB>  <TAB>  <TAB> for key in self._secrets.get(fingerprint, []): <TAB>  <TAB>  <TAB>  <TAB> subkey = key.subkey_for_path(path) <TAB>  <TAB>  <TAB>  <TAB> self._add_key_to_cache(subkey) <TAB> return self._secret_exponent_cache.get(hash160, default)",if v :,155
3142,"def fetch_all(self, api_client, fetchstatuslogger, q, targets): <TAB> self.fetchstatuslogger = fetchstatuslogger <TAB> if targets != None: <TAB>  <TAB> # Ensure targets is a tuple <MASK> targets = tuple( <TAB>  <TAB>  <TAB>  <TAB> targets, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> elif type(targets) != tuple: <TAB>  <TAB>  <TAB> targets = tuple(targets) <TAB> for target in targets: <TAB>  <TAB> self._fetch_targets(api_client, q, target)",if type ( targets ) != list and type ( targets ) != tuple :,130
3143,"def dgl_mp_batchify_fn(data): <TAB> if isinstance(data[0], tuple): <TAB>  <TAB> data = zip(*data) <TAB>  <TAB> return [dgl_mp_batchify_fn(i) for i in data] <TAB> for dt in data: <MASK> if isinstance(dt, dgl.DGLGraph): <TAB>  <TAB>  <TAB>  <TAB> return [d for d in data if isinstance(d, dgl.DGLGraph)] <TAB>  <TAB>  <TAB> elif isinstance(dt, nd.NDArray): <TAB>  <TAB>  <TAB>  <TAB> pad = Pad(axis=(1, 2), num_shards=1, ret_length=False) <TAB>  <TAB>  <TAB>  <TAB> data_list = [dt for dt in data if dt is not None] <TAB>  <TAB>  <TAB>  <TAB> return pad(data_list)",if dt is not None :,183
3144,"def capture_server(evt, buf, serv): <TAB> try: <TAB>  <TAB> serv.listen(5) <TAB>  <TAB> conn, addr = serv.accept() <TAB> except socket.timeout: <TAB>  <TAB> pass <TAB> else: <TAB>  <TAB> n = 200 <TAB>  <TAB> while n > 0: <TAB>  <TAB>  <TAB> r, w, e = select.select([conn], [], []) <MASK> data = conn.recv(10) <TAB>  <TAB>  <TAB>  <TAB> # keep everything except for the newline terminator <TAB>  <TAB>  <TAB>  <TAB> buf.write(data.replace(""\n"", """")) <TAB>  <TAB>  <TAB>  <TAB> if ""\n"" in data: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> n -= 1 <TAB>  <TAB>  <TAB> time.sleep(0.01) <TAB>  <TAB> conn.close() <TAB> finally: <TAB>  <TAB> serv.close() <TAB>  <TAB> evt.set()",if r :,195
3145,"def elem(): <TAB> if ints_only: <TAB>  <TAB> return random.randint(0, 10000000000) <TAB> else: <TAB>  <TAB> t = random.randint(0, 2) <TAB>  <TAB> if t == 0: <TAB>  <TAB>  <TAB> return random.randint(0, 10000000000) <TAB>  <TAB> elif t == 1: <TAB>  <TAB>  <TAB> return float(random.randint(0, 10000000000)) <MASK> return strings[random.randint(0, len(strings) - 1)] <TAB>  <TAB> return random_string(random.randint(100, 1000))",elif strings is not None :,132
3146,"def has_changed(self, initial, data): <TAB> if self.disabled: <TAB>  <TAB> return False <TAB> if initial is None: <TAB>  <TAB> initial = ["""" for x in range(0, len(data))] <TAB> else: <MASK> initial = self.widget.decompress(initial) <TAB> for field, initial, data in zip(self.fields, initial, data): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> initial = field.to_python(initial) <TAB>  <TAB> except ValidationError: <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> if field.has_changed(initial, data): <TAB>  <TAB>  <TAB> return True <TAB> return False","if not isinstance ( initial , list ) :",151
3147,"def _load_testfile(filename, package, module_relative): <TAB> if module_relative: <TAB>  <TAB> package = _normalize_module(package, 3) <TAB>  <TAB> filename = _module_relative_path(package, filename) <MASK> if hasattr(package.__loader__, ""get_data""): <TAB>  <TAB>  <TAB>  <TAB> file_contents = package.__loader__.get_data(filename) <TAB>  <TAB>  <TAB>  <TAB> # get_data() opens files as 'rb', so one must do the equivalent <TAB>  <TAB>  <TAB>  <TAB> # conversion as universal newlines would do. <TAB>  <TAB>  <TAB>  <TAB> return file_contents.replace(os.linesep, ""\n""), filename <TAB> return open(filename).read(), filename","if hasattr ( package , ""__loader__"" ) :",163
3148,"def release(self): <TAB> tid = _thread.get_ident() <TAB> with self.lock: <TAB>  <TAB> if self.owner != tid: <TAB>  <TAB>  <TAB> raise RuntimeError(""cannot release un-acquired lock"") <TAB>  <TAB> assert self.count > 0 <TAB>  <TAB> self.count -= 1 <TAB>  <TAB> if self.count == 0: <TAB>  <TAB>  <TAB> self.owner = None <MASK> self.waiters -= 1 <TAB>  <TAB>  <TAB>  <TAB> self.wakeup.release()",if self . waiters :,117
3149,"def stage( <TAB> self, x, num_modules, num_blocks, channels, multi_scale_output=True, name=None): <TAB> out = x <TAB> for i in range(num_modules): <MASK> out = self.high_resolution_module( <TAB>  <TAB>  <TAB>  <TAB> out, <TAB>  <TAB>  <TAB>  <TAB> num_blocks, <TAB>  <TAB>  <TAB>  <TAB> channels, <TAB>  <TAB>  <TAB>  <TAB> multi_scale_output=False, <TAB>  <TAB>  <TAB>  <TAB> name=name + ""_"" + str(i + 1), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> out = self.high_resolution_module( <TAB>  <TAB>  <TAB>  <TAB> out, num_blocks, channels, name=name + ""_"" + str(i + 1) <TAB>  <TAB>  <TAB> ) <TAB> return out",if i == num_modules - 1 and multi_scale_output == False :,193
3150,"def changeFrontAlteration(intV, alter): <TAB> # fati = front alteration transpose interval <TAB> fati = self.frontAlterationTransposeInterval <TAB> if fati: <TAB>  <TAB> newFati = interval.add([fati, intV]) <TAB>  <TAB> self.frontAlterationTransposeInterval = newFati <TAB>  <TAB> self.frontAlterationAccidental.alter = ( <TAB>  <TAB>  <TAB> self.frontAlterationAccidental.alter + alter <TAB>  <TAB> ) <MASK> self.frontAlterationTransposeInterval = None <TAB>  <TAB>  <TAB> self.frontAlterationAccidental = None <TAB> else: <TAB>  <TAB> self.frontAlterationTransposeInterval = intV <TAB>  <TAB> self.frontAlterationAccidental = pitch.Accidental(alter)",if self . frontAlterationAccidental . alter == 0 :,199
3151,"def set_to_train(self): <TAB> for T in self.trainable_attributes(): <TAB>  <TAB> for k, v in T.items(): <MASK> c_f.set_requires_grad(v, requires_grad=False) <TAB>  <TAB>  <TAB>  <TAB> v.eval() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> v.train() <TAB> self.maybe_freeze_trunk_batchnorm()",if k in self . freeze_these :,107
3152,"def _migrate(self, sig=None, compact=True): <TAB> with self.lock: <TAB>  <TAB> sig = sig or self.sig <MASK> return <TAB>  <TAB> if sig in self.WORDS and len(self.WORDS[sig]) > 0: <TAB>  <TAB>  <TAB> PostingList.Append( <TAB>  <TAB>  <TAB>  <TAB> self.session, sig, self.WORDS[sig], sig=sig, compact=compact <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> del self.WORDS[sig]",if sig in GPL_NEVER_MIGRATE :,123
3153,"def on_prediction_step(self, args, state, control, eval_dataloader=None, **kwargs): <TAB> if self.prediction_bar is None: <MASK> self.prediction_bar = self.training_tracker.add_child(len(eval_dataloader)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.prediction_bar = NotebookProgressBar(len(eval_dataloader)) <TAB>  <TAB> self.prediction_bar.update(1) <TAB> else: <TAB>  <TAB> self.prediction_bar.update(self.prediction_bar.value + 1)",if self . training_tracker is not None :,137
3154,"def show(self, indent=0): <TAB> """"""Pretty print this structure."""""" <TAB> if indent == 0: <TAB>  <TAB> print(""struct {}"".format(self.name)) <TAB> for field in self.fields: <TAB>  <TAB> if field.offset is None: <TAB>  <TAB>  <TAB> offset = ""0x??"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> offset = ""0x{:02x}"".format(field.offset) <TAB>  <TAB> print(""{}+{} {} {}"".format("" "" * indent, offset, field.name, field.type)) <MASK> field.type.show(indent + 1)","if isinstance ( field . type , Structure ) :",143
3155,"def __exit__(self, exc, value, tb): <TAB> for key in self.overrides.keys(): <TAB>  <TAB> old_value = self.old[key] <MASK> delattr(self.instance, key) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> setattr(self.instance, key, old_value) <TAB> self.instance.save()",if old_value is NULL :,88
3156,"def complete(self, block): <TAB> with self._condition: <MASK> return False <TAB>  <TAB> if self._complete(): <TAB>  <TAB>  <TAB> self._calculate_state_root_if_not_already_done() <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> if block: <TAB>  <TAB>  <TAB> self._condition.wait_for(self._complete) <TAB>  <TAB>  <TAB> self._calculate_state_root_if_not_already_done() <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> return False",if not self . _final :,117
3157,"def parseArguments(self): <TAB> args = [] <TAB> self.expect(""("") <TAB> if not self.match("")""): <TAB>  <TAB> while self.startIndex < self.length: <TAB>  <TAB>  <TAB> args.append(self.isolateCoverGrammar(self.parseAssignmentExpression)) <MASK> break <TAB>  <TAB>  <TAB> self.expectCommaSeparator() <TAB> self.expect("")"") <TAB> return args","if self . match ( "")"" ) :",95
3158,"def isValidDateString(config_param_name, value, valid_value): <TAB> try: <TAB>  <TAB> if value == ""DD-MM-YYYY"": <TAB>  <TAB>  <TAB> return value <TAB>  <TAB> day, month, year = value.split(""-"") <MASK> raise DateStringValueError(config_param_name, value) <TAB>  <TAB> if int(month) < 1 or int(month) > 12: <TAB>  <TAB>  <TAB> raise DateStringValueError(config_param_name, value) <TAB>  <TAB> if int(year) < 1900 or int(year) > 2013: <TAB>  <TAB>  <TAB> raise DateStringValueError(config_param_name, value) <TAB>  <TAB> return value <TAB> except Exception: <TAB>  <TAB> raise DateStringValueError(config_param_name, value)",if int ( day ) < 1 or int ( day ) > 31 :,187
3159,"def build_tree(path): <TAB> tree = Tree() <TAB> for basename, entry in trees[path].items(): <MASK> mode = stat.S_IFDIR <TAB>  <TAB>  <TAB> sha = build_tree(pathjoin(path, basename)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> (mode, sha) = entry <TAB>  <TAB> tree.add(basename, mode, sha) <TAB> object_store.add_object(tree) <TAB> return tree.id","if isinstance ( entry , dict ) :",113
3160,"def get_quarantine_count(self): <TAB> """"""get obj/container/account quarantine counts"""""" <TAB> qcounts = {""objects"": 0, ""containers"": 0, ""accounts"": 0} <TAB> qdir = ""quarantined"" <TAB> for device in os.listdir(self.devices): <TAB>  <TAB> for qtype in qcounts: <TAB>  <TAB>  <TAB> qtgt = os.path.join(self.devices, device, qdir, qtype) <MASK> linkcount = os.lstat(qtgt).st_nlink <TAB>  <TAB>  <TAB>  <TAB> if linkcount > 2: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> qcounts[qtype] += linkcount - 2 <TAB> return qcounts",if os . path . exists ( qtgt ) :,171
3161,"def _is_static_shape(self, shape): <TAB> if shape is None or not isinstance(shape, list): <TAB>  <TAB> return False <TAB> for dim_value in shape: <MASK> return False <TAB>  <TAB> if dim_value < 0: <TAB>  <TAB>  <TAB> raise Exception(""Negative dimension is illegal: %d"" % dim_value) <TAB> return True","if not isinstance ( dim_value , int ) :",94
3162,"def BraceDetectAll(words): <TAB> # type: (List[compound_word]) -> List[word_t] <TAB> """"""Return a new list of words, possibly with BracedTree instances."""""" <TAB> out = []  # type: List[word_t] <TAB> for w in words: <TAB>  <TAB> # The shortest possible brace expansion is {,}.  This heuristic prevents <TAB>  <TAB> # a lot of garbage from being created, since otherwise nearly every word <TAB>  <TAB> # would be checked.  We could be even more precise but this is cheap. <TAB>  <TAB> if len(w.parts) >= 3: <TAB>  <TAB>  <TAB> brace_tree = _BraceDetect(w) <MASK> out.append(brace_tree) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> out.append(w) <TAB> return out",if brace_tree :,191
3163,"def __init__(original, self, *args, **kwargs): <TAB> data = args[0] if len(args) > 0 else kwargs.get(""data"") <TAB> if data is not None: <TAB>  <TAB> try: <MASK> raise Exception( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""cannot gather example input when dataset is loaded from a file."" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> input_example_info = _InputExampleInfo( <TAB>  <TAB>  <TAB>  <TAB> input_example=deepcopy(data[:INPUT_EXAMPLE_SAMPLE_ROWS]) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> input_example_info = _InputExampleInfo(error_msg=str(e)) <TAB>  <TAB> setattr(self, ""input_example_info"", input_example_info) <TAB> original(self, *args, **kwargs)","if isinstance ( data , str ) :",198
3164,"def setRow(self, row, vals): <TAB> if row > self.rowCount() - 1: <TAB>  <TAB> self.setRowCount(row + 1) <TAB> for col in range(len(vals)): <TAB>  <TAB> val = vals[col] <TAB>  <TAB> item = self.itemClass(val, row) <TAB>  <TAB> item.setEditable(self.editable) <TAB>  <TAB> sortMode = self.sortModes.get(col, None) <MASK> item.setSortMode(sortMode) <TAB>  <TAB> format = self._formats.get(col, self._formats[None]) <TAB>  <TAB> item.setFormat(format) <TAB>  <TAB> self.items.append(item) <TAB>  <TAB> self.setItem(row, col, item) <TAB>  <TAB> item.setValue(val)  # Required--the text-change callback is invoked",if sortMode is not None :,198
3165,"def wakeUp(self): <TAB> """"""Write one byte to the pipe, and flush it."""""" <TAB> # We don't use fdesc.writeToFD since we need to distinguish <TAB> # between EINTR (try again) and EAGAIN (do nothing). <TAB> if self.o is not None: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> util.untilConcludes(os.write, self.o, b""x"") <TAB>  <TAB> except OSError as e: <TAB>  <TAB>  <TAB> # XXX There is no unit test for raising the exception <TAB>  <TAB>  <TAB> # for other errnos. See #4285. <MASK> raise",if e . errno != errno . EAGAIN :,158
3166,"def _setup(self, field_name, owner_model): <TAB> # Resolve possible name-based model references. <TAB> resolved_classes = [] <TAB> for m in self.model_classes: <MASK> if m == owner_model.__name__: <TAB>  <TAB>  <TAB>  <TAB> resolved_classes.append(owner_model) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise Exception( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""PolyModelType: Unable to resolve model '{}'."".format(m) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> resolved_classes.append(m) <TAB> self.model_classes = tuple(resolved_classes) <TAB> super(PolyModelType, self)._setup(field_name, owner_model)","if isinstance ( m , string_type ) :",176
3167,"def _wrap_forwarded(self, key, value): <TAB> if isinstance(value, SourceCode) and value.late_binding: <TAB>  <TAB> # get cached return value if present <TAB>  <TAB> value_ = self._late_binding_returnvalues.get(key, KeyError) <TAB>  <TAB> if value_ is KeyError: <TAB>  <TAB>  <TAB> # evaluate the late-bound function <TAB>  <TAB>  <TAB> value_ = self._eval_late_binding(value) <TAB>  <TAB>  <TAB> schema = self.late_bind_schemas.get(key) <MASK> value_ = schema.validate(value_) <TAB>  <TAB>  <TAB> # cache result of late bound func <TAB>  <TAB>  <TAB> self._late_binding_returnvalues[key] = value_ <TAB>  <TAB> return value_ <TAB> else: <TAB>  <TAB> return value",if schema is not None :,187
3168,"def convert(self, ctx, argument): <TAB> arg = argument.replace(""0x"", """").lower() <TAB> if arg[0] == ""#"": <TAB>  <TAB> arg = arg[1:] <TAB> try: <TAB>  <TAB> value = int(arg, base=16) <MASK> raise BadColourArgument(arg) <TAB>  <TAB> return discord.Colour(value=value) <TAB> except ValueError: <TAB>  <TAB> arg = arg.replace("" "", ""_"") <TAB>  <TAB> method = getattr(discord.Colour, arg, None) <TAB>  <TAB> if arg.startswith(""from_"") or method is None or not inspect.ismethod(method): <TAB>  <TAB>  <TAB> raise BadColourArgument(arg) <TAB>  <TAB> return method()",if not ( 0 <= value <= 0xFFFFFF ) :,172
3169,"def get_versions(*, all=False, quiet=None): <TAB> import bonobo <TAB> from bonobo.util.pkgs import bonobo_packages <TAB> yield _format_version(bonobo, quiet=quiet) <TAB> if all: <TAB>  <TAB> for name in sorted(bonobo_packages): <MASK> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> mod = __import__(name.replace(""-"", ""_"")) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield _format_version(mod, name=name, quiet=quiet) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> except Exception as exc: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield ""{} ({})"".format(name, exc) <TAB>  <TAB>  <TAB>  <TAB> except ImportError as exc: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield ""{} is not importable ({})."".format(name, exc)","if name != ""bonobo"" :",188
3170,"def assertOperationsInjected(self, plan, **kwargs): <TAB> for migration, _backward in plan: <TAB>  <TAB> operations = iter(migration.operations) <TAB>  <TAB> for operation in operations: <MASK> next_operation = next(operations) <TAB>  <TAB>  <TAB>  <TAB> self.assertIsInstance( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> next_operation, contenttypes_management.RenameContentType <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(next_operation.app_label, migration.app_label) <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(next_operation.old_model, operation.old_name_lower) <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(next_operation.new_model, operation.new_name_lower)","if isinstance ( operation , migrations . RenameModel ) :",177
3171,"def valid_localparts(strip_delimiters=False): <TAB> for line in ABRIDGED_LOCALPART_VALID_TESTS.split(""\n""): <TAB>  <TAB> # strip line, skip over empty lines <TAB>  <TAB> line = line.strip() <TAB>  <TAB> if line == """": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # skip over comments or empty lines <TAB>  <TAB> match = COMMENT.match(line) <TAB>  <TAB> if match: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # skip over localparts with delimiters <MASK> if "","" in line or "";"" in line: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> yield line",if strip_delimiters :,145
3172,"def read_lccn(line, is_marc8=False): <TAB> found = [] <TAB> for k, v in get_raw_subfields(line, [""a""]): <TAB>  <TAB> lccn = v.strip() <TAB>  <TAB> if re_question.match(lccn): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> m = re_lccn.search(lccn) <TAB>  <TAB> if not m: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # remove letters and bad chars <TAB>  <TAB> lccn = re_letters_and_bad.sub("""", m.group(1)).strip() <MASK> found.append(lccn) <TAB> return found",if lccn :,151
3173,"def test_named_parameters_and_constraints(self): <TAB> likelihood = gpytorch.likelihoods.GaussianLikelihood() <TAB> model = ExactGPModel(None, None, likelihood) <TAB> for name, _param, constraint in model.named_parameters_and_constraints(): <TAB>  <TAB> if name == ""likelihood.noise_covar.raw_noise"": <TAB>  <TAB>  <TAB> self.assertIsInstance(constraint, gpytorch.constraints.GreaterThan) <TAB>  <TAB> elif name == ""mean_module.constant"": <TAB>  <TAB>  <TAB> self.assertIsNone(constraint) <TAB>  <TAB> elif name == ""covar_module.raw_outputscale"": <TAB>  <TAB>  <TAB> self.assertIsInstance(constraint, gpytorch.constraints.Positive) <MASK> self.assertIsInstance(constraint, gpytorch.constraints.Positive)","elif name == ""covar_module.base_kernel.raw_lengthscale"" :",192
3174,"def _cleanupSocket(self): <TAB> """"""Close the Connection's socket."""""" <TAB> try: <TAB>  <TAB> self._sock.shutdown(socket.SHUT_WR) <TAB> except: <TAB>  <TAB> return <TAB> try: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> r, w, e = select.select([self._sock], [], []) <MASK> break <TAB> except: <TAB>  <TAB> pass <TAB> self._sock.close()",if not r or not self . _sock . recv ( 1024 ) :,113
3175,"def fadeIn(self, acts=None, t=None, duration=None): <TAB> """"""Gradually switch on the input list of meshes by increasing opacity."""""" <TAB> if self.bookingMode: <TAB>  <TAB> acts, t, duration, rng = self._parse(acts, t, duration) <TAB>  <TAB> for tt in rng: <TAB>  <TAB>  <TAB> alpha = linInterpolate(tt, [t, t + duration], [0, 1]) <TAB>  <TAB>  <TAB> self.events.append((tt, self.fadeIn, acts, alpha)) <TAB> else: <TAB>  <TAB> for a in self._performers: <MASK> continue <TAB>  <TAB>  <TAB> a.alpha(self._inputvalues) <TAB> return self",if a . alpha ( ) >= self . _inputvalues :,172
3176,"def get_config_updates_recursive(self): <TAB> config_updates = self.config_updates.copy() <TAB> for sr_path, subrunner in self.subrunners.items(): <MASK> continue <TAB>  <TAB> update = subrunner.get_config_updates_recursive() <TAB>  <TAB> if update: <TAB>  <TAB>  <TAB> config_updates[rel_path(self.path, sr_path)] = update <TAB> return config_updates","if not is_prefix ( self . path , sr_path ) :",115
3177,"def setArgs(self, **kwargs): <TAB> """"""See GridSearchCostGamma"""""" <TAB> for key, value in list(kwargs.items()): <TAB>  <TAB> if key in (""folds"", ""nfolds""): <TAB>  <TAB>  <TAB> self._n_folds = int(value) <MASK> self._validator_kwargs[""max_epochs""] = value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> GridSearchDOE.setArgs(self, **{key: value})","elif key in ( ""max_epochs"" ) :",111
3178,"def _parse_composite_axis(composite_axis_name: str): <TAB> axes_names = [axis for axis in composite_axis_name.split("" "") if len(axis) > 0] <TAB> for axis in axes_names: <MASK> continue <TAB>  <TAB> assert ""a"" <= axis[0] <= ""z"" <TAB>  <TAB> for letter in axis: <TAB>  <TAB>  <TAB> assert str.isdigit(letter) or ""a"" <= letter <= ""z"" <TAB> return axes_names","if axis == ""_"" :",117
3179,"def visit_For(self, node, for_branch=""body"", **kwargs): <TAB> if for_branch == ""body"": <TAB>  <TAB> self.sym_visitor.visit(node.target, store_as_param=True) <TAB>  <TAB> branch = node.body <TAB> elif for_branch == ""else"": <TAB>  <TAB> branch = node.else_ <TAB> elif for_branch == ""test"": <TAB>  <TAB> self.sym_visitor.visit(node.target, store_as_param=True) <MASK> self.sym_visitor.visit(node.test) <TAB>  <TAB> return <TAB> else: <TAB>  <TAB> raise RuntimeError(""Unknown for branch"") <TAB> for item in branch or (): <TAB>  <TAB> self.sym_visitor.visit(item)",if node . test is not None :,178
3180,def contains_only_whitespace(node): <TAB> if is_tag(node): <MASK> if not any([unicode(s).strip() for s in node.contents]): <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False,if not any ( [ not is_text ( s ) for s in node . contents ] ) :,72
3181,"def dir_tag_click(event): <TAB> mouse_index = self.path_bar.index(""@%d,%d"" % (event.x, event.y)) <TAB> lineno = int(float(mouse_index)) <TAB> if lineno == 1: <TAB>  <TAB> self.request_focus_into("""") <TAB> else: <TAB>  <TAB> assert lineno == 2 <TAB>  <TAB> dir_range = get_dir_range(event) <TAB>  <TAB> if dir_range: <TAB>  <TAB>  <TAB> _, end_index = dir_range <TAB>  <TAB>  <TAB> path = self.path_bar.get(""2.0"", end_index) <MASK> path += ""\\"" <TAB>  <TAB>  <TAB> self.request_focus_into(path)","if path . endswith ( "":"" ) :",168
3182,"def validate_employee_id(self): <TAB> if self.employee: <TAB>  <TAB> sales_person = frappe.db.get_value(""Sales Person"", {""employee"": self.employee}) <MASK> frappe.throw( <TAB>  <TAB>  <TAB>  <TAB> _(""Another Sales Person {0} exists with the same Employee id"").format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> sales_person <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> )",if sales_person and sales_person != self . name :,116
3183,"def pytest_collection_modifyitems(items): <TAB> for item in items: <TAB>  <TAB> if item.nodeid.startswith(""tests/infer""): <TAB>  <TAB>  <TAB> if ""stage"" not in item.keywords: <TAB>  <TAB>  <TAB>  <TAB> item.add_marker(pytest.mark.stage(""unit"")) <MASK> item.add_marker(pytest.mark.init(rng_seed=123))","if ""init"" not in item . keywords :",102
3184,"def poll(self, timeout): <TAB> if timeout < 0: <TAB>  <TAB> timeout = None  # kqueue behaviour <TAB> events = self._kqueue.control(None, KqueueLoop.MAX_EVENTS, timeout) <TAB> results = defaultdict(lambda: POLL_NULL) <TAB> for e in events: <TAB>  <TAB> fd = e.ident <TAB>  <TAB> if e.filter == select.KQ_FILTER_READ: <TAB>  <TAB>  <TAB> results[fd] |= POLL_IN <MASK> results[fd] |= POLL_OUT <TAB> return results.items()",elif e . filter == select . KQ_FILTER_WRITE :,142
3185,"def _read_dimensions(self, *dimnames, **kwargs): <TAB> path = kwargs.get(""path"", ""/"") <TAB> try: <MASK> return [self.rootgrp.dimensions[dname] for dname in dimnames] <TAB>  <TAB> group = self.path2group[path] <TAB>  <TAB> return [group.dimensions[dname] for dname in dimnames] <TAB> except KeyError: <TAB>  <TAB> raise self.Error( <TAB>  <TAB>  <TAB> ""In file %s:\nError while reading dimensions: `%s` with kwargs: `%s`"" <TAB>  <TAB>  <TAB> % (self.path, dimnames, kwargs) <TAB>  <TAB> )","if path == ""/"" :",150
3186,"def spam_to_me(address): <TAB> sock = eventlet.connect(address) <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> sock.sendall(b""hello world"") <TAB>  <TAB>  <TAB> # Arbitrary delay to not use all available CPU, keeps the test <TAB>  <TAB>  <TAB> # running quickly and reliably under a second <TAB>  <TAB>  <TAB> time.sleep(0.001) <TAB>  <TAB> except socket.error as e: <MASK> return <TAB>  <TAB>  <TAB> raise",if get_errno ( e ) == errno . EPIPE :,122
3187,"def has_hash_of(self, destpath, code, package_level): <TAB> """"""Determine if a file has the hash of the code."""""" <TAB> if destpath is not None and os.path.isfile(destpath): <TAB>  <TAB> with univ_open(destpath, ""r"") as opened: <TAB>  <TAB>  <TAB> compiled = readfile(opened) <TAB>  <TAB> hashash = gethash(compiled) <MASK> return True <TAB> return False","if hashash is not None and hashash == self . comp . genhash ( code , package_level ) :",126
3188,"def insert(self, index, item): <TAB> if len(self.lists) == 1: <TAB>  <TAB> self.lists[0].insert(index, item) <TAB>  <TAB> self._balance_list(0) <TAB> else: <TAB>  <TAB> list_idx, rel_idx = self._translate_index(index) <MASK> raise IndexError() <TAB>  <TAB> self.lists[list_idx].insert(rel_idx, item) <TAB>  <TAB> self._balance_list(list_idx) <TAB> return",if list_idx is None :,123
3189,"def _parse_class_simplified(symbol): <TAB> results = {} <TAB> name = symbol.name + ""("" <TAB> name += "", "".join([analyzer.expand_attribute(base) for base in symbol.bases]) <TAB> name += "")"" <TAB> for sym in symbol.body: <TAB>  <TAB> if isinstance(sym, ast.FunctionDef): <TAB>  <TAB>  <TAB> result = _parse_function_simplified(sym, symbol.name) <TAB>  <TAB>  <TAB> results.update(result) <MASK> result = _parse_class_simplified(sym) <TAB>  <TAB>  <TAB> results.update(result) <TAB> lineno = symbol.lineno <TAB> for decorator in symbol.decorator_list: <TAB>  <TAB> lineno += 1 <TAB> results[lineno] = (name, ""c"") <TAB> return results","elif isinstance ( sym , ast . ClassDef ) :",181
3190,"def append_vars(pairs, result): <TAB> for name, value in sorted(pairs.items()): <TAB>  <TAB> if isinstance(value, list): <TAB>  <TAB>  <TAB> value = ""[%s]"" % "","".join(value) <MASK> result.append(""%s:%s=%s"" % (package, name, value)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result.append(""%s=%s"" % (name, value))",if package :,99
3191,"def nextEditable(self): <TAB> """"""Moves focus of the cursor to the next editable window"""""" <TAB> if self.currentEditable is None: <MASK> self._currentEditableRef = self._editableChildren[0] <TAB> else: <TAB>  <TAB> for ref in weakref.getweakrefs(self.currentEditable): <TAB>  <TAB>  <TAB> if ref in self._editableChildren: <TAB>  <TAB>  <TAB>  <TAB> cei = self._editableChildren.index(ref) <TAB>  <TAB>  <TAB>  <TAB> nei = cei + 1 <TAB>  <TAB>  <TAB>  <TAB> if nei >= len(self._editableChildren): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> nei = 0 <TAB>  <TAB>  <TAB>  <TAB> self._currentEditableRef = self._editableChildren[nei] <TAB> return self.currentEditable",if len ( self . _editableChildren ) :,179
3192,"def everythingIsUnicode(d): <TAB> """"""Takes a dictionary, recursively verifies that every value is unicode"""""" <TAB> for k, v in d.iteritems(): <TAB>  <TAB> if isinstance(v, dict) and k != ""headers"": <TAB>  <TAB>  <TAB> if not everythingIsUnicode(v): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> elif isinstance(v, list): <TAB>  <TAB>  <TAB> for i in v: <TAB>  <TAB>  <TAB>  <TAB> if isinstance(i, dict) and not everythingIsUnicode(i): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB>  <TAB> elif isinstance(i, _bytes): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <MASK> return False <TAB> return True","elif isinstance ( v , _bytes ) :",158
3193,"def is_valid(sample): <TAB> if sample is None: <TAB>  <TAB> return False <TAB> if isinstance(sample, tuple): <TAB>  <TAB> for s in sample: <TAB>  <TAB>  <TAB> if s is None: <TAB>  <TAB>  <TAB>  <TAB> return False <MASK> return False <TAB>  <TAB>  <TAB> elif isinstance(s, collections.abc.Sequence) and len(s) == 0: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return True","elif isinstance ( s , np . ndarray ) and s . size == 0 :",114
3194,"def scan_resource_conf(self, conf): <TAB> if ""properties"" in conf: <TAB>  <TAB> if ""attributes"" in conf[""properties""]: <TAB>  <TAB>  <TAB> if ""exp"" in conf[""properties""][""attributes""]: <MASK> return CheckResult.PASSED <TAB> return CheckResult.FAILED","if conf [ ""properties"" ] [ ""attributes"" ] [ ""exp"" ] :",82
3195,"def encode(self): <TAB> if self.expr in gpregs.expr: <TAB>  <TAB> self.value = gpregs.expr.index(self.expr) <TAB>  <TAB> self.parent.rot2.value = 0 <TAB> elif isinstance(self.expr, ExprOp) and self.expr.op == allshifts[3]: <TAB>  <TAB> reg, value = self.expr.args <MASK> return False <TAB>  <TAB> self.value = gpregs.expr.index(reg) <TAB>  <TAB> if not isinstance(value, ExprInt): <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> value = int(value) <TAB>  <TAB> if not value in [8, 16, 24]: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> self.parent.rot2.value = value // 8 <TAB> return True",if reg not in gpregs . expr :,192
3196,"def validate_transaction_reference(self): <TAB> bank_account = self.paid_to if self.payment_type == ""Receive"" else self.paid_from <TAB> bank_account_type = frappe.db.get_value(""Account"", bank_account, ""account_type"") <TAB> if bank_account_type == ""Bank"": <MASK> frappe.throw( <TAB>  <TAB>  <TAB>  <TAB> _(""Reference No and Reference Date is mandatory for Bank transaction"") <TAB>  <TAB>  <TAB> )",if not self . reference_no or not self . reference_date :,128
3197,"def monad(self): <TAB> if not self.cls_bl_idname: <TAB>  <TAB> return None <TAB> for monad in bpy.data.node_groups: <TAB>  <TAB> if hasattr(monad, ""cls_bl_idname""): <MASK> return monad <TAB> return None",if monad . cls_bl_idname == self . cls_bl_idname :,93
3198,"def _create_mask(self, plen): <TAB> mask = [] <TAB> for i in range(16): <TAB>  <TAB> if plen >= 8: <TAB>  <TAB>  <TAB> mask.append(0xFF) <MASK> mask.append(0xFF >> (8 - plen) << (8 - plen)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> mask.append(0x00) <TAB>  <TAB> plen -= 8 <TAB> return mask",elif plen > 0 :,107
3199,"def dataset_to_stream(dataset, input_name): <TAB> """"""Takes a tf.Dataset and creates a numpy stream of ready batches."""""" <TAB> # All input-pipeline processing should be on CPU. <TAB> for example in fastmath.dataset_as_numpy(dataset): <TAB>  <TAB> features = example[0] <TAB>  <TAB> inp, out = features[input_name], example[1] <TAB>  <TAB> mask = features[""mask""] if ""mask"" in features else None <TAB>  <TAB> # Some accelerators don't handle uint8 well, cast to int. <MASK> inp = inp.astype(np.int32) <TAB>  <TAB> if isinstance(out, np.uint8): <TAB>  <TAB>  <TAB> out = out.astype(np.int32) <TAB>  <TAB> yield (inp, out) if mask is None else (inp, out, mask)","if isinstance ( inp , np . uint8 ) :",198
3200,"def _idle_redraw_cb(self): <TAB> assert self._idle_redraw_src_id is not None <TAB> queue = self._idle_redraw_queue <TAB> if len(queue) > 0: <TAB>  <TAB> bbox = queue.pop(0) <MASK> super(CanvasRenderer, self).queue_draw() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> super(CanvasRenderer, self).queue_draw_area(*bbox) <TAB> if len(queue) == 0: <TAB>  <TAB> self._idle_redraw_src_id = None <TAB>  <TAB> return False <TAB> return True",if bbox is None :,138
3201,"def mutated(self, indiv): <TAB> """"""mutate some genes of the given individual"""""" <TAB> res = indiv.copy() <TAB> # to avoid having a child identical to one of the currentpopulation''' <TAB> for i in range(self.numParameters): <MASK> if self.xBound is None: <TAB>  <TAB>  <TAB>  <TAB> res[i] = indiv[i] + gauss(0, self.mutationStdDev) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> res[i] = max( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> min(indiv[i] + gauss(0, self.mutationStdDev), self.maxs[i]), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.mins[i], <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return res",if random ( ) < self . mutationProb :,177
3202,"def _justifyDrawParaLine(tx, offset, extraspace, words, last=0): <TAB> setXPos(tx, offset) <TAB> text = b"" "".join(words) <TAB> if last: <TAB>  <TAB> # last one, left align <TAB>  <TAB> tx._textOut(text, 1) <TAB> else: <TAB>  <TAB> nSpaces = len(words) - 1 <MASK> tx.setWordSpace(extraspace / float(nSpaces)) <TAB>  <TAB>  <TAB> tx._textOut(text, 1) <TAB>  <TAB>  <TAB> tx.setWordSpace(0) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tx._textOut(text, 1) <TAB> setXPos(tx, -offset) <TAB> return offset",if nSpaces :,168
3203,"def _read_0(self, stream): <TAB> r = b"""" <TAB> while True: <TAB>  <TAB> c = stream.read(2) <MASK> raise EOFError() <TAB>  <TAB> if c == b""\x00\x00"": <TAB>  <TAB>  <TAB> break <TAB>  <TAB> r += c <TAB> return r.decode(self.encoding)",if len ( c ) != 2 :,87
3204,"def run(self, app, editor, args): <TAB> line_nums = [] <TAB> for cursor in editor.cursors: <MASK> line_nums.append(cursor.y) <TAB>  <TAB>  <TAB> data = editor.lines[cursor.y].get_data().upper() <TAB>  <TAB>  <TAB> editor.lines[cursor.y].set_data(data)",if cursor . y not in line_nums :,94
3205,"def create_default_energy_point_rules(): <TAB> for rule in get_default_energy_point_rules(): <TAB>  <TAB> # check if any rule for ref. doctype exists <TAB>  <TAB> rule_exists = frappe.db.exists( <TAB>  <TAB>  <TAB> ""Energy Point Rule"", {""reference_doctype"": rule.get(""reference_doctype"")} <TAB>  <TAB> ) <MASK> continue <TAB>  <TAB> doc = frappe.get_doc(rule) <TAB>  <TAB> doc.insert(ignore_permissions=True)",if rule_exists :,127
3206,"def __new__(cls, *nodes): <TAB> if not nodes: <TAB>  <TAB> raise TypeError(""DisjunctionNode() requires at least one node"") <TAB> elif len(nodes) == 1: <TAB>  <TAB> return nodes[0] <TAB> self = super(DisjunctionNode, cls).__new__(cls) <TAB> self.__nodes = [] <TAB> # TODO: Remove duplicates? <TAB> for node in nodes: <TAB>  <TAB> if not isinstance(node, Node): <TAB>  <TAB>  <TAB> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""DisjunctionNode() expects Node instances as arguments;"" <TAB>  <TAB>  <TAB>  <TAB> "" received a non-Node instance %r"" % node <TAB>  <TAB>  <TAB> ) <MASK> self.__nodes.extend(node.__nodes) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.__nodes.append(node) <TAB> return self","if isinstance ( node , DisjunctionNode ) :",191
3207,def dfs(v: str) -> Iterator[Set[str]]: <TAB> index[v] = len(stack) <TAB> stack.append(v) <TAB> boundaries.append(index[v]) <TAB> for w in edges[v]: <TAB>  <TAB> if w not in index: <TAB>  <TAB>  <TAB> yield from dfs(w) <MASK> while index[w] < boundaries[-1]: <TAB>  <TAB>  <TAB>  <TAB> boundaries.pop() <TAB> if boundaries[-1] == index[v]: <TAB>  <TAB> boundaries.pop() <TAB>  <TAB> scc = set(stack[index[v] :]) <TAB>  <TAB> del stack[index[v] :] <TAB>  <TAB> identified.update(scc) <TAB>  <TAB> yield scc,elif w not in identified :,162
3208,"def unpack_item_obj(map_uuid_global_id, misp_obj): <TAB> obj_meta = get_object_metadata(misp_obj) <TAB> obj_id = None <TAB> io_content = None <TAB> for attribute in misp_obj.attributes: <MASK> obj_id = attribute.value  # # TODO: sanitize <TAB>  <TAB>  <TAB> io_content = attribute.data  # # TODO: check if type == io <TAB> if obj_id and io_content: <TAB>  <TAB> res = Item.create_item(obj_id, obj_meta, io_content) <TAB>  <TAB> map_uuid_global_id[misp_obj.uuid] = get_global_id(""item"", obj_id)","if attribute . object_relation == ""raw-data"" :",182
3209,"def parse(self, response): <TAB> soup = BeautifulSoup(response.content.decode(""utf-8"", ""ignore""), ""lxml"") <TAB> image_divs = soup.find_all(""div"", class_=""imgpt"") <TAB> pattern = re.compile(r""murl\"":\""(.*?)\.jpg"") <TAB> for div in image_divs: <TAB>  <TAB> href_str = html_parser.HTMLParser().unescape(div.a[""m""]) <TAB>  <TAB> match = pattern.search(href_str) <MASK> name = match.group(1) if six.PY3 else match.group(1).encode(""utf-8"") <TAB>  <TAB>  <TAB> img_url = ""{}.jpg"".format(name) <TAB>  <TAB>  <TAB> yield dict(file_url=img_url)",if match :,180
3210,"def filter_errors(self, errors: List[str]) -> List[str]: <TAB> real_errors: List[str] = list() <TAB> current_file = __file__ <TAB> current_path = os.path.split(current_file) <TAB> for line in errors: <TAB>  <TAB> line = line.strip() <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> fn, lno, lvl, msg = self.parse_trace_line(line) <MASK> _path = os.path.split(fn) <TAB>  <TAB>  <TAB> if _path[-1] != current_path[-1]: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> real_errors.append(line) <TAB> return real_errors",if fn is not None :,171
3211,"def decompileFormat1(self, reader, otFont): <TAB> self.classDefs = classDefs = [] <TAB> startGlyphID = reader.readUShort() <TAB> glyphCount = reader.readUShort() <TAB> for i in range(glyphCount): <TAB>  <TAB> glyphName = otFont.getglyphName(startGlyphID + i) <TAB>  <TAB> classValue = reader.readUShort() <MASK> classDefs.append((glyphName, classValue))",if classValue :,118
3212,"def compress(self, data_list): <TAB> if len(data_list) == 2: <TAB>  <TAB> value, lookup_expr = data_list <MASK> if lookup_expr not in EMPTY_VALUES: <TAB>  <TAB>  <TAB>  <TAB> return Lookup(value=value, lookup_expr=lookup_expr) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise forms.ValidationError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.error_messages[""lookup_required""], code=""lookup_required"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return None",if value not in EMPTY_VALUES :,127
3213,"def open_compat(path, mode=""r""): <TAB> if mode in [""r"", ""rb""] and not os.path.exists(path): <TAB>  <TAB> raise FileNotFoundError(u'The file ""%s"" could not be found' % path) <TAB> if sys.version_info >= (3,): <TAB>  <TAB> encoding = ""utf-8"" <TAB>  <TAB> errors = ""replace"" <MASK> encoding = None <TAB>  <TAB>  <TAB> errors = None <TAB>  <TAB> return open(path, mode, encoding=encoding, errors=errors) <TAB> else: <TAB>  <TAB> return open(path, mode)","if mode in [ ""rb"" , ""wb"" , ""ab"" ] :",145
3214,"def filter_errors(self, errors: List[str]) -> List[str]: <TAB> real_errors: List[str] = list() <TAB> current_file = __file__ <TAB> current_path = os.path.split(current_file) <TAB> for line in errors: <TAB>  <TAB> line = line.strip() <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> fn, lno, lvl, msg = self.parse_trace_line(line) <TAB>  <TAB> if fn is not None: <TAB>  <TAB>  <TAB> _path = os.path.split(fn) <MASK> continue <TAB>  <TAB> real_errors.append(line) <TAB> return real_errors",if _path [ - 1 ] != current_path [ - 1 ] :,171
3215,"def filter_by_level(record, level_per_module): <TAB> name = record[""name""] <TAB> level = 0 <TAB> if name in level_per_module: <TAB>  <TAB> level = level_per_module[name] <TAB> elif name is not None: <TAB>  <TAB> lookup = """" <TAB>  <TAB> if """" in level_per_module: <TAB>  <TAB>  <TAB> level = level_per_module[""""] <TAB>  <TAB> for n in name.split("".""): <TAB>  <TAB>  <TAB> lookup += n <MASK> level = level_per_module[lookup] <TAB>  <TAB>  <TAB> lookup += ""."" <TAB> if level is False: <TAB>  <TAB> return False <TAB> return record[""level""].no >= level",if lookup in level_per_module :,166
3216,"def CountButtons(self): <TAB> """"""Returns the number of visible buttons in the docked pane."""""" <TAB> n = 0 <TAB> if self.HasCaption() or self.HasCaptionLeft(): <TAB>  <TAB> if isinstance(wx.GetTopLevelParent(self.window), AuiFloatingFrame): <TAB>  <TAB>  <TAB> return 1 <TAB>  <TAB> if self.HasCloseButton(): <TAB>  <TAB>  <TAB> n += 1 <MASK> n += 1 <TAB>  <TAB> if self.HasMinimizeButton(): <TAB>  <TAB>  <TAB> n += 1 <TAB>  <TAB> if self.HasPinButton(): <TAB>  <TAB>  <TAB> n += 1 <TAB> return n",if self . HasMaximizeButton ( ) :,149
3217,"def search(a, b, desired): <TAB> if a == b: <TAB>  <TAB> return a <TAB> if abs(b - a) < 0.005: <TAB>  <TAB> ca = count(a) <TAB>  <TAB> cb = count(b) <TAB>  <TAB> dista = abs(desired - ca) <TAB>  <TAB> distb = abs(desired - cb) <MASK> return a <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return b <TAB> m = (a + b) / 2.0 <TAB> cm = count(m) <TAB> if desired < cm: <TAB>  <TAB> return search(m, b, desired) <TAB> else: <TAB>  <TAB> return search(a, m, desired)",if dista < distb :,161
3218,"def force_ipv4(self, *args): <TAB> """"""only ipv4 localhost in /etc/hosts"""""" <TAB> logg.debug(""checking /etc/hosts for '::1 localhost'"") <TAB> lines = [] <TAB> for line in open(self.etc_hosts()): <MASK> newline = re.sub(""\\slocalhost\\s"", "" "", line) <TAB>  <TAB>  <TAB> if line != newline: <TAB>  <TAB>  <TAB>  <TAB> logg.info(""/etc/hosts: '%s' => '%s'"", line.rstrip(), newline.rstrip()) <TAB>  <TAB>  <TAB>  <TAB> line = newline <TAB>  <TAB> lines.append(line) <TAB> f = open(self.etc_hosts(), ""w"") <TAB> for line in lines: <TAB>  <TAB> f.write(line) <TAB> f.close()","if ""::1"" in line :",182
3219,"def aiter_cogs(cls) -> AsyncIterator[Tuple[str, str]]: <TAB> yield ""Core"", ""0"" <TAB> for _dir in data_manager.cog_data_path().iterdir(): <TAB>  <TAB> fpath = _dir / ""settings.json"" <MASK> continue <TAB>  <TAB> with fpath.open() as f: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> data = json.load(f) <TAB>  <TAB>  <TAB> except json.JSONDecodeError: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if not isinstance(data, dict): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> cog_name = _dir.stem <TAB>  <TAB> for cog_id, inner in data.items(): <TAB>  <TAB>  <TAB> if not isinstance(inner, dict): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> yield cog_name, cog_id",if not fpath . exists ( ) :,192
3220,"def _get_dbutils(): <TAB> try: <TAB>  <TAB> import IPython <TAB>  <TAB> ip_shell = IPython.get_ipython() <MASK> raise _NoDbutilsError <TAB>  <TAB> return ip_shell.ns_table[""user_global""][""dbutils""] <TAB> except ImportError: <TAB>  <TAB> raise _NoDbutilsError <TAB> except KeyError: <TAB>  <TAB> raise _NoDbutilsError",if ip_shell is None :,97
3221,"def _bytecode_filenames(self, py_filenames): <TAB> bytecode_files = [] <TAB> for py_file in py_filenames: <TAB>  <TAB> # Since build_py handles package data installation, the <TAB>  <TAB> # list of outputs can contain more than just .py files. <TAB>  <TAB> # Make sure we only report bytecode for the .py files. <TAB>  <TAB> ext = os.path.splitext(os.path.normcase(py_file))[1] <MASK> continue <TAB>  <TAB> if self.compile: <TAB>  <TAB>  <TAB> bytecode_files.append(py_file + ""c"") <TAB>  <TAB> if self.optimize > 0: <TAB>  <TAB>  <TAB> bytecode_files.append(py_file + ""o"") <TAB> return bytecode_files",if ext != PYTHON_SOURCE_EXTENSION :,175
3222,"def compute_distances_mu(line, pts, result, gates, tolerance): <TAB> """"""calculate all distances with mathuutils"""""" <TAB> line_origin = V(line[0]) <TAB> line_end = V(line[-1]) <TAB> local_result = [[], [], [], [], []] <TAB> for point in pts: <TAB>  <TAB> data = compute_distance(V(point), line_origin, line_end, tolerance) <TAB>  <TAB> for i, res in enumerate(local_result): <TAB>  <TAB>  <TAB> res.append(data[i]) <TAB> for i, res in enumerate(result): <MASK> res.append(local_result[i])",if gates [ i ] :,153
3223,"def _get_next_segment(self, segment_path, page_size, segment_cursor=None): <TAB> if segment_path: <MASK> return None <TAB>  <TAB> return Segment(self.client, segment_path, page_size, segment_cursor) <TAB> return None",if self . end_time and self . _is_later_than_end_time ( segment_path ) :,91
3224,"def _check_number_of_sessions(): <TAB> nb_desktop_sessions = sessions.get_number_of_desktop_sessions(ignore_gdm=True) <TAB> if nb_desktop_sessions > 1: <TAB>  <TAB> print( <TAB>  <TAB>  <TAB> ""WARNING : There are %d other desktop sessions open. The GPU switch will not become effective until you have manually"" <TAB>  <TAB>  <TAB> "" logged out from ALL desktop sessions.\n"" <TAB>  <TAB>  <TAB> ""Continue ? (y/N)"" % (nb_desktop_sessions - 1) <TAB>  <TAB> ) <TAB>  <TAB> confirmation = ask_confirmation() <MASK> sys.exit(0)",if not confirmation :,149
3225,"def delete_compute_environment(self, compute_environment_name): <TAB> if compute_environment_name is None: <TAB>  <TAB> raise InvalidParameterValueException(""Missing computeEnvironment parameter"") <TAB> compute_env = self.get_compute_environment(compute_environment_name) <TAB> if compute_env is not None: <TAB>  <TAB> # Pop ComputeEnvironment <TAB>  <TAB> self._compute_environments.pop(compute_env.arn) <TAB>  <TAB> # Delete ECS cluster <TAB>  <TAB> self.ecs_backend.delete_cluster(compute_env.ecs_name) <MASK> # Delete compute environment <TAB>  <TAB>  <TAB> instance_ids = [instance.id for instance in compute_env.instances] <TAB>  <TAB>  <TAB> self.ec2_backend.terminate_instances(instance_ids)","if compute_env . env_type == ""MANAGED"" :",187
3226,"def run(self): <TAB> results = {} <TAB> for func_name in [ <TAB>  <TAB> # Execute every function starting with check_* <TAB>  <TAB> fn <TAB>  <TAB> for fn in self.check_functions <TAB>  <TAB> # if the user does not specify any name <TAB>  <TAB> if not self.args.get(""check"") <TAB>  <TAB> # of if specify the current function name <TAB>  <TAB> or self.args.get(""check"") == fn <TAB> ]: <TAB>  <TAB> function = getattr(self, func_name) <TAB>  <TAB> log.warn(function.__doc__) <TAB>  <TAB> result = function() <MASK> log.info(""\n"".join(result)) <TAB>  <TAB>  <TAB> results.update({func_name: result}) <TAB> return results",if result :,167
3227,"def invalidate(self, layers=None): <TAB> if layers is None: <TAB>  <TAB> layers = Layer.AllLayers <TAB> if layers: <TAB>  <TAB> layers = set(layers) <TAB>  <TAB> self.invalidLayers.update(layers) <TAB>  <TAB> blockRenderers = [ <TAB>  <TAB>  <TAB> br <TAB>  <TAB>  <TAB> for br in self.blockRenderers <MASK> ] <TAB>  <TAB> if len(blockRenderers) < len(self.blockRenderers): <TAB>  <TAB>  <TAB> self.forgetDisplayLists() <TAB>  <TAB> self.blockRenderers = blockRenderers <TAB>  <TAB> if self.renderer.showRedraw and Layer.Blocks in layers: <TAB>  <TAB>  <TAB> self.needsRedisplay = True",if br . layer is Layer . Blocks or br . layer not in layers,184
3228,"def get_library_dirs(platform, arch=None): <TAB> if platform == ""win32"": <TAB>  <TAB> jre_home = get_jre_home(platform) <TAB>  <TAB> jdk_home = JAVA_HOME <MASK> jre_home = jre_home.decode(""utf-8"") <TAB>  <TAB> return [join(jdk_home, ""lib""), join(jdk_home, ""bin"", ""server"")] <TAB> elif platform == ""android"": <TAB>  <TAB> return [""libs/{}"".format(arch)] <TAB> return []","if isinstance ( jre_home , bytes ) :",136
3229,"def save_plugin_options(self): <TAB> for name, option_widgets in self._plugin_option_widgets.items(): <MASK> self.config[""plugins""][name] = {} <TAB>  <TAB> plugin_config = self.config[""plugins""][ <TAB>  <TAB>  <TAB> name <TAB>  <TAB> ]  # use or instead of get incase the value is actually None <TAB>  <TAB> for option_name, option_widget in option_widgets.items(): <TAB>  <TAB>  <TAB> plugin_config[option_name] = option_widget.option.get_widget_value( <TAB>  <TAB>  <TAB>  <TAB> option_widget.widget <TAB>  <TAB>  <TAB> )","if name not in self . config [ ""plugins"" ] :",149
3230,"def _select_block(str_in, start_tag, end_tag): <TAB> """"""Select first block delimited by start_tag and end_tag"""""" <TAB> start_pos = str_in.find(start_tag) <TAB> if start_pos < 0: <TAB>  <TAB> raise ValueError(""start_tag not found"") <TAB> depth = 0 <TAB> for pos in range(start_pos, len(str_in)): <TAB>  <TAB> if str_in[pos] == start_tag: <TAB>  <TAB>  <TAB> depth += 1 <TAB>  <TAB> elif str_in[pos] == end_tag: <TAB>  <TAB>  <TAB> depth -= 1 <MASK> break <TAB> sel = str_in[start_pos + 1 : pos] <TAB> return sel",if depth == 0 :,171
3231,"def _coerce_to_bool(self, node, var, true_val=True): <TAB> """"""Coerce the values in a variable to bools."""""" <TAB> bool_var = self.program.NewVariable() <TAB> for b in var.bindings: <TAB>  <TAB> v = b.data <TAB>  <TAB> if isinstance(v, mixin.PythonConstant) and isinstance(v.pyval, bool): <TAB>  <TAB>  <TAB> const = v.pyval is true_val <TAB>  <TAB> elif not compare.compatible_with(v, True): <TAB>  <TAB>  <TAB> const = not true_val <MASK> const = true_val <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> const = None <TAB>  <TAB> bool_var.AddBinding(self.convert.bool_values[const], {b}, node) <TAB> return bool_var","elif not compare . compatible_with ( v , False ) :",192
3232,def multiline_indentation(self): <TAB> if self._multiline_indentation is None: <TAB>  <TAB> offset = 0 <MASK> offset = 2 <TAB>  <TAB> indentation = make_indentation(3 * self.indent_size + offset) <TAB>  <TAB> self._multiline_indentation = indentation <TAB> if self.current_rule: <TAB>  <TAB> indent_extra = make_indentation(self.indent_size) <TAB>  <TAB> return self._multiline_indentation + indent_extra <TAB> return self._multiline_indentation,if self . show_aligned_keywords :,120
3233,"def __call__(self, event, data=None): <TAB> datatype, delta = event <TAB> self.midi_ctrl.delta += delta <TAB> if TIMING_CLOCK in datatype and not self.played: <TAB>  <TAB> self.midi_ctrl.pulse += 1 <MASK> t_master = 60.0 <TAB>  <TAB>  <TAB> self.midi_ctrl.bpm = round(60.0 / self.midi_ctrl.delta, 0) <TAB>  <TAB>  <TAB> self.midi_ctrl.pulse = 0 <TAB>  <TAB>  <TAB> self.midi_ctrl.delta = 0.0",if self . midi_ctrl . pulse == self . midi_ctrl . ppqn :,155
3234,"def handle_sent(self, elt): <TAB> sent = [] <TAB> for child in elt: <MASK> itm = self.handle_word(child) <TAB>  <TAB>  <TAB> if self._unit == ""word"": <TAB>  <TAB>  <TAB>  <TAB> sent.extend(itm) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> sent.append(itm) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""Unexpected element %s"" % child.tag) <TAB> return SemcorSentence(elt.attrib[""snum""], sent)","if child . tag in ( ""wf"" , ""punc"" ) :",126
3235,"def _handle_def_errors(testdef): <TAB> # If the test generation had an error, raise <TAB> if testdef.error: <MASK> if isinstance(testdef.exception, Exception): <TAB>  <TAB>  <TAB>  <TAB> raise testdef.exception <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise Exception(testdef.exception) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception(""Test parse failure"")",if testdef . exception :,100
3236,"def _authorized_sid(self, jid, sid, ifrom, iq): <TAB> with self._preauthed_sids_lock: <MASK> del self._preauthed_sids[(jid, sid, ifrom)] <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> return False","if ( jid , sid , ifrom ) in self . _preauthed_sids :",88
3237,"def wait(self, timeout=None): <TAB> if self.returncode is None: <MASK> msecs = _subprocess.INFINITE <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> msecs = max(0, int(timeout * 1000 + 0.5)) <TAB>  <TAB> res = _subprocess.WaitForSingleObject(int(self._handle), msecs) <TAB>  <TAB> if res == _subprocess.WAIT_OBJECT_0: <TAB>  <TAB>  <TAB> code = _subprocess.GetExitCodeProcess(self._handle) <TAB>  <TAB>  <TAB> if code == TERMINATE: <TAB>  <TAB>  <TAB>  <TAB> code = -signal.SIGTERM <TAB>  <TAB>  <TAB> self.returncode = code <TAB> return self.returncode",if timeout is None :,154
3238,"def _gen_legal_y_s_t(self): <TAB> while True: <TAB>  <TAB> y = self._gen_random_scalar() <TAB>  <TAB> s = self.tec_arithmetic.mul( <TAB>  <TAB>  <TAB> scalar=y, a=self.tec_arithmetic.get_generator() <TAB>  <TAB> )  # S = yG <TAB>  <TAB> t = self._hash_tec_element(s) <MASK> # Both S and T are legal <TAB>  <TAB>  <TAB> LOGGER.info(""randomly generated y, S, T"") <TAB>  <TAB>  <TAB> return y, s, t",if self . tec_arithmetic . is_in_group ( s ) and type ( t ) != int :,160
3239,"def write_out(): <TAB> while True: <MASK> time.sleep(0.1) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> data_str = self.instrument_queue.get() <TAB>  <TAB> data_str = data_str.splitlines() <TAB>  <TAB> tb.write("""")  # position cursor to end <TAB>  <TAB> for line in data_str: <TAB>  <TAB>  <TAB> tb.write(line) <TAB>  <TAB> tb.write(""\n"")",if self . instrument_queue . empty ( ) :,112
3240,"def _parse_preamble(self): <TAB> """"""Parse metadata about query (PRIVATE)."""""" <TAB> meta = {} <TAB> while self.line: <TAB>  <TAB> regx = re.search(_RE_QUERY, self.line) <TAB>  <TAB> if regx: <TAB>  <TAB>  <TAB> self.query_id = regx.group(1) <MASK> self.seq_len = int(self.line.strip().split()[1]) <TAB>  <TAB> self.line = self.handle.readline().strip() <TAB> return meta","if self . line . startswith ( ""Match_columns"" ) :",130
3241,"def init_sequence(self, coll_name, seq_config): <TAB> if not isinstance(seq_config, list): <TAB>  <TAB> raise Exception('""sequence"" config must be a list') <TAB> handlers = [] <TAB> for entry in seq_config: <MASK> raise Exception('""sequence"" entry must be a dict') <TAB>  <TAB> name = entry.get(""name"", """") <TAB>  <TAB> handler = self.load_coll(name, entry) <TAB>  <TAB> handlers.append(handler) <TAB> return HandlerSeq(handlers)","if not isinstance ( entry , dict ) :",126
3242,"def change_args_to_dict(string): <TAB> if string is None: <TAB>  <TAB> return None <TAB> ans = [] <TAB> strings = string.split(""\n"") <TAB> ind = 1 <TAB> start = 0 <TAB> while ind <= len(strings): <TAB>  <TAB> if ind < len(strings) and strings[ind].startswith("" ""): <TAB>  <TAB>  <TAB> ind += 1 <TAB>  <TAB> else: <MASK> ans.append(""\n"".join(strings[start:ind])) <TAB>  <TAB>  <TAB> start = ind <TAB>  <TAB>  <TAB> ind += 1 <TAB> d = {} <TAB> for line in ans: <TAB>  <TAB> if "":"" in line and len(line) > 0: <TAB>  <TAB>  <TAB> lines = line.split("":"") <TAB>  <TAB>  <TAB> d[lines[0]] = lines[1].strip() <TAB> return d",if start < ind :,188
3243,"def wait(self): <TAB> while True: <TAB>  <TAB> return_code = self._process.poll() <TAB>  <TAB> if return_code is not None: <TAB>  <TAB>  <TAB> line = self._process.stdout.readline().decode(""utf-8"") <MASK> break <TAB>  <TAB>  <TAB> log.debug(line.strip(""\n"")) <TAB> return True","if line == """" :",87
3244,"def __getattr__(self, key): <TAB> for tag in self.tag.children: <MASK> continue <TAB>  <TAB> if ""name"" in tag.attrs and tag.attrs[""name""] in (key,): <TAB>  <TAB>  <TAB> from thug.DOM.W3C.Core.DOMImplementation import DOMImplementation <TAB>  <TAB>  <TAB> return DOMImplementation.createHTMLElement(self.doc, tag) <TAB> raise AttributeError","if tag . name not in ( ""input"" , ) :",104
3245,"def compare_hash(hash_of_gold, path_to_file): <TAB> with open(path_to_file, ""rb"") as f: <TAB>  <TAB> hash_of_file = hashlib.sha256(f.read()).hexdigest() <MASK> print( <TAB>  <TAB>  <TAB>  <TAB> ""########## Hash sum of"", <TAB>  <TAB>  <TAB>  <TAB> path_to_file, <TAB>  <TAB>  <TAB>  <TAB> ""differs from the target, the topology will be deleted !!! ##########"", <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> shutil.rmtree(os.path.dirname(path_to_file))",if hash_of_file != hash_of_gold :,147
3246,def on_completed2(): <TAB> doner[0] = True <TAB> if not qr: <MASK> observer.on_next(False) <TAB>  <TAB>  <TAB> observer.on_completed() <TAB>  <TAB> elif donel[0]: <TAB>  <TAB>  <TAB> observer.on_next(True) <TAB>  <TAB>  <TAB> observer.on_completed(),if len ( ql ) > 0 :,86
3247,"def get_other(self, data, items): <TAB> is_tuple = False <TAB> if type(data) == tuple: <TAB>  <TAB> data = list(data) <TAB>  <TAB> is_tuple = True <TAB> if type(data) == list: <TAB>  <TAB> m_items = items.copy() <TAB>  <TAB> for idx, item in enumerate(items): <MASK> m_items[idx] = len(data) - abs(item) <TAB>  <TAB> for i in sorted(set(m_items), reverse=True): <TAB>  <TAB>  <TAB> if i < len(data) and i > -1: <TAB>  <TAB>  <TAB>  <TAB> del data[i] <TAB>  <TAB> if is_tuple: <TAB>  <TAB>  <TAB> return tuple(data) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return data <TAB> else: <TAB>  <TAB> return None",if item < 0 :,191
3248,"def _open_url(cls, url): <TAB> if config.browser: <TAB>  <TAB> cmd = [config.browser, url] <MASK> print(""running command: %s"" % "" "".join(cmd)) <TAB>  <TAB> p = Popen(cmd) <TAB>  <TAB> p.communicate() <TAB> else: <TAB>  <TAB> if not config.quiet: <TAB>  <TAB>  <TAB> print(""opening URL in browser: %s"" % url) <TAB>  <TAB> webbrowser.open_new(url)",if not config . quiet :,117
3249,"def setLabel(self, s, protect=False): <TAB> """"""Set the label of the minibuffer."""""" <TAB> c, k, w = self.c, self, self.w <TAB> if w: <TAB>  <TAB> # Support for the curses gui. <TAB>  <TAB> if hasattr(g.app.gui, ""set_minibuffer_label""): <TAB>  <TAB>  <TAB> g.app.gui.set_minibuffer_label(c, s) <TAB>  <TAB> w.setAllText(s) <TAB>  <TAB> n = len(s) <TAB>  <TAB> w.setSelectionRange(n, n, insert=n) <MASK> k.mb_prefix = s",if protect :,151
3250,"def __init__(self, path): <TAB> self.symcaches = [] <TAB> for path in path.split("";""): <TAB>  <TAB> if os.path.isdir(path): <TAB>  <TAB>  <TAB> self.symcaches.append(SymbolCache(dirname=path)) <TAB>  <TAB>  <TAB> continue <MASK> import cobra <TAB>  <TAB>  <TAB> self.symcaches.append(cobra.CobraProxy(path)) <TAB>  <TAB>  <TAB> continue","if path . startswith ( ""cobra://"" ) or path . startswith ( ""cobrassl://"" ) :",111
3251,"def init_params(net): <TAB> """"""Init layer parameters."""""" <TAB> for module in net.modules(): <TAB>  <TAB> if isinstance(module, nn.Conv2d): <TAB>  <TAB>  <TAB> init.kaiming_normal(module.weight, mode=""fan_out"") <TAB>  <TAB>  <TAB> if module.bias: <TAB>  <TAB>  <TAB>  <TAB> init.constant(module.bias, 0) <MASK> init.constant(module.weight, 1) <TAB>  <TAB>  <TAB> init.constant(module.bias, 0) <TAB>  <TAB> elif isinstance(module, nn.Linear): <TAB>  <TAB>  <TAB> init.normal(module.weight, std=1e-3) <TAB>  <TAB>  <TAB> if module.bias: <TAB>  <TAB>  <TAB>  <TAB> init.constant(module.bias, 0)","elif isinstance ( module , nn . BatchNorm2d ) :",180
3252,"def _diff_dict(self, old, new): <TAB> diff = {} <TAB> removed = [] <TAB> added = [] <TAB> for key, value in old.items(): <MASK> removed.append(key) <TAB>  <TAB> elif old[key] != new[key]: <TAB>  <TAB>  <TAB> # modified is indicated by a remove and add <TAB>  <TAB>  <TAB> removed.append(key) <TAB>  <TAB>  <TAB> added.append(key) <TAB> for key, value in new.items(): <TAB>  <TAB> if key not in old: <TAB>  <TAB>  <TAB> added.append(key) <TAB> if removed: <TAB>  <TAB> diff[""removed""] = sorted(removed) <TAB> if added: <TAB>  <TAB> diff[""added""] = sorted(added) <TAB> return diff",if key not in new :,172
3253,"def __init__(self, *args, **kwargs): <TAB> _kwargs = { <TAB>  <TAB> ""max_length"": 20, <TAB>  <TAB> ""widget"": forms.TextInput(attrs={""autocomplete"": ""off""}), <TAB>  <TAB> ""label"": _(""Card number""), <TAB> } <TAB> if ""types"" in kwargs: <TAB>  <TAB> self.accepted_cards = set(kwargs.pop(""types"")) <TAB>  <TAB> difference = self.accepted_cards - VALID_CARDS <MASK> raise ImproperlyConfigured( <TAB>  <TAB>  <TAB>  <TAB> ""The following accepted_cards are "" ""unknown: %s"" % difference <TAB>  <TAB>  <TAB> ) <TAB> _kwargs.update(kwargs) <TAB> super().__init__(*args, **_kwargs)",if difference :,160
3254,"def dumps(self): <TAB> sections = [] <TAB> for name, env_info in self._dependencies_.items(): <TAB>  <TAB> sections.append(""[ENV_%s]"" % name) <TAB>  <TAB> for var, values in sorted(env_info.vars.items()): <TAB>  <TAB>  <TAB> tmp = ""%s="" % var <MASK> tmp += ""[%s]"" % "","".join(['""%s""' % val for val in values]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> tmp += ""%s"" % values <TAB>  <TAB>  <TAB> sections.append(tmp) <TAB> return ""\n"".join(sections)","if isinstance ( values , list ) :",144
3255,"def air_quality(self): <TAB> aqi_data = self._get_aqi_data() <TAB> if aqi_data: <TAB>  <TAB> if aqi_data.get(""status"") == ""ok"": <TAB>  <TAB>  <TAB> aqi_data = self._organize(aqi_data) <TAB>  <TAB>  <TAB> aqi_data = self._manipulate(aqi_data) <MASK> self.py3.error(aqi_data.get(""data"")) <TAB> return { <TAB>  <TAB> ""cached_until"": self.py3.time_in(self.cache_timeout), <TAB>  <TAB> ""full_text"": self.py3.safe_format(self.format, aqi_data), <TAB> }","elif aqi_data . get ( ""status"" ) == ""error"" :",190
3256,"def _blend(x, y):  # pylint: disable=invalid-name <TAB> """"""Implements the ""blend"" strategy for `deep_merge`."""""" <TAB> if isinstance(x, (dict, OrderedDict)): <TAB>  <TAB> if not isinstance(y, (dict, OrderedDict)): <TAB>  <TAB>  <TAB> return y <TAB>  <TAB> return _merge(x, y, recursion_func=_blend) <TAB> if isinstance(x, (list, tuple)): <MASK> return y <TAB>  <TAB> result = [_blend(*i) for i in zip(x, y)] <TAB>  <TAB> if len(x) > len(y): <TAB>  <TAB>  <TAB> result += x[len(y) :] <TAB>  <TAB> elif len(x) < len(y): <TAB>  <TAB>  <TAB> result += y[len(x) :] <TAB>  <TAB> return result <TAB> return y","if not isinstance ( y , ( list , tuple ) ) :",194
3257,"def _rate(cls, sample1, sample2): <TAB> ""Simple rate"" <TAB> try: <TAB>  <TAB> interval = sample2[0] - sample1[0] <MASK> raise Infinity() <TAB>  <TAB> delta = sample2[1] - sample1[1] <TAB>  <TAB> if delta < 0: <TAB>  <TAB>  <TAB> raise UnknownValue() <TAB>  <TAB> return (sample2[0], delta / interval, sample2[2], sample2[3]) <TAB> except Infinity: <TAB>  <TAB> raise <TAB> except UnknownValue: <TAB>  <TAB> raise <TAB> except Exception as e: <TAB>  <TAB> raise NaN(e)",if interval == 0 :,146
3258,"def wrapped_request_method(*args, **kwargs): <TAB> """"""Modifies HTTP headers to include a specified user-agent."""""" <TAB> if kwargs.get(""headers"") is not None: <MASK> if user_agent not in kwargs[""headers""][""user-agent""]: <TAB>  <TAB>  <TAB>  <TAB> # Save the existing user-agent header and tack on our own. <TAB>  <TAB>  <TAB>  <TAB> kwargs[""headers""][""user-agent""] = ( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f""{user_agent} "" f'{kwargs[""headers""][""user-agent""]}' <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> kwargs[""headers""][""user-agent""] = user_agent <TAB> else: <TAB>  <TAB> kwargs[""headers""] = {""user-agent"": user_agent} <TAB> return request_method(*args, **kwargs)","if kwargs [ ""headers"" ] . get ( ""user-agent"" ) :",191
3259,"def remove_addons(auth, resource_object_list): <TAB> for config in AbstractNode.ADDONS_AVAILABLE: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> settings_model = config.node_settings <TAB>  <TAB> except LookupError: <TAB>  <TAB>  <TAB> settings_model = None <MASK> addon_list = settings_model.objects.filter( <TAB>  <TAB>  <TAB>  <TAB> owner__in=resource_object_list, is_deleted=False <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> for addon in addon_list: <TAB>  <TAB>  <TAB>  <TAB> addon.after_delete(auth.user)",if settings_model :,138
3260,"def Decorator(*args, **kwargs): <TAB> delay = 0.2 <TAB> num_attempts = 15 <TAB> cur_attempt = 0 <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return f(*args, **kwargs) <TAB>  <TAB> except exceptions.WebDriverException as e: <TAB>  <TAB>  <TAB> logging.warning(""Selenium raised %s"", utils.SmartUnicode(e)) <TAB>  <TAB>  <TAB> cur_attempt += 1 <MASK> raise <TAB>  <TAB>  <TAB> time.sleep(delay)",if cur_attempt == num_attempts :,122
3261,"def _cleanup_parts_dir(parts_dir, local_plugins_dir, parts): <TAB> if os.path.exists(parts_dir): <TAB>  <TAB> logger.info(""Cleaning up parts directory"") <TAB>  <TAB> for subdirectory in os.listdir(parts_dir): <TAB>  <TAB>  <TAB> path = os.path.join(parts_dir, subdirectory) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> shutil.rmtree(path) <TAB>  <TAB>  <TAB>  <TAB> except NotADirectoryError: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> os.remove(path) <TAB> for part in parts: <TAB>  <TAB> part.mark_cleaned(steps.BUILD) <TAB>  <TAB> part.mark_cleaned(steps.PULL)",if path != local_plugins_dir :,165
3262,"def traverse_trees(node_pos, sample, trees: List[HeteroDecisionTreeGuest]): <TAB> if node_pos[""reach_leaf_node""].all(): <TAB>  <TAB> return node_pos <TAB> for t_idx, tree in enumerate(trees): <TAB>  <TAB> cur_node_idx = node_pos[""node_pos""][t_idx] <TAB>  <TAB> # reach leaf <MASK> continue <TAB>  <TAB> rs, reach_leaf = HeteroSecureBoostingTreeGuest.traverse_a_tree( <TAB>  <TAB>  <TAB> tree, sample, cur_node_idx <TAB>  <TAB> ) <TAB>  <TAB> if reach_leaf: <TAB>  <TAB>  <TAB> node_pos[""reach_leaf_node""][t_idx] = True <TAB>  <TAB> node_pos[""node_pos""][t_idx] = rs <TAB> return node_pos",if cur_node_idx == - 1 :,196
3263,"def get_measurements(self, pipeline, object_name, category): <TAB> if self.get_categories(pipeline, object_name) == [category]: <TAB>  <TAB> results = [] <TAB>  <TAB> if self.do_corr_and_slope: <TAB>  <TAB>  <TAB> if object_name == ""Image"": <TAB>  <TAB>  <TAB>  <TAB> results += [""Correlation"", ""Slope""] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> results += [""Correlation""] <TAB>  <TAB> if self.do_overlap: <TAB>  <TAB>  <TAB> results += [""Overlap"", ""K""] <MASK> results += [""Manders""] <TAB>  <TAB> if self.do_rwc: <TAB>  <TAB>  <TAB> results += [""RWC""] <TAB>  <TAB> if self.do_costes: <TAB>  <TAB>  <TAB> results += [""Costes""] <TAB>  <TAB> return results <TAB> return []",if self . do_manders :,195
3264,"def create_connection(self, infos, f2, laddr_infos, protocol): <TAB> for family in infos: <TAB>  <TAB> try: <MASK> for laddr in laddr_infos: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB>  <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> protocol = ""foo"" <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> protocol = ""bar"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> raise <TAB> return protocol",if f2 :,139
3265,"def app_middleware(next, root, info, **kwargs): <TAB> app_auth_header = ""HTTP_AUTHORIZATION"" <TAB> prefix = ""bearer"" <TAB> request = info.context <TAB> if request.path == API_PATH: <TAB>  <TAB> if not hasattr(request, ""app""): <TAB>  <TAB>  <TAB> request.app = None <TAB>  <TAB>  <TAB> auth = request.META.get(app_auth_header, """").split() <TAB>  <TAB>  <TAB> if len(auth) == 2: <TAB>  <TAB>  <TAB>  <TAB> auth_prefix, auth_token = auth <MASK> request.app = SimpleLazyObject(lambda: get_app(auth_token)) <TAB> return next(root, info, **kwargs)",if auth_prefix . lower ( ) == prefix :,171
3266,"def when(self, matches, context): <TAB> ret = [] <TAB> for episode in matches.named(""episode"", lambda match: len(match.initiator) == 1): <TAB>  <TAB> group = matches.markers.at_match( <TAB>  <TAB>  <TAB> episode, lambda marker: marker.name == ""group"", index=0 <TAB>  <TAB> ) <MASK> if not matches.range( <TAB>  <TAB>  <TAB>  <TAB> *group.span, predicate=lambda match: match.name == ""title"" <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> ret.append(episode) <TAB> return ret",if group :,132
3267,def locate_via_pep514(spec): <TAB> with _PY_LOCK: <TAB>  <TAB> if not _PY_AVAILABLE: <TAB>  <TAB>  <TAB> from . import pep514 <TAB>  <TAB>  <TAB> _PY_AVAILABLE.extend(pep514.discover_pythons()) <TAB>  <TAB>  <TAB> _PY_AVAILABLE.append(CURRENT) <TAB> for cur_spec in _PY_AVAILABLE: <MASK> return cur_spec.path,if cur_spec . satisfies ( spec ) :,110
3268,"def setCorkImageDefault(self): <TAB> if settings.corkBackground[""image""] != """": <TAB>  <TAB> i = self.cmbCorkImage.findData(settings.corkBackground[""image""]) <MASK> self.cmbCorkImage.setCurrentIndex(i)",if i != - 1 :,72
3269,"def _split_key(key): <TAB> if isinstance(key, util.string_types): <TAB>  <TAB> # coerce fooload('*') into ""default loader strategy"" <TAB>  <TAB> if key == _WILDCARD_TOKEN: <TAB>  <TAB>  <TAB> return (_DEFAULT_TOKEN,) <TAB>  <TAB> # coerce fooload("".*"") into ""wildcard on default entity"" <MASK> key = key[1:] <TAB>  <TAB> return key.split(""."") <TAB> else: <TAB>  <TAB> return (key,)","elif key . startswith ( ""."" + _WILDCARD_TOKEN ) :",122
3270,"def detach_volume(self, volume): <TAB> # We need to find the node using this volume <TAB> for node in self.list_nodes(): <MASK> # This node has only one associated image. It is not the one we <TAB>  <TAB>  <TAB> # are after. <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for disk in node.image: <TAB>  <TAB>  <TAB> if disk.id == volume.id: <TAB>  <TAB>  <TAB>  <TAB> # Node found. We can now detach the volume <TAB>  <TAB>  <TAB>  <TAB> disk_id = disk.extra[""disk_id""] <TAB>  <TAB>  <TAB>  <TAB> return self._do_detach_volume(node.id, disk_id) <TAB> return False",if type ( node . image ) is not list :,160
3271,"def create(self, private=False): <TAB> try: <MASK> log.info(""Creating private channel %s."", self) <TAB>  <TAB>  <TAB> self._bot.api_call( <TAB>  <TAB>  <TAB>  <TAB> ""conversations.create"", data={""name"": self.name, ""is_private"": True} <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.info(""Creating channel %s."", self) <TAB>  <TAB>  <TAB> self._bot.api_call(""conversations.create"", data={""name"": self.name}) <TAB> except SlackAPIResponseError as e: <TAB>  <TAB> if e.error == ""user_is_bot"": <TAB>  <TAB>  <TAB> raise RoomError(f""Unable to create channel. {USER_IS_BOT_HELPTEXT}"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise RoomError(e)",if private :,189
3272,"def test_dataset_has_valid_etag(self, dataset_name): <TAB> py_script_path = list(filter(lambda x: x, dataset_name.split(""/"")))[-1] + "".py"" <TAB> dataset_url = hf_bucket_url(dataset_name, filename=py_script_path, dataset=True) <TAB> etag = None <TAB> try: <TAB>  <TAB> response = requests.head( <TAB>  <TAB>  <TAB> dataset_url, allow_redirects=True, proxies=None, timeout=10 <TAB>  <TAB> ) <MASK> etag = response.headers.get(""Etag"") <TAB> except (EnvironmentError, requests.exceptions.Timeout): <TAB>  <TAB> pass <TAB> self.assertIsNotNone(etag)",if response . status_code == 200 :,173
3273,"def set_dir_modes(self, dirname, mode): <TAB> if not self.is_chmod_supported(): <TAB>  <TAB> return <TAB> for dirpath, dirnames, fnames in os.walk(dirname): <TAB>  <TAB> if os.path.islink(dirpath): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> log.info(""changing mode of %s to %o"", dirpath, mode) <MASK> os.chmod(dirpath, mode)",if not self . dry_run :,105
3274,"def _clean(self): <TAB> logger.info(""Cleaning up..."") <TAB> if self._process is not None: <MASK> for _ in range(3): <TAB>  <TAB>  <TAB>  <TAB> self._process.terminate() <TAB>  <TAB>  <TAB>  <TAB> time.sleep(0.5) <TAB>  <TAB>  <TAB>  <TAB> if self._process.poll() is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._process.kill() <TAB>  <TAB>  <TAB>  <TAB> self._process.wait() <TAB>  <TAB>  <TAB>  <TAB> logger.error(""KILLED"") <TAB> if os.path.exists(self._tmp_dir): <TAB>  <TAB> shutil.rmtree(self._tmp_dir) <TAB> self._process = None <TAB> self._ws = None <TAB> logger.info(""Cleanup complete"")",if self . _process . poll ( ) is None :,189
3275,"def iter_chars_to_words(self, chars): <TAB> current_word = [] <TAB> for char in chars: <TAB>  <TAB> if not self.keep_blank_chars and char[""text""].isspace(): <MASK> yield current_word <TAB>  <TAB>  <TAB>  <TAB> current_word = [] <TAB>  <TAB> elif current_word and self.char_begins_new_word(current_word, char): <TAB>  <TAB>  <TAB> yield current_word <TAB>  <TAB>  <TAB> current_word = [char] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> current_word.append(char) <TAB> if current_word: <TAB>  <TAB> yield current_word",if current_word :,150
3276,"def _lookup(components, specs, provided, name, i, l): <TAB> if i < l: <TAB>  <TAB> for spec in specs[i].__sro__: <TAB>  <TAB>  <TAB> comps = components.get(spec) <TAB>  <TAB>  <TAB> if comps: <TAB>  <TAB>  <TAB>  <TAB> r = _lookup(comps, specs, provided, name, i + 1, l) <MASK> return r <TAB> else: <TAB>  <TAB> for iface in provided: <TAB>  <TAB>  <TAB> comps = components.get(iface) <TAB>  <TAB>  <TAB> if comps: <TAB>  <TAB>  <TAB>  <TAB> r = comps.get(name) <TAB>  <TAB>  <TAB>  <TAB> if r is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return r <TAB> return None",if r is not None :,166
3277,"def run(cmd, task=None): <TAB> process = subprocess.Popen( <TAB>  <TAB> cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, close_fds=True <TAB> ) <TAB> output_lines = [] <TAB> while True: <TAB>  <TAB> line = process.stdout.readline() <MASK> break <TAB>  <TAB> line = line.decode(""utf-8"") <TAB>  <TAB> output_lines += [line] <TAB>  <TAB> logger.info(line.rstrip(""\n"")) <TAB> process.stdout.close() <TAB> exit_code = process.wait() <TAB> if exit_code: <TAB>  <TAB> output = """".join(output_lines) <TAB>  <TAB> raise subprocess.CalledProcessError(exit_code, cmd, output=output)",if not line :,169
3278,"def process_response(self, request, response): <TAB> if ( <TAB>  <TAB> response.status_code == 404 <TAB>  <TAB> and request.path_info.endswith(""/"") <TAB>  <TAB> and not is_valid_path(request.path_info) <TAB>  <TAB> and is_valid_path(request.path_info[:-1]) <TAB> ): <TAB>  <TAB> # Use request.path because we munged app/locale in path_info. <TAB>  <TAB> newurl = request.path[:-1] <MASK> with safe_query_string(request): <TAB>  <TAB>  <TAB>  <TAB> newurl += ""?"" + request.META[""QUERY_STRING""] <TAB>  <TAB> return HttpResponsePermanentRedirect(newurl) <TAB> return response",if request . GET :,163
3279,"def dependencies(self): <TAB> deps = [] <TAB> midx = None <TAB> if self.ref is not None: <TAB>  <TAB> query = TypeQuery(self.ref) <TAB>  <TAB> super = query.execute(self.schema) <TAB>  <TAB> if super is None: <TAB>  <TAB>  <TAB> log.debug(self.schema) <TAB>  <TAB>  <TAB> raise TypeNotFound(self.ref) <MASK> deps.append(super) <TAB>  <TAB>  <TAB> midx = 0 <TAB> return (midx, deps)",if not super . builtin ( ) :,120
3280,"def _get_vtkjs(self): <TAB> if self._vtkjs is None and self.object is not None: <TAB>  <TAB> if isinstance(self.object, string_types) and self.object.endswith("".vtkjs""): <MASK> with open(self.object, ""rb"") as f: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> vtkjs = f.read() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> data_url = urlopen(self.object) <TAB>  <TAB>  <TAB>  <TAB> vtkjs = data_url.read() <TAB>  <TAB> elif hasattr(self.object, ""read""): <TAB>  <TAB>  <TAB> vtkjs = self.object.read() <TAB>  <TAB> self._vtkjs = vtkjs <TAB> return self._vtkjs",if isfile ( self . object ) :,180
3281,"def _save(self): <TAB> fd, tempname = tempfile.mkstemp() <TAB> fd = os.fdopen(fd, ""w"") <TAB> json.dump(self._cache, fd, indent=2, separators=("","", "": "")) <TAB> fd.close() <TAB> # Silently ignore errors <TAB> try: <MASK> os.makedirs(os.path.dirname(self.filename)) <TAB>  <TAB> shutil.move(tempname, self.filename) <TAB> except (IOError, OSError): <TAB>  <TAB> os.remove(tempname)",if not os . path . exists ( os . path . dirname ( self . filename ) ) :,139
3282,"def refiner_configs(self): <TAB> rv = {} <TAB> for refiner in refiner_manager: <MASK> rv[refiner.name] = {k: v for k, v in self.config.items(refiner.name)} <TAB> return rv",if self . config . has_section ( refiner . name ) :,78
3283,"def com_slice(self, primary, node, assigning): <TAB> # short_slice:  [lower_bound] "":"" [upper_bound] <TAB> lower = upper = None <TAB> if len(node.children) == 2: <MASK> upper = self.com_node(node.children[1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lower = self.com_node(node.children[0]) <TAB> elif len(node.children) == 3: <TAB>  <TAB> lower = self.com_node(node.children[0]) <TAB>  <TAB> upper = self.com_node(node.children[2]) <TAB> return Slice(primary, assigning, lower, upper, lineno=extractLineNo(node))",if node . children [ 0 ] . type == token . COLON :,177
3284,"def close(self, *args, **kwargs): <TAB> super(mytqdm, self).close(*args, **kwargs) <TAB> # If it was not run in a notebook, sp is not assigned, check for it <TAB> if hasattr(self, ""sp""): <TAB>  <TAB> # Try to detect if there was an error or KeyboardInterrupt <TAB>  <TAB> # in manual mode: if n < total, things probably got wrong <TAB>  <TAB> if self.total and self.n < self.total: <TAB>  <TAB>  <TAB> self.sp(bar_style=""danger"") <TAB>  <TAB> else: <MASK> self.sp(bar_style=""success"") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.sp(close=True)",if self . leave :,167
3285,"def test_alloc(self): <TAB> b = bytearray() <TAB> alloc = b.__alloc__() <TAB> self.assertTrue(alloc >= 0) <TAB> seq = [alloc] <TAB> for i in range(100): <TAB>  <TAB> b += b""x"" <TAB>  <TAB> alloc = b.__alloc__() <TAB>  <TAB> self.assertTrue(alloc >= len(b)) <MASK> seq.append(alloc)",if alloc not in seq :,98
3286,"def flush_file(self, key, f): <TAB> f.flush() <MASK> f.compress = zlib.compressobj( <TAB>  <TAB>  <TAB> 9, zlib.DEFLATED, -zlib.MAX_WBITS, zlib.DEF_MEM_LEVEL, 0 <TAB>  <TAB> ) <TAB> if len(self.files) > self.MAX_OPEN_FILES: <TAB>  <TAB> if self.compress: <TAB>  <TAB>  <TAB> open_files = sum(1 for f in self.files.values() if f.fileobj is not None) <TAB>  <TAB>  <TAB> if open_files > self.MAX_OPEN_FILES: <TAB>  <TAB>  <TAB>  <TAB> f.fileobj.close() <TAB>  <TAB>  <TAB>  <TAB> f.fileobj = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> f.close() <TAB>  <TAB>  <TAB> self.files.pop(key)",if self . compress :,183
3287,"def _run(self): <TAB> # Low-level run method to do the actual scheduling loop. <TAB> self.running = True <TAB> while self.running: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.sched.run() <TAB>  <TAB> except Exception as x: <TAB>  <TAB>  <TAB> logging.error( <TAB>  <TAB>  <TAB>  <TAB> ""Error during scheduler execution: %s"" % str(x), exc_info=True <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> # queue is empty; sleep a short while before checking again <MASK> time.sleep(5)",if self . running :,132
3288,"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_app_id(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> self.set_max_rows(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 16 :,124
3289,"def check(dbdef): <TAB> ""drop script must clear the database"" <TAB> for version in dbdef: <TAB>  <TAB> connector = MemConnector().bound(None) <TAB>  <TAB> create(dbdef, version, connector) <TAB>  <TAB> drop(dbdef, version, connector) <TAB>  <TAB> remaining = connector.execute( <TAB>  <TAB>  <TAB> ""SELECT * FROM sqlite_master WHERE name NOT LIKE 'sqlite_%'"" <TAB>  <TAB> ).fetchall() <MASK> yield ""{0}:drop.sql"".format(version), remaining",if remaining :,120
3290,"def test_open_overwrite_offset_size(self, sftp): <TAB> """"""Test writing data at a specific offset"""""" <TAB> f = None <TAB> try: <TAB>  <TAB> self._create_file(""file"", ""xxxxyyyy"") <TAB>  <TAB> f = yield from sftp.open(""file"", ""r+"") <TAB>  <TAB> yield from f.write(""zz"", 3) <TAB>  <TAB> yield from f.close() <TAB>  <TAB> with open(""file"") as localf: <TAB>  <TAB>  <TAB> self.assertEqual(localf.read(), ""xxxzzyyy"") <TAB> finally: <MASK> # pragma: no branch <TAB>  <TAB>  <TAB> yield from f.close() <TAB>  <TAB> remove(""file"")",if f :,155
3291,"def pump(): <TAB> import sys as _sys <TAB> while self.countdown_active(): <TAB>  <TAB> if not (self.connected(""send"") and other.connected(""recv"")): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> data = other.recv(timeout=0.05) <TAB>  <TAB> except EOFError: <TAB>  <TAB>  <TAB> break <MASK> return <TAB>  <TAB> if not data: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.send(data) <TAB>  <TAB> except EOFError: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if not _sys: <TAB>  <TAB>  <TAB> return <TAB> self.shutdown(""send"") <TAB> other.shutdown(""recv"")",if not _sys :,158
3292,"def parse_results(cwd): <TAB> optimal_dd = None <TAB> optimal_measure = numpy.inf <TAB> for tup in tools.find_conf_files(cwd): <TAB>  <TAB> dd = tup[1] <TAB>  <TAB> if ""results.train_y_misclass"" in dd: <MASK> optimal_measure = dd[""results.train_y_misclass""] <TAB>  <TAB>  <TAB>  <TAB> optimal_dd = dd <TAB> print(""Optimal results.train_y_misclass:"", str(optimal_measure)) <TAB> for key, value in optimal_dd.items(): <TAB>  <TAB> if ""hyper_parameters"" in key: <TAB>  <TAB>  <TAB> print(key + "": "" + str(value))","if dd [ ""results.train_y_misclass"" ] < optimal_measure :",177
3293,"def valid(self): <TAB> valid = True <MASK> return valid <TAB> else: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> with io.open(self.pathfile, ""w"", encoding=""utf-8"") as f: <TAB>  <TAB>  <TAB>  <TAB> f.close()  # do nothing <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> valid = False <TAB>  <TAB> if os.path.exists(self.pathfile): <TAB>  <TAB>  <TAB> os.remove(self.pathfile) <TAB>  <TAB> return valid",if os . path . exists ( self . pathfile ) :,124
3294,"def __getitem__(self, key): <TAB> try: <TAB>  <TAB> value = self.cache[key] <TAB> except KeyError: <TAB>  <TAB> f = BytesIO(self.dict[key.encode(self.keyencoding)]) <TAB>  <TAB> value = Unpickler(f).load() <MASK> self.cache[key] = value <TAB> return value",if self . writeback :,87
3295,"def hasMenu(cls, callingWindow, mainItem, selection, *fullContexts): <TAB> for i, fullContext in enumerate(fullContexts): <TAB>  <TAB> srcContext = fullContext[0] <TAB>  <TAB> for menuHandler in cls.menus: <TAB>  <TAB>  <TAB> m = menuHandler() <MASK> return True <TAB>  <TAB> return False","if m . _baseDisplay ( callingWindow , srcContext , mainItem , selection ) :",98
3296,"def lr_read_tables(module=tab_module, optimize=0): <TAB> global _lr_action, _lr_goto, _lr_productions, _lr_method <TAB> try: <TAB>  <TAB> exec(""import %s as parsetab"" % module) <TAB>  <TAB> global parsetab  # declare the name of the imported module <MASK> _lr_action = parsetab._lr_action <TAB>  <TAB>  <TAB> _lr_goto = parsetab._lr_goto <TAB>  <TAB>  <TAB> _lr_productions = parsetab._lr_productions <TAB>  <TAB>  <TAB> _lr_method = parsetab._lr_method <TAB>  <TAB>  <TAB> return 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return 0 <TAB> except (ImportError, AttributeError): <TAB>  <TAB> return 0",if ( optimize ) or ( Signature . digest ( ) == parsetab . _lr_signature ) :,192
3297,"def _Determine_Do(self): <TAB> if sys.platform.startswith(""win""): <TAB>  <TAB> self.applicable = 1 <TAB>  <TAB> for opt, optarg in self.chosenOptions: <TAB>  <TAB>  <TAB> if opt == ""--moz-tools"": <TAB>  <TAB>  <TAB>  <TAB> self.value = os.path.abspath(os.path.normpath(optarg)) <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <MASK> self.value = os.environ[self.name] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.value = None <TAB> else: <TAB>  <TAB> self.applicable = 0 <TAB> self.determined = 1",if os . environ . has_key ( self . name ) :,157
3298,"def parse_chunked(self, unreader): <TAB> (size, rest) = self.parse_chunk_size(unreader) <TAB> while size > 0: <TAB>  <TAB> while size > len(rest): <TAB>  <TAB>  <TAB> size -= len(rest) <TAB>  <TAB>  <TAB> yield rest <TAB>  <TAB>  <TAB> rest = unreader.read() <TAB>  <TAB>  <TAB> if not rest: <TAB>  <TAB>  <TAB>  <TAB> raise NoMoreData() <TAB>  <TAB> yield rest[:size] <TAB>  <TAB> # Remove \r\n after chunk <TAB>  <TAB> rest = rest[size:] <TAB>  <TAB> while len(rest) < 2: <TAB>  <TAB>  <TAB> rest += unreader.read() <MASK> raise ChunkMissingTerminator(rest[:2]) <TAB>  <TAB> (size, rest) = self.parse_chunk_size(unreader, data=rest[2:])","if rest [ : 2 ] != b""\r\n"" :",197
3299,"def _scroll_down(self, cli): <TAB> ""Scroll window down."" <TAB> info = self.render_info <TAB> if self.vertical_scroll < info.content_height - info.window_height: <MASK> self.content.move_cursor_down(cli) <TAB>  <TAB> self.vertical_scroll += 1",if info . cursor_position . y <= info . configured_scroll_offsets . top :,96
3300,"def _add_defaults_data_files(self): <TAB> # getting distribution.data_files <TAB> if self.distribution.has_data_files(): <TAB>  <TAB> for item in self.distribution.data_files: <TAB>  <TAB>  <TAB> if isinstance(item, str): <TAB>  <TAB>  <TAB>  <TAB> # plain file <TAB>  <TAB>  <TAB>  <TAB> item = convert_path(item) <TAB>  <TAB>  <TAB>  <TAB> if os.path.isfile(item): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.filelist.append(item) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> # a (dirname, filenames) tuple <TAB>  <TAB>  <TAB>  <TAB> dirname, filenames = item <TAB>  <TAB>  <TAB>  <TAB> for f in filenames: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f = convert_path(f) <MASK> self.filelist.append(f)",if os . path . isfile ( f ) :,192
3301,"def list_stuff(self, upto=10, start_after=-1): <TAB> for i in range(upto): <MASK> continue <TAB>  <TAB> if i == 2 and self.count < 1: <TAB>  <TAB>  <TAB> self.count += 1 <TAB>  <TAB>  <TAB> raise TemporaryProblem <TAB>  <TAB> if i == 7 and self.count < 4: <TAB>  <TAB>  <TAB> self.count += 1 <TAB>  <TAB>  <TAB> raise TemporaryProblem <TAB>  <TAB> yield i",if i <= start_after :,110
3302,"def is_open(self): <TAB> if self.signup_code: <TAB>  <TAB> return True <TAB> else: <MASK> if self.messages.get(""invalid_signup_code""): <TAB>  <TAB>  <TAB>  <TAB> messages.add_message( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.request, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.messages[""invalid_signup_code""][""level""], <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.messages[""invalid_signup_code""][""text""].format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> **{ <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""code"": self.get_code(), <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return settings.ACCOUNT_OPEN_SIGNUP",if self . signup_code_present :,172
3303,"def on_delete_from_disk(self, widget, data=None): <TAB> model, iter = self.get_selection().get_selected() <TAB> if iter: <TAB>  <TAB> path = model.get_value(iter, COLUMN_PATH) <MASK> ErrorDialog(_(""Can't delete system item from disk."")).launch() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> os.remove(path) <TAB> self.update_items()",if self . is_defaultitem ( path ) :,110
3304,"def get_detections_for_batch(self, images): <TAB> images = images[..., ::-1] <TAB> detected_faces = self.face_detector.detect_from_batch(images.copy()) <TAB> results = [] <TAB> for i, d in enumerate(detected_faces): <MASK> results.append(None) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> d = d[0] <TAB>  <TAB> d = np.clip(d, 0, None) <TAB>  <TAB> x1, y1, x2, y2 = map(int, d[:-1]) <TAB>  <TAB> results.append((x1, y1, x2, y2)) <TAB> return results",if len ( d ) == 0 :,159
3305,def on_update(self): <TAB> # <TAB> # Calculate maximum # of planes per well <TAB> # <TAB> self.max_per_well = 0 <TAB> for pd in list(self.plate_well_site.values()): <TAB>  <TAB> for wd in list(pd.values()): <TAB>  <TAB>  <TAB> nplanes = sum([len(x) for x in list(wd.values())]) <MASK> self.max_per_well = nplanes <TAB> for registrant in self.registrants: <TAB>  <TAB> registrant(),if nplanes > self . max_per_well :,137
3306,"def is_writable(self, path): <TAB> result = False <TAB> while not result: <TAB>  <TAB> if os.path.exists(path): <TAB>  <TAB>  <TAB> result = os.access(path, os.W_OK) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> parent = os.path.dirname(path) <MASK> break <TAB>  <TAB> path = parent <TAB> return result",if parent == path :,92
3307,"def _check_seed(self, seed): <TAB> if seed is not None: <MASK> self._raise_error( <TAB>  <TAB>  <TAB>  <TAB> ""The random number generator seed value, seed, should be integer type or None."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if seed < 0: <TAB>  <TAB>  <TAB> self._raise_error( <TAB>  <TAB>  <TAB>  <TAB> ""The random number generator seed value, seed, should be non-negative integer or None."" <TAB>  <TAB>  <TAB> )",if type ( seed ) != int :,114
3308,"def write(self, x): <TAB> # try to use backslash and surrogate escape strategies before failing <TAB> self._errors = ""backslashescape"" if self.encoding != ""mbcs"" else ""surrogateescape"" <TAB> try: <TAB>  <TAB> return io.TextIOWrapper.write(self, to_text(x, errors=self._errors)) <TAB> except UnicodeDecodeError: <MASK> self._errors = ""surrogateescape"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._errors = ""replace"" <TAB>  <TAB> return io.TextIOWrapper.write(self, to_text(x, errors=self._errors))","if self . _errors != ""surrogateescape"" :",141
3309,"def post(self, request, *args, **kwargs): <TAB> validated_session = [] <TAB> for session_id in request.data: <TAB>  <TAB> session = get_object_or_none(Session, id=session_id) <MASK> validated_session.append(session_id) <TAB>  <TAB>  <TAB> self.model.objects.create( <TAB>  <TAB>  <TAB>  <TAB> name=""kill_session"", <TAB>  <TAB>  <TAB>  <TAB> args=session.id, <TAB>  <TAB>  <TAB>  <TAB> terminal=session.terminal, <TAB>  <TAB>  <TAB> ) <TAB> return Response({""ok"": validated_session})",if session and not session . is_finished :,141
3310,"def _has_list_or_dict_var_value_before(self, arg_index): <TAB> for idx, value in enumerate(self.args): <MASK> return False <TAB>  <TAB> if variablematcher.is_list_variable( <TAB>  <TAB>  <TAB> value <TAB>  <TAB> ) and not variablematcher.is_list_variable_subitem(value): <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> if robotapi.is_dict_var(value) and not variablematcher.is_dict_var_access( <TAB>  <TAB>  <TAB> value <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> return True <TAB> return False",if idx > arg_index :,142
3311,"def test_return_correct_type(self): <TAB> for proto in protocols: <TAB>  <TAB> # Protocol 0 supports only ASCII strings. <MASK> self._check_return_correct_type(""abc"", 0) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for obj in [b""abc\n"", ""abc\n"", -1, -1.1 * 0.1, str]: <TAB>  <TAB>  <TAB>  <TAB> self._check_return_correct_type(obj, proto)",if proto == 0 :,113
3312,"def backward_impl(self, inputs, outputs, prop_down, accum): <TAB> # inputs: [inputs_fwd_graph] + [inputs_bwd_graph] or <TAB> # [inputs_fwd_graph] + [outputs_fwd_graph] + [inputs_bwd_graph] <TAB> # Args <TAB> axis = self.forward_func.info.args[""axis""] <TAB> # Compute <TAB> ## w.r.t. dy <TAB> if prop_down[-1]: <TAB>  <TAB> g_dy = inputs[-1].grad <TAB>  <TAB> g_dy_ = F.stack(*[o.grad for o in outputs], axis=axis) <MASK> g_dy += g_dy_ <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> g_dy.copy_from(g_dy_)",if accum [ - 1 ] :,190
3313,"def remove(self, url): <TAB> try: <TAB>  <TAB> i = self.items.index(url) <TAB> except (ValueError, IndexError): <TAB>  <TAB> pass <TAB> else: <TAB>  <TAB> was_selected = i in self.selectedindices() <TAB>  <TAB> self.list.delete(i) <TAB>  <TAB> del self.items[i] <TAB>  <TAB> if not self.items: <TAB>  <TAB>  <TAB> self.mp.hidepanel(self.name) <TAB>  <TAB> elif was_selected: <MASK> i = len(self.items) - 1 <TAB>  <TAB>  <TAB> self.list.select_set(i)",if i >= len ( self . items ) :,150
3314,"def prepend(self, value): <TAB> """"""prepend value to nodes"""""" <TAB> root, root_text = self._get_root(value) <TAB> for i, tag in enumerate(self): <TAB>  <TAB> if not tag.text: <TAB>  <TAB>  <TAB> tag.text = """" <TAB>  <TAB> if len(root) > 0: <TAB>  <TAB>  <TAB> root[-1].tail = tag.text <TAB>  <TAB>  <TAB> tag.text = root_text <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tag.text = root_text + tag.text <MASK> root = deepcopy(list(root)) <TAB>  <TAB> tag[:0] = root <TAB>  <TAB> root = tag[: len(root)] <TAB> return self",if i > 0 :,160
3315,"def _get_tracks_compositors_list(): <TAB> tracks_list = [] <TAB> tracks = current_sequence().tracks <TAB> compositors = current_sequence().compositors <TAB> for track_index in range(1, len(tracks) - 1): <TAB>  <TAB> track_compositors = [] <TAB>  <TAB> for j in range(0, len(compositors)): <TAB>  <TAB>  <TAB> comp = compositors[j] <MASK> track_compositors.append(comp) <TAB>  <TAB> tracks_list.append(track_compositors) <TAB> return tracks_list",if comp . transition . b_track == track_index :,143
3316,"def __getattr__(self, name): <TAB> if name in self._sections: <TAB>  <TAB> return ""\n"".join(self._sections[name]) <TAB> else: <MASK> return """" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ConanException(""ConfigParser: Unrecognized field '%s'"" % name)",if self . _allowed_fields and name in self . _allowed_fields :,86
3317,"def get_first_param_index(self, group_id, param_group, partition_id): <TAB> for index, param in enumerate(param_group): <TAB>  <TAB> param_id = self.get_param_id(param) <MASK> return index <TAB> return None",if partition_id in self . param_to_partition_ids [ group_id ] [ param_id ] :,90
3318,"def handle_uv_sockets(self, context): <TAB> u_socket = self.inputs[""U""] <TAB> v_socket = self.inputs[""V""] <TAB> if self.cast_mode == ""Sphere"": <TAB>  <TAB> u_socket.hide_safe = True <TAB>  <TAB> v_socket.hide_safe = True <TAB> elif self.cast_mode in [""Cylinder"", ""Prism""]: <TAB>  <TAB> v_socket.hide_safe = True <MASK> u_socket.hide_safe = False <TAB> else: <TAB>  <TAB> if u_socket.hide_safe: <TAB>  <TAB>  <TAB> u_socket.hide_safe = False <TAB>  <TAB> if v_socket.hide_safe: <TAB>  <TAB>  <TAB> v_socket.hide_safe = False",if u_socket . hide_safe :,184
3319,"def _scrub_generated_timestamps(self, target_workdir): <TAB> """"""Remove the first line of comment from each file if it contains a timestamp."""""" <TAB> for root, _, filenames in safe_walk(target_workdir): <TAB>  <TAB> for filename in filenames: <TAB>  <TAB>  <TAB> source = os.path.join(root, filename) <TAB>  <TAB>  <TAB> with open(source, ""r"") as f: <TAB>  <TAB>  <TAB>  <TAB> lines = f.readlines() <MASK> return <TAB>  <TAB>  <TAB> with open(source, ""w"") as f: <TAB>  <TAB>  <TAB>  <TAB> if not self._COMMENT_WITH_TIMESTAMP_RE.match(lines[0]): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f.write(lines[0]) <TAB>  <TAB>  <TAB>  <TAB> for line in lines[1:]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f.write(line)",if len ( lines ) < 1 :,196
3320,"def inner(request, *args, **kwargs): <TAB> page = request.current_page <TAB> if page: <TAB>  <TAB> if page.login_required and not request.user.is_authenticated: <TAB>  <TAB>  <TAB> return redirect_to_login( <TAB>  <TAB>  <TAB>  <TAB> urlquote(request.get_full_path()), settings.LOGIN_URL <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> site = get_current_site() <MASK> return _handle_no_page(request) <TAB> return func(request, *args, **kwargs)","if not user_can_view_page ( request . user , page , site ) :",141
3321,"def flush(self, *args, **kwargs): <TAB> with self._lock: <TAB>  <TAB> self._last_updated = time.time() <TAB>  <TAB> try: <MASK> self._locked_flush_without_tempfile() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> mailbox.mbox.flush(self, *args, **kwargs) <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> if ""_create_temporary"" in traceback.format_exc(): <TAB>  <TAB>  <TAB>  <TAB> self._locked_flush_without_tempfile() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> self._last_updated = time.time()","if kwargs . get ( ""in_place"" , False ) :",157
3322,"def sanitize_event_keys(kwargs, valid_keys): <TAB> # Sanity check: Don't honor keys that we don't recognize. <TAB> for key in list(kwargs.keys()): <TAB>  <TAB> if key not in valid_keys: <TAB>  <TAB>  <TAB> kwargs.pop(key) <TAB> # Truncate certain values over 1k <TAB> for key in [""play"", ""role"", ""task"", ""playbook""]: <MASK> if len(kwargs[""event_data""][key]) > 1024: <TAB>  <TAB>  <TAB>  <TAB> kwargs[""event_data""][key] = Truncator(kwargs[""event_data""][key]).chars( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> 1024 <TAB>  <TAB>  <TAB>  <TAB> )","if isinstance ( kwargs . get ( ""event_data"" , { } ) . get ( key ) , str ) :",168
3323,"def parse_auth(val): <TAB> if val is not None: <TAB>  <TAB> authtype, params = val.split("" "", 1) <MASK> if authtype == ""Basic"" and '""' not in params: <TAB>  <TAB>  <TAB>  <TAB> # this is the ""Authentication: Basic XXXXX=="" case <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> params = parse_auth_params(params) <TAB>  <TAB> return authtype, params <TAB> return val",if authtype in known_auth_schemes :,117
3324,"def _memoized(*args): <TAB> now = time.time() <TAB> try: <TAB>  <TAB> value, last_update = self.cache[args] <TAB>  <TAB> age = now - last_update <TAB>  <TAB> if self._call_count > self.ctl or age > self.ttl: <TAB>  <TAB>  <TAB> self._call_count = 0 <TAB>  <TAB>  <TAB> raise AttributeError <TAB>  <TAB> if self.ctl: <TAB>  <TAB>  <TAB> self._call_count += 1 <TAB>  <TAB> return value <TAB> except (KeyError, AttributeError): <TAB>  <TAB> value = func(*args) <MASK> self.cache[args] = (value, now) <TAB>  <TAB> return value <TAB> except TypeError: <TAB>  <TAB> return func(*args)",if value :,164
3325,"def _get_md_bg_color_down(self): <TAB> t = self.theme_cls <TAB> c = self.md_bg_color  # Default to no change on touch <TAB> # Material design specifies using darker hue when on Dark theme <TAB> if t.theme_style == ""Dark"": <TAB>  <TAB> if self.md_bg_color == t.primary_color: <TAB>  <TAB>  <TAB> c = t.primary_dark <MASK> c = t.accent_dark <TAB> return c",elif self . md_bg_color == t . accent_color :,135
3326,def _init_table_h(): <TAB> _table_h = [] <TAB> for i in range(256): <TAB>  <TAB> part_l = i <TAB>  <TAB> part_h = 0 <TAB>  <TAB> for j in range(8): <TAB>  <TAB>  <TAB> rflag = part_l & 1 <TAB>  <TAB>  <TAB> part_l >>= 1 <MASK> part_l |= 1 << 31 <TAB>  <TAB>  <TAB> part_h >>= 1 <TAB>  <TAB>  <TAB> if rflag: <TAB>  <TAB>  <TAB>  <TAB> part_h ^= 0xD8000000 <TAB>  <TAB> _table_h.append(part_h) <TAB> return _table_h,if part_h & 1 :,147
3327,"def migrate_Stats(self): <TAB> for old_obj in self.session_old.query(self.model_from[""Stats""]): <TAB>  <TAB> if not old_obj.summary: <TAB>  <TAB>  <TAB> self.entries_count[""Stats""] -= 1 <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> new_obj = self.model_to[""Stats""]() <TAB>  <TAB> for key in new_obj.__table__.columns._data.keys(): <MASK> continue <TAB>  <TAB>  <TAB> setattr(new_obj, key, getattr(old_obj, key)) <TAB>  <TAB> self.session_new.add(new_obj)",if key not in old_obj . __table__ . columns :,152
3328,"def get_in_turn_repetition(pred, is_cn=False): <TAB> """"""Get in-turn repetition."""""" <TAB> if len(pred) == 0: <TAB>  <TAB> return 1.0 <TAB> if isinstance(pred[0], str): <TAB>  <TAB> pred = [tok.lower() for tok in pred] <TAB>  <TAB> if is_cn: <TAB>  <TAB>  <TAB> pred = """".join(pred) <TAB> tri_grams = set() <TAB> for i in range(len(pred) - 2): <TAB>  <TAB> tri_gram = tuple(pred[i : i + 3]) <MASK> return 1.0 <TAB>  <TAB> tri_grams.add(tri_gram) <TAB> return 0.0",if tri_gram in tri_grams :,169
3329,"def translate(): <TAB> assert Lex.next() is AttributeList <TAB> reader.read()  # Discard attribute list from reader. <TAB> attrs = {} <TAB> d = AttributeList.match.groupdict() <TAB> for k, v in d.items(): <TAB>  <TAB> if v is not None: <MASK> v = subs_attrs(v) <TAB>  <TAB>  <TAB>  <TAB> if v: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> parse_attributes(v, attrs) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> AttributeList.attrs[k] = v <TAB> AttributeList.subs(attrs) <TAB> AttributeList.attrs.update(attrs)","if k == ""attrlist"" :",150
3330,"def _parse(self, engine): <TAB> """"""Parse the layer."""""" <TAB> if isinstance(self.args, dict): <TAB>  <TAB> if ""axis"" in self.args: <TAB>  <TAB>  <TAB> self.axis = engine.evaluate(self.args[""axis""], recursive=True) <MASK> raise ParsingError('""axis"" must be an integer.') <TAB>  <TAB> if ""momentum"" in self.args: <TAB>  <TAB>  <TAB> self.momentum = engine.evaluate(self.args[""momentum""], recursive=True) <TAB>  <TAB>  <TAB> if not isinstance(self.momentum, (int, float)): <TAB>  <TAB>  <TAB>  <TAB> raise ParsingError('""momentum"" must be numeric.')","if not isinstance ( self . axis , int ) :",157
3331,"def __getattr__(self, attrname): <TAB> if attrname in (""visamp"", ""visamperr"", ""visphi"", ""visphierr""): <TAB>  <TAB> return ma.masked_array(self.__dict__[""_"" + attrname], mask=self.flag) <TAB> elif attrname in (""cflux"", ""cfluxerr""): <MASK> return ma.masked_array(self.__dict__[""_"" + attrname], mask=self.flag) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return None <TAB> else: <TAB>  <TAB> raise AttributeError(attrname)","if self . __dict__ [ ""_"" + attrname ] != None :",141
3332,"def draw(self, context): <TAB> layout = self.layout <TAB> presets.draw_presets_ops(layout, context=context) <TAB> for category in presets.get_category_names(): <MASK> if category in preset_category_menus: <TAB>  <TAB>  <TAB>  <TAB> class_name = preset_category_menus[category].__name__ <TAB>  <TAB>  <TAB>  <TAB> layout.menu(class_name)",if category in preset_category_menus :,107
3333,"def __setitem__(self, key, value): <TAB> if isinstance(value, (tuple, list)): <TAB>  <TAB> info, reference = value <TAB>  <TAB> if info not in self._reverse_infos: <TAB>  <TAB>  <TAB> self._reverse_infos[info] = len(self._infos) <TAB>  <TAB>  <TAB> self._infos.append(info) <MASK> self._reverse_references[reference] = len(self._references) <TAB>  <TAB>  <TAB> self._references.append(reference) <TAB>  <TAB> self._trails[key] = ""%d,%d"" % ( <TAB>  <TAB>  <TAB> self._reverse_infos[info], <TAB>  <TAB>  <TAB> self._reverse_references[reference], <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> raise Exception(""unsupported type '%s'"" % type(value))",if reference not in self . _reverse_references :,184
3334,"def format_bpe_text(symbols, delimiter=b""@@""): <TAB> """"""Convert a sequence of bpe words into sentence."""""" <TAB> words = [] <TAB> word = b"""" <TAB> if isinstance(symbols, str): <TAB>  <TAB> symbols = symbols.encode() <TAB> delimiter_len = len(delimiter) <TAB> for symbol in symbols: <MASK> word += symbol[:-delimiter_len] <TAB>  <TAB> else:  # end of a word <TAB>  <TAB>  <TAB> word += symbol <TAB>  <TAB>  <TAB> words.append(word) <TAB>  <TAB>  <TAB> word = b"""" <TAB> return b"" "".join(words)",if len ( symbol ) >= delimiter_len and symbol [ - delimiter_len : ] == delimiter :,154
3335,"def output_type(data, request, response): <TAB> accept = request.accept <TAB> if accept in ("""", ""*"", ""/""): <TAB>  <TAB> handler = default or handlers and next(iter(handlers.values())) <TAB> else: <TAB>  <TAB> handler = default <TAB>  <TAB> accepted = [accept_quality(accept_type) for accept_type in accept.split("","")] <TAB>  <TAB> accepted.sort(key=itemgetter(0)) <TAB>  <TAB> for _quality, accepted_content_type in reversed(accepted): <MASK> handler = handlers[accepted_content_type] <TAB>  <TAB>  <TAB>  <TAB> break <TAB> if not handler: <TAB>  <TAB> raise falcon.HTTPNotAcceptable(error) <TAB> response.content_type = handler.content_type <TAB> return handler(data, request=request, response=response)",if accepted_content_type in handlers :,189
3336,"def _render_raw_list(bytes_items): <TAB> flatten_items = [] <TAB> for item in bytes_items: <TAB>  <TAB> if item is None: <TAB>  <TAB>  <TAB> flatten_items.append(b"""") <TAB>  <TAB> elif isinstance(item, bytes): <TAB>  <TAB>  <TAB> flatten_items.append(item) <MASK> flatten_items.append(str(item).encode()) <TAB>  <TAB> elif isinstance(item, list): <TAB>  <TAB>  <TAB> flatten_items.append(_render_raw_list(item)) <TAB> return b""\n"".join(flatten_items)","elif isinstance ( item , int ) :",138
3337,"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.set_mime_type(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 16: <TAB>  <TAB>  <TAB> self.set_quality(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 8 :,122
3338,"def delete(self, waiters): <TAB> # Delete flow. <TAB> msgs = self.ofctl.get_all_flow(waiters) <TAB> for msg in msgs: <TAB>  <TAB> for stats in msg.body: <TAB>  <TAB>  <TAB> vlan_id = VlanRouter._cookie_to_id(REST_VLANID, stats.cookie) <MASK> self.ofctl.delete_flow(stats) <TAB> assert len(self.packet_buffer) == 0",if vlan_id == self . vlan_id :,127
3339,def missing_push_allowance(push_allowances: List[PushAllowance]) -> bool: <TAB> for push_allowance in push_allowances: <TAB>  <TAB> # a null databaseId indicates this is not a GitHub App. <TAB>  <TAB> if push_allowance.actor.databaseId is None: <TAB>  <TAB>  <TAB> continue <MASK> return False <TAB> return True,if str ( push_allowance . actor . databaseId ) == str ( app_config . GITHUB_APP_ID ) :,112
3340,"def _cluster_page(self, htmlpage): <TAB> template_cluster, preferred = _CLUSTER_NA, None <TAB> if self.clustering: <TAB>  <TAB> self.clustering.add_page(htmlpage) <MASK> clt = self.clustering.classify(htmlpage) <TAB>  <TAB>  <TAB> if clt != -1: <TAB>  <TAB>  <TAB>  <TAB> template_cluster = preferred = self.template_names[clt] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> template_cluster = _CLUSTER_OUTLIER <TAB> return template_cluster, preferred",if self . clustering . is_fit :,136
3341,"def readlines(self, size=-1): <TAB> if self._nbr == self._size: <TAB>  <TAB> return [] <TAB> # leave all additional logic to our readline method, we just check the size <TAB> out = [] <TAB> nbr = 0 <TAB> while True: <TAB>  <TAB> line = self.readline() <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> out.append(line) <TAB>  <TAB> if size > -1: <TAB>  <TAB>  <TAB> nbr += len(line) <MASK> break <TAB>  <TAB> # END handle size constraint <TAB> # END readline loop <TAB> return out",if nbr > size :,145
3342,"def post_mortem(t=None): <TAB> # handling the default <MASK> # sys.exc_info() returns (type, value, traceback) if an exception is <TAB>  <TAB> # being handled, otherwise it returns None <TAB>  <TAB> t = sys.exc_info()[2] <TAB>  <TAB> if t is None: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""A valid traceback must be passed if no exception is being handled."" <TAB>  <TAB>  <TAB> ) <TAB> p = BPdb() <TAB> p.reset() <TAB> p.interaction(None, t)",if t is None :,132
3343,"def fixup(m): <TAB> txt = m.group(0) <TAB> if txt[:2] == ""&#"": <TAB>  <TAB> # character reference <TAB>  <TAB> try: <MASK> return unichr(int(txt[3:-1], 16)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return unichr(int(txt[2:-1])) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> pass <TAB> else: <TAB>  <TAB> # named entity <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> txt = unichr(htmlentitydefs.name2codepoint[txt[1:-1]]) <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> pass <TAB> return txt  # leave as is","if txt [ : 3 ] == ""&#x"" :",157
3344,"def parse_converter_args(argstr: str) -> t.Tuple[t.Tuple, t.Dict[str, t.Any]]: <TAB> argstr += "","" <TAB> args = [] <TAB> kwargs = {} <TAB> for item in _converter_args_re.finditer(argstr): <TAB>  <TAB> value = item.group(""stringval"") <MASK> value = item.group(""value"") <TAB>  <TAB> value = _pythonize(value) <TAB>  <TAB> if not item.group(""name""): <TAB>  <TAB>  <TAB> args.append(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = item.group(""name"") <TAB>  <TAB>  <TAB> kwargs[name] = value <TAB> return tuple(args), kwargs",if value is None :,164
3345,"def IT(cpu): <TAB> cc = cpu.instruction.cc <TAB> true_case = cpu._evaluate_conditional(cc) <TAB> # this is incredibly hacky--how else does capstone expose this? <TAB> # TODO: find a better way than string parsing the mnemonic -GR, 2017-07-13 <TAB> for c in cpu.instruction.mnemonic[1:]: <MASK> cpu._it_conditional.append(true_case) <TAB>  <TAB> elif c == ""e"": <TAB>  <TAB>  <TAB> cpu._it_conditional.append(not true_case)","if c == ""t"" :",138
3346,"def flatten(self): <TAB> # this is similar to fill_messages except it uses a list instead <TAB> # of a queue to place the messages in. <TAB> result = [] <TAB> channel = await self.messageable._get_channel() <TAB> self.channel = channel <TAB> while self._get_retrieve(): <TAB>  <TAB> data = await self._retrieve_messages(self.retrieve) <MASK> self.limit = 0  # terminate the infinite loop <TAB>  <TAB> if self.reverse: <TAB>  <TAB>  <TAB> data = reversed(data) <TAB>  <TAB> if self._filter: <TAB>  <TAB>  <TAB> data = filter(self._filter, data) <TAB>  <TAB> for element in data: <TAB>  <TAB>  <TAB> result.append(self.state.create_message(channel=channel, data=element)) <TAB> return result",if len ( data ) < 100 :,187
3347,"def _get_beta_accumulators(self): <TAB> with tf.init_scope(): <MASK> graph = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> graph = tf.get_default_graph() <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB> self._get_non_slot_variable(""beta1_power"", graph=graph), <TAB>  <TAB>  <TAB> self._get_non_slot_variable(""beta2_power"", graph=graph), <TAB>  <TAB> )",if tf . executing_eagerly ( ) :,113
3348,"def prefixed(self, prefix: _StrType) -> typing.Iterator[""Env""]: <TAB> """"""Context manager for parsing envvars with a common prefix."""""" <TAB> try: <TAB>  <TAB> old_prefix = self._prefix <MASK> self._prefix = prefix <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._prefix = f""{old_prefix}{prefix}"" <TAB>  <TAB> yield self <TAB> finally: <TAB>  <TAB> # explicitly reset the stored prefix on completion and exceptions <TAB>  <TAB> self._prefix = None <TAB> self._prefix = old_prefix",if old_prefix is None :,126
3349,"def decode_content(self): <TAB> """"""Return the best possible representation of the response body."""""" <TAB> ct = self.headers.get(""content-type"") <TAB> if ct: <TAB>  <TAB> ct, options = parse_options_header(ct) <TAB>  <TAB> charset = options.get(""charset"") <TAB>  <TAB> if ct in JSON_CONTENT_TYPES: <TAB>  <TAB>  <TAB> return self.json(charset) <MASK> return self.text(charset) <TAB>  <TAB> elif ct == FORM_URL_ENCODED: <TAB>  <TAB>  <TAB> return parse_qsl(self.content.decode(charset), keep_blank_values=True) <TAB> return self.content","elif ct . startswith ( ""text/"" ) :",156
3350,"def test_incrementaldecoder(self): <TAB> UTF8Writer = codecs.getwriter(""utf-8"") <TAB> for sizehint in [None, -1] + list(range(1, 33)) + [64, 128, 256, 512, 1024]: <TAB>  <TAB> istream = BytesIO(self.tstring[0]) <TAB>  <TAB> ostream = UTF8Writer(BytesIO()) <TAB>  <TAB> decoder = self.incrementaldecoder() <TAB>  <TAB> while 1: <TAB>  <TAB>  <TAB> data = istream.read(sizehint) <MASK> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> u = decoder.decode(data) <TAB>  <TAB>  <TAB>  <TAB> ostream.write(u) <TAB>  <TAB> self.assertEqual(ostream.getvalue(), self.tstring[1])",if not data :,178
3351,"def delete_all(path): <TAB> ppath = os.getcwd() <TAB> os.chdir(path) <TAB> for fn in glob.glob(""*""): <TAB>  <TAB> fn_full = os.path.join(path, fn) <MASK> delete_all(fn_full) <TAB>  <TAB> elif fn.endswith("".png""): <TAB>  <TAB>  <TAB> os.remove(fn_full) <TAB>  <TAB> elif fn.endswith("".md""): <TAB>  <TAB>  <TAB> os.remove(fn_full) <TAB>  <TAB> elif DELETE_ALL_OLD: <TAB>  <TAB>  <TAB> os.remove(fn_full) <TAB> os.chdir(ppath) <TAB> os.rmdir(path)",if os . path . isdir ( fn ) :,158
3352,"def _delete_reason(self): <TAB> for i in range(_lib.X509_REVOKED_get_ext_count(self._revoked)): <TAB>  <TAB> ext = _lib.X509_REVOKED_get_ext(self._revoked, i) <TAB>  <TAB> obj = _lib.X509_EXTENSION_get_object(ext) <MASK> _lib.X509_EXTENSION_free(ext) <TAB>  <TAB>  <TAB> _lib.X509_REVOKED_delete_ext(self._revoked, i) <TAB>  <TAB>  <TAB> break",if _lib . OBJ_obj2nid ( obj ) == _lib . NID_crl_reason :,158
3353,"def hexcmp(x, y): <TAB> try: <TAB>  <TAB> a = int(x, 16) <TAB>  <TAB> b = int(y, 16) <TAB>  <TAB> if a < b: <TAB>  <TAB>  <TAB> return -1 <MASK> return 1 <TAB>  <TAB> return 0 <TAB> except: <TAB>  <TAB> return cmp(x, y)",if a > b :,83
3354,"def get_indentation_count(view, start): <TAB> indent_count = 0 <TAB> i = start - 1 <TAB> while i > 0: <TAB>  <TAB> ch = view.substr(i) <TAB>  <TAB> scope = view.scope_name(i) <TAB>  <TAB> # Skip preprocessors, strings, characaters and comments <TAB>  <TAB> if ""string.quoted"" in scope or ""comment"" in scope or ""preprocessor"" in scope: <TAB>  <TAB>  <TAB> extent = view.extract_scope(i) <TAB>  <TAB>  <TAB> i = extent.a - 1 <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> i -= 1 <MASK> indent_count -= 1 <TAB>  <TAB> elif ch == ""{"": <TAB>  <TAB>  <TAB> indent_count += 1 <TAB> return indent_count","if ch == ""}"" :",177
3355,"def set(self, name, value, ex=None, px=None, nx=False, xx=False): <TAB> if ( <TAB>  <TAB> (not nx and not xx) <TAB>  <TAB> or (nx and self._db.get(name, None) is None) <TAB>  <TAB> or (xx and not self._db.get(name, None) is None) <TAB> ): <TAB>  <TAB> if ex > 0: <TAB>  <TAB>  <TAB> self._db.expire(name, datetime.now() + timedelta(seconds=ex)) <MASK> self._db.expire(name, datetime.now() + timedelta(milliseconds=px)) <TAB>  <TAB> self._db[name] = str(value) <TAB>  <TAB> return True <TAB> else: <TAB>  <TAB> return None",elif px > 0 :,174
3356,"def _get_between(content, start, end=None): <TAB> should_yield = False <TAB> for line in content.split(""\n""): <TAB>  <TAB> if start in line: <TAB>  <TAB>  <TAB> should_yield = True <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if end and end in line: <TAB>  <TAB>  <TAB> return <MASK> yield line.strip().split("" "")[0]",if should_yield and line :,94
3357,"def iter_event_handlers( <TAB> self, <TAB> resource: resources_.Resource, <TAB> event: bodies.RawEvent,) -> Iterator[handlers.ResourceWatchingHandler]: <TAB> warnings.warn( <TAB>  <TAB> ""SimpleRegistry.iter_event_handlers() is deprecated; use "" <TAB>  <TAB> ""ResourceWatchingRegistry.iter_handlers()."", <TAB>  <TAB> DeprecationWarning, <TAB> ) <TAB> cause = _create_watching_cause(resource, event) <TAB> for handler in self._handlers: <MASK> pass <TAB>  <TAB> elif registries.match(handler=handler, cause=cause, ignore_fields=True): <TAB>  <TAB>  <TAB> yield handler","if not isinstance ( handler , handlers . ResourceWatchingHandler ) :",160
3358,"def __enter__(self): <TAB> if log_timer: <MASK> self.logger.debug(""%s starting"" % self.name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print((""[%s starting]..."" % self.name)) <TAB>  <TAB> self.tstart = time.time()",if self . logger :,74
3359,"def _handle_errors(errors): <TAB> """"""Log out and possibly reraise errors during import."""""" <TAB> if not errors: <TAB>  <TAB> return <TAB> log_all = True  # pylint: disable=unused-variable <TAB> err_msg = ""T2T: skipped importing {num_missing} data_generators modules."" <TAB> print(err_msg.format(num_missing=len(errors))) <TAB> for module, err in errors: <TAB>  <TAB> err_str = str(err) <MASK> print(""Did not import module: %s; Cause: %s"" % (module, err_str)) <TAB>  <TAB> if not _is_import_err_msg(err_str, module): <TAB>  <TAB>  <TAB> print(""From module %s"" % module) <TAB>  <TAB>  <TAB> raise err",if log_all :,184
3360,"def _ungroup(sequence, groups=None): <TAB> for v in sequence: <TAB>  <TAB> if isinstance(v, (list, tuple)): <MASK> groups.append(list(_ungroup(v, groups=None))) <TAB>  <TAB>  <TAB> for v in _ungroup(v, groups): <TAB>  <TAB>  <TAB>  <TAB> yield v <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield v",if groups is not None :,95
3361,def run(self): <TAB> while not self.completed: <TAB>  <TAB> if self.block: <TAB>  <TAB>  <TAB> time.sleep(self.period) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._completed.wait(self.period) <TAB>  <TAB> self.counter += 1 <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.callback(self.counter) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> self.stop() <TAB>  <TAB> if self.timeout is not None: <TAB>  <TAB>  <TAB> dt = time.time() - self._start_time <MASK> self.stop() <TAB>  <TAB> if self.counter == self.count: <TAB>  <TAB>  <TAB> self.stop(),if dt > self . timeout :,159
3362,"def dont_let_stderr_buffer(): <TAB> while True: <TAB>  <TAB> line = context.daemon.stderr.readline() <MASK> return <TAB>  <TAB> if DEAD_DEPLOYD_WORKER_MESSAGE.encode(""utf-8"") in line: <TAB>  <TAB>  <TAB> context.num_workers_crashed += 1 <TAB>  <TAB> print(f""deployd stderr: {line}"")",if not line :,93
3363,"def mergeHiLo(self, x_stats): <TAB> """"""Merge the highs and lows of another accumulator into myself."""""" <TAB> if x_stats.firsttime is not None: <TAB>  <TAB> if self.firsttime is None or x_stats.firsttime < self.firsttime: <TAB>  <TAB>  <TAB> self.firsttime = x_stats.firsttime <TAB>  <TAB>  <TAB> self.first = x_stats.first <TAB> if x_stats.lasttime is not None: <MASK> self.lasttime = x_stats.lasttime <TAB>  <TAB>  <TAB> self.last = x_stats.last",if self . lasttime is None or x_stats . lasttime >= self . lasttime :,157
3364,"def test_rlimit_get(self): <TAB> import resource <TAB> p = psutil.Process(os.getpid()) <TAB> names = [x for x in dir(psutil) if x.startswith(""RLIMIT"")] <TAB> assert names <TAB> for name in names: <TAB>  <TAB> value = getattr(psutil, name) <TAB>  <TAB> self.assertGreaterEqual(value, 0) <MASK> self.assertEqual(value, getattr(resource, name)) <TAB>  <TAB>  <TAB> self.assertEqual(p.rlimit(value), resource.getrlimit(value)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret = p.rlimit(value) <TAB>  <TAB>  <TAB> self.assertEqual(len(ret), 2) <TAB>  <TAB>  <TAB> self.assertGreaterEqual(ret[0], -1) <TAB>  <TAB>  <TAB> self.assertGreaterEqual(ret[1], -1)",if name in dir ( resource ) :,192
3365,"def _calculate_writes_for_built_in_indices(self, entity): <TAB> writes = 0 <TAB> for prop_name in entity.keys(): <TAB>  <TAB> if not prop_name in entity.unindexed_properties(): <TAB>  <TAB>  <TAB> prop_vals = entity[prop_name] <MASK> num_prop_vals = len(prop_vals) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> num_prop_vals = 1 <TAB>  <TAB>  <TAB> writes += 2 * num_prop_vals <TAB> return writes","if isinstance ( prop_vals , ( list ) ) :",131
3366,"def check_value_check(self, x_data, t_data, use_cudnn): <TAB> x = chainer.Variable(x_data) <TAB> t = chainer.Variable(t_data) <TAB> with chainer.using_config(""use_cudnn"", use_cudnn): <MASK> # Check if it throws nothing <TAB>  <TAB>  <TAB> functions.softmax_cross_entropy( <TAB>  <TAB>  <TAB>  <TAB> x, t, enable_double_backprop=self.enable_double_backprop <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> with self.assertRaises(ValueError): <TAB>  <TAB>  <TAB>  <TAB> functions.softmax_cross_entropy( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> x, t, enable_double_backprop=self.enable_double_backprop <TAB>  <TAB>  <TAB>  <TAB> )",if self . valid :,188
3367,"def get_note_title_file(note): <TAB> mo = note_title_re.match(note.get(""content"", """")) <TAB> if mo: <TAB>  <TAB> fn = mo.groups()[0] <TAB>  <TAB> fn = fn.replace("" "", ""_"") <TAB>  <TAB> fn = fn.replace(""/"", ""_"") <MASK> return """" <TAB>  <TAB> if isinstance(fn, str): <TAB>  <TAB>  <TAB> fn = unicode(fn, ""utf-8"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> fn = unicode(fn) <TAB>  <TAB> if note_markdown(note): <TAB>  <TAB>  <TAB> fn += "".mkdn"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> fn += "".txt"" <TAB>  <TAB> return fn <TAB> else: <TAB>  <TAB> return """"",if not fn :,169
3368,"def _parseparam(s): <TAB> plist = [] <TAB> while s[:1] == "";"": <TAB>  <TAB> s = s[1:] <TAB>  <TAB> end = s.find("";"") <TAB>  <TAB> while end > 0 and (s.count('""', 0, end) - s.count('\\""', 0, end)) % 2: <TAB>  <TAB>  <TAB> end = s.find("";"", end + 1) <TAB>  <TAB> if end < 0: <TAB>  <TAB>  <TAB> end = len(s) <TAB>  <TAB> f = s[:end] <MASK> i = f.index(""="") <TAB>  <TAB>  <TAB> f = f[:i].strip().lower() + ""="" + f[i + 1 :].strip() <TAB>  <TAB> plist.append(f.strip()) <TAB>  <TAB> s = s[end:] <TAB> return plist","if ""="" in f :",177
3369,"def doDir(elem): <TAB> for child in elem.childNodes: <TAB>  <TAB> if not isinstance(child, minidom.Element): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if child.tagName == ""Directory"": <TAB>  <TAB>  <TAB> doDir(child) <TAB>  <TAB> elif child.tagName == ""Component"": <TAB>  <TAB>  <TAB> for grandchild in child.childNodes: <TAB>  <TAB>  <TAB>  <TAB> if not isinstance(grandchild, minidom.Element): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB>  <TAB>  <TAB> files.add(grandchild.getAttribute(""Source"").replace(os.sep, ""/""))","if grandchild . tagName != ""File"" :",152
3370,"def date_to_format(value, target_format): <TAB> """"""Convert date to specified format"""""" <TAB> if target_format == str: <MASK> ret = value.strftime(""%d/%m/%y"") <TAB>  <TAB> elif isinstance(value, datetime.datetime): <TAB>  <TAB>  <TAB> ret = value.strftime(""%d/%m/%y"") <TAB>  <TAB> elif isinstance(value, datetime.time): <TAB>  <TAB>  <TAB> ret = value.strftime(""%H:%M:%S"") <TAB> else: <TAB>  <TAB> ret = value <TAB> return ret","if isinstance ( value , datetime . date ) :",130
3371,"def __listingColumns(self): <TAB> columns = [] <TAB> for name in self.__getColumns(): <TAB>  <TAB> definition = column(name) <MASK> IECore.msg( <TAB>  <TAB>  <TAB>  <TAB> IECore.Msg.Level.Error, <TAB>  <TAB>  <TAB>  <TAB> ""GafferImageUI.CatalogueUI"", <TAB>  <TAB>  <TAB>  <TAB> ""No column registered with name '%s'"" % name, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if isinstance(definition, IconColumn): <TAB>  <TAB>  <TAB> c = GafferUI.PathListingWidget.IconColumn(definition.title(), """", name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> c = GafferUI.PathListingWidget.StandardColumn(definition.title(), name) <TAB>  <TAB> columns.append(c) <TAB> return columns",if not definition :,184
3372,"def metrics_to_scalars(self, metrics): <TAB> new_metrics = {} <TAB> for k, v in metrics.items(): <MASK> v = v.item() <TAB>  <TAB> if isinstance(v, dict): <TAB>  <TAB>  <TAB> v = self.metrics_to_scalars(v) <TAB>  <TAB> new_metrics[k] = v <TAB> return new_metrics","if isinstance ( v , torch . Tensor ) :",95
3373,"def start(self, connection): <TAB> try: <TAB>  <TAB> if self.client_name: <TAB>  <TAB>  <TAB> creds = gssapi.Credentials(name=gssapi.Name(self.client_name)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> creds = None <TAB>  <TAB> hostname = self.get_hostname(connection) <TAB>  <TAB> name = gssapi.Name( <TAB>  <TAB>  <TAB> b""@"".join([self.service, hostname]), gssapi.NameType.hostbased_service <TAB>  <TAB> ) <TAB>  <TAB> context = gssapi.SecurityContext(name=name, creds=creds) <TAB>  <TAB> return context.step(None) <TAB> except gssapi.raw.misc.GSSError: <MASK> return NotImplemented <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise",if self . fail_soft :,186
3374,"def nanmax(self, axis=None, dtype=None, keepdims=None): <TAB> ret = self._reduction( <TAB>  <TAB> ""nanmax"", axis=axis, dtype=dtype, keepdims=keepdims, todense=True <TAB> ) <TAB> if not issparse(ret): <MASK> return ret <TAB>  <TAB> xps = get_sparse_module(self.spmatrix) <TAB>  <TAB> ret = SparseNDArray(xps.csr_matrix(ret)) <TAB>  <TAB> return ret <TAB> return ret",if get_array_module ( ret ) . isscalar ( ret ) :,120
3375,"def utterance_to_sample(query_data, tagging_scheme, language): <TAB> tokens, tags = [], [] <TAB> current_length = 0 <TAB> for chunk in query_data: <TAB>  <TAB> chunk_tokens = tokenize(chunk[TEXT], language) <TAB>  <TAB> tokens += [ <TAB>  <TAB>  <TAB> Token(t.value, current_length + t.start, current_length + t.end) <TAB>  <TAB>  <TAB> for t in chunk_tokens <TAB>  <TAB> ] <TAB>  <TAB> current_length += len(chunk[TEXT]) <MASK> tags += negative_tagging(len(chunk_tokens)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tags += positive_tagging( <TAB>  <TAB>  <TAB>  <TAB> tagging_scheme, chunk[SLOT_NAME], len(chunk_tokens) <TAB>  <TAB>  <TAB> ) <TAB> return {TOKENS: tokens, TAGS: tags}",if SLOT_NAME not in chunk :,200
3376,"def use_index( <TAB> self, term: Union[str, Index], *terms: Union[str, Index]) -> ""QueryBuilder"": <TAB> for t in (term, *terms): <TAB>  <TAB> if isinstance(t, Index): <TAB>  <TAB>  <TAB> self._use_indexes.append(t) <MASK> self._use_indexes.append(Index(t))","elif isinstance ( t , str ) :",94
3377,"def reconfigServiceWithBuildbotConfig(self, new_config): <TAB> if new_config.manhole != self.manhole: <TAB>  <TAB> if self.manhole: <TAB>  <TAB>  <TAB> yield self.manhole.disownServiceParent() <TAB>  <TAB>  <TAB> self.manhole = None <MASK> self.manhole = new_config.manhole <TAB>  <TAB>  <TAB> yield self.manhole.setServiceParent(self) <TAB> # chain up <TAB> yield service.ReconfigurableServiceMixin.reconfigServiceWithBuildbotConfig( <TAB>  <TAB> self, new_config <TAB> )",if new_config . manhole :,142
3378,"def cleanup_folder(target_folder): <TAB> for file in os.listdir(target_folder): <TAB>  <TAB> file_path = os.path.join(target_folder, file) <TAB>  <TAB> try: <MASK> os.remove(file_path) <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> logging.error(e)",if os . path . isfile ( file_path ) :,93
3379,"def to_key(literal_or_identifier): <TAB> """"""returns string representation of this object"""""" <TAB> if literal_or_identifier[""type""] == ""Identifier"": <TAB>  <TAB> return literal_or_identifier[""name""] <TAB> elif literal_or_identifier[""type""] == ""Literal"": <TAB>  <TAB> k = literal_or_identifier[""value""] <MASK> return unicode(float_repr(k)) <TAB>  <TAB> elif ""regex"" in literal_or_identifier: <TAB>  <TAB>  <TAB> return compose_regex(k) <TAB>  <TAB> elif isinstance(k, bool): <TAB>  <TAB>  <TAB> return ""true"" if k else ""false"" <TAB>  <TAB> elif k is None: <TAB>  <TAB>  <TAB> return ""null"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return unicode(k)","if isinstance ( k , float ) :",179
3380,"def decompile(decompiler): <TAB> for pos, next_pos, opname, arg in decompiler.instructions: <TAB>  <TAB> if pos in decompiler.targets: <TAB>  <TAB>  <TAB> decompiler.process_target(pos) <TAB>  <TAB> method = getattr(decompiler, opname, None) <MASK> throw(DecompileError(""Unsupported operation: %s"" % opname)) <TAB>  <TAB> decompiler.pos = pos <TAB>  <TAB> decompiler.next_pos = next_pos <TAB>  <TAB> x = method(*arg) <TAB>  <TAB> if x is not None: <TAB>  <TAB>  <TAB> decompiler.stack.append(x)",if method is None :,143
3381,"def shutdown(self, timeout, callback=None): <TAB> logger.debug(""background worker got shutdown request"") <TAB> with self._lock: <TAB>  <TAB> if self.is_alive: <TAB>  <TAB>  <TAB> self._queue.put_nowait(_TERMINATOR) <MASK> self._wait_shutdown(timeout, callback) <TAB>  <TAB> self._thread = None <TAB>  <TAB> self._thread_for_pid = None <TAB> logger.debug(""background worker shut down"")",if timeout > 0.0 :,113
3382,"def getDOMImplementation(features=None): <TAB> if features: <MASK> features = domreg._parse_feature_string(features) <TAB>  <TAB> for f, v in features: <TAB>  <TAB>  <TAB> if not Document.implementation.hasFeature(f, v): <TAB>  <TAB>  <TAB>  <TAB> return None <TAB> return Document.implementation","if isinstance ( features , str ) :",83
3383,"def validate_subevent(self, subevent): <TAB> if self.context[""event""].has_subevents: <MASK> raise ValidationError(""You need to set a subevent."") <TAB>  <TAB> if subevent.event != self.context[""event""]: <TAB>  <TAB>  <TAB> raise ValidationError( <TAB>  <TAB>  <TAB>  <TAB> ""The specified subevent does not belong to this event."" <TAB>  <TAB>  <TAB> ) <TAB> elif subevent: <TAB>  <TAB> raise ValidationError(""You cannot set a subevent for this event."") <TAB> return subevent",if not subevent :,120
3384,"def einsum(job_id, idx, einsum_expr, data_list): <TAB> _, all_parties = session_init(job_id, idx) <TAB> with SPDZ(): <MASK> x = FixedPointTensor.from_source(""x"", data_list[0]) <TAB>  <TAB>  <TAB> y = FixedPointTensor.from_source(""y"", all_parties[1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> x = FixedPointTensor.from_source(""x"", all_parties[0]) <TAB>  <TAB>  <TAB> y = FixedPointTensor.from_source(""y"", data_list[1]) <TAB>  <TAB> return x.einsum(y, einsum_expr).get()",if idx == 0 :,162
3385,"def slowSorted(qq): <TAB> ""Reference sort peformed by insertion using only <"" <TAB> rr = list() <TAB> for q in qq: <TAB>  <TAB> i = 0 <TAB>  <TAB> for i in range(len(rr)): <MASK> rr.insert(i, q) <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> rr.append(q) <TAB> return rr",if q < rr [ i ] :,101
3386,"def _format_entry(entry, src): <TAB> if entry: <TAB>  <TAB> result = [] <TAB>  <TAB> for x in entry.split("",""): <TAB>  <TAB>  <TAB> x = x.strip() <TAB>  <TAB>  <TAB> if os.path.exists(os.path.join(src, x)): <TAB>  <TAB>  <TAB>  <TAB> result.append(relpath(os.path.join(src, x), src)) <MASK> result.append(relpath(os.path.abspath(x), src)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise RuntimeError(""No entry script %s found"" % x) <TAB>  <TAB> return "","".join(result)",elif os . path . exists ( x ) :,153
3387,"def reloadCols(self): <TAB> self.columns = [] <TAB> for i, (name, fmt, *shape) in enumerate(self.npy.dtype.descr): <TAB>  <TAB> if shape: <TAB>  <TAB>  <TAB> t = anytype <TAB>  <TAB> elif ""M"" in fmt: <TAB>  <TAB>  <TAB> self.addColumn(Column(name, type=date, getter=lambda c, r, i=i: str(r[i]))) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif ""i"" in fmt: <TAB>  <TAB>  <TAB> t = int <MASK> t = float <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> t = anytype <TAB>  <TAB> self.addColumn(ColumnItem(name, i, type=t))","elif ""f"" in fmt :",168
3388,"def tool_lineages(self, trans): <TAB> rval = [] <TAB> for id, tool in self.app.toolbox.tools(): <MASK> lineage_dict = tool.lineage.to_dict() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lineage_dict = None <TAB>  <TAB> entry = dict(id=id, lineage=lineage_dict) <TAB>  <TAB> rval.append(entry) <TAB> return rval","if hasattr ( tool , ""lineage"" ) :",102
3389,"def item(self, tensor): <TAB> numel = 0 <TAB> if len(tensor.shape) > 0: <TAB>  <TAB> numel = fct.reduce(op.mul, tensor.shape) <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> f""expected tensor with one element, "" f""got {tensor.shape}"" <TAB>  <TAB>  <TAB> ) <TAB> if numel == 1: <TAB>  <TAB> return tensor[0] <TAB> return tensor",if numel != 1 :,105
3390,"def get_host_metadata(self): <TAB> meta = {} <TAB> if self.agent_url: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> resp = requests.get( <TAB>  <TAB>  <TAB>  <TAB> self.agent_url + ECS_AGENT_METADATA_PATH, timeout=1 <TAB>  <TAB>  <TAB> ).json() <TAB>  <TAB>  <TAB> if ""Version"" in resp: <TAB>  <TAB>  <TAB>  <TAB> match = AGENT_VERSION_EXP.search(resp.get(""Version"")) <MASK> meta[""ecs_version""] = match.group(1) <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> self.log.debug(""Error getting ECS version: %s"" % str(e)) <TAB> return meta",if match is not None and len ( match . groups ( ) ) == 1 :,176
3391,"def generate(): <TAB> for leaf in u.leaves: <TAB>  <TAB> if isinstance(leaf, Integer): <TAB>  <TAB>  <TAB> val = leaf.get_int_value() <TAB>  <TAB>  <TAB> if val in (0, 1): <TAB>  <TAB>  <TAB>  <TAB> yield val <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise _NoBoolVector <TAB>  <TAB> elif isinstance(leaf, Symbol): <MASK> yield 1 <TAB>  <TAB>  <TAB> elif leaf == SymbolFalse: <TAB>  <TAB>  <TAB>  <TAB> yield 0 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise _NoBoolVector <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise _NoBoolVector",if leaf == SymbolTrue :,138
3392,"def _test_set_metadata(self, metadata, mask=None): <TAB> header = ofproto.OXM_OF_METADATA <TAB> match = OFPMatch() <TAB> if mask is None: <TAB>  <TAB> match.set_metadata(metadata) <TAB> else: <MASK> header = ofproto.OXM_OF_METADATA_W <TAB>  <TAB> match.set_metadata_masked(metadata, mask) <TAB>  <TAB> metadata &= mask <TAB> self._test_serialize_and_parser(match, header, metadata, mask)",if ( mask + 1 ) >> 64 != 1 :,134
3393,"def pixbufrenderer(self, column, crp, model, it): <TAB> tok = model.get_value(it, 0) <TAB> if tok.type == ""class"": <TAB>  <TAB> icon = ""class"" <TAB> else: <TAB>  <TAB> if tok.visibility == ""private"": <TAB>  <TAB>  <TAB> icon = ""method_priv"" <MASK> icon = ""method_prot"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> icon = ""method"" <TAB> crp.set_property(""pixbuf"", imagelibrary.pixbufs[icon])","elif tok . visibility == ""protected"" :",132
3394,"def path_sum2(root, s): <TAB> if root is None: <TAB>  <TAB> return [] <TAB> res = [] <TAB> stack = [(root, [root.val])] <TAB> while stack: <TAB>  <TAB> node, ls = stack.pop() <TAB>  <TAB> if node.left is None and node.right is None and sum(ls) == s: <TAB>  <TAB>  <TAB> res.append(ls) <MASK> stack.append((node.left, ls + [node.left.val])) <TAB>  <TAB> if node.right is not None: <TAB>  <TAB>  <TAB> stack.append((node.right, ls + [node.right.val])) <TAB> return res",if node . left is not None :,157
3395,"def clear_slot(self, slot_id, trigger_changed): <TAB> if self.slots[slot_id] is not None: <TAB>  <TAB> old_resource_id = self.slots[slot_id].resource_id <MASK> del self.sell_list[old_resource_id] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> del self.buy_list[old_resource_id] <TAB> self.slots[slot_id] = None <TAB> if trigger_changed: <TAB>  <TAB> self._changed()",if self . slots [ slot_id ] . selling :,132
3396,"def OnRightUp(self, event): <TAB> self.HandleMouseEvent(event) <TAB> self.Unbind(wx.EVT_RIGHT_UP, handler=self.OnRightUp) <TAB> self.Unbind(wx.EVT_MOUSE_CAPTURE_LOST, handler=self.OnRightUp) <TAB> self._right = False <TAB> if not self._left: <TAB>  <TAB> self.Unbind(wx.EVT_MOTION, handler=self.OnMotion) <TAB>  <TAB> self.SendChangeEvent() <TAB>  <TAB> self.SetToolTip(wx.ToolTip(self._tooltip)) <MASK> self.ReleaseMouse()",if self . HasCapture ( ) :,150
3397,"def __init__(self, *args, **kwargs): <TAB> for arg in args: <TAB>  <TAB> for k, v in arg.items(): <MASK> arg[k] = AttrDict(v) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> arg[k] = v <TAB> super(AttrDict, self).__init__(*args, **kwargs)","if isinstance ( v , dict ) :",89
3398,"def _toplevelTryFunc(func, *args, status=status, **kwargs): <TAB> with ThreadProfiler(threading.current_thread()) as prof: <TAB>  <TAB> t = threading.current_thread() <TAB>  <TAB> t.name = func.__name__ <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> t.status = func(*args, **kwargs) <TAB>  <TAB> except EscapeException as e:  # user aborted <TAB>  <TAB>  <TAB> t.status = ""aborted by user"" <TAB>  <TAB>  <TAB> if status: <TAB>  <TAB>  <TAB>  <TAB> status(""%s aborted"" % t.name, priority=2) <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> t.exception = e <TAB>  <TAB>  <TAB> t.status = ""exception"" <TAB>  <TAB>  <TAB> vd.exceptionCaught(e) <MASK> t.sheet.currentThreads.remove(t)",if t . sheet :,193
3399,"def comboSelectionChanged(self, index): <TAB> text = self.comboBox.cb.itemText(index) <TAB> for i in range(self.labelList.count()): <TAB>  <TAB> if text == """": <TAB>  <TAB>  <TAB> self.labelList.item(i).setCheckState(2) <MASK> self.labelList.item(i).setCheckState(0) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.labelList.item(i).setCheckState(2)",elif text != self . labelList . item ( i ) . text ( ) :,120
3400,"def __attempt_add_to_linked_match( <TAB> self, input_name, hdca, collection_type_description, subcollection_type): <TAB> structure = get_structure( <TAB>  <TAB> hdca, collection_type_description, leaf_subcollection_type=subcollection_type <TAB> ) <TAB> if not self.linked_structure: <TAB>  <TAB> self.linked_structure = structure <TAB>  <TAB> self.collections[input_name] = hdca <TAB>  <TAB> self.subcollection_types[input_name] = subcollection_type <TAB> else: <MASK> raise exceptions.MessageException(CANNOT_MATCH_ERROR_MESSAGE) <TAB>  <TAB> self.collections[input_name] = hdca <TAB>  <TAB> self.subcollection_types[input_name] = subcollection_type",if not self . linked_structure . can_match ( structure ) :,194
3401,"def _wait_for_bot_presense(self, online): <TAB> for _ in range(10): <TAB>  <TAB> time.sleep(2) <MASK> break <TAB>  <TAB> if not online and not self._is_testbot_online(): <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> raise AssertionError( <TAB>  <TAB>  <TAB> ""test bot is still {}"".format(""offline"" if online else ""online"") <TAB>  <TAB> )",if online and self . _is_testbot_online ( ) :,111
3402,"def find(self, path): <TAB> if os.path.isfile(path) or os.path.islink(path): <TAB>  <TAB> self.num_files = self.num_files + 1 <MASK> self.files.append(path) <TAB> elif os.path.isdir(path): <TAB>  <TAB> for content in os.listdir(path): <TAB>  <TAB>  <TAB> file = os.path.join(path, content) <TAB>  <TAB>  <TAB> if os.path.isfile(file) or os.path.islink(file): <TAB>  <TAB>  <TAB>  <TAB> self.num_files = self.num_files + 1 <TAB>  <TAB>  <TAB>  <TAB> if self.match_function(file): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.files.append(file) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.find(file)",if self . match_function ( path ) :,192
3403,"def optimize(self, graph: Graph): <TAB> MAX_TEXTURE_SIZE = config.WEBGL_MAX_TEXTURE_SIZE <TAB> flag_changed = False <TAB> for v in traverse.listup_variables(graph): <TAB>  <TAB> if not Placeholder.check_resolved(v.size): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> height, width = TextureShape.get(v) <MASK> continue <TAB>  <TAB> if not v.has_attribute(SplitTarget): <TAB>  <TAB>  <TAB> flag_changed = True <TAB>  <TAB>  <TAB> v.attributes.add(SplitTarget()) <TAB> return graph, flag_changed",if height <= MAX_TEXTURE_SIZE and width <= MAX_TEXTURE_SIZE :,157
3404,"def brightness_func(args): <TAB> device = _get_device_from_filter(args) <TAB> if args.set is None: <TAB>  <TAB> # Get brightness <TAB>  <TAB> if args.raw: <TAB>  <TAB>  <TAB> print(str(device.brightness)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""Brightness: {0}%"".format(device.brightness)) <TAB> else: <TAB>  <TAB> brightness_value = float(_clamp_u8(args.set)) <MASK> print(""Setting brightness to {0}%"".format(brightness_value)) <TAB>  <TAB> device.brightness = brightness_value",if not args . raw :,139
3405,"def _setup(self, field_name, owner_model): <TAB> # Resolve possible name-based model reference. <TAB> if not self.model_class: <MASK> self.model_class = owner_model <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> ""ModelType: Unable to resolve model '{}'."".format(self.model_name) <TAB>  <TAB>  <TAB> ) <TAB> super(ModelType, self)._setup(field_name, owner_model)",if self . model_name == owner_model . __name__ :,124
3406,"def build_json_schema_object(cls, parent_builder=None): <TAB> builder = builders.ObjectBuilder(cls, parent_builder) <TAB> if builder.count_type(builder.type) > 1: <TAB>  <TAB> return builder <TAB> for _, name, field in cls.iterate_with_name(): <TAB>  <TAB> if isinstance(field, fields.EmbeddedField): <TAB>  <TAB>  <TAB> builder.add_field(name, field, _parse_embedded(field, builder)) <MASK> builder.add_field(name, field, _parse_list(field, builder)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> builder.add_field(name, field, _create_primitive_field_schema(field)) <TAB> return builder","elif isinstance ( field , fields . ListField ) :",178
3407,"def filter_module(mod, type_req=None, subclass_req=None): <TAB> for name in dir(mod): <TAB>  <TAB> val = getattr(mod, name) <TAB>  <TAB> if type_req is not None and not isinstance(val, type_req): <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> yield name, val","if subclass_req is not None and not issubclass ( val , subclass_req ) :",97
3408,"def get_icon(self): <TAB> if self.icon is not None: <TAB>  <TAB> # Load it from an absolute filename <TAB>  <TAB> if os.path.exists(self.icon): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> return GdkPixbuf.Pixbuf.new_from_file_at_size(self.icon, 24, 24) <TAB>  <TAB>  <TAB> except GObject.GError as ge: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> # Load it from the current icon theme <TAB>  <TAB> (icon_name, extension) = os.path.splitext(os.path.basename(self.icon)) <TAB>  <TAB> theme = Gtk.IconTheme() <MASK> return theme.load_icon(icon_name, 24, 0)",if theme . has_icon ( icon_name ) :,174
3409,"def sysctlTestAndSet(name, limit): <TAB> ""Helper function to set sysctl limits"" <TAB> # convert non-directory names into directory names <TAB> if ""/"" not in name: <TAB>  <TAB> name = ""/proc/sys/"" + name.replace(""."", ""/"") <TAB> # read limit <TAB> with open(name, ""r"") as readFile: <TAB>  <TAB> oldLimit = readFile.readline() <TAB>  <TAB> if isinstance(limit, int): <TAB>  <TAB>  <TAB> # compare integer limits before overriding <MASK> with open(name, ""w"") as writeFile: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> writeFile.write(""%d"" % limit) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # overwrite non-integer limits <TAB>  <TAB>  <TAB> with open(name, ""w"") as writeFile: <TAB>  <TAB>  <TAB>  <TAB> writeFile.write(limit)",if int ( oldLimit ) < limit :,197
3410,"def _wait_for_bot_presense(self, online): <TAB> for _ in range(10): <TAB>  <TAB> time.sleep(2) <TAB>  <TAB> if online and self._is_testbot_online(): <TAB>  <TAB>  <TAB> break <MASK> break <TAB> else: <TAB>  <TAB> raise AssertionError( <TAB>  <TAB>  <TAB> ""test bot is still {}"".format(""offline"" if online else ""online"") <TAB>  <TAB> )",if not online and not self . _is_testbot_online ( ) :,111
3411,"def handle(self, context, sign, *args): <TAB> if context.rounding in (ROUND_HALF_UP, ROUND_HALF_EVEN, ROUND_HALF_DOWN, ROUND_UP): <TAB>  <TAB> return Infsign[sign] <TAB> if sign == 0: <TAB>  <TAB> if context.rounding == ROUND_CEILING: <TAB>  <TAB>  <TAB> return Infsign[sign] <TAB>  <TAB> return Decimal((sign, (9,) * context.prec, context.Emax - context.prec + 1)) <TAB> if sign == 1: <MASK> return Infsign[sign] <TAB>  <TAB> return Decimal((sign, (9,) * context.prec, context.Emax - context.prec + 1))",if context . rounding == ROUND_FLOOR :,184
3412,"def _get_item_columns_panel(items, rows): <TAB> hbox = Gtk.HBox(False, 4) <TAB> n_item = 0 <TAB> col_items = 0 <TAB> vbox = Gtk.VBox() <TAB> hbox.pack_start(vbox, False, False, 0) <TAB> while n_item < len(items): <TAB>  <TAB> item = items[n_item] <TAB>  <TAB> vbox.pack_start(item, False, False, 0) <TAB>  <TAB> n_item += 1 <TAB>  <TAB> col_items += 1 <MASK> vbox = Gtk.VBox() <TAB>  <TAB>  <TAB> hbox.pack_start(vbox, False, False, 0) <TAB>  <TAB>  <TAB> col_items = 0 <TAB> return hbox",if col_items > rows :,179
3413,"def _changed(self): <TAB> if self.gtk_range.get_sensitive(): <MASK> self.timer.cancel() <TAB>  <TAB> self.timer = _Timer(0.5, lambda: GLib.idle_add(self._write)) <TAB>  <TAB> self.timer.start()",if self . timer :,74
3414,"def unlock_graph(result, callback, interval=1, propagate=False, max_retries=None): <TAB> if result.ready(): <TAB>  <TAB> second_level_res = result.get() <MASK> with allow_join_result(): <TAB>  <TAB>  <TAB>  <TAB> signature(callback).delay( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> list(joinall(second_level_res, propagate=propagate)) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> unlock_graph.retry(countdown=interval, max_retries=max_retries)",if second_level_res . ready ( ) :,131
3415,"def update(self, other=None, /, **kwargs): <TAB> if self._pending_removals: <TAB>  <TAB> self._commit_removals() <TAB> d = self.data <TAB> if other is not None: <MASK> other = dict(other) <TAB>  <TAB> for key, o in other.items(): <TAB>  <TAB>  <TAB> d[key] = KeyedRef(o, self._remove, key) <TAB> for key, o in kwargs.items(): <TAB>  <TAB> d[key] = KeyedRef(o, self._remove, key)","if not hasattr ( other , ""items"" ) :",135
3416,"def default(self, o): <TAB> try: <TAB>  <TAB> if type(o) == datetime.datetime: <TAB>  <TAB>  <TAB> return str(o) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # remove unwanted attributes from the provider object during conversion to json <TAB>  <TAB>  <TAB> if hasattr(o, ""profile""): <TAB>  <TAB>  <TAB>  <TAB> del o.profile <TAB>  <TAB>  <TAB> if hasattr(o, ""credentials""): <TAB>  <TAB>  <TAB>  <TAB> del o.credentials <TAB>  <TAB>  <TAB> if hasattr(o, ""metadata_path""): <TAB>  <TAB>  <TAB>  <TAB> del o.metadata_path <MASK> del o.services_config <TAB>  <TAB>  <TAB> return vars(o) <TAB> except Exception as e: <TAB>  <TAB> return str(o)","if hasattr ( o , ""services_config"" ) :",172
3417,"def read(self, count=True, timeout=None, ignore_non_errors=True, ignore_timeouts=True): <TAB> try: <TAB>  <TAB> return self._read(count, timeout) <TAB> except usb.USBError as e: <MASK> log.info( <TAB>  <TAB>  <TAB>  <TAB> ""read: e.errno=%s e.strerror=%s e.message=%s repr=%s"" <TAB>  <TAB>  <TAB>  <TAB> % (e.errno, e.strerror, e.message, repr(e)) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if ignore_timeouts and is_timeout(e): <TAB>  <TAB>  <TAB> return [] <TAB>  <TAB> if ignore_non_errors and is_noerr(e): <TAB>  <TAB>  <TAB> return [] <TAB>  <TAB> raise",if DEBUG_COMM :,174
3418,def heal(self): <TAB> if not self.doctors: <TAB>  <TAB> return <TAB> proc_ids = self._get_process_ids() <TAB> for proc_id in proc_ids: <TAB>  <TAB> # get proc every time for latest state <TAB>  <TAB> proc = PipelineProcess.objects.get(id=proc_id) <MASK> continue <TAB>  <TAB> for dr in self.doctors: <TAB>  <TAB>  <TAB> if dr.confirm(proc): <TAB>  <TAB>  <TAB>  <TAB> dr.cure(proc) <TAB>  <TAB>  <TAB>  <TAB> break,if not proc . is_alive or proc . is_frozen :,138
3419,"def to_value(self, value): <TAB> # Tip: 'value' is the object returned by <TAB> # <TAB>   taiga.projects.history.models.HistoryEntry.values_diff() <TAB> ret = {} <TAB> for key, val in value.items(): <MASK> ret[key] = val <TAB>  <TAB> elif key == ""points"": <TAB>  <TAB>  <TAB> ret[key] = {k: {""from"": v[0], ""to"": v[1]} for k, v in val.items()} <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret[key] = {""from"": val[0], ""to"": val[1]} <TAB> return ret","if key in [ ""attachments"" , ""custom_attributes"" , ""description_diff"" ] :",169
3420,"def default_generator( <TAB> self, dataset, epochs=1, mode=""fit"", deterministic=True, pad_batches=True): <TAB> for epoch in range(epochs): <TAB>  <TAB> for (X_b, y_b, w_b, ids_b) in dataset.iterbatches( <TAB>  <TAB>  <TAB> batch_size=self.batch_size, <TAB>  <TAB>  <TAB> deterministic=deterministic, <TAB>  <TAB>  <TAB> pad_batches=pad_batches, <TAB>  <TAB> ): <MASK> dropout = np.array(0.0) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> dropout = np.array(1.0) <TAB>  <TAB>  <TAB> yield ([X_b, dropout], [y_b], [w_b])","if mode == ""predict"" :",172
3421,"def _cygwin_hack_find_addresses(target): <TAB> addresses = [] <TAB> for h in [ <TAB>  <TAB> target, <TAB>  <TAB> ""localhost"", <TAB>  <TAB> ""127.0.0.1"", <TAB> ]: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> addr = get_local_ip_for(h) <MASK> addresses.append(addr) <TAB>  <TAB> except socket.gaierror: <TAB>  <TAB>  <TAB> pass <TAB> return defer.succeed(addresses)",if addr not in addresses :,116
3422,"def _get_notify(self, action_node): <TAB> if action_node.name not in self._skip_notify_tasks: <TAB>  <TAB> if action_node.notify: <TAB>  <TAB>  <TAB> task_notify = NotificationsHelper.to_model(action_node.notify) <TAB>  <TAB>  <TAB> return task_notify <MASK> return self._chain_notify <TAB> return None",elif self . _chain_notify :,95
3423,"def filterTokenLocation(): <TAB> i = None <TAB> entry = None <TAB> token = None <TAB> tokens = [] <TAB> i = 0 <TAB> while 1: <MASK> break <TAB>  <TAB> entry = extra.tokens[i] <TAB>  <TAB> token = jsdict( <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB> ""type"": entry.type, <TAB>  <TAB>  <TAB>  <TAB> ""value"": entry.value, <TAB>  <TAB>  <TAB> } <TAB>  <TAB> ) <TAB>  <TAB> if extra.range: <TAB>  <TAB>  <TAB> token.range = entry.range <TAB>  <TAB> if extra.loc: <TAB>  <TAB>  <TAB> token.loc = entry.loc <TAB>  <TAB> tokens.append(token) <TAB>  <TAB> i += 1 <TAB> extra.tokens = tokens",if not ( i < len ( extra . tokens ) ) :,172
3424,"def read(self, size=-1): <TAB> buf = bytearray() <TAB> while size != 0 and self.cursor < self.maxpos: <TAB>  <TAB> if not self.in_current_block(self.cursor): <TAB>  <TAB>  <TAB> self.seek_to_block(self.cursor) <TAB>  <TAB> part = self.current_stream.read(size) <MASK> if len(part) == 0: <TAB>  <TAB>  <TAB>  <TAB> raise EOFError() <TAB>  <TAB>  <TAB> size -= len(part) <TAB>  <TAB> self.cursor += len(part) <TAB>  <TAB> buf += part <TAB> return bytes(buf)",if size > 0 :,142
3425,"def get_properties_from_model(model_class): <TAB> """"""Show properties from a model"""""" <TAB> properties = [] <TAB> attr_names = [name for (name, value) in inspect.getmembers(model_class, isprop)] <TAB> for attr_name in attr_names: <MASK> attr_names.remove(attr_name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> properties.append( <TAB>  <TAB>  <TAB>  <TAB> dict(label=attr_name, name=attr_name.strip(""_"").replace(""_"", "" "")) <TAB>  <TAB>  <TAB> ) <TAB> return sorted(properties, key=lambda k: k[""label""])","if attr_name . endswith ( ""pk"" ) :",151
3426,"def __getitem__(self, name, set=set, getattr=getattr, id=id): <TAB> visited = set() <TAB> mydict = self.basedict <TAB> while 1: <TAB>  <TAB> value = mydict[name] <TAB>  <TAB> if value is not None: <TAB>  <TAB>  <TAB> return value <TAB>  <TAB> myid = id(mydict) <TAB>  <TAB> assert myid not in visited <TAB>  <TAB> visited.add(myid) <TAB>  <TAB> mydict = mydict.Parent <MASK> return",if mydict is None :,120
3427,"def multicolumn(self, list, format, cols=4): <TAB> """"""Format a list of items into a multi-column list."""""" <TAB> result = """" <TAB> rows = (len(list) + cols - 1) // cols <TAB> for col in range(cols): <TAB>  <TAB> result = result + '<td width=""%d%%"" valign=top>' % (100 // cols) <TAB>  <TAB> for i in range(rows * col, rows * col + rows): <MASK> result = result + format(list[i]) + ""<br>\n"" <TAB>  <TAB> result = result + ""</td>"" <TAB> return '<table width=""100%%"" summary=""list""><tr>%s</tr></table>' % result",if i < len ( list ) :,167
3428,"def format_exc(exc=None): <TAB> """"""Return exc (or sys.exc_info if None), formatted."""""" <TAB> try: <MASK> exc = _exc_info() <TAB>  <TAB> if exc == (None, None, None): <TAB>  <TAB>  <TAB> return """" <TAB>  <TAB> import traceback <TAB>  <TAB> return """".join(traceback.format_exception(*exc)) <TAB> finally: <TAB>  <TAB> del exc",if exc is None :,98
3429,"def assert_counts(res, lang, files, blank, comment, code): <TAB> for line in res: <TAB>  <TAB> fields = line.split() <TAB>  <TAB> if len(fields) >= 5: <MASK> self.assertEqual(files, int(fields[1])) <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(blank, int(fields[2])) <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(comment, int(fields[3])) <TAB>  <TAB>  <TAB>  <TAB> self.assertEqual(code, int(fields[4])) <TAB>  <TAB>  <TAB>  <TAB> return <TAB> self.fail(""Found no output line for {}"".format(lang))",if fields [ 0 ] == lang :,147
3430,"def __iter__(self): <TAB> for name, value in self.__class__.__dict__.items(): <MASK> continue <TAB>  <TAB> if isinstance(value, flag_value): <TAB>  <TAB>  <TAB> yield (name, self._has_flag(value.flag))","if isinstance ( value , alias_flag_value ) :",71
3431,"def optimize_models(args, use_cuda, models): <TAB> """"""Optimize ensemble for generation"""""" <TAB> for model in models: <TAB>  <TAB> model.make_generation_fast_( <TAB>  <TAB>  <TAB> beamable_mm_beam_size=None if args.no_beamable_mm else args.beam, <TAB>  <TAB>  <TAB> need_attn=args.print_alignment, <TAB>  <TAB> ) <TAB>  <TAB> if args.fp16: <TAB>  <TAB>  <TAB> model.half() <MASK> model.cuda()",if use_cuda :,122
3432,"def convertstore(self, mydict): <TAB> targetheader = self.mypofile.header() <TAB> targetheader.addnote(""extracted from web2py"", ""developer"") <TAB> for source_str in mydict.keys(): <TAB>  <TAB> target_str = mydict[source_str] <TAB>  <TAB> if target_str == source_str: <TAB>  <TAB>  <TAB> # a convention with new (untranslated) web2py files <TAB>  <TAB>  <TAB> target_str = u"""" <MASK> # an older convention <TAB>  <TAB>  <TAB> target_str = u"""" <TAB>  <TAB> pounit = self.convertunit(source_str, target_str) <TAB>  <TAB> self.mypofile.addunit(pounit) <TAB> return self.mypofile","elif target_str . startswith ( u""*** "" ) :",180
3433,"def __sparse_values_set(instances, static_col_indexes: list): <TAB> tmp_result = {idx: set() for idx in static_col_indexes} <TAB> for _, instance in instances: <TAB>  <TAB> data_generator = instance.features.get_all_data() <TAB>  <TAB> for idx, value in data_generator: <MASK> continue <TAB>  <TAB>  <TAB> tmp_result[idx].add(value) <TAB> result = [tmp_result[x] for x in static_col_indexes] <TAB> return result",if idx not in tmp_result :,132
3434,def puts(self): <MASK> self.lazy_init_lock_.acquire() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if self.puts_ is None: <TAB>  <TAB>  <TAB>  <TAB> self.puts_ = PutRequest() <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self.lazy_init_lock_.release() <TAB> return self.puts_,if self . puts_ is None :,89
3435,"def run(self, args, **kwargs): <TAB> if args.resource_ref or args.policy_type: <TAB>  <TAB> filters = {} <TAB>  <TAB> if args.resource_ref: <TAB>  <TAB>  <TAB> filters[""resource_ref""] = args.resource_ref <MASK> filters[""policy_type""] = args.policy_type <TAB>  <TAB> filters.update(**kwargs) <TAB>  <TAB> return self.manager.query(**filters) <TAB> else: <TAB>  <TAB> return self.manager.get_all(**kwargs)",if args . policy_type :,123
3436,"def Get_Gene(self, id): <TAB> """"""Retreive the gene name (GN)."""""" <TAB> entry = self.Get(id) <TAB> if not entry: <TAB>  <TAB> return None <TAB> GN = """" <TAB> for line in string.split(entry, ""\n""): <TAB>  <TAB> if line[0:5] == ""GN   "": <TAB>  <TAB>  <TAB> GN = string.strip(line[5:]) <MASK> GN = GN[0:-1] <TAB>  <TAB>  <TAB> return GN <TAB>  <TAB> if line[0:2] == ""//"": <TAB>  <TAB>  <TAB> break <TAB> return GN","if GN [ - 1 ] == ""."" :",150
3437,"def processMovie(self, atom): <TAB> for field in atom: <MASK> self.processTrack(field[""track""]) <TAB>  <TAB> if ""movie_hdr"" in field: <TAB>  <TAB>  <TAB> self.processMovieHeader(field[""movie_hdr""])","if ""track"" in field :",69
3438,"def get_next_video_frame(self, skip_empty_frame=True): <TAB> if not self.video_format: <TAB>  <TAB> return <TAB> while True: <TAB>  <TAB> # We skip video packets which are not video frames <TAB>  <TAB> # This happens in mkv files for the first few frames. <TAB>  <TAB> video_packet = self._get_video_packet() <MASK> self._decode_video_packet(video_packet) <TAB>  <TAB> if video_packet.image is not None or not skip_empty_frame: <TAB>  <TAB>  <TAB> break <TAB> if _debug: <TAB>  <TAB> print(""Returning"", video_packet) <TAB> return video_packet.image",if video_packet . image == 0 :,162
3439,"def get_devices(display=None): <TAB> base = ""/dev/input"" <TAB> for filename in os.listdir(base): <TAB>  <TAB> if filename.startswith(""event""): <TAB>  <TAB>  <TAB> path = os.path.join(base, filename) <MASK> continue <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> _devices[path] = EvdevDevice(display, path) <TAB>  <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB> return list(_devices.values())",if path in _devices :,120
3440,"def _ensure_header_written(self, datasize): <TAB> if not self._headerwritten: <TAB>  <TAB> if not self._nchannels: <TAB>  <TAB>  <TAB> raise Error(""# channels not specified"") <MASK> raise Error(""sample width not specified"") <TAB>  <TAB> if not self._framerate: <TAB>  <TAB>  <TAB> raise Error(""sampling rate not specified"") <TAB>  <TAB> self._write_header(datasize)",if not self . _sampwidth :,99
3441,"def process(self, fuzzresult): <TAB> base_url = urljoin(fuzzresult.url, "".."") <TAB> for line in fuzzresult.history.content.splitlines(): <TAB>  <TAB> record = line.split(""/"") <TAB>  <TAB> if len(record) == 6 and record[1]: <TAB>  <TAB>  <TAB> self.queue_url(urljoin(base_url, record[1])) <TAB>  <TAB>  <TAB> # Directory <MASK> self.queue_url(urljoin(base_url, record[1])) <TAB>  <TAB>  <TAB>  <TAB> self.queue_url(urljoin(base_url, ""%s/CVS/Entries"" % (record[1])))","if record [ 0 ] == ""D"" :",153
3442,"def tearDown(self): <TAB> """"""Shutdown the UDP server."""""" <TAB> try: <MASK> self.server.stop(2.0) <TAB>  <TAB> if self.sock_hdlr: <TAB>  <TAB>  <TAB> self.root_logger.removeHandler(self.sock_hdlr) <TAB>  <TAB>  <TAB> self.sock_hdlr.close() <TAB> finally: <TAB>  <TAB> BaseTest.tearDown(self)",if self . server :,97
3443,"def get_backend(find_library=None): <TAB> try: <TAB>  <TAB> global _lib, _ctx <MASK> _lib = _load_library(find_library) <TAB>  <TAB>  <TAB> _setup_prototypes(_lib) <TAB>  <TAB>  <TAB> _ctx = _Context() <TAB>  <TAB> _logger.warning( <TAB>  <TAB>  <TAB> ""OpenUSB backend deprecated (https://github.com/pyusb/pyusb/issues/284)"" <TAB>  <TAB> ) <TAB>  <TAB> return _OpenUSB() <TAB> except usb.libloader.LibraryException: <TAB>  <TAB> # exception already logged (if any) <TAB>  <TAB> _logger.error(""Error loading OpenUSB backend"", exc_info=False) <TAB>  <TAB> return None <TAB> except Exception: <TAB>  <TAB> _logger.error(""Error loading OpenUSB backend"", exc_info=True) <TAB>  <TAB> return None",if _lib is None :,199
3444,"def __init__(self, event, event_info, fields=[]): <TAB> _wmi_object.__init__(self, event, fields=fields) <TAB> _set(self, ""event_type"", None) <TAB> _set(self, ""timestamp"", None) <TAB> _set(self, ""previous"", None) <TAB> if event_info: <TAB>  <TAB> event_type = self.event_type_re.match(event_info.Path_.Class).group(1).lower() <TAB>  <TAB> _set(self, ""event_type"", event_type) <TAB>  <TAB> if hasattr(event_info, ""TIME_CREATED""): <TAB>  <TAB>  <TAB> _set(self, ""timestamp"", from_1601(event_info.TIME_CREATED)) <MASK> _set(self, ""previous"", event_info.PreviousInstance)","if hasattr ( event_info , ""PreviousInstance"" ) :",199
3445,"def _getListNextPackagesReadyToBuild(): <TAB> for pkg in Scheduler.listOfPackagesToBuild: <MASK> continue <TAB>  <TAB> if constants.rpmCheck or Scheduler._checkNextPackageIsReadyToBuild(pkg): <TAB>  <TAB>  <TAB> Scheduler.listOfPackagesNextToBuild.put((-Scheduler._getPriority(pkg), pkg)) <TAB>  <TAB>  <TAB> Scheduler.logger.debug(""Adding "" + pkg + "" to the schedule list"")",if pkg in Scheduler . listOfPackagesCurrentlyBuilding :,113
3446,"def process_all(self, lines, times=1): <TAB> gap = False <TAB> for _ in range(times): <TAB>  <TAB> for line in lines: <MASK> self.write("""") <TAB>  <TAB>  <TAB> self.process(line) <TAB>  <TAB>  <TAB> if not is_command(line): <TAB>  <TAB>  <TAB>  <TAB> gap = True <TAB> return 0",if gap :,86
3447,"def diff(old, new, display=True): <TAB> """"""Nice colored diff implementation"""""" <TAB> if not isinstance(old, list): <TAB>  <TAB> old = decolorize(str(old)).splitlines() <TAB> if not isinstance(new, list): <TAB>  <TAB> new = decolorize(str(new)).splitlines() <TAB> line_types = {"" "": ""%Reset"", ""-"": ""%Red"", ""+"": ""%Green"", ""?"": ""%Pink""} <TAB> if display: <TAB>  <TAB> for line in difflib.Differ().compare(old, new): <MASK> continue <TAB>  <TAB>  <TAB> print(colorize(line_types[line[0]], line)) <TAB> return old != new","if line . startswith ( ""?"" ) :",155
3448,"def get_limit(self, request): <TAB> if self.limit_query_param: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> limit = int(request.query_params[self.limit_query_param]) <TAB>  <TAB>  <TAB> if limit < 0: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError() <TAB>  <TAB>  <TAB> # Enforce maximum page size, if defined <TAB>  <TAB>  <TAB> if settings.MAX_PAGE_SIZE: <MASK> return settings.MAX_PAGE_SIZE <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return min(limit, settings.MAX_PAGE_SIZE) <TAB>  <TAB>  <TAB> return limit <TAB>  <TAB> except (KeyError, ValueError): <TAB>  <TAB>  <TAB> pass <TAB> return self.default_limit",if limit == 0 :,169
3449,"def slice_fill(self, slice_): <TAB> ""Fills the slice with zeroes for the dimensions that have single elements and squeeze_dims true"" <TAB> if isinstance(self.indexes, int): <TAB>  <TAB> new_slice_ = [0] <TAB>  <TAB> offset = 0 <TAB> else: <TAB>  <TAB> new_slice_ = [slice_[0]] <TAB>  <TAB> offset = 1 <TAB> for i in range(1, len(self.nums)): <TAB>  <TAB> if self.squeeze_dims[i]: <TAB>  <TAB>  <TAB> new_slice_.append(0) <MASK> new_slice_.append(slice_[offset]) <TAB>  <TAB>  <TAB> offset += 1 <TAB> new_slice_ += slice_[offset:] <TAB> return new_slice_",elif offset < len ( slice_ ) :,171
3450,"def wrapper(*args, **kw): <TAB> instance = args[0] <TAB> try: <MASK> ret_dict = instance._create_ret_object( <TAB>  <TAB>  <TAB>  <TAB> instance.FAILURE, None, True, instance.MUST_JSON <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> instance.logger.error(instance.MUST_JSON) <TAB>  <TAB>  <TAB> return jsonify(ret_dict), 400 <TAB> except BadRequest: <TAB>  <TAB> ret_dict = instance._create_ret_object( <TAB>  <TAB>  <TAB> instance.FAILURE, None, True, instance.MUST_JSON <TAB>  <TAB> ) <TAB>  <TAB> instance.logger.error(instance.MUST_JSON) <TAB>  <TAB> return jsonify(ret_dict), 400 <TAB> instance.logger.debug(""JSON is valid"") <TAB> return f(*args, **kw)",if request . get_json ( ) is None :,191
3451,"def add_css(self, data): <TAB> if data: <TAB>  <TAB> for medium, paths in data.items(): <TAB>  <TAB>  <TAB> for path in paths: <MASK> self._css.setdefault(medium, []).append(path)",if not self . _css . get ( medium ) or path not in self . _css [ medium ] :,80
3452,"def mangle_template(template: str, template_vars: Set[str]) -> str: <TAB> if TEMPLATE_PREFIX in template or TEMPLATE_SUFFIX in template: <TAB>  <TAB> raise Exception(""Cannot parse a template containing reserved strings"") <TAB> for var in template_vars: <TAB>  <TAB> original = f""{{{var}}}"" <MASK> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> f'Template string is missing a reference to ""{var}"" referred to in kwargs' <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> template = template.replace(original, mangled_name(var)) <TAB> return template",if original not in template :,135
3453,"def filterSimilarKeywords(keyword, kwdsIterator): <TAB> """"""Return a sorted list of keywords similar to the one given."""""" <TAB> seenDict = {} <TAB> kwdSndx = soundex(keyword.encode(""ascii"", ""ignore"")) <TAB> matches = [] <TAB> matchesappend = matches.append <TAB> checkContained = False <TAB> if len(keyword) > 4: <TAB>  <TAB> checkContained = True <TAB> for movieID, key in kwdsIterator: <TAB>  <TAB> if key in seenDict: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> seenDict[key] = None <TAB>  <TAB> if checkContained and keyword in key: <TAB>  <TAB>  <TAB> matchesappend(key) <TAB>  <TAB>  <TAB> continue <MASK> matchesappend(key) <TAB> return _sortKeywords(keyword, matches)","if kwdSndx == soundex ( key . encode ( ""ascii"" , ""ignore"" ) ) :",193
3454,"def GetInfo(self): <TAB> for k, v in sorted(self.memory_parameters.items()): <MASK> continue <TAB>  <TAB> if not v: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> print(""%s: \t%#08x (%s)"" % (k, v, v)) <TAB> print(""Memory ranges:"") <TAB> print(""Start\t\tEnd\t\tLength"") <TAB> for start, length in self.runs: <TAB>  <TAB> print(""0x%X\t\t0x%X\t\t0x%X"" % (start, start + length, length))","if k . startswith ( ""Pad"" ) :",145
3455,"def Children(self): <TAB> """"""Returns a list of all of this object's owned (strong) children."""""" <TAB> children = [] <TAB> for property, attributes in self._schema.iteritems(): <TAB>  <TAB> (is_list, property_type, is_strong) = attributes[0:3] <TAB>  <TAB> if is_strong and property in self._properties: <MASK> children.append(self._properties[property]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> children.extend(self._properties[property]) <TAB> return children",if not is_list :,130
3456,"def normalize_res_identifier(self, emu, cw, val): <TAB> mask = (16 ** (emu.get_ptr_size() // 2) - 1) << 16 <TAB> if val & mask:  # not an INTRESOURCE <TAB>  <TAB> name = emu.read_mem_string(val, cw) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> name = int(name[1:]) <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> return 0 <TAB> else: <TAB>  <TAB> name = val <TAB> return name","if name [ 0 ] == ""#"" :",132
3457,"def _optimize(self, solutions): <TAB> best_a = None <TAB> best_silhouette = None <TAB> best_k = None <TAB> for a, silhouette, k in solutions(): <TAB>  <TAB> if best_silhouette is None: <TAB>  <TAB>  <TAB> pass <MASK> break <TAB>  <TAB> best_silhouette = silhouette <TAB>  <TAB> best_a = a <TAB>  <TAB> best_k = k <TAB> return best_a, best_silhouette, best_k",elif silhouette <= best_silhouette :,109
3458,"def find_commit_type(sha): <TAB> try: <TAB>  <TAB> o = obj_store[sha] <TAB> except KeyError: <MASK> raise <TAB> else: <TAB>  <TAB> if isinstance(o, Commit): <TAB>  <TAB>  <TAB> commits.add(sha) <TAB>  <TAB> elif isinstance(o, Tag): <TAB>  <TAB>  <TAB> tags.add(sha) <TAB>  <TAB>  <TAB> commits.add(o.object[1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise KeyError(""Not a commit or a tag: %s"" % sha)",if not ignore_unknown :,127
3459,"def on_search_entry_keypress(self, widget, event): <TAB> key = Gdk.keyval_name(event.keyval) <TAB> if key == ""Escape"": <TAB>  <TAB> self.hide_search_box() <TAB> elif key == ""Return"": <TAB>  <TAB> # Combine with Shift? <MASK> self.search_prev = False <TAB>  <TAB>  <TAB> self.do_search(None) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.search_prev = True",if event . state & Gdk . ModifierType . SHIFT_MASK :,121
3460,"def process_webhook_prop(namespace): <TAB> if not isinstance(namespace.webhook_properties, list): <TAB>  <TAB> return <TAB> result = {} <TAB> for each in namespace.webhook_properties: <MASK> if ""="" in each: <TAB>  <TAB>  <TAB>  <TAB> key, value = each.split(""="", 1) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> key, value = each, """" <TAB>  <TAB>  <TAB> result[key] = value <TAB> namespace.webhook_properties = result",if each :,111
3461,"def run(self): <TAB> global WAITING_BEFORE_START <TAB> time.sleep(WAITING_BEFORE_START) <TAB> while self.keep_alive: <TAB>  <TAB> path_id, module, resolve = self.queue_receive.get() <MASK> continue <TAB>  <TAB> self.lock.acquire() <TAB>  <TAB> self.modules[path_id] = module <TAB>  <TAB> self.lock.release() <TAB>  <TAB> if resolve: <TAB>  <TAB>  <TAB> resolution = self._resolve_with_other_modules(resolve) <TAB>  <TAB>  <TAB> self._relations[path_id] = [] <TAB>  <TAB>  <TAB> for package in resolution: <TAB>  <TAB>  <TAB>  <TAB> self._relations[path_id].append(resolution[package]) <TAB>  <TAB>  <TAB> self.queue_send.put((path_id, module, False, resolution))",if path_id is None :,190
3462,"def _get_download_link(self, url, download_type=""torrent""): <TAB> links = { <TAB>  <TAB> ""torrent"": """", <TAB>  <TAB> ""magnet"": """", <TAB> } <TAB> try: <TAB>  <TAB> data = self.session.get(url).text <TAB>  <TAB> with bs4_parser(data) as html: <TAB>  <TAB>  <TAB> downloads = html.find(""div"", {""class"": ""download""}) <TAB>  <TAB>  <TAB> if downloads: <TAB>  <TAB>  <TAB>  <TAB> for download in downloads.findAll(""a""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> link = download[""href""] <MASK> links[""magnet""] = link <TAB>  <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> links[""torrent""] = urljoin(self.urls[""base_url""], link) <TAB> except Exception: <TAB>  <TAB> pass <TAB> return links[download_type]","if link . startswith ( ""magnet"" ) :",200
3463,"def _parse_fields(cls, read): <TAB> read = unicode_to_str(read) <TAB> if type(read) is not str: <TAB>  <TAB> _wrong_type_for_arg(read, ""str"", ""read"") <TAB> fields = {} <TAB> while read and read[0] != "";"": <MASK> DeserializeError(read, ""does not separate fields with commas"") <TAB>  <TAB> read = read[1:] <TAB>  <TAB> key, _type, value, read = cls._parse_field(read) <TAB>  <TAB> fields[key] = (_type, value) <TAB> if read: <TAB>  <TAB> # read[0] == ';' <TAB>  <TAB> read = read[1:] <TAB> return fields, read","if read and read [ 0 ] != "","" :",173
3464,"def _convertDict(self, d): <TAB> r = {} <TAB> for k, v in d.items(): <MASK> v = str(v, ""utf-8"") <TAB>  <TAB> elif isinstance(v, list) or isinstance(v, tuple): <TAB>  <TAB>  <TAB> v = self._convertList(v) <TAB>  <TAB> elif isinstance(v, dict): <TAB>  <TAB>  <TAB> v = self._convertDict(v) <TAB>  <TAB> if isinstance(k, bytes): <TAB>  <TAB>  <TAB> k = str(k, ""utf-8"") <TAB>  <TAB> r[k] = v <TAB> return r","if isinstance ( v , bytes ) :",142
3465,"def wrapper(filename): <TAB> mtime = getmtime(filename) <TAB> with lock: <TAB>  <TAB> if filename in cache: <TAB>  <TAB>  <TAB> old_mtime, result = cache.pop(filename) <MASK> # Move to the end <TAB>  <TAB>  <TAB>  <TAB> cache[filename] = old_mtime, result <TAB>  <TAB>  <TAB>  <TAB> return result <TAB> result = function(filename) <TAB> with lock: <TAB>  <TAB> cache[filename] = mtime, result  # at the end <TAB>  <TAB> if len(cache) > max_size: <TAB>  <TAB>  <TAB> cache.popitem(last=False) <TAB> return result",if old_mtime == mtime :,144
3466,def isFinished(self): <TAB> # returns true if episode timesteps has reached episode length and resets the task <TAB> if self.count > self.epiLen: <TAB>  <TAB> self.res() <TAB>  <TAB> return True <TAB> else: <MASK> self.pertGlasPos(0) <TAB>  <TAB> if self.count == self.epiLen / 2 + 1: <TAB>  <TAB>  <TAB> self.env.reset() <TAB>  <TAB>  <TAB> self.pertGlasPos(1) <TAB>  <TAB> self.count += 1 <TAB>  <TAB> return False,if self . count == 1 :,132
3467,"def _check_vulnerabilities(self, processed_analysis): <TAB> matched_vulnerabilities = list() <TAB> for vulnerability in self._rule_base_vulnerabilities: <MASK> vulnerability_data = vulnerability.get_dict() <TAB>  <TAB>  <TAB> name = vulnerability_data.pop(""short_name"") <TAB>  <TAB>  <TAB> matched_vulnerabilities.append((name, vulnerability_data)) <TAB> return matched_vulnerabilities","if evaluate ( processed_analysis , vulnerability . rule ) :",100
3468,"def _table_reprfunc(self, row, col, val): <TAB> if self._table.column_names[col].endswith(""Size""): <MASK> return ""  %s"" % val <TAB>  <TAB> elif val < 1024 ** 2: <TAB>  <TAB>  <TAB> return ""  %.1f KB"" % (val / 1024.0 ** 1) <TAB>  <TAB> elif val < 1024 ** 3: <TAB>  <TAB>  <TAB> return ""  %.1f MB"" % (val / 1024.0 ** 2) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""  %.1f GB"" % (val / 1024.0 ** 3) <TAB> if col in (0, """"): <TAB>  <TAB> return str(val) <TAB> else: <TAB>  <TAB> return ""  %s"" % val","if isinstance ( val , compat . string_types ) :",182
3469,"def serve_until_stopped(self) -> None: <TAB> while True: <TAB>  <TAB> rd, wr, ex = select.select([self.socket.fileno()], [], [], self.timeout) <TAB>  <TAB> if rd: <TAB>  <TAB>  <TAB> self.handle_request() <MASK> break",if self . event is not None and self . event . is_set ( ) :,83
3470,"def resize(self, *e): <TAB> bold = (""helvetica"", -self._size.get(), ""bold"") <TAB> helv = (""helvetica"", -self._size.get()) <TAB> xspace = self._size.get() <TAB> yspace = self._size.get() <TAB> for widget in self._widgets: <TAB>  <TAB> widget[""node_font""] = bold <TAB>  <TAB> widget[""leaf_font""] = helv <TAB>  <TAB> widget[""xspace""] = xspace <TAB>  <TAB> widget[""yspace""] = yspace <TAB>  <TAB> if self._size.get() < 20: <TAB>  <TAB>  <TAB> widget[""line_width""] = 1 <MASK> widget[""line_width""] = 2 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> widget[""line_width""] = 3 <TAB> self._layout()",elif self . _size . get ( ) < 30 :,185
3471,"def __assertTilesChangedInRegion(self, t1, t2, region): <TAB> for tileOriginTuple in t1.keys(): <TAB>  <TAB> tileOrigin = imath.V2i(*tileOriginTuple) <TAB>  <TAB> tileRegion = imath.Box2i( <TAB>  <TAB>  <TAB> tileOrigin, tileOrigin + imath.V2i(GafferImage.ImagePlug.tileSize()) <TAB>  <TAB> ) <MASK> self.assertNotEqual(t1[tileOriginTuple], t2[tileOriginTuple]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertEqual(t1[tileOriginTuple], t2[tileOriginTuple])","if GafferImage . BufferAlgo . intersects ( tileRegion , region ) :",165
3472,"def grouped_by_prefix(args, prefixes): <TAB> """"""Group behave args by (directory) scope into multiple test-runs."""""" <TAB> group_args = [] <TAB> current_scope = None <TAB> for arg in args.strip().split(): <TAB>  <TAB> assert not arg.startswith(""-""), ""REQUIRE: arg, not options"" <TAB>  <TAB> scope = select_prefix_for(arg, prefixes) <TAB>  <TAB> if scope != current_scope: <MASK> # -- DETECTED GROUP-END: <TAB>  <TAB>  <TAB>  <TAB> yield "" "".join(group_args) <TAB>  <TAB>  <TAB>  <TAB> group_args = [] <TAB>  <TAB>  <TAB> current_scope = scope <TAB>  <TAB> group_args.append(arg) <TAB> if group_args: <TAB>  <TAB> yield "" "".join(group_args)",if group_args :,183
3473,"def __print__(self, defaults=False): <TAB> if defaults: <TAB>  <TAB> print_func = str <TAB> else: <TAB>  <TAB> print_func = repr <TAB> pieces = [] <TAB> default_values = self.__defaults__ <TAB> for k in self.__fields__: <TAB>  <TAB> value = getattr(self, k) <MASK> continue <TAB>  <TAB> if isinstance(value, basestring): <TAB>  <TAB>  <TAB> print_func = repr  # keep quotes around strings <TAB>  <TAB> pieces.append(""%s=%s"" % (k, print_func(value))) <TAB> if pieces or self.__base__: <TAB>  <TAB> return ""%s(%s)"" % (self.__class__.__name__, "", "".join(pieces)) <TAB> else: <TAB>  <TAB> return """"",if not defaults and value == default_values [ k ] :,178
3474,"def setInnerHTML(self, html): <TAB> log.HTMLClassifier.classify( <TAB>  <TAB> log.ThugLogging.url if log.ThugOpts.local else log.last_url, html <TAB> ) <TAB> self.tag.clear() <TAB> for node in bs4.BeautifulSoup(html, ""html.parser"").contents: <TAB>  <TAB> self.tag.append(node) <TAB>  <TAB> name = getattr(node, ""name"", None) <MASK> continue <TAB>  <TAB> handler = getattr(log.DFT, ""handle_%s"" % (name,), None) <TAB>  <TAB> if handler: <TAB>  <TAB>  <TAB> handler(node)",if name is None :,151
3475,"def createFields(self): <TAB> yield Enum(Bits(self, ""class"", 2), self.CLASS_DESC) <TAB> yield Enum(Bit(self, ""form""), self.FORM_DESC) <TAB> if self[""class""].value == 0: <TAB>  <TAB> yield Enum(Bits(self, ""type"", 5), self.TYPE_DESC) <TAB> else: <TAB>  <TAB> yield Bits(self, ""type"", 5) <TAB> yield ASNInteger(self, ""size"", ""Size in bytes"") <TAB> size = self[""size""].value <TAB> if size: <MASK> for field in self._handler(self, size): <TAB>  <TAB>  <TAB>  <TAB> yield field <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield RawBytes(self, ""raw"", size)",if self . _handler :,175
3476,"def _process_service_request(self, pkttype, pktid, packet): <TAB> """"""Process a service request"""""" <TAB> # pylint: disable=unused-argument <TAB> service = packet.get_string() <TAB> packet.check_end() <TAB> if service == self._next_service: <TAB>  <TAB> self.logger.debug2(""Accepting request for service %s"", service) <TAB>  <TAB> self._next_service = None <TAB>  <TAB> self.send_packet(MSG_SERVICE_ACCEPT, String(service)) <MASK> # pragma: no branch <TAB>  <TAB>  <TAB> self._auth_in_progress = True <TAB>  <TAB>  <TAB> self._send_deferred_packets() <TAB> else: <TAB>  <TAB> raise DisconnectError( <TAB>  <TAB>  <TAB> DISC_SERVICE_NOT_AVAILABLE, ""Unexpected service request received"" <TAB>  <TAB> )",if self . is_server ( ) and service == _USERAUTH_SERVICE :,198
3477,"def _read_fixed_body( <TAB> self, content_length: int, delegate: httputil.HTTPMessageDelegate) -> None: <TAB> while content_length > 0: <TAB>  <TAB> body = await self.stream.read_bytes( <TAB>  <TAB>  <TAB> min(self.params.chunk_size, content_length), partial=True <TAB>  <TAB> ) <TAB>  <TAB> content_length -= len(body) <MASK> with _ExceptionLoggingContext(app_log): <TAB>  <TAB>  <TAB>  <TAB> ret = delegate.data_received(body) <TAB>  <TAB>  <TAB>  <TAB> if ret is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> await ret",if not self . _write_finished or self . is_client :,158
3478,"def wait_for_child(pid, timeout=1.0): <TAB> deadline = mitogen.core.now() + timeout <TAB> while timeout < mitogen.core.now(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> target_pid, status = os.waitpid(pid, os.WNOHANG) <MASK> return <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> e = sys.exc_info()[1] <TAB>  <TAB>  <TAB> if e.args[0] == errno.ECHILD: <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> time.sleep(0.05) <TAB> assert False, ""wait_for_child() timed out""",if target_pid == pid :,156
3479,"def execute(cls, ctx, op: ""DataFrameGroupByAgg""): <TAB> try: <TAB>  <TAB> pd.set_option(""mode.use_inf_as_na"", op.use_inf_as_na) <TAB>  <TAB> if op.stage == OperandStage.map: <TAB>  <TAB>  <TAB> cls._execute_map(ctx, op) <MASK> cls._execute_combine(ctx, op) <TAB>  <TAB> elif op.stage == OperandStage.agg: <TAB>  <TAB>  <TAB> cls._execute_agg(ctx, op) <TAB>  <TAB> else:  # pragma: no cover <TAB>  <TAB>  <TAB> raise ValueError(""Aggregation operand not executable"") <TAB> finally: <TAB>  <TAB> pd.reset_option(""mode.use_inf_as_na"")",elif op . stage == OperandStage . combine :,171
3480,def cut(sentence): <TAB> sentence = strdecode(sentence) <TAB> blocks = re_han.split(sentence) <TAB> for blk in blocks: <TAB>  <TAB> if re_han.match(blk): <TAB>  <TAB>  <TAB> for word in __cut(blk): <MASK> yield word <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for c in word: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield c <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tmp = re_skip.split(blk) <TAB>  <TAB>  <TAB> for x in tmp: <TAB>  <TAB>  <TAB>  <TAB> if x: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield x,if word not in Force_Split_Words :,156
3481,"def _iter_tags(self, type=None): <TAB> """"""Yield all raw tags (limit to |type| if specified)"""""" <TAB> for n in itertools.count(): <TAB>  <TAB> tag = self._get_tag(n) <MASK> yield tag <TAB>  <TAB> if tag[""d_tag""] == ""DT_NULL"": <TAB>  <TAB>  <TAB> break","if type is None or tag [ ""d_tag"" ] == type :",95
3482,"def reverse_search_history(self, searchfor, startpos=None): <TAB> if startpos is None: <TAB>  <TAB> startpos = self.history_cursor <TAB> if _ignore_leading_spaces: <TAB>  <TAB> res = [ <TAB>  <TAB>  <TAB> (idx, line.lstrip()) <TAB>  <TAB>  <TAB> for idx, line in enumerate(self.history[startpos:0:-1]) <TAB>  <TAB>  <TAB> if line.lstrip().startswith(searchfor.lstrip()) <TAB>  <TAB> ] <TAB> else: <TAB>  <TAB> res = [ <TAB>  <TAB>  <TAB> (idx, line) <TAB>  <TAB>  <TAB> for idx, line in enumerate(self.history[startpos:0:-1]) <MASK> ] <TAB> if res: <TAB>  <TAB> self.history_cursor -= res[0][0] <TAB>  <TAB> return res[0][1].get_line_text() <TAB> return """"",if line . startswith ( searchfor ),198
3483,"def value_to_db_datetime(self, value): <TAB> if value is None: <TAB>  <TAB> return None <TAB> # Oracle doesn't support tz-aware datetimes <TAB> if timezone.is_aware(value): <MASK> value = value.astimezone(timezone.utc).replace(tzinfo=None) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Oracle backend does not support timezone-aware datetimes when USE_TZ is False."" <TAB>  <TAB>  <TAB> ) <TAB> return unicode(value)",if settings . USE_TZ :,130
3484,"def _sniff(filename, oxlitype): <TAB> try: <TAB>  <TAB> with open(filename, ""rb"") as fileobj: <TAB>  <TAB>  <TAB> header = fileobj.read(4) <TAB>  <TAB>  <TAB> if header == b""OXLI"": <TAB>  <TAB>  <TAB>  <TAB> fileobj.read(1)  # skip the version number <TAB>  <TAB>  <TAB>  <TAB> ftype = fileobj.read(1) <MASK> return True <TAB>  <TAB> return False <TAB> except OSError: <TAB>  <TAB> return False",if binascii . hexlify ( ftype ) == oxlitype :,126
3485,"def unget(self, char): <TAB> # Only one character is allowed to be ungotten at once - it must <TAB> # be consumed again before any further call to unget <TAB> if char is not EOF: <MASK> # unget is called quite rarely, so it's a good idea to do <TAB>  <TAB>  <TAB> # more work here if it saves a bit of work in the frequently <TAB>  <TAB>  <TAB> # called char and charsUntil. <TAB>  <TAB>  <TAB> # So, just prepend the ungotten character onto the current <TAB>  <TAB>  <TAB> # chunk: <TAB>  <TAB>  <TAB> self.chunk = char + self.chunk <TAB>  <TAB>  <TAB> self.chunkSize += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.chunkOffset -= 1 <TAB>  <TAB>  <TAB> assert self.chunk[self.chunkOffset] == char",if self . chunkOffset == 0 :,188
3486,"def scan(rule, extensions, paths, ignore_paths=None): <TAB> """"""The libsast scan."""""" <TAB> try: <TAB>  <TAB> options = { <TAB>  <TAB>  <TAB> ""match_rules"": rule, <TAB>  <TAB>  <TAB> ""match_extensions"": extensions, <TAB>  <TAB>  <TAB> ""ignore_paths"": ignore_paths, <TAB>  <TAB>  <TAB> ""show_progress"": False, <TAB>  <TAB> } <TAB>  <TAB> scanner = Scanner(options, paths) <TAB>  <TAB> res = scanner.scan() <MASK> return format_findings(res[""pattern_matcher""], paths[0]) <TAB> except Exception: <TAB>  <TAB> logger.exception(""libsast scan"") <TAB> return {}",if res :,150
3487,"def _getPatternTemplate(pattern, key=None): <TAB> if key is None: <TAB>  <TAB> key = pattern <MASK> key = pattern.upper() <TAB> template = DD_patternCache.get(key) <TAB> if not template: <TAB>  <TAB> if key in (""EPOCH"", ""{^LN-BEG}EPOCH"", ""^EPOCH""): <TAB>  <TAB>  <TAB> template = DateEpoch(lineBeginOnly=(key != ""EPOCH"")) <TAB>  <TAB> elif key in (""TAI64N"", ""{^LN-BEG}TAI64N"", ""^TAI64N""): <TAB>  <TAB>  <TAB> template = DateTai64n(wordBegin=(""start"" if key != ""TAI64N"" else False)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> template = DatePatternRegex(pattern) <TAB> DD_patternCache.set(key, template) <TAB> return template","if ""%"" not in pattern :",195
3488,"def _forward_response(self, src, dst): <TAB> """"""Forward an SCP response between two remote SCP servers"""""" <TAB> # pylint: disable=no-self-use <TAB> try: <TAB>  <TAB> exc = yield from src.await_response() <MASK> dst.send_error(exc) <TAB>  <TAB>  <TAB> return exc <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> dst.send_ok() <TAB>  <TAB>  <TAB> return None <TAB> except OSError as exc: <TAB>  <TAB> return exc",if exc :,114
3489,"def _maybe_signal_recovery_end() -> None: <TAB> if self.in_recovery and not self.active_remaining_total(): <TAB>  <TAB> # apply anything stuck in the buffers <TAB>  <TAB> self.flush_buffers() <TAB>  <TAB> self._set_recovery_ended() <MASK> self._actives_span.set_tag(""Actives-Ready"", True) <TAB>  <TAB> self.signal_recovery_end.set()",if self . _actives_span is not None :,115
3490,"def main(): <TAB> tmpdir = None <TAB> try: <TAB>  <TAB> # Create a temporary working directory <TAB>  <TAB> tmpdir = tempfile.mkdtemp() <TAB>  <TAB> # Unpack the zipfile into the temporary directory <TAB>  <TAB> pip_zip = os.path.join(tmpdir, ""pip.zip"") <TAB>  <TAB> with open(pip_zip, ""wb"") as fp: <TAB>  <TAB>  <TAB> fp.write(b85decode(DATA.replace(b""\n"", b""""))) <TAB>  <TAB> # Add the zipfile to sys.path so that we can import it <TAB>  <TAB> sys.path.insert(0, pip_zip) <TAB>  <TAB> # Run the bootstrap <TAB>  <TAB> bootstrap(tmpdir=tmpdir) <TAB> finally: <TAB>  <TAB> # Clean up our temporary working directory <MASK> shutil.rmtree(tmpdir, ignore_errors=True)",if tmpdir :,185
3491,"def __init__(self, api_version_str): <TAB> try: <TAB>  <TAB> self.latest = self.preview = False <TAB>  <TAB> self.yyyy = self.mm = self.dd = None <TAB>  <TAB> if api_version_str == ""latest"": <TAB>  <TAB>  <TAB> self.latest = True <TAB>  <TAB> else: <MASK> self.preview = True <TAB>  <TAB>  <TAB> parts = api_version_str.split(""-"") <TAB>  <TAB>  <TAB> self.yyyy = int(parts[0]) <TAB>  <TAB>  <TAB> self.mm = int(parts[1]) <TAB>  <TAB>  <TAB> self.dd = int(parts[2]) <TAB> except (ValueError, TypeError): <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> ""The API version {} is not in a "" ""supported format"".format(api_version_str) <TAB>  <TAB> )","if ""preview"" in api_version_str :",199
3492,"def _merge(self, items, map_id, dep_id, use_disk, meminfo, mem_limit): <TAB> combined = self.combined <TAB> merge_combiner = self.aggregator.mergeCombiners <TAB> for k, v in items: <TAB>  <TAB> o = combined.get(k) <TAB>  <TAB> combined[k] = merge_combiner(o, v) if o is not None else v <MASK> mem_limit = self._rotate()",if use_disk and meminfo . rss > mem_limit :,120
3493,"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.set_value(d.getVarInt32()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 8 :,90
3494,"def nice(deltat): <TAB> # singular,plural <TAB> times = _( <TAB>  <TAB> ""second,seconds:minute,minutes:hour,hours:day,days:week,weeks:month,months:year,years"" <TAB> ).split("":"") <TAB> d = abs(int(deltat)) <TAB> for div, time in zip((60, 60, 24, 7, 4, 12, 100), times): <MASK> return ""%s%i %s"" % (deltat < 0 and ""-"" or """", d, time.split("","")[d != 1]) <TAB>  <TAB> d /= div",if d < div * 5 :,143
3495,"def after_get_object(self, event, view_kwargs): <TAB> if event and event.state == ""draft"": <MASK> raise ObjectNotFound({""parameter"": ""{id}""}, ""Event: not found"")","if not is_logged_in ( ) or not has_access ( ""is_coorganizer"" , event_id = event . id ) :",79
3496,def daemonize_if_required(self): <TAB> if self.options.daemon: <MASK> # Stop the logging queue listener for the current process <TAB>  <TAB>  <TAB> # We'll restart it once forked <TAB>  <TAB>  <TAB> log.shutdown_multiprocessing_logging_listener(daemonizing=True) <TAB>  <TAB> # Late import so logging works correctly <TAB>  <TAB> salt.utils.process.daemonize() <TAB> # Setup the multiprocessing log queue listener if enabled <TAB> self._setup_mp_logging_listener(),if self . _setup_mp_logging_listener_ is True :,128
3497,"def iter_modules(self, by_clients=False, clients_filter=None): <TAB> """"""iterate over all modules"""""" <TAB> clients = None <TAB> if by_clients: <TAB>  <TAB> clients = self.get_clients(clients_filter) <TAB>  <TAB> if not clients: <TAB>  <TAB>  <TAB> return <TAB> self._refresh_modules() <TAB> for module_name in self.modules: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> module = self.get_module(module_name) <TAB>  <TAB> except PupyModuleDisabled: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if clients is not None: <TAB>  <TAB>  <TAB> for client in clients: <MASK> yield module <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield module",if module . is_compatible_with ( client ) :,181
3498,"def _incremental_avg_dp(self, avg, new_el, idx): <TAB> for attr in [""coarse_segm"", ""fine_segm"", ""u"", ""v""]: <TAB>  <TAB> setattr( <TAB>  <TAB>  <TAB> avg, attr, (getattr(avg, attr) * idx + getattr(new_el, attr)) / (idx + 1) <TAB>  <TAB> ) <MASK> # Deletion of the > 0 index intermediary values to prevent GPU OOM <TAB>  <TAB>  <TAB> setattr(new_el, attr, None) <TAB> return avg",if idx :,129
3499,"def run(self, paths=[]): <TAB> collapsed = False <TAB> for item in SideBarSelection(paths).getSelectedDirectories(): <TAB>  <TAB> for view in item.views(): <MASK> Window().focus_view(view) <TAB>  <TAB>  <TAB>  <TAB> self.collapse_sidebar_folder() <TAB>  <TAB>  <TAB>  <TAB> collapsed = True <TAB>  <TAB>  <TAB> view.close()",if not collapsed :,90
3500,"def test_reductions(expr, rdd): <TAB> result = compute(expr, rdd) <TAB> expected = compute(expr, data) <TAB> if not result == expected: <TAB>  <TAB> print(result) <TAB>  <TAB> print(expected) <MASK> assert abs(result - expected) < 0.001 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert result == expected","if isinstance ( result , float ) :",93
3501,"def deltask(task, d): <TAB> if task[:3] != ""do_"": <TAB>  <TAB> task = ""do_"" + task <TAB> bbtasks = d.getVar(""__BBTASKS"", False) or [] <TAB> if task in bbtasks: <TAB>  <TAB> bbtasks.remove(task) <TAB>  <TAB> d.delVarFlag(task, ""task"") <TAB>  <TAB> d.setVar(""__BBTASKS"", bbtasks) <TAB> d.delVarFlag(task, ""deps"") <TAB> for bbtask in d.getVar(""__BBTASKS"", False) or []: <TAB>  <TAB> deps = d.getVarFlag(bbtask, ""deps"", False) or [] <MASK> deps.remove(task) <TAB>  <TAB>  <TAB> d.setVarFlag(bbtask, ""deps"", deps)",if task in deps :,184
3502,"def _apply_weightnorm(self, list_layers): <TAB> """"""Try apply weightnorm for all layer in list_layers."""""" <TAB> for i in range(len(list_layers)): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> layer_name = list_layers[i].name.lower() <MASK> list_layers[i] = WeightNormalization(list_layers[i]) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> pass","if ""conv1d"" in layer_name or ""dense"" in layer_name :",120
3503,"def __init__(self, execution_context, aggregate_operators): <TAB> super(_QueryExecutionAggregateEndpointComponent, self).__init__(execution_context) <TAB> self._local_aggregators = [] <TAB> self._results = None <TAB> self._result_index = 0 <TAB> for operator in aggregate_operators: <TAB>  <TAB> if operator == ""Average"": <TAB>  <TAB>  <TAB> self._local_aggregators.append(_AverageAggregator()) <TAB>  <TAB> elif operator == ""Count"": <TAB>  <TAB>  <TAB> self._local_aggregators.append(_CountAggregator()) <MASK> self._local_aggregators.append(_MaxAggregator()) <TAB>  <TAB> elif operator == ""Min"": <TAB>  <TAB>  <TAB> self._local_aggregators.append(_MinAggregator()) <TAB>  <TAB> elif operator == ""Sum"": <TAB>  <TAB>  <TAB> self._local_aggregators.append(_SumAggregator())","elif operator == ""Max"" :",192
3504,"def _conv_layer(self, sess, bottom, name, trainable=True, padding=""SAME"", relu=True): <TAB> with tf.variable_scope(name) as scope: <TAB>  <TAB> filt = self._get_conv_filter(sess, name, trainable=trainable) <TAB>  <TAB> conv_biases = self._get_bias(sess, name, trainable=trainable) <TAB>  <TAB> conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding=padding) <TAB>  <TAB> bias = tf.nn.bias_add(conv, conv_biases) <MASK> bias = tf.nn.relu(bias) <TAB>  <TAB> return bias",if relu :,159
3505,"def get_partners(self) -> Dict[AbstractNode, Set[int]]: <TAB> partners = {}  # type: Dict[AbstractNode, Set[int]] <TAB> for edge in self.edges: <TAB>  <TAB> if edge.is_dangling(): <TAB>  <TAB>  <TAB> raise ValueError(""Cannot contract copy tensor with dangling edges"") <MASK> continue <TAB>  <TAB> partner_node, shared_axis = self._get_partner(edge) <TAB>  <TAB> if partner_node not in partners: <TAB>  <TAB>  <TAB> partners[partner_node] = set() <TAB>  <TAB> partners[partner_node].add(shared_axis) <TAB> return partners",if self . _is_my_trace ( edge ) :,163
3506,"def close(self): <TAB> with self._lock: <TAB>  <TAB> """"""Close this _MultiFileWatcher object forever."""""" <MASK> self._folder_handlers = {} <TAB>  <TAB>  <TAB> LOGGER.debug( <TAB>  <TAB>  <TAB>  <TAB> ""Stopping observer thread even though there is a non-zero "" <TAB>  <TAB>  <TAB>  <TAB> ""number of event observers!"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> LOGGER.debug(""Stopping observer thread"") <TAB>  <TAB> self._observer.stop() <TAB>  <TAB> self._observer.join(timeout=5)",if len ( self . _folder_handlers ) != 0 :,135
3507,"def comboSelectionChanged(self, index): <TAB> text = self.comboBox.cb.itemText(index) <TAB> for i in range(self.labelList.count()): <MASK> self.labelList.item(i).setCheckState(2) <TAB>  <TAB> elif text != self.labelList.item(i).text(): <TAB>  <TAB>  <TAB> self.labelList.item(i).setCheckState(0) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.labelList.item(i).setCheckState(2)","if text == """" :",120
3508,"def _get_messages(self): <TAB> r = [] <TAB> try: <TAB>  <TAB> self._connect() <TAB>  <TAB> self._login() <TAB>  <TAB> for message in self._fetch(): <MASK> r.append(message) <TAB>  <TAB> self._connection.expunge() <TAB>  <TAB> self._connection.close() <TAB>  <TAB> self._connection.logout() <TAB> except MailFetcherError as e: <TAB>  <TAB> self.log(""error"", str(e)) <TAB> return r",if message :,114
3509,"def get_current_user(self): <TAB> try: <MASK> return config.get(""json_authentication_override"") <TAB>  <TAB> tkn_header = self.request.headers[""authorization""] <TAB> except KeyError: <TAB>  <TAB> raise WebAuthNError(reason=""Missing Authorization Header"") <TAB> else: <TAB>  <TAB> tkn_str = tkn_header.split("" "")[-1] <TAB> try: <TAB>  <TAB> tkn = self.jwt_validator(tkn_str) <TAB> except AuthenticationError as e: <TAB>  <TAB> raise WebAuthNError(reason=e.message) <TAB> else: <TAB>  <TAB> return tkn","if config . get ( ""development"" ) and config . get ( ""json_authentication_override"" ) :",157
3510,def _get_data(self): <TAB> formdata = self._formdata <TAB> if formdata: <TAB>  <TAB> data = [] <TAB>  <TAB> # TODO: Optimize? <TAB>  <TAB> for item in formdata: <TAB>  <TAB>  <TAB> model = self.loader.get_one(item) if item else None <MASK> data.append(model) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._invalid_formdata = True <TAB>  <TAB> self._set_data(data) <TAB> return self._data,if model :,118
3511,"def _getSubstrings(self, va, size, ltyp): <TAB> # rip through the desired memory range to populate any substrings <TAB> subs = set() <TAB> end = va + size <TAB> for offs in range(va, end, 1): <TAB>  <TAB> loc = self.getLocation(offs, range=True) <TAB>  <TAB> if loc and loc[L_LTYPE] == LOC_STRING and loc[L_VA] > va: <TAB>  <TAB>  <TAB> subs.add((loc[L_VA], loc[L_SIZE])) <MASK> subs = subs.union(set(loc[L_TINFO])) <TAB> return list(subs)",if loc [ L_TINFO ] :,161
3512,def monad(self): <TAB> if not self.cls_bl_idname: <TAB>  <TAB> return None <TAB> for monad in bpy.data.node_groups: <MASK> if monad.cls_bl_idname == self.cls_bl_idname: <TAB>  <TAB>  <TAB>  <TAB> return monad <TAB> return None,"if hasattr ( monad , ""cls_bl_idname"" ) :",93
3513,"def _set_peer_statuses(self): <TAB> """"""Set peer statuses."""""" <TAB> cutoff = time.time() - STALE_SECS <TAB> for peer in self.peers: <TAB>  <TAB> if peer.bad: <TAB>  <TAB>  <TAB> peer.status = PEER_BAD <MASK> peer.status = PEER_GOOD <TAB>  <TAB> elif peer.last_good: <TAB>  <TAB>  <TAB> peer.status = PEER_STALE <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> peer.status = PEER_NEVER",elif peer . last_good > cutoff :,128
3514,"def title_by_index(self, trans, index, context): <TAB> d_type = self.get_datatype(trans, context) <TAB> for i, (composite_name, composite_file) in enumerate(d_type.writable_files.items()): <TAB>  <TAB> if i == index: <TAB>  <TAB>  <TAB> rval = composite_name <MASK> rval = ""{} ({})"".format(rval, composite_file.description) <TAB>  <TAB>  <TAB> if composite_file.optional: <TAB>  <TAB>  <TAB>  <TAB> rval = ""%s [optional]"" % rval <TAB>  <TAB>  <TAB> return rval <TAB> if index < self.get_file_count(trans, context): <TAB>  <TAB> return ""Extra primary file"" <TAB> return None",if composite_file . description :,167
3515,"def testUiViewServerDump_windowIntM1(self): <TAB> device = None <TAB> try: <TAB>  <TAB> device = MockDevice(version=15, startviewserver=True) <TAB>  <TAB> vc = ViewClient(device, device.serialno, adb=TRUE, autodump=False) <TAB>  <TAB> vc.dump(window=-1) <TAB>  <TAB> vc.findViewByIdOrRaise(""id/home"") <TAB> finally: <MASK> device.shutdownMockViewServer()",if device :,116
3516,"def _convertDict(self, d): <TAB> r = {} <TAB> for k, v in d.items(): <TAB>  <TAB> if isinstance(v, bytes): <TAB>  <TAB>  <TAB> v = str(v, ""utf-8"") <TAB>  <TAB> elif isinstance(v, list) or isinstance(v, tuple): <TAB>  <TAB>  <TAB> v = self._convertList(v) <MASK> v = self._convertDict(v) <TAB>  <TAB> if isinstance(k, bytes): <TAB>  <TAB>  <TAB> k = str(k, ""utf-8"") <TAB>  <TAB> r[k] = v <TAB> return r","elif isinstance ( v , dict ) :",142
3517,"def _testSendmsgTimeout(self): <TAB> try: <TAB>  <TAB> self.cli_sock.settimeout(0.03) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB>  <TAB> self.sendmsgToServer([b""a"" * 512]) <TAB>  <TAB> except socket.timeout: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> except OSError as exc: <MASK> raise <TAB>  <TAB>  <TAB> # bpo-33937 the test randomly fails on Travis CI with <TAB>  <TAB>  <TAB> # ""OSError: [Errno 12] Cannot allocate memory"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.fail(""socket.timeout not raised"") <TAB> finally: <TAB>  <TAB> self.misc_event.set()",if exc . errno != errno . ENOMEM :,170
3518,"def addError(self, test, err): <TAB> if err[0] is SkipTest: <TAB>  <TAB> if self.showAll: <TAB>  <TAB>  <TAB> self.stream.writeln(str(err[1])) <MASK> self.stream.write(""s"") <TAB>  <TAB>  <TAB> self.stream.flush() <TAB>  <TAB> return <TAB> _org_AddError(self, test, err)",elif self . dots :,93
3519,"def mouse_down(self, event): <TAB> if event.button == 1: <TAB>  <TAB> if self.scrolling: <TAB>  <TAB>  <TAB> p = event.local <TAB>  <TAB>  <TAB> if self.scroll_up_rect().collidepoint(p): <TAB>  <TAB>  <TAB>  <TAB> self.scroll_up() <TAB>  <TAB>  <TAB>  <TAB> return <MASK> self.scroll_down() <TAB>  <TAB>  <TAB>  <TAB> return <TAB> if event.button == 4: <TAB>  <TAB> self.scroll_up() <TAB> if event.button == 5: <TAB>  <TAB> self.scroll_down() <TAB> GridView.mouse_down(self, event)",elif self . scroll_down_rect ( ) . collidepoint ( p ) :,160
3520,"def find_file_copyright_notices(fname): <TAB> ret = set() <TAB> f = open(fname) <TAB> lines = f.readlines() <TAB> for l in lines[:80]:  # hmmm, assume copyright to be in first 80 lines <TAB>  <TAB> idx = l.lower().find(""copyright"") <TAB>  <TAB> if idx < 0: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> copyright = l[idx + 9 :].strip() <MASK> continue <TAB>  <TAB> copyright = sanitise(copyright) <TAB>  <TAB> # hmm, do a quick check to see if there's a year, <TAB>  <TAB> # if not, skip it <TAB>  <TAB> if not copyright.find(""200"") >= 0 and not copyright.find(""199"") >= 0: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> ret.add(copyright) <TAB> return ret",if not copyright :,186
3521,"def get_selectable_values(self, request): <TAB> shop = lfs.core.utils.get_default_shop(request) <TAB> countries = [] <TAB> for country in shop.shipping_countries.all(): <MASK> selected = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> selected = False <TAB>  <TAB> countries.append( <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB> ""id"": country.id, <TAB>  <TAB>  <TAB>  <TAB> ""name"": country.name, <TAB>  <TAB>  <TAB>  <TAB> ""selected"": selected, <TAB>  <TAB>  <TAB> } <TAB>  <TAB> ) <TAB> return countries",if country in self . value . all ( ) :,139
3522,"def _addItemToLayout(self, sample, label): <TAB> col = self.layout.columnCount() <TAB> row = self.layout.rowCount() <TAB> if row: <TAB>  <TAB> row -= 1 <TAB> nCol = self.columnCount * 2 <TAB> # FIRST ROW FULL <TAB> if col == nCol: <TAB>  <TAB> for col in range(0, nCol, 2): <TAB>  <TAB>  <TAB> # FIND RIGHT COLUMN <TAB>  <TAB>  <TAB> if not self.layout.itemAt(row, col): <TAB>  <TAB>  <TAB>  <TAB> break <MASK> # MAKE NEW ROW <TAB>  <TAB>  <TAB> col = 0 <TAB>  <TAB>  <TAB> row += 1 <TAB> self.layout.addItem(sample, row, col) <TAB> self.layout.addItem(label, row, col + 1)",if col + 2 == nCol :,185
3523,def contains_only_whitespace(node): <TAB> if is_tag(node): <TAB>  <TAB> if not any([not is_text(s) for s in node.contents]): <MASK> return True <TAB> return False,if not any ( [ unicode ( s ) . strip ( ) for s in node . contents ] ) :,72
3524,"def tokenize_generator(cw): <TAB> ret = [] <TAB> done = {} <TAB> for op in ops: <TAB>  <TAB> ch = op.symbol[0] <MASK> continue <TAB>  <TAB> sops = start_symbols[ch] <TAB>  <TAB> cw.write(""case '%s':"" % ch) <TAB>  <TAB> for t in gen_tests(sops, 1): <TAB>  <TAB>  <TAB> cw.write(t) <TAB>  <TAB> done[ch] = True <TAB> return ret",if ch in done :,113
3525,"def _convertNbCharsInNbBits(self, nbChars): <TAB> nbMinBit = None <TAB> nbMaxBit = None <TAB> if nbChars is not None: <MASK> nbMinBit = nbChars * 8 <TAB>  <TAB>  <TAB> nbMaxBit = nbMinBit <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if nbChars[0] is not None: <TAB>  <TAB>  <TAB>  <TAB> nbMinBit = nbChars[0] * 8 <TAB>  <TAB>  <TAB> if nbChars[1] is not None: <TAB>  <TAB>  <TAB>  <TAB> nbMaxBit = nbChars[1] * 8 <TAB> return (nbMinBit, nbMaxBit)","if isinstance ( nbChars , int ) :",158
3526,"def init(self, *args, **kwargs): <TAB> if ""_state"" not in kwargs: <TAB>  <TAB> state = {} <TAB>  <TAB> # Older versions have the _state entries as individual kwargs <TAB>  <TAB> for arg in (""children"", ""windowState"", ""detachedPanels""): <TAB>  <TAB>  <TAB> if arg in kwargs: <TAB>  <TAB>  <TAB>  <TAB> state[arg] = kwargs[arg] <TAB>  <TAB>  <TAB>  <TAB> del kwargs[arg] <MASK> kwargs[""_state""] = state <TAB> originalInit(self, *args, **kwargs)",if state :,125
3527,"def spm_decode(tokens: List[str]) -> List[str]: <TAB> words = [] <TAB> pieces: List[str] = [] <TAB> for t in tokens: <MASK> if len(pieces) > 0: <TAB>  <TAB>  <TAB>  <TAB> words.append("""".join(pieces)) <TAB>  <TAB>  <TAB> pieces = [t[1:]] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pieces.append(t) <TAB> if len(pieces) > 0: <TAB>  <TAB> words.append("""".join(pieces)) <TAB> return words",if t [ 0 ] == DecodeMixin . spm_bos_token :,133
3528,"def _compare_dirs(self, dir1: str, dir2: str) -> List[str]: <TAB> # check that dir1 and dir2 are equivalent, <TAB> # return the diff <TAB> diff = []  # type: List[str] <TAB> for root, dirs, files in os.walk(dir1): <TAB>  <TAB> for file_ in files: <TAB>  <TAB>  <TAB> path = os.path.join(root, file_) <TAB>  <TAB>  <TAB> target_path = os.path.join(dir2, os.path.split(path)[-1]) <MASK> diff.append(file_) <TAB> return diff",if not os . path . exists ( target_path ) :,155
3529,"def credentials(self): <TAB> """"""The session credentials as a dict"""""" <TAB> creds = {} <TAB> if self._creds: <MASK> # pragma: no branch <TAB>  <TAB>  <TAB> creds[""aws_access_key_id""] = self._creds.access_key <TAB>  <TAB> if self._creds.secret_key:  # pragma: no branch <TAB>  <TAB>  <TAB> creds[""aws_secret_access_key""] = self._creds.secret_key <TAB>  <TAB> if self._creds.token: <TAB>  <TAB>  <TAB> creds[""aws_session_token""] = self._creds.token <TAB> if self._session.region_name: <TAB>  <TAB> creds[""aws_region""] = self._session.region_name <TAB> if self.requester_pays: <TAB>  <TAB> creds[""aws_request_payer""] = ""requester"" <TAB> return creds",if self . _creds . access_key :,194
3530,"def got_arbiter_module_type_defined(self, mod_type): <TAB> for a in self.arbiters: <TAB>  <TAB> # Do like the linkify will do after.... <TAB>  <TAB> for m in getattr(a, ""modules"", []): <TAB>  <TAB>  <TAB> # So look at what the arbiter try to call as module <TAB>  <TAB>  <TAB> m = m.strip() <TAB>  <TAB>  <TAB> # Ok, now look in modules... <TAB>  <TAB>  <TAB> for mod in self.modules: <TAB>  <TAB>  <TAB>  <TAB> # try to see if this module is the good type <TAB>  <TAB>  <TAB>  <TAB> if getattr(mod, ""module_type"", """").strip() == mod_type.strip(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # if so, the good name? <MASK> return True <TAB> return False","if getattr ( mod , ""module_name"" , """" ) . strip ( ) == m :",199
3531,"def find_file_at_path_with_indexes(self, path, url): <TAB> if url.endswith(""/""): <TAB>  <TAB> path = os.path.join(path, self.index_file) <TAB>  <TAB> return self.get_static_file(path, url) <TAB> elif url.endswith(""/"" + self.index_file): <TAB>  <TAB> if os.path.isfile(path): <TAB>  <TAB>  <TAB> return self.redirect(url, url[: -len(self.index_file)]) <TAB> else: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self.get_static_file(path, url) <TAB>  <TAB> except IsDirectoryError: <MASK> return self.redirect(url, url + ""/"") <TAB> raise MissingFileError(path)","if os . path . isfile ( os . path . join ( path , self . index_file ) ) :",193
3532,def _use_full_params(self) -> None: <TAB> for p in self.params: <TAB>  <TAB> if not p._is_sharded: <MASK> assert p._fp16_shard.storage().size() != 0 <TAB>  <TAB>  <TAB>  <TAB> p.data = p._fp16_shard <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert p._full_param_padded.storage().size() != 0 <TAB>  <TAB>  <TAB> p.data = p._full_param_padded[: p._orig_size.numel()].view(p._orig_size),if self . mixed_precision :,136
3533,"def _attrdata(self, cont, name, *val): <TAB> if not name: <TAB>  <TAB> return None, False <TAB> if isinstance(name, Mapping): <TAB>  <TAB> if val: <TAB>  <TAB>  <TAB> raise TypeError(""Cannot set a value to %s"" % name) <TAB>  <TAB> return name, True <TAB> else: <TAB>  <TAB> if val: <MASK> return {name: val[0]}, True <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise TypeError(""Too may arguments"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> cont = self._extra.get(cont) <TAB>  <TAB>  <TAB> return cont.get(name) if cont else None, False",if len ( val ) == 1 :,158
3534,"def evaluate(env, net, device=""cpu""): <TAB> obs = env.reset() <TAB> reward = 0.0 <TAB> steps = 0 <TAB> while True: <TAB>  <TAB> obs_v = ptan.agent.default_states_preprocessor([obs]).to(device) <TAB>  <TAB> action_v = net(obs_v) <TAB>  <TAB> action = action_v.data.cpu().numpy()[0] <TAB>  <TAB> obs, r, done, _ = env.step(action) <TAB>  <TAB> reward += r <TAB>  <TAB> steps += 1 <MASK> break <TAB> return reward, steps",if done :,137
3535,"def convert_html_js_files(app: Sphinx, config: Config) -> None: <TAB> """"""This converts string styled html_js_files to tuple styled one."""""" <TAB> html_js_files = []  # type: List[Tuple[str, Dict]] <TAB> for entry in config.html_js_files: <MASK> html_js_files.append((entry, {})) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> filename, attrs = entry <TAB>  <TAB>  <TAB>  <TAB> html_js_files.append((filename, attrs)) <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> logger.warning(__(""invalid js_file: %r, ignored""), entry) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB> config.html_js_files = html_js_files  # type: ignore","if isinstance ( entry , str ) :",193
3536,"def _check_duplications(self, regs): <TAB> """"""n^2 loop which verifies that each reg exists only once."""""" <TAB> for reg in regs: <TAB>  <TAB> count = 0 <TAB>  <TAB> for r in regs: <MASK> count += 1 <TAB>  <TAB> if count > 1: <TAB>  <TAB>  <TAB> genutil.die(""reg %s defined more than once"" % reg)",if reg == r :,94
3537,"def PyJsHoisted_vault_(key, forget, this, arguments, var=var): <TAB> var = Scope( <TAB>  <TAB> {u""this"": this, u""forget"": forget, u""key"": key, u""arguments"": arguments}, var <TAB> ) <TAB> var.registers([u""forget"", u""key""]) <TAB> if PyJsStrictEq(var.get(u""key""), var.get(u""passkey"")): <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB> var.put(u""secret"", var.get(u""null"")) <MASK> else ( <TAB>  <TAB>  <TAB>  <TAB> var.get(u""secret"") <TAB>  <TAB>  <TAB>  <TAB> or var.put(u""secret"", var.get(u""secretCreatorFn"")(var.get(u""object""))) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> )","if var . get ( u""forget"" )",198
3538,"def sort_nested_dictionary_lists(d): <TAB> for k, v in d.items(): <TAB>  <TAB> if isinstance(v, list): <TAB>  <TAB>  <TAB> for i in range(0, len(v)): <TAB>  <TAB>  <TAB>  <TAB> if isinstance(v[i], dict): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> v[i] = await sort_nested_dictionary_lists(v[i]) <TAB>  <TAB>  <TAB>  <TAB> d[k] = sorted(v) <MASK> d[k] = await sort_nested_dictionary_lists(v) <TAB> return d","if isinstance ( v , dict ) :",134
3539,"def transceiver(self, data): <TAB> out = [] <TAB> for t in range(8): <TAB>  <TAB> if data[t] == 0: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> value = data[t] <TAB>  <TAB> for b in range(8): <TAB>  <TAB>  <TAB> if value & 0x80: <MASK> out.append(""(unknown)"") <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> out.append(TRANSCEIVER[t][b]) <TAB>  <TAB>  <TAB> value <<= 1 <TAB> self.annotate(""Transceiver compliance"", "", "".join(out))",if len ( TRANSCEIVER [ t ] ) < b + 1 :,155
3540,"def process_string(self, remove_repetitions, sequence): <TAB> string = """" <TAB> for i, char in enumerate(sequence): <TAB>  <TAB> if char != self.int_to_char[self.blank_index]: <TAB>  <TAB>  <TAB> # if this char is a repetition and remove_repetitions=true, <TAB>  <TAB>  <TAB> # skip. <MASK> pass <TAB>  <TAB>  <TAB> elif char == self.labels[self.space_index]: <TAB>  <TAB>  <TAB>  <TAB> string += "" "" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> string = string + char <TAB> return string",if remove_repetitions and i != 0 and char == sequence [ i - 1 ] :,152
3541,"def clean(self): <TAB> username = self.cleaned_data.get(""username"") <TAB> password = self.cleaned_data.get(""password"") <TAB> if username and password: <TAB>  <TAB> self.user_cache = authenticate(username=username, password=password) <MASK> raise forms.ValidationError(self.error_messages[""invalid_login""]) <TAB>  <TAB> elif not self.user_cache.is_active: <TAB>  <TAB>  <TAB> raise forms.ValidationError(self.error_messages[""inactive""]) <TAB> self.check_for_test_cookie() <TAB> return self.cleaned_data",if self . user_cache is None :,143
3542,"def is_listening_for_message(conversation_id: Text, endpoint: EndpointConfig) -> bool: <TAB> """"""Check if the conversation is in need for a user message."""""" <TAB> tracker = await retrieve_tracker(endpoint, conversation_id, EventVerbosity.APPLIED) <TAB> for i, e in enumerate(reversed(tracker.get(""events"", []))): <TAB>  <TAB> if e.get(""event"") == UserUttered.type_name: <TAB>  <TAB>  <TAB> return False <MASK> return e.get(""name"") == ACTION_LISTEN_NAME <TAB> return False","elif e . get ( ""event"" ) == ActionExecuted . type_name :",154
3543,"def getReferences(view, name=""""): <TAB> """"""Find all reference definitions."""""" <TAB> # returns {name -> Region} <TAB> refs = [] <TAB> name = re.escape(name) <TAB> if name == """": <TAB>  <TAB> refs.extend(view.find_all(r""(?<=^\[)([^\]]+)(?=\]:)"", 0)) <TAB> else: <TAB>  <TAB> refs.extend(view.find_all(r""(?<=^\[)(%s)(?=\]:)"" % name, 0)) <TAB> regions = refs <TAB> ids = {} <TAB> for reg in regions: <TAB>  <TAB> name = view.substr(reg).strip() <TAB>  <TAB> key = name.lower() <MASK> ids[key].regions.append(reg) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ids[key] = Obj(regions=[reg], label=name) <TAB> return ids",if key in ids :,199
3544,"def _get_header(self, requester, header_name): <TAB> hits = sum([header_name in headers for _, headers in requester.requests]) <TAB> self.assertEquals(hits, 2 if self.revs_enabled else 1) <TAB> for url, headers in requester.requests: <MASK> if self.revs_enabled: <TAB>  <TAB>  <TAB>  <TAB> self.assertTrue(url.endswith(""/latest""), msg=url) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.assertTrue(url.endswith(""/download_urls""), msg=url) <TAB>  <TAB>  <TAB> return headers.get(header_name)",if header_name in headers :,143
3545,"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.set_shuffle_name(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 10 :,92
3546,"def make_release_tree(self, base_dir, files): <TAB> """"""Make the release tree."""""" <TAB> self.mkpath(base_dir) <TAB> create_tree(base_dir, files, dry_run=self.dry_run) <TAB> if not files: <TAB>  <TAB> self.log.warning(""no files to distribute -- empty manifest?"") <TAB> else: <TAB>  <TAB> self.log.info(""copying files to %s..."", base_dir) <TAB> for filename in files: <MASK> self.log.warning(""'%s' not a regular file -- skipping"", filename) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> dest = os.path.join(base_dir, filename) <TAB>  <TAB>  <TAB> self.copy_file(filename, dest) <TAB> self.distribution.metadata.write_pkg_info(base_dir)",if not os . path . isfile ( filename ) :,199
3547,"def _parse_names_set(feature_names): <TAB> """"""Helping function of `_parse_feature_names` that parses a set of feature names."""""" <TAB> feature_collection = OrderedDict() <TAB> for feature_name in feature_names: <MASK> feature_collection[feature_name] = ... <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""Failed to parse {}, expected string"".format(feature_name)) <TAB> return feature_collection","if isinstance ( feature_name , str ) :",111
3548,"def get_connection(self, url, proxies=None): <TAB> with self.pools.lock: <TAB>  <TAB> pool = self.pools.get(url) <MASK> return pool <TAB>  <TAB> pool = NpipeHTTPConnectionPool( <TAB>  <TAB>  <TAB> self.npipe_path, self.timeout, maxsize=self.max_pool_size <TAB>  <TAB> ) <TAB>  <TAB> self.pools[url] = pool <TAB> return pool",if pool :,102
3549,"def _parse_dimensions(dimensions): <TAB> arrays = [] <TAB> names = [] <TAB> for key in dimensions: <TAB>  <TAB> values = [v[""name""] for v in key[""values""]] <TAB>  <TAB> role = key.get(""role"", None) <MASK> values = [_fix_quarter_values(v) for v in values] <TAB>  <TAB>  <TAB> values = pd.DatetimeIndex(values) <TAB>  <TAB> arrays.append(values) <TAB>  <TAB> names.append(key[""name""]) <TAB> midx = pd.MultiIndex.from_product(arrays, names=names) <TAB> if len(arrays) == 1 and isinstance(midx, pd.MultiIndex): <TAB>  <TAB> # Fix for pandas >= 0.21 <TAB>  <TAB> midx = midx.levels[0] <TAB> return midx","if role in ( ""time"" , ""TIME_PERIOD"" ) :",190
3550,"def _add_trials(self, name, spec): <TAB> """"""Add trial by invoking TrialRunner."""""" <TAB> resource = {} <TAB> resource[""trials""] = [] <TAB> trial_generator = BasicVariantGenerator() <TAB> trial_generator.add_configurations({name: spec}) <TAB> while not trial_generator.is_finished(): <TAB>  <TAB> trial = trial_generator.next_trial() <MASK> break <TAB>  <TAB> runner.add_trial(trial) <TAB>  <TAB> resource[""trials""].append(self._trial_info(trial)) <TAB> return resource",if not trial :,130
3551,"def _retrieve_key(self): <TAB> url = ""http://www.canadapost.ca/cpo/mc/personal/postalcode/fpc.jsf"" <TAB> text = """" <TAB> try: <TAB>  <TAB> r = requests.get(url, timeout=self.timeout, proxies=self.proxies) <TAB>  <TAB> text = r.text <TAB> except: <TAB>  <TAB> self.error = ""ERROR - URL Connection"" <TAB> if text: <TAB>  <TAB> expression = r""'(....-....-....-....)';"" <TAB>  <TAB> pattern = re.compile(expression) <TAB>  <TAB> match = pattern.search(text) <MASK> self.key = match.group(1) <TAB>  <TAB>  <TAB> return self.key <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.error = ""ERROR - No API Key""",if match :,190
3552,"def test_net(net, env, count=10, device=""cpu""): <TAB> rewards = 0.0 <TAB> steps = 0 <TAB> for _ in range(count): <TAB>  <TAB> obs = env.reset() <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> obs_v = ptan.agent.float32_preprocessor([obs]).to(device) <TAB>  <TAB>  <TAB> mu_v = net(obs_v)[0] <TAB>  <TAB>  <TAB> action = mu_v.squeeze(dim=0).data.cpu().numpy() <TAB>  <TAB>  <TAB> action = np.clip(action, -1, 1) <TAB>  <TAB>  <TAB> obs, reward, done, _ = env.step(action) <TAB>  <TAB>  <TAB> rewards += reward <TAB>  <TAB>  <TAB> steps += 1 <MASK> break <TAB> return rewards / count, steps / count",if done :,190
3553,"def compile(self, filename, obfuscate=False, raw=False, magic=""\x00"" * 8): <TAB> body = marshal.dumps(compile(self.visit(self._source_ast), filename, ""exec"")) <TAB> if obfuscate: <TAB>  <TAB> body_len = len(body) <TAB>  <TAB> offset = 0 if raw else 8 <TAB>  <TAB> output = bytearray(body_len + 8) <TAB>  <TAB> for i, x in enumerate(body): <TAB>  <TAB>  <TAB> output[i + offset] = ord(x) ^ ((2 ** ((65535 - i) % 65535)) % 251) <MASK> for i in xrange(8): <TAB>  <TAB>  <TAB>  <TAB> output[i] = 0 <TAB>  <TAB> return output <TAB> elif raw: <TAB>  <TAB> return body <TAB> else: <TAB>  <TAB> return magic + body",if raw :,188
3554,"def _map_saslprep(s): <TAB> """"""Map stringprep table B.1 to nothing and C.1.2 to ASCII space"""""" <TAB> r = [] <TAB> for c in s: <TAB>  <TAB> if stringprep.in_table_c12(c): <TAB>  <TAB>  <TAB> r.append("" "") <MASK> r.append(c) <TAB> return """".join(r)",elif not stringprep . in_table_b1 ( c ) :,106
3555,"def ensemble(self, pairs, other_preds): <TAB> """"""Ensemble the dict with statistical model predictions."""""" <TAB> lemmas = [] <TAB> assert len(pairs) == len(other_preds) <TAB> for p, pred in zip(pairs, other_preds): <TAB>  <TAB> w, pos = p <TAB>  <TAB> if (w, pos) in self.composite_dict: <TAB>  <TAB>  <TAB> lemma = self.composite_dict[(w, pos)] <MASK> lemma = self.word_dict[w] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lemma = pred <TAB>  <TAB> if lemma is None: <TAB>  <TAB>  <TAB> lemma = w <TAB>  <TAB> lemmas.append(lemma) <TAB> return lemmas",elif w in self . word_dict :,164
3556,"def quiet_f(*args): <TAB> vars = {arg_name: Real(arg) for arg_name, arg in zip(arg_names, args)} <TAB> value = dynamic_scoping(quiet_expr.evaluate, vars, evaluation) <TAB> if expect_list: <MASK> value = [extract_pyreal(item) for item in value.leaves] <TAB>  <TAB>  <TAB> if any(item is None for item in value): <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB>  <TAB> return value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return None <TAB> else: <TAB>  <TAB> value = extract_pyreal(value) <TAB>  <TAB> if value is None or isinf(value) or isnan(value): <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> return value","if value . has_form ( ""List"" , None ) :",177
3557,"def _copy_package_apps( <TAB> local_bin_dir: Path, app_paths: List[Path], suffix: str = """") -> None: <TAB> for src_unresolved in app_paths: <TAB>  <TAB> src = src_unresolved.resolve() <TAB>  <TAB> app = src.name <TAB>  <TAB> dest = Path(local_bin_dir / add_suffix(app, suffix)) <TAB>  <TAB> if not dest.parent.is_dir(): <TAB>  <TAB>  <TAB> mkdir(dest.parent) <MASK> logger.warning(f""{hazard}  Overwriting file {str(dest)} with {str(src)}"") <TAB>  <TAB>  <TAB> dest.unlink() <TAB>  <TAB> if src.exists(): <TAB>  <TAB>  <TAB> shutil.copy(src, dest)",if dest . exists ( ) :,177
3558,"def assert_readback(vehicle, values): <TAB> i = 10 <TAB> while i > 0: <TAB>  <TAB> time.sleep(0.1) <TAB>  <TAB> i -= 0.1 <TAB>  <TAB> for k, v in values.items(): <MASK> continue <TAB>  <TAB> break <TAB> if i <= 0: <TAB>  <TAB> raise Exception(""Did not match in channels readback %s"" % values)",if vehicle . channels [ k ] != v :,105
3559,"def _get_linode_client(self): <TAB> api_key = self.credentials.conf(""key"") <TAB> api_version = self.credentials.conf(""version"") <TAB> if api_version == """": <TAB>  <TAB> api_version = None <TAB> if not api_version: <TAB>  <TAB> api_version = 3 <TAB>  <TAB> # Match for v4 api key <TAB>  <TAB> regex_v4 = re.compile(""^[0-9a-f]{64}$"") <TAB>  <TAB> regex_match = regex_v4.match(api_key) <MASK> api_version = 4 <TAB> else: <TAB>  <TAB> api_version = int(api_version) <TAB> return _LinodeLexiconClient(api_key, api_version)",if regex_match :,175
3560,"def mergeHiLo(self, x_stats): <TAB> """"""Merge the highs and lows of another accumulator into myself."""""" <TAB> if x_stats.firsttime is not None: <MASK> self.firsttime = x_stats.firsttime <TAB>  <TAB>  <TAB> self.first = x_stats.first <TAB> if x_stats.lasttime is not None: <TAB>  <TAB> if self.lasttime is None or x_stats.lasttime >= self.lasttime: <TAB>  <TAB>  <TAB> self.lasttime = x_stats.lasttime <TAB>  <TAB>  <TAB> self.last = x_stats.last",if self . firsttime is None or x_stats . firsttime < self . firsttime :,157
3561,"def _check_good_input(self, X, y=None): <TAB> if isinstance(X, dict): <TAB>  <TAB> lengths = [len(X1) for X1 in X.values()] <MASK> raise ValueError(""Not all values of X are of equal length."") <TAB>  <TAB> x_len = lengths[0] <TAB> else: <TAB>  <TAB> x_len = len(X) <TAB> if y is not None: <TAB>  <TAB> if len(y) != x_len: <TAB>  <TAB>  <TAB> raise ValueError(""X and y are not of equal length."") <TAB> if self.regression and y is not None and y.ndim == 1: <TAB>  <TAB> y = y.reshape(-1, 1) <TAB> return X, y",if len ( set ( lengths ) ) > 1 :,175
3562,"def set(self, obj, **kwargs): <TAB> """"""Check for missing event functions and substitute these with"""""" <TAB> """"""the ignore method"""""" <TAB> ignore = getattr(self, ""ignore"") <TAB> for k, v in kwargs.iteritems(): <TAB>  <TAB> setattr(self, k, getattr(obj, v)) <TAB>  <TAB> if k in self.combinations: <TAB>  <TAB>  <TAB> for k1 in self.combinations[k]: <MASK> setattr(self, k1, ignore)","if not hasattr ( self , k1 ) :",121
3563,"def _parse_list(self, tokens): <TAB> # Process left to right, allow descending in sub lists <TAB> assert tokens[0] in (""["", ""("") <TAB> delim = ""]"" if tokens.pop(0) == ""["" else "")"" <TAB> expr = ExpressionList() <TAB> while tokens and tokens[0] != delim: <TAB>  <TAB> item = self._parse(tokens) <MASK> if tokens.pop(0) != "","": <TAB>  <TAB>  <TAB>  <TAB> raise ExpressionSyntaxError('Expected: "",""') <TAB>  <TAB> expr.append(item) <TAB> if not tokens or tokens[0] != delim: <TAB>  <TAB> raise ExpressionSyntaxError('Missing: ""%s""' % delim) <TAB> else: <TAB>  <TAB> tokens.pop(0) <TAB> return expr",if tokens and tokens [ 0 ] != delim :,174
3564,"def param_value(self): <TAB> # This is part of the ""handle quoted extended parameters"" hack. <TAB> for token in self: <TAB>  <TAB> if token.token_type == ""value"": <TAB>  <TAB>  <TAB> return token.stripped_value <MASK> for token in token: <TAB>  <TAB>  <TAB>  <TAB> if token.token_type == ""bare-quoted-string"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for token in token: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if token.token_type == ""value"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return token.stripped_value <TAB> return """"","if token . token_type == ""quoted-string"" :",143
3565,"def paragraph_is_fully_commented(lines, comment, main_language): <TAB> """"""Is the paragraph fully commented?"""""" <TAB> for i, line in enumerate(lines): <MASK> if line[len(comment) :].lstrip().startswith(comment): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if is_magic(line, main_language): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> return i > 0 and _BLANK_LINE.match(line) <TAB> return True",if line . startswith ( comment ) :,121
3566,"def lots_connected_to_existing_roads(model): <TAB> set = [] <TAB> for h in model.HarvestCells: <TAB>  <TAB> for (i, j) in model.ExistingRoads: <MASK> if h not in set: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> set.append(h) <TAB> return set",if ( i in model . COriginNodeForCell [ h ] ) or ( j in model . COriginNodeForCell [ h ] ) :,108
3567,"def detect(get_page): <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS: <TAB>  <TAB> page, headers, code = get_page(get=vector) <TAB>  <TAB> retval = ( <TAB>  <TAB>  <TAB> re.search( <TAB>  <TAB>  <TAB>  <TAB> r""\Abarra_counter_session="", <TAB>  <TAB>  <TAB>  <TAB> headers.get(HTTP_HEADER.SET_COOKIE, """"), <TAB>  <TAB>  <TAB>  <TAB> re.I, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> is not None <TAB>  <TAB> ) <TAB>  <TAB> retval |= ( <TAB>  <TAB>  <TAB> re.search( <TAB>  <TAB>  <TAB>  <TAB> r""(\A|\b)barracuda_"", headers.get(HTTP_HEADER.SET_COOKIE, """"), re.I <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> is not None <TAB>  <TAB> ) <MASK> break <TAB> return retval",if retval :,194
3568,"def test_files(self): <TAB> # get names of files to test <TAB> dist_dir = os.path.join(os.path.dirname(__file__), os.pardir, os.pardir) <TAB> names = [] <TAB> for d in self.test_directories: <TAB>  <TAB> test_dir = os.path.join(dist_dir, d) <TAB>  <TAB> for n in os.listdir(test_dir): <MASK> names.append(os.path.join(test_dir, n)) <TAB> for filename in names: <TAB>  <TAB> if test_support.verbose: <TAB>  <TAB>  <TAB> print(""Testing %s"" % filename) <TAB>  <TAB> source = read_pyfile(filename) <TAB>  <TAB> self.check_roundtrip(source)","if n . endswith ( "".py"" ) and not n . startswith ( ""bad"" ) :",186
3569,"def test_calibrate_target(create_target): <TAB> mod, params = testing.synthetic.get_workload() <TAB> dataset = get_calibration_dataset(mod, ""data"") <TAB> with relay.quantize.qconfig(calibrate_mode=""kl_divergence""): <MASK> with tvm.target.Target(""llvm""): <TAB>  <TAB>  <TAB>  <TAB> relay.quantize.quantize(mod, params, dataset) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # current_target = None <TAB>  <TAB>  <TAB> relay.quantize.quantize(mod, params, dataset)",if create_target :,133
3570,"def _cleanSubmodule(self, _=None): <TAB> rc = RC_SUCCESS <TAB> if self.submodules: <TAB>  <TAB> command = [ <TAB>  <TAB>  <TAB> ""submodule"", <TAB>  <TAB>  <TAB> ""foreach"", <TAB>  <TAB>  <TAB> ""--recursive"", <TAB>  <TAB>  <TAB> ""git"", <TAB>  <TAB>  <TAB> ""clean"", <TAB>  <TAB>  <TAB> ""-f"", <TAB>  <TAB>  <TAB> ""-f"", <TAB>  <TAB>  <TAB> ""-d"", <TAB>  <TAB> ] <MASK> command.append(""-x"") <TAB>  <TAB> rc = yield self._dovccmd(command) <TAB> defer.returnValue(rc)","if self . mode == ""full"" and self . method == ""fresh"" :",147
3571,"def screen_length_to_bytes_count(string, screen_length_limit, encoding): <TAB> bytes_count = 0 <TAB> screen_length = 0 <TAB> for unicode_char in string: <TAB>  <TAB> screen_length += screen_len(unicode_char) <TAB>  <TAB> char_bytes_count = len(unicode_char.encode(encoding)) <TAB>  <TAB> bytes_count += char_bytes_count <MASK> bytes_count -= char_bytes_count <TAB>  <TAB>  <TAB> break <TAB> return bytes_count",if screen_length > screen_length_limit :,129
3572,"def tamper(payload, **kwargs): <TAB> junk_chars = ""!#$%&()*~+-_.,:;?@[/|\]^`"" <TAB> retval = """" <TAB> for i, char in enumerate(payload, start=1): <TAB>  <TAB> amount = random.randint(10, 15) <TAB>  <TAB> if char == "">"": <TAB>  <TAB>  <TAB> retval += "">"" <TAB>  <TAB>  <TAB> for _ in range(amount): <TAB>  <TAB>  <TAB>  <TAB> retval += random.choice(junk_chars) <MASK> retval += ""<"" <TAB>  <TAB>  <TAB> for _ in range(amount): <TAB>  <TAB>  <TAB>  <TAB> retval += random.choice(junk_chars) <TAB>  <TAB> elif char == "" "": <TAB>  <TAB>  <TAB> for _ in range(amount): <TAB>  <TAB>  <TAB>  <TAB> retval += random.choice(junk_chars) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> retval += char <TAB> return retval","elif char == ""<"" :",200
3573,"def test_parse(self): <TAB> correct = 0 <TAB> for example in EXAMPLES: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> schema.parse(example.schema_string) <TAB>  <TAB>  <TAB> if example.valid: <TAB>  <TAB>  <TAB>  <TAB> correct += 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.fail(""Invalid schema was parsed: "" + example.schema_string) <TAB>  <TAB> except: <MASK> correct += 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.fail(""Valid schema failed to parse: "" + example.schema_string) <TAB> fail_msg = ""Parse behavior correct on %d out of %d schemas."" % ( <TAB>  <TAB> correct, <TAB>  <TAB> len(EXAMPLES), <TAB> ) <TAB> self.assertEqual(correct, len(EXAMPLES), fail_msg)",if not example . valid :,188
3574,"def _on_change(self): <TAB> changed = False <TAB> self.save() <TAB> for key, value in self.data.items(): <MASK> if value: <TAB>  <TAB>  <TAB>  <TAB> changed = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if isinstance(value, int): <TAB>  <TAB>  <TAB> if value != 1: <TAB>  <TAB>  <TAB>  <TAB> changed = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif value is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif len(value) != 0: <TAB>  <TAB>  <TAB> changed = True <TAB>  <TAB>  <TAB> break <TAB> self._reset_button.disabled = not changed","if isinstance ( value , bool ) :",145
3575,"def normalize(d: Dict[Any, Any]) -> Dict[str, Any]: <TAB> first_exception = None <TAB> for normalizer in normalizers: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> normalized = normalizer(d) <TAB>  <TAB> except KeyError as e: <MASK> first_exception = e <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return normalized <TAB> assert first_exception is not None <TAB> raise first_exception",if not first_exception :,103
3576,"def gather_callback_args(self, obj, callbacks): <TAB> session = sa.orm.object_session(obj) <TAB> for callback in callbacks: <TAB>  <TAB> backref = callback.backref <TAB>  <TAB> root_objs = getdotattr(obj, backref) if backref else obj <TAB>  <TAB> if root_objs: <TAB>  <TAB>  <TAB> if not isinstance(root_objs, Iterable): <TAB>  <TAB>  <TAB>  <TAB> root_objs = [root_objs] <TAB>  <TAB>  <TAB> with session.no_autoflush: <TAB>  <TAB>  <TAB>  <TAB> for root_obj in root_objs: <MASK> args = self.get_callback_args(root_obj, callback) <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if args: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield args",if root_obj :,182
3577,"def test_opdm_to_oqdm(self): <TAB> for file in filter(lambda x: x.endswith("".hdf5""), os.listdir(DATA_DIRECTORY)): <TAB>  <TAB> molecule = MolecularData(filename=os.path.join(DATA_DIRECTORY, file)) <MASK> test_oqdm = map_one_pdm_to_one_hole_dm(molecule.fci_one_rdm) <TAB>  <TAB>  <TAB> true_oqdm = numpy.eye(molecule.n_qubits) - molecule.fci_one_rdm <TAB>  <TAB>  <TAB> assert numpy.allclose(test_oqdm, true_oqdm)",if molecule . fci_one_rdm is not None :,171
3578,"def emitSubDomainData(self, subDomainData, event): <TAB> self.emitRawRirData(subDomainData, event) <TAB> for subDomainElem in subDomainData: <TAB>  <TAB> if self.checkForStop(): <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> subDomain = subDomainElem.get(""subdomain"", """").strip() <MASK> self.emitHostname(subDomain, event)",if subDomain :,99
3579,"def download_cve( <TAB> download_path: str, years: Optional[List[int]] = None, update: bool = False): <TAB> if update: <TAB>  <TAB> process_url(CVE_URL.format(""modified""), download_path) <TAB> else: <TAB>  <TAB> all_cve_urls = get_cve_links(CVE_URL, years) <MASK> raise CveLookupException(""Error: No CVE links found"") <TAB>  <TAB> for url in all_cve_urls: <TAB>  <TAB>  <TAB> process_url(url, download_path)",if not all_cve_urls :,142
3580,"def is_special(s, i, directive): <TAB> """"""Return True if the body text contains the @ directive."""""" <TAB> # j = skip_line(s,i) ; trace(s[i:j],':',directive) <TAB> assert directive and directive[0] == ""@"" <TAB> # 10/23/02: all directives except @others must start the line. <TAB> skip_flag = directive in (""@others"", ""@all"") <TAB> while i < len(s): <TAB>  <TAB> if match_word(s, i, directive): <TAB>  <TAB>  <TAB> return True, i <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> i = skip_line(s, i) <MASK> i = skip_ws(s, i) <TAB> return False, -1",if skip_flag :,178
3581,"def run_async(self, nuke_cursors): <TAB> # type: (bool) -> None <TAB> interface_type = self.view.settings().get(""git_savvy.interface"") <TAB> for cls in subclasses: <TAB>  <TAB> if cls.interface_type == interface_type: <TAB>  <TAB>  <TAB> vid = self.view.id() <TAB>  <TAB>  <TAB> interface = interfaces.get(vid, None) <MASK> interface = interfaces[vid] = cls(view=self.view) <TAB>  <TAB>  <TAB> interface.render(nuke_cursors=nuke_cursors)  # type: ignore[union-attr] <TAB>  <TAB>  <TAB> break",if not interface :,155
3582,"def scan_resource_conf(self, conf): <TAB> if ""properties"" in conf: <MASK> if str(conf[""properties""][""sslEnforcement""]).lower() == ""enabled"": <TAB>  <TAB>  <TAB>  <TAB> return CheckResult.PASSED <TAB> return CheckResult.FAILED","if ""sslEnforcement"" in conf [ ""properties"" ] :",77
3583,"def do_shorts( <TAB> opts: List[Tuple[str, str]], optstring: str, shortopts: str, args: List[str]) -> Tuple[List[Tuple[str, str]], List[str]]: <TAB> while optstring != """": <TAB>  <TAB> opt, optstring = optstring[0], optstring[1:] <TAB>  <TAB> if short_has_arg(opt, shortopts): <TAB>  <TAB>  <TAB> if optstring == """": <MASK> raise GetoptError(""option -%s requires argument"" % opt, opt) <TAB>  <TAB>  <TAB>  <TAB> optstring, args = args[0], args[1:] <TAB>  <TAB>  <TAB> optarg, optstring = optstring, """" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> optarg = """" <TAB>  <TAB> opts.append((""-"" + opt, optarg)) <TAB> return opts, args",if not args :,183
3584,"def release(self): <TAB> tid = _thread.get_ident() <TAB> with self.lock: <MASK> raise RuntimeError(""cannot release un-acquired lock"") <TAB>  <TAB> assert self.count > 0 <TAB>  <TAB> self.count -= 1 <TAB>  <TAB> if self.count == 0: <TAB>  <TAB>  <TAB> self.owner = None <TAB>  <TAB>  <TAB> if self.waiters: <TAB>  <TAB>  <TAB>  <TAB> self.waiters -= 1 <TAB>  <TAB>  <TAB>  <TAB> self.wakeup.release()",if self . owner != tid :,117
3585,"def _summarize_kraken(fn): <TAB> """"""get the value at species level"""""" <TAB> kraken = {} <TAB> list_sp, list_value = [], [] <TAB> with open(fn) as handle: <TAB>  <TAB> for line in handle: <TAB>  <TAB>  <TAB> cols = line.strip().split(""\t"") <TAB>  <TAB>  <TAB> sp = cols[5].strip() <MASK> list_sp.append(sp) <TAB>  <TAB>  <TAB>  <TAB> list_value.append(cols[0]) <TAB> kraken = {""kraken_sp"": list_sp, ""kraken_value"": list_value} <TAB> return kraken","if len ( sp . split ( "" "" ) ) > 1 and not sp . startswith ( ""cellular"" ) :",159
3586,"def _sync_remote_run(remote_run): <TAB> assert remote_run.remote <TAB> remote_name = remote_run.remote.name <TAB> pull_args = click_util.Args(remote=remote_name, delete=False) <TAB> try: <TAB>  <TAB> remote_impl_support.pull_runs([remote_run], pull_args) <TAB> except Exception as e: <MASK> log.exception(""pull %s from %s"", remote_run.id, remote_name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.error(""error pulling %s from %s: %s"", remote_run.id, remote_name, e)",if log . getEffectiveLevel ( ) <= logging . DEBUG :,163
3587,"def group_by_sign(seq, slop=sin(pi / 18), key=lambda x: x): <TAB> sign = None <TAB> subseq = [] <TAB> for i in seq: <TAB>  <TAB> ki = key(i) <MASK> subseq.append(i) <TAB>  <TAB>  <TAB> if ki != 0: <TAB>  <TAB>  <TAB>  <TAB> sign = ki / abs(ki) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> subseq.append(i) <TAB>  <TAB>  <TAB> if sign * ki < -slop: <TAB>  <TAB>  <TAB>  <TAB> sign = ki / abs(ki) <TAB>  <TAB>  <TAB>  <TAB> yield subseq <TAB>  <TAB>  <TAB>  <TAB> subseq = [i] <TAB> if subseq: <TAB>  <TAB> yield subseq",if sign is None :,167
3588,"def import_til(self): <TAB> log(""Importing type libraries..."") <TAB> cur = self.db_cursor() <TAB> sql = ""select name from diff.program_data where type = 'til'"" <TAB> cur.execute(sql) <TAB> for row in cur.fetchall(): <TAB>  <TAB> til = row[""name""] <MASK> til = til.decode(""utf-8"") <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> add_default_til(til) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> log(""Error loading til %s: %s"" % (row[""name""], str(sys.exc_info()[1]))) <TAB> cur.close() <TAB> auto_wait()",if type ( til ) is bytes :,168
3589,"def getBranches(self): <TAB> returned = [] <TAB> for git_branch_line in self._executeGitCommandAssertSuccess(""branch"").stdout: <MASK> git_branch_line = git_branch_line[1:] <TAB>  <TAB> git_branch_line = git_branch_line.strip() <TAB>  <TAB> if BRANCH_ALIAS_MARKER in git_branch_line: <TAB>  <TAB>  <TAB> alias_name, aliased = git_branch_line.split(BRANCH_ALIAS_MARKER) <TAB>  <TAB>  <TAB> returned.append(branch.LocalBranchAlias(self, alias_name, aliased)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> returned.append(branch.LocalBranch(self, git_branch_line)) <TAB> return returned","if git_branch_line . startswith ( ""*"" ) :",178
3590,"def add_include_dirs(self, args): <TAB> ids = [] <TAB> for a in args: <TAB>  <TAB> # FIXME same hack, forcibly unpack from holder. <MASK> a = a.includedirs <TAB>  <TAB> if not isinstance(a, IncludeDirs): <TAB>  <TAB>  <TAB> raise InvalidArguments( <TAB>  <TAB>  <TAB>  <TAB> ""Include directory to be added is not an include directory object."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ids.append(a) <TAB> self.include_dirs += ids","if hasattr ( a , ""includedirs"" ) :",120
3591,"def _serialize_feature(self, feature): <TAB> name = feature.unique_name() <MASK> self._features_dict[feature.unique_name()] = feature.to_dictionary() <TAB>  <TAB> for dependency in feature.get_dependencies(deep=True): <TAB>  <TAB>  <TAB> name = dependency.unique_name() <TAB>  <TAB>  <TAB> if name not in self._features_dict: <TAB>  <TAB>  <TAB>  <TAB> self._features_dict[name] = dependency.to_dictionary()",if name not in self . _features_dict :,117
3592,"def generate_io(chart_type, race_configs, environment): <TAB> # output JSON structures <TAB> structures = [] <TAB> for race_config in race_configs: <MASK> title = chart_type.format_title( <TAB>  <TAB>  <TAB>  <TAB> environment, <TAB>  <TAB>  <TAB>  <TAB> race_config.track, <TAB>  <TAB>  <TAB>  <TAB> es_license=race_config.es_license, <TAB>  <TAB>  <TAB>  <TAB> suffix=""%s-io"" % race_config.label, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> structures.append(chart_type.io(title, environment, race_config)) <TAB> return structures","if ""io"" in race_config . charts :",150
3593,"def format_partition(partition, partition_schema): <TAB> tokens = [] <TAB> if isinstance(partition, dict): <TAB>  <TAB> for name in partition_schema: <MASK> tok = _format_partition_kv( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> name, partition[name], partition_schema[name] <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> # dynamic partitioning <TAB>  <TAB>  <TAB>  <TAB> tok = name <TAB>  <TAB>  <TAB> tokens.append(tok) <TAB> else: <TAB>  <TAB> for name, value in zip(partition_schema, partition): <TAB>  <TAB>  <TAB> tok = _format_partition_kv(name, value, partition_schema[name]) <TAB>  <TAB>  <TAB> tokens.append(tok) <TAB> return ""PARTITION ({})"".format("", "".join(tokens))",if name in partition :,183
3594,"def to_dict(self, validate=True, ignore=(), context=None): <TAB> context = context or {} <TAB> condition = getattr(self, ""condition"", Undefined) <TAB> copy = self  # don't copy unless we need to <TAB> if condition is not Undefined: <TAB>  <TAB> if isinstance(condition, core.SchemaBase): <TAB>  <TAB>  <TAB> pass <MASK> kwds = parse_shorthand(condition[""field""], context.get(""data"", None)) <TAB>  <TAB>  <TAB> copy = self.copy(deep=[""condition""]) <TAB>  <TAB>  <TAB> copy.condition.update(kwds) <TAB> return super(ValueChannelMixin, copy).to_dict( <TAB>  <TAB> validate=validate, ignore=ignore, context=context <TAB> )","elif ""field"" in condition and ""type"" not in condition :",175
3595,"def _checkForCommand(self): <TAB> prompt = b""cftp> "" <TAB> if self._expectingCommand and self._lineBuffer == prompt: <TAB>  <TAB> buf = b""\n"".join(self._linesReceived) <MASK> buf = buf[len(prompt) :] <TAB>  <TAB> self.clearBuffer() <TAB>  <TAB> d, self._expectingCommand = self._expectingCommand, None <TAB>  <TAB> d.callback(buf)",if buf . startswith ( prompt ) :,109
3596,"def schedule_logger(job_id=None, delete=False): <TAB> if not job_id: <TAB>  <TAB> return getLogger(""fate_flow_schedule"") <TAB> else: <TAB>  <TAB> if delete: <TAB>  <TAB>  <TAB> with LoggerFactory.lock: <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for key in LoggerFactory.schedule_logger_dict.keys(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if job_id in key: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> del LoggerFactory.schedule_logger_dict[key] <TAB>  <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> key = job_id + ""schedule"" <MASK> return LoggerFactory.schedule_logger_dict[key] <TAB>  <TAB> return LoggerFactory.get_schedule_logger(job_id)",if key in LoggerFactory . schedule_logger_dict :,198
3597,"def halfMultipartScore(nzb_name): <TAB> try: <TAB>  <TAB> wrong_found = 0 <TAB>  <TAB> for nr in [1, 2, 3, 4, 5, ""i"", ""ii"", ""iii"", ""iv"", ""v"", ""a"", ""b"", ""c"", ""d"", ""e""]: <TAB>  <TAB>  <TAB> for wrong in [""cd"", ""part"", ""dis"", ""disc"", ""dvd""]: <TAB>  <TAB>  <TAB>  <TAB> if ""%s%s"" % (wrong, nr) in nzb_name.lower(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> wrong_found += 1 <MASK> return -30 <TAB>  <TAB> return 0 <TAB> except: <TAB>  <TAB> log.error(""Failed doing halfMultipartScore: %s"", traceback.format_exc()) <TAB> return 0",if wrong_found == 1 :,183
3598,"def parse_converter_args(argstr: str) -> t.Tuple[t.Tuple, t.Dict[str, t.Any]]: <TAB> argstr += "","" <TAB> args = [] <TAB> kwargs = {} <TAB> for item in _converter_args_re.finditer(argstr): <TAB>  <TAB> value = item.group(""stringval"") <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB> value = item.group(""value"") <TAB>  <TAB> value = _pythonize(value) <MASK> args.append(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = item.group(""name"") <TAB>  <TAB>  <TAB> kwargs[name] = value <TAB> return tuple(args), kwargs","if not item . group ( ""name"" ) :",164
3599,"def leaves(self, unique=True): <TAB> """"""Get the leaves of the tree starting at this root."""""" <TAB> if not self.children: <TAB>  <TAB> return [self] <TAB> else: <TAB>  <TAB> res = list() <TAB>  <TAB> for child in self.children: <TAB>  <TAB>  <TAB> for sub_child in child.leaves(unique=unique): <MASK> res.append(sub_child) <TAB>  <TAB> return res",if not unique or sub_child not in res :,112
3600,"def to_tree(self, tagname=None, idx=None, namespace=None): <TAB> axIds = set((ax.axId for ax in self._axes)) <TAB> for chart in self._charts: <TAB>  <TAB> for id, axis in chart._axes.items(): <MASK> setattr(self, axis.tagname, axis) <TAB>  <TAB>  <TAB>  <TAB> axIds.add(id) <TAB> return super(PlotArea, self).to_tree(tagname)",if id not in axIds :,116
3601,"def update_neighbor(neigh_ip_address, changes): <TAB> rets = [] <TAB> for k, v in changes.items(): <TAB>  <TAB> if k == neighbors.MULTI_EXIT_DISC: <TAB>  <TAB>  <TAB> rets.append(_update_med(neigh_ip_address, v)) <TAB>  <TAB> if k == neighbors.ENABLED: <TAB>  <TAB>  <TAB> rets.append(update_neighbor_enabled(neigh_ip_address, v)) <MASK> rets.append(_update_connect_mode(neigh_ip_address, v)) <TAB> return all(rets)",if k == neighbors . CONNECT_MODE :,138
3602,"def close_all_connections(): <TAB> global _managers, _lock, _in_use, _timer <TAB> _lock.acquire() <TAB> try: <MASK> _timer.cancel() <TAB>  <TAB>  <TAB> _timer = None <TAB>  <TAB> for domain, managers in _managers.items(): <TAB>  <TAB>  <TAB> for manager in managers: <TAB>  <TAB>  <TAB>  <TAB> manager.close() <TAB>  <TAB> _managers = {} <TAB> finally: <TAB>  <TAB> _lock.release()",if _timer :,109
3603,"def _instrument_model(self, model): <TAB> for key, value in list( <TAB>  <TAB> model.__dict__.items() <TAB> ):  # avoid ""dictionary keys changed during iteration"" <TAB>  <TAB> if isinstance(value, tf.keras.layers.Layer): <TAB>  <TAB>  <TAB> new_layer = self._instrument(value) <TAB>  <TAB>  <TAB> if new_layer is not value: <TAB>  <TAB>  <TAB>  <TAB> setattr(model, key, new_layer) <TAB>  <TAB> elif isinstance(value, list): <TAB>  <TAB>  <TAB> for i, item in enumerate(value): <MASK> value[i] = self._instrument(item) <TAB> return model","if isinstance ( item , tf . keras . layers . Layer ) :",164
3604,"def target_glob(tgt, hosts): <TAB> ret = {} <TAB> for host in hosts: <TAB>  <TAB> if fnmatch.fnmatch(tgt, host): <TAB>  <TAB>  <TAB> ret[host] = copy.deepcopy(__opts__.get(""roster_defaults"", {})) <TAB>  <TAB>  <TAB> ret[host].update({""host"": host}) <MASK> ret[host].update({""user"": __opts__[""ssh_user""]}) <TAB> return ret","if __opts__ . get ( ""ssh_user"" ) :",110
3605,"def write(self, data): <TAB> if mock_target._mirror_on_stderr: <TAB>  <TAB> if self._write_line: <TAB>  <TAB>  <TAB> sys.stderr.write(fn + "": "") <MASK> sys.stderr.write(data.decode(""utf8"")) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sys.stderr.write(data) <TAB>  <TAB> if (data[-1]) == ""\n"": <TAB>  <TAB>  <TAB> self._write_line = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._write_line = False <TAB> super(Buffer, self).write(data)",if bytes :,137
3606,"def task_thread(): <TAB> while not task_queue.empty(): <TAB>  <TAB> host, port, username, password = task_queue.get() <TAB>  <TAB> logger.info( <TAB>  <TAB>  <TAB> ""try burst {}:{} use username:{} password:{}"".format( <TAB>  <TAB>  <TAB>  <TAB> host, port, username, password <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <MASK> with task_queue.mutex: <TAB>  <TAB>  <TAB>  <TAB> task_queue.queue.clear() <TAB>  <TAB>  <TAB> result_queue.put((username, password))","if telnet_login ( host , port , username , password ) :",135
3607,"def _format_results(name, ppl, scores, metrics): <TAB> """"""Format results."""""" <TAB> result_str = """" <TAB> if ppl: <TAB>  <TAB> result_str = ""%s ppl %.2f"" % (name, ppl) <TAB> if scores: <TAB>  <TAB> for metric in metrics: <MASK> result_str += "", %s %s %.1f"" % (name, metric, scores[metric]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> result_str = ""%s %s %.1f"" % (name, metric, scores[metric]) <TAB> return result_str",if result_str :,142
3608,"def info_query(self, query): <TAB> """"""Send a query which only returns 1 row"""""" <TAB> self._cmysql.query(query) <TAB> first_row = () <TAB> if self._cmysql.have_result_set: <TAB>  <TAB> first_row = self._cmysql.fetch_row() <MASK> self._cmysql.free_result() <TAB>  <TAB>  <TAB> raise errors.InterfaceError(""Query should not return more than 1 row"") <TAB> self._cmysql.free_result() <TAB> return first_row",if self . _cmysql . fetch_row ( ) :,131
3609,"def reset_class(self): <TAB> for f in self.fields_order: <MASK> f.value = int(f.strbits, 2) <TAB>  <TAB> elif ""default_val"" in f.kargs: <TAB>  <TAB>  <TAB> f.value = int(f.kargs[""default_val""], 2) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> f.value = None <TAB>  <TAB> if f.fname: <TAB>  <TAB>  <TAB> setattr(self, f.fname, f)",if f . strbits and isbin ( f . strbits ) :,123
3610,"def _walk_map_list(self, access_func): <TAB> seen = [] <TAB> cur = self <TAB> while cur: <MASK> break <TAB>  <TAB> yield cur <TAB>  <TAB> seen.append(cur.obj_offset) <TAB>  <TAB> # check for signs of infinite looping <TAB>  <TAB> if len(seen) > 1024: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> cur = access_func(cur)",if cur . obj_offset in seen :,102
3611,def bgdel(): <TAB> q = bgdelq <TAB> while True: <TAB>  <TAB> name = q.get() <TAB>  <TAB> while os.path.exists(name): <TAB>  <TAB>  <TAB> try: <MASK> os.remove(name) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> shutil.rmtree(name) <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> if os.path.exists(name): <TAB>  <TAB>  <TAB>  <TAB> time.sleep(0.1),if os . path . isfile ( name ) :,127
3612,"def _find_all_variables(transfer_variable): <TAB> d = {} <TAB> for _k, _v in transfer_variable.__dict__.items(): <TAB>  <TAB> if isinstance(_v, Variable): <TAB>  <TAB>  <TAB> d[_v._name] = _v <MASK> d.update(_find_all_variables(_v)) <TAB> return d","elif isinstance ( _v , BaseTransferVariables ) :",91
3613,"def set_val(): <TAB> idx = 0 <TAB> for idx in range(0, len(model)): <TAB>  <TAB> row = model[idx] <MASK> break <TAB>  <TAB> if idx == len(os_widget.get_model()) - 1: <TAB>  <TAB>  <TAB> idx = -1 <TAB> os_widget.set_active(idx) <TAB> if idx == -1: <TAB>  <TAB> os_widget.set_active(0) <TAB> if idx >= 0: <TAB>  <TAB> return row[1] <TAB> if self.show_all_os: <TAB>  <TAB> return None",if value and row [ 0 ] == value :,142
3614,"def _make_cache_key(group, window, rate, value, methods): <TAB> count, period = _split_rate(rate) <TAB> safe_rate = ""%d/%ds"" % (count, period) <TAB> parts = [group, safe_rate, value, str(window)] <TAB> if methods is not None: <TAB>  <TAB> if methods == ALL: <TAB>  <TAB>  <TAB> methods = """" <MASK> methods = """".join(sorted([m.upper() for m in methods])) <TAB>  <TAB> parts.append(methods) <TAB> prefix = getattr(settings, ""RATELIMIT_CACHE_PREFIX"", ""rl:"") <TAB> return prefix + hashlib.md5(u"""".join(parts).encode(""utf-8"")).hexdigest()","elif isinstance ( methods , ( list , tuple ) ) :",175
3615,"def findfiles(path): <TAB> files = [] <TAB> for name in os.listdir(path): <TAB>  <TAB> # ignore hidden files/dirs and other unwanted files <MASK> continue <TAB>  <TAB> pathname = os.path.join(path, name) <TAB>  <TAB> st = os.lstat(pathname) <TAB>  <TAB> mode = st.st_mode <TAB>  <TAB> if stat.S_ISDIR(mode): <TAB>  <TAB>  <TAB> files.extend(findfiles(pathname)) <TAB>  <TAB> elif stat.S_ISREG(mode): <TAB>  <TAB>  <TAB> files.append((pathname, name, st)) <TAB> return files","if name . startswith ( ""."" ) or name == ""lastsnap.jpg"" :",150
3616,"def __getitem__(self, key): <TAB> if isinstance(key, str_types): <TAB>  <TAB> keys = self.get_keys() <MASK> raise KeyError(' ""{0}"" is an invalid key'.format(key)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self[keys.index(key)] <TAB> else: <TAB>  <TAB> return list.__getitem__(self, key)",if key not in keys :,93
3617,"def test_assert_set_equal(estimate: tp.Iterable[int], message: str) -> None: <TAB> reference = {1, 2, 3} <TAB> try: <TAB>  <TAB> testing.assert_set_equal(estimate, reference) <TAB> except AssertionError as error: <TAB>  <TAB> if not message: <TAB>  <TAB>  <TAB> raise AssertionError( <TAB>  <TAB>  <TAB>  <TAB> ""An error has been raised while it should not."" <TAB>  <TAB>  <TAB> ) from error <TAB>  <TAB> np.testing.assert_equal(error.args[0].split(""\n"")[1:], message) <TAB> else: <MASK> raise AssertionError(""An error should have been raised."")",if message :,148
3618,"def get_directory_info(prefix, pth, recursive): <TAB> res = [] <TAB> directory = os.listdir(pth) <TAB> directory.sort() <TAB> for p in directory: <MASK> subp = os.path.join(pth, p) <TAB>  <TAB>  <TAB> p = os.path.join(prefix, p) <TAB>  <TAB>  <TAB> if recursive and os.path.isdir(subp): <TAB>  <TAB>  <TAB>  <TAB> res.append([p, get_directory_info(prefix, subp, 1)]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> res.append([p, None]) <TAB> return res","if p [ 0 ] != ""."" :",148
3619,"def check(self, runner, script, info): <TAB> if isinstance(info, ast.FunctionDef): <TAB>  <TAB> for arg in info.args.args: <MASK> if arg.id in script.modelVars: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.problem( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Function {0} may shadow model variable {1}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> info.name, arg.id <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> lineno=info.lineno, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> )","if isinstance ( arg , ast . Name ) :",137
3620,"def db_lookup(field, key, publish_year=None): <TAB> sql = ""select sum(ebook_count) as num from subjects where field=$field and key=$key"" <TAB> if publish_year: <MASK> sql += "" and publish_year between $y1 and $y2"" <TAB>  <TAB>  <TAB> (y1, y2) = publish_year <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sql += "" and publish_year=$publish_year"" <TAB> return list(ebook_count_db.query(sql, vars=locals()))[0].num","if isinstance ( publish_year , ( tuple , list ) ) :",141
3621,"def put(self, session): <TAB> with sess_lock: <TAB>  <TAB> self.parent.put(session) <TAB>  <TAB> # Do not store the session if skip paths <TAB>  <TAB> for sp in self.skip_paths: <MASK> return <TAB>  <TAB> if session.sid in self._cache: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> del self._cache[session.sid] <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> self._cache[session.sid] = session <TAB> self._normalize()",if request . path . startswith ( sp ) :,133
3622,"def summarize(self): <TAB> if self.bad_commit and self.good_commit: <TAB>  <TAB> for subresult in self.subresults.values(): <TAB>  <TAB>  <TAB> sub = subresult.summarize() <MASK> return sub <TAB>  <TAB> return ""Detected bad commit in {} repository:\n{} {}"".format( <TAB>  <TAB>  <TAB> self.repo_name, self.bad_commit, get_message(self.suite, self.bad_commit) <TAB>  <TAB> ) <TAB> return """"",if sub :,115
3623,def compute_nullable_nonterminals(self): <TAB> nullable = {} <TAB> num_nullable = 0 <TAB> while 1: <TAB>  <TAB> for p in self.grammar.Productions[1:]: <TAB>  <TAB>  <TAB> if p.len == 0: <TAB>  <TAB>  <TAB>  <TAB> nullable[p.name] = 1 <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> for t in p.prod: <TAB>  <TAB>  <TAB>  <TAB> if not t in nullable: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> nullable[p.name] = 1 <MASK> break <TAB>  <TAB> num_nullable = len(nullable) <TAB> return nullable,if len ( nullable ) == num_nullable :,153
3624,"def _cast_float64_to_float32(self, feeds): <TAB> for input_name, input_type in self.inputs: <MASK> feed = feeds.get(input_name) <TAB>  <TAB>  <TAB> if feed is not None and feed.dtype == np.float64: <TAB>  <TAB>  <TAB>  <TAB> feeds[input_name] = feed.astype(np.float32) <TAB> return feeds","if input_type == ""tensor(float)"" :",103
3625,"def proc_minute(d): <TAB> if expanded[0][0] != ""*"": <TAB>  <TAB> diff_min = nearest_diff_method(d.minute, expanded[0], 60) <MASK> if is_prev: <TAB>  <TAB>  <TAB>  <TAB> d += relativedelta(minutes=diff_min, second=59) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> d += relativedelta(minutes=diff_min, second=0) <TAB>  <TAB>  <TAB> return True, d <TAB> return False, d",if diff_min is not None and diff_min != 0 :,128
3626,"def detype(self): <TAB> if self._detyped is not None: <TAB>  <TAB> return self._detyped <TAB> ctx = {} <TAB> for key, val in self._d.items(): <TAB>  <TAB> if not isinstance(key, str): <TAB>  <TAB>  <TAB> key = str(key) <TAB>  <TAB> detyper = self.get_detyper(key) <TAB>  <TAB> if detyper is None: <TAB>  <TAB>  <TAB> # cannot be detyped <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> deval = detyper(val) <MASK> # cannot be detyped <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> ctx[key] = deval <TAB> self._detyped = ctx <TAB> return ctx",if deval is None :,163
3627,"def get_or_create_user(request, user_data): <TAB> try: <TAB>  <TAB> user = User.objects.get(sso_id=user_data[""id""]) <MASK> update_user(user, user_data) <TAB>  <TAB> return user <TAB> except User.DoesNotExist: <TAB>  <TAB> user = User.objects.create_user( <TAB>  <TAB>  <TAB> user_data[""username""], <TAB>  <TAB>  <TAB> user_data[""email""], <TAB>  <TAB>  <TAB> is_active=user_data.get(""is_active"", True), <TAB>  <TAB>  <TAB> sso_id=user_data[""id""], <TAB>  <TAB> ) <TAB>  <TAB> user.update_acl_key() <TAB>  <TAB> setup_new_user(request.settings, user) <TAB>  <TAB> return user","if user_needs_updating ( user , user_data ) :",185
3628,"def _populate_tree(self, element, d): <TAB> """"""Populates an etree with attributes & elements, given a dict."""""" <TAB> for k, v in d.iteritems(): <TAB>  <TAB> if isinstance(v, dict): <TAB>  <TAB>  <TAB> self._populate_dict(element, k, v) <TAB>  <TAB> elif isinstance(v, list): <TAB>  <TAB>  <TAB> self._populate_list(element, k, v) <MASK> self._populate_bool(element, k, v) <TAB>  <TAB> elif isinstance(v, basestring): <TAB>  <TAB>  <TAB> self._populate_str(element, k, v) <TAB>  <TAB> elif type(v) in [int, float, long, complex]: <TAB>  <TAB>  <TAB> self._populate_number(element, k, v)","elif isinstance ( v , bool ) :",178
3629,"def load(cls): <TAB> if not cls._loaded: <TAB>  <TAB> cls.log.debug(""Loading action_sets..."") <MASK> cls._find_action_sets(PATHS.ACTION_SETS_DIRECTORY) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> cls.action_sets = JsonDecoder.load(PATHS.ACTION_SETS_JSON_FILE) <TAB>  <TAB> cls.log.debug(""Done!"") <TAB>  <TAB> cls._loaded = True",if not horizons . globals . fife . use_atlases :,118
3630,"def Resolve(self, updater=None): <TAB> if len(self.Conflicts): <TAB>  <TAB> for setting, edge in self.Conflicts: <TAB>  <TAB>  <TAB> answer = self.AskUser(self.Setting, setting) <MASK> value = setting.Value.split(""|"") <TAB>  <TAB>  <TAB>  <TAB> value.remove(edge) <TAB>  <TAB>  <TAB>  <TAB> setting.Value = ""|"".join(value) <TAB>  <TAB>  <TAB>  <TAB> if updater: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> updater.UpdateSetting(setting) <TAB>  <TAB>  <TAB> if answer == Gtk.ResponseType.NO: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return True",if answer == Gtk . ResponseType . YES :,146
3631,"def read_tsv(input_file, quotechar=None): <TAB> """"""Reads a tab separated value file."""""" <TAB> with open(input_file, ""r"", encoding=""utf-8-sig"") as f: <TAB>  <TAB> reader = csv.reader(f, delimiter=""\t"", quotechar=quotechar) <TAB>  <TAB> lines = [] <TAB>  <TAB> for line in reader: <MASK> line = list(str(cell, ""utf-8"") for cell in line)  # noqa: F821 <TAB>  <TAB>  <TAB> lines.append(line) <TAB>  <TAB> return lines",if sys . version_info [ 0 ] == 2 :,140
3632,"def devd_devfs_hook(middleware, data): <TAB> if data.get(""subsystem"") != ""CDEV"": <TAB>  <TAB> return <TAB> if data[""type""] == ""CREATE"": <TAB>  <TAB> disks = await middleware.run_in_thread( <TAB>  <TAB>  <TAB> lambda: sysctl.filter(""kern.disks"")[0].value.split() <TAB>  <TAB> ) <TAB>  <TAB> # Device notified about is not a disk <TAB>  <TAB> if data[""cdev""] not in disks: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> await added_disk(middleware, data[""cdev""]) <TAB> elif data[""type""] == ""DESTROY"": <TAB>  <TAB> # Device notified about is not a disk <MASK> return <TAB>  <TAB> await remove_disk(middleware, data[""cdev""])","if not RE_ISDISK . match ( data [ ""cdev"" ] ) :",190
3633,"def on_edit_button_clicked(self, event=None, a=None, col=None): <TAB> tree, tree_id = self.treeView.get_selection().get_selected() <TAB> watchdir_id = str(self.store.get_value(tree_id, 0)) <TAB> if watchdir_id: <MASK> if self.watchdirs[watchdir_id][""enabled""]: <TAB>  <TAB>  <TAB>  <TAB> client.autoadd.disable_watchdir(watchdir_id) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> client.autoadd.enable_watchdir(watchdir_id) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.opts_dialog.show(self.watchdirs[watchdir_id], watchdir_id)","if col and col . get_title ( ) == _ ( ""Active"" ) :",187
3634,"def _execute(self, options, args): <TAB> if len(args) < 1: <TAB>  <TAB> raise CommandError(_(""Not enough arguments"")) <TAB> paths = args <TAB> songs = [self.load_song(p) for p in paths] <TAB> for song in songs: <MASK> raise CommandError( <TAB>  <TAB>  <TAB>  <TAB> _(""Image editing not supported for %(file_name)s "" ""(%(file_format)s)"") <TAB>  <TAB>  <TAB>  <TAB> % {""file_name"": song(""~filename""), ""file_format"": song(""~format"")} <TAB>  <TAB>  <TAB> ) <TAB> for song in songs: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> song.clear_images() <TAB>  <TAB> except AudioFileError as e: <TAB>  <TAB>  <TAB> raise CommandError(e)",if not song . can_change_images :,176
3635,"def filter_pricing_rule_based_on_condition(pricing_rules, doc=None): <TAB> filtered_pricing_rules = [] <TAB> if doc: <TAB>  <TAB> for pricing_rule in pricing_rules: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if frappe.safe_eval(pricing_rule.condition, None, doc.as_dict()): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> filtered_pricing_rules.append(pricing_rule) <TAB>  <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> filtered_pricing_rules.append(pricing_rule) <TAB> else: <TAB>  <TAB> filtered_pricing_rules = pricing_rules <TAB> return filtered_pricing_rules",if pricing_rule . condition :,179
3636,"def ProcessStringLiteral(self): <TAB> if self._lastToken == None or self._lastToken.type == self.OpenBrace: <TAB>  <TAB> text = super(JavaScriptBaseLexer, self).text <TAB>  <TAB> if text == '""use strict""' or text == ""'use strict'"": <MASK> self._scopeStrictModes.pop() <TAB>  <TAB>  <TAB> self._useStrictCurrent = True <TAB>  <TAB>  <TAB> self._scopeStrictModes.append(self._useStrictCurrent)",if len ( self . _scopeStrictModes ) > 0 :,124
3637,"def _find_remote_inputs(metadata): <TAB> out = [] <TAB> for fr_key in metadata.keys(): <TAB>  <TAB> if isinstance(fr_key, (list, tuple)): <TAB>  <TAB>  <TAB> frs = fr_key <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> frs = [fr_key] <TAB>  <TAB> for fr in frs: <MASK> out.append(fr) <TAB> return out",if objectstore . is_remote ( fr ) :,107
3638,"def sub_paragraph(self, li): <TAB> """"""Search for checkbox in sub-paragraph."""""" <TAB> found = False <TAB> if len(li): <TAB>  <TAB> first = list(li)[0] <TAB>  <TAB> if first.tag == ""p"" and first.text is not None: <TAB>  <TAB>  <TAB> m = RE_CHECKBOX.match(first.text) <MASK> first.text = self.markdown.htmlStash.store( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> get_checkbox(m.group(""state"")), safe=True <TAB>  <TAB>  <TAB>  <TAB> ) + m.group(""line"") <TAB>  <TAB>  <TAB>  <TAB> found = True <TAB> return found",if m is not None :,152
3639,"def list_files(basedir): <TAB> """"""List files in the directory rooted at |basedir|."""""" <TAB> if not os.path.isdir(basedir): <TAB>  <TAB> raise NoSuchDirectory(basedir) <TAB> directories = [""""] <TAB> while directories: <TAB>  <TAB> d = directories.pop() <TAB>  <TAB> for basename in os.listdir(os.path.join(basedir, d)): <TAB>  <TAB>  <TAB> filename = os.path.join(d, basename) <MASK> directories.append(filename) <TAB>  <TAB>  <TAB> elif os.path.exists(os.path.join(basedir, filename)): <TAB>  <TAB>  <TAB>  <TAB> yield filename","if os . path . isdir ( os . path . join ( basedir , filename ) ) :",159
3640,"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_version(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,90
3641,"def _dump(self, fd): <TAB> with self.no_unpicklable_properties(): <MASK> d = pickle.dumps(self) <TAB>  <TAB>  <TAB> module_name = os.path.basename(sys.argv[0]).rsplit(""."", 1)[0] <TAB>  <TAB>  <TAB> d = d.replace(b""c__main__"", b""c"" + module_name.encode(""ascii"")) <TAB>  <TAB>  <TAB> fd.write(d) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pickle.dump(self, fd)","if self . __module__ == ""__main__"" :",128
3642,"def assert_session_stack(classes): <TAB> assert len(_SklearnTrainingSession._session_stack) == len(classes) <TAB> for idx, (sess, (parent_clazz, clazz)) in enumerate( <TAB>  <TAB> zip(_SklearnTrainingSession._session_stack, classes) <TAB> ): <TAB>  <TAB> assert sess.clazz == clazz <MASK> assert sess._parent is None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert sess._parent.clazz == parent_clazz",if idx == 0 :,118
3643,"def native_color(c): <TAB> try: <TAB>  <TAB> color = CACHE[c] <TAB> except KeyError: <MASK> c = NAMED_COLOR[c] <TAB>  <TAB> color = Color.FromArgb( <TAB>  <TAB>  <TAB> int(c.rgba.a * 255), int(c.rgba.r), int(c.rgba.g), int(c.rgba.b) <TAB>  <TAB> ) <TAB>  <TAB> CACHE[c] = color <TAB> return color","if isinstance ( c , str ) :",115
3644,"def callback(name): <TAB> # XXX: move into Action <TAB> for neighbor_name in reactor.configuration.neighbors.keys(): <TAB>  <TAB> neighbor = reactor.configuration.neighbors.get(neighbor_name, None) <MASK> continue <TAB>  <TAB> neighbor.rib.outgoing.announce_watchdog(name) <TAB>  <TAB> yield False <TAB> reactor.processes.answer_done(service)",if not neighbor :,97
3645,"def token_producer(source): <TAB> token = source.read_uint8() <TAB> while token is not None: <MASK> yield DataToken(read_data(token, source)) <TAB>  <TAB> elif is_small_integer(token): <TAB>  <TAB>  <TAB> yield SmallIntegerToken(read_small_integer(token)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield Token(token) <TAB>  <TAB> token = source.read_uint8()",if is_push_data_token ( token ) :,113
3646,"def setattr(self, req, ino, attr, to_set, fi): <TAB> print(""setattr:"", ino, to_set) <TAB> a = self.attr[ino] <TAB> for key in to_set: <MASK> # Keep the old file type bit fields <TAB>  <TAB>  <TAB> a[""st_mode""] = S_IFMT(a[""st_mode""]) | S_IMODE(attr[""st_mode""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> a[key] = attr[key] <TAB> self.attr[ino] = a <TAB> self.reply_attr(req, a, 1.0)","if key == ""st_mode"" :",149
3647,"def check_enum_exports(module, eq_callback, only=None): <TAB> """"""Make sure module exports all mnemonics from enums"""""" <TAB> for attr in enumerate_module(module, enum.Enum): <MASK> print(""SKIP"", attr) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> for flag, value in attr.__members__.items(): <TAB>  <TAB>  <TAB> print(module, flag, value) <TAB>  <TAB>  <TAB> eq_callback(getattr(module, flag), value)",if only is not None and attr not in only :,118
3648,"def remove_edit_vars_to(self, n): <TAB> try: <TAB>  <TAB> removals = [] <TAB>  <TAB> for v, cei in self.edit_var_map.items(): <MASK> removals.append(v) <TAB>  <TAB> for v in removals: <TAB>  <TAB>  <TAB> self.remove_edit_var(v) <TAB>  <TAB> assert len(self.edit_var_map) == n <TAB> except ConstraintNotFound: <TAB>  <TAB> raise InternalError(""Constraint not found during internal removal"")",if cei . index >= n :,129
3649,"def fix_repeating_arguments(self): <TAB> """"""Fix elements that should accumulate/increment values."""""" <TAB> either = [list(child.children) for child in transform(self).children] <TAB> for case in either: <TAB>  <TAB> for e in [child for child in case if case.count(child) > 1]: <TAB>  <TAB>  <TAB> if type(e) is Argument or type(e) is Option and e.argcount: <MASK> e.value = [] <TAB>  <TAB>  <TAB>  <TAB> elif type(e.value) is not list: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> e.value = e.value.split() <TAB>  <TAB>  <TAB> if type(e) is Command or type(e) is Option and e.argcount == 0: <TAB>  <TAB>  <TAB>  <TAB> e.value = 0 <TAB> return self",if e . value is None :,190
3650,"def add_I_prefix(current_line: List[str], ner: int, tag: str): <TAB> for i in range(0, len(current_line)): <TAB>  <TAB> if i == 0: <TAB>  <TAB>  <TAB> f.write(line_list[i]) <MASK> f.write("" I-"" + tag) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> f.write("" "" + current_line[i]) <TAB> f.write(""\n"")",elif i == ner :,111
3651,def select_word_at_cursor(self): <TAB> word_region = None <TAB> selection = self.view.sel() <TAB> for region in selection: <TAB>  <TAB> word_region = self.view.word(region) <MASK> selection.clear() <TAB>  <TAB>  <TAB> selection.add(word_region) <TAB>  <TAB>  <TAB> return word_region <TAB> return word_region,if not word_region . empty ( ) :,96
3652,"def calc(self, arg): <TAB> op = arg[""op""] <TAB> if op == ""C"": <TAB>  <TAB> self.clear() <TAB>  <TAB> return str(self.current) <TAB> num = decimal.Decimal(arg[""num""]) <TAB> if self.op: <TAB>  <TAB> if self.op == ""+"": <TAB>  <TAB>  <TAB> self.current += num <MASK> self.current -= num <TAB>  <TAB> elif self.op == ""*"": <TAB>  <TAB>  <TAB> self.current *= num <TAB>  <TAB> elif self.op == ""/"": <TAB>  <TAB>  <TAB> self.current /= num <TAB>  <TAB> self.op = op <TAB> else: <TAB>  <TAB> self.op = op <TAB>  <TAB> self.current = num <TAB> res = str(self.current) <TAB> if op == ""="": <TAB>  <TAB> self.clear() <TAB> return res","elif self . op == ""-"" :",187
3653,"def strip_pod(lines): <TAB> in_pod = False <TAB> stripped_lines = [] <TAB> for line in lines: <TAB>  <TAB> if re.match(r""^=(?:end|cut)"", line): <TAB>  <TAB>  <TAB> in_pod = False <TAB>  <TAB> elif re.match(r""^=\w+"", line): <TAB>  <TAB>  <TAB> in_pod = True <MASK> stripped_lines.append(line) <TAB> return stripped_lines",elif not in_pod :,108
3654,"def __init__(self, patch_files, patch_directories): <TAB> files = [] <TAB> files_data = {} <TAB> for filename_data in patch_files: <TAB>  <TAB> if isinstance(filename_data, list): <TAB>  <TAB>  <TAB> filename, data = filename_data <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> filename = filename_data <TAB>  <TAB>  <TAB> data = None <TAB>  <TAB> if not filename.startswith(os.sep): <TAB>  <TAB>  <TAB> filename = ""{0}{1}"".format(FakeState.deploy_dir, filename) <TAB>  <TAB> files.append(filename) <MASK> files_data[filename] = data <TAB> self.files = files <TAB> self.files_data = files_data <TAB> self.directories = patch_directories",if data :,171
3655,"def loadPerfsFromModule(self, module): <TAB> """"""Return a suite of all perfs cases contained in the given module"""""" <TAB> perfs = [] <TAB> for name in dir(module): <TAB>  <TAB> obj = getattr(module, name) <MASK> perfs.append(self.loadPerfsFromPerfCase(obj)) <TAB> return self.suiteClass(perfs)","if type ( obj ) == types . ClassType and issubclass ( obj , PerfCase ) :",108
3656,"def download_subtitle(self, subtitle): <TAB> if isinstance(subtitle, XSubsSubtitle): <TAB>  <TAB> # download the subtitle <TAB>  <TAB> logger.info(""Downloading subtitle %r"", subtitle) <TAB>  <TAB> r = self.session.get( <TAB>  <TAB>  <TAB> subtitle.download_link, headers={""Referer"": subtitle.page_link}, timeout=10 <TAB>  <TAB> ) <TAB>  <TAB> r.raise_for_status() <MASK> logger.debug(""Unable to download subtitle. No data returned from provider"") <TAB>  <TAB>  <TAB> return <TAB>  <TAB> subtitle.content = fix_line_ending(r.content)",if not r . content :,145
3657,"def get_inlaws(self, person): <TAB> inlaws = [] <TAB> family_handles = person.get_family_handle_list() <TAB> for handle in family_handles: <TAB>  <TAB> fam = self.database.get_family_from_handle(handle) <TAB>  <TAB> if fam.father_handle and not fam.father_handle == person.handle: <TAB>  <TAB>  <TAB> inlaws.append(self.database.get_person_from_handle(fam.father_handle)) <MASK> inlaws.append(self.database.get_person_from_handle(fam.mother_handle)) <TAB> return inlaws",elif fam . mother_handle and not fam . mother_handle == person . handle :,180
3658,"def _check_xorg_conf(): <TAB> if is_there_a_default_xorg_conf_file(): <TAB>  <TAB> print( <TAB>  <TAB>  <TAB> ""WARNING : Found a Xorg config file at /etc/X11/xorg.conf. If you did not"" <TAB>  <TAB>  <TAB> "" create it yourself, it was likely generated by your distribution or by an Nvidia utility.\n"" <TAB>  <TAB>  <TAB> ""This file may contain hard-coded GPU configuration that could interfere with optimus-manager,"" <TAB>  <TAB>  <TAB> "" so it is recommended that you delete it before proceeding.\n"" <TAB>  <TAB>  <TAB> ""Ignore this warning and proceed with GPU switching ? (y/N)"" <TAB>  <TAB> ) <TAB>  <TAB> confirmation = ask_confirmation() <MASK> sys.exit(0)",if not confirmation :,178
3659,"def _make_cache_key(group, window, rate, value, methods): <TAB> count, period = _split_rate(rate) <TAB> safe_rate = ""%d/%ds"" % (count, period) <TAB> parts = [group, safe_rate, value, str(window)] <TAB> if methods is not None: <MASK> methods = """" <TAB>  <TAB> elif isinstance(methods, (list, tuple)): <TAB>  <TAB>  <TAB> methods = """".join(sorted([m.upper() for m in methods])) <TAB>  <TAB> parts.append(methods) <TAB> prefix = getattr(settings, ""RATELIMIT_CACHE_PREFIX"", ""rl:"") <TAB> return prefix + hashlib.md5(u"""".join(parts).encode(""utf-8"")).hexdigest()",if methods == ALL :,175
3660,"def num_of_mapped_volumes(self, initiator): <TAB> cnt = 0 <TAB> for lm_link in self.req(""lun-maps"")[""lun-maps""]: <TAB>  <TAB> idx = lm_link[""href""].split(""/"")[-1] <TAB>  <TAB> # NOTE(geguileo): There can be races so mapped elements retrieved <TAB>  <TAB> # in the listing may no longer exist. <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> lm = self.req(""lun-maps"", idx=int(idx))[""content""] <TAB>  <TAB> except exception.NotFound: <TAB>  <TAB>  <TAB> continue <MASK> cnt += 1 <TAB> return cnt","if lm [ ""ig-name"" ] == initiator :",157
3661,"def _setAbsoluteY(self, value): <TAB> if value is None: <TAB>  <TAB> self._absoluteY = None <TAB> else: <MASK> value = 10 <TAB>  <TAB> elif value == ""below"": <TAB>  <TAB>  <TAB> value = -70 <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> value = common.numToIntOrFloat(value) <TAB>  <TAB> except ValueError as ve: <TAB>  <TAB>  <TAB> raise TextFormatException( <TAB>  <TAB>  <TAB>  <TAB> f""Not a supported absoluteY position: {value!r}"" <TAB>  <TAB>  <TAB> ) from ve <TAB>  <TAB> self._absoluteY = value","if value == ""above"" :",137
3662,"def render_markdown(text): <TAB> users = {u.username.lower(): u for u in get_mention_users(text)} <TAB> parts = MENTION_RE.split(text) <TAB> for pos, part in enumerate(parts): <TAB>  <TAB> if not part.startswith(""@""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> username = part[1:].lower() <MASK> user = users[username] <TAB>  <TAB>  <TAB> parts[pos] = '**[{}]({} ""{}"")**'.format( <TAB>  <TAB>  <TAB>  <TAB> part, user.get_absolute_url(), user.get_visible_name() <TAB>  <TAB>  <TAB> ) <TAB> text = """".join(parts) <TAB> return mark_safe(MARKDOWN(text))",if username in users :,168
3663,def start_process(self): <TAB> with self.thread_lock: <MASK> self.allow_process_request = False <TAB>  <TAB>  <TAB> t = threading.Thread(target=self.__start) <TAB>  <TAB>  <TAB> t.daemon = True <TAB>  <TAB>  <TAB> t.start(),if self . allow_process_request :,75
3664,"def close(self): <TAB> if self._fh.closed: <TAB>  <TAB> return <TAB> self._fh.close() <TAB> if os.path.isfile(self._filename): <MASK> salt.utils.win_dacl.copy_security( <TAB>  <TAB>  <TAB>  <TAB> source=self._filename, target=self._tmp_filename <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> shutil.copymode(self._filename, self._tmp_filename) <TAB>  <TAB>  <TAB> st = os.stat(self._filename) <TAB>  <TAB>  <TAB> os.chown(self._tmp_filename, st.st_uid, st.st_gid) <TAB> atomic_rename(self._tmp_filename, self._filename)",if salt . utils . win_dacl . HAS_WIN32 :,179
3665,"def _splitSchemaNameDotFieldName(sn_fn, fnRequired=True): <TAB> if sn_fn.find(""."") != -1: <TAB>  <TAB> schemaName, fieldName = sn_fn.split(""."", 1) <TAB>  <TAB> schemaName = schemaName.strip() <TAB>  <TAB> fieldName = fieldName.strip() <TAB>  <TAB> if schemaName and fieldName: <TAB>  <TAB>  <TAB> return (schemaName, fieldName) <TAB> elif not fnRequired: <TAB>  <TAB> schemaName = sn_fn.strip() <MASK> return (schemaName, None) <TAB> controlflow.system_error_exit( <TAB>  <TAB> 2, f""{sn_fn} is not a valid custom schema.field name."" <TAB> )",if schemaName :,164
3666,"def modified(self): <TAB> paths = set() <TAB> dictionary_list = [] <TAB> for op_list in self._operations: <MASK> op_list = (op_list,) <TAB>  <TAB> for item in chain(*op_list): <TAB>  <TAB>  <TAB> if item is None: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> dictionary = item.dictionary <TAB>  <TAB>  <TAB> if dictionary.path in paths: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> paths.add(dictionary.path) <TAB>  <TAB>  <TAB> dictionary_list.append(dictionary) <TAB> return dictionary_list","if not isinstance ( op_list , list ) :",139
3667,"def apply(self, db, person): <TAB> for family_handle in person.get_family_handle_list(): <TAB>  <TAB> family = db.get_family_from_handle(family_handle) <MASK> for event_ref in family.get_event_ref_list(): <TAB>  <TAB>  <TAB>  <TAB> if event_ref: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> event = db.get_event_from_handle(event_ref.ref) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if not event.get_place_handle(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if not event.get_date_object(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if family :,159
3668,"def test_cleanup_params(self, body, rpc_mock): <TAB> res = self._get_resp_post(body) <TAB> self.assertEqual(http_client.ACCEPTED, res.status_code) <TAB> rpc_mock.assert_called_once_with(self.context, mock.ANY) <TAB> cleanup_request = rpc_mock.call_args[0][1] <TAB> for key, value in body.items(): <MASK> if value is not None: <TAB>  <TAB>  <TAB>  <TAB> value = value == ""true"" <TAB>  <TAB> self.assertEqual(value, getattr(cleanup_request, key)) <TAB> self.assertEqual(self._expected_services(*SERVICES), res.json)","if key in ( ""disabled"" , ""is_up"" ) :",177
3669,"def get_billable_and_total_duration(activity, start_time, end_time): <TAB> precision = frappe.get_precision(""Timesheet Detail"", ""hours"") <TAB> activity_duration = time_diff_in_hours(end_time, start_time) <TAB> billing_duration = 0.0 <TAB> if activity.billable: <TAB>  <TAB> billing_duration = activity.billing_hours <MASK> billing_duration = ( <TAB>  <TAB>  <TAB>  <TAB> activity_duration * activity.billing_hours / activity.hours <TAB>  <TAB>  <TAB> ) <TAB> return flt(activity_duration, precision), flt(billing_duration, precision)",if activity_duration != activity . billing_hours :,167
3670,"def cpus(self): <TAB> try: <TAB>  <TAB> cpus = ( <TAB>  <TAB>  <TAB> self.inspect[""Spec""][""Resources""][""Reservations""][""NanoCPUs""] / 1000000000.0 <TAB>  <TAB> ) <MASK> cpus = int(cpus) <TAB>  <TAB> return cpus <TAB> except TypeError: <TAB>  <TAB> return None <TAB> except KeyError: <TAB>  <TAB> return 0",if cpus == int ( cpus ) :,92
3671,"def _create_object(self, obj_body): <TAB> props = obj_body[SYMBOL_PROPERTIES] <TAB> for prop_name, prop_value in props.items(): <MASK> # get the first key as the convert function <TAB>  <TAB>  <TAB> func_name = list(prop_value.keys())[0] <TAB>  <TAB>  <TAB> if func_name.startswith(""_""): <TAB>  <TAB>  <TAB>  <TAB> func = getattr(self, func_name) <TAB>  <TAB>  <TAB>  <TAB> props[prop_name] = func(prop_value[func_name]) <TAB> if SYMBOL_TYPE in obj_body and obj_body[SYMBOL_TYPE] in self.fake_func_mapping: <TAB>  <TAB> return self.fake_func_mapping[obj_body[SYMBOL_TYPE]](**props) <TAB> else: <TAB>  <TAB> return props","if isinstance ( prop_value , dict ) and prop_value :",199
3672,"def _yield_unescaped(self, string): <TAB> while ""\\"" in string: <TAB>  <TAB> finder = EscapeFinder(string) <TAB>  <TAB> yield finder.before + finder.backslashes <MASK> yield self._unescape(finder.text) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield finder.text <TAB>  <TAB> string = finder.after <TAB> yield string",if finder . escaped and finder . text :,91
3673,"def _check_matches(rule, matches): <TAB> errors = 0 <TAB> for match in matches: <TAB>  <TAB> filematch = _match_to_test_file(match) <MASK> utils.error( <TAB>  <TAB>  <TAB>  <TAB> ""The match '{}' for rule '{}' points to a non existing test module path: {}"", <TAB>  <TAB>  <TAB>  <TAB> match, <TAB>  <TAB>  <TAB>  <TAB> rule, <TAB>  <TAB>  <TAB>  <TAB> filematch, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> errors += 1 <TAB> return errors",if not filematch . exists ( ) :,118
3674,"def focused_windows(): <TAB> tree = i3.get_tree() <TAB> workspaces = tree.workspaces() <TAB> for workspace in workspaces: <TAB>  <TAB> container = workspace <TAB>  <TAB> while container: <TAB>  <TAB>  <TAB> if not hasattr(container, ""focus"") or not container.focus: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> container_id = container.focus[0] <TAB>  <TAB>  <TAB> container = container.find_by_id(container_id) <MASK> coname = container.name <TAB>  <TAB>  <TAB> wsname = workspace.name <TAB>  <TAB>  <TAB> print(""WS"", wsname + "":"", coname)",if container :,146
3675,"def normals(self, value): <TAB> if value is not None: <TAB>  <TAB> value = np.asanyarray(value, dtype=np.float32) <TAB>  <TAB> value = np.ascontiguousarray(value) <MASK> raise ValueError(""Incorrect normals shape"") <TAB> self._normals = value",if value . shape != self . positions . shape :,77
3676,"def test_hexdigest(self): <TAB> for cons in self.hash_constructors: <TAB>  <TAB> h = cons() <MASK> self.assertIsInstance(h.digest(16), bytes) <TAB>  <TAB>  <TAB> self.assertEqual(hexstr(h.digest(16)), h.hexdigest(16)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertIsInstance(h.digest(), bytes) <TAB>  <TAB>  <TAB> self.assertEqual(hexstr(h.digest()), h.hexdigest())",if h . name in self . shakes :,117
3677,"def _get_cluster_status(self): <TAB> try: <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB> self.dataproc_client.projects() <TAB>  <TAB>  <TAB> .regions() <TAB>  <TAB>  <TAB> .clusters() <TAB>  <TAB>  <TAB> .get( <TAB>  <TAB>  <TAB>  <TAB> projectId=self.gcloud_project_id, <TAB>  <TAB>  <TAB>  <TAB> region=self.dataproc_region, <TAB>  <TAB>  <TAB>  <TAB> clusterName=self.dataproc_cluster_name, <TAB>  <TAB>  <TAB>  <TAB> fields=""status"", <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> .execute() <TAB>  <TAB> ) <TAB> except HttpError as e: <MASK> return None  # We got a 404 so the cluster doesn't exist <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise e",if e . resp . status == 404 :,175
3678,"def _items_from(self, context): <TAB> self._context = context <TAB> if self._is_local_variable(self._keyword_name, context): <TAB>  <TAB> for item in self._items_from_controller(context): <TAB>  <TAB>  <TAB> yield item <TAB> else: <TAB>  <TAB> for df in context.datafiles: <TAB>  <TAB>  <TAB> self._yield_for_other_threads() <MASK> for item in self._items_from_datafile(df): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield item",if self . _items_from_datafile_should_be_checked ( df ) :,135
3679,"def Command(argv, funcs, path_val): <TAB> arg, i = COMMAND_SPEC.Parse(argv) <TAB> status = 0 <TAB> if arg.v: <TAB>  <TAB> for kind, arg in _ResolveNames(argv[i:], funcs, path_val): <MASK> status = 1  # nothing printed, but we fail <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> # This is for -v, -V is more detailed. <TAB>  <TAB>  <TAB>  <TAB> print(arg) <TAB> else: <TAB>  <TAB> util.warn(""*** command without -v not not implemented ***"") <TAB>  <TAB> status = 1 <TAB> return status",if kind is None :,147
3680,"def delete_doc(elastic_document_id, node, index=None, category=None): <TAB> index = index or INDEX <TAB> if not category: <TAB>  <TAB> if isinstance(node, Preprint): <TAB>  <TAB>  <TAB> category = ""preprint"" <MASK> category = ""registration"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> category = node.project_or_component <TAB> client().delete( <TAB>  <TAB> index=index, <TAB>  <TAB> doc_type=category, <TAB>  <TAB> id=elastic_document_id, <TAB>  <TAB> refresh=True, <TAB>  <TAB> ignore=[404], <TAB> )",elif node . is_registration :,143
3681,"def getDictFromTree(tree): <TAB> ret_dict = {} <TAB> for child in tree.getchildren(): <MASK> ## Complex-type child. Recurse <TAB>  <TAB>  <TAB> content = getDictFromTree(child) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> content = child.text <TAB>  <TAB> if ret_dict.has_key(child.tag): <TAB>  <TAB>  <TAB> if not type(ret_dict[child.tag]) == list: <TAB>  <TAB>  <TAB>  <TAB> ret_dict[child.tag] = [ret_dict[child.tag]] <TAB>  <TAB>  <TAB> ret_dict[child.tag].append(content or """") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret_dict[child.tag] = content or """" <TAB> return ret_dict",if child . getchildren ( ) :,175
3682,"def get(self, block=True, timeout=None, ack=False): <TAB> if not block: <TAB>  <TAB> return self.get_nowait() <TAB> start_time = time.time() <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self.get_nowait(ack) <TAB>  <TAB> except BaseQueue.Empty: <MASK> lasted = time.time() - start_time <TAB>  <TAB>  <TAB>  <TAB> if timeout > lasted: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> time.sleep(min(self.max_timeout, timeout - lasted)) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> time.sleep(self.max_timeout)",if timeout :,169
3683,"def rewrite(self, string): <TAB> string = super(JSReplaceFuzzy, self).rewrite(string) <TAB> cdx = self.url_rewriter.rewrite_opts[""cdx""] <TAB> if cdx.get(""is_fuzzy""): <TAB>  <TAB> expected = unquote(cdx[""url""]) <TAB>  <TAB> actual = unquote(self.url_rewriter.wburl.url) <TAB>  <TAB> exp_m = self.rx_obj.search(expected) <TAB>  <TAB> act_m = self.rx_obj.search(actual) <MASK> result = string.replace(exp_m.group(1), act_m.group(1)) <TAB>  <TAB>  <TAB> if result != string: <TAB>  <TAB>  <TAB>  <TAB> string = result <TAB> return string",if exp_m and act_m :,179
3684,"def locate_exe_dir(d, check=True): <TAB> exe_dir = os.path.join(d, ""Scripts"") if ON_WINDOWS else os.path.join(d, ""bin"") <TAB> if not os.path.isdir(exe_dir): <MASK> bin_dir = os.path.join(d, ""bin"") <TAB>  <TAB>  <TAB> if os.path.isdir(bin_dir): <TAB>  <TAB>  <TAB>  <TAB> return bin_dir <TAB>  <TAB> if check: <TAB>  <TAB>  <TAB> raise InvalidVirtualEnv(""Unable to locate executables directory."") <TAB> return exe_dir",if ON_WINDOWS :,140
3685,"def _ensuresyspath(self, ensuremode, path): <TAB> if ensuremode: <TAB>  <TAB> s = str(path) <TAB>  <TAB> if ensuremode == ""append"": <TAB>  <TAB>  <TAB> if s not in sys.path: <TAB>  <TAB>  <TAB>  <TAB> sys.path.append(s) <TAB>  <TAB> else: <MASK> sys.path.insert(0, s)",if s != sys . path [ 0 ] :,97
3686,"def create_season_banners(self, show_obj): <TAB> if self.season_banners and show_obj: <TAB>  <TAB> result = [] <TAB>  <TAB> for season, episodes in show_obj.episodes.iteritems():  # @UnusedVariable <MASK> logger.log( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> u""Metadata provider "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> + self.name <TAB>  <TAB>  <TAB>  <TAB>  <TAB> + "" creating season banners for "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> + show_obj.name, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> logger.DEBUG, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> result = result + [self.save_season_banners(show_obj, season)] <TAB>  <TAB> return all(result) <TAB> return False","if not self . _has_season_banner ( show_obj , season ) :",197
3687,"def validate_nb(self, nb): <TAB> super(MetadataValidatorV3, self).validate_nb(nb) <TAB> ids = set([]) <TAB> for cell in nb.cells: <TAB>  <TAB> if ""nbgrader"" not in cell.metadata: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> grade = cell.metadata[""nbgrader""][""grade""] <TAB>  <TAB> solution = cell.metadata[""nbgrader""][""solution""] <TAB>  <TAB> locked = cell.metadata[""nbgrader""][""locked""] <MASK> continue <TAB>  <TAB> grade_id = cell.metadata[""nbgrader""][""grade_id""] <TAB>  <TAB> if grade_id in ids: <TAB>  <TAB>  <TAB> raise ValidationError(""Duplicate grade id: {}"".format(grade_id)) <TAB>  <TAB> ids.add(grade_id)",if not grade and not solution and not locked :,186
3688,"def read_version(): <TAB> regexp = re.compile(r""^__version__\W*=\W*'([\d.abrc]+)'"") <TAB> init_py = os.path.join(os.path.dirname(__file__), ""aiopg"", ""__init__.py"") <TAB> with open(init_py) as f: <TAB>  <TAB> for line in f: <TAB>  <TAB>  <TAB> match = regexp.match(line) <MASK> return match.group(1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise RuntimeError(""Cannot find version in aiopg/__init__.py"")",if match is not None :,137
3689,"def _column_keys(self): <TAB> """"""Get a dictionary of all columns and their case mapping."""""" <TAB> if not self.exists: <TAB>  <TAB> return {} <TAB> with self.db.lock: <TAB>  <TAB> if self._columns is None: <TAB>  <TAB>  <TAB> # Initialise the table if it doesn't exist <TAB>  <TAB>  <TAB> table = self.table <TAB>  <TAB>  <TAB> self._columns = {} <TAB>  <TAB>  <TAB> for column in table.columns: <TAB>  <TAB>  <TAB>  <TAB> name = normalize_column_name(column.name) <TAB>  <TAB>  <TAB>  <TAB> key = normalize_column_key(name) <MASK> log.warning(""Duplicate column: %s"", name) <TAB>  <TAB>  <TAB>  <TAB> self._columns[key] = name <TAB>  <TAB> return self._columns",if key in self . _columns :,180
3690,"def find_controller_by_names(self, names, testname): <TAB> namestring = ""."".join(names) <TAB> if not namestring.startswith(self.name): <TAB>  <TAB> return None <TAB> if namestring == self.name: <TAB>  <TAB> return self <TAB> for suite in self.suites: <TAB>  <TAB> res = suite.find_controller_by_names( <TAB>  <TAB>  <TAB> namestring[len(self.name) + 1 :].split("".""), testname <TAB>  <TAB> ) <MASK> return res",if res :,122
3691,"def _volume_x_metadata_get_item( <TAB> context, volume_id, key, model, notfound_exec, session=None): <TAB> result = ( <TAB>  <TAB> _volume_x_metadata_get_query(context, volume_id, model, session=session) <TAB>  <TAB> .filter_by(key=key) <TAB>  <TAB> .first() <TAB> ) <TAB> if not result: <MASK> raise notfound_exec(id=volume_id) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise notfound_exec(metadata_key=key, volume_id=volume_id) <TAB> return result",if model is models . VolumeGlanceMetadata :,155
3692,"def parse_results(cwd): <TAB> optimal_dd = None <TAB> optimal_measure = numpy.inf <TAB> for tup in tools.find_conf_files(cwd): <TAB>  <TAB> dd = tup[1] <MASK> if dd[""results.train_y_misclass""] < optimal_measure: <TAB>  <TAB>  <TAB>  <TAB> optimal_measure = dd[""results.train_y_misclass""] <TAB>  <TAB>  <TAB>  <TAB> optimal_dd = dd <TAB> print(""Optimal results.train_y_misclass:"", str(optimal_measure)) <TAB> for key, value in optimal_dd.items(): <TAB>  <TAB> if ""hyper_parameters"" in key: <TAB>  <TAB>  <TAB> print(key + "": "" + str(value))","if ""results.train_y_misclass"" in dd :",177
3693,"def _stop_by_max_time_mins(self): <TAB> """"""Stop optimization process once maximum minutes have elapsed."""""" <TAB> if self.max_time_mins: <TAB>  <TAB> total_mins_elapsed = ( <TAB>  <TAB>  <TAB> datetime.now() - self._start_datetime <TAB>  <TAB> ).total_seconds() / 60.0 <MASK> raise KeyboardInterrupt( <TAB>  <TAB>  <TAB>  <TAB> ""{:.2f} minutes have elapsed. TPOT will close down."".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> total_mins_elapsed <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> )",if total_mins_elapsed >= self . max_time_mins :,144
3694,"def __new__(meta, cls_name, bases, cls_dict): <TAB> func = cls_dict.get(""func"") <TAB> monad_cls = super(FuncMonadMeta, meta).__new__(meta, cls_name, bases, cls_dict) <TAB> if func: <MASK> functions = func <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> functions = (func,) <TAB>  <TAB> for func in functions: <TAB>  <TAB>  <TAB> registered_functions[func] = monad_cls <TAB> return monad_cls",if type ( func ) is tuple :,126
3695,"def get_tokens_unprocessed(self, text): <TAB> buffered = """" <TAB> insertions = [] <TAB> lng_buffer = [] <TAB> for i, t, v in self.language_lexer.get_tokens_unprocessed(text): <MASK> if lng_buffer: <TAB>  <TAB>  <TAB>  <TAB> insertions.append((len(buffered), lng_buffer)) <TAB>  <TAB>  <TAB>  <TAB> lng_buffer = [] <TAB>  <TAB>  <TAB> buffered += v <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lng_buffer.append((i, t, v)) <TAB> if lng_buffer: <TAB>  <TAB> insertions.append((len(buffered), lng_buffer)) <TAB> return do_insertions(insertions, self.root_lexer.get_tokens_unprocessed(buffered))",if t is self . needle :,185
3696,"def get_conditions(filters): <TAB> conditions = {""docstatus"": (""="", 1)} <TAB> if filters.get(""from_date"") and filters.get(""to_date""): <TAB>  <TAB> conditions[""result_date""] = ( <TAB>  <TAB>  <TAB> ""between"", <TAB>  <TAB>  <TAB> (filters.get(""from_date""), filters.get(""to_date"")), <TAB>  <TAB> ) <TAB>  <TAB> filters.pop(""from_date"") <TAB>  <TAB> filters.pop(""to_date"") <TAB> for key, value in filters.items(): <MASK> conditions[key] = value <TAB> return conditions",if filters . get ( key ) :,140
3697,"def _limit_value(key, value, config): <TAB> if config[key].get(""upper_limit""): <TAB>  <TAB> limit = config[key][""upper_limit""] <TAB>  <TAB> # auto handle datetime <TAB>  <TAB> if isinstance(value, datetime) and isinstance(limit, timedelta): <MASK> if (datetime.now() - limit) > value: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value = datetime.now() - limit <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> if (datetime.now() + limit) < value: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value = datetime.now() + limit <TAB>  <TAB> elif value > limit: <TAB>  <TAB>  <TAB> value = limit <TAB> return value","if config [ key ] [ ""inverse"" ] is True :",164
3698,"def GetCurrentKeySet(self): <TAB> ""Return CurrentKeys with 'darwin' modifications."" <TAB> result = self.GetKeySet(self.CurrentKeys()) <TAB> if sys.platform == ""darwin"": <TAB>  <TAB> # macOS (OS X) Tk variants do not support the ""Alt"" <TAB>  <TAB> # keyboard modifier.  Replace it with ""Option"". <TAB>  <TAB> # TODO (Ned?): the ""Option"" modifier does not work properly <TAB>  <TAB> # <TAB>  for Cocoa Tk and XQuartz Tk so we should not use it <TAB>  <TAB> # <TAB>  in the default 'OSX' keyset. <TAB>  <TAB> for k, v in result.items(): <TAB>  <TAB>  <TAB> v2 = [x.replace(""<Alt-"", ""<Option-"") for x in v] <MASK> result[k] = v2 <TAB> return result",if v != v2 :,200
3699,"def _load_testfile(filename, package, module_relative): <TAB> if module_relative: <TAB>  <TAB> package = _normalize_module(package, 3) <TAB>  <TAB> filename = _module_relative_path(package, filename) <TAB>  <TAB> if hasattr(package, ""__loader__""): <MASK> file_contents = package.__loader__.get_data(filename) <TAB>  <TAB>  <TAB>  <TAB> # get_data() opens files as 'rb', so one must do the equivalent <TAB>  <TAB>  <TAB>  <TAB> # conversion as universal newlines would do. <TAB>  <TAB>  <TAB>  <TAB> return file_contents.replace(os.linesep, ""\n""), filename <TAB> return open(filename).read(), filename","if hasattr ( package . __loader__ , ""get_data"" ) :",163
3700,"def iter_from_X_lengths(X, lengths): <TAB> if lengths is None: <TAB>  <TAB> yield 0, len(X) <TAB> else: <TAB>  <TAB> n_samples = X.shape[0] <TAB>  <TAB> end = np.cumsum(lengths).astype(np.int32) <TAB>  <TAB> start = end - lengths <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""more than {:d} samples in lengths array {!s}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> n_samples, lengths <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> for i in range(len(lengths)): <TAB>  <TAB>  <TAB> yield start[i], end[i]",if end [ - 1 ] > n_samples :,161
3701,"def change_sel(self): <TAB> """"""Change the view's selections."""""" <TAB> if self.alter_select and len(self.sels) > 0: <MASK> self.view.show(self.sels[0]) <TAB>  <TAB> self.view.sel().clear() <TAB>  <TAB> self.view.sel().add_all(self.sels)",if self . multi_select is False :,94
3702,"def cb_syncthing_device_data_changed( <TAB> self, daemon, nid, address, client_version, inbps, outbps, inbytes, outbytes): <TAB> if nid in self.devices:  # Should be always <TAB>  <TAB> device = self.devices[nid] <TAB>  <TAB> # Update strings <TAB>  <TAB> device[""address""] = address <MASK> device[""version""] = client_version <TAB>  <TAB> # Update rates <TAB>  <TAB> device[""inbps""] = ""%s/s (%s)"" % (sizeof_fmt(inbps), sizeof_fmt(inbytes)) <TAB>  <TAB> device[""outbps""] = ""%s/s (%s)"" % (sizeof_fmt(outbps), sizeof_fmt(outbytes))","if client_version not in ( ""?"" , None ) :",184
3703,"def then(self, matches, when_response, context): <TAB> if is_iterable(when_response): <TAB>  <TAB> ret = [] <TAB>  <TAB> when_response = list(when_response) <TAB>  <TAB> for match in when_response: <TAB>  <TAB>  <TAB> if match not in matches: <MASK> match.name = self.match_name <TAB>  <TAB>  <TAB>  <TAB> matches.append(match) <TAB>  <TAB>  <TAB>  <TAB> ret.append(match) <TAB>  <TAB> return ret <TAB> if self.match_name: <TAB>  <TAB> when_response.name = self.match_name <TAB> if when_response not in matches: <TAB>  <TAB> matches.append(when_response) <TAB>  <TAB> return when_response",if self . match_name :,169
3704,"def __update_parents(self, fileobj, path, delta): <TAB> """"""Update all parent atoms with the new size."""""" <TAB> if delta == 0: <TAB>  <TAB> return <TAB> for atom in path: <TAB>  <TAB> fileobj.seek(atom.offset) <TAB>  <TAB> size = cdata.uint_be(fileobj.read(4)) <MASK> # 64bit <TAB>  <TAB>  <TAB> # skip name (4B) and read size (8B) <TAB>  <TAB>  <TAB> size = cdata.ulonglong_be(fileobj.read(12)[4:]) <TAB>  <TAB>  <TAB> fileobj.seek(atom.offset + 8) <TAB>  <TAB>  <TAB> fileobj.write(cdata.to_ulonglong_be(size + delta)) <TAB>  <TAB> else:  # 32bit <TAB>  <TAB>  <TAB> fileobj.seek(atom.offset) <TAB>  <TAB>  <TAB> fileobj.write(cdata.to_uint_be(size + delta))",if size == 1 :,200
3705,"def _fields_to_index(cls): <TAB> fields = [] <TAB> for field in cls._meta.sorted_fields: <TAB>  <TAB> if field.primary_key: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> requires_index = any( <TAB>  <TAB>  <TAB> (field.index, field.unique, isinstance(field, ForeignKeyField)) <TAB>  <TAB> ) <MASK> fields.append(field) <TAB> return fields",if requires_index :,99
3706,"def __init__(self, value): <TAB> """"""Initialize the integer to the given value."""""" <TAB> self._mpz_p = new_mpz() <TAB> self._initialized = False <TAB> if isinstance(value, float): <TAB>  <TAB> raise ValueError(""A floating point type is not a natural number"") <TAB> self._initialized = True <TAB> if isinstance(value, (int, long)): <TAB>  <TAB> _gmp.mpz_init(self._mpz_p) <TAB>  <TAB> result = _gmp.gmp_sscanf(tobytes(str(value)), b(""%Zd""), self._mpz_p) <MASK> raise ValueError(""Error converting '%d'"" % value) <TAB> else: <TAB>  <TAB> _gmp.mpz_init_set(self._mpz_p, value._mpz_p)",if result != 1 :,193
3707,"def decode(cls, data): <TAB> while data: <TAB>  <TAB> length, format_type, control_flags, sequence, pid = unpack( <TAB>  <TAB>  <TAB> cls.Header.PACK, data[: cls.Header.LEN] <TAB>  <TAB> ) <MASK> raise NetLinkError(""Buffer underrun"") <TAB>  <TAB> yield cls.format( <TAB>  <TAB>  <TAB> format_type, control_flags, sequence, pid, data[cls.Header.LEN : length] <TAB>  <TAB> ) <TAB>  <TAB> data = data[length:]",if len ( data ) < length :,125
3708,"def __post_init__(self): <TAB> if self._node_id is not None: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""invalid node_id: {}"".format(hexlify(self._node_id).decode()) <TAB>  <TAB>  <TAB> ) <TAB> if self.udp_port is not None and not 1 <= self.udp_port <= 65535: <TAB>  <TAB> raise ValueError(""invalid udp port"") <TAB> if self.tcp_port is not None and not 1 <= self.tcp_port <= 65535: <TAB>  <TAB> raise ValueError(""invalid tcp port"") <TAB> if not is_valid_public_ipv4(self.address, self.allow_localhost): <TAB>  <TAB> raise ValueError(f""invalid ip address: '{self.address}'"")",if not len ( self . _node_id ) == constants . HASH_LENGTH :,185
3709,"def orderUp(self, items): <TAB> sel = []  # new selection <TAB> undoinfo = [] <TAB> for bid, lid in items: <TAB>  <TAB> if isinstance(lid, int): <TAB>  <TAB>  <TAB> undoinfo.append(self.orderUpLineUndo(bid, lid)) <TAB>  <TAB>  <TAB> sel.append((bid, lid - 1)) <MASK> undoinfo.append(self.orderUpBlockUndo(bid)) <TAB>  <TAB>  <TAB> if bid == 0: <TAB>  <TAB>  <TAB>  <TAB> return items <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> sel.append((bid - 1, None)) <TAB> self.addUndo(undoinfo, ""Move Up"") <TAB> return sel",elif lid is None :,164
3710,"def filter_data(self, min_len, max_len): <TAB> logging.info(f""filtering data, min len: {min_len}, max len: {max_len}"") <TAB> initial_len = len(self.src) <TAB> filtered_src = [] <TAB> filtered_tgt = [] <TAB> for src, tgt in zip(self.src, self.tgt): <MASK> filtered_src.append(src) <TAB>  <TAB>  <TAB> filtered_tgt.append(tgt) <TAB> self.src = filtered_src <TAB> self.tgt = filtered_tgt <TAB> filtered_len = len(self.src) <TAB> logging.info(f""pairs before: {initial_len}, after: {filtered_len}"")",if min_len <= len ( src ) <= max_len and min_len <= len ( tgt ) <= max_len :,193
3711,"def layer_pretrained(self, net, args, options): <TAB> model = getattr(torchvision.models, args[0])(pretrained=True) <TAB> model.train(True) <TAB> if options.layer: <TAB>  <TAB> layers = list(model.children())[: options.layer] <MASK> layers[-1] = nn.Sequential(*layers[-1][: options.sublayer]) <TAB> else: <TAB>  <TAB> layers = [model] <TAB>  <TAB> print(""List of pretrained layers:"", layers) <TAB>  <TAB> raise ValidationException( <TAB>  <TAB>  <TAB> ""layer=-1 required for pretrained, sublayer=-1 optional.  Layers outputted above."" <TAB>  <TAB> ) <TAB> return nn.Sequential(*layers)",if options . sublayer :,163
3712,"def deleteCalendar(users): <TAB> calendarId = normalizeCalendarId(sys.argv[5]) <TAB> for user in users: <TAB>  <TAB> user, cal = buildCalendarGAPIObject(user) <MASK> continue <TAB>  <TAB> gapi.call(cal.calendarList(), ""delete"", soft_errors=True, calendarId=calendarId)",if not cal :,84
3713,"def iter_modules(self, by_clients=False, clients_filter=None): <TAB> """"""iterate over all modules"""""" <TAB> clients = None <TAB> if by_clients: <TAB>  <TAB> clients = self.get_clients(clients_filter) <MASK> return <TAB> self._refresh_modules() <TAB> for module_name in self.modules: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> module = self.get_module(module_name) <TAB>  <TAB> except PupyModuleDisabled: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if clients is not None: <TAB>  <TAB>  <TAB> for client in clients: <TAB>  <TAB>  <TAB>  <TAB> if module.is_compatible_with(client): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield module <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield module",if not clients :,181
3714,"def update_me(self): <TAB> try: <TAB>  <TAB> while 1: <TAB>  <TAB>  <TAB> line = self.queue.get_nowait() <MASK> self.delete(1.0, tk.END) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.insert(tk.END, str(line)) <TAB>  <TAB>  <TAB> self.see(tk.END) <TAB>  <TAB>  <TAB> self.update_idletasks() <TAB> except queue.Empty: <TAB>  <TAB> pass <TAB> self.after(100, self.update_me)",if line is None :,128
3715,"def request_power_state(self, state, force=False): <TAB> if self.current_state != state or force: <MASK> self.request_in_progress = True <TAB>  <TAB>  <TAB> logging.info(""Requesting %s"" % state) <TAB>  <TAB>  <TAB> cb = PowerManager.Callback(self, state) <TAB>  <TAB>  <TAB> rets = self.parent.Plugins.run( <TAB>  <TAB>  <TAB>  <TAB> ""on_power_state_change_requested"", self, state, cb <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> cb.num_cb = len(rets) <TAB>  <TAB>  <TAB> cb.check() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logging.info(""Another request in progress"")",if not self . request_in_progress :,165
3716,"def __getitem__(self, idx): <TAB> super(BatchDataset, self).__getitem__(idx) <TAB> maxidx = len(self.dataset) <TAB> samples = [] <TAB> for i in range(0, self.batchsize): <TAB>  <TAB> j = idx * self.batchsize + i <TAB>  <TAB> if j >= maxidx: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> j = self.perm(j, maxidx) <TAB>  <TAB> sample = self.dataset[j] <MASK> samples.append(sample) <TAB> samples = self.makebatch(samples) <TAB> return samples",if self . filter ( sample ) :,135
3717,"def __call__(self, request, *args, **kwargs): <TAB> template_vars = {} <TAB> for form_name, form_class in self.forms.iteritems(): <MASK> template_vars[form_name] = form_class(request) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> template_vars[form_name] = None <TAB> if request.method == ""POST"": <TAB>  <TAB> action = self.find_post_handler_action(request) <TAB>  <TAB> form = self.handlers[action](request, data=request.POST, files=request.FILES) <TAB>  <TAB> template_vars.update(form.dispatch(action, request, *args, **kwargs)) <TAB> return self.GET(template_vars, request, *args, **kwargs)","if form_class . must_display ( request , * args , ** kwargs ) :",191
3718,"def on_show_all(self, widget, another): <TAB> if widget.get_active(): <MASK> self.treeview.update_items(all=True, comment=True) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.treeview.update_items(all=True) <TAB> else: <TAB>  <TAB> if another.get_active(): <TAB>  <TAB>  <TAB> self.treeview.update_items(comment=True) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.treeview.update_items()",if another . get_active ( ) :,121
3719,"def close(self): <TAB> if self._closed: <TAB>  <TAB> return <TAB> self._closed = True <TAB> for proto in self._pipes.values(): <TAB>  <TAB> if proto is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> proto.pipe.close() <TAB> if ( <TAB>  <TAB> self._proc is not None <TAB>  <TAB> and <TAB>  <TAB> # has the child process finished? <TAB>  <TAB> self._returncode is None <TAB>  <TAB> and <TAB>  <TAB> # the child process has finished, but the <TAB>  <TAB> # transport hasn't been notified yet? <TAB>  <TAB> self._proc.poll() is None <TAB> ): <MASK> logger.warning(""Close running child process: kill %r"", self) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self._proc.kill() <TAB>  <TAB> except ProcessLookupError: <TAB>  <TAB>  <TAB> pass",if self . _loop . get_debug ( ) :,191
3720,"def runTest(self): <TAB> self.poco(text=""wait UI"").click() <TAB> bomb_count = 0 <TAB> while True: <TAB>  <TAB> blue_fish = self.poco(""fish_emitter"").child(""blue"") <TAB>  <TAB> yellow_fish = self.poco(""fish_emitter"").child(""yellow"") <TAB>  <TAB> bomb = self.poco(""fish_emitter"").child(""bomb"") <TAB>  <TAB> fish = self.poco.wait_for_any([blue_fish, yellow_fish, bomb]) <TAB>  <TAB> if fish is bomb: <TAB>  <TAB>  <TAB> bomb_count += 1 <MASK> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> fish.click() <TAB>  <TAB> time.sleep(2.5)",if bomb_count > 3 :,192
3721,"def load_managers(*, loop, only): <TAB> managers = {} <TAB> for key in DB_CLASSES: <MASK> continue <TAB>  <TAB> params = DB_DEFAULTS.get(key) or {} <TAB>  <TAB> params.update(DB_OVERRIDES.get(key) or {}) <TAB>  <TAB> database = DB_CLASSES[key](**params) <TAB>  <TAB> managers[key] = peewee_async.Manager(database, loop=loop) <TAB> return managers",if only and key not in only :,112
3722,"def links_extracted(self, request, links): <TAB> for link in links: <MASK> r = self._create_request(link.url) <TAB>  <TAB>  <TAB> r.meta[b""depth""] = request.meta[b""depth""] + 1 <TAB>  <TAB>  <TAB> self.schedule(r, self._get_score(r.meta[b""depth""])) <TAB>  <TAB>  <TAB> link.meta[b""state""] = States.QUEUED","if link . meta [ b""state"" ] == States . NOT_CRAWLED :",123
3723,"def find_worktree_git_dir(dotgit): <TAB> """"""Search for a gitdir for this worktree."""""" <TAB> try: <TAB>  <TAB> statbuf = os.stat(dotgit) <TAB> except OSError: <TAB>  <TAB> return None <TAB> if not stat.S_ISREG(statbuf.st_mode): <TAB>  <TAB> return None <TAB> try: <TAB>  <TAB> lines = open(dotgit, ""r"").readlines() <TAB>  <TAB> for key, value in [line.strip().split("": "") for line in lines]: <MASK> return value <TAB> except ValueError: <TAB>  <TAB> pass <TAB> return None","if key == ""gitdir"" :",147
3724,"def _is_static_shape(self, shape): <TAB> if shape is None or not isinstance(shape, list): <TAB>  <TAB> return False <TAB> for dim_value in shape: <TAB>  <TAB> if not isinstance(dim_value, int): <TAB>  <TAB>  <TAB> return False <MASK> raise Exception(""Negative dimension is illegal: %d"" % dim_value) <TAB> return True",if dim_value < 0 :,94
3725,"def init_logger(): <TAB> configured_loggers = [log_config.get(""root"", {})] + [ <TAB>  <TAB> logger for logger in log_config.get(""loggers"", {}).values() <TAB> ] <TAB> used_handlers = { <TAB>  <TAB> handler for log in configured_loggers for handler in log.get(""handlers"", []) <TAB> } <TAB> for handler_id, handler in list(log_config[""handlers""].items()): <TAB>  <TAB> if handler_id not in used_handlers: <TAB>  <TAB>  <TAB> del log_config[""handlers""][handler_id] <MASK> filename = handler[""filename""] <TAB>  <TAB>  <TAB> logfile_path = Path(filename).expanduser().resolve() <TAB>  <TAB>  <TAB> handler[""filename""] = str(logfile_path) <TAB> logging.config.dictConfig(log_config)","elif ""filename"" in handler . keys ( ) :",192
3726,"def __call__(self): <TAB> dmin, dmax = self.viewlim_to_dt() <TAB> ymin = self.base.le(dmin.year) <TAB> ymax = self.base.ge(dmax.year) <TAB> ticks = [dmin.replace(year=ymin, **self.replaced)] <TAB> while 1: <TAB>  <TAB> dt = ticks[-1] <MASK> return date2num(ticks) <TAB>  <TAB> year = dt.year + self.base.get_base() <TAB>  <TAB> ticks.append(dt.replace(year=year, **self.replaced))",if dt . year >= ymax :,144
3727,"def taiga(request, trigger_id, key): <TAB> signature = request.META.get(""HTTP_X_TAIGA_WEBHOOK_SIGNATURE"") <TAB> # check that the data are ok with the provided signature <TAB> if verify_signature(request._request.body, key, signature): <TAB>  <TAB> data = data_filter(trigger_id, **request.data) <TAB>  <TAB> status = save_data(trigger_id, data) <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB> Response({""message"": ""Success""}) <MASK> else Response({""message"": ""Failed!""}) <TAB>  <TAB> ) <TAB> Response({""message"": ""Bad request""})",if status,149
3728,"def ParseResponses( <TAB> self, <TAB> knowledge_base: rdf_client.KnowledgeBase, <TAB> responses: Iterable[rdfvalue.RDFValue],) -> Iterator[rdf_client.User]: <TAB> for response in responses: <MASK> raise TypeError(f""Unexpected response type: `{type(response)}`"") <TAB>  <TAB> # TODO: `st_mode` has to be an `int`, not `StatMode`. <TAB>  <TAB> if stat.S_ISDIR(int(response.st_mode)): <TAB>  <TAB>  <TAB> homedir = response.pathspec.path <TAB>  <TAB>  <TAB> username = os.path.basename(homedir) <TAB>  <TAB>  <TAB> if username not in self._ignore_users: <TAB>  <TAB>  <TAB>  <TAB> yield rdf_client.User(username=username, homedir=homedir)","if not isinstance ( response , rdf_client_fs . StatEntry ) :",198
3729,"def _iter_lines(path=path, response=response, max_next=options.http_max_next): <TAB> path.responses = [] <TAB> n = 0 <TAB> while response: <TAB>  <TAB> path.responses.append(response) <TAB>  <TAB> yield from response.iter_lines(decode_unicode=True) <TAB>  <TAB> src = response.links.get(""next"", {}).get(""url"", None) <TAB>  <TAB> if not src: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> n += 1 <MASK> vd.warning(f""stopping at max {max_next} pages"") <TAB>  <TAB>  <TAB> break <TAB>  <TAB> vd.status(f""fetching next page from {src}"") <TAB>  <TAB> response = requests.get(src, stream=True)",if n > max_next :,179
3730,"def __enter__(self): <TAB> """"""Open a file and read it."""""" <TAB> if self.code is None: <TAB>  <TAB> LOGGER.info(""File is reading: %s"", self.path) <MASK> self._file = open(self.path, encoding=""utf-8"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._file = open(self.path, ""rU"") <TAB>  <TAB> self.code = self._file.read() <TAB> return self","if sys . version_info >= ( 3 , ) :",117
3731,"def facts_for_oauthclients(self, namespace): <TAB> """"""Gathers facts for oauthclients used with logging"""""" <TAB> self.default_keys_for(""oauthclients"") <TAB> a_list = self.oc_command( <TAB>  <TAB> ""get"", ""oauthclients"", namespace=namespace, add_options=[""-l"", LOGGING_SELECTOR] <TAB> ) <TAB> if len(a_list[""items""]) == 0: <TAB>  <TAB> return <TAB> for item in a_list[""items""]: <TAB>  <TAB> name = item[""metadata""][""name""] <TAB>  <TAB> comp = self.comp(name) <MASK> result = dict(redirectURIs=item[""redirectURIs""]) <TAB>  <TAB>  <TAB> self.add_facts_for(comp, ""oauthclients"", name, result)",if comp is not None :,173
3732,"def get(self, k): <TAB> with self._lock: <MASK> self._data1[k] = self._data2[k] <TAB>  <TAB>  <TAB> del self._data2[k] <TAB> return self._data1.get(k)",if k not in self . _data1 and k in self . _data2 :,77
3733,"def _parseparam(s): <TAB> plist = [] <TAB> while s[:1] == "";"": <TAB>  <TAB> s = s[1:] <TAB>  <TAB> end = s.find("";"") <TAB>  <TAB> while end > 0 and (s.count('""', 0, end) - s.count('\\""', 0, end)) % 2: <TAB>  <TAB>  <TAB> end = s.find("";"", end + 1) <MASK> end = len(s) <TAB>  <TAB> f = s[:end] <TAB>  <TAB> if ""="" in f: <TAB>  <TAB>  <TAB> i = f.index(""="") <TAB>  <TAB>  <TAB> f = f[:i].strip().lower() + ""="" + f[i + 1 :].strip() <TAB>  <TAB> plist.append(f.strip()) <TAB>  <TAB> s = s[end:] <TAB> return plist",if end < 0 :,177
3734,"def __init__(self, **params): <TAB> if ""length"" in params: <MASK> raise ValueError(""Supply either length or start and end to Player not both"") <TAB>  <TAB> params[""start""] = 0 <TAB>  <TAB> params[""end""] = params.pop(""length"") - 1 <TAB> elif params.get(""start"", 0) > 0 and not ""value"" in params: <TAB>  <TAB> params[""value""] = params[""start""] <TAB> super(Player, self).__init__(**params)","if ""start"" in params or ""end"" in params :",126
3735,"def libcxx_define(settings): <TAB> compiler = _base_compiler(settings) <TAB> libcxx = settings.get_safe(""compiler.libcxx"") <TAB> if not compiler or not libcxx: <TAB>  <TAB> return """" <TAB> if str(compiler) in GCC_LIKE: <TAB>  <TAB> if str(libcxx) == ""libstdc++"": <TAB>  <TAB>  <TAB> return ""_GLIBCXX_USE_CXX11_ABI=0"" <MASK> return ""_GLIBCXX_USE_CXX11_ABI=1"" <TAB> return """"","elif str ( libcxx ) == ""libstdc++11"" :",146
3736,"def _get_sort_map(tags): <TAB> """"""See TAG_TO_SORT"""""" <TAB> tts = {} <TAB> for name, tag in tags.items(): <TAB>  <TAB> if tag.has_sort: <TAB>  <TAB>  <TAB> if tag.user: <TAB>  <TAB>  <TAB>  <TAB> tts[name] = ""%ssort"" % name <MASK> tts[""~%s"" % name] = ""~%ssort"" % name <TAB> return tts",if tag . internal :,111
3737,"def quiet_f(*args): <TAB> vars = {arg_name: Real(arg) for arg_name, arg in zip(arg_names, args)} <TAB> value = dynamic_scoping(quiet_expr.evaluate, vars, evaluation) <TAB> if expect_list: <TAB>  <TAB> if value.has_form(""List"", None): <TAB>  <TAB>  <TAB> value = [extract_pyreal(item) for item in value.leaves] <TAB>  <TAB>  <TAB> if any(item is None for item in value): <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB>  <TAB> return value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return None <TAB> else: <TAB>  <TAB> value = extract_pyreal(value) <MASK> return None <TAB>  <TAB> return value",if value is None or isinf ( value ) or isnan ( value ) :,177
3738,"def on_action_chosen(self, id, action, mark_changed=True): <TAB> before = self.set_action(self.current, id, action) <TAB> if mark_changed: <MASK> # TODO: Maybe better comparison <TAB>  <TAB>  <TAB> self.undo.append(UndoRedo(id, before, action)) <TAB>  <TAB>  <TAB> self.builder.get_object(""btUndo"").set_sensitive(True) <TAB>  <TAB> self.on_profile_modified() <TAB> else: <TAB>  <TAB> self.on_profile_modified(update_ui=False) <TAB> return before",if before . to_string ( ) != action . to_string ( ) :,149
3739,"def setUp(self): <TAB> super(OperaterTest, self).setUp() <TAB> if is_cli: <TAB>  <TAB> import clr <TAB>  <TAB> self.load_iron_python_test() <MASK> clr.AddReference(""System.Drawing.Primitives"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> clr.AddReference(""System.Drawing"")",if is_netcoreapp :,93
3740,"def field_to_field_type(field): <TAB> field_type = field[""type""] <TAB> if isinstance(field_type, dict): <TAB>  <TAB> field_type = field_type[""type""] <TAB> if isinstance(field_type, list): <TAB>  <TAB> field_type_length = len(field_type) <TAB>  <TAB> if field_type_length == 0: <TAB>  <TAB>  <TAB> raise Exception(""Zero-length type list encountered, invalid CWL?"") <MASK> field_type = field_type[0] <TAB> return field_type",elif len ( field_type ) == 1 :,135
3741,"def _flatten(*args): <TAB> ahs = set() <TAB> if len(args) > 0: <TAB>  <TAB> for item in args: <MASK> ahs.add(item) <TAB>  <TAB>  <TAB> elif type(item) in (list, tuple, dict, set): <TAB>  <TAB>  <TAB>  <TAB> for ah in item: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if type(ah) is not ActionHandle:  # pragma:nocover <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise ActionManagerError(""Bad argument type %s"" % str(ah)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ahs.add(ah) <TAB>  <TAB>  <TAB> else:  # pragma:nocover <TAB>  <TAB>  <TAB>  <TAB> raise ActionManagerError(""Bad argument type %s"" % str(item)) <TAB> return ahs",if type ( item ) is ActionHandle :,183
3742,"def _Determine_Do(self): <TAB> self.applicable = 1 <TAB> configTokens = black.configure.items[""configTokens""].Get() <TAB> buildFlavour = black.configure.items[""buildFlavour""].Get() <TAB> if buildFlavour == ""full"": <TAB>  <TAB> self.value = False <TAB> else: <TAB>  <TAB> self.value = True <TAB> for opt, optarg in self.chosenOptions: <MASK> if not self.value: <TAB>  <TAB>  <TAB>  <TAB> configTokens.append(""tests"") <TAB>  <TAB>  <TAB> self.value = True <TAB>  <TAB> elif opt == ""--without-tests"": <TAB>  <TAB>  <TAB> if self.value: <TAB>  <TAB>  <TAB>  <TAB> configTokens.append(""notests"") <TAB>  <TAB>  <TAB> self.value = False <TAB> self.determined = 1","if opt == ""--with-tests"" :",183
3743,"def title_by_index(self, trans, index, context): <TAB> d_type = self.get_datatype(trans, context) <TAB> for i, (composite_name, composite_file) in enumerate(d_type.writable_files.items()): <MASK> rval = composite_name <TAB>  <TAB>  <TAB> if composite_file.description: <TAB>  <TAB>  <TAB>  <TAB> rval = ""{} ({})"".format(rval, composite_file.description) <TAB>  <TAB>  <TAB> if composite_file.optional: <TAB>  <TAB>  <TAB>  <TAB> rval = ""%s [optional]"" % rval <TAB>  <TAB>  <TAB> return rval <TAB> if index < self.get_file_count(trans, context): <TAB>  <TAB> return ""Extra primary file"" <TAB> return None",if i == index :,167
3744,"def func(x, y): <TAB> try: <MASK> z = x + 2 * math.sin(y) <TAB>  <TAB>  <TAB> return z ** 2 <TAB>  <TAB> elif x == y: <TAB>  <TAB>  <TAB> return 4 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return 2 ** 3 <TAB> except ValueError: <TAB>  <TAB> foo = 0 <TAB>  <TAB> for i in range(4): <TAB>  <TAB>  <TAB> foo += i <TAB>  <TAB> return foo <TAB> except TypeError: <TAB>  <TAB> return 42 <TAB> else: <TAB>  <TAB> return 33 <TAB> finally: <TAB>  <TAB> print(""finished"")",if x > y :,134
3745,"def test_suite(): <TAB> suite = unittest.TestSuite() <TAB> for fn in os.listdir(here): <MASK> modname = ""distutils.tests."" + fn[:-3] <TAB>  <TAB>  <TAB> __import__(modname) <TAB>  <TAB>  <TAB> module = sys.modules[modname] <TAB>  <TAB>  <TAB> suite.addTest(module.test_suite()) <TAB> return suite","if fn . startswith ( ""test"" ) and fn . endswith ( "".py"" ) :",98
3746,"def check_stack_names(self, frame, expected): <TAB> names = [] <TAB> while frame: <TAB>  <TAB> name = frame.f_code.co_name <TAB>  <TAB> # Stop checking frames when we get to our test helper. <MASK> break <TAB>  <TAB> names.append(name) <TAB>  <TAB> frame = frame.f_back <TAB> self.assertEqual(names, expected)","if name . startswith ( ""check_"" ) or name . startswith ( ""call_"" ) :",104
3747,"def leave(self, reason=None): <TAB> try: <TAB>  <TAB> if self.id.startswith(""C""): <TAB>  <TAB>  <TAB> log.info(""Leaving channel %s (%s)"", self, self.id) <TAB>  <TAB>  <TAB> self._bot.api_call(""conversations.leave"", data={""channel"": self.id}) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.info(""Leaving group %s (%s)"", self, self.id) <TAB>  <TAB>  <TAB> self._bot.api_call(""conversations.leave"", data={""channel"": self.id}) <TAB> except SlackAPIResponseError as e: <MASK> raise RoomError(f""Unable to leave channel. {USER_IS_BOT_HELPTEXT}"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise RoomError(e) <TAB> self._id = None","if e . error == ""user_is_bot"" :",197
3748,"def ident(self): <TAB> value = self._ident <TAB> if value is False: <TAB>  <TAB> value = None <TAB>  <TAB> # XXX: how will this interact with orig_prefix ? <TAB>  <TAB> # <TAB>   not exposing attrs for now if orig_prefix is set. <MASK> wrapped = self.wrapped <TAB>  <TAB>  <TAB> ident = getattr(wrapped, ""ident"", None) <TAB>  <TAB>  <TAB> if ident is not None: <TAB>  <TAB>  <TAB>  <TAB> value = self._wrap_hash(ident) <TAB>  <TAB> self._ident = value <TAB> return value",if not self . orig_prefix :,135
3749,"def is_ac_power_connected(): <TAB> for power_source_path in Path(""/sys/class/power_supply/"").iterdir(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> with open(power_source_path / ""type"", ""r"") as f: <MASK> continue <TAB>  <TAB>  <TAB> with open(power_source_path / ""online"", ""r"") as f: <TAB>  <TAB>  <TAB>  <TAB> if f.read(1) == ""1"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> except IOError: <TAB>  <TAB>  <TAB> continue <TAB> return False","if f . read ( ) . strip ( ) != ""Mains"" :",144
3750,"def _get_pending_by_app_token(self, app_token): <TAB> result = [] <TAB> with self._pending_lock: <TAB>  <TAB> self._remove_stale_pending() <TAB>  <TAB> for data in self._pending_decisions: <MASK> result.append(data) <TAB> return result",if data . app_token == app_token :,86
3751,"def do_create(specific_tables=None, base=Base): <TAB> engine = get_engine() <TAB> try: <MASK> logger.info( <TAB>  <TAB>  <TAB>  <TAB> ""Initializing only a subset of tables as requested: {}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> specific_tables <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> base.metadata.create_all(engine, tables=specific_tables) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> base.metadata.create_all(engine) <TAB> except Exception as err: <TAB>  <TAB> raise Exception(""could not create/re-create DB tables - exception: "" + str(err))",if specific_tables :,152
3752,"def __setitem__(self, ndx, val): <TAB> # <TAB> # Get the expression data object <TAB> # <TAB> exprdata = None <TAB> if ndx in self._data: <TAB>  <TAB> exprdata = self._data[ndx] <TAB> else: <TAB>  <TAB> _ndx = normalize_index(ndx) <MASK> exprdata = self._data[_ndx] <TAB> if exprdata is None: <TAB>  <TAB> raise KeyError( <TAB>  <TAB>  <TAB> ""Cannot set the value of Expression '%s' with "" <TAB>  <TAB>  <TAB> ""invalid index '%s'"" % (self.cname(True), str(ndx)) <TAB>  <TAB> ) <TAB> # <TAB> # Set the value <TAB> # <TAB> exprdata.set_value(val)",if _ndx in self . _data :,179
3753,"def write(self, *bits): <TAB> for bit in bits: <MASK> self.bytestream.append(0) <TAB>  <TAB> byte = self.bytestream[self.bytenum] <TAB>  <TAB> if self.bitnum == 8: <TAB>  <TAB>  <TAB> if self.bytenum == len(self.bytestream) - 1: <TAB>  <TAB>  <TAB>  <TAB> byte = 0 <TAB>  <TAB>  <TAB>  <TAB> self.bytestream += bytes([byte]) <TAB>  <TAB>  <TAB> self.bytenum += 1 <TAB>  <TAB>  <TAB> self.bitnum = 0 <TAB>  <TAB> mask = 2 ** self.bitnum <TAB>  <TAB> if bit: <TAB>  <TAB>  <TAB> byte |= mask <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> byte &= ~mask <TAB>  <TAB> self.bytestream[self.bytenum] = byte <TAB>  <TAB> self.bitnum += 1",if not self . bytestream :,186
3754,"def terminate_subprocess(proc, timeout=0.1, log=None): <TAB> if proc.poll() is None: <MASK> log.info(""Sending SIGTERM to %r"", proc) <TAB>  <TAB> proc.terminate() <TAB>  <TAB> timeout_time = time.time() + timeout <TAB>  <TAB> while proc.poll() is None and time.time() < timeout_time: <TAB>  <TAB>  <TAB> time.sleep(0.02) <TAB>  <TAB> if proc.poll() is None: <TAB>  <TAB>  <TAB> if log: <TAB>  <TAB>  <TAB>  <TAB> log.info(""Sending SIGKILL to %r"", proc) <TAB>  <TAB>  <TAB> proc.kill() <TAB> return proc.returncode",if log :,152
3755,"def mkpanel(color, rows, cols, tly, tlx): <TAB> win = curses.newwin(rows, cols, tly, tlx) <TAB> pan = panel.new_panel(win) <TAB> if curses.has_colors(): <MASK> fg = curses.COLOR_WHITE <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> fg = curses.COLOR_BLACK <TAB>  <TAB> bg = color <TAB>  <TAB> curses.init_pair(color, fg, bg) <TAB>  <TAB> win.bkgdset(ord("" ""), curses.color_pair(color)) <TAB> else: <TAB>  <TAB> win.bkgdset(ord("" ""), curses.A_BOLD) <TAB> return pan",if color == curses . COLOR_BLUE :,162
3756,"def all_words(filename): <TAB> start_char = True <TAB> for c in characters(filename): <TAB>  <TAB> if start_char == True: <TAB>  <TAB>  <TAB> word = """" <MASK> # We found the start of a word <TAB>  <TAB>  <TAB>  <TAB> word = c.lower() <TAB>  <TAB>  <TAB>  <TAB> start_char = False <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if c.isalnum(): <TAB>  <TAB>  <TAB>  <TAB> word += c.lower() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> # We found end of word, emit it <TAB>  <TAB>  <TAB>  <TAB> start_char = True <TAB>  <TAB>  <TAB>  <TAB> yield word",if c . isalnum ( ) :,158
3757,"def get_tf_weights_as_numpy(path=""./ckpt/aeslc/model.ckpt-32000"") -> Dict: <TAB> init_vars = tf.train.list_variables(path) <TAB> tf_weights = {} <TAB> ignore_name = [""Adafactor"", ""global_step""] <TAB> for name, shape in tqdm(init_vars, desc=""converting tf checkpoint to dict""): <TAB>  <TAB> skip_key = any([pat in name for pat in ignore_name]) <MASK> continue <TAB>  <TAB> array = tf.train.load_variable(path, name) <TAB>  <TAB> tf_weights[name] = array <TAB> return tf_weights",if skip_key :,156
3758,"def app(scope, receive, send): <TAB> while True: <TAB>  <TAB> message = await receive() <TAB>  <TAB> if message[""type""] == ""websocket.connect"": <TAB>  <TAB>  <TAB> await send({""type"": ""websocket.accept""}) <MASK> pass <TAB>  <TAB> elif message[""type""] == ""websocket.disconnect"": <TAB>  <TAB>  <TAB> break","elif message [ ""type"" ] == ""websocket.receive"" :",93
3759,"def autoload(self): <TAB> if self._app.config.THEME == ""auto"": <TAB>  <TAB> if sys.platform == ""darwin"": <MASK> theme = DARK <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> theme = LIGHT <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> theme = self.guess_system_theme() <TAB>  <TAB>  <TAB> if theme == Dark: <TAB>  <TAB>  <TAB>  <TAB> theme = MacOSDark <TAB> else:  # user settings have highest priority <TAB>  <TAB> theme = self._app.config.THEME <TAB> self.load_theme(theme)",if get_osx_theme ( ) == 1 :,141
3760,"def example_reading_spec(self): <TAB> data_fields = {""targets"": tf.VarLenFeature(tf.int64)} <MASK> data_fields[""inputs""] = tf.VarLenFeature(tf.int64) <TAB> if self.packed_length: <TAB>  <TAB> if self.has_inputs: <TAB>  <TAB>  <TAB> data_fields[""inputs_segmentation""] = tf.VarLenFeature(tf.int64) <TAB>  <TAB>  <TAB> data_fields[""inputs_position""] = tf.VarLenFeature(tf.int64) <TAB>  <TAB> data_fields[""targets_segmentation""] = tf.VarLenFeature(tf.int64) <TAB>  <TAB> data_fields[""targets_position""] = tf.VarLenFeature(tf.int64) <TAB> data_items_to_decoders = None <TAB> return (data_fields, data_items_to_decoders)",if self . has_inputs :,188
3761,"def _prepare_travel_graph(self): <TAB> for op in self.op_dict.values(): <TAB>  <TAB> op.const = False <TAB>  <TAB> if op.node.op in [""Const"", ""Placeholder""]: <TAB>  <TAB>  <TAB> op.resolved = True <MASK> op.const = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> op.resolved = False","if op . node . op == ""Const"" :",96
3762,"def get_filestream_file_items(self): <TAB> data = {} <TAB> fs_file_updates = self.get_filestream_file_updates() <TAB> for k, v in six.iteritems(fs_file_updates): <TAB>  <TAB> l = [] <TAB>  <TAB> for d in v: <TAB>  <TAB>  <TAB> offset = d.get(""offset"") <TAB>  <TAB>  <TAB> content = d.get(""content"") <TAB>  <TAB>  <TAB> assert offset is not None <TAB>  <TAB>  <TAB> assert content is not None <TAB>  <TAB>  <TAB> assert offset == 0 or offset == len(l), (k, v, l, d) <MASK> l = [] <TAB>  <TAB>  <TAB> l.extend(map(json.loads, content)) <TAB>  <TAB> data[k] = l <TAB> return data",if not offset :,179
3763,"def _rewrite_exprs(self, table, what): <TAB> from ibis.expr.analysis import substitute_parents <TAB> what = util.promote_list(what) <TAB> all_exprs = [] <TAB> for expr in what: <MASK> all_exprs.extend(expr.exprs()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> bound_expr = ir.bind_expr(table, expr) <TAB>  <TAB>  <TAB> all_exprs.append(bound_expr) <TAB> return [substitute_parents(x, past_projection=False) for x in all_exprs]","if isinstance ( expr , ir . ExprList ) :",139
3764,"def _group_by_commit_and_time(self, hits): <TAB> result = {} <TAB> for hit in hits: <TAB>  <TAB> source_hit = hit[""_source""] <TAB>  <TAB> key = ""%s_%s"" % (source_hit[""commit_info""][""id""], source_hit[""datetime""]) <TAB>  <TAB> benchmark = self._benchmark_from_es_record(source_hit) <MASK> result[key][""benchmarks""].append(benchmark) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> run_info = self._run_info_from_es_record(source_hit) <TAB>  <TAB>  <TAB> run_info[""benchmarks""] = [benchmark] <TAB>  <TAB>  <TAB> result[key] = run_info <TAB> return result",if key in result :,170
3765,"def _build_index(self): <TAB> self._index = {} <TAB> for start_char, sorted_offsets in self._offsets.items(): <TAB>  <TAB> self._index[start_char] = {} <TAB>  <TAB> for i, offset in enumerate(sorted_offsets.get_offsets()): <TAB>  <TAB>  <TAB> identifier = sorted_offsets.get_identifier_by_offset(offset) <MASK> self._index[start_char][identifier[0 : self.index_depth]] = i",if identifier [ 0 : self . index_depth ] not in self . _index [ start_char ] :,134
3766,"def scan_resource_conf(self, conf): <TAB> if ""properties"" in conf: <MASK> if ""exp"" in conf[""properties""][""attributes""]: <TAB>  <TAB>  <TAB>  <TAB> if conf[""properties""][""attributes""][""exp""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return CheckResult.PASSED <TAB> return CheckResult.FAILED","if ""attributes"" in conf [ ""properties"" ] :",82
3767,"def _PatchArtifact(self, artifact: rdf_artifacts.Artifact) -> rdf_artifacts.Artifact: <TAB> """"""Patches artifact to not contain byte-string source attributes."""""" <TAB> patched = False <TAB> for source in artifact.sources: <TAB>  <TAB> attributes = source.attributes.ToDict() <TAB>  <TAB> unicode_attributes = compatibility.UnicodeJson(attributes) <MASK> source.attributes = unicode_attributes <TAB>  <TAB>  <TAB> patched = True <TAB> if patched: <TAB>  <TAB> self.DeleteArtifact(str(artifact.name)) <TAB>  <TAB> self.WriteArtifact(artifact) <TAB> return artifact",if attributes != unicode_attributes :,139
3768,"def edit_file(self, filename): <TAB> import subprocess <TAB> editor = self.get_editor() <TAB> if self.env: <TAB>  <TAB> environ = os.environ.copy() <TAB>  <TAB> environ.update(self.env) <TAB> else: <TAB>  <TAB> environ = None <TAB> try: <TAB>  <TAB> c = subprocess.Popen('%s ""%s""' % (editor, filename), env=environ, shell=True) <TAB>  <TAB> exit_code = c.wait() <MASK> raise ClickException(""%s: Editing failed!"" % editor) <TAB> except OSError as e: <TAB>  <TAB> raise ClickException(""%s: Editing failed: %s"" % (editor, e))",if exit_code != 0 :,157
3769,"def findControlPointsInMesh(glyph, va, subsegments): <TAB> controlPointIndices = np.zeros((len(va), 1)) <TAB> index = 0 <TAB> for i, c in enumerate(subsegments): <TAB>  <TAB> segmentCount = len(glyph.contours[i].segments) - 1 <TAB>  <TAB> for j, s in enumerate(c): <MASK> if glyph.contours[i].segments[j].type == ""line"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> controlPointIndices[index] = 1 <TAB>  <TAB>  <TAB> index += s[1] <TAB> return controlPointIndices",if j < segmentCount :,143
3770,"def to_representation(self, value): <TAB> old_social_string_fields = [""twitter"", ""github"", ""linkedIn""] <TAB> request = self.context.get(""request"") <TAB> show_old_format = ( <TAB>  <TAB> request <TAB>  <TAB> and is_deprecated(request.version, self.min_version) <TAB>  <TAB> and request.method == ""GET"" <TAB> ) <TAB> if show_old_format: <TAB>  <TAB> social = value.copy() <TAB>  <TAB> for key in old_social_string_fields: <MASK> social[key] = value[key][0] <TAB>  <TAB>  <TAB> elif social.get(key) == []: <TAB>  <TAB>  <TAB>  <TAB> social[key] = """" <TAB>  <TAB> value = social <TAB> return super(SocialField, self).to_representation(value)",if social . get ( key ) :,200
3771,"def iter_raw_frames(path, packet_sizes, ctx): <TAB> with open(path, ""rb"") as f: <TAB>  <TAB> for i, size in enumerate(packet_sizes): <TAB>  <TAB>  <TAB> packet = Packet(size) <TAB>  <TAB>  <TAB> read_size = f.readinto(packet) <TAB>  <TAB>  <TAB> assert size <TAB>  <TAB>  <TAB> assert read_size == size <TAB>  <TAB>  <TAB> if not read_size: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> for frame in ctx.decode(packet): <TAB>  <TAB>  <TAB>  <TAB> yield frame <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> frames = ctx.decode(None) <TAB>  <TAB>  <TAB> except EOFError: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> for frame in frames: <TAB>  <TAB>  <TAB>  <TAB> yield frame <MASK> break",if not frames :,189
3772,"def get_shadows_zip(filename): <TAB> import zipfile <TAB> shadow_pkgs = set() <TAB> with zipfile.ZipFile(filename) as lib_zip: <TAB>  <TAB> already_test = [] <TAB>  <TAB> for fname in lib_zip.namelist(): <TAB>  <TAB>  <TAB> pname, fname = os.path.split(fname) <TAB>  <TAB>  <TAB> if fname or (pname and fname): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if pname not in already_test and ""/"" not in pname: <TAB>  <TAB>  <TAB>  <TAB> already_test.append(pname) <MASK> shadow_pkgs.add(pname) <TAB> return shadow_pkgs",if is_shadowing ( pname ) :,159
3773,"def metrics_to_scalars(self, metrics): <TAB> new_metrics = {} <TAB> for k, v in metrics.items(): <TAB>  <TAB> if isinstance(v, torch.Tensor): <TAB>  <TAB>  <TAB> v = v.item() <MASK> v = self.metrics_to_scalars(v) <TAB>  <TAB> new_metrics[k] = v <TAB> return new_metrics","if isinstance ( v , dict ) :",95
3774,"def insert_resets(f): <TAB> newsync = dict() <TAB> for k, v in f.sync.items(): <MASK> newsync[k] = insert_reset(ResetSignal(k), v) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> newsync[k] = v <TAB> f.sync = newsync",if f . clock_domains [ k ] . rst is not None :,91
3775,"def get_attached_nodes(self, external_account): <TAB> for node in self.get_nodes_with_oauth_grants(external_account): <TAB>  <TAB> if node is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> node_settings = node.get_addon(self.oauth_provider.short_name) <MASK> continue <TAB>  <TAB> if node_settings.external_account == external_account: <TAB>  <TAB>  <TAB> yield node",if node_settings is None :,110
3776,"def visitIf(self, node, scope): <TAB> for test, body in node.tests: <TAB>  <TAB> if isinstance(test, ast.Const): <TAB>  <TAB>  <TAB> if type(test.value) in self._const_types: <MASK> continue <TAB>  <TAB> self.visit(test, scope) <TAB>  <TAB> self.visit(body, scope) <TAB> if node.else_: <TAB>  <TAB> self.visit(node.else_, scope)",if not test . value :,112
3777,"def flatten(self): <TAB> # this is similar to fill_messages except it uses a list instead <TAB> # of a queue to place the messages in. <TAB> result = [] <TAB> channel = await self.messageable._get_channel() <TAB> self.channel = channel <TAB> while self._get_retrieve(): <TAB>  <TAB> data = await self._retrieve_messages(self.retrieve) <TAB>  <TAB> if len(data) < 100: <TAB>  <TAB>  <TAB> self.limit = 0  # terminate the infinite loop <MASK> data = reversed(data) <TAB>  <TAB> if self._filter: <TAB>  <TAB>  <TAB> data = filter(self._filter, data) <TAB>  <TAB> for element in data: <TAB>  <TAB>  <TAB> result.append(self.state.create_message(channel=channel, data=element)) <TAB> return result",if self . reverse :,187
3778,"def compute(self, x, y=None, targets=None): <TAB> if targets is None: <TAB>  <TAB> targets = self.out_params <TAB> in_params = list(self.in_x) <TAB> if len(in_params) == 1: <TAB>  <TAB> args = [x] <TAB> else: <TAB>  <TAB> args = list(zip(*x)) <TAB> if y is None: <TAB>  <TAB> pipe = self.pipe <TAB> else: <TAB>  <TAB> pipe = self.train_pipe <MASK> args.append(y) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> args += list(zip(*y)) <TAB>  <TAB> in_params += self.in_y <TAB> return self._compute(*args, pipe=pipe, param_names=in_params, targets=targets)",if len ( self . in_y ) == 1 :,190
3779,"def _import_top_module(self, name): <TAB> # scan sys.path looking for a location in the filesystem that contains <TAB> # the module, or an Importer object that can import the module. <TAB> for item in sys.path: <MASK> module = self.fs_imp.import_from_dir(item, name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> module = item.import_top(name) <TAB>  <TAB> if module: <TAB>  <TAB>  <TAB> return module <TAB> return None","if isinstance ( item , _StringType ) :",124
3780,"def __getitem__(self, key, _get_mode=False): <TAB> if not _get_mode: <TAB>  <TAB> if isinstance(key, (int, long)): <TAB>  <TAB>  <TAB> return self._list[key] <TAB>  <TAB> elif isinstance(key, slice): <TAB>  <TAB>  <TAB> return self.__class__(self._list[key]) <TAB> ikey = key.lower() <TAB> for k, v in self._list: <MASK> return v <TAB> # micro optimization: if we are in get mode we will catch that <TAB> # exception one stack level down so we can raise a standard <TAB> # key error instead of our special one. <TAB> if _get_mode: <TAB>  <TAB> raise KeyError() <TAB> raise BadRequestKeyError(key)",if k . lower ( ) == ikey :,176
3781,"def execute(self, arbiter, props): <TAB> watcher = self._get_watcher(arbiter, props.pop(""name"")) <TAB> action = 0 <TAB> for key, val in props.get(""options"", {}).items(): <TAB>  <TAB> if key == ""hooks"": <TAB>  <TAB>  <TAB> new_action = 0 <TAB>  <TAB>  <TAB> for name, _val in val.items(): <TAB>  <TAB>  <TAB>  <TAB> action = watcher.set_opt(""hooks.%s"" % name, _val) <MASK> new_action = 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_action = watcher.set_opt(key, val) <TAB>  <TAB> if new_action == 1: <TAB>  <TAB>  <TAB> action = 1 <TAB> # trigger needed action <TAB> return watcher.do_action(action)",if action == 1 :,186
3782,"def OnBodyClick(self, event=None): <TAB> try: <TAB>  <TAB> c = self.c <TAB>  <TAB> p = c.currentPosition() <MASK> self.OnActivateBody(event=event) <TAB>  <TAB> g.doHook(""bodyclick2"", c=c, p=p, v=p, event=event) <TAB> except: <TAB>  <TAB> g.es_event_exception(""bodyclick"")","if not g . doHook ( ""bodyclick1"" , c = c , p = p , v = p , event = event ) :",124
3783,"def _class_weights(spec: config.MetricsSpec) -> Optional[Dict[int, float]]: <TAB> """"""Returns class weights associated with AggregationOptions at offset."""""" <TAB> if spec.aggregate.HasField(""top_k_list""): <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""class_weights are not supported when top_k_list used: "" <TAB>  <TAB>  <TAB>  <TAB> ""spec={}"".format(spec) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return None <TAB> return dict(spec.aggregate.class_weights) or None",if spec . aggregate . class_weights :,130
3784,"def _is_perf_file(file_path): <TAB> f = get_file(file_path) <TAB> for line in f: <TAB>  <TAB> if line[0] == ""#"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> r = event_regexp.search(line) <MASK> f.close() <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> f.close() <TAB>  <TAB> return False",if r :,92
3785,"def _get_before_insertion_node(self): <TAB> if self._nodes_stack.is_empty(): <TAB>  <TAB> return None <TAB> line = self._nodes_stack.parsed_until_line + 1 <TAB> node = self._new_module.get_last_leaf() <TAB> while True: <TAB>  <TAB> parent = node.parent <MASK> assert node.end_pos[0] <= line <TAB>  <TAB>  <TAB> assert node.end_pos[1] == 0 or ""\n"" in self._prefix <TAB>  <TAB>  <TAB> return node <TAB>  <TAB> node = parent","if parent . type in ( ""suite"" , ""file_input"" ) :",143
3786,"def PyJsHoisted_parseClassRanges_(this, arguments, var=var): <TAB> var = Scope({u""this"": this, u""arguments"": arguments}, var) <TAB> var.registers([u""res""]) <TAB> pass <TAB> if var.get(u""current"")(Js(u""]"")): <TAB>  <TAB> return Js([]) <TAB> else: <TAB>  <TAB> var.put(u""res"", var.get(u""parseNonemptyClassRanges"")()) <MASK> var.get(u""bail"")(Js(u""nonEmptyClassRanges"")) <TAB>  <TAB> return var.get(u""res"")","if var . get ( u""res"" ) . neg ( ) :",152
3787,"def _recurse_children(self, offset): <TAB> """"""Recurses thorugh the available children"""""" <TAB> while offset < self.obj_offset + self.Length: <TAB>  <TAB> item = obj.Object(""VerStruct"", offset=offset, vm=self.obj_vm, parent=self) <MASK> raise StopIteration( <TAB>  <TAB>  <TAB>  <TAB> ""Could not recover a key for a child at offset {0}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> item.obj_offset <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> yield item.get_key(), item.get_children() <TAB>  <TAB> offset = self.offset_pad(offset + item.Length) <TAB> raise StopIteration(""No children"")",if item . Length < 1 or item . get_key ( ) == None :,177
3788,"def _adapt_types(self, descr): <TAB> names = [] <TAB> adapted_types = [] <TAB> for col in descr: <TAB>  <TAB> names.append(col[0]) <TAB>  <TAB> impala_typename = col[1] <TAB>  <TAB> typename = udf._impala_to_ibis_type[impala_typename.lower()] <MASK> precision, scale = col[4:6] <TAB>  <TAB>  <TAB> adapted_types.append(dt.Decimal(precision, scale)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> adapted_types.append(typename) <TAB> return names, adapted_types","if typename == ""decimal"" :",144
3789,"def sniff(self, filename): <TAB> try: <MASK> with tarfile.open(filename, ""r"") as temptar: <TAB>  <TAB>  <TAB>  <TAB> for f in temptar: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if not f.isfile(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if f.name.endswith("".fast5""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> except Exception as e: <TAB>  <TAB> log.warning(""%s, sniff Exception: %s"", self, e) <TAB> return False",if filename and tarfile . is_tarfile ( filename ) :,149
3790,"def getValue(self): <TAB> if getattr(self.object, ""type"", """") != ""CURVE"": <TAB>  <TAB> return BezierSpline() <TAB> evaluatedObject = getEvaluatedID(self.object) <TAB> bSplines = evaluatedObject.data.splines <TAB> if len(bSplines) > 0: <TAB>  <TAB> spline = createSplineFromBlenderSpline(bSplines[0]) <TAB>  <TAB> # Is None when the spline type is not supported. <TAB>  <TAB> if spline is not None: <MASK> spline.transform(evaluatedObject.matrix_world) <TAB>  <TAB>  <TAB> return spline <TAB> return BezierSpline()",if self . useWorldSpace :,153
3791,"def escape(text, newline=False): <TAB> """"""Escape special html characters."""""" <TAB> if isinstance(text, str): <TAB>  <TAB> if ""&"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""&"", ""&amp;"") <MASK> text = text.replace("">"", ""&gt;"") <TAB>  <TAB> if ""<"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""<"", ""&lt;"") <TAB>  <TAB> if '""' in text: <TAB>  <TAB>  <TAB> text = text.replace('""', ""&quot;"") <TAB>  <TAB> if ""'"" in text: <TAB>  <TAB>  <TAB> text = text.replace(""'"", ""&quot;"") <TAB>  <TAB> if newline: <TAB>  <TAB>  <TAB> if ""\n"" in text: <TAB>  <TAB>  <TAB>  <TAB> text = text.replace(""\n"", ""<br>"") <TAB> return text","if "">"" in text :",170
3792,"def _get_ilo_version(self): <TAB> try: <TAB>  <TAB> self._get_ilo2('<?xml version=""1.0""?><RIBCL VERSION=""2.0""></RIBCL>') <TAB> except ResponseError as e: <TAB>  <TAB> if hasattr(e, ""code""): <MASK> return 3 <TAB>  <TAB>  <TAB> if e.code == 501: <TAB>  <TAB>  <TAB>  <TAB> return 1 <TAB>  <TAB> raise <TAB> return 2",if e . code == 405 :,113
3793,"def convert_path(ctx, tpath): <TAB> for points, code in tpath.iter_segments(): <TAB>  <TAB> if code == Path.MOVETO: <TAB>  <TAB>  <TAB> ctx.move_to(*points) <TAB>  <TAB> elif code == Path.LINETO: <TAB>  <TAB>  <TAB> ctx.line_to(*points) <TAB>  <TAB> elif code == Path.CURVE3: <TAB>  <TAB>  <TAB> ctx.curve_to( <TAB>  <TAB>  <TAB>  <TAB> points[0], points[1], points[0], points[1], points[2], points[3] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> elif code == Path.CURVE4: <TAB>  <TAB>  <TAB> ctx.curve_to(*points) <MASK> ctx.close_path()",elif code == Path . CLOSEPOLY :,172
3794,"def called_by_shrinker(): <TAB> frame = sys._getframe(0) <TAB> while frame: <TAB>  <TAB> fname = frame.f_globals.get(""__file__"", """") <MASK> return True <TAB>  <TAB> frame = frame.f_back <TAB> return False","if os . path . basename ( fname ) == ""shrinker.py"" :",83
3795,"def _ensuresyspath(self, ensuremode, path): <TAB> if ensuremode: <TAB>  <TAB> s = str(path) <TAB>  <TAB> if ensuremode == ""append"": <MASK> sys.path.append(s) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if s != sys.path[0]: <TAB>  <TAB>  <TAB>  <TAB> sys.path.insert(0, s)",if s not in sys . path :,97
3796,"def get_instances(self, region: str, vpc: str): <TAB> try: <TAB>  <TAB> await self._cache_instances(region) <TAB>  <TAB> return [ <TAB>  <TAB>  <TAB> instance <TAB>  <TAB>  <TAB> for instance in self._instances_cache[region] <MASK> ] <TAB> except Exception as e: <TAB>  <TAB> print_exception(f""Failed to get RDS instances: {e}"") <TAB>  <TAB> return []","if instance [ ""VpcId"" ] == vpc",105
3797,def get_and_set_all_disambiguation(self): <TAB> all_disambiguations = [] <TAB> for page in self.pages: <TAB>  <TAB> if page.relations.disambiguation_links_norm is not None: <TAB>  <TAB>  <TAB> all_disambiguations.extend(page.relations.disambiguation_links_norm) <MASK> all_disambiguations.extend(page.relations.disambiguation_links) <TAB> return set(all_disambiguations),if page . relations . disambiguation_links is not None :,113
3798,"def __str__(self, prefix="""", printElemNumber=0): <TAB> res = """" <TAB> cnt = 0 <TAB> for e in self.options_: <TAB>  <TAB> elm = """" <MASK> elm = ""(%d)"" % cnt <TAB>  <TAB> res += prefix + (""options%s <\n"" % elm) <TAB>  <TAB> res += e.__str__(prefix + ""  "", printElemNumber) <TAB>  <TAB> res += prefix + "">\n"" <TAB>  <TAB> cnt += 1 <TAB> return res",if printElemNumber :,119
3799,"def pre_save_task(self, task, credentials, verrors): <TAB> if task[""attributes""][""encryption""] not in (None, """", ""AES256""): <TAB>  <TAB> verrors.add(""encryption"", 'Encryption should be null or ""AES256""') <TAB> if not credentials[""attributes""].get(""skip_region"", False): <MASK> response = await self.middleware.run_in_thread( <TAB>  <TAB>  <TAB>  <TAB> self._get_client(credentials).get_bucket_location, <TAB>  <TAB>  <TAB>  <TAB> Bucket=task[""attributes""][""bucket""], <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> task[""attributes""][""region""] = response[""LocationConstraint""] or ""us-east-1""","if not credentials [ ""attributes"" ] . get ( ""region"" , """" ) . strip ( ) :",167
3800,"def get_best_config_reward(self): <TAB> """"""Returns the best configuration found so far, as well as the reward associated with this best config."""""" <TAB> with self.LOCK: <MASK> config_pkl = max(self._results, key=self._results.get) <TAB>  <TAB>  <TAB> return pickle.loads(config_pkl), self._results[config_pkl] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return dict(), self._reward_while_pending()",if self . _results :,112
3801,"def parse_setup_cfg(self): <TAB> # type: () -> Dict[STRING_TYPE, Any] <TAB> if self.setup_cfg is not None and self.setup_cfg.exists(): <TAB>  <TAB> contents = self.setup_cfg.read_text() <TAB>  <TAB> base_dir = self.setup_cfg.absolute().parent.as_posix() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> parsed = setuptools_parse_setup_cfg(self.setup_cfg.as_posix()) <TAB>  <TAB> except Exception: <MASK> contents = self.setup_cfg.read_bytes() <TAB>  <TAB>  <TAB> parsed = parse_setup_cfg(contents, base_dir) <TAB>  <TAB> if not parsed: <TAB>  <TAB>  <TAB> return {} <TAB>  <TAB> return parsed <TAB> return {}",if six . PY2 :,183
3802,"def readall(read_fn, sz): <TAB> buff = b"""" <TAB> have = 0 <TAB> while have < sz: <TAB>  <TAB> chunk = yield from read_fn(sz - have) <TAB>  <TAB> have += len(chunk) <TAB>  <TAB> buff += chunk <MASK> raise TTransportException( <TAB>  <TAB>  <TAB>  <TAB> TTransportException.END_OF_FILE, ""End of file reading from transport"" <TAB>  <TAB>  <TAB> ) <TAB> return buff",if len ( chunk ) == 0 :,111
3803,"def _get_use_previous( <TAB> f,):  # TODO Sort and group features for DateOffset with two different temporal values <TAB> if isinstance(f, AggregationFeature) and f.use_previous is not None: <MASK> return ("""", -1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> unit = list(f.use_previous.times.keys())[0] <TAB>  <TAB>  <TAB> value = f.use_previous.times[unit] <TAB>  <TAB>  <TAB> return (unit, value) <TAB> else: <TAB>  <TAB> return ("""", -1)",if len ( f . use_previous . times . keys ( ) ) > 1 :,140
3804,"def istrue(self): <TAB> try: <TAB>  <TAB> return self._istrue() <TAB> except Exception: <TAB>  <TAB> self.exc = sys.exc_info() <MASK> msg = [ <TAB>  <TAB>  <TAB>  <TAB> "" "" * (self.exc[1].offset + 4) + ""^"", <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB> msg.append(""SyntaxError: invalid syntax"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> msg = traceback.format_exception_only(*self.exc[:2]) <TAB>  <TAB> pytest.fail( <TAB>  <TAB>  <TAB> ""Error evaluating %r expression\n"" <TAB>  <TAB>  <TAB> "" <TAB> %s\n"" <TAB>  <TAB>  <TAB> ""%s"" % (self.name, self.expr, ""\n"".join(msg)), <TAB>  <TAB>  <TAB> pytrace=False, <TAB>  <TAB> )","if isinstance ( self . exc [ 1 ] , SyntaxError ) :",194
3805,"def wait_for_crm_operation(operation, crm): <TAB> """"""Poll for cloud resource manager operation until finished."""""" <TAB> logger.info( <TAB>  <TAB> ""wait_for_crm_operation: "" <TAB>  <TAB> ""Waiting for operation {} to finish..."".format(operation) <TAB> ) <TAB> for _ in range(MAX_POLLS): <TAB>  <TAB> result = crm.operations().get(name=operation[""name""]).execute() <MASK> raise Exception(result[""error""]) <TAB>  <TAB> if ""done"" in result and result[""done""]: <TAB>  <TAB>  <TAB> logger.info(""wait_for_crm_operation: Operation done."") <TAB>  <TAB>  <TAB> break <TAB>  <TAB> time.sleep(POLL_INTERVAL) <TAB> return result","if ""error"" in result :",173
3806,"def cb_blob_detail_from_elem_and_buf(self, elem, buf): <TAB> if elem.get(""lang"") != buf.lang:  # multi-lang doc <TAB>  <TAB> return ""%s Code in %s"" % (elem.get(""lang""), buf.path) <TAB> else: <TAB>  <TAB> dir, base = os.path.split(buf.path) <MASK> return ""%s (%s)"" % (base, dir) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return base",if dir :,119
3807,"def removedir(self, path): <TAB> # type: (Text) -> None <TAB> _path = self.validatepath(path) <TAB> if _path == ""/"": <TAB>  <TAB> raise errors.RemoveRootError() <TAB> with ftp_errors(self, path): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.ftp.rmd(_encode(_path, self.ftp.encoding)) <TAB>  <TAB> except error_perm as error: <TAB>  <TAB>  <TAB> code, _ = _parse_ftp_error(error) <MASK> if self.isfile(path): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise errors.DirectoryExpected(path) <TAB>  <TAB>  <TAB>  <TAB> if not self.isempty(path): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise errors.DirectoryNotEmpty(path) <TAB>  <TAB>  <TAB> raise  # pragma: no cover","if code == ""550"" :",189
3808,"def p_clause(self, node, position): <TAB> if isinstance(node, Graph): <TAB>  <TAB> self.subjectDone(node) <MASK> self.write("" "") <TAB>  <TAB> self.write(""{"") <TAB>  <TAB> self.depth += 1 <TAB>  <TAB> serializer = N3Serializer(node, parent=self) <TAB>  <TAB> serializer.serialize(self.stream) <TAB>  <TAB> self.depth -= 1 <TAB>  <TAB> self.write(self.indent() + ""}"") <TAB>  <TAB> return True <TAB> else: <TAB>  <TAB> return False",if position is OBJECT :,124
3809,"def get_default_shell_info(shell_name=None, settings=None): <TAB> if not shell_name: <TAB>  <TAB> settings = settings or load_settings(lazy=True) <TAB>  <TAB> shell_name = settings.get(""shell"") <TAB>  <TAB> if shell_name: <TAB>  <TAB>  <TAB> return shell_name, None <TAB>  <TAB> shell_path = os.environ.get(""SHELL"") <MASK> shell_name = basepath(shell_path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> shell_name = DEFAULT_SHELL <TAB>  <TAB> return shell_name, shell_path <TAB> return shell_name, None",if shell_path :,150
3810,"def GetCategory(self, pidls): <TAB> ret = [] <TAB> for pidl in pidls: <TAB>  <TAB> # Why don't we just get the size of the PIDL? <TAB>  <TAB> val = self.sf.GetDetailsEx(pidl, PKEY_Sample_AreaSize) <TAB>  <TAB> val = int(val)  # it probably came in a VT_BSTR variant <TAB>  <TAB> if val < 255 // 3: <TAB>  <TAB>  <TAB> cid = IDS_SMALL <MASK> cid = IDS_MEDIUM <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> cid = IDS_LARGE <TAB>  <TAB> ret.append(cid) <TAB> return ret",elif val < 2 * 255 // 3 :,158
3811,"def Tokenize(s): <TAB> # type: (str) -> Iterator[Token] <TAB> for item in TOKEN_RE.findall(s): <TAB>  <TAB> # The type checker can't know the true type of item! <TAB>  <TAB> item = cast(TupleStr4, item) <TAB>  <TAB> if item[0]: <TAB>  <TAB>  <TAB> typ = ""number"" <TAB>  <TAB>  <TAB> val = item[0] <TAB>  <TAB> elif item[1]: <TAB>  <TAB>  <TAB> typ = ""name"" <TAB>  <TAB>  <TAB> val = item[1] <TAB>  <TAB> elif item[2]: <TAB>  <TAB>  <TAB> typ = item[2] <TAB>  <TAB>  <TAB> val = item[2] <MASK> typ = item[3] <TAB>  <TAB>  <TAB> val = item[3] <TAB>  <TAB> yield Token(typ, val)",elif item [ 3 ] :,181
3812,"def add_package_declarations(generated_root_path): <TAB> file_names = os.listdir(generated_root_path) <TAB> for file_name in file_names: <MASK> continue <TAB>  <TAB> full_name = os.path.join(generated_root_path, file_name) <TAB>  <TAB> add_package(full_name)","if not file_name . endswith ( "".java"" ) :",93
3813,"def _call_with_retry(out, retry, retry_wait, method, *args, **kwargs): <TAB> for counter in range(retry + 1): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return method(*args, **kwargs) <TAB>  <TAB> except ( <TAB>  <TAB>  <TAB> NotFoundException, <TAB>  <TAB>  <TAB> ForbiddenException, <TAB>  <TAB>  <TAB> AuthenticationException, <TAB>  <TAB>  <TAB> RequestErrorException, <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> except ConanException as exc: <MASK> raise <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> if out: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> out.error(exc) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> out.info(""Waiting %d seconds to retry..."" % retry_wait) <TAB>  <TAB>  <TAB>  <TAB> time.sleep(retry_wait)",if counter == retry :,180
3814,"def to_wburl_str( <TAB> url, type=BaseWbUrl.LATEST_REPLAY, mod="""", timestamp="""", end_timestamp=""""): <TAB> if WbUrl.is_query_type(type): <TAB>  <TAB> tsmod = """" <MASK> tsmod += mod + ""/"" <TAB>  <TAB> tsmod += timestamp <TAB>  <TAB> tsmod += ""*"" <TAB>  <TAB> tsmod += end_timestamp <TAB>  <TAB> tsmod += ""/"" + url <TAB>  <TAB> if type == BaseWbUrl.URL_QUERY: <TAB>  <TAB>  <TAB> tsmod += ""*"" <TAB>  <TAB> return tsmod <TAB> else: <TAB>  <TAB> tsmod = timestamp + mod <TAB>  <TAB> if len(tsmod) > 0: <TAB>  <TAB>  <TAB> return tsmod + ""/"" + url <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return url",if mod :,180
3815,"def _configured_ploidy(items): <TAB> ploidies = collections.defaultdict(set) <TAB> for data in items: <TAB>  <TAB> ploidy = dd.get_ploidy(data) <MASK> for k, v in ploidy.items(): <TAB>  <TAB>  <TAB>  <TAB> ploidies[k].add(v) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ploidies[""default""].add(ploidy) <TAB> out = {} <TAB> for k, vs in ploidies.items(): <TAB>  <TAB> assert len(vs) == 1, ""Multiple ploidies set for group calling: %s %s"" % ( <TAB>  <TAB>  <TAB> k, <TAB>  <TAB>  <TAB> list(vs), <TAB>  <TAB> ) <TAB>  <TAB> out[k] = vs.pop() <TAB> return out","if isinstance ( ploidy , dict ) :",187
3816,"def removeUser(self, username): <TAB> hideFromOSD = not constants.SHOW_DIFFERENT_ROOM_OSD <TAB> if username in self._users: <TAB>  <TAB> user = self._users[username] <MASK> if self.isRoomSame(user.room): <TAB>  <TAB>  <TAB>  <TAB> hideFromOSD = not constants.SHOW_SAME_ROOM_OSD <TAB> if username in self._users: <TAB>  <TAB> self._users.pop(username) <TAB>  <TAB> message = getMessage(""left-notification"").format(username) <TAB>  <TAB> self.ui.showMessage(message, hideFromOSD) <TAB>  <TAB> self._client.lastLeftTime = time.time() <TAB>  <TAB> self._client.lastLeftUser = username <TAB> self.userListChange()",if user . room :,184
3817,"def _thd_cleanup_instance(self): <TAB> container_name = self.getContainerName() <TAB> instances = self.client.containers(all=1, filters=dict(name=container_name)) <TAB> for instance in instances: <TAB>  <TAB> # hyper filtering will match 'hyper12"" if you search for 'hyper1' ! <MASK> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.client.remove_container(instance[""Id""], v=True, force=True) <TAB>  <TAB> except NotFound: <TAB>  <TAB>  <TAB> pass  # that's a race condition <TAB>  <TAB> except docker.errors.APIError as e: <TAB>  <TAB>  <TAB> if ""Conflict operation on container"" not in str(e): <TAB>  <TAB>  <TAB>  <TAB> raise","if """" . join ( instance [ ""Names"" ] ) . strip ( ""/"" ) != container_name :",182
3818,"def handle_ctcp(self, conn, evt): <TAB> args = evt.arguments() <TAB> source = evt.source().split(""!"")[0] <TAB> if args: <TAB>  <TAB> if args[0] == ""VERSION"": <TAB>  <TAB>  <TAB> conn.ctcp_reply(source, ""VERSION "" + BOT_VERSION) <MASK> conn.ctcp_reply(source, ""PING"") <TAB>  <TAB> elif args[0] == ""CLIENTINFO"": <TAB>  <TAB>  <TAB> conn.ctcp_reply(source, ""CLIENTINFO PING VERSION CLIENTINFO"")","elif args [ 0 ] == ""PING"" :",136
3819,"def new_func(self, *args, **kwargs): <TAB> obj = self.obj_ref() <TAB> attr = self.attr <TAB> if obj is not None: <TAB>  <TAB> args = tuple(TrackedValue.make(obj, attr, arg) for arg in args) <MASK> kwargs = { <TAB>  <TAB>  <TAB>  <TAB> key: TrackedValue.make(obj, attr, value) <TAB>  <TAB>  <TAB>  <TAB> for key, value in iteritems(kwargs) <TAB>  <TAB>  <TAB> } <TAB> result = func(self, *args, **kwargs) <TAB> self._changed_() <TAB> return result",if kwargs :,138
3820,"def add_doc(target, variables, body_lines): <TAB> if isinstance(target, ast.Name): <TAB>  <TAB> # if it is a variable name add it to the doc <TAB>  <TAB> name = target.id <MASK> doc = find_doc_for(target, body_lines) <TAB>  <TAB>  <TAB> if doc is not None: <TAB>  <TAB>  <TAB>  <TAB> variables[name] = doc <TAB> elif isinstance(target, ast.Tuple): <TAB>  <TAB> # if it is a tuple then iterate the elements <TAB>  <TAB> # this can happen like this: <TAB>  <TAB> # a, b = 1, 2 <TAB>  <TAB> for e in target.elts: <TAB>  <TAB>  <TAB> add_doc(e, variables, body_lines)",if name not in variables :,167
3821,"def _terminal_messenger(tp=""write"", msg="""", out=sys.stdout): <TAB> try: <TAB>  <TAB> if tp == ""write"": <TAB>  <TAB>  <TAB> out.write(msg) <TAB>  <TAB> elif tp == ""flush"": <TAB>  <TAB>  <TAB> out.flush() <MASK> out.write(msg) <TAB>  <TAB>  <TAB> out.flush() <TAB>  <TAB> elif tp == ""print"": <TAB>  <TAB>  <TAB> print(msg, file=out) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""Unsupported type: "" + tp) <TAB> except IOError as e: <TAB>  <TAB> logger.critical(""{}: {}"".format(type(e).__name__, ucd(e))) <TAB>  <TAB> pass","elif tp == ""write_flush"" :",160
3822,"def get_files(d): <TAB> res = [] <TAB> for p in glob.glob(os.path.join(d, ""*"")): <TAB>  <TAB> if not p: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> (pth, fname) = os.path.split(p) <MASK> continue <TAB>  <TAB> if os.path.islink(p): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if os.path.isdir(p): <TAB>  <TAB>  <TAB> res += get_dir(p) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> res.append(p) <TAB> return res",if skip_file ( fname ) :,136
3823,"def _list_outputs(self): <TAB> outputs = super(VolSymm, self)._list_outputs() <TAB> # Have to manually check for the grid files. <TAB> if os.path.exists(outputs[""trans_file""]): <MASK> outputs[""output_grid""] = re.sub( <TAB>  <TAB>  <TAB>  <TAB> "".(nlxfm|xfm)$"", ""_grid_0.mnc"", outputs[""trans_file""] <TAB>  <TAB>  <TAB> ) <TAB> return outputs","if ""grid"" in open ( outputs [ ""trans_file"" ] , ""r"" ) . read ( ) :",126
3824,"def _set_texture(self, texture): <TAB> if texture.id is not self._texture.id: <TAB>  <TAB> self._group = SpriteGroup( <TAB>  <TAB>  <TAB> texture, self._group.blend_src, self._group.blend_dest, self._group.parent <TAB>  <TAB> ) <MASK> self._vertex_list.tex_coords[:] = texture.tex_coords <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._vertex_list.delete() <TAB>  <TAB>  <TAB> self._texture = texture <TAB>  <TAB>  <TAB> self._create_vertex_list() <TAB> else: <TAB>  <TAB> self._vertex_list.tex_coords[:] = texture.tex_coords <TAB> self._texture = texture",if self . _batch is None :,166
3825,"def got_result(result): <TAB> deployment = self.persistence_service.get() <TAB> for node in deployment.nodes: <MASK> dataset_ids = [ <TAB>  <TAB>  <TAB>  <TAB> (m.dataset.deleted, m.dataset.dataset_id) <TAB>  <TAB>  <TAB>  <TAB> for m in node.manifestations.values() <TAB>  <TAB>  <TAB> ] <TAB>  <TAB>  <TAB> self.assertIn((True, expected_dataset_id), dataset_ids) <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> self.fail(""Node not found. {}"".format(node.uuid))","if same_node ( node , origin ) :",138
3826,"def check_result(result, func, arguments): <TAB> if check_warning(result) and (result.value != ReturnCode.WARN_NODATA): <TAB>  <TAB> log.warning(UcanWarning(result, func, arguments)) <TAB> elif check_error(result): <MASK> raise UcanCmdError(result, func, arguments) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise UcanError(result, func, arguments) <TAB> return result",if check_error_cmd ( result ) :,114
3827,"def _compress_and_sort_bdg_files(out_dir, data): <TAB> for fn in glob.glob(os.path.join(out_dir, ""*bdg"")): <TAB>  <TAB> out_file = fn + "".gz"" <MASK> continue <TAB>  <TAB> bedtools = config_utils.get_program(""bedtools"", data) <TAB>  <TAB> with file_transaction(out_file) as tx_out_file: <TAB>  <TAB>  <TAB> cmd = f""sort -k1,1 -k2,2n {fn} | bgzip -c > {tx_out_file}"" <TAB>  <TAB>  <TAB> message = f""Compressing and sorting {fn}."" <TAB>  <TAB>  <TAB> do.run(cmd, message)",if utils . file_exists ( out_file ) :,176
3828,"def kill_members(members, sig, hosts=nodes): <TAB> for member in sorted(members): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if ha_tools_debug: <TAB>  <TAB>  <TAB>  <TAB> print(""killing %s"" % member) <TAB>  <TAB>  <TAB> proc = hosts[member][""proc""] <TAB>  <TAB>  <TAB> # Not sure if cygwin makes sense here... <MASK> os.kill(proc.pid, signal.CTRL_C_EVENT) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> os.kill(proc.pid, sig) <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> if ha_tools_debug: <TAB>  <TAB>  <TAB>  <TAB> print(""%s already dead?"" % member)","if sys . platform in ( ""win32"" , ""cygwin"" ) :",172
3829,"def get_top_level_stats(self): <TAB> for func, (cc, nc, tt, ct, callers) in self.stats.items(): <TAB>  <TAB> self.total_calls += nc <TAB>  <TAB> self.prim_calls += cc <TAB>  <TAB> self.total_tt += tt <MASK> self.top_level[func] = None <TAB>  <TAB> if len(func_std_string(func)) > self.max_name_len: <TAB>  <TAB>  <TAB> self.max_name_len = len(func_std_string(func))","if ( ""jprofile"" , 0 , ""profiler"" ) in callers :",141
3830,"def __str__(self): <TAB> """"""Only keeps the True values."""""" <TAB> result = [""SlicingSpec(""] <TAB> if self.entire_dataset: <TAB>  <TAB> result.append("" Entire dataset,"") <TAB> if self.by_class: <TAB>  <TAB> if isinstance(self.by_class, Iterable): <TAB>  <TAB>  <TAB> result.append("" Into classes %s,"" % self.by_class) <MASK> result.append("" Up to class %d,"" % self.by_class) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result.append("" By classes,"") <TAB> if self.by_percentiles: <TAB>  <TAB> result.append("" By percentiles,"") <TAB> if self.by_classification_correctness: <TAB>  <TAB> result.append("" By classification correctness,"") <TAB> result.append("")"") <TAB> return ""\n"".join(result)","elif isinstance ( self . by_class , int ) :",197
3831,"def save_params(self): <TAB> if self._save_controller: <TAB>  <TAB> if not os.path.exists(self._save_controller): <TAB>  <TAB>  <TAB> os.makedirs(self._save_controller) <TAB>  <TAB> output_dir = self._save_controller <TAB> else: <MASK> os.makedirs(""./.rlnas_controller"") <TAB>  <TAB> output_dir = ""./.rlnas_controller"" <TAB> with open(os.path.join(output_dir, ""rlnas.params""), ""wb"") as f: <TAB>  <TAB> pickle.dump(self._params_dict, f) <TAB> _logger.debug(""Save params done"")","if not os . path . exists ( ""./.rlnas_controller"" ) :",166
3832,"def unexport(self, pin): <TAB> with self._lock: <TAB>  <TAB> self._pin_refs[pin] -= 1 <MASK> with io.open(self.path(""unexport""), ""wb"") as f: <TAB>  <TAB>  <TAB>  <TAB> f.write(str(pin).encode(""ascii""))",if self . _pin_refs [ pin ] == 0 :,83
3833,"def emit(self, type, info=None): <TAB> # Overload emit() to send events to the proxy object at the other end <TAB> ev = super().emit(type, info) <TAB> if self._has_proxy is True and self._session.status > 0: <TAB>  <TAB> # implicit: and self._disposed is False: <TAB>  <TAB> if type in self.__proxy_properties__: <TAB>  <TAB>  <TAB> self._session.send_command(""INVOKE"", self._id, ""_emit_at_proxy"", [ev]) <MASK> self._session.send_command(""INVOKE"", self._id, ""_emit_at_proxy"", [ev])",elif type in self . __event_types_at_proxy :,161
3834,"def __call__(self, params): <TAB> all_errs = {} <TAB> for handler in self.handlers: <TAB>  <TAB> out_headers, res, errs = handler(params) <TAB>  <TAB> all_errs.update(errs) <MASK> return out_headers, res, all_errs <TAB> return None, None, all_errs",if res is not None :,84
3835,"def await_test_end(self): <TAB> iterations = 0 <TAB> while True: <MASK> self.log.debug(""Await: iteration limit reached"") <TAB>  <TAB>  <TAB> return <TAB>  <TAB> status = self.master.get_status() <TAB>  <TAB> if status.get(""status"") == ""ENDED"": <TAB>  <TAB>  <TAB> return <TAB>  <TAB> iterations += 1 <TAB>  <TAB> time.sleep(1.0)",if iterations > 100 :,100
3836,"def _load(self, path: str): <TAB> ds = DataSet() <TAB> with open(path, ""r"", encoding=""utf-8"") as f: <TAB>  <TAB> for line in f: <TAB>  <TAB>  <TAB> line = line.strip() <MASK> parts = line.split(""\t"") <TAB>  <TAB>  <TAB>  <TAB> raw_words1 = parts[1] <TAB>  <TAB>  <TAB>  <TAB> raw_words2 = parts[2] <TAB>  <TAB>  <TAB>  <TAB> target = parts[0] <TAB>  <TAB>  <TAB>  <TAB> if raw_words1 and raw_words2 and target: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ds.append( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> Instance( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raw_words1=raw_words1, raw_words2=raw_words2, target=target <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return ds",if line :,200
3837,"def avatar_delete(event_id, speaker_id): <TAB> if request.method == ""DELETE"": <TAB>  <TAB> speaker = ( <TAB>  <TAB>  <TAB> DataGetter.get_speakers(event_id) <TAB>  <TAB>  <TAB> .filter_by(user_id=login.current_user.id, id=speaker_id) <TAB>  <TAB>  <TAB> .first() <TAB>  <TAB> ) <MASK> speaker.photo = """" <TAB>  <TAB>  <TAB> speaker.small = """" <TAB>  <TAB>  <TAB> speaker.thumbnail = """" <TAB>  <TAB>  <TAB> speaker.icon = """" <TAB>  <TAB>  <TAB> save_to_db(speaker) <TAB>  <TAB>  <TAB> return jsonify({""status"": ""ok""}) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> abort(403)",if speaker :,162
3838,"def getline(filename, lineno, *args, **kwargs): <TAB> line = py2exe_getline(filename, lineno, *args, **kwargs) <TAB> if not line: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> with open(filename, ""rb"") as f: <TAB>  <TAB>  <TAB>  <TAB> for i, line in enumerate(f): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> line = line.decode(""utf-8"") <MASK> break <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> line = """" <TAB>  <TAB> except (IOError, OSError): <TAB>  <TAB>  <TAB> line = """" <TAB> return line",if lineno == i + 1 :,149
3839,"def write(self, data): <TAB> if not isinstance(data, (bytes, bytearray, memoryview)): <TAB>  <TAB> raise TypeError(""data argument must be byte-ish (%r)"", type(data)) <TAB> if not data: <TAB>  <TAB> return <TAB> if self._conn_lost: <MASK> logger.warning(""socket.send() raised exception."") <TAB>  <TAB> self._conn_lost += 1 <TAB>  <TAB> return <TAB> if not self._buffer: <TAB>  <TAB> self._loop.add_writer(self._sock_fd, self._write_ready) <TAB> # Add it to the buffer. <TAB> self._buffer.extend(data) <TAB> self._maybe_pause_protocol()",if self . _conn_lost >= constants . LOG_THRESHOLD_FOR_CONNLOST_WRITES :,179
3840,"def _get_x_for_y(self, xValue, x, y): <TAB> # print(""searching ""+x+"" with the value ""+str(xValue)+"" and want to give back ""+y) <TAB> if not self.xmlMap: <TAB>  <TAB> return 0 <TAB> x_value = str(xValue) <TAB> for anime in self.xmlMap.findall(""anime""): <TAB>  <TAB> try: <MASK> return int(anime.get(y, 0)) <TAB>  <TAB> except ValueError as e: <TAB>  <TAB>  <TAB> continue <TAB> return 0","if anime . get ( x , False ) == x_value :",145
3841,"def _RewriteModinfo( <TAB> self, <TAB> modinfo, <TAB> obj_kernel_version, <TAB> this_kernel_version, <TAB> info_strings=None, <TAB> to_remove=None,): <TAB> new_modinfo = """" <TAB> for line in modinfo.split(""\x00""): <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if to_remove and line.split(""="")[0] == to_remove: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if info_strings is not None: <TAB>  <TAB>  <TAB> info_strings.add(line.split(""="")[0]) <MASK> line = line.replace(obj_kernel_version, this_kernel_version) <TAB>  <TAB> new_modinfo += line + ""\x00"" <TAB> return new_modinfo","if line . startswith ( ""vermagic"" ) :",187
3842,"def _score(self, X, y): <TAB> for col in self.cols: <TAB>  <TAB> # Score the column <TAB>  <TAB> X[col] = X[col].map(self.mapping[col]) <TAB>  <TAB> # Randomization is meaningful only for training data -> we do it only if y is present <MASK> random_state_generator = check_random_state(self.random_state) <TAB>  <TAB>  <TAB> X[col] = X[col] * random_state_generator.normal( <TAB>  <TAB>  <TAB>  <TAB> 1.0, self.sigma, X[col].shape[0] <TAB>  <TAB>  <TAB> ) <TAB> return X",if self . randomized and y is not None :,155
3843,"def onMouseWheel(self, event): <TAB> if self.selectedHuman.isVisible(): <TAB>  <TAB> zoomOut = event.wheelDelta > 0 <MASK> zoomOut = not zoomOut <TAB>  <TAB> if event.x is not None: <TAB>  <TAB>  <TAB> self.modelCamera.mousePickHumanCenter(event.x, event.y) <TAB>  <TAB> if zoomOut: <TAB>  <TAB>  <TAB> self.zoomOut() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.zoomIn()","if self . getSetting ( ""invertMouseWheel"" ) :",121
3844,"def prehook(self, emu, op, eip): <TAB> if op in self.badops: <TAB>  <TAB> emu.stopEmu() <TAB>  <TAB> raise v_exc.BadOpBytes(op.va) <TAB> if op.mnem in STOS: <TAB>  <TAB> if self.arch == ""i386"": <TAB>  <TAB>  <TAB> reg = emu.getRegister(envi.archs.i386.REG_EDI) <MASK> reg = emu.getRegister(envi.archs.amd64.REG_RDI) <TAB>  <TAB> if self.vw.isValidPointer(reg) and self.vw.getLocation(reg) is None: <TAB>  <TAB>  <TAB> self.vw.makePointer(reg, follow=True)","elif self . arch == ""amd64"" :",186
3845,"def callback(actions, form, tablename=None): <TAB> if actions: <TAB>  <TAB> if tablename and isinstance(actions, dict): <TAB>  <TAB>  <TAB> actions = actions.get(tablename, []) <MASK> actions = [actions] <TAB>  <TAB> [action(form) for action in actions]","if not isinstance ( actions , ( list , tuple ) ) :",80
3846,"def FetchFn(bigger_than_3_only=None, less_than_7_only=None, even_only=None): <TAB> result = [] <TAB> for i in range(10): <TAB>  <TAB> # This line introduces a bug. <TAB>  <TAB> if bigger_than_3_only and less_than_7_only and i == 4: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if bigger_than_3_only and i <= 3: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if less_than_7_only and i >= 7: <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> result.append(i) <TAB> return result",if even_only and i % 2 != 0 :,158
3847,"def set_trial_values(self, trial_id: int, values: Sequence[float]) -> None: <TAB> with self._lock: <TAB>  <TAB> cached_trial = self._get_cached_trial(trial_id) <MASK> self._check_trial_is_updatable(cached_trial) <TAB>  <TAB>  <TAB> updates = self._get_updates(trial_id) <TAB>  <TAB>  <TAB> cached_trial.values = values <TAB>  <TAB>  <TAB> updates.values = values <TAB>  <TAB>  <TAB> return <TAB> self._backend._update_trial(trial_id, values=values)",if cached_trial is not None :,141
3848,"def _get_label_format(self, workunit): <TAB> for label, label_format in self.LABEL_FORMATTING.items(): <TAB>  <TAB> if workunit.has_label(label): <TAB>  <TAB>  <TAB> return label_format <TAB> # Recursively look for a setting to suppress child label formatting. <TAB> if workunit.parent: <TAB>  <TAB> label_format = self._get_label_format(workunit.parent) <TAB>  <TAB> if label_format == LabelFormat.CHILD_DOT: <TAB>  <TAB>  <TAB> return LabelFormat.DOT <MASK> return LabelFormat.SUPPRESS <TAB> return LabelFormat.FULL",if label_format == LabelFormat . CHILD_SUPPRESS :,151
3849,"def open_session(self, app, request): <TAB> sid = request.cookies.get(app.session_cookie_name) <TAB> if sid: <TAB>  <TAB> stored_session = self.cls.objects(sid=sid).first() <TAB>  <TAB> if stored_session: <TAB>  <TAB>  <TAB> expiration = stored_session.expiration <TAB>  <TAB>  <TAB> if not expiration.tzinfo: <TAB>  <TAB>  <TAB>  <TAB> expiration = expiration.replace(tzinfo=utc) <MASK> return MongoEngineSession( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> initial=stored_session.data, sid=stored_session.sid <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return MongoEngineSession(sid=str(uuid.uuid4()))",if expiration > datetime . datetime . utcnow ( ) . replace ( tzinfo = utc ) :,174
3850,"def _manage_torrent_cache(self): <TAB> """"""Carry tracker/peer/file lists over to new torrent list"""""" <TAB> for torrent in self._torrent_cache: <TAB>  <TAB> new_torrent = rtorrentlib.common.find_torrent(torrent.info_hash, self.torrents) <MASK> new_torrent.files = torrent.files <TAB>  <TAB>  <TAB> new_torrent.peers = torrent.peers <TAB>  <TAB>  <TAB> new_torrent.trackers = torrent.trackers <TAB> self._torrent_cache = self.torrents",if new_torrent is not None :,142
3851,"def _clean_regions(items, region): <TAB> """"""Intersect region with target file if it exists"""""" <TAB> variant_regions = bedutils.population_variant_regions(items, merged=True) <TAB> with utils.tmpfile() as tx_out_file: <TAB>  <TAB> target = subset_variant_regions(variant_regions, region, tx_out_file, items) <TAB>  <TAB> if target: <MASK> target = _load_regions(target) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> target = [target] <TAB>  <TAB>  <TAB> return target","if isinstance ( target , six . string_types ) and os . path . isfile ( target ) :",151
3852,def _get_stdout(self): <TAB> while True: <TAB>  <TAB> BUFFER_SIZE = 1000 <TAB>  <TAB> stdout_buffer = self.kernel.process.GetSTDOUT(BUFFER_SIZE) <MASK> break <TAB>  <TAB> yield stdout_buffer,if len ( stdout_buffer ) == 0 :,67
3853,"def do_query(data, q): <TAB> ret = [] <TAB> if not q: <TAB>  <TAB> return ret <TAB> qkey = q[0] <TAB> for key, value in iterate(data): <TAB>  <TAB> if len(q) == 1: <MASK> ret.append(value) <TAB>  <TAB>  <TAB> elif is_iterable(value): <TAB>  <TAB>  <TAB>  <TAB> ret.extend(do_query(value, q)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if not is_iterable(value): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if key == qkey: <TAB>  <TAB>  <TAB>  <TAB> ret.extend(do_query(value, q[1:])) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> ret.extend(do_query(value, q)) <TAB> return ret",if key == qkey :,185
3854,"def test_expect_setecho_off(self): <TAB> """"""This tests that echo may be toggled off."""""" <TAB> p = pexpect.spawn(""cat"", echo=True, timeout=5) <TAB> try: <TAB>  <TAB> self._expect_echo_toggle(p) <TAB> except IOError: <MASK> if hasattr(unittest, ""SkipTest""): <TAB>  <TAB>  <TAB>  <TAB> raise unittest.SkipTest(""Not supported on this platform."") <TAB>  <TAB>  <TAB> return ""skip"" <TAB>  <TAB> raise","if sys . platform . lower ( ) . startswith ( ""sunos"" ) :",123
3855,"def _resolve_relative_config(dir, config): <TAB> # Some code shared between Notebook and NotebookInfo <TAB> # Resolve icon, can be relative <TAB> icon = config.get(""icon"") <TAB> if icon: <MASK> icon = File(icon) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> icon = dir.resolve_file(icon) <TAB> # Resolve document_root, can also be relative <TAB> document_root = config.get(""document_root"") <TAB> if document_root: <TAB>  <TAB> if zim.fs.isabs(document_root) or not dir: <TAB>  <TAB>  <TAB> document_root = Dir(document_root) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> document_root = dir.resolve_dir(document_root) <TAB> return icon, document_root",if zim . fs . isabs ( icon ) or not dir :,191
3856,"def _providers(self, descriptor): <TAB> res = [] <TAB> for _md in self.metadata.values(): <TAB>  <TAB> for ent_id, ent_desc in _md.items(): <MASK> if ent_id in res: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # print(""duplicated entity_id: %s"" % res) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> res.append(ent_id) <TAB> return res",if descriptor in ent_desc :,118
3857,"def poll_ms(self, timeout=-1): <TAB> s = bytearray(self.evbuf) <TAB> if timeout >= 0: <TAB>  <TAB> deadline = utime.ticks_add(utime.ticks_ms(), timeout) <TAB> while True: <TAB>  <TAB> n = epoll_wait(self.epfd, s, 1, timeout) <TAB>  <TAB> if not os.check_error(n): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if timeout >= 0: <TAB>  <TAB>  <TAB> timeout = utime.ticks_diff(deadline, utime.ticks_ms()) <MASK> n = 0 <TAB>  <TAB>  <TAB>  <TAB> break <TAB> res = [] <TAB> if n > 0: <TAB>  <TAB> vals = struct.unpack(epoll_event, s) <TAB>  <TAB> res.append((vals[1], vals[0])) <TAB> return res",if timeout < 0 :,192
3858,"def banned(): <TAB> if request.endpoint == ""views.themes"": <TAB>  <TAB> return <TAB> if authed(): <TAB>  <TAB> user = get_current_user_attrs() <TAB>  <TAB> team = get_current_team_attrs() <TAB>  <TAB> if user and user.banned: <TAB>  <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB>  <TAB> render_template( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""errors/403.html"", error=""You have been banned from this CTF"" <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB>  <TAB> 403, <TAB>  <TAB>  <TAB> ) <MASK> return ( <TAB>  <TAB>  <TAB>  <TAB> render_template( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""errors/403.html"", <TAB>  <TAB>  <TAB>  <TAB>  <TAB> error=""Your team has been banned from this CTF"", <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB>  <TAB> 403, <TAB>  <TAB>  <TAB> )",if team and team . banned :,193
3859,"def _update_read(self): <TAB> """"""Update state when there is read event"""""" <TAB> try: <TAB>  <TAB> msg = bytes(self._sock.recv(4096)) <TAB>  <TAB> if msg: <TAB>  <TAB>  <TAB> self.on_message(msg) <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> # normal close, remote is closed <TAB>  <TAB> self.close() <TAB> except socket.error as err: <MASK> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.on_error(err) <TAB> return False","if err . args [ 0 ] in ( errno . EAGAIN , errno . EWOULDBLOCK ) :",142
3860,"def update_topic_attr_as_not(modeladmin, request, queryset, attr): <TAB> for topic in queryset: <TAB>  <TAB> if attr == ""sticky"": <TAB>  <TAB>  <TAB> topic.sticky = not topic.sticky <TAB>  <TAB> elif attr == ""closed"": <TAB>  <TAB>  <TAB> topic.closed = not topic.closed <MASK> topic.hidden = not topic.hidden <TAB>  <TAB> topic.save()","elif attr == ""hidden"" :",97
3861,"def Startprobe(self, q): <TAB> while not self.finished: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> sniff(iface=self.interface, count=10, prn=lambda x: q.put(x)) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> pass <MASK> break",if self . finished :,73
3862,"def _maybe_female(self, path_elements, female, strict): <TAB> if female: <MASK> elements = path_elements + [""female""] <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> return self._get_file(elements, "".png"", strict=strict) <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> if strict: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> elif strict: <TAB>  <TAB>  <TAB> raise ValueError(""Pokemon %s has no gender differences"" % self.species_id) <TAB> return self._get_file(path_elements, "".png"", strict=strict)",if self . has_gender_differences :,146
3863,"def change_args_to_dict(string): <TAB> if string is None: <TAB>  <TAB> return None <TAB> ans = [] <TAB> strings = string.split(""\n"") <TAB> ind = 1 <TAB> start = 0 <TAB> while ind <= len(strings): <MASK> ind += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if start < ind: <TAB>  <TAB>  <TAB>  <TAB> ans.append(""\n"".join(strings[start:ind])) <TAB>  <TAB>  <TAB> start = ind <TAB>  <TAB>  <TAB> ind += 1 <TAB> d = {} <TAB> for line in ans: <TAB>  <TAB> if "":"" in line and len(line) > 0: <TAB>  <TAB>  <TAB> lines = line.split("":"") <TAB>  <TAB>  <TAB> d[lines[0]] = lines[1].strip() <TAB> return d","if ind < len ( strings ) and strings [ ind ] . startswith ( "" "" ) :",188
3864,"def _send_with_auth(self, req_kwargs, desired_auth, rsession): <TAB> if desired_auth.oauth: <MASK> self._oauth_creds.refresh(httplib2.Http()) <TAB>  <TAB> req_kwargs[""headers""] = req_kwargs.get(""headers"", {}) <TAB>  <TAB> req_kwargs[""headers""][""Authorization""] = ( <TAB>  <TAB>  <TAB> ""Bearer "" + self._oauth_creds.access_token <TAB>  <TAB> ) <TAB> return rsession.request(**req_kwargs)",if self . _oauth_creds . access_token_expired :,130
3865,"def parse_search_response(json_data): <TAB> """"""Construct response for any input"""""" <TAB> if json_data is None: <TAB>  <TAB> return {""error"": ""Error parsing empty search engine response""} <TAB> try: <TAB>  <TAB> return json.loads(json_data) <TAB> except json.JSONDecodeError: <TAB>  <TAB> logger.exception(""Error parsing search engine response"") <TAB>  <TAB> m = re_pre.search(json_data) <MASK> return {""error"": ""Error parsing search engine response""} <TAB>  <TAB> error = web.htmlunquote(m.group(1)) <TAB>  <TAB> solr_error = ""org.apache.lucene.queryParser.ParseException: "" <TAB>  <TAB> if error.startswith(solr_error): <TAB>  <TAB>  <TAB> error = error[len(solr_error) :] <TAB>  <TAB> return {""error"": error}",if m is None :,198
3866,"def wrapper(*args, **kws): <TAB> missing = [] <TAB> saved = getattr(warnings, ""__warningregistry__"", missing).copy() <TAB> try: <TAB>  <TAB> return func(*args, **kws) <TAB> finally: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> del warnings.__warningregistry__ <TAB>  <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> warnings.__warningregistry__ = saved",if saved is missing :,100
3867,"def parse_expression(self): <TAB> """"""Return string containing command to run."""""" <TAB> expression_el = self.root.find(""expression"") <TAB> if expression_el is not None: <TAB>  <TAB> expression_type = expression_el.get(""type"") <MASK> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> ""Unknown expression type [%s] encountered"" % expression_type <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return expression_el.text <TAB> return None","if expression_type != ""ecma5.1"" :",115
3868,"def test_geocode(): <TAB> # look for tweets from New York ; the search radius is larger than NYC <TAB> # so hopefully we'll find one from New York in the first 500? <TAB> count = 0 <TAB> found = False <TAB> for tweet in T.search(None, geocode=""40.7484,-73.9857,1mi""): <MASK> found = True <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if count > 500: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> count += 1 <TAB> assert found","if ( tweet [ ""place"" ] or { } ) . get ( ""name"" ) == ""Manhattan"" :",138
3869,"def __init__(self, name: Optional[str] = None, order: int = 0): <TAB> if name is None: <MASK> name = ""std_dev"" <TAB>  <TAB> elif order == 1: <TAB>  <TAB>  <TAB> name = ""sample_std_dev"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> name = f""std_dev{order})"" <TAB> super().__init__(name=name, order=order) <TAB> self.order = order",if order == 0 :,109
3870,"def __cmp__(self, other): <TAB> if isinstance(other, date) or isinstance(other, datetime): <TAB>  <TAB> a = self._d.getTime() <TAB>  <TAB> b = other._d.getTime() <MASK> return -1 <TAB>  <TAB> elif a == b: <TAB>  <TAB>  <TAB> return 0 <TAB> else: <TAB>  <TAB> raise TypeError(""expected date or datetime object"") <TAB> return 1",if a < b :,98
3871,"def run(self): <TAB> tid = self.ident <TAB> try: <TAB>  <TAB> with self._lock: <TAB>  <TAB>  <TAB> _GUIS[tid] = self <TAB>  <TAB>  <TAB> self._state(True) <TAB>  <TAB> self.new_mail_notifications(summarize=True) <TAB>  <TAB> loop_count = 0 <TAB>  <TAB> while self._sock: <TAB>  <TAB>  <TAB> loop_count += 1 <TAB>  <TAB>  <TAB> self._select_sleep(1)  # FIXME: Lengthen this when possible <TAB>  <TAB>  <TAB> self.change_state() <MASK> # FIXME: This involves a fair number of set operations, <TAB>  <TAB>  <TAB>  <TAB> # <TAB>  <TAB> should only do this after new mail has arrived. <TAB>  <TAB>  <TAB>  <TAB> self.new_mail_notifications() <TAB> finally: <TAB>  <TAB> del _GUIS[tid]",if loop_count % 5 == 0 :,200
3872,"def __cache_dimension_masks(self, *args): <TAB> # cache masks for each feature map we'll need <TAB> if len(self.masks) == 0: <TAB>  <TAB> for m1 in args: <TAB>  <TAB>  <TAB> batch_size, emb_dim, h, w = m1.size() <TAB>  <TAB>  <TAB> # make mask <MASK> mask = self.feat_size_w_mask(h, m1) <TAB>  <TAB>  <TAB>  <TAB> self.masks[h] = mask",if h not in self . masks :,122
3873,"def __call__(self, *flattened_representation): <TAB> unflattened_representation = [] <TAB> for index, subtree in self.children: <MASK> unflattened_representation.append(flattened_representation[index]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sub_representation = flattened_representation[index] <TAB>  <TAB>  <TAB> unflattened_representation.append(subtree(*sub_representation)) <TAB> return self._cls(*unflattened_representation, **self._kwargs)",if subtree is None :,109
3874,"def click_outside(event): <TAB> if event not in d: <TAB>  <TAB> x, y, z = self.blockFaceUnderCursor[0] <TAB>  <TAB> if y == 0: <TAB>  <TAB>  <TAB> y = 64 <TAB>  <TAB> y += 3 <TAB>  <TAB> gotoPanel.X, gotoPanel.Y, gotoPanel.Z = x, y, z <MASK> d.dismiss(""Goto"")",if event . num_clicks == 2 :,100
3875,"def get_mapped_input_keysequences(self, mode=""global"", prefix=u""""): <TAB> # get all bindings in this mode <TAB> globalmaps, modemaps = self.get_keybindings(mode) <TAB> candidates = list(globalmaps.keys()) + list(modemaps.keys()) <TAB> if prefix is not None: <TAB>  <TAB> prefixes = prefix + "" "" <TAB>  <TAB> cand = [c for c in candidates if c.startswith(prefixes)] <MASK> candidates = cand + [prefix] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> candidates = cand <TAB> return candidates",if prefix in candidates :,136
3876,"def _set_length(self, length): <TAB> with self._cond: <TAB>  <TAB> self._length = length <MASK> self._ready = True <TAB>  <TAB>  <TAB> self._cond.notify() <TAB>  <TAB>  <TAB> del self._cache[self._job]",if self . _index == self . _length :,70
3877,"def _pct_encoded_replace_unreserved(mo): <TAB> try: <TAB>  <TAB> i = int(mo.group(1), 16) <MASK> return chr(i) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return mo.group().upper() <TAB> except ValueError: <TAB>  <TAB> return mo.group()",if _unreserved [ i ] :,81
3878,"def is_open(self): <TAB> if self.signup_code: <TAB>  <TAB> return True <TAB> else: <TAB>  <TAB> if self.signup_code_present: <MASK> messages.add_message( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.request, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.messages[""invalid_signup_code""][""level""], <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.messages[""invalid_signup_code""][""text""].format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> **{ <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""code"": self.get_code(), <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ), <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return settings.ACCOUNT_OPEN_SIGNUP","if self . messages . get ( ""invalid_signup_code"" ) :",172
3879,"def _get_field_value(self, test, key, match): <TAB> if test.ver == ofproto_v1_0.OFP_VERSION: <TAB>  <TAB> members = inspect.getmembers(match) <TAB>  <TAB> for member in members: <MASK> field_value = member[1] <TAB>  <TAB>  <TAB> elif member[0] == ""wildcards"": <TAB>  <TAB>  <TAB>  <TAB> wildcards = member[1] <TAB>  <TAB> if key == ""nw_src"": <TAB>  <TAB>  <TAB> field_value = test.nw_src_to_str(wildcards, field_value) <TAB>  <TAB> elif key == ""nw_dst"": <TAB>  <TAB>  <TAB> field_value = test.nw_dst_to_str(wildcards, field_value) <TAB> else: <TAB>  <TAB> field_value = match[key] <TAB> return field_value",if member [ 0 ] == key :,200
3880,"def move_sender_strings_to_sender_model(apps, schema_editor): <TAB> sender_model = apps.get_model(""documents"", ""Sender"") <TAB> document_model = apps.get_model(""documents"", ""Document"") <TAB> # Create the sender and log the relationship with the document <TAB> for document in document_model.objects.all(): <MASK> ( <TAB>  <TAB>  <TAB>  <TAB> DOCUMENT_SENDER_MAP[document.pk], <TAB>  <TAB>  <TAB>  <TAB> created, <TAB>  <TAB>  <TAB> ) = sender_model.objects.get_or_create( <TAB>  <TAB>  <TAB>  <TAB> name=document.sender, defaults={""slug"": slugify(document.sender)} <TAB>  <TAB>  <TAB> )",if document . sender :,160
3881,"def compute_output_shape(self, input_shape): <TAB> if None not in input_shape[1:]: <MASK> total = np.prod(input_shape[2:4]) * self.num_anchors <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> total = np.prod(input_shape[1:3]) * self.num_anchors <TAB>  <TAB> return (input_shape[0], total, 4) <TAB> else: <TAB>  <TAB> return (input_shape[0], None, 4)","if keras . backend . image_data_format ( ) == ""channels_first"" :",135
3882,"def decompress(self, value): <TAB> if value: <TAB>  <TAB> if type(value) == PhoneNumber: <MASK> return [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""+%d"" % value.country_code, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> national_significant_number(value), <TAB>  <TAB>  <TAB>  <TAB> ] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return value.split(""."") <TAB> return [None, """"]",if value . country_code and value . national_number :,111
3883,"def ignore(self, other): <TAB> if isinstance(other, Suppress): <MASK> super(ParseElementEnhance, self).ignore(other) <TAB>  <TAB>  <TAB> if self.expr is not None: <TAB>  <TAB>  <TAB>  <TAB> self.expr.ignore(self.ignoreExprs[-1]) <TAB> else: <TAB>  <TAB> super(ParseElementEnhance, self).ignore(other) <TAB>  <TAB> if self.expr is not None: <TAB>  <TAB>  <TAB> self.expr.ignore(self.ignoreExprs[-1]) <TAB> return self",if other not in self . ignoreExprs :,129
3884,"def mkdir(self, mode=0o777, parents=False, exist_ok=False): <TAB> if self._closed: <TAB>  <TAB> self._raise_closed() <TAB> if not parents: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self._accessor.mkdir(self, mode) <TAB>  <TAB> except FileExistsError: <MASK> raise <TAB> else: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self._accessor.mkdir(self, mode) <TAB>  <TAB> except FileExistsError: <TAB>  <TAB>  <TAB> if not exist_ok or not self.is_dir(): <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> except OSError as e: <TAB>  <TAB>  <TAB> if e.errno != ENOENT: <TAB>  <TAB>  <TAB>  <TAB> raise <TAB>  <TAB>  <TAB> self.parent.mkdir(parents=True) <TAB>  <TAB>  <TAB> self._accessor.mkdir(self, mode)",if not exist_ok or not self . is_dir ( ) :,199
3885,"def _mark_lcs(mask, dirs, m, n): <TAB> while m != 0 and n != 0: <TAB>  <TAB> if dirs[m, n] == ""|"": <TAB>  <TAB>  <TAB> m -= 1 <TAB>  <TAB>  <TAB> n -= 1 <TAB>  <TAB>  <TAB> mask[m] = 1 <TAB>  <TAB> elif dirs[m, n] == ""^"": <TAB>  <TAB>  <TAB> m -= 1 <MASK> n -= 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise UnboundLocalError(""Illegal move"") <TAB> return mask","elif dirs [ m , n ] == ""<"" :",122
3886,"def clean(self, *args, **kwargs): <TAB> data = super().clean(*args, **kwargs) <TAB> if isinstance(data, File): <TAB>  <TAB> filename = data.name <TAB>  <TAB> ext = os.path.splitext(filename)[1] <TAB>  <TAB> ext = ext.lower() <MASK> raise forms.ValidationError(_(""Filetype not allowed!"")) <TAB> return data",if ext not in self . ext_whitelist :,97
3887,"def get_doc_object(obj, what=None): <TAB> if what is None: <TAB>  <TAB> if inspect.isclass(obj): <TAB>  <TAB>  <TAB> what = ""class"" <MASK> what = ""module"" <TAB>  <TAB> elif callable(obj): <TAB>  <TAB>  <TAB> what = ""function"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> what = ""object"" <TAB> if what == ""class"": <TAB>  <TAB> return SphinxClassDoc(obj, """", func_doc=SphinxFunctionDoc) <TAB> elif what in (""function"", ""method""): <TAB>  <TAB> return SphinxFunctionDoc(obj, """") <TAB> else: <TAB>  <TAB> return SphinxDocString(pydoc.getdoc(obj))",elif inspect . ismodule ( obj ) :,161
3888,"def apply_pssm(val): <TAB> if val is not None: <TAB>  <TAB> val_c = PSSM_VALUES.get(val, None) <MASK> assert isinstance( <TAB>  <TAB>  <TAB>  <TAB> val, tuple(PSSM_VALUES.values()) <TAB>  <TAB>  <TAB> ), ""'store_as' should be one of: %r or an instance of %r not %r"" % ( <TAB>  <TAB>  <TAB>  <TAB> tuple(PSSM_VALUES.keys()), <TAB>  <TAB>  <TAB>  <TAB> tuple(PSSM_VALUES.values()), <TAB>  <TAB>  <TAB>  <TAB> val, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return val <TAB>  <TAB> return val_c()",if val_c is None :,155
3889,"def read_postmaster_opts(self): <TAB> """"""returns the list of option names/values from postgres.opts, Empty dict if read failed or no file"""""" <TAB> result = {} <TAB> try: <TAB>  <TAB> with open(os.path.join(self._postgresql.data_dir, ""postmaster.opts"")) as f: <TAB>  <TAB>  <TAB> data = f.read() <TAB>  <TAB>  <TAB> for opt in data.split('"" ""'): <MASK> name, val = opt.split(""="", 1) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> result[name.strip(""-"")] = val.rstrip('""\n') <TAB> except IOError: <TAB>  <TAB> logger.exception(""Error when reading postmaster.opts"") <TAB> return result","if ""="" in opt and opt . startswith ( ""--"" ) :",169
3890,"def detect(get_page): <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS: <TAB>  <TAB> page, headers, code = get_page(get=vector) <TAB>  <TAB> retval = ( <TAB>  <TAB>  <TAB> re.search(r""F5-TrafficShield"", headers.get(HTTP_HEADER.SERVER, """"), re.I) <TAB>  <TAB>  <TAB> is not None <TAB>  <TAB> ) <TAB>  <TAB> retval |= ( <TAB>  <TAB>  <TAB> re.search(r""\AASINFO="", headers.get(HTTP_HEADER.SET_COOKIE, """"), re.I) <TAB>  <TAB>  <TAB> is not None <TAB>  <TAB> ) <MASK> break <TAB> return retval",if retval :,159
3891,"def on_task_start(self, task, config): <TAB> for item in config: <TAB>  <TAB> for plugin_name, plugin_config in item.items(): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> thelist = plugin.get(plugin_name, self).get_list(plugin_config) <TAB>  <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB>  <TAB> raise PluginError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Plugin %s does not support list interface"" % plugin_name <TAB>  <TAB>  <TAB>  <TAB> ) <MASK> raise plugin.PluginError(thelist.immutable)",if thelist . immutable :,139
3892,"def nq(t): <TAB> p = t[0] if (t and t[0] in ""-+"") else """" <TAB> t = t[len(p) :] <TAB> if t.startswith(""tag:"") or t.startswith(""in:""): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> raw_tag = session.config.get_tag(t.split("":"")[1]) <MASK> t = ""in:%s"" % raw_tag.slug <TAB>  <TAB> except (IndexError, KeyError, TypeError): <TAB>  <TAB>  <TAB> pass <TAB> return p + t",if raw_tag and raw_tag . hasattr ( slug ) :,139
3893,"def _recur_strip(s): <TAB> if is_str(s): <MASK> return "" "".join(s.strip().split()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return "" "".join(s.strip().split()).replace(bos_token + "" "", """") <TAB> else: <TAB>  <TAB> s_ = [_recur_strip(si) for si in s] <TAB>  <TAB> return _maybe_list_to_array(s_, s)","if bos_token == """" :",110
3894,"def __delitem__(self, key): <TAB> ""Deleting tag[key] deletes all 'key' attributes for the tag."" <TAB> for item in self.attrs: <MASK> self.attrs.remove(item) <TAB>  <TAB>  <TAB> # We don't break because bad HTML can define the same <TAB>  <TAB>  <TAB> # attribute multiple times. <TAB>  <TAB> self._getAttrMap() <TAB>  <TAB> if self.attrMap.has_key(key): <TAB>  <TAB>  <TAB> del self.attrMap[key]",if item [ 0 ] == key :,119
3895,"def comment_import_help(init_file, out_file): <TAB> f_out = open(out_file, ""w"") <TAB> output = """" <TAB> updated = False <TAB> with open(init_file, ""r"") as f_in: <TAB>  <TAB> for line in f_in: <MASK> updated = True <TAB>  <TAB>  <TAB>  <TAB> line = ""# "" + line <TAB>  <TAB>  <TAB> output += line <TAB> f_out.write(output) <TAB> f_out.close() <TAB> return updated","if ""import"" in line and ""_help"" in line and not updated :",136
3896,"def prepare_text(lines): <TAB> out = [] <TAB> for s in lines.split(""|""): <TAB>  <TAB> s = s.strip() <MASK> # line beginning with '/' is in italics <TAB>  <TAB>  <TAB> s = r""{\i1}%s{\i0}"" % s[1:].strip() <TAB>  <TAB> out.append(s) <TAB> return ""\\N"".join(out)","if s . startswith ( ""/"" ) :",96
3897,"def sqlctx(sc): <TAB> pytest.importorskip(""pyspark"") <TAB> from odo.backends.sparksql import HiveContext <TAB> try: <TAB>  <TAB> yield HiveContext(sc) <TAB> finally: <TAB>  <TAB> dbpath = ""metastore_db"" <TAB>  <TAB> logpath = ""derby.log"" <MASK> assert os.path.isdir(dbpath) <TAB>  <TAB>  <TAB> shutil.rmtree(dbpath) <TAB>  <TAB> if os.path.exists(logpath): <TAB>  <TAB>  <TAB> assert os.path.isfile(logpath) <TAB>  <TAB>  <TAB> os.remove(logpath)",if os . path . exists ( dbpath ) :,147
3898,"def _user2dict(self, uid): <TAB> usdict = None <TAB> if uid in self.users: <TAB>  <TAB> usdict = self.users[uid] <MASK> infos = self.users_info[uid] <TAB>  <TAB>  <TAB> for attr in infos: <TAB>  <TAB>  <TAB>  <TAB> usdict[attr[""attr_type""]] = attr[""attr_data""] <TAB>  <TAB> usdict[""uid""] = uid <TAB> return usdict",if uid in self . users_info :,109
3899,"def _validate_options(self): <TAB> for option in self.options: <TAB>  <TAB> # if value type is bool or int, then we know the options is set <MASK> if self.options.required[option] is True and not self.options[option]: <TAB>  <TAB>  <TAB>  <TAB> if option == Constants.PASSWORD_CLEAR: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> option = ""password"".upper() <TAB>  <TAB>  <TAB>  <TAB> raise FrameworkException( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Value required for the '%s' option."" % (option.upper()) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return","if not type ( self . options [ option ] ) in [ bool , int ] :",148
3900,"def _copy_package_apps( <TAB> local_bin_dir: Path, app_paths: List[Path], suffix: str = """") -> None: <TAB> for src_unresolved in app_paths: <TAB>  <TAB> src = src_unresolved.resolve() <TAB>  <TAB> app = src.name <TAB>  <TAB> dest = Path(local_bin_dir / add_suffix(app, suffix)) <MASK> mkdir(dest.parent) <TAB>  <TAB> if dest.exists(): <TAB>  <TAB>  <TAB> logger.warning(f""{hazard}  Overwriting file {str(dest)} with {str(src)}"") <TAB>  <TAB>  <TAB> dest.unlink() <TAB>  <TAB> if src.exists(): <TAB>  <TAB>  <TAB> shutil.copy(src, dest)",if not dest . parent . is_dir ( ) :,177
3901,"def truncate_seq_pair(tokens_a, tokens_b, max_length): <TAB> """"""Truncates a sequence pair in place to the maximum length."""""" <TAB> # This is a simple heuristic which will always truncate the longer sequence <TAB> # one token at a time. This makes more sense than truncating an equal percent <TAB> # of tokens from each, since if one sequence is very short then each token <TAB> # that's truncated likely contains more information than a longer sequence. <TAB> while True: <TAB>  <TAB> total_length = len(tokens_a) + len(tokens_b) <MASK> break <TAB>  <TAB> if len(tokens_a) > len(tokens_b): <TAB>  <TAB>  <TAB> tokens_a.pop() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tokens_b.pop()",if total_length <= max_length :,185
3902,"def add_channels(cls, voucher, add_channels): <TAB> for add_channel in add_channels: <TAB>  <TAB> channel = add_channel[""channel""] <TAB>  <TAB> defaults = {""currency"": channel.currency_code} <TAB>  <TAB> if ""discount_value"" in add_channel.keys(): <TAB>  <TAB>  <TAB> defaults[""discount_value""] = add_channel.get(""discount_value"") <MASK> defaults[""min_spent_amount""] = add_channel.get(""min_amount_spent"", None) <TAB>  <TAB> models.VoucherChannelListing.objects.update_or_create( <TAB>  <TAB>  <TAB> voucher=voucher, <TAB>  <TAB>  <TAB> channel=channel, <TAB>  <TAB>  <TAB> defaults=defaults, <TAB>  <TAB> )","if ""min_amount_spent"" in add_channel . keys ( ) :",176
3903,"def services(self, id=None, name=None): <TAB> for service_dict in self.service_ls(id=id, name=name): <TAB>  <TAB> service_id = service_dict[""ID""] <TAB>  <TAB> service_name = service_dict[""NAME""] <MASK> continue <TAB>  <TAB> task_list = self.service_ps(service_id) <TAB>  <TAB> yield DockerService.from_cli(self, service_dict, task_list)",if not service_name . startswith ( self . _name_prefix ) :,121
3904,"def lll(dirname): <TAB> for name in os.listdir(dirname): <MASK> full = os.path.join(dirname, name) <TAB>  <TAB>  <TAB> if os.path.islink(full): <TAB>  <TAB>  <TAB>  <TAB> print(name, ""->"", os.readlink(full))","if name not in ( os . curdir , os . pardir ) :",80
3905,"def convertstore(self, mydict): <TAB> targetheader = self.mypofile.header() <TAB> targetheader.addnote(""extracted from web2py"", ""developer"") <TAB> for source_str in mydict.keys(): <TAB>  <TAB> target_str = mydict[source_str] <MASK> # a convention with new (untranslated) web2py files <TAB>  <TAB>  <TAB> target_str = u"""" <TAB>  <TAB> elif target_str.startswith(u""*** ""): <TAB>  <TAB>  <TAB> # an older convention <TAB>  <TAB>  <TAB> target_str = u"""" <TAB>  <TAB> pounit = self.convertunit(source_str, target_str) <TAB>  <TAB> self.mypofile.addunit(pounit) <TAB> return self.mypofile",if target_str == source_str :,180
3906,"def __init__(self, **kwargs): <TAB> for k, v in kwargs.items(): <TAB>  <TAB> setattr(self, k, v) <TAB> self.attempted_charsets = set() <TAB> request = cherrypy.serving.request <TAB> if request.handler is not None: <TAB>  <TAB> # Replace request.handler with self <MASK> cherrypy.log(""Replacing request.handler"", ""TOOLS.ENCODE"") <TAB>  <TAB> self.oldhandler = request.handler <TAB>  <TAB> request.handler = self",if self . debug :,128
3907,"def _fastqc_data_section(self, section_name): <TAB> out = [] <TAB> in_section = False <TAB> data_file = os.path.join(self._dir, ""fastqc_data.txt"") <TAB> if os.path.exists(data_file): <TAB>  <TAB> with open(data_file) as in_handle: <TAB>  <TAB>  <TAB> for line in in_handle: <TAB>  <TAB>  <TAB>  <TAB> if line.startswith("">>%s"" % section_name): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> in_section = True <MASK> if line.startswith("">>END""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB>  <TAB>  <TAB> out.append(line.rstrip(""\r\n"")) <TAB> return out",elif in_section :,173
3908,"def bit_length(n): <TAB> try: <TAB>  <TAB> return n.bit_length() <TAB> except AttributeError: <TAB>  <TAB> norm = deflate_long(n, False) <TAB>  <TAB> hbyte = byte_ord(norm[0]) <MASK> return 1 <TAB>  <TAB> bitlen = len(norm) * 8 <TAB>  <TAB> while not (hbyte & 0x80): <TAB>  <TAB>  <TAB> hbyte <<= 1 <TAB>  <TAB>  <TAB> bitlen -= 1 <TAB>  <TAB> return bitlen",if hbyte == 0 :,118
3909,"def step(self, action): <TAB> """"""Repeat action, sum reward, and max over last observations."""""" <TAB> total_reward = 0.0 <TAB> done = None <TAB> for i in range(self._skip): <TAB>  <TAB> obs, reward, done, info = self.env.step(action) <TAB>  <TAB> if i == self._skip - 2: <TAB>  <TAB>  <TAB> self._obs_buffer[0] = obs <TAB>  <TAB> if i == self._skip - 1: <TAB>  <TAB>  <TAB> self._obs_buffer[1] = obs <TAB>  <TAB> total_reward += reward <MASK> break <TAB> # Note that the observation on the done=True frame <TAB> # doesn't matter <TAB> max_frame = self._obs_buffer.max(axis=0) <TAB> return max_frame, total_reward, done, info",if done :,189
3910,"def _sample_translation(reference, max_len): <TAB> translation = reference[:] <TAB> while np.random.uniform() < 0.8 and 1 < len(translation) < max_len: <TAB>  <TAB> trans_len = len(translation) <TAB>  <TAB> ind = np.random.randint(trans_len) <TAB>  <TAB> action = np.random.choice(actions) <MASK> del translation[ind] <TAB>  <TAB> elif action == ""replacement"": <TAB>  <TAB>  <TAB> ind_rep = np.random.randint(trans_len) <TAB>  <TAB>  <TAB> translation[ind] = translation[ind_rep] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ind_insert = np.random.randint(trans_len) <TAB>  <TAB>  <TAB> translation.insert(ind, translation[ind_insert]) <TAB> return translation","if action == ""deletion"" :",186
3911,"def group_by_sign(seq, slop=sin(pi / 18), key=lambda x: x): <TAB> sign = None <TAB> subseq = [] <TAB> for i in seq: <TAB>  <TAB> ki = key(i) <TAB>  <TAB> if sign is None: <TAB>  <TAB>  <TAB> subseq.append(i) <MASK> sign = ki / abs(ki) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> subseq.append(i) <TAB>  <TAB>  <TAB> if sign * ki < -slop: <TAB>  <TAB>  <TAB>  <TAB> sign = ki / abs(ki) <TAB>  <TAB>  <TAB>  <TAB> yield subseq <TAB>  <TAB>  <TAB>  <TAB> subseq = [i] <TAB> if subseq: <TAB>  <TAB> yield subseq",if ki != 0 :,167
3912,def get_dirlist(_rootdir): <TAB> dirlist = [] <TAB> with os.scandir(_rootdir) as rit: <TAB>  <TAB> for entry in rit: <MASK> dirlist.append(entry.path) <TAB>  <TAB>  <TAB>  <TAB> dirlist += get_dirlist(entry.path) <TAB> return dirlist,"if not entry . name . startswith ( ""."" ) and entry . is_dir ( ) :",91
3913,"def __init__( <TAB> self, <TAB> fixed: MQTTFixedHeader = None, <TAB> variable_header: PublishVariableHeader = None, <TAB> payload=None,): <TAB> if fixed is None: <TAB>  <TAB> header = MQTTFixedHeader(PUBLISH, 0x00) <TAB> else: <MASK> raise HBMQTTException( <TAB>  <TAB>  <TAB>  <TAB> ""Invalid fixed packet type %s for PublishPacket init"" <TAB>  <TAB>  <TAB>  <TAB> % fixed.packet_type <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> header = fixed <TAB> super().__init__(header) <TAB> self.variable_header = variable_header <TAB> self.payload = payload",if fixed . packet_type is not PUBLISH :,160
3914,"def get_files(d): <TAB> res = [] <TAB> for p in glob.glob(os.path.join(d, ""*"")): <TAB>  <TAB> if not p: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> (pth, fname) = os.path.split(p) <MASK> continue <TAB>  <TAB> if fname == ""PureMVC_Python_1_0"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if fname[-4:] == "".pyc"":  # ehmm.. no. <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if os.path.isdir(p): <TAB>  <TAB>  <TAB> get_dir(p) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> res.append(p) <TAB> return res","if fname == ""output"" :",162
3915,"def reward(self): <TAB> """"""Returns a tuple of sum of raw and processed rewards."""""" <TAB> raw_rewards, processed_rewards = 0, 0 <TAB> for ts in self.time_steps: <TAB>  <TAB> # NOTE: raw_reward and processed_reward are None for the first time-step. <MASK> raw_rewards += ts.raw_reward <TAB>  <TAB> if ts.processed_reward is not None: <TAB>  <TAB>  <TAB> processed_rewards += ts.processed_reward <TAB> return raw_rewards, processed_rewards",if ts . raw_reward is not None :,134
3916,"def _process_file(self, content): <TAB> args = [] <TAB> for line in content.splitlines(): <TAB>  <TAB> line = line.strip() <MASK> args.extend(self._split_option(line)) <TAB>  <TAB> elif line and not line.startswith(""#""): <TAB>  <TAB>  <TAB> args.append(line) <TAB> return args","if line . startswith ( ""-"" ) :",83
3917,"def __on_change_button_clicked(self, widget=None): <TAB> """"""compute all primary objects and toggle the 'Change' attribute"""""" <TAB> self.change_status = not self.change_status <TAB> for prim_obj, tmp in self.xobjects: <TAB>  <TAB> obj_change = self.top.get_object(""%s_change"" % prim_obj) <MASK> continue <TAB>  <TAB> self.change_entries[prim_obj].set_val(self.change_status) <TAB>  <TAB> obj_change.set_active(self.change_status)",if not obj_change . get_sensitive ( ) :,145
3918,"def aiter_cogs(cls) -> AsyncIterator[Tuple[str, str]]: <TAB> yield ""Core"", ""0"" <TAB> for _dir in data_manager.cog_data_path().iterdir(): <TAB>  <TAB> fpath = _dir / ""settings.json"" <TAB>  <TAB> if not fpath.exists(): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> with fpath.open() as f: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> data = json.load(f) <TAB>  <TAB>  <TAB> except json.JSONDecodeError: <TAB>  <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> cog_name = _dir.stem <TAB>  <TAB> for cog_id, inner in data.items(): <TAB>  <TAB>  <TAB> if not isinstance(inner, dict): <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> yield cog_name, cog_id","if not isinstance ( data , dict ) :",192
3919,"def _verifySubs(self): <TAB> for inst in self.subs: <TAB>  <TAB> if not isinstance(inst, (_Block, _Instantiator, Cosimulation)): <TAB>  <TAB>  <TAB> raise BlockError(_error.ArgType % (self.name,)) <TAB>  <TAB> if isinstance(inst, (_Block, _Instantiator)): <MASK> raise BlockError(_error.InstanceError % (self.name, inst.callername))",if not inst . modctxt :,110
3920,"def _is_xml(accepts): <TAB> if accepts.startswith(b""application/""): <TAB>  <TAB> has_xml = accepts.find(b""xml"") <TAB>  <TAB> if has_xml > 0: <TAB>  <TAB>  <TAB> semicolon = accepts.find(b"";"") <MASK> return True <TAB> return False",if semicolon < 0 or has_xml < semicolon :,86
3921,"def _accept_with(cls, orm, target): <TAB> if target is orm.mapper: <TAB>  <TAB> return mapperlib.Mapper <TAB> elif isinstance(target, type): <MASK> return target <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> mapper = _mapper_or_none(target) <TAB>  <TAB>  <TAB> if mapper is not None: <TAB>  <TAB>  <TAB>  <TAB> return mapper <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return _MapperEventsHold(target) <TAB> else: <TAB>  <TAB> return target","if issubclass ( target , mapperlib . Mapper ) :",123
3922,"def _get_font_afm(self, prop): <TAB> key = hash(prop) <TAB> font = self.afmfontd.get(key) <MASK> fname = findfont(prop, fontext=""afm"") <TAB>  <TAB> font = self.afmfontd.get(fname) <TAB>  <TAB> if font is None: <TAB>  <TAB>  <TAB> font = AFM(file(findfont(prop, fontext=""afm""))) <TAB>  <TAB>  <TAB> self.afmfontd[fname] = font <TAB>  <TAB> self.afmfontd[key] = font <TAB> return font",if font is None :,142
3923,"def __call__(self, groupby): <TAB> normalize_reduction_funcs(self, ndim=groupby.ndim) <TAB> df = groupby <TAB> while df.op.output_types[0] not in (OutputType.dataframe, OutputType.series): <TAB>  <TAB> df = df.inputs[0] <TAB> if self.raw_func == ""size"": <TAB>  <TAB> self.output_types = [OutputType.series] <TAB> else: <TAB>  <TAB> self.output_types = ( <TAB>  <TAB>  <TAB> [OutputType.dataframe] <MASK> else [OutputType.series] <TAB>  <TAB> ) <TAB> if self.output_types[0] == OutputType.dataframe: <TAB>  <TAB> return self._call_dataframe(groupby, df) <TAB> else: <TAB>  <TAB> return self._call_series(groupby, df)",if groupby . op . output_types [ 0 ] == OutputType . dataframe_groupby,197
3924,"def save(self): <TAB> if self.preferences.get(ENCRYPT_ON_DISK, False): <MASK> return self.storage.write( <TAB>  <TAB>  <TAB>  <TAB> self.to_dict(encrypt_password=self.encryption_password) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> elif not self.is_locked: <TAB>  <TAB>  <TAB> log.warning( <TAB>  <TAB>  <TAB>  <TAB> ""Disk encryption requested but no password available for encryption. "" <TAB>  <TAB>  <TAB>  <TAB> ""Resetting encryption preferences and saving wallet in an unencrypted state."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.preferences[ENCRYPT_ON_DISK] = False <TAB> return self.storage.write(self.to_dict())",if self . encryption_password is not None :,164
3925,"def isValidDateString(config_param_name, value, valid_value): <TAB> try: <TAB>  <TAB> if value == ""DD-MM-YYYY"": <TAB>  <TAB>  <TAB> return value <TAB>  <TAB> day, month, year = value.split(""-"") <TAB>  <TAB> if int(day) < 1 or int(day) > 31: <TAB>  <TAB>  <TAB> raise DateStringValueError(config_param_name, value) <MASK> raise DateStringValueError(config_param_name, value) <TAB>  <TAB> if int(year) < 1900 or int(year) > 2013: <TAB>  <TAB>  <TAB> raise DateStringValueError(config_param_name, value) <TAB>  <TAB> return value <TAB> except Exception: <TAB>  <TAB> raise DateStringValueError(config_param_name, value)",if int ( month ) < 1 or int ( month ) > 12 :,187
3926,"def _capture(self, call_name, data=None, **kwargs): <TAB> if data is None: <TAB>  <TAB> data = self.get_default_context() <TAB> else: <TAB>  <TAB> default_context = self.get_default_context() <MASK> default_context.update(data) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> default_context[""extra""][""extra_data""] = data <TAB>  <TAB> data = default_context <TAB> client = self.get_sentry_client() <TAB> return getattr(client, call_name)(data=data, **kwargs)","if isinstance ( data , dict ) :",139
3927,"def check(input, expected_output=None, expected_ffi_error=False): <TAB> import _cffi_backend <TAB> ffi = _cffi_backend.FFI() <TAB> if not expected_ffi_error: <TAB>  <TAB> ct = ffi.typeof(input) <TAB>  <TAB> assert isinstance(ct, ffi.CType) <TAB>  <TAB> assert ct.cname == (expected_output or input) <TAB> else: <TAB>  <TAB> e = py.test.raises(ffi.error, ffi.typeof, input) <MASK> assert str(e.value) == expected_ffi_error","if isinstance ( expected_ffi_error , str ) :",157
3928,"def run(self): <TAB> """"""Process queries from task queue, stop if processor is None."""""" <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> processor, iprot, oprot, otrans, callback = self.queue.get() <MASK> break <TAB>  <TAB>  <TAB> processor.process(iprot, oprot) <TAB>  <TAB>  <TAB> callback(True, otrans.getvalue()) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> logging.exception(""Exception while processing request"") <TAB>  <TAB>  <TAB> callback(False, """")",if processor is None :,128
3929,"def search(self, query): <TAB> query = query.strip().lower() <TAB> results = [] <TAB> for provider in SidebarItemProvider.all(self.context): <TAB>  <TAB> for item in provider.provide(): <TAB>  <TAB>  <TAB> if ""url"" in item: <TAB>  <TAB>  <TAB>  <TAB> search_source = ""$"".join( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> [item.get(""id"", """"), item.get(""name"", """")] <TAB>  <TAB>  <TAB>  <TAB> ).lower() <MASK> results.append( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""title"": item[""name""], <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""icon"": item[""icon""], <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""url"": item[""url""], <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return results",if query in search_source :,197
3930,"def handle(self) -> None: <TAB> """"""Handles a request ignoring dropped connections."""""" <TAB> try: <TAB>  <TAB> BaseHTTPRequestHandler.handle(self) <TAB> except (ConnectionError, socket.timeout) as e: <TAB>  <TAB> self.connection_dropped(e) <TAB> except Exception as e: <MASK> self.log_error(""SSL error occurred: %s"", e) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise <TAB> if self.server.shutdown_signal: <TAB>  <TAB> self.initiate_shutdown()",if self . server . ssl_context is not None and is_ssl_error ( e ) :,137
3931,"def cdn_url_handler(error, endpoint, kwargs): <TAB> if endpoint == ""cdn"": <TAB>  <TAB> path = kwargs.pop(""path"") <TAB>  <TAB> # cdn = app.config.get('cdn', 'http://cdn.staticfile.org/') <TAB>  <TAB> # cdn = app.config.get('cdn', '//cdnjs.cloudflare.com/ajax/libs/') <TAB>  <TAB> cdn = app.config.get(""cdn"", ""//cdnjscn.b0.upaiyun.com/libs/"") <TAB>  <TAB> return urljoin(cdn, path) <TAB> else: <TAB>  <TAB> exc_type, exc_value, tb = sys.exc_info() <MASK> reraise(exc_type, exc_value, tb) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise error",if exc_value is error :,186
3932,"def pairs(self): <TAB> for path in os.listdir(""src""): <TAB>  <TAB> if path == "".svn"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> dep = join(""src"", path) <MASK> continue <TAB>  <TAB> yield dep, join(build_dir, path)",if isdir ( dep ) :,69
3933,"def get_condition(self): <TAB> """"""Return the condition element's name."""""" <TAB> for child in self.xml: <MASK> cond = child.tag.split(""}"", 1)[-1] <TAB>  <TAB>  <TAB> if cond in self.conditions: <TAB>  <TAB>  <TAB>  <TAB> return cond <TAB> return ""not-authorized""","if ""{%s}"" % self . namespace in child . tag :",85
3934,"def end(self, tag): <TAB> # call the appropriate end tag handler <TAB> try: <TAB>  <TAB> f = self.dispatch[tag] <TAB> except KeyError: <MASK> return  # unknown tag ? <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> f = self.dispatch[tag.split("":"")[-1]] <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> return  # unknown tag ? <TAB> return f(self, """".join(self._data))","if "":"" not in tag :",107
3935,"def checkIfSessionCodeExists(self, sessionCode): <TAB> if self.emrtFile: <TAB>  <TAB> sessionsForExperiment = ( <TAB>  <TAB>  <TAB> self.emrtFile.root.data_collection.session_meta_data.where( <TAB>  <TAB>  <TAB>  <TAB> ""experiment_id == %d"" % (self.active_experiment_id,) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB>  <TAB> sessionCodeMatch = [ <TAB>  <TAB>  <TAB> sess for sess in sessionsForExperiment if sess[""code""] == sessionCode <TAB>  <TAB> ] <MASK> return True <TAB>  <TAB> return False",if len ( sessionCodeMatch ) > 0 :,145
3936,"def save_bytearray(self, obj): <TAB> if self.proto < 5: <MASK> # bytearray is empty <TAB>  <TAB>  <TAB> self.save_reduce(bytearray, (), obj=obj) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.save_reduce(bytearray, (bytes(obj),), obj=obj) <TAB>  <TAB> return <TAB> n = len(obj) <TAB> if n >= self.framer._FRAME_SIZE_TARGET: <TAB>  <TAB> self._write_large_bytes(BYTEARRAY8 + pack(""<Q"", n), obj) <TAB> else: <TAB>  <TAB> self.write(BYTEARRAY8 + pack(""<Q"", n) + obj)",if not obj :,151
3937,"def _restore_freeze(self, new): <TAB> size_change = [] <TAB> for k, v in six.iteritems(self._freeze_backup): <TAB>  <TAB> newv = new.get(k, []) <MASK> size_change.append((self._key_name(k), len(v), len(newv))) <TAB> if size_change: <TAB>  <TAB> logger.info( <TAB>  <TAB>  <TAB> ""These collections were modified but restored in {}: {}"".format( <TAB>  <TAB>  <TAB>  <TAB> self._name, <TAB>  <TAB>  <TAB>  <TAB> "", "".join(map(lambda t: ""({}: {}->{})"".format(*t), size_change)), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB> restore_collection(self._freeze_backup)",if len ( v ) != len ( newv ) :,176
3938,"def check_options(self, expr, evaluation, options): <TAB> for key in options: <TAB>  <TAB> if key != ""System`SameTest"": <MASK> evaluation.message(""ContainsOnly"", ""optx"", Symbol(key)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return evaluation.message(""ContainsOnly"", ""optx"", Symbol(key), expr) <TAB> return None",if expr is None :,91
3939,"def bundle_directory(self, dirpath): <TAB> """"""Bundle all modules/packages in the given directory."""""" <TAB> dirpath = os.path.abspath(dirpath) <TAB> for nm in os.listdir(dirpath): <TAB>  <TAB> nm = _u(nm) <TAB>  <TAB> if nm.startswith("".""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> itempath = os.path.join(dirpath, nm) <TAB>  <TAB> if os.path.isdir(itempath): <MASK> self.bundle_package(itempath) <TAB>  <TAB> elif nm.endswith("".py""): <TAB>  <TAB>  <TAB> self.bundle_module(itempath)","if os . path . exists ( os . path . join ( itempath , ""__init__.py"" ) ) :",160
3940,"def _read_block(self, size): <TAB> if self._file_end is not None: <TAB>  <TAB> max_size = self._file_end - self._file.tell() <MASK> size = max_size <TAB>  <TAB> size = max(min(size, max_size), 0) <TAB> return self._file.read(size)",if size == - 1 :,88
3941,"def question_mark(self): <TAB> """"""Shows help for this command and it's sub-commands."""""" <TAB> ret = [] <TAB> if self.param_help_msg or len(self.subcommands) == 0: <TAB>  <TAB> ret.append(self._quick_help()) <TAB> if len(self.subcommands) > 0: <TAB>  <TAB> for k, _ in sorted(self.subcommands.items()): <TAB>  <TAB>  <TAB> command_path, param_help, cmd_help = self._instantiate_subcommand( <TAB>  <TAB>  <TAB>  <TAB> k <TAB>  <TAB>  <TAB> )._quick_help(nested=True) <MASK> ret.append((command_path, param_help, cmd_help)) <TAB> return (CommandsResponse(STATUS_OK, self.help_formatter(ret)), self.__class__)",if command_path or param_help or cmd_help :,193
3942,"def list_domains(self, r53, **kwargs): <TAB> marker = None <TAB> domains = [] <TAB> while True: <TAB>  <TAB> if marker: <TAB>  <TAB>  <TAB> response = self.wrap_aws_rate_limited_call(r53.list_domains(Marker=marker)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> response = self.wrap_aws_rate_limited_call(r53.list_domains) <TAB>  <TAB> for domain in response.get(""Domains""): <TAB>  <TAB>  <TAB> domains.append(domain) <MASK> marker = response.get(""NextPageMarker"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> return domains","if response . get ( ""NextPageMarker"" ) :",157
3943,"def writer(stream, items): <TAB> sep = """" <TAB> for item in items: <TAB>  <TAB> stream.write(sep) <TAB>  <TAB> sep = "" "" <TAB>  <TAB> if not isinstance(item, str): <TAB>  <TAB>  <TAB> item = str(item) <TAB>  <TAB> if not PY3K: <MASK> item = str(item) <TAB>  <TAB> stream.write(item) <TAB> stream.write(""\n"")","if not isinstance ( item , unicode ) :",106
3944,"def f(view, s): <TAB> if mode == modes.INTERNAL_NORMAL: <TAB>  <TAB> view.run_command(""toggle_comment"") <MASK> pt = utils.next_non_white_space_char(view, s.a, white_space="" \t"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> pt = utils.next_non_white_space_char( <TAB>  <TAB>  <TAB>  <TAB> view, self.view.line(s.a).a, white_space="" \t"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return R(pt, pt) <TAB> return s","if utils . row_at ( self . view , s . a ) != utils . row_at ( self . view , self . view . size ( ) ) :",166
3945,"def _parse_timestamp(value): <TAB> if value: <TAB>  <TAB> match = _TIMESTAMP_PATTERN.match(value) <MASK> if match.group(2): <TAB>  <TAB>  <TAB>  <TAB> format = ""%Y-%m-%d %H:%M:%S.%f"" <TAB>  <TAB>  <TAB>  <TAB> # use the pattern to truncate the value <TAB>  <TAB>  <TAB>  <TAB> value = match.group() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> format = ""%Y-%m-%d %H:%M:%S"" <TAB>  <TAB>  <TAB> value = datetime.datetime.strptime(value, format) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception('Cannot convert ""{}"" into a datetime'.format(value)) <TAB> else: <TAB>  <TAB> value = None <TAB> return value",if match :,170
3946,"def _compute_log_r(model_trace, guide_trace): <TAB> log_r = MultiFrameTensor() <TAB> stacks = get_plate_stacks(model_trace) <TAB> for name, model_site in model_trace.nodes.items(): <TAB>  <TAB> if model_site[""type""] == ""sample"": <TAB>  <TAB>  <TAB> log_r_term = model_site[""log_prob""] <MASK> log_r_term = log_r_term - guide_trace.nodes[name][""log_prob""] <TAB>  <TAB>  <TAB> log_r.add((stacks[name], log_r_term.detach())) <TAB> return log_r","if not model_site [ ""is_observed"" ] :",162
3947,"def get_translationproject(self): <TAB> """"""returns the translation project belonging to this directory."""""" <TAB> if self.is_language() or self.is_project(): <TAB>  <TAB> return None <TAB> else: <MASK> return self.translationproject <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> aux_dir = self <TAB>  <TAB>  <TAB> while not aux_dir.is_translationproject() and aux_dir.parent is not None: <TAB>  <TAB>  <TAB>  <TAB> aux_dir = aux_dir.parent <TAB>  <TAB>  <TAB> return aux_dir.translationproject",if self . is_translationproject ( ) :,130
3948,"def get_hosted_content(): <TAB> try: <TAB>  <TAB> scheme, rest = target.split(""://"", 1) <TAB>  <TAB> prefix, host_and_port = rest.split("".interactivetool."") <TAB>  <TAB> faked_host = rest <MASK> faked_host = rest.split(""/"", 1)[0] <TAB>  <TAB> url = ""%s://%s"" % (scheme, host_and_port) <TAB>  <TAB> response = requests.get(url, timeout=1, headers={""Host"": faked_host}) <TAB>  <TAB> return response.text <TAB> except Exception as e: <TAB>  <TAB> print(e) <TAB>  <TAB> return None","if ""/"" in rest :",148
3949,"def install(self): <TAB> log.info(self.openssl_cli) <TAB> if not self.has_openssl or self.args.force: <MASK> self._download_src() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.debug(""Already has src {}"".format(self.src_file)) <TAB>  <TAB> self._unpack_src() <TAB>  <TAB> self._build_src() <TAB>  <TAB> self._make_install() <TAB> else: <TAB>  <TAB> log.info(""Already has installation {}"".format(self.install_dir)) <TAB> # validate installation <TAB> version = self.openssl_version <TAB> if self.version not in version: <TAB>  <TAB> raise ValueError(version)",if not self . has_src :,162
3950,"def format(self, formatstr): <TAB> pieces = [] <TAB> for i, piece in enumerate(re_formatchars.split(force_text(formatstr))): <TAB>  <TAB> if i % 2: <TAB>  <TAB>  <TAB> pieces.append(force_text(getattr(self, piece)())) <MASK> pieces.append(re_escaped.sub(r""\1"", piece)) <TAB> return """".join(pieces)",elif piece :,99
3951,"def get_current_events_users(calendar): <TAB> now = timezone.make_aware(datetime.now(), timezone.get_current_timezone()) <TAB> result = [] <TAB> day = Day(calendar.events.all(), now) <TAB> for o in day.get_occurrences(): <MASK> usernames = o.event.title.split("","") <TAB>  <TAB>  <TAB> for username in usernames: <TAB>  <TAB>  <TAB>  <TAB> result.append(User.objects.get(username=username.strip())) <TAB> return result",if o . start <= now <= o . end :,128
3952,"def from_cfn_params(self, cfn_params): <TAB> """"""Initialize param value by parsing CFN input only if the scheduler is awsbatch."""""" <TAB> cfn_converter = self.definition.get(""cfn_param_mapping"", None) <TAB> if cfn_converter and cfn_params: <MASK> # we have the same CFN input parameters for both spot_price and spot_bid_percentage <TAB>  <TAB>  <TAB> # so the CFN input could be a float <TAB>  <TAB>  <TAB> self.value = int(float(get_cfn_param(cfn_params, cfn_converter))) <TAB> return self","if get_cfn_param ( cfn_params , ""Scheduler"" ) == ""awsbatch"" :",165
3953,"def onCompletion(self, text): <TAB> res = [] <TAB> for l in text.split(""\n""): <MASK> continue <TAB>  <TAB> l = l.split("":"") <TAB>  <TAB> if len(l) != 2: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> res.append([l[0].strip(), l[1].strip()]) <TAB> self.panel.setChapters(res)",if not l :,93
3954,"def update_ranges(l, i): <TAB> for _range in l: <TAB>  <TAB> # most common case: extend a range <TAB>  <TAB> if i == _range[0] - 1: <TAB>  <TAB>  <TAB> _range[0] = i <TAB>  <TAB>  <TAB> merge_ranges(l) <TAB>  <TAB>  <TAB> return <MASK> _range[1] = i <TAB>  <TAB>  <TAB> merge_ranges(l) <TAB>  <TAB>  <TAB> return <TAB> # somewhere outside of range proximity <TAB> l.append([i, i]) <TAB> l.sort(key=lambda x: x[0])",elif i == _range [ 1 ] + 1 :,145
3955,"def process_dollar(token, state, command_line): <TAB> if not state.is_range_start_line_parsed: <MASK> raise ValueError(""bad range: {0}"".format(state.scanner.state.source)) <TAB>  <TAB> command_line.line_range.start.append(token) <TAB> else: <TAB>  <TAB> if command_line.line_range.end: <TAB>  <TAB>  <TAB> raise ValueError(""bad range: {0}"".format(state.scanner.state.source)) <TAB>  <TAB> command_line.line_range.end.append(token) <TAB> return parse_line_ref, command_line",if command_line . line_range . start :,156
3956,"def _parse_description(self, text: str): <TAB> result = dict(links=[], versions=[]) <TAB> for line in text.splitlines(): <TAB>  <TAB> clean = REX_TAG.sub("""", line.strip()) <MASK> result[""severity""] = clean.split()[1] <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if clean.startswith(""Affects:""): <TAB>  <TAB>  <TAB> result[""name""] = clean.split()[1] <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if "" or higher"" in clean: <TAB>  <TAB>  <TAB> result[""versions""] = self._get_versions(clean) <TAB>  <TAB> result[""links""].extend(REX_LINK.findall(line)) <TAB> return result","if clean . startswith ( ""Severity:"" ) :",162
3957,"def apply(self, chart, grammar): <TAB> for prod in grammar.productions(empty=True): <TAB>  <TAB> for index in compat.xrange(chart.num_leaves() + 1): <TAB>  <TAB>  <TAB> new_edge = TreeEdge.from_production(prod, index) <MASK> yield new_edge","if chart . insert ( new_edge , ( ) ) :",83
3958,"def calc(self, arg): <TAB> op = arg[""op""] <TAB> if op == ""C"": <TAB>  <TAB> self.clear() <TAB>  <TAB> return str(self.current) <TAB> num = decimal.Decimal(arg[""num""]) <TAB> if self.op: <MASK> self.current += num <TAB>  <TAB> elif self.op == ""-"": <TAB>  <TAB>  <TAB> self.current -= num <TAB>  <TAB> elif self.op == ""*"": <TAB>  <TAB>  <TAB> self.current *= num <TAB>  <TAB> elif self.op == ""/"": <TAB>  <TAB>  <TAB> self.current /= num <TAB>  <TAB> self.op = op <TAB> else: <TAB>  <TAB> self.op = op <TAB>  <TAB> self.current = num <TAB> res = str(self.current) <TAB> if op == ""="": <TAB>  <TAB> self.clear() <TAB> return res","if self . op == ""+"" :",187
3959,"def cascade(self, event=None): <TAB> """"""Cascade all Leo windows."""""" <TAB> x, y, delta = 50, 50, 50 <TAB> for frame in g.app.windowList: <TAB>  <TAB> w = frame and frame.top <TAB>  <TAB> if w: <TAB>  <TAB>  <TAB> r = w.geometry()  # a Qt.Rect <TAB>  <TAB>  <TAB> # 2011/10/26: Fix bug 823601: cascade-windows fails. <TAB>  <TAB>  <TAB> w.setGeometry(QtCore.QRect(x, y, r.width(), r.height())) <TAB>  <TAB>  <TAB> # Compute the new offsets. <TAB>  <TAB>  <TAB> x += 30 <TAB>  <TAB>  <TAB> y += 30 <MASK> x = 10 + delta <TAB>  <TAB>  <TAB>  <TAB> y = 40 + delta <TAB>  <TAB>  <TAB>  <TAB> delta += 10",if x > 200 :,190
3960,"def redirect(self): <TAB> c = self.c <TAB> if c.config.getBool(""eval-redirect""): <TAB>  <TAB> self.old_stderr = g.stdErrIsRedirected() <TAB>  <TAB> self.old_stdout = g.stdOutIsRedirected() <MASK> g.redirectStderr() <TAB>  <TAB> if not self.old_stdout: <TAB>  <TAB>  <TAB> g.redirectStdout()",if not self . old_stderr :,103
3961,"def on_event(self, c, button, data): <TAB> if self.rvGestureGrab.get_reveal_child(): <MASK> self.use() <TAB>  <TAB> elif button == ""Y"" and data[0] == 0: <TAB>  <TAB>  <TAB> self.start_over()","if button == ""A"" and data [ 0 ] == 0 :",83
3962,"def __init__(self, in_feats, out_feats, norm=""both"", bias=True, activation=None): <TAB> super(DenseGraphConv, self).__init__() <TAB> self._in_feats = in_feats <TAB> self._out_feats = out_feats <TAB> self._norm = norm <TAB> with self.name_scope(): <TAB>  <TAB> self.weight = self.params.get( <TAB>  <TAB>  <TAB> ""weight"", <TAB>  <TAB>  <TAB> shape=(in_feats, out_feats), <TAB>  <TAB>  <TAB> init=mx.init.Xavier(magnitude=math.sqrt(2.0)), <TAB>  <TAB> ) <MASK> self.bias = self.params.get(""bias"", shape=(out_feats,), init=mx.init.Zero()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.bias = None <TAB>  <TAB> self._activation = activation",if bias :,195
3963,"def _import_top_module(self, name): <TAB> # scan sys.path looking for a location in the filesystem that contains <TAB> # the module, or an Importer object that can import the module. <TAB> for item in sys.path: <TAB>  <TAB> if isinstance(item, _StringType): <TAB>  <TAB>  <TAB> module = self.fs_imp.import_from_dir(item, name) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> module = item.import_top(name) <MASK> return module <TAB> return None",if module :,124
3964,"def resolver(schemas, f): <TAB> if not callable(f): <TAB>  <TAB> return <TAB> if not hasattr(f, ""accepts""): <TAB>  <TAB> return <TAB> new_params = [] <TAB> for p in f.accepts: <MASK> new_params.append(p.resolve(schemas)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ResolverError(""Invalid parameter definition {0}"".format(p)) <TAB> # FIXME: for some reason assigning params (f.accepts = new_params) does not work <TAB> f.accepts.clear() <TAB> f.accepts.extend(new_params)","if isinstance ( p , ( Patch , Ref , Attribute ) ) :",153
3965,"def get_files(d): <TAB> res = [] <TAB> for p in glob.glob(os.path.join(d, ""*"")): <TAB>  <TAB> if not p: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> (pth, fname) = os.path.split(p) <TAB>  <TAB> if fname == ""output"": <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> if fname[-4:] == "".pyc"":  # ehmm.. no. <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if os.path.isdir(p): <TAB>  <TAB>  <TAB> get_dir(p) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> res.append(p) <TAB> return res","if fname == ""PureMVC_Python_1_0"" :",162
3966,"def _addRightnames(groups, kerning, leftname, rightnames, includeAll=True): <TAB> if leftname in kerning: <TAB>  <TAB> for rightname in kerning[leftname]: <TAB>  <TAB>  <TAB> if rightname[0] == ""@"": <TAB>  <TAB>  <TAB>  <TAB> for rightname2 in groups[rightname]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> rightnames.add(rightname2) <MASK> # TODO: in this case, pick the one rightname that has the highest <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # ranking in glyphorder <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> rightnames.add(rightname)",if not includeAll :,161
3967,"def migrate_Stats(self): <TAB> for old_obj in self.session_old.query(self.model_from[""Stats""]): <MASK> self.entries_count[""Stats""] -= 1 <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> new_obj = self.model_to[""Stats""]() <TAB>  <TAB> for key in new_obj.__table__.columns._data.keys(): <TAB>  <TAB>  <TAB> if key not in old_obj.__table__.columns: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> setattr(new_obj, key, getattr(old_obj, key)) <TAB>  <TAB> self.session_new.add(new_obj)",if not old_obj . summary :,152
3968,"def _readenv(var, msg): <TAB> match = _ENV_VAR_PAT.match(var) <TAB> if match and match.groups(): <TAB>  <TAB> envvar = match.groups()[0] <MASK> value = os.environ[envvar] <TAB>  <TAB>  <TAB> if six.PY2: <TAB>  <TAB>  <TAB>  <TAB> value = value.decode(""utf8"") <TAB>  <TAB>  <TAB> return value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise InvalidConfigException( <TAB>  <TAB>  <TAB>  <TAB> ""{} - environment variable '{}' not set"".format(msg, var) <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> raise InvalidConfigException( <TAB>  <TAB>  <TAB> ""{} - environment variable name '{}' does not match pattern '{}'"".format( <TAB>  <TAB>  <TAB>  <TAB> msg, var, _ENV_VAR_PAT_STR <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> )",if envvar in os . environ :,190
3969,"def __next__(self): <TAB> self._parse_reset() <TAB> while True: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> line = next(self.input_iter) <TAB>  <TAB> except StopIteration: <TAB>  <TAB>  <TAB> # End of input OR exception <MASK> raise Error(""newline inside string"") <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> self.line_num += 1 <TAB>  <TAB> if ""\0"" in line: <TAB>  <TAB>  <TAB> raise Error(""line contains NULL byte"") <TAB>  <TAB> pos = 0 <TAB>  <TAB> while pos < len(line): <TAB>  <TAB>  <TAB> pos = self._parse_process_char(line, pos) <TAB>  <TAB> self._parse_eol() <TAB>  <TAB> if self.state == self.START_RECORD: <TAB>  <TAB>  <TAB> break <TAB> fields = self.fields <TAB> self.fields = [] <TAB> return fields",if len ( self . field ) > 0 :,198
3970,"def createFields(self): <TAB> while self.current_size < self.size: <TAB>  <TAB> pos = self.stream.searchBytes( <TAB>  <TAB>  <TAB> ""\0\0\1"", self.current_size, self.current_size + 1024 * 1024 * 8 <TAB>  <TAB> )  # seek forward by at most 1MB <MASK> padsize = pos - self.current_size <TAB>  <TAB>  <TAB> if padsize: <TAB>  <TAB>  <TAB>  <TAB> yield PaddingBytes(self, ""pad[]"", padsize // 8) <TAB>  <TAB> chunk = Chunk(self, ""chunk[]"") <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> # force chunk to be processed, so that CustomFragments are complete <TAB>  <TAB>  <TAB> chunk[""content/data""] <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> yield chunk",if pos is not None :,184
3971,"def spew(): <TAB> seenUID = False <TAB> start() <TAB> for part in query: <TAB>  <TAB> if part.type == ""uid"": <TAB>  <TAB>  <TAB> seenUID = True <MASK> yield self.spew_body(part, id, msg, write, flush) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> f = getattr(self, ""spew_"" + part.type) <TAB>  <TAB>  <TAB> yield f(id, msg, write, flush) <TAB>  <TAB> if part is not query[-1]: <TAB>  <TAB>  <TAB> space() <TAB> if uid and not seenUID: <TAB>  <TAB> space() <TAB>  <TAB> yield self.spew_uid(id, msg, write, flush) <TAB> finish() <TAB> flush()","if part . type == ""body"" :",174
3972,"def _limit_value(key, value, config): <TAB> if config[key].get(""upper_limit""): <TAB>  <TAB> limit = config[key][""upper_limit""] <TAB>  <TAB> # auto handle datetime <TAB>  <TAB> if isinstance(value, datetime) and isinstance(limit, timedelta): <TAB>  <TAB>  <TAB> if config[key][""inverse""] is True: <TAB>  <TAB>  <TAB>  <TAB> if (datetime.now() - limit) > value: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value = datetime.now() - limit <TAB>  <TAB>  <TAB> else: <MASK> value = datetime.now() + limit <TAB>  <TAB> elif value > limit: <TAB>  <TAB>  <TAB> value = limit <TAB> return value",if ( datetime . now ( ) + limit ) < value :,164
3973,"def _fix_var_naming(operators, names, mod=""input""): <TAB> new_names = [] <TAB> map = {} <TAB> for op in operators: <TAB>  <TAB> if mod == ""input"": <TAB>  <TAB>  <TAB> iter = op.inputs <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> iter = op.outputs <TAB>  <TAB> for i in iter: <TAB>  <TAB>  <TAB> for name in names: <TAB>  <TAB>  <TAB>  <TAB> if i.raw_name == name and name not in map: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> map[i.raw_name] = i.full_name <MASK> break <TAB> for name in names: <TAB>  <TAB> new_names.append(map[name]) <TAB> return new_names",if len ( map ) == len ( names ) :,168
3974,"def traverse(tree): <TAB> """"""Generator dropping comment nodes"""""" <TAB> for entry in tree: <TAB>  <TAB> # key, values = entry <TAB>  <TAB> spaceless = [e for e in entry if not nginxparser.spacey(e)] <TAB>  <TAB> if spaceless: <TAB>  <TAB>  <TAB> key = spaceless[0] <TAB>  <TAB>  <TAB> values = spaceless[1] if len(spaceless) > 1 else None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> key = values = """" <TAB>  <TAB> if isinstance(key, list): <TAB>  <TAB>  <TAB> new = copy.deepcopy(entry) <TAB>  <TAB>  <TAB> new[1] = filter_comments(values) <TAB>  <TAB>  <TAB> yield new <TAB>  <TAB> else: <MASK> yield spaceless","if key != ""#"" and spaceless :",173
3975,"def mergeCombiners(self, x, y): <TAB> for item in y: <MASK> self.heap.push(x, item) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.heap.push_pop(x, item) <TAB> return x",if len ( x ) < self . heap_limit :,73
3976,"def test_scatter(self, harness: primitive_harness.Harness): <TAB> f_name = harness.params[""f_lax""].__name__ <TAB> dtype = harness.params[""dtype""] <TAB> if jtu.device_under_test() == ""tpu"": <MASK> raise unittest.SkipTest(f""TODO: complex {f_name} on TPU fails in JAX"") <TAB> self.ConvertAndCompare(harness.dyn_fun, *harness.dyn_args_maker(self.rng()))","if dtype is np . complex64 and f_name in [ ""scatter_min"" , ""scatter_max"" ] :",148
3977,"def TryMerge(self, decoder): <TAB> while decoder.avail() > 0: <TAB>  <TAB> tag = decoder.getVarInt32() <TAB>  <TAB> if tag == TAG_BEGIN_ITEM_GROUP: <TAB>  <TAB>  <TAB> (type_id, message) = Item.Decode(decoder) <MASK> self.items[type_id].MergeFrom(Item(message)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.items[type_id] = Item(message) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tag == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> decoder.skipData(tag)",if type_id in self . items :,154
3978,"def process_continuations(lines): <TAB> global continuation_pattern <TAB> olines = [] <TAB> while len(lines) != 0: <TAB>  <TAB> line = no_comments(lines[0]) <TAB>  <TAB> line = line.strip() <TAB>  <TAB> lines.pop(0) <TAB>  <TAB> if line == """": <TAB>  <TAB>  <TAB> continue <MASK> # combine this line with the next line if the next line exists <TAB>  <TAB>  <TAB> line = continuation_pattern.sub("""", line) <TAB>  <TAB>  <TAB> if len(lines) >= 1: <TAB>  <TAB>  <TAB>  <TAB> combined_lines = [line + lines[0]] <TAB>  <TAB>  <TAB>  <TAB> lines.pop(0) <TAB>  <TAB>  <TAB>  <TAB> lines = combined_lines + lines <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> olines.append(line) <TAB> del lines <TAB> return olines",if continuation_pattern . search ( line ) :,193
3979,"def _getListNextPackagesReadyToBuild(): <TAB> for pkg in Scheduler.listOfPackagesToBuild: <TAB>  <TAB> if pkg in Scheduler.listOfPackagesCurrentlyBuilding: <TAB>  <TAB>  <TAB> continue <MASK> Scheduler.listOfPackagesNextToBuild.put((-Scheduler._getPriority(pkg), pkg)) <TAB>  <TAB>  <TAB> Scheduler.logger.debug(""Adding "" + pkg + "" to the schedule list"")",if constants . rpmCheck or Scheduler . _checkNextPackageIsReadyToBuild ( pkg ) :,113
3980,"def process_signature(app, what, name, obj, options, signature, return_annotation): <TAB> if signature: <TAB>  <TAB> # replace Mock function names <TAB>  <TAB> signature = re.sub(""<Mock name='([^']+)'.*>"", ""\g<1>"", signature) <TAB>  <TAB> signature = re.sub(""tensorflow"", ""tf"", signature) <TAB>  <TAB> # add scope name to layer signatures: <TAB>  <TAB> if hasattr(obj, ""use_scope""): <TAB>  <TAB>  <TAB> if obj.use_scope: <TAB>  <TAB>  <TAB>  <TAB> signature = signature[0] + ""variable_scope_name, "" + signature[1:] <MASK> signature = signature[0] + ""[variable_scope_name,] "" + signature[1:] <TAB> # signature: arg list <TAB> return signature, return_annotation",elif obj . use_scope is None :,188
3981,"def find_distribution_modules(name=__name__, file=__file__): <TAB> current_dist_depth = len(name.split(""."")) - 1 <TAB> current_dist = os.path.join( <TAB>  <TAB> os.path.dirname(file), *([os.pardir] * current_dist_depth) <TAB> ) <TAB> abs = os.path.abspath(current_dist) <TAB> dist_name = os.path.basename(abs) <TAB> for dirpath, dirnames, filenames in os.walk(abs): <TAB>  <TAB> package = (dist_name + dirpath[len(abs) :]).replace(""/"", ""."") <MASK> yield package <TAB>  <TAB>  <TAB> for filename in filenames: <TAB>  <TAB>  <TAB>  <TAB> if filename.endswith("".py"") and filename != ""__init__.py"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield ""."".join([package, filename])[:-3]","if ""__init__.py"" in filenames :",198
3982,"def transform_value(i, v, *args): <TAB> if i not in converter_functions: <TAB>  <TAB> # no converter defined on this field, return value as-is <TAB>  <TAB> return v <TAB> else: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return converter_functions[i](v, *args) <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> if failonerror == ""inline"": <TAB>  <TAB>  <TAB>  <TAB> return e <MASK> raise e <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return errorvalue",elif failonerror :,126
3983,"def _get_file(self): <TAB> if self._file is None: <TAB>  <TAB> self._file = SpooledTemporaryFile( <TAB>  <TAB>  <TAB> max_size=self._storage.max_memory_size, <TAB>  <TAB>  <TAB> suffix="".S3Boto3StorageFile"", <TAB>  <TAB>  <TAB> dir=setting(""FILE_UPLOAD_TEMP_DIR""), <TAB>  <TAB> ) <MASK> self._is_dirty = False <TAB>  <TAB>  <TAB> self.obj.download_fileobj(self._file) <TAB>  <TAB>  <TAB> self._file.seek(0) <TAB>  <TAB> if self._storage.gzip and self.obj.content_encoding == ""gzip"": <TAB>  <TAB>  <TAB> self._file = GzipFile(mode=self._mode, fileobj=self._file, mtime=0.0) <TAB> return self._file","if ""r"" in self . _mode :",184
3984,"def connect(self, host, port, timeout): <TAB> fp = Telnet() <TAB> for i in range(50): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> fp.sock = socket.create_connection( <TAB>  <TAB>  <TAB>  <TAB> (host, int(port)), timeout=int(timeout), source_address=("""", 1023 - i) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> except socket.error as e: <MASK> raise e <TAB> self.need_handshake = True <TAB> return TCP_Connection(fp)","if ( e . errno , e . strerror ) != ( 98 , ""Address already in use"" ) :",145
3985,"def filtercomments(source): <TAB> """"""NOT USED: strips trailing comments and put them at the top."""""" <TAB> trailing_comments = [] <TAB> comment = True <TAB> while comment: <TAB>  <TAB> if re.search(r""^\s*\/\*"", source): <TAB>  <TAB>  <TAB> comment = source[0, source.index(""*/"") + 2] <MASK> comment = re.search(r""^\s*\/\/"", source).group(0) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> comment = None <TAB>  <TAB> if comment: <TAB>  <TAB>  <TAB> source = re.sub(r""^\s+"", """", source[len(comment) :]) <TAB>  <TAB>  <TAB> trailing_comments.append(comment) <TAB> return ""\n"".join(trailing_comments) + source","elif re . search ( r""^\s*\/\/"" , source ) :",179
3986,"def yview(self, mode=None, value=None, units=None): <TAB> if type(value) == str: <TAB>  <TAB> value = float(value) <TAB> if mode is None: <TAB>  <TAB> return self.vsb.get() <TAB> elif mode == ""moveto"": <TAB>  <TAB> frameHeight = self.innerframe.winfo_reqheight() <TAB>  <TAB> self._startY = value * float(frameHeight) <TAB> else:  # mode == 'scroll' <TAB>  <TAB> clipperHeight = self._clipper.winfo_height() <MASK> jump = int(clipperHeight * self._jfraction) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> jump = clipperHeight <TAB>  <TAB> self._startY = self._startY + value * jump <TAB> self.reposition()","if units == ""units"" :",181
3987,"def visit(stmt): <TAB> """"""Collect information about VTCM buffers and their alignments."""""" <TAB> if isinstance(stmt, tvm.tir.AttrStmt): <TAB>  <TAB> if stmt.attr_key == ""storage_scope"" and stmt.value == ""local.vtcm"": <TAB>  <TAB>  <TAB> vtcm_buffers.append(stmt.node) <MASK> if not stmt.node in alignments: <TAB>  <TAB>  <TAB>  <TAB> alignments[stmt.node] = [] <TAB>  <TAB>  <TAB> alignments[stmt.node].append(stmt.value)","elif stmt . attr_key == ""storage_alignment"" :",133
3988,"def cost(P): <TAB> # wda loss <TAB> loss_b = 0 <TAB> loss_w = 0 <TAB> for i, xi in enumerate(xc): <TAB>  <TAB> xi = np.dot(xi, P) <TAB>  <TAB> for j, xj in enumerate(xc[i:]): <TAB>  <TAB>  <TAB> xj = np.dot(xj, P) <TAB>  <TAB>  <TAB> M = dist(xi, xj) <TAB>  <TAB>  <TAB> G = sinkhorn(wc[i], wc[j + i], M, reg, k) <MASK> loss_w += np.sum(G * M) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> loss_b += np.sum(G * M) <TAB> # loss inversed because minimization <TAB> return loss_w / loss_b",if j == 0 :,187
3989,"def __init__(self, comm, in_channels, out_channels, ksize, pad=1): <TAB> super(Block, self).__init__() <TAB> with self.init_scope(): <MASK> self.conv = ParallelConvolution2D( <TAB>  <TAB>  <TAB>  <TAB> comm, in_channels, out_channels, ksize, pad=pad, nobias=True <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.conv = chainer.links.Convolution2D( <TAB>  <TAB>  <TAB>  <TAB> in_channels, out_channels, ksize, pad=pad, nobias=True <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self.bn = L.BatchNormalization(out_channels)",if comm . size <= in_channels :,164
3990,"def halfMultipartScore(nzb_name): <TAB> try: <TAB>  <TAB> wrong_found = 0 <TAB>  <TAB> for nr in [1, 2, 3, 4, 5, ""i"", ""ii"", ""iii"", ""iv"", ""v"", ""a"", ""b"", ""c"", ""d"", ""e""]: <TAB>  <TAB>  <TAB> for wrong in [""cd"", ""part"", ""dis"", ""disc"", ""dvd""]: <MASK> wrong_found += 1 <TAB>  <TAB> if wrong_found == 1: <TAB>  <TAB>  <TAB> return -30 <TAB>  <TAB> return 0 <TAB> except: <TAB>  <TAB> log.error(""Failed doing halfMultipartScore: %s"", traceback.format_exc()) <TAB> return 0","if ""%s%s"" % ( wrong , nr ) in nzb_name . lower ( ) :",183
3991,"def should_include(service): <TAB> for f in filt: <MASK> state = filt[f] <TAB>  <TAB>  <TAB> containers = project.containers([service.name], stopped=True) <TAB>  <TAB>  <TAB> if not has_container_with_state(containers, state): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> elif f == ""source"": <TAB>  <TAB>  <TAB> source = filt[f] <TAB>  <TAB>  <TAB> if source == ""image"" or source == ""build"": <TAB>  <TAB>  <TAB>  <TAB> if source not in service.options: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise UserError(""Invalid value for source filter: %s"" % source) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise UserError(""Invalid filter: %s"" % f) <TAB> return True","if f == ""status"" :",184
3992,"def get_blob_type_declaration_sql(self, column): <TAB> length = column.get(""length"") <TAB> if length: <TAB>  <TAB> if length <= self.LENGTH_LIMIT_TINYBLOB: <TAB>  <TAB>  <TAB> return ""TINYBLOB"" <MASK> return ""BLOB"" <TAB>  <TAB> if length <= self.LENGTH_LIMIT_MEDIUMBLOB: <TAB>  <TAB>  <TAB> return ""MEDIUMBLOB"" <TAB> return ""LONGBLOB""",if length <= self . LENGTH_LIMIT_BLOB :,115
3993,"def click_outside(event): <TAB> if event not in d: <TAB>  <TAB> x, y, z = self.blockFaceUnderCursor[0] <MASK> y = 64 <TAB>  <TAB> y += 3 <TAB>  <TAB> gotoPanel.X, gotoPanel.Y, gotoPanel.Z = x, y, z <TAB>  <TAB> if event.num_clicks == 2: <TAB>  <TAB>  <TAB> d.dismiss(""Goto"")",if y == 0 :,100
3994,"def check_related_active_jobs(self, obj): <TAB> active_jobs = obj.get_active_jobs() <TAB> if len(active_jobs) > 0: <TAB>  <TAB> raise ActiveJobConflict(active_jobs) <TAB> time_cutoff = now() - dateutil.relativedelta.relativedelta(minutes=1) <TAB> recent_jobs = obj._get_related_jobs().filter(finished__gte=time_cutoff) <TAB> for unified_job in recent_jobs.get_real_instances(): <MASK> raise PermissionDenied( <TAB>  <TAB>  <TAB>  <TAB> _(""Related job {} is still processing events."").format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> unified_job.log_format <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> )",if not unified_job . event_processing_finished :,176
3995,"def run(self): <TAB> self.alive = True <TAB> if _log.isEnabledFor(_DEBUG): <TAB>  <TAB> _log.debug(""started"") <TAB> while self.alive: <TAB>  <TAB> task = self.queue.get() <MASK> function, args, kwargs = task <TAB>  <TAB>  <TAB> assert function <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> function(*args, **kwargs) <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> _log.exception(""calling %s"", function) <TAB> if _log.isEnabledFor(_DEBUG): <TAB>  <TAB> _log.debug(""stopped"")",if task :,134
3996,"def update_sysconfig_file(fn, adjustments, allow_empty=False): <TAB> if not adjustments: <TAB>  <TAB> return <TAB> (exists, contents) = read_sysconfig_file(fn) <TAB> updated_am = 0 <TAB> for (k, v) in adjustments.items(): <TAB>  <TAB> if v is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> v = str(v) <MASK> continue <TAB>  <TAB> contents[k] = v <TAB>  <TAB> updated_am += 1 <TAB> if updated_am: <TAB>  <TAB> lines = [ <TAB>  <TAB>  <TAB> str(contents), <TAB>  <TAB> ] <TAB>  <TAB> if not exists: <TAB>  <TAB>  <TAB> lines.insert(0, util.make_header()) <TAB>  <TAB> util.write_file(fn, ""\n"".join(lines) + ""\n"", 0o644)",if len ( v ) == 0 and not allow_empty :,198
3997,"def wrapper(  # type: ignore <TAB> self: RequestHandler, *args, **kwargs) -> Optional[Awaitable[None]]: <TAB> if self.request.path.endswith(""/""): <TAB>  <TAB> if self.request.method in (""GET"", ""HEAD""): <TAB>  <TAB>  <TAB> uri = self.request.path.rstrip(""/"") <MASK> # don't try to redirect '/' to '' <TAB>  <TAB>  <TAB>  <TAB> if self.request.query: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> uri += ""?"" + self.request.query <TAB>  <TAB>  <TAB>  <TAB> self.redirect(uri, permanent=True) <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise HTTPError(404) <TAB> return method(self, *args, **kwargs)",if uri :,163
3998,def output_handles_from_execution_plan(execution_plan): <TAB> output_handles_for_current_run = set() <TAB> for step_level in execution_plan.execution_step_levels(): <TAB>  <TAB> for step in step_level: <TAB>  <TAB>  <TAB> for step_input in step.step_inputs: <MASK> output_handles_for_current_run.update(step_input.source_handles) <TAB> return output_handles_for_current_run,if step_input . source_handles :,124
3999,"def _read_value(self, item): <TAB> item = _normalize_path(item) <TAB> if item in self._store: <MASK> del self._store[item] <TAB>  <TAB>  <TAB> raise KeyError(item) <TAB>  <TAB> return PathResult(item, value=self._store[item]) <TAB> elif item in self._children: <TAB>  <TAB> return PathResult(item, dir=True) <TAB> else: <TAB>  <TAB> raise KeyError(item)",if item in self . _expire_time and self . _expire_time [ item ] < datetime . now ( ) :,125
4000,"def _line_ranges(statements, lines): <TAB> """"""Produce a list of ranges for `format_lines`."""""" <TAB> statements = sorted(statements) <TAB> lines = sorted(lines) <TAB> pairs = [] <TAB> start = None <TAB> lidx = 0 <TAB> for stmt in statements: <TAB>  <TAB> if lidx >= len(lines): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if stmt == lines[lidx]: <TAB>  <TAB>  <TAB> lidx += 1 <MASK> start = stmt <TAB>  <TAB>  <TAB> end = stmt <TAB>  <TAB> elif start: <TAB>  <TAB>  <TAB> pairs.append((start, end)) <TAB>  <TAB>  <TAB> start = None <TAB> if start: <TAB>  <TAB> pairs.append((start, end)) <TAB> return pairs",if not start :,167
4001,"def _update_help_obj_params(help_obj, data_params, params_equal, attr_key_tups): <TAB> loaded_params = [] <TAB> for param_obj in help_obj.parameters: <TAB>  <TAB> loaded_param = next( <TAB>  <TAB>  <TAB> (n for n in data_params if params_equal(param_obj, n)), None <TAB>  <TAB> ) <MASK> BaseHelpLoader._update_obj_from_data_dict( <TAB>  <TAB>  <TAB>  <TAB> param_obj, loaded_param, attr_key_tups <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> loaded_params.append(param_obj) <TAB> help_obj.parameters = loaded_params",if loaded_param :,159
4002,"def __get_ratio(self): <TAB> """"""Return splitter ratio of the main splitter."""""" <TAB> c = self.c <TAB> free_layout = c.free_layout <TAB> if free_layout: <TAB>  <TAB> w = free_layout.get_main_splitter() <MASK> aList = w.sizes() <TAB>  <TAB>  <TAB> if len(aList) == 2: <TAB>  <TAB>  <TAB>  <TAB> n1, n2 = aList <TAB>  <TAB>  <TAB>  <TAB> # 2017/06/07: guard against division by zero. <TAB>  <TAB>  <TAB>  <TAB> ratio = 0.5 if n1 + n2 == 0 else float(n1) / float(n1 + n2) <TAB>  <TAB>  <TAB>  <TAB> return ratio <TAB> return 0.5",if w :,170
4003,"def _check_required_env_variables(vars): <TAB> for var in vars: <MASK> self.tc.logger.error( <TAB>  <TAB>  <TAB>  <TAB> ""%s is not set. Did you forget to source your build environment setup script?"" <TAB>  <TAB>  <TAB>  <TAB> % var <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> raise OEQAPreRun",if not os . environ . get ( var ) :,89
4004,"def clean_indexes(): <TAB> for coll_name in mongo.collection_types.keys(): <TAB>  <TAB> coll = mongo.get_collection(coll_name) <TAB>  <TAB> indexes = coll_indexes[coll_name] <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> for index in coll.list_indexes(): <TAB>  <TAB>  <TAB>  <TAB> name = index[""name""] <MASK> continue <TAB>  <TAB>  <TAB>  <TAB> coll.drop_index(name) <TAB>  <TAB> except pymongo.errors.OperationFailure: <TAB>  <TAB>  <TAB> pass","if name == ""_id"" or name == ""_id_"" or name in indexes :",140
4005,"def _compare_dirs(self, dir1, dir2): <TAB> # check that dir1 and dir2 are equivalent, <TAB> # return the diff <TAB> diff = [] <TAB> for root, dirs, files in os.walk(dir1): <TAB>  <TAB> for file_ in files: <TAB>  <TAB>  <TAB> path = os.path.join(root, file_) <TAB>  <TAB>  <TAB> target_path = os.path.join(dir2, os.path.split(path)[-1]) <MASK> diff.append(file_) <TAB> return diff",if not os . path . exists ( target_path ) :,138
4006,"def load_state_dict(self, state_dict, strict=True): <TAB> """"""Customized load."""""" <TAB> self.language_model.load_state_dict( <TAB>  <TAB> state_dict[self._language_model_key], strict=strict <TAB> ) <TAB> if mpu.is_pipeline_last_stage(): <MASK> self.multichoice_head.load_state_dict( <TAB>  <TAB>  <TAB>  <TAB> state_dict[self._multichoice_head_key], strict=strict <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print_rank_last( <TAB>  <TAB>  <TAB>  <TAB> ""***WARNING*** could not find {} in the checkpoint, "" <TAB>  <TAB>  <TAB>  <TAB> ""initializing to random"".format(self._multichoice_head_key) <TAB>  <TAB>  <TAB> )",if self . _multichoice_head_key in state_dict :,197
4007,"def _parse_timedelta(self, value): <TAB> try: <TAB>  <TAB> sum = datetime.timedelta() <TAB>  <TAB> start = 0 <TAB>  <TAB> while start < len(value): <TAB>  <TAB>  <TAB> m = self._TIMEDELTA_PATTERN.match(value, start) <MASK> raise Exception() <TAB>  <TAB>  <TAB> num = float(m.group(1)) <TAB>  <TAB>  <TAB> units = m.group(2) or ""seconds"" <TAB>  <TAB>  <TAB> units = self._TIMEDELTA_ABBREV_DICT.get(units, units) <TAB>  <TAB>  <TAB> sum += datetime.timedelta(**{units: num}) <TAB>  <TAB>  <TAB> start = m.end() <TAB>  <TAB> return sum <TAB> except: <TAB>  <TAB> raise",if not m :,165
4008,"def SetChildMenuBar(self, pChild): <TAB> if not pChild: <TAB>  <TAB> # No Child, set Our menu bar back. <TAB>  <TAB> if self._pMyMenuBar: <TAB>  <TAB>  <TAB> self.SetMenuBar(self._pMyMenuBar) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.SetMenuBar(self.GetMenuBar()) <TAB>  <TAB> # Make sure we know our menu bar is in use <TAB>  <TAB> self._pMyMenuBar = None <TAB> else: <TAB>  <TAB> if pChild.GetMenuBar() is None: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> # Do we need to save the current bar? <MASK> self._pMyMenuBar = self.GetMenuBar() <TAB>  <TAB> self.SetMenuBar(pChild.GetMenuBar())",if self . _pMyMenuBar is None :,188
4009,"def init_weights(self): <TAB> """"""Initialize weights of the head."""""" <TAB> # retinanet_bias_init <TAB> bias_cls = bias_init_with_prob(0.01) <TAB> normal_init(self.conv_reg, std=0.01) <TAB> normal_init(self.conv_centerness, std=0.01) <TAB> normal_init(self.conv_cls, std=0.01, bias=bias_cls) <TAB> for branch in [self.cls_convs, self.reg_convs]: <TAB>  <TAB> for module in branch.modules(): <MASK> caffe2_xavier_init(module.conv)","if isinstance ( module , ConvModule ) and isinstance ( module . conv , nn . Conv2d ) :",178
4010,"def handle_exception(self, e, result): <TAB> for k in sorted(result.thrift_spec): <TAB>  <TAB> if result.thrift_spec[k][1] == ""success"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> _, exc_name, exc_cls, _ = result.thrift_spec[k] <MASK> setattr(result, exc_name, e) <TAB>  <TAB>  <TAB> break <TAB> else: <TAB>  <TAB> raise","if isinstance ( e , exc_cls ) :",115
4011,"def scripts(self): <TAB> application_root = current_app.config.get(""APPLICATION_ROOT"") <TAB> subdir = application_root != ""/"" <TAB> scripts = [] <TAB> for script in get_registered_scripts(): <MASK> scripts.append(f'<script defer src=""{script}""></script>') <TAB>  <TAB> elif subdir: <TAB>  <TAB>  <TAB> scripts.append(f'<script defer src=""{application_root}/{script}""></script>') <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> scripts.append(f'<script defer src=""{script}""></script>') <TAB> return markup(""\n"".join(scripts))","if script . startswith ( ""http"" ) :",146
4012,"def test_related_objects_local(self): <TAB> result_key = ""get_all_related_objects_with_model_local"" <TAB> for model, expected in TEST_RESULTS[result_key].items(): <TAB>  <TAB> objects = [ <TAB>  <TAB>  <TAB> (field, self._model(model, field)) <TAB>  <TAB>  <TAB> for field in model._meta.get_fields(include_parents=False) <MASK> ] <TAB>  <TAB> self.assertEqual( <TAB>  <TAB>  <TAB> sorted(self._map_related_query_names(objects), key=self.key_name), <TAB>  <TAB>  <TAB> sorted(expected, key=self.key_name), <TAB>  <TAB> )",if field . auto_created and not field . concrete,164
4013,"def setTestOutcome(self, event): <TAB> """"""Update outcome, exc_info and reason based on configured mappings"""""" <TAB> if event.exc_info: <TAB>  <TAB> ec, ev, tb = event.exc_info <TAB>  <TAB> classname = ec.__name__ <TAB>  <TAB> if classname in self.treatAsFail: <TAB>  <TAB>  <TAB> short, long_ = self.labels(classname) <TAB>  <TAB>  <TAB> self._setOutcome(event, ""failed"", short, long_) <MASK> short, long_ = self.labels(classname, upper=False) <TAB>  <TAB>  <TAB> self._setOutcome(event, ""skipped"", short, ""%s: '%s'"" % (long_, ev), str(ev))",elif classname in self . treatAsSkip :,169
4014,"def small_count(v): <TAB> if not v: <TAB>  <TAB> return 0 <TAB> z = [ <TAB>  <TAB> (1000000000, _(""b"")), <TAB>  <TAB> (1000000, _(""m"")), <TAB>  <TAB> (1000, _(""k"")), <TAB> ] <TAB> v = int(v) <TAB> for x, y in z: <TAB>  <TAB> o, p = divmod(v, x) <TAB>  <TAB> if o: <MASK> return ""%d%s"" % (o, y) <TAB>  <TAB>  <TAB> return ""%.1f%s"" % (v / float(x), y) <TAB> return v",if len ( str ( o ) ) > 2 or not p :,149
4015,"def __read(self, n): <TAB> if self._read_watcher is None: <TAB>  <TAB> raise UnsupportedOperation(""read"") <TAB> while 1: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return _read(self._fileno, n) <TAB>  <TAB> except (IOError, OSError) as ex: <MASK> raise <TAB>  <TAB> wait_on_watcher(self._read_watcher, None, None, self.hub)",if ex . args [ 0 ] not in ignored_errors :,111
4016,"def locked(self): <TAB> inputfiles = set(self.all_inputfiles()) <TAB> outputfiles = set(self.all_outputfiles()) <TAB> if os.path.exists(self._lockdir): <TAB>  <TAB> for lockfile in self._locks(""input""): <TAB>  <TAB>  <TAB> with open(lockfile) as lock: <TAB>  <TAB>  <TAB>  <TAB> for f in lock: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f = f.strip() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if f in outputfiles: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> for lockfile in self._locks(""output""): <TAB>  <TAB>  <TAB> with open(lockfile) as lock: <TAB>  <TAB>  <TAB>  <TAB> for f in lock: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f = f.strip() <MASK> return True <TAB> return False",if f in outputfiles or f in inputfiles :,195
4017,"def _flags_to_int(flags): <TAB> # Note, that order does not matter, libev has its own predefined order <TAB> if not flags: <TAB>  <TAB> return 0 <TAB> if isinstance(flags, integer_types): <TAB>  <TAB> return flags <TAB> result = 0 <TAB> try: <MASK> flags = flags.split("","") <TAB>  <TAB> for value in flags: <TAB>  <TAB>  <TAB> value = value.strip().lower() <TAB>  <TAB>  <TAB> if value: <TAB>  <TAB>  <TAB>  <TAB> result |= _flags_str2int[value] <TAB> except KeyError as ex: <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> ""Invalid backend or flag: %s\nPossible values: %s"" <TAB>  <TAB>  <TAB> % (ex, "", "".join(sorted(_flags_str2int.keys()))) <TAB>  <TAB> ) <TAB> return result","if isinstance ( flags , basestring ) :",191
4018,"def setFg(self, colour, override=False): <TAB> if not self.ttkFlag: <TAB>  <TAB> self.containerStack[-1][""fg""] = colour <TAB>  <TAB> gui.SET_WIDGET_FG(self._getContainerProperty(""container""), colour, override) <TAB>  <TAB> for child in self._getContainerProperty(""container"").winfo_children(): <MASK> gui.SET_WIDGET_FG(child, colour, override) <TAB> else: <TAB>  <TAB> gui.trace(""In ttk mode - trying to set FG to %s"", colour) <TAB>  <TAB> self.ttkStyle.configure(""TLabel"", foreground=colour) <TAB>  <TAB> self.ttkStyle.configure(""TFrame"", foreground=colour)",if not self . _isWidgetContainer ( child ) :,178
4019,"def find_scintilla_constants(f): <TAB> lexers = [] <TAB> states = [] <TAB> for name in f.order: <TAB>  <TAB> v = f.features[name] <TAB>  <TAB> if v[""Category""] != ""Deprecated"": <TAB>  <TAB>  <TAB> if v[""FeatureType""] == ""val"": <TAB>  <TAB>  <TAB>  <TAB> if name.startswith(""SCE_""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> states.append((name, v[""Value""])) <MASK> lexers.append((name, v[""Value""])) <TAB> return (lexers, states)","elif name . startswith ( ""SCLEX_"" ) :",137
4020,"def extract_error_message(response: requests.Response): <TAB> if response.content: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> content = json.loads(response.content) <MASK> return content[""message""] <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> logging.debug(f""Failed to parse the response content: {response.content}"") <TAB> return response.reason","if ""message"" in content :",94
4021,"def canvas_size(self): <TAB> """"""Return the width and height for this sprite canvas"""""" <TAB> width = height = 0 <TAB> for image in self.images: <TAB>  <TAB> x = image.x + image.absolute_width <TAB>  <TAB> y = image.y + image.absolute_height <MASK> width = x <TAB>  <TAB> if height < y: <TAB>  <TAB>  <TAB> height = y <TAB> return round_up(width), round_up(height)",if width < x :,110
4022,"def _load_widgets(self): <TAB> logger.info(""Loading plugins preferences widgets"") <TAB> # Collect the preferences widget for each active plugin <TAB> for plugin in self.plugin_manager.get_active_plugins(): <TAB>  <TAB> plugin_name = plugin.metadata.get(""name"") <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> preferences_widget = plugin.get_preferences_widget() <MASK> self._tabs.addTab(preferences_widget, plugin_name) <TAB>  <TAB> except Exception as reason: <TAB>  <TAB>  <TAB> logger.error( <TAB>  <TAB>  <TAB>  <TAB> ""Unable to add the preferences widget (%s): %s"", plugin_name, reason <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> continue",if preferences_widget :,162
4023,"def clean_objects(string, common_attributes): <TAB> """"""Return object and attribute lists"""""" <TAB> string = clean_string(string) <TAB> words = string.split() <TAB> if len(words) > 1: <TAB>  <TAB> prefix_words_are_adj = True <TAB>  <TAB> for att in words[:-1]: <TAB>  <TAB>  <TAB> if att not in common_attributes: <TAB>  <TAB>  <TAB>  <TAB> prefix_words_are_adj = False <MASK> return words[-1:], words[:-1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return [string], [] <TAB> else: <TAB>  <TAB> return [string], []",if prefix_words_are_adj :,148
4024,"def _reader(): <TAB> if shuffle: <TAB>  <TAB> random.shuffle(file_list) <TAB> while True: <TAB>  <TAB> for fn in file_list: <TAB>  <TAB>  <TAB> for line in open(fn, ""r""): <TAB>  <TAB>  <TAB>  <TAB> yield self._process_line(line) <MASK> break",if not cycle :,76
4025,"def load(weights, model, K, fsz, dil): <TAB> index = 0 <TAB> layers = model.layers <TAB> for layer in layers._layers: <MASK> if layer.W.shape == weights[index].shape: <TAB>  <TAB>  <TAB>  <TAB> layer.W[:] = weights[index] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> layer.W[:] = dilate(weights[index], K, fsz, dil) <TAB>  <TAB>  <TAB> index += 1","if hasattr ( layer , ""W"" ) :",115
4026,"def upgrade(migrate_engine): <TAB> print(__doc__) <TAB> metadata.bind = migrate_engine <TAB> liftoverjobs = dict() <TAB> jobs = context.query(DeferredJob).filter_by(plugin=""LiftOverTransferPlugin"").all() <TAB> for job in jobs: <MASK> liftoverjobs[job.params[""parentjob""]] = [] <TAB>  <TAB> liftoverjobs[job.params[""parentjob""]].append(job.id) <TAB> for parent in liftoverjobs: <TAB>  <TAB> lifts = liftoverjobs[parent] <TAB>  <TAB> deferred = context.query(DeferredJob).filter_by(id=parent).first() <TAB>  <TAB> deferred.params[""liftover""] = lifts <TAB> context.flush()","if job . params [ ""parentjob"" ] not in liftoverjobs :",182
4027,"def get_refs(self, recursive=False): <TAB> """""":see: AbstractExpression.get_refs()"""""" <TAB> if recursive: <TAB>  <TAB> conds_refs = self.refs + sum((c.get_refs(True) for c in self.conds), []) <MASK> conds_refs.extend(self.consequent.get_refs(True)) <TAB>  <TAB> return conds_refs <TAB> else: <TAB>  <TAB> return self.refs",if self . consequent :,105
4028,"def _parse(self, engine): <TAB> """"""Parse the layer."""""" <TAB> if isinstance(self.args, dict): <MASK> self.axis = engine.evaluate(self.args[""axis""], recursive=True) <TAB>  <TAB>  <TAB> if not isinstance(self.axis, int): <TAB>  <TAB>  <TAB>  <TAB> raise ParsingError('""axis"" must be an integer.') <TAB>  <TAB> if ""momentum"" in self.args: <TAB>  <TAB>  <TAB> self.momentum = engine.evaluate(self.args[""momentum""], recursive=True) <TAB>  <TAB>  <TAB> if not isinstance(self.momentum, (int, float)): <TAB>  <TAB>  <TAB>  <TAB> raise ParsingError('""momentum"" must be numeric.')","if ""axis"" in self . args :",157
4029,"def CountMatches(pat, predicate): <TAB> num_matches = 0 <TAB> for i in xrange(256): <TAB>  <TAB> b = chr(i) <TAB>  <TAB> m = pat.match(b) <TAB>  <TAB> left = bool(m) <TAB>  <TAB> right = predicate(i) <TAB>  <TAB> if left != right: <TAB>  <TAB>  <TAB> self.fail(""i = %d, b = %r, match: %s, predicate: %s"" % (i, b, left, right)) <MASK> num_matches += 1 <TAB> return num_matches",if m :,131
4030,"def __new__(cls, *args, **kwargs): <TAB> if len(args) == 1: <TAB>  <TAB> if len(kwargs): <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""You can either use {} with one positional argument or with keyword arguments, not both."".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> cls.__name__ <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if not args[0]: <TAB>  <TAB>  <TAB> return super().__new__(cls) <MASK> return cls <TAB> return super().__new__(cls, *args, **kwargs)","if isinstance ( args [ 0 ] , cls ) :",137
4031,"def concatenateCharacterTokens(tokens): <TAB> pendingCharacters = [] <TAB> for token in tokens: <TAB>  <TAB> type = token[""type""] <TAB>  <TAB> if type in (""Characters"", ""SpaceCharacters""): <TAB>  <TAB>  <TAB> pendingCharacters.append(token[""data""]) <TAB>  <TAB> else: <MASK> yield {""type"": ""Characters"", ""data"": """".join(pendingCharacters)} <TAB>  <TAB>  <TAB>  <TAB> pendingCharacters = [] <TAB>  <TAB>  <TAB> yield token <TAB> if pendingCharacters: <TAB>  <TAB> yield {""type"": ""Characters"", ""data"": """".join(pendingCharacters)}",if pendingCharacters :,130
4032,"def get_ranges_from_func_set(support_set): <TAB> pos_start = 0 <TAB> pos_end = 0 <TAB> ranges = [] <TAB> for pos, func in enumerate(network.function): <TAB>  <TAB> if func.type in support_set: <TAB>  <TAB>  <TAB> pos_end = pos <TAB>  <TAB> else: <MASK> ranges.append((pos_start, pos_end)) <TAB>  <TAB>  <TAB> pos_start = pos + 1 <TAB> if pos_end >= pos_start: <TAB>  <TAB> ranges.append((pos_start, pos_end)) <TAB> return ranges",if pos_end >= pos_start :,145
4033,"def _visit(self, func): <TAB> fname = func[0] <TAB> if fname in self._flags: <MASK> logger.critical(""Fatal error! network ins not Dag."") <TAB>  <TAB>  <TAB> import sys <TAB>  <TAB>  <TAB> sys.exit(-1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return <TAB> else: <TAB>  <TAB> if fname not in self._flags: <TAB>  <TAB>  <TAB> self._flags[fname] = 1 <TAB>  <TAB> for output in func[3]: <TAB>  <TAB>  <TAB> for f in self._orig: <TAB>  <TAB>  <TAB>  <TAB> for input in f[2]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if output == input: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._visit(f) <TAB> self._flags[fname] = 2 <TAB> self._sorted.insert(0, func)",if self . _flags [ fname ] == 1 :,188
4034,"def graph_merge_softmax_with_crossentropy_softmax(node): <TAB> if node.op == softmax_with_bias: <TAB>  <TAB> x, b = node.inputs <TAB>  <TAB> for x_client in x.clients: <MASK> big_client = x_client[0] <TAB>  <TAB>  <TAB>  <TAB> if big_client in [b_client[0] for b_client in b.clients]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> xx, bb, ll = big_client.inputs <TAB>  <TAB>  <TAB>  <TAB>  <TAB> mergeable_client = big_client.op(x, b, ll) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> copy_stack_trace(node.outputs[0], mergeable_client[1]) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return [mergeable_client[1]]",if x_client [ 0 ] . op == crossentropy_softmax_argmax_1hot_with_bias :,199
4035,"def confidence(self): <TAB> if self.bbox: <TAB>  <TAB> # Units are measured in Kilometers <TAB>  <TAB> distance = Distance(self.northeast, self.southwest, units=""km"") <TAB>  <TAB> for score, maximum in [ <TAB>  <TAB>  <TAB> (10, 0.25), <TAB>  <TAB>  <TAB> (9, 0.5), <TAB>  <TAB>  <TAB> (8, 1), <TAB>  <TAB>  <TAB> (7, 5), <TAB>  <TAB>  <TAB> (6, 7.5), <TAB>  <TAB>  <TAB> (5, 10), <TAB>  <TAB>  <TAB> (4, 15), <TAB>  <TAB>  <TAB> (3, 20), <TAB>  <TAB>  <TAB> (2, 25), <TAB>  <TAB> ]: <TAB>  <TAB>  <TAB> if distance < maximum: <TAB>  <TAB>  <TAB>  <TAB> return score <MASK> return 1 <TAB> # Cannot determine score <TAB> return 0",if distance >= 25 :,192
4036,"def OnListEndLabelEdit(self, std, extra): <TAB> item = extra[0] <TAB> text = item[4] <TAB> if text is None: <TAB>  <TAB> return <TAB> item_id = self.GetItem(item[0])[6] <TAB> from bdb import Breakpoint <TAB> for bplist in Breakpoint.bplist.itervalues(): <TAB>  <TAB> for bp in bplist: <TAB>  <TAB>  <TAB> if id(bp) == item_id: <MASK> text = None <TAB>  <TAB>  <TAB>  <TAB> bp.cond = text <TAB>  <TAB>  <TAB>  <TAB> break <TAB> self.RespondDebuggerData()","if text . strip ( ) . lower ( ) == ""none"" :",151
4037,"def _handle_autocomplete_request_for_text(text): <TAB> if not hasattr(text, ""autocompleter""): <MASK> if isinstance(text, CodeViewText): <TAB>  <TAB>  <TAB>  <TAB> text.autocompleter = Completer(text) <TAB>  <TAB>  <TAB> elif isinstance(text, ShellText): <TAB>  <TAB>  <TAB>  <TAB> text.autocompleter = ShellCompleter(text) <TAB>  <TAB>  <TAB> text.bind(""<1>"", text.autocompleter.on_text_click) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return <TAB> text.autocompleter.handle_autocomplete_request()","if isinstance ( text , ( CodeViewText , ShellText ) ) and text . is_python_text ( ) :",151
4038,"def visit_Macro(self, node, frame): <TAB> macro_frame, macro_ref = self.macro_body(node, frame) <TAB> self.newline() <TAB> if frame.toplevel: <MASK> self.write(""context.exported_vars.add(%r)"" % node.name) <TAB>  <TAB> ref = frame.symbols.ref(node.name) <TAB>  <TAB> self.writeline(""context.vars[%r] = "" % node.name) <TAB> self.write(""%s = "" % frame.symbols.ref(node.name)) <TAB> self.macro_def(macro_ref, macro_frame)","if not node . name . startswith ( ""_"" ) :",150
4039,"def execute(cls, ctx, op): <TAB> try: <TAB>  <TAB> pd.set_option(""mode.use_inf_as_na"", op.use_inf_as_na) <MASK> return cls._execute_map(ctx, op) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return cls._execute_combine(ctx, op) <TAB> finally: <TAB>  <TAB> pd.reset_option(""mode.use_inf_as_na"")",if op . stage == OperandStage . map :,113
4040,"def ranges(self, start, end): <TAB> try: <TAB>  <TAB> iterators = [i.ranges(start, end) for i in self.range_iterators] <TAB>  <TAB> starts, ends, values = zip(*[next(i) for i in iterators]) <TAB>  <TAB> starts = list(starts) <TAB>  <TAB> ends = list(ends) <TAB>  <TAB> values = list(values) <TAB>  <TAB> while start < end: <TAB>  <TAB>  <TAB> min_end = min(ends) <TAB>  <TAB>  <TAB> yield start, min_end, values <TAB>  <TAB>  <TAB> start = min_end <TAB>  <TAB>  <TAB> for i, iterator in enumerate(iterators): <MASK> starts[i], ends[i], values[i] = next(iterator) <TAB> except StopIteration: <TAB>  <TAB> return",if ends [ i ] == min_end :,188
4041,"def get_explanation(self, spec): <TAB> """"""Expand an explanation."""""" <TAB> if spec: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> a = self.dns_txt(spec) <MASK> return str(self.expand(to_ascii(a[0]), stripdot=False)) <TAB>  <TAB> except PermError: <TAB>  <TAB>  <TAB> # RFC4408 6.2/4 syntax errors cause exp= to be ignored <TAB>  <TAB>  <TAB> if self.strict > 1: <TAB>  <TAB>  <TAB>  <TAB> raise  # but report in harsh mode for record checking tools <TAB>  <TAB>  <TAB> pass <TAB> elif self.strict > 1: <TAB>  <TAB> raise PermError(""Empty domain-spec on exp="") <TAB> # RFC4408 6.2/4 empty domain spec is ignored <TAB> # (unless you give precedence to the grammar). <TAB> return None",if len ( a ) == 1 :,200
4042,"def iter_fields(node, *, include_meta=True, exclude_unset=False): <TAB> exclude_meta = not include_meta <TAB> for field_name, field in node._fields.items(): <TAB>  <TAB> if exclude_meta and field.meta: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> field_val = getattr(node, field_name, _marker) <TAB>  <TAB> if field_val is _marker: <TAB>  <TAB>  <TAB> continue <MASK> if callable(field.default): <TAB>  <TAB>  <TAB>  <TAB> default = field.default() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> default = field.default <TAB>  <TAB>  <TAB> if field_val == default: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> yield field_name, field_val",if exclude_unset :,171
4043,"def __setattr__(self, name, value): <TAB> try: <TAB>  <TAB> field = self._meta.get_field(name) <MASK> value = value[: field.max_length] <TAB> except models.fields.FieldDoesNotExist: <TAB>  <TAB> pass  # This happens with foreign keys. <TAB> super.__setattr__(self, name, value)","if type ( field ) in [ models . CharField , models . TextField ] and type ( value ) == str :",104
4044,"def create_child(self, value=None, _id=None): <TAB> with atomic(savepoint=False): <TAB>  <TAB> child_key = self.get_next_child_key() <MASK> value = child_key <TAB>  <TAB> child = self.__class__.objects.create(id=_id, key=child_key, value=value) <TAB>  <TAB> return child",if value is None :,92
4045,"def list_tags_for_stream(self, stream_name, exclusive_start_tag_key=None, limit=None): <TAB> stream = self.describe_stream(stream_name) <TAB> tags = [] <TAB> result = {""HasMoreTags"": False, ""Tags"": tags} <TAB> for key, val in sorted(stream.tags.items(), key=lambda x: x[0]): <MASK> result[""HasMoreTags""] = True <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if exclusive_start_tag_key and key < exclusive_start_tag_key: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> tags.append({""Key"": key, ""Value"": val}) <TAB> return result",if limit and len ( tags ) >= limit :,166
4046,"def emit(self, record): <TAB> try: <TAB>  <TAB> app = get_app() <MASK> msg = self.format(record) <TAB>  <TAB>  <TAB> debug_buffer = app.layout.get_buffer_by_name(""debug_buffer"") <TAB>  <TAB>  <TAB> current_document = debug_buffer.document.text <TAB>  <TAB>  <TAB> if current_document: <TAB>  <TAB>  <TAB>  <TAB> msg = ""\n"".join([current_document, msg]) <TAB>  <TAB>  <TAB> debug_buffer.set_document(Document(text=msg), bypass_readonly=True) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> super().emit(record) <TAB> except: <TAB>  <TAB> self.handleError(record)","if app . is_running and getattr ( app , ""debug"" , False ) :",170
4047,"def worker(): <TAB> global error <TAB> while True: <TAB>  <TAB> (num, q) = pq.get() <MASK> pq.task_done() <TAB>  <TAB>  <TAB> break <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> process_one(q) <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> error = e <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> pq.task_done()",if q is None or error is not None :,99
4048,"def transceiver(self, data): <TAB> out = [] <TAB> for t in range(8): <TAB>  <TAB> if data[t] == 0: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> value = data[t] <TAB>  <TAB> for b in range(8): <MASK> if len(TRANSCEIVER[t]) < b + 1: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> out.append(""(unknown)"") <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> out.append(TRANSCEIVER[t][b]) <TAB>  <TAB>  <TAB> value <<= 1 <TAB> self.annotate(""Transceiver compliance"", "", "".join(out))",if value & 0x80 :,155
4049,"def skip_to_close_match(self): <TAB> nestedCount = 1 <TAB> while 1: <TAB>  <TAB> tok = self.tokenizer.get_next_token() <TAB>  <TAB> ttype = tok[""style""] <MASK> return <TAB>  <TAB> elif self.classifier.is_index_op(tok): <TAB>  <TAB>  <TAB> tval = tok[""text""] <TAB>  <TAB>  <TAB> if self.opHash.has_key(tval): <TAB>  <TAB>  <TAB>  <TAB> if self.opHash[tval][1] == 1: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> nestedCount += 1 <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> nestedCount -= 1 <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if nestedCount <= 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break",if ttype == SCE_PL_UNUSED :,176
4050,"def GenerateVector(self, hits, vector, level): <TAB> """"""Generate possible hit vectors which match the rules."""""" <TAB> for item in hits.get(level, []): <TAB>  <TAB> if vector: <MASK> continue <TAB>  <TAB>  <TAB> if item > self.max_separation + vector[-1]: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> new_vector = vector + [item] <TAB>  <TAB> if level + 1 == len(hits): <TAB>  <TAB>  <TAB> yield new_vector <TAB>  <TAB> elif level + 1 < len(hits): <TAB>  <TAB>  <TAB> for result in self.GenerateVector(hits, new_vector, level + 1): <TAB>  <TAB>  <TAB>  <TAB> yield result",if item < vector [ - 1 ] :,157
4051,"def __setattr__(self, name, value): <TAB> if name == ""path"": <MASK> if value[0] != ""/"": <TAB>  <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> 'The page path should always start with a slash (""/"").' <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> elif name == ""load_time"": <TAB>  <TAB> if value and not isinstance(value, int): <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Page load time must be specified in integer milliseconds."" <TAB>  <TAB>  <TAB> ) <TAB> object.__setattr__(self, name, value)","if value and value != """" :",136
4052,"def awaitTermination(self, timeout=None): <TAB> if self.scheduler is None: <TAB>  <TAB> raise RuntimeError(""StreamimgContext not started"") <TAB> try: <TAB>  <TAB> deadline = time.time() + timeout if timeout is not None else None <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> is_terminated = self._runOnce() <MASK> break <TAB>  <TAB>  <TAB> if self.batchCallback: <TAB>  <TAB>  <TAB>  <TAB> self.batchCallback() <TAB> except KeyboardInterrupt: <TAB>  <TAB> pass <TAB> finally: <TAB>  <TAB> self.sc.stop() <TAB>  <TAB> logger.info(""StreamingContext stopped successfully"")",if is_terminated or ( deadline is not None and time . time ( ) > deadline ) :,157
4053,"def stopbutton(self): <TAB> if GPIOcontrol: <TAB>  <TAB> while mediastopbutton: <TAB>  <TAB>  <TAB> time.sleep(0.25) <MASK> print(""Stopped"") <TAB>  <TAB>  <TAB>  <TAB> stop()",if not GPIO . input ( stoppushbutton ) :,64
4054,"def test_create_connection_timeout(self): <TAB> # Issue #9792: create_connection() should not recast timeout errors <TAB> # as generic socket errors. <TAB> with self.mocked_socket_module(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> socket.create_connection((HOST, 1234)) <TAB>  <TAB> except socket.timeout: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> except OSError as exc: <MASK> raise <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.fail(""socket.timeout not raised"")",if support . IPV6_ENABLED or exc . errno != errno . EAFNOSUPPORT :,135
4055,"def handle_exception_and_die(e): <TAB> if hasattr(e, ""kind""): <MASK> sys.stderr.write(""ABORT: "" + e.msg + ""\n"") <TAB>  <TAB>  <TAB> sys.exit(e.value) <TAB>  <TAB> elif e.kind == ""exit"": <TAB>  <TAB>  <TAB> sys.stderr.write(""EXITING\n"") <TAB>  <TAB>  <TAB> sys.exit(e.value) <TAB> else: <TAB>  <TAB> print(str(e)) <TAB>  <TAB> sys.exit(1)","if e . kind == ""die"" :",128
4056,"def gets(self, key): <TAB> with self.client_pool.get_and_release(destroy_on_fail=True) as client: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return client.gets(key) <TAB>  <TAB> except Exception: <MASK> return (None, None) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise",if self . ignore_exc :,90
4057,"def _execute(self, options, args): <TAB> if len(args) < 3: <TAB>  <TAB> raise CommandError(_(""Not enough arguments"")) <TAB> tag = fsn2text(args[0]) <TAB> value = fsn2text(args[1]) <TAB> paths = args[2:] <TAB> songs = [] <TAB> for path in paths: <TAB>  <TAB> song = self.load_song(path) <MASK> raise CommandError(_(""Can not set %r"") % tag) <TAB>  <TAB> self.log(""Add %r to %r"" % (value, tag)) <TAB>  <TAB> song.add(tag, value) <TAB>  <TAB> songs.append(song) <TAB> self.save_songs(songs)",if not song . can_change ( tag ) :,169
4058,"def get_place_name(self, place_handle): <TAB> """"""Obtain a place name"""""" <TAB> text = """" <TAB> if place_handle: <TAB>  <TAB> place = self.dbstate.db.get_place_from_handle(place_handle) <TAB>  <TAB> if place: <TAB>  <TAB>  <TAB> place_title = place_displayer.display(self.dbstate.db, place) <MASK> if len(place_title) > 25: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> text = place_title[:24] + ""..."" <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> text = place_title <TAB> return text","if place_title != """" :",153
4059,"def _Determine_Do(self): <TAB> self.applicable = 1 <TAB> self.value = os.environ.get(self.name, None) <TAB> if self.value is None and black.configure.items.has_key(""buildType""): <TAB>  <TAB> buildType = black.configure.items[""buildType""].Get() <MASK> self.value = ""warn"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.value = None <TAB> self.determined = 1","if buildType == ""debug"" :",115
4060,"def bundle_directory(self, dirpath): <TAB> """"""Bundle all modules/packages in the given directory."""""" <TAB> dirpath = os.path.abspath(dirpath) <TAB> for nm in os.listdir(dirpath): <TAB>  <TAB> nm = _u(nm) <MASK> continue <TAB>  <TAB> itempath = os.path.join(dirpath, nm) <TAB>  <TAB> if os.path.isdir(itempath): <TAB>  <TAB>  <TAB> if os.path.exists(os.path.join(itempath, ""__init__.py"")): <TAB>  <TAB>  <TAB>  <TAB> self.bundle_package(itempath) <TAB>  <TAB> elif nm.endswith("".py""): <TAB>  <TAB>  <TAB> self.bundle_module(itempath)","if nm . startswith ( ""."" ) :",160
4061,"def header_fields(self, fields): <TAB> headers = dict(self.conn.response.getheaders()) <TAB> ret = {} <TAB> for field in fields: <MASK> raise ValueError(""%s was not found in response header"" % (field[1])) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> ret[field[0]] = int(headers[field[1]]) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> ret[field[0]] = headers[field[1]] <TAB> return ret",if not headers . has_key ( field [ 1 ] ) :,124
4062,"def caesar_cipher(s, k): <TAB> result = """" <TAB> for char in s: <TAB>  <TAB> n = ord(char) <MASK> n = ((n - 65 + k) % 26) + 65 <TAB>  <TAB> if 96 < n < 123: <TAB>  <TAB>  <TAB> n = ((n - 97 + k) % 26) + 97 <TAB>  <TAB> result = result + chr(n) <TAB> return result",if 64 < n < 91 :,104
4063,"def qtTypeIdent(conn, *args): <TAB> # We're not using the conn object at the moment, but - we will <TAB> # modify the <TAB> # logic to use the server version specific keywords later. <TAB> res = None <TAB> value = None <TAB> for val in args: <TAB>  <TAB> # DataType doesn't have len function then convert it to string <TAB>  <TAB> if not hasattr(val, ""__len__""): <TAB>  <TAB>  <TAB> val = str(val) <MASK> continue <TAB>  <TAB> value = val <TAB>  <TAB> if Driver.needsQuoting(val, True): <TAB>  <TAB>  <TAB> value = value.replace('""', '""""') <TAB>  <TAB>  <TAB> value = '""' + value + '""' <TAB>  <TAB> res = ((res and res + ""."") or """") + value <TAB> return res",if len ( val ) == 0 :,181
4064,"def _parse_timezone( <TAB> value: Optional[str], error: Type[Exception]) -> Union[None, int, timezone]: <TAB> if value == ""Z"": <TAB>  <TAB> return timezone.utc <TAB> elif value is not None: <TAB>  <TAB> offset_mins = int(value[-2:]) if len(value) > 3 else 0 <TAB>  <TAB> offset = 60 * int(value[1:3]) + offset_mins <MASK> offset = -offset <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return timezone(timedelta(minutes=offset)) <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB> raise error() <TAB> else: <TAB>  <TAB> return None","if value [ 0 ] == ""-"" :",153
4065,"def indent(elem, level=0): <TAB> i = ""\n"" + level * ""  "" <TAB> if len(elem): <TAB>  <TAB> if not elem.text or not elem.text.strip(): <TAB>  <TAB>  <TAB> elem.text = i + ""  "" <MASK> elem.tail = i <TAB>  <TAB> for elem in elem: <TAB>  <TAB>  <TAB> indent(elem, level + 1) <TAB>  <TAB> if not elem.tail or not elem.tail.strip(): <TAB>  <TAB>  <TAB> elem.tail = i <TAB> else: <TAB>  <TAB> if level and (not elem.tail or not elem.tail.strip()): <TAB>  <TAB>  <TAB> elem.tail = i",if not elem . tail or not elem . tail . strip ( ) :,161
4066,"def _make_slices( <TAB> shape: tp.Tuple[int, ...], <TAB> axes: tp.Tuple[int, ...], <TAB> size: int, <TAB> rng: np.random.RandomState,) -> tp.List[slice]: <TAB> slices = [] <TAB> for a, s in enumerate(shape): <TAB>  <TAB> if a in axes: <MASK> raise ValueError(""Cannot crossover on axis with size 1"") <TAB>  <TAB>  <TAB> start = rng.randint(s - size) <TAB>  <TAB>  <TAB> slices.append(slice(start, start + size)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> slices.append(slice(None)) <TAB> return slices",if s <= 1 :,154
4067,"def _loadTestsFromTestCase(self, event, testCaseClass): <TAB> evt = events.LoadFromTestCaseEvent(event.loader, testCaseClass) <TAB> result = self.session.hooks.loadTestsFromTestCase(evt) <TAB> if evt.handled: <TAB>  <TAB> loaded_suite = result or event.loader.suiteClass() <TAB> else: <TAB>  <TAB> names = self._getTestCaseNames(event, testCaseClass) <MASK> names = [""runTest""] <TAB>  <TAB> # FIXME return failure test case if name not in testcase class <TAB>  <TAB> loaded_suite = event.loader.suiteClass(map(testCaseClass, names)) <TAB> if evt.extraTests: <TAB>  <TAB> loaded_suite.addTests(evt.extraTests) <TAB> return loaded_suite","if not names and hasattr ( testCaseClass , ""runTest"" ) :",185
4068,"def check_settings(self): <TAB> if self.settings_dict[""TIME_ZONE""] is not None: <TAB>  <TAB> if not settings.USE_TZ: <TAB>  <TAB>  <TAB> raise ImproperlyConfigured( <TAB>  <TAB>  <TAB>  <TAB> ""Connection '%s' cannot set TIME_ZONE because USE_TZ is "" <TAB>  <TAB>  <TAB>  <TAB> ""False."" % self.alias <TAB>  <TAB>  <TAB> ) <MASK> raise ImproperlyConfigured( <TAB>  <TAB>  <TAB>  <TAB> ""Connection '%s' cannot set TIME_ZONE because its engine "" <TAB>  <TAB>  <TAB>  <TAB> ""handles time zones conversions natively."" % self.alias <TAB>  <TAB>  <TAB> )",elif self . features . supports_timezones :,140
4069,"def collect_conflicting_diffs(path, decisions): <TAB> local_conflict_diffs = [] <TAB> remote_conflict_diffs = [] <TAB> for d in decisions: <MASK> ld = adjust_patch_level(path, d.common_path, d.local_diff) <TAB>  <TAB>  <TAB> rd = adjust_patch_level(path, d.common_path, d.remote_diff) <TAB>  <TAB>  <TAB> local_conflict_diffs.extend(ld) <TAB>  <TAB>  <TAB> remote_conflict_diffs.extend(rd) <TAB> return local_conflict_diffs, remote_conflict_diffs",if d . conflict :,140
4070,"def short_repr(obj): <TAB> if isinstance( <TAB>  <TAB> obj, <TAB>  <TAB> (type, types.ModuleType, types.BuiltinMethodType, types.BuiltinFunctionType), <TAB> ): <TAB>  <TAB> return obj.__name__ <TAB> if isinstance(obj, types.MethodType): <MASK> return obj.im_func.__name__ + "" (bound)"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return obj.im_func.__name__ <TAB> if isinstance(obj, (tuple, list, dict, set)): <TAB>  <TAB> return ""%d items"" % len(obj) <TAB> if isinstance(obj, weakref.ref): <TAB>  <TAB> return ""all_weakrefs_are_one"" <TAB> return repr(obj)[:40]",if obj . im_self is not None :,172
4071,"def _massage_uri(uri): <TAB> if uri: <MASK> uri = uri.replace(""hdfs://"", get_defaultfs()) <TAB>  <TAB> elif uri.startswith(""/""): <TAB>  <TAB>  <TAB> uri = get_defaultfs() + uri <TAB> return uri","if uri . startswith ( ""hdfs:///"" ) :",68
4072,"def chsub(self, msg, chatid): <TAB> (cmd, evt, params) = self.tokenize(msg, 3) <TAB> if cmd == ""/sub"": <TAB>  <TAB> sql = ""replace into telegram_subscriptions(uid, event_type, parameters) values (?, ?, ?)"" <TAB> else: <MASK> sql = ""delete from telegram_subscriptions where uid = ? and (event_type = ? or parameters = ? or 1 = 1)""  # does not look very elegant, but makes unsub'ing everythign possible <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sql = ""delete from telegram_subscriptions where uid = ? and event_type = ? and parameters = ?"" <TAB> with self.bot.database as conn: <TAB>  <TAB> conn.execute(sql, [chatid, evt, params]) <TAB>  <TAB> conn.commit() <TAB> return","if evt == ""everything"" :",196
4073,"def undefined_symbols(self): <TAB> result = [] <TAB> for p in self.Productions: <MASK> continue <TAB>  <TAB> for s in p.prod: <TAB>  <TAB>  <TAB> if not s in self.Prodnames and not s in self.Terminals and s != ""error"": <TAB>  <TAB>  <TAB>  <TAB> result.append((s, p)) <TAB> return result",if not p :,88
4074,"def renumber(self, x1, y1, x2, y2, dx, dy): <TAB> out = [] <TAB> for part in re.split(""(\w+)"", self.formula): <TAB>  <TAB> m = re.match(""^([A-Z]+)([1-9][0-9]*)$"", part) <TAB>  <TAB> if m is not None: <TAB>  <TAB>  <TAB> sx, sy = m.groups() <TAB>  <TAB>  <TAB> x = colname2num(sx) <TAB>  <TAB>  <TAB> y = int(sy) <MASK> part = cellname(x + dx, y + dy) <TAB>  <TAB> out.append(part) <TAB> return FormulaCell("""".join(out), self.fmt, self.alignment)",if x1 <= x <= x2 and y1 <= y <= y2 :,179
4075,"def modify_column(self, column: List[Optional[""Cell""]]): <TAB> for i in range(len(column)): <TAB>  <TAB> gate = column[i] <TAB>  <TAB> if gate is self: <TAB>  <TAB>  <TAB> continue <MASK> # The first parity control to modify the column must merge all <TAB>  <TAB>  <TAB> # of the other parity controls into itself. <TAB>  <TAB>  <TAB> column[i] = None <TAB>  <TAB>  <TAB> self._basis_change += gate._basis_change <TAB>  <TAB>  <TAB> self.qubits += gate.qubits <TAB>  <TAB> elif gate is not None: <TAB>  <TAB>  <TAB> column[i] = gate.controlled_by(self.qubits[0])","elif isinstance ( gate , ParityControlCell ) :",164
4076,"def update_neighbor(neigh_ip_address, changes): <TAB> rets = [] <TAB> for k, v in changes.items(): <MASK> rets.append(_update_med(neigh_ip_address, v)) <TAB>  <TAB> if k == neighbors.ENABLED: <TAB>  <TAB>  <TAB> rets.append(update_neighbor_enabled(neigh_ip_address, v)) <TAB>  <TAB> if k == neighbors.CONNECT_MODE: <TAB>  <TAB>  <TAB> rets.append(_update_connect_mode(neigh_ip_address, v)) <TAB> return all(rets)",if k == neighbors . MULTI_EXIT_DISC :,138
4077,"def writexml( <TAB> self, <TAB> stream, <TAB> indent="""", <TAB> addindent="""", <TAB> newl="""", <TAB> strip=0, <TAB> nsprefixes={}, <TAB> namespace="""",): <TAB> w = _streamWriteWrapper(stream) <TAB> if self.raw: <TAB>  <TAB> val = self.nodeValue <TAB>  <TAB> if not isinstance(val, str): <TAB>  <TAB>  <TAB> val = str(self.nodeValue) <TAB> else: <TAB>  <TAB> v = self.nodeValue <MASK> v = str(v) <TAB>  <TAB> if strip: <TAB>  <TAB>  <TAB> v = "" "".join(v.split()) <TAB>  <TAB> val = escape(v) <TAB> w(val)","if not isinstance ( v , str ) :",164
4078,"def _condition(ct): <TAB> for qobj in args: <MASK> # normal kwargs are an AND anyway, so just use those for now <TAB>  <TAB>  <TAB> for child in qobj.children: <TAB>  <TAB>  <TAB>  <TAB> kwargs.update(dict([child])) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise NotImplementedError(""Unsupported Q object"") <TAB> for attr, val in kwargs.items(): <TAB>  <TAB> if getattr(ct, attr) != val: <TAB>  <TAB>  <TAB> return False <TAB> return True","if qobj . connector == ""AND"" and not qobj . negated :",127
4079,"def results_iter(self): <MASK> from django.db.models.fields import DateTimeField <TAB>  <TAB> fields = [DateTimeField()] <TAB> else: <TAB>  <TAB> needs_string_cast = self.connection.features.needs_datetime_string_cast <TAB> offset = len(self.query.extra_select) <TAB> for rows in self.execute_sql(MULTI): <TAB>  <TAB> for row in rows: <TAB>  <TAB>  <TAB> date = row[offset] <TAB>  <TAB>  <TAB> if self.connection.ops.oracle: <TAB>  <TAB>  <TAB>  <TAB> date = self.resolve_columns(row, fields)[offset] <TAB>  <TAB>  <TAB> elif needs_string_cast: <TAB>  <TAB>  <TAB>  <TAB> date = typecast_timestamp(str(date)) <TAB>  <TAB>  <TAB> yield date",if self . connection . ops . oracle :,182
4080,"def get_job_type(self): <TAB> if int(self.job_runtime_conf.get(""dsl_version"", 1)) == 2: <TAB>  <TAB> job_type = ( <TAB>  <TAB>  <TAB> self.job_runtime_conf[""job_parameters""].get(""common"", {}).get(""job_type"") <TAB>  <TAB> ) <MASK> job_type = self.job_runtime_conf[""job_parameters""].get(""job_type"", ""train"") <TAB> else: <TAB>  <TAB> job_type = self.job_runtime_conf[""job_parameters""].get(""job_type"", ""train"") <TAB> return job_type",if not job_type :,150
4081,"def validate_assessment_criteria(self): <TAB> if self.assessment_criteria: <TAB>  <TAB> total_weightage = 0 <TAB>  <TAB> for criteria in self.assessment_criteria: <TAB>  <TAB>  <TAB> total_weightage += criteria.weightage or 0 <MASK> frappe.throw(_(""Total Weightage of all Assessment Criteria must be 100%""))",if total_weightage != 100 :,97
4082,"def get_list_of_strings_to_mongo_objects(self, notifications_list=None): <TAB> result = [] <TAB> if len(notifications_list) > 0: <TAB>  <TAB> for x in notifications_list: <TAB>  <TAB>  <TAB> split_provider_id = x.split("":"")  # email:id <MASK> _id = split_provider_id[1] <TAB>  <TAB>  <TAB>  <TAB> cursor = self.get_by_id(_id) <TAB>  <TAB>  <TAB>  <TAB> if cursor:  # Append if exists <TAB>  <TAB>  <TAB>  <TAB>  <TAB> result.append(cursor) <TAB> return result",if len ( split_provider_id ) == 2 :,148
4083,"def dump_predictions_to_database(relation, predictions): <TAB> judge = ""iepy-run on {}"".format(datetime.now().strftime(""%Y-%m-%d %H:%M"")) <TAB> for evidence, relation_is_present in predictions.items(): <TAB>  <TAB> label = ( <TAB>  <TAB>  <TAB> EvidenceLabel.YESRELATION <MASK> else EvidenceLabel.NORELATION <TAB>  <TAB> ) <TAB>  <TAB> evidence.set_label(relation, label, judge, labeled_by_machine=True)",if relation_is_present,129
4084,"def __init__(self, **kwargs): <TAB> # We hard-code the `to` argument for ForeignKey.__init__ <TAB> dfl = get_model_label(self.default_model_class) <TAB> if ""to"" in kwargs.keys():  # pragma: no cover <TAB>  <TAB> old_to = get_model_label(kwargs.pop(""to"")) <MASK> msg = ""%s can only be a ForeignKey to %s; %s passed"" % ( <TAB>  <TAB>  <TAB>  <TAB> self.__class__.__name__, <TAB>  <TAB>  <TAB>  <TAB> dfl, <TAB>  <TAB>  <TAB>  <TAB> old_to, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> warnings.warn(msg, SyntaxWarning) <TAB> kwargs[""to""] = dfl <TAB> super().__init__(**kwargs)",if old_to . lower ( ) != dfl . lower ( ) :,182
4085,"def reverse(self): <TAB> """"""Reverse *IN PLACE*."""""" <TAB> li = self.leftindex <TAB> lb = self.leftblock <TAB> ri = self.rightindex <TAB> rb = self.rightblock <TAB> for i in range(self.len >> 1): <TAB>  <TAB> lb.data[li], rb.data[ri] = rb.data[ri], lb.data[li] <TAB>  <TAB> li += 1 <TAB>  <TAB> if li >= BLOCKLEN: <TAB>  <TAB>  <TAB> lb = lb.rightlink <TAB>  <TAB>  <TAB> li = 0 <TAB>  <TAB> ri -= 1 <MASK> rb = rb.leftlink <TAB>  <TAB>  <TAB> ri = BLOCKLEN - 1",if ri < 0 :,156
4086,"def get_api(user, url): <TAB> global API_CACHE <TAB> if API_CACHE is None or API_CACHE.get(url) is None: <TAB>  <TAB> API_CACHE_LOCK.acquire() <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if API_CACHE is None: <TAB>  <TAB>  <TAB>  <TAB> API_CACHE = {} <MASK> API_CACHE[url] = ImpalaDaemonApi(url) <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> API_CACHE_LOCK.release() <TAB> api = API_CACHE[url] <TAB> api.set_user(user) <TAB> return api",if API_CACHE . get ( url ) is None :,148
4087,"def invert_index(cls, index, length): <TAB> if np.isscalar(index): <TAB>  <TAB> return length - index <TAB> elif isinstance(index, slice): <TAB>  <TAB> start, stop = index.start, index.stop <TAB>  <TAB> new_start, new_stop = None, None <TAB>  <TAB> if start is not None: <TAB>  <TAB>  <TAB> new_stop = length - start <MASK> new_start = length - stop <TAB>  <TAB> return slice(new_start - 1, new_stop - 1) <TAB> elif isinstance(index, Iterable): <TAB>  <TAB> new_index = [] <TAB>  <TAB> for ind in index: <TAB>  <TAB>  <TAB> new_index.append(length - ind) <TAB> return new_index",if stop is not None :,168
4088,"def infer_returned_object(pyfunction, args): <TAB> """"""Infer the `PyObject` this `PyFunction` returns after calling"""""" <TAB> object_info = pyfunction.pycore.object_info <TAB> result = object_info.get_exact_returned(pyfunction, args) <TAB> if result is not None: <TAB>  <TAB> return result <TAB> result = _infer_returned(pyfunction, args) <TAB> if result is not None: <MASK> params = args.get_arguments(pyfunction.get_param_names(special_args=False)) <TAB>  <TAB>  <TAB> object_info.function_called(pyfunction, params, result) <TAB>  <TAB> return result <TAB> return object_info.get_returned(pyfunction, args)",if args and pyfunction . get_module ( ) . get_resource ( ) is not None :,187
4089,"def _check_imports(lib): <TAB> # Make sure no conflicting libraries have been imported. <TAB> libs = [""PyQt4"", ""PyQt5"", ""PySide""] <TAB> libs.remove(lib) <TAB> for lib2 in libs: <TAB>  <TAB> lib2 += "".QtCore"" <MASK> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB> ""Refusing to import %s because %s is already "" ""imported."" % (lib, lib2) <TAB>  <TAB>  <TAB> )",if lib2 in sys . modules :,116
4090,"def _poll(fds, timeout): <TAB> if timeout is not None: <TAB>  <TAB> timeout = int(timeout * 1000)  # timeout is in milliseconds <TAB> fd_map = {} <TAB> pollster = select.poll() <TAB> for fd in fds: <TAB>  <TAB> pollster.register(fd, select.POLLIN) <MASK> fd_map[fd.fileno()] = fd <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> fd_map[fd] = fd <TAB> ls = [] <TAB> for fd, event in pollster.poll(timeout): <TAB>  <TAB> if event & select.POLLNVAL: <TAB>  <TAB>  <TAB> raise ValueError(""invalid file descriptor %i"" % fd) <TAB>  <TAB> ls.append(fd_map[fd]) <TAB> return ls","if hasattr ( fd , ""fileno"" ) :",180
4091,"def default(cls, connection=None): <TAB> """"""show the default connection, or make CONNECTION the default"""""" <TAB> if connection is not None: <TAB>  <TAB> target = cls._get_config_filename(connection) <MASK> if os.path.exists(cls._default_symlink): <TAB>  <TAB>  <TAB>  <TAB> os.remove(cls._default_symlink) <TAB>  <TAB>  <TAB> os.symlink(target, cls._default_symlink) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> cls._no_config_file_error(target) <TAB> if os.path.exists(cls._default_symlink): <TAB>  <TAB> print(""Default connection is "" + cls._default_connection()) <TAB> else: <TAB>  <TAB> print(""There is no default connection set"")",if os . path . exists ( target ) :,175
4092,"def process(self, fuzzresult): <TAB> base_url = urljoin(fuzzresult.url, "".."") <TAB> for line in fuzzresult.history.content.splitlines(): <TAB>  <TAB> record = line.split(""/"") <MASK> self.queue_url(urljoin(base_url, record[1])) <TAB>  <TAB>  <TAB> # Directory <TAB>  <TAB>  <TAB> if record[0] == ""D"": <TAB>  <TAB>  <TAB>  <TAB> self.queue_url(urljoin(base_url, record[1])) <TAB>  <TAB>  <TAB>  <TAB> self.queue_url(urljoin(base_url, ""%s/CVS/Entries"" % (record[1])))",if len ( record ) == 6 and record [ 1 ] :,153
4093,"def _GetCSVRow(self, value): <TAB> row = [] <TAB> for type_info in value.__class__.type_infos: <MASK> row.extend(self._GetCSVRow(value.Get(type_info.name))) <TAB>  <TAB> elif isinstance(type_info, rdf_structs.ProtoBinary): <TAB>  <TAB>  <TAB> row.append(text.Asciify(value.Get(type_info.name))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> row.append(str(value.Get(type_info.name))) <TAB> return row","if isinstance ( type_info , rdf_structs . ProtoEmbedded ) :",143
4094,"def get_history(self, state, dict_, passive=PASSIVE_OFF): <TAB> if self.key in dict_: <TAB>  <TAB> return History.from_scalar_attribute(self, state, dict_[self.key]) <TAB> else: <MASK> passive ^= INIT_OK <TAB>  <TAB> current = self.get(state, dict_, passive=passive) <TAB>  <TAB> if current is PASSIVE_NO_RESULT: <TAB>  <TAB>  <TAB> return HISTORY_BLANK <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return History.from_scalar_attribute(self, state, current)",if passive & INIT_OK :,143
4095,"def _iterate_self_and_parents(self, upto=None): <TAB> current = self <TAB> result = () <TAB> while current: <TAB>  <TAB> result += (current,) <MASK> break <TAB>  <TAB> elif current._parent is None: <TAB>  <TAB>  <TAB> raise sa_exc.InvalidRequestError( <TAB>  <TAB>  <TAB>  <TAB> ""Transaction %s is not on the active transaction list"" % (upto) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> current = current._parent <TAB> return result",if current . _parent is upto :,126
4096,"def get_by_uri(self, uri: str) -> bytes: <TAB> userId, bucket, key = self._parse_uri(uri) <TAB> try: <TAB>  <TAB> with db.session_scope() as dbsession: <TAB>  <TAB>  <TAB> result = db_archivedocument.get(userId, bucket, key, session=dbsession) <MASK> return utils.ensure_bytes(self._decode(result)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ObjectKeyNotFoundError(userId, bucket, key, caused_by=None) <TAB> except Exception as err: <TAB>  <TAB> logger.debug(""cannot get data: exception - "" + str(err)) <TAB>  <TAB> raise err",if result :,158
4097,"def app(scope, receive, send): <TAB> while True: <TAB>  <TAB> message = await receive() <TAB>  <TAB> if message[""type""] == ""websocket.connect"": <TAB>  <TAB>  <TAB> await send({""type"": ""websocket.accept""}) <TAB>  <TAB> elif message[""type""] == ""websocket.receive"": <TAB>  <TAB>  <TAB> pass <MASK> break","elif message [ ""type"" ] == ""websocket.disconnect"" :",93
4098,"def recv_some(p, t=0.1, e=1, tr=5, stderr=0): <TAB> if tr < 1: <TAB>  <TAB> tr = 1 <TAB> x = time.time() + t <TAB> y = [] <TAB> r = """" <TAB> if stderr: <TAB>  <TAB> pr = p.recv_err <TAB> else: <TAB>  <TAB> pr = p.recv <TAB> while time.time() < x or r: <TAB>  <TAB> r = pr() <TAB>  <TAB> if r is None: <TAB>  <TAB>  <TAB> break <MASK> y.append(r) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> time.sleep(max((x - time.time()) / tr, 0)) <TAB> return """".join(y)",elif r :,168
4099,"def mouse_down(self, event): <TAB> if event.button == 1: <MASK> p = event.local <TAB>  <TAB>  <TAB> if self.scroll_up_rect().collidepoint(p): <TAB>  <TAB>  <TAB>  <TAB> self.scroll_up() <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> elif self.scroll_down_rect().collidepoint(p): <TAB>  <TAB>  <TAB>  <TAB> self.scroll_down() <TAB>  <TAB>  <TAB>  <TAB> return <TAB> if event.button == 4: <TAB>  <TAB> self.scroll_up() <TAB> if event.button == 5: <TAB>  <TAB> self.scroll_down() <TAB> GridView.mouse_down(self, event)",if self . scrolling :,160
4100,"def copy_from(self, other): <TAB> if self is other: <TAB>  <TAB> return  # Myself! <TAB> self.strictness = other.strictness  # sets behaviors in bulk <TAB> for name in self.all_behaviors: <TAB>  <TAB> self.set_behavior(name, other.get_behavior(name)) <TAB> for name in self._plain_attrs: <TAB>  <TAB> val = getattr(other, name) <TAB>  <TAB> if isinstance(val, set): <TAB>  <TAB>  <TAB> val = val.copy() <MASK> val = val.copy() <TAB>  <TAB> setattr(self, name, val)","elif decimal and isinstance ( val , decimal . Decimal ) :",148
4101,"def __array_wrap__(self, out_arr, context=None): <TAB> if self.dim is None: <TAB>  <TAB> return out_arr <TAB> else: <TAB>  <TAB> this = self[:] <MASK> return Quantity.__array_wrap__(self[:], out_arr, context=context) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return out_arr","if isinstance ( this , Quantity ) :",90
4102,"def _ArgumentListHasDictionaryEntry(self, token): <TAB> """"""Check if the function argument list has a dictionary as an arg."""""" <TAB> if _IsArgumentToFunction(token): <TAB>  <TAB> while token: <MASK> length = token.matching_bracket.total_length - token.total_length <TAB>  <TAB>  <TAB>  <TAB> return length + self.stack[-2].indent > self.column_limit <TAB>  <TAB>  <TAB> if token.ClosesScope(): <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> if token.OpensScope(): <TAB>  <TAB>  <TAB>  <TAB> token = token.matching_bracket <TAB>  <TAB>  <TAB> token = token.next_token <TAB> return False","if token . value == ""{"" :",153
4103,"def save_all_changed_extensions(self): <TAB> """"""Save configuration changes to the user config file."""""" <TAB> has_changes = False <TAB> for ext_name in self.extensions: <TAB>  <TAB> options = self.extensions[ext_name] <TAB>  <TAB> for opt in options: <MASK> has_changes = True <TAB> if has_changes: <TAB>  <TAB> self.ext_userCfg.Save()","if self . set_extension_value ( ext_name , opt ) :",111
4104,"def to_dict(self): <TAB> out = {} <TAB> for key in ACTIVITY_KEYS: <TAB>  <TAB> attr = getattr(self, key) <MASK> out[key] = str(attr) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> out[key] = attr <TAB> if self.streak: <TAB>  <TAB> out[""streak""] = self.streak <TAB> return out","if isinstance ( attr , ( datetime . timedelta , datetime . datetime ) ) :",102
4105,"def clean_publication_date(cls, cleaned_input): <TAB> for add_channel in cleaned_input.get(""add_channels"", []): <TAB>  <TAB> is_published = add_channel.get(""is_published"") <TAB>  <TAB> publication_date = add_channel.get(""publication_date"") <MASK> add_channel[""publication_date""] = datetime.date.today()",if is_published and not publication_date :,98
4106,"def _random_blur(self, batch, sigma_max): <TAB> for i in range(len(batch)): <MASK> # Random sigma <TAB>  <TAB>  <TAB> sigma = random.uniform(0.0, sigma_max) <TAB>  <TAB>  <TAB> batch[i] = scipy.ndimage.filters.gaussian_filter(batch[i], sigma) <TAB> return batch",if bool ( random . getrandbits ( 1 ) ) :,92
4107,"def conninfo_parse(dsn): <TAB> ret = {} <TAB> length = len(dsn) <TAB> i = 0 <TAB> while i < length: <TAB>  <TAB> if dsn[i].isspace(): <TAB>  <TAB>  <TAB> i += 1 <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> param_match = PARAMETER_RE.match(dsn[i:]) <TAB>  <TAB> if not param_match: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> param = param_match.group(1) <TAB>  <TAB> i += param_match.end() <MASK> return <TAB>  <TAB> value, end = read_param_value(dsn[i:]) <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> i += end <TAB>  <TAB> ret[param] = value <TAB> return ret",if i >= length :,175
4108,"def set_environment_vars(env, source_env): <TAB> """"""Copy allowed environment variables from |source_env|."""""" <TAB> if not source_env: <TAB>  <TAB> return <TAB> for name, value in six.iteritems(source_env): <TAB>  <TAB> if is_forwarded_environment_variable(name): <TAB>  <TAB>  <TAB> # Avoid creating circular dependencies from importing environment by <TAB>  <TAB>  <TAB> # using os.getenv. <MASK> value = file_host.rebase_to_worker_root(value) <TAB>  <TAB>  <TAB> env[name] = value","if os . getenv ( ""TRUSTED_HOST"" ) and should_rebase_environment_value ( name ) :",152
4109,"def toterminal(self, tw): <TAB> # the entries might have different styles <TAB> last_style = None <TAB> for i, entry in enumerate(self.reprentries): <TAB>  <TAB> if entry.style == ""long"": <TAB>  <TAB>  <TAB> tw.line("""") <TAB>  <TAB> entry.toterminal(tw) <MASK> next_entry = self.reprentries[i + 1] <TAB>  <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB>  <TAB> entry.style == ""long"" <TAB>  <TAB>  <TAB>  <TAB> or entry.style == ""short"" <TAB>  <TAB>  <TAB>  <TAB> and next_entry.style == ""long"" <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> tw.sep(self.entrysep) <TAB> if self.extraline: <TAB>  <TAB> tw.line(self.extraline)",if i < len ( self . reprentries ) - 1 :,198
4110,"def __init__(self, loc, tabs=None): <TAB> if os.path.isdir(loc): <TAB>  <TAB> for item in os.listdir(loc): <MASK> continue <TAB>  <TAB>  <TAB> path = os.path.join(loc, item) <TAB>  <TAB>  <TAB> self.append(CronTab(user=False, tabfile=path)) <TAB> elif os.path.isfile(loc): <TAB>  <TAB> self.append(CronTab(user=False, tabfile=loc))","if item [ 0 ] == ""."" :",121
4111,"def import_data(self, fname): <TAB> """"""Import data in current namespace"""""" <TAB> if self.count(): <TAB>  <TAB> nsb = self.currentWidget() <TAB>  <TAB> nsb.refresh_table() <TAB>  <TAB> nsb.import_data(fname) <MASK> self.dockwidget.setVisible(True) <TAB>  <TAB>  <TAB> self.dockwidget.raise_()",if self . dockwidget and not self . ismaximized :,103
4112,"def get_menu_items(node): <TAB> aList = [] <TAB> for child in node.children: <TAB>  <TAB> for tag in (""@menu"", ""@item""): <MASK> name = child.h[len(tag) + 1 :].strip() <TAB>  <TAB>  <TAB>  <TAB> if tag == ""@menu"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> aList.append((""%s %s"" % (tag, name), get_menu_items(child), None)) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> b = g.splitLines("""".join(child.b)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> aList.append((tag, name, b[0] if b else """")) <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return aList",if child . h . startswith ( tag ) :,173
4113,"def __init__(self, *args, **kw): <TAB> if len(args) > 1: <TAB>  <TAB> raise TypeError(""MultiDict can only be called with one positional "" ""argument"") <TAB> if args: <TAB>  <TAB> if hasattr(args[0], ""iteritems""): <TAB>  <TAB>  <TAB> items = list(args[0].iteritems()) <MASK> items = list(args[0].items()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> items = list(args[0]) <TAB>  <TAB> self._items = items <TAB> else: <TAB>  <TAB> self._items = [] <TAB> if kw: <TAB>  <TAB> self._items.extend(kw.items())","elif hasattr ( args [ 0 ] , ""items"" ) :",156
4114,"def open(self) -> ""KeyValueDb"": <TAB> """"""Create a new data base or open existing one"""""" <TAB> if os.path.exists(self._name): <TAB>  <TAB> if not os.path.isfile(self._name): <TAB>  <TAB>  <TAB> raise IOError(""%s exists and is not a file"" % self._name) <MASK> # ignore empty files <TAB>  <TAB>  <TAB> return self <TAB>  <TAB> with open(self._name, ""rb"") as _in:  # binary mode <TAB>  <TAB>  <TAB> self.set_records(pickle.load(_in)) <TAB> else: <TAB>  <TAB> # make sure path exists <TAB>  <TAB> mkpath(os.path.dirname(self._name)) <TAB>  <TAB> self.commit() <TAB> return self",if os . path . getsize ( self . _name ) == 0 :,180
4115,"def sortModules(self): <TAB> super(NeuronDecomposableNetwork, self).sortModules() <TAB> self._constructParameterInfo() <TAB> # contains a list of lists of indices <TAB> self.decompositionIndices = {} <TAB> for neuron in self._neuronIterator(): <TAB>  <TAB> self.decompositionIndices[neuron] = [] <TAB> for w in range(self.paramdim): <TAB>  <TAB> inneuron, outneuron = self.paramInfo[w] <MASK> self.decompositionIndices[inneuron].append(w) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.decompositionIndices[outneuron].append(w)",if self . espStyleDecomposition and outneuron [ 0 ] in self . outmodules :,158
4116,"def visit_Options(self, node: qlast.Options) -> None: <TAB> for i, opt in enumerate(node.options.values()): <MASK> self.write("" "") <TAB>  <TAB> self.write(opt.name) <TAB>  <TAB> if not isinstance(opt, qlast.Flag): <TAB>  <TAB>  <TAB> self.write(f"" {opt.val}"")",if i > 0 :,90
4117,"def is_child_of(self, item_hash, possible_child_hash): <TAB> if self.get_last(item_hash) != self.get_last(possible_child_hash): <TAB>  <TAB> return None <TAB> while True: <TAB>  <TAB> if possible_child_hash == item_hash: <TAB>  <TAB>  <TAB> return True <MASK> return False <TAB>  <TAB> possible_child_hash = self.items[possible_child_hash].previous_hash",if possible_child_hash not in self . items :,119
4118,"def __call__(self, text, **kargs): <TAB> words = jieba.tokenize(text, mode=""search"") <TAB> token = Token() <TAB> for (w, start_pos, stop_pos) in words: <MASK> continue <TAB>  <TAB> token.original = token.text = w <TAB>  <TAB> token.pos = start_pos <TAB>  <TAB> token.startchar = start_pos <TAB>  <TAB> token.endchar = stop_pos <TAB>  <TAB> yield token",if not accepted_chars . match ( w ) and len ( w ) <= 1 :,123
4119,"def test_analysis_jobs_cypher_syntax(neo4j_session): <TAB> parameters = { <TAB>  <TAB> ""AWS_ID"": None, <TAB>  <TAB> ""UPDATE_TAG"": None, <TAB>  <TAB> ""OKTA_ORG_ID"": None, <TAB> } <TAB> for job_name in contents(""cartography.data.jobs.analysis""): <MASK> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> cartography.util.run_analysis_job(job_name, neo4j_session, parameters) <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> pytest.fail( <TAB>  <TAB>  <TAB>  <TAB> f""run_analysis_job failed for analysis job '{job_name}' with exception: {e}"" <TAB>  <TAB>  <TAB> )","if not job_name . endswith ( "".json"" ) :",180
4120,"def _interleave_dataset_results_and_tensors(dataset_results, flat_run_tensors): <TAB> flattened_results = [] <TAB> for idx in range(len(dataset_results) + len(flat_run_tensors)): <MASK> flattened_results.append(dataset_results[idx]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> flattened_results.append(flat_run_tensors.pop(0)) <TAB> return flattened_results",if dataset_results . get ( idx ) :,111
4121,"def test_k_is_stochastic_parameter(self): <TAB> # k as stochastic parameter <TAB> aug = iaa.MedianBlur(k=iap.Choice([3, 5])) <TAB> seen = [False, False] <TAB> for i in sm.xrange(100): <TAB>  <TAB> observed = aug.augment_image(self.base_img) <MASK> seen[0] += True <TAB>  <TAB> elif np.array_equal(observed, self.blur5x5): <TAB>  <TAB>  <TAB> seen[1] += True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception(""Unexpected result in MedianBlur@2"") <TAB>  <TAB> if all(seen): <TAB>  <TAB>  <TAB> break <TAB> assert np.all(seen)","if np . array_equal ( observed , self . blur3x3 ) :",176
4122,"def pickPath(self, color): <TAB> self.path[color] = () <TAB> currentPos = self.starts[color] <TAB> while True: <TAB>  <TAB> minDist = None <TAB>  <TAB> minGuide = None <TAB>  <TAB> for guide in self.guides[color]: <TAB>  <TAB>  <TAB> guideDist = dist(currentPos, guide) <TAB>  <TAB>  <TAB> if minDist == None or guideDist < minDist: <TAB>  <TAB>  <TAB>  <TAB> minDist = guideDist <TAB>  <TAB>  <TAB>  <TAB> minGuide = guide <TAB>  <TAB> if dist(currentPos, self.ends[color]) == 1: <TAB>  <TAB>  <TAB> return <MASK> return <TAB>  <TAB> self.path[color] = self.path[color] + (minGuide,) <TAB>  <TAB> currentPos = minGuide <TAB>  <TAB> self.guides[color].remove(minGuide)",if minGuide == None :,192
4123,"def UpdateRepository(self): <TAB> if hasattr(self, ""commit_update""): <MASK> if not path.isdir("".git/""): <TAB>  <TAB>  <TAB>  <TAB> self.gitZipRepo() <TAB>  <TAB>  <TAB> call([""git"", ""reset"", ""--hard"", ""origin/{}"".format(self.getBranch)]) <TAB>  <TAB>  <TAB> self.ProcessCall_([""git"", ""pull"", ""origin"", self.getBranch]) <TAB>  <TAB>  <TAB> self.ProcessCall_([""pip"", ""install"", ""-r"", ""requirements.txt""])","if self . commit_update [ ""Updates"" ] != [ ] :",126
4124,"def callback(result=Cr.NS_OK, message=None, success=None): <TAB> if success is None: <MASK> success = Ci.koIAsyncCallback.RESULT_SUCCESSFUL <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> success = Ci.koIAsyncCallback.RESULT_ERROR <TAB> data = Namespace(result=result, message=message, _com_interfaces_=[Ci.koIErrorInfo]) <TAB> self._invoke_activate_callbacks(success, data)",if Cr . NS_SUCCEEDED ( result ) :,121
4125,"def get_location(device): <TAB> location = [] <TAB> node = device <TAB> while node: <TAB>  <TAB> position = node.get_position() or """" <MASK> position = "" [%s]"" % position <TAB>  <TAB> location.append(node.name + position) <TAB>  <TAB> node = node.parent <TAB> return "" / "".join(reversed(location))",if position :,87
4126,"def load_checkpoint(path, model, optimizer, reset_optimizer): <TAB> global global_step <TAB> global global_epoch <TAB> print(""Load checkpoint from: {}"".format(path)) <TAB> checkpoint = _load(path) <TAB> model.load_state_dict(checkpoint[""state_dict""]) <TAB> if not reset_optimizer: <TAB>  <TAB> optimizer_state = checkpoint[""optimizer""] <MASK> print(""Load optimizer state from {}"".format(path)) <TAB>  <TAB>  <TAB> optimizer.load_state_dict(checkpoint[""optimizer""]) <TAB> global_step = checkpoint[""global_step""] <TAB> global_epoch = checkpoint[""global_epoch""] <TAB> return model",if optimizer_state is not None :,155
4127,"def run_command(self, command: str, data: Dict[str, object]) -> Dict[str, object]: <TAB> """"""Run a specific command from the registry."""""" <TAB> key = ""cmd_"" + command <TAB> method = getattr(self.__class__, key, None) <TAB> if method is None: <TAB>  <TAB> return {""error"": ""Unrecognized command '%s'"" % command} <TAB> else: <MASK> # Only the above commands use some error formatting. <TAB>  <TAB>  <TAB> del data[""is_tty""] <TAB>  <TAB>  <TAB> del data[""terminal_width""] <TAB>  <TAB> return method(self, **data)","if command not in { ""check"" , ""recheck"" , ""run"" } :",151
4128,"def call_init(self, node, instance): <TAB> # Call __init__ on each binding. <TAB> for b in instance.bindings: <MASK> continue <TAB>  <TAB> self._initialized_instances.add(b.data) <TAB>  <TAB> node = self._call_init_on_binding(node, b) <TAB> return node",if b . data in self . _initialized_instances :,89
4129,"def get_request_headers() -> Dict: <TAB> url = urlparse(uri) <TAB> candidates = [ <TAB>  <TAB> ""%s://%s"" % (url.scheme, url.netloc), <TAB>  <TAB> ""%s://%s/"" % (url.scheme, url.netloc), <TAB>  <TAB> uri, <TAB>  <TAB> ""*"", <TAB> ] <TAB> for u in candidates: <MASK> headers = dict(DEFAULT_REQUEST_HEADERS) <TAB>  <TAB>  <TAB> headers.update(self.config.linkcheck_request_headers[u]) <TAB>  <TAB>  <TAB> return headers <TAB> return {}",if u in self . config . linkcheck_request_headers :,142
4130,"def get_next_video_frame(self, skip_empty_frame=True): <TAB> if not self.video_format: <TAB>  <TAB> return <TAB> while True: <TAB>  <TAB> # We skip video packets which are not video frames <TAB>  <TAB> # This happens in mkv files for the first few frames. <TAB>  <TAB> video_packet = self._get_video_packet() <TAB>  <TAB> if video_packet.image == 0: <TAB>  <TAB>  <TAB> self._decode_video_packet(video_packet) <MASK> break <TAB> if _debug: <TAB>  <TAB> print(""Returning"", video_packet) <TAB> return video_packet.image",if video_packet . image is not None or not skip_empty_frame :,162
4131,"def convert_path(ctx, tpath): <TAB> for points, code in tpath.iter_segments(): <TAB>  <TAB> if code == Path.MOVETO: <TAB>  <TAB>  <TAB> ctx.move_to(*points) <TAB>  <TAB> elif code == Path.LINETO: <TAB>  <TAB>  <TAB> ctx.line_to(*points) <MASK> ctx.curve_to( <TAB>  <TAB>  <TAB>  <TAB> points[0], points[1], points[0], points[1], points[2], points[3] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> elif code == Path.CURVE4: <TAB>  <TAB>  <TAB> ctx.curve_to(*points) <TAB>  <TAB> elif code == Path.CLOSEPOLY: <TAB>  <TAB>  <TAB> ctx.close_path()",elif code == Path . CURVE3 :,172
4132,"def __init__( <TAB> self, layout, value=None, string=None, *, dtype: np.dtype = np.float64) -> None: <TAB> """"""Constructor."""""" <TAB> self.layout = layout <TAB> if value is None: <TAB>  <TAB> if string is None: <TAB>  <TAB>  <TAB> self.value = np.zeros((self.layout.gaDims,), dtype=dtype) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.value = layout.parse_multivector(string).value <TAB> else: <TAB>  <TAB> self.value = np.array(value) <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""value must be a sequence of length %s"" % self.layout.gaDims <TAB>  <TAB>  <TAB> )","if self . value . shape != ( self . layout . gaDims , ) :",180
4133,"def to_dict(self): <TAB> contexts_ = {} <TAB> for k, data in self.contexts.items(): <TAB>  <TAB> data_ = data.copy() <TAB>  <TAB> if ""context"" in data_: <TAB>  <TAB>  <TAB> del data_[""context""] <MASK> del data_[""loaded""] <TAB>  <TAB> contexts_[k] = data_ <TAB> return dict(contexts=contexts_)","if ""loaded"" in data_ :",94
4134,"def include_module(module): <TAB> if not include_these: <TAB>  <TAB> return True <TAB> result = False <TAB> for check in include_these: <TAB>  <TAB> if ""/*"" in check: <MASK> result = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if (os.getcwd() + ""/"" + check + "".py"") == module: <TAB>  <TAB>  <TAB>  <TAB> result = True <TAB> if result: <TAB>  <TAB> print_status(""Including module: "" + module) <TAB> return result",if check [ : - 1 ] in module :,122
4135,"def extract_from(msg_body, content_type=""text/plain""): <TAB> try: <TAB>  <TAB> if content_type == ""text/plain"": <TAB>  <TAB>  <TAB> return extract_from_plain(msg_body) <MASK> return extract_from_html(msg_body) <TAB> except Exception: <TAB>  <TAB> log.exception(""ERROR extracting message"") <TAB> return msg_body","elif content_type == ""text/html"" :",100
4136,"def test_list(self): <TAB> self._create_locations() <TAB> response = self.client.get(self.geojson_boxedlocation_list_url) <TAB> self.assertEqual(response.status_code, 200) <TAB> self.assertEqual(len(response.data[""features""]), 2) <TAB> for feature in response.data[""features""]: <TAB>  <TAB> self.assertIn(""bbox"", feature) <TAB>  <TAB> fid = feature[""id""] <MASK> self.assertEqual(feature[""bbox""], self.bl1.bbox_geometry.extent) <TAB>  <TAB> elif fid == 2: <TAB>  <TAB>  <TAB> self.assertEqual(feature[""bbox""], self.bl2.bbox_geometry.extent) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.fail(""Unexpected id: {0}"".format(fid)) <TAB> BoxedLocation.objects.all().delete()",if fid == 1 :,196
4137,"def overrideCommand(self, commandName, func): <TAB> # Override entries in c.k.masterBindingsDict <TAB> k = self <TAB> d = k.masterBindingsDict <TAB> for key in d: <TAB>  <TAB> d2 = d.get(key) <TAB>  <TAB> for key2 in d2: <TAB>  <TAB>  <TAB> bi = d2.get(key2) <MASK> bi.func = func <TAB>  <TAB>  <TAB>  <TAB> d2[key2] = bi",if bi . commandName == commandName :,118
4138,"def _lookup(components, specs, provided, name, i, l): <TAB> if i < l: <TAB>  <TAB> for spec in specs[i].__sro__: <TAB>  <TAB>  <TAB> comps = components.get(spec) <MASK> r = _lookup(comps, specs, provided, name, i + 1, l) <TAB>  <TAB>  <TAB>  <TAB> if r is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return r <TAB> else: <TAB>  <TAB> for iface in provided: <TAB>  <TAB>  <TAB> comps = components.get(iface) <TAB>  <TAB>  <TAB> if comps: <TAB>  <TAB>  <TAB>  <TAB> r = comps.get(name) <TAB>  <TAB>  <TAB>  <TAB> if r is not None: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return r <TAB> return None",if comps :,166
4139,"def to_representation(self, value): <TAB> old_social_string_fields = [""twitter"", ""github"", ""linkedIn""] <TAB> request = self.context.get(""request"") <TAB> show_old_format = ( <TAB>  <TAB> request <TAB>  <TAB> and is_deprecated(request.version, self.min_version) <TAB>  <TAB> and request.method == ""GET"" <TAB> ) <TAB> if show_old_format: <TAB>  <TAB> social = value.copy() <TAB>  <TAB> for key in old_social_string_fields: <TAB>  <TAB>  <TAB> if social.get(key): <TAB>  <TAB>  <TAB>  <TAB> social[key] = value[key][0] <MASK> social[key] = """" <TAB>  <TAB> value = social <TAB> return super(SocialField, self).to_representation(value)",elif social . get ( key ) == [ ] :,200
4140,"def process_ref_attribute(self, node, array_type=None): <TAB> ref = qname_attr(node, ""ref"") <TAB> if ref: <TAB>  <TAB> ref = self._create_qname(ref) <TAB>  <TAB> # Some wsdl's reference to xs:schema, we ignore that for now. It <TAB>  <TAB> # might be better in the future to process the actual schema file <TAB>  <TAB> # so that it is handled correctly <MASK> return <TAB>  <TAB> return xsd_elements.RefAttribute( <TAB>  <TAB>  <TAB> node.tag, ref, self.schema, array_type=array_type <TAB>  <TAB> )","if ref . namespace == ""http://www.w3.org/2001/XMLSchema"" :",161
4141,"def unescape(text): <TAB> """"""Removes '\\' escaping from 'text'."""""" <TAB> rv = """" <TAB> i = 0 <TAB> while i < len(text): <MASK> rv += text[i + 1] <TAB>  <TAB>  <TAB> i += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> rv += text[i] <TAB>  <TAB> i += 1 <TAB> return rv","if i + 1 < len ( text ) and text [ i ] == ""\\"" :",99
4142,"def wait_child_process(signum, frame): <TAB> try: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> child_pid, status = os.waitpid(-1, os.WNOHANG) <TAB>  <TAB>  <TAB> if child_pid == 0: <TAB>  <TAB>  <TAB>  <TAB> stat_logger.info(""no child process was immediately available"") <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> exitcode = status >> 8 <TAB>  <TAB>  <TAB> stat_logger.info( <TAB>  <TAB>  <TAB>  <TAB> ""child process %s exit with exitcode %s"", child_pid, exitcode <TAB>  <TAB>  <TAB> ) <TAB> except OSError as e: <MASK> stat_logger.warning( <TAB>  <TAB>  <TAB>  <TAB> ""current process has no existing unwaited-for child processes."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise",if e . errno == errno . ECHILD :,190
4143,"def translate_from_sortname(name, sortname): <TAB> """"""'Translate' the artist name by reversing the sortname."""""" <TAB> for c in name: <TAB>  <TAB> ctg = unicodedata.category(c) <TAB>  <TAB> if ctg[0] == ""L"" and unicodedata.name(c).find(""LATIN"") == -1: <TAB>  <TAB>  <TAB> for separator in ("" & "", ""; "", "" and "", "" vs. "", "" with "", "" y ""): <MASK> parts = sortname.split(separator) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> parts = [sortname] <TAB>  <TAB>  <TAB>  <TAB> separator = """" <TAB>  <TAB>  <TAB> return separator.join(map(_reverse_sortname, parts)) <TAB> return name",if separator in sortname :,181
4144,"def python_value(self, value): <TAB> if value: <MASK> pp = lambda x: x.time() <TAB>  <TAB>  <TAB> return format_date_time(value, self.formats, pp) <TAB>  <TAB> elif isinstance(value, datetime.datetime): <TAB>  <TAB>  <TAB> return value.time() <TAB> if value is not None and isinstance(value, datetime.timedelta): <TAB>  <TAB> return (datetime.datetime.min + value).time() <TAB> return value","if isinstance ( value , basestring ) :",113
4145,"def __init__(self, fileobj, info): <TAB> pages = [] <TAB> complete = False <TAB> while not complete: <TAB>  <TAB> page = OggPage(fileobj) <MASK> pages.append(page) <TAB>  <TAB>  <TAB> complete = page.complete or (len(page.packets) > 1) <TAB> data = OggPage.to_packets(pages)[0][7:] <TAB> super(OggTheoraCommentDict, self).__init__(data, framing=False) <TAB> self._padding = len(data) - self._size",if page . serial == info . serial :,133
4146,"def configure(self): <TAB> # hack to configure 'from_' and 'to' and avoid exception <TAB> if ""from_"" in self.wmeta.properties: <TAB>  <TAB> from_ = float(self.wmeta.properties[""from_""]) <TAB>  <TAB> to = float(self.wmeta.properties.get(""to"", 0)) <MASK> to = from_ + 1 <TAB>  <TAB>  <TAB> self.wmeta.properties[""to""] = str(to) <TAB> super(TKSpinbox, self).configure()",if from_ > to :,123
4147,"def get_error_diagnostics(self): <TAB> diagnostics = [] <TAB> if self.stdout is not None: <TAB>  <TAB> with open(self.stdout.name) as fds: <TAB>  <TAB>  <TAB> contents = fds.read().strip() <MASK> diagnostics.append(""ab STDOUT:\n"" + contents) <TAB> if self.stderr is not None: <TAB>  <TAB> with open(self.stderr.name) as fds: <TAB>  <TAB>  <TAB> contents = fds.read().strip() <TAB>  <TAB>  <TAB> if contents.strip(): <TAB>  <TAB>  <TAB>  <TAB> diagnostics.append(""ab STDERR:\n"" + contents) <TAB> return diagnostics",if contents . strip ( ) :,156
4148,"def set_environment_vars(env, source_env): <TAB> """"""Copy allowed environment variables from |source_env|."""""" <TAB> if not source_env: <TAB>  <TAB> return <TAB> for name, value in six.iteritems(source_env): <MASK> # Avoid creating circular dependencies from importing environment by <TAB>  <TAB>  <TAB> # using os.getenv. <TAB>  <TAB>  <TAB> if os.getenv(""TRUSTED_HOST"") and should_rebase_environment_value(name): <TAB>  <TAB>  <TAB>  <TAB> value = file_host.rebase_to_worker_root(value) <TAB>  <TAB>  <TAB> env[name] = value",if is_forwarded_environment_variable ( name ) :,152
4149,"def update_content(self, more_content: StringList) -> None: <TAB> if isinstance(self.object, TypeVar): <TAB>  <TAB> attrs = [repr(self.object.__name__)] <TAB>  <TAB> for constraint in self.object.__constraints__: <TAB>  <TAB>  <TAB> attrs.append(stringify_typehint(constraint)) <TAB>  <TAB> if self.object.__covariant__: <TAB>  <TAB>  <TAB> attrs.append(""covariant=True"") <MASK> attrs.append(""contravariant=True"") <TAB>  <TAB> more_content.append(_(""alias of TypeVar(%s)"") % "", "".join(attrs), """") <TAB>  <TAB> more_content.append("""", """") <TAB> super().update_content(more_content)",if self . object . __contravariant__ :,160
4150,"def after(self, event, state): <TAB> group = event.group <TAB> for plugin in self.get_plugins(): <MASK> continue <TAB>  <TAB> metrics.incr(""notifications.sent"", instance=plugin.slug) <TAB>  <TAB> yield self.future(plugin.rule_notify)","if not safe_execute ( plugin . should_notify , group = group , event = event ) :",87
4151,"def distinct(expr, *on): <TAB> fields = frozenset(expr.fields) <TAB> _on = [] <TAB> append = _on.append <TAB> for n in on: <TAB>  <TAB> if isinstance(n, Field): <MASK> n = n._name <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""{0} is not a field of {1}"".format(n, expr)) <TAB>  <TAB> if not isinstance(n, _strtypes): <TAB>  <TAB>  <TAB> raise TypeError(""on must be a name or field, not: {0}"".format(n)) <TAB>  <TAB> elif n not in fields: <TAB>  <TAB>  <TAB> raise ValueError(""{0} is not a field of {1}"".format(n, expr)) <TAB>  <TAB> append(n) <TAB> return Distinct(expr, tuple(_on))",if n . _child . isidentical ( expr ) :,192
4152,"def build_filter(arg): <TAB> filt = {} <TAB> if arg is not None: <MASK> raise UserError(""Arguments to --filter should be in form KEY=VAL"") <TAB>  <TAB> key, val = arg.split(""="", 1) <TAB>  <TAB> filt[key] = val <TAB> return filt","if ""="" not in arg :",75
4153,"def pickline(file, key, casefold=1): <TAB> try: <TAB>  <TAB> f = open(file, ""r"") <TAB> except IOError: <TAB>  <TAB> return None <TAB> pat = re.escape(key) + "":"" <TAB> prog = re.compile(pat, casefold and re.IGNORECASE) <TAB> while 1: <TAB>  <TAB> line = f.readline() <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB> break <MASK> text = line[len(key) + 1 :] <TAB>  <TAB>  <TAB> while 1: <TAB>  <TAB>  <TAB>  <TAB> line = f.readline() <TAB>  <TAB>  <TAB>  <TAB> if not line or not line[0].isspace(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB>  <TAB> text = text + line <TAB>  <TAB>  <TAB> return text.strip() <TAB> return None",if prog . match ( line ) :,182
4154,"def delete_doc(elastic_document_id, node, index=None, category=None): <TAB> index = index or INDEX <TAB> if not category: <MASK> category = ""preprint"" <TAB>  <TAB> elif node.is_registration: <TAB>  <TAB>  <TAB> category = ""registration"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> category = node.project_or_component <TAB> client().delete( <TAB>  <TAB> index=index, <TAB>  <TAB> doc_type=category, <TAB>  <TAB> id=elastic_document_id, <TAB>  <TAB> refresh=True, <TAB>  <TAB> ignore=[404], <TAB> )","if isinstance ( node , Preprint ) :",143
4155,"def update(self, preds, labels): <TAB> if not _is_numpy_(labels): <TAB>  <TAB> raise ValueError(""The 'labels' must be a numpy ndarray."") <TAB> if not _is_numpy_(preds): <TAB>  <TAB> raise ValueError(""The 'predictions' must be a numpy ndarray."") <TAB> for i, lbl in enumerate(labels): <TAB>  <TAB> value = preds[i, 1] <TAB>  <TAB> bin_idx = int(value * self._num_thresholds) <TAB>  <TAB> assert bin_idx <= self._num_thresholds <MASK> self._stat_pos[bin_idx] += 1.0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._stat_neg[bin_idx] += 1.0",if lbl :,163
4156,"def checkStatusClient(self): <TAB> if str(self.comboxBoxIPAddress.currentText()) != """": <MASK> self.btnEnable.setEnabled(False) <TAB>  <TAB>  <TAB> self.btncancel.setEnabled(True) <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> self.btnEnable.setEnabled(True) <TAB>  <TAB> self.btncancel.setEnabled(False)","if self . ClientsLogged [ str ( self . comboxBoxIPAddress . currentText ( ) ) ] [ ""Status"" ] :",111
4157,"def colorizeDiffs(sheet, col, row, cellval): <TAB> if not row or not col: <TAB>  <TAB> return None <TAB> vcolidx = sheet.visibleCols.index(col) <TAB> rowidx = sheet.rows.index(row) <TAB> if vcolidx < len(othersheet.visibleCols) and rowidx < len(othersheet.rows): <TAB>  <TAB> otherval = othersheet.visibleCols[vcolidx].getDisplayValue( <TAB>  <TAB>  <TAB> othersheet.rows[rowidx] <TAB>  <TAB> ) <MASK> return ""color_diff"" <TAB> else: <TAB>  <TAB> return ""color_diff_add""",if cellval . display != otherval :,162
4158,"def identwaf(self, findall=False): <TAB> detected = list() <TAB> try: <TAB>  <TAB> self.attackres = self.performCheck(self.centralAttack) <TAB> except RequestBlocked: <TAB>  <TAB> return detected <TAB> for wafvendor in self.checklist: <TAB>  <TAB> self.log.info(""Checking for %s"" % wafvendor) <MASK> detected.append(wafvendor) <TAB>  <TAB>  <TAB> if not findall: <TAB>  <TAB>  <TAB>  <TAB> break <TAB> self.knowledge[""wafname""] = detected <TAB> return detected",if self . wafdetections [ wafvendor ] ( self ) :,143
4159,"def get_repository_metadata_by_repository_id_changeset_revision( <TAB> app, id, changeset_revision, metadata_only=False): <TAB> """"""Get a specified metadata record for a specified repository in the tool shed."""""" <TAB> if metadata_only: <TAB>  <TAB> repository_metadata = get_repository_metadata_by_changeset_revision( <TAB>  <TAB>  <TAB> app, id, changeset_revision <TAB>  <TAB> ) <MASK> return repository_metadata.metadata <TAB>  <TAB> return None <TAB> return get_repository_metadata_by_changeset_revision(app, id, changeset_revision)",if repository_metadata and repository_metadata . metadata :,145
4160,"def getmultiline(self): <TAB> line = self.getline() <TAB> if line[3:4] == ""-"": <TAB>  <TAB> code = line[:3] <TAB>  <TAB> while 1: <TAB>  <TAB>  <TAB> nextline = self.getline() <TAB>  <TAB>  <TAB> line = line + (""\n"" + nextline) <MASK> break <TAB> return line","if nextline [ : 3 ] == code and nextline [ 3 : 4 ] != ""-"" :",100
4161,"def _validate_reports(value, *args, **kwargs): <TAB> from osf.models import OSFUser <TAB> for key, val in value.items(): <TAB>  <TAB> if not OSFUser.load(key): <TAB>  <TAB>  <TAB> raise ValidationValueError(""Keys must be user IDs"") <MASK> raise ValidationTypeError(""Values must be dictionaries"") <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB> ""category"" not in val <TAB>  <TAB>  <TAB> or ""text"" not in val <TAB>  <TAB>  <TAB> or ""date"" not in val <TAB>  <TAB>  <TAB> or ""retracted"" not in val <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> raise ValidationValueError( <TAB>  <TAB>  <TAB>  <TAB> (""Values must include `date`, `category`, "", ""`text`, `retracted` keys"") <TAB>  <TAB>  <TAB> )","if not isinstance ( val , dict ) :",179
4162,"def deselectItem(self, item): <TAB> if self.isSelected(item): <MASK> listItem = self._getListItem(item) <TAB>  <TAB>  <TAB> selections = self.getSelectedItems() <TAB>  <TAB>  <TAB> selections.remove(self.loadHandler.getSelection(listItem)) <TAB>  <TAB>  <TAB> self.setSelections(selections) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.deselectAll()",if self . multiSelect :,101
4163,"def __init__(self, **kwargs): <TAB> if self.name is None: <TAB>  <TAB> raise RuntimeError(""RenderPrimitive cannot be used directly"") <TAB> self.option_values = {} <TAB> for key, val in kwargs.items(): <TAB>  <TAB> if not key in self.options: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""primitive `{0}' has no option `{1}'"".format(self.name, key) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self.option_values[key] = val <TAB> # set up defaults <TAB> for name, (description, default) in self.options.items(): <MASK> self.option_values[name] = default",if not name in self . option_values :,162
4164,"def setup_smart_indent(self, view, lang): <TAB> # Configure a ""per-view"" instance <TAB> if type(view) == gedit.View: <MASK> setattr(view, ""smart_indent_instance"", SmartIndent()) <TAB>  <TAB>  <TAB> handler_id = view.connect( <TAB>  <TAB>  <TAB>  <TAB> ""key-press-event"", view.smart_indent_instance.key_press_handler <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.handler_ids.append((handler_id, view)) <TAB>  <TAB> view.smart_indent_instance.set_language(lang, view)","if getattr ( view , ""smart_indent_instance"" , False ) == False :",157
4165,"def get_strings_of_set(word, char_set, threshold=20): <TAB> count = 0 <TAB> letters = """" <TAB> strings = [] <TAB> for char in word: <MASK> letters += char <TAB>  <TAB>  <TAB> count += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if count > threshold: <TAB>  <TAB>  <TAB>  <TAB> strings.append(letters) <TAB>  <TAB>  <TAB> letters = """" <TAB>  <TAB>  <TAB> count = 0 <TAB> if count > threshold: <TAB>  <TAB> strings.append(letters) <TAB> return strings",if char in char_set :,125
4166,"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_logout_url(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,92
4167,def __create_table(self): <TAB> for i in range(256): <TAB>  <TAB> crcreg = i <TAB>  <TAB> for j in range(8): <MASK> crcreg = self.__CRCPOLYNOMIAL ^ (crcreg >> 1) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> crcreg >>= 1 <TAB>  <TAB> self.__crctable[i] = crcreg,if ( crcreg & 1 ) != 0 :,100
4168,"def destroy(self): <TAB> """"""Flush all entries and empty cache"""""" <TAB> # Note: this method is currently also used for dropping the cache <TAB> for i in range(len(self.cached_rows)): <TAB>  <TAB> id_ = self.cached_rows[i] <TAB>  <TAB> self.cached_rows[i] = None <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> inode = self.attrs[id_] <TAB>  <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB>  <TAB> # We may have deleted that inode <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> del self.attrs[id_] <TAB>  <TAB>  <TAB>  <TAB> self.setattr(inode) <TAB> assert len(self.attrs) == 0",if id_ is not None :,167
4169,"def set_config(self): <TAB> """"""Set configuration options for QTextEdit."""""" <TAB> c = self.c <TAB> w = self.widget <TAB> w.setWordWrapMode(QtGui.QTextOption.NoWrap) <TAB> if 0:  # This only works when there is no style sheet. <TAB>  <TAB> n = c.config.getInt(""qt-rich-text-zoom-in"") <MASK> w.zoomIn(n) <TAB>  <TAB>  <TAB> w.updateMicroFocus() <TAB> # tab stop in pixels - no config for this (yet) <TAB> w.setTabStopWidth(24)","if n not in ( None , 0 ) :",154
4170,"def mouseDragEvent(self, ev): <TAB> if self.movable and ev.button() == QtCore.Qt.LeftButton: <TAB>  <TAB> if ev.isStart(): <TAB>  <TAB>  <TAB> self.moving = True <TAB>  <TAB>  <TAB> self.cursorOffset = self.pos() - self.mapToParent(ev.buttonDownPos()) <TAB>  <TAB>  <TAB> self.startPosition = self.pos() <TAB>  <TAB> ev.accept() <TAB>  <TAB> if not self.moving: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> self.setPos(self.cursorOffset + self.mapToParent(ev.pos())) <TAB>  <TAB> self.sigDragged.emit(self) <MASK> self.moving = False <TAB>  <TAB>  <TAB> self.sigPositionChangeFinished.emit(self)",if ev . isFinish ( ) :,178
4171,"def reparentChildren(self, newParent): <TAB> if newParent.childNodes: <TAB>  <TAB> newParent.childNodes[-1]._element.tail += self._element.text <TAB> else: <TAB>  <TAB> if not newParent._element.text: <TAB>  <TAB>  <TAB> newParent._element.text = """" <MASK> newParent._element.text += self._element.text <TAB> self._element.text = """" <TAB> base.Node.reparentChildren(self, newParent)",if self . _element . text is not None :,121
4172,"def _no_sp_or_bp(self, bl): <TAB> for s in bl.vex.statements: <TAB>  <TAB> for e in chain([s], s.expressions): <MASK> reg = self.get_reg_name(self.project.arch, e.offset) <TAB>  <TAB>  <TAB>  <TAB> if reg == ""ebp"" or reg == ""esp"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB>  <TAB> elif e.tag == ""Ist_Put"": <TAB>  <TAB>  <TAB>  <TAB> reg = self.get_reg_name(self.project.arch, e.offset) <TAB>  <TAB>  <TAB>  <TAB> if reg == ""ebp"" or reg == ""esp"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return True","if e . tag == ""Iex_Get"" :",176
4173,"def _get_import_chain(self, *, until=None): <TAB> stack = inspect.stack()[2:] <TAB> try: <TAB>  <TAB> for frameinfo in stack: <TAB>  <TAB>  <TAB> try: <MASK> continue <TAB>  <TAB>  <TAB>  <TAB> data = dedent("""".join(frameinfo.code_context)) <TAB>  <TAB>  <TAB>  <TAB> if data.strip() == until: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise StopIteration <TAB>  <TAB>  <TAB>  <TAB> yield frameinfo.filename, frameinfo.lineno, data.strip() <TAB>  <TAB>  <TAB>  <TAB> del data <TAB>  <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB>  <TAB> del frameinfo <TAB> finally: <TAB>  <TAB> del stack",if not frameinfo . code_context :,155
4174,"def stream_docker_log(log_stream): <TAB> async for line in log_stream: <TAB>  <TAB> if ""stream"" in line and line[""stream""].strip(): <TAB>  <TAB>  <TAB> logger.debug(line[""stream""].strip()) <TAB>  <TAB> elif ""status"" in line: <TAB>  <TAB>  <TAB> logger.debug(line[""status""].strip()) <MASK> logger.error(line[""error""].strip()) <TAB>  <TAB>  <TAB> raise DockerBuildError","elif ""error"" in line :",108
4175,"def get_cycle_path(self, curr_node, goal_node_index): <TAB> for dep in curr_node[""deps""]: <TAB>  <TAB> if dep == goal_node_index: <TAB>  <TAB>  <TAB> return [curr_node[""address""]] <TAB> for dep in curr_node[""deps""]: <TAB>  <TAB> path = self.get_cycle_path( <TAB>  <TAB>  <TAB> self.get_by_address(dep), goal_node_index <TAB>  <TAB> )  # self.nodelist[dep], goal_node_index) <MASK> path.insert(0, curr_node[""address""]) <TAB>  <TAB>  <TAB> return path <TAB> return []",if len ( path ) > 0 :,153
4176,"def prompt(default=None): <TAB> editor = ""nano"" <TAB> with tempfile.NamedTemporaryFile(mode=""r+"") as tmpfile: <MASK> tmpfile.write(default) <TAB>  <TAB>  <TAB> tmpfile.flush() <TAB>  <TAB> child_pid = os.fork() <TAB>  <TAB> is_child = child_pid == 0 <TAB>  <TAB> if is_child: <TAB>  <TAB>  <TAB> os.execvp(editor, [editor, tmpfile.name]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> os.waitpid(child_pid, 0) <TAB>  <TAB>  <TAB> tmpfile.seek(0) <TAB>  <TAB>  <TAB> return tmpfile.read().strip()",if default :,143
4177,"def _get_annotated_template(self, template): <TAB> changed = False <TAB> if template.get(""version"", ""0.12.0"") >= ""0.13.0"": <TAB>  <TAB> using_js = self.spider._filter_js_urls(template[""url""]) <TAB>  <TAB> body = ""rendered_body"" if using_js else ""original_body"" <MASK> template[""body""] = body <TAB>  <TAB>  <TAB> changed = True <TAB> if changed or not template.get(""annotated""): <TAB>  <TAB> _build_sample(template) <TAB> return template","if template . get ( ""body"" ) != body :",139
4178,"def collect(self, paths): <TAB> for path in paths or (): <TAB>  <TAB> relpath = os.path.relpath(path, self._artifact_root) <TAB>  <TAB> dst = os.path.join(self._directory, relpath) <TAB>  <TAB> safe_mkdir(os.path.dirname(dst)) <MASK> shutil.copytree(path, dst) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> shutil.copy(path, dst) <TAB>  <TAB> self._relpaths.add(relpath)",if os . path . isdir ( path ) :,120
4179,"def dependencies(context=None): <TAB> """"""Return all dependencies detected by knowit."""""" <TAB> deps = OrderedDict([]) <TAB> try: <TAB>  <TAB> initialize(context) <TAB>  <TAB> for name, provider_cls in _provider_map.items(): <MASK> deps[name] = available_providers[name].version <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> deps[name] = {} <TAB> except Exception: <TAB>  <TAB> pass <TAB> return deps",if name in available_providers :,111
4180,"def _getaddrinfo(self, host_bytes, port, family, socktype, proto, flags): <TAB> while True: <TAB>  <TAB> ares = self.cares <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self.__getaddrinfo(host_bytes, port, family, socktype, proto, flags) <TAB>  <TAB> except gaierror: <MASK> raise",if ares is self . cares :,96
4181,"def write_entries(cmd, basename, filename): <TAB> ep = cmd.distribution.entry_points <TAB> if isinstance(ep, basestring) or ep is None: <TAB>  <TAB> data = ep <TAB> elif ep is not None: <TAB>  <TAB> data = [] <TAB>  <TAB> for section, contents in ep.items(): <MASK> contents = EntryPoint.parse_group(section, contents) <TAB>  <TAB>  <TAB>  <TAB> contents = ""\n"".join(map(str, contents.values())) <TAB>  <TAB>  <TAB> data.append(""[%s]\n%s\n\n"" % (section, contents)) <TAB>  <TAB> data = """".join(data) <TAB> cmd.write_or_delete_file(""entry points"", filename, data, True)","if not isinstance ( contents , basestring ) :",174
4182,"def _highlight_do(self): <TAB> new_hl_text = self.highlight_text.text() <TAB> if new_hl_text != self.hl_text: <TAB>  <TAB> self.hl_text = new_hl_text <TAB>  <TAB> if self.hl is not None: <TAB>  <TAB>  <TAB> self.hl.setDocument(None) <TAB>  <TAB>  <TAB> self.hl = None <MASK> self.hl = Highlighter(self.hl_text, parent=self.doc) <TAB>  <TAB> self.clear_highlight_button.setEnabled(bool(self.hl))",if self . hl_text :,151
4183,"def traverse(node, functions=[]): <TAB> if hasattr(node, ""grad_fn""): <TAB>  <TAB> node = node.grad_fn <TAB> if hasattr(node, ""variable""): <TAB>  <TAB> node = graph.nodes_by_id.get(id(node.variable)) <MASK> node.functions = list(functions) <TAB>  <TAB>  <TAB> del functions[:] <TAB> if hasattr(node, ""next_functions""): <TAB>  <TAB> functions.append(type(node).__name__) <TAB>  <TAB> for f in node.next_functions: <TAB>  <TAB>  <TAB> if f[0]: <TAB>  <TAB>  <TAB>  <TAB> functions.append(type(f[0]).__name__) <TAB>  <TAB>  <TAB>  <TAB> traverse(f[0], functions) <TAB> if hasattr(node, ""saved_tensors""): <TAB>  <TAB> for t in node.saved_tensors: <TAB>  <TAB>  <TAB> traverse(t)",if node :,195
4184,"def compress(self, data_list): <TAB> if data_list: <TAB>  <TAB> page_id = data_list[1] <TAB>  <TAB> if page_id in EMPTY_VALUES: <MASK> return None <TAB>  <TAB>  <TAB> raise forms.ValidationError(self.error_messages[""invalid_page""]) <TAB>  <TAB> return Page.objects.get(pk=page_id) <TAB> return None",if not self . required :,98
4185,"def test_field_attr_existence(self): <TAB> for name, item in ast.__dict__.items(): <TAB>  <TAB> if self._is_ast_node(name, item): <TAB>  <TAB>  <TAB> if name == ""Index"": <TAB>  <TAB>  <TAB>  <TAB> # Index(value) just returns value now. <TAB>  <TAB>  <TAB>  <TAB> # The argument is required. <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> x = item() <MASK> self.assertEqual(type(x._fields), tuple)","if isinstance ( x , ast . AST ) :",122
4186,"def handle_starttag(self, tag, attrs): <TAB> if tag == ""base"": <TAB>  <TAB> self.base_url = dict(attrs).get(""href"") <TAB> if self.scan_tag(tag): <TAB>  <TAB> for attr, value in attrs: <TAB>  <TAB>  <TAB> if self.scan_attr(attr): <MASK> value = strip_html5_whitespace(value) <TAB>  <TAB>  <TAB>  <TAB> url = self.process_attr(value) <TAB>  <TAB>  <TAB>  <TAB> link = Link(url=url) <TAB>  <TAB>  <TAB>  <TAB> self.links.append(link) <TAB>  <TAB>  <TAB>  <TAB> self.current_link = link",if self . strip :,151
4187,"def _initialize_asset_map(cls): <TAB> # Generating a list of acceptable asset files reduces the possibility of <TAB> # path attacks. <TAB> cls._asset_name_to_path = {} <TAB> assets = os.listdir(ASSETS_PATH) <TAB> for asset in assets: <TAB>  <TAB> path = os.path.join(ASSETS_PATH, asset) <MASK> cls._asset_name_to_path[os.path.basename(path)] = path",if os . path . isfile ( path ) :,120
4188,"def dataReceived(self, data): <TAB> self.buf += data <TAB> if self._paused: <TAB>  <TAB> log.startLogging(sys.stderr) <TAB>  <TAB> log.msg(""dataReceived while transport paused!"") <TAB>  <TAB> self.transport.loseConnection() <TAB> else: <TAB>  <TAB> self.transport.write(data) <MASK> self.transport.loseConnection() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.pause()","if self . buf . endswith ( b""\n0\n"" ) :",114
4189,"def test_case_sensitive(self): <TAB> with support.EnvironmentVarGuard() as env: <TAB>  <TAB> env.unset(""PYTHONCASEOK"") <MASK> self.skipTest(""os.environ changes not reflected in "" ""_os.environ"") <TAB>  <TAB> loader = self.find_module() <TAB>  <TAB> self.assertIsNone(loader)","if b""PYTHONCASEOK"" in _bootstrap_external . _os . environ :",92
4190,"def manifest(self): <TAB> """"""The current manifest dictionary."""""" <TAB> if self.reload: <TAB>  <TAB> if not self.exists(self.manifest_path): <TAB>  <TAB>  <TAB> return {} <TAB>  <TAB> mtime = self.getmtime(self.manifest_path) <MASK> self._manifest = self.get_manifest() <TAB>  <TAB>  <TAB> self._mtime = mtime <TAB> return self._manifest",if self . _mtime is None or mtime > self . _mtime :,102
4191,"def test_named_parameters_and_constraints(self): <TAB> likelihood = gpytorch.likelihoods.GaussianLikelihood() <TAB> model = ExactGPModel(None, None, likelihood) <TAB> for name, _param, constraint in model.named_parameters_and_constraints(): <MASK> self.assertIsInstance(constraint, gpytorch.constraints.GreaterThan) <TAB>  <TAB> elif name == ""mean_module.constant"": <TAB>  <TAB>  <TAB> self.assertIsNone(constraint) <TAB>  <TAB> elif name == ""covar_module.raw_outputscale"": <TAB>  <TAB>  <TAB> self.assertIsInstance(constraint, gpytorch.constraints.Positive) <TAB>  <TAB> elif name == ""covar_module.base_kernel.raw_lengthscale"": <TAB>  <TAB>  <TAB> self.assertIsInstance(constraint, gpytorch.constraints.Positive)","if name == ""likelihood.noise_covar.raw_noise"" :",192
4192,"def process_plugin_result(name, result): <TAB> if result: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> jsonify(test=result) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> logger.exception( <TAB>  <TAB>  <TAB>  <TAB> ""Error while jsonifying settings from plugin {}, please contact the plugin author about this"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> name <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> else: <MASK> del result[""__enabled""] <TAB>  <TAB>  <TAB> data[name] = result","if ""__enabled"" in result :",129
4193,"def benchmarking(net, ctx, num_iteration, datashape=300, batch_size=64): <TAB> input_shape = (batch_size, 3) + (datashape, datashape) <TAB> data = mx.random.uniform(-1.0, 1.0, shape=input_shape, ctx=ctx, dtype=""float32"") <TAB> dryrun = 5 <TAB> for i in range(dryrun + num_iteration): <MASK> tic = time.time() <TAB>  <TAB> ids, scores, bboxes = net(data) <TAB>  <TAB> ids.asnumpy() <TAB>  <TAB> scores.asnumpy() <TAB>  <TAB> bboxes.asnumpy() <TAB> toc = time.time() - tic <TAB> return toc",if i == dryrun :,165
4194,"def merge_weekdays(base_wd, icu_wd): <TAB> result = [] <TAB> for left, right in zip(base_wd, icu_wd): <MASK> result.append(left) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> left = set(left.split(""|"")) <TAB>  <TAB> right = set(right.split(""|"")) <TAB>  <TAB> result.append(""|"".join(left | right)) <TAB> return result",if left == right :,104
4195,"def create_key(self, request): <TAB> if self._ignored_parameters: <TAB>  <TAB> url, body = self._remove_ignored_parameters(request) <TAB> else: <TAB>  <TAB> url, body = request.url, request.body <TAB> key = hashlib.sha256() <TAB> key.update(_to_bytes(request.method.upper())) <TAB> key.update(_to_bytes(url)) <TAB> if request.body: <TAB>  <TAB> key.update(_to_bytes(body)) <TAB> else: <MASK> for name, value in sorted(request.headers.items()): <TAB>  <TAB>  <TAB>  <TAB> key.update(_to_bytes(name)) <TAB>  <TAB>  <TAB>  <TAB> key.update(_to_bytes(value)) <TAB> return key.hexdigest()",if self . _include_get_headers and request . headers != _DEFAULT_HEADERS :,190
4196,"def test_invalid_mountinfo(self): <TAB> line = ( <TAB>  <TAB> ""20 1 252:1 / / rw,relatime - ext4 /dev/mapper/vg0-root"" <TAB>  <TAB> ""rw,errors=remount-ro,data=ordered"" <TAB> ) <TAB> elements = line.split() <TAB> for i in range(len(elements) + 1): <TAB>  <TAB> lines = ["" "".join(elements[0:i])] <MASK> expected = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> expected = (""/dev/mapper/vg0-root"", ""ext4"", ""/"") <TAB>  <TAB> self.assertEqual(expected, util.parse_mount_info(""/"", lines))",if i < 10 :,161
4197,"def nested_filter(self, items, mask): <TAB> keep_current = self.current_mask(mask) <TAB> keep_nested_lookup = self.nested_masks(mask) <TAB> for k, v in items: <TAB>  <TAB> keep_nested = keep_nested_lookup.get(k) <TAB>  <TAB> if k in keep_current: <TAB>  <TAB>  <TAB> if keep_nested is not None: <MASK> yield k, dict(self.nested_filter(v.items(), keep_nested)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield k, v","if isinstance ( v , dict ) :",142
4198,"def traverse_trees(node_pos, sample, trees: List[HeteroDecisionTreeGuest]): <TAB> if node_pos[""reach_leaf_node""].all(): <TAB>  <TAB> return node_pos <TAB> for t_idx, tree in enumerate(trees): <TAB>  <TAB> cur_node_idx = node_pos[""node_pos""][t_idx] <TAB>  <TAB> # reach leaf <TAB>  <TAB> if cur_node_idx == -1: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> rs, reach_leaf = HeteroSecureBoostingTreeGuest.traverse_a_tree( <TAB>  <TAB>  <TAB> tree, sample, cur_node_idx <TAB>  <TAB> ) <MASK> node_pos[""reach_leaf_node""][t_idx] = True <TAB>  <TAB> node_pos[""node_pos""][t_idx] = rs <TAB> return node_pos",if reach_leaf :,196
4199,"def _pop_waiting_trial_id(self) -> Optional[int]: <TAB> # TODO(c-bata): Reduce database query counts for extracting waiting trials. <TAB> for trial in self._storage.get_all_trials(self._study_id, deepcopy=False): <MASK> continue <TAB>  <TAB> if not self._storage.set_trial_state(trial._trial_id, TrialState.RUNNING): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> _logger.debug(""Trial {} popped from the trial queue."".format(trial.number)) <TAB>  <TAB> return trial._trial_id <TAB> return None",if trial . state != TrialState . WAITING :,150
4200,"def get_step_best(self, step_models): <TAB> best_score = None <TAB> best_model = """" <TAB> for model in step_models: <TAB>  <TAB> model_info = self.models_trained[model] <TAB>  <TAB> score = model_info.get_score() <MASK> continue <TAB>  <TAB> if best_score is None or score < best_score: <TAB>  <TAB>  <TAB> best_score = score <TAB>  <TAB>  <TAB> best_model = model <TAB> LOGGER.info(f""step {self.n_step}, best model {best_model}"") <TAB> return best_model",if score is None :,142
4201,"def iter_filters(filters, block_end=False): <TAB> queue = deque(filters) <TAB> while queue: <TAB>  <TAB> f = queue.popleft() <TAB>  <TAB> if f is not None and f.type in (""or"", ""and"", ""not""): <MASK> queue.appendleft(None) <TAB>  <TAB>  <TAB> for gf in f.filters: <TAB>  <TAB>  <TAB>  <TAB> queue.appendleft(gf) <TAB>  <TAB> yield f",if block_end :,105
4202,"def _buffer_decode(self, input, errors, final): <TAB> if self.decoder is None: <TAB>  <TAB> (output, consumed, byteorder) = codecs.utf_16_ex_decode(input, errors, 0, final) <TAB>  <TAB> if byteorder == -1: <TAB>  <TAB>  <TAB> self.decoder = codecs.utf_16_le_decode <MASK> self.decoder = codecs.utf_16_be_decode <TAB>  <TAB> elif consumed >= 2: <TAB>  <TAB>  <TAB> raise UnicodeError(""UTF-16 stream does not start with BOM"") <TAB>  <TAB> return (output, consumed) <TAB> return self.decoder(input, self.errors, final)",elif byteorder == 1 :,156
4203,"def _load_db(self): <TAB> try: <TAB>  <TAB> with open(self.db) as db: <TAB>  <TAB>  <TAB> content = db.read(8) <TAB>  <TAB>  <TAB> db.seek(0) <MASK> data = StringIO() <TAB>  <TAB>  <TAB>  <TAB> if self.encryptor: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.encryptor.decrypt(db, data) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise EncryptionError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Encrpyted credential storage: {}"".format(self.db) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> return json.loads(data.getvalue()) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return json.load(db) <TAB> except: <TAB>  <TAB> return {""creds"": []}","if content == ( ""Salted__"" ) :",187
4204,"def _getbytes(self, start, l=1): <TAB> out = [] <TAB> for ad in range(l): <TAB>  <TAB> offset = ad + start + self.base_address <MASK> raise IOError(""not enough bytes"") <TAB>  <TAB> out.append(int_to_byte(Byte(offset))) <TAB> return b"""".join(out)",if not is_mapped ( offset ) :,90
4205,"def cache_sqs_queues_across_accounts() -> bool: <TAB> function: str = f""{__name__}.{sys._getframe().f_code.co_name}"" <TAB> # First, get list of accounts <TAB> accounts_d: list = async_to_sync(get_account_id_to_name_mapping)() <TAB> # Second, call tasks to enumerate all the roles across all accounts <TAB> for account_id in accounts_d.keys(): <TAB>  <TAB> if config.get(""environment"") == ""prod"": <TAB>  <TAB>  <TAB> cache_sqs_queues_for_account.delay(account_id) <TAB>  <TAB> else: <MASK> cache_sqs_queues_for_account.delay(account_id) <TAB> stats.count(f""{function}.success"") <TAB> return True","if account_id in config . get ( ""celery.test_account_ids"" , [ ] ) :",200
4206,"def insertLine(self, refnum, linenum, line): <TAB> i = -1 <TAB> for i, row in enumerate(self.rows): <TAB>  <TAB> if row[0] == linenum: <MASK> row[refnum + 1] = line <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> # else keep looking <TAB>  <TAB> elif row[0] > linenum: <TAB>  <TAB>  <TAB> break <TAB> self.rows.insert(i, self.newRow(linenum, refnum, line))",if row [ refnum + 1 ] is None :,125
4207,"def __setattr__(self, name, val): <TAB> if self.__dict__.get(name, ""hamster_graphics_no_value_really"") == val: <TAB>  <TAB> return <TAB> Sprite.__setattr__(self, name, val) <TAB> if name == ""image_data"": <TAB>  <TAB> self._surface = None <MASK> self.__dict__[""width""] = self.image_data.get_width() <TAB>  <TAB>  <TAB> self.__dict__[""height""] = self.image_data.get_height()",if self . image_data :,126
4208,"def process_signature(app, what, name, obj, options, signature, return_annotation): <TAB> if signature: <TAB>  <TAB> # replace Mock function names <TAB>  <TAB> signature = re.sub(""<Mock name='([^']+)'.*>"", ""\g<1>"", signature) <TAB>  <TAB> signature = re.sub(""tensorflow"", ""tf"", signature) <TAB>  <TAB> # add scope name to layer signatures: <TAB>  <TAB> if hasattr(obj, ""use_scope""): <MASK> signature = signature[0] + ""variable_scope_name, "" + signature[1:] <TAB>  <TAB>  <TAB> elif obj.use_scope is None: <TAB>  <TAB>  <TAB>  <TAB> signature = signature[0] + ""[variable_scope_name,] "" + signature[1:] <TAB> # signature: arg list <TAB> return signature, return_annotation",if obj . use_scope :,188
4209,"def L_op(self, inputs, outputs, gout): <TAB> (x,) = inputs <TAB> (gz,) = gout <TAB> if x.type in complex_types: <TAB>  <TAB> raise NotImplementedError() <TAB> if outputs[0].type in discrete_types: <MASK> return [x.zeros_like(dtype=theano.config.floatX)] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return [x.zeros_like()] <TAB> return (gz * (1 - sqr(tanh(x))),)",if x . type in discrete_types :,124
4210,"def confirm_on_console(topic, msg): <TAB> done = False <TAB> print(topic) <TAB> while not done: <TAB>  <TAB> output = raw_input(msg + "":[y/n]"") <MASK> return True <TAB>  <TAB> if output.lower() == ""n"": <TAB>  <TAB>  <TAB> return False","if output . lower ( ) == ""y"" :",82
4211,"def replace_documentation_for_matching_shape(self, event_name, section, **kwargs): <TAB> if self._shape_name == section.context.get(""shape""): <TAB>  <TAB> self._replace_documentation(event_name, section) <TAB> for section_name in section.available_sections: <TAB>  <TAB> sub_section = section.get_section(section_name) <MASK> self._replace_documentation(event_name, sub_section) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.replace_documentation_for_matching_shape(event_name, sub_section)","if self . _shape_name == sub_section . context . get ( ""shape"" ) :",152
4212,"def confirm_on_console(topic, msg): <TAB> done = False <TAB> print(topic) <TAB> while not done: <TAB>  <TAB> output = raw_input(msg + "":[y/n]"") <TAB>  <TAB> if output.lower() == ""y"": <TAB>  <TAB>  <TAB> return True <MASK> return False","if output . lower ( ) == ""n"" :",82
4213,"def __getitem__(self, index): <TAB> if self._check(): <TAB>  <TAB> if isinstance(index, int): <MASK> raise IndexError(index) <TAB>  <TAB>  <TAB> if self.features[index] is None: <TAB>  <TAB>  <TAB>  <TAB> feature = self.device.feature_request(FEATURE.FEATURE_SET, 0x10, index) <TAB>  <TAB>  <TAB>  <TAB> if feature: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> (feature,) = _unpack(""!H"", feature[:2]) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.features[index] = FEATURE[feature] <TAB>  <TAB>  <TAB> return self.features[index] <TAB>  <TAB> elif isinstance(index, slice): <TAB>  <TAB>  <TAB> indices = index.indices(len(self.features)) <TAB>  <TAB>  <TAB> return [self.__getitem__(i) for i in range(*indices)]",if index < 0 or index >= len ( self . features ) :,195
4214,"def _parse_locator(self, locator): <TAB> prefix = None <TAB> criteria = locator <TAB> if not locator.startswith(""//""): <TAB>  <TAB> locator_parts = locator.partition(""="") <MASK> prefix = locator_parts[0] <TAB>  <TAB>  <TAB> criteria = locator_parts[2].strip() <TAB> return (prefix, criteria)",if len ( locator_parts [ 1 ] ) > 0 :,89
4215,"def trakt_episode_data_generate(self, data): <TAB> # Find how many unique season we have <TAB> uniqueSeasons = [] <TAB> for season, episode in data: <MASK> uniqueSeasons.append(season) <TAB> # build the query <TAB> seasonsList = [] <TAB> for searchedSeason in uniqueSeasons: <TAB>  <TAB> episodesList = [] <TAB>  <TAB> for season, episode in data: <TAB>  <TAB>  <TAB> if season == searchedSeason: <TAB>  <TAB>  <TAB>  <TAB> episodesList.append({""number"": episode}) <TAB>  <TAB> seasonsList.append({""number"": searchedSeason, ""episodes"": episodesList}) <TAB> post_data = {""seasons"": seasonsList} <TAB> return post_data",if season not in uniqueSeasons :,189
4216,"def __init__(self, data, n_bins): <TAB> bin_width = span / n_bins <TAB> bins = [0] * n_bins <TAB> for x in data: <TAB>  <TAB> b = int(mpfloor((x - minimum) / bin_width)) <MASK> b = 0 <TAB>  <TAB> elif b >= n_bins: <TAB>  <TAB>  <TAB> b = n_bins - 1 <TAB>  <TAB> bins[b] += 1 <TAB> self.bins = bins <TAB> self.bin_width = bin_width",if b < 0 :,124
4217,"def infer_context(typ, context=""http://schema.org""): <TAB> parsed_context = urlparse(typ) <TAB> if parsed_context.netloc: <TAB>  <TAB> base = """".join([parsed_context.scheme, ""://"", parsed_context.netloc]) <MASK> context = urljoin(base, parsed_context.path) <TAB>  <TAB>  <TAB> typ = parsed_context.fragment.strip(""/"") <TAB>  <TAB> elif parsed_context.path: <TAB>  <TAB>  <TAB> context = base <TAB>  <TAB>  <TAB> typ = parsed_context.path.strip(""/"") <TAB> return context, typ",if parsed_context . path and parsed_context . fragment :,140
4218,"def parse(self, items): <TAB> for index, item in enumerate(items): <TAB>  <TAB> keys = self.build_key(item) <TAB>  <TAB> if keys is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # Update `items` <TAB>  <TAB> self.items[tuple(keys)] = (index, item) <TAB>  <TAB> # Update `table` <MASK> log.info(""Unable to update table (keys: %r)"", keys)","if not self . path_set ( self . table , keys , ( index , item ) ) :",120
4219,"def dict_to_XML(tag, dictionary, **kwargs): <TAB> """"""Return XML element converting dicts recursively."""""" <TAB> elem = Element(tag, **kwargs) <TAB> for key, val in dictionary.items(): <TAB>  <TAB> if tag == ""layers"": <TAB>  <TAB>  <TAB> child = dict_to_XML(""layer"", val, name=key) <TAB>  <TAB> elif isinstance(val, MutableMapping): <TAB>  <TAB>  <TAB> child = dict_to_XML(key, val) <TAB>  <TAB> else: <MASK> child = Element(""variable"", name=key) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> child = Element(key) <TAB>  <TAB>  <TAB> child.text = str(val) <TAB>  <TAB> elem.append(child) <TAB> return elem","if tag == ""config"" :",175
4220,"def _get_config_value(self, section, key): <TAB> if section: <MASK> self.log.error(""Error: Config section '%s' not found"", section) <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> return self.config[section].get(key, self.config[key]) <TAB> else: <TAB>  <TAB> return self.config[key]",if section not in self . config :,93
4221,"def h_line_down(self, input): <TAB> end_this_line = self.value.find(""\n"", self.cursor_position) <TAB> if end_this_line == -1: <TAB>  <TAB> if self.scroll_exit: <TAB>  <TAB>  <TAB> self.h_exit_down(None) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.cursor_position = len(self.value) <TAB> else: <TAB>  <TAB> self.cursor_position = end_this_line + 1 <TAB>  <TAB> for x in range(self.cursorx): <MASK> break <TAB>  <TAB>  <TAB> elif self.value[self.cursor_position] == ""\n"": <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.cursor_position += 1",if self . cursor_position > len ( self . value ) - 1 :,193
4222,"def printsumfp(fp, filename, out=sys.stdout): <TAB> m = md5() <TAB> try: <TAB>  <TAB> while 1: <TAB>  <TAB>  <TAB> data = fp.read(bufsize) <MASK> break <TAB>  <TAB>  <TAB> if isinstance(data, str): <TAB>  <TAB>  <TAB>  <TAB> data = data.encode(fp.encoding) <TAB>  <TAB>  <TAB> m.update(data) <TAB> except IOError as msg: <TAB>  <TAB> sys.stderr.write(""%s: I/O error: %s\n"" % (filename, msg)) <TAB>  <TAB> return 1 <TAB> out.write(""%s %s\n"" % (m.hexdigest(), filename)) <TAB> return 0",if not data :,159
4223,"def main(input): <TAB> logging.info(""Running Azure Cloud Custodian Policy %s"", input) <TAB> context = { <TAB>  <TAB> ""config_file"": join(function_directory, ""config.json""), <TAB>  <TAB> ""auth_file"": join(function_directory, ""auth.json""), <TAB> } <TAB> event = None <TAB> subscription_id = None <TAB> if isinstance(input, QueueMessage): <MASK> return <TAB>  <TAB> event = input.get_json() <TAB>  <TAB> subscription_id = ResourceIdParser.get_subscription_id(event[""subject""]) <TAB> handler.run(event, context, subscription_id)",if input . dequeue_count > max_dequeue_count :,166
4224,"def maybeExtractTarball(self): <TAB> if self.tarball: <TAB>  <TAB> tar = self.computeTarballOptions() + [""-xvf"", self.tarball] <TAB>  <TAB> res = yield self._Cmd(tar, abandonOnFailure=False) <MASK> # error with tarball.. erase repo dir and tarball <TAB>  <TAB>  <TAB> yield self._Cmd([""rm"", ""-f"", self.tarball], abandonOnFailure=False) <TAB>  <TAB>  <TAB> yield self.runRmdir(self.repoDir(), abandonOnFailure=False)",if res :,124
4225,"def execute(self, arbiter, props): <TAB> watcher = self._get_watcher(arbiter, props.pop(""name"")) <TAB> action = 0 <TAB> for key, val in props.get(""options"", {}).items(): <MASK> new_action = 0 <TAB>  <TAB>  <TAB> for name, _val in val.items(): <TAB>  <TAB>  <TAB>  <TAB> action = watcher.set_opt(""hooks.%s"" % name, _val) <TAB>  <TAB>  <TAB>  <TAB> if action == 1: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> new_action = 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_action = watcher.set_opt(key, val) <TAB>  <TAB> if new_action == 1: <TAB>  <TAB>  <TAB> action = 1 <TAB> # trigger needed action <TAB> return watcher.do_action(action)","if key == ""hooks"" :",186
4226,"def _import_playlists(self, fns, library): <TAB> added = 0 <TAB> for filename in fns: <TAB>  <TAB> name = _name_for(filename) <TAB>  <TAB> with open(filename, ""rb"") as f: <MASK> playlist = parse_m3u(f, name, library=library) <TAB>  <TAB>  <TAB> elif filename.endswith("".pls""): <TAB>  <TAB>  <TAB>  <TAB> playlist = parse_pls(f, name, library=library) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> print_w(""Unsupported playlist type for '%s'"" % filename) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> self.changed(playlist) <TAB>  <TAB> library.add(playlist) <TAB>  <TAB> added += 1 <TAB> return added","if filename . endswith ( "".m3u"" ) or filename . endswith ( "".m3u8"" ) :",186
4227,"def unwrap_term_buckets(self, timestamp, term_buckets): <TAB> for term_data in term_buckets: <MASK> self.unwrap_interval_buckets( <TAB>  <TAB>  <TAB>  <TAB> timestamp, term_data[""key""], term_data[""interval_aggs""][""buckets""] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.check_matches(timestamp, term_data[""key""], term_data)","if ""interval_aggs"" in term_data :",108
4228,"def _get_exception(flags, timeout_ms, payload_size): <TAB> if flags & FLAG_ERROR: <TAB>  <TAB> if flags & FLAG_TIMEOUT: <TAB>  <TAB>  <TAB> return SpicommTimeoutError(timeout_ms / 1000.0) <MASK> return SpicommOverflowError(payload_size) <TAB>  <TAB> return SpicommError() <TAB> return None",if flags & FLAG_OVERFLOW :,99
4229,"def _get_pattern(self, pattern_id): <TAB> """"""Get pattern item by id."""""" <TAB> for key in (Tag.PATTERNS1, Tag.PATTERNS2, Tag.PATTERNS3): <TAB>  <TAB> if key in self.tagged_blocks: <TAB>  <TAB>  <TAB> data = self.tagged_blocks.get_data(key) <TAB>  <TAB>  <TAB> for pattern in data: <MASK> return pattern <TAB> return None",if pattern . pattern_id == pattern_id :,110
4230,"def print_quiet(self, context, *args, **kwargs): <TAB> for index, (key, value) in enumerate( <TAB>  <TAB> itertools.chain(enumerate(args), kwargs.items()) <TAB> ): <MASK> print( <TAB>  <TAB>  <TAB>  <TAB> self.format_quiet(index, key, value, fields=context.get_input_fields()) <TAB>  <TAB>  <TAB> )","if self . filter ( index , key , value ) :",99
4231,"def complete(self, block): <TAB> with self._condition: <TAB>  <TAB> if not self._final: <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> if self._complete(): <TAB>  <TAB>  <TAB> self._calculate_state_root_if_not_already_done() <TAB>  <TAB>  <TAB> return True <MASK> self._condition.wait_for(self._complete) <TAB>  <TAB>  <TAB> self._calculate_state_root_if_not_already_done() <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> return False",if block :,117
4232,"def compression_rotator(source, dest): <TAB> with open(source, ""rb"") as sf: <TAB>  <TAB> with gzip.open(dest, ""wb"") as wf: <TAB>  <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB>  <TAB> data = sf.read(CHUNK_SIZE) <MASK> break <TAB>  <TAB>  <TAB>  <TAB> wf.write(data) <TAB> os.remove(source)",if not data :,100
4233,"def mockup(self, records): <TAB> provider = TransipProvider("""", """", """") <TAB> _dns_entries = [] <TAB> for record in records: <MASK> entries_for = getattr(provider, ""_entries_for_{}"".format(record._type)) <TAB>  <TAB>  <TAB> # Root records have '@' as name <TAB>  <TAB>  <TAB> name = record.name <TAB>  <TAB>  <TAB> if name == """": <TAB>  <TAB>  <TAB>  <TAB> name = provider.ROOT_RECORD <TAB>  <TAB>  <TAB> _dns_entries.extend(entries_for(name, record)) <TAB>  <TAB>  <TAB> # NS is not supported as a DNS Entry, <TAB>  <TAB>  <TAB> # so it should cover the if statement <TAB>  <TAB>  <TAB> _dns_entries.append(DnsEntry(""@"", ""3600"", ""NS"", ""ns01.transip.nl."")) <TAB> self.mockupEntries = _dns_entries",if record . _type in provider . SUPPORTS :,196
4234,"def parse_known_args(self, args=None, namespace=None): <TAB> entrypoint = self.prog.split("" "")[0] <TAB> try: <TAB>  <TAB> defs = get_defaults_for_argparse(entrypoint) <TAB>  <TAB> ignore = defs.pop(""Ignore"", None) <TAB>  <TAB> self.set_defaults(**defs) <MASK> set_notebook_diff_ignores(ignore) <TAB> except ValueError: <TAB>  <TAB> pass <TAB> return super(ConfigBackedParser, self).parse_known_args( <TAB>  <TAB> args=args, namespace=namespace <TAB> )",if ignore :,134
4235,"def _maybeRebuildAtlas(self, threshold=4, minlen=1000): <TAB> n = len(self.fragmentAtlas) <TAB> if (n > minlen) and (n > threshold * len(self.data)): <TAB>  <TAB> self.fragmentAtlas.rebuild( <TAB>  <TAB>  <TAB> list(zip(*self._style([""symbol"", ""size"", ""pen"", ""brush""]))) <TAB>  <TAB> ) <TAB>  <TAB> self.data[""sourceRect""] = 0 <MASK> self._sourceQRect.clear() <TAB>  <TAB> self.updateSpots()",if _USE_QRECT :,137
4236,"def dispatch_return(self, frame, arg): <TAB> if self.stop_here(frame) or frame == self.returnframe: <TAB>  <TAB> # Ignore return events in generator except when stepping. <MASK> return self.trace_dispatch <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.frame_returning = frame <TAB>  <TAB>  <TAB> self.user_return(frame, arg) <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self.frame_returning = None <TAB>  <TAB> if self.quitting: <TAB>  <TAB>  <TAB> raise BdbQuit <TAB>  <TAB> # The user issued a 'next' or 'until' command. <TAB>  <TAB> if self.stopframe is frame and self.stoplineno != -1: <TAB>  <TAB>  <TAB> self._set_stopinfo(None, None) <TAB> return self.trace_dispatch",if self . stopframe and frame . f_code . co_flags & CO_GENERATOR :,199
4237,"def tearDown(self): <TAB> if not self.is_playback(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if self.hosted_service_name is not None: <TAB>  <TAB>  <TAB>  <TAB> self.sms.delete_hosted_service(self.hosted_service_name) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> try: <MASK> self.sms.delete_storage_account(self.storage_account_name) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.sms.delete_affinity_group(self.affinity_group_name) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> pass <TAB> return super(LegacyMgmtAffinityGroupTest, self).tearDown()",if self . storage_account_name is not None :,180
4238,"def make_log_msg(self, msg, *other_messages): <TAB> MAX_MESSAGE_LENGTH = 1000 <TAB> if not other_messages: <TAB>  <TAB> # assume that msg is a single string <TAB>  <TAB> return msg[-MAX_MESSAGE_LENGTH:] <TAB> else: <TAB>  <TAB> if len(msg): <TAB>  <TAB>  <TAB> msg += ""\n...\n"" <TAB>  <TAB>  <TAB> NEXT_MESSAGE_OFFSET = MAX_MESSAGE_LENGTH - len(msg) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> NEXT_MESSAGE_OFFSET = MAX_MESSAGE_LENGTH <MASK> msg += other_messages[0][-NEXT_MESSAGE_OFFSET:] <TAB>  <TAB>  <TAB> return self.make_log_msg(msg, *other_messages[1:]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.make_log_msg(msg)",if NEXT_MESSAGE_OFFSET > 0 :,196
4239,"def wrapper(  # type: ignore <TAB> self: RequestHandler, *args, **kwargs) -> Optional[Awaitable[None]]: <TAB> if self.request.path.endswith(""/""): <TAB>  <TAB> if self.request.method in (""GET"", ""HEAD""): <TAB>  <TAB>  <TAB> uri = self.request.path.rstrip(""/"") <TAB>  <TAB>  <TAB> if uri:  # don't try to redirect '/' to '' <MASK> uri += ""?"" + self.request.query <TAB>  <TAB>  <TAB>  <TAB> self.redirect(uri, permanent=True) <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise HTTPError(404) <TAB> return method(self, *args, **kwargs)",if self . request . query :,163
4240,"def process_lib(vars_, coreval): <TAB> for d in vars_: <TAB>  <TAB> var = d.upper() <TAB>  <TAB> if var == ""QTCORE"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> value = env[""LIBPATH_"" + var] <MASK> core = env[coreval] <TAB>  <TAB>  <TAB> accu = [] <TAB>  <TAB>  <TAB> for lib in value: <TAB>  <TAB>  <TAB>  <TAB> if lib in core: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB>  <TAB> accu.append(lib) <TAB>  <TAB>  <TAB> env[""LIBPATH_"" + var] = accu",if value :,133
4241,"def _attach_children(self, other, exclude_worldbody, dry_run=False): <TAB> for other_child in other.all_children(): <MASK> self_child = self.get_children(other_child.spec.name) <TAB>  <TAB>  <TAB> self_child._attach( <TAB>  <TAB>  <TAB>  <TAB> other_child, exclude_worldbody, dry_run <TAB>  <TAB>  <TAB> )  # pylint: disable=protected-access",if not other_child . spec . repeated :,115
4242,"def getDictFromTree(tree): <TAB> ret_dict = {} <TAB> for child in tree.getchildren(): <TAB>  <TAB> if child.getchildren(): <TAB>  <TAB>  <TAB> ## Complex-type child. Recurse <TAB>  <TAB>  <TAB> content = getDictFromTree(child) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> content = child.text <MASK> if not type(ret_dict[child.tag]) == list: <TAB>  <TAB>  <TAB>  <TAB> ret_dict[child.tag] = [ret_dict[child.tag]] <TAB>  <TAB>  <TAB> ret_dict[child.tag].append(content or """") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret_dict[child.tag] = content or """" <TAB> return ret_dict",if ret_dict . has_key ( child . tag ) :,175
4243,"def nsUriMatch(self, value, wanted, strict=0, tt=type(())): <TAB> """"""Return a true value if two namespace uri values match."""""" <TAB> if value == wanted or (type(wanted) is tt) and value in wanted: <TAB>  <TAB> return 1 <TAB> if not strict and value is not None: <TAB>  <TAB> wanted = type(wanted) is tt and wanted or (wanted,) <TAB>  <TAB> value = value[-1:] != ""/"" and value or value[:-1] <TAB>  <TAB> for item in wanted: <MASK> return 1 <TAB> return 0",if item == value or item [ : - 1 ] == value :,141
4244,"def update_repository(self, ignore_issues=False, force=False): <TAB> """"""Update."""""" <TAB> if not await self.common_update(ignore_issues, force): <TAB>  <TAB> return <TAB> # Get appdaemon objects. <TAB> if self.repository_manifest: <MASK> self.content.path.remote = """" <TAB> if self.content.path.remote == ""apps"": <TAB>  <TAB> self.data.domain = get_first_directory_in_directory( <TAB>  <TAB>  <TAB> self.tree, self.content.path.remote <TAB>  <TAB> ) <TAB>  <TAB> self.content.path.remote = f""apps/{self.data.name}"" <TAB> # Set local path <TAB> self.content.path.local = self.localpath",if self . data . content_in_root :,181
4245,"def addOutput(self, data, isAsync=None, **kwargs): <TAB> isAsync = _get_async_param(isAsync, **kwargs) <TAB> if isAsync: <TAB>  <TAB> self.terminal.eraseLine() <TAB>  <TAB> self.terminal.cursorBackward(len(self.lineBuffer) + len(self.ps[self.pn])) <TAB> self.terminal.write(data) <TAB> if isAsync: <MASK> self.terminal.nextLine() <TAB>  <TAB> self.terminal.write(self.ps[self.pn]) <TAB>  <TAB> if self.lineBuffer: <TAB>  <TAB>  <TAB> oldBuffer = self.lineBuffer <TAB>  <TAB>  <TAB> self.lineBuffer = [] <TAB>  <TAB>  <TAB> self.lineBufferIndex = 0 <TAB>  <TAB>  <TAB> self._deliverBuffer(oldBuffer)",if self . _needsNewline ( ) :,188
4246,"def is_installed(self, dlc_title="""") -> bool: <TAB> installed = False <TAB> if dlc_title: <TAB>  <TAB> dlc_version = self.get_dlc_info(""version"", dlc_title) <TAB>  <TAB> installed = True if dlc_version else False <TAB>  <TAB> # Start: Code for compatibility with minigalaxy 1.0 <MASK> status = self.legacy_get_dlc_status(dlc_title) <TAB>  <TAB>  <TAB> installed = True if status in [""installed"", ""updatable""] else False <TAB>  <TAB> # End: Code for compatibility with minigalaxy 1.0 <TAB> else: <TAB>  <TAB> if self.install_dir and os.path.exists(self.install_dir): <TAB>  <TAB>  <TAB> installed = True <TAB> return installed",if not installed :,178
4247,"def close(self): <TAB> self.selector.close() <TAB> if self.sock: <TAB>  <TAB> sockname = None <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> sockname = self.sock.getsockname() <TAB>  <TAB> except (socket.error, OSError): <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> self.sock.close() <MASK> # it was a Unix domain socket, remove it from the filesystem <TAB>  <TAB>  <TAB> if os.path.exists(sockname): <TAB>  <TAB>  <TAB>  <TAB> os.remove(sockname) <TAB> self.sock = None",if type ( sockname ) is str :,128
4248,"def post_file(self, file_path, graph_type=""edges"", file_type=""csv""): <TAB> dataset_id = self.dataset_id <TAB> tok = self.token <TAB> base_path = self.server_base_path <TAB> with open(file_path, ""rb"") as file: <TAB>  <TAB> out = requests.post( <TAB>  <TAB>  <TAB> f""{base_path}/api/v2/upload/datasets/{dataset_id}/{graph_type}/{file_type}"", <TAB>  <TAB>  <TAB> verify=self.certificate_validation, <TAB>  <TAB>  <TAB> headers={""Authorization"": f""Bearer {tok}""}, <TAB>  <TAB>  <TAB> data=file.read(), <TAB>  <TAB> ).json() <MASK> raise Exception(out) <TAB>  <TAB> return out","if not out [ ""success"" ] :",176
4249,"def _get_vqa_v2_image_raw_dataset(directory, image_root_url, image_urls): <TAB> """"""Extract the VQA V2 image data set to directory unless it's there."""""" <TAB> for url in image_urls: <TAB>  <TAB> filename = os.path.basename(url) <TAB>  <TAB> download_url = os.path.join(image_root_url, url) <TAB>  <TAB> path = generator_utils.maybe_download(directory, filename, download_url) <TAB>  <TAB> unzip_dir = os.path.join(directory, filename.strip("".zip"")) <MASK> zipfile.ZipFile(path, ""r"").extractall(directory)",if not tf . gfile . Exists ( unzip_dir ) :,165
4250,"def __call__(self, environ, start_response): <TAB> for key in ""REQUEST_URL"", ""REQUEST_URI"", ""UNENCODED_URL"": <MASK> continue <TAB>  <TAB> request_uri = unquote(environ[key]) <TAB>  <TAB> script_name = unquote(environ.get(""SCRIPT_NAME"", """")) <TAB>  <TAB> if request_uri.startswith(script_name): <TAB>  <TAB>  <TAB> environ[""PATH_INFO""] = request_uri[len(script_name) :].split(""?"", 1)[0] <TAB>  <TAB>  <TAB> break <TAB> return self.app(environ, start_response)",if key not in environ :,140
4251,"def _instrument_model(self, model): <TAB> for key, value in list( <TAB>  <TAB> model.__dict__.items() <TAB> ):  # avoid ""dictionary keys changed during iteration"" <TAB>  <TAB> if isinstance(value, tf.keras.layers.Layer): <TAB>  <TAB>  <TAB> new_layer = self._instrument(value) <TAB>  <TAB>  <TAB> if new_layer is not value: <TAB>  <TAB>  <TAB>  <TAB> setattr(model, key, new_layer) <MASK> for i, item in enumerate(value): <TAB>  <TAB>  <TAB>  <TAB> if isinstance(item, tf.keras.layers.Layer): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value[i] = self._instrument(item) <TAB> return model","elif isinstance ( value , list ) :",164
4252,"def __init__(self, parent, dir, mask, with_dirs=True): <TAB> filelist = [] <TAB> dirlist = [""..""] <TAB> self.dir = dir <TAB> self.file = """" <TAB> mask = mask.upper() <TAB> pattern = self.MakeRegex(mask) <TAB> for i in os.listdir(dir): <TAB>  <TAB> if i == ""."" or i == "".."": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> path = os.path.join(dir, i) <TAB>  <TAB> if os.path.isdir(path): <TAB>  <TAB>  <TAB> dirlist.append(i) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> path = path.upper() <TAB>  <TAB> value = i.upper() <MASK> filelist.append(i) <TAB> self.files = filelist <TAB> if with_dirs: <TAB>  <TAB> self.dirs = dirlist",if pattern . match ( value ) is not None :,199
4253,"def get_text(self, nodelist): <TAB> """"""Return a string representation of the motif's properties listed on nodelist ."""""" <TAB> retlist = [] <TAB> for node in nodelist: <TAB>  <TAB> if node.nodeType == Node.TEXT_NODE: <TAB>  <TAB>  <TAB> retlist.append(node.wholeText) <MASK> retlist.append(self.get_text(node.childNodes)) <TAB> return re.sub(r""\s+"", "" "", """".join(retlist))",elif node . hasChildNodes :,119
4254,"def _persist_metadata(self, dirname, filename): <TAB> metadata_path = ""{0}/{1}.json"".format(dirname, filename) <TAB> if self.media_metadata or self.comments or self.include_location: <TAB>  <TAB> if self.posts: <TAB>  <TAB>  <TAB> if self.latest: <TAB>  <TAB>  <TAB>  <TAB> self.merge_json({""GraphImages"": self.posts}, metadata_path) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.save_json({""GraphImages"": self.posts}, metadata_path) <MASK> if self.latest: <TAB>  <TAB>  <TAB>  <TAB> self.merge_json({""GraphStories"": self.stories}, metadata_path) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.save_json({""GraphStories"": self.stories}, metadata_path)",if self . stories :,190
4255,"def _get_python_wrapper_content(self, job_class, args): <TAB> job = job_class([""-r"", ""hadoop""] + list(args)) <TAB> job.sandbox() <TAB> with job.make_runner() as runner: <TAB>  <TAB> runner._create_setup_wrapper_scripts() <MASK> with open(runner._spark_python_wrapper_path) as f: <TAB>  <TAB>  <TAB>  <TAB> return f.read() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return None",if runner . _spark_python_wrapper_path :,125
4256,"def computeLeadingWhitespaceWidth(s, tab_width): <TAB> w = 0 <TAB> for ch in s: <MASK> w += 1 <TAB>  <TAB> elif ch == ""\t"": <TAB>  <TAB>  <TAB> w += abs(tab_width) - (w % abs(tab_width)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> return w","if ch == "" "" :",87
4257,def run(self): <TAB> # if the i3status process dies we want to restart it. <TAB> # We give up restarting if we have died too often <TAB> for _ in range(10): <MASK> break <TAB>  <TAB> self.spawn_i3status() <TAB>  <TAB> # check if we never worked properly and if so quit now <TAB>  <TAB> if not self.ready: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> # limit restart rate <TAB>  <TAB> self.lock.wait(5),if not self . py3_wrapper . running :,122
4258,"def translate_len( <TAB> builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Optional[Value]: <TAB> # Special case builtins.len <TAB> if len(expr.args) == 1 and expr.arg_kinds == [ARG_POS]: <TAB>  <TAB> expr_rtype = builder.node_type(expr.args[0]) <MASK> # len() of fixed-length tuple can be trivially determined statically, <TAB>  <TAB>  <TAB> # though we still need to evaluate it. <TAB>  <TAB>  <TAB> builder.accept(expr.args[0]) <TAB>  <TAB>  <TAB> return Integer(len(expr_rtype.types)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> obj = builder.accept(expr.args[0]) <TAB>  <TAB>  <TAB> return builder.builtin_len(obj, -1) <TAB> return None","if isinstance ( expr_rtype , RTuple ) :",188
4259,"def parse_auth(val): <TAB> if val is not None: <TAB>  <TAB> authtype, params = val.split("" "", 1) <TAB>  <TAB> if authtype in known_auth_schemes: <MASK> # this is the ""Authentication: Basic XXXXX=="" case <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> params = parse_auth_params(params) <TAB>  <TAB> return authtype, params <TAB> return val","if authtype == ""Basic"" and '""' not in params :",117
4260,"def toxml(self): <TAB> text = self.value <TAB> self.parent.setBidi(getBidiType(text)) <TAB> if not text.startswith(HTML_PLACEHOLDER_PREFIX): <TAB>  <TAB> if self.parent.nodeName == ""p"": <TAB>  <TAB>  <TAB> text = text.replace(""\n"", ""\n   "") <MASK> text = ""\n <TAB>  "" + text.replace(""\n"", ""\n <TAB>  "") <TAB> text = self.doc.normalizeEntities(text) <TAB> return text","elif self . parent . nodeName == ""li"" and self . parent . childNodes [ 0 ] == self :",148
4261,"def get_all_related_many_to_many_objects(self): <TAB> try:  # Try the cache first. <TAB>  <TAB> return self._all_related_many_to_many_objects <TAB> except AttributeError: <TAB>  <TAB> rel_objs = [] <TAB>  <TAB> for klass in get_models(): <TAB>  <TAB>  <TAB> for f in klass._meta.many_to_many: <MASK> rel_objs.append(RelatedObject(f.rel.to, klass, f)) <TAB>  <TAB> self._all_related_many_to_many_objects = rel_objs <TAB>  <TAB> return rel_objs",if f . rel and self == f . rel . to . _meta :,158
4262,"def state_highstate(self, state, dirpath): <TAB> opts = copy.copy(self.config) <TAB> opts[""file_roots""] = dict(base=[dirpath]) <TAB> HIGHSTATE = HighState(opts) <TAB> HIGHSTATE.push_active() <TAB> try: <TAB>  <TAB> high, errors = HIGHSTATE.render_highstate(state) <MASK> import pprint <TAB>  <TAB>  <TAB> pprint.pprint(""\n"".join(errors)) <TAB>  <TAB>  <TAB> pprint.pprint(high) <TAB>  <TAB> out = HIGHSTATE.state.call_high(high) <TAB>  <TAB> # pprint.pprint(out) <TAB> finally: <TAB>  <TAB> HIGHSTATE.pop_active()",if errors :,156
4263,"def _update_target_host(self, target, target_host): <TAB> """"""Update target host."""""" <TAB> target_host = None if target_host == """" else target_host <TAB> if not target_host: <TAB>  <TAB> for device_type, tgt in target.items(): <MASK> target_host = tgt <TAB>  <TAB>  <TAB>  <TAB> break <TAB> if not target_host: <TAB>  <TAB> target_host = ""llvm"" if tvm.runtime.enabled(""llvm"") else ""stackvm"" <TAB> if isinstance(target_host, str): <TAB>  <TAB> target_host = tvm.target.Target(target_host) <TAB> return target_host",if device_type . value == tvm . nd . cpu ( 0 ) . device_type :,171
4264,"def __console_writer(self): <TAB> while True: <TAB>  <TAB> self.__writer_event.wait() <TAB>  <TAB> self.__writer_event.clear() <TAB>  <TAB> if self.__console_view: <MASK> self.log.debug(""Writing console view to STDOUT"") <TAB>  <TAB>  <TAB>  <TAB> sys.stdout.write(self.console_markup.clear) <TAB>  <TAB>  <TAB>  <TAB> sys.stdout.write(self.__console_view) <TAB>  <TAB>  <TAB>  <TAB> sys.stdout.write(self.console_markup.TOTAL_RESET)",if not self . short_only :,134
4265,"def goToPrevMarkedHeadline(self, event=None): <TAB> """"""Select the next marked node."""""" <TAB> c = self <TAB> p = c.p <TAB> if not p: <TAB>  <TAB> return <TAB> p.moveToThreadBack() <TAB> wrapped = False <TAB> while 1: <TAB>  <TAB> if p and p.isMarked(): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif p: <TAB>  <TAB>  <TAB> p.moveToThreadBack() <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> wrapped = True <TAB>  <TAB>  <TAB> p = c.rootPosition() <TAB> if not p: <TAB>  <TAB> g.blue(""done"") <TAB> c.treeSelectHelper(p)  # Sets focus.",elif wrapped :,164
4266,"def delete_map(self, query=None): <TAB> query_map = self.interpolated_map(query=query) <TAB> for alias, drivers in six.iteritems(query_map.copy()): <TAB>  <TAB> for driver, vms in six.iteritems(drivers.copy()): <TAB>  <TAB>  <TAB> for vm_name, vm_details in six.iteritems(vms.copy()): <TAB>  <TAB>  <TAB>  <TAB> if vm_details == ""Absent"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> query_map[alias][driver].pop(vm_name) <TAB>  <TAB>  <TAB> if not query_map[alias][driver]: <TAB>  <TAB>  <TAB>  <TAB> query_map[alias].pop(driver) <MASK> query_map.pop(alias) <TAB> return query_map",if not query_map [ alias ] :,177
4267,"def get_shadows_zip(filename): <TAB> import zipfile <TAB> shadow_pkgs = set() <TAB> with zipfile.ZipFile(filename) as lib_zip: <TAB>  <TAB> already_test = [] <TAB>  <TAB> for fname in lib_zip.namelist(): <TAB>  <TAB>  <TAB> pname, fname = os.path.split(fname) <MASK> continue <TAB>  <TAB>  <TAB> if pname not in already_test and ""/"" not in pname: <TAB>  <TAB>  <TAB>  <TAB> already_test.append(pname) <TAB>  <TAB>  <TAB>  <TAB> if is_shadowing(pname): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> shadow_pkgs.add(pname) <TAB> return shadow_pkgs",if fname or ( pname and fname ) :,159
4268,"def make_chains(chains_info): <TAB> chains = [[] for _ in chains_info[0][1]] <TAB> for i, num_ids in enumerate(chains_info[:-1]): <TAB>  <TAB> num, ids = num_ids <TAB>  <TAB> for j, ident in enumerate(ids): <MASK> next_chain_info = chains_info[i + 1] <TAB>  <TAB>  <TAB>  <TAB> previous = next_chain_info[1][j] <TAB>  <TAB>  <TAB>  <TAB> block = SimpleBlock(num, ident, previous) <TAB>  <TAB>  <TAB>  <TAB> chains[j].append(block) <TAB> chains = {i: make_generator(chain) for i, chain in enumerate(chains)} <TAB> return chains","if ident != """" :",164
4269,"def filter_input(mindate, maxdate, files): <TAB> mindate = parse(mindate) if mindate is not None else datetime.datetime.min <TAB> maxdate = parse(maxdate) if maxdate is not None else datetime.datetime.max <TAB> for line in fileinput.input(files): <TAB>  <TAB> tweet = json.loads(line) <TAB>  <TAB> created_at = parse(tweet[""created_at""]) <TAB>  <TAB> created_at = created_at.replace(tzinfo=None) <MASK> print(json.dumps(tweet))",if mindate < created_at and maxdate > created_at :,149
4270,"def get(self): <TAB> """"""If a value/an exception is stored, return/raise it. Otherwise until switch() or throw() is called."""""" <TAB> if self._exception is not _NONE: <TAB>  <TAB> if self._exception is None: <TAB>  <TAB>  <TAB> return self.value <TAB>  <TAB> getcurrent().throw(*self._exception)  # pylint:disable=undefined-variable <TAB> else: <MASK> raise ConcurrentObjectUseError( <TAB>  <TAB>  <TAB>  <TAB> ""This Waiter is already used by %r"" % (self.greenlet,) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self.greenlet = getcurrent()  # pylint:disable=undefined-variable <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self.hub.switch() <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> self.greenlet = None",if self . greenlet is not None :,188
4271,"def default_loader(href, parse, encoding=None): <TAB> with open(href) as file: <MASK> data = ElementTree.parse(file).getroot() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> data = file.read() <TAB>  <TAB>  <TAB> if encoding: <TAB>  <TAB>  <TAB>  <TAB> data = data.decode(encoding) <TAB> return data","if parse == ""xml"" :",86
4272,def is_all_qud(world): <TAB> m = True <TAB> for obj in world: <MASK> if obj.nice: <TAB>  <TAB>  <TAB>  <TAB> m = m and True <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> m = m and False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> m = m and True <TAB> return m,if obj . blond :,85
4273,"def run(self, edit): <TAB> if not self.has_selection(): <TAB>  <TAB> region = sublime.Region(0, self.view.size()) <TAB>  <TAB> originalBuffer = self.view.substr(region) <TAB>  <TAB> prefixed = self.prefix(originalBuffer) <TAB>  <TAB> if prefixed: <TAB>  <TAB>  <TAB> self.view.replace(edit, region, prefixed) <TAB>  <TAB> return <TAB> for region in self.view.sel(): <MASK> continue <TAB>  <TAB> originalBuffer = self.view.substr(region) <TAB>  <TAB> prefixed = self.prefix(originalBuffer) <TAB>  <TAB> if prefixed: <TAB>  <TAB>  <TAB> self.view.replace(edit, region, prefixed)",if region . empty ( ) :,163
4274,"def add_fields(self, params): <TAB> for (key, val) in params.iteritems(): <MASK> new_params = {} <TAB>  <TAB>  <TAB> for k in val: <TAB>  <TAB>  <TAB>  <TAB> new_params[""%s__%s"" % (key, k)] = val[k] <TAB>  <TAB>  <TAB> self.add_fields(new_params) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.add_field(key, val)","if isinstance ( val , dict ) :",108
4275,"def find_magic(self, f, pos, magic): <TAB> f.seek(pos) <TAB> block = f.read(32 * 1024) <TAB> if len(block) < len(magic): <TAB>  <TAB> return -1 <TAB> p = block.find(magic) <TAB> while p < 0: <TAB>  <TAB> pos += len(block) - len(magic) + 1 <TAB>  <TAB> block = block[1 - len(magic) :] + f.read(32 << 10) <MASK> return -1 <TAB>  <TAB> p = block.find(magic) <TAB> return pos + p",if len ( block ) == len ( magic ) - 1 :,148
4276,"def check_strings(self): <TAB> """"""Check that all strings have been consumed."""""" <TAB> for i, aList in enumerate(self.string_tokens): <MASK> g.trace(""warning: line %s. unused strings"" % i) <TAB>  <TAB>  <TAB> for z in aList: <TAB>  <TAB>  <TAB>  <TAB> print(self.dump_token(z))",if aList :,87
4277,"def get_tokens_unprocessed(self, text): <TAB> from pygments.lexers._cocoa_builtins import ( <TAB>  <TAB> COCOA_INTERFACES, <TAB>  <TAB> COCOA_PROTOCOLS, <TAB>  <TAB> COCOA_PRIMITIVES, <TAB> ) <TAB> for index, token, value in RegexLexer.get_tokens_unprocessed(self, text): <MASK> if ( <TAB>  <TAB>  <TAB>  <TAB> value in COCOA_INTERFACES <TAB>  <TAB>  <TAB>  <TAB> or value in COCOA_PROTOCOLS <TAB>  <TAB>  <TAB>  <TAB> or value in COCOA_PRIMITIVES <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> token = Name.Builtin.Pseudo <TAB>  <TAB> yield index, token, value",if token is Name or token is Name . Class :,176
4278,"def key_from_key_value_dict(key_info): <TAB> res = [] <TAB> if not ""key_value"" in key_info: <TAB>  <TAB> return res <TAB> for value in key_info[""key_value""]: <MASK> e = base64_to_long(value[""rsa_key_value""][""exponent""]) <TAB>  <TAB>  <TAB> m = base64_to_long(value[""rsa_key_value""][""modulus""]) <TAB>  <TAB>  <TAB> key = RSA.construct((m, e)) <TAB>  <TAB>  <TAB> res.append(key) <TAB> return res","if ""rsa_key_value"" in value :",141
4279,"def run(self, edit): <TAB> if not self.has_selection(): <TAB>  <TAB> region = sublime.Region(0, self.view.size()) <TAB>  <TAB> originalBuffer = self.view.substr(region) <TAB>  <TAB> prefixed = self.prefix(originalBuffer) <MASK> self.view.replace(edit, region, prefixed) <TAB>  <TAB> return <TAB> for region in self.view.sel(): <TAB>  <TAB> if region.empty(): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> originalBuffer = self.view.substr(region) <TAB>  <TAB> prefixed = self.prefix(originalBuffer) <TAB>  <TAB> if prefixed: <TAB>  <TAB>  <TAB> self.view.replace(edit, region, prefixed)",if prefixed :,163
4280,def finalize(self): <TAB> if self.ct < 1: <TAB>  <TAB> return <TAB> elif self.ct == 1: <TAB>  <TAB> return 0 <TAB> total = ct = 0 <TAB> dtp = None <TAB> while self.heap: <MASK> if dtp is None: <TAB>  <TAB>  <TAB>  <TAB> dtp = heapq.heappop(self.heap) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> dt = heapq.heappop(self.heap) <TAB>  <TAB> diff = dt - dtp <TAB>  <TAB> ct += 1 <TAB>  <TAB> total += total_seconds(diff) <TAB>  <TAB> dtp = dt <TAB> return float(total) / ct,if total == 0 :,150
4281,"def _test_configuration(self): <TAB> config_path = self._write_config() <TAB> try: <TAB>  <TAB> self._log.debug(""testing configuration"") <TAB>  <TAB> verboseflag = ""-Q"" <MASK> verboseflag = ""-v"" <TAB>  <TAB> p = subprocess.Popen([self.PATH_SLAPTEST, verboseflag, ""-f"", config_path]) <TAB>  <TAB> if p.wait() != 0: <TAB>  <TAB>  <TAB> raise RuntimeError(""configuration test failed"") <TAB>  <TAB> self._log.debug(""configuration seems ok"") <TAB> finally: <TAB>  <TAB> os.remove(config_path)",if self . _log . isEnabledFor ( logging . DEBUG ) :,147
4282,"def exe(self, ret): <TAB> if not ret: <TAB>  <TAB> self.assertEqual(ret, """") <TAB> else: <TAB>  <TAB> assert os.path.isabs(ret), ret <TAB>  <TAB> # Note: os.stat() may return False even if the file is there <TAB>  <TAB> # hence we skip the test, see: <TAB>  <TAB> # http://stackoverflow.com/questions/3112546/os-path-exists-lies <MASK> assert os.path.isfile(ret), ret <TAB>  <TAB>  <TAB> if hasattr(os, ""access"") and hasattr(os, ""X_OK""): <TAB>  <TAB>  <TAB>  <TAB> # XXX may fail on OSX <TAB>  <TAB>  <TAB>  <TAB> self.assertTrue(os.access(ret, os.X_OK))",if POSIX :,171
4283,"def _do_cleanup(sg_name, device_id): <TAB> masking_view_list = self.rest.get_masking_views_from_storage_group(array, sg_name) <TAB> for masking_view in masking_view_list: <MASK> self.rest.delete_masking_view(array, masking_view) <TAB>  <TAB>  <TAB> self.rest.remove_vol_from_sg(array, sg_name, device_id, extra_specs) <TAB>  <TAB>  <TAB> self.rest.delete_volume(array, device_id) <TAB>  <TAB>  <TAB> self.rest.delete_storage_group(array, sg_name)","if ""STG-"" in masking_view :",159
4284,"def hide_tooltip_if_necessary(self, key): <TAB> """"""Hide calltip when necessary"""""" <TAB> try: <TAB>  <TAB> calltip_char = self.get_character(self.calltip_position) <TAB>  <TAB> before = self.is_cursor_before(self.calltip_position, char_offset=1) <TAB>  <TAB> other = key in (Qt.Key_ParenRight, Qt.Key_Period, Qt.Key_Tab) <MASK> QToolTip.hideText() <TAB> except (IndexError, TypeError): <TAB>  <TAB> QToolTip.hideText()","if calltip_char not in ( ""?"" , ""("" ) or before or other :",148
4285,"def list_tags_for_stream(self, stream_name, exclusive_start_tag_key=None, limit=None): <TAB> stream = self.describe_stream(stream_name) <TAB> tags = [] <TAB> result = {""HasMoreTags"": False, ""Tags"": tags} <TAB> for key, val in sorted(stream.tags.items(), key=lambda x: x[0]): <TAB>  <TAB> if limit and len(tags) >= limit: <TAB>  <TAB>  <TAB> result[""HasMoreTags""] = True <TAB>  <TAB>  <TAB> break <MASK> continue <TAB>  <TAB> tags.append({""Key"": key, ""Value"": val}) <TAB> return result",if exclusive_start_tag_key and key < exclusive_start_tag_key :,166
4286,"def parametrize_function_name(request, function_name): <TAB> suffixes = [] <TAB> if ""parametrize"" in request.keywords: <TAB>  <TAB> argnames = request.keywords[""parametrize""].args[::2] <TAB>  <TAB> argnames = [x.strip() for names in argnames for x in names.split("","")] <TAB>  <TAB> for name in argnames: <TAB>  <TAB>  <TAB> value = request.getfuncargvalue(name) <MASK> value = value.__name__ <TAB>  <TAB>  <TAB> suffixes.append(""{}={}"".format(name, value)) <TAB> return ""+"".join([function_name] + suffixes)",if inspect . isclass ( value ) :,145
4287,"def add_entities(self, positions): <TAB> e1 = EntityFactory() <TAB> for p in positions: <MASK> start, length = p <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> start, length = p, 1 <TAB>  <TAB> EntityOccurrenceFactory( <TAB>  <TAB>  <TAB> document=self.doc, <TAB>  <TAB>  <TAB> entity=e1, <TAB>  <TAB>  <TAB> offset=start, <TAB>  <TAB>  <TAB> offset_end=start + length, <TAB>  <TAB>  <TAB> alias=""AB"", <TAB>  <TAB> )","if isinstance ( p , tuple ) :",119
4288,"def transform_value(value): <TAB> if isinstance(value, collections.MutableMapping): <MASK> return DBRef(value[""_ns""], transform_value(value[""_id""])) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return transform_dict(SON(value)) <TAB> elif isinstance(value, list): <TAB>  <TAB> return [transform_value(v) for v in value] <TAB> return value","if ""_id"" in value and ""_ns"" in value :",103
4289,"def remove(self, items): <TAB> """"""Remove messages from lease management."""""" <TAB> with self._add_remove_lock: <TAB>  <TAB> # Remove the ack ID from lease management, and decrement the <TAB>  <TAB> # byte counter. <TAB>  <TAB> for item in items: <TAB>  <TAB>  <TAB> if self._leased_messages.pop(item.ack_id, None) is not None: <TAB>  <TAB>  <TAB>  <TAB> self._bytes -= item.byte_size <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> _LOGGER.debug(""Item %s was not managed."", item.ack_id) <MASK> _LOGGER.debug(""Bytes was unexpectedly negative: %d"", self._bytes) <TAB>  <TAB>  <TAB> self._bytes = 0",if self . _bytes < 0 :,172
4290,"def parse_hgsub(lines): <TAB> """"""Fills OrderedDict with hgsub file content passed as list of lines"""""" <TAB> rv = OrderedDict() <TAB> for l in lines: <TAB>  <TAB> ls = l.strip() <MASK> continue <TAB>  <TAB> name, value = l.split(""="", 1) <TAB>  <TAB> rv[name.strip()] = value.strip() <TAB> return rv","if not ls or ls [ 0 ] == ""#"" :",98
4291,"def del_(self, key): <TAB> initial_hash = hash_ = self.hash(key) <TAB> while True: <TAB>  <TAB> if self._keys[hash_] is self._empty: <TAB>  <TAB>  <TAB> # That key was never assigned <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> elif self._keys[hash_] == key: <TAB>  <TAB>  <TAB> # key found, assign with deleted sentinel <TAB>  <TAB>  <TAB> self._keys[hash_] = self._deleted <TAB>  <TAB>  <TAB> self._values[hash_] = self._deleted <TAB>  <TAB>  <TAB> self._len -= 1 <TAB>  <TAB>  <TAB> return <TAB>  <TAB> hash_ = self._rehash(hash_) <MASK> # table is full and wrapped around <TAB>  <TAB>  <TAB> return None",if initial_hash == hash_ :,166
4292,"def atom(token, no_symbol=False): <TAB> try: <TAB>  <TAB> return int(token) <TAB> except ValueError: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return float(token) <TAB>  <TAB> except ValueError: <MASK> return token[1:-1] <TAB>  <TAB>  <TAB> elif no_symbol: <TAB>  <TAB>  <TAB>  <TAB> return token <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return Symbol(token)","if token . startswith ( ""'"" ) or token . startswith ( '""' ) :",107
4293,"def __Suffix_Noun_Step1b(self, token): <TAB> for suffix in self.__suffix_noun_step1b: <MASK> token = token[:-1] <TAB>  <TAB>  <TAB> self.suffixe_noun_step1b_success = True <TAB>  <TAB>  <TAB> break <TAB> return token",if token . endswith ( suffix ) and len ( token ) > 5 :,87
4294,"def _guardAgainstUnicode(self, data): <TAB> # Only accept byte strings or ascii unicode values, otherwise <TAB> # there is no way to correctly decode the data into bytes. <TAB> if _pythonMajorVersion < 3: <MASK> data = data.encode(""utf8"") <TAB> else: <TAB>  <TAB> if isinstance(data, str): <TAB>  <TAB>  <TAB> # Only accept ascii unicode values. <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> return data.encode(""ascii"") <TAB>  <TAB>  <TAB> except UnicodeEncodeError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> raise ValueError(""pyDes can only work with encoded strings, not Unicode."") <TAB> return data","if isinstance ( data , unicode ) :",154
4295,"def populate_resource_parameters(self, tool_source): <TAB> root = getattr(tool_source, ""root"", None) <TAB> if ( <TAB>  <TAB> root is not None <TAB>  <TAB> and hasattr(self.app, ""job_config"") <TAB>  <TAB> and hasattr(self.app.job_config, ""get_tool_resource_xml"") <TAB> ): <TAB>  <TAB> resource_xml = self.app.job_config.get_tool_resource_xml( <TAB>  <TAB>  <TAB> root.get(""id""), self.tool_type <TAB>  <TAB> ) <TAB>  <TAB> if resource_xml is not None: <TAB>  <TAB>  <TAB> inputs = root.find(""inputs"") <MASK> inputs = parse_xml_string(""<inputs/>"") <TAB>  <TAB>  <TAB>  <TAB> root.append(inputs) <TAB>  <TAB>  <TAB> inputs.append(resource_xml)",if inputs is None :,194
4296,"def test_arguments_regex(self): <TAB> argument_matches = ( <TAB>  <TAB> (""pip=1.1"", (""pip"", ""1.1"")), <TAB>  <TAB> (""pip==1.1"", None), <TAB>  <TAB> (""pip=1.2=1"", (""pip"", ""1.2=1"")), <TAB> ) <TAB> for argument, match in argument_matches: <MASK> self.assertIsNone(salt.utils.args.KWARG_REGEX.match(argument)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertEqual( <TAB>  <TAB>  <TAB>  <TAB> salt.utils.args.KWARG_REGEX.match(argument).groups(), match <TAB>  <TAB>  <TAB> )",if match is None :,157
4297,"def _get_sidebar_selected(self): <TAB> sidebar_selected = None <TAB> if self.businessline_id: <TAB>  <TAB> sidebar_selected = ""bl_%s"" % self.businessline_id <TAB>  <TAB> if self.service_id: <TAB>  <TAB>  <TAB> sidebar_selected += ""_s_%s"" % self.service_id <MASK> sidebar_selected += ""_env_%s"" % self.environment_id <TAB> return sidebar_selected",if self . environment_id :,113
4298,"def get_ip_info(ipaddress): <TAB> """"""Returns device information by IP address"""""" <TAB> result = {} <TAB> try: <TAB>  <TAB> ip = IPAddress.objects.select_related().get(address=ipaddress) <TAB> except IPAddress.DoesNotExist: <TAB>  <TAB> pass <TAB> else: <TAB>  <TAB> if ip.venture is not None: <TAB>  <TAB>  <TAB> result[""venture_id""] = ip.venture.id <MASK> result[""device_id""] = ip.device.id <TAB>  <TAB>  <TAB> if ip.device.venture is not None: <TAB>  <TAB>  <TAB>  <TAB> result[""venture_id""] = ip.device.venture.id <TAB> return result",if ip . device is not None :,162
4299,"def apply(self, db, person): <TAB> for family_handle in person.get_family_handle_list(): <TAB>  <TAB> family = db.get_family_from_handle(family_handle) <TAB>  <TAB> if family: <TAB>  <TAB>  <TAB> for event_ref in family.get_event_ref_list(): <TAB>  <TAB>  <TAB>  <TAB> if event_ref: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> event = db.get_event_from_handle(event_ref.ref) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if not event.get_place_handle(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <MASK> return True <TAB> return False",if not event . get_date_object ( ) :,159
4300,"def killIfDead(): <TAB> if not self._isalive: <TAB>  <TAB> self.log.debug( <TAB>  <TAB>  <TAB> ""WampLongPoll: killing inactive WAMP session with transport '{0}'"".format( <TAB>  <TAB>  <TAB>  <TAB> self._transport_id <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB>  <TAB> self.onClose(False, 5000, ""session inactive"") <TAB>  <TAB> self._receive._kill() <MASK> del self._parent._transports[self._transport_id] <TAB> else: <TAB>  <TAB> self.log.debug( <TAB>  <TAB>  <TAB> ""WampLongPoll: transport '{0}' is still alive"".format(self._transport_id) <TAB>  <TAB> ) <TAB>  <TAB> self._isalive = False <TAB>  <TAB> self.reactor.callLater(killAfter, killIfDead)",if self . _transport_id in self . _parent . _transports :,196
4301,"def offsets(self): <TAB> offsets = {} <TAB> offset_so_far = 0 <TAB> for name, ty in self.fields.items(): <MASK> l.warning( <TAB>  <TAB>  <TAB>  <TAB> ""Found a bottom field in struct %s. Ignore and increment the offset using the default "" <TAB>  <TAB>  <TAB>  <TAB> ""element size."", <TAB>  <TAB>  <TAB>  <TAB> self.name, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if not self._pack: <TAB>  <TAB>  <TAB> align = ty.alignment <TAB>  <TAB>  <TAB> if offset_so_far % align != 0: <TAB>  <TAB>  <TAB>  <TAB> offset_so_far += align - offset_so_far % align <TAB>  <TAB> offsets[name] = offset_so_far <TAB>  <TAB> offset_so_far += ty.size // self._arch.byte_width <TAB> return offsets","if isinstance ( ty , SimTypeBottom ) :",196
4302,"def get_override_css(self): <TAB> """"""handls allow_css_overrides setting."""""" <TAB> if self.settings.get(""allow_css_overrides""): <TAB>  <TAB> filename = self.view.file_name() <TAB>  <TAB> filetypes = self.settings.get(""markdown_filetypes"") <MASK> for filetype in filetypes: <TAB>  <TAB>  <TAB>  <TAB> if filename.endswith(filetype): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> css_filename = filename.rpartition(filetype)[0] + "".css"" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if os.path.isfile(css_filename): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return u""<style>%s</style>"" % load_utf8(css_filename) <TAB> return """"",if filename and filetypes :,165
4303,"def setFullCSSSource(self, fullsrc, inline=False): <TAB> self.fullsrc = fullsrc <TAB> if type(self.fullsrc) == six.binary_type: <TAB>  <TAB> self.fullsrc = six.text_type(self.fullsrc, ""utf-8"") <TAB> if inline: <TAB>  <TAB> self.inline = inline <TAB> if self.fullsrc: <TAB>  <TAB> self.srcFullIdx = self.fullsrc.find(self.src) <TAB>  <TAB> if self.srcFullIdx < 0: <TAB>  <TAB>  <TAB> del self.srcFullIdx <TAB>  <TAB> self.ctxsrcFullIdx = self.fullsrc.find(self.ctxsrc) <MASK> del self.ctxsrcFullIdx",if self . ctxsrcFullIdx < 0 :,175
4304,"def title(self): <TAB> ret = theme[""title""] <TAB> if isinstance(self.name, six.string_types): <TAB>  <TAB> width = self.statwidth() <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB> ret + self.name[0:width].center(width).replace("" "", ""-"") + theme[""default""] <TAB>  <TAB> ) <TAB> for i, name in enumerate(self.name): <TAB>  <TAB> width = self.colwidth() <TAB>  <TAB> ret = ret + name[0:width].center(width).replace("" "", ""-"") <TAB>  <TAB> if i + 1 != len(self.vars): <MASK> ret = ret + theme[""frame""] + char[""dash""] + theme[""title""] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> ret = ret + char[""space""] <TAB> return ret",if op . color :,188
4305,"def _get_requested_databases(self): <TAB> """"""Returns a list of databases requested, not including ignored dbs"""""" <TAB> requested_databases = [] <TAB> if (self._requested_namespaces is not None) and (self._requested_namespaces != []): <TAB>  <TAB> for requested_namespace in self._requested_namespaces: <MASK> return [] <TAB>  <TAB>  <TAB> elif requested_namespace[0] not in IGNORE_DBS: <TAB>  <TAB>  <TAB>  <TAB> requested_databases.append(requested_namespace[0]) <TAB> return requested_databases","if requested_namespace [ 0 ] is ""*"" :",131
4306,"def add_channels(cls, voucher, add_channels): <TAB> for add_channel in add_channels: <TAB>  <TAB> channel = add_channel[""channel""] <TAB>  <TAB> defaults = {""currency"": channel.currency_code} <MASK> defaults[""discount_value""] = add_channel.get(""discount_value"") <TAB>  <TAB> if ""min_amount_spent"" in add_channel.keys(): <TAB>  <TAB>  <TAB> defaults[""min_spent_amount""] = add_channel.get(""min_amount_spent"", None) <TAB>  <TAB> models.VoucherChannelListing.objects.update_or_create( <TAB>  <TAB>  <TAB> voucher=voucher, <TAB>  <TAB>  <TAB> channel=channel, <TAB>  <TAB>  <TAB> defaults=defaults, <TAB>  <TAB> )","if ""discount_value"" in add_channel . keys ( ) :",176
4307,"def read_xml(path): <TAB> with tf.gfile.GFile(path) as f: <TAB>  <TAB> root = etree.fromstring(f.read()) <TAB> annotations = {} <TAB> for node in root.getchildren(): <TAB>  <TAB> key, val = node2dict(node) <TAB>  <TAB> # If `key` is object, it's actually a list. <MASK> annotations.setdefault(key, []).append(val) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> annotations[key] = val <TAB> return annotations","if key == ""object"" :",123
4308,"def get_ip_info(ipaddress): <TAB> """"""Returns device information by IP address"""""" <TAB> result = {} <TAB> try: <TAB>  <TAB> ip = IPAddress.objects.select_related().get(address=ipaddress) <TAB> except IPAddress.DoesNotExist: <TAB>  <TAB> pass <TAB> else: <MASK> result[""venture_id""] = ip.venture.id <TAB>  <TAB> if ip.device is not None: <TAB>  <TAB>  <TAB> result[""device_id""] = ip.device.id <TAB>  <TAB>  <TAB> if ip.device.venture is not None: <TAB>  <TAB>  <TAB>  <TAB> result[""venture_id""] = ip.device.venture.id <TAB> return result",if ip . venture is not None :,162
4309,"def test_large_headers(self): <TAB> with ExpectLog(gen_log, ""Unsatisfiable read"", required=False): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.fetch(""/"", headers={""X-Filler"": ""a"" * 1000}, raise_error=True) <TAB>  <TAB>  <TAB> self.fail(""did not raise expected exception"") <TAB>  <TAB> except HTTPError as e: <TAB>  <TAB>  <TAB> # 431 is ""Request Header Fields Too Large"", defined in RFC <TAB>  <TAB>  <TAB> # 6585. However, many implementations just close the <TAB>  <TAB>  <TAB> # connection in this case, resulting in a missing response. <MASK> self.assertIn(e.response.code, (431, 599))",if e . response is not None :,167
4310,"def validate_reserved_serial_no_consumption(self): <TAB> for item in self.items: <TAB>  <TAB> if item.s_warehouse and not item.t_warehouse and item.serial_no: <TAB>  <TAB>  <TAB> for sr in get_serial_nos(item.serial_no): <TAB>  <TAB>  <TAB>  <TAB> sales_order = frappe.db.get_value(""Serial No"", sr, ""sales_order"") <MASK> msg = _( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""(Serial No: {0}) cannot be consumed as it's reserverd to fullfill Sales Order {1}."" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ).format(sr, sales_order) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> frappe.throw(_(""Item {0} {1}"").format(item.item_code, msg))",if sales_order :,190
4311,"def force_decode(string, encoding): <TAB> if isinstance(string, str): <MASK> string = string.decode(encoding) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> # try decoding with utf-8, should only work for real UTF-8 <TAB>  <TAB>  <TAB>  <TAB> string = string.decode(""utf-8"") <TAB>  <TAB>  <TAB> except UnicodeError: <TAB>  <TAB>  <TAB>  <TAB> # last resort -- can't fail <TAB>  <TAB>  <TAB>  <TAB> string = string.decode(""latin1"") <TAB> return string",if encoding :,121
4312,"def _add_cs(master_cs, sub_cs, prefix, delimiter=""."", parent_hp=None): <TAB> new_parameters = [] <TAB> for hp in sub_cs.get_hyperparameters(): <TAB>  <TAB> new_parameter = copy.deepcopy(hp) <TAB>  <TAB> # Allow for an empty top-level parameter <TAB>  <TAB> if new_parameter.name == """": <TAB>  <TAB>  <TAB> new_parameter.name = prefix <MASK> new_parameter.name = ""{}{}{}"".format(prefix, SPLITTER, new_parameter.name) <TAB>  <TAB> new_parameters.append(new_parameter) <TAB> for hp in new_parameters: <TAB>  <TAB> _add_hp(master_cs, hp)","elif not prefix == """" :",162
4313,"def __call__(self, *args, **kwargs): <TAB> if self.log_file is not None: <TAB>  <TAB> kwargs[""file""] = self.log_file <TAB>  <TAB> print(*args, **kwargs) <MASK> # get immediate feedback <TAB>  <TAB>  <TAB> self.log_file.flush() <TAB> elif self.log_func is not None: <TAB>  <TAB> self.log_func(*args, **kwargs)","if hasattr ( self . log_file , ""flush"" ) :",109
4314,"def df_index_expr(self, length_expr=None, as_range=False): <TAB> """"""Generate expression to get or create index of DF"""""" <TAB> if isinstance(self.index, types.NoneType): <MASK> length_expr = df_length_expr(self) <TAB>  <TAB> if as_range: <TAB>  <TAB>  <TAB> return f""range({length_expr})"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return f""numpy.arange({length_expr})"" <TAB> return ""self._index""",if length_expr is None :,123
4315,"def _setWeight(self, value): <TAB> if value is None: <TAB>  <TAB> self._fontWeight = None <TAB> else: <MASK> raise TextFormatException(f""Not a supported fontWeight: {value}"") <TAB>  <TAB> self._fontWeight = value.lower()","if value . lower ( ) not in ( ""normal"" , ""bold"" ) :",78
4316,"def _test_configuration(self): <TAB> config_path = self._write_config() <TAB> try: <TAB>  <TAB> self._log.debug(""testing configuration"") <TAB>  <TAB> verboseflag = ""-Q"" <TAB>  <TAB> if self._log.isEnabledFor(logging.DEBUG): <TAB>  <TAB>  <TAB> verboseflag = ""-v"" <TAB>  <TAB> p = subprocess.Popen([self.PATH_SLAPTEST, verboseflag, ""-f"", config_path]) <MASK> raise RuntimeError(""configuration test failed"") <TAB>  <TAB> self._log.debug(""configuration seems ok"") <TAB> finally: <TAB>  <TAB> os.remove(config_path)",if p . wait ( ) != 0 :,147
4317,"def filter_queryset(self, request, queryset, view): <TAB> kwargs = {} <TAB> for field in view.filterset_fields: <TAB>  <TAB> value = request.GET.get(field) <TAB>  <TAB> if not value: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if field == ""node_id"": <TAB>  <TAB>  <TAB> value = get_object_or_none(Node, pk=value) <TAB>  <TAB>  <TAB> kwargs[""node""] = value <TAB>  <TAB>  <TAB> continue <MASK> field = ""asset"" <TAB>  <TAB> kwargs[field] = value <TAB> if kwargs: <TAB>  <TAB> queryset = queryset.filter(**kwargs) <TAB> logger.debug(""Filter {}"".format(kwargs)) <TAB> return queryset","elif field == ""asset_id"" :",162
4318,"def _find_closing_brace(string, start_pos): <TAB> """"""Finds the corresponding closing brace after start_pos."""""" <TAB> bracks_open = 1 <TAB> for idx, char in enumerate(string[start_pos:]): <TAB>  <TAB> if char == ""("": <MASK> bracks_open += 1 <TAB>  <TAB> elif char == "")"": <TAB>  <TAB>  <TAB> if string[idx + start_pos - 1] != ""\\"": <TAB>  <TAB>  <TAB>  <TAB> bracks_open -= 1 <TAB>  <TAB>  <TAB> if not bracks_open: <TAB>  <TAB>  <TAB>  <TAB> return start_pos + idx + 1","if string [ idx + start_pos - 1 ] != ""\\"" :",145
4319,"def _set_hostport(self, host, port): <TAB> if port is None: <TAB>  <TAB> i = host.rfind("":"") <TAB>  <TAB> j = host.rfind(""]"")  # ipv6 addresses have [...] <TAB>  <TAB> if i > j: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> port = int(host[i + 1 :]) <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> raise InvalidURL(""nonnumeric port: '%s'"" % host[i + 1 :]) <TAB>  <TAB>  <TAB> host = host[:i] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> port = self.default_port <MASK> host = host[1:-1] <TAB> self.host = host <TAB> self.port = port","if host and host [ 0 ] == ""["" and host [ - 1 ] == ""]"" :",176
4320,"def __getstate__(self): <TAB> state = {} <TAB> for cls in type(self).mro(): <TAB>  <TAB> cls_slots = getattr(cls, ""__slots__"", ()) <TAB>  <TAB> for slot in cls_slots: <TAB>  <TAB>  <TAB> if slot != ""__weakref__"": <MASK> state[slot] = getattr(self, slot) <TAB> state[""_cookiejar_cookies""] = list(self.cookiejar) <TAB> del state[""cookiejar""] <TAB> return state","if hasattr ( self , slot ) :",113
4321,"def _evp_pkey_from_der_traditional_key(self, bio_data, password): <TAB> key = self._lib.d2i_PrivateKey_bio(bio_data.bio, self._ffi.NULL) <TAB> if key != self._ffi.NULL: <TAB>  <TAB> key = self._ffi.gc(key, self._lib.EVP_PKEY_free) <MASK> raise TypeError(""Password was given but private key is not encrypted."") <TAB>  <TAB> return key <TAB> else: <TAB>  <TAB> self._consume_errors() <TAB>  <TAB> return None",if password is not None :,142
4322,"def is_special(s, i, directive): <TAB> """"""Return True if the body text contains the @ directive."""""" <TAB> # j = skip_line(s,i) ; trace(s[i:j],':',directive) <TAB> assert directive and directive[0] == ""@"" <TAB> # 10/23/02: all directives except @others must start the line. <TAB> skip_flag = directive in (""@others"", ""@all"") <TAB> while i < len(s): <MASK> return True, i <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> i = skip_line(s, i) <TAB>  <TAB>  <TAB> if skip_flag: <TAB>  <TAB>  <TAB>  <TAB> i = skip_ws(s, i) <TAB> return False, -1","if match_word ( s , i , directive ) :",178
4323,"def _decorator(coro_func): <TAB> fut = asyncio.ensure_future(coro_func()) <TAB> self._tests.append((coro_func.__name__, fut)) <TAB> if timeout_sec is not None: <TAB>  <TAB> timeout_at = self._loop.time() + timeout_sec <TAB>  <TAB> handle = self.MASTER_LOOP.call_at( <TAB>  <TAB>  <TAB> timeout_at, self._set_exception_if_not_done, fut, asyncio.TimeoutError() <TAB>  <TAB> ) <TAB>  <TAB> fut.add_done_callback(lambda *args: handle.cancel()) <MASK> self._global_timeout_at = timeout_at <TAB> return coro_func",if timeout_at > self . _global_timeout_at :,171
4324,"def _load(self, db, owner): <TAB> self.__init(owner) <TAB> db_result = db( <TAB>  <TAB> ""SELECT ship_id, state_id FROM ai_combat_ship WHERE owner_id = ?"", <TAB>  <TAB> self.owner.worldid, <TAB> ) <TAB> for ( <TAB>  <TAB> ship_id, <TAB>  <TAB> state_id, <TAB> ) in db_result: <TAB>  <TAB> ship = WorldObject.get_object_by_id(ship_id) <TAB>  <TAB> state = self.shipStates[state_id] <TAB>  <TAB> # add move callbacks corresponding to given state <MASK> ship.add_move_callback(Callback(BehaviorMoveCallback._arrived, ship)) <TAB>  <TAB> self.add_new_unit(ship, state)",if state == self . shipStates . moving :,188
4325,"def addError(self, test, err): <TAB> if err[0] is SkipTest: <MASK> self.stream.writeln(str(err[1])) <TAB>  <TAB> elif self.dots: <TAB>  <TAB>  <TAB> self.stream.write(""s"") <TAB>  <TAB>  <TAB> self.stream.flush() <TAB>  <TAB> return <TAB> _org_AddError(self, test, err)",if self . showAll :,93
4326,"def _construct(self, node): <TAB> self.flatten_mapping(node) <TAB> ret = self.construct_pairs(node) <TAB> keys = [d[0] for d in ret] <TAB> keys_sorted = sorted(keys, key=_natsort_key) <TAB> for key in keys: <TAB>  <TAB> expected = keys_sorted.pop(0) <MASK> raise ConstructorError( <TAB>  <TAB>  <TAB>  <TAB> None, <TAB>  <TAB>  <TAB>  <TAB> None, <TAB>  <TAB>  <TAB>  <TAB> ""keys out of order: "" <TAB>  <TAB>  <TAB>  <TAB> ""expected {} got {} at {}"".format(expected, key, node.start_mark), <TAB>  <TAB>  <TAB> ) <TAB> return dict(ret)",if key != expected :,159
4327,"def sample_pos_items_for_u(u, num): <TAB> # sample num pos items for u-th user <TAB> pos_items = self.train_items[u] <TAB> n_pos_items = len(pos_items) <TAB> pos_batch = [] <TAB> while True: <TAB>  <TAB> if len(pos_batch) == num: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> pos_id = np.random.randint(low=0, high=n_pos_items, size=1)[0] <TAB>  <TAB> pos_i_id = pos_items[pos_id] <MASK> pos_batch.append(pos_i_id) <TAB> return pos_batch",if pos_i_id not in pos_batch :,171
4328,"def _get_id(self, type, id): <TAB> fields = id.split("":"") <TAB> if len(fields) >= 3: <MASK> logger.warning( <TAB>  <TAB>  <TAB>  <TAB> ""Expected id of type %s but found type %s %s"", type, fields[-2], id <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return fields[-1] <TAB> fields = id.split(""/"") <TAB> if len(fields) >= 3: <TAB>  <TAB> itype = fields[-2] <TAB>  <TAB> if type != itype: <TAB>  <TAB>  <TAB> logger.warning( <TAB>  <TAB>  <TAB>  <TAB> ""Expected id of type %s but found type %s %s"", type, itype, id <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return fields[-1].split(""?"")[0] <TAB> return id",if type != fields [ - 2 ] :,178
4329,"def uninstall_environments(self, environments): <TAB> environments = [ <TAB>  <TAB> env <TAB>  <TAB> if not env.startswith(self.conda_context.envs_path) <TAB>  <TAB> else os.path.basename(env) <TAB>  <TAB> for env in environments <TAB> ] <TAB> return_codes = [self.conda_context.exec_remove([env]) for env in environments] <TAB> final_return_code = 0 <TAB> for env, return_code in zip(environments, return_codes): <MASK> log.debug(""Conda environment '%s' successfully removed."" % env) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.debug(""Conda environment '%s' could not be removed."" % env) <TAB>  <TAB>  <TAB> final_return_code = return_code <TAB> return final_return_code",if return_code == 0 :,191
4330,"def _add_hit_offset(self, context_list, string_name, original_offset, value): <TAB> for context in context_list: <TAB>  <TAB> hits_by_context_dict = self.hits_by_context.setdefault(context, {}) <MASK> hits_by_context_dict[string_name] = ( <TAB>  <TAB>  <TAB>  <TAB> original_offset, <TAB>  <TAB>  <TAB>  <TAB> value.encode(""base64""), <TAB>  <TAB>  <TAB> )",if string_name not in hits_by_context_dict :,119
4331,"def detab(self, text, length=None): <TAB> """"""Remove a tab from the front of each line of the given text."""""" <TAB> if length is None: <TAB>  <TAB> length = self.tab_length <TAB> newtext = [] <TAB> lines = text.split(""\n"") <TAB> for line in lines: <TAB>  <TAB> if line.startswith("" "" * length): <TAB>  <TAB>  <TAB> newtext.append(line[length:]) <MASK> newtext.append("""") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> return ""\n"".join(newtext), ""\n"".join(lines[len(newtext) :])",elif not line . strip ( ) :,147
4332,"def dump(self): <TAB> print(self.package_name) <TAB> for package, value in self.entries: <TAB>  <TAB> print(str(package.version)) <MASK> print("" <TAB> [FILTERED]"") <TAB>  <TAB> elif isinstance(value, list): <TAB>  <TAB>  <TAB> variants = value <TAB>  <TAB>  <TAB> for variant in variants: <TAB>  <TAB>  <TAB>  <TAB> print("" <TAB> %s"" % str(variant)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print("" <TAB> %s"" % str(package))",if value is None :,125
4333,"def __lexical_scope(*args, **kwargs): <TAB> try: <TAB>  <TAB> scope = Scope(quasi) <MASK> binding_name_set_stack[-1].add_child(scope) <TAB>  <TAB> binding_name_set_stack.append(scope) <TAB>  <TAB> return func(*args, **kwargs) <TAB> finally: <TAB>  <TAB> if binding_name_set_stack[-1] is scope: <TAB>  <TAB>  <TAB> binding_name_set_stack.pop()",if quasi :,114
4334,"def getnotes(self, origin=None): <TAB> if origin is None: <TAB>  <TAB> result = self.translator_comments <MASK> if result: <TAB>  <TAB>  <TAB>  <TAB> result += ""\n"" + self.developer_comments <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> result = self.developer_comments <TAB>  <TAB> return result <TAB> elif origin == ""translator"": <TAB>  <TAB> return self.translator_comments <TAB> elif origin in (""programmer"", ""developer"", ""source code""): <TAB>  <TAB> return self.developer_comments <TAB> else: <TAB>  <TAB> raise ValueError(""Comment type not valid"")",if self . developer_comments :,141
4335,"def fix_datetime_fields(data: TableData, table: TableName) -> None: <TAB> for item in data[table]: <TAB>  <TAB> for field_name in DATE_FIELDS[table]: <MASK> item[field_name] = datetime.datetime.fromtimestamp( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> item[field_name], tz=datetime.timezone.utc <TAB>  <TAB>  <TAB>  <TAB> )",if item [ field_name ] is not None :,102
4336,"def _check_for_cart_error(cart): <TAB> if cart._safe_get_element(""Cart.Request.Errors"") is not None: <TAB>  <TAB> error = cart._safe_get_element(""Cart.Request.Errors.Error.Code"").text <MASK> raise CartInfoMismatchException( <TAB>  <TAB>  <TAB>  <TAB> ""CartGet failed: AWS.ECommerceService.CartInfoMismatch "" <TAB>  <TAB>  <TAB>  <TAB> ""make sure AssociateTag, CartId and HMAC are correct "" <TAB>  <TAB>  <TAB>  <TAB> ""(dont use URLEncodedHMAC!!!)"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> raise CartException(""CartGet failed: "" + error)","if error == ""AWS.ECommerceService.CartInfoMismatch"" :",165
4337,"def check_bounds(geometry): <TAB> if isinstance(geometry[0], (list, tuple)): <TAB>  <TAB> return list(map(check_bounds, geometry)) <TAB> else: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Longitude is out of bounds, check your JSON format or data"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if geometry[1] > 90 or geometry[1] < -90: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""Latitude is out of bounds, check your JSON format or data"" <TAB>  <TAB>  <TAB> )",if geometry [ 0 ] > 180 or geometry [ 0 ] < - 180 :,143
4338,"def _mapper_output_protocol(self, step_num, step_map): <TAB> map_key = self._step_key(step_num, ""mapper"") <TAB> if map_key in step_map: <MASK> return self.output_protocol() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.internal_protocol() <TAB> else: <TAB>  <TAB> # mapper is not a script substep, so protocols don't apply at all <TAB>  <TAB> return RawValueProtocol()",if step_map [ map_key ] >= ( len ( step_map ) - 1 ) :,130
4339,"def asset(*paths): <TAB> for path in paths: <TAB>  <TAB> fspath = www_root + ""/assets/"" + path <TAB>  <TAB> etag = """" <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if env.cache_static: <TAB>  <TAB>  <TAB>  <TAB> etag = asset_etag(fspath) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> os.stat(fspath) <TAB>  <TAB> except FileNotFoundError as e: <MASK> if not os.path.exists(fspath + "".spt""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> tell_sentry(e, {}) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> tell_sentry(e, {}) <TAB>  <TAB> return asset_url + path + (etag and ""?etag="" + etag)",if path == paths [ - 1 ] :,182
4340,"def ping(self, payload: Union[str, bytes] = """") -> None: <TAB> if self.trace_enabled and self.ping_pong_trace_enabled: <MASK> payload = payload.decode(""utf-8"") <TAB>  <TAB> self.logger.debug( <TAB>  <TAB>  <TAB> ""Sending a ping data frame "" <TAB>  <TAB>  <TAB> f""(session id: {self.session_id}, payload: {payload})"" <TAB>  <TAB> ) <TAB> data = _build_data_frame_for_sending(payload, FrameHeader.OPCODE_PING) <TAB> with self.sock_send_lock: <TAB>  <TAB> self.sock.send(data)","if isinstance ( payload , bytes ) :",155
4341,"def is_ac_power_connected(): <TAB> for power_source_path in Path(""/sys/class/power_supply/"").iterdir(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> with open(power_source_path / ""type"", ""r"") as f: <TAB>  <TAB>  <TAB>  <TAB> if f.read().strip() != ""Mains"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> with open(power_source_path / ""online"", ""r"") as f: <MASK> return True <TAB>  <TAB> except IOError: <TAB>  <TAB>  <TAB> continue <TAB> return False","if f . read ( 1 ) == ""1"" :",144
4342,"def handle_noargs(self, **options): <TAB> self.style = color_style() <TAB> print(""Running Django's own validation:"") <TAB> self.validate(display_num_errors=True) <TAB> for model in loading.get_models(): <MASK> self.validate_base_model(model) <TAB>  <TAB> if hasattr(model, ""_feincms_content_models""): <TAB>  <TAB>  <TAB> self.validate_content_type(model)","if hasattr ( model , ""_create_content_base"" ) :",117
4343,"def _init_weights(self, module): <TAB> if isinstance(module, nn.Linear): <TAB>  <TAB> module.weight.data.normal_(mean=0.0, std=self.config.init_std) <MASK> module.bias.data.zero_() <TAB> elif isinstance(module, nn.Embedding): <TAB>  <TAB> module.weight.data.normal_(mean=0.0, std=self.config.init_std) <TAB>  <TAB> if module.padding_idx is not None: <TAB>  <TAB>  <TAB> module.weight.data[module.padding_idx].zero_()",if module . bias is not None :,141
4344,"def walk(msg, callback, data): <TAB> partnum = 0 <TAB> for part in msg.walk(): <TAB>  <TAB> # multipart/* are just containers <TAB>  <TAB> if part.get_content_maintype() == ""multipart"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> ctype = part.get_content_type() <MASK> ctype = OCTET_TYPE <TAB>  <TAB> filename = part.get_filename() <TAB>  <TAB> if not filename: <TAB>  <TAB>  <TAB> filename = PART_FN_TPL % (partnum) <TAB>  <TAB> headers = dict(part) <TAB>  <TAB> LOG.debug(headers) <TAB>  <TAB> headers[""Content-Type""] = ctype <TAB>  <TAB> payload = util.fully_decoded_payload(part) <TAB>  <TAB> callback(data, filename, payload, headers) <TAB>  <TAB> partnum = partnum + 1",if ctype is None :,190
4345,"def _mark_lcs(mask, dirs, m, n): <TAB> while m != 0 and n != 0: <TAB>  <TAB> if dirs[m, n] == ""|"": <TAB>  <TAB>  <TAB> m -= 1 <TAB>  <TAB>  <TAB> n -= 1 <TAB>  <TAB>  <TAB> mask[m] = 1 <MASK> m -= 1 <TAB>  <TAB> elif dirs[m, n] == ""<"": <TAB>  <TAB>  <TAB> n -= 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise UnboundLocalError(""Illegal move"") <TAB> return mask","elif dirs [ m , n ] == ""^"" :",122
4346,"def valid_localparts(strip_delimiters=False): <TAB> for line in ABRIDGED_LOCALPART_VALID_TESTS.split(""\n""): <TAB>  <TAB> # strip line, skip over empty lines <TAB>  <TAB> line = line.strip() <MASK> continue <TAB>  <TAB> # skip over comments or empty lines <TAB>  <TAB> match = COMMENT.match(line) <TAB>  <TAB> if match: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # skip over localparts with delimiters <TAB>  <TAB> if strip_delimiters: <TAB>  <TAB>  <TAB> if "","" in line or "";"" in line: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> yield line","if line == """" :",145
4347,"def fetch(self, *tileables, **kw): <TAB> ret_list = False <TAB> if len(tileables) == 1 and isinstance(tileables[0], (tuple, list)): <TAB>  <TAB> ret_list = True <TAB>  <TAB> tileables = tileables[0] <TAB> elif len(tileables) > 1: <TAB>  <TAB> ret_list = True <TAB> result = self._sess.fetch(*tileables, **kw) <TAB> ret = [] <TAB> for r, t in zip(result, tileables): <MASK> ret.append(r.item()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret.append(r) <TAB> if ret_list: <TAB>  <TAB> return ret <TAB> return ret[0]","if hasattr ( t , ""isscalar"" ) and t . isscalar ( ) and getattr ( r , ""size"" , None ) == 1 :",183
4348,"def _convert(container): <TAB> if _value_marker in container: <TAB>  <TAB> force_list = False <TAB>  <TAB> values = container.pop(_value_marker) <TAB>  <TAB> if container.pop(_list_marker, False): <TAB>  <TAB>  <TAB> force_list = True <TAB>  <TAB>  <TAB> values.extend(_convert(x[1]) for x in sorted(container.items())) <MASK> values = values[0] <TAB>  <TAB> if not container: <TAB>  <TAB>  <TAB> return values <TAB>  <TAB> return _convert(container) <TAB> elif container.pop(_list_marker, False): <TAB>  <TAB> return [_convert(x[1]) for x in sorted(container.items())] <TAB> return dict_cls((k, _convert(v)) for k, v in iteritems(container))",if not force_list and len ( values ) == 1 :,188
4349,"def _transform_init_kwargs(cls, kwargs): <TAB> transformed = [] <TAB> for field in list(kwargs.keys()): <TAB>  <TAB> prop = getattr(cls, field, None) <MASK> value = kwargs.pop(field) <TAB>  <TAB>  <TAB> _transform_single_init_kwarg(prop, field, value, kwargs) <TAB>  <TAB>  <TAB> transformed.append((field, value)) <TAB> return transformed","if isinstance ( prop , MoneyProperty ) :",102
4350,"def haslayer(self, cls): <TAB> """"""true if self has a layer that is an instance of cls. Superseded by ""cls in self"" syntax."""""" <TAB> if self.__class__ == cls or self.__class__.__name__ == cls: <TAB>  <TAB> return 1 <TAB> for f in self.packetfields: <TAB>  <TAB> fvalue_gen = self.getfieldval(f.name) <TAB>  <TAB> if fvalue_gen is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if not f.islist: <TAB>  <TAB>  <TAB> fvalue_gen = SetGen(fvalue_gen, _iterpacket=0) <TAB>  <TAB> for fvalue in fvalue_gen: <TAB>  <TAB>  <TAB> if isinstance(fvalue, Packet): <TAB>  <TAB>  <TAB>  <TAB> ret = fvalue.haslayer(cls) <MASK> return ret <TAB> return self.payload.haslayer(cls)",if ret :,199
4351,def insert_broken_add_sometimes(node): <TAB> if node.op == theano.tensor.add: <TAB>  <TAB> last_time_replaced[0] = not last_time_replaced[0] <MASK> return [off_by_half(*node.inputs)] <TAB> return False,if last_time_replaced [ 0 ] :,78
4352,"def testReadChunk10(self): <TAB> # ""Test BZ2File.read() in chunks of 10 bytes"" <TAB> self.createTempFile() <TAB> with BZ2File(self.filename) as bz2f: <TAB>  <TAB> text = """" <TAB>  <TAB> while 1: <TAB>  <TAB>  <TAB> str = bz2f.read(10) <MASK> break <TAB>  <TAB>  <TAB> text += str <TAB>  <TAB> self.assertEqual(text, self.TEXT)",if not str :,111
4353,"def generate_sv_faces(dcel_mesh, point_index, only_select=False, del_flag=None): <TAB> # This part of function creates faces in SV format <TAB> # It ignores  boundless super face <TAB> sv_faces = [] <TAB> for i, face in enumerate(dcel_mesh.faces): <TAB>  <TAB> if face.inners and face.outer: <TAB>  <TAB>  <TAB> ""Face ({}) has inner components! Sverchok cant show polygons with holes."".format( <TAB>  <TAB>  <TAB>  <TAB> i <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if not face.outer or del_flag in face.flags: <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> sv_faces.append([point_index[hedge.origin] for hedge in face.outer.loop_hedges]) <TAB> return sv_faces",if only_select and not face . select :,198
4354,"def __check_dict_contains(dct, dict_name, keys, comment="""", result=True): <TAB> for key in keys: <MASK> result = False <TAB>  <TAB>  <TAB> comment = __append_comment( <TAB>  <TAB>  <TAB>  <TAB> ""Missing {0} in {1}"".format(key, dict_name), comment <TAB>  <TAB>  <TAB> ) <TAB> return result, comment",if key not in six . iterkeys ( dct ) :,95
4355,"def _dump_arg_defaults(kwargs): <TAB> """"""Inject default arguments for dump functions."""""" <TAB> if current_app: <TAB>  <TAB> kwargs.setdefault(""cls"", current_app.json_encoder) <MASK> kwargs.setdefault(""ensure_ascii"", False) <TAB>  <TAB> kwargs.setdefault(""sort_keys"", current_app.config[""JSON_SORT_KEYS""]) <TAB> else: <TAB>  <TAB> kwargs.setdefault(""sort_keys"", True) <TAB>  <TAB> kwargs.setdefault(""cls"", JSONEncoder)","if not current_app . config [ ""JSON_AS_ASCII"" ] :",129
4356,"def _on_change(self): <TAB> changed = False <TAB> self.save() <TAB> for key, value in self.data.items(): <TAB>  <TAB> if isinstance(value, bool): <TAB>  <TAB>  <TAB> if value: <TAB>  <TAB>  <TAB>  <TAB> changed = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if isinstance(value, int): <TAB>  <TAB>  <TAB> if value != 1: <TAB>  <TAB>  <TAB>  <TAB> changed = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif value is None: <TAB>  <TAB>  <TAB> continue <MASK> changed = True <TAB>  <TAB>  <TAB> break <TAB> self._reset_button.disabled = not changed",elif len ( value ) != 0 :,145
4357,"def parse_win_proxy(val): <TAB> proxies = [] <TAB> for p in val.split("";""): <MASK> tab = p.split(""="", 1) <TAB>  <TAB>  <TAB> if tab[0] == ""socks"": <TAB>  <TAB>  <TAB>  <TAB> tab[0] = ""SOCKS4"" <TAB>  <TAB>  <TAB> proxies.append( <TAB>  <TAB>  <TAB>  <TAB> (tab[0].upper(), tab[1], None, None) <TAB>  <TAB>  <TAB> )  # type, addr:port, username, password <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> proxies.append((""HTTP"", p, None, None)) <TAB> return proxies","if ""="" in p :",142
4358,"def predict(collect_dir, keys): <TAB> run_all = len(keys) == 0 <TAB> validate_keys(keys) <TAB> for exp_cfg in cfg: <MASK> key = exp_cfg[""key""] <TAB>  <TAB>  <TAB> _predict(key, exp_cfg[""sample_img""], collect_dir)","if run_all or exp_cfg [ ""key"" ] in keys :",89
4359,"def convert_port_bindings(port_bindings): <TAB> result = {} <TAB> for k, v in six.iteritems(port_bindings): <TAB>  <TAB> key = str(k) <MASK> key += ""/tcp"" <TAB>  <TAB> if isinstance(v, list): <TAB>  <TAB>  <TAB> result[key] = [_convert_port_binding(binding) for binding in v] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result[key] = [_convert_port_binding(v)] <TAB> return result","if ""/"" not in key :",119
4360,"def assert_conll_writer_output( <TAB> dataset: InternalBioNerDataset, <TAB> expected_output: List[str], <TAB> sentence_splitter: SentenceSplitter = None,): <TAB> outfile_path = tempfile.mkstemp()[1] <TAB> try: <TAB>  <TAB> sentence_splitter = ( <TAB>  <TAB>  <TAB> sentence_splitter <MASK> else NoSentenceSplitter(tokenizer=SpaceTokenizer()) <TAB>  <TAB> ) <TAB>  <TAB> writer = CoNLLWriter(sentence_splitter=sentence_splitter) <TAB>  <TAB> writer.write_to_conll(dataset, Path(outfile_path)) <TAB>  <TAB> contents = [l.strip() for l in open(outfile_path).readlines() if l.strip()] <TAB> finally: <TAB>  <TAB> os.remove(outfile_path) <TAB> assert contents == expected_output",if sentence_splitter,175
4361,"def post(self, request, *args, **kwargs): <TAB> self.comment_obj = get_object_or_404(Comment, id=request.POST.get(""commentid"")) <TAB> if request.user == self.comment_obj.commented_by: <TAB>  <TAB> form = LeadCommentForm(request.POST, instance=self.comment_obj) <MASK> return self.form_valid(form) <TAB>  <TAB> return self.form_invalid(form) <TAB> data = {""error"": ""You don't have permission to edit this comment.""} <TAB> return JsonResponse(data)",if form . is_valid ( ) :,142
4362,"def trivia_list(self, ctx: commands.Context): <TAB> """"""List available trivia categories."""""" <TAB> lists = set(p.stem for p in self._all_lists()) <TAB> if await ctx.embed_requested(): <TAB>  <TAB> await ctx.send( <TAB>  <TAB>  <TAB> embed=discord.Embed( <TAB>  <TAB>  <TAB>  <TAB> title=_(""Available trivia lists""), <TAB>  <TAB>  <TAB>  <TAB> colour=await ctx.embed_colour(), <TAB>  <TAB>  <TAB>  <TAB> description="", "".join(sorted(lists)), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> msg = box(bold(_(""Available trivia lists"")) + ""\n\n"" + "", "".join(sorted(lists))) <MASK> await ctx.author.send(msg) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> await ctx.send(msg)",if len ( msg ) > 1000 :,193
4363,"def validate(self): <TAB> result = validators.SUCCESS <TAB> msgs = [] <TAB> for validator in self._validators: <TAB>  <TAB> res, err = validator.validate() <TAB>  <TAB> if res == validators.ERROR: <TAB>  <TAB>  <TAB> result = res <TAB>  <TAB> elif res == validators.WARNING and result != validators.ERROR: <TAB>  <TAB>  <TAB> result = res <MASK> msgs.append(err) <TAB> return result, ""\n"".join(msgs)",if len ( err ) > 0 :,111
4364,"def get_code(self, fullname=None): <TAB> fullname = self._fix_name(fullname) <TAB> if self.code is None: <TAB>  <TAB> mod_type = self.etc[2] <TAB>  <TAB> if mod_type == imp.PY_SOURCE: <TAB>  <TAB>  <TAB> source = self.get_source(fullname) <TAB>  <TAB>  <TAB> self.code = compile(source, self.filename, ""exec"") <MASK> self._reopen() <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> self.code = read_code(self.file) <TAB>  <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB>  <TAB> self.file.close() <TAB>  <TAB> elif mod_type == imp.PKG_DIRECTORY: <TAB>  <TAB>  <TAB> self.code = self._get_delegate().get_code() <TAB> return self.code",elif mod_type == imp . PY_COMPILED :,196
4365,"def flush_file(self, key, f): <TAB> f.flush() <TAB> if self.compress: <TAB>  <TAB> f.compress = zlib.compressobj( <TAB>  <TAB>  <TAB> 9, zlib.DEFLATED, -zlib.MAX_WBITS, zlib.DEF_MEM_LEVEL, 0 <TAB>  <TAB> ) <TAB> if len(self.files) > self.MAX_OPEN_FILES: <TAB>  <TAB> if self.compress: <TAB>  <TAB>  <TAB> open_files = sum(1 for f in self.files.values() if f.fileobj is not None) <MASK> f.fileobj.close() <TAB>  <TAB>  <TAB>  <TAB> f.fileobj = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> f.close() <TAB>  <TAB>  <TAB> self.files.pop(key)",if open_files > self . MAX_OPEN_FILES :,183
4366,"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> self.add_version(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 10 :,90
4367,"def init_author_file(self): <TAB> self.author_map = {} <TAB> if self.ui.config(""git"", ""authors""): <TAB>  <TAB> f = open(self.repo.wjoin(self.ui.config(""git"", ""authors""))) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> for line in f: <TAB>  <TAB>  <TAB>  <TAB> line = line.strip() <MASK> continue <TAB>  <TAB>  <TAB>  <TAB> from_, to = RE_AUTHOR_FILE.split(line, 2) <TAB>  <TAB>  <TAB>  <TAB> self.author_map[from_] = to <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> f.close()","if not line or line . startswith ( ""#"" ) :",152
4368,"def decode_imsi(self, imsi): <TAB> new_imsi = """" <TAB> for a in imsi: <TAB>  <TAB> c = hex(a) <MASK> new_imsi += str(c[3]) + str(c[2]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_imsi += str(c[2]) + ""0"" <TAB> mcc = new_imsi[1:4] <TAB> mnc = new_imsi[4:6] <TAB> return new_imsi, mcc, mnc",if len ( c ) == 4 :,136
4369,"def _get_infoset(self, prefname): <TAB> """"""Return methods with the name starting with prefname."""""" <TAB> infoset = [] <TAB> excludes = (""%sinfoset"" % prefname,) <TAB> preflen = len(prefname) <TAB> for name in dir(self.__class__): <TAB>  <TAB> if name.startswith(prefname) and name not in excludes: <TAB>  <TAB>  <TAB> member = getattr(self.__class__, name) <MASK> infoset.append(name[preflen:].replace(""_"", "" "")) <TAB> return infoset","if isinstance ( member , MethodType ) :",133
4370,"def skip_to_close_match(self): <TAB> nestedCount = 1 <TAB> while 1: <TAB>  <TAB> tok = self.tokenizer.get_next_token() <TAB>  <TAB> ttype = tok[""style""] <TAB>  <TAB> if ttype == SCE_PL_UNUSED: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> elif self.classifier.is_index_op(tok): <TAB>  <TAB>  <TAB> tval = tok[""text""] <TAB>  <TAB>  <TAB> if self.opHash.has_key(tval): <TAB>  <TAB>  <TAB>  <TAB> if self.opHash[tval][1] == 1: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> nestedCount += 1 <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> nestedCount -= 1 <MASK> break",if nestedCount <= 0 :,176
4371,"def findMarkForUnitTestNodes(self): <TAB> """"""return the position of *all* non-ignored @mark-for-unit-test nodes."""""" <TAB> c = self.c <TAB> p, result, seen = c.rootPosition(), [], [] <TAB> while p: <MASK> p.moveToNodeAfterTree() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> seen.append(p.v) <TAB>  <TAB>  <TAB> if g.match_word(p.h, 0, ""@ignore""): <TAB>  <TAB>  <TAB>  <TAB> p.moveToNodeAfterTree() <TAB>  <TAB>  <TAB> elif p.h.startswith(""@mark-for-unit-tests""): <TAB>  <TAB>  <TAB>  <TAB> result.append(p.copy()) <TAB>  <TAB>  <TAB>  <TAB> p.moveToNodeAfterTree() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> p.moveToThreadNext() <TAB> return result",if p . v in seen :,200
4372,"def assert_parts_cleaned(self, earlier_parts, current_parts, expected_parts, hint): <TAB> cleaned_parts = [] <TAB> for earlier in earlier_parts: <TAB>  <TAB> earlier_part = earlier[""part""] <TAB>  <TAB> earlier_step = earlier[""step""] <TAB>  <TAB> found = False <TAB>  <TAB> for current in current_parts: <TAB>  <TAB>  <TAB> if earlier_part == current[""part""] and earlier_step == current[""step""]: <TAB>  <TAB>  <TAB>  <TAB> found = True <TAB>  <TAB>  <TAB>  <TAB> break <MASK> cleaned_parts.append(dict(part=earlier_part, step=earlier_step)) <TAB> self.assertThat(cleaned_parts, HasLength(len(expected_parts)), hint) <TAB> for expected in expected_parts: <TAB>  <TAB> self.assertThat(cleaned_parts, Contains(expected), hint)",if not found :,194
4373,"def unmark_first_parents(event=None): <TAB> """"""Mark the node and all its parents."""""" <TAB> c = event.get(""c"") <TAB> if not c: <TAB>  <TAB> return <TAB> changed = [] <TAB> for parent in c.p.self_and_parents(): <MASK> parent.v.clearMarked() <TAB>  <TAB>  <TAB> parent.setAllAncestorAtFileNodesDirty() <TAB>  <TAB>  <TAB> changed.append(parent.copy()) <TAB> if changed: <TAB>  <TAB> # g.es(""unmarked: "" + ', '.join([z.h for z in changed])) <TAB>  <TAB> c.setChanged() <TAB>  <TAB> c.redraw() <TAB> return changed",if parent . isMarked ( ) :,164
4374,"def stop(self): <TAB> self._log(""Monitor stop"") <TAB> self._stop_requested = True <TAB> try: <MASK> fd = os.open(self.fifo_path, os.O_WRONLY) <TAB>  <TAB>  <TAB> os.write(fd, b""X"") <TAB>  <TAB>  <TAB> os.close(fd) <TAB> except Exception as e: <TAB>  <TAB> self._log(""err while closing: {0}"".format(str(e))) <TAB> if self._thread: <TAB>  <TAB> self._thread.join() <TAB>  <TAB> self._thread = None",if os . path . exists ( self . fifo_path ) :,141
4375,"def DeleteEmptyCols(self): <TAB> cols2delete = [] <TAB> for c in range(0, self.GetCols()): <TAB>  <TAB> f = True <TAB>  <TAB> for r in range(0, self.GetRows()): <MASK> f = False <TAB>  <TAB> if f: <TAB>  <TAB>  <TAB> cols2delete.append(c) <TAB> for i in range(0, len(cols2delete)): <TAB>  <TAB> self.ShiftColsLeft(cols2delete[i] + 1) <TAB>  <TAB> cols2delete = [x - 1 for x in cols2delete]","if self . FindItemAtPosition ( ( r , c ) ) is not None :",150
4376,"def _load_objects(self, obj_id_zset, limit, chunk_size=1000): <TAB> ct = i = 0 <TAB> while True: <TAB>  <TAB> id_chunk = obj_id_zset[i : i + chunk_size] <MASK> return <TAB>  <TAB> i += chunk_size <TAB>  <TAB> for raw_data in self._data[id_chunk]: <TAB>  <TAB>  <TAB> if not raw_data: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> if self._use_json: <TAB>  <TAB>  <TAB>  <TAB> yield json.loads(decode(raw_data)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield raw_data <TAB>  <TAB>  <TAB> ct += 1 <TAB>  <TAB>  <TAB> if limit and ct == limit: <TAB>  <TAB>  <TAB>  <TAB> return",if not id_chunk :,178
4377,"def _convert_example(example, use_bfloat16): <TAB> """"""Cast int64 into int32 and float32 to bfloat16 if use_bfloat16."""""" <TAB> for key in list(example.keys()): <TAB>  <TAB> val = example[key] <TAB>  <TAB> if tf.keras.backend.is_sparse(val): <TAB>  <TAB>  <TAB> val = tf.sparse.to_dense(val) <MASK> val = tf.cast(val, tf.int32) <TAB>  <TAB> if use_bfloat16 and val.dtype == tf.float32: <TAB>  <TAB>  <TAB> val = tf.cast(val, tf.bfloat16) <TAB>  <TAB> example[key] = val",if val . dtype == tf . int64 :,166
4378,"def print_callees(self, *amount): <TAB> width, list = self.get_print_list(amount) <TAB> if list: <TAB>  <TAB> self.calc_callees() <TAB>  <TAB> self.print_call_heading(width, ""called..."") <TAB>  <TAB> for func in list: <MASK> self.print_call_line(width, func, self.all_callees[func]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.print_call_line(width, func, {}) <TAB>  <TAB> print >>self.stream <TAB>  <TAB> print >>self.stream <TAB> return self",if func in self . all_callees :,147
4379,"def on_task_input(self, task, config): <TAB> if config is False: <TAB>  <TAB> return <TAB> for entry in task.entries: <MASK> log_once( <TAB>  <TAB>  <TAB>  <TAB> ""Corrected `%s` url (replaced &amp; with &)"" % entry[""title""], <TAB>  <TAB>  <TAB>  <TAB> logger=log, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> entry[""url""] = entry[""url""].replace(""&amp;"", ""&"")","if ""&amp;"" in entry [ ""url"" ] :",112
4380,"def function(self, inputs, outputs, ignore_empty=False): <TAB> f = function(inputs, outputs, mode=self.mode) <TAB> if self.mode is not None or theano.config.mode != ""FAST_COMPILE"": <TAB>  <TAB> topo = f.maker.fgraph.toposort() <TAB>  <TAB> topo_ = [node for node in topo if not isinstance(node.op, self.ignore_topo)] <TAB>  <TAB> if ignore_empty: <TAB>  <TAB>  <TAB> assert len(topo_) <= 1, topo_ <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert len(topo_) == 1, topo_ <MASK> assert type(topo_[0].op) is self.op <TAB> return f",if len ( topo_ ) > 0 :,165
4381,"def _get_env_command(self) -> Sequence[str]: <TAB> """"""Get command sequence for `env` with configured flags."""""" <TAB> env_list = [""env""] <TAB> # Pass through configurable environment variables. <TAB> for key in [""http_proxy"", ""https_proxy""]: <TAB>  <TAB> value = self.build_provider_flags.get(key) <MASK> continue <TAB>  <TAB> # Ensure item is treated as string and append it. <TAB>  <TAB> value = str(value) <TAB>  <TAB> env_list.append(f""{key}={value}"") <TAB> return env_list",if not value :,136
4382,"def _compare_single_run(self, compares_done): <TAB> try: <TAB>  <TAB> compare_id, redo = self.in_queue.get( <TAB>  <TAB>  <TAB> timeout=float(self.config[""ExpertSettings""][""block_delay""]) <TAB>  <TAB> ) <TAB> except Empty: <TAB>  <TAB> pass <TAB> else: <TAB>  <TAB> if self._decide_whether_to_process(compare_id, redo, compares_done): <TAB>  <TAB>  <TAB> if redo: <TAB>  <TAB>  <TAB>  <TAB> self.db_interface.delete_old_compare_result(compare_id) <TAB>  <TAB>  <TAB> compares_done.add(compare_id) <TAB>  <TAB>  <TAB> self._process_compare(compare_id) <MASK> self.callback()",if self . callback :,177
4383,"def clean(self): <TAB> # TODO: check for clashes if the random code is already taken <TAB> if not self.code: <TAB>  <TAB> self.code = u""static-%s"" % uuid.uuid4() <TAB> if not self.site: <TAB>  <TAB> placeholders = StaticPlaceholder.objects.filter( <TAB>  <TAB>  <TAB> code=self.code, site__isnull=True <TAB>  <TAB> ) <TAB>  <TAB> if self.pk: <TAB>  <TAB>  <TAB> placeholders = placeholders.exclude(pk=self.pk) <MASK> raise ValidationError( <TAB>  <TAB>  <TAB>  <TAB> _(""A static placeholder with the same site and code already exists"") <TAB>  <TAB>  <TAB> )",if placeholders . exists ( ) :,149
4384,"def load_parser(self): <TAB> result = OrderedDict() <TAB> for name, flags in self.filenames: <TAB>  <TAB> filename = self.get_filename(name) <TAB>  <TAB> for match in sorted(glob(filename), key=self.file_key): <TAB>  <TAB>  <TAB> # Needed to allow overlapping globs, more specific first <MASK> continue <TAB>  <TAB>  <TAB> result[match] = TextParser(match, os.path.relpath(match, self.base), flags) <TAB> return result",if match in result :,119
4385,"def __init__(self, selectable, name=None): <TAB> baseselectable = selectable <TAB> while isinstance(baseselectable, Alias): <TAB>  <TAB> baseselectable = baseselectable.element <TAB> self.original = baseselectable <TAB> self.supports_execution = baseselectable.supports_execution <TAB> if self.supports_execution: <TAB>  <TAB> self._execution_options = baseselectable._execution_options <TAB> self.element = selectable <TAB> if name is None: <MASK> name = getattr(self.original, ""name"", None) <TAB>  <TAB> name = _anonymous_label(""%%(%d %s)s"" % (id(self), name or ""anon"")) <TAB> self.name = name",if self . original . named_with_column :,165
4386,"def load_tour(self, tour_id): <TAB> for tour_dir in self.tour_directories: <TAB>  <TAB> tour_path = os.path.join(tour_dir, tour_id + "".yaml"") <TAB>  <TAB> if not os.path.exists(tour_path): <TAB>  <TAB>  <TAB> tour_path = os.path.join(tour_dir, tour_id + "".yml"") <MASK> return self._load_tour_from_path(tour_path)",if os . path . exists ( tour_path ) :,122
4387,"def _get_md_bg_color_down(self): <TAB> t = self.theme_cls <TAB> c = self.md_bg_color  # Default to no change on touch <TAB> # Material design specifies using darker hue when on Dark theme <TAB> if t.theme_style == ""Dark"": <MASK> c = t.primary_dark <TAB>  <TAB> elif self.md_bg_color == t.accent_color: <TAB>  <TAB>  <TAB> c = t.accent_dark <TAB> return c",if self . md_bg_color == t . primary_color :,135
4388,"def get_data(self, state=None, request=None): <TAB> if self.load_in_memory: <TAB>  <TAB> data, shapes = self._in_memory_get_data(state, request) <TAB> else: <TAB>  <TAB> data, shapes = self._out_of_memory_get_data(state, request) <TAB> for i in range(len(data)): <TAB>  <TAB> if shapes[i] is not None: <MASK> data[i] = data[i].reshape(shapes[i]) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> for j in range(len(data[i])): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> data[i][j] = data[i][j].reshape(shapes[i][j]) <TAB> return tuple(data)","if isinstance ( request , numbers . Integral ) :",187
4389,"def onClicked(event): <TAB> if not self.path: <MASK> os.makedirs(mh.getPath(""render"")) <TAB>  <TAB> self.path = mh.getPath(""render"") <TAB> filename, ftype = mh.getSaveFileName( <TAB>  <TAB> os.path.splitext(self.path)[0], <TAB>  <TAB> ""PNG Image (*.png);;JPEG Image (*.jpg);;Thumbnail (*.thumb);;All files (*.*)"", <TAB> ) <TAB> if filename: <TAB>  <TAB> if ""Thumbnail"" in ftype: <TAB>  <TAB>  <TAB> self.image.save(filename, iformat=""PNG"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.image.save(filename) <TAB>  <TAB> self.path = os.path.dirname(filename)","if not os . path . exists ( mh . getPath ( ""render"" ) ) :",187
4390,"def _build_dom(cls, content, mode): <TAB> assert mode in (""html"", ""xml"") <TAB> if mode == ""html"": <MASK> THREAD_STORAGE.html_parser = HTMLParser() <TAB>  <TAB> dom = defusedxml.lxml.parse( <TAB>  <TAB>  <TAB> StringIO(content), parser=THREAD_STORAGE.html_parser <TAB>  <TAB> ) <TAB>  <TAB> return dom.getroot() <TAB> else: <TAB>  <TAB> if not hasattr(THREAD_STORAGE, ""xml_parser""): <TAB>  <TAB>  <TAB> THREAD_STORAGE.xml_parser = XMLParser() <TAB>  <TAB> dom = defusedxml.lxml.parse(BytesIO(content), parser=THREAD_STORAGE.xml_parser) <TAB>  <TAB> return dom.getroot()","if not hasattr ( THREAD_STORAGE , ""html_parser"" ) :",175
4391,"def convert_path(ctx, tpath): <TAB> for points, code in tpath.iter_segments(): <MASK> ctx.move_to(*points) <TAB>  <TAB> elif code == Path.LINETO: <TAB>  <TAB>  <TAB> ctx.line_to(*points) <TAB>  <TAB> elif code == Path.CURVE3: <TAB>  <TAB>  <TAB> ctx.curve_to( <TAB>  <TAB>  <TAB>  <TAB> points[0], points[1], points[0], points[1], points[2], points[3] <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> elif code == Path.CURVE4: <TAB>  <TAB>  <TAB> ctx.curve_to(*points) <TAB>  <TAB> elif code == Path.CLOSEPOLY: <TAB>  <TAB>  <TAB> ctx.close_path()",if code == Path . MOVETO :,172
4392,"def _targets(self, sigmaparser): <TAB> # build list of matching target mappings <TAB> targets = set() <TAB> for condfield in self.conditions: <TAB>  <TAB> if condfield in sigmaparser.values: <TAB>  <TAB>  <TAB> rulefieldvalues = sigmaparser.values[condfield] <TAB>  <TAB>  <TAB> for condvalue in self.conditions[condfield]: <MASK> targets.update(self.conditions[condfield][condvalue]) <TAB> return targets",if condvalue in rulefieldvalues :,115
4393,"def create_image_upload(): <TAB> if request.method == ""POST"": <TAB>  <TAB> image = request.form[""image""] <MASK> image_file = uploaded_file(file_content=image) <TAB>  <TAB>  <TAB> image_url = upload_local( <TAB>  <TAB>  <TAB>  <TAB> image_file, UPLOAD_PATHS[""temp""][""image""].format(uuid=uuid4()) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return jsonify({""status"": ""ok"", ""image_url"": image_url}) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return jsonify({""status"": ""no_image""})",if image :,135
4394,"def lookup_actions(self, resp): <TAB> actions = {} <TAB> for action, conditions in self.actions.items(): <TAB>  <TAB> for condition, opts in conditions: <TAB>  <TAB>  <TAB> for key, val in condition: <TAB>  <TAB>  <TAB>  <TAB> if key[-1] == ""!"": <MASK> break <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if not resp.match(key, val): <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> actions[action] = opts <TAB> return actions","if resp . match ( key [ : - 1 ] , val ) :",138
4395,"def accept_quality(accept, default=1): <TAB> """"""Separates out the quality score from the accepted content_type"""""" <TAB> quality = default <TAB> if accept and "";"" in accept: <TAB>  <TAB> accept, rest = accept.split("";"", 1) <TAB>  <TAB> accept_quality = RE_ACCEPT_QUALITY.search(rest) <MASK> quality = float(accept_quality.groupdict().get(""quality"", quality).strip()) <TAB> return (quality, accept.strip())",if accept_quality :,113
4396,"def save(self, session=None, to=None, pickler=None): <TAB> if to and pickler: <TAB>  <TAB> self._save_to = (pickler, to) <TAB> if self._save_to and len(self) > 0: <TAB>  <TAB> with self._lock: <TAB>  <TAB>  <TAB> pickler, fn = self._save_to <MASK> session.ui.mark(_(""Saving %s state to %s"") % (self, fn)) <TAB>  <TAB>  <TAB> pickler(self, fn)",if session :,123
4397,"def get_safe_settings(): <TAB> ""Returns a dictionary of the settings module, with sensitive settings blurred out."" <TAB> settings_dict = {} <TAB> for k in dir(settings): <TAB>  <TAB> if k.isupper(): <MASK> settings_dict[k] = ""********************"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> settings_dict[k] = getattr(settings, k) <TAB> return settings_dict",if HIDDEN_SETTINGS . search ( k ) :,109
4398,def _init_table_h(): <TAB> _table_h = [] <TAB> for i in range(256): <TAB>  <TAB> part_l = i <TAB>  <TAB> part_h = 0 <TAB>  <TAB> for j in range(8): <TAB>  <TAB>  <TAB> rflag = part_l & 1 <TAB>  <TAB>  <TAB> part_l >>= 1 <TAB>  <TAB>  <TAB> if part_h & 1: <TAB>  <TAB>  <TAB>  <TAB> part_l |= 1 << 31 <TAB>  <TAB>  <TAB> part_h >>= 1 <MASK> part_h ^= 0xD8000000 <TAB>  <TAB> _table_h.append(part_h) <TAB> return _table_h,if rflag :,147
4399,"def dns_query(server, timeout, protocol, qname, qtype, qclass): <TAB> request = dns.message.make_query(qname, qtype, qclass) <TAB> if protocol == ""tcp"": <TAB>  <TAB> response = dns.query.tcp( <TAB>  <TAB>  <TAB> request, server, timeout=timeout, one_rr_per_rrset=True <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> response = dns.query.udp( <TAB>  <TAB>  <TAB> request, server, timeout=timeout, one_rr_per_rrset=True <TAB>  <TAB> ) <MASK> response = dns.query.tcp( <TAB>  <TAB>  <TAB>  <TAB> request, server, timeout=timeout, one_rr_per_rrset=True <TAB>  <TAB>  <TAB> ) <TAB> return response",if response . flags & dns . flags . TC :,184
4400,"def sum_and_divide(self, losses): <TAB> if self.total_divisor != 0: <TAB>  <TAB> output = torch.sum(losses) / self.total_divisor <MASK> # remove from autograd graph if necessary <TAB>  <TAB>  <TAB> self.total_divisor = self.total_divisor.item() <TAB>  <TAB> return output <TAB> return torch.sum(losses * 0)",if torch . is_tensor ( self . total_divisor ) :,102
4401,"def __iter__(self): <TAB> for chunk in self.source: <TAB>  <TAB> if chunk is not None: <TAB>  <TAB>  <TAB> self.wait_counter = 0 <TAB>  <TAB>  <TAB> yield chunk <MASK> self.wait_counter += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logger.warning( <TAB>  <TAB>  <TAB>  <TAB> ""Data poller has been receiving no data for {} seconds.\n"" <TAB>  <TAB>  <TAB>  <TAB> ""Closing data poller"".format(self.wait_cntr_max * self.poll_period) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> time.sleep(self.poll_period)",elif self . wait_counter < self . wait_cntr_max :,156
4402,"def test_find_directive_from_block(self): <TAB> blocks = self.config.parser_root.find_blocks(""virtualhost"") <TAB> found = False <TAB> for vh in blocks: <MASK> servername = vh.find_directives(""servername"") <TAB>  <TAB>  <TAB> self.assertEqual(servername[0].parameters[0], ""certbot.demo"") <TAB>  <TAB>  <TAB> found = True <TAB> self.assertTrue(found)","if vh . filepath . endswith ( ""sites-enabled/certbot.conf"" ) :",118
4403,"def assign_products(request, discount_id): <TAB> """"""Assign products to given property group with given property_group_id."""""" <TAB> discount = lfs_get_object_or_404(Discount, pk=discount_id) <TAB> for temp_id in request.POST.keys(): <MASK> temp_id = temp_id.split(""-"")[1] <TAB>  <TAB>  <TAB> product = Product.objects.get(pk=temp_id) <TAB>  <TAB>  <TAB> discount.products.add(product) <TAB> html = [[""#products-inline"", products_inline(request, discount_id, as_string=True)]] <TAB> result = json.dumps( <TAB>  <TAB> {""html"": html, ""message"": _(u""Products have been assigned."")}, cls=LazyEncoder <TAB> ) <TAB> return HttpResponse(result, content_type=""application/json"")","if temp_id . startswith ( ""product"" ) :",199
4404,"def ChangeStyle(self, combos): <TAB> style = 0 <TAB> for combo in combos: <TAB>  <TAB> if combo.GetValue() == 1: <MASK> style = style | HTL.TR_VIRTUAL <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> style = style | eval(""wx."" + combo.GetLabel()) <TAB>  <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> style = style | eval(""HTL."" + combo.GetLabel()) <TAB> if self.GetAGWWindowStyleFlag() != style: <TAB>  <TAB> self.SetAGWWindowStyleFlag(style)","if combo . GetLabel ( ) == ""TR_VIRTUAL"" :",153
4405,"def _set_autocomplete(self, notebook): <TAB> if notebook: <TAB>  <TAB> try: <MASK> notebook = NotebookInfo(notebook) <TAB>  <TAB>  <TAB> obj, x = build_notebook(notebook) <TAB>  <TAB>  <TAB> self.form.widgets[""namespace""].notebook = obj <TAB>  <TAB>  <TAB> self.form.widgets[""page""].notebook = obj <TAB>  <TAB>  <TAB> logger.debug(""Notebook for autocomplete: %s (%s)"", obj, notebook) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> logger.exception(""Could not set notebook: %s"", notebook) <TAB> else: <TAB>  <TAB> self.form.widgets[""namespace""].notebook = None <TAB>  <TAB> self.form.widgets[""page""].notebook = None <TAB>  <TAB> logger.debug(""Notebook for autocomplete unset"")","if isinstance ( notebook , str ) :",178
4406,"def emitSubDomainData(self, subDomainData, event): <TAB> self.emitRawRirData(subDomainData, event) <TAB> for subDomainElem in subDomainData: <MASK> return None <TAB>  <TAB> subDomain = subDomainElem.get(""subdomain"", """").strip() <TAB>  <TAB> if subDomain: <TAB>  <TAB>  <TAB> self.emitHostname(subDomain, event)",if self . checkForStop ( ) :,99
4407,"def get_all_subnets(self, subnet_ids=None, filters=None): <TAB> # Extract a list of all subnets <TAB> matches = itertools.chain(*[x.values() for x in self.subnets.values()]) <TAB> if subnet_ids: <TAB>  <TAB> matches = [sn for sn in matches if sn.id in subnet_ids] <MASK> unknown_ids = set(subnet_ids) - set(matches) <TAB>  <TAB>  <TAB> raise InvalidSubnetIdError(unknown_ids) <TAB> if filters: <TAB>  <TAB> matches = generic_filter(filters, matches) <TAB> return matches",if len ( subnet_ids ) > len ( matches ) :,152
4408,"def _compat_map(self, avs): <TAB> apps = {} <TAB> for av in avs: <TAB>  <TAB> av.version = self <TAB>  <TAB> app_id = av.application <MASK> apps[amo.APP_IDS[app_id]] = av <TAB> return apps",if app_id in amo . APP_IDS :,80
4409,"def generator(self, data): <TAB> if self._config.SILENT: <TAB>  <TAB> silent_vars = self._get_silent_vars() <TAB> for task in data: <TAB>  <TAB> for var, val in task.environment_variables(): <TAB>  <TAB>  <TAB> if self._config.SILENT: <MASK> continue <TAB>  <TAB>  <TAB> yield ( <TAB>  <TAB>  <TAB>  <TAB> 0, <TAB>  <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> int(task.UniqueProcessId), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> str(task.ImageFileName), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> Address(task.Peb.ProcessParameters.Environment), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> str(var), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> str(val), <TAB>  <TAB>  <TAB>  <TAB> ], <TAB>  <TAB>  <TAB> )",if var in silent_vars :,182
4410,"def warn_if_repeatable_read(self): <TAB> if ""mysql"" in self.current_engine().lower(): <TAB>  <TAB> cursor = self.connection_for_read().cursor() <TAB>  <TAB> if cursor.execute(""SELECT @@tx_isolation""): <TAB>  <TAB>  <TAB> isolation = cursor.fetchone()[0] <MASK> warnings.warn( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> TxIsolationWarning( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Polling results with transaction isolation level "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""repeatable-read within the same transaction "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""may give outdated results. Be sure to commit the "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""transaction for each poll iteration."" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> )","if isolation == ""REPEATABLE-READ"" :",182
4411,"def filter_by_level(record, level_per_module): <TAB> name = record[""name""] <TAB> level = 0 <TAB> if name in level_per_module: <TAB>  <TAB> level = level_per_module[name] <TAB> elif name is not None: <TAB>  <TAB> lookup = """" <MASK> level = level_per_module[""""] <TAB>  <TAB> for n in name.split("".""): <TAB>  <TAB>  <TAB> lookup += n <TAB>  <TAB>  <TAB> if lookup in level_per_module: <TAB>  <TAB>  <TAB>  <TAB> level = level_per_module[lookup] <TAB>  <TAB>  <TAB> lookup += ""."" <TAB> if level is False: <TAB>  <TAB> return False <TAB> return record[""level""].no >= level","if """" in level_per_module :",166
4412,"def _readStream(self, handle: str, path: str) -> None: <TAB> eof = False <TAB> file = Path(path) <TAB> with file.open(""w"") as f: <TAB>  <TAB> while not eof: <TAB>  <TAB>  <TAB> response = await self._client.send(""IO.read"", {""handle"": handle}) <TAB>  <TAB>  <TAB> eof = response.get(""eof"", False) <MASK> f.write(response.get(""data"", """")) <TAB> await self._client.send(""IO.close"", {""handle"": handle})",if path :,128
4413,"def sendall(self, data, flags=0): <TAB> if self._sslobj: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""non-zero flags not allowed in calls to sendall() on %s"" <TAB>  <TAB>  <TAB>  <TAB> % self.__class__ <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> amount = len(data) <TAB>  <TAB> count = 0 <TAB>  <TAB> while count < amount: <TAB>  <TAB>  <TAB> v = self.send(data[count:]) <TAB>  <TAB>  <TAB> count += v <TAB>  <TAB> return amount <TAB> else: <TAB>  <TAB> return socket.sendall(self, data, flags)",if flags != 0 :,141
4414,"def run(self): <TAB> utils.assert_main_thread() <TAB> # As a convenience, we'll set up the connection <TAB> # if there isn't one. So F5 (etc) can be hit <TAB> # to get started. <TAB> if not channel: <MASK> SwiDebugStartChromeCommand.run(self) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.window.run_command(""swi_debug_start"") <TAB> elif paused: <TAB>  <TAB> logger.info(""Resuming..."") <TAB>  <TAB> channel.send(webkit.Debugger.resume()) <TAB> else: <TAB>  <TAB> logger.info(""Pausing..."") <TAB>  <TAB> channel.send(webkit.Debugger.setSkipAllPauses(False)) <TAB>  <TAB> channel.send(webkit.Debugger.pause())",if not chrome_launched ( ) :,190
4415,"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> length = d.getVarInt32() <TAB>  <TAB>  <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB>  <TAB>  <TAB> d.skip(length) <TAB>  <TAB>  <TAB> self.add_presence_response().TryMerge(tmp) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,140
4416,"def _replace_home(x): <TAB> if xp.ON_WINDOWS: <TAB>  <TAB> home = ( <TAB>  <TAB>  <TAB> builtins.__xonsh__.env[""HOMEDRIVE""] + builtins.__xonsh__.env[""HOMEPATH""][0] <TAB>  <TAB> ) <TAB>  <TAB> if x.startswith(home): <TAB>  <TAB>  <TAB> x = x.replace(home, ""~"", 1) <MASK> x = x.replace(os.sep, os.altsep) <TAB>  <TAB> return x <TAB> else: <TAB>  <TAB> home = builtins.__xonsh__.env[""HOME""] <TAB>  <TAB> if x.startswith(home): <TAB>  <TAB>  <TAB> x = x.replace(home, ""~"", 1) <TAB>  <TAB> return x","if builtins . __xonsh__ . env . get ( ""FORCE_POSIX_PATHS"" ) :",176
4417,"def semanticTags(self, semanticTags): <TAB> if semanticTags is None: <TAB>  <TAB> self.__semanticTags = OrderedDict() <TAB> # check <TAB> for key, value in list(semanticTags.items()): <MASK> raise TypeError(""At least one key is not a valid int position"") <TAB>  <TAB> if not isinstance(value, list): <TAB>  <TAB>  <TAB> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB> ""At least one value of the provided dict is not a list of string"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> for x in value: <TAB>  <TAB>  <TAB> if not isinstance(x, str): <TAB>  <TAB>  <TAB>  <TAB> raise TypeError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""At least one value of the provided dict is not a list of string"" <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> self.__semanticTags = semanticTags","if not isinstance ( key , int ) :",184
4418,"def _recv(): <TAB> try: <TAB>  <TAB> return sock.recv(bufsize) <TAB> except SSLWantReadError: <TAB>  <TAB> pass <TAB> except socket.error as exc: <TAB>  <TAB> error_code = extract_error_code(exc) <TAB>  <TAB> if error_code is None: <TAB>  <TAB>  <TAB> raise <MASK> raise <TAB> r, w, e = select.select((sock,), (), (), sock.gettimeout()) <TAB> if r: <TAB>  <TAB> return sock.recv(bufsize)",if error_code != errno . EAGAIN or error_code != errno . EWOULDBLOCK :,139
4419,"def _authenticate(self): <TAB> oauth_token = self.options.get(""oauth_token"") <TAB> if oauth_token and not self.api.oauth_token: <TAB>  <TAB> self.logger.info(""Attempting to authenticate using OAuth token"") <TAB>  <TAB> self.api.oauth_token = oauth_token <TAB>  <TAB> user = self.api.user(schema=_user_schema) <MASK> self.logger.info(""Successfully logged in as {0}"", user) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.logger.error( <TAB>  <TAB>  <TAB>  <TAB> ""Failed to authenticate, the access token "" ""is not valid"" <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> return JustinTVPluginBase._authenticate(self)",if user :,168
4420,"def reverse(self, *args): <TAB> assert self._path is not None, ""Cannot reverse url regex "" + self.regex.pattern <TAB> assert len(args) == self._group_count, ""required number of arguments "" ""not found"" <TAB> if not len(args): <TAB>  <TAB> return self._path <TAB> converted_args = [] <TAB> for a in args: <MASK> a = str(a) <TAB>  <TAB> converted_args.append(escape.url_escape(utf8(a), plus=False)) <TAB> return self._path % tuple(converted_args)","if not isinstance ( a , ( unicode_type , bytes ) ) :",147
4421,"def determine_block_hints(self, text): <TAB> hints = """" <TAB> if text: <MASK> hints += str(self.best_indent) <TAB>  <TAB> if text[-1] not in ""\n\x85\u2028\u2029"": <TAB>  <TAB>  <TAB> hints += ""-"" <TAB>  <TAB> elif len(text) == 1 or text[-2] in ""\n\x85\u2028\u2029"": <TAB>  <TAB>  <TAB> hints += ""+"" <TAB> return hints","if text [ 0 ] in "" \n\x85\u2028\u2029"" :",132
4422,"def find_package_modules(package, mask): <TAB> import fnmatch <TAB> if hasattr(package, ""__loader__"") and hasattr(package.__loader__, ""_files""): <TAB>  <TAB> path = package.__name__.replace(""."", os.path.sep) <TAB>  <TAB> mask = os.path.join(path, mask) <TAB>  <TAB> for fnm in package.__loader__._files.iterkeys(): <MASK> yield os.path.splitext(fnm)[0].replace(os.path.sep, ""."") <TAB> else: <TAB>  <TAB> path = package.__path__[0] <TAB>  <TAB> for fnm in os.listdir(path): <TAB>  <TAB>  <TAB> if fnmatch.fnmatchcase(fnm, mask): <TAB>  <TAB>  <TAB>  <TAB> yield ""%s.%s"" % (package.__name__, os.path.splitext(fnm)[0])","if fnmatch . fnmatchcase ( fnm , mask ) :",191
4423,"def _condition(ct): <TAB> for qobj in args: <TAB>  <TAB> if qobj.connector == ""AND"" and not qobj.negated: <TAB>  <TAB>  <TAB> # normal kwargs are an AND anyway, so just use those for now <TAB>  <TAB>  <TAB> for child in qobj.children: <TAB>  <TAB>  <TAB>  <TAB> kwargs.update(dict([child])) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise NotImplementedError(""Unsupported Q object"") <TAB> for attr, val in kwargs.items(): <MASK> return False <TAB> return True","if getattr ( ct , attr ) != val :",127
4424,"def process(self, resources): <TAB> session = local_session(self.manager.session_factory) <TAB> client = session.client(""logs"") <TAB> state = self.data.get(""state"", True) <TAB> key = self.resolve_key(self.data.get(""kms-key"")) <TAB> for r in resources: <TAB>  <TAB> try: <MASK> client.associate_kms_key(logGroupName=r[""logGroupName""], kmsKeyId=key) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> client.disassociate_kms_key(logGroupName=r[""logGroupName""]) <TAB>  <TAB> except client.exceptions.ResourceNotFoundException: <TAB>  <TAB>  <TAB> continue",if state :,153
4425,"def get_xmm(env, ii): <TAB> if is_gather(ii): <MASK> return gen_reg_simd_unified(env, ""xmm_evex"", True) <TAB>  <TAB> return gen_reg_simd_unified(env, ""xmm"", False) <TAB> if ii.space == ""evex"": <TAB>  <TAB> return gen_reg(env, ""xmm_evex"") <TAB> return gen_reg(env, ""xmm"")","if ii . space == ""evex"" :",119
4426,"def parent(self): <TAB> """"""Return the parent device."""""" <TAB> if self._has_parent is None: <TAB>  <TAB> _parent = self._ctx.backend.get_parent(self._ctx.dev) <TAB>  <TAB> self._has_parent = _parent is not None <MASK> self._parent = Device(_parent, self._ctx.backend) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._parent = None <TAB> return self._parent",if self . _has_parent :,109
4427,"def cascade(self, event=None): <TAB> """"""Cascade all Leo windows."""""" <TAB> x, y, delta = 50, 50, 50 <TAB> for frame in g.app.windowList: <TAB>  <TAB> w = frame and frame.top <MASK> r = w.geometry()  # a Qt.Rect <TAB>  <TAB>  <TAB> # 2011/10/26: Fix bug 823601: cascade-windows fails. <TAB>  <TAB>  <TAB> w.setGeometry(QtCore.QRect(x, y, r.width(), r.height())) <TAB>  <TAB>  <TAB> # Compute the new offsets. <TAB>  <TAB>  <TAB> x += 30 <TAB>  <TAB>  <TAB> y += 30 <TAB>  <TAB>  <TAB> if x > 200: <TAB>  <TAB>  <TAB>  <TAB> x = 10 + delta <TAB>  <TAB>  <TAB>  <TAB> y = 40 + delta <TAB>  <TAB>  <TAB>  <TAB> delta += 10",if w :,190
4428,"def _GetGoodDispatchAndUserName(IDispatch, userName, clsctx): <TAB> # Get a dispatch object, and a 'user name' (ie, the name as <TAB> # displayed to the user in repr() etc. <TAB> if userName is None: <TAB>  <TAB> if isinstance(IDispatch, str): <TAB>  <TAB>  <TAB> userName = IDispatch <MASK> # We always want the displayed name to be a real string <TAB>  <TAB>  <TAB> userName = IDispatch.encode(""ascii"", ""replace"") <TAB> elif type(userName) == unicode: <TAB>  <TAB> # As above - always a string... <TAB>  <TAB> userName = userName.encode(""ascii"", ""replace"") <TAB> else: <TAB>  <TAB> userName = str(userName) <TAB> return (_GetGoodDispatch(IDispatch, clsctx), userName)","elif isinstance ( IDispatch , unicode ) :",200
4429,"def _infer_return_type(*args): <TAB> """"""Look at the type of all args and divine their implied return type."""""" <TAB> return_type = None <TAB> for arg in args: <TAB>  <TAB> if arg is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if isinstance(arg, bytes): <TAB>  <TAB>  <TAB> if return_type is str: <TAB>  <TAB>  <TAB>  <TAB> raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."") <TAB>  <TAB>  <TAB> return_type = bytes <TAB>  <TAB> else: <MASK> raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."") <TAB>  <TAB>  <TAB> return_type = str <TAB> if return_type is None: <TAB>  <TAB> return str  # tempfile APIs return a str by default. <TAB> return return_type",if return_type is bytes :,186
4430,"def test_ESPnetDataset_h5file_1(h5file_1): <TAB> dataset = IterableESPnetDataset( <TAB>  <TAB> path_name_type_list=[(h5file_1, ""data4"", ""hdf5"")], <TAB>  <TAB> preprocess=preprocess, <TAB> ) <TAB> for key, data in dataset: <TAB>  <TAB> if key == ""a"": <TAB>  <TAB>  <TAB> assert data[""data4""].shape == ( <TAB>  <TAB>  <TAB>  <TAB> 100, <TAB>  <TAB>  <TAB>  <TAB> 80, <TAB>  <TAB>  <TAB> ) <MASK> assert data[""data4""].shape == ( <TAB>  <TAB>  <TAB>  <TAB> 150, <TAB>  <TAB>  <TAB>  <TAB> 80, <TAB>  <TAB>  <TAB> )","if key == ""b"" :",157
4431,"def iter_fields(node, *, include_meta=True, exclude_unset=False): <TAB> exclude_meta = not include_meta <TAB> for field_name, field in node._fields.items(): <TAB>  <TAB> if exclude_meta and field.meta: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> field_val = getattr(node, field_name, _marker) <MASK> continue <TAB>  <TAB> if exclude_unset: <TAB>  <TAB>  <TAB> if callable(field.default): <TAB>  <TAB>  <TAB>  <TAB> default = field.default() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> default = field.default <TAB>  <TAB>  <TAB> if field_val == default: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> yield field_name, field_val",if field_val is _marker :,171
4432,"def then(self, matches, when_response, context): <TAB> if is_iterable(when_response): <TAB>  <TAB> ret = [] <TAB>  <TAB> when_response = list(when_response) <TAB>  <TAB> for match in when_response: <MASK> if self.match_name: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> match.name = self.match_name <TAB>  <TAB>  <TAB>  <TAB> matches.append(match) <TAB>  <TAB>  <TAB>  <TAB> ret.append(match) <TAB>  <TAB> return ret <TAB> if self.match_name: <TAB>  <TAB> when_response.name = self.match_name <TAB> if when_response not in matches: <TAB>  <TAB> matches.append(when_response) <TAB>  <TAB> return when_response",if match not in matches :,169
4433,"def _set_chat_ids(self, chat_id: SLT[int]) -> None: <TAB> with self.__lock: <MASK> raise RuntimeError( <TAB>  <TAB>  <TAB>  <TAB> f""Can't set {self.chat_id_name} in conjunction with (already set) "" <TAB>  <TAB>  <TAB>  <TAB> f""{self.username_name}s."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self._chat_ids = self._parse_chat_id(chat_id)",if chat_id and self . _usernames :,118
4434,"def discover(self, *objlist): <TAB> ret = [] <TAB> for l in self.splitlines(): <MASK> continue <TAB>  <TAB> if l[0] == ""Filename"": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> int(l[2]) <TAB>  <TAB>  <TAB> int(l[3]) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # <TAB>  <TAB>    ret.append(improve(l[0])) <TAB>  <TAB> ret.append(l[0]) <TAB> ret.sort() <TAB> for item in objlist: <TAB>  <TAB> ret.append(item) <TAB> return ret",if len ( l ) < 5 :,154
4435,"def get_changed_module(self): <TAB> source = self.resource.read() <TAB> change_collector = codeanalyze.ChangeCollector(source) <TAB> if self.replacement is not None: <TAB>  <TAB> change_collector.add_change(self.skip_start, self.skip_end, self.replacement) <TAB> for occurrence in self.occurrence_finder.find_occurrences(self.resource): <TAB>  <TAB> start, end = occurrence.get_primary_range() <MASK> self.handle.occurred_inside_skip(change_collector, occurrence) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.handle.occurred_outside_skip(change_collector, occurrence) <TAB> result = change_collector.get_changed() <TAB> if result is not None and result != source: <TAB>  <TAB> return result",if self . skip_start <= start < self . skip_end :,198
4436,"def hpat_pandas_series_var_impl( <TAB> self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None): <TAB> if skipna is None: <TAB>  <TAB> skipna = True <TAB> if skipna: <TAB>  <TAB> valuable_length = len(self._data) - numpy.sum(numpy.isnan(self._data)) <MASK> return numpy.nan <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB> numpy_like.nanvar(self._data) * valuable_length / (valuable_length - ddof) <TAB>  <TAB> ) <TAB> if len(self._data) <= ddof: <TAB>  <TAB> return numpy.nan <TAB> return self._data.var() * len(self._data) / (len(self._data) - ddof)",if valuable_length <= ddof :,188
4437,"def to_dict(self, validate=True, ignore=(), context=None): <TAB> context = context or {} <TAB> condition = getattr(self, ""condition"", Undefined) <TAB> copy = self  # don't copy unless we need to <TAB> if condition is not Undefined: <MASK> pass <TAB>  <TAB> elif ""field"" in condition and ""type"" not in condition: <TAB>  <TAB>  <TAB> kwds = parse_shorthand(condition[""field""], context.get(""data"", None)) <TAB>  <TAB>  <TAB> copy = self.copy(deep=[""condition""]) <TAB>  <TAB>  <TAB> copy.condition.update(kwds) <TAB> return super(ValueChannelMixin, copy).to_dict( <TAB>  <TAB> validate=validate, ignore=ignore, context=context <TAB> )","if isinstance ( condition , core . SchemaBase ) :",175
4438,"def get_field_result(self, result, field_name): <TAB> if isinstance(result.field, models.ImageField): <MASK> img = getattr(result.obj, field_name) <TAB>  <TAB>  <TAB> result.text = mark_safe( <TAB>  <TAB>  <TAB>  <TAB> '<a href=""%s"" target=""_blank"" title=""%s"" data-gallery=""gallery""><img src=""%s"" class=""field_img""/></a>' <TAB>  <TAB>  <TAB>  <TAB> % (img.url, result.label, img.url) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.include_image = True <TAB> return result",if result . value :,148
4439,"def run(self): <TAB> try: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> dp = self.queue_get_stoppable(self.inq) <MASK> return <TAB>  <TAB>  <TAB> # cannot ignore None here. will lead to unsynced send/recv <TAB>  <TAB>  <TAB> obj = self.func(dp) <TAB>  <TAB>  <TAB> self.queue_put_stoppable(self.outq, obj) <TAB> except Exception: <TAB>  <TAB> if self.stopped(): <TAB>  <TAB>  <TAB> pass  # skip duplicated error messages <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise <TAB> finally: <TAB>  <TAB> self.stop()",if self . stopped ( ) :,148
4440,"def _evaluate_local_single(self, iterator): <TAB> for batch in iterator: <TAB>  <TAB> in_arrays = convert._call_converter(self.converter, batch, self.device) <TAB>  <TAB> with function.no_backprop_mode(): <TAB>  <TAB>  <TAB> if isinstance(in_arrays, tuple): <TAB>  <TAB>  <TAB>  <TAB> results = self.calc_local(*in_arrays) <TAB>  <TAB>  <TAB> elif isinstance(in_arrays, dict): <TAB>  <TAB>  <TAB>  <TAB> results = self.calc_local(**in_arrays) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> results = self.calc_local(in_arrays) <MASK> self._progress_hook(batch) <TAB>  <TAB> yield results",if self . _progress_hook :,166
4441,"def merge(self, other): <TAB> d = self._name2ft <TAB> for name, (f, t) in other._name2ft.items(): <MASK> # Don't print here by default, since doing <TAB>  <TAB>  <TAB> # <TAB>  so breaks some of the buildbots <TAB>  <TAB>  <TAB> # print ""*** DocTestRunner.merge: '"" + name + ""' in both"" \ <TAB>  <TAB>  <TAB> # <TAB> "" testers; summing outcomes."" <TAB>  <TAB>  <TAB> f2, t2 = d[name] <TAB>  <TAB>  <TAB> f = f + f2 <TAB>  <TAB>  <TAB> t = t + t2 <TAB>  <TAB> d[name] = f, t",if name in d :,157
4442,"def _addSettingsToPanels(self, category, left, right): <TAB> count = len(profile.getSubCategoriesFor(category)) + len( <TAB>  <TAB> profile.getSettingsForCategory(category) <TAB> ) <TAB> p = left <TAB> n = 0 <TAB> for title in profile.getSubCategoriesFor(category): <TAB>  <TAB> n += 1 + len(profile.getSettingsForCategory(category, title)) <MASK> p = right <TAB>  <TAB> configBase.TitleRow(p, _(title)) <TAB>  <TAB> for s in profile.getSettingsForCategory(category, title): <TAB>  <TAB>  <TAB> configBase.SettingRow(p, s.getName())",if n > count / 2 :,159
4443,"def __init__(self, parent, dir, mask, with_dirs=True): <TAB> filelist = [] <TAB> dirlist = [""..""] <TAB> self.dir = dir <TAB> self.file = """" <TAB> mask = mask.upper() <TAB> pattern = self.MakeRegex(mask) <TAB> for i in os.listdir(dir): <MASK> continue <TAB>  <TAB> path = os.path.join(dir, i) <TAB>  <TAB> if os.path.isdir(path): <TAB>  <TAB>  <TAB> dirlist.append(i) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> path = path.upper() <TAB>  <TAB> value = i.upper() <TAB>  <TAB> if pattern.match(value) is not None: <TAB>  <TAB>  <TAB> filelist.append(i) <TAB> self.files = filelist <TAB> if with_dirs: <TAB>  <TAB> self.dirs = dirlist","if i == ""."" or i == "".."" :",199
4444,def check_network_private(test_network): <TAB> test_net = ipaddress.IPNetwork(test_network) <TAB> test_start = test_net.network <TAB> test_end = test_net.broadcast <TAB> for network in settings.vpn.safe_priv_subnets: <TAB>  <TAB> network = ipaddress.IPNetwork(network) <TAB>  <TAB> net_start = network.network <TAB>  <TAB> net_end = network.broadcast <MASK> return True <TAB> return False,if test_start >= net_start and test_end <= net_end :,128
4445,"def _end_description(self): <TAB> if self._summaryKey == ""content"": <TAB>  <TAB> self._end_content() <TAB> else: <TAB>  <TAB> value = self.popContent(""description"") <TAB>  <TAB> context = self._getContext() <MASK> context[""textinput""][""description""] = value <TAB>  <TAB> elif self.inimage: <TAB>  <TAB>  <TAB> context[""image""][""description""] = value <TAB> self._summaryKey = None",if self . intextinput :,107
4446,def compute_nullable_nonterminals(self): <TAB> nullable = {} <TAB> num_nullable = 0 <TAB> while 1: <TAB>  <TAB> for p in self.grammar.Productions[1:]: <MASK> nullable[p.name] = 1 <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> for t in p.prod: <TAB>  <TAB>  <TAB>  <TAB> if not t in nullable: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> nullable[p.name] = 1 <TAB>  <TAB> if len(nullable) == num_nullable: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> num_nullable = len(nullable) <TAB> return nullable,if p . len == 0 :,153
4447,"def process_bind_param(self, value, dialect): <TAB> if value is not None: <TAB>  <TAB> if MAX_METADATA_VALUE_SIZE is not None: <TAB>  <TAB>  <TAB> for k, v in list(value.items()): <TAB>  <TAB>  <TAB>  <TAB> sz = total_size(v) <MASK> del value[k] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> log.warning( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Refusing to bind metadata key {} due to size ({})"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> k, sz <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> value = json_encoder.encode(value).encode() <TAB> return value",if sz > MAX_METADATA_VALUE_SIZE :,168
4448,"def process_input_line(self, line, store_history=True): <TAB> """"""process the input, capturing stdout"""""" <TAB> stdout = sys.stdout <TAB> splitter = self.IP.input_splitter <TAB> try: <TAB>  <TAB> sys.stdout = self.cout <TAB>  <TAB> splitter.push(line) <TAB>  <TAB> more = splitter.push_accepts_more() <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> source_raw = splitter.source_raw_reset()[1] <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB> # recent ipython #4504 <TAB>  <TAB>  <TAB>  <TAB> source_raw = splitter.raw_reset() <TAB>  <TAB>  <TAB> self.IP.run_cell(source_raw, store_history=store_history) <TAB> finally: <TAB>  <TAB> sys.stdout = stdout",if not more :,186
4449,"def _dump_section(self, name, values, f): <TAB> doc = ""__doc__"" <MASK> print(""# %s"" % values[doc], file=f) <TAB> print(""%s("" % name, file=f) <TAB> for k, v in values.items(): <TAB>  <TAB> if k.endswith(""__doc__""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> doc = k + ""__doc__"" <TAB>  <TAB> if doc in values: <TAB>  <TAB>  <TAB> print("" <TAB> # %s"" % values[doc], file=f) <TAB>  <TAB> print("" <TAB> %s = %s,"" % (k, pprint.pformat(v, indent=8)), file=f) <TAB> print("")\n"", file=f)",if doc in values :,168
4450,"def open_session(self, app, request): <TAB> sid = request.cookies.get(app.session_cookie_name) <TAB> if sid: <TAB>  <TAB> stored_session = self.cls.objects(sid=sid).first() <TAB>  <TAB> if stored_session: <TAB>  <TAB>  <TAB> expiration = stored_session.expiration <MASK> expiration = expiration.replace(tzinfo=utc) <TAB>  <TAB>  <TAB> if expiration > datetime.datetime.utcnow().replace(tzinfo=utc): <TAB>  <TAB>  <TAB>  <TAB> return MongoEngineSession( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> initial=stored_session.data, sid=stored_session.sid <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return MongoEngineSession(sid=str(uuid.uuid4()))",if not expiration . tzinfo :,174
4451,"def table_entry(mode1, bind_type1, mode2, bind_type2): <TAB> with sock(mode1) as sock1: <TAB>  <TAB> bind(sock1, bind_type1) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> with sock(mode2) as sock2: <TAB>  <TAB>  <TAB>  <TAB> bind(sock2, bind_type2) <TAB>  <TAB> except OSError as exc: <MASK> return ""INUSE"" <TAB>  <TAB>  <TAB> elif exc.winerror == errno.WSAEACCES: <TAB>  <TAB>  <TAB>  <TAB> return ""ACCESS"" <TAB>  <TAB>  <TAB> raise <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""Success""",if exc . winerror == errno . WSAEADDRINUSE :,160
4452,"def __init__(self, ruleset): <TAB> # Organize rules by path <TAB> self.ruleset = ruleset <TAB> self.rules = {} <TAB> for filename in self.ruleset.rules: <TAB>  <TAB> for rule in self.ruleset.rules[filename]: <MASK> continue <TAB>  <TAB>  <TAB> manage_dictionary(self.rules, rule.path, []) <TAB>  <TAB>  <TAB> self.rules[rule.path].append(rule)",if not rule . enabled :,111
4453,"def talk(self, words): <TAB> if self.writeSentence(words) == 0: <TAB>  <TAB> return <TAB> r = [] <TAB> while 1: <TAB>  <TAB> i = self.readSentence() <TAB>  <TAB> if len(i) == 0: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> reply = i[0] <TAB>  <TAB> attrs = {} <TAB>  <TAB> for w in i[1:]: <TAB>  <TAB>  <TAB> j = w.find(""="", 1) <MASK> attrs[w] = """" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> attrs[w[:j]] = w[j + 1 :] <TAB>  <TAB> r.append((reply, attrs)) <TAB>  <TAB> if reply == ""!done"": <TAB>  <TAB>  <TAB> return r",if j == - 1 :,169
4454,"def _check_decorator_overload(name: str, old: str, new: str) -> int: <TAB> """"""Conditions for a decorator to overload an existing one."""""" <TAB> properties = _property_decorators(name) <TAB> if old == new: <TAB>  <TAB> return _MERGE <TAB> elif old in properties and new in properties: <TAB>  <TAB> p_old, p_new = properties[old].precedence, properties[new].precedence <MASK> return _DISCARD <TAB>  <TAB> elif p_old == p_new: <TAB>  <TAB>  <TAB> return _MERGE <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return _REPLACE <TAB> raise OverloadedDecoratorError(name, """")",if p_old > p_new :,158
4455,"def validate_pk(self): <TAB> try: <TAB>  <TAB> self._key = serialization.load_pem_private_key( <TAB>  <TAB>  <TAB> self.key, password=None, backend=default_backend() <TAB>  <TAB> ) <TAB>  <TAB> if self._key.key_size > 2048: <TAB>  <TAB>  <TAB> AWSValidationException( <TAB>  <TAB>  <TAB>  <TAB> ""The private key length is not supported. Only 1024-bit and 2048-bit are allowed."" <TAB>  <TAB>  <TAB> ) <TAB> except Exception as err: <MASK> raise <TAB>  <TAB> raise AWSValidationException( <TAB>  <TAB>  <TAB> ""The private key is not PEM-encoded or is not valid."" <TAB>  <TAB> )","if isinstance ( err , AWSValidationException ) :",157
4456,"def _add_custom_statement(self, custom_statements): <TAB> if custom_statements is None: <TAB>  <TAB> return <TAB> self.resource_policy[""Version""] = ""2012-10-17"" <TAB> if self.resource_policy.get(""Statement"") is None: <TAB>  <TAB> self.resource_policy[""Statement""] = custom_statements <TAB> else: <MASK> custom_statements = [custom_statements] <TAB>  <TAB> statement = self.resource_policy[""Statement""] <TAB>  <TAB> if not isinstance(statement, list): <TAB>  <TAB>  <TAB> statement = [statement] <TAB>  <TAB> for s in custom_statements: <TAB>  <TAB>  <TAB> if s not in statement: <TAB>  <TAB>  <TAB>  <TAB> statement.append(s) <TAB>  <TAB> self.resource_policy[""Statement""] = statement","if not isinstance ( custom_statements , list ) :",184
4457,"def load(self, repn): <TAB> for key in repn: <TAB>  <TAB> tmp = self._convert(key) <MASK> self.declare(tmp) <TAB>  <TAB> item = dict.__getitem__(self, tmp) <TAB>  <TAB> item._active = True <TAB>  <TAB> item.load(repn[key])",if tmp not in self :,80
4458,"def on_press_release(x): <TAB> """"""Keyboard callback function."""""" <TAB> global is_recording, enable_trigger_record <TAB> press = keyboard.KeyboardEvent(""down"", 28, ""space"") <TAB> release = keyboard.KeyboardEvent(""up"", 28, ""space"") <TAB> if x.event_type == ""down"" and x.name == press.name: <TAB>  <TAB> if (not is_recording) and enable_trigger_record: <TAB>  <TAB>  <TAB> sys.stdout.write(""Start Recording ... "") <TAB>  <TAB>  <TAB> sys.stdout.flush() <TAB>  <TAB>  <TAB> is_recording = True <TAB> if x.event_type == ""up"" and x.name == release.name: <MASK> is_recording = False",if is_recording == True :,173
4459,"def apply_mask(self, mask, data_t, data_f): <TAB> ind_t, ind_f = 0, 0 <TAB> out = [] <TAB> for m in cycle(mask): <TAB>  <TAB> if m: <TAB>  <TAB>  <TAB> if ind_t == len(data_t): <TAB>  <TAB>  <TAB>  <TAB> return out <TAB>  <TAB>  <TAB> out.append(data_t[ind_t]) <TAB>  <TAB>  <TAB> ind_t += 1 <TAB>  <TAB> else: <MASK> return out <TAB>  <TAB>  <TAB> out.append(data_f[ind_f]) <TAB>  <TAB>  <TAB> ind_f += 1 <TAB> return out",if ind_f == len ( data_f ) :,154
4460,"def oo_contains_rule(source, apiGroups, resources, verbs): <TAB> """"""Return true if the specified rule is contained within the provided source"""""" <TAB> rules = source[""rules""] <TAB> if rules: <TAB>  <TAB> for rule in rules: <TAB>  <TAB>  <TAB> if set(rule[""apiGroups""]) == set(apiGroups): <TAB>  <TAB>  <TAB>  <TAB> if set(rule[""resources""]) == set(resources): <MASK> return True <TAB> return False","if set ( rule [ ""verbs"" ] ) == set ( verbs ) :",118
4461,"def _maybe_commit_artifact(self, artifact_id): <TAB> artifact_status = self._artifacts[artifact_id] <TAB> if artifact_status[""pending_count""] == 0 and artifact_status[""commit_requested""]: <TAB>  <TAB> for callback in artifact_status[""pre_commit_callbacks""]: <TAB>  <TAB>  <TAB> callback() <MASK> self._api.commit_artifact(artifact_id) <TAB>  <TAB> for callback in artifact_status[""post_commit_callbacks""]: <TAB>  <TAB>  <TAB> callback()","if artifact_status [ ""finalize"" ] :",121
4462,"def shuffler(iterator, pool_size=10 ** 5, refill_threshold=0.9): <TAB> yields_between_refills = round(pool_size * (1 - refill_threshold)) <TAB> # initialize pool; this step may or may not exhaust the iterator. <TAB> pool = take_n(pool_size, iterator) <TAB> while True: <TAB>  <TAB> random.shuffle(pool) <TAB>  <TAB> for i in range(yields_between_refills): <TAB>  <TAB>  <TAB> yield pool.pop() <TAB>  <TAB> next_batch = take_n(yields_between_refills, iterator) <MASK> break <TAB>  <TAB> pool.extend(next_batch) <TAB> # finish consuming whatever's left - no need for further randomization. <TAB> yield from pool",if not next_batch :,186
4463,"def __getitem__(self, key, _get_mode=False): <TAB> if not _get_mode: <TAB>  <TAB> if isinstance(key, (int, long)): <TAB>  <TAB>  <TAB> return self._list[key] <MASK> return self.__class__(self._list[key]) <TAB> ikey = key.lower() <TAB> for k, v in self._list: <TAB>  <TAB> if k.lower() == ikey: <TAB>  <TAB>  <TAB> return v <TAB> # micro optimization: if we are in get mode we will catch that <TAB> # exception one stack level down so we can raise a standard <TAB> # key error instead of our special one. <TAB> if _get_mode: <TAB>  <TAB> raise KeyError() <TAB> raise BadRequestKeyError(key)","elif isinstance ( key , slice ) :",176
4464,"def find(self, path): <TAB> if os.path.isfile(path) or os.path.islink(path): <TAB>  <TAB> self.num_files = self.num_files + 1 <TAB>  <TAB> if self.match_function(path): <TAB>  <TAB>  <TAB> self.files.append(path) <TAB> elif os.path.isdir(path): <TAB>  <TAB> for content in os.listdir(path): <TAB>  <TAB>  <TAB> file = os.path.join(path, content) <TAB>  <TAB>  <TAB> if os.path.isfile(file) or os.path.islink(file): <TAB>  <TAB>  <TAB>  <TAB> self.num_files = self.num_files + 1 <MASK> self.files.append(file) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.find(file)",if self . match_function ( file ) :,192
4465,"def validate_nb(self, nb): <TAB> super(MetadataValidatorV3, self).validate_nb(nb) <TAB> ids = set([]) <TAB> for cell in nb.cells: <MASK> continue <TAB>  <TAB> grade = cell.metadata[""nbgrader""][""grade""] <TAB>  <TAB> solution = cell.metadata[""nbgrader""][""solution""] <TAB>  <TAB> locked = cell.metadata[""nbgrader""][""locked""] <TAB>  <TAB> if not grade and not solution and not locked: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> grade_id = cell.metadata[""nbgrader""][""grade_id""] <TAB>  <TAB> if grade_id in ids: <TAB>  <TAB>  <TAB> raise ValidationError(""Duplicate grade id: {}"".format(grade_id)) <TAB>  <TAB> ids.add(grade_id)","if ""nbgrader"" not in cell . metadata :",186
4466,"def _skip_start(self): <TAB> start, stop = self.start, self.stop <TAB> for chunk in self.app_iter: <TAB>  <TAB> self._pos += len(chunk) <TAB>  <TAB> if self._pos < start: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif self._pos == start: <TAB>  <TAB>  <TAB> return b"""" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> chunk = chunk[start - self._pos :] <MASK> chunk = chunk[: stop - self._pos] <TAB>  <TAB>  <TAB>  <TAB> assert len(chunk) == stop - start <TAB>  <TAB>  <TAB> return chunk <TAB> else: <TAB>  <TAB> raise StopIteration()",if stop is not None and self . _pos > stop :,156
4467,"def _SetUser(self, users): <TAB> for user in users.items(): <TAB>  <TAB> username = user[0] <TAB>  <TAB> settings = user[1] <TAB>  <TAB> room = settings[""room""][""name""] if ""room"" in settings else None <TAB>  <TAB> file_ = settings[""file""] if ""file"" in settings else None <TAB>  <TAB> if ""event"" in settings: <TAB>  <TAB>  <TAB> if ""joined"" in settings[""event""]: <TAB>  <TAB>  <TAB>  <TAB> self._client.userlist.addUser(username, room, file_) <MASK> self._client.removeUser(username) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._client.userlist.modUser(username, room, file_)","elif ""left"" in settings [ ""event"" ] :",170
4468,"def run_tests(): <TAB> # type: () -> None <TAB> x = 5 <TAB> with switch(x) as case: <TAB>  <TAB> if case(0): <TAB>  <TAB>  <TAB> print(""zero"") <TAB>  <TAB>  <TAB> print(""zero"") <MASK> print(""one or two"") <TAB>  <TAB> elif case(3, 4): <TAB>  <TAB>  <TAB> print(""three or four"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""default"") <TAB>  <TAB>  <TAB> print(""another"")","elif case ( 1 , 2 ) :",114
4469,"def _populate(): <TAB> for fname in glob.glob(os.path.join(os.path.dirname(__file__), ""data"", ""*.json"")): <TAB>  <TAB> with open(fname) as inf: <TAB>  <TAB>  <TAB> data = json.load(inf) <TAB>  <TAB>  <TAB> data = data[list(data.keys())[0]] <TAB>  <TAB>  <TAB> data = data[list(data.keys())[0]] <TAB>  <TAB>  <TAB> for item in data: <MASK> LOGGER.warning(""Repeated emoji {}"".format(item[""key""])) <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> TABLE[item[""key""]] = item[""value""]","if item [ ""key"" ] in TABLE :",157
4470,"def slot_to_material(bobject: bpy.types.Object, slot: bpy.types.MaterialSlot): <TAB> mat = slot.material <TAB> # Pick up backed material if present <TAB> if mat is not None: <TAB>  <TAB> baked_mat = mat.name + ""_"" + bobject.name + ""_baked"" <MASK> mat = bpy.data.materials[baked_mat] <TAB> return mat",if baked_mat in bpy . data . materials :,111
4471,"def __keyPress(self, widget, event): <TAB> if event.key == ""G"" and event.modifiers & event.Modifiers.Control: <TAB>  <TAB> if not all(hasattr(p, ""isGanged"") for p in self.getPlugs()): <TAB>  <TAB>  <TAB> return False <MASK> self.__ungang() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.__gang() <TAB>  <TAB> return True <TAB> return False",if all ( p . isGanged ( ) for p in self . getPlugs ( ) ) :,123
4472,"def check_expected(result, expected, contains=False): <TAB> if sys.version_info[0] >= 3: <TAB>  <TAB> if isinstance(result, str): <TAB>  <TAB>  <TAB> result = result.encode(""ascii"") <MASK> expected = expected.encode(""ascii"") <TAB> resultlines = result.splitlines() <TAB> expectedlines = expected.splitlines() <TAB> if len(resultlines) != len(expectedlines): <TAB>  <TAB> return False <TAB> for rline, eline in zip(resultlines, expectedlines): <TAB>  <TAB> if contains: <TAB>  <TAB>  <TAB> if eline not in rline: <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if not rline.endswith(eline): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB> return True","if isinstance ( expected , str ) :",181
4473,"def hosts_to_domains(self, hosts, exclusions=[]): <TAB> domains = [] <TAB> for host in hosts: <TAB>  <TAB> elements = host.split(""."") <TAB>  <TAB> # recursively walk through the elements <TAB>  <TAB> # extracting all possible (sub)domains <TAB>  <TAB> while len(elements) >= 2: <TAB>  <TAB>  <TAB> # account for domains stored as hosts <TAB>  <TAB>  <TAB> if len(elements) == 2: <TAB>  <TAB>  <TAB>  <TAB> domain = ""."".join(elements) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> # drop the host element <TAB>  <TAB>  <TAB>  <TAB> domain = ""."".join(elements[1:]) <MASK> domains.append(domain) <TAB>  <TAB>  <TAB> del elements[0] <TAB> return domains",if domain not in domains + exclusions :,167
4474,"def hsconn_sender(self): <TAB> while not self.stop_event.is_set(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> # Block, but timeout, so that we can exit the loop gracefully <TAB>  <TAB>  <TAB> request = self.send_queue.get(True, 6.0) <MASK> # Socket got closed and set to None in another thread... <TAB>  <TAB>  <TAB>  <TAB> self.socket.sendall(request) <TAB>  <TAB>  <TAB> if self.send_queue is not None: <TAB>  <TAB>  <TAB>  <TAB> self.send_queue.task_done() <TAB>  <TAB> except queue.Empty: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> self.stop_event.set()",if self . socket is not None :,168
4475,"def get_url_args(self, item): <TAB> if self.url_args: <MASK> url_args = self.url_args(item) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> url_args = dict(self.url_args) <TAB>  <TAB> url_args[""id""] = item.id <TAB>  <TAB> return url_args <TAB> else: <TAB>  <TAB> return dict(operation=self.label, id=item.id)","if hasattr ( self . url_args , ""__call__"" ) :",115
4476,"def list_projects(self): <TAB> projects = [] <TAB> page = 1 <TAB> while True: <TAB>  <TAB> repos = self._client.get( <TAB>  <TAB>  <TAB> ""/user/repos"", {""sort"": ""full_name"", ""page"": page, ""per_page"": 100} <TAB>  <TAB> ) <TAB>  <TAB> page += 1 <TAB>  <TAB> for repo in repos: <TAB>  <TAB>  <TAB> projects.append( <TAB>  <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""id"": repo[""full_name""], <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""name"": repo[""full_name""], <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""description"": repo[""description""], <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""is_private"": repo[""private""], <TAB>  <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB> ) <MASK> break <TAB> return projects",if len ( repos ) < 100 :,185
4477,"def scripts(self): <TAB> application_root = current_app.config.get(""APPLICATION_ROOT"") <TAB> subdir = application_root != ""/"" <TAB> scripts = [] <TAB> for script in get_registered_scripts(): <TAB>  <TAB> if script.startswith(""http""): <TAB>  <TAB>  <TAB> scripts.append(f'<script defer src=""{script}""></script>') <MASK> scripts.append(f'<script defer src=""{application_root}/{script}""></script>') <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> scripts.append(f'<script defer src=""{script}""></script>') <TAB> return markup(""\n"".join(scripts))",elif subdir :,146
4478,"def print_map(node, l): <TAB> if node.title not in l: <TAB>  <TAB> l[node.title] = [] <TAB> for n in node.children: <MASK> w = {n.title: []} <TAB>  <TAB>  <TAB> l[node.title].append(w) <TAB>  <TAB>  <TAB> print_map(n, w) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> l[node.title].append(n.title)",if len ( n . children ) > 0 :,112
4479,"def _validate_distinct_on_different_types_and_field_orders( <TAB> self, collection, query, expected_results, get_mock_result): <TAB> self.count = 0 <TAB> self.get_mock_result = get_mock_result <TAB> query_iterable = collection.query_items(query, enable_cross_partition_query=True) <TAB> results = list(query_iterable) <TAB> for i in range(len(expected_results)): <TAB>  <TAB> if isinstance(results[i], dict): <TAB>  <TAB>  <TAB> self.assertDictEqual(results[i], expected_results[i]) <MASK> self.assertListEqual(results[i], expected_results[i]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertEqual(results[i], expected_results[i]) <TAB> self.count = 0","elif isinstance ( results [ i ] , list ) :",196
4480,"def run(self): <TAB> for k, v in iteritems(self.objs): <MASK> continue <TAB>  <TAB> if ( <TAB>  <TAB>  <TAB> v[""_class""] == ""Question"" <TAB>  <TAB>  <TAB> or v[""_class""] == ""Message"" <TAB>  <TAB>  <TAB> or v[""_class""] == ""Announcement"" <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> v[""admin""] = None <TAB> return self.objs","if k . startswith ( ""_"" ) :",99
4481,"def qvec(self): <TAB> # <TAB>  <TAB> if self.polrep != 'stokes': <TAB> # <TAB>  <TAB>  <TAB> raise Exception(""qvec is not defined unless self.polrep=='stokes'"") <TAB> qvec = np.array([]) <TAB> if self.polrep == ""stokes"": <TAB>  <TAB> qvec = self._imdict[""Q""] <TAB> elif self.polrep == ""circ"": <MASK> qvec = np.real(0.5 * (self.lrvec + self.rlvec)) <TAB> return qvec",if len ( self . rlvec ) != 0 and len ( self . lrvec ) != 0 :,159
4482,"def display_value(self, key, w): <TAB> if key == ""vdevices"": <TAB>  <TAB> # Very special case <TAB>  <TAB> nids = [n[""deviceID""] for n in self.get_value(""devices"")] <TAB>  <TAB> for device in self.app.devices.values(): <MASK> b = Gtk.CheckButton(device.get_title(), False) <TAB>  <TAB>  <TAB>  <TAB> b.set_tooltip_text(device[""id""]) <TAB>  <TAB>  <TAB>  <TAB> self[""vdevices""].pack_start(b, False, False, 0) <TAB>  <TAB>  <TAB>  <TAB> b.set_active(device[""id""] in nids) <TAB>  <TAB> self[""vdevices""].show_all() <TAB> else: <TAB>  <TAB> EditorDialog.display_value(self, key, w)","if device [ ""id"" ] != self . app . daemon . get_my_id ( ) :",197
4483,"def _set_xflux_setting(self, **kwargs): <TAB> for key, value in kwargs.items(): <TAB>  <TAB> if key in self._settings_map: <MASK> self._set_xflux_screen_color(value) <TAB>  <TAB>  <TAB>  <TAB> self._current_color = str(value) <TAB>  <TAB>  <TAB>  <TAB> # hackish - changing the current color unpauses xflux, <TAB>  <TAB>  <TAB>  <TAB> # must reflect that with state change <TAB>  <TAB>  <TAB>  <TAB> if self.state == self.states[""PAUSED""]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.state = self.states[""RUNNING""] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._xflux.sendline(self._settings_map[key] + str(value)) <TAB>  <TAB>  <TAB> self._c()","if key == ""color"" :",187
4484,"def apply_acceleration(self, veh_ids, acc): <TAB> """"""See parent class."""""" <TAB> # to hand the case of a single vehicle <TAB> if type(veh_ids) == str: <TAB>  <TAB> veh_ids = [veh_ids] <TAB>  <TAB> acc = [acc] <TAB> for i, vid in enumerate(veh_ids): <MASK> this_vel = self.get_speed(vid) <TAB>  <TAB>  <TAB> next_vel = max([this_vel + acc[i] * self.sim_step, 0]) <TAB>  <TAB>  <TAB> self.kernel_api.vehicle.slowDown(vid, next_vel, 1e-3)",if acc [ i ] is not None and vid in self . get_ids ( ) :,172
4485,"def largest_factor_relatively_prime(a, b): <TAB> """"""Return the largest factor of a relatively prime to b."""""" <TAB> while 1: <TAB>  <TAB> d = gcd(a, b) <MASK> break <TAB>  <TAB> b = d <TAB>  <TAB> while 1: <TAB>  <TAB>  <TAB> q, r = divmod(a, d) <TAB>  <TAB>  <TAB> if r > 0: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> a = q <TAB> return a",if d <= 1 :,111
4486,"def check_status(self): <TAB> try: <TAB>  <TAB> du = psutil.disk_usage(""/"") <MASK> raise ServiceWarning( <TAB>  <TAB>  <TAB>  <TAB> ""{host} {percent}% disk usage exceeds {disk_usage}%"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> host=host, percent=du.percent, disk_usage=DISK_USAGE_MAX <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> except ValueError as e: <TAB>  <TAB> self.add_error(ServiceReturnedUnexpectedResult(""ValueError""), e)",if DISK_USAGE_MAX and du . percent >= DISK_USAGE_MAX :,136
4487,"def build_reply(self, msg, text=None, private=False, threaded=False): <TAB> response = self.build_message(text) <TAB> if msg.is_group: <MASK> response.frm = self.bot_identifier <TAB>  <TAB>  <TAB> response.to = IRCPerson(str(msg.frm)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> response.frm = IRCRoomOccupant(str(self.bot_identifier), msg.frm.room) <TAB>  <TAB>  <TAB> response.to = msg.frm.room <TAB> else: <TAB>  <TAB> response.frm = self.bot_identifier <TAB>  <TAB> response.to = msg.frm <TAB> return response",if private :,159
4488,"def _dict_refs(obj, named): <TAB> """"""Return key and value objects of a dict/proxy."""""" <TAB> try: <MASK> for k, v in _items(obj): <TAB>  <TAB>  <TAB>  <TAB> s = str(k) <TAB>  <TAB>  <TAB>  <TAB> yield _NamedRef(""[K] "" + s, k) <TAB>  <TAB>  <TAB>  <TAB> yield _NamedRef(""[V] "" + s + "": "" + _repr(v), v) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> for k, v in _items(obj): <TAB>  <TAB>  <TAB>  <TAB> yield k <TAB>  <TAB>  <TAB>  <TAB> yield v <TAB> except (KeyError, ReferenceError, TypeError) as x: <TAB>  <TAB> warnings.warn(""Iterating '%s': %r"" % (_classof(obj), x))",if named :,172
4489,"def fetch_images(): <TAB> images = [] <TAB> marker = None <TAB> while True: <TAB>  <TAB> batch = image_service.detail( <TAB>  <TAB>  <TAB> context, <TAB>  <TAB>  <TAB> filters=filters, <TAB>  <TAB>  <TAB> marker=marker, <TAB>  <TAB>  <TAB> sort_key=""created_at"", <TAB>  <TAB>  <TAB> sort_dir=""desc"", <TAB>  <TAB> ) <MASK> break <TAB>  <TAB> images += batch <TAB>  <TAB> marker = batch[-1][""id""] <TAB> return images",if not batch :,113
4490,"def compress(self, data_list): <TAB> warn_untested() <TAB> if data_list: <TAB>  <TAB> if data_list[1] in forms.fields.EMPTY_VALUES: <TAB>  <TAB>  <TAB> error = self.error_messages[""invalid_year""] <TAB>  <TAB>  <TAB> raise forms.ValidationError(error) <MASK> error = self.error_messages[""invalid_month""] <TAB>  <TAB>  <TAB> raise forms.ValidationError(error) <TAB>  <TAB> year = int(data_list[1]) <TAB>  <TAB> month = int(data_list[0]) <TAB>  <TAB> # find last day of the month <TAB>  <TAB> day = monthrange(year, month)[1] <TAB>  <TAB> return date(year, month, day) <TAB> return None",if data_list [ 0 ] in forms . fields . EMPTY_VALUES :,181
4491,"def _diff_dict(self, old, new): <TAB> diff = {} <TAB> removed = [] <TAB> added = [] <TAB> for key, value in old.items(): <TAB>  <TAB> if key not in new: <TAB>  <TAB>  <TAB> removed.append(key) <MASK> # modified is indicated by a remove and add <TAB>  <TAB>  <TAB> removed.append(key) <TAB>  <TAB>  <TAB> added.append(key) <TAB> for key, value in new.items(): <TAB>  <TAB> if key not in old: <TAB>  <TAB>  <TAB> added.append(key) <TAB> if removed: <TAB>  <TAB> diff[""removed""] = sorted(removed) <TAB> if added: <TAB>  <TAB> diff[""added""] = sorted(added) <TAB> return diff",elif old [ key ] != new [ key ] :,172
4492,"def add_filters(self, function): <TAB> try: <TAB>  <TAB> subscription = self.exists(function) <MASK> response = self._sns.call( <TAB>  <TAB>  <TAB>  <TAB> ""set_subscription_attributes"", <TAB>  <TAB>  <TAB>  <TAB> SubscriptionArn=subscription[""SubscriptionArn""], <TAB>  <TAB>  <TAB>  <TAB> AttributeName=""FilterPolicy"", <TAB>  <TAB>  <TAB>  <TAB> AttributeValue=json.dumps(self.filters), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> kappa.event_source.sns.LOG.debug(response) <TAB> except Exception: <TAB>  <TAB> kappa.event_source.sns.LOG.exception( <TAB>  <TAB>  <TAB> ""Unable to add filters for SNS topic %s"", self.arn <TAB>  <TAB> )",if subscription :,165
4493,"def init_weights(self, pretrained=None): <TAB> if isinstance(pretrained, str): <TAB>  <TAB> logger = logging.getLogger() <TAB>  <TAB> load_checkpoint(self, pretrained, strict=False, logger=logger) <TAB> elif pretrained is None: <TAB>  <TAB> for m in self.modules(): <TAB>  <TAB>  <TAB> if isinstance(m, nn.Conv2d): <TAB>  <TAB>  <TAB>  <TAB> kaiming_init(m) <MASK> constant_init(m, 1) <TAB> else: <TAB>  <TAB> raise TypeError(""pretrained must be a str or None"")","elif isinstance ( m , ( _BatchNorm , nn . GroupNorm ) ) :",141
4494,def test_is_native_login(self): <TAB> for campaign in self.campaign_lists: <TAB>  <TAB> native = campaigns.is_native_login(campaign) <MASK> assert_true(native) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert_false(native) <TAB> native = campaigns.is_proxy_login(self.invalid_campaign) <TAB> assert_true(native is None),"if campaign == ""prereg"" or campaign == ""erpc"" :",132
4495,"def _process_filter(self, query, host_state): <TAB> """"""Recursively parse the query structure."""""" <TAB> if not query: <TAB>  <TAB> return True <TAB> cmd = query[0] <TAB> method = self.commands[cmd] <TAB> cooked_args = [] <TAB> for arg in query[1:]: <TAB>  <TAB> if isinstance(arg, list): <TAB>  <TAB>  <TAB> arg = self._process_filter(arg, host_state) <MASK> arg = self._parse_string(arg, host_state) <TAB>  <TAB> if arg is not None: <TAB>  <TAB>  <TAB> cooked_args.append(arg) <TAB> result = method(self, cooked_args) <TAB> return result","elif isinstance ( arg , basestring ) :",163
4496,"def find_go_files_mtime(app_files): <TAB> files, mtime = [], 0 <TAB> for f, mt in app_files.items(): <MASK> continue <TAB>  <TAB> if APP_CONFIG.nobuild_files.match(f): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> files.append(f) <TAB>  <TAB> mtime = max(mtime, mt) <TAB> return files, mtime","if not f . endswith ( "".go"" ) :",100
4497,"def ExcludePath(self, path): <TAB> """"""Check to see if this is a service url and matches inbound_services."""""" <TAB> skip = False <TAB> for reserved_path in self.reserved_paths.keys(): <MASK> if ( <TAB>  <TAB>  <TAB>  <TAB> not self.inbound_services <TAB>  <TAB>  <TAB>  <TAB> or self.reserved_paths[reserved_path] not in self.inbound_services <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB> return (True, self.reserved_paths[reserved_path]) <TAB> return (False, None)",if path . startswith ( reserved_path ) :,132
4498,"def param_cov(self) -> DataFrame: <TAB> """"""Parameter covariance"""""" <TAB> if self._param_cov is not None: <TAB>  <TAB> param_cov = self._param_cov <TAB> else: <TAB>  <TAB> params = np.asarray(self.params) <MASK> param_cov = self.model.compute_param_cov(params) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> param_cov = self.model.compute_param_cov(params, robust=False) <TAB> return DataFrame(param_cov, columns=self._names, index=self._names)","if self . cov_type == ""robust"" :",141
4499,"def test_calculate_all_attentions(module, atype): <TAB> m = importlib.import_module(module) <TAB> args = make_arg(atype=atype) <MASK> batch = prepare_inputs(""pytorch"") <TAB> else: <TAB>  <TAB> raise NotImplementedError <TAB> model = m.E2E(6, 5, args) <TAB> with chainer.no_backprop_mode(): <TAB>  <TAB> if ""pytorch"" in module: <TAB>  <TAB>  <TAB> att_ws = model.calculate_all_attentions(*batch)[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise NotImplementedError <TAB>  <TAB> print(att_ws.shape)","if ""pytorch"" in module :",149
4500,"def __eq__(self, other): <TAB> try: <TAB>  <TAB> if self.type != other.type: <TAB>  <TAB>  <TAB> return False <MASK> return self.askAnswer == other.askAnswer <TAB>  <TAB> elif self.type == ""SELECT"": <TAB>  <TAB>  <TAB> return self.vars == other.vars and self.bindings == other.bindings <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return self.graph == other.graph <TAB> except: <TAB>  <TAB> return False","if self . type == ""ASK"" :",116
4501,"def validate_memory(self, value): <TAB> for k, v in value.viewitems(): <TAB>  <TAB> if v is None:  # use NoneType to unset a value <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if not re.match(PROCTYPE_MATCH, k): <TAB>  <TAB>  <TAB> raise serializers.ValidationError(""Process types can only contain [a-z]"") <MASK> raise serializers.ValidationError( <TAB>  <TAB>  <TAB>  <TAB> ""Limit format: <number><unit>, where unit = B, K, M or G"" <TAB>  <TAB>  <TAB> ) <TAB> return value","if not re . match ( MEMLIMIT_MATCH , str ( v ) ) :",141
4502,"def get_connections(data_about): <TAB> data = data_about.find(""h3"", text=""Connections"").findNext() <TAB> connections = {} <TAB> for row in data.find_all(""tr""): <TAB>  <TAB> key = row.find_all(""td"")[0].text <TAB>  <TAB> value = row.find_all(""td"")[1] <MASK> connections[key] = get_all_links(value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> connections[key] = value.text <TAB> return connections","if ""Teams"" in key :",129
4503,"def _compute_map(self, first_byte, second_byte=None): <TAB> if first_byte != 0x0F: <TAB>  <TAB> return ""XED_ILD_MAP0"" <TAB> else: <TAB>  <TAB> if second_byte == None: <TAB>  <TAB>  <TAB> return ""XED_ILD_MAP1"" <TAB>  <TAB> if second_byte == 0x38: <TAB>  <TAB>  <TAB> return ""XED_ILD_MAP2"" <TAB>  <TAB> if second_byte == 0x3A: <TAB>  <TAB>  <TAB> return ""XED_ILD_MAP3"" <MASK> return ""XED_ILD_MAPAMD"" <TAB> die(""Unhandled escape {} / map {} bytes"".format(first_byte, second_byte))",if second_byte == 0x0F and self . amd_enabled :,181
4504,"def compress(self, data_list): <TAB> if data_list: <TAB>  <TAB> page_id = data_list[1] <MASK> if not self.required: <TAB>  <TAB>  <TAB>  <TAB> return None <TAB>  <TAB>  <TAB> raise forms.ValidationError(self.error_messages[""invalid_page""]) <TAB>  <TAB> return Page.objects.get(pk=page_id) <TAB> return None",if page_id in EMPTY_VALUES :,98
4505,"def find_module(self, fullname, path=None): <TAB> path = path or self.path_entry <TAB> # print('looking for ""%s"" in %s ...' % (fullname, path)) <TAB> for _ext in [""js"", ""pyj"", ""py""]: <TAB>  <TAB> _filepath = os.path.join(self.path_entry, ""%s.%s"" % (fullname, _ext)) <MASK> print(""module found at %s:%s"" % (_filepath, fullname)) <TAB>  <TAB>  <TAB> return VFSModuleLoader(_filepath, fullname) <TAB> print(""module %s not found"" % fullname) <TAB> raise ImportError() <TAB> return None",if _filepath in VFS :,158
4506,"def __decToBin(self, myDec): <TAB> n = 0 <TAB> binOfDec = """" <TAB> while myDec > 2 ** n: <TAB>  <TAB> n = n + 1 <TAB> if (myDec < 2 ** n) & (myDec != 0): <TAB>  <TAB> n = n - 1 <TAB> while n >= 0: <MASK> myDec = myDec - 2 ** n <TAB>  <TAB>  <TAB> binOfDec = binOfDec + ""1"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> binOfDec = binOfDec + ""0"" <TAB>  <TAB> n = n - 1 <TAB> return binOfDec",if myDec >= 2 ** n :,148
4507,"def __str__(self): <TAB> try: <MASK> NVMLError._errcode_to_string[self.value] = str(nvmlErrorString(self.value)) <TAB>  <TAB> return NVMLError._errcode_to_string[self.value] <TAB> except NVMLError_Uninitialized: <TAB>  <TAB> return ""NVML Error with code %d"" % self.value",if self . value not in NVMLError . _errcode_to_string :,101
4508,"def abspath(pathdir: str) -> str: <TAB> if Path is not None and isinstance(pathdir, Path): <TAB>  <TAB> return pathdir.abspath() <TAB> else: <TAB>  <TAB> pathdir = path.abspath(pathdir) <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> pathdir = pathdir.decode(fs_encoding) <TAB>  <TAB>  <TAB> except UnicodeDecodeError as exc: <TAB>  <TAB>  <TAB>  <TAB> raise UnicodeDecodeError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""multibyte filename not supported on "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""this filesystem encoding "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""(%r)"" % fs_encoding <TAB>  <TAB>  <TAB>  <TAB> ) from exc <TAB>  <TAB> return pathdir","if isinstance ( pathdir , bytes ) :",156
4509,"def _get_vtkjs(self): <TAB> if self._vtkjs is None and self.object is not None: <MASK> if isfile(self.object): <TAB>  <TAB>  <TAB>  <TAB> with open(self.object, ""rb"") as f: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> vtkjs = f.read() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> data_url = urlopen(self.object) <TAB>  <TAB>  <TAB>  <TAB> vtkjs = data_url.read() <TAB>  <TAB> elif hasattr(self.object, ""read""): <TAB>  <TAB>  <TAB> vtkjs = self.object.read() <TAB>  <TAB> self._vtkjs = vtkjs <TAB> return self._vtkjs","if isinstance ( self . object , string_types ) and self . object . endswith ( "".vtkjs"" ) :",180
4510,"def _set_uid(self, val): <TAB> if val is not None: <TAB>  <TAB> if pwd is None: <TAB>  <TAB>  <TAB> self.bus.log(""pwd module not available; ignoring uid."", level=30) <TAB>  <TAB>  <TAB> val = None <MASK> val = pwd.getpwnam(val)[2] <TAB> self._uid = val","elif isinstance ( val , text_or_bytes ) :",92
4511,"def get_attached_nodes(self, external_account): <TAB> for node in self.get_nodes_with_oauth_grants(external_account): <MASK> continue <TAB>  <TAB> node_settings = node.get_addon(self.oauth_provider.short_name) <TAB>  <TAB> if node_settings is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if node_settings.external_account == external_account: <TAB>  <TAB>  <TAB> yield node",if node is None :,110
4512,"def from_obj(cls, py_obj): <TAB> if not isinstance(py_obj, Image): <TAB>  <TAB> raise TypeError(""py_obj must be a wandb.Image"") <TAB> else: <TAB>  <TAB> if hasattr(py_obj, ""_boxes"") and py_obj._boxes: <TAB>  <TAB>  <TAB> box_keys = list(py_obj._boxes.keys()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> box_keys = [] <MASK> mask_keys = list(py_obj.masks.keys()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> mask_keys = [] <TAB>  <TAB> return cls(box_keys, mask_keys)","if hasattr ( py_obj , ""masks"" ) and py_obj . masks :",164
4513,"def write(self, *bits): <TAB> for bit in bits: <TAB>  <TAB> if not self.bytestream: <TAB>  <TAB>  <TAB> self.bytestream.append(0) <TAB>  <TAB> byte = self.bytestream[self.bytenum] <TAB>  <TAB> if self.bitnum == 8: <MASK> byte = 0 <TAB>  <TAB>  <TAB>  <TAB> self.bytestream += bytes([byte]) <TAB>  <TAB>  <TAB> self.bytenum += 1 <TAB>  <TAB>  <TAB> self.bitnum = 0 <TAB>  <TAB> mask = 2 ** self.bitnum <TAB>  <TAB> if bit: <TAB>  <TAB>  <TAB> byte |= mask <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> byte &= ~mask <TAB>  <TAB> self.bytestream[self.bytenum] = byte <TAB>  <TAB> self.bitnum += 1",if self . bytenum == len ( self . bytestream ) - 1 :,186
4514,"def destroy(self, wipe=False): <TAB> if self.state == self.UP: <TAB>  <TAB> image = self.image() <MASK> return self.confirm_destroy(image, self.full_name, abort=False) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.warn(""tried to destroy {0} which didn't exist"".format(self.full_name)) <TAB> return True",if image :,95
4515,"def get_host_metadata(self): <TAB> meta = {} <TAB> if self.agent_url: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> resp = requests.get( <TAB>  <TAB>  <TAB>  <TAB> self.agent_url + ECS_AGENT_METADATA_PATH, timeout=1 <TAB>  <TAB>  <TAB> ).json() <MASK> match = AGENT_VERSION_EXP.search(resp.get(""Version"")) <TAB>  <TAB>  <TAB>  <TAB> if match is not None and len(match.groups()) == 1: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> meta[""ecs_version""] = match.group(1) <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> self.log.debug(""Error getting ECS version: %s"" % str(e)) <TAB> return meta","if ""Version"" in resp :",176
4516,"def _path_type(st, lst): <TAB> parts = [] <TAB> if st: <MASK> parts.append(""file"") <TAB>  <TAB> elif stat.S_ISDIR(st.st_mode): <TAB>  <TAB>  <TAB> parts.append(""dir"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> parts.append(""other"") <TAB> if lst: <TAB>  <TAB> if stat.S_ISLNK(lst.st_mode): <TAB>  <TAB>  <TAB> parts.append(""link"") <TAB> return "" "".join(parts)",if stat . S_ISREG ( st . st_mode ) :,130
4517,"def changed(self, action): <TAB> # Something was changed in the 'files' list <TAB> if len(action.key) >= 1 and action.key[0].lower() == ""files"": <TAB>  <TAB> # Refresh project files model <MASK> # Don't clear the existing items if only inserting new things <TAB>  <TAB>  <TAB> self.update_model(clear=False) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Clear existing items <TAB>  <TAB>  <TAB> self.update_model(clear=True)","if action . type == ""insert"" :",120
4518,"def process(self, resources, event=None): <TAB> client = local_session(self.manager.session_factory).client(""es"") <TAB> for r in resources: <MASK> result = self.manager.retry( <TAB>  <TAB>  <TAB>  <TAB> client.describe_elasticsearch_domain_config, <TAB>  <TAB>  <TAB>  <TAB> DomainName=r[""DomainName""], <TAB>  <TAB>  <TAB>  <TAB> ignore_err_codes=(""ResourceNotFoundException"",), <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> if result: <TAB>  <TAB>  <TAB>  <TAB> r[self.policy_attribute] = json.loads( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> result.get(""DomainConfig"").get(""AccessPolicies"").get(""Options"") <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return super().process(resources)",if self . policy_attribute not in r :,175
4519,"def line_items(self): <TAB> line_items = [] <TAB> for line in self.lines_str: <TAB>  <TAB> line = line.split(""|"") <TAB>  <TAB> line = line[1:-1]  # del first and last empty item (consequence of split) <TAB>  <TAB> items = [] <TAB>  <TAB> for item in line: <TAB>  <TAB>  <TAB> i = re.search(r""(\S+([ \t]+\S+)*)+"", item) <MASK> items.append(i.group()) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> items.append("" "") <TAB>  <TAB> line_items.append(items) <TAB> return line_items",if i :,151
4520,"def on_data(res): <TAB> if terminate.is_set(): <TAB>  <TAB> return <TAB> if args.strings and not args.no_content: <TAB>  <TAB> if type(res) == tuple: <TAB>  <TAB>  <TAB> f, v = res <TAB>  <TAB>  <TAB> if type(f) == unicode: <TAB>  <TAB>  <TAB>  <TAB> f = f.encode(""utf-8"") <TAB>  <TAB>  <TAB> if type(v) == unicode: <TAB>  <TAB>  <TAB>  <TAB> v = v.encode(""utf-8"") <TAB>  <TAB>  <TAB> self.success(""{}: {}"".format(f, v)) <MASK> self.success(res) <TAB> else: <TAB>  <TAB> self.success(res)",elif not args . content_only :,158
4521,"def get_servers(self, detail=True, search_opts=None): <TAB> rel_url = ""/servers/detail"" if detail else ""/servers"" <TAB> if search_opts is not None: <TAB>  <TAB> qparams = {} <TAB>  <TAB> for opt, val in search_opts.iteritems(): <TAB>  <TAB>  <TAB> qparams[opt] = val <MASK> query_string = ""?%s"" % urllib.urlencode(qparams) <TAB>  <TAB>  <TAB> rel_url += query_string <TAB> return self.api_get(rel_url)[""servers""]",if qparams :,130
4522,"def run(self): <TAB> while not self.__exit__: <MASK> sleep(10) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> o = self.playlist[0] <TAB>  <TAB> self.playlist.remove(o) <TAB>  <TAB> obj = json.loads(o) <TAB>  <TAB> if not ""args"" in obj: <TAB>  <TAB>  <TAB> obj[""args""] = {""ua"": """", ""header"": """", ""title"": """", ""referer"": """"} <TAB>  <TAB> obj[""play""] = False <TAB>  <TAB> self.handle = launch_player(obj[""urls""], obj[""ext""], **obj[""args""]) <TAB>  <TAB> self.handle.wait()",if len ( self . playlist ) == 0 :,151
4523,"def get_to_download_runs_ids(session, headers): <TAB> last_date = 0 <TAB> result = [] <TAB> while 1: <TAB>  <TAB> r = session.get(RUN_DATA_API.format(last_date=last_date), headers=headers) <MASK> run_logs = r.json()[""data""][""records""] <TAB>  <TAB>  <TAB> result.extend([i[""logs""][0][""stats""][""id""] for i in run_logs]) <TAB>  <TAB>  <TAB> last_date = r.json()[""data""][""lastTimestamp""] <TAB>  <TAB>  <TAB> since_time = datetime.utcfromtimestamp(last_date / 1000) <TAB>  <TAB>  <TAB> print(f""pares keep ids data since {since_time}"") <TAB>  <TAB>  <TAB> time.sleep(1)  # spider rule <TAB>  <TAB>  <TAB> if not last_date: <TAB>  <TAB>  <TAB>  <TAB> break <TAB> return result",if r . ok :,199
4524,"def __saveWork(self, work, results): <TAB> """"""Stores the resulting last log line to the cache with the proxy key"""""" <TAB> del work <TAB> # pylint: disable=broad-except <TAB> try: <MASK> __cached = self.__cache[results[0]] <TAB>  <TAB>  <TAB> __cached[self.__TIME] = time.time() <TAB>  <TAB>  <TAB> __cached[self.__LINE] = results[1] <TAB>  <TAB>  <TAB> __cached[self.__LLU] = results[2] <TAB> except KeyError as e: <TAB>  <TAB> # Could happen while switching jobs with work in the queue <TAB>  <TAB> pass <TAB> except Exception as e: <TAB>  <TAB> list(map(logger.warning, cuegui.Utils.exceptionOutput(e)))",if results :,170
4525,"def read_notes(rec): <TAB> found = [] <TAB> for tag in range(500, 595): <TAB>  <TAB> if tag in (505, 520): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> fields = rec.get_fields(str(tag)) <MASK> continue <TAB>  <TAB> for f in fields: <TAB>  <TAB>  <TAB> x = f.get_lower_subfields() <TAB>  <TAB>  <TAB> if x: <TAB>  <TAB>  <TAB>  <TAB> found.append("" "".join(x).strip("" "")) <TAB> if found: <TAB>  <TAB> return ""\n\n"".join(found)",if not fields :,134
4526,"def serialize_to(self, stream, alternate_script=None): <TAB> stream.write(self.txo_ref.tx_ref.hash) <TAB> stream.write_uint32(self.txo_ref.position) <TAB> if alternate_script is not None: <TAB>  <TAB> stream.write_string(alternate_script) <TAB> else: <MASK> stream.write_string(self.coinbase) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> stream.write_string(self.script.source) <TAB> stream.write_uint32(self.sequence)",if self . is_coinbase :,142
4527,"def func_named(self, arg): <TAB> result = None <TAB> target = ""do_"" + arg <TAB> if target in dir(self): <TAB>  <TAB> result = target <TAB> else: <MASK> # accept shortened versions of commands <TAB>  <TAB>  <TAB> funcs = [fname for fname in self.keywords if fname.startswith(arg)] <TAB>  <TAB>  <TAB> if len(funcs) == 1: <TAB>  <TAB>  <TAB>  <TAB> result = ""do_"" + funcs[0] <TAB> return result",if self . abbrev :,110
4528,"def static_login(self, token, *, bot): <TAB> # Necessary to get aiohttp to stop complaining about session creation <TAB> self.__session = aiohttp.ClientSession( <TAB>  <TAB> connector=self.connector, ws_response_class=DiscordClientWebSocketResponse <TAB> ) <TAB> old_token, old_bot = self.token, self.bot_token <TAB> self._token(token, bot=bot) <TAB> try: <TAB>  <TAB> data = await self.request(Route(""GET"", ""/users/@me"")) <TAB> except HTTPException as exc: <TAB>  <TAB> self._token(old_token, bot=old_bot) <MASK> raise LoginFailure(""Improper token has been passed."") from exc <TAB>  <TAB> raise <TAB> return data",if exc . response . status == 401 :,179
4529,"def render_buttons(self): <TAB> for x, button in enumerate(self.button_list): <TAB>  <TAB> gcolor = Gdk.color_parse(self.color_list[x]) <MASK> fgcolor = Gdk.color_parse(""#FFFFFF"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> fgcolor = Gdk.color_parse(""#000000"") <TAB>  <TAB> button.set_label(self.color_list[x]) <TAB>  <TAB> button.set_sensitive(True) <TAB>  <TAB> button.modify_bg(Gtk.StateType.NORMAL, gcolor) <TAB>  <TAB> button.modify_fg(Gtk.StateType.NORMAL, fgcolor)","if util . get_hls_val ( self . color_list [ x ] , ""light"" ) < 99 :",170
4530,"def _set_text(self, data): <TAB> lines = [] <TAB> for key, value in data.items(): <TAB>  <TAB> lines.append("""") <TAB>  <TAB> txt = yaml.dump({key: value}, default_flow_style=False) <TAB>  <TAB> title = self.titles.get(key) <MASK> lines.append(""# %s"" % title) <TAB>  <TAB> lines.append(txt.rstrip()) <TAB> txt = ""\n"".join(lines) + ""\n"" <TAB> txt = txt.lstrip() <TAB> self.edit.setPlainText(txt)",if title :,134
4531,"def build_path(self): <TAB> for variable in re_path_template.findall(self.path): <TAB>  <TAB> name = variable.strip(""{}"") <MASK> # No 'user' parameter provided, fetch it from Auth instead. <TAB>  <TAB>  <TAB> value = self.api.auth.get_username() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> value = quote(self.session.params[name]) <TAB>  <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB>  <TAB> raise TweepError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""No parameter value found for path variable: %s"" % name <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> del self.session.params[name] <TAB>  <TAB> self.path = self.path.replace(variable, value)","if name == ""user"" and ""user"" not in self . session . params and self . api . auth :",197
4532,"def _calculate_writes_for_built_in_indices(self, entity): <TAB> writes = 0 <TAB> for prop_name in entity.keys(): <MASK> prop_vals = entity[prop_name] <TAB>  <TAB>  <TAB> if isinstance(prop_vals, (list)): <TAB>  <TAB>  <TAB>  <TAB> num_prop_vals = len(prop_vals) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> num_prop_vals = 1 <TAB>  <TAB>  <TAB> writes += 2 * num_prop_vals <TAB> return writes",if not prop_name in entity . unindexed_properties ( ) :,131
4533,"def create_connection(self, address, protocol_factory=None, **kw): <TAB> """"""Helper method for creating a connection to an ``address``."""""" <TAB> protocol_factory = protocol_factory or self.create_protocol <TAB> if isinstance(address, tuple): <TAB>  <TAB> host, port = address <MASK> self.logger.debug(""Create connection %s:%s"", host, port) <TAB>  <TAB> _, protocol = await self._loop.create_connection( <TAB>  <TAB>  <TAB> protocol_factory, host, port, **kw <TAB>  <TAB> ) <TAB>  <TAB> await protocol.event(""connection_made"") <TAB> else: <TAB>  <TAB> raise NotImplementedError(""Could not connect to %s"" % str(address)) <TAB> return protocol",if self . debug :,165
4534,def _increment_bracket_num(self): <TAB> self._current_bracket -= 1 <TAB> if self._current_bracket < 0: <TAB>  <TAB> self._current_bracket = self._get_num_brackets() - 1 <TAB>  <TAB> self._current_iteration += 1 <MASK> self._current_bracket = 0,if self . _current_iteration > self . hyperband_iterations :,88
4535,"def get_cycle_path(self, curr_node, goal_node_index): <TAB> for dep in curr_node[""deps""]: <MASK> return [curr_node[""address""]] <TAB> for dep in curr_node[""deps""]: <TAB>  <TAB> path = self.get_cycle_path( <TAB>  <TAB>  <TAB> self.get_by_address(dep), goal_node_index <TAB>  <TAB> )  # self.nodelist[dep], goal_node_index) <TAB>  <TAB> if len(path) > 0: <TAB>  <TAB>  <TAB> path.insert(0, curr_node[""address""]) <TAB>  <TAB>  <TAB> return path <TAB> return []",if dep == goal_node_index :,153
4536,"def as_dict(path="""", version=""latest"", section=""meta-data""): <TAB> result = {} <TAB> dirs = dir(path, version, section) <TAB> if not dirs: <TAB>  <TAB> return None <TAB> for item in dirs: <TAB>  <TAB> if item.endswith(""/""): <TAB>  <TAB>  <TAB> records = as_dict(path + item, version, section) <MASK> result[item[:-1]] = records <TAB>  <TAB> elif is_dict.match(item): <TAB>  <TAB>  <TAB> idx, name = is_dict.match(item).groups() <TAB>  <TAB>  <TAB> records = as_dict(path + idx + ""/"", version, section) <TAB>  <TAB>  <TAB> if records: <TAB>  <TAB>  <TAB>  <TAB> result[name] = records <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result[item] = valueconv(get(path + item, version, section)) <TAB> return result",if records :,197
4537,"def preprocess_raw_enwik9(input_filename, output_filename): <TAB> with open(input_filename, ""r"") as f1: <TAB>  <TAB> with open(output_filename, ""w"") as f2: <TAB>  <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB>  <TAB> line = f1.readline() <TAB>  <TAB>  <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB>  <TAB> line = list(enwik9_norm_transform([line]))[0] <TAB>  <TAB>  <TAB>  <TAB> if line != "" "" and line != """": <MASK> line = line[1:] <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f2.writelines(line + ""\n"")","if line [ 0 ] == "" "" :",164
4538,"def _handle_unsubscribe(self, web_sock): <TAB> index = None <TAB> with await self._subscriber_lock: <TAB>  <TAB> for i, (subscriber_web_sock, _) in enumerate(self._subscribers): <MASK> index = i <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if index is not None: <TAB>  <TAB>  <TAB> del self._subscribers[index] <TAB>  <TAB> if not self._subscribers: <TAB>  <TAB>  <TAB> asyncio.ensure_future(self._unregister_subscriptions())",if subscriber_web_sock == web_sock :,124
4539,"def formatmonthname(self, theyear, themonth, withyear=True): <TAB> with TimeEncoding(self.locale) as encoding: <TAB>  <TAB> s = month_name[themonth] <TAB>  <TAB> if encoding is not None: <TAB>  <TAB>  <TAB> s = s.decode(encoding) <MASK> s = ""%s %s"" % (s, theyear) <TAB>  <TAB> return '<tr><th colspan=""7"" class=""month"">%s</th></tr>' % s",if withyear :,115
4540,"def generate_sitemaps(filename): <TAB> rows = (line.strip().split(""\t"") for line in open(filename)) <TAB> for sortkey, chunk in itertools.groupby(rows, lambda row: row[0]): <TAB>  <TAB> things = [] <TAB>  <TAB> _chunk = list(chunk) <TAB>  <TAB> for segment in _chunk: <TAB>  <TAB>  <TAB> sortkey = segment.pop(0) <TAB>  <TAB>  <TAB> last_modified = segment.pop(-1) <TAB>  <TAB>  <TAB> path = """".join(segment) <TAB>  <TAB>  <TAB> things.append(web.storage(path=path, last_modified=last_modified)) <MASK> write(""sitemaps/sitemap_%s.xml.gz"" % sortkey, sitemap(things))",if things :,165
4541,"def use_index( <TAB> self, term: Union[str, Index], *terms: Union[str, Index]) -> ""QueryBuilder"": <TAB> for t in (term, *terms): <MASK> self._use_indexes.append(t) <TAB>  <TAB> elif isinstance(t, str): <TAB>  <TAB>  <TAB> self._use_indexes.append(Index(t))","if isinstance ( t , Index ) :",94
4542,"def get_changed(self): <TAB> if self._is_expression(): <TAB>  <TAB> result = self._get_node_text(self.ast) <MASK> return None <TAB>  <TAB> return result <TAB> else: <TAB>  <TAB> collector = codeanalyze.ChangeCollector(self.source) <TAB>  <TAB> last_end = -1 <TAB>  <TAB> for match in self.matches: <TAB>  <TAB>  <TAB> start, end = match.get_region() <TAB>  <TAB>  <TAB> if start < last_end: <TAB>  <TAB>  <TAB>  <TAB> if not self._is_expression(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> last_end = end <TAB>  <TAB>  <TAB> replacement = self._get_matched_text(match) <TAB>  <TAB>  <TAB> collector.add_change(start, end, replacement) <TAB>  <TAB> return collector.get_changed()",if result == self . source :,189
4543,"def quiet_f(*args): <TAB> vars = {arg_name: Real(arg) for arg_name, arg in zip(arg_names, args)} <TAB> value = dynamic_scoping(quiet_expr.evaluate, vars, evaluation) <TAB> if expect_list: <TAB>  <TAB> if value.has_form(""List"", None): <TAB>  <TAB>  <TAB> value = [extract_pyreal(item) for item in value.leaves] <MASK> return None <TAB>  <TAB>  <TAB> return value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return None <TAB> else: <TAB>  <TAB> value = extract_pyreal(value) <TAB>  <TAB> if value is None or isinf(value) or isnan(value): <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> return value",if any ( item is None for item in value ) :,177
4544,"def _reemit_nested_event(self, event: Event): <TAB> source_index = self.index(event.source) <TAB> for attr in (""index"", ""new_index""): <MASK> src_index = ensure_tuple_index(event.index) <TAB>  <TAB>  <TAB> setattr(event, attr, (source_index,) + src_index) <TAB> if not hasattr(event, ""index""): <TAB>  <TAB> setattr(event, ""index"", source_index) <TAB> # reemit with this object's EventEmitter of the same type if present <TAB> # otherwise just emit with the EmitterGroup itself <TAB> getattr(self.events, event.type, self.events)(event)","if hasattr ( event , attr ) :",163
4545,"def check(self): <TAB> """"""Perform required checks to conclude if it's safe to operate"""""" <TAB> if self.interpreter.manual is None: <MASK> self.error = self.process.error <TAB>  <TAB>  <TAB> self.tip = self.process.tip <TAB>  <TAB>  <TAB> return False <TAB> start = time.time() <TAB> while not self._status(): <TAB>  <TAB> if time.time() - start >= 2:  # 2s <TAB>  <TAB>  <TAB> self.error = ""can't connect to the minserver on {}:{}"".format( <TAB>  <TAB>  <TAB>  <TAB> self.interpreter.host, self.interpreter.port <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.tip = ""check your vagrant machine is running"" <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> time.sleep(0.1) <TAB> return True",if not self . process . healthy :,189
4546,"def apply(self): <TAB> new_block = self.block.copy() <TAB> new_block.clear() <TAB> for inst in self.block.body: <MASK> const_assign = self._assign_const(inst) <TAB>  <TAB>  <TAB> new_block.append(const_assign) <TAB>  <TAB>  <TAB> inst = self._assign_getitem(inst, index=const_assign.target) <TAB>  <TAB> new_block.append(inst) <TAB> return new_block","if isinstance ( inst , Assign ) and inst . value in self . getattrs :",126
4547,"def _get_orientation(self): <TAB> if self.state: <TAB>  <TAB> rotation = [0] * 9 <TAB>  <TAB> inclination = [0] * 9 <TAB>  <TAB> gravity = [] <TAB>  <TAB> geomagnetic = [] <TAB>  <TAB> gravity = self.listener_a.values <TAB>  <TAB> geomagnetic = self.listener_m.values <MASK> ff_state = SensorManager.getRotationMatrix( <TAB>  <TAB>  <TAB>  <TAB> rotation, inclination, gravity, geomagnetic <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> if ff_state: <TAB>  <TAB>  <TAB>  <TAB> values = [0, 0, 0] <TAB>  <TAB>  <TAB>  <TAB> values = SensorManager.getOrientation(rotation, values) <TAB>  <TAB>  <TAB> return values",if gravity [ 0 ] is not None and geomagnetic [ 0 ] is not None :,187
4548,def getFirstSubGraph(graph): <TAB> if len(graph) == 0: <TAB>  <TAB> return None <TAB> subg = {} <TAB> todo = [graph.keys()[0]] <TAB> while len(todo) > 0: <MASK> subg[todo[0]] = graph[todo[0]] <TAB>  <TAB>  <TAB> todo.extend(graph[todo[0]]) <TAB>  <TAB>  <TAB> del graph[todo[0]] <TAB>  <TAB> del todo[0] <TAB> return subg,if todo [ 0 ] in graph . keys ( ) :,120
4549,"def decorated_function(*args, **kwargs): <TAB> rv = f(*args, **kwargs) <TAB> if ""Last-Modified"" not in rv.headers: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> result = date <TAB>  <TAB>  <TAB> if callable(result): <TAB>  <TAB>  <TAB>  <TAB> result = result(rv) <MASK> from werkzeug.http import http_date <TAB>  <TAB>  <TAB>  <TAB> result = http_date(result) <TAB>  <TAB>  <TAB> if result: <TAB>  <TAB>  <TAB>  <TAB> rv.headers[""Last-Modified""] = result <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> logging.getLogger(__name__).exception( <TAB>  <TAB>  <TAB>  <TAB> ""Error while calculating the lastmodified value for response {!r}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> rv <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> return rv","if not isinstance ( result , basestring ) :",189
4550,"def set_invoice_details(self, row): <TAB> invoice_details = self.invoice_details.get(row.voucher_no, {}) <TAB> if row.due_date: <TAB>  <TAB> invoice_details.pop(""due_date"", None) <TAB> row.update(invoice_details) <TAB> if row.voucher_type == ""Sales Invoice"": <MASK> self.set_delivery_notes(row) <TAB>  <TAB> if self.filters.show_sales_person and row.sales_team: <TAB>  <TAB>  <TAB> row.sales_person = "", "".join(row.sales_team) <TAB>  <TAB>  <TAB> del row[""sales_team""]",if self . filters . show_delivery_notes :,160
4551,"def process(output): <TAB> modules = {} <TAB> for line in output: <TAB>  <TAB> name, size, instances, depends, state, _ = line.split("" "", 5) <TAB>  <TAB> instances = int(instances) <TAB>  <TAB> module = { <TAB>  <TAB>  <TAB> ""size"": size, <TAB>  <TAB>  <TAB> ""instances"": instances, <TAB>  <TAB>  <TAB> ""state"": state, <TAB>  <TAB> } <MASK> module[""depends""] = [value for value in depends.split("","") if value] <TAB>  <TAB> modules[name] = module <TAB> return modules","if depends != ""-"" :",127
4552,"def _get_host_from_zc_service_info(service_info: zeroconf.ServiceInfo): <TAB> """"""Get hostname or IP + port from zeroconf service_info."""""" <TAB> host = None <TAB> port = None <TAB> if ( <TAB>  <TAB> service_info <TAB>  <TAB> and service_info.port <TAB>  <TAB> and (service_info.server or len(service_info.addresses) > 0) <TAB> ): <MASK> host = socket.inet_ntoa(service_info.addresses[0]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> host = service_info.server.lower() <TAB>  <TAB> port = service_info.port <TAB> return (host, port)",if len ( service_info . addresses ) > 0 :,170
4553,"def _init_weights(self, module): <TAB> if isinstance(module, nn.Linear): <TAB>  <TAB> module.weight.data.normal_(mean=0.0, std=self.config.init_std) <TAB>  <TAB> if module.bias is not None: <TAB>  <TAB>  <TAB> module.bias.data.zero_() <TAB> elif isinstance(module, nn.Embedding): <TAB>  <TAB> module.weight.data.normal_(mean=0.0, std=self.config.init_std) <MASK> module.weight.data[module.padding_idx].zero_()",if module . padding_idx is not None :,141
4554,"def visitFromImport(self, import_stmt, import_info): <TAB> new_pairs = [] <TAB> if not import_info.is_star_import(): <TAB>  <TAB> for name, alias in import_info.names_and_aliases: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> pyname = self.pymodule[alias or name] <MASK> continue <TAB>  <TAB>  <TAB> except exceptions.AttributeNotFoundError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> new_pairs.append((name, alias)) <TAB> return importinfo.FromImport(import_info.module_name, import_info.level, new_pairs)","if occurrences . same_pyname ( self . pyname , pyname ) :",162
4555,"def _apply_patches(self): <TAB> try: <TAB>  <TAB> s = Subprocess( <TAB>  <TAB>  <TAB> log=self.logfile, cwd=self.build_dir, verbose=self.options.verbose <TAB>  <TAB> ) <TAB>  <TAB> for patch in self.patches: <MASK> for ed, source in patch.items(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> s.shell(""ed - %s < %s"" % (source, ed)) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> s.shell(""patch -p0 < %s"" % patch) <TAB> except: <TAB>  <TAB> logger.error(""Failed to patch `%s`.\n%s"" % (self.build_dir, sys.exc_info()[1])) <TAB>  <TAB> sys.exit(1)",if type ( patch ) is dict :,183
4556,"def __init__(self, parent, dir, mask, with_dirs=True): <TAB> filelist = [] <TAB> dirlist = [""..""] <TAB> self.dir = dir <TAB> self.file = """" <TAB> mask = mask.upper() <TAB> pattern = self.MakeRegex(mask) <TAB> for i in os.listdir(dir): <TAB>  <TAB> if i == ""."" or i == "".."": <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> path = os.path.join(dir, i) <MASK> dirlist.append(i) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> path = path.upper() <TAB>  <TAB> value = i.upper() <TAB>  <TAB> if pattern.match(value) is not None: <TAB>  <TAB>  <TAB> filelist.append(i) <TAB> self.files = filelist <TAB> if with_dirs: <TAB>  <TAB> self.dirs = dirlist",if os . path . isdir ( path ) :,199
4557,"def remove_invalid_dirs(paths, bp_dir, module_name): <TAB> ret = [] <TAB> for path in paths: <MASK> ret.append(path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logging.warning('Dir ""%s"" of module ""%s"" does not exist', path, module_name) <TAB> return ret","if os . path . isdir ( os . path . join ( bp_dir , path ) ) :",98
4558,"def update_sockets(self): <TAB> inputs = self.inputs <TAB> inputs_n = ""ABabcd"" <TAB> penta_sockets = pentagon_dict[self.grid_type].input_sockets <TAB> for socket in inputs_n: <TAB>  <TAB> if socket in penta_sockets: <MASK> inputs[socket].hide_safe = False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> inputs[socket].hide_safe = True",if inputs [ socket ] . hide_safe :,113
4559,"def __cut(sentence): <TAB> global emit_P <TAB> prob, pos_list = viterbi(sentence, ""BMES"", start_P, trans_P, emit_P) <TAB> begin, nexti = 0, 0 <TAB> # print pos_list, sentence <TAB> for i, char in enumerate(sentence): <TAB>  <TAB> pos = pos_list[i] <TAB>  <TAB> if pos == ""B"": <TAB>  <TAB>  <TAB> begin = i <TAB>  <TAB> elif pos == ""E"": <TAB>  <TAB>  <TAB> yield sentence[begin : i + 1] <TAB>  <TAB>  <TAB> nexti = i + 1 <MASK> yield char <TAB>  <TAB>  <TAB> nexti = i + 1 <TAB> if nexti < len(sentence): <TAB>  <TAB> yield sentence[nexti:]","elif pos == ""S"" :",174
4560,"def validate(self): <TAB> if self.data.get(""encrypted"", True): <TAB>  <TAB> key = self.data.get(""target_key"") <MASK> raise PolicyValidationError( <TAB>  <TAB>  <TAB>  <TAB> ""Encrypted snapshot copy requires kms key on %s"" % (self.manager.data,) <TAB>  <TAB>  <TAB> ) <TAB> return self",if not key :,82
4561,"def __init__(self, patch_files, patch_directories): <TAB> files = [] <TAB> files_data = {} <TAB> for filename_data in patch_files: <TAB>  <TAB> if isinstance(filename_data, list): <TAB>  <TAB>  <TAB> filename, data = filename_data <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> filename = filename_data <TAB>  <TAB>  <TAB> data = None <MASK> filename = ""{0}{1}"".format(FakeState.deploy_dir, filename) <TAB>  <TAB> files.append(filename) <TAB>  <TAB> if data: <TAB>  <TAB>  <TAB> files_data[filename] = data <TAB> self.files = files <TAB> self.files_data = files_data <TAB> self.directories = patch_directories",if not filename . startswith ( os . sep ) :,171
4562,"def validate_name_and_description(body, check_length=True): <TAB> for attribute in [""name"", ""description"", ""display_name"", ""display_description""]: <TAB>  <TAB> value = body.get(attribute) <TAB>  <TAB> if value is not None: <TAB>  <TAB>  <TAB> if isinstance(value, six.string_types): <TAB>  <TAB>  <TAB>  <TAB> body[attribute] = value.strip() <MASK> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> utils.check_string_length( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> body[attribute], attribute, min_length=0, max_length=255 <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> except exception.InvalidInput as error: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise webob.exc.HTTPBadRequest(explanation=error.msg)",if check_length :,184
4563,"def pick(items, sel): <TAB> for x, s in zip(items, sel): <TAB>  <TAB> if match(s): <TAB>  <TAB>  <TAB> yield x <MASK> yield x.restructure(x.head, pick(x.leaves, s.leaves), evaluation)",elif not x . is_atom ( ) and not s . is_atom ( ) :,79
4564,"def wait_or_kill(self): <TAB> """"""Wait for the program to terminate, or kill it after 5s."""""" <TAB> if self.instance.poll() is None: <TAB>  <TAB> # We try one more time to kill gracefully using Ctrl-C. <TAB>  <TAB> logger.info(""Interrupting %s and waiting..."", self.coord) <TAB>  <TAB> self.instance.send_signal(signal.SIGINT) <TAB>  <TAB> # FIXME on py3 this becomes self.instance.wait(timeout=5) <TAB>  <TAB> t = monotonic_time() <TAB>  <TAB> while monotonic_time() - t < 5: <MASK> logger.info(""Terminated %s."", self.coord) <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> time.sleep(0.1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.kill()",if self . instance . poll ( ) is not None :,194
4565,"def sort_collection(self, models, many): <TAB> ordering = self.ordering <TAB> if not many or not ordering: <TAB>  <TAB> return models <TAB> for key in reversed(ordering): <TAB>  <TAB> reverse = key[0] == ""-"" <MASK> key = key[1:] <TAB>  <TAB> models = sorted(models, key=partial(deep_getattr, key=key), reverse=reverse) <TAB> return models",if reverse :,98
4566,"def get_palette_for_custom_classes(self, class_names, palette=None): <TAB> if self.label_map is not None: <TAB>  <TAB> # return subset of palette <TAB>  <TAB> palette = [] <TAB>  <TAB> for old_id, new_id in sorted(self.label_map.items(), key=lambda x: x[1]): <MASK> palette.append(self.PALETTE[old_id]) <TAB>  <TAB> palette = type(self.PALETTE)(palette) <TAB> elif palette is None: <TAB>  <TAB> if self.PALETTE is None: <TAB>  <TAB>  <TAB> palette = np.random.randint(0, 255, size=(len(class_names), 3)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> palette = self.PALETTE <TAB> return palette",if new_id != - 1 :,194
4567,"def _find_tcl_dir(): <TAB> lib_dirs = [os.path.dirname(_x) for _x in sys.path if _x.lower().endswith(""lib"")] <TAB> for lib_dir in lib_dirs: <TAB>  <TAB> base_dir = os.path.join(lib_dir, TclLibrary.FOLDER) <MASK> for root, _, files in os.walk(base_dir): <TAB>  <TAB>  <TAB>  <TAB> if TclLibrary.INIT_TCL in files: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return root",if os . path . exists ( base_dir ) :,133
4568,"def __next__(self): <TAB> """"""Special paging functionality"""""" <TAB> if self.iter is None: <TAB>  <TAB> self.iter = iter(self.objs) <TAB> try: <TAB>  <TAB> return next(self.iter) <TAB> except StopIteration: <TAB>  <TAB> self.iter = None <TAB>  <TAB> self.objs = [] <MASK> self.page += 1 <TAB>  <TAB>  <TAB> self._connection.get_response(self.action, self.params, self.page, self) <TAB>  <TAB>  <TAB> return next(self) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise",if int ( self . page ) < int ( self . total_pages ) :,144
4569,"def parse(cls, api, json): <TAB> lst = List(api) <TAB> setattr(lst, ""_json"", json) <TAB> for k, v in json.items(): <TAB>  <TAB> if k == ""user"": <TAB>  <TAB>  <TAB> setattr(lst, k, User.parse(api, v)) <MASK> setattr(lst, k, parse_datetime(v)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> setattr(lst, k, v) <TAB> return lst","elif k == ""created_at"" :",115
4570,"def real_type(self): <TAB> # Find the real type representation by updating it as required <TAB> real_type = self.type <TAB> if self.flag_indicator: <TAB>  <TAB> real_type = ""#"" <TAB> if self.is_vector: <MASK> real_type = ""Vector<{}>"".format(real_type) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> real_type = ""vector<{}>"".format(real_type) <TAB> if self.is_generic: <TAB>  <TAB> real_type = ""!{}"".format(real_type) <TAB> if self.is_flag: <TAB>  <TAB> real_type = ""flags.{}?{}"".format(self.flag_index, real_type) <TAB> return real_type",if self . use_vector_id :,171
4571,"def check_fs(path): <TAB> with open(path, ""rb"") as f: <TAB>  <TAB> code = python_bytes_to_unicode(f.read(), errors=""replace"") <MASK> module = _load_module(evaluator, path, code) <TAB>  <TAB>  <TAB> module_name = sys_path.dotted_path_in_sys_path( <TAB>  <TAB>  <TAB>  <TAB> evaluator.project.sys_path, path <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> if module_name is not None: <TAB>  <TAB>  <TAB>  <TAB> add_module(evaluator, module_name, module) <TAB>  <TAB>  <TAB> return module",if name in code :,143
4572,"def infoCalendar(users): <TAB> calendarId = normalizeCalendarId(sys.argv[5], checkPrimary=True) <TAB> i = 0 <TAB> count = len(users) <TAB> for user in users: <TAB>  <TAB> i += 1 <TAB>  <TAB> user, cal = buildCalendarGAPIObject(user) <TAB>  <TAB> if not cal: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> result = gapi.call( <TAB>  <TAB>  <TAB> cal.calendarList(), ""get"", soft_errors=True, calendarId=calendarId <TAB>  <TAB> ) <MASK> print(f""User: {user}, Calendar:{display.current_count(i, count)}"") <TAB>  <TAB>  <TAB> _showCalendar(result, 1, 1)",if result :,163
4573,"def set_hidestate_input_sockets_to_cope_with_switchnum(self): <TAB> tndict = get_indices_that_should_be_visible(self.node_state) <TAB> for key, value in tndict.items(): <TAB>  <TAB> socket = self.inputs[key] <TAB>  <TAB> desired_hide_state = not (value) <MASK> socket.hide_safe = desired_hide_state",if not socket . hide == desired_hide_state :,111
4574,"def get_class_name(item): <TAB> class_name, module_name = None, None <TAB> for parent in reversed(item.listchain()): <TAB>  <TAB> if isinstance(parent, pytest.Class): <TAB>  <TAB>  <TAB> class_name = parent.name <MASK> module_name = parent.module.__name__ <TAB>  <TAB>  <TAB> break <TAB> # heuristic: <TAB> # - better to group gpu and task tests, since tests from those modules <TAB> #   are likely to share caching more <TAB> # - split up the rest by class name because slow tests tend to be in <TAB> #   the same module <TAB> if class_name and "".tasks."" not in module_name: <TAB>  <TAB> return ""{}.{}"".format(module_name, class_name) <TAB> else: <TAB>  <TAB> return module_name","elif isinstance ( parent , pytest . Module ) :",190
4575,"def run(self): <TAB> versions = versioneer.get_versions() <TAB> tempdir = tempfile.mkdtemp() <TAB> generated = os.path.join(tempdir, ""rundemo"") <TAB> with open(generated, ""wb"") as f: <TAB>  <TAB> for line in open(""src/rundemo-template"", ""rb""): <MASK> f.write((""versions = %r\n"" % (versions,)).encode(""ascii"")) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> f.write(line) <TAB> self.scripts = [generated] <TAB> rc = build_scripts.run(self) <TAB> os.unlink(generated) <TAB> os.rmdir(tempdir) <TAB> return rc","if line . strip ( ) . decode ( ""ascii"" ) == ""#versions"" :",172
4576,"def get_user_context(request, escape=False): <TAB> if isinstance(request, HttpRequest): <TAB>  <TAB> user = getattr(request, ""user"", None) <TAB>  <TAB> result = {""ip_address"": request.META[""REMOTE_ADDR""]} <MASK> result.update( <TAB>  <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""email"": user.email, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""id"": user.id, <TAB>  <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> if user.name: <TAB>  <TAB>  <TAB>  <TAB> result[""name""] = user.name <TAB> else: <TAB>  <TAB> result = {} <TAB> return mark_safe(json.dumps(result))",if user and user . is_authenticated ( ) :,163
4577,"def tokens_to_spans() -> Iterable[Tuple[str, Optional[Style]]]: <TAB> """"""Convert tokens to spans."""""" <TAB> tokens = iter(line_tokenize()) <TAB> line_no = 0 <TAB> _line_start = line_start - 1 <TAB> # Skip over tokens until line start <TAB> while line_no < _line_start: <TAB>  <TAB> _token_type, token = next(tokens) <TAB>  <TAB> yield (token, None) <MASK> line_no += 1 <TAB> # Generate spans until line end <TAB> for token_type, token in tokens: <TAB>  <TAB> yield (token, _get_theme_style(token_type)) <TAB>  <TAB> if token.endswith(""\n""): <TAB>  <TAB>  <TAB> line_no += 1 <TAB>  <TAB>  <TAB> if line_no >= line_end: <TAB>  <TAB>  <TAB>  <TAB> break","if token . endswith ( ""\n"" ) :",194
4578,"def encode(self, encodeFun, value, defMode, maxChunkSize): <TAB> substrate, isConstructed = self.encodeValue(encodeFun, value, defMode, maxChunkSize) <TAB> tagSet = value.getTagSet() <TAB> if tagSet: <MASK> # primitive form implies definite mode <TAB>  <TAB>  <TAB> defMode = 1 <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB> self.encodeTag(tagSet[-1], isConstructed) <TAB>  <TAB>  <TAB> + self.encodeLength(len(substrate), defMode) <TAB>  <TAB>  <TAB> + substrate <TAB>  <TAB>  <TAB> + self._encodeEndOfOctets(encodeFun, defMode) <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> return substrate  # untagged value",if not isConstructed :,175
4579,def _run(self): <TAB> while True: <TAB>  <TAB> request = self._requests.get() <MASK> self.shutdown() <TAB>  <TAB>  <TAB> break <TAB>  <TAB> self.process(request) <TAB>  <TAB> self._requests.task_done(),if request is None :,64
4580,"def _decode_payload(self, payload): <TAB> # we need to decrypt it <TAB> if payload[""enc""] == ""aes"": <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> payload[""load""] = self.crypticle.loads(payload[""load""]) <TAB>  <TAB> except salt.crypt.AuthenticationError: <MASK> raise <TAB>  <TAB>  <TAB> payload[""load""] = self.crypticle.loads(payload[""load""]) <TAB> return payload",if not self . _update_aes ( ) :,107
4581,"def test_row(self, row): <TAB> for idx, test in self.patterns.items(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> value = row[idx] <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB> value = """" <TAB>  <TAB> result = test(value) <TAB>  <TAB> if self.any_match: <MASK> return not self.inverse  # True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if not result: <TAB>  <TAB>  <TAB>  <TAB> return self.inverse  # False <TAB> if self.any_match: <TAB>  <TAB> return self.inverse  # False <TAB> else: <TAB>  <TAB> return not self.inverse  # True",if result :,149
4582,"def setup_parameter_node(self, param_node): <TAB> if param_node.bl_idname == ""SvNumberNode"": <TAB>  <TAB> if self.use_prop or self.get_prop_name(): <TAB>  <TAB>  <TAB> value = self.sv_get()[0][0] <TAB>  <TAB>  <TAB> print(""V"", value) <TAB>  <TAB>  <TAB> if isinstance(value, int): <TAB>  <TAB>  <TAB>  <TAB> param_node.selected_mode = ""int"" <TAB>  <TAB>  <TAB>  <TAB> param_node.int_ = value <MASK> param_node.selected_mode = ""float"" <TAB>  <TAB>  <TAB>  <TAB> param_node.float_ = value","elif isinstance ( value , float ) :",156
4583,"def iter_modules(self, by_clients=False, clients_filter=None): <TAB> """"""iterate over all modules"""""" <TAB> clients = None <TAB> if by_clients: <TAB>  <TAB> clients = self.get_clients(clients_filter) <TAB>  <TAB> if not clients: <TAB>  <TAB>  <TAB> return <TAB> self._refresh_modules() <TAB> for module_name in self.modules: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> module = self.get_module(module_name) <TAB>  <TAB> except PupyModuleDisabled: <TAB>  <TAB>  <TAB> continue <MASK> for client in clients: <TAB>  <TAB>  <TAB>  <TAB> if module.is_compatible_with(client): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield module <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield module",if clients is not None :,181
4584,"def filter_pricing_rule_based_on_condition(pricing_rules, doc=None): <TAB> filtered_pricing_rules = [] <TAB> if doc: <TAB>  <TAB> for pricing_rule in pricing_rules: <TAB>  <TAB>  <TAB> if pricing_rule.condition: <TAB>  <TAB>  <TAB>  <TAB> try: <MASK> filtered_pricing_rules.append(pricing_rule) <TAB>  <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> filtered_pricing_rules.append(pricing_rule) <TAB> else: <TAB>  <TAB> filtered_pricing_rules = pricing_rules <TAB> return filtered_pricing_rules","if frappe . safe_eval ( pricing_rule . condition , None , doc . as_dict ( ) ) :",179
4585,"def build_query_string(kv_data, ignore_none=True): <TAB> # {""a"": 1, ""b"": ""test""} -> ""?a=1&b=test"" <TAB> query_string = """" <TAB> for k, v in kv_data.iteritems(): <MASK> continue <TAB>  <TAB> if query_string != """": <TAB>  <TAB>  <TAB> query_string += ""&"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> query_string = ""?"" <TAB>  <TAB> query_string += k + ""="" + str(v) <TAB> return query_string",if ignore_none is True and kv_data [ k ] is None :,140
4586,"def sample(self, **config): <TAB> """"""Sample a configuration from this search space."""""" <TAB> ret = {} <TAB> ret.update(self.data) <TAB> kwspaces = self.kwspaces <TAB> kwspaces.update(config) <TAB> striped_keys = [k.split(SPLITTER)[0] for k in config.keys()] <TAB> for k, v in kwspaces.items(): <TAB>  <TAB> if k in striped_keys: <MASK> sub_config = _strip_config_space(config, prefix=k) <TAB>  <TAB>  <TAB>  <TAB> ret[k] = v.sample(**sub_config) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> ret[k] = v <TAB> return ret","if isinstance ( v , NestedSpace ) :",172
4587,"def task_failed(self, task_id, hostname, reason): <TAB> logger.debug(""task %d failed with message %s"", task_id, str(reason)) <TAB> if hostname in self.host_dict: <TAB>  <TAB> host_status = self.host_dict[hostname] <TAB>  <TAB> host_status.task_failed(task_id) <MASK> self.task_host_failed_dict[task_id] = set() <TAB>  <TAB> self.task_host_failed_dict[task_id].add(hostname)",if task_id not in self . task_host_failed_dict :,141
4588,"def match(path): <TAB> for pat, _type, _property, default_title in patterns: <TAB>  <TAB> m = web.re_compile(""^"" + pat).match(path) <MASK> prefix = m.group() <TAB>  <TAB>  <TAB> extra = web.lstrips(path, prefix) <TAB>  <TAB>  <TAB> tokens = extra.split(""/"", 2) <TAB>  <TAB>  <TAB> # `extra` starts with ""/"". So first token is always empty. <TAB>  <TAB>  <TAB> middle = web.listget(tokens, 1, """") <TAB>  <TAB>  <TAB> suffix = web.listget(tokens, 2, """") <TAB>  <TAB>  <TAB> if suffix: <TAB>  <TAB>  <TAB>  <TAB> suffix = ""/"" + suffix <TAB>  <TAB>  <TAB> return _type, _property, default_title, prefix, middle, suffix <TAB> return None, None, None, None, None, None",if m :,187
4589,"def _get_cached_resources(self, ids): <TAB> key = self.get_cache_key(None) <TAB> if self._cache.load(): <TAB>  <TAB> resources = self._cache.get(key) <MASK> self.log.debug(""Using cached results for get_resources"") <TAB>  <TAB>  <TAB> m = self.get_model() <TAB>  <TAB>  <TAB> id_set = set(ids) <TAB>  <TAB>  <TAB> return [r for r in resources if r[m.id] in id_set] <TAB> return None",if resources is not None :,127
4590,"def has_api_behaviour(self, protocol): <TAB> config = get_config() <TAB> try: <TAB>  <TAB> r = self.session.get( <TAB>  <TAB>  <TAB> f""{protocol}://{self.event.host}:{self.event.port}"", <TAB>  <TAB>  <TAB> timeout=config.network_timeout, <TAB>  <TAB> ) <MASK> return True <TAB> except requests.exceptions.SSLError: <TAB>  <TAB> logger.debug( <TAB>  <TAB>  <TAB> f""{[protocol]} protocol not accepted on {self.event.host}:{self.event.port}"" <TAB>  <TAB> ) <TAB> except Exception: <TAB>  <TAB> logger.debug( <TAB>  <TAB>  <TAB> f""Failed probing {self.event.host}:{self.event.port}"", exc_info=True <TAB>  <TAB> )","if ( ""k8s"" in r . text ) or ( '""code""' in r . text and r . status_code != 200 ) :",200
4591,"def get_file_type(self, context, parent_context=None): <TAB> file_type = context.get(self.file_type_name, None) <TAB> if file_type == """": <MASK> file_type = parent_context.get(self.file_type_name, self.default_file_type) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> file_type = self.default_file_type <TAB> return file_type",if parent_context :,110
4592,"def selectionToChunks(self, remove=False, add=False): <TAB> box = self.selectionBox() <TAB> if box: <TAB>  <TAB> if box == self.level.bounds: <TAB>  <TAB>  <TAB> self.selectedChunks = set(self.level.allChunks) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> selectedChunks = self.selectedChunks <TAB>  <TAB> boxedChunks = set(box.chunkPositions) <MASK> remove = True <TAB>  <TAB> if remove and not add: <TAB>  <TAB>  <TAB> selectedChunks.difference_update(boxedChunks) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> selectedChunks.update(boxedChunks) <TAB> self.selectionTool.selectNone()",if boxedChunks . issubset ( selectedChunks ) :,158
4593,"def _run_split_on_punc(self, text, never_split=None): <TAB> """"""Splits punctuation on a piece of text."""""" <TAB> if never_split is not None and text in never_split: <TAB>  <TAB> return [text] <TAB> chars = list(text) <TAB> i = 0 <TAB> start_new_word = True <TAB> output = [] <TAB> while i < len(chars): <TAB>  <TAB> char = chars[i] <MASK> output.append([char]) <TAB>  <TAB>  <TAB> start_new_word = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if start_new_word: <TAB>  <TAB>  <TAB>  <TAB> output.append([]) <TAB>  <TAB>  <TAB> start_new_word = False <TAB>  <TAB>  <TAB> output[-1].append(char) <TAB>  <TAB> i += 1 <TAB> return ["""".join(x) for x in output]",if _is_punctuation ( char ) :,199
4594,"def _save_images(notebook): <TAB> if os.getenv(""NB_NO_IMAGES"") == ""1"": <TAB>  <TAB> return <TAB> logged = False <TAB> for filename, img_bytes in _iter_notebook_images(notebook): <MASK> log.info(""Saving images"") <TAB>  <TAB>  <TAB> logged = True <TAB>  <TAB> with open(filename, ""wb"") as f: <TAB>  <TAB>  <TAB> f.write(img_bytes)",if not logged :,104
4595,"def pickPath(self, color): <TAB> self.path[color] = () <TAB> currentPos = self.starts[color] <TAB> while True: <TAB>  <TAB> minDist = None <TAB>  <TAB> minGuide = None <TAB>  <TAB> for guide in self.guides[color]: <TAB>  <TAB>  <TAB> guideDist = dist(currentPos, guide) <MASK> minDist = guideDist <TAB>  <TAB>  <TAB>  <TAB> minGuide = guide <TAB>  <TAB> if dist(currentPos, self.ends[color]) == 1: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> if minGuide == None: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> self.path[color] = self.path[color] + (minGuide,) <TAB>  <TAB> currentPos = minGuide <TAB>  <TAB> self.guides[color].remove(minGuide)",if minDist == None or guideDist < minDist :,192
4596,"def _terminal_messenger(tp=""write"", msg="""", out=sys.stdout): <TAB> try: <MASK> out.write(msg) <TAB>  <TAB> elif tp == ""flush"": <TAB>  <TAB>  <TAB> out.flush() <TAB>  <TAB> elif tp == ""write_flush"": <TAB>  <TAB>  <TAB> out.write(msg) <TAB>  <TAB>  <TAB> out.flush() <TAB>  <TAB> elif tp == ""print"": <TAB>  <TAB>  <TAB> print(msg, file=out) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""Unsupported type: "" + tp) <TAB> except IOError as e: <TAB>  <TAB> logger.critical(""{}: {}"".format(type(e).__name__, ucd(e))) <TAB>  <TAB> pass","if tp == ""write"" :",160
4597,"def __new__(mcs, name, bases, attrs): <TAB> include_profile = include_trace = include_garbage = True <TAB> bases = list(bases) <TAB> if name == ""SaltLoggingClass"": <TAB>  <TAB> for base in bases: <MASK> include_trace = False <TAB>  <TAB>  <TAB> if hasattr(base, ""garbage""): <TAB>  <TAB>  <TAB>  <TAB> include_garbage = False <TAB> if include_profile: <TAB>  <TAB> bases.append(LoggingProfileMixin) <TAB> if include_trace: <TAB>  <TAB> bases.append(LoggingTraceMixin) <TAB> if include_garbage: <TAB>  <TAB> bases.append(LoggingGarbageMixin) <TAB> return super(LoggingMixinMeta, mcs).__new__(mcs, name, tuple(bases), attrs)","if hasattr ( base , ""trace"" ) :",176
4598,"def generatePidEncryptionTable(): <TAB> table = [] <TAB> for counter1 in range(0, 0x100): <TAB>  <TAB> value = counter1 <TAB>  <TAB> for counter2 in range(0, 8): <MASK> value = value >> 1 <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> value = value >> 1 <TAB>  <TAB>  <TAB>  <TAB> value = value ^ 0xEDB88320 <TAB>  <TAB> table.append(value) <TAB> return table",if value & 1 == 0 :,109
4599,"def pytest_collection_modifyitems(items): <TAB> for item in items: <TAB>  <TAB> if item.nodeid.startswith(""tests/params""): <MASK> item.add_marker(pytest.mark.stage(""unit"")) <TAB>  <TAB>  <TAB> if ""init"" not in item.keywords: <TAB>  <TAB>  <TAB>  <TAB> item.add_marker(pytest.mark.init(rng_seed=123))","if ""stage"" not in item . keywords :",102
4600,"def python_value(self, value): <TAB> if value: <TAB>  <TAB> if isinstance(value, basestring): <TAB>  <TAB>  <TAB> pp = lambda x: x.time() <TAB>  <TAB>  <TAB> return format_date_time(value, self.formats, pp) <MASK> return value.time() <TAB> if value is not None and isinstance(value, datetime.timedelta): <TAB>  <TAB> return (datetime.datetime.min + value).time() <TAB> return value","elif isinstance ( value , datetime . datetime ) :",113
4601,"def list_interesting_hosts(self): <TAB> hosts = [] <TAB> targets = self.target[""other""] <TAB> for target in targets: <MASK> hosts.append( <TAB>  <TAB>  <TAB>  <TAB> {""ip"": target.ip, ""description"": target.domain + "" / "" + target.name} <TAB>  <TAB>  <TAB> ) <TAB> return hosts",if self . is_interesting ( target ) and target . status and target . status != 400 :,99
4602,"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> length = d.getVarInt32() <TAB>  <TAB>  <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB>  <TAB>  <TAB> d.skip(length) <TAB>  <TAB>  <TAB> self.mutable_cost().TryMerge(tmp) <TAB>  <TAB>  <TAB> continue <MASK> self.add_version(d.getVarInt64()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 24 :,167
4603,"def _wait_for_finish(self) -> PollExitResponse: <TAB> while True: <TAB>  <TAB> if self._backend: <TAB>  <TAB>  <TAB> poll_exit_resp = self._backend.interface.communicate_poll_exit() <TAB>  <TAB> logger.info(""got exit ret: %s"", poll_exit_resp) <TAB>  <TAB> if poll_exit_resp: <TAB>  <TAB>  <TAB> done = poll_exit_resp.done <TAB>  <TAB>  <TAB> pusher_stats = poll_exit_resp.pusher_stats <MASK> self._on_finish_progress(pusher_stats, done) <TAB>  <TAB>  <TAB> if done: <TAB>  <TAB>  <TAB>  <TAB> return poll_exit_resp <TAB>  <TAB> time.sleep(2)",if pusher_stats :,170
4604,"def listing_items(method): <TAB> marker = None <TAB> once = True <TAB> items = [] <TAB> while once or items: <TAB>  <TAB> for i in items: <TAB>  <TAB>  <TAB> yield i <TAB>  <TAB> if once or marker: <MASK> items = method(parms={""marker"": marker}) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> items = method() <TAB>  <TAB>  <TAB> if len(items) == 10000: <TAB>  <TAB>  <TAB>  <TAB> marker = items[-1] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> marker = None <TAB>  <TAB>  <TAB> once = False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> items = []",if marker :,145
4605,"def call(monad, *args): <TAB> for arg, name in izip(args, (""hour"", ""minute"", ""second"", ""microsecond"")): <TAB>  <TAB> if not isinstance(arg, NumericMixin) or arg.type is not int: <TAB>  <TAB>  <TAB> throw( <TAB>  <TAB>  <TAB>  <TAB> TypeError, <TAB>  <TAB>  <TAB>  <TAB> ""'%s' argument of time(...) function must be of 'int' type. Got: %r"" <TAB>  <TAB>  <TAB>  <TAB> % (name, type2str(arg.type)), <TAB>  <TAB>  <TAB> ) <MASK> throw(NotImplementedError) <TAB> return ConstMonad.new(time(*tuple(arg.value for arg in args)))","if not isinstance ( arg , ConstMonad ) :",157
4606,"def group_by_sign(seq, slop=sin(pi / 18), key=lambda x: x): <TAB> sign = None <TAB> subseq = [] <TAB> for i in seq: <TAB>  <TAB> ki = key(i) <TAB>  <TAB> if sign is None: <TAB>  <TAB>  <TAB> subseq.append(i) <TAB>  <TAB>  <TAB> if ki != 0: <TAB>  <TAB>  <TAB>  <TAB> sign = ki / abs(ki) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> subseq.append(i) <MASK> sign = ki / abs(ki) <TAB>  <TAB>  <TAB>  <TAB> yield subseq <TAB>  <TAB>  <TAB>  <TAB> subseq = [i] <TAB> if subseq: <TAB>  <TAB> yield subseq",if sign * ki < - slop :,167
4607,"def walk_links(self): <TAB> link_info_list = [] <TAB> for item in self.content: <MASK> link_info = LinkInfo(link=item, name=item.name, sections=()) <TAB>  <TAB>  <TAB> link_info_list.append(link_info) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> link_info_list.extend(item.walk_links()) <TAB> return link_info_list","if isinstance ( item , Link ) :",106
4608,"def get_subkeys(self, key): <TAB> # TODO: once we revamp the registry emulation, <TAB> # make this better <TAB> parent_path = key.get_path() <TAB> subkeys = [] <TAB> for k in self.keys: <TAB>  <TAB> test_path = k.get_path() <TAB>  <TAB> if test_path.lower().startswith(parent_path.lower()): <TAB>  <TAB>  <TAB> sub = test_path[len(parent_path) :] <TAB>  <TAB>  <TAB> if sub.startswith(""\\""): <TAB>  <TAB>  <TAB>  <TAB> sub = sub[1:] <TAB>  <TAB>  <TAB> end_slash = sub.find(""\\"") <MASK> sub = sub[:end_slash] <TAB>  <TAB>  <TAB> if not sub: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> subkeys.append(sub) <TAB> return subkeys",if end_slash >= 0 :,192
4609,"def load_dict(dict_path, reverse=False): <TAB> word_dict = {} <TAB> with open(dict_path, ""rb"") as fdict: <TAB>  <TAB> for idx, line in enumerate(fdict): <TAB>  <TAB>  <TAB> line = cpt.to_text(line) <MASK> word_dict[idx] = line.strip(""\n"") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> word_dict[line.strip(""\n"")] = idx <TAB> return word_dict",if reverse :,118
4610,"def test_network(coords, feats, model, batch_sizes, forward_only=True): <TAB> for batch_size in batch_sizes: <TAB>  <TAB> bcoords = batched_coordinates([coords for i in range(batch_size)]) <TAB>  <TAB> bfeats = torch.cat([feats for i in range(batch_size)], 0) <MASK> with torch.no_grad(): <TAB>  <TAB>  <TAB>  <TAB> time, length = forward(bcoords, bfeats, model) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> time, length = train(bcoords, bfeats, model) <TAB>  <TAB> print(f""{net.__name__}\t{voxel_size}\t{batch_size}\t{length}\t{time}"") <TAB>  <TAB> torch.cuda.empty_cache()",if forward_only :,181
4611,"def markUVs(self, indices=None): <TAB> if isinstance(indices, tuple): <TAB>  <TAB> indices = indices[0] <TAB> ntexco = len(self.texco) <TAB> if indices is None: <TAB>  <TAB> self.utexc = True <TAB> else: <MASK> self.utexc = np.zeros(ntexco, dtype=bool) <TAB>  <TAB> if self.utexc is not True: <TAB>  <TAB>  <TAB> self.utexc[indices] = True",if self . utexc is False :,120
4612,"def has_module(self, module, version): <TAB> has_module = False <TAB> for directory in self.directories: <TAB>  <TAB> module_directory = join(directory, module) <TAB>  <TAB> has_module_directory = isdir(module_directory) <MASK> has_module = has_module_directory or exists( <TAB>  <TAB>  <TAB>  <TAB> module_directory <TAB>  <TAB>  <TAB> )  # could be a bare modulefile <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> modulefile = join(module_directory, version) <TAB>  <TAB>  <TAB> has_modulefile = exists(modulefile) <TAB>  <TAB>  <TAB> has_module = has_module_directory and has_modulefile <TAB>  <TAB> if has_module: <TAB>  <TAB>  <TAB> break <TAB> return has_module",if not version :,171
4613,"def get_editops(self): <TAB> if not self._editops: <MASK> self._editops = editops(self._opcodes, self._str1, self._str2) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._editops = editops(self._str1, self._str2) <TAB> return self._editops",if self . _opcodes :,86
4614,"def to_representation(self, data): <TAB> value = super(CredentialTypeSerializer, self).to_representation(data) <TAB> # translate labels and help_text for credential fields ""managed by Tower"" <TAB> if value.get(""managed_by_tower""): <TAB>  <TAB> value[""name""] = _(value[""name""]) <TAB>  <TAB> for field in value.get(""inputs"", {}).get(""fields"", []): <TAB>  <TAB>  <TAB> field[""label""] = _(field[""label""]) <MASK> field[""help_text""] = _(field[""help_text""]) <TAB> return value","if ""help_text"" in field :",140
4615,"def sort_nested_dictionary_lists(d): <TAB> for k, v in d.items(): <TAB>  <TAB> if isinstance(v, list): <TAB>  <TAB>  <TAB> for i in range(0, len(v)): <MASK> v[i] = await sort_nested_dictionary_lists(v[i]) <TAB>  <TAB>  <TAB>  <TAB> d[k] = sorted(v) <TAB>  <TAB> if isinstance(v, dict): <TAB>  <TAB>  <TAB> d[k] = await sort_nested_dictionary_lists(v) <TAB> return d","if isinstance ( v [ i ] , dict ) :",134
4616,"def messageSourceStamps(self, source_stamps): <TAB> text = """" <TAB> for ss in source_stamps: <TAB>  <TAB> source = """" <TAB>  <TAB> if ss[""branch""]: <TAB>  <TAB>  <TAB> source += ""[branch %s] "" % ss[""branch""] <TAB>  <TAB> if ss[""revision""]: <TAB>  <TAB>  <TAB> source += str(ss[""revision""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> source += ""HEAD"" <MASK> source += "" (plus patch)"" <TAB>  <TAB> discriminator = """" <TAB>  <TAB> if ss[""codebase""]: <TAB>  <TAB>  <TAB> discriminator = "" '%s'"" % ss[""codebase""] <TAB>  <TAB> text += ""Build Source Stamp%s: %s\n"" % (discriminator, source) <TAB> return text","if ss [ ""patch"" ] is not None :",176
4617,"def fit_one(self, x): <TAB> for i, xi in x.items(): <MASK> self.median[i].update(xi) <TAB>  <TAB> if self.with_scaling: <TAB>  <TAB>  <TAB> self.iqr[i].update(xi) <TAB> return self",if self . with_centering :,75
4618,"def start_response(self, status, headers, exc_info=None): <TAB> if exc_info: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> if self.started: <TAB>  <TAB>  <TAB>  <TAB> six.reraise(exc_info[0], exc_info[1], exc_info[2]) <TAB>  <TAB> finally: <TAB>  <TAB>  <TAB> exc_info = None <TAB> self.request.status = int(status[:3]) <TAB> for key, val in headers: <MASK> self.request.set_content_length(int(val)) <TAB>  <TAB> elif key.lower() == ""content-type"": <TAB>  <TAB>  <TAB> self.request.content_type = val <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.request.headers_out.add(key, val) <TAB> return self.write","if key . lower ( ) == ""content-length"" :",191
4619,"def _osp2ec(self, bytes): <TAB> compressed = self._from_bytes(bytes) <TAB> y = compressed >> self._bits <TAB> x = compressed & (1 << self._bits) - 1 <TAB> if x == 0: <TAB>  <TAB> y = self._curve.b <TAB> else: <TAB>  <TAB> result = self.sqrtp( <TAB>  <TAB>  <TAB> x ** 3 + self._curve.a * x + self._curve.b, self._curve.field.p <TAB>  <TAB> ) <TAB>  <TAB> if len(result) == 1: <TAB>  <TAB>  <TAB> y = result[0] <MASK> y1, y2 = result <TAB>  <TAB>  <TAB> y = y1 if (y1 & 1 == y) else y2 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return None <TAB> return ec.Point(self._curve, x, y)",elif len ( result ) == 2 :,200
4620,"def trace(self, ee, rname): <TAB> print(type(self)) <TAB> self.traceIndent() <TAB> guess = """" <TAB> if self.inputState.guessing > 0: <TAB>  <TAB> guess = "" [guessing]"" <TAB> print((ee + rname + guess)) <TAB> for i in xrange(1, self.k + 1): <TAB>  <TAB> if i != 1: <TAB>  <TAB>  <TAB> print("", "") <MASK> v = self.LT(i).getText() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> v = ""null"" <TAB>  <TAB> print(""LA(%s) == %s"" % (i, v)) <TAB> print(""\n"")",if self . LT ( i ) :,158
4621,"def _table_schema(self, table): <TAB> rows = self.db.execute_sql(""PRAGMA table_info('%s')"" % table).fetchall() <TAB> # Build list of fields from table information <TAB> result = {} <TAB> for _, name, data_type, not_null, _, primary_key in rows: <TAB>  <TAB> parts = [data_type] <TAB>  <TAB> if primary_key: <TAB>  <TAB>  <TAB> parts.append(""PRIMARY KEY"") <MASK> parts.append(""NOT NULL"") <TAB>  <TAB> result[name] = "" "".join(parts) <TAB> return result",if not_null :,137
4622,"def _parse_csrf(self, response): <TAB> for d in response: <TAB>  <TAB> if d.startswith(""Set-Cookie:""): <TAB>  <TAB>  <TAB> for c in d.split("":"", 1)[1].split("";""): <TAB>  <TAB>  <TAB>  <TAB> if c.strip().startswith(""CSRF-Token-""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self._CSRFtoken = c.strip("" \r\n"") <TAB>  <TAB>  <TAB>  <TAB>  <TAB> log.verbose(""Got new cookie: %s"", self._CSRFtoken) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <MASK> break",if self . _CSRFtoken != None :,135
4623,"def _update_from_item(self, row, download_item): <TAB> progress_stats = download_item.progress_stats <TAB> for key in self.columns: <TAB>  <TAB> column = self.columns[key][0] <MASK> # Not the best place but we build the playlist status here <TAB>  <TAB>  <TAB> status = ""{0} {1}/{2}"".format( <TAB>  <TAB>  <TAB>  <TAB> progress_stats[""status""], <TAB>  <TAB>  <TAB>  <TAB> progress_stats[""playlist_index""], <TAB>  <TAB>  <TAB>  <TAB> progress_stats[""playlist_size""], <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.SetStringItem(row, column, status) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.SetStringItem(row, column, progress_stats[key])","if key == ""status"" and progress_stats [ ""playlist_index"" ] :",183
4624,"def unmarshal_package_repositories(cls, data: Any) -> List[""PackageRepository""]: <TAB> repositories = list() <TAB> if data is not None: <MASK> raise RuntimeError(f""invalid package-repositories: {data!r}"") <TAB>  <TAB> for repository in data: <TAB>  <TAB>  <TAB> package_repo = cls.unmarshal(repository) <TAB>  <TAB>  <TAB> repositories.append(package_repo) <TAB> return repositories","if not isinstance ( data , list ) :",114
4625,"def remove_message(e=None): <TAB> itop = scanbox.nearest(0) <TAB> sel = scanbox.curselection() <TAB> if not sel: <TAB>  <TAB> dialog( <TAB>  <TAB>  <TAB> root, <TAB>  <TAB>  <TAB> ""No Message To Remove"", <TAB>  <TAB>  <TAB> ""Please select a message to remove"", <TAB>  <TAB>  <TAB> """", <TAB>  <TAB>  <TAB> 0, <TAB>  <TAB>  <TAB> ""OK"", <TAB>  <TAB> ) <TAB>  <TAB> return <TAB> todo = [] <TAB> for i in sel: <TAB>  <TAB> line = scanbox.get(i) <MASK> todo.append(string.atoi(scanparser.group(1))) <TAB> mhf.removemessages(todo) <TAB> rescan() <TAB> fixfocus(min(todo), itop)",if scanparser . match ( line ) >= 0 :,182
4626,"def test_patches(): <TAB> print( <TAB>  <TAB> ""Botocore version: {} aiohttp version: {}"".format( <TAB>  <TAB>  <TAB> botocore.__version__, aiohttp.__version__ <TAB>  <TAB> ) <TAB> ) <TAB> success = True <TAB> for obj, digests in chain(_AIOHTTP_DIGESTS.items(), _API_DIGESTS.items()): <TAB>  <TAB> digest = hashlib.sha1(getsource(obj).encode(""utf-8"")).hexdigest() <MASK> print( <TAB>  <TAB>  <TAB>  <TAB> ""Digest of {}:{} not found in: {}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> obj.__qualname__, digest, digests <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> success = False <TAB> assert success",if digest not in digests :,167
4627,"def sample_admin_user(): <TAB> """"""List of iris messages"""""" <TAB> with iris_ctl.db_from_config(sample_db_config) as (conn, cursor): <TAB>  <TAB> cursor.execute( <TAB>  <TAB>  <TAB> ""SELECT `name` FROM `target` JOIN `user` on `target`.`id` = `user`.`target_id` WHERE `user`.`admin` = TRUE LIMIT 1"" <TAB>  <TAB> ) <TAB>  <TAB> result = cursor.fetchone() <MASK> return result[0]",if result :,123
4628,"def _addRightnames(groups, kerning, leftname, rightnames, includeAll=True): <TAB> if leftname in kerning: <TAB>  <TAB> for rightname in kerning[leftname]: <MASK> for rightname2 in groups[rightname]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> rightnames.add(rightname2) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if not includeAll: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # TODO: in this case, pick the one rightname that has the highest <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # ranking in glyphorder <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> rightnames.add(rightname)","if rightname [ 0 ] == ""@"" :",161
4629,"def build(self, input_shape): <TAB> if isinstance(input_shape, list) and len(input_shape) == 2: <TAB>  <TAB> self.data_mode = ""disjoint"" <TAB>  <TAB> self.F = input_shape[0][-1] <TAB> else: <MASK> self.data_mode = ""single"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.data_mode = ""batch"" <TAB>  <TAB> self.F = input_shape[-1]",if len ( input_shape ) == 2 :,120
4630,"def update_ranges(l, i): <TAB> for _range in l: <TAB>  <TAB> # most common case: extend a range <MASK> _range[0] = i <TAB>  <TAB>  <TAB> merge_ranges(l) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> elif i == _range[1] + 1: <TAB>  <TAB>  <TAB> _range[1] = i <TAB>  <TAB>  <TAB> merge_ranges(l) <TAB>  <TAB>  <TAB> return <TAB> # somewhere outside of range proximity <TAB> l.append([i, i]) <TAB> l.sort(key=lambda x: x[0])",if i == _range [ 0 ] - 1 :,145
4631,"def transform(a, cmds): <TAB> buf = a.split(""\n"") <TAB> for cmd in cmds: <TAB>  <TAB> ctype, line, col, char = cmd <MASK> if char != ""\n"": <TAB>  <TAB>  <TAB>  <TAB> buf[line] = buf[line][:col] + buf[line][col + len(char) :] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> buf[line] = buf[line] + buf[line + 1] <TAB>  <TAB>  <TAB>  <TAB> del buf[line + 1] <TAB>  <TAB> elif ctype == ""I"": <TAB>  <TAB>  <TAB> buf[line] = buf[line][:col] + char + buf[line][col:] <TAB>  <TAB> buf = ""\n"".join(buf).split(""\n"") <TAB> return ""\n"".join(buf)","if ctype == ""D"" :",182
4632,"def _media_files_drag_received(widget, context, x, y, data, info, timestamp): <TAB> uris = data.get_uris() <TAB> files = [] <TAB> for uri in uris: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> uri_tuple = GLib.filename_from_uri(uri) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> uri, unused = uri_tuple <TAB>  <TAB> if os.path.exists(uri) == True: <MASK> files.append(uri) <TAB> if len(files) == 0: <TAB>  <TAB> return <TAB> open_dropped_files(files)",if utils . is_media_file ( uri ) == True :,159
4633,"def __walk_proceed_remote_dir_act(self, r, args): <TAB> dirjs, filejs = args <TAB> j = r.json() <TAB> if ""list"" not in j: <TAB>  <TAB> self.pd( <TAB>  <TAB>  <TAB> ""Key 'list' not found in the response of directory listing request:\n{}"".format( <TAB>  <TAB>  <TAB>  <TAB> j <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB>  <TAB> return const.ERequestFailed <TAB> paths = j[""list""] <TAB> for path in paths: <MASK> dirjs.append(path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> filejs.append(path) <TAB> return const.ENoError","if path [ ""isdir"" ] :",159
4634,"def TaskUpdatesVerbose(task, progress): <TAB> if isinstance(task.info.progress, int): <TAB>  <TAB> info = task.info <MASK> progress = ""%d%% (%s)"" % (info.progress, info.state) <TAB>  <TAB> print( <TAB>  <TAB>  <TAB> ""Task %s (key:%s, desc:%s) - %s"" <TAB>  <TAB>  <TAB> % (info.name.info.name, info.key, info.description, progress) <TAB>  <TAB> )","if not isinstance ( progress , str ) :",118
4635,"def dump_constants(header): <TAB> output = StringIO.StringIO() <TAB> output.write(header) <TAB> for attribute in dir(FSEvents): <TAB>  <TAB> value = getattr(FSEvents, attribute) <MASK> output.write("" <TAB> %s = %s\n"" % (attribute, hex(value))) <TAB> content = output.getvalue() <TAB> output.close() <TAB> return content","if attribute . startswith ( ""k"" ) and isinstance ( value , int ) :",112
4636,"def _ensure_data_is_loaded( <TAB> self, <TAB> sql_object, <TAB> input_params, <TAB> stdin_file, <TAB> stdin_filename=""-"", <TAB> stop_after_analysis=False,): <TAB> data_loads = [] <TAB> # Get each ""table name"" which is actually the file name <TAB> for filename in sql_object.qtable_names: <TAB>  <TAB> data_load = self._load_data( <TAB>  <TAB>  <TAB> filename, <TAB>  <TAB>  <TAB> input_params, <TAB>  <TAB>  <TAB> stdin_file=stdin_file, <TAB>  <TAB>  <TAB> stdin_filename=stdin_filename, <TAB>  <TAB>  <TAB> stop_after_analysis=stop_after_analysis, <TAB>  <TAB> ) <MASK> data_loads.append(data_load) <TAB> return data_loads",if data_load is not None :,189
4637,"def _get_instantiation(self): <TAB> if self._data is None: <TAB>  <TAB> f, l, c, o = c_object_p(), c_uint(), c_uint(), c_uint() <TAB>  <TAB> SourceLocation_loc(self, byref(f), byref(l), byref(c), byref(o)) <MASK> f = File(f) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> f = None <TAB>  <TAB> self._data = (f, int(l.value), int(c.value), int(c.value)) <TAB> return self._data",if f :,136
4638,"def _get_all_info_lines(data): <TAB> infos = [] <TAB> for row in data: <TAB>  <TAB> splitrow = row.split() <MASK> if splitrow[0] == ""INFO:"": <TAB>  <TAB>  <TAB>  <TAB> infos.append("" "".join(splitrow[1:])) <TAB> return infos",if len ( splitrow ) > 0 :,82
4639,"def _brush_modified_cb(self, settings): <TAB> """"""Updates the brush's base setting adjustments on brush changes"""""" <TAB> for cname in settings: <TAB>  <TAB> adj = self.brush_adjustment.get(cname, None) <MASK> continue <TAB>  <TAB> value = self.brush.get_base_value(cname) <TAB>  <TAB> adj.set_value(value)",if adj is None :,92
4640,"def migrate_node_facts(facts): <TAB> """"""Migrate facts from various roles into node"""""" <TAB> params = { <TAB>  <TAB> ""common"": (""dns_ip""), <TAB> } <TAB> if ""node"" not in facts: <TAB>  <TAB> facts[""node""] = {} <TAB> # pylint: disable=consider-iterating-dictionary <TAB> for role in params.keys(): <TAB>  <TAB> if role in facts: <TAB>  <TAB>  <TAB> for param in params[role]: <MASK> facts[""node""][param] = facts[role].pop(param) <TAB> return facts",if param in facts [ role ] :,136
4641,"def serialize_content_range(value): <TAB> if isinstance(value, (tuple, list)): <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""When setting content_range to a list/tuple, it must "" <TAB>  <TAB>  <TAB>  <TAB> ""be length 2 or 3 (not %r)"" % value <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> if len(value) == 2: <TAB>  <TAB>  <TAB> begin, end = value <TAB>  <TAB>  <TAB> length = None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> begin, end, length = value <TAB>  <TAB> value = ContentRange(begin, end, length) <TAB> value = str(value).strip() <TAB> if not value: <TAB>  <TAB> return None <TAB> return value","if len ( value ) not in ( 2 , 3 ) :",169
4642,"def clean(self): <TAB> data = super().clean() <TAB> if data.get(""expires""): <MASK> data[""expires""] = make_aware( <TAB>  <TAB>  <TAB>  <TAB> datetime.combine(data[""expires""], time(hour=23, minute=59, second=59)), <TAB>  <TAB>  <TAB>  <TAB> self.instance.event.timezone, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> data[""expires""] = data[""expires""].replace(hour=23, minute=59, second=59) <TAB>  <TAB> if data[""expires""] < now(): <TAB>  <TAB>  <TAB> raise ValidationError(_(""The new expiry date needs to be in the future."")) <TAB> return data","if isinstance ( data [ ""expires"" ] , date ) :",158
4643,"def _build(self, obj, stream, context): <TAB> if self.include_name: <TAB>  <TAB> name, obj = obj <TAB>  <TAB> for sc in self.subcons: <MASK> sc._build(obj, stream, context) <TAB>  <TAB>  <TAB>  <TAB> return <TAB> else: <TAB>  <TAB> for sc in self.subcons: <TAB>  <TAB>  <TAB> stream2 = BytesIO() <TAB>  <TAB>  <TAB> context2 = context.__copy__() <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> sc._build(obj, stream2, context2) <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> context.__update__(context2) <TAB>  <TAB>  <TAB>  <TAB> stream.write(stream2.getvalue()) <TAB>  <TAB>  <TAB>  <TAB> return <TAB> raise SelectError(""no subconstruct matched"", obj)",if sc . name == name :,195
4644,"def records(account_id): <TAB> """"""Fetch locks data"""""" <TAB> s = boto3.Session() <TAB> table = s.resource(""dynamodb"").Table(""Sphere11.Dev.ResourceLocks"") <TAB> results = table.scan() <TAB> for r in results[""Items""]: <MASK> r[""LockDate""] = datetime.fromtimestamp(r[""LockDate""]) <TAB>  <TAB> if ""RevisionDate"" in r: <TAB>  <TAB>  <TAB> r[""RevisionDate""] = datetime.fromtimestamp(r[""RevisionDate""]) <TAB> print(tabulate.tabulate(results[""Items""], headers=""keys"", tablefmt=""fancy_grid""))","if ""LockDate"" in r :",149
4645,"def visitIf(self, node, scope): <TAB> for test, body in node.tests: <TAB>  <TAB> if isinstance(test, ast.Const): <MASK> if not test.value: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> self.visit(test, scope) <TAB>  <TAB> self.visit(body, scope) <TAB> if node.else_: <TAB>  <TAB> self.visit(node.else_, scope)",if type ( test . value ) in self . _const_types :,112
4646,"def validate_max_discount(self): <TAB> if self.rate_or_discount == ""Discount Percentage"" and self.get(""items""): <TAB>  <TAB> for d in self.items: <TAB>  <TAB>  <TAB> max_discount = frappe.get_cached_value(""Item"", d.item_code, ""max_discount"") <MASK> throw( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _(""Max discount allowed for item: {0} is {1}%"").format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.item_code, max_discount <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> )",if max_discount and flt ( self . discount_percentage ) > flt ( max_discount ) :,158
4647,"def has_invalid_cce(yaml_file, product_yaml=None): <TAB> rule = yaml.open_and_macro_expand(yaml_file, product_yaml) <TAB> if ""identifiers"" in rule and rule[""identifiers""] is not None: <TAB>  <TAB> for i_type, i_value in rule[""identifiers""].items(): <TAB>  <TAB>  <TAB> if i_type[0:3] == ""cce"": <MASK> return True <TAB> return False","if not checks . is_cce_value_valid ( ""CCE-"" + str ( i_value ) ) :",134
4648,"def parse_calendar_eras(data, calendar): <TAB> eras = data.setdefault(""eras"", {}) <TAB> for width in calendar.findall(""eras/*""): <TAB>  <TAB> width_type = NAME_MAP[width.tag] <TAB>  <TAB> widths = eras.setdefault(width_type, {}) <TAB>  <TAB> for elem in width.getiterator(): <TAB>  <TAB>  <TAB> if elem.tag == ""era"": <TAB>  <TAB>  <TAB>  <TAB> _import_type_text(widths, elem, type=int(elem.attrib.get(""type""))) <MASK> eras[width_type] = Alias( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _translate_alias([""eras"", width_type], elem.attrib[""path""]) <TAB>  <TAB>  <TAB>  <TAB> )","elif elem . tag == ""alias"" :",170
4649,"def validate_grammar() -> None: <TAB> for fn in _NONTERMINAL_CONVERSIONS_SEQUENCE: <TAB>  <TAB> fn_productions = get_productions(fn) <TAB>  <TAB> if all(p.name == fn_productions[0].name for p in fn_productions): <TAB>  <TAB>  <TAB> # all the production names are the same, ensure that the `convert_` function <TAB>  <TAB>  <TAB> # is named correctly <TAB>  <TAB>  <TAB> production_name = fn_productions[0].name <TAB>  <TAB>  <TAB> expected_name = f""convert_{production_name}"" <MASK> raise Exception( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> f""The conversion function for '{production_name}' "" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> + f""must be called '{expected_name}', not '{fn.__name__}'."" <TAB>  <TAB>  <TAB>  <TAB> )",if fn . __name__ != expected_name :,189
4650,"def split_ratio(row): <TAB> if float(row[""Numerator""]) > 0: <MASK> n, m = row[""Splitratio""].split("":"") <TAB>  <TAB>  <TAB> return float(m) / float(n) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return eval(row[""Splitratio""]) <TAB> else: <TAB>  <TAB> return 1","if "":"" in row [ ""Splitratio"" ] :",87
4651,"def _handle_def_errors(testdef): <TAB> # If the test generation had an error, raise <TAB> if testdef.error: <TAB>  <TAB> if testdef.exception: <MASK> raise testdef.exception <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise Exception(testdef.exception) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception(""Test parse failure"")","if isinstance ( testdef . exception , Exception ) :",100
4652,"def _get_quota_availability(self): <TAB> quotas_ok = defaultdict(int) <TAB> qa = QuotaAvailability() <TAB> qa.queue(*[k for k, v in self._quota_diff.items() if v > 0]) <TAB> qa.compute(now_dt=self.now_dt) <TAB> for quota, count in self._quota_diff.items(): <TAB>  <TAB> if count <= 0: <TAB>  <TAB>  <TAB> quotas_ok[quota] = 0 <TAB>  <TAB>  <TAB> break <TAB>  <TAB> avail = qa.results[quota] <MASK> quotas_ok[quota] = min(count, avail[1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> quotas_ok[quota] = count <TAB> return quotas_ok",if avail [ 1 ] is not None and avail [ 1 ] < count :,182
4653,"def reverse(self): <TAB> """"""Reverse *IN PLACE*."""""" <TAB> li = self.leftindex <TAB> lb = self.leftblock <TAB> ri = self.rightindex <TAB> rb = self.rightblock <TAB> for i in range(self.len >> 1): <TAB>  <TAB> lb.data[li], rb.data[ri] = rb.data[ri], lb.data[li] <TAB>  <TAB> li += 1 <MASK> lb = lb.rightlink <TAB>  <TAB>  <TAB> li = 0 <TAB>  <TAB> ri -= 1 <TAB>  <TAB> if ri < 0: <TAB>  <TAB>  <TAB> rb = rb.leftlink <TAB>  <TAB>  <TAB> ri = BLOCKLEN - 1",if li >= BLOCKLEN :,156
4654,"def __manipulate_item(self, item): <TAB> if self._Cursor__manipulate: <TAB>  <TAB> db = self._Cursor__collection.database <TAB>  <TAB> son = db._fix_outgoing(item, self._Cursor__collection) <TAB> else: <TAB>  <TAB> son = item <TAB> if self.__wrap is not None: <MASK> return getattr(self._Cursor__collection, son[self.__wrap.type_field])(son) <TAB>  <TAB> return self.__wrap(son, collection=self._Cursor__collection) <TAB> else: <TAB>  <TAB> return son",if self . __wrap . type_field in son :,140
4655,"def apply_transforms(self): <TAB> """"""Apply all of the stored transforms, in priority order."""""" <TAB> self.document.reporter.attach_observer(self.document.note_transform_message) <TAB> while self.transforms: <MASK> # Unsorted initially, and whenever a transform is added. <TAB>  <TAB>  <TAB> self.transforms.sort() <TAB>  <TAB>  <TAB> self.transforms.reverse() <TAB>  <TAB>  <TAB> self.sorted = 1 <TAB>  <TAB> priority, transform_class, pending, kwargs = self.transforms.pop() <TAB>  <TAB> transform = transform_class(self.document, startnode=pending) <TAB>  <TAB> transform.apply(**kwargs) <TAB>  <TAB> self.applied.append((priority, transform_class, pending, kwargs))",if not self . sorted :,169
4656,"def format_sql(sql, params): <TAB> rv = [] <TAB> if isinstance(params, dict): <TAB>  <TAB> # convert sql with named parameters to sql with unnamed parameters <TAB>  <TAB> conv = _FormatConverter(params) <MASK> sql = sql_to_string(sql) <TAB>  <TAB>  <TAB> sql = sql % conv <TAB>  <TAB>  <TAB> params = conv.params <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> params = () <TAB> for param in params or (): <TAB>  <TAB> if param is None: <TAB>  <TAB>  <TAB> rv.append(""NULL"") <TAB>  <TAB> param = safe_repr(param) <TAB>  <TAB> rv.append(param) <TAB> return sql, rv",if params :,151
4657,"def on_execution_item(self, cpath, execution): <TAB> if not isinstance(execution, dict): <TAB>  <TAB> return <TAB> if ""executor"" in execution and execution.get(""executor"") != ""jmeter"": <TAB>  <TAB> return <TAB> scenario = execution.get(""scenario"", None) <MASK> return <TAB> if isinstance(scenario, str): <TAB>  <TAB> scenario_name = scenario <TAB>  <TAB> scenario = self.get_named_scenario(scenario_name) <TAB>  <TAB> if not scenario: <TAB>  <TAB>  <TAB> scenario = None <TAB>  <TAB> scenario_path = Path(""scenarios"", scenario_name) <TAB> else: <TAB>  <TAB> scenario_path = cpath.copy() <TAB>  <TAB> scenario_path.add_component(""scenario"") <TAB> if scenario is not None: <TAB>  <TAB> self.check_jmeter_scenario(scenario_path, scenario)",if not scenario :,192
4658,"def _poll_ipc_requests(self) -> None: <TAB> try: <TAB>  <TAB> if self._ipc_requests.empty(): <TAB>  <TAB>  <TAB> return <TAB>  <TAB> while not self._ipc_requests.empty(): <TAB>  <TAB>  <TAB> args = self._ipc_requests.get() <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> for filename in args: <MASK> self.get_editor_notebook().show_file(filename) <TAB>  <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB>  <TAB> logger.exception(""Problem processing ipc request"", exc_info=e) <TAB>  <TAB> self.become_active_window() <TAB> finally: <TAB>  <TAB> self.after(50, self._poll_ipc_requests)",if os . path . isfile ( filename ) :,180
4659,"def get_scroll_distance_to_element(driver, element): <TAB> try: <TAB>  <TAB> scroll_position = driver.execute_script(""return window.scrollY;"") <TAB>  <TAB> element_location = None <TAB>  <TAB> element_location = element.location[""y""] <TAB>  <TAB> element_location = element_location - 130 <MASK> element_location = 0 <TAB>  <TAB> distance = element_location - scroll_position <TAB>  <TAB> return distance <TAB> except Exception: <TAB>  <TAB> return 0",if element_location < 0 :,118
4660,"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_access_token(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> self.set_expiration_time(d.getVarInt64()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 16 :,124
4661,"def _validate_and_define(params, key, value): <TAB> (key, force_generic) = _validate_key(_unescape(key)) <TAB> if key in params: <TAB>  <TAB> raise SyntaxError(f'duplicate key ""{key}""') <TAB> cls = _class_for_key.get(key, GenericParam) <TAB> emptiness = cls.emptiness() <TAB> if value is None: <TAB>  <TAB> if emptiness == Emptiness.NEVER: <TAB>  <TAB>  <TAB> raise SyntaxError(""value cannot be empty"") <TAB>  <TAB> value = cls.from_value(value) <TAB> else: <MASK> value = cls.from_wire_parser(dns.wire.Parser(_unescape(value))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value = cls.from_value(value) <TAB> params[key] = value",if force_generic :,194
4662,"def iter_fields(node, *, include_meta=True, exclude_unset=False): <TAB> exclude_meta = not include_meta <TAB> for field_name, field in node._fields.items(): <MASK> continue <TAB>  <TAB> field_val = getattr(node, field_name, _marker) <TAB>  <TAB> if field_val is _marker: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if exclude_unset: <TAB>  <TAB>  <TAB> if callable(field.default): <TAB>  <TAB>  <TAB>  <TAB> default = field.default() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> default = field.default <TAB>  <TAB>  <TAB> if field_val == default: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> yield field_name, field_val",if exclude_meta and field . meta :,171
4663,"def tearDown(self): <TAB> """"""Shutdown the server."""""" <TAB> try: <TAB>  <TAB> if self.server: <TAB>  <TAB>  <TAB> self.server.stop() <MASK> self.root_logger.removeHandler(self.sl_hdlr) <TAB>  <TAB>  <TAB> self.sl_hdlr.close() <TAB> finally: <TAB>  <TAB> BaseTest.tearDown(self)",if self . sl_hdlr :,92
4664,"def _wait_for_async_copy(self, share_name, file_path): <TAB> count = 0 <TAB> share_client = self.fsc.get_share_client(share_name) <TAB> file_client = share_client.get_file_client(file_path) <TAB> properties = file_client.get_file_properties() <TAB> while properties.copy.status != ""success"": <TAB>  <TAB> count = count + 1 <MASK> self.fail(""Timed out waiting for async copy to complete."") <TAB>  <TAB> self.sleep(6) <TAB>  <TAB> properties = file_client.get_file_properties() <TAB> self.assertEqual(properties.copy.status, ""success"")",if count > 10 :,165
4665,"def __new__( <TAB> cls, <TAB> message_type: OrderBookMessageType, <TAB> content: Dict[str, any], <TAB> timestamp: Optional[float] = None, <TAB> *args, <TAB> **kwargs,): <TAB> if timestamp is None: <MASK> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> ""timestamp must not be None when initializing snapshot messages."" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> timestamp = int(time.time()) <TAB> return super(KucoinOrderBookMessage, cls).__new__( <TAB>  <TAB> cls, message_type, content, timestamp=timestamp, *args, **kwargs <TAB> )",if message_type is OrderBookMessageType . SNAPSHOT :,152
4666,"def _drop_unique_features( <TAB> X: DataFrame, feature_metadata: FeatureMetadata, max_unique_ratio) -> list: <TAB> features_to_drop = [] <TAB> X_len = len(X) <TAB> max_unique_value_count = X_len * max_unique_ratio <TAB> for column in X: <TAB>  <TAB> unique_value_count = len(X[column].unique()) <MASK> features_to_drop.append(column) <TAB>  <TAB> elif feature_metadata.get_feature_type_raw(column) in [ <TAB>  <TAB>  <TAB> R_CATEGORY, <TAB>  <TAB>  <TAB> R_OBJECT, <TAB>  <TAB> ] and (unique_value_count > max_unique_value_count): <TAB>  <TAB>  <TAB> features_to_drop.append(column) <TAB> return features_to_drop",if unique_value_count == 1 :,197
4667,"def get_src_findex_by_pad(s, S, padding_mode, align_corners): <TAB> if padding_mode == ""zero"": <TAB>  <TAB> return get_src_findex_with_zero_pad(s, S) <TAB> elif padding_mode == ""reflect"": <MASK> return get_src_findex_with_reflect_pad(s, S, True) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sf = get_src_findex_with_reflect_pad(s, S, False) <TAB>  <TAB>  <TAB> return get_src_findex_with_repeat_pad(sf, S) <TAB> elif padding_mode == ""repeat"": <TAB>  <TAB> return get_src_findex_with_repeat_pad(s, S)",if align_corners :,175
4668,"def _iterate_self_and_parents(self, upto=None): <TAB> current = self <TAB> result = () <TAB> while current: <TAB>  <TAB> result += (current,) <TAB>  <TAB> if current._parent is upto: <TAB>  <TAB>  <TAB> break <MASK> raise sa_exc.InvalidRequestError( <TAB>  <TAB>  <TAB>  <TAB> ""Transaction %s is not on the active transaction list"" % (upto) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> current = current._parent <TAB> return result",elif current . _parent is None :,126
4669,"def __setattr__(self, name: str, val: Any): <TAB> if name.startswith(""COMPUTED_""): <MASK> old_val = self[name] <TAB>  <TAB>  <TAB> if old_val == val: <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB>  <TAB> raise KeyError( <TAB>  <TAB>  <TAB>  <TAB> ""Computed attributed '{}' already exists "" <TAB>  <TAB>  <TAB>  <TAB> ""with a different value! old={}, new={}."".format(name, old_val, val) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self[name] = val <TAB> else: <TAB>  <TAB> super().__setattr__(name, val)",if name in self :,137
4670,"def get_fnlist(bbhandler, pkg_pn, preferred): <TAB> """"""Get all recipe file names"""""" <MASK> (latest_versions, preferred_versions) = bb.providers.findProviders( <TAB>  <TAB>  <TAB> bbhandler.config_data, bbhandler.cooker.recipecaches[""""], pkg_pn <TAB>  <TAB> ) <TAB> fn_list = [] <TAB> for pn in sorted(pkg_pn): <TAB>  <TAB> if preferred: <TAB>  <TAB>  <TAB> fn_list.append(preferred_versions[pn][1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> fn_list.extend(pkg_pn[pn]) <TAB> return fn_list",if preferred :,150
4671,"def links_extracted(self, _, links): <TAB> links_deduped = {} <TAB> for link in links: <TAB>  <TAB> link_fingerprint = link.meta[FIELD_FINGERPRINT] <MASK> continue <TAB>  <TAB> links_deduped[link_fingerprint] = link <TAB> [ <TAB>  <TAB> self._redis_pipeline.hmset(fingerprint, self._create_link_extracted(link)) <TAB>  <TAB> for (fingerprint, link) in links_deduped.items() <TAB> ] <TAB> self._redis_pipeline.execute()",if link_fingerprint in links_deduped :,138
4672,"def __call__(self, name, rawtext, text, lineno, inliner, options=None, content=None): <TAB> options = options or {} <TAB> content = content or [] <TAB> issue_nos = [each.strip() for each in utils.unescape(text).split("","")] <TAB> config = inliner.document.settings.env.app.config <TAB> ret = [] <TAB> for i, issue_no in enumerate(issue_nos): <TAB>  <TAB> node = self.make_node(name, issue_no, config, options=options) <TAB>  <TAB> ret.append(node) <MASK> sep = nodes.raw(text="", "", format=""html"") <TAB>  <TAB>  <TAB> ret.append(sep) <TAB> return ret, []",if i != len ( issue_nos ) - 1 :,176
4673,"def init_messengers(messengers): <TAB> for messenger in messengers: <MASK> module_path = messenger[""type""] <TAB>  <TAB>  <TAB> messenger[""type""] = messenger[""type""].split(""."")[-1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> module_path = ""oncall.messengers."" + messenger[""type""] <TAB>  <TAB> instance = getattr(importlib.import_module(module_path), messenger[""type""])( <TAB>  <TAB>  <TAB> messenger <TAB>  <TAB> ) <TAB>  <TAB> for transport in instance.supports: <TAB>  <TAB>  <TAB> _active_messengers[transport].append(instance)","if ""."" in messenger [ ""type"" ] :",141
4674,"def _process_enum_definition(self, tok): <TAB> fields = [] <TAB> for field in tok.fields: <MASK> expression = self.expression_parser.parse(field.expression) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> expression = None <TAB>  <TAB> fields.append(c_ast.CEnumField(name=field.name.first, value=expression)) <TAB> name = tok.enum_name <TAB> if name: <TAB>  <TAB> name = ""enum %s"" % tok.enum_name.first <TAB> else: <TAB>  <TAB> name = self._make_anonymous_type(""enum"") <TAB> return c_ast.CTypeDefinition( <TAB>  <TAB> name=name, <TAB>  <TAB> type_definition=c_ast.CEnum( <TAB>  <TAB>  <TAB> attributes=tok.attributes, fields=fields, name=name <TAB>  <TAB> ), <TAB> )",if field . expression :,199
4675,def result_iterator(): <TAB> try: <TAB>  <TAB> # reverse to keep finishing order <TAB>  <TAB> fs.reverse() <TAB>  <TAB> while fs: <TAB>  <TAB>  <TAB> # Careful not to keep a reference to the popped future <MASK> yield fs.pop().result() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> yield fs.pop().result(end_time - time.time()) <TAB> finally: <TAB>  <TAB> for future in fs: <TAB>  <TAB>  <TAB> future.cancel(),if timeout is None :,117
4676,"def has_encrypted_ssh_key_data(self): <TAB> try: <TAB>  <TAB> ssh_key_data = self.get_input(""ssh_key_data"") <TAB> except AttributeError: <TAB>  <TAB> return False <TAB> try: <TAB>  <TAB> pem_objects = validate_ssh_private_key(ssh_key_data) <TAB>  <TAB> for pem_object in pem_objects: <MASK> return True <TAB> except ValidationError: <TAB>  <TAB> pass <TAB> return False","if pem_object . get ( ""key_enc"" , False ) :",123
4677,"def test_seq_object_transcription_method(self): <TAB> for nucleotide_seq in test_seqs: <MASK> self.assertEqual( <TAB>  <TAB>  <TAB>  <TAB> repr(Seq.transcribe(nucleotide_seq)), <TAB>  <TAB>  <TAB>  <TAB> repr(nucleotide_seq.transcribe()), <TAB>  <TAB>  <TAB> )","if isinstance ( nucleotide_seq , Seq . Seq ) :",96
4678,"def max_elevation(self): <TAB> max_el = None <TAB> for y in xrange(self.height): <TAB>  <TAB> for x in xrange(self.width): <TAB>  <TAB>  <TAB> el = self.elevation[""data""][y][x] <MASK> max_el = el <TAB> return max_el",if max_el is None or el > max_el :,91
4679,"def stress(mapping, index): <TAB> for count in range(OPERATIONS): <TAB>  <TAB> function = random.choice(functions) <TAB>  <TAB> function(mapping, index) <MASK> print(""\r"", len(mapping), "" "" * 7, end="""") <TAB> print()",if count % 1000 == 0 :,72
4680,"def sync_terminology(self): <TAB> if self.is_source: <TAB>  <TAB> return <TAB> store = self.store <TAB> missing = [] <TAB> for source in self.component.get_all_sources(): <TAB>  <TAB> if ""terminology"" not in source.all_flags: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> _unit, add = store.find_unit(source.context, source.source) <TAB>  <TAB> except UnitNotFound: <TAB>  <TAB>  <TAB> add = True <TAB>  <TAB> # Unit is already present <MASK> continue <TAB>  <TAB> missing.append((source.context, source.source, """")) <TAB> if missing: <TAB>  <TAB> self.add_units(None, missing)",if not add :,166
4681,"def get_generators(self): <TAB> """"""Get a dict with all registered generators, indexed by name"""""" <TAB> generators = {} <TAB> for core in self.db.find(): <MASK> _generators = core.get_generators({}) <TAB>  <TAB>  <TAB> if _generators: <TAB>  <TAB>  <TAB>  <TAB> generators[str(core.name)] = _generators <TAB> return generators","if hasattr ( core , ""get_generators"" ) :",93
4682,"def act(self, state): <TAB> if self.body.env.clock.frame < self.training_start_step: <TAB>  <TAB> return policy_util.random(state, self, self.body).cpu().squeeze().numpy() <TAB> else: <TAB>  <TAB> action = self.action_policy(state, self, self.body) <MASK> action = self.scale_action(torch.tanh(action))  # continuous action bound <TAB>  <TAB> return action.cpu().squeeze().numpy()",if not self . body . is_discrete :,124
4683,"def try_open_completions_event(self, event=None): <TAB> ""(./) Open completion list after pause with no movement."" <TAB> lastchar = self.text.get(""insert-1c"") <TAB> if lastchar in TRIGGERS: <TAB>  <TAB> args = TRY_A if lastchar == ""."" else TRY_F <TAB>  <TAB> self._delayed_completion_index = self.text.index(""insert"") <MASK> self.text.after_cancel(self._delayed_completion_id) <TAB>  <TAB> self._delayed_completion_id = self.text.after( <TAB>  <TAB>  <TAB> self.popupwait, self._delayed_open_completions, args <TAB>  <TAB> )",if self . _delayed_completion_id is not None :,167
4684,"def token_is_available(self): <TAB> if self.token: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> resp = requests.get( <TAB>  <TAB>  <TAB>  <TAB> ""https://api.shodan.io/account/profile?key={0}"".format(self.token) <TAB>  <TAB>  <TAB> ) <MASK> return True <TAB>  <TAB> except Exception as ex: <TAB>  <TAB>  <TAB> logger.error(str(ex)) <TAB> return False","if resp and resp . status_code == 200 and ""member"" in resp . json ( ) :",121
4685,"def next_bar_(self, event): <TAB> bars = event.bar_dict <TAB> self._current_minute = self._minutes_since_midnight( <TAB>  <TAB> self.ucontext.now.hour, self.ucontext.now.minute <TAB> ) <TAB> for day_rule, time_rule, func in self._registry: <MASK> with ExecutionContext(EXECUTION_PHASE.SCHEDULED): <TAB>  <TAB>  <TAB>  <TAB> with ModifyExceptionFromType(EXC_TYPE.USER_EXC): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> func(self.ucontext, bars) <TAB> self._last_minute = self._current_minute",if day_rule ( ) and time_rule ( ) :,156
4686,"def decoder(s): <TAB> r = [] <TAB> decode = [] <TAB> for c in s: <TAB>  <TAB> if c == ""&"" and not decode: <TAB>  <TAB>  <TAB> decode.append(""&"") <MASK> if len(decode) == 1: <TAB>  <TAB>  <TAB>  <TAB> r.append(""&"") <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> r.append(modified_unbase64("""".join(decode[1:]))) <TAB>  <TAB>  <TAB> decode = [] <TAB>  <TAB> elif decode: <TAB>  <TAB>  <TAB> decode.append(c) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> r.append(c) <TAB> if decode: <TAB>  <TAB> r.append(modified_unbase64("""".join(decode[1:]))) <TAB> bin_str = """".join(r) <TAB> return (bin_str, len(s))","elif c == ""-"" and decode :",188
4687,"def admin_audit_get(admin_id): <TAB> if settings.app.demo_mode: <TAB>  <TAB> resp = utils.demo_get_cache() <MASK> return utils.jsonify(resp) <TAB> if not flask.g.administrator.super_user: <TAB>  <TAB> return utils.jsonify( <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB> ""error"": REQUIRES_SUPER_USER, <TAB>  <TAB>  <TAB>  <TAB> ""error_msg"": REQUIRES_SUPER_USER_MSG, <TAB>  <TAB>  <TAB> }, <TAB>  <TAB>  <TAB> 400, <TAB>  <TAB> ) <TAB> admin = auth.get_by_id(admin_id) <TAB> resp = admin.get_audit_events() <TAB> if settings.app.demo_mode: <TAB>  <TAB> utils.demo_set_cache(resp) <TAB> return utils.jsonify(resp)",if resp :,190
4688,"def vjp(self, argnum, outgrad, ans, vs, gvs, args, kwargs): <TAB> try: <TAB>  <TAB> return self.vjps[argnum](outgrad, ans, vs, gvs, *args, **kwargs) <TAB> except KeyError: <MASK> errstr = ""Gradient of {0} not yet implemented."" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> errstr = ""Gradient of {0} w.r.t. arg number {1} not yet implemented."" <TAB>  <TAB> raise NotImplementedError(errstr.format(self.fun.__name__, argnum))",if self . vjps == { } :,143
4689,"def update(self, *args, **kwargs): <TAB> assert not self.readonly <TAB> longest_key = 0 <TAB> _dict = self._dict <TAB> reverse = self.reverse <TAB> casereverse = self.casereverse <TAB> for iterable in args + (kwargs,): <MASK> iterable = iterable.items() <TAB>  <TAB> for key, value in iterable: <TAB>  <TAB>  <TAB> longest_key = max(longest_key, len(key)) <TAB>  <TAB>  <TAB> _dict[key] = value <TAB>  <TAB>  <TAB> reverse[value].append(key) <TAB>  <TAB>  <TAB> casereverse[value.lower()][value] += 1 <TAB> self._longest_key = max(self._longest_key, longest_key)","if isinstance ( iterable , ( dict , StenoDictionary ) ) :",172
4690,"def update_ui(self, window): <TAB> view = window.get_active_view() <TAB> self.set_status(view) <TAB> lang = ""plain_text"" <TAB> if view: <TAB>  <TAB> buf = view.get_buffer() <TAB>  <TAB> language = buf.get_language() <MASK> lang = language.get_id() <TAB>  <TAB> self.setup_smart_indent(view, lang)",if language :,101
4691,"def number_operators(self, a, b, skip=[]): <TAB> dict = {""a"": a, ""b"": b} <TAB> for name, expr in self.binops.items(): <TAB>  <TAB> if name not in skip: <TAB>  <TAB>  <TAB> name = ""__%s__"" % name <MASK> res = eval(expr, dict) <TAB>  <TAB>  <TAB>  <TAB> self.binop_test(a, b, res, expr, name) <TAB> for name, expr in self.unops.items(): <TAB>  <TAB> if name not in skip: <TAB>  <TAB>  <TAB> name = ""__%s__"" % name <TAB>  <TAB>  <TAB> if hasattr(a, name): <TAB>  <TAB>  <TAB>  <TAB> res = eval(expr, dict) <TAB>  <TAB>  <TAB>  <TAB> self.unop_test(a, res, expr, name)","if hasattr ( a , name ) :",187
4692,"def _getItemHeight(self, item, ctrl=None): <TAB> """"""Returns the full height of the item to be inserted in the form"""""" <TAB> if type(ctrl) == psychopy.visual.TextBox2: <TAB>  <TAB> return ctrl.size[1] <TAB> if type(ctrl) == psychopy.visual.Slider: <TAB>  <TAB> # Set radio button layout <MASK> return 0.03 + ctrl.labelHeight * 3 <TAB>  <TAB> elif item[""layout""] == ""vert"": <TAB>  <TAB>  <TAB> # for vertical take into account the nOptions <TAB>  <TAB>  <TAB> return ctrl.labelHeight * len(item[""options""])","if item [ ""layout"" ] == ""horiz"" :",155
4693,"def test_cleanup_params(self, body, rpc_mock): <TAB> res = self._get_resp_post(body) <TAB> self.assertEqual(http_client.ACCEPTED, res.status_code) <TAB> rpc_mock.assert_called_once_with(self.context, mock.ANY) <TAB> cleanup_request = rpc_mock.call_args[0][1] <TAB> for key, value in body.items(): <TAB>  <TAB> if key in (""disabled"", ""is_up""): <MASK> value = value == ""true"" <TAB>  <TAB> self.assertEqual(value, getattr(cleanup_request, key)) <TAB> self.assertEqual(self._expected_services(*SERVICES), res.json)",if value is not None :,177
4694,"def _read_json_content(self, body_is_optional=False): <TAB> if ""content-length"" not in self.headers: <TAB>  <TAB> return self.send_error(411) if not body_is_optional else {} <TAB> try: <TAB>  <TAB> content_length = int(self.headers.get(""content-length"")) <TAB>  <TAB> if content_length == 0 and body_is_optional: <TAB>  <TAB>  <TAB> return {} <TAB>  <TAB> request = json.loads(self.rfile.read(content_length).decode(""utf-8"")) <MASK> return request <TAB> except Exception: <TAB>  <TAB> logger.exception(""Bad request"") <TAB> self.send_error(400)","if isinstance ( request , dict ) and ( request or body_is_optional ) :",176
4695,"def env_purge_doc(app: Sphinx, env: BuildEnvironment, docname: str) -> None: <TAB> modules = getattr(env, ""_viewcode_modules"", {}) <TAB> for modname, entry in list(modules.items()): <MASK> continue <TAB>  <TAB> code, tags, used, refname = entry <TAB>  <TAB> for fullname in list(used): <TAB>  <TAB>  <TAB> if used[fullname] == docname: <TAB>  <TAB>  <TAB>  <TAB> used.pop(fullname) <TAB>  <TAB> if len(used) == 0: <TAB>  <TAB>  <TAB> modules.pop(modname)",if entry is False :,133
4696,"def frames(self): <TAB> """"""an array of all the frames (including iframes) in the current window"""""" <TAB> from thug.DOM.W3C.HTML.HTMLCollection import HTMLCollection <TAB> frames = set() <TAB> for frame in self._findAll([""frame"", ""iframe""]): <MASK> from thug.DOM.W3C.Core.DOMImplementation import DOMImplementation <TAB>  <TAB>  <TAB> DOMImplementation.createHTMLElement(self.window.doc, frame) <TAB>  <TAB> frames.add(frame._node) <TAB> return HTMLCollection(self.doc, list(frames))","if not getattr ( frame , ""_node"" , None ) :",145
4697,"def check(self, **kw): <TAB> if not kw: <TAB>  <TAB> return exists(self.strpath) <TAB> if len(kw) == 1: <MASK> return not kw[""dir""] ^ isdir(self.strpath) <TAB>  <TAB> if ""file"" in kw: <TAB>  <TAB>  <TAB> return not kw[""file""] ^ isfile(self.strpath) <TAB> return super(LocalPath, self).check(**kw)","if ""dir"" in kw :",106
4698,"def __init__(self, folders): <TAB> self.folders = folders <TAB> self.duplicates = {} <TAB> for folder, path in folders.items(): <TAB>  <TAB> duplicates = [] <TAB>  <TAB> for other_folder, other_path in folders.items(): <MASK> continue <TAB>  <TAB>  <TAB> if other_path == path: <TAB>  <TAB>  <TAB>  <TAB> duplicates.append(other_folder) <TAB>  <TAB> if len(duplicates): <TAB>  <TAB>  <TAB> self.duplicates[folder] = duplicates",if other_folder == folder :,117
4699,"def next(self, buf, pos): <TAB> if pos >= len(buf): <TAB>  <TAB> return EOF, """", pos <TAB> mo = self.tokens_re.match(buf, pos) <TAB> if mo: <TAB>  <TAB> text = mo.group() <TAB>  <TAB> type, regexp, test_lit = self.tokens[mo.lastindex - 1] <TAB>  <TAB> pos = mo.end() <MASK> type = self.literals.get(text, type) <TAB>  <TAB> return type, text, pos <TAB> else: <TAB>  <TAB> c = buf[pos] <TAB>  <TAB> return self.symbols.get(c, None), c, pos + 1",if test_lit :,153
4700,"def step(self, action): <TAB> """"""Repeat action, sum reward, and max over last observations."""""" <TAB> total_reward = 0.0 <TAB> done = None <TAB> for i in range(self._skip): <TAB>  <TAB> obs, reward, done, info = self.env.step(action) <MASK> self._obs_buffer[0] = obs <TAB>  <TAB> if i == self._skip - 1: <TAB>  <TAB>  <TAB> self._obs_buffer[1] = obs <TAB>  <TAB> total_reward += reward <TAB>  <TAB> if done: <TAB>  <TAB>  <TAB> break <TAB> # Note that the observation on the done=True frame <TAB> # doesn't matter <TAB> max_frame = self._obs_buffer.max(axis=0) <TAB> return max_frame, total_reward, done, info",if i == self . _skip - 2 :,189
4701,"def convert(self, ctx, argument): <TAB> arg = argument.replace(""0x"", """").lower() <TAB> if arg[0] == ""#"": <TAB>  <TAB> arg = arg[1:] <TAB> try: <TAB>  <TAB> value = int(arg, base=16) <TAB>  <TAB> if not (0 <= value <= 0xFFFFFF): <TAB>  <TAB>  <TAB> raise BadColourArgument(arg) <TAB>  <TAB> return discord.Colour(value=value) <TAB> except ValueError: <TAB>  <TAB> arg = arg.replace("" "", ""_"") <TAB>  <TAB> method = getattr(discord.Colour, arg, None) <MASK> raise BadColourArgument(arg) <TAB>  <TAB> return method()","if arg . startswith ( ""from_"" ) or method is None or not inspect . ismethod ( method ) :",172
4702,"def run(self, **inputs): <TAB> if self.inputs.copy_inputs: <TAB>  <TAB> self.inputs.subjects_dir = os.getcwd() <MASK> inputs[""subjects_dir""] = self.inputs.subjects_dir <TAB>  <TAB> for originalfile in [self.inputs.in_file, self.inputs.in_norm]: <TAB>  <TAB>  <TAB> copy2subjdir(self, originalfile, folder=""mri"") <TAB> return super(SegmentCC, self).run(**inputs)","if ""subjects_dir"" in inputs :",122
4703,"def get_queryset(self): <TAB> if not hasattr(self, ""_queryset""): <MASK> qs = self.queryset <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> qs = self.model._default_manager.get_queryset() <TAB>  <TAB> # If the queryset isn't already ordered we need to add an <TAB>  <TAB> # artificial ordering here to make sure that all formsets <TAB>  <TAB> # constructed from this queryset have the same form order. <TAB>  <TAB> if not qs.ordered: <TAB>  <TAB>  <TAB> qs = qs.order_by(self.model._meta.pk.name) <TAB>  <TAB> # Removed queryset limiting here. As per discussion re: #13023 <TAB>  <TAB> # on django-dev, max_num should not prevent existing <TAB>  <TAB> # related objects/inlines from being displayed. <TAB>  <TAB> self._queryset = qs <TAB> return self._queryset",if self . queryset is not None :,197
4704,"def visit_simple_stmt(self, node: Node) -> Iterator[Line]: <TAB> """"""Visit a statement without nested statements."""""" <TAB> is_suite_like = node.parent and node.parent.type in STATEMENT <TAB> if is_suite_like: <MASK> yield from self.visit_default(node) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield from self.line(+1) <TAB>  <TAB>  <TAB> yield from self.visit_default(node) <TAB>  <TAB>  <TAB> yield from self.line(-1) <TAB> else: <TAB>  <TAB> if not self.is_pyi or not node.parent or not is_stub_suite(node.parent): <TAB>  <TAB>  <TAB> yield from self.line() <TAB>  <TAB> yield from self.visit_default(node)",if self . is_pyi and is_stub_body ( node ) :,189
4705,"def rawDataReceived(self, data): <TAB> if self.timeout > 0: <TAB>  <TAB> self.resetTimeout() <TAB> self._pendingSize -= len(data) <TAB> if self._pendingSize > 0: <TAB>  <TAB> self._pendingBuffer.write(data) <TAB> else: <TAB>  <TAB> passon = b"""" <MASK> data, passon = data[: self._pendingSize], data[self._pendingSize :] <TAB>  <TAB> self._pendingBuffer.write(data) <TAB>  <TAB> rest = self._pendingBuffer <TAB>  <TAB> self._pendingBuffer = None <TAB>  <TAB> self._pendingSize = None <TAB>  <TAB> rest.seek(0, 0) <TAB>  <TAB> self._parts.append(rest.read()) <TAB>  <TAB> self.setLineMode(passon.lstrip(b""\r\n""))",if self . _pendingSize < 0 :,189
4706,"def handle(self, *args, **options): <TAB> app_name = options.get(""app_name"") <TAB> job_name = options.get(""job_name"") <TAB> # hack since we are using job_name nargs='?' for -l to work <TAB> if app_name and not job_name: <TAB>  <TAB> job_name = app_name <TAB>  <TAB> app_name = None <TAB> if options.get(""list_jobs""): <TAB>  <TAB> print_jobs(only_scheduled=False, show_when=True, show_appname=True) <TAB> else: <MASK> print(""Run a single maintenance job. Please specify the name of the job."") <TAB>  <TAB>  <TAB> return <TAB>  <TAB> self.runjob(app_name, job_name, options)",if not job_name :,184
4707,"def _exportReceived(self, content, error=False, server=None, context={}, **kwargs): <TAB> if error: <MASK> self.error.emit(content[""message""], True) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.error.emit(""Can't export the project from the server"", True) <TAB>  <TAB> self.finished.emit() <TAB>  <TAB> return <TAB> self.finished.emit()",if content :,97
4708,"def __iter__(self): <TAB> n = self.n <TAB> k = self.k <TAB> j = int(np.ceil(n / k)) <TAB> for i in range(k): <TAB>  <TAB> test_index = np.zeros(n, dtype=bool) <MASK> test_index[i * j : (i + 1) * j] = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> test_index[i * j :] = True <TAB>  <TAB> train_index = np.logical_not(test_index) <TAB>  <TAB> yield train_index, test_index",if i < k - 1 :,140
4709,"def addType(self, graphene_type): <TAB> meta = get_meta(graphene_type) <TAB> if meta: <MASK> self._typeMap[meta.name] = graphene_type <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> ""Type {typeName} already exists in the registry."".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> typeName=meta.name <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> raise Exception(""Cannot add unnamed type or a non-type to registry."")",if not graphene_type in self . _typeMap :,135
4710,"def test_len(self): <TAB> eq = self.assertEqual <TAB> eq(base64MIME.base64_len(""hello""), len(base64MIME.encode(""hello"", eol=""""))) <TAB> for size in range(15): <TAB>  <TAB> if size == 0: <TAB>  <TAB>  <TAB> bsize = 0 <TAB>  <TAB> elif size <= 3: <TAB>  <TAB>  <TAB> bsize = 4 <MASK> bsize = 8 <TAB>  <TAB> elif size <= 9: <TAB>  <TAB>  <TAB> bsize = 12 <TAB>  <TAB> elif size <= 12: <TAB>  <TAB>  <TAB> bsize = 16 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> bsize = 20 <TAB>  <TAB> eq(base64MIME.base64_len(""x"" * size), bsize)",elif size <= 6 :,160
4711,"def _asStringList(self, sep=""""): <TAB> out = [] <TAB> for item in self._toklist: <MASK> out.append(sep) <TAB>  <TAB> if isinstance(item, ParseResults): <TAB>  <TAB>  <TAB> out += item._asStringList() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> out.append(str(item)) <TAB> return out",if out and sep :,88
4712,"def open_file_input(cli_parsed): <TAB> files = glob.glob(os.path.join(cli_parsed.d, ""*report.html"")) <TAB> if len(files) > 0: <TAB>  <TAB> print(""\n[*] Done! Report written in the "" + cli_parsed.d + "" folder!"") <TAB>  <TAB> print(""Would you like to open the report now? [Y/n]"") <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> response = input().lower() <MASK> return True <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return strtobool(response) <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> print(""Please respond with y or n"") <TAB> else: <TAB>  <TAB> print(""[*] No report files found to open, perhaps no hosts were successful"") <TAB>  <TAB> return False","if response == """" :",200
4713,"def init_values(self): <TAB> config = self._raw_config <TAB> for valname, value in self.overrides.iteritems(): <MASK> realvalname, key = valname.split(""."", 1) <TAB>  <TAB>  <TAB> config.setdefault(realvalname, {})[key] = value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> config[valname] = value <TAB> for name in config: <TAB>  <TAB> if name in self.values: <TAB>  <TAB>  <TAB> self.__dict__[name] = config[name] <TAB> del self._raw_config","if ""."" in valname :",131
4714,"def get_result(self): <TAB> result_list = [] <TAB> exc_info = None <TAB> for f in self.children: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> result_list.append(f.get_result()) <TAB>  <TAB> except Exception as e: <MASK> exc_info = sys.exc_info() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> if not isinstance(e, self.quiet_exceptions): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> app_log.error(""Multiple exceptions in yield list"", exc_info=True) <TAB> if exc_info is not None: <TAB>  <TAB> raise_exc_info(exc_info) <TAB> if self.keys is not None: <TAB>  <TAB> return dict(zip(self.keys, result_list)) <TAB> else: <TAB>  <TAB> return list(result_list)",if exc_info is None :,196
4715,"def test01e_json(self): <TAB> ""Testing GeoJSON input/output."" <TAB> if not GEOJSON: <TAB>  <TAB> return <TAB> for g in self.geometries.json_geoms: <TAB>  <TAB> geom = OGRGeometry(g.wkt) <MASK> self.assertEqual(g.json, geom.json) <TAB>  <TAB>  <TAB> self.assertEqual(g.json, geom.geojson) <TAB>  <TAB> self.assertEqual(OGRGeometry(g.wkt), OGRGeometry(geom.json))","if not hasattr ( g , ""not_equal"" ) :",133
4716,"def __init__(self, hub=None):  # pylint: disable=unused-argument <TAB> if resolver._resolver is None: <TAB>  <TAB> _resolver = resolver._resolver = _DualResolver() <MASK> _resolver.network_resolver.nameservers[:] = config.resolver_nameservers <TAB>  <TAB> if config.resolver_timeout: <TAB>  <TAB>  <TAB> _resolver.network_resolver.lifetime = config.resolver_timeout <TAB> # Different hubs in different threads could be sharing the same <TAB> # resolver. <TAB> assert isinstance(resolver._resolver, _DualResolver) <TAB> self._resolver = resolver._resolver",if config . resolver_nameservers :,147
4717,"def __iadd__(self, term): <TAB> if isinstance(term, (int, long)): <MASK> _gmp.mpz_add_ui(self._mpz_p, self._mpz_p, c_ulong(term)) <TAB>  <TAB>  <TAB> return self <TAB>  <TAB> if -65535 < term < 0: <TAB>  <TAB>  <TAB> _gmp.mpz_sub_ui(self._mpz_p, self._mpz_p, c_ulong(-term)) <TAB>  <TAB>  <TAB> return self <TAB>  <TAB> term = Integer(term) <TAB> _gmp.mpz_add(self._mpz_p, self._mpz_p, term._mpz_p) <TAB> return self",if 0 <= term < 65536 :,170
4718,"def copy(dst, src): <TAB> for (k, v) in src.iteritems(): <MASK> d = {} <TAB>  <TAB>  <TAB> dst[k] = d <TAB>  <TAB>  <TAB> copy(d, v) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> dst[k] = v","if isinstance ( v , dict ) :",73
4719,"def generator(self, data): <TAB> self.procs = OrderedDict() <TAB> for task in data: <TAB>  <TAB> self.recurse_task(task, 0, 0, self.procs) <TAB> for offset, name, level, pid, ppid, uid, euid, gid in self.procs.values(): <MASK> yield ( <TAB>  <TAB>  <TAB>  <TAB> 0, <TAB>  <TAB>  <TAB>  <TAB> [ <TAB>  <TAB>  <TAB>  <TAB>  <TAB> Address(offset), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> str(name), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> str(level), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> int(pid), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> int(ppid), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> int(uid), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> int(gid), <TAB>  <TAB>  <TAB>  <TAB>  <TAB> int(euid), <TAB>  <TAB>  <TAB>  <TAB> ], <TAB>  <TAB>  <TAB> )",if offset :,186
4720,"def apply(self, db, person): <TAB> families = person.get_parent_family_handle_list() <TAB> if families == []: <TAB>  <TAB> return True <TAB> for family_handle in person.get_parent_family_handle_list(): <TAB>  <TAB> family = db.get_family_from_handle(family_handle) <MASK> father_handle = family.get_father_handle() <TAB>  <TAB>  <TAB> mother_handle = family.get_mother_handle() <TAB>  <TAB>  <TAB> if not father_handle: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB> if not mother_handle: <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if family :,157
4721,"def _arctic_task_exec(request): <TAB> request.start_time = time.time() <TAB> logging.debug( <TAB>  <TAB> ""Executing asynchronous request for {}/{}"".format( <TAB>  <TAB>  <TAB> request.library, request.symbol <TAB>  <TAB> ) <TAB> ) <TAB> result = None <TAB> try: <TAB>  <TAB> request.is_running = True <MASK> result = mongo_retry(request.fun)(*request.args, **request.kwargs) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result = request.fun(*request.args, **request.kwargs) <TAB> except Exception as e: <TAB>  <TAB> request.exception = e <TAB> finally: <TAB>  <TAB> request.data = result <TAB>  <TAB> request.end_time = time.time() <TAB>  <TAB> request.is_running = False <TAB> return result",if request . mongo_retry :,191
4722,"def _setup_styles(self): <TAB> for ttype, ndef in self.style: <TAB>  <TAB> escape = EscapeSequence() <MASK> escape.fg = self._color_index(ndef[""color""]) <TAB>  <TAB> if ndef[""bgcolor""]: <TAB>  <TAB>  <TAB> escape.bg = self._color_index(ndef[""bgcolor""]) <TAB>  <TAB> if self.usebold and ndef[""bold""]: <TAB>  <TAB>  <TAB> escape.bold = True <TAB>  <TAB> if self.useunderline and ndef[""underline""]: <TAB>  <TAB>  <TAB> escape.underline = True <TAB>  <TAB> self.style_string[str(ttype)] = (escape.color_string(), escape.reset_string())","if ndef [ ""color"" ] :",156
4723,"def process_string(self, remove_repetitions, sequence): <TAB> string = """" <TAB> for i, char in enumerate(sequence): <TAB>  <TAB> if char != self.int_to_char[self.blank_index]: <TAB>  <TAB>  <TAB> # if this char is a repetition and remove_repetitions=true, <TAB>  <TAB>  <TAB> # skip. <TAB>  <TAB>  <TAB> if remove_repetitions and i != 0 and char == sequence[i - 1]: <TAB>  <TAB>  <TAB>  <TAB> pass <MASK> string += "" "" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> string = string + char <TAB> return string",elif char == self . labels [ self . space_index ] :,152
4724,"def arith_expr(self, nodelist): <TAB> node = self.com_node(nodelist[0]) <TAB> for i in range(2, len(nodelist), 2): <TAB>  <TAB> right = self.com_node(nodelist[i]) <MASK> node = Add(node, right, lineno=nodelist[1].context) <TAB>  <TAB> elif nodelist[i - 1].type == token.MINUS: <TAB>  <TAB>  <TAB> node = Sub(node, right, lineno=nodelist[1].context) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise ValueError(""unexpected token: %s"" % nodelist[i - 1][0]) <TAB> return node",if nodelist [ i - 1 ] . type == token . PLUS :,160
4725,"def invert_index(cls, index, length): <TAB> if np.isscalar(index): <TAB>  <TAB> return length - index <TAB> elif isinstance(index, slice): <TAB>  <TAB> start, stop = index.start, index.stop <TAB>  <TAB> new_start, new_stop = None, None <MASK> new_stop = length - start <TAB>  <TAB> if stop is not None: <TAB>  <TAB>  <TAB> new_start = length - stop <TAB>  <TAB> return slice(new_start - 1, new_stop - 1) <TAB> elif isinstance(index, Iterable): <TAB>  <TAB> new_index = [] <TAB>  <TAB> for ind in index: <TAB>  <TAB>  <TAB> new_index.append(length - ind) <TAB> return new_index",if start is not None :,168
4726,"def getRoots(job): <TAB> if job not in visited: <TAB>  <TAB> visited.add(job) <MASK> list(map(lambda p: getRoots(p), job._directPredecessors)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> roots.add(job) <TAB>  <TAB> # The following call ensures we explore all successor edges. <TAB>  <TAB> list(map(lambda c: getRoots(c), job._children + job._followOns))",if len ( job . _directPredecessors ) > 0 :,120
4727,"def visit_filter_projection(self, node, value): <TAB> base = self.visit(node[""children""][0], value) <TAB> if not isinstance(base, list): <TAB>  <TAB> return None <TAB> comparator_node = node[""children""][2] <TAB> collected = [] <TAB> for element in base: <MASK> current = self.visit(node[""children""][1], element) <TAB>  <TAB>  <TAB> if current is not None: <TAB>  <TAB>  <TAB>  <TAB> collected.append(current) <TAB> return collected","if self . _is_true ( self . visit ( comparator_node , element ) ) :",132
4728,"def func(x, y): <TAB> try: <TAB>  <TAB> if x > y: <TAB>  <TAB>  <TAB> z = x + 2 * math.sin(y) <TAB>  <TAB>  <TAB> return z ** 2 <MASK> return 4 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return 2 ** 3 <TAB> except ValueError: <TAB>  <TAB> foo = 0 <TAB>  <TAB> for i in range(4): <TAB>  <TAB>  <TAB> foo += i <TAB>  <TAB> return foo <TAB> except TypeError: <TAB>  <TAB> return 42 <TAB> else: <TAB>  <TAB> return 33 <TAB> finally: <TAB>  <TAB> print(""finished"")",elif x == y :,134
4729,"def set_filter(self, dataset_opt): <TAB> """"""This function create and set the pre_filter to the obj as attributes"""""" <TAB> self.pre_filter = None <TAB> for key_name in dataset_opt.keys(): <MASK> new_name = key_name.replace(""filters"", ""filter"") <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> filt = instantiate_filters(getattr(dataset_opt, key_name)) <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> log.exception( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Error trying to create {}, {}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> new_name, getattr(dataset_opt, key_name) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB> setattr(self, new_name, filt)","if ""filter"" in key_name :",195
4730,"def _add_states_to_lookup( <TAB> self, trackers_as_states, trackers_as_actions, domain, online=False): <TAB> """"""Add states to lookup dict"""""" <TAB> for states in trackers_as_states: <TAB>  <TAB> active_form = self._get_active_form_name(states[-1]) <MASK> # modify the states <TAB>  <TAB>  <TAB> states = self._modified_states(states) <TAB>  <TAB>  <TAB> feature_key = self._create_feature_key(states) <TAB>  <TAB>  <TAB> # even if there are two identical feature keys <TAB>  <TAB>  <TAB> # their form will be the same <TAB>  <TAB>  <TAB> # because of `active_form_...` feature <TAB>  <TAB>  <TAB> self.lookup[feature_key] = active_form",if active_form and self . _prev_action_listen_in_state ( states [ - 1 ] ) :,192
4731,"def list_loaded_payloads(self): <TAB> print(helpers.color(""\n [*] Available Payloads:\n"")) <TAB> lastBase = None <TAB> x = 1 <TAB> for name in sorted(self.active_payloads.keys()): <TAB>  <TAB> parts = name.split(""/"") <MASK> print() <TAB>  <TAB> lastBase = parts[0] <TAB>  <TAB> print(""\t%s)\t%s"" % (x, ""{0: <24}"".format(name))) <TAB>  <TAB> x += 1 <TAB> print(""\n"") <TAB> return",if lastBase and parts [ 0 ] != lastBase :,136
4732,"def reprSmart(vw, item): <TAB> ptype = type(item) <TAB> if ptype is int: <TAB>  <TAB> if -1024 < item < 1024: <TAB>  <TAB>  <TAB> return str(item) <MASK> return vw.reprPointer(item) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return hex(item) <TAB> elif ptype in (list, tuple): <TAB>  <TAB> return reprComplex(vw, item)  # recurse <TAB> elif ptype is dict: <TAB>  <TAB> return ""{%s}"" % "","".join( <TAB>  <TAB>  <TAB> [""%s:%s"" % (reprSmart(vw, k), reprSmart(vw, v)) for k, v in item.items()] <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> return repr(item)",elif vw . isValidPointer ( item ) :,183
4733,"def ConfigSectionMap(section): <TAB> config = ConfigParser.RawConfigParser() <TAB> configurations = config_manager()  # Class from mkchromecast.config <TAB> configf = configurations.configf <TAB> config.read(configf) <TAB> dict1 = {} <TAB> options = config.options(section) <TAB> for option in options: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> dict1[option] = config.get(section, option) <MASK> DebugPrint(""skip: %s"" % option) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> print(""Exception on %s!"" % option) <TAB>  <TAB>  <TAB> dict1[option] = None <TAB> return dict1",if dict1 [ option ] == - 1 :,162
4734,"def on_success(result): <TAB> subtasks = {} <TAB> if result: <TAB>  <TAB> subtasks = { <TAB>  <TAB>  <TAB> self.nodes_keys.inverse[s[""node_id""]]: s.get(""subtask_id"") <TAB>  <TAB>  <TAB> for s in result <MASK> } <TAB> if subtasks: <TAB>  <TAB> print(""subtask finished"") <TAB>  <TAB> self.next() <TAB> else: <TAB>  <TAB> print(""waiting for a subtask to finish"") <TAB>  <TAB> time.sleep(10)","if s . get ( ""status"" ) == ""Failure""",129
4735,"def redirect_aware_commmunicate(p, sys=_sys): <TAB> """"""Variant of process.communicate that works with in process I/O redirection."""""" <TAB> assert sys is not None <TAB> out, err = p.communicate() <TAB> if redirecting_io(sys=sys): <TAB>  <TAB> if out: <TAB>  <TAB>  <TAB> # We don't unicodify in Python2 because sys.stdout may be a <TAB>  <TAB>  <TAB> # cStringIO.StringIO object, which does not accept Unicode strings <TAB>  <TAB>  <TAB> out = unicodify(out) <TAB>  <TAB>  <TAB> sys.stdout.write(out) <TAB>  <TAB>  <TAB> out = None <MASK> err = unicodify(err) <TAB>  <TAB>  <TAB> sys.stderr.write(err) <TAB>  <TAB>  <TAB> err = None <TAB> return out, err",if err :,177
4736,"def __exit__(self, *args, **kwargs): <TAB> self._samples_cache = {} <TAB> if is_validation_enabled() and isinstance(self.prior, dict): <TAB>  <TAB> extra = set(self.prior) - self._param_hits <MASK> warnings.warn( <TAB>  <TAB>  <TAB>  <TAB> ""pyro.module prior did not find params ['{}']. "" <TAB>  <TAB>  <TAB>  <TAB> ""Did you instead mean one of ['{}']?"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""', '"".join(extra), ""', '"".join(self._param_misses) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> return super().__exit__(*args, **kwargs)",if extra :,156
4737,def __download_thread(self): <TAB> while True: <MASK> self.__current_download = self.__queue.get() <TAB>  <TAB>  <TAB> self.__download_file(self.__current_download) <TAB>  <TAB> time.sleep(0.1),if not self . __queue . empty ( ) :,68
4738,"def plot_timer_command(args): <TAB> import nnabla.monitor as M <TAB> format_unit = dict( <TAB>  <TAB> s=""seconds"", <TAB>  <TAB> m=""minutes"", <TAB>  <TAB> h=""hours"", <TAB>  <TAB> d=""days"", <TAB> ) <TAB> if not args.ylabel: <MASK> args.ylabel = ""Total elapsed time [{}]"".format(format_unit[args.time_unit]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> args.ylabel = ""Elapsed time [{}/iter]"".format(format_unit[args.time_unit]) <TAB> plot_any_command( <TAB>  <TAB> args, M.plot_time_elapsed, dict(elapsed=args.elapsed, unit=args.time_unit) <TAB> ) <TAB> return True",if args . elapsed :,177
4739,"def resolve_page(root: ChannelContext[models.MenuItem], info, **kwargs): <TAB> if root.node.page_id: <TAB>  <TAB> requestor = get_user_or_app_from_context(info.context) <TAB>  <TAB> requestor_has_access_to_all = requestor.is_active and requestor.has_perm( <TAB>  <TAB>  <TAB> PagePermissions.MANAGE_PAGES <TAB>  <TAB> ) <TAB>  <TAB> return ( <TAB>  <TAB>  <TAB> PageByIdLoader(info.context) <TAB>  <TAB>  <TAB> .load(root.node.page_id) <TAB>  <TAB>  <TAB> .then( <TAB>  <TAB>  <TAB>  <TAB> lambda page: page <MASK> else None <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> ) <TAB> return None",if requestor_has_access_to_all or page . is_visible,177
4740,"def find(self, pattern): <TAB> """"""Find pages in database."""""" <TAB> results = self._search_keyword(pattern) <TAB> pat = re.compile(""(.*?)(%s)(.*?)( \(.*\))?$"" % re.escape(pattern), re.I) <TAB> if results: <TAB>  <TAB> for name, keyword, url in results: <MASK> keyword = pat.sub( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> r""\1\033[1;31m\2\033[0m\3\033[1;33m\4\033[0m"", keyword <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> print(""%s - %s"" % (keyword, name)) <TAB> else: <TAB>  <TAB> raise RuntimeError(""%s: nothing appropriate."" % pattern)",if os . isatty ( sys . stdout . fileno ( ) ) :,184
4741,"def _certonly_new_request_common(self, mock_client, args=None): <TAB> with mock.patch( <TAB>  <TAB> ""certbot._internal.main._find_lineage_for_domains_and_certname"" <TAB> ) as mock_renewal: <TAB>  <TAB> mock_renewal.return_value = (""newcert"", None) <TAB>  <TAB> with mock.patch(""certbot._internal.main._init_le_client"") as mock_init: <TAB>  <TAB>  <TAB> mock_init.return_value = mock_client <MASK> args = [] <TAB>  <TAB>  <TAB> args += ""-d foo.bar -a standalone certonly"".split() <TAB>  <TAB>  <TAB> self._call(args)",if args is None :,169
4742,"def __init__(self, *args, **kw): <TAB> if len(args) > 1: <TAB>  <TAB> raise TypeError(""MultiDict can only be called with one positional "" ""argument"") <TAB> if args: <MASK> items = list(args[0].iteritems()) <TAB>  <TAB> elif hasattr(args[0], ""items""): <TAB>  <TAB>  <TAB> items = list(args[0].items()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> items = list(args[0]) <TAB>  <TAB> self._items = items <TAB> else: <TAB>  <TAB> self._items = [] <TAB> if kw: <TAB>  <TAB> self._items.extend(kw.items())","if hasattr ( args [ 0 ] , ""iteritems"" ) :",156
4743,"def test08_ExceptionTypes(self): <TAB> self.assertTrue(issubclass(db.DBError, Exception)) <TAB> for i, j in db.__dict__.items(): <MASK> self.assertTrue(issubclass(j, db.DBError), msg=i) <TAB>  <TAB>  <TAB> if i not in (""DBKeyEmptyError"", ""DBNotFoundError""): <TAB>  <TAB>  <TAB>  <TAB> self.assertFalse(issubclass(j, KeyError), msg=i) <TAB> # This two exceptions have two bases <TAB> self.assertTrue(issubclass(db.DBKeyEmptyError, KeyError)) <TAB> self.assertTrue(issubclass(db.DBNotFoundError, KeyError))","if i . startswith ( ""DB"" ) and i . endswith ( ""Error"" ) :",154
4744,"def _delegate_to_sinks(self, value: Any) -> None: <TAB> for sink in self._sinks: <TAB>  <TAB> if isinstance(sink, AgentT): <TAB>  <TAB>  <TAB> await sink.send(value=value) <MASK> await cast(TopicT, sink).send(value=value) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> await maybe_async(cast(Callable, sink)(value))","elif isinstance ( sink , ChannelT ) :",103
4745,"def _select_block(str_in, start_tag, end_tag): <TAB> """"""Select first block delimited by start_tag and end_tag"""""" <TAB> start_pos = str_in.find(start_tag) <TAB> if start_pos < 0: <TAB>  <TAB> raise ValueError(""start_tag not found"") <TAB> depth = 0 <TAB> for pos in range(start_pos, len(str_in)): <TAB>  <TAB> if str_in[pos] == start_tag: <TAB>  <TAB>  <TAB> depth += 1 <MASK> depth -= 1 <TAB>  <TAB> if depth == 0: <TAB>  <TAB>  <TAB> break <TAB> sel = str_in[start_pos + 1 : pos] <TAB> return sel",elif str_in [ pos ] == end_tag :,171
4746,"def confirm(request): <TAB> details = request.session.get(""reauthenticate"") <TAB> if not details: <TAB>  <TAB> return redirect(""home"") <TAB> # Monkey patch request <TAB> request.user = User.objects.get(pk=details[""user_pk""]) <TAB> if request.method == ""POST"": <TAB>  <TAB> confirm_form = PasswordConfirmForm(request, request.POST) <MASK> request.session.pop(""reauthenticate"") <TAB>  <TAB>  <TAB> request.session[""reauthenticate_done""] = True <TAB>  <TAB>  <TAB> return redirect(""social:complete"", backend=details[""backend""]) <TAB> else: <TAB>  <TAB> confirm_form = PasswordConfirmForm(request) <TAB> context = {""confirm_form"": confirm_form} <TAB> context.update(details) <TAB> return render(request, ""accounts/confirm.html"", context)",if confirm_form . is_valid ( ) :,195
4747,"def verify_credentials(self): <TAB> if self.enabled: <TAB>  <TAB> response = requests.get( <TAB>  <TAB>  <TAB> ""https://api.exotel.com/v1/Accounts/{sid}"".format(sid=self.account_sid), <TAB>  <TAB>  <TAB> auth=(self.api_key, self.api_token), <TAB>  <TAB> ) <MASK> frappe.throw(_(""Invalid credentials""))",if response . status_code != 200 :,103
4748,"def pixbufrenderer(self, column, crp, model, it): <TAB> tok = model.get_value(it, 0) <TAB> if tok.type == ""class"": <TAB>  <TAB> icon = ""class"" <TAB> else: <MASK> icon = ""method_priv"" <TAB>  <TAB> elif tok.visibility == ""protected"": <TAB>  <TAB>  <TAB> icon = ""method_prot"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> icon = ""method"" <TAB> crp.set_property(""pixbuf"", imagelibrary.pixbufs[icon])","if tok . visibility == ""private"" :",132
4749,"def _omit_keywords(self, context): <TAB> omitted_kws = 0 <TAB> for event, elem in context: <TAB>  <TAB> # Teardowns aren't omitted to allow checking suite teardown status. <TAB>  <TAB> omit = elem.tag == ""kw"" and elem.get(""type"") != ""teardown"" <TAB>  <TAB> start = event == ""start"" <TAB>  <TAB> if omit and start: <TAB>  <TAB>  <TAB> omitted_kws += 1 <TAB>  <TAB> if not omitted_kws: <TAB>  <TAB>  <TAB> yield event, elem <MASK> elem.clear() <TAB>  <TAB> if omit and not start: <TAB>  <TAB>  <TAB> omitted_kws -= 1",elif not start :,144
4750,"def on_double_click(self, event): <TAB> # TODO: don't act when the click happens below last item <TAB> path = self.get_selected_path() <TAB> kind = self.get_selected_kind() <TAB> name = self.get_selected_name() <TAB> if kind == ""file"": <MASK> self.open_file(path) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.open_path_with_system_app(path) <TAB> elif kind == ""dir"": <TAB>  <TAB> self.request_focus_into(path) <TAB> return ""break""",if self . should_open_name_in_thonny ( name ) :,152
4751,"def search_cve(db: DatabaseInterface, product: Product) -> dict: <TAB> result = {} <TAB> for query_result in db.fetch_multiple(QUERIES[""cve_lookup""]): <TAB>  <TAB> cve_entry = CveDbEntry(*query_result) <MASK> result[cve_entry.cve_id] = { <TAB>  <TAB>  <TAB>  <TAB> ""score2"": cve_entry.cvss_v2_score, <TAB>  <TAB>  <TAB>  <TAB> ""score3"": cve_entry.cvss_v3_score, <TAB>  <TAB>  <TAB>  <TAB> ""cpe_version"": build_version_string(cve_entry), <TAB>  <TAB>  <TAB> } <TAB> return result","if _product_matches_cve ( product , cve_entry ) :",174
4752,"def find_go_files_mtime(app_files): <TAB> files, mtime = [], 0 <TAB> for f, mt in app_files.items(): <TAB>  <TAB> if not f.endswith("".go""): <TAB>  <TAB>  <TAB> continue <MASK> continue <TAB>  <TAB> files.append(f) <TAB>  <TAB> mtime = max(mtime, mt) <TAB> return files, mtime",if APP_CONFIG . nobuild_files . match ( f ) :,100
4753,"def wrapper(filename): <TAB> mtime = getmtime(filename) <TAB> with lock: <MASK> old_mtime, result = cache.pop(filename) <TAB>  <TAB>  <TAB> if old_mtime == mtime: <TAB>  <TAB>  <TAB>  <TAB> # Move to the end <TAB>  <TAB>  <TAB>  <TAB> cache[filename] = old_mtime, result <TAB>  <TAB>  <TAB>  <TAB> return result <TAB> result = function(filename) <TAB> with lock: <TAB>  <TAB> cache[filename] = mtime, result  # at the end <TAB>  <TAB> if len(cache) > max_size: <TAB>  <TAB>  <TAB> cache.popitem(last=False) <TAB> return result",if filename in cache :,144
4754,"def Tokenize(s): <TAB> # type: (str) -> Iterator[Token] <TAB> for item in TOKEN_RE.findall(s): <TAB>  <TAB> # The type checker can't know the true type of item! <TAB>  <TAB> item = cast(TupleStr4, item) <MASK> typ = ""number"" <TAB>  <TAB>  <TAB> val = item[0] <TAB>  <TAB> elif item[1]: <TAB>  <TAB>  <TAB> typ = ""name"" <TAB>  <TAB>  <TAB> val = item[1] <TAB>  <TAB> elif item[2]: <TAB>  <TAB>  <TAB> typ = item[2] <TAB>  <TAB>  <TAB> val = item[2] <TAB>  <TAB> elif item[3]: <TAB>  <TAB>  <TAB> typ = item[3] <TAB>  <TAB>  <TAB> val = item[3] <TAB>  <TAB> yield Token(typ, val)",if item [ 0 ] :,181
4755,"def _show_encoders(self, *args, **kwargs): <TAB> if issubclass(self.current_module.__class__, BasePayload): <TAB>  <TAB> encoders = self.current_module.get_encoders() <MASK> headers = (""Encoder"", ""Name"", ""Description"") <TAB>  <TAB>  <TAB> print_table(headers, *encoders, max_column_length=100) <TAB>  <TAB>  <TAB> return <TAB> print_error(""No encoders available"")",if encoders :,109
4756,"def __init__(self): <TAB> Builder.__init__(self, commandName=""VCExpress.exe"", formatName=""msvcProject"") <TAB> for key in [""VS90COMNTOOLS"", ""VC80COMNTOOLS"", ""VC71COMNTOOLS""]: <MASK> self.programDir = os.path.join(os.environ[key], "".."", ""IDE"") <TAB> if self.programDir is None: <TAB>  <TAB> for version in [""9.0"", ""8"", "".NET 2003""]: <TAB>  <TAB>  <TAB> msvcDir = ( <TAB>  <TAB>  <TAB>  <TAB> ""C:\\Program Files\\Microsoft Visual Studio %s\\Common7\\IDE"" % version <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> if os.path.exists(msvcDir): <TAB>  <TAB>  <TAB>  <TAB> self.programDir = msvcDir",if os . environ . has_key ( key ) :,192
4757,"def _inner(*args, **kwargs): <TAB> component_manager = args[0].component_manager <TAB> for condition_name in condition_names: <TAB>  <TAB> condition_result, err_msg = component_manager.evaluate_condition(condition_name) <MASK> raise ComponentStartConditionNotMetError(err_msg) <TAB> if not component_manager.all_components_running(*components): <TAB>  <TAB> raise ComponentsNotStartedError( <TAB>  <TAB>  <TAB> f""the following required components have not yet started: {json.dumps(components)}"" <TAB>  <TAB> ) <TAB> return method(*args, **kwargs)",if not condition_result :,144
4758,"def _gridconvvalue(self, value): <TAB> if isinstance(value, (str, _tkinter.Tcl_Obj)): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> svalue = str(value) <TAB>  <TAB>  <TAB> if not svalue: <TAB>  <TAB>  <TAB>  <TAB> return None <MASK> return self.tk.getdouble(svalue) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> return self.tk.getint(svalue) <TAB>  <TAB> except (ValueError, TclError): <TAB>  <TAB>  <TAB> pass <TAB> return value","elif ""."" in svalue :",129
4759,"def check_songs(): <TAB> desc = numeric_phrase(""%d song"", ""%d songs"", len(songs)) <TAB> with Task(_(""Rescan songs""), desc) as task: <TAB>  <TAB> task.copool(check_songs) <TAB>  <TAB> for i, song in enumerate(songs): <TAB>  <TAB>  <TAB> song = song._song <MASK> app.library.reload(song) <TAB>  <TAB>  <TAB> task.update((float(i) + 1) / len(songs)) <TAB>  <TAB>  <TAB> yield",if song in app . library :,121
4760,"def initialize(self): <TAB> nn.init.xavier_uniform_(self.linear.weight.data) <TAB> if self.linear.bias is not None: <TAB>  <TAB> self.linear.bias.data.uniform_(-1.0, 1.0) <TAB> if self.self_layer: <TAB>  <TAB> nn.init.xavier_uniform_(self.linear_self.weight.data) <MASK> self.linear_self.bias.data.uniform_(-1.0, 1.0)",if self . linear_self . bias is not None :,126
4761,"def test_row(self, row): <TAB> for idx, test in self.patterns.items(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> value = row[idx] <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB> value = """" <TAB>  <TAB> result = test(value) <MASK> if result: <TAB>  <TAB>  <TAB>  <TAB> return not self.inverse  # True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if not result: <TAB>  <TAB>  <TAB>  <TAB> return self.inverse  # False <TAB> if self.any_match: <TAB>  <TAB> return self.inverse  # False <TAB> else: <TAB>  <TAB> return not self.inverse  # True",if self . any_match :,149
4762,"def toterminal(self, tw): <TAB> for element in self.chain: <TAB>  <TAB> element[0].toterminal(tw) <MASK> tw.line("""") <TAB>  <TAB>  <TAB> tw.line(element[2], yellow=True) <TAB> super(ExceptionChainRepr, self).toterminal(tw)",if element [ 2 ] is not None :,88
4763,"def runMainLoop(self): <TAB> """"""The curses gui main loop."""""" <TAB> # pylint: disable=no-member <TAB> # <TAB> # Do NOT change g.app! <TAB> self.curses_app = LeoApp() <TAB> stdscr = curses.initscr() <TAB> if 1:  # Must follow initscr. <TAB>  <TAB> self.dump_keys() <TAB> try: <TAB>  <TAB> self.curses_app.run() <TAB>  <TAB> # run calls CApp.main(), which calls CGui.run(). <TAB> finally: <TAB>  <TAB> curses.nocbreak() <TAB>  <TAB> stdscr.keypad(0) <TAB>  <TAB> curses.echo() <TAB>  <TAB> curses.endwin() <MASK> g.pr(""Exiting Leo..."")","if ""shutdown"" in g . app . debug :",179
4764,"def test_chunkcoding(self): <TAB> for native, utf8 in zip(*[StringIO(f).readlines() for f in self.tstring]): <TAB>  <TAB> u = self.decode(native)[0] <TAB>  <TAB> self.assertEqual(u, utf8.decode(""utf-8"")) <MASK> self.assertEqual(native, self.encode(u)[0])",if self . roundtriptest :,93
4765,"def reload_sanitize_allowlist(self, explicit=True): <TAB> self.sanitize_allowlist = [] <TAB> try: <TAB>  <TAB> with open(self.sanitize_allowlist_file) as f: <TAB>  <TAB>  <TAB> for line in f.readlines(): <MASK> self.sanitize_allowlist.append(line.strip()) <TAB> except OSError: <TAB>  <TAB> if explicit: <TAB>  <TAB>  <TAB> log.warning( <TAB>  <TAB>  <TAB>  <TAB> ""Sanitize log file explicitly specified as '%s' but does not exist, continuing with no tools allowlisted."", <TAB>  <TAB>  <TAB>  <TAB> self.sanitize_allowlist_file, <TAB>  <TAB>  <TAB> )","if not line . startswith ( ""#"" ) :",149
4766,"def get_all_extensions(subtree=None): <TAB> if subtree is None: <TAB>  <TAB> subtree = full_extension_tree() <TAB> result = [] <TAB> if isinstance(subtree, dict): <TAB>  <TAB> for value in subtree.values(): <TAB>  <TAB>  <TAB> if isinstance(value, dict): <TAB>  <TAB>  <TAB>  <TAB> result += get_all_extensions(value) <MASK> result += value.extensions <TAB>  <TAB>  <TAB> elif isinstance(value, (list, tuple)): <TAB>  <TAB>  <TAB>  <TAB> result += value <TAB> elif isinstance(subtree, (ContentTypeMapping, ContentTypeDetector)): <TAB>  <TAB> result = subtree.extensions <TAB> elif isinstance(subtree, (list, tuple)): <TAB>  <TAB> result = subtree <TAB> return result","elif isinstance ( value , ( ContentTypeMapping , ContentTypeDetector ) ) :",172
4767,"def _configuration_dict_to_commandlist(name, config_dict): <TAB> command_list = [""config:%s"" % name] <TAB> for key, value in config_dict.items(): <MASK> if value: <TAB>  <TAB>  <TAB>  <TAB> b = ""true"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> b = ""false"" <TAB>  <TAB>  <TAB> command_list.append(""%s:%s"" % (key, b)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> command_list.append(""%s:%s"" % (key, value)) <TAB> return command_list",if type ( value ) is bool :,140
4768,"def _RewriteModinfo( <TAB> self, <TAB> modinfo, <TAB> obj_kernel_version, <TAB> this_kernel_version, <TAB> info_strings=None, <TAB> to_remove=None,): <TAB> new_modinfo = """" <TAB> for line in modinfo.split(""\x00""): <MASK> continue <TAB>  <TAB> if to_remove and line.split(""="")[0] == to_remove: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if info_strings is not None: <TAB>  <TAB>  <TAB> info_strings.add(line.split(""="")[0]) <TAB>  <TAB> if line.startswith(""vermagic""): <TAB>  <TAB>  <TAB> line = line.replace(obj_kernel_version, this_kernel_version) <TAB>  <TAB> new_modinfo += line + ""\x00"" <TAB> return new_modinfo",if not line :,187
4769,"def zip_random_open_test(self, f, compression): <TAB> self.make_test_archive(f, compression) <TAB> # Read the ZIP archive <TAB> with zipfile.ZipFile(f, ""r"", compression) as zipfp: <TAB>  <TAB> zipdata1 = [] <TAB>  <TAB> with zipfp.open(TESTFN) as zipopen1: <TAB>  <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB>  <TAB> read_data = zipopen1.read(randint(1, 1024)) <MASK> break <TAB>  <TAB>  <TAB>  <TAB> zipdata1.append(read_data) <TAB>  <TAB> testdata = """".join(zipdata1) <TAB>  <TAB> self.assertEqual(len(testdata), len(self.data)) <TAB>  <TAB> self.assertEqual(testdata, self.data)",if not read_data :,182
4770,"def _memoized(*args): <TAB> now = time.time() <TAB> try: <TAB>  <TAB> value, last_update = self.cache[args] <TAB>  <TAB> age = now - last_update <MASK> self._call_count = 0 <TAB>  <TAB>  <TAB> raise AttributeError <TAB>  <TAB> if self.ctl: <TAB>  <TAB>  <TAB> self._call_count += 1 <TAB>  <TAB> return value <TAB> except (KeyError, AttributeError): <TAB>  <TAB> value = func(*args) <TAB>  <TAB> if value: <TAB>  <TAB>  <TAB> self.cache[args] = (value, now) <TAB>  <TAB> return value <TAB> except TypeError: <TAB>  <TAB> return func(*args)",if self . _call_count > self . ctl or age > self . ttl :,164
4771,"def on_data(res): <TAB> if terminate.is_set(): <TAB>  <TAB> return <TAB> if args.strings and not args.no_content: <TAB>  <TAB> if type(res) == tuple: <TAB>  <TAB>  <TAB> f, v = res <MASK> f = f.encode(""utf-8"") <TAB>  <TAB>  <TAB> if type(v) == unicode: <TAB>  <TAB>  <TAB>  <TAB> v = v.encode(""utf-8"") <TAB>  <TAB>  <TAB> self.success(""{}: {}"".format(f, v)) <TAB>  <TAB> elif not args.content_only: <TAB>  <TAB>  <TAB> self.success(res) <TAB> else: <TAB>  <TAB> self.success(res)",if type ( f ) == unicode :,158
4772,"def _finalize_setup_keywords(self): <TAB> for ep in pkg_resources.iter_entry_points(""distutils.setup_keywords""): <TAB>  <TAB> value = getattr(self, ep.name, None) <MASK> ep.require(installer=self.fetch_build_egg) <TAB>  <TAB>  <TAB> ep.load()(self, ep.name, value)",if value is not None :,90
4773,"def test_attributes_types(self): <TAB> if not self.connection.strategy.pooled: <MASK> self.connection.refresh_server_info() <TAB>  <TAB> self.assertEqual( <TAB>  <TAB>  <TAB> type(self.connection.server.schema.attribute_types[""cn""]), AttributeTypeInfo <TAB>  <TAB> )",if not self . connection . server . info :,82
4774,"def to_key(literal_or_identifier): <TAB> """"""returns string representation of this object"""""" <TAB> if literal_or_identifier[""type""] == ""Identifier"": <TAB>  <TAB> return literal_or_identifier[""name""] <TAB> elif literal_or_identifier[""type""] == ""Literal"": <TAB>  <TAB> k = literal_or_identifier[""value""] <TAB>  <TAB> if isinstance(k, float): <TAB>  <TAB>  <TAB> return unicode(float_repr(k)) <TAB>  <TAB> elif ""regex"" in literal_or_identifier: <TAB>  <TAB>  <TAB> return compose_regex(k) <MASK> return ""true"" if k else ""false"" <TAB>  <TAB> elif k is None: <TAB>  <TAB>  <TAB> return ""null"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return unicode(k)","elif isinstance ( k , bool ) :",179
4775,"def list2rec(x, test=False): <TAB> if test: <TAB>  <TAB> vid = ""{}_{:06d}_{:06d}"".format(x[0], int(x[1]), int(x[2])) <TAB>  <TAB> label = -1  # label unknown <TAB>  <TAB> return vid, label <TAB> else: <TAB>  <TAB> vid = ""{}_{:06d}_{:06d}"".format(x[1], int(x[2]), int(x[3])) <MASK> vid = ""{}/{}"".format(convert_label(x[0]), vid) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert level == 1 <TAB>  <TAB> label = class_mapping[convert_label(x[0])] <TAB>  <TAB> return vid, label",if level == 2 :,169
4776,"def _expand_env(self, snapcraft_yaml): <TAB> environment_keys = [""name"", ""version""] <TAB> for key in snapcraft_yaml: <MASK> continue <TAB>  <TAB> replacements = environment_to_replacements( <TAB>  <TAB>  <TAB> get_snapcraft_global_environment(self.project) <TAB>  <TAB> ) <TAB>  <TAB> snapcraft_yaml[key] = replace_attr(snapcraft_yaml[key], replacements) <TAB> return snapcraft_yaml",if any ( ( key == env_key for env_key in environment_keys ) ) :,124
4777,"def enableCtrls(self): <TAB> # Check if each ctrl has a requirement or an incompatibility, <TAB> # look it up, and enable/disable if so <TAB> for data in self.storySettingsData: <TAB>  <TAB> name = data[""name""] <MASK> if ""requires"" in data: <TAB>  <TAB>  <TAB>  <TAB> set = self.getSetting(data[""requires""]) <TAB>  <TAB>  <TAB>  <TAB> for i in self.ctrls[name]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> i.Enable(set not in [""off"", ""false"", ""0""])",if name in self . ctrls :,133
4778,"def __init__(self, *args, **kwargs): <TAB> super(ChallengePhaseCreateSerializer, self).__init__(*args, **kwargs) <TAB> context = kwargs.get(""context"") <TAB> if context: <TAB>  <TAB> challenge = context.get(""challenge"") <MASK> kwargs[""data""][""challenge""] = challenge.pk <TAB>  <TAB> test_annotation = context.get(""test_annotation"") <TAB>  <TAB> if test_annotation: <TAB>  <TAB>  <TAB> kwargs[""data""][""test_annotation""] = test_annotation",if challenge :,119
4779,def set_inactive(self): <TAB> for title in self.gramplet_map: <TAB>  <TAB> if self.gramplet_map[title].pui: <MASK> self.gramplet_map[title].pui.active = False,"if self . gramplet_map [ title ] . gstate != ""detached"" :",81
4780,"def authenticate(username, password): <TAB> try: <TAB>  <TAB> u = User.objects.get(username=username) <MASK> userLogger.info(""User logged in : %s"", username) <TAB>  <TAB>  <TAB> return u <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> userLogger.warn(""Attempt to log in to : %s"", username) <TAB>  <TAB>  <TAB> return False <TAB> except DoesNotExist: <TAB>  <TAB> return False","if check_password_hash ( u . password , password ) :",109
4781,def _check_date(self): <TAB> if not self.value: <TAB>  <TAB> return None <TAB> if not self.allow_date_in_past: <TAB>  <TAB> if self.value < self.date_or_datetime().today(): <MASK> self.value = self.date_or_datetime().today() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.value = self.date_or_datetime().today() + datetime.timedelta(1),if self . allow_todays_date :,119
4782,"def update(self, E=None, **F): <TAB> if E: <MASK> # Update with `E` dictionary <TAB>  <TAB>  <TAB> for k in E: <TAB>  <TAB>  <TAB>  <TAB> self[k] = E[k] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Update with `E` items <TAB>  <TAB>  <TAB> for (k, v) in E: <TAB>  <TAB>  <TAB>  <TAB> self[k] = v <TAB> # Update with `F` dictionary <TAB> for k in F: <TAB>  <TAB> self[k] = F[k]","if hasattr ( E , ""keys"" ) :",131
4783,"def _get_quota_availability(self): <TAB> quotas_ok = defaultdict(int) <TAB> qa = QuotaAvailability() <TAB> qa.queue(*[k for k, v in self._quota_diff.items() if v > 0]) <TAB> qa.compute(now_dt=self.now_dt) <TAB> for quota, count in self._quota_diff.items(): <MASK> quotas_ok[quota] = 0 <TAB>  <TAB>  <TAB> break <TAB>  <TAB> avail = qa.results[quota] <TAB>  <TAB> if avail[1] is not None and avail[1] < count: <TAB>  <TAB>  <TAB> quotas_ok[quota] = min(count, avail[1]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> quotas_ok[quota] = count <TAB> return quotas_ok",if count <= 0 :,182
4784,"def gen_env_vars(): <TAB> for fd_id, fd in zip(STDIO_DESCRIPTORS, (stdin, stdout, stderr)): <TAB>  <TAB> is_atty = fd.isatty() <TAB>  <TAB> yield (cls.TTY_ENV_TMPL.format(fd_id), cls.encode_env_var_value(int(is_atty))) <MASK> yield (cls.TTY_PATH_ENV.format(fd_id), os.ttyname(fd.fileno()) or b"""")",if is_atty :,123
4785,"def _convertDict(self, d): <TAB> r = {} <TAB> for k, v in d.items(): <TAB>  <TAB> if isinstance(v, bytes): <TAB>  <TAB>  <TAB> v = str(v, ""utf-8"") <TAB>  <TAB> elif isinstance(v, list) or isinstance(v, tuple): <TAB>  <TAB>  <TAB> v = self._convertList(v) <TAB>  <TAB> elif isinstance(v, dict): <TAB>  <TAB>  <TAB> v = self._convertDict(v) <MASK> k = str(k, ""utf-8"") <TAB>  <TAB> r[k] = v <TAB> return r","if isinstance ( k , bytes ) :",142
4786,"def get_attribute_value(self, nodeid, attr): <TAB> with self._lock: <TAB>  <TAB> self.logger.debug(""get attr val: %s %s"", nodeid, attr) <TAB>  <TAB> if nodeid not in self._nodes: <TAB>  <TAB>  <TAB> dv = ua.DataValue() <TAB>  <TAB>  <TAB> dv.StatusCode = ua.StatusCode(ua.StatusCodes.BadNodeIdUnknown) <TAB>  <TAB>  <TAB> return dv <TAB>  <TAB> node = self._nodes[nodeid] <MASK> dv = ua.DataValue() <TAB>  <TAB>  <TAB> dv.StatusCode = ua.StatusCode(ua.StatusCodes.BadAttributeIdInvalid) <TAB>  <TAB>  <TAB> return dv <TAB>  <TAB> attval = node.attributes[attr] <TAB>  <TAB> if attval.value_callback: <TAB>  <TAB>  <TAB> return attval.value_callback() <TAB>  <TAB> return attval.value",if attr not in node . attributes :,200
4787,"def conninfo_parse(dsn): <TAB> ret = {} <TAB> length = len(dsn) <TAB> i = 0 <TAB> while i < length: <MASK> i += 1 <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> param_match = PARAMETER_RE.match(dsn[i:]) <TAB>  <TAB> if not param_match: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> param = param_match.group(1) <TAB>  <TAB> i += param_match.end() <TAB>  <TAB> if i >= length: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> value, end = read_param_value(dsn[i:]) <TAB>  <TAB> if value is None: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> i += end <TAB>  <TAB> ret[param] = value <TAB> return ret",if dsn [ i ] . isspace ( ) :,175
4788,"def connect(self, buttons): <TAB> for button in buttons: <TAB>  <TAB> assert button is not None <TAB>  <TAB> handled = False <TAB>  <TAB> for handler_idx in range(0, len(self.__signal_handlers)): <TAB>  <TAB>  <TAB> (obj_class, signal, handler, handler_id) = self.__signal_handlers[ <TAB>  <TAB>  <TAB>  <TAB> handler_idx <TAB>  <TAB>  <TAB> ] <MASK> handler_id = button.connect(signal, handler) <TAB>  <TAB>  <TAB>  <TAB> handled = True <TAB>  <TAB>  <TAB> self.__signal_handlers[handler_idx] = ( <TAB>  <TAB>  <TAB>  <TAB> obj_class, <TAB>  <TAB>  <TAB>  <TAB> signal, <TAB>  <TAB>  <TAB>  <TAB> handler, <TAB>  <TAB>  <TAB>  <TAB> handler_id, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> assert handled","if isinstance ( button , obj_class ) :",182
4789,"def _parse_display(display): <TAB> """"""Parse an X11 display value"""""" <TAB> try: <TAB>  <TAB> host, dpynum = display.rsplit("":"", 1) <TAB>  <TAB> if host.startswith(""["") and host.endswith(""]""): <TAB>  <TAB>  <TAB> host = host[1:-1] <TAB>  <TAB> idx = dpynum.find(""."") <MASK> screen = int(dpynum[idx + 1 :]) <TAB>  <TAB>  <TAB> dpynum = dpynum[:idx] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> screen = 0 <TAB> except (ValueError, UnicodeEncodeError): <TAB>  <TAB> raise ValueError(""Invalid X11 display"") from None <TAB> return host, dpynum, screen",if idx >= 0 :,156
4790,"def delete_all(path): <TAB> ppath = os.getcwd() <TAB> os.chdir(path) <TAB> for fn in glob.glob(""*""): <TAB>  <TAB> fn_full = os.path.join(path, fn) <TAB>  <TAB> if os.path.isdir(fn): <TAB>  <TAB>  <TAB> delete_all(fn_full) <MASK> os.remove(fn_full) <TAB>  <TAB> elif fn.endswith("".md""): <TAB>  <TAB>  <TAB> os.remove(fn_full) <TAB>  <TAB> elif DELETE_ALL_OLD: <TAB>  <TAB>  <TAB> os.remove(fn_full) <TAB> os.chdir(ppath) <TAB> os.rmdir(path)","elif fn . endswith ( "".png"" ) :",158
4791,"def _sync_get(self, identifier, *args, **kw): <TAB> self._mutex.acquire() <TAB> try: <TAB>  <TAB> try: <MASK> return self._values[identifier] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self._values[identifier] = value = self.creator(identifier, *args, **kw) <TAB>  <TAB>  <TAB>  <TAB> return value <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> self._values[identifier] = value = self.creator(identifier, *args, **kw) <TAB>  <TAB>  <TAB> return value <TAB> finally: <TAB>  <TAB> self._mutex.release()",if identifier in self . _values :,148
4792,"def _query_fd(self): <TAB> if self.stream is None: <TAB>  <TAB> self._last_stat = None, None <TAB> else: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> st = os.stat(self._filename) <TAB>  <TAB> except OSError: <TAB>  <TAB>  <TAB> e = sys.exc_info()[1] <MASK> raise <TAB>  <TAB>  <TAB> self._last_stat = None, None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._last_stat = st[stat.ST_DEV], st[stat.ST_INO]",if e . errno != errno . ENOENT :,137
4793,"def get_place_name(self, place_handle): <TAB> """"""Obtain a place name"""""" <TAB> text = """" <TAB> if place_handle: <TAB>  <TAB> place = self.dbstate.db.get_place_from_handle(place_handle) <MASK> place_title = place_displayer.display(self.dbstate.db, place) <TAB>  <TAB>  <TAB> if place_title != """": <TAB>  <TAB>  <TAB>  <TAB> if len(place_title) > 25: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> text = place_title[:24] + ""..."" <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> text = place_title <TAB> return text",if place :,153
4794,"def test_decoder_state(self): <TAB> # Check that getstate() and setstate() handle the state properly <TAB> u = ""abc123"" <TAB> for encoding in all_unicode_encodings: <MASK> self.check_state_handling_decode(encoding, u, u.encode(encoding)) <TAB>  <TAB>  <TAB> self.check_state_handling_encode(encoding, u, u.encode(encoding))",if encoding not in broken_unicode_with_stateful :,110
4795,"def cleanup(self): <TAB> if os.path.exists(self.meta_gui_dir): <TAB>  <TAB> for f in os.listdir(self.meta_gui_dir): <MASK> os.remove(os.path.join(self.meta_gui_dir, f))","if os . path . splitext ( f ) [ 1 ] == "".desktop"" :",85
4796,"def _have_applied_incense(self): <TAB> for applied_item in inventory.applied_items().all(): <TAB>  <TAB> self.logger.info(applied_item) <MASK> mins = format_time(applied_item.expire_ms * 1000) <TAB>  <TAB>  <TAB> self.logger.info( <TAB>  <TAB>  <TAB>  <TAB> ""Not applying incense, currently active: %s, %s minutes remaining"", <TAB>  <TAB>  <TAB>  <TAB> applied_item.item.name, <TAB>  <TAB>  <TAB>  <TAB> mins, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.logger.info("""") <TAB>  <TAB>  <TAB> return False <TAB> return False",if applied_item . expire_ms > 0 :,162
4797,"def get_closest_point(self, point): <TAB> point = to_point(point) <TAB> cp, cd = None, None <TAB> for p0, p1 in iter_pairs(self.pts, self.connected): <TAB>  <TAB> diff = p1 - p0 <TAB>  <TAB> l = diff.length <TAB>  <TAB> d = diff / l <TAB>  <TAB> pp = p0 + d * max(0, min(l, (point - p0).dot(d))) <TAB>  <TAB> dist = (point - pp).length <MASK> cp, cd = pp, dist <TAB> return cp",if not cp or dist < cd :,143
4798,"def process_return(lines): <TAB> for line in lines: <TAB>  <TAB> m = re.fullmatch(r""(?P<param>\w+)\s+:\s+(?P<type>[\w.]+)"", line) <MASK> # Once this is in scanpydoc, we can use the fancy hover stuff <TAB>  <TAB>  <TAB> yield f'**{m[""param""]}** : :class:`~{m[""type""]}`' <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield line",if m :,106
4799,"def _classify(nodes_by_level): <TAB> missing, invalid, downloads = [], [], [] <TAB> for level in nodes_by_level: <TAB>  <TAB> for node in level: <TAB>  <TAB>  <TAB> if node.binary == BINARY_MISSING: <TAB>  <TAB>  <TAB>  <TAB> missing.append(node) <MASK> invalid.append(node) <TAB>  <TAB>  <TAB> elif node.binary in (BINARY_UPDATE, BINARY_DOWNLOAD): <TAB>  <TAB>  <TAB>  <TAB> downloads.append(node) <TAB> return missing, invalid, downloads",elif node . binary == BINARY_INVALID :,126
4800,"def safe_parse_date(date_hdr): <TAB> """"""Parse a Date: or Received: header into a unix timestamp."""""" <TAB> try: <MASK> date_hdr = date_hdr.split("";"")[-1].strip() <TAB>  <TAB> msg_ts = long(rfc822.mktime_tz(rfc822.parsedate_tz(date_hdr))) <TAB>  <TAB> if (msg_ts > (time.time() + 24 * 3600)) or (msg_ts < 1): <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return msg_ts <TAB> except (ValueError, TypeError, OverflowError): <TAB>  <TAB> return None","if "";"" in date_hdr :",150
4801,"def _on_change(self): <TAB> changed = False <TAB> self.save() <TAB> for key, value in self.data.items(): <TAB>  <TAB> if isinstance(value, bool): <TAB>  <TAB>  <TAB> if value: <TAB>  <TAB>  <TAB>  <TAB> changed = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if isinstance(value, int): <MASK> changed = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> elif value is None: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> elif len(value) != 0: <TAB>  <TAB>  <TAB> changed = True <TAB>  <TAB>  <TAB> break <TAB> self._reset_button.disabled = not changed",if value != 1 :,145
4802,"def _rewrite_prepend_append(self, string, prepend, append=None): <TAB> if append is None: <TAB>  <TAB> append = prepend <TAB> if not isinstance(string, StringElem): <TAB>  <TAB> string = StringElem(string) <TAB> string.sub.insert(0, prepend) <TAB> if unicode(string).endswith(u""\n""): <TAB>  <TAB> # Try and remove the last character from the tree <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> lastnode = string.flatten()[-1] <MASK> lastnode.sub[-1] = lastnode.sub[-1].rstrip(u""\n"") <TAB>  <TAB> except IndexError: <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> string.sub.append(append + u""\n"") <TAB> else: <TAB>  <TAB> string.sub.append(append) <TAB> return string","if isinstance ( lastnode . sub [ - 1 ] , unicode ) :",197
4803,"def parse_indentless_sequence_entry(self): <TAB> if self.check_token(BlockEntryToken): <TAB>  <TAB> token = self.get_token() <MASK> self.states.append(self.parse_indentless_sequence_entry) <TAB>  <TAB>  <TAB> return self.parse_block_node() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.state = self.parse_indentless_sequence_entry <TAB>  <TAB>  <TAB> return self.process_empty_scalar(token.end_mark) <TAB> token = self.peek_token() <TAB> event = SequenceEndEvent(token.start_mark, token.start_mark) <TAB> self.state = self.states.pop() <TAB> return event","if not self . check_token ( BlockEntryToken , KeyToken , ValueToken , BlockEndToken ) :",184
4804,"def walk_directory(directory, verbose=False): <TAB> """"""Iterates a directory's text files and their contents."""""" <TAB> for dir_path, _, filenames in os.walk(directory): <TAB>  <TAB> for filename in filenames: <TAB>  <TAB>  <TAB> file_path = os.path.join(dir_path, filename) <TAB>  <TAB>  <TAB> if os.path.isfile(file_path) and not filename.startswith("".""): <TAB>  <TAB>  <TAB>  <TAB> with io.open(file_path, ""r"", encoding=""utf-8"") as file: <MASK> print(""Reading {}"".format(filename)) <TAB>  <TAB>  <TAB>  <TAB>  <TAB> doc_text = file.read() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> yield filename, doc_text",if verbose :,166
4805,"def set_bounds(self, x, y, width, height): <TAB> if self.native: <TAB>  <TAB> # Root level widgets may require vertical adjustment to <TAB>  <TAB> # account for toolbars, etc. <MASK> vertical_shift = self.frame.vertical_shift <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> vertical_shift = 0 <TAB>  <TAB> self.native.Size = Size(width, height) <TAB>  <TAB> self.native.Location = Point(x, y + vertical_shift)",if self . interface . parent is None :,122
4806,"def _check_x11(self, command=None, *, exc=None, exit_status=None, **kwargs): <TAB> """"""Check requesting X11 forwarding"""""" <TAB> with (yield from self.connect()) as conn: <MASK> with self.assertRaises(exc): <TAB>  <TAB>  <TAB>  <TAB> yield from _create_x11_process(conn, command, **kwargs) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> proc = yield from _create_x11_process(conn, command, **kwargs) <TAB>  <TAB>  <TAB> yield from proc.wait() <TAB>  <TAB>  <TAB> self.assertEqual(proc.exit_status, exit_status) <TAB> yield from conn.wait_closed()",if exc :,156
4807,"def repr(self): <TAB> try: <MASK> from infogami.infobase.utils import prepr <TAB>  <TAB>  <TAB> return prepr(self.obj) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return repr(self.obj) <TAB> except: <TAB>  <TAB> return ""failed"" <TAB> return render_template(""admin/memory/object"", self.obj)","if isinstance ( self . obj , ( dict , web . threadeddict ) ) :",100
4808,"def add(self, tag, values): <TAB> if tag not in self.different: <TAB>  <TAB> if tag not in self: <TAB>  <TAB>  <TAB> self[tag] = values <MASK> self.different.add(tag) <TAB>  <TAB>  <TAB> self[tag] = [""""] <TAB> self.counts[tag] += 1",elif self [ tag ] != values :,82
4809,"def _on_geturl(self, event): <TAB> selected = self._status_list.get_selected() <TAB> if selected != -1: <TAB>  <TAB> object_id = self._status_list.GetItemData(selected) <TAB>  <TAB> download_item = self._download_list.get_item(object_id) <TAB>  <TAB> url = download_item.url <MASK> clipdata = wx.TextDataObject() <TAB>  <TAB>  <TAB> clipdata.SetText(url) <TAB>  <TAB>  <TAB> wx.TheClipboard.Open() <TAB>  <TAB>  <TAB> wx.TheClipboard.SetData(clipdata) <TAB>  <TAB>  <TAB> wx.TheClipboard.Close()",if not wx . TheClipboard . IsOpened ( ) :,163
4810,"def escape2null(text): <TAB> """"""Return a string with escape-backslashes converted to nulls."""""" <TAB> parts = [] <TAB> start = 0 <TAB> while True: <TAB>  <TAB> found = text.find(""\\"", start) <MASK> parts.append(text[start:]) <TAB>  <TAB>  <TAB> return """".join(parts) <TAB>  <TAB> parts.append(text[start:found]) <TAB>  <TAB> parts.append(""\x00"" + text[found + 1 : found + 2]) <TAB>  <TAB> start = found + 2  # skip character after escape",if found == - 1 :,129
4811,def _process_inner_views(self): <TAB> for view in self.baseviews: <TAB>  <TAB> for inner_class in view.get_uninit_inner_views(): <TAB>  <TAB>  <TAB> for v in self.baseviews: <MASK> view.get_init_inner_views().append(v),"if isinstance ( v , inner_class ) and v not in view . get_init_inner_views ( ) :",99
4812,"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> self.set_url(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> self.set_app_version_id(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 26: <TAB>  <TAB>  <TAB> self.set_method(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 34: <TAB>  <TAB>  <TAB> self.set_queue(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 18 :,184
4813,"def test_sample_output(): <TAB> comment = ""SAMPLE OUTPUT"" <TAB> skip_files = [""__init__.py""] <TAB> errors = [] <TAB> for _file in sorted(MODULE_PATH.iterdir()): <TAB>  <TAB> if _file.suffix == "".py"" and _file.name not in skip_files: <TAB>  <TAB>  <TAB> with _file.open() as f: <MASK> errors.append((comment, _file)) <TAB> if errors: <TAB>  <TAB> line = ""Missing sample error(s) detected!\n\n"" <TAB>  <TAB> for error in errors: <TAB>  <TAB>  <TAB> line += ""`{}` is not in module `{}`\n"".format(*error) <TAB>  <TAB> print(line[:-1]) <TAB>  <TAB> assert False",if comment not in f . read ( ) :,174
4814,"def _get_planner(name, path, source): <TAB> for klass in _planners: <MASK> LOG.debug(""%r accepted %r (filename %r)"", klass, name, path) <TAB>  <TAB>  <TAB> return klass <TAB>  <TAB> LOG.debug(""%r rejected %r"", klass, name) <TAB> raise ansible.errors.AnsibleError(NO_METHOD_MSG + repr(invocation))","if klass . detect ( path , source ) :",100
4815,"def _to_string_infix(self, ostream, idx, verbose): <TAB> if verbose: <TAB>  <TAB> ostream.write("" , "") <TAB> else: <TAB>  <TAB> hasConst = not ( <TAB>  <TAB>  <TAB> self._const.__class__ in native_numeric_types and self._const == 0 <TAB>  <TAB> ) <MASK> idx -= 1 <TAB>  <TAB> _l = self._coef[id(self._args[idx])] <TAB>  <TAB> _lt = _l.__class__ <TAB>  <TAB> if _lt is _NegationExpression or (_lt in native_numeric_types and _l < 0): <TAB>  <TAB>  <TAB> ostream.write("" - "") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ostream.write("" + "")",if hasConst :,169
4816,"def cluster_info_query(self): <TAB> if self._major_version >= 90600: <TAB>  <TAB> extra = ( <TAB>  <TAB>  <TAB> "", CASE WHEN latest_end_lsn IS NULL THEN NULL ELSE received_tli END,"" <TAB>  <TAB>  <TAB> "" slot_name, conninfo FROM pg_catalog.pg_stat_get_wal_receiver()"" <TAB>  <TAB> ) <MASK> extra = ""timeline_id"" + extra + "", pg_catalog.pg_control_checkpoint()"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> extra = ""0"" + extra <TAB> else: <TAB>  <TAB> extra = ""0, NULL, NULL, NULL"" <TAB> return (""SELECT "" + self.TL_LSN + "", {2}"").format( <TAB>  <TAB> self.wal_name, self.lsn_name, extra <TAB> )","if self . role == ""standby_leader"" :",199
4817,"def __init__(self, *args, **kwargs): <TAB> self.country = kwargs.pop(""country"") <TAB> self.fields_needed = kwargs.pop(""fields_needed"", []) <TAB> super(DynamicManagedAccountForm, self).__init__(*args, **kwargs) <TAB> # build our form using the country specific fields and falling <TAB> # back to our default set <TAB> for f in self.fields_needed: <MASK> # pragma: no branch <TAB>  <TAB>  <TAB> field_name, field = FIELDS_BY_COUNTRY[self.country][f] <TAB>  <TAB>  <TAB> self.fields[field_name] = field","if f in FIELDS_BY_COUNTRY . get ( self . country , { } ) :",155
4818,"def delete_map(self, query=None): <TAB> query_map = self.interpolated_map(query=query) <TAB> for alias, drivers in six.iteritems(query_map.copy()): <TAB>  <TAB> for driver, vms in six.iteritems(drivers.copy()): <TAB>  <TAB>  <TAB> for vm_name, vm_details in six.iteritems(vms.copy()): <MASK> query_map[alias][driver].pop(vm_name) <TAB>  <TAB>  <TAB> if not query_map[alias][driver]: <TAB>  <TAB>  <TAB>  <TAB> query_map[alias].pop(driver) <TAB>  <TAB> if not query_map[alias]: <TAB>  <TAB>  <TAB> query_map.pop(alias) <TAB> return query_map","if vm_details == ""Absent"" :",177
4819,"def on_strokes_edited(self): <TAB> strokes = self._strokes() <TAB> if strokes: <TAB>  <TAB> translation = self._engine.raw_lookup(strokes) <MASK> fmt = _(""{strokes} maps to {translation}"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> fmt = _(""{strokes} is not in the dictionary"") <TAB>  <TAB> info = self._format_label(fmt, (strokes,), translation) <TAB> else: <TAB>  <TAB> info = """" <TAB> self.strokes_info.setText(info)",if translation is not None :,123
4820,"def release(self): <TAB> tid = _thread.get_ident() <TAB> with self.lock: <TAB>  <TAB> if self.owner != tid: <TAB>  <TAB>  <TAB> raise RuntimeError(""cannot release un-acquired lock"") <TAB>  <TAB> assert self.count > 0 <TAB>  <TAB> self.count -= 1 <MASK> self.owner = None <TAB>  <TAB>  <TAB> if self.waiters: <TAB>  <TAB>  <TAB>  <TAB> self.waiters -= 1 <TAB>  <TAB>  <TAB>  <TAB> self.wakeup.release()",if self . count == 0 :,117
4821,"def _cat_blob(self, gcs_uri): <TAB> """""":py:meth:`cat_file`, minus decompression."""""" <TAB> blob = self._get_blob(gcs_uri) <TAB> if not blob: <TAB>  <TAB> return  # don't cat nonexistent files <TAB> start = 0 <TAB> while True: <TAB>  <TAB> end = start + _CAT_CHUNK_SIZE <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> chunk = blob.download_as_string(start=start, end=end) <TAB>  <TAB> except google.api_core.exceptions.RequestRangeNotSatisfiable: <TAB>  <TAB>  <TAB> return <TAB>  <TAB> yield chunk <MASK> return <TAB>  <TAB> start = end",if len ( chunk ) < _CAT_CHUNK_SIZE :,168
4822,"def device_iter(**kwargs): <TAB> for dev in backend.enumerate_devices(): <TAB>  <TAB> d = Device(dev, backend) <TAB>  <TAB> tests = (val == _try_getattr(d, key) for key, val in kwargs.items()) <MASK> yield d",if _interop . _all ( tests ) and ( custom_match is None or custom_match ( d ) ) :,88
4823,"def _get_vtkjs(self): <TAB> if self._vtkjs is None and self.object is not None: <TAB>  <TAB> if isinstance(self.object, string_types) and self.object.endswith("".vtkjs""): <TAB>  <TAB>  <TAB> if isfile(self.object): <TAB>  <TAB>  <TAB>  <TAB> with open(self.object, ""rb"") as f: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> vtkjs = f.read() <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> data_url = urlopen(self.object) <TAB>  <TAB>  <TAB>  <TAB> vtkjs = data_url.read() <MASK> vtkjs = self.object.read() <TAB>  <TAB> self._vtkjs = vtkjs <TAB> return self._vtkjs","elif hasattr ( self . object , ""read"" ) :",180
4824,"def _execute_with_error(command, error, message): <TAB> try: <TAB>  <TAB> cli.invocation = cli.invocation_cls( <TAB>  <TAB>  <TAB> cli_ctx=cli, <TAB>  <TAB>  <TAB> parser_cls=cli.parser_cls, <TAB>  <TAB>  <TAB> commands_loader_cls=cli.commands_loader_cls, <TAB>  <TAB>  <TAB> help_cls=cli.help_cls, <TAB>  <TAB> ) <TAB>  <TAB> cli.invocation.execute(command.split()) <TAB> except CLIError as ex: <MASK> raise AssertionError( <TAB>  <TAB>  <TAB>  <TAB> ""{}\nExpected: {}\nActual: {}"".format(message, error, ex) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> return <TAB> except Exception as ex: <TAB>  <TAB> raise ex <TAB> raise AssertionError(""exception not raised for '{0}'"".format(message))",if error not in str ( ex ) :,193
4825,"def ray_intersection(self, p, line): <TAB> p = Vector(center(line.sites)) <TAB> min_r = BIG_FLOAT <TAB> nearest = None <TAB> for v_i, v_j in self.edges: <TAB>  <TAB> bound = LineEquation2D.from_two_points(v_i, v_j) <TAB>  <TAB> intersection = bound.intersect_with_line(line) <TAB>  <TAB> if intersection is not None: <TAB>  <TAB>  <TAB> r = (p - intersection).length <TAB>  <TAB>  <TAB> # info(""INT: [%s - %s] X [%s] => %s (%s)"", v_i, v_j, line, intersection, r) <MASK> nearest = intersection <TAB>  <TAB>  <TAB>  <TAB> min_r = r <TAB> return nearest",if r < min_r :,187
4826,"def CalculateChecksum(data): <TAB> # The checksum is just a sum of all the bytes. I swear. <TAB> if isinstance(data, bytearray): <TAB>  <TAB> total = sum(data) <TAB> elif isinstance(data, bytes): <MASK> # Python 2 bytes (str) index as single-character strings. <TAB>  <TAB>  <TAB> total = sum(map(ord, data)) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Python 3 bytes index as numbers (and PY2 empty strings sum() to 0) <TAB>  <TAB>  <TAB> total = sum(data) <TAB> else: <TAB>  <TAB> # Unicode strings (should never see?) <TAB>  <TAB> total = sum(map(ord, data)) <TAB> return total & 0xFFFFFFFF","if data and isinstance ( data [ 0 ] , bytes ) :",172
4827,"def __mul__(self, other: Union[""Tensor"", float]) -> ""Tensor"": <TAB> if isinstance(other, Tensor): <MASK> errstr = ( <TAB>  <TAB>  <TAB>  <TAB> f""Given backens are inconsistent. Found '{self.backend.name}'"" <TAB>  <TAB>  <TAB>  <TAB> f""and '{other.backend.name}'"" <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> raise ValueError(errstr) <TAB>  <TAB> other = other.array <TAB> array = self.backend.multiply(self.array, other) <TAB> return Tensor(array, backend=self.backend)",if self . backend . name != other . backend . name :,140
4828,"def next_item(self, direction): <TAB> """"""Selects next menu item, based on self._direction"""""" <TAB> start, i = -1, 0 <TAB> try: <TAB>  <TAB> start = self.items.index(self._selected) <TAB>  <TAB> i = start + direction <TAB> except: <TAB>  <TAB> pass <TAB> while True: <MASK> # Cannot find valid menu item <TAB>  <TAB>  <TAB> self.select(start) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> if i >= len(self.items): <TAB>  <TAB>  <TAB> i = 0 <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if i < 0: <TAB>  <TAB>  <TAB> i = len(self.items) - 1 <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if self.select(i): <TAB>  <TAB>  <TAB> break <TAB>  <TAB> i += direction <TAB>  <TAB> if start < 0: <TAB>  <TAB>  <TAB> start = 0",if i == start :,194
4829,"def resolve_none(self, data): <TAB> # replace None to '_' <TAB> for tok_idx in range(len(data)): <TAB>  <TAB> for feat_idx in range(len(data[tok_idx])): <MASK> data[tok_idx][feat_idx] = ""_"" <TAB> return data",if data [ tok_idx ] [ feat_idx ] is None :,87
4830,"def distinct(expr, *on): <TAB> fields = frozenset(expr.fields) <TAB> _on = [] <TAB> append = _on.append <TAB> for n in on: <TAB>  <TAB> if isinstance(n, Field): <TAB>  <TAB>  <TAB> if n._child.isidentical(expr): <TAB>  <TAB>  <TAB>  <TAB> n = n._name <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError(""{0} is not a field of {1}"".format(n, expr)) <TAB>  <TAB> if not isinstance(n, _strtypes): <TAB>  <TAB>  <TAB> raise TypeError(""on must be a name or field, not: {0}"".format(n)) <MASK> raise ValueError(""{0} is not a field of {1}"".format(n, expr)) <TAB>  <TAB> append(n) <TAB> return Distinct(expr, tuple(_on))",elif n not in fields :,192
4831,"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <MASK> length = d.getVarInt32() <TAB>  <TAB>  <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB>  <TAB>  <TAB> d.skip(length) <TAB>  <TAB>  <TAB> self.mutable_cost().TryMerge(tmp) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 24: <TAB>  <TAB>  <TAB> self.add_version(d.getVarInt64()) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 0: <TAB>  <TAB>  <TAB> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 10 :,167
4832,"def func_std_string(func_name):  # match what old profile produced <TAB> if func_name[:2] == (""~"", 0): <TAB>  <TAB> # special case for built-in functions <TAB>  <TAB> name = func_name[2] <MASK> return ""{%s}"" % name[1:-1] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return name <TAB> else: <TAB>  <TAB> return ""%s:%d(%s)"" % func_name","if name . startswith ( ""<"" ) and name . endswith ( "">"" ) :",115
4833,"def f(): <TAB> try: <TAB>  <TAB> # Intra-buffer read then buffer-flushing read <TAB>  <TAB> for n in cycle([1, 19]): <TAB>  <TAB>  <TAB> s = bufio.read(n) <MASK> break <TAB>  <TAB>  <TAB> # list.append() is atomic <TAB>  <TAB>  <TAB> results.append(s) <TAB> except Exception as e: <TAB>  <TAB> errors.append(e) <TAB>  <TAB> raise",if not s :,104
4834,"def stop(self): <TAB> # Try to shut the connection down, but if we get any sort of <TAB> # errors, go ahead and ignore them.. as we're shutting down anyway <TAB> try: <TAB>  <TAB> self.rpcserver.stop() <TAB>  <TAB> if self.backend_rpcserver: <TAB>  <TAB>  <TAB> self.backend_rpcserver.stop() <MASK> self.cluster_rpcserver.stop() <TAB> except Exception: <TAB>  <TAB> pass <TAB> if self.coordination: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> coordination.COORDINATOR.stop() <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> pass <TAB> super(Service, self).stop(graceful=True)",if self . cluster_rpcserver :,171
4835,"def download(cls, architecture, path=""./""): <TAB> if cls.sanity_check(architecture): <TAB>  <TAB> architecture_file = download_file( <TAB>  <TAB>  <TAB> cls.architecture_map[architecture], directory=path <TAB>  <TAB> ) <MASK> return None <TAB>  <TAB> print(""Coreml model {} is saved in [{}]"".format(architecture, path)) <TAB>  <TAB> return architecture_file <TAB> else: <TAB>  <TAB> return None",if not architecture_file :,107
4836,"def opps_output_converter(kpt_list): <TAB> kpts = [] <TAB> mpii_keys = to_opps_converter.keys() <TAB> for mpii_idx in range(0, 16): <MASK> model_idx = to_opps_converter[mpii_idx] <TAB>  <TAB>  <TAB> x, y = kpt_list[model_idx] <TAB>  <TAB>  <TAB> if x < 0 or y < 0: <TAB>  <TAB>  <TAB>  <TAB> kpts += [0.0, 0.0, -1.0] <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> kpts += [x, y, 1.0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> kpts += [0.0, 0.0, -1.0] <TAB> return kpts",if mpii_idx in mpii_keys :,188
4837,"def _get_headers(self, headers=None): <TAB> request_headers = headers or {} <TAB> # Auth headers if access_token is present <TAB> if self._client.client.config: <TAB>  <TAB> config = self._client.client.config <TAB>  <TAB> if ""Authorization"" not in request_headers and config.token: <TAB>  <TAB>  <TAB> request_headers.update( <TAB>  <TAB>  <TAB>  <TAB> { <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""Authorization"": ""{} {}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> config.authentication_type, config.token <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> } <TAB>  <TAB>  <TAB> ) <MASK> request_headers.update({config.header: config.header_service}) <TAB> return request_headers",if config . header and config . header_service :,176
4838,"def get_last_traded_prices(cls, trading_pairs: List[str]) -> Dict[str, float]: <TAB> results = dict() <TAB> async with aiohttp.ClientSession() as client: <TAB>  <TAB> resp = await client.get(f""{constants.REST_URL}/tickers"") <TAB>  <TAB> resp_json = await resp.json() <TAB>  <TAB> for trading_pair in trading_pairs: <TAB>  <TAB>  <TAB> resp_record = [ <TAB>  <TAB>  <TAB>  <TAB> o <TAB>  <TAB>  <TAB>  <TAB> for o in resp_json <MASK> ][0] <TAB>  <TAB>  <TAB> results[trading_pair] = float(resp_record[""price""]) <TAB> return results","if o [ ""symbol"" ] == convert_to_exchange_trading_pair ( trading_pair )",181
4839,"def reset_two_factor_hotp(): <TAB> uid = request.form[""uid""] <TAB> otp_secret = request.form.get(""otp_secret"", None) <TAB> if otp_secret: <TAB>  <TAB> user = Journalist.query.get(uid) <MASK> return render_template(""admin_edit_hotp_secret.html"", uid=uid) <TAB>  <TAB> db.session.commit() <TAB>  <TAB> return redirect(url_for(""admin.new_user_two_factor"", uid=uid)) <TAB> else: <TAB>  <TAB> return render_template(""admin_edit_hotp_secret.html"", uid=uid)","if not validate_hotp_secret ( user , otp_secret ) :",166
4840,"def ctx_for_video(self, vurl): <TAB> ""Get a context dict for a given video URL"" <TAB> ctx = self.get_context_dict() <TAB> for portal, match, context_fn in self.PORTALS: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> ctx.update(context_fn(vurl)) <TAB>  <TAB>  <TAB>  <TAB> ctx[""portal""] = portal <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB> return ctx",if match . search ( vurl ) :,122
4841,"def get(self): <TAB> name = request.args.get(""filename"") <TAB> if name is not None: <TAB>  <TAB> opts = dict() <TAB>  <TAB> opts[""type""] = ""episode"" <TAB>  <TAB> result = guessit(name, options=opts) <TAB>  <TAB> res = dict() <TAB>  <TAB> if ""episode"" in result: <TAB>  <TAB>  <TAB> res[""episode""] = result[""episode""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> res[""episode""] = 0 <TAB>  <TAB> if ""season"" in result: <TAB>  <TAB>  <TAB> res[""season""] = result[""season""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> res[""season""] = 0 <MASK> res[""subtitle_language""] = str(result[""subtitle_language""]) <TAB>  <TAB> return jsonify(data=res) <TAB> else: <TAB>  <TAB> return """", 400","if ""subtitle_language"" in result :",196
4842,"def package_files(package_path, directory_name): <TAB> paths = [] <TAB> directory_path = os.path.join(package_path, directory_name) <TAB> for (path, directories, filenames) in os.walk(directory_path): <TAB>  <TAB> relative_path = os.path.relpath(path, package_path) <TAB>  <TAB> for filename in filenames: <MASK> continue <TAB>  <TAB>  <TAB> paths.append(os.path.join(relative_path, filename)) <TAB> return paths","if filename [ 0 ] == ""."" :",126
4843,"def parse_simple(d, data): <TAB> units = {} <TAB> for v in data[d]: <TAB>  <TAB> key = v[""name""] <TAB>  <TAB> if not key: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> key_to_insert = make_key(key) <MASK> index = 2 <TAB>  <TAB>  <TAB> tmp = f""{key_to_insert}_{index}"" <TAB>  <TAB>  <TAB> while tmp in units: <TAB>  <TAB>  <TAB>  <TAB> index += 1 <TAB>  <TAB>  <TAB>  <TAB> tmp = f""{key_to_insert}_{index}"" <TAB>  <TAB>  <TAB> key_to_insert = tmp <TAB>  <TAB> units[key_to_insert] = v[""id""] <TAB> return units",if key_to_insert in units :,160
4844,"def parse_clademodelc(branch_type_no, line_floats, site_classes): <TAB> """"""Parse results specific to the clade model C."""""" <TAB> if not site_classes or len(line_floats) == 0: <TAB>  <TAB> return <TAB> for n in range(len(line_floats)): <MASK> site_classes[n][""branch types""] = {} <TAB>  <TAB> site_classes[n][""branch types""][branch_type_no] = line_floats[n] <TAB> return site_classes","if site_classes [ n ] . get ( ""branch types"" ) is None :",134
4845,"def track_modules(self, *modules): <TAB> """"""Add module names to the tracked list."""""" <TAB> already_tracked = self.session.GetParameter(""autodetect_build_local_tracked"") or [] <TAB> needed = set(modules) <TAB> if not needed.issubset(already_tracked): <TAB>  <TAB> needed.update(already_tracked) <TAB>  <TAB> with self.session as session: <TAB>  <TAB>  <TAB> session.SetParameter(""autodetect_build_local_tracked"", needed) <TAB>  <TAB>  <TAB> for module_name in modules: <TAB>  <TAB>  <TAB>  <TAB> module_obj = self.GetModuleByName(module_name) <MASK> # Clear the module's profile. This will force it to <TAB>  <TAB>  <TAB>  <TAB>  <TAB> # reload a new profile. <TAB>  <TAB>  <TAB>  <TAB>  <TAB> module_obj.profile = None",if module_obj :,196
4846,"def set_job_on_hold(self, value, blocking=True): <TAB> trigger = False <TAB> # don't run any locking code beyond this... <TAB> if not self._job_on_hold.acquire(blocking=blocking): <TAB>  <TAB> return False <TAB> try: <MASK> self._job_on_hold.set() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._job_on_hold.clear() <TAB>  <TAB>  <TAB> if self._job_on_hold.counter == 0: <TAB>  <TAB>  <TAB>  <TAB> trigger = True <TAB> finally: <TAB>  <TAB> self._job_on_hold.release() <TAB> # locking code is now safe to run again <TAB> if trigger: <TAB>  <TAB> self._continue_sending() <TAB> return True",if value :,172
4847,"def moveToThreadNext(self): <TAB> """"""Move a position to threadNext position."""""" <TAB> p = self <TAB> if p.v: <MASK> p.moveToFirstChild() <TAB>  <TAB> elif p.hasNext(): <TAB>  <TAB>  <TAB> p.moveToNext() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> p.moveToParent() <TAB>  <TAB>  <TAB> while p: <TAB>  <TAB>  <TAB>  <TAB> if p.hasNext(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> p.moveToNext() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break  # found <TAB>  <TAB>  <TAB>  <TAB> p.moveToParent() <TAB>  <TAB>  <TAB> # not found. <TAB> return p",if p . v . children :,150
4848,"def best_image(width, height): <TAB> # A heuristic for finding closest sized image to required size. <TAB> image = images[0] <TAB> for img in images: <MASK> # Exact match always used <TAB>  <TAB>  <TAB> return img <TAB>  <TAB> elif img.width >= width and img.width * img.height > image.width * image.height: <TAB>  <TAB>  <TAB> # At least wide enough, and largest area <TAB>  <TAB>  <TAB> image = img <TAB> return image",if img . width == width and img . height == height :,120
4849,"def _check_input_types(self): <TAB> if len(self.base_features) == 0: <TAB>  <TAB> return True <TAB> input_types = self.primitive.input_types <TAB> if input_types is not None: <MASK> input_types = [input_types] <TAB>  <TAB> for t in input_types: <TAB>  <TAB>  <TAB> zipped = list(zip(t, self.base_features)) <TAB>  <TAB>  <TAB> if all([issubclass(f.variable_type, v) for v, f in zipped]): <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> else: <TAB>  <TAB> return True <TAB> return False",if type ( input_types [ 0 ] ) != list :,154
4850,"def get_result(self): <TAB> result_list = [] <TAB> exc_info = None <TAB> for f in self.children: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> result_list.append(f.get_result()) <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> if exc_info is None: <TAB>  <TAB>  <TAB>  <TAB> exc_info = sys.exc_info() <TAB>  <TAB>  <TAB> else: <MASK> app_log.error(""Multiple exceptions in yield list"", exc_info=True) <TAB> if exc_info is not None: <TAB>  <TAB> raise_exc_info(exc_info) <TAB> if self.keys is not None: <TAB>  <TAB> return dict(zip(self.keys, result_list)) <TAB> else: <TAB>  <TAB> return list(result_list)","if not isinstance ( e , self . quiet_exceptions ) :",196
4851,"def _update_learning_params(self): <TAB> model = self.model <TAB> hparams = self.hparams <TAB> fd = self.runner.feed_dict <TAB> step_num = self.step_num <TAB> if hparams.model_type == ""resnet_tf"": <TAB>  <TAB> if step_num < hparams.lrn_step: <TAB>  <TAB>  <TAB> lrn_rate = hparams.mom_lrn <MASK> lrn_rate = hparams.mom_lrn / 10 <TAB>  <TAB> elif step_num < 35000: <TAB>  <TAB>  <TAB> lrn_rate = hparams.mom_lrn / 100 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lrn_rate = hparams.mom_lrn / 1000 <TAB>  <TAB> fd[model.lrn_rate] = lrn_rate",elif step_num < 30000 :,190
4852,"def topic_exists(self, arn): <TAB> response = self._conn.get_all_topics() <TAB> topics = response[""ListTopicsResponse""][""ListTopicsResult""][""Topics""] <TAB> current_topics = [] <TAB> if len(topics) > 0: <TAB>  <TAB> for topic in topics: <TAB>  <TAB>  <TAB> topic_arn = topic[""TopicArn""] <TAB>  <TAB>  <TAB> current_topics.append(topic_arn) <MASK> return True <TAB> return False",if arn in current_topics :,115
4853,"def assertStartsWith(self, expectedPrefix, text, msg=None): <TAB> if not text.startswith(expectedPrefix): <MASK> text = text[: len(expectedPrefix) + 5] + ""..."" <TAB>  <TAB> standardMsg = ""{} not found at the start of {}"".format( <TAB>  <TAB>  <TAB> repr(expectedPrefix), repr(text) <TAB>  <TAB> ) <TAB>  <TAB> self.fail(self._formatMessage(msg, standardMsg))",if len ( expectedPrefix ) + 5 < len ( text ) :,112
4854,"def validate_memory(self, value): <TAB> for k, v in value.viewitems(): <MASK> # use NoneType to unset a value <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if not re.match(PROCTYPE_MATCH, k): <TAB>  <TAB>  <TAB> raise serializers.ValidationError(""Process types can only contain [a-z]"") <TAB>  <TAB> if not re.match(MEMLIMIT_MATCH, str(v)): <TAB>  <TAB>  <TAB> raise serializers.ValidationError( <TAB>  <TAB>  <TAB>  <TAB> ""Limit format: <number><unit>, where unit = B, K, M or G"" <TAB>  <TAB>  <TAB> ) <TAB> return value",if v is None :,141
4855,"def open(self) -> ""KeyValueJsonDb"": <TAB> """"""Create a new data base or open existing one"""""" <TAB> if os.path.exists(self._name): <MASK> raise IOError(""%s exists and is not a file"" % self._name) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> with open(self._name, ""r"") as _in: <TAB>  <TAB>  <TAB>  <TAB> self.set_records(json.load(_in)) <TAB>  <TAB> except json.JSONDecodeError: <TAB>  <TAB>  <TAB> # file corrupted, reset it. <TAB>  <TAB>  <TAB> self.commit() <TAB> else: <TAB>  <TAB> # make sure path exists <TAB>  <TAB> mkpath(os.path.dirname(self._name)) <TAB>  <TAB> self.commit() <TAB> return self",if not os . path . isfile ( self . _name ) :,180
4856,"def _calculate(self): <TAB> before = self.before.data <TAB> after = self.after.data <TAB> self.deleted = {} <TAB> self.updated = {} <TAB> self.created = after.copy() <TAB> for path, f in before.items(): <MASK> self.deleted[path] = f <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> del self.created[path] <TAB>  <TAB> if f.mtime < after[path].mtime: <TAB>  <TAB>  <TAB> self.updated[path] = after[path]",if path not in after :,125
4857,"def cache_sqs_queues_across_accounts() -> bool: <TAB> function: str = f""{__name__}.{sys._getframe().f_code.co_name}"" <TAB> # First, get list of accounts <TAB> accounts_d: list = async_to_sync(get_account_id_to_name_mapping)() <TAB> # Second, call tasks to enumerate all the roles across all accounts <TAB> for account_id in accounts_d.keys(): <MASK> cache_sqs_queues_for_account.delay(account_id) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if account_id in config.get(""celery.test_account_ids"", []): <TAB>  <TAB>  <TAB>  <TAB> cache_sqs_queues_for_account.delay(account_id) <TAB> stats.count(f""{function}.success"") <TAB> return True","if config . get ( ""environment"" ) == ""prod"" :",200
4858,"def remove(self, path, config=None, error_on_path=False, defaults=None): <TAB> if not path: <TAB>  <TAB> if error_on_path: <TAB>  <TAB>  <TAB> raise NoSuchSettingsPath() <TAB>  <TAB> return <TAB> if config is not None or defaults is not None: <MASK> config = self._config <TAB>  <TAB> if defaults is None: <TAB>  <TAB>  <TAB> defaults = dict(self._map.parents) <TAB>  <TAB> chain = HierarchicalChainMap(config, defaults) <TAB> else: <TAB>  <TAB> chain = self._map <TAB> try: <TAB>  <TAB> chain.del_by_path(path) <TAB>  <TAB> self._mark_dirty() <TAB> except KeyError: <TAB>  <TAB> if error_on_path: <TAB>  <TAB>  <TAB> raise NoSuchSettingsPath() <TAB>  <TAB> pass",if config is None :,184
4859,"def PopulateProjectId(project_id=None): <TAB> """"""Fills in a project_id from the boto config file if one is not provided."""""" <TAB> if not project_id: <TAB>  <TAB> default_id = boto.config.get_value(""GSUtil"", ""default_project_id"") <MASK> raise ProjectIdException(""MissingProjectId"") <TAB>  <TAB> return default_id <TAB> return project_id",if not default_id :,101
4860,"def set(self, name, value): <TAB> with self._object_cache_lock: <TAB>  <TAB> old_value = self._object_cache.get(name) <TAB>  <TAB> ret = not old_value or int(old_value.metadata.resource_version) < int( <TAB>  <TAB>  <TAB> value.metadata.resource_version <TAB>  <TAB> ) <MASK> self._object_cache[name] = value <TAB> return ret, old_value",if ret :,106
4861,"def remove(self, url): <TAB> try: <TAB>  <TAB> i = self.items.index(url) <TAB> except (ValueError, IndexError): <TAB>  <TAB> pass <TAB> else: <TAB>  <TAB> was_selected = i in self.selectedindices() <TAB>  <TAB> self.list.delete(i) <TAB>  <TAB> del self.items[i] <TAB>  <TAB> if not self.items: <TAB>  <TAB>  <TAB> self.mp.hidepanel(self.name) <MASK> if i >= len(self.items): <TAB>  <TAB>  <TAB>  <TAB> i = len(self.items) - 1 <TAB>  <TAB>  <TAB> self.list.select_set(i)",elif was_selected :,150
4862,"def add_directory_csv_files(dir_path, paths=None): <TAB> if not paths: <TAB>  <TAB> paths = [] <TAB> for p in listdir(dir_path): <TAB>  <TAB> path = join(dir_path, p) <MASK> # call recursively for each dir <TAB>  <TAB>  <TAB> paths = add_directory_csv_files(path, paths) <TAB>  <TAB> elif isfile(path) and path.endswith("".csv""): <TAB>  <TAB>  <TAB> # add every file to the list <TAB>  <TAB>  <TAB> paths.append(path) <TAB> return paths",if isdir ( path ) :,130
4863,"def _get_client(rp_mapping, resource_provider): <TAB> for key, value in rp_mapping.items(): <MASK> if isinstance(value, dict): <TAB>  <TAB>  <TAB>  <TAB> return GeneralPrivateEndpointClient( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> key, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value[""api_version""], <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value[""support_list_or_not""], <TAB>  <TAB>  <TAB>  <TAB>  <TAB> value[""resource_get_api_version""], <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return value() <TAB> raise CLIError( <TAB>  <TAB> ""Resource type must be one of {}"".format("", "".join(rp_mapping.keys())) <TAB> )",if str . lower ( key ) == str . lower ( resource_provider ) :,165
4864,"def compute_rule_hash(self, rule): <TAB> buf = ""%d-%d-%s-"" % ( <TAB>  <TAB> rule.get(""FromPort"", 0) or 0, <TAB>  <TAB> rule.get(""ToPort"", 0) or 0, <TAB>  <TAB> rule.get(""IpProtocol"", ""-1"") or ""-1"", <TAB> ) <TAB> for a, ke in self.RULE_ATTRS: <MASK> continue <TAB>  <TAB> ev = [e[ke] for e in rule[a]] <TAB>  <TAB> ev.sort() <TAB>  <TAB> for e in ev: <TAB>  <TAB>  <TAB> buf += ""%s-"" % e <TAB> # mask to generate the same numeric value across all Python versions <TAB> return zlib.crc32(buf.encode(""ascii"")) & 0xFFFFFFFF",if a not in rule :,176
4865,"def analysis_sucess_metrics(analysis_time: float, allow_exception=False): <TAB> try: <TAB>  <TAB> anchore_engine.subsys.metrics.counter_inc(name=""anchore_analysis_success"") <TAB>  <TAB> anchore_engine.subsys.metrics.histogram_observe( <TAB>  <TAB>  <TAB> ""anchore_analysis_time_seconds"", <TAB>  <TAB>  <TAB> analysis_time, <TAB>  <TAB>  <TAB> buckets=ANALYSIS_TIME_SECONDS_BUCKETS, <TAB>  <TAB>  <TAB> status=""success"", <TAB>  <TAB> ) <TAB> except: <MASK> raise <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logger.exception( <TAB>  <TAB>  <TAB>  <TAB> ""Unexpected exception during metrics update for a successful analysis. Swallowing error and continuing"" <TAB>  <TAB>  <TAB> )",if allow_exception :,179
4866,"def decide_file_icon(file): <TAB> if file.state == File.ERROR: <TAB>  <TAB> return FileItem.icon_error <TAB> elif isinstance(file.parent, Track): <MASK> return FileItem.icon_saved <TAB>  <TAB> elif file.state == File.PENDING: <TAB>  <TAB>  <TAB> return FileItem.match_pending_icons[int(file.similarity * 5 + 0.5)] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return FileItem.match_icons[int(file.similarity * 5 + 0.5)] <TAB> elif file.state == File.PENDING: <TAB>  <TAB> return FileItem.icon_file_pending <TAB> else: <TAB>  <TAB> return FileItem.icon_file",if file . state == File . NORMAL :,169
4867,"def deleteMenu(self, menuName): <TAB> try: <TAB>  <TAB> menu = self.getMenu(menuName) <MASK> self.destroy(menu) <TAB>  <TAB>  <TAB> self.destroyMenu(menuName) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> g.es(""can't delete menu:"", menuName) <TAB> except Exception: <TAB>  <TAB> g.es(""exception deleting"", menuName, ""menu"") <TAB>  <TAB> g.es_exception()",if menu :,106
4868,"def parser(cls, buf): <TAB> (type_, code, csum) = struct.unpack_from(cls._PACK_STR, buf) <TAB> msg = cls(type_, code, csum) <TAB> offset = cls._MIN_LEN <TAB> if len(buf) > offset: <TAB>  <TAB> cls_ = cls._ICMPV6_TYPES.get(type_, None) <MASK> msg.data = cls_.parser(buf, offset) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> msg.data = buf[offset:] <TAB> return msg, None, None",if cls_ :,133
4869,"def _load_dataset_area(self, dsid, file_handlers, coords): <TAB> """"""Get the area for *dsid*."""""" <TAB> try: <TAB>  <TAB> return self._load_area_def(dsid, file_handlers) <TAB> except NotImplementedError: <TAB>  <TAB> if any(x is None for x in coords): <TAB>  <TAB>  <TAB> logger.warning(""Failed to load coordinates for '{}'"".format(dsid)) <TAB>  <TAB>  <TAB> return None <TAB>  <TAB> area = self._make_area_from_coords(coords) <MASK> logger.debug(""No coordinates found for %s"", str(dsid)) <TAB>  <TAB> return area",if area is None :,148
4870,"def __getattr__(self, name): <TAB> if Popen.verbose: <TAB>  <TAB> sys.stdout.write(""Getattr: %s..."" % name) <TAB> if name in Popen.__slots__: <TAB>  <TAB> return object.__getattribute__(self, name) <TAB> else: <TAB>  <TAB> if self.popen is not None: <TAB>  <TAB>  <TAB> if Popen.verbose: <TAB>  <TAB>  <TAB>  <TAB> print(""from Popen"") <TAB>  <TAB>  <TAB> return getattr(self.popen, name) <TAB>  <TAB> else: <MASK> return self.emu_wait <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise Exception(""subprocess emulation: not implemented: %s"" % name)","if name == ""wait"" :",156
4871,"def update(self, time_delta): <TAB> super().update(time_delta) <TAB> n = self.menu.selected_option <TAB> if n == self.last: <TAB>  <TAB> return <TAB> self.last = n <TAB> s = """" <TAB> for i in range(len(self.files)): <MASK> for l in open(self.files[i][1]): <TAB>  <TAB>  <TAB>  <TAB> x = l.strip() <TAB>  <TAB>  <TAB>  <TAB> if len(x) > 1 and x[0] == ""#"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> x = ""<b><u>"" + x[1:] + "" </u></b>"" <TAB>  <TAB>  <TAB>  <TAB> s += x + ""<br>"" <TAB> self.set_text(s)",if self . files [ i ] [ 0 ] == n :,178
4872,"def wrapper(*args, **kwargs): <TAB> list_args, empty = _apply_defaults(func, args, kwargs) <TAB> if len(dimensions) > len(list_args): <TAB>  <TAB> raise TypeError( <TAB>  <TAB>  <TAB> ""%s takes %i parameters, but %i dimensions were passed"" <TAB>  <TAB>  <TAB> % (func.__name__, len(list_args), len(dimensions)) <TAB>  <TAB> ) <TAB> for dim, value in zip(dimensions, list_args): <TAB>  <TAB> if dim is None: <TAB>  <TAB>  <TAB> continue <MASK> val_dim = ureg.get_dimensionality(value) <TAB>  <TAB>  <TAB> raise DimensionalityError(value, ""a quantity of"", val_dim, dim) <TAB> return func(*args, **kwargs)",if not ureg . Quantity ( value ) . check ( dim ) :,182
4873,"def _check(self, name, size=None, *extra): <TAB> func = getattr(imageop, name) <TAB> for height in VALUES: <TAB>  <TAB> for width in VALUES: <TAB>  <TAB>  <TAB> strlen = abs(width * height) <TAB>  <TAB>  <TAB> if size: <TAB>  <TAB>  <TAB>  <TAB> strlen *= size <MASK> data = ""A"" * strlen <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> data = AAAAA <TAB>  <TAB>  <TAB> if size: <TAB>  <TAB>  <TAB>  <TAB> arguments = (data, size, width, height) + extra <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> arguments = (data, width, height) + extra <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> func(*arguments) <TAB>  <TAB>  <TAB> except (ValueError, imageop.error): <TAB>  <TAB>  <TAB>  <TAB> pass",if strlen < MAX_LEN :,188
4874,"def wait_send_all_might_not_block(self) -> None: <TAB> with self._send_conflict_detector: <MASK> raise trio.ClosedResourceError(""file was already closed"") <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> await trio.lowlevel.wait_writable(self._fd_holder.fd) <TAB>  <TAB> except BrokenPipeError as e: <TAB>  <TAB>  <TAB> # kqueue: raises EPIPE on wait_writable instead <TAB>  <TAB>  <TAB> # of sending, which is annoying <TAB>  <TAB>  <TAB> raise trio.BrokenResourceError from e",if self . _fd_holder . closed :,135
4875,"def parse_win_proxy(val): <TAB> proxies = [] <TAB> for p in val.split("";""): <TAB>  <TAB> if ""="" in p: <TAB>  <TAB>  <TAB> tab = p.split(""="", 1) <MASK> tab[0] = ""SOCKS4"" <TAB>  <TAB>  <TAB> proxies.append( <TAB>  <TAB>  <TAB>  <TAB> (tab[0].upper(), tab[1], None, None) <TAB>  <TAB>  <TAB> )  # type, addr:port, username, password <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> proxies.append((""HTTP"", p, None, None)) <TAB> return proxies","if tab [ 0 ] == ""socks"" :",142
4876,"def _super_function(args): <TAB> passed_class, passed_self = args.get_arguments([""type"", ""self""]) <TAB> if passed_self is None: <TAB>  <TAB> return passed_class <TAB> else: <TAB>  <TAB> # pyclass = passed_self.get_type() <TAB>  <TAB> pyclass = passed_class <TAB>  <TAB> if isinstance(pyclass, pyobjects.AbstractClass): <TAB>  <TAB>  <TAB> supers = pyclass.get_superclasses() <MASK> return pyobjects.PyObject(supers[0]) <TAB>  <TAB> return passed_self",if supers :,132
4877,"def update_output_mintime(job): <TAB> try: <TAB>  <TAB> return output_mintime[job] <TAB> except KeyError: <TAB>  <TAB> for job_ in chain([job], self.depending[job]): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> t = output_mintime[job_] <TAB>  <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB>  <TAB> t = job_.output_mintime <MASK> output_mintime[job] = t <TAB>  <TAB>  <TAB>  <TAB> return <TAB>  <TAB> output_mintime[job] = None",if t is not None :,136
4878,"def get_list_of_strings_to_mongo_objects(self, notifications_list=None): <TAB> result = [] <TAB> if len(notifications_list) > 0: <TAB>  <TAB> for x in notifications_list: <TAB>  <TAB>  <TAB> split_provider_id = x.split("":"")  # email:id <TAB>  <TAB>  <TAB> if len(split_provider_id) == 2: <TAB>  <TAB>  <TAB>  <TAB> _id = split_provider_id[1] <TAB>  <TAB>  <TAB>  <TAB> cursor = self.get_by_id(_id) <MASK> # Append if exists <TAB>  <TAB>  <TAB>  <TAB>  <TAB> result.append(cursor) <TAB> return result",if cursor :,148
4879,"def stop(self): <TAB> with self.lock: <MASK> return <TAB>  <TAB> self.task_queue.put(None) <TAB>  <TAB> self.result_queue.put(None) <TAB>  <TAB> process = self.process <TAB>  <TAB> self.process = None <TAB>  <TAB> self.task_queue = None <TAB>  <TAB> self.result_queue = None <TAB> process.join(timeout=0.1) <TAB> if process.exitcode is None: <TAB>  <TAB> os.kill(process.pid, signal.SIGKILL) <TAB>  <TAB> process.join()",if not self . process :,132
4880,"def on_api_command(self, command, data): <TAB> if command == ""select"": <TAB>  <TAB> if not Permissions.PLUGIN_ACTION_COMMAND_PROMPT_INTERACT.can(): <TAB>  <TAB>  <TAB> return flask.abort(403, ""Insufficient permissions"") <MASK> return flask.abort(409, ""No active prompt"") <TAB>  <TAB> choice = data[""choice""] <TAB>  <TAB> if not isinstance(choice, int) or not self._prompt.validate_choice(choice): <TAB>  <TAB>  <TAB> return flask.abort( <TAB>  <TAB>  <TAB>  <TAB> 400, ""{!r} is not a valid value for choice"".format(choice) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> self._answer_prompt(choice)",if self . _prompt is None :,164
4881,"def application_openFiles_(self, nsapp, filenames): <TAB> # logging.info('[osx] file open') <TAB> # logging.info('[osx] file : %s' % (filenames)) <TAB> for filename in filenames: <TAB>  <TAB> logging.info(""[osx] receiving from macOS : %s"", filename) <MASK> if sabnzbd.filesystem.get_ext(filename) in VALID_ARCHIVES + VALID_NZB_FILES: <TAB>  <TAB>  <TAB>  <TAB> sabnzbd.add_nzbfile(filename, keep=True)",if os . path . exists ( filename ) :,136
4882,"def test_error_through_destructor(self): <TAB> # Test that the exception state is not modified by a destructor, <TAB> # even if close() fails. <TAB> rawio = self.CloseFailureIO() <TAB> with support.catch_unraisable_exception() as cm: <TAB>  <TAB> with self.assertRaises(AttributeError): <TAB>  <TAB>  <TAB> self.tp(rawio).xyzzy <MASK> self.assertIsNone(cm.unraisable) <TAB>  <TAB> elif cm.unraisable is not None: <TAB>  <TAB>  <TAB> self.assertEqual(cm.unraisable.exc_type, OSError)",if not IOBASE_EMITS_UNRAISABLE :,157
4883,"def http_wrapper(self, url, postdata={}): <TAB> try: <MASK> f = urllib.urlopen(url, postdata) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> f = urllib.urlopen(url) <TAB>  <TAB> response = f.read() <TAB> except: <TAB>  <TAB> import traceback <TAB>  <TAB> import logging, sys <TAB>  <TAB> cla, exc, tb = sys.exc_info() <TAB>  <TAB> logging.error(url) <TAB>  <TAB> if postdata: <TAB>  <TAB>  <TAB> logging.error(""with post data"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logging.error(""without post data"") <TAB>  <TAB> logging.error(exc.args) <TAB>  <TAB> logging.error(traceback.format_tb(tb)) <TAB>  <TAB> response = """" <TAB> return response",if postdata != { } :,178
4884,"def check_single_file(fn, fetchuri): <TAB> """"""Determine if a single downloaded file is something we can't handle"""""" <TAB> with open(fn, ""r"", errors=""surrogateescape"") as f: <MASK> logger.error( <TAB>  <TAB>  <TAB>  <TAB> 'Fetching ""%s"" returned a single HTML page - check the URL is correct and functional' <TAB>  <TAB>  <TAB>  <TAB> % fetchuri <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> sys.exit(1)","if ""<html"" in f . read ( 100 ) . lower ( ) :",117
4885,"def update_properties(self, update_dict): <TAB> signed_attribute_changed = False <TAB> for k, value in update_dict.items(): <TAB>  <TAB> if getattr(self, k) != value: <TAB>  <TAB>  <TAB> setattr(self, k, value) <TAB>  <TAB>  <TAB> signed_attribute_changed = signed_attribute_changed or ( <TAB>  <TAB>  <TAB>  <TAB> k in self.payload_arguments <TAB>  <TAB>  <TAB> ) <TAB> if signed_attribute_changed: <MASK> self.status = UPDATED <TAB>  <TAB> self.timestamp = clock.tick() <TAB>  <TAB> self.sign() <TAB> return self",if self . status != NEW :,145
4886,"def clean_items(event, items, variations): <TAB> for item in items: <TAB>  <TAB> if event != item.event: <TAB>  <TAB>  <TAB> raise ValidationError(_(""One or more items do not belong to this event."")) <TAB>  <TAB> if item.has_variations: <MASK> raise ValidationError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> _( <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""One or more items has variations but none of these are in the variations list."" <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> )",if not any ( var . item == item for var in variations ) :,127
4887,"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> length = d.getVarInt32() <TAB>  <TAB>  <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB>  <TAB>  <TAB> d.skip(length) <TAB>  <TAB>  <TAB> self.add_status().TryMerge(tmp) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if tt == 18: <TAB>  <TAB>  <TAB> self.add_doc_id(d.getPrefixedString()) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,169
4888,"def connections(self): <TAB> # Connections look something like this: <TAB> # socket:[102422] <TAB> fds = self.open_files <TAB> socket = ""socket:["" <TAB> result = [] <TAB> functions = [pwndbg.net.tcp, pwndbg.net.unix, pwndbg.net.netlink] <TAB> for fd, path in fds.items(): <TAB>  <TAB> if socket not in path: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> inode = path[len(socket) : -1] <TAB>  <TAB> inode = int(inode) <TAB>  <TAB> for func in functions: <TAB>  <TAB>  <TAB> for x in func(): <MASK> x.fd = fd <TAB>  <TAB>  <TAB>  <TAB>  <TAB> result.append(x) <TAB> return tuple(result)",if x . inode == inode :,184
4889,"def _movement_finished(self): <TAB> if self.in_ship_map: <TAB>  <TAB> # if the movement somehow stops, the position sticks, and the unit isn't at next_target any more <MASK> ship = self.session.world.ship_map.get(self._next_target.to_tuple()) <TAB>  <TAB>  <TAB> if ship is not None and ship() is self: <TAB>  <TAB>  <TAB>  <TAB> del self.session.world.ship_map[self._next_target.to_tuple()] <TAB> super()._movement_finished()",if self . _next_target is not None :,136
4890,"def print_addresses(self): <TAB> p = 3 <TAB> tmp_str = ""["" <TAB> if self.get_len() >= 7:  # at least one complete IP address <TAB>  <TAB> while 1: <TAB>  <TAB>  <TAB> if p + 1 == self.get_ptr(): <TAB>  <TAB>  <TAB>  <TAB> tmp_str += ""#"" <TAB>  <TAB>  <TAB> tmp_str += self.get_ip_address(p) <TAB>  <TAB>  <TAB> p += 4 <MASK> break <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> tmp_str += "", "" <TAB> tmp_str += ""] "" <TAB> if self.get_ptr() % 4:  # ptr field should be a multiple of 4 <TAB>  <TAB> tmp_str += ""nonsense ptr field: %d "" % self.get_ptr() <TAB> return tmp_str",if p >= self . get_len ( ) :,191
4891,"def source_shapes(self): <TAB> """"""Prints debug information about the sources in this provider."""""" <TAB> if logger.isEnabledFor(logging.DEBUG): <TAB>  <TAB> for i, source in enumerate(self.sources): <MASK> name = ""anonymous"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> name = self.keys[i] <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> shape = source.shape() <TAB>  <TAB>  <TAB> except NotImplementedError: <TAB>  <TAB>  <TAB>  <TAB> shape = ""N/A"" <TAB>  <TAB>  <TAB> logger.debug( <TAB>  <TAB>  <TAB>  <TAB> 'Data source ""%s"": entries=%s, shape=%s', name, len(source), shape <TAB>  <TAB>  <TAB> )",if self . keys is None :,161
4892,def swap_actions(actions): <TAB> for mutexgroup in mutex_groups: <TAB>  <TAB> mutex_actions = mutexgroup._group_actions <MASK> # make a best guess as to where we should store the group <TAB>  <TAB>  <TAB> targetindex = actions.index(mutexgroup._group_actions[0]) <TAB>  <TAB>  <TAB> # insert the _ArgumentGroup container <TAB>  <TAB>  <TAB> actions[targetindex] = mutexgroup <TAB>  <TAB>  <TAB> # remove the duplicated individual actions <TAB>  <TAB>  <TAB> actions = [action for action in actions if action not in mutex_actions] <TAB> return actions,"if contains_actions ( mutex_actions , actions ) :",147
4893,"def rec_deps(services, container_by_name, cnt, init_service): <TAB> deps = cnt[""_deps""] <TAB> for dep in deps.copy(): <TAB>  <TAB> dep_cnts = services.get(dep) <TAB>  <TAB> if not dep_cnts: <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> dep_cnt = container_by_name.get(dep_cnts[0]) <TAB>  <TAB> if dep_cnt: <TAB>  <TAB>  <TAB> # TODO: avoid creating loops, A->B->A <MASK> continue <TAB>  <TAB>  <TAB> new_deps = rec_deps(services, container_by_name, dep_cnt, init_service) <TAB>  <TAB>  <TAB> deps.update(new_deps) <TAB> return deps","if init_service and init_service in dep_cnt [ ""_deps"" ] :",181
4894,"def make_dump_list_by_name_list(name_list): <TAB> info_list = [] <TAB> for info_name in name_list: <TAB>  <TAB> info = next((x for x in DUMP_LIST if x.info_name == info_name), None) <MASK> raise RuntimeError('Unknown info name: ""{}""'.format(info_name)) <TAB>  <TAB> info_list.append(info) <TAB> return info_list",if not info :,106
4895,"def create(self, private=False): <TAB> try: <TAB>  <TAB> if private: <TAB>  <TAB>  <TAB> log.info(""Creating private channel %s."", self) <TAB>  <TAB>  <TAB> self._bot.api_call( <TAB>  <TAB>  <TAB>  <TAB> ""conversations.create"", data={""name"": self.name, ""is_private"": True} <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> log.info(""Creating channel %s."", self) <TAB>  <TAB>  <TAB> self._bot.api_call(""conversations.create"", data={""name"": self.name}) <TAB> except SlackAPIResponseError as e: <MASK> raise RoomError(f""Unable to create channel. {USER_IS_BOT_HELPTEXT}"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise RoomError(e)","if e . error == ""user_is_bot"" :",189
4896,"def talk(self, words): <TAB> if self.writeSentence(words) == 0: <TAB>  <TAB> return <TAB> r = [] <TAB> while 1: <TAB>  <TAB> i = self.readSentence() <MASK> continue <TAB>  <TAB> reply = i[0] <TAB>  <TAB> attrs = {} <TAB>  <TAB> for w in i[1:]: <TAB>  <TAB>  <TAB> j = w.find(""="", 1) <TAB>  <TAB>  <TAB> if j == -1: <TAB>  <TAB>  <TAB>  <TAB> attrs[w] = """" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> attrs[w[:j]] = w[j + 1 :] <TAB>  <TAB> r.append((reply, attrs)) <TAB>  <TAB> if reply == ""!done"": <TAB>  <TAB>  <TAB> return r",if len ( i ) == 0 :,169
4897,"def _load_logfile(self, lfn): <TAB> enc_key = self.decryption_key_func() <TAB> with open(os.path.join(self.logdir, lfn)) as fd: <MASK> with DecryptingStreamer( <TAB>  <TAB>  <TAB>  <TAB> fd, mep_key=enc_key, name=""EventLog/DS(%s)"" % lfn <TAB>  <TAB>  <TAB> ) as streamer: <TAB>  <TAB>  <TAB>  <TAB> lines = streamer.read() <TAB>  <TAB>  <TAB>  <TAB> streamer.verify(_raise=IOError) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> lines = fd.read() <TAB>  <TAB> if lines: <TAB>  <TAB>  <TAB> for line in lines.splitlines(): <TAB>  <TAB>  <TAB>  <TAB> event = Event.Parse(line.strip()) <TAB>  <TAB>  <TAB>  <TAB> self._events[event.event_id] = event",if enc_key :,191
4898,"def set_ok_port(self, cookie, request): <TAB> if cookie.port_specified: <TAB>  <TAB> req_port = request_port(request) <TAB>  <TAB> if req_port is None: <TAB>  <TAB>  <TAB> req_port = ""80"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> req_port = str(req_port) <TAB>  <TAB> for p in cookie.port.split("",""): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> int(p) <TAB>  <TAB>  <TAB> except ValueError: <TAB>  <TAB>  <TAB>  <TAB> debug(""   bad port %s (not numeric)"", p) <TAB>  <TAB>  <TAB>  <TAB> return False <MASK> break <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> debug(""   request port (%s) not found in %s"", req_port, cookie.port) <TAB>  <TAB>  <TAB> return False <TAB> return True",if p == req_port :,195
4899,"def get_attribute_value(self, nodeid, attr): <TAB> with self._lock: <TAB>  <TAB> self.logger.debug(""get attr val: %s %s"", nodeid, attr) <MASK> dv = ua.DataValue() <TAB>  <TAB>  <TAB> dv.StatusCode = ua.StatusCode(ua.StatusCodes.BadNodeIdUnknown) <TAB>  <TAB>  <TAB> return dv <TAB>  <TAB> node = self._nodes[nodeid] <TAB>  <TAB> if attr not in node.attributes: <TAB>  <TAB>  <TAB> dv = ua.DataValue() <TAB>  <TAB>  <TAB> dv.StatusCode = ua.StatusCode(ua.StatusCodes.BadAttributeIdInvalid) <TAB>  <TAB>  <TAB> return dv <TAB>  <TAB> attval = node.attributes[attr] <TAB>  <TAB> if attval.value_callback: <TAB>  <TAB>  <TAB> return attval.value_callback() <TAB>  <TAB> return attval.value",if nodeid not in self . _nodes :,200
4900,"def data_logging_status(self, trail_name, trail_details, api_client): <TAB> for es in api_client.get_event_selectors(TrailName=trail_name)[""EventSelectors""]: <TAB>  <TAB> has_wildcard = { <TAB>  <TAB>  <TAB> u""Values"": [u""arn:aws:s3:::""], <TAB>  <TAB>  <TAB> u""Type"": u""AWS::S3::Object"", <TAB>  <TAB> } in es[""DataResources""] <TAB>  <TAB> is_logging = trail_details[""IsLogging""] <MASK> return True <TAB> return False",if has_wildcard and is_logging and self . is_fresh ( trail_details ) :,149
4901,"def pytest_deselected(items): <TAB> if sb_config.dashboard: <TAB>  <TAB> sb_config.item_count -= len(items) <TAB>  <TAB> for item in items: <TAB>  <TAB>  <TAB> test_id, display_id = _get_test_ids_(item) <MASK> sb_config._results.pop(test_id)",if test_id in sb_config . _results . keys ( ) :,96
4902,"def _visit(self, func): <TAB> fname = func[0] <TAB> if fname in self._flags: <TAB>  <TAB> if self._flags[fname] == 1: <TAB>  <TAB>  <TAB> logger.critical(""Fatal error! network ins not Dag."") <TAB>  <TAB>  <TAB> import sys <TAB>  <TAB>  <TAB> sys.exit(-1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return <TAB> else: <TAB>  <TAB> if fname not in self._flags: <TAB>  <TAB>  <TAB> self._flags[fname] = 1 <TAB>  <TAB> for output in func[3]: <TAB>  <TAB>  <TAB> for f in self._orig: <TAB>  <TAB>  <TAB>  <TAB> for input in f[2]: <MASK> self._visit(f) <TAB> self._flags[fname] = 2 <TAB> self._sorted.insert(0, func)",if output == input :,188
4903,"def printWiki(): <TAB> firstHeading = False <TAB> for m in protocol: <MASK> if firstHeading: <TAB>  <TAB>  <TAB>  <TAB> output(""|}"") <TAB>  <TAB>  <TAB> __printWikiHeader(m[1], m[2]) <TAB>  <TAB>  <TAB> firstHeading = True <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> output(""|-"") <TAB>  <TAB>  <TAB> output( <TAB>  <TAB>  <TAB>  <TAB> '| <span style=""white-space:nowrap;""><tt>' <TAB>  <TAB>  <TAB>  <TAB> + m[0] <TAB>  <TAB>  <TAB>  <TAB> + ""</tt></span> || || "" <TAB>  <TAB>  <TAB>  <TAB> + m[1] <TAB>  <TAB>  <TAB> ) <TAB> output(""|}"")","if m [ 0 ] == """" :",155
4904,"def test_getitem(self): <TAB> n = 200 <TAB> d = deque(range(n)) <TAB> l = list(range(n)) <TAB> for i in range(n): <TAB>  <TAB> d.popleft() <TAB>  <TAB> l.pop(0) <MASK> d.append(i) <TAB>  <TAB>  <TAB> l.append(i) <TAB>  <TAB> for j in range(1 - len(l), len(l)): <TAB>  <TAB>  <TAB> assert d[j] == l[j] <TAB> d = deque(""superman"") <TAB> self.assertEqual(d[0], ""s"") <TAB> self.assertEqual(d[-1], ""n"") <TAB> d = deque() <TAB> self.assertRaises(IndexError, d.__getitem__, 0) <TAB> self.assertRaises(IndexError, d.__getitem__, -1)",if random . random ( ) < 0.5 :,193
4905,"def get_num(line, char_ptr, num_chars): <TAB> char_ptr = char_ptr + 1 <TAB> numstr = """" <TAB> good = ""-.0123456789"" <TAB> while char_ptr < num_chars: <TAB>  <TAB> digit = line[char_ptr] <MASK> numstr = numstr + digit <TAB>  <TAB>  <TAB> char_ptr = char_ptr + 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> break <TAB> return numstr",if good . find ( digit ) != - 1 :,116
4906,"def read_digits(source, start, first_code): <TAB> body = source.body <TAB> position = start <TAB> code = first_code <TAB> if code is not None and 48 <= code <= 57:  # 0 - 9 <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> position += 1 <TAB>  <TAB>  <TAB> code = char_code_at(body, position) <MASK> break <TAB>  <TAB> return position <TAB> raise GraphQLSyntaxError( <TAB>  <TAB> source, <TAB>  <TAB> position, <TAB>  <TAB> u""Invalid number, expected digit but got: {}."".format(print_char_code(code)), <TAB> )",if not ( code is not None and 48 <= code <= 57 ) :,155
4907,"def get_aws_metadata(headers, provider=None): <TAB> if not provider: <TAB>  <TAB> provider = boto.provider.get_default() <TAB> metadata_prefix = provider.metadata_prefix <TAB> metadata = {} <TAB> for hkey in headers.keys(): <MASK> val = urllib.unquote_plus(headers[hkey]) <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> metadata[hkey[len(metadata_prefix) :]] = unicode(val, ""utf-8"") <TAB>  <TAB>  <TAB> except UnicodeDecodeError: <TAB>  <TAB>  <TAB>  <TAB> metadata[hkey[len(metadata_prefix) :]] = val <TAB>  <TAB>  <TAB> del headers[hkey] <TAB> return metadata",if hkey . lower ( ) . startswith ( metadata_prefix ) :,164
4908,"def _process_rtdest(self): <TAB> LOG.debug(""Processing RT NLRI destination..."") <TAB> if self._rtdest_queue.is_empty(): <TAB>  <TAB> return <TAB> else: <TAB>  <TAB> processed_any = False <TAB>  <TAB> while not self._rtdest_queue.is_empty(): <TAB>  <TAB>  <TAB> # We process the first destination in the queue. <TAB>  <TAB>  <TAB> next_dest = self._rtdest_queue.pop_first() <TAB>  <TAB>  <TAB> if next_dest: <TAB>  <TAB>  <TAB>  <TAB> next_dest.process() <TAB>  <TAB>  <TAB>  <TAB> processed_any = True <MASK> # Since RT destination were updated we update RT filters <TAB>  <TAB>  <TAB> self._core_service.update_rtfilters()",if processed_any :,171
4909,"def _get_header(self, requester, header_name): <TAB> hits = sum([header_name in headers for _, headers in requester.requests]) <TAB> self.assertEquals(hits, 2 if self.revs_enabled else 1) <TAB> for url, headers in requester.requests: <TAB>  <TAB> if header_name in headers: <MASK> self.assertTrue(url.endswith(""/latest""), msg=url) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.assertTrue(url.endswith(""/download_urls""), msg=url) <TAB>  <TAB>  <TAB> return headers.get(header_name)",if self . revs_enabled :,143
4910,"def add_external_deps(self, deps): <TAB> for dep in deps: <TAB>  <TAB> if hasattr(dep, ""el""): <TAB>  <TAB>  <TAB> dep = dep.el <MASK> raise InvalidArguments(""Argument is not an external dependency"") <TAB>  <TAB> self.external_deps.append(dep) <TAB>  <TAB> if isinstance(dep, dependencies.Dependency): <TAB>  <TAB>  <TAB> self.process_sourcelist(dep.get_sources())","if not isinstance ( dep , dependencies . Dependency ) :",109
4911,"def _consume_msg(self): <TAB> ws = self._ws <TAB> try: <TAB>  <TAB> while True: <TAB>  <TAB>  <TAB> r = await ws.recv() <TAB>  <TAB>  <TAB> if isinstance(r, bytes): <TAB>  <TAB>  <TAB>  <TAB> r = r.decode(""utf-8"") <TAB>  <TAB>  <TAB> msg = json.loads(r) <TAB>  <TAB>  <TAB> stream = msg.get(""stream"") <MASK> await self._dispatch(stream, msg) <TAB> except websockets.WebSocketException as wse: <TAB>  <TAB> logging.warn(wse) <TAB>  <TAB> await self.close() <TAB>  <TAB> asyncio.ensure_future(self._ensure_ws())",if stream is not None :,158
4912,"def generate_and_check_random(): <TAB> random_size = 256 <TAB> while True: <TAB>  <TAB> random = os.urandom(random_size) <TAB>  <TAB> a = int.from_bytes(random, ""big"") <TAB>  <TAB> A = pow(g, a, p) <MASK> a_for_hash = big_num_for_hash(A) <TAB>  <TAB>  <TAB> u = int.from_bytes(sha256(a_for_hash, b_for_hash), ""big"") <TAB>  <TAB>  <TAB> if u > 0: <TAB>  <TAB>  <TAB>  <TAB> return (a, a_for_hash, u)","if is_good_mod_exp_first ( A , p ) :",158
4913,"def write(self, datagram, address): <TAB> """"""Write a datagram."""""" <TAB> try: <TAB>  <TAB> return self.socket.sendto(datagram, address) <TAB> except OSError as se: <TAB>  <TAB> no = se.args[0] <TAB>  <TAB> if no == EINTR: <TAB>  <TAB>  <TAB> return self.write(datagram, address) <TAB>  <TAB> elif no == EMSGSIZE: <TAB>  <TAB>  <TAB> raise error.MessageLengthError(""message too long"") <MASK> # oh, well, drop the data. The only difference from UDP <TAB>  <TAB>  <TAB> # is that UDP won't ever notice. <TAB>  <TAB>  <TAB> # TODO: add TCP-like buffering <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise",elif no == EAGAIN :,176
4914,"def doDir(elem): <TAB> for child in elem.childNodes: <MASK> continue <TAB>  <TAB> if child.tagName == ""Directory"": <TAB>  <TAB>  <TAB> doDir(child) <TAB>  <TAB> elif child.tagName == ""Component"": <TAB>  <TAB>  <TAB> for grandchild in child.childNodes: <TAB>  <TAB>  <TAB>  <TAB> if not isinstance(grandchild, minidom.Element): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB>  <TAB> if grandchild.tagName != ""File"": <TAB>  <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB>  <TAB>  <TAB> files.add(grandchild.getAttribute(""Source"").replace(os.sep, ""/""))","if not isinstance ( child , minidom . Element ) :",152
4915,"def add_reversed_tensor(i, X, reversed_X): <TAB> # Do not keep tensors that should stop the mapping. <TAB> if X in stop_mapping_at_tensors: <TAB>  <TAB> return <TAB> if X not in reversed_tensors: <TAB>  <TAB> reversed_tensors[X] = {""id"": (nid, i), ""tensor"": reversed_X} <TAB> else: <TAB>  <TAB> tmp = reversed_tensors[X] <TAB>  <TAB> if ""tensor"" in tmp and ""tensors"" in tmp: <TAB>  <TAB>  <TAB> raise Exception(""Wrong order, tensors already aggregated!"") <MASK> tmp[""tensors""] = [tmp[""tensor""], reversed_X] <TAB>  <TAB>  <TAB> del tmp[""tensor""] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tmp[""tensors""].append(reversed_X)","if ""tensor"" in tmp :",183
4916,"def walk(source, path, default, delimiter="".""): <TAB> """"""Walk the sourch hash given the path and return the value or default if not found"""""" <TAB> if not isinstance(source, dict): <TAB>  <TAB> raise RuntimeError( <TAB>  <TAB>  <TAB> ""The source is not a walkable dict: {} path: {}"".format(source, path) <TAB>  <TAB> ) <TAB> keys = path.split(delimiter) <TAB> max_depth = len(keys) <TAB> cur_depth = 0 <TAB> while cur_depth < max_depth: <MASK> source = source[keys[cur_depth]] <TAB>  <TAB>  <TAB> cur_depth = cur_depth + 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return default <TAB> return source",if keys [ cur_depth ] in source :,171
4917,"def _from_txt_get_vulns(self): <TAB> file_vulns = [] <TAB> vuln_regex = ( <TAB>  <TAB> 'SQL injection in a .*? was found at: ""(.*?)""' <TAB>  <TAB> ', using HTTP method (.*?). The sent .*?data was: ""(.*?)""' <TAB> ) <TAB> vuln_re = re.compile(vuln_regex) <TAB> for line in file(self.OUTPUT_FILE): <TAB>  <TAB> mo = vuln_re.search(line) <MASK> v = MockVuln(""TestCase"", None, ""High"", 1, ""plugin"") <TAB>  <TAB>  <TAB> v.set_url(URL(mo.group(1))) <TAB>  <TAB>  <TAB> v.set_method(mo.group(2)) <TAB>  <TAB>  <TAB> file_vulns.append(v) <TAB> return file_vulns",if mo :,194
4918,"def __get__(self, instance, instance_type=None): <TAB> if instance: <TAB>  <TAB> if self.att_name not in instance._obj_cache: <TAB>  <TAB>  <TAB> rel_obj = self.get_obj(instance) <MASK> instance._obj_cache[self.att_name] = rel_obj <TAB>  <TAB> return instance._obj_cache.get(self.att_name) <TAB> return self",if rel_obj :,105
4919,"def get_ranges_from_func_set(support_set): <TAB> pos_start = 0 <TAB> pos_end = 0 <TAB> ranges = [] <TAB> for pos, func in enumerate(network.function): <MASK> pos_end = pos <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> if pos_end >= pos_start: <TAB>  <TAB>  <TAB>  <TAB> ranges.append((pos_start, pos_end)) <TAB>  <TAB>  <TAB> pos_start = pos + 1 <TAB> if pos_end >= pos_start: <TAB>  <TAB> ranges.append((pos_start, pos_end)) <TAB> return ranges",if func . type in support_set :,145
4920,"def get_all_active_plugins(self) -> List[BotPlugin]: <TAB> """"""This returns the list of plugins in the callback ordered defined from the config."""""" <TAB> all_plugins = [] <TAB> for name in self.plugins_callback_order: <TAB>  <TAB> # None is a placeholder for any plugin not having a defined order <TAB>  <TAB> if name is None: <TAB>  <TAB>  <TAB> all_plugins += [ <TAB>  <TAB>  <TAB>  <TAB> plugin <TAB>  <TAB>  <TAB>  <TAB> for name, plugin in self.plugins.items() <MASK> ] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> plugin = self.plugins[name] <TAB>  <TAB>  <TAB> if plugin.is_activated: <TAB>  <TAB>  <TAB>  <TAB> all_plugins.append(plugin) <TAB> return all_plugins",if name not in self . plugins_callback_order and plugin . is_activated,186
4921,"def render_token_list(self, tokens): <TAB> result = [] <TAB> vars = [] <TAB> for token in tokens: <MASK> result.append(token.contents.replace(""%"", ""%%"")) <TAB>  <TAB> elif token.token_type == TOKEN_VAR: <TAB>  <TAB>  <TAB> result.append(""%%(%s)s"" % token.contents) <TAB>  <TAB>  <TAB> vars.append(token.contents) <TAB> msg = """".join(result) <TAB> if self.trimmed: <TAB>  <TAB> msg = translation.trim_whitespace(msg) <TAB> return msg, vars",if token . token_type == TOKEN_TEXT :,139
4922,"def test_build_root_config_overwrite(self): <TAB> cfg = build_root_config(""tests.files.settings_overwrite"") <TAB> for key, val in DEFAULT_SPIDER_GLOBAL_CONFIG.items(): <MASK> self.assertEqual(cfg[""global""][key], [""zzz""]) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.assertEqual(cfg[""global""][key], val)","if key == ""spider_modules"" :",98
4923,"def get_limit(self, request): <TAB> if self.limit_query_param: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> limit = int(request.query_params[self.limit_query_param]) <TAB>  <TAB>  <TAB> if limit < 0: <TAB>  <TAB>  <TAB>  <TAB> raise ValueError() <TAB>  <TAB>  <TAB> # Enforce maximum page size, if defined <MASK> if limit == 0: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return settings.MAX_PAGE_SIZE <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return min(limit, settings.MAX_PAGE_SIZE) <TAB>  <TAB>  <TAB> return limit <TAB>  <TAB> except (KeyError, ValueError): <TAB>  <TAB>  <TAB> pass <TAB> return self.default_limit",if settings . MAX_PAGE_SIZE :,169
4924,"def track_handler(handler): <TAB> tid = handler.request.tid <TAB> for event in events_monitored: <MASK> e = Event(event, handler.request.execution_time) <TAB>  <TAB>  <TAB> State.tenant_state[tid].RecentEventQ.append(e) <TAB>  <TAB>  <TAB> State.tenant_state[tid].EventQ.append(e) <TAB>  <TAB>  <TAB> break","if event [ ""handler_check"" ] ( handler ) :",105
4925,"def TryMerge(self, d): <TAB> while d.avail() > 0: <TAB>  <TAB> tt = d.getVarInt32() <TAB>  <TAB> if tt == 10: <TAB>  <TAB>  <TAB> length = d.getVarInt32() <TAB>  <TAB>  <TAB> tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length) <TAB>  <TAB>  <TAB> d.skip(length) <TAB>  <TAB>  <TAB> self.add_subscription().TryMerge(tmp) <TAB>  <TAB>  <TAB> continue <MASK> raise ProtocolBuffer.ProtocolBufferDecodeError <TAB>  <TAB> d.skipData(tt)",if tt == 0 :,138
4926,"def GetCreateInstanceBinder(self, info): <TAB> with self._lock: <MASK> return self._createInstanceBinders[info] <TAB>  <TAB> b = runtime.SymplCreateInstanceBinder(info) <TAB>  <TAB> self._createInstanceBinders[info] = b <TAB> return b",if self . _createInstanceBinders . ContainsKey ( info ) :,83
4927,"def process_task(self, body, message): <TAB> if ""control"" in body: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return self.control(body, message) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> logger.exception(""Exception handling control message:"") <TAB>  <TAB>  <TAB> return <TAB> if len(self.pool): <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> queue = UUID(body[""uuid""]).int % len(self.pool) <TAB>  <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB>  <TAB> queue = self.total_messages % len(self.pool) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> queue = self.total_messages % len(self.pool) <TAB> else: <TAB>  <TAB> queue = 0 <TAB> self.pool.write(queue, body) <TAB> self.total_messages += 1 <TAB> message.ack()","if ""uuid"" in body and body [ ""uuid"" ] :",199
4928,"def is_defined_in_base_class(self, var: Var) -> bool: <TAB> if var.info: <TAB>  <TAB> for base in var.info.mro[1:]: <TAB>  <TAB>  <TAB> if base.get(var.name) is not None: <TAB>  <TAB>  <TAB>  <TAB> return True <MASK> return True <TAB> return False",if var . info . fallback_to_any :,90
4929,"def ant_map(m): <TAB> tmp = ""rows %s\ncols %s\n"" % (len(m), len(m[0])) <TAB> players = {} <TAB> for row in m: <TAB>  <TAB> tmp += ""m "" <TAB>  <TAB> for col in row: <TAB>  <TAB>  <TAB> if col == LAND: <TAB>  <TAB>  <TAB>  <TAB> tmp += ""."" <MASK> tmp += ""%"" <TAB>  <TAB>  <TAB> elif col == FOOD: <TAB>  <TAB>  <TAB>  <TAB> tmp += ""*"" <TAB>  <TAB>  <TAB> elif col == UNSEEN: <TAB>  <TAB>  <TAB>  <TAB> tmp += ""?"" <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> players[col] = True <TAB>  <TAB>  <TAB>  <TAB> tmp += chr(col + 97) <TAB>  <TAB> tmp += ""\n"" <TAB> tmp = (""players %s\n"" % len(players)) + tmp <TAB> return tmp",elif col == BARRIER :,199
4930,"def prompt_for_resume(config): <TAB> logger = logging.getLogger(""changeme"") <TAB> logger.error( <TAB>  <TAB> ""A previous scan was interrupted. Type R to resume or F to start a fresh scan"" <TAB> ) <TAB> answer = """" <TAB> while not (answer == ""R"" or answer == ""F""): <TAB>  <TAB> prompt = ""(R/F)> "" <TAB>  <TAB> answer = """" <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> answer = raw_input(prompt) <TAB>  <TAB> except NameError: <TAB>  <TAB>  <TAB> answer = input(prompt) <MASK> logger.debug(""Forcing a fresh scan"") <TAB>  <TAB> elif answer.upper() == ""R"": <TAB>  <TAB>  <TAB> logger.debug(""Resuming previous scan"") <TAB>  <TAB>  <TAB> config.resume = True <TAB> return config.resume","if answer . upper ( ) == ""F"" :",189
4931,"def f(view, s): <TAB> if mode == modes.INTERNAL_NORMAL: <MASK> if view.line(s.b).size() > 0: <TAB>  <TAB>  <TAB>  <TAB> eol = view.line(s.b).b <TAB>  <TAB>  <TAB>  <TAB> return R(s.b, eol) <TAB>  <TAB>  <TAB> return s <TAB> return s",if count == 1 :,85
4932,"def flush(self): <TAB> if not self.cuts: <TAB>  <TAB> return <TAB> for move, (x, y, z), cent in douglas(self.cuts, self.tolerance, self.plane): <MASK> self.write(""%s X%.4f Y%.4f Z%.4f %s"" % (move, x, y, z, cent)) <TAB>  <TAB>  <TAB> self.lastgcode = None <TAB>  <TAB>  <TAB> self.lastx = x <TAB>  <TAB>  <TAB> self.lasty = y <TAB>  <TAB>  <TAB> self.lastz = z <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.move_common(x, y, z, gcode=""G1"") <TAB> self.cuts = []",if cent :,167
4933,"def copy_shell(self): <TAB> cls = self.__class__ <TAB> old_id = cls.id <TAB> new_i = cls()  # create a new group <TAB> new_i.id = self.id  # with the same id <TAB> cls.id = old_id  # Reset the Class counter <TAB> # Copy all properties <TAB> for prop in cls.properties: <MASK> if self.has(prop): <TAB>  <TAB>  <TAB>  <TAB> val = getattr(self, prop) <TAB>  <TAB>  <TAB>  <TAB> setattr(new_i, prop, val) <TAB> # but no members <TAB> new_i.members = [] <TAB> return new_i","if prop is not ""members"" :",156
4934,"def find_region_by_value(key, value): <TAB> for region in cognitoidp_backends: <TAB>  <TAB> backend = cognitoidp_backends[region] <TAB>  <TAB> for user_pool in backend.user_pools.values(): <TAB>  <TAB>  <TAB> if key == ""client_id"" and value in user_pool.clients: <TAB>  <TAB>  <TAB>  <TAB> return region <MASK> return region <TAB> # If we can't find the `client_id` or `access_token`, we just pass <TAB> # back a default backend region, which will raise the appropriate <TAB> # error message (e.g. NotAuthorized or NotFound). <TAB> return list(cognitoidp_backends)[0]","if key == ""access_token"" and value in user_pool . access_tokens :",184
4935,"def __init__( <TAB> self, fixed: MQTTFixedHeader = None, variable_header: PacketIdVariableHeader = None): <TAB> if fixed is None: <TAB>  <TAB> header = MQTTFixedHeader(PUBREL, 0x02)  # [MQTT-3.6.1-1] <TAB> else: <MASK> raise HBMQTTException( <TAB>  <TAB>  <TAB>  <TAB> ""Invalid fixed packet type %s for PubrelPacket init"" % fixed.packet_type <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> header = fixed <TAB> super().__init__(header) <TAB> self.variable_header = variable_header <TAB> self.payload = None",if fixed . packet_type is not PUBREL :,163
4936,"def _on_event_MetadataStatisticsUpdated(self, event, data): <TAB> with self._selectedFileMutex: <MASK> self._setJobData( <TAB>  <TAB>  <TAB>  <TAB> self._selectedFile[""filename""], <TAB>  <TAB>  <TAB>  <TAB> self._selectedFile[""filesize""], <TAB>  <TAB>  <TAB>  <TAB> self._selectedFile[""sd""], <TAB>  <TAB>  <TAB>  <TAB> self._selectedFile[""user""], <TAB>  <TAB>  <TAB> )",if self . _selectedFile :,99
4937,"def _validate_parameter_range(self, value_hp, parameter_range): <TAB> """"""Placeholder docstring"""""" <TAB> for ( <TAB>  <TAB> parameter_range_key, <TAB>  <TAB> parameter_range_value, <TAB> ) in parameter_range.__dict__.items(): <MASK> continue <TAB>  <TAB> # Categorical ranges <TAB>  <TAB> if isinstance(parameter_range_value, list): <TAB>  <TAB>  <TAB> for categorical_value in parameter_range_value: <TAB>  <TAB>  <TAB>  <TAB> value_hp.validate(categorical_value) <TAB>  <TAB> # Continuous, Integer ranges <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> value_hp.validate(parameter_range_value)","if parameter_range_key == ""scaling_type"" :",159
4938,"def visit_filter_projection(self, node, value): <TAB> base = self.visit(node[""children""][0], value) <TAB> if not isinstance(base, list): <TAB>  <TAB> return None <TAB> comparator_node = node[""children""][2] <TAB> collected = [] <TAB> for element in base: <TAB>  <TAB> if self._is_true(self.visit(comparator_node, element)): <TAB>  <TAB>  <TAB> current = self.visit(node[""children""][1], element) <MASK> collected.append(current) <TAB> return collected",if current is not None :,132
4939,"def _getSubstrings(self, va, size, ltyp): <TAB> # rip through the desired memory range to populate any substrings <TAB> subs = set() <TAB> end = va + size <TAB> for offs in range(va, end, 1): <TAB>  <TAB> loc = self.getLocation(offs, range=True) <MASK> subs.add((loc[L_VA], loc[L_SIZE])) <TAB>  <TAB>  <TAB> if loc[L_TINFO]: <TAB>  <TAB>  <TAB>  <TAB> subs = subs.union(set(loc[L_TINFO])) <TAB> return list(subs)",if loc and loc [ L_LTYPE ] == LOC_STRING and loc [ L_VA ] > va :,161
4940,"def run(self): <TAB> while not self._stopped: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> test_name = next(self.pending) <TAB>  <TAB>  <TAB> except StopIteration: <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB>  <TAB> mp_result = self._runtest(test_name) <TAB>  <TAB>  <TAB> self.output.put((False, mp_result)) <MASK> break <TAB>  <TAB> except ExitThread: <TAB>  <TAB>  <TAB> break <TAB>  <TAB> except BaseException: <TAB>  <TAB>  <TAB> self.output.put((True, traceback.format_exc())) <TAB>  <TAB>  <TAB> break","if must_stop ( mp_result . result , self . ns ) :",151
4941,"def get_in_inputs(key, data): <TAB> if isinstance(data, dict): <TAB>  <TAB> for k, v in data.items(): <TAB>  <TAB>  <TAB> if k == key: <TAB>  <TAB>  <TAB>  <TAB> return v <TAB>  <TAB>  <TAB> elif isinstance(v, (list, tuple, dict)): <TAB>  <TAB>  <TAB>  <TAB> out = get_in_inputs(key, v) <MASK> return out <TAB> elif isinstance(data, (list, tuple)): <TAB>  <TAB> out = [get_in_inputs(key, x) for x in data] <TAB>  <TAB> out = [x for x in out if x] <TAB>  <TAB> if out: <TAB>  <TAB>  <TAB> return out[0]",if out :,160
4942,"def act_mapping(self, items, actions, mapping): <TAB> """"""Executes all the actions on the list of pods."""""" <TAB> success = True <TAB> for action in actions: <TAB>  <TAB> for key, method in mapping.items(): <TAB>  <TAB>  <TAB> if key in action: <TAB>  <TAB>  <TAB>  <TAB> params = action.get(key) <TAB>  <TAB>  <TAB>  <TAB> ret = method(items, params) <MASK> success = False <TAB> return success",if not ret :,109
4943,"def _apply(self, plan): <TAB> desired = plan.desired <TAB> changes = plan.changes <TAB> self.log.debug(""_apply: zone=%s, len(changes)=%d"", desired.name, len(changes)) <TAB> domain_name = desired.name[:-1] <TAB> try: <TAB>  <TAB> nsone_zone = self._client.loadZone(domain_name) <TAB> except ResourceException as e: <MASK> raise <TAB>  <TAB> self.log.debug(""_apply:   no matching zone, creating"") <TAB>  <TAB> nsone_zone = self._client.createZone(domain_name) <TAB> for change in changes: <TAB>  <TAB> class_name = change.__class__.__name__ <TAB>  <TAB> getattr(self, ""_apply_{}"".format(class_name))(nsone_zone, change)",if e . message != self . ZONE_NOT_FOUND_MESSAGE :,198
4944,"def split_artists(self, json): <TAB> if len(json) == 0: <TAB>  <TAB> ([], []) <TAB> elif len(json) == 1: <TAB>  <TAB> artist = Artist.query.filter_by(name=json[0][""name""]).first() <TAB>  <TAB> return ([artist], []) <TAB> my_artists = [] <TAB> other_artists = [] <TAB> for artist_dict in json: <TAB>  <TAB> artist = Artist.query.filter_by(name=artist_dict[""name""]) <MASK> my_artists.append(artist.first()) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> del artist_dict[""thumb_url""] <TAB>  <TAB>  <TAB> other_artists.append(artist_dict) <TAB> return (my_artists, other_artists)",if artist . count ( ) :,176
4945,"def update_metadata(self): <TAB> for attrname in dir(self): <TAB>  <TAB> if attrname.startswith(""__""): <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> attrvalue = getattr(self, attrname, None) <MASK> continue <TAB>  <TAB> if attrname == ""salt_version"": <TAB>  <TAB>  <TAB> attrname = ""version"" <TAB>  <TAB> if hasattr(self.metadata, ""set_{0}"".format(attrname)): <TAB>  <TAB>  <TAB> getattr(self.metadata, ""set_{0}"".format(attrname))(attrvalue) <TAB>  <TAB> elif hasattr(self.metadata, attrname): <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> setattr(self.metadata, attrname, attrvalue) <TAB>  <TAB>  <TAB> except AttributeError: <TAB>  <TAB>  <TAB>  <TAB> pass",if attrvalue == 0 :,173
4946,"def close(self, code=errno.ECONNRESET): <TAB> with self.shutdown_lock: <MASK> super(RemoteIPRoute, self).close(code=code) <TAB>  <TAB>  <TAB> self.closed = True <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB> self._mitogen_call.get() <TAB>  <TAB>  <TAB> except mitogen.core.ChannelError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> if self._mitogen_broker is not None: <TAB>  <TAB>  <TAB>  <TAB> self._mitogen_broker.shutdown() <TAB>  <TAB>  <TAB>  <TAB> self._mitogen_broker.join()",if not self . closed :,142
4947,"def untokenize(self, iterable): <TAB> for t in iterable: <MASK> self.compat(t, iterable) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> tok_type, token, start, end, line = t <TAB>  <TAB> self.add_whitespace(start) <TAB>  <TAB> self.tokens.append(token) <TAB>  <TAB> self.prev_row, self.prev_col = end <TAB>  <TAB> if tok_type in (NEWLINE, NL): <TAB>  <TAB>  <TAB> self.prev_row += 1 <TAB>  <TAB>  <TAB> self.prev_col = 0 <TAB> return """".join(self.tokens)",if len ( t ) == 2 :,143
4948,"def __call__(self, x, uttid=None): <TAB> if self.utt2spk is not None: <TAB>  <TAB> spk = self.utt2spk[uttid] <TAB> else: <TAB>  <TAB> spk = uttid <TAB> if not self.reverse: <TAB>  <TAB> if self.norm_means: <TAB>  <TAB>  <TAB> x = np.add(x, self.bias[spk]) <MASK> x = np.multiply(x, self.scale[spk]) <TAB> else: <TAB>  <TAB> if self.norm_vars: <TAB>  <TAB>  <TAB> x = np.divide(x, self.scale[spk]) <TAB>  <TAB> if self.norm_means: <TAB>  <TAB>  <TAB> x = np.subtract(x, self.bias[spk]) <TAB> return x",if self . norm_vars :,189
4949,"def get_party_total(self, args): <TAB> self.party_total = frappe._dict() <TAB> for d in self.receivables: <TAB>  <TAB> self.init_party_total(d) <TAB>  <TAB> # Add all amount columns <TAB>  <TAB> for k in list(self.party_total[d.party]): <MASK> self.party_total[d.party][k] += d.get(k, 0.0) <TAB>  <TAB> # set territory, customer_group, sales person etc <TAB>  <TAB> self.set_party_details(d)","if k not in [ ""currency"" , ""sales_person"" ] :",150
4950,"def get_databases(request): <TAB> dbs = {} <TAB> global_env = globals() <TAB> for (key, value) in global_env.items(): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> cond = isinstance(value, GQLDB) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> cond = isinstance(value, SQLDB) <MASK> dbs[key] = value <TAB> return dbs",if cond :,97
4951,"def check_twobit_file(dbkey, GALAXY_DATA_INDEX_DIR): <TAB> twobit_file = ""%s/twobit.loc"" % GALAXY_DATA_INDEX_DIR <TAB> twobit_path = """" <TAB> twobits = {} <TAB> for i, line in enumerate(open(twobit_file)): <TAB>  <TAB> line = line.rstrip(""\r\n"") <TAB>  <TAB> if line and not line.startswith(""#""): <TAB>  <TAB>  <TAB> fields = line.split(""\t"") <MASK> continue <TAB>  <TAB>  <TAB> twobits[(fields[0])] = fields[1] <TAB> if dbkey in twobits: <TAB>  <TAB> twobit_path = twobits[(dbkey)] <TAB> return twobit_path",if len ( fields ) < 2 :,177
4952,"def action(scheduler, _): <TAB> nonlocal state <TAB> nonlocal has_result <TAB> nonlocal result <TAB> nonlocal first <TAB> nonlocal time <MASK> observer.on_next(result) <TAB> try: <TAB>  <TAB> if first: <TAB>  <TAB>  <TAB> first = False <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> state = iterate(state) <TAB>  <TAB> has_result = condition(state) <TAB>  <TAB> if has_result: <TAB>  <TAB>  <TAB> result = state <TAB>  <TAB>  <TAB> time = time_mapper(state) <TAB> except Exception as e:  # pylint: disable=broad-except <TAB>  <TAB> observer.on_error(e) <TAB>  <TAB> return <TAB> if has_result: <TAB>  <TAB> mad.disposable = scheduler.schedule_relative(time, action) <TAB> else: <TAB>  <TAB> observer.on_completed()",if has_result :,187
4953,def orthogonalEnd(self): <TAB> if self.type == Segment.LINE: <TAB>  <TAB> O = self.AB.orthogonal() <TAB>  <TAB> O.norm() <TAB>  <TAB> return O <TAB> else: <TAB>  <TAB> O = self.B - self.C <TAB>  <TAB> O.norm() <MASK> return -O <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return O,if self . type == Segment . CCW :,97
4954,"def remove(self, values): <TAB> if not isinstance(values, (list, tuple, set)): <TAB>  <TAB> values = [values] <TAB> for v in values: <TAB>  <TAB> v = str(v) <TAB>  <TAB> if isinstance(self._definition, dict): <TAB>  <TAB>  <TAB> self._definition.pop(v, None) <TAB>  <TAB> elif self._definition == ""ANY"": <MASK> self._definition = [] <TAB>  <TAB> elif v in self._definition: <TAB>  <TAB>  <TAB> self._definition.remove(v) <TAB> if ( <TAB>  <TAB> self._value is not None <TAB>  <TAB> and self._value not in self._definition <TAB>  <TAB> and self._not_any() <TAB> ): <TAB>  <TAB> raise ConanException(bad_value_msg(self._name, self._value, self.values_range))","if v == ""ANY"" :",192
4955,"def __enter__(self) -> None: <TAB> try: <MASK> signal.signal(signal.SIGALRM, self.handle_timeout) <TAB>  <TAB>  <TAB> signal.alarm(self.seconds) <TAB> except ValueError as ex: <TAB>  <TAB> logger.warning(""timeout can't be used in the current context"") <TAB>  <TAB> logger.exception(ex)",if threading . current_thread ( ) == threading . main_thread ( ) :,98
4956,"def __init__(self, fixed: MQTTFixedHeader = None): <TAB> if fixed is None: <TAB>  <TAB> header = MQTTFixedHeader(PINGRESP, 0x00) <TAB> else: <MASK> raise HBMQTTException( <TAB>  <TAB>  <TAB>  <TAB> ""Invalid fixed packet type %s for PingRespPacket init"" <TAB>  <TAB>  <TAB>  <TAB> % fixed.packet_type <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> header = fixed <TAB> super().__init__(header) <TAB> self.variable_header = None <TAB> self.payload = None",if fixed . packet_type is not PINGRESP :,140
4957,"def _put_nowait(self, data, *, sender): <TAB> if not self._running: <TAB>  <TAB> logger.warning(""Pub/Sub listener message after stop: %r, %r"", sender, data) <TAB>  <TAB> return <TAB> self._queue.put_nowait((sender, data)) <TAB> if self._waiter is not None: <TAB>  <TAB> fut, self._waiter = self._waiter, None <MASK> assert fut.cancelled(), (""Waiting future is in wrong state"", self, fut) <TAB>  <TAB>  <TAB> return <TAB>  <TAB> fut.set_result(None)",if fut . done ( ) :,139
4958,"def OnAssignBuiltin(self, cmd_val): <TAB> # type: (cmd_value__Assign) -> None <TAB> buf = self._ShTraceBegin() <TAB> if not buf: <TAB>  <TAB> return <TAB> for i, arg in enumerate(cmd_val.argv): <MASK> buf.write("" "") <TAB>  <TAB> buf.write(arg) <TAB> for pair in cmd_val.pairs: <TAB>  <TAB> buf.write("" "") <TAB>  <TAB> buf.write(pair.var_name) <TAB>  <TAB> buf.write(""="") <TAB>  <TAB> if pair.rval: <TAB>  <TAB>  <TAB> _PrintShValue(pair.rval, buf) <TAB> buf.write(""\n"") <TAB> self.f.write(buf.getvalue())",if i != 0 :,169
4959,"def convertDict(obj): <TAB> obj = dict(obj) <TAB> for k, v in obj.items(): <TAB>  <TAB> del obj[k] <TAB>  <TAB> if not (isinstance(k, str) or isinstance(k, unicode)): <TAB>  <TAB>  <TAB> k = dumps(k) <TAB>  <TAB>  <TAB> # Keep track of which keys need to be decoded when loading. <MASK> obj[Types.KEYS] = [] <TAB>  <TAB>  <TAB> obj[Types.KEYS].append(k) <TAB>  <TAB> obj[k] = convertObjects(v) <TAB> return obj",if Types . KEYS not in obj :,137
4960,"def _ArgumentListHasDictionaryEntry(self, token): <TAB> """"""Check if the function argument list has a dictionary as an arg."""""" <TAB> if _IsArgumentToFunction(token): <TAB>  <TAB> while token: <TAB>  <TAB>  <TAB> if token.value == ""{"": <TAB>  <TAB>  <TAB>  <TAB> length = token.matching_bracket.total_length - token.total_length <TAB>  <TAB>  <TAB>  <TAB> return length + self.stack[-2].indent > self.column_limit <TAB>  <TAB>  <TAB> if token.ClosesScope(): <TAB>  <TAB>  <TAB>  <TAB> break <MASK> token = token.matching_bracket <TAB>  <TAB>  <TAB> token = token.next_token <TAB> return False",if token . OpensScope ( ) :,153
4961,"def get_editable_dict(self): <TAB> ret = {} <TAB> for ref, ws_package in self._workspace_packages.items(): <TAB>  <TAB> path = ws_package.root_folder <MASK> path = os.path.join(path, CONANFILE) <TAB>  <TAB> ret[ref] = {""path"": path, ""layout"": ws_package.layout} <TAB> return ret",if os . path . isdir ( path ) :,100
4962,"def serialize(self, name=None): <TAB> data = super(WebLink, self).serialize(name) <TAB> data[""contentType""] = self.contentType <TAB> if self.width: <MASK> raise InvalidWidthException(self.width) <TAB>  <TAB> data[""inputOptions""] = {} <TAB>  <TAB> data[""width""] = self.width <TAB> data.update({""content"": {""url"": self.linkUrl, ""text"": self.linkText}}) <TAB> return data","if self . width not in [ 100 , 50 , 33 , 25 ] :",122
4963,"def callback(lexer, match, context): <TAB> text = match.group() <TAB> extra = """" <TAB> if start: <TAB>  <TAB> context.next_indent = len(text) <MASK> while context.next_indent < context.indent: <TAB>  <TAB>  <TAB>  <TAB> context.indent = context.indent_stack.pop() <TAB>  <TAB>  <TAB> if context.next_indent > context.indent: <TAB>  <TAB>  <TAB>  <TAB> extra = text[context.indent :] <TAB>  <TAB>  <TAB>  <TAB> text = text[: context.indent] <TAB> else: <TAB>  <TAB> context.next_indent += len(text) <TAB> if text: <TAB>  <TAB> yield match.start(), TokenClass, text <TAB> if extra: <TAB>  <TAB> yield match.start() + len(text), TokenClass.Error, extra <TAB> context.pos = match.end()",if context . next_indent < context . indent :,196
4964,"def _handle_unsubscribe(self, web_sock): <TAB> index = None <TAB> with await self._subscriber_lock: <TAB>  <TAB> for i, (subscriber_web_sock, _) in enumerate(self._subscribers): <TAB>  <TAB>  <TAB> if subscriber_web_sock == web_sock: <TAB>  <TAB>  <TAB>  <TAB> index = i <TAB>  <TAB>  <TAB>  <TAB> break <MASK> del self._subscribers[index] <TAB>  <TAB> if not self._subscribers: <TAB>  <TAB>  <TAB> asyncio.ensure_future(self._unregister_subscriptions())",if index is not None :,124
4965,"def test_missing_dict_param(): <TAB> expected_err = ""params dictionary did not contain value for placeholder"" <TAB> try: <TAB>  <TAB> substitute_params( <TAB>  <TAB>  <TAB> ""SELECT * FROM cust WHERE salesrep = %(name)s"", {""foobar"": ""John Doe""} <TAB>  <TAB> ) <TAB>  <TAB> assert False, ""expected exception b/c dict did not contain replacement value"" <TAB> except ValueError as exc: <MASK> raise",if expected_err not in str ( exc ) :,110
4966,"def one_gpr_reg_one_mem_scalable(ii): <TAB> n, r = 0, 0 <TAB> for op in _gen_opnds(ii): <MASK> n += 1 <TAB>  <TAB> elif op_gprv(op): <TAB>  <TAB>  <TAB> r += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return False <TAB> return n == 1 and r == 1","if op_agen ( op ) or ( op_mem ( op ) and op . oc2 in [ ""v"" ] ) :",113
4967,"def on_enter(self): <TAB> """"""Fired when mouse enter the bbox of the widget."""""" <TAB> if hasattr(self, ""md_bg_color"") and self.focus_behavior: <TAB>  <TAB> if hasattr(self, ""theme_cls"") and not self.focus_color: <TAB>  <TAB>  <TAB> self.md_bg_color = self.theme_cls.bg_normal <TAB>  <TAB> else: <MASK> self.md_bg_color = App.get_running_app().theme_cls.bg_normal <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> self.md_bg_color = self.focus_color",if not self . focus_color :,154
4968,"def __init__(self, *args, **kwargs): <TAB> BaseCellExporter.__init__(self, *args, **kwargs) <TAB> self.comment = ""#"" <TAB> for key in [""cell_marker""]: <MASK> self.metadata[key] = self.unfiltered_metadata[key] <TAB> if self.fmt.get(""rst2md""): <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB> ""The 'rst2md' option is a read only option. The reverse conversion is not "" <TAB>  <TAB>  <TAB> ""implemented. Please either deactivate the option, or save to another format."" <TAB>  <TAB> )  # pragma: no cover",if key in self . unfiltered_metadata :,150
4969,"def sendQueryQueueByAfterNate(self): <TAB> for i in range(10): <TAB>  <TAB> queryQueueByAfterNateRsp = self.session.httpClint.send(urls.get(""queryQueue"")) <MASK> print( <TAB>  <TAB>  <TAB>  <TAB> """".join(queryQueueByAfterNateRsp.get(""messages"")) <TAB>  <TAB>  <TAB>  <TAB> or queryQueueByAfterNateRsp.get(""validateMessages"") <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> time.sleep(1) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> sendEmail(ticket.WAIT_ORDER_SUCCESS) <TAB>  <TAB>  <TAB> sendServerChan(ticket.WAIT_ORDER_SUCCESS) <TAB>  <TAB>  <TAB> raise ticketIsExitsException(ticket.WAIT_AFTER_NATE_SUCCESS)","if not queryQueueByAfterNateRsp . get ( ""status"" ) :",190
4970,"def filter_errors(self, errors: List[str]) -> List[str]: <TAB> real_errors: List[str] = list() <TAB> current_file = __file__ <TAB> current_path = os.path.split(current_file) <TAB> for line in errors: <TAB>  <TAB> line = line.strip() <MASK> continue <TAB>  <TAB> fn, lno, lvl, msg = self.parse_trace_line(line) <TAB>  <TAB> if fn is not None: <TAB>  <TAB>  <TAB> _path = os.path.split(fn) <TAB>  <TAB>  <TAB> if _path[-1] != current_path[-1]: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> real_errors.append(line) <TAB> return real_errors",if not line :,171
4971,"def pretty(self, n, comment=True): <TAB> if isinstance(n, (str, bytes, list, tuple, dict)): <TAB>  <TAB> r = repr(n) <TAB>  <TAB> if not comment:  # then it can be inside a comment! <TAB>  <TAB>  <TAB> r = r.replace(""*/"", r""\x2a/"") <TAB>  <TAB> return r <TAB> if not isinstance(n, six.integer_types): <TAB>  <TAB> return n <TAB> if isinstance(n, constants.Constant): <MASK> return ""%s /* %s */"" % (n, self.pretty(int(n))) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return ""%s (%s)"" % (n, self.pretty(int(n))) <TAB> elif abs(n) < 10: <TAB>  <TAB> return str(n) <TAB> else: <TAB>  <TAB> return hex(n)",if comment :,194
4972,"def get_pricings(self, subscription_id: str): <TAB> try: <TAB>  <TAB> client = self.get_client(subscription_id) <TAB>  <TAB> pricings_list = await run_concurrently(lambda: client.pricings.list()) <MASK> return pricings_list.value <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return [] <TAB> except Exception as e: <TAB>  <TAB> print_exception(f""Failed to retrieve pricings: {e}"") <TAB>  <TAB> return []","if hasattr ( pricings_list , ""value"" ) :",131
4973,"def add_doc(target, variables, body_lines): <TAB> if isinstance(target, ast.Name): <TAB>  <TAB> # if it is a variable name add it to the doc <TAB>  <TAB> name = target.id <TAB>  <TAB> if name not in variables: <TAB>  <TAB>  <TAB> doc = find_doc_for(target, body_lines) <MASK> variables[name] = doc <TAB> elif isinstance(target, ast.Tuple): <TAB>  <TAB> # if it is a tuple then iterate the elements <TAB>  <TAB> # this can happen like this: <TAB>  <TAB> # a, b = 1, 2 <TAB>  <TAB> for e in target.elts: <TAB>  <TAB>  <TAB> add_doc(e, variables, body_lines)",if doc is not None :,167
4974,"def find_word_bounds(self, text, index, allowed_chars): <TAB> right = left = index <TAB> done = False <TAB> while not done: <TAB>  <TAB> if left == 0: <TAB>  <TAB>  <TAB> done = True <TAB>  <TAB> elif not self.word_boundary_char(text[left - 1]): <TAB>  <TAB>  <TAB> left -= 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> done = True <TAB> done = False <TAB> while not done: <MASK> done = True <TAB>  <TAB> elif not self.word_boundary_char(text[right]): <TAB>  <TAB>  <TAB> right += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> done = True <TAB> return left, right",if right == len ( text ) :,159
4975,"def pxrun_nodes(self, *args, **kwargs): <TAB> cell = self._px_cell <TAB> if re.search(r""^\s*%autopx\b"", cell): <TAB>  <TAB> self._disable_autopx() <TAB>  <TAB> return False <TAB> else: <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> result = self.view.execute(cell, silent=False, block=False) <TAB>  <TAB> except: <TAB>  <TAB>  <TAB> self.shell.showtraceback() <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> else: <MASK> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> result.get() <TAB>  <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> self.shell.showtraceback() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB>  <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> result.display_outputs() <TAB>  <TAB>  <TAB> return False",if self . view . block :,198
4976,"def candidates() -> Generator[""Symbol"", None, None]: <TAB> s = self <TAB> if Symbol.debug_lookup: <TAB>  <TAB> Symbol.debug_print(""searching in self:"") <TAB>  <TAB> print(s.to_string(Symbol.debug_indent + 1), end="""") <TAB> while True: <TAB>  <TAB> if matchSelf: <TAB>  <TAB>  <TAB> yield s <TAB>  <TAB> if recurseInAnon: <TAB>  <TAB>  <TAB> yield from s.children_recurse_anon <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> yield from s._children <MASK> break <TAB>  <TAB> s = s.siblingAbove <TAB>  <TAB> if Symbol.debug_lookup: <TAB>  <TAB>  <TAB> Symbol.debug_print(""searching in sibling:"") <TAB>  <TAB>  <TAB> print(s.to_string(Symbol.debug_indent + 1), end="""")",if s . siblingAbove is None :,190
4977,"def decTaskGen(): <TAB> cnt = intbv(0, min=-n, max=n) <TAB> while 1: <TAB>  <TAB> yield clock.posedge, reset.negedge <MASK> cnt[:] = 0 <TAB>  <TAB>  <TAB> count.next = 0 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # print count <TAB>  <TAB>  <TAB> decTaskFunc(cnt, enable, reset, n) <TAB>  <TAB>  <TAB> count.next = cnt",if reset == ACTIVE_LOW :,107
4978,"def __call__(self, *args, **kwargs): <TAB> if not NET_INITTED: <TAB>  <TAB> return self.raw(*args, **kwargs) <TAB> for stack in traceback.walk_stack(None): <MASK> layer = stack[0].f_locals[""self""] <TAB>  <TAB>  <TAB> if layer in layer_names: <TAB>  <TAB>  <TAB>  <TAB> log.pytorch_layer_name = layer_names[layer] <TAB>  <TAB>  <TAB>  <TAB> print(layer_names[layer]) <TAB>  <TAB>  <TAB>  <TAB> break <TAB> out = self.obj(self.raw, *args, **kwargs) <TAB> # if isinstance(out,Variable): <TAB> # <TAB>  out=[out] <TAB> return out","if ""self"" in stack [ 0 ] . f_locals :",173
4979,"def to_json_dict(self): <TAB> d = super().to_json_dict() <TAB> d[""bullet_list""] = RenderedContent.rendered_content_list_to_json(self.bullet_list) <TAB> if self.header is not None: <TAB>  <TAB> if isinstance(self.header, RenderedContent): <TAB>  <TAB>  <TAB> d[""header""] = self.header.to_json_dict() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> d[""header""] = self.header <TAB> if self.subheader is not None: <MASK> d[""subheader""] = self.subheader.to_json_dict() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> d[""subheader""] = self.subheader <TAB> return d","if isinstance ( self . subheader , RenderedContent ) :",172
4980,"def add(request): <TAB> form_type = ""servers"" <TAB> if request.method == ""POST"": <TAB>  <TAB> form = BookMarkForm(request.POST) <MASK> form_type = form.save() <TAB>  <TAB>  <TAB> messages.add_message(request, messages.INFO, ""Bookmark created"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> messages.add_message(request, messages.INFO, form.errors) <TAB>  <TAB> if form_type == ""server"": <TAB>  <TAB>  <TAB> url = reverse(""servers"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> url = reverse(""metrics"") <TAB>  <TAB> return redirect(url) <TAB> else: <TAB>  <TAB> return redirect(reverse(""servers""))",if form . is_valid ( ) :,164
4981,"def fee_amount_in_quote(self, trading_pair: str, price: Decimal, order_amount: Decimal): <TAB> fee_amount = Decimal(""0"") <TAB> if self.percent > 0: <TAB>  <TAB> fee_amount = (price * order_amount) * self.percent <TAB> base, quote = trading_pair.split(""-"") <TAB> for flat_fee in self.flat_fees: <TAB>  <TAB> if interchangeable(flat_fee[0], base): <TAB>  <TAB>  <TAB> fee_amount += flat_fee[1] * price <MASK> fee_amount += flat_fee[1] <TAB> return fee_amount","elif interchangeable ( flat_fee [ 0 ] , quote ) :",163
4982,"def load_batch(fpath): <TAB> with open(fpath, ""rb"") as f: <MASK> # Python3 <TAB>  <TAB>  <TAB> d = pickle.load(f, encoding=""latin1"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Python2 <TAB>  <TAB>  <TAB> d = pickle.load(f) <TAB> data = d[""data""] <TAB> labels = d[""labels""] <TAB> return data, labels","if sys . version_info > ( 3 , 0 ) :",106
4983,"def clear_entries(options): <TAB> """"""Clear pending entries"""""" <TAB> with Session() as session: <TAB>  <TAB> query = session.query(db.PendingEntry).filter(db.PendingEntry.approved == False) <MASK> query = query.filter(db.PendingEntry.task_name == options.task_name) <TAB>  <TAB> deleted = query.delete() <TAB>  <TAB> console(""Successfully deleted %i pending entries"" % deleted)",if options . task_name :,110
4984,"def attribute_table(self, attribute): <TAB> """"""Return a tuple (schema, table) for attribute."""""" <TAB> dimension = attribute.dimension <TAB> if dimension: <TAB>  <TAB> schema = self.naming.dimension_schema or self.naming.schema <MASK> table = self.fact_name <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> table = self.naming.dimension_table_name(dimension) <TAB> else: <TAB>  <TAB> table = self.fact_name <TAB>  <TAB> schema = self.naming.schema <TAB> return (schema, table)",if dimension . is_flat and not dimension . has_details :,137
4985,"def remove_rating(self, songs, librarian): <TAB> count = len(songs) <TAB> if count > 1 and config.getboolean(""browsers"", ""rating_confirm_multiple""): <TAB>  <TAB> parent = qltk.get_menu_item_top_parent(self) <TAB>  <TAB> dialog = ConfirmRateMultipleDialog(parent, _(""_Remove Rating""), count, None) <TAB>  <TAB> if dialog.run() != Gtk.ResponseType.YES: <TAB>  <TAB>  <TAB> return <TAB> reset = [] <TAB> for song in songs: <MASK> del song[""~#rating""] <TAB>  <TAB>  <TAB> reset.append(song) <TAB> librarian.changed(reset)","if ""~#rating"" in song :",159
4986,"def find_word_bounds(self, text, index, allowed_chars): <TAB> right = left = index <TAB> done = False <TAB> while not done: <TAB>  <TAB> if left == 0: <TAB>  <TAB>  <TAB> done = True <TAB>  <TAB> elif not self.word_boundary_char(text[left - 1]): <TAB>  <TAB>  <TAB> left -= 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> done = True <TAB> done = False <TAB> while not done: <TAB>  <TAB> if right == len(text): <TAB>  <TAB>  <TAB> done = True <MASK> right += 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> done = True <TAB> return left, right",elif not self . word_boundary_char ( text [ right ] ) :,159
4987,"def handle_read(self): <TAB> """"""Called when there is data waiting to be read."""""" <TAB> try: <TAB>  <TAB> chunk = self.recv(self.ac_in_buffer_size) <TAB> except RetryError: <TAB>  <TAB> pass <TAB> except socket.error: <TAB>  <TAB> self.handle_error() <TAB> else: <TAB>  <TAB> self.tot_bytes_received += len(chunk) <TAB>  <TAB> if not chunk: <TAB>  <TAB>  <TAB> self.transfer_finished = True <TAB>  <TAB>  <TAB> # self.close()  # <-- asyncore.recv() already do that... <TAB>  <TAB>  <TAB> return <MASK> chunk = self._data_wrapper(chunk) <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.file_obj.write(chunk) <TAB>  <TAB> except OSError as err: <TAB>  <TAB>  <TAB> raise _FileReadWriteError(err)",if self . _data_wrapper is not None :,200
4988,"def toggle(self, event=None): <TAB> if self.absolute: <TAB>  <TAB> if self.save == self.split: <TAB>  <TAB>  <TAB> self.save = 100 <TAB>  <TAB> if self.split > 20: <TAB>  <TAB>  <TAB> self.save = self.split <TAB>  <TAB>  <TAB> self.split = 1 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.split = self.save <TAB> else: <TAB>  <TAB> if self.save == self.split: <TAB>  <TAB>  <TAB> self.save = 0.3 <TAB>  <TAB> if self.split <= self.min or self.split >= self.max: <TAB>  <TAB>  <TAB> self.split = self.save <MASK> self.split = self.min <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.split = self.max <TAB> self.placeChilds()",elif self . split < 0.5 :,189
4989,"def readAtOffset(self, offset, size, shortok=False): <TAB> ret = b"""" <TAB> self.fd.seek(offset) <TAB> while len(ret) != size: <TAB>  <TAB> rlen = size - len(ret) <TAB>  <TAB> x = self.fd.read(rlen) <TAB>  <TAB> if x == b"""": <MASK> return None <TAB>  <TAB>  <TAB> return ret <TAB>  <TAB> ret += x <TAB> return ret",if not shortok :,111
4990,"def webfinger(environ, start_response, _): <TAB> query = parse_qs(environ[""QUERY_STRING""]) <TAB> try: <TAB>  <TAB> rel = query[""rel""] <TAB>  <TAB> resource = query[""resource""][0] <TAB> except KeyError: <TAB>  <TAB> resp = BadRequest(""Missing parameter in request"") <TAB> else: <MASK> resp = BadRequest(""Bad issuer in request"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> wf = WebFinger() <TAB>  <TAB>  <TAB> resp = Response(wf.response(subject=resource, base=OAS.baseurl)) <TAB> return resp(environ, start_response)",if rel != [ OIC_ISSUER ] :,152
4991,"def _tokenize(self, text): <TAB> if format_text(text) == EMPTY_TEXT: <TAB>  <TAB> return [self.additional_special_tokens[0]] <TAB> split_tokens = [] <TAB> if self.do_basic_tokenize: <TAB>  <TAB> for token in self.basic_tokenizer.tokenize( <TAB>  <TAB>  <TAB> text, never_split=self.all_special_tokens <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> # If the token is part of the never_split set <MASK> split_tokens.append(token) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> split_tokens += self.wordpiece_tokenizer.tokenize(token) <TAB> else: <TAB>  <TAB> split_tokens = self.wordpiece_tokenizer.tokenize(text) <TAB> return split_tokens",if token in self . basic_tokenizer . never_split :,189
4992,"def send_packed_command(self, command, check_health=True): <TAB> if not self._sock: <TAB>  <TAB> self.connect() <TAB> try: <TAB>  <TAB> if isinstance(command, str): <TAB>  <TAB>  <TAB> command = [command] <TAB>  <TAB> for item in command: <TAB>  <TAB>  <TAB> self._sock.sendall(item) <TAB> except socket.error as e: <TAB>  <TAB> self.disconnect() <MASK> _errno, errmsg = ""UNKNOWN"", e.args[0] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _errno, errmsg = e.args <TAB>  <TAB> raise ConnectionError( <TAB>  <TAB>  <TAB> ""Error %s while writing to socket. %s."" % (_errno, errmsg) <TAB>  <TAB> ) <TAB> except Exception: <TAB>  <TAB> self.disconnect() <TAB>  <TAB> raise",if len ( e . args ) == 1 :,188
4993,"def to_value(self, value): <TAB> # Tip: 'value' is the object returned by <TAB> # <TAB>   taiga.projects.history.models.HistoryEntry.values_diff() <TAB> ret = {} <TAB> for key, val in value.items(): <TAB>  <TAB> if key in [""attachments"", ""custom_attributes"", ""description_diff""]: <TAB>  <TAB>  <TAB> ret[key] = val <MASK> ret[key] = {k: {""from"": v[0], ""to"": v[1]} for k, v in val.items()} <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> ret[key] = {""from"": val[0], ""to"": val[1]} <TAB> return ret","elif key == ""points"" :",169
4994,"def to_child(cls, key=None, process=None): <TAB> if process is not None: <TAB>  <TAB> if type(process) is not dict: <TAB>  <TAB>  <TAB> raise ValueError( <TAB>  <TAB>  <TAB>  <TAB> 'Invalid value provided for ""process"" parameter, expected a dictionary' <TAB>  <TAB>  <TAB> ) <MASK> # Merge class `__process__` parameters with provided parameters <TAB>  <TAB>  <TAB> result = {} <TAB>  <TAB>  <TAB> result.update(deepcopy(cls.__process__)) <TAB>  <TAB>  <TAB> result.update(process) <TAB>  <TAB>  <TAB> process = result <TAB> class Child(cls): <TAB>  <TAB> __key__ = key <TAB>  <TAB> __process__ = process <TAB>  <TAB> __root__ = False <TAB> Child.__name__ = cls.__name__ <TAB> return Child",if cls . __process__ :,173
4995,"def _super_function(args): <TAB> passed_class, passed_self = args.get_arguments([""type"", ""self""]) <TAB> if passed_self is None: <TAB>  <TAB> return passed_class <TAB> else: <TAB>  <TAB> # pyclass = passed_self.get_type() <TAB>  <TAB> pyclass = passed_class <MASK> supers = pyclass.get_superclasses() <TAB>  <TAB>  <TAB> if supers: <TAB>  <TAB>  <TAB>  <TAB> return pyobjects.PyObject(supers[0]) <TAB>  <TAB> return passed_self","if isinstance ( pyclass , pyobjects . AbstractClass ) :",132
4996,"def get_data(row): <TAB> data = [] <TAB> for field_name, field_xpath in fields: <TAB>  <TAB> result = row.xpath(field_xpath) <MASK> result = "" "".join( <TAB>  <TAB>  <TAB>  <TAB> text <TAB>  <TAB>  <TAB>  <TAB> for text in map( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> six.text_type.strip, map(six.text_type, map(unescape, result)) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB>  <TAB> if text <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> result = None <TAB>  <TAB> data.append(result) <TAB> return data",if result :,142
4997,"def say(jarvis, s): <TAB> """"""Reads what is typed."""""" <TAB> if not s: <TAB>  <TAB> jarvis.say(""What should I say?"") <TAB> else: <TAB>  <TAB> voice_state = jarvis.is_voice_enabled() <TAB>  <TAB> jarvis.enable_voice() <TAB>  <TAB> jarvis.say(s) <MASK> jarvis.disable_voice()",if not voice_state :,99
4998,"def __import__(name, globals=None, locals=None, fromlist=(), level=0): <TAB> module = orig___import__(name, globals, locals, fromlist, level) <TAB> if fromlist and module.__name__ in modules: <MASK> fromlist = list(fromlist) <TAB>  <TAB>  <TAB> fromlist.remove(""*"") <TAB>  <TAB>  <TAB> fromlist.extend(getattr(module, ""__all__"", [])) <TAB>  <TAB> for x in fromlist: <TAB>  <TAB>  <TAB> if isinstance(getattr(module, x, None), types.ModuleType): <TAB>  <TAB>  <TAB>  <TAB> from_name = ""{}.{}"".format(module.__name__, x) <TAB>  <TAB>  <TAB>  <TAB> if from_name in modules: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> importlib.import_module(from_name) <TAB> return module","if ""*"" in fromlist :",175
4999,"def _read_pricing_file(self, region=None, pricing_file=None): <TAB> if not self.__pricing_file_cache: <MASK> logging.info(""Reading pricing file..."") <TAB>  <TAB>  <TAB> with open(pricing_file) as data_file: <TAB>  <TAB>  <TAB>  <TAB> self.__pricing_file_cache = json.load(data_file) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.__pricing_file_cache = self._download_pricing_file(region) <TAB> return self.__pricing_file_cache",if pricing_file :,130
