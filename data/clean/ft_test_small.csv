cleaned_method,target_block,tokens_in_method
"def read(self, count=True, timeout=None, ignore_non_errors=True, ignore_timeouts=True): <TAB> try: <TAB>  <TAB> return self._read(count, timeout) <TAB> except usb.USBError as e: <TAB>  <TAB> if DEBUG_COMM: <TAB>  <TAB>  <TAB> log.info( <TAB>  <TAB>  <TAB>  <TAB> ""read: e.errno=%s e.strerror=%s e.message=%s repr=%s"" <TAB>  <TAB>  <TAB>  <TAB> % (e.errno, e.strerror, e.message, repr(e)) <TAB>  <TAB>  <TAB> ) <MASK> return [] <TAB>  <TAB> if ignore_non_errors and is_noerr(e): <TAB>  <TAB>  <TAB> return [] <TAB>  <TAB> raise",if ignore_timeouts and is_timeout ( e ) :,174
"def _cache_mem(curr_out, prev_mem, mem_len, reuse_len=None): <TAB> """"""cache hidden states into memory."""""" <TAB> if mem_len is None or mem_len == 0: <TAB>  <TAB> return None <TAB> else: <TAB>  <TAB> if reuse_len is not None and reuse_len > 0: <TAB>  <TAB>  <TAB> curr_out = curr_out[:reuse_len] <MASK> new_mem = curr_out[-mem_len:] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> new_mem = tf.concat([prev_mem, curr_out], 0)[-mem_len:] <TAB> new_mem.stop_gradient = True <TAB> return new_mem",if prev_mem is None :,165
def filtered(gen): <TAB> for example in gen: <TAB>  <TAB> example_len = length_fn(example) <TAB>  <TAB> # Checking max length boundary. <TAB>  <TAB> if max_length is not None: <MASK> continue <TAB>  <TAB> # Checking min length boundary. <TAB>  <TAB> if min_length is not None: <TAB>  <TAB>  <TAB> if example_len < min_length: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> # Within bounds. <TAB>  <TAB> yield example,if example_len > max_length :,117
"def search(self, query): <TAB> # ""Search.ashx?query="" + query + filterVal <TAB> if not query: <TAB>  <TAB> logger.debug(""Empty search query"") <TAB>  <TAB> return [] <TAB> logger.debug('Searching TuneIn for ""%s""' % query) <TAB> args = ""&query="" + query <TAB> search_results = self._tunein(""Search.ashx"", args) <TAB> results = [] <TAB> for item in self._flatten(search_results): <MASK> # Only return stations <TAB>  <TAB>  <TAB> self._stations[item[""guide_id""]] = item <TAB>  <TAB>  <TAB> results.append(item) <TAB> return results","if item . get ( ""type"" , """" ) == ""audio"" :",163
"def _check_script(self, script, directive): <TAB> for var in compile_script(script): <MASK> # Skip variable checks <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> if var.can_contain("".""): <TAB>  <TAB>  <TAB> # Yay! Our variable can contain any symbols! <TAB>  <TAB>  <TAB> reason = ( <TAB>  <TAB>  <TAB>  <TAB> 'At least variable ""${var}"" can contain untrusted user input'.format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> var=var.name <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> self.add_issue(directive=[directive] + var.providers, reason=reason) <TAB>  <TAB>  <TAB> return True <TAB> return False","if var . must_contain ( ""/"" ) :",157
"def getAllDataLinkIDs(): <TAB> linkDataIDs = set() <TAB> dataType = _forestData.dataTypeBySocket <TAB> for socketID, linkedIDs in _forestData.linkedSockets.items(): <TAB>  <TAB> for linkedID in linkedIDs: <MASK> # check which one is origin/target <TAB>  <TAB>  <TAB>  <TAB> linkDataIDs.add( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> (socketID, linkedID, dataType[socketID], dataType[linkedID]) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> linkDataIDs.add( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> (linkedID, socketID, dataType[linkedID], dataType[socketID]) <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return linkDataIDs",if socketID [ 1 ] :,174
"def _stderr_supports_color(): <TAB> try: <TAB>  <TAB> if hasattr(sys.stderr, ""isatty"") and sys.stderr.isatty(): <TAB>  <TAB>  <TAB> if curses: <TAB>  <TAB>  <TAB>  <TAB> curses.setupterm() <MASK> return True <TAB>  <TAB>  <TAB> elif colorama: <TAB>  <TAB>  <TAB>  <TAB> if sys.stderr is getattr( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> colorama.initialise, ""wrapped_stderr"", object() <TAB>  <TAB>  <TAB>  <TAB> ): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> except Exception: <TAB>  <TAB> # Very broad exception handling because it's always better to <TAB>  <TAB> # fall back to non-colored logs than to break at startup. <TAB>  <TAB> pass <TAB> return False","if curses . tigetnum ( ""colors"" ) > 0 :",170
"def offsets(self): <TAB> offsets = {} <TAB> offset_so_far = 0 <TAB> for name, ty in self.fields.items(): <TAB>  <TAB> if isinstance(ty, SimTypeBottom): <TAB>  <TAB>  <TAB> l.warning( <TAB>  <TAB>  <TAB>  <TAB> ""Found a bottom field in struct %s. Ignore and increment the offset using the default "" <TAB>  <TAB>  <TAB>  <TAB> ""element size."", <TAB>  <TAB>  <TAB>  <TAB> self.name, <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> if not self._pack: <TAB>  <TAB>  <TAB> align = ty.alignment <MASK> offset_so_far += align - offset_so_far % align <TAB>  <TAB> offsets[name] = offset_so_far <TAB>  <TAB> offset_so_far += ty.size // self._arch.byte_width <TAB> return offsets",if offset_so_far % align != 0 :,196
"def Restore(self): <TAB> picker, obj = self._window, self._pObject <TAB> value = obj.RestoreValue(PERSIST_FILEDIRPICKER_PATH) <TAB> if value is not None: <TAB>  <TAB> if issubclass(picker.__class__, wx.FileDialog): <MASK> value = value[-1] <TAB>  <TAB> picker.SetPath(value) <TAB>  <TAB> return True <TAB> return False",if type ( value ) == list :,102
"def dt_s_tup_to_string(dt_s_tup): <TAB> dt_string = dt_s_tup[0]  # string for identifying the file to parse. <TAB> if dt_s_tup[1] > 0:  # if there are seasons in the model <MASK> dt_string = dt_string[:2] + ""s"" + dt_string[2:] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> dt_string = ""s"" + dt_string <TAB> return dt_string","if ""co"" in dt_string or ""ci"" in dt_string or ""nc"" in dt_string :",146
"def writer(stream, items): <TAB> sep = """" <TAB> for item in items: <TAB>  <TAB> stream.write(sep) <TAB>  <TAB> sep = "" "" <MASK> item = str(item) <TAB>  <TAB> if not PY3K: <TAB>  <TAB>  <TAB> if not isinstance(item, unicode): <TAB>  <TAB>  <TAB>  <TAB> item = str(item) <TAB>  <TAB> stream.write(item) <TAB> stream.write(""\n"")","if not isinstance ( item , str ) :",106
"def _get_result_keys(self, config): <TAB> result_key = config.get(""result_key"") <TAB> if result_key is not None: <MASK> result_key = [result_key] <TAB>  <TAB> result_key = [jmespath.compile(rk) for rk in result_key] <TAB>  <TAB> return result_key","if not isinstance ( result_key , list ) :",92
"def _download_build_artifacts(self, build: Dict[str, Any]) -> None: <TAB> arch = build[""arch_tag""] <TAB> snap_build = self._lp_load_url(build[""self_link""]) <TAB> urls = snap_build.getFileUrls() <TAB> if not urls: <TAB>  <TAB> logger.error(f""Snap file not available for arch {arch!r}."") <TAB>  <TAB> return <TAB> for url in urls: <TAB>  <TAB> file_name = _get_url_basename(url) <TAB>  <TAB> self._download_file(url=url, dst=file_name) <MASK> logger.info(f""Snapped {file_name}"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> logger.info(f""Fetched {file_name}"")","if file_name . endswith ( "".snap"" ) :",187
"def _add_custom_statement(self, custom_statements): <TAB> if custom_statements is None: <TAB>  <TAB> return <TAB> self.resource_policy[""Version""] = ""2012-10-17"" <TAB> if self.resource_policy.get(""Statement"") is None: <TAB>  <TAB> self.resource_policy[""Statement""] = custom_statements <TAB> else: <TAB>  <TAB> if not isinstance(custom_statements, list): <TAB>  <TAB>  <TAB> custom_statements = [custom_statements] <TAB>  <TAB> statement = self.resource_policy[""Statement""] <TAB>  <TAB> if not isinstance(statement, list): <TAB>  <TAB>  <TAB> statement = [statement] <TAB>  <TAB> for s in custom_statements: <MASK> statement.append(s) <TAB>  <TAB> self.resource_policy[""Statement""] = statement",if s not in statement :,184
"def display_failures_for_single_test(result: TestResult) -> None: <TAB> """"""Display a failure for a single method / endpoint."""""" <TAB> display_subsection(result) <TAB> checks = _get_unique_failures(result.checks) <TAB> for idx, check in enumerate(checks, 1): <TAB>  <TAB> message: Optional[str] <MASK> message = f""{idx}. {check.message}"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> message = None <TAB>  <TAB> example = cast(Case, check.example)  # filtered in `_get_unique_failures` <TAB>  <TAB> display_example(example, check.name, message, result.seed) <TAB>  <TAB> # Display every time except the last check <TAB>  <TAB> if idx != len(checks): <TAB>  <TAB>  <TAB> click.echo(""\n"")",if check . message :,188
"def build(opt): <TAB> dpath = os.path.join(opt[""datapath""], ""qangaroo"") <TAB> version = ""v1.1"" <TAB> if not build_data.built(dpath, version_string=version): <TAB>  <TAB> print(""[building data: "" + dpath + ""]"") <MASK> # An older version exists, so remove these outdated files. <TAB>  <TAB>  <TAB> build_data.remove_dir(dpath) <TAB>  <TAB> build_data.make_dir(dpath) <TAB>  <TAB> # Download the data. <TAB>  <TAB> for downloadable_file in RESOURCES: <TAB>  <TAB>  <TAB> downloadable_file.download_file(dpath) <TAB>  <TAB> # Mark the data as built. <TAB>  <TAB> build_data.mark_done(dpath, version_string=version)",if build_data . built ( dpath ) :,188
"def call(self, step_input, states): <TAB> new_states = [] <TAB> for i in range(self.num_layers): <TAB>  <TAB> out, new_state = self.lstm_cells[i](step_input, states[i]) <TAB>  <TAB> step_input = ( <TAB>  <TAB>  <TAB> layers.dropout( <TAB>  <TAB>  <TAB>  <TAB> out, self.dropout_prob, dropout_implementation=""upscale_in_train"" <TAB>  <TAB>  <TAB> ) <MASK> else out <TAB>  <TAB> ) <TAB>  <TAB> new_states.append(new_state) <TAB> return step_input, new_states",if self . dropout_prob > 0.0,148
"def jupyter_progress_bar(min=0, max=1.0): <TAB> """"""Returns an ipywidget progress bar or None if we can't import it"""""" <TAB> widgets = wandb.util.get_module(""ipywidgets"") <TAB> try: <MASK> # TODO: this currently works in iPython but it's deprecated since 4.0 <TAB>  <TAB>  <TAB> from IPython.html import widgets  # type: ignore <TAB>  <TAB> assert hasattr(widgets, ""VBox"") <TAB>  <TAB> assert hasattr(widgets, ""Label"") <TAB>  <TAB> assert hasattr(widgets, ""FloatProgress"") <TAB>  <TAB> return ProgressWidget(widgets, min=min, max=max) <TAB> except (ImportError, AssertionError): <TAB>  <TAB> return None",if widgets is None :,168
"def _record_event(self, path, fsevent_handle, filename, events, error): <TAB> with self.lock: <TAB>  <TAB> self.events[path].append(events) <MASK> if not os.path.exists(path): <TAB>  <TAB>  <TAB>  <TAB> self.watches.pop(path).close()",if events | pyuv . fs . UV_RENAME :,89
"def _get_v1_id_from_tags(self, tags_obj, tag): <TAB> """"""Get image id from array of tags"""""" <TAB> if isinstance(tags_obj, dict): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> return tags_obj[tag] <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> pass <TAB> elif isinstance(tags_obj, []): <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> for tag_dict in tags_obj: <MASK> return tag_dict[""layer""] <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB> pass <TAB> return """"","if tag_dict [ ""name"" ] == tag :",142
"def query_lister(domain, query="""", max_items=None, attr_names=None): <TAB> more_results = True <TAB> num_results = 0 <TAB> next_token = None <TAB> while more_results: <TAB>  <TAB> rs = domain.connection.query_with_attributes( <TAB>  <TAB>  <TAB> domain, query, attr_names, next_token=next_token <TAB>  <TAB> ) <TAB>  <TAB> for item in rs: <MASK> if num_results == max_items: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise StopIteration <TAB>  <TAB>  <TAB> yield item <TAB>  <TAB>  <TAB> num_results += 1 <TAB>  <TAB> next_token = rs.next_token <TAB>  <TAB> more_results = next_token != None",if max_items :,166
"def filter(this, args): <TAB> array = to_object(this, args.space) <TAB> callbackfn = get_arg(args, 0) <TAB> arr_len = js_arr_length(array) <TAB> if not is_callable(callbackfn): <TAB>  <TAB> raise MakeError(""TypeError"", ""callbackfn must be a function"") <TAB> _this = get_arg(args, 1) <TAB> k = 0 <TAB> res = [] <TAB> while k < arr_len: <MASK> kValue = array.get(unicode(k)) <TAB>  <TAB>  <TAB> if to_boolean(callbackfn.call(_this, (kValue, float(k), array))): <TAB>  <TAB>  <TAB>  <TAB> res.append(kValue) <TAB>  <TAB> k += 1 <TAB> return args.space.ConstructArray(res)",if array . has_property ( unicode ( k ) ) :,194
"def every_one_is(self, dst): <TAB> msg = ""all members of %r should be %r, but the %dth is %r"" <TAB> for index, item in enumerate(self._src): <TAB>  <TAB> if self._range: <TAB>  <TAB>  <TAB> if index < self._range[0] or index > self._range[1]: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> error = msg % (self._src, dst, index, item) <MASK> raise AssertionError(error) <TAB> return True",if item != dst :,124
"def schedule_logger(job_id=None, delete=False): <TAB> if not job_id: <TAB>  <TAB> return getLogger(""fate_flow_schedule"") <TAB> else: <TAB>  <TAB> if delete: <TAB>  <TAB>  <TAB> with LoggerFactory.lock: <TAB>  <TAB>  <TAB>  <TAB> try: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> for key in LoggerFactory.schedule_logger_dict.keys(): <MASK> del LoggerFactory.schedule_logger_dict[key] <TAB>  <TAB>  <TAB>  <TAB> except: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB>  <TAB> return True <TAB>  <TAB> key = job_id + ""schedule"" <TAB>  <TAB> if key in LoggerFactory.schedule_logger_dict: <TAB>  <TAB>  <TAB> return LoggerFactory.schedule_logger_dict[key] <TAB>  <TAB> return LoggerFactory.get_schedule_logger(job_id)",if job_id in key :,198
"def Tokenize(s): <TAB> # type: (str) -> Iterator[Token] <TAB> for item in TOKEN_RE.findall(s): <TAB>  <TAB> # The type checker can't know the true type of item! <TAB>  <TAB> item = cast(TupleStr4, item) <TAB>  <TAB> if item[0]: <TAB>  <TAB>  <TAB> typ = ""number"" <TAB>  <TAB>  <TAB> val = item[0] <TAB>  <TAB> elif item[1]: <TAB>  <TAB>  <TAB> typ = ""name"" <TAB>  <TAB>  <TAB> val = item[1] <MASK> typ = item[2] <TAB>  <TAB>  <TAB> val = item[2] <TAB>  <TAB> elif item[3]: <TAB>  <TAB>  <TAB> typ = item[3] <TAB>  <TAB>  <TAB> val = item[3] <TAB>  <TAB> yield Token(typ, val)",elif item [ 2 ] :,181
"def _read_data_from_all_categories(self, directory, config, categories): <TAB> lines = [] <TAB> for category in categories: <TAB>  <TAB> data_file = os.path.join(directory, _DATASET_VERSION, category, config) <MASK> with open(data_file) as f: <TAB>  <TAB>  <TAB>  <TAB> ls = f.read().split(""\n"") <TAB>  <TAB>  <TAB>  <TAB> for l in ls[::-1]: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> if not l: <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ls.remove(l) <TAB>  <TAB>  <TAB>  <TAB> lines.extend(ls) <TAB> return lines",if os . path . exists ( data_file ) :,150
"def find_handlers(self, forms): <TAB> handlers = {} <TAB> for form in forms.itervalues(): <TAB>  <TAB> for action_name, _action_label in form.actions: <MASK> handlers[action_name] = form <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise HandlerError( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> ""More than one form defines the handler %s"" % action_name <TAB>  <TAB>  <TAB>  <TAB> ) <TAB> return handlers",if action_name not in handlers :,112
"def get_story_task_completed_body(payload: Dict[str, Any]) -> Optional[str]: <TAB> action = get_action_with_primary_id(payload) <TAB> kwargs = { <TAB>  <TAB> ""task_description"": action[""description""], <TAB> } <TAB> story_id = action[""story_id""] <TAB> for ref in payload[""references""]: <MASK> kwargs[""name_template""] = STORY_NAME_TEMPLATE.format( <TAB>  <TAB>  <TAB>  <TAB> name=ref[""name""], <TAB>  <TAB>  <TAB>  <TAB> app_url=ref[""app_url""], <TAB>  <TAB>  <TAB> ) <TAB> if action[""changes""][""complete""][""new""]: <TAB>  <TAB> return STORY_TASK_COMPLETED_TEMPLATE.format(**kwargs) <TAB> else: <TAB>  <TAB> return None","if ref [ ""id"" ] == story_id :",188
"def _create_valid_graph(graph): <TAB> nodes = graph.nodes() <TAB> for i in range(len(nodes)): <TAB>  <TAB> for j in range(len(nodes)): <MASK> continue <TAB>  <TAB>  <TAB> edge = (nodes[i], nodes[j]) <TAB>  <TAB>  <TAB> if graph.has_edge(edge): <TAB>  <TAB>  <TAB>  <TAB> graph.del_edge(edge) <TAB>  <TAB>  <TAB> graph.add_edge(edge, 1)",if i == j :,112
"def _post_order(op): <TAB> if isinstance(op, tvm.tir.Allocate): <TAB>  <TAB> lift_stmt[-1].append(op) <TAB>  <TAB> return op.body <TAB> if isinstance(op, tvm.tir.AttrStmt): <MASK> lift_stmt[-1].append(op) <TAB>  <TAB>  <TAB> return op.body <TAB>  <TAB> if op.attr_key == ""virtual_thread"": <TAB>  <TAB>  <TAB> return _merge_block(lift_stmt.pop() + [op], op.body) <TAB>  <TAB> return op <TAB> if isinstance(op, tvm.tir.For): <TAB>  <TAB> return _merge_block(lift_stmt.pop() + [op], op.body) <TAB> raise RuntimeError(""not reached"")","if op . attr_key == ""storage_scope"" :",188
"def format_lazy_import(names): <TAB> """"""Formats lazy import lines"""""" <TAB> lines = """" <TAB> for _, name, asname in names: <TAB>  <TAB> pkg, _, _ = name.partition(""."") <MASK> line = ""{pkg} = _LazyModule.load({pkg!r}, {mod!r})\n"" <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> line = ""{asname} = _LazyModule.load({pkg!r}, {mod!r}, {asname!r})\n"" <TAB>  <TAB> lines += line.format(pkg=pkg, mod=name, asname=asname) <TAB> return lines",if asname is None :,140
"def evaluateWord(self, argument): <TAB> wildcard_count = argument[0].count(""*"") <TAB> if wildcard_count > 0: <TAB>  <TAB> if wildcard_count == 1 and argument[0].startswith(""*""): <TAB>  <TAB>  <TAB> return self.GetWordWildcard(argument[0][1:], method=""endswith"") <TAB>  <TAB> if wildcard_count == 1 and argument[0].endswith(""*""): <TAB>  <TAB>  <TAB> return self.GetWordWildcard(argument[0][:-1], method=""startswith"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> _regex = argument[0].replace(""*"", "".+"") <TAB>  <TAB>  <TAB> matched = False <TAB>  <TAB>  <TAB> for w in self.words: <TAB>  <TAB>  <TAB>  <TAB> matched = bool(re.search(_regex, w)) <MASK> break <TAB>  <TAB>  <TAB> return matched <TAB> return self.GetWord(argument[0])",if matched :,194
"def setup(self, ir: ""IR"", aconf: Config) -> bool: <TAB> if self.kind == ""ConsulResolver"": <TAB>  <TAB> self.resolve_with = ""consul"" <MASK> self.post_error(""ConsulResolver is required to have a datacenter"") <TAB>  <TAB>  <TAB> return False <TAB> elif self.kind == ""KubernetesServiceResolver"": <TAB>  <TAB> self.resolve_with = ""k8s"" <TAB> elif self.kind == ""KubernetesEndpointResolver"": <TAB>  <TAB> self.resolve_with = ""k8s"" <TAB> else: <TAB>  <TAB> self.post_error(f""Resolver kind {self.kind} unknown"") <TAB>  <TAB> return False <TAB> return True","if not self . get ( ""datacenter"" ) :",170
"def get_success_url(self): <TAB> """"""Continue to the flow index or redirect according `?back` parameter."""""" <TAB> if ""back"" in self.request.GET: <TAB>  <TAB> back_url = self.request.GET[""back""] <MASK> back_url = ""/"" <TAB>  <TAB> return back_url <TAB> return reverse(self.success_url)","if not is_safe_url ( url = back_url , allowed_hosts = { self . request . get_host ( ) } ) :",111
"def download_main( <TAB> download, download_playlist, urls, playlist, output_dir, merge, info_only): <TAB> for url in urls: <TAB>  <TAB> if url.startswith(""https://""): <TAB>  <TAB>  <TAB> url = url[8:] <MASK> url = ""http://"" + url <TAB>  <TAB> if playlist: <TAB>  <TAB>  <TAB> download_playlist( <TAB>  <TAB>  <TAB>  <TAB> url, output_dir=output_dir, merge=merge, info_only=info_only <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> download(url, output_dir=output_dir, merge=merge, info_only=info_only)","if not url . startswith ( ""http://"" ) :",155
"def __str__(self): <TAB> buf = [""""] <TAB> if self.fileName: <TAB>  <TAB> buf.append(self.fileName + "":"") <TAB> if self.line != -1: <MASK> buf.append(""line "") <TAB>  <TAB> buf.append(str(self.line)) <TAB>  <TAB> if self.column != -1: <TAB>  <TAB>  <TAB> buf.append("":"" + str(self.column)) <TAB>  <TAB> buf.append("":"") <TAB> buf.append("" "") <TAB> return str("""").join(buf)",if not self . fileName :,124
"def parse_bash_set_output(output): <TAB> """"""Parse Bash-like 'set' output"""""" <TAB> if not sys.platform.startswith(""win""): <TAB>  <TAB> # Replace ""\""-continued lines in *Linux* environment dumps. <TAB>  <TAB> # Cannot do this on Windows because a ""\"" at the end of the <TAB>  <TAB> # line does not imply a continuation. <TAB>  <TAB> output = output.replace(""\\\n"", """") <TAB> environ = {} <TAB> for line in output.splitlines(0): <TAB>  <TAB> line = line.rstrip() <TAB>  <TAB> if not line: <TAB>  <TAB>  <TAB> continue  # skip black lines <TAB>  <TAB> item = _ParseBashEnvStr(line) <MASK> environ[item[0]] = item[1] <TAB> return environ",if item :,177
"def remove_selected(self): <TAB> """"""Removes selected items from list."""""" <TAB> to_delete = [] <TAB> for i in range(len(self)): <TAB>  <TAB> if self[i].selected: <TAB>  <TAB>  <TAB> to_delete.append(i) <TAB> to_delete.reverse() <TAB> for i in to_delete: <TAB>  <TAB> self.pop(i) <TAB> if len(to_delete) > 0: <TAB>  <TAB> first_to_delete = to_delete[-1] <MASK> self[0].selected = True <TAB>  <TAB> elif first_to_delete > 0: <TAB>  <TAB>  <TAB> self[first_to_delete - 1].selected = True",if first_to_delete == 0 and len ( self ) > 0 :,169
"def update(self, update_tracks=True): <TAB> self.enable_update_metadata_images(False) <TAB> old_album_title = self.metadata[""album""] <TAB> self.metadata[""album""] = config.setting[""nat_name""] <TAB> for track in self.tracks: <MASK> track.metadata[""album""] = self.metadata[""album""] <TAB>  <TAB> for file in track.linked_files: <TAB>  <TAB>  <TAB> track.update_file_metadata(file) <TAB> self.enable_update_metadata_images(True) <TAB> super().update(update_tracks)","if old_album_title == track . metadata [ ""album"" ] :",149
"def on_input(self, target, message): <TAB> if message.strip() == """": <TAB>  <TAB> self.panel(""No commit message provided"") <TAB>  <TAB> return <TAB> if target: <TAB>  <TAB> command = [""git"", ""add""] <MASK> command.append(""--all"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> command.extend((""--"", target)) <TAB>  <TAB> self.run_command(command, functools.partial(self.add_done, message)) <TAB> else: <TAB>  <TAB> self.add_done(message, """")","if target == ""*"" :",125
"def go_to_last_edit_location(self): <TAB> if self.last_edit_cursor_pos is not None: <TAB>  <TAB> filename, position = self.last_edit_cursor_pos <MASK> self.last_edit_cursor_pos = None <TAB>  <TAB>  <TAB> return <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.load(filename) <TAB>  <TAB>  <TAB> editor = self.get_current_editor() <TAB>  <TAB>  <TAB> if position < editor.document().characterCount(): <TAB>  <TAB>  <TAB>  <TAB> editor.set_cursor_position(position)",if not osp . isfile ( filename ) :,135
"def returnByType(self, results): <TAB> new_results = {} <TAB> for r in results: <TAB>  <TAB> type_name = r.get(""type"", ""movie"") + ""s"" <MASK> new_results[type_name] = [] <TAB>  <TAB> new_results[type_name].append(r) <TAB> # Combine movies, needs a cleaner way.. <TAB> if ""movies"" in new_results: <TAB>  <TAB> new_results[""movies""] = self.combineOnIMDB(new_results[""movies""]) <TAB> return new_results",if type_name not in new_results :,144
"def cache_sns_topics_across_accounts() -> bool: <TAB> function: str = f""{__name__}.{sys._getframe().f_code.co_name}"" <TAB> # First, get list of accounts <TAB> accounts_d: list = async_to_sync(get_account_id_to_name_mapping)() <TAB> for account_id in accounts_d.keys(): <TAB>  <TAB> if config.get(""environment"") == ""prod"": <TAB>  <TAB>  <TAB> cache_sns_topics_for_account.delay(account_id) <TAB>  <TAB> else: <MASK> cache_sns_topics_for_account.delay(account_id) <TAB> stats.count(f""{function}.success"") <TAB> return True","if account_id in config . get ( ""celery.test_account_ids"" , [ ] ) :",185
"def get(self, subject, topic): <TAB> """"""Handles GET requests."""""" <TAB> if subject in feconf.AVAILABLE_LANDING_PAGES: <MASK> self.render_template(""topic-landing-page.mainpage.html"") <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise self.PageNotFoundException <TAB> else: <TAB>  <TAB> raise self.PageNotFoundException",if topic in feconf . AVAILABLE_LANDING_PAGES [ subject ] :,100
"def callback(compiled): <MASK> logger.show_tabulated( <TAB>  <TAB>  <TAB> ""Compiled"", showpath(codepath), ""without writing to file."" <TAB>  <TAB> ) <TAB> else: <TAB>  <TAB> with univ_open(destpath, ""w"") as opened: <TAB>  <TAB>  <TAB> writefile(opened, compiled) <TAB>  <TAB> logger.show_tabulated(""Compiled to"", showpath(destpath), ""."") <TAB> if self.show: <TAB>  <TAB> print(compiled) <TAB> if run: <TAB>  <TAB> if destpath is None: <TAB>  <TAB>  <TAB> self.execute(compiled, path=codepath, allow_show=False) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self.execute_file(destpath)",if destpath is None :,166
"def _find_start_index(self, string, start, end): <TAB> while True: <TAB>  <TAB> index = string.find(""{"", start, end) - 1 <TAB>  <TAB> if index < 0: <TAB>  <TAB>  <TAB> return -1 <MASK> return index <TAB>  <TAB> start = index + 2","if self . _start_index_is_ok ( string , index ) :",84
"def _get_nlu_target_format(export_path: Text) -> Text: <TAB> guessed_format = loading.guess_format(export_path) <TAB> if guessed_format not in {MARKDOWN, RASA, RASA_YAML}: <TAB>  <TAB> if rasa.shared.data.is_likely_json_file(export_path): <TAB>  <TAB>  <TAB> guessed_format = RASA <TAB>  <TAB> elif rasa.shared.data.is_likely_markdown_file(export_path): <TAB>  <TAB>  <TAB> guessed_format = MARKDOWN <MASK> guessed_format = RASA_YAML <TAB> return guessed_format",elif rasa . shared . data . is_likely_yaml_file ( export_path ) :,166
"def moveToThreadNext(self): <TAB> """"""Move a position to threadNext position."""""" <TAB> p = self <TAB> if p.v: <TAB>  <TAB> if p.v.children: <TAB>  <TAB>  <TAB> p.moveToFirstChild() <TAB>  <TAB> el <MASK> p.moveToNext() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> p.moveToParent() <TAB>  <TAB>  <TAB> while p: <TAB>  <TAB>  <TAB>  <TAB> if p.hasNext(): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> p.moveToNext() <TAB>  <TAB>  <TAB>  <TAB>  <TAB> break  # found <TAB>  <TAB>  <TAB>  <TAB> p.moveToParent() <TAB>  <TAB>  <TAB> # not found. <TAB> return p",if p . hasNext ( ) :,150
"def copy_attributes(info_add, obj, name_fmt, attributes, formatter=None): <TAB> for attr in attributes: <TAB>  <TAB> value = getattr(obj, attr, None) <MASK> continue <TAB>  <TAB> name = name_fmt % attr <TAB>  <TAB> if formatter is not None: <TAB>  <TAB>  <TAB> value = formatter(attr, value) <TAB>  <TAB> info_add(name, value)",if value is None :,97
"def getElement(self, aboutUri, namespace, name): <TAB> for desc in self.rdfRoot.getElementsByTagNameNS(RDF_NAMESPACE, ""Description""): <MASK> attr = desc.getAttributeNodeNS(namespace, name) <TAB>  <TAB>  <TAB> if attr != None: <TAB>  <TAB>  <TAB>  <TAB> yield attr <TAB>  <TAB>  <TAB> for element in desc.getElementsByTagNameNS(namespace, name): <TAB>  <TAB>  <TAB>  <TAB> yield element","if desc . getAttributeNS ( RDF_NAMESPACE , ""about"" ) == aboutUri :",113
def run(self): <TAB> while not self.completed: <TAB>  <TAB> if self.block: <TAB>  <TAB>  <TAB> time.sleep(self.period) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> self._completed.wait(self.period) <TAB>  <TAB> self.counter += 1 <TAB>  <TAB> try: <TAB>  <TAB>  <TAB> self.callback(self.counter) <TAB>  <TAB> except Exception: <TAB>  <TAB>  <TAB> self.stop() <MASK> dt = time.time() - self._start_time <TAB>  <TAB>  <TAB> if dt > self.timeout: <TAB>  <TAB>  <TAB>  <TAB> self.stop() <TAB>  <TAB> if self.counter == self.count: <TAB>  <TAB>  <TAB> self.stop(),if self . timeout is not None :,159
"def _parse_fixits(message, titer, line): <TAB> """"""Parses fixit messages."""""" <TAB> while ( <TAB>  <TAB> OutputParser.message_line_re.match(line) is None <TAB>  <TAB> and OutputParser.note_line_re.match(line) is None <TAB> ): <TAB>  <TAB> message_text = line.strip() <MASK> message.fixits.append( <TAB>  <TAB>  <TAB>  <TAB> Note( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> message.path, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> message.line, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> line.find(message_text) + 1, <TAB>  <TAB>  <TAB>  <TAB>  <TAB> message_text, <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB> line = next(titer) <TAB> return line","if message_text != """" :",177
"def _connect_db(self, force_reconnect=False): <TAB> thread_id = thread.get_ident() <TAB> if force_reconnect and thread_id in ENGINES: <TAB>  <TAB> del ENGINES[thread_id] <TAB> conn = None <TAB> try: <TAB>  <TAB> engine = ENGINES[thread_id] <TAB>  <TAB> conn = engine.connect() <TAB>  <TAB> _test = conn.execute(""SELECT 1"") <TAB>  <TAB> _test.fetchall() <TAB> except (KeyError, MySQLdb.OperationalError): <MASK> conn.close() <TAB>  <TAB> engine = sqla.create_engine(self.db_url, pool_recycle=3600) <TAB>  <TAB> ENGINES[thread_id] = engine <TAB>  <TAB> conn = engine.connect() <TAB> return conn",if conn :,183
"def read(self, n): <TAB> if self.current_frame: <TAB>  <TAB> data = self.current_frame.read(n) <MASK> self.current_frame = None <TAB>  <TAB>  <TAB> return self.file_read(n) <TAB>  <TAB> if len(data) < n: <TAB>  <TAB>  <TAB> raise UnpicklingError(""pickle exhausted before end of frame"") <TAB>  <TAB> return data <TAB> else: <TAB>  <TAB> return self.file_read(n)",if not data and n != 0 :,115
"def __setLoadCmd(self): <TAB> base = self.__rawLoadCmd <TAB> for _ in range(self.__machHeader.ncmds): <TAB>  <TAB> command = LOAD_COMMAND.from_buffer_copy(base) <MASK> segment = SEGMENT_COMMAND.from_buffer_copy(base) <TAB>  <TAB>  <TAB> self.__setSections(segment, base[56:], 32) <TAB>  <TAB> elif command.cmd == MACHOFlags.LC_SEGMENT_64: <TAB>  <TAB>  <TAB> segment = SEGMENT_COMMAND64.from_buffer_copy(base) <TAB>  <TAB>  <TAB> self.__setSections(segment, base[72:], 64) <TAB>  <TAB> base = base[command.cmdsize :]",if command . cmd == MACHOFlags . LC_SEGMENT :,174
"def emit_post_sync_signal(created_models, verbosity, interactive, db): <TAB> # Emit the post_sync signal for every application. <TAB> for app in models.get_apps(): <TAB>  <TAB> app_name = app.__name__.split(""."")[-2] <MASK> print(""Running post-sync handlers for application %s"" % app_name) <TAB>  <TAB> models.signals.post_syncdb.send( <TAB>  <TAB>  <TAB> sender=app, <TAB>  <TAB>  <TAB> app=app, <TAB>  <TAB>  <TAB> created_models=created_models, <TAB>  <TAB>  <TAB> verbosity=verbosity, <TAB>  <TAB>  <TAB> interactive=interactive, <TAB>  <TAB>  <TAB> db=db, <TAB>  <TAB> )",if verbosity >= 2 :,158
"def git_pull(args): <TAB> if len(args) <= 1: <TAB>  <TAB> repo = _get_repo() <TAB>  <TAB> _confirm_dangerous() <TAB>  <TAB> url = args[0] if len(args) == 1 else repo.remotes.get(""origin"", """") <TAB>  <TAB> if url in repo.remotes: <TAB>  <TAB>  <TAB> origin = url <TAB>  <TAB>  <TAB> url = repo.remotes.get(origin) <MASK> repo.pull(origin_uri=url) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> print(""No pull URL."") <TAB> else: <TAB>  <TAB> print(command_help[""git pull""])",if url :,147
"def version(self): <TAB> try: <TAB>  <TAB> return self._version <TAB> except AttributeError: <TAB>  <TAB> for line in self._get_metadata(self.PKG_INFO): <MASK> self._version = safe_version(line.split("":"", 1)[1].strip()) <TAB>  <TAB>  <TAB>  <TAB> return self._version <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> tmpl = ""Missing 'Version:' header and/or %s file"" <TAB>  <TAB>  <TAB> raise ValueError(tmpl % self.PKG_INFO, self)","if line . lower ( ) . startswith ( ""version:"" ) :",127
"def increment(self, metric, labels, delta): <TAB> """"""Increment a value by |delta|."""""" <TAB> with self._lock: <TAB>  <TAB> key = self._get_key(metric.name, labels) <MASK> start_time = self._store[key].start_time <TAB>  <TAB>  <TAB> value = self._store[key].value + delta <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> start_time = time.time() <TAB>  <TAB>  <TAB> value = metric.default_value + delta <TAB>  <TAB> self._store[key] = _StoreValue(metric, labels, start_time, value)",if key in self . _store :,143
"def get_current_connections(session): <TAB> """"""Retrieves open connections using the the given session"""""" <TAB> # Use Show process list to count the open sesions. <TAB> res = session.sql(""SHOW PROCESSLIST"").execute() <TAB> rows = res.fetch_all() <TAB> connections = {} <TAB> for row in rows: <MASK> connections[row.get_string(""User"")] = [row.get_string(""Host"")] <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> connections[row.get_string(""User"")].append(row.get_string(""Host"")) <TAB> return connections","if row . get_string ( ""User"" ) not in connections :",148
"def asset(*paths): <TAB> for path in paths: <TAB>  <TAB> fspath = www_root + ""/assets/"" + path <TAB>  <TAB> etag = """" <TAB>  <TAB> try: <MASK> etag = asset_etag(fspath) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> os.stat(fspath) <TAB>  <TAB> except FileNotFoundError as e: <TAB>  <TAB>  <TAB> if path == paths[-1]: <TAB>  <TAB>  <TAB>  <TAB> if not os.path.exists(fspath + "".spt""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> tell_sentry(e, {}) <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> continue <TAB>  <TAB> except Exception as e: <TAB>  <TAB>  <TAB> tell_sentry(e, {}) <TAB>  <TAB> return asset_url + path + (etag and ""?etag="" + etag)",if env . cache_static :,182
def thread_loop(self) -> None: <TAB> while not self.stop_event.is_set(): <TAB>  <TAB> time.sleep(1) <TAB>  <TAB> new_trials = self.study.trials <TAB>  <TAB> with self.lock: <TAB>  <TAB>  <TAB> need_to_add_callback = self.new_trials is None <TAB>  <TAB>  <TAB> self.new_trials = new_trials <MASK> self.doc.add_next_tick_callback(self.update_callback),if need_to_add_callback :,122
"def _cache_db_tables_iterator(tables, cache_alias, db_alias): <TAB> no_tables = not tables <TAB> cache_aliases = settings.CACHES if cache_alias is None else (cache_alias,) <TAB> db_aliases = settings.DATABASES if db_alias is None else (db_alias,) <TAB> for db_alias in db_aliases: <TAB>  <TAB> if no_tables: <TAB>  <TAB>  <TAB> tables = connections[db_alias].introspection.table_names() <MASK> for cache_alias in cache_aliases: <TAB>  <TAB>  <TAB>  <TAB> yield cache_alias, db_alias, tables",if tables :,145
"def remove_subscriber(self, topic, subscriber): <TAB> if subscriber in self.subscribers[topic]: <TAB>  <TAB> if hasattr(subscriber, ""_pyroRelease""): <TAB>  <TAB>  <TAB> subscriber._pyroRelease() <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> proxy = self.proxy_cache[subscriber._pyroUri] <TAB>  <TAB>  <TAB>  <TAB> proxy._pyroRelease() <TAB>  <TAB>  <TAB>  <TAB> del self.proxy_cache[subscriber._pyroUri] <TAB>  <TAB>  <TAB> except KeyError: <TAB>  <TAB>  <TAB>  <TAB> pass <TAB>  <TAB> self.subscribers[topic].discard(subscriber)","if hasattr ( subscriber , ""_pyroUri"" ) :",139
"def test_constructor(job_id): <TAB> with patch(""apscheduler.job.Job._modify"") as _modify: <TAB>  <TAB> scheduler_mock = MagicMock(BaseScheduler) <TAB>  <TAB> job = Job(scheduler_mock, id=job_id) <TAB>  <TAB> assert job._scheduler is scheduler_mock <TAB>  <TAB> assert job._jobstore_alias is None <TAB>  <TAB> modify_kwargs = _modify.call_args[1] <MASK> assert len(modify_kwargs[""id""]) == 32 <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> assert modify_kwargs[""id""] == job_id",if job_id is None :,141
"def get_connection(self): <TAB> if self.config.proxy_host != """": <TAB>  <TAB> return httplib.HTTPConnection(self.config.proxy_host, self.config.proxy_port) <TAB> else: <MASK> return httplib.HTTPSConnection(self.config.simpledb_host) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> return httplib.HTTPConnection(self.config.simpledb_host)",if self . config . use_https :,107
"def notify_login(self, ipaddress=""""): <TAB> if app.NOTIFY_ON_LOGIN: <TAB>  <TAB> update_text = common.notifyStrings[common.NOTIFY_LOGIN_TEXT] <TAB>  <TAB> title = common.notifyStrings[common.NOTIFY_LOGIN] <MASK> self._notify_pht(title, update_text.format(ipaddress))",if update_text and title and ipaddress :,93
"def _getItemHeight(self, item, ctrl=None): <TAB> """"""Returns the full height of the item to be inserted in the form"""""" <TAB> if type(ctrl) == psychopy.visual.TextBox2: <TAB>  <TAB> return ctrl.size[1] <TAB> if type(ctrl) == psychopy.visual.Slider: <TAB>  <TAB> # Set radio button layout <TAB>  <TAB> if item[""layout""] == ""horiz"": <TAB>  <TAB>  <TAB> return 0.03 + ctrl.labelHeight * 3 <MASK> # for vertical take into account the nOptions <TAB>  <TAB>  <TAB> return ctrl.labelHeight * len(item[""options""])","elif item [ ""layout"" ] == ""vert"" :",155
"def _get_errors_lines(self): <TAB> """"""Return the number of lines that contains errors to highlight."""""" <TAB> errors_lines = [] <TAB> block = self.document().begin() <TAB> while block.isValid(): <TAB>  <TAB> user_data = get_user_data(block) <MASK> errors_lines.append(block.blockNumber()) <TAB>  <TAB> block = block.next() <TAB> return errors_lines",if user_data . error :,105
"def set_pbar_fraction(self, frac, progress, stage=None): <TAB> gtk.gdk.threads_enter() <TAB> try: <TAB>  <TAB> self.is_pulsing = False <TAB>  <TAB> self.set_stage_text(stage or _(""Processing..."")) <TAB>  <TAB> self.pbar.set_text(progress) <TAB>  <TAB> if frac > 1: <TAB>  <TAB>  <TAB> frac = 1.0 <MASK> frac = 0 <TAB>  <TAB> self.pbar.set_fraction(frac) <TAB> finally: <TAB>  <TAB> gtk.gdk.threads_leave()",if frac < 0 :,135
"def list_files(basedir): <TAB> """"""List files in the directory rooted at |basedir|."""""" <TAB> if not os.path.isdir(basedir): <TAB>  <TAB> raise NoSuchDirectory(basedir) <TAB> directories = [""""] <TAB> while directories: <TAB>  <TAB> d = directories.pop() <TAB>  <TAB> for basename in os.listdir(os.path.join(basedir, d)): <TAB>  <TAB>  <TAB> filename = os.path.join(d, basename) <TAB>  <TAB>  <TAB> if os.path.isdir(os.path.join(basedir, filename)): <TAB>  <TAB>  <TAB>  <TAB> directories.append(filename) <MASK> yield filename","elif os . path . exists ( os . path . join ( basedir , filename ) ) :",159
"def assistive(self): <TAB> """"""Detects if item can be used as assistance"""""" <TAB> # Make sure we cache results <TAB> if self.__assistive is None: <TAB>  <TAB> assistive = False <TAB>  <TAB> # Go through all effects and find first assistive <TAB>  <TAB> for effect in self.effects.values(): <MASK> # If we find one, stop and mark item as assistive <TAB>  <TAB>  <TAB>  <TAB> assistive = True <TAB>  <TAB>  <TAB>  <TAB> break <TAB>  <TAB> self.__assistive = assistive <TAB> return self.__assistive",if effect . isAssistance is True :,141
"def closest_unseen(self, row1, col1, filter=None): <TAB> # find the closest unseen from this row/col <TAB> min_dist = maxint <TAB> closest_unseen = None <TAB> for row in range(self.height): <TAB>  <TAB> for col in range(self.width): <TAB>  <TAB>  <TAB> if filter is None or (row, col) not in filter: <TAB>  <TAB>  <TAB>  <TAB> if self.map[row][col] == UNSEEN: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> dist = self.distance(row1, col1, row, col) <MASK> min_dist = dist <TAB>  <TAB>  <TAB>  <TAB>  <TAB>  <TAB> closest_unseen = (row, col) <TAB> return closest_unseen",if dist < min_dist :,174
"def _maybe_has_default_route(self): <TAB> for route in self.iter_routes(): <MASK> return True <TAB> for iface in self.iter_interfaces(): <TAB>  <TAB> for subnet in iface.get(""subnets"", []): <TAB>  <TAB>  <TAB> for route in subnet.get(""routes"", []): <TAB>  <TAB>  <TAB>  <TAB> if self._is_default_route(route): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> return True <TAB> return False",if self . _is_default_route ( route ) :,113
"def data(self, data): <TAB> if data is None: <TAB>  <TAB> raise Exception(""Data cannot be None"") <TAB> val = [] <TAB> for d in data: <TAB>  <TAB> if isinstance(d, str): <TAB>  <TAB>  <TAB> val.append(bytes(d, ""utf-8"")) <MASK> val.append(d) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise Exception( <TAB>  <TAB>  <TAB>  <TAB> ""Invalid type, data can only be an str or a bytes not {}: {}"".format( <TAB>  <TAB>  <TAB>  <TAB>  <TAB> type(data), d <TAB>  <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> ) <TAB> self.__data = val","elif isinstance ( d , bytes ) :",149
"def get_one_segment_function(data, context, echoerr): <TAB> ext = data[""ext""] <TAB> function_name = context[-2][1].get(""function"") <TAB> if function_name: <TAB>  <TAB> module, function_name = get_function_strings(function_name, context, ext) <TAB>  <TAB> func = import_segment(function_name, data, context, echoerr, module=module) <MASK> yield func",if func :,107
"def generic_visit(self, node, parents=None): <TAB> parents = (parents or []) + [node] <TAB> for field, value in iter_fields(node): <TAB>  <TAB> if isinstance(value, list): <TAB>  <TAB>  <TAB> for item in value: <MASK> self.visit(item, parents) <TAB>  <TAB> elif isinstance(value, AST): <TAB>  <TAB>  <TAB> self.visit(value, parents)","if isinstance ( item , AST ) :",106
"def find_scintilla_constants(f): <TAB> lexers = [] <TAB> states = [] <TAB> for name in f.order: <TAB>  <TAB> v = f.features[name] <MASK> if v[""FeatureType""] == ""val"": <TAB>  <TAB>  <TAB>  <TAB> if name.startswith(""SCE_""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> states.append((name, v[""Value""])) <TAB>  <TAB>  <TAB>  <TAB> elif name.startswith(""SCLEX_""): <TAB>  <TAB>  <TAB>  <TAB>  <TAB> lexers.append((name, v[""Value""])) <TAB> return (lexers, states)","if v [ ""Category"" ] != ""Deprecated"" :",137
"def things(self, query): <TAB> limit = query.pop(""limit"", 100) <TAB> offset = query.pop(""offset"", 0) <TAB> keys = set(self.docs) <TAB> for k, v in query.items(): <MASK> # query keys need to be flattened properly, <TAB>  <TAB>  <TAB> # this corrects any nested keys that have been included <TAB>  <TAB>  <TAB> # in values. <TAB>  <TAB>  <TAB> flat = common.flatten_dict(v)[0] <TAB>  <TAB>  <TAB> k += ""."" + web.rstrips(flat[0], "".key"") <TAB>  <TAB>  <TAB> v = flat[1] <TAB>  <TAB> keys = set(k for k in self.filter_index(self.index, k, v) if k in keys) <TAB> keys = sorted(keys) <TAB> return keys[offset : offset + limit]","if isinstance ( v , dict ) :",194
"def del_(self, key): <TAB> initial_hash = hash_ = self.hash(key) <TAB> while True: <TAB>  <TAB> if self._keys[hash_] is self._empty: <TAB>  <TAB>  <TAB> # That key was never assigned <TAB>  <TAB>  <TAB> return None <MASK> # key found, assign with deleted sentinel <TAB>  <TAB>  <TAB> self._keys[hash_] = self._deleted <TAB>  <TAB>  <TAB> self._values[hash_] = self._deleted <TAB>  <TAB>  <TAB> self._len -= 1 <TAB>  <TAB>  <TAB> return <TAB>  <TAB> hash_ = self._rehash(hash_) <TAB>  <TAB> if initial_hash == hash_: <TAB>  <TAB>  <TAB> # table is full and wrapped around <TAB>  <TAB>  <TAB> return None",elif self . _keys [ hash_ ] == key :,166
"def test_204_invalid_content_length(self): <TAB> # 204 status with non-zero content length is malformed <TAB> with ExpectLog(gen_log, "".*Response with code 204 should not have body""): <TAB>  <TAB> response = self.fetch(""/?error=1"") <MASK> self.skipTest(""requires HTTP/1.x"") <TAB>  <TAB> if self.http_client.configured_class != SimpleAsyncHTTPClient: <TAB>  <TAB>  <TAB> self.skipTest(""curl client accepts invalid headers"") <TAB>  <TAB> self.assertEqual(response.code, 599)",if not self . http1 :,136
"def __str__(self) -> str: <TAB> text = ""\n"" <TAB> for k, r in self.result.items(): <TAB>  <TAB> text += ""{}\n"".format(""#"" * 40) <MASK> text += ""# {} (failed)\n"".format(k) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> text += ""# {} (succeeded)\n"".format(k) <TAB>  <TAB> text += ""{}\n"".format(""#"" * 40) <TAB>  <TAB> for sub_r in r: <TAB>  <TAB>  <TAB> text += ""**** {}\n"".format(sub_r.name) <TAB>  <TAB>  <TAB> text += ""{}\n"".format(sub_r) <TAB> return text",if r . failed :,153
"def DeleteTask(): <TAB> oid = request.form.get(""oid"", """") <TAB> if oid: <TAB>  <TAB> result = Mongo.coll[""Task""].delete_one({""_id"": ObjectId(oid)}) <MASK> result = Mongo.coll[""Result""].delete_many({""task_id"": ObjectId(oid)}) <TAB>  <TAB>  <TAB> if result: <TAB>  <TAB>  <TAB>  <TAB> return ""success"" <TAB> return ""fail""",if result . deleted_count > 0 :,108
"def _replace_vars(self, line, extracted, env_variables): <TAB> for e in extracted: <MASK> value = env_variables.get(e) <TAB>  <TAB>  <TAB> if isinstance(value, dict) or isinstance(value, list): <TAB>  <TAB>  <TAB>  <TAB> value = pprint.pformat(value) <TAB>  <TAB>  <TAB> decorated = self._decorate_var(e) <TAB>  <TAB>  <TAB> line = line.replace(decorated, str(value)) <TAB> return line",if e in env_variables :,113
"def should_include(service): <TAB> for f in filt: <TAB>  <TAB> if f == ""status"": <TAB>  <TAB>  <TAB> state = filt[f] <TAB>  <TAB>  <TAB> containers = project.containers([service.name], stopped=True) <TAB>  <TAB>  <TAB> if not has_container_with_state(containers, state): <TAB>  <TAB>  <TAB>  <TAB> return False <TAB>  <TAB> elif f == ""source"": <TAB>  <TAB>  <TAB> source = filt[f] <TAB>  <TAB>  <TAB> if source == ""image"" or source == ""build"": <MASK> return False <TAB>  <TAB>  <TAB> else: <TAB>  <TAB>  <TAB>  <TAB> raise UserError(""Invalid value for source filter: %s"" % source) <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> raise UserError(""Invalid filter: %s"" % f) <TAB> return True",if source not in service . options :,184
def state_callback_loop(): <TAB> if usercallback: <TAB>  <TAB> when = 1 <TAB>  <TAB> while ( <TAB>  <TAB>  <TAB> when <TAB>  <TAB>  <TAB> and not self.future_removed.done() <TAB>  <TAB>  <TAB> and not self.session.shutdownstarttime <TAB>  <TAB> ): <TAB>  <TAB>  <TAB> result = usercallback(self.get_state()) <TAB>  <TAB>  <TAB> when = (await result) if iscoroutine(result) else result <MASK> await sleep(when),if when > 0.0 and not self . session . shutdownstarttime :,122
"def __get_new_timeout(self, timeout): <TAB> """"""When using --timeout_multiplier=#.#"""""" <TAB> self.__check_scope() <TAB> try: <TAB>  <TAB> timeout_multiplier = float(self.timeout_multiplier) <MASK> timeout_multiplier = 0.5 <TAB>  <TAB> timeout = int(math.ceil(timeout_multiplier * timeout)) <TAB>  <TAB> return timeout <TAB> except Exception: <TAB>  <TAB> # Wrong data type for timeout_multiplier (expecting int or float) <TAB>  <TAB> return timeout",if timeout_multiplier <= 0.5 :,126
"def readexactly(self, n): <TAB> buf = b"""" <TAB> while n: <TAB>  <TAB> yield IORead(self.s) <TAB>  <TAB> res = self.s.read(n) <TAB>  <TAB> assert res is not None <MASK> yield IOReadDone(self.s) <TAB>  <TAB>  <TAB> break <TAB>  <TAB> buf += res <TAB>  <TAB> n -= len(res) <TAB> return buf",if not res :,99
"def contract_rendering_pane(event): <TAB> """"""Expand the rendering pane."""""" <TAB> c = event.get(""c"") <TAB> if c: <TAB>  <TAB> vr = c.frame.top.findChild(QtWidgets.QWidget, ""viewrendered_pane"") <MASK> vr.contract() <TAB>  <TAB> else: <TAB>  <TAB>  <TAB> # Just open the pane. <TAB>  <TAB>  <TAB> viewrendered(event)",if vr :,103
"def translate_headers(self, environ): <TAB> """"""Translate CGI-environ header names to HTTP header names."""""" <TAB> for cgiName in environ: <TAB>  <TAB> # We assume all incoming header keys are uppercase already. <MASK> yield self.headerNames[cgiName], environ[cgiName] <TAB>  <TAB> elif cgiName[:5] == ""HTTP_"": <TAB>  <TAB>  <TAB> # Hackish attempt at recovering original header names. <TAB>  <TAB>  <TAB> translatedHeader = cgiName[5:].replace(""_"", ""-"") <TAB>  <TAB>  <TAB> yield translatedHeader, environ[cgiName]",if cgiName in self . headerNames :,134
"def get_value_from_string(self, string_value): <TAB> """"""Return internal representation starting from CFN/user-input value."""""" <TAB> param_value = self.get_default_value() <TAB> try: <MASK> string_value = str(string_value).strip() <TAB>  <TAB>  <TAB> if string_value != ""NONE"": <TAB>  <TAB>  <TAB>  <TAB> param_value = int(string_value) <TAB> except ValueError: <TAB>  <TAB> self.pcluster_config.warn( <TAB>  <TAB>  <TAB> ""Unable to convert the value '{0}' to an Integer. "" <TAB>  <TAB>  <TAB> ""Using default value for parameter '{1}'"".format(string_value, self.key) <TAB>  <TAB> ) <TAB> return param_value",if string_value is not None :,172
"def monitor_filter(self): <TAB> """"""Return filtered service objects list"""""" <TAB> services = self.client.services.list(filters={""label"": ""com.ouroboros.enable""}) <TAB> monitored_services = [] <TAB> for service in services: <TAB>  <TAB> ouro_label = service.attrs[""Spec""][""Labels""].get(""com.ouroboros.enable"") <MASK> monitored_services.append(service) <TAB> self.data_manager.monitored_containers[self.socket] = len(monitored_services) <TAB> self.data_manager.set(self.socket) <TAB> return monitored_services","if not self . config . label_enable or ouro_label . lower ( ) in [ ""true"" , ""yes"" ] :",176
"def nextEditable(self): <TAB> """"""Moves focus of the cursor to the next editable window"""""" <TAB> if self.currentEditable is None: <TAB>  <TAB> if len(self._editableChildren): <TAB>  <TAB>  <TAB> self._currentEditableRef = self._editableChildren[0] <TAB> else: <TAB>  <TAB> for ref in weakref.getweakrefs(self.currentEditable): <TAB>  <TAB>  <TAB> if ref in self._editableChildren: <TAB>  <TAB>  <TAB>  <TAB> cei = self._editableChildren.index(ref) <TAB>  <TAB>  <TAB>  <TAB> nei = cei + 1 <MASK> nei = 0 <TAB>  <TAB>  <TAB>  <TAB> self._currentEditableRef = self._editableChildren[nei] <TAB> return self.currentEditable",if nei >= len ( self . _editableChildren ) :,179
"def linkify_cm_by_tp(self, timeperiods): <TAB> for rm in self: <TAB>  <TAB> mtp_name = rm.modulation_period.strip() <TAB>  <TAB> # The new member list, in id <TAB>  <TAB> mtp = timeperiods.find_by_name(mtp_name) <MASK> err = ( <TAB>  <TAB>  <TAB>  <TAB> ""Error: the business impact modulation '%s' got an unknown "" <TAB>  <TAB>  <TAB>  <TAB> ""modulation_period '%s'"" % (rm.get_name(), mtp_name) <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> rm.configuration_errors.append(err) <TAB>  <TAB> rm.modulation_period = mtp","if mtp_name != """" and mtp is None :",169
def close_open_fds(keep=None):  # noqa <TAB> keep = [maybe_fileno(f) for f in (keep or []) if maybe_fileno(f) is not None] <TAB> for fd in reversed(range(get_fdmax(default=2048))): <MASK> try: <TAB>  <TAB>  <TAB>  <TAB> os.close(fd) <TAB>  <TAB>  <TAB> except OSError as exc: <TAB>  <TAB>  <TAB>  <TAB> if exc.errno != errno.EBADF: <TAB>  <TAB>  <TAB>  <TAB>  <TAB> raise,if fd not in keep :,120
"def _append_child_from_unparsed_xml(father_node, unparsed_xml): <TAB> """"""Append child xml nodes to a node."""""" <TAB> dom_tree = parseString(unparsed_xml) <TAB> if dom_tree.hasChildNodes(): <TAB>  <TAB> first_child = dom_tree.childNodes[0] <MASK> child_nodes = first_child.childNodes <TAB>  <TAB>  <TAB> for _ in range(len(child_nodes)): <TAB>  <TAB>  <TAB>  <TAB> childNode = child_nodes.item(0) <TAB>  <TAB>  <TAB>  <TAB> father_node.appendChild(childNode) <TAB>  <TAB>  <TAB> return <TAB> raise DistutilsInternalError( <TAB>  <TAB> ""Could not Append append elements to "" ""the Windows msi descriptor."" <TAB> )",if first_child . hasChildNodes ( ) :,178
"def process_request(self, request): <TAB> for old, new in self.names_name: <TAB>  <TAB> request.uri = request.uri.replace(old, new) <MASK> body = six.ensure_str(request.body) <TAB>  <TAB>  <TAB> if old in body: <TAB>  <TAB>  <TAB>  <TAB> request.body = body.replace(old, new) <TAB> return request",if is_text_payload ( request ) and request . body :,103
"def __init__(self, **options): <TAB> self.func_name_highlighting = get_bool_opt(options, ""func_name_highlighting"", True) <TAB> self.disabled_modules = get_list_opt(options, ""disabled_modules"", []) <TAB> self._functions = set() <TAB> if self.func_name_highlighting: <TAB>  <TAB> from pygments.lexers._luabuiltins import MODULES <TAB>  <TAB> for mod, func in MODULES.iteritems(): <MASK> self._functions.update(func) <TAB> RegexLexer.__init__(self, **options)",if mod not in self . disabled_modules :,153
"def GetBestSizeForParentSize(self, parentSize): <TAB> """"""Finds the best width and height given the parent's width and height."""""" <TAB> if len(self.GetChildren()) == 1: <TAB>  <TAB> win = self.GetChildren()[0] <MASK> temp_dc = wx.ClientDC(self) <TAB>  <TAB>  <TAB> childSize = win.GetBestSizeForParentSize(parentSize) <TAB>  <TAB>  <TAB> clientParentSize = self._art.GetPanelClientSize( <TAB>  <TAB>  <TAB>  <TAB> temp_dc, self, wx.Size(*parentSize), None <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> overallSize = self._art.GetPanelSize( <TAB>  <TAB>  <TAB>  <TAB> temp_dc, self, wx.Size(*clientParentSize), None <TAB>  <TAB>  <TAB> ) <TAB>  <TAB>  <TAB> return overallSize <TAB> return self.GetSize()","if isinstance ( win , RibbonControl ) :",199